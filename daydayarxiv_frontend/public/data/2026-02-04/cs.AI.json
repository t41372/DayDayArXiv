{
  "date": "2026-02-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2026-02-04 的 arXiv 中文 TLDR 快报！\n\n**今日总结**：\n今天的 arXiv 又是 \"Agentic AI\" 和 \"System 2 Reasoning\"（推理系统）爆发的一天。Google DeepMind 领衔展示了 Gemini 在科学发现中的深度应用，而社区正密集地探讨如何通过**多样性（Diversity）**而非单纯堆砌数量来扩展 Agent 能力，以及如何更聪明地分配推理时的计算预算（Compute Budget）。此外，针对量化模型的微调理论、机器人的跨具身泛化（Cross-Embodiment）也有令人兴奋的进展。\n\n---\n\n### 🚀 封面头条：AI 助力科学与 Gemini 的进击\n\n**2. 加速科学研究：Gemini 的案例研究与通用技术**\n**Accelerating Scientific Research with Gemini: Case Studies and Common Techniques**\n*   **作者**: David P. Woodruff, Vahab Mirrokni (Google) 等\n*   **核心**: Google DeepMind 团队展示了 **Gemini Deep Think** 及其变体如何解决理论计算机科学、经济学和物理学中的开放问题。\n*   **发现**: 文章不仅仅是聊天，而是将模型作为**对抗性审稿人（Adversarial Reviewer）**来检测证明漏洞，并嵌入 \"神经-符号\"（Neuro-symbolic）循环中编写代码验证推导。这标志着 AI 从工具向真正的科研合作伙伴转变。\n\n**3. AutoFigure：生成和优化出版级科学插图**\n**AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations**\n*   **核心**: 科研痛点解决。提出了 FigureBench 基准和 AutoFigure 框架。\n*   **贡献**: 这是一个 Agent 框架，它在渲染最终结果前会进行通过 Recombination 和 Validation 进行“思考”，能根据长篇科学文本自动生成结构合理、美观的科研配图，解决了手动绘图的瓶颈。\n\n---\n\n### 🧠 推理与计算预算 (System 2 Reasoning)\n\n**5. 形式化思维：计算预算下的推理风险控制**\n**Conformal Thinking: Risk Control for Reasoning on a Compute Budget**\n*   **核心**: **自适应推理（Adaptive Reasoning）**。\n*   **发现**: 并不是所有问题都需要长思维链。文章将 Token 预算问题重新构建为风险控制问题。引入了上限阈值（自信时停止推理）和下限阈值（不可解时提前放弃），在保证用户指定的风险目标下最大化计算效率。\n\n**108. 手风琴式思考：自我调节的步骤摘要以实现高效推理**\n**Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning**\n*   **核心**: 上下文压缩与推理效率。\n*   **贡献**: 提出了一种 \"Fold\" 推理模式，模型会周期性地**总结**之前的思维过程并丢弃历史 Token。通过强化学习激励，模型学会了在不牺牲准确率的情况下大幅压缩推理上下文（3倍吞吐量提升），解决了长 CoT 的显存和计算瓶颈。\n\n**63. 自我验证困境：LLM 推理中过度检查的经验驱动抑制**\n**Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning**\n*   **核心**: 反思（Reflection）的效率问题。\n*   **发现**: 大量实验发现，LLM 的自我验证（Self-verification）大多是无效的重复确认，极少纠正错误。作者提出了一种机制，利用过往经验判断何时“没必要检查”，从而在保持准确率的同时减少 20% 的 Token 消耗。\n\n---\n\n### 🤖 Agentic AI：从数量到多样性\n\n**11. 理解多智能体系统的扩展性：多样性是关键**\n**Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity**\n*   **核心**: **Scaling Law for Agents**。\n*   **发现**: 单纯增加同质化 Agent 的数量存在严重的边际收益递减。即：**2 个异构（Heterogeneous）Agent 的表现可能超过 16 个同质 Agent**。这为多智能体系统的设计提供了重要指导：与其堆数量，不如增加模型、提示词或工具的多样性。\n\n**225. MARS：用于自动化 AI 研究的反思性搜索模块化 Agent**\n**MARS: Modular Agent with Reflective Search for Automated AI Research**\n*   **核心**: 自动化科研 Agent。\n*   **贡献**: 针对 AI 研究中评估昂贵的问题，引入了**预算感知规划（Budget-Aware Planning）**和 MCTS（蒙特卡洛树搜索）。MARS 能够像人类研究员一样，通过“设计-分解-实现”的模块化流程管理复杂的代码库，并在 MLE-Bench 上取得了 SOTA。\n\n**183. FIRE-Bench：评估 Agent 对科学洞察的“再发现”能力**\n**FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights**\n*   **核心**: 深度科研能力的评估基准。\n*   **贡献**: 让 Agent 只基于一个高层问题，去“重新发现”机器学习领域的经典论文成果（包括实验设计、代码实现、结论得出）。结果显示，即使是 GPT-5 级别的模型，要完成全周期的科学再发现依然非常困难（F1 < 50）。\n\n---\n\n### 🦾 具身智能与机器人\n\n**93. RDT2：迈向零样本跨具身泛化的 UMI 数据扩展极限**\n**RDT2: Exploring the Scaling Limit of UMI Data Towards Zero-Shot Cross-Embodiment Generalization**\n*   **核心**: 机器人基础模型。\n*   **贡献**: 基于 7B VLM 构建，利用 **10,000 小时** 的多样化机器人数据（通过 UMI 收集）。RDT2 是首批能实现**零样本跨具身（Zero-shot Cross-Embodiment）**泛化的模型之一，能直接操控未见过的机器人平台完成任务。\n\n**171. EAGLE：基于具身感知的通才-专才蒸馏**\n**Embodiment-Aware Generalist Specialist Distillation for Unified Humanoid Whole-Body Control**\n*   **核心**: 人形机器人通用控制。\n*   **贡献**: 解决单一策略难以控制不同构型人形机器人的问题。提出一种迭代的**通才-专才蒸馏（Generalist-Specialist Distillation）**框架，训练出的策略可以直接部署在 Unitree H1, G1 等多种机器人上，支持深蹲、倾斜等复杂动作。\n\n---\n\n### ⚡ 模型效率与量化\n\n**132. 量化进化策略：以低精度成本对量化 LLM 进行高精度微调**\n**Quantized Evolution Strategies: High-precision Fine-tuning of Quantized LLMs at Low-precision Cost**\n*   **核心**: 量化模型微调。\n*   **贡献**: 针对部署在端侧的量化模型难以微调（因为梯度不可导）的问题，提出了 **QES**。它利用进化策略（Evolution Strategies）在量化空间直接优化，结合累积误差反馈，实现了无需反向传播的高效微调。\n\n**220. 每一比特都重要：量化 Transformer 的精度-表达能力权衡**\n**Every Bit Counts: A Theoretical Study of Precision-Expressivity Tradeoffs in Quantized Transformers**\n*   **核心**: 量化的理论边界。\n*   **发现**: 证明了一个硬性阈值：对于某些需要精确匹配（Equality-like）的任务，如果精度低于 $p$ 比特，Transformer 将**理论上无法计算**该函数。这解释了为什么量化会导致模型在某些逻辑任务上突然崩溃。\n\n---\n\n### 🛡️ 安全与防御\n\n**6. 反蒸馏指纹：保护大模型版权**\n**Antidistillation Fingerprinting**\n*   **核心**: 模型水印与版权保护。\n*   **贡献**: 针对“学生模型偷窃教师模型”的行为，提出 ADFP。不同于传统降低质量的水印，它通过**反蒸馏采样**，让学生模型在微调后显现出明显的指纹，且几乎不影响生成质量，即使学生模型架构未知也能检测。\n\n**141. 大海捞针：提取和重建 LLM 后门触发器**\n**The Trigger in the Haystack: Extracting and Reconstructing LLM Backdoor Triggers**\n*   **核心**: 后门检测。\n*   **发现**: 潜伏代理（Sleeper Agents）倾向于记忆有毒数据。作者利用这一特性开发了扫描器，可以在不知道触发词的情况下，通过分析注意力头和输出分布，反向恢复出攻击者的后门触发器。\n\n---\n\n### 🎥 创意与多模态\n\n**1. PrevizWhiz：结合粗糙 3D 场景与 2D 视频的生成式视频预演**\n**PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization**\n*   **核心**: 电影制作辅助工具。\n*   **应用**: 解决了传统电影分镜手绘太慢、3D 资产太贵的问题。系统利用粗糙的 3D 场景结合生成式 AI 模型，快速生成风格化的视频预览，大幅降低了电影预制作的技术门槛。\n\n**53. Morphe：基于视觉基础模型的高保真生成式视频流**\n**Morphe: High-Fidelity Generative Video Streaming with Vision Foundation Model**\n*   **核心**: 下一代视频会议/流媒体。\n*   **贡献**: 利用 VFM（视觉基础模型）强大的理解和生成能力进行视频压缩传输。相比 H.265 **节省了 62.5% 的带宽**，同时保持了视觉高保真度，这可能是未来低带宽环境下高质量视频通话的方向。\n\n---\n\n**39. LLM 能搞定火箭科学吗？探索复杂推理的极限**\n**Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12**\n*   **趣闻**: 将 LLM 放在复杂的轨道力学挑战（GTOC 12）中测试。\n*   **结论**: 现在的模型（如 Gemini 1.5 Pro, o3）在战略构思上得分翻倍，但在**执行层面**（物理单位、边界条件、调试）依然很弱。它们目前更适合做“领域辅助者”而非“自主工程师”。",
  "papers": [
    {
      "arxiv_id": "2602.03838v1",
      "title": "PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization",
      "title_zh": "PrevizWhiz：结合粗略3D场景与2D视频引导的生成式视频视觉预演",
      "authors": [
        "Erzhen Hu",
        "Frederik Brudy",
        "David Ledo",
        "George Fitzmaurice",
        "Fraser Anderson"
      ],
      "abstract": "In pre-production, filmmakers and 3D animation experts must rapidly prototype ideas to explore a film's possibilities before fullscale production, yet conventional approaches involve trade-offs in efficiency and expressiveness. Hand-drawn storyboards often lack spatial precision needed for complex cinematography, while 3D previsualization demands expertise and high-quality rigged assets. To address this gap, we present PrevizWhiz, a system that leverages rough 3D scenes in combination with generative image and video models to create stylized video previews. The workflow integrates frame-level image restyling with adjustable resemblance, time-based editing through motion paths or external video inputs, and refinement into high-fidelity video clips. A study with filmmakers demonstrates that our system lowers technical barriers for film-makers, accelerates creative iteration, and effectively bridges the communication gap, while also surfacing challenges of continuity, authorship, and ethical consideration in AI-assisted filmmaking.",
      "tldr_zh": "该研究提出了 PrevizWhiz，这是一种将粗糙的 3D 场景与生成式图像和视频模型相结合的系统，旨在优化电影预可视化 (Previsualization) 的创作流程。针对传统绘图脚本 (Storyboards) 缺乏空间精确性以及专业 3D 建模门槛高的问题，该系统整合了帧级图像重塑 (Image Restyling)、基于运动路径 (Motion Paths) 或外部视频输入的编辑技术。通过这种工作流，电影制作人能够快速生成具有风格化的高保真视频预览，并根据需要调整画面相似度与动态效果。实验研究表明，PrevizWhiz 显著降低了技术门槛，加速了创意迭代，并有效弥合了团队间的沟通鸿沟。尽管该系统在提升效率方面表现出色，但也引发了关于画面连续性 (Continuity)、作者身份 (Authorship) 以及 AI 辅助创作伦理等方面的深入探讨。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 13 figures; accepted and to appear at CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03838v1",
      "published_date": "2026-02-03 18:56:40 UTC",
      "updated_date": "2026-02-03 18:56:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:32:35.786110+00:00"
    },
    {
      "arxiv_id": "2602.03837v1",
      "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques",
      "title_zh": "利用 Gemini 加速科学研究：案例研究与常用技术",
      "authors": [
        "David P. Woodruff",
        "Vincent Cohen-Addad",
        "Lalit Jain",
        "Jieming Mao",
        "Song Zuo",
        "MohammadHossein Bateni",
        "Simina Branzei",
        "Michael P. Brenner",
        "Lin Chen",
        "Ying Feng",
        "Lance Fortnow",
        "Gang Fu",
        "Ziyi Guan",
        "Zahra Hadizadeh",
        "Mohammad T. Hajiaghayi",
        "Mahdi JafariRaviz",
        "Adel Javanmard",
        "Karthik C. S.",
        "Ken-ichi Kawarabayashi",
        "Ravi Kumar",
        "Silvio Lattanzi",
        "Euiwoong Lee",
        "Yi Li",
        "Ioannis Panageas",
        "Dimitris Paparas",
        "Benjamin Przybocki",
        "Bernardo Subercaseaux",
        "Ola Svensson",
        "Shayan Taherijam",
        "Xuan Wu",
        "Eylon Yogev",
        "Morteza Zadimoghaddam",
        "Samson Zhou",
        "Vahab Mirrokni"
      ],
      "abstract": "Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a \"neuro-symbolic\" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.",
      "tldr_zh": "该研究通过一系列案例展示了谷歌的 Gemini 系列模型（特别是 Gemini Deep Think 及其变体）在加速科学研究方面的潜力，涵盖了理论计算机科学、经济学、优化和物理等多个领域。通过与研究人员协作，这些模型成功解决了多个开放性问题、反驳了既有猜想并生成了新的数学证明。文章提取了有效的人机协作技术，包括迭代细化(iterative refinement)、问题分解(problem decomposition)以及跨学科知识转移(cross-disciplinary knowledge transfer)。除了常规的对话交互，研究还展示了将模型作为对抗性评审(adversarial reviewer)来识别证明中的细微缺陷，以及利用神经符号(neuro-symbolic)循环自动编写代码以验证复杂推导。这些案例共同表明，AI 已进化为科学发现创意过程中真正的合作伙伴，而不仅仅是简单的自动化工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03837v1",
      "published_date": "2026-02-03 18:56:17 UTC",
      "updated_date": "2026-02-03 18:56:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:32:36.432619+00:00"
    },
    {
      "arxiv_id": "2602.03828v1",
      "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations",
      "title_zh": "AutoFigure：生成与优化可供发表的高质量科学插图",
      "authors": [
        "Minjun Zhu",
        "Zhen Lin",
        "Yixuan Weng",
        "Panzhong Lu",
        "Qiujie Xie",
        "Yifan Wei",
        "Sifan Liu",
        "Qiyao Sun",
        "Yue Zhang"
      ],
      "abstract": "High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.",
      "tldr_zh": "该研究针对高质量科学插图创作难的问题，提出了FigureBench，这是首个从长篇科学文本生成科学插图的大规模基准数据集(benchmark)，涵盖了3300个高质量的文本-插图对。同时，研究者设计了AutoFigure，这是首个能够根据长篇文本自动生成科学插图的代理框架(agentic framework)。该框架在最终渲染前会进行深入的思考、重组和验证，以生成结构稳健且美观的布局(layout)，确保插图兼具结构完整性与视觉吸引力。实验结果证明，AutoFigure的表现持续优于各类基线方法(baseline methods)，能够生成符合出版要求(publication-ready)的高质量科学插图。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.DL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03828v1",
      "published_date": "2026-02-03 18:41:43 UTC",
      "updated_date": "2026-02-03 18:41:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:32:38.703592+00:00"
    },
    {
      "arxiv_id": "2602.03817v1",
      "title": "Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion",
      "title_zh": "面向音频-时空融合的自适应证据加权",
      "authors": [
        "Oscar Ovanger",
        "Levi Harris",
        "Timothy H. Keitt"
      ],
      "abstract": "Many machine learning systems have access to multiple sources of evidence for the same prediction target, yet these sources often differ in reliability and informativeness across inputs. In bioacoustic classification, species identity may be inferred both from the acoustic signal and from spatiotemporal context such as location and season; while Bayesian inference motivates multiplicative evidence combination, in practice we typically only have access to discriminative predictors rather than calibrated generative models. We introduce \\textbf{F}usion under \\textbf{IN}dependent \\textbf{C}onditional \\textbf{H}ypotheses (\\textbf{FINCH}), an adaptive log-linear evidence fusion framework that integrates a pre-trained audio classifier with a structured spatiotemporal predictor. FINCH learns a per-sample gating function that estimates the reliability of contextual information from uncertainty and informativeness statistics. The resulting fusion family \\emph{contains} the audio-only classifier as a special case and explicitly bounds the influence of contextual evidence, yielding a risk-contained hypothesis class with an interpretable audio-only fallback. Across benchmarks, FINCH consistently outperforms fixed-weight fusion and audio-only baselines, improving robustness and error trade-offs even when contextual information is weak in isolation. We achieve state-of-the-art performance on CBI and competitive or improved performance on several subsets of BirdSet using a lightweight, interpretable, evidence-based approach. Code is available: \\texttt{\\href{https://anonymous.4open.science/r/birdnoise-85CD/README.md}{anonymous-repository}}",
      "tldr_zh": "该研究针对生物声学分类(bioacoustic classification)中音频信号与时空背景(spatiotemporal context)证据可靠性差异较大的问题，提出了一种名为FINCH (Fusion under INdependent Conditional Hypotheses) 的自适应对数线性证据融合框架。该框架将预训练的音频分类器与结构化时空预测器集成，通过学习每样本门控函数(per-sample gating function)并结合不确定性与信息量统计，实现对背景信息可靠性的动态评估。FINCH明确限制了背景证据的影响范围，并保留了可解释的音频回退机制(audio-only fallback)，从而形成了一个风险受限的假设类。实验结果证明，该框架在多个基准测试中均优于固定权重融合(fixed-weight fusion)及纯音频模型，在背景信息较弱时仍表现出极强的鲁棒性。该方法在CBI数据集上取得了state-of-the-art性能，并在BirdSet的多个子集中展现出竞争优势，为多源证据融合提供了一种轻量且高效的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03817v1",
      "published_date": "2026-02-03 18:21:13 UTC",
      "updated_date": "2026-02-03 18:21:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:32:33.105331+00:00"
    },
    {
      "arxiv_id": "2602.03814v1",
      "title": "Conformal Thinking: Risk Control for Reasoning on a Compute Budget",
      "title_zh": "Conformal Thinking：计算预算约束下的推理风险控制",
      "authors": [
        "Xi Wang",
        "Anushri Suresh",
        "Alvin Zhang",
        "Rishi More",
        "William Jurayj",
        "Benjamin Van Durme",
        "Mehrdad Farajtabar",
        "Daniel Khashabi",
        "Eric Nalisnick"
      ],
      "abstract": "Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.",
      "tldr_zh": "该研究针对推理型大语言模型(Reasoning LLMs)在推理阶段的可扩展性(test-time scaling)问题，探讨了如何在提升准确性的同时优化计算预算(compute budget)的挑战。为此，作者提出了Conformal Thinking框架，将预算设置问题转化为风险控制(risk control)任务，旨在保证错误率低于预设目标的前提下最小化计算开销。该框架引入了一个上限阈值以在模型置信度足够高时停止推理，并设计了一个创新的参数化下限阈值来提前终止不可解的实例，从而避免无效的资源浪费。研究利用无分布风险控制(distribution-free risk control)技术，根据验证集和目标风险自动优化这些停止机制，并结合效率损失函数选择最优的退出方案。实验结果表明，该方法在多种推理任务中均能有效达成用户指定的风险目标，通过下限阈值和集成停止机制显著提升了计算效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03814v1",
      "published_date": "2026-02-03 18:17:22 UTC",
      "updated_date": "2026-02-03 18:17:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:32:56.198449+00:00"
    },
    {
      "arxiv_id": "2602.03812v1",
      "title": "Antidistillation Fingerprinting",
      "title_zh": "反蒸馏指纹技术",
      "authors": [
        "Yixuan Even Xu",
        "John Kirchenbauer",
        "Yash Savani",
        "Asher Trockman",
        "Alexander Robey",
        "Tom Goldstein",
        "Fei Fang",
        "J. Zico Kolter"
      ],
      "abstract": "Model distillation enables efficient emulation of frontier large language models (LLMs), creating a need for robust mechanisms to detect when a third-party student model has trained on a teacher model's outputs. However, existing fingerprinting techniques that could be used to detect such distillation rely on heuristic perturbations that impose a steep trade-off between generation quality and fingerprinting strength, often requiring significant degradation of utility to ensure the fingerprint is effectively internalized by the student. We introduce antidistillation fingerprinting (ADFP), a principled approach that aligns the fingerprinting objective with the student's learning dynamics. Building upon the gradient-based framework of antidistillation sampling, ADFP utilizes a proxy model to identify and sample tokens that directly maximize the expected detectability of the fingerprint in the student after fine-tuning, rather than relying on the incidental absorption of the un-targeted biases of a more naive watermark. Experiments on GSM8K and OASST1 benchmarks demonstrate that ADFP achieves a significant Pareto improvement over state-of-the-art baselines, yielding stronger detection confidence with minimal impact on utility, even when the student model's architecture is unknown.",
      "tldr_zh": "该研究提出了反蒸馏指纹 (Antidistillation Fingerprinting, ADFP)，旨在解决模型蒸馏 (Model distillation) 场景下检测第三方学生模型是否使用教师模型输出训练的问题。现有的指纹 (Fingerprinting) 技术往往依赖启发式扰动，在文本生成质量与指纹强度之间存在严重的权衡，通常需要牺牲大量实用性。ADFP 通过引入代理模型来识别并采样能直接最大化学生模型微调后指纹可检测性的 Token，实现了指纹目标与学生模型学习动态的精准对齐。实验在 GSM8K 和 OASST1 基准上证明，ADFP 相比最先进的基准模型实现了显著的帕累托改进 (Pareto improvement)。该方法在对学生模型架构未知的情况下，仍能以极小的效用损失实现更强的检测置信度，为大语言模型的版权保护提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03812v1",
      "published_date": "2026-02-03 18:15:50 UTC",
      "updated_date": "2026-02-03 18:15:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:33:21.521394+00:00"
    },
    {
      "arxiv_id": "2602.03808v1",
      "title": "Enhancing Imbalanced Node Classification via Curriculum-Guided Feature Learning and Three-Stage Attention Network",
      "title_zh": "基于课程引导特征学习与三阶段注意力网络的不平衡节点分类增强",
      "authors": [
        "Abdul Joseph Fofanah",
        "Lian Wen",
        "David Chen",
        "Shaoyang Zhang"
      ],
      "abstract": "Imbalanced node classification in graph neural networks (GNNs) happens when some labels are much more common than others, which causes the model to learn unfairly and perform badly on the less common classes. To solve this problem, we propose a Curriculum-Guided Feature Learning and Three-Stage Attention Network (CL3AN-GNN), a learning network that uses a three-step attention system (Engage, Enact, Embed) similar to how humans learn. The model begins by engaging with structurally simpler features, defined as (1) local neighbourhood patterns (1-hop), (2) low-degree node attributes, and (3) class-separable node pairs identified via initial graph convolutional networks and graph attention networks (GCN and GAT) embeddings. This foundation enables stable early learning despite label skew. The Enact stage then addresses complicated aspects: (1) connections that require multiple steps, (2) edges that connect different types of nodes, and (3) nodes at the edges of minority classes by using adjustable attention weights. Finally, Embed consolidates these features via iterative message passing and curriculum-aligned loss weighting. We evaluate CL3AN-GNN on eight Open Graph Benchmark datasets spanning social, biological, and citation networks. Experiments show consistent improvements across all datasets in accuracy, F1-score, and AUC over recent state-of-the-art methods. The model's step-by-step method works well with different types of graph datasets, showing quicker results than training everything at once, better performance on new, imbalanced graphs, and clear explanations of each step using gradient stability and attention correlation learning curves. This work provides both a theoretically grounded framework for curriculum learning in GNNs and practical evidence of its effectiveness against imbalances, validated through metrics, convergence speeds, and generalisation tests.",
      "tldr_zh": "该研究提出了CL3AN-GNN，一种结合课程学习引导的特征学习与三阶段注意力网络（Curriculum-Guided Feature Learning and Three-Stage Attention Network），旨在解决图神经网络（GNNs）在不平衡节点分类中由于类别偏差导致的性能下降问题。该模型模拟人类学习路径，通过Engage、Enact和Embed三个阶段逐步学习，首先利用Engage阶段处理1-hop邻域、低度节点及易区分的节点对，以确保在标签偏斜情况下的早期学习稳定性。随后，Enact阶段通过可调注意力权重聚焦于多步连接、异质边以及少数类边界节点等复杂结构信息，最后由Embed阶段通过迭代消息传递和课程对齐损失加权（curriculum-aligned loss weighting）进行特征整合。实验在八个Open Graph Benchmark数据集上验证了该方法的有效性，结果显示其在Accuracy、F1-score和AUC指标上一致优于最新的SOTA模型。此外，CL3AN-GNN还表现出更快的收敛速度、更强的泛化能力以及通过梯度稳定性和注意力曲线体现出的优异可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03808v1",
      "published_date": "2026-02-03 18:10:40 UTC",
      "updated_date": "2026-02-03 18:10:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:33:05.791288+00:00"
    },
    {
      "arxiv_id": "2602.03806v1",
      "title": "Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation",
      "title_zh": "弥合在线与离线强化学习：面向多轮代码生成的上下文老虎机学习",
      "authors": [
        "Ziru Chen",
        "Dongdong Chen",
        "Ruinan Jin",
        "Yingbin Liang",
        "Yujia Xie",
        "Huan Sun"
      ],
      "abstract": "Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.",
      "tldr_zh": "该研究提出了Cobalt，一种旨在弥合在线与离线强化学习(RL)差距的新方法，专门用于优化多轮代码生成(Multi-Turn Code Generation)任务。基于多轮代码生成可建模为单步可恢复马尔可夫决策过程(MDP)的观察，Cobalt首先利用参考模型收集代码生成轨迹，并将其划分为部分轨迹作为上下文提示。在训练过程中，大语言模型(LLM)通过上下文老虎机学习(Contextual Bandit Learning)完成单步生成，有效结合了在线学习的高性能与离线轨迹的稳定性。实验结果显示，Cobalt在LiveCodeBench基准测试中优于GRPO和VeRPO等在线强化学习基线，使R1-Distill 8B和Qwen3 8B的Pass@1分数分别提升了9.0和6.2。此外，研究团队还通过分析LLM在上下文中的奖励作弊(Reward Hacking)行为，引入扰动轨迹增强训练以缓解该问题，证明了Cobalt在处理复杂迭代决策任务中的显著潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03806v1",
      "published_date": "2026-02-03 18:08:41 UTC",
      "updated_date": "2026-02-03 18:08:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:33:11.599161+00:00"
    },
    {
      "arxiv_id": "2602.03802v1",
      "title": "Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods",
      "title_zh": "我们需要异步 SGD 吗？论同步方法的近优性",
      "authors": [
        "Grigory Begunov",
        "Alexander Tyurin"
      ],
      "abstract": "Modern distributed optimization methods mostly rely on traditional synchronous approaches, despite substantial recent progress in asynchronous optimization. We revisit Synchronous SGD and its robust variant, called $m$-Synchronous SGD, and theoretically show that they are nearly optimal in many heterogeneous computation scenarios, which is somewhat unexpected. We analyze the synchronous methods under random computation times and adversarial partial participation of workers, and prove that their time complexities are optimal in many practical regimes, up to logarithmic factors. While synchronous methods are not universal solutions and there exist tasks where asynchronous methods may be necessary, we show that they are sufficient for many modern heterogeneous computation scenarios.",
      "tldr_zh": "该研究重新审视了同步随机梯度下降(Synchronous SGD)及其鲁棒变体$m$-Synchronous SGD在分布式优化中的有效性，挑战了异步优化在异构环境下必然更优的传统观点。通过在随机计算时间和计算节点对抗性部分参与(adversarial partial participation)的框架下进行理论分析，作者证明了同步方法在多种异构计算(heterogeneous computation)场景中具有近乎最优的性能。研究结果显示，在许多实际应用机制中，这些同步方法的时空复杂度(time complexities)在对数因子意义下达到了最优水平。虽然该研究承认异步方法在特定任务中可能仍有必要，但其核心发现表明同步方法对于处理大多数现代异构计算需求已十分充分。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "math.NA",
        "math.OC"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03802v1",
      "published_date": "2026-02-03 18:02:14 UTC",
      "updated_date": "2026-02-03 18:02:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:33:14.324655+00:00"
    },
    {
      "arxiv_id": "2602.03799v1",
      "title": "Conformal Reachability for Safe Control in Unknown Environments",
      "title_zh": "未知环境下安全控制的一致性可达性",
      "authors": [
        "Xinhang Ma",
        "Junlin Wu",
        "Yiannis Kantaros",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "Designing provably safe control is a core problem in trustworthy autonomy. However, most prior work in this regard assumes either that the system dynamics are known or deterministic, or that the state and action space are finite, significantly limiting application scope. We address this limitation by developing a probabilistic verification framework for unknown dynamical systems which combines conformal prediction with reachability analysis. In particular, we use conformal prediction to obtain valid uncertainty intervals for the unknown dynamics at each time step, with reachability then verifying whether safety is maintained within the conformal uncertainty bounds. Next, we develop an algorithmic approach for training control policies that optimize nominal reward while also maximizing the planning horizon with sound probabilistic safety guarantees. We evaluate the proposed approach in seven safe control settings spanning four domains -- cartpole, lane following, drone control, and safe navigation -- for both affine and nonlinear safety specifications. Our experiments show that the policies we learn achieve the strongest provable safety guarantees while still maintaining high average reward.",
      "tldr_zh": "该研究针对未知动力系统中的可证明安全控制(provably safe control)问题，提出了一个结合Conformal Prediction与Reachability Analysis的概率验证框架。该框架利用Conformal Prediction为每个时间步的未知动力学提供有效的不确定性区间(uncertainty intervals)，随后通过Reachability分析验证在这些不确定性边界内是否能维持安全性。基于此，研究团队开发了一种算法用于训练控制策略，在优化标称奖励(nominal reward)的同时，在具备健全概率安全保证的前提下最大化规划时界(planning horizon)。实验在Cartpole、车道跟随(lane following)、无人机控制(drone control)和安全导航(safe navigation)等多个领域的七种设置中进行了评估，涵盖了仿射(affine)和非线性安全规范。结果显示，该方法训练的策略在保持高平均奖励的同时，实现了目前最强的可证明安全保证。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03799v1",
      "published_date": "2026-02-03 18:01:38 UTC",
      "updated_date": "2026-02-03 18:01:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:33:28.555276+00:00"
    },
    {
      "arxiv_id": "2602.03794v1",
      "title": "Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity",
      "title_zh": "从多样性视角理解基于大语言模型的多智能体系统中的智能体扩展",
      "authors": [
        "Yingxuan Yang",
        "Chengrui Qu",
        "Muning Wen",
        "Laixi Shi",
        "Ying Wen",
        "Weinan Zhang",
        "Adam Wierman",
        "Shangding Gu"
      ],
      "abstract": "LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.",
      "tldr_zh": "该研究探讨了基于大语言模型的多智能体系统 (LLM-based multi-agent systems, MAS) 中的智能体扩展问题，发现增加同质智能体数量会产生明显的边际收益递减现象，而引入异质性则能持续带来显著收益。研究提出了一套信息论框架 (information-theoretic framework)，揭示了 MAS 的性能受限于任务固有的不确定性而非智能体数量，并证明性能提升取决于系统接入的有效通道数量。由于同质智能体的输出高度相关会导致性能过早饱和，而异质智能体能提供互补证据，研究进一步引入了有效通道计数 $K^*$ 来量化协作效率。实验结果表明，异质配置在扩展效率上远超同质配置，仅需 2 个多样化智能体即可匹配或超过 16 个同质智能体的表现。该研究为通过多样化设计 (diversity-aware design) 构建高效且鲁棒的 MAS 提供了重要的原则性指导。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03794v1",
      "published_date": "2026-02-03 17:58:10 UTC",
      "updated_date": "2026-02-03 17:58:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:09.515707+00:00"
    },
    {
      "arxiv_id": "2602.03792v1",
      "title": "WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents",
      "title_zh": "WebSentinel：面向 Web 智能体的提示词注入攻击检测与定位",
      "authors": [
        "Xilong Wang",
        "Yinuo Liu",
        "Zhun Wang",
        "Dawn Song",
        "Neil Gong"
      ],
      "abstract": "Prompt injection attacks manipulate webpage content to cause web agents to execute attacker-specified tasks instead of the user's intended ones. Existing methods for detecting and localizing such attacks achieve limited effectiveness, as their underlying assumptions often do not hold in the web-agent setting. In this work, we propose WebSentinel, a two-step approach for detecting and localizing prompt injection attacks in webpages. Given a webpage, Step I extracts \\emph{segments of interest} that may be contaminated, and Step II evaluates each segment by checking its consistency with the webpage content as context. We show that WebSentinel is highly effective, substantially outperforming baseline methods across multiple datasets of both contaminated and clean webpages that we collected. Our code is available at: https://github.com/wxl-lxw/WebSentinel.",
      "tldr_zh": "该研究针对 Web Agents 面临的提示词注入攻击（Prompt injection attacks）提出了 WebSentinel，这是一种旨在检测和定位网页中恶意指令的两步走框架。针对现有检测方法在 Web Agent 场景下有效性受限的问题，WebSentinel 的第一步负责从网页中提取可能被污染的 segments of interest（感兴趣片段），第二步则通过检查这些片段与网页上下文（webpage content as context）的一致性来进行攻击评估。实验结果显示，WebSentinel 在多个包含受污染和纯净网页的数据集上表现出色，其性能显著优于现有的基线方法。该研究为识别网页中的恶意操纵内容提供了高效的解决方案，目前相关代码已在 GitHub 平台开源。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03792v1",
      "published_date": "2026-02-03 17:55:04 UTC",
      "updated_date": "2026-02-03 17:55:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:33:41.851099+00:00"
    },
    {
      "arxiv_id": "2602.03789v1",
      "title": "Fast Sampling for Flows and Diffusions with Lazy and Point Mass Stochastic Interpolants",
      "title_zh": "基于懒惰与点质量随机插值的流与扩散快速采样",
      "authors": [
        "Gabriel Damsholt",
        "Jes Frellsen",
        "Susanne Ditlevsen"
      ],
      "abstract": "Stochastic interpolants unify flows and diffusions, popular generative modeling frameworks. A primary hyperparameter in these methods is the interpolation schedule that determines how to bridge a standard Gaussian base measure to an arbitrary target measure. We prove how to convert a sample path of a stochastic differential equation (SDE) with arbitrary diffusion coefficient under any schedule into the unique sample path under another arbitrary schedule and diffusion coefficient. We then extend the stochastic interpolant framework to admit a larger class of point mass schedules in which the Gaussian base measure collapses to a point mass measure. Under the assumption of Gaussian data, we identify lazy schedule families that make the drift identically zero and show that with deterministic sampling one gets a variance-preserving schedule commonly used in diffusion models, whereas with statistically optimal SDE sampling one gets our point mass schedule. Finally, to demonstrate the usefulness of our theoretical results on realistic highly non-Gaussian data, we apply our lazy schedule conversion to a state-of-the-art pretrained flow model and show that this allows for generating images in fewer steps without retraining the model.",
      "tldr_zh": "该研究探讨了统一流动(Flows)与扩散(Diffusions)生成模型的随机插值(Stochastic Interpolants)框架，并证明了如何在不同调度(Schedule)和扩散系数下转换随机微分方程(SDE)的样本路径。研究进一步扩展了该框架以容纳点质量调度(Point Mass Schedules)，并在高斯数据假设下识别出使漂移(Drift)恒为零的懒惰调度(Lazy Schedules)族。通过理论推导，研究揭示了确定性采样与扩散模型中方差保持调度的联系，以及统计最优SDE采样与点质量调度的关联。实验结果表明，通过将懒惰调度转换应用于最先进的预训练Flow模型，可以在无需重新训练的情况下，以更少的步数实现高效的图像生成。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03789v1",
      "published_date": "2026-02-03 17:48:34 UTC",
      "updated_date": "2026-02-03 17:48:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:18.716744+00:00"
    },
    {
      "arxiv_id": "2602.03786v1",
      "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration",
      "title_zh": "AOrchestra：面向智能体编排的子智能体自动化创建",
      "authors": [
        "Jianhao Ruan",
        "Zhihao Xu",
        "Yiran Peng",
        "Fashen Ren",
        "Zhaoyang Yu",
        "Xinbing Liang",
        "Jinyu Xiang",
        "Bang Liu",
        "Chenglin Wu",
        "Yuyu Luo",
        "Jiayi Zhang"
      ],
      "abstract": "Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra",
      "tldr_zh": "该研究提出了 AOrchestra，这是一个旨在通过自动化子智能体(Sub-Agent)创建来实现智能编排的系统，解决了现有设计在处理复杂长时程任务时缺乏动态抽象和适应性不足的问题。研究团队引入了一种统一且与框架无关的智能体抽象模型，将任何智能体建模为由 Instruction、Context、Tools 和 Model 组成的四元组。AOrchestra 的核心编排器能够根据任务需求，在每一步实时具体化该四元组，通过按需自动创建专门的执行器来委托任务，并精准筛选任务相关的上下文与工具。这种设计不仅显著减少了人工工程量，还支持多样化智能体的即插即用，并实现了性能与成本之间的可控权衡，使系统能够趋近 Pareto-efficient 状态。在 GAIA、SWE-Bench 和 Terminal-Bench 三项挑战性基准测试中，AOrchestra 配合 Gemini-3-Flash 模型时，相比最强基线模型实现了 16.28% 的相对提升，证明了其在复杂任务自动化方面的卓越性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03786v1",
      "published_date": "2026-02-03 17:46:16 UTC",
      "updated_date": "2026-02-03 17:46:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:05.621633+00:00"
    },
    {
      "arxiv_id": "2602.03783v1",
      "title": "Efficient Estimation of Kernel Surrogate Models for Task Attribution",
      "title_zh": "用于任务归因的核代理模型高效估计",
      "authors": [
        "Zhenshuo Zhang",
        "Minxuan Duan",
        "Hongyang R. Zhang"
      ],
      "abstract": "Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing each task, but is computationally infeasible at scale. An alternative approach that builds surrogate models to predict a target task's performance for any subset of training tasks has emerged in recent literature. Prior work focuses on linear surrogate models, which capture first-order relationships, but miss nonlinear interactions such as synergy, antagonism, or XOR-type effects. In this paper, we first consider a unified task weighting framework for analyzing task attribution methods, and show a new connection between linear surrogate models and influence functions through a second-order analysis. Then, we introduce kernel surrogate models, which more effectively represent second-order task interactions. To efficiently learn the kernel surrogate, we develop a gradient-based estimation procedure that leverages a first-order approximation of pretrained models; empirically, this yields accurate estimates with less than $2\\%$ relative error without repeated retraining. Experiments across multiple domains -- including math reasoning in transformers, in-context learning, and multi-objective reinforcement learning -- demonstrate the effectiveness of kernel surrogate models. They achieve a $25\\%$ higher correlation with the leave-one-out ground truth than linear surrogates and influence-function baselines. When used for downstream task selection, kernel surrogate models yield a $40\\%$ improvement in demonstration selection for in-context learning and multi-objective reinforcement learning benchmarks.",
      "tldr_zh": "该研究针对大型语言模型等多任务训练中的任务归因(Task Attribution)问题，旨在量化不同训练任务对目标任务性能的贡献。为了解决留一法重训练(leave-one-out retraining)计算开销过大以及线性代理模型(linear surrogate models)难以捕捉非线性交互的缺陷，作者引入了核代理模型(kernel surrogate models)以更有效地表征二阶任务交互。研究通过统一的任务加权框架揭示了线性代理模型与影响函数(influence functions)之间的内在联系，并提出了一种基于梯度的快速估计程序，利用预训练模型的一阶近似实现了高精度的模型学习。实验证明，该方法在无需重复训练的前提下能将相对误差控制在2%以内，且与真实值的相关性比线性基准提升了25%。在上下文学习(in-context learning)和多目标强化学习(multi-objective reinforcement learning)的下游应用中，核代理模型在示例选择上实现了显著的性能改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages. To appear in ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03783v1",
      "published_date": "2026-02-03 17:43:48 UTC",
      "updated_date": "2026-02-03 17:43:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:04.814079+00:00"
    },
    {
      "arxiv_id": "2602.03778v1",
      "title": "Reward Redistribution for CVaR MDPs using a Bellman Operator on L-infinity",
      "title_zh": "基于 $L_\\infty$ 贝尔曼算子的 CVaR MDP 奖励重分配",
      "authors": [
        "Aneri Muni",
        "Vincent Taboga",
        "Esther Derman",
        "Pierre-Luc Bacon",
        "Erick Delage"
      ],
      "abstract": "Tail-end risk measures such as static conditional value-at-risk (CVaR) are used in safety-critical applications to prevent rare, yet catastrophic events. Unlike risk-neutral objectives, the static CVaR of the return depends on entire trajectories without admitting a recursive Bellman decomposition in the underlying Markov decision process. A classical resolution relies on state augmentation with a continuous variable. However, unless restricted to a specialized class of admissible value functions, this formulation induces sparse rewards and degenerate fixed points. In this work, we propose a novel formulation of the static CVaR objective based on augmentation. Our alternative approach leads to a Bellman operator with: (1) dense per-step rewards; (2) contracting properties on the full space of bounded value functions. Building on this theoretical foundation, we develop risk-averse value iteration and model-free Q-learning algorithms that rely on discretized augmented states. We further provide convergence guarantees and approximation error bounds due to discretization. Empirical results demonstrate that our algorithms successfully learn CVaR-sensitive policies and achieve effective performance-safety trade-offs.",
      "tldr_zh": "该研究针对安全关键应用中的静态 Conditional Value-at-Risk (CVaR) 风险度量，提出了一种基于状态增强的创新奖励重分配方案，以解决其在 Markov decision process (MDPs) 中缺乏递归 Bellman 分解的问题。相较于传统方法易导致奖励稀疏和退化不动点的缺陷，该方案构建了一个具有密集每步奖励且在 $L_\\infty$ 空间上满足收缩特性的 Bellman Operator。在此理论基础上，研究者开发了基于离散化增强状态的风险规避 Value Iteration 和无模型 Q-learning 算法。论文进一步提供了严格的收敛性保证以及由离散化引起的误差界限分析。实验结果表明，该算法能够有效学习 CVaR 敏感策略，并在复杂任务的性能与安全性之间达成理想的权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03778v1",
      "published_date": "2026-02-03 17:39:45 UTC",
      "updated_date": "2026-02-03 17:39:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:33:59.421282+00:00"
    },
    {
      "arxiv_id": "2602.03776v1",
      "title": "DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books",
      "title_zh": "DiffLOB：限价单簿反事实生成的扩散模型",
      "authors": [
        "Zhuohan Wang",
        "Carmine Ventre"
      ],
      "abstract": "Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require interaction with another agent to explore alternative outcomes. This limits their usefulness for stress testing, scenario analysis, and decision-making. We propose \\textbf{DiffLOB}, a regime-conditioned \\textbf{Diff}usion model for controllable and counterfactual generation of \\textbf{LOB} trajectories. DiffLOB explicitly conditions the generative process on future market regimes--including trend, volatility, liquidity, and order-flow imbalance, which enables the model to answer counterfactual queries of the form: ``If the future market regime were X instead of Y, how would the limit order book evolve?'' Our systematic evaluation framework for counterfactual LOB generation consists of three criteria: (1) \\textit{Controllable Realism}, measuring how well generated trajectories can reproduce marginal distributions, temporal dependence structure and regime variables; (2) \\textit{Counterfactual validity}, testing whether interventions on future regimes induce consistent changes in the generated LOB dynamics; (3) \\textit{Counterfactual usefulness}, assessing whether synthetic counterfactual trajectories improve downstream prediction of future market regimes.",
      "tldr_zh": "该研究提出了DiffLOB，一种针对限价指令簿(Limit Order Books, LOB)设计的状态调节扩散模型(Diffusion model)，旨在实现可控且反事实(Counterfactual)的轨迹生成。针对现有LOB生成模型在压力测试和场景分析中表现出的被动性，DiffLOB通过将生成过程明确地建立在未来市场状态（包括趋势、波动性、流动性和订单流失衡）之上，实现了对LOB演变的模拟。该模型能够有效回答“如果未来市场状态改变，LOB将如何演化”的反事实查询，弥补了领域内对虚拟未来情景模拟的空白。研究团队还提出了一个由可控现实性(Controllable Realism)、反事实有效性(Counterfactual validity)和反事实有用性(Counterfactual usefulness)组成的系统化评估框架。实验结果表明，DiffLOB生成的合成反事实轨迹不仅具有高度的真实感，还能显著提升下游对未来市场状态的预测准确性。",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "12 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03776v1",
      "published_date": "2026-02-03 17:34:56 UTC",
      "updated_date": "2026-02-03 17:34:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:19.725386+00:00"
    },
    {
      "arxiv_id": "2602.03775v1",
      "title": "An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents",
      "title_zh": "大语言模型智能体中的集体行为与社会动力学实证研究",
      "authors": [
        "Farnoosh Hashemi",
        "Michael W. Macy"
      ],
      "abstract": "Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and interactions among 32K LLM agents over a year. We start with homophily and social influence among LLMs, learning that similar to humans', their social networks exhibit these fundamental phenomena. Next, we study the toxic language of LLMs, its linguistic features, and their interaction patterns, finding that LLMs show different structural patterns in toxic posting than humans. After studying the ideological leaning in LLMs posts, and the polarization in their community, we focus on how to prevent their potential harmful activities. We present a simple yet effective method, called Chain of Social Thought (CoST), that reminds LLM agents to avoid harmful posting.",
      "tldr_zh": "该项实证研究通过分析 Chirper.ai 平台上 32,000 个 LLM 智能体在一年内产生的 700 万条互动数据，深入探讨了大规模语言模型在社交环境中的集体行为与社会动力学。研究发现 LLM 智能体的社交网络展现出与人类相似的同质性 (homophily) 和社会影响 (social influence) 等基本社会现象。但在毒性语言 (toxic language) 的语言特征和交互模式上，LLM 表现出的结构化特征与人类存在显著差异。此外，研究还分析了智能体群体的意识形态倾向与极化 (polarization) 问题，揭示了其在长期互动中可能产生的社会化影响。为降低潜在的有害行为，研究提出了一种名为 Chain of Social Thought (CoST) 的简单有效方法，通过提示机制引导智能体避免发布有害内容。该研究为理解 LLM 在复杂社交系统中的演化规律及安全治理提供了重要的实证依据。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03775v1",
      "published_date": "2026-02-03 17:34:32 UTC",
      "updated_date": "2026-02-03 17:34:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:17.417733+00:00"
    },
    {
      "arxiv_id": "2602.03772v1",
      "title": "UniGeM: Unifying Data Mixing and Selection via Geometric Exploration and Mining",
      "title_zh": "UniGeM：通过几何探索与挖掘实现数据配比与筛选的统一",
      "authors": [
        "Changhao Wang",
        "Yunfei Yu",
        "Xinhao Yao",
        "Jiaolong Yang",
        "Riccardo Cantoro",
        "Chaobo Li",
        "Qing Cui",
        "Jun Zhou"
      ],
      "abstract": "The scaling of Large Language Models (LLMs) is increasingly limited by data quality. Most methods handle data mixing and sample selection separately, which can break the structure in code corpora. We introduce \\textbf{UniGeM}, a framework that unifies mixing and selection by treating data curation as a \\textit{manifold approximation} problem without training proxy models or relying on external reference datasets. UniGeM operates hierarchically: \\textbf{Macro-Exploration} learns mixing weights with stability-based clustering; \\textbf{Micro-Mining} filters high-quality instances by their geometric distribution to ensure logical consistency. Validated by training 8B and 16B MoE models on 100B tokens, UniGeM achieves \\textbf{2.0$\\times$ data efficiency} over a random baseline and further improves overall performance compared to SOTA methods in reasoning-heavy evaluations and multilingual generalization.",
      "tldr_zh": "该研究提出了 UniGeM 框架，旨在解决大型语言模型 (LLMs) 在扩展过程中面临的数据质量瓶颈，特别是传统方法将数据混合 (Data Mixing) 与样本选择 (Sample Selection) 分离而导致语料逻辑结构受损的问题。UniGeM 将数据策展视为一种流形近似 (Manifold Approximation) 任务，无需训练代理模型或依赖外部参考数据集。该框架采用分层操作模式，通过宏观探索 (Macro-Exploration) 利用基于稳定性的聚类来学习混合权重，并结合微观挖掘 (Micro-Mining) 根据几何分布过滤高质量实例以确保逻辑一致性。在 100B Token 规模下对 8B 和 16B 的混合专家模型 (MoE) 进行的训练实验表明，UniGeM 实现了比随机基线高出 2.0 倍的数据效率。此外，该方法在重推理评估和多语言泛化方面的表现均优于现有的最先进 (SOTA) 方法，显著提升了模型的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03772v1",
      "published_date": "2026-02-03 17:32:56 UTC",
      "updated_date": "2026-02-03 17:32:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:19.419232+00:00"
    },
    {
      "arxiv_id": "2602.03767v1",
      "title": "Decision-oriented benchmarking to transform AI weather forecast access: Application to the Indian monsoon",
      "title_zh": "以决策为导向的基准评估变革人工智能天气预报获取：在印度季风中的应用",
      "authors": [
        "Rajat Masiwal",
        "Colin Aitken",
        "Adam Marchakitus",
        "Mayank Gupta",
        "Katherine Kowal",
        "Hamid A. Pahlavan",
        "Tyler Yang",
        "Y. Qiang Sun",
        "Michael Kremer",
        "Amir Jina",
        "William R. Boos",
        "Pedram Hassanzadeh"
      ],
      "abstract": "Artificial intelligence weather prediction (AIWP) models now often outperform traditional physics-based models on common metrics while requiring orders-of-magnitude less computing resources and time. Open-access AIWP models thus hold promise as transformational tools for helping low- and middle-income populations make decisions in the face of high-impact weather shocks. Yet, current approaches to evaluating AIWP models focus mainly on aggregated meteorological metrics without considering local stakeholders' needs in decision-oriented, operational frameworks. Here, we introduce such a framework that connects meteorology, AI, and social sciences. As an example, we apply it to the 150-year-old problem of Indian monsoon forecasting, focusing on benefits to rain-fed agriculture, which is highly susceptible to climate change. AIWP models skillfully predict an agriculturally relevant onset index at regional scales weeks in advance when evaluated out-of-sample using deterministic and probabilistic metrics. This framework informed a government-led effort in 2025 to send 38 million Indian farmers AI-based monsoon onset forecasts, which captured an unusual weeks-long pause in monsoon progression. This decision-oriented benchmarking framework provides a key component of a blueprint for harnessing the power of AIWP models to help large vulnerable populations adapt to weather shocks in the face of climate variability and change.",
      "tldr_zh": "这项研究提出了一个面向决策的评估框架(Decision-oriented benchmarking framework)，旨在弥合气象学、人工智能(AI)和社会科学之间的鸿沟，从而提升人工智能天气预报(AI weather prediction, AIWP)的实际应用价值。该框架针对当前AIWP模型过分关注气象指标而忽视地方利益相关者实际决策需求的问题，将其应用于复杂的印度季风(Indian monsoon)预报，特别是针对极易受气候变化影响的雨养农业(rain-fed agriculture)。研究证明，AIWP模型在区域尺度上能提前数周通过确定性和概率性指标熟练预测农业相关的季风爆发指数(onset index)。这一框架在2025年成功支持了向3800万印度农民发送预报的政府行动，并准确捕捉到了季风进程中异常的数周停顿。该研究为如何利用AI技术帮助脆弱人群适应气候变率和天气冲击提供了一个关键蓝图。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.GN",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03767v1",
      "published_date": "2026-02-03 17:27:22 UTC",
      "updated_date": "2026-02-03 17:27:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:35.217953+00:00"
    },
    {
      "arxiv_id": "2602.03750v1",
      "title": "Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives",
      "title_zh": "基于零样本大视觉语言模型提示的古放射学 X 射线档案自动化骨骼识别",
      "authors": [
        "Owen Dong",
        "Lily Gao",
        "Manish Kota",
        "Bennett A. Landmana",
        "Jelena Bekvalac",
        "Gaynor Western",
        "Katherine D. Van Schaik"
      ],
      "abstract": "Paleoradiology, the use of modern imaging technologies to study archaeological and anthropological remains, offers new windows on millennial scale patterns of human health. Unfortunately, the radiographs collected during field campaigns are heterogeneous: bones are disarticulated, positioning is ad hoc, and laterality markers are often absent. Additionally, factors such as age at death, age of bone, sex, and imaging equipment introduce high variability. Thus, content navigation, such as identifying a subset of images with a specific projection view, can be time consuming and difficult, making efficient triaging a bottleneck for expert analysis. We report a zero shot prompting strategy that leverages a state of the art Large Vision Language Model (LVLM) to automatically identify the main bone, projection view, and laterality in such images. Our pipeline converts raw DICOM files to bone windowed PNGs, submits them to the LVLM with a carefully engineered prompt, and receives structured JSON outputs, which are extracted and formatted onto a spreadsheet in preparation for validation. On a random sample of 100 images reviewed by an expert board certified paleoradiologist, the system achieved 92% main bone accuracy, 80% projection view accuracy, and 100% laterality accuracy, with low or medium confidence flags for ambiguous cases. These results suggest that LVLMs can substantially accelerate code word development for large paleoradiology datasets, allowing for efficient content navigation in future anthropology workflows.",
      "tldr_zh": "这项研究针对古放射学(Paleoradiology)在研究考古遗骸时面临的X射线档案异质性高、骨骼脱节及标记缺失等导致专家分析效率低下的问题，提出了一种基于大视觉语言模型(LVLM)的零样本提示(Zero-shot Prompting)策略。该工作流程将原始DICOM文件转换为骨窗处理后的PNG格式，通过精心设计的提示词利用LVLM自动识别图像中的主要骨骼、投影视图(Projection View)和侧向性(Laterality)，并将结果提取为结构化JSON输出。在由专业古放射学家评审的100张随机样本测试中，该系统实现了92%的主要骨骼识别准确率、80%的投影视图准确率以及100%的侧向性识别准确率，并能对模糊案例提供置信度标记。研究结果表明，LVLM能够显著加速大型古放射学数据集的检索与分类工作，为未来人类学工作流中的高效内容导航和自动化分诊奠定了技术基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03750v1",
      "published_date": "2026-02-03 17:14:23 UTC",
      "updated_date": "2026-02-03 17:14:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:49.528637+00:00"
    },
    {
      "arxiv_id": "2602.03704v1",
      "title": "Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models",
      "title_zh": "认知多样化选择题生成：基于大语言模型的混合多智能体框架",
      "authors": [
        "Yu Tian",
        "Linh Huynh",
        "Katerina Christhilf",
        "Shubham Chakraborty",
        "Micah Watanabe",
        "Tracy Arner",
        "Danielle McNamara"
      ],
      "abstract": "Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap, we introduce ReQUESTA, a hybrid, multi-agent framework for generating cognitively diverse MCQs that systematically target text-based, inferential, and main idea comprehension. ReQUESTA decomposes MCQ authoring into specialized subtasks and coordinates LLM-powered agents with rule-based components to support planning, controlled generation, iterative evaluation, and post-processing. We evaluated the framework in a large-scale reading comprehension study using academic expository texts, comparing ReQUESTA-generated MCQs with those produced by a single-pass GPT-5 zero-shot baseline. Psychometric analyses of learner responses assessed item difficulty and discrimination, while expert raters evaluated question quality across multiple dimensions, including topic relevance and distractor quality. Results showed that ReQUESTA-generated items were consistently more challenging, more discriminative, and more strongly aligned with overall reading comprehension performance. Expert evaluations further indicated stronger alignment with central concepts and superior distractor linguistic consistency and semantic plausibility, particularly for inferential questions. These findings demonstrate that hybrid, agentic orchestration can systematically improve the reliability and controllability of LLM-based generation, highlighting workflow design as a key lever for structured artifact generation beyond single-pass prompting.",
      "tldr_zh": "该研究提出了ReQUESTA，一个旨在生成具有认知多样性的多项选择题(MCQ)的混合多智能体框架，以解决大语言模型(LLMs)在满足受控认知需求生成方面的挑战。该框架将MCQ编写分解为专门的子任务，通过协调LLM驱动的智能体与基于规则的组件，实现了涵盖规划、受控生成、迭代评估和后处理的协同工作流。在针对学术性说明文的大规模阅读理解研究中，研究人员将ReQUESTA生成的题目与GPT-5零样本基线进行了对比。心理测量分析表明，ReQUESTA生成的题目在难度和区分度上表现更佳，且与读者的整体阅读理解能力高度一致。专家评估进一步证实，该框架在中心概念对齐以及干扰项(distractor)的语言一致性和语义合理性方面具有显著优势，尤其在推理类题目中表现突出。该项研究证明了混合智能体编排(hybrid, agentic orchestration)能系统性提升LLM生成内容的可靠性与可控性，突显了工作流设计在结构化任务生成中的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This manuscript is under review at Electronics",
      "pdf_url": "https://arxiv.org/pdf/2602.03704v1",
      "published_date": "2026-02-03 16:26:47 UTC",
      "updated_date": "2026-02-03 16:26:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:51.616565+00:00"
    },
    {
      "arxiv_id": "2602.03702v1",
      "title": "Anytime Pretraining: Horizon-Free Learning-Rate Schedules with Weight Averaging",
      "title_zh": "随时预训练：结合权重平均的无预设时长学习率调度",
      "authors": [
        "Alexandru Meterez",
        "Pranav Ajit Nair",
        "Depen Morwani",
        "Cengiz Pehlevan",
        "Sham Kakade"
      ],
      "abstract": "Large language models are increasingly trained in continual or open-ended settings, where the total training horizon is not known in advance. Despite this, most existing pretraining recipes are not anytime: they rely on horizon-dependent learning rate schedules and extensive tuning under a fixed compute budget. In this work, we provide a theoretical analysis demonstrating the existence of anytime learning schedules for overparameterized linear regression, and we highlight the central role of weight averaging - also known as model merging - in achieving the minimax convergence rates of stochastic gradient descent. We show that these anytime schedules polynomially decay with time, with the decay rate determined by the source and capacity conditions of the problem. Empirically, we evaluate 150M and 300M parameter language models trained at 1-32x Chinchilla scale, comparing constant learning rates with weight averaging and $1/\\sqrt{t}$ schedules with weight averaging against a well-tuned cosine schedule. Across the full training range, the anytime schedules achieve comparable final loss to cosine decay. Taken together, our results suggest that weight averaging combined with simple, horizon-free step sizes offers a practical and effective anytime alternative to cosine learning rate schedules for large language model pretraining.",
      "tldr_zh": "该研究针对大语言模型在持续学习或开放式预训练中总训练时长未知的挑战，提出了一种无需预设时长的 Anytime Pretraining 学习率调度方案。通过对超参数化线性回归的理论分析，研究者揭示了权重平均 (Weight Averaging)，亦称模型合并 (Model Merging)，在确保随机梯度下降实现最优收敛率中的核心作用。这种 anytime schedules 随时间呈多项式衰减，其具体衰减率取决于问题的特定条件。实验在 150M 和 300M 参数的模型上，涵盖 1-32x Chinchilla 规模，验证了带有权重平均的 $1/\\sqrt{t}$ 或恒定学习率调度。结果表明，这种随时可停的学习率调度在整个训练过程中能取得与经过精细调优的余弦调度 (Cosine Schedule) 相当的最终损失 (Final Loss)。该工作证明了权重平均结合简单的无需预设时长的步长 (Horizon-Free Step Sizes)，是大规模模型预训练中极具实用价值且高效的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03702v1",
      "published_date": "2026-02-03 16:24:05 UTC",
      "updated_date": "2026-02-03 16:24:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:34:56.119062+00:00"
    },
    {
      "arxiv_id": "2602.03695v1",
      "title": "Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems",
      "title_zh": "Agent Primitives：多智能体系统的可复用潜层构建模块",
      "authors": [
        "Haibo Jin",
        "Kuang Peng",
        "Ye Yu",
        "Xiaopeng Yuan",
        "Haohan Wang"
      ],
      "abstract": "While existing multi-agent systems (MAS) can handle complex problems by enabling collaboration among multiple agents, they are often highly task-specific, relying on manually crafted agent roles and interaction prompts, which leads to increased architectural complexity and limited reusability across tasks. Moreover, most MAS communicate primarily through natural language, making them vulnerable to error accumulation and instability in long-context, multi-stage interactions within internal agent histories.\n  In this work, we propose \\textbf{Agent Primitives}, a set of reusable latent building blocks for LLM-based MAS. Inspired by neural network design, where complex models are built from reusable components, we observe that many existing MAS architectures can be decomposed into a small number of recurring internal computation patterns. Based on this observation, we instantiate three primitives: Review, Voting and Selection, and Planning and Execution. All primitives communicate internally via key-value (KV) cache, which improves both robustness and efficiency by mitigating information degradation across multi-stage interactions. To enable automatic system construction, an Organizer agent selects and composes primitives for each query, guided by a lightweight knowledge pool of previously successful configurations, forming a primitive-based MAS.\n  Experiments show that primitives-based MAS improve average accuracy by 12.0-16.5\\% over single-agent baselines, reduce token usage and inference latency by approximately 3$\\times$-4$\\times$ compared to text-based MAS, while incurring only 1.3$\\times$-1.6$\\times$ overhead relative to single-agent inference and providing more stable performance across model backbones.",
      "tldr_zh": "当前的多智能体系统(Multi-Agent Systems, MAS)由于过度依赖任务特定的人工设计和自然语言通信，面临架构复杂、复用性低以及长序列交互中的错误累积等挑战。该研究提出了Agent Primitives，这是一组受神经网络模块化设计启发的、可重用的潜空间构建块，旨在简化LLM-based MAS的构建。研究具体定义了Review、Voting and Selection、以及Planning and Execution三种原子操作，并创新性地利用KV cache进行内部通信，有效减少了多阶段交互中的信息退化并提升了系统鲁棒性。系统还引入了Organizer agent，能够根据轻量化知识池自动选择并组合这些原子操作，实现了多智能体系统的自动化构建。实验结果显示，基于Agent Primitives的MAS相比单智能体基线在准确率上平均提升了12.0%至16.5%。与传统的文本通信MAS相比，该方法在仅产生轻微推理开销的前提下，将Token消耗和推理延迟显著降低了约3至4倍，并在多种模型底座上展现出更佳的稳定性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "16 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.03695v1",
      "published_date": "2026-02-03 16:17:53 UTC",
      "updated_date": "2026-02-03 16:17:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:35:58.027796+00:00"
    },
    {
      "arxiv_id": "2602.03693v1",
      "title": "OCRTurk: A Comprehensive OCR Benchmark for Turkish",
      "title_zh": "OCRTurk：针对土耳其语的全面OCR基准",
      "authors": [
        "Deniz Yılmaz",
        "Evren Ayberk Munis",
        "Çağrı Toraman",
        "Süha Kağan Köse",
        "Burak Aktaş",
        "Mehmet Can Baytekin",
        "Bilge Kaan Görür"
      ],
      "abstract": "Document parsing is now widely used in applications, such as large-scale document digitization, retrieval-augmented generation, and domain-specific pipelines in healthcare and education. Benchmarking these models is crucial for assessing their reliability and practical robustness. Existing benchmarks mostly target high-resource languages and provide limited coverage for low-resource settings, such as Turkish. Moreover, existing studies on Turkish document parsing lack a standardized benchmark that reflects real-world scenarios and document diversity. To address this gap, we introduce OCRTurk, a Turkish document parsing benchmark covering multiple layout elements and document categories at three difficulty levels. OCRTurk consists of 180 Turkish documents drawn from academic articles, theses, slide decks, and non-academic articles. We evaluate seven OCR models on OCRTurk using element-wise metrics. Across difficulty levels, PaddleOCR achieves the strongest overall results, leading most element-wise metrics except figures and attaining high Normalized Edit Distance scores in easy, medium, and hard subsets. We also observe performance variation by document type. Models perform well on non-academic documents, while slideshows become the most challenging.",
      "tldr_zh": "该研究推出了OCRTurk，这是一个针对土耳其语文档解析的综合性基准测试，旨在解决低资源语言在现实场景中缺乏标准化评估的问题。OCRTurk包含180份涵盖学术论文、学位论文、幻灯片和非学术文章的土耳其语文档，并根据布局元素和类别划分为三个难度等级。研究人员利用元素级指标对七种OCR模型进行了深入评估，结果显示PaddleOCR在大多数指标上表现最强，并获得了较高的归一化编辑距离(Normalized Edit Distance)分数。实验还观察到模型性能随文档类型而异，其中非学术文档的处理效果较好，而幻灯片(slideshows)则被证明是最具挑战性的类别。该基准测试为评估土耳其语文档解析的可靠性和实用鲁棒性提供了重要工具，填补了低资源语言在该领域的空白。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EACL 2026 SIGTURK",
      "pdf_url": "https://arxiv.org/pdf/2602.03693v1",
      "published_date": "2026-02-03 16:11:25 UTC",
      "updated_date": "2026-02-03 16:11:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:35:38.424162+00:00"
    },
    {
      "arxiv_id": "2602.03690v1",
      "title": "LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization",
      "title_zh": "受 LLM 启发的小数据大规模优化“预训练-微调”方法",
      "authors": [
        "Zishi Zhang",
        "Jinhui Han",
        "Ming Hu",
        "Yijie Peng"
      ],
      "abstract": "We consider small-data, large-scale decision problems in which a firm must make many operational decisions simultaneously (e.g., across a large product portfolio) while observing only a few, potentially noisy, data points per instance. Inspired by the success of large language models (LLMs), we propose a pretrain-then-finetune approach built on a designed Transformer model to address this challenge. The model is first pretrained on large-scale, domain-informed synthetic data that encode managerial knowledge and structural features of the decision environment, and is then fine-tuned on real observations. This new pipeline offers two complementary advantages: pretraining injects domain knowledge into the learning process and enables the training of high-capacity models using abundant synthetic data, while finetuning adapts the pretrained model to the operational environment and improves alignment with the true data-generating regime. While we have leveraged the Transformer's state-of-the-art representational capacity, particularly its attention mechanism, to efficiently extract cross-task structure, our approach is not an off-the-shelf application. Instead, it relies on problem-specific architectural design and a tailored training procedure to match the decision setting. Theoretically, we develop the first comprehensive error analysis regarding Transformer learning in relevant contexts, establishing nonasymptotic guarantees that validate the method's effectiveness. Critically, our analysis reveals how pretraining and fine-tuning jointly determine performance, with the dominant contribution governed by whichever is more favorable. In particular, finetuning exhibits an economies-of-scale effect, whereby transfer learning becomes increasingly effective as the number of instances grows.",
      "tldr_zh": "该研究针对小数据、大规模决策问题（Small-data, Large-scale Optimization），提出了受大语言模型（LLMs）启发的“预训练-微调”（Pretrain-Then-Finetune）框架，旨在解决单实例观测数据稀缺且含有噪声的挑战。该方案基于定制的 Transformer 模型，先在融入管理知识的大规模合成数据上进行预训练以注入领域知识，再通过真实观测数据进行微调以对齐实际运营环境。研究强调该方法并非直接套用现有模型，而是依赖于针对决策场景的特定架构设计与训练流程，利用注意力机制有效提取跨任务结构。理论上，该研究首次针对相关背景下的 Transformer 学习进行了全面误差分析，并提供了验证其有效性的非渐近保证（Nonasymptotic Guarantees）。研究分析揭示了预训练与微调在性能提升中的共同作用，并指出微调具有显著的规模经济效应（Economies-of-scale），使得迁移学习的有效性随决策实例数量的增加而持续增强。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03690v1",
      "published_date": "2026-02-03 16:08:33 UTC",
      "updated_date": "2026-02-03 16:08:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:35:28.612028+00:00"
    },
    {
      "arxiv_id": "2602.03689v1",
      "title": "Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation",
      "title_zh": "重新审视重排器：面向稳健检索增强生成的边界感知证据选择",
      "authors": [
        "Jiashuo Sun",
        "Pengcheng Jiang",
        "Saizhuo Wang",
        "Jiajun Fan",
        "Heng Wang",
        "Siru Ouyang",
        "Ming Zhong",
        "Yizhu Jiao",
        "Chengsong Huang",
        "Xueqiang Xu",
        "Pengrui Han",
        "Peiran Li",
        "Jiaxin Huang",
        "Ge Liu",
        "Heng Ji",
        "Jiawei Han"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems remain brittle under realistic retrieval noise, even when the required evidence appears in the top-K results. A key reason is that retrievers and rerankers optimize solely for relevance, often selecting either trivial, answer-revealing passages or evidence that lacks the critical information required to answer the question, without considering whether the evidence is suitable for the generator. We propose BAR-RAG, which reframes the reranker as a boundary-aware evidence selector that targets the generator's Goldilocks Zone -- evidence that is neither trivially easy nor fundamentally unanswerable for the generator, but is challenging yet sufficient for inference and thus provides the strongest learning signal. BAR-RAG trains the selector with reinforcement learning using generator feedback, and adopts a two-stage pipeline that fine-tunes the generator under the induced evidence distribution to mitigate the distribution mismatch between training and inference. Experiments on knowledge-intensive question answering benchmarks show that BAR-RAG consistently improves end-to-end performance under noisy retrieval, achieving an average gain of 10.3 percent over strong RAG and reranking baselines while substantially improving robustness. Code is publicly avaliable at https://github.com/GasolSun36/BAR-RAG.",
      "tldr_zh": "该研究提出了BAR-RAG，旨在解决检索增强生成(RAG)系统在面对现实检索噪声时表现出的脆弱性问题。作者指出传统的检索器和重排序器(Reranker)过度关注相关性，而忽视了所选证据是否真正适合生成器(Generator)进行推理。为此，BAR-RAG将重排序器重新定义为边界感知(Boundary-Aware)的证据选择器，重点筛选处于生成器“Goldilocks Zone”的证据，即那些具有挑战性但足以支持推理的关键信息。该框架利用强化学习(Reinforcement Learning)结合生成器反馈进行训练，并采用两阶段管道微调生成器以消除训练与推理之间的分布偏差。实验结果表明，BAR-RAG在知识密集型问答基准测试中相比强基准模型实现了10.3%的平均性能提升，并显著增强了系统的鲁棒性(Robustness)。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 8 tables, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03689v1",
      "published_date": "2026-02-03 16:08:23 UTC",
      "updated_date": "2026-02-03 16:08:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:35:27.730919+00:00"
    },
    {
      "arxiv_id": "2602.03688v1",
      "title": "TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System",
      "title_zh": "TodyComm：面向多轮大语言模型多智能体系统的任务导向动态通信",
      "authors": [
        "Wenzhe Fan",
        "Tommaso Tognoli",
        "Henry Peng Zou",
        "Chunyu Miao",
        "Yibo Wang",
        "Xinhua Zhang"
      ],
      "abstract": "Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic applications where the agents' roles may change \\textit{across rounds} due to dynamic adversary, task progression, or time-varying constraints such as communication bandwidth. In this paper, we propose addressing this issue through TodyComm, a \\textbf{t}ask-\\textbf{o}riented \\textbf{dy}namic \\textbf{comm}unication algorithm. It produces behavior-driven collaboration topologies that adapt to the dynamics at each round, optimizing the utility for the task through policy gradient. Experiments on five benchmarks demonstrate that under both dynamic adversary and communications budgets, TodyComm delivers superior task effectiveness while retaining token efficiency and scalability.",
      "tldr_zh": "该研究针对基于大语言模型(LLM-based)的多智能体系统在多轮协作中固定通信拓扑的局限性，提出了TodyComm这一任务导向的动态通信算法。由于智能体角色常因动态对手(dynamic adversary)、任务进展或通信带宽限制而随轮次发生变化，TodyComm通过策略梯度(policy gradient)生成行为驱动的协作拓扑，使其能够根据每一轮的动态环境自适应调整。该算法旨在优化特定任务的效用，确保智能体间的高效协作。在五个基准测试上的实验结果证明，在面临动态对手和通信预算限制时，TodyComm在保持token效率和可扩展性(scalability)的同时，显著提升了任务的完成效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03688v1",
      "published_date": "2026-02-03 16:07:59 UTC",
      "updated_date": "2026-02-03 16:07:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:35:34.424970+00:00"
    },
    {
      "arxiv_id": "2602.03686v1",
      "title": "QuAIL: Quality-Aware Inertial Learning for Robust Training under Data Corruption",
      "title_zh": "QuAIL：针对数据受损环境下鲁棒训练的质量感知惯性学习",
      "authors": [
        "Mattia Sabella",
        "Alberto Archetti",
        "Pietro Pinoli",
        "Matteo Matteucci",
        "Cinzia Cappiello"
      ],
      "abstract": "Tabular machine learning systems are frequently trained on data affected by non-uniform corruption, including noisy measurements, missing entries, and feature-specific biases. In practice, these defects are often documented only through column-level reliability indicators rather than instance-wise quality annotations, limiting the applicability of many robustness and cleaning techniques. We present QuAIL, a quality-informed training mechanism that incorporates feature reliability priors directly into the learning process. QuAIL augments existing models with a learnable feature-modulation layer whose updates are selectively constrained by a quality-dependent proximal regularizer, thereby inducing controlled adaptation across features of varying trustworthiness. This stabilizes optimization under structured corruption without explicit data repair or sample-level reweighting. Empirical evaluation across 50 classification and regression datasets demonstrates that QuAIL consistently improves average performance over neural baselines under both random and value-dependent corruption, with especially robust behavior in low-data and systematically biased settings. These results suggest that incorporating feature reliability information directly into optimization dynamics is a practical and effective approach for resilient tabular learning.",
      "tldr_zh": "该研究提出了 QuAIL (Quality-Aware Inertial Learning)，一种针对数据损坏环境下的鲁棒训练而设计的质量感知学习机制。针对表格机器学习中常见的非均匀损坏（如噪声测量、缺失项和特征偏见）以及通常仅有的列级可靠性指标，QuAIL 将特征可靠性先验直接引入学习过程。该机制通过为现有模型增加一个可学习的特征调制层 (feature-modulation layer)，并利用质量依赖的近端正则项 (proximal regularizer) 约束其更新，从而在不同可信度的特征间实现受控的自适应。这种方法在无需显式数据修复或样本重加权的情况下，稳定了结构化损坏下的优化过程。在 50 个分类和回归数据集上的实验表明，QuAIL 在随机和值相关损坏下均显著提升了神经基准模型 (neural baselines) 的平均性能，尤其在低数据和系统性偏见设置中表现出极强的稳健性。研究结果证明，将特征可靠性信息直接融入优化动力学是增强表格学习韧性的一种实用且高效的方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03686v1",
      "published_date": "2026-02-03 16:06:30 UTC",
      "updated_date": "2026-02-03 16:06:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:35:43.513040+00:00"
    },
    {
      "arxiv_id": "2602.03685v1",
      "title": "Universal One-third Time Scaling in Learning Peaked Distributions",
      "title_zh": "**Finalizing the Translation**\n\nI've completed the translation. By carefully weighing each term and considering the context provided by the abstract, I'm confident that the Chinese title accurately reflects the original's meaning while sounding natural and authoritative in an academic setting.\n\n尖峰分布学习中的普适三分之一时间标度律",
      "authors": [
        "Yizhou Liu",
        "Ziming Liu",
        "Cengiz Pehlevan",
        "Jeff Gore"
      ],
      "abstract": "Training large language models (LLMs) is computationally expensive, partly because the loss exhibits slow power-law convergence whose origin remains debatable. Through systematic analysis of toy models and empirical evaluation of LLMs, we show that this behavior can arise intrinsically from the use of softmax and cross-entropy. When learning peaked probability distributions, e.g., next-token distributions, these components yield power-law vanishing losses and gradients, creating a fundamental optimization bottleneck. This ultimately leads to power-law time scaling of the loss with a universal exponent of $1/3$. Our results provide a mechanistic explanation for observed neural scaling and suggest new directions for improving LLM training efficiency.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)训练中损失函数呈现缓慢幂律收敛(power-law convergence)的现象，并揭示了其内在机制。通过系统分析，研究发现这种行为源于在学习峰值概率分布(peaked probability distributions)时使用的softmax和交叉熵(cross-entropy)损失函数。这些组件在处理预测下一个标记(next-token distributions)等任务时会导致幂律衰减的损失和梯度消失，从而形成根本性的优化瓶颈。实验证明，这最终导致损失随训练时间呈现出指数为1/3的通用幂律时间缩放(universal one-third time scaling)。该成果为神经缩放定律(neural scaling laws)提供了机械论层面的解释，并为提升LLM训练效率指明了新的方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 6 main text figures, 27 figures in total",
      "pdf_url": "https://arxiv.org/pdf/2602.03685v1",
      "published_date": "2026-02-03 16:06:18 UTC",
      "updated_date": "2026-02-03 16:06:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:36:16.128251+00:00"
    },
    {
      "arxiv_id": "2602.03678v1",
      "title": "ContraLog: Log File Anomaly Detection with Contrastive Learning and Masked Language Modeling",
      "title_zh": "ContraLog：结合对比学习与掩码语言建模的日志文件异常检测",
      "authors": [
        "Simon Dietz",
        "Kai Klede",
        "An Nguyen",
        "Bjoern M Eskofier"
      ],
      "abstract": "Log files record computational events that reflect system state and behavior, making them a primary source of operational insights in modern computer systems. Automated anomaly detection on logs is therefore critical, yet most established methods rely on log parsers that collapse messages into discrete templates, discarding variable values and semantic content. We propose ContraLog, a parser-free and self-supervised method that reframes log anomaly detection as predicting continuous message embeddings rather than discrete template IDs. ContraLog combines a message encoder that produces rich embeddings for individual log messages with a sequence encoder to model temporal dependencies within sequences. The model is trained with a combination of masked language modeling and contrastive learning to predict masked message embeddings based on the surrounding context. Experiments on the HDFS, BGL, and Thunderbird benchmark datasets empirically demonstrate effectiveness on complex datasets with diverse log messages. Additionally, we find that message embeddings generated by ContraLog carry meaningful information and are predictive of anomalies even without sequence context. These results highlight embedding-level prediction as an approach for log anomaly detection, with potential applicability to other event sequences.",
      "tldr_zh": "该研究提出了 ContraLog，一种无解析器 (parser-free) 且自监督的日志异常检测方法，旨在解决传统方法依赖日志解析器 (log parsers) 导致信息丢失的问题。该方法将日志异常检测重新定义为预测连续的消息嵌入 (message embeddings)，而非离散的模板 ID。ContraLog 结合了用于生成单个日志消息丰富嵌入的消息编码器 (message encoder) 和用于建模序列时间依赖性的序列编码器 (sequence encoder)。模型通过掩码语言建模 (Masked Language Modeling) 和对比学习 (Contrastive Learning) 的结合进行训练，旨在根据周围上下文预测被遮蔽的消息嵌入。在 HDFS、BGL 和 Thunderbird 等基准数据集上的实验结果表明，该方法在处理具有多样化日志消息的复杂数据集时表现出极高的有效性。研究还发现 ContraLog 生成的消息嵌入包含丰富的语义信息，即使在没有序列上下文的情况下也具有异常预测能力。这一研究成果突出了嵌入级别预测作为日志异常检测方法的新路径，并展现了其在其他事件序列分析中的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages with 16 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03678v1",
      "published_date": "2026-02-03 15:59:40 UTC",
      "updated_date": "2026-02-03 15:59:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:36:28.326867+00:00"
    },
    {
      "arxiv_id": "2602.03670v1",
      "title": "Equilibrium Propagation for Non-Conservative Systems",
      "title_zh": "非保守系统的平衡传播",
      "authors": [
        "Antonino Emanuele Scurria",
        "Dimitri Vanden Abeele",
        "Bortolo Matteo Mognetti",
        "Serge Massar"
      ],
      "abstract": "Equilibrium Propagation (EP) is a physics-inspired learning algorithm that uses stationary states of a dynamical system both for inference and learning. In its original formulation it is limited to conservative systems, $\\textit{i.e.}$ to dynamics which derive from an energy function. Given their importance in applications, it is important to extend EP to nonconservative systems, $\\textit{i.e.}$ systems with non-reciprocal interactions. Previous attempts to generalize EP to such systems failed to compute the exact gradient of the cost function. Here we propose a framework that extends EP to arbitrary nonconservative systems, including feedforward networks. We keep the key property of equilibrium propagation, namely the use of stationary states both for inference and learning. However, we modify the dynamics in the learning phase by a term proportional to the non-reciprocal part of the interaction so as to obtain the exact gradient of the cost function. This algorithm can also be derived using a variational formulation that generates the learning dynamics through an energy function defined over an augmented state space. Numerical experiments using the MNIST database show that this algorithm achieves better performance and learns faster than previous proposals.",
      "tldr_zh": "该研究提出了一种将 Equilibrium Propagation (EP) 扩展至任意 Non-Conservative Systems 的通用框架，克服了传统 EP 仅限于能量驱动型系统且此前方法难以计算精确梯度的局限。该方法成功将 EP 应用于包括 Feedforward Networks 在内的非对称交互系统，并保留了利用平稳状态进行推理与学习的核心机制。通过在学习阶段引入与交互作用非对称部分成比例的修正项，该框架实现了代价函数精确梯度的计算。此外，研究者还通过增强状态空间上的 Variational Formulation 为该算法提供了理论支撑。在 MNIST 数据库上的数值实验证明，该算法相较于此前的改进方案具有更优的性能表现和更快的收敛速度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "math.DS",
        "physics.class-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages (9 pages main text), 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03670v1",
      "published_date": "2026-02-03 15:52:23 UTC",
      "updated_date": "2026-02-03 15:52:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:36:32.523102+00:00"
    },
    {
      "arxiv_id": "2602.03669v1",
      "title": "Efficient Sequential Neural Network with Spatial-Temporal Attention and Linear LSTM for Robust Lane Detection Using Multi-Frame Images",
      "title_zh": "融合时空注意力和线性 LSTM 的高效序列神经网络，用于多帧图像的鲁棒车道线检测",
      "authors": [
        "Sandeep Patil",
        "Yongqi Dong",
        "Haneen Farah",
        "Hans Hellendoorn"
      ],
      "abstract": "Lane detection is a crucial perception task for all levels of automated vehicles (AVs) and Advanced Driver Assistance Systems, particularly in mixed-traffic environments where AVs must interact with human-driven vehicles (HDVs) and challenging traffic scenarios. Current methods lack versatility in delivering accurate, robust, and real-time compatible lane detection, especially vision-based methods often neglect critical regions of the image and their spatial-temporal (ST) salience, leading to poor performance in difficult circumstances such as serious occlusion and dazzle lighting. This study introduces a novel sequential neural network model with a spatial-temporal attention mechanism to focus on key features of lane lines and exploit salient ST correlations among continuous image frames. The proposed model, built on a standard encoder-decoder structure and common neural network backbones, is trained and evaluated on three large-scale open-source datasets. Extensive experiments demonstrate the strength and robustness of the proposed model, outperforming state-of-the-art methods in various testing scenarios. Furthermore, with the ST attention mechanism, the developed sequential neural network models exhibit fewer parameters and reduced Multiply-Accumulate Operations (MACs) compared to baseline sequential models, highlighting their computational efficiency. Relevant data, code, and models are released at https://doi.org/10.4121/4619cab6-ae4a-40d5-af77-582a77f3d821.",
      "tldr_zh": "该研究提出了一种新型序列神经网络模型，旨在解决自动驾驶车辆(AVs)在复杂交通场景（如严重遮挡和眩光）中的稳健车道线检测问题。该模型基于标准的encoder-decoder结构，引入了空间-时间注意力机制(Spatial-Temporal Attention)和Linear LSTM，以捕捉车道线的关键特征并利用连续图像帧之间的时空显著相关性。通过在三个大型开源数据集上的评估，实验结果显示该模型在多种测试场景下均优于现有的先进(SOTA)方法。此外，得益于ST attention机制的应用，该模型相较于基准序列模型具有更少的参数量和更低的乘加运算量(MACs)，显著提升了计算效率。该研究证明了利用多帧图像的时空特征可以有效增强感知的鲁棒性，为自动驾驶系统提供了更具性能优势的视觉感知方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 9 figures, under review by IEEE T-ITS",
      "pdf_url": "https://arxiv.org/pdf/2602.03669v1",
      "published_date": "2026-02-03 15:51:29 UTC",
      "updated_date": "2026-02-03 15:51:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:37:07.726521+00:00"
    },
    {
      "arxiv_id": "2602.03664v1",
      "title": "Mitigating Conversational Inertia in Multi-Turn Agents",
      "title_zh": "缓解多轮智能体中的对话惯性",
      "authors": [
        "Yang Wan",
        "Zheng Cao",
        "Zhenhao Zhang",
        "Zhengwen Zeng",
        "Shuheng Shen",
        "Changhua Meng",
        "Linchao Zhu"
      ],
      "abstract": "Large language models excel as few-shot learners when provided with appropriate demonstrations, yet this strength becomes problematic in multiturn agent scenarios, where LLMs erroneously mimic their own previous responses as few-shot examples. Through attention analysis, we identify conversational inertia, a phenomenon where models exhibit strong diagonal attention to previous responses, which is associated with imitation bias that constrains exploration. This reveals a tension when transforming few-shot LLMs into agents: longer context enriches environmental feedback for exploitation, yet also amplifies conversational inertia that undermines exploration. Our key insight is that for identical states, actions generated with longer contexts exhibit stronger inertia than those with shorter contexts, enabling construction of preference pairs without environment rewards. Based on this, we propose Context Preference Learning to calibrate model preferences to favor low-inertia responses over highinertia ones. We further provide context management strategies at inference time to balance exploration and exploitation. Experimental results across eight agentic environments and one deep research scenario validate that our framework reduces conversational inertia and achieves performance improvements.",
      "tldr_zh": "该研究针对多轮智能体中存在的对话惯性(Conversational Inertia)问题进行了深入探讨，即大语言模型(LLMs)倾向于将先前的响应误作为少样本示例进行模仿，从而限制了对环境的探索。通过注意力机制分析，作者发现模型对过往响应存在强烈的对角注意力，揭示了长上下文在提供反馈的同时也会放大模仿偏差的矛盾。研究提出了一种上下文偏好学习(Context Preference Learning)方法，利用长短上下文生成的动作差异构建偏好对，在无需环境奖励的情况下校准模型偏好以减少惯性。同时，该框架配合推理阶段的上下文管理策略，有效平衡了智能体的探索与利用。在八个智能体环境及深度研究场景中的实验证明，该方法能显著减轻对话惯性并提升任务性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03664v1",
      "published_date": "2026-02-03 15:47:32 UTC",
      "updated_date": "2026-02-03 15:47:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:36:35.321097+00:00"
    },
    {
      "arxiv_id": "2602.03652v1",
      "title": "RAGTurk: Best Practices for Retrieval Augmented Generation in Turkish",
      "title_zh": "RAGTurk：土耳其语检索增强生成的最佳实践",
      "authors": [
        "Süha Kağan Köse",
        "Mehmet Can Baytekin",
        "Burak Aktaş",
        "Bilge Kaan Görür",
        "Evren Ayberk Munis",
        "Deniz Yılmaz",
        "Muhammed Yusuf Kartal",
        "Çağrı Toraman"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) enhances LLM factuality, yet design guidance remains English-centric, limiting insights for morphologically rich languages like Turkish. We address this by constructing a comprehensive Turkish RAG dataset derived from Turkish Wikipedia and CulturaX, comprising question-answer pairs and relevant passage chunks. We benchmark seven stages of the RAG pipeline, from query transformation and reranking to answer refinement, without task-specific fine-tuning. Our results show that complex methods like HyDE maximize accuracy (85%) that is considerably higher than the baseline (78.70%). Also a Pareto-optimal configuration using Cross-encoder Reranking and Context Augmentation achieves comparable performance (84.60%) with much lower cost. We further demonstrate that over-stacking generative modules can degrade performance by distorting morphological cues, whereas simple query clarification with robust reranking offers an effective solution.",
      "tldr_zh": "该研究提出了RAGTurk，旨在解决检索增强生成（Retrieval-Augmented Generation, RAG）领域缺乏针对土耳其语（Turkish）这类形态丰富语言设计指导的问题。通过利用土耳其语Wikipedia和CulturaX构建大规模数据集，研究者对包括Query Transformation、Reranking和Answer Refinement在内的七个RAG流程阶段进行了基准测试。实验表明，HyDE等复杂方法可将准确率从基线（baseline）的78.70%提升至85%，而采用Cross-encoder Reranking和Context Augmentation的Pareto-optimal配置则能在较低成本下实现84.60%的性能。研究还发现，过度堆叠生成模块会因破坏形态特征（morphological cues）而降低效果，相比之下，简单的Query Clarification结合鲁棒的Reranking提供了更有效的解决方案。该研究为非英语语境下的RAG系统构建提供了重要的实践指南。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EACL 2026 SIGTURK",
      "pdf_url": "https://arxiv.org/pdf/2602.03652v1",
      "published_date": "2026-02-03 15:35:11 UTC",
      "updated_date": "2026-02-03 15:35:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:36:58.021308+00:00"
    },
    {
      "arxiv_id": "2602.03647v1",
      "title": "Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration",
      "title_zh": "Search-R2：通过 Actor-Refiner 协作增强搜索集成推理",
      "authors": [
        "Bowei He",
        "Minda Hu",
        "Zenan Xu",
        "Hongru Wang",
        "Licheng Zong",
        "Yankai Chen",
        "Chen Ma",
        "Xue Liu",
        "Pluto Zhou",
        "Irwin King"
      ],
      "abstract": "Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a 'cut-and-regenerate' mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy, proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.",
      "tldr_zh": "该研究提出了Search-R2，一种旨在增强搜索集成推理(Search-integrated reasoning)能力的Actor-Refiner协作框架，解决了强化学习在处理多尺度信用分配(multi-scale credit assignment)时因奖励稀疏导致的无效搜索问题。该框架将生成过程分解为负责初始推理的Actor，以及通过“剪切并重新生成”(cut-and-regenerate)机制选择性诊断并修复错误步骤的Meta-Refiner。为了实现精细化监督，研究设计了混合奖励机制，将结果正确性与衡量检索证据信息密度的密集过程奖励(dense process reward)相结合。理论分析证明了这种选择性校正策略相较于强基准模型具有显著的性能提升。在多项通用及多跳问答任务中的实验表明，Search-R2在多种模型规模下均显著优于传统的检索增强生成(RAG)和基于强化学习(RL)的基准方法，能够以极低的额外开销显著提升推理准确性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03647v1",
      "published_date": "2026-02-03 15:32:09 UTC",
      "updated_date": "2026-02-03 15:32:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:36:40.827219+00:00"
    },
    {
      "arxiv_id": "2602.03640v1",
      "title": "Tutorial on Reasoning for IR & IR for Reasoning",
      "title_zh": "面向信息检索的推理与面向推理的信息检索：专题教程",
      "authors": [
        "Mohanna Hoveyda",
        "Panagiotis Efstratiadis",
        "Arjen de Vries",
        "Maarten de Rijke"
      ],
      "abstract": "Information retrieval has long focused on ranking documents by semantic relatedness. Yet many real-world information needs demand more: enforcement of logical constraints, multi-step inference, and synthesis of multiple pieces of evidence. Addressing these requirements is, at its core, a problem of reasoning. Across AI communities, researchers are developing diverse solutions for the problem of reasoning, from inference-time strategies and post-training of LLMs, to neuro-symbolic systems, Bayesian and probabilistic frameworks, geometric representations, and energy-based models. These efforts target the same problem: to move beyond pattern-matching systems toward structured, verifiable inference. However, they remain scattered across disciplines, making it difficult for IR researchers to identify the most relevant ideas and opportunities. To help navigate the fragmented landscape of research in reasoning, this tutorial first articulates a working definition of reasoning within the context of information retrieval and derives from it a unified analytical framework. The framework maps existing approaches along axes that reflect the core components of the definition. By providing a comprehensive overview of recent approaches and mapping current methods onto the defined axes, we expose their trade-offs and complementarities, highlight where IR can benefit from cross-disciplinary advances, and illustrate how retrieval process itself can play a central role in broader reasoning systems. The tutorial will equip participants with both a conceptual framework and practical guidance for enhancing reasoning-capable IR systems, while situating IR as a domain that both benefits and contributes to the broader development of reasoning methodologies.",
      "tldr_zh": "该教程探讨了信息检索(Information Retrieval, IR)领域从单纯的语义相关性排序向逻辑约束、多步推理和证据合成等更高级推理需求转变的必然性。针对当前推理研究在LLMs、神经符号系统(neuro-symbolic systems)及概率框架等多个学科间分散化的现状，该教程旨在为IR研究者提供一个清晰的导航路径。研究首先在IR语境下给出了推理(reasoning)的工作定义，并据此推导出一个统一的分析框架。该框架沿多个核心轴向对现有方法进行映射，深入剖析了不同技术在结构化与可验证推理(verifiable inference)方面的权衡与互补性。教程不仅强调了检索过程本身在更广泛推理系统中可以发挥的核心作用，还揭示了IR如何通过跨学科进展获得提升。通过提供概念框架与实践指导，该教程旨在增强IR系统处理复杂推理任务的能力，同时确立IR在通用推理方法论发展中的重要地位。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to ECIR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03640v1",
      "published_date": "2026-02-03 15:24:36 UTC",
      "updated_date": "2026-02-03 15:24:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:37:10.124966+00:00"
    },
    {
      "arxiv_id": "2602.03633v1",
      "title": "BIRDTurk: Adaptation of the BIRD Text-to-SQL Dataset to Turkish",
      "title_zh": "BIRDTurk：BIRD Text-to-SQL 数据集的土耳其语适配",
      "authors": [
        "Burak Aktaş",
        "Mehmet Can Baytekin",
        "Süha Kağan Köse",
        "Ömer İlbilgi",
        "Elif Özge Yılmaz",
        "Çağrı Toraman",
        "Bilge Kaan Görür"
      ],
      "abstract": "Text-to-SQL systems have achieved strong performance on English benchmarks, yet their behavior in morphologically rich, low-resource languages remains largely unexplored. We introduce BIRDTurk, the first Turkish adaptation of the BIRD benchmark, constructed through a controlled translation pipeline that adapts schema identifiers to Turkish while strictly preserving the logical structure and execution semantics of SQL queries and databases. Translation quality is validated on a sample size determined by the Central Limit Theorem to ensure 95% confidence, achieving 98.15% accuracy on human-evaluated samples. Using BIRDTurk, we evaluate inference-based prompting, agentic multi-stage reasoning, and supervised fine-tuning. Our results reveal that Turkish introduces consistent performance degradation, driven by both structural linguistic divergence and underrepresentation in LLM pretraining, while agentic reasoning demonstrates stronger cross-lingual robustness. Supervised fine-tuning remains challenging for standard multilingual baselines but scales effectively with modern instruction-tuned models. BIRDTurk provides a controlled testbed for cross-lingual Text-to-SQL evaluation under realistic database conditions. We release the training and development splits to support future research.",
      "tldr_zh": "该研究推出了 BIRDTurk，这是首个将 BIRD 基准适配至土耳其语的 Text-to-SQL 数据集，旨在探索形态丰富且低资源语言在该领域的表现。通过受控的翻译流水线，研究者在严格保留 SQL 查询逻辑和执行语义的前提下完成了架构适配，并利用 Central Limit Theorem 验证了翻译的高准确性。研究评估了推理提示、智能体多阶段推理 (agentic multi-stage reasoning) 和 Supervised Fine-tuning (SFT) 的表现，发现土耳其语的结构特征和预训练不足会导致性能持续下降。实验结果显示，智能体推理在跨语言场景中具有更强的鲁棒性，而 SFT 在现代指令微调模型上效果显著。BIRDTurk 为现实数据库条件下的跨语言 Text-to-SQL 评估提供了受控测试平台，并公开发布了数据集以促进后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EACL 2026 SIGTURK",
      "pdf_url": "https://arxiv.org/pdf/2602.03633v1",
      "published_date": "2026-02-03 15:21:00 UTC",
      "updated_date": "2026-02-03 15:21:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:37:31.022387+00:00"
    },
    {
      "arxiv_id": "2602.03630v1",
      "title": "Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12",
      "title_zh": "LLM 能搞火箭科学吗？基于 GTOC 12 探索复杂推理的边界",
      "authors": [
        "Iñaki del Campo",
        "Pablo Cuervo",
        "Victor Rodriguez-Fernandez",
        "Roberto Armellin",
        "Jack Yarndley"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in code generation and general reasoning, yet their capacity for autonomous multi-stage planning in high-dimensional, physically constrained environments remains an open research question. This study investigates the limits of current AI agents by evaluating them against the 12th Global Trajectory Optimization Competition (GTOC 12), a complex astrodynamics challenge requiring the design of a large-scale asteroid mining campaign. We adapt the MLE-Bench framework to the domain of orbital mechanics and deploy an AIDE-based agent architecture to autonomously generate and refine mission solutions. To assess performance beyond binary validity, we employ an \"LLM-as-a-Judge\" methodology, utilizing a rubric developed by domain experts to evaluate strategic viability across five structural categories. A comparative analysis of models, ranging from GPT-4-Turbo to reasoning-enhanced architectures like Gemini 2.5 Pro, and o3, reveals a significant trend: the average strategic viability score has nearly doubled in the last two years (rising from 9.3 to 17.2 out of 26). However, we identify a critical capability gap between strategy and execution. While advanced models demonstrate sophisticated conceptual understanding, correctly framing objective functions and mission architectures, they consistently fail at implementation due to physical unit inconsistencies, boundary condition errors, and inefficient debugging loops. We conclude that, while current LLMs often demonstrate sufficient knowledge and intelligence to tackle space science tasks, they remain limited by an implementation barrier, functioning as powerful domain facilitators rather than fully autonomous engineers.",
      "tldr_zh": "这项研究通过第12届全球轨迹优化竞赛(GTOC 12)的天体力学挑战，探讨了大语言模型(LLMs)在处理高维度、受物理约束的复杂推理任务中的能力。研究团队适配了 MLE-Bench 框架并采用基于 AIDE 的智能体架构，使 LLMs 能够自主生成并改进大规模小行星采矿任务的方案。通过 \"LLM-as-a-Judge\" 方法对 GPT-4-Turbo、Gemini 1.5 Pro 和 o3 等模型进行评估，结果显示其平均策略可行性得分在两年内从 9.3 显著提升至 17.2。尽管先进模型展现了卓越的战略构思和目标函数构建能力，但由于物理单位(physical unit)不一致、边界条件(boundary condition)错误以及调试循环(debugging loops)效率低下，在执行层面仍存在明显短板。研究得出结论，当前的 LLMs 虽具备处理航天科学任务的知识和智能，但受限于执行障碍，目前更倾向于充当功能强大的领域协调者而非完全自主的工程师。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of the paper presented at AIAA SciTech 2026 Forum. Includes futher experiments, corrections and new appendix",
      "pdf_url": "https://arxiv.org/pdf/2602.03630v1",
      "published_date": "2026-02-03 15:18:26 UTC",
      "updated_date": "2026-02-03 15:18:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:37:11.328227+00:00"
    },
    {
      "arxiv_id": "2602.03608v1",
      "title": "Controlling Output Rankings in Generative Engines for LLM-based Search",
      "title_zh": "基于大语言模型搜索的生成式引擎输出排名控制",
      "authors": [
        "Haibo Jin",
        "Ruoxi Chen",
        "Peiyan Zhang",
        "Yifeng Luo",
        "Huimin Zeng",
        "Man Luo",
        "Haohan Wang"
      ],
      "abstract": "The way customers search for and choose products is changing with the rise of large language models (LLMs). LLM-based search, or generative engines, provides direct product recommendations to users, rather than traditional online search results that require users to explore options themselves. However, these recommendations are strongly influenced by the initial retrieval order of LLMs, which disadvantages small businesses and independent creators by limiting their visibility.\n  In this work, we propose CORE, an optimization method that \\textbf{C}ontrols \\textbf{O}utput \\textbf{R}ankings in g\\textbf{E}nerative Engines for LLM-based search. Since the LLM's interactions with the search engine are black-box, CORE targets the content returned by search engines as the primary means of influencing output rankings. Specifically, CORE optimizes retrieved content by appending strategically designed optimization content to steer the ranking of outputs. We introduce three types of optimization content: string-based, reasoning-based, and review-based, demonstrating their effectiveness in shaping output rankings. To evaluate CORE in realistic settings, we introduce ProductBench, a large-scale benchmark with 15 product categories and 200 products per category, where each product is associated with its top-10 recommendations collected from Amazon's search interface.\n  Extensive experiments on four LLMs with search capabilities (GPT-4o, Gemini-2.5, Claude-4, and Grok-3) demonstrate that CORE achieves an average Promotion Success Rate of \\textbf{91.4\\% @Top-5}, \\textbf{86.6\\% @Top-3}, and \\textbf{80.3\\% @Top-1}, across 15 product categories, outperforming existing ranking manipulation methods while preserving the fluency of optimized content.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)驱动的生成式引擎(Generative Engines)如何改变产品搜索模式，并指出其检索顺序对小企业可见性的负面影响。为此，作者提出了CORE优化方法，通过在检索内容中附加战略性设计的优化内容（包括string-based、reasoning-based和review-based三种类型）来直接控制输出排名。为了验证该方法，研究团队引入了包含15个类别的大规模基准测试集ProductBench。实验结果显示，在GPT-4o、Gemini-2.5、Claude-4和Grok-3等主流模型上，CORE的Top-5促销成功率(Promotion Success Rate)平均达到91.4%，在Top-1上也达到了80.3%，显著超越了现有的排名操纵技术。该方法不仅在引导输出排名方面表现卓越，同时也很好地保持了优化后内容的语言流畅性，为生成式搜索环境下的排名控制提供了有效方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.03608v1",
      "published_date": "2026-02-03 14:59:48 UTC",
      "updated_date": "2026-02-03 14:59:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:37:38.027871+00:00"
    },
    {
      "arxiv_id": "2602.03604v1",
      "title": "A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures",
      "title_zh": "基于能量的联合嵌入预测架构轻量级库",
      "authors": [
        "Basile Terver",
        "Randall Balestriero",
        "Megi Dervishi",
        "David Fan",
        "Quentin Garrido",
        "Tushar Nagarajan",
        "Koustuv Sinha",
        "Wancong Zhang",
        "Mike Rabbat",
        "Yann LeCun",
        "Amir Bar"
      ],
      "abstract": "We present EB-JEPA, an open-source library for learning representations and world models using Joint-Embedding Predictive Architectures (JEPAs). JEPAs learn to predict in representation space rather than pixel space, avoiding the pitfalls of generative modeling while capturing semantically meaningful features suitable for downstream tasks. Our library provides modular, self-contained implementations that illustrate how representation learning techniques developed for image-level self-supervised learning can transfer to video, where temporal dynamics add complexity, and ultimately to action-conditioned world models, where the model must additionally learn to predict the effects of control inputs. Each example is designed for single-GPU training within a few hours, making energy-based self-supervised learning accessible for research and education. We provide ablations of JEA components on CIFAR-10. Probing these representations yields 91% accuracy, indicating that the model learns useful features. Extending to video, we include a multi-step prediction example on Moving MNIST that demonstrates how the same principles scale to temporal modeling. Finally, we show how these representations can drive action-conditioned world models, achieving a 97% planning success rate on the Two Rooms navigation task. Comprehensive ablations reveal the critical importance of each regularization component for preventing representation collapse. Code is available at https://github.com/facebookresearch/eb_jepa.",
      "tldr_zh": "该研究推出了EB-JEPA，一个专门用于通过Joint-Embedding Predictive Architectures (JEPAs) 学习表示和世界模型的开源轻量级库。与生成模型不同，JEPA在表示空间而非像素空间进行预测，能够有效捕获对下游任务具有语义意义的特征。该库提供了模块化的实现，演示了Self-Supervised Learning技术如何从图像迁移至视频时空建模，并最终应用于能够预测控制输入影响的动作条件世界模型。所有示例均针对单GPU训练进行了优化，可在数小时内完成，极大提升了能量自监督学习在研究与教育中的可访问性。实验结果显示，该模型在CIFAR-10上达到了91%的探测准确率，并在Two Rooms导航任务中实现了97%的规划成功率。通过详尽的消融实验，研究进一步揭示了正则化组件在防止表示崩溃(Representation Collapse)中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03604v1",
      "published_date": "2026-02-03 14:56:24 UTC",
      "updated_date": "2026-02-03 14:56:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:01.431926+00:00"
    },
    {
      "arxiv_id": "2602.03586v1",
      "title": "APEX: Probing Neural Networks via Activation Perturbation",
      "title_zh": "APEX：基于激活扰动的神经网络探测",
      "authors": [
        "Tao Ren",
        "Xiaoyu Luo",
        "Qiongxiu Li"
      ],
      "abstract": "Prior work on probing neural networks primarily relies on input-space analysis or parameter perturbation, both of which face fundamental limitations in accessing structural information encoded in intermediate representations. We introduce Activation Perturbation for EXploration (APEX), an inference-time probing paradigm that perturbs hidden activations while keeping both inputs and model parameters fixed. We theoretically show that activation perturbation induces a principled transition from sample-dependent to model-dependent behavior by suppressing input-specific signals and amplifying representation-level structure, and further establish that input perturbation corresponds to a constrained special case of this framework. Through representative case studies, we demonstrate the practical advantages of APEX. In the small-noise regime, APEX provides a lightweight and efficient measure of sample regularity that aligns with established metrics, while also distinguishing structured from randomly labeled models and revealing semantically coherent prediction transitions. In the large-noise regime, APEX exposes training-induced model-level biases, including a pronounced concentration of predictions on the target class in backdoored models. Overall, our results show that APEX offers an effective perspective for exploring, and understanding neural networks beyond what is accessible from input space alone.",
      "tldr_zh": "该研究提出了 APEX (Activation Perturbation for EXploration)，这是一种在推理阶段通过扰动 hidden activations 来探查神经网络的新范式，有效解决了传统方法在获取中间表示结构信息方面的局限性。APEX 在保持输入和模型参数固定的前提下，理论上证明了其能通过抑制输入特定信号并放大 representation-level structure，实现从 sample-dependent 到 model-dependent 行为的原则性转变。在小噪声 regime 下，APEX 提供了一种高效的样本规律性衡量指标，能够准确区分结构化模型与随机标记模型，并揭示语义一致的预测转换。在大噪声 regime 下，该范式能够暴露训练诱导的模型层面偏差，例如识别 backdoored models 中预测向目标类别的显著集中现象。总体而言，实验结果表明 APEX 为探索和理解神经网络提供了一个超越 input space 的有效视角，展示了其在揭示模型内部编码结构方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03586v1",
      "published_date": "2026-02-03 14:36:36 UTC",
      "updated_date": "2026-02-03 14:36:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:04.618119+00:00"
    },
    {
      "arxiv_id": "2602.03584v1",
      "title": "$V_0$: A Generalist Value Model for Any Policy at State Zero",
      "title_zh": "$V_0$：针对任意策略零状态的通用价值模型",
      "authors": [
        "Yi-Kai Zhang",
        "Zhiyuan Yao",
        "Hongyan Hao",
        "Yueqing Sun",
        "Qi Gu",
        "Hui Su",
        "Xunliang Cai",
        "De-Chuan Zhan",
        "Han-Jia Ye"
      ],
      "abstract": "Policy gradient methods rely on a baseline to measure the relative advantage of an action, ensuring the model reinforces behaviors that outperform its current average capability. In the training of Large Language Models (LLMs) using Actor-Critic methods (e.g., PPO), this baseline is typically estimated by a Value Model (Critic) often as large as the policy model itself. However, as the policy continuously evolves, the value model requires expensive, synchronous incremental training to accurately track the shifting capabilities of the policy. To avoid this overhead, Group Relative Policy Optimization (GRPO) eliminates the coupled value model by using the average reward of a group of rollouts as the baseline; yet, this approach necessitates extensive sampling to maintain estimation stability. In this paper, we propose $V_0$, a Generalist Value Model capable of estimating the expected performance of any model on unseen prompts without requiring parameter updates. We reframe value estimation by treating the policy's dynamic capability as an explicit context input; specifically, we leverage a history of instruction-performance pairs to dynamically profile the model, departing from the traditional paradigm that relies on parameter fitting to perceive capability shifts. Focusing on value estimation at State Zero (i.e., the initial prompt, hence $V_0$), our model serves as a critical resource scheduler. During GRPO training, $V_0$ predicts success rates prior to rollout, allowing for efficient sampling budget allocation; during deployment, it functions as a router, dispatching instructions to the most cost-effective and suitable model. Empirical results demonstrate that $V_0$ significantly outperforms heuristic budget allocation and achieves a Pareto-optimal trade-off between performance and cost in LLM routing tasks.",
      "tldr_zh": "该研究提出了 $V_0$，一种能够在无需参数更新的情况下评估任何策略模型在初始状态表现的通用价值模型（Generalist Value Model）。针对 Actor-Critic 方法（如 PPO）中价值模型训练成本高以及 GRPO 采样效率低的问题，$V_0$ 将模型的动态能力重新定义为显式上下文输入，利用指令-性能对（instruction-performance pairs）的历史数据进行动态建模。该模型专注于零状态（State Zero）的价值估计，在 GRPO 训练中可作为资源调度器预估采样成功率，从而实现高效的采样预算分配。此外，在部署阶段 $V_0$ 还能充当智能路由（router），将任务分发至最合适且最具成本效益的模型。实验结果表明，$V_0$ 在预算分配任务中显著优于启发式方法，并在大语言模型（LLM）路由任务中达到了帕累托最优（Pareto-optimal）的性能与成本权衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03584v1",
      "published_date": "2026-02-03 14:35:23 UTC",
      "updated_date": "2026-02-03 14:35:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:37:57.629457+00:00"
    },
    {
      "arxiv_id": "2602.03580v1",
      "title": "Don't believe everything you read: Understanding and Measuring MCP Behavior under Misleading Tool Descriptions",
      "title_zh": "莫轻信所读：理解与衡量误导性工具描述下的 MCP 行为",
      "authors": [
        "Zhihao Li",
        "Boyang Ma",
        "Xuelong Dai",
        "Minghui Xu",
        "Yue Zhang",
        "Biwei Yan",
        "Kun Li"
      ],
      "abstract": "The Model Context Protocol (MCP) enables large language models to invoke external tools through natural-language descriptions, forming the foundation of many AI agent applications. However, MCP does not enforce consistency between documented tool behavior and actual code execution, even though MCP Servers often run with broad system privileges. This gap introduces a largely unexplored security risk. We study how mismatches between externally presented tool descriptions and underlying implementations systematically shape the mental models and decision-making behavior of intelligent agents. Specifically, we present the first large-scale study of description-code inconsistency in the MCP ecosystem. We design an automated static analysis framework and apply it to 10,240 real-world MCP Servers across 36 categories. Our results show that while most servers are highly consistent, approximately 13% exhibit substantial mismatches that can enable undocumented privileged operations, hidden state mutations, or unauthorized financial actions. We further observe systematic differences across application categories, popularity levels, and MCP marketplaces. Our findings demonstrate that description-code inconsistency is a concrete and prevalent attack surface in MCP-based AI agents, and motivate the need for systematic auditing and stronger transparency guarantees in future agent ecosystems.",
      "tldr_zh": "该研究深入探讨了 Model Context Protocol (MCP) 生态系统中工具描述与底层代码实现之间不一致性所引发的安全隐患，这种不一致性可能导致 AI 智能体在执行任务时产生错误的决策。研究团队开发了一套自动化静态分析框架，并对 36 个类别中的 10,240 个真实 MCP Servers 进行了首次大规模系统性研究。结果显示，虽然多数工具表现一致，但约 13% 的服务器存在显著的不匹配问题，这使得未记录的特权操作、隐藏状态更改以及未经授权的财务行为成为可能。研究还发现这种不一致性在不同应用类别和市场平台间呈现出系统性差异。该工作证实了 description-code inconsistency 已成为基于 MCP 的 AI 智能体中一个具体且普遍的攻击面 (attack surface)。最后，研究强调了在未来智能体生态系统中实施系统化审计和增强透明度保障的迫切需求。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03580v1",
      "published_date": "2026-02-03 14:31:52 UTC",
      "updated_date": "2026-02-03 14:31:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:04.931750+00:00"
    },
    {
      "arxiv_id": "2602.03578v1",
      "title": "Use Graph When It Needs: Efficiently and Adaptively Integrating Retrieval-Augmented Generation with Graphs",
      "title_zh": "按需用图：检索增强生成与图的高效自适应融合",
      "authors": [
        "Su Dong",
        "Qinggang Zhang",
        "Yilin Xiao",
        "Shengyuan Chen",
        "Chuang Zhou",
        "Xiao Huang"
      ],
      "abstract": "Large language models (LLMs) often struggle with knowledge-intensive tasks due to hallucinations and outdated parametric knowledge. While Retrieval-Augmented Generation (RAG) addresses this by integrating external corpora, its effectiveness is limited by fragmented information in unstructured domain documents. Graph-augmented RAG (GraphRAG) emerged to enhance contextual reasoning through structured knowledge graphs, yet paradoxically underperforms vanilla RAG in real-world scenarios, exhibiting significant accuracy drops and prohibitive latency despite gains on complex queries. We identify the rigid application of GraphRAG to all queries, regardless of complexity, as the root cause. To resolve this, we propose an efficient and adaptive GraphRAG framework called EA-GraphRAG that dynamically integrates RAG and GraphRAG paradigms through syntax-aware complexity analysis. Our approach introduces: (i) a syntactic feature constructor that parses each query and extracts a set of structural features; (ii) a lightweight complexity scorer that maps these features to a continuous complexity score; and (iii) a score-driven routing policy that selects dense RAG for low-score queries, invokes graph-based retrieval for high-score queries, and applies complexity-aware reciprocal rank fusion to handle borderline cases. Extensive experiments on a comprehensive benchmark, consisting of two single-hop and two multi-hop QA benchmarks, demonstrate that our EA-GraphRAG significantly improves accuracy, reduces latency, and achieves state-of-the-art performance in handling mixed scenarios involving both simple and complex queries.",
      "tldr_zh": "该研究提出了 EA-GraphRAG，一种旨在高效且自适应地集成检索增强生成 (RAG) 与知识图谱的框架。针对现有 GraphRAG 在处理不同复杂度查询时存在的效率低下和准确率波动问题，EA-GraphRAG 引入了基于语法感知的复杂度分析机制。该方法通过语法特征构造器提取查询结构，并利用轻量级复杂度评分器对任务难度进行评估。其核心的路由策略能够根据评分灵活选择 vanilla RAG 处理简单查询，或调用基于图的检索处理复杂查询，并对边界情况应用复杂度感知的倒数排名融合 (Reciprocal Rank Fusion)。实验结果表明，EA-GraphRAG 在单跳和多跳问答任务中显著提升了准确率并大幅降低了延迟。该框架在处理涵盖简单与复杂任务的混合场景时，达到了当前最先进 (State-of-the-art) 的性能水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03578v1",
      "published_date": "2026-02-03 14:26:28 UTC",
      "updated_date": "2026-02-03 14:26:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:03.117939+00:00"
    },
    {
      "arxiv_id": "2602.03569v1",
      "title": "EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories",
      "title_zh": "EHRWorld：面向长程临床轨迹的以患者为中心的医疗世界模型",
      "authors": [
        "Linjie Mu",
        "Zhongzhen Huang",
        "Yannian Gu",
        "Shengqian Qin",
        "Shaoting Zhang",
        "Xiaofan Zhang"
      ],
      "abstract": "World models offer a principled framework for simulating future states under interventions, but realizing such models in complex, high-stakes domains like medicine remains challenging. Recent large language models (LLMs) have achieved strong performance on static medical reasoning tasks, raising the question of whether they can function as dynamic medical world models capable of simulating disease progression and treatment outcomes over time. In this work, we show that LLMs only incorporating medical knowledge struggle to maintain consistent patient states under sequential interventions, leading to error accumulation in long-horizon clinical simulation. To address this limitation, we introduce EHRWorld, a patient-centric medical world model trained under a causal sequential paradigm, together with EHRWorld-110K, a large-scale longitudinal clinical dataset derived from real-world electronic health records. Extensive evaluations demonstrate that EHRWorld significantly outperforms naive LLM-based baselines, achieving more stable long-horizon simulation, improved modeling of clinically sensitive events, and favorable reasoning efficiency, highlighting the necessity of training on causally grounded, temporally evolving clinical data for reliable and robust medical world modeling.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在动态医学模拟中因难以维持一致患者状态而导致长期临床轨迹预测出现误差积累的问题，提出了 EHRWorld，一种以患者为中心的医学世界模型（Medical World Model）。该模型在因果序列范式（causal sequential paradigm）下进行训练，并配套推出了基于真实电子健康档案（EHR）的大规模纵向临床数据集 EHRWorld-110K。实验结果显示，EHRWorld 在长期模拟稳定性、临床敏感事件建模以及推理效率方面均显著优于纯 LLM 基线模型。该研究成果强调了在因果关联且随时间演变的临床数据上进行训练，对于构建可靠且鲁棒的医学世界模型具有至关重要的意义。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03569v1",
      "published_date": "2026-02-03 14:12:24 UTC",
      "updated_date": "2026-02-03 14:12:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:15.778757+00:00"
    },
    {
      "arxiv_id": "2602.03567v1",
      "title": "EVE: Efficient Verification of Data Erasure through Customized Perturbation in Approximate Unlearning",
      "title_zh": "EVE：在近似遗忘学习中通过定制化扰动实现数据擦除的高效验证",
      "authors": [
        "Weiqi Wang",
        "Zhiyi Tian",
        "Chenhan Zhang",
        "Luoyu Chen",
        "Shui Yu"
      ],
      "abstract": "Verifying whether the machine unlearning process has been properly executed is critical but remains underexplored. Some existing approaches propose unlearning verification methods based on backdooring techniques. However, these methods typically require participation in the model's initial training phase to backdoor the model for later verification, which is inefficient and impractical. In this paper, we propose an efficient verification of erasure method (EVE) for verifying machine unlearning without requiring involvement in the model's initial training process. The core idea is to perturb the unlearning data to ensure the model prediction of the specified samples will change before and after unlearning with perturbed data. The unlearning users can leverage the observation of the changes as a verification signal. Specifically, the perturbations are designed with two key objectives: ensuring the unlearning effect and altering the unlearned model's prediction of target samples. We formalize the perturbation generation as an adversarial optimization problem, solving it by aligning the unlearning gradient with the gradient of boundary change for target samples. We conducted extensive experiments, and the results show that EVE can verify machine unlearning without involving the model's initial training process, unlike backdoor-based methods. Moreover, EVE significantly outperforms state-of-the-art unlearning verification methods, offering significant speedup in efficiency while enhancing verification accuracy. The source code of EVE is released at \\uline{https://anonymous.4open.science/r/EVE-C143}, providing a novel tool for verification of machine unlearning.",
      "tldr_zh": "本研究提出了EVE，一种用于验证机器学习遗忘(Machine Unlearning)效率的方法，解决了现有基于后门的方法必须参与模型初始训练而导致的低效和不切实际问题。EVE的核心思路是对待遗忘数据施加定制化扰动(Customized Perturbation)，使得模型对特定样本的预测在数据擦除前后发生可观测的变化，从而作为用户的验证信号。该研究将扰动生成形式化为对抗优化(Adversarial Optimization)问题，通过对齐遗忘梯度与目标样本的决策边界变化梯度来实现验证目标。大量实验结果证明，EVE在不涉及初始训练的前提下，在验证准确性和运行速度上均显著优于现有的先进(SOTA)方法。该研究为确保近似遗忘(Approximate Unlearning)场景下的数据删除透明度和可验证性提供了一个高效且实用的新工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03567v1",
      "published_date": "2026-02-03 14:09:54 UTC",
      "updated_date": "2026-02-03 14:09:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:49.303050+00:00"
    },
    {
      "arxiv_id": "2602.03560v1",
      "title": "HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing",
      "title_zh": "HySparse：融合 Oracle 令牌选择与 KV 缓存共享的混合稀疏注意力架构",
      "authors": [
        "Yizhao Gao",
        "Jianyu Wei",
        "Qihao Zhang",
        "Yu Cheng",
        "Shimao Chen",
        "Zhengju Tang",
        "Zihan Jiang",
        "Yifan Song",
        "Hailin Zhang",
        "Liang Zhao",
        "Bo Yang",
        "Gang Wang",
        "Shijie Cao",
        "Fuli Luo"
      ],
      "abstract": "This work introduces Hybrid Sparse Attention (HySparse), a new architecture that interleaves each full attention layer with several sparse attention layers. While conceptually simple, HySparse strategically derives each sparse layer's token selection and KV caches directly from the preceding full attention layer. This architecture resolves two fundamental limitations of prior sparse attention methods. First, conventional approaches typically rely on additional proxies to predict token importance, introducing extra complexity and potentially suboptimal performance. In contrast, HySparse uses the full attention layer as a precise oracle to identify important tokens. Second, existing sparse attention designs often reduce computation without saving KV cache. HySparse enables sparse attention layers to reuse the full attention KV cache, thereby reducing both computation and memory. We evaluate HySparse on both 7B dense and 80B MoE models. Across all settings, HySparse consistently outperforms both full attention and hybrid SWA baselines. Notably, in the 80B MoE model with 49 total layers, only 5 layers employ full attention, yet HySparse achieves substantial performance gains while reducing KV cache storage by nearly 10x.",
      "tldr_zh": "该研究提出了 HySparse，这是一种在 full attention layer 之间交替插入多个 sparse attention layers 的混合稀疏注意力架构。HySparse 巧妙地将前一个全注意力层作为 oracle，直接从中提取 token selection 和 KV cache，从而为后续的稀疏层提供精确指导。这种设计解决了传统稀疏注意力方法依赖额外代理模型预测 token importance 所带来的复杂性与性能瓶颈，确保了关键信息的捕捉。同时，HySparse 允许稀疏层复用全层 KV cache，在降低计算量的同时显著减少了内存占用。实验在 7B dense model 和 80B MoE model 上验证了该架构的优越性，其性能始终优于全注意力及混合 SWA 基准。特别是在 80B MoE 模型中，仅需 5 层全注意力即可实现显著性能提升，并将 KV cache 存储需求降低了近 10 倍。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03560v1",
      "published_date": "2026-02-03 14:05:57 UTC",
      "updated_date": "2026-02-03 14:05:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:32.209964+00:00"
    },
    {
      "arxiv_id": "2602.03558v1",
      "title": "ELIQ: A Label-Free Framework for Quality Assessment of Evolving AI-Generated Images",
      "title_zh": "ELIQ：一种用于演进中 AI 生成图像质量评估的无标签框架",
      "authors": [
        "Xinyue Li",
        "Zhiming Xu",
        "Zhichao Zhang",
        "Zhaolin Cai",
        "Sijing Wu",
        "Xiongkuo Min",
        "Yitong Chen",
        "Guangtao Zhai"
      ],
      "abstract": "Generative text-to-image models are advancing at an unprecedented pace, continuously shifting the perceptual quality ceiling and rendering previously collected labels unreliable for newer generations. To address this, we present ELIQ, a Label-free Framework for Quality Assessment of Evolving AI-generated Images. Specifically, ELIQ focuses on visual quality and prompt-image alignment, automatically constructs positive and aspect-specific negative pairs to cover both conventional distortions and AIGC-specific distortion modes, enabling transferable supervision without human annotations. Building on these pairs, ELIQ adapts a pre-trained multimodal model into a quality-aware critic via instruction tuning and predicts two-dimensional quality using lightweight gated fusion and a Quality Query Transformer. Experiments across multiple benchmarks demonstrate that ELIQ consistently outperforms existing label-free methods, generalizes from AI-generated content (AIGC) to user-generated content (UGC) scenarios without modification, and paves the way for scalable and label-free quality assessment under continuously evolving generative models. The code will be released upon publication.",
      "tldr_zh": "该研究针对文本生成图像(text-to-image)模型快速演进导致人工标注数据难以追赶的问题，提出了ELIQ，一个用于评估演进中AI生成图像质量的无需标注(Label-free)框架。ELIQ专注于视觉质量与提示词-图像对齐(prompt-image alignment)，通过自动构建正样本和针对特定维度的负样本对，全面覆盖传统失真及AIGC特有的失真模式，实现了无需人工标注的可迁移监督。该框架利用指令微调(instruction tuning)将预训练多模态模型转化为质量感知评估器，并结合轻量级门控融合与质量查询转换器(Quality Query Transformer)预测二维质量。实验结果表明，ELIQ在多个基准测试中均优于现有的无需标注方法，且在无需修改的情况下即可从AI生成内容(AIGC)推广至用户生成内容(UGC)场景，为持续演进的生成模型提供了可扩展且无需标注的质量评估方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03558v1",
      "published_date": "2026-02-03 14:04:51 UTC",
      "updated_date": "2026-02-03 14:04:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:19.689164+00:00"
    },
    {
      "arxiv_id": "2602.03554v1",
      "title": "When Single Answer Is Not Enough: Rethinking Single-Step Retrosynthesis Benchmarks for LLMs",
      "title_zh": "当单一答案不再足够：重新审视大语言模型的单步逆合成评估基准",
      "authors": [
        "Bogdan Zagribelnyy",
        "Ivan Ilin",
        "Maksim Kuznetsov",
        "Nikita Bondarev",
        "Roman Schutski",
        "Thomas MacDougall",
        "Rim Shayakhmetov",
        "Zulfat Miftakhutdinov",
        "Mikolaj Mizera",
        "Vladimir Aladinskiy",
        "Alex Aliper",
        "Alex Zhavoronkov"
      ],
      "abstract": "Recent progress has expanded the use of large language models (LLMs) in drug discovery, including synthesis planning. However, objective evaluation of retrosynthesis performance remains limited. Existing benchmarks and metrics typically rely on published synthetic procedures and Top-K accuracy based on single ground-truth, which does not capture the open-ended nature of real-world synthesis planning. We propose a new benchmarking framework for single-step retrosynthesis that evaluates both general-purpose and chemistry-specialized LLMs using ChemCensor, a novel metric for chemical plausibility. By emphasizing plausibility over exact match, this approach better aligns with human synthesis planning practices. We also introduce CREED, a novel dataset comprising millions of ChemCensor-validated reaction records for LLM training, and use it to train a model that improves over the LLM baselines under this benchmark.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在药物研发和合成规划中的应用，指出当前基于单一标准答案和Top-K准确率的逆合成评估基准难以捕捉现实世界合成规划的开放性。为此，研究者提出了一个新的单步逆合成评估框架，并引入了名为ChemCensor的新型化学合理性度量指标，旨在评估通用型和化学专用型LLMs。该方法强调化学合理性(plausibility)而非精确匹配(exact match)，使其评估标准更符合人类合成规划的实际。此外，论文还介绍了包含数百万条经过ChemCensor验证反应记录的CREED数据集，用于提升LLM的性能。实验结果表明，在该基准下，利用CREED训练的模型显著优于现有的LLM基线模型，为更客观地评价逆合成技术提供了新方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03554v1",
      "published_date": "2026-02-03 14:03:32 UTC",
      "updated_date": "2026-02-03 14:03:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:38:21.196841+00:00"
    },
    {
      "arxiv_id": "2602.03545v1",
      "title": "Persona Generators: Generating Diverse Synthetic Personas at Scale",
      "title_zh": "Persona Generators：大规模生成多样化合成画像",
      "authors": [
        "Davide Paglieri",
        "Logan Cross",
        "William A. Cunningham",
        "Joel Z. Leibo",
        "Alexander Sasha Vezhnevets"
      ],
      "abstract": "Evaluating AI systems that interact with humans requires understanding their behavior across diverse user populations, but collecting representative human data is often expensive or infeasible, particularly for novel technologies or hypothetical future scenarios. Recent work in Generative Agent-Based Modeling has shown that large language models can simulate human-like synthetic personas with high fidelity, accurately reproducing the beliefs and behaviors of specific individuals. However, most approaches require detailed data about target populations and often prioritize density matching (replicating what is most probable) rather than support coverage (spanning what is possible), leaving long-tail behaviors underexplored. We introduce Persona Generators, functions that can produce diverse synthetic populations tailored to arbitrary contexts. We apply an iterative improvement loop based on AlphaEvolve, using large language models as mutation operators to refine our Persona Generator code over hundreds of iterations. The optimization process produces lightweight Persona Generators that can automatically expand small descriptions into populations of diverse synthetic personas that maximize coverage of opinions and preferences along relevant diversity axes. We demonstrate that evolved generators substantially outperform existing baselines across six diversity metrics on held-out contexts, producing populations that span rare trait combinations difficult to achieve in standard LLM outputs.",
      "tldr_zh": "该研究针对AI系统评估中真实人类数据收集困难，以及现有生成式代理建模(Generative Agent-Based Modeling)在覆盖长尾行为和多样性方面存在局限的问题展开研究。作者提出了Persona Generators，这是一种能够针对任意上下文生成大规模、多样化合成人格(Synthetic Personas)的函数。该方法采用基于AlphaEvolve的迭代改进循环，利用大语言模型(LLMs)作为变异算子，通过数百次迭代不断优化生成器代码。这种优化过程产生了一种轻量级的Persona Generators，能够自动将简短描述扩展为在相关多样性维度上最大化意见和偏好覆盖范围的合成群体。实验结果显示，进化后的生成器在六项多样性指标上显著优于现有基准模型。该研究成功生成了包含罕见特征组合的群体，有效解决了标准LLM输出在支持覆盖(Support Coverage)方面的不足，为大规模探索长尾行为提供了有力工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03545v1",
      "published_date": "2026-02-03 13:59:03 UTC",
      "updated_date": "2026-02-03 13:59:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:39:12.325738+00:00"
    },
    {
      "arxiv_id": "2602.03541v1",
      "title": "Group Selection as a Safeguard Against AI Substitution",
      "title_zh": "群体选择：抵御人工智能替代的保障机制",
      "authors": [
        "Qiankun Zhong",
        "Thomas F. Eisenmann",
        "Julian Garcia",
        "Iyad Rahwan"
      ],
      "abstract": "Reliance on generative AI can reduce cultural variance and diversity, especially in creative work. This reduction in variance has already led to problems in model performance, including model collapse and hallucination. In this paper, we examine the long-term consequences of AI use for human cultural evolution and the conditions under which widespread AI use may lead to \"cultural collapse\", a process in which reliance on AI-generated content reduces human variation and innovation and slows cumulative cultural evolution. Using an agent-based model and evolutionary game theory, we compare two types of AI use: complement and substitute. AI-complement users seek suggestions and guidance while remaining the main producers of the final output, whereas AI-substitute users provide minimal input, and rely on AI to produce most of the output. We then study how these use strategies compete and spread under evolutionary dynamics. We find that AI-substitute users prevail under individual-level selection despite the stronger reduction in cultural variance. By contrast, AI-complement users can benefit their groups by maintaining the variance needed for exploration, and can therefore be favored under cultural group selection when group boundaries are strong. Overall, our findings shed light on the long-term, population-level effects of AI adoption and inform policy and organizational strategies to mitigate these risks.",
      "tldr_zh": "该研究探讨了生成式人工智能对人类文化演化的长期影响，特别是过度依赖 AI 可能引发的 \"cultural collapse\" 风险，即创新减少和文化累积演化减速。研究团队利用 Agent-based model 和 Evolutionary Game Theory，对比分析了将 AI 作为辅助引导的 AI-complement 模式与完全依赖 AI 产出的 AI-substitute 模式。研究发现在 Individual-level selection 机制下，尽管 AI-substitute 会严重削减文化多样性，但此类用户往往在竞争中占据主导地位。相比之下，AI-complement 用户能够维持创新探索所需的文化差异性（variance），从而使所在群体整体受益。模拟结果显示，当群体边界较强时，Cultural Group Selection 能够有效支持 AI-complement 策略的传播，使其成为抵御 AI 替代风险的一种保障机制。该研究揭示了 AI 采纳在人口层面的长期效应，并为制定缓解文化多样性流失风险的组织与政策策略提供了理论依据。",
      "categories": [
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 7 Figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03541v1",
      "published_date": "2026-02-03 13:56:47 UTC",
      "updated_date": "2026-02-03 13:56:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:39:11.003799+00:00"
    },
    {
      "arxiv_id": "2602.03529v1",
      "title": "Morphe: High-Fidelity Generative Video Streaming with Vision Foundation Model",
      "title_zh": "Morphe：基于视觉基础模型的高保真生成式视频流",
      "authors": [
        "Tianyi Gong",
        "Zijian Cao",
        "Zixing Zhang",
        "Jiangkai Wu",
        "Xinggong Zhang",
        "Shuguang Cui",
        "Fangxin Wang"
      ],
      "abstract": "Video streaming is a fundamental Internet service, while the quality still cannot be guaranteed especially in poor network conditions such as bandwidth-constrained and remote areas. Existing works mainly work towards two directions: traditional pixel-codec streaming nearly approaches its limit and is hard to step further in compression; the emerging neural-enhanced or generative streaming usually fall short in latency and visual fidelity, hindering their practical deployment. Inspired by the recent success of vision foundation model (VFM), we strive to harness the powerful video understanding and processing capacities of VFM to achieve generalization, high fidelity and loss resilience for real-time video streaming with even higher compression rate. We present the first revolutionized paradigm that enables VFM-based end-to-end generative video streaming towards this goal. Specifically, Morphe employs joint training of visual tokenizers and variable-resolution spatiotemporal optimization under simulated network constraints. Additionally, a robust streaming system is constructed that leverages intelligent packet dropping to resist real-world network perturbations. Extensive evaluation demonstrates that Morphe achieves comparable visual quality while saving 62.5\\% bandwidth compared to H.265, and accomplishes real-time, loss-resilient video delivery in challenging network environments, representing a milestone in VFM-enabled multimedia streaming solutions.",
      "tldr_zh": "该研究针对网络带宽受限环境下视频流质量难以保障的问题，提出了 Morphe，这是首个基于视觉基础模型 (Vision Foundation Model, VFM) 的端到端生成式视频流传输范式。为了克服传统像素编解码器 (pixel-codec) 的压缩极限以及现有神经增强方案在延迟和保真度上的缺陷，Morphe 利用 VFM 强大的视频理解能力来实现高保真和抗丢包的实时传输。在技术实现上，该框架采用了视觉分词器 (visual tokenizers) 的联合训练，并针对模拟网络约束进行了变分辨率时空优化 (variable-resolution spatiotemporal optimization)。此外，系统通过引入智能丢包 (intelligent packet dropping) 机制，显著提升了在现实网络波动中的鲁棒性。评估结果表明，Morphe 在维持同等视觉质量的前提下，比 H.265 标准节省了 62.5% 的带宽。该成果在极端网络条件下实现了实时、稳健的视频交付，是利用 VFM 赋能多媒体流媒体技术的重要里程碑。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted by NSDI 2026 Fall",
      "pdf_url": "https://arxiv.org/pdf/2602.03529v1",
      "published_date": "2026-02-03 13:47:18 UTC",
      "updated_date": "2026-02-03 13:47:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:39:49.107909+00:00"
    },
    {
      "arxiv_id": "2602.03523v1",
      "title": "D3PIA: A Discrete Denoising Diffusion Model for Piano Accompaniment Generation From Lead sheet",
      "title_zh": "D3PIA：基于主旋律谱的钢琴伴奏生成离散去噪扩散模型",
      "authors": [
        "Eunjin Choi",
        "Hounsu Kim",
        "Hayeon Bang",
        "Taegyun Kwon",
        "Juhan Nam"
      ],
      "abstract": "Generating piano accompaniments in the symbolic music domain is a challenging task that requires producing a complete piece of piano music from given melody and chord constraints, such as those provided by a lead sheet. In this paper, we propose a discrete diffusion-based piano accompaniment generation model, D3PIA, leveraging local alignment between lead sheet and accompaniment in piano-roll representation. D3PIA incorporates Neighborhood Attention (NA) to both encode the lead sheet and condition it for predicting note states in the piano accompaniment. This design enhances local contextual modeling by efficiently attending to nearby melody and chord conditions. We evaluate our model using the POP909 dataset, a widely used benchmark for piano accompaniment generation. Objective evaluation results demonstrate that D3PIA preserves chord conditions more faithfully compared to continuous diffusion-based and Transformer-based baselines. Furthermore, a subjective listening test indicates that D3PIA generates more musically coherent accompaniments than the comparison models.",
      "tldr_zh": "该研究提出了D3PIA，一种基于离散扩散模型(Discrete Denoising Diffusion Model)的钢琴伴奏生成框架，旨在通过Lead sheet提供的旋律与和弦约束生成高质量的符号音乐。该模型在Piano-roll表示法中利用了Lead sheet与伴奏之间的局部对齐特性，并引入邻域注意力机制(Neighborhood Attention, NA)进行编码与条件调节。这种设计通过高效捕捉邻近的旋律与和弦信息，显著增强了局部上下文的建模能力。在POP909数据集上的客观评估表明，D3PIA在保留和弦约束方面比连续扩散模型和Transformer基准模型更具优势。此外，主观听力测试证明该模型生成的伴奏具有更强的音乐连贯性，为符号音乐生成的局部建模提供了有效的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
      "pdf_url": "https://arxiv.org/pdf/2602.03523v1",
      "published_date": "2026-02-03 13:39:33 UTC",
      "updated_date": "2026-02-03 13:39:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:40:14.793566+00:00"
    },
    {
      "arxiv_id": "2602.03520v1",
      "title": "Live or Lie: Action-Aware Capsule Multiple Instance Learning for Risk Assessment in Live Streaming Platforms",
      "title_zh": "Live or Lie：面向直播平台风险评估的动作感知胶囊多示例学习",
      "authors": [
        "Yiran Qiao",
        "Jing Chen",
        "Xiang Ao",
        "Qiwei Zhong",
        "Yang Liu",
        "Qing He"
      ],
      "abstract": "Live streaming has become a cornerstone of today's internet, enabling massive real-time social interactions. However, it faces severe risks arising from sparse, coordinated malicious behaviors among multiple participants, which are often concealed within normal activities and challenging to detect timely and accurately. In this work, we provide a pioneering study on risk assessment in live streaming rooms, characterized by weak supervision where only room-level labels are available. We formulate the task as a Multiple Instance Learning (MIL) problem, treating each room as a bag and defining structured user-timeslot capsules as instances. These capsules represent subsequences of user actions within specific time windows, encapsulating localized behavioral patterns. Based on this formulation, we propose AC-MIL, an Action-aware Capsule MIL framework that models both individual behaviors and group-level coordination patterns. AC-MIL captures multi-granular semantics and behavioral cues through a serial and parallel architecture that jointly encodes temporal dynamics and cross-user dependencies. These signals are integrated for robust room-level risk prediction, while also offering interpretable evidence at the behavior segment level. Extensive experiments on large-scale industrial datasets from Douyin demonstrate that AC-MIL significantly outperforms MIL and sequential baselines, establishing new state-of-the-art performance in room-level risk assessment for live streaming. Moreover, AC-MIL provides capsule-level interpretability, enabling identification of risky behavior segments as actionable evidence for intervention. The project page is available at: https://qiaoyran.github.io/AC-MIL/.",
      "tldr_zh": "该研究针对直播平台中恶意行为稀疏且隐蔽、仅有房间级标签(room-level labels)的弱监督风险评估难题，提出了名为AC-MIL的Action-aware Capsule Multiple Instance Learning框架。该框架将每个直播间视为一个包(bag)，并定义结构化的用户-时间槽胶囊(user-timeslot capsules)作为实例，以表征特定时间窗口内的行为序列。AC-MIL采用串并行架构(serial and parallel architecture)同时对时间动态(temporal dynamics)和跨用户依赖关系(cross-user dependencies)进行编码，从而有效捕捉个体行为与群体协调模式。在抖音(Douyin)大规模工业数据集上的实验证明，AC-MIL在房间级风险评估上显著优于现有的MIL和序列模型基线。此外，该方法还提供了胶囊级别的可解释性(interpretability)，能够精准识别风险行为片段并为平台的干预措施提供可操作的证据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03520v1",
      "published_date": "2026-02-03 13:36:59 UTC",
      "updated_date": "2026-02-03 13:36:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:40:15.616519+00:00"
    },
    {
      "arxiv_id": "2602.03516v1",
      "title": "Not All Negative Samples Are Equal: LLMs Learn Better from Plausible Reasoning",
      "title_zh": "并非所有负样本都同等重要：大语言模型能从合情合理的推理中更有效地学习",
      "authors": [
        "Zixiang Di",
        "Jinyi Han",
        "Shuo Zhang",
        "Ying Liao",
        "Zhi Li",
        "Xiaofeng Ji",
        "Yongqi Wang",
        "Zheming Yang",
        "Ming Gao",
        "Bingdong Li",
        "Jie Wang"
      ],
      "abstract": "Learning from negative samples holds great promise for improving Large Language Model (LLM) reasoning capability, yet existing methods treat all incorrect responses as equally informative, overlooking the crucial role of sample quality. To address this, we propose Plausible Negative Samples (PNS), a method that synthesizes high-quality negative samples exhibiting expected format and structural coherence while ultimately yielding incorrect answers. PNS trains a dedicated model via reverse reinforcement learning (RL) guided by a composite reward combining format compliance, accuracy inversion, reward model assessment, and chain-of-thought evaluation, generating responses nearly indistinguishable from correct solutions. We further validate PNS as a plug-and-play data source for preference optimization across three backbone models on seven mathematical reasoning benchmarks. Results demonstrate that PNS consistently outperforms other negative sample synthesis methods, achieving an average improvement of 2.03% over RL-trained models.",
      "tldr_zh": "该研究针对大语言模型(LLMs)推理能力提升中现有方法忽略负样本质量的问题，提出了Plausible Negative Samples (PNS)方法。PNS旨在合成具有预期格式和结构一致性但最终结果错误的高质量负样本，从而更有效地引导模型学习。该方法通过逆向强化学习(Reverse Reinforcement Learning)训练专用模型，并结合格式合规性、准确性反转、奖励模型评估和链式思维(Chain-of-Thought)评估的复合奖励，生成与正确答案在结构上几乎难以区分的响应。研究人员在三个骨干模型和七个数学推理基准测试上将PNS作为偏好优化(Preference Optimization)的即插即用数据源。实验结果表明，PNS一致优于现有的负样本合成方法，在强化学习训练模型的基础上平均提升了2.03%的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03516v1",
      "published_date": "2026-02-03 13:32:02 UTC",
      "updated_date": "2026-02-03 13:32:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:40:07.688608+00:00"
    },
    {
      "arxiv_id": "2602.03515v1",
      "title": "Mitigating Staleness in Asynchronous Pipeline Parallelism via Basis Rotation",
      "title_zh": "通过基旋转缓解异步流水线并行的陈旧性",
      "authors": [
        "Hyunji Jung",
        "Sungbin Shin",
        "Namhoon Lee"
      ],
      "abstract": "Asynchronous pipeline parallelism maximizes hardware utilization by eliminating the pipeline bubbles inherent in synchronous execution, offering a path toward efficient large-scale distributed training. However, this efficiency gain can be compromised by gradient staleness, where the immediate model updates with delayed gradients introduce noise into the optimization process. Crucially, we identify a critical, yet often overlooked, pathology: this delay scales linearly with pipeline depth, fundamentally undermining the very scalability that the method originally intends to provide. In this work, we investigate this inconsistency and bridge the gap by rectifying delayed gradients through basis rotation, restoring scalable asynchronous training while maintaining performance. Specifically, we observe that the deleterious effects of delayed gradients are exacerbated when the Hessian eigenbasis is misaligned with the standard coordinate basis. We demonstrate that this misalignment prevents coordinate-wise adaptive schemes, such as Adam, from effectively leveraging curvature-aware adaptivity. This failure leads to significant oscillations in the optimization trajectory and, consequently, slower convergence. We substantiate these findings through both rigorous theoretical analysis and empirical evaluation. To address this challenge, we propose the use of basis rotation, demonstrating that it effectively mitigates the alignment issue and significantly accelerates convergence in asynchronous settings. For example, our training of a 1B-parameter LLM with basis rotation achieves the same training loss in 76.8% fewer iterations compared to the best-performing asynchronous pipeline parallel training baseline.",
      "tldr_zh": "该研究针对异步流水线并行（Asynchronous pipeline parallelism）中的梯度过期（Gradient staleness）问题，提出了一种基于基旋转（Basis rotation）的优化方案。作者指出，梯度延迟随流水线深度线性增长，且Hessian特征基（Hessian eigenbasis）与标准坐标基（Standard coordinate basis）的失配会导致Adam等自适应优化器难以有效利用曲率信息，从而引发训练轨迹震荡并减缓收敛。通过引入基旋转（Basis rotation）技术，该方法能够纠正延迟梯度并增强优化过程的稳定性。理论分析与实验评估均证实，该技术能显著加速异步环境下的模型收敛。在10亿参数规模的LLM训练实验中，采用基旋转（Basis rotation）的方法仅需减少76.8%的迭代次数即可达到与最佳异步基准模型相同的训练损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under review",
      "pdf_url": "https://arxiv.org/pdf/2602.03515v1",
      "published_date": "2026-02-03 13:31:51 UTC",
      "updated_date": "2026-02-03 13:31:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:39:55.899143+00:00"
    },
    {
      "arxiv_id": "2602.03511v1",
      "title": "CMR: Contractive Mapping Embeddings for Robust Humanoid Locomotion on Unstructured Terrains",
      "title_zh": "CMR：面向非结构化地形下鲁棒类人运动的收缩映射嵌入",
      "authors": [
        "Qixin Zeng",
        "Hongyin Zhang",
        "Shangke Lyu",
        "Junxi Jin",
        "Donglin Wang",
        "Chao Huang"
      ],
      "abstract": "Robust disturbance rejection remains a longstanding challenge in humanoid locomotion, particularly on unstructured terrains where sensing is unreliable and model mismatch is pronounced. While perception information, such as height map, enhances terrain awareness, sensor noise and sim-to-real gaps can destabilize policies in practice. In this work, we provide theoretical analysis that bounds the return gap under observation noise, when the induced latent dynamics are contractive. Furthermore, we present Contractive Mapping for Robustness (CMR) framework that maps high-dimensional, disturbance-prone observations into a latent space, where local perturbations are attenuated over time. Specifically, this approach couples contrastive representation learning with Lipschitz regularization to preserve task-relevant geometry while explicitly controlling sensitivity. Notably, the formulation can be incorporated into modern deep reinforcement learning pipelines as an auxiliary loss term with minimal additional technical effort required. Further, our extensive humanoid experiments show that CMR potently outperforms other locomotion algorithms under increased noise.",
      "tldr_zh": "该研究针对人形机器人在非结构化地形(unstructured terrains)中因传感器噪声和模型失配导致的扰动抑制挑战，提出了CMR（Contractive Mapping for Robustness）框架。作者通过理论分析证明了当诱导潜在动力学(induced latent dynamics)具有收缩性时，能够有效限制观测噪声下的回报差距。CMR框架将高维、易受干扰的观测映射到一个潜在空间中，通过结合对比表示学习(contrastive representation learning)和Lipschitz正则化，使局部微扰随时间减弱，并在保留任务相关几何信息的同时显式控制系统的灵敏度。该方法可以作为辅助损失项(auxiliary loss term)轻松集成到现有的深度强化学习(deep reinforcement learning)流水线中。多项人形机器人实验表明，在噪声增加的环境下，CMR的运动表现显著优于其他对比算法，为实现鲁棒的人形机器人足式运动提供了有效方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03511v1",
      "published_date": "2026-02-03 13:30:18 UTC",
      "updated_date": "2026-02-03 13:30:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:41:04.495872+00:00"
    },
    {
      "arxiv_id": "2602.03506v1",
      "title": "Explaining the Explainer: Understanding the Inner Workings of Transformer-based Symbolic Regression Models",
      "title_zh": "解释“解释器”：深入理解基于 Transformer 的符号回归模型的内在机理",
      "authors": [
        "Arco van Breda",
        "Erman Acar"
      ],
      "abstract": "Following their success across many domains, transformers have also proven effective for symbolic regression (SR); however, the internal mechanisms underlying their generation of mathematical operators remain largely unexplored. Although mechanistic interpretability has successfully identified circuits in language and vision models, it has not yet been applied to SR. In this article, we introduce PATCHES, an evolutionary circuit discovery algorithm that identifies compact and correct circuits for SR. Using PATCHES, we isolate 28 circuits, providing the first circuit-level characterisation of an SR transformer. We validate these findings through a robust causal evaluation framework based on key notions such as faithfulness, completeness, and minimality. Our analysis shows that mean patching with performance-based evaluation most reliably isolates functionally correct circuits. In contrast, we demonstrate that direct logit attribution and probing classifiers primarily capture correlational features rather than causal ones, limiting their utility for circuit discovery. Overall, these results establish SR as a high-potential application domain for mechanistic interpretability and propose a principled methodology for circuit discovery.",
      "tldr_zh": "该研究探讨了基于Transformer的符号回归(Symbolic Regression)模型的内部机制，通过引入一种名为PATCHES的演化电路发现算法，首次实现了对符号回归Transformer的电路级特征描述。研究团队利用PATCHES成功识别并隔离了28个功能正确且紧凑的电路，并采用基于忠实度(faithfulness)、完整性(completeness)和最小性(minimality)的因果评估框架进行了系统验证。分析结果表明，结合性能导向评估的均值修补(mean patching)在分离功能性电路上最为可靠，而传统的直接逻辑归因(logit attribution)和探测分类器(probing classifiers)更多捕捉到的是相关性而非因果特征。该项工作证明了符号回归是机械可解释性(mechanistic interpretability)研究中极具潜力的应用领域，并为电路发现提供了一套规范的方法论。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03506v1",
      "published_date": "2026-02-03 13:27:10 UTC",
      "updated_date": "2026-02-03 13:27:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:40:07.000634+00:00"
    },
    {
      "arxiv_id": "2602.03505v1",
      "title": "Generative Decompression: Optimal Lossy Decoding Against Distribution Mismatch",
      "title_zh": "生成式解压缩：应对分布失配的最优有损解码",
      "authors": [
        "Saeed R. Khosravirad",
        "Ahmed Alkhateeb",
        "Ingrid van de Voorde"
      ],
      "abstract": "This paper addresses optimal decoding strategies in lossy compression where the assumed distribution for compressor design mismatches the actual (true) distribution of the source. This problem has immediate relevance in standardized communication systems where the decoder acquires side information or priors about the true distribution that are unavailable to the fixed encoder. We formally define the mismatched quantization problem, demonstrating that the optimal reconstruction rule, termed generative decompression, aligns with classical Bayesian estimation by taking the conditional expectation under the true distribution given the quantization indices and adapting it to fixed-encoder constraints. This strategy effectively performs a generative Bayesian correction on the decoder side, strictly outperforming the conventional centroid rule. We extend this framework to transmission over noisy channels, deriving a robust soft-decoding rule that quantifies the inefficiency of standard modular source--channel separation architectures under mismatch. Furthermore, we generalize the approach to task-oriented decoding, showing that the optimal strategy shifts from conditional mean estimation to maximum a posteriori (MAP) detection. Experimental results on Gaussian sources and deep-learning-based semantic classification demonstrate that generative decompression closes a vast majority of the performance gap to the ideal joint-optimization benchmark, enabling adaptive, high-fidelity reconstruction without modifying the encoder.",
      "tldr_zh": "该研究探讨了有损压缩(lossy compression)中编码器设计分布与源数据真实分布不匹配时的最优解码策略，这在标准化通信系统中具有重要应用价值。论文正式定义了不匹配量化问题(mismatched quantization problem)，并提出了一种名为生成式解压缩(generative decompression)的最优重建规则。该方法通过在已知量化索引的情况下利用真实分布下的条件期望(conditional expectation)进行生成式贝叶斯校正，其性能显著优于传统的质心规则(centroid rule)。研究进一步将该框架扩展到有噪声信道传输，推导出了鲁棒的软解码规则，并揭示了标准模块化信源信道分离架构在分布不匹配时的低效性。此外，该方法还被推广至面向任务的解码，将最优策略从条件均值估计转变为最大后验概率(MAP)检测。实验结果表明，generative decompression 在高斯源和基于深度学习的语义分类任务中，弥补了与理想联合优化基准之间的大部分性能差距，在不修改编码器的情况下实现了自适应的高保真重建。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03505v1",
      "published_date": "2026-02-03 13:25:23 UTC",
      "updated_date": "2026-02-03 13:25:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:40:33.183538+00:00"
    },
    {
      "arxiv_id": "2602.03501v1",
      "title": "Reparameterization Flow Policy Optimization",
      "title_zh": "重参数化流策略优化",
      "authors": [
        "Hai Zhong",
        "Zhuoran Li",
        "Xun Wang",
        "Longbo Huang"
      ],
      "abstract": "Reparameterization Policy Gradient (RPG) has emerged as a powerful paradigm for model-based reinforcement learning, enabling high sample efficiency by backpropagating gradients through differentiable dynamics. However, prior RPG approaches have been predominantly restricted to Gaussian policies, limiting their performance and failing to leverage recent advances in generative models. In this work, we identify that flow policies, which generate actions via differentiable ODE integration, naturally align with the RPG framework, a connection not established in prior work. However, naively exploiting this synergy proves ineffective, often suffering from training instability and a lack of exploration. We propose Reparameterization Flow Policy Optimization (RFO). RFO computes policy gradients by backpropagating jointly through the flow generation process and system dynamics, unlocking high sample efficiency without requiring intractable log-likelihood calculations. RFO includes two tailored regularization terms for stability and exploration. We also propose a variant of RFO with action chunking. Extensive experiments on diverse locomotion and manipulation tasks, involving both rigid and soft bodies with state or visual inputs, demonstrate the effectiveness of RFO. Notably, on a challenging locomotion task controlling a soft-body quadruped, RFO achieves almost $2\\times$ the reward of the state-of-the-art baseline.",
      "tldr_zh": "该研究针对基于模型的强化学习 (Model-based Reinforcement Learning) 中重参数化策略梯度 (Reparameterization Policy Gradient, RPG) 长期受限于高斯策略 (Gaussian policies) 的问题，提出了重参数化流策略优化 (Reparameterization Flow Policy Optimization, RFO)。研究者发现通过可微 ODE 积分生成动作的流策略 (flow policies) 与 RPG 框架高度契合，RFO 通过在流生成过程和系统动力学中共同进行梯度反向传播，在无需计算复杂的对数似然 (log-likelihood) 的情况下实现了极高的样本效率。针对训练不稳定和探索不足的挑战，RFO 引入了两项定制的正则化项，并提供了支持动作块 (action chunking) 的变体。在涉及刚体与软体、状态或视觉输入的多种运动和操纵任务中，RFO 均表现出优异性能。实验结果表明，在极具挑战性的软体四足机器人运动任务中，RFO 获得的奖励达到现有最先进基线方法的近两倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03501v1",
      "published_date": "2026-02-03 13:22:08 UTC",
      "updated_date": "2026-02-03 13:22:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:41:23.565920+00:00"
    },
    {
      "arxiv_id": "2602.03486v1",
      "title": "DeepDFA: Injecting Temporal Logic in Deep Learning for Sequential Subsymbolic Applications",
      "title_zh": "DeepDFA：面向序列亚符号应用的深度学习时序逻辑注入",
      "authors": [
        "Elena Umili",
        "Francesco Argenziano",
        "Roberto Capobianco"
      ],
      "abstract": "Integrating logical knowledge into deep neural network training is still a hard challenge, especially for sequential or temporally extended domains involving subsymbolic observations. To address this problem, we propose DeepDFA, a neurosymbolic framework that integrates high-level temporal logic - expressed as Deterministic Finite Automata (DFA) or Moore Machines - into neural architectures. DeepDFA models temporal rules as continuous, differentiable layers, enabling symbolic knowledge injection into subsymbolic domains. We demonstrate how DeepDFA can be used in two key settings: (i) static image sequence classification, and (ii) policy learning in interactive non-Markovian environments. Across extensive experiments, DeepDFA outperforms traditional deep learning models (e.g., LSTMs, GRUs, Transformers) and novel neuro-symbolic systems, achieving state-of-the-art results in temporal knowledge integration. These results highlight the potential of DeepDFA to bridge subsymbolic learning and symbolic reasoning in sequential tasks.",
      "tldr_zh": "该研究提出了 DeepDFA，一种旨在将高级时序逻辑集成到深度学习架构中的神经符号(neurosymbolic)框架，解决了在涉及亚符号(subsymbolic)观测的时序领域中整合逻辑知识的难题。DeepDFA 通过将以 Deterministic Finite Automata (DFA) 或 Moore Machines 表达的时序逻辑建模为连续、可微的层，实现了符号知识向亚符号领域的有效注入。该框架在静态图像序列分类和交互式非马尔可夫(non-Markovian)环境下的策略学习两项任务中均表现出色。实验结果显示，DeepDFA 在时序知识整合方面达到了 state-of-the-art 水平，性能显著优于 LSTMs、GRUs、Transformers 等传统深度学习模型。这项研究证明了 DeepDFA 在连接序列任务中的亚符号学习与符号推理方面的潜力，为构建具备时序逻辑推理能力的神经网络提供了有效路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03486v1",
      "published_date": "2026-02-03 12:59:47 UTC",
      "updated_date": "2026-02-03 12:59:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:41:42.322252+00:00"
    },
    {
      "arxiv_id": "2602.03485v1",
      "title": "Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning",
      "title_zh": "自我验证困境：大语言模型推理中过度校验的经验驱动抑制",
      "authors": [
        "Quanyu Long",
        "Kai Jie Jiang",
        "Jianda Chen",
        "Xu Guo",
        "Leilei Gan",
        "Wenya Wang"
      ],
      "abstract": "Large Reasoning Models (LRMs) achieve strong performance by generating long reasoning traces with reflection. Through a large-scale empirical analysis, we find that a substantial fraction of reflective steps consist of self-verification (recheck) that repeatedly confirm intermediate results. These rechecks occur frequently across models and benchmarks, yet the vast majority are confirmatory rather than corrective, rarely identifying errors and altering reasoning outcomes. This reveals a mismatch between how often self-verification is activated and how often it is actually useful. Motivated by this, we propose a novel, experience-driven test-time framework that reduces the overused verification. Our method detects the activation of recheck behavior, consults an offline experience pool of past verification outcomes, and estimates whether a recheck is likely unnecessary via efficient retrieval. When historical experience suggests unnecessary, a suppression signal redirects the model to proceed. Across multiple model and benchmarks, our approach reduces token usage up to 20.3% while maintaining the accuracy, and in some datasets even yields accuracy improvements.",
      "tldr_zh": "该研究探讨了大语言模型(Large Reasoning Models)推理中的“自我验证困境”(Self-Verification Dilemma)，指出模型在推理链中频繁进行的自我验证(recheck)步骤往往处于过度使用的状态。通过实证分析发现，这些验证行为大多仅起到确认作用而非纠正错误，其触发频率与实际效用严重失配。为此，作者提出了一种经验驱动的测试时框架(test-time framework)，通过检测验证行为的触发并检索离线经验池(experience pool)来识别不必要的验证。当系统判定验证冗余时，会发出抑制信号(suppression signal)引导模型直接跳过验证并继续推理。实验结果显示，该方法在保持甚至提升推理准确率的同时，成功将Token使用量降低了高达20.3%，有效优化了长链推理的计算效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03485v1",
      "published_date": "2026-02-03 12:58:23 UTC",
      "updated_date": "2026-02-03 12:58:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:41:29.934430+00:00"
    },
    {
      "arxiv_id": "2602.03478v1",
      "title": "When Routing Collapses: On the Degenerate Convergence of LLM Routers",
      "title_zh": "路由崩溃：论大语言模型路由器的退化收敛",
      "authors": [
        "Guannan Lai",
        "Han-Jia Ye"
      ],
      "abstract": "LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user's cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.",
      "tldr_zh": "该研究揭示了大型语言模型（LLM）路由（routing）中普遍存在的一种失效模式，即“路由坍缩（routing collapse）”，表现为随着用户预算增加，路由系统会盲目选择最昂贵模型而忽略已能胜任的小模型，导致计算资源浪费。研究认为这种坍缩源于目标与决策的不匹配（objective-decision mismatch），即现有系统倾向于预测标量性能分数而非进行离散比较，微小的预测误差即可引发次优决策。为此，作者提出了 EquiRouter，这是一种决策感知（decision-aware）的路由模型，通过直接学习模型排名（model rankings）来恢复小模型的作用并缓解路由坍缩。在 RouterBench 基准测试中，EquiRouter 在保持 GPT-4 级别性能的前提下，比最强的现有路由系统降低了约 17% 的成本。该工作通过优化决策机制，为实现更高效率的跨模型推理与资源调度提供了新的路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03478v1",
      "published_date": "2026-02-03 12:51:55 UTC",
      "updated_date": "2026-02-03 12:51:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:41:34.728627+00:00"
    },
    {
      "arxiv_id": "2602.03477v1",
      "title": "ScDiVa: Masked Discrete Diffusion for Joint Modeling of Single-Cell Identity and Expression",
      "title_zh": "ScDiVa：用于单细胞身份与表达联合建模的掩码离散扩散模型",
      "authors": [
        "Mingxuan Wang",
        "Cheng Chen",
        "Gaoyang Jiang",
        "Zijia Ren",
        "Chuangxin Zhao",
        "Lu Shi",
        "Yanbiao Ma"
      ],
      "abstract": "Single-cell RNA-seq profiles are high-dimensional, sparse, and unordered, causing autoregressive generation to impose an artificial ordering bias and suffer from error accumulation. To address this, we propose scDiVa, a masked discrete diffusion foundation model that aligns generation with the dropout-like corruption process by defining a continuous-time forward masking mechanism in token space. ScDiVa features a bidirectional denoiser that jointly models discrete gene identities and continuous values, utilizing entropy-normalized serialization and a latent anchor token to maximize information efficiency and preserve global cell identity. The model is trained via depth-invariant time sampling and a dual denoising objective to simulate varying sparsity levels while ensuring precise recovery of both identity and magnitude. Pre-trained on 59 million cells, scDiVa achieves strong transfer performance across major benchmarks, including batch integration, cell type annotation, and perturbation response prediction. These results suggest that masked discrete diffusion serves as a biologically coherent and effective alternative to autoregression.",
      "tldr_zh": "该研究提出了 scDiVa，一种掩码离散扩散 (Masked Discrete Diffusion) 基础模型，旨在通过联合建模单细胞的基因身份 (gene identities) 和表达值，解决自回归模型在处理高维、稀疏且无序的单细胞数据时产生的排序偏见和误差累积问题。该模型在令牌空间 (token space) 中定义了连续时间前向掩码机制，使生成过程与生物学中常见的丢弃 (dropout) 过程对齐。scDiVa 采用了双向去噪器 (bidirectional denoiser)，并结合熵归一化序列化 (entropy-normalized serialization) 和潜在锚点令牌 (latent anchor token)，以最大化信息效率并保留全局细胞身份。通过深度不变时间采样 (depth-invariant time sampling) 和双重去噪目标，模型能够模拟多样的稀疏水平并实现对基因身份与表达强度的精确恢复。在 5900 万个细胞的大规模预训练基础上，scDiVa 在批次整合 (batch integration)、细胞类型标注 (cell type annotation) 和扰动响应预测 (perturbation response prediction) 等多个基准任务中展现出卓越的迁移性能。实验结果证明，掩码离散扩散作为自回归的一种有效替代方案，在生物学一致性和建模效率上具有显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03477v1",
      "published_date": "2026-02-03 12:50:29 UTC",
      "updated_date": "2026-02-03 12:50:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:41:41.020150+00:00"
    },
    {
      "arxiv_id": "2602.03468v1",
      "title": "IntentRL: Training Proactive User-intent Agents for Open-ended Deep Research via Reinforcement Learning",
      "title_zh": "IntentRL：基于强化学习训练面向开放式深度研究的主动式用户意图智能体",
      "authors": [
        "Haohao Luo",
        "Zexi Li",
        "Yuexiang Xie",
        "Wenhao Zhang",
        "Yaliang Li",
        "Ying Shen"
      ],
      "abstract": "Deep Research (DR) agents extend Large Language Models (LLMs) beyond parametric knowledge by autonomously retrieving and synthesizing evidence from large web corpora into long-form reports, enabling a long-horizon agentic paradigm. However, unlike real-time conversational assistants, DR is computationally expensive and time-consuming, creating an autonomy-interaction dilemma: high autonomy on ambiguous user queries often leads to prolonged execution with unsatisfactory outcomes. To address this, we propose IntentRL, a framework that trains proactive agents to clarify latent user intents before starting long-horizon research. To overcome the scarcity of open-ended research data, we introduce a scalable pipeline that expands a few seed samples into high-quality dialogue turns via a shallow-to-deep intent refinement graph. We further adopt a two-stage reinforcement learning (RL) strategy: Stage I applies RL on offline dialogues to efficiently learn general user-interaction behavior, while Stage II uses the trained agent and a user simulator for online rollouts to strengthen adaptation to diverse user feedback. Extensive experiments show that IntentRL significantly improves both intent hit rate and downstream task performance, outperforming the built-in clarify modules of closed-source DR agents and proactive LLM baselines.",
      "tldr_zh": "该研究针对深层研究(Deep Research)智能体在处理模糊查询时，因高度自主性导致的计算昂贵、耗时且结果不佳等“自主-交互困境”，提出了IntentRL框架。该框架旨在通过训练主动型智能体在启动长程研究任务前澄清潜在的用户意图，从而提升任务的精准度。为解决开放式研究数据稀缺的挑战，研究者引入了一种可扩展的流程，利用浅层到深层的意图细化图(Shallow-to-Deep Intent Refinement Graph)将少量种子样本扩展为高质量对话数据。随后，研究采用了两阶段强化学习(Reinforcement Learning)策略，通过离线对话学习通用交互行为，并结合用户模拟器(User Simulator)进行在线演练以增强对多样化反馈的适应性。实验结果表明，IntentRL在提升意图命中率(Intent Hit Rate)和下游任务性能方面表现出色，显著优于闭源研究智能体的内置澄清模块及主动型大语言模型(LLM)基准。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2602.03468v1",
      "published_date": "2026-02-03 12:43:09 UTC",
      "updated_date": "2026-02-03 12:43:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:41:38.134178+00:00"
    },
    {
      "arxiv_id": "2602.03467v1",
      "title": "The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding",
      "title_zh": "符号化解释中无关信息抽象的双重作用：认知努力与理解力的权衡",
      "authors": [
        "Zeynep G. Saribatur",
        "Johannes Langer",
        "Ute Schmid"
      ],
      "abstract": "Explanations are central to human cognition, yet AI systems often produce outputs that are difficult to understand. While symbolic AI offers a transparent foundation for interpretability, raw logical traces often impose a high extraneous cognitive load. We investigate how formal abstractions, specifically removal and clustering, impact human reasoning performance and cognitive effort. Utilizing Answer Set Programming (ASP) as a formal framework, we define a notion of irrelevant details to be abstracted over to obtain simplified explanations. Our cognitive experiments, in which participants classified stimuli across domains with explanations derived from an answer set program, show that clustering details significantly improve participants' understanding, while removal of details significantly reduce cognitive effort, supporting the hypothesis that abstraction enhances human-centered symbolic explanations.",
      "tldr_zh": "该研究探讨了在符号化解释中对无关细节进行抽象的双重作用，旨在解决Symbolic AI中原始逻辑追踪导致的高认知负荷问题。研究人员利用回答集编程(Answer Set Programming, ASP)作为形式化框架，定义了移除(removal)和聚类(clustering)两种形式化抽象手段，以简化复杂的逻辑解释。通过跨领域的认知实验，研究观察了参与者在处理不同抽象程度解释时的推理表现与认知努力。实验结果表明，聚类细节能显著提升参与者的理解能力，而移除细节则能有效降低认知负荷。这一发现支持了抽象技术能够增强以人为中心的符号化解释的假设，为开发更具可解释性的AI系统提供了重要参考。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03467v1",
      "published_date": "2026-02-03 12:42:41 UTC",
      "updated_date": "2026-02-03 12:42:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:41:40.136872+00:00"
    },
    {
      "arxiv_id": "2602.03452v1",
      "title": "Beyond Variance: Prompt-Efficient RLVR via Rare-Event Amplification and Bidirectional Pairing",
      "title_zh": "超越方差：基于稀有事件放大与双向配对的高提示效率 RLVR",
      "authors": [
        "Xin Sheng",
        "Jiaxin Li",
        "Yujuan Pang",
        "Ran Peng",
        "Yong Ma"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) is effective for training large language models on deterministic outcome reasoning tasks. Prior work shows RLVR works with few prompts, but prompt selection is often based only on training-accuracy variance, leading to unstable optimization directions and weaker transfer. We revisit prompt selection from a mechanism-level view and argue that an effective minibatch should provide both (i) a reliable positive anchor and (ii) explicit negative learning signals from rare failures. Based on this principle, we propose \\emph{positive--negative pairing}: at each update, we sample a hard-but-solvable $q^{+}$ and an easy-but-brittle prompt $q^{-}$(high success rate but not perfect), characterized by low and high empirical success rates under multiple rollouts. We further introduce Weighted GRPO, which reweights binary outcomes at the pair level and uses group-normalized advantages to amplify rare successes on $q^{+}$ into sharp positive guidance while turning rare failures on $q^{-}$ into strong negative penalties. This bidirectional signal provides informative learning feedback for both successes and failures, improving sample efficiency without suppressing exploration. On Qwen2.5-Math-7B, a single paired minibatch per update consistently outperforms a GRPO baseline that selects two prompts via commonly used variance-based selection heuristics: AIME~2025 Pass@8 improves from 16.8 to 22.2, and AMC23 Pass@64 from 94.0 to 97.0, while remaining competitive with large-scale RLVR trained from a pool of 1209 training prompts. Similar gains are observed on Qwen2.5-Math-7B-Instruct.",
      "tldr_zh": "该研究针对可验证奖励强化学习 (RLVR) 在大语言模型推理任务中因依赖方差进行提示词选择而导致的优化不稳问题，提出了一种名为正负对齐 (positive-negative pairing) 的高效机制。该机制主张有效的小批次应包含可靠的正向锚点和来自罕见失败的明确负向信号，通过在每次更新中采样一个“难而可解”的提示词 q+ 和一个“易而脆弱”的提示词 q- 来实现。研究进一步引入了 Weighted GRPO 算法，通过对成对结果进行重加权和组归一化优势计算，将 q+ 上的罕见成功转化为锐利的正向引导，并将 q- 上的罕见失败转变为强力的负向惩罚。这种双向信号在不抑制探索的前提下显著提升了样本效率。实验结果表明，在 Qwen2.5-Math-7B 模型上，该方法在 AIME 2025 的 Pass@8 从 16.8 提升至 22.2，在 AMC23 的 Pass@64 从 94.0 提升至 97.0。此外，该方法在仅使用极少量提示词的情况下，展现出了足以媲美大规模 RLVR 训练的竞争力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03452v1",
      "published_date": "2026-02-03 12:17:25 UTC",
      "updated_date": "2026-02-03 12:17:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:04.610177+00:00"
    },
    {
      "arxiv_id": "2602.03448v1",
      "title": "Hierarchical Concept-to-Appearance Guidance for Multi-Subject Image Generation",
      "title_zh": "面向多主体图像生成的层级化概念到外观引导",
      "authors": [
        "Yijia Xu",
        "Zihao Wang",
        "Jinshi Cui"
      ],
      "abstract": "Multi-subject image generation aims to synthesize images that faithfully preserve the identities of multiple reference subjects while following textual instructions. However, existing methods often suffer from identity inconsistency and limited compositional control, as they rely on diffusion models to implicitly associate text prompts with reference images. In this work, we propose Hierarchical Concept-to-Appearance Guidance (CAG), a framework that provides explicit, structured supervision from high-level concepts to fine-grained appearances. At the conceptual level, we introduce a VAE dropout training strategy that randomly omits reference VAE features, encouraging the model to rely more on robust semantic signals from a Visual Language Model (VLM) and thereby promoting consistent concept-level generation in the absence of complete appearance cues. At the appearance level, we integrate the VLM-derived correspondences into a correspondence-aware masked attention module within the Diffusion Transformer (DiT). This module restricts each text token to attend only to its matched reference regions, ensuring precise attribute binding and reliable multi-subject composition. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the multi-subject image generation, substantially improving prompt following and subject consistency.",
      "tldr_zh": "该研究提出了层级化概念到外观引导框架 Hierarchical Concept-to-Appearance Guidance (CAG)，旨在解决多主体图像生成中常见的身份不一致和组合控制力有限等挑战。在概念层面，研究引入了一种 VAE dropout 训练策略，通过随机省略参考图像的 VAE 特征，促使模型强化对视觉语言模型 Visual Language Model (VLM) 语义信号的依赖，从而在外观线索不全时提升概念生成的一致性。在外观层面，CAG 将 VLM 衍生的对应关系集成到 Diffusion Transformer (DiT) 的对应感知掩码注意力模块 correspondence-aware masked attention module 中，限制文本标记仅关注匹配的参考区域。这种机制确保了精确的属性绑定和可靠的多主体组合，克服了现有模型仅依赖隐式关联的局限。实验结果表明，该方法在多主体图像生成领域取得了 State-of-the-art 的性能表现，显著提升了模型对提示词的遵循能力及主体一致性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03448v1",
      "published_date": "2026-02-03 12:13:29 UTC",
      "updated_date": "2026-02-03 12:13:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:00.126062+00:00"
    },
    {
      "arxiv_id": "2602.03445v1",
      "title": "CRL-VLA: Continual Vision-Language-Action Learning",
      "title_zh": "CRL-VLA：持续视觉-语言-动作学习",
      "authors": [
        "Qixin Zeng",
        "Shuo Zhang",
        "Hongyin Zhang",
        "Renjie Wang",
        "Han Zhao",
        "Libang Zhao",
        "Runze Li",
        "Donglin Wang",
        "Chao Huang"
      ],
      "abstract": "Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.",
      "tldr_zh": "该研究针对具体化智能体在开放环境中的持续学习挑战，提出了CRL-VLA框架，旨在解决Vision-Language-Action (VLA)模型在通过强化学习微调掌握灵巧操作时面临的稳定性与塑性平衡难题。研究者推导出了一个统一的性能边界，将稳定性与塑性的权衡与目标条件优势量(goal-conditioned advantage magnitude)以及策略分歧(policy divergence)联系起来。CRL-VLA通过非对称调节(asymmetric regulation)解决了这一困境，即在限制旧任务优势量的同时，允许新任务优势量的受控增长。该框架采用了创新的双评论家架构(dual-critic architecture)和目标条件价值公式(Goal-Conditioned Value Formulation, GCVF)，通过冻结的评论家锚定语义一致性，并利用可训练的估计器驱动模型适应。在LIBERO基准测试上的实验结果表明，CRL-VLA在抗遗忘(anti-forgetting)和正向适应(forward adaptation)方面均优于基准模型，有效协调了持续强化学习(Continual Reinforcement Learning)中的冲突目标。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03445v1",
      "published_date": "2026-02-03 12:09:53 UTC",
      "updated_date": "2026-02-03 12:09:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:01.113109+00:00"
    },
    {
      "arxiv_id": "2602.03439v1",
      "title": "Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents",
      "title_zh": "面向 LLM 智能体可执行语义约束强制执行的本体到工具编译",
      "authors": [
        "Xiaochi Zhou",
        "Patrick Bulter",
        "Changxuan Yang",
        "Simon D. Rihm",
        "Thitikarn Angkanaporn",
        "Jethro Akroyd",
        "Sebastian Mosbach",
        "Markus Kraft"
      ],
      "abstract": "We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge. Within The World Avatar (TWA), ontological specifications are compiled into executable tool interfaces that LLM-based agents must use to create and modify knowledge graph instances, enforcing semantic constraints during generation rather than through post-hoc validation. Extending TWA's semantic agent composition framework, the Model Context Protocol (MCP) and associated agents are integral components of the knowledge graph ecosystem, enabling structured interaction between generative models, symbolic constraints, and external resources. An agent-based workflow translates ontologies into ontology-aware tools and iteratively applies them to extract, validate, and repair structured knowledge from unstructured scientific text. Using metal-organic polyhedra synthesis literature as an illustrative case, we show how executable ontological semantics can guide LLM behaviour and reduce manual schema and prompt engineering, establishing a general paradigm for embedding formal knowledge into generative systems.",
      "tldr_zh": "该研究提出了 ontology-to-tools compilation 机制，作为将 Large Language Models (LLMs) 与正式领域知识耦合的原理验证方法。在 The World Avatar (TWA) 框架下，本体规范被直接编译为可执行的工具接口，强制 LLM 智能体在生成知识图谱 Knowledge Graph 实例的过程中遵循语义约束，而非进行事后验证。该方法集成了 Model Context Protocol (MCP) 与语义智能体组合框架，实现了生成模型、符号约束与外部资源之间的结构化交互。通过一种智能体驱动的工作流，该系统能将本体转化为具备本体感知能力的工具，并迭代应用于从非结构化科学文本中提取、验证和修复结构化知识。以 metal-organic polyhedra 合成文献为案例研究，实验证明该范式能有效引导 LLM 行为并显著减少人工 schema 和 prompt engineering 的需求，为在生成系统中嵌入正式知识建立了通用范式。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03439v1",
      "published_date": "2026-02-03 12:03:26 UTC",
      "updated_date": "2026-02-03 12:03:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:20.617385+00:00"
    },
    {
      "arxiv_id": "2602.03429v1",
      "title": "DiscoverLLM: From Executing Intents to Discovering Them",
      "title_zh": "DiscoverLLM：从执行意图到发现意图",
      "authors": [
        "Tae Soo Kim",
        "Yoonjoo Lee",
        "Jaesang Yu",
        "John Joon Young Chung",
        "Juho Kim"
      ],
      "abstract": "To handle ambiguous and open-ended requests, Large Language Models (LLMs) are increasingly trained to interact with users to surface intents they have not yet expressed (e.g., ask clarification questions). However, users are often ambiguous because they have not yet formed their intents: they must observe and explore outcomes to discover what they want. Simply asking \"what kind of tone do you want?\" fails when users themselves do not know. We introduce DiscoverLLM, a novel and generalizable framework that trains LLMs to help users form and discover their intents. Central to our approach is a novel user simulator that models cognitive state with a hierarchy of intents that progressively concretize as the model surfaces relevant options -- where the degree of concretization serves as a reward signal that models can be trained to optimize. Resulting models learn to collaborate with users by adaptively diverging (i.e., explore options) when intents are unclear, and converging (i.e., refine and implement) when intents concretize. Across proposed interactive benchmarks in creative writing, technical writing, and SVG drawing, DiscoverLLM achieves over 10% higher task performance while reducing conversation length by up to 40%. In a user study with 75 human participants, DiscoverLLM improved conversation satisfaction and efficiency compared to baselines.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在处理模糊或开放式请求时，因用户尚未形成明确意图而导致传统澄清机制失效的问题，提出了DiscoverLLM框架。该框架旨在通过交互引导用户发现并形成潜在意图，其核心在于引入了一个模拟用户认知状态并具有层次化意图结构的全新用户模拟器。模型以意图的具体化程度作为奖励信号进行优化，使其能够根据意图的清晰度自适应地在发散式探索选项与收敛式精炼执行之间进行切换。实验结果显示，DiscoverLLM在创意写作、技术写作和SVG绘图等多个基准测试中，将任务性能提升了10%以上，并将对话长度缩短了多达40%。此外，一项包含75名参与者的用户研究进一步证实，该框架在对话满意度和交互效率方面均显著优于现有基线模型。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03429v1",
      "published_date": "2026-02-03 11:51:46 UTC",
      "updated_date": "2026-02-03 11:51:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:24.931350+00:00"
    },
    {
      "arxiv_id": "2602.03414v1",
      "title": "Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction",
      "title_zh": "Socratic-Geo：基于多智能体交互的合成数据生成与几何推理",
      "authors": [
        "Zhengbo Jiao",
        "Shaobo Wang",
        "Zifan Zhang",
        "Wei Wang",
        "Bing Zhao",
        "Hu Wei",
        "Linfeng Zhang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have significantly advanced vision-language understanding. However, even state-of-the-art models struggle with geometric reasoning, revealing a critical bottleneck: the extreme scarcity of high-quality image-text pairs. Human annotation is prohibitively expensive, while automated methods fail to ensure fidelity and training effectiveness. Existing approaches either passively adapt to available images or employ inefficient random exploration with filtering, decoupling generation from learning needs. We propose Socratic-Geo, a fully autonomous framework that dynamically couples data synthesis with model learning through multi-agent interaction. The Teacher agent generates parameterized Python scripts with reflective feedback (Reflect for solvability, RePI for visual validity), ensuring image-text pair purity. The Solver agent optimizes reasoning through preference learning, with failure paths guiding Teacher's targeted augmentation. Independently, the Generator learns image generation capabilities on accumulated \"image-code-instruction\" triplets, distilling programmatic drawing intelligence into visual generation. Starting from only 108 seed problems, Socratic-Solver achieves 49.11 on six benchmarks using one-quarter of baseline data, surpassing strong baselines by 2.43 points. Socratic-Generator achieves 42.4% on GenExam, establishing new state-of-the-art for open-source models, surpassing Seedream-4.0 (39.8%) and approaching Gemini-2.5-Flash-Image (43.1%).",
      "tldr_zh": "该研究提出了Socratic-Geo，这是一个通过多智能体交互(Multi-Agent Interaction)动态耦合数据合成与模型学习的自主框架，旨在解决多模态大语言模型(MLLMs)在几何推理(Geometric Reasoning)中面临的高质量数据稀缺问题。该框架由Teacher智能体利用带有反射反馈机制的Python脚本确保图文对的纯度，并由Solver智能体通过偏好学习(Preference Learning)优化推理过程，同时利用失败路径引导Teacher进行定向数据增强。此外，Generator通过学习累积的指令三元组，将程序化绘图智能蒸馏为视觉生成能力。实验结果显示，Socratic-Solver仅使用基线模型四分之一的数据量就在六项基准测试中取得了49.11的评分，超越了强基线模型，而Socratic-Generator在GenExam上达到了42.4%的准确率，创下了开源模型的State-of-the-Art纪录并接近Gemini-2.5-Flash-Image的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18pages",
      "pdf_url": "https://arxiv.org/pdf/2602.03414v1",
      "published_date": "2026-02-03 11:42:25 UTC",
      "updated_date": "2026-02-03 11:42:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:22.944444+00:00"
    },
    {
      "arxiv_id": "2602.03403v1",
      "title": "Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations",
      "title_zh": "直觉模糊偏好冲突情境下的冲突消解可行策略",
      "authors": [
        "Guangming Lang",
        "Mingchuan Shang",
        "Mengjun Hu",
        "Jie Zhou",
        "Feng Xu"
      ],
      "abstract": "In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on three qualitative relations, namely, preference, converse, and indifference, to describe agents' attitudes towards issue pairs, which significantly limits their capacity in capturing the essence of conflict. To overcome this limitation, we introduce the concept of an intuitionistic fuzzy preference-based conflict situation that captures agents' attitudes towards issue pairs with finer granularity than that afforded by classical preference-based models. Afterwards, we develop intuitionistic fuzzy preference-based conflict measures within this framework, and construct three-way conflict analysis models for trisecting the set of agent pairs, the agent set, and the issue set. Additionally, relative loss functions built on the proposed conflict functions are employed to calculate thresholds for three-way conflict analysis. Finally, we present adjustment mechanism-based feasible strategies that simultaneously account for both adjustment magnitudes and conflict degrees, together with an algorithm for constructing such feasible strategies, and provide an illustrative example to demonstrate the validity and effectiveness of the proposed model.",
      "tldr_zh": "该研究针对三支冲突分析(three-way conflict analysis)中偏好冲突模型仅能描述偏好、逆偏好和无差异三种定性关系的局限性，提出了 intuitionistic fuzzy preference-based conflict situation（基于直觉模糊偏好的冲突情境）概念，旨在以更细的粒度刻画代理人对议题对的复杂态度。研究在该框架下开发了直觉模糊偏好冲突度量，并构建了相应的模型，实现了对代理人对、代理人集合及议题集合的三划分。此外，研究引入基于冲突函数的相对损失函数(relative loss functions)来计算三支决策阈值。最后，论文提出了同时兼顾调节幅度与冲突程度的基于调节机制的可行策略(adjustment mechanism-based feasible strategies)及其构建算法。通过实例演示，该模型被证明在处理偏好冲突情境时具有显著的有效性和实用价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03403v1",
      "published_date": "2026-02-03 11:30:34 UTC",
      "updated_date": "2026-02-03 11:30:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:21.859988+00:00"
    },
    {
      "arxiv_id": "2602.03402v1",
      "title": "Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility",
      "title_zh": "风险意识注入：在不牺牲效用的前提下校准视觉语言模型的安全性",
      "authors": [
        "Mengxuan Wang",
        "Yuxin Chen",
        "Gang Xu",
        "Tao He",
        "Hongjie Jiang",
        "Ming Li"
      ],
      "abstract": "Vision language models (VLMs) extend the reasoning capabilities of large language models (LLMs) to cross-modal settings, yet remain highly vulnerable to multimodal jailbreak attacks. Existing defenses predominantly rely on safety fine-tuning or aggressive token manipulations, incurring substantial training costs or significantly degrading utility. Recent research shows that LLMs inherently recognize unsafe content in text, and the incorporation of visual inputs in VLMs frequently dilutes risk-related signals. Motivated by this, we propose Risk Awareness Injection (RAI), a lightweight and training-free framework for safety calibration that restores LLM-like risk recognition by amplifying unsafe signals in VLMs. Specifically, RAI constructs an Unsafe Prototype Subspace from language embeddings and performs targeted modulation on selected high-risk visual tokens, explicitly activating safety-critical signals within the cross-modal feature space. This modulation restores the model's LLM-like ability to detect unsafe content from visual inputs, while preserving the semantic integrity of original tokens for cross-modal reasoning. Extensive experiments across multiple jailbreak and utility benchmarks demonstrate that RAI substantially reduces attack success rate without compromising task performance.",
      "tldr_zh": "该研究针对视觉语言模型(VLMs)易受多模态越狱攻击(multimodal jailbreak attacks)且现有防御手段成本高或损害效用的问题，提出了风险意识注入(Risk Awareness Injection, RAI)框架。研究发现视觉输入常会稀释模型对风险的感知，RAI作为一种轻量级且无需训练的安全校准方法，旨在恢复模型类似大型语言模型(LLMs)的风险识别能力。具体而言，该框架通过从语言嵌入中构建不安全原型子空间(Unsafe Prototype Subspace)，对高风险视觉标记(visual tokens)进行定向调制，从而在跨模态特征空间中显式激活安全关键信号。这种方法在不破坏原始标记语义完整性的情况下，增强了模型从图像中检测不安全内容的能力。实验结果证明，RAI在多个基准测试中显著降低了攻击成功率(attack success rate)，且完全不影响模型的任务执行性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03402v1",
      "published_date": "2026-02-03 11:26:05 UTC",
      "updated_date": "2026-02-03 11:26:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:49.129355+00:00"
    },
    {
      "arxiv_id": "2602.03400v1",
      "title": "Precision in Practice: Knowledge Guided Code Summarizing Grounded in Industrial Expectations",
      "title_zh": "实践中的精准：植根于工业预期的知识引导型代码摘要",
      "authors": [
        "Jintai Li",
        "Songqiang Chen",
        "Shuo Jin",
        "Xiaoyuan Xie"
      ],
      "abstract": "Code summaries are essential for helping developers understand code functionality and reducing maintenance and collaboration costs. Although recent advances in large language models (LLMs) have significantly improved automatic code summarization, the practical usefulness of generated summaries in industrial settings remains insufficiently explored. In collaboration with documentation experts from the industrial HarmonyOS project, we conducted a questionnaire study showing that over 57.4% of code summaries produced by state-of-the-art approaches were rejected due to violations of developers' expectations for industrial documentation. Beyond semantic similarity to reference summaries, developers emphasize additional requirements, including the use of appropriate domain terminology, explicit function categorization, and the avoidance of redundant implementation details.\n  To address these expectations, we propose ExpSum, an expectation-aware code summarization approach that integrates function metadata abstraction, informative metadata filtering, context-aware domain knowledge retrieval, and constraint-driven prompting to guide LLMs in generating structured, expectation-aligned summaries. We evaluate ExpSum on the HarmonyOS project and widely used code summarization benchmarks. Experimental results show that ExpSum consistently outperforms all baselines, achieving improvements of up to 26.71% in BLEU-4 and 20.10% in ROUGE-L on HarmonyOS. Furthermore, LLM-based evaluations indicate that ExpSum-generated summaries better align with developer expectations across other projects, demonstrating its effectiveness for industrial code documentation.",
      "tldr_zh": "该研究调查了工业界对代码摘要(code summarization)的实际需求，通过对HarmonyOS项目的研究发现，超过57.4%的现有SOTA模型生成的摘要因违反开发者对工业文档(industrial expectations)的预期而被拒绝。针对开发者对领域术语(domain terminology)、显式函数分类(function categorization)及避免冗余细节的要求，作者提出了ExpSum，一种预期感知(expectation-aware)的代码摘要生成方法。该方法集成了函数元数据抽象(function metadata abstraction)、信息元数据过滤(metadata filtering)、上下文感知领域知识检索(domain knowledge retrieval)以及约束驱动提示(constraint-driven prompting)，引导大语言模型生成结构化且符合预期的摘要。在HarmonyOS项目及多项基准测试上的实验结果显示，ExpSum在BLEU-4和ROUGE-L指标上较基线模型分别提升了高达26.71%和20.10%，证明了其在生成工业级代码文档方面的有效性与实用性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03400v1",
      "published_date": "2026-02-03 11:22:28 UTC",
      "updated_date": "2026-02-03 11:22:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:43.242824+00:00"
    },
    {
      "arxiv_id": "2602.03392v1",
      "title": "On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models",
      "title_zh": "论大语言模型强化微调中的熵动力学",
      "authors": [
        "Shumin Wang",
        "Yuexiang Xie",
        "Wenhao Zhang",
        "Yuchang Sun",
        "Yanxi Chen",
        "Yaliang Li",
        "Yanyong Zhang"
      ],
      "abstract": "Entropy serves as a critical metric for measuring the diversity of outputs generated by large language models (LLMs), providing valuable insights into their exploration capabilities. While recent studies increasingly focus on monitoring and adjusting entropy to better balance exploration and exploitation in reinforcement fine-tuning (RFT), a principled understanding of entropy dynamics during this process is yet to be thoroughly investigated. In this paper, we establish a theoretical framework for analyzing the entropy dynamics during the RFT process, which begins with a discriminant expression that quantifies entropy change under a single logit update. This foundation enables the derivation of a first-order expression for entropy change, which can be further extended to the update formula of Group Relative Policy Optimization (GRPO). The corollaries and insights drawn from the theoretical analysis inspire the design of entropy control methods, and also offer a unified lens for interpreting various entropy-based methods in existing studies. We provide empirical evidence to support the main conclusions of our analysis and demonstrate the effectiveness of the derived entropy-discriminator clipping methods. This study yields novel insights into RFT training dynamics, providing theoretical support and practical strategies for optimizing the exploration-exploitation balance during LLM fine-tuning.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在强化微调(RFT)过程中熵(Entropy)的动态演变，旨在为平衡探索与利用提供理论支撑。论文建立了一个分析RFT过程中熵动态的理论框架，首先推导出了单个Logit更新下熵变化的判别式。基于此基础，研究者进一步推导出了熵变化的一阶表达式，并将其扩展到群体相对策略优化(GRPO)的更新公式中。该理论分析不仅为解释现有的各种基于熵的方法提供了统一视角，还启发了新型熵控制方法的设计。通过实证研究，论文验证了主要理论结论，并证明了所提出的熵判别器裁剪(Entropy-discriminator clipping)方法的有效性。这项工作为理解RFT训练动态提供了新见解，并为优化LLM微调过程中的探索-利用平衡提供了实用的实践策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03392v1",
      "published_date": "2026-02-03 11:14:58 UTC",
      "updated_date": "2026-02-03 11:14:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:41.430526+00:00"
    },
    {
      "arxiv_id": "2602.03389v1",
      "title": "Chain-of-Goals Hierarchical Policy for Long-Horizon Offline Goal-Conditioned RL",
      "title_zh": "面向长时程离线目标条件强化学习的目标链式层级策略",
      "authors": [
        "Jinwoo Choi",
        "Sang-Hyun Lee",
        "Seung-Woo Seo"
      ],
      "abstract": "Offline goal-conditioned reinforcement learning remains challenging for long-horizon tasks. While hierarchical approaches mitigate this issue by decomposing tasks, most existing methods rely on separate high- and low-level networks and generate only a single intermediate subgoal, making them inadequate for complex tasks that require coordinating multiple intermediate decisions. To address this limitation, we draw inspiration from the chain-of-thought paradigm and propose the Chain-of-Goals Hierarchical Policy (CoGHP), a novel framework that reformulates hierarchical decision-making as autoregressive sequence modeling within a unified architecture. Given a state and a final goal, CoGHP autoregressively generates a sequence of latent subgoals followed by the primitive action, where each latent subgoal acts as a reasoning step that conditions subsequent predictions. To implement this efficiently, we pioneer the use of an MLP-Mixer backbone, which supports cross-token communication and captures structural relationships among state, goal, latent subgoals, and action. Across challenging navigation and manipulation benchmarks, CoGHP consistently outperforms strong offline baselines, demonstrating improved performance on long-horizon tasks.",
      "tldr_zh": "该研究提出了Chain-of-Goals Hierarchical Policy (CoGHP)，这是一个旨在解决长时程(long-horizon)离线目标条件强化学习(Offline goal-conditioned RL)挑战的新型框架。针对现有分层方法依赖独立高低层网络且仅能生成单一中间子目标的局限性，CoGHP借鉴了链式思维(chain-of-thought)范式，将分层决策过程重新表述为统一架构下的自回归序列建模(autoregressive sequence modeling)。在该架构中，系统根据当前状态和最终目标自回归地生成一系列潜在子目标(latent subgoals)及原始动作，每个子目标均作为引导后续预测的推理步骤。为了高效实现这一过程，该研究率先采用了MLP-Mixer骨干网络以支持跨令牌通信，并捕捉状态、目标、子目标与动作之间的结构化关系。实验结果表明，CoGHP在具有挑战性的导航和操作基准测试中一致优于强大的离线基准模型，显著提升了在复杂长时程任务中的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.03389v1",
      "published_date": "2026-02-03 11:11:03 UTC",
      "updated_date": "2026-02-03 11:11:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:42.825145+00:00"
    },
    {
      "arxiv_id": "2602.03387v1",
      "title": "Toward a Sustainable Federated Learning Ecosystem: A Practical Least Core Mechanism for Payoff Allocation",
      "title_zh": "迈向可持续联邦学习生态系统：一种实用的收益分配最小核机制",
      "authors": [
        "Zhengwei Ni",
        "Zhidu Li",
        "Wei Chen",
        "Zhaoyang Zhang",
        "Zehua Wang",
        "F. Richard Yu",
        "Victor C. M. Leung"
      ],
      "abstract": "Emerging network paradigms and applications increasingly rely on federated learning (FL) to enable collaborative intelligence while preserving privacy. However, the sustainability of such collaborative environments hinges on a fair and stable payoff allocation mechanism. Focusing on coalition stability, this paper introduces a payoff allocation framework based on the least core (LC) concept. Unlike traditional methods, the LC prioritizes the cohesion of the federation by minimizing the maximum dissatisfaction among all potential subgroups, ensuring that no participant has an incentive to break away. To adapt this game-theoretic concept to practical, large-scale networks, we propose a streamlined implementation with a stack-based pruning algorithm, effectively balancing computational efficiency with allocation precision. Case studies in federated intrusion detection demonstrate that our mechanism correctly identifies pivotal contributors and strategic alliances. The results confirm that the practical LC framework promotes stable collaboration and fosters a sustainable FL ecosystem.",
      "tldr_zh": "该研究针对联邦学习(Federated Learning, FL)生态系统中协作环境的可持续性问题，提出了一种基于最小核心(Least Core, LC)概念的收益分配框架。与传统方法不同，LC 机制通过最小化所有潜在子群体中的最大不满程度来优先保障联邦的凝聚力，从而确保没有任何参与者有动机脱离联盟。为了将这一博弈论概念应用于实际的大规模网络，研究团队设计了一种结合栈式剪枝算法(stack-based pruning algorithm)的简化实现方案，在保障分配精度的同时提升了计算效率。在联邦入侵检测(federated intrusion detection)案例中的实验表明，该机制能够准确识别关键贡献者与战略联盟。研究结果证明，这种实用的 LC 框架有效促进了参与者间的稳定协作，为构建可持续的 FL 生态系统奠定了基础。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "7 pages, 3 figures, submitted to IEEE Network",
      "pdf_url": "https://arxiv.org/pdf/2602.03387v1",
      "published_date": "2026-02-03 11:10:50 UTC",
      "updated_date": "2026-02-03 11:10:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:42:43.817627+00:00"
    },
    {
      "arxiv_id": "2602.03386v1",
      "title": "An Approximate Ascent Approach To Prove Convergence of PPO",
      "title_zh": "证明 PPO 收敛性的近似上升法",
      "authors": [
        "Leif Doering",
        "Daniel Schmidt",
        "Moritz Melcher",
        "Sebastian Kassing",
        "Benedikt Wille",
        "Tilman Aach",
        "Simon Weissmann"
      ],
      "abstract": "Proximal Policy Optimization (PPO) is among the most widely used deep reinforcement learning algorithms, yet its theoretical foundations remain incomplete. Most importantly, convergence and understanding of fundamental PPO advantages remain widely open. Under standard theory assumptions we show how PPO's policy update scheme (performing multiple epochs of minibatch updates on multi-use rollouts with a surrogate gradient) can be interpreted as approximated policy gradient ascent. We show how to control the bias accumulated by the surrogate gradients and use techniques from random reshuffling to prove a convergence theorem for PPO that sheds light on PPO's success. Additionally, we identify a previously overlooked issue in truncated Generalized Advantage Estimation commonly used in PPO. The geometric weighting scheme induces infinite mass collapse onto the longest $k$-step advantage estimator at episode boundaries. Empirical evaluations show that a simple weight correction can yield substantial improvements in environments with strong terminal signal, such as Lunar Lander.",
      "tldr_zh": "本研究深入探讨了Proximal Policy Optimization (PPO)的理论基础，旨在解决其在深度强化学习中收敛性证明不完整的问题。作者将PPO的更新策略解释为一种近似策略梯度上升(Approximate Policy Gradient Ascent)方法，并提出了控制替代梯度(Surrogate Gradients)累积偏差的方案。通过引入随机重排(Random Reshuffling)技术，该研究成功证明了PPO的收敛定理，从而阐明了该算法取得成功的理论机制。此外，研究还发现了截断广义优势估计(Generalized Advantage Estimation, GAE)在回合边界处由于几何加权方案导致的权重坍缩问题。实验验证表明，仅需对权重进行简单修正，即可显著提升PPO在Lunar Lander等具有强终止信号环境下的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03386v1",
      "published_date": "2026-02-03 11:10:22 UTC",
      "updated_date": "2026-02-03 11:10:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:02.923017+00:00"
    },
    {
      "arxiv_id": "2602.03379v1",
      "title": "Rethinking Benign Relearning: Syntax as the Hidden Driver of Unlearning Failures",
      "title_zh": "重新审视良性重学习：句法是遗忘失效的深层动因",
      "authors": [
        "Sangyeon Yoon",
        "Hyesoo Hong",
        "Wonje Jeung",
        "Albert No"
      ],
      "abstract": "Machine unlearning aims to remove specific content from trained models while preserving overall performance. However, the phenomenon of benign relearning, in which forgotten information reemerges even from benign fine-tuning data, reveals that existing unlearning methods remain fundamentally fragile. A common explanation attributes this effect to topical relevance, but we find this account insufficient. Through systematic analysis, we demonstrate that syntactic similarity, rather than topicality, is the primary driver: across benchmarks, syntactically similar data consistently trigger recovery even without topical overlap, due to their alignment in representations and gradients with the forgotten content. Motivated by this insight, we introduce syntactic diversification, which paraphrases the original forget queries into heterogeneous structures prior to unlearning. This approach effectively suppresses benign relearning, accelerates forgetting, and substantially alleviates the trade-off between unlearning efficacy and model utility.",
      "tldr_zh": "该研究探讨了机器遗忘(Machine Unlearning)中的良性重新学习(Benign Relearning)现象，即被遗忘的信息在良性微调后重新出现并导致遗忘失效的脆弱性问题。作者通过系统分析发现，驱动这一现象的核心因素并非传统认为的主题相关性(Topical Relevance)，而是句法相似性(Syntactic Similarity)。实验证明，即使在没有主题重叠的情况下，句法相似的数据也会因为与被遗忘内容在表示和梯度上的对齐而触发信息恢复。基于此发现，研究提出了句法多样化(Syntactic Diversification)方法，在遗忘处理前将原始查询改写为异构结构。该方法有效抑制了良性重新学习，加速了遗忘过程，并显著优化了遗忘效果与模型效用(Model Utility)之间的权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03379v1",
      "published_date": "2026-02-03 10:57:19 UTC",
      "updated_date": "2026-02-03 10:57:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:17.513807+00:00"
    },
    {
      "arxiv_id": "2602.03372v1",
      "title": "SLIM-Diff: Shared Latent Image-Mask Diffusion with Lp loss for Data-Scarce Epilepsy FLAIR MRI",
      "title_zh": "SLIM-Diff：基于 $L_p$ 损失的共享潜空间图像-掩码扩散模型，用于数据稀缺的癫痫 FLAIR MRI",
      "authors": [
        "Mario Pascual-González",
        "Ariadna Jiménez-Partinen",
        "R. M. Luque-Baena",
        "Fátima Nagib-Raya",
        "Ezequiel López-Rubio"
      ],
      "abstract": "Focal cortical dysplasia (FCD) lesions in epilepsy FLAIR MRI are subtle and scarce, making joint image--mask generative modeling prone to instability and memorization. We propose SLIM-Diff, a compact joint diffusion model whose main contributions are (i) a single shared-bottleneck U-Net that enforces tight coupling between anatomy and lesion geometry from a 2-channel image+mask representation, and (ii) loss-geometry tuning via a tunable $L_p$ objective. As an internal baseline, we include the canonical DDPM-style objective ($ε$-prediction with $L_2$ loss) and isolate the effect of prediction parameterization and $L_p$ geometry under a matched setup. Experiments show that $x_0$-prediction is consistently the strongest choice for joint synthesis, and that fractional sub-quadratic penalties ($L_{1.5}$) improve image fidelity while $L_2$ better preserves lesion mask morphology. Our code and model weights are available in https://github.com/MarioPasc/slim-diff",
      "tldr_zh": "针对癫痫 FLAIR MRI 中局灶性皮质发育不良 (FCD) 病灶细微且稀缺导致的联合图像-掩膜生成建模不稳定及记忆化问题，该研究提出了 SLIM-Diff 联合扩散模型。该模型的核心贡献在于采用了一个共享瓶颈 (Shared-bottleneck) 的 U-Net 结构，通过双通道图像与掩膜表示强化了解剖结构与病灶几何之间的紧密耦合。此外，研究引入了可调节的 $L_p$ 损失目标，并对比了不同预测参数化方式对合成效果的影响。实验结果表明，$x_0$-prediction 是联合合成任务中的最优选择。研究还发现分数亚二次项惩罚 ($L_{1.5}$) 能够有效提升图像保真度，而 $L_2$ 损失在保留病灶掩膜 (Lesion mask) 形态方面表现更佳。该研究为数据稀缺场景下的医学影像精密建模提供了有效的技术路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 figures, 1 table, conference paper",
      "pdf_url": "https://arxiv.org/pdf/2602.03372v1",
      "published_date": "2026-02-03 10:48:57 UTC",
      "updated_date": "2026-02-03 10:48:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:18.032381+00:00"
    },
    {
      "arxiv_id": "2602.03359v1",
      "title": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling",
      "title_zh": "MeKi：基于存储的专家知识注入实现高效 LLM 扩展",
      "authors": [
        "Ning Ding",
        "Fangcheng Liu",
        "Kyungrae Kim",
        "Linji Hao",
        "Kyeng-Hun Lee",
        "Hyeonmok Ko",
        "Yehui Tang"
      ],
      "abstract": "Scaling Large Language Models (LLMs) typically relies on increasing the number of parameters or test-time computations to boost performance. However, these strategies are impractical for edge device deployment due to limited RAM and NPU resources. Despite hardware constraints, deploying performant LLM on edge devices such as smartphone remains crucial for user experience. To address this, we propose MeKi (Memory-based Expert Knowledge Injection), a novel system that scales LLM capacity via storage space rather than FLOPs. MeKi equips each Transformer layer with token-level memory experts that injects pre-stored semantic knowledge into the generation process. To bridge the gap between training capacity and inference efficiency, we employ a re-parameterization strategy to fold parameter matrices used during training into a compact static lookup table. By offloading the knowledge to ROM, MeKi decouples model capacity from computational cost, introducing zero inference latency overhead. Extensive experiments demonstrate that MeKi significantly outperforms dense LLM baselines with identical inference speed, validating the effectiveness of memory-based scaling paradigm for on-device LLMs. Project homepage is at https://github.com/ningding-o/MeKi.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在边缘设备部署时受限于内存 (RAM) 和计算资源 (NPU) 的挑战，提出了 MeKi (Memory-based Expert Knowledge Injection) 系统。MeKi 创新性地通过存储空间而非计算量 (FLOPs) 来扩展模型容量，在每个 Transformer 层配备标记级 (token-level) 内存专家，将预存的语义知识注入生成过程。为了兼顾训练容量与推理效率，该研究采用了重参数化 (re-parameterization) 策略，将训练时的参数矩阵折叠为紧凑的静态查找表 (lookup table)。通过将知识负荷卸载至只读存储器 (ROM)，MeKi 成功实现了模型容量与计算成本的解耦，且未增加额外的推理延迟。实验结果显示，MeKi 在保持与稠密 LLM 基准模型相同推理速度的前提下，显著提升了模型性能。这一成果验证了基于存储的扩展范式在端侧大模型应用中的高效性与可行性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03359v1",
      "published_date": "2026-02-03 10:32:04 UTC",
      "updated_date": "2026-02-03 10:32:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:25.115702+00:00"
    },
    {
      "arxiv_id": "2602.03358v1",
      "title": "GFlowPO: Generative Flow Network as a Language Model Prompt Optimizer",
      "title_zh": "GFlowPO：作为语言模型提示词优化器的生成式流网络",
      "authors": [
        "Junmo Cho",
        "Suhan Kim",
        "Sangjune An",
        "Minsu Kim",
        "Dong Bok Lee",
        "Heejun Lee",
        "Sung Ju Hwang",
        "Hae Beom Lee"
      ],
      "abstract": "Finding effective prompts for language models (LMs) is critical yet notoriously difficult: the prompt space is combinatorially large, rewards are sparse due to expensive target-LM evaluation. Yet, existing RL-based prompt optimizers often rely on on-policy updates and a meta-prompt sampled from a fixed distribution, leading to poor sample efficiency. We propose GFlowPO, a probabilistic prompt optimization framework that casts prompt search as a posterior inference problem over latent prompts regularized by a meta-prompted reference-LM prior. In the first step, we fine-tune a lightweight prompt-LM with an off-policy Generative Flow Network (GFlowNet) objective, using a replay-based training policy that reuses past prompt evaluations to enable sample-efficient exploration. In the second step, we introduce Dynamic Memory Update (DMU), a training-free mechanism that updates the meta-prompt by injecting both (i) diverse prompts from a replay buffer and (ii) top-performing prompts from a small priority queue, thereby progressively concentrating the search process on high-reward regions. Across few-shot text classification, instruction induction benchmarks, and question answering tasks, GFlowPO consistently outperforms recent discrete prompt optimization baselines.",
      "tldr_zh": "该研究提出了 GFlowPO，一种将提示词搜索 (prompt search) 视为潜在提示词后验推理问题的概率提示优化框架，旨在解决语言模型在巨大搜索空间中采样效率低且评估成本高的问题。该方法首先利用离线 Generative Flow Network (GFlowNet) 目标微调轻量级的 prompt-LM，并采用基于重放 (replay-based) 的训练策略重用历史评估数据以实现高效探索。随后，研究引入了动态内存更新 (Dynamic Memory Update, DMU) 机制，通过在元提示 (meta-prompt) 中持续注入多样化及高奖励提示词，引导搜索过程逐步聚焦于高回报区域。实验结果显示，GFlowPO 在少样本分类、指令诱导 (instruction induction) 和问答任务中均一致优于现有的离散提示优化基准。这种方法通过结合概率建模与动态记忆机制，为自动化提示词工程提供了一种更具采样效率且性能稳健的新方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03358v1",
      "published_date": "2026-02-03 10:30:03 UTC",
      "updated_date": "2026-02-03 10:30:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:30.506541+00:00"
    },
    {
      "arxiv_id": "2602.03353v1",
      "title": "Causal Graph Learning via Distributional Invariance of Cause-Effect Relationship",
      "title_zh": "基于因果关系分布不变性的因果图学习",
      "authors": [
        "Nang Hung Nguyen",
        "Phi Le Nguyen",
        "Thao Nguyen Truong",
        "Trong Nghia Hoang",
        "Masashi Sugiyama"
      ],
      "abstract": "This paper introduces a new framework for recovering causal graphs from observational data, leveraging the observation that the distribution of an effect, conditioned on its causes, remains invariant to changes in the prior distribution of those causes. This insight enables a direct test for potential causal relationships by checking the variance of their corresponding effect-cause conditional distributions across multiple downsampled subsets of the data. These subsets are selected to reflect different prior cause distributions, while preserving the effect-cause conditional relationships. Using this invariance test and exploiting an (empirical) sparsity of most causal graphs, we develop an algorithm that efficiently uncovers causal relationships with quadratic complexity in the number of observational variables, reducing the processing time by up to 25x compared to state-of-the-art methods. Our empirical experiments on a varied benchmark of large-scale datasets show superior or equivalent performance compared to existing works, while achieving enhanced scalability.",
      "tldr_zh": "该研究提出了一种从观测数据中恢复因果图(Causal Graph)的新框架，其核心在于利用了效应(Effect)在给定原因(Cause)条件下的分布对于原因先验分布的变化具有分布不变性(Distributional Invariance)的特性。该方法通过在多个下采样数据子集中检测条件分布的方差来识别因果关系，这些子集被设计为反映不同的原因先验分布并同时保留因果条件关系。结合因果图的经验稀疏性(Sparsity)，研究团队开发了一种具有平方复杂度的算法，相比现有最先进方法，其处理速度提升了高达25倍。在各种大规模数据集上的实验结果证明，该框架在保持与现有技术相当或更优性能的同时，显著增强了算法的可扩展性(Scalability)，为大规模因果发现提供了高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03353v1",
      "published_date": "2026-02-03 10:26:16 UTC",
      "updated_date": "2026-02-03 10:26:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:27.428994+00:00"
    },
    {
      "arxiv_id": "2602.03351v1",
      "title": "Building Interpretable Models for Moral Decision-Making",
      "title_zh": "构建面向道德决策的可解释模型",
      "authors": [
        "Mayank Goel",
        "Aritra Das",
        "Paras Chopra"
      ],
      "abstract": "We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy on Moral Machine data while remaining small enough for detailed analysis. We use different interpretability techniques to uncover how moral reasoning distributes across the network, demonstrating that biases localize to distinct computational stages among other findings.",
      "tldr_zh": "该研究通过构建自定义的 transformer 模型，深入探讨了神经网络在处理类电车难题（trolley-style dilemmas）时的道德决策机制。该模型利用特定的 embeddings 编码受影响的对象、人数及结果路径，实现了对结构化道德场景的处理。所采用的 2-layer 架构在 Moral Machine 数据集上达到了 77% 的准确度，其紧凑的设计为精细的可解释性分析提供了可能。研究运用多种可解释性（interpretability）技术揭示了道德推理在神经网络中的分布规律，并发现偏见（biases）会定位于特定的计算阶段。该工作为理解人工神经网络的道德判断逻辑以及构建可解释的决策模型提供了重要依据。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures, accepted to AAAI'26 Machine Ethics Workshop",
      "pdf_url": "https://arxiv.org/pdf/2602.03351v1",
      "published_date": "2026-02-03 10:22:42 UTC",
      "updated_date": "2026-02-03 10:22:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:45.822295+00:00"
    },
    {
      "arxiv_id": "2602.03344v1",
      "title": "Robustness as an Emergent Property of Task Performance",
      "title_zh": "鲁棒性：任务性能的一种涌现属性",
      "authors": [
        "Shir Ashury-Tahan",
        "Ariel Gera",
        "Elron Bandel",
        "Michal Shmueli-Scheuer",
        "Leshem Choshen"
      ],
      "abstract": "Robustness is often regarded as a critical future challenge for real-world applications, where stability is essential. However, as models often learn tasks in a similar order, we hypothesize that easier tasks will be easier regardless of how they are presented to the model. Indeed, in this paper, we show that as models approach high performance on a task, robustness is effectively achieved. Through an empirical analysis of multiple models across diverse datasets and configurations (e.g., paraphrases, different temperatures), we find a strong positive correlation. Moreover, we find that robustness is primarily driven by task-specific competence rather than inherent model-level properties, challenging current approaches that treat robustness as an independent capability. Thus, from a high-level perspective, we may expect that as new tasks saturate, model robustness on these tasks will emerge accordingly. For researchers, this implies that explicit efforts to measure and improve robustness may warrant reduced emphasis, as such robustness is likely to develop alongside performance gains. For practitioners, it acts as a sign that indeed the tasks that the literature deals with are unreliable, but on easier past tasks, the models are reliable and ready for real-world deployment.",
      "tldr_zh": "该研究探讨了鲁棒性(Robustness)作为任务性能(Task Performance)涌现属性的观点，挑战了将鲁棒性视为独立能力的传统认知。作者通过对多种模型和数据集在改写(paraphrases)和不同温度(temperatures)配置下的实证分析，发现任务性能与鲁棒性之间存在极强的正相关性。实验结果表明，鲁棒性主要源于模型对特定任务的胜任程度，而非模型层面的固有属性。随着模型在特定任务上的表现趋于饱和，其应对扰动的鲁棒性会自然产生。这一发现暗示研究人员或许可以减少对衡量和提升鲁棒性的专项投入，因为鲁棒性会随性能提升而同步发展。对于从业者而言，这意味着在性能表现优异且趋于饱和的任务中，模型已具备投入实际应用所需的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03344v1",
      "published_date": "2026-02-03 10:10:38 UTC",
      "updated_date": "2026-02-03 10:10:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:40.423180+00:00"
    },
    {
      "arxiv_id": "2602.03342v1",
      "title": "Tiled Prompts: Overcoming Prompt Underspecification in Image and Video Super-Resolution",
      "title_zh": "Tiled Prompts：解决图像和视频超分辨率中的提示词欠描述问题",
      "authors": [
        "Bryan Sangwoo Kim",
        "Jonghyun Park",
        "Jong Chul Ye"
      ],
      "abstract": "Text-conditioned diffusion models have advanced image and video super-resolution by using prompts as semantic priors, but modern super-resolution pipelines typically rely on latent tiling to scale to high resolutions, where a single global caption causes prompt underspecification. A coarse global prompt often misses localized details (prompt sparsity) and provides locally irrelevant guidance (prompt misguidance) that can be amplified by classifier-free guidance. We propose Tiled Prompts, a unified framework for image and video super-resolution that generates a tile-specific prompt for each latent tile and performs super-resolution under locally text-conditioned posteriors, providing high-information guidance that resolves prompt underspecification with minimal overhead. Experiments on high resolution real-world images and videos show consistent gains in perceptual quality and text alignment, while reducing hallucinations and tile-level artifacts relative to global-prompt baselines.",
      "tldr_zh": "该研究针对文本条件扩散模型在图像和视频超分辨率(super-resolution)中面临的 prompt underspecification 问题提出了 Tiled Prompts 框架。现有的超分辨率管线在处理高分辨率内容时通常依赖 latent tiling 技术，但单一的全局提示词往往会导致局部细节缺失或产生无关的语义引导。Tiled Prompts 通过为每个 latent tile 生成特定的 tile-specific prompt，并在局部文本条件的后验概率下执行超分辨率，从而提供高信息量的引导。实验结果表明，该框架在处理真实世界的高分辨率图像和视频时，显著提升了感知质量(perceptual quality)和文本对齐(text alignment)能力。相比于基于全局提示词(global-prompt)的基准模型，该方法在保持极低开销的同时，有效减少了幻觉(hallucinations)和切片产生的边缘伪影(tile-level artifacts)。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03342v1",
      "published_date": "2026-02-03 10:09:27 UTC",
      "updated_date": "2026-02-03 10:09:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:41.618572+00:00"
    },
    {
      "arxiv_id": "2602.03340v1",
      "title": "MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis",
      "title_zh": "MentalSeek-Dx：面向真实世界精神科诊断的渐进式假说演绎推理",
      "authors": [
        "Xiao Sun",
        "Yuming Yang",
        "Junnan Zhu",
        "Jiang Zhong",
        "Xinyu Zhou",
        "Kaiwen Wei"
      ],
      "abstract": "Mental health disorders represent a burgeoning global public health challenge. While Large Language Models (LLMs) have demonstrated potential in psychiatric assessment, their clinical utility is severely constrained by benchmarks that lack ecological validity and fine-grained diagnostic supervision. To bridge this gap, we introduce \\textbf{MentalDx Bench}, the first benchmark dedicated to disorder-level psychiatric diagnosis within real-world clinical settings. Comprising 712 de-identified electronic health records annotated by board-certified psychiatrists under ICD-11 guidelines, the benchmark covers 76 disorders across 16 diagnostic categories. Evaluation of 18 LLMs reveals a critical \\textit{paradigm misalignment}: strong performance at coarse diagnostic categorization contrasts with systematic failure at disorder-level diagnosis, underscoring a gap between pattern-based modeling and clinical hypothetico-deductive reasoning. In response, we propose \\textbf{MentalSeek-Dx}, a medical-specialized LLM trained to internalize this clinical reasoning process through supervised trajectory construction and curriculum-based reinforcement learning. Experiments on MentalDx Bench demonstrate that MentalSeek-Dx achieves state-of-the-art (SOTA) performance with only 14B parameters, establishing a clinically grounded framework for reliable psychiatric diagnosis.",
      "tldr_zh": "该研究针对全球精神健康挑战以及大语言模型（LLMs）在精神科诊断中因基准测试缺乏生态效度和细粒度监督而导致的临床实用性受限问题，推出了首个专注于真实临床环境疾病级别诊断的基准测试MentalDx Bench。该基准包含由资深精神科医生依据ICD-11指南标注的712份电子健康记录（EHRs），涵盖16个类别的76种疾病。通过评估18个LLMs，研究发现模型在粗粒度分类与疾病级别诊断之间存在严重的“范式错位”，暴露出模式建模与临床假设演绎推理（hypothetico-deductive reasoning）之间的差距。为此，研究者提出了医疗专用模型MentalSeek-Dx，通过监督轨迹构建和基于课程的强化学习（curriculum-based reinforcement learning）内化临床推理过程。实验表明，MentalSeek-Dx仅凭14B参数便在MentalDx Bench上达到了SOTA性能，为构建可靠且具备临床基础的精神科诊断系统奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 27 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03340v1",
      "published_date": "2026-02-03 10:03:35 UTC",
      "updated_date": "2026-02-03 10:03:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:49.537568+00:00"
    },
    {
      "arxiv_id": "2602.03320v1",
      "title": "MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning",
      "title_zh": "MedSAM-Agent：利用多轮智能体强化学习赋能交互式医学图像分割",
      "authors": [
        "Shengyuan Liu",
        "Liuxin Bao",
        "Qi Yang",
        "Wanting Geng",
        "Boyun Zheng",
        "Chenxin Li",
        "Wenting Chen",
        "Houwen Peng",
        "Yixuan Yuan"
      ],
      "abstract": "Medical image segmentation is evolving from task-specific models toward generalizable frameworks. Recent research leverages Multi-modal Large Language Models (MLLMs) as autonomous agents, employing reinforcement learning with verifiable reward (RLVR) to orchestrate specialized tools like the Segment Anything Model (SAM). However, these approaches often rely on single-turn, rigid interaction strategies and lack process-level supervision during training, which hinders their ability to fully exploit the dynamic potential of interactive tools and leads to redundant actions. To bridge this gap, we propose MedSAM-Agent, a framework that reformulates interactive segmentation as a multi-step autonomous decision-making process. First, we introduce a hybrid prompting strategy for expert-curated trajectory generation, enabling the model to internalize human-like decision heuristics and adaptive refinement strategies. Furthermore, we develop a two-stage training pipeline that integrates multi-turn, end-to-end outcome verification with a clinical-fidelity process reward design to promote interaction parsimony and decision efficiency. Extensive experiments across 6 medical modalities and 21 datasets demonstrate that MedSAM-Agent achieves state-of-the-art performance, effectively unifying autonomous medical reasoning with robust, iterative optimization. Code is available \\href{https://github.com/CUHK-AIM-Group/MedSAM-Agent}{here}.",
      "tldr_zh": "该研究提出了 MedSAM-Agent 框架，旨在解决现有医疗图像分割智能体因交互策略僵化且缺乏过程级监督而导致的动作冗余问题。该框架将交互式分割重新定义为一个多步自主决策过程，通过引入混合提示（hybrid prompting）策略生成专家轨迹，使模型能够内化类人的决策启发式方法。研究进一步开发了两阶段训练流水线，将多轮端到端结果验证与临床保真度过程奖励设计（clinical-fidelity process reward design）相结合，显著提升了交互的精简度和决策效率。在 6 种医学模态和 21 个数据集上的实验结果表明，MedSAM-Agent 达到了 state-of-the-art 性能，成功实现了自主医疗推理与鲁棒迭代优化的有机统一。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 Pages, 4 Figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03320v1",
      "published_date": "2026-02-03 09:47:49 UTC",
      "updated_date": "2026-02-03 09:47:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:43:47.716962+00:00"
    },
    {
      "arxiv_id": "2602.03317v1",
      "title": "Multiparameter Uncertainty Mapping in Quantitative Molecular MRI using a Physics-Structured Variational Autoencoder (PS-VAE)",
      "title_zh": "基于物理结构化变分自编码器（PS-VAE）的定量分子 MRI 多参数不确定性映射",
      "authors": [
        "Alex Finkelstein",
        "Ron Moneta",
        "Or Zohar",
        "Michal Rivlin",
        "Moritz Zaiss",
        "Dinora Friedmann Morvinski",
        "Or Perlman"
      ],
      "abstract": "Quantitative imaging methods, such as magnetic resonance fingerprinting (MRF), aim to extract interpretable pathology biomarkers by estimating biophysical tissue parameters from signal evolutions. However, the pattern-matching algorithms or neural networks used in such inverse problems often lack principled uncertainty quantification, which limits the trustworthiness and transparency, required for clinical acceptance. Here, we describe a physics-structured variational autoencoder (PS-VAE) designed for rapid extraction of voxelwise multi-parameter posterior distributions. Our approach integrates a differentiable spin physics simulator with self-supervised learning, and provides a full covariance that captures the inter-parameter correlations of the latent biophysical space. The method was validated in a multi-proton pool chemical exchange saturation transfer (CEST) and semisolid magnetization transfer (MT) molecular MRF study, across in-vitro phantoms, tumor-bearing mice, healthy human volunteers, and a subject with glioblastoma. The resulting multi-parametric posteriors are in good agreement with those calculated using a brute-force Bayesian analysis, while providing an orders-of-magnitude acceleration in whole brain quantification. In addition, we demonstrate how monitoring the multi-parameter posterior dynamics across progressively acquired signals provides practical insights for protocol optimization and may facilitate real-time adaptive acquisition.",
      "tldr_zh": "该研究针对磁共振指纹技术 (MRF) 等定量成像方法在反演问题中缺乏不确定性量化 (uncertainty quantification) 的挑战，提出了一种物理结构变分自编码器 (PS-VAE)，用于快速提取体素级多参数后验分布 (multi-parameter posterior distributions)。该框架通过集成可微自旋物理模拟器 (differentiable spin physics simulator) 与自监督学习 (self-supervised learning)，能够提供捕获参数间相关性的完整协方差 (full covariance)。在涉及 CEST 和 MT 的分子 MRF 实验中，该方法在体外模型、荷瘤小鼠及人类受试者（包括胶质母细胞瘤患者）上均得到了验证。结果表明，PS-VAE 获得的结果与暴力贝叶斯分析 (brute-force Bayesian analysis) 高度一致，且在全脑量化速度上实现了数量级的提升。此外，该研究还证明了监测多参数后验动态可为协议优化 (protocol optimization) 和实时自适应采集提供重要的实践指导。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "physics.med-ph"
      ],
      "primary_category": "stat.ML",
      "comment": "Submitted to IEEE Transactions on Medical Imaging. This project was funded by the European Union (ERC, BabyMagnet, project no. 101115639). Views and opinions expressed are, however, those of the authors only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them",
      "pdf_url": "https://arxiv.org/pdf/2602.03317v1",
      "published_date": "2026-02-03 09:46:55 UTC",
      "updated_date": "2026-02-03 09:46:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:03.723009+00:00"
    },
    {
      "arxiv_id": "2602.03315v1",
      "title": "Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity",
      "title_zh": "Memora：平衡抽象性与具体性的调和记忆表征",
      "authors": [
        "Menglin Xia",
        "Xuchao Zhang",
        "Shantanu Dixit",
        "Paramaguru Harimurugan",
        "Rujia Wang",
        "Victor Ruhle",
        "Robert Sim",
        "Chetan Bansal",
        "Saravan Rajmohan"
      ],
      "abstract": "Agent memory systems must accommodate continuously growing information while supporting efficient, context-aware retrieval for downstream tasks. Abstraction is essential for scaling agent memory, yet it often comes at the cost of specificity, obscuring the fine-grained details required for effective reasoning. We introduce Memora, a harmonic memory representation that structurally balances abstraction and specificity. Memora organizes information via its primary abstractions that index concrete memory values and consolidate related updates into unified memory entries, while cue anchors expand retrieval access across diverse aspects of the memory and connect related memories. Building on this structure, we employ a retrieval policy that actively exploits these memory connections to retrieve relevant information beyond direct semantic similarity. Theoretically, we show that standard Retrieval-Augmented Generation (RAG) and Knowledge Graph (KG)-based memory systems emerge as special cases of our framework. Empirically, Memora establishes a new state-of-the-art on the LoCoMo and LongMemEval benchmarks, demonstrating better retrieval relevance and reasoning effectiveness as memory scales.",
      "tldr_zh": "该研究提出了Memora，一种在结构上平衡Abstraction与Specificity的调和内存表示框架，旨在解决智能体内存系统在扩展抽象能力时往往会牺牲精细细节的问题。Memora通过Primary Abstractions对具体内存值进行索引，并将相关更新整合为统一的内存条目，同时利用Cue Anchors在多维度扩展检索路径并连接相关记忆。基于此结构，Memora采用了一种主动利用记忆关联的检索策略，能够检索到超出直接语义相似度(Semantic Similarity)的相关信息。理论分析证明，标准的检索增强生成(RAG)和基于知识图谱(KG)的内存系统均可视为该框架的特例。实验结果显示，Memora在LoCoMo和LongMemEval基准测试中达到了SOTA性能，在内存规模扩大时展现出更出色的检索相关性和推理有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03315v1",
      "published_date": "2026-02-03 09:44:43 UTC",
      "updated_date": "2026-02-03 09:44:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:12.244335+00:00"
    },
    {
      "arxiv_id": "2602.03310v1",
      "title": "RDT2: Exploring the Scaling Limit of UMI Data Towards Zero-Shot Cross-Embodiment Generalization",
      "title_zh": "RDT2：探索 UMI 数据规模极限，迈向零样本跨具身泛化",
      "authors": [
        "Songming Liu",
        "Bangguo Li",
        "Kai Ma",
        "Lingxuan Wu",
        "Hengkai Tan",
        "Xiao Ouyang",
        "Hang Su",
        "Jun Zhu"
      ],
      "abstract": "Vision-Language-Action (VLA) models hold promise for generalist robotics but currently struggle with data scarcity, architectural inefficiencies, and the inability to generalize across different hardware platforms. We introduce RDT2, a robotic foundation model built upon a 7B parameter VLM designed to enable zero-shot deployment on novel embodiments for open-vocabulary tasks. To achieve this, we collected one of the largest open-source robotic datasets--over 10,000 hours of demonstrations in diverse families--using an enhanced, embodiment-agnostic Universal Manipulation Interface (UMI). Our approach employs a novel three-stage training recipe that aligns discrete linguistic knowledge with continuous control via Residual Vector Quantization (RVQ), flow-matching, and distillation for real-time inference. Consequently, RDT2 becomes one of the first models that simultaneously zero-shot generalizes to unseen objects, scenes, instructions, and even robotic platforms. Besides, it outperforms state-of-the-art baselines in dexterous, long-horizon, and dynamic downstream tasks like playing table tennis. See https://rdt-robotics.github.io/rdt2/ for more information.",
      "tldr_zh": "该研究推出了RDT2，一种基于7B参数视觉语言动作模型(VLA)的机器人基础模型，旨在解决机器人领域数据稀缺、架构效率低下以及难以跨硬件平台泛化等核心挑战。为了实现零样本(Zero-shot)部署，研究团队通过增强的具身无关通用操作界面(UMI)收集了超过10,000小时的多样化示教数据，构建了规模最大的开源机器人数据集之一。在技术实现上，RDT2采用了创新的三阶段训练策略，利用残差向量量化(RVQ)和流匹配(Flow-matching)技术将离散语言知识与连续动作控制对齐，并结合知识蒸馏(Distillation)确保实时推理性能。实验结果表明，RDT2是首批能够同时对未知物体、场景、指令乃至全新机器人平台实现Zero-shot泛化的模型。此外，该模型在灵巧操作、长程任务及打乒乓球等高动态下游任务中的表现均显著优于现有的State-of-the-art基线模型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03310v1",
      "published_date": "2026-02-03 09:38:23 UTC",
      "updated_date": "2026-02-03 09:38:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:07.118387+00:00"
    },
    {
      "arxiv_id": "2602.03309v1",
      "title": "Entropy-Gated Selective Policy Optimization:Token-Level Gradient Allocation for Hybrid Training of Large Language Models",
      "title_zh": "熵门控选择性策略优化：面向大语言模型混合训练的词元级梯度分配",
      "authors": [
        "Yuelin Hu",
        "Zhengxue Cheng",
        "Wei Liu",
        "Li Song"
      ],
      "abstract": "Hybrid training methods for large language models combine supervised fine tuning (SFT) on expert demonstrations with reinforcement learning (RL) on model rollouts, typically at the sample level. We propose Entropy Gated Selective Policy Optimization (EGSPO), a three stage framework that extends sample level mixing with token level gradient modulation.\n  Stage 1, SFT expert learning, establishes a reliable warm up policy using expert demonstrations with a pure SFT loss. Stage 2, RL rollout generation, samples trajectories from the current policy and computes per token predictive entropy. Stage 3, the EGSPO mechanism, applies entropy gated gradient allocation: a predictive entropy module routes high entropy tokens to full PPO updates to encourage exploration, and low entropy tokens to attenuated PPO updates to reduce variance and preserve knowledge. Critically, both branches incorporate the advantage function A_t, ensuring that incorrect trajectories receive consistent negative learning signals and preventing reinforcement of confident errors.\n  EGSPO achieves consistent improvements on mathematical reasoning benchmarks, with gains of 3.8 percent on AIME and 2.9 percent on MATH over the CHORD phi baseline, while incurring only 3.4 percent additional computational overhead.",
      "tldr_zh": "该研究提出了Entropy-Gated Selective Policy Optimization (EGSPO)，这是一种针对大语言模型(LLMs)混合训练的三阶段框架。该框架通过Token-level gradient allocation将传统的样本级别(sample level)混合训练进行了扩展。在第一阶段SFT专家学习建立预热策略后，第二阶段在RL生成过程中计算每个token的predictive entropy。第三阶段通过熵门控机制进行梯度分配，将高熵token引导至完整PPO updates以鼓励探索，将低熵token引导至衰减的PPO updates以减少方差。关键的是，两个分支均引入了advantage function $A_t$，确保错误轨迹能接收到一致的负向学习信号，从而防止reinforcement of confident errors。实验结果显示，EGSPO在AIME和MATH数学推理基准上分别比CHORD phi基线提升了3.8%和2.9%，且仅增加了3.4%的额外计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted by cscwd2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03309v1",
      "published_date": "2026-02-03 09:38:21 UTC",
      "updated_date": "2026-02-03 09:38:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:16.621858+00:00"
    },
    {
      "arxiv_id": "2602.03306v1",
      "title": "Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval",
      "title_zh": "学习选择：面向稠密检索的查询感知自适应维度选择",
      "authors": [
        "Zhanyu Wu",
        "Richong Zhang",
        "Zhijie Nie"
      ],
      "abstract": "Dense retrieval represents queries and docu-002 ments as high-dimensional embeddings, but003 these representations can be redundant at the004 query level: for a given information need, only005 a subset of dimensions is consistently help-006 ful for ranking. Prior work addresses this via007 pseudo-relevance feedback (PRF) based dimen-008 sion importance estimation, which can produce009 query-aware masks without labeled data but010 often relies on noisy pseudo signals and heuris-011 tic test-time procedures. In contrast, super-012 vised adapter methods leverage relevance labels013 to improve embedding quality, yet they learn014 global transformations shared across queries015 and do not explicitly model query-aware di-016 mension importance. We propose a Query-017 Aware Adaptive Dimension Selection frame-018 work that learns to predict per-dimension im-019 portance directly from query embedding. We020 first construct oracle dimension importance dis-021 tributions over embedding dimensions using022 supervised relevance labels, and then train a023 predictor to map a query embedding to these024 label-distilled importance scores. At inference,025 the predictor selects a query-aware subset of026 dimensions for similarity computation based027 solely on the query embedding, without pseudo-028 relevance feedback. Experiments across multi-029 ple dense retrievers and benchmarks show that030 our learned dimension selector improves re-031 trieval effectiveness over the full-dimensional032 baseline as well as PRF-based masking and033 supervised adapter baselines.",
      "tldr_zh": "该研究探讨了稠密检索(Dense Retrieval)中高维嵌入(embeddings)在查询层面的冗余问题，指出对于特定的信息需求，仅有部分维度对排序具有持续贡献。针对现有基于伪相关反馈(Pseudo-Relevance Feedback)的方法依赖噪声信号且有监督适配器(Supervised Adapter)仅能学习全局变换的局限，作者提出了查询感知自适应维度选择(Query-Aware Adaptive Dimension Selection)框架。该框架利用有监督相关性标签构建理想的维度分布，训练预测器将查询嵌入直接映射为标签蒸馏(Label-Distilled)的重要性分数。在推理阶段，预测器能够仅依据查询嵌入动态选择维度子集进行相似度计算，摆脱了对伪相关反馈的依赖。实验结果表明，该学习维度选择器在多个检索器和基准测试中均显著提升了检索效能，其表现优于全维度基准(Full-Dimensional Baseline)以及现有的掩码和适配器方法。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03306v1",
      "published_date": "2026-02-03 09:32:21 UTC",
      "updated_date": "2026-02-03 09:32:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:17.831185+00:00"
    },
    {
      "arxiv_id": "2602.03302v1",
      "title": "Full end-to-end diagnostic workflow automation of 3D OCT via foundation model-driven AI for retinal diseases",
      "title_zh": "基于基础模型驱动 AI 的视网膜疾病 3D OCT 全端到端诊断工作流自动化",
      "authors": [
        "Jinze Zhang",
        "Jian Zhong",
        "Li Lin",
        "Jiaxiong Li",
        "Ke Ma",
        "Naiyang Li",
        "Meng Li",
        "Yuan Pan",
        "Zeyu Meng",
        "Mengyun Zhou",
        "Shang Huang",
        "Shilong Yu",
        "Zhengyu Duan",
        "Sutong Li",
        "Honghui Xia",
        "Juping Liu",
        "Dan Liang",
        "Yantao Wei",
        "Xiaoying Tang",
        "Jin Yuan",
        "Peng Xiao"
      ],
      "abstract": "Optical coherence tomography (OCT) has revolutionized retinal disease diagnosis with its high-resolution and three-dimensional imaging nature, yet its full diagnostic automation in clinical practices remains constrained by multi-stage workflows and conventional single-slice single-task AI models. We present Full-process OCT-based Clinical Utility System (FOCUS), a foundation model-driven framework enabling end-to-end automation of 3D OCT retinal disease diagnosis. FOCUS sequentially performs image quality assessment with EfficientNetV2-S, followed by abnormality detection and multi-disease classification using a fine-tuned Vision Foundation Model. Crucially, FOCUS leverages a unified adaptive aggregation method to intelligently integrate 2D slices-level predictions into comprehensive 3D patient-level diagnosis. Trained and tested on 3,300 patients (40,672 slices), and externally validated on 1,345 patients (18,498 slices) across four different-tier centers and diverse OCT devices, FOCUS achieved high F1 scores for quality assessment (99.01%), abnormally detection (97.46%), and patient-level diagnosis (94.39%). Real-world validation across centers also showed stable performance (F1: 90.22%-95.24%). In human-machine comparisons, FOCUS matched expert performance in abnormality detection (F1: 95.47% vs 90.91%) and multi-disease diagnosis (F1: 93.49% vs 91.35%), while demonstrating better efficiency. FOCUS automates the image-to-diagnosis pipeline, representing a critical advance towards unmanned ophthalmology with a validated blueprint for autonomous screening to enhance population scale retinal care accessibility and efficiency.",
      "tldr_zh": "该研究提出了名为 FOCUS 的基础模型驱动框架，旨在实现 3D OCT 视网膜疾病诊断的端到端全流程自动化。FOCUS 克服了传统多阶段工作流和单切片单任务 AI 模型的局限性，通过 EfficientNetV2-S 进行图像质量评估，并利用微调的 Vision Foundation Model 执行异常检测与多疾病分类。该框架核心在于采用一种统一的自适应聚合方法 (unified adaptive aggregation method)，将 2D 切片预测智能整合为全面的 3D 患者级诊断。在涉及 3,300 名患者的内部训练及跨中心、跨设备的外部验证中，系统在质量评估、异常检测和患者级诊断上分别取得了 99.01%、97.46% 和 94.39% 的高 F1 scores。实证研究表明，FOCUS 的诊断表现可媲美专业医师且在效率上更具优势。该研究通过自动化“图像到诊断”的工作流，为实现无人值守眼科 (unmanned ophthalmology) 及大规模视网膜健康筛查提供了关键的技术支撑和实践蓝图。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03302v1",
      "published_date": "2026-02-03 09:28:51 UTC",
      "updated_date": "2026-02-03 09:28:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:22.517439+00:00"
    },
    {
      "arxiv_id": "2602.03301v1",
      "title": "Periodic Regularized Q-Learning",
      "title_zh": "周期正则化Q学习",
      "authors": [
        "Hyukjun Yang",
        "Han-Dong Lim",
        "Donghwan Lee"
      ],
      "abstract": "In reinforcement learning (RL), Q-learning is a fundamental algorithm whose convergence is guaranteed in the tabular setting. However, this convergence guarantee does not hold under linear function approximation. To overcome this limitation, a significant line of research has introduced regularization techniques to ensure stable convergence under function approximation. In this work, we propose a new algorithm, periodic regularized Q-learning (PRQ). We first introduce regularization at the level of the projection operator and explicitly construct a regularized projected value iteration (RP-VI), subsequently extending it to a sample-based RL algorithm. By appropriately regularizing the projection operator, the resulting projected value iteration becomes a contraction. By extending this regularized projection into the stochastic setting, we establish the PRQ algorithm and provide a rigorous theoretical analysis that proves finite-time convergence guarantees for PRQ under linear function approximation.",
      "tldr_zh": "该研究针对Reinforcement Learning中Q-learning在linear function approximation下无法保证收敛的基础性挑战，提出了一种名为Periodic Regularized Q-learning (PRQ)的新算法。研究者首先在projection operator层面引入正则化技术，显式构建了Regularized Projected Value Iteration (RP-VI)，并随后将其扩展为基于样本的强化学习算法。通过对projection operator进行适当的正则化处理，确保了所得的投影值迭代具有contraction性质，从而保证了算法的稳定性。通过将这种正则化投影应用于随机环境，研究团队确立了PRQ算法，并提供了严谨的理论分析，证明了PRQ在linear function approximation下具有有限时间收敛(finite-time convergence)保证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03301v1",
      "published_date": "2026-02-03 09:28:06 UTC",
      "updated_date": "2026-02-03 09:28:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:24.433869+00:00"
    },
    {
      "arxiv_id": "2602.03300v1",
      "title": "R1-SyntheticVL: Is Synthetic Data from Generative Models Ready for Multimodal Large Language Model?",
      "title_zh": "R1-SyntheticVL：生成式模型合成数据是否已为多模态大语言模型做好准备？",
      "authors": [
        "Jingyi Zhang",
        "Tianyi Lin",
        "Huanjin Yao",
        "Xiang Lan",
        "Shunyu Liu",
        "Jiaxing Huang"
      ],
      "abstract": "In this work, we aim to develop effective data synthesis techniques that autonomously synthesize multimodal training data for enhancing MLLMs in solving complex real-world tasks. To this end, we propose Collective Adversarial Data Synthesis (CADS), a novel and general approach to synthesize high-quality, diverse and challenging multimodal data for MLLMs. The core idea of CADS is to leverage collective intelligence to ensure high-quality and diverse generation, while exploring adversarial learning to synthesize challenging samples for effectively driving model improvement. Specifically, CADS operates with two cyclic phases, i.e., Collective Adversarial Data Generation (CAD-Generate) and Collective Adversarial Data Judgment (CAD-Judge). CAD-Generate leverages collective knowledge to jointly generate new and diverse multimodal data, while CAD-Judge collaboratively assesses the quality of synthesized data. In addition, CADS introduces an Adversarial Context Optimization mechanism to optimize the generation context to encourage challenging and high-value data generation. With CADS, we construct MMSynthetic-20K and train our model R1-SyntheticVL, which demonstrates superior performance on various benchmarks.",
      "tldr_zh": "该研究提出了Collective Adversarial Data Synthesis (CADS)，这是一种旨在自主合成高质量、多样化且具有挑战性的多模态数据的新方法，用以提升Multimodal Large Language Models (MLLMs) 解决复杂现实任务的能力。CADS的核心理念是结合集体智慧与对抗性学习 (Adversarial Learning)，在确保数据多样性的同时合成高难度的训练样本。该方法包含Collective Adversarial Data Generation (CAD-Generate) 和 Collective Adversarial Data Judgment (CAD-Judge) 两个循环阶段，分别负责数据的联合生成与质量协作评估。此外，研究引入了Adversarial Context Optimization机制，通过优化生成上下文来进一步挖掘高价值数据。基于该方法构建的MMSynthetic-20K数据集训练出的R1-SyntheticVL模型在多个基准测试中展现了卓越的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03300v1",
      "published_date": "2026-02-03 09:26:32 UTC",
      "updated_date": "2026-02-03 09:26:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:28.227966+00:00"
    },
    {
      "arxiv_id": "2602.03295v1",
      "title": "POP: Prefill-Only Pruning for Efficient Large Model Inference",
      "title_zh": "POP：面向高效大模型推理的仅预填充剪枝",
      "authors": [
        "Junhui He",
        "Zhihui Fu",
        "Jun Wang",
        "Qingan Li"
      ],
      "abstract": "Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable capabilities. However, their deployment is hindered by significant computational costs. Existing structured pruning methods, while hardware-efficient, often suffer from significant accuracy degradation. In this paper, we argue that this failure stems from a stage-agnostic pruning approach that overlooks the asymmetric roles between the prefill and decode stages. By introducing a virtual gate mechanism, our importance analysis reveals that deep layers are critical for next-token prediction (decode) but largely redundant for context encoding (prefill). Leveraging this insight, we propose Prefill-Only Pruning (POP), a stage-aware inference strategy that safely omits deep layers during the computationally intensive prefill stage while retaining the full model for the sensitive decode stage. To enable the transition between stages, we introduce independent Key-Value (KV) projections to maintain cache integrity, and a boundary handling strategy to ensure the accuracy of the first generated token. Extensive experiments on Llama-3.1, Qwen3-VL, and Gemma-3 across diverse modalities demonstrate that POP achieves up to 1.37$\\times$ speedup in prefill latency with minimal performance loss, effectively overcoming the accuracy-efficiency trade-off limitations of existing structured pruning methods.",
      "tldr_zh": "该研究针对大语言模型（LLMs）和视觉语言模型（VLMs）部署中计算成本高昂且现有结构化剪枝易导致精度下降的问题，提出了阶段感知的推理策略 Prefill-Only Pruning (POP)。作者通过虚拟门机制（Virtual Gate Mechanism）发现，深层网络在 Decode 阶段对于下一标记预测至关重要，但在 Prefill 阶段的上下文编码中则存在大量冗余。POP 策略在计算密集的 Prefill 阶段安全地省略深层网络，而在敏感的 Decode 阶段保留完整模型，并通过独立的 Key-Value (KV) 投影与边界处理策略确保缓存完整性和首个标记的生成准确性。在 Llama-3.1、Qwen3-VL 和 Gemma-3 等多种模态模型上的实验表明，POP 在 Prefill 延迟上实现了高达 1.37 倍的加速，且性能损失极小。该方法有效克服了传统剪枝技术在准确率与效率之间的权衡限制，为高效模型推理提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03295v1",
      "published_date": "2026-02-03 09:22:26 UTC",
      "updated_date": "2026-02-03 09:22:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:33.820569+00:00"
    },
    {
      "arxiv_id": "2602.03286v1",
      "title": "Rejecting Arguments Based on Doubt in Structured Bipolar Argumentation",
      "title_zh": "结构化双极论证中基于怀疑的论证拒绝",
      "authors": [
        "Michael A. Müller",
        "Srdjan Vesic",
        "Bruno Yun"
      ],
      "abstract": "This paper develops a new approach to computational argumentation that is informed by philosophical and linguistic views. Namely, it takes into account two ideas that have received little attention in the literature on computational argumentation: First, an agent may rationally reject an argument based on mere doubt, thus not all arguments they could defend must be accepted; and, second, that it is sometimes more natural to think in terms of which individual sentences or claims an agent accepts in a debate, rather than which arguments. In order to incorporate these two ideas into a computational approach, we first define the notion of structured bipolar argumentation frameworks (SBAFs), where arguments consist of sentences and we have both an attack and a support relation between them. Then, we provide semantics for SBAFs with two features: (1) Unlike with completeness-based semantics, our semantics do not force agents to accept all defended arguments. (2) In addition to argument extensions, which give acceptable sets of arguments, we also provide semantics for language extensions that specify acceptable sets of sentences. These semantics represent reasonable positions an agent might have in a debate. Our semantics lie between the admissible and complete semantics of abstract argumentation. Further, our approach can be used to provide a new perspective on existing approaches. For instance, we can specify the conditions under which an agent can ignore support between arguments (i.e. under which the use of abstract argumentation is warranted) and we show that deductive support semantics is a special case of our approach.",
      "tldr_zh": "该研究提出了一种基于哲学和语言学视角的计算辩论新方法，旨在解决传统模型中代理必须接受所有被辩护论据的局限性。该方法引入了结构化双极辩论框架 (Structured Bipolar Argumentation Frameworks, SBAFs)，允许代理基于疑虑 (doubt) 理性地拒绝论据，并关注论辩中单个句子或主张 (claims) 的接受度而非仅关注整体论据。在 SBAFs 中，论据由句子构成，同时具备攻击 (attack) 和支持 (support) 两种关系。研究设计的语义特征不仅不强迫代理接受所有被辩护的论据，还能通过语言扩展 (language extensions) 确定可接受的句子集合。这些语义在强度上介于抽象辩论的容许语义 (admissible semantics) 与完备语义 (complete semantics) 之间。此外，该框架还明确了忽略论据间支持关系的特定条件，并证明了演绎支持语义 (deductive support semantics) 是该方法的一个特例。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAMAS 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03286v1",
      "published_date": "2026-02-03 09:09:19 UTC",
      "updated_date": "2026-02-03 09:09:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:35.513335+00:00"
    },
    {
      "arxiv_id": "2602.03285v1",
      "title": "MeetBench-XL: Calibrated Multi-Dimensional Evaluation and Learned Dual-Policy Agents for Real-Time Meetings",
      "title_zh": "MeetBench-XL：面向实时会议的校准多维度评估与学习型双策略智能体",
      "authors": [
        "Yuelin Hu",
        "Jun Xu",
        "Bingcong Lu",
        "Zhengxue Cheng",
        "Hongwei Hu",
        "Ronghua Wu",
        "Li Song"
      ],
      "abstract": "Enterprise meeting environments require AI assistants that handle diverse operational tasks, from rapid fact checking during live discussions to cross meeting analysis for strategic planning, under strict latency, cost, and privacy constraints. Existing meeting benchmarks mainly focus on simplified question answering and fail to reflect real world enterprise workflows, where queries arise organically from multi stakeholder collaboration, span long temporal contexts, and require tool augmented reasoning.\n  We address this gap through a grounded dataset and a learned agent framework. First, we introduce MeetAll, a bilingual and multimodal corpus derived from 231 enterprise meetings totaling 140 hours. Questions are injected using an enterprise informed protocol validated by domain expert review and human discriminability studies. Unlike purely synthetic benchmarks, this protocol is grounded in four enterprise critical dimensions: cognitive load, temporal context span, domain expertise, and actionable task execution, calibrated through interviews with stakeholders across finance, healthcare, and technology sectors.\n  Second, we propose MeetBench XL, a multi dimensional evaluation protocol aligned with human judgment that measures factual fidelity, intent alignment, response efficiency, structural clarity, and completeness. Third, we present MeetMaster XL, a learned dual policy agent that jointly optimizes query routing between fast and slow reasoning paths and tool invocation, including retrieval, cross meeting aggregation, and web search. A lightweight classifier enables accurate routing with minimal overhead, achieving a superior quality latency tradeoff over single model baselines. Experiments against commercial systems show consistent gains, supported by ablations, robustness tests, and a real world deployment case study.Resources: https://github.com/huyuelin/MeetBench.",
      "tldr_zh": "该研究针对企业会议环境中 AI 助手在实时事实核查、跨会议分析及严格延迟限制下表现不足的问题，提出了 MeetAll 双语多模态语料库，该库基于认知负荷 (cognitive load)、时间跨度 (temporal context span) 等四个企业关键维度进行了校准。为更准确地衡量系统性能，研究进一步开发了 MeetBench-XL 评估协议，旨在从事实忠实度 (factual fidelity) 和意图对齐 (intent alignment) 等维度提供与人类判断一致的评价。在此基础上，研究团队推出了 MeetMaster-XL 双策略智能体 (dual-policy agent)，利用轻量级分类器在快速与慢速推理路径间进行动态路由，并优化了检索、跨会议聚合等工具调用 (tool invocation)。实验结果和实际部署案例显示，该框架在质量与延迟的权衡上显著优于现有商业系统，为实现高效、专业的实时会议辅助技术提供了有力支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted by AAAI2026 ws",
      "pdf_url": "https://arxiv.org/pdf/2602.03285v1",
      "published_date": "2026-02-03 09:08:18 UTC",
      "updated_date": "2026-02-03 09:08:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:03.920479+00:00"
    },
    {
      "arxiv_id": "2602.03282v1",
      "title": "Global Geometry Is Not Enough for Vision Representations",
      "title_zh": "全局几何不足以支撑视觉表征",
      "authors": [
        "Jiwan Chung",
        "Seon Joo Kim"
      ],
      "abstract": "A common assumption in representation learning is that globally well-distributed embeddings support robust and generalizable representations. This focus has shaped both training objectives and evaluation protocols, implicitly treating global geometry as a proxy for representational competence. While global geometry effectively encodes which elements are present, it is often insensitive to how they are composed. We investigate this limitation by testing the ability of geometric metrics to predict compositional binding across 21 vision encoders. We find that standard geometry-based statistics exhibit near-zero correlation with compositional binding. In contrast, functional sensitivity, as measured by the input-output Jacobian, reliably tracks this capability. We further provide an analytic account showing that this disparity arises from objective design, as existing losses explicitly constrain embedding geometry but leave the local input-output mapping unconstrained. These results suggest that global embedding geometry captures only a partial view of representational competence and establish functional sensitivity as a critical complementary axis for modeling composite structure.",
      "tldr_zh": "该研究探讨了表示学习中的一个核心假设，即全局分布良好的嵌入（Global Geometry）是衡量表示能力的关键指标。通过对21个视觉编码器进行实验，研究人员发现传统的几何度量指标与组合绑定（Compositional Binding）能力之间几乎不存在相关性，表明全局几何虽能有效编码元素的构成，却对其组合方式并不敏感。相比之下，基于输入-输出雅可比矩阵（Input-output Jacobian）衡量的功能敏感性（Functional Sensitivity）能够更可靠地追踪这种组合能力。分析表明，这种差异源于现有的目标函数设计通常只显式约束嵌入几何，而未对局部的输入-输出映射进行约束。研究结果证明，全局嵌入几何仅能提供表示能力的片面视图，并确立了功能敏感性在建模复合结构中作为关键互补维度的地位。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03282v1",
      "published_date": "2026-02-03 09:06:18 UTC",
      "updated_date": "2026-02-03 09:06:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:55.036992+00:00"
    },
    {
      "arxiv_id": "2602.03279v1",
      "title": "Agentic Proposing: Enhancing Large Language Model Reasoning via Compositional Skill Synthesis",
      "title_zh": "Agentic Proposing：通过组合式技能合成增强大语言模型推理能力",
      "authors": [
        "Zhengbo Jiao",
        "Shaobo Wang",
        "Zifan Zhang",
        "Xuan Ren",
        "Wei Wang",
        "Bing Zhao",
        "Hu Wei",
        "Linfeng Zhang"
      ],
      "abstract": "Advancing complex reasoning in large language models relies on high-quality, verifiable datasets, yet human annotation remains cost-prohibitive and difficult to scale. Current synthesis paradigms often face a recurring trade-off: maintaining structural validity typically restricts problem complexity, while relaxing constraints to increase difficulty frequently leads to inconsistent or unsolvable instances. To address this, we propose Agentic Proposing, a framework that models problem synthesis as a goal-driven sequential decision process where a specialized agent dynamically selects and composes modular reasoning skills. Through an iterative workflow of internal reflection and tool-use, we develop the Agentic-Proposer-4B using Multi-Granularity Policy Optimization (MGPO) to generate high-precision, verifiable training trajectories across mathematics, coding, and science. Empirical results demonstrate that downstream solvers trained on agent-synthesized data significantly outperform leading baselines and exhibit robust cross-domain generalization. Notably, a 30B solver trained on only 11,000 synthesized trajectories achieves a state-of-the-art 91.6% accuracy on AIME25, rivaling frontier-scale proprietary models such as GPT-5 and proving that a small volume of high-quality synthetic signals can effectively substitute for massive human-curated datasets.",
      "tldr_zh": "该研究提出了 Agentic Proposing 框架，旨在解决高质量推理数据集在人工标注中面临的成本高昂且难以规模化的问题。该框架将问题合成过程建模为目标驱动的序列决策任务，由专门的智能体通过内部反思和工具调用，动态选择并组合模块化推理技能。研究团队利用多粒度策略优化（Multi-Granularity Policy Optimization, MGPO）开发了 Agentic-Proposer-4B，用于生成数学、编程及科学领域的高精度训练轨迹。实验结果显示，使用该合成数据训练的下游求解器显著优于现有基准，展现出极强的跨领域泛化性。其中，仅凭 1.1 万条合成数据训练的 30B 模型在 AIME25 上达到了 91.6% 的准确率，足以抗衡 GPT-5 等前沿闭源模型。该研究有力证明了少量高质量合成信号可有效替代海量人工数据集，为增强大语言模型推理能力提供了新范式。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "23page4",
      "pdf_url": "https://arxiv.org/pdf/2602.03279v1",
      "published_date": "2026-02-03 09:02:53 UTC",
      "updated_date": "2026-02-03 09:02:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:09.425916+00:00"
    },
    {
      "arxiv_id": "2602.03268v1",
      "title": "Unveiling Covert Toxicity in Multimodal Data via Toxicity Association Graphs: A Graph-Based Metric and Interpretable Detection Framework",
      "title_zh": "通过毒性关联图揭示多模态数据中的隐蔽毒性：一种基于图的度量指标与可解释检测框架",
      "authors": [
        "Guanzong Wu",
        "Zihao Zhu",
        "Siwei Lyu",
        "Baoyuan Wu"
      ],
      "abstract": "Detecting toxicity in multimodal data remains a significant challenge, as harmful meanings often lurk beneath seemingly benign individual modalities: only emerging when modalities are combined and semantic associations are activated. To address this, we propose a novel detection framework based on Toxicity Association Graphs (TAGs), which systematically model semantic associations between innocuous entities and latent toxic implications. Leveraging TAGs, we introduce the first quantifiable metric for hidden toxicity, the Multimodal Toxicity Covertness (MTC), which measures the degree of concealment in toxic multimodal expressions. By integrating our detection framework with the MTC metric, our approach enables precise identification of covert toxicity while preserving full interpretability of the decision-making process, significantly enhancing transparency in multimodal toxicity detection. To validate our method, we construct the Covert Toxic Dataset, the first benchmark specifically designed to capture high-covertness toxic multimodal instances. This dataset encodes nuanced cross-modal associations and serves as a rigorous testbed for evaluating both the proposed metric and detection framework. Extensive experiments demonstrate that our approach outperforms existing methods across both low- and high-covertness toxicity regimes, while delivering clear, interpretable, and auditable detection outcomes. Together, our contributions advance the state of the art in explainable multimodal toxicity detection and lay the foundation for future context-aware and interpretable approaches. Content Warning: This paper contains examples of toxic multimodal content that may be offensive or disturbing to some readers. Reader discretion is advised.",
      "tldr_zh": "该研究针对多模态数据中难以察觉的隐蔽毒性 (covert toxicity) 检测挑战，提出了一种基于毒性关联图 (Toxicity Association Graphs, TAGs) 的新型检测框架，通过建模无害实体与潜在毒性含义之间的语义关联来识别有害信息。利用 TAGs，研究者引入了首个量化隐藏毒性的指标——多模态毒性隐蔽性 (Multimodal Toxicity Covertness, MTC)，用于衡量多模态表达中毒性内容的隐藏程度。该方法将检测框架与 MTC 指标集成，在精确识别隐蔽毒性的同时，确保了决策过程的完全可解释性 (interpretability) 和透明度。此外，研究构建了首个专门捕获高隐蔽性毒性实例的基准数据集 Covert Toxic Dataset，为评估检测效能提供了严谨的测试平台。实验证明，该方法在低隐蔽和高隐蔽毒性场景下均优于现有方法，并能提供清晰、可审计的检测结果，为未来上下文感知且可解释的多模态毒性检测奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03268v1",
      "published_date": "2026-02-03 08:54:25 UTC",
      "updated_date": "2026-02-03 08:54:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:52.551102+00:00"
    },
    {
      "arxiv_id": "2602.03263v1",
      "title": "CSR-Bench: A Benchmark for Evaluating the Cross-modal Safety and Reliability of MLLMs",
      "title_zh": "CSR-Bench：评估多模态大语言模型跨模态安全性与可靠性的基准",
      "authors": [
        "Yuxuan Liu",
        "Yuntian Shi",
        "Kun Wang",
        "Haoting Shen",
        "Kun Yang"
      ],
      "abstract": "Multimodal large language models (MLLMs) enable interaction over both text and images, but their safety behavior can be driven by unimodal shortcuts instead of true joint intent understanding. We introduce CSR-Bench, a benchmark for evaluating cross-modal reliability through four stress-testing interaction patterns spanning Safety, Over-rejection, Bias, and Hallucination, covering 61 fine-grained types. Each instance is constructed to require integrated image-text interpretation, and we additionally provide paired text-only controls to diagnose modality-induced behavior shifts. We evaluate 16 state-of-the-art MLLMs and observe systematic cross-modal alignment gaps. Models show weak safety awareness, strong language dominance under interference, and consistent performance degradation from text-only controls to multimodal inputs. We also observe a clear trade-off between reducing over-rejection and maintaining safe, non-discriminatory behavior, suggesting that some apparent safety gains may come from refusal-oriented heuristics rather than robust intent understanding. WARNING: This paper contains unsafe contents.",
      "tldr_zh": "该研究提出了CSR-Bench，一个用于评估多模态大语言模型（MLLMs）跨模态可靠性的基准测试，涵盖了Safety、Over-rejection、Bias和Hallucination四个维度的61个细分类型。该基准要求模型必须整合图像与文本进行理解，并引入了配对的纯文本控制组以诊断模型行为的偏移。通过对16个先进MLLMs的评估，研究发现模型普遍存在跨模态对齐缺口，且在受到干扰时表现出强烈的语言主导(Language Dominance)特征。实验结果显示，模型在多模态输入下的表现相较于纯文本控制组有明显退化。此外，研究揭示了减少过度拒绝与维持安全性之间的权衡关系，表明目前的安全性提升可能更多依赖拒绝导向的启发式策略(Refusal-oriented Heuristics)，而非真正的意图理解。这一研究为提升MLLMs在复杂跨模态交互中的稳健性和安全性提供了重要见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 1 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03263v1",
      "published_date": "2026-02-03 08:49:44 UTC",
      "updated_date": "2026-02-03 08:49:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:44:55.340465+00:00"
    },
    {
      "arxiv_id": "2602.03257v1",
      "title": "GraDE: A Graph Diffusion Estimator for Frequent Subgraph Discovery in Neural Architectures",
      "title_zh": "GraDE：用于神经网络架构频繁子图发现的图扩散估计器",
      "authors": [
        "Yikang Yang",
        "Zhengxin Yang",
        "Minghao Luo",
        "Luzhou Peng",
        "Hongxiao Li",
        "Wanling Gao",
        "Lei Wang",
        "Jianfeng Zhan"
      ],
      "abstract": "Finding frequently occurring subgraph patterns or network motifs in neural architectures is crucial for optimizing efficiency, accelerating design, and uncovering structural insights. However, as the subgraph size increases, enumeration-based methods are perfectly accurate but computationally prohibitive, while sampling-based methods are computationally tractable but suffer from a severe decline in discovery capability. To address these challenges, this paper proposes GraDE, a diffusion-guided search framework that ensures both computational feasibility and discovery capability. The key innovation is the Graph Diffusion Estimator (GraDE), which is the first to introduce graph diffusion models to identify frequent subgraphs by scoring their typicality within the learned distribution. Comprehensive experiments demonstrate that the estimator achieves superior ranking accuracy, with up to 114\\% improvement compared to sampling-based baselines. Benefiting from this, the proposed framework successfully discovers large-scale frequent patterns, achieving up to 30$\\times$ higher median frequency than sampling-based methods.",
      "tldr_zh": "该研究探讨了神经架构中频繁子图模式或 network motifs 的发现问题，旨在解决传统基于枚举的方法计算成本高昂以及采样法在大规模发现能力上严重不足的缺陷。为此，作者提出了 GraDE，这是一个结合了扩散引导搜索的创新框架，旨在兼顾计算效率与发现精度。该框架的核心创新在于引入了 Graph Diffusion Estimator (GraDE)，这是首个利用 graph diffusion models 在学习分布中对子图典型性进行评分以识别频繁子图的技术。实验证明，GraDE 在排名准确度上比基于采样的基准方法提升了高达 114%，并能成功发现大规模频繁模式。得益于这种高效的估算机制，其发现的子图中位频率达到了采样方法的 30 倍，为优化神经网络设计和深入理解其结构属性提供了强有力的技术支撑。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03257v1",
      "published_date": "2026-02-03 08:41:10 UTC",
      "updated_date": "2026-02-03 08:41:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:04.229310+00:00"
    },
    {
      "arxiv_id": "2602.03255v1",
      "title": "LPS-Bench: Benchmarking Safety Awareness of Computer-Use Agents in Long-Horizon Planning under Benign and Adversarial Scenarios",
      "title_zh": "LPS-Bench：良性与对抗场景下计算机操作智能体长程规划安全意识评测基准",
      "authors": [
        "Tianyu Chen",
        "Chujia Hu",
        "Ge Gao",
        "Dongrui Liu",
        "Xia Hu",
        "Wenjie Wang"
      ],
      "abstract": "Computer-use agents (CUAs) that interact with real computer systems can perform automated tasks but face critical safety risks. Ambiguous instructions may trigger harmful actions, and adversarial users can manipulate tool execution to achieve malicious goals. Existing benchmarks mostly focus on short-horizon or GUI-based tasks, evaluating on execution-time errors but overlooking the ability to anticipate planning-time risks. To fill this gap, we present LPS-Bench, a benchmark that evaluates the planning-time safety awareness of MCP-based CUAs under long-horizon tasks, covering both benign and adversarial interactions across 65 scenarios of 7 task domains and 9 risk types. We introduce a multi-agent automated pipeline for scalable data generation and adopt an LLM-as-a-judge evaluation protocol to assess safety awareness through the planning trajectory. Experiments reveal substantial deficiencies in existing CUAs' ability to maintain safe behavior. We further analyze the risks and propose mitigation strategies to improve long-horizon planning safety in MCP-based CUA systems. We open-source our code at https://github.com/tychenn/LPS-Bench.",
      "tldr_zh": "该研究提出了 LPS-Bench，这是一个旨在评估基于 MCP 的计算机使用智能体 (Computer-use agents, CUAs) 在长程规划 (Long-horizon planning) 过程中安全意识的基准测试。针对现有基准大多关注短程任务或执行阶段错误，而忽视了智能体在规划阶段预判风险能力的问题，LPS-Bench 涵盖了良性与对抗性交互下的 65 个场景，涉及 7 个任务领域和 9 种风险类型。研究团队引入了多智能体自动流水线以实现可扩展的数据生成，并采用 LLM-as-a-judge 评估协议，通过分析规划轨迹来衡量智能体的安全意识。实验结果揭示了现有 CUAs 在维持安全行为方面存在显著缺陷，尤其是在面对复杂指令和对抗性操纵时。最后，该研究深入分析了相关安全风险并提出了针对性的缓解策略，旨在提升 MCP 系统在长程规划中的安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03255v1",
      "published_date": "2026-02-03 08:40:24 UTC",
      "updated_date": "2026-02-03 08:40:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:09.122420+00:00"
    },
    {
      "arxiv_id": "2602.03249v1",
      "title": "Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning",
      "title_zh": "Accordion-Thinking：通过自主调节步骤摘要实现高效且易读的大语言模型推理",
      "authors": [
        "Zhicheng Yang",
        "Zhijiang Guo",
        "Yinya Huang",
        "Yongxin Wang",
        "Wenlei Shi",
        "Yiwei Wang",
        "Xiaodan Liang",
        "Jing Tang"
      ],
      "abstract": "Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.",
      "tldr_zh": "该研究提出了 Accordion-Thinking，这是一个端到端的框架，旨在解决长 Chain-of-Thought (CoT) 在测试时计算扩展中面临的 KV cache 线性增长和注意力复杂度问题。该框架允许大语言模型 (LLMs) 通过动态摘要机制自我调节推理步骤的粒度，并引入了 Fold 推理模式，即定期总结思路并丢弃先前的 Token 以减少历史依赖。研究团队应用 Reinforcement Learning (RL) 激励这一能力，发现高效的 Fold 模式与详尽的 Unfold 模式之间的准确率差距在训练过程中逐渐消失。这表明模型学会了将关键推理信息编码为紧凑的摘要，实现了推理上下文的有效压缩。实验结果显示，Accordion-Thinker 在不损失解题质量的情况下，于 48GB GPU 显存配置下实现了 3 倍的吞吐量提升，同时其结构化的步骤摘要也增强了推理过程的人类可读性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03249v1",
      "published_date": "2026-02-03 08:34:20 UTC",
      "updated_date": "2026-02-03 08:34:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:10.818536+00:00"
    },
    {
      "arxiv_id": "2602.03238v1",
      "title": "The Necessity of a Unified Framework for LLM-Based Agent Evaluation",
      "title_zh": "基于 LLM 的智能体评估统一框架的必要性",
      "authors": [
        "Pengyu Zhu",
        "Li Sun",
        "Philip S. Yu",
        "Sen Su"
      ],
      "abstract": "With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.",
      "tldr_zh": "随着大语言模型(LLMs)的发展，通用智能体取得了显著进步，但其评估面临着与静态QA基准测试不同的独特挑战。该研究指出，当前的智能体基准测试受到系统提示词(system prompts)、工具集配置和环境动态等外部因素的严重干扰。现有的评估通常依赖于碎片化且研究者特定的框架，推理和工具使用的提示工程(prompt engineering)差异巨大，导致难以将性能归功于模型本身。此外，由于缺乏标准化的环境数据，导致错误无法追踪且结果不可复现，为该领域带来了显著的不公平性和不透明性。该研究强调，建立一个统一的评估框架对于推动智能体评估的严谨发展至关重要。为此，作者提出了一项旨在标准化智能体评估的提案，旨在为该领域的严谨进步奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03238v1",
      "published_date": "2026-02-03 08:18:37 UTC",
      "updated_date": "2026-02-03 08:18:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:14.324639+00:00"
    },
    {
      "arxiv_id": "2602.03226v1",
      "title": "ATACompressor: Adaptive Task-Aware Compression for Efficient Long-Context Processing in LLMs",
      "title_zh": "ATACompressor：面向大语言模型高效长上下文处理的自适应任务感知压缩",
      "authors": [
        "Xuancheng Li",
        "Haitao Li",
        "Yujia Zhou",
        "Qingyao Ai",
        "Yiqun Liu"
      ],
      "abstract": "Long-context inputs in large language models (LLMs) often suffer from the \"lost in the middle\" problem, where critical information becomes diluted or ignored due to excessive length. Context compression methods aim to address this by reducing input size, but existing approaches struggle with balancing information preservation and compression efficiency. We propose Adaptive Task-Aware Compressor (ATACompressor), which dynamically adjusts compression based on the specific requirements of the task. ATACompressor employs a selective encoder that compresses only the task-relevant portions of long contexts, ensuring that essential information is preserved while reducing unnecessary content. Its adaptive allocation controller perceives the length of relevant content and adjusts the compression rate accordingly, optimizing resource utilization. We evaluate ATACompressor on three QA datasets: HotpotQA, MSMARCO, and SQUAD-showing that it outperforms existing methods in terms of both compression efficiency and task performance. Our approach provides a scalable solution for long-context processing in LLMs. Furthermore, we perform a range of ablation studies and analysis experiments to gain deeper insights into the key components of ATACompressor.",
      "tldr_zh": "该研究提出了 ATACompressor，这是一种自适应任务感知压缩框架，旨在解决大语言模型（LLMs）在处理长上下文时常遇到的 \"lost in the middle\" 现象。针对现有压缩方法难以平衡信息保留与效率的问题，ATACompressor 通过 selective encoder 仅对任务相关的上下文部分进行压缩，确保关键信息不被稀释。其内置的 adaptive allocation controller 能够感知相关内容的长度并动态调整压缩率，实现了资源利用的最优化。在 HotpotQA、MSMARCO 和 SQUAD 三个问答数据集上的实验评估表明，该方法在压缩效率和任务表现上均超越了现有主流方案。这项工作为 LLMs 的长上下文处理提供了一种高效且可扩展的解决方案，并通过消融实验深入探讨了其核心组件的性能贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03226v1",
      "published_date": "2026-02-03 07:53:29 UTC",
      "updated_date": "2026-02-03 07:53:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:17.623308+00:00"
    },
    {
      "arxiv_id": "2602.03224v1",
      "title": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking",
      "title_zh": "TAME：具备系统性基准测试的可信智能体记忆测试时演化",
      "authors": [
        "Yu Cheng",
        "Jiuan Zhou",
        "Yongkang Hu",
        "Yihang Chen",
        "Huichi Zhou",
        "Mingang Chen",
        "Zhizhong Zhang",
        "Kun Shao",
        "Yuan Xie",
        "Zhaoxia Yin"
      ],
      "abstract": "Test-time evolution of agent memory serves as a pivotal paradigm for achieving AGI by bolstering complex reasoning through experience accumulation. However, even during benign task evolution, agent safety alignment remains vulnerable-a phenomenon known as Agent Memory Misevolution. To evaluate this phenomenon, we construct the Trust-Memevo benchmark to assess multi-dimensional trustworthiness during benign task evolution, revealing an overall decline in trustworthiness across various task domains and evaluation settings. To address this issue, we propose TAME, a dual-memory evolutionary framework that separately evolves executor memory to improve task performance by distilling generalizable methodologies, and evaluator memory to refine assessments of both safety and task utility based on historical feedback. Through a closed loop of memory filtering, draft generation, trustworthy refinement, execution, and dual-track memory updating, TAME preserves trustworthiness without sacrificing utility. Experiments demonstrate that TAME mitigates misevolution, achieving a joint improvement in both trustworthiness and task performance.",
      "tldr_zh": "该研究探讨了智能体内存的测试时演化（Test-time evolution）在实现通用人工智能（AGI）中的重要性，并指出智能体在任务演化中可能面临安全性对齐受损的 Agent Memory Misevolution 现象。为此，作者构建了 Trust-Memevo 基准用以评估多维可信度，发现现有智能体在演化过程中普遍存在可信度下降的问题。针对这一挑战，研究提出了 TAME 双内存演化框架，通过分别演化执行器内存（executor memory）以提升任务性能，以及演化评估器内存（evaluator memory）以细化安全评估。该框架结合内存过滤、可信优化及双轨更新等闭环机制，确保了智能体在经验积累过程中的可信度。实验证明，TAME 能够有效缓解内存演化失当问题，在提升任务性能的同时显著增强了系统的 trustworthiness。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03224v1",
      "published_date": "2026-02-03 07:52:26 UTC",
      "updated_date": "2026-02-03 07:52:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:29.423109+00:00"
    },
    {
      "arxiv_id": "2602.03223v1",
      "title": "Distribution-Aware End-to-End Embedding for Streaming Numerical Features in Click-Through Rate Prediction",
      "title_zh": "点击率预测中流式数值特征的分布感知端到端嵌入",
      "authors": [
        "Jiahao Liu",
        "Hongji Ruan",
        "Weimin Zhang",
        "Ziye Tong",
        "Derick Tang",
        "Zhanpeng Zeng",
        "Qinsong Zeng",
        "Peng Zhang",
        "Tun Lu",
        "Ning Gu"
      ],
      "abstract": "This paper explores effective numerical feature embedding for Click-Through Rate prediction in streaming environments. Conventional static binning methods rely on offline statistics of numerical distributions; however, this inherently two-stage process often triggers semantic drift during bin boundary updates. While neural embedding methods enable end-to-end learning, they often discard explicit distributional information. Integrating such information end-to-end is challenging because streaming features often violate the i.i.d. assumption, precluding unbiased estimation of the population distribution via the expectation of order statistics. Furthermore, the critical context dependency of numerical distributions is often neglected. To this end, we propose DAES, an end-to-end framework designed to tackle numerical feature embedding in streaming training scenarios by integrating distributional information with an adaptive modulation mechanism. Specifically, we introduce an efficient reservoir-sampling-based distribution estimation method and two field-aware distribution modulation strategies to capture streaming distributions and field-dependent semantics. DAES significantly outperforms existing approaches as demonstrated by extensive offline and online experiments and has been fully deployed on a leading short-video platform with hundreds of millions of daily active users.",
      "tldr_zh": "该研究探讨了流式环境下点击率预测(Click-Through Rate prediction)中的数值特征嵌入(numerical feature embedding)问题，旨在解决传统分桶方法在分布变化时产生的语义偏移及神经网络方法对分布信息利用不足的挑战。作者提出了DAES框架，这是一种集成了分布感知与自适应调节机制的端到端学习方案。该框架引入了基于水塘采样(reservoir-sampling-based)的分布估计方法，能够有效捕获流式特征的动态分布，并结合领域感知(field-aware)的调节策略来精准刻画不同特征域的语义信息。实验结果表明，DAES在离线和在线评估中均显著优于现有方法。目前，该系统已在日活过亿的领先短视频平台成功部署，证明了其在大规模实时生产环境中的卓越性能和实用价值。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2602.03223v1",
      "published_date": "2026-02-03 07:50:54 UTC",
      "updated_date": "2026-02-03 07:50:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:32.431582+00:00"
    },
    {
      "arxiv_id": "2602.03219v1",
      "title": "Beyond Quantity: Trajectory Diversity Scaling for Code Agents",
      "title_zh": "超越数量：代码智能体的轨迹多样性缩放",
      "authors": [
        "Guhong Chen",
        "Chenghao Sun",
        "Cheng Fu",
        "Qiyao Wang",
        "Zhihong Huang",
        "Chaopeng Wei",
        "Guangxu Chen",
        "Feiteng Fang",
        "Ahmadreza Argha",
        "Bing Zhao",
        "Xander Xu",
        "Qi Han",
        "Hamid Alinejad-Rokny",
        "Qiang Qu",
        "Binhua Li",
        "Shiwen Ni",
        "Min Yang",
        "Hu Wei",
        "Yongbin Li"
      ],
      "abstract": "As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quantity-centric scaling exhibits an early bottleneck that underutilizes trajectory data. We propose TDScaling, a Trajectory Diversity Scaling-based data synthesis framework for code agents that scales performance through diversity rather than raw volume. Under a fixed training budget, increasing trajectory diversity yields larger gains than adding more trajectories, improving the performance-cost trade-off for agent training. TDScaling integrates four innovations: (1) a Business Cluster mechanism that captures real-service logical dependencies; (2) a blueprint-driven multi-agent paradigm that enforces trajectory coherence; (3) an adaptive evolution mechanism that steers synthesis toward long-tail scenarios using Domain Entropy, Reasoning Mode Entropy, and Cumulative Action Complexity to prevent mode collapse; and (4) a sandboxed code tool that mitigates catastrophic forgetting of intrinsic coding capabilities. Experiments on general tool-use benchmarks (BFCL, tau^2-Bench) and code agent tasks (RebenchT, CodeCI, BIRD) demonstrate a win-win outcome: TDScaling improves both tool-use generalization and inherent coding proficiency. We plan to release the full codebase and the synthesized dataset (including 30,000+ tool clusters) upon publication.",
      "tldr_zh": "该研究针对代码大语言模型（LLMs）作为智能体在 Model Context Protocol (MCP) 环境下，因合成数据质量低和数量缩放（quantity scaling）收益递减而导致的泛化受限问题，提出了 TDScaling 框架。该框架主张通过轨迹多样性（Trajectory Diversity）而非单纯的数据量来驱动性能提升，在固定训练预算下实现了更高的性能成本效率。TDScaling 整合了四大创新：捕捉业务逻辑依赖的 Business Cluster 机制、保障轨迹连贯性的蓝图驱动多智能体范式、利用领域熵（Domain Entropy）与推理模式熵等指标防止模式坍塌的自适应演化机制，以及防止编程能力遗忘的沙箱化代码工具。在 BFCL、tau^2-Bench 及 CodeCI 等多个通用工具使用和代码智能体基准测试上的实验表明，TDScaling 显著提升了工具使用的泛化能力和模型固有的编程水平。该研究证明了多样性缩放在代码智能体训练中的关键作用，为突破合成数据规模瓶颈提供了高效的系统化方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03219v1",
      "published_date": "2026-02-03 07:43:03 UTC",
      "updated_date": "2026-02-03 07:43:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:37.323658+00:00"
    },
    {
      "arxiv_id": "2602.03217v1",
      "title": "Topology Matters: A Cautionary Case Study of Graph SSL on Neuro-Inspired Benchmarks",
      "title_zh": "拓扑的重要性：图自监督学习在类脑启发基准上的警示性案例研究",
      "authors": [
        "May Kristine Jonson Carlon",
        "Su Myat Noe",
        "Haojiong Wang",
        "Yasuo Kuniyoshi"
      ],
      "abstract": "Understanding how local interactions give rise to global brain organization requires models that can represent information across multiple scales. We introduce a hierarchical self-supervised learning (SSL) framework that jointly learns node-, edge-, and graph-level embeddings, inspired by multimodal neuroimaging. We construct a controllable synthetic benchmark mimicking the topological properties of connectomes. Our four-stage evaluation protocol reveals a critical failure: the invariance-based SSL model is fundamentally misaligned with the benchmark's topological properties and is catastrophically outperformed by classical, topology-aware heuristics. Ablations confirm an objective mismatch: SSL objectives designed to be invariant to topological perturbations learn to ignore the very community structure that classical methods exploit. Our results expose a fundamental pitfall in applying generic graph SSL to connectome-like data. We present this framework as a cautionary case study, highlighting the need for new, topology-aware SSL objectives for neuro-AI research that explicitly reward the preservation of structure (e.g., modularity or motifs).",
      "tldr_zh": "该研究探讨了局部交互如何产生全局脑组织，并受多模态神经影像学启发，提出了一个能同时学习节点、边缘和图级别嵌入的层次化自监督学习(Self-supervised learning, SSL)框架。作者构建了一个能够模拟脑连接组(Connectomes)拓扑特性的可控合成基准，并设计了四阶段评估协议。研究发现基于不变性的SSL模型与基准的拓扑特性根本不匹配，其表现显著逊色于经典的拓扑感知启发式方法(Topology-aware heuristics)。消融实验证实了这种目标函数的不匹配，即旨在对拓扑扰动保持不变性的SSL目标会忽略经典方法所利用的社区结构。作为一项警示性案例研究，该成果揭示了将通用图SSL应用于连接组类数据时的根本陷阱。最后，研究强调了在神经AI领域开发新型拓扑感知SSL目标的必要性，建议此类目标应明确奖励对结构(如Modularity或Motifs)的保留。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03217v1",
      "published_date": "2026-02-03 07:35:54 UTC",
      "updated_date": "2026-02-03 07:35:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:37.723405+00:00"
    },
    {
      "arxiv_id": "2602.03215v1",
      "title": "Latent Neural-ODE for Model-Informed Precision Dosing: Overcoming Structural Assumptions in Pharmacokinetics",
      "title_zh": "潜神经常微分方程用于模型引导的精准给药：克服药代动力学中的结构性假设",
      "authors": [
        "Benjamin Maurel",
        "Agathe Guilloux",
        "Sarah Zohar",
        "Moreno Ursino",
        "Jean-Baptiste Woillard"
      ],
      "abstract": "Accurate estimation of tacrolimus exposure, quantified by the area under the concentration-time curve (AUC), is essential for precision dosing after renal transplantation. Current practice relies on population pharmacokinetic (PopPK) models based on nonlinear mixed-effects (NLME) methods. However, these models depend on rigid, pre-specified assumptions and may struggle to capture complex, patient-specific dynamics, leading to model misspecification.\n  In this study, we introduce a novel data-driven alternative based on Latent Ordinary Differential Equations (Latent ODEs) for tacrolimus AUC prediction. This deep learning approach learns individualized pharmacokinetic dynamics directly from sparse clinical data, enabling greater flexibility in modeling complex biological behavior. The model was evaluated through extensive simulations across multiple scenarios and benchmarked against two standard approaches: NLME-based estimation and the iterative two-stage Bayesian (it2B) method. We further performed a rigorous clinical validation using a development dataset (n = 178) and a completely independent external dataset (n = 75).\n  In simulation, the Latent ODE model demonstrated superior robustness, maintaining high accuracy even when underlying biological mechanisms deviated from standard assumptions. Regarding experiments on clinical datasets, in internal validation, it achieved significantly higher precision with a mean RMSPE of 7.99% compared with 9.24% for it2B (p < 0.001). On the external cohort, it achieved an RMSPE of 10.82%, comparable to the two standard estimators (11.48% and 11.54%).\n  These results establish the Latent ODE as a powerful and reliable tool for AUC prediction. Its flexible architecture provides a promising foundation for next-generation, multi-modal models in personalized medicine.",
      "tldr_zh": "该研究针对肾移植后他克莫司（tacrolimus）精准给药中药代动力学（PopPK）模型受限于结构性假设、难以捕捉复杂个体动态的问题，提出了一种基于潜随机微分方程（Latent Ordinary Differential Equations，简称Latent ODEs）的数据驱动新方法。该深度学习方法直接从稀疏临床数据中学习个体化的药代动力学（Pharmacokinetics）动力学特征，在模拟实验中展现出比非线性混合效应模型（NLME）更强的鲁棒性，尤其能有效处理生物机制偏离标准假设的情况。在包含178例样本的内部临床验证中，该模型实现的平均均方根百分比误差（RMSPE）显著优于迭代两阶段贝叶斯法（it2B）。随后在独立外部数据集中进一步验证了其可靠的泛化性能，其预测精度与标准估算器相当。研究结果证实了Latent ODE在曲线下面积（AUC）预测方面的卓越效能，为未来个性化医疗中的多模态精准给药模型提供了灵活的技术框架。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03215v1",
      "published_date": "2026-02-03 07:30:48 UTC",
      "updated_date": "2026-02-03 07:30:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:47.419026+00:00"
    },
    {
      "arxiv_id": "2602.03211v1",
      "title": "Lookahead Sample Reward Guidance for Test-Time Scaling of Diffusion Models",
      "title_zh": "扩散模型测试时扩展的前瞻样本奖励引导",
      "authors": [
        "Yeongmin Kim",
        "Donghyeok Shin",
        "Byeonghu Na",
        "Minsang Park",
        "Richard Lee Kim",
        "Il-Chul Moon"
      ],
      "abstract": "Diffusion models have demonstrated strong generative performance; however, generated samples often fail to fully align with human intent. This paper studies a test-time scaling method that enables sampling from regions with higher human-aligned reward values. Existing gradient guidance methods approximate the expected future reward (EFR) at an intermediate particle $\\mathbf{x}_t$ using a Taylor approximation, but this approximation at each time step incurs high computational cost due to sequential neural backpropagation. We show that the EFR at any $\\mathbf{x}_t$ can be computed using only marginal samples from a pre-trained diffusion model. The proposed EFR formulation detaches the neural dependency between $\\mathbf{x}_t$ and the EFR, enabling closed-form guidance computation without neural backpropagation. To further improve efficiency, we introduce lookahead sampling to collect marginal samples. For final sample generation, we use an accurate solver that guides particles toward high-reward lookahead samples. We refer to this sampling scheme as LiDAR sampling. LiDAR achieves substantial performance improvements using only three samples with a 3-step lookahead solver, exhibiting steep performance gains as lookahead accuracy and sample count increase; notably, it reaches the same GenEval performance as the latest gradient guidance method for SDXL with a 9.5x speedup.",
      "tldr_zh": "该研究提出了 LiDAR sampling，这是一种针对扩散模型(Diffusion Models)在推理阶段进行缩放(Test-Time Scaling)的新方法，旨在提高生成结果与人类意图(human intent)的对齐度。针对传统梯度引导方法在计算期望未来奖励(Expected Future Reward, EFR)时因神经网络反向传播导致计算成本高昂的问题，该研究证明了 EFR 仅通过预训练模型的边缘样本即可计算，从而实现了无需反向传播的闭式解引导。LiDAR 框架通过引入前瞻采样(lookahead sampling)来高效收集边缘样本，并利用精确求解器将生成粒子引导至高奖励的前瞻样本区域。实验结果表明，在 SDXL 模型上，LiDAR 仅需 3 个样本即可在 GenEval 评估中达到与最先进梯度引导方法相当的性能，且推理速度提升了 9.5 倍。这为扩散模型在保证对齐质量的同时实现高效推理提供了重要的方法论支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2602.03211v1",
      "published_date": "2026-02-03 07:27:27 UTC",
      "updated_date": "2026-02-03 07:27:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:43.228532+00:00"
    },
    {
      "arxiv_id": "2602.03200v1",
      "title": "Hand3R: Online 4D Hand-Scene Reconstruction in the Wild",
      "title_zh": "Hand3R：自然场景下的在线4D手部-场景重建",
      "authors": [
        "Wendi Hu",
        "Haonan Zhou",
        "Wenhao Hu",
        "Gaoang Wang"
      ],
      "abstract": "For Embodied AI, jointly reconstructing dynamic hands and the dense scene context is crucial for understanding physical interaction. However, most existing methods recover isolated hands in local coordinates, overlooking the surrounding 3D environment. To address this, we present Hand3R, the first online framework for joint 4D hand-scene reconstruction from monocular video. Hand3R synergizes a pre-trained hand expert with a 4D scene foundation model via a scene-aware visual prompting mechanism. By injecting high-fidelity hand priors into a persistent scene memory, our approach enables simultaneous reconstruction of accurate hand meshes and dense metric-scale scene geometry in a single forward pass. Experiments demonstrate that Hand3R bypasses the reliance on offline optimization and delivers competitive performance in both local hand reconstruction and global positioning.",
      "tldr_zh": "该研究提出了 Hand3R，这是首个从单目视频(monocular video)中实现联合 4D 手部-场景重建(joint 4D hand-scene reconstruction)的在线框架，旨在为具身智能(Embodied AI)提供对物理交互的深入理解。针对现有方法仅在局部坐标系重建孤立手部而忽视周围 3D 环境的局限，Hand3R 通过场景感知视觉提示(scene-aware visual prompting)机制，将预训练的手部专家模型与 4D 场景基础模型(4D scene foundation model)有机结合。该框架通过向持久场景记忆注入高保真手部先验，实现了在单次前向传播中同时生成精确的手部网格(hand meshes)与稠密的度量尺度场景几何。实验证明，Hand3R 无需依赖离线优化即可在局部手部重建和全局定位任务中取得极具竞争力的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03200v1",
      "published_date": "2026-02-03 07:13:01 UTC",
      "updated_date": "2026-02-03 07:13:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:48.510524+00:00"
    },
    {
      "arxiv_id": "2602.03195v1",
      "title": "Reinforcement Learning with Promising Tokens for Large Language Models",
      "title_zh": "基于潜力 Token 的大语言模型强化学习",
      "authors": [
        "Jing-Cheng Pang",
        "Liang Lu",
        "Xian Tang",
        "Kun Jiang",
        "Sijie Wu",
        "Kai Zhang",
        "Xubin Li"
      ],
      "abstract": "Reinforcement learning (RL) has emerged as a key paradigm for aligning and optimizing large language models (LLMs). Standard approaches treat the LLM as the policy and apply RL directly over the full vocabulary space. However, this formulation includes the massive tail of contextually irrelevant tokens in the action space, which could distract the policy from focusing on decision-making among the truly reasonable tokens. In this work, we verify that valid reasoning paths could inherently concentrate within a low-rank subspace. Based on this insight, we introduce Reinforcement Learning with Promising Tokens (RLPT), a framework that mitigates the action space issue by decoupling strategic decision-making from token generation. Specifically, RLPT leverages the semantic priors of the base model to identify a dynamic set of \\emph{promising tokens} and constrains policy optimization exclusively to this refined subset via masking. Theoretical analysis and empirical results demonstrate that RLPT effectively reduces gradient variance, stabilizes the training process, and improves sample efficiency. Experiment results on math, coding, and telecom reasoning show that RLPT outperforms standard RL baselines and integrates effectively across various model sizes (4B and 8B) and RL algorithms (GRPO and DAPO).",
      "tldr_zh": "该研究针对大语言模型(LLMs)在强化学习(RL)过程中动作空间过大、包含大量无关Token导致策略难以聚焦的问题，提出了Reinforcement Learning with Promising Tokens (RLPT)框架。RLPT基于有效推理路径集中在低秩子空间(low-rank subspace)的观察，通过将战略决策与Token生成解耦，利用基础模型的语义先验识别出一组动态的Promising Tokens。该框架通过掩码(masking)技术将策略优化限制在这一精简子集内，从而有效降低了梯度方差(gradient variance)，并显著提升了训练稳定性和样本效率(sample efficiency)。实验结果显示，RLPT在数学、代码和电信推理任务上均优于标准RL基线模型。此外，该方法在不同模型规模（4B和8B）以及GRPO和DAPO等多种RL算法中均表现出良好的兼容性与优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03195v1",
      "published_date": "2026-02-03 07:08:06 UTC",
      "updated_date": "2026-02-03 07:08:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:54.416884+00:00"
    },
    {
      "arxiv_id": "2602.03190v1",
      "title": "Prompt Augmentation Scales up GRPO Training on Mathematical Reasoning",
      "title_zh": "提示增强助力数学推理中的 GRPO 规模化训练",
      "authors": [
        "Wenquan Lu",
        "Hai Huang",
        "Randall Balestriero"
      ],
      "abstract": "Reinforcement learning algorithms such as group-relative policy optimization (GRPO) have demonstrated strong potential for improving the mathematical reasoning capabilities of large language models. However, prior work has consistently observed an entropy collapse phenomenon during reinforcement post-training, characterized by a monotonic decrease in policy entropy that ultimately leads to training instability and collapse. As a result, most existing approaches restrict training to short horizons (typically 5-20 epochs), limiting sustained exploration and hindering further policy improvement. In addition, nearly all prior work relies on a single, fixed reasoning prompt or template during training. In this work, we introduce prompt augmentation, a training strategy that instructs the model to generate reasoning traces under diverse templates and formats, thereby increasing rollout diversity. We show that, without a KL regularization term, prompt augmentation enables stable scaling of training duration under a fixed dataset and allows the model to tolerate low-entropy regimes without premature collapse. Empirically, a Qwen2.5-Math-1.5B model trained with prompt augmentation on the MATH Level 3-5 dataset achieves state-of-the-art performance, reaching 44.5 per-benchmark accuracy and 51.3 per-question accuracy on standard mathematical reasoning benchmarks, including AIME24, AMC, MATH500, Minerva, and OlympiadBench. The code and model checkpoints are available at https://github.com/wenquanlu/prompt-augmentation-GRPO.",
      "tldr_zh": "该研究针对大型语言模型在数学推理强化学习过程中普遍存在的熵崩溃 (entropy collapse) 现象提出了改进方案，旨在解决 group-relative policy optimization (GRPO) 训练不稳定和难以持续优化的问题。作者引入了提示词增强 (prompt augmentation) 策略，通过指导模型在多样化的模板和格式下生成推理轨迹，从而显著提升了采样过程中的多样性 (rollout diversity)。实验证明，即使在没有 KL 正则化项的情况下，该方法也能支持模型在固定数据集上进行更长周期的稳定训练，使其能够耐受低熵状态而不会过早发生训练崩溃。采用该策略训练的 Qwen2.5-Math-1.5B 模型在 AIME24、AMC 和 MATH500 等标准数学推理基准测试中取得了 SOTA 性能，单题准确率达到 51.3%。该研究证明了增加提示词多样性可以有效扩展强化学习的训练规模，为进一步提升模型的数学逻辑推理能力提供了新的技术路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03190v1",
      "published_date": "2026-02-03 06:59:42 UTC",
      "updated_date": "2026-02-03 06:59:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:58.624522+00:00"
    },
    {
      "arxiv_id": "2602.03183v1",
      "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch",
      "title_zh": "Privasis：从零开始合成最大规模的“公开”隐私数据集",
      "authors": [
        "Hyunwoo Kim",
        "Niloofar Mireshghallah",
        "Michael Duan",
        "Rui Xin",
        "Shuyue Stella Li",
        "Jaehun Jung",
        "David Acuna",
        "Qi Pang",
        "Hanshen Xiao",
        "G. Edward Suh",
        "Sewoong Oh",
        "Yulia Tsvetkov",
        "Pang Wei Koh",
        "Yejin Choi"
      ],
      "abstract": "Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models, such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.",
      "tldr_zh": "该研究提出了 Privasis，这是首个从零开始构建的百万级全合成隐私数据集，旨在解决隐私敏感数据稀缺对 AI Agents 研究的长期限制。该数据集包含 140 万条记录，涵盖医疗记录、法律文件、财务记录、日历和短信等多种文档类型，并标注了 5510 万个如 ethnicity、date of birth 和 workplace 等敏感属性。研究团队利用 Privasis 构建了一个用于 text sanitization（文本脱敏）的平行语料库，并设计了分解文本并进行针对性脱敏的处理管线。实验结果表明，在该数据集上训练的小型脱敏模型（≤4B）在性能上超越了 GPT-5 和 Qwen-3 235B 等最先进的大型语言模型。该项工作通过提供大规模、高质量且多样化的合成数据，为隐私敏感领域及可信 AI 智能体的开发奠定了重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "For code and data, see https://privasis.github.io",
      "pdf_url": "https://arxiv.org/pdf/2602.03183v1",
      "published_date": "2026-02-03 06:54:46 UTC",
      "updated_date": "2026-02-03 06:54:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:45:57.127881+00:00"
    },
    {
      "arxiv_id": "2602.03164v1",
      "title": "MemCast: Memory-Driven Time Series Forecasting with Experience-Conditioned Reasoning",
      "title_zh": "MemCast：基于经验条件推理的记忆驱动时间序列预测",
      "authors": [
        "Xiaoyu Tao",
        "Mingyue Cheng",
        "Ze Guo",
        "Shuo Yu",
        "Yaguo Liu",
        "Qi Liu",
        "Shijin Wang"
      ],
      "abstract": "Time series forecasting (TSF) plays a critical role in decision-making for many real-world applications. Recently, LLM-based forecasters have made promising advancements. Despite their effectiveness, existing methods often lack explicit experience accumulation and continual evolution. In this work, we propose MemCast, a learning-to-memory framework that reformulates TSF as an experience-conditioned reasoning task. Specifically, we learn experience from the training set and organize it into a hierarchical memory. This is achieved by summarizing prediction results into historical patterns, distilling inference trajectories into reasoning wisdom, and inducing extracted temporal features into general laws. Furthermore, during inference, we leverage historical patterns to guide the reasoning process and utilize reasoning wisdom to select better trajectories, while general laws serve as criteria for reflective iteration. Additionally, to enable continual evolution, we design a dynamic confidence adaptation strategy that updates the confidence of individual entries without leaking the test set distribution. Extensive experiments on multiple datasets demonstrate that MemCast consistently outperforms previous methods, validating the effectiveness of our approach. Our code is available at https://github.com/Xiaoyu-Tao/MemCast-TS.",
      "tldr_zh": "该研究提出了 MemCast，这是一种旨在解决 LLM-based forecasters 缺乏经验积累和持续演进问题的学习记忆框架 (learning-to-memory framework)。MemCast 将时间序列预测 (Time Series Forecasting, TSF) 重新定义为一种经验条件推理任务，通过从训练集中提取经验并将其组织成层次化存储。该系统通过总结历史模式 (historical patterns) 引导推理，提炼推理智慧 (reasoning wisdom) 以优化预测轨迹，并归纳一般法则 (general laws) 作为反思迭代的准则。为了实现持续演进，研究还设计了动态置信度自适应策略 (dynamic confidence adaptation strategy)，在不接触测试集分布的前提下更新记忆条目。多项数据集上的实验表明，MemCast 的预测性能一致优于现有方法，充分验证了这种经验驱动推理框架的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03164v1",
      "published_date": "2026-02-03 06:31:40 UTC",
      "updated_date": "2026-02-03 06:31:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:10.420757+00:00"
    },
    {
      "arxiv_id": "2602.03160v1",
      "title": "VALUEFLOW: Toward Pluralistic and Steerable Value-based Alignment in Large Language Models",
      "title_zh": "VALUEFLOW：面向大语言模型多元化与可控的基于价值的对齐",
      "authors": [
        "Woojin Kim",
        "Sieun Hyeon",
        "Jusang Oh",
        "Jaeyoung Do"
      ],
      "abstract": "Aligning Large Language Models (LLMs) with the diverse spectrum of human values remains a central challenge: preference-based methods often fail to capture deeper motivational principles. Value-based approaches offer a more principled path, yet three gaps persist: extraction often ignores hierarchical structure, evaluation detects presence but not calibrated intensity, and the steerability of LLMs at controlled intensities remains insufficiently understood. To address these limitations, we introduce VALUEFLOW, the first unified framework that spans extraction, evaluation, and steering with calibrated intensity control. The framework integrates three components: (i) HIVES, a hierarchical value embedding space that captures intra- and cross-theory value structure; (ii) the Value Intensity DataBase (VIDB), a large-scale resource of value-labeled texts with intensity estimates derived from ranking-based aggregation; and (iii) an anchor-based evaluator that produces consistent intensity scores for model outputs by ranking them against VIDB panels. Using VALUEFLOW, we conduct a comprehensive large-scale study across ten models and four value theories, identifying asymmetries in steerability and composition laws for multi-value control. This paper establishes a scalable infrastructure for evaluating and controlling value intensity, advancing pluralistic alignment of LLMs.",
      "tldr_zh": "该研究提出了 VALUEFLOW，这是一个旨在解决大语言模型 (LLMs) 在多元价值观对齐中面临的层次结构缺失、强度校准不足和可控性差等问题的统一框架。该框架整合了捕捉跨理论价值结构的层次化价值嵌入空间 HIVES，以及包含大规模价值标注与强度估计的数据库 VIDB。此外，研究还引入了基于锚点的评估器，通过将模型输出与 VIDB 面板进行排序对比来生成一致的强度评分。利用 VALUEFLOW，研究者对 10 个模型和 4 种价值理论进行了大规模实验，识别出模型在 steerability 上的不对称性以及多价值控制的组合规律。该成果为评估和控制 LLMs 的价值强度建立了可扩展的基础设施，有效推进了 pluralistic alignment 的发展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03160v1",
      "published_date": "2026-02-03 06:19:57 UTC",
      "updated_date": "2026-02-03 06:19:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:22.228419+00:00"
    },
    {
      "arxiv_id": "2602.03154v1",
      "title": "Intelligent Front-End Personalization: AI-Driven UI Adaptation",
      "title_zh": "智能前端个性化：AI 驱动的 UI 自适应",
      "authors": [
        "Mona Rajhans"
      ],
      "abstract": "Front-end personalization has traditionally relied on static designs or rule-based adaptations, which fail to fully capture user behavior patterns. This paper presents an AI driven approach for dynamic front-end personalization, where UI layouts, content, and features adapt in real-time based on predicted user behavior. We propose three strategies: dynamic layout adaptation using user path prediction, content prioritization through reinforcement learning, and a comparative analysis of AI-driven vs. rule-based personalization. Technical implementation details, algorithms, system architecture, and evaluation methods are provided to illustrate feasibility and performance gains.",
      "tldr_zh": "该研究提出了一种 AI-driven 的动态前端个性化方法，旨在解决传统静态设计或 rule-based 适配难以捕捉用户行为模式的问题。该方法通过预测用户行为，实现 UI 布局、内容和功能的实时动态调整。具体策略包括利用 user path prediction 进行动态布局适配，以及通过 reinforcement learning 实现内容优先级排序。论文还对比分析了 AI-driven 与 rule-based 个性化方案的差异。通过对技术实现细节、算法及系统架构的深入探讨，实验评估验证了该方法在提升前端交互体验方面的可行性与显著性能增益。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "To be published in proceedings of IEEE ACDSA 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03154v1",
      "published_date": "2026-02-03 06:10:10 UTC",
      "updated_date": "2026-02-03 06:10:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:14.320523+00:00"
    },
    {
      "arxiv_id": "2602.03151v1",
      "title": "Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration",
      "title_zh": "提升基础 VLM 对模态缺失的鲁棒性：用于双向特征修复的可扩展扩散模型",
      "authors": [
        "Wei Dai",
        "Haoyu Wang",
        "Honghao Chang",
        "Lijun He",
        "Fan Li",
        "Jian Sun",
        "Haixia Bi"
      ],
      "abstract": "Vision Language Models (VLMs) typically assume complete modality input during inference. However, their effectiveness drops sharply when certain modalities are unavailable or incomplete. Current research primarily faces two dilemmas: Prompt-based methods struggle to restore missing yet indispensable features and impair generalization of VLMs. Imputation-based approaches, lacking effective guidance, are prone to generating semantically irrelevant noise. Restoring precise semantics while sustaining VLM generalization remains challenging. Therefore, we propose a general missing modality restoration strategy in this paper. We introduce an enhanced diffusion model as a pluggable mid-stage training module to effectively restore missing features. Our strategy introduces two key innovations: (I) Dynamic Modality Gating, which adaptively leverages conditional features to steer the generation of semantically consistent features; (II) Cross-Modal Mutual Learning mechanism, which bridges the semantic spaces of dual encoders to achieve bidirectional alignment. Zero-shot evaluations across benchmark datasets demonstrate that our approach outperforms existing baseline methods. Extensive experiments and ablation studies confirm our model as a robust and scalable extension for VLMs in missing modality scenarios, ensuring reliability across diverse missing rates and environments. Our code and models will be publicly available.",
      "tldr_zh": "该研究针对视觉语言模型(Vision Language Models, VLMs)在推理过程中因模态缺失导致性能骤降的问题，提出了一种通用的缺失模态恢复策略。作者引入了一个增强的扩散模型(Diffusion Model)作为可插拔的中期训练模块，旨在有效地恢复缺失特征并保持模型的泛化能力。该策略提出了动态模态门控(Dynamic Modality Gating)以引导语义一致特征的生成，并结合跨模态互学习(Cross-Modal Mutual Learning)机制来实现双编码器语义空间的双向对齐。在多个基准数据集上的零样本(Zero-shot)评估表明，该方法在性能上显著优于现有基准模型。广泛的实验和消融研究证实，该模型为处理缺失模态场景提供了一种鲁棒且可扩展的扩展方案，在不同缺失率和环境下均表现出极高的可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.03151v1",
      "published_date": "2026-02-03 06:06:35 UTC",
      "updated_date": "2026-02-03 06:06:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:20.928782+00:00"
    },
    {
      "arxiv_id": "2602.03146v1",
      "title": "General Agents Contain World Models, even under Partial Observability and Stochasticity",
      "title_zh": "通用智能体包含世界模型，即便在部分可观测性与随机性情形下",
      "authors": [
        "Santiago Cifuentes"
      ],
      "abstract": "Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necessarily contains sufficient knowledge of its environment to allow an approximate reconstruction of it by querying the agent as a black box. This result relied on the assumptions that the agent is deterministic and that the environment is fully observable.\n  In this work, we remove both assumptions by extending the theorem to stochastic agents operating in partially observable environments. Fundamentally, this shows that stochastic agents cannot avoid learning their environment through the usage of randomization. We also strengthen the result by weakening the notion of generality, proving that less powerful agents already contain a model of the world in which they operate.",
      "tldr_zh": "该研究深入探讨了General Agents是否必然包含其周围World Models这一核心命题。通过扩展先前的理论框架，作者证明了即使在Partial Observability和Stochasticity的复杂条件下，几乎最优的智能体也必须掌握足够的环境知识。研究指出，Stochastic agents无法通过Randomization的使用来避免对环境的学习，从而确立了环境表征的必要性。此外，论文通过弱化Generality的定义增强了结论，证明了即使是不那么强大的智能体也同样拥有其操作环境的模型。这一成果为理解智能体的认知局限及其能力本质提供了坚实的理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03146v1",
      "published_date": "2026-02-03 06:00:41 UTC",
      "updated_date": "2026-02-03 06:00:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:21.543502+00:00"
    },
    {
      "arxiv_id": "2602.03145v1",
      "title": "Internet of Agentic AI: Incentive-Compatible Distributed Teaming and Workflow",
      "title_zh": "Internet of Agentic AI：激励相容的分布式协同组网与工作流",
      "authors": [
        "Ya-Ting Yang",
        "Quanyan Zhu"
      ],
      "abstract": "Large language models (LLMs) have enabled a new class of agentic AI systems that reason, plan, and act by invoking external tools. However, most existing agentic architectures remain centralized and monolithic, limiting scalability, specialization, and interoperability. This paper proposes a framework for scalable agentic intelligence, termed the Internet of Agentic AI, in which autonomous, heterogeneous agents distributed across cloud and edge infrastructure dynamically form coalitions to execute task-driven workflows. We formalize a network-native model of agentic collaboration and introduce an incentive-compatible workflow-coalition feasibility framework that integrates capability coverage, network locality, and economic implementability. To enable scalable coordination, we formulate a minimum-effort coalition selection problem and propose a decentralized coalition formation algorithm. The proposed framework can operate as a coordination layer above the Model Context Protocol (MCP). A healthcare case study demonstrates how domain specialization, cloud-edge heterogeneity, and dynamic coalition formation enable scalable, resilient, and economically viable agentic workflows. This work lays the foundation for principled coordination and scalability in the emerging era of Internet of Agentic AI.",
      "tldr_zh": "该研究提出了“智能体互联网”(Internet of Agentic AI)框架，旨在解决当前大型语言模型(LLMs)智能体系统在中心化和单体架构下面临的扩展性与互操作性难题。研究形式化了一个网络原生的智能体协作模型，并引入了集成了能力覆盖(capability coverage)、网络局部性(network locality)和经济可实现性(economic implementability)的激励相容工作流-联盟可行性框架。通过定义最小努力联盟选择问题并提出去中心化联盟形成算法，该框架能够在Model Context Protocol (MCP)之上实现高效的大规模协调。医疗保健领域的案例研究证明了领域专业化、云边异构性和动态联盟形成在构建可扩展、高韧性且经济可行的智能体工作流中的有效性。该工作为新兴的智能体互联网时代提供了原则性协调与扩展的基础方案。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03145v1",
      "published_date": "2026-02-03 06:00:34 UTC",
      "updated_date": "2026-02-03 06:00:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:25.232874+00:00"
    },
    {
      "arxiv_id": "2602.03143v1",
      "title": "Self-Hinting Language Models Enhance Reinforcement Learning",
      "title_zh": "自提示语言模型增强强化学习",
      "authors": [
        "Baohao Liao",
        "Hanze Dong",
        "Xinxing Xu",
        "Christof Monz",
        "Jiang Bian"
      ],
      "abstract": "Group Relative Policy Optimization (GRPO) has recently emerged as a practical recipe for aligning large language models with verifiable objectives. However, under sparse terminal rewards, GRPO often stalls because rollouts within a group frequently receive identical rewards, causing relative advantages to collapse and updates to vanish. We propose self-hint aligned GRPO with privileged supervision (SAGE), an on-policy reinforcement learning framework that injects privileged hints during training to reshape the rollout distribution under the same terminal verifier reward. For each prompt $x$, the model samples a compact hint $h$ (e.g., a plan or decomposition) and then generates a solution $τ$ conditioned on $(x,h)$. Crucially, the task reward $R(x,τ)$ is unchanged; hints only increase within-group outcome diversity under finite sampling, preventing GRPO advantages from collapsing under sparse rewards. At test time, we set $h=\\varnothing$ and deploy the no-hint policy without any privileged information. Moreover, sampling diverse self-hints serves as an adaptive curriculum that tracks the learner's bottlenecks more effectively than fixed hints from an initial policy or a stronger external model. Experiments over 6 benchmarks with 3 LLMs show that SAGE consistently outperforms GRPO, on average +2.0 on Llama-3.2-3B-Instruct, +1.2 on Qwen2.5-7B-Instruct and +1.3 on Qwen3-4B-Instruct. The code is available at https://github.com/BaohaoLiao/SAGE.",
      "tldr_zh": "该研究针对Group Relative Policy Optimization (GRPO) 在稀疏终端奖励下容易因组内样本奖励相同导致优势坍缩(advantage collapse)的问题，提出了SAGE (Self-hint aligned GRPO with privileged supervision) 强化学习框架。SAGE 在训练阶段通过为每个提示注入特权提示(privileged hints)，如任务计划或分解，以重塑相同验证器奖励下的采样分布。该方法在不改变任务奖励$R(x,τ)$的前提下，通过增加组内输出的多样性，有效防止了训练更新消失。在测试阶段，模型将提示设为空值，直接部署不依赖特权信息的原始策略。研究发现，这种自启发采样机制能作为自适应课程，比来自外部模型或初始策略的固定提示更有效地识别学习瓶颈。实验在3个大语言模型和6项基准测试上证明，SAGE 在Llama-3.2-3B-Instruct、Qwen2.5-7B-Instruct和Qwen3-4B-Instruct上分别实现了2.0、1.2和1.3的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03143v1",
      "published_date": "2026-02-03 05:56:20 UTC",
      "updated_date": "2026-02-03 05:56:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:27.116056+00:00"
    },
    {
      "arxiv_id": "2602.03134v1",
      "title": "SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass",
      "title_zh": "SwiftVLM：基于跨层 Token 旁路的高效视觉语言模型推理",
      "authors": [
        "Chen Qian",
        "Xinran Yu",
        "Danyang Li",
        "Guoxuan Chi",
        "Zheng Yang",
        "Qiang Ma",
        "Xin Miao"
      ],
      "abstract": "Visual token pruning is a promising approach for reducing the computational cost of vision-language models (VLMs), and existing methods often rely on early pruning decisions to improve efficiency. While effective on coarse-grained reasoning tasks, they suffer from significant performance degradation on tasks requiring fine-grained visual details. Through layer-wise analysis, we reveal substantial discrepancies in visual token importance across layers, showing that tokens deemed unimportant at shallow layers can later become highly relevant for text-conditioned reasoning. To avoid irreversible critical information loss caused by premature pruning, we introduce a new pruning paradigm, termed bypass, which preserves unselected visual tokens and forwards them to subsequent pruning stages for re-evaluation. Building on this paradigm, we propose SwiftVLM, a simple and training-free method that performs pruning at model-specific layers with strong visual token selection capability, while enabling independent pruning decisions across layers. Experiments across multiple VLMs and benchmarks demonstrate that SwiftVLM consistently outperforms existing pruning strategies, achieving superior accuracy-efficiency trade-offs and more faithful visual token selection behavior.",
      "tldr_zh": "该研究提出了SwiftVLM，一种无需训练的视觉语言模型(VLMs)高效推理方法，旨在通过跨层Token旁路(Cross-Layer Token Bypass)机制解决视觉Token修剪(Visual token pruning)导致的性能退化问题。作者通过层级分析发现，视觉Token在不同层的重要性存在显著差异，早期被判定为不重要的Token在后续文本条件推理中可能变得至关重要。为了避免过早修剪造成不可逆的关键信息丢失，SwiftVLM引入了旁路(bypass)范式，将未选中的视觉Token保留并转发至后续层进行重新评估。该方法在模型特定的关键层执行独立的修剪决策，确保了更忠实的Token选择行为。实验证明，SwiftVLM在多个基准测试中均优于现有策略，在保持高准确率的同时实现了卓越的准确率与效率权衡(accuracy-efficiency trade-offs)。该研究为细粒度推理任务下的视觉语言模型加速提供了全新的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03134v1",
      "published_date": "2026-02-03 05:42:51 UTC",
      "updated_date": "2026-02-03 05:42:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:40.708736+00:00"
    },
    {
      "arxiv_id": "2602.03132v1",
      "title": "Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery",
      "title_zh": "面向 LLM 辅助算法发现的对比概念树搜索",
      "authors": [
        "Timothee Leleu",
        "Sudeera Gunathilaka",
        "Federico Ghimenti",
        "Surya Ganguli"
      ],
      "abstract": "Large language Model (LLM)-assisted algorithm discovery is an iterative, black-box optimization process over programs to approximatively solve a target task, where an LLM proposes candidate programs and an external evaluator provides task feedback. Despite intense recent research on the topic and promising results, how can the LLM internal representation of the space of possible programs be maximally exploited to improve performance is an open question. Here, we introduce Contrastive Concept-Tree Search (CCTS), which extracts a hierarchical concept representation from the generated programs and learns a contrastive concept model that guides parent selection. By reweighting parents using a likelihood-ratio score between high- and low-performing solutions, CCTS biases search toward useful concept combinations and away from misleading ones, providing guidance through an explicit concept hierarchy rather than the algorithm lineage constructed by the LLM. We show that CCTS improves search efficiency over fitness-based baselines and produces interpretable, task-specific concept trees across a benchmark of open Erdős-type combinatorics problems. Our analysis indicates that the gains are driven largely by learning which concepts to avoid. We further validate these findings in a controlled synthetic algorithm-discovery environment, which reproduces qualitatively the search dynamics observed with the LLMs.",
      "tldr_zh": "该研究提出了 Contrastive Concept-Tree Search (CCTS)，旨在优化大语言模型 (LLM) 辅助的算法发现过程。针对 LLM 在程序空间表示利用不足的问题，CCTS 从生成的程序中提取层次化概念表示，并构建对比概念模型来引导父节点选择。该方法通过计算高性能和低性能解决方案之间的似然比得分 (likelihood-ratio score)，引导搜索转向有用的概念组合并避开误导性概念，而非仅仅依赖 LLM 构建的算法谱系。在 Erdős 型组合数学问题的基准测试中，CCTS 的搜索效率显著优于基于适应度 (fitness-based) 的基线模型，并生成了具有可解释性的任务特定概念树。分析表明，其性能提升主要源于成功学习了哪些概念应当被避免，这一发现在受控合成环境中得到了进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03132v1",
      "published_date": "2026-02-03 05:41:35 UTC",
      "updated_date": "2026-02-03 05:41:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:41.308706+00:00"
    },
    {
      "arxiv_id": "2602.03128v1",
      "title": "Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis",
      "title_zh": "深入理解多智能体大语言模型框架：统一基准与实验分析",
      "authors": [
        "Abdelghny Orogat",
        "Ana Rostam",
        "Essam Mansour"
      ],
      "abstract": "Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finally, we translate our findings into concrete architectural design principles and framework selection guidance, and outline promising future research directions.",
      "tldr_zh": "该研究针对多智能体大语言模型框架 (Multi-agent LLM frameworks) 架构设计对性能影响尚不明确的问题，提出了一套系统的评估方案。作者首先定义了一个架构分类法 (Architectural taxonomy)，用于在基础维度上系统对比不同框架的特征。随后开发了统一评估套件 MAFBench，通过标准化的执行流水线在受控环境下隔离并分析架构效应。实验结果显示，不同的框架设计会导致延迟产生超过 100 倍的差异，并使规划准确率下降 30%，协调成功率从 90% 以上降至 30% 以下。该工作最终提炼出了具体的架构设计原则和框架选择指南，为构建高效、可靠的多智能体系统提供了实验支撑和理论依据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 9 figures and 13 tables; introduces MAFBench unified multi-agent evaluation suite",
      "pdf_url": "https://arxiv.org/pdf/2602.03128v1",
      "published_date": "2026-02-03 05:37:56 UTC",
      "updated_date": "2026-02-03 05:37:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:42.522877+00:00"
    },
    {
      "arxiv_id": "2602.03123v1",
      "title": "Beyond Cropping and Rotation: Automated Evolution of Powerful Task-Specific Augmentations with Generative Models",
      "title_zh": "超越裁剪与旋转：基于生成模型的任务特定强力数据增强自动化演化",
      "authors": [
        "Judah Goldfeder",
        "Shreyes Kaliyur",
        "Vaibhav Sourirajan",
        "Patrick Minwan Puma",
        "Philippe Martin Wyder",
        "Yuhang Hu",
        "Jiong Lin",
        "Hod Lipson"
      ],
      "abstract": "Data augmentation has long been a cornerstone for reducing overfitting in vision models, with methods like AutoAugment automating the design of task-specific augmentations. Recent advances in generative models, such as conditional diffusion and few-shot NeRFs, offer a new paradigm for data augmentation by synthesizing data with significantly greater diversity and realism. However, unlike traditional augmentations like cropping or rotation, these methods introduce substantial changes that enhance robustness but also risk degrading performance if the augmentations are poorly matched to the task. In this work, we present EvoAug, an automated augmentation learning pipeline, which leverages these generative models alongside an efficient evolutionary algorithm to learn optimal task-specific augmentations. Our pipeline introduces a novel approach to image augmentation that learns stochastic augmentation trees that hierarchically compose augmentations, enabling more structured and adaptive transformations. We demonstrate strong performance across fine-grained classification and few-shot learning tasks. Notably, our pipeline discovers augmentations that align with domain knowledge, even in low-data settings. These results highlight the potential of learned generative augmentations, unlocking new possibilities for robust model training.",
      "tldr_zh": "该研究提出了EvoAug，一种自动化的数据增强(Data augmentation)学习流水线，旨在克服传统裁剪或旋转等增强手段在多样性与真实感上的局限。该框架利用条件扩散模型(conditional diffusion)和少样本NeRFs等生成式模型合成数据，并结合高效的进化算法(evolutionary algorithm)来学习最优的任务特定增强策略。研究创新性地引入了随机增强树(stochastic augmentation trees)来层次化地组合增强操作，实现了更具结构化和自适应性的图像变换，有效降低了生成式增强与任务不匹配的风险。实验证明，EvoAug在细粒度分类(fine-grained classification)和少样本学习(few-shot learning)任务中表现优异，能够自动发现符合领域知识的增强模式。该成果展示了学习型生成式增强在提升模型鲁棒性方面的巨大潜力，为稳健的模型训练开辟了新的技术路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03123v1",
      "published_date": "2026-02-03 05:29:26 UTC",
      "updated_date": "2026-02-03 05:29:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:53.736625+00:00"
    },
    {
      "arxiv_id": "2602.03120v1",
      "title": "Quantized Evolution Strategies: High-precision Fine-tuning of Quantized LLMs at Low-precision Cost",
      "title_zh": "量化进化策略：以低精度成本实现量化大语言模型的高精度微调",
      "authors": [
        "Yinggan Xu",
        "Risto Miikkulainen",
        "Xin Qiu"
      ],
      "abstract": "Post-Training Quantization (PTQ) is essential for deploying Large Language Models (LLMs) on memory-constrained devices, yet it renders models static and difficult to fine-tune. Standard fine-tuning paradigms, including Reinforcement Learning (RL), fundamentally rely on backpropagation and high-precision weights to compute gradients. Thus they cannot be used on quantized models, where the parameter space is discrete and non-differentiable. While Evolution Strategies (ES) offer a backpropagation-free alternative, optimization of the quantized parameters can still fail due to vanishing or inaccurate gradient. This paper introduces Quantized Evolution Strategies (QES), an optimization paradigm that performs full-parameter fine-tuning directly in the quantized space. QES is based on two innovations: (1) it integrates accumulated error feedback to preserve high-precision gradient signals, and (2) it utilizes a stateless seed replay to reduce memory usage to low-precision inference levels. QES significantly outperforms the state-of-the-art zeroth-order fine-tuning method on arithmetic reasoning tasks, making direct fine-tuning for quantized models possible. It therefore opens up the possibility for scaling up LLMs entirely in the quantized space. The source code is available at https://github.com/dibbla/Quantized-Evolution-Strategies .",
      "tldr_zh": "该研究提出了Quantized Evolution Strategies (QES)，这是一种直接在量化空间进行全参数微调的优化范式，旨在解决Large Language Models (LLMs) 在训练后量化 (Post-Training Quantization, PTQ) 后因参数空间离散且不可微而难以微调的挑战。传统的微调范式和Reinforcement Learning (RL) 严重依赖backpropagation，而QES通过集成累积误差反馈(accumulated error feedback)来保留高精度的梯度信号，克服了演化策略在量化优化中的梯度失效问题。此外，QES利用无状态种子重放(stateless seed replay)技术，将内存消耗降低至低精度推理水平，实现了低成本的高效优化。实验结果表明，QES在算术推理任务上显著优于最先进的zeroth-order微调方法。该研究证明了直接对量化模型进行高精度微调的可行性，为完全在量化空间内扩展LLMs规模开辟了新的可能性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint version",
      "pdf_url": "https://arxiv.org/pdf/2602.03120v1",
      "published_date": "2026-02-03 05:24:31 UTC",
      "updated_date": "2026-02-03 05:24:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:57.322027+00:00"
    },
    {
      "arxiv_id": "2602.03114v1",
      "title": "Digital Lifelong Learning in the Age of AI: Trends and Insights",
      "title_zh": "人工智能时代的数字终身学习：趋势与洞察",
      "authors": [
        "Geeta Puri",
        "Nachamma Socklingam",
        "Dorien Herremans"
      ],
      "abstract": "Rapid innovations in AI and large language models (LLMs) have accelerated the adoption of digital learning, particularly beyond formal education. What began as an emergency response during COVID-19 has shifted from a supplementary resource to an essential pillar of education. Understanding how digital learning continues to evolve for adult and lifelong learners is therefore increasingly important.\n  This study examines how various demographics interact with digital learning platforms, focusing on the learner motivations, the effectiveness of gamification in digital learning, and the integration of AI. Using multi survey data from 200 respondents and advanced analytics, our findings reveal a notable increase in the perceived relevance of digital learning after the pandemic, especially among young adults and women, coinciding with the rise of LLM-powered AI tools that support personalized learning. We aim to provide actionable insights for businesses, government policymakers, and educators seeking to optimize their digital learning offerings to meet evolving workforce needs.",
      "tldr_zh": "该研究探讨了在AI和大型语言模型(LLMs)快速创新的背景下，数字学习(Digital Learning)如何从疫情期间的应急手段演变为终身学习的核心支柱。研究通过对200名受访者的多项调查数据进行高级分析(Advanced Analytics)，重点考察了学习者动机、游戏化(Gamification)的有效性以及AI的集成应用。调查结果显示，后疫情时代数字学习的感知相关性显著提升，尤其是在年轻人和女性群体中表现尤为突出。这一趋势与LLM支持的AI工具兴起相吻合，这些工具通过提供个性化学习(Personalized Learning)进一步推动了数字平台的普及。研究最终为企业、政府政策制定者和教育工作者提供了优化数字学习产品的实用见解，以满足不断变化的劳动力市场需求。该论文强调了在人工智能时代，持续进化的数字学习生态对于成人终身学习者的重要意义。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "41 pages including references, appendix, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03114v1",
      "published_date": "2026-02-03 05:14:28 UTC",
      "updated_date": "2026-02-03 05:14:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:46:58.123112+00:00"
    },
    {
      "arxiv_id": "2602.03104v1",
      "title": "\"I'm happy even though it's not real\": GenAI Photo Editing as a Remembering Experience",
      "title_zh": "“虽非真实，亦感欣悦”：作为一种记忆体验的生成式人工智能照片编辑",
      "authors": [
        "Yufeng Wu",
        "Qing Li",
        "Elise van den Hoven",
        "Baki Kocaballi"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) is increasingly integrated into photo applications on personal devices, making editing photographs easier than ever while potentially influencing the memories they represent. This study explores how and why people use GenAI to edit personal photos and how this shapes their remembering experience. We conducted a two-phase qualitative study with 12 participants: a photo editing session using a GenAI tool guided by the Remembering Experience (RX) dimensions, followed by semi-structured interviews where participants reflected on the editing process and results. Findings show that participants prioritised felt memory over factual accuracy. For different photo elements, environments were modified easily, however, editing was deemed unacceptable if it touched upon a person's identity. Editing processes brought positive and negative impacts, and itself also became a remembering experience. We further discuss potential benefits and risks of GenAI editing for remembering purposes and propose design implications for responsible GenAI.",
      "tldr_zh": "该研究探讨了生成式人工智能(GenAI)在个人照片编辑中的应用及其对记忆体验(Remembering Experience, RX)的影响。通过对12名参与者进行包含照片编辑环节和半结构化访谈的两阶段定性研究，分析了用户使用GenAI编辑照片的动机及后果。研究发现，参与者在编辑个人照片时更倾向于优先考虑“感受记忆”(felt memory)而非事实准确性。对于照片元素，环境背景的修改容易被接受，但涉及人物身份(identity)的修改则被视为不可接受。编辑过程本身不仅带来了积极与消极的影响，还演变成了一种独特的记忆体验。该研究进一步讨论了GenAI编辑在记忆用途上的潜在收益与风险，并为负责任的GenAI设计提供了实践启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03104v1",
      "published_date": "2026-02-03 04:58:32 UTC",
      "updated_date": "2026-02-03 04:58:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:03.324952+00:00"
    },
    {
      "arxiv_id": "2602.03103v1",
      "title": "Task--Specificity Score: Measuring How Much Instructions Really Matter for Supervision",
      "title_zh": "Task-Specificity Score：量化指令对监督任务的实际重要程度",
      "authors": [
        "Pritam Kadasi",
        "Abhishek Upperwal",
        "Mayank Singh"
      ],
      "abstract": "Instruction tuning is now the default way to train and adapt large language models, but many instruction--input--output pairs are only weakly specified: for a given input, the same output can remain plausible under several alternative instructions. This raises a simple question: \\emph{does the instruction uniquely determine the target output?}\n  We propose the \\textbf{Task--Specificity Score (TSS)} to quantify how much an instruction matters for predicting its output, by contrasting the true instruction against plausible alternatives for the same input. We further introduce \\textbf{TSS++}, which uses hard alternatives and a small quality term to mitigate easy-negative effects. Across three instruction datasets (\\textsc{Alpaca}, \\textsc{Dolly-15k}, \\textsc{NI-20}) and three open LLMs (Gemma, Llama, Qwen), we show that selecting task-specific examples improves downstream performance under tight token budgets and complements quality-based filters such as perplexity and IFD.",
      "tldr_zh": "该研究针对指令微调(Instruction tuning)中常见的指令-输入-输出三元组规范性弱的问题，即同一输入在不同指令下可能产生相似输出的现象，探讨了指令对目标输出的决定性程度。为此，作者提出了任务特异性评分(Task-Specificity Score, TSS)，通过将真实指令与同一输入的备选指令进行对比，量化指令在预测输出中的重要性。研究进一步引入了TSS++，通过采用硬负例(hard alternatives)和小型质量项，有效缓解了易负例(easy-negative)效应。在Alpaca、Dolly-15k和NI-20三个指令数据集以及Gemma、Llama、Qwen等大语言模型(LLMs)上的实验表明，筛选任务特异性较高的示例能显著提升模型在有限Token预算下的下游任务性能。此外，TSS还被证明可以作为困惑度(perplexity)和IFD等基于质量的过滤器的有效补充，为优化数据选择策略提供了新的维度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03103v1",
      "published_date": "2026-02-03 04:57:47 UTC",
      "updated_date": "2026-02-03 04:57:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:02.728222+00:00"
    },
    {
      "arxiv_id": "2602.03100v1",
      "title": "Risky-Bench: Probing Agentic Safety Risks under Real-World Deployment",
      "title_zh": "Risky-Bench：探究真实部署环境下的智能体安全风险",
      "authors": [
        "Jingnan Zheng",
        "Yanzhen Luo",
        "Jingjun Xu",
        "Bingnan Liu",
        "Yuxin Chen",
        "Chenhang Cui",
        "Gelei Deng",
        "Chaochao Lu",
        "Xiang Wang",
        "An Zhang",
        "Tat-Seng Chua"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed as agents that operate in real-world environments, introducing safety risks beyond linguistic harm. Existing agent safety evaluations rely on risk-oriented tasks tailored to specific agent settings, resulting in limited coverage of safety risk space and failing to assess agent safety behavior during long-horizon, interactive task execution in complex real-world deployments. Moreover, their specialization to particular agent settings limits adaptability across diverse agent configurations. To address these limitations, we propose Risky-Bench, a framework that enables systematic agent safety evaluation grounded in real-world deployment. Risky-Bench organizes evaluation around domain-agnostic safety principles to derive context-aware safety rubrics that delineate safety space, and systematically evaluates safety risks across this space through realistic task execution under varying threat assumptions. When applied to life-assist agent settings, Risky-Bench uncovers substantial safety risks in state-of-the-art agents under realistic execution conditions. Moreover, as a well-structured evaluation pipeline, Risky-Bench is not confined to life-assist scenarios and can be adapted to other deployment settings to construct environment-specific safety evaluations, providing an extensible methodology for agent safety assessment.",
      "tldr_zh": "该研究提出了Risky-Bench，这是一个旨在系统评估真实世界部署环境下智能体(Agent)安全风险的框架，以解决现有评估方法在安全风险覆盖范围和复杂交互任务适应性上的局限。Risky-Bench基于领域无关的安全原则(domain-agnostic safety principles)推导出上下文感知的安全准则(context-aware safety rubrics)，通过在不同威胁假设下执行真实任务来全面探测安全空间。在生活助手智能体(life-assist agent)场景的应用中，该框架揭示了当前最先进智能体在真实执行条件下存在的显著安全风险。作为一个结构化的评估流水线，Risky-Bench不仅限于生活辅助场景，还具有良好的可扩展性，能够为多种部署环境提供定制化的智能体安全评估方法论。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03100v1",
      "published_date": "2026-02-03 04:44:11 UTC",
      "updated_date": "2026-02-03 04:44:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:04.217657+00:00"
    },
    {
      "arxiv_id": "2602.03098v1",
      "title": "TextME: Bridging Unseen Modalities Through Text Descriptions",
      "title_zh": "TextME：利用文本描述衔接未见模态",
      "authors": [
        "Soyeon Hong",
        "Jinchan Kim",
        "Jaegook You",
        "Seungtaek Choi",
        "Suha Kwak",
        "Hyunsouk Cho"
      ],
      "abstract": "Expanding multimodal representations to novel modalities is constrained by reliance on large-scale paired datasets (e.g., text-image, text-audio, text-3D, text-molecule), which are costly and often infeasible in domains requiring expert annotation such as medical imaging and molecular analysis. We introduce TextME, the first text-only modality expansion framework, to the best of our knowledge, projecting diverse modalities into LLM embedding space as a unified anchor. Our approach exploits the geometric structure of pretrained contrastive encoders to enable zero-shot cross-modal transfer using only text descriptions, without paired supervision. We empirically validate that such consistent modality gaps exist across image, video, audio, 3D, X-ray, and molecular domains, demonstrating that text-only training can preserve substantial performance of pretrained encoders. We further show that our framework enables emergent cross-modal retrieval between modality pairs not explicitly aligned during training (e.g., audio-to-image, 3D-to-image). These results establish text-only training as a practical alternative to paired supervision for modality expansion.",
      "tldr_zh": "该研究提出了TextME，这是首个仅依赖文本的模态扩展（modality expansion）框架，旨在解决多模态表示学习对大规模成对数据集（paired datasets）的依赖问题。该框架将多种模态投射到大语言模型（LLM）嵌入空间中作为统一锚点，利用预训练对比编码器（pretrained contrastive encoders）的几何结构，在无需成对监督的情况下实现零样本（zero-shot）跨模态迁移。实验在图像、视频、音频、3D、X射线和分子等多个领域验证了模态间隙（modality gaps）的一致性，证明仅靠文本训练即可保留预训练编码器的显著性能。此外，TextME还实现了训练中未对齐模态间的涌现（emergent）跨模态检索，例如音频到图像（audio-to-image）和3D到图像（3D-to-image）的检索。这些研究结果确立了文本唯一训练（text-only training）可以作为模态扩展中成对监督方案的实用替代路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03098v1",
      "published_date": "2026-02-03 04:43:13 UTC",
      "updated_date": "2026-02-03 04:43:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:10.520661+00:00"
    },
    {
      "arxiv_id": "2602.03097v1",
      "title": "De-conflating Preference and Qualification: Constrained Dual-Perspective Reasoning for Job Recommendation with Large Language Models",
      "title_zh": "解耦偏好与资历：基于大语言模型的约束双视角推理职位推荐",
      "authors": [
        "Bryce Kan",
        "Wei Yang",
        "Emily Nguyen",
        "Ganghui Yi",
        "Bowen Yi",
        "Chenxiao Yu",
        "Yan Liu"
      ],
      "abstract": "Professional job recommendation involves a complex bipartite matching process that must reconcile a candidate's subjective preference with an employer's objective qualification. While Large Language Models (LLMs) are well-suited for modeling the rich semantics of resumes and job descriptions, existing paradigms often collapse these two decision dimensions into a single interaction signal, yielding confounded supervision under recruitment-funnel censoring and limiting policy controllability. To address these challenges, We propose JobRec, a generative job recommendation framework for de-conflating preference and qualification via constrained dual-perspective reasoning. JobRec introduces a Unified Semantic Alignment Schema that aligns candidate and job attributes into structured semantic layers, and a Two-Stage Cooperative Training Strategy that learns decoupled experts to separately infer preference and qualification. Building on these experts, a Lagrangian-based Policy Alignment module optimizes recommendations under explicit eligibility requirements, enabling controllable trade-offs. To mitigate data scarcity, we construct a synthetic dataset refined by experts. Experiments show that JobRec consistently outperforms strong baselines and provides improved controllability for strategy-aware professional matching.",
      "tldr_zh": "该研究针对专业职位推荐中求职者主观偏好(Preference)与雇主客观资质(Qualification)容易混淆的问题，提出了基于大语言模型(LLMs)的JobRec生成式推荐框架。JobRec引入了统一语义对齐架构(Unified Semantic Alignment Schema)，将候选人和职位属性对齐到结构化语义层，并通过两阶段协作训练策略(Two-Stage Cooperative Training Strategy)学习解耦的专家模型，从而分别推断偏好与资质。此外，该框架采用基于拉格朗日(Lagrangian-based)的策略对齐模块，在明确的入职要求约束下优化推荐结果，实现了可控的策略权衡。为了缓解数据稀缺问题，研究团队还构建了经专家精炼的合成数据集。实验结果表明，JobRec在专业匹配任务中一致优于现有强基准模型，并在策略感知匹配中表现出更强的可控性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03097v1",
      "published_date": "2026-02-03 04:42:53 UTC",
      "updated_date": "2026-02-03 04:42:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:09.144323+00:00"
    },
    {
      "arxiv_id": "2602.03096v1",
      "title": "PRISM: Structured Optimization via Anisotropic Spectral Shaping",
      "title_zh": "PRISM：基于各向异性谱整形的结构化优化",
      "authors": [
        "Yujie Yang"
      ],
      "abstract": "We propose PRISM, an optimizer that enhances first-order spectral descent methods like Muon with partial second-order information. It constructs an efficient, low-rank quasi-second-order preconditioner via innovation-augmented polar decomposition. This mechanism enables PRISM to perform anisotropic spectral shaping, which adaptively suppresses updates in high-variance subspaces while preserving update strength in signal-dominated directions. Crucially, this is achieved with minimal computational overhead and zero additional memory compared to first-order baselines. PRISM demonstrates a practical strategy for integrating curvature-adaptive properties into the spectral optimization paradigm.",
      "tldr_zh": "该研究提出了 PRISM，一种旨在通过引入部分二阶信息来增强 Muon 等一阶谱下降(spectral descent)方法的优化器。PRISM 通过创新增强极分解(innovation-augmented polar decomposition)构建了一个高效的低秩准二阶预处理器。这种机制赋予了优化器进行各向异性谱整形(anisotropic spectral shaping)的能力，从而能够自适应地抑制高方差子空间中的更新，同时保留信号主导方向的更新强度。与一阶基准模型相比，PRISM 在实现曲率自适应(curvature-adaptive)特性的同时，仅需极小的计算开销且不增加额外的内存占用。该工作为在谱优化范式中整合二阶曲率特性提供了一种极具实用价值的新策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03096v1",
      "published_date": "2026-02-03 04:41:11 UTC",
      "updated_date": "2026-02-03 04:41:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:18.711396+00:00"
    },
    {
      "arxiv_id": "2602.03087v1",
      "title": "Training and Simulation of Quadrupedal Robot in Adaptive Stair Climbing for Indoor Firefighting: An End-to-End Reinforcement Learning Approach",
      "title_zh": "面向室内消防的四足机器人自适应楼梯攀爬训练与仿真：一种端到端强化学习方法",
      "authors": [
        "Baixiao Huang",
        "Baiyu Huang",
        "Yu Hou"
      ],
      "abstract": "Quadruped robots are used for primary searches during the early stages of indoor fires. A typical primary search involves quickly and thoroughly looking for victims under hazardous conditions and monitoring flammable materials. However, situational awareness in complex indoor environments and rapid stair climbing across different staircases remain the main challenges for robot-assisted primary searches. In this project, we designed a two-stage end-to-end deep reinforcement learning (RL) approach to optimize both navigation and locomotion. In the first stage, the quadrupeds, Unitree Go2, were trained to climb stairs in Isaac Lab's pyramid-stair terrain. In the second stage, the quadrupeds were trained to climb various realistic indoor staircases in the Isaac Lab engine, with the learned policy transferred from the previous stage. These indoor staircases are straight, L-shaped, and spiral, to support climbing tasks in complex environments. This project explores how to balance navigation and locomotion and how end-to-end RL methods can enable quadrupeds to adapt to different stair shapes. Our main contributions are: (1) A two-stage end-to-end RL framework that transfers stair-climbing skills from abstract pyramid terrain to realistic indoor stair topologies. (2) A centerline-based navigation formulation that enables unified learning of navigation and locomotion without hierarchical planning. (3) Demonstration of policy generalization across diverse staircases using only local height-map perception. (4) An empirical analysis of success, efficiency, and failure modes under increasing stair difficulty.",
      "tldr_zh": "该研究针对室内消防初期搜救任务，探讨了四足机器人在复杂室内环境中适应性爬楼梯的挑战。论文提出了一种两阶段端到端深度强化学习(Deep Reinforcement Learning, RL)方法，旨在优化导航与运动控制。在第一阶段，Unitree Go2 机器人在 Isaac Lab 的金字塔楼梯地形中接受基础爬楼梯训练；第二阶段则将学习到的策略迁移至包括直线型、L型和螺旋型在内的真实室内楼梯场景。研究引入了基于中心线(Centerline-based)的导航公式，实现了导航与运动的统一学习，无需传统的分层规划。通过仅依赖局部高度图(Local Height-map)感知，该方案展示了策略在不同形状楼梯上的强大泛化能力。实验最后对不同难度下爬楼梯的成功率和效率进行了实证分析，证明了该框架在提升机器人室内消防辅助能力方面的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 9 figures, 43rd International Symposium on Automation and Robotics in Construction",
      "pdf_url": "https://arxiv.org/pdf/2602.03087v1",
      "published_date": "2026-02-03 04:23:50 UTC",
      "updated_date": "2026-02-03 04:23:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:16.921428+00:00"
    },
    {
      "arxiv_id": "2602.03085v1",
      "title": "The Trigger in the Haystack: Extracting and Reconstructing LLM Backdoor Triggers",
      "title_zh": "草堆寻针：LLM 后门触发器的提取与重构",
      "authors": [
        "Blake Bullwinkel",
        "Giorgio Severi",
        "Keegan Hines",
        "Amanda Minnich",
        "Ram Shankar Siva Kumar",
        "Yonatan Zunger"
      ],
      "abstract": "Detecting whether a model has been poisoned is a longstanding problem in AI security. In this work, we present a practical scanner for identifying sleeper agent-style backdoors in causal language models. Our approach relies on two key findings: first, sleeper agents tend to memorize poisoning data, making it possible to leak backdoor examples using memory extraction techniques. Second, poisoned LLMs exhibit distinctive patterns in their output distributions and attention heads when backdoor triggers are present in the input. Guided by these observations, we develop a scalable backdoor scanning methodology that assumes no prior knowledge of the trigger or target behavior and requires only inference operations. Our scanner integrates naturally into broader defensive strategies and does not alter model performance. We show that our method recovers working triggers across multiple backdoor scenarios and a broad range of models and fine-tuning methods.",
      "tldr_zh": "该研究针对因果语言模型(Causal Language Models)中类似“睡眠代理(Sleeper Agent)”风格的后门检测难题，提出了一种实用的后门扫描器。研究基于两个核心发现：首先，这类模型倾向于记忆中毒数据，使其可能通过内存提取(Memory Extraction)技术被泄露；其次，当输入中存在触发器时，受污染的语言模型在输出分布和注意力头(Attention Heads)上会表现出显著的特异性模式。基于此，该团队开发了一种可扩展的扫描方法，该方法仅需推理操作，且无需预先了解触发器或目标行为。实验结果显示，该扫描器能有效整合入现有的防御策略而不影响性能，并在多种模型和微调环境下成功恢复了可工作的后门触发器。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03085v1",
      "published_date": "2026-02-03 04:17:21 UTC",
      "updated_date": "2026-02-03 04:17:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:38.116187+00:00"
    },
    {
      "arxiv_id": "2602.03067v1",
      "title": "FlashSinkhorn: IO-Aware Entropic Optimal Transport",
      "title_zh": "FlashSinkhorn：IO感知的熵最优传输",
      "authors": [
        "Felix X. -F. Ye",
        "Xingjie Li",
        "An Yu",
        "Ming-Ching Chang",
        "Linsong Chu",
        "Davis Wertheimer"
      ],
      "abstract": "Entropic optimal transport (EOT) via Sinkhorn iterations is widely used in modern machine learning, yet GPU solvers remain inefficient at scale. Tensorized implementations suffer quadratic HBM traffic from dense $n\\times m$ interactions, while existing online backends avoid storing dense matrices but still rely on generic tiled map-reduce reduction kernels with limited fusion. We present \\textbf{FlashSinkhorn}, an IO-aware EOT solver for squared Euclidean cost that rewrites stabilized log-domain Sinkhorn updates as row-wise LogSumExp reductions of biased dot-product scores, the same normalization as transformer attention. This enables FlashAttention-style fusion and tiling: fused Triton kernels stream tiles through on-chip SRAM and update dual potentials in a single pass, substantially reducing HBM IO per iteration while retaining linear-memory operations. We further provide streaming kernels for transport application, enabling scalable first- and second-order optimization. On A100 GPUs, FlashSinkhorn achieves up to $32\\times$ forward-pass and $161\\times$ end-to-end speedups over state-of-the-art online baselines on point-cloud OT, improves scalability on OT-based downstream tasks. For reproducibility, we release an open-source implementation at https://github.com/ot-triton-lab/ot_triton.",
      "tldr_zh": "该研究提出了FlashSinkhorn，一种针对平方欧几里得代价（squared Euclidean cost）的IO-aware Entropic Optimal Transport (EOT)求解器，旨在解决大规模Sinkhorn迭代在GPU上因高HBM流量导致的效率瓶颈。FlashSinkhorn通过将对数域Sinkhorn更新重写为类似于Transformer Attention中的行向LogSumExp约减，成功引入了FlashAttention风格的算子融合与Tiling（分块）技术。该方法利用Triton内核在片上SRAM中流式处理数据，实现了在单次Pass中更新dual potentials，从而显著降低了迭代过程中的HBM IO开销。实验结果显示，在A100 GPU的点云OT任务中，FlashSinkhorn相比现有的在线基准（online baselines）实现了高达32倍的前向传播加速和161倍的端到端提速。此外，该求解器还支持可扩展的一阶与二阶优化流式内核，显著提升了下游任务的性能，并已在GitHub开源了相关实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03067v1",
      "published_date": "2026-02-03 03:52:20 UTC",
      "updated_date": "2026-02-03 03:52:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:33.215002+00:00"
    },
    {
      "arxiv_id": "2602.03066v1",
      "title": "Shortcut Features as Top Eigenfunctions of NTK: A Linear Neural Network Case and More",
      "title_zh": "快捷特征即 NTK 的主特征函数：线性神经网络案例及其拓展",
      "authors": [
        "Jinwoo Lim",
        "Suhyun Kim",
        "Soo-Mook Moon"
      ],
      "abstract": "One of the chronic problems of deep-learning models is shortcut learning. In a case where the majority of training data are dominated by a certain feature, neural networks prefer to learn such a feature even if the feature is not generalizable outside the training set. Based on the framework of Neural Tangent Kernel (NTK), we analyzed the case of linear neural networks to derive some important properties of shortcut learning. We defined a feature of a neural network as an eigenfunction of NTK. Then, we found that shortcut features correspond to features with larger eigenvalues when the shortcuts stem from the imbalanced number of samples in the clustered distribution. We also showed that the features with larger eigenvalues still have a large influence on the neural network output even after training, due to data variances in the clusters. Such a preference for certain features remains even when a margin of a neural network output is controlled, which shows that the max-margin bias is not the only major reason for shortcut learning. These properties of linear neural networks are empirically extended for more complex neural networks as a two-layer fully-connected ReLU network and a ResNet-18.",
      "tldr_zh": "该研究探讨了深度学习中普遍存在的 Shortcut learning 问题，即神经网络倾向于学习训练集中占据主导地位但缺乏泛化能力的特征。作者基于 Neural Tangent Kernel (NTK) 框架分析了线性神经网络，将网络特征定义为 NTK 的特征函数 (Eigenfunctions)，并发现当数据分布不平衡时，Shortcut features 对应于具有较大特征值 (Eigenvalues) 的部分。研究表明由于聚类内部的数据方差，这些大特征值特征在训练结束后仍对模型输出有显著影响。此外，即便在控制输出间隔 (Margin) 时特征偏好依然存在，证明 Max-margin bias 并非捷径学习的唯一诱因。最后，该理论在线性模型的基础上被成功扩展至两层全连接 ReLU 网络和 ResNet-18 等复杂架构，验证了其在更深层网络中的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03066v1",
      "published_date": "2026-02-03 03:50:18 UTC",
      "updated_date": "2026-02-03 03:50:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:35.129559+00:00"
    },
    {
      "arxiv_id": "2602.03064v1",
      "title": "JRDB-Pose3D: A Multi-person 3D Human Pose and Shape Estimation Dataset for Robotics",
      "title_zh": "JRDB-Pose3D：面向机器人领域的多人三维人体姿态与形状估计数据集",
      "authors": [
        "Sandika Biswas",
        "Kian Izadpanah",
        "Hamid Rezatofighi"
      ],
      "abstract": "Real-world scenes are inherently crowded. Hence, estimating 3D poses of all nearby humans, tracking their movements over time, and understanding their activities within social and environmental contexts are essential for many applications, such as autonomous driving, robot perception, robot navigation, and human-robot interaction. However, most existing 3D human pose estimation datasets primarily focus on single-person scenes or are collected in controlled laboratory environments, which restricts their relevance to real-world applications. To bridge this gap, we introduce JRDB-Pose3D, which captures multi-human indoor and outdoor environments from a mobile robotic platform. JRDB-Pose3D provides rich 3D human pose annotations for such complex and dynamic scenes, including SMPL-based pose annotations with consistent body-shape parameters and track IDs for each individual over time. JRDB-Pose3D contains, on average, 5-10 human poses per frame, with some scenes featuring up to 35 individuals simultaneously. The proposed dataset presents unique challenges, including frequent occlusions, truncated bodies, and out-of-frame body parts, which closely reflect real-world environments. Moreover, JRDB-Pose3D inherits all available annotations from the JRDB dataset, such as 2D pose, information about social grouping, activities, and interactions, full-scene semantic masks with consistent human- and object-level tracking, and detailed annotations for each individual, such as age, gender, and race, making it a holistic dataset for a wide range of downstream perception and human-centric understanding tasks.",
      "tldr_zh": "该研究推出了 JRDB-Pose3D，这是一个旨在解决现有 3D 人体姿态估计数据集在真实多人场景下局限性的新数据集。该数据集通过移动机器人平台在室内外环境采集，提供了包括基于 SMPL 模型的一致体型参数和时间追踪 ID (track IDs) 在内的详尽标注。JRDB-Pose3D 包含高密度的人群场景，每帧平均有 5-10 人，最高可达 35 人，涵盖了频繁遮挡 (occlusions) 和身体残缺等具有挑战性的真实工况。除了 3D 姿态，该数据集还继承了 JRDB 的 2D 姿态、社会分组 (social grouping)、行为活动以及全场景语义掩码 (semantic masks) 等多维度信息。作为一套综合性数据集，JRDB-Pose3D 为机器人导航、人机交互以及多层面的以人为中心的感知任务提供了重要支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03064v1",
      "published_date": "2026-02-03 03:46:27 UTC",
      "updated_date": "2026-02-03 03:46:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:43.318626+00:00"
    },
    {
      "arxiv_id": "2602.03061v1",
      "title": "Evaluating LLMs When They Do Not Know the Answer: Statistical Evaluation of Mathematical Reasoning via Comparative Signals",
      "title_zh": "评估LLM在未知答案情境下的表现：基于比较信号的数学推理统计评估",
      "authors": [
        "Zihan Dong",
        "Zhixian Zhang",
        "Yang Zhou",
        "Can Jin",
        "Ruijia Wu",
        "Linjun Zhang"
      ],
      "abstract": "Evaluating mathematical reasoning in LLMs is constrained by limited benchmark sizes and inherent model stochasticity, yielding high-variance accuracy estimates and unstable rankings across platforms. On difficult problems, an LLM may fail to produce a correct final answer, yet still provide reliable pairwise comparison signals indicating which of two candidate solutions is better. We leverage this observation to design a statistically efficient evaluation framework that combines standard labeled outcomes with pairwise comparison signals obtained by having models judge auxiliary reasoning chains. Treating these comparison signals as control variates, we develop a semiparametric estimator based on the efficient influence function (EIF) for the setting where auxiliary reasoning chains are observed. This yields a one-step estimator that achieves the semiparametric efficiency bound, guarantees strict variance reduction over naive sample averaging, and admits asymptotic normality for principled uncertainty quantification. Across simulations, our one-step estimator substantially improves ranking accuracy, with gains increasing as model output noise grows. Experiments on GPQA Diamond, AIME 2025, and GSM8K further demonstrate more precise performance estimation and more reliable model rankings, especially in small-sample regimes where conventional evaluation is pretty unstable.",
      "tldr_zh": "该研究针对大语言模型(LLMs)数学推理评估中因基准规模有限和模型随机性导致的高方差及排名不稳定问题，提出了一种结合标准标注结果与成对比较信号(pairwise comparison signals)的统计评估框架。研究发现，即使模型无法给出正确答案，其对辅助推理链优劣的判断仍能提供可靠的比较信号。通过将这些信号视为控制变量(control variates)，研究者开发了基于有效影响函数(efficient influence function, EIF)的半参数估计器和一步估计器(one-step estimator)。该方法在理论上达到了半参数效率界限，确保了比传统样本平均更低的方差，并支持渐近正态性以进行原则性的不确定性量化。在GPQA Diamond、AIME 2025和GSM8K等数据集上的实验证明，该评估框架在小样本情境下能显著提升模型排名精度和性能估计的稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03061v1",
      "published_date": "2026-02-03 03:40:01 UTC",
      "updated_date": "2026-02-03 03:40:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:38.429647+00:00"
    },
    {
      "arxiv_id": "2602.03054v1",
      "title": "Towards Considerate Embodied AI: Co-Designing Situated Multi-Site Healthcare Robots from Abstract Concepts to High-Fidelity Prototypes",
      "title_zh": "迈向周全的具身智能：从抽象概念到高保真原型的多场景情境化医疗机器人协作设计",
      "authors": [
        "Yuanchen Bai",
        "Ruixiang Han",
        "Niti Parikh",
        "Wendy Ju",
        "Angelique Taylor"
      ],
      "abstract": "Co-design is essential for grounding embodied artificial intelligence (AI) systems in real-world contexts, especially high-stakes domains such as healthcare. While prior work has explored multidisciplinary collaboration, iterative prototyping, and support for non-technical participants, few have interwoven these into a sustained co-design process. Such efforts often target one context and low-fidelity stages, limiting the generalizability of findings and obscuring how participants' ideas evolve. To address these limitations, we conducted a 14-week workshop with a multidisciplinary team of 22 participants, centered around how embodied AI can reduce non-value-added task burdens in three healthcare settings: emergency departments, long-term rehabilitation facilities, and sleep disorder clinics. We found that the iterative progression from abstract brainstorming to high-fidelity prototypes, supported by educational scaffolds, enabled participants to understand real-world trade-offs and generate more deployable solutions. We propose eight guidelines for co-designing more considerate embodied AI: attuned to context, responsive to social dynamics, mindful of expectations, and grounded in deployment. Project Page: https://byc-sophie.github.io/Towards-Considerate-Embodied-AI/",
      "tldr_zh": "该研究探讨了如何通过协同设计(Co-design)将具身人工智能(Embodied AI)系统有效应用于高风险的医疗场景，旨在减少急诊室、长期康复机构和睡眠障碍诊所中的非增值任务负担。研究团队开展了为期14周的多学科研讨会，通过从抽象概念到高保真原型(High-fidelity prototypes)的迭代演进，并结合教育引导(Educational scaffolds)，显著提升了参与者对现实权衡的理解及解决方案的可部署性。实验表明，这种跨越多个现场的持续协作流程能够更有效地捕捉用户需求随技术保真度提升而产生的演变，克服了以往研究局限于单一场景或低保真阶段的不足。最终，论文提出了构建“体贴的具身人工智能”(Considerate embodied AI)的八项设计准则，强调系统必须对特定语境(Context)具有敏锐感知，能灵活响应社交动态(Social dynamics)，并充分顾及用户期望与实际部署(Deployment)环境的紧密结合。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear in Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI 2026)",
      "pdf_url": "https://arxiv.org/pdf/2602.03054v1",
      "published_date": "2026-02-03 03:30:41 UTC",
      "updated_date": "2026-02-03 03:30:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:55.225584+00:00"
    },
    {
      "arxiv_id": "2602.03053v1",
      "title": "MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems",
      "title_zh": "MAS-ProVe：深入理解多智能体系统的过程验证",
      "authors": [
        "Vishal Venkataramani",
        "Haizhou Shi",
        "Zixuan Ke",
        "Austin Xu",
        "Xiaoxiao He",
        "Yingbo Zhou",
        "Semih Yavuz",
        "Hao Wang",
        "Shafiq Joty"
      ],
      "abstract": "Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, and has been suggested as a potential tool for guiding coordination of MAS; however, its actual effectiveness in MAS remains unclear. To fill this gap, we present MAS-ProVe, a systematic empirical study of process verification for multi-agent systems (MAS). Our study spans three verification paradigms (LLM-as-a-Judge, reward models, and process reward models), evaluated across two levels of verification granularity (agent-level and iteration-level). We further examine five representative verifiers and four context management strategies, and conduct experiments over six diverse MAS frameworks on multiple reasoning benchmarks. We find that process-level verification does not consistently improve performance and frequently exhibits high variance, highlighting the difficulty of reliably evaluating partial multi-agent trajectories. Among the methods studied, LLM-as-a-Judge generally outperforms reward-based approaches, with trained judges surpassing general-purpose LLMs. We further observe a small performance gap between LLMs acting as judges and as single agents, and identify a context-length-performance trade-off in verification. Overall, our results suggest that effective and robust process verification for MAS remains an open challenge, requiring further advances beyond current paradigms. Code is available at https://github.com/Wang-ML-Lab/MAS-ProVe.",
      "tldr_zh": "该研究针对基于大语言模型(LLMs)的多智能体系统(MAS)在推理轨迹中表现出的高方差问题，系统地探讨了过程验证(Process Verification)在协调MAS中的实际有效性。论文提出了MAS-ProVe，这是一项关于多智能体系统过程验证的系统性实证研究，涵盖了LLM-as-a-Judge、奖励模型(Reward Models)和过程奖励模型(Process Reward Models)三种验证范式。研究在智能体层级(Agent-level)和迭代层级(Iteration-level)两个细粒度上评估了五种代表性验证器，并在六种不同的MAS框架及多个推理基准测试上进行了广泛实验。研究发现，过程级验证并不总是能稳定提升性能，且经常表现出高方差，这凸显了可靠评估多智能体部分轨迹的极高难度。在所有方法中，LLM-as-a-Judge的表现通常优于基于奖励的方法，且经过训练的专用评判模型优于通用型LLMs。此外，研究还识别出了验证过程中存在的上下文长度与性能权衡(Context-length-performance trade-off)问题。总体而言，MAS-ProVe表明为多智能体系统建立有效且稳健的过程验证仍然是一个开放性挑战，需要超越当前范式的进一步技术突破。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint; work in progress",
      "pdf_url": "https://arxiv.org/pdf/2602.03053v1",
      "published_date": "2026-02-03 03:30:36 UTC",
      "updated_date": "2026-02-03 03:30:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:51.011031+00:00"
    },
    {
      "arxiv_id": "2602.03048v1",
      "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs",
      "title_zh": "CoBA-RL：面向能力的大语言模型强化学习预算分配",
      "authors": [
        "Zhiyuan Yao",
        "Yi-Kai Zhang",
        "Yuxin Chen",
        "Yueqing Sun",
        "Zishan Xu",
        "Yu Yang",
        "Tianhao Hu",
        "Qi Gu",
        "Hui Su",
        "Xunliang Cai"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key approach for enhancing LLM reasoning.However, standard frameworks like Group Relative Policy Optimization (GRPO) typically employ a uniform rollout budget, leading to resource inefficiency. Moreover, existing adaptive methods often rely on instance-level metrics, such as task pass rates, failing to capture the model's dynamic learning state. To address these limitations, we propose CoBA-RL, a reinforcement learning algorithm designed to adaptively allocate rollout budgets based on the model's evolving capability. Specifically, CoBA-RL utilizes a Capability-Oriented Value function to map tasks to their potential training gains and employs a heap-based greedy strategy to efficiently self-calibrate the distribution of computational resources to samples with high training value. Extensive experiments demonstrate that our approach effectively orchestrates the trade-off between exploration and exploitation, delivering consistent generalization improvements across multiple challenging benchmarks. These findings underscore that quantifying sample training value and optimizing budget allocation are pivotal for advancing LLM post-training efficiency.",
      "tldr_zh": "该研究针对大语言模型(LLMs)中可验证奖励强化学习(RLVR)存在的资源效率低下问题，提出了CoBA-RL算法。现有的标准框架如GRPO通常采用统一的Rollout预算，而现有的自适应方法往往依赖于无法捕捉模型动态学习状态的实例级指标。CoBA-RL通过引入一种能力导向价值函数(Capability-Oriented Value function)，将具体任务映射为潜在的训练增益。随后，该方法采用基于堆的贪心策略(heap-based greedy strategy)，通过自我校准将计算资源高效分配给具有高训练价值的样本。在多个具有挑战性的基准测试上的实验表明，CoBA-RL能够有效平衡探索与开发(exploration and exploitation)，实现了一致的泛化能力提升。该项工作最终证明了量化样本训练价值和优化预算分配是提升大语言模型后训练(post-training)效率的关键。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03048v1",
      "published_date": "2026-02-03 03:14:36 UTC",
      "updated_date": "2026-02-03 03:14:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:50.630085+00:00"
    },
    {
      "arxiv_id": "2602.03043v1",
      "title": "SAFE-KD: Risk-Controlled Early-Exit Distillation for Vision Backbones",
      "title_zh": "SAFE-KD：面向视觉骨干网络的风险受控提前退出蒸馏",
      "authors": [
        "Salim Khazem"
      ],
      "abstract": "Early-exit networks reduce inference cost by allowing ``easy'' inputs to stop early, but practical deployment hinges on knowing \\emph{when} early exit is safe. We introduce SAFE-KD, a universal multi-exit wrapper for modern vision backbones that couples hierarchical distillation with \\emph{conformal risk control}. SAFE-KD attaches lightweight exit heads at intermediate depths, distills a strong teacher into all exits via Decoupled Knowledge Distillation (DKD), and enforces deep-to-shallow consistency between exits. At inference, we calibrate per-exit stopping thresholds on a held-out set using conformal risk control (CRC) to guarantee a user-specified \\emph{selective} misclassification risk (among the samples that exit early) under exchangeability. Across multiple datasets and architectures, SAFE-KD yields improved accuracy compute trade-offs, stronger calibration, and robust performance under corruption while providing finite-sample risk guarantees.",
      "tldr_zh": "该研究提出了 SAFE-KD，一种针对现代视觉骨干网络 (vision backbones) 的通用多出口 (multi-exit) 包装器，旨在解决早期退出 (early-exit) 网络在实际部署中难以确定退出时机安全性这一核心挑战。该框架在网络中间深度附加轻量级退出头，利用解耦知识蒸馏 (Decoupled Knowledge Distillation, DKD) 将强教师模型的知识传递给所有出口，并强制执行出口间的深浅一致性约束。在推理过程中，SAFE-KD 引入了符合风险控制 (conformal risk control, CRC) 机制，通过在留出集上校准各出口的停止阈值，确保在满足可交换性前提下达到用户指定的选择性误分类风险保证。多项实验结果证明，SAFE-KD 在不同数据集和架构上显著优化了准确率与计算成本之间的权衡，并提升了模型的校准性能与对抗数据损坏的鲁棒性。此外，该方法还为早期退出决策提供了关键的有限样本风险理论保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IJCNN",
      "pdf_url": "https://arxiv.org/pdf/2602.03043v1",
      "published_date": "2026-02-03 03:07:31 UTC",
      "updated_date": "2026-02-03 03:07:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:47:54.852322+00:00"
    },
    {
      "arxiv_id": "2602.03038v1",
      "title": "Bongards at the Boundary of Perception and Reasoning: Programs or Language?",
      "title_zh": "感知与推理边界的 Bongard 问题：程序还是语言？",
      "authors": [
        "Cassidy Langenfeld",
        "Claas Beger",
        "Gloria Geng",
        "Wasu Top Piriyakulkij",
        "Keya Hu",
        "Yewen Pu",
        "Kevin Ellis"
      ],
      "abstract": "Vision-Language Models (VLMs) have made great strides in everyday visual tasks, such as captioning a natural image, or answering commonsense questions about such images. But humans possess the puzzling ability to deploy their visual reasoning abilities in radically new situations, a skill rigorously tested by the classic set of visual reasoning challenges known as the Bongard problems. We present a neurosymbolic approach to solving these problems: given a hypothesized solution rule for a Bongard problem, we leverage LLMs to generate parameterized programmatic representations for the rule and perform parameter fitting using Bayesian optimization. We evaluate our method on classifying Bongard problem images given the ground truth rule, as well as on solving the problems from scratch.",
      "tldr_zh": "Vision-Language Models (VLMs) 在日常视觉任务中取得了长足进步，但人类在处理如经典的 Bongard problems 等全新视觉推理挑战时展现出了更为卓越的通用能力。该研究提出了一种神经符号 (neurosymbolic) 方法来应对这些挑战，旨在探索感知与推理的边界。针对假设的解题规则，该方法利用 Large Language Models (LLMs) 生成参数化的程序化表示 (parameterized programmatic representations)，并进一步采用 Bayesian optimization 进行参数拟合。研究在基于 ground truth 规则的图像分类以及从零开始解决问题的两种场景下对该方法进行了验证。该工作不仅展示了结合程序化表示解决复杂视觉逻辑问题的潜力，也为理解人工智能在视觉推理中的语言与程序路径提供了新视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.03038v1",
      "published_date": "2026-02-03 03:04:27 UTC",
      "updated_date": "2026-02-03 03:04:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:07.024089+00:00"
    },
    {
      "arxiv_id": "2602.03034v1",
      "title": "KANFIS A Neuro-Symbolic Framework for Interpretable and Uncertainty-Aware Learning",
      "title_zh": "KANFIS：面向可解释性与不确定性感知学习的神经符号框架",
      "authors": [
        "Binbin Yong",
        "Haoran Pei",
        "Jun Shen",
        "Haoran Li",
        "Qingguo Zhou",
        "Zhao Su"
      ],
      "abstract": "Adaptive Neuro-Fuzzy Inference System (ANFIS) was designed to combine the learning capabilities of neural network with the reasoning transparency of fuzzy logic. However, conventional ANFIS architectures suffer from structural complexity, where the product-based inference mechanism causes an exponential explosion of rules in high-dimensional spaces. We herein propose the Kolmogorov-Arnold Neuro-Fuzzy Inference System (KANFIS), a compact neuro-symbolic architecture that unifies fuzzy reasoning with additive function decomposition. KANFIS employs an additive aggregation mechanism, under which both model parameters and rule complexity scale linearly with input dimensionality rather than exponentially. Furthermore, KANFIS is compatible with both Type-1 (T1) and Interval Type-2 (IT2) fuzzy logic systems, enabling explicit modeling of uncertainty and ambiguity in fuzzy representations. By using sparse masking mechanisms, KANFIS generates compact and structured rule sets, resulting in an intrinsically interpretable model with clear rule semantics and transparent inference processes. Empirical results demonstrate that KANFIS achieves competitive performance against representative neural and neuro-fuzzy baselines.",
      "tldr_zh": "该研究针对传统的自适应神经模糊推理系统 (ANFIS) 在处理高维数据时因乘积推理机制导致的规则爆炸和结构复杂性问题，提出了 KANFIS 框架。KANFIS 是一种紧凑的神经符号 (neuro-symbolic) 架构，它巧妙地将模糊推理与加性函数分解 (additive function decomposition) 相结合。通过采用加性聚合机制，该模型的参数和规则复杂度随输入维度的增加呈线性增长而非指数增长，显著提升了模型在大规模数据下的适用性。此外，KANFIS 同时兼容 Type-1 (T1) 和 Interval Type-2 (IT2) 模糊逻辑系统，能够对模糊表示中的不确定性和歧义性进行显式建模。借助稀疏掩码 (sparse masking) 机制，KANFIS 能够生成结构紧凑且具有清晰语义的规则集，确保了推理过程的透明度和内在可解释性。实验结果证明，KANFIS 在性能上能够与代表性的神经和神经模糊基准模型相媲美，为构建可解释且具备不确定性感知能力的学习系统提供了有效方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03034v1",
      "published_date": "2026-02-03 03:02:17 UTC",
      "updated_date": "2026-02-03 03:02:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:20.911329+00:00"
    },
    {
      "arxiv_id": "2602.03026v1",
      "title": "Visual Reasoning over Time Series via Multi-Agent System",
      "title_zh": "基于多智能体系统的时间序列视觉推理",
      "authors": [
        "Weilin Ruan",
        "Yuxuan Liang"
      ],
      "abstract": "Time series analysis underpins many real-world applications, yet existing time-series-specific methods and pretrained large-model-based approaches remain limited in integrating intuitive visual reasoning and generalizing across tasks with adaptive tool usage. To address these limitations, we propose MAS4TS, a tool-driven multi-agent system for general time series tasks, built upon an Analyzer-Reasoner-Executor paradigm that integrates agent communication, visual reasoning, and latent reconstruction within a unified framework. MAS4TS first performs visual reasoning over time series plots with structured priors using a Vision-Language Model to extract temporal structures, and subsequently reconstructs predictive trajectories in latent space. Three specialized agents coordinate via shared memory and gated communication, while a router selects task-specific tool chains for execution. Extensive experiments on multiple benchmarks demonstrate that MAS4TS achieves state-of-the-art performance across a wide range of time series tasks, while exhibiting strong generalization and efficient inference.",
      "tldr_zh": "该研究提出了MAS4TS，一种用于通用时间序列(Time Series)任务的工具驱动多智能体系统，旨在解决现有方法在直觉视觉推理和自适应工具使用泛化方面的局限性。MAS4TS基于“分析者-推理者-执行者”(Analyzer-Reasoner-Executor)范式构建，将智能体通信、视觉推理(Visual Reasoning)和潜空间重建(Latent Reconstruction)集成在一个统一框架内。该系统首先利用视觉语言模型(Vision-Language Model)配合结构化先验对时间序列图进行视觉推理以提取时间结构，随后在潜空间中重建预测轨迹。框架包含三个通过共享内存和门控通信(Gated Communication)协同工作的专门智能体，并使用路由器选择任务特定的工具链进行执行。广泛的实验证明，MAS4TS在多项时间序列任务中达到了最先进的(State-of-the-art)性能，同时展现出卓越的泛化能力和推理效率。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03026v1",
      "published_date": "2026-02-03 02:48:57 UTC",
      "updated_date": "2026-02-03 02:48:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:23.329726+00:00"
    },
    {
      "arxiv_id": "2602.03025v1",
      "title": "RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents",
      "title_zh": "RC-GRPO：面向多轮工具调用智能体的奖励条件化组相对策略优化",
      "authors": [
        "Haitian Zhong",
        "Jixiu Zhai",
        "Lei Song",
        "Jiang Bian",
        "Qiang Liu",
        "Tieniu Tan"
      ],
      "abstract": "Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a group receive the all 0 or all 1 reward), making the group-normalized advantage uninformative and yielding vanishing updates. To address this problem, we propose RC-GRPO (Reward-Conditioned Group Relative Policy Optimization), which treats exploration as a controllable steering problem via discrete reward tokens. We first fine-tune a Reward-Conditioned Trajectory Policy (RCTP) on mixed-quality trajectories with reward goal special tokens (e.g., <|high_reward|>, <|low_reward|>) injected into the prompts, enabling the model to learn how to generate distinct quality trajectories on demand. Then during RL, we sample diverse reward tokens within each GRPO group and condition rollouts on the sampled token to improve within-group diversity, improving advantage gains. On the Berkeley Function Calling Leaderboard v4 (BFCLv4) multi-turn benchmark, our method yields consistently improved performance than baselines, and the performance on Qwen-2.5-7B-Instruct even surpasses all closed-source API models.",
      "tldr_zh": "该研究针对多轮工具调用(Multi-turn tool calling)中奖励稀疏和探索成本高的问题，提出了RC-GRPO (Reward-Conditioned Group Relative Policy Optimization) 框架。传统方法如SFT结合GRPO在组内奖励差异较小时，常因优势函数(Advantage)信息不足导致更新停滞。RC-GRPO通过引入离散的奖励Token将探索转化为可控的引导问题，首先在混合质量轨迹上训练奖励条件轨迹策略(Reward-Conditioned Trajectory Policy, RCTP)，使其能够根据Token生成不同质量的轨迹。在强化学习(RL)阶段，该方法通过在GRPO组内采样多样的奖励Token来引导Rollouts，显著增强了组内多样性并提升了训练效率。实验证明，该方法在Berkeley Function Calling Leaderboard v4 (BFCLv4)多轮基准测试中表现优异，基于Qwen-2.5-7B-Instruct的模型性能甚至超越了所有闭源API模型。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03025v1",
      "published_date": "2026-02-03 02:47:32 UTC",
      "updated_date": "2026-02-03 02:47:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:31.922643+00:00"
    },
    {
      "arxiv_id": "2602.03024v1",
      "title": "Consistency Deep Equilibrium Models",
      "title_zh": "一致性深层均衡模型",
      "authors": [
        "Junchao Lin",
        "Zenan Ling",
        "Jingwen Xu",
        "Robert C. Qiu"
      ],
      "abstract": "Deep Equilibrium Models (DEQs) have emerged as a powerful paradigm in deep learning, offering the ability to model infinite-depth networks with constant memory usage. However, DEQs incur significant inference latency due to the iterative nature of fixed-point solvers. In this work, we introduce the Consistency Deep Equilibrium Model (C-DEQ), a novel framework that leverages consistency distillation to accelerate DEQ inference. We cast the DEQ iterative inference process as evolution along a fixed ODE trajectory toward the equilibrium. Along this trajectory, we train C-DEQs to consistently map intermediate states directly to the fixed point, enabling few-step inference while preserving the performance of the teacher DEQ. At the same time, it facilitates multi-step evaluation to flexibly trade computation for performance gains. Extensive experiments across various domain tasks demonstrate that C-DEQs achieves consistent 2-20$\\times$ accuracy improvements over implicit DEQs under the same few-step inference budget.",
      "tldr_zh": "该研究提出了 Consistency Deep Equilibrium Model (C-DEQ)，这是一种利用一致性蒸馏 (consistency distillation) 技术加速深度平衡模型 (Deep Equilibrium Models, DEQs) 推理的新型框架。传统的 DEQs 虽然具有恒定内存消耗的优势，但受限于不动点求解器的迭代性质，推理延迟显著。C-DEQ 将 DEQ 的迭代推理过程建模为沿固定 ODE 轨迹向平衡点演化的过程，通过训练模型将中间状态直接映射到不动点，实现了在保留教师模型性能的同时进行少步推理。此外，该框架支持多步评估，允许在计算资源与性能表现之间进行灵活权衡。在多个领域任务上的实验验证了 C-DEQ 的有效性，在相同的少步推理预算下，其准确率相比隐式 DEQs 提升了 2-20 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03024v1",
      "published_date": "2026-02-03 02:42:48 UTC",
      "updated_date": "2026-02-03 02:42:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:22.840433+00:00"
    },
    {
      "arxiv_id": "2602.03022v1",
      "title": "STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models",
      "title_zh": "STAR：面向超小型函数调用模型的相似度引导与教师辅助精调",
      "authors": [
        "Jiliang Ni",
        "Jiachen Pu",
        "Zhongyi Yang",
        "Jingfeng Luo",
        "Conggang Hu"
      ],
      "abstract": "The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs' capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.",
      "tldr_zh": "该研究提出了 STAR（Similarity-guided Teacher-Assisted Refinement），这是一个旨在将 Large Language Models (LLMs) 的 function calling 能力有效迁移至 super-tiny models 的整体框架。针对现有模型训练中的过拟合与不稳定性问题，STAR 核心包含了两项技术创新：约束知识蒸馏（Constrained Knowledge Distillation, CKD）通过优化前向 KL 散度来抑制错误预测，从而在确保训练稳定的同时保留强化学习（RL）的探索能力；相似度引导强化学习（Similarity-guided RL, Sim-RL）则引入了细粒度的相似度奖励机制，为策略优化提供比传统二元奖励更丰富、连续的信号。实验表明，STAR 模型在同尺寸类别中达到了 SOTA 水平，其表现显著优于基准模型。特别地，仅有 0.6B 参数的 STAR 模型在所有 1B 以下的开源模型中取得了最佳性能，甚至超越了部分更大规模的知名模型。该研究为构建高效、易于获取的强大 AI agents 提供了重要的技术路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The paper has been accepted to ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03022v1",
      "published_date": "2026-02-03 02:41:11 UTC",
      "updated_date": "2026-02-03 02:41:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:33.814585+00:00"
    },
    {
      "arxiv_id": "2602.03019v1",
      "title": "FedKRSO: Communication and Memory Efficient Federated Fine-Tuning of Large Language Models",
      "title_zh": "FedKRSO：通信与内存高效的大语言模型联邦微调",
      "authors": [
        "Guohao Yang",
        "Tongle Wu",
        "Yuanxiong Guo",
        "Ying Sun",
        "Yanmin Gong"
      ],
      "abstract": "Fine-tuning is essential to adapt general-purpose large language models (LLMs) to domain-specific tasks. As a privacy-preserving framework to leverage decentralized data for collaborative model training, Federated Learning (FL) is gaining popularity in LLM fine-tuning, but remains challenging due to the high cost of transmitting full model parameters and computing full gradients on resource-constrained clients. While Parameter-Efficient Fine-Tuning (PEFT) methods are widely used in FL to reduce communication and memory costs, they often sacrifice model performance compared to FFT. This paper proposes FedKRSO (Federated $K$-Seed Random Subspace Optimization), a novel method that enables communication and memory efficient FFT of LLMs in federated settings. In FedKRSO, clients update the model within a shared set of random low-dimension subspaces generated by the server to save memory usage. Furthermore, instead of transmitting full model parameters in each FL round, clients send only the model update accumulators along the subspaces to the server, enabling efficient global model aggregation and dissemination. By using these strategies, FedKRSO can substantially reduce communication and memory overhead while overcoming the performance limitations of PEFT, closely approximating the performance of federated FFT. The convergence properties of FedKRSO are analyzed rigorously under general FL settings. Extensive experiments on the GLUE benchmark across diverse FL scenarios demonstrate that FedKRSO achieves both superior performance and low communication and memory overhead, paving the way towards on federated LLM fine-tuning at the resource-constrained edge.",
      "tldr_zh": "该研究提出了FedKRSO（Federated K-Seed Random Subspace Optimization），旨在解决大语言模型（LLMs）在联邦学习（Federated Learning）场景下全量微调（FFT）带来的高通信与内存开销挑战。FedKRSO允许客户端在由服务器生成的共享随机低维子空间内进行模型更新，从而显著降低内存占用。在通信方面，客户端仅需传输子空间内的模型更新累加器而非全量模型参数，大幅提升了全局模型聚合与分发的效率。理论分析证明了该方法在通用联邦学习设置下的收敛性，且在GLUE基准测试的多种联邦场景实验中，FedKRSO在保持极低资源开销的同时，克服了参数高效微调（PEFT）的性能局限，其表现接近联邦全量微调。该研究为资源受限的边缘设备进行高效且高性能的联邦大语言模型微调提供了新的技术路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by INFOCOM 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.03019v1",
      "published_date": "2026-02-03 02:39:33 UTC",
      "updated_date": "2026-02-03 02:39:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:33.230760+00:00"
    },
    {
      "arxiv_id": "2602.03012v1",
      "title": "CVE-Factory: Scaling Expert-Level Agentic Tasks for Code Security Vulnerability",
      "title_zh": "CVE-Factory：面向代码安全漏洞的专家级智能体任务规模化构建",
      "authors": [
        "Xianzhen Luo",
        "Jingyuan Zhang",
        "Shiqi Zhou",
        "Rain Huang",
        "Chuan Xiao",
        "Qingfu Zhu",
        "Zhiyuan Ma",
        "Xing Yue",
        "Yang Yue",
        "Wencong Zeng",
        "Wanxiang Che"
      ],
      "abstract": "Evaluating and improving the security capabilities of code agents requires high-quality, executable vulnerability tasks. However, existing works rely on costly, unscalable manual reproduction and suffer from outdated data distributions. To address these, we present CVE-Factory, the first multi-agent framework to achieve expert-level quality in automatically transforming sparse CVE metadata into fully executable agentic tasks. Cross-validation against human expert reproductions shows that CVE-Factory achieves 95\\% solution correctness and 96\\% environment fidelity, confirming its expert-level quality. It is also evaluated on the latest realistic vulnerabilities and achieves a 66.2\\% verified success. This automation enables two downstream contributions. First, we construct LiveCVEBench, a continuously updated benchmark of 190 tasks spanning 14 languages and 153 repositories that captures emerging threats including AI-tooling vulnerabilities. Second, we synthesize over 1,000 executable training environments, the first large-scale scaling of agentic tasks in code security. Fine-tuned Qwen3-32B improves from 5.3\\% to 35.8\\% on LiveCVEBench, surpassing Claude 4.5 Sonnet, with gains generalizing to Terminal Bench (12.5\\% to 31.3\\%). We open-source CVE-Factory, LiveCVEBench, Abacus-cve (fine-tuned model), training dataset, and leaderboard. All resources are available at https://github.com/livecvebench/CVE-Factory .",
      "tldr_zh": "该研究提出了CVE-Factory，这是首个旨在自动将稀疏的CVE metadata转化为专家级、完全可执行任务的多智能体框架，有效解决了现有漏洞基准测试依赖高成本人工复现且数据滞后的局限。交叉验证显示，CVE-Factory在解答正确率和环境保真度上分别达到95%和96%，并在最新真实漏洞测试中取得了66.2%的验证成功率。基于此框架，研究者构建了涵盖14种语言、持续更新的基准测试LiveCVEBench，并合成了超过1000个可执行的训练环境，实现了代码安全领域智能体任务的大规模扩展。实验证明，经过微调的Qwen3-32B模型在LiveCVEBench上的准确率从5.3%大幅提升至35.8%，性能超越了Claude 4.5 Sonnet，且相关能力在Terminal Bench上展现了良好的泛化性。目前，CVE-Factory、LiveCVEBench以及微调模型Abacus-cve均已开源。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2602.03012v1",
      "published_date": "2026-02-03 02:27:16 UTC",
      "updated_date": "2026-02-03 02:27:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:37.726772+00:00"
    },
    {
      "arxiv_id": "2602.03007v1",
      "title": "VOILA: Value-of-Information Guided Fidelity Selection for Cost-Aware Multimodal Question Answering",
      "title_zh": "VOILA：基于信息价值引导的成本感知多模态问答保真度选择",
      "authors": [
        "Rahul Atul Bhope",
        "K. R. Jayaram",
        "Vinod Muthusamy",
        "Ritesh Kumar",
        "Vatche Isahagian",
        "Nalini Venkatasubramanian"
      ],
      "abstract": "Despite significant costs from retrieving and processing high-fidelity visual inputs, most multimodal vision-language systems operate at fixed fidelity levels. We introduce VOILA, a framework for Value-Of-Information-driven adaptive fidelity selection in Visual Question Answering (VQA) that optimizes what information to retrieve before model execution. Given a query, VOILA uses a two-stage pipeline: a gradient-boosted regressor estimates correctness likelihood at each fidelity from question features alone, then an isotonic calibrator refines these probabilities for reliable decision-making. The system selects the minimum-cost fidelity maximizing expected utility given predicted accuracy and retrieval costs. We evaluate VOILA across three deployment scenarios using five datasets (VQA-v2, GQA, TextVQA, LoCoMo, FloodNet) and six Vision-Language Models (VLMs) with 7B-235B parameters. VOILA consistently achieves 50-60% cost reductions while retaining 90-95% of full-resolution accuracy across diverse query types and model architectures, demonstrating that pre-retrieval fidelity selection is vital to optimize multimodal inference under resource constraints.",
      "tldr_zh": "该研究针对多模态视觉语言系统在处理高保真视觉输入时面临的高昂成本问题，提出了 VOILA 框架。VOILA 是一种基于信息价值 (Value-of-Information) 驱动的自适应保真度选择框架，旨在在 Visual Question Answering (VQA) 任务的模型执行前优化信息检索策略。该框架采用两阶段流水线：首先利用梯度提升回归器 (gradient-boosted regressor) 仅根据问题特征估计各保真度下的正确性概率，随后通过等序校准器 (isotonic calibrator) 精细化这些概率以实现可靠决策。系统会根据预测准确率与检索成本，选择能够使期望效用最大化的最低成本保真度。实验在五个数据集和六个参数量在 7B-235B 之间的 Vision-Language Models (VLMs) 上进行了验证。结果显示，VOILA 在保持 90-95% 的全分辨率准确率的同时，能够减少 50-60% 的推理成本。该研究证明了检索前保真度选择在资源受限环境下优化多模态推理的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03007v1",
      "published_date": "2026-02-03 02:19:47 UTC",
      "updated_date": "2026-02-03 02:19:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:46.325526+00:00"
    },
    {
      "arxiv_id": "2602.03006v1",
      "title": "Distilling LLM Reasoning into Graph of Concept Predictors",
      "title_zh": "将 LLM 推理蒸馏为概念预测器图",
      "authors": [
        "Ziyang Yu",
        "Liang Zhao"
      ],
      "abstract": "Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.",
      "tldr_zh": "该研究针对大语言模型（LLMs）在判别任务中面临的推理延迟和高昂计算成本问题，提出了Graph of Concept Predictors (GCP)这一推理感知的主动蒸馏框架。与仅蒸馏最终标签的传统流水线不同，GCP将教师模型的决策过程外化为有向无环图（Directed Acyclic Graph, DAG），并在学生模型中通过模块化的概念预测器进行模拟。该框架采用一种图感知的采集策略，针对关键推理节点的不确定性和分歧来提高样本效率，并结合针对性的子模块重训机制以提升训练的稳定性和效率。在八项NLP分类基准测试上的实验结果证明，GCP在有限的标注预算下显著增强了模型性能，同时使训练动态更具解释性和可控性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03006v1",
      "published_date": "2026-02-03 02:19:14 UTC",
      "updated_date": "2026-02-03 02:19:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:45.522157+00:00"
    },
    {
      "arxiv_id": "2602.03004v1",
      "title": "Causal Graph Spatial-Temporal Autoencoder for Reliable and Interpretable Process Monitoring",
      "title_zh": "面向可靠且可解释过程监控的因果图时空自动编码器",
      "authors": [
        "Xiangrui Zhang",
        "Chunyue Song",
        "Wei Dai",
        "Zheng Zhang",
        "Kaihua Gao",
        "Furong Gao"
      ],
      "abstract": "To improve the reliability and interpretability of industrial process monitoring, this article proposes a Causal Graph Spatial-Temporal Autoencoder (CGSTAE). The network architecture of CGSTAE combines two components: a correlation graph structure learning module based on spatial self-attention mechanism (SSAM) and a spatial-temporal encoder-decoder module utilizing graph convolutional long-short term memory (GCLSTM). The SSAM learns correlation graphs by capturing dynamic relationships between variables, while a novel three-step causal graph structure learning algorithm is introduced to derive a causal graph from these correlation graphs. The algorithm leverages a reverse perspective of causal invariance principle to uncover the invariant causal graph from varying correlations. The spatial-temporal encoder-decoder, built with GCLSTM units, reconstructs time-series process data within a sequence-to-sequence framework. The proposed CGSTAE enables effective process monitoring and fault detection through two statistics in the feature space and residual space. Finally, we validate the effectiveness of CGSTAE in process monitoring through the Tennessee Eastman process and a real-world air separation process.",
      "tldr_zh": "该研究提出了因果图时空自编码器(Causal Graph Spatial-Temporal Autoencoder, CGSTAE)，旨在提升工业过程监控的可靠性与可解释性。CGSTAE 的架构结合了基于空间自注意力机制(SSAM)的相关图结构学习模块，以及利用图卷积长短期记忆网络(GCLSTM)的时空编码器-解码器模块。SSAM 通过捕捉变量间的动态关系来学习相关图，并引入一种三阶段因果图结构学习算法，利用因果不变性原理(Causal Invariance Principle)从变化的相关性中提取不变的因果图。基于 GCLSTM 的模块在序列到序列(Sequence-to-Sequence)框架下重建时间序列数据，并通过特征空间和残差空间的两种统计量实现高效的过程监控与故障检测。实验结果在 Tennessee Eastman 过程和真实空分过程数据上验证了 CGSTAE 的有效性，证明其能为工业系统提供更具鲁棒性的监测方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03004v1",
      "published_date": "2026-02-03 02:18:09 UTC",
      "updated_date": "2026-02-03 02:18:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:48:46.714554+00:00"
    },
    {
      "arxiv_id": "2602.03003v1",
      "title": "Methods and Open Problems in Differentiable Social Choice: Learning Mechanisms, Decisions, and Alignment",
      "title_zh": "可微社会选择的方法与开放性问题：学习机制、决策与对齐",
      "authors": [
        "Zhiyu An",
        "Wan Du"
      ],
      "abstract": "Social choice is no longer a peripheral concern of political theory or economics-it has become a foundational component of modern machine learning systems. From auctions and resource allocation to federated learning, participatory governance, and the alignment of large language models, machine learning pipelines increasingly aggregate heterogeneous preferences, incentives, and judgments into collective decisions. In effect, many contemporary machine learning systems already implement social choice mechanisms, often implicitly and without explicit normative scrutiny.\n  This Review surveys differentiable social choice: an emerging paradigm that formulates voting rules, mechanisms, and aggregation procedures as learnable, differentiable models optimized from data. We synthesize work across auctions, voting, budgeting, liquid democracy, decentralized aggregation, and inverse mechanism learning, showing how classical axioms and impossibility results reappear as objectives, constraints, and optimization trade-offs. We conclude by identifying 36 open problems defining a new research agenda at the intersection of machine learning, economics, and democratic theory.",
      "tldr_zh": "该研究综述了可微社会选择(Differentiable Social Choice)这一新兴范式，旨在将投票规则、机制和聚合程序构建为可从数据中优化的可微分模型。社会选择已成为现代机器学习(Machine Learning)系统的核心组件，广泛应用于拍卖、联邦学习(Federated Learning)以及大语言模型(Large Language Models)的对齐(Alignment)等领域。本文系统地整合了关于拍卖、投票、预算分配、流体民主(Liquid Democracy)和逆向机制学习(Inverse Mechanism Learning)的研究工作。研究进一步揭示了古典社会选择中的公理(Axioms)和不可能结果(Impossibility Results)如何演变为机器学习优化过程中的目标、约束和折中方案。最后，作者提出了定义机器学习、经济学和民主理论交叉领域研究议程的36个开放问题，为未来的学术探索提供了明确方向。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.03003v1",
      "published_date": "2026-02-03 02:17:16 UTC",
      "updated_date": "2026-02-03 02:17:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:05.335658+00:00"
    },
    {
      "arxiv_id": "2602.03001v1",
      "title": "Adaptive Batch Sizes Using Non-Euclidean Gradient Noise Scales for Stochastic Sign and Spectral Descent",
      "title_zh": "针对随机符号与谱下降的基于非欧几里得梯度噪声规模的自适应批量大小",
      "authors": [
        "Hiroki Naganuma",
        "Shagun Gupta",
        "Youssef Briki",
        "Ioannis Mitliagkas",
        "Irina Rish",
        "Parameswaran Raman",
        "Hao-Jun Michael Shi"
      ],
      "abstract": "To maximize hardware utilization, modern machine learning systems typically employ large constant or manually tuned batch size schedules, relying on heuristics that are brittle and costly to tune. Existing adaptive strategies based on gradient noise scale (GNS) offer a principled alternative. However, their assumption of SGD's Euclidean geometry creates a fundamental mismatch with popular optimizers based on generalized norms, such as signSGD / Signum ($\\ell_\\infty$) and stochastic spectral descent (specSGD) / Muon ($\\mathcal{S}_\\infty$). In this work, we derive gradient noise scales for signSGD and specSGD that naturally emerge from the geometry of their respective dual norms. To practically estimate these non-Euclidean metrics, we propose an efficient variance estimation procedure that leverages the local mini-batch gradients on different ranks in distributed data-parallel systems. Our experiments demonstrate that adaptive batch size strategies using non-Euclidean GNS enable us to match the validation loss of constant-batch baselines while reducing training steps by up to 66% for Signum and Muon on a 160 million parameter Llama model.",
      "tldr_zh": "该研究针对 signSGD/Signum ($\\ell_\\infty$) 和 specSGD/Muon ($\\mathcal{S}_\\infty$) 等基于广义范数的优化器，提出了一种利用非欧几里得梯度噪声标度(Gradient Noise Scale, GNS)来实现自适应批量大小(adaptive batch sizes)的方法。研究指出，现有的 GNS 策略通常假设 SGD 的欧几里得几何特性，这与符号下降和谱下降优化器的对偶范数(dual norms)存在根本性的几何失配。为此，作者从各自的几何特性出发，为 signSGD 和 specSGD 推导出了天然匹配的非欧几里得梯度噪声标度。同时，研究还提出了一种高效的方差估计程序，通过分布式数据并行系统中的局部小批量梯度来实践这些非欧几里得指标。实验结果表明，在 1.6 亿参数的 Llama 模型上，该自适应策略在保证验证损失的同时，使 Signum 和 Muon 的训练步数减少了高达 66%，显著提升了硬件利用率与训练效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 2 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.03001v1",
      "published_date": "2026-02-03 02:16:55 UTC",
      "updated_date": "2026-02-03 02:16:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:10.413271+00:00"
    },
    {
      "arxiv_id": "2602.02995v1",
      "title": "Agent Alpha: Tree Search Unifying Generation, Exploration and Evaluation for Computer-Use Agents",
      "title_zh": "Agent Alpha：融合生成、探索与评估的计算机操作智能体树搜索框架",
      "authors": [
        "Sizhe Tang",
        "Rongqian Chen",
        "Tian Lan"
      ],
      "abstract": "While scaling test-time compute through trajectory-level sampling has significantly improved Graphical User Interface (GUI) agents, the lack of regressive ability prevents the reuse of partial successes and the recovery from early missteps. In this paper, we introduce Agent Alpha, a unified framework that synergizes generation, exploration, and evaluation through step-level Monte Carlo Tree Search (MCTS). It enables active modeling or exploiting structures of the planning space. By integrating alpha-UCT guided search into the interaction loop, Agent Alpha enables deliberate planning, facilitating early pruning of suboptimal branches and efficient prefix reuse. We also employ comparison-driven evaluation to mitigate absolute scoring biases and diversity-constrained expansion to maintain a compact, informative search space. Regret bound of alpha-UCT is analyzed. On the OSWorld benchmark, Agent Alpha achieves a state-of-the-art success rate of $\\sim 77\\%$, significantly outperforming trajectory-level baselines under equivalent compute.",
      "tldr_zh": "该研究提出了 Agent Alpha，这是一个通过步级(step-level) Monte Carlo Tree Search (MCTS) 协同生成、探索与评估的统一框架，旨在解决图形用户界面(GUI)智能体在轨迹级采样中因缺乏回溯能力而难以从早期错误中恢复的问题。通过将 alpha-UCT 引导的搜索集成到交互循环中，Agent Alpha 实现了审慎的规划，支持对次优分支进行早期剪枝并高效重用成功路径。此外，该框架采用比较驱动的评估来减轻绝对评分偏差，并利用多样性约束扩展来维持精简且高效的搜索空间。研究团队还对 alpha-UCT 的悔值界限(Regret bound)进行了理论分析，验证了其稳定性。实验结果显示，Agent Alpha 在 OSWorld 基准测试中达到了约 77% 的成功率，刷新了 SOTA 纪录，在同等计算资源下显著优于传统的轨迹级基线模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02995v1",
      "published_date": "2026-02-03 02:07:12 UTC",
      "updated_date": "2026-02-03 02:07:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:00.736242+00:00"
    },
    {
      "arxiv_id": "2602.02991v1",
      "title": "Large Language Models Can Take False First Steps at Inference-time Planning",
      "title_zh": "大语言模型在推理时规划中可能出现首步失误",
      "authors": [
        "Haijiang Yan",
        "Jian-Qiao Zhu",
        "Adam Sanborn"
      ],
      "abstract": "Large language models (LLMs) have been shown to acquire sequence-level planning abilities during training, yet their planning behavior exhibited at inference time often appears short-sighted and inconsistent with these capabilities. We propose a Bayesian account for this gap by grounding planning behavior in the evolving generative context: given the subtle differences between natural language and the language internalized by LLMs, accumulated self-generated context drives a planning-shift during inference and thereby creates the appearance of compromised planning behavior. We further validate the proposed model through two controlled experiments: a random-generation task demonstrating constrained planning under human prompts and increasing planning strength as self-generated context accumulates, and a Gaussian-sampling task showing reduced initial bias when conditioning on self-generated sequences. These findings provide a theoretical explanation along with empirical evidence for characterizing how LLMs plan ahead during inference.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)虽然在训练中获得了序列级规划能力，但在推理过程中往往表现出短视且不一致的规划行为。作者提出了一种贝叶斯(Bayesian)视角的解释，认为自然语言与模型内化语言之间的差异导致累积的自生成上下文(self-generated context)在推理时引发了规划偏移(planning-shift)，从而造成规划能力受损的假象。通过随机生成任务和高斯采样(Gaussian-sampling)任务两项受控实验，研究证实了在人类提示词(human prompts)引导下模型的初始规划会受到约束，而随着自生成内容的增加，规划强度会随之提升并减少初始偏差。这些发现为表征LLMs在推理阶段如何进行超前规划提供了重要的理论解释与实证依据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02991v1",
      "published_date": "2026-02-03 01:54:55 UTC",
      "updated_date": "2026-02-03 01:54:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:04.120676+00:00"
    },
    {
      "arxiv_id": "2602.02988v1",
      "title": "NLI:Non-uniform Linear Interpolation Approximation of Nonlinear Operations for Efficient LLMs Inference",
      "title_zh": "NLI：面向高效大语言模型推理的非线性操作非均匀线性插值逼近",
      "authors": [
        "Jiangyong Yu",
        "Xiaomeng Han",
        "Xing Hu",
        "Chen Xu",
        "Zhe Jiang",
        "Dawei Yang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of tasks, but their deployment is often constrained by substantial memory footprints and computational costs. While prior work has achieved significant progress in compressing and accelerating linear layers, nonlinear layers-such as SiLU, RMSNorm, and Softmax-still heavily depend on high-precision floating-point operations. In this paper, we propose a calibration-free, dynamic-programming-optimal, and hardware-friendly framework called Non-uniform Linear Interpolation (NLI). NLI is capable of efficiently approximating a variety of nonlinear functions, enabling seamless integration into LLMs and other deep neural networks with almost no loss in accuracy. NLI ingeniously recasts cutpoint selection as a dynamic-programming problem, achieving the globally minimal interpolation error in O(MxN2) time via Bellman's optimality principle. Based on the NLI algorithm, we also design and implement a plug-and-play universal nonlinear computation unit. Hardware experiments demonstrate that the NLI Engine achieves more than 4x improvement in computational efficiency compared to the state-of-the-art designs.",
      "tldr_zh": "该研究针对大语言模型(LLMs)推理过程中非线性层（如SiLU、RMSNorm和Softmax）对高精度浮点运算的依赖及计算成本问题，提出了名为Non-uniform Linear Interpolation(NLI)的高效优化框架。NLI能够高效近似多种非线性函数，且具备无需校准和硬件友好的特性，可无缝集成至deep neural networks中。该框架巧妙地将插值断点选择转化为动态规划问题，利用Bellman's optimality principle在O(MxN^2)时间复杂度内实现了全局最小插值误差。研究者据此设计并实现了即插即用的通用非线性计算单元NLI Engine。硬件实验证明，NLI在几乎不损失精度的情况下，比目前最先进设计的计算效率提升了4倍以上。这一成果为解决LLMs推理阶段的计算瓶颈提供了全新的硬件友好型方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Admitted to ICLR 18pages 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.02988v1",
      "published_date": "2026-02-03 01:47:58 UTC",
      "updated_date": "2026-02-03 01:47:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:07.534077+00:00"
    },
    {
      "arxiv_id": "2602.02983v1",
      "title": "Are LLMs Biased Like Humans? Causal Reasoning as a Function of Prior Knowledge, Irrelevant Information, and Reasoning Budget",
      "title_zh": "大语言模型是否具有类人偏见？先验知识、无关信息与推理预算影响下的因果推理",
      "authors": [
        "Hanna M. Dettki",
        "Charley M. Wu",
        "Bob Rehder"
      ],
      "abstract": "Large language models (LLMs) are increasingly used in domains where causal reasoning matters, yet it remains unclear whether their judgments reflect normative causal computation, human-like shortcuts, or brittle pattern matching. We benchmark 20+ LLMs against a matched human baseline on 11 causal judgment tasks formalized by a collider structure ($C_1 \\!\\rightarrow\\! E\\! \\leftarrow \\!C_2$). We find that a small interpretable model compresses LLMs' causal judgments well and that most LLMs exhibit more rule-like reasoning strategies than humans who seem to account for unmentioned latent factors in their probability judgments. Furthermore, most LLMs do not mirror the characteristic human collider biases of weak explaining away and Markov violations. We probe LLMs' causal judgment robustness under (i) semantic abstraction and (ii) prompt overloading (injecting irrelevant text), and find that chain-of-thought (CoT) increases robustness for many LLMs. Together, this divergence suggests LLMs can complement humans when known biases are undesirable, but their rule-like reasoning may break down when uncertainty is intrinsic -- highlighting the need to characterize LLM reasoning strategies for safe, effective deployment.",
      "tldr_zh": "该研究通过对20多个大型语言模型（LLMs）在11项基于碰撞结构（collider structure）的因果判断任务中进行基准测试，评估了其推理是基于规范计算还是类人捷径。研究发现，相比于会考虑潜在因素的人类，大多数模型表现出更明显的规则化推理特征，且并未镜像出人类常见的弱解释抵消（weak explaining away）和马尔可夫违规（Markov violations）偏见。通过在语义抽象和提示词过载（prompt overloading）环境下进行压力测试，研究证实思维链（Chain-of-Thought）技术能有效提升模型因果推理的鲁棒性。这种认知差异意味着模型可以在需要规避人类固有偏见的领域与人类互补，但其规则化逻辑在面对内在不确定性时可能失效。该研究结果强调了在实际部署中表征模型推理策略的重要性，以确保其在复杂任务中的安全性和有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02983v1",
      "published_date": "2026-02-03 01:43:09 UTC",
      "updated_date": "2026-02-03 01:43:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:30.832978+00:00"
    },
    {
      "arxiv_id": "2602.02978v1",
      "title": "Structuring Value Representations via Geometric Coherence in Markov Decision Processes",
      "title_zh": "Markov 决策过程中基于几何一致性的价值表示结构化",
      "authors": [
        "Zuyuan Zhang",
        "Zeyu Fang",
        "Tian Lan"
      ],
      "abstract": "Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \\emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.",
      "tldr_zh": "该研究探讨了如何利用几何特性稳定和加速Reinforcement Learning，并从序理论(order theory)的角度提出了GCR-RL框架。该方法将价值函数估计重新构建为学习一个所需的偏序集(poset)，通过计算一系列超偏序集精炼(super-poset refinements)来确保价值函数底层的几何相干性(geometric coherence)。研究人员针对该框架开发了基于Q-learning和actor-critic的两种新型算法，并对其理论性质和收敛速度进行了深入分析。实验结果表明，GCR-RL在多项任务中显著提升了样本效率(sample efficiency)，并在性能稳定性方面展现出优于现有强基线模型的表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02978v1",
      "published_date": "2026-02-03 01:35:58 UTC",
      "updated_date": "2026-02-03 01:35:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:40.315479+00:00"
    },
    {
      "arxiv_id": "2602.02977v1",
      "title": "Aligning Forest and Trees in Images and Long Captions for Visually Grounded Understanding",
      "title_zh": "图像与长标题中全局与局部语义的对齐：实现视觉接地的理解",
      "authors": [
        "Byeongju Woo",
        "Zilin Wang",
        "Byeonghyun Pak",
        "Sangwoo Mo",
        "Stella X. Yu"
      ],
      "abstract": "Large vision-language models such as CLIP struggle with long captions because they align images and texts as undifferentiated wholes. Fine-grained vision-language understanding requires hierarchical semantics capturing both global context and localized details across visual and textual domains. Yet linguistic hierarchies from syntax or semantics rarely match visual organization, and purely visual hierarchies tend to fragment scenes into appearance-driven parts without semantic focus. We propose CAFT (Cross-domain Alignment of Forests and Trees), a hierarchical image-text representation learning framework that aligns global and local semantics across images and long captions without pixel-level supervision. Coupling a fine-to-coarse visual encoder with a hierarchical text transformer, it uses a hierarchical alignment loss that matches whole images with whole captions while biasing region-sentence correspondences, so that coarse semantics are built from fine-grained evidence rather than from aggregation untethered to part-level grounding. Trained on 30M image-text pairs, CAFT achieves state-of-the-art performance on six long-text retrieval benchmarks and exhibits strong scaling behavior. Experiments show that hierarchical cross-domain alignment enables fine-grained, visually grounded image-text representations to emerge without explicit region-level supervision.",
      "tldr_zh": "该研究提出了CAFT (Cross-domain Alignment of Forests and Trees)，这是一种旨在实现视觉接地理解(Visually grounded understanding)的分层图像-文本表征学习框架。针对 CLIP 等模型在处理长描述(Long captions)时因仅进行整体对齐而导致细粒度理解不足的问题，CAFT 通过耦合从细到粗的视觉编码器与分层文本 Transformer，捕捉跨视觉和文本领域的全局上下文与局部细节。该框架引入了分层对齐损失(Hierarchical alignment loss)，在匹配整体图像与全文的同时，诱导区域与句子之间的对应关系，确保高层语义建立在细粒度的接地证据之上。在3000万个图像-文本对上的训练结果显示，CAFT 在六项长文本检索基准测试中均达到了 SOTA 性能，并展现出强大的扩展行为。实验证明，这种跨域分层对齐机制使模型能够在无需像素级或区域级监督的情况下，自发涌现出具有视觉接地能力的细粒度图像-文本表征。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2602.02977v1",
      "published_date": "2026-02-03 01:31:55 UTC",
      "updated_date": "2026-02-03 01:31:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:20.718288+00:00"
    },
    {
      "arxiv_id": "2602.02975v1",
      "title": "Where Norms and References Collide: Evaluating LLMs on Normative Reasoning",
      "title_zh": "规范与指称的碰撞：大语言模型规范推理能力评估",
      "authors": [
        "Mitchell Abrams",
        "Kaveh Eskandari Miandoab",
        "Felix Gervits",
        "Vasanth Sarathy",
        "Matthias Scheutz"
      ],
      "abstract": "Embodied agents, such as robots, will need to interact in situated environments where successful communication often depends on reasoning over social norms: shared expectations that constrain what actions are appropriate in context. A key capability in such settings is norm-based reference resolution (NBRR), where interpreting referential expressions requires inferring implicit normative expectations grounded in physical and social context. Yet it remains unclear whether Large Language Models (LLMs) can support this kind of reasoning. In this work, we introduce SNIC (Situated Norms in Context), a human-validated diagnostic testbed designed to probe how well state-of-the-art LLMs can extract and utilize normative principles relevant to NBRR. SNIC emphasizes physically grounded norms that arise in everyday tasks such as cleaning, tidying, and serving. Across a range of controlled evaluations, we find that even the strongest LLMs struggle to consistently identify and apply social norms, particularly when norms are implicit, underspecified, or in conflict. These findings reveal a blind spot in current LLMs and highlight a key challenge for deploying language-based systems in socially situated, embodied settings.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在基于规范的指称消解(Norm-based reference resolution, NBRR)方面的推理能力，即在物理和社交语境中推断隐含规范以解释指称表达的能力。为此，研究团队引入了SNIC (Situated Norms in Context)，这是一个经过人类验证的诊断性测试平台，专注于探测模型在清洁、整理和家务服务等日常任务中提取和利用规范原则的表现。通过一系列受控评估，研究发现即使是最强大的LLMs在一致地识别和应用社交规范方面仍面临困难，尤其是在规范表现为隐含、描述不详或相互冲突的情况下。这些实验结果揭示了当前LLMs在处理复杂规范推理时的明显盲点。该论文的研究发现强调了在社交具身环境(Socially situated, embodied settings)中部署基于语言的智能系统所面临的关键挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 40th AAAI Conference on Artificial Intelligence (AAAI-26)",
      "pdf_url": "https://arxiv.org/pdf/2602.02975v1",
      "published_date": "2026-02-03 01:23:22 UTC",
      "updated_date": "2026-02-03 01:23:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:22.149901+00:00"
    },
    {
      "arxiv_id": "2602.02961v1",
      "title": "Generative Engine Optimization: A VLM and Agent Framework for Pinterest Acquisition Growth",
      "title_zh": "生成式引擎优化：一种助力 Pinterest 获客增长的 VLM 与智能体框架",
      "authors": [
        "Faye Zhang",
        "Qianyu Cheng",
        "Jasmine Wan",
        "Vishwakarma Singh",
        "Jinfeng Rao",
        "Kofi Boakye"
      ],
      "abstract": "Large Language Models are fundamentally reshaping content discovery through AI-native search systems such as ChatGPT, Gemini, and Claude. Unlike traditional search engines that match keywords to documents, these systems infer user intent, synthesize multimodal evidence, and generate contextual answers directly on the search page, introducing a paradigm shift from Search Engine Optimization (SEO) to Generative Engine Optimization (GEO). For visual content platforms hosting billions of assets, this poses an acute challenge: individual images lack the semantic depth and authority signals that generative search prioritizes, risking disintermediation as user needs are satisfied in-place without site visits.\n  We present Pinterest GEO, a production-scale framework that pioneers reverse search design: rather than generating generic image captions describing what content is, we fine-tune Vision-Language Models (VLMs) to predict what users would actually search for, augmented this with AI agents that mine real-time internet trends to capture emerging search demand. These VLM-generated queries then drive construction of semantically coherent Collection Pages via multimodal embeddings, creating indexable aggregations optimized for generative retrieval. Finally, we employ hybrid VLM and two-tower ANN architectures to build authority-aware interlinking structures that propagate signals across billions of visual assets. Deployed at scale across billions of images and tens of millions of collections, GEO delivers 20\\% organic traffic growth contributing to multi-million monthly active user (MAU) growth, demonstrating a principled pathway for visual platforms to thrive in the generative search era.",
      "tldr_zh": "该研究针对 AI 原生搜索系统引发的生成式引擎优化 (Generative Engine Optimization, GEO) 范式转变，提出了 Pinterest GEO 这一大规模生产框架，旨在解决视觉内容平台在生成式搜索时代面临的流量流失挑战。该框架采用了创新的反向搜索设计，通过微调视觉语言模型 (VLMs) 预测用户的实际搜索意图，并结合 AI 智能体 (AI Agents) 挖掘实时互联网趋势以捕捉新兴需求。研究利用多模态嵌入 (Multimodal Embeddings) 构建语义连贯且易于索引的集合页面，同时采用混合 VLM 和双塔人工神经网络 (Two-tower ANN) 架构建立了权威感知的互联结构，从而在海量视觉资产间传播权威信号。实际部署结果显示，该框架在数十亿规模的图像数据上实现了 20% 的自然流量增长，贡献了每月数百万的活跃用户 (MAU) 增量。该项工作为视觉平台在生成式搜索环境中保持竞争力并实现持续增长提供了一套系统化的路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02961v1",
      "published_date": "2026-02-03 00:58:50 UTC",
      "updated_date": "2026-02-03 00:58:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:27.129546+00:00"
    },
    {
      "arxiv_id": "2602.02960v1",
      "title": "Embodiment-Aware Generalist Specialist Distillation for Unified Humanoid Whole-Body Control",
      "title_zh": "面向统一的人形机器人全身控制的具身感知型通才-专才蒸馏",
      "authors": [
        "Quanquan Peng",
        "Yunfeng Lin",
        "Yufei Xue",
        "Jiangmiao Pang",
        "Weinan Zhang"
      ],
      "abstract": "Humanoid Whole-Body Controllers trained with reinforcement learning (RL) have recently achieved remarkable performance, yet many target a single robot embodiment. Variations in dynamics, degrees of freedom (DoFs), and kinematic topology still hinder a single policy from commanding diverse humanoids. Moreover, obtaining a generalist policy that not only transfers across embodiments but also supports richer behaviors-beyond simple walking to squatting, leaning-remains especially challenging. In this work, we tackle these obstacles by introducing EAGLE, an iterative generalist-specialist distillation framework that produces a single unified policy that controls multiple heterogeneous humanoids without per-robot reward tuning. During each cycle, embodiment-specific specialists are forked from the current generalist, refined on their respective robots, and new skills are distilled back into the generalist by training on the pooled embodiment set. Repeating this loop until performance convergence produces a robust Whole-Body Controller validated on robots such as Unitree H1, G1, and Fourier N1. We conducted experiments on five different robots in simulation and four in real-world settings. Through quantitative evaluations, EAGLE achieves high tracking accuracy and robustness compared to other methods, marking a step toward scalable, fleet-level humanoid control. See more details at https://eagle-wbc.github.io/",
      "tldr_zh": "该研究提出了EAGLE，一种用于统一的人形机器人全身控制(Whole-Body Control)的迭代式通用-专家蒸馏(Generalist-Specialist Distillation)框架。针对不同机器人形态在动力学、自由度(DoFs)和运动学拓扑上的差异导致难以通过单一策略实现多样化动作的问题，EAGLE通过从当前通用模型(Generalist)派生特定形态的专家模型(Specialists)，在各自机器人上优化后再将技能蒸馏回通用模型，且无需针对每个机器人进行奖励调优。该方法不仅支持基础行走，还能实现深蹲、倾斜等更丰富的行为。实验在Unitree H1、G1和Fourier N1等五种仿真机器人及四种真实机器人上进行了验证，结果表明EAGLE在跟踪精度和鲁棒性方面均优于现有方法。这一成果为实现可扩展的、舰队级(fleet-level)的人形机器人统一控制迈出了重要一步。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02960v1",
      "published_date": "2026-02-03 00:58:29 UTC",
      "updated_date": "2026-02-03 00:58:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:56.724939+00:00"
    },
    {
      "arxiv_id": "2602.02955v1",
      "title": "Synthetic Data Augmentation for Medical Audio Classification: A Preliminary Evaluation",
      "title_zh": "医疗音频分类中的合成数据增强：初步评估",
      "authors": [
        "David McShannon",
        "Anthony Mella",
        "Nicholas Dietrich"
      ],
      "abstract": "Medical audio classification remains challenging due to low signal-to-noise ratios, subtle discriminative features, and substantial intra-class variability, often compounded by class imbalance and limited training data. Synthetic data augmentation has been proposed as a potential strategy to mitigate these constraints; however, prior studies report inconsistent methodological approaches and mixed empirical results. In this preliminary study, we explore the impact of synthetic augmentation on respiratory sound classification using a baseline deep convolutional neural network trained on a moderately imbalanced dataset (73%:27%). Three generative augmentation strategies (variational autoencoders, generative adversarial networks, and diffusion models) were assessed under controlled experimental conditions. The baseline model without augmentation achieved an F1-score of 0.645. Across individual augmentation strategies, performance gains were not observed, with several configurations demonstrating neutral or degraded classification performance. Only an ensemble of augmented models yielded a modest improvement in F1-score (0.664). These findings suggest that, for medical audio classification, synthetic augmentation may not consistently enhance performance when applied to a standard CNN classifier. Future work should focus on delineating task-specific data characteristics, model-augmentation compatibility, and evaluation frameworks necessary for synthetic augmentation to be effective in medical audio applications.",
      "tldr_zh": "该研究针对医疗音频分类中存在的低信噪比、类别不平衡及训练数据有限等挑战，初步评估了合成数据增强（Synthetic Data Augmentation）对分类性能的实际影响。研究人员在呼吸音分类任务中，测试了变分自编码器（Variational Autoencoders, VAEs）、生成对抗网络（Generative Adversarial Networks, GANs）及扩散模型（Diffusion Models）三种生成策略对深度卷积神经网络（CNN）表现的作用。实验结果显示，未经过增强处理的基准模型 F1-score 为 0.645，而采用单一增强策略并未带来明显的性能增益，部分配置甚至导致分类性能下降。仅在通过增强模型的集成（Ensemble）处理后，F1-score 才实现了 0.664 的微弱提升。该研究表明，在医疗音频分类领域，合成数据增强并不能稳定地提高标准 CNN 分类器的性能，未来研究应侧重于探索特定任务的数据特征、模型与增强技术的兼容性以及更完善的评估框架。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2602.02955v1",
      "published_date": "2026-02-03 00:52:49 UTC",
      "updated_date": "2026-02-03 00:52:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:54.915593+00:00"
    },
    {
      "arxiv_id": "2602.02952v1",
      "title": "UAT-LITE: Inference-Time Uncertainty-Aware Attention for Pretrained Transformers",
      "title_zh": "UAT-LITE：面向预训练 Transformer 的推理时不确定性感知注意力机制",
      "authors": [
        "Elias Hossain",
        "Shubhashis Roy Dipta",
        "Subash Neupane",
        "Rajib Rana",
        "Ravid Shwartz-Ziv",
        "Ivan Garibay",
        "Niloofar Yousefi"
      ],
      "abstract": "Neural NLP models are often miscalibrated, assigning high confidence to incorrect predictions, which undermines selective prediction and high-stakes deployment. Post-hoc calibration methods adjust output probabilities but leave internal computation unchanged, while ensemble and Bayesian approaches improve uncertainty at substantial training or storage cost. We propose UAT-LITE, an inference-time framework that makes self-attention uncertainty-aware using approximate Bayesian inference via Monte Carlo dropout in pretrained transformer classifiers. Token-level epistemic uncertainty is estimated from stochastic forward passes and used to modulate self-attention during contextualization, without modifying pretrained weights or training objectives. We additionally introduce a layerwise variance decomposition to diagnose how predictive uncertainty accumulates across transformer depth. Across the SQuAD 2.0 answerability, MNLI, and SST-2, UAT-LITE reduces Expected Calibration Error by approximately 20% on average relative to a fine-tuned BERT-base baseline while preserving task accuracy, and improves selective prediction and robustness under distribution shift.",
      "tldr_zh": "该研究提出了 UAT-LITE，一种针对预训练 Transformer 模型的推理阶段不确定性感知注意力框架，旨在解决神经 NLP 模型因校准失准(Miscalibration)导致对错误预测分配高置信度的问题。该框架通过在预训练分类器中应用蒙特卡洛随机失活(Monte Carlo dropout)进行近似贝叶斯推理，在不修改权重或训练目标的前提下，从随机前向传播中估计令牌级认知不确定性(Token-level epistemic uncertainty)并据此调节自注意力(Self-attention)机制。研究还引入了层级方差分解(Layerwise variance decomposition)来诊断预测不确定性随模型深度的累积情况。实验表明，UAT-LITE 在 SQuAD 2.0、MNLI 和 SST-2 任务上比 BERT-base 基线平均降低了约 20% 的期望校准误差(Expected Calibration Error)。在保持原有任务准确性的同时，该方法显著提升了模型在分布偏移(Distribution shift)下的鲁棒性和选择性预测性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02952v1",
      "published_date": "2026-02-03 00:51:26 UTC",
      "updated_date": "2026-02-03 00:51:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:49:59.535087+00:00"
    },
    {
      "arxiv_id": "2602.02951v1",
      "title": "Nüwa: Mending the Spatial Integrity Torn by VLM Token Pruning",
      "title_zh": "Nüwa：弥合 VLM Token 剪枝造成的空间完整性破坏",
      "authors": [
        "Yihong Huang",
        "Fei Ma",
        "Yihua Shao",
        "Jingcai Guo",
        "Zitong Yu",
        "Laizhong Cui",
        "Qi Tian"
      ],
      "abstract": "Vision token pruning has proven to be an effective acceleration technique for the efficient Vision Language Model (VLM). However, existing pruning methods demonstrate excellent performance preservation in visual question answering (VQA) and suffer substantial degradation on visual grounding (VG) tasks. Our analysis of the VLM's processing pipeline reveals that strategies utilizing global semantic similarity and attention scores lose the global spatial reference frame, which is derived from the interactions of tokens' positional information. Motivated by these findings, we propose $\\text{Nüwa}$, a two-stage token pruning framework that enables efficient feature aggregation while maintaining spatial integrity. In the first stage, after the vision encoder, we apply three operations, namely separation, alignment, and aggregation, which are inspired by swarm intelligence algorithms to retain information-rich global spatial anchors. In the second stage, within the LLM, we perform text-guided pruning to retain task-relevant visual tokens. Extensive experiments demonstrate that $\\text{Nüwa}$ achieves SOTA performance on multiple VQA benchmarks (from 94% to 95%) and yields substantial improvements on visual grounding tasks (from 7% to 47%).",
      "tldr_zh": "该研究针对 Vision Language Model (VLM) 在进行 Vision token pruning 时面临的视觉定位 (Visual Grounding, VG) 性能大幅下降的问题，提出了名为 Nüwa 的两阶段 Token 修剪框架。通过分析发现，现有的基于全局语义相似度和注意力分数的修剪策略破坏了全局空间参考框架，导致模型失去了基于位置信息交互的空间完整性。Nüwa 框架在第一阶段受群智算法 (Swarm Intelligence Algorithms) 启发，在 Vision encoder 后执行分离、对齐和聚合三项操作，以保留富含信息的全局空间锚点。在第二阶段中，该框架在 LLM 内部实施文本引导的修剪 (Text-guided Pruning)，从而精准保留与具体任务相关的视觉 Token。实验结果表明，Nüwa 在多个 VQA 基准测试上达到了 SOTA 性能，并将视觉定位任务的准确率从 7% 大幅提升至 47%。这项工作成功地在保持模型高效特征聚合的同时，有效弥补了 Token 修剪对空间完整性造成的破坏，为构建高效且鲁棒的视觉语言模型提供了新方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02951v1",
      "published_date": "2026-02-03 00:51:03 UTC",
      "updated_date": "2026-02-03 00:51:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:00.026221+00:00"
    },
    {
      "arxiv_id": "2602.02932v1",
      "title": "Equal Access, Unequal Interaction: A Counterfactual Audit of LLM Fairness",
      "title_zh": "访问平等，交互不均：大语言模型公平性的反事实审计",
      "authors": [
        "Alireza Amiri-Margavi",
        "Arshia Gharagozlou",
        "Amin Gholami Davodi",
        "Seyed Pouyan Mousavi Davoudi",
        "Hamidreza Hasani Balyani"
      ],
      "abstract": "Prior work on fairness in large language models (LLMs) has primarily focused on access-level behaviors such as refusals and safety filtering. However, equitable access does not ensure equitable interaction quality once a response is provided. In this paper, we conduct a controlled fairness audit examining how LLMs differ in tone, uncertainty, and linguistic framing across demographic identities after access is granted. Using a counterfactual prompt design, we evaluate GPT-4 and LLaMA-3.1-70B on career advice tasks while varying identity attributes along age, gender, and nationality. We assess access fairness through refusal analysis and measure interaction quality using automated linguistic metrics, including sentiment, politeness, and hedging. Identity-conditioned differences are evaluated using paired statistical tests. Both models exhibit zero refusal rates across all identities, indicating uniform access. Nevertheless, we observe systematic, model-specific disparities in interaction quality: GPT-4 expresses significantly higher hedging toward younger male users, while LLaMA exhibits broader sentiment variation across identity groups. These results show that fairness disparities can persist at the interaction level even when access is equal, motivating evaluation beyond refusal-based audits.",
      "tldr_zh": "该研究对大语言模型(LLMs)的公平性进行了反事实审计(Counterfactual Audit)，重点探讨了在获得平等访问权限后，模型在语气、不确定性和语言框架等交互质量方面的差异。研究人员使用反事实提示设计(Counterfactual Prompt Design)，在职业建议任务中对GPT-4和LLaMA-3.1-70B进行了评估，变量涵盖年龄、性别和国籍等人口统计学特征。实验结果显示，尽管两种模型在所有身份特征下的拒绝率均为零，实现了访问层面的公平，但在交互质量上仍存在系统性的模型特定差异。具体而言，GPT-4在面对年轻男性用户时表现出显著更高的对冲(Hedging)倾向，而LLaMA在不同身份群体间则表现出更广泛的情感(Sentiment)波动。这些发现表明，即使在访问权限平等的情况下，交互层面的公平性差异依然存在，这促使研究者在未来的评估中需超越传统的基于拒绝率的审计模式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2602.02932v1",
      "published_date": "2026-02-03 00:05:38 UTC",
      "updated_date": "2026-02-03 00:05:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:06.927581+00:00"
    },
    {
      "arxiv_id": "2602.02929v1",
      "title": "RPG-AE: Neuro-Symbolic Graph Autoencoders with Rare Pattern Mining for Provenance-Based Anomaly Detection",
      "title_zh": "RPG-AE：结合罕见模式挖掘的神经符号图自编码器，用于基于溯源的异常检测",
      "authors": [
        "Asif Tauhid",
        "Sidahmed Benabderrahmane",
        "Mohamad Altrabulsi",
        "Ahamed Foisal",
        "Talal Rahwan"
      ],
      "abstract": "Advanced Persistent Threats (APTs) are sophisticated, long-term cyberattacks that are difficult to detect because they operate stealthily and often blend into normal system behavior. This paper presents a neuro-symbolic anomaly detection framework that combines a Graph Autoencoder (GAE) with rare pattern mining to identify APT-like activities in system-level provenance data. Our approach first constructs a process behavioral graph using k-Nearest Neighbors based on feature similarity, then learns normal relational structure using a Graph Autoencoder. Anomaly candidates are identified through deviations between observed and reconstructed graph structure. To further improve detection, we integrate an rare pattern mining module that discovers infrequent behavioral co-occurrences and uses them to boost anomaly scores for processes exhibiting rare signatures. We evaluate the proposed method on the DARPA Transparent Computing datasets and show that rare-pattern boosting yields substantial gains in anomaly ranking quality over the baseline GAE. Compared with existing unsupervised approaches on the same benchmark, our single unified model consistently outperforms individual context-based detectors and achieves performance competitive with ensemble aggregation methods that require multiple separate detectors. These results highlight the value of coupling graph-based representation learning with classical pattern mining to improve both effectiveness and interpretability in provenance-based security anomaly detection.",
      "tldr_zh": "该研究针对高级持续性威胁(APTs)隐蔽性强且难以检测的问题，提出了名为RPG-AE的神经符号异常检测框架，将图自动编码器(Graph Autoencoder, GAE)与稀有模式挖掘相结合。该方法首先利用基于特征相似性的k-Nearest Neighbors (k-NN)构建进程行为图，并通过GAE学习系统级溯源数据的正常关系结构，利用观测结构与重建结构间的偏差识别异常。为了进一步优化检测效果，RPG-AE集成了稀有模式挖掘(Rare Pattern Mining)模块，通过识别不频繁的行为共现来增强异常评分。在DARPA Transparent Computing数据集上的实验表明，稀有模式增强技术显著提升了异常排序质量。相比于现有的无监督方法，该统一模型不仅优于单个上下文检测器，在性能上更可与复杂的集成方法(Ensemble aggregation methods)相媲美。该成果突显了图表示学习与传统模式挖掘相结合在提升安全异常检测有效性与可解释性方面的巨大价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02929v1",
      "published_date": "2026-02-03 00:02:37 UTC",
      "updated_date": "2026-02-03 00:02:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:06.736295+00:00"
    },
    {
      "arxiv_id": "2602.02925v1",
      "title": "Refining Decision Boundaries In Anomaly Detection Using Similarity Search Within the Feature Space",
      "title_zh": "利用特征空间相似性搜索优化异常检测中的决策边界",
      "authors": [
        "Sidahmed Benabderrahmane",
        "Petko Valtchev",
        "James Cheney",
        "Talal Rahwan"
      ],
      "abstract": "Detecting rare and diverse anomalies in highly imbalanced datasets-such as Advanced Persistent Threats (APTs) in cybersecurity-remains a fundamental challenge for machine learning systems. Active learning offers a promising direction by strategically querying an oracle to minimize labeling effort, yet conventional approaches often fail to exploit the intrinsic geometric structure of the feature space for model refinement. In this paper, we introduce SDA2E, a Sparse Dual Adversarial Attention-based AutoEncoder designed to learn compact and discriminative latent representations from imbalanced, high-dimensional data. We further propose a similarity-guided active learning framework that integrates three novel strategies to refine decision boundaries efficiently: mormal-like expansion, which enriches the training set with points similar to labeled normals to improve reconstruction fidelity; anomaly-like prioritization, which boosts ranking accuracy by focusing on points resembling known anomalies; and a hybrid strategy that combines both for balanced model refinement and ranking. A key component of our framework is a new similarity measure, Normalized Matching 1s (SIM_NM1), tailored for sparse binary embeddings. We evaluate SDA2E extensively across 52 imbalanced datasets, including multiple DARPA Transparent Computing scenarios, and benchmark it against 15 state-of-the-art anomaly detection methods. Results demonstrate that SDA2E consistently achieves superior ranking performance (nDCG up to 1.0 in several cases) while reducing the required labeled data by up to 80% compared to passive training. Statistical tests confirm the significance of these improvements. Our work establishes a robust, efficient, and statistically validated framework for anomaly detection that is particularly suited to cybersecurity applications such as APT detection.",
      "tldr_zh": "该研究针对网络安全领域中高级持续性威胁(APTs)等高度不平衡数据集的异常检测难题，提出了SDA2E，一种基于稀疏对偶对抗注意力自编码器(Sparse Dual Adversarial Attention-based AutoEncoder)的框架。SDA2E通过从高维数据中学习紧凑且具有判别力的潜空间表示，并结合相似度引导的主动学习(Active learning)策略，包括normal-like expansion、anomaly-like prioritization及混合策略，实现了对决策边界的高效精炼。研究还引入了一种专门用于稀疏二进制嵌入的相似性度量指标SIM_NM1(Normalized Matching 1s)，以增强模型在特征空间内的搜索与重构能力。在涉及52个不平衡数据集（如DARPA Transparent Computing场景）的实验中，SDA2E相较于15种SOTA模型在减少多达80%标注需求的同时，显著提升了nDCG等排序性能指标。该工作为网络安全中的异常检测提供了一个稳健且高效的统计验证框架，证明了利用特征空间几何结构优化模型性能的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02925v1",
      "published_date": "2026-02-02 23:55:08 UTC",
      "updated_date": "2026-02-02 23:55:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:09.139167+00:00"
    },
    {
      "arxiv_id": "2602.02919v1",
      "title": "DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution",
      "title_zh": "DeltaEvolve：基于动量驱动演化加速科学发现",
      "authors": [
        "Jiachen Jiang",
        "Tianyu Ding",
        "Zhihui Zhu"
      ],
      "abstract": "LLM-driven evolutionary systems have shown promise for automated science discovery, yet existing approaches such as AlphaEvolve rely on full-code histories that are context-inefficient and potentially provide weak evolutionary guidance. In this work, we first formalize the evolutionary agents as a general Expectation-Maximization framework, where the language model samples candidate programs (E-step) and the system updates the control context based on evaluation feedback (M-step). Under this view, constructing context via full-code snapshots constitutes a suboptimal M-step, as redundant implement details dilutes core algorithmic ideas, making it difficult to provide clear inspirations for evolution. To address this, we propose DeltaEvolve, a momentum-driven evolutionary framework that replaces full-code history with structured semantic delta capturing how and why modifications between successive nodes affect performance. As programs are often decomposable, semantic delta usually contains many effective components which are transferable and more informative to drive improvement. By organizing semantic delta through multi-level database and progressive disclosure mechanism, input tokens are further reduced. Empirical evaluations on tasks across diverse scientific domains show that our framework can discover better solution with less token consumption over full-code-based evolutionary agents.",
      "tldr_zh": "该研究提出了DeltaEvolve，一种动量驱动的演化框架，旨在解决现有大语言模型（LLM）驱动的自动科学发现系统因依赖完整代码历史而导致的上下文效率低下问题。研究者首先将演化智能体形式化为通用的期望最大化（Expectation-Maximization, EM）框架，指出使用全代码快照会因冗余细节稀释核心思想，从而构成次优的M步（M-step）。DeltaEvolve采用结构化语义增量（semantic delta）取代代码历史，通过捕捉代码修改与性能变化之间的逻辑关系，提取出更具启发性和可迁移性的有效组件。此外，该框架结合多级数据库和渐进式披露机制（progressive disclosure mechanism），进一步降低了输入标记（tokens）的消耗。在多个科学领域任务的实验表明，DeltaEvolve能够以更少的Token消耗发现比AlphaEvolve等基线模型更优的解决方案，显著提升了自动化科学探索的效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02919v1",
      "published_date": "2026-02-02 23:47:54 UTC",
      "updated_date": "2026-02-02 23:47:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:22.631801+00:00"
    },
    {
      "arxiv_id": "2602.02918v1",
      "title": "A Multi-scale Linear-time Encoder for Whole-Slide Image Analysis",
      "title_zh": "面向全扫描切片图像分析的多尺度线性时间编码器",
      "authors": [
        "Jagan Mohan Reddy Dwarampudi",
        "Joshua Wong",
        "Hien Van Nguyen",
        "Tania Banerjee"
      ],
      "abstract": "We introduce Multi-scale Adaptive Recurrent Biomedical Linear-time Encoder (MARBLE), the first \\textit{purely Mamba-based} multi-state multiple instance learning (MIL) framework for whole-slide image (WSI) analysis. MARBLE processes multiple magnification levels in parallel and integrates coarse-to-fine reasoning within a linear-time state-space model, efficiently capturing cross-scale dependencies with minimal parameter overhead. WSI analysis remains challenging due to gigapixel resolutions and hierarchical magnifications, while existing MIL methods typically operate at a single scale and transformer-based approaches suffer from quadratic attention costs. By coupling parallel multi-scale processing with linear-time sequence modeling, MARBLE provides a scalable and modular alternative to attention-based architectures. Experiments on five public datasets show improvements of up to \\textbf{6.9\\%} in AUC, \\textbf{20.3\\%} in accuracy, and \\textbf{2.3\\%} in C-index, establishing MARBLE as an efficient and generalizable framework for multi-scale WSI analysis.",
      "tldr_zh": "该研究提出了MARBLE，这是首个纯基于Mamba的多状态多实例学习(MIL)框架，专门用于全扫描病理图像(WSI)分析。该框架通过并行处理多个放大倍率，并在线性时间状态空间模型中整合由粗到细的推理，从而以极小的参数开销高效捕捉跨尺度依赖关系。针对WSI分析中超高分辨率和分层放大带来的计算压力，MARBLE利用线性时间序列建模克服了传统Transformer架构中二次方注意力成本的局限。实验在五个公共数据集上进行，结果显示MARBLE在AUC上最高提升了6.9%，准确率提升了20.3%，C-index提升了2.3%。这些结果确立了MARBLE作为一种高效且泛化能力强的多尺度WSI分析框架，为医疗影像处理提供了具有扩展性的模块化替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.TO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ISBI 2026, 4 pages with 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.02918v1",
      "published_date": "2026-02-02 23:47:07 UTC",
      "updated_date": "2026-02-02 23:47:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:11.719665+00:00"
    },
    {
      "arxiv_id": "2602.02912v1",
      "title": "Notes on the Reward Representation of Posterior Updates",
      "title_zh": "论后验更新的奖励表示",
      "authors": [
        "Pedro A. Ortega"
      ],
      "abstract": "Many ideas in modern control and reinforcement learning treat decision-making as inference: start from a baseline distribution and update it when a signal arrives. We ask when this can be made literal rather than metaphorical. We study the special case where a KL-regularized soft update is exactly a Bayesian posterior inside a single fixed probabilistic model, so the update variable is a genuine channel through which information is transmitted. In this regime, behavioral change is driven only by evidence carried by that channel: the update must be explainable as an evidence reweighing of the baseline. This yields a sharp identification result: posterior updates determine the relative, context-dependent incentive signal that shifts behavior, but they do not uniquely determine absolute rewards, which remain ambiguous up to context-specific baselines. Requiring one reusable continuation value across different update directions adds a further coherence constraint linking the reward descriptions associated with different conditioning orders.",
      "tldr_zh": "该研究探讨了现代控制和强化学习中将决策视为推理的视角，重点研究了KL-regularized软更新在何种条件下可以精确等同于单一固定概率模型中的Bayesian posterior更新。在这种机制下，行为的变化完全由通道传输的证据驱动，即更新可以被解释为对基准分布的证据重加权（evidence reweighing）。研究得出了一个明确的识别结果：Posterior updates决定了改变行为的相对且依赖于上下文的激励信号，但无法唯一确定绝对Rewards，绝对奖励在特定上下文的基准下仍具有歧义性。此外，研究还指出，若要求在不同更新方向上使用统一的可重用Continuation value，则会引入进一步的一致性约束，从而将与不同条件顺序相关的奖励描述联系起来。该工作为理解决策制定中的信息传输与奖励表示提供了深刻的理论见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical report, 9 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.02912v1",
      "published_date": "2026-02-02 23:37:39 UTC",
      "updated_date": "2026-02-02 23:37:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:21.638908+00:00"
    },
    {
      "arxiv_id": "2602.02909v1",
      "title": "Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs",
      "title_zh": "推理之推理：大语言模型中链式思维 Token 复杂度的 BAPO 边界",
      "authors": [
        "Kiran Tomlinson",
        "Tobias Schnabel",
        "Adith Swaminathan",
        "Jennifer Neville"
      ],
      "abstract": "Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $Ω(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)通过链式思维(Chain-of-Thought, CoT)推理在推理时间缩放(Inference-time scaling)时面临的延迟与计算成本问题。为了量化解决任务所需的推理token数量，研究者扩展了有界注意力前缀预测器(bounded attention prefix oracle, BAPO)模型。理论证明表明，在处理二进制多数、三元组匹配和图可达性这三项BAPO-hard任务时，所需的CoT tokens下界为$Ω(n)$，即与输入规模$n$呈线性增长。研究还通过显式构造提供了匹配或接近匹配的复杂度上界。对前沿推理模型的实验结果显示，这些任务在实际运行中确实呈现近似线性的推理token缩放特征，且在计算预算不足时会导致任务失败。这项工作识别了CoT在推理时间计算中的基本瓶颈，并为分析和确定最优推理长度提供了一个原则性的理论工具。",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.02909v1",
      "published_date": "2026-02-02 23:33:34 UTC",
      "updated_date": "2026-02-02 23:33:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:36.315506+00:00"
    },
    {
      "arxiv_id": "2602.02908v1",
      "title": "A Random Matrix Theory Perspective on the Consistency of Diffusion Models",
      "title_zh": "随机矩阵理论视角下的扩散模型一致性",
      "authors": [
        "Binxu Wang",
        "Jacob Zavatone-Veth",
        "Cengiz Pehlevan"
      ],
      "abstract": "Diffusion models trained on different, non-overlapping subsets of a dataset often produce strikingly similar outputs when given the same noise seed. We trace this consistency to a simple linear effect: the shared Gaussian statistics across splits already predict much of the generated images. To formalize this, we develop a random matrix theory (RMT) framework that quantifies how finite datasets shape the expectation and variance of the learned denoiser and sampling map in the linear setting. For expectations, sampling variability acts as a renormalization of the noise level through a self-consistent relation $σ^2 \\mapsto κ(σ^2)$, explaining why limited data overshrink low-variance directions and pull samples toward the dataset mean. For fluctuations, our variance formulas reveal three key factors behind cross-split disagreement: \\textit{anisotropy} across eigenmodes, \\textit{inhomogeneity} across inputs, and overall scaling with dataset size. Extending deterministic-equivalence tools to fractional matrix powers further allows us to analyze entire sampling trajectories. The theory sharply predicts the behavior of linear diffusion models, and we validate its predictions on UNet and DiT architectures in their non-memorization regime, identifying where and how samples deviates across training data split. This provides a principled baseline for reproducibility in diffusion training, linking spectral properties of data to the stability of generative outputs.",
      "tldr_zh": "该研究探讨了在不同非重叠数据子集上训练的 Diffusion models 为何在相同噪声种子下会产生高度一致的输出，并将其归因于共享的 Gaussian 统计特性。作者开发了一个 Random Matrix Theory (RMT) 框架，用于量化有限数据集在线性设置下如何影响 Denoiser 和采样映射的期望与方差。研究发现采样变异性通过自洽关系 $σ^2 \\mapsto κ(σ^2)$ 导致噪声水平重归一化，解释了有限数据如何诱导模型在低方差方向过度收缩并将样本拉向均值。针对不同数据划分产生的不一致性，该理论揭示了特征模态的 Anisotropy、输入的 Inhomogeneity 以及数据集规模是三个关键影响因素。通过将 Deterministic-equivalence 工具扩展至分数矩阵幂，该框架实现了对完整采样轨迹的分析。实验在 UNet 和 DiT 架构上验证了理论预测，揭示了样本在不同训练数据划分下的偏离方式。该研究为 Diffusion 模型训练的可重复性提供了理论基础，并将数据的谱特性与生成输出的稳定性联系起来。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "65 pages; 53 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.02908v1",
      "published_date": "2026-02-02 23:30:28 UTC",
      "updated_date": "2026-02-02 23:30:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:37.029759+00:00"
    },
    {
      "arxiv_id": "2602.02905v1",
      "title": "FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights",
      "title_zh": "FIRE-Bench：评估智能体再发现科学见解的能力",
      "authors": [
        "Zhen Wang",
        "Fan Bai",
        "Zhongyan Luo",
        "Jinyan Su",
        "Kaiser Sun",
        "Xinle Yu",
        "Jieyuan Liu",
        "Kun Zhou",
        "Claire Cardie",
        "Mark Dredze",
        "Eric P. Xing",
        "Zhiting Hu"
      ],
      "abstract": "Autonomous agents powered by large language models (LLMs) promise to accelerate scientific discovery end-to-end, but rigorously evaluating their capacity for verifiable discovery remains a central challenge. Existing benchmarks face a trade-off: they either heavily rely on LLM-as-judge evaluations of automatically generated research outputs or optimize convenient yet isolated performance metrics that provide coarse proxies for scientific insight. To address this gap, we introduce FIRE-Bench (Full-cycle Insight Rediscovery Evaluation), a benchmark that evaluates agents through the rediscovery of established findings from recent, high-impact machine learning research. Agents are given only a high-level research question extracted from a published, verified study and must autonomously explore ideas, design experiments, implement code, execute their plans, and derive conclusions supported by empirical evidence. We evaluate a range of state-of-the-art agents with frontier LLMs backbones like gpt-5 on FIRE-Bench. Our results show that full-cycle scientific research remains challenging for current agent systems: even the strongest agents achieve limited rediscovery success (<50 F1), exhibit high variance across runs, and display recurring failure modes in experimental design, execution, and evidence-based reasoning. FIRE-Bench provides a rigorous and diagnostic framework for measuring progress toward reliable agent-driven scientific discovery.",
      "tldr_zh": "该研究针对现有大语言模型（LLMs）驱动的自主智能体在科学发现评估中存在的指标粗糙或过度依赖 LLM-as-judge 等局限性，提出了 FIRE-Bench (Full-cycle Insight Rediscovery Evaluation) 评测基准。该基准通过要求智能体重新发现高影响力机器学习（ML）研究中已确立的发现，来严谨地评估其验证性发现能力。智能体在仅获知高层次研究问题的情况下，需自主完成想法探索、实验设计、代码实现、执行计划并推导出基于经验证据的结论。实验利用 gpt-5 等前沿模型底座对多种智能体进行了评估，结果表明全周期科学研究对当前系统仍极具挑战，最强智能体的成功率 F1 分数不足 50。研究发现这些智能体在实验设计、执行及证据推理方面存在显著的失败模式和高方差，这表明 FIRE-Bench 为衡量可靠的智能体驱动科学发现（Agent-driven scientific discovery）的进展提供了一个严谨且具有诊断价值的框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 4 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.02905v1",
      "published_date": "2026-02-02 23:21:13 UTC",
      "updated_date": "2026-02-02 23:21:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:47.844432+00:00"
    },
    {
      "arxiv_id": "2602.02903v1",
      "title": "Spatiotemporal Decision Transformer for Traffic Coordination",
      "title_zh": "面向交通协调的时空决策 Transformer",
      "authors": [
        "Haoran Su",
        "Yandong Sun",
        "Hanxiao Deng"
      ],
      "abstract": "Traffic signal control is a critical challenge in urban transportation, requiring coordination among multiple intersections to optimize network-wide traffic flow. While reinforcement learning has shown promise for adaptive signal control, existing methods struggle with multi-agent coordination and sample efficiency. We introduce MADT (Multi-Agent Decision Transformer), a novel approach that reformulates multi-agent traffic signal control as a sequence modeling problem. MADT extends the Decision Transformer paradigm to multi-agent settings by incorporating: (1) a graph attention mechanism for modeling spatial dependencies between intersections, (2) a|temporal transformer encoder for capturing traffic dynamics, and (3) return-to-go conditioning for target performance specification. Our approach enables offline learning from historical traffic data, with architecture design that facilitates potential online fine-tuning. Experiments on synthetic grid networks and real-world traffic scenarios demonstrate that MADT achieves state-of-the-art performance, reducing average travel time by 5-6% compared to the strongest baseline while exhibiting superior coordination among adjacent intersections.",
      "tldr_zh": "该研究提出了MADT (Multi-Agent Decision Transformer)，将多智能体交通信号控制重新表述为序列建模问题，以解决城市交通中的协调挑战和样本效率问题。该框架扩展了Decision Transformer范式，引入了用于建模空间依赖性的graph attention mechanism和捕捉交通动态的temporal transformer encoder。通过采用return-to-go conditioning技术，MADT能够实现从历史数据中进行离线学习，并具备在线微调的潜力。在合成网格和真实交通场景的实验中，MADT比最强基线模型缩短了5-6%的平均旅行时间，达到了State-of-the-art性能。研究结果表明，该方法在相邻交叉路口的协同调度方面表现卓越，显著优化了网络级交通流。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02903v1",
      "published_date": "2026-02-02 23:19:13 UTC",
      "updated_date": "2026-02-02 23:19:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:53.116194+00:00"
    },
    {
      "arxiv_id": "2602.02902v1",
      "title": "Minimal Computational Preconditions for Subjective Perspective in Artificial Agents",
      "title_zh": "人工智能体主观视角的最小计算前提",
      "authors": [
        "Hongju Pae"
      ],
      "abstract": "This study operationalizes subjective perspective in artificial agents by grounding it in a minimal, phenomenologically motivated internal structure. The perspective is implemented as a slowly evolving global latent state that modulates fast policy dynamics without being directly optimized for behavioral consequences. In a reward-free environment with regime shifts, this latent structure exhibits direction-dependent hysteresis, while policy-level behavior remains comparatively reactive. I argue that such hysteresis constitutes a measurable signature of perspective-like subjectivity in machine systems.",
      "tldr_zh": "该研究通过一种受现象学启发的最小内部结构，实现了人工智能体中 subjective perspective（主观视角）的运算化。该视角被设计为一个缓慢演化的 global latent state（全局潜在状态），用于调节 fast policy dynamics（快速策略动态），且其演化过程并不针对行为后果进行直接优化。在存在 regime shifts（机制切换）的 reward-free environment（无奖励环境）实验中，该潜在结构展现出了 direction-dependent hysteresis（方向依赖的迟滞现象），而策略层面的行为则表现为相对的反应式。研究论证了这种迟滞现象可以作为机器系统中视角式主观性的一种可测量特征，为理解人工系统的内在状态提供了计算基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02902v1",
      "published_date": "2026-02-02 23:18:10 UTC",
      "updated_date": "2026-02-02 23:18:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:47.226926+00:00"
    },
    {
      "arxiv_id": "2602.02900v1",
      "title": "Manifold-Constrained Energy-Based Transition Models for Offline Reinforcement Learning",
      "title_zh": "面向离线强化学习的流形约束能量基转移模型",
      "authors": [
        "Zeyu Fang",
        "Zuyuan Zhang",
        "Mahdi Imani",
        "Tian Lan"
      ],
      "abstract": "Model-based offline reinforcement learning is brittle under distribution shift: policy improvement drives rollouts into state--action regions weakly supported by the dataset, where compounding model error yields severe value overestimation. We propose Manifold-Constrained Energy-based Transition Models (MC-ETM), which train conditional energy-based transition models using a manifold projection--diffusion negative sampler. MC-ETM learns a latent manifold of next states and generates near-manifold hard negatives by perturbing latent codes and running Langevin dynamics in latent space with the learned conditional energy, sharpening the energy landscape around the dataset support and improving sensitivity to subtle out-of-distribution deviations. For policy optimization, the learned energy provides a single reliability signal: rollouts are truncated when the minimum energy over sampled next states exceeds a threshold, and Bellman backups are stabilized via pessimistic penalties based on Q-value-level dispersion across energy-guided samples. We formalize MC-ETM through a hybrid pessimistic MDP formulation and derive a conservative performance bound separating in-support evaluation error from truncation risk. Empirically, MC-ETM improves multi-step dynamics fidelity and yields higher normalized returns on standard offline control benchmarks, particularly under irregular dynamics and sparse data coverage.",
      "tldr_zh": "该研究针对模型化离线强化学习 (Model-based offline reinforcement learning) 在分布偏移 (distribution shift) 下容易产生模型误差和价值高估的问题，提出了流形约束的基于能量的转移模型 (MC-ETM)。MC-ETM 通过流形投影-扩散负采样器 (manifold projection--diffusion negative sampler) 学习下一状态的潜流形 (latent manifold)，并利用 Langevin dynamics 在潜空间生成硬负样本，从而强化数据集支撑区域周围的能量景观并提高对分布外偏差的敏感性。该模型在策略优化中利用学习到的能量作为可靠性信号，当采样状态的最小能量超过阈值时截断 rollout，并通过基于能量引导样本的 Q 值分散度实施悲观惩罚 (pessimistic penalties) 来稳定 Bellman backups。研究通过一种混合悲观 MDP 公式化了 MC-ETM，并推导出了一个将支撑内评估误差与截断风险区分开的保守性能界限。实验结果表明，MC-ETM 显著提高了多步动力学的保真度，在标准离线控制基准测试中获得了更高的归一化收益，特别是在动力学不规则和数据覆盖稀疏的场景下表现优异。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02900v1",
      "published_date": "2026-02-02 23:15:43 UTC",
      "updated_date": "2026-02-02 23:15:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:50:47.538050+00:00"
    },
    {
      "arxiv_id": "2602.02898v1",
      "title": "Aligning Language Model Benchmarks with Pairwise Preferences",
      "title_zh": "基于成对偏好的语言模型基准对齐",
      "authors": [
        "Marco Gutierrez",
        "Xinyi Leng",
        "Hannah Cyberey",
        "Jonathan Richard Schwarz",
        "Ahmed Alaa",
        "Thomas Hartvigsen"
      ],
      "abstract": "Language model benchmarks are pervasive and computationally-efficient proxies for real-world performance. However, many recent works find that benchmarks often fail to predict real utility. Towards bridging this gap, we introduce benchmark alignment, where we use limited amounts of information about model performance to automatically update offline benchmarks, aiming to produce new static benchmarks that predict model pairwise preferences in given test settings. We then propose BenchAlign, the first solution to this problem, which learns preference-aligned weight- ings for benchmark questions using the question-level performance of language models alongside ranked pairs of models that could be collected during deployment, producing new benchmarks that rank previously unseen models according to these preferences. Our experiments show that our aligned benchmarks can accurately rank unseen models according to models of human preferences, even across different sizes, while remaining interpretable. Overall, our work provides insights into the limits of aligning benchmarks with practical human preferences, which stands to accelerate model development towards real utility.",
      "tldr_zh": "该研究探讨了语言模型基准测试 (Benchmarks) 与真实实用性之间的偏差，并引入了基准对齐 (Benchmark alignment) 的概念，旨在通过有限的模型性能信息自动更新离线基准，以预测特定测试设置中的模型成对偏好 (Pairwise preferences)。为此，研究团队提出了 BenchAlign 框架，该框架利用语言模型在问题层面的表现以及模型排序对数据，学习基准问题的偏好对齐权重。通过这种方式，BenchAlign 可以生成新的基准测试，从而根据既定偏好对未见过的模型进行准确排名。实验结果证明，该对齐基准能够依据人类偏好模型对不同规模的未知模型进行有效排序，并保持了基准的可解释性 (Interpretable)。这项工作揭示了将基准测试与实际人类偏好对齐的可能性与局限性，有助于推动更具真实实用性的语言模型开发。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02898v1",
      "published_date": "2026-02-02 23:11:09 UTC",
      "updated_date": "2026-02-02 23:11:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:02.314122+00:00"
    },
    {
      "arxiv_id": "2602.02895v1",
      "title": "Moving On, Even When You're Broken: Fail-Active Trajectory Generation via Diffusion Policies Conditioned on Embodiment and Task",
      "title_zh": "即使故障，依然前行：基于具身与任务约束扩散策略的故障运行轨迹生成",
      "authors": [
        "Gilberto G. Briscoe-Martinez",
        "Yaashia Gautam",
        "Rahul Shetty",
        "Anuj Pasricha",
        "Marco M. Nicotra",
        "Alessandro Roncone"
      ],
      "abstract": "Robot failure is detrimental and disruptive, often requiring human intervention to recover. Maintaining safe operation under impairment to achieve task completion, i.e. fail-active operation, is our target. Focusing on actuation failures, we introduce DEFT, a diffusion-based trajectory generator conditioned on the robot's current embodiment and task constraints. DEFT generalizes across failure types, supports constrained and unconstrained motions, and enables task completion under arbitrary failure. We evaluated DEFT in both simulation and real-world scenarios using a 7-DoF robotic arm. In simulation over thousands of joint-failure cases across multiple tasks, DEFT outperformed the baseline by up to 2 times. On failures unseen during training, it continued to outperform the baseline, indicating robust generalization in simulation. Further, we performed real-world evaluations on two multi-step tasks, drawer manipulation and whiteboard erasing. These experiments demonstrated DEFT succeeding on tasks where classical methods failed. Our results show that DEFT achieves fail-active manipulation across arbitrary failure configurations and real-world deployments.",
      "tldr_zh": "该研究针对机器人执行器失效导致的运行中断问题，提出了名为DEFT的基于扩散模型(Diffusion-based)的轨迹生成器。DEFT以机器人的当前具体形态(Embodiment)和任务约束为条件，旨在实现故障主动(Fail-Active)操作，确保机器人在受损情况下仍能维持安全运行并完成任务。该框架能够跨多种故障类型进行泛化，支持受限和非受限运动，并在任意故障配置下实现任务目标。在针对7自由度(7-DoF)机械臂的数千次模拟实验中，DEFT的表现优于基线模型达2倍，且对训练中未见过的故障展现出强大的泛化能力。在真实世界的抽屉操作和白板擦除等多步任务评估中，DEFT在传统方法失效的情况下依然取得了成功。研究结果证明了DEFT在复杂故障配置和实际部署环境下实现稳健故障主动操纵的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "To be published in the 2026 IEEE International Conference on Robotics & Automation",
      "pdf_url": "https://arxiv.org/pdf/2602.02895v1",
      "published_date": "2026-02-02 23:02:48 UTC",
      "updated_date": "2026-02-02 23:02:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:00.215074+00:00"
    },
    {
      "arxiv_id": "2602.02888v1",
      "title": "HALT: Hallucination Assessment via Log-probs as Time series",
      "title_zh": "HALT：基于对数概率时间序列的幻觉评估",
      "authors": [
        "Ahmad Shapiro",
        "Karan Taneja",
        "Ashok Goel"
      ],
      "abstract": "Hallucinations remain a major obstacle for large language models (LLMs), especially in safety-critical domains. We present HALT (Hallucination Assessment via Log-probs as Time series), a lightweight hallucination detector that leverages only the top-20 token log-probabilities from LLM generations as a time series. HALT uses a gated recurrent unit model combined with entropy-based features to learn model calibration bias, providing an extremely efficient alternative to large encoders. Unlike white-box approaches, HALT does not require access to hidden states or attention maps, relying only on output log-probabilities. Unlike black-box approaches, it operates on log-probs rather than surface-form text, which enables stronger domain generalization and compatibility with proprietary LLMs without requiring access to internal weights. To benchmark performance, we introduce HUB (Hallucination detection Unified Benchmark), which consolidates prior datasets into ten capabilities covering both reasoning tasks (Algorithmic, Commonsense, Mathematical, Symbolic, Code Generation) and general purpose skills (Chat, Data-to-Text, Question Answering, Summarization, World Knowledge). While being 30x smaller, HALT outperforms Lettuce, a fine-tuned modernBERT-base encoder, achieving a 60x speedup gain on HUB. HALT and HUB together establish an effective framework for hallucination detection across diverse LLM capabilities.",
      "tldr_zh": "该研究提出了HALT（Hallucination Assessment via Log-probs as Time series），一种针对大语言模型(LLMs)的高效轻量级幻觉检测器。该工具仅利用模型生成的Top-20 Token对数概率(log-probabilities)作为时间序列，并结合门控循环单元(GRU)与基于熵(entropy-based)的特征来识别模型校准偏差。与需要访问隐藏状态(hidden states)或注意力图(attention maps)的白盒方法不同，HALT仅依赖输出概率，从而能更好地泛化至不同领域并兼容闭源模型。为了全面评估性能，研究者还发布了涵盖推理、代码生成及通用任务等十项能力的统一基准HUB（Hallucination detection Unified Benchmark）。实验结果显示，HALT在参数量缩小30倍的情况下，性能优于基于modernBERT-base微调的检测器，且推理速度提升了60倍。HALT与HUB的结合为在各种LLM能力中进行有效的幻觉检测建立了一个可靠且实用的框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02888v1",
      "published_date": "2026-02-02 22:46:23 UTC",
      "updated_date": "2026-02-02 22:46:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:10.713258+00:00"
    },
    {
      "arxiv_id": "2602.02886v1",
      "title": "Mixture of Concept Bottleneck Experts",
      "title_zh": "概念瓶颈专家混合",
      "authors": [
        "Francesco De Santis",
        "Gabriele Ciravegna",
        "Giovanni De Felice",
        "Arianna Casanova",
        "Francesco Giannini",
        "Michelangelo Diligenti",
        "Mateo Espinosa Zarlenga",
        "Pietro Barbiero",
        "Johannes Schneider",
        "Danilo Giordano"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) promote interpretability by grounding predictions in human-understandable concepts. However, existing CBMs typically fix their task predictor to a single linear or Boolean expression, limiting both predictive accuracy and adaptability to diverse user needs. We propose Mixture of Concept Bottleneck Experts (M-CBEs), a framework that generalizes existing CBMs along two dimensions: the number of experts and the functional form of each expert, exposing an underexplored region of the design space. We investigate this region by instantiating two novel models: Linear M-CBE, which learns a finite set of linear expressions, and Symbolic M-CBE, which leverages symbolic regression to discover expert functions from data under user-specified operator vocabularies. Empirical evaluation demonstrates that varying the mixture size and functional form provides a robust framework for navigating the accuracy-interpretability trade-off, adapting to different user and task needs.",
      "tldr_zh": "该研究提出了 Mixture of Concept Bottleneck Experts (M-CBEs) 框架，旨在解决现有 Concept Bottleneck Models (CBMs) 因预测器形式固定为单一线性或布尔表达式而导致的准确性与适应性受限问题。该框架在专家数量和每个专家的函数形式两个维度上对 CBMs 进行了泛化，填补了设计空间的研究空白。研究具体实现了 Linear M-CBE 和 Symbolic M-CBE 两种模型，前者学习有限的线性表达式集，后者利用符号回归 (symbolic regression) 在给定算子库下自动发现专家函数。实验结果表明，通过灵活调整专家混合规模和函数形式，M-CBEs 能够有效处理准确性与可解释性之间的权衡 (accuracy-interpretability trade-off)。该框架表现出极强的鲁棒性，能够根据特定的用户和任务需求提供高度定制化的解释方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02886v1",
      "published_date": "2026-02-02 22:44:42 UTC",
      "updated_date": "2026-02-02 22:44:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:09.514754+00:00"
    },
    {
      "arxiv_id": "2602.02881v1",
      "title": "Learning-Infused Formal Reasoning: From Contract Synthesis to Artifact Reuse and Formal Semantics",
      "title_zh": "融入学习的形式化推理：从合约合成到工件复用与形式语义",
      "authors": [
        "Arshad Beg",
        "Diarmuid O'Donoghue",
        "Rosemary Monahan"
      ],
      "abstract": "This vision paper articulates a long-term research agenda for formal methods at the intersection with artificial intelligence, outlining multiple conceptual and technical dimensions and reporting on our ongoing work toward realising this agenda. It advances a forward-looking perspective on the next generation of formal methods based on the integration of automated contract synthesis, semantic artifact reuse, and refinement-based theory. We argue that future verification systems must move beyond isolated correctness proofs toward a cumulative, knowledge-driven paradigm in which specifications, contracts, and proofs are continuously synthesised and transferred across systems. To support this shift, we outline a hybrid framework combining large language models with graph-based representations to enable scalable semantic matching and principled reuse of verification artifacts. Learning-based components provide semantic guidance across heterogeneous notations and abstraction levels, while symbolic matching ensures formal soundness. Grounded in compositional reasoning, this vision points toward verification ecosystems that evolve systematically, leveraging past verification efforts to accelerate future assurance.",
      "tldr_zh": "这篇愿景论文提出了形式化方法(Formal Methods)与人工智能(Artificial Intelligence)交叉领域的长期研究议程，探讨了自动合约合成(Contract Synthesis)、语义构件重用(Artifact Reuse)及基于精化理论(Refinement-based Theory)的整合路径。作者主张未来的验证系统应从孤立的证明转向累积的、知识驱动的范式，使规范、合约和证明能够在不同系统间持续合成与迁移。文章提出了一种结合大语言模型(Large Language Models)与图表示(Graph-based Representations)的混合框架，旨在实现可扩展的语义匹配。在该架构中，学习组件在异构符号和抽象层级间提供语义引导，而符号匹配(Symbolic Matching)则确保了形式化完备性(Soundness)。这一基于组合推理(Compositional Reasoning)的愿景旨在通过复用既有验证成果，构建能够系统演化并加速未来安全保障的验证生态系统。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "18 pages. Accepted at VERIFAI-2026: The Interplay between Artificial Intelligence and Software Verification LASER center, Villebrumier, France, March 8-11, 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.02881v1",
      "published_date": "2026-02-02 22:39:02 UTC",
      "updated_date": "2026-02-02 22:39:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:27.492332+00:00"
    },
    {
      "arxiv_id": "2602.02863v1",
      "title": "\"I May Not Have Articulated Myself Clearly\": Diagnosing Dynamic Instability in LLM Reasoning at Inference Time",
      "title_zh": "“我可能表达得不够清楚”：大语言模型推理过程中的动态不稳定性诊断",
      "authors": [
        "Jinkun Chen",
        "Fengxiang Cheng",
        "Sijia Han",
        "Vlado Keselj"
      ],
      "abstract": "Reasoning failures in large language models (LLMs) are typically measured only at the end of a generation, yet many failures manifest as a process-level breakdown: the model \"loses the thread\" mid-reasoning. We study whether such breakdowns are detectable from inference-time observables available in standard APIs (token log probabilities), without any training or fine-tuning. We define a simple instability signal that combines consecutive-step distributional shift (JSD) and uncertainty (entropy), summarize each trace by its peak instability strength, and show that this signal reliably predicts failure. Across GSM8K and HotpotQA, instability strength predicts wrong answers with above-chance AUC and yields monotonic bucket-level accuracy decline at scale across model sizes. Crucially, we show that instability is not uniformly harmful: early instability can reflect subsequent stabilization and a correct final answer (\\emph{corrective instability}), whereas late instability is more often followed by failure (\\emph{destructive instability}), even at comparable peak magnitudes, indicating that recoverability depends not only on how strongly the distribution changes but also on when such changes occur relative to the remaining decoding horizon. The method is model-agnostic, training-free, and reproducible, and is presented as a diagnostic lens rather than a corrective or control mechanism.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在推理过程中的动态不稳定性，即模型在生成过程中出现“思路中断”的现象，并研究了如何利用推理时可观测的Token Log Probabilities在无需额外训练的情况下检测此类失效。研究定义了一种结合连续步骤分布偏移(JSD)和不确定性(Entropy)的不稳定性信号，证明该信号的峰值强度能以高于随机水平的AUC准确预测GSM8K和HotpotQA任务中的错误答案。关键发现指出，推理早期的不稳定性可能源于模型随后的自我修正(Corrective Instability)，而推理后期出现的不稳定性则通常预示着不可恢复的破坏性失败(Destructive Instability)。这种方法具有模型无关性(Model-agnostic)且完全可复现，为诊断和评估LLMs在推理过程中的稳定性提供了一个全新的实时诊断视角。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 12 figures, 15 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.02863v1",
      "published_date": "2026-02-02 22:11:25 UTC",
      "updated_date": "2026-02-02 22:11:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:26.089251+00:00"
    },
    {
      "arxiv_id": "2602.02862v1",
      "title": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search",
      "title_zh": "STEER：基于受约束质量-多样性搜索的推理时风险控制",
      "authors": [
        "Eric Yang",
        "Jong Ha Lee",
        "Jonathan Amar",
        "Elissa Ye",
        "Yugang Jia"
      ],
      "abstract": "Large Language Models (LLMs) trained for average correctness often exhibit mode collapse, producing narrow decision behaviors on tasks where multiple responses may be reasonable. This limitation is particularly problematic in ordinal decision settings such as clinical triage, where standard alignment removes the ability to trade off specificity and sensitivity (the ROC operating point) based on contextual constraints. We propose STEER (Steerable Tuning via Evolutionary Ensemble Refinement), a training-free framework that reintroduces this tunable control. STEER constructs a population of natural-language personas through an offline, constrained quality-diversity search that promotes behavioral coverage while enforcing minimum safety, reasoning, and stability thresholds. At inference time, STEER exposes a single, interpretable control parameter that maps a user-specified risk percentile to a selected persona, yielding a monotonic adjustment of decision conservativeness. On two clinical triage benchmarks, STEER achieves broader behavioral coverage compared to temperature-based sampling and static persona ensembles. Compared to a representative post-training method, STEER maintains substantially higher accuracy on unambiguous urgent cases while providing comparable control over ambiguous decisions. These results demonstrate STEER as a safety-preserving paradigm for risk control, capable of steering behavior without compromising domain competence.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在序贯决策任务中因模式崩塌 (mode collapse) 导致的行为单一问题，提出了 STEER (Steerable Tuning via Evolutionary Ensemble Refinement) 这一无需训练的风险控制框架。该框架通过离线的约束性 Quality-Diversity search 构建具备多样化行为特征的自然语言人格 (personas) 种群，并在满足安全、推理和稳定性阈值的基础上扩展行为覆盖。在推理过程中，STEER 引入一个可解释的控制参数，允许用户通过风险百分位单调调节决策的保守程度。实验结果表明，在临床分诊 (clinical triage) 基准测试中，STEER 的行为覆盖能力优于传统的温度采样 (temperature-based sampling) 和静态集成方法。此外，STEER 在处理模糊决策时提供了良好的控制能力，同时能确保在明确紧急情况下的高准确率，为大模型在敏感领域的受控部署提供了安全保障。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages",
      "pdf_url": "https://arxiv.org/pdf/2602.02862v1",
      "published_date": "2026-02-02 22:10:32 UTC",
      "updated_date": "2026-02-02 22:10:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:25.278100+00:00"
    },
    {
      "arxiv_id": "2602.02849v1",
      "title": "AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents",
      "title_zh": "AutoSizer：基于大语言模型（LLM）智能体的模拟与混合信号电路自动尺寸设计",
      "authors": [
        "Xi Yu",
        "Dmitrii Torbunov",
        "Soumyajit Mandal",
        "Yihui Ren"
      ],
      "abstract": "The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Existing Electronic Design Automation (EDA) methods typically frame sizing as static black-box optimization, resulting in inefficient and less robust solutions. Although Large Language Models (LLMs) exhibit strong reasoning abilities, they are not suited for precise numerical optimization in AMS sizing. To address this gap, we propose AutoSizer, a reflective LLM-driven meta-optimization framework that unifies circuit understanding, adaptive search-space construction, and optimization orchestration in a closed loop. It employs a two-loop optimization framework, with an inner loop for circuit sizing and an outer loop that analyzes optimization dynamics and constraints to iteratively refine the search space from simulation feedback. We further introduce AMS-SizingBench, an open benchmark comprising 24 diverse AMS circuits in SKY130 CMOS technology, designed to evaluate adaptive optimization policies under realistic simulator-based constraints. AutoSizer experimentally achieves higher solution quality, faster convergence, and higher success rate across varying circuit difficulties, outperforming both traditional optimization methods and existing LLM-based agents.",
      "tldr_zh": "该研究提出了 AutoSizer，这是一种针对模拟与混合信号 (Analog and Mixed-Signal, AMS) 集成电路设计的反射式大语言模型 (LLM) 驱动元优化框架，旨在解决晶体管尺寸调整 (Sizing) 过程中因非线性、高维空间及严格性能约束导致的效率瓶颈。该框架采用双环优化体系，通过内环执行电路尺寸调整，外环利用模拟反馈迭代精细化搜索空间，实现了电路理解与优化编排的闭环统一。为评估该系统，研究者还推出了 AMS-SizingBench 基准测试集，涵盖 24 种基于 SKY130 CMOS 技术的电路。实验表明，AutoSizer 在解的质量、收敛速度以及任务成功率方面均显著优于传统电子设计自动化 (EDA) 优化方法及现有的 LLM 智能体。该框架不仅弥补了 LLM 在精确数值优化方面的短板，也为自动化电路设计提供了一种更为稳健和高效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02849v1",
      "published_date": "2026-02-02 21:51:55 UTC",
      "updated_date": "2026-02-02 21:51:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:39.792649+00:00"
    },
    {
      "arxiv_id": "2602.02847v1",
      "title": "Causal Flow Q-Learning for Robust Offline Reinforcement Learning",
      "title_zh": "面向鲁棒离线强化学习的因果流 Q 学习",
      "authors": [
        "Mingxuan Li",
        "Junzhe Zhang",
        "Elias Bareinboim"
      ],
      "abstract": "Expressive policies based on flow-matching have been successfully applied in reinforcement learning (RL) more recently due to their ability to model complex action distributions from offline data. These algorithms build on standard policy gradients, which assume that there is no unmeasured confounding in the data. However, this condition does not necessarily hold for pixel-based demonstrations when a mismatch exists between the demonstrator's and the learner's sensory capabilities, leading to implicit confounding biases in offline data. We address the challenge by investigating the problem of confounded observations in offline RL from a causal perspective. We develop a novel causal offline RL objective that optimizes policies' worst-case performance that may arise due to confounding biases. Based on this new objective, we introduce a practical implementation that learns expressive flow-matching policies from confounded demonstrations, employing a deep discriminator to assess the discrepancy between the target policy and the nominal behavioral policy. Experiments across 25 pixel-based tasks demonstrate that our proposed confounding-robust augmentation procedure achieves a success rate 120\\% that of confounding-unaware, state-of-the-art offline RL methods.",
      "tldr_zh": "该研究探讨了离线强化学习(Offline RL)中因观察者与学习者感知能力差异导致的隐性混杂偏差(Confounding Biases)问题，指出传统的流匹配(Flow-matching)策略往往忽视了像素级演示数据中未测量的混杂因素。为解决这一挑战，作者从因果视角提出了一种全新的因果离线强化学习目标，旨在优化策略在潜在混杂偏差下的最差情况表现。在此基础上，研究实现了Causal Flow Q-Learning算法，利用深度判别器(Deep Discriminator)评估目标策略与行为策略间的差异，以学习高表达能力的策略。实验结果表明，该方法在25项基于像素的任务中表现优异，其成功率达到现有最先进的非因果感知离线强化学习方法的120%。该研究为处理含有隐性混杂偏见的离线数据提供了一种鲁棒的因果增强方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02847v1",
      "published_date": "2026-02-02 21:50:52 UTC",
      "updated_date": "2026-02-02 21:50:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:36.877248+00:00"
    },
    {
      "arxiv_id": "2602.02842v1",
      "title": "Chain of Simulation: A Dual-Mode Reasoning Framework for Large Language Models with Dynamic Problem Routing",
      "title_zh": "Chain of Simulation：具有动态问题路由的大语言模型双模式推理框架",
      "authors": [
        "Saeid Sheikhi"
      ],
      "abstract": "We present Chain of Simulation (CoS), a novel dual-mode reasoning framework that dynamically routes problems to specialized reasoning strategies in Large Language Models (LLMs). Unlike existing uniform prompting approaches, CoS employs three distinct reasoning modes: (1) computational flow with self-consistency for mathematical problems, (2) symbolic state tracking with JSON representations for spatial reasoning, and (3) hybrid fact-extraction for multi-hop inference. Through comprehensive evaluation on GSM8K, StrategyQA, and bAbI benchmarks using four state-of-the-art models (Gemma-3 27B, LLaMA-3.1 8B, Mistral 7B, and Qwen-2.5 14B), we demonstrate that CoS achieves 71.5% accuracy on GSM8K (1.0% absolute improvement), 90.0% on StrategyQA (2.5% improvement), and 19.0% on bAbI (65.2% relative improvement) compared to the strongest baselines. The analysis reveals that problem-specific mode selection is crucial, with computational mode achieving 81.2% accuracy when correctly applied to mathematical problems, while misrouting leads to 0% accuracy. We provide detailed algorithms for mode selection, state tracking, and answer extraction, establishing CoS as an effective approach for improving LLM reasoning without additional training. The framework provides superior trade-offs between accuracy and efficiency compared to Self-Consistency, achieving comparable performance at 54% lower computational cost.",
      "tldr_zh": "该研究提出了Chain of Simulation (CoS)，一种为大语言模型(Large Language Models, LLMs)设计的具有动态问题路由功能的双模式推理框架。该框架将复杂问题动态分发至三种专门的推理模式，包括针对数学问题的具有Self-consistency的计算流、针对空间推理的JSON格式Symbolic state tracking，以及针对多跳推理的Hybrid fact-extraction。在GSM8K、StrategyQA和bAbI基准测试的评估中，CoS在Gemma-3 27B和LLaMA-3.1 8B等模型上均取得了显著的性能提升，其中bAbI任务的相对准确率提高了65.2%。研究发现针对特定问题的模式路由至关重要，正确的模式应用能显著提升特定领域的准确率，而路由错误则会导致性能大幅下降。相比于传统的Self-consistency方法，CoS在保证同等甚至更优性能的前提下将计算成本降低了54%。这项工作为在无需额外训练的情况下提升LLMs推理能力的准确性与效率提供了有效的技术路径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02842v1",
      "published_date": "2026-02-02 21:44:01 UTC",
      "updated_date": "2026-02-02 21:44:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:43.584772+00:00"
    },
    {
      "arxiv_id": "2602.02841v1",
      "title": "Semantics-Aware Generative Latent Data Augmentation for Learning in Low-Resource Domains",
      "title_zh": "面向低资源领域学习的语义感知生成式隐空间数据增强",
      "authors": [
        "Jae-Sung Bae",
        "Minje Kim"
      ],
      "abstract": "Despite strong performance in data-rich regimes, deep learning often underperforms in the data-scarce settings common in practice. While foundation models (FMs) trained on massive datasets demonstrate strong generalization by extracting general-purpose features, they can still suffer from scarce labeled data during downstream fine-tuning. To address this, we propose GeLDA, a semantics-aware generative latent data augmentation framework that leverages conditional diffusion models to synthesize samples in an FM-induced latent space. Because this space is low-dimensional and concentrates task-relevant information compared to the input space, GeLDA enables efficient, high-quality data generation. GeLDA conditions generation on auxiliary feature vectors that capture semantic relationships among classes or subdomains, facilitating data augmentation in low-resource domains. We validate GeLDA in two large-scale recognition tasks: (a) in zero-shot language-specific speech emotion recognition, GeLDA improves the Whisper-large baseline's unweighted average recall by 6.13%; and (b) in long-tailed image classification, it achieves 74.7% tail-class accuracy on ImageNet-LT, setting a new state-of-the-art result.",
      "tldr_zh": "该研究提出了 GeLDA，一种语义感知的生成式潜空间数据增强（semantics-aware generative latent data augmentation）框架，旨在解决深度学习在低资源领域（low-resource domains）中由于标注数据匮乏导致的性能下降问题。GeLDA 利用条件扩散模型（conditional diffusion models）在基础模型（Foundation Models, FMs）诱导的潜空间内合成样本，该空间相比于输入空间维度更低且能更集中地体现任务相关信息，从而实现高效且高质量的数据生成。该框架通过捕获类别或子域间语义关系的辅助特征向量来指导生成过程，有效支持了低资源域的数据增强需求。实验结果显示，在零样本语音情感识别任务中，GeLDA 将 Whisper-large 基线的未加权平均召回率提升了 6.13%。此外，在 ImageNet-LT 长尾图像分类任务中，该方法实现了 74.7% 的尾部类别准确率，创下了新的 SOTA 记录。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02841v1",
      "published_date": "2026-02-02 21:43:54 UTC",
      "updated_date": "2026-02-02 21:43:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:38.733189+00:00"
    },
    {
      "arxiv_id": "2602.02834v1",
      "title": "Tabula RASA: Exposing and Breaking the Relational Bottleneck in Transformers",
      "title_zh": "Tabula RASA：揭示与突破 Transformer 中的关系瓶颈",
      "authors": [
        "Jonas Petersen",
        "Camilla Mazzoleni",
        "Riccardo Maggioni"
      ],
      "abstract": "Transformers achieve remarkable performance across many domains, yet struggle with tasks requiring multi-hop relational reasoning over structured data. We analyze this limitation through circuit complexity: standard transformers are $\\mathsf{TC}^0$-complete and require $Ω(k)$ layers for $k$-hop reasoning. We introduce RASA (Relation-Aware Sparse Attention), a minimal modification adding: (1) edge-type embeddings that inject relational structure into attention scores, and (2) sparse masking that restricts attention to graph-adjacent positions. While RASA has the same asymptotic depth requirements, sparse masking reduces the attention search space from $O(2^{n^2})$ to $O(2^m)$ patterns, and edge biases provide explicit relation routing. Empirically, on MetaQA (1/2/3-hop) and WebQuestionsSP, RASA outperforms standard transformers and matches GPT-4 at lower cost, with advantages growing with reasoning depth (+7.1 points on 3-hop). We do not claim formal learnability guarantees; the contribution is empirical validation that minimal structural modifications substantially improve multi-hop reasoning.",
      "tldr_zh": "该研究分析了 Transformer 在处理结构化数据多步关系推理(multi-hop relational reasoning)时的瓶颈，指出标准模型在 $k$ 步推理中面临层数复杂度的限制。为此，作者提出了 RASA (Relation-Aware Sparse Attention)，通过引入边类型嵌入(edge-type embeddings)注入关系结构，并利用稀疏掩码(sparse masking)将注意力限制在图相邻位置。这种改进将注意力的搜索空间从 $O(2^{n^2})$ 显著降低到 $O(2^m)$，并通过边偏置(edge biases)实现了明确的关系路由。在 MetaQA 和 WebQuestionsSP 的实验中，RASA 的性能优于标准 Transformer，并在更低成本下达到了与 GPT-4 相当的水平。随着推理深度增加，其优势进一步扩大，在 3-hop 任务中准确率提升了 7.1 分。该研究实证验证了通过极小的结构化改进即可显著增强模型的多步推理能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures, 8 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.02834v1",
      "published_date": "2026-02-02 21:35:39 UTC",
      "updated_date": "2026-02-02 21:35:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:45.281678+00:00"
    },
    {
      "arxiv_id": "2602.02820v1",
      "title": "From Tokens to Numbers: Continuous Number Modeling for SVG Generation",
      "title_zh": "从 Token 到数值：面向 SVG 生成的连续数值建模",
      "authors": [
        "Michael Ogezi",
        "Martin Bell",
        "Freda Shi",
        "Ethan Smith"
      ],
      "abstract": "For certain image generation tasks, vector graphics such as Scalable Vector Graphics (SVGs) offer clear benefits such as increased flexibility, size efficiency, and editing ease, but remain less explored than raster-based approaches. A core challenge is that the numerical, geometric parameters, which make up a large proportion of SVGs, are inefficiently encoded as long sequences of tokens. This slows training, reduces accuracy, and hurts generalization. To address these problems, we propose Continuous Number Modeling (CNM), an approach that directly models numbers as first-class, continuous values rather than discrete tokens. This formulation restores the mathematical elegance of the representation by aligning the model's inputs with the data's continuous nature, removing discretization artifacts introduced by token-based encoding. We then train a multimodal transformer on 2 million raster-to-SVG samples, followed by fine-tuning via reinforcement learning using perceptual feedback to further improve visual quality. Our approach improves training speed by over 30% while maintaining higher perceptual fidelity compared to alternative approaches. This work establishes CNM as a practical and efficient approach for high-quality vector generation, with potential for broader applications. We make our code available http://github.com/mikeogezi/CNM.",
      "tldr_zh": "该研究针对 Scalable Vector Graphics (SVG) 在图像生成任务中面临的数值参数编码低效问题，提出了 Continuous Number Modeling (CNM) 框架，将数值直接建模为连续值而非离散 Token。CNM 通过将模型输入与数据的连续本质对齐，消除了离散化处理带来的伪影，恢复了表示方式的数学严谨性。研究者在 200 万个 raster-to-SVG 样本上训练了多模态 Transformer 模型，并利用感知反馈通过 Reinforcement Learning (RL) 进行了微调，以显著提升视觉质量。实验结果表明，CNM 在保持更高感知忠实度的同时，将模型训练速度提升了 30% 以上。该工作确立了 CNM 作为高质量矢量图生成的实用高效方案，并展现了其在更广泛领域中的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02820v1",
      "published_date": "2026-02-02 21:20:38 UTC",
      "updated_date": "2026-02-02 21:20:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:51:54.884841+00:00"
    },
    {
      "arxiv_id": "2602.02808v1",
      "title": "LmPT: Conditional Point Transformer for Anatomical Landmark Detection on 3D Point Clouds",
      "title_zh": "LmPT：面向三维点云解剖标志点检测的条件式 Point Transformer",
      "authors": [
        "Matteo Bastico",
        "Pierre Onghena",
        "David Ryckelynck",
        "Beatriz Marcotegui",
        "Santiago Velasco-Forero",
        "Laurent Corté",
        "Caroline Robine--Decourcelle",
        "Etienne Decencière"
      ],
      "abstract": "Accurate identification of anatomical landmarks is crucial for various medical applications. Traditional manual landmarking is time-consuming and prone to inter-observer variability, while rule-based methods are often tailored to specific geometries or limited sets of landmarks. In recent years, anatomical surfaces have been effectively represented as point clouds, which are lightweight structures composed of spatial coordinates. Following this strategy and to overcome the limitations of existing landmarking techniques, we propose Landmark Point Transformer (LmPT), a method for automatic anatomical landmark detection on point clouds that can leverage homologous bones from different species for translational research. The LmPT model incorporates a conditioning mechanism that enables adaptability to different input types to conduct cross-species learning. We focus the evaluation of our approach on femoral landmarking using both human and newly annotated dog femurs, demonstrating its generalization and effectiveness across species. The code and dog femur dataset will be publicly available at: https://github.com/Pierreoo/LandmarkPointTransformer.",
      "tldr_zh": "该研究提出了 LmPT (Landmark Point Transformer)，这是一种针对 3D 点云 (Point Clouds) 进行解剖标志自动检测的条件点变换器模型。该模型通过引入条件机制 (Conditioning Mechanism)，使其能够灵活适应不同的输入类型并执行跨物种学习 (Cross-species Learning)，从而有效支持转化医学研究。LmPT 成功克服了传统手动标注耗时且易受主观差异影响的缺陷，并解决了规则化方法对特定几何形状的依赖问题。研究团队通过对人类和新标注的狗股骨数据集进行评估，验证了该模型在不同物种间卓越的泛化性能与检测准确性。该研究展示了利用点云结构进行自动化、跨物种解剖标注的巨大潜力，并为医学影像分析提供了高效的轻量化解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted at International Symposium on Biomedical Imaging (ISBI) 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.02808v1",
      "published_date": "2026-02-02 21:06:36 UTC",
      "updated_date": "2026-02-02 21:06:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:05.084532+00:00"
    },
    {
      "arxiv_id": "2602.02799v1",
      "title": "Joint Learning of Hierarchical Neural Options and Abstract World Model",
      "title_zh": "联合学习分层神经选项与抽象世界模型",
      "authors": [
        "Wasu Top Piriyakulkij",
        "Wolfgang Lehrach",
        "Kevin Ellis",
        "Kevin Murphy"
      ],
      "abstract": "Building agents that can perform new skills by composing existing skills is a long-standing goal of AI agent research. Towards this end, we investigate how to efficiently acquire a sequence of skills, formalized as hierarchical neural options. However, existing model-free hierarchical reinforcement algorithms need a lot of data. We propose a novel method, which we call AgentOWL (Option and World model Learning Agent), that jointly learns -- in a sample efficient way -- an abstract world model (abstracting across both states and time) and a set of hierarchical neural options. We show, on a subset of Object-Centric Atari games, that our method can learn more skills using much less data than baseline methods.",
      "tldr_zh": "该研究探讨了如何通过组合现有技能使智能体执行新技能，并针对现有无模型分层强化学习(Model-free Hierarchical Reinforcement Learning)算法数据效率低下的挑战，提出了一种名为 AgentOWL (Option and World model Learning Agent) 的新方法。AgentOWL 通过在状态和时间维度上进行抽象，实现了抽象世界模型(Abstract World Model)与一组分层神经算子(Hierarchical Neural Options)的联合学习。这种联合学习机制显著提升了样本效率，使得智能体能够更有效地获取技能序列。在以对象为中心的 Atari 游戏(Object-Centric Atari games)子集上的实验表明，AgentOWL 能够比基线方法使用更少的数据学习到更多的技能。该研究为实现高效、可组合的智能体技能学习提供了重要的技术支撑。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02799v1",
      "published_date": "2026-02-02 20:58:11 UTC",
      "updated_date": "2026-02-02 20:58:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:14.183279+00:00"
    },
    {
      "arxiv_id": "2602.02793v1",
      "title": "Causality--Δ: Jacobian-Based Dependency Analysis in Flow Matching Models",
      "title_zh": "Causality--Δ：流匹配模型中基于雅可比的依赖性分析",
      "authors": [
        "Reza Rezvan",
        "Gustav Gille",
        "Moritz Schauer",
        "Richard Torkar"
      ],
      "abstract": "Flow matching learns a velocity field that transports a base distribution to data. We study how small latent perturbations propagate through these flows and show that Jacobian-vector products (JVPs) provide a practical lens on dependency structure in the generated features. We derive closed-form expressions for the optimal drift and its Jacobian in Gaussian and mixture-of-Gaussian settings, revealing that even globally nonlinear flows admit local affine structure. In low-dimensional synthetic benchmarks, numerical JVPs recover the analytical Jacobians. In image domains, composing the flow with an attribute classifier yields an attribute-level JVP estimator that recovers empirical correlations on MNIST and CelebA. Conditioning on small classifier-Jacobian norms reduces correlations in a way consistent with a hypothesized common-cause structure, while we emphasize that this conditioning is not a formal do intervention.",
      "tldr_zh": "该研究探讨了 Flow matching 模型中的依赖结构，提出了 Causality--Δ 框架。研究通过分析小潜变量扰动在流中的传播，证明了 Jacobian-vector products (JVPs) 是研究生成特征依赖结构的实用工具。作者在 Gaussian 和 mixture-of-Gaussian 场景下推导了最优 drift 及其 Jacobian 的闭式表达式，揭示了非线性流中的局部 affine structure。实验在低维基准测试中验证了数值 JVPs 与解析 Jacobian 的一致性。在图像领域，通过结合属性分类器构建的 JVP estimator 成功恢复了 MNIST 和 CelebA 的经验相关性。研究进一步发现，对分类器 Jacobian 范数进行条件化处理可以减少相关性，这与假设的 common-cause 结构相吻合。尽管该方法并非正式的 do intervention，但它为生成模型的特征解耦与因果分析提供了实证视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures. Code: https://github.com/rezaarezvan/causdiff",
      "pdf_url": "https://arxiv.org/pdf/2602.02793v1",
      "published_date": "2026-02-02 20:52:52 UTC",
      "updated_date": "2026-02-02 20:52:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:33.979775+00:00"
    },
    {
      "arxiv_id": "2602.02790v1",
      "title": "Simulating Human Audiovisual Search Behavior",
      "title_zh": "模拟人类视听搜索行为",
      "authors": [
        "Hyunsung Cho",
        "Xuejing Luo",
        "Byungjoo Lee",
        "David Lindlbauer",
        "Antti Oulasvirta"
      ],
      "abstract": "Locating a target based on auditory and visual cues$\\unicode{x2013}$such as finding a car in a crowded parking lot or identifying a speaker in a virtual meeting$\\unicode{x2013}$requires balancing effort, time, and accuracy under uncertainty. Existing models of audiovisual search often treat perception and action in isolation, overlooking how people adaptively coordinate movement and sensory strategies. We present Sensonaut, a computational model of embodied audiovisual search. The core assumption is that people deploy their body and sensory systems in ways they believe will most efficiently improve their chances of locating a target, trading off time and effort under perceptual constraints. Our model formulates this as a resource-rational decision-making problem under partial observability. We validate the model against newly collected human data, showing that it reproduces both adaptive scaling of search time and effort under task complexity, occlusion, and distraction, and characteristic human errors. Our simulation of human-like resource-rational search informs the design of audiovisual interfaces that minimize search cost and cognitive load.",
      "tldr_zh": "该研究提出了Sensonaut，一种用于模拟具身视听搜索(Audiovisual Search)行为的计算模型，旨在揭示人类如何在不确定环境下权衡时间与精力来定位目标。该模型基于资源理性(Resource-Rational)的假设，将搜索过程建模为部分可观测性(Partial Observability)下的决策问题，即个体通过协调身体动作和感官策略来高效提升目标定位的成功率。通过与新收集的人类实验数据对比，Sensonaut成功复现了人类在面对复杂任务、遮挡和干扰时的自适应搜索行为以及特征性错误。这项关于类人资源理性搜索的模拟研究，为优化视听界面设计以降低用户搜索成本和认知负荷(Cognitive Load)提供了重要的理论依据。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, 10 figures, CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.02790v1",
      "published_date": "2026-02-02 20:47:05 UTC",
      "updated_date": "2026-02-02 20:47:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:18.886172+00:00"
    },
    {
      "arxiv_id": "2602.02788v1",
      "title": "Structure-Preserving Learning Improves Geometry Generalization in Neural PDEs",
      "title_zh": "结构保持学习提升神经偏微分方程的几何泛化能力",
      "authors": [
        "Benjamin D. Shaffer",
        "Shawn Koohy",
        "Brooks Kinch",
        "M. Ani Hsieh",
        "Nathaniel Trask"
      ],
      "abstract": "We aim to develop physics foundation models for science and engineering that provide real-time solutions to Partial Differential Equations (PDEs) which preserve structure and accuracy under adaptation to unseen geometries. To this end, we introduce General-Geometry Neural Whitney Forms (Geo-NeW): a data-driven finite element method. We jointly learn a differential operator and compatible reduced finite element spaces defined on the underlying geometry. The resulting model is solved to generate predictions, while exactly preserving physical conservation laws through Finite Element Exterior Calculus. Geometry enters the model as a discretized mesh both through a transformer-based encoding and as the basis for the learned finite element spaces. This explicitly connects the underlying geometry and imposed boundary conditions to the solution, providing a powerful inductive bias for learning neural PDEs, which we demonstrate improves generalization to unseen domains. We provide a novel parameterization of the constitutive model ensuring the existence and uniqueness of the solution. Our approach demonstrates state-of-the-art performance on several steady-state PDE benchmarks, and provides a significant improvement over conventional baselines on out-of-distribution geometries.",
      "tldr_zh": "该研究旨在开发能够适应未知几何形状并保持结构与准确性的物理基础模型(physics foundation models)，为此提出了名为General-Geometry Neural Whitney Forms (Geo-NeW)的数据驱动有限元方法。该方法通过联合学习微分算子(differential operator)与兼容的简化有限元空间，并利用有限元外演算(Finite Element Exterior Calculus)确保模型能精确遵循物理守恒定律。几何形状通过基于Transformer的编码以及作为学习有限元空间基底的方式进入模型，将底层几何与边界条件直接关联至数值解，从而为Neural PDEs的学习提供了强大的归纳偏置(inductive bias)。研究还引入了新型的本构模型(constitutive model)参数化方案，以保证解的存在性与唯一性。实验结果显示，Geo-NeW在多个稳态PDE基准测试中实现了领先性能(state-of-the-art)，并在处理分布外(out-of-distribution)几何形状时比传统基线模型有显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02788v1",
      "published_date": "2026-02-02 20:45:07 UTC",
      "updated_date": "2026-02-02 20:45:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:23.199866+00:00"
    },
    {
      "arxiv_id": "2602.02784v1",
      "title": "Cross-Temporal Attention Fusion (CTAF) for Multimodal Physiological Signals in Self-Supervised Learning",
      "title_zh": "自监督学习中多模态生理信号的跨时域注意力融合 (CTAF)",
      "authors": [
        "Arian Khorasani",
        "Théophile Demazure"
      ],
      "abstract": "We study multimodal affect modeling when EEG and peripheral physiology are asynchronous, which most fusion methods ignore or handle with costly warping. We propose Cross-Temporal Attention Fusion (CTAF), a self-supervised module that learns soft bidirectional alignments between modalities and builds a robust clip embedding using time-aware cross attention, a lightweight fusion gate, and alignment-regularized contrastive objectives with optional weak supervision. On the K-EmoCon dataset, under leave-one-out cross-validation evaluation, CTAF yields higher cosine margins for matched pairs and better cross-modal token retrieval within one second, and it is competitive with the baseline on three-bin accuracy and macro-F1 while using few labels. Our contributions are a time-aware fusion mechanism that directly models correspondence, an alignment-driven self-supervised objective tailored to EEG and physiology, and an evaluation protocol that measures alignment quality itself. Our approach accounts for the coupling between the central and autonomic nervous systems in psychophysiological time series. These results indicate that CTAF is a strong step toward label-efficient, generalizable EEG-peripheral fusion under temporal asynchrony.",
      "tldr_zh": "该研究针对脑电图(EEG)与外周生理信号(peripheral physiology)在多模态情感建模中的异步性问题，提出了一种名为Cross-Temporal Attention Fusion (CTAF)的自监督模块。CTAF通过时间感知交叉注意力(time-aware cross attention)、轻量化融合门和对齐正则化对比目标，实现了模态间的软双向对齐并构建了鲁棒的片段嵌入。在K-EmoCon数据集上的实验结果显示，该方法在匹配对余弦边距和跨模态令牌检索方面表现出色，且在极少标签的情况下，其三分类准确率和macro-F1与基线模型相比极具竞争力。该研究的主要贡献在于直接建模对应关系的时间感知融合机制，以及一套衡量对齐质量的评估协议。实验证明CTAF能有效捕捉中枢与自主神经系统在心理生理时间序列中的耦合关系，为解决时间异步下的多模态融合提供了高效且具泛化性的方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02784v1",
      "published_date": "2026-02-02 20:40:04 UTC",
      "updated_date": "2026-02-02 20:40:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:28.587203+00:00"
    },
    {
      "arxiv_id": "2602.02781v1",
      "title": "Evaluating False Alarm and Missing Attacks in CAN IDS",
      "title_zh": "CAN 入侵检测系统中误报与漏报攻击的评估",
      "authors": [
        "Nirab Hossain",
        "Pablo Moriano"
      ],
      "abstract": "Modern vehicles rely on electronic control units (ECUs) interconnected through the Controller Area Network (CAN), making in-vehicle communication a critical security concern. Machine learning (ML)-based intrusion detection systems (IDS) are increasingly deployed to protect CAN traffic, yet their robustness against adversarial manipulation remains largely unexplored. We present a systematic adversarial evaluation of CAN IDS using the ROAD dataset, comparing four shallow learning models with a deep neural network-based detector. Using protocol-compliant, payload-level perturbations generated via FGSM, BIM and PGD, we evaluate adversarial effects on both benign and malicious CAN frames. While all models achieve strong baseline performance under benign conditions, adversarial perturbations reveal substantial vulnerabilities. Although shallow and deep models are robust to false-alarm induction, with the deep neural network (DNN) performing best on benign traffic, all architectures suffer significant increases in missed attacks. Notably, under gradient-based attacks, the shallow model extra trees (ET) demonstrates improved robustness to missed-attack induction compared to the other models. Our results demonstrate that adversarial manipulation can simultaneously trigger false alarms and evade detection, underscoring the need for adversarial robustness evaluation in safety-critical automotive IDS.",
      "tldr_zh": "该研究对控制器局域网(CAN)入侵检测系统(IDS)在对抗攻击下的鲁棒性进行了系统评估，重点探讨了对抗样本对诱发虚警(False Alarm)和漏报(Missing Attacks)的影响。研究人员利用ROAD数据集，对比了四种浅层学习模型与一种基于深度神经网络(DNN)的检测器在面对FGSM、BIM和PGD等梯度攻击时的表现。实验结果显示，尽管各模型在良性交通环境下表现优异，但对抗扰动揭示了其显著的脆弱性，尤其是所有架构在面对旨在诱发漏报的攻击时性能均大幅下降。值得注意的是，虽然DNN在处理良性流量时表现最佳，但在梯度攻击环境下，浅层模型Extra Trees (ET)在抵御漏报攻击方面展现出了比其他模型更强的鲁棒性。该研究证实了对抗性操纵可以同时触发虚警并规避检测，强调了在安全至上的车载IDS开发中纳入对抗鲁棒性评估的紧迫性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 2 figures, and 8 tables",
      "pdf_url": "https://arxiv.org/pdf/2602.02781v1",
      "published_date": "2026-02-02 20:38:01 UTC",
      "updated_date": "2026-02-02 20:38:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:24.184587+00:00"
    },
    {
      "arxiv_id": "2602.02780v1",
      "title": "Scaling-Aware Adapter for Structure-Grounded LLM Reasoning",
      "title_zh": "面向结构化大语言模型推理的尺度感知适配器",
      "authors": [
        "Zihao Jing",
        "Qiuhao Zeng",
        "Ruiyi Fang",
        "Yan Yi Li",
        "Yan Sun",
        "Boyu Wang",
        "Pingzhao Hu"
      ],
      "abstract": "Large language models (LLMs) are enabling reasoning over biomolecular structures, yet existing methods remain modality-specific and typically compress structural inputs through sequence-based tokenization or fixed-length query connectors. Such architectures either omit the geometric groundings requisite for mitigating structural hallucinations or impose inflexible modality fusion bottlenecks that concurrently over-compress and suboptimally allocate structural tokens, thereby impeding the realization of generalized all-atom reasoning. We introduce Cuttlefish, a unified all-atom LLM that grounds language reasoning in geometric cues while scaling modality tokens with structural complexity. First, Scaling-Aware Patching leverages an instruction-conditioned gating mechanism to generate variable-size patches over structural graphs, adaptively scaling the query token budget with structural complexity to mitigate fixed-length connector bottlenecks. Second, Geometry Grounding Adapter refines these adaptive tokens via cross-attention to modality embeddings and injects the resulting modality tokens into the LLM, exposing explicit geometric cues to reduce structural hallucination. Experiments across diverse all-atom benchmarks demonstrate that Cuttlefish achieves superior performance in heterogeneous structure-grounded reasoning. Code is available at the project repository.",
      "tldr_zh": "该研究提出了Cuttlefish，一个旨在提升大语言模型(LLMs)对生物分子结构推理能力的统一全原子模型。针对现有方法在模态特定性、结构幻觉以及固定长度连接器导致的过压缩和标记分配不均等问题，Cuttlefish通过将语言推理锚定在几何线索中，实现了随结构复杂度扩展的模态标记处理。其核心技术包含Scaling-Aware Patching，利用指令调节的门控机制动态生成可变大小的补丁，从而克服了固定长度连接器的瓶颈。此外，Geometry Grounding Adapter通过交叉注意力机制(cross-attention)优化这些自适应标记，并将显式几何线索注入LLM中，有效减少了结构幻觉的发生。在多种全原子基准测试上的实验结果证明，Cuttlefish在异构结构基准推理任务中表现出色，显著提升了推理性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review at ICML 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.02780v1",
      "published_date": "2026-02-02 20:35:44 UTC",
      "updated_date": "2026-02-02 20:35:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:34.690263+00:00"
    },
    {
      "arxiv_id": "2602.02767v1",
      "title": "Provable Effects of Data Replay in Continual Learning: A Feature Learning Perspective",
      "title_zh": "持续学习中数据重放的可证明效应：特征学习视角",
      "authors": [
        "Meng Ding",
        "Jinhui Xu",
        "Kaiyi Ji"
      ],
      "abstract": "Continual learning (CL) aims to train models on a sequence of tasks while retaining performance on previously learned ones. A core challenge in this setting is catastrophic forgetting, where new learning interferes with past knowledge. Among various mitigation strategies, data-replay methods, where past samples are periodically revisited, are considered simple yet effective, especially when memory constraints are relaxed. However, the theoretical effectiveness of full data replay, where all past data is accessible during training, remains largely unexplored. In this paper, we present a comprehensive theoretical framework for analyzing full data-replay training in continual learning from a feature learning perspective. Adopting a multi-view data model, we identify the signal-to-noise ratio (SNR) as a critical factor affecting forgetting. Focusing on task-incremental binary classification across $M$ tasks, our analysis verifies two key conclusions: (1) forgetting can still occur under full replay when the cumulative noise from later tasks dominates the signal from earlier ones; and (2) with sufficient signal accumulation, data replay can recover earlier tasks-even if their initial learning was poor. Notably, we uncover a novel insight into task ordering: prioritizing higher-signal tasks not only facilitates learning of lower-signal tasks but also helps prevent catastrophic forgetting. We validate our theoretical findings through synthetic and real-world experiments that visualize the interplay between signal learning and noise memorization across varying SNRs and task correlation regimes.",
      "tldr_zh": "该研究从特征学习(Feature learning)的角度探讨了持续学习(Continual learning)中数据重播(Data-replay)方法的理论有效性，旨在深入理解如何缓解灾难性遗忘(Catastrophic forgetting)。作者通过多视图数据模型(Multi-view data model)建立了理论分析框架，并确定信噪比(Signal-to-noise ratio, SNR)是决定遗忘是否发生的关键因素。研究发现在任务增量二进制分类(Task-incremental binary classification)场景下，即使采用全数据重播，若后期任务的累积噪声超过早期信号，遗忘仍会发生；但若信号积累充足，重播则能有效恢复早期任务的性能。此外，研究揭示了任务排序(Task ordering)的独特作用，即优先学习高信号强度的任务不仅能辅助后续学习，还能显著预防灾难性遗忘。合成实验与真实世界实验共同验证了在不同信噪比及任务相关性下，信号学习与噪声记忆之间的复杂相互作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.02767v1",
      "published_date": "2026-02-02 20:21:17 UTC",
      "updated_date": "2026-02-02 20:21:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:37.482676+00:00"
    },
    {
      "arxiv_id": "2602.02751v1",
      "title": "Scaling Small Agents Through Strategy Auctions",
      "title_zh": "通过策略拍卖实现小型智能体的规模化扩展",
      "authors": [
        "Lisa Alazraki",
        "William F. Shen",
        "Yoram Bachrach",
        "Akhil Mathur"
      ],
      "abstract": "Small language models are increasingly viewed as a promising, cost-effective approach to agentic AI, with proponents claiming they are sufficiently capable for agentic workflows. However, while smaller agents can closely match larger ones on simple tasks, it remains unclear how their performance scales with task complexity, when large models become necessary, and how to better leverage small agents for long-horizon workloads. In this work, we empirically show that small agents' performance fails to scale with task complexity on deep search and coding tasks, and we introduce Strategy Auctions for Workload Efficiency (SALE), an agent framework inspired by freelancer marketplaces. In SALE, agents bid with short strategic plans, which are scored by a systematic cost-value mechanism and refined via a shared auction memory, enabling per-task routing and continual self-improvement without training a separate router or running all models to completion. Across deep search and coding tasks of varying complexity, SALE reduces reliance on the largest agent by 53%, lowers overall cost by 35%, and consistently improves upon the largest agent's pass@1 with only a negligible overhead beyond executing the final trace. In contrast, established routers that rely on task descriptions either underperform the largest agent or fail to reduce cost -- often both -- underscoring their poor fit for agentic workflows. These results suggest that while small agents may be insufficient for complex workloads, they can be effectively \"scaled up\" through coordinated task allocation and test-time self-improvement. More broadly, they motivate a systems-level view of agentic AI in which performance gains come less from ever-larger individual models and more from market-inspired coordination mechanisms that organize heterogeneous agents into efficient, adaptive ecosystems.",
      "tldr_zh": "该研究探讨了小型语言模型在处理深层搜索和编程等复杂任务时性能难以扩展的瓶颈，并提出了名为 SALE (Strategy Auctions for Workload Efficiency) 的智能体框架。受自由职业者市场启发，SALE 允许不同规模的智能体通过提交简短战略计划进行竞标，利用成本价值机制进行评分并通过共享拍卖内存实现任务的精准路由与持续自我改进。实验结果表明，SALE 在显著降低 35% 总成本和 53% 最大模型依赖的同时，依然能够超越最大单体智能体的 pass@1 性能。这项工作证明了小型智能体可以通过协调的任务分配和测试时自我提升实现有效扩展，强调了通过市场化协调机制将异构智能体组织成高效、自适应生态系统的重要性，而非单纯依赖更大规模的单一模型。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02751v1",
      "published_date": "2026-02-02 20:05:51 UTC",
      "updated_date": "2026-02-02 20:05:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:48.394930+00:00"
    },
    {
      "arxiv_id": "2602.02742v1",
      "title": "Entropy-Guided Dynamic Tokens for Graph-LLM Alignment in Molecular Understanding",
      "title_zh": "熵引导动态 Token：面向分子理解的图-LLM 对齐",
      "authors": [
        "Zihao Jing",
        "Qiuhao Zeng",
        "Ruiyi Fang",
        "Yan Sun",
        "Boyu Wang",
        "Pingzhao Hu"
      ],
      "abstract": "Molecular understanding is central to advancing areas such as scientific discovery, yet Large Language Models (LLMs) struggle to understand molecular graphs effectively. Existing graph-LLM bridges often adapt the Q-Former-style connector with fixed-length static tokens, which is originally designed for vision tasks. These designs overlook stereochemistry and substructural context and typically require costly LLM-backbone fine-tuning, limiting efficiency and generalization. We introduce EDT-Former, an Entropy-guided Dynamic Token Transformer that generates tokens aligned with informative molecular patches, thereby preserving both local and global structural features for molecular graph understanding. Beyond prior approaches, EDT-Former enables alignment between frozen graph encoders and LLMs without tuning the LLM backbone (excluding the embedding layer), resulting in computationally efficient finetuning, and achieves stateof-the-art results on MoleculeQA, Molecule-oriented Mol-Instructions, and property prediction benchmarks (TDC, MoleculeNet), underscoring its effectiveness for scalable and generalizable multimodal molecular understanding",
      "tldr_zh": "该研究提出了EDT-Former，一种熵引导的动态Token转换器(Entropy-guided Dynamic Token Transformer)，旨在增强大语言模型(LLMs)对分子图的理解能力。针对现有Graph-LLM连接器因使用固定长度静态Token而忽略立体化学(stereochemistry)及子结构上下文的问题，EDT-Former通过生成与信息丰富的分子补丁(molecular patches)相对齐的动态Token，有效保留了分子的局部与全局结构特征。该方法实现了冻结图编码器(frozen graph encoders)与LLM之间的对齐，且无需对LLM主干(backbone)进行复杂微调，显著提升了计算和微调效率。实验证明，EDT-Former在MoleculeQA、Mol-Instructions以及TDC、MoleculeNet等多个属性预测基准测试中均达到了SOTA性能。这项工作为实现高效、可扩展且通用的多模态分子理解提供了新的技术路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.02742v1",
      "published_date": "2026-02-02 19:56:21 UTC",
      "updated_date": "2026-02-02 19:56:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:43.090017+00:00"
    },
    {
      "arxiv_id": "2602.02739v1",
      "title": "TopoPrune: Robust Data Pruning via Unified Latent Space Topology",
      "title_zh": "TopoPrune：基于统一潜空间拓扑的鲁棒数据剪枝",
      "authors": [
        "Arjun Roy",
        "Prajna G. Malettira",
        "Manish Nagaraj",
        "Kaushik Roy"
      ],
      "abstract": "Geometric data pruning methods, while practical for leveraging pretrained models, are fundamentally unstable. Their reliance on extrinsic geometry renders them highly sensitive to latent space perturbations, causing performance to degrade during cross-architecture transfer or in the presence of feature noise. We introduce TopoPrune, a framework which resolves this challenge by leveraging topology to capture the stable, intrinsic structure of data. TopoPrune operates at two scales, (1) utilizing a topology-aware manifold approximation to establish a global low-dimensional embedding of the dataset. Subsequently, (2) it employs differentiable persistent homology to perform a local topological optimization on the manifold embeddings, ranking samples by their structural complexity. We demonstrate that our unified dual-scale topological approach ensures high accuracy and precision, particularly at significant dataset pruning rates (e.g., 90%). Furthermore, through the inherent stability properties of topology, TopoPrune is (a) exceptionally robust to noise perturbations of latent feature embeddings and (b) demonstrates superior transferability across diverse network architectures. This study demonstrates a promising avenue towards stable and principled topology-based frameworks for robust data-efficient learning.",
      "tldr_zh": "该研究针对几何数据剪枝（Geometric data pruning）方法在潜在空间扰动下表现不稳定的问题，提出了 TopoPrune 框架。该框架通过拓扑学方法捕捉数据的内在稳定结构，主要包含两个维度的操作：首先利用拓扑感知流形近似（topology-aware manifold approximation）建立数据集的全局低维嵌入，随后通过可微分持久同调（differentiable persistent homology）对流形嵌入进行局部拓扑优化，并根据结构复杂度对样本进行排名。实验结果表明，TopoPrune 在极高的数据剪枝率（如 90%）下仍能保持高精度和高准度。此外，得益于拓扑学的固有稳定性，该方法对潜在特征嵌入中的噪声表现出极强的鲁棒性，并在不同网络架构之间展现了卓越的可迁移性。该研究为开发稳健且有原则的拓扑驱动数据高效学习框架提供了重要路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under Review",
      "pdf_url": "https://arxiv.org/pdf/2602.02739v1",
      "published_date": "2026-02-02 19:53:59 UTC",
      "updated_date": "2026-02-02 19:53:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:52:58.489012+00:00"
    },
    {
      "arxiv_id": "2602.02738v1",
      "title": "When Noise Lowers The Loss: Rethinking Likelihood-Based Evaluation in Music Large Language Models",
      "title_zh": "当噪声降低损耗：重新审视音乐大语言模型中基于似然的评估",
      "authors": [
        "Xiaosha Li",
        "Chun Liu",
        "Ziyu Wang"
      ],
      "abstract": "The rise of music large language models (LLMs) demands robust methods of evaluating output quality, especially in distinguishing high-quality compositions from \"garbage music\". Curiously, we observe that the standard cross-entropy loss -- a core training metric -- often decrease when models encounter systematically corrupted music, undermining its validity as a standalone quality indicator. To investigate this paradox, we introduce noise injection experiment, where controlled noise signal of varying lengths are injected into musical contexts. We hypothesize that a model's loss reacting positively to these perturbations, specifically a sharp increase (\"Peak\" area) for short injection, can serve as a proxy for its ability to discern musical integrity. Experiments with MusicGen models in the audio waveform domain confirm that Music LLMs respond more strongly to local, texture-level disruptions than to global semantic corruption. Beyond exposing this bias, our results highlight a new principle: the shape of the loss curve -- rather than its absolute value -- encodes critical information about the quality of the generated content (i.e., model behavior). We envision this profile-based evaluation as a label-free, model-intrinsic framework for assessing musical quality -- opening the door to more principled training objectives and sharper benchmarks.",
      "tldr_zh": "该研究探讨了音乐大语言模型 (Music Large Language Models) 在评估输出质量时面临的挑战，发现核心训练指标交叉熵损失 (cross-entropy loss) 在遇到系统性损坏的音乐时往往会降低，导致其无法单独作为可靠的质量评价指标。为此，作者设计了噪声注入实验 (noise injection experiment)，通过向音乐语境中注入可控噪声，观察模型损失函数的变化（特别是短时间注入产生的“峰值”区域）来衡量模型对音乐完整性的辨别能力。在 MusicGen 模型上的实验结果表明，模型对局部纹理层面的破坏比对全局语义损坏更为敏感，揭示了损失曲线的形状而非绝对值才是编码生成内容质量的关键。据此，研究提出了一种基于剖面的评估框架 (profile-based evaluation)，作为一种无需标签的模型内在评价方法，为优化训练目标和建立更精准的音乐评估基准提供了新途径。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026",
      "pdf_url": "https://arxiv.org/pdf/2602.02738v1",
      "published_date": "2026-02-02 19:53:12 UTC",
      "updated_date": "2026-02-02 19:53:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:04.838086+00:00"
    },
    {
      "arxiv_id": "2602.02734v1",
      "title": "WAXAL: A Large-Scale Multilingual African Language Speech Corpus",
      "title_zh": "WAXAL：大规模多语言非洲语言语音语料库",
      "authors": [
        "Abdoulaye Diack",
        "Perry Nelson",
        "Kwaku Agbesi",
        "Angela Nakalembe",
        "MohamedElfatih MohamedKhair",
        "Vusumuzi Dube",
        "Tavonga Siyavora",
        "Subhashini Venugopalan",
        "Jason Hickey",
        "Uche Okonkwo",
        "Abhishek Bapna",
        "Isaac Wiafe",
        "Raynard Dodzi Helegah",
        "Elikem Doe Atsakpo",
        "Charles Nutrokpor",
        "Fiifi Baffoe Payin Winful",
        "Kafui Kwashie Solaga",
        "Jamal-Deen Abdulai",
        "Akon Obu Ekpezu",
        "Audace Niyonkuru",
        "Samuel Rutunda",
        "Boris Ishimwe",
        "Michael Melese",
        "Engineer Bainomugisha",
        "Joyce Nakatumba-Nabende",
        "Andrew Katumba",
        "Claire Babirye",
        "Jonathan Mukiibi",
        "Vincent Kimani",
        "Samuel Kibacia",
        "James Maina",
        "Fridah Emmah",
        "Ahmed Ibrahim Shekarau",
        "Ibrahim Shehu Adamu",
        "Yusuf Abdullahi",
        "Howard Lakougna",
        "Bob MacDonald",
        "Hadar Shemtov",
        "Aisha Walcott-Bryant",
        "Moustapha Cisse",
        "Avinatan Hassidim",
        "Jeff Dean",
        "Yossi Matias"
      ],
      "abstract": "The advancement of speech technology has predominantly favored high-resource languages, creating a significant digital divide for speakers of most Sub-Saharan African languages. To address this gap, we introduce WAXAL, a large-scale, openly accessible speech dataset for 21 languages representing over 100 million speakers. The collection consists of two main components: an Automated Speech Recognition (ASR) dataset containing approximately 1,250 hours of transcribed, natural speech from a diverse range of speakers, and a Text-to-Speech (TTS) dataset with over 180 hours of high-quality, single-speaker recordings reading phonetically balanced scripts. This paper details our methodology for data collection, annotation, and quality control, which involved partnerships with four African academic and community organizations. We provide a detailed statistical overview of the dataset and discuss its potential limitations and ethical considerations. The WAXAL datasets are released at https://huggingface.co/datasets/google/WaxalNLP under the permissive CC-BY-4.0 license to catalyze research, enable the development of inclusive technologies, and serve as a vital resource for the digital preservation of these languages.",
      "tldr_zh": "该研究推出了WAXAL，这是一个面向21种语言、覆盖超过1亿使用者的开源大规模多语种非洲语言语音数据集，旨在缩小撒哈拉以南非洲语言在语音技术领域的数字鸿沟。WAXAL包含两个核心组成部分：约1250小时包含转写自然语音的自动语音识别(ASR)数据集，以及超过180小时的高质量、单人朗读音素平衡脚本的文本转语音(TTS)数据集。研究团队通过与四个非洲学术及社区组织建立合作伙伴关系，确保了数据采集、标注和质量控制流程的专业性。论文提供了详细的数据集统计概况，并深入探讨了其潜在局限性与伦理考量。目前，WAXAL已在CC-BY-4.0许可下发布，为推动包容性语音技术研发、学术研究以及非洲语言的数字化保存提供了至关重要的资源。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "Initial dataset release",
      "pdf_url": "https://arxiv.org/pdf/2602.02734v1",
      "published_date": "2026-02-02 19:49:19 UTC",
      "updated_date": "2026-02-02 19:49:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:07.594954+00:00"
    },
    {
      "arxiv_id": "2602.02731v1",
      "title": "Predicting first-episode homelessness among US Veterans using longitudinal EHR data: time-varying models and social risk factors",
      "title_zh": "基于纵向电子健康记录数据预测美国退伍军人首次流浪：时变模型与社会风险因素",
      "authors": [
        "Rohan Pandey",
        "Haijuan Yan",
        "Hong Yu",
        "Jack Tsai"
      ],
      "abstract": "Homelessness among US veterans remains a critical public health challenge, yet risk prediction offers a pathway for proactive intervention. In this retrospective prognostic study, we analyzed electronic health record (EHR) data from 4,276,403 Veterans Affairs patients during a 2016 observation period to predict first-episode homelessness occurring 3-12 months later in 2017 (prevalence: 0.32-1.19%). We constructed static and time-varying EHR representations, utilizing clinician-informed logic to model the persistence of clinical conditions and social risks over time. We then compared the performance of classical machine learning, transformer-based masked language models, and fine-tuned large language models (LLMs). We demonstrate that incorporating social and behavioral factors into longitudinal models improved precision-recall area under the curve (PR-AUC) by 15-30%. In the top 1% risk tier, models yielded positive predictive values ranging from 3.93-4.72% at 3 months, 7.39-8.30% at 6 months, 9.84-11.41% at 9 months, and 11.65-13.80% at 12 months across model architectures. Large language models underperformed encoder-based models on discrimination but showed smaller performance disparities across racial groups. These results demonstrate that longitudinal, socially informed EHR modeling concentrates homelessness risk into actionable strata, enabling targeted and data-informed prevention strategies for at-risk veterans.",
      "tldr_zh": "该研究利用超过427万名美国退伍军人的纵向电子健康档案(EHR)数据，旨在通过构建静态和时变(Time-varying)的表征来预测退伍军人首次发生无家可归的风险。研究团队对比了传统机器学习、基于Transformer的掩码语言模型(Masked Language Models)以及微调的大语言模型(LLMs)的表现，并重点模拟了临床状况和社交风险随时间变化的持久性。实验结果表明，在纵向模型中整合社交和行为因素可将精确率-召回率曲线下面积(PR-AUC)提升15%至30%，且在最高风险层级中，模型在预测未来3至12个月风险时表现出良好的阳性预测值(PPVs)。虽然LLMs在区分度性能上略逊于基于编码器的模型，但在不同种族群体间展现了更小的性能差异。该研究证明了融合社交信息的纵向EHR建模能够将无家可归风险集中到可操作的层级，为针对高风险退伍军人的精准预防策略提供了数据支撑。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02731v1",
      "published_date": "2026-02-02 19:46:46 UTC",
      "updated_date": "2026-02-02 19:46:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:05.237547+00:00"
    },
    {
      "arxiv_id": "2602.02729v1",
      "title": "CAPS: Unifying Attention, Recurrence, and Alignment in Transformer-based Time Series Forecasting",
      "title_zh": "CAPS：在基于 Transformer 的时间序列预测中统一注意力、循环与对齐",
      "authors": [
        "Viresh Pati",
        "Yubin Kim",
        "Vinh Pham",
        "Jevon Twitty",
        "Shihao Yang",
        "Jiecheng Lu"
      ],
      "abstract": "This paper presents $\\textbf{CAPS}$ (Clock-weighted Aggregation with Prefix-products and Softmax), a structured attention mechanism for time series forecasting that decouples three distinct temporal structures: global trends, local shocks, and seasonal patterns. Standard softmax attention entangles these through global normalization, while recent recurrent models sacrifice long-term, order-independent selection for order-dependent causal structure. CAPS combines SO(2) rotations for phase alignment with three additive gating paths -- Riemann softmax, prefix-product gates, and a Clock baseline -- within a single attention layer. We introduce the Clock mechanism, a learned temporal weighting that modulates these paths through a shared notion of temporal importance. Experiments on long- and short-term forecasting benchmarks surpass vanilla softmax and linear attention mechanisms and demonstrate competitive performance against seven strong baselines with linear complexity. Our code implementation is available at https://github.com/vireshpati/CAPS-Attention.",
      "tldr_zh": "该研究提出了CAPS (Clock-weighted Aggregation with Prefix-products and Softmax)，一种专为时间序列预测设计的结构化注意力机制，旨在统一注意力、递归和对齐。该模型通过解耦全局趋势(global trends)、局部冲击(local shocks)和季节性模式(seasonal patterns)，解决了标准softmax注意力在处理不同时间结构时的纠缠问题。CAPS在单一注意力层中结合了用于相位对齐的SO(2) rotations，以及Riemann softmax、前缀积门控(prefix-product gates)和Clock baseline三个加性门控路径。论文引入了Clock机制，通过学习到的时间权重在共享的时间重要性概念下对这些路径进行调节。实验结果显示，CAPS在长期和短期预测基准测试中均优于传统的softmax和线性注意力机制。在保持线性复杂度(linear complexity)的同时，该模型在与七个强基线模型的对比中展现出极具竞争力的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02729v1",
      "published_date": "2026-02-02 19:44:24 UTC",
      "updated_date": "2026-02-02 19:44:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:08.935888+00:00"
    },
    {
      "arxiv_id": "2602.02727v1",
      "title": "Search-Augmented Masked Diffusion Models for Constrained Generation",
      "title_zh": "面向约束生成的搜索增强掩码扩散模型",
      "authors": [
        "Huu Binh Ta",
        "Michael Cardei",
        "Alvaro Velasquez",
        "Ferdinando Fioretto"
      ],
      "abstract": "Discrete diffusion models generate sequences by iteratively denoising samples corrupted by categorical noise, offering an appealing alternative to autoregressive decoding for structured and symbolic generation. However, standard training targets a likelihood-based objective that primarily matches the data distribution and provides no native mechanism for enforcing hard constraints or optimizing non-differentiable properties at inference time. This work addresses this limitation and introduces Search-Augmented Masked Diffusion (SearchDiff), a training-free neurosymbolic inference framework that integrates informed search directly into the reverse denoising process. At each denoising step, the model predictions define a proposal set that is optimized under a user-specified property satisfaction, yielding a modified reverse transition that steers sampling toward probable and feasible solutions. Experiments in biological design and symbolic reasoning illustrate that SearchDiff substantially improves constraint satisfaction and property adherence, while consistently outperforming discrete diffusion and autoregressive baselines.",
      "tldr_zh": "该研究针对离散扩散模型(Discrete Diffusion Models)在推理过程中难以强制执行硬约束或优化非微分属性的局限，提出了Search-Augmented Masked Diffusion (SearchDiff)框架。这是一个无需额外训练(Training-free)的神经符号推理框架，旨在将启发式搜索(Informed Search)直接集成到反向去噪(Reverse Denoising)过程中。在每个去噪步骤中，模型根据用户指定的属性满意度(Property Satisfaction)优化预测的候选集，通过修正后的反向转换引导采样过程朝向高概率且可行的解。在生物设计(Biological Design)和符号推理(Symbolic Reasoning)领域的实验结果表明，SearchDiff显著提升了约束满足率和属性符合度。该框架在性能上一致优于标准的离散扩散模型以及传统的自回归(Autoregressive)基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Huu Binh Ta and Michael Cardei contributed equally to this work",
      "pdf_url": "https://arxiv.org/pdf/2602.02727v1",
      "published_date": "2026-02-02 19:43:25 UTC",
      "updated_date": "2026-02-02 19:43:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:09.901393+00:00"
    },
    {
      "arxiv_id": "2602.02711v1",
      "title": "Dynamic Mix Precision Routing for Efficient Multi-step LLM Interaction",
      "title_zh": "面向高效多步大语言模型交互的动态混合精度路由",
      "authors": [
        "Yuanzhe Li",
        "Jianing Deng",
        "Jingtong Hu",
        "Tianlong Chen",
        "Song Wang",
        "Huanrui Yang"
      ],
      "abstract": "Large language models (LLM) achieve strong performance in long-horizon decision-making tasks through multi-step interaction and reasoning at test time. While practitioners commonly believe a higher task success rate necessitates the use of a larger and stronger LLM model, multi-step interaction with a large LLM incurs prohibitive inference cost. To address this problem, we explore the use of low-precision quantized LLM in the long-horizon decision-making process. Based on the observation of diverse sensitivities among interaction steps, we propose a dynamic mix-precision routing framework that adaptively selects between high-precision and low-precision LLMs at each decision step. The router is trained via a two-stage pipeline, consisting of KL-divergence-based supervised learning that identifies precision-sensitive steps, followed by Group-Relative Policy Optimization (GRPO) to further improve task success rates. Experiments on ALFWorld demonstrate that our approach achieves a great improvement on accuracy-cost trade-off over single-precision baselines and heuristic routing methods.",
      "tldr_zh": "该研究针对大语言模型(LLM)在长时决策任务中多步交互带来的高昂推理成本问题，提出了一种Dynamic Mix-Precision Routing框架。该框架利用低精度量化的LLM，并基于不同交互步骤对精度敏感度存在差异的观察，在每个决策步骤中动态选择高精度或低精度的LLM进行处理。路由器的训练采用了两阶段流水线，首先通过基于KL-divergence的监督学习识别敏感步骤，随后利用Group-Relative Policy Optimization (GRPO) 进一步优化任务成功率。在ALFWorld基准测试上的实验结果表明，该方法在准确率与成本的权衡(Accuracy-Cost Trade-off)上显著优于单精度基准模型和传统的启发式路由方法。该研究为实现高效且低成本的多步LLM推理与决策提供了创新的技术路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02711v1",
      "published_date": "2026-02-02 19:24:04 UTC",
      "updated_date": "2026-02-02 19:24:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:18.925659+00:00"
    },
    {
      "arxiv_id": "2602.02709v1",
      "title": "ATLAS : Adaptive Self-Evolutionary Research Agent with Task-Distributed Multi-LLM Supporters",
      "title_zh": "ATLAS：基于任务分布式多 LLM 支撑的自适应自演化研究智能体",
      "authors": [
        "Ujin Jeon",
        "Jiyong Kwon",
        "Madison Ann Sullivan",
        "Caleb Eunho Lee",
        "Guang Lin"
      ],
      "abstract": "Recent multi-LLM agent systems perform well in prompt optimization and automated problem-solving, but many either keep the solver frozen after fine-tuning or rely on a static preference-optimization loop, which becomes intractable for long-horizon tasks. We propose ATLAS (Adaptive Task-distributed Learning for Agentic Self-evolution), a task-distributed framework that iteratively develops a lightweight research agent while delegating complementary roles to specialized supporter agents for exploration, hyperparameter tuning, and reference policy management. Our core algorithm, Evolving Direct Preference Optimization (EvoDPO), adaptively updates the phase-indexed reference policy. We provide a theoretical regret analysis for a preference-based contextual bandit under concept drift. In addition, experiments were conducted on non-stationary linear contextual bandits and scientific machine learning (SciML) loss reweighting for the 1D Burgers' equation. Both results show that ATLAS improves stability and performance over a static single-agent baseline.",
      "tldr_zh": "该研究提出了 ATLAS (Adaptive Task-distributed Learning for Agentic Self-evolution)，一种旨在解决现有多大语言模型 (Multi-LLM) 智能体系统在长程任务中因策略固定或静态偏好优化循环而导致性能受限的任务分布式框架。该系统通过开发一个轻量级研究智能体，并将探索、超参数调优和参考策略管理等互补角色委派给专门的辅助智能体，实现了智能体的自我演化。其核心算法 Evolving Direct Preference Optimization (EvoDPO) 能够自适应地更新阶段索引的参考策略，研究还针对概念漂移下的偏好上下文老虎机 (Contextual Bandit) 提供了理论上的悔恨值分析 (Regret Analysis)。在非平稳线性上下文老虎机和科学机器学习 (SciML) 的 1D Burgers' 方程损失重权衡量实验中，ATLAS 展现出比静态单智能体基准更高的稳定性和性能，为复杂科研任务中的智能体自主进化提供了有效方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02709v1",
      "published_date": "2026-02-02 19:23:33 UTC",
      "updated_date": "2026-02-02 19:23:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:16.022962+00:00"
    },
    {
      "arxiv_id": "2602.02708v1",
      "title": "BinaryPPO: Efficient Policy Optimization for Binary Classification",
      "title_zh": "BinaryPPO：面向二分类的高效策略优化",
      "authors": [
        "Punya Syon Pandey",
        "Zhijing Jin"
      ],
      "abstract": "Supervised fine-tuning (SFT) is the standard approach for binary classification tasks such as toxicity detection, factuality verification, and causal inference. However, SFT often performs poorly in real-world settings with label noise, class imbalance, or sparse supervision. We introduce BinaryPPO, an offline reinforcement learning large language model (LLM) framework that reformulates binary classification as a reward maximization problem. Our method leverages a variant of Proximal Policy Optimization (PPO) with a confidence-weighted reward function that penalizes uncertain or incorrect predictions, enabling the model to learn robust decision policies from static datasets without online interaction. Across eight domain-specific benchmarks and multiple models with differing architectures, BinaryPPO improves accuracy by 40-60 percentage points, reaching up to 99%, substantially outperforming supervised baselines. We provide an in-depth analysis of the role of reward shaping, advantage scaling, and policy stability in enabling this improvement. Overall, we demonstrate that confidence-based reward design provides a robust alternative to SFT for binary classification. Our code is available at https://github.com/psyonp/BinaryPPO.",
      "tldr_zh": "该研究提出了BinaryPPO，一种专为二分类任务设计的离线强化学习(Offline Reinforcement Learning)大语言模型框架，旨在解决监督微调(Supervised Fine-Tuning, SFT)在面对标签噪声、类别失衡或稀疏监督时表现不佳的问题。BinaryPPO将二分类任务重构为奖励最大化问题，并利用一种带有置信度加权奖励函数(Confidence-Weighted Reward Function)的近端策略优化(Proximal Policy Optimization, PPO)变体，通过惩罚不确定或错误的预测，使模型能从静态数据集中学习鲁棒的决策策略。在涵盖毒性检测和事实核实等八个领域特定基准测试中，BinaryPPO在不同架构模型上的准确率显著提升了40至60个百分点，最高达到99%，大幅超越了传统的监督基准。此外，该研究还深入分析了奖励建模(Reward Shaping)、优势缩放(Advantage Scaling)和策略稳定性(Policy Stability)在性能提升中的关键作用。实验结果最终证明，基于置信度的奖励设计是二分类任务中替代SFT的一种稳健且高效的方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02708v1",
      "published_date": "2026-02-02 19:22:45 UTC",
      "updated_date": "2026-02-02 19:22:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:21.901808+00:00"
    },
    {
      "arxiv_id": "2602.02707v1",
      "title": "Every Bit Counts: A Theoretical Study of Precision-Expressivity Tradeoffs in Quantized Transformers",
      "title_zh": "每一比特皆关键：量化 Transformer 精度与表达能力权衡的理论研究",
      "authors": [
        "Sayak Chakrabarti",
        "Toniann Pitassi",
        "Josh Alman"
      ],
      "abstract": "Quantization reduces the numerical precision of Transformer computations and is widely used to accelerate inference, yet its effect on expressivity remains poorly characterized. We demonstrate a fine-grained theoretical tradeoff between expressivity and precision: For every p we exhibit a function Γ, inspired by the equality function, and prove that a one-layer softmax Transformer can compute Γ, with p bits of precision, but not with p-1 bits of precision.\n  This result concretely explains the widely observed phenomenon of empirical loss of expressivity when quantization is used. Practically, it suggests that tasks requiring equality-like comparisons (exact match, membership, etc.) are especially sensitive to quantization. Dropping even one bit can cross a threshold where the model cannot represent the needed comparison reliably. Thus, it paves the way for developing heuristics that will help practitioners choose how much quantization is possible: the precision should be chosen as a function of the length of equality to be checked for the specific task.\n  Our proofs combine explicit finite-precision Transformer constructions with communication-complexity lower bounds, yielding a tight \"one-bit\" threshold.",
      "tldr_zh": "这项研究针对 Quantized Transformers 中的精度与表达能力 (Expressivity) 权衡问题进行了深入的理论探讨。研究者通过受 Equality function 启发的 $\\Gamma$ 函数证明，单层 Softmax Transformer 在 $p$ 位精度下可以计算该函数，但在 $p-1$ 位精度下则无法实现，从理论上具体解释了量化过程中模型表达能力受损的现象。研究指出，涉及 Exact match 或 Membership 等相等比较的任务对量化极其敏感，减少哪怕 1 位精度都可能导致模型无法可靠地表示必要的逻辑比较。因此，论文建议实际应用中应根据具体任务所需的相等性检查长度来选择合适的精度。该研究结合了有限精度 Transformer 构造与 Communication-complexity 下界，得出了紧凑的 One-bit 阈值，为开发量化启发式算法提供了理论依据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02707v1",
      "published_date": "2026-02-02 19:22:32 UTC",
      "updated_date": "2026-02-02 19:22:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:26.122973+00:00"
    },
    {
      "arxiv_id": "2602.02699v1",
      "title": "Sparsely Supervised Diffusion",
      "title_zh": "稀疏监督扩散",
      "authors": [
        "Wenshuai Zhao",
        "Zhiyuan Li",
        "Yi Zhao",
        "Mohammad Hassan Vali",
        "Martin Trapp",
        "Joni Pajarinen",
        "Juho Kannala",
        "Arno Solin"
      ],
      "abstract": "Diffusion models have shown remarkable success across a wide range of generative tasks. However, they often suffer from spatially inconsistent generation, arguably due to the inherent locality of their denoising mechanisms. This can yield samples that are locally plausible but globally inconsistent. To mitigate this issue, we propose sparsely supervised learning for diffusion models, a simple yet effective masking strategy that can be implemented with only a few lines of code. Interestingly, the experiments show that it is safe to mask up to 98\\% of pixels during diffusion model training. Our method delivers competitive FID scores across experiments and, most importantly, avoids training instability on small datasets. Moreover, the masking strategy reduces memorization and promotes the use of essential contextual information during generation.",
      "tldr_zh": "该研究针对扩散模型 (Diffusion models) 因去噪机制局部性导致的空间生成不一致问题，提出了扩散模型的稀疏监督学习 (Sparsely Supervised Diffusion)，这是一种简单且高效的掩码 (masking) 策略。实验结果表明，在模型训练过程中掩盖高达 98% 的像素依然是安全的，且该方法在多项实验中均取得了具有竞争力的 FID 分数。此外，该策略有效避免了在小数据集上的训练不稳定现象，并显著降低了模型的记忆效应 (memorization)。通过促使模型在生成过程中充分利用关键的上下文信息 (contextual information)，该方法不仅提高了生成的全局一致性，还显著增强了模型的泛化表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.02699v1",
      "published_date": "2026-02-02 19:11:56 UTC",
      "updated_date": "2026-02-02 19:11:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:42.435503+00:00"
    },
    {
      "arxiv_id": "2602.02689v1",
      "title": "Eidolon: A Practical Post-Quantum Signature Scheme Based on k-Colorability in the Age of Graph Neural Networks",
      "title_zh": "Eidolon：图神经网络时代基于 k-可着色性的实用后量子签名方案",
      "authors": [
        "Asmaa Cherkaoui",
        "Ramon Flores",
        "Delaram Kahrobaei",
        "Richard Wilson"
      ],
      "abstract": "We propose Eidolon, a practical post-quantum signature scheme based on the NP-complete k-colorability problem. Our construction generalizes the Goldreich-Micali-Wigderson zero-knowledge protocol to arbitrary k >= 3, applies the Fiat-Shamir transform, and uses Merkle-tree commitments to compress signatures from O(tn) to O(t log n). Crucially, we generate hard instances via planted \"quiet\" colorings that preserve the statistical profile of random graphs. We present the first empirical security analysis of such a scheme against both classical solvers (ILP, DSatur) and a custom graph neural network (GNN) attacker. Experiments show that for n >= 60, neither approach recovers the secret coloring, demonstrating that well-engineered k-coloring instances can resist modern cryptanalysis, including machine learning. This revives combinatorial hardness as a credible foundation for post-quantum signatures.",
      "tldr_zh": "该研究提出了 Eidolon，一种基于 NP-complete 问题 k-colorability 的实用后量子签名方案 (post-quantum signature scheme)。该方案通过将 Goldreich-Micali-Wigderson 零知识协议扩展至任意 k >= 3，并结合 Fiat-Shamir 变换以及 Merkle-tree 承诺技术，成功将签名复杂度从 O(tn) 压缩至 O(t log n)。为了确保安全性，研究者通过植入保留随机图统计特性的 quiet 着色方法生成困难实例，以抵御现代密码分析。研究团队针对该方案进行了首次实证安全分析，涵盖了 ILP、DSatur 等经典求解器以及自定义的图神经网络 (GNN) 攻击者。实验结果表明，在 n >= 60 的情况下，没有任何攻击手段能够恢复秘密着色，证明了精心设计的 k-coloring 实例具备抵抗机器学习攻击的潜力。这项工作重新确立了组合数学硬度作为后量子签名可靠基础的地位。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "23 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2602.02689v1",
      "published_date": "2026-02-02 19:05:50 UTC",
      "updated_date": "2026-02-02 19:05:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:43.034146+00:00"
    },
    {
      "arxiv_id": "2602.02686v1",
      "title": "Monotonicity as an Architectural Bias for Robust Language Models",
      "title_zh": "单调性：提升语言模型鲁棒性的架构偏置",
      "authors": [
        "Patrick Cooper",
        "Alireza Nadali",
        "Ashutosh Trivedi",
        "Alvaro Velasquez"
      ],
      "abstract": "Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, carefully structured perturbations in high-dimensional input spaces can induce large and unpredictable changes in internal semantic representations and output.\n  We investigate monotonicity as an architectural inductive bias for improving the robustness of Transformer-based language models. Monotonicity constrains semantic transformations so that strengthening information, evidence, or constraints cannot lead to regressions in the corresponding internal representations. Such order-preserving behavior has long been exploited in control and safety-critical systems to simplify reasoning and improve robustness, but has traditionally been viewed as incompatible with the expressivity required by neural language models.\n  We show that this trade-off is not inherent. By enforcing monotonicity selectively in the feed-forward sublayers of sequence-to-sequence Transformers -- while leaving attention mechanisms unconstrained -- we obtain monotone language models that preserve the performance of their pretrained counterparts. This architectural separation allows negation, contradiction, and contextual interactions to be introduced explicitly through attention, while ensuring that subsequent semantic refinement is order-preserving. Empirically, monotonicity substantially improves robustness: adversarial attack success rates drop from approximately 69% to 19%, while standard summarization performance degrades only marginally.",
      "tldr_zh": "该研究探讨了将单调性(Monotonicity)作为一种架构归纳偏差(Architectural Inductive Bias)，以提升Transformer语言模型在面对对抗性攻击和越狱攻击时的鲁棒性。研究者通过在序列到序列(Sequence-to-Sequence)架构的Feed-forward Sublayers中选择性地强制执行单调性约束，同时保持Attention mechanisms不受限制，实现了保序的语义转换。这种设计允许模型通过注意力机制处理否定和上下文交互，同时确保后续的语义细化过程不会因信息的加强而导致内部表征的异常波动。实验结果显示，该模型在基本维持标准摘要性能的同时，使对抗性攻击的成功率从约69%大幅降低至19%。该研究证明了单调性约束能够有效平衡神经网络的表达能力与安全性，为构建更可靠的语言模型提供了新的架构思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2602.02686v1",
      "published_date": "2026-02-02 19:03:19 UTC",
      "updated_date": "2026-02-02 19:03:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:43.525116+00:00"
    },
    {
      "arxiv_id": "2602.02671v1",
      "title": "MARA: Continuous SE(3)-Equivariant Attention for Molecular Force Fields",
      "title_zh": "MARA：面向分子力场的连续 SE(3) 等变注意力机制",
      "authors": [
        "Francesco Leonardi",
        "Boris Bonev",
        "Kaspar Riesen"
      ],
      "abstract": "Machine learning force fields (MLFFs) have become essential for accurate and efficient atomistic modeling. Despite their high accuracy, most existing approaches rely on fixed angular expansions, limiting flexibility in weighting local geometric interactions. We introduce Modular Angular-Radial Attention (MARA), a module that extends spherical attention -- originally developed for SO(3) tasks -- to the molecular domain and SE(3), providing an efficient approximation of equivariant interactions. MARA operates directly on the angular and radial coordinates of neighboring atoms, enabling flexible, geometrically informed, and modular weighting of local environments. Unlike existing attention mechanisms in SE(3)-equivariant architectures, MARA can be integrated in a plug-and-play manner into models such as MACE without architectural modifications. Across molecular benchmarks, MARA improves energy and force predictions, reduces high-error events, and enhances robustness. These results demonstrate that continuous spherical attention is an effective and generalizable geometric operator that increases the expressiveness, stability, and reliability of atomistic models.",
      "tldr_zh": "该研究针对机器学习力场(Machine learning force fields)在处理局部几何交互时依赖固定角度展开且缺乏灵活性的问题，提出了模块化角径向注意力(Modular Angular-Radial Attention, MARA)模块。MARA将原本用于SO(3)任务的球面注意力扩展至分子领域和SE(3)等变空间，通过直接作用于相邻原子的角坐标和径向坐标，实现了对局部环境灵活且具有几何感知能力的模块化加权。该模块具有显著的即插即用(plug-and-play)特性，能够无缝集成到MACE等现有架构中而无需进行架构修改。实验结果表明，MARA在多个分子基准测试中有效提升了能量和力预测的精度，显著减少了高误差事件并增强了模型的鲁棒性。这项工作证明了连续球面注意力是一种有效且通用的几何算子，能够显著提升原子模型的表达能力、稳定性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02671v1",
      "published_date": "2026-02-02 19:00:08 UTC",
      "updated_date": "2026-02-02 19:00:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:47.520455+00:00"
    },
    {
      "arxiv_id": "2602.02660v1",
      "title": "MARS: Modular Agent with Reflective Search for Automated AI Research",
      "title_zh": "MARS：基于反思搜索的自动化 AI 研究模块化智能体",
      "authors": [
        "Jiefeng Chen",
        "Bhavana Dalvi Mishra",
        "Jaehyun Nam",
        "Rui Meng",
        "Tomas Pfister",
        "Jinsung Yoon"
      ],
      "abstract": "Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that ignore execution costs and causal factors. We introduce MARS (Modular Agent with Reflective Search), a framework optimized for autonomous AI research. MARS relies on three pillars: (1) Budget-Aware Planning via cost-constrained Monte Carlo Tree Search (MCTS) to explicitly balance performance with execution expense; (2) Modular Construction, employing a \"Design-Decompose-Implement\" pipeline to manage complex research repositories; and (3) Comparative Reflective Memory, which addresses credit assignment by analyzing solution differences to distill high-signal insights. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench under comparable settings, maintaining competitiveness with the global leaderboard's top methods. Furthermore, the system exhibits qualitative \"Aha!\" moments, where 63% of all utilized lessons originate from cross-branch transfer, demonstrating that the agent effectively generalizes insights across search paths.",
      "tldr_zh": "该研究引入了 MARS (Modular Agent with Reflective Search)，这是一种专为自动化 AI 研究设计的模块化智能体框架，旨在解决现有 LLM 智能体在处理高昂计算成本和复杂性能归因时的不足。MARS 建立了三大核心支柱：首先是通过受成本约束的蒙特卡洛树搜索 (Monte Carlo Tree Search, MCTS) 实现预算感知规划，从而在执行支出与模型性能间取得平衡；其次是利用“设计-分解-实现”的流水线进行模块化构建，以高效管理复杂的科研代码库；最后通过比较反射记忆 (Comparative Reflective Memory) 分析不同方案的差异，从而精准提取高信号的科研见解。实验结果显示，MARS 在 MLE-Bench 基准测试中取得了开源框架的先进水平 (State-of-the-art)，并展现出卓越的知识泛化能力，其 63% 的有效经验源自搜索路径间的跨分支迁移。该系统不仅在性能上保持全球竞争力，还证明了其在受限预算下进行自主科学发现的巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2602.02660v1",
      "published_date": "2026-02-02 19:00:03 UTC",
      "updated_date": "2026-02-02 19:00:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-02-04T07:53:48.526233+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 225,
  "processed_papers_count": 225,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-02-04T07:55:11.986388+00:00"
}