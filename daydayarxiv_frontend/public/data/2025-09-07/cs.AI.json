{
  "date": "2025-09-07",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-07 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\næˆ‘æ˜¯ä½ ä»¬çš„è€æœ‹å‹ï¼Œä¸“æ³¨äº arXiv è®ºæ–‡é€Ÿè¯»çš„ç ”ç©¶å‘˜ã€‚\n\n**ä¸€å¥è¯æ€»ç»“ä»Šå¤©ï¼š**\nä»Šå¤©çš„ arXiv ä¾ç„¶æ˜¯ LLM çš„å¤©ä¸‹ï¼Œä½†é‡å¿ƒæ˜æ˜¾è½¬å‘äº†æ›´æ·±å±‚çš„**æ¨ç†ä¼˜åŒ–ï¼ˆReasoningï¼‰**â€”â€”ç‰¹åˆ«æ˜¯å¦‚ä½•ç»™ O1/R1 ç±»æ¨¡å‹çš„é•¿æ€ç»´é“¾â€œç˜¦èº«â€ï¼›**Agent åœ¨è½¯ä»¶å·¥ç¨‹ä¸­çš„ç³»ç»ŸåŒ–è½åœ°**è¿æ¥äº†é‡ç£…ç»¼è¿°ï¼›æ­¤å¤–ï¼Œ**é‡‘èå’Œå®‰å…¨é¢†åŸŸçš„çº¢é˜Ÿæµ‹è¯•**ã€ç¡¬ä»¶ç”Ÿæˆçš„éªŒè¯ä»¥åŠ **1-bit ç¥ç»ç½‘ç»œ**çš„é«˜æ•ˆæ¶æ„ä¹Ÿæ¶Œç°äº†éå¸¸æ‰å®çš„å·¥ä½œã€‚\n\nä¸‹é¢æˆ‘ä»¬è¿›å…¥æ­£é¢˜ï¼Œå…ˆçœ‹å‡ ç¯‡ä¸å¾—ä¸è¯»çš„é‡ç£…æ–‡ç« ã€‚\n\n---\n\n### ğŸš€ã€é‡ç£…æ¨è & æ ¸å¿ƒæ¶æ„ã€‘\n\n#### 1. è½¯ä»¶å·¥ç¨‹ 3.0ï¼šä»ç”Ÿæˆä»£ç åˆ°ç”Ÿæˆå·¥ç¨‹\n**Agentic Software Engineering: Foundational Pillars and a Research Roadmap**\n*(æ™ºèƒ½ä½“è½¯ä»¶å·¥ç¨‹ï¼šåŸºçŸ³ä¸ç ”ç©¶è·¯çº¿å›¾)*\n\n> **Authors:** Ahmed E. Hassan, et al. (SE é¢†åŸŸçš„çŸ¥åå›¢é˜Ÿ)\n> **å…³é”®è¯:** Agentic SE (SE 3.0), Agent Command Environment (ACE), Agent Execution Environment (AEE)\n\n**ä¸»è¦è´¡çŒ®ï¼š** è¿™æ˜¯ä¸€ç¯‡éå¸¸æœ‰åˆ†é‡çš„ Vision Paperã€‚ä½œè€…è®¤ä¸ºæˆ‘ä»¬æ­£å¤„äº **Agentic SE (SE 3.0)** çš„æ–°æ—¶ä»£ï¼Œæ™ºèƒ½ä½“ä¸å†åªæ˜¯ç®€å•çš„ç”Ÿæˆä»£ç ï¼Œè€Œæ˜¯è¦å®Œæˆå¤æ‚çš„ã€ç›®æ ‡å¯¼å‘çš„å·¥ç¨‹ä»»åŠ¡ã€‚æ–‡ç« æå‡ºäº† **SE for Humans** å’Œ **SE for Agents** çš„åŒé‡æ€§ï¼Œå¹¶è®¾è®¡äº†ä¸¤ä¸ªæ ¸å¿ƒç¯å¢ƒï¼š\n1.  **ACE (Agent Command Environment):** äººç±»ä½œä¸ºæŒ‡æŒ¥å®˜ï¼Œåœ¨è¿™é‡Œç¼–æ’å’ŒæŒ‡å¯¼æ™ºèƒ½ä½“å›¢é˜Ÿã€‚\n2.  **AEE (Agent Execution Environment):** æ™ºèƒ½ä½“çš„æ•°å­—å·¥ä½œç©ºé—´ï¼Œå®ƒä»¬åœ¨è¿™é‡Œæ‰§è¡Œä»»åŠ¡ï¼Œå¹¶åœ¨é‡åˆ°æ¨¡ç³Šæ€§æ—¶å›è°ƒäººç±»ä¸“å®¶ã€‚\n**Implication:** è½¯ä»¶å·¥ç¨‹çš„èŒƒå¼æ­£åœ¨ä»â€œè¾…åŠ©ç¼–ç â€å‘â€œçœŸæ­£çš„æ™ºèƒ½ä½“å·¥ç¨‹â€è½¬å˜ï¼Œè¿™ç¯‡è®ºæ–‡ä¸ºæœªæ¥çš„ SE ç ”ç©¶æä¾›äº†æ¦‚å¿µæ”¯æ¶å’Œè¯æ±‡è¡¨ã€‚\n\n#### 2. ç»™æ¨ç†æ¨¡å‹â€œç˜¦èº«â€ï¼šé•¿æ€ç»´é“¾ä¸ä¸€å®šæœ€å¥½\n**From Long to Short: LLMs Excel at Trimming Own Reasoning Chains**\n*(ä»é•¿åˆ°çŸ­ï¼šå¤§æ¨¡å‹æ“…é•¿ä¿®å‰ªè‡ªå·±çš„æ¨ç†é“¾)*\n\n> **Authors:** Wei Han, et al.\n> **å…³é”®è¯:** Large Reasoning Models (LRMs), Test-time Scaling, EDIT, Overthinking\n\n**ä¸»è¦è´¡çŒ®ï¼š** é’ˆå¯¹ O1/R1 é£æ ¼çš„é•¿æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ï¼Œä½œè€…å‘ç°äº†ä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ï¼š**è¿‡åº¦æ€è€ƒï¼ˆOverthinkingï¼‰**ã€‚æ¨¡å‹å¾€å¾€ä¼šæŠŠç®€å•é—®é¢˜å¤æ‚åŒ–ï¼Œå¯¼è‡´æ¨ç†è·¯å¾„å†—é•¿ä¸”éš¾ä»¥è§£é‡Šã€‚ä½œè€…æå‡ºäº†ä¸€ç§æµ‹è¯•æ—¶æ‰©å±•æ–¹æ³• **EDIT (Efficient Dynamic Inference Trimming)**ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** EDIT èƒ½å¤Ÿåœ¨æµ‹è¯•æ—¶é€šè¿‡çº¦æŸå¼•å¯¼ç”Ÿæˆï¼ŒåŒæ—¶è¿½è¸ªé•¿åº¦å’Œç­”æ¡ˆåˆ†å¸ƒï¼Œå¸®åŠ©æ¨¡å‹è¯†åˆ«å¹¶ä¿®å‰ªå‡ºâ€œæœ€çŸ­çš„æ­£ç¡®æ¨ç†è·¯å¾„â€ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ä¸ä»…æé«˜äº†æ¨ç†æ•ˆç‡ï¼Œè¿˜æå‡äº†å¯è¯»æ€§ï¼Œä¸”ä¸ç‰ºç‰²å‡†ç¡®ç‡ã€‚\n\n#### 3. ç¡¬ä»¶ç”Ÿæˆçš„â€œå½¢å¼åŒ–éªŒè¯â€çªç ´\n**Proof2Silicon: Prompt Repair for Verified Code and Hardware Generation via Reinforcement Learning**\n*(Proof2Siliconï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œæç¤ºä¿®å¤ï¼Œä»¥ç”Ÿæˆç»è¿‡éªŒè¯çš„ä»£ç å’Œç¡¬ä»¶)*\n\n> **Authors:** Manvi Jha, et al.\n> **å…³é”®è¯:** Hardware Generation, Formal Verification, Dafny, Reinforcement Learning, Vivado HLS\n\n**ä¸»è¦è´¡çŒ®ï¼š** é’ˆå¯¹ LLM ç”Ÿæˆç¡¬ä»¶ä»£ç ï¼ˆå¦‚ Verilog/Cï¼‰éš¾ä»¥é€šè¿‡å½¢å¼åŒ–éªŒè¯çš„ç—›ç‚¹ï¼Œä½œè€…æå‡ºäº† **Proof2Silicon**ã€‚è¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œå®ƒä¸ç›´æ¥å¾®è°ƒ LLMï¼Œè€Œæ˜¯ä½¿ç”¨**å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰**æ¥è¿­ä»£ä¿®å¤ Promptï¼Œå¼•å¯¼å†»ç»“çš„ LLM ç”Ÿæˆå¯ä»¥é€šè¿‡éªŒè¯çš„ Dafny ä»£ç ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** ç”Ÿæˆçš„ Dafny ä»£ç ä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸ºå¯ç»¼åˆçš„ C ä»£ç ï¼Œæœ€ç»ˆé€šè¿‡ Vivado HLS ç”Ÿæˆ RTLã€‚åœ¨ 100 ä¸ªä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œç«¯åˆ°ç«¯ç¡¬ä»¶ç»¼åˆæˆåŠŸç‡é«˜è¾¾ 72%ï¼Œè§£å†³äº†è‡ªç„¶è¯­è¨€åˆ°ç¡…å®ç°ä¸­çš„â€œæ­£ç¡®æ€§â€éš¾é¢˜ã€‚\n\n#### 4. 1 Bit å°±å¤Ÿäº†ï¼Ÿæè‡´å‹ç¼©çš„ç¥ç»ç½‘ç»œ\n**1 bit is all we need: binary normalized neural networks**\n*(æˆ‘ä»¬åªéœ€è¦ 1 bitï¼šäºŒå€¼å½’ä¸€åŒ–ç¥ç»ç½‘ç»œ)*\n\n> **Authors:** Eduardo Lobo Lustoda Cabral, et al.\n> **å…³é”®è¯:** Binary Normalized Layer, 1-bit parameters, Memory Efficiency\n\n**ä¸»è¦è´¡çŒ®ï¼š** ä¸ºäº†åº”å¯¹å¤§æ¨¡å‹éƒ¨ç½²çš„å†…å­˜æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„ **äºŒå€¼å½’ä¸€åŒ–å±‚ï¼ˆBinary Normalized Layerï¼‰**ã€‚åœ¨è¿™ä¸ªæ¶æ„ä¸­ï¼Œæ‰€æœ‰å‚æ•°ï¼ˆåŒ…æ‹¬æƒé‡å’Œåç½®ï¼‰åªæœ‰ 0 æˆ– 1 ä¸¤ä¸ªå€¼ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** è¿™ç§æ–¹æ³•å¯ä»¥ç”¨åœ¨å·ç§¯ã€å…¨è¿æ¥ç”šè‡³ Transformer çš„æ³¨æ„åŠ›å±‚ä¸­ã€‚å®éªŒæ˜¾ç¤ºï¼Œä½¿ç”¨äºŒå€¼å½’ä¸€åŒ–å±‚çš„æ¨¡å‹åœ¨å›¾åƒåˆ†ç±»å’Œè¯­è¨€é¢„æµ‹ä»»åŠ¡ä¸Šï¼Œæ€§èƒ½å‡ ä¹ä¸ 32-bit æ¨¡å‹æŒå¹³ï¼Œä½†å†…å­˜éœ€æ±‚å‡å°‘äº† 32 å€ï¼Œä¸”æ— éœ€ä¸“ç”¨ç¡¬ä»¶ï¼Œæ™®é€š CPU å³å¯é«˜æ•ˆè¿è¡Œã€‚\n\n---\n\n### ğŸ›¡ï¸ã€LLM å®‰å…¨ã€å¯¹é½ä¸çº¢é˜Ÿæµ‹è¯•ã€‘\n\n#### 5. é‡‘è LLM çš„éšè”½é£é™©\n**Uncovering the Vulnerability of Large Language Models in the Financial Domain via Risk Concealment**\n*(é€šè¿‡é£é™©éšè—æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹åœ¨é‡‘èé¢†åŸŸçš„è„†å¼±æ€§)*\n\n> **Authors:** Gang Cheng, et al.\n> **å…³é”®è¯:** Financial LLMs, Red-teaming, Risk-Concealment Attacks (RCA), FIN-Bench\n\n**ä¸»è¦è´¡çŒ®ï¼š** ç°æœ‰çš„çº¢é˜Ÿæµ‹è¯•ä¸»è¦å…³æ³¨æœ‰å®³å†…å®¹ï¼Œå¾€å¾€å¿½ç•¥äº†**åˆè§„é£é™©**ã€‚ä½œè€…æå‡ºäº† **RCA (Risk-Concealment Attacks)**ï¼Œè¿™æ˜¯ä¸€ç§å¤šè½®å¯¹è¯æ”»å‡»æ¡†æ¶ï¼Œé€šè¿‡â€œéšè—â€ç›‘ç®¡é£é™©æ¥è¯±å¯¼æ¨¡å‹ç»™å‡ºçœ‹ä¼¼åˆè§„ä½†å®é™…è¿è§„çš„å»ºè®®ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** åœ¨è‡ªå»ºçš„ FIN-Bench åŸºå‡†ä¸Šï¼ŒRCA æˆåŠŸæ”»ç ´äº† 9 ä¸ªä¸»æµ LLMï¼Œå¹³å‡æˆåŠŸç‡ 93.18%ï¼ˆGPT-4.1 ç”šè‡³é«˜è¾¾ 98.28%ï¼‰ï¼Œæ­ç¤ºäº†é‡‘è AI åœ¨ç›‘ç®¡åˆè§„æ–¹é¢çš„å·¨å¤§æ¼æ´ã€‚\n\n#### 6. å‰–æâ€œæ‹’ç»â€æœºåˆ¶ï¼šä¸ºä»€ä¹ˆæ¨¡å‹è¯´â€œå¯¹ä¸èµ·â€ï¼Ÿ\n**Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal**\n*(è¶…è¶Šâ€œå¯¹ä¸èµ·ï¼Œæˆ‘ä¸èƒ½â€ï¼šå‰–æå¤§è¯­è¨€æ¨¡å‹çš„æ‹’ç»æœºåˆ¶)*\n\n> **Authors:** Nirmalendu Prakash, et al.\n> **å…³é”®è¯:** Refusal Mechanism, Sparse Autoencoders (SAEs), Jailbreak, Interpretability\n\n**ä¸»è¦è´¡çŒ®ï¼š** ä½œè€…åˆ©ç”¨ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨ï¼ˆSAEï¼‰æ·±å…¥ç ”ç©¶äº† Gemma-2 å’Œ LLaMA-3.1 çš„**æ‹’ç»ï¼ˆRefusalï¼‰**è¡Œä¸ºã€‚ä»–ä»¬ä¸æ˜¯ç®€å•åœ°æµ‹è¯•è¶Šç‹±ï¼Œè€Œæ˜¯è¯•å›¾æ‰¾åˆ°å¯¼è‡´æ¨¡å‹æ‹’ç»çš„â€œç‰¹å¾æ–¹å‘â€ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** é€šè¿‡æ¶ˆèç‰¹å®šçš„ SAE ç‰¹å¾ï¼Œå¯ä»¥å¼ºåˆ¶æ¨¡å‹ä»â€œæ‹’ç»â€è½¬å˜ä¸ºâ€œé¡ºä»â€ï¼Œä»è€Œå®ç°è¶Šç‹±ã€‚ç ”ç©¶è¿˜å‘ç°æ¨¡å‹å†…éƒ¨å­˜åœ¨å†—ä½™çš„æ‹’ç»æœºåˆ¶ï¼Œå…³é—­ä¸€å±‚ï¼Œå¦ä¸€å±‚å¯èƒ½ä¼šæ¿€æ´»ã€‚\n\n#### 7. é’ˆå¯¹ RAG çš„æ–°æ”»å‡»\n**DCMI: A Differential Calibration Membership Inference Attack Against Retrieval-Augmented Generation**\n*(DCMIï¼šé’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆçš„å·®åˆ†æ ¡å‡†æˆå‘˜æ¨ç†æ”»å‡»)*\n\n> **Authors:** Xinyu Gao, et al.\n> **å…³é”®è¯:** RAG, Membership Inference Attacks (MIA), Privacy\n\n**ä¸»è¦è´¡çŒ®ï¼š** RAG ç³»ç»Ÿè™½ç„¶å‡å°‘äº†å¹»è§‰ï¼Œä½†ä¹Ÿå¼•å…¥äº†éšç§é£é™©ã€‚ä½œè€…æå‡ºäº† **DCMI**ï¼Œä¸€ç§é’ˆå¯¹ RAG å¤–éƒ¨çŸ¥è¯†åº“çš„æˆå‘˜æ¨ç†æ”»å‡»ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** è¯¥æ–¹æ³•åˆ©ç”¨æˆå‘˜æ–‡æ¡£å’Œéæˆå‘˜æ–‡æ¡£åœ¨æŸ¥è¯¢æ‰°åŠ¨ä¸‹çš„**æ•æ„Ÿåº¦å·®å¼‚**æ¥è¿›è¡ŒåŒºåˆ†ã€‚åœ¨çœŸå® RAG å¹³å°ï¼ˆå¦‚ Difyï¼‰ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒDCMI æ¯”ç°æœ‰åŸºçº¿æ”»å‡»æ–¹æ³•çš„ AUC é«˜å‡º 10%-20%ï¼Œè¯æ˜äº† RAG ç³»ç»Ÿçš„éšç§æ³„éœ²é£é™©ã€‚\n\n---\n\n### ğŸ’¡ã€å‚ç›´é¢†åŸŸåº”ç”¨ä¸ Agentã€‘\n\n#### 8. ææ–™ç§‘å­¦çš„â€œè¯­è¨€åŸç”Ÿâ€é©å‘½\n**Language-Native Materials Processing Design by Lightly Structured Text Database and Reasoning Large Language Model**\n*(åŸºäºè½»é‡çº§ç»“æ„åŒ–æ–‡æœ¬æ•°æ®åº“å’Œæ¨ç†å¤§æ¨¡å‹çš„è¯­è¨€åŸç”Ÿææ–™åŠ å·¥è®¾è®¡)*\n\n> **Authors:** Yuze Liu, et al.\n> **å…³é”®è¯:** Materials Synthesis, RAG, Reasoning, BNNS\n\n**ä¸»è¦è´¡çŒ®ï¼š** ææ–™åˆæˆæ­¥éª¤é€šå¸¸éšè—åœ¨éç»“æ„åŒ–çš„å®éªŒè®°å½•ä¸­ã€‚ä½œè€…æå‡ºäº†ä¸€ç§â€œè¯­è¨€åŸç”Ÿâ€çš„æ¡†æ¶ï¼Œå°†åˆæˆè§„åˆ’é‡æ„ä¸ºæ–‡æœ¬æ¨ç†ä»»åŠ¡ã€‚ç³»ç»Ÿç»“åˆäº† RAG å’Œ **EAR (Experience-Augmented Reasoning)**ï¼Œä¸ä»…ç»™å‡ºå‚æ•°ï¼Œè¿˜æä¾›åŸºäºæ–‡çŒ®çš„â€œä¸“å®¶å¼æ¨ç†â€å’Œå‡è®¾ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** è¯¥ç³»ç»ŸæˆåŠŸè§„åˆ’äº†æ°®åŒ–ç¡¼çº³ç±³ç‰‡ï¼ˆBNNSï¼‰çš„åˆæˆè·¯å¾„ï¼Œæ‰¾åˆ°äº†æœ€ä½³çš„ç ”ç£¨å’Œåˆ†ç¦»ç­–ç•¥ï¼Œå¹¶å¾—åˆ°äº†å®éªŒéªŒè¯ã€‚\n\n#### 9. ç²¾ç¥ç—…å­¦ LLM åŸºå‡†æµ‹è¯•\n**PsychiatryBench: A Multi-Task Benchmark for LLMs in Psychiatry**\n*(PsychiatryBenchï¼šç²¾ç¥ç—…å­¦å¤§æ¨¡å‹çš„å¤šä»»åŠ¡åŸºå‡†)*\n\n> **Authors:** Aya E. Fouda, et al.\n> **å…³é”®è¯:** Psychiatry, Diagnostic Reasoning, Benchmark\n\n**ä¸»è¦è´¡çŒ®ï¼š** ç°æœ‰çš„åŒ»ç–— AI è¯„æµ‹å¾€å¾€ç¼ºä¹ä¸´åºŠæ·±åº¦ã€‚ä½œè€…åŸºäºæƒå¨æ•™ç§‘ä¹¦å’Œç—…ä¾‹é›†æ„å»ºäº† **PsychiatryBench**ï¼ŒåŒ…å« 5188 ä¸ªä¸“å®¶æ ‡æ³¨é¡¹ç›®ï¼Œæ¶µç›–è¯Šæ–­æ¨ç†ã€æ²»ç–—è§„åˆ’ã€çºµå‘éšè®¿ç­‰ 11 ç±»ä»»åŠ¡ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** å³ä½¿æ˜¯é¡¶å°–æ¨¡å‹ï¼ˆå¦‚ GPT-5, MedGemmaï¼‰ï¼Œåœ¨å¤šè½®éšè®¿å’Œç®¡ç†ä»»åŠ¡ä¸­çš„**ä¸´åºŠä¸€è‡´æ€§å’Œå®‰å…¨æ€§**ä»å­˜åœ¨æ˜¾è‘—å·®è·ã€‚\n\n#### 10. æ¸¸æˆå¼€å‘çš„è‡ªåŠ¨åŒ–æµæ°´çº¿\n**Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs**\n*(åŸºäº NLP å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹çš„æ¸¸æˆè®¾è®¡æ–‡æ¡£åˆ° Unity æ¸¸æˆæ¨¡æ¿è‡ªåŠ¨åŒ–ç”Ÿæˆ)*\n\n> **Authors:** Amna Hassan\n> **å…³é”®è¯:** Game Development, Unity, GDD, Code Generation\n\n**ä¸»è¦è´¡çŒ®ï¼š** èƒ½å¤Ÿç›´æ¥è§£æ**æ¸¸æˆè®¾è®¡æ–‡æ¡£ (GDD)**ï¼Œæå–ç»“æ„åŒ–è§„èŒƒï¼Œå¹¶ç”Ÿæˆå…¼å®¹ Unity çš„ C# ä»£ç ã€‚ä½œè€…å¾®è°ƒäº† LLaMA-3 æ¨¡å‹ä¸“é—¨ç”¨äº Unity ä»£ç ç”Ÿæˆï¼Œèƒ½å¤Ÿå®ç°ä»æ–‡æ¡£åˆ°å¯è¿è¡ŒåŸå‹çš„ç«¯åˆ°ç«¯è½¬æ¢ã€‚\n\n#### 11. åœ°ç†ç©ºé—´æ¨ç† Agent\n**MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration**\n*(MapAgentï¼šç”¨äºåœ°ç†ç©ºé—´æ¨ç†çš„åˆ†å±‚æ™ºèƒ½ä½“ä¸åŠ¨æ€åœ°å›¾å·¥å…·é›†æˆ)*\n\n> **Authors:** Md Hasebul Hasan, et al.\n> **å…³é”®è¯:** Geospatial Reasoning, Hierarchical Agent, Map APIs\n\n**ä¸»è¦è´¡çŒ®ï¼š** é’ˆå¯¹åœ°å›¾ç±»ä»»åŠ¡ï¼ˆå¦‚â€œæ‰¾ä¸€ä¸ªç¦»å…¬å›­è¿‘ä¸”å®‰é™çš„å’–å•¡é¦†â€ï¼‰ï¼Œç°æœ‰çš„é€šç”¨ Agent è¡¨ç°ä¸ä½³ã€‚**MapAgent** é‡‡ç”¨åˆ†å±‚è®¾è®¡ï¼Œå°†è§„åˆ’ä¸æ‰§è¡Œè§£è€¦ï¼Œå¹¶è®¾è®¡äº†ä¸“é—¨çš„åœ°å›¾å·¥å…· Agent æ¥å¹¶è¡Œç¼–æ’ API è°ƒç”¨ï¼Œæ˜¾è‘—æå‡äº†åœ°ç†ç©ºé—´ä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚\n\n---\n\n### ğŸ‘ï¸ã€è§†è§‰ã€å¤šæ¨¡æ€ä¸é«˜æ•ˆè®¡ç®—ã€‘\n\n#### 12. 3DGS çš„æè‡´æ˜¾å­˜ä¼˜åŒ–\n**MEGS^2: Memory-Efficient Gaussian Splatting via Spherical Gaussians and Unified Pruning**\n*(MEGS^2ï¼šåŸºäºçƒå½¢é«˜æ–¯å’Œç»Ÿä¸€å‰ªæçš„å†…å­˜é«˜æ•ˆé«˜æ–¯æ³¼æº…)*\n\n> **Authors:** Jiarui Chen, et al.\n> **å…³é”®è¯:** 3D Gaussian Splatting, Rendering Memory, Pruning\n\n**ä¸»è¦è´¡çŒ®ï¼š** 3DGS è™½ç„¶æ¸²æŸ“å¿«ä½†æ˜¾å­˜å ç”¨æå¤§ã€‚ä½œè€…ç”¨è½»é‡çº§çš„**çƒå½¢é«˜æ–¯ (Spherical Gaussians)** æ›¿ä»£äº†çƒè°å‡½æ•°ï¼Œå¹¶æå‡ºäº†ä¸€å¥—ç»Ÿä¸€çš„å‰ªææ¡†æ¶ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** è¯¥æ–¹æ³•å®ç°äº† 50% çš„é™æ€æ˜¾å­˜å‡å°‘å’Œ **40% çš„æ¸²æŸ“æ˜¾å­˜å‡å°‘**ï¼Œè¿™å¯¹äºåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œé«˜è´¨é‡ 3D åœºæ™¯è‡³å…³é‡è¦ã€‚\n\n#### 13. ç»Ÿä¸€è§†é¢‘åœºæ™¯å›¾ç”Ÿæˆ\n**UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning**\n*(UNOï¼šé€šè¿‡ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„è§†è§‰è¡¨ç¤ºå­¦ä¹ ç»Ÿä¸€å•é˜¶æ®µè§†é¢‘åœºæ™¯å›¾ç”Ÿæˆ)*\n\n> **Authors:** Huy Le, et al.\n> **å…³é”®è¯:** Video Scene Graph Generation (VidSGG), Slot Attention, Object-Centric\n\n**ä¸»è¦è´¡çŒ®ï¼š** æå‡ºäº† **UNO**ï¼Œä¸€ä¸ªå•é˜¶æ®µçš„ç»Ÿä¸€æ¡†æ¶ï¼Œå¯ä»¥åŒæ—¶å¤„ç†ç²—ç²’åº¦ï¼ˆBox-levelï¼‰å’Œç»†ç²’åº¦ï¼ˆPixel-levelï¼‰çš„è§†é¢‘åœºæ™¯å›¾ç”Ÿæˆä»»åŠ¡ã€‚åˆ©ç”¨æ‰©å±•çš„ Slot Attention æœºåˆ¶å°†è§†è§‰ç‰¹å¾åˆ†è§£ä¸ºå¯¹è±¡æ§½å’Œå…³ç³»æ§½ï¼Œæ— éœ€æ˜¾å¼çš„è·Ÿè¸ªæ¨¡å—å³å¯ä¿æŒæ—¶é—´ä¸€è‡´æ€§ã€‚\n\n#### 14. æ‰©æ•£æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒåŠ é€Ÿ\n**BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models**\n*(BranchGRPOï¼šæ‰©æ•£æ¨¡å‹ä¸­ç¨³å®šé«˜æ•ˆçš„ç»“æ„åŒ–åˆ†æ”¯ GRPO)*\n\n> **Authors:** Yuming Li, et al.\n> **å…³é”®è¯:** Diffusion Models, Alignment, RLHF, GRPO\n\n**ä¸»è¦è´¡çŒ®ï¼š** é’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„å¯¹é½è®­ç»ƒï¼ˆAlignmentï¼‰ï¼Œä½œè€…æ”¹è¿›äº† GRPO ç®—æ³•ï¼Œæå‡ºäº† **BranchGRPO**ã€‚é€šè¿‡æ ‘çŠ¶åˆ†æ”¯ç»“æ„å…±äº«å‰ç¼€è®¡ç®—ï¼Œå¹¶å¼•å…¥å‰ªæç­–ç•¥ã€‚\n**æ ¸å¿ƒå‘ç°ï¼š** ç›¸æ¯” DanceGRPOï¼Œè®­ç»ƒæ—¶é—´å‡å°‘äº† **55%**ï¼ŒåŒæ—¶åœ¨ HPDv2.1 å¯¹é½åˆ†æ•°ä¸Šæå‡äº† 16%ã€‚\n\n---\n\n### ğŸµã€å…¶ä»–æœ‰è¶£çš„ç ”ç©¶ã€‘\n\n*   **[Climate] Distillation of CNN Ensemble Results for Enhanced Long-Term Prediction of the ENSO Phenomenon:** é’ˆå¯¹å„å°”å°¼è¯ºç°è±¡ï¼ˆENSOï¼‰çš„é•¿æœŸé¢„æµ‹ï¼Œå‘ç°æŒ‘é€‰ Ensemble ä¸­çš„â€œç²¾è‹±æˆå‘˜â€æ¯”ç®€å•çš„å¹³å‡æ•ˆæœå¥½å¾—å¤šï¼Œç‰¹åˆ«æ˜¯åœ¨ 23 ä¸ªæœˆçš„è¶…é•¿é¢„æµ‹æœŸä¸Šã€‚\n*   **[BCI] A Real-Time BCI for Stroke Hand Rehabilitation:** è¿™æ˜¯ä¸€ä¸ªä½æˆæœ¬çš„ä¸­é£åº·å¤ç³»ç»Ÿï¼Œåˆ©ç”¨ 3D æ‰“å°å¤–éª¨éª¼å’Œè„‘æœºæ¥å£ï¼Œé€šè¿‡ç®€å•çš„å·ç§¯è‡ªç¼–ç å™¨å¤„ç† EEG ä¿¡å·ï¼Œå¹¶åœ¨ Jetson Nano ä¸Šå®æ—¶è¿è¡Œã€‚\n*   **[Gender Bias] Evaluating and comparing gender bias across four text-to-image models:** å¯¹æ¯”äº† SDXL, DALL-E ç­‰æ¨¡å‹ã€‚æœ‰è¶£çš„æ˜¯ï¼Œä½œè€…å‘ç° DALL-E æœ‰æ—¶è¡¨ç°å‡º**å¯¹å¥³æ€§çš„åå‘ï¼ˆBias favored femalesï¼‰**ï¼Œè¿™å¯èƒ½æ˜¯ OpenAI åå°æ‚„æ‚„ä¿®æ”¹ Prompt çš„ç»“æœã€‚\n\n---\nä»¥ä¸Šå°±æ˜¯ä»Šå¤©çš„ arXiv å¿«æŠ¥ã€‚æ— è®ºæ˜¯ **Agentic SE** çš„å®å¤§æ„¿æ™¯ï¼Œè¿˜æ˜¯ **Proof2Silicon** å’Œ **1-bit NN** çš„ç¡¬æ ¸æŠ€æœ¯ï¼Œéƒ½è®©äººæ„Ÿåˆ° AI é¢†åŸŸåœ¨è¿™ä¸ªå‘¨æ—¥çš„æ—ºç››ç”Ÿå‘½åŠ›ã€‚\n\nç¥å¤§å®¶é˜…è¯»æ„‰å¿«ï¼Œæ–°çš„ä¸€å‘¨ç§‘ç ”é¡ºåˆ©ï¼",
  "papers": [
    {
      "arxiv_id": "2509.06239v2",
      "title": "Proof2Silicon: Prompt Repair for Verified Code and Hardware Generation via Reinforcement Learning",
      "title_zh": "Proof2Siliconï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„æç¤ºè¯ä¿®å¤ï¼Œç”¨äºç»éªŒè¯çš„ä»£ç ä¸ç¡¬ä»¶ç”Ÿæˆ",
      "authors": [
        "Manvi Jha",
        "Jiaxin Wan",
        "Deming Chen"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in automated code generation but frequently produce code that fails formal verification, an essential requirement for hardware and safety-critical domains. To overcome this fundamental limitation, we previously proposed PREFACE, a model-agnostic framework based on reinforcement learning (RL) that iteratively repairs the prompts provided to frozen LLMs, systematically steering them toward generating formally verifiable Dafny code without costly fine-tuning. This work presents Proof2Silicon, a novel end-to-end synthesis framework that embeds the previously proposed PREFACE flow to enable the generation of correctness-by-construction hardware directly from natural language specifications. Proof2Silicon operates by: (1) leveraging PREFACE's verifier-driven RL agent to optimize prompt generation iteratively, ensuring Dafny code correctness; (2) automatically translating verified Dafny programs into synthesizable high-level C using Dafny's Python backend and PyLog; and (3) employing Vivado HLS to produce RTL implementations. Evaluated rigorously on a challenging 100-task benchmark, PREFACE's RL-guided prompt optimization consistently improved Dafny verification success rates across diverse LLMs by up to 21%. Crucially, Proof2Silicon achieved an end-to-end hardware synthesis success rate of up to 72%, generating RTL designs through Vivado HLS synthesis flows. These results demonstrate a robust, scalable, and automated pipeline for LLM-driven, formally verified hardware synthesis, bridging natural-language specification and silicon realization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç¡¬ä»¶ç”Ÿæˆå’Œå®‰å…¨æ€§å…³é”®é¢†åŸŸä¸­éš¾ä»¥é€šè¿‡å½¢å¼åŒ–éªŒè¯(formal verification)çš„å±€é™æ€§ï¼Œæå‡ºäº†Proof2Siliconç«¯åˆ°ç«¯åˆæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶é›†æˆäº†PREFACEæµç¨‹ï¼Œåˆ©ç”¨åŸºäºå¼ºåŒ–å­¦ä¹ (RL)çš„éªŒè¯é©±åŠ¨æ™ºèƒ½ä½“å¯¹Promptè¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œä»è€Œåœ¨ä¸è¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹å¼•å¯¼LLMsç”Ÿæˆæ­£ç¡®çš„Dafnyä»£ç ã€‚Proof2Siliconéšåé€šè¿‡Dafnyçš„Pythonåç«¯ä¸PyLogå°†å·²éªŒè¯çš„ç¨‹åºè½¬æ¢ä¸ºå¯ç»¼åˆçš„é«˜çº§Cè¯­è¨€ï¼Œå¹¶æœ€ç»ˆåˆ©ç”¨Vivado HLSç”ŸæˆRTLå®ç°ã€‚åœ¨åŒ…å«100é¡¹æŒ‘æˆ˜æ€§ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒPREFACEä½¿ä¸åŒæ¨¡å‹çš„DafnyéªŒè¯æˆåŠŸç‡æœ€é«˜æå‡äº†21%ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒProof2Siliconå®ç°äº†é«˜è¾¾72%çš„ç«¯åˆ°ç«¯ç¡¬ä»¶åˆæˆæˆåŠŸç‡ï¼Œä¸ºä»è‡ªç„¶è¯­è¨€è§„èŒƒåˆ°ç»è¿‡å½¢å¼åŒ–éªŒè¯çš„ç¡…ç‰‡å®ç°æä¾›äº†ä¸€æ¡è‡ªåŠ¨åŒ–ä¸”ç¨³å¥çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06239v2",
      "published_date": "2025-09-07 23:04:15 UTC",
      "updated_date": "2025-10-20 22:10:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:02:07.105364+00:00"
    },
    {
      "arxiv_id": "2509.06235v1",
      "title": "PillagerBench: Benchmarking LLM-Based Agents in Competitive Minecraft Team Environments",
      "title_zh": "PillagerBenchï¼šç«äº‰æ€§ Minecraft å›¢é˜Ÿç¯å¢ƒä¸‹åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•",
      "authors": [
        "Olivier Schipper",
        "Yudi Zhang",
        "Yali Du",
        "Mykola Pechenizkiy",
        "Meng Fang"
      ],
      "abstract": "LLM-based agents have shown promise in various cooperative and strategic reasoning tasks, but their effectiveness in competitive multi-agent environments remains underexplored. To address this gap, we introduce PillagerBench, a novel framework for evaluating multi-agent systems in real-time competitive team-vs-team scenarios in Minecraft. It provides an extensible API, multi-round testing, and rule-based built-in opponents for fair, reproducible comparisons. We also propose TactiCrafter, an LLM-based multi-agent system that facilitates teamwork through human-readable tactics, learns causal dependencies, and adapts to opponent strategies. Our evaluation demonstrates that TactiCrafter outperforms baseline approaches and showcases adaptive learning through self-play. Additionally, we analyze its learning process and strategic evolution over multiple game episodes. To encourage further research, we have open-sourced PillagerBench, fostering advancements in multi-agent AI for competitive environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PillagerBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨Minecraftç¯å¢ƒä¸­è¯„ä¼°åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä½“åœ¨å®æ—¶ç«äº‰æ€§å›¢é˜Ÿå¯¹æŠ—åœºæ™¯ä¸‹è¡¨ç°çš„æ–°å‹åŸºå‡†æµ‹è¯•æ¡†æ¶ã€‚è¯¥æ¡†æ¶æä¾›å¯æ‰©å±•çš„APIã€å¤šè½®æµ‹è¯•ä»¥åŠåŸºäºè§„åˆ™çš„å†…ç½®å¯¹æ‰‹ï¼Œæ—¨åœ¨å®ç°å…¬å¹³ä¸”å¯é‡å¤çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ€§èƒ½æ¯”è¾ƒã€‚ç ”ç©¶äººå‘˜åŒæ­¥æå‡ºäº†TactiCrafterï¼Œè¿™æ˜¯ä¸€ç§åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œé€šè¿‡äººç±»å¯è¯»çš„æˆ˜æœ¯ï¼ˆtacticsï¼‰ä¿ƒè¿›å›¢é˜Ÿåä½œï¼Œå¹¶èƒ½å­¦ä¹ å› æœä¾èµ–å…³ç³»ï¼ˆcausal dependenciesï¼‰ä»¥é€‚åº”å¯¹æ‰‹ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTactiCrafteråœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†é€šè¿‡è‡ªåšå¼ˆï¼ˆself-playï¼‰å®ç°çš„é€‚åº”æ€§å­¦ä¹ ä¸ç­–ç•¥æ¼”åŒ–è¿‡ç¨‹ã€‚è¯¥é¡¹ç›®çš„å¼€æºä¸ºç«äº‰æ€§ç¯å¢ƒä¸‹å¤šæ™ºèƒ½ä½“AIçš„ç ”ç©¶æä¾›äº†é‡è¦å·¥å…·ï¼Œæœ‰æ•ˆæ¨åŠ¨äº†å¤æ‚åŠ¨æ€åœºæ™¯ä¸‹æ™ºèƒ½ä½“åä½œä¸å¯¹æŠ—æŠ€æœ¯çš„å‘å±•ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "for the source code, see https://github.com/aialt/PillagerBench",
      "pdf_url": "https://arxiv.org/pdf/2509.06235v1",
      "published_date": "2025-09-07 22:51:12 UTC",
      "updated_date": "2025-09-07 22:51:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:01:50.265080+00:00"
    },
    {
      "arxiv_id": "2509.10546v1",
      "title": "Uncovering the Vulnerability of Large Language Models in the Financial Domain via Risk Concealment",
      "title_zh": "é€šè¿‡é£é™©éšè—æ­ç¤ºé‡‘èé¢†åŸŸå¤§è¯­è¨€æ¨¡å‹çš„è„†å¼±æ€§",
      "authors": [
        "Gang Cheng",
        "Haibo Jin",
        "Wenbin Zhang",
        "Haohan Wang",
        "Jun Zhuang"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into financial applications, yet existing red-teaming research primarily targets harmful content, largely neglecting regulatory risks. In this work, we aim to investigate the vulnerability of financial LLMs through red-teaming approaches. We introduce Risk-Concealment Attacks (RCA), a novel multi-turn framework that iteratively conceals regulatory risks to provoke seemingly compliant yet regulatory-violating responses from LLMs. To enable systematic evaluation, we construct FIN-Bench, a domain-specific benchmark for assessing LLM safety in financial contexts. Extensive experiments on FIN-Bench demonstrate that RCA effectively bypasses nine mainstream LLMs, achieving an average attack success rate (ASR) of 93.18%, including 98.28% on GPT-4.1 and 97.56% on OpenAI o1. These findings reveal a critical gap in current alignment techniques and underscore the urgent need for stronger moderation mechanisms in financial domains. We hope this work offers practical insights for advancing robust and domain-aware LLM alignment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨é‡‘èé¢†åŸŸé¢ä¸´çš„ç›‘ç®¡é£é™©æ¼æ´ï¼ŒæŒ‡å‡ºå½“å‰çš„çº¢é˜Ÿæµ‹è¯•(red-teaming)ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æœ‰å®³å†…å®¹è€Œå¿½è§†äº†åˆè§„æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åä¸ºé£é™©éšè—æ”»å‡»(Risk-Concealment Attacks, RCA)çš„æ–°å‹å¤šè½®æ¡†æ¶ï¼Œé€šè¿‡è¿­ä»£éšè—é£é™©å› ç´ ï¼Œè¯±ä½¿æ¨¡å‹äº§ç”Ÿçœ‹ä¼¼åˆè§„å®åˆ™è¿è§„çš„å›ç­”ã€‚ä¸ºäº†è¯„ä¼°è¿™ä¸€å¨èƒï¼Œç ”ç©¶æ„å»ºäº†ä¸“é—¨ç”¨äºé‡‘èå®‰å…¨è¯„ä¼°çš„åŸºå‡†æµ‹è¯•é›†FIN-Benchã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRCAå¯¹ä¹ç§ä¸»æµLLMsçš„å¹³å‡æ”»å‡»æˆåŠŸç‡(ASR)é«˜è¾¾93.18%ï¼Œåœ¨GPT-4.1å’ŒOpenAI o1ä¸Šçš„æˆåŠŸç‡ç”šè‡³åˆ†åˆ«è¾¾åˆ°äº†98.28%å’Œ97.56%ã€‚è¿™äº›å‘ç°æš´éœ²äº†ç°æœ‰å¯¹é½æŠ€æœ¯(alignment techniques)åœ¨é‡‘èä¸“ä¸šé¢†åŸŸçš„ä¸¥é‡ç¼ºé™·ï¼Œå¹¶å¼ºè°ƒäº†åœ¨é‡‘èé¢†åŸŸå»ºç«‹æ›´å¼ºæœ‰åŠ›çš„å®¡æ ¸æœºåˆ¶ä¸é¢†åŸŸæ„ŸçŸ¥å¯¹é½çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint, under review. TL;DR: We propose a multi-turn red-teaming framework, RCA, that reveals critical regulatory vulnerabilities in financial LLMs, achieving over 93% attack success on a proposed new benchmark, FIN-Bench",
      "pdf_url": "https://arxiv.org/pdf/2509.10546v1",
      "published_date": "2025-09-07 22:35:15 UTC",
      "updated_date": "2025-09-07 22:35:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:02:30.586395+00:00"
    },
    {
      "arxiv_id": "2509.06227v1",
      "title": "Distillation of CNN Ensemble Results for Enhanced Long-Term Prediction of the ENSO Phenomenon",
      "title_zh": "è’¸é¦ CNN é›†æˆç»“æœä»¥å¢å¼º ENSO ç°è±¡çš„é•¿æ—¶é¢„æµ‹",
      "authors": [
        "Saghar Ganji",
        "Mohammad Naisipour",
        "Alireza Hassani",
        "Arash Adib"
      ],
      "abstract": "The accurate long-term forecasting of the El Nino Southern Oscillation (ENSO) is still one of the biggest challenges in climate science. While it is true that short-to medium-range performance has been improved significantly using the advances in deep learning, statistical dynamical hybrids, most operational systems still use the simple mean of all ensemble members, implicitly assuming equal skill across members. In this study, we demonstrate, through a strictly a-posteriori evaluation , for any large enough ensemble of ENSO forecasts, there is a subset of members whose skill is substantially higher than that of the ensemble mean. Using a state-of-the-art ENSO forecast system cross-validated against the 1986-2017 observed Nino3.4 index, we identify two Top-5 subsets one ranked on lowest Root Mean Square Error (RMSE) and another on highest Pearson correlation. Generally across all leads, these outstanding members show higher correlation and lower RMSE, with the advantage rising enormously with lead time. Whereas at short leads (1 month) raises the mean correlation by about +0.02 (+1.7%) and lowers the RMSE by around 0.14 Â°C or by 23.3% compared to the All-40 mean, at extreme leads (23 months) the correlation is raised by +0.43 (+172%) and RMSE by 0.18 Â°C or by 22.5% decrease. The enhancements are largest during crucial ENSO transition periods such as SON and DJF, when accurate amplitude and phase forecasting is of greatest socio-economic benefit, and furthermore season-dependent e.g., mid-year months such as JJA and MJJ have incredibly large RMSE reductions. This study provides a solid foundation for further investigations to identify reliable clues for detecting high-quality ensemble members, thereby enhancing forecasting skill.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šè¿‡è’¸é¦ CNN Ensemble ç»“æœæ¥å¢å¼º ENSO ç°è±¡é•¿å‘¨æœŸé¢„æµ‹çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç›®å‰ä¸šåŠ¡ç³»ç»Ÿæ™®éé‡‡ç”¨ç®€å•é›†åˆå‡å€¼è€Œå¿½ç•¥æˆå‘˜é¢„æµ‹èƒ½åŠ›å·®å¼‚çš„é—®é¢˜ã€‚ç ”ç©¶è€…åˆ©ç”¨ 1986-2017 å¹´è§‚æµ‹åˆ°çš„ Nino3.4 index è¿›è¡Œäº¤å‰éªŒè¯ï¼Œè¯†åˆ«å‡ºåœ¨ Root Mean Square Error (RMSE) æœ€ä½å’Œ Pearson correlation æœ€é«˜æ–¹é¢çš„ Top-5 æˆå‘˜å­é›†ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™äº›ä¼˜é€‰æˆå‘˜åœ¨æ‰€æœ‰ lead time ä¸‹å‡è¡¨ç°å‡ºæ›´ä¼˜çš„é¢„æµ‹æ€§èƒ½ï¼Œä¸”ä¼˜åŠ¿éšæ—¶é—´å¢åŠ è€Œæ˜¾è‘—æ‰©å¤§ã€‚åœ¨ 23 ä¸ªæœˆçš„æé•¿é¢„æŠ¥æ—¶æ•ˆä¸‹ï¼Œç›¸å…³æ€§ç›¸æ¯”é›†åˆå‡å€¼æå‡äº† 172%ï¼Œè€Œ RMSE é™ä½äº† 22.5%ã€‚è¿™ç§æå‡åœ¨ SON å’Œ DJF ç­‰å…³é”®çš„ ENSO è½¬æ¢æœŸå°¤ä¸ºæ˜¾è‘—ï¼Œä¸ºè¯†åˆ«é«˜è´¨é‡é›†åˆæˆå‘˜å¹¶å¢å¼ºæ°”å€™é¢„æŠ¥èƒ½åŠ›æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.CE",
        "physics.app-ph"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "20 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06227v1",
      "published_date": "2025-09-07 22:26:42 UTC",
      "updated_date": "2025-09-07 22:26:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:02:35.286725+00:00"
    },
    {
      "arxiv_id": "2510.15890v1",
      "title": "A Real-Time BCI for Stroke Hand Rehabilitation Using Latent EEG Features from Healthy Subjects",
      "title_zh": "åŸºäºå¥åº·å—è¯•è€…è„‘ç”µæ½œç‰¹å¾çš„å®æ—¶ä¸­é£æ‰‹éƒ¨åº·å¤è„‘æœºæ¥å£",
      "authors": [
        "F. M. Omar",
        "A. M. Omar",
        "K. H. Eyada",
        "M. Rabie",
        "M. A. Kamel",
        "A. M. Azab"
      ],
      "abstract": "This study presents a real-time, portable brain-computer interface (BCI) system designed to support hand rehabilitation for stroke patients. The system combines a low cost 3D-printed robotic exoskeleton with an embedded controller that converts brain signals into physical hand movements. EEG signals are recorded using a 14-channel Emotiv EPOC+ headset and processed through a supervised convolutional autoencoder (CAE) to extract meaningful latent features from single-trial data. The model is trained on publicly available EEG data from healthy individuals (WAY-EEG-GAL dataset), with electrode mapping adapted to match the Emotiv headset layout. Among several tested classifiers, Ada Boost achieved the highest accuracy (89.3%) and F1-score (0.89) in offline evaluations. The system was also tested in real time on five healthy subjects, achieving classification accuracies between 60% and 86%. The complete pipeline - EEG acquisition, signal processing, classification, and robotic control - is deployed on an NVIDIA Jetson Nano platform with a real-time graphical interface. These results demonstrate the system's potential as a low-cost, standalone solution for home-based neurorehabilitation.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ä¸ªå®æ—¶ä¸”ä¾¿æºçš„è„‘æœºæ¥å£(BCI)ç³»ç»Ÿï¼Œæ—¨åœ¨è¾…åŠ©ä¸­é£æ‚£è€…çš„æ‰‹éƒ¨åŠŸèƒ½åº·å¤ã€‚ç³»ç»Ÿé›†æˆäº†ä½æˆæœ¬çš„3Dæ‰“å°æœºå™¨äººå¤–éª¨éª¼(robotic exoskeleton)ï¼Œé€šè¿‡14é€šé“çš„Emotiv EPOC+è®¾å¤‡é‡‡é›†ä¿¡å·ã€‚ç ”ç©¶é‡‡ç”¨æœ‰ç›‘ç£çš„å·ç§¯è‡ªç¼–ç å™¨(CAE)ä»å¥åº·å—è¯•è€…çš„å…¬å¼€æ•°æ®é›†WAY-EEG-GALä¸­æå–å•æ¬¡è¯•éªŒçš„æ½œç‰¹å¾(latent features)è¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAda Booståˆ†ç±»å™¨åœ¨ç¦»çº¿è¯„ä¼°ä¸­å–å¾—äº†89.3%çš„å‡†ç¡®ç‡ã€‚æ•´ä¸ªæŠ€æœ¯ç®¡çº¿è¢«éƒ¨ç½²åœ¨NVIDIA Jetson Nanoå¹³å°ä¸Šï¼Œå¹¶åœ¨é’ˆå¯¹å¥åº·å—è¯•è€…çš„å®æ—¶æµ‹è¯•ä¸­å®ç°äº†60%è‡³86%çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†è¯¥ç³»ç»Ÿä½œä¸ºä½æˆæœ¬ã€ç‹¬ç«‹å±…å®¶ç¥ç»åº·å¤(neurorehabilitation)è§£å†³æ–¹æ¡ˆçš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.HC",
      "comment": "Proceedings of the 7th Novel Intelligent and Leading Emerging Sciences Conference (NILES 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.15890v1",
      "published_date": "2025-09-07 22:19:03 UTC",
      "updated_date": "2025-09-07 22:19:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:02:26.891638+00:00"
    },
    {
      "arxiv_id": "2509.08004v1",
      "title": "Evaluating and comparing gender bias across four text-to-image models",
      "title_zh": "å››ç§æ–‡ç”Ÿå›¾æ¨¡å‹æ€§åˆ«åè§çš„è¯„ä¼°ä¸å¯¹æ¯”",
      "authors": [
        "Zoya Hammad",
        "Nii Longdon Sowah"
      ],
      "abstract": "As we increasingly use Artificial Intelligence (AI) in decision-making for industries like healthcare, finance, e-commerce, and even entertainment, it is crucial to also reflect on the ethical aspects of AI, for example the inclusivity and fairness of the information it provides. In this work, we aimed to evaluate different text-to-image AI models and compare the degree of gender bias they present. The evaluated models were Stable Diffusion XL (SDXL), Stable Diffusion Cascade (SC), DALL-E and Emu. We hypothesized that DALL-E and Stable Diffusion, which are comparatively older models, would exhibit a noticeable degree of gender bias towards men, while Emu, which was recently released by Meta AI, would have more balanced results. As hypothesized, we found that both Stable Diffusion models exhibit a noticeable degree of gender bias while Emu demonstrated more balanced results (i.e. less gender bias). However, interestingly, Open AI's DALL-E exhibited almost opposite results, such that the ratio of women to men was significantly higher in most cases tested. Here, although we still observed a bias, the bias favored females over males. This bias may be explained by the fact that OpenAI changed the prompts at its backend, as observed during our experiment. We also observed that Emu from Meta AI utilized user information while generating images via WhatsApp. We also proposed some potential solutions to avoid such biases, including ensuring diversity across AI research teams and having diverse datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°å¹¶æ¯”è¾ƒäº† Stable Diffusion XL (SDXL)ã€Stable Diffusion Cascade (SC)ã€DALL-E å’Œ Emu å››ç§ text-to-image æ¨¡å‹ä¸­çš„æ€§åˆ«åè§ (gender bias)ã€‚å®éªŒç»“æœè¯å®ï¼Œè¾ƒæ—©æœŸçš„æ¨¡å‹ Stable Diffusion ç³»åˆ—ï¼ˆSDXL å’Œ SCï¼‰è¡¨ç°å‡ºæ˜æ˜¾çš„å€¾å‘äºç”·æ€§çš„åè§ï¼Œè€Œ Meta AI å‘å¸ƒçš„ Emu æ¨¡å‹åˆ™å‘ˆç°å‡ºæ›´å‡è¡¡çš„ç»“æœã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒOpenAI çš„ DALL-E å‘ˆç°å‡ºå‡ ä¹ç›¸åçš„è¶‹åŠ¿ï¼Œåœ¨å¤šæ•°æµ‹è¯•æ¡ˆä¾‹ä¸­å¥³æ€§æ¯”ä¾‹æ˜¾è‘—é«˜äºç”·æ€§ï¼Œè¿™ç§åè§å¯èƒ½æºäº OpenAI åœ¨åç«¯å¯¹æç¤ºè¯ (prompts) è¿›è¡Œäº†ä¿®æ”¹ã€‚ç ”ç©¶è¿˜è§‚å¯Ÿåˆ° Emu åœ¨é€šè¿‡ WhatsApp ç”Ÿæˆå›¾åƒæ—¶ä¼šåˆ©ç”¨ç”¨æˆ·ä¿¡æ¯ã€‚æœ€åï¼Œä½œè€…æå‡ºäº†é€šè¿‡ç¡®ä¿äººå·¥æ™ºèƒ½ç ”ç©¶å›¢é˜Ÿå¤šæ ·æ€§ä»¥åŠæ„å»ºå¤šæ ·åŒ–æ•°æ®é›† (diverse datasets) æ¥ç¼“è§£æ€§åˆ«åè§é—®é¢˜çš„æ½œåœ¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08004v1",
      "published_date": "2025-09-07 22:15:58 UTC",
      "updated_date": "2025-09-07 22:15:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:02:06.194672+00:00"
    },
    {
      "arxiv_id": "2509.07032v1",
      "title": "A Maslow-Inspired Hierarchy of Engagement with AI Model",
      "title_zh": "å— Maslow å¯å‘çš„ AI å‚ä¸å±‚æ¬¡æ¨¡å‹",
      "authors": [
        "Madara Ogot"
      ],
      "abstract": "The rapid proliferation of artificial intelligence (AI) across industry, government, and education highlights the urgent need for robust frameworks to conceptualise and guide engagement. This paper introduces the Hierarchy of Engagement with AI model, a novel maturity framework inspired by Maslow's hierarchy of needs. The model conceptualises AI adoption as a progression through eight levels, beginning with initial exposure and basic understanding and culminating in ecosystem collaboration and societal impact. Each level integrates technical, organisational, and ethical dimensions, emphasising that AI maturity is not only a matter of infrastructure and capability but also of trust, governance, and responsibility. Initial validation of the model using four diverse case studies (General Motors, the Government of Estonia, the University of Texas System, and the African Union AI Strategy) demonstrate the model's contextual flexibility across various sectors. The model provides scholars with a framework for analysing AI maturity and offers practitioners and policymakers a diagnostic and strategic planning tool to guide responsible and sustainable AI engagement. The proposed model demonstrates that AI maturity progression is multi-dimensional, requiring technological capability, ethical integrity, organisational resilience, and ecosystem collaboration.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å—é©¬æ–¯æ´›éœ€æ±‚å±‚æ¬¡ç†è®º(Maslow's hierarchy of needs)å¯å‘çš„â€œAIå‚ä¸å±‚æ¬¡æ¨¡å‹â€(Hierarchy of Engagement with AI)ï¼Œæ—¨åœ¨ä¸ºå·¥ä¸šã€æ”¿åºœå’Œæ•™è‚²ç­‰é¢†åŸŸçš„AIé‡‡ç”¨æä¾›ä¸€å¥—ç³»ç»ŸåŒ–çš„æˆç†Ÿåº¦æ¡†æ¶ã€‚è¯¥æ¨¡å‹å°†AIçš„æ¼”è¿›è¿‡ç¨‹æ¦‚å¿µåŒ–ä¸ºä»åˆæ­¥æ¥è§¦ã€åŸºç¡€ç†è§£åˆ°æœ€ç»ˆå®ç°ç”Ÿæ€ç³»ç»Ÿåä½œä¸ç¤¾ä¼šå½±å“çš„å…«ä¸ªé˜¶æ®µã€‚æ¯ä¸ªå±‚çº§éƒ½æ·±åº¦æ•´åˆäº†æŠ€æœ¯ã€ç»„ç»‡å’Œä¼¦ç†ç»´åº¦ï¼Œå¼ºè°ƒAIæˆç†Ÿåº¦ä¸ä»…å–å†³äºåŸºç¡€è®¾æ–½å’Œèƒ½åŠ›å»ºè®¾ï¼Œæ›´å…³ä¹ä¿¡ä»»ã€æ²»ç†ä¸è´£ä»»çš„è½å®ã€‚é€šè¿‡å¯¹é€šç”¨æ±½è½¦(General Motors)ã€çˆ±æ²™å°¼äºšæ”¿åºœã€å¾·å…‹è¨æ–¯å¤§å­¦ç³»ç»ŸåŠéç›ŸAIæˆ˜ç•¥å››ä¸ªå¤šå…ƒåŒ–æ¡ˆä¾‹çš„åˆ†æï¼ŒéªŒè¯äº†è¯¥æ¨¡å‹åœ¨ä¸åŒè¡Œä¸šèƒŒæ™¯ä¸‹çš„çµæ´»æ€§ã€‚è¯¥æ¨¡å‹ä¸ä»…ä¸ºå­¦è€…æä¾›äº†åˆ†æAIæˆç†Ÿåº¦çš„ç†è®ºå·¥å…·ï¼Œä¹Ÿä¸ºæ”¿ç­–åˆ¶å®šè€…å’Œä»ä¸šè€…æä¾›äº†è¯Šæ–­ä¸è§„åˆ’è´Ÿè´£ä»»ã€å¯æŒç»­AIå‚ä¸è·¯å¾„çš„æˆ˜ç•¥æŒ‡å—ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒAIæˆç†Ÿåº¦çš„æå‡æ˜¯å¤šç»´åº¦çš„ï¼Œéœ€è¦æŠ€æœ¯èƒ½åŠ›ã€ä¼¦ç†è¯šä¿¡ã€ç»„ç»‡éŸ§æ€§ä»¥åŠç”Ÿæ€åä½œçš„å…±åŒé©±åŠ¨ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "30 pages, 14 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.07032v1",
      "published_date": "2025-09-07 21:54:21 UTC",
      "updated_date": "2025-09-07 21:54:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:03:19.663495+00:00"
    },
    {
      "arxiv_id": "2509.08847v1",
      "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs",
      "title_zh": "åŸºäº NLP ä¸å¤šæ¨¡æ€ LLMs çš„ GDD è‡ªåŠ¨åŒ– Unity æ¸¸æˆæ¨¡æ¿ç”Ÿæˆ",
      "authors": [
        "Amna Hassan"
      ],
      "abstract": "This paper presents a novel framework for automated game template generation by transforming Game Design Documents (GDDs) into functional Unity game prototypes using Natural Language Processing (NLP) and multi-modal Large Language Models (LLMs). We introduce an end-to-end system that parses GDDs, extracts structured game specifications, and synthesizes Unity-compatible C# code that implements the core mechanics, systems, and architecture defined in the design documentation. Our approach combines a fine-tuned LLaMA-3 model specialized for Unity code generation with a custom Unity integration package that streamlines the implementation process. Evaluation results demonstrate significant improvements over baseline models, with our fine-tuned model achieving superior performance (4.8/5.0 average score) compared to state-of-the-art LLMs across compilation success, GDD adherence, best practices adoption, and code modularity metrics. The generated templates demonstrate high adherence to GDD specifications across multiple game genres. Our system effectively addresses critical gaps in AI-assisted game development, positioning LLMs as valuable tools in streamlining the transition from game design to implementation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å’Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(multi-modal LLMs)å°†æ¸¸æˆè®¾è®¡æ–‡æ¡£(GDDs)è½¬åŒ–ä¸ºåŠŸèƒ½æ€§Unityæ¸¸æˆåŸå‹çš„è‡ªåŠ¨åŒ–ç”Ÿæˆæ¡†æ¶ã€‚è¯¥ç«¯åˆ°ç«¯ç³»ç»Ÿèƒ½å¤Ÿè§£æGDDså¹¶æå–ç»“æ„åŒ–è§„æ ¼ï¼Œè¿›è€Œè‡ªåŠ¨åˆæˆå®ç°æ ¸å¿ƒæœºåˆ¶ã€ç³»ç»Ÿå’Œæ¶æ„çš„Unityå…¼å®¹C#ä»£ç ã€‚å…¶æ ¸å¿ƒé‡‡ç”¨äº†ä¸“é—¨é’ˆå¯¹Unityä»£ç ç”Ÿæˆè¿›è¡Œå¾®è°ƒçš„LLaMA-3æ¨¡å‹ï¼Œå¹¶ç»“åˆè‡ªå®šä¹‰Unityé›†æˆåŒ…æ¥ç®€åŒ–å¼€å‘æµç¨‹ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨ç¼–è¯‘æˆåŠŸç‡ã€GDDéµå¾ªåº¦ã€æœ€ä½³å®è·µé‡‡ç”¨å’Œä»£ç æ¨¡å—åŒ–ç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›LLMsï¼Œå¹³å‡è¯„åˆ†è¾¾åˆ°4.8/5.0ã€‚å®éªŒè¯æ˜è¯¥ç³»ç»Ÿåœ¨å¤šç§æ¸¸æˆç±»å‹ä¸­å‡è¡¨ç°å‡ºæé«˜çš„è§„æ ¼éµå¾ªåº¦ï¼Œæœ‰æ•ˆåœ°å¡«è¡¥äº†AIè¾…åŠ©æ¸¸æˆå¼€å‘ä¸­çš„æŠ€æœ¯ç©ºç™½ï¼Œä¸ºä»æ¸¸æˆè®¾è®¡åˆ°å®ç°çš„é«˜æ•ˆè¿‡æ¸¡æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08847v1",
      "published_date": "2025-09-07 21:53:37 UTC",
      "updated_date": "2025-09-07 21:53:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:02:48.397809+00:00"
    },
    {
      "arxiv_id": "2509.06221v1",
      "title": "Beamforming-LLM: What, Where and When Did I Miss?",
      "title_zh": "Beamforming-LLMï¼šæˆ‘é”™è¿‡äº†ä»€ä¹ˆï¼Œåœ¨ä½•å¤„ï¼Œåˆæ˜¯ä½•æ—¶ï¼Ÿ",
      "authors": [
        "Vishal Choudhari"
      ],
      "abstract": "We present Beamforming-LLM, a system that enables users to semantically recall conversations they may have missed in multi-speaker environments. The system combines spatial audio capture using a microphone array with retrieval-augmented generation (RAG) to support natural language queries such as, \"What did I miss when I was following the conversation on dogs?\" Directional audio streams are separated using beamforming, transcribed with Whisper, and embedded into a vector database using sentence encoders. Upon receiving a user query, semantically relevant segments are retrieved, temporally aligned with non-attended segments, and summarized using a lightweight large language model (GPT-4o-mini). The result is a user-friendly interface that provides contrastive summaries, spatial context, and timestamped audio playback. This work lays the foundation for intelligent auditory memory systems and has broad applications in assistive technology, meeting summarization, and context-aware personal spatial computing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Beamforming-LLMï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å¸®åŠ©ç”¨æˆ·åœ¨å¤šå‘è¨€äººç¯å¢ƒ(multi-speaker environments)ä¸­è¯­ä¹‰åŒ–æ£€ç´¢å¹¶æ‰¾å›é—æ¼å¯¹è¯ä¿¡æ¯çš„ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨éº¦å…‹é£é˜µåˆ—è¿›è¡Œç©ºé—´éŸ³é¢‘æ•è·(spatial audio capture)ï¼Œå¹¶ç»“åˆæ³¢æŸæˆå½¢(beamforming)æŠ€æœ¯åˆ†ç¦»å‡ºä¸åŒæ–¹å‘çš„éŸ³é¢‘æµã€‚æå–å‡ºçš„éŸ³é¢‘é€šè¿‡Whisperè¿›è¡Œè½¬å½•ï¼Œå¹¶åˆ©ç”¨å¥å­ç¼–ç å™¨(sentence encoders)å°†æ–‡æœ¬åµŒå…¥åˆ°å‘é‡æ•°æ®åº“(vector database)ä¸­ã€‚åœ¨æ¥æ”¶åˆ°ç”¨æˆ·æŸ¥è¯¢åï¼Œç³»ç»Ÿåˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ä»æ•°æ®åº“ä¸­æå–è¯­ä¹‰ç›¸å…³çš„ç‰‡æ®µï¼Œå¹¶ç”±è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹GPT-4o-miniç”Ÿæˆå¯¹æ¯”æ€§æ€»ç»“ã€‚æœ€ç»ˆç•Œé¢èƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›åŒ…å«ç©ºé—´èƒŒæ™¯(spatial context)å’Œå¸¦æ—¶é—´æˆ³éŸ³é¢‘å›æ”¾çš„æ‘˜è¦ï¼Œä»è€Œå®ç°å¯¹é—æ¼å†…å®¹çš„ç²¾å‡†å®šä½ã€‚è¿™é¡¹å·¥ä½œä¸ºæ™ºèƒ½å¬è§‰è®°å¿†ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œåœ¨è¾…åŠ©æŠ€æœ¯ã€ä¼šè®®æ‘˜è¦å’Œæƒ…å¢ƒæ„ŸçŸ¥ä¸ªäººç©ºé—´è®¡ç®—é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06221v1",
      "published_date": "2025-09-07 21:52:26 UTC",
      "updated_date": "2025-09-07 21:52:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:02:46.796255+00:00"
    },
    {
      "arxiv_id": "2509.06218v2",
      "title": "The Efficiency Frontier: Classical Shadows versus Quantum Footage",
      "title_zh": "æ•ˆç‡å‰æ²¿ï¼šç»å…¸é˜´å½±ä¸é‡å­å½±åƒ",
      "authors": [
        "Shuowei Ma",
        "Junyu Liu"
      ],
      "abstract": "Interfacing quantum and classical processors is an important subroutine in full-stack quantum algorithms. The so-called \"classical shadow\" method efficiently extracts essential classical information from quantum states, enabling the prediction of many properties of a quantum system from only a few measurements. However, for a small number of highly non-local observables, or when classical post-processing power is limited, the classical shadow method is not always the most efficient choice. Here, we address this issue quantitatively by performing a full-stack resource analysis that compares classical shadows with \"quantum footage,\" which refers to direct quantum measurement. Under certain assumptions, our analysis illustrates a boundary of download efficiency between classical shadows and quantum footage. For observables expressed as linear combinations of Pauli matrices, the classical shadow method outperforms direct measurement when the number of observables is large and the Pauli weight is small. For observables in the form of large Hermitian sparse matrices, the classical shadow method shows an advantage when the number of observables, the sparsity of the matrix, and the number of qubits fall within a certain range. The key parameters influencing this behavior include the number of qubits $n$, observables $M$, sparsity $k$, Pauli weight $w$, accuracy requirement $Îµ$, and failure tolerance $Î´$. We also compare the resource consumption of the two methods on different types of quantum computers and identify break-even points where the classical shadow method becomes more efficient, which vary depending on the hardware. This paper opens a new avenue for quantitatively designing optimal strategies for hybrid quantum-classical tomography and provides practical insights for selecting the most suitable quantum measurement approach in real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å…¨æ ˆèµ„æºåˆ†æï¼Œå®šé‡åœ°æ¯”è¾ƒäº†Classical Shadowsä¸Quantum Footageï¼ˆå³ç›´æ¥é‡å­æµ‹é‡ï¼‰åœ¨é‡å­ä¸ç»å…¸å¤„ç†å™¨æ¥å£å­ç¨‹åºä¸­çš„æ•ˆç‡è¾¹ç•Œã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå°½ç®¡Classical Shadowsèƒ½ä»æå°‘é‡æµ‹é‡ä¸­é¢„æµ‹å¤šä¸ªé‡å­ç³»ç»Ÿå±æ€§ï¼Œä½†åœ¨é¢å¯¹é«˜åº¦éå±€éƒ¨è§‚æµ‹å€¼æˆ–å—é™çš„ç»å…¸åå¤„ç†èƒ½åŠ›æ—¶ï¼Œå…¶æ•ˆç‡ä¼˜åŠ¿å¹¶ä¸å›ºå®šã€‚åˆ†æè¡¨æ˜ï¼Œå¯¹äºPauli Matricesçº¿æ€§ç»„åˆå½¢å¼çš„è§‚æµ‹å€¼ï¼ŒClassical Shadowsåœ¨è§‚æµ‹å€¼æ•°é‡è¾ƒå¤šä¸”Pauli Weightè¾ƒå°æ—¶è¡¨ç°æ›´ä½³ï¼›è€Œé’ˆå¯¹å¤§å‹Hermitianç¨€ç–çŸ©é˜µï¼Œå…¶ä¼˜åŠ¿åŒºé—´å—Qubitsæ•°é‡$n$ã€è§‚æµ‹å€¼æ•°é‡$M$åŠç¨€ç–åº¦$k$ç­‰å‚æ•°å…±åŒå½±å“ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡å¯¹æ¯”ä¸åŒé‡å­ç¡¬ä»¶çš„èµ„æºæ¶ˆè€—ï¼Œç¡®å®šäº†Classical Shadowsä¼˜äºç›´æ¥æµ‹é‡çš„å¹³è¡¡ç‚¹ï¼ˆBreak-even pointsï¼‰ã€‚è¯¥å·¥ä½œä¸ºè®¾è®¡Hybrid Quantum-Classical Tomographyçš„æœ€ä¼˜ç­–ç•¥å¼€è¾Ÿäº†æ–°è·¯å¾„ï¼Œå¹¶ä¸ºå®é™…åº”ç”¨ä¸­é€‰æ‹©æœ€åŒ¹é…ç¡¬ä»¶çš„æµ‹é‡æ–¹æ¡ˆæä¾›äº†é‡è¦çš„å®šé‡æŒ‡å¯¼ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "quant-ph",
      "comment": "23 pages, many figures. v2: changes gibberish texts due to latex compilation error",
      "pdf_url": "https://arxiv.org/pdf/2509.06218v2",
      "published_date": "2025-09-07 21:46:56 UTC",
      "updated_date": "2025-09-09 18:39:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:02:56.163353+00:00"
    },
    {
      "arxiv_id": "2509.12229v1",
      "title": "Profiling LoRA/QLoRA Fine-Tuning Efficiency on Consumer GPUs: An RTX 4060 Case Study",
      "title_zh": "æ¶ˆè´¹çº§ GPU ä¸Šçš„ LoRA/QLoRA å¾®è°ƒæ•ˆç‡æ€§èƒ½åˆ†æï¼šRTX 4060 æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "MSR Avinash"
      ],
      "abstract": "Fine-tuning large language models (LLMs) with parameter-efficient techniques such as LoRA and QLoRA has enabled adaptation of foundation models on modest hardware. Yet the efficiency of such training on consumer-grade GPUs, especially under strict 8 GB VRAM limits, remains underexplored. We present a controlled profiling study of LoRA/QLoRA fine-tuning using the Qwen2.5-1.5B-Instruct model on a single NVIDIA RTX 4060. Across three representative configurations, we systematically vary batch size, sequence length, optimizer choice (AdamW vs. PagedAdamW), and precision (fp16 vs. bf16). We report throughput (tokens/s), time per 10k tokens, and VRAM footprint, alongside energy estimates derived from GPU board power limits. Our results show that paged optimizers improve throughput by up to 25% (628 tok/s vs. 500 tok/s baseline), while bf16 degrades efficiency relative to fp16. Despite 8 GB constraints, sequence lengths up to 2048 tokens were feasible using parameter-efficient strategies. To our knowledge, this is the first systematic case study of LLM fine- tuning efficiency on consumer GPUs, providing reproducible benchmarks and practical guidelines for resource-constrained researchers and practitioners.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨æ¶ˆè´¹çº§GPUï¼ˆç‰¹åˆ«æ˜¯æ˜¾å­˜é™åˆ¶ä¸º8 GBçš„RTX 4060ï¼‰ä¸Šè¿›è¡Œå¤§è¯­è¨€æ¨¡å‹(LLMs)å¾®è°ƒçš„æ•ˆç‡è¿›è¡Œäº†ç³»ç»Ÿæ€§åˆ†æï¼Œé‡ç‚¹æ¢è®¨äº†LoRAå’ŒQLoRAç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åœ¨ä½æ˜¾å­˜ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚ç ”ç©¶è€…åœ¨Qwen2.5-1.5B-Instructæ¨¡å‹ä¸Šç³»ç»Ÿæµ‹è¯•äº†ä¸åŒBatch Sizeã€Sequence Lengthã€ä¼˜åŒ–å™¨ï¼ˆAdamWä¸PagedAdamWï¼‰åŠç²¾åº¦ï¼ˆfp16ä¸bf16ï¼‰çš„ç»„åˆï¼Œå¹¶è®°å½•äº†Throughputã€æ˜¾å­˜å ç”¨åŠåŠŸè€—ç­‰å…³é”®æŒ‡æ ‡ã€‚å®éªŒå‘ç°ï¼Œä½¿ç”¨PagedAdamWä¼˜åŒ–å™¨å¯å°†Throughputæå‡é«˜è¾¾25%ï¼Œä½†åœ¨è¯¥ç¡¬ä»¶ç¯å¢ƒä¸‹fp16çš„æ•ˆç‡è¡¨ç°ä¼˜äºbf16ã€‚å°½ç®¡å­˜åœ¨8 GB VRAMçš„ä¸¥æ ¼é™åˆ¶ï¼Œç ”ç©¶è¯æ˜åˆ©ç”¨å‚æ•°é«˜æ•ˆç­–ç•¥ä»å¯å®ç°é•¿è¾¾2048 tokensçš„åºåˆ—å¾®è°ƒã€‚ä½œä¸ºé¦–ä¸ªé’ˆå¯¹æ¶ˆè´¹çº§æ˜¾å¡å¾®è°ƒæ•ˆç‡çš„ç³»ç»Ÿæ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥å·¥ä½œä¸ºèµ„æºå—é™çš„ç ”ç©¶è€…æä¾›äº†å®è´µçš„åŸºå‡†æ•°æ®å’Œå®è·µæŒ‡å—ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures, 2 tables. Primary category: cs.LG (Machine Learning); secondary: cs.AI (Artificial Intelligence). LaTeX source with figures included",
      "pdf_url": "https://arxiv.org/pdf/2509.12229v1",
      "published_date": "2025-09-07 21:41:14 UTC",
      "updated_date": "2025-09-07 21:41:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:01.764433+00:00"
    },
    {
      "arxiv_id": "2509.06216v2",
      "title": "Agentic Software Engineering: Foundational Pillars and a Research Roadmap",
      "title_zh": "æ™ºèƒ½ä½“åŒ–è½¯ä»¶å·¥ç¨‹ï¼šåŸºç¡€æ”¯æŸ±ä¸ç ”ç©¶è·¯çº¿å›¾",
      "authors": [
        "Ahmed E. Hassan",
        "Hao Li",
        "Dayi Lin",
        "Bram Adams",
        "Tse-Hsun Chen",
        "Yutaro Kashiwa",
        "Dong Qiu"
      ],
      "abstract": "Agentic Software Engineering (SE 3.0) represents a new era where intelligent agents are tasked not with simple code generation, but with achieving complex, goal-oriented SE objectives. To harness these new capabilities while ensuring trustworthiness, we must recognize a fundamental duality within the SE field in the Agentic SE era, comprising two symbiotic modalities: SE for Humans and SE for Agents. This duality demands a radical reimagining of the foundational pillars of SE (actors, processes, tools, and artifacts) which manifest differently across each modality. We propose two purpose-built workbenches to support this vision. The Agent Command Environment (ACE) serves as a command center where humans orchestrate and mentor agent teams, handling outputs such as Merge-Readiness Packs (MRPs) and Consultation Request Packs (CRPs). The Agent Execution Environment (AEE) is a digital workspace where agents perform tasks while invoking human expertise when facing ambiguity or complex trade-offs. This bi-directional partnership, which supports agent-initiated human callbacks and handovers, gives rise to new, structured engineering activities (i.e., processes) that redefine human-AI collaboration, elevating the practice from agentic coding to true agentic software engineering. This paper presents the Structured Agentic Software Engineering (SASE) vision, outlining several of the foundational pillars for the future of SE. The paper culminates in a research roadmap that identifies a few key challenges and opportunities while briefly discussing the resulting impact of this future on SE education. Our goal is not to offer a definitive solution, but to provide a conceptual scaffold with structured vocabulary to catalyze a community-wide dialogue, pushing the SE community to think beyond its classic, human-centric tenets toward a disciplined, scalable, and trustworthy agentic future.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ™ºèƒ½è½¯ä»¶å·¥ç¨‹çš„æ–°çºªå…ƒ Agentic Software Engineering (SE 3.0)ï¼Œå…¶æ ¸å¿ƒåœ¨äºè®©æ™ºèƒ½ä½“ Agents å®Œæˆå¤æ‚çš„ã€ä»¥ç›®æ ‡ä¸ºå¯¼å‘çš„è½¯ä»¶å·¥ç¨‹ä»»åŠ¡ï¼Œè€Œéç®€å•çš„ä»£ç ç”Ÿæˆã€‚è®ºæ–‡æå‡ºåœ¨ Agentic SE æ—¶ä»£ï¼Œè½¯ä»¶å·¥ç¨‹é¢†åŸŸå­˜åœ¨â€œä¸ºäººç±»è®¾è®¡çš„è½¯ä»¶å·¥ç¨‹â€ SE for Humans ä¸â€œä¸ºæ™ºèƒ½ä½“è®¾è®¡çš„è½¯ä»¶å·¥ç¨‹â€ SE for Agents è¿™ä¸€æ ¹æœ¬æ€§çš„å…±ç”ŸåŒé‡æ€§ã€‚ä¸ºå®ç°è¿™ä¸€æ„¿æ™¯ï¼Œç ”ç©¶è€…é‡æ–°å®šä¹‰äº†è½¯ä»¶å·¥ç¨‹çš„åŸºç¡€æ”¯æŸ±ï¼ŒåŒ…æ‹¬å‚ä¸è€… Actorsã€æµç¨‹ Processesã€å·¥å…· Tools å’Œäº§ç‰© Artifactsã€‚è®ºæ–‡æå‡ºäº†ä¸¤ä¸ªä¸“é—¨æ„å»ºçš„å·¥ä½œå°ï¼šç”¨äºäººç±»ç¼–æ’å’ŒæŒ‡å¯¼å›¢é˜Ÿçš„æ™ºèƒ½ä½“æŒ‡æŒ¥ç¯å¢ƒ Agent Command Environment (ACE)ï¼Œä»¥åŠç”¨äºæ™ºèƒ½ä½“æ‰§è¡Œä»»åŠ¡å¹¶è°ƒç”¨äººç±»ä¸“å®¶çš„æ™ºèƒ½ä½“æ‰§è¡Œç¯å¢ƒ Agent Execution Environment (AEE)ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†ç»“æ„åŒ–æ™ºèƒ½ä½“è½¯ä»¶å·¥ç¨‹ Structured Agentic Software Engineering (SASE) çš„æ„¿æ™¯ï¼Œå¼ºè°ƒé€šè¿‡åŒå‘åä½œå’Œç»“æ„åŒ–çš„å·¥ç¨‹æ´»åŠ¨ï¼Œå°†å¼€å‘æ¨¡å¼ä» Agentic Coding æå‡è‡³çœŸæ­£çš„ Agentic SEã€‚è®ºæ–‡æœ€åæä¾›äº†ä¸€ä»½ç ”ç©¶è·¯çº¿å›¾ï¼Œæ—¨åœ¨ä¸ºå­¦æœ¯ç•Œæä¾›ç»“æ„åŒ–çš„æ¦‚å¿µæ¡†æ¶ï¼Œæ¨åŠ¨è½¯ä»¶å·¥ç¨‹ä»ä»¥äººç±»ä¸ºä¸­å¿ƒè½¬å‘è§„èŒƒã€å¯æ‰©å±•ä¸”å¯ä¿¡çš„æ™ºèƒ½ä½“æœªæ¥ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06216v2",
      "published_date": "2025-09-07 21:40:10 UTC",
      "updated_date": "2025-09-23 01:01:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:03:35.178442+00:00"
    },
    {
      "arxiv_id": "2509.06213v3",
      "title": "Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning",
      "title_zh": "è¿ˆå‘äººå·¥æ™ºèƒ½è®¡é‡å­¦ï¼šéšè—è§„åˆ™ç¯å¢ƒä¸å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Christo Mathew",
        "Wentian Wang",
        "Jacob Feldman",
        "Lazaros K. Gallos",
        "Paul B. Kantor",
        "Vladimir Menkov",
        "Hao Wang"
      ],
      "abstract": "We investigate reinforcement learning in the Game Of Hidden Rules (GOHR) environment, a complex puzzle in which an agent must infer and execute hidden rules to clear a 6$\\times$6 board by placing game pieces into buckets. We explore two state representation strategies, namely Feature-Centric (FC) and Object-Centric (OC), and employ a Transformer-based Advantage Actor-Critic (A2C) algorithm for training. The agent has access only to partial observations and must simultaneously infer the governing rule and learn the optimal policy through experience. We evaluate our models across multiple rule-based and trial-list-based experimental setups, analyzing transfer effects and the impact of representation on learning efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨éšæ€§è§„åˆ™æ¸¸æˆ (Game Of Hidden Rules, GOHR) ç¯å¢ƒä¸‹çš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning)ï¼Œè¿™æ˜¯ä¸€ç§è¦æ±‚æ™ºèƒ½ä½“åœ¨ 6x6 æ£‹ç›˜ä¸Šé€šè¿‡å°†æ£‹å­æ”¾å…¥æ¡¶ä¸­æ¥æ¨æ–­å¹¶æ‰§è¡Œéšæ€§è§„åˆ™çš„å¤æ‚è°œé¢˜ã€‚ç ”ç©¶æ¢ç´¢äº†ç‰¹å¾ä¸­å¿ƒ (Feature-Centric, FC) å’Œå¯¹è±¡ä¸­å¿ƒ (Object-Centric, OC) ä¸¤ç§çŠ¶æ€è¡¨ç¤ºç­–ç•¥ï¼Œå¹¶é‡‡ç”¨åŸºäº Transformer çš„ä¼˜åŠ¿åŠ¨ä½œè¯„ä»· (Advantage Actor-Critic, A2C) ç®—æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚æ™ºèƒ½ä½“åœ¨ä»…èƒ½è·å¾—éƒ¨åˆ†è§‚æµ‹ (Partial Observations) çš„æŒ‘æˆ˜ä¸‹ï¼Œå¿…é¡»é€šè¿‡äº¤äº’ç»éªŒåŒæ­¥å®ç°è§„åˆ™æ¨æ–­ä¸æœ€ä¼˜ç­–ç•¥å­¦ä¹ ã€‚é€šè¿‡åœ¨å¤šç§è§„åˆ™å’Œè¯•éªŒåˆ—è¡¨è®¾ç½®ä¸‹çš„å®éªŒï¼Œè¯¥ç ”ç©¶æ·±å…¥è¯„ä¼°äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶åˆ†æäº†è¿ç§»æ•ˆåº” (Transfer Effects) ä»¥åŠè¡¨ç¤ºç­–ç•¥å¯¹å­¦ä¹ æ•ˆç‡çš„å…·ä½“å½±å“ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06213v3",
      "published_date": "2025-09-07 21:22:14 UTC",
      "updated_date": "2025-10-23 04:14:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:03:38.162816+00:00"
    },
    {
      "arxiv_id": "2509.09711v2",
      "title": "PsychiatryBench: A Multi-Task Benchmark for LLMs in Psychiatry",
      "title_zh": "PsychiatryBenchï¼šé¢å‘ç²¾ç¥åŒ»å­¦å¤§è¯­è¨€æ¨¡å‹çš„å¤šä»»åŠ¡åŸºå‡†",
      "authors": [
        "Aya E. Fouda",
        "Abdelrahamn A. Hassan",
        "Radwa J. Hanafy",
        "Mohammed E. Fouda"
      ],
      "abstract": "Large language models (LLMs) offer significant potential in enhancing psychiatric practice, from improving diagnostic accuracy to streamlining clinical documentation and therapeutic support. However, existing evaluation resources heavily rely on small clinical interview corpora, social media posts, or synthetic dialogues, which limits their clinical validity and fails to capture the full complexity of diagnostic reasoning. In this work, we introduce PsychiatryBench, a rigorously curated benchmark grounded exclusively in authoritative, expert-validated psychiatric textbooks and casebooks. PsychiatryBench comprises eleven distinct question-answering tasks ranging from diagnostic reasoning and treatment planning to longitudinal follow-up, management planning, clinical approach, sequential case analysis, and multiple-choice/extended matching formats totaling 5,188 expert-annotated items. {\\color{red}We evaluate a diverse set of frontier LLMs (including Google Gemini, DeepSeek, Sonnet 4.5, and GPT 5) alongside leading open-source medical models such as MedGemma using both conventional metrics and an \"LLM-as-judge\" similarity scoring framework. Our results reveal substantial gaps in clinical consistency and safety, particularly in multi-turn follow-up and management tasks, underscoring the need for specialized model tuning and more robust evaluation paradigms. PsychiatryBench offers a modular, extensible platform for benchmarking and improving LLM performance in mental health applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PsychiatryBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ç²¾ç¥åŒ»å­¦é¢†åŸŸå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šä»»åŠ¡åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°èµ„æºåœ¨ä¸´åºŠæœ‰æ•ˆæ€§å’Œè¯Šæ–­æ¨ç†å¤æ‚æ€§ä¸Šçš„å±€é™ã€‚PsychiatryBenchå®Œå…¨åŸºäºæƒå¨ä¸”ç»ä¸“å®¶éªŒè¯çš„ç²¾ç¥ç§‘æ•™ç§‘ä¹¦ä¸æ¡ˆä¾‹é›†ï¼Œæ¶µç›–äº†è¯Šæ–­æ¨ç†ã€æ²»ç–—è®¡åˆ’ã€çºµå‘éšè®¿åŠç®¡ç†è§„åˆ’ç­‰11é¡¹ä¸åŒçš„é—®ç­”ä»»åŠ¡ï¼ŒåŒ…å«å…±è®¡5,188ä¸ªä¸“å®¶æ ‡æ³¨é¡¹ç›®ã€‚é€šè¿‡å¯¹Google Geminiã€DeepSeekã€Sonnet 4.5ã€GPT 5ä»¥åŠMedGemmaç­‰å‰æ²¿æ¨¡å‹çš„è¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†æ¨¡å‹åœ¨ä¸´åºŠä¸€è‡´æ€§å’Œå®‰å…¨æ€§æ–¹é¢çš„æ˜¾è‘—å·®è·ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè½®éšè®¿å’Œç®¡ç†ä»»åŠ¡ä¸­ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ºè¡¡é‡å¹¶æå‡LLMsåœ¨å¿ƒç†å¥åº·åº”ç”¨ä¸­çš„è¡¨ç°æä¾›äº†ä¸€ä¸ªæ¨¡å—åŒ–ä¸”å¯æ‰©å±•çš„è¯„ä¼°å¹³å°ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09711v2",
      "published_date": "2025-09-07 20:57:24 UTC",
      "updated_date": "2025-11-23 15:40:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:03:53.869322+00:00"
    },
    {
      "arxiv_id": "2509.06201v1",
      "title": "Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control",
      "title_zh": "Grasp-MPCï¼šåŸºäºä»·å€¼å¼•å¯¼æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„é—­ç¯è§†è§‰æŠ“å–",
      "authors": [
        "Jun Yamada",
        "Adithyavairavan Murali",
        "Ajay Mandlekar",
        "Clemens Eppner",
        "Ingmar Posner",
        "Balakumar Sundaralingam"
      ],
      "abstract": "Grasping of diverse objects in unstructured environments remains a significant challenge. Open-loop grasping methods, effective in controlled settings, struggle in cluttered environments. Grasp prediction errors and object pose changes during grasping are the main causes of failure. In contrast, closed-loop methods address these challenges in simplified settings (e.g., single object on a table) on a limited set of objects, with no path to generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping policy designed for robust and reactive grasping of novel objects in cluttered environments. Grasp-MPC incorporates a value function, trained on visual observations from a large-scale synthetic dataset of 2 million grasp trajectories that include successful and failed attempts. We deploy this learned value function in an MPC framework in combination with other cost terms that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC on FetchBench and real-world settings across diverse environments. Grasp-MPC improves grasp success rates by up to 32.6% in simulation and 33.3% in real-world noisy conditions, outperforming open-loop, diffusion policy, transformer policy, and IQL approaches. Videos and more at http://grasp-mpc.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Grasp-MPCï¼Œä¸€ç§åŸºäºè§†è§‰çš„é—­ç¯(closed-loop)å…­è‡ªç”±åº¦(6-DoF)æŠ“å–ç­–ç•¥ï¼Œæ—¨åœ¨æ‚ä¹±ç¯å¢ƒä¸‹å®ç°å¯¹æ–°é¢–ç‰©ä½“çš„é²æ£’å’Œååº”å¼æŠ“å–ã€‚Grasp-MPCå¼•å…¥äº†ä¸€ä¸ªåœ¨åŒ…å«200ä¸‡æ¡æŠ“å–è½¨è¿¹ï¼ˆæ¶µç›–æˆåŠŸä¸å¤±è´¥å°è¯•ï¼‰çš„å¤§è§„æ¨¡åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒçš„ä»·å€¼å‡½æ•°(value function)ã€‚è¯¥æ–¹æ³•å°†å­¦ä¹ åˆ°çš„ä»·å€¼å‡½æ•°ä¸é¿éšœ(collision avoidance)åŠå¹³æ»‘æ‰§è¡Œç­‰æˆæœ¬é¡¹ç›¸ç»“åˆï¼Œæ•´åˆè¿›æ¨¡å‹é¢„æµ‹æ§åˆ¶(MPC)æ¡†æ¶ä¸­ã€‚åœ¨FetchBenchå’Œç°å®åœºæ™¯çš„è¯„ä¼°ä¸­ï¼ŒGrasp-MPCåœ¨ä»¿çœŸå’Œç°å®å™ªå£°ç¯å¢ƒä¸‹çš„æŠ“å–æˆåŠŸç‡åˆ†åˆ«æå‡äº†32.6%å’Œ33.3%ã€‚å®éªŒç»“æœè¯æ˜å…¶æ€§èƒ½ä¼˜äºå¼€ç¯æ–¹æ³•ã€æ‰©æ•£ç­–ç•¥(diffusion policy)ã€Transformerç­–ç•¥ä»¥åŠIQLç­‰ä¸»æµæ–¹æ³•ï¼Œä¸ºéç»“æ„åŒ–ç¯å¢ƒä¸‹çš„æœºå™¨äººè§†è§‰æŠ“å–æä¾›äº†æœ‰æ•ˆçš„é—­ç¯è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "14 pages, 17 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06201v1",
      "published_date": "2025-09-07 20:28:21 UTC",
      "updated_date": "2025-09-07 20:28:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:03:50.863213+00:00"
    },
    {
      "arxiv_id": "2509.06195v1",
      "title": "Language Bias in Information Retrieval: The Nature of the Beast and Mitigation Methods",
      "title_zh": "ä¿¡æ¯æ£€ç´¢ä¸­çš„è¯­è¨€åè§ï¼šé—®é¢˜æœ¬è´¨ä¸ç¼“è§£æ–¹æ³•",
      "authors": [
        "Jinrui Yang",
        "Fan Jiang",
        "Timothy Baldwin"
      ],
      "abstract": "Language fairness in multilingual information retrieval (MLIR) systems is crucial for ensuring equitable access to information across diverse languages. This paper sheds light on the issue, based on the assumption that queries in different languages, but with identical semantics, should yield equivalent ranking lists when retrieving on the same multilingual documents. We evaluate the degree of fairness using both traditional retrieval methods, and a DPR neural ranker based on mBERT and XLM-R. Additionally, we introduce `LaKDA', a novel loss designed to mitigate language biases in neural MLIR approaches. Our analysis exposes intrinsic language biases in current MLIR technologies, with notable disparities across the retrieval methods, and the effectiveness of LaKDA in enhancing language fairness.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢(Multilingual Information Retrieval, MLIR)ç³»ç»Ÿä¸­çš„è¯­è¨€å…¬å¹³æ€§é—®é¢˜ï¼ŒåŸºäºè¯­ä¹‰ç›¸åŒçš„ä¸åŒè¯­è¨€æŸ¥è¯¢åœ¨æ£€ç´¢ç›¸åŒå¤šè¯­è¨€æ–‡æ¡£æ—¶åº”äº§ç”Ÿç­‰æ•ˆæ’åºåˆ—è¡¨çš„å‡è®¾è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ä½œè€…è¯„ä¼°äº†ä¼ ç»Ÿæ£€ç´¢æ–¹æ³•ä»¥åŠåŸºäº mBERT å’Œ XLM-R çš„ DPR ç¥ç»æ’åºå™¨åœ¨å…¬å¹³æ€§æ–¹é¢çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å½“å‰ MLIR æŠ€æœ¯ä¸­æ™®éå­˜åœ¨çš„å†…åœ¨è¯­è¨€åè§ä»¥åŠä¸åŒæ£€ç´¢æ–¹æ³•ä¹‹é—´çš„æ˜¾è‘—å·®å¼‚ã€‚ä¸ºäº†åº”å¯¹è¿™äº›åè§ï¼Œè®ºæ–‡å¼•å…¥äº†ä¸€ç§åä¸º LaKDA çš„æ–°å‹æŸå¤±å‡½æ•°ï¼Œä¸“é—¨ç”¨äºç¼“è§£ç¥ç» MLIR æ–¹æ³•ä¸­çš„è¯­è¨€åå·®ã€‚å®éªŒåˆ†æè¯æ˜äº† LaKDA åœ¨å¢å¼ºè¯­è¨€å…¬å¹³æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæå‡å¤šè¯­è¨€æ£€ç´¢ç³»ç»Ÿçš„ä¿¡æ¯è·å–å¹³ç­‰æ€§æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at EMNLP MRL 2024",
      "pdf_url": "https://arxiv.org/pdf/2509.06195v1",
      "published_date": "2025-09-07 20:10:49 UTC",
      "updated_date": "2025-09-07 20:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:03:47.565256+00:00"
    },
    {
      "arxiv_id": "2509.07030v2",
      "title": "A Minimalist Bayesian Framework for Stochastic Optimization",
      "title_zh": "éšæœºä¼˜åŒ–çš„æç®€è´å¶æ–¯æ¡†æ¶",
      "authors": [
        "Kaizheng Wang"
      ],
      "abstract": "The Bayesian paradigm offers principled tools for sequential decision-making under uncertainty, but its reliance on a probabilistic model for all parameters can hinder the incorporation of complex structural constraints. We introduce a minimalist Bayesian framework that places a prior only on the component of interest, such as the location of the optimum. Nuisance parameters are eliminated via profile likelihood, which naturally handles constraints. As a direct instantiation, we develop a MINimalist Thompson Sampling (MINTS) algorithm. Our framework accommodates structured problems, including continuum-armed Lipschitz bandits and dynamic pricing. It also provides a probabilistic lens on classical convex optimization algorithms such as the center of gravity and ellipsoid methods. We further analyze MINTS for multi-armed bandits and establish near-optimal regret guarantees.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºéšæœºä¼˜åŒ–(Stochastic Optimization)çš„æç®€è´å¶æ–¯æ¡†æ¶(Minimalist Bayesian Framework)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè´å¶æ–¯èŒƒå¼åœ¨å¤„ç†å¤æ‚ç»“æ„çº¦æŸæ—¶é¢ä¸´çš„å‚æ•°å»ºæ¨¡éš¾é¢˜ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°ä»…åœ¨æ„Ÿå…´è¶£çš„éƒ¨åˆ†ï¼ˆå¦‚æœ€ä¼˜è§£ä½ç½®ï¼‰ä¸Šè®¾ç½®å…ˆéªŒåˆ†å¸ƒï¼Œå¹¶é€šè¿‡å‰–é¢ä¼¼ç„¶(Profile Likelihood)æ¶ˆé™¤å†—ä½™å‚æ•°ï¼Œä»è€Œèƒ½å¤Ÿè‡ªç„¶åœ°å¤„ç†å„ç±»çº¦æŸã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œä½œè€…å¼€å‘äº†æç®€æ±¤æ™®æ£®é‡‡æ ·(MINimalist Thompson Sampling, MINTS)ç®—æ³•ï¼Œå¹¶è¯æ˜å…¶é€‚ç”¨äºè¿ç»­è‡‚Lipschitzè€è™æœº(Continuum-armed Lipschitz Bandits)å’ŒåŠ¨æ€å®šä»·(Dynamic Pricing)ç­‰å¤šç§ç»“æ„åŒ–é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜ä¸ºé‡å¿ƒæ³•(Center of Gravity)å’Œæ¤­çƒæ³•(Ellipsoid Methods)ç­‰ç»å…¸å‡¸ä¼˜åŒ–ç®—æ³•æä¾›äº†æ¦‚ç‡è§†è§’çš„è§£é‡Šã€‚ç†è®ºåˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼ŒMINTSç®—æ³•åœ¨å¤šè‡‚è€è™æœº(Multi-armed Bandits)ä»»åŠ¡ä¸­å…·æœ‰æ¥è¿‘æœ€ä¼˜çš„é—æ†¾ç•Œ(Regret Guarantees)ä¿è¯ï¼Œä¸ºä¸ç¡®å®šæ€§ä¸‹çš„åºåˆ—å†³ç­–æä¾›äº†é«˜æ•ˆä¸”ç¨³å¥çš„å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07030v2",
      "published_date": "2025-09-07 19:31:12 UTC",
      "updated_date": "2025-10-08 01:52:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:03:52.098838+00:00"
    },
    {
      "arxiv_id": "2509.06176v2",
      "title": "AI Governance in Higher Education: A course design exploring regulatory, ethical and practical considerations",
      "title_zh": "é«˜ç­‰æ•™è‚²ä¸­çš„äººå·¥æ™ºèƒ½æ²»ç†ï¼šä¸€é¡¹æ¢è®¨ç›‘ç®¡ã€ä¼¦ç†ä¸å®è·µè€ƒé‡çš„è¯¾ç¨‹è®¾è®¡",
      "authors": [
        "RaphaÃ«l Weuts",
        "Johannes Bleher",
        "Hannah Bleher",
        "Rozanne Tuesday Flores",
        "Guo Xuanyang",
        "PaweÅ‚ Pujszo",
        "Zsolt AlmÃ¡si"
      ],
      "abstract": "As artificial intelligence (AI) systems permeate critical sectors, the need for professionals who can address ethical, legal and governance challenges has become urgent. Current AI ethics education remains fragmented, often siloed by discipline and disconnected from practice. This paper synthesizes literature and regulatory developments to propose a modular, interdisciplinary curriculum that integrates technical foundations with ethics, law and policy. We highlight recurring operational failures in AI - bias, misspecified objectives, generalization errors, misuse and governance breakdowns - and link them to pedagogical strategies for teaching AI governance. Drawing on perspectives from the EU, China and international frameworks, we outline a semester plan that emphasizes integrated ethics, stakeholder engagement and experiential learning. The curriculum aims to prepare students to diagnose risks, navigate regulation and engage diverse stakeholders, fostering adaptive and ethically grounded professionals for responsible AI governance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜ç­‰æ•™è‚²ä¸­AI ethicsæ•™è‚²ç¢ç‰‡åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€å¥—æ•´åˆäº†æŠ€æœ¯åŸºç¡€ã€ä¼¦ç†ã€æ³•å¾‹å’Œæ”¿ç­–çš„æ¨¡å—åŒ–ã€è·¨å­¦ç§‘è¯¾ç¨‹è®¾è®¡æ–¹æ¡ˆã€‚è¯¾ç¨‹ç»“åˆäº†æ¬§ç›Ÿã€ä¸­å›½åŠå›½é™…ç›‘ç®¡æ¡†æ¶çš„å‘å±•è¶‹åŠ¿ï¼Œé€šè¿‡ç»¼åˆæ–‡çŒ®ç»¼è¿°å’Œç›‘ç®¡åŠ¨æ€ï¼Œæ„å»ºäº†æ¶µç›–AIæ²»ç†æ ¸å¿ƒæŒ‘æˆ˜çš„æ•™å­¦ä½“ç³»ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†AIç³»ç»Ÿåœ¨å®è·µä¸­å¸¸è§çš„åè§(bias)ã€ç›®æ ‡è¯¯è®¾å®š(misspecified objectives)ã€æ³›åŒ–è¯¯å·®(generalization errors)åŠæ»¥ç”¨ç­‰æ“ä½œæ€§å¤±æ•ˆï¼Œå¹¶å°†è¿™äº›é—®é¢˜ä¸AI governanceçš„æ•™å­¦ç­–ç•¥ç›´æ¥æŒ‚é’©ã€‚æå‡ºçš„å­¦æœŸè®¡åˆ’å¼ºè°ƒç»¼åˆä¼¦ç†(integrated ethics)ã€åˆ©ç›Šç›¸å…³è€…å‚ä¸(stakeholder engagement)å’Œä½“éªŒå¼å­¦ä¹ (experiential learning)ï¼Œæ—¨åœ¨åŸ¹å…»å­¦ç”Ÿçš„é£é™©è¯Šæ–­ä¸ç›‘ç®¡å¯¼èˆªèƒ½åŠ›ã€‚è¯¥è¯¾ç¨‹è®¾è®¡æ—¨åœ¨ä¸ºè´Ÿè´£ä»»çš„AIæ²»ç†åŸ¹å…»å…·æœ‰é€‚åº”æ€§å’Œä¼¦ç†åŸºç¡€çš„ä¸“ä¸šäººæ‰ï¼Œä»¥åº”å¯¹æ—¥ç›Šå¤æ‚çš„æ³•å¾‹ä¸ä¼¦ç†æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06176v2",
      "published_date": "2025-09-07 19:09:12 UTC",
      "updated_date": "2025-09-16 15:37:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:01.070790+00:00"
    },
    {
      "arxiv_id": "2509.06174v1",
      "title": "From Long to Short: LLMs Excel at Trimming Own Reasoning Chains",
      "title_zh": "ç”±é•¿åŠçŸ­ï¼šå¤§è¯­è¨€æ¨¡å‹æ“…é•¿ç²¾ç®€è‡ªèº«çš„æ¨ç†é“¾",
      "authors": [
        "Wei Han",
        "Geng Zhan",
        "Sicheng Yu",
        "Chenyu Wang",
        "Bryan Hooi"
      ],
      "abstract": "O1/R1 style large reasoning models (LRMs) signal a substantial leap forward over conventional instruction-following LLMs. By applying test-time scaling to generate extended reasoning paths, they establish many SOTAs across a wide range of complex reasoning tasks. However, recent studies show that LRMs are prone to suffer from overthinking -- the tendency to overcomplicate simple problems, leading to excessive strategy switching and long, convoluted reasoning traces that hinder their interpretability. To mitigate this issue, we conduct a systematic investigation into the reasoning efficiency of a broad set of LRMs and uncover a common dilemma: the difficulty in balancing multiple generation objectives such as correctness and brevity. Based on this discovery, we propose a test-time scaling method, EDIT (Efficient Dynamic Inference Trimming), which efficiently guides LRMs to identify the shortest correct reasoning paths at test time. EDIT employs constraint-guided generation while jointly tracking length and answer distributions under varying constraints, allowing it to select responses that strike an optimal balance between conciseness and correctness. Extensive experiments across diverse models and datasets show that EDIT substantially enhance the reasoning efficiency, producing compact yet informative outputs that improve readability and user experience.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†O1/R1é£æ ¼çš„å¤§è¯­è¨€æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰è™½ç„¶åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†æ™®éå­˜åœ¨è¿‡åº¦æ€è€ƒï¼ˆoverthinkingï¼‰çš„é—®é¢˜ï¼Œå¯¼è‡´æ¨ç†è·¯å¾„å†—é•¿ä¸”å¯è§£é‡Šæ€§å·®ã€‚é€šè¿‡ç³»ç»Ÿè°ƒæŸ¥ï¼Œç ”ç©¶è€…å‘ç°LRMséš¾ä»¥åœ¨ç”Ÿæˆæ­£ç¡®æ€§ï¼ˆcorrectnessï¼‰ä¸ç®€æ´æ€§ï¼ˆbrevityï¼‰ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºEDITï¼ˆEfficient Dynamic Inference Trimmingï¼‰çš„æµ‹è¯•æ—¶æ‰©å±•ï¼ˆtest-time scalingï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨çº¦æŸå¼•å¯¼ç”ŸæˆæŠ€æœ¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯»æ‰¾æœ€çŸ­çš„æ­£ç¡®è·¯å¾„ã€‚EDITé€šè¿‡åŠ¨æ€è·Ÿè¸ªä¸åŒçº¦æŸä¸‹çš„é•¿åº¦å’Œç­”æ¡ˆåˆ†å¸ƒï¼Œç¡®ä¿è¾“å‡ºç»“æœåœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶å°½å¯èƒ½ç²¾ç®€ã€‚å®éªŒè¯æ˜ï¼ŒEDITåœ¨å¤šç§æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡èƒ½æ˜¾è‘—æå‡æ¨ç†æ•ˆç‡ï¼Œé€šè¿‡æä¾›æ›´ç®€æ´ã€æ›´å…·å¯è¯»æ€§çš„è¾“å‡ºç»“æœï¼Œæœ‰æ•ˆä¼˜åŒ–äº†ç”¨æˆ·çš„äº¤äº’ä½“éªŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 5 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.06174v1",
      "published_date": "2025-09-07 19:00:44 UTC",
      "updated_date": "2025-09-07 19:00:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:03.759911+00:00"
    },
    {
      "arxiv_id": "2509.06169v1",
      "title": "Reasoning Language Model for Personalized Lung Cancer Screening",
      "title_zh": "ç”¨äºä¸ªä½“åŒ–è‚ºç™Œç­›æŸ¥çš„æ¨ç†è¯­è¨€æ¨¡å‹",
      "authors": [
        "Chuang Niu",
        "Ge Wang"
      ],
      "abstract": "Accurate risk assessment in lung cancer screening is critical for enabling early cancer detection and minimizing unnecessary invasive procedures. The Lung CT Screening Reporting and Data System (Lung-RADS) has been widely used as the standard framework for patient management and follow-up. Nevertheless, Lung-RADS faces trade-offs between sensitivity and specificity, as it stratifies risk solely based on lung nodule characteristics without incorporating various risk factors. Here we propose a reasoning language model (RLM) to integrate radiology findings with longitudinal medical records for individualized lung cancer risk assessment. Through a systematic study including dataset construction and distillation, supervised fine-tuning, reinforcement learning, and comprehensive evaluation, our model makes significant improvements in risk prediction performance on datasets in the national lung screening trial. Notably, RLM can decompose the risk evaluation task into sub-components, analyze the contributions of diverse risk factors, and synthesize them into a final risk score computed using our data-driven system equation. Our approach improves both predictive accuracy and monitorability through the chain of thought reasoning process, thereby facilitating clinical translation into lung cancer screening.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†æ¨ç†è¯­è¨€æ¨¡å‹(Reasoning Language Model, RLM)ï¼Œæ—¨åœ¨è§£å†³è‚ºç™Œç­›æŸ¥ä¸­Lung-RADSæ¡†æ¶å› ä»…ä¾èµ–ç»“èŠ‚ç‰¹å¾è€Œå¯¼è‡´çš„æ•æ„Ÿæ€§ä¸ç‰¹å¼‚æ€§å¹³è¡¡é—®é¢˜ã€‚RLMé€šè¿‡æ•´åˆæ”¾å°„å­¦å½±åƒå‘ç°ä¸çºµå‘åŒ»ç–—è®°å½•ï¼Œå®ç°äº†é«˜åº¦ä¸ªæ€§åŒ–çš„è‚ºç™Œé£é™©è¯„ä¼°ã€‚ç ”ç©¶å›¢é˜Ÿç³»ç»Ÿæ€§åœ°è¿ç”¨äº†æ•°æ®é›†æ„å»ºä¸è’¸é¦ã€æœ‰ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)ä»¥åŠå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç­‰æŠ€æœ¯ï¼Œåœ¨å›½å®¶è‚ºç™Œç­›æŸ¥è¯•éªŒ(NLST)æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†é£é™©é¢„æµ‹æ€§èƒ½ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå°†å¤æ‚çš„è¯„ä¼°ä»»åŠ¡åˆ†è§£ä¸ºå­ç»„ä»¶ï¼Œåˆ†æä¸åŒé£é™©å› ç´ çš„è´¡çŒ®ï¼Œå¹¶åˆ©ç”¨æ•°æ®é©±åŠ¨çš„ç³»ç»Ÿæ–¹ç¨‹åˆæˆæœ€ç»ˆè¯„åˆ†ã€‚é€šè¿‡å¼•å…¥é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†è¿‡ç¨‹ï¼Œè¯¥æ–¹æ³•åœ¨æé«˜é¢„æµ‹å‡†ç¡®æ€§çš„åŒæ—¶å¢å¼ºäº†æ¨¡å‹çš„å¯ç›‘æµ‹æ€§ï¼Œä»è€Œæœ‰åŠ›åœ°æ¨åŠ¨äº†äººå·¥æ™ºèƒ½åœ¨è‚ºç™Œç­›æŸ¥ä¸­çš„ä¸´åºŠè½¬åŒ–ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06169v1",
      "published_date": "2025-09-07 18:38:39 UTC",
      "updated_date": "2025-09-07 18:38:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:10.870192+00:00"
    },
    {
      "arxiv_id": "2509.06165v4",
      "title": "UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning",
      "title_zh": "UNOï¼šåŸºäºä»¥ç‰©ä½“ä¸ºä¸­å¿ƒè§†è§‰è¡¨ç¤ºå­¦ä¹ çš„ç»Ÿä¸€å•é˜¶æ®µè§†é¢‘åœºæ™¯å›¾ç”Ÿæˆ",
      "authors": [
        "Huy Le",
        "Nhat Chung",
        "Tung Kieu",
        "Jingkang Yang",
        "Ngan Le"
      ],
      "abstract": "Video Scene Graph Generation (VidSGG) aims to represent dynamic visual content by detecting objects and modeling their temporal interactions as structured graphs. Prior studies typically target either coarse-grained box-level or fine-grained panoptic pixel-level VidSGG, often requiring task-specific architectures and multi-stage training pipelines. In this paper, we present UNO (UNified Object-centric VidSGG), a single-stage, unified framework that jointly addresses both tasks within an end-to-end architecture. UNO is designed to minimize task-specific modifications and maximize parameter sharing, enabling generalization across different levels of visual granularity. The core of UNO is an extended slot attention mechanism that decomposes visual features into object and relation slots. To ensure robust temporal modeling, we introduce object temporal consistency learning, which enforces consistent object representations across frames without relying on explicit tracking modules. Additionally, a dynamic triplet prediction module links relation slots to corresponding object pairs, capturing evolving interactions over time. We evaluate UNO on standard box-level and pixel-level VidSGG benchmarks. Results demonstrate that UNO not only achieves competitive performance across both tasks but also offers improved efficiency through a unified, object-centric design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† UNO (UNified Object-centric VidSGG)ï¼Œè¿™æ˜¯ä¸€ä¸ªå•é˜¶æ®µã€ç»Ÿä¸€çš„è§†é¢‘åœºæ™¯å›¾ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨åŒæ—¶å¤„ç†ç²—ç²’åº¦çš„è¾¹ç•Œæ¡†çº§åˆ«å’Œç»†ç²’åº¦çš„å…¨æ™¯åƒç´ çº§åˆ«ä»»åŠ¡ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ¶æ„ï¼Œé€šè¿‡æ‰©å±•çš„ Slot Attention æœºåˆ¶å°†è§†è§‰ç‰¹å¾åˆ†è§£ä¸º Object Slots å’Œ Relation Slotsï¼Œä»è€Œå®ç°è·¨ä»»åŠ¡çš„å‚æ•°å…±äº«ä¸æ³›åŒ–ã€‚ä¸ºäº†å¢å¼ºæ—¶åºå»ºæ¨¡èƒ½åŠ›ï¼Œç ”ç©¶å¼•å…¥äº† Object Temporal Consistency Learningï¼Œåœ¨ä¸ä¾èµ–æ˜¾å¼è·Ÿè¸ªæ¨¡å—çš„æƒ…å†µä¸‹ç¡®ä¿è·¨å¸§å¯¹è±¡è¡¨ç¤ºçš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡ Dynamic Triplet Prediction Module å°†å…³ç³»æ§½ä¸ç›¸åº”çš„å¯¹è±¡å¯¹å…³è”ï¼Œæœ‰æ•ˆæ•æ‰è§†é¢‘ä¸­éšæ—¶é—´æ¼”å˜çš„åŠ¨æ€äº¤äº’ã€‚åœ¨æ ‡å‡†çš„è¾¹ç•Œæ¡†çº§å’Œåƒç´ çº§ VidSGG åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜ï¼ŒUNO ä¸ä»…åœ¨ä¸¤é¡¹ä»»åŠ¡ä¸­å‡å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè¿˜é€šè¿‡ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„ä¸€ä½“åŒ–è®¾è®¡æ˜¾è‘—æå‡äº†å¤„ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures. Accepted at WACV 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.06165v4",
      "published_date": "2025-09-07 18:30:41 UTC",
      "updated_date": "2025-12-11 20:39:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:47.271398+00:00"
    },
    {
      "arxiv_id": "2509.06164v2",
      "title": "Benchmarking Gender and Political Bias in Large Language Models",
      "title_zh": "å¤§å‹è¯­è¨€æ¨¡å‹æ€§åˆ«ä¸æ”¿æ²»åè§çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Jinrui Yang",
        "Xudong Han",
        "Timothy Baldwin"
      ],
      "abstract": "We introduce EuroParlVote, a novel benchmark for evaluating large language models (LLMs) in politically sensitive contexts. It links European Parliament debate speeches to roll-call vote outcomes and includes rich demographic metadata for each Member of the European Parliament (MEP), such as gender, age, country, and political group. Using EuroParlVote, we evaluate state-of-the-art LLMs on two tasks -- gender classification and vote prediction -- revealing consistent patterns of bias. We find that LLMs frequently misclassify female MEPs as male and demonstrate reduced accuracy when simulating votes for female speakers. Politically, LLMs tend to favor centrist groups while underperforming on both far-left and far-right ones. Proprietary models like GPT-4o outperform open-weight alternatives in terms of both robustness and fairness. We release the EuroParlVote dataset, code, and demo to support future research on fairness and accountability in NLP within political contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† EuroParlVoteï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ”¿æ²»æ•æ„Ÿè¯­å¢ƒä¸‹è¡¨ç°çš„æ–°å‹åŸºå‡†æµ‹è¯•ï¼Œè¯¥åŸºå‡†å°†æ¬§æ´²è®®ä¼šè¾©è®ºæ¼”è¯´ä¸è®°åæŠ•ç¥¨ç»“æœç›¸ç»“åˆï¼Œå¹¶åŒ…å«æ€§åˆ«ã€å¹´é¾„ã€å›½å®¶å’Œæ”¿æ²»å›¢ä½“ç­‰ä¸°å¯Œçš„äººå£ç»Ÿè®¡å…ƒæ•°æ®ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ EuroParlVote åœ¨æ€§åˆ«åˆ†ç±» (gender classification) å’ŒæŠ•ç¥¨é¢„æµ‹ (vote prediction) ä¸¤é¡¹ä»»åŠ¡ä¸Šå¯¹æœ€å…ˆè¿›çš„ LLMs è¿›è¡Œäº†è¯„ä¼°ï¼Œæ­ç¤ºäº†æ¨¡å‹ä¸­ä¸€è‡´çš„åè§æ¨¡å¼ã€‚å®éªŒå‘ç° LLMs é¢‘ç¹åœ°å°†å¥³æ€§è®®å‘˜è¯¯åˆ†ç±»ä¸ºç”·æ€§ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿå¥³æ€§å‘è¨€äººçš„æŠ•ç¥¨æ—¶è¡¨ç°å‡ºè¾ƒä½çš„å‡†ç¡®ç‡ã€‚åœ¨æ”¿æ²»å€¾å‘æ–¹é¢ï¼ŒLLMs å€¾å‘äºåå¥½ä¸­é—´æ´¾å›¢ä½“ (centrist groups)ï¼Œè€Œåœ¨æå·¦ç¿¼å’Œæå³ç¿¼å›¢ä½“çš„è¡¨ç°åˆ™è¾ƒå·®ã€‚ä»¥ GPT-4o ä¸ºä»£è¡¨çš„å•†ä¸šæ¨¡å‹åœ¨é²æ£’æ€§ (robustness) å’Œå…¬å¹³æ€§ (fairness) æ–¹é¢å‡ä¼˜äºå¼€æºæ¨¡å‹ã€‚è¯¥ç ”ç©¶é€šè¿‡å‘å¸ƒ EuroParlVote æ•°æ®é›†ã€ä»£ç å’Œæ¼”ç¤ºï¼Œä¸ºæœªæ¥åœ¨æ”¿æ²»èƒŒæ™¯ä¸‹å¼€å±•è‡ªç„¶è¯­è¨€å¤„ç† (NLP) çš„å…¬å¹³æ€§ä¸é—®è´£åˆ¶ç ”ç©¶æä¾›äº†æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06164v2",
      "published_date": "2025-09-07 18:23:30 UTC",
      "updated_date": "2025-09-16 05:28:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:26.970631+00:00"
    },
    {
      "arxiv_id": "2509.06161v1",
      "title": "Tracking daily paths in home contexts with RSSI fingerprinting based on UWB through deep learning models",
      "title_zh": "åŸºäº UWB RSSI æŒ‡çº¹è¯†åˆ«ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å±…å®¶æ—¥å¸¸è·¯å¾„è¿½è¸ª",
      "authors": [
        "Aurora Polo-RodrÃ­guez",
        "Juan Carlos Valera",
        "JesÃºs Peral",
        "David Gil",
        "Javier Medina-Quero"
      ],
      "abstract": "The field of human activity recognition has evolved significantly, driven largely by advancements in Internet of Things (IoT) device technology, particularly in personal devices. This study investigates the use of ultra-wideband (UWB) technology for tracking inhabitant paths in home environments using deep learning models. UWB technology estimates user locations via time-of-flight and time-difference-of-arrival methods, which are significantly affected by the presence of walls and obstacles in real environments, reducing their precision. To address these challenges, we propose a fingerprinting-based approach utilizing received signal strength indicator (RSSI) data collected from inhabitants in two flats (60 m2 and 100 m2) while performing daily activities. We compare the performance of convolutional neural network (CNN), long short-term memory (LSTM), and hybrid CNN+LSTM models, as well as the use of Bluetooth technology. Additionally, we evaluate the impact of the type and duration of the temporal window (future, past, or a combination of both). Our results demonstrate a mean absolute error close to 50 cm, highlighting the superiority of the hybrid model in providing accurate location estimates, thus facilitating its application in daily human activity recognition in residential settings.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åœ¨å®¶åº­ç¯å¢ƒä¸­ä½¿ç”¨è¶…å®½å¸¦(UWB)æŠ€æœ¯åŠæ·±åº¦å­¦ä¹ æ¨¡å‹è¿½è¸ªå±…ä½è€…è·¯å¾„çš„æ–¹æ³•ï¼Œä»¥æå‡äººä½“æ´»åŠ¨è¯†åˆ«(Human Activity Recognition)çš„æ€§èƒ½ã€‚é’ˆå¯¹ä¼ ç»Ÿçš„é£è¡Œæ—¶é—´(Time-of-Flight)å’Œåˆ°è¾¾æ—¶é—´å·®(Time-Difference-of-Arrival)æ–¹æ³•åœ¨çœŸå®å®¤å†…ç¯å¢ƒä¸­æ˜“å—å¢™å£å’Œéšœç¢ç‰©å¹²æ‰°è€Œç²¾åº¦ä¸‹é™çš„é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºæŒ‡çº¹è¯†åˆ«(Fingerprinting)çš„æ–°ç­–ç•¥ã€‚è¯¥ç ”ç©¶åˆ©ç”¨ä»ä¸¤å¥—ä¸åŒé¢ç§¯ä½å®…ä¸­æ”¶é›†çš„æ¥æ”¶ä¿¡å·å¼ºåº¦æŒ‡ç¤º(RSSI)æ•°æ®ï¼Œå¯¹æ¯”äº†å·ç§¯ç¥ç»ç½‘ç»œ(CNN)ã€é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)åŠæ··åˆCNN+LSTMæ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶æ·±å…¥è¯„ä¼°äº†ä¸åŒæ—¶é—´çª—å£(Temporal Window)å¯¹å®šä½ç²¾åº¦çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆçš„å¹³å‡ç»å¯¹è¯¯å·®(Mean Absolute Error)å¯é™è‡³çº¦50å˜ç±³ï¼Œå…¶ä¸­æ··åˆæ¨¡å‹åœ¨æä¾›ç²¾ç¡®ä½ç½®ä¼°è®¡æ–¹é¢å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºä½å®…åœºæ™¯ä¸‹å®ç°é«˜ç²¾åº¦ã€å¯æ‰©å±•çš„äººä½“æ´»åŠ¨ç›‘æµ‹å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06161v1",
      "published_date": "2025-09-07 18:08:05 UTC",
      "updated_date": "2025-09-07 18:08:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:28.654280+00:00"
    },
    {
      "arxiv_id": "2509.06160v1",
      "title": "Reverse-Engineered Reasoning for Open-Ended Generation",
      "title_zh": "é¢å‘å¼€æ”¾å¼ç”Ÿæˆçš„é€†å‘å·¥ç¨‹æ¨ç†",
      "authors": [
        "Haozhe Wang",
        "Haoran Que",
        "Qixin Xu",
        "Minghao Liu",
        "Wangchunshu Zhou",
        "Jiazhan Feng",
        "Wanjun Zhong",
        "Wei Ye",
        "Tong Yang",
        "Wenhao Huang",
        "Ge Zhang",
        "Fangzhen Lin"
      ],
      "abstract": "While the ``deep reasoning'' paradigm has spurred significant advances in verifiable domains like mathematics, its application to open-ended, creative generation remains a critical challenge. The two dominant methods for instilling reasoning -- reinforcement learning (RL) and instruction distillation -- falter in this area; RL struggles with the absence of clear reward signals and high-quality reward models, while distillation is prohibitively expensive and capped by the teacher model's capabilities. To overcome these limitations, we introduce REverse-Engineered Reasoning (REER), a new paradigm that fundamentally shifts the approach. Instead of building a reasoning process ``forwards'' through trial-and-error or imitation, REER works ``backwards'' from known-good solutions to computationally discover the latent, step-by-step deep reasoning process that could have produced them. Using this scalable, gradient-free approach, we curate and open-source DeepWriting-20K, a large-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks. Our model, DeepWriter-8B, trained on this data, not only surpasses strong open-source baselines but also achieves performance competitive with, and at times superior to, leading proprietary models like GPT-4o and Claude 3.5.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹â€œæ·±åº¦æ¨ç†â€(deep reasoning)èŒƒå¼åœ¨å¼€æ”¾å¼åˆ›ä½œç”Ÿæˆé¢†åŸŸé¢ä¸´çš„å¥–åŠ±ä¿¡å·ç¼ºå¤±å’Œè’¸é¦æˆæœ¬é«˜ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†é€†å‘å·¥ç¨‹æ¨ç†(REverse-Engineered Reasoning, REER)è¿™ä¸€æ–°èŒƒå¼ã€‚ä¸åŒäºä¼ ç»Ÿçš„é€šè¿‡è¯•é”™æˆ–æ¨¡ä»¿çš„â€œæ­£å‘â€æ„å»ºæ–¹å¼ï¼ŒREERé€šè¿‡ä»å·²æœ‰çš„ä¼˜ç§€è§£å†³æ–¹æ¡ˆä¸­â€œå‘åâ€æ¨å¯¼ï¼Œä»¥è®¡ç®—æ–¹å¼å‘ç°äº§ç”Ÿè¿™äº›ç»“æœçš„æ½œåœ¨ã€é€æ­¥çš„æ·±åº¦æ¨ç†è¿‡ç¨‹ã€‚åˆ©ç”¨è¿™ç§å¯æ‰©å±•ä¸”æ— éœ€æ¢¯åº¦çš„ç­–ç•¥ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºå¹¶å¼€æºäº†åŒ…å«2ä¸‡æ¡æ·±åº¦æ¨ç†è½¨è¿¹çš„å¤§è§„æ¨¡æ•°æ®é›†DeepWriting-20Kã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºè¯¥æ•°æ®é›†è®­ç»ƒçš„DeepWriter-8Bæ¨¡å‹ä¸ä»…æ˜¾è‘—è¶…è¶Šäº†å¼ºåŠ›å¼€æºåŸºå‡†ï¼Œå…¶æ€§èƒ½ç”šè‡³èƒ½ä¸GPT-4oå’ŒClaude 3.5ç­‰é¢†å…ˆçš„å•†ä¸šæ¨¡å‹ç›¸åª²ç¾ï¼Œä¸ºå¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›æå‡æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2509.06160v1",
      "published_date": "2025-09-07 18:07:58 UTC",
      "updated_date": "2025-09-07 18:07:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:32.076979+00:00"
    },
    {
      "arxiv_id": "2509.06159v3",
      "title": "FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes",
      "title_zh": "FASL-Segï¼šæ‰‹æœ¯åœºæ™¯ä¸‹çš„è§£å‰–ç»“æ„ä¸æ‰‹æœ¯å™¨æ¢°åˆ†å‰²",
      "authors": [
        "Muraam Abdel-Ghani",
        "Mahmoud Ali",
        "Mohamed Ali",
        "Fatmaelzahraa Ahmed",
        "Muhammad Arsalan",
        "Abdulaziz Al-Ali",
        "Shidin Balakrishnan"
      ],
      "abstract": "The growing popularity of robotic minimally invasive surgeries has made deep learning-based surgical training a key area of research. A thorough understanding of the surgical scene components is crucial, which semantic segmentation models can help achieve. However, most existing work focuses on surgical tools and overlooks anatomical objects. Additionally, current state-of-the-art (SOTA) models struggle to balance capturing high-level contextual features and low-level edge features. We propose a Feature-Adaptive Spatial Localization model (FASL-Seg), designed to capture features at multiple levels of detail through two distinct processing streams, namely a Low-Level Feature Projection (LLFP) and a High-Level Feature Projection (HLFP) stream, for varying feature resolutions - enabling precise segmentation of anatomy and surgical instruments. We evaluated FASL-Seg on surgical segmentation benchmark datasets EndoVis18 and EndoVis17 on three use cases. The FASL-Seg model achieves a mean Intersection over Union (mIoU) of 72.71% on parts and anatomy segmentation in EndoVis18, improving on SOTA by 5%. It further achieves a mIoU of 85.61% and 72.78% in EndoVis18 and EndoVis17 tool type segmentation, respectively, outperforming SOTA overall performance, with comparable per-class SOTA results in both datasets and consistent performance in various classes for anatomy and instruments, demonstrating the effectiveness of distinct processing streams for varying feature resolutions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FASL-Segï¼Œä¸€ç§ç‰¹å¾è‡ªé€‚åº”ç©ºé—´å®šä½(Feature-Adaptive Spatial Localization)æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³æœºå™¨äººå¾®åˆ›æ‰‹æœ¯åœºæ™¯ä¸­è§£å‰–ç»“æ„ä¸æ‰‹æœ¯å·¥å…·çš„ç²¾ç¡®è¯­ä¹‰åˆ†å‰²é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æ¨¡å‹éš¾ä»¥å¹³è¡¡é«˜å±‚ä¸Šä¸‹æ–‡ç‰¹å¾ä¸åº•å±‚è¾¹ç¼˜ç‰¹å¾çš„æŒ‘æˆ˜ï¼ŒFASL-Segè®¾è®¡äº†ä½çº§ç‰¹å¾æŠ•å½±(Low-Level Feature Projection, LLFP)å’Œé«˜çº§ç‰¹å¾æŠ•å½±(High-Level Feature Projection, HLFP)ä¸¤ä¸ªç‹¬ç«‹æµï¼Œä»¥å¤„ç†ä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾ã€‚ç ”ç©¶åœ¨EndoVis18å’ŒEndoVis17åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºFASL-Segåœ¨EndoVis18çš„è§£å‰–ç»“æ„åˆ†å‰²ä»»åŠ¡ä¸­è¾¾åˆ°äº†72.71%çš„mIoUï¼Œæ¯”SOTAæ¨¡å‹æå‡äº†5%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨EndoVis18å’ŒEndoVis17çš„å·¥å…·ç±»å‹åˆ†å‰²ä¸­åˆ†åˆ«å–å¾—äº†85.61%å’Œ72.78%çš„mIoUï¼Œæ•´ä½“æ€§èƒ½è¶…è¶Šäº†ç°æœ‰SOTAæ°´å¹³ã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥åŒæµå¤„ç†æ¶æ„åœ¨æ•è·å¤šç²’åº¦ç‰¹å¾æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¤æ‚æ‰‹æœ¯åœºæ™¯çš„ç†è§£æä¾›äº†æ›´ç²¾å‡†çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages, 6 figures, In Proceedings of European Conference on Artificial Intelligence (ECAI) 2025 <https://doi.org/10.3233/FAIA250908>",
      "pdf_url": "https://arxiv.org/pdf/2509.06159v3",
      "published_date": "2025-09-07 17:59:09 UTC",
      "updated_date": "2025-10-30 08:10:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:36.068922+00:00"
    },
    {
      "arxiv_id": "2509.09710v2",
      "title": "Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data",
      "title_zh": "ç»“åˆäººå£æ™®æŸ¥ä¸åœŸåœ°åˆ©ç”¨æ•°æ®ï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸ªäººå‡ºè¡Œæ—¥å¿—",
      "authors": [
        "Sepehr Golrokh Amin",
        "Devin Rhoads",
        "Fatemeh Fakhrmoosavi",
        "Nicholas E. Lownes",
        "John N. Ivan"
      ],
      "abstract": "This study introduces a Large Language Model (LLM) scheme for generating individual travel diaries in agent-based transportation models. While traditional approaches rely on large quantities of proprietary household travel surveys, the method presented in this study generates personas stochastically from open-source American Community Survey (ACS) and Smart Location Database (SLD) data, then synthesizes diaries through direct prompting. This study features a novel one-to-cohort realism score: a composite of four metrics (Trip Count Score, Interval Score, Purpose Score, and Mode Score) validated against the Connecticut Statewide Transportation Study (CSTS) diaries, matched across demographic variables. The validation utilizes Jensen-Shannon Divergence to measure distributional similarities between generated and real diaries. When compared to diaries generated with classical methods (Negative Binomial for trip generation; Multinomial Logit for mode/purpose) calibrated on the validation set, LLM-generated diaries achieve comparable overall realism (LLM mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and demonstrates greater consistency (narrower realism score distribution), while classical models lead in numerical estimates of trip count and activity duration. Aggregate validation confirms the LLM's statistical representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot viability and establishing a quantifiable metric of diary realism for future synthetic diary evaluation systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) ç”Ÿæˆä¸ªä½“å‡ºè¡Œæ—¥å¿—çš„æ–°æ–¹æ¡ˆï¼Œæ—¨åœ¨å…‹æœä¼ ç»Ÿäº¤é€šæ¨¡å‹å¯¹ç§æœ‰å®¶åº­è°ƒæŸ¥æ•°æ®çš„ä¾èµ–ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¼€æºçš„ç¾å›½ç¤¾åŒºè°ƒæŸ¥ (ACS) å’Œæ™ºèƒ½ä½ç½®æ•°æ®åº“ (SLD) æ•°æ®éšæœºç”Ÿæˆç”»åƒï¼Œå¹¶é€šè¿‡ç›´æ¥æç¤ºè¯æŠ€æœ¯åˆæˆå‡ºè¡Œæ—¥å¿—ã€‚ç ”ç©¶å¼•å…¥äº†ç”±å‡ºè¡Œæ¬¡æ•° (Trip Count)ã€é—´éš” (Interval)ã€ç›®çš„ (Purpose) å’Œæ–¹å¼ (Mode) å››é¡¹æŒ‡æ ‡ç»„æˆçš„â€œä¸ªä½“å¯¹ç¾¤ç»„â€çœŸå®æ€§è¯„åˆ† (one-to-cohort realism score)ï¼Œå¹¶ä½¿ç”¨ Jensen-Shannon Divergence éªŒè¯å…¶ä¸çœŸå®æ•°æ®çš„ä¸€è‡´æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒLLM ç”Ÿæˆçš„æ—¥å¿—åœ¨æ•´ä½“çœŸå®æ€§ä¸Šä¸ç»è¿‡æ ¡å‡†çš„ä¼ ç»Ÿæ¨¡å‹ç›¸å½“ï¼Œä¸”åœ¨å‡ºè¡Œç›®çš„åˆ¤å®šå’Œç»“æœä¸€è‡´æ€§æ–¹é¢å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚ç»¼åˆéªŒè¯è¯æ˜äº† LLM åœ¨ç»Ÿè®¡ä¸Šçš„ä»£è¡¨æ€§åŠå…¶é›¶æ ·æœ¬ (zero-shot) å¯è¡Œæ€§ï¼Œä¸ºæœªæ¥åˆæˆå‡ºè¡Œæ•°æ®çš„è¯„ä¼°ä½“ç³»å¥ å®šäº†é‡åŒ–åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09710v2",
      "published_date": "2025-09-07 17:03:08 UTC",
      "updated_date": "2025-10-20 23:59:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:49.654824+00:00"
    },
    {
      "arxiv_id": "2509.07029v1",
      "title": "The Impact of Artificial Intelligence on Traditional Art Forms: A Disruption or Enhancement",
      "title_zh": "äººå·¥æ™ºèƒ½å¯¹ä¼ ç»Ÿè‰ºæœ¯å½¢å¼çš„å½±å“ï¼šé¢ è¦†è¿˜æ˜¯èµ‹èƒ½",
      "authors": [
        "Viswa Chaitanya Marella",
        "Sai Teja Erukude",
        "Suhasnadh Reddy Veluru"
      ],
      "abstract": "The introduction of Artificial Intelligence (AI) into the domains of traditional art (visual arts, performing arts, and crafts) has sparked a complicated discussion about whether this might be an agent of disruption or an enhancement of our traditional art forms. This paper looks at the duality of AI, exploring the ways that recent technologies like Generative Adversarial Networks and Diffusion Models, and text-to-image generators are changing the fields of painting, sculpture, calligraphy, dance, music, and the arts of craft. Using examples and data, we illustrate the ways that AI can democratize creative expression, improve productivity, and preserve cultural heritage, while also examining the negative aspects, including: the threats to authenticity within art, ethical concerns around data, and issues including socio-economic factors such as job losses. While we argue for the context-dependence of the impact of AI (the potential for creative homogenization and the devaluation of human agency in artmaking), we also illustrate the potential for hybrid practices featuring AI in cuisine, etc. We advocate for the development of ethical guidelines, collaborative approaches, and inclusive technology development. In sum, we are articulating a vision of AI in which it amplifies our innate creativity while resisting the displacement of the cultural, nuanced, and emotional aspects of traditional art. The future will be determined by human choices about how to govern AI so that it becomes a mechanism for artistic evolution and not a substitute for the artist's soul.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)å¯¹ç»˜ç”»ã€é›•å¡‘ã€ä¹¦æ³•ã€èˆè¹ˆåŠéŸ³ä¹ç­‰ä¼ ç»Ÿè‰ºæœ¯å½¢å¼çš„å¤šé‡å½±å“ï¼Œåˆ†æäº†å…¶ä½œä¸ºâ€œé¢ è¦†è€…â€ä¸â€œå¢å¼ºè€…â€çš„åŒé‡è§’è‰²ã€‚æ–‡ç« è¯¦ç»†é˜è¿°äº†Generative Adversarial Networks (GANs)ã€Diffusion ModelsåŠtext-to-image generatorsç­‰å‰æ²¿æŠ€æœ¯å¦‚ä½•æ”¹å˜åˆ›ä½œé¢†åŸŸï¼Œå¹¶æŒ‡å‡ºAIåœ¨æ°‘ä¸»åŒ–åˆ›æ„è¡¨è¾¾ã€æå‡ç”Ÿäº§åŠ›å’Œä¿æŠ¤æ–‡åŒ–é—äº§æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚ä¸æ­¤åŒæ—¶ï¼Œç ”ç©¶ä¹Ÿæ·±å…¥åˆ†æäº†AIå¸¦æ¥çš„è´Ÿé¢æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¯¹è‰ºæœ¯çœŸå®æ€§(authenticity)çš„å¨èƒã€æ•°æ®ä¼¦ç†äº‰è®®ä»¥åŠè‰ºæœ¯åˆ›ä½œä¸­äººç±»ä¸»ä½“æ€§(human agency)è´¬å€¼ç­‰é£é™©ã€‚é€šè¿‡å¯¹çƒ¹é¥ªç­‰è·¨ç•Œé¢†åŸŸæ··åˆå®è·µçš„è§‚å¯Ÿï¼Œä½œè€…ä¸»å¼ é€šè¿‡å»ºç«‹ä¼¦ç†å‡†åˆ™ã€åä½œæ–¹æ³•å’ŒåŒ…å®¹æ€§æŠ€æœ¯å¼€å‘æ¥å¼•å¯¼æŠ€æœ¯èµ°å‘ã€‚æœ€ç»ˆï¼Œç ”ç©¶å¼ºè°ƒAIåº”è¢«è§†ä¸ºæ”¾å¤§äººç±»å…ˆå¤©åˆ›é€ åŠ›çš„å·¥å…·ï¼Œè€Œéå–ä»£è‰ºæœ¯çµé­‚ä¸­æ–‡åŒ–ã€æƒ…æ„Ÿä¸ç»†å¾®å·®åˆ«çš„æ›¿ä»£å“ï¼Œè‰ºæœ¯çš„æœªæ¥å°†å–å†³äºäººç±»å¯¹AIçš„æ²»ç†é€‰æ‹©ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "13 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.07029v1",
      "published_date": "2025-09-07 16:37:04 UTC",
      "updated_date": "2025-09-07 16:37:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:42.661211+00:00"
    },
    {
      "arxiv_id": "2509.08846v1",
      "title": "Uncertainty Estimation using Variance-Gated Distributions",
      "title_zh": "åŸºäºæ–¹å·®é—¨æ§åˆ†å¸ƒçš„ä¸ç¡®å®šæ€§ä¼°è®¡",
      "authors": [
        "H. Martin Gillis",
        "Isaac Xu",
        "Thomas Trappenberg"
      ],
      "abstract": "Evaluation of per-sample uncertainty quantification from neural networks is essential for decision-making involving high-risk applications. A common approach is to use the predictive distribution from Bayesian or approximation models and decompose the corresponding predictive uncertainty into epistemic (model-related) and aleatoric (data-related) components. However, additive decomposition has recently been questioned. In this work, we propose an intuitive framework for uncertainty estimation and decomposition based on the signal-to-noise ratio of class probability distributions across different model predictions. We introduce a variance-gated measure that scales predictions by a confidence factor derived from ensembles. We use this measure to discuss the existence of a collapse in the diversity of committee machines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜é£é™©åº”ç”¨ä¸­ç¥ç»ç½‘ç»œçš„å•æ ·æœ¬ä¸ç¡®å®šæ€§é‡åŒ–(uncertainty quantification)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ–¹å·®é—¨æ§åˆ†å¸ƒ(Variance-Gated Distributions)çš„ç›´è§‚ä¸ç¡®å®šæ€§ä¼°è®¡ä¸åˆ†è§£æ¡†æ¶ã€‚é’ˆå¯¹è¿‘æœŸå­¦æœ¯ç•Œå¯¹ä¼ ç»Ÿè®¤çŸ¥ä¸ç¡®å®šæ€§ä¸å¶ç„¶ä¸ç¡®å®šæ€§åŠ æ€§åˆ†è§£(additive decomposition)æ–¹æ³•çš„è´¨ç–‘ï¼Œè¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°åˆ©ç”¨è·¨ä¸åŒæ¨¡å‹é¢„æµ‹çš„ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒä¿¡å™ªæ¯”(signal-to-noise ratio)æ¥è¿›è¡Œä¸ç¡®å®šæ€§è¯„ä¼°ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ç§æ–¹å·®é—¨æ§åº¦é‡(variance-gated measure)ï¼Œé€šè¿‡ä»é›†æˆæ¨¡å‹(ensembles)ä¸­æå–çš„ç½®ä¿¡å› å­å¯¹é¢„æµ‹ç»“æœè¿›è¡ŒåŠ¨æ€ç¼©æ”¾ã€‚ä½œè€…è¿›ä¸€æ­¥åˆ©ç”¨è¯¥åº¦é‡æ·±å…¥æ¢è®¨å¹¶åˆ†æäº†å§”å‘˜ä¼šæœºå™¨(committee machines)ä¸­å­˜åœ¨çš„å¤šæ ·æ€§å´©æºƒ(diversity collapse)ç°è±¡ã€‚è¿™ä¸€ç ”ç©¶ä¸ºç†è§£æ·±åº¦å­¦ä¹ æ¨¡å‹çš„é¢„æµ‹ç½®ä¿¡åº¦æä¾›äº†æ–°çš„è§†è§’ï¼Œå¢å¼ºäº†æ¨¡å‹åœ¨å…³é”®å†³ç­–åœºæ™¯ä¸­çš„é€æ˜åº¦ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.08846v1",
      "published_date": "2025-09-07 16:19:21 UTC",
      "updated_date": "2025-09-07 16:19:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:04:44.870198+00:00"
    },
    {
      "arxiv_id": "2509.06122v1",
      "title": "SpecSwin3D: Generating Hyperspectral Imagery from Multispectral Data via Transformer Networks",
      "title_zh": "SpecSwin3Dï¼šåˆ©ç”¨ Transformer ç½‘ç»œä»å¤šå…‰è°±æ•°æ®ç”Ÿæˆé«˜å…‰è°±å›¾åƒ",
      "authors": [
        "Tang Sui",
        "Songxi Yang",
        "Qunying Huang"
      ],
      "abstract": "Multispectral and hyperspectral imagery are widely used in agriculture, environmental monitoring, and urban planning due to their complementary spatial and spectral characteristics. A fundamental trade-off persists: multispectral imagery offers high spatial but limited spectral resolution, while hyperspectral imagery provides rich spectra at lower spatial resolution. Prior hyperspectral generation approaches (e.g., pan-sharpening variants, matrix factorization, CNNs) often struggle to jointly preserve spatial detail and spectral fidelity. In response, we propose SpecSwin3D, a transformer-based model that generates hyperspectral imagery from multispectral inputs while preserving both spatial and spectral quality. Specifically, SpecSwin3D takes five multispectral bands as input and reconstructs 224 hyperspectral bands at the same spatial resolution. In addition, we observe that reconstruction errors grow for hyperspectral bands spectrally distant from the input bands. To address this, we introduce a cascade training strategy that progressively expands the spectral range to stabilize learning and improve fidelity. Moreover, we design an optimized band sequence that strategically repeats and orders the five selected multispectral bands to better capture pairwise relations within a 3D shifted-window transformer framework. Quantitatively, our model achieves a PSNR of 35.82 dB, SAM of 2.40Â°, and SSIM of 0.96, outperforming the baseline MHF-Net by +5.6 dB in PSNR and reducing ERGAS by more than half. Beyond reconstruction, we further demonstrate the practical value of SpecSwin3D on two downstream tasks, including land use classification and burnt area segmentation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SpecSwin3Dï¼Œä¸€ç§åŸºäºTransformeræ¶æ„çš„æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¤šå…‰è°±å›¾åƒ(Multispectral Imagery)ä¸é«˜å…‰è°±å›¾åƒ(Hyperspectral Imagery)åœ¨ç©ºé—´å’Œå…‰è°±åˆ†è¾¨ç‡ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ã€‚è¯¥æ¨¡å‹ä»…éœ€è¾“å…¥5ä¸ªå¤šå…‰è°±æ³¢æ®µå³å¯é‡å»ºå‡º224ä¸ªé«˜å…‰è°±æ³¢æ®µï¼Œå¹¶åˆ©ç”¨çº§è”è®­ç»ƒç­–ç•¥(Cascade Training Strategy)é€æ­¥æ‰©å±•å…‰è°±èŒƒå›´ï¼Œæœ‰æ•ˆç¼“è§£äº†è¿œç¨‹æ³¢æ®µçš„é‡å»ºè¯¯å·®ã€‚é€šè¿‡åœ¨3Dç§»çª—Transformer(3D Shifted-Window Transformer)æ¡†æ¶å†…é‡‡ç”¨ä¼˜åŒ–çš„æ³¢æ®µæ’åºç­–ç•¥ï¼ŒSpecSwin3Dèƒ½å¤Ÿæ›´ç²¾å‡†åœ°æ•æ‰å…‰è°±é—´çš„æˆå¯¹å…³ç³»ã€‚å®šé‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨PSNRæŒ‡æ ‡ä¸Šè¾¾åˆ°35.82 dBï¼Œåœ¨æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹MHF-Netçš„åŒæ—¶å°†ERGASè¯¯å·®é™ä½äº†ä¸€åŠä»¥ä¸Šã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åœ¨åœŸåœ°åˆ©ç”¨åˆ†ç±»å’Œè¿‡ç«é¢ç§¯åˆ†å‰²ä»»åŠ¡ä¸­éªŒè¯äº†ç”Ÿæˆæ•°æ®åœ¨ä¸‹æ¸¸åº”ç”¨ä¸­çš„å®é™…ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06122v1",
      "published_date": "2025-09-07 16:18:31 UTC",
      "updated_date": "2025-09-07 16:18:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:05:09.977317+00:00"
    },
    {
      "arxiv_id": "2509.06094v1",
      "title": "Teaching Precommitted Agents: Model-Free Policy Evaluation and Control in Quasi-Hyperbolic Discounted MDPs",
      "title_zh": "æ•™å¯¼é¢„æ‰¿è¯ºæ™ºèƒ½ä½“ï¼šæ‹ŸåŒæ›²æŠ˜æ‰£ MDP ä¸­çš„æ— æ¨¡å‹ç­–ç•¥è¯„ä¼°ä¸æ§åˆ¶",
      "authors": [
        "S. R. Eshwar"
      ],
      "abstract": "Time-inconsistent preferences, where agents favor smaller-sooner over larger-later rewards, are a key feature of human and animal decision-making. Quasi-Hyperbolic (QH) discounting provides a simple yet powerful model for this behavior, but its integration into the reinforcement learning (RL) framework has been limited. This paper addresses key theoretical and algorithmic gaps for precommitted agents with QH preferences. We make two primary contributions: (i) we formally characterize the structure of the optimal policy, proving for the first time that it reduces to a simple one-step non-stationary form; and (ii) we design the first practical, model-free algorithms for both policy evaluation and Q-learning in this setting, both with provable convergence guarantees. Our results provide foundational insights for incorporating QH preferences in RL.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å…·æœ‰Quasi-Hyperbolic (QH)æŠ˜æ‰£åå¥½çš„Precommittedæ™ºèƒ½ä½“ï¼Œæ¢è®¨äº†å…¶åœ¨å¼ºåŒ–å­¦ä¹ (RL)ä¸­çš„å†³ç­–å»ºæ¨¡ã€‚ç ”ç©¶æ—¨åœ¨è§£å†³QHåå¥½å¼•èµ·çš„è·¨æ—¶é€‰æ‹©ä¸ä¸€è‡´æ€§é—®é¢˜ï¼Œå¡«è¡¥äº†è¯¥åå¥½åœ¨Quasi-Hyperbolic Discounted MDPsä¸­çš„ç†è®ºå’Œç®—æ³•ç©ºç™½ã€‚è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åœ¨äºé¦–æ¬¡å½¢å¼åŒ–è¡¨å¾äº†æœ€ä¼˜ç­–ç•¥çš„ç»“æ„ï¼Œè¯æ˜å…¶å¯ç®€åŒ–ä¸ºä¸€ç§ç®€å•çš„ä¸€æ­¥éå¹³ç¨³å½¢å¼(one-step non-stationary form)ã€‚åŒæ—¶ï¼Œç ”ç©¶æå‡ºäº†é¦–ä¸ªå®ç”¨çš„Model-freeç®—æ³•ï¼Œç”¨äºè¯¥è®¾ç½®ä¸‹çš„Policy Evaluationå’ŒQ-learningï¼Œå¹¶å‡æä¾›äº†æ”¶æ•›æ€§ä¿è¯ã€‚è¿™ä¸€å‘ç°ä¸ºåœ¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸­æ•´åˆå¤æ‚çš„ç”Ÿç‰©åŠäººç±»å†³ç­–åå¥½æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06094v1",
      "published_date": "2025-09-07 15:16:15 UTC",
      "updated_date": "2025-09-07 15:16:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:05:32.163105+00:00"
    },
    {
      "arxiv_id": "2509.06093v3",
      "title": "Language-Native Materials Processing Design by Lightly Structured Text Database and Reasoning Large Language Model",
      "title_zh": "åŸºäºè½»ç»“æ„åŒ–æ–‡æœ¬æ•°æ®åº“ä¸æ¨ç†å¤§è¯­è¨€æ¨¡å‹çš„åŸç”Ÿè¯­è¨€ææ–™å·¥è‰ºè®¾è®¡",
      "authors": [
        "Yuze Liu",
        "Zhaoyuan Zhang",
        "Xiangsheng Zeng",
        "Yihe Zhang",
        "Leping Yu",
        "Liu Yang",
        "Lejia Wang",
        "Xi Yu"
      ],
      "abstract": "Materials synthesis procedures are predominantly documented as narrative text in protocols and lab notebooks, rendering them inaccessible to conventional structured data optimization. This language-native nature poses a critical challenge for complex, multistage processes--such as the preparation of boron nitride nanosheet (BNNS)--where outcomes depend on path-dependent choices in exfoliation and functionalization. Here, we recast synthesis planning as a text reasoning task enabled by a lightly structured text database, which preserves the conditional logic and causal contexts essential for expert-like decision-making. Building on a heterogeneous schema that indexes both narrative excerpts and computable entities (e.g., reaction conditions), our system implements a hybrid retrieval engine to combine semantic context with precise parameter filtering. On top of this, the framework operates in two modes, i.e. retrieval-augmented generation (RAG), which grounds recommendations in retrieved evidence modules, and experience-augmented reasoning (EAR), which uses iteratively refined text guides distilled from multi-source narrative data. Instead of suggesting single \"optimal\" settings, the system produces interpretable guidance aligned with expert reasoning patterns--hypotheses, parameter ranges, and citation-backed standard operating procedures--that support iterative planning and failure diagnosis. We validated this framework on the targeted exfoliation of BNNS, a process highly sensitive to multivariate constraints. The system successfully identified optimal combinations of grinding aids, milling configurations, and separation strategies from a wide range of literature-reported methods, which were experimentally verified to yield high-quality nanosheets, illustrating the potential of language-native reasoning to streamline critical operations in materials processing.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ææ–™åˆæˆè¿‡ç¨‹ä¸»è¦ä»¥å™è¿°æ€§æ–‡æœ¬è®°å½•è€Œéš¾ä»¥è¿›è¡Œç»“æ„åŒ–ä¼˜åŒ–çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè½»é‡åŒ–ç»“æ„æ–‡æœ¬æ•°æ®åº“å’Œæ¨ç†å‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆReasoning LLMï¼‰çš„è¯­è¨€åŸç”Ÿï¼ˆLanguage-Nativeï¼‰ææ–™åŠ å·¥è®¾è®¡æ¡†æ¶ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ„å»ºæ•´åˆå™è¿°ç‰‡æ®µä¸å¯è®¡ç®—å®ä½“çš„å¼‚æ„æ¨¡å¼ï¼Œå°†åˆæˆè§„åˆ’è½¬å˜ä¸ºæ–‡æœ¬æ¨ç†ä»»åŠ¡ï¼Œä»è€Œå®Œæ•´ä¿ç•™ä¸“å®¶å†³ç­–æ‰€éœ€çš„æ¡ä»¶é€»è¾‘ä¸å› æœèƒŒæ™¯ã€‚æ¡†æ¶é›†æˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œç»éªŒå¢å¼ºæ¨ç†ï¼ˆEARï¼‰ä¸¤ç§æ¨¡å¼ï¼Œåˆ©ç”¨æ··åˆæ£€ç´¢å¼•æ“æä¾›åŒ…å«å‡è®¾ã€å‚æ•°èŒƒå›´åŠæ–‡çŒ®æ”¯æŒçš„å¯è§£é‡Šæ€§æŒ‡å¯¼ï¼Œè€Œéä»…æä¾›å•ä¸€çš„æœ€ä¼˜è®¾ç½®ã€‚åœ¨æ°®åŒ–ç¡¼çº³ç±³ç‰‡ï¼ˆBNNSï¼‰å®šå‘å‰¥ç¦»çš„å®éªŒéªŒè¯ä¸­ï¼Œç³»ç»ŸæˆåŠŸä»å¹¿æ³›çš„æ–‡çŒ®è®°å½•ä¸­è¯†åˆ«å‡ºç ”ç£¨åŠ©å‰‚ã€çƒç£¨é…ç½®åŠåˆ†ç¦»ç­–ç•¥çš„æœ€ä½³ç»„åˆã€‚å®éªŒç»“æœè¯å®ï¼Œè¯¥æ¡†æ¶ç”Ÿæˆçš„æ ‡å‡†åŒ–æ“ä½œç¨‹åºï¼ˆSOPï¼‰èƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒè¿­ä»£è§„åˆ’ä¸æ•…éšœè¯Šæ–­ï¼Œå±•ç°äº†è¯­è¨€åŸç”Ÿæ¨ç†åœ¨ç®€åŒ–å¤æ‚ææ–™åŠ å·¥æµç¨‹åŠæå‡å†³ç­–æ•ˆç‡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.DB",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06093v3",
      "published_date": "2025-09-07 15:15:55 UTC",
      "updated_date": "2026-01-21 00:43:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:05:54.974813+00:00"
    },
    {
      "arxiv_id": "2509.06085v1",
      "title": "Software Dependencies 2.0: An Empirical Study of Reuse and Integration of Pre-Trained Models in Open-Source Projects",
      "title_zh": "è½¯ä»¶ä¾èµ– 2.0ï¼šå¼€æºé¡¹ç›®ä¸­é¢„è®­ç»ƒæ¨¡å‹å¤ç”¨ä¸é›†æˆçš„å®è¯ç ”ç©¶",
      "authors": [
        "Jerin Yasmin",
        "Wenxin Jiang",
        "James C. Davis",
        "Yuan Tian"
      ],
      "abstract": "Pre-trained models (PTMs) are machine learning models that have been trained in advance, often on large-scale data, and can be reused for new tasks, thereby reducing the need for costly training from scratch. Their widespread adoption introduces a new class of software dependency, which we term Software Dependencies 2.0, extending beyond conventional libraries to learned behaviors embodied in trained models and their associated artifacts. The integration of PTMs as software dependencies in real projects remains unclear, potentially threatening maintainability and reliability of modern software systems that increasingly rely on them. Objective: In this study, we investigate Software Dependencies 2.0 in open-source software (OSS) projects by examining the reuse of PTMs, with a focus on how developers manage and integrate these models. Specifically, we seek to understand: (1) how OSS projects structure and document their PTM dependencies; (2) what stages and organizational patterns emerge in the reuse pipelines of PTMs within these projects; and (3) the interactions among PTMs and other learned components across pipeline stages. We conduct a mixed-methods analysis of a statistically significant random sample of 401 GitHub repositories from the PeaTMOSS dataset (28,575 repositories reusing PTMs from Hugging Face and PyTorch Hub). We quantitatively examine PTM reuse by identifying patterns and qualitatively investigate how developers integrate and manage these models in practice.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é¢„è®­ç»ƒæ¨¡å‹(PTMs)ä½œä¸ºä¸€ç§æ–°å‹è½¯ä»¶ä¾èµ–ï¼ˆç§°ä¸ºSoftware Dependencies 2.0ï¼‰åœ¨å¼€æºé¡¹ç›®ä¸­çš„å¤ç”¨ä¸é›†æˆæƒ…å†µã€‚éšç€é¢„è®­ç»ƒæ¨¡å‹(PTMs)çš„å¹¿æ³›åº”ç”¨ï¼Œç†è§£å¼€å‘è€…å¦‚ä½•ç®¡ç†è¿™äº›è•´å«å­¦ä¹ è¡Œä¸ºçš„ä¾èµ–é¡¹å¯¹äºç»´æŒç°ä»£è½¯ä»¶ç³»ç»Ÿçš„å¯ç»´æŠ¤æ€§å’Œå¯é æ€§è‡³å…³é‡è¦ã€‚ç ”ç©¶äººå‘˜é€šè¿‡æ··åˆæ–¹æ³•(mixed-methods analysis)ï¼Œå¯¹æ¥è‡ªPeaTMOSSæ•°æ®é›†çš„401ä¸ªGitHubä»£ç ä»“åº“è¿›è¡Œäº†ç»Ÿè®¡å­¦æ„ä¹‰ä¸Šçš„éšæœºæŠ½æ ·è°ƒæŸ¥ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†å¼€æºé¡¹ç›®å¦‚ä½•ç»„ç»‡å’Œè®°å½•å…¶é¢„è®­ç»ƒæ¨¡å‹(PTMs)ä¾èµ–ï¼Œä»¥åŠåœ¨å¤ç”¨æµæ°´çº¿(reuse pipelines)ä¸­å‡ºç°çš„ç»„ç»‡é˜¶æ®µä¸æ¨¡å¼ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ­ç¤ºäº†æµæ°´çº¿ä¸åŒé˜¶æ®µä¸­é¢„è®­ç»ƒæ¨¡å‹(PTMs)ä¸å…¶ä»–å­¦ä¹ ç»„ä»¶ä¹‹é—´çš„äº¤äº’å…³ç³»ã€‚é€šè¿‡å®šé‡è¯†åˆ«æ¨¡å¼å’Œå®šæ€§è°ƒæŸ¥å®è·µï¼Œè¯¥å®è¯ç ”ç©¶ä¸ºç†è§£å’Œä¼˜åŒ–åŸºäºAIç»„ä»¶çš„è½¯ä»¶å·¥ç¨‹ç”Ÿå‘½å‘¨æœŸæä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Submitted to Empirical Software Engineering (EMSE) Journal",
      "pdf_url": "https://arxiv.org/pdf/2509.06085v1",
      "published_date": "2025-09-07 15:00:22 UTC",
      "updated_date": "2025-09-07 15:00:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:05:46.280735+00:00"
    },
    {
      "arxiv_id": "2509.21331v1",
      "title": "Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+",
      "title_zh": "åŸºäºæ·±åº¦åˆ†å‰²ç½‘ç»œçš„å¤šæºç‚®é›†åœ°éœ‡é€Ÿåº¦åæ¼”ï¼šU-Net å˜ä½“ä¸ SeismoLabV3+ çš„æ€§èƒ½åŸºå‡†ç ”ç©¶",
      "authors": [
        "Mahedi Hasan"
      ],
      "abstract": "Seismic velocity inversion is a key task in geophysical exploration, enabling the reconstruction of subsurface structures from seismic wave data. It is critical for high-resolution seismic imaging and interpretation. Traditional physics-driven methods, such as Full Waveform Inversion (FWI), are computationally demanding, sensitive to initialization, and limited by the bandwidth of seismic data. Recent advances in deep learning have led to data-driven approaches that treat velocity inversion as a dense prediction task. This research benchmarks three advanced encoder-decoder architectures -- U-Net, U-Net++, and DeepLabV3+ -- together with SeismoLabV3+, an optimized variant of DeepLabV3+ with a ResNeXt50 32x4d backbone and task-specific modifications -- for seismic velocity inversion using the ThinkOnward 2025 Speed \\& Structure dataset, which consists of five-channel seismic shot gathers paired with high-resolution velocity maps. Experimental results show that SeismoLabV3+ achieves the best performance, with MAPE values of 0.03025 on the internal validation split and 0.031246 on the hidden test set as scored via the official ThinkOnward leaderboard. These findings demonstrate the suitability of deep segmentation networks for seismic velocity inversion and underscore the value of tailored architectural refinements in advancing geophysical AI models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ°éœ‡é€Ÿåº¦åæ¼” (Seismic velocity inversion) ä»»åŠ¡ï¼Œæ—¨åœ¨åˆ©ç”¨æ·±åº¦åˆ†å‰²ç½‘ç»œä»å¤šæºç‚®é›†æ•°æ®ä¸­é‡å»ºåœ°ä¸‹ç»“æ„ï¼Œä»¥å…‹æœä¼ ç»Ÿå…¨æ³¢å½¢åæ¼” (Full Waveform Inversion, FWI) è®¡ç®—å¼€é”€å¤§ä¸”å¯¹åˆå§‹åŒ–æ•æ„Ÿçš„å±€é™ã€‚ç ”ç©¶äººå‘˜åœ¨ ThinkOnward 2025 Speed & Structure æ•°æ®é›†ä¸ŠåŸºå‡†æµ‹è¯•äº† U-Netã€U-Net++ã€DeepLabV3+ ä»¥åŠä¼˜åŒ–çš„å˜ä½“ SeismoLabV3+ï¼Œå…¶ä¸­ SeismoLabV3+ é›†æˆäº† ResNeXt50 32x4d éª¨å¹²ç½‘ç»œå¹¶è¿›è¡Œäº†ä»»åŠ¡ç‰¹å®šçš„ä¿®æ”¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSeismoLabV3+ è¡¨ç°æœ€ä¸ºå‡ºè‰²ï¼Œåœ¨éšè—æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº† 0.031246 çš„å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (MAPE)ã€‚è¿™ä¸€å‘ç°å……åˆ†è¯æ˜äº†æ·±åº¦åˆ†å‰²ç½‘ç»œåœ¨å¤„ç†åœ°éœ‡é€Ÿåº¦åæ¼”è¿™ç±»å¯†é›†é¢„æµ‹ä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ã€‚è¯¥é¡¹å·¥ä½œè¿›ä¸€æ­¥å¼ºè°ƒäº†é’ˆå¯¹åœ°çƒç‰©ç†äººå·¥æ™ºèƒ½æ¨¡å‹è¿›è¡Œç‰¹å®šæ¶æ„ä¼˜åŒ–çš„é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.21331v1",
      "published_date": "2025-09-07 14:41:39 UTC",
      "updated_date": "2025-09-07 14:41:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:17.287836+00:00"
    },
    {
      "arxiv_id": "2509.07027v3",
      "title": "Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models",
      "title_zh": "åŸºäºçŸ©ä¸åŠŸç‡è°±çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹é«˜æ–¯æ€§æ­£åˆ™åŒ–",
      "authors": [
        "Jisung Hwang",
        "Jaihoon Kim",
        "Minhyuk Sung"
      ],
      "abstract": "We propose a novel regularization loss that enforces standard Gaussianity, encouraging samples to align with a standard Gaussian distribution. This facilitates a range of downstream tasks involving optimization in the latent space of text-to-image models. We treat elements of a high-dimensional sample as one-dimensional standard Gaussian variables and define a composite loss that combines moment-based regularization in the spatial domain with power spectrum-based regularization in the spectral domain. Since the expected values of moments and power spectrum distributions are analytically known, the loss promotes conformity to these properties. To ensure permutation invariance, the losses are applied to randomly permuted inputs. Notably, existing Gaussianity-based regularizations fall within our unified framework: some correspond to moment losses of specific orders, while the previous covariance-matching loss is equivalent to our spectral loss but incurs higher time complexity due to its spatial-domain computation. We showcase the application of our regularization in generative modeling for test-time reward alignment with a text-to-image model, specifically to enhance aesthetics and text alignment. Our regularization outperforms previous Gaussianity regularization, effectively prevents reward hacking and accelerates convergence.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Momentï¼ˆçŸ©ï¼‰å’Œ Power Spectrumï¼ˆåŠŸç‡è°±ï¼‰çš„æ–°å‹ Gaussianityï¼ˆé«˜æ–¯æ€§ï¼‰æ­£åˆ™åŒ–æŸå¤±ï¼Œæ—¨åœ¨å¼ºåˆ¶æ ·æœ¬ç¬¦åˆæ ‡å‡† Gaussian åˆ†å¸ƒï¼Œä»¥ä¼˜åŒ–æ–‡ç”Ÿå›¾æ¨¡å‹çš„éšç©ºé—´é‡‡æ ·ã€‚è¯¥æ–¹æ³•å°†é«˜ç»´æ ·æœ¬å…ƒç´ è§†ä¸ºä¸€ç»´æ ‡å‡† Gaussian å˜é‡ï¼Œé€šè¿‡ç»“åˆç©ºé—´åŸŸçš„çŸ©æ­£åˆ™åŒ–ä¸é¢‘åŸŸçš„åŠŸç‡è°±æ­£åˆ™åŒ–ï¼Œåˆ©ç”¨è§£æå·²çŸ¥çš„ç»Ÿè®¡æœŸæœ›å€¼æ¥å¼•å¯¼æ¨¡å‹ç¬¦åˆç›®æ ‡åˆ†å¸ƒã€‚ä¸ºäº†ç¡®ä¿ Permutation Invarianceï¼ˆç½®æ¢ä¸å˜æ€§ï¼‰ï¼Œç ”ç©¶è€…å°†æŸå¤±åº”ç”¨äºéšæœºç½®æ¢çš„è¾“å…¥ï¼Œå¹¶è¯æ˜äº†ç°æœ‰æ­£åˆ™åŒ–æ–¹æ³•å‡å¯çº³å…¥è¯¥ç»Ÿä¸€æ¡†æ¶ã€‚åœ¨æµ‹è¯•æ—¶ Reward Alignmentï¼ˆå¥–åŠ±å¯¹é½ï¼‰çš„åº”ç”¨åœºæ™¯ä¸­ï¼Œè¯¥æ­£åˆ™åŒ–æ˜¾è‘—æå‡äº†å›¾åƒçš„ç¾å­¦è´¨é‡å’Œ Text Alignmentï¼ˆæ–‡æœ¬å¯¹é½ï¼‰æ•ˆæœã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”ä»¥å¾€æŠ€æœ¯èƒ½æ›´æœ‰æ•ˆåœ°é˜²æ­¢ Reward Hackingï¼ˆå¥–åŠ±ä½œå¼Šï¼‰ï¼Œå¹¶æ˜¾è‘—åŠ å¿«äº†æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.07027v3",
      "published_date": "2025-09-07 14:22:01 UTC",
      "updated_date": "2025-09-18 15:35:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:12.654251+00:00"
    },
    {
      "arxiv_id": "2509.06060v1",
      "title": "ARIES: Relation Assessment and Model Recommendation for Deep Time Series Forecasting",
      "title_zh": "ARIESï¼šé¢å‘æ·±åº¦æ—¶é—´åºåˆ—é¢„æµ‹çš„å…³ç³»è¯„ä¼°ä¸æ¨¡å‹æ¨è",
      "authors": [
        "Fei Wang",
        "Yujie Li",
        "Zezhi Shao",
        "Chengqing Yu",
        "Yisong Fu",
        "Zhulin An",
        "Yongjun Xu",
        "Xueqi Cheng"
      ],
      "abstract": "Recent advancements in deep learning models for time series forecasting have been significant. These models often leverage fundamental time series properties such as seasonality and non-stationarity, which may suggest an intrinsic link between model performance and data properties. However, existing benchmark datasets fail to offer diverse and well-defined temporal patterns, restricting the systematic evaluation of such connections. Additionally, there is no effective model recommendation approach, leading to high time and cost expenditures when testing different architectures across different downstream applications. For those reasons, we propose ARIES, a framework for assessing relation between time series properties and modeling strategies, and for recommending deep forcasting models for realistic time series. First, we construct a synthetic dataset with multiple distinct patterns, and design a comprehensive system to compute the properties of time series. Next, we conduct an extensive benchmarking of over 50 forecasting models, and establish the relationship between time series properties and modeling strategies. Our experimental results reveal a clear correlation. Based on these findings, we propose the first deep forecasting model recommender, capable of providing interpretable suggestions for real-world time series. In summary, ARIES is the first study to establish the relations between the properties of time series data and modeling strategies, while also implementing a model recommendation system. The code is available at: https://github.com/blisky-li/ARIES.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ARIES æ¡†æ¶ï¼Œæ—¨åœ¨è¯„ä¼°æ—¶é—´åºåˆ—å±æ€§ä¸å»ºæ¨¡ç­–ç•¥ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ä¸ºæ·±åº¦æ—¶é—´åºåˆ—é¢„æµ‹ (Deep Time Series Forecasting) æä¾›æ¨¡å‹æ¨èã€‚ä¸ºè§£å†³ç°æœ‰åŸºå‡†æ•°æ®é›†ç¼ºä¹å¤šæ ·åŒ–æ—¶é—´æ¨¡å¼çš„é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿé¦–å…ˆæ„å»ºäº†ä¸€ä¸ªåŒ…å«å¤šç§ç‹¬ç‰¹æ¨¡å¼çš„åˆæˆæ•°æ®é›†ï¼Œå¹¶è®¾è®¡äº†ä¸€å¥—ç”¨äºè®¡ç®—æ—¶é—´åºåˆ—å±æ€§çš„ç»¼åˆç³»ç»Ÿã€‚é€šè¿‡å¯¹è¶…è¿‡ 50 ç§é¢„æµ‹æ¨¡å‹è¿›è¡Œå¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ï¼Œè¯¥æ¡†æ¶æˆåŠŸå»ºç«‹äº†æ—¶é—´åºåˆ—å±æ€§ä¸ä¸åŒå»ºæ¨¡ç­–ç•¥ä¹‹é—´çš„å…³è”ã€‚å®éªŒç»“æœæ­ç¤ºäº†æ•°æ®å±æ€§ä¸æ¨¡å‹è¡¨ç°ä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„å…³è”æ€§ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œç ”ç©¶è€…å¼€å‘äº†é¦–ä¸ªæ·±åº¦é¢„æµ‹æ¨¡å‹æ¨èç³»ç»Ÿï¼Œèƒ½å¤Ÿä¸ºç°å®ä¸–ç•Œçš„æ—¶é—´åºåˆ—æ•°æ®æä¾›å…·æœ‰å¯è§£é‡Šæ€§çš„å»ºè®®ã€‚ARIES ä½œä¸ºé¦–ä¸ªç¡®ç«‹æ•°æ®å±æ€§ä¸å»ºæ¨¡ç­–ç•¥å…³ç³»çš„ç ”ç©¶ï¼Œæœ‰æ•ˆé™ä½äº†åœ¨ä¸åŒåº”ç”¨åœºæ™¯ä¸­é€‰æ‹©æœ€ä¼˜æ¨¡å‹æ¶æ„çš„æ—¶é—´ä¸æˆæœ¬ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06060v1",
      "published_date": "2025-09-07 13:57:14 UTC",
      "updated_date": "2025-09-07 13:57:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:04.669642+00:00"
    },
    {
      "arxiv_id": "2509.07026v1",
      "title": "Contradictions",
      "title_zh": "çŸ›ç›¾",
      "authors": [
        "Yang Xu",
        "Shuwei Chen",
        "Xiaomei Zhong",
        "Jun Liu",
        "Xingxing He"
      ],
      "abstract": "Trustworthy AI requires reasoning systems that are not only powerful but also transparent and reliable. Automated Theorem Proving (ATP) is central to formal reasoning, yet classical binary resolution remains limited, as each step involves only two clauses and eliminates at most two literals. To overcome this bottleneck, the concept of standard contradiction and the theory of contradiction-separation-based deduction were introduced in 2018. This paper advances that framework by focusing on the systematic construction of standard contradictions. Specially, this study investigates construction methods for two principal forms of standard contradiction: the maximum triangular standard contradiction and the triangular-type standard contradiction. Building on these structures, we propose a procedure for determining the satisfiability and unsatisfiability of clause sets via maximum standard contradiction. Furthermore, we derive formulas for computing the number of standard sub-contradictions embedded within both the maximum triangular standard contradiction and the triangular-type standard contradiction. The results presented herein furnish the methodological basis for advancing contradiction-separation-based dynamic multi-clause automated deduction, thereby extending the expressive and deductive capabilities of automated reasoning systems beyond the classical binary paradigm.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯ä¿¡äººå·¥æ™ºèƒ½(Trustworthy AI)å¯¹æ¨ç†ç³»ç»Ÿé€æ˜åº¦å’Œå¯é æ€§çš„è¦æ±‚ï¼Œæ¢è®¨äº†è‡ªåŠ¨å®šç†è¯æ˜(Automated Theorem Proving, ATP)ä¸­ç»å…¸äºŒè¿›åˆ¶å½’ç»“(Binary Resolution)å¤„ç†èƒ½åŠ›çš„å±€é™æ€§ã€‚ä¸ºçªç ´æ¯ä¸€æ­¥ä»…èƒ½æ¶ˆé™¤æœ‰é™æ–‡å­—çš„ç“¶é¢ˆï¼Œè®ºæ–‡è¿›ä¸€æ­¥å‘å±•äº†æ ‡å‡†çŸ›ç›¾(Standard Contradiction)æ¦‚å¿µåŠåŸºäºçŸ›ç›¾åˆ†ç¦»çš„æ¼”ç»(Contradiction-separation-based Deduction)ç†è®ºã€‚æœ¬ç ”ç©¶é‡ç‚¹æ¢è®¨äº†æå¤§ä¸‰è§’å½¢æ ‡å‡†çŸ›ç›¾(Maximum Triangular Standard Contradiction)å’Œä¸‰è§’å½¢ç±»æ ‡å‡†çŸ›ç›¾(Triangular-type Standard Contradiction)çš„ç³»ç»Ÿæ„å»ºæ–¹æ³•ã€‚åŸºäºè¿™äº›ç»“æ„ï¼Œè®ºæ–‡æå‡ºäº†ä¸€å¥—åˆ¤å®šå­å¥é›†å¯æ»¡è¶³æ€§(Satisfiability)ä¸ä¸å¯æ»¡è¶³æ€§(Unsatisfiability)çš„æ–°ç¨‹åºï¼Œå¹¶æ¨å¯¼å‡ºäº†è®¡ç®—å…¶ä¸­æ ‡å‡†å­çŸ›ç›¾(Standard Sub-contradictions)æ•°é‡çš„å…¬å¼ã€‚è¿™ä¸€æˆæœä¸ºæ¨è¿›åŠ¨æ€å¤šå­å¥è‡ªåŠ¨æ¼”ç»æä¾›äº†æ–¹æ³•è®ºåŸºç¡€ï¼Œæ˜¾è‘—æ‰©å±•äº†è‡ªåŠ¨æ¨ç†ç³»ç»Ÿè¶…è¶Šç»å…¸äºŒè¿›åˆ¶èŒƒå¼çš„è¡¨è¾¾å’Œæ¼”ç»èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "37 Pages,9 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.07026v1",
      "published_date": "2025-09-07 13:47:51 UTC",
      "updated_date": "2025-09-07 13:47:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:02.070017+00:00"
    },
    {
      "arxiv_id": "2510.21712v1",
      "title": "DecoupleSearch: Decouple Planning and Search via Hierarchical Reward Modeling",
      "title_zh": "DecoupleSearchï¼šåŸºäºåˆ†å±‚å¥–åŠ±å»ºæ¨¡çš„è§„åˆ’ä¸æœç´¢è§£è€¦",
      "authors": [
        "Hao Sun",
        "Zile Qiao",
        "Bo Wang",
        "Guoxin Chen",
        "Yingyan Hou",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Yan Zhang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems have emerged as a pivotal methodology for enhancing Large Language Models (LLMs) through the dynamic integration of external knowledge. To further improve RAG's flexibility, Agentic RAG introduces autonomous agents into the workflow. However, Agentic RAG faces several challenges: (1) the success of each step depends on both high-quality planning and accurate search, (2) the lack of supervision for intermediate reasoning steps, and (3) the exponentially large candidate space for planning and searching. To address these challenges, we propose DecoupleSearch, a novel framework that decouples planning and search processes using dual value models, enabling independent optimization of plan reasoning and search grounding. Our approach constructs a reasoning tree, where each node represents planning and search steps. We leverage Monte Carlo Tree Search to assess the quality of each step. During inference, Hierarchical Beam Search iteratively refines planning and search candidates with dual value models. Extensive experiments across policy models of varying parameter sizes, demonstrate the effectiveness of our method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ™ºèƒ½ä½“åŒ–æ£€ç´¢å¢å¼ºç”Ÿæˆ (Agentic RAG) ç³»ç»Ÿä¸­è§„åˆ’ä¸æœç´¢ç›¸äº’ä¾èµ–ã€ä¸­é—´æ¨ç†ç¼ºä¹ç›‘ç£ä»¥åŠå€™é€‰ç©ºé—´å·¨å¤§ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº† DecoupleSearch æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åŒä»·å€¼æ¨¡å‹ (dual value models) å°†è§„åˆ’ (planning) ä¸æœç´¢ (search) è¿‡ç¨‹è§£è€¦ï¼Œä»è€Œå®ç°äº†è®¡åˆ’æ¨ç†ä¸æœç´¢è½åœ°çš„ç‹¬ç«‹ä¼˜åŒ–ã€‚ç³»ç»Ÿæ„å»ºäº†ä¸€ä¸ªæ¨ç†æ ‘ (reasoning tree) æ¥è¡¨ç¤ºæ­¥éª¤ï¼Œå¹¶åˆ©ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢ (Monte Carlo Tree Search) è¯„ä¼°æ¯ä¸€æ­¥çš„è´¨é‡ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œé€šè¿‡åˆ†å±‚é›†æŸæœç´¢ (Hierarchical Beam Search) ç»“åˆåŒä»·å€¼æ¨¡å‹ï¼Œå¯¹è§„åˆ’å’Œæœç´¢çš„å€™é€‰é¡¹è¿›è¡Œè¿­ä»£ç²¾ç‚¼ã€‚åœ¨ä¸åŒå‚æ•°è§„æ¨¡çš„ç­–ç•¥æ¨¡å‹ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æ˜¾è‘—æå‡ç³»ç»Ÿçš„æ€§èƒ½ï¼Œä¸ºä¼˜åŒ–å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„çŸ¥è¯†é›†æˆæä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "EMNLP 2025 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2510.21712v1",
      "published_date": "2025-09-07 13:45:09 UTC",
      "updated_date": "2025-09-07 13:45:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:08.965575+00:00"
    },
    {
      "arxiv_id": "2509.06053v1",
      "title": "PolicyEvolve: Evolving Programmatic Policies by LLMs for multi-player games via Population-Based Training",
      "title_zh": "PolicyEvolveï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹ä¸ç§ç¾¤è®­ç»ƒçš„å¤šäººæ¸¸æˆç¨‹åºåŒ–ç­–ç•¥è¿›åŒ–",
      "authors": [
        "Mingrui Lv",
        "Hangzhi Liu",
        "Zhi Luo",
        "Hongjie Zhang",
        "Jie Ou"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) has achieved significant progress in solving complex multi-player games through self-play. However, training effective adversarial policies requires millions of experience samples and substantial computational resources. Moreover, these policies lack interpretability, hindering their practical deployment. Recently, researchers have successfully leveraged Large Language Models (LLMs) to generate programmatic policies for single-agent tasks, transforming neural network-based policies into interpretable rule-based code with high execution efficiency. Inspired by this, we propose PolicyEvolve, a general framework for generating programmatic policies in multi-player games. PolicyEvolve significantly reduces reliance on manually crafted policy code, achieving high-performance policies with minimal environmental interactions. The framework comprises four modules: Global Pool, Local Pool, Policy Planner, and Trajectory Critic. The Global Pool preserves elite policies accumulated during iterative training. The Local Pool stores temporary policies for the current iteration; only sufficiently high-performing policies from this pool are promoted to the Global Pool. The Policy Planner serves as the core policy generation module. It samples the top three policies from the Global Pool, generates an initial policy for the current iteration based on environmental information, and refines this policy using feedback from the Trajectory Critic. Refined policies are then deposited into the Local Pool. This iterative process continues until the policy achieves a sufficiently high average win rate against the Global Pool, at which point it is integrated into the Global Pool. The Trajectory Critic analyzes interaction data from the current policy, identifies vulnerabilities, and proposes directional improvements to guide the Policy Planner",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PolicyEvolveï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨ Large Language Models (LLMs) ä¸ºå¤šäººæ¸¸æˆç”Ÿæˆç¨‹åºåŒ–ç­–ç•¥ (programmatic policies) çš„é€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ Multi-agent reinforcement learning (MARL) åœ¨è®­ç»ƒæ•ˆç‡å’Œå¯è§£é‡Šæ€§æ–¹é¢çš„å±€é™ã€‚è¯¥æ¡†æ¶é€šè¿‡ Population-Based Training çš„æ€è·¯ï¼Œå°†ä¼ ç»Ÿçš„ç­–ç•¥æ¨¡å‹è½¬åŒ–ä¸ºé«˜æ•ˆä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„è§„åˆ™ä»£ç ã€‚PolicyEvolve ç”± Global Poolã€Local Poolã€Policy Planner å’Œ Trajectory Critic å››ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼Œé€šè¿‡ç²¾è‹±ç­–ç•¥çš„ç§¯ç´¯ä¸ä¸´æ—¶ç­–ç•¥çš„ç­›é€‰å®ç°å¾ªç¯æ¼”åŒ–ã€‚å…¶ä¸­ï¼ŒPolicy Planner ç»“åˆç¯å¢ƒä¿¡æ¯ä¸å†å²ç²¾è‹±ç­–ç•¥ç”Ÿæˆåˆå§‹æ–¹æ¡ˆï¼Œè€Œ Trajectory Critic åˆ™é€šè¿‡åˆ†æäº¤äº’æ•°æ®è¯†åˆ«æ¼æ´å¹¶æä¾›å®šå‘æ”¹è¿›å»ºè®®ã€‚ç­–ç•¥åœ¨åé¦ˆæœºåˆ¶ä¸‹ä¸æ–­ä¼˜åŒ–ï¼Œç›´è‡³å…¶é’ˆå¯¹ Global Pool çš„å¹³å‡èƒœç‡è¾¾æ ‡åå®Œæˆæ™‹å‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPolicyEvolve æ˜¾è‘—å‡å°‘äº†å¯¹äººå·¥ç­–ç•¥ä»£ç çš„ä¾èµ–ï¼Œèƒ½ä»¥æå°‘çš„ç¯å¢ƒäº¤äº’å®ç°é«˜æ€§èƒ½ç­–ç•¥ï¼Œä¸ºå¤æ‚åšå¼ˆä»»åŠ¡ä¸­çš„æ™ºèƒ½ä½“æ¼”åŒ–æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06053v1",
      "published_date": "2025-09-07 13:33:31 UTC",
      "updated_date": "2025-09-07 13:33:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:18.163447+00:00"
    },
    {
      "arxiv_id": "2509.06052v1",
      "title": "Empirical Study of Code Large Language Models for Binary Security Patch Detection",
      "title_zh": "ä»£ç å¤§è¯­è¨€æ¨¡å‹åœ¨äºŒè¿›åˆ¶å®‰å…¨è¡¥ä¸æ£€æµ‹ä¸­çš„å®è¯ç ”ç©¶",
      "authors": [
        "Qingyuan Li",
        "Binchang Li",
        "Cuiyun Gao",
        "Shuzheng Gao",
        "Zongjie Li"
      ],
      "abstract": "Security patch detection (SPD) is crucial for maintaining software security, as unpatched vulnerabilities can lead to severe security risks. In recent years, numerous learning-based SPD approaches have demonstrated promising results on source code. However, these approaches typically cannot be applied to closed-source applications and proprietary systems that constitute a significant portion of real-world software, as they release patches only with binary files, and the source code is inaccessible. Given the impressive performance of code large language models (LLMs) in code intelligence and binary analysis tasks such as decompilation and compilation optimization, their potential for detecting binary security patches remains unexplored, exposing a significant research gap between their demonstrated low-level code understanding capabilities and this critical security task. To address this gap, we construct a large-scale binary patch dataset containing \\textbf{19,448} samples, with two levels of representation: assembly code and pseudo-code, and systematically evaluate \\textbf{19} code LLMs of varying scales to investigate their capability in binary SPD tasks. Our initial exploration demonstrates that directly prompting vanilla code LLMs struggles to accurately identify security patches from binary patches, and even state-of-the-art prompting techniques fail to mitigate the lack of domain knowledge in binary SPD within vanilla models. Drawing on the initial findings, we further investigate the fine-tuning strategy for injecting binary SPD domain knowledge into code LLMs through two levels of representation. Experimental results demonstrate that fine-tuned LLMs achieve outstanding performance, with the best results obtained on the pseudo-code representation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é—­æºè½¯ä»¶å’Œä¸“æœ‰ç³»ç»Ÿä¸­äºŒè¿›åˆ¶å®‰å…¨è¡¥ä¸æ£€æµ‹(Security patch detection, SPD)çš„ç´§è¿«æ€§ï¼Œæ¢è®¨äº†ä»£ç å¤§è¯­è¨€æ¨¡å‹(Code LLMs)åœ¨å¤„ç†æ­¤ç±»å…³é”®å®‰å…¨ä»»åŠ¡æ—¶çš„æ½œåŠ›ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å«19,448ä¸ªæ ·æœ¬çš„å¤§è§„æ¨¡äºŒè¿›åˆ¶è¡¥ä¸æ•°æ®é›†ï¼Œæ¶µç›–æ±‡ç¼–ä»£ç (assembly code)å’Œä¼ªä»£ç (pseudo-code)ä¸¤ç§è¡¨ç¤ºå½¢å¼ã€‚é€šè¿‡å¯¹19ä¸ªä¸åŒè§„æ¨¡çš„ä»£ç å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç³»ç»Ÿè¯„ä¼°ï¼Œç ”ç©¶å‘ç°ç›´æ¥ä½¿ç”¨æç¤º(prompting)æŠ€æœ¯éš¾ä»¥è®©åŸå§‹æ¨¡å‹å‡†ç¡®è¯†åˆ«è¡¥ä¸ï¼Œåæ˜ å‡ºæ¨¡å‹åœ¨äºŒè¿›åˆ¶SPDé¢†åŸŸçŸ¥è¯†æ–¹é¢çš„å±€é™æ€§ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶è¿›ä¸€æ­¥æ¢ç´¢äº†å¾®è°ƒ(fine-tuning)ç­–ç•¥ï¼Œæ—¨åœ¨å‘æ¨¡å‹æ³¨å…¥ç‰¹å®šçš„é¢†åŸŸçŸ¥è¯†ã€‚å®éªŒç»“æœè¯æ˜ï¼Œç»è¿‡å¾®è°ƒçš„ä»£ç å¤§è¯­è¨€æ¨¡å‹åœ¨äºŒè¿›åˆ¶SPDä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨ä¼ªä»£ç è¡¨ç¤ºå½¢å¼ä¸‹è¾¾åˆ°äº†æœ€ä½³æ£€æµ‹æ•ˆæœã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06052v1",
      "published_date": "2025-09-07 13:31:43 UTC",
      "updated_date": "2025-09-07 13:31:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:24.053248+00:00"
    },
    {
      "arxiv_id": "2509.07025v1",
      "title": "1 bit is all we need: binary normalized neural networks",
      "title_zh": "1 æ¯”ç‰¹è¶³çŸ£ï¼šäºŒå€¼å½’ä¸€åŒ–ç¥ç»ç½‘ç»œ",
      "authors": [
        "Eduardo Lobo Lustoda Cabral",
        "Paulo Pirozelli",
        "Larissa Driemeier"
      ],
      "abstract": "The increasing size of large neural network models, specifically language models and foundational image models, poses deployment challenges, prompting efforts to reduce memory requirements and enhance computational efficiency. These efforts are critical to ensure practical deployment and effective utilization of these models across various applications. In this work, a novel type of neural network layers and models is developed that uses only single-bit parameters. In this novel type of models all parameters of all layers, including kernel weights and biases, only have values equal to zero or one. This novel type of models uses layers named as binary normalized layer. These binary normalized layers can be of any type, such as fully connected, convolutional, attention, etc., and they consist of slight variations of the corresponding conventional layers. To show the effectiveness of the binary normalized layers, two different models are configured to solve a multiclass image classification problem and a language decoder to predict the next token of a sequence. The model to solve the image classification has convolutional and fully connected layers, and the language model is composed of transformer blocks with multi-head attention. The results show that models with binary normalized layers present almost the same results obtained by equivalent models with real 32-bit parameters. The binary normalized layers allow to develop models that use 32 times less memory than current models and have equivalent performance. Besides, the binary normalized layers can be easily implemented on current computers using 1-bit arrays, and do not require the development of dedicated electronic hardware. This novel type of layers opens a new era for large neural network models with reduced memory requirements that can be deployed using simple and cheap hardware, such as mobile devices or only cpus.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º binary normalized neural networks çš„æ–°å‹ç¥ç»ç½‘ç»œï¼Œå…¶æ‰€æœ‰å±‚ï¼ˆåŒ…æ‹¬æƒé‡å’Œåç½®ï¼‰çš„å‚æ•°å‡ä»…ä½¿ç”¨ single-bitï¼ˆ0 æˆ– 1ï¼‰ã€‚è¿™ç§æ¶æ„é€šè¿‡å¼•å…¥ binary normalized layersï¼Œå¯ä»¥çµæ´»åº”ç”¨äº fully connectedã€convolutional åŠ attention ç­‰å¤šç§æ¨¡å‹ç»„ä»¶ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡å’Œ language decoder åºåˆ—é¢„æµ‹ä¸­ï¼Œè¯¥æ¨¡å‹çš„æ€§èƒ½ä¸ä¼ ç»Ÿçš„ 32-bit æ¨¡å‹å‡ ä¹ç›¸å½“ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºèƒ½å°†å†…å­˜éœ€æ±‚é™ä½ 32 å€ï¼Œä¸”æ— éœ€ä¸“é—¨çš„ç”µå­ç¡¬ä»¶å³å¯åœ¨å½“å‰è®¡ç®—æœºã€CPU æˆ–ç§»åŠ¨è®¾å¤‡ä¸Šé€šè¿‡ 1-bit arrays è½»æ¾å®ç°ã€‚è¿™ä¸€æˆæœä¸ºå¤§è§„æ¨¡æ¨¡å‹åœ¨ä½æˆæœ¬ç¡¬ä»¶ä¸Šçš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†æ–°æ–¹æ¡ˆï¼Œå¼€å¯äº†è½»é‡åŒ–ç¥ç»ç½‘ç»œæ¨¡å‹çš„æ–°çºªå…ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages; 2 figures; 5 tables; 8 algorithms",
      "pdf_url": "https://arxiv.org/pdf/2509.07025v1",
      "published_date": "2025-09-07 13:27:15 UTC",
      "updated_date": "2025-09-07 13:27:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:33.966112+00:00"
    },
    {
      "arxiv_id": "2509.06040v5",
      "title": "BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models",
      "title_zh": "BranchGRPOï¼šåŸºäºç»“æ„åŒ–åˆ†æ”¯çš„æ‰©æ•£æ¨¡å‹ç¨³å®šé«˜æ•ˆ GRPO",
      "authors": [
        "Yuming Li",
        "Yikai Wang",
        "Yuying Zhu",
        "Zhongyu Zhao",
        "Ming Lu",
        "Qi She",
        "Shanghang Zhang"
      ],
      "abstract": "Recent progress in aligning image and video generative models with Group Relative Policy Optimization (GRPO) has improved human preference alignment, but existing variants remain inefficient due to sequential rollouts and large numbers of sampling steps, unreliable credit assignment: sparse terminal rewards are uniformly propagated across timesteps, failing to capture the varying criticality of decisions during denoising. In this paper, we present BranchGRPO, a method that restructures the rollout process into a branching tree, where shared prefixes amortize computation and pruning removes low-value paths and redundant depths. BranchGRPO introduces three contributions: (1) a branching scheme that amortizes rollout cost through shared prefixes while preserving exploration diversity; (2) a reward fusion and depth-wise advantage estimator that transforms sparse terminal rewards into dense step-level signals; and (3) pruning strategies that cut gradient computation but leave forward rollouts and exploration unaffected. On HPDv2.1 image alignment, BranchGRPO improves alignment scores by up to \\textbf{16\\%} over DanceGRPO, while reducing per-iteration training time by nearly \\textbf{55\\%}. A hybrid variant, BranchGRPO-Mix, further accelerates training to 4.7x faster than DanceGRPO without degrading alignment. On WanX video generation, it further achieves higher Video-Align scores with sharper and temporally consistent frames compared to DanceGRPO. Codes are available at \\href{https://fredreic1849.github.io/BranchGRPO-Webpage/}{BranchGRPO}.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹(Diffusion Models)åœ¨äººç±»åå¥½å¯¹é½ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œæå‡ºäº†BranchGRPOï¼Œæ—¨åœ¨è§£å†³Group Relative Policy Optimization (GRPO) åœ¨é¡ºåºé‡‡æ ·æ—¶çš„é«˜å»¶è¿Ÿä»¥åŠç¨€ç–ç»ˆç«¯å¥–åŠ±å¯¼è‡´çš„ä¿¡ç”¨åˆ†é…(credit assignment)ä¸å¯é ç­‰æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†rolloutè¿‡ç¨‹é‡æ„ä¸ºåˆ†æ”¯æ ‘(branching tree)ç»“æ„ï¼Œåˆ©ç”¨å…±äº«å‰ç¼€(shared prefixes)åˆ†æ‘Šè®¡ç®—æˆæœ¬ï¼Œåœ¨ä¿æŒæ¢ç´¢å¤šæ ·æ€§çš„åŒæ—¶æ˜¾è‘—æå‡äº†æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒBranchGRPOå¼•å…¥äº†å¥–åŠ±èåˆä¸æ·±åº¦ä¼˜åŠ¿ä¼°è®¡å™¨(depth-wise advantage estimator)ï¼Œå°†ç¨€ç–çš„ç»ˆç«¯å¥–åŠ±è½¬åŒ–ä¸ºç¨ å¯†çš„æ­¥çº§ä¿¡å·(step-level signals)ï¼Œä»è€Œç²¾ç¡®æ•æ‰å»å™ªè¿‡ç¨‹ä¸­ä¸åŒé˜¶æ®µçš„å†³ç­–å…³é”®æ€§ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†ä¿®å‰ªç­–ç•¥(pruning strategies)æ¥å‰Šå‡æ¢¯åº¦è®¡ç®—ï¼Œä¸”ä¸å½±å“å‰å‘rolloutå’Œæ¢ç´¢è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨HPDv2.1å›¾åƒå¯¹é½ä»»åŠ¡ä¸Šï¼ŒBranchGRPOç›¸è¾ƒäºDanceGRPOä¸ä»…å°†å¯¹é½è¯„åˆ†æå‡äº†16%ï¼Œè¿˜å°†å•æ¬¡è¿­ä»£è®­ç»ƒæ—¶é—´ç¼©çŸ­äº†è¿‘55%ã€‚å…¶æ··åˆå˜ä½“BranchGRPO-Mixåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å®ç°äº†æ¯”DanceGRPOå¿«4.7å€çš„è®­ç»ƒé€Ÿåº¦ï¼Œå¹¶åœ¨WanXè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸­å±•ç°äº†æ›´é«˜çš„Video-Alignè¯„åˆ†ä»¥åŠæ›´ä¼˜çš„è§†è§‰ä¸€è‡´æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06040v5",
      "published_date": "2025-09-07 12:53:06 UTC",
      "updated_date": "2025-09-29 13:20:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:48.267306+00:00"
    },
    {
      "arxiv_id": "2509.06035v9",
      "title": "TinyDef-DETR: A Transformer-Based Framework for Defect Detection in Transmission Lines from UAV Imagery",
      "title_zh": "TinyDef-DETRï¼šä¸€ç§åŸºäº Transformer çš„æ— äººæœºå½±åƒè¾“ç”µçº¿è·¯ç¼ºé™·æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Feng Shen",
        "Jiaming Cui",
        "Wenqiang Li",
        "Shuai Zhou"
      ],
      "abstract": "Automated defect detection from UAV imagery of transmission lines is a challenging task due to the small size, ambiguity, and complex backgrounds of defects. This paper proposes TinyDef-DETR, a DETR-based framework designed to achieve accurate and efficient detection of transmission line defects from UAV-acquired images. The model integrates four major components: an edge-enhanced ResNet backbone to strengthen boundary-sensitive representations, a stride-free space-to-depth module to enable detail-preserving downsampling, a cross-stage dual-domain multi-scale attention mechanism to jointly model global context and local cues, and a Focaler-Wise-SIoU regression loss to improve the localization of small and difficult objects. Together, these designs effectively mitigate the limitations of conventional detectors. Extensive experiments on both public and real-world datasets demonstrate that TinyDef-DETR achieves superior detection performance and strong generalization capability, while maintaining modest computational overhead. The accuracy and efficiency of TinyDef-DETR make it a suitable method for UAV-based transmission line defect detection, particularly in scenarios involving small and ambiguous objects.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TinyDef-DETRï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº DETR çš„ Transformer æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ— äººæœº UAV è¾“ç”µçº¿è·¯å›¾åƒä¸­ç¼ºé™·ç›®æ ‡å¾®å°ã€æ¨¡ç³Šä¸”èƒŒæ™¯å¤æ‚çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹é›†æˆäº†å››é¡¹æ ¸å¿ƒè®¾è®¡ï¼šé€šè¿‡ edge-enhanced ResNet ä¸»å¹²ç½‘ç»œå¢å¼ºè¾¹ç•Œæ•æ„Ÿç‰¹å¾ï¼Œåˆ©ç”¨ stride-free space-to-depth æ¨¡å—å®ç°ä¿ç•™ç»†èŠ‚çš„ä¸‹é‡‡æ ·ï¼Œå¼•å…¥ cross-stage dual-domain multi-scale attention æœºåˆ¶å…±åŒå»ºæ¨¡å…¨å±€ä¸Šä¸‹æ–‡ä¸å±€éƒ¨çº¿ç´¢ï¼Œå¹¶é‡‡ç”¨ Focaler-Wise-SIoU å›å½’æŸå¤±æå‡å¯¹å¾®å°åŠå›°éš¾ç›®æ ‡çš„å®šä½ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTinyDef-DETR åœ¨å…¬å¼€å’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡å±•ç°å‡ºå“è¶Šçš„æ£€æµ‹æ€§èƒ½ä¸å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒä½çš„è®¡ç®—å¼€é”€ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆåœ°å…‹æœäº†ä¼ ç»Ÿæ£€æµ‹å™¨çš„å±€é™æ€§ï¼Œä¸º UAV è‡ªåŠ¨ç”µåŠ›å·¡æ£€ä¸­å¤„ç†å¾®å°ã€æ¨¡ç³Šç¼ºé™·æä¾›äº†é«˜æ•ˆä¸”å‡†ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06035v9",
      "published_date": "2025-09-07 12:36:33 UTC",
      "updated_date": "2025-11-13 07:30:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:52.278544+00:00"
    },
    {
      "arxiv_id": "2509.06027v1",
      "title": "DreamAudio: Customized Text-to-Audio Generation with Diffusion Models",
      "title_zh": "DreamAudioï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å®šåˆ¶åŒ–æ–‡æœ¬åˆ°éŸ³é¢‘ç”Ÿæˆ",
      "authors": [
        "Yi Yuan",
        "Xubo Liu",
        "Haohe Liu",
        "Xiyuan Kang",
        "Zhuo Chen",
        "Yuxuan Wang",
        "Mark D. Plumbley",
        "Wenwu Wang"
      ],
      "abstract": "With the development of large-scale diffusion-based and language-modeling-based generative models, impressive progress has been achieved in text-to-audio generation. Despite producing high-quality outputs, existing text-to-audio models mainly aim to generate semantically aligned sound and fall short on precisely controlling fine-grained acoustic characteristics of specific sounds. As a result, users that need specific sound content may find it challenging to generate the desired audio clips. In this paper, we present DreamAudio for customized text-to-audio generation (CTTA). Specifically, we introduce a new framework that is designed to enable the model to identify auditory information from user-provided reference concepts for audio generation. Given a few reference audio samples containing personalized audio events, our system can generate new audio samples that include these specific events. In addition, two types of datasets are developed for training and testing the customized systems. The experiments show that the proposed model, DreamAudio, generates audio samples that are highly consistent with the customized audio features and aligned well with the input text prompts. Furthermore, DreamAudio offers comparable performance in general text-to-audio tasks. We also provide a human-involved dataset containing audio events from real-world CTTA cases as the benchmark for customized generation tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DreamAudioï¼Œä¸€ç§æ—¨åœ¨å®ç°å®šåˆ¶åŒ–æ–‡æœ¬åˆ°éŸ³é¢‘ç”Ÿæˆ (Customized Text-to-Audio Generation, CTTA) çš„æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨ç²¾ç¡®æ§åˆ¶ç‰¹å®šå£°éŸ³ç»†ç²’åº¦å£°å­¦ç‰¹å¾æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥ä¸€ç§æ–°çš„æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»ç”¨æˆ·æä¾›çš„å°‘é‡å‚è€ƒéŸ³é¢‘ä¸­è¯†åˆ«å¹¶æå–ç‰¹å®šçš„å¬è§‰ä¿¡æ¯ï¼Œè¿›è€Œç”ŸæˆåŒ…å«è¿™äº›ä¸ªæ€§åŒ–éŸ³é¢‘äº‹ä»¶çš„æ–°é‡‡æ ·ã€‚ä¸ºäº†è¯„ä¼°ç³»ç»Ÿæ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸¤ç±»ä¸“é—¨çš„è®­ç»ƒä¸æµ‹è¯•æ•°æ®é›†ï¼Œå¹¶å»ºç«‹äº†ä¸€ä¸ªåŸºäºçœŸå®ä¸–ç•Œ CTTA æ¡ˆä¾‹çš„äººå·¥æ ‡æ³¨åŸºå‡†ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒDreamAudio ç”Ÿæˆçš„éŸ³é¢‘åœ¨ä¿æŒä¸å®šåˆ¶åŒ–ç‰¹å¾é«˜åº¦ä¸€è‡´çš„åŒæ—¶ï¼Œèƒ½ä¸è¾“å…¥æ–‡æœ¬æç¤ºè¯­ç²¾å‡†å¯¹é½ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨é€šç”¨æ–‡æœ¬åˆ°éŸ³é¢‘ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºäº†ä¸ç°æœ‰é¢†å…ˆæŠ€æœ¯ç›¸å½“çš„æ°´å¹³ï¼Œä¸ºé«˜è´¨é‡ã€å¯æ§çš„éŸ³é¢‘åˆæˆæä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Demos are available at https://yyua8222.github.io/DreamAudio_demopage/",
      "pdf_url": "https://arxiv.org/pdf/2509.06027v1",
      "published_date": "2025-09-07 12:06:21 UTC",
      "updated_date": "2025-09-07 12:06:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:51.399627+00:00"
    },
    {
      "arxiv_id": "2509.06026v1",
      "title": "DCMI: A Differential Calibration Membership Inference Attack Against Retrieval-Augmented Generation",
      "title_zh": "DCMIï¼šé’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆçš„å·®å¼‚åŒ–æ ¡å‡†æˆå‘˜æ¨ç†æ”»å‡»",
      "authors": [
        "Xinyu Gao",
        "Xiangtao Meng",
        "Yingkai Dong",
        "Zheng Li",
        "Shanqing Guo"
      ],
      "abstract": "While Retrieval-Augmented Generation (RAG) effectively reduces hallucinations by integrating external knowledge bases, it introduces vulnerabilities to membership inference attacks (MIAs), particularly in systems handling sensitive data. Existing MIAs targeting RAG's external databases often rely on model responses but ignore the interference of non-member-retrieved documents on RAG outputs, limiting their effectiveness. To address this, we propose DCMI, a differential calibration MIA that mitigates the negative impact of non-member-retrieved documents. Specifically, DCMI leverages the sensitivity gap between member and non-member retrieved documents under query perturbation. It generates perturbed queries for calibration to isolate the contribution of member-retrieved documents while minimizing the interference from non-member-retrieved documents. Experiments under progressively relaxed assumptions show that DCMI consistently outperforms baselines--for example, achieving 97.42% AUC and 94.35% Accuracy against the RAG system with Flan-T5, exceeding the MBA baseline by over 40%. Furthermore, on real-world RAG platforms such as Dify and MaxKB, DCMI maintains a 10%-20% advantage over the baseline. These results highlight significant privacy risks in RAG systems and emphasize the need for stronger protection mechanisms. We appeal to the community's consideration of deeper investigations, like ours, against the data leakage risks in rapidly evolving RAG systems. Our code is available at https://github.com/Xinyu140203/RAG_MIA.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ç³»ç»Ÿåœ¨å¤„ç†æ•æ„Ÿæ•°æ®æ—¶é¢ä¸´çš„æˆå‘˜æ¨ç†æ”»å‡»(Membership Inference Attacks, MIAs)é£é™©ã€‚é’ˆå¯¹ç°æœ‰æ”»å‡»æ–¹æ³•å®¹æ˜“å—éæˆå‘˜æ£€ç´¢æ–‡æ¡£å¹²æ‰°çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†DCMIï¼Œä¸€ç§åˆ©ç”¨å·®åˆ†æ ¡å‡†(Differential Calibration)æŠ€æœ¯æå‡æ”»å‡»ç²¾åº¦çš„æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡æŸ¥è¯¢æ‰°åŠ¨(Query Perturbation)æ•æ‰æˆå‘˜ä¸éæˆå‘˜æ–‡æ¡£ä¹‹é—´çš„æ•æ„Ÿåº¦å·®å¼‚ï¼Œå¹¶ç”Ÿæˆæ ¡å‡†åçš„æ‰°åŠ¨æŸ¥è¯¢ä»¥éš”ç¦»æˆå‘˜æ–‡æ¡£çš„å…·ä½“è´¡çŒ®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDCMIåœ¨åŸºäºFlan-T5çš„RAGç³»ç»Ÿä¸Šå®ç°äº†97.42%çš„AUCå’Œ94.35%çš„å‡†ç¡®ç‡ï¼Œä¸”åœ¨Difyå’ŒMaxKBç­‰çœŸå®å·¥ä¸šå¹³å°ä¸Šä¹Ÿæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†RAGæ¶æ„ä¸­å­˜åœ¨çš„ä¸¥é‡éšç§æ³„éœ²æ¼æ´ï¼Œå¹¶å¼ºè°ƒäº†åœ¨å¿«é€Ÿå‘å±•çš„RAGåº”ç”¨ä¸­å¼€å‘æ›´å¼ºæ•°æ®ä¿æŠ¤æœºåˆ¶çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06026v1",
      "published_date": "2025-09-07 11:58:02 UTC",
      "updated_date": "2025-09-07 11:58:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:59.877206+00:00"
    },
    {
      "arxiv_id": "2509.06025v1",
      "title": "Unified Interaction Foundational Model (UIFM) for Predicting Complex User and System Behavior",
      "title_zh": "ç»Ÿä¸€äº¤äº’åŸºç¡€æ¨¡å‹ (UIFM)ï¼šç”¨äºé¢„æµ‹å¤æ‚ç”¨æˆ·ä¸ç³»ç»Ÿè¡Œä¸º",
      "authors": [
        "Vignesh Ethiraj",
        "Subhash Talluri"
      ],
      "abstract": "A central goal of artificial intelligence is to build systems that can understand and predict complex, evolving sequences of events. However, current foundation models, designed for natural language, fail to grasp the holistic nature of structured interactions found in domains like telecommunications, e-commerce and finance. By serializing events into text, they disassemble them into semantically fragmented parts, losing critical context. In this work, we introduce the Unified Interaction Foundation Model (UIFM), a foundation model engineered for genuine behavioral understanding. At its core is the principle of composite tokenization, where each multi-attribute event is treated as a single, semantically coherent unit. This allows UIFM to learn the underlying \"grammar\" of user behavior, perceiving entire interactions rather than a disconnected stream of data points. We demonstrate that this architecture is not just more accurate, but represents a fundamental step towards creating more adaptable and intelligent predictive systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Unified Interaction Foundation Model (UIFM)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è‡ªç„¶è¯­è¨€åŸºç¡€æ¨¡å‹åœ¨ç”µä¿¡ã€ç”µå•†å’Œé‡‘èç­‰é¢†åŸŸå¤„ç†ç»“æ„åŒ–äº¤äº’æ—¶å› æ–‡æœ¬åºåˆ—åŒ–å¯¼è‡´è¯­ä¹‰ç¢ç‰‡åŒ–çš„é—®é¢˜ã€‚UIFM çš„æ ¸å¿ƒåœ¨äºå¼•å…¥äº† composite tokenization æœºåˆ¶ï¼Œå°†åŒ…å«å¤šä¸ªå±æ€§çš„å¤æ‚äº‹ä»¶è§†ä¸ºå•ä¸€ä¸”è¯­ä¹‰è¿è´¯çš„å•å…ƒè¿›è¡Œå¤„ç†ã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°ç”¨æˆ·è¡Œä¸ºçš„åº•å±‚â€œè¯­æ³• (grammar)â€ï¼Œä»è€Œå®Œæ•´åœ°æ„ŸçŸ¥å¤æ‚çš„äº¤äº’é€»è¾‘ï¼Œè€Œéå­¤ç«‹çš„æ•°æ®ç‚¹åºåˆ—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¶æ„ä¸ä»…åœ¨è¡Œä¸ºé¢„æµ‹çš„å‡†ç¡®æ€§ä¸Šè¡¨ç°å“è¶Šï¼Œè¿˜ä¸ºæ„å»ºæ›´å…·é€‚åº”æ€§å’Œæ™ºèƒ½åŒ–çš„é¢„æµ‹ç³»ç»Ÿæä¾›äº†å…³é”®æŠ€æœ¯è·¯å¾„ã€‚è¿™ç§ä»æ•´ä½“è§†è§’å»ºæ¨¡ç³»ç»Ÿè¡Œä¸ºçš„æ–¹æ³•ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿæ¨¡å‹åœ¨æ•æ‰å¤šç»´ä¸Šä¸‹æ–‡å…³è”æ—¶çš„å±€é™æ€§ï¼Œå®ç°äº†å¯¹äº¤äº’è¡Œä¸ºæ›´æ·±å±‚æ¬¡çš„è¯­ä¹‰ç†è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06025v1",
      "published_date": "2025-09-07 11:57:41 UTC",
      "updated_date": "2025-09-07 11:57:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:06:59.165821+00:00"
    },
    {
      "arxiv_id": "2509.06024v1",
      "title": "Rethinking Reasoning Quality in Large Language Models through Enhanced Chain-of-Thought via RL",
      "title_zh": "é‡æ–°å®¡è§†å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†è´¨é‡ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°æ€ç»´é“¾å¢å¼º",
      "authors": [
        "Haoyang He",
        "Zihua Rong",
        "Kun Ji",
        "Chenyang Li",
        "Qing Huang",
        "Chong Xia",
        "Lan Yang",
        "Honggang Zhang"
      ],
      "abstract": "Reinforcement learning (RL) has recently become the dominant paradigm for strengthening the reasoning abilities of large language models (LLMs). Yet the rule-based reward functions commonly used on mathematical or programming benchmarks assess only answer format and correctness, providing no signal as to whether the induced Chain-of-Thought (CoT) actually improves the answer. Furthermore, such task-specific training offers limited control over logical depth and therefore may fail to reveal a model's genuine reasoning capacity. We propose Dynamic Reasoning Efficiency Reward (DRER) -- a plug-and-play RL reward framework that reshapes both reward and advantage signals. (i) A Reasoning Quality Reward assigns fine-grained credit to those reasoning chains that demonstrably raise the likelihood of the correct answer, directly incentivising the trajectories with beneficial CoT tokens. (ii) A Dynamic Length Advantage decays the advantage of responses whose length deviates from a validation-derived threshold, stabilising training. To facilitate rigorous assessment, we also release Logictree, a dynamically constructed deductive reasoning dataset that functions both as RL training data and as a comprehensive benchmark. Experiments confirm the effectiveness of DRER: our 7B model attains GPT-o3-mini level performance on Logictree with 400 trianing steps, while the average confidence of CoT-augmented answers rises by 30%. The model further exhibits generalisation across diverse logical-reasoning datasets, and the mathematical benchmark AIME24. These results illuminate how RL shapes CoT behaviour and chart a practical path toward enhancing formal-reasoning skills in large language models. All code and data are available in repository https://github.com/Henryhe09/DRER.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (Reinforcement learning, RL)åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›æ—¶ä»…å…³æ³¨ç­”æ¡ˆæ­£ç¡®æ€§è€Œå¿½è§†æ€ç»´é“¾(Chain-of-Thought, CoT)è´¨é‡çš„é—®é¢˜ï¼Œæå‡ºäº†åŠ¨æ€æ¨ç†æ•ˆç‡å¥–åŠ±(Dynamic Reasoning Efficiency Reward, DRER)è¿™ä¸€å³æ’å³ç”¨çš„å¥–åŠ±æ¡†æ¶ã€‚DRERé€šè¿‡Reasoning Quality Rewardä¸ºèƒ½æ˜¾è‘—æé«˜æ­£ç¡®ç­”æ¡ˆæ¦‚ç‡çš„æ¨ç†é“¾åˆ†é…ç»†ç²’åº¦ä¿¡ç”¨ï¼Œå¹¶åˆ©ç”¨Dynamic Length Advantageæ ¹æ®éªŒè¯é˜ˆå€¼è°ƒèŠ‚å“åº”é•¿åº¦ä»¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚ä¸ºäº†è¿›è¡Œä¸¥è°¨è¯„ä¼°ï¼Œç ”ç©¶è€…è¿˜å‘å¸ƒäº†åŠ¨æ€æ„å»ºçš„æ¼”ç»æ¨ç†æ•°æ®é›†Logictreeï¼Œè¯¥æ•°æ®é›†å…¼å…·è®­ç»ƒä¸åŸºå‡†æµ‹è¯•åŠŸèƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºè¯¥æ¡†æ¶è®­ç»ƒçš„7Bæ¨¡å‹ä»…éœ€400ä¸ªè®­ç»ƒæ­¥æ•°å³å¯åœ¨Logictreeä¸Šè¾¾åˆ°GPT-o3-miniæ°´å¹³ï¼Œä¸”CoTå¢å¼ºç­”æ¡ˆçš„å¹³å‡ç½®ä¿¡åº¦æå‡äº†30%ã€‚è¯¥æ¨¡å‹åœ¨é€»è¾‘æ¨ç†åŠAIME24æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ·±åº¦ä¸å½¢å¼åŒ–æ¨ç†æŠ€èƒ½æä¾›äº†æœ‰æ•ˆçš„å®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06024v1",
      "published_date": "2025-09-07 11:52:18 UTC",
      "updated_date": "2025-09-07 11:52:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:07.771082+00:00"
    },
    {
      "arxiv_id": "2509.06006v1",
      "title": "Khana: A Comprehensive Indian Cuisine Dataset",
      "title_zh": "Khanaï¼šå…¨é¢çš„å°åº¦æ–™ç†æ•°æ®é›†",
      "authors": [
        "Omkar Prabhu"
      ],
      "abstract": "As global interest in diverse culinary experiences grows, food image models are essential for improving food-related applications by enabling accurate food recognition, recipe suggestions, dietary tracking, and automated meal planning. Despite the abundance of food datasets, a noticeable gap remains in capturing the nuances of Indian cuisine due to its vast regional diversity, complex preparations, and the lack of comprehensive labeled datasets that cover its full breadth. Through this exploration, we uncover Khana, a new benchmark dataset for food image classification, segmentation, and retrieval of dishes from Indian cuisine. Khana fills the gap by establishing a taxonomy of Indian cuisine and offering around 131K images in the dataset spread across 80 labels, each with a resolution of 500x500 pixels. This paper describes the dataset creation process and evaluates state-of-the-art models on classification, segmentation, and retrieval as baselines. Khana bridges the gap between research and development by providing a comprehensive and challenging benchmark for researchers while also serving as a valuable resource for developers creating real-world applications that leverage the rich tapestry of Indian cuisine. Webpage: https://khana.omkar.xyz",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Khanaï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å°åº¦èœè‚´çš„å¤§å‹åŸºå‡†æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰é£Ÿç‰©å›¾åƒæ¨¡å‹åœ¨å¤„ç†å°åº¦é¥®é£ŸåŒºåŸŸå¤šæ ·æ€§å’Œå¤æ‚çƒ¹é¥ªæ–¹å¼æ—¶çš„ä¸è¶³ã€‚Khana å»ºç«‹äº†å°åº¦æ–™ç†çš„åˆ†ç±»ä½“ç³» (taxonomy)ï¼ŒåŒ…å«çº¦ 13.1 ä¸‡å¼ æ¶µç›– 80 ä¸ªç±»åˆ«çš„ 500x500 åƒç´ é«˜åˆ†è¾¨ç‡å›¾åƒã€‚è¯¥æ•°æ®é›†æ”¯æŒé£Ÿç‰©å›¾åƒçš„åˆ†ç±» (classification)ã€åˆ†å‰² (segmentation) å’Œæ£€ç´¢ (retrieval) ä»»åŠ¡ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯„ä¼°åŸºå‡†ã€‚è®ºæ–‡è¯¦ç»†æè¿°äº†æ•°æ®é›†çš„æ„å»ºè¿‡ç¨‹ï¼Œå¹¶åˆ©ç”¨å¤šç§å…ˆè¿›æ¨¡å‹ (state-of-the-art models) è¿›è¡Œäº†æ€§èƒ½è¯„ä¼°ã€‚é€šè¿‡å¡«è¡¥å°åº¦æ–™ç†åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ç©ºç™½ï¼ŒKhana ä¸ºå¼€å‘ç²¾ç¡®çš„é£Ÿç‰©è¯†åˆ«ã€é£Ÿè°±å»ºè®®å’Œè‡ªåŠ¨åŒ–è†³é£Ÿè§„åˆ’ç­‰å®é™…åº”ç”¨æä¾›äº†é‡è¦çš„æ•°æ®æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06006v1",
      "published_date": "2025-09-07 10:43:29 UTC",
      "updated_date": "2025-09-07 10:43:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:14.978082+00:00"
    },
    {
      "arxiv_id": "2509.09709v1",
      "title": "Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¾…åŠ©ç§‘ç ”é¡¹ç›®ç”³è¯·ä¹¦å†™ä½œï¼šè¯„ä¼°ä¸ä¼˜åŒ–",
      "authors": [
        "Jing Ren",
        "Weiqi Wang"
      ],
      "abstract": "Large language models (LLMs) like ChatGPT are increasingly used in academic writing, yet issues such as incorrect or fabricated references raise ethical concerns. Moreover, current content quality evaluations often rely on subjective human judgment, which is labor-intensive and lacks objectivity, potentially compromising the consistency and reliability. In this study, to provide a quantitative evaluation and enhance research proposal writing capabilities of LLMs, we propose two key evaluation metrics--content quality and reference validity--and an iterative prompting method based on the scores derived from these two metrics. Our extensive experiments show that the proposed metrics provide an objective, quantitative framework for assessing ChatGPT's writing performance. Additionally, iterative prompting significantly enhances content quality while reducing reference inaccuracies and fabrications, addressing critical ethical challenges in academic contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨å­¦æœ¯ææ¡ˆå†™ä½œä¸­é¢ä¸´çš„è™šå‡å¼•ç”¨å’Œä¸»è§‚è¯„ä¼°ç­‰é—®é¢˜ï¼Œæå‡ºäº†å†…å®¹è´¨é‡(content quality)å’Œå¼•ç”¨æœ‰æ•ˆæ€§(reference validity)ä¸¤é¡¹é‡åŒ–è¯„ä¼°æŒ‡æ ‡ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸€ç§åŸºäºè¯„ä¼°å¾—åˆ†çš„è¿­ä»£æç¤º(iterative prompting)æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡å¾ªç¯åé¦ˆæå‡æ¨¡å‹ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ä¸è´¨é‡ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¿™äº›æŒ‡æ ‡ä¸ºè¯„ä¼°ChatGPTç­‰æ¨¡å‹çš„å­¦æœ¯å†™ä½œè¡¨ç°æä¾›äº†ä¸€ä¸ªå®¢è§‚ã€å®šé‡çš„åˆ†ææ¡†æ¶ã€‚é€šè¿‡è¿­ä»£æç¤ºï¼Œç³»ç»Ÿèƒ½å¤Ÿæ˜¾è‘—æ”¹å–„ç ”ç©¶ææ¡ˆçš„å†…å®¹è´¨é‡ï¼Œå¹¶æœ‰æ•ˆå‡å°‘å¼•ç”¨çš„é”™è¯¯å’Œä¼ªé€ ï¼Œä»è€Œåº”å¯¹äº†å­¦æœ¯ç ”ç©¶ä¸­çš„å…³é”®ä¼¦ç†æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09709v1",
      "published_date": "2025-09-07 10:24:28 UTC",
      "updated_date": "2025-09-07 10:24:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:08.970064+00:00"
    },
    {
      "arxiv_id": "2509.05999v1",
      "title": "S-LAM3D: Segmentation-Guided Monocular 3D Object Detection via Feature Space Fusion",
      "title_zh": "S-LAM3Dï¼šåŸºäºç‰¹å¾ç©ºé—´èåˆçš„åˆ†å‰²å¼•å¯¼å•ç›® 3D ç›®æ ‡æ£€æµ‹",
      "authors": [
        "Diana-Alexandra Sas",
        "Florin Oniga"
      ],
      "abstract": "Monocular 3D Object Detection represents a challenging Computer Vision task due to the nature of the input used, which is a single 2D image, lacking in any depth cues and placing the depth estimation problem as an ill-posed one. Existing solutions leverage the information extracted from the input by using Convolutional Neural Networks or Transformer architectures as feature extraction backbones, followed by specific detection heads for 3D parameters prediction. In this paper, we introduce a decoupled strategy based on injecting precomputed segmentation information priors and fusing them directly into the feature space for guiding the detection, without expanding the detection model or jointly learning the priors. The focus is on evaluating the impact of additional segmentation information on existing detection pipelines without adding additional prediction branches. The proposed method is evaluated on the KITTI 3D Object Detection Benchmark, outperforming the equivalent architecture that relies only on RGB image features for small objects in the scene: pedestrians and cyclists, and proving that understanding the input data can balance the need for additional sensors or training data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† S-LAM3Dï¼Œä¸€ç§åŸºäºåˆ†å‰²å¼•å¯¼çš„å•ç›®ä¸‰ç»´ç›®æ ‡æ£€æµ‹(Monocular 3D Object Detection)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å•å¹… 2D å›¾åƒç”±äºç¼ºä¹æ·±åº¦çº¿ç´¢è€Œå¯¼è‡´çš„æ·±åº¦ä¼°è®¡éš¾é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§è§£è€¦ç­–ç•¥ï¼Œé€šè¿‡å°†é¢„è®¡ç®—çš„åˆ†å‰²ä¿¡æ¯å…ˆéªŒ(Segmentation information priors)ç›´æ¥èåˆè¿›ç‰¹å¾ç©ºé—´(Feature space)æ¥å¼•å¯¼æ£€æµ‹è¿‡ç¨‹ï¼Œè€Œæ— éœ€æ‰©å±•æ£€æµ‹æ¨¡å‹æˆ–åŒæ­¥å­¦ä¹ å…ˆéªŒçŸ¥è¯†ã€‚ç ”ç©¶é‡ç‚¹è¯„ä¼°äº†åœ¨ä¸å¢åŠ é¢„æµ‹åˆ†æ”¯çš„æƒ…å†µä¸‹ï¼Œé¢å¤–åˆ†å‰²ä¿¡æ¯å¯¹ç°æœ‰æ£€æµ‹æµæ°´çº¿æ€§èƒ½çš„æå‡ä½œç”¨ã€‚åœ¨ KITTI 3D Object Detection Benchmark ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¡Œäºº(Pedestrians)å’Œéª‘è¡Œè€…(Cyclists)ç­‰å°ç›®æ ‡æ£€æµ‹ä¸Šä¼˜äºä»…ä¾èµ– RGB å›¾åƒç‰¹å¾çš„åŸºçº¿æ¨¡å‹ã€‚è¿™è¯æ˜äº†é€šè¿‡ä¼˜åŒ–å¯¹è¾“å…¥æ•°æ®çš„ç†è§£ä¸èåˆï¼Œå¯ä»¥æœ‰æ•ˆå¹³è¡¡å¯¹é¢å¤–ä¼ æ„Ÿå™¨æˆ–å¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„éœ€æ±‚ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages. Accepted to MMSP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.05999v1",
      "published_date": "2025-09-07 10:14:56 UTC",
      "updated_date": "2025-09-07 10:14:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:10.866955+00:00"
    },
    {
      "arxiv_id": "2509.05985v1",
      "title": "Operationalising AI Regulatory Sandboxes under the EU AI Act: The Triple Challenge of Capacity, Coordination and Attractiveness to Providers",
      "title_zh": "æ¬§ç›Ÿã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹ä¸‹äººå·¥æ™ºèƒ½ç›‘ç®¡æ²™ç›’çš„è½åœ°å®æ–½ï¼šèƒ½åŠ›ã€åè°ƒä¸æä¾›è€…å¸å¼•åŠ›çš„ä¸‰é‡æŒ‘æˆ˜",
      "authors": [
        "Deirdre Ahern"
      ],
      "abstract": "The EU AI Act provides a rulebook for all AI systems being put on the market or into service in the European Union. This article investigates the requirement under the AI Act that Member States establish national AI regulatory sandboxes for testing and validation of innovative AI systems under regulatory supervision to assist with fostering innovation and complying with regulatory requirements. Against the backdrop of the EU objective that AI regulatory sandboxes would both foster innovation and assist with compliance, considerable challenges are identified for Member States around capacity-building and design of regulatory sandboxes. While Member States are early movers in laying the ground for national AI regulatory sandboxes, the article contends that there is a risk that differing approaches being taken by individual national sandboxes could jeopardise a uniform interpretation of the AI Act and its application in practice. This could motivate innovators to play sandbox arbitrage. The article therefore argues that the European Commission and the AI Board need to act decisively in developing rules and guidance to ensure a cohesive, coordinated approach in national AI regulatory sandboxes. With sandbox participation being voluntary, the possibility that AI regulatory sandboxes may prove unattractive to innovators on their compliance journey is also explored. Confidentiality concerns, the inability to relax legal rules during the sandbox, and the inability of sandboxes to deliver a presumption of conformity with the AI Act are identified as pertinent concerns for innovators contemplating applying to AI regulatory sandboxes as compared with other direct compliance routes provided to them through application of harmonised standards and conformity assessment procedures.",
      "tldr_zh": "æœ¬æ–‡æ¢è®¨äº†ã€Šæ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹(EU AI Act) ä¸‹æˆå‘˜å›½å»ºç«‹å›½å®¶äººå·¥æ™ºèƒ½ç›‘ç®¡æ²™ç›’ (AI regulatory sandboxes) çš„è¦æ±‚ï¼Œæ—¨åœ¨é€šè¿‡ç›‘ç®¡æŒ‡å¯¼ä¿ƒè¿›åˆ›æ–°å¹¶ç¡®ä¿åˆè§„ã€‚ç ”ç©¶è¯†åˆ«äº†æˆå‘˜å›½åœ¨èƒ½åŠ›å»ºè®¾ (capacity-building) ä¸æ²™ç›’è®¾è®¡æ–¹é¢é¢ä¸´çš„é‡å¤§æŒ‘æˆ˜ï¼Œå¹¶æŒ‡å‡ºä¸åŒå›½å®¶çš„å·®å¼‚åŒ–åšæ³•å¯èƒ½å¯¼è‡´å¯¹æ³•æ¡ˆçš„è§£è¯»ä¸ä¸€ï¼Œä»è€Œå¼•å‘ç›‘ç®¡å¥—åˆ© (sandbox arbitrage) é£é™©ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« ä¸»å¼ æ¬§ç›Ÿå§”å‘˜ä¼š (European Commission) å’Œ AI Board åº”åˆ¶å®šç»Ÿä¸€è§„åˆ™ä»¥ç¡®ä¿å„æ²™ç›’é—´çš„åè°ƒä¸€è‡´ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ·±å…¥åˆ†æäº†æ²™ç›’å¯¹åˆ›æ–°è€…çš„å¸å¼•åŠ›ä¸è¶³é—®é¢˜ï¼Œç‰¹åˆ«æåˆ°äº†ä¿å¯†æ€§ç–‘è™‘ã€æ²™ç›’æœŸé—´æ³•å¾‹è§„åˆ™æ— æ³•è±å…ç­‰æ ¸å¿ƒé™åˆ¶ã€‚åŒæ—¶ï¼Œæ²™ç›’æ— æ³•æä¾›ç¬¦åˆæ³•æ¡ˆè¦æ±‚çš„æ¨å®šåˆæ ¼ (presumption of conformity)ï¼Œè¿™ä½¿å¾—å…¶ç›¸å¯¹äºä¼ ç»Ÿçš„åˆè§„è¯„ä¼°ç¨‹åºç«äº‰åŠ›å‡å¼±ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†åœ¨å®æ–½ã€Šæ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹è¿‡ç¨‹ä¸­ï¼Œèƒ½åŠ›ã€åè°ƒä¸å¸å¼•åŠ›è¿™ä¸‰é‡æŒ‘æˆ˜å¯¹ç›‘ç®¡æ²™ç›’æœ‰æ•ˆè¿è¡Œçš„æ·±è¿œå½±å“ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05985v1",
      "published_date": "2025-09-07 09:20:40 UTC",
      "updated_date": "2025-09-07 09:20:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:27.266124+00:00"
    },
    {
      "arxiv_id": "2509.05983v3",
      "title": "TSPC: A Two-Stage Phoneme-Centric Architecture for code-switching Vietnamese-English Speech Recognition",
      "title_zh": "TSPCï¼šä¸€ç§é¢å‘è¶Šè‹±è¯­ç è½¬æ¢è¯­éŸ³è¯†åˆ«çš„ä¸¤é˜¶æ®µéŸ³ç´ ä¸­å¿ƒæ¶æ„",
      "authors": [
        "Minh N. H. Nguyen",
        "Anh Nguyen Tran",
        "Dung Truong Dinh",
        "Nam Van Vo"
      ],
      "abstract": "Code-switching (CS) presents a significant challenge for general Auto-Speech Recognition (ASR) systems. Existing methods often fail to capture the subtle phonological shifts inherent in CS scenarios. The challenge is particularly difficult for language pairs like Vietnamese and English, where both distinct phonological features and the ambiguity arising from similar sound recognition are present. In this paper, we propose a novel architecture for Vietnamese-English CS ASR, a Two-Stage Phoneme-Centric model (TSPC). The TSPC employs a phoneme-centric approach, built upon an extended Vietnamese phoneme set as an intermediate representation to facilitate mixed-lingual modeling. Experimental results demonstrate that TSPC consistently outperforms existing baselines, including PhoWhisper-base, in Vietnamese-English CS ASR, achieving a significantly lower word error rate of 19.9% with reduced training resources. Furthermore, the phonetic-based two-stage architecture enables phoneme adaptation and language conversion to enhance ASR performance in complex CS Vietnamese-English ASR scenarios",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¶Šå—è¯­-è‹±è¯­ (Vietnamese-English) è¯­ç è½¬æ¢ (Code-switching) è¯­éŸ³è¯†åˆ«ä¸­éš¾ä»¥æ•æ‰è¯­éŸ³å˜åŒ–åŠæ¶ˆé™¤å‘éŸ³æ­§ä¹‰çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º TSPC çš„ä¸¤é˜¶æ®µä»¥éŸ³ç´ ä¸ºä¸­å¿ƒ (Two-Stage Phoneme-Centric) çš„æ–°å‹æ¶æ„ã€‚è¯¥æ¨¡å‹åˆ©ç”¨æ‰©å±•çš„è¶Šå—è¯­éŸ³ç´ é›†ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œæœ‰æ•ˆä¿ƒè¿›äº†æ··åˆè¯­è¨€å»ºæ¨¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTSPC åœ¨å‡å°‘è®­ç»ƒèµ„æºçš„æƒ…å†µä¸‹ï¼Œåœ¨è¶Šå—è¯­-è‹±è¯­ CS ASR ä»»åŠ¡ä¸­æŒç»­ä¼˜äº PhoWhisper-base ç­‰åŸºçº¿æ¨¡å‹ï¼Œå¹¶å®ç°äº† 19.9% çš„è¯é”™è¯¯ç‡ (Word Error Rate)ã€‚æ­¤å¤–ï¼Œè¿™ç§åŸºäºéŸ³ç´ çš„åŒé˜¶æ®µæ¶æ„æ”¯æŒéŸ³ç´ é€‚é…å’Œè¯­è¨€è½¬æ¢ï¼Œæ˜¾è‘—å¢å¼ºäº†åœ¨å¤æ‚è¯­ç è½¬æ¢åœºæ™¯ä¸‹çš„ ASR æ€§èƒ½ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Update new version",
      "pdf_url": "https://arxiv.org/pdf/2509.05983v3",
      "published_date": "2025-09-07 09:19:03 UTC",
      "updated_date": "2025-09-20 14:15:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:44.970525+00:00"
    },
    {
      "arxiv_id": "2509.07022v1",
      "title": "Preventing Another Tessa: Modular Safety Middleware For Health-Adjacent AI Assistants",
      "title_zh": "é¢„é˜²ä¸‹ä¸€ä¸ª Tessaï¼šé¢å‘æ³›å¥åº·é¢†åŸŸ AI åŠ©æ‰‹çš„æ¨¡å—åŒ–å®‰å…¨ä¸­é—´ä»¶",
      "authors": [
        "Pavan Reddy",
        "Nithin Reddy"
      ],
      "abstract": "In 2023, the National Eating Disorders Association's (NEDA) chatbot Tessa was suspended after providing harmful weight-loss advice to vulnerable users-an avoidable failure that underscores the risks of unsafe AI in healthcare contexts. This paper examines Tessa as a case study in absent safety engineering and demonstrates how a lightweight, modular safeguard could have prevented the incident. We propose a hybrid safety middleware that combines deterministic lexical gates with an in-line large language model (LLM) policy filter, enforcing fail-closed verdicts and escalation pathways within a single model call. Using synthetic evaluations, we show that this design achieves perfect interception of unsafe prompts at baseline cost and latency, outperforming traditional multi-stage pipelines. Beyond technical remedies, we map Tessa's failure patterns to established frameworks (OWASP LLM Top10, NIST SP 800-53), connecting practical safeguards to actionable governance controls. The results highlight that robust, auditable safety in health-adjacent AI does not require heavyweight infrastructure: explicit, testable checks at the last mile are sufficient to prevent \"another Tessa\", while governance and escalation ensure sustainability in real-world deployment.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»¥2023å¹´ç¾å›½å›½å®¶é¥®é£Ÿå¤±è°ƒåä¼š(NEDA)çš„èŠå¤©æœºå™¨äººTessaå› æä¾›æœ‰å®³å»ºè®®è€Œè¢«åœç”¨çš„äº‹ä»¶ä¸ºæ¡ˆä¾‹ï¼Œæ·±å…¥åˆ†æäº†å¥åº·ç›¸å…³AIåŠ©æ‰‹åœ¨å®‰å…¨å·¥ç¨‹æ–¹é¢çš„ç¼ºå¤±ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§çš„æ··åˆå®‰å…¨ä¸­é—´ä»¶(hybrid safety middleware)ï¼Œé€šè¿‡ç»“åˆç¡®å®šæ€§è¯æ³•é—¨æ§(lexical gates)ä¸å†…è”å¤§è¯­è¨€æ¨¡å‹(LLM)ç­–ç•¥è¿‡æ»¤å™¨(policy filter)ï¼Œåœ¨å•æ¬¡æ¨¡å‹è°ƒç”¨ä¸­å®ç°å¼ºåˆ¶å…³é—­(fail-closed)åˆ¤å®šä¸å‡çº§è·¯å¾„(escalation pathways)ã€‚å®éªŒé€šè¿‡åˆæˆè¯„ä¼°(synthetic evaluations)è¯æ˜ï¼Œè¯¥æ–¹æ¡ˆèƒ½ä»¥æä½çš„æˆæœ¬å’Œå»¶è¿Ÿå®ç°å¯¹ä¸å®‰å…¨æç¤ºçš„å®Œç¾æ‹¦æˆªï¼Œè¡¨ç°ä¼˜äºä¼ ç»Ÿçš„å¤šé˜¶æ®µæµæ°´çº¿ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å°†æ•…éšœæ¨¡å¼æ˜ å°„è‡³OWASP LLM Top10å’ŒNIST SP 800-53ç­‰æ²»ç†æ¡†æ¶ï¼Œç¡®ç«‹äº†æŠ€æœ¯é˜²æŠ¤ä¸è¡Œæ”¿ç®¡æ§ä¹‹é—´çš„å…³è”ã€‚ç»“æœè¡¨æ˜ï¼Œç¡®ä¿å¥åº·ç±»AIçš„å®‰å…¨æ€§å¹¶ä¸éœ€è¦æ²‰é‡çš„æ¶æ„ï¼Œè€Œæ˜¯åœ¨åº”ç”¨ç«¯éƒ¨ç½²æ˜ç¡®ã€å¯æµ‹è¯•çš„æ£€æŸ¥æœºåˆ¶ï¼Œä»è€Œæœ‰æ•ˆé˜²æ­¢ç±»ä¼¼Tessaçš„å®‰å…¨äº‹æ•…å†æ¬¡å‘ç”Ÿã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages content, 1 page reference, 1 figure, Accepted at AAAI Fall Symposium Series",
      "pdf_url": "https://arxiv.org/pdf/2509.07022v1",
      "published_date": "2025-09-07 08:43:39 UTC",
      "updated_date": "2025-09-07 08:43:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:45.172996+00:00"
    },
    {
      "arxiv_id": "2509.05975v1",
      "title": "ConstStyle: Robust Domain Generalization with Unified Style Transformation",
      "title_zh": "ConstStyleï¼šåŸºäºç»Ÿä¸€é£æ ¼è½¬æ¢çš„é²æ£’åŸŸæ³›åŒ–",
      "authors": [
        "Nam Duong Tran",
        "Nam Nguyen Phuong",
        "Hieu H. Pham",
        "Phi Le Nguyen",
        "My T. Thai"
      ],
      "abstract": "Deep neural networks often suffer performance drops when test data distribution differs from training data. Domain Generalization (DG) aims to address this by focusing on domain-invariant features or augmenting data for greater diversity. However, these methods often struggle with limited training domains or significant gaps between seen (training) and unseen (test) domains. To enhance DG robustness, we hypothesize that it is essential for the model to be trained on data from domains that closely resemble unseen test domains-an inherently difficult task due to the absence of prior knowledge about the unseen domains. Accordingly, we propose ConstStyle, a novel approach that leverages a unified domain to capture domain-invariant features and bridge the domain gap with theoretical analysis. During training, all samples are mapped onto this unified domain, optimized for seen domains. During testing, unseen domain samples are projected similarly before predictions. By aligning both training and testing data within this unified domain, ConstStyle effectively reduces the impact of domain shifts, even with large domain gaps or few seen domains. Extensive experiments demonstrate that ConstStyle consistently outperforms existing methods across diverse scenarios. Notably, when only a limited number of seen domains are available, ConstStyle can boost accuracy up to 19.82\\% compared to the next best approach.",
      "tldr_zh": "æ·±åº¦ç¥ç»ç½‘ç»œåœ¨æµ‹è¯•æ•°æ®åˆ†å¸ƒä¸è®­ç»ƒæ•°æ®ä¸ä¸€è‡´æ—¶é€šå¸¸æ€§èƒ½ä¸‹é™ï¼Œè€Œé¢†åŸŸæ³›åŒ–(Domain Generalization)æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨æœ‰é™çš„è®­ç»ƒé¢†åŸŸæˆ–æ˜¾è‘—çš„é¢†åŸŸå·®è·ä¸‹è¡¨ç°ä¸ä½³ã€‚è¯¥ç ”ç©¶æå‡ºäº†ConstStyleï¼Œä¸€ç§åˆ©ç”¨ç»Ÿä¸€é¢†åŸŸ(unified domain)æ•æ‰é¢†åŸŸä¸å˜ç‰¹å¾å¹¶å¼¥åˆé¢†åŸŸå·®è·çš„æ–°é¢–æ–¹æ³•ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ‰€æœ‰æ ·æœ¬éƒ½è¢«æ˜ å°„åˆ°è¿™ä¸€ç»Ÿä¸€é¢†åŸŸå¹¶é’ˆå¯¹å·²çŸ¥é¢†åŸŸ(seen domains)è¿›è¡Œä¼˜åŒ–ï¼›åœ¨æµ‹è¯•é˜¶æ®µï¼ŒæœªçŸ¥é¢†åŸŸ(unseen domains)çš„æ ·æœ¬åœ¨é¢„æµ‹å‰ä¹Ÿä¼šè¢«æŠ•å½±åˆ°è¯¥é¢†åŸŸã€‚é€šè¿‡åœ¨ç»Ÿä¸€é¢†åŸŸå†…å¯¹é½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ï¼ŒConstStyleæœ‰æ•ˆå‡å°‘äº†é¢†åŸŸåç§»(domain shifts)çš„å½±å“ï¼Œå³ä½¿åœ¨é¢†åŸŸå·®è·è¾ƒå¤§æˆ–å·²çŸ¥é¢†åŸŸæå°‘çš„æƒ…å†µä¸‹ä¹Ÿèƒ½ä¿æŒé²æ£’æ€§ã€‚å®éªŒè¯æ˜ï¼ŒConstStyleåœ¨å¤šç§åœºæ™¯ä¸‹ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨å·²çŸ¥é¢†åŸŸæœ‰é™æ—¶ï¼Œå‡†ç¡®ç‡æ¯”æ¬¡ä¼˜æ–¹æ³•æå‡äº†é«˜è¾¾19.82%ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.05975v1",
      "published_date": "2025-09-07 08:40:19 UTC",
      "updated_date": "2025-09-07 08:40:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:53.171045+00:00"
    },
    {
      "arxiv_id": "2509.07021v2",
      "title": "MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians and Unified Pruning",
      "title_zh": "MEGS$^{2}$ï¼šåŸºäºçƒé¢é«˜æ–¯ä¸ç»Ÿä¸€å‰ªæçš„å†…å­˜é«˜æ•ˆé«˜æ–¯æ³¼æº…",
      "authors": [
        "Jiarui Chen",
        "Yikeng Chen",
        "Yingshuang Zou",
        "Ye Huang",
        "Peng Wang",
        "Yuan Liu",
        "Yujing Sun",
        "Wenping Wang"
      ],
      "abstract": "3D Gaussian Splatting (3DGS) has emerged as a dominant novel-view synthesis technique, but its high memory consumption severely limits its applicability on edge devices. A growing number of 3DGS compression methods have been proposed to make 3DGS more efficient, yet most only focus on storage compression and fail to address the critical bottleneck of rendering memory. To address this problem, we introduce MEGS$^{2}$, a novel memory-efficient framework that tackles this challenge by jointly optimizing two key factors: the total primitive number and the parameters per primitive, achieving unprecedented memory compression. Specifically, we replace the memory-intensive spherical harmonics with lightweight, arbitrarily oriented spherical Gaussian lobes as our color representations. More importantly, we propose a unified soft pruning framework that models primitive-number and lobe-number pruning as a single constrained optimization problem. Experiments show that MEGS$^{2}$ achieves a 50% static VRAM reduction and a 40% rendering VRAM reduction compared to existing methods, while maintaining comparable rendering quality. Project page: https://megs-2.github.io/",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MEGS$^{2}$ï¼Œä¸€ç§é’ˆå¯¹3D Gaussian Splatting (3DGS)å†…å­˜ä¼˜åŒ–çš„é«˜æ•ˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæ¸²æŸ“å†…å­˜å ç”¨è¿‡é«˜çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è”åˆä¼˜åŒ–åŸºå…ƒæ€»æ•°å’Œæ¯ä¸ªåŸºå…ƒçš„å‚æ•°é‡ï¼Œå®ç°äº†æ˜¾è‘—çš„å†…å­˜å‹ç¼©ã€‚å…·ä½“æ¥è¯´ï¼Œç ”ç©¶è€…ä½¿ç”¨è½»é‡çº§ä¸”æ–¹å‘çµæ´»çš„Spherical Gaussians (SG)æ›¿ä»£äº†å†…å­˜å¯†é›†å‹çš„Spherical Harmonics (SH)ä½œä¸ºé¢œè‰²è¡¨ç¤ºæ–¹æ³•ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒMEGS$^{2}$å¼•å…¥äº†ä¸€ä¸ªç»Ÿä¸€çš„è½¯å‰ªææ¡†æ¶(unified soft pruning framework)ï¼Œå°†åŸºå…ƒæ•°é‡å’Œæ³¢ç“£æ•°é‡çš„å‰ªææ•´åˆä¸ºå•ä¸€çš„çº¦æŸä¼˜åŒ–é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMEGS$^{2}$åœ¨ä¿æŒæ¸²æŸ“è´¨é‡çš„å‰æä¸‹ï¼Œæ¯”ç°æœ‰æ–¹æ³•å‡å°‘äº†50%çš„é™æ€VRAMå’Œ40%çš„æ¸²æŸ“VRAMå ç”¨ã€‚è¿™ä¸€æˆæœä¸ºåœ¨ä½åŠŸè€—ç¡¬ä»¶ä¸Šå®ç°é«˜è´¨é‡çš„å®æ—¶æ¸²æŸ“æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 8 figures. Project page at https://megs-2.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2509.07021v2",
      "published_date": "2025-09-07 07:06:03 UTC",
      "updated_date": "2025-09-23 17:01:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:51.781420+00:00"
    },
    {
      "arxiv_id": "2509.05933v2",
      "title": "MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration",
      "title_zh": "MapAgentï¼šé›†æˆåŠ¨æ€åœ°å›¾å·¥å…·çš„åœ°ç†ç©ºé—´æ¨ç†å±‚æ¬¡åŒ–æ™ºèƒ½ä½“",
      "authors": [
        "Md Hasebul Hasan",
        "Mahir Labib Dihan",
        "Tanzima Hashem",
        "Mohammed Eunus Ali",
        "Md Rizwan Parvez"
      ],
      "abstract": "Agentic AI has significantly extended the capabilities of large language models (LLMs) by enabling complex reasoning and tool use. However, most existing frameworks are tailored to domains such as mathematics, coding, or web automation, and fall short on geospatial tasks that require spatial reasoning, multi-hop planning, and real-time map interaction. To address these challenges, we introduce MapAgent, a hierarchical multi-agent plug-and-play framework with customized toolsets and agentic scaffolds for map-integrated geospatial reasoning. Unlike existing flat agent-based approaches that treat tools uniformly-often overwhelming the LLM when handling similar but subtly different geospatial APIs-MapAgent decouples planning from execution. A high-level planner decomposes complex queries into subgoals, which are routed to specialized modules. For tool-heavy modules-such as map-based services-we then design a dedicated map-tool agent that efficiently orchestrates related APIs adaptively in parallel to effectively fetch geospatial data relevant for the query, while simpler modules (e.g., solution generation or answer extraction) operate without additional agent overhead. This hierarchical design reduces cognitive load, improves tool selection accuracy, and enables precise coordination across similar APIs. We evaluate MapAgent on four diverse geospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and MapQA-and demonstrate substantial gains over state-of-the-art tool-augmented and agentic baselines. We open-source our framwork at https://github.com/Hasebul/MapAgent.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ï¼ˆAgentic AIï¼‰åœ¨åœ°ç†ç©ºé—´ä»»åŠ¡ä¸­é¢ä¸´çš„ç©ºé—´æ¨ç†ã€å¤šæ­¥è§„åˆ’åŠå®æ—¶åœ°å›¾äº¤äº’èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº† MapAgent æ¡†æ¶ã€‚MapAgent é‡‡ç”¨äº†ä¸€ç§åˆ†å±‚å¼ï¼ˆHierarchicalï¼‰å¤šæ™ºèƒ½ä½“å³æ’å³ç”¨æ¡†æ¶ï¼Œé€šè¿‡è§£è€¦è§„åˆ’ä¸æ‰§è¡Œæ¥æœ‰æ•ˆé™ä½å¤§æ¨¡å‹çš„è®¤çŸ¥è´Ÿè·ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å«ä¸€ä¸ªé«˜å±‚è§„åˆ’å™¨ï¼ˆHigh-level Plannerï¼‰ï¼Œè´Ÿè´£å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå­ç›®æ ‡å¹¶è·¯ç”±è‡³ä¸“é—¨æ¨¡å—ã€‚é’ˆå¯¹å·¥å…·å¯†é›†å‹ä»»åŠ¡ï¼ŒMapAgent ä¸“é—¨è®¾è®¡äº†åœ°å›¾å·¥å…·æ™ºèƒ½ä½“ï¼ˆMap-tool agentï¼‰ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°å¹¶è¡Œè°ƒåº¦ç›¸å…³ API ä»¥é«˜æ•ˆè·å–åœ°ç†ç©ºé—´æ•°æ®ã€‚ä¸ä¼ ç»Ÿçš„æ‰å¹³åŒ–æ™ºèƒ½ä½“æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§åˆ†å±‚è®¾è®¡æ˜¾è‘—æé«˜äº†å·¥å…·é€‰æ‹©çš„å‡†ç¡®æ€§ï¼Œå¹¶å®ç°äº†ç›¸ä¼¼ API é—´çš„ç²¾å‡†åè°ƒã€‚åœ¨ MapEval-Textualã€MapEval-APIã€MapEval-Visual å’Œ MapQA å››ä¸ªåœ°ç†ç©ºé—´åŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒMapAgent çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å·¥å…·å¢å¼ºå‹å’Œæ™ºèƒ½ä½“åŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºå¤æ‚çš„åœ°ç†ç©ºé—´æ¨ç†æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶å·²å¼€æºå…¶ç›¸å…³ä»£ç ä¸æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "27 Pages",
      "pdf_url": "https://arxiv.org/pdf/2509.05933v2",
      "published_date": "2025-09-07 05:47:58 UTC",
      "updated_date": "2025-10-14 04:15:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:54.373829+00:00"
    },
    {
      "arxiv_id": "2509.05926v1",
      "title": "Meta-training of diffractive meta-neural networks for super-resolution direction of arrival estimation",
      "title_zh": "ç”¨äºè¶…åˆ†è¾¨ç‡æ³¢è¾¾æ–¹å‘ä¼°è®¡çš„è¡å°„è¶…ç¥ç»ç½‘ç»œå…ƒè®­ç»ƒ",
      "authors": [
        "Songtao Yang",
        "Sheng Gao",
        "Chu Wu",
        "Zejia Zhao",
        "Haiou Zhang",
        "Xing Lin"
      ],
      "abstract": "Diffractive neural networks leverage the high-dimensional characteristics of electromagnetic (EM) fields for high-throughput computing. However, the existing architectures face challenges in integrating large-scale multidimensional metasurfaces with precise network training and haven't utilized multidimensional EM field coding scheme for super-resolution sensing. Here, we propose diffractive meta-neural networks (DMNNs) for accurate EM field modulation through metasurfaces, which enable multidimensional multiplexing and coding for multi-task learning and high-throughput super-resolution direction of arrival estimation. DMNN integrates pre-trained mini-metanets to characterize the amplitude and phase responses of meta-atoms across different polarizations and frequencies, with structure parameters inversely designed using the gradient-based meta-training. For wide-field super-resolution angle estimation, the system simultaneously resolves azimuthal and elevational angles through x and y-polarization channels, while the interleaving of frequency-multiplexed angular intervals generates spectral-encoded optical super-oscillations to achieve full-angle high-resolution estimation. Post-processing lightweight electronic neural networks further enhance the performance. Experimental results validate that a three-layer DMNN operating at 27 GHz, 29 GHz, and 31 GHz achieves $\\sim7\\times$ Rayleigh diffraction-limited angular resolution (0.5$^\\circ$), a mean absolute error of 0.048$^\\circ$ for two incoherent targets within a $\\pm 11.5^\\circ$ field of view, and an angular estimation throughput an order of magnitude higher (1917) than that of existing methods. The proposed architecture advances high-dimensional photonic computing systems by utilizing inherent high-parallelism and all-optical coding methods for ultra-high-resolution, high-throughput applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†è¡å°„å…ƒç¥ç»ç½‘ç»œï¼ˆDiffractive Meta-Neural Networks, DMNNsï¼‰ï¼Œåˆ©ç”¨è¶…è¡¨é¢ï¼ˆmetasurfacesï¼‰å®ç°ç²¾ç¡®çš„ç”µç£åœºè°ƒåˆ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡å¤šç»´è¶…è¡¨é¢çš„é›†æˆä¸è®­ç»ƒéš¾é¢˜å¹¶å®ç°è¶…åˆ†è¾¨ç‡ä¼ æ„Ÿã€‚è¯¥æ¡†æ¶é›†æˆäº†é¢„è®­ç»ƒçš„å¾®å‹å…ƒç½‘ç»œï¼ˆmini-metanetsï¼‰ä»¥è¡¨å¾ä¸åŒæåŒ–å’Œé¢‘ç‡ä¸‹çš„å…ƒåŸå­ï¼ˆmeta-atomsï¼‰å“åº”ï¼Œå¹¶é€šè¿‡åŸºäºæ¢¯åº¦çš„å…ƒè®­ç»ƒï¼ˆmeta-trainingï¼‰å®Œæˆç»“æ„å‚æ•°çš„é€†å‘è®¾è®¡ã€‚ç³»ç»Ÿåˆ©ç”¨ x å’Œ y æåŒ–é€šé“åŒæ­¥è§£ææ–¹ä½è§’ä¸ä»°è§’ï¼Œç»“åˆé¢‘ç‡å¤ç”¨äº§ç”Ÿçš„é¢‘è°±ç¼–ç å…‰å­¦è¶…æŒ¯è¡ï¼ˆsuper-oscillationsï¼‰å®ç°äº†å…¨è§’åº¦çš„é«˜åˆ†è¾¨ç‡ä¼°è®¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸‰å±‚ DMNN åœ¨ 27 GHz è‡³ 31 GHz é¢‘ç‡ä¸‹è¾¾åˆ°äº†çº¦ 7 å€ç‘åˆ©è¡å°„æé™ï¼ˆRayleigh diffraction-limitedï¼‰çš„è§’åˆ†è¾¨ç‡ï¼Œå¯¹ä¸¤ä¸ªéç›¸å¹²ç›®æ ‡çš„å¹³å‡ç»å¯¹è¯¯å·®ä»…ä¸º 0.048Â°ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆçš„è§’ä¼°è®¡ååé‡æ¯”ç°æœ‰æ–¹æ³•é«˜å‡ºä¸€ä¸ªæ•°é‡çº§ï¼Œå……åˆ†å±•ç¤ºäº†é«˜å¹¶è¡Œå…¨å…‰å­¦ç¼–ç åœ¨è¶…é«˜åˆ†è¾¨ç‡ã€é«˜ååé‡å…‰å­è®¡ç®—é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "physics.optics",
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "physics.optics",
      "comment": "47 pages, 17 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05926v1",
      "published_date": "2025-09-07 04:49:51 UTC",
      "updated_date": "2025-09-07 04:49:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:07:59.878206+00:00"
    },
    {
      "arxiv_id": "2509.07019v1",
      "title": "An efficient deep reinforcement learning environment for flexible job-shop scheduling",
      "title_zh": "é¢å‘æŸ”æ€§ä½œä¸šè½¦é—´è°ƒåº¦çš„é«˜æ•ˆæ·±åº¦å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ",
      "authors": [
        "Xinquan Wu",
        "Xuefeng Yan",
        "Mingqiang Wei",
        "Donghai Guan"
      ],
      "abstract": "The Flexible Job-shop Scheduling Problem (FJSP) is a classical combinatorial optimization problem that has a wide-range of applications in the real world. In order to generate fast and accurate scheduling solutions for FJSP, various deep reinforcement learning (DRL) scheduling methods have been developed. However, these methods are mainly focused on the design of DRL scheduling Agent, overlooking the modeling of DRL environment. This paper presents a simple chronological DRL environment for FJSP based on discrete event simulation and an end-to-end DRL scheduling model is proposed based on the proximal policy optimization (PPO). Furthermore, a short novel state representation of FJSP is proposed based on two state variables in the scheduling environment and a novel comprehensible reward function is designed based on the scheduling area of machines. Experimental results on public benchmark instances show that the performance of simple priority dispatching rules (PDR) is improved in our scheduling environment and our DRL scheduling model obtains competing performance compared with OR-Tools, meta-heuristic, DRL and PDR scheduling methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŸ”æ€§ä½œä¸šè½¦é—´è°ƒåº¦é—®é¢˜ (Flexible Job-shop Scheduling Problem, FJSP)ï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ·±åº¦å¼ºåŒ–å­¦ä¹  (Deep Reinforcement Learning, DRL) ç¯å¢ƒã€‚ä¸ä»¥å¾€ä¾§é‡äºæ™ºèƒ½ä½“è®¾è®¡çš„ç ”ç©¶ä¸åŒï¼Œè¯¥è®ºæ–‡åŸºäºç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿ (Discrete Event Simulation) æ„å»ºäº†ä¸€ä¸ªç®€æ´çš„æ—¶é—´é¡ºåº DRL ç¯å¢ƒï¼Œå¹¶æå‡ºäº†åŸºäºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ– (Proximal Policy Optimization, PPO) çš„ç«¯åˆ°ç«¯ DRL è°ƒåº¦æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†ä»…åŒ…å«ä¸¤ä¸ªçŠ¶æ€å˜é‡çš„ç®€æ´çŠ¶æ€è¡¨ç¤ºï¼Œä»¥åŠåŸºäºæœºå™¨è°ƒåº¦åŒºåŸŸçš„æ˜“äºç†è§£çš„å¥–åŠ±å‡½æ•°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç¯å¢ƒèƒ½å¤Ÿæœ‰æ•ˆæå‡ç®€å•ä¼˜å…ˆè°ƒåº¦è§„åˆ™ (Priority Dispatching Rules, PDR) çš„æ€§èƒ½ï¼Œä¸”è¯¥ DRL æ¨¡å‹åœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºä¸ OR-Toolsã€å…ƒå¯å‘å¼ç®—æ³• (Meta-heuristic) åŠå…¶ä»– DRL æ–¹æ³•ç›¸å½“çš„ç«äº‰åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07019v1",
      "published_date": "2025-09-07 02:50:09 UTC",
      "updated_date": "2025-09-07 02:50:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:06.473328+00:00"
    },
    {
      "arxiv_id": "2509.09708v2",
      "title": "Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal",
      "title_zh": "ä¸æ­¢äºâ€œæŠ±æ­‰ï¼Œæˆ‘æ— æ³•åšåˆ°â€ï¼šæ·±åº¦å‰–æå¤§è¯­è¨€æ¨¡å‹çš„æ‹’ç»è¡Œä¸º",
      "authors": [
        "Nirmalendu Prakash",
        "Yeo Wei Jie",
        "Amir Abdullah",
        "Ranjan Satapathy",
        "Erik Cambria",
        "Roy Ka Wei Lee"
      ],
      "abstract": "Refusal on harmful prompts is a key safety behaviour in instruction-tuned large language models (LLMs), yet the internal causes of this behaviour remain poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on residual-stream activations. Given a harmful prompt, we search the SAE latent space for feature sets whose ablation flips the model from refusal to compliance, demonstrating causal influence and creating a jailbreak. Our search proceeds in three stages: (1) Refusal Direction: find a refusal-mediating direction and collect SAE features near that direction; (2) Greedy Filtering: prune to a minimal set; and (3) Interaction Discovery: fit a factorization machine (FM) that captures nonlinear interactions among the remaining active features and the minimal set. This pipeline yields a broad set of jailbreak-critical features, offering insight into the mechanistic basis of refusal. Moreover, we find evidence of redundant features that remain dormant unless earlier features are suppressed. Our findings highlight the potential for fine-grained auditing and targeted intervention in safety behaviours by manipulating the interpretable latent space.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥å‰–æäº†æŒ‡ä»¤å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ‹’ç»æœ‰å®³æç¤ºçš„å†…éƒ¨æœºåˆ¶ï¼Œä¸»è¦é’ˆå¯¹ Gemma-2-2B-IT å’Œ LLaMA-3.1-8B-IT å±•å¼€åˆ†æã€‚ç ”ç©¶è€…åˆ©ç”¨åœ¨æ®‹å·®æµæ¿€æ´»ä¸Šè®­ç»ƒçš„ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨ï¼ˆSparse Autoencoders, SAEsï¼‰æ¢ç´¢æ½œç©ºé—´ï¼Œé€šè¿‡è¯†åˆ«æ‹’ç»æ–¹å‘ã€è´ªå©ªè¿‡æ»¤åŠåˆ©ç”¨å› å­åˆ†è§£æœºï¼ˆFactorization Machine, FMï¼‰å‘ç°éçº¿æ€§äº¤äº’ï¼ŒæˆåŠŸæå–å‡ºå½±å“æ‹’ç»å†³ç­–çš„å…³é”®ç‰¹å¾é›†ã€‚å®éªŒè¯æ˜ï¼Œæ¶ˆèè¿™äº›ç‰¹å¾èƒ½ä½¿æ¨¡å‹ä»æ‹’ç»è½¬ä¸ºåˆè§„ï¼Œä»è€Œå®ç°è¶Šç‹±ï¼ˆjailbreakï¼‰ï¼Œå¹¶æ­ç¤ºäº†æ‹’ç»è¡Œä¸ºçš„æœºæ¢°è®ºåŸºç¡€ã€‚ç ”ç©¶è¿˜å‘ç°äº†æ¨¡å‹ä¸­å­˜åœ¨å†—ä½™ç‰¹å¾ï¼Œå³åœ¨ä¸»è¦ç‰¹å¾å—æŠ‘åˆ¶æ—¶æ‰ä¼šæ¿€æ´»çš„ä¼‘çœ æœºåˆ¶ã€‚è¯¥æˆæœçªæ˜¾äº†é€šè¿‡æ“çºµå¯è§£é‡Šçš„æ½œç©ºé—´å¯¹ AI å®‰å…¨è¡Œä¸ºè¿›è¡Œç»†ç²’åº¦å®¡è®¡å’Œå®šå‘å¹²é¢„çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09708v2",
      "published_date": "2025-09-07 02:29:07 UTC",
      "updated_date": "2025-10-10 07:46:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:05.769834+00:00"
    },
    {
      "arxiv_id": "2509.05892v1",
      "title": "Challenges in Deep Learning-Based Small Organ Segmentation: A Benchmarking Perspective for Medical Research with Limited Datasets",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„å°å™¨å®˜åˆ†å‰²æŒ‘æˆ˜ï¼šæœ‰é™æ•°æ®é›†ä¸‹åŒ»å­¦ç ”ç©¶çš„åŸºå‡†è¯„æµ‹è§†è§’",
      "authors": [
        "Phongsakon Mark Konrad",
        "Andrei-Alexandru Popa",
        "Yaser Sabzehmeidani",
        "Liang Zhong",
        "Elisa A. Liehn",
        "Serkan Ayvaz"
      ],
      "abstract": "Accurate segmentation of carotid artery structures in histopathological images is vital for advancing cardiovascular disease research and diagnosis. However, deep learning model development in this domain is constrained by the scarcity of annotated cardiovascular histopathological data. This study investigates a systematic evaluation of state-of-the-art deep learning segmentation models, including convolutional neural networks (U-Net, DeepLabV3+), a Vision Transformer (SegFormer), and recent foundation models (SAM, MedSAM, MedSAM+UNet), on a limited dataset of cardiovascular histology images. Despite employing an extensive hyperparameter optimization strategy with Bayesian search, our findings reveal that model performance is highly sensitive to data splits, with minor differences driven more by statistical noise than by true algorithmic superiority. This instability exposes the limitations of standard benchmarking practices in low-data clinical settings and challenges the assumption that performance rankings reflect meaningful clinical utility.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ†å‰²ç»„ç»‡ç—…ç†å­¦å›¾åƒä¸­é¢ˆåŠ¨è„‰ç»“æ„çš„æŒ‘æˆ˜ã€‚ç ”ç©¶äººå‘˜åœ¨æœ‰é™çš„å¿ƒè¡€ç®¡ç»„ç»‡å­¦æ•°æ®é›†ä¸Šï¼Œç³»ç»Ÿè¯„ä¼°äº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆU-Netã€DeepLabV3+ï¼‰ã€Vision Transformerï¼ˆSegFormerï¼‰ä»¥åŠåŸºç¡€æ¨¡å‹ï¼ˆSAMã€MedSAMã€MedSAM+UNetï¼‰çš„æ€§èƒ½ã€‚å°½ç®¡é‡‡ç”¨äº†åŸºäº Bayesian search çš„å¹¿æ³›è¶…å‚æ•°ä¼˜åŒ–ç­–ç•¥ï¼Œå®éªŒç»“æœä»æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½å¯¹æ•°æ®åˆ’åˆ†ï¼ˆdata splitsï¼‰å…·æœ‰æé«˜çš„æ•æ„Ÿæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œä¸åŒæ¨¡å‹é—´çš„å¾®å°æ€§èƒ½å·®å¼‚æ›´å¤šæºäºç»Ÿè®¡å™ªå£°è€ŒéçœŸå®çš„ç®—æ³•ä¼˜è¶Šæ€§ã€‚è¿™ç§ä¸ç¨³å®šæ€§æ­ç¤ºäº†åœ¨ä½æ•°æ®é‡ä¸´åºŠåœºæ™¯ä¸‹ï¼Œæ ‡å‡†åŸºå‡†æµ‹è¯•ï¼ˆbenchmarkingï¼‰å®è·µå­˜åœ¨æ˜æ˜¾çš„å±€é™æ€§ã€‚è¯¥å‘ç°æŒ‘æˆ˜äº†æ€§èƒ½æ’åèƒ½å¤Ÿåæ˜ å®é™…ä¸´åºŠåº”ç”¨ä»·å€¼çš„ä¼ ç»Ÿå‡è®¾ï¼Œä¸ºåŒ»å­¦å½±åƒç ”ç©¶ä¸­çš„æ¨¡å‹è¯„ä¼°æä¾›äº†å®¡æ…çš„åŸºå‡†è§†è§’ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05892v1",
      "published_date": "2025-09-07 01:54:20 UTC",
      "updated_date": "2025-09-07 01:54:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:08.968161+00:00"
    },
    {
      "arxiv_id": "2509.05890v2",
      "title": "Quantum spatial best-arm identification via quantum walks",
      "title_zh": "åŸºäºé‡å­æ¼«æ­¥çš„é‡å­ç©ºé—´æœ€ä½³è‡‚è¯†åˆ«",
      "authors": [
        "Tomoki Yamagami",
        "Etsuo Segawa",
        "Takatomo Mihana",
        "AndrÃ© RÃ¶hm",
        "Atsushi Uchida",
        "Ryoichi Horisaki"
      ],
      "abstract": "Quantum reinforcement learning has emerged as a framework combining quantum computation with sequential decision-making, and applications to the multi-armed bandit (MAB) problem have been reported. The graph bandit problem extends the MAB setting by introducing spatial constraints, yet quantum approaches remain limited. We propose a quantum algorithmic framework for best-arm identification in graph bandits, termed Quantum Spatial Best-Arm Identification (QSBAI), which is applicable to general graph structures. The method employs quantum walks to encode superpositions over graph-constrained actions, extending amplitude amplification and generalizing the Quantum BAI algorithm via Szegedy's walk framework. This establishes a link between Grover-type search and reinforcement learning tasks with structural restrictions. We focus our theoretical analysis on complete and bipartite graphs, deriving the maximal success probability of identifying the best arm and the time step at which it is achieved. Our results highlight the potential of quantum walks to accelerate exploration in constrained environments and extend the applicability of quantum algorithms for decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¸¦æœ‰ç©ºé—´é™åˆ¶çš„å›¾å¤šè‡‚è€è™æœº(Graph Bandit)é—®é¢˜ï¼Œæå‡ºäº†åä¸ºQuantum Spatial Best-Arm Identification (QSBAI)çš„é‡å­ç®—æ³•æ¡†æ¶ï¼Œæ—¨åœ¨å¡«è¡¥å›¾ç»“æ„ä¸‹é‡å­å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„ç©ºç™½ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é‡å­èµ°ä½(Quantum Walks)å¯¹å›¾é™åˆ¶ä¸‹çš„åŠ¨ä½œè¿›è¡Œå åŠ ç¼–ç ï¼Œå¹¶ç»“åˆSzegedy's walkæ¡†æ¶æ‰©å±•äº†æŒ¯å¹…æ”¾å¤§(Amplitude Amplification)æŠ€æœ¯ï¼Œä»è€Œæ¨å¹¿äº†ç°æœ‰çš„Quantum BAIç®—æ³•ã€‚è¿™é¡¹å·¥ä½œåœ¨Grover-type searchä¸å…·æœ‰ç»“æ„é™åˆ¶çš„å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ä¹‹é—´å»ºç«‹äº†ç†è®ºè”ç³»ï¼Œå¹¶é‡ç‚¹åˆ†æäº†ç®—æ³•åœ¨å®Œå…¨å›¾(Complete Graphs)å’ŒäºŒéƒ¨å›¾(Bipartite Graphs)ä¸Šçš„è¡¨ç°ã€‚é€šè¿‡æ¨å¯¼è¯†åˆ«æœ€ä½³è‡‚çš„æœ€å¤§æˆåŠŸæ¦‚ç‡åŠå…¶è¾¾æˆæ‰€éœ€çš„æ—¶é—´æ­¥é•¿ï¼Œç ”ç©¶è¯æ˜äº†é‡å­èµ°ä½èƒ½å¤Ÿæœ‰æ•ˆåŠ é€Ÿå—é™ç¯å¢ƒä¸­çš„æ¢ç´¢è¿‡ç¨‹ã€‚è¯¥æˆæœä¸ä»…æå‡äº†é‡å­ç®—æ³•åœ¨å†³ç­–ä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ï¼Œä¹Ÿä¸ºé‡å­å¼ºåŒ–å­¦ä¹ åœ¨å¤æ‚æ‹“æ‰‘ç»“æ„ä¸‹çš„åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "math-ph"
      ],
      "primary_category": "quant-ph",
      "comment": "15 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05890v2",
      "published_date": "2025-09-07 01:53:09 UTC",
      "updated_date": "2026-01-19 06:46:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:09.169043+00:00"
    },
    {
      "arxiv_id": "2509.10544v1",
      "title": "ASL360: AI-Enabled Adaptive Streaming of Layered 360Â° Video over UAV-assisted Wireless Networks",
      "title_zh": "ASL360ï¼šæ— äººæœºè¾…åŠ©æ— çº¿ç½‘ç»œä¸­åˆ†å±‚360Â°è§†é¢‘çš„AIèµ‹èƒ½è‡ªé€‚åº”æµä¼ è¾“",
      "authors": [
        "Alireza Mohammadhosseini",
        "Jacob Chakareski",
        "Nicholas Mastronarde"
      ],
      "abstract": "We propose ASL360, an adaptive deep reinforcement learning-based scheduler for on-demand 360Â° video streaming to mobile VR users in next generation wireless networks. We aim to maximize the overall Quality of Experience (QoE) of the users served over a UAV-assisted 5G wireless network. Our system model comprises a macro base station (MBS) and a UAV-mounted base station which both deploy mm-Wave transmission to the users. The 360Â° video is encoded into dependent layers and segmented tiles, allowing a user to schedule downloads of each layer's segments. Furthermore, each user utilizes multiple buffers to store the corresponding video layer's segments. We model the scheduling decision as a Constrained Markov Decision Process (CMDP), where the agent selects Base or Enhancement layers to maximize the QoE and use a policy gradient-based method (PPO) to find the optimal policy. Additionally, we implement a dynamic adjustment mechanism for cost components, allowing the system to adaptively balance and prioritize the video quality, buffer occupancy, and quality change based on real-time network and streaming session conditions. We demonstrate that ASL360 significantly improves the QoE, achieving approximately 2 dB higher average video quality, 80% lower average rebuffering time, and 57% lower video quality variation, relative to competitive baseline methods. Our results show the effectiveness of our layered and adaptive approach in enhancing the QoE in immersive videostreaming applications, particularly in dynamic and challenging network environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ASL360ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning)çš„è‡ªé€‚åº”è°ƒåº¦å™¨ï¼Œæ—¨åœ¨ä¼˜åŒ–æ— äººæœº(UAV)è¾…åŠ©æ— çº¿ç½‘ç»œä¸­çš„360Â°è§†é¢‘ç‚¹æ’­æµä¼ è¾“ä½“éªŒè´¨é‡(QoE)ã€‚ç³»ç»Ÿæ¨¡å‹ç”±å®åŸºç«™(MBS)å’Œæ­è½½æ¯«ç±³æ³¢(mm-Wave)ä¼ è¾“æŠ€æœ¯çš„æ— äººæœºåŸºç«™ç»„æˆï¼Œå…±åŒä¸ºç§»åŠ¨VRç”¨æˆ·æä¾›æœåŠ¡ã€‚è¯¥æ–¹æ³•å°†360Â°è§†é¢‘ç¼–ç ä¸ºä¾èµ–å±‚(Layered)å’Œåˆ†å—åˆ‡ç‰‡(Tiles)ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡å¤šç¼“å†²åŒº(Multiple Buffers)è°ƒåº¦å¹¶å­˜å‚¨å„å±‚è§†é¢‘åˆ†æ®µã€‚ç ”ç©¶å°†è°ƒåº¦å†³ç­–å»ºæ¨¡ä¸ºå—é™é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(CMDP)ï¼Œå¹¶åˆ©ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)ç®—æ³•æ±‚è§£æœ€ä¼˜ç­–ç•¥ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿå¼•å…¥äº†åŠ¨æ€è°ƒæ•´æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®å®æ—¶ç½‘ç»œç¯å¢ƒè‡ªé€‚åº”å¹³è¡¡è§†é¢‘è´¨é‡ã€ç¼“å†²åŒºçŠ¶æ€åŠè´¨é‡ç¨³å®šæ€§ã€‚å®éªŒè¯æ˜ï¼ŒASL360æ¯”åŸºçº¿æ–¹æ³•åœ¨å¹³å‡è§†é¢‘è´¨é‡ä¸Šæå‡äº†çº¦2 dBï¼Œé‡æ–°ç¼“å†²æ—¶é—´é™ä½äº†80%ï¼Œä¸”è§†é¢‘è´¨é‡æ³¢åŠ¨å‡å°‘äº†57%ã€‚è¯¥ç ”ç©¶éªŒè¯äº†åˆ†å±‚è‡ªé€‚åº”æ–¹æ¡ˆåœ¨åŠ¨æ€ä¸”å…·æŒ‘æˆ˜æ€§çš„ç½‘ç»œç¯å¢ƒä¸‹å¢å¼ºæ²‰æµ¸å¼è§†é¢‘æµä¼ è¾“æ€§èƒ½çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.NI",
      "comment": "This paper has been accepted for presentation at the IEEE Global Communications Conference (GLOBECOM) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.10544v1",
      "published_date": "2025-09-07 01:22:57 UTC",
      "updated_date": "2025-09-07 01:22:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:22.876123+00:00"
    },
    {
      "arxiv_id": "2509.07017v1",
      "title": "From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning",
      "title_zh": "ä»ç‰¹å¾æ¨¡æ€åˆ°è¯æ˜ï¼šèåˆå›¾è°±ç®—å­ä¸ç¬¦å·åŒ–å¯è§£é‡Šæ¨ç†",
      "authors": [
        "Andrew Kiruluta",
        "Priscilla Burity"
      ],
      "abstract": "We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning framework that embeds logical rules as spectral templates and performs inference directly in the graph spectral domain. By leveraging graph signal processing (GSP) and frequency-selective filters grounded in the Laplacian eigenstructure of knowledge graphs, the architecture unifies the interpretability of symbolic reasoning with the scalability and adaptability of spectral learning. Beyond the core formulation, we incorporate a comprehensive set of extensions, including dynamic graph and basis learning, rational and diffusion filters for sharper spectral selectivity, mixture-of-spectral-experts for modular specialization, proof-guided training with spectral curricula, and uncertainty quantification for calibrated confidence. Additional enhancements such as large language model coupling, co-spectral transfer alignment, adversarial robustness, efficient GPU kernels, generalized Laplacians, and causal interventions further expand the versatility of the framework.\n  Empirical evaluation on state-of-the-art reasoning benchmarks such as ProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior accuracy, faster inference, improved robustness to adversarial perturbations, and higher interpretability compared to leading baselines including transformers, message-passing neural networks, and neuro-symbolic logic programming systems. Spectral attribution and proof-band agreement analyses confirm that model decisions align closely with symbolic proof structures, while transfer experiments validate effective domain adaptation through co-spectral alignment. These results establish Spectral NSR as a scalable and principled foundation for the next generation of reasoning systems, offering transparency, robustness, and generalization beyond conventional approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Spectral NSRï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨è°±ç¥ç»ç¬¦å·æ¨ç†æ¡†æ¶ (neuro-symbolic reasoning framework)ï¼Œæ—¨åœ¨å°†é€»è¾‘è§„åˆ™åµŒå…¥ä¸ºè°±æ¨¡æ¿ (spectral templates) å¹¶ç›´æ¥åœ¨å›¾è°±åŸŸ (graph spectral domain) ä¸­æ‰§è¡Œæ¨ç†ã€‚è¯¥æ¶æ„åˆ©ç”¨å›¾ä¿¡å·å¤„ç† (GSP) å’ŒåŸºäºçŸ¥è¯†å›¾è°±æ‹‰æ™®æ‹‰æ–¯ç‰¹å¾ç»“æ„ (Laplacian eigenstructure) çš„é¢‘é€‰æ»¤æ³¢å™¨ï¼ŒæˆåŠŸå°†ç¬¦å·æ¨ç†çš„å¯è§£é‡Šæ€§ä¸è°±å­¦ä¹ çš„å¯æ‰©å±•æ€§åŠè‡ªé€‚åº”æ€§ç›¸ç»Ÿä¸€ã€‚é™¤äº†æ ¸å¿ƒå…¬å¼å¤–ï¼Œè¯¥æ¡†æ¶è¿˜é›†æˆäº†åŠ¨æ€å›¾ä¸åŸºåº•å­¦ä¹ ã€æœ‰ç†ä¸æ‰©æ•£æ»¤æ³¢å™¨ã€è°±ä¸“å®¶æ··åˆ (mixture-of-spectral-experts) ä»¥åŠè¯æ˜å¼•å¯¼è®­ç»ƒç­‰å¢å¼ºåŠŸèƒ½ã€‚åœ¨ ProofWriter å’Œ CLUTRR ç­‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSpectral NSR åœ¨å‡†ç¡®ç‡ã€æ¨ç†é€Ÿåº¦ã€å¯¹æŠ—æ‰°åŠ¨é²æ£’æ€§ä»¥åŠå¯è§£é‡Šæ€§æ–¹é¢å‡ä¼˜äº Transformer å’Œæ¶ˆæ¯ä¼ é€’ç¥ç»ç½‘ç»œ (MPNNs) ç­‰ä¸»æµåŸºå‡†æ¨¡å‹ã€‚è°±å½’å›  (Spectral attribution) å’Œè¯æ˜å¸¦ä¸€è‡´æ€§åˆ†æè¯å®ï¼Œè¯¥æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ä¸ç¬¦å·è¯æ˜ç»“æ„é«˜åº¦å»åˆã€‚è¿™äº›ç»“æœè¯æ˜äº† Spectral NSR ä½œä¸ºä¸‹ä¸€ä»£æ¨ç†ç³»ç»ŸåŸºç¡€çš„æ½œåŠ›ï¼Œä¸ºå¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æä¾›äº†å…·å¤‡é€æ˜åº¦å’Œæ³›åŒ–èƒ½åŠ›çš„åŸåˆ™æ€§æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07017v1",
      "published_date": "2025-09-07 01:12:20 UTC",
      "updated_date": "2025-09-07 01:12:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:23.576194+00:00"
    },
    {
      "arxiv_id": "2509.05883v1",
      "title": "Multimodal Prompt Injection Attacks: Risks and Defenses for Modern LLMs",
      "title_zh": "å¤šæ¨¡æ€æç¤ºæ³¨å…¥æ”»å‡»ï¼šç°ä»£å¤§è¯­è¨€æ¨¡å‹çš„é£é™©ä¸é˜²å¾¡",
      "authors": [
        "Andrew Yeo",
        "Daeseon Choi"
      ],
      "abstract": "Large Language Models (LLMs) have seen rapid adoption in recent years, with industries increasingly relying on them to maintain a competitive advantage. These models excel at interpreting user instructions and generating human-like responses, leading to their integration across diverse domains, including consulting and information retrieval. However, their widespread deployment also introduces substantial security risks, most notably in the form of prompt injection and jailbreak attacks.\n  To systematically evaluate LLM vulnerabilities -- particularly to external prompt injection -- we conducted a series of experiments on eight commercial models. Each model was tested without supplementary sanitization, relying solely on its built-in safeguards. The results exposed exploitable weaknesses and emphasized the need for stronger security measures. Four categories of attacks were examined: direct injection, indirect (external) injection, image-based injection, and prompt leakage. Comparative analysis indicated that Claude 3 demonstrated relatively greater robustness; nevertheless, empirical findings confirm that additional defenses, such as input normalization, remain necessary to achieve reliable protection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£å¤§è¯­è¨€æ¨¡å‹ (LLMs) é¢ä¸´çš„å¤šæ¨¡æ€æç¤ºæ³¨å…¥æ”»å‡» (Multimodal Prompt Injection Attacks) é£é™©ï¼Œå¯¹å…«ä¸ªä¸»æµå•†ç”¨æ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿçš„å®‰å…¨æ€§è¯„ä¼°ã€‚é€šè¿‡åœ¨ä»…ä¾èµ–å†…ç½®é˜²å¾¡çš„æƒ…å†µä¸‹æµ‹è¯•ç›´æ¥æ³¨å…¥ (Direct Injection)ã€é—´æ¥æ³¨å…¥ (Indirect Injection)ã€åŸºäºå›¾åƒçš„æ³¨å…¥ (Image-based Injection) åŠæç¤ºæ³„éœ² (Prompt Leakage) å››ç±»æ”»å‡»æ–¹å¼ï¼Œå®éªŒæ­ç¤ºäº†æ¨¡å‹ä¸­æ™®éå­˜åœ¨çš„è„†å¼±æ€§ã€‚è™½ç„¶å¯¹æ¯”åˆ†ææ˜¾ç¤º Claude 3 å…·æœ‰ç›¸å¯¹æ›´é«˜çš„é²æ£’æ€§ (Robustness)ï¼Œä½†æ‰€æœ‰æµ‹è¯•æ¨¡å‹å‡è¡¨ç°å‡ºå¯è¢«åˆ©ç”¨çš„æ¼æ´ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†å¼ºåŒ–å®‰å…¨æªæ–½çš„ç´§è¿«æ€§ï¼Œå¹¶æŒ‡å‡ºå•çº¯ä¾èµ–æ¨¡å‹å†…ç½®é˜²æŠ¤ä¸è¶³ä»¥åº”å¯¹å¤æ‚çš„å¤–éƒ¨æ”»å‡»ã€‚ä½œè€…æœ€åå»ºè®®ï¼Œå¿…é¡»ç»“åˆè¾“å…¥è§„èŒƒåŒ– (Input Normalization) ç­‰é¢å¤–é˜²å¾¡æ‰‹æ®µï¼Œæ‰èƒ½ä¸º LLMs æä¾›æ›´å¯é çš„å®‰å…¨ä¿éšœã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 4 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.05883v1",
      "published_date": "2025-09-07 01:11:10 UTC",
      "updated_date": "2025-09-07 01:11:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:29.870768+00:00"
    },
    {
      "arxiv_id": "2509.05882v2",
      "title": "Collaborate, Deliberate, Evaluate: How LLM Alignment Affects Coordinated Multi-Agent Outcomes",
      "title_zh": "åä½œã€å®¡è®®ä¸è¯„ä¼°ï¼šå¤§è¯­è¨€æ¨¡å‹å¯¹é½å¯¹å¤šæ™ºèƒ½ä½“åä½œæˆæœçš„å½±å“",
      "authors": [
        "Abhijnan Nath",
        "Carine Graff",
        "Nikhil Krishnaswamy"
      ],
      "abstract": "As Large Language Models (LLMs) get integrated into diverse workflows, they are increasingly being regarded as \"collaborators\" with humans, and required to work in coordination with other AI systems. If such AI collaborators are to reliably coordinate their actions and behaviors with humans or other AIs, their properties and behaviors over multi-turn interactions must be known and predictable. This paper examines how different alignment methods affect LLM agents' effectiveness as partners in multi-turn, multi-party collaborations. We study this question through the lens of intervention agents that insert themselves into group dialogues not to provide answers, but to encourage the collaborative group to slow down and reflect upon their reasoning for deliberative decision-making. Common alignment techniques are typically developed under simplified single-user settings and assume the optimality of the underlying token MDP. Using the theoretical lens of the modified-action MDP, we show how they do not account for the dynamics of long-horizon multi-party interactions. We present a novel roleplay simulation methodology, where we align LLMs according to different methods and then deploy them in collaborative task dialogues to quantify how interventions affect the trajectory of group collaboration, belief alignment, and coordination. Our results show that an intervention agent that is robust to action modification significantly outperforms common alignment baselines in supporting correct task outcomes.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤šè½®ã€å¤šæ–¹åä½œä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯å¯¹é½æ–¹æ³•(Alignment Methods)å¦‚ä½•å½±å“å…¶ä½œä¸ºåˆä½œä¼™ä¼´çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¹²é¢„æ™ºèƒ½ä½“(Intervention Agents)çš„è§†è§’ï¼Œåˆ†æäº†è¿™äº›æ™ºèƒ½ä½“å¦‚ä½•å¼•å¯¼å›¢é˜Ÿè¿›è¡Œå®¡æ…å†³ç­–å’Œåæ€ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œä¼ ç»Ÿçš„å¯¹é½æŠ€æœ¯ä¸»è¦é’ˆå¯¹å•ç”¨æˆ·åœºæ™¯ï¼Œæœªèƒ½å……åˆ†è€ƒè™‘å¤šæ–¹äº¤äº’ä¸­é•¿æ—¶ç¨‹(Long-horizon)çš„åŠ¨æ€å˜åŒ–ã€‚åŸºäºä¿®æ”¹è¡ŒåŠ¨é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Modified-action MDP)çš„ç†è®ºæ¡†æ¶ï¼Œç ”ç©¶æ­ç¤ºäº†ç°æœ‰å¯¹é½æ–¹æ³•åœ¨å¤šæ™ºèƒ½ä½“åè°ƒä¸­çš„å±€é™æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§’è‰²æ‰®æ¼”æ¨¡æ‹Ÿæ–¹æ³•(Roleplay Simulation Methodology)ï¼Œç”¨äºé‡åŒ–ä¸åŒå¯¹é½æ–¹å¼ä¸‹çš„å¹²é¢„å¯¹å›¢é˜Ÿåä½œè½¨è¿¹ã€ä¿¡å¿µå¯¹é½(Belief Alignment)åŠåè°ƒæ•ˆæœçš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¯¹è¡ŒåŠ¨ä¿®æ”¹å…·æœ‰é²æ£’æ€§çš„å¹²é¢„æ™ºèƒ½ä½“åœ¨æ”¯æŒæ­£ç¡®ä»»åŠ¡ç»“æœæ–¹é¢ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å¯¹é½åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This submission is a new version of arXiv:2509.05882v1. with a substantially revised experimental pipeline and new metrics. In particular, collaborator agents are now instantiated independently via separate API calls, rather than generated autoregressively by a single agent. All experimental results are new. Accepted as an extended abstract at AAMAS 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.05882v2",
      "published_date": "2025-09-07 00:58:10 UTC",
      "updated_date": "2026-01-21 21:29:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:31.752377+00:00"
    },
    {
      "arxiv_id": "2509.05881v1",
      "title": "GeoAnalystBench: A GeoAI benchmark for assessing large language models for spatial analysis workflow and code generation",
      "title_zh": "GeoAnalystBenchï¼šç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ç©ºé—´åˆ†æå·¥ä½œæµä¸ä»£ç ç”Ÿæˆèƒ½åŠ›çš„ GeoAI åŸºå‡†æµ‹è¯•",
      "authors": [
        "Qianheng Zhang",
        "Song Gao",
        "Chen Wei",
        "Yibo Zhao",
        "Ying Nie",
        "Ziru Chen",
        "Shijie Chen",
        "Yu Su",
        "Huan Sun"
      ],
      "abstract": "Recent advances in large language models (LLMs) have fueled growing interest in automating geospatial analysis and GIS workflows, yet their actual capabilities remain uncertain. In this work, we call for rigorous evaluation of LLMs on well-defined geoprocessing tasks before making claims about full GIS automation. To this end, we present GeoAnalystBench, a benchmark of 50 Python-based tasks derived from real-world geospatial problems and carefully validated by GIS experts. Each task is paired with a minimum deliverable product, and evaluation covers workflow validity, structural alignment, semantic similarity, and code quality (CodeBLEU). Using this benchmark, we assess both proprietary and open source models. Results reveal a clear gap: proprietary models such as ChatGPT-4o-mini achieve high validity 95% and stronger code alignment (CodeBLEU 0.39), while smaller open source models like DeepSeek-R1-7B often generate incomplete or inconsistent workflows (48.5% validity, 0.272 CodeBLEU). Tasks requiring deeper spatial reasoning, such as spatial relationship detection or optimal site selection, remain the most challenging across all models. These findings demonstrate both the promise and limitations of current LLMs in GIS automation and provide a reproducible framework to advance GeoAI research with human-in-the-loop support.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GeoAnalystBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«50ä¸ªåŸºäºPythonä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨åœ°ç†ç©ºé—´åˆ†æå·¥ä½œæµå’Œä»£ç ç”Ÿæˆæ–¹é¢çš„å®é™…èƒ½åŠ›ã€‚è¿™äº›ä»»åŠ¡æºè‡ªçœŸå®çš„åœ°ç†ç©ºé—´é—®é¢˜å¹¶ç»GISä¸“å®¶éªŒè¯ï¼Œè¯„ä¼°ç»´åº¦æ¶µç›–äº†å·¥ä½œæµæœ‰æ•ˆæ€§ã€ç»“æ„å¯¹é½ã€è¯­ä¹‰ç›¸ä¼¼åº¦åŠä»£ç è´¨é‡(CodeBLEU)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä»¥ChatGPT-4o-miniä¸ºä»£è¡¨çš„ç§æœ‰æ¨¡å‹åœ¨æœ‰æ•ˆæ€§å’Œä»£ç å¯¹é½æ–¹é¢æ˜¾è‘—ä¼˜äºå°å‹å¼€æºæ¨¡å‹ï¼Œåè€…å¸¸å‡ºç°å·¥ä½œæµä¸å®Œæ•´æˆ–ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œæ¶‰åŠæ·±åº¦ç©ºé—´æ¨ç†çš„ä»»åŠ¡ï¼Œå¦‚ç©ºé—´å…³ç³»æ£€æµ‹æˆ–æœ€ä½³é€‰å€(optimal site selection)ï¼Œå¯¹å½“å‰æ‰€æœ‰æ¨¡å‹è€Œè¨€ä»å…·æŒ‘æˆ˜æ€§ã€‚è¯¥åŸºå‡†æµ‹è¯•æ­ç¤ºäº†LLMsåœ¨GISè‡ªåŠ¨åŒ–é¢†åŸŸçš„æ½œåŠ›ä¸å±€é™ï¼Œå¹¶ä¸ºæ¨åŠ¨å¸¦æœ‰äººæœºååŒæ”¯æŒçš„GeoAIç ”ç©¶æä¾›äº†ä¸€ä¸ªå¯é‡å¤çš„è¯„ä¼°æ¡†æ¶ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "34 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05881v1",
      "published_date": "2025-09-07 00:51:57 UTC",
      "updated_date": "2025-09-07 00:51:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:35.881529+00:00"
    },
    {
      "arxiv_id": "2509.05877v2",
      "title": "Uncertainty Quantification in Probabilistic Machine Learning Models: Theory, Methods, and Insights",
      "title_zh": "æ¦‚ç‡æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼šç†è®ºã€æ–¹æ³•ä¸è§è§£",
      "authors": [
        "Marzieh Ajirak",
        "Anand Ravishankar",
        "Petar M. Djuric"
      ],
      "abstract": "Uncertainty Quantification (UQ) is essential in probabilistic machine learning models, particularly for assessing the reliability of predictions. In this paper, we present a systematic framework for estimating both epistemic and aleatoric uncertainty in probabilistic models. We focus on Gaussian Process Latent Variable Models and employ scalable Random Fourier Features-based Gaussian Processes to approximate predictive distributions efficiently. We derive a theoretical formulation for UQ, propose a Monte Carlo sampling-based estimation method, and conduct experiments to evaluate the impact of uncertainty estimation. Our results provide insights into the sources of predictive uncertainty and illustrate the effectiveness of our approach in quantifying the confidence in the predictions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¦‚ç‡æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)å±•å¼€æ¢è®¨ï¼Œæ—¨åœ¨æé«˜é¢„æµ‹ç»“æœçš„å¯é æ€§ã€‚è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°æ¦‚ç‡æ¨¡å‹ä¸­çš„è®¤çŸ¥ä¸ç¡®å®šæ€§(epistemic uncertainty)å’Œå¶ç„¶ä¸ç¡®å®šæ€§(aleatoric uncertainty)ã€‚ç ”ç©¶é‡ç‚¹å…³æ³¨é«˜æ–¯è¿‡ç¨‹æ½œåœ¨å˜é‡æ¨¡å‹(Gaussian Process Latent Variable Models)ï¼Œå¹¶é‡‡ç”¨å¯æ‰©å±•çš„åŸºäºéšæœºå‚…é‡Œå¶ç‰¹å¾(Random Fourier Features)çš„é«˜æ–¯è¿‡ç¨‹æ¥é«˜æ•ˆè¿‘ä¼¼é¢„æµ‹åˆ†å¸ƒã€‚é€šè¿‡æ¨å¯¼UQçš„ç†è®ºå…¬å¼å¹¶ç»“åˆè’™ç‰¹å¡æ´›(Monte Carlo)é‡‡æ ·ä¼°è®¡æ–¹æ³•ï¼Œè¯¥ç ”ç©¶æ·±å…¥åˆ†æäº†é¢„æµ‹ä¸ç¡®å®šæ€§çš„æ¥æºã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨é‡åŒ–é¢„æµ‹ç½®ä¿¡åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºç†è§£å’Œæå‡æ¦‚ç‡æ¨¡å‹çš„é¢„æµ‹é€æ˜åº¦æä¾›äº†ç†è®ºæ”¯æ’‘ä¸å®è·µå·¥å…·ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted to EUSIPCO 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.05877v2",
      "published_date": "2025-09-07 00:38:33 UTC",
      "updated_date": "2025-09-10 17:02:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:39.363659+00:00"
    },
    {
      "arxiv_id": "2509.10543v1",
      "title": "Robust DDoS-Attack Classification with 3D CNNs Against Adversarial Methods",
      "title_zh": "åŸºäº 3D å·ç§¯ç¥ç»ç½‘ç»œçš„æŠ—å¯¹æŠ—æ€§ DDoS æ”»å‡»ç¨³å¥åˆ†ç±»",
      "authors": [
        "Landon Bragg",
        "Nathan Dorsey",
        "Josh Prior",
        "John Ajit",
        "Ben Kim",
        "Nate Willis",
        "Pablo Rivas"
      ],
      "abstract": "Distributed Denial-of-Service (DDoS) attacks remain a serious threat to online infrastructure, often bypassing detection by altering traffic in subtle ways. We present a method using hive-plot sequences of network data and a 3D convolutional neural network (3D CNN) to classify DDoS traffic with high accuracy. Our system relies on three main ideas: (1) using spatio-temporal hive-plot encodings to set a pattern-recognition baseline, (2) applying adversarial training with FGSM and PGD alongside spatial noise and image shifts, and (3) analyzing frame-wise predictions to find early signals. On a benchmark dataset, our method lifts adversarial accuracy from 50-55% to over 93% while maintaining clean-sample performance. Frames 3-4 offer strong predictive signals, showing early-stage classification is possible.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ†å¸ƒå¼æ‹’ç»æœåŠ¡(DDoS)æ”»å‡»é€šè¿‡å¾®è°ƒæµé‡è§„é¿æ£€æµ‹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆhive-plotåºåˆ—ä¸3Då·ç§¯ç¥ç»ç½‘ç»œ(3D CNN)çš„é«˜ç²¾åº¦åˆ†ç±»æ–¹æ³•ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æ—¶ç©º(spatio-temporal) hive-plotç¼–ç å»ºç«‹äº†æ¨¡å¼è¯†åˆ«åŸºå‡†ï¼Œä»è€Œæœ‰æ•ˆæ•æ‰ç½‘ç»œæ•°æ®ä¸­çš„å…³é”®ç‰¹å¾ã€‚ä¸ºäº†å¢å¼ºé²æ£’æ€§ï¼Œç ”ç©¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥äº†å¿«é€Ÿæ¢¯åº¦ç¬¦å·æ³•(FGSM)å’ŒæŠ•å½±æ¢¯åº¦ä¸‹é™(PGD)ç­‰å¯¹æŠ—æ€§è®­ç»ƒ(adversarial training)ï¼Œå¹¶ç»“åˆäº†ç©ºé—´å™ªå£°å’Œå›¾åƒå¹³ç§»æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆ†æå¸§çº§åˆ«(frame-wise)çš„é¢„æµ‹ç»“æœï¼Œç ”ç©¶äººå‘˜æˆåŠŸè¯†åˆ«å‡ºäº†æµé‡ä¸­çš„æ—©æœŸé¢„è­¦ä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šå°†å¯¹æŠ—æ€§ç¯å¢ƒä¸‹çš„å‡†ç¡®ç‡ä»50-55%æ˜¾è‘—æå‡è‡³93%ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†å¯¹æ¸…æ´æ ·æœ¬çš„é«˜æ•ˆåˆ†ç±»æ€§èƒ½ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œç¬¬3-4å¸§å³å¯æä¾›å¼ºæœ‰åŠ›çš„é¢„æµ‹ä¿¡å·ï¼Œè¯æ˜äº†åœ¨æ”»å‡»æ—©æœŸé˜¶æ®µè¿›è¡Œåˆ†ç±»å¹¶å®ç°ä¸»åŠ¨é˜²å¾¡çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "The 27th International Conference on Artificial Intelligence (ICAI'25)",
      "pdf_url": "https://arxiv.org/pdf/2509.10543v1",
      "published_date": "2025-09-07 00:20:32 UTC",
      "updated_date": "2025-09-07 00:20:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:43.953737+00:00"
    },
    {
      "arxiv_id": "2509.05874v1",
      "title": "Learning to Construct Knowledge through Sparse Reference Selection with Reinforcement Learning",
      "title_zh": "åŸºäºå¼ºåŒ–å­¦ä¹ çš„ç¨€ç–æ–‡çŒ®ç­›é€‰ä¸çŸ¥è¯†æ„å»ºå­¦ä¹ ",
      "authors": [
        "Shao-An Yin"
      ],
      "abstract": "The rapid expansion of scientific literature makes it increasingly difficult to acquire new knowledge, particularly in specialized domains where reasoning is complex, full-text access is restricted, and target references are sparse among a large set of candidates. We present a Deep Reinforcement Learning framework for sparse reference selection that emulates human knowledge construction, prioritizing which papers to read under limited time and cost. Evaluated on drug--gene relation discovery with access restricted to titles and abstracts, our approach demonstrates that both humans and machines can construct knowledge effectively from partial information.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç§‘å­¦æ–‡çŒ®å¿«é€Ÿæ‰©å¼ å¸¦æ¥çš„çŸ¥è¯†è·å–éš¾é¢˜ï¼Œç‰¹åˆ«æ˜¯å¤æ‚æ¨ç†ã€å…¨æ–‡å—é™ä»¥åŠåœ¨æµ·é‡å€™é€‰æ–‡çŒ®ä¸­ç›®æ ‡å‚è€ƒæ–‡çŒ®ç¨€ç–çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹  (Deep Reinforcement Learning) çš„ç¨€ç–å‚è€ƒé€‰æ‹©æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨æ¨¡æ‹Ÿäººç±»æ„å»ºçŸ¥è¯†çš„è¿‡ç¨‹ï¼Œåœ¨æœ‰é™çš„æ—¶é—´å’Œæˆæœ¬çº¦æŸä¸‹ï¼Œèƒ½å¤Ÿæ™ºèƒ½åœ°ä¼˜å…ˆé€‰æ‹©æœ€å…·ä»·å€¼çš„è®ºæ–‡è¿›è¡Œé˜…è¯»ã€‚ç ”ç©¶äººå‘˜é€šè¿‡è¯ç‰©ä¸åŸºå› å…³ç³»å‘ç° (drug-gene relation discovery) ä»»åŠ¡å¯¹è¯¥æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒè®¾å®šä¸ºä»…èƒ½è®¿é—®è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ç­‰å±€éƒ¨ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åœ¨ç¨€ç–å¼•ç”¨ç¯å¢ƒä¸­è¿›è¡Œç²¾å‡†çš„æ–‡çŒ®ç­›é€‰ï¼Œè¯æ˜äº†äººç±»å’Œæœºå™¨å‡èƒ½ä»…å‡­éƒ¨åˆ†ä¿¡æ¯é«˜æ•ˆåœ°æ„å»ºä¸“ä¸šé¢†åŸŸçŸ¥è¯†ã€‚è¿™ä¸€ç ”ç©¶ä¸ºåœ¨ä¿¡æ¯è¿‡è½½èƒŒæ™¯ä¸‹è¿›è¡Œé«˜æ•ˆã€ä½æˆæœ¬çš„çŸ¥è¯†æå–ä¸æ„å»ºæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05874v1",
      "published_date": "2025-09-07 00:19:13 UTC",
      "updated_date": "2025-09-07 00:19:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:47.454765+00:00"
    },
    {
      "arxiv_id": "2509.07016v1",
      "title": "Random Forest Stratified K-Fold Cross Validation on SYN DoS Attack SD-IoV",
      "title_zh": "é¢å‘ SD-IoV ä¸­ SYN DoS æ”»å‡»æ£€æµ‹çš„éšæœºæ£®æ—åˆ†å±‚ K æŠ˜äº¤å‰éªŒè¯",
      "authors": [
        "Muhammad Arif Hakimi Zamrai",
        "Kamaludin Mohd Yusof"
      ],
      "abstract": "In response to the prevalent concern of TCP SYN flood attacks within the context of Software-Defined Internet of Vehicles (SD-IoV), this study addresses the significant challenge of network security in rapidly evolving vehicular communication systems. This research focuses on optimizing a Random Forest Classifier model to achieve maximum accuracy and minimal detection time, thereby enhancing vehicular network security. The methodology involves preprocessing a dataset containing SYN attack instances, employing feature scaling and label encoding techniques, and applying Stratified K-Fold cross-validation to target key metrics such as accuracy, precision, recall, and F1-score. This research achieved an average value of 0.999998 for all metrics with a SYN DoS attack detection time of 0.24 seconds. Results show that the fine-tuned Random Forest model, configured with 20 estimators and a depth of 10, effectively differentiates between normal and malicious traffic with high accuracy and minimal detection time, which is crucial for SD-IoV networks. This approach marks a significant advancement and introduces a state-of-the-art algorithm in detecting SYN flood attacks, combining high accuracy with minimal detection time. It contributes to vehicular network security by providing a robust solution against TCP SYN flood attacks while maintaining network efficiency and reliability.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è½¯ä»¶å®šä¹‰è½¦è½½ç½‘(SD-IoV)ä¸­æ™®éå­˜åœ¨çš„TCP SYN floodæ”»å‡»é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä¼˜åŒ–çš„Random Forest Classifieræ¨¡å‹ä»¥å¢å¼ºç½‘ç»œå®‰å…¨ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹åŒ…å«SYNæ”»å‡»å®ä¾‹çš„æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œåº”ç”¨äº†ç‰¹å¾ç¼©æ”¾(feature scaling)å’Œæ ‡ç­¾ç¼–ç (label encoding)æŠ€æœ¯ï¼Œå¹¶é‡‡ç”¨åˆ†å±‚KæŠ˜äº¤å‰éªŒè¯(Stratified K-Fold cross-validation)æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚å®éªŒä¸­ç»è¿‡å¾®è°ƒçš„Random Forestæ¨¡å‹é…ç½®äº†20ä¸ªè¯„ä¼°å™¨(estimators)å’Œ10å±‚æ·±åº¦ï¼Œèƒ½å¤Ÿé«˜æ•ˆåŒºåˆ†æ­£å¸¸æµé‡ä¸æ¶æ„æµé‡ã€‚ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨å‡†ç¡®ç‡ã€ç²¾ç¡®åº¦ã€å¬å›ç‡å’ŒF1å€¼ä¸Šå‡è¾¾åˆ°äº†0.999998çš„å¹³å‡å€¼ï¼Œä¸”SYN DoSæ”»å‡»æ£€æµ‹æ—¶é—´ä»…ä¸º0.24ç§’ã€‚è¿™é¡¹ç ”ç©¶å¼•å…¥äº†ä¸€ç§æœ€å…ˆè¿›çš„æ£€æµ‹ç®—æ³•ï¼Œåœ¨ç»´æŒç½‘ç»œæ•ˆç‡å’Œå¯é æ€§çš„åŒæ—¶ï¼Œä¸ºè½¦è½½ç½‘ç»œå®‰å…¨æä¾›äº†é²æ£’çš„é˜²å¾¡æ‰‹æ®µã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07016v1",
      "published_date": "2025-09-07 00:18:30 UTC",
      "updated_date": "2025-09-07 00:18:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:08:46.668255+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 69,
  "processed_papers_count": 69,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T17:09:42.560813+00:00"
}