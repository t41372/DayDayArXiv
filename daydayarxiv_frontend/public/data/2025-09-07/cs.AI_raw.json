[
  {
    "arxiv_id": "2509.06239v2",
    "title": "Proof2Silicon: Prompt Repair for Verified Code and Hardware Generation via Reinforcement Learning",
    "authors": [
      "Manvi Jha",
      "Jiaxin Wan",
      "Deming Chen"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in automated code generation but frequently produce code that fails formal verification, an essential requirement for hardware and safety-critical domains. To overcome this fundamental limitation, we previously proposed PREFACE, a model-agnostic framework based on reinforcement learning (RL) that iteratively repairs the prompts provided to frozen LLMs, systematically steering them toward generating formally verifiable Dafny code without costly fine-tuning. This work presents Proof2Silicon, a novel end-to-end synthesis framework that embeds the previously proposed PREFACE flow to enable the generation of correctness-by-construction hardware directly from natural language specifications. Proof2Silicon operates by: (1) leveraging PREFACE's verifier-driven RL agent to optimize prompt generation iteratively, ensuring Dafny code correctness; (2) automatically translating verified Dafny programs into synthesizable high-level C using Dafny's Python backend and PyLog; and (3) employing Vivado HLS to produce RTL implementations. Evaluated rigorously on a challenging 100-task benchmark, PREFACE's RL-guided prompt optimization consistently improved Dafny verification success rates across diverse LLMs by up to 21%. Crucially, Proof2Silicon achieved an end-to-end hardware synthesis success rate of up to 72%, generating RTL designs through Vivado HLS synthesis flows. These results demonstrate a robust, scalable, and automated pipeline for LLM-driven, formally verified hardware synthesis, bridging natural-language specification and silicon realization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06239v2",
    "published_date": "2025-09-07 23:04:15 UTC",
    "updated_date": "2025-10-20 22:10:34 UTC"
  },
  {
    "arxiv_id": "2509.06235v1",
    "title": "PillagerBench: Benchmarking LLM-Based Agents in Competitive Minecraft Team Environments",
    "authors": [
      "Olivier Schipper",
      "Yudi Zhang",
      "Yali Du",
      "Mykola Pechenizkiy",
      "Meng Fang"
    ],
    "abstract": "LLM-based agents have shown promise in various cooperative and strategic reasoning tasks, but their effectiveness in competitive multi-agent environments remains underexplored. To address this gap, we introduce PillagerBench, a novel framework for evaluating multi-agent systems in real-time competitive team-vs-team scenarios in Minecraft. It provides an extensible API, multi-round testing, and rule-based built-in opponents for fair, reproducible comparisons. We also propose TactiCrafter, an LLM-based multi-agent system that facilitates teamwork through human-readable tactics, learns causal dependencies, and adapts to opponent strategies. Our evaluation demonstrates that TactiCrafter outperforms baseline approaches and showcases adaptive learning through self-play. Additionally, we analyze its learning process and strategic evolution over multiple game episodes. To encourage further research, we have open-sourced PillagerBench, fostering advancements in multi-agent AI for competitive environments.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "for the source code, see https://github.com/aialt/PillagerBench",
    "pdf_url": "https://arxiv.org/pdf/2509.06235v1",
    "published_date": "2025-09-07 22:51:12 UTC",
    "updated_date": "2025-09-07 22:51:12 UTC"
  },
  {
    "arxiv_id": "2509.10546v1",
    "title": "Uncovering the Vulnerability of Large Language Models in the Financial Domain via Risk Concealment",
    "authors": [
      "Gang Cheng",
      "Haibo Jin",
      "Wenbin Zhang",
      "Haohan Wang",
      "Jun Zhuang"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly integrated into financial applications, yet existing red-teaming research primarily targets harmful content, largely neglecting regulatory risks. In this work, we aim to investigate the vulnerability of financial LLMs through red-teaming approaches. We introduce Risk-Concealment Attacks (RCA), a novel multi-turn framework that iteratively conceals regulatory risks to provoke seemingly compliant yet regulatory-violating responses from LLMs. To enable systematic evaluation, we construct FIN-Bench, a domain-specific benchmark for assessing LLM safety in financial contexts. Extensive experiments on FIN-Bench demonstrate that RCA effectively bypasses nine mainstream LLMs, achieving an average attack success rate (ASR) of 93.18%, including 98.28% on GPT-4.1 and 97.56% on OpenAI o1. These findings reveal a critical gap in current alignment techniques and underscore the urgent need for stronger moderation mechanisms in financial domains. We hope this work offers practical insights for advancing robust and domain-aware LLM alignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint, under review. TL;DR: We propose a multi-turn red-teaming framework, RCA, that reveals critical regulatory vulnerabilities in financial LLMs, achieving over 93% attack success on a proposed new benchmark, FIN-Bench",
    "pdf_url": "https://arxiv.org/pdf/2509.10546v1",
    "published_date": "2025-09-07 22:35:15 UTC",
    "updated_date": "2025-09-07 22:35:15 UTC"
  },
  {
    "arxiv_id": "2509.06227v1",
    "title": "Distillation of CNN Ensemble Results for Enhanced Long-Term Prediction of the ENSO Phenomenon",
    "authors": [
      "Saghar Ganji",
      "Mohammad Naisipour",
      "Alireza Hassani",
      "Arash Adib"
    ],
    "abstract": "The accurate long-term forecasting of the El Nino Southern Oscillation (ENSO) is still one of the biggest challenges in climate science. While it is true that short-to medium-range performance has been improved significantly using the advances in deep learning, statistical dynamical hybrids, most operational systems still use the simple mean of all ensemble members, implicitly assuming equal skill across members. In this study, we demonstrate, through a strictly a-posteriori evaluation , for any large enough ensemble of ENSO forecasts, there is a subset of members whose skill is substantially higher than that of the ensemble mean. Using a state-of-the-art ENSO forecast system cross-validated against the 1986-2017 observed Nino3.4 index, we identify two Top-5 subsets one ranked on lowest Root Mean Square Error (RMSE) and another on highest Pearson correlation. Generally across all leads, these outstanding members show higher correlation and lower RMSE, with the advantage rising enormously with lead time. Whereas at short leads (1 month) raises the mean correlation by about +0.02 (+1.7%) and lowers the RMSE by around 0.14 °C or by 23.3% compared to the All-40 mean, at extreme leads (23 months) the correlation is raised by +0.43 (+172%) and RMSE by 0.18 °C or by 22.5% decrease. The enhancements are largest during crucial ENSO transition periods such as SON and DJF, when accurate amplitude and phase forecasting is of greatest socio-economic benefit, and furthermore season-dependent e.g., mid-year months such as JJA and MJJ have incredibly large RMSE reductions. This study provides a solid foundation for further investigations to identify reliable clues for detecting high-quality ensemble members, thereby enhancing forecasting skill.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.CE",
      "physics.app-ph"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "20 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.06227v1",
    "published_date": "2025-09-07 22:26:42 UTC",
    "updated_date": "2025-09-07 22:26:42 UTC"
  },
  {
    "arxiv_id": "2510.15890v1",
    "title": "A Real-Time BCI for Stroke Hand Rehabilitation Using Latent EEG Features from Healthy Subjects",
    "authors": [
      "F. M. Omar",
      "A. M. Omar",
      "K. H. Eyada",
      "M. Rabie",
      "M. A. Kamel",
      "A. M. Azab"
    ],
    "abstract": "This study presents a real-time, portable brain-computer interface (BCI) system designed to support hand rehabilitation for stroke patients. The system combines a low cost 3D-printed robotic exoskeleton with an embedded controller that converts brain signals into physical hand movements. EEG signals are recorded using a 14-channel Emotiv EPOC+ headset and processed through a supervised convolutional autoencoder (CAE) to extract meaningful latent features from single-trial data. The model is trained on publicly available EEG data from healthy individuals (WAY-EEG-GAL dataset), with electrode mapping adapted to match the Emotiv headset layout. Among several tested classifiers, Ada Boost achieved the highest accuracy (89.3%) and F1-score (0.89) in offline evaluations. The system was also tested in real time on five healthy subjects, achieving classification accuracies between 60% and 86%. The complete pipeline - EEG acquisition, signal processing, classification, and robotic control - is deployed on an NVIDIA Jetson Nano platform with a real-time graphical interface. These results demonstrate the system's potential as a low-cost, standalone solution for home-based neurorehabilitation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.HC",
    "comment": "Proceedings of the 7th Novel Intelligent and Leading Emerging Sciences Conference (NILES 2025)",
    "pdf_url": "https://arxiv.org/pdf/2510.15890v1",
    "published_date": "2025-09-07 22:19:03 UTC",
    "updated_date": "2025-09-07 22:19:03 UTC"
  },
  {
    "arxiv_id": "2509.08004v1",
    "title": "Evaluating and comparing gender bias across four text-to-image models",
    "authors": [
      "Zoya Hammad",
      "Nii Longdon Sowah"
    ],
    "abstract": "As we increasingly use Artificial Intelligence (AI) in decision-making for industries like healthcare, finance, e-commerce, and even entertainment, it is crucial to also reflect on the ethical aspects of AI, for example the inclusivity and fairness of the information it provides. In this work, we aimed to evaluate different text-to-image AI models and compare the degree of gender bias they present. The evaluated models were Stable Diffusion XL (SDXL), Stable Diffusion Cascade (SC), DALL-E and Emu. We hypothesized that DALL-E and Stable Diffusion, which are comparatively older models, would exhibit a noticeable degree of gender bias towards men, while Emu, which was recently released by Meta AI, would have more balanced results. As hypothesized, we found that both Stable Diffusion models exhibit a noticeable degree of gender bias while Emu demonstrated more balanced results (i.e. less gender bias). However, interestingly, Open AI's DALL-E exhibited almost opposite results, such that the ratio of women to men was significantly higher in most cases tested. Here, although we still observed a bias, the bias favored females over males. This bias may be explained by the fact that OpenAI changed the prompts at its backend, as observed during our experiment. We also observed that Emu from Meta AI utilized user information while generating images via WhatsApp. We also proposed some potential solutions to avoid such biases, including ensuring diversity across AI research teams and having diverse datasets.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08004v1",
    "published_date": "2025-09-07 22:15:58 UTC",
    "updated_date": "2025-09-07 22:15:58 UTC"
  },
  {
    "arxiv_id": "2509.07032v1",
    "title": "A Maslow-Inspired Hierarchy of Engagement with AI Model",
    "authors": [
      "Madara Ogot"
    ],
    "abstract": "The rapid proliferation of artificial intelligence (AI) across industry, government, and education highlights the urgent need for robust frameworks to conceptualise and guide engagement. This paper introduces the Hierarchy of Engagement with AI model, a novel maturity framework inspired by Maslow's hierarchy of needs. The model conceptualises AI adoption as a progression through eight levels, beginning with initial exposure and basic understanding and culminating in ecosystem collaboration and societal impact. Each level integrates technical, organisational, and ethical dimensions, emphasising that AI maturity is not only a matter of infrastructure and capability but also of trust, governance, and responsibility. Initial validation of the model using four diverse case studies (General Motors, the Government of Estonia, the University of Texas System, and the African Union AI Strategy) demonstrate the model's contextual flexibility across various sectors. The model provides scholars with a framework for analysing AI maturity and offers practitioners and policymakers a diagnostic and strategic planning tool to guide responsible and sustainable AI engagement. The proposed model demonstrates that AI maturity progression is multi-dimensional, requiring technological capability, ethical integrity, organisational resilience, and ecosystem collaboration.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "30 pages, 14 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.07032v1",
    "published_date": "2025-09-07 21:54:21 UTC",
    "updated_date": "2025-09-07 21:54:21 UTC"
  },
  {
    "arxiv_id": "2509.08847v1",
    "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs",
    "authors": [
      "Amna Hassan"
    ],
    "abstract": "This paper presents a novel framework for automated game template generation by transforming Game Design Documents (GDDs) into functional Unity game prototypes using Natural Language Processing (NLP) and multi-modal Large Language Models (LLMs). We introduce an end-to-end system that parses GDDs, extracts structured game specifications, and synthesizes Unity-compatible C# code that implements the core mechanics, systems, and architecture defined in the design documentation. Our approach combines a fine-tuned LLaMA-3 model specialized for Unity code generation with a custom Unity integration package that streamlines the implementation process. Evaluation results demonstrate significant improvements over baseline models, with our fine-tuned model achieving superior performance (4.8/5.0 average score) compared to state-of-the-art LLMs across compilation success, GDD adherence, best practices adoption, and code modularity metrics. The generated templates demonstrate high adherence to GDD specifications across multiple game genres. Our system effectively addresses critical gaps in AI-assisted game development, positioning LLMs as valuable tools in streamlining the transition from game design to implementation.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08847v1",
    "published_date": "2025-09-07 21:53:37 UTC",
    "updated_date": "2025-09-07 21:53:37 UTC"
  },
  {
    "arxiv_id": "2509.06221v1",
    "title": "Beamforming-LLM: What, Where and When Did I Miss?",
    "authors": [
      "Vishal Choudhari"
    ],
    "abstract": "We present Beamforming-LLM, a system that enables users to semantically recall conversations they may have missed in multi-speaker environments. The system combines spatial audio capture using a microphone array with retrieval-augmented generation (RAG) to support natural language queries such as, \"What did I miss when I was following the conversation on dogs?\" Directional audio streams are separated using beamforming, transcribed with Whisper, and embedded into a vector database using sentence encoders. Upon receiving a user query, semantically relevant segments are retrieved, temporally aligned with non-attended segments, and summarized using a lightweight large language model (GPT-4o-mini). The result is a user-friendly interface that provides contrastive summaries, spatial context, and timestamped audio playback. This work lays the foundation for intelligent auditory memory systems and has broad applications in assistive technology, meeting summarization, and context-aware personal spatial computing.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06221v1",
    "published_date": "2025-09-07 21:52:26 UTC",
    "updated_date": "2025-09-07 21:52:26 UTC"
  },
  {
    "arxiv_id": "2509.06218v2",
    "title": "The Efficiency Frontier: Classical Shadows versus Quantum Footage",
    "authors": [
      "Shuowei Ma",
      "Junyu Liu"
    ],
    "abstract": "Interfacing quantum and classical processors is an important subroutine in full-stack quantum algorithms. The so-called \"classical shadow\" method efficiently extracts essential classical information from quantum states, enabling the prediction of many properties of a quantum system from only a few measurements. However, for a small number of highly non-local observables, or when classical post-processing power is limited, the classical shadow method is not always the most efficient choice. Here, we address this issue quantitatively by performing a full-stack resource analysis that compares classical shadows with \"quantum footage,\" which refers to direct quantum measurement. Under certain assumptions, our analysis illustrates a boundary of download efficiency between classical shadows and quantum footage. For observables expressed as linear combinations of Pauli matrices, the classical shadow method outperforms direct measurement when the number of observables is large and the Pauli weight is small. For observables in the form of large Hermitian sparse matrices, the classical shadow method shows an advantage when the number of observables, the sparsity of the matrix, and the number of qubits fall within a certain range. The key parameters influencing this behavior include the number of qubits $n$, observables $M$, sparsity $k$, Pauli weight $w$, accuracy requirement $ε$, and failure tolerance $δ$. We also compare the resource consumption of the two methods on different types of quantum computers and identify break-even points where the classical shadow method becomes more efficient, which vary depending on the hardware. This paper opens a new avenue for quantitatively designing optimal strategies for hybrid quantum-classical tomography and provides practical insights for selecting the most suitable quantum measurement approach in real-world applications.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "quant-ph",
    "comment": "23 pages, many figures. v2: changes gibberish texts due to latex compilation error",
    "pdf_url": "https://arxiv.org/pdf/2509.06218v2",
    "published_date": "2025-09-07 21:46:56 UTC",
    "updated_date": "2025-09-09 18:39:03 UTC"
  },
  {
    "arxiv_id": "2509.12229v1",
    "title": "Profiling LoRA/QLoRA Fine-Tuning Efficiency on Consumer GPUs: An RTX 4060 Case Study",
    "authors": [
      "MSR Avinash"
    ],
    "abstract": "Fine-tuning large language models (LLMs) with parameter-efficient techniques such as LoRA and QLoRA has enabled adaptation of foundation models on modest hardware. Yet the efficiency of such training on consumer-grade GPUs, especially under strict 8 GB VRAM limits, remains underexplored. We present a controlled profiling study of LoRA/QLoRA fine-tuning using the Qwen2.5-1.5B-Instruct model on a single NVIDIA RTX 4060. Across three representative configurations, we systematically vary batch size, sequence length, optimizer choice (AdamW vs. PagedAdamW), and precision (fp16 vs. bf16). We report throughput (tokens/s), time per 10k tokens, and VRAM footprint, alongside energy estimates derived from GPU board power limits. Our results show that paged optimizers improve throughput by up to 25% (628 tok/s vs. 500 tok/s baseline), while bf16 degrades efficiency relative to fp16. Despite 8 GB constraints, sequence lengths up to 2048 tokens were feasible using parameter-efficient strategies. To our knowledge, this is the first systematic case study of LLM fine- tuning efficiency on consumer GPUs, providing reproducible benchmarks and practical guidelines for resource-constrained researchers and practitioners.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures, 2 tables. Primary category: cs.LG (Machine Learning); secondary: cs.AI (Artificial Intelligence). LaTeX source with figures included",
    "pdf_url": "https://arxiv.org/pdf/2509.12229v1",
    "published_date": "2025-09-07 21:41:14 UTC",
    "updated_date": "2025-09-07 21:41:14 UTC"
  },
  {
    "arxiv_id": "2509.06216v2",
    "title": "Agentic Software Engineering: Foundational Pillars and a Research Roadmap",
    "authors": [
      "Ahmed E. Hassan",
      "Hao Li",
      "Dayi Lin",
      "Bram Adams",
      "Tse-Hsun Chen",
      "Yutaro Kashiwa",
      "Dong Qiu"
    ],
    "abstract": "Agentic Software Engineering (SE 3.0) represents a new era where intelligent agents are tasked not with simple code generation, but with achieving complex, goal-oriented SE objectives. To harness these new capabilities while ensuring trustworthiness, we must recognize a fundamental duality within the SE field in the Agentic SE era, comprising two symbiotic modalities: SE for Humans and SE for Agents. This duality demands a radical reimagining of the foundational pillars of SE (actors, processes, tools, and artifacts) which manifest differently across each modality. We propose two purpose-built workbenches to support this vision. The Agent Command Environment (ACE) serves as a command center where humans orchestrate and mentor agent teams, handling outputs such as Merge-Readiness Packs (MRPs) and Consultation Request Packs (CRPs). The Agent Execution Environment (AEE) is a digital workspace where agents perform tasks while invoking human expertise when facing ambiguity or complex trade-offs. This bi-directional partnership, which supports agent-initiated human callbacks and handovers, gives rise to new, structured engineering activities (i.e., processes) that redefine human-AI collaboration, elevating the practice from agentic coding to true agentic software engineering. This paper presents the Structured Agentic Software Engineering (SASE) vision, outlining several of the foundational pillars for the future of SE. The paper culminates in a research roadmap that identifies a few key challenges and opportunities while briefly discussing the resulting impact of this future on SE education. Our goal is not to offer a definitive solution, but to provide a conceptual scaffold with structured vocabulary to catalyze a community-wide dialogue, pushing the SE community to think beyond its classic, human-centric tenets toward a disciplined, scalable, and trustworthy agentic future.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06216v2",
    "published_date": "2025-09-07 21:40:10 UTC",
    "updated_date": "2025-09-23 01:01:15 UTC"
  },
  {
    "arxiv_id": "2509.06213v3",
    "title": "Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning",
    "authors": [
      "Christo Mathew",
      "Wentian Wang",
      "Jacob Feldman",
      "Lazaros K. Gallos",
      "Paul B. Kantor",
      "Vladimir Menkov",
      "Hao Wang"
    ],
    "abstract": "We investigate reinforcement learning in the Game Of Hidden Rules (GOHR) environment, a complex puzzle in which an agent must infer and execute hidden rules to clear a 6$\\times$6 board by placing game pieces into buckets. We explore two state representation strategies, namely Feature-Centric (FC) and Object-Centric (OC), and employ a Transformer-based Advantage Actor-Critic (A2C) algorithm for training. The agent has access only to partial observations and must simultaneously infer the governing rule and learn the optimal policy through experience. We evaluate our models across multiple rule-based and trial-list-based experimental setups, analyzing transfer effects and the impact of representation on learning efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06213v3",
    "published_date": "2025-09-07 21:22:14 UTC",
    "updated_date": "2025-10-23 04:14:39 UTC"
  },
  {
    "arxiv_id": "2509.09711v2",
    "title": "PsychiatryBench: A Multi-Task Benchmark for LLMs in Psychiatry",
    "authors": [
      "Aya E. Fouda",
      "Abdelrahamn A. Hassan",
      "Radwa J. Hanafy",
      "Mohammed E. Fouda"
    ],
    "abstract": "Large language models (LLMs) offer significant potential in enhancing psychiatric practice, from improving diagnostic accuracy to streamlining clinical documentation and therapeutic support. However, existing evaluation resources heavily rely on small clinical interview corpora, social media posts, or synthetic dialogues, which limits their clinical validity and fails to capture the full complexity of diagnostic reasoning. In this work, we introduce PsychiatryBench, a rigorously curated benchmark grounded exclusively in authoritative, expert-validated psychiatric textbooks and casebooks. PsychiatryBench comprises eleven distinct question-answering tasks ranging from diagnostic reasoning and treatment planning to longitudinal follow-up, management planning, clinical approach, sequential case analysis, and multiple-choice/extended matching formats totaling 5,188 expert-annotated items. {\\color{red}We evaluate a diverse set of frontier LLMs (including Google Gemini, DeepSeek, Sonnet 4.5, and GPT 5) alongside leading open-source medical models such as MedGemma using both conventional metrics and an \"LLM-as-judge\" similarity scoring framework. Our results reveal substantial gaps in clinical consistency and safety, particularly in multi-turn follow-up and management tasks, underscoring the need for specialized model tuning and more robust evaluation paradigms. PsychiatryBench offers a modular, extensible platform for benchmarking and improving LLM performance in mental health applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09711v2",
    "published_date": "2025-09-07 20:57:24 UTC",
    "updated_date": "2025-11-23 15:40:27 UTC"
  },
  {
    "arxiv_id": "2509.06201v1",
    "title": "Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control",
    "authors": [
      "Jun Yamada",
      "Adithyavairavan Murali",
      "Ajay Mandlekar",
      "Clemens Eppner",
      "Ingmar Posner",
      "Balakumar Sundaralingam"
    ],
    "abstract": "Grasping of diverse objects in unstructured environments remains a significant challenge. Open-loop grasping methods, effective in controlled settings, struggle in cluttered environments. Grasp prediction errors and object pose changes during grasping are the main causes of failure. In contrast, closed-loop methods address these challenges in simplified settings (e.g., single object on a table) on a limited set of objects, with no path to generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping policy designed for robust and reactive grasping of novel objects in cluttered environments. Grasp-MPC incorporates a value function, trained on visual observations from a large-scale synthetic dataset of 2 million grasp trajectories that include successful and failed attempts. We deploy this learned value function in an MPC framework in combination with other cost terms that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC on FetchBench and real-world settings across diverse environments. Grasp-MPC improves grasp success rates by up to 32.6% in simulation and 33.3% in real-world noisy conditions, outperforming open-loop, diffusion policy, transformer policy, and IQL approaches. Videos and more at http://grasp-mpc.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "14 pages, 17 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.06201v1",
    "published_date": "2025-09-07 20:28:21 UTC",
    "updated_date": "2025-09-07 20:28:21 UTC"
  },
  {
    "arxiv_id": "2509.06195v1",
    "title": "Language Bias in Information Retrieval: The Nature of the Beast and Mitigation Methods",
    "authors": [
      "Jinrui Yang",
      "Fan Jiang",
      "Timothy Baldwin"
    ],
    "abstract": "Language fairness in multilingual information retrieval (MLIR) systems is crucial for ensuring equitable access to information across diverse languages. This paper sheds light on the issue, based on the assumption that queries in different languages, but with identical semantics, should yield equivalent ranking lists when retrieving on the same multilingual documents. We evaluate the degree of fairness using both traditional retrieval methods, and a DPR neural ranker based on mBERT and XLM-R. Additionally, we introduce `LaKDA', a novel loss designed to mitigate language biases in neural MLIR approaches. Our analysis exposes intrinsic language biases in current MLIR technologies, with notable disparities across the retrieval methods, and the effectiveness of LaKDA in enhancing language fairness.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at EMNLP MRL 2024",
    "pdf_url": "https://arxiv.org/pdf/2509.06195v1",
    "published_date": "2025-09-07 20:10:49 UTC",
    "updated_date": "2025-09-07 20:10:49 UTC"
  },
  {
    "arxiv_id": "2509.07030v2",
    "title": "A Minimalist Bayesian Framework for Stochastic Optimization",
    "authors": [
      "Kaizheng Wang"
    ],
    "abstract": "The Bayesian paradigm offers principled tools for sequential decision-making under uncertainty, but its reliance on a probabilistic model for all parameters can hinder the incorporation of complex structural constraints. We introduce a minimalist Bayesian framework that places a prior only on the component of interest, such as the location of the optimum. Nuisance parameters are eliminated via profile likelihood, which naturally handles constraints. As a direct instantiation, we develop a MINimalist Thompson Sampling (MINTS) algorithm. Our framework accommodates structured problems, including continuum-armed Lipschitz bandits and dynamic pricing. It also provides a probabilistic lens on classical convex optimization algorithms such as the center of gravity and ellipsoid methods. We further analyze MINTS for multi-armed bandits and establish near-optimal regret guarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.07030v2",
    "published_date": "2025-09-07 19:31:12 UTC",
    "updated_date": "2025-10-08 01:52:40 UTC"
  },
  {
    "arxiv_id": "2509.06176v2",
    "title": "AI Governance in Higher Education: A course design exploring regulatory, ethical and practical considerations",
    "authors": [
      "Raphaël Weuts",
      "Johannes Bleher",
      "Hannah Bleher",
      "Rozanne Tuesday Flores",
      "Guo Xuanyang",
      "Paweł Pujszo",
      "Zsolt Almási"
    ],
    "abstract": "As artificial intelligence (AI) systems permeate critical sectors, the need for professionals who can address ethical, legal and governance challenges has become urgent. Current AI ethics education remains fragmented, often siloed by discipline and disconnected from practice. This paper synthesizes literature and regulatory developments to propose a modular, interdisciplinary curriculum that integrates technical foundations with ethics, law and policy. We highlight recurring operational failures in AI - bias, misspecified objectives, generalization errors, misuse and governance breakdowns - and link them to pedagogical strategies for teaching AI governance. Drawing on perspectives from the EU, China and international frameworks, we outline a semester plan that emphasizes integrated ethics, stakeholder engagement and experiential learning. The curriculum aims to prepare students to diagnose risks, navigate regulation and engage diverse stakeholders, fostering adaptive and ethically grounded professionals for responsible AI governance.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06176v2",
    "published_date": "2025-09-07 19:09:12 UTC",
    "updated_date": "2025-09-16 15:37:52 UTC"
  },
  {
    "arxiv_id": "2509.06174v1",
    "title": "From Long to Short: LLMs Excel at Trimming Own Reasoning Chains",
    "authors": [
      "Wei Han",
      "Geng Zhan",
      "Sicheng Yu",
      "Chenyu Wang",
      "Bryan Hooi"
    ],
    "abstract": "O1/R1 style large reasoning models (LRMs) signal a substantial leap forward over conventional instruction-following LLMs. By applying test-time scaling to generate extended reasoning paths, they establish many SOTAs across a wide range of complex reasoning tasks. However, recent studies show that LRMs are prone to suffer from overthinking -- the tendency to overcomplicate simple problems, leading to excessive strategy switching and long, convoluted reasoning traces that hinder their interpretability. To mitigate this issue, we conduct a systematic investigation into the reasoning efficiency of a broad set of LRMs and uncover a common dilemma: the difficulty in balancing multiple generation objectives such as correctness and brevity. Based on this discovery, we propose a test-time scaling method, EDIT (Efficient Dynamic Inference Trimming), which efficiently guides LRMs to identify the shortest correct reasoning paths at test time. EDIT employs constraint-guided generation while jointly tracking length and answer distributions under varying constraints, allowing it to select responses that strike an optimal balance between conciseness and correctness. Extensive experiments across diverse models and datasets show that EDIT substantially enhance the reasoning efficiency, producing compact yet informative outputs that improve readability and user experience.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 5 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.06174v1",
    "published_date": "2025-09-07 19:00:44 UTC",
    "updated_date": "2025-09-07 19:00:44 UTC"
  },
  {
    "arxiv_id": "2509.06169v1",
    "title": "Reasoning Language Model for Personalized Lung Cancer Screening",
    "authors": [
      "Chuang Niu",
      "Ge Wang"
    ],
    "abstract": "Accurate risk assessment in lung cancer screening is critical for enabling early cancer detection and minimizing unnecessary invasive procedures. The Lung CT Screening Reporting and Data System (Lung-RADS) has been widely used as the standard framework for patient management and follow-up. Nevertheless, Lung-RADS faces trade-offs between sensitivity and specificity, as it stratifies risk solely based on lung nodule characteristics without incorporating various risk factors. Here we propose a reasoning language model (RLM) to integrate radiology findings with longitudinal medical records for individualized lung cancer risk assessment. Through a systematic study including dataset construction and distillation, supervised fine-tuning, reinforcement learning, and comprehensive evaluation, our model makes significant improvements in risk prediction performance on datasets in the national lung screening trial. Notably, RLM can decompose the risk evaluation task into sub-components, analyze the contributions of diverse risk factors, and synthesize them into a final risk score computed using our data-driven system equation. Our approach improves both predictive accuracy and monitorability through the chain of thought reasoning process, thereby facilitating clinical translation into lung cancer screening.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06169v1",
    "published_date": "2025-09-07 18:38:39 UTC",
    "updated_date": "2025-09-07 18:38:39 UTC"
  },
  {
    "arxiv_id": "2509.06165v4",
    "title": "UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning",
    "authors": [
      "Huy Le",
      "Nhat Chung",
      "Tung Kieu",
      "Jingkang Yang",
      "Ngan Le"
    ],
    "abstract": "Video Scene Graph Generation (VidSGG) aims to represent dynamic visual content by detecting objects and modeling their temporal interactions as structured graphs. Prior studies typically target either coarse-grained box-level or fine-grained panoptic pixel-level VidSGG, often requiring task-specific architectures and multi-stage training pipelines. In this paper, we present UNO (UNified Object-centric VidSGG), a single-stage, unified framework that jointly addresses both tasks within an end-to-end architecture. UNO is designed to minimize task-specific modifications and maximize parameter sharing, enabling generalization across different levels of visual granularity. The core of UNO is an extended slot attention mechanism that decomposes visual features into object and relation slots. To ensure robust temporal modeling, we introduce object temporal consistency learning, which enforces consistent object representations across frames without relying on explicit tracking modules. Additionally, a dynamic triplet prediction module links relation slots to corresponding object pairs, capturing evolving interactions over time. We evaluate UNO on standard box-level and pixel-level VidSGG benchmarks. Results demonstrate that UNO not only achieves competitive performance across both tasks but also offers improved efficiency through a unified, object-centric design.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 7 figures. Accepted at WACV 2026",
    "pdf_url": "https://arxiv.org/pdf/2509.06165v4",
    "published_date": "2025-09-07 18:30:41 UTC",
    "updated_date": "2025-12-11 20:39:40 UTC"
  },
  {
    "arxiv_id": "2509.06164v2",
    "title": "Benchmarking Gender and Political Bias in Large Language Models",
    "authors": [
      "Jinrui Yang",
      "Xudong Han",
      "Timothy Baldwin"
    ],
    "abstract": "We introduce EuroParlVote, a novel benchmark for evaluating large language models (LLMs) in politically sensitive contexts. It links European Parliament debate speeches to roll-call vote outcomes and includes rich demographic metadata for each Member of the European Parliament (MEP), such as gender, age, country, and political group. Using EuroParlVote, we evaluate state-of-the-art LLMs on two tasks -- gender classification and vote prediction -- revealing consistent patterns of bias. We find that LLMs frequently misclassify female MEPs as male and demonstrate reduced accuracy when simulating votes for female speakers. Politically, LLMs tend to favor centrist groups while underperforming on both far-left and far-right ones. Proprietary models like GPT-4o outperform open-weight alternatives in terms of both robustness and fairness. We release the EuroParlVote dataset, code, and demo to support future research on fairness and accountability in NLP within political contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06164v2",
    "published_date": "2025-09-07 18:23:30 UTC",
    "updated_date": "2025-09-16 05:28:09 UTC"
  },
  {
    "arxiv_id": "2509.06161v1",
    "title": "Tracking daily paths in home contexts with RSSI fingerprinting based on UWB through deep learning models",
    "authors": [
      "Aurora Polo-Rodríguez",
      "Juan Carlos Valera",
      "Jesús Peral",
      "David Gil",
      "Javier Medina-Quero"
    ],
    "abstract": "The field of human activity recognition has evolved significantly, driven largely by advancements in Internet of Things (IoT) device technology, particularly in personal devices. This study investigates the use of ultra-wideband (UWB) technology for tracking inhabitant paths in home environments using deep learning models. UWB technology estimates user locations via time-of-flight and time-difference-of-arrival methods, which are significantly affected by the presence of walls and obstacles in real environments, reducing their precision. To address these challenges, we propose a fingerprinting-based approach utilizing received signal strength indicator (RSSI) data collected from inhabitants in two flats (60 m2 and 100 m2) while performing daily activities. We compare the performance of convolutional neural network (CNN), long short-term memory (LSTM), and hybrid CNN+LSTM models, as well as the use of Bluetooth technology. Additionally, we evaluate the impact of the type and duration of the temporal window (future, past, or a combination of both). Our results demonstrate a mean absolute error close to 50 cm, highlighting the superiority of the hybrid model in providing accurate location estimates, thus facilitating its application in daily human activity recognition in residential settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 14 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.06161v1",
    "published_date": "2025-09-07 18:08:05 UTC",
    "updated_date": "2025-09-07 18:08:05 UTC"
  },
  {
    "arxiv_id": "2509.06160v1",
    "title": "Reverse-Engineered Reasoning for Open-Ended Generation",
    "authors": [
      "Haozhe Wang",
      "Haoran Que",
      "Qixin Xu",
      "Minghao Liu",
      "Wangchunshu Zhou",
      "Jiazhan Feng",
      "Wanjun Zhong",
      "Wei Ye",
      "Tong Yang",
      "Wenhao Huang",
      "Ge Zhang",
      "Fangzhen Lin"
    ],
    "abstract": "While the ``deep reasoning'' paradigm has spurred significant advances in verifiable domains like mathematics, its application to open-ended, creative generation remains a critical challenge. The two dominant methods for instilling reasoning -- reinforcement learning (RL) and instruction distillation -- falter in this area; RL struggles with the absence of clear reward signals and high-quality reward models, while distillation is prohibitively expensive and capped by the teacher model's capabilities. To overcome these limitations, we introduce REverse-Engineered Reasoning (REER), a new paradigm that fundamentally shifts the approach. Instead of building a reasoning process ``forwards'' through trial-and-error or imitation, REER works ``backwards'' from known-good solutions to computationally discover the latent, step-by-step deep reasoning process that could have produced them. Using this scalable, gradient-free approach, we curate and open-source DeepWriting-20K, a large-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks. Our model, DeepWriter-8B, trained on this data, not only surpasses strong open-source baselines but also achieves performance competitive with, and at times superior to, leading proprietary models like GPT-4o and Claude 3.5.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2509.06160v1",
    "published_date": "2025-09-07 18:07:58 UTC",
    "updated_date": "2025-09-07 18:07:58 UTC"
  },
  {
    "arxiv_id": "2509.06159v3",
    "title": "FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes",
    "authors": [
      "Muraam Abdel-Ghani",
      "Mahmoud Ali",
      "Mohamed Ali",
      "Fatmaelzahraa Ahmed",
      "Muhammad Arsalan",
      "Abdulaziz Al-Ali",
      "Shidin Balakrishnan"
    ],
    "abstract": "The growing popularity of robotic minimally invasive surgeries has made deep learning-based surgical training a key area of research. A thorough understanding of the surgical scene components is crucial, which semantic segmentation models can help achieve. However, most existing work focuses on surgical tools and overlooks anatomical objects. Additionally, current state-of-the-art (SOTA) models struggle to balance capturing high-level contextual features and low-level edge features. We propose a Feature-Adaptive Spatial Localization model (FASL-Seg), designed to capture features at multiple levels of detail through two distinct processing streams, namely a Low-Level Feature Projection (LLFP) and a High-Level Feature Projection (HLFP) stream, for varying feature resolutions - enabling precise segmentation of anatomy and surgical instruments. We evaluated FASL-Seg on surgical segmentation benchmark datasets EndoVis18 and EndoVis17 on three use cases. The FASL-Seg model achieves a mean Intersection over Union (mIoU) of 72.71% on parts and anatomy segmentation in EndoVis18, improving on SOTA by 5%. It further achieves a mIoU of 85.61% and 72.78% in EndoVis18 and EndoVis17 tool type segmentation, respectively, outperforming SOTA overall performance, with comparable per-class SOTA results in both datasets and consistent performance in various classes for anatomy and instruments, demonstrating the effectiveness of distinct processing streams for varying feature resolutions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "8 pages, 6 figures, In Proceedings of European Conference on Artificial Intelligence (ECAI) 2025 <https://doi.org/10.3233/FAIA250908>",
    "pdf_url": "https://arxiv.org/pdf/2509.06159v3",
    "published_date": "2025-09-07 17:59:09 UTC",
    "updated_date": "2025-10-30 08:10:05 UTC"
  },
  {
    "arxiv_id": "2509.09710v2",
    "title": "Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data",
    "authors": [
      "Sepehr Golrokh Amin",
      "Devin Rhoads",
      "Fatemeh Fakhrmoosavi",
      "Nicholas E. Lownes",
      "John N. Ivan"
    ],
    "abstract": "This study introduces a Large Language Model (LLM) scheme for generating individual travel diaries in agent-based transportation models. While traditional approaches rely on large quantities of proprietary household travel surveys, the method presented in this study generates personas stochastically from open-source American Community Survey (ACS) and Smart Location Database (SLD) data, then synthesizes diaries through direct prompting. This study features a novel one-to-cohort realism score: a composite of four metrics (Trip Count Score, Interval Score, Purpose Score, and Mode Score) validated against the Connecticut Statewide Transportation Study (CSTS) diaries, matched across demographic variables. The validation utilizes Jensen-Shannon Divergence to measure distributional similarities between generated and real diaries. When compared to diaries generated with classical methods (Negative Binomial for trip generation; Multinomial Logit for mode/purpose) calibrated on the validation set, LLM-generated diaries achieve comparable overall realism (LLM mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and demonstrates greater consistency (narrower realism score distribution), while classical models lead in numerical estimates of trip count and activity duration. Aggregate validation confirms the LLM's statistical representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot viability and establishing a quantifiable metric of diary realism for future synthetic diary evaluation systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09710v2",
    "published_date": "2025-09-07 17:03:08 UTC",
    "updated_date": "2025-10-20 23:59:26 UTC"
  },
  {
    "arxiv_id": "2509.07029v1",
    "title": "The Impact of Artificial Intelligence on Traditional Art Forms: A Disruption or Enhancement",
    "authors": [
      "Viswa Chaitanya Marella",
      "Sai Teja Erukude",
      "Suhasnadh Reddy Veluru"
    ],
    "abstract": "The introduction of Artificial Intelligence (AI) into the domains of traditional art (visual arts, performing arts, and crafts) has sparked a complicated discussion about whether this might be an agent of disruption or an enhancement of our traditional art forms. This paper looks at the duality of AI, exploring the ways that recent technologies like Generative Adversarial Networks and Diffusion Models, and text-to-image generators are changing the fields of painting, sculpture, calligraphy, dance, music, and the arts of craft. Using examples and data, we illustrate the ways that AI can democratize creative expression, improve productivity, and preserve cultural heritage, while also examining the negative aspects, including: the threats to authenticity within art, ethical concerns around data, and issues including socio-economic factors such as job losses. While we argue for the context-dependence of the impact of AI (the potential for creative homogenization and the devaluation of human agency in artmaking), we also illustrate the potential for hybrid practices featuring AI in cuisine, etc. We advocate for the development of ethical guidelines, collaborative approaches, and inclusive technology development. In sum, we are articulating a vision of AI in which it amplifies our innate creativity while resisting the displacement of the cultural, nuanced, and emotional aspects of traditional art. The future will be determined by human choices about how to govern AI so that it becomes a mechanism for artistic evolution and not a substitute for the artist's soul.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "13 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.07029v1",
    "published_date": "2025-09-07 16:37:04 UTC",
    "updated_date": "2025-09-07 16:37:04 UTC"
  },
  {
    "arxiv_id": "2509.08846v1",
    "title": "Uncertainty Estimation using Variance-Gated Distributions",
    "authors": [
      "H. Martin Gillis",
      "Isaac Xu",
      "Thomas Trappenberg"
    ],
    "abstract": "Evaluation of per-sample uncertainty quantification from neural networks is essential for decision-making involving high-risk applications. A common approach is to use the predictive distribution from Bayesian or approximation models and decompose the corresponding predictive uncertainty into epistemic (model-related) and aleatoric (data-related) components. However, additive decomposition has recently been questioned. In this work, we propose an intuitive framework for uncertainty estimation and decomposition based on the signal-to-noise ratio of class probability distributions across different model predictions. We introduce a variance-gated measure that scales predictions by a confidence factor derived from ensembles. We use this measure to discuss the existence of a collapse in the diversity of committee machines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.08846v1",
    "published_date": "2025-09-07 16:19:21 UTC",
    "updated_date": "2025-09-07 16:19:21 UTC"
  },
  {
    "arxiv_id": "2509.06122v1",
    "title": "SpecSwin3D: Generating Hyperspectral Imagery from Multispectral Data via Transformer Networks",
    "authors": [
      "Tang Sui",
      "Songxi Yang",
      "Qunying Huang"
    ],
    "abstract": "Multispectral and hyperspectral imagery are widely used in agriculture, environmental monitoring, and urban planning due to their complementary spatial and spectral characteristics. A fundamental trade-off persists: multispectral imagery offers high spatial but limited spectral resolution, while hyperspectral imagery provides rich spectra at lower spatial resolution. Prior hyperspectral generation approaches (e.g., pan-sharpening variants, matrix factorization, CNNs) often struggle to jointly preserve spatial detail and spectral fidelity. In response, we propose SpecSwin3D, a transformer-based model that generates hyperspectral imagery from multispectral inputs while preserving both spatial and spectral quality. Specifically, SpecSwin3D takes five multispectral bands as input and reconstructs 224 hyperspectral bands at the same spatial resolution. In addition, we observe that reconstruction errors grow for hyperspectral bands spectrally distant from the input bands. To address this, we introduce a cascade training strategy that progressively expands the spectral range to stabilize learning and improve fidelity. Moreover, we design an optimized band sequence that strategically repeats and orders the five selected multispectral bands to better capture pairwise relations within a 3D shifted-window transformer framework. Quantitatively, our model achieves a PSNR of 35.82 dB, SAM of 2.40°, and SSIM of 0.96, outperforming the baseline MHF-Net by +5.6 dB in PSNR and reducing ERGAS by more than half. Beyond reconstruction, we further demonstrate the practical value of SpecSwin3D on two downstream tasks, including land use classification and burnt area segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06122v1",
    "published_date": "2025-09-07 16:18:31 UTC",
    "updated_date": "2025-09-07 16:18:31 UTC"
  },
  {
    "arxiv_id": "2509.06094v1",
    "title": "Teaching Precommitted Agents: Model-Free Policy Evaluation and Control in Quasi-Hyperbolic Discounted MDPs",
    "authors": [
      "S. R. Eshwar"
    ],
    "abstract": "Time-inconsistent preferences, where agents favor smaller-sooner over larger-later rewards, are a key feature of human and animal decision-making. Quasi-Hyperbolic (QH) discounting provides a simple yet powerful model for this behavior, but its integration into the reinforcement learning (RL) framework has been limited. This paper addresses key theoretical and algorithmic gaps for precommitted agents with QH preferences. We make two primary contributions: (i) we formally characterize the structure of the optimal policy, proving for the first time that it reduces to a simple one-step non-stationary form; and (ii) we design the first practical, model-free algorithms for both policy evaluation and Q-learning in this setting, both with provable convergence guarantees. Our results provide foundational insights for incorporating QH preferences in RL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06094v1",
    "published_date": "2025-09-07 15:16:15 UTC",
    "updated_date": "2025-09-07 15:16:15 UTC"
  },
  {
    "arxiv_id": "2509.06093v3",
    "title": "Language-Native Materials Processing Design by Lightly Structured Text Database and Reasoning Large Language Model",
    "authors": [
      "Yuze Liu",
      "Zhaoyuan Zhang",
      "Xiangsheng Zeng",
      "Yihe Zhang",
      "Leping Yu",
      "Liu Yang",
      "Lejia Wang",
      "Xi Yu"
    ],
    "abstract": "Materials synthesis procedures are predominantly documented as narrative text in protocols and lab notebooks, rendering them inaccessible to conventional structured data optimization. This language-native nature poses a critical challenge for complex, multistage processes--such as the preparation of boron nitride nanosheet (BNNS)--where outcomes depend on path-dependent choices in exfoliation and functionalization. Here, we recast synthesis planning as a text reasoning task enabled by a lightly structured text database, which preserves the conditional logic and causal contexts essential for expert-like decision-making. Building on a heterogeneous schema that indexes both narrative excerpts and computable entities (e.g., reaction conditions), our system implements a hybrid retrieval engine to combine semantic context with precise parameter filtering. On top of this, the framework operates in two modes, i.e. retrieval-augmented generation (RAG), which grounds recommendations in retrieved evidence modules, and experience-augmented reasoning (EAR), which uses iteratively refined text guides distilled from multi-source narrative data. Instead of suggesting single \"optimal\" settings, the system produces interpretable guidance aligned with expert reasoning patterns--hypotheses, parameter ranges, and citation-backed standard operating procedures--that support iterative planning and failure diagnosis. We validated this framework on the targeted exfoliation of BNNS, a process highly sensitive to multivariate constraints. The system successfully identified optimal combinations of grinding aids, milling configurations, and separation strategies from a wide range of literature-reported methods, which were experimentally verified to yield high-quality nanosheets, illustrating the potential of language-native reasoning to streamline critical operations in materials processing.",
    "categories": [
      "cs.DB",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06093v3",
    "published_date": "2025-09-07 15:15:55 UTC",
    "updated_date": "2026-01-21 00:43:22 UTC"
  },
  {
    "arxiv_id": "2509.06085v1",
    "title": "Software Dependencies 2.0: An Empirical Study of Reuse and Integration of Pre-Trained Models in Open-Source Projects",
    "authors": [
      "Jerin Yasmin",
      "Wenxin Jiang",
      "James C. Davis",
      "Yuan Tian"
    ],
    "abstract": "Pre-trained models (PTMs) are machine learning models that have been trained in advance, often on large-scale data, and can be reused for new tasks, thereby reducing the need for costly training from scratch. Their widespread adoption introduces a new class of software dependency, which we term Software Dependencies 2.0, extending beyond conventional libraries to learned behaviors embodied in trained models and their associated artifacts. The integration of PTMs as software dependencies in real projects remains unclear, potentially threatening maintainability and reliability of modern software systems that increasingly rely on them. Objective: In this study, we investigate Software Dependencies 2.0 in open-source software (OSS) projects by examining the reuse of PTMs, with a focus on how developers manage and integrate these models. Specifically, we seek to understand: (1) how OSS projects structure and document their PTM dependencies; (2) what stages and organizational patterns emerge in the reuse pipelines of PTMs within these projects; and (3) the interactions among PTMs and other learned components across pipeline stages. We conduct a mixed-methods analysis of a statistically significant random sample of 401 GitHub repositories from the PeaTMOSS dataset (28,575 repositories reusing PTMs from Hugging Face and PyTorch Hub). We quantitatively examine PTM reuse by identifying patterns and qualitatively investigate how developers integrate and manage these models in practice.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Submitted to Empirical Software Engineering (EMSE) Journal",
    "pdf_url": "https://arxiv.org/pdf/2509.06085v1",
    "published_date": "2025-09-07 15:00:22 UTC",
    "updated_date": "2025-09-07 15:00:22 UTC"
  },
  {
    "arxiv_id": "2509.21331v1",
    "title": "Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+",
    "authors": [
      "Mahedi Hasan"
    ],
    "abstract": "Seismic velocity inversion is a key task in geophysical exploration, enabling the reconstruction of subsurface structures from seismic wave data. It is critical for high-resolution seismic imaging and interpretation. Traditional physics-driven methods, such as Full Waveform Inversion (FWI), are computationally demanding, sensitive to initialization, and limited by the bandwidth of seismic data. Recent advances in deep learning have led to data-driven approaches that treat velocity inversion as a dense prediction task. This research benchmarks three advanced encoder-decoder architectures -- U-Net, U-Net++, and DeepLabV3+ -- together with SeismoLabV3+, an optimized variant of DeepLabV3+ with a ResNeXt50 32x4d backbone and task-specific modifications -- for seismic velocity inversion using the ThinkOnward 2025 Speed \\& Structure dataset, which consists of five-channel seismic shot gathers paired with high-resolution velocity maps. Experimental results show that SeismoLabV3+ achieves the best performance, with MAPE values of 0.03025 on the internal validation split and 0.031246 on the hidden test set as scored via the official ThinkOnward leaderboard. These findings demonstrate the suitability of deep segmentation networks for seismic velocity inversion and underscore the value of tailored architectural refinements in advancing geophysical AI models.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.21331v1",
    "published_date": "2025-09-07 14:41:39 UTC",
    "updated_date": "2025-09-07 14:41:39 UTC"
  },
  {
    "arxiv_id": "2509.07027v3",
    "title": "Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models",
    "authors": [
      "Jisung Hwang",
      "Jaihoon Kim",
      "Minhyuk Sung"
    ],
    "abstract": "We propose a novel regularization loss that enforces standard Gaussianity, encouraging samples to align with a standard Gaussian distribution. This facilitates a range of downstream tasks involving optimization in the latent space of text-to-image models. We treat elements of a high-dimensional sample as one-dimensional standard Gaussian variables and define a composite loss that combines moment-based regularization in the spatial domain with power spectrum-based regularization in the spectral domain. Since the expected values of moments and power spectrum distributions are analytically known, the loss promotes conformity to these properties. To ensure permutation invariance, the losses are applied to randomly permuted inputs. Notably, existing Gaussianity-based regularizations fall within our unified framework: some correspond to moment losses of specific orders, while the previous covariance-matching loss is equivalent to our spectral loss but incurs higher time complexity due to its spatial-domain computation. We showcase the application of our regularization in generative modeling for test-time reward alignment with a text-to-image model, specifically to enhance aesthetics and text alignment. Our regularization outperforms previous Gaussianity regularization, effectively prevents reward hacking and accelerates convergence.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.07027v3",
    "published_date": "2025-09-07 14:22:01 UTC",
    "updated_date": "2025-09-18 15:35:34 UTC"
  },
  {
    "arxiv_id": "2509.06060v1",
    "title": "ARIES: Relation Assessment and Model Recommendation for Deep Time Series Forecasting",
    "authors": [
      "Fei Wang",
      "Yujie Li",
      "Zezhi Shao",
      "Chengqing Yu",
      "Yisong Fu",
      "Zhulin An",
      "Yongjun Xu",
      "Xueqi Cheng"
    ],
    "abstract": "Recent advancements in deep learning models for time series forecasting have been significant. These models often leverage fundamental time series properties such as seasonality and non-stationarity, which may suggest an intrinsic link between model performance and data properties. However, existing benchmark datasets fail to offer diverse and well-defined temporal patterns, restricting the systematic evaluation of such connections. Additionally, there is no effective model recommendation approach, leading to high time and cost expenditures when testing different architectures across different downstream applications. For those reasons, we propose ARIES, a framework for assessing relation between time series properties and modeling strategies, and for recommending deep forcasting models for realistic time series. First, we construct a synthetic dataset with multiple distinct patterns, and design a comprehensive system to compute the properties of time series. Next, we conduct an extensive benchmarking of over 50 forecasting models, and establish the relationship between time series properties and modeling strategies. Our experimental results reveal a clear correlation. Based on these findings, we propose the first deep forecasting model recommender, capable of providing interpretable suggestions for real-world time series. In summary, ARIES is the first study to establish the relations between the properties of time series data and modeling strategies, while also implementing a model recommendation system. The code is available at: https://github.com/blisky-li/ARIES.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06060v1",
    "published_date": "2025-09-07 13:57:14 UTC",
    "updated_date": "2025-09-07 13:57:14 UTC"
  },
  {
    "arxiv_id": "2509.07026v1",
    "title": "Contradictions",
    "authors": [
      "Yang Xu",
      "Shuwei Chen",
      "Xiaomei Zhong",
      "Jun Liu",
      "Xingxing He"
    ],
    "abstract": "Trustworthy AI requires reasoning systems that are not only powerful but also transparent and reliable. Automated Theorem Proving (ATP) is central to formal reasoning, yet classical binary resolution remains limited, as each step involves only two clauses and eliminates at most two literals. To overcome this bottleneck, the concept of standard contradiction and the theory of contradiction-separation-based deduction were introduced in 2018. This paper advances that framework by focusing on the systematic construction of standard contradictions. Specially, this study investigates construction methods for two principal forms of standard contradiction: the maximum triangular standard contradiction and the triangular-type standard contradiction. Building on these structures, we propose a procedure for determining the satisfiability and unsatisfiability of clause sets via maximum standard contradiction. Furthermore, we derive formulas for computing the number of standard sub-contradictions embedded within both the maximum triangular standard contradiction and the triangular-type standard contradiction. The results presented herein furnish the methodological basis for advancing contradiction-separation-based dynamic multi-clause automated deduction, thereby extending the expressive and deductive capabilities of automated reasoning systems beyond the classical binary paradigm.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "37 Pages,9 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.07026v1",
    "published_date": "2025-09-07 13:47:51 UTC",
    "updated_date": "2025-09-07 13:47:51 UTC"
  },
  {
    "arxiv_id": "2510.21712v1",
    "title": "DecoupleSearch: Decouple Planning and Search via Hierarchical Reward Modeling",
    "authors": [
      "Hao Sun",
      "Zile Qiao",
      "Bo Wang",
      "Guoxin Chen",
      "Yingyan Hou",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Yan Zhang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems have emerged as a pivotal methodology for enhancing Large Language Models (LLMs) through the dynamic integration of external knowledge. To further improve RAG's flexibility, Agentic RAG introduces autonomous agents into the workflow. However, Agentic RAG faces several challenges: (1) the success of each step depends on both high-quality planning and accurate search, (2) the lack of supervision for intermediate reasoning steps, and (3) the exponentially large candidate space for planning and searching. To address these challenges, we propose DecoupleSearch, a novel framework that decouples planning and search processes using dual value models, enabling independent optimization of plan reasoning and search grounding. Our approach constructs a reasoning tree, where each node represents planning and search steps. We leverage Monte Carlo Tree Search to assess the quality of each step. During inference, Hierarchical Beam Search iteratively refines planning and search candidates with dual value models. Extensive experiments across policy models of varying parameter sizes, demonstrate the effectiveness of our method.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "EMNLP 2025 Main Conference",
    "pdf_url": "https://arxiv.org/pdf/2510.21712v1",
    "published_date": "2025-09-07 13:45:09 UTC",
    "updated_date": "2025-09-07 13:45:09 UTC"
  },
  {
    "arxiv_id": "2509.06053v1",
    "title": "PolicyEvolve: Evolving Programmatic Policies by LLMs for multi-player games via Population-Based Training",
    "authors": [
      "Mingrui Lv",
      "Hangzhi Liu",
      "Zhi Luo",
      "Hongjie Zhang",
      "Jie Ou"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) has achieved significant progress in solving complex multi-player games through self-play. However, training effective adversarial policies requires millions of experience samples and substantial computational resources. Moreover, these policies lack interpretability, hindering their practical deployment. Recently, researchers have successfully leveraged Large Language Models (LLMs) to generate programmatic policies for single-agent tasks, transforming neural network-based policies into interpretable rule-based code with high execution efficiency. Inspired by this, we propose PolicyEvolve, a general framework for generating programmatic policies in multi-player games. PolicyEvolve significantly reduces reliance on manually crafted policy code, achieving high-performance policies with minimal environmental interactions. The framework comprises four modules: Global Pool, Local Pool, Policy Planner, and Trajectory Critic. The Global Pool preserves elite policies accumulated during iterative training. The Local Pool stores temporary policies for the current iteration; only sufficiently high-performing policies from this pool are promoted to the Global Pool. The Policy Planner serves as the core policy generation module. It samples the top three policies from the Global Pool, generates an initial policy for the current iteration based on environmental information, and refines this policy using feedback from the Trajectory Critic. Refined policies are then deposited into the Local Pool. This iterative process continues until the policy achieves a sufficiently high average win rate against the Global Pool, at which point it is integrated into the Global Pool. The Trajectory Critic analyzes interaction data from the current policy, identifies vulnerabilities, and proposes directional improvements to guide the Policy Planner",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06053v1",
    "published_date": "2025-09-07 13:33:31 UTC",
    "updated_date": "2025-09-07 13:33:31 UTC"
  },
  {
    "arxiv_id": "2509.06052v1",
    "title": "Empirical Study of Code Large Language Models for Binary Security Patch Detection",
    "authors": [
      "Qingyuan Li",
      "Binchang Li",
      "Cuiyun Gao",
      "Shuzheng Gao",
      "Zongjie Li"
    ],
    "abstract": "Security patch detection (SPD) is crucial for maintaining software security, as unpatched vulnerabilities can lead to severe security risks. In recent years, numerous learning-based SPD approaches have demonstrated promising results on source code. However, these approaches typically cannot be applied to closed-source applications and proprietary systems that constitute a significant portion of real-world software, as they release patches only with binary files, and the source code is inaccessible. Given the impressive performance of code large language models (LLMs) in code intelligence and binary analysis tasks such as decompilation and compilation optimization, their potential for detecting binary security patches remains unexplored, exposing a significant research gap between their demonstrated low-level code understanding capabilities and this critical security task. To address this gap, we construct a large-scale binary patch dataset containing \\textbf{19,448} samples, with two levels of representation: assembly code and pseudo-code, and systematically evaluate \\textbf{19} code LLMs of varying scales to investigate their capability in binary SPD tasks. Our initial exploration demonstrates that directly prompting vanilla code LLMs struggles to accurately identify security patches from binary patches, and even state-of-the-art prompting techniques fail to mitigate the lack of domain knowledge in binary SPD within vanilla models. Drawing on the initial findings, we further investigate the fine-tuning strategy for injecting binary SPD domain knowledge into code LLMs through two levels of representation. Experimental results demonstrate that fine-tuned LLMs achieve outstanding performance, with the best results obtained on the pseudo-code representation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06052v1",
    "published_date": "2025-09-07 13:31:43 UTC",
    "updated_date": "2025-09-07 13:31:43 UTC"
  },
  {
    "arxiv_id": "2509.07025v1",
    "title": "1 bit is all we need: binary normalized neural networks",
    "authors": [
      "Eduardo Lobo Lustoda Cabral",
      "Paulo Pirozelli",
      "Larissa Driemeier"
    ],
    "abstract": "The increasing size of large neural network models, specifically language models and foundational image models, poses deployment challenges, prompting efforts to reduce memory requirements and enhance computational efficiency. These efforts are critical to ensure practical deployment and effective utilization of these models across various applications. In this work, a novel type of neural network layers and models is developed that uses only single-bit parameters. In this novel type of models all parameters of all layers, including kernel weights and biases, only have values equal to zero or one. This novel type of models uses layers named as binary normalized layer. These binary normalized layers can be of any type, such as fully connected, convolutional, attention, etc., and they consist of slight variations of the corresponding conventional layers. To show the effectiveness of the binary normalized layers, two different models are configured to solve a multiclass image classification problem and a language decoder to predict the next token of a sequence. The model to solve the image classification has convolutional and fully connected layers, and the language model is composed of transformer blocks with multi-head attention. The results show that models with binary normalized layers present almost the same results obtained by equivalent models with real 32-bit parameters. The binary normalized layers allow to develop models that use 32 times less memory than current models and have equivalent performance. Besides, the binary normalized layers can be easily implemented on current computers using 1-bit arrays, and do not require the development of dedicated electronic hardware. This novel type of layers opens a new era for large neural network models with reduced memory requirements that can be deployed using simple and cheap hardware, such as mobile devices or only cpus.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages; 2 figures; 5 tables; 8 algorithms",
    "pdf_url": "https://arxiv.org/pdf/2509.07025v1",
    "published_date": "2025-09-07 13:27:15 UTC",
    "updated_date": "2025-09-07 13:27:15 UTC"
  },
  {
    "arxiv_id": "2509.06040v5",
    "title": "BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models",
    "authors": [
      "Yuming Li",
      "Yikai Wang",
      "Yuying Zhu",
      "Zhongyu Zhao",
      "Ming Lu",
      "Qi She",
      "Shanghang Zhang"
    ],
    "abstract": "Recent progress in aligning image and video generative models with Group Relative Policy Optimization (GRPO) has improved human preference alignment, but existing variants remain inefficient due to sequential rollouts and large numbers of sampling steps, unreliable credit assignment: sparse terminal rewards are uniformly propagated across timesteps, failing to capture the varying criticality of decisions during denoising. In this paper, we present BranchGRPO, a method that restructures the rollout process into a branching tree, where shared prefixes amortize computation and pruning removes low-value paths and redundant depths. BranchGRPO introduces three contributions: (1) a branching scheme that amortizes rollout cost through shared prefixes while preserving exploration diversity; (2) a reward fusion and depth-wise advantage estimator that transforms sparse terminal rewards into dense step-level signals; and (3) pruning strategies that cut gradient computation but leave forward rollouts and exploration unaffected. On HPDv2.1 image alignment, BranchGRPO improves alignment scores by up to \\textbf{16\\%} over DanceGRPO, while reducing per-iteration training time by nearly \\textbf{55\\%}. A hybrid variant, BranchGRPO-Mix, further accelerates training to 4.7x faster than DanceGRPO without degrading alignment. On WanX video generation, it further achieves higher Video-Align scores with sharper and temporally consistent frames compared to DanceGRPO. Codes are available at \\href{https://fredreic1849.github.io/BranchGRPO-Webpage/}{BranchGRPO}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.06040v5",
    "published_date": "2025-09-07 12:53:06 UTC",
    "updated_date": "2025-09-29 13:20:45 UTC"
  },
  {
    "arxiv_id": "2509.06035v9",
    "title": "TinyDef-DETR: A Transformer-Based Framework for Defect Detection in Transmission Lines from UAV Imagery",
    "authors": [
      "Feng Shen",
      "Jiaming Cui",
      "Wenqiang Li",
      "Shuai Zhou"
    ],
    "abstract": "Automated defect detection from UAV imagery of transmission lines is a challenging task due to the small size, ambiguity, and complex backgrounds of defects. This paper proposes TinyDef-DETR, a DETR-based framework designed to achieve accurate and efficient detection of transmission line defects from UAV-acquired images. The model integrates four major components: an edge-enhanced ResNet backbone to strengthen boundary-sensitive representations, a stride-free space-to-depth module to enable detail-preserving downsampling, a cross-stage dual-domain multi-scale attention mechanism to jointly model global context and local cues, and a Focaler-Wise-SIoU regression loss to improve the localization of small and difficult objects. Together, these designs effectively mitigate the limitations of conventional detectors. Extensive experiments on both public and real-world datasets demonstrate that TinyDef-DETR achieves superior detection performance and strong generalization capability, while maintaining modest computational overhead. The accuracy and efficiency of TinyDef-DETR make it a suitable method for UAV-based transmission line defect detection, particularly in scenarios involving small and ambiguous objects.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06035v9",
    "published_date": "2025-09-07 12:36:33 UTC",
    "updated_date": "2025-11-13 07:30:16 UTC"
  },
  {
    "arxiv_id": "2509.06027v1",
    "title": "DreamAudio: Customized Text-to-Audio Generation with Diffusion Models",
    "authors": [
      "Yi Yuan",
      "Xubo Liu",
      "Haohe Liu",
      "Xiyuan Kang",
      "Zhuo Chen",
      "Yuxuan Wang",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "abstract": "With the development of large-scale diffusion-based and language-modeling-based generative models, impressive progress has been achieved in text-to-audio generation. Despite producing high-quality outputs, existing text-to-audio models mainly aim to generate semantically aligned sound and fall short on precisely controlling fine-grained acoustic characteristics of specific sounds. As a result, users that need specific sound content may find it challenging to generate the desired audio clips. In this paper, we present DreamAudio for customized text-to-audio generation (CTTA). Specifically, we introduce a new framework that is designed to enable the model to identify auditory information from user-provided reference concepts for audio generation. Given a few reference audio samples containing personalized audio events, our system can generate new audio samples that include these specific events. In addition, two types of datasets are developed for training and testing the customized systems. The experiments show that the proposed model, DreamAudio, generates audio samples that are highly consistent with the customized audio features and aligned well with the input text prompts. Furthermore, DreamAudio offers comparable performance in general text-to-audio tasks. We also provide a human-involved dataset containing audio events from real-world CTTA cases as the benchmark for customized generation tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Demos are available at https://yyua8222.github.io/DreamAudio_demopage/",
    "pdf_url": "https://arxiv.org/pdf/2509.06027v1",
    "published_date": "2025-09-07 12:06:21 UTC",
    "updated_date": "2025-09-07 12:06:21 UTC"
  },
  {
    "arxiv_id": "2509.06026v1",
    "title": "DCMI: A Differential Calibration Membership Inference Attack Against Retrieval-Augmented Generation",
    "authors": [
      "Xinyu Gao",
      "Xiangtao Meng",
      "Yingkai Dong",
      "Zheng Li",
      "Shanqing Guo"
    ],
    "abstract": "While Retrieval-Augmented Generation (RAG) effectively reduces hallucinations by integrating external knowledge bases, it introduces vulnerabilities to membership inference attacks (MIAs), particularly in systems handling sensitive data. Existing MIAs targeting RAG's external databases often rely on model responses but ignore the interference of non-member-retrieved documents on RAG outputs, limiting their effectiveness. To address this, we propose DCMI, a differential calibration MIA that mitigates the negative impact of non-member-retrieved documents. Specifically, DCMI leverages the sensitivity gap between member and non-member retrieved documents under query perturbation. It generates perturbed queries for calibration to isolate the contribution of member-retrieved documents while minimizing the interference from non-member-retrieved documents. Experiments under progressively relaxed assumptions show that DCMI consistently outperforms baselines--for example, achieving 97.42% AUC and 94.35% Accuracy against the RAG system with Flan-T5, exceeding the MBA baseline by over 40%. Furthermore, on real-world RAG platforms such as Dify and MaxKB, DCMI maintains a 10%-20% advantage over the baseline. These results highlight significant privacy risks in RAG systems and emphasize the need for stronger protection mechanisms. We appeal to the community's consideration of deeper investigations, like ours, against the data leakage risks in rapidly evolving RAG systems. Our code is available at https://github.com/Xinyu140203/RAG_MIA.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06026v1",
    "published_date": "2025-09-07 11:58:02 UTC",
    "updated_date": "2025-09-07 11:58:02 UTC"
  },
  {
    "arxiv_id": "2509.06025v1",
    "title": "Unified Interaction Foundational Model (UIFM) for Predicting Complex User and System Behavior",
    "authors": [
      "Vignesh Ethiraj",
      "Subhash Talluri"
    ],
    "abstract": "A central goal of artificial intelligence is to build systems that can understand and predict complex, evolving sequences of events. However, current foundation models, designed for natural language, fail to grasp the holistic nature of structured interactions found in domains like telecommunications, e-commerce and finance. By serializing events into text, they disassemble them into semantically fragmented parts, losing critical context. In this work, we introduce the Unified Interaction Foundation Model (UIFM), a foundation model engineered for genuine behavioral understanding. At its core is the principle of composite tokenization, where each multi-attribute event is treated as a single, semantically coherent unit. This allows UIFM to learn the underlying \"grammar\" of user behavior, perceiving entire interactions rather than a disconnected stream of data points. We demonstrate that this architecture is not just more accurate, but represents a fundamental step towards creating more adaptable and intelligent predictive systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06025v1",
    "published_date": "2025-09-07 11:57:41 UTC",
    "updated_date": "2025-09-07 11:57:41 UTC"
  },
  {
    "arxiv_id": "2509.06024v1",
    "title": "Rethinking Reasoning Quality in Large Language Models through Enhanced Chain-of-Thought via RL",
    "authors": [
      "Haoyang He",
      "Zihua Rong",
      "Kun Ji",
      "Chenyang Li",
      "Qing Huang",
      "Chong Xia",
      "Lan Yang",
      "Honggang Zhang"
    ],
    "abstract": "Reinforcement learning (RL) has recently become the dominant paradigm for strengthening the reasoning abilities of large language models (LLMs). Yet the rule-based reward functions commonly used on mathematical or programming benchmarks assess only answer format and correctness, providing no signal as to whether the induced Chain-of-Thought (CoT) actually improves the answer. Furthermore, such task-specific training offers limited control over logical depth and therefore may fail to reveal a model's genuine reasoning capacity. We propose Dynamic Reasoning Efficiency Reward (DRER) -- a plug-and-play RL reward framework that reshapes both reward and advantage signals. (i) A Reasoning Quality Reward assigns fine-grained credit to those reasoning chains that demonstrably raise the likelihood of the correct answer, directly incentivising the trajectories with beneficial CoT tokens. (ii) A Dynamic Length Advantage decays the advantage of responses whose length deviates from a validation-derived threshold, stabilising training. To facilitate rigorous assessment, we also release Logictree, a dynamically constructed deductive reasoning dataset that functions both as RL training data and as a comprehensive benchmark. Experiments confirm the effectiveness of DRER: our 7B model attains GPT-o3-mini level performance on Logictree with 400 trianing steps, while the average confidence of CoT-augmented answers rises by 30%. The model further exhibits generalisation across diverse logical-reasoning datasets, and the mathematical benchmark AIME24. These results illuminate how RL shapes CoT behaviour and chart a practical path toward enhancing formal-reasoning skills in large language models. All code and data are available in repository https://github.com/Henryhe09/DRER.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06024v1",
    "published_date": "2025-09-07 11:52:18 UTC",
    "updated_date": "2025-09-07 11:52:18 UTC"
  },
  {
    "arxiv_id": "2509.06006v1",
    "title": "Khana: A Comprehensive Indian Cuisine Dataset",
    "authors": [
      "Omkar Prabhu"
    ],
    "abstract": "As global interest in diverse culinary experiences grows, food image models are essential for improving food-related applications by enabling accurate food recognition, recipe suggestions, dietary tracking, and automated meal planning. Despite the abundance of food datasets, a noticeable gap remains in capturing the nuances of Indian cuisine due to its vast regional diversity, complex preparations, and the lack of comprehensive labeled datasets that cover its full breadth. Through this exploration, we uncover Khana, a new benchmark dataset for food image classification, segmentation, and retrieval of dishes from Indian cuisine. Khana fills the gap by establishing a taxonomy of Indian cuisine and offering around 131K images in the dataset spread across 80 labels, each with a resolution of 500x500 pixels. This paper describes the dataset creation process and evaluates state-of-the-art models on classification, segmentation, and retrieval as baselines. Khana bridges the gap between research and development by providing a comprehensive and challenging benchmark for researchers while also serving as a valuable resource for developers creating real-world applications that leverage the rich tapestry of Indian cuisine. Webpage: https://khana.omkar.xyz",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06006v1",
    "published_date": "2025-09-07 10:43:29 UTC",
    "updated_date": "2025-09-07 10:43:29 UTC"
  },
  {
    "arxiv_id": "2509.09709v1",
    "title": "Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement",
    "authors": [
      "Jing Ren",
      "Weiqi Wang"
    ],
    "abstract": "Large language models (LLMs) like ChatGPT are increasingly used in academic writing, yet issues such as incorrect or fabricated references raise ethical concerns. Moreover, current content quality evaluations often rely on subjective human judgment, which is labor-intensive and lacks objectivity, potentially compromising the consistency and reliability. In this study, to provide a quantitative evaluation and enhance research proposal writing capabilities of LLMs, we propose two key evaluation metrics--content quality and reference validity--and an iterative prompting method based on the scores derived from these two metrics. Our extensive experiments show that the proposed metrics provide an objective, quantitative framework for assessing ChatGPT's writing performance. Additionally, iterative prompting significantly enhances content quality while reducing reference inaccuracies and fabrications, addressing critical ethical challenges in academic contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09709v1",
    "published_date": "2025-09-07 10:24:28 UTC",
    "updated_date": "2025-09-07 10:24:28 UTC"
  },
  {
    "arxiv_id": "2509.05999v1",
    "title": "S-LAM3D: Segmentation-Guided Monocular 3D Object Detection via Feature Space Fusion",
    "authors": [
      "Diana-Alexandra Sas",
      "Florin Oniga"
    ],
    "abstract": "Monocular 3D Object Detection represents a challenging Computer Vision task due to the nature of the input used, which is a single 2D image, lacking in any depth cues and placing the depth estimation problem as an ill-posed one. Existing solutions leverage the information extracted from the input by using Convolutional Neural Networks or Transformer architectures as feature extraction backbones, followed by specific detection heads for 3D parameters prediction. In this paper, we introduce a decoupled strategy based on injecting precomputed segmentation information priors and fusing them directly into the feature space for guiding the detection, without expanding the detection model or jointly learning the priors. The focus is on evaluating the impact of additional segmentation information on existing detection pipelines without adding additional prediction branches. The proposed method is evaluated on the KITTI 3D Object Detection Benchmark, outperforming the equivalent architecture that relies only on RGB image features for small objects in the scene: pedestrians and cyclists, and proving that understanding the input data can balance the need for additional sensors or training data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages. Accepted to MMSP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.05999v1",
    "published_date": "2025-09-07 10:14:56 UTC",
    "updated_date": "2025-09-07 10:14:56 UTC"
  },
  {
    "arxiv_id": "2509.05985v1",
    "title": "Operationalising AI Regulatory Sandboxes under the EU AI Act: The Triple Challenge of Capacity, Coordination and Attractiveness to Providers",
    "authors": [
      "Deirdre Ahern"
    ],
    "abstract": "The EU AI Act provides a rulebook for all AI systems being put on the market or into service in the European Union. This article investigates the requirement under the AI Act that Member States establish national AI regulatory sandboxes for testing and validation of innovative AI systems under regulatory supervision to assist with fostering innovation and complying with regulatory requirements. Against the backdrop of the EU objective that AI regulatory sandboxes would both foster innovation and assist with compliance, considerable challenges are identified for Member States around capacity-building and design of regulatory sandboxes. While Member States are early movers in laying the ground for national AI regulatory sandboxes, the article contends that there is a risk that differing approaches being taken by individual national sandboxes could jeopardise a uniform interpretation of the AI Act and its application in practice. This could motivate innovators to play sandbox arbitrage. The article therefore argues that the European Commission and the AI Board need to act decisively in developing rules and guidance to ensure a cohesive, coordinated approach in national AI regulatory sandboxes. With sandbox participation being voluntary, the possibility that AI regulatory sandboxes may prove unattractive to innovators on their compliance journey is also explored. Confidentiality concerns, the inability to relax legal rules during the sandbox, and the inability of sandboxes to deliver a presumption of conformity with the AI Act are identified as pertinent concerns for innovators contemplating applying to AI regulatory sandboxes as compared with other direct compliance routes provided to them through application of harmonised standards and conformity assessment procedures.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05985v1",
    "published_date": "2025-09-07 09:20:40 UTC",
    "updated_date": "2025-09-07 09:20:40 UTC"
  },
  {
    "arxiv_id": "2509.05983v3",
    "title": "TSPC: A Two-Stage Phoneme-Centric Architecture for code-switching Vietnamese-English Speech Recognition",
    "authors": [
      "Minh N. H. Nguyen",
      "Anh Nguyen Tran",
      "Dung Truong Dinh",
      "Nam Van Vo"
    ],
    "abstract": "Code-switching (CS) presents a significant challenge for general Auto-Speech Recognition (ASR) systems. Existing methods often fail to capture the subtle phonological shifts inherent in CS scenarios. The challenge is particularly difficult for language pairs like Vietnamese and English, where both distinct phonological features and the ambiguity arising from similar sound recognition are present. In this paper, we propose a novel architecture for Vietnamese-English CS ASR, a Two-Stage Phoneme-Centric model (TSPC). The TSPC employs a phoneme-centric approach, built upon an extended Vietnamese phoneme set as an intermediate representation to facilitate mixed-lingual modeling. Experimental results demonstrate that TSPC consistently outperforms existing baselines, including PhoWhisper-base, in Vietnamese-English CS ASR, achieving a significantly lower word error rate of 19.9% with reduced training resources. Furthermore, the phonetic-based two-stage architecture enables phoneme adaptation and language conversion to enhance ASR performance in complex CS Vietnamese-English ASR scenarios",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Update new version",
    "pdf_url": "https://arxiv.org/pdf/2509.05983v3",
    "published_date": "2025-09-07 09:19:03 UTC",
    "updated_date": "2025-09-20 14:15:55 UTC"
  },
  {
    "arxiv_id": "2509.07022v1",
    "title": "Preventing Another Tessa: Modular Safety Middleware For Health-Adjacent AI Assistants",
    "authors": [
      "Pavan Reddy",
      "Nithin Reddy"
    ],
    "abstract": "In 2023, the National Eating Disorders Association's (NEDA) chatbot Tessa was suspended after providing harmful weight-loss advice to vulnerable users-an avoidable failure that underscores the risks of unsafe AI in healthcare contexts. This paper examines Tessa as a case study in absent safety engineering and demonstrates how a lightweight, modular safeguard could have prevented the incident. We propose a hybrid safety middleware that combines deterministic lexical gates with an in-line large language model (LLM) policy filter, enforcing fail-closed verdicts and escalation pathways within a single model call. Using synthetic evaluations, we show that this design achieves perfect interception of unsafe prompts at baseline cost and latency, outperforming traditional multi-stage pipelines. Beyond technical remedies, we map Tessa's failure patterns to established frameworks (OWASP LLM Top10, NIST SP 800-53), connecting practical safeguards to actionable governance controls. The results highlight that robust, auditable safety in health-adjacent AI does not require heavyweight infrastructure: explicit, testable checks at the last mile are sufficient to prevent \"another Tessa\", while governance and escalation ensure sustainability in real-world deployment.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages content, 1 page reference, 1 figure, Accepted at AAAI Fall Symposium Series",
    "pdf_url": "https://arxiv.org/pdf/2509.07022v1",
    "published_date": "2025-09-07 08:43:39 UTC",
    "updated_date": "2025-09-07 08:43:39 UTC"
  },
  {
    "arxiv_id": "2509.05975v1",
    "title": "ConstStyle: Robust Domain Generalization with Unified Style Transformation",
    "authors": [
      "Nam Duong Tran",
      "Nam Nguyen Phuong",
      "Hieu H. Pham",
      "Phi Le Nguyen",
      "My T. Thai"
    ],
    "abstract": "Deep neural networks often suffer performance drops when test data distribution differs from training data. Domain Generalization (DG) aims to address this by focusing on domain-invariant features or augmenting data for greater diversity. However, these methods often struggle with limited training domains or significant gaps between seen (training) and unseen (test) domains. To enhance DG robustness, we hypothesize that it is essential for the model to be trained on data from domains that closely resemble unseen test domains-an inherently difficult task due to the absence of prior knowledge about the unseen domains. Accordingly, we propose ConstStyle, a novel approach that leverages a unified domain to capture domain-invariant features and bridge the domain gap with theoretical analysis. During training, all samples are mapped onto this unified domain, optimized for seen domains. During testing, unseen domain samples are projected similarly before predictions. By aligning both training and testing data within this unified domain, ConstStyle effectively reduces the impact of domain shifts, even with large domain gaps or few seen domains. Extensive experiments demonstrate that ConstStyle consistently outperforms existing methods across diverse scenarios. Notably, when only a limited number of seen domains are available, ConstStyle can boost accuracy up to 19.82\\% compared to the next best approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.05975v1",
    "published_date": "2025-09-07 08:40:19 UTC",
    "updated_date": "2025-09-07 08:40:19 UTC"
  },
  {
    "arxiv_id": "2509.07021v2",
    "title": "MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians and Unified Pruning",
    "authors": [
      "Jiarui Chen",
      "Yikeng Chen",
      "Yingshuang Zou",
      "Ye Huang",
      "Peng Wang",
      "Yuan Liu",
      "Yujing Sun",
      "Wenping Wang"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) has emerged as a dominant novel-view synthesis technique, but its high memory consumption severely limits its applicability on edge devices. A growing number of 3DGS compression methods have been proposed to make 3DGS more efficient, yet most only focus on storage compression and fail to address the critical bottleneck of rendering memory. To address this problem, we introduce MEGS$^{2}$, a novel memory-efficient framework that tackles this challenge by jointly optimizing two key factors: the total primitive number and the parameters per primitive, achieving unprecedented memory compression. Specifically, we replace the memory-intensive spherical harmonics with lightweight, arbitrarily oriented spherical Gaussian lobes as our color representations. More importantly, we propose a unified soft pruning framework that models primitive-number and lobe-number pruning as a single constrained optimization problem. Experiments show that MEGS$^{2}$ achieves a 50% static VRAM reduction and a 40% rendering VRAM reduction compared to existing methods, while maintaining comparable rendering quality. Project page: https://megs-2.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 8 figures. Project page at https://megs-2.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2509.07021v2",
    "published_date": "2025-09-07 07:06:03 UTC",
    "updated_date": "2025-09-23 17:01:06 UTC"
  },
  {
    "arxiv_id": "2509.05933v2",
    "title": "MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration",
    "authors": [
      "Md Hasebul Hasan",
      "Mahir Labib Dihan",
      "Tanzima Hashem",
      "Mohammed Eunus Ali",
      "Md Rizwan Parvez"
    ],
    "abstract": "Agentic AI has significantly extended the capabilities of large language models (LLMs) by enabling complex reasoning and tool use. However, most existing frameworks are tailored to domains such as mathematics, coding, or web automation, and fall short on geospatial tasks that require spatial reasoning, multi-hop planning, and real-time map interaction. To address these challenges, we introduce MapAgent, a hierarchical multi-agent plug-and-play framework with customized toolsets and agentic scaffolds for map-integrated geospatial reasoning. Unlike existing flat agent-based approaches that treat tools uniformly-often overwhelming the LLM when handling similar but subtly different geospatial APIs-MapAgent decouples planning from execution. A high-level planner decomposes complex queries into subgoals, which are routed to specialized modules. For tool-heavy modules-such as map-based services-we then design a dedicated map-tool agent that efficiently orchestrates related APIs adaptively in parallel to effectively fetch geospatial data relevant for the query, while simpler modules (e.g., solution generation or answer extraction) operate without additional agent overhead. This hierarchical design reduces cognitive load, improves tool selection accuracy, and enables precise coordination across similar APIs. We evaluate MapAgent on four diverse geospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and MapQA-and demonstrate substantial gains over state-of-the-art tool-augmented and agentic baselines. We open-source our framwork at https://github.com/Hasebul/MapAgent.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "27 Pages",
    "pdf_url": "https://arxiv.org/pdf/2509.05933v2",
    "published_date": "2025-09-07 05:47:58 UTC",
    "updated_date": "2025-10-14 04:15:07 UTC"
  },
  {
    "arxiv_id": "2509.05926v1",
    "title": "Meta-training of diffractive meta-neural networks for super-resolution direction of arrival estimation",
    "authors": [
      "Songtao Yang",
      "Sheng Gao",
      "Chu Wu",
      "Zejia Zhao",
      "Haiou Zhang",
      "Xing Lin"
    ],
    "abstract": "Diffractive neural networks leverage the high-dimensional characteristics of electromagnetic (EM) fields for high-throughput computing. However, the existing architectures face challenges in integrating large-scale multidimensional metasurfaces with precise network training and haven't utilized multidimensional EM field coding scheme for super-resolution sensing. Here, we propose diffractive meta-neural networks (DMNNs) for accurate EM field modulation through metasurfaces, which enable multidimensional multiplexing and coding for multi-task learning and high-throughput super-resolution direction of arrival estimation. DMNN integrates pre-trained mini-metanets to characterize the amplitude and phase responses of meta-atoms across different polarizations and frequencies, with structure parameters inversely designed using the gradient-based meta-training. For wide-field super-resolution angle estimation, the system simultaneously resolves azimuthal and elevational angles through x and y-polarization channels, while the interleaving of frequency-multiplexed angular intervals generates spectral-encoded optical super-oscillations to achieve full-angle high-resolution estimation. Post-processing lightweight electronic neural networks further enhance the performance. Experimental results validate that a three-layer DMNN operating at 27 GHz, 29 GHz, and 31 GHz achieves $\\sim7\\times$ Rayleigh diffraction-limited angular resolution (0.5$^\\circ$), a mean absolute error of 0.048$^\\circ$ for two incoherent targets within a $\\pm 11.5^\\circ$ field of view, and an angular estimation throughput an order of magnitude higher (1917) than that of existing methods. The proposed architecture advances high-dimensional photonic computing systems by utilizing inherent high-parallelism and all-optical coding methods for ultra-high-resolution, high-throughput applications.",
    "categories": [
      "physics.optics",
      "cs.AI",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics",
    "comment": "47 pages, 17 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.05926v1",
    "published_date": "2025-09-07 04:49:51 UTC",
    "updated_date": "2025-09-07 04:49:51 UTC"
  },
  {
    "arxiv_id": "2509.07019v1",
    "title": "An efficient deep reinforcement learning environment for flexible job-shop scheduling",
    "authors": [
      "Xinquan Wu",
      "Xuefeng Yan",
      "Mingqiang Wei",
      "Donghai Guan"
    ],
    "abstract": "The Flexible Job-shop Scheduling Problem (FJSP) is a classical combinatorial optimization problem that has a wide-range of applications in the real world. In order to generate fast and accurate scheduling solutions for FJSP, various deep reinforcement learning (DRL) scheduling methods have been developed. However, these methods are mainly focused on the design of DRL scheduling Agent, overlooking the modeling of DRL environment. This paper presents a simple chronological DRL environment for FJSP based on discrete event simulation and an end-to-end DRL scheduling model is proposed based on the proximal policy optimization (PPO). Furthermore, a short novel state representation of FJSP is proposed based on two state variables in the scheduling environment and a novel comprehensible reward function is designed based on the scheduling area of machines. Experimental results on public benchmark instances show that the performance of simple priority dispatching rules (PDR) is improved in our scheduling environment and our DRL scheduling model obtains competing performance compared with OR-Tools, meta-heuristic, DRL and PDR scheduling methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.07019v1",
    "published_date": "2025-09-07 02:50:09 UTC",
    "updated_date": "2025-09-07 02:50:09 UTC"
  },
  {
    "arxiv_id": "2509.09708v2",
    "title": "Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal",
    "authors": [
      "Nirmalendu Prakash",
      "Yeo Wei Jie",
      "Amir Abdullah",
      "Ranjan Satapathy",
      "Erik Cambria",
      "Roy Ka Wei Lee"
    ],
    "abstract": "Refusal on harmful prompts is a key safety behaviour in instruction-tuned large language models (LLMs), yet the internal causes of this behaviour remain poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on residual-stream activations. Given a harmful prompt, we search the SAE latent space for feature sets whose ablation flips the model from refusal to compliance, demonstrating causal influence and creating a jailbreak. Our search proceeds in three stages: (1) Refusal Direction: find a refusal-mediating direction and collect SAE features near that direction; (2) Greedy Filtering: prune to a minimal set; and (3) Interaction Discovery: fit a factorization machine (FM) that captures nonlinear interactions among the remaining active features and the minimal set. This pipeline yields a broad set of jailbreak-critical features, offering insight into the mechanistic basis of refusal. Moreover, we find evidence of redundant features that remain dormant unless earlier features are suppressed. Our findings highlight the potential for fine-grained auditing and targeted intervention in safety behaviours by manipulating the interpretable latent space.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.09708v2",
    "published_date": "2025-09-07 02:29:07 UTC",
    "updated_date": "2025-10-10 07:46:26 UTC"
  },
  {
    "arxiv_id": "2509.05892v1",
    "title": "Challenges in Deep Learning-Based Small Organ Segmentation: A Benchmarking Perspective for Medical Research with Limited Datasets",
    "authors": [
      "Phongsakon Mark Konrad",
      "Andrei-Alexandru Popa",
      "Yaser Sabzehmeidani",
      "Liang Zhong",
      "Elisa A. Liehn",
      "Serkan Ayvaz"
    ],
    "abstract": "Accurate segmentation of carotid artery structures in histopathological images is vital for advancing cardiovascular disease research and diagnosis. However, deep learning model development in this domain is constrained by the scarcity of annotated cardiovascular histopathological data. This study investigates a systematic evaluation of state-of-the-art deep learning segmentation models, including convolutional neural networks (U-Net, DeepLabV3+), a Vision Transformer (SegFormer), and recent foundation models (SAM, MedSAM, MedSAM+UNet), on a limited dataset of cardiovascular histology images. Despite employing an extensive hyperparameter optimization strategy with Bayesian search, our findings reveal that model performance is highly sensitive to data splits, with minor differences driven more by statistical noise than by true algorithmic superiority. This instability exposes the limitations of standard benchmarking practices in low-data clinical settings and challenges the assumption that performance rankings reflect meaningful clinical utility.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05892v1",
    "published_date": "2025-09-07 01:54:20 UTC",
    "updated_date": "2025-09-07 01:54:20 UTC"
  },
  {
    "arxiv_id": "2509.05890v2",
    "title": "Quantum spatial best-arm identification via quantum walks",
    "authors": [
      "Tomoki Yamagami",
      "Etsuo Segawa",
      "Takatomo Mihana",
      "André Röhm",
      "Atsushi Uchida",
      "Ryoichi Horisaki"
    ],
    "abstract": "Quantum reinforcement learning has emerged as a framework combining quantum computation with sequential decision-making, and applications to the multi-armed bandit (MAB) problem have been reported. The graph bandit problem extends the MAB setting by introducing spatial constraints, yet quantum approaches remain limited. We propose a quantum algorithmic framework for best-arm identification in graph bandits, termed Quantum Spatial Best-Arm Identification (QSBAI), which is applicable to general graph structures. The method employs quantum walks to encode superpositions over graph-constrained actions, extending amplitude amplification and generalizing the Quantum BAI algorithm via Szegedy's walk framework. This establishes a link between Grover-type search and reinforcement learning tasks with structural restrictions. We focus our theoretical analysis on complete and bipartite graphs, deriving the maximal success probability of identifying the best arm and the time step at which it is achieved. Our results highlight the potential of quantum walks to accelerate exploration in constrained environments and extend the applicability of quantum algorithms for decision-making.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "math-ph"
    ],
    "primary_category": "quant-ph",
    "comment": "15 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.05890v2",
    "published_date": "2025-09-07 01:53:09 UTC",
    "updated_date": "2026-01-19 06:46:47 UTC"
  },
  {
    "arxiv_id": "2509.10544v1",
    "title": "ASL360: AI-Enabled Adaptive Streaming of Layered 360° Video over UAV-assisted Wireless Networks",
    "authors": [
      "Alireza Mohammadhosseini",
      "Jacob Chakareski",
      "Nicholas Mastronarde"
    ],
    "abstract": "We propose ASL360, an adaptive deep reinforcement learning-based scheduler for on-demand 360° video streaming to mobile VR users in next generation wireless networks. We aim to maximize the overall Quality of Experience (QoE) of the users served over a UAV-assisted 5G wireless network. Our system model comprises a macro base station (MBS) and a UAV-mounted base station which both deploy mm-Wave transmission to the users. The 360° video is encoded into dependent layers and segmented tiles, allowing a user to schedule downloads of each layer's segments. Furthermore, each user utilizes multiple buffers to store the corresponding video layer's segments. We model the scheduling decision as a Constrained Markov Decision Process (CMDP), where the agent selects Base or Enhancement layers to maximize the QoE and use a policy gradient-based method (PPO) to find the optimal policy. Additionally, we implement a dynamic adjustment mechanism for cost components, allowing the system to adaptively balance and prioritize the video quality, buffer occupancy, and quality change based on real-time network and streaming session conditions. We demonstrate that ASL360 significantly improves the QoE, achieving approximately 2 dB higher average video quality, 80% lower average rebuffering time, and 57% lower video quality variation, relative to competitive baseline methods. Our results show the effectiveness of our layered and adaptive approach in enhancing the QoE in immersive videostreaming applications, particularly in dynamic and challenging network environments.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.NI",
    "comment": "This paper has been accepted for presentation at the IEEE Global Communications Conference (GLOBECOM) 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.10544v1",
    "published_date": "2025-09-07 01:22:57 UTC",
    "updated_date": "2025-09-07 01:22:57 UTC"
  },
  {
    "arxiv_id": "2509.07017v1",
    "title": "From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning",
    "authors": [
      "Andrew Kiruluta",
      "Priscilla Burity"
    ],
    "abstract": "We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning framework that embeds logical rules as spectral templates and performs inference directly in the graph spectral domain. By leveraging graph signal processing (GSP) and frequency-selective filters grounded in the Laplacian eigenstructure of knowledge graphs, the architecture unifies the interpretability of symbolic reasoning with the scalability and adaptability of spectral learning. Beyond the core formulation, we incorporate a comprehensive set of extensions, including dynamic graph and basis learning, rational and diffusion filters for sharper spectral selectivity, mixture-of-spectral-experts for modular specialization, proof-guided training with spectral curricula, and uncertainty quantification for calibrated confidence. Additional enhancements such as large language model coupling, co-spectral transfer alignment, adversarial robustness, efficient GPU kernels, generalized Laplacians, and causal interventions further expand the versatility of the framework.\n  Empirical evaluation on state-of-the-art reasoning benchmarks such as ProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior accuracy, faster inference, improved robustness to adversarial perturbations, and higher interpretability compared to leading baselines including transformers, message-passing neural networks, and neuro-symbolic logic programming systems. Spectral attribution and proof-band agreement analyses confirm that model decisions align closely with symbolic proof structures, while transfer experiments validate effective domain adaptation through co-spectral alignment. These results establish Spectral NSR as a scalable and principled foundation for the next generation of reasoning systems, offering transparency, robustness, and generalization beyond conventional approaches.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.07017v1",
    "published_date": "2025-09-07 01:12:20 UTC",
    "updated_date": "2025-09-07 01:12:20 UTC"
  },
  {
    "arxiv_id": "2509.05883v1",
    "title": "Multimodal Prompt Injection Attacks: Risks and Defenses for Modern LLMs",
    "authors": [
      "Andrew Yeo",
      "Daeseon Choi"
    ],
    "abstract": "Large Language Models (LLMs) have seen rapid adoption in recent years, with industries increasingly relying on them to maintain a competitive advantage. These models excel at interpreting user instructions and generating human-like responses, leading to their integration across diverse domains, including consulting and information retrieval. However, their widespread deployment also introduces substantial security risks, most notably in the form of prompt injection and jailbreak attacks.\n  To systematically evaluate LLM vulnerabilities -- particularly to external prompt injection -- we conducted a series of experiments on eight commercial models. Each model was tested without supplementary sanitization, relying solely on its built-in safeguards. The results exposed exploitable weaknesses and emphasized the need for stronger security measures. Four categories of attacks were examined: direct injection, indirect (external) injection, image-based injection, and prompt leakage. Comparative analysis indicated that Claude 3 demonstrated relatively greater robustness; nevertheless, empirical findings confirm that additional defenses, such as input normalization, remain necessary to achieve reliable protection.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 4 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.05883v1",
    "published_date": "2025-09-07 01:11:10 UTC",
    "updated_date": "2025-09-07 01:11:10 UTC"
  },
  {
    "arxiv_id": "2509.05882v2",
    "title": "Collaborate, Deliberate, Evaluate: How LLM Alignment Affects Coordinated Multi-Agent Outcomes",
    "authors": [
      "Abhijnan Nath",
      "Carine Graff",
      "Nikhil Krishnaswamy"
    ],
    "abstract": "As Large Language Models (LLMs) get integrated into diverse workflows, they are increasingly being regarded as \"collaborators\" with humans, and required to work in coordination with other AI systems. If such AI collaborators are to reliably coordinate their actions and behaviors with humans or other AIs, their properties and behaviors over multi-turn interactions must be known and predictable. This paper examines how different alignment methods affect LLM agents' effectiveness as partners in multi-turn, multi-party collaborations. We study this question through the lens of intervention agents that insert themselves into group dialogues not to provide answers, but to encourage the collaborative group to slow down and reflect upon their reasoning for deliberative decision-making. Common alignment techniques are typically developed under simplified single-user settings and assume the optimality of the underlying token MDP. Using the theoretical lens of the modified-action MDP, we show how they do not account for the dynamics of long-horizon multi-party interactions. We present a novel roleplay simulation methodology, where we align LLMs according to different methods and then deploy them in collaborative task dialogues to quantify how interventions affect the trajectory of group collaboration, belief alignment, and coordination. Our results show that an intervention agent that is robust to action modification significantly outperforms common alignment baselines in supporting correct task outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This submission is a new version of arXiv:2509.05882v1. with a substantially revised experimental pipeline and new metrics. In particular, collaborator agents are now instantiated independently via separate API calls, rather than generated autoregressively by a single agent. All experimental results are new. Accepted as an extended abstract at AAMAS 2026",
    "pdf_url": "https://arxiv.org/pdf/2509.05882v2",
    "published_date": "2025-09-07 00:58:10 UTC",
    "updated_date": "2026-01-21 21:29:06 UTC"
  },
  {
    "arxiv_id": "2509.05881v1",
    "title": "GeoAnalystBench: A GeoAI benchmark for assessing large language models for spatial analysis workflow and code generation",
    "authors": [
      "Qianheng Zhang",
      "Song Gao",
      "Chen Wei",
      "Yibo Zhao",
      "Ying Nie",
      "Ziru Chen",
      "Shijie Chen",
      "Yu Su",
      "Huan Sun"
    ],
    "abstract": "Recent advances in large language models (LLMs) have fueled growing interest in automating geospatial analysis and GIS workflows, yet their actual capabilities remain uncertain. In this work, we call for rigorous evaluation of LLMs on well-defined geoprocessing tasks before making claims about full GIS automation. To this end, we present GeoAnalystBench, a benchmark of 50 Python-based tasks derived from real-world geospatial problems and carefully validated by GIS experts. Each task is paired with a minimum deliverable product, and evaluation covers workflow validity, structural alignment, semantic similarity, and code quality (CodeBLEU). Using this benchmark, we assess both proprietary and open source models. Results reveal a clear gap: proprietary models such as ChatGPT-4o-mini achieve high validity 95% and stronger code alignment (CodeBLEU 0.39), while smaller open source models like DeepSeek-R1-7B often generate incomplete or inconsistent workflows (48.5% validity, 0.272 CodeBLEU). Tasks requiring deeper spatial reasoning, such as spatial relationship detection or optimal site selection, remain the most challenging across all models. These findings demonstrate both the promise and limitations of current LLMs in GIS automation and provide a reproducible framework to advance GeoAI research with human-in-the-loop support.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "34 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.05881v1",
    "published_date": "2025-09-07 00:51:57 UTC",
    "updated_date": "2025-09-07 00:51:57 UTC"
  },
  {
    "arxiv_id": "2509.05877v2",
    "title": "Uncertainty Quantification in Probabilistic Machine Learning Models: Theory, Methods, and Insights",
    "authors": [
      "Marzieh Ajirak",
      "Anand Ravishankar",
      "Petar M. Djuric"
    ],
    "abstract": "Uncertainty Quantification (UQ) is essential in probabilistic machine learning models, particularly for assessing the reliability of predictions. In this paper, we present a systematic framework for estimating both epistemic and aleatoric uncertainty in probabilistic models. We focus on Gaussian Process Latent Variable Models and employ scalable Random Fourier Features-based Gaussian Processes to approximate predictive distributions efficiently. We derive a theoretical formulation for UQ, propose a Monte Carlo sampling-based estimation method, and conduct experiments to evaluate the impact of uncertainty estimation. Our results provide insights into the sources of predictive uncertainty and illustrate the effectiveness of our approach in quantifying the confidence in the predictions.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "Accepted to EUSIPCO 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.05877v2",
    "published_date": "2025-09-07 00:38:33 UTC",
    "updated_date": "2025-09-10 17:02:44 UTC"
  },
  {
    "arxiv_id": "2509.10543v1",
    "title": "Robust DDoS-Attack Classification with 3D CNNs Against Adversarial Methods",
    "authors": [
      "Landon Bragg",
      "Nathan Dorsey",
      "Josh Prior",
      "John Ajit",
      "Ben Kim",
      "Nate Willis",
      "Pablo Rivas"
    ],
    "abstract": "Distributed Denial-of-Service (DDoS) attacks remain a serious threat to online infrastructure, often bypassing detection by altering traffic in subtle ways. We present a method using hive-plot sequences of network data and a 3D convolutional neural network (3D CNN) to classify DDoS traffic with high accuracy. Our system relies on three main ideas: (1) using spatio-temporal hive-plot encodings to set a pattern-recognition baseline, (2) applying adversarial training with FGSM and PGD alongside spatial noise and image shifts, and (3) analyzing frame-wise predictions to find early signals. On a benchmark dataset, our method lifts adversarial accuracy from 50-55% to over 93% while maintaining clean-sample performance. Frames 3-4 offer strong predictive signals, showing early-stage classification is possible.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "The 27th International Conference on Artificial Intelligence (ICAI'25)",
    "pdf_url": "https://arxiv.org/pdf/2509.10543v1",
    "published_date": "2025-09-07 00:20:32 UTC",
    "updated_date": "2025-09-07 00:20:32 UTC"
  },
  {
    "arxiv_id": "2509.05874v1",
    "title": "Learning to Construct Knowledge through Sparse Reference Selection with Reinforcement Learning",
    "authors": [
      "Shao-An Yin"
    ],
    "abstract": "The rapid expansion of scientific literature makes it increasingly difficult to acquire new knowledge, particularly in specialized domains where reasoning is complex, full-text access is restricted, and target references are sparse among a large set of candidates. We present a Deep Reinforcement Learning framework for sparse reference selection that emulates human knowledge construction, prioritizing which papers to read under limited time and cost. Evaluated on drug--gene relation discovery with access restricted to titles and abstracts, our approach demonstrates that both humans and machines can construct knowledge effectively from partial information.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.05874v1",
    "published_date": "2025-09-07 00:19:13 UTC",
    "updated_date": "2025-09-07 00:19:13 UTC"
  },
  {
    "arxiv_id": "2509.07016v1",
    "title": "Random Forest Stratified K-Fold Cross Validation on SYN DoS Attack SD-IoV",
    "authors": [
      "Muhammad Arif Hakimi Zamrai",
      "Kamaludin Mohd Yusof"
    ],
    "abstract": "In response to the prevalent concern of TCP SYN flood attacks within the context of Software-Defined Internet of Vehicles (SD-IoV), this study addresses the significant challenge of network security in rapidly evolving vehicular communication systems. This research focuses on optimizing a Random Forest Classifier model to achieve maximum accuracy and minimal detection time, thereby enhancing vehicular network security. The methodology involves preprocessing a dataset containing SYN attack instances, employing feature scaling and label encoding techniques, and applying Stratified K-Fold cross-validation to target key metrics such as accuracy, precision, recall, and F1-score. This research achieved an average value of 0.999998 for all metrics with a SYN DoS attack detection time of 0.24 seconds. Results show that the fine-tuned Random Forest model, configured with 20 estimators and a depth of 10, effectively differentiates between normal and malicious traffic with high accuracy and minimal detection time, which is crucial for SD-IoV networks. This approach marks a significant advancement and introduces a state-of-the-art algorithm in detecting SYN flood attacks, combining high accuracy with minimal detection time. It contributes to vehicular network security by providing a robust solution against TCP SYN flood attacks while maintaining network efficiency and reliability.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.07016v1",
    "published_date": "2025-09-07 00:18:30 UTC",
    "updated_date": "2025-09-07 00:18:30 UTC"
  }
]