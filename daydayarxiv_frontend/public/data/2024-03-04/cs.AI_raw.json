[
  {
    "arxiv_id": "2403.02545v4",
    "title": "Wukong: Towards a Scaling Law for Large-Scale Recommendation",
    "authors": [
      "Buyun Zhang",
      "Liang Luo",
      "Yuxin Chen",
      "Jade Nie",
      "Xi Liu",
      "Daifeng Guo",
      "Yanli Zhao",
      "Shen Li",
      "Yuchen Hao",
      "Yantao Yao",
      "Guna Lakshminarayanan",
      "Ellie Dingqiao Wen",
      "Jongsoo Park",
      "Maxim Naumov",
      "Wenlin Chen"
    ],
    "abstract": "Scaling laws play an instrumental role in the sustainable improvement in\nmodel quality. Unfortunately, recommendation models to date do not exhibit such\nlaws similar to those observed in the domain of large language models, due to\nthe inefficiencies of their upscaling mechanisms. This limitation poses\nsignificant challenges in adapting these models to increasingly more complex\nreal-world datasets. In this paper, we propose an effective network\narchitecture based purely on stacked factorization machines, and a synergistic\nupscaling strategy, collectively dubbed Wukong, to establish a scaling law in\nthe domain of recommendation. Wukong's unique design makes it possible to\ncapture diverse, any-order of interactions simply through taller and wider\nlayers. We conducted extensive evaluations on six public datasets, and our\nresults demonstrate that Wukong consistently outperforms state-of-the-art\nmodels quality-wise. Further, we assessed Wukong's scalability on an internal,\nlarge-scale dataset. The results show that Wukong retains its superiority in\nquality over state-of-the-art models, while holding the scaling law across two\norders of magnitude in model complexity, extending beyond 100 GFLOP/example,\nwhere prior arts fall short.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.02545v4",
    "published_date": "2024-03-04 23:40:20 UTC",
    "updated_date": "2024-06-04 04:29:24 UTC"
  },
  {
    "arxiv_id": "2403.02528v2",
    "title": "DACO: Towards Application-Driven and Comprehensive Data Analysis via Code Generation",
    "authors": [
      "Xueqing Wu",
      "Rui Zheng",
      "Jingzhen Sha",
      "Te-Lin Wu",
      "Hanyu Zhou",
      "Mohan Tang",
      "Kai-Wei Chang",
      "Nanyun Peng",
      "Haoran Huang"
    ],
    "abstract": "Data analysis is a crucial analytical process to generate in-depth studies\nand conclusive insights to comprehensively answer a given user query for\ntabular data. In this work, we aim to propose new resources and benchmarks to\ninspire future research on this crucial yet challenging and under-explored\ntask. However, collecting data analysis annotations curated by experts can be\nprohibitively expensive. We propose to automatically generate high-quality\nanswer annotations leveraging the code-generation capabilities of LLMs with a\nmulti-turn prompting technique. We construct the DACO dataset, containing (1)\n440 databases (of tabular data) collected from real-world scenarios, (2) ~2k\nquery-answer pairs that can serve as weak supervision for model training, and\n(3) a concentrated but high-quality test set with human refined annotations\nthat serves as our main evaluation benchmark. We train a 6B supervised\nfine-tuning (SFT) model on DACO dataset, and find that the SFT model learns\nreasonable data analysis capabilities. To further align the models with human\npreference, we use reinforcement learning to encourage generating analysis\nperceived by human as helpful, and design a set of dense rewards to propagate\nthe sparse human preference reward to intermediate code generation steps. Our\nDACO-RL algorithm is evaluated by human annotators to produce more helpful\nanswers than SFT model in 57.72% cases, validating the effectiveness of our\nproposed algorithm. Data and code are released at\nhttps://github.com/shirley-wu/daco",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 Dataset and Benchmark Track",
    "pdf_url": "http://arxiv.org/pdf/2403.02528v2",
    "published_date": "2024-03-04 22:47:58 UTC",
    "updated_date": "2024-10-28 22:07:43 UTC"
  },
  {
    "arxiv_id": "2403.02523v1",
    "title": "Transformer for Times Series: an Application to the S&P500",
    "authors": [
      "Pierre Brugiere",
      "Gabriel Turinici"
    ],
    "abstract": "The transformer models have been extensively used with good results in a wide\narea of machine learning applications including Large Language Models and image\ngeneration. Here, we inquire on the applicability of this approach to financial\ntime series. We first describe the dataset construction for two prototypical\nsituations: a mean reverting synthetic Ornstein-Uhlenbeck process on one hand\nand real S&P500 data on the other hand. Then, we present in detail the proposed\nTransformer architecture and finally we discuss some encouraging results. For\nthe synthetic data we predict rather accurately the next move, and for the\nS&P500 we get some interesting results related to quadratic variation and\nvolatility prediction.",
    "categories": [
      "cs.AI",
      "q-fin.PM",
      "q-fin.ST",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02523v1",
    "published_date": "2024-03-04 22:27:11 UTC",
    "updated_date": "2024-03-04 22:27:11 UTC"
  },
  {
    "arxiv_id": "2403.02522v1",
    "title": "HeAR -- Health Acoustic Representations",
    "authors": [
      "Sebastien Baur",
      "Zaid Nabulsi",
      "Wei-Hung Weng",
      "Jake Garrison",
      "Louis Blankemeier",
      "Sam Fishman",
      "Christina Chen",
      "Sujay Kakarmath",
      "Minyoi Maimbolwa",
      "Nsala Sanjase",
      "Brian Shuma",
      "Yossi Matias",
      "Greg S. Corrado",
      "Shwetak Patel",
      "Shravya Shetty",
      "Shruthi Prabhakara",
      "Monde Muyoyeta",
      "Diego Ardila"
    ],
    "abstract": "Health acoustic sounds such as coughs and breaths are known to contain useful\nhealth signals with significant potential for monitoring health and disease,\nyet are underexplored in the medical machine learning community. The existing\ndeep learning systems for health acoustics are often narrowly trained and\nevaluated on a single task, which is limited by data and may hinder\ngeneralization to other tasks. To mitigate these gaps, we develop HeAR, a\nscalable self-supervised learning-based deep learning system using masked\nautoencoders trained on a large dataset of 313 million two-second long audio\nclips. Through linear probes, we establish HeAR as a state-of-the-art health\naudio embedding model on a benchmark of 33 health acoustic tasks across 6\ndatasets. By introducing this work, we hope to enable and accelerate further\nhealth acoustics research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 tables, 4 figures, 6 supplementary tables, 3 supplementary figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02522v1",
    "published_date": "2024-03-04 22:26:25 UTC",
    "updated_date": "2024-03-04 22:26:25 UTC"
  },
  {
    "arxiv_id": "2403.02514v2",
    "title": "A Formalisation of the Purpose Framework: the Autonomy-Alignment Problem in Open-Ended Learning Robots",
    "authors": [
      "Gianluca Baldassarre",
      "Richard J. Duro",
      "Emilio Cartoni",
      "Mehdi Khamassi",
      "Alejandro Romero",
      "Vieri Giuliano Santucci"
    ],
    "abstract": "The unprecedented advancement of artificial intelligence enables the\ndevelopment of increasingly autonomous robots. These robots hold significant\npotential, particularly in moving beyond engineered factory settings to operate\nin the unstructured environments inhabited by humans. However, this possibility\nalso generates a relevant autonomy-alignment problem to ensure that robots'\nautonomous learning processes still focus on acquiring knowledge relevant to\naccomplish human practical purposes, while their behaviour still aligns with\ntheir broader purposes. The literature has only begun to address this problem,\nand a conceptual, terminological, and formal framework is still lacking. Here\nwe address one of the most challenging instances of the problem: autonomous\nopen-ended learning (OEL) robots, capable of cumulatively acquiring new skills\nand knowledge through direct interaction with the environment, guided by\nself-generated goals and intrinsic motivations. In particular, we propose a\ncomputational framework, first introduced qualitatively and then formalised, to\nsupport the design of OEL robot architectures that balance autonomy and\ncontrol. The framework pivots on the novel concept of purpose. A human purpose\nspecifies what humans (e.g., designers or users) want the robot to learn, do or\nnot do, within a certain boundary of autonomy and independently of the domains\nin which it operates.The framework decomposes the autonomy-alignment problem\ninto more tractable sub-problems: the alignment of `robot purposes' with human\npurposes, either by hardwiring or through learning; the arbitration between\nmultiple purposes; the grounding of purposes into specific domain-dependent\nrobot goals; and the competence acquisition needed to accomplish these goals.\nThe framework and its potential utility are further elucidated through the\ndiscussion of hypothetical example scenarios framed within it.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02514v2",
    "published_date": "2024-03-04 22:03:49 UTC",
    "updated_date": "2025-04-07 17:46:43 UTC"
  },
  {
    "arxiv_id": "2403.02509v1",
    "title": "SPUQ: Perturbation-Based Uncertainty Quantification for Large Language Models",
    "authors": [
      "Xiang Gao",
      "Jiaxin Zhang",
      "Lalla Mouatadid",
      "Kamalika Das"
    ],
    "abstract": "In recent years, large language models (LLMs) have become increasingly\nprevalent, offering remarkable text generation capabilities. However, a\npressing challenge is their tendency to make confidently wrong predictions,\nhighlighting the critical need for uncertainty quantification (UQ) in LLMs.\nWhile previous works have mainly focused on addressing aleatoric uncertainty,\nthe full spectrum of uncertainties, including epistemic, remains inadequately\nexplored. Motivated by this gap, we introduce a novel UQ method, sampling with\nperturbation for UQ (SPUQ), designed to tackle both aleatoric and epistemic\nuncertainties. The method entails generating a set of perturbations for LLM\ninputs, sampling outputs for each perturbation, and incorporating an\naggregation module that generalizes the sampling uncertainty approach for text\ngeneration tasks. Through extensive experiments on various datasets, we\ninvestigated different perturbation and aggregation techniques. Our findings\nshow a substantial improvement in model uncertainty calibration, with a\nreduction in Expected Calibration Error (ECE) by 50\\% on average. Our findings\nsuggest that our proposed UQ method offers promising steps toward enhancing the\nreliability and trustworthiness of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to appear at EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02509v1",
    "published_date": "2024-03-04 21:55:22 UTC",
    "updated_date": "2024-03-04 21:55:22 UTC"
  },
  {
    "arxiv_id": "2403.02504v3",
    "title": "A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing",
    "authors": [
      "Yu Wang",
      "Wen Qu"
    ],
    "abstract": "Given that natural language serves as the primary conduit for expressing\nthoughts and emotions, text analysis has become a key technique in\npsychological research. It enables the extraction of valuable insights from\nnatural language, facilitating endeavors like personality traits assessment,\nmental health monitoring, and sentiment analysis in interpersonal\ncommunications. In text analysis, existing studies often resort to either human\ncoding, which is time-consuming, using pre-built dictionaries, which often\nfails to cover all possible scenarios, or training models from scratch, which\nrequires large amounts of labeled data. In this tutorial, we introduce the\npretrain-finetune paradigm. The pretrain-finetune paradigm represents a\ntransformative approach in text analysis and natural language processing. This\nparadigm distinguishes itself through the use of large pretrained language\nmodels, demonstrating remarkable efficiency in finetuning tasks, even with\nlimited training data. This efficiency is especially beneficial for research in\nsocial sciences, where the number of annotated samples is often quite limited.\nOur tutorial offers a comprehensive introduction to the pretrain-finetune\nparadigm. We first delve into the fundamental concepts of pretraining and\nfinetuning, followed by practical exercises using real-world applications. We\ndemonstrate the application of the paradigm across various tasks, including\nmulti-class classification and regression. Emphasizing its efficacy and\nuser-friendliness, the tutorial aims to encourage broader adoption of this\nparadigm. To this end, we have provided open access to all our code and\ndatasets. The tutorial is highly beneficial across various psychology\ndisciplines, providing a comprehensive guide to employing text analysis in\ndiverse research settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 6 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.02504v3",
    "published_date": "2024-03-04 21:51:11 UTC",
    "updated_date": "2024-08-02 04:44:29 UTC"
  },
  {
    "arxiv_id": "2403.02502v2",
    "title": "Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents",
    "authors": [
      "Yifan Song",
      "Da Yin",
      "Xiang Yue",
      "Jie Huang",
      "Sujian Li",
      "Bill Yuchen Lin"
    ],
    "abstract": "Large Language Models (LLMs) have become integral components in various\nautonomous agent systems. In this study, we present an exploration-based\ntrajectory optimization approach, referred to as ETO. This learning method is\ndesigned to enhance the performance of open LLM agents. Contrary to previous\nstudies that exclusively train on successful expert trajectories, our method\nallows agents to learn from their exploration failures. This leads to improved\nperformance through an iterative optimization framework. During the exploration\nphase, the agent interacts with the environment while completing given tasks,\ngathering failure trajectories to create contrastive trajectory pairs. In the\nsubsequent training phase, the agent utilizes these trajectory preference pairs\nto update its policy using contrastive learning methods like DPO. This\niterative cycle of exploration and training fosters continued improvement in\nthe agents. Our experiments on three complex tasks demonstrate that ETO\nconsistently surpasses baseline performance by a large margin. Furthermore, an\nexamination of task-solving efficiency and potential in scenarios lacking\nexpert trajectory underscores the effectiveness of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 Main Conference; Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2403.02502v2",
    "published_date": "2024-03-04 21:50:29 UTC",
    "updated_date": "2024-07-10 17:36:25 UTC"
  },
  {
    "arxiv_id": "2403.02495v1",
    "title": "Pseudo-Labeling and Contextual Curriculum Learning for Online Grasp Learning in Robotic Bin Picking",
    "authors": [
      "Huy Le",
      "Philipp Schillinger",
      "Miroslav Gabriel",
      "Alexander Qualmann",
      "Ngo Anh Vien"
    ],
    "abstract": "The prevailing grasp prediction methods predominantly rely on offline\nlearning, overlooking the dynamic grasp learning that occurs during real-time\nadaptation to novel picking scenarios. These scenarios may involve previously\nunseen objects, variations in camera perspectives, and bin configurations,\namong other factors. In this paper, we introduce a novel approach, SSL-ConvSAC,\nthat combines semi-supervised learning and reinforcement learning for online\ngrasp learning. By treating pixels with reward feedback as labeled data and\nothers as unlabeled, it efficiently exploits unlabeled data to enhance\nlearning. In addition, we address the imbalance between labeled and unlabeled\ndata by proposing a contextual curriculum-based method. We ablate the proposed\napproach on real-world evaluation data and demonstrate promise for improving\nonline grasp learning on bin picking tasks using a physical 7-DoF Franka Emika\nrobot arm with a suction gripper. Video: https://youtu.be/OAro5pg8I9U",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02495v1",
    "published_date": "2024-03-04 21:41:27 UTC",
    "updated_date": "2024-03-04 21:41:27 UTC"
  },
  {
    "arxiv_id": "2403.02484v1",
    "title": "Encodings for Prediction-based Neural Architecture Search",
    "authors": [
      "Yash Akhauri",
      "Mohamed S. Abdelfattah"
    ],
    "abstract": "Predictor-based methods have substantially enhanced Neural Architecture\nSearch (NAS) optimization. The efficacy of these predictors is largely\ninfluenced by the method of encoding neural network architectures. While\ntraditional encodings used an adjacency matrix describing the graph structure\nof a neural network, novel encodings embrace a variety of approaches from\nunsupervised pretraining of latent representations to vectors of zero-cost\nproxies. In this paper, we categorize and investigate neural encodings from\nthree main types: structural, learned, and score-based. Furthermore, we extend\nthese encodings and introduce \\textit{unified encodings}, that extend NAS\npredictors to multiple search spaces. Our analysis draws from experiments\nconducted on over 1.5 million neural network architectures on NAS spaces such\nas NASBench-101 (NB101), NB201, NB301, Network Design Spaces (NDS), and\nTransNASBench-101. Building on our study, we present our predictor\n\\textbf{FLAN}: \\textbf{Fl}ow \\textbf{A}ttention for \\textbf{N}AS. FLAN\nintegrates critical insights on predictor design, transfer learning, and\n\\textit{unified encodings} to enable more than an order of magnitude cost\nreduction for training NAS accuracy predictors. Our implementation and\nencodings for all neural networks are open-sourced at\n\\href{https://github.com/abdelfattah-lab/flan_nas}{https://github.com/abdelfattah-lab/flan\\_nas}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02484v1",
    "published_date": "2024-03-04 21:05:52 UTC",
    "updated_date": "2024-03-04 21:05:52 UTC"
  },
  {
    "arxiv_id": "2403.02482v1",
    "title": "MORBDD: Multiobjective Restricted Binary Decision Diagrams by Learning to Sparsify",
    "authors": [
      "Rahul Patel",
      "Elias B. Khalil",
      "David Bergman"
    ],
    "abstract": "In multicriteria decision-making, a user seeks a set of non-dominated\nsolutions to a (constrained) multiobjective optimization problem, the so-called\nPareto frontier. In this work, we seek to bring a state-of-the-art method for\nexact multiobjective integer linear programming into the heuristic realm. We\nfocus on binary decision diagrams (BDDs) which first construct a graph that\nrepresents all feasible solutions to the problem and then traverse the graph to\nextract the Pareto frontier. Because the Pareto frontier may be exponentially\nlarge, enumerating it over the BDD can be time-consuming. We explore how\nrestricted BDDs, which have already been shown to be effective as heuristics\nfor single-objective problems, can be adapted to multiobjective optimization\nthrough the use of machine learning (ML). MORBDD, our ML-based BDD sparsifier,\nfirst trains a binary classifier to eliminate BDD nodes that are unlikely to\ncontribute to Pareto solutions, then post-processes the sparse BDD to ensure\nits connectivity via optimization. Experimental results on multiobjective\nknapsack problems show that MORBDD is highly effective at producing very small\nrestricted BDDs with excellent approximation quality, outperforming\nwidth-limited restricted BDDs and the well-known evolutionary algorithm\nNSGA-II.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02482v1",
    "published_date": "2024-03-04 21:04:54 UTC",
    "updated_date": "2024-03-04 21:04:54 UTC"
  },
  {
    "arxiv_id": "2403.02454v1",
    "title": "The Ink Splotch Effect: A Case Study on ChatGPT as a Co-Creative Game Designer",
    "authors": [
      "Asad Anjum",
      "Yuting Li",
      "Noelle Law",
      "M Charity",
      "Julian Togelius"
    ],
    "abstract": "This paper studies how large language models (LLMs) can act as effective,\nhigh-level creative collaborators and ``muses'' for game design. We model the\ndesign of this study after the exercises artists use by looking at amorphous\nink splotches for creative inspiration. Our goal is to determine whether\nAI-assistance can improve, hinder, or provide an alternative quality to games\nwhen compared to the creative intents implemented by human designers. The\ncapabilities of LLMs as game designers are stress tested by placing it at the\nforefront of the decision making process. Three prototype games are designed\nacross 3 different genres: (1) a minimalist base game, (2) a game with features\nand game feel elements added by a human game designer, and (3) a game with\nfeatures and feel elements directly implemented from prompted outputs of the\nLLM, ChatGPT. A user study was conducted and participants were asked to blindly\nevaluate the quality and their preference of these games. We discuss both the\ndevelopment process of communicating creative intent to an AI chatbot and the\nsynthesized open feedback of the participants. We use this data to determine\nboth the benefits and shortcomings of AI in a more design-centric role.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.02454v1",
    "published_date": "2024-03-04 20:14:38 UTC",
    "updated_date": "2024-03-04 20:14:38 UTC"
  },
  {
    "arxiv_id": "2403.02444v1",
    "title": "Anatomically Constrained Tractography of the Fetal Brain",
    "authors": [
      "Camilo Calixto",
      "Camilo Jaimes",
      "Matheus D. Soldatelli",
      "Simon K. Warfield",
      "Ali Gholipour",
      "Davood Karimi"
    ],
    "abstract": "Diffusion-weighted Magnetic Resonance Imaging (dMRI) is increasingly used to\nstudy the fetal brain in utero. An important computation enabled by dMRI is\nstreamline tractography, which has unique applications such as tract-specific\nanalysis of the brain white matter and structural connectivity assessment.\nHowever, due to the low fetal dMRI data quality and the challenging nature of\ntractography, existing methods tend to produce highly inaccurate results. They\ngenerate many false streamlines while failing to reconstruct streamlines that\nconstitute the major white matter tracts. In this paper, we advocate for\nanatomically constrained tractography based on an accurate segmentation of the\nfetal brain tissue directly in the dMRI space. We develop a deep learning\nmethod to compute the segmentation automatically. Experiments on independent\ntest data show that this method can accurately segment the fetal brain tissue\nand drastically improve tractography results. It enables the reconstruction of\nhighly curved tracts such as optic radiations. Importantly, our method infers\nthe tissue segmentation and streamline propagation direction from a diffusion\ntensor fit to the dMRI data, making it applicable to routine fetal dMRI scans.\nThe proposed method can lead to significant improvements in the accuracy and\nreproducibility of quantitative assessment of the fetal brain with dMRI.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02444v1",
    "published_date": "2024-03-04 19:56:19 UTC",
    "updated_date": "2024-03-04 19:56:19 UTC"
  },
  {
    "arxiv_id": "2403.02439v1",
    "title": "Root Causing Prediction Anomalies Using Explainable AI",
    "authors": [
      "Ramanathan Vishnampet",
      "Rajesh Shenoy",
      "Jianhui Chen",
      "Anuj Gupta"
    ],
    "abstract": "This paper presents a novel application of explainable AI (XAI) for\nroot-causing performance degradation in machine learning models that learn\ncontinuously from user engagement data. In such systems a single feature\ncorruption can cause cascading feature, label and concept drifts. We have\nsuccessfully applied this technique to improve the reliability of models used\nin personalized advertising. Performance degradation in such systems manifest\nas prediction anomalies in the models. These models are typically trained\ncontinuously using features that are produced by hundreds of real time data\nprocessing pipelines or derived from other upstream models. A failure in any of\nthese pipelines or an instability in any of the upstream models can cause\nfeature corruption, causing the model's predicted output to deviate from the\nactual output and the training data to become corrupted. The causal\nrelationship between the features and the predicted output is complex, and\nroot-causing is challenging due to the scale and dynamism of the system. We\ndemonstrate how temporal shifts in the global feature importance distribution\ncan effectively isolate the cause of a prediction anomaly, with better recall\nthan model-to-feature correlation methods. The technique appears to be\neffective even when approximating the local feature importance using a simple\nperturbation-based method, and aggregating over a few thousand examples. We\nhave found this technique to be a model-agnostic, cheap and effective way to\nmonitor complex data pipelines in production and have deployed a system for\ncontinuously analyzing the global feature importance distribution of\ncontinuously trained models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to The 2nd World Conference on eXplainable Artificial\n  Intelligence, 17-19 July, 2024, Malta, Valletta",
    "pdf_url": "http://arxiv.org/pdf/2403.02439v1",
    "published_date": "2024-03-04 19:38:50 UTC",
    "updated_date": "2024-03-04 19:38:50 UTC"
  },
  {
    "arxiv_id": "2403.02437v3",
    "title": "A Survey on Federated Unlearning: Challenges and Opportunities",
    "authors": [
      "Hyejun Jeong",
      "Shiqing Ma",
      "Amir Houmansadr"
    ],
    "abstract": "Federated learning (FL), introduced in 2017, facilitates collaborative\nlearning between non-trusting parties with no need for the parties to\nexplicitly share their data among themselves. This allows training models on\nuser data while respecting privacy regulations such as GDPR and CPRA. However,\nemerging privacy requirements may mandate model owners to be able to\n\\emph{forget} some learned data, e.g., when requested by data owners or law\nenforcement. This has given birth to an active field of research called\n\\emph{machine unlearning}. In the context of FL, many techniques developed for\nunlearning in centralized settings are not trivially applicable! This is due to\nthe unique differences between centralized and distributed learning, in\nparticular, interactivity, stochasticity, heterogeneity, and limited\naccessibility in FL. In response, a recent line of work has focused on\ndeveloping unlearning mechanisms tailored to FL.\n  This SoK paper aims to take a deep look at the \\emph{federated unlearning}\nliterature, with the goal of identifying research trends and challenges in this\nemerging field. By carefully categorizing papers published on FL unlearning\n(since 2020), we aim to pinpoint the unique complexities of federated\nunlearning, highlighting limitations on directly applying centralized\nunlearning methods. We compare existing federated unlearning methods regarding\ninfluence removal and performance recovery, compare their threat models and\nassumptions, and discuss their implications and limitations. For instance, we\nanalyze the experimental setup of FL unlearning studies from various\nperspectives, including data heterogeneity and its simulation, the datasets\nused for demonstration, and evaluation metrics. Our work aims to offer insights\nand suggestions for future research on federated unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02437v3",
    "published_date": "2024-03-04 19:35:08 UTC",
    "updated_date": "2025-04-07 19:55:57 UTC"
  },
  {
    "arxiv_id": "2403.02429v1",
    "title": "Towards efficient deep autoencoders for multivariate time series anomaly detection",
    "authors": [
      "Marcin Pietroń",
      "Dominik Żurek",
      "Kamil Faber",
      "Roberto Corizzo"
    ],
    "abstract": "Multivariate time series anomaly detection is a crucial problem in many\nindustrial and research applications. Timely detection of anomalies allows, for\ninstance, to prevent defects in manufacturing processes and failures in\ncyberphysical systems. Deep learning methods are preferred among others for\ntheir accuracy and robustness for the analysis of complex multivariate data.\nHowever, a key aspect is being able to extract predictions in a timely manner,\nto accommodate real-time requirements in different applications. In the case of\ndeep learning models, model reduction is extremely important to achieve optimal\nresults in real-time systems with limited time and memory constraints. In this\npaper, we address this issue by proposing a novel compression method for deep\nautoencoders that involves three key factors. First, pruning reduces the number\nof weights, while preventing catastrophic drops in accuracy by means of a fast\nsearch process that identifies high sparsity levels. Second, linear and\nnon-linear quantization reduces model complexity by reducing the number of bits\nfor every single weight. The combined contribution of these three aspects allow\nthe model size to be reduced, by removing a subset of the weights (pruning),\nand decreasing their bit-width (quantization). As a result, the compressed\nmodel is faster and easier to adopt in highly constrained hardware\nenvironments. Experiments performed on popular multivariate anomaly detection\nbenchmarks, show that our method is capable of achieving significant model\ncompression ratio (between 80% and 95%) without a significant reduction in the\nanomaly detection performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02429v1",
    "published_date": "2024-03-04 19:22:09 UTC",
    "updated_date": "2024-03-04 19:22:09 UTC"
  },
  {
    "arxiv_id": "2403.02419v2",
    "title": "Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems",
    "authors": [
      "Lingjiao Chen",
      "Jared Quincy Davis",
      "Boris Hanin",
      "Peter Bailis",
      "Ion Stoica",
      "Matei Zaharia",
      "James Zou"
    ],
    "abstract": "Many recent state-of-the-art results in language tasks were achieved using\ncompound systems that perform multiple Language Model (LM) calls and aggregate\ntheir responses. However, there is little understanding of how the number of LM\ncalls - e.g., when asking the LM to answer each question multiple times and\ntaking a majority vote - affects such a compound system's performance. In this\npaper, we initiate the study of scaling properties of compound inference\nsystems. We analyze, theoretically and empirically, how the number of LM calls\naffects the performance of Vote and Filter-Vote, two of the simplest compound\nsystem designs, which aggregate LM responses via majority voting, optionally\napplying LM filters. We find, surprisingly, that across multiple language\ntasks, the performance of both Vote and Filter-Vote can first increase but then\ndecrease as a function of the number of LM calls. Our theoretical results\nsuggest that this non-monotonicity is due to the diversity of query\ndifficulties within a task: more LM calls lead to higher performance on \"easy\"\nqueries, but lower performance on \"hard\" queries, and non-monotone behavior can\nemerge when a task contains both types of queries. This insight then allows us\nto compute, from a small number of samples, the number of LM calls that\nmaximizes system performance, and define an analytical scaling model for both\nsystems. Experiments show that our scaling model can accurately predict the\nperformance of Vote and Filter-Vote systems and thus find the optimal number of\nLM calls to make.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02419v2",
    "published_date": "2024-03-04 19:12:48 UTC",
    "updated_date": "2024-06-04 21:20:33 UTC"
  },
  {
    "arxiv_id": "2403.02338v2",
    "title": "Twisting Lids Off with Two Hands",
    "authors": [
      "Toru Lin",
      "Zhao-Heng Yin",
      "Haozhi Qi",
      "Pieter Abbeel",
      "Jitendra Malik"
    ],
    "abstract": "Manipulating objects with two multi-fingered hands has been a long-standing\nchallenge in robotics, due to the contact-rich nature of many manipulation\ntasks and the complexity inherent in coordinating a high-dimensional bimanual\nsystem. In this work, we share novel insights into physical modeling, real-time\nperception, and reward design that enable policies trained in simulation using\ndeep reinforcement learning (RL) to be effectively and efficiently transferred\nto the real world. Specifically, we consider the problem of twisting lids of\nvarious bottle-like objects with two hands, demonstrating policies with\ngeneralization capabilities across a diverse set of unseen objects as well as\ndynamic and dexterous behaviors. To the best of our knowledge, this is the\nfirst sim-to-real RL system that enables such capabilities on bimanual\nmulti-fingered hands.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project page can be found at https://toruowo.github.io/bimanual-twist",
    "pdf_url": "http://arxiv.org/pdf/2403.02338v2",
    "published_date": "2024-03-04 18:59:30 UTC",
    "updated_date": "2024-10-14 06:02:45 UTC"
  },
  {
    "arxiv_id": "2403.02336v1",
    "title": "Brand Visibility in Packaging: A Deep Learning Approach for Logo Detection, Saliency-Map Prediction, and Logo Placement Analysis",
    "authors": [
      "Alireza Hosseini",
      "Kiana Hooshanfar",
      "Pouria Omrani",
      "Reza Toosi",
      "Ramin Toosi",
      "Zahra Ebrahimian",
      "Mohammad Ali Akhaee"
    ],
    "abstract": "In the highly competitive area of product marketing, the visibility of brand\nlogos on packaging plays a crucial role in shaping consumer perception,\ndirectly influencing the success of the product. This paper introduces a\ncomprehensive framework to measure the brand logo's attention on a packaging\ndesign. The proposed method consists of three steps. The first step leverages\nYOLOv8 for precise logo detection across prominent datasets, FoodLogoDet-1500\nand LogoDet-3K. The second step involves modeling the user's visual attention\nwith a novel saliency prediction model tailored for the packaging context. The\nproposed saliency model combines the visual elements with text maps employing a\ntransformers-based architecture to predict user attention maps. In the third\nstep, by integrating logo detection with a saliency map generation, the\nframework provides a comprehensive brand attention score. The effectiveness of\nthe proposed method is assessed module by module, ensuring a thorough\nevaluation of each component. Comparing logo detection and saliency map\nprediction with state-of-the-art models shows the superiority of the proposed\nmethods. To investigate the robustness of the proposed brand attention score,\nwe collected a unique dataset to examine previous psychophysical hypotheses\nrelated to brand visibility. the results show that the brand attention score is\nin line with all previous studies. Also, we introduced seven new hypotheses to\ncheck the impact of position, orientation, presence of person, and other visual\nelements on brand attention. This research marks a significant stride in the\nintersection of cognitive psychology, computer vision, and marketing, paving\nthe way for advanced, consumer-centric packaging designs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02336v1",
    "published_date": "2024-03-04 18:58:53 UTC",
    "updated_date": "2024-03-04 18:58:53 UTC"
  },
  {
    "arxiv_id": "2403.02334v1",
    "title": "Gradient Correlation Subspace Learning against Catastrophic Forgetting",
    "authors": [
      "Tammuz Dubnov",
      "Vishal Thengane"
    ],
    "abstract": "Efficient continual learning techniques have been a topic of significant\nresearch over the last few years. A fundamental problem with such learning is\nsevere degradation of performance on previously learned tasks, known also as\ncatastrophic forgetting. This paper introduces a novel method to reduce\ncatastrophic forgetting in the context of incremental class learning called\nGradient Correlation Subspace Learning (GCSL). The method detects a subspace of\nthe weights that is least affected by previous tasks and projects the weights\nto train for the new task into said subspace. The method can be applied to one\nor more layers of a given network architectures and the size of the subspace\nused can be altered from layer to layer and task to task. Code will be\navailable at\n\\href{https://github.com/vgthengane/GCSL}{https://github.com/vgthengane/GCSL}",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "5 figures; Code will be available here:\n  https://github.com/vgthengane/GCSL",
    "pdf_url": "http://arxiv.org/pdf/2403.02334v1",
    "published_date": "2024-03-04 18:58:46 UTC",
    "updated_date": "2024-03-04 18:58:46 UTC"
  },
  {
    "arxiv_id": "2403.02333v3",
    "title": "Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning",
    "authors": [
      "Yiming Huang",
      "Xiao Liu",
      "Yeyun Gong",
      "Zhibin Gou",
      "Yelong Shen",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "abstract": "Large language models (LLMs) have shown great potential in complex reasoning\ntasks, yet their performance is often hampered by the scarcity of high-quality\nand reasoning-focused training datasets. Addressing this challenge, we propose\nKey-Point-Driven Data Synthesis (KPDDS), a novel data synthesis framework that\nsynthesizes question-answer pairs by leveraging key points and exemplar\npractices from authentic data sources. KPDDS ensures the generation of novel\nquestions with rigorous quality control and substantial scalability. As a\nresult, we present KPMath, an extensive synthetic dataset tailored for\nmathematical reasoning, comprising over 800K question-answer pairs. Utilizing\nKPMath and augmenting it with additional reasoning-intensive corpora, we create\nthe comprehensive KPMath-Plus dataset. The Qwen1.5-72B model, fine-tuned on\nKPMath-Plus, achieves 87.0% PASS@1 accuracy on GSM8K and 58.3% on MATH,\nsurpassing competitors in the 7B to 70B range and best commercial models like\nGPT-4 across multiple math reasoning datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "In progress",
    "pdf_url": "http://arxiv.org/pdf/2403.02333v3",
    "published_date": "2024-03-04 18:58:30 UTC",
    "updated_date": "2024-05-08 01:48:46 UTC"
  },
  {
    "arxiv_id": "2403.02327v2",
    "title": "Model Lakes",
    "authors": [
      "Koyena Pal",
      "David Bau",
      "Renée J. Miller"
    ],
    "abstract": "Given a set of deep learning models, it can be hard to find models\nappropriate to a task, understand the models, and characterize how models are\ndifferent one from another. Currently, practitioners rely on manually-written\ndocumentation to understand and choose models. However, not all models have\ncomplete and reliable documentation. As the number of models increases, the\nchallenges of finding, differentiating, and understanding models become\nincreasingly crucial. Inspired from research on data lakes, we introduce the\nconcept of model lakes. We formalize key model lake tasks, including model\nattribution, versioning, search, and benchmarking, and discuss fundamental\nresearch challenges in the management of large models. We also explore what\ndata management techniques can be brought to bear on the study of large model\nmanagement.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted to EDBT 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.02327v2",
    "published_date": "2024-03-04 18:55:50 UTC",
    "updated_date": "2025-02-21 16:46:33 UTC"
  },
  {
    "arxiv_id": "2403.02325v1",
    "title": "Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training",
    "authors": [
      "David Wan",
      "Jaemin Cho",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ],
    "abstract": "Highlighting particularly relevant regions of an image can improve the\nperformance of vision-language models (VLMs) on various vision-language (VL)\ntasks by guiding the model to attend more closely to these regions of interest.\nFor example, VLMs can be given a \"visual prompt\", where visual markers such as\nbounding boxes delineate key image regions. However, current VLMs that can\nincorporate visual guidance are either proprietary and expensive or require\ncostly training on curated data that includes visual prompts. We introduce\nContrastive Region Guidance (CRG), a training-free guidance method that enables\nopen-source VLMs to respond to visual prompts. CRG contrasts model outputs\nproduced with and without visual prompts, factoring out biases revealed by the\nmodel when answering without the information required to produce a correct\nanswer (i.e., the model's prior). CRG achieves substantial improvements in a\nwide variety of VL tasks: When region annotations are provided, CRG increases\nabsolute accuracy by up to 11.1% on ViP-Bench, a collection of six diverse\nregion-based tasks such as recognition, math, and object relationship\nreasoning. We also show CRG's applicability to spatial reasoning, with 10%\nimprovement on What'sUp, as well as to compositional generalization --\nimproving accuracy by 11.5% and 7.5% on two challenging splits from SugarCrepe\n-- and to image-text alignment for generated images, where we improve by up to\n8.4 AUROC and 6.8 F1 points on SeeTRUE. When reference regions are absent, CRG\nallows us to re-rank proposed regions in referring expression comprehension and\nphrase grounding benchmarks like RefCOCO/+/g and Flickr30K Entities, with an\naverage gain of 3.2% in accuracy. Our analysis explores alternative masking\nstrategies for CRG, quantifies CRG's probability shift, and evaluates the role\nof region guidance strength, empirically validating CRG's design choices.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website: https://contrastive-region-guidance.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2403.02325v1",
    "published_date": "2024-03-04 18:55:30 UTC",
    "updated_date": "2024-03-04 18:55:30 UTC"
  },
  {
    "arxiv_id": "2403.02302v4",
    "title": "Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation",
    "authors": [
      "Maksim Kuprashevich",
      "Grigorii Alekseenko",
      "Irina Tolstykh"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have recently gained immense\npopularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as\nopen-source ones such as LLaVA, are essentially general-purpose models and are\napplied to solve a wide variety of tasks, including those in computer vision.\nThese neural networks possess such strong general knowledge and reasoning\nabilities that they have proven capable of working even on tasks for which they\nwere not specifically trained. We compared the capabilities of the most\npowerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task\nof age and gender estimation with our state-of-the-art specialized model,\nMiVOLO. We also updated MiVOLO and provide details and new metrics in this\narticle. This comparison has yielded some interesting results and insights\nabout the strengths and weaknesses of the participating models. Furthermore, we\nattempted various ways to fine-tune the ShareGPT4V model for this specific\ntask, aiming to achieve state-of-the-art results in this particular challenge.\nAlthough such a model would not be practical in production, as it is incredibly\nexpensive compared to a specialized model like MiVOLO, it could be very useful\nin some tasks, like data annotation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.0; I.4.0; I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02302v4",
    "published_date": "2024-03-04 18:32:12 UTC",
    "updated_date": "2025-01-21 14:50:25 UTC"
  },
  {
    "arxiv_id": "2403.02372v1",
    "title": "OTClean: Data Cleaning for Conditional Independence Violations using Optimal Transport",
    "authors": [
      "Alireza Pirhadi",
      "Mohammad Hossein Moslemi",
      "Alexander Cloninger",
      "Mostafa Milani",
      "Babak Salimi"
    ],
    "abstract": "Ensuring Conditional Independence (CI) constraints is pivotal for the\ndevelopment of fair and trustworthy machine learning models. In this paper, we\nintroduce \\sys, a framework that harnesses optimal transport theory for data\nrepair under CI constraints. Optimal transport theory provides a rigorous\nframework for measuring the discrepancy between probability distributions,\nthereby ensuring control over data utility. We formulate the data repair\nproblem concerning CIs as a Quadratically Constrained Linear Program (QCLP) and\npropose an alternating method for its solution. However, this approach faces\nscalability issues due to the computational cost associated with computing\noptimal transport distances, such as the Wasserstein distance. To overcome\nthese scalability challenges, we reframe our problem as a regularized\noptimization problem, enabling us to develop an iterative algorithm inspired by\nSinkhorn's matrix scaling algorithm, which efficiently addresses\nhigh-dimensional and large-scale data. Through extensive experiments, we\ndemonstrate the efficacy and efficiency of our proposed methods, showcasing\ntheir practical utility in real-world data cleaning and preprocessing tasks.\nFurthermore, we provide comparisons with traditional approaches, highlighting\nthe superiority of our techniques in terms of preserving data utility while\nensuring adherence to the desired CI constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02372v1",
    "published_date": "2024-03-04 18:23:55 UTC",
    "updated_date": "2024-03-04 18:23:55 UTC"
  },
  {
    "arxiv_id": "2403.02290v1",
    "title": "Koopman-Assisted Reinforcement Learning",
    "authors": [
      "Preston Rozwood",
      "Edward Mehrez",
      "Ludger Paehler",
      "Wen Sun",
      "Steven L. Brunton"
    ],
    "abstract": "The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman\n(HJB) equation, are ubiquitous in reinforcement learning (RL) and control\ntheory. However, these equations quickly become intractable for systems with\nhigh-dimensional states and nonlinearity. This paper explores the connection\nbetween the data-driven Koopman operator and Markov Decision Processes (MDPs),\nresulting in the development of two new RL algorithms to address these\nlimitations. We leverage Koopman operator techniques to lift a nonlinear system\ninto new coordinates where the dynamics become approximately linear, and where\nHJB-based methods are more tractable. In particular, the Koopman operator is\nable to capture the expectation of the time evolution of the value function of\na given system via linear dynamics in the lifted coordinates. By parameterizing\nthe Koopman operator with the control actions, we construct a ``Koopman\ntensor'' that facilitates the estimation of the optimal value function. Then, a\ntransformation of Bellman's framework in terms of the Koopman tensor enables us\nto reformulate two max-entropy RL algorithms: soft value iteration and soft\nactor-critic (SAC). This highly flexible framework can be used for\ndeterministic or stochastic systems as well as for discrete or continuous-time\ndynamics. Finally, we show that these Koopman Assisted Reinforcement Learning\n(KARL) algorithms attain state-of-the-art (SOTA) performance with respect to\ntraditional neural network-based SAC and linear quadratic regulator (LQR)\nbaselines on four controlled dynamical systems: a linear state-space system,\nthe Lorenz system, fluid flow past a cylinder, and a double-well potential with\nnon-isotropic stochastic forcing.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.DS",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02290v1",
    "published_date": "2024-03-04 18:19:48 UTC",
    "updated_date": "2024-03-04 18:19:48 UTC"
  },
  {
    "arxiv_id": "2403.02268v1",
    "title": "Subjective $\\textit{Isms}$? On the Danger of Conflating Hate and Offence in Abusive Language Detection",
    "authors": [
      "Amanda Cercas Curry",
      "Gavin Abercrombie",
      "Zeerak Talat"
    ],
    "abstract": "Natural language processing research has begun to embrace the notion of\nannotator subjectivity, motivated by variations in labelling. This approach\nunderstands each annotator's view as valid, which can be highly suitable for\ntasks that embed subjectivity, e.g., sentiment analysis. However, this\nconstruction may be inappropriate for tasks such as hate speech detection, as\nit affords equal validity to all positions on e.g., sexism or racism. We argue\nthat the conflation of hate and offence can invalidate findings on hate speech,\nand call for future work to be situated in theory, disentangling hate from its\northogonal concept, offence.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02268v1",
    "published_date": "2024-03-04 17:56:28 UTC",
    "updated_date": "2024-03-04 17:56:28 UTC"
  },
  {
    "arxiv_id": "2403.05589v4",
    "title": "Ergonomic Design of Computer Laboratory Furniture: Mismatch Analysis Utilizing Anthropometric Data of University Students",
    "authors": [
      "Anik Kumar Saha",
      "Md Abrar Jahin",
      "Md. Rafiquzzaman",
      "M. F. Mridha"
    ],
    "abstract": "Many studies have shown how ergonomically designed furniture improves\nproductivity and well-being. As computers have become a part of students'\nacademic lives, they will grow further in the future. We propose\nanthropometric-based furniture dimensions suitable for university students to\nimprove computer laboratory ergonomics. We collected data from 380 participants\nand analyzed 11 anthropometric measurements, correlating them to 11 furniture\ndimensions. Two types of furniture were studied: a non-adjustable chair with a\nnon-adjustable table and an adjustable chair with a non-adjustable table. The\nmismatch calculation showed a significant difference between furniture\ndimensions and anthropometric measurements. The one-way ANOVA test with a\nsignificance level of 5% also showed a significant difference between proposed\nand existing furniture dimensions. The proposed dimensions were found to be\nmore compatible and reduced mismatch percentages for both males and females\ncompared to existing furniture. The proposed dimensions of the furniture set\nwith adjustable seat height showed slightly improved results compared to the\nnon-adjustable furniture set. This suggests that the proposed dimensions can\nimprove comfort levels and reduce the risk of musculoskeletal disorders among\nstudents. Further studies on the implementation and long-term effects of these\nproposed dimensions in real-world computer laboratory settings are recommended.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05589v4",
    "published_date": "2024-03-04 17:44:18 UTC",
    "updated_date": "2024-11-18 23:21:50 UTC"
  },
  {
    "arxiv_id": "2403.02253v2",
    "title": "KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection",
    "authors": [
      "Yuexin Li",
      "Chengyu Huang",
      "Shumin Deng",
      "Mei Lin Lock",
      "Tri Cao",
      "Nay Oo",
      "Hoon Wei Lim",
      "Bryan Hooi"
    ],
    "abstract": "Phishing attacks have inflicted substantial losses on individuals and\nbusinesses alike, necessitating the development of robust and efficient\nautomated phishing detection approaches. Reference-based phishing detectors\n(RBPDs), which compare the logos on a target webpage to a known set of logos,\nhave emerged as the state-of-the-art approach. However, a major limitation of\nexisting RBPDs is that they rely on a manually constructed brand knowledge\nbase, making it infeasible to scale to a large number of brands, which results\nin false negative errors due to the insufficient brand coverage of the\nknowledge base. To address this issue, we propose an automated knowledge\ncollection pipeline, using which we collect a large-scale multimodal brand\nknowledge base, KnowPhish, containing 20k brands with rich information about\neach brand. KnowPhish can be used to boost the performance of existing RBPDs in\na plug-and-play manner. A second limitation of existing RBPDs is that they\nsolely rely on the image modality, ignoring useful textual information present\nin the webpage HTML. To utilize this textual information, we propose a Large\nLanguage Model (LLM)-based approach to extract brand information of webpages\nfrom text. Our resulting multimodal phishing detection approach, KnowPhish\nDetector (KPD), can detect phishing webpages with or without logos. We evaluate\nKnowPhish and KPD on a manually validated dataset, and a field study under\nSingapore's local context, showing substantial improvements in effectiveness\nand efficiency compared to state-of-the-art baselines.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by USENIX Security 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02253v2",
    "published_date": "2024-03-04 17:38:32 UTC",
    "updated_date": "2024-06-15 11:34:45 UTC"
  },
  {
    "arxiv_id": "2403.02249v2",
    "title": "Non-autoregressive Sequence-to-Sequence Vision-Language Models",
    "authors": [
      "Kunyu Shi",
      "Qi Dong",
      "Luis Goncalves",
      "Zhuowen Tu",
      "Stefano Soatto"
    ],
    "abstract": "Sequence-to-sequence vision-language models are showing promise, but their\napplicability is limited by their inference latency due to their autoregressive\nway of generating predictions. We propose a parallel decoding\nsequence-to-sequence vision-language model, trained with a Query-CTC loss, that\nmarginalizes over multiple inference paths in the decoder. This allows us to\nmodel the joint distribution of tokens, rather than restricting to conditional\ndistribution as in an autoregressive model. The resulting model, NARVL,\nachieves performance on-par with its state-of-the-art autoregressive\ncounterpart, but is faster at inference time, reducing from the linear\ncomplexity associated with the sequential generation of tokens to a paradigm of\nconstant time joint inference.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02249v2",
    "published_date": "2024-03-04 17:34:59 UTC",
    "updated_date": "2025-03-13 00:22:34 UTC"
  },
  {
    "arxiv_id": "2403.02243v1",
    "title": "Better Schedules for Low Precision Training of Deep Neural Networks",
    "authors": [
      "Cameron R. Wolfe",
      "Anastasios Kyrillidis"
    ],
    "abstract": "Low precision training can significantly reduce the computational overhead of\ntraining deep neural networks (DNNs). Though many such techniques exist, cyclic\nprecision training (CPT), which dynamically adjusts precision throughout\ntraining according to a cyclic schedule, achieves particularly impressive\nimprovements in training efficiency, while actually improving DNN performance.\nExisting CPT implementations take common learning rate schedules (e.g.,\ncyclical cosine schedules) and use them for low precision training without\nadequate comparisons to alternative scheduling options. We define a diverse\nsuite of CPT schedules and analyze their performance across a variety of DNN\ntraining regimes, some of which are unexplored in the low precision training\nliterature (e.g., node classification with graph neural networks). From these\nexperiments, we discover alternative CPT schedules that offer further\nimprovements in training efficiency and model performance, as well as derive a\nset of best practices for choosing CPT schedules. Going further, we find that a\ncorrelation exists between model performance and training cost, and that\nchanging the underlying CPT schedule can control the tradeoff between these two\nvariables. To explain the direct correlation between model performance and\ntraining cost, we draw a connection between quantized training and critical\nlearning periods, suggesting that aggressive quantization is a form of learning\nimpairment that can permanently damage model performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.10; I.4.0"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 8 figures, 1 table, ACML 2023",
    "pdf_url": "http://arxiv.org/pdf/2403.02243v1",
    "published_date": "2024-03-04 17:33:39 UTC",
    "updated_date": "2024-03-04 17:33:39 UTC"
  },
  {
    "arxiv_id": "2403.02241v3",
    "title": "Neural Redshift: Random Networks are not Random Functions",
    "authors": [
      "Damien Teney",
      "Armand Nicolicioiu",
      "Valentin Hartmann",
      "Ehsan Abbasnejad"
    ],
    "abstract": "Our understanding of the generalization capabilities of neural networks (NNs)\nis still incomplete. Prevailing explanations are based on implicit biases of\ngradient descent (GD) but they cannot account for the capabilities of models\nfrom gradient-free methods nor the simplicity bias recently observed in\nuntrained networks. This paper seeks other sources of generalization in NNs.\n  Findings. To understand the inductive biases provided by architectures\nindependently from GD, we examine untrained, random-weight networks. Even\nsimple MLPs show strong inductive biases: uniform sampling in weight space\nyields a very biased distribution of functions in terms of complexity. But\nunlike common wisdom, NNs do not have an inherent \"simplicity bias\". This\nproperty depends on components such as ReLUs, residual connections, and layer\nnormalizations. Alternative architectures can be built with a bias for any\nlevel of complexity. Transformers also inherit all these properties from their\nbuilding blocks.\n  Implications. We provide a fresh explanation for the success of deep learning\nindependent from gradient-based training. It points at promising avenues for\ncontrolling the solutions implemented by trained models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02241v3",
    "published_date": "2024-03-04 17:33:20 UTC",
    "updated_date": "2025-04-29 19:25:29 UTC"
  },
  {
    "arxiv_id": "2403.02238v2",
    "title": "Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks",
    "authors": [
      "Dimitrios Michael Manias",
      "Ali Chouman",
      "Abdallah Shami"
    ],
    "abstract": "The integration of Machine Learning and Artificial Intelligence (ML/AI) into\nfifth-generation (5G) networks has made evident the limitations of network\nintelligence with ever-increasing, strenuous requirements for current and\nnext-generation devices. This transition to ubiquitous intelligence demands\nhigh connectivity, synchronicity, and end-to-end communication between users\nand network operators, and will pave the way towards full network automation\nwithout human intervention. Intent-based networking is a key factor in the\nreduction of human actions, roles, and responsibilities while shifting towards\nnovel extraction and interpretation of automated network management. This paper\npresents the development of a custom Large Language Model (LLM) for 5G and\nnext-generation intent-based networking and provides insights into future LLM\ndevelopments and integrations to realize end-to-end intent-based networking for\nfully automated network intelligence.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Presented at DRCN 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02238v2",
    "published_date": "2024-03-04 17:29:57 UTC",
    "updated_date": "2024-05-22 13:34:33 UTC"
  },
  {
    "arxiv_id": "2403.02232v2",
    "title": "Comprehensive evaluation of Mal-API-2019 dataset by machine learning in malware detection",
    "authors": [
      "Zhenglin Li",
      "Haibei Zhu",
      "Houze Liu",
      "Jintong Song",
      "Qishuo Cheng"
    ],
    "abstract": "This study conducts a thorough examination of malware detection using machine\nlearning techniques, focusing on the evaluation of various classification\nmodels using the Mal-API-2019 dataset. The aim is to advance cybersecurity\ncapabilities by identifying and mitigating threats more effectively. Both\nensemble and non-ensemble machine learning methods, such as Random Forest,\nXGBoost, K Nearest Neighbor (KNN), and Neural Networks, are explored. Special\nemphasis is placed on the importance of data pre-processing techniques,\nparticularly TF-IDF representation and Principal Component Analysis, in\nimproving model performance. Results indicate that ensemble methods,\nparticularly Random Forest and XGBoost, exhibit superior accuracy, precision,\nand recall compared to others, highlighting their effectiveness in malware\ndetection. The paper also discusses limitations and potential future\ndirections, emphasizing the need for continuous adaptation to address the\nevolving nature of malware. This research contributes to ongoing discussions in\ncybersecurity and provides practical insights for developing more robust\nmalware detection systems in the digital era.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02232v2",
    "published_date": "2024-03-04 17:22:43 UTC",
    "updated_date": "2024-03-25 21:33:18 UTC"
  },
  {
    "arxiv_id": "2403.02227v2",
    "title": "Policy Space Response Oracles: A Survey",
    "authors": [
      "Ariyan Bighashdel",
      "Yongzhao Wang",
      "Stephen McAleer",
      "Rahul Savani",
      "Frans A. Oliehoek"
    ],
    "abstract": "Game theory provides a mathematical way to study the interaction between\nmultiple decision makers. However, classical game-theoretic analysis is limited\nin scalability due to the large number of strategies, precluding direct\napplication to more complex scenarios. This survey provides a comprehensive\noverview of a framework for large games, known as Policy Space Response Oracles\n(PSRO), which holds promise to improve scalability by focusing attention on\nsufficient subsets of strategies. We first motivate PSRO and provide historical\ncontext. We then focus on the strategy exploration problem for PSRO: the\nchallenge of assembling effective subsets of strategies that still represent\nthe original game well with minimum computational cost. We survey current\nresearch directions for enhancing the efficiency of PSRO, and explore the\napplications of PSRO across various domains. We conclude by discussing open\nquestions and future research.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "Ariyan Bighashdel and Yongzhao Wang contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2403.02227v2",
    "published_date": "2024-03-04 17:15:09 UTC",
    "updated_date": "2024-05-27 16:49:18 UTC"
  },
  {
    "arxiv_id": "2403.02181v3",
    "title": "Not All Layers of LLMs Are Necessary During Inference",
    "authors": [
      "Siqi Fan",
      "Xin Jiang",
      "Xiang Li",
      "Xuying Meng",
      "Peng Han",
      "Shuo Shang",
      "Aixin Sun",
      "Yequan Wang",
      "Zhongyuan Wang"
    ],
    "abstract": "Due to the large number of parameters, the inference phase of Large Language\nModels (LLMs) is resource-intensive. However, not all requests posed to LLMs\nare equally difficult to handle. Through analysis, we show that for some tasks,\nLLMs can achieve results comparable to the final output at some intermediate\nlayers. That is, not all layers of LLMs are necessary during inference. If we\ncan predict at which layer the inferred results match the final results\n(produced by evaluating all layers), we could significantly reduce the\ninference cost. To this end, we propose a simple yet effective algorithm named\nAdaInfer to adaptively terminate the inference process for an input instance.\nAdaInfer relies on easily obtainable statistical features and classic\nclassifiers like SVM. Experiments on well-known LLMs like the Llama2 series and\nOPT, show that AdaInfer can achieve an average of 17.8% pruning ratio, and up\nto 43% on sentiment tasks, with nearly no performance drop (<1%). Because\nAdaInfer does not alter LLM parameters, the LLMs incorporated with AdaInfer\nmaintain generalizability across tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02181v3",
    "published_date": "2024-03-04 16:23:58 UTC",
    "updated_date": "2024-07-09 11:59:01 UTC"
  },
  {
    "arxiv_id": "2403.02178v2",
    "title": "Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models",
    "authors": [
      "Changyu Chen",
      "Xiting Wang",
      "Ting-En Lin",
      "Ang Lv",
      "Yuchuan Wu",
      "Xin Gao",
      "Ji-Rong Wen",
      "Rui Yan",
      "Yongbin Li"
    ],
    "abstract": "In reasoning tasks, even a minor error can cascade into inaccurate results,\nleading to suboptimal performance of large language models in such domains.\nEarlier fine-tuning approaches sought to mitigate this by leveraging more\nprecise supervisory signals from human labeling, larger models, or\nself-sampling, although at a high cost. Conversely, we develop a method that\navoids external resources, relying instead on introducing perturbations to the\ninput. Our training approach randomly masks certain tokens within the chain of\nthought, a technique we found to be particularly effective for reasoning tasks.\nWhen applied to fine-tuning with GSM8K on Llama-2-7B, this method achieved a\n5\\% improvement in GSM8K accuracy and a 10\\% improvement in GSM-IC accuracy\nover standard supervised fine-tuning with a few codes modified. Furthermore, it\nis complementary to existing methods. When integrated with related explicit\ndata augmentation methods, it leads to improvements across five datasets of\nvarious augmentation methods, as well as two different base models. We further\ninvestigate the mechanisms behind this improvement through case studies and\nquantitative analysis, suggesting that our approach may provide superior\nsupport for the model in capturing long-distance dependencies, especially those\nrelated to questions. This enhancement could deepen understanding of the\npremises in questions and prior steps. Our code is available at Github.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02178v2",
    "published_date": "2024-03-04 16:21:54 UTC",
    "updated_date": "2024-07-10 19:15:24 UTC"
  },
  {
    "arxiv_id": "2403.04795v1",
    "title": "Large Language Models in Fire Engineering: An Examination of Technical Questions Against Domain Knowledge",
    "authors": [
      "Haley Hostetter",
      "M. Z. Naser",
      "Xinyan Huang",
      "John Gales"
    ],
    "abstract": "This communication presents preliminary findings from comparing two recent\nchatbots, OpenAI's ChatGPT and Google's Bard, in the context of fire\nengineering by evaluating their responses in handling fire safety related\nqueries. A diverse range of fire engineering questions and scenarios were\ncreated and examined, including structural fire design, fire prevention\nstrategies, evacuation, building code compliance, and fire suppression systems\n(some of which resemble those commonly present in the Fire Protection exam\n(FPE)). The results reveal some key differences in the performance of the\nchatbots, with ChatGPT demonstrating a relatively superior performance. Then,\nthis communication highlights the potential for chatbot technology to\nrevolutionize fire engineering practices by providing instant access to\ncritical information while outlining areas for further improvement and\nresearch. Evidently, and when it matures, this technology will likely be\nelemental to our engineers' practice and education.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04795v1",
    "published_date": "2024-03-04 16:18:36 UTC",
    "updated_date": "2024-03-04 16:18:36 UTC"
  },
  {
    "arxiv_id": "2403.02371v3",
    "title": "NeuroVoz: a Castillian Spanish corpus of parkinsonian speech",
    "authors": [
      "Janaína Mendes-Laureano",
      "Jorge A. Gómez-García",
      "Alejandro Guerrero-López",
      "Elisa Luque-Buzo",
      "Julián D. Arias-Londoño",
      "Francisco J. Grandas-Pérez",
      "Juan I. Godino-Llorente"
    ],
    "abstract": "The screening of Parkinson's Disease (PD) through speech is hindered by a\nnotable lack of publicly available datasets in different languages. This fact\nlimits the reproducibility and further exploration of existing research.\n  To address this gap, this manuscript presents the NeuroVoz corpus consisting\nof 112 native Castilian-Spanish speakers, including 58 healthy controls and 54\nindividuals with PD, all recorded in ON state. The corpus showcases a diverse\narray of speech tasks: sustained vowels; diadochokinetic tests; 16\nListen-and-Repeat utterances; and spontaneous monologues.\n  The dataset is also complemented with subjective assessments of voice quality\nperformed by an expert according to the GRBAS scale\n(Grade/Roughness/Breathiness/Asthenia/Strain), as well as annotations with a\nthorough examination of phonation quality, intensity, speed, resonance,\nintelligibility, and prosody.\n  The corpus offers a substantial resource for the exploration of the impact of\nPD on speech. This data set has already supported several studies, achieving a\nbenchmark accuracy of 89% for the screening of PD. Despite these advances, the\nbroader challenge of conducting a language-agnostic, cross-corpora analysis of\nParkinsonian speech patterns remains open.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Paper accepted at Scientific Data",
    "pdf_url": "http://arxiv.org/pdf/2403.02371v3",
    "published_date": "2024-03-04 16:17:39 UTC",
    "updated_date": "2025-02-26 15:42:41 UTC"
  },
  {
    "arxiv_id": "2403.02167v3",
    "title": "EMOVOME: A Dataset for Emotion Recognition in Spontaneous Real-Life Speech",
    "authors": [
      "Lucía Gómez-Zaragozá",
      "Rocío del Amor",
      "María José Castro-Bleda",
      "Valery Naranjo",
      "Mariano Alcañiz Raya",
      "Javier Marín-Morales"
    ],
    "abstract": "Spontaneous datasets for Speech Emotion Recognition (SER) are scarce and\nfrequently derived from laboratory environments or staged scenarios, such as TV\nshows, limiting their application in real-world contexts. We developed and\npublicly released the Emotional Voice Messages (EMOVOME) dataset, including 999\nvoice messages from real conversations of 100 Spanish speakers on a messaging\napp, labeled in continuous and discrete emotions by expert and non-expert\nannotators. We evaluated speaker-independent SER models using acoustic features\nas baseline and transformer-based models. We compared the results with\nreference datasets including acted and elicited speech, and analyzed the\ninfluence of annotators and gender fairness. The pre-trained\nUniSpeech-SAT-Large model achieved the highest results, 61.64% and 55.57%\nUnweighted Accuracy (UA) for 3-class valence and arousal prediction\nrespectively on EMOVOME, a 10% improvement over baseline models. For the\nemotion categories, 42.58% UA was obtained. EMOVOME performed lower than the\nacted RAVDESS dataset. The elicited IEMOCAP dataset also outperformed EMOVOME\nin predicting emotion categories, while similar results were obtained in\nvalence and arousal. EMOVOME outcomes varied with annotator labels, showing\nbetter results and fairness when combining expert and non-expert annotations.\nThis study highlights the gap between controlled and real-life scenarios,\nsupporting further advancements in recognizing genuine emotions.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD",
      "I.5.1; I.5.4"
    ],
    "primary_category": "eess.AS",
    "comment": "This article is a merged version of the description of the EMOVOME\n  database in arXiv:2402.17496v1 and the speech emotion recognition models in\n  arXiv:2403.02167v1. This work has been submitted to the IEEE for possible\n  publication",
    "pdf_url": "http://arxiv.org/pdf/2403.02167v3",
    "published_date": "2024-03-04 16:13:39 UTC",
    "updated_date": "2024-12-04 02:08:13 UTC"
  },
  {
    "arxiv_id": "2403.02164v2",
    "title": "Cognition is All You Need -- The Next Layer of AI Above Large Language Models",
    "authors": [
      "Nova Spivack",
      "Sam Douglas",
      "Michelle Crames",
      "Tim Connors"
    ],
    "abstract": "Recent studies of the applications of conversational AI tools, such as\nchatbots powered by large language models, to complex real-world knowledge work\nhave shown limitations related to reasoning and multi-step problem solving.\nSpecifically, while existing chatbots simulate shallow reasoning and\nunderstanding they are prone to errors as problem complexity increases. The\nfailure of these systems to address complex knowledge work is due to the fact\nthat they do not perform any actual cognition. In this position paper, we\npresent Cognitive AI, a higher-level framework for implementing\nprogrammatically defined neuro-symbolic cognition above and outside of large\nlanguage models. Specifically, we propose a dual-layer functional architecture\nfor Cognitive AI that serves as a roadmap for AI systems that can perform\ncomplex multi-step knowledge work. We propose that Cognitive AI is a necessary\nprecursor for the evolution of higher forms of AI, such as AGI, and\nspecifically claim that AGI cannot be achieved by probabilistic approaches on\ntheir own. We conclude with a discussion of the implications for large language\nmodels, adoption cycles in AI, and commercial Cognitive AI development.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "63 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02164v2",
    "published_date": "2024-03-04 16:11:57 UTC",
    "updated_date": "2024-03-05 10:23:52 UTC"
  },
  {
    "arxiv_id": "2403.02131v3",
    "title": "Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution",
    "authors": [
      "Hongshu Guo",
      "Yining Ma",
      "Zeyuan Ma",
      "Jiacheng Chen",
      "Xinglin Zhang",
      "Zhiguang Cao",
      "Jun Zhang",
      "Yue-Jiao Gong"
    ],
    "abstract": "Evolutionary algorithms, such as Differential Evolution, excel in solving\nreal-parameter optimization challenges. However, the effectiveness of a single\nalgorithm varies across different problem instances, necessitating considerable\nefforts in algorithm selection or configuration. This paper aims to address the\nlimitation by leveraging the complementary strengths of a group of algorithms\nand dynamically scheduling them throughout the optimization progress for\nspecific problems. We propose a deep reinforcement learning-based dynamic\nalgorithm selection framework to accomplish this task. Our approach models the\ndynamic algorithm selection a Markov Decision Process, training an agent in a\npolicy gradient manner to select the most suitable algorithm according to the\nfeatures observed during the optimization process. To empower the agent with\nthe necessary information, our framework incorporates a thoughtful design of\nlandscape and algorithmic features. Meanwhile, we employ a sophisticated deep\nneural network model to infer the optimal action, ensuring informed algorithm\nselections. Additionally, an algorithm context restoration mechanism is\nembedded to facilitate smooth switching among different algorithms. These\nmechanisms together enable our framework to seamlessly select and switch\nalgorithms in a dynamic online fashion. Notably, the proposed framework is\nsimple and generic, offering potential improvements across a broad spectrum of\nevolutionary algorithms. As a proof-of-principle study, we apply this framework\nto a group of Differential Evolution algorithms. The experimental results\nshowcase the remarkable effectiveness of the proposed framework, not only\nenhancing the overall optimization performance but also demonstrating favorable\ngeneralization ability across different problem classes.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted by IEEE Transactions on Systems, Man, and Cybernetics:\n  Systems at Thu, Feb 29, 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02131v3",
    "published_date": "2024-03-04 15:40:28 UTC",
    "updated_date": "2024-03-07 09:42:47 UTC"
  },
  {
    "arxiv_id": "2403.02127v1",
    "title": "LOCR: Location-Guided Transformer for Optical Character Recognition",
    "authors": [
      "Yu Sun",
      "Dongzhan Zhou",
      "Chen Lin",
      "Conghui He",
      "Wanli Ouyang",
      "Han-Sen Zhong"
    ],
    "abstract": "Academic documents are packed with texts, equations, tables, and figures,\nrequiring comprehensive understanding for accurate Optical Character\nRecognition (OCR). While end-to-end OCR methods offer improved accuracy over\nlayout-based approaches, they often grapple with significant repetition issues,\nespecially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this\nissue, we propose LOCR, a model that integrates location guiding into the\ntransformer architecture during autoregression. We train the model on a dataset\ncomprising over 77M text-location pairs from 125K academic document pages,\nincluding bounding boxes for words, tables and mathematical symbols. LOCR\nadeptly handles various formatting elements and generates content in Markdown\nlanguage. It outperforms all existing methods in our test set constructed from\narXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also\nreduces repetition frequency from 4.4% of pages to 0.5% in the arXiv dataset,\nfrom 13.2% to 1.3% in OOD quantum physics documents and from 8.1% to 1.8% in\nOOD marketing documents. Additionally, LOCR features an interactive OCR mode,\nfacilitating the generation of complex documents through a few location prompts\nfrom human.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02127v1",
    "published_date": "2024-03-04 15:34:12 UTC",
    "updated_date": "2024-03-04 15:34:12 UTC"
  },
  {
    "arxiv_id": "2403.03230v4",
    "title": "Large language models surpass human experts in predicting neuroscience results",
    "authors": [
      "Xiaoliang Luo",
      "Akilles Rechardt",
      "Guangzhi Sun",
      "Kevin K. Nejad",
      "Felipe Yáñez",
      "Bati Yilmaz",
      "Kangjoo Lee",
      "Alexandra O. Cohen",
      "Valentina Borghesani",
      "Anton Pashkov",
      "Daniele Marinazzo",
      "Jonathan Nicholas",
      "Alessandro Salatiello",
      "Ilia Sucholutsky",
      "Pasquale Minervini",
      "Sepehr Razavi",
      "Roberta Rocca",
      "Elkhan Yusifov",
      "Tereza Okalova",
      "Nianlong Gu",
      "Martin Ferianc",
      "Mikail Khona",
      "Kaustubh R. Patil",
      "Pui-Shee Lee",
      "Rui Mata",
      "Nicholas E. Myers",
      "Jennifer K Bizley",
      "Sebastian Musslick",
      "Isil Poyraz Bilgin",
      "Guiomar Niso",
      "Justin M. Ales",
      "Michael Gaebler",
      "N Apurva Ratan Murty",
      "Leyla Loued-Khenissi",
      "Anna Behler",
      "Chloe M. Hall",
      "Jessica Dafflon",
      "Sherry Dongqi Bao",
      "Bradley C. Love"
    ],
    "abstract": "Scientific discoveries often hinge on synthesizing decades of research, a\ntask that potentially outstrips human information processing capacities. Large\nlanguage models (LLMs) offer a solution. LLMs trained on the vast scientific\nliterature could potentially integrate noisy yet interrelated findings to\nforecast novel results better than human experts. To evaluate this possibility,\nwe created BrainBench, a forward-looking benchmark for predicting neuroscience\nresults. We find that LLMs surpass experts in predicting experimental outcomes.\nBrainGPT, an LLM we tuned on the neuroscience literature, performed better yet.\nLike human experts, when LLMs were confident in their predictions, they were\nmore likely to be correct, which presages a future where humans and LLMs team\ntogether to make discoveries. Our approach is not neuroscience-specific and is\ntransferable to other knowledge-intensive endeavors.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "The latest version of this paper has been published at Nature Human\n  Behaviour, please see https://www.nature.com/articles/s41562-024-02046-9",
    "pdf_url": "http://arxiv.org/pdf/2403.03230v4",
    "published_date": "2024-03-04 15:27:59 UTC",
    "updated_date": "2024-11-28 08:49:00 UTC"
  },
  {
    "arxiv_id": "2403.02121v1",
    "title": "Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models",
    "authors": [
      "Sargam Yadav",
      "Abhishek Kaushik",
      "Kevin McDaid"
    ],
    "abstract": "The advent of Large Language Models (LLMs) has advanced the benchmark in\nvarious Natural Language Processing (NLP) tasks. However, large amounts of\nlabelled training data are required to train LLMs. Furthermore, data annotation\nand training are computationally expensive and time-consuming. Zero and\nfew-shot learning have recently emerged as viable options for labelling data\nusing large pre-trained models. Hate speech detection in mix-code low-resource\nlanguages is an active problem area where the use of LLMs has proven\nbeneficial. In this study, we have compiled a dataset of 100 YouTube comments,\nand weakly labelled them for coarse and fine-grained misogyny classification in\nmix-code Hinglish. Weak annotation was applied due to the labor-intensive\nannotation process. Zero-shot learning, one-shot learning, and few-shot\nlearning and prompting approaches have then been applied to assign labels to\nthe comments and compare them to human-assigned labels. Out of all the\napproaches, zero-shot classification using the Bidirectional Auto-Regressive\nTransformers (BART) large model and few-shot prompting using Generative\nPre-trained Transformer- 3 (ChatGPT-3) achieve the best results",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is accepted in the 16th ISDSI-Global Conference 2023\n  https://isdsi2023.iimranchi.ac.in",
    "pdf_url": "http://arxiv.org/pdf/2403.02121v1",
    "published_date": "2024-03-04 15:27:49 UTC",
    "updated_date": "2024-03-04 15:27:49 UTC"
  },
  {
    "arxiv_id": "2403.02118v4",
    "title": "Position: Towards Implicit Prompt For Text-To-Image Models",
    "authors": [
      "Yue Yang",
      "Yuqi Lin",
      "Hong Liu",
      "Wenqi Shao",
      "Runjian Chen",
      "Hailong Shang",
      "Yu Wang",
      "Yu Qiao",
      "Kaipeng Zhang",
      "Ping Luo"
    ],
    "abstract": "Recent text-to-image (T2I) models have had great success, and many benchmarks\nhave been proposed to evaluate their performance and safety. However, they only\nconsider explicit prompts while neglecting implicit prompts (hint at a target\nwithout explicitly mentioning it). These prompts may get rid of safety\nconstraints and pose potential threats to the applications of these models.\nThis position paper highlights the current state of T2I models toward implicit\nprompts. We present a benchmark named ImplicitBench and conduct an\ninvestigation on the performance and impacts of implicit prompts with popular\nT2I models. Specifically, we design and collect more than 2,000 implicit\nprompts of three aspects: General Symbols, Celebrity Privacy, and\nNot-Safe-For-Work (NSFW) Issues, and evaluate six well-known T2I models'\ncapabilities under these implicit prompts. Experiment results show that (1) T2I\nmodels are able to accurately create various target symbols indicated by\nimplicit prompts; (2) Implicit prompts bring potential risks of privacy leakage\nfor T2I models. (3) Constraints of NSFW in most of the evaluated T2I models can\nbe bypassed with implicit prompts. We call for increased attention to the\npotential and risks of implicit prompts in the T2I community and further\ninvestigation into the capabilities and impacts of implicit prompts, advocating\nfor a balanced approach that harnesses their benefits while mitigating their\nrisks.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02118v4",
    "published_date": "2024-03-04 15:21:51 UTC",
    "updated_date": "2024-05-28 04:24:14 UTC"
  },
  {
    "arxiv_id": "2403.02107v6",
    "title": "Iterated $Q$-Network: Beyond One-Step Bellman Updates in Deep Reinforcement Learning",
    "authors": [
      "Théo Vincent",
      "Daniel Palenicek",
      "Boris Belousov",
      "Jan Peters",
      "Carlo D'Eramo"
    ],
    "abstract": "The vast majority of Reinforcement Learning methods is largely impacted by\nthe computation effort and data requirements needed to obtain effective\nestimates of action-value functions, which in turn determine the quality of the\noverall performance and the sample-efficiency of the learning procedure.\nTypically, action-value functions are estimated through an iterative scheme\nthat alternates the application of an empirical approximation of the Bellman\noperator and a subsequent projection step onto a considered function space. It\nhas been observed that this scheme can be potentially generalized to carry out\nmultiple iterations of the Bellman operator at once, benefiting the underlying\nlearning algorithm. However, till now, it has been challenging to effectively\nimplement this idea, especially in high-dimensional problems. In this paper, we\nintroduce iterated $Q$-Network (i-QN), a novel principled approach that enables\nmultiple consecutive Bellman updates by learning a tailored sequence of\naction-value functions where each serves as the target for the next. We show\nthat i-QN is theoretically grounded and that it can be seamlessly used in\nvalue-based and actor-critic methods. We empirically demonstrate the advantages\nof i-QN in Atari $2600$ games and MuJoCo continuous control problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at TMLR: https://openreview.net/forum?id=Lt2H8Bd8jF",
    "pdf_url": "http://arxiv.org/pdf/2403.02107v6",
    "published_date": "2024-03-04 15:07:33 UTC",
    "updated_date": "2025-04-03 13:58:46 UTC"
  },
  {
    "arxiv_id": "2406.18535v1",
    "title": "DRAK: Unlocking Molecular Insights with Domain-Specific Retrieval-Augmented Knowledge in LLMs",
    "authors": [
      "Jinzhe Liu",
      "Xiangsheng Huang",
      "Zhuo Chen",
      "Yin Fang"
    ],
    "abstract": "Large Language Models (LLMs) encounter challenges with the unique syntax of\nspecific domains, such as biomolecules. Existing fine-tuning or modality\nalignment techniques struggle to bridge the domain knowledge gap and understand\ncomplex molecular data, limiting LLMs' progress in specialized fields. To\novercome these limitations, we propose an expandable and adaptable\nnon-parametric knowledge injection framework named Domain-specific\nRetrieval-Augmented Knowledge (DRAK), aimed at enhancing reasoning capabilities\nin specific domains. Utilizing knowledge-aware prompts and gold label-induced\nreasoning, DRAK has developed profound expertise in the molecular domain and\nthe capability to handle a broad spectrum of analysis tasks. We evaluated two\ndistinct forms of DRAK variants, proving that DRAK exceeds previous benchmarks\non six molecular tasks within the Mol-Instructions dataset. Extensive\nexperiments have underscored DRAK's formidable performance and its potential to\nunlock molecular insights, offering a unified paradigm for LLMs to tackle\nknowledge-intensive tasks in specific domains. Our code will be available soon.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Ongoing work; 11 pages, 6 Figures, 2 Tables",
    "pdf_url": "http://arxiv.org/pdf/2406.18535v1",
    "published_date": "2024-03-04 15:04:05 UTC",
    "updated_date": "2024-03-04 15:04:05 UTC"
  },
  {
    "arxiv_id": "2403.02370v1",
    "title": "adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource Languages with Integrated LLM Playgrounds",
    "authors": [
      "Séamus Lankford",
      "Haithem Afli",
      "Andy Way"
    ],
    "abstract": "The advent of Multilingual Language Models (MLLMs) and Large Language Models\nhas spawned innovation in many areas of natural language processing. Despite\nthe exciting potential of this technology, its impact on developing\nhigh-quality Machine Translation (MT) outputs for low-resource languages\nremains relatively under-explored. Furthermore, an open-source application,\ndedicated to both fine-tuning MLLMs and managing the complete MT workflow for\nlow-resources languages, remains unavailable. We aim to address these\nimbalances through the development of adaptMLLM, which streamlines all\nprocesses involved in the fine-tuning of MLLMs for MT. This open-source\napplication is tailored for developers, translators, and users who are engaged\nin MT. An intuitive interface allows for easy customisation of hyperparameters,\nand the application offers a range of metrics for model evaluation and the\ncapability to deploy models as a translation service directly within the\napplication. As a multilingual tool, we used adaptMLLM to fine-tune models for\ntwo low-resource language pairs: English to Irish (EN$\\leftrightarrow$GA) and\nEnglish to Marathi (EN$\\leftrightarrow$MR). Compared with baselines from the\nLoResMT2021 Shared Task, the adaptMLLM system demonstrated significant\nimprovements. In the EN$\\rightarrow$GA direction, an improvement of 5.2 BLEU\npoints was observed and an increase of 40.5 BLEU points was recorded in the\nGA$\\rightarrow$EN direction. Significant improvements in the translation\nperformance of the EN$\\leftrightarrow$MR pair were also observed notably in the\nMR$\\rightarrow$EN direction with an increase of 21.3 BLEU points. Finally, a\nfine-grained human evaluation of the MLLM output on the EN$\\rightarrow$GA pair\nwas conducted using the Multidimensional Quality Metrics and Scalar Quality\nMetrics error taxonomies. The application and models are freely available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02370v1",
    "published_date": "2024-03-04 14:49:18 UTC",
    "updated_date": "2024-03-04 14:49:18 UTC"
  },
  {
    "arxiv_id": "2403.02076v1",
    "title": "VTG-GPT: Tuning-Free Zero-Shot Video Temporal Grounding with GPT",
    "authors": [
      "Yifang Xu",
      "Yunzhuo Sun",
      "Zien Xie",
      "Benxiang Zhai",
      "Sidan Du"
    ],
    "abstract": "Video temporal grounding (VTG) aims to locate specific temporal segments from\nan untrimmed video based on a linguistic query. Most existing VTG models are\ntrained on extensive annotated video-text pairs, a process that not only\nintroduces human biases from the queries but also incurs significant\ncomputational costs. To tackle these challenges, we propose VTG-GPT, a\nGPT-based method for zero-shot VTG without training or fine-tuning. To reduce\nprejudice in the original query, we employ Baichuan2 to generate debiased\nqueries. To lessen redundant information in videos, we apply MiniGPT-v2 to\ntransform visual content into more precise captions. Finally, we devise the\nproposal generator and post-processing to produce accurate segments from\ndebiased queries and image captions. Extensive experiments demonstrate that\nVTG-GPT significantly outperforms SOTA methods in zero-shot settings and\nsurpasses unsupervised approaches. More notably, it achieves competitive\nperformance comparable to supervised methods. The code is available on\nhttps://github.com/YoucanBaby/VTG-GPT",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02076v1",
    "published_date": "2024-03-04 14:22:02 UTC",
    "updated_date": "2024-03-04 14:22:02 UTC"
  },
  {
    "arxiv_id": "2403.02074v1",
    "title": "Modality-Aware and Shift Mixer for Multi-modal Brain Tumor Segmentation",
    "authors": [
      "Zhongzhen Huang",
      "Linda Wei",
      "Shaoting Zhang",
      "Xiaofan Zhang"
    ],
    "abstract": "Combining images from multi-modalities is beneficial to explore various\ninformation in computer vision, especially in the medical domain. As an\nessential part of clinical diagnosis, multi-modal brain tumor segmentation aims\nto delineate the malignant entity involving multiple modalities. Although\nexisting methods have shown remarkable performance in the task, the information\nexchange for cross-scale and high-level representations fusion in spatial and\nmodality are limited in these methods. In this paper, we present a novel\nModality Aware and Shift Mixer that integrates intra-modality and\ninter-modality dependencies of multi-modal images for effective and robust\nbrain tumor segmentation. Specifically, we introduce a Modality-Aware module\naccording to neuroimaging studies for modeling the specific modality pair\nrelationships at low levels, and a Modality-Shift module with specific mosaic\npatterns is developed to explore the complex relationships across modalities at\nhigh levels via the self-attention. Experimentally, we outperform previous\nstate-of-the-art approaches on the public Brain Tumor Segmentation (BraTS 2021\nsegmentation) dataset. Further qualitative experiments demonstrate the efficacy\nand robustness of MASM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02074v1",
    "published_date": "2024-03-04 14:21:51 UTC",
    "updated_date": "2024-03-04 14:21:51 UTC"
  },
  {
    "arxiv_id": "2403.04793v1",
    "title": "A Data-Driven Two-Phase Multi-Split Causal Ensemble Model for Time Series",
    "authors": [
      "Zhipeng Ma",
      "Marco Kemmerling",
      "Daniel Buschmann",
      "Chrismarie Enslin",
      "Daniel Lütticke",
      "Robert H. Schmitt"
    ],
    "abstract": "Causal inference is a fundamental research topic for discovering the\ncause-effect relationships in many disciplines. However, not all algorithms are\nequally well-suited for a given dataset. For instance, some approaches may only\nbe able to identify linear relationships, while others are applicable for\nnon-linearities. Algorithms further vary in their sensitivity to noise and\ntheir ability to infer causal information from coupled vs. non-coupled time\nseries. Therefore, different algorithms often generate different causal\nrelationships for the same input. To achieve a more robust causal inference\nresult, this publication proposes a novel data-driven two-phase multi-split\ncausal ensemble model to combine the strengths of different causality base\nalgorithms. In comparison to existing approaches, the proposed ensemble method\nreduces the influence of noise through a data partitioning scheme in the first\nphase. To achieve this, the data are initially divided into several partitions\nand the base algorithms are applied to each partition. Subsequently, Gaussian\nmixture models are used to identify the causal relationships derived from the\ndifferent partitions that are likely to be valid. In the second phase, the\nidentified relationships from each base algorithm are then merged based on\nthree combination rules. The proposed ensemble approach is evaluated using\nmultiple metrics, among them a newly developed evaluation index for causal\nensemble approaches. We perform experiments using three synthetic datasets with\ndifferent volumes and complexity, which are specifically designed to test\ncausality detection methods under different circumstances while knowing the\nground truth causal relationships. In these experiments, our causality ensemble\noutperforms each of its base algorithms. In practical applications, the use of\nthe proposed method could hence lead to more robust and reliable causality\nresults.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04793v1",
    "published_date": "2024-03-04 14:20:41 UTC",
    "updated_date": "2024-03-04 14:20:41 UTC"
  },
  {
    "arxiv_id": "2403.02054v1",
    "title": "Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism",
    "authors": [
      "Shuvayan Brahmachary",
      "Subodh M. Joshi",
      "Aniruddha Panda",
      "Kaushik Koneripalli",
      "Arun Kumar Sagotra",
      "Harshil Patel",
      "Ankush Sharma",
      "Ameya D. Jagtap",
      "Kaushic Kalyanaraman"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning\nabilities, prompting interest in their application as black-box optimizers.\nThis paper asserts that LLMs possess the capability for zero-shot optimization\nacross diverse scenarios, including multi-objective and high-dimensional\nproblems. We introduce a novel population-based method for numerical\noptimization using LLMs called Language-Model-Based Evolutionary Optimizer\n(LEO). Our hypothesis is supported through numerical examples, spanning\nbenchmark and industrial engineering problems such as supersonic nozzle shape\noptimization, heat transfer, and windfarm layout optimization. We compare our\nmethod to several gradient-based and gradient-free optimization approaches.\nWhile LLMs yield comparable results to state-of-the-art methods, their\nimaginative nature and propensity to hallucinate demand careful handling. We\nprovide practical guidelines for obtaining reliable answers from LLMs and\ndiscuss method limitations and potential research directions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02054v1",
    "published_date": "2024-03-04 13:57:37 UTC",
    "updated_date": "2024-03-04 13:57:37 UTC"
  },
  {
    "arxiv_id": "2403.02053v1",
    "title": "A Scoping Review of Energy-Efficient Driving Behaviors and Applied State-of-the-Art AI Methods",
    "authors": [
      "Zhipeng Ma",
      "Bo Nørregaard Jørgensen",
      "Zheng Ma"
    ],
    "abstract": "The transportation sector remains a major contributor to greenhouse gas\nemissions. The understanding of energy-efficient driving behaviors and\nutilization of energy-efficient driving strategies are essential to reduce\nvehicles' fuel consumption. However, there is no comprehensive investigation\ninto energy-efficient driving behaviors and strategies. Furthermore, many\nstate-of-the-art AI models have been applied for the analysis of eco-friendly\ndriving styles, but no overview is available. To fill the gap, this paper\nconducts a thorough literature review on ecological driving behaviors and\nstyles and analyzes the driving factors influencing energy consumption and\nstate-of-the-art methodologies. With a thorough scoping review process, the\nmethodological and related data are compared. The results show that the factors\nthat impact driving behaviors can be summarized into eleven features including\nspeed, acceleration, deceleration, pedal, and so on. This paper finds that\nsupervised/unsupervised learning algorithms and reinforcement learning\nframeworks have been popularly used to model the vehicle's energy consumption\nwith multi-dimensional data. Furthermore, the literature shows that the driving\ndata are collected from either simulators or real-world experiments, and the\nreal-world data are mainly stored and transmitted by meters, controller area\nnetworks, onboard data services, smartphones, and additional sensors installed\nin the vehicle. Based on driving behavior factors, driver characteristics, and\nsafety rules, this paper recommends nine energy-efficient driving styles\nincluding four guidelines for the drivers' selection and adjustment of the\nvehicle parameters, three recommendations for the energy-efficient driving\nstyles in different driving scenarios, and two subjective suggestions for\ndifferent types of drivers and employers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02053v1",
    "published_date": "2024-03-04 13:57:34 UTC",
    "updated_date": "2024-03-04 13:57:34 UTC"
  },
  {
    "arxiv_id": "2403.12988v1",
    "title": "Improving the Robustness of Object Detection and Classification AI models against Adversarial Patch Attacks",
    "authors": [
      "Roie Kazoom",
      "Raz Birman",
      "Ofer Hadar"
    ],
    "abstract": "Adversarial patch attacks, crafted to compromise the integrity of Deep Neural\nNetworks (DNNs), significantly impact Artificial Intelligence (AI) systems\ndesigned for object detection and classification tasks. The primary purpose of\nthis work is to defend models against real-world physical attacks that target\nobject detection and classification. We analyze attack techniques and propose a\nrobust defense approach. We successfully reduce model confidence by over 20%\nusing adversarial patch attacks that exploit object shape, texture and\nposition. Leveraging the inpainting pre-processing technique, we effectively\nrestore the original confidence levels, demonstrating the importance of robust\ndefenses in mitigating these threats. Following fine-tuning of an AI model for\ntraffic sign classification, we subjected it to a simulated pixelized\npatch-based physical adversarial attack, resulting in misclassifications. Our\ninpainting defense approach significantly enhances model resilience, achieving\nhigh accuracy and reliable localization despite the adversarial attacks. This\ncontribution advances the resilience and reliability of object detection and\nclassification networks against adversarial challenges, providing a robust\nfoundation for critical applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12988v1",
    "published_date": "2024-03-04 13:32:48 UTC",
    "updated_date": "2024-03-04 13:32:48 UTC"
  },
  {
    "arxiv_id": "2403.02368v1",
    "title": "A Novel Hybrid Feature Importance and Feature Interaction Detection Framework for Predictive Optimization in Industry 4.0 Applications",
    "authors": [
      "Zhipeng Ma",
      "Bo Nørregaard Jørgensen",
      "Zheng Grace Ma"
    ],
    "abstract": "Advanced machine learning algorithms are increasingly utilized to provide\ndata-based prediction and decision-making support in Industry 4.0. However, the\nprediction accuracy achieved by the existing models is insufficient to warrant\npractical implementation in real-world applications. This is because not all\nfeatures present in real-world datasets possess a direct relevance to the\npredictive analysis being conducted. Consequently, the careful incorporation of\nselect features has the potential to yield a substantial positive impact on the\noutcome. To address the research gap, this paper proposes a novel hybrid\nframework that combines the feature importance detector - local interpretable\nmodel-agnostic explanations (LIME) and the feature interaction detector -\nneural interaction detection (NID), to improve prediction accuracy. By applying\nthe proposed framework, unnecessary features can be eliminated, and\ninteractions are encoded to generate a more conducive dataset for predictive\npurposes. Subsequently, the proposed model is deployed to refine the prediction\nof electricity consumption in foundry processing. The experimental outcomes\nreveal an augmentation of up to 9.56% in the R2 score, and a diminution of up\nto 24.05% in the root mean square error.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02368v1",
    "published_date": "2024-03-04 13:22:53 UTC",
    "updated_date": "2024-03-04 13:22:53 UTC"
  },
  {
    "arxiv_id": "2403.02018v1",
    "title": "Cross Domain Policy Transfer with Effect Cycle-Consistency",
    "authors": [
      "Ruiqi Zhu",
      "Tianhong Dai",
      "Oya Celiktutan"
    ],
    "abstract": "Training a robotic policy from scratch using deep reinforcement learning\nmethods can be prohibitively expensive due to sample inefficiency. To address\nthis challenge, transferring policies trained in the source domain to the\ntarget domain becomes an attractive paradigm. Previous research has typically\nfocused on domains with similar state and action spaces but differing in other\naspects. In this paper, our primary focus lies in domains with different state\nand action spaces, which has broader practical implications, i.e. transfer the\npolicy from robot A to robot B. Unlike prior methods that rely on paired data,\nwe propose a novel approach for learning the mapping functions between state\nand action spaces across domains using unpaired data. We propose effect cycle\nconsistency, which aligns the effects of transitions across two domains through\na symmetrical optimization structure for learning these mapping functions. Once\nthe mapping functions are learned, we can seamlessly transfer the policy from\nthe source domain to the target domain. Our approach has been tested on three\nlocomotion tasks and two robotic manipulation tasks. The empirical results\ndemonstrate that our method can reduce alignment errors significantly and\nachieve better performance compared to the state-of-the-art method.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to International Conference on Robotics and Automation\n  (ICRA), 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02018v1",
    "published_date": "2024-03-04 13:20:07 UTC",
    "updated_date": "2024-03-04 13:20:07 UTC"
  },
  {
    "arxiv_id": "2403.02014v1",
    "title": "Unveiling Hidden Links Between Unseen Security Entities",
    "authors": [
      "Daniel Alfasi",
      "Tal Shapira",
      "Anat Bremler Barr"
    ],
    "abstract": "The proliferation of software vulnerabilities poses a significant challenge\nfor security databases and analysts tasked with their timely identification,\nclassification, and remediation. With the National Vulnerability Database (NVD)\nreporting an ever-increasing number of vulnerabilities, the traditional manual\nanalysis becomes untenably time-consuming and prone to errors. This paper\nintroduces VulnScopper, an innovative approach that utilizes multi-modal\nrepresentation learning, combining Knowledge Graphs (KG) and Natural Language\nProcessing (NLP), to automate and enhance the analysis of software\nvulnerabilities. Leveraging ULTRA, a knowledge graph foundation model, combined\nwith a Large Language Model (LLM), VulnScopper effectively handles unseen\nentities, overcoming the limitations of previous KG approaches. We evaluate\nVulnScopper on two major security datasets, the NVD and the Red Hat CVE\ndatabase. Our method significantly improves the link prediction accuracy\nbetween Common Vulnerabilities and Exposures (CVEs), Common Weakness\nEnumeration (CWEs), and Common Platform Enumerations (CPEs). Our results show\nthat VulnScopper outperforms existing methods, achieving up to 78% Hits@10\naccuracy in linking CVEs to CPEs and CWEs and presenting an 11.7% improvement\nover large language models in predicting CWE labels based on the Red Hat\ndatabase. Based on the NVD, only 6.37% of the linked CPEs are being published\nduring the first 30 days; many of them are related to critical and high-risk\nvulnerabilities which, according to multiple compliance frameworks (such as\nCISA and PCI), should be remediated within 15-30 days. Our model can uncover\nnew products linked to vulnerabilities, reducing remediation time and improving\nvulnerability management. We analyzed several CVEs from 2023 to showcase this\nability.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02014v1",
    "published_date": "2024-03-04 13:14:39 UTC",
    "updated_date": "2024-03-04 13:14:39 UTC"
  },
  {
    "arxiv_id": "2403.01985v1",
    "title": "Transformers for Low-Resource Languages: Is Féidir Linn!",
    "authors": [
      "Séamus Lankford",
      "Haithem Afli",
      "Andy Way"
    ],
    "abstract": "The Transformer model is the state-of-the-art in Machine Translation.\nHowever, in general, neural translation models often under perform on language\npairs with insufficient training data. As a consequence, relatively few\nexperiments have been carried out using this architecture on low-resource\nlanguage pairs. In this study, hyperparameter optimization of Transformer\nmodels in translating the low-resource English-Irish language pair is\nevaluated. We demonstrate that choosing appropriate parameters leads to\nconsiderable performance improvements. Most importantly, the correct choice of\nsubword model is shown to be the biggest driver of translation performance.\nSentencePiece models using both unigram and BPE approaches were appraised.\nVariations on model architectures included modifying the number of layers,\ntesting various regularisation techniques and evaluating the optimal number of\nheads for attention. A generic 55k DGT corpus and an in-domain 88k public admin\ncorpus were used for evaluation. A Transformer optimized model demonstrated a\nBLEU score improvement of 7.8 points when compared with a baseline RNN model.\nImprovements were observed across a range of metrics, including TER, indicating\na substantially reduced post editing effort for Transformer optimized models\nwith 16k BPE subword models. Bench-marked against Google Translate, our\ntranslation engines demonstrated significant improvements. The question of\nwhether or not Transformers can be used effectively in a low-resource setting\nof English-Irish translation has been addressed. Is f\\'eidir linn - yes we can.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.01985v1",
    "published_date": "2024-03-04 12:29:59 UTC",
    "updated_date": "2024-03-04 12:29:59 UTC"
  },
  {
    "arxiv_id": "2403.01977v2",
    "title": "TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions",
    "authors": [
      "Maytus Piriyajitakonkij",
      "Mingfei Sun",
      "Mengmi Zhang",
      "Wei Pan"
    ],
    "abstract": "Robot navigation under visual corruption presents a formidable challenge. To\naddress this, we propose a Test-time Adaptation (TTA) method, named as TTA-Nav,\nfor point-goal navigation under visual corruptions. Our \"plug-and-play\" method\nincorporates a top-down decoder to a pre-trained navigation model. Firstly, the\npre-trained navigation model gets a corrupted image and extracts features.\nSecondly, the top-down decoder produces the reconstruction given the high-level\nfeatures extracted by the pre-trained model. Then, it feeds the reconstruction\nof a corrupted image back to the pre-trained model. Finally, the pre-trained\nmodel does forward pass again to output action. Despite being trained solely on\nclean images, the top-down decoder can reconstruct cleaner images from\ncorrupted ones without the need for gradient-based adaptation. The pre-trained\nnavigation model with our top-down decoder significantly enhances navigation\nperformance across almost all visual corruptions in our benchmarks. Our method\nimproves the success rate of point-goal navigation from the state-of-the-art\nresult of 46% to 94% on the most severe corruption. This suggests its potential\nfor broader application in robotic visual navigation. Project page:\nhttps://sites.google.com/view/tta-nav",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to IROS2024",
    "pdf_url": "http://arxiv.org/pdf/2403.01977v2",
    "published_date": "2024-03-04 12:20:29 UTC",
    "updated_date": "2024-03-14 16:30:48 UTC"
  },
  {
    "arxiv_id": "2403.02367v1",
    "title": "adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation",
    "authors": [
      "Séamus Lankford",
      "Haithem Afli",
      "Andy Way"
    ],
    "abstract": "adaptNMT streamlines all processes involved in the development and deployment\nof RNN and Transformer neural translation models. As an open-source\napplication, it is designed for both technical and non-technical users who work\nin the field of machine translation. Built upon the widely-adopted OpenNMT\necosystem, the application is particularly useful for new entrants to the field\nsince the setup of the development environment and creation of train,\nvalidation and test splits is greatly simplified. Graphing, embedded within the\napplication, illustrates the progress of model training, and SentencePiece is\nused for creating subword segmentation models. Hyperparameter customization is\nfacilitated through an intuitive user interface, and a single-click model\ndevelopment approach has been implemented. Models developed by adaptNMT can be\nevaluated using a range of metrics, and deployed as a translation service\nwithin the application. To support eco-friendly research in the NLP space, a\ngreen report also flags the power consumption and kgCO$_{2}$ emissions\ngenerated during model development. The application is freely available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02367v1",
    "published_date": "2024-03-04 12:10:17 UTC",
    "updated_date": "2024-03-04 12:10:17 UTC"
  },
  {
    "arxiv_id": "2403.01964v2",
    "title": "The Heterogeneous Productivity Effects of Generative AI",
    "authors": [
      "David Kreitmeir",
      "Paul A. Raschky"
    ],
    "abstract": "We analyse the individual productivity effects of Italy's ban on ChatGPT, a\ngenerative pretrained transformer chatbot. We compile data on the daily coding\noutput quantity and quality of over 36,000 GitHub users in Italy and other\nEuropean countries and combine these data with the sudden announcement of the\nban in a difference-in-differences framework. Among the affected users in\nItaly, we find a short-term increase in output quantity and quality for less\nexperienced users and a decrease in productivity on more routine tasks for\nexperienced users.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01964v2",
    "published_date": "2024-03-04 12:07:28 UTC",
    "updated_date": "2024-06-03 01:21:01 UTC"
  },
  {
    "arxiv_id": "2403.01954v4",
    "title": "DECIDER: A Dual-System Rule-Controllable Decoding Framework for Language Generation",
    "authors": [
      "Chen Xu",
      "Tian Lan",
      "Yu Ji",
      "Changlong Yu",
      "Wei Wang",
      "Jun Gao",
      "Qunxi Dong",
      "Kun Qian",
      "Piji Li",
      "Wei Bi",
      "Bin Hu"
    ],
    "abstract": "Constrained decoding approaches aim to control the meaning or style of text\ngenerated by the pre-trained large language models (LLMs or also PLMs) for\nvarious tasks at inference time. However, these methods often guide plausible\ncontinuations by greedily and explicitly selecting targets. Though fulfilling\nthe task requirements, these methods may overlook certain general and natural\nlogics that humans would implicitly follow towards such targets. Inspired by\ncognitive dual-process theory, in this work, we propose a novel decoding\nframework DECIDER where the base LLMs are equipped with a First-Order Logic\n(FOL) reasoner to express and evaluate the rules, along with a decision\nfunction that merges the outputs of both systems to guide the generation.\nUnlike previous constrained decodings, DECIDER transforms the encouragement of\ntarget-specific words into all words that satisfy several high-level rules,\nenabling us to programmatically integrate our logic into LLMs. Experiments on\nCommonGen and PersonaChat demonstrate that DECIDER effectively follows given\nFOL rules to guide LLMs in a more human-like and logic-controlled manner.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IEEE TKDE 2025, 14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.01954v4",
    "published_date": "2024-03-04 11:49:08 UTC",
    "updated_date": "2025-05-04 06:48:20 UTC"
  },
  {
    "arxiv_id": "2403.02366v1",
    "title": "Human Evaluation of English--Irish Transformer-Based NMT",
    "authors": [
      "Séamus Lankford",
      "Haithem Afli",
      "Andy Way"
    ],
    "abstract": "In this study, a human evaluation is carried out on how hyperparameter\nsettings impact the quality of Transformer-based Neural Machine Translation\n(NMT) for the low-resourced English--Irish pair. SentencePiece models using\nboth Byte Pair Encoding (BPE) and unigram approaches were appraised. Variations\nin model architectures included modifying the number of layers, evaluating the\noptimal number of heads for attention and testing various regularisation\ntechniques. The greatest performance improvement was recorded for a\nTransformer-optimized model with a 16k BPE subword model. Compared with a\nbaseline Recurrent Neural Network (RNN) model, a Transformer-optimized model\ndemonstrated a BLEU score improvement of 7.8 points. When benchmarked against\nGoogle Translate, our translation engines demonstrated significant\nimprovements. Furthermore, a quantitative fine-grained manual evaluation was\nconducted which compared the performance of machine translation systems. Using\nthe Multidimensional Quality Metrics (MQM) error taxonomy, a human evaluation\nof the error types generated by an RNN-based system and a Transformer-based\nsystem was explored. Our findings show the best-performing Transformer system\nsignificantly reduces both accuracy and fluency errors when compared with an\nRNN-based model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2403.01985",
    "pdf_url": "http://arxiv.org/pdf/2403.02366v1",
    "published_date": "2024-03-04 11:45:46 UTC",
    "updated_date": "2024-03-04 11:45:46 UTC"
  },
  {
    "arxiv_id": "2403.06999v1",
    "title": "Survival modeling using deep learning, machine learning and statistical methods: A comparative analysis for predicting mortality after hospital admission",
    "authors": [
      "Ziwen Wang",
      "Jin Wee Lee",
      "Tanujit Chakraborty",
      "Yilin Ning",
      "Mingxuan Liu",
      "Feng Xie",
      "Marcus Eng Hock Ong",
      "Nan Liu"
    ],
    "abstract": "Survival analysis is essential for studying time-to-event outcomes and\nproviding a dynamic understanding of the probability of an event occurring over\ntime. Various survival analysis techniques, from traditional statistical models\nto state-of-the-art machine learning algorithms, support healthcare\nintervention and policy decisions. However, there remains ongoing discussion\nabout their comparative performance. We conducted a comparative study of\nseveral survival analysis methods, including Cox proportional hazards (CoxPH),\nstepwise CoxPH, elastic net penalized Cox model, Random Survival Forests (RSF),\nGradient Boosting machine (GBM) learning, AutoScore-Survival, DeepSurv,\ntime-dependent Cox model based on neural network (CoxTime), and DeepHit\nsurvival neural network. We applied the concordance index (C-index) for model\ngoodness-of-fit, and integral Brier scores (IBS) for calibration, and\nconsidered the model interpretability. As a case study, we performed a\nretrospective analysis of patients admitted through the emergency department of\na tertiary hospital from 2017 to 2019, predicting 90-day all-cause mortality\nbased on patient demographics, clinicopathological features, and historical\ndata. The results of the C-index indicate that deep learning achieved\ncomparable performance, with DeepSurv producing the best discrimination\n(DeepSurv: 0.893; CoxTime: 0.892; DeepHit: 0.891). The calibration of DeepSurv\n(IBS: 0.041) performed the best, followed by RSF (IBS: 0.042) and GBM (IBS:\n0.0421), all using the full variables. Moreover, AutoScore-Survival, using a\nminimal variable subset, is easy to interpret, and can achieve good\ndiscrimination and calibration (C-index: 0.867; IBS: 0.044). While all models\nwere satisfactory, DeepSurv exhibited the best discrimination and calibration.\nIn addition, AutoScore-Survival offers a more parsimonious model and excellent\ninterpretability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06999v1",
    "published_date": "2024-03-04 10:46:02 UTC",
    "updated_date": "2024-03-04 10:46:02 UTC"
  },
  {
    "arxiv_id": "2403.01924v2",
    "title": "To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering",
    "authors": [
      "Giacomo Frisoni",
      "Alessio Cocchieri",
      "Alex Presepi",
      "Gianluca Moro",
      "Zaiqiao Meng"
    ],
    "abstract": "Medical open-domain question answering demands substantial access to\nspecialized knowledge. Recent efforts have sought to decouple knowledge from\nmodel parameters, counteracting architectural scaling and allowing for training\non common low-resource hardware. The retrieve-then-read paradigm has become\nubiquitous, with model predictions grounded on relevant knowledge pieces from\nexternal repositories such as PubMed, textbooks, and UMLS. An alternative path,\nstill under-explored but made possible by the advent of domain-specific large\nlanguage models, entails constructing artificial contexts through prompting. As\na result, \"to generate or to retrieve\" is the modern equivalent of Hamlet's\ndilemma. This paper presents MedGENIE, the first generate-then-read framework\nfor multiple-choice question answering in medicine. We conduct extensive\nexperiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical\nperspective by assuming a maximum of 24GB VRAM. MedGENIE sets a new\nstate-of-the-art in the open-book setting of each testbed, allowing a\nsmall-scale reader to outcompete zero-shot closed-book 175B baselines while\nusing up to 706$\\times$ fewer parameters. Our findings reveal that generated\npassages are more effective than retrieved ones in attaining higher accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (camera-ready paper)",
    "pdf_url": "http://arxiv.org/pdf/2403.01924v2",
    "published_date": "2024-03-04 10:41:52 UTC",
    "updated_date": "2024-06-13 08:42:05 UTC"
  },
  {
    "arxiv_id": "2404.02912v1",
    "title": "Probabilistic Generating Circuits -- Demystified",
    "authors": [
      "Sanyam Agarwal",
      "Markus Bläser"
    ],
    "abstract": "Zhang et al. (ICML 2021, PLMR 139, pp. 12447-1245) introduced probabilistic\ngenerating circuits (PGCs) as a probabilistic model to unify probabilistic\ncircuits (PCs) and determinantal point processes (DPPs). At a first glance,\nPGCs store a distribution in a very different way, they compute the probability\ngenerating polynomial instead of the probability mass function and it seems\nthat this is the main reason why PGCs are more powerful than PCs or DPPs.\nHowever, PGCs also allow for negative weights, whereas classical PCs assume\nthat all weights are nonnegative. One of the main insights of our paper is that\nthe negative weights are responsible for the power of PGCs and not the\ndifferent representation. PGCs are PCs in disguise, in particular, we show how\nto transform any PGC into a PC with negative weights with only polynomial\nblowup.\n  PGCs were defined by Zhang et al. only for binary random variables. As our\nsecond main result, we show that there is a good reason for this: we prove that\nPGCs for categorial variables with larger image size do not support tractable\nmarginalization unless NP = P. On the other hand, we show that we can model\ncategorial variables with larger image size as PC with negative weights\ncomputing set-multilinear polynomials. These allow for tractable\nmarginalization. In this sense, PCs with negative weights strictly subsume\nPGCs.",
    "categories": [
      "cs.CC",
      "cs.AI"
    ],
    "primary_category": "cs.CC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.02912v1",
    "published_date": "2024-03-04 10:40:09 UTC",
    "updated_date": "2024-03-04 10:40:09 UTC"
  },
  {
    "arxiv_id": "2403.01915v2",
    "title": "xT: Nested Tokenization for Larger Context in Large Images",
    "authors": [
      "Ritwik Gupta",
      "Shufan Li",
      "Tyler Zhu",
      "Jitendra Malik",
      "Trevor Darrell",
      "Karttikeya Mangalam"
    ],
    "abstract": "Modern computer vision pipelines handle large images in one of two\nsub-optimal ways: down-sampling or cropping. These two methods incur\nsignificant losses in the amount of information and context present in an\nimage. There are many downstream applications in which global context matters\nas much as high frequency details, such as in real-world satellite imagery; in\nsuch cases researchers have to make the uncomfortable choice of which\ninformation to discard. We introduce xT, a simple framework for vision\ntransformers which effectively aggregates global context with local details and\ncan model large images end-to-end on contemporary GPUs. We select a set of\nbenchmark datasets across classic vision tasks which accurately reflect a\nvision model's ability to understand truly large images and incorporate fine\ndetails over large scales and assess our method's improvement on them. xT is a\nstreaming, two-stage architecture that adapts existing vision backbones and\nlong sequence language models to effectively model large images without\nquadratic memory growth. We are able to increase accuracy by up to 8.6% on\nchallenging classification tasks and $F_1$ score by 11.6 on context-dependent\nsegmentation on images as large as 29,000 x 29,000 pixels.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the 2024 International Conference on Machine Learning\n  (ICML)",
    "pdf_url": "http://arxiv.org/pdf/2403.01915v2",
    "published_date": "2024-03-04 10:29:58 UTC",
    "updated_date": "2024-07-21 02:33:00 UTC"
  },
  {
    "arxiv_id": "2403.01909v3",
    "title": "Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey",
    "authors": [
      "Lingyan Ran",
      "Yali Li",
      "Guoqiang Liang",
      "Yanning Zhang"
    ],
    "abstract": "Semantic segmentation is an important and popular research area in computer\nvision that focuses on classifying pixels in an image based on their semantics.\nHowever, supervised deep learning requires large amounts of data to train\nmodels and the process of labeling images pixel by pixel is time-consuming and\nlaborious. This review aims to provide a first comprehensive and organized\noverview of the state-of-the-art research results on pseudo-label methods in\nthe field of semi-supervised semantic segmentation, which we categorize from\ndifferent perspectives and present specific methods for specific application\nareas. In addition, we explore the application of pseudo-label technology in\nmedical and remote-sensing image segmentation. Finally, we also propose some\nfeasible future research directions to address the existing challenges.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE Transactions on Circuits and Systems for Video\n  Technology(TCSVT)",
    "pdf_url": "http://arxiv.org/pdf/2403.01909v3",
    "published_date": "2024-03-04 10:18:38 UTC",
    "updated_date": "2025-03-18 05:27:02 UTC"
  },
  {
    "arxiv_id": "2403.04790v1",
    "title": "Online Training of Large Language Models: Learn while chatting",
    "authors": [
      "Juhao Liang",
      "Ziwei Wang",
      "Zhuoheng Ma",
      "Jianquan Li",
      "Zhiyi Zhang",
      "Xiangbo Wu",
      "Benyou Wang"
    ],
    "abstract": "Large Language Models(LLMs) have dramatically revolutionized the field of\nNatural Language Processing(NLP), offering remarkable capabilities that have\ngarnered widespread usage. However, existing interaction paradigms between LLMs\nand users are constrained by either inflexibility, limitations in\ncustomization, or a lack of persistent learning. This inflexibility is\nparticularly evident as users, especially those without programming skills,\nhave restricted avenues to enhance or personalize the model. Existing\nframeworks further complicate the model training and deployment process due to\ntheir computational inefficiencies and lack of user-friendly interfaces. To\novercome these challenges, this paper introduces a novel interaction\nparadigm-'Online Training using External Interactions'-that merges the benefits\nof persistent, real-time model updates with the flexibility for individual\ncustomization through external interactions such as AI agents or online/offline\nknowledge bases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04790v1",
    "published_date": "2024-03-04 10:00:55 UTC",
    "updated_date": "2024-03-04 10:00:55 UTC"
  },
  {
    "arxiv_id": "2403.01895v1",
    "title": "Unsupervised Distance Metric Learning for Anomaly Detection Over Multivariate Time Series",
    "authors": [
      "Hanyang Yuan",
      "Qinglin Cai",
      "Keting Yin"
    ],
    "abstract": "Distance-based time series anomaly detection methods are prevalent due to\ntheir relative non-parametric nature and interpretability. However, the\ncommonly used Euclidean distance is sensitive to noise. While existing works\nhave explored dynamic time warping (DTW) for its robustness, they only support\nsupervised tasks over multivariate time series (MTS), leaving a scarcity of\nunsupervised methods. In this work, we propose FCM-wDTW, an unsupervised\ndistance metric learning method for anomaly detection over MTS, which encodes\nraw data into latent space and reveals normal dimension relationships through\ncluster centers. FCM-wDTW introduces locally weighted DTW into fuzzy C-means\nclustering and learns the optimal latent space efficiently, enabling anomaly\nidentification via data reconstruction. Experiments with 11 different types of\nbenchmarks demonstrate our method's competitive accuracy and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01895v1",
    "published_date": "2024-03-04 09:55:16 UTC",
    "updated_date": "2024-03-04 09:55:16 UTC"
  },
  {
    "arxiv_id": "2403.01888v3",
    "title": "Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on Zero-Cost Benchmarks",
    "authors": [
      "Shuhei Watanabe",
      "Neeratyoy Mallik",
      "Edward Bergman",
      "Frank Hutter"
    ],
    "abstract": "While deep learning has celebrated many successes, its results often hinge on\nthe meticulous selection of hyperparameters (HPs). However, the time-consuming\nnature of deep learning training makes HP optimization (HPO) a costly endeavor,\nslowing down the development of efficient HPO tools. While zero-cost\nbenchmarks, which provide performance and runtime without actual training,\noffer a solution for non-parallel setups, they fall short in parallel setups as\neach worker must communicate its queried runtime to return its evaluation in\nthe exact order. This work addresses this challenge by introducing a\nuser-friendly Python package that facilitates efficient parallel HPO with\nzero-cost benchmarks. Our approach calculates the exact return order based on\nthe information stored in file system, eliminating the need for long waiting\ntimes and enabling much faster HPO evaluations. We first verify the correctness\nof our approach through extensive testing and the experiments with 6 popular\nHPO libraries show its applicability to diverse libraries and its ability to\nachieve over 1000x speedup compared to a traditional approach. Our package can\nbe installed via pip install mfhpo-simulator.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to AutoML Conference 2024 ABCD Track",
    "pdf_url": "http://arxiv.org/pdf/2403.01888v3",
    "published_date": "2024-03-04 09:49:35 UTC",
    "updated_date": "2024-08-19 08:07:38 UTC"
  },
  {
    "arxiv_id": "2403.01886v1",
    "title": "FCDS: Fusing Constituency and Dependency Syntax into Document-Level Relation Extraction",
    "authors": [
      "Xudong Zhu",
      "Zhao Kang",
      "Bei Hui"
    ],
    "abstract": "Document-level Relation Extraction (DocRE) aims to identify relation labels\nbetween entities within a single document. It requires handling several\nsentences and reasoning over them. State-of-the-art DocRE methods use a graph\nstructure to connect entities across the document to capture dependency syntax\ninformation. However, this is insufficient to fully exploit the rich syntax\ninformation in the document. In this work, we propose to fuse constituency and\ndependency syntax into DocRE. It uses constituency syntax to aggregate the\nwhole sentence information and select the instructive sentences for the pairs\nof targets. It exploits the dependency syntax in a graph structure with\nconstituency syntax enhancement and chooses the path between entity pairs based\non the dependency graph. The experimental results on datasets from various\ndomains demonstrate the effectiveness of the proposed method. The code is\npublicly available at this url.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Appear in COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.01886v1",
    "published_date": "2024-03-04 09:48:55 UTC",
    "updated_date": "2024-03-04 09:48:55 UTC"
  },
  {
    "arxiv_id": "2403.01875v4",
    "title": "Locally Convex Global Loss Network for Decision-Focused Learning",
    "authors": [
      "Haeun Jeon",
      "Hyunglip Bae",
      "Minsu Park",
      "Chanyeong Kim",
      "Woo Chang Kim"
    ],
    "abstract": "In decision-making problems under uncertainty, predicting unknown parameters\nis often considered independent of the optimization part. Decision-focused\nlearning (DFL) is a task-oriented framework that integrates prediction and\noptimization by adapting the predictive model to give better decisions for the\ncorresponding task. Here, an inevitable challenge arises when computing the\ngradients of the optimal decision with respect to the parameters. Existing\nresearch copes with this issue by smoothly reforming surrogate optimization or\nconstructing surrogate loss functions that mimic task loss. However, they are\napplied to restricted optimization domains. In this paper, we propose Locally\nConvex Global Loss Network (LCGLN), a global surrogate loss model that can be\nimplemented in a general DFL paradigm. LCGLN learns task loss via a partial\ninput convex neural network which is guaranteed to be convex for chosen inputs\nwhile keeping the non-convex global structure for the other inputs. This\nenables LCGLN to admit general DFL through only a single surrogate loss without\nany sense for choosing appropriate parametric forms. We confirm the\neffectiveness and flexibility of LCGLN by evaluating our proposed model with\nthree stochastic decision-making problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI-25 (Oral Presentation)",
    "pdf_url": "http://arxiv.org/pdf/2403.01875v4",
    "published_date": "2024-03-04 09:31:56 UTC",
    "updated_date": "2025-02-10 10:48:40 UTC"
  },
  {
    "arxiv_id": "2403.01861v1",
    "title": "AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes",
    "authors": [
      "Jaehoon Jang",
      "Inha Lee",
      "Minje Kim",
      "Kyungdon Joo"
    ],
    "abstract": "Indoor scenes we are living in are visually homogenous or textureless, while\nthey inherently have structural forms and provide enough structural priors for\n3D scene reconstruction. Motivated by this fact, we propose a structure-aware\nonline signed distance fields (SDF) reconstruction framework in indoor scenes,\nespecially under the Atlanta world (AW) assumption. Thus, we dub this\nincremental SDF reconstruction for AW as AiSDF. Within the online framework, we\ninfer the underlying Atlanta structure of a given scene and then estimate\nplanar surfel regions supporting the Atlanta structure. This Atlanta-aware\nsurfel representation provides an explicit planar map for a given scene. In\naddition, based on these Atlanta planar surfel regions, we adaptively sample\nand constrain the structural regularity in the SDF reconstruction, which\nenables us to improve the reconstruction quality by maintaining a high-level\nstructure while enhancing the details of a given scene. We evaluate the\nproposed AiSDF on the ScanNet and ReplicaCAD datasets, where we demonstrate\nthat the proposed framework is capable of reconstructing fine details of\nobjects implicitly, as well as structures explicitly in room-scale scenes.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures, Accepted to IEEE RA-L (First two authors\n  contributed equally)",
    "pdf_url": "http://arxiv.org/pdf/2403.01861v1",
    "published_date": "2024-03-04 09:18:13 UTC",
    "updated_date": "2024-03-04 09:18:13 UTC"
  },
  {
    "arxiv_id": "2403.01851v1",
    "title": "Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral",
    "authors": [
      "Yiming Cui",
      "Xin Yao"
    ],
    "abstract": "Mixtral, a representative sparse mixture of experts (SMoE) language model,\nhas received significant attention due to its unique model design and superior\nperformance. Based on Mixtral-8x7B-v0.1, in this paper, we propose\nChinese-Mixtral and Chinese-Mixtral-Instruct with improved Chinese language\nabilities by adopting further pre-training and instruction fine-tuning.\nExperimental results show that our Chinese-Mixtral and Chinese-Mixtral-Instruct\nsuccessfully improve Chinese understanding and generation performance while\nretaining the original English abilities. Then, we discuss several key\nquestions when performing language adaptation on large language models,\nincluding the necessity of extending the language-specific vocabulary and the\nchoice of the initialization model (foundation model v.s. instruction model),\nby providing empirical results and analysis. We also present the visualizations\nof each expert to examine their importance on downstream tasks. Our resources\nare publicly available through \\url{https://github.com/ymcui/Chinese-Mixtral}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.01851v1",
    "published_date": "2024-03-04 09:01:10 UTC",
    "updated_date": "2024-03-04 09:01:10 UTC"
  },
  {
    "arxiv_id": "2403.01849v1",
    "title": "One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models",
    "authors": [
      "Lin Li",
      "Haoyan Guan",
      "Jianing Qiu",
      "Michael Spratling"
    ],
    "abstract": "Large pre-trained Vision-Language Models (VLMs) like CLIP, despite having\nremarkable generalization ability, are highly vulnerable to adversarial\nexamples. This work studies the adversarial robustness of VLMs from the novel\nperspective of the text prompt instead of the extensively studied model weights\n(frozen in this work). We first show that the effectiveness of both adversarial\nattack and defense are sensitive to the used text prompt. Inspired by this, we\npropose a method to improve resilience to adversarial attacks by learning a\nrobust text prompt for VLMs. The proposed method, named Adversarial Prompt\nTuning (APT), is effective while being both computationally and data efficient.\nExtensive experiments are conducted across 15 datasets and 4 data sparsity\nschemes (from 1-shot to full training data settings) to show APT's superiority\nover hand-engineered prompts and other state-of-the-art adaption methods. APT\ndemonstrated excellent abilities in terms of the in-distribution performance\nand the generalization under input distribution shift and across datasets.\nSurprisingly, by simply adding one learned word to the prompts, APT can\nsignificantly boost the accuracy and robustness (epsilon=4/255) over the\nhand-engineered prompts by +13% and +8.5% on average respectively. The\nimprovement further increases, in our most effective setting, to +26.4% for\naccuracy and +16.7% for robustness. Code is available at\nhttps://github.com/TreeLLi/APT.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR2024",
    "pdf_url": "http://arxiv.org/pdf/2403.01849v1",
    "published_date": "2024-03-04 08:59:32 UTC",
    "updated_date": "2024-03-04 08:59:32 UTC"
  },
  {
    "arxiv_id": "2403.01845v2",
    "title": "NASH: Neural Architecture Search for Hardware-Optimized Machine Learning Models",
    "authors": [
      "Mengfei Ji",
      "Yuchun Chang",
      "Baolin Zhang",
      "Zaid Al-Ars"
    ],
    "abstract": "As machine learning (ML) algorithms get deployed in an ever-increasing number\nof applications, these algorithms need to achieve better trade-offs between\nhigh accuracy, high throughput and low latency. This paper introduces NASH, a\nnovel approach that applies neural architecture search to machine learning\nhardware. Using NASH, hardware designs can achieve not only high throughput and\nlow latency but also superior accuracy performance. We present four versions of\nthe NASH strategy in this paper, all of which show higher accuracy than the\noriginal models. The strategy can be applied to various convolutional neural\nnetworks, selecting specific model operations among many to guide the training\nprocess toward higher accuracy. Experimental results show that applying NASH on\nResNet18 or ResNet34 achieves a top 1 accuracy increase of up to 3.1% and a top\n5 accuracy increase of up to 2.2% compared to the non-NASH version when tested\non the ImageNet data set. We also integrated this approach into the FINN\nhardware model synthesis tool to automate the application of our approach and\nthe generation of the hardware model. Results show that using FINN can achieve\na maximum throughput of 324.5 fps. In addition, NASH models can also result in\na better trade-off between accuracy and hardware resource utilization. The\naccuracy-hardware (HW) Pareto curve shows that the models with the four NASH\nversions represent the best trade-offs achieving the highest accuracy for a\ngiven HW utilization. The code for our implementation is open-source and\npublicly available on GitHub at https://github.com/MFJI/NASH.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01845v2",
    "published_date": "2024-03-04 08:51:38 UTC",
    "updated_date": "2024-03-10 05:49:03 UTC"
  },
  {
    "arxiv_id": "2404.01308v1",
    "title": "Learning to Solve Job Shop Scheduling under Uncertainty",
    "authors": [
      "Guillaume Infantes",
      "Stéphanie Roussel",
      "Pierre Pereira",
      "Antoine Jacquet",
      "Emmanuel Benazera"
    ],
    "abstract": "Job-Shop Scheduling Problem (JSSP) is a combinatorial optimization problem\nwhere tasks need to be scheduled on machines in order to minimize criteria such\nas makespan or delay. To address more realistic scenarios, we associate a\nprobability distribution with the duration of each task. Our objective is to\ngenerate a robust schedule, i.e. that minimizes the average makespan. This\npaper introduces a new approach that leverages Deep Reinforcement Learning\n(DRL) techniques to search for robust solutions, emphasizing JSSPs with\nuncertain durations. Key contributions of this research include: (1)\nadvancements in DRL applications to JSSPs, enhancing generalization and\nscalability, (2) a novel method for addressing JSSPs with uncertain durations.\nThe Wheatley approach, which integrates Graph Neural Networks (GNNs) and DRL,\nis made publicly available for further research and applications.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published at CPAIOR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.01308v1",
    "published_date": "2024-03-04 08:38:55 UTC",
    "updated_date": "2024-03-04 08:38:55 UTC"
  },
  {
    "arxiv_id": "2403.04789v2",
    "title": "TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection",
    "authors": [
      "Jiamin Luo",
      "Jingjing Wang",
      "Guodong Zhou"
    ],
    "abstract": "Multimodal Conversational Emotion (MCE) detection, generally spanning across\nthe acoustic, vision and language modalities, has attracted increasing interest\nin the multimedia community. Previous studies predominantly focus on learning\ncontextual information in conversations with only a few considering the topic\ninformation in single language modality, while always neglecting the acoustic\nand vision topic information. On this basis, we propose a model-agnostic\nTopic-enriched Diffusion (TopicDiff) approach for capturing multimodal topic\ninformation in MCE tasks. Particularly, we integrate the diffusion model into\nneural topic model to alleviate the diversity deficiency problem of neural\ntopic model in capturing topic information. Detailed evaluations demonstrate\nthe significant improvements of TopicDiff over the state-of-the-art MCE\nbaselines, justifying the importance of multimodal topic information to MCE and\nthe effectiveness of TopicDiff in capturing such information. Furthermore, we\nobserve an interesting finding that the topic information in acoustic and\nvision is more discriminative and robust compared to the language.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04789v2",
    "published_date": "2024-03-04 08:38:53 UTC",
    "updated_date": "2024-03-11 01:04:28 UTC"
  },
  {
    "arxiv_id": "2403.01840v1",
    "title": "FreeA: Human-object Interaction Detection using Free Annotation Labels",
    "authors": [
      "Yuxiao Wang",
      "Zhenao Wei",
      "Xinyu Jiang",
      "Yu Lei",
      "Weiying Xue",
      "Jinxiu Liu",
      "Qi Liu"
    ],
    "abstract": "Recent human-object interaction (HOI) detection approaches rely on high cost\nof manpower and require comprehensive annotated image datasets. In this paper,\nwe propose a novel self-adaption language-driven HOI detection method, termed\nas FreeA, without labeling by leveraging the adaptability of CLIP to generate\nlatent HOI labels. To be specific, FreeA matches image features of human-object\npairs with HOI text templates, and a priori knowledge-based mask method is\ndeveloped to suppress improbable interactions. In addition, FreeA utilizes the\nproposed interaction correlation matching method to enhance the likelihood of\nactions related to a specified action, further refine the generated HOI labels.\nExperiments on two benchmark datasets show that FreeA achieves state-of-the-art\nperformance among weakly supervised HOI models. Our approach is +8.58 mean\nAverage Precision (mAP) on HICO-DET and +1.23 mAP on V-COCO more accurate in\nlocalizing and classifying the interactive actions than the newest weakly\nmodel, and +1.68 mAP and +7.28 mAP than the latest weakly+ model, respectively.\nCode will be available at https://drliuqi.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 7 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.01840v1",
    "published_date": "2024-03-04 08:38:15 UTC",
    "updated_date": "2024-03-04 08:38:15 UTC"
  },
  {
    "arxiv_id": "2403.01832v1",
    "title": "Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals and Industrial Pragmatism",
    "authors": [
      "Chanjun Park",
      "Minsoo Khang",
      "Dahyun Kim"
    ],
    "abstract": "This paper delves into the contrasting roles of data within academic and\nindustrial spheres, highlighting the divergence between Data-Centric AI and\nModel-Agnostic AI approaches. We argue that while Data-Centric AI focuses on\nthe primacy of high-quality data for model performance, Model-Agnostic AI\nprioritizes algorithmic flexibility, often at the expense of data quality\nconsiderations. This distinction reveals that academic standards for data\nquality frequently do not meet the rigorous demands of industrial applications,\nleading to potential pitfalls in deploying academic models in real-world\nsettings. Through a comprehensive analysis, we address these disparities,\npresenting both the challenges they pose and strategies for bridging the gap.\nFurthermore, we propose a novel paradigm: Model-Based Data-Centric AI, which\naims to reconcile these differences by integrating model considerations into\ndata optimization processes. This approach underscores the necessity for\nevolving data requirements that are sensitive to the nuances of both academic\nresearch and industrial deployment. By exploring these discrepancies, we aim to\nfoster a more nuanced understanding of data's role in AI development and\nencourage a convergence of academic and industrial standards to enhance AI's\nreal-world applicability.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for Data-centric Machine Learning Research (DMLR) Workshop\n  at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.01832v1",
    "published_date": "2024-03-04 08:29:15 UTC",
    "updated_date": "2024-03-04 08:29:15 UTC"
  },
  {
    "arxiv_id": "2403.01827v3",
    "title": "Analysis and Fully Memristor-based Reservoir Computing for Temporal Data Classification",
    "authors": [
      "Ankur Singh",
      "Sanghyeon Choi",
      "Gunuk Wang",
      "Maryaradhiya Daimari",
      "Byung-Geun Lee"
    ],
    "abstract": "Reservoir computing (RC) offers a neuromorphic framework that is particularly\neffective for processing spatiotemporal signals. Known for its temporal\nprocessing prowess, RC significantly lowers training costs compared to\nconventional recurrent neural networks. A key component in its hardware\ndeployment is the ability to generate dynamic reservoir states. Our research\nintroduces a novel dual-memory RC system, integrating a short-term memory via a\nWOx-based memristor, capable of achieving 16 distinct states encoded over 4\nbits, and a long-term memory component using a TiOx-based memristor within the\nreadout layer. We thoroughly examine both memristor types and leverage the RC\nsystem to process temporal data sets. The performance of the proposed RC system\nis validated through two benchmark tasks: isolated spoken digit recognition\nwith incomplete inputs and Mackey-Glass time series prediction. The system\ndelivered an impressive 98.84% accuracy in digit recognition and sustained a\nlow normalized root mean square error (NRMSE) of 0.036 in the time series\nprediction task, underscoring its capability. This study illuminates the\nadeptness of memristor-based RC systems in managing intricate temporal\nchallenges, laying the groundwork for further innovations in neuromorphic\ncomputing.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "22 pages, 20 figures, Journal, Typo corrected and updated reference",
    "pdf_url": "http://arxiv.org/pdf/2403.01827v3",
    "published_date": "2024-03-04 08:22:29 UTC",
    "updated_date": "2025-03-21 06:52:25 UTC"
  },
  {
    "arxiv_id": "2403.01823v2",
    "title": "RT-H: Action Hierarchies Using Language",
    "authors": [
      "Suneel Belkhale",
      "Tianli Ding",
      "Ted Xiao",
      "Pierre Sermanet",
      "Quon Vuong",
      "Jonathan Tompson",
      "Yevgen Chebotar",
      "Debidatta Dwibedi",
      "Dorsa Sadigh"
    ],
    "abstract": "Language provides a way to break down complex concepts into digestible\npieces. Recent works in robot imitation learning use language-conditioned\npolicies that predict actions given visual observations and the high-level task\nspecified in language. These methods leverage the structure of natural language\nto share data between semantically similar tasks (e.g., \"pick coke can\" and\n\"pick an apple\") in multi-task datasets. However, as tasks become more\nsemantically diverse (e.g., \"pick coke can\" and \"pour cup\"), sharing data\nbetween tasks becomes harder, so learning to map high-level tasks to actions\nrequires much more demonstration data. To bridge tasks and actions, our insight\nis to teach the robot the language of actions, describing low-level motions\nwith more fine-grained phrases like \"move arm forward\". Predicting these\nlanguage motions as an intermediate step between tasks and actions forces the\npolicy to learn the shared structure of low-level motions across seemingly\ndisparate tasks. Furthermore, a policy that is conditioned on language motions\ncan easily be corrected during execution through human-specified language\nmotions. This enables a new paradigm for flexible policies that can learn from\nhuman intervention in language. Our method RT-H builds an action hierarchy\nusing language motions: it first learns to predict language motions, and\nconditioned on this and the high-level task, it predicts actions, using visual\ncontext at all stages. We show that RT-H leverages this language-action\nhierarchy to learn policies that are more robust and flexible by effectively\ntapping into multi-task datasets. We show that these policies not only allow\nfor responding to language interventions, but can also learn from such\ninterventions and outperform methods that learn from teleoperated\ninterventions. Our website and videos are found at\nhttps://rt-hierarchy.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01823v2",
    "published_date": "2024-03-04 08:16:11 UTC",
    "updated_date": "2024-06-01 01:54:54 UTC"
  },
  {
    "arxiv_id": "2403.14668v1",
    "title": "Predicting Learning Performance with Large Language Models: A Study in Adult Literacy",
    "authors": [
      "Liang Zhang",
      "Jionghao Lin",
      "Conrad Borchers",
      "John Sabatini",
      "John Hollander",
      "Meng Cao",
      "Xiangen Hu"
    ],
    "abstract": "Intelligent Tutoring Systems (ITSs) have significantly enhanced adult\nliteracy training, a key factor for societal participation, employment\nopportunities, and lifelong learning. Our study investigates the application of\nadvanced AI models, including Large Language Models (LLMs) like GPT-4, for\npredicting learning performance in adult literacy programs in ITSs. This\nresearch is motivated by the potential of LLMs to predict learning performance\nbased on its inherent reasoning and computational capabilities. By using\nreading comprehension datasets from the ITS, AutoTutor, we evaluate the\npredictive capabilities of GPT-4 versus traditional machine learning methods in\npredicting learning performance through five-fold cross-validation techniques.\nOur findings show that the GPT-4 presents the competitive predictive abilities\nwith traditional machine learning methods such as Bayesian Knowledge Tracing,\nPerformance Factor Analysis, Sparse Factor Analysis Lite (SPARFA-Lite), tensor\nfactorization and eXtreme Gradient Boosting (XGBoost). While XGBoost (trained\non local machine) outperforms GPT-4 in predictive accuracy, GPT-4-selected\nXGBoost and its subsequent tuning on the GPT-4 platform demonstrates superior\nperformance compared to local machine execution. Moreover, our investigation\ninto hyper-parameter tuning by GPT-4 versus grid-search suggests comparable\nperformance, albeit with less stability in the automated approach, using\nXGBoost as the case study. Our study contributes to the field by highlighting\nthe potential of integrating LLMs with traditional machine learning models to\nenhance predictive accuracy and personalize adult literacy education, setting a\nfoundation for future research in applying LLMs within ITSs.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "26TH International Conference on Human-Computer Interaction",
    "pdf_url": "http://arxiv.org/pdf/2403.14668v1",
    "published_date": "2024-03-04 08:14:07 UTC",
    "updated_date": "2024-03-04 08:14:07 UTC"
  },
  {
    "arxiv_id": "2403.02363v1",
    "title": "Addressing Long-Tail Noisy Label Learning Problems: a Two-Stage Solution with Label Refurbishment Considering Label Rarity",
    "authors": [
      "Ying-Hsuan Wu",
      "Jun-Wei Hsieh",
      "Li Xin",
      "Shin-You Teng",
      "Yi-Kuan Hsieh",
      "Ming-Ching Chang"
    ],
    "abstract": "Real-world datasets commonly exhibit noisy labels and class imbalance, such\nas long-tailed distributions. While previous research addresses this issue by\ndifferentiating noisy and clean samples, reliance on information from\npredictions based on noisy long-tailed data introduces potential errors. To\novercome the limitations of prior works, we introduce an effective two-stage\napproach by combining soft-label refurbishing with multi-expert ensemble\nlearning. In the first stage of robust soft label refurbishing, we acquire\nunbiased features through contrastive learning, making preliminary predictions\nusing a classifier trained with a carefully designed BAlanced Noise-tolerant\nCross-entropy (BANC) loss. In the second stage, our label refurbishment method\nis applied to obtain soft labels for multi-expert ensemble learning, providing\na principled solution to the long-tail noisy label problem. Experiments\nconducted across multiple benchmarks validate the superiority of our approach,\nLabel Refurbishment considering Label Rarity (LR^2), achieving remarkable\naccuracies of 94.19% and 77.05% on simulated noisy CIFAR-10 and CIFAR-100\nlong-tail datasets, as well as 77.74% and 81.40% on real-noise long-tail\ndatasets, Food-101N and Animal-10N, surpassing existing state-of-the-art\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02363v1",
    "published_date": "2024-03-04 08:06:57 UTC",
    "updated_date": "2024-03-04 08:06:57 UTC"
  },
  {
    "arxiv_id": "2403.01818v3",
    "title": "AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation",
    "authors": [
      "Haonan Wang",
      "Qixiang Zhang",
      "Yi Li",
      "Xiaomeng Li"
    ],
    "abstract": "Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate\nthe burden of time-consuming pixel-level manual labeling, which leverages\nlimited labeled data along with larger amounts of unlabeled data. Current\nstate-of-the-art methods train the labeled data with ground truths and\nunlabeled data with pseudo labels. However, the two training flows are\nseparate, which allows labeled data to dominate the training process, resulting\nin low-quality pseudo labels and, consequently, sub-optimal results. To\nalleviate this issue, we present AllSpark, which reborns the labeled features\nfrom unlabeled ones with the channel-wise cross-attention mechanism. We further\nintroduce a Semantic Memory along with a Channel Semantic Grouping strategy to\nensure that unlabeled features adequately represent labeled features. The\nAllSpark shed new light on the architecture level designs of SSSS rather than\nframework level, which avoids increasingly complicated training pipeline\ndesigns. It can also be regarded as a flexible bottleneck module that can be\nseamlessly integrated into a general transformer-based segmentation model. The\nproposed AllSpark outperforms existing methods across all evaluation protocols\non Pascal, Cityscapes and COCO benchmarks without bells-and-whistles. Code and\nmodel weights are available at: https://github.com/xmed-lab/AllSpark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2024; correct typos; this is not the camera-ready\n  version",
    "pdf_url": "http://arxiv.org/pdf/2403.01818v3",
    "published_date": "2024-03-04 08:06:41 UTC",
    "updated_date": "2024-03-14 15:39:51 UTC"
  },
  {
    "arxiv_id": "2403.01816v1",
    "title": "SMAUG: A Sliding Multidimensional Task Window-Based MARL Framework for Adaptive Real-Time Subtask Recognition",
    "authors": [
      "Wenjing Zhang",
      "Wei Zhang"
    ],
    "abstract": "Instead of making behavioral decisions directly from the exponentially\nexpanding joint observational-action space, subtask-based multi-agent\nreinforcement learning (MARL) methods enable agents to learn how to tackle\ndifferent subtasks. Most existing subtask-based MARL methods are based on\nhierarchical reinforcement learning (HRL). However, these approaches often\nlimit the number of subtasks, perform subtask recognition periodically, and can\nonly identify and execute a specific subtask within the predefined fixed time\nperiod, which makes them inflexible and not suitable for diverse and dynamic\nscenarios with constantly changing subtasks. To break through above\nrestrictions, a \\textbf{S}liding \\textbf{M}ultidimensional t\\textbf{A}sk window\nbased m\\textbf{U}ti-agent reinforcement learnin\\textbf{G} framework (SMAUG) is\nproposed for adaptive real-time subtask recognition. It leverages a sliding\nmultidimensional task window to extract essential information of subtasks from\ntrajectory segments concatenated based on observed and predicted trajectories\nin varying lengths. An inference network is designed to iteratively predict\nfuture trajectories with the subtask-oriented policy network. Furthermore,\nintrinsic motivation rewards are defined to promote subtask exploration and\nbehavior diversity. SMAUG can be integrated with any Q-learning-based approach.\nExperiments on StarCraft II show that SMAUG not only demonstrates performance\nsuperiority in comparison with all baselines but also presents a more prominent\nand swift rise in rewards during the initial training stage.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01816v1",
    "published_date": "2024-03-04 08:04:41 UTC",
    "updated_date": "2024-03-04 08:04:41 UTC"
  },
  {
    "arxiv_id": "2403.01801v1",
    "title": "COLA: Cross-city Mobility Transformer for Human Trajectory Simulation",
    "authors": [
      "Yu Wang",
      "Tongya Zheng",
      "Yuxuan Liang",
      "Shunyu Liu",
      "Mingli Song"
    ],
    "abstract": "Human trajectory data produced by daily mobile devices has proven its\nusefulness in various substantial fields such as urban planning and epidemic\nprevention. In terms of the individual privacy concern, human trajectory\nsimulation has attracted increasing attention from researchers, targeting at\noffering numerous realistic mobility data for downstream tasks. Nevertheless,\nthe prevalent issue of data scarcity undoubtedly degrades the reliability of\nexisting deep learning models. In this paper, we are motivated to explore the\nintriguing problem of mobility transfer across cities, grasping the universal\npatterns of human trajectories to augment the powerful Transformer with\nexternal mobility data. There are two crucial challenges arising in the\nknowledge transfer across cities: 1) how to transfer the Transformer to adapt\nfor domain heterogeneity; 2) how to calibrate the Transformer to adapt for\nsubtly different long-tail frequency distributions of locations. To address\nthese challenges, we have tailored a Cross-city mObiLity trAnsformer (COLA)\nwith a dedicated model-agnostic transfer framework by effectively transferring\ncross-city knowledge for human trajectory simulation. Firstly, COLA divides the\nTransformer into the private modules for city-specific characteristics and the\nshared modules for city-universal mobility patterns. Secondly, COLA leverages a\nlightweight yet effective post-hoc adjustment strategy for trajectory\nsimulation, without disturbing the complex bi-level optimization of\nmodel-agnostic knowledge transfer. Extensive experiments of COLA compared to\nstate-of-the-art single-city baselines and our implemented cross-city baselines\nhave demonstrated its superiority and effectiveness. The code is available at\nhttps://github.com/Star607/Cross-city-Mobility-Transformer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.01801v1",
    "published_date": "2024-03-04 07:45:29 UTC",
    "updated_date": "2024-03-04 07:45:29 UTC"
  },
  {
    "arxiv_id": "2403.01791v1",
    "title": "Beyond Recommender: An Exploratory Study of the Effects of Different AI Roles in AI-Assisted Decision Making",
    "authors": [
      "Shuai Ma",
      "Chenyi Zhang",
      "Xinru Wang",
      "Xiaojuan Ma",
      "Ming Yin"
    ],
    "abstract": "Artificial Intelligence (AI) is increasingly employed in various\ndecision-making tasks, typically as a Recommender, providing recommendations\nthat the AI deems correct. However, recent studies suggest this may diminish\nhuman analytical thinking and lead to humans' inappropriate reliance on AI,\nimpairing the synergy in human-AI teams. In contrast, human advisors in group\ndecision-making perform various roles, such as analyzing alternative options or\ncriticizing decision-makers to encourage their critical thinking. This\ndiversity of roles has not yet been empirically explored in AI assistance. In\nthis paper, we examine three AI roles: Recommender, Analyzer, and Devil's\nAdvocate, and evaluate their effects across two AI performance levels. Our\nresults show each role's distinct strengths and limitations in task\nperformance, reliance appropriateness, and user experience. Notably, the\nRecommender role is not always the most effective, especially if the AI\nperformance level is low, the Analyzer role may be preferable. These insights\noffer valuable implications for designing AI assistants with adaptive\nfunctional roles according to different situations.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01791v1",
    "published_date": "2024-03-04 07:32:28 UTC",
    "updated_date": "2024-03-04 07:32:28 UTC"
  },
  {
    "arxiv_id": "2403.01784v1",
    "title": "CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text",
    "authors": [
      "Zhenru Lin",
      "Yiqun Yao",
      "Yang Yuan"
    ],
    "abstract": "Large language models (LLMs) such as ChatGPT are increasingly proficient in\nunderstanding and generating a mixture of code and text. Evaluation based on\nsuch $\\textit{mixture}$ can lead to a more comprehensive understanding of the\nmodels' abilities in solving coding problems. However, in this context, current\nevaluation methods are either limited in task coverage or lack standardization.\nTo address this issue, we propose using category theory as a framework for\nevaluation. Specifically, morphisms within a code category can represent code\ndebugging and transformation, functors between two categories represent code\ntranslation, and functors between a code category and a natural language\ncategory represent code generation, explanation, and reproduction. We present\nan automatic evaluation framework called $\\textbf{CatCode}$\n($\\textbf{Cat}$egory $\\textbf{Code}$) that can comprehensively assess the\ncoding abilities of LLMs, including ChatGPT, Text-Davinci, and CodeGeeX.",
    "categories": [
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.01784v1",
    "published_date": "2024-03-04 07:26:07 UTC",
    "updated_date": "2024-03-04 07:26:07 UTC"
  },
  {
    "arxiv_id": "2403.01781v1",
    "title": "Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning",
    "authors": [
      "Tung Le",
      "Khai Nguyen",
      "Shanlin Sun",
      "Nhat Ho",
      "Xiaohui Xie"
    ],
    "abstract": "In the realm of computer vision and graphics, accurately establishing\ncorrespondences between geometric 3D shapes is pivotal for applications like\nobject tracking, registration, texture transfer, and statistical shape\nanalysis. Moving beyond traditional hand-crafted and data-driven feature\nlearning methods, we incorporate spectral methods with deep learning, focusing\non functional maps (FMs) and optimal transport (OT). Traditional OT-based\napproaches, often reliant on entropy regularization OT in learning-based\nframework, face computational challenges due to their quadratic cost. Our key\ncontribution is to employ the sliced Wasserstein distance (SWD) for OT, which\nis a valid fast optimal transport metric in an unsupervised shape matching\nframework. This unsupervised framework integrates functional map regularizers\nwith a novel OT-based loss derived from SWD, enhancing feature alignment\nbetween shapes treated as discrete probability measures. We also introduce an\nadaptive refinement process utilizing entropy regularized OT, further refining\nfeature alignments for accurate point-to-point correspondences. Our method\ndemonstrates superior performance in non-rigid shape matching, including\nnear-isometric and non-isometric scenarios, and excels in downstream tasks like\nsegmentation transfer. The empirical results on diverse datasets highlight our\nframework's effectiveness and generalization capabilities, setting new\nstandards in non-rigid shape matching with efficient OT metrics and an adaptive\nrefinement module.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.01781v1",
    "published_date": "2024-03-04 07:21:07 UTC",
    "updated_date": "2024-03-04 07:21:07 UTC"
  },
  {
    "arxiv_id": "2403.01773v2",
    "title": "Improving out-of-distribution generalization in graphs via hierarchical semantic environments",
    "authors": [
      "Yinhua Piao",
      "Sangseon Lee",
      "Yijingxiu Lu",
      "Sun Kim"
    ],
    "abstract": "Out-of-distribution (OOD) generalization in the graph domain is challenging\ndue to complex distribution shifts and a lack of environmental contexts. Recent\nmethods attempt to enhance graph OOD generalization by generating flat\nenvironments. However, such flat environments come with inherent limitations to\ncapture more complex data distributions. Considering the DrugOOD dataset, which\ncontains diverse training environments (e.g., scaffold, size, etc.), flat\ncontexts cannot sufficiently address its high heterogeneity. Thus, a new\nchallenge is posed to generate more semantically enriched environments to\nenhance graph invariant learning for handling distribution shifts. In this\npaper, we propose a novel approach to generate hierarchical semantic\nenvironments for each graph. Firstly, given an input graph, we explicitly\nextract variant subgraphs from the input graph to generate proxy predictions on\nlocal environments. Then, stochastic attention mechanisms are employed to\nre-extract the subgraphs for regenerating global environments in a hierarchical\nmanner. In addition, we introduce a new learning objective that guides our\nmodel to learn the diversity of environments within the same hierarchy while\nmaintaining consistency across different hierarchies. This approach enables our\nmodel to consider the relationships between environments and facilitates robust\ngraph invariant learning. Extensive experiments on real-world graph data have\ndemonstrated the effectiveness of our framework. Particularly, in the\nchallenging dataset DrugOOD, our method achieves up to 1.29% and 2.83%\nimprovement over the best baselines on IC50 and EC50 prediction tasks,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.01773v2",
    "published_date": "2024-03-04 07:03:10 UTC",
    "updated_date": "2024-06-03 05:05:24 UTC"
  },
  {
    "arxiv_id": "2403.01769v1",
    "title": "A Safe Screening Rule with Bi-level Optimization of $ν$ Support Vector Machine",
    "authors": [
      "Zhiji Yang",
      "Wanyi Chen",
      "Huan Zhang",
      "Yitian Xu",
      "Lei Shi",
      "Jianhua Zhao"
    ],
    "abstract": "Support vector machine (SVM) has achieved many successes in machine learning,\nespecially for a small sample problem. As a famous extension of the traditional\nSVM, the $\\nu$ support vector machine ($\\nu$-SVM) has shown outstanding\nperformance due to its great model interpretability. However, it still faces\nchallenges in training overhead for large-scale problems. To address this\nissue, we propose a safe screening rule with bi-level optimization for\n$\\nu$-SVM (SRBO-$\\nu$-SVM) which can screen out inactive samples before\ntraining and reduce the computational cost without sacrificing the prediction\naccuracy. Our SRBO-$\\nu$-SVM is strictly deduced by integrating the\nKarush-Kuhn-Tucker (KKT) conditions, the variational inequalities of convex\nproblems and the $\\nu$-property. Furthermore, we develop an efficient dual\ncoordinate descent method (DCDM) to further improve computational speed.\nFinally, a unified framework for SRBO is proposed to accelerate many SVM-type\nmodels, and it is successfully applied to one-class SVM. Experimental results\non 6 artificial data sets and 30 benchmark data sets have verified the\neffectiveness and safety of our proposed methods in supervised and unsupervised\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01769v1",
    "published_date": "2024-03-04 06:55:57 UTC",
    "updated_date": "2024-03-04 06:55:57 UTC"
  },
  {
    "arxiv_id": "2403.01768v1",
    "title": "Canonical Form of Datatic Description in Control Systems",
    "authors": [
      "Guojian Zhan",
      "Ziang Zheng",
      "Shengbo Eben Li"
    ],
    "abstract": "The design of feedback controllers is undergoing a paradigm shift from\nmodelic (i.e., model-driven) control to datatic (i.e., data-driven) control.\nCanonical form of state space model is an important concept in modelic control\nsystems, exemplified by Jordan form, controllable form and observable form,\nwhose purpose is to facilitate system analysis and controller synthesis. In the\nrealm of datatic control, there is a notable absence in the standardization of\ndata-based system representation. This paper for the first time introduces the\nconcept of canonical data form for the purpose of achieving more effective\ndesign of datatic controllers. In a control system, the data sample in\ncanonical form consists of a transition component and an attribute component.\nThe former encapsulates the plant dynamics at the sampling time independently,\nwhich is a tuple containing three elements: a state, an action and their\ncorresponding next state. The latter describes one or some artificial\ncharacteristics of the current sample, whose calculation must be performed in\nan online manner. The attribute of each sample must adhere to two requirements:\n(1) causality, ensuring independence from any future samples; and (2) locality,\nallowing dependence on historical samples but constrained to a finite\nneighboring set. The purpose of adding attribute is to offer some kinds of\nbenefits for controller design in terms of effectiveness and efficiency. To\nprovide a more close-up illustration, we present two canonical data forms:\ntemporal form and spatial form, and demonstrate their advantages in reducing\ninstability and enhancing training efficiency in two datatic control systems.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01768v1",
    "published_date": "2024-03-04 06:53:38 UTC",
    "updated_date": "2024-03-04 06:53:38 UTC"
  },
  {
    "arxiv_id": "2403.01757v1",
    "title": "How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems",
    "authors": [
      "Yuxiao Huang",
      "Wenjie Zhang",
      "Liang Feng",
      "Xingyu Wu",
      "Kay Chen Tan"
    ],
    "abstract": "Recently, large language models (LLMs) have notably positioned them as\ncapable tools for addressing complex optimization challenges. Despite this\nrecognition, a predominant limitation of existing LLM-based optimization\nmethods is their struggle to capture the relationships among decision variables\nwhen relying exclusively on numerical text prompts, especially in\nhigh-dimensional problems. Keeping this in mind, we first propose to enhance\nthe optimization performance using multimodal LLM capable of processing both\ntextual and visual prompts for deeper insights of the processed optimization\nproblem. This integration allows for a more comprehensive understanding of\noptimization problems, akin to human cognitive processes. We have developed a\nmultimodal LLM-based optimization framework that simulates human\nproblem-solving workflows, thereby offering a more nuanced and effective\nanalysis. The efficacy of this method is evaluated through extensive empirical\nstudies focused on a well-known combinatorial optimization problem, i.e.,\ncapacitated vehicle routing problem. The results are compared against those\nobtained from the LLM-based optimization algorithms that rely solely on textual\nprompts, demonstrating the significant advantages of our multimodal approach.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NE",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "8pages,3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.01757v1",
    "published_date": "2024-03-04 06:24:21 UTC",
    "updated_date": "2024-03-04 06:24:21 UTC"
  },
  {
    "arxiv_id": "2403.01748v3",
    "title": "NeuSpeech: Decode Neural signal as Speech",
    "authors": [
      "Yiqian Yang",
      "Yiqun Duan",
      "Qiang Zhang",
      "Hyejeong Jo",
      "Jinni Zhou",
      "Won Hee Lee",
      "Renjing Xu",
      "Hui Xiong"
    ],
    "abstract": "Decoding language from brain dynamics is an important open direction in the\nrealm of brain-computer interface (BCI), especially considering the rapid\ngrowth of large language models. Compared to invasive-based signals which\nrequire electrode implantation surgery, non-invasive neural signals (e.g. EEG,\nMEG) have attracted increasing attention considering their safety and\ngenerality. However, the exploration is not adequate in three aspects: 1)\nprevious methods mainly focus on EEG but none of the previous works address\nthis problem on MEG with better signal quality; 2) prior works have\npredominantly used $``teacher-forcing\"$ during generative decoding, which is\nimpractical; 3) prior works are mostly $``BART-based\"$ not fully\nauto-regressive, which performs better in other sequence tasks. In this paper,\nwe explore the brain-to-text translation of MEG signals in a speech-decoding\nformation. Here we are the first to investigate a cross-attention-based\n``whisper\" model for generating text directly from MEG signals without teacher\nforcing. Our model achieves impressive BLEU-1 scores of 60.30 and 52.89 without\npretraining $\\&$ teacher-forcing on two major datasets ($\\textit{GWilliams}$\nand $\\textit{Schoffelen}$). This paper conducts a comprehensive review to\nunderstand how speech decoding formation performs on the neural decoding tasks,\nincluding pretraining initialization, training $\\&$ evaluation set splitting,\naugmentation, and scaling law. Code is available at\nhttps://github.com/NeuSpeech/NeuSpeech1$.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01748v3",
    "published_date": "2024-03-04 05:55:01 UTC",
    "updated_date": "2024-06-03 16:58:04 UTC"
  },
  {
    "arxiv_id": "2403.01742v3",
    "title": "Diffusion-TS: Interpretable Diffusion for General Time Series Generation",
    "authors": [
      "Xinyu Yuan",
      "Yan Qiao"
    ],
    "abstract": "Denoising diffusion probabilistic models (DDPMs) are becoming the leading\nparadigm for generative models. It has recently shown breakthroughs in audio\nsynthesis, time series imputation and forecasting. In this paper, we propose\nDiffusion-TS, a novel diffusion-based framework that generates multivariate\ntime series samples of high quality by using an encoder-decoder transformer\nwith disentangled temporal representations, in which the decomposition\ntechnique guides Diffusion-TS to capture the semantic meaning of time series\nwhile transformers mine detailed sequential information from the noisy model\ninput. Different from existing diffusion-based approaches, we train the model\nto directly reconstruct the sample instead of the noise in each diffusion step,\ncombining a Fourier-based loss term. Diffusion-TS is expected to generate time\nseries satisfying both interpretablity and realness. In addition, it is shown\nthat the proposed Diffusion-TS can be easily extended to conditional generation\ntasks, such as forecasting and imputation, without any model changes. This also\nmotivates us to further explore the performance of Diffusion-TS under irregular\nsettings. Finally, through qualitative and quantitative experiments, results\nshow that Diffusion-TS achieves the state-of-the-art results on various\nrealistic analyses of time series.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01742v3",
    "published_date": "2024-03-04 05:39:23 UTC",
    "updated_date": "2024-10-21 04:38:08 UTC"
  },
  {
    "arxiv_id": "2403.01734v1",
    "title": "Offline Goal-Conditioned Reinforcement Learning for Safety-Critical Tasks with Recovery Policy",
    "authors": [
      "Chenyang Cao",
      "Zichen Yan",
      "Renhao Lu",
      "Junbo Tan",
      "Xueqian Wang"
    ],
    "abstract": "Offline goal-conditioned reinforcement learning (GCRL) aims at solving\ngoal-reaching tasks with sparse rewards from an offline dataset. While prior\nwork has demonstrated various approaches for agents to learn near-optimal\npolicies, these methods encounter limitations when dealing with diverse\nconstraints in complex environments, such as safety constraints. Some of these\napproaches prioritize goal attainment without considering safety, while others\nexcessively focus on safety at the expense of training efficiency. In this\npaper, we study the problem of constrained offline GCRL and propose a new\nmethod called Recovery-based Supervised Learning (RbSL) to accomplish\nsafety-critical tasks with various goals. To evaluate the method performance,\nwe build a benchmark based on the robot-fetching environment with a randomly\npositioned obstacle and use expert or random policies to generate an offline\ndataset. We compare RbSL with three offline GCRL algorithms and one offline\nsafe RL algorithm. As a result, our method outperforms the existing\nstate-of-the-art methods to a large extent. Furthermore, we validate the\npracticality and effectiveness of RbSL by deploying it on a real Panda\nmanipulator. Code is available at https://github.com/Sunlighted/RbSL.git.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "68T40"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by ICRA24",
    "pdf_url": "http://arxiv.org/pdf/2403.01734v1",
    "published_date": "2024-03-04 05:20:57 UTC",
    "updated_date": "2024-03-04 05:20:57 UTC"
  },
  {
    "arxiv_id": "2403.02360v1",
    "title": "Towards Optimal Customized Architecture for Heterogeneous Federated Learning with Contrastive Cloud-Edge Model Decoupling",
    "authors": [
      "Xingyan Chen",
      "Tian Du",
      "Mu Wang",
      "Tiancheng Gu",
      "Yu Zhao",
      "Gang Kou",
      "Changqiao Xu",
      "Dapeng Oliver Wu"
    ],
    "abstract": "Federated learning, as a promising distributed learning paradigm, enables\ncollaborative training of a global model across multiple network edge clients\nwithout the need for central data collecting. However, the heterogeneity of\nedge data distribution drags the model towards the local minima, which can be\ndistant from the global optimum. Such heterogeneity often leads to slow\nconvergence and substantial communication overhead. To address these issues, we\npropose a novel federated learning framework called FedCMD, a model decoupling\ntailored to the Cloud-edge supported federated learning that separates deep\nneural networks into a body for capturing shared representations in Cloud and a\npersonalized head for migrating data heterogeneity. Our motivation is that, by\nthe deep investigation of the performance of selecting different neural network\nlayers as the personalized head, we found rigidly assigning the last layer as\nthe personalized head in current studies is not always optimal. Instead, it is\nnecessary to dynamically select the personalized layer that maximizes the\ntraining performance by taking the representation difference between neighbor\nlayers into account. To find the optimal personalized layer, we utilize the\nlow-dimensional representation of each layer to contrast feature distribution\ntransfer and introduce a Wasserstein-based layer selection method, aimed at\nidentifying the best-match layer for personalization. Additionally, a weighted\nglobal aggregation algorithm is proposed based on the selected personalized\nlayer for the practical application of FedCMD. Extensive experiments on ten\nbenchmarks demonstrate the efficiency and superior performance of our solution\ncompared with nine state-of-the-art solutions. All code and results are\navailable at https://github.com/elegy112138/FedCMD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02360v1",
    "published_date": "2024-03-04 05:10:28 UTC",
    "updated_date": "2024-03-04 05:10:28 UTC"
  },
  {
    "arxiv_id": "2403.01709v1",
    "title": "Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study",
    "authors": [
      "Rudra Dhar",
      "Karthik Vaidhyanathan",
      "Vasudeva Varma"
    ],
    "abstract": "Architectural Knowledge Management (AKM) involves the organized handling of\ninformation related to architectural decisions and design within a project or\norganization. An essential artifact of AKM is the Architecture Decision Records\n(ADR), which documents key design decisions. ADRs are documents that capture\ndecision context, decision made and various aspects related to a design\ndecision, thereby promoting transparency, collaboration, and understanding.\nDespite their benefits, ADR adoption in software development has been slow due\nto challenges like time constraints and inconsistent uptake. Recent\nadvancements in Large Language Models (LLMs) may help bridge this adoption gap\nby facilitating ADR generation. However, the effectiveness of LLM for ADR\ngeneration or understanding is something that has not been explored. To this\nend, in this work, we perform an exploratory study that aims to investigate the\nfeasibility of using LLM for the generation of ADRs given the decision context.\nIn our exploratory study, we utilize GPT and T5-based models with 0-shot,\nfew-shot, and fine-tuning approaches to generate the Decision of an ADR given\nits Context. Our results indicate that in a 0-shot setting, state-of-the-art\nmodels such as GPT-4 generate relevant and accurate Design Decisions, although\nthey fall short of human-level performance. Additionally, we observe that more\ncost-effective models like GPT-3.5 can achieve similar outcomes in a few-shot\nsetting, and smaller models such as Flan-T5 can yield comparable results after\nfine-tuning. To conclude, this exploratory study suggests that LLM can generate\nDesign Decisions, but further research is required to attain human-level\ngeneration and establish standardized widespread adoption.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper has been accepted to IEEE ICSA 2024 (Main Track - Research\n  Track)",
    "pdf_url": "http://arxiv.org/pdf/2403.01709v1",
    "published_date": "2024-03-04 03:56:14 UTC",
    "updated_date": "2024-03-04 03:56:14 UTC"
  },
  {
    "arxiv_id": "2403.07932v1",
    "title": "Feint in Multi-Player Games",
    "authors": [
      "Junyu Liu",
      "Wangkai Jin",
      "Xiangjun Peng"
    ],
    "abstract": "This paper introduces the first formalization, implementation and\nquantitative evaluation of Feint in Multi-Player Games. Our work first\nformalizes Feint from the perspective of Multi-Player Games, in terms of the\ntemporal, spatial, and their collective impacts. The formalization is built\nupon Non-transitive Active Markov Game Model, where Feint can have a\nconsiderable amount of impacts. Then, our work considers practical\nimplementation details of Feint in Multi-Player Games, under the\nstate-of-the-art progress of multi-agent modeling to date (namely Multi-Agent\nReinforcement Learning). Finally, our work quantitatively examines the\neffectiveness of our design, and the results show that our design of Feint can\n(1) greatly improve the reward gains from the game; (2) significantly improve\nthe diversity of Multi-Player Games; and (3) only incur negligible overheads in\nterms of time consumption. We conclude that our design of Feint is effective\nand practical, to make Multi-Player Games more interesting.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07932v1",
    "published_date": "2024-03-04 03:43:45 UTC",
    "updated_date": "2024-03-04 03:43:45 UTC"
  },
  {
    "arxiv_id": "2403.01699v3",
    "title": "Brilla AI: AI Contestant for the National Science and Maths Quiz",
    "authors": [
      "George Boateng",
      "Jonathan Abrefah Mensah",
      "Kevin Takyi Yeboah",
      "William Edor",
      "Andrew Kojo Mensah-Onumah",
      "Naafi Dasana Ibrahim",
      "Nana Sam Yeboah"
    ],
    "abstract": "The African continent lacks enough qualified teachers which hampers the\nprovision of adequate learning support. An AI could potentially augment the\nefforts of the limited number of teachers, leading to better learning outcomes.\nTowards that end, this work describes and evaluates the first key output for\nthe NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for\nsuch an AI: \"Build an AI to compete live in Ghana's National Science and Maths\nQuiz (NSMQ) competition and win - performing better than the best contestants\nin all rounds and stages of the competition\". The NSMQ is an annual live\nscience and mathematics competition for senior secondary school students in\nGhana in which 3 teams of 2 students compete by answering questions across\nbiology, chemistry, physics, and math in 5 rounds over 5 progressive stages\nuntil a winning team is crowned for that year. In this work, we built Brilla\nAI, an AI contestant that we deployed to unofficially compete remotely and live\nin the Riddles round of the 2023 NSMQ Grand Finale, the first of its kind in\nthe 30-year history of the competition. Brilla AI is currently available as a\nweb app that livestreams the Riddles round of the contest, and runs 4 machine\nlearning systems: (1) speech to text (2) question extraction (3) question\nanswering and (4) text to speech that work together in real-time to quickly and\naccurately provide an answer, and then say it with a Ghanaian accent. In its\ndebut, our AI answered one of the 4 riddles ahead of the 3 human contesting\nteams, unofficially placing second (tied). Improvements and extensions of this\nAI could potentially be deployed to offer science tutoring to students and\neventually enable millions across Africa to have one-on-one learning\ninteractions, democratizing science education.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages. Accepted for the WideAIED track at the 25th International\n  Conference on AI in Education (AIED 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.01699v3",
    "published_date": "2024-03-04 03:24:18 UTC",
    "updated_date": "2024-04-30 19:22:36 UTC"
  },
  {
    "arxiv_id": "2403.01698v1",
    "title": "Hypertext Entity Extraction in Webpage",
    "authors": [
      "Yifei Yang",
      "Tianqiao Liu",
      "Bo Shao",
      "Hai Zhao",
      "Linjun Shou",
      "Ming Gong",
      "Daxin Jiang"
    ],
    "abstract": "Webpage entity extraction is a fundamental natural language processing task\nin both research and applications. Nowadays, the majority of webpage entity\nextraction models are trained on structured datasets which strive to retain\ntextual content and its structure information. However, existing datasets all\noverlook the rich hypertext features (e.g., font color, font size) which show\ntheir effectiveness in previous works. To this end, we first collect a\n\\textbf{H}ypertext \\textbf{E}ntity \\textbf{E}xtraction \\textbf{D}ataset\n(\\textit{HEED}) from the e-commerce domains, scraping both the text and the\ncorresponding explicit hypertext features with high-quality manual entity\nannotations. Furthermore, we present the \\textbf{Mo}E-based \\textbf{E}ntity\n\\textbf{E}xtraction \\textbf{F}ramework (\\textit{MoEEF}), which efficiently\nintegrates multiple features to enhance model performance by Mixture of Experts\nand outperforms strong baselines, including the state-of-the-art small-scale\nmodels and GPT-3.5-turbo. Moreover, the effectiveness of hypertext features in\n\\textit{HEED} and several model components in \\textit{MoEEF} are analyzed.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01698v1",
    "published_date": "2024-03-04 03:21:40 UTC",
    "updated_date": "2024-03-04 03:21:40 UTC"
  },
  {
    "arxiv_id": "2403.01695v3",
    "title": "DyCE: Dynamically Configurable Exiting for Deep Learning Compression and Real-time Scaling",
    "authors": [
      "Qingyuan Wang",
      "Barry Cardiff",
      "Antoine Frappé",
      "Benoit Larras",
      "Deepu John"
    ],
    "abstract": "Conventional deep learning (DL) model compression and scaling methods focus\non altering the model's components, impacting the results across all samples\nuniformly. However, since samples vary in difficulty, a dynamic model that\nadapts computation based on sample complexity offers a novel perspective for\ncompression and scaling. Despite this potential, existing dynamic models are\ntypically monolithic and model-specific, limiting their generalizability as\nbroad compression and scaling methods. Additionally, most deployed DL systems\nare fixed, unable to adjust their scale once deployed and, therefore, cannot\nadapt to the varying real-time demands. This paper introduces DyCE, a\ndynamically configurable system that can adjust the performance-complexity\ntrade-off of a DL model at runtime without requiring re-initialization or\nredeployment on inference hardware. DyCE achieves this by adding small exit\nnetworks to intermediate layers of the original model, allowing computation to\nterminate early if acceptable results are obtained. DyCE also decouples the\ndesign of an efficient dynamic model, facilitating easy adaptation to new base\nmodels and potential general use in compression and scaling. We also propose\nmethods for generating optimized configurations and determining the types and\npositions of exit networks to achieve desired performance and complexity\ntrade-offs. By enabling simple configuration switching, DyCE provides\nfine-grained performance tuning in real-time. We demonstrate the effectiveness\nof DyCE through image classification tasks using deep convolutional neural\nnetworks (CNNs). DyCE significantly reduces computational complexity by 23.5%\nfor ResNet152 and 25.9% for ConvNextv2-tiny on ImageNet, with accuracy\nreductions of less than 0.5%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01695v3",
    "published_date": "2024-03-04 03:09:28 UTC",
    "updated_date": "2025-05-07 23:56:40 UTC"
  },
  {
    "arxiv_id": "2403.01693v3",
    "title": "HanDiffuser: Text-to-Image Generation With Realistic Hand Appearances",
    "authors": [
      "Supreeth Narasimhaswamy",
      "Uttaran Bhattacharya",
      "Xiang Chen",
      "Ishita Dasgupta",
      "Saayan Mitra",
      "Minh Hoai"
    ],
    "abstract": "Text-to-image generative models can generate high-quality humans, but realism\nis lost when generating hands. Common artifacts include irregular hand poses,\nshapes, incorrect numbers of fingers, and physically implausible finger\norientations. To generate images with realistic hands, we propose a novel\ndiffusion-based architecture called HanDiffuser that achieves realism by\ninjecting hand embeddings in the generative process. HanDiffuser consists of\ntwo components: a Text-to-Hand-Params diffusion model to generate SMPL-Body and\nMANO-Hand parameters from input text prompts, and a Text-Guided\nHand-Params-to-Image diffusion model to synthesize images by conditioning on\nthe prompts and hand parameters generated by the previous component. We\nincorporate multiple aspects of hand representation, including 3D shapes and\njoint-level finger positions, orientations and articulations, for robust\nlearning and reliable performance during inference. We conduct extensive\nquantitative and qualitative experiments and perform user studies to\ndemonstrate the efficacy of our method in generating images with high-quality\nhands.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Revisions: 1. Added a link to project page in the abstract, 2.\n  Updated references and related work, 3. Fixed some grammatical errors",
    "pdf_url": "http://arxiv.org/pdf/2403.01693v3",
    "published_date": "2024-03-04 03:00:22 UTC",
    "updated_date": "2024-11-22 22:42:46 UTC"
  },
  {
    "arxiv_id": "2403.01673v1",
    "title": "CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables",
    "authors": [
      "Jiecheng Lu",
      "Xu Han",
      "Yan Sun",
      "Shihao Yang"
    ],
    "abstract": "For Multivariate Time Series Forecasting (MTSF), recent deep learning\napplications show that univariate models frequently outperform multivariate\nones. To address the difficiency in multivariate models, we introduce a method\nto Construct Auxiliary Time Series (CATS) that functions like a 2D\ntemporal-contextual attention mechanism, which generates Auxiliary Time Series\n(ATS) from Original Time Series (OTS) to effectively represent and incorporate\ninter-series relationships for forecasting. Key principles of ATS - continuity,\nsparsity, and variability - are identified and implemented through different\nmodules. Even with a basic 2-layer MLP as core predictor, CATS achieves\nstate-of-the-art, significantly reducing complexity and parameters compared to\nprevious multivariate models, marking it an efficient and transferable MTSF\nsolution.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01673v1",
    "published_date": "2024-03-04 01:52:40 UTC",
    "updated_date": "2024-03-04 01:52:40 UTC"
  },
  {
    "arxiv_id": "2403.01649v1",
    "title": "Recommendations for Government Development and Use of Advanced Automated Systems to Make Decisions about Individuals",
    "authors": [
      "Susan Landau",
      "James X. Dempsey",
      "Ece Kamar",
      "Steven M. Bellovin"
    ],
    "abstract": "Contestability -- the ability to effectively challenge a decision -- is\ncritical to the implementation of fairness. In the context of governmental\ndecision making about individuals, contestability is often constitutionally\nrequired as an element of due process; specific procedures may be required by\nstate or federal law relevant to a particular program. In addition,\ncontestability can be a valuable way to discover systemic errors, contributing\nto ongoing assessments and system improvement.\n  On January 24-25, 2024, with support from the National Science Foundation and\nthe William and Flora Hewlett Foundation, we convened a diverse group of\ngovernment officials, representatives of leading technology companies,\ntechnology and policy experts from academia and the non-profit sector,\nadvocates, and stakeholders for a workshop on advanced automated decision\nmaking, contestability, and the law. Informed by the workshop's rich and\nwide-ranging discussion, we offer these recommendations. A full report\nsummarizing the discussion is in preparation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4; K.5; I.2"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01649v1",
    "published_date": "2024-03-04 00:03:00 UTC",
    "updated_date": "2024-03-04 00:03:00 UTC"
  }
]