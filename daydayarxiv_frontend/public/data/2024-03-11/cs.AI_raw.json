[
  {
    "arxiv_id": "2403.07949v1",
    "title": "Algorithmic Bayesian Epistemology",
    "authors": [
      "Eric Neyman"
    ],
    "abstract": "One aspect of the algorithmic lens in theoretical computer science is a view\non other scientific disciplines that focuses on satisfactory solutions that\nadhere to real-world constraints, as opposed to solutions that would be optimal\nignoring such constraints. The algorithmic lens has provided a unique and\nimportant perspective on many academic fields, including molecular biology,\necology, neuroscience, quantum physics, economics, and social science.\n  This thesis applies the algorithmic lens to Bayesian epistemology.\nTraditional Bayesian epistemology provides a comprehensive framework for how an\nindividual's beliefs should evolve upon receiving new information. However,\nthese methods typically assume an exhaustive model of such information,\nincluding the correlation structure between different pieces of evidence. In\nreality, individuals might lack such an exhaustive model, while still needing\nto form beliefs. Beyond such informational constraints, an individual may be\nbounded by limited computation, or by limited communication with agents that\nhave access to information, or by the strategic behavior of such agents. Even\nwhen these restrictions prevent the formation of a *perfectly* accurate belief,\narriving at a *reasonably* accurate belief remains crucial. In this thesis, we\nestablish fundamental possibility and impossibility results about belief\nformation under a variety of restrictions, and lay the groundwork for further\nexploration.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "385 pages, PhD thesis, 14 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.07949v1",
    "published_date": "2024-03-11 23:03:04 UTC",
    "updated_date": "2024-03-11 23:03:04 UTC"
  },
  {
    "arxiv_id": "2403.07201v1",
    "title": "A multi-cohort study on prediction of acute brain dysfunction states using selective state space models",
    "authors": [
      "Brandon Silva",
      "Miguel Contreras",
      "Sabyasachi Bandyopadhyay",
      "Yuanfang Ren",
      "Ziyuan Guan",
      "Jeremy Balch",
      "Kia Khezeli",
      "Tezcan Ozrazgat Baslanti",
      "Ben Shickel",
      "Azra Bihorac",
      "Parisa Rashidi"
    ],
    "abstract": "Assessing acute brain dysfunction (ABD), including delirium and coma in the\nintensive care unit (ICU), is a critical challenge due to its prevalence and\nsevere implications for patient outcomes. Current diagnostic methods rely on\ninfrequent clinical observations, which can only determine a patient's ABD\nstatus after onset. Our research attempts to solve these problems by harnessing\nElectronic Health Records (EHR) data to develop automated methods for ABD\nprediction for patients in the ICU. Existing models solely predict a single\nstate (e.g., either delirium or coma), require at least 24 hours of observation\ndata to make predictions, do not dynamically predict fluctuating ABD conditions\nduring ICU stay (typically a one-time prediction), and use small sample size,\nproprietary single-hospital datasets. Our research fills these gaps in the\nexisting literature by dynamically predicting delirium, coma, and mortality for\n12-hour intervals throughout an ICU stay and validating on two public datasets.\nOur research also introduces the concept of dynamically predicting critical\ntransitions from non-ABD to ABD and between different ABD states in real time,\nwhich could be clinically more informative for the hospital staff. We compared\nthe predictive performance of two state-of-the-art neural network models, the\nMAMBA selective state space model and the Longformer Transformer model. Using\nthe MAMBA model, we achieved a mean area under the receiving operator\ncharacteristic curve (AUROC) of 0.95 on outcome prediction of ABD for 12-hour\nintervals. The model achieves a mean AUROC of 0.79 when predicting transitions\nbetween ABD states. Our study uses a curated dataset from the University of\nFlorida Health Shands Hospital for internal validation and two publicly\navailable datasets, MIMIC-IV and eICU, for external validation, demonstrating\nrobustness across ICU stays from 203 hospitals and 140,945 patients.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 8 figures, To be published",
    "pdf_url": "http://arxiv.org/pdf/2403.07201v1",
    "published_date": "2024-03-11 22:58:11 UTC",
    "updated_date": "2024-03-11 22:58:11 UTC"
  },
  {
    "arxiv_id": "2403.07193v1",
    "title": "CuentosIE: can a chatbot about \"tales with a message\" help to teach emotional intelligence?",
    "authors": [
      "Antonio Ferrández",
      "Rocío Lavigne-Cerván",
      "Jesús Peral",
      "Ignasi Navarro-Soria",
      "Ángel Lloret",
      "David Gil",
      "Carmen Rocamora"
    ],
    "abstract": "In this article, we present CuentosIE (TalesEI: chatbot of tales with a\nmessage to develop Emotional Intelligence), an educational chatbot on emotions\nthat also provides teachers and psychologists with a tool to monitor their\nstudents/patients through indicators and data compiled by CuentosIE. The use of\n\"tales with a message\" is justified by their simplicity and easy understanding,\nthanks to their moral or associated metaphors. The main contributions of\nCuentosIE are the selection, collection, and classification of a set of highly\nspecialized tales, as well as the provision of tools (searching, reading\ncomprehension, chatting, recommending, and classifying) that are useful for\nboth educating users about emotions and monitoring their emotional development.\nThe preliminary evaluation of the tool has obtained encouraging results, which\nprovides an affirmative answer to the question posed in the title of the\narticle.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.07193v1",
    "published_date": "2024-03-11 22:27:16 UTC",
    "updated_date": "2024-03-11 22:27:16 UTC"
  },
  {
    "arxiv_id": "2403.07191v1",
    "title": "$\\mathbf{(N,K)}$-Puzzle: A Cost-Efficient Testbed for Benchmarking Reinforcement Learning Algorithms in Generative Language Model",
    "authors": [
      "Yufeng Zhang",
      "Liyu Chen",
      "Boyi Liu",
      "Yingxiang Yang",
      "Qiwen Cui",
      "Yunzhe Tao",
      "Hongxia Yang"
    ],
    "abstract": "Recent advances in reinforcement learning (RL) algorithms aim to enhance the\nperformance of language models at scale. Yet, there is a noticeable absence of\na cost-effective and standardized testbed tailored to evaluating and comparing\nthese algorithms. To bridge this gap, we present a generalized version of the\n24-Puzzle: the $(N,K)$-Puzzle, which challenges language models to reach a\ntarget value $K$ with $N$ integers. We evaluate the effectiveness of\nestablished RL algorithms such as Proximal Policy Optimization (PPO), alongside\nnovel approaches like Identity Policy Optimization (IPO) and Direct Policy\nOptimization (DPO).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.07191v1",
    "published_date": "2024-03-11 22:24:14 UTC",
    "updated_date": "2024-03-11 22:24:14 UTC"
  },
  {
    "arxiv_id": "2403.07183v2",
    "title": "Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews",
    "authors": [
      "Weixin Liang",
      "Zachary Izzo",
      "Yaohui Zhang",
      "Haley Lepp",
      "Hancheng Cao",
      "Xuandong Zhao",
      "Lingjiao Chen",
      "Haotian Ye",
      "Sheng Liu",
      "Zhi Huang",
      "Daniel A. McFarland",
      "James Y. Zou"
    ],
    "abstract": "We present an approach for estimating the fraction of text in a large corpus\nwhich is likely to be substantially modified or produced by a large language\nmodel (LLM). Our maximum likelihood model leverages expert-written and\nAI-generated reference texts to accurately and efficiently examine real-world\nLLM-use at the corpus level. We apply this approach to a case study of\nscientific peer review in AI conferences that took place after the release of\nChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023. Our results suggest\nthat between 6.5% and 16.9% of text submitted as peer reviews to these\nconferences could have been substantially modified by LLMs, i.e. beyond\nspell-checking or minor writing updates. The circumstances in which generated\ntext occurs offer insight into user behavior: the estimated fraction of\nLLM-generated text is higher in reviews which report lower confidence, were\nsubmitted close to the deadline, and from reviewers who are less likely to\nrespond to author rebuttals. We also observe corpus-level trends in generated\ntext which may be too subtle to detect at the individual level, and discuss the\nimplications of such trends on peer review. We call for future\ninterdisciplinary work to examine how LLM use is changing our information and\nknowledge practices.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "46 pages, 31 figures, ICML '24",
    "pdf_url": "http://arxiv.org/pdf/2403.07183v2",
    "published_date": "2024-03-11 21:51:39 UTC",
    "updated_date": "2024-06-15 05:23:06 UTC"
  },
  {
    "arxiv_id": "2403.07175v3",
    "title": "Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing",
    "authors": [
      "Akshat Gupta",
      "Sidharth Baskaran",
      "Gopala Anumanchipalli"
    ],
    "abstract": "Recent work using Rank-One Model Editing (ROME), a popular model editing\nmethod, has shown that there are certain facts that the algorithm is unable to\nedit without breaking the model. Such edits have previously been called\ndisabling edits. These disabling edits cause immediate model collapse and\nlimits the use of ROME for sequential editing. In this paper, we show that\ndisabling edits are an artifact of irregularities in the implementation of\nROME. With this paper, we provide a more stable implementation ROME, which we\ncall r-ROME and show that model collapse is no longer observed when making\nlarge scale sequential edits with r-ROME, while further improving\ngeneralization and locality of model editing compared to the original\nimplementation of ROME. We also provide a detailed mathematical explanation of\nthe reason behind disabling edits.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 (Main)",
    "pdf_url": "http://arxiv.org/pdf/2403.07175v3",
    "published_date": "2024-03-11 21:33:05 UTC",
    "updated_date": "2024-10-09 03:41:43 UTC"
  },
  {
    "arxiv_id": "2403.07151v1",
    "title": "Don't Forget What I did?: Assessing Client Contributions in Federated Learning",
    "authors": [
      "Bishwamittra Ghosh",
      "Debabrota Basu",
      "Fu Huazhu",
      "Wang Yuan",
      "Renuga Kanagavelu",
      "Jiang Jin Peng",
      "Liu Yong",
      "Goh Siow Mong Rick",
      "Wei Qingsong"
    ],
    "abstract": "Federated Learning (FL) is a collaborative machine learning (ML) approach,\nwhere multiple clients participate in training an ML model without exposing the\nprivate data. Fair and accurate assessment of client contributions is an\nimportant problem in FL to facilitate incentive allocation and encouraging\ndiverse clients to participate in a unified model training. Existing methods\nfor assessing client contribution adopts co-operative game-theoretic concepts,\nsuch as Shapley values, but under simplified assumptions. In this paper, we\npropose a history-aware game-theoretic framework, called FLContrib, to assess\nclient contributions when a subset of (potentially non-i.i.d.) clients\nparticipate in each epoch of FL training. By exploiting the FL training process\nand linearity of Shapley value, we develop FLContrib that yields a historical\ntimeline of client contributions as FL training progresses over epochs.\nAdditionally, to assess client contribution under limited computational budget,\nwe propose a scheduling procedure that considers a two-sided fairness criteria\nto perform expensive Shapley value computation only in a subset of training\nepochs. In experiments, we demonstrate a controlled trade-off between the\ncorrectness and efficiency of client contributions assessed via FLContrib. To\ndemonstrate the benefits of history-aware client contributions, we apply\nFLContrib to detect dishonest clients conducting data poisoning in FL training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Under submission",
    "pdf_url": "http://arxiv.org/pdf/2403.07151v1",
    "published_date": "2024-03-11 20:39:32 UTC",
    "updated_date": "2024-03-11 20:39:32 UTC"
  },
  {
    "arxiv_id": "2403.07136v1",
    "title": "On the Limited Representational Power of Value Functions and its Links to Statistical (In)Efficiency",
    "authors": [
      "David Cheikhi",
      "Daniel Russo"
    ],
    "abstract": "Identifying the trade-offs between model-based and model-free methods is a\ncentral question in reinforcement learning. Value-based methods offer\nsubstantial computational advantages and are sometimes just as statistically\nefficient as model-based methods. However, focusing on the core problem of\npolicy evaluation, we show information about the transition dynamics may be\nimpossible to represent in the space of value functions. We explore this\nthrough a series of case studies focused on structures that arises in many\nimportant problems. In several, there is no information loss and value-based\nmethods are as statistically efficient as model based ones. In other\nclosely-related examples, information loss is severe and value-based methods\nare severely outperformed. A deeper investigation points to the limitations of\nthe representational power as the driver of the inefficiency, as opposed to\nfailure in algorithm design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07136v1",
    "published_date": "2024-03-11 20:05:48 UTC",
    "updated_date": "2024-03-11 20:05:48 UTC"
  },
  {
    "arxiv_id": "2403.07131v1",
    "title": "Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot Task Allocation",
    "authors": [
      "Steve Paul",
      "Nathan Maurer",
      "Souma Chowdhury"
    ],
    "abstract": "Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07131v1",
    "published_date": "2024-03-11 19:55:08 UTC",
    "updated_date": "2024-03-11 19:55:08 UTC"
  },
  {
    "arxiv_id": "2403.07090v1",
    "title": "Time Series Analysis of Key Societal Events as Reflected in Complex Social Media Data Streams",
    "authors": [
      "Andy Skumanich",
      "Han Kyul Kim"
    ],
    "abstract": "Social media platforms hold valuable insights, yet extracting essential\ninformation can be challenging. Traditional top-down approaches often struggle\nto capture critical signals in rapidly changing events. As global events evolve\nswiftly, social media narratives, including instances of disinformation, become\nsignificant sources of insights. To address the need for an inductive strategy,\nwe explore a niche social media platform GAB and an established messaging\nservice Telegram, to develop methodologies applicable on a broader scale. This\nstudy investigates narrative evolution on these platforms using quantitative\ncorpus-based discourse analysis techniques. Our approach is a novel mode to\nstudy multiple social media domains to distil key information which may be\nobscured otherwise, allowing for useful and actionable insights. The paper\ndetails the technical and methodological aspects of gathering and preprocessing\nGAB and Telegram data for a keyness (Log Ratio) metric analysis, identifying\ncrucial nouns and verbs for deeper exploration. Empirically, this approach is\napplied to a case study of a well defined event that had global impact: the\n2023 Wagner mutiny. The main findings are: (1) the time line can be\ndeconstructed to provide useful data features allowing for improved\ninterpretation; (2) a methodology is applied which provides a basis for\ngeneralization. The key contribution is an approach, that in some cases,\nprovides the ability to capture the dynamic narrative shifts over time with\nelevated confidence. The approach can augment near-real-time assessment of key\nsocial movements, allowing for informed governance choices. This research is\nimportant because it lays out a useful methodology for time series relevant\ninfo-culling, which can enable proactive modes for positive social engagement.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "AAAI2024 Workshop on AI for Time Series Analysis (AI4TS)",
    "pdf_url": "http://arxiv.org/pdf/2403.07090v1",
    "published_date": "2024-03-11 18:33:56 UTC",
    "updated_date": "2024-03-11 18:33:56 UTC"
  },
  {
    "arxiv_id": "2403.07087v1",
    "title": "LSTM-Based Text Generation: A Study on Historical Datasets",
    "authors": [
      "Mustafa Abbas Hussein Hussein",
      "Serkan Savaş"
    ],
    "abstract": "This paper presents an exploration of Long Short-Term Memory (LSTM) networks\nin the realm of text generation, focusing on the utilization of historical\ndatasets for Shakespeare and Nietzsche. LSTMs, known for their effectiveness in\nhandling sequential data, are applied here to model complex language patterns\nand structures inherent in historical texts. The study demonstrates that\nLSTM-based models, when trained on historical datasets, can not only generate\ntext that is linguistically rich and contextually relevant but also provide\ninsights into the evolution of language patterns over time. The finding\npresents models that are highly accurate and efficient in predicting text from\nworks of Nietzsche, with low loss values and a training time of 100 iterations.\nThe accuracy of the model is 0.9521, indicating high accuracy. The loss of the\nmodel is 0.2518, indicating its effectiveness. The accuracy of the model in\npredicting text from the work of Shakespeare is 0.9125, indicating a low error\nrate. The training time of the model is 100, mirroring the efficiency of the\nNietzsche dataset. This efficiency demonstrates the effectiveness of the model\ndesign and training methodology, especially when handling complex literary\ntexts. This research contributes to the field of natural language processing by\nshowcasing the versatility of LSTM networks in text generation and offering a\npathway for future explorations in historical linguistics and beyond.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07087v1",
    "published_date": "2024-03-11 18:25:01 UTC",
    "updated_date": "2024-03-11 18:25:01 UTC"
  },
  {
    "arxiv_id": "2403.07078v1",
    "title": "Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning",
    "authors": [
      "Fuseinin Mumuni",
      "Alhassan Mumuni"
    ],
    "abstract": "We review current and emerging knowledge-informed and brain-inspired\ncognitive systems for realizing adversarial defenses, eXplainable Artificial\nIntelligence (XAI), and zero-shot or few-short learning. Data-driven deep\nlearning models have achieved remarkable performance and demonstrated\ncapabilities surpassing human experts in many applications. Yet, their\ninability to exploit domain knowledge leads to serious performance limitations\nin practical applications. In particular, deep learning systems are exposed to\nadversarial attacks, which can trick them into making glaringly incorrect\ndecisions. Moreover, complex data-driven models typically lack interpretability\nor explainability, i.e., their decisions cannot be understood by human\nsubjects. Furthermore, models are usually trained on standard datasets with a\nclosed-world assumption. Hence, they struggle to generalize to unseen cases\nduring inference in practical open-world environments, thus, raising the zero-\nor few-shot generalization problem. Although many conventional solutions exist,\nexplicit domain knowledge, brain-inspired neural network and cognitive\narchitectures offer powerful new dimensions towards alleviating these problems.\nPrior knowledge is represented in appropriate forms and incorporated in deep\nlearning frameworks to improve performance. Brain-inspired cognition methods\nuse computational models that mimic the human mind to enhance intelligent\nbehavior in artificial agents and autonomous robots. Ultimately, these models\nachieve better explainability, higher adversarial robustness and data-efficient\nlearning, and can, in turn, provide insights for cognitive science and\nneuroscience-that is, to deepen human understanding on how the brain works in\ngeneral, and how it handles these problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07078v1",
    "published_date": "2024-03-11 18:11:00 UTC",
    "updated_date": "2024-03-11 18:11:00 UTC"
  },
  {
    "arxiv_id": "2403.07076v1",
    "title": "Mapping High-level Semantic Regions in Indoor Environments without Object Recognition",
    "authors": [
      "Roberto Bigazzi",
      "Lorenzo Baraldi",
      "Shreyas Kousik",
      "Rita Cucchiara",
      "Marco Pavone"
    ],
    "abstract": "Robots require a semantic understanding of their surroundings to operate in\nan efficient and explainable way in human environments. In the literature,\nthere has been an extensive focus on object labeling and exhaustive scene graph\ngeneration; less effort has been focused on the task of purely identifying and\nmapping large semantic regions. The present work proposes a method for semantic\nregion mapping via embodied navigation in indoor environments, generating a\nhigh-level representation of the knowledge of the agent. To enable region\nidentification, the method uses a vision-to-language model to provide scene\ninformation for mapping. By projecting egocentric scene understanding into the\nglobal frame, the proposed method generates a semantic map as a distribution\nover possible region labels at each location. This mapping procedure is paired\nwith a trained navigation policy to enable autonomous map generation. The\nproposed method significantly outperforms a variety of baselines, including an\nobject-based system and a pretrained scene classifier, in experiments in a\nphotorealistic simulator.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by IEEE International Conference on Robotics and Automation\n  (ICRA 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.07076v1",
    "published_date": "2024-03-11 18:09:50 UTC",
    "updated_date": "2024-03-11 18:09:50 UTC"
  },
  {
    "arxiv_id": "2403.06963v2",
    "title": "The pitfalls of next-token prediction",
    "authors": [
      "Gregor Bachmann",
      "Vaishnavh Nagarajan"
    ],
    "abstract": "Can a mere next-token predictor faithfully model human intelligence? We\ncrystallize this emerging concern and correct popular misconceptions\nsurrounding it, and advocate a simple multi-token objective.\n  As a starting point, we argue that the two often-conflated phases of\nnext-token prediction -- autoregressive inference and teacher-forced training\n-- must be treated distinctly. The popular criticism that errors can compound\nduring autoregressive inference, crucially assumes that teacher-forcing has\nlearned an accurate next-token predictor. This assumption sidesteps a more\ndeep-rooted problem we expose: in certain classes of tasks, teacher-forcing can\nsimply fail to learn an accurate next-token predictor in the first place. We\ndescribe a general mechanism of how teacher-forcing can fail, and design a\nminimal planning task where both the Transformer and the Mamba architecture\nempirically fail in that manner -- remarkably, despite the task being\nstraightforward to learn.\n  Finally, we provide preliminary evidence that this failure can be resolved\nusing a simple modification that predicts multiple tokens in advance. We hope\nthis finding can ground future debates and inspire explorations beyond the\nnext-token prediction paradigm. We make our code available under\nhttps://github.com/gregorbachmann/Next-Token-Failures",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06963v2",
    "published_date": "2024-03-11 17:47:30 UTC",
    "updated_date": "2024-07-05 20:48:04 UTC"
  },
  {
    "arxiv_id": "2403.13835v1",
    "title": "SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees",
    "authors": [
      "Saehan Jo",
      "Immanuel Trummer"
    ],
    "abstract": "The advancement of Large Language Models (LLMs) has significantly boosted\nperformance in natural language processing (NLP) tasks. However, the deployment\nof high-performance LLMs incurs substantial costs, primarily due to the\nincreased number of parameters aimed at enhancing model performance. This has\nmade the use of state-of-the-art LLMs more expensive for end-users. AI service\nproviders, such as OpenAI and Anthropic, often offer multiple versions of LLMs\nwith varying prices and performance. However, end-users still face challenges\nin choosing the appropriate LLM for their tasks that balance result quality\nwith cost.\n  We introduce SMART, Scaling Models Adaptively for Reduced Token Fees, a novel\nLLM framework designed to minimize the inference costs of NLP tasks while\nensuring sufficient result quality. It enables users to specify an accuracy\nconstraint in terms of the equivalence of outputs to those of the most powerful\nLLM. SMART then generates results that deviate from the outputs of this LLM\nonly with a probability below a user-defined threshold. SMART employs a\nprofiling phase that evaluates the performance of multiple LLMs to identify\nthose that meet the user-defined accuracy level. SMART optimizes the tradeoff\nbetween profiling overheads and the anticipated cost savings resulting from\nprofiling. Moreover, our approach significantly reduces inference costs by\nstrategically leveraging a mix of LLMs. Our experiments on three real-world\ndatasets show that, based on OpenAI models, SMART achieves significant cost\nsavings, up to 25.6x in comparison to GPT-4.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13835v1",
    "published_date": "2024-03-11 17:45:47 UTC",
    "updated_date": "2024-03-11 17:45:47 UTC"
  },
  {
    "arxiv_id": "2403.06952v1",
    "title": "SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data",
    "authors": [
      "Jialu Li",
      "Jaemin Cho",
      "Yi-Lin Sung",
      "Jaehong Yoon",
      "Mohit Bansal"
    ],
    "abstract": "Recent text-to-image (T2I) generation models have demonstrated impressive\ncapabilities in creating images from text descriptions. However, these T2I\ngeneration models often fall short of generating images that precisely match\nthe details of the text inputs, such as incorrect spatial relationship or\nmissing objects. In this paper, we introduce SELMA: Skill-Specific Expert\nLearning and Merging with Auto-Generated Data, a novel paradigm to improve the\nfaithfulness of T2I models by fine-tuning models on automatically generated,\nmulti-skill image-text datasets, with skill-specific expert learning and\nmerging. First, SELMA leverages an LLM's in-context learning capability to\ngenerate multiple datasets of text prompts that can teach different skills, and\nthen generates the images with a T2I model based on the prompts. Next, SELMA\nadapts the T2I model to the new skills by learning multiple single-skill LoRA\n(low-rank adaptation) experts followed by expert merging. Our independent\nexpert fine-tuning specializes multiple models for different skills, and expert\nmerging helps build a joint multi-skill T2I model that can generate faithful\nimages given diverse text prompts, while mitigating the knowledge conflict from\ndifferent datasets. We empirically demonstrate that SELMA significantly\nimproves the semantic alignment and text faithfulness of state-of-the-art T2I\ndiffusion models on multiple benchmarks (+2.1% on TIFA and +6.9% on DSG), human\npreference metrics (PickScore, ImageReward, and HPS), as well as human\nevaluation. Moreover, fine-tuning with image-text pairs auto-collected via\nSELMA shows comparable performance to fine-tuning with ground truth data.\nLastly, we show that fine-tuning with images from a weaker T2I model can help\nimprove the generation quality of a stronger T2I model, suggesting promising\nweak-to-strong generalization in T2I models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "First two authors contributed equally; Project website:\n  https://selma-t2i.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2403.06952v1",
    "published_date": "2024-03-11 17:35:33 UTC",
    "updated_date": "2024-03-11 17:35:33 UTC"
  },
  {
    "arxiv_id": "2403.06936v1",
    "title": "Counterfactual Reasoning with Knowledge Graph Embeddings",
    "authors": [
      "Lena Zellinger",
      "Andreas Stephan",
      "Benjamin Roth"
    ],
    "abstract": "Knowledge graph embeddings (KGEs) were originally developed to infer true but\nmissing facts in incomplete knowledge repositories. In this paper, we link\nknowledge graph completion and counterfactual reasoning via our new task CFKGR.\nWe model the original world state as a knowledge graph, hypothetical scenarios\nas edges added to the graph, and plausible changes to the graph as inferences\nfrom logical rules. We create corresponding benchmark datasets, which contain\ndiverse hypothetical scenarios with plausible changes to the original knowledge\ngraph and facts that should be retained. We develop COULDD, a general method\nfor adapting existing knowledge graph embeddings given a hypothetical premise,\nand evaluate it on our benchmark. Our results indicate that KGEs learn patterns\nin the graph without explicit training. We further observe that KGEs adapted\nwith COULDD solidly detect plausible counterfactual changes to the graph that\nfollow these patterns. An evaluation on human-annotated data reveals that KGEs\nadapted with COULDD are mostly unable to recognize changes to the graph that do\nnot follow learned inference rules. In contrast, ChatGPT mostly outperforms\nKGEs in detecting plausible changes to the graph but has poor knowledge\nretention. In summary, CFKGR connects two previously distinct areas, namely KG\ncompletion and counterfactual reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06936v1",
    "published_date": "2024-03-11 17:21:39 UTC",
    "updated_date": "2024-03-11 17:21:39 UTC"
  },
  {
    "arxiv_id": "2403.06925v2",
    "title": "Transformers Learn Low Sensitivity Functions: Investigations and Implications",
    "authors": [
      "Bhavya Vasudeva",
      "Deqing Fu",
      "Tianyi Zhou",
      "Elliott Kau",
      "Youqi Huang",
      "Vatsal Sharan"
    ],
    "abstract": "Transformers achieve state-of-the-art accuracy and robustness across many\ntasks, but an understanding of their inductive biases and how those biases\ndiffer from other neural network architectures remains elusive. In this work,\nwe identify the sensitivity of the model to token-wise random perturbations in\nthe input as a unified metric which explains the inductive bias of transformers\nacross different data modalities and distinguishes them from other\narchitectures. We show that transformers have lower sensitivity than MLPs,\nCNNs, ConvMixers and LSTMs, across both vision and language tasks. We also show\nthat this low-sensitivity bias has important implications: i) lower sensitivity\ncorrelates with improved robustness; it can also be used as an efficient\nintervention to further improve the robustness of transformers; ii) it\ncorresponds to flatter minima in the loss landscape; and iii) it can serve as a\nprogress measure for grokking. We support these findings with theoretical\nresults showing (weak) spectral bias of transformers in the NTK regime, and\nimproved robustness due to the lower sensitivity. The code is available at\nhttps://github.com/estija/sensitivity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025. 24 pages, 19 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.06925v2",
    "published_date": "2024-03-11 17:12:09 UTC",
    "updated_date": "2025-02-13 18:58:58 UTC"
  },
  {
    "arxiv_id": "2403.06914v2",
    "title": "MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning",
    "authors": [
      "Yichuan Li",
      "Xiyao Ma",
      "Sixing Lu",
      "Kyumin Lee",
      "Xiaohu Liu",
      "Chenlei Guo"
    ],
    "abstract": "Large Language models (LLMs) have demonstrated impressive in-context learning\n(ICL) capabilities, where a LLM makes predictions for a given test input\ntogether with a few input-output pairs (demonstrations). Nevertheless, the\ninclusion of demonstrations leads to a quadratic increase in the computational\noverhead of the self-attention mechanism. Existing solutions attempt to distill\nlengthy demonstrations into compact vectors. However, they often require\ntask-specific retraining or compromise LLM's in-context learning performance.\nTo mitigate these challenges, we present Meta dEmonstratioN Distillation\n(MEND), where a language model learns to distill any lengthy demonstrations\ninto vectors without retraining for a new downstream task. We exploit the\nknowledge distillation to enhance alignment between MEND and LLM, achieving\nboth efficiency and effectiveness simultaneously. MEND is endowed with the\nmeta-knowledge of distilling demonstrations through a two-stage training\nprocess, which includes meta-distillation pretraining and fine-tuning.\nComprehensive evaluations across seven diverse ICL task partitions using\ndecoder-only (GPT-2) and encoder-decoder (T5) attest to MEND's prowess. It not\nonly matches but often outperforms the Vanilla ICL as well as other\nstate-of-the-art distillation models, while significantly reducing the\ncomputational demands. This innovation promises enhanced scalability and\nefficiency for the practical deployment of large language models",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06914v2",
    "published_date": "2024-03-11 17:03:04 UTC",
    "updated_date": "2024-03-12 15:52:14 UTC"
  },
  {
    "arxiv_id": "2403.06910v1",
    "title": "Responsible Artificial Intelligence: A Structured Literature Review",
    "authors": [
      "Sabrina Goellner",
      "Marina Tropmann-Frick",
      "Bostjan Brumen"
    ],
    "abstract": "Our research endeavors to advance the concept of responsible artificial\nintelligence (AI), a topic of increasing importance within EU policy\ndiscussions. The EU has recently issued several publications emphasizing the\nnecessity of trust in AI, underscoring the dual nature of AI as both a\nbeneficial tool and a potential weapon. This dichotomy highlights the urgent\nneed for international regulation. Concurrently, there is a need for frameworks\nthat guide companies in AI development, ensuring compliance with such\nregulations. Our research aims to assist lawmakers and machine learning\npractitioners in navigating the evolving landscape of AI regulation,\nidentifying focal areas for future attention. This paper introduces a\ncomprehensive and, to our knowledge, the first unified definition of\nresponsible AI. Through a structured literature review, we elucidate the\ncurrent understanding of responsible AI. Drawing from this analysis, we propose\nan approach for developing a future framework centered around this concept. Our\nfindings advocate for a human-centric approach to Responsible AI. This approach\nencompasses the implementation of AI methods with a strong emphasis on ethics,\nmodel explainability, and the pillars of privacy, security, and trust.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06910v1",
    "published_date": "2024-03-11 17:01:13 UTC",
    "updated_date": "2024-03-11 17:01:13 UTC"
  },
  {
    "arxiv_id": "2403.06906v3",
    "title": "Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints",
    "authors": [
      "Jean V. Alves",
      "Diogo Leitão",
      "Sérgio Jesus",
      "Marco O. P. Sampaio",
      "Javier Liébana",
      "Pedro Saleiro",
      "Mário A. T. Figueiredo",
      "Pedro Bizarro"
    ],
    "abstract": "Learning to defer (L2D) aims to improve human-AI collaboration systems by\nlearning how to defer decisions to humans when they are more likely to be\ncorrect than an ML classifier. Existing research in L2D overlooks key\nreal-world aspects that impede its practical adoption, namely: i) neglecting\ncost-sensitive scenarios, where type I and type II errors have different costs;\nii) requiring concurrent human predictions for every instance of the training\ndataset; and iii) not dealing with human work-capacity constraints. To address\nthese issues, we propose the \\textit{deferral under cost and capacity\nconstraints framework} (DeCCaF). DeCCaF is a novel L2D approach, employing\nsupervised learning to model the probability of human error under less\nrestrictive data requirements (only one expert prediction per instance) and\nusing constraint programming to globally minimize the error cost, subject to\nworkload limitations. We test DeCCaF in a series of cost-sensitive fraud\ndetection scenarios with different teams of 9 synthetic fraud analysts, with\nindividual work-capacity constraints. The results demonstrate that our approach\nperforms significantly better than the baselines in a wide array of scenarios,\nachieving an average $8.4\\%$ reduction in the misclassification cost. The code\nused for the experiments is available at https://github.com/feedzai/deccaf",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06906v3",
    "published_date": "2024-03-11 16:57:20 UTC",
    "updated_date": "2024-08-19 18:18:30 UTC"
  },
  {
    "arxiv_id": "2403.09714v1",
    "title": "Linguistic Structure Induction from Language Models",
    "authors": [
      "Omar Momen"
    ],
    "abstract": "Linear sequences of words are implicitly represented in our brains by\nhierarchical structures that organize the composition of words in sentences.\nLinguists formalize different frameworks to model this hierarchy; two of the\nmost common syntactic frameworks are Constituency and Dependency. Constituency\nrepresents sentences as nested groups of phrases, while dependency represents a\nsentence by assigning relations between its words. Recently, the pursuit of\nintelligent machines has produced Language Models (LMs) capable of solving many\nlanguage tasks with a human-level performance. Many studies now question\nwhether LMs implicitly represent syntactic hierarchies. This thesis focuses on\nproducing constituency and dependency structures from LMs in an unsupervised\nsetting. I review the critical methods in this field and highlight a line of\nwork that utilizes a numerical representation for binary constituency trees\n(Syntactic Distance). I present a detailed study on StructFormer (SF) (Shen et\nal., 2021), which retrofits a transformer encoder architecture with a parser\nnetwork to produce constituency and dependency structures. I present six\nexperiments to analyze and address this field's challenges; experiments include\ninvestigating the effect of repositioning the parser network within the SF\narchitecture, evaluating subword-based induced trees, and benchmarking the\nmodels developed in the thesis experiments on linguistic tasks. Models\nbenchmarking is performed by participating in the BabyLM challenge, published\nat CoNLL 2023 (Momen et al., 2023). The results of this thesis encourage\nfurther development in the direction of retrofitting transformer-based models\nto induce syntactic structures, supported by the acceptable performance of SF\nin different experimental settings and the observed limitations that require\ninnovative solutions to advance the state of syntactic structure induction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Master's Thesis. Supervised by Laura Kallmeyer and David Arps",
    "pdf_url": "http://arxiv.org/pdf/2403.09714v1",
    "published_date": "2024-03-11 16:54:49 UTC",
    "updated_date": "2024-03-11 16:54:49 UTC"
  },
  {
    "arxiv_id": "2403.06901v1",
    "title": "LIBR+: Improving Intraoperative Liver Registration by Learning the Residual of Biomechanics-Based Deformable Registration",
    "authors": [
      "Dingrong Wang",
      "Soheil Azadvar",
      "Jon Heiselman",
      "Xiajun Jiang",
      "Michael Miga",
      "Linwei Wang"
    ],
    "abstract": "The surgical environment imposes unique challenges to the intraoperative\nregistration of organ shapes to their preoperatively-imaged geometry.\nBiomechanical model-based registration remains popular, while deep learning\nsolutions remain limited due to the sparsity and variability of intraoperative\nmeasurements and the limited ground-truth deformation of an organ that can be\nobtained during the surgery. In this paper, we propose a novel \\textit{hybrid}\nregistration approach that leverage a linearized iterative boundary\nreconstruction (LIBR) method based on linear elastic biomechanics, and use deep\nneural networks to learn its residual to the ground-truth deformation (LIBR+).\nWe further formulate a dual-branch spline-residual graph convolutional neural\nnetwork (SR-GCN) to assimilate information from sparse and variable\nintraoperative measurements and effectively propagate it through the geometry\nof the 3D organ. Experiments on a large intraoperative liver registration\ndataset demonstrated the consistent improvements achieved by LIBR+ in\ncomparison to existing rigid, biomechnical model-based non-rigid, and\ndeep-learning based non-rigid approaches to intraoperative liver registration.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "12 pages, Medical Image Computing and Computer Assisted Intervention\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06901v1",
    "published_date": "2024-03-11 16:54:44 UTC",
    "updated_date": "2024-03-11 16:54:44 UTC"
  },
  {
    "arxiv_id": "2403.06880v2",
    "title": "Unveiling the Significance of Toddler-Inspired Reward Transition in Goal-Oriented Reinforcement Learning",
    "authors": [
      "Junseok Park",
      "Yoonsung Kim",
      "Hee Bin Yoo",
      "Min Whoo Lee",
      "Kibeom Kim",
      "Won-Seok Choi",
      "Minsu Lee",
      "Byoung-Tak Zhang"
    ],
    "abstract": "Toddlers evolve from free exploration with sparse feedback to exploiting\nprior experiences for goal-directed learning with denser rewards. Drawing\ninspiration from this Toddler-Inspired Reward Transition, we set out to explore\nthe implications of varying reward transitions when incorporated into\nReinforcement Learning (RL) tasks. Central to our inquiry is the transition\nfrom sparse to potential-based dense rewards, which share optimal strategies\nregardless of reward changes. Through various experiments, including those in\negocentric navigation and robotic arm manipulation tasks, we found that proper\nreward transitions significantly influence sample efficiency and success rates.\nOf particular note is the efficacy of the toddler-inspired Sparse-to-Dense\n(S2D) transition. Beyond these performance metrics, using Cross-Density\nVisualizer technique, we observed that transitions, especially the S2D, smooth\nthe policy loss landscape, promoting wide minima that enhance generalization in\nRL models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a full paper at AAAI 2024 (Oral presentation): 7 pages\n  (main paper), 2 pages (references), 17 pages (appendix) each",
    "pdf_url": "http://arxiv.org/pdf/2403.06880v2",
    "published_date": "2024-03-11 16:34:23 UTC",
    "updated_date": "2024-03-18 09:43:20 UTC"
  },
  {
    "arxiv_id": "2403.06872v1",
    "title": "Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents",
    "authors": [
      "Nishchal Prasad",
      "Mohand Boughanem",
      "Taoufiq Dkaki"
    ],
    "abstract": "Legal judgment prediction suffers from the problem of long case documents\nexceeding tens of thousands of words, in general, and having a non-uniform\nstructure. Predicting judgments from such documents becomes a challenging task,\nmore so on documents with no structural annotation. We explore the\nclassification of these large legal documents and their lack of structural\ninformation with a deep-learning-based hierarchical framework which we call\nMESc; \"Multi-stage Encoder-based Supervised with-clustering\"; for judgment\nprediction. Specifically, we divide a document into parts to extract their\nembeddings from the last four layers of a custom fine-tuned Large Language\nModel, and try to approximate their structure through unsupervised clustering.\nWhich we use in another set of transformer encoder layers to learn the\ninter-chunk representations. We analyze the adaptability of Large Language\nModels (LLMs) with multi-billion parameters (GPT-Neo, and GPT-J) with the\nhierarchical framework of MESc and compare them with their standalone\nperformance on legal texts. We also study their intra-domain(legal) transfer\nlearning capability and the impact of combining embeddings from their last\nlayers in MESc. We test these methods and their effectiveness with extensive\nexperiments and ablation studies on legal documents from India, the European\nUnion, and the United States with the ILDC dataset and a subset of the LexGLUE\ndataset. Our approach achieves a minimum total performance gain of\napproximately 2 points over previous state-of-the-art methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper was accepted as a long paper at ECIR 2024. arXiv admin\n  note: substantial text overlap with arXiv:2309.10563",
    "pdf_url": "http://arxiv.org/pdf/2403.06872v1",
    "published_date": "2024-03-11 16:24:08 UTC",
    "updated_date": "2024-03-11 16:24:08 UTC"
  },
  {
    "arxiv_id": "2403.06869v3",
    "title": "Impact of Noisy Supervision in Foundation Model Learning",
    "authors": [
      "Hao Chen",
      "Zihan Wang",
      "Ran Tao",
      "Hongxin Wei",
      "Xing Xie",
      "Masashi Sugiyama",
      "Bhiksha Raj",
      "Jindong Wang"
    ],
    "abstract": "Foundation models are usually pre-trained on large-scale datasets and then\nadapted to downstream tasks through tuning. However, the large-scale\npre-training datasets, often inaccessible or too expensive to handle, can\ncontain label noise that may adversely affect the generalization of the model\nand pose unexpected risks. This paper stands out as the first work to\ncomprehensively understand and analyze the nature of noise in pre-training\ndatasets and then effectively mitigate its impacts on downstream tasks.\nSpecifically, through extensive experiments of fully-supervised and image-text\ncontrastive pre-training on synthetic noisy ImageNet-1K, YFCC15M, and CC12M\ndatasets, we demonstrate that, while slight noise in pre-training can benefit\nin-domain (ID) performance, where the training and testing data share a similar\ndistribution, it always deteriorates out-of-domain (OOD) performance, where\ntraining and testing distributions are significantly different. These\nobservations are agnostic to scales of pre-training datasets, pre-training\nnoise types, model architectures, pre-training objectives, downstream tuning\nmethods, and downstream applications. We empirically ascertain that the reason\nbehind this is that the pre-training noise shapes the feature space\ndifferently. We then propose a tuning method (NMTune) to affine the feature\nspace to mitigate the malignant effect of noise and improve generalization,\nwhich is applicable in both parameter-efficient and black-box tuning manners.\nWe additionally conduct extensive experiments on popular vision and language\nmodels, including APIs, which are supervised and self-supervised pre-trained on\nrealistic noisy data for evaluation. Our analysis and results demonstrate the\nimportance of this novel and fundamental research direction, which we term as\nNoisy Model Learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 10 figures, 6 tables, preprint. arXiv admin note:\n  substantial text overlap with arXiv:2309.17002",
    "pdf_url": "http://arxiv.org/pdf/2403.06869v3",
    "published_date": "2024-03-11 16:22:41 UTC",
    "updated_date": "2025-05-05 03:07:00 UTC"
  },
  {
    "arxiv_id": "2403.07040v1",
    "title": "All in One: Multi-Task Prompting for Graph Neural Networks (Extended Abstract)",
    "authors": [
      "Xiangguo Sun",
      "Hong Cheng",
      "Jia Li",
      "Bo Liu",
      "Jihong Guan"
    ],
    "abstract": "This paper is an extended abstract of our original work published in KDD23,\nwhere we won the best research paper award (Xiangguo Sun, Hong Cheng, Jia Li,\nBo Liu, and Jihong Guan. All in one: Multi-task prompting for graph neural\nnetworks. KDD 23) The paper introduces a novel approach to bridging the gap\nbetween pre-trained graph models and the diverse tasks they're applied to,\ninspired by the success of prompt learning in NLP. Recognizing the challenge of\naligning pre-trained models with varied graph tasks (node level, edge level,\nand graph level), which can lead to negative transfer and poor performance, we\npropose a multi-task prompting method for graphs. This method involves unifying\ngraph and language prompt formats, enabling NLP's prompting strategies to be\nadapted for graph tasks. By analyzing the task space of graph applications, we\nreformulate problems to fit graph-level tasks and apply meta-learning to\nimprove prompt initialization for multiple tasks. Experiments show our method's\neffectiveness in enhancing model performance across different graph tasks.\n  Beyond the original work, in this extended abstract, we further discuss the\ngraph prompt from a bigger picture and provide some of the latest work toward\nthis area.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "submitted to IJCAI 2024 Sister Conferences Track. The original paper\n  can be seen at arXiv:2307.01504",
    "pdf_url": "http://arxiv.org/pdf/2403.07040v1",
    "published_date": "2024-03-11 16:04:58 UTC",
    "updated_date": "2024-03-11 16:04:58 UTC"
  },
  {
    "arxiv_id": "2403.06843v1",
    "title": "Towards an educational tool for supporting neonatologists in the delivery room",
    "authors": [
      "Giorgio Leonardi",
      "Clara Maldarizzi",
      "Stefania Montani",
      "Manuel Striani",
      "Mariachiara Martina Strozzi"
    ],
    "abstract": "Nowadays, there is evidence that several factors may increase the risk, for\nan infant, to require stabilisation or resuscitation manoeuvres at birth.\nHowever, this risk factors are not completely known, and a universally\napplicable model for predicting high-risk situations is not available yet.\nConsidering both these limitations and the fact that the need for resuscitation\nat birth is a rare event, periodic training of the healthcare personnel\nresponsible for newborn caring in the delivery room is mandatory.\n  In this paper, we propose a machine learning approach for identifying risk\nfactors and their impact on the birth event from real data, which can be used\nby personnel to progressively increase and update their knowledge. Our final\ngoal will be the one of designing a user-friendly mobile application, able to\nimprove the recognition rate and the planning of the appropriate interventions\non high-risk patients.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 figures, conference paper",
    "pdf_url": "http://arxiv.org/pdf/2403.06843v1",
    "published_date": "2024-03-11 16:03:21 UTC",
    "updated_date": "2024-03-11 16:03:21 UTC"
  },
  {
    "arxiv_id": "2403.06840v2",
    "title": "RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback",
    "authors": [
      "Yanming Liu",
      "Xinyue Peng",
      "Xuhong Zhang",
      "Weihao Liu",
      "Jianwei Yin",
      "Jiannan Cao",
      "Tianyu Du"
    ],
    "abstract": "Large language models (LLMs) demonstrate exceptional performance in numerous\ntasks but still heavily rely on knowledge stored in their parameters. Moreover,\nupdating this knowledge incurs high training costs. Retrieval-augmented\ngeneration (RAG) methods address this issue by integrating external knowledge.\nThe model can answer questions it couldn't previously by retrieving knowledge\nrelevant to the query. This approach improves performance in certain scenarios\nfor specific tasks. However, if irrelevant texts are retrieved, it may impair\nmodel performance. In this paper, we propose Retrieval Augmented Iterative\nSelf-Feedback (RA-ISF), a framework that iteratively decomposes tasks and\nprocesses them in three submodules to enhance the model's problem-solving\ncapabilities. Experiments show that our method outperforms existing benchmarks,\nperforming well on models like GPT3.5, Llama2, significantly enhancing factual\nreasoning capabilities and reducing hallucinations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, multiple figures. Providing second version RA-ISF",
    "pdf_url": "http://arxiv.org/pdf/2403.06840v2",
    "published_date": "2024-03-11 16:01:05 UTC",
    "updated_date": "2024-06-06 11:55:36 UTC"
  },
  {
    "arxiv_id": "2403.08506v1",
    "title": "DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning",
    "authors": [
      "Sikai Bai",
      "Jie Zhang",
      "Shuaicheng Li",
      "Song Guo",
      "Jingcai Guo",
      "Jun Hou",
      "Tao Han",
      "Xiaocheng Lu"
    ],
    "abstract": "Federated learning (FL) has emerged as a powerful paradigm for learning from\ndecentralized data, and federated domain generalization further considers the\ntest dataset (target domain) is absent from the decentralized training data\n(source domains). However, most existing FL methods assume that domain labels\nare provided during training, and their evaluation imposes explicit constraints\non the number of domains, which must strictly match the number of clients.\nBecause of the underutilization of numerous edge devices and additional\ncross-client domain annotations in the real world, such restrictions may be\nimpractical and involve potential privacy leaks. In this paper, we propose an\nefficient and novel approach, called Disentangled Prompt Tuning (DiPrompT), a\nmethod that tackles the above restrictions by learning adaptive prompts for\ndomain generalization in a distributed manner. Specifically, we first design\ntwo types of prompts, i.e., global prompt to capture general knowledge across\nall clients and domain prompts to capture domain-specific knowledge. They\neliminate the restriction on the one-to-one mapping between source domains and\nlocal clients. Furthermore, a dynamic query metric is introduced to\nautomatically search the suitable domain label for each sample, which includes\ntwo-substep text-image alignments based on prompt tuning without\nlabor-intensive annotation. Extensive experiments on multiple datasets\ndemonstrate that our DiPrompT achieves superior domain generalization\nperformance over state-of-the-art FL methods when domain labels are not\nprovided, and even outperforms many centralized learning methods using domain\nlabels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08506v1",
    "published_date": "2024-03-11 15:58:15 UTC",
    "updated_date": "2024-03-11 15:58:15 UTC"
  },
  {
    "arxiv_id": "2403.06835v1",
    "title": "Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting",
    "authors": [
      "Wenting Chen",
      "Pengyu Wang",
      "Hui Ren",
      "Lichao Sun",
      "Quanzheng Li",
      "Yixuan Yuan",
      "Xiang Li"
    ],
    "abstract": "Data scarcity and privacy concerns limit the availability of high-quality\nmedical images for public use, which can be mitigated through medical image\nsynthesis. However, current medical image synthesis methods often struggle to\naccurately capture the complexity of detailed anatomical structures and\npathological conditions. To address these challenges, we propose a novel\nmedical image synthesis model that leverages fine-grained image-text alignment\nand anatomy-pathology prompts to generate highly detailed and accurate\nsynthetic medical images. Our method integrates advanced natural language\nprocessing techniques with image generative modeling, enabling precise\nalignment between descriptive text prompts and the synthesized images'\nanatomical and pathological details. The proposed approach consists of two key\ncomponents: an anatomy-pathology prompting module and a fine-grained\nalignment-based synthesis module. The anatomy-pathology prompting module\nautomatically generates descriptive prompts for high-quality medical images. To\nfurther synthesize high-quality medical images from the generated prompts, the\nfine-grained alignment-based synthesis module pre-defines a visual codebook for\nthe radiology dataset and performs fine-grained alignment between the codebook\nand generated prompts to obtain key patches as visual clues, facilitating\naccurate image synthesis. We validate the superiority of our method through\nexperiments on public chest X-ray datasets and demonstrate that our synthetic\nimages preserve accurate semantic information, making them valuable for various\nmedical applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.06835v1",
    "published_date": "2024-03-11 15:56:17 UTC",
    "updated_date": "2024-03-11 15:56:17 UTC"
  },
  {
    "arxiv_id": "2403.06832v4",
    "title": "Noise-powered Multi-modal Knowledge Graph Representation Framework",
    "authors": [
      "Zhuo Chen",
      "Yin Fang",
      "Yichi Zhang",
      "Lingbing Guo",
      "Jiaoyan Chen",
      "Jeff Z. Pan",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "abstract": "The rise of Multi-modal Pre-training highlights the necessity for a unified\nMulti-Modal Knowledge Graph (MMKG) representation learning framework. Such a\nframework is essential for embedding structured knowledge into multi-modal\nLarge Language Models effectively, alleviating issues like knowledge\nmisconceptions and multi-modal hallucinations. In this work, we explore the\nefficacy of models in accurately embedding entities within MMKGs through two\npivotal tasks: Multi-modal Knowledge Graph Completion (MKGC) and Multi-modal\nEntity Alignment (MMEA). Building on this foundation, we propose a novel SNAG\nmethod that utilizes a Transformer-based architecture equipped with\nmodality-level noise masking to robustly integrate multi-modal entity features\nin KGs. By incorporating specific training objectives for both MKGC and MMEA,\nour approach achieves SOTA performance across a total of ten datasets,\ndemonstrating its versatility. Moreover, SNAG can not only function as a\nstandalone model but also enhance other existing methods, providing stable\nperformance improvements. Code and data are available at\nhttps://github.com/zjukg/SNAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2025 Accepted, Repo is available at\n  https://github.com/zjukg/SNAG",
    "pdf_url": "http://arxiv.org/pdf/2403.06832v4",
    "published_date": "2024-03-11 15:48:43 UTC",
    "updated_date": "2025-01-15 06:30:19 UTC"
  },
  {
    "arxiv_id": "2403.06828v3",
    "title": "NeuPAN: Direct Point Robot Navigation with End-to-End Model-based Learning",
    "authors": [
      "Ruihua Han",
      "Shuai Wang",
      "Shuaijun Wang",
      "Zeqing Zhang",
      "Jianjun Chen",
      "Shijie Lin",
      "Chengyang Li",
      "Chengzhong Xu",
      "Yonina C. Eldar",
      "Qi Hao",
      "Jia Pan"
    ],
    "abstract": "Navigating a nonholonomic robot in a cluttered, unknown environment requires\naccurate perception and precise motion control for real-time collision\navoidance. This paper presents NeuPAN: a real-time, highly accurate, map-free,\neasy-to-deploy, and environment-invariant robot motion planner. Leveraging a\ntightly coupled perception-to-control framework, NeuPAN has two key innovations\ncompared to existing approaches: 1) it directly maps raw point cloud data to a\nlatent distance feature space for collision-free motion generation, avoiding\nerror propagation from the perception to control pipeline; 2) it is\ninterpretable from an end-to-end model-based learning perspective. The crux of\nNeuPAN is solving an end-to-end mathematical model with numerous point-level\nconstraints using a plug-and-play (PnP) proximal alternating-minimization\nnetwork (PAN), incorporating neurons in the loop. This allows NeuPAN to\ngenerate real-time, physically interpretable motions. It seamlessly integrates\ndata and knowledge engines, and its network parameters can be fine-tuned via\nbackpropagation. We evaluate NeuPAN on a ground mobile robot, a wheel-legged\nrobot, and an autonomous vehicle, in extensive simulated and real-world\nenvironments. Results demonstrate that NeuPAN outperforms existing baselines in\nterms of accuracy, efficiency, robustness, and generalization capabilities\nacross various environments, including the cluttered sandbox, office, corridor,\nand parking lot. We show that NeuPAN works well in unknown and unstructured\nenvironments with arbitrarily shaped objects, transforming impassable paths\ninto passable ones.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by TRO 2025; project website:\n  https://hanruihua.github.io/neupan_project/",
    "pdf_url": "http://arxiv.org/pdf/2403.06828v3",
    "published_date": "2024-03-11 15:44:38 UTC",
    "updated_date": "2025-02-11 15:47:43 UTC"
  },
  {
    "arxiv_id": "2403.06826v1",
    "title": "In-context Exploration-Exploitation for Reinforcement Learning",
    "authors": [
      "Zhenwen Dai",
      "Federico Tomasi",
      "Sina Ghiassian"
    ],
    "abstract": "In-context learning is a promising approach for online policy learning of\noffline reinforcement learning (RL) methods, which can be achieved at inference\ntime without gradient optimization. However, this method is hindered by\nsignificant computational costs resulting from the gathering of large training\ntrajectory sets and the need to train large Transformer models. We address this\nchallenge by introducing an In-context Exploration-Exploitation (ICEE)\nalgorithm, designed to optimize the efficiency of in-context policy learning.\nUnlike existing models, ICEE performs an exploration-exploitation trade-off at\ninference time within a Transformer model, without the need for explicit\nBayesian inference. Consequently, ICEE can solve Bayesian optimization problems\nas efficiently as Gaussian process biased methods do, but in significantly less\ntime. Through experiments in grid world environments, we demonstrate that ICEE\ncan learn to solve new RL tasks using only tens of episodes, marking a\nsubstantial improvement over the hundreds of episodes needed by the previous\nin-context learning method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06826v1",
    "published_date": "2024-03-11 15:43:14 UTC",
    "updated_date": "2024-03-11 15:43:14 UTC"
  },
  {
    "arxiv_id": "2403.06817v2",
    "title": "Are Targeted Messages More Effective?",
    "authors": [
      "Martin Grohe",
      "Eran Rosenbluth"
    ],
    "abstract": "Graph neural networks (GNN) are deep learning architectures for graphs.\nEssentially, a GNN is a distributed message passing algorithm, which is\ncontrolled by parameters learned from data. It operates on the vertices of a\ngraph: in each iteration, vertices receive a message on each incoming edge,\naggregate these messages, and then update their state based on their current\nstate and the aggregated messages. The expressivity of GNNs can be\ncharacterised in terms of certain fragments of first-order logic with counting\nand the Weisfeiler-Lehman algorithm.\n  The core GNN architecture comes in two different versions. In the first\nversion, a message only depends on the state of the source vertex, whereas in\nthe second version it depends on the states of the source and target vertices.\nIn practice, both of these versions are used, but the theory of GNNs so far\nmostly focused on the first one. On the logical side, the two versions\ncorrespond to two fragments of first-order logic with counting that we call\nmodal and guarded.\n  The question whether the two versions differ in their expressivity has been\nmostly overlooked in the GNN literature and has only been asked recently\n(Grohe, LICS'23). We answer this question here. It turns out that the answer is\nnot as straightforward as one might expect. By proving that the modal and\nguarded fragment of first-order logic with counting have the same expressivity\nover labelled undirected graphs, we show that in a non-uniform setting the two\nGNN versions have the same expressivity. However, we also prove that in a\nuniform setting the second version is strictly more expressive.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG",
      "68T05, 68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06817v2",
    "published_date": "2024-03-11 15:34:57 UTC",
    "updated_date": "2024-05-19 11:43:18 UTC"
  },
  {
    "arxiv_id": "2403.09713v2",
    "title": "A Hybrid Intelligence Method for Argument Mining",
    "authors": [
      "Michiel van der Meer",
      "Enrico Liscio",
      "Catholijn M. Jonker",
      "Aske Plaat",
      "Piek Vossen",
      "Pradeep K. Murukannaiah"
    ],
    "abstract": "Large-scale survey tools enable the collection of citizen feedback in opinion\ncorpora. Extracting the key arguments from a large and noisy set of opinions\nhelps in understanding the opinions quickly and accurately. Fully automated\nmethods can extract arguments but (1) require large labeled datasets that\ninduce large annotation costs and (2) work well for known viewpoints, but not\nfor novel points of view. We propose HyEnA, a hybrid (human + AI) method for\nextracting arguments from opinionated texts, combining the speed of automated\nprocessing with the understanding and reasoning capabilities of humans. We\nevaluate HyEnA on three citizen feedback corpora. We find that, on the one\nhand, HyEnA achieves higher coverage and precision than a state-of-the-art\nautomated method when compared to a common set of diverse opinions, justifying\nthe need for human insight. On the other hand, HyEnA requires less human effort\nand does not compromise quality compared to (fully manual) expert analysis,\ndemonstrating the benefit of combining human and artificial intelligence.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in JAIR",
    "pdf_url": "http://arxiv.org/pdf/2403.09713v2",
    "published_date": "2024-03-11 15:15:27 UTC",
    "updated_date": "2024-08-01 11:24:13 UTC"
  },
  {
    "arxiv_id": "2403.06786v1",
    "title": "Genetic Learning for Designing Sim-to-Real Data Augmentations",
    "authors": [
      "Bram Vanherle",
      "Nick Michiels",
      "Frank Van Reeth"
    ],
    "abstract": "Data augmentations are useful in closing the sim-to-real domain gap when\ntraining on synthetic data. This is because they widen the training data\ndistribution, thus encouraging the model to generalize better to other domains.\nMany image augmentation techniques exist, parametrized by different settings,\nsuch as strength and probability. This leads to a large space of different\npossible augmentation policies. Some policies work better than others for\novercoming the sim-to-real gap for specific datasets, and it is unclear why.\nThis paper presents two different interpretable metrics that can be combined to\npredict how well a certain augmentation policy will work for a specific\nsim-to-real setting, focusing on object detection. We validate our metrics by\ntraining many models with different augmentation policies and showing a strong\ncorrelation with performance on real data. Additionally, we introduce\nGeneticAugment, a genetic programming method that can leverage these metrics to\nautomatically design an augmentation policy for a specific dataset without\nneeding to train a model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages; accepted at DMLR Workshop @ ICRL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06786v1",
    "published_date": "2024-03-11 15:00:56 UTC",
    "updated_date": "2024-03-11 15:00:56 UTC"
  },
  {
    "arxiv_id": "2403.06764v3",
    "title": "An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models",
    "authors": [
      "Liang Chen",
      "Haozhe Zhao",
      "Tianyu Liu",
      "Shuai Bai",
      "Junyang Lin",
      "Chang Zhou",
      "Baobao Chang"
    ],
    "abstract": "In this study, we identify the inefficient attention phenomena in Large\nVision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5,\nQwenVL-Chat and Video-LLaVA. We find out that the attention computation over\nvisual tokens is of extreme inefficiency in the deep layers of popular LVLMs,\nsuggesting a need for a sparser approach compared to textual data handling. To\nthis end, we introduce FastV, a versatile plug-and-play method designed to\noptimize computational efficiency by learning adaptive attention patterns in\nearly layers and pruning visual tokens in subsequent ones. Our evaluations\ndemonstrate FastV's ability to dramatically reduce computational costs (e.g., a\n45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in a\nwide range of image and video understanding tasks. The computational efficiency\nand performance trade-off of FastV are highly customizable and\npareto-efficient. It can compress the FLOPs of a 13B-parameter model to achieve\na lower budget than that of a 7B-parameter model, while still maintaining\nsuperior performance. We believe FastV has practical values for deployment of\nLVLMs in edge devices and commercial models. Code is released at\nhttps://github.com/pkunlp-icler/FastV.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV 2024 (Oral), code is released at\n  https://github.com/pkunlp-icler/FastV,",
    "pdf_url": "http://arxiv.org/pdf/2403.06764v3",
    "published_date": "2024-03-11 14:35:32 UTC",
    "updated_date": "2024-09-02 05:48:54 UTC"
  },
  {
    "arxiv_id": "2403.06754v2",
    "title": "ALaRM: Align Language Models via Hierarchical Rewards Modeling",
    "authors": [
      "Yuhang Lai",
      "Siyuan Wang",
      "Shujun Liu",
      "Xuanjing Huang",
      "Zhongyu Wei"
    ],
    "abstract": "We introduce ALaRM, the first framework modeling hierarchical rewards in\nreinforcement learning from human feedback (RLHF), which is designed to enhance\nthe alignment of large language models (LLMs) with human preferences. The\nframework addresses the limitations of current alignment approaches, which\noften struggle with the inconsistency and sparsity of human supervision\nsignals, by integrating holistic rewards with aspect-specific rewards. This\nintegration enables more precise and consistent guidance of language models\ntowards desired outcomes, particularly in complex and open text generation\ntasks. By employing a methodology that filters and combines multiple rewards\nbased on their consistency, the framework provides a reliable mechanism for\nimproving model alignment. We validate our approach through applications in\nlong-form question answering and machine translation tasks, employing\ngpt-3.5-turbo for pairwise comparisons, and demonstrate improvements over\nexisting baselines. Our work underscores the effectiveness of hierarchical\nrewards modeling in refining LLM training processes for better human preference\nalignment. We release our code at https://ALaRM-fdu.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.06754v2",
    "published_date": "2024-03-11 14:28:40 UTC",
    "updated_date": "2024-03-16 12:43:33 UTC"
  },
  {
    "arxiv_id": "2403.06745v1",
    "title": "ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation",
    "authors": [
      "Shaojie Dai",
      "Xin Liu",
      "Ping Luo",
      "Yue Yu"
    ],
    "abstract": "Large language model (LLM) has achieved promising performance in multilingual\nmachine translation tasks through zero/few-shot prompts or prompt-tuning.\nHowever, due to the mixture of multilingual data during the pre-training of\nLLM, the LLM-based translation models face the off-target issue in both\nprompt-based methods, including a series of phenomena, namely instruction\nmisunderstanding, translation with wrong language and over-generation. For this\nissue, this paper introduces an\n\\textbf{\\underline{A}}uto-\\textbf{\\underline{C}}onstriction\n\\textbf{\\underline{T}}urning mechanism for \\textbf{\\underline{M}}ultilingual\n\\textbf{\\underline{N}}eural \\textbf{\\underline{M}}achine\n\\textbf{\\underline{T}}ranslation (\\model), which is a novel supervised\nfine-tuning mechanism and orthogonal to the traditional prompt-based methods.\nIn this method, \\model automatically constructs a constrained template in the\ntarget side by adding trigger tokens ahead of the ground truth. Furthermore,\ntrigger tokens can be arranged and combined freely to represent different task\nsemantics, and they can be iteratively updated to maximize the label\nlikelihood. Experiments are performed on WMT test sets with multiple metrics,\nand the experimental results demonstrate that \\model achieves substantially\nimproved performance across multiple translation directions and reduce the\noff-target phenomena in the translation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06745v1",
    "published_date": "2024-03-11 14:10:57 UTC",
    "updated_date": "2024-03-11 14:10:57 UTC"
  },
  {
    "arxiv_id": "2403.06735v1",
    "title": "Enhancing Image Caption Generation Using Reinforcement Learning with Human Feedback",
    "authors": [
      "Adarsh N L",
      "Arun P V",
      "Aravindh N L"
    ],
    "abstract": "Research on generative models to produce human-aligned / human-preferred\noutputs has seen significant recent contributions. Between text and\nimage-generative models, we narrowed our focus to text-based generative models,\nparticularly to produce captions for images that align with human preferences.\nIn this research, we explored a potential method to amplify the performance of\nthe Deep Neural Network Model to generate captions that are preferred by\nhumans. This was achieved by integrating Supervised Learning and Reinforcement\nLearning with Human Feedback (RLHF) using the Flickr8k dataset. Also, a novel\nloss function that is capable of optimizing the model based on human feedback\nis introduced. In this paper, we provide a concise sketch of our approach and\nresults, hoping to contribute to the ongoing advances in the field of\nhuman-aligned generative AI models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 Pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.06735v1",
    "published_date": "2024-03-11 13:57:05 UTC",
    "updated_date": "2024-03-11 13:57:05 UTC"
  },
  {
    "arxiv_id": "2403.06734v1",
    "title": "Real-Time Multimodal Cognitive Assistant for Emergency Medical Services",
    "authors": [
      "Keshara Weerasinghe",
      "Saahith Janapati",
      "Xueren Ge",
      "Sion Kim",
      "Sneha Iyer",
      "John A. Stankovic",
      "Homa Alemzadeh"
    ],
    "abstract": "Emergency Medical Services (EMS) responders often operate under\ntime-sensitive conditions, facing cognitive overload and inherent risks,\nrequiring essential skills in critical thinking and rapid decision-making. This\npaper presents CognitiveEMS, an end-to-end wearable cognitive assistant system\nthat can act as a collaborative virtual partner engaging in the real-time\nacquisition and analysis of multimodal data from an emergency scene and\ninteracting with EMS responders through Augmented Reality (AR) smart glasses.\nCognitiveEMS processes the continuous streams of data in real-time and\nleverages edge computing to provide assistance in EMS protocol selection and\nintervention recognition. We address key technical challenges in real-time\ncognitive assistance by introducing three novel components: (i) a Speech\nRecognition model that is fine-tuned for real-world medical emergency\nconversations using simulated EMS audio recordings, augmented with synthetic\ndata generated by large language models (LLMs); (ii) an EMS Protocol Prediction\nmodel that combines state-of-the-art (SOTA) tiny language models with EMS\ndomain knowledge using graph-based attention mechanisms; (iii) an EMS Action\nRecognition module which leverages multimodal audio and video data and protocol\npredictions to infer the intervention/treatment actions taken by the responders\nat the incident scene. Our results show that for speech recognition we achieve\nsuperior performance compared to SOTA (WER of 0.290 vs. 0.618) on\nconversational data. Our protocol prediction component also significantly\noutperforms SOTA (top-3 accuracy of 0.800 vs. 0.200) and the action recognition\nachieves an accuracy of 0.727, while maintaining an end-to-end latency of 3.78s\nfor protocol prediction on the edge and 0.31s on the server.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2403.06734v1",
    "published_date": "2024-03-11 13:56:57 UTC",
    "updated_date": "2024-03-11 13:56:57 UTC"
  },
  {
    "arxiv_id": "2403.06725v4",
    "title": "Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning",
    "authors": [
      "Hengyuan Zhang",
      "Zitao Liu",
      "Shuyan Huang",
      "Chenming Shang",
      "Bojun Zhan",
      "Yong Jiang"
    ],
    "abstract": "Knowledge tracing (KT) aims to estimate student's knowledge mastery based on\ntheir historical interactions. Recently, the deep learning based KT (DLKT)\napproaches have achieved impressive performance in the KT task. These DLKT\nmodels heavily rely on the large number of available student interactions.\nHowever, due to various reasons such as budget constraints and privacy\nconcerns, observed interactions are very limited in many real-world scenarios,\na.k.a, low-resource KT datasets. Directly training a DLKT model on a\nlow-resource KT dataset may lead to overfitting and it is difficult to choose\nthe appropriate deep neural architecture. Therefore, in this paper, we propose\na low-resource KT framework called LoReKT to address above challenges. Inspired\nby the prevalent \"pre-training and fine-tuning\" paradigm, we aim to learn\ntransferable parameters and representations from rich-resource KT datasets\nduring the pre-training stage and subsequently facilitate effective adaptation\nto low-resource KT datasets. Specifically, we simplify existing sophisticated\nDLKT model architectures with purely a stack of transformer decoders. We design\nan encoding mechanism to incorporate student interactions from multiple KT data\nsources and develop an importance mechanism to prioritize updating parameters\nwith high importance while constraining less important ones during the\nfine-tuning stage. We evaluate LoReKT on six public KT datasets and\nexperimental results demonstrate the superiority of our approach in terms of\nAUC and Accuracy. To encourage reproducible research, we make our data and code\npublicly available at https://github.com/rattlesnakey/LoReKT.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "29 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.06725v4",
    "published_date": "2024-03-11 13:44:43 UTC",
    "updated_date": "2024-10-25 10:20:22 UTC"
  },
  {
    "arxiv_id": "2403.06677v1",
    "title": "Streamlining in the Riemannian Realm: Efficient Riemannian Optimization with Loopless Variance Reduction",
    "authors": [
      "Yury Demidovich",
      "Grigory Malinovsky",
      "Peter Richtárik"
    ],
    "abstract": "In this study, we investigate stochastic optimization on Riemannian\nmanifolds, focusing on the crucial variance reduction mechanism used in both\nEuclidean and Riemannian settings. Riemannian variance-reduced methods usually\ninvolve a double-loop structure, computing a full gradient at the start of each\nloop. Determining the optimal inner loop length is challenging in practice, as\nit depends on strong convexity or smoothness constants, which are often unknown\nor hard to estimate. Motivated by Euclidean methods, we introduce the\nRiemannian Loopless SVRG (R-LSVRG) and PAGE (R-PAGE) methods. These methods\nreplace the outer loop with probabilistic gradient computation triggered by a\ncoin flip in each iteration, ensuring simpler proofs, efficient hyperparameter\nselection, and sharp convergence guarantees. Using R-PAGE as a framework for\nnon-convex Riemannian optimization, we demonstrate its applicability to various\nimportant settings. For example, we derive Riemannian MARINA (R-MARINA) for\ndistributed settings with communication compression, providing the best\ntheoretical communication complexity guarantees for non-convex distributed\noptimization over Riemannian manifolds. Experimental results support our\ntheoretical findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06677v1",
    "published_date": "2024-03-11 12:49:37 UTC",
    "updated_date": "2024-03-11 12:49:37 UTC"
  },
  {
    "arxiv_id": "2403.06675v1",
    "title": "Poisoning Programs by Un-Repairing Code: Security Concerns of AI-generated Code",
    "authors": [
      "Cristina Improta"
    ],
    "abstract": "AI-based code generators have gained a fundamental role in assisting\ndevelopers in writing software starting from natural language (NL). However,\nsince these large language models are trained on massive volumes of data\ncollected from unreliable online sources (e.g., GitHub, Hugging Face), AI\nmodels become an easy target for data poisoning attacks, in which an attacker\ncorrupts the training data by injecting a small amount of poison into it, i.e.,\nastutely crafted malicious samples. In this position paper, we address the\nsecurity of AI code generators by identifying a novel data poisoning attack\nthat results in the generation of vulnerable code. Next, we devise an extensive\nevaluation of how these attacks impact state-of-the-art models for code\ngeneration. Lastly, we discuss potential solutions to overcome this threat.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at The 1st IEEE International Workshop on Reliable and\n  Secure AI for Software Engineering (ReSAISE), co-located with ISSRE 2023",
    "pdf_url": "http://arxiv.org/pdf/2403.06675v1",
    "published_date": "2024-03-11 12:47:04 UTC",
    "updated_date": "2024-03-11 12:47:04 UTC"
  },
  {
    "arxiv_id": "2403.06674v1",
    "title": "Car Damage Detection and Patch-to-Patch Self-supervised Image Alignment",
    "authors": [
      "Hanxiao Chen"
    ],
    "abstract": "Most computer vision applications aim to identify pixels in a scene and use\nthem for diverse purposes. One intriguing application is car damage detection\nfor insurance carriers which tends to detect all car damages by comparing both\npre-trip and post-trip images, even requiring two components: (i) car damage\ndetection; (ii) image alignment. Firstly, we implemented a Mask R-CNN model to\ndetect car damages on custom images. Whereas for the image alignment section,\nwe especially propose a novel self-supervised Patch-to-Patch SimCLR inspired\nalignment approach to find perspective transformations between custom pre/post\ncar rental images except for traditional computer vision methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper has been accepted and given a poster presentation at\n  NeurIPS 2021 WiML Workshop\n  (https://nips.cc/virtual/2021/affinity-workshop/22882)",
    "pdf_url": "http://arxiv.org/pdf/2403.06674v1",
    "published_date": "2024-03-11 12:46:53 UTC",
    "updated_date": "2024-03-11 12:46:53 UTC"
  },
  {
    "arxiv_id": "2403.06670v2",
    "title": "CEAT: Continual Expansion and Absorption Transformer for Non-Exemplar Class-Incremental Learning",
    "authors": [
      "Xinyuan Gao",
      "Songlin Dong",
      "Yuhang He",
      "Xing Wei",
      "Yihong Gong"
    ],
    "abstract": "In real-world applications, dynamic scenarios require the models to possess\nthe capability to learn new tasks continuously without forgetting the old\nknowledge. Experience-Replay methods store a subset of the old images for joint\ntraining. In the scenario of more strict privacy protection, storing the old\nimages becomes infeasible, which leads to a more severe plasticity-stability\ndilemma and classifier bias. To meet the above challenges, we propose a new\narchitecture, named continual expansion and absorption transformer~(CEAT). The\nmodel can learn the novel knowledge by extending the expanded-fusion layers in\nparallel with the frozen previous parameters. After the task ends, we\nlosslessly absorb the extended parameters into the backbone to ensure that the\nnumber of parameters remains constant. To improve the learning ability of the\nmodel, we designed a novel prototype contrastive loss to reduce the overlap\nbetween old and new classes in the feature space. Besides, to address the\nclassifier bias towards the new classes, we propose a novel approach to\ngenerate the pseudo-features to correct the classifier. We experiment with our\nmethods on three standard Non-Exemplar Class-Incremental Learning~(NECIL)\nbenchmarks. Extensive experiments demonstrate that our model gets a significant\nimprovement compared with the previous works and achieves 5.38%, 5.20%, and\n4.92% improvement on CIFAR-100, TinyImageNet, and ImageNet-Subset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06670v2",
    "published_date": "2024-03-11 12:40:12 UTC",
    "updated_date": "2024-03-12 03:04:15 UTC"
  },
  {
    "arxiv_id": "2403.06660v1",
    "title": "FashionReGen: LLM-Empowered Fashion Report Generation",
    "authors": [
      "Yujuan Ding",
      "Yunshan Ma",
      "Wenqi Fan",
      "Yige Yao",
      "Tat-Seng Chua",
      "Qing Li"
    ],
    "abstract": "Fashion analysis refers to the process of examining and evaluating trends,\nstyles, and elements within the fashion industry to understand and interpret\nits current state, generating fashion reports. It is traditionally performed by\nfashion professionals based on their expertise and experience, which requires\nhigh labour cost and may also produce biased results for relying heavily on a\nsmall group of people. In this paper, to tackle the Fashion Report Generation\n(FashionReGen) task, we propose an intelligent Fashion Analyzing and Reporting\nsystem based the advanced Large Language Models (LLMs), debbed as GPT-FAR.\nSpecifically, it tries to deliver FashionReGen based on effective catwalk\nanalysis, which is equipped with several key procedures, namely, catwalk\nunderstanding, collective organization and analysis, and report generation. By\nposing and exploring such an open-ended, complex and domain-specific task of\nFashionReGen, it is able to test the general capability of LLMs in fashion\ndomain. It also inspires the explorations of more high-level tasks with\nindustrial significance in other domains. Video illustration and more materials\nof GPT-FAR can be found in https://github.com/CompFashion/FashionReGen.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06660v1",
    "published_date": "2024-03-11 12:29:35 UTC",
    "updated_date": "2024-03-11 12:29:35 UTC"
  },
  {
    "arxiv_id": "2403.06659v3",
    "title": "Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement",
    "authors": [
      "Che Liu",
      "Zhongwei Wan",
      "Cheng Ouyang",
      "Anand Shah",
      "Wenjia Bai",
      "Rossella Arcucci"
    ],
    "abstract": "Electrocardiograms (ECGs) are non-invasive diagnostic tools crucial for\ndetecting cardiac arrhythmic diseases in clinical practice. While ECG\nSelf-supervised Learning (eSSL) methods show promise in representation learning\nfrom unannotated ECG data, they often overlook the clinical knowledge that can\nbe found in reports. This oversight and the requirement for annotated samples\nfor downstream tasks limit eSSL's versatility. In this work, we address these\nissues with the Multimodal ECG Representation Learning (MERL}) framework.\nThrough multimodal learning on ECG records and associated reports, MERL is\ncapable of performing zero-shot ECG classification with text prompts,\neliminating the need for training data in downstream tasks. At test time, we\npropose the Clinical Knowledge Enhanced Prompt Engineering (CKEPE) approach,\nwhich uses Large Language Models (LLMs) to exploit external expert-verified\nclinical knowledge databases, generating more descriptive prompts and reducing\nhallucinations in LLM-generated content to boost zero-shot classification.\nBased on MERL, we perform the first benchmark across six public ECG datasets,\nshowing the superior performance of MERL compared against eSSL methods.\nNotably, MERL achieves an average AUC score of 75.2% in zero-shot\nclassification (without training data), 3.2% higher than linear probed eSSL\nmethods with 10\\% annotated training data, averaged across all six datasets.\nCode and models are available at https://github.com/cheliu-computation/MERL",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted by ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06659v3",
    "published_date": "2024-03-11 12:28:55 UTC",
    "updated_date": "2024-07-02 16:51:11 UTC"
  },
  {
    "arxiv_id": "2403.06642v2",
    "title": "TRAWL: External Knowledge-Enhanced Recommendation with LLM Assistance",
    "authors": [
      "Weiqing Luo",
      "Chonggang Song",
      "Lingling Yi",
      "Gong Cheng"
    ],
    "abstract": "Combining semantic information with behavioral data is a crucial research\narea in recommender systems. A promising approach involves leveraging external\nknowledge to enrich behavioral-based recommender systems with abundant semantic\ninformation. However, this approach faces two primary challenges: denoising raw\nexternal knowledge and adapting semantic representations. To address these\nchallenges, we propose an External Knowledge-Enhanced Recommendation method\nwith LLM Assistance (TRAWL). This method utilizes large language models (LLMs)\nto extract relevant recommendation knowledge from raw external data and employs\na contrastive learning strategy for adapter training. Experiments on public\ndatasets and real-world online recommender systems validate the effectiveness\nof our approach.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.06642v2",
    "published_date": "2024-03-11 12:04:20 UTC",
    "updated_date": "2024-05-24 09:09:35 UTC"
  },
  {
    "arxiv_id": "2403.08828v3",
    "title": "People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior: Insights from Cognitive Science for Explainable AI",
    "authors": [
      "Balint Gyevnar",
      "Stephanie Droop",
      "Tadeg Quillien",
      "Shay B. Cohen",
      "Neil R. Bramley",
      "Christopher G. Lucas",
      "Stefano V. Albrecht"
    ],
    "abstract": "It is often argued that effective human-centered explainable artificial\nintelligence (XAI) should resemble human reasoning. However, empirical\ninvestigations of how concepts from cognitive science can aid the design of XAI\nare lacking. Based on insights from cognitive science, we propose a framework\nof explanatory modes to analyze how people frame explanations, whether\nmechanistic, teleological, or counterfactual. Using the complex safety-critical\ndomain of autonomous driving, we conduct an experiment consisting of two\nstudies on (i) how people explain the behavior of a vehicle in 14 unique\nscenarios (N1=54) and (ii) how they perceive these explanations (N2=382),\ncurating the novel Human Explanations for Autonomous Driving Decisions (HEADD)\ndataset. Our main finding is that participants deem teleological explanations\nsignificantly better quality than counterfactual ones, with perceived teleology\nbeing the best predictor of perceived quality. Based on our results, we argue\nthat explanatory modes are an important axis of analysis when designing and\nevaluating XAI and highlight the need for a principled and empirically grounded\nunderstanding of the cognitive mechanisms of explanation. The HEADD dataset and\nour code are available at: https://datashare.ed.ac.uk/handle/10283/8930.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.08828v3",
    "published_date": "2024-03-11 11:48:50 UTC",
    "updated_date": "2025-02-03 21:49:26 UTC"
  },
  {
    "arxiv_id": "2403.06631v1",
    "title": "Evaluating the Energy Efficiency of Few-Shot Learning for Object Detection in Industrial Settings",
    "authors": [
      "Georgios Tsoumplekas",
      "Vladislav Li",
      "Ilias Siniosoglou",
      "Vasileios Argyriou",
      "Sotirios K. Goudos",
      "Ioannis D. Moscholios",
      "Panagiotis Radoglou-Grammatikis",
      "Panagiotis Sarigiannidis"
    ],
    "abstract": "In the ever-evolving era of Artificial Intelligence (AI), model performance\nhas constituted a key metric driving innovation, leading to an exponential\ngrowth in model size and complexity. However, sustainability and energy\nefficiency have been critical requirements during deployment in contemporary\nindustrial settings, necessitating the use of data-efficient approaches such as\nfew-shot learning. In this paper, to alleviate the burden of lengthy model\ntraining and minimize energy consumption, a finetuning approach to adapt\nstandard object detection models to downstream tasks is examined. Subsequently,\na thorough case study and evaluation of the energy demands of the developed\nmodels, applied in object detection benchmark datasets from volatile industrial\nenvironments is presented. Specifically, different finetuning strategies as\nwell as utilization of ancillary evaluation data during training are examined,\nand the trade-off between performance and efficiency is highlighted in this\nlow-data regime. Finally, this paper introduces a novel way to quantify this\ntrade-off through a customized Efficiency Factor metric.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.06631v1",
    "published_date": "2024-03-11 11:41:30 UTC",
    "updated_date": "2024-03-11 11:41:30 UTC"
  },
  {
    "arxiv_id": "2403.06621v1",
    "title": "Forest Inspection Dataset for Aerial Semantic Segmentation and Depth Estimation",
    "authors": [
      "Bianca-Cerasela-Zelia Blaga",
      "Sergiu Nedevschi"
    ],
    "abstract": "Humans use UAVs to monitor changes in forest environments since they are\nlightweight and provide a large variety of surveillance data. However, their\ninformation does not present enough details for understanding the scene which\nis needed to assess the degree of deforestation. Deep learning algorithms must\nbe trained on large amounts of data to output accurate interpretations, but\nground truth recordings of annotated forest imagery are not available. To solve\nthis problem, we introduce a new large aerial dataset for forest inspection\nwhich contains both real-world and virtual recordings of natural environments,\nwith densely annotated semantic segmentation labels and depth maps, taken in\ndifferent illumination conditions, at various altitudes and recording angles.\nWe test the performance of two multi-scale neural networks for solving the\nsemantic segmentation task (HRNet and PointFlow network), studying the impact\nof the various acquisition conditions and the capabilities of transfer learning\nfrom virtual to real data. Our results showcase that the best results are\nobtained when the training is done on a dataset containing a large variety of\nscenarios, rather than separating the data into specific categories. We also\ndevelop a framework to assess the deforestation degree of an area.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06621v1",
    "published_date": "2024-03-11 11:26:44 UTC",
    "updated_date": "2024-03-11 11:26:44 UTC"
  },
  {
    "arxiv_id": "2403.06611v1",
    "title": "MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding",
    "authors": [
      "Jiageng Wu",
      "Xian Wu",
      "Yefeng Zheng",
      "Jie Yang"
    ],
    "abstract": "With appropriate data selection and training techniques, Large Language\nModels (LLMs) have demonstrated exceptional success in various medical\nexaminations and multiple-choice questions. However, the application of LLMs in\nmedical dialogue generation-a task more closely aligned with actual medical\npractice-has been less explored. This gap is attributed to the insufficient\nmedical knowledge of LLMs, which leads to inaccuracies and hallucinated\ninformation in the generated medical responses. In this work, we introduce the\nMedical dialogue with Knowledge enhancement and clinical Pathway encoding\n(MedKP) framework, which integrates an external knowledge enhancement module\nthrough a medical knowledge graph and an internal clinical pathway encoding via\nmedical entities and physician actions. Evaluated with comprehensive metrics,\nour experiments on two large-scale, real-world online medical consultation\ndatasets (MedDG and KaMed) demonstrate that MedKP surpasses multiple baselines\nand mitigates the incidence of hallucinations, achieving a new\nstate-of-the-art. Extensive ablation studies further reveal the effectiveness\nof each component of MedKP. This enhancement advances the development of\nreliable, automated medical consultation responses using LLMs, thereby\nbroadening the potential accessibility of precise and real-time medical\nassistance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06611v1",
    "published_date": "2024-03-11 10:57:45 UTC",
    "updated_date": "2024-03-11 10:57:45 UTC"
  },
  {
    "arxiv_id": "2403.06609v2",
    "title": "Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds",
    "authors": [
      "Jiageng WU",
      "Xian Wu",
      "Jie Yang"
    ],
    "abstract": "Clinical reasoning refers to the cognitive process that physicians employ in\nevaluating and managing patients. This process typically involves suggesting\nnecessary examinations, diagnosing patients' diseases, and deciding on\nappropriate therapies, etc. Accurate clinical reasoning requires extensive\nmedical knowledge and rich clinical experience, setting a high bar for\nphysicians. This is particularly challenging in developing countries due to the\noverwhelming number of patients and limited physician resources, contributing\nsignificantly to global health inequity and necessitating automated clinical\nreasoning approaches. Recently, the emergence of large language models (LLMs)\nsuch as ChatGPT and GPT-4 have demonstrated their potential in clinical\nreasoning. However, these LLMs are prone to hallucination problems, and the\nreasoning process of LLMs may not align with the clinical decision path of\nphysicians. In this study, we introduce a novel framework, In-Context Padding\n(ICP), designed to enhance LLMs with medical knowledge. Specifically, we infer\ncritical clinical reasoning elements (referred to as knowledge seeds) and use\nthese as anchors to guide the generation process of LLMs. Experiments on two\nclinical question datasets demonstrate that ICP significantly improves the\nclinical reasoning ability of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06609v2",
    "published_date": "2024-03-11 10:53:20 UTC",
    "updated_date": "2024-06-08 04:14:46 UTC"
  },
  {
    "arxiv_id": "2403.06601v2",
    "title": "Cross-domain and Cross-dimension Learning for Image-to-Graph Transformers",
    "authors": [
      "Alexander H. Berger",
      "Laurin Lux",
      "Suprosanna Shit",
      "Ivan Ezhov",
      "Georgios Kaissis",
      "Martin J. Menten",
      "Daniel Rueckert",
      "Johannes C. Paetzold"
    ],
    "abstract": "Direct image-to-graph transformation is a challenging task that involves\nsolving object detection and relationship prediction in a single model. Due to\nthis task's complexity, large training datasets are rare in many domains,\nmaking the training of deep-learning methods challenging. This data sparsity\nnecessitates transfer learning strategies akin to the state-of-the-art in\ngeneral computer vision. In this work, we introduce a set of methods enabling\ncross-domain and cross-dimension learning for image-to-graph transformers. We\npropose (1) a regularized edge sampling loss to effectively learn object\nrelations in multiple domains with different numbers of edges, (2) a domain\nadaptation framework for image-to-graph transformers aligning image- and\ngraph-level features from different domains, and (3) a projection function that\nallows using 2D data for training 3D transformers. We demonstrate our method's\nutility in cross-domain and cross-dimension experiments, where we utilize\nlabeled data from 2D road networks for simultaneous learning in vastly\ndifferent target domains. Our method consistently outperforms standard transfer\nlearning and self-supervised pretraining on challenging benchmarks, such as\nretinal or whole-brain vessel graph extraction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06601v2",
    "published_date": "2024-03-11 10:48:56 UTC",
    "updated_date": "2024-12-05 15:19:47 UTC"
  },
  {
    "arxiv_id": "2403.06592v3",
    "title": "Exploiting Style Latent Flows for Generalizing Deepfake Video Detection",
    "authors": [
      "Jongwook Choi",
      "Taehoon Kim",
      "Yonghyun Jeong",
      "Seungryul Baek",
      "Jongwon Choi"
    ],
    "abstract": "This paper presents a new approach for the detection of fake videos, based on\nthe analysis of style latent vectors and their abnormal behavior in temporal\nchanges in the generated videos. We discovered that the generated facial videos\nsuffer from the temporal distinctiveness in the temporal changes of style\nlatent vectors, which are inevitable during the generation of temporally stable\nvideos with various facial expressions and geometric transformations. Our\nframework utilizes the StyleGRU module, trained by contrastive learning, to\nrepresent the dynamic properties of style latent vectors. Additionally, we\nintroduce a style attention module that integrates StyleGRU-generated features\nwith content-based features, enabling the detection of visual and temporal\nartifacts. We demonstrate our approach across various benchmark scenarios in\ndeepfake detection, showing its superiority in cross-dataset and\ncross-manipulation scenarios. Through further analysis, we also validate the\nimportance of using temporal changes of style latent vectors to improve the\ngenerality of deepfake video detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint version, final version will be available at\n  https://openaccess.thecvf.com The IEEE / CVF Computer Vision and Pattern\n  Recognition Conference (CVPR) (2024) Published by: IEEE & CVF",
    "pdf_url": "http://arxiv.org/pdf/2403.06592v3",
    "published_date": "2024-03-11 10:35:58 UTC",
    "updated_date": "2024-05-20 13:01:23 UTC"
  },
  {
    "arxiv_id": "2403.06586v2",
    "title": "ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models",
    "authors": [
      "Luca Arrotta",
      "Claudio Bettini",
      "Gabriele Civitarese",
      "Michele Fiori"
    ],
    "abstract": "Context-aware Human Activity Recognition (HAR) is a hot research area in\nmobile computing, and the most effective solutions in the literature are based\non supervised deep learning models. However, the actual deployment of these\nsystems is limited by the scarcity of labeled data that is required for\ntraining. Neuro-Symbolic AI (NeSy) provides an interesting research direction\nto mitigate this issue, by infusing common-sense knowledge about human\nactivities and the contexts in which they can be performed into HAR deep\nlearning classifiers. Existing NeSy methods for context-aware HAR rely on\nknowledge encoded in logic-based models (e.g., ontologies) whose design,\nimplementation, and maintenance to capture new activities and contexts require\nsignificant human engineering efforts, technical knowledge, and domain\nexpertise. Recent works show that pre-trained Large Language Models (LLMs)\neffectively encode common-sense knowledge about human activities. In this work,\nwe propose ContextGPT: a novel prompt engineering approach to retrieve from\nLLMs common-sense knowledge about the relationship between human activities and\nthe context in which they are performed. Unlike ontologies, ContextGPT requires\nlimited human effort and expertise. An extensive evaluation carried out on two\npublic datasets shows how a NeSy model obtained by infusing common-sense\nknowledge from ContextGPT is effective in data scarcity scenarios, leading to\nsimilar (and sometimes better) recognition rates than logic-based approaches\nwith a fraction of the effort.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06586v2",
    "published_date": "2024-03-11 10:32:23 UTC",
    "updated_date": "2025-03-20 18:38:58 UTC"
  },
  {
    "arxiv_id": "2403.06568v2",
    "title": "Better Understandings and Configurations in MaxSAT Local Search Solvers via Anytime Performance Analysis",
    "authors": [
      "Furong Ye",
      "Chuan Luo",
      "Shaowei Cai"
    ],
    "abstract": "Though numerous solvers have been proposed for the MaxSAT problem, and the\nbenchmark environment such as MaxSAT Evaluations provides a platform for the\ncomparison of the state-of-the-art solvers, existing assessments were usually\nevaluated based on the quality, e.g., fitness, of the best-found solutions\nobtained within a given running time budget. However, concerning solely the\nfinal obtained solutions regarding specific time budgets may restrict us from\ncomprehending the behavior of the solvers along the convergence process. This\npaper demonstrates that Empirical Cumulative Distribution Functions can be used\nto compare MaxSAT stochastic local search solvers' anytime performance across\nmultiple problem instances and various time budgets. The assessment reveals\ndistinctions in solvers' performance and displays that the (dis)advantages of\nsolvers adjust along different running times. This work also exhibits that the\nquantitative and high variance assessment of anytime performance can guide\nmachines, i.e., automatic configurators, to search for better parameter\nsettings. Our experimental results show that the hyperparameter optimization\ntool, i.e., SMAC, can achieve better parameter settings of solvers when using\nthe anytime performance as the cost function, compared to using the metrics\nbased on the fitness of the best-found solutions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06568v2",
    "published_date": "2024-03-11 10:10:35 UTC",
    "updated_date": "2025-02-04 10:41:51 UTC"
  },
  {
    "arxiv_id": "2403.07039v1",
    "title": "From English to ASIC: Hardware Implementation with Large Language Model",
    "authors": [
      "Emil Goh",
      "Maoyang Xiang",
      "I-Chyn Wey",
      "T. Hui Teo"
    ],
    "abstract": "In the realm of ASIC engineering, the landscape has been significantly\nreshaped by the rapid development of LLM, paralleled by an increase in the\ncomplexity of modern digital circuits. This complexity has escalated the\nrequirements for HDL coding, necessitating a higher degree of precision and\nsophistication. However, challenges have been faced due to the\nless-than-optimal performance of modern language models in generating hardware\ndescription code, a situation further exacerbated by the scarcity of the\ncorresponding high-quality code datasets. These challenges have highlighted the\ngap between the potential of LLMs to revolutionize digital circuit design and\ntheir current capabilities in accurately interpreting and implementing hardware\nspecifications. To address these challenges, a strategy focusing on the\nfine-tuning of the leading-edge nature language model and the reshuffling of\nthe HDL code dataset has been developed. The fine-tuning aims to enhance\nmodels' proficiency in generating precise and efficient ASIC design, while the\ndataset reshuffling is intended to broaden the scope and improve the quality of\ntraining material. The model demonstrated significant improvements compared to\nthe base model, with approximately 10% to 20% increase in accuracy across a\nwide range of temperature for the pass@1 metric. This approach is expected to\nfacilitate a simplified and more efficient LLM-assisted framework for complex\ncircuit design, leveraging their capabilities to meet the sophisticated demands\nof HDL coding and thus streamlining the ASIC development process.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AR",
    "comment": "15 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2403.07039v1",
    "published_date": "2024-03-11 09:57:16 UTC",
    "updated_date": "2024-03-11 09:57:16 UTC"
  },
  {
    "arxiv_id": "2403.06545v1",
    "title": "ReStainGAN: Leveraging IHC to IF Stain Domain Translation for in-silico Data Generation",
    "authors": [
      "Dominik Winter",
      "Nicolas Triltsch",
      "Philipp Plewa",
      "Marco Rosati",
      "Thomas Padel",
      "Ross Hill",
      "Markus Schick",
      "Nicolas Brieu"
    ],
    "abstract": "The creation of in-silico datasets can expand the utility of existing\nannotations to new domains with different staining patterns in computational\npathology. As such, it has the potential to significantly lower the cost\nassociated with building large and pixel precise datasets needed to train\nsupervised deep learning models. We propose a novel approach for the generation\nof in-silico immunohistochemistry (IHC) images by disentangling morphology\nspecific IHC stains into separate image channels in immunofluorescence (IF)\nimages. The proposed approach qualitatively and quantitatively outperforms\nbaseline methods as proven by training nucleus segmentation models on the\ncreated in-silico datasets.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.2.10, J.3, I.4.6"
    ],
    "primary_category": "eess.IV",
    "comment": "4 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2403.06545v1",
    "published_date": "2024-03-11 09:45:34 UTC",
    "updated_date": "2024-03-11 09:45:34 UTC"
  },
  {
    "arxiv_id": "2403.10544v1",
    "title": "Process-Aware Analysis of Treatment Paths in Heart Failure Patients: A Case Study",
    "authors": [
      "Harry H. Beyel",
      "Marlo Verket",
      "Viki Peeva",
      "Christian Rennert",
      "Marco Pegoraro",
      "Katharina Schütt",
      "Wil M. P. van der Aalst",
      "Nikolaus Marx"
    ],
    "abstract": "Process mining in healthcare presents a range of challenges when working with\ndifferent types of data within the healthcare domain. There is high diversity\nconsidering the variety of data collected from healthcare processes:\noperational processes given by claims data, a collection of events during\nsurgery, data related to pre-operative and post-operative care, and high-level\ndata collections based on regular ambulant visits with no apparent events. In\nthis case study, a data set from the last category is analyzed. We apply\nprocess-mining techniques on sparse patient heart failure data and investigate\nwhether an information gain towards several research questions is achievable.\nHere, available data are transformed into an event log format, and process\ndiscovery and conformance checking are applied. Additionally, patients are\nsplit into different cohorts based on comorbidities, such as diabetes and\nchronic kidney disease, and multiple statistics are compared between the\ncohorts. Conclusively, we apply decision mining to determine whether a patient\nwill have a cardiovascular outcome and whether a patient will die.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "10 pages, 3 figures, 9 tables, 31 references",
    "pdf_url": "http://arxiv.org/pdf/2403.10544v1",
    "published_date": "2024-03-11 09:33:21 UTC",
    "updated_date": "2024-03-11 09:33:21 UTC"
  },
  {
    "arxiv_id": "2403.06535v1",
    "title": "Decentralized and Lifelong-Adaptive Multi-Agent Collaborative Learning",
    "authors": [
      "Shuo Tang",
      "Rui Ye",
      "Chenxin Xu",
      "Xiaowen Dong",
      "Siheng Chen",
      "Yanfeng Wang"
    ],
    "abstract": "Decentralized and lifelong-adaptive multi-agent collaborative learning aims\nto enhance collaboration among multiple agents without a central server, with\neach agent solving varied tasks over time. To achieve efficient collaboration,\nagents should: i) autonomously identify beneficial collaborative relationships\nin a decentralized manner; and ii) adapt to dynamically changing task\nobservations. In this paper, we propose DeLAMA, a decentralized multi-agent\nlifelong collaborative learning algorithm with dynamic collaboration graphs. To\npromote autonomous collaboration relationship learning, we propose a\ndecentralized graph structure learning algorithm, eliminating the need for\nexternal priors. To facilitate adaptation to dynamic tasks, we design a memory\nunit to capture the agents' accumulated learning history and knowledge, while\npreserving finite storage consumption. To further augment the system's\nexpressive capabilities and computational efficiency, we apply algorithm\nunrolling, leveraging the advantages of both mathematical optimization and\nneural networks. This allows the agents to `learn to collaborate' through the\nsupervision of training tasks. Our theoretical analysis verifies that\ninter-agent collaboration is communication efficient under a small number of\ncommunication rounds. The experimental results verify its ability to facilitate\nthe discovery of collaboration strategies and adaptation to dynamic learning\nscenarios, achieving a 98.80% reduction in MSE and a 188.87% improvement in\nclassification accuracy. We expect our work can serve as a foundational\ntechnique to facilitate future works towards an intelligent, decentralized, and\ndynamic multi-agent system. Code is available at\nhttps://github.com/ShuoTang123/DeLAMA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.06535v1",
    "published_date": "2024-03-11 09:21:11 UTC",
    "updated_date": "2024-03-11 09:21:11 UTC"
  },
  {
    "arxiv_id": "2403.06534v2",
    "title": "SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection",
    "authors": [
      "Yuxuan Li",
      "Xiang Li",
      "Weijie Li",
      "Qibin Hou",
      "Li Liu",
      "Ming-Ming Cheng",
      "Jian Yang"
    ],
    "abstract": "Synthetic Aperture Radar (SAR) object detection has gained significant\nattention recently due to its irreplaceable all-weather imaging capabilities.\nHowever, this research field suffers from both limited public datasets (mostly\ncomprising <2K images with only mono-category objects) and inaccessible source\ncode. To tackle these challenges, we establish a new benchmark dataset and an\nopen-source method for large-scale SAR object detection. Our dataset,\nSARDet-100K, is a result of intense surveying, collecting, and standardizing 10\nexisting SAR detection datasets, providing a large-scale and diverse dataset\nfor research purposes. To the best of our knowledge, SARDet-100K is the first\nCOCO-level large-scale multi-class SAR object detection dataset ever created.\nWith this high-quality dataset, we conducted comprehensive experiments and\nuncovered a crucial challenge in SAR object detection: the substantial\ndisparities between the pretraining on RGB datasets and finetuning on SAR\ndatasets in terms of both data domain and model structure. To bridge these\ngaps, we propose a novel Multi-Stage with Filter Augmentation (MSFA)\npretraining framework that tackles the problems from the perspective of data\ninput, domain transition, and model migration. The proposed MSFA method\nsignificantly enhances the performance of SAR object detection models while\ndemonstrating exceptional generalizability and flexibility across diverse\nmodels. This work aims to pave the way for further advancements in SAR object\ndetection. The dataset and code is available at\nhttps://github.com/zcablii/SARDet_100K.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "22 Pages, 10 Figures, 9 Tables",
    "pdf_url": "http://arxiv.org/pdf/2403.06534v2",
    "published_date": "2024-03-11 09:20:40 UTC",
    "updated_date": "2024-09-30 08:38:28 UTC"
  },
  {
    "arxiv_id": "2403.06524v1",
    "title": "Tactical Decision Making for Autonomous Trucks by Deep Reinforcement Learning with Total Cost of Operation Based Reward",
    "authors": [
      "Deepthi Pathare",
      "Leo Laine",
      "Morteza Haghir Chehreghani"
    ],
    "abstract": "We develop a deep reinforcement learning framework for tactical decision\nmaking in an autonomous truck, specifically for Adaptive Cruise Control (ACC)\nand lane change maneuvers in a highway scenario. Our results demonstrate that\nit is beneficial to separate high-level decision-making processes and low-level\ncontrol actions between the reinforcement learning agent and the low-level\ncontrollers based on physical models. In the following, we study optimizing the\nperformance with a realistic and multi-objective reward function based on Total\nCost of Operation (TCOP) of the truck using different approaches; by adding\nweights to reward components, by normalizing the reward components and by using\ncurriculum learning techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06524v1",
    "published_date": "2024-03-11 08:58:42 UTC",
    "updated_date": "2024-03-11 08:58:42 UTC"
  },
  {
    "arxiv_id": "2403.06520v1",
    "title": "How to Understand Named Entities: Using Common Sense for News Captioning",
    "authors": [
      "Ning Xu",
      "Yanhui Wang",
      "Tingting Zhang",
      "Hongshuo Tian",
      "Mohan Kankanhalli",
      "An-An Liu"
    ],
    "abstract": "News captioning aims to describe an image with its news article body as\ninput. It greatly relies on a set of detected named entities, including\nreal-world people, organizations, and places. This paper exploits commonsense\nknowledge to understand named entities for news captioning. By ``understand'',\nwe mean correlating the news content with common sense in the wild, which helps\nan agent to 1) distinguish semantically similar named entities and 2) describe\nnamed entities using words outside of training corpora. Our approach consists\nof three modules: (a) Filter Module aims to clarify the common sense concerning\na named entity from two aspects: what does it mean? and what is it related to?,\nwhich divide the common sense into explanatory knowledge and relevant\nknowledge, respectively. (b) Distinguish Module aggregates explanatory\nknowledge from node-degree, dependency, and distinguish three aspects to\ndistinguish semantically similar named entities. (c) Enrich Module attaches\nrelevant knowledge to named entities to enrich the entity description by\ncommonsense information (e.g., identity and social position). Finally, the\nprobability distributions from both modules are integrated to generate the news\ncaptions. Extensive experiments on two challenging datasets (i.e., GoodNews and\nNYTimes) demonstrate the superiority of our method. Ablation studies and\nvisualization further validate its effectiveness in understanding named\nentities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06520v1",
    "published_date": "2024-03-11 08:52:52 UTC",
    "updated_date": "2024-03-11 08:52:52 UTC"
  },
  {
    "arxiv_id": "2403.06517v2",
    "title": "Active Generation for Image Classification",
    "authors": [
      "Tao Huang",
      "Jiaqi Liu",
      "Shan You",
      "Chang Xu"
    ],
    "abstract": "Recently, the growing capabilities of deep generative models have underscored\ntheir potential in enhancing image classification accuracy. However, existing\nmethods often demand the generation of a disproportionately large number of\nimages compared to the original dataset, while having only marginal\nimprovements in accuracy. This computationally expensive and time-consuming\nprocess hampers the practicality of such approaches. In this paper, we propose\nto address the efficiency of image generation by focusing on the specific needs\nand characteristics of the model. With a central tenet of active learning, our\nmethod, named ActGen, takes a training-aware approach to image generation. It\naims to create images akin to the challenging or misclassified samples\nencountered by the current model and incorporates these generated images into\nthe training set to augment model performance. ActGen introduces an attentive\nimage guidance technique, using real images as guides during the denoising\nprocess of a diffusion model. The model's attention on class prompt is\nleveraged to ensure the preservation of similar foreground object while\ndiversifying the background. Furthermore, we introduce a gradient-based\ngeneration guidance method, which employs two losses to generate more\nchallenging samples and prevent the generated images from being too similar to\npreviously generated ones. Experimental results on the CIFAR and ImageNet\ndatasets demonstrate that our method achieves better performance with a\nsignificantly reduced number of generated images. Code is available at\nhttps://github.com/hunto/ActGen.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06517v2",
    "published_date": "2024-03-11 08:45:31 UTC",
    "updated_date": "2024-08-15 05:04:21 UTC"
  },
  {
    "arxiv_id": "2403.06514v2",
    "title": "Structure Your Data: Towards Semantic Graph Counterfactuals",
    "authors": [
      "Angeliki Dimitriou",
      "Maria Lymperaiou",
      "Giorgos Filandrianos",
      "Konstantinos Thomas",
      "Giorgos Stamou"
    ],
    "abstract": "Counterfactual explanations (CEs) based on concepts are explanations that\nconsider alternative scenarios to understand which high-level semantic features\ncontributed to particular model predictions. In this work, we propose CEs based\non the semantic graphs accompanying input data to achieve more descriptive,\naccurate, and human-aligned explanations. Building upon state-of-the-art (SoTA)\nconceptual attempts, we adopt a model-agnostic edit-based approach and\nintroduce leveraging GNNs for efficient Graph Edit Distance (GED) computation.\nWith a focus on the visual domain, we represent images as scene graphs and\nobtain their GNN embeddings to bypass solving the NP-hard graph similarity\nproblem for all input pairs, an integral part of the CE computation process. We\napply our method to benchmark and real-world datasets with varying difficulty\nand availability of semantic annotations. Testing on diverse classifiers, we\nfind that our CEs outperform previous SoTA explanation models based on\nsemantics, including both white and black-box as well as conceptual and\npixel-level approaches. Their superiority is proven quantitatively and\nqualitatively, as validated by human subjects, highlighting the significance of\nleveraging semantic edges in the presence of intricate relationships. Our\nmodel-agnostic graph-based approach is widely applicable and easily extensible,\nproducing actionable explanations across different contexts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06514v2",
    "published_date": "2024-03-11 08:40:37 UTC",
    "updated_date": "2024-07-20 05:23:05 UTC"
  },
  {
    "arxiv_id": "2403.06483v2",
    "title": "The negation of permutation mass function",
    "authors": [
      "Yongchuan Tang",
      "Rongfei Li"
    ],
    "abstract": "Negation is an important perspective of knowledge representation. Existing\nnegation methods are mainly applied in probability theory, evidence theory and\ncomplex evidence theory. As a generalization of evidence theory, random\npermutation sets theory may represent information more precisely. However, how\nto apply the concept of negation to random permutation sets theory has not been\nstudied. In this paper, the negation of permutation mass function is proposed.\nMoreover, in the negation process, the convergence of proposed negation method\nis verified. The trends of uncertainty and dissimilarity after each negation\noperation are investigated. Numerical examples are used to demonstrate the\nrationality of the proposed method.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06483v2",
    "published_date": "2024-03-11 07:44:59 UTC",
    "updated_date": "2024-03-13 02:17:25 UTC"
  },
  {
    "arxiv_id": "2403.06479v2",
    "title": "Ada-Tracker: Soft Tissue Tracking via Inter-Frame and Adaptive-Template Matching",
    "authors": [
      "Jiaxin Guo",
      "Jiangliu Wang",
      "Zhaoshuo Li",
      "Tongyu Jia",
      "Qi Dou",
      "Yun-Hui Liu"
    ],
    "abstract": "Soft tissue tracking is crucial for computer-assisted interventions. Existing\napproaches mainly rely on extracting discriminative features from the template\nand videos to recover corresponding matches. However, it is difficult to adopt\nthese techniques in surgical scenes, where tissues are changing in shape and\nappearance throughout the surgery. To address this problem, we exploit optical\nflow to naturally capture the pixel-wise tissue deformations and adaptively\ncorrect the tracked template. Specifically, we first implement an inter-frame\nmatching mechanism to extract a coarse region of interest based on optical flow\nfrom consecutive frames. To accommodate appearance change and alleviate drift,\nwe then propose an adaptive-template matching method, which updates the tracked\ntemplate based on the reliability of the estimates. Our approach, Ada-Tracker,\nenjoys both short-term dynamics modeling by capturing local deformations and\nlong-term dynamics modeling by introducing global temporal compensation. We\nevaluate our approach on the public SurgT benchmark, which is generated from\nHamlyn, SCARED, and Kidney boundary datasets. The experimental results show\nthat Ada-Tracker achieves superior accuracy and performs more robustly against\nprior works. Code is available at https://github.com/wrld/Ada-Tracker.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE International Conference on Robotics and Automation (ICRA) 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06479v2",
    "published_date": "2024-03-11 07:42:40 UTC",
    "updated_date": "2024-05-24 08:01:56 UTC"
  },
  {
    "arxiv_id": "2403.06466v1",
    "title": "RL-MSA: a Reinforcement Learning-based Multi-line bus Scheduling Approach",
    "authors": [
      "Yingzhuo Liu"
    ],
    "abstract": "Multiple Line Bus Scheduling Problem (MLBSP) is vital to save operational\ncost of bus company and guarantee service quality for passengers. Existing\napproaches typically generate a bus scheduling scheme in an offline manner and\nthen schedule buses according to the scheme. In practice, uncertain events such\nas traffic congestion occur frequently, which may make the pre-determined bus\nscheduling scheme infeasible. In this paper, MLBSP is modeled as a Markov\nDecision Process (MDP). A Reinforcement Learning-based Multi-line bus\nScheduling Approach (RL-MSA) is proposed for bus scheduling at both the offline\nand online phases. At the offline phase, deadhead decision is integrated into\nbus selection decision for the first time to simplify the learning problem. At\nthe online phase, deadhead decision is made through a time window mechanism\nbased on the policy learned at the offline phase. We develop several new and\nuseful state features including the features for control points, bus lines and\nbuses. A bus priority screening mechanism is invented to construct bus-related\nfeatures. Considering the interests of both the bus company and passengers, a\nreward function combining the final reward and the step-wise reward is devised.\nExperiments at the offline phase demonstrate that the number of buses used of\nRL-MSA is decreased compared with offline optimization approaches. At the\nonline phase, RL-MSA can cover all departure times in a timetable (i.e.,\nservice quality) without increasing the number of buses used (i.e., operational\ncost).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06466v1",
    "published_date": "2024-03-11 07:07:05 UTC",
    "updated_date": "2024-03-11 07:07:05 UTC"
  },
  {
    "arxiv_id": "2403.06465v1",
    "title": "RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems",
    "authors": [
      "Jianxun Lian",
      "Yuxuan Lei",
      "Xu Huang",
      "Jing Yao",
      "Wei Xu",
      "Xing Xie"
    ],
    "abstract": "This paper introduces RecAI, a practical toolkit designed to augment or even\nrevolutionize recommender systems with the advanced capabilities of Large\nLanguage Models (LLMs). RecAI provides a suite of tools, including Recommender\nAI Agent, Recommendation-oriented Language Models, Knowledge Plugin,\nRecExplainer, and Evaluator, to facilitate the integration of LLMs into\nrecommender systems from multifaceted perspectives. The new generation of\nrecommender systems, empowered by LLMs, are expected to be more versatile,\nexplainable, conversational, and controllable, paving the way for more\nintelligent and user-centric recommendation experiences. We hope the\nopen-source of RecAI can help accelerate evolution of new advanced recommender\nsystems. The source code of RecAI is available at\n\\url{https://github.com/microsoft/RecAI}.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.IR",
    "comment": "4 pages. Webconf 2024 demo track",
    "pdf_url": "http://arxiv.org/pdf/2403.06465v1",
    "published_date": "2024-03-11 07:07:02 UTC",
    "updated_date": "2024-03-11 07:07:02 UTC"
  },
  {
    "arxiv_id": "2403.06448v2",
    "title": "Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models",
    "authors": [
      "Weihang Su",
      "Changyue Wang",
      "Qingyao Ai",
      "Yiran HU",
      "Zhijing Wu",
      "Yujia Zhou",
      "Yiqun Liu"
    ],
    "abstract": "Hallucinations in large language models (LLMs) refer to the phenomenon of\nLLMs producing responses that are coherent yet factually inaccurate. This issue\nundermines the effectiveness of LLMs in practical applications, necessitating\nresearch into detecting and mitigating hallucinations of LLMs. Previous studies\nhave mainly concentrated on post-processing techniques for hallucination\ndetection, which tend to be computationally intensive and limited in\neffectiveness due to their separation from the LLM's inference process. To\novercome these limitations, we introduce MIND, an unsupervised training\nframework that leverages the internal states of LLMs for real-time\nhallucination detection without requiring manual annotations. Additionally, we\npresent HELM, a new benchmark for evaluating hallucination detection across\nmultiple LLMs, featuring diverse LLM outputs and the internal states of LLMs\nduring their inference process. Our experiments demonstrate that MIND\noutperforms existing state-of-the-art methods in hallucination detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06448v2",
    "published_date": "2024-03-11 05:51:03 UTC",
    "updated_date": "2024-06-10 05:48:30 UTC"
  },
  {
    "arxiv_id": "2403.06447v1",
    "title": "CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation",
    "authors": [
      "Junda Wu",
      "Cheng-Chun Chang",
      "Tong Yu",
      "Zhankui He",
      "Jianing Wang",
      "Yupeng Hou",
      "Julian McAuley"
    ],
    "abstract": "The long-tail recommendation is a challenging task for traditional\nrecommender systems, due to data sparsity and data imbalance issues. The recent\ndevelopment of large language models (LLMs) has shown their abilities in\ncomplex reasoning, which can help to deduce users' preferences based on very\nfew previous interactions. However, since most LLM-based systems rely on items'\nsemantic meaning as the sole evidence for reasoning, the collaborative\ninformation of user-item interactions is neglected, which can cause the LLM's\nreasoning to be misaligned with task-specific collaborative information of the\ndataset. To further align LLMs' reasoning to task-specific user-item\ninteraction knowledge, we introduce collaborative retrieval-augmented LLMs,\nCoRAL, which directly incorporate collaborative evidence into the prompts.\nBased on the retrieved user-item interactions, the LLM can analyze shared and\ndistinct preferences among users, and summarize the patterns indicating which\ntypes of users would be attracted by certain items. The retrieved collaborative\nevidence prompts the LLM to align its reasoning with the user-item interaction\npatterns in the dataset. However, since the capacity of the input prompt is\nlimited, finding the minimally-sufficient collaborative information for\nrecommendation tasks can be challenging. We propose to find the optimal\ninteraction set through a sequential decision-making process and develop a\nretrieval policy learned through a reinforcement learning (RL) framework,\nCoRAL. Our experimental results show that CoRAL can significantly improve LLMs'\nreasoning abilities on specific recommendation tasks. Our analysis also reveals\nthat CoRAL can more efficiently explore collaborative information through\nreinforcement learning.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.06447v1",
    "published_date": "2024-03-11 05:49:34 UTC",
    "updated_date": "2024-03-11 05:49:34 UTC"
  },
  {
    "arxiv_id": "2403.07033v1",
    "title": "Interpreting What Typical Fault Signals Look Like via Prototype-matching",
    "authors": [
      "Qian Chen",
      "Xingjian Dong",
      "Zhike Peng"
    ],
    "abstract": "Neural networks, with powerful nonlinear mapping and classification\ncapabilities, are widely applied in mechanical fault diagnosis to ensure\nsafety. However, being typical black-box models, their application is limited\nin high-reliability-required scenarios. To understand the classification logic\nand explain what typical fault signals look like, the prototype matching\nnetwork (PMN) is proposed by combining the human-inherent prototype-matching\nwith autoencoder (AE). The PMN matches AE-extracted feature with each prototype\nand selects the most similar prototype as the prediction result. It has three\ninterpreting paths on classification logic, fault prototypes, and matching\ncontributions. Conventional diagnosis and domain generalization experiments\ndemonstrate its competitive diagnostic performance and distinguished advantages\nin representation learning. Besides, the learned typical fault signals (i.e.,\nsample-level prototypes) showcase the ability for denoising and extracting\nsubtle key features that experts find challenging to capture. This ability\nbroadens human understanding and provides a promising solution from\ninterpretability research to AI-for-Science.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 12 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.07033v1",
    "published_date": "2024-03-11 05:47:07 UTC",
    "updated_date": "2024-03-11 05:47:07 UTC"
  },
  {
    "arxiv_id": "2404.07941v1",
    "title": "SiGNN: A Spike-induced Graph Neural Network for Dynamic Graph Representation Learning",
    "authors": [
      "Dong Chen",
      "Shuai Zheng",
      "Muhao Xu",
      "Zhenfeng Zhu",
      "Yao Zhao"
    ],
    "abstract": "In the domain of dynamic graph representation learning (DGRL), the efficient\nand comprehensive capture of temporal evolution within real-world networks is\ncrucial. Spiking Neural Networks (SNNs), known as their temporal dynamics and\nlow-power characteristic, offer an efficient solution for temporal processing\nin DGRL task. However, owing to the spike-based information encoding mechanism\nof SNNs, existing DGRL methods employed SNNs face limitations in their\nrepresentational capacity. Given this issue, we propose a novel framework named\nSpike-induced Graph Neural Network (SiGNN) for learning enhanced\nspatialtemporal representations on dynamic graphs. In detail, a harmonious\nintegration of SNNs and GNNs is achieved through an innovative Temporal\nActivation (TA) mechanism. Benefiting from the TA mechanism, SiGNN not only\neffectively exploits the temporal dynamics of SNNs but also adeptly circumvents\nthe representational constraints imposed by the binary nature of spikes.\nFurthermore, leveraging the inherent adaptability of SNNs, we explore an\nin-depth analysis of the evolutionary patterns within dynamic graphs across\nmultiple time granularities. This approach facilitates the acquisition of a\nmultiscale temporal node representation.Extensive experiments on various\nreal-world dynamic graph datasets demonstrate the superior performance of SiGNN\nin the node classification task.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07941v1",
    "published_date": "2024-03-11 05:19:43 UTC",
    "updated_date": "2024-03-11 05:19:43 UTC"
  },
  {
    "arxiv_id": "2403.06433v1",
    "title": "Fine-Grained Pillar Feature Encoding Via Spatio-Temporal Virtual Grid for 3D Object Detection",
    "authors": [
      "Konyul Park",
      "Yecheol Kim",
      "Junho Koh",
      "Byungwoo Park",
      "Jun Won Choi"
    ],
    "abstract": "Developing high-performance, real-time architectures for LiDAR-based 3D\nobject detectors is essential for the successful commercialization of\nautonomous vehicles. Pillar-based methods stand out as a practical choice for\nonboard deployment due to their computational efficiency. However, despite\ntheir efficiency, these methods can sometimes underperform compared to\nalternative point encoding techniques such as Voxel-encoding or PointNet++. We\nargue that current pillar-based methods have not sufficiently captured the\nfine-grained distributions of LiDAR points within each pillar structure.\nConsequently, there exists considerable room for improvement in pillar feature\nencoding. In this paper, we introduce a novel pillar encoding architecture\nreferred to as Fine-Grained Pillar Feature Encoding (FG-PFE). FG-PFE utilizes\nSpatio-Temporal Virtual (STV) grids to capture the distribution of point clouds\nwithin each pillar across vertical, temporal, and horizontal dimensions.\nThrough STV grids, points within each pillar are individually encoded using\nVertical PFE (V-PFE), Temporal PFE (T-PFE), and Horizontal PFE (H-PFE). These\nencoded features are then aggregated through an Attentive Pillar Aggregation\nmethod. Our experiments conducted on the nuScenes dataset demonstrate that\nFG-PFE achieves significant performance improvements over baseline models such\nas PointPillar, CenterPoint-Pillar, and PillarNet, with only a minor increase\nin computational overhead.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06433v1",
    "published_date": "2024-03-11 04:58:36 UTC",
    "updated_date": "2024-03-11 04:58:36 UTC"
  },
  {
    "arxiv_id": "2403.07032v2",
    "title": "STARFlow: Spatial Temporal Feature Re-embedding with Attentive Learning for Real-world Scene Flow",
    "authors": [
      "Zhiyang Lu",
      "Qinghan Chen",
      "Ming Cheng"
    ],
    "abstract": "Scene flow prediction is a crucial underlying task in understanding dynamic\nscenes as it offers fundamental motion information. However, contemporary scene\nflow methods encounter three major challenges. Firstly, flow estimation solely\nbased on local receptive fields lacks long-dependency matching of point pairs.\nTo address this issue, we propose global attentive flow embedding to match\nall-to-all point pairs in both feature space and Euclidean space, providing\nglobal initialization before local refinement. Secondly, there are deformations\nexisting in non-rigid objects after warping, which leads to variations in the\nspatiotemporal relation between the consecutive frames. For a more precise\nestimation of residual flow, a spatial temporal feature re-embedding module is\ndevised to acquire the sequence features after deformation. Furthermore,\nprevious methods perform poor generalization due to the significant domain gap\nbetween the synthesized and LiDAR-scanned datasets. We leverage novel domain\nadaptive losses to effectively bridge the gap of motion inference from\nsynthetic to real-world. Experiments demonstrate that our approach achieves\nstate-of-the-art performance across various datasets, with particularly\noutstanding results on real-world LiDAR-scanned datasets. Our code is available\nat https://github.com/O-VIGIA/StarFlow.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper was renamed to:\"SSRFlow: Semantic-aware Fusion with\n  Spatial Temporal Re-embedding for Real-world Scene Flow\" [arXiv:2408.07825]\n  and was accepted in 3DV 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.07032v2",
    "published_date": "2024-03-11 04:56:10 UTC",
    "updated_date": "2024-11-14 06:36:57 UTC"
  },
  {
    "arxiv_id": "2403.06425v1",
    "title": "A Differential Geometric View and Explainability of GNN on Evolving Graphs",
    "authors": [
      "Yazheng Liu",
      "Xi Zhang",
      "Sihong Xie"
    ],
    "abstract": "Graphs are ubiquitous in social networks and biochemistry, where Graph Neural\nNetworks (GNN) are the state-of-the-art models for prediction. Graphs can be\nevolving and it is vital to formally model and understand how a trained GNN\nresponds to graph evolution. We propose a smooth parameterization of the GNN\npredicted distributions using axiomatic attribution, where the distributions\nare on a low-dimensional manifold within a high-dimensional embedding space. We\nexploit the differential geometric viewpoint to model distributional evolution\nas smooth curves on the manifold. We reparameterize families of curves on the\nmanifold and design a convex optimization problem to find a unique curve that\nconcisely approximates the distributional evolution for human interpretation.\nExtensive experiments on node classification, link prediction, and graph\nclassification tasks with evolving graphs demonstrate the better sparsity,\nfaithfulness, and intuitiveness of the proposed method over the\nstate-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted into ICLR 2023",
    "pdf_url": "http://arxiv.org/pdf/2403.06425v1",
    "published_date": "2024-03-11 04:26:18 UTC",
    "updated_date": "2024-03-11 04:26:18 UTC"
  },
  {
    "arxiv_id": "2403.12999v1",
    "title": "Prompt Selection and Augmentation for Few Examples Code Generation in Large Language Model and its Application in Robotics Control",
    "authors": [
      "On Tai Wu",
      "Frodo Kin Sun Chan",
      "Zunhao Zhang",
      "Yan Nei Law",
      "Benny Drescher",
      "Edmond Shiao Bun Lai"
    ],
    "abstract": "Few-shot prompting and step-by-step reasoning have enhanced the capabilities\nof Large Language Models (LLMs) in tackling complex tasks including code\ngeneration. In this paper, we introduce a prompt selection and augmentation\nalgorithm aimed at improving mathematical reasoning and robot arm operations.\nOur approach incorporates a multi-stage example augmentation scheme combined\nwith an example selection scheme. This algorithm improves LLM performance by\nselecting a set of examples that increase diversity, minimize redundancy, and\nincrease relevance to the question. When combined with the Program-of-Thought\nprompting, our algorithm demonstrates an improvement in performance on the\nGSM8K and SVAMP benchmarks, with increases of 0.3% and 1.1% respectively.\nFurthermore, in simulated tabletop environments, our algorithm surpasses the\nCode-as-Policies approach by achieving a 3.4% increase in successful task\ncompletions and a decrease of over 70% in the number of examples used. Its\nability to discard examples that contribute little to solving the problem\nreduces the inferencing time of an LLM-powered robotics system. This algorithm\nalso offers important benefits for industrial process automation by\nstreamlining the development and deployment process, reducing manual\nprogramming effort, and enhancing code reusability.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "17 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.12999v1",
    "published_date": "2024-03-11 04:13:29 UTC",
    "updated_date": "2024-03-11 04:13:29 UTC"
  },
  {
    "arxiv_id": "2403.06420v2",
    "title": "RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models",
    "authors": [
      "Liangliang Chen",
      "Yutian Lei",
      "Shiyu Jin",
      "Ying Zhang",
      "Liangjun Zhang"
    ],
    "abstract": "Reinforcement learning (RL) has demonstrated its capability in solving\nvarious tasks but is notorious for its low sample efficiency. In this paper, we\npropose RLingua, a framework that can leverage the internal knowledge of large\nlanguage models (LLMs) to reduce the sample complexity of RL in robotic\nmanipulations. To this end, we first present a method for extracting the prior\nknowledge of LLMs by prompt engineering so that a preliminary rule-based robot\ncontroller for a specific task can be generated in a user-friendly manner.\nDespite being imperfect, the LLM-generated robot controller is utilized to\nproduce action samples during rollouts with a decaying probability, thereby\nimproving RL's sample efficiency. We employ TD3, the widely-used RL baseline\nmethod, and modify the actor loss to regularize the policy learning towards the\nLLM-generated controller. RLingua also provides a novel method of improving the\nimperfect LLM-generated robot controllers by RL. We demonstrate that RLingua\ncan significantly reduce the sample complexity of TD3 in four robot tasks of\npanda_gym and achieve high success rates in 12 sampled sparsely rewarded robot\ntasks in RLBench, where the standard TD3 fails. Additionally, We validated\nRLingua's effectiveness in real-world robot experiments through Sim2Real,\ndemonstrating that the learned policies are effectively transferable to real\nrobot tasks. Further details about our work are available at our project\nwebsite https://rlingua.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06420v2",
    "published_date": "2024-03-11 04:13:26 UTC",
    "updated_date": "2024-03-19 17:52:09 UTC"
  },
  {
    "arxiv_id": "2403.06410v1",
    "title": "A Logical Pattern Memory Pre-trained Model for Entailment Tree Generation",
    "authors": [
      "Li Yuan",
      "Yi Cai",
      "Haopeng Ren",
      "Jiexin Wang"
    ],
    "abstract": "Generating coherent and credible explanations remains a significant challenge\nin the field of AI. In recent years, researchers have delved into the\nutilization of entailment trees to depict explanations, which exhibit a\nreasoning process of how a hypothesis is deduced from the supporting facts.\nHowever, existing models often overlook the importance of generating\nintermediate conclusions with logical consistency from the given facts, leading\nto inaccurate conclusions and undermining the overall credibility of entailment\ntrees. To address this limitation, we propose the logical pattern memory\npre-trained model (LMPM). LMPM incorporates an external memory structure to\nlearn and store the latent representations of logical patterns, which aids in\ngenerating logically consistent conclusions. Furthermore, to mitigate the\ninfluence of logically irrelevant domain knowledge in the Wikipedia-based data,\nwe introduce an entity abstraction approach to construct the dataset for\npre-training LMPM. The experimental results highlight the effectiveness of our\napproach in improving the quality of entailment tree generation. By leveraging\nlogical entailment patterns, our model produces more coherent and reasonable\nconclusions that closely align with the underlying premises. Code and Data are\nreleased at https://github.com/YuanLi95/T5-LMPM",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted By Coling 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06410v1",
    "published_date": "2024-03-11 03:45:09 UTC",
    "updated_date": "2024-03-11 03:45:09 UTC"
  },
  {
    "arxiv_id": "2403.06408v1",
    "title": "What Makes Quantization for Large Language Models Hard? An Empirical Study from the Lens of Perturbation",
    "authors": [
      "Zhuocheng Gong",
      "Jiahao Liu",
      "Jingang Wang",
      "Xunliang Cai",
      "Dongyan Zhao",
      "Rui Yan"
    ],
    "abstract": "Quantization has emerged as a promising technique for improving the memory\nand computational efficiency of large language models (LLMs). Though the\ntrade-off between performance and efficiency is well-known, there is still much\nto be learned about the relationship between quantization and LLM performance.\nTo shed light on this relationship, we propose a new perspective on\nquantization, viewing it as perturbations added to the weights and activations\nof LLMs. We call this approach \"the lens of perturbation\". Using this lens, we\nconduct experiments with various artificial perturbations to explore their\nimpact on LLM performance. Our findings reveal several connections between the\nproperties of perturbations and LLM performance, providing insights into the\nfailure cases of uniform quantization and suggesting potential solutions to\nimprove the robustness of LLM quantization. To demonstrate the significance of\nour findings, we implement a simple non-uniform quantization approach based on\nour insights. Our experiments show that this approach achieves minimal\nperformance degradation on both 4-bit weight quantization and 8-bit\nquantization for weights and activations. These results validate the\ncorrectness of our approach and highlight its potential to improve the\nefficiency of LLMs without sacrificing performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06408v1",
    "published_date": "2024-03-11 03:42:51 UTC",
    "updated_date": "2024-03-11 03:42:51 UTC"
  },
  {
    "arxiv_id": "2403.09712v1",
    "title": "A Knowledge-Injected Curriculum Pretraining Framework for Question Answering",
    "authors": [
      "Xin Lin",
      "Tianhuang Su",
      "Zhenya Huang",
      "Shangzi Xue",
      "Haifeng Liu",
      "Enhong Chen"
    ],
    "abstract": "Knowledge-based question answering (KBQA) is a key task in NLP research, and\nalso an approach to access the web data and knowledge, which requires\nexploiting knowledge graphs (KGs) for reasoning. In the literature, one\npromising solution for KBQA is to incorporate the pretrained language model\n(LM) with KGs by generating KG-centered pretraining corpus, which has shown its\nsuperiority. However, these methods often depend on specific techniques and\nresources to work, which may not always be available and restrict its\napplication. Moreover, existing methods focus more on improving language\nunderstanding with KGs, while neglect the more important human-like complex\nreasoning. To this end, in this paper, we propose a general Knowledge-Injected\nCurriculum Pretraining framework (KICP) to achieve comprehensive KG learning\nand exploitation for KBQA tasks, which is composed of knowledge injection (KI),\nknowledge adaptation (KA) and curriculum reasoning (CR). Specifically, the KI\nmodule first injects knowledge into the LM by generating KG-centered\npretraining corpus, and generalizes the process into three key steps that could\nwork with different implementations for flexible application. Next, the KA\nmodule learns knowledge from the generated corpus with LM equipped with an\nadapter as well as keeps its original natural language understanding ability to\nreduce the negative impacts of the difference between the generated and natural\ncorpus. Last, to enable the LM with complex reasoning, the CR module follows\nhuman reasoning patterns to construct three corpora with increasing\ndifficulties of reasoning, and further trains the LM from easy to hard in a\ncurriculum manner. We provide an implementation of the general framework, and\nevaluate the proposed KICP on four real-word datasets. The results demonstrate\nthat our framework can achieve higher performances.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.09712v1",
    "published_date": "2024-03-11 03:42:03 UTC",
    "updated_date": "2024-03-11 03:42:03 UTC"
  },
  {
    "arxiv_id": "2403.06398v3",
    "title": "On the Diminishing Returns of Width for Continual Learning",
    "authors": [
      "Etash Guha",
      "Vihan Lakshman"
    ],
    "abstract": "While deep neural networks have demonstrated groundbreaking performance in\nvarious settings, these models often suffer from \\emph{catastrophic forgetting}\nwhen trained on new tasks in sequence. Several works have empirically\ndemonstrated that increasing the width of a neural network leads to a decrease\nin catastrophic forgetting but have yet to characterize the exact relationship\nbetween width and continual learning. We design one of the first frameworks to\nanalyze Continual Learning Theory and prove that width is directly related to\nforgetting in Feed-Forward Networks (FFN). Specifically, we demonstrate that\nincreasing network widths to reduce forgetting yields diminishing returns. We\nempirically verify our claims at widths hitherto unexplored in prior studies\nwhere the diminishing returns are clearly observed as predicted by our theory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages. ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.06398v3",
    "published_date": "2024-03-11 03:19:45 UTC",
    "updated_date": "2024-06-18 21:22:10 UTC"
  },
  {
    "arxiv_id": "2403.06397v2",
    "title": "DeepSafeMPC: Deep Learning-Based Model Predictive Control for Safe Multi-Agent Reinforcement Learning",
    "authors": [
      "Xuefeng Wang",
      "Henglin Pu",
      "Hyung Jun Kim",
      "Husheng Li"
    ],
    "abstract": "Safe Multi-agent reinforcement learning (safe MARL) has increasingly gained\nattention in recent years, emphasizing the need for agents to not only optimize\nthe global return but also adhere to safety requirements through behavioral\nconstraints. Some recent work has integrated control theory with multi-agent\nreinforcement learning to address the challenge of ensuring safety. However,\nthere have been only very limited applications of Model Predictive Control\n(MPC) methods in this domain, primarily due to the complex and implicit\ndynamics characteristic of multi-agent environments. To bridge this gap, we\npropose a novel method called Deep Learning-Based Model Predictive Control for\nSafe Multi-Agent Reinforcement Learning (DeepSafeMPC). The key insight of\nDeepSafeMPC is leveraging a entralized deep learning model to well predict\nenvironmental dynamics. Our method applies MARL principles to search for\noptimal solutions. Through the employment of MPC, the actions of agents can be\nrestricted within safe states concurrently. We demonstrate the effectiveness of\nour approach using the Safe Multi-agent MuJoCo environment, showcasing\nsignificant advancements in addressing safety concerns in MARL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.06397v2",
    "published_date": "2024-03-11 03:17:33 UTC",
    "updated_date": "2024-03-12 02:13:51 UTC"
  },
  {
    "arxiv_id": "2403.06382v1",
    "title": "Pre-Trained Model Recommendation for Downstream Fine-tuning",
    "authors": [
      "Jiameng Bai",
      "Sai Wu",
      "Jie Song",
      "Junbo Zhao",
      "Gang Chen"
    ],
    "abstract": "As a fundamental problem in transfer learning, model selection aims to rank\noff-the-shelf pre-trained models and select the most suitable one for the new\ntarget task. Existing model selection techniques are often constrained in their\nscope and tend to overlook the nuanced relationships between models and tasks.\nIn this paper, we present a pragmatic framework \\textbf{Fennec}, delving into a\ndiverse, large-scale model repository while meticulously considering the\nintricate connections between tasks and models. The key insight is to map all\nmodels and historical tasks into a transfer-related subspace, where the\ndistance between model vectors and task vectors represents the magnitude of\ntransferability. A large vision model, as a proxy, infers a new task's\nrepresentation in the transfer space, thereby circumventing the computational\nburden of extensive forward passes. We also investigate the impact of the\ninherent inductive bias of models on transfer results and propose a novel\nmethod called \\textbf{archi2vec} to encode the intricate structures of models.\nThe transfer score is computed through straightforward vector arithmetic with a\ntime complexity of $\\mathcal{O}(1)$. Finally, we make a substantial\ncontribution to the field by releasing a comprehensive benchmark. We validate\nthe effectiveness of our framework through rigorous testing on two benchmarks.\nThe benchmark and the code will be publicly available in the near future.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06382v1",
    "published_date": "2024-03-11 02:24:32 UTC",
    "updated_date": "2024-03-11 02:24:32 UTC"
  },
  {
    "arxiv_id": "2403.07028v1",
    "title": "An Efficient Learning-based Solver Comparable to Metaheuristics for the Capacitated Arc Routing Problem",
    "authors": [
      "Runze Guo",
      "Feng Xue",
      "Anlong Ming",
      "Nicu Sebe"
    ],
    "abstract": "Recently, neural networks (NN) have made great strides in combinatorial\noptimization. However, they face challenges when solving the capacitated arc\nrouting problem (CARP) which is to find the minimum-cost tour covering all\nrequired edges on a graph, while within capacity constraints. In tackling CARP,\nNN-based approaches tend to lag behind advanced metaheuristics, since they lack\ndirected arc modeling and efficient learning methods tailored for complex CARP.\nIn this paper, we introduce an NN-based solver to significantly narrow the gap\nwith advanced metaheuristics while exhibiting superior efficiency. First, we\npropose the direction-aware attention model (DaAM) to incorporate\ndirectionality into the embedding process, facilitating more effective\none-stage decision-making. Second, we design a supervised reinforcement\nlearning scheme that involves supervised pre-training to establish a robust\ninitial policy for subsequent reinforcement fine-tuning. It proves particularly\nvaluable for solving CARP that has a higher complexity than the node routing\nproblems (NRPs). Finally, a path optimization method is proposed to adjust the\ndepot return positions within the path generated by DaAM. Experiments\nillustrate that our approach surpasses heuristics and achieves decision quality\ncomparable to state-of-the-art metaheuristics for the first time while\nmaintaining superior efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07028v1",
    "published_date": "2024-03-11 02:17:42 UTC",
    "updated_date": "2024-03-11 02:17:42 UTC"
  },
  {
    "arxiv_id": "2403.06360v1",
    "title": "Human and Automatic Interpretation of Romanian Noun Compounds",
    "authors": [
      "Ioana Marinescu",
      "Christiane Fellbaum"
    ],
    "abstract": "Determining the intended, context-dependent meanings of noun compounds like\n\"shoe sale\" and \"fire sale\" remains a challenge for NLP. Previous work has\nrelied on inventories of semantic relations that capture the different meanings\nbetween compound members. Focusing on Romanian compounds, whose morphosyntax\ndiffers from that of their English counterparts, we propose a new set of\nrelations and test it with human annotators and a neural net classifier.\nResults show an alignment of the network's predictions and human judgments,\neven where the human agreement rate is low. Agreement tracks with the frequency\nof the selected relations, regardless of structural differences. However, the\nmost frequently selected relation was none of the sixteen labeled semantic\nrelations, indicating the need for a better relation inventory.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.06360v1",
    "published_date": "2024-03-11 01:18:00 UTC",
    "updated_date": "2024-03-11 01:18:00 UTC"
  },
  {
    "arxiv_id": "2403.06356v1",
    "title": "Video Generation with Consistency Tuning",
    "authors": [
      "Chaoyi Wang",
      "Yaozhe Song",
      "Yafeng Zhang",
      "Jun Pei",
      "Lijie Xia",
      "Jianpo Liu"
    ],
    "abstract": "Currently, various studies have been exploring generation of long videos.\nHowever, the generated frames in these videos often exhibit jitter and noise.\nTherefore, in order to generate the videos without these noise, we propose a\nnovel framework composed of four modules: separate tuning module, average\nfusion module, combined tuning module, and inter-frame consistency module. By\napplying our newly proposed modules subsequently, the consistency of the\nbackground and foreground in each video frames is optimized. Besides, the\nexperimental results demonstrate that videos generated by our method exhibit a\nhigh quality in comparison of the state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06356v1",
    "published_date": "2024-03-11 01:11:28 UTC",
    "updated_date": "2024-03-11 01:11:28 UTC"
  },
  {
    "arxiv_id": "2403.06349v1",
    "title": "MOAB: Multi-Modal Outer Arithmetic Block For Fusion Of Histopathological Images And Genetic Data For Brain Tumor Grading",
    "authors": [
      "Omnia Alwazzan",
      "Abbas Khan",
      "Ioannis Patras",
      "Gregory Slabaugh"
    ],
    "abstract": "Brain tumors are an abnormal growth of cells in the brain. They can be\nclassified into distinct grades based on their growth. Often grading is\nperformed based on a histological image and is one of the most significant\npredictors of a patients prognosis, the higher the grade, the more aggressive\nthe tumor. Correct diagnosis of a tumor grade remains challenging. Though\nhistopathological grading has been shown to be prognostic, results are subject\nto interobserver variability, even among experienced pathologists. Recently,\nthe World Health Organization reported that advances in molecular genetics have\nled to improvements in tumor classification. This paper seeks to integrate\nhistological images and genetic data for improved computer-aided diagnosis. We\npropose a novel Multi-modal Outer Arithmetic Block (MOAB) based on arithmetic\noperations to combine latent representations of the different modalities for\npredicting the tumor grade (Grade \\rom{2}, \\rom{3} and \\rom{4}). Extensive\nexperiments evaluate the effectiveness of our approach. By applying MOAB to The\nCancer Genome Atlas (TCGA) glioma dataset, we show that it can improve\nseparation between similar classes (Grade \\rom{2} and \\rom{3}) and outperform\nprior state-of-the-art grade classification techniques.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06349v1",
    "published_date": "2024-03-11 00:33:28 UTC",
    "updated_date": "2024-03-11 00:33:28 UTC"
  }
]