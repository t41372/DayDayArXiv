{
  "date": "2024-03-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-11 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 应用创新，包括大型语言模型（LLM）的优化与伦理挑战、医疗图像处理与诊断、强化学习在机器人控制中的进展，以及知识图谱和图神经网络的改进，其中令人印象深刻的是 Weixin Liang 等人的 AI 修改内容监控研究，以及医疗领域的多模态学习方法，这些论文展示了 AI 在实际场景中的潜力。\n\n### 重点论文讨论\n我们挑选了今天最有影响力和话题度的论文进行详细讨论，将相关主题归类，先聊 AI 和 LLM 相关的，再聊医疗和机器人领域，最后快速掠过其他次要论文。以下是核心摘要，强调主要贡献和发现。\n\n#### AI 和 LLM 相关\n- **Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews**（中文：大规模监控 AI 修改内容：ChatGPT 对 AI 会议同行评审影响的案例研究；英文：Monitoring AI-Modified Content at Scale）  \n  Weixin Liang 等人的研究使用最大似然模型估计 LLM（如 ChatGPT）修改文本的比例，分析了 ICLR 2024 等会议的同行评审，发现 6.5% 到 16.9% 的文本可能被 LLM 显著修改，主要贡献在于揭示 LLM 在学术评审中的潜在风险，并强调了低置信度评审和截止期限临近的文本更容易受影响，这对 AI 伦理和学术诚信有重要启示。\n\n- **An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models**（中文：图像在第 2 层后仅值 1/2 标记：用于大型视觉语言模型的即插即用推理加速；英文：An Image is Worth 1/2 Tokens After Layer 2）  \n  这篇论文提出 FastV 框架，通过学习自适应注意力模式减少视觉标记计算，显著加速 LVLMs（如 LLaVA-1.5）的推理过程。主要发现是，在保持性能的前提下，FLOPs 减少 45%，并在图像和视频任务中表现出色，展示了高效视觉语言模型部署的潜力。\n\n- **The pitfalls of next-token prediction**（中文：下一标记预测的陷阱；英文：The pitfalls of next-token prediction）  \n  作者分析了 Transformer 和 Mamba 模型在下一标记预测中的失败，提出多标记预测作为改进。主要贡献是揭示训练时无法学习准确预测的根本问题，并通过实验验证了新方法的有效性，这对 LLM 的设计和优化有重要启示。\n\n- **Impact of Noisy Supervision in Foundation Model Learning**（中文：噪声监督对基础模型学习的影响；英文：Impact of Noisy Supervision in Foundation Model Learning）  \n  这篇论文探讨了噪声标签对基础模型（如视觉和语言模型）的影响，发现噪声可改善同域性能但损害异域性能。主要发现是通过新框架 NMTune 减轻噪声影响，提升模型鲁棒性，适用于大规模预训练场景。\n\n#### 医疗 AI 相关\n- **A multi-cohort study on prediction of acute brain dysfunction states using selective state space models**（中文：使用选择性状态空间模型预测急性脑功能障碍的多队列研究；英文：A multi-cohort study on prediction of acute brain dysfunction states）  \n  研究使用 MAMBA 模型从 EHR 数据动态预测 ICU 中的谵妄、昏迷和死亡，AUROC 达 0.95。主要贡献是填补了现有模型的空白，实现 12 小时间隔预测，并验证了在多个公共数据集上的鲁棒性，这对临床实时监控有实际价值。\n\n- **Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting**（中文：通过细粒度图像-文本对齐和解剖-病理提示的医疗图像合成；英文：Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting）  \n  论文提出框架使用解剖-病理提示和视觉代码本合成高精度医疗图像（如胸部 X 光），主要发现是提升了图像的语义对齐，在 TIFA 和 DSG 基准上性能提升 2.1% 和 6.9%，这有助于解决医疗数据稀缺问题。\n\n- **Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds**（中文：通过知识种子引导大型语言模型的临床推理；英文：Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds）  \n  该工作使用 LLM 生成知识种子指导临床决策，主要贡献是提升了模型在医疗任务中的准确性，并在数据集上表现出色，强调了 LLM 在减少医疗错误中的潜力。\n\n#### 机器人和强化学习相关\n- **DeepSafeMPC: Deep Learning-Based Model Predictive Control for Safe Multi-Agent Reinforcement Learning**（中文：基于深度学习的模型预测控制用于安全多代理强化学习；英文：DeepSafeMPC: Deep Learning-Based Model Predictive Control for Safe Multi-Agent Reinforcement Learning）  \n  论文引入 DeepSafeMPC 框架结合深度学习和 MPC，确保多代理 RL 的安全性，主要发现是在安全约束下优化全局回报，实验证明在模拟环境中显著提升任务完成率。\n\n- **RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models**（中文：使用大型语言模型提升机器人操作中强化学习的样本效率；英文：RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models）  \n  该研究利用 LLM 生成初步控制器提升 RL 效率，主要贡献是减少样本需求，并在 RLBench 数据集上成功率提升 70%，证明了 LLM 在机器人任务中的实用性。\n\n#### 其他快速掠过\n剩余论文涉及知识图谱、图神经网络和图像生成等，但多为技术性较强的次要工作，仅简要提及：\n- **Noise-powered Multi-modal Knowledge Graph Representation Framework**（中文：噪声驱动的多模态知识图谱表示框架；英文：Noise-powered Multi-modal Knowledge Graph Representation Framework）：提出 SNAG 方法提升知识图谱表示，SOTA 性能。\n- **SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection**（中文：面向大规模 SAR 对象检测的开源基准和工具包；英文：SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection）：发布新数据集和方法，提升 SAR 检测准确性。\n- 其他如 **Algorithmic Bayesian Epistemology**（理论认识论）、**CuentosIE**（情感智能聊天机器人）和 **Rebuilding ROME**（模型编辑）等，贡献在于基础理论或特定应用，但影响力较小，故从简。\n\n今天的 arXiv 更新展示了 AI 在多领域的潜力，但也提醒我们关注效率、伦理和实际部署挑战。更多细节请查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2403.07949v1",
      "title": "Algorithmic Bayesian Epistemology",
      "title_zh": "算法贝叶斯认识论",
      "authors": [
        "Eric Neyman"
      ],
      "abstract": "One aspect of the algorithmic lens in theoretical computer science is a view\non other scientific disciplines that focuses on satisfactory solutions that\nadhere to real-world constraints, as opposed to solutions that would be optimal\nignoring such constraints. The algorithmic lens has provided a unique and\nimportant perspective on many academic fields, including molecular biology,\necology, neuroscience, quantum physics, economics, and social science.\n  This thesis applies the algorithmic lens to Bayesian epistemology.\nTraditional Bayesian epistemology provides a comprehensive framework for how an\nindividual's beliefs should evolve upon receiving new information. However,\nthese methods typically assume an exhaustive model of such information,\nincluding the correlation structure between different pieces of evidence. In\nreality, individuals might lack such an exhaustive model, while still needing\nto form beliefs. Beyond such informational constraints, an individual may be\nbounded by limited computation, or by limited communication with agents that\nhave access to information, or by the strategic behavior of such agents. Even\nwhen these restrictions prevent the formation of a *perfectly* accurate belief,\narriving at a *reasonably* accurate belief remains crucial. In this thesis, we\nestablish fundamental possibility and impossibility results about belief\nformation under a variety of restrictions, and lay the groundwork for further\nexploration.",
      "tldr_zh": "这篇论文通过algorithmic lens视角审视Bayesian epistemology，强调在现实约束下形成满意信念的重要性，而不是追求忽略约束的最优解。传统Bayesian epistemology假设详尽的信息模型，但实际中个体可能面临信息缺失、计算限制、通信障碍或战略行为的影响。论文建立了信念形成的基本可能性和不可能性结果，并为该领域进一步探索奠定基础。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "385 pages, PhD thesis, 14 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.07949v1",
      "published_date": "2024-03-11 23:03:04 UTC",
      "updated_date": "2024-03-11 23:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:11:46.744033"
    },
    {
      "arxiv_id": "2403.07201v1",
      "title": "A multi-cohort study on prediction of acute brain dysfunction states using selective state space models",
      "title_zh": "使用选择性状态空间模型预测急性脑功能障碍状态的多队列研究",
      "authors": [
        "Brandon Silva",
        "Miguel Contreras",
        "Sabyasachi Bandyopadhyay",
        "Yuanfang Ren",
        "Ziyuan Guan",
        "Jeremy Balch",
        "Kia Khezeli",
        "Tezcan Ozrazgat Baslanti",
        "Ben Shickel",
        "Azra Bihorac",
        "Parisa Rashidi"
      ],
      "abstract": "Assessing acute brain dysfunction (ABD), including delirium and coma in the\nintensive care unit (ICU), is a critical challenge due to its prevalence and\nsevere implications for patient outcomes. Current diagnostic methods rely on\ninfrequent clinical observations, which can only determine a patient's ABD\nstatus after onset. Our research attempts to solve these problems by harnessing\nElectronic Health Records (EHR) data to develop automated methods for ABD\nprediction for patients in the ICU. Existing models solely predict a single\nstate (e.g., either delirium or coma), require at least 24 hours of observation\ndata to make predictions, do not dynamically predict fluctuating ABD conditions\nduring ICU stay (typically a one-time prediction), and use small sample size,\nproprietary single-hospital datasets. Our research fills these gaps in the\nexisting literature by dynamically predicting delirium, coma, and mortality for\n12-hour intervals throughout an ICU stay and validating on two public datasets.\nOur research also introduces the concept of dynamically predicting critical\ntransitions from non-ABD to ABD and between different ABD states in real time,\nwhich could be clinically more informative for the hospital staff. We compared\nthe predictive performance of two state-of-the-art neural network models, the\nMAMBA selective state space model and the Longformer Transformer model. Using\nthe MAMBA model, we achieved a mean area under the receiving operator\ncharacteristic curve (AUROC) of 0.95 on outcome prediction of ABD for 12-hour\nintervals. The model achieves a mean AUROC of 0.79 when predicting transitions\nbetween ABD states. Our study uses a curated dataset from the University of\nFlorida Health Shands Hospital for internal validation and two publicly\navailable datasets, MIMIC-IV and eICU, for external validation, demonstrating\nrobustness across ICU stays from 203 hospitals and 140,945 patients.",
      "tldr_zh": "本研究针对 ICU 中急性脑功能障碍 (ABD，包括谵妄和昏迷) 的预测挑战，使用 Electronic Health Records (EHR) 数据开发动态预测方法，填补了现有模型的局限，如仅预测单一状态或需 24 小时观察。研究引入动态预测 ABD 状态（如从非-ABD 到 ABD 的转变）每 12 小时一次，并比较了 MAMBA 选择性状态空间模型和 Longformer Transformer 模型。结果显示，MAMBA 模型在 ABD 预测上平均 AUROC 达 0.95，在状态转变预测上达 0.79，并通过 University of Florida Health Shands Hospital、MIMIC-IV 和 eICU 等数据集验证，展示了在 203 家医院和 140,945 名患者中的鲁棒性，为临床实时决策提供了更具信息性的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 8 figures, To be published",
      "pdf_url": "http://arxiv.org/pdf/2403.07201v1",
      "published_date": "2024-03-11 22:58:11 UTC",
      "updated_date": "2024-03-11 22:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:12:02.067791"
    },
    {
      "arxiv_id": "2403.07193v1",
      "title": "CuentosIE: can a chatbot about \"tales with a message\" help to teach emotional intelligence?",
      "title_zh": "CuentosIE：关于“带有寓意的故事”的聊天机器人能帮助教授情感智力吗？",
      "authors": [
        "Antonio Ferrández",
        "Rocío Lavigne-Cerván",
        "Jesús Peral",
        "Ignasi Navarro-Soria",
        "Ángel Lloret",
        "David Gil",
        "Carmen Rocamora"
      ],
      "abstract": "In this article, we present CuentosIE (TalesEI: chatbot of tales with a\nmessage to develop Emotional Intelligence), an educational chatbot on emotions\nthat also provides teachers and psychologists with a tool to monitor their\nstudents/patients through indicators and data compiled by CuentosIE. The use of\n\"tales with a message\" is justified by their simplicity and easy understanding,\nthanks to their moral or associated metaphors. The main contributions of\nCuentosIE are the selection, collection, and classification of a set of highly\nspecialized tales, as well as the provision of tools (searching, reading\ncomprehension, chatting, recommending, and classifying) that are useful for\nboth educating users about emotions and monitoring their emotional development.\nThe preliminary evaluation of the tool has obtained encouraging results, which\nprovides an affirmative answer to the question posed in the title of the\narticle.",
      "tldr_zh": "本研究介绍了 CuentosIE，一种基于“tales with a message”的教育聊天机器人，旨在通过简单易懂的故事和道德隐喻来教导 Emotional Intelligence，并为老师和心理学家提供监控学生/患者情感发展的工具。CuentosIE 的主要贡献包括选择、收集和分类一组专业故事，以及提供搜索、阅读理解、聊天、推荐和分类等功能，以支持用户的情感教育和跟踪。初步评估显示积极结果，证实了聊天机器人有助于提升 Emotional Intelligence。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.07193v1",
      "published_date": "2024-03-11 22:27:16 UTC",
      "updated_date": "2024-03-11 22:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:12:11.933913"
    },
    {
      "arxiv_id": "2403.07191v1",
      "title": "$\\mathbf{(N,K)}$-Puzzle: A Cost-Efficient Testbed for Benchmarking Reinforcement Learning Algorithms in Generative Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yufeng Zhang",
        "Liyu Chen",
        "Boyi Liu",
        "Yingxiang Yang",
        "Qiwen Cui",
        "Yunzhe Tao",
        "Hongxia Yang"
      ],
      "abstract": "Recent advances in reinforcement learning (RL) algorithms aim to enhance the\nperformance of language models at scale. Yet, there is a noticeable absence of\na cost-effective and standardized testbed tailored to evaluating and comparing\nthese algorithms. To bridge this gap, we present a generalized version of the\n24-Puzzle: the $(N,K)$-Puzzle, which challenges language models to reach a\ntarget value $K$ with $N$ integers. We evaluate the effectiveness of\nestablished RL algorithms such as Proximal Policy Optimization (PPO), alongside\nnovel approaches like Identity Policy Optimization (IPO) and Direct Policy\nOptimization (DPO).",
      "tldr_zh": "该研究针对强化学习（RL）算法在生成语言模型中的性能评估问题，提出了一种成本高效的标准化测试平台：(N,K)-Puzzle，这是一个泛化版的24-Puzzle，要求语言模型用N个整数达到目标值K。相比传统方法，该平台能有效桥接算法评估的空白，并支持比较多种算法。实验评估了Proximal Policy Optimization (PPO)、Identity Policy Optimization (IPO) 和 Direct Policy Optimization (DPO)，展示了其在RL算法基准测试中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.07191v1",
      "published_date": "2024-03-11 22:24:14 UTC",
      "updated_date": "2024-03-11 22:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:12:23.993841"
    },
    {
      "arxiv_id": "2403.07183v2",
      "title": "Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews",
      "title_zh": "大规模监控 AI 修改的内容：ChatGPT 对 AI 会议同行评议影响的案例研究",
      "authors": [
        "Weixin Liang",
        "Zachary Izzo",
        "Yaohui Zhang",
        "Haley Lepp",
        "Hancheng Cao",
        "Xuandong Zhao",
        "Lingjiao Chen",
        "Haotian Ye",
        "Sheng Liu",
        "Zhi Huang",
        "Daniel A. McFarland",
        "James Y. Zou"
      ],
      "abstract": "We present an approach for estimating the fraction of text in a large corpus\nwhich is likely to be substantially modified or produced by a large language\nmodel (LLM). Our maximum likelihood model leverages expert-written and\nAI-generated reference texts to accurately and efficiently examine real-world\nLLM-use at the corpus level. We apply this approach to a case study of\nscientific peer review in AI conferences that took place after the release of\nChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023. Our results suggest\nthat between 6.5% and 16.9% of text submitted as peer reviews to these\nconferences could have been substantially modified by LLMs, i.e. beyond\nspell-checking or minor writing updates. The circumstances in which generated\ntext occurs offer insight into user behavior: the estimated fraction of\nLLM-generated text is higher in reviews which report lower confidence, were\nsubmitted close to the deadline, and from reviewers who are less likely to\nrespond to author rebuttals. We also observe corpus-level trends in generated\ntext which may be too subtle to detect at the individual level, and discuss the\nimplications of such trends on peer review. We call for future\ninterdisciplinary work to examine how LLM use is changing our information and\nknowledge practices.",
      "tldr_zh": "本研究提出了一种最大似然模型，用于估计大型语料库中可能被大型语言模型（LLM）大幅修改或生成的文本比例，该模型利用专家撰写和AI生成的参考文本进行高效分析。针对ChatGPT发布后的AI会议同行评审（如ICLR 2024、NeurIPS 2023、CoRL 2023和EMNLP 2023）的案例研究，结果显示6.5%至16.9%的评审文本可能被LLM实质性修改，且这类文本更常见于置信度低的评审、接近截止期限的提交，以及不太回应作者反驳的评审。论文还观察到语料库级别的LLM使用趋势，并呼吁未来跨学科研究来探讨这些变化对信息和知识实践的影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "46 pages, 31 figures, ICML '24",
      "pdf_url": "http://arxiv.org/pdf/2403.07183v2",
      "published_date": "2024-03-11 21:51:39 UTC",
      "updated_date": "2024-06-15 05:23:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:12:37.110467"
    },
    {
      "arxiv_id": "2403.07175v3",
      "title": "Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing",
      "title_zh": "重建 ROME：",
      "authors": [
        "Akshat Gupta",
        "Sidharth Baskaran",
        "Gopala Anumanchipalli"
      ],
      "abstract": "Recent work using Rank-One Model Editing (ROME), a popular model editing\nmethod, has shown that there are certain facts that the algorithm is unable to\nedit without breaking the model. Such edits have previously been called\ndisabling edits. These disabling edits cause immediate model collapse and\nlimits the use of ROME for sequential editing. In this paper, we show that\ndisabling edits are an artifact of irregularities in the implementation of\nROME. With this paper, we provide a more stable implementation ROME, which we\ncall r-ROME and show that model collapse is no longer observed when making\nlarge scale sequential edits with r-ROME, while further improving\ngeneralization and locality of model editing compared to the original\nimplementation of ROME. We also provide a detailed mathematical explanation of\nthe reason behind disabling edits.",
      "tldr_zh": "该研究发现，Rank-One Model Editing (ROME) 在进行连续模型编辑时，某些编辑（称为 disabling edits）会导致模型崩溃，从而限制了其应用。作者提出了一种更稳定的实现版本 r-ROME，通过修正ROME的实现不规则性，避免了模型崩溃问题，同时提升了编辑的泛化和局部性。实验结果显示，r-ROME 支持大规模连续编辑，并提供了 disabling edits 原因的详细数学解释。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2403.07175v3",
      "published_date": "2024-03-11 21:33:05 UTC",
      "updated_date": "2024-10-09 03:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:12:46.548133"
    },
    {
      "arxiv_id": "2403.07151v1",
      "title": "Don't Forget What I did?: Assessing Client Contributions in Federated Learning",
      "title_zh": "不要忘记我做了什么？：评估联邦学习中的客户端贡献",
      "authors": [
        "Bishwamittra Ghosh",
        "Debabrota Basu",
        "Fu Huazhu",
        "Wang Yuan",
        "Renuga Kanagavelu",
        "Jiang Jin Peng",
        "Liu Yong",
        "Goh Siow Mong Rick",
        "Wei Qingsong"
      ],
      "abstract": "Federated Learning (FL) is a collaborative machine learning (ML) approach,\nwhere multiple clients participate in training an ML model without exposing the\nprivate data. Fair and accurate assessment of client contributions is an\nimportant problem in FL to facilitate incentive allocation and encouraging\ndiverse clients to participate in a unified model training. Existing methods\nfor assessing client contribution adopts co-operative game-theoretic concepts,\nsuch as Shapley values, but under simplified assumptions. In this paper, we\npropose a history-aware game-theoretic framework, called FLContrib, to assess\nclient contributions when a subset of (potentially non-i.i.d.) clients\nparticipate in each epoch of FL training. By exploiting the FL training process\nand linearity of Shapley value, we develop FLContrib that yields a historical\ntimeline of client contributions as FL training progresses over epochs.\nAdditionally, to assess client contribution under limited computational budget,\nwe propose a scheduling procedure that considers a two-sided fairness criteria\nto perform expensive Shapley value computation only in a subset of training\nepochs. In experiments, we demonstrate a controlled trade-off between the\ncorrectness and efficiency of client contributions assessed via FLContrib. To\ndemonstrate the benefits of history-aware client contributions, we apply\nFLContrib to detect dishonest clients conducting data poisoning in FL training.",
      "tldr_zh": "这篇论文探讨了在Federated Learning (FL) 中评估客户端贡献的重要性，以促进激励分配和鼓励参与。作者提出FLContrib框架，这是一种history-aware game-theoretic方法，利用Shapley values的线性特性，提供客户端贡献的历史时间线，并处理非i.i.d.数据。框架还包括一个调度程序，基于两侧公平性标准，只在部分训练epoch计算贡献，以平衡正确性和计算效率；实验验证了FLContrib在检测数据中毒的欺骗客户端方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Under submission",
      "pdf_url": "http://arxiv.org/pdf/2403.07151v1",
      "published_date": "2024-03-11 20:39:32 UTC",
      "updated_date": "2024-03-11 20:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:12:59.359919"
    },
    {
      "arxiv_id": "2403.07136v1",
      "title": "On the Limited Representational Power of Value Functions and its Links to Statistical (In)Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "David Cheikhi",
        "Daniel Russo"
      ],
      "abstract": "Identifying the trade-offs between model-based and model-free methods is a\ncentral question in reinforcement learning. Value-based methods offer\nsubstantial computational advantages and are sometimes just as statistically\nefficient as model-based methods. However, focusing on the core problem of\npolicy evaluation, we show information about the transition dynamics may be\nimpossible to represent in the space of value functions. We explore this\nthrough a series of case studies focused on structures that arises in many\nimportant problems. In several, there is no information loss and value-based\nmethods are as statistically efficient as model based ones. In other\nclosely-related examples, information loss is severe and value-based methods\nare severely outperformed. A deeper investigation points to the limitations of\nthe representational power as the driver of the inefficiency, as opposed to\nfailure in algorithm design.",
      "tldr_zh": "本论文探讨了强化学习中基于值函数(value functions)的方法与基于模型(model-based methods)的权衡，强调值函数在策略评估(policy evaluation)中可能无法充分表示转移动态信息，从而导致统计效率低下。通过一系列案例研究，作者发现某些问题结构下值函数方法与模型方法效率相当，而在其他相关场景中，信息损失严重，导致值函数方法表现远逊于模型方法。最终，研究指出，这种低效性主要源于值函数的表示能力有限，而非算法设计失败。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07136v1",
      "published_date": "2024-03-11 20:05:48 UTC",
      "updated_date": "2024-03-11 20:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:13:11.996835"
    },
    {
      "arxiv_id": "2403.07131v1",
      "title": "Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot Task Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Paul",
        "Nathan Maurer",
        "Souma Chowdhury"
      ],
      "abstract": "Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.",
      "tldr_zh": "这篇论文针对 Multi-Robot Task Allocation (MRTA) 问题，提出了一种使用 Graph Reinforcement Learning (GRL) 框架来学习二分图匹配的激励函数，以避免手动设计启发式规则的繁琐性。方法基于修改后的 Capsule Attention 政策模型，结合机器人状态图编码和两个 Multihead Attention 解码器，生成 LogNormal 分布矩阵来计算任务与机器人的配对权重。实验结果显示，该方法与使用专家指定启发式的传统二分图匹配性能相当，但提供了更高的鲁棒性，且学习到的激励政策在训练过程中先接近专家政策然后略微偏离。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper was accepted for presentation in proceedings of IEEE\n  International Conference on Robotics and Automation 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07131v1",
      "published_date": "2024-03-11 19:55:08 UTC",
      "updated_date": "2024-03-11 19:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:13:24.436360"
    },
    {
      "arxiv_id": "2403.07090v1",
      "title": "Time Series Analysis of Key Societal Events as Reflected in Complex Social Media Data Streams",
      "title_zh": "翻译失败",
      "authors": [
        "Andy Skumanich",
        "Han Kyul Kim"
      ],
      "abstract": "Social media platforms hold valuable insights, yet extracting essential\ninformation can be challenging. Traditional top-down approaches often struggle\nto capture critical signals in rapidly changing events. As global events evolve\nswiftly, social media narratives, including instances of disinformation, become\nsignificant sources of insights. To address the need for an inductive strategy,\nwe explore a niche social media platform GAB and an established messaging\nservice Telegram, to develop methodologies applicable on a broader scale. This\nstudy investigates narrative evolution on these platforms using quantitative\ncorpus-based discourse analysis techniques. Our approach is a novel mode to\nstudy multiple social media domains to distil key information which may be\nobscured otherwise, allowing for useful and actionable insights. The paper\ndetails the technical and methodological aspects of gathering and preprocessing\nGAB and Telegram data for a keyness (Log Ratio) metric analysis, identifying\ncrucial nouns and verbs for deeper exploration. Empirically, this approach is\napplied to a case study of a well defined event that had global impact: the\n2023 Wagner mutiny. The main findings are: (1) the time line can be\ndeconstructed to provide useful data features allowing for improved\ninterpretation; (2) a methodology is applied which provides a basis for\ngeneralization. The key contribution is an approach, that in some cases,\nprovides the ability to capture the dynamic narrative shifts over time with\nelevated confidence. The approach can augment near-real-time assessment of key\nsocial movements, allowing for informed governance choices. This research is\nimportant because it lays out a useful methodology for time series relevant\ninfo-culling, which can enable proactive modes for positive social engagement.",
      "tldr_zh": "本研究探讨了从复杂社交媒体数据流中分析关键社会事件的方法，针对 GAB 和 Telegram 平台，使用定量语料库分析（corpus-based discourse analysis）技术，包括数据收集、预处理和关键性指标分析（如 Log Ratio 度量），以捕捉叙事演变和潜在虚假信息。应用案例为 2023 年 Wagner mutiny 事件，结果显示时间线分解能提供有用数据特征，并提升对动态叙事变化的捕捉信心。论文的主要贡献是提出一种可推广的方法，支持近实时评估社会运动，从而为主动社会治理和正向参与提供决策依据。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "AAAI2024 Workshop on AI for Time Series Analysis (AI4TS)",
      "pdf_url": "http://arxiv.org/pdf/2403.07090v1",
      "published_date": "2024-03-11 18:33:56 UTC",
      "updated_date": "2024-03-11 18:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:13:36.099886"
    },
    {
      "arxiv_id": "2403.07087v1",
      "title": "LSTM-Based Text Generation: A Study on Historical Datasets",
      "title_zh": "基于 LSTM 的文本生成：对历史数据集的研究",
      "authors": [
        "Mustafa Abbas Hussein Hussein",
        "Serkan Savaş"
      ],
      "abstract": "This paper presents an exploration of Long Short-Term Memory (LSTM) networks\nin the realm of text generation, focusing on the utilization of historical\ndatasets for Shakespeare and Nietzsche. LSTMs, known for their effectiveness in\nhandling sequential data, are applied here to model complex language patterns\nand structures inherent in historical texts. The study demonstrates that\nLSTM-based models, when trained on historical datasets, can not only generate\ntext that is linguistically rich and contextually relevant but also provide\ninsights into the evolution of language patterns over time. The finding\npresents models that are highly accurate and efficient in predicting text from\nworks of Nietzsche, with low loss values and a training time of 100 iterations.\nThe accuracy of the model is 0.9521, indicating high accuracy. The loss of the\nmodel is 0.2518, indicating its effectiveness. The accuracy of the model in\npredicting text from the work of Shakespeare is 0.9125, indicating a low error\nrate. The training time of the model is 100, mirroring the efficiency of the\nNietzsche dataset. This efficiency demonstrates the effectiveness of the model\ndesign and training methodology, especially when handling complex literary\ntexts. This research contributes to the field of natural language processing by\nshowcasing the versatility of LSTM networks in text generation and offering a\npathway for future explorations in historical linguistics and beyond.",
      "tldr_zh": "这篇论文探讨了Long Short-Term Memory (LSTM) 网络在文本生成中的应用，特别针对莎士比亚和尼采的历史数据集进行训练，以捕捉复杂语言模式和结构。研究发现，LSTM 模型在尼采文本上实现了0.9521的准确率和0.2518的损失值，在莎士比亚文本上达到0.9125的准确率，训练迭代均需100次，展示了高效性能。总体而言，该工作证明了LSTM 在生成语义丰富文本和分析语言演变方面的多功能性，为自然语言处理和历史语言学领域提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07087v1",
      "published_date": "2024-03-11 18:25:01 UTC",
      "updated_date": "2024-03-11 18:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:13:49.257312"
    },
    {
      "arxiv_id": "2403.07078v1",
      "title": "Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning",
      "title_zh": "翻译失败",
      "authors": [
        "Fuseinin Mumuni",
        "Alhassan Mumuni"
      ],
      "abstract": "We review current and emerging knowledge-informed and brain-inspired\ncognitive systems for realizing adversarial defenses, eXplainable Artificial\nIntelligence (XAI), and zero-shot or few-short learning. Data-driven deep\nlearning models have achieved remarkable performance and demonstrated\ncapabilities surpassing human experts in many applications. Yet, their\ninability to exploit domain knowledge leads to serious performance limitations\nin practical applications. In particular, deep learning systems are exposed to\nadversarial attacks, which can trick them into making glaringly incorrect\ndecisions. Moreover, complex data-driven models typically lack interpretability\nor explainability, i.e., their decisions cannot be understood by human\nsubjects. Furthermore, models are usually trained on standard datasets with a\nclosed-world assumption. Hence, they struggle to generalize to unseen cases\nduring inference in practical open-world environments, thus, raising the zero-\nor few-shot generalization problem. Although many conventional solutions exist,\nexplicit domain knowledge, brain-inspired neural network and cognitive\narchitectures offer powerful new dimensions towards alleviating these problems.\nPrior knowledge is represented in appropriate forms and incorporated in deep\nlearning frameworks to improve performance. Brain-inspired cognition methods\nuse computational models that mimic the human mind to enhance intelligent\nbehavior in artificial agents and autonomous robots. Ultimately, these models\nachieve better explainability, higher adversarial robustness and data-efficient\nlearning, and can, in turn, provide insights for cognitive science and\nneuroscience-that is, to deepen human understanding on how the brain works in\ngeneral, and how it handles these problems.",
      "tldr_zh": "这篇调查论文探讨了如何通过整合先验知识（prior knowledge）和认知模型来提升深度学习的性能，重点解决 explainability, adversarial robustness 和 zero-shot learning 的挑战。论文审查了脑启发认知系统和显式领域知识的应用，这些方法能帮助深度学习模型抵御对抗攻击、提高决策解释性，并实现数据高效的零样本或少样本泛化。最终，这些创新框架不仅增强了人工智能的鲁棒性和可解释性，还为认知科学和神经科学提供了新洞见，促进了对人类大脑处理类似问题的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07078v1",
      "published_date": "2024-03-11 18:11:00 UTC",
      "updated_date": "2024-03-11 18:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:14:02.087988"
    },
    {
      "arxiv_id": "2403.07076v1",
      "title": "Mapping High-level Semantic Regions in Indoor Environments without Object Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Bigazzi",
        "Lorenzo Baraldi",
        "Shreyas Kousik",
        "Rita Cucchiara",
        "Marco Pavone"
      ],
      "abstract": "Robots require a semantic understanding of their surroundings to operate in\nan efficient and explainable way in human environments. In the literature,\nthere has been an extensive focus on object labeling and exhaustive scene graph\ngeneration; less effort has been focused on the task of purely identifying and\nmapping large semantic regions. The present work proposes a method for semantic\nregion mapping via embodied navigation in indoor environments, generating a\nhigh-level representation of the knowledge of the agent. To enable region\nidentification, the method uses a vision-to-language model to provide scene\ninformation for mapping. By projecting egocentric scene understanding into the\nglobal frame, the proposed method generates a semantic map as a distribution\nover possible region labels at each location. This mapping procedure is paired\nwith a trained navigation policy to enable autonomous map generation. The\nproposed method significantly outperforms a variety of baselines, including an\nobject-based system and a pretrained scene classifier, in experiments in a\nphotorealistic simulator.",
      "tldr_zh": "本文提出了一种无需对象识别的语义区域映射方法，针对机器人通过 embodied navigation 在室内环境生成高级语义表示。该方法利用 vision-to-language 模型从第一人称视角提取场景信息，并将其投影到全局框架中，形成每个位置的区域标签分布图。结合训练的导航策略，该系统实现了自主地图生成，并在光线逼真的模拟器实验中显著优于基线系统，包括基于对象的系统和预训练的场景分类器。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by IEEE International Conference on Robotics and Automation\n  (ICRA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.07076v1",
      "published_date": "2024-03-11 18:09:50 UTC",
      "updated_date": "2024-03-11 18:09:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:14:12.297525"
    },
    {
      "arxiv_id": "2403.06963v2",
      "title": "The pitfalls of next-token prediction",
      "title_zh": "下一词元预测的陷阱",
      "authors": [
        "Gregor Bachmann",
        "Vaishnavh Nagarajan"
      ],
      "abstract": "Can a mere next-token predictor faithfully model human intelligence? We\ncrystallize this emerging concern and correct popular misconceptions\nsurrounding it, and advocate a simple multi-token objective.\n  As a starting point, we argue that the two often-conflated phases of\nnext-token prediction -- autoregressive inference and teacher-forced training\n-- must be treated distinctly. The popular criticism that errors can compound\nduring autoregressive inference, crucially assumes that teacher-forcing has\nlearned an accurate next-token predictor. This assumption sidesteps a more\ndeep-rooted problem we expose: in certain classes of tasks, teacher-forcing can\nsimply fail to learn an accurate next-token predictor in the first place. We\ndescribe a general mechanism of how teacher-forcing can fail, and design a\nminimal planning task where both the Transformer and the Mamba architecture\nempirically fail in that manner -- remarkably, despite the task being\nstraightforward to learn.\n  Finally, we provide preliminary evidence that this failure can be resolved\nusing a simple modification that predicts multiple tokens in advance. We hope\nthis finding can ground future debates and inspire explorations beyond the\nnext-token prediction paradigm. We make our code available under\nhttps://github.com/gregorbachmann/Next-Token-Failures",
      "tldr_zh": "这篇论文质疑了下一个标记预测（next-token prediction）是否能准确模拟人类智能，并澄清了相关常见误解，同时提出采用简单的多标记（multi-token）目标作为替代。作者强调了 autoregressive inference 和 teacher-forced training 两个阶段的区别，并揭示了一个核心问题：在某些任务中，teacher-forced training 可能根本无法学习有效的下一个标记预测。论文设计了一个最小规划任务，展示了 Transformer 和 Mamba 架构在该任务上的失败，尽管任务本身易学。最后，通过初步实验证据表明，使用多标记预测可以缓解这一问题，并呼吁未来研究超越 next-token prediction 范式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06963v2",
      "published_date": "2024-03-11 17:47:30 UTC",
      "updated_date": "2024-07-05 20:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:14:24.750309"
    },
    {
      "arxiv_id": "2403.13835v1",
      "title": "SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees",
      "title_zh": "翻译失败",
      "authors": [
        "Saehan Jo",
        "Immanuel Trummer"
      ],
      "abstract": "The advancement of Large Language Models (LLMs) has significantly boosted\nperformance in natural language processing (NLP) tasks. However, the deployment\nof high-performance LLMs incurs substantial costs, primarily due to the\nincreased number of parameters aimed at enhancing model performance. This has\nmade the use of state-of-the-art LLMs more expensive for end-users. AI service\nproviders, such as OpenAI and Anthropic, often offer multiple versions of LLMs\nwith varying prices and performance. However, end-users still face challenges\nin choosing the appropriate LLM for their tasks that balance result quality\nwith cost.\n  We introduce SMART, Scaling Models Adaptively for Reduced Token Fees, a novel\nLLM framework designed to minimize the inference costs of NLP tasks while\nensuring sufficient result quality. It enables users to specify an accuracy\nconstraint in terms of the equivalence of outputs to those of the most powerful\nLLM. SMART then generates results that deviate from the outputs of this LLM\nonly with a probability below a user-defined threshold. SMART employs a\nprofiling phase that evaluates the performance of multiple LLMs to identify\nthose that meet the user-defined accuracy level. SMART optimizes the tradeoff\nbetween profiling overheads and the anticipated cost savings resulting from\nprofiling. Moreover, our approach significantly reduces inference costs by\nstrategically leveraging a mix of LLMs. Our experiments on three real-world\ndatasets show that, based on OpenAI models, SMART achieves significant cost\nsavings, up to 25.6x in comparison to GPT-4.",
      "tldr_zh": "本文提出 SMART 框架，一种自动缩减大型语言模型 (LLMs) 规模的方法，旨在降低自然语言处理 (NLP) 任务的推理成本，同时确保输出质量与最强大模型相当。SMART 通过一个评估阶段 (profiling phase) 来评估多个 LLMs 的性能，选择满足用户指定准确性阈值的模型，并优化评估开销与成本节约的权衡。实验在三个真实数据集上显示，该框架可实现高达 25.6 倍的成本节约，与 GPT-4 相比显著提升了性价比。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13835v1",
      "published_date": "2024-03-11 17:45:47 UTC",
      "updated_date": "2024-03-11 17:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:14:37.217920"
    },
    {
      "arxiv_id": "2403.06952v1",
      "title": "SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jialu Li",
        "Jaemin Cho",
        "Yi-Lin Sung",
        "Jaehong Yoon",
        "Mohit Bansal"
      ],
      "abstract": "Recent text-to-image (T2I) generation models have demonstrated impressive\ncapabilities in creating images from text descriptions. However, these T2I\ngeneration models often fall short of generating images that precisely match\nthe details of the text inputs, such as incorrect spatial relationship or\nmissing objects. In this paper, we introduce SELMA: Skill-Specific Expert\nLearning and Merging with Auto-Generated Data, a novel paradigm to improve the\nfaithfulness of T2I models by fine-tuning models on automatically generated,\nmulti-skill image-text datasets, with skill-specific expert learning and\nmerging. First, SELMA leverages an LLM's in-context learning capability to\ngenerate multiple datasets of text prompts that can teach different skills, and\nthen generates the images with a T2I model based on the prompts. Next, SELMA\nadapts the T2I model to the new skills by learning multiple single-skill LoRA\n(low-rank adaptation) experts followed by expert merging. Our independent\nexpert fine-tuning specializes multiple models for different skills, and expert\nmerging helps build a joint multi-skill T2I model that can generate faithful\nimages given diverse text prompts, while mitigating the knowledge conflict from\ndifferent datasets. We empirically demonstrate that SELMA significantly\nimproves the semantic alignment and text faithfulness of state-of-the-art T2I\ndiffusion models on multiple benchmarks (+2.1% on TIFA and +6.9% on DSG), human\npreference metrics (PickScore, ImageReward, and HPS), as well as human\nevaluation. Moreover, fine-tuning with image-text pairs auto-collected via\nSELMA shows comparable performance to fine-tuning with ground truth data.\nLastly, we show that fine-tuning with images from a weaker T2I model can help\nimprove the generation quality of a stronger T2I model, suggesting promising\nweak-to-strong generalization in T2I models.",
      "tldr_zh": "本研究提出 SELMA，一种基于自动生成数据的技能特定专家学习和合并框架，旨在提升文本到图像 (T2I) 模型的保真度，解决现有模型在处理文本细节（如 spatial relationship 或 missing objects）时的不足。SELMA 利用 LLM 的 in-context learning 生成多技能图像-文本数据集，并通过训练多个 single-skill LoRA (low-rank adaptation) 专家模型，然后进行专家合并，以构建一个联合的多技能 T2I 模型，从而减少知识冲突并提高生成图像的语义对齐。实验结果显示，SELMA 显著改善了状态-of-the-art T2I 扩散模型的表现，在 TIFA 和 DSG 基准上分别提升 2.1% 和 6.9%，并在人类偏好指标（PickScore, ImageReward, and HPS）及人工评估中表现出色；此外，使用自动生成数据微调的性能可媲美 ground truth 数据，并证明弱 T2I 模型的图像可帮助强模型实现 weak-to-strong generalization。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "First two authors contributed equally; Project website:\n  https://selma-t2i.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2403.06952v1",
      "published_date": "2024-03-11 17:35:33 UTC",
      "updated_date": "2024-03-11 17:35:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:14:51.222932"
    },
    {
      "arxiv_id": "2403.06936v1",
      "title": "Counterfactual Reasoning with Knowledge Graph Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Lena Zellinger",
        "Andreas Stephan",
        "Benjamin Roth"
      ],
      "abstract": "Knowledge graph embeddings (KGEs) were originally developed to infer true but\nmissing facts in incomplete knowledge repositories. In this paper, we link\nknowledge graph completion and counterfactual reasoning via our new task CFKGR.\nWe model the original world state as a knowledge graph, hypothetical scenarios\nas edges added to the graph, and plausible changes to the graph as inferences\nfrom logical rules. We create corresponding benchmark datasets, which contain\ndiverse hypothetical scenarios with plausible changes to the original knowledge\ngraph and facts that should be retained. We develop COULDD, a general method\nfor adapting existing knowledge graph embeddings given a hypothetical premise,\nand evaluate it on our benchmark. Our results indicate that KGEs learn patterns\nin the graph without explicit training. We further observe that KGEs adapted\nwith COULDD solidly detect plausible counterfactual changes to the graph that\nfollow these patterns. An evaluation on human-annotated data reveals that KGEs\nadapted with COULDD are mostly unable to recognize changes to the graph that do\nnot follow learned inference rules. In contrast, ChatGPT mostly outperforms\nKGEs in detecting plausible changes to the graph but has poor knowledge\nretention. In summary, CFKGR connects two previously distinct areas, namely KG\ncompletion and counterfactual reasoning.",
      "tldr_zh": "本文提出CFKGR任务，将知识图嵌入(KGEs)应用于反事实推理，通过将原世界状态建模为知识图、假设场景作为添加的边，以及逻辑规则的推理来预测合理图改变，并创建了包含多样化假设场景的基准数据集。研究开发了COULDD方法，用于根据假设前提适应现有KGEs，结果显示KGEs能够在无显式训练下学习图模式，并有效检测遵循这些模式的反事实改变。相比之下，ChatGPT在检测合理改变上表现更优，但知识保留较差；总体而言，该工作连接了知识图完成和反事实推理两个领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06936v1",
      "published_date": "2024-03-11 17:21:39 UTC",
      "updated_date": "2024-03-11 17:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:15:02.561047"
    },
    {
      "arxiv_id": "2403.06925v2",
      "title": "Transformers Learn Low Sensitivity Functions: Investigations and Implications",
      "title_zh": "Transformer",
      "authors": [
        "Bhavya Vasudeva",
        "Deqing Fu",
        "Tianyi Zhou",
        "Elliott Kau",
        "Youqi Huang",
        "Vatsal Sharan"
      ],
      "abstract": "Transformers achieve state-of-the-art accuracy and robustness across many\ntasks, but an understanding of their inductive biases and how those biases\ndiffer from other neural network architectures remains elusive. In this work,\nwe identify the sensitivity of the model to token-wise random perturbations in\nthe input as a unified metric which explains the inductive bias of transformers\nacross different data modalities and distinguishes them from other\narchitectures. We show that transformers have lower sensitivity than MLPs,\nCNNs, ConvMixers and LSTMs, across both vision and language tasks. We also show\nthat this low-sensitivity bias has important implications: i) lower sensitivity\ncorrelates with improved robustness; it can also be used as an efficient\nintervention to further improve the robustness of transformers; ii) it\ncorresponds to flatter minima in the loss landscape; and iii) it can serve as a\nprogress measure for grokking. We support these findings with theoretical\nresults showing (weak) spectral bias of transformers in the NTK regime, and\nimproved robustness due to the lower sensitivity. The code is available at\nhttps://github.com/estija/sensitivity.",
      "tldr_zh": "本研究探讨了Transformer模型的感应偏差（inductive biases），通过模型对输入token-wise随机扰动的敏感性作为统一指标，揭示了Transformer与其他架构（如MLPs、CNNs、ConvMixers和LSTMs）在视觉和语言任务中的差异。结果显示，Transformer的敏感性更低，这与更高的鲁棒性（robustness）相关，并可作为提升模型鲁棒性的高效干预手段，同时对应于损失景观中的更平坦极小值（flatter minima）。此外，该低敏感性偏差还能作为grokking进展的测量指标，并得到NTK regime下理论结果的支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025. 24 pages, 19 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.06925v2",
      "published_date": "2024-03-11 17:12:09 UTC",
      "updated_date": "2025-02-13 18:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:15:13.058070"
    },
    {
      "arxiv_id": "2403.06914v2",
      "title": "MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yichuan Li",
        "Xiyao Ma",
        "Sixing Lu",
        "Kyumin Lee",
        "Xiaohu Liu",
        "Chenlei Guo"
      ],
      "abstract": "Large Language models (LLMs) have demonstrated impressive in-context learning\n(ICL) capabilities, where a LLM makes predictions for a given test input\ntogether with a few input-output pairs (demonstrations). Nevertheless, the\ninclusion of demonstrations leads to a quadratic increase in the computational\noverhead of the self-attention mechanism. Existing solutions attempt to distill\nlengthy demonstrations into compact vectors. However, they often require\ntask-specific retraining or compromise LLM's in-context learning performance.\nTo mitigate these challenges, we present Meta dEmonstratioN Distillation\n(MEND), where a language model learns to distill any lengthy demonstrations\ninto vectors without retraining for a new downstream task. We exploit the\nknowledge distillation to enhance alignment between MEND and LLM, achieving\nboth efficiency and effectiveness simultaneously. MEND is endowed with the\nmeta-knowledge of distilling demonstrations through a two-stage training\nprocess, which includes meta-distillation pretraining and fine-tuning.\nComprehensive evaluations across seven diverse ICL task partitions using\ndecoder-only (GPT-2) and encoder-decoder (T5) attest to MEND's prowess. It not\nonly matches but often outperforms the Vanilla ICL as well as other\nstate-of-the-art distillation models, while significantly reducing the\ncomputational demands. This innovation promises enhanced scalability and\nefficiency for the practical deployment of large language models",
      "tldr_zh": "本研究提出了一种名为 MEND 的 Meta dEmonstratioN Distillation 框架，旨在提升 Large Language Models (LLMs) 在 in-context learning (ICL) 中的效率和效果，通过将冗长演示浓缩成紧凑向量，而无需针对新任务进行重训练。MEND 利用 knowledge distillation 技术增强与 LLM 的对齐，并通过两阶段训练过程（meta-distillation pretraining 和 fine-tuning）来获取演示浓缩的元知识。在跨七个多样 ICL 任务分区上，使用 GPT-2 和 T5 模型的全面评估显示，MEND 不仅匹配或超越 Vanilla ICL 和其他最先进模型，还显著降低了计算开销，从而提升了 LLM 的可扩展性和实际部署潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06914v2",
      "published_date": "2024-03-11 17:03:04 UTC",
      "updated_date": "2024-03-12 15:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:15:26.079604"
    },
    {
      "arxiv_id": "2403.06910v1",
      "title": "Responsible Artificial Intelligence: A Structured Literature Review",
      "title_zh": "翻译失败",
      "authors": [
        "Sabrina Goellner",
        "Marina Tropmann-Frick",
        "Bostjan Brumen"
      ],
      "abstract": "Our research endeavors to advance the concept of responsible artificial\nintelligence (AI), a topic of increasing importance within EU policy\ndiscussions. The EU has recently issued several publications emphasizing the\nnecessity of trust in AI, underscoring the dual nature of AI as both a\nbeneficial tool and a potential weapon. This dichotomy highlights the urgent\nneed for international regulation. Concurrently, there is a need for frameworks\nthat guide companies in AI development, ensuring compliance with such\nregulations. Our research aims to assist lawmakers and machine learning\npractitioners in navigating the evolving landscape of AI regulation,\nidentifying focal areas for future attention. This paper introduces a\ncomprehensive and, to our knowledge, the first unified definition of\nresponsible AI. Through a structured literature review, we elucidate the\ncurrent understanding of responsible AI. Drawing from this analysis, we propose\nan approach for developing a future framework centered around this concept. Our\nfindings advocate for a human-centric approach to Responsible AI. This approach\nencompasses the implementation of AI methods with a strong emphasis on ethics,\nmodel explainability, and the pillars of privacy, security, and trust.",
      "tldr_zh": "该研究通过结构化文献综述探讨了Responsible AI的概念，强调其在欧盟政策中的重要性，并突出AI作为工具和潜在风险的双重性。论文首次提出一个统一的Responsible AI定义，并分析了当前文献以指导决策者和机器学习从业者应对AI监管挑战。研究倡导以人为本的方法，聚焦于AI伦理、可解释性以及隐私、安全和信任等核心支柱，为未来AI框架开发提供实用路径。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06910v1",
      "published_date": "2024-03-11 17:01:13 UTC",
      "updated_date": "2024-03-11 17:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:15:35.486150"
    },
    {
      "arxiv_id": "2403.06906v3",
      "title": "Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints",
      "title_zh": "成本敏感学习向多个专家延迟决策，考虑工作负载约束",
      "authors": [
        "Jean V. Alves",
        "Diogo Leitão",
        "Sérgio Jesus",
        "Marco O. P. Sampaio",
        "Javier Liébana",
        "Pedro Saleiro",
        "Mário A. T. Figueiredo",
        "Pedro Bizarro"
      ],
      "abstract": "Learning to defer (L2D) aims to improve human-AI collaboration systems by\nlearning how to defer decisions to humans when they are more likely to be\ncorrect than an ML classifier. Existing research in L2D overlooks key\nreal-world aspects that impede its practical adoption, namely: i) neglecting\ncost-sensitive scenarios, where type I and type II errors have different costs;\nii) requiring concurrent human predictions for every instance of the training\ndataset; and iii) not dealing with human work-capacity constraints. To address\nthese issues, we propose the \\textit{deferral under cost and capacity\nconstraints framework} (DeCCaF). DeCCaF is a novel L2D approach, employing\nsupervised learning to model the probability of human error under less\nrestrictive data requirements (only one expert prediction per instance) and\nusing constraint programming to globally minimize the error cost, subject to\nworkload limitations. We test DeCCaF in a series of cost-sensitive fraud\ndetection scenarios with different teams of 9 synthetic fraud analysts, with\nindividual work-capacity constraints. The results demonstrate that our approach\nperforms significantly better than the baselines in a wide array of scenarios,\nachieving an average $8.4\\%$ reduction in the misclassification cost. The code\nused for the experiments is available at https://github.com/feedzai/deccaf",
      "tldr_zh": "该研究提出了一种新的学习延迟框架（Learning to Defer, L2D）方法，名为 DeCCaF，以解决现有模型在成本敏感场景中的局限性，包括 type I and type II errors 的不同成本、训练数据对人类预测的依赖以及工作容量约束。DeCCaF 通过监督学习建模人类错误概率，仅需每个实例一个专家预测，并结合约束编程全局最小化错误成本，同时满足工作负载限制。实验在成本敏感的欺诈检测场景中进行，使用9个合成欺诈分析师，结果显示 DeCCaF 比基线方法平均减少8.4%的错误分类成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06906v3",
      "published_date": "2024-03-11 16:57:20 UTC",
      "updated_date": "2024-08-19 18:18:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:15:48.939105"
    },
    {
      "arxiv_id": "2403.09714v1",
      "title": "Linguistic Structure Induction from Language Models",
      "title_zh": "从语言模型中诱导语言结构",
      "authors": [
        "Omar Momen"
      ],
      "abstract": "Linear sequences of words are implicitly represented in our brains by\nhierarchical structures that organize the composition of words in sentences.\nLinguists formalize different frameworks to model this hierarchy; two of the\nmost common syntactic frameworks are Constituency and Dependency. Constituency\nrepresents sentences as nested groups of phrases, while dependency represents a\nsentence by assigning relations between its words. Recently, the pursuit of\nintelligent machines has produced Language Models (LMs) capable of solving many\nlanguage tasks with a human-level performance. Many studies now question\nwhether LMs implicitly represent syntactic hierarchies. This thesis focuses on\nproducing constituency and dependency structures from LMs in an unsupervised\nsetting. I review the critical methods in this field and highlight a line of\nwork that utilizes a numerical representation for binary constituency trees\n(Syntactic Distance). I present a detailed study on StructFormer (SF) (Shen et\nal., 2021), which retrofits a transformer encoder architecture with a parser\nnetwork to produce constituency and dependency structures. I present six\nexperiments to analyze and address this field's challenges; experiments include\ninvestigating the effect of repositioning the parser network within the SF\narchitecture, evaluating subword-based induced trees, and benchmarking the\nmodels developed in the thesis experiments on linguistic tasks. Models\nbenchmarking is performed by participating in the BabyLM challenge, published\nat CoNLL 2023 (Momen et al., 2023). The results of this thesis encourage\nfurther development in the direction of retrofitting transformer-based models\nto induce syntactic structures, supported by the acceptable performance of SF\nin different experimental settings and the observed limitations that require\ninnovative solutions to advance the state of syntactic structure induction.",
      "tldr_zh": "这篇论文探讨了从 Language Models (LMs) 中无监督诱导语法结构，包括 Constituency 和 Dependency 框架，以模拟大脑中句子层级组织。作者回顾了关键方法，如 Syntactic Distance，并详细分析了 StructFormer (SF)，一种将 transformer 编码器与解析器网络结合的模型。论文通过六次实验，包括调整 SF 架构、评估子词级结构，并在 BabyLM challenge 中基准测试，证明了这些模型在语法任务中的可行性。总体结果显示 SF 表现良好，但仍存在局限性，鼓励进一步创新 transformer-based 模型来提升语法结构诱导的水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Master's Thesis. Supervised by Laura Kallmeyer and David Arps",
      "pdf_url": "http://arxiv.org/pdf/2403.09714v1",
      "published_date": "2024-03-11 16:54:49 UTC",
      "updated_date": "2024-03-11 16:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:16:02.490781"
    },
    {
      "arxiv_id": "2403.06901v1",
      "title": "LIBR+: Improving Intraoperative Liver Registration by Learning the Residual of Biomechanics-Based Deformable Registration",
      "title_zh": "翻译失败",
      "authors": [
        "Dingrong Wang",
        "Soheil Azadvar",
        "Jon Heiselman",
        "Xiajun Jiang",
        "Michael Miga",
        "Linwei Wang"
      ],
      "abstract": "The surgical environment imposes unique challenges to the intraoperative\nregistration of organ shapes to their preoperatively-imaged geometry.\nBiomechanical model-based registration remains popular, while deep learning\nsolutions remain limited due to the sparsity and variability of intraoperative\nmeasurements and the limited ground-truth deformation of an organ that can be\nobtained during the surgery. In this paper, we propose a novel \\textit{hybrid}\nregistration approach that leverage a linearized iterative boundary\nreconstruction (LIBR) method based on linear elastic biomechanics, and use deep\nneural networks to learn its residual to the ground-truth deformation (LIBR+).\nWe further formulate a dual-branch spline-residual graph convolutional neural\nnetwork (SR-GCN) to assimilate information from sparse and variable\nintraoperative measurements and effectively propagate it through the geometry\nof the 3D organ. Experiments on a large intraoperative liver registration\ndataset demonstrated the consistent improvements achieved by LIBR+ in\ncomparison to existing rigid, biomechnical model-based non-rigid, and\ndeep-learning based non-rigid approaches to intraoperative liver registration.",
      "tldr_zh": "该论文提出了一种新型混合注册方法 LIBR+，旨在改善术中肝脏注册的精度，通过学习基于线性弹性生物力学模型的 LIBR 方法的残差来修正变形误差。方法结合了双分支样条-残差图卷积神经网络（SR-GCN），有效处理稀疏和可变的术中测量数据，并在 3D 器官几何中传播信息。实验结果显示，在大型术中肝脏注册数据集上，LIBR+ 比现有的刚性注册、基于生物力学的非刚性注册以及基于深度学习的非刚性方法实现了持续的性能提升。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "12 pages, Medical Image Computing and Computer Assisted Intervention\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06901v1",
      "published_date": "2024-03-11 16:54:44 UTC",
      "updated_date": "2024-03-11 16:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:16:14.053849"
    },
    {
      "arxiv_id": "2403.06880v2",
      "title": "Unveiling the Significance of Toddler-Inspired Reward Transition in Goal-Oriented Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junseok Park",
        "Yoonsung Kim",
        "Hee Bin Yoo",
        "Min Whoo Lee",
        "Kibeom Kim",
        "Won-Seok Choi",
        "Minsu Lee",
        "Byoung-Tak Zhang"
      ],
      "abstract": "Toddlers evolve from free exploration with sparse feedback to exploiting\nprior experiences for goal-directed learning with denser rewards. Drawing\ninspiration from this Toddler-Inspired Reward Transition, we set out to explore\nthe implications of varying reward transitions when incorporated into\nReinforcement Learning (RL) tasks. Central to our inquiry is the transition\nfrom sparse to potential-based dense rewards, which share optimal strategies\nregardless of reward changes. Through various experiments, including those in\negocentric navigation and robotic arm manipulation tasks, we found that proper\nreward transitions significantly influence sample efficiency and success rates.\nOf particular note is the efficacy of the toddler-inspired Sparse-to-Dense\n(S2D) transition. Beyond these performance metrics, using Cross-Density\nVisualizer technique, we observed that transitions, especially the S2D, smooth\nthe policy loss landscape, promoting wide minima that enhance generalization in\nRL models.",
      "tldr_zh": "本研究从 toddlers 的学习过程（从稀疏反馈到密集奖励）中汲取灵感，探讨了在目标导向 Reinforcement Learning (RL) 中奖励过渡（尤其是从 sparse 到 potential-based dense rewards）的重要性，这些过渡共享最优策略。\n通过 egocentric navigation 和 robotic arm manipulation 等实验，研究发现适当的奖励过渡（如 Toddler-Inspired Sparse-to-Dense, S2D）显著提升了样本效率和成功率。\n此外，使用 Cross-Density Visualizer 技术，观察到这种过渡能平滑政策损失景观，促进广义最小值，从而增强 RL 模型的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a full paper at AAAI 2024 (Oral presentation): 7 pages\n  (main paper), 2 pages (references), 17 pages (appendix) each",
      "pdf_url": "http://arxiv.org/pdf/2403.06880v2",
      "published_date": "2024-03-11 16:34:23 UTC",
      "updated_date": "2024-03-18 09:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:16:25.958972"
    },
    {
      "arxiv_id": "2403.06872v1",
      "title": "Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents",
      "title_zh": "探索大型语言模型和层次化框架，用于大型非结构化法律文档的分类",
      "authors": [
        "Nishchal Prasad",
        "Mohand Boughanem",
        "Taoufiq Dkaki"
      ],
      "abstract": "Legal judgment prediction suffers from the problem of long case documents\nexceeding tens of thousands of words, in general, and having a non-uniform\nstructure. Predicting judgments from such documents becomes a challenging task,\nmore so on documents with no structural annotation. We explore the\nclassification of these large legal documents and their lack of structural\ninformation with a deep-learning-based hierarchical framework which we call\nMESc; \"Multi-stage Encoder-based Supervised with-clustering\"; for judgment\nprediction. Specifically, we divide a document into parts to extract their\nembeddings from the last four layers of a custom fine-tuned Large Language\nModel, and try to approximate their structure through unsupervised clustering.\nWhich we use in another set of transformer encoder layers to learn the\ninter-chunk representations. We analyze the adaptability of Large Language\nModels (LLMs) with multi-billion parameters (GPT-Neo, and GPT-J) with the\nhierarchical framework of MESc and compare them with their standalone\nperformance on legal texts. We also study their intra-domain(legal) transfer\nlearning capability and the impact of combining embeddings from their last\nlayers in MESc. We test these methods and their effectiveness with extensive\nexperiments and ablation studies on legal documents from India, the European\nUnion, and the United States with the ILDC dataset and a subset of the LexGLUE\ndataset. Our approach achieves a minimum total performance gain of\napproximately 2 points over previous state-of-the-art methods.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs，如 GPT-Neo 和 GPT-J）及分层框架处理大型非结构化法律文档的分类问题，特别是针对法律判决预测的挑战。提出了一种名为 MESc（Multi-stage Encoder-based Supervised with-clustering）的深度学习框架，该框架将文档分成部分，使用自定义微调的 LLMs 从其最后四层提取嵌入，通过无监督聚类近似文档结构，并利用 transformer encoder 学习跨部分表示。实验在 ILDC 数据集和 LexGLUE 子集（涵盖印度、欧盟和美国的法律文档）上进行，结果显示 MESc 比现有最先进方法至少提高了 2 点的总性能，并验证了 LLMs 的领域内迁移学习能力和多层嵌入结合的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper was accepted as a long paper at ECIR 2024. arXiv admin\n  note: substantial text overlap with arXiv:2309.10563",
      "pdf_url": "http://arxiv.org/pdf/2403.06872v1",
      "published_date": "2024-03-11 16:24:08 UTC",
      "updated_date": "2024-03-11 16:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:16:37.719822"
    },
    {
      "arxiv_id": "2403.06869v3",
      "title": "Impact of Noisy Supervision in Foundation Model Learning",
      "title_zh": "噪声监督在基础模型学习中的影响",
      "authors": [
        "Hao Chen",
        "Zihan Wang",
        "Ran Tao",
        "Hongxin Wei",
        "Xing Xie",
        "Masashi Sugiyama",
        "Bhiksha Raj",
        "Jindong Wang"
      ],
      "abstract": "Foundation models are usually pre-trained on large-scale datasets and then\nadapted to downstream tasks through tuning. However, the large-scale\npre-training datasets, often inaccessible or too expensive to handle, can\ncontain label noise that may adversely affect the generalization of the model\nand pose unexpected risks. This paper stands out as the first work to\ncomprehensively understand and analyze the nature of noise in pre-training\ndatasets and then effectively mitigate its impacts on downstream tasks.\nSpecifically, through extensive experiments of fully-supervised and image-text\ncontrastive pre-training on synthetic noisy ImageNet-1K, YFCC15M, and CC12M\ndatasets, we demonstrate that, while slight noise in pre-training can benefit\nin-domain (ID) performance, where the training and testing data share a similar\ndistribution, it always deteriorates out-of-domain (OOD) performance, where\ntraining and testing distributions are significantly different. These\nobservations are agnostic to scales of pre-training datasets, pre-training\nnoise types, model architectures, pre-training objectives, downstream tuning\nmethods, and downstream applications. We empirically ascertain that the reason\nbehind this is that the pre-training noise shapes the feature space\ndifferently. We then propose a tuning method (NMTune) to affine the feature\nspace to mitigate the malignant effect of noise and improve generalization,\nwhich is applicable in both parameter-efficient and black-box tuning manners.\nWe additionally conduct extensive experiments on popular vision and language\nmodels, including APIs, which are supervised and self-supervised pre-trained on\nrealistic noisy data for evaluation. Our analysis and results demonstrate the\nimportance of this novel and fundamental research direction, which we term as\nNoisy Model Learning.",
      "tldr_zh": "这篇论文探讨了基础模型（Foundation models）预训练中标签噪声对模型泛化能力的影响，首次全面分析噪声的性质并提出缓解策略。通过在合成噪声数据集（如ImageNet-1K、YFCC15M和CC12M）上进行的实验，研究发现，轻微噪声可能提升同域（ID）性能，但总是损害异域（OOD）性能，且这一现象独立于数据集规模、噪声类型和模型架构。论文揭示了噪声通过改变特征空间导致这些影响，并提出了一种调整方法NMTune，用于微调特征空间以改善泛化效果，支持参数高效和黑箱调整方式。在各种视觉和语言模型上的实验验证了这一方法的效果，强调了“Noisy Model Learning”这一新研究方向的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 10 figures, 6 tables, preprint. arXiv admin note:\n  substantial text overlap with arXiv:2309.17002",
      "pdf_url": "http://arxiv.org/pdf/2403.06869v3",
      "published_date": "2024-03-11 16:22:41 UTC",
      "updated_date": "2025-05-05 03:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:16:49.750899"
    },
    {
      "arxiv_id": "2403.07040v1",
      "title": "All in One: Multi-Task Prompting for Graph Neural Networks (Extended Abstract)",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangguo Sun",
        "Hong Cheng",
        "Jia Li",
        "Bo Liu",
        "Jihong Guan"
      ],
      "abstract": "This paper is an extended abstract of our original work published in KDD23,\nwhere we won the best research paper award (Xiangguo Sun, Hong Cheng, Jia Li,\nBo Liu, and Jihong Guan. All in one: Multi-task prompting for graph neural\nnetworks. KDD 23) The paper introduces a novel approach to bridging the gap\nbetween pre-trained graph models and the diverse tasks they're applied to,\ninspired by the success of prompt learning in NLP. Recognizing the challenge of\naligning pre-trained models with varied graph tasks (node level, edge level,\nand graph level), which can lead to negative transfer and poor performance, we\npropose a multi-task prompting method for graphs. This method involves unifying\ngraph and language prompt formats, enabling NLP's prompting strategies to be\nadapted for graph tasks. By analyzing the task space of graph applications, we\nreformulate problems to fit graph-level tasks and apply meta-learning to\nimprove prompt initialization for multiple tasks. Experiments show our method's\neffectiveness in enhancing model performance across different graph tasks.\n  Beyond the original work, in this extended abstract, we further discuss the\ngraph prompt from a bigger picture and provide some of the latest work toward\nthis area.",
      "tldr_zh": "这篇论文介绍了“All in One”方法，即多任务提示(multi-task prompting)用于Graph Neural Networks，以桥接预训练模型与多样图任务（如节点级别、边级别和图级别）的差距，解决负转移(negative transfer)问题。方法通过统一图和语言提示格式，将NLP的提示学习策略适应到图任务，并应用元学习(meta-learning)来优化提示初始化和任务空间分析。实验结果显示，该方法显著提升了模型在不同图任务上的性能；扩展摘要进一步讨论了图提示的更大图景和相关最新工作。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "submitted to IJCAI 2024 Sister Conferences Track. The original paper\n  can be seen at arXiv:2307.01504",
      "pdf_url": "http://arxiv.org/pdf/2403.07040v1",
      "published_date": "2024-03-11 16:04:58 UTC",
      "updated_date": "2024-03-11 16:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:17:01.654923"
    },
    {
      "arxiv_id": "2403.06843v1",
      "title": "Towards an educational tool for supporting neonatologists in the delivery room",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Leonardi",
        "Clara Maldarizzi",
        "Stefania Montani",
        "Manuel Striani",
        "Mariachiara Martina Strozzi"
      ],
      "abstract": "Nowadays, there is evidence that several factors may increase the risk, for\nan infant, to require stabilisation or resuscitation manoeuvres at birth.\nHowever, this risk factors are not completely known, and a universally\napplicable model for predicting high-risk situations is not available yet.\nConsidering both these limitations and the fact that the need for resuscitation\nat birth is a rare event, periodic training of the healthcare personnel\nresponsible for newborn caring in the delivery room is mandatory.\n  In this paper, we propose a machine learning approach for identifying risk\nfactors and their impact on the birth event from real data, which can be used\nby personnel to progressively increase and update their knowledge. Our final\ngoal will be the one of designing a user-friendly mobile application, able to\nimprove the recognition rate and the planning of the appropriate interventions\non high-risk patients.",
      "tldr_zh": "本研究针对新生儿出生时可能需要稳定或复苏操作的风险因素不确定性，提出了一种机器学习方法，从真实数据中识别这些风险因素及其对出生事件的影响。该方法旨在帮助产房医疗人员（如neonatologists）通过定期培训逐步提升和更新知识，最终目标是开发一个用户友好的移动应用，提高对高风险患者的识别率和干预规划，从而增强医疗决策的准确性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures, conference paper",
      "pdf_url": "http://arxiv.org/pdf/2403.06843v1",
      "published_date": "2024-03-11 16:03:21 UTC",
      "updated_date": "2024-03-11 16:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:17:11.261947"
    },
    {
      "arxiv_id": "2403.06840v2",
      "title": "RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Xuhong Zhang",
        "Weihao Liu",
        "Jianwei Yin",
        "Jiannan Cao",
        "Tianyu Du"
      ],
      "abstract": "Large language models (LLMs) demonstrate exceptional performance in numerous\ntasks but still heavily rely on knowledge stored in their parameters. Moreover,\nupdating this knowledge incurs high training costs. Retrieval-augmented\ngeneration (RAG) methods address this issue by integrating external knowledge.\nThe model can answer questions it couldn't previously by retrieving knowledge\nrelevant to the query. This approach improves performance in certain scenarios\nfor specific tasks. However, if irrelevant texts are retrieved, it may impair\nmodel performance. In this paper, we propose Retrieval Augmented Iterative\nSelf-Feedback (RA-ISF), a framework that iteratively decomposes tasks and\nprocesses them in three submodules to enhance the model's problem-solving\ncapabilities. Experiments show that our method outperforms existing benchmarks,\nperforming well on models like GPT3.5, Llama2, significantly enhancing factual\nreasoning capabilities and reducing hallucinations.",
      "tldr_zh": "大型语言模型 (LLMs) 在诸多任务中表现出色，但依赖参数存储的知识且更新成本高昂，而 Retrieval-Augmented Generation (RAG) 方法虽能整合外部知识提升性能，却可能因检索无关文本而影响模型表现。本文提出 Retrieval Augmented Iterative Self-Feedback (RA-ISF) 框架，通过迭代分解任务并在三个子模块中处理，增强模型的回答和理解能力。RA-ISF 框架显著提高了事实推理能力并减少了 hallucinations。实验结果表明，该方法在 GPT3.5 和 Llama2 等模型上超越现有基准，展示了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, multiple figures. Providing second version RA-ISF",
      "pdf_url": "http://arxiv.org/pdf/2403.06840v2",
      "published_date": "2024-03-11 16:01:05 UTC",
      "updated_date": "2024-06-06 11:55:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:17:26.240957"
    },
    {
      "arxiv_id": "2403.08506v1",
      "title": "DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sikai Bai",
        "Jie Zhang",
        "Shuaicheng Li",
        "Song Guo",
        "Jingcai Guo",
        "Jun Hou",
        "Tao Han",
        "Xiaocheng Lu"
      ],
      "abstract": "Federated learning (FL) has emerged as a powerful paradigm for learning from\ndecentralized data, and federated domain generalization further considers the\ntest dataset (target domain) is absent from the decentralized training data\n(source domains). However, most existing FL methods assume that domain labels\nare provided during training, and their evaluation imposes explicit constraints\non the number of domains, which must strictly match the number of clients.\nBecause of the underutilization of numerous edge devices and additional\ncross-client domain annotations in the real world, such restrictions may be\nimpractical and involve potential privacy leaks. In this paper, we propose an\nefficient and novel approach, called Disentangled Prompt Tuning (DiPrompT), a\nmethod that tackles the above restrictions by learning adaptive prompts for\ndomain generalization in a distributed manner. Specifically, we first design\ntwo types of prompts, i.e., global prompt to capture general knowledge across\nall clients and domain prompts to capture domain-specific knowledge. They\neliminate the restriction on the one-to-one mapping between source domains and\nlocal clients. Furthermore, a dynamic query metric is introduced to\nautomatically search the suitable domain label for each sample, which includes\ntwo-substep text-image alignments based on prompt tuning without\nlabor-intensive annotation. Extensive experiments on multiple datasets\ndemonstrate that our DiPrompT achieves superior domain generalization\nperformance over state-of-the-art FL methods when domain labels are not\nprovided, and even outperforms many centralized learning methods using domain\nlabels.",
      "tldr_zh": "本文提出 DiPrompT，一种解耦提示调整方法，用于 Federated Learning (FL) 中的多隐域泛化问题，旨在解决现有方法对域标签依赖和客户端-域一一映射的限制。DiPrompT 通过设计 global prompt 捕获跨客户端的通用知识，以及 domain prompts 捕获特定域知识，并在动态查询指标的帮助下，实现自动文本-图像对齐来为样本分配域标签，而无需手动标注。实验在多个数据集上表明，DiPrompT 在无域标签情况下显著优于最先进 FL 方法，甚至超越了许多使用域标签的集中式学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08506v1",
      "published_date": "2024-03-11 15:58:15 UTC",
      "updated_date": "2024-03-11 15:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:17:39.099757"
    },
    {
      "arxiv_id": "2403.06835v1",
      "title": "Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Wenting Chen",
        "Pengyu Wang",
        "Hui Ren",
        "Lichao Sun",
        "Quanzheng Li",
        "Yixuan Yuan",
        "Xiang Li"
      ],
      "abstract": "Data scarcity and privacy concerns limit the availability of high-quality\nmedical images for public use, which can be mitigated through medical image\nsynthesis. However, current medical image synthesis methods often struggle to\naccurately capture the complexity of detailed anatomical structures and\npathological conditions. To address these challenges, we propose a novel\nmedical image synthesis model that leverages fine-grained image-text alignment\nand anatomy-pathology prompts to generate highly detailed and accurate\nsynthetic medical images. Our method integrates advanced natural language\nprocessing techniques with image generative modeling, enabling precise\nalignment between descriptive text prompts and the synthesized images'\nanatomical and pathological details. The proposed approach consists of two key\ncomponents: an anatomy-pathology prompting module and a fine-grained\nalignment-based synthesis module. The anatomy-pathology prompting module\nautomatically generates descriptive prompts for high-quality medical images. To\nfurther synthesize high-quality medical images from the generated prompts, the\nfine-grained alignment-based synthesis module pre-defines a visual codebook for\nthe radiology dataset and performs fine-grained alignment between the codebook\nand generated prompts to obtain key patches as visual clues, facilitating\naccurate image synthesis. We validate the superiority of our method through\nexperiments on public chest X-ray datasets and demonstrate that our synthetic\nimages preserve accurate semantic information, making them valuable for various\nmedical applications.",
      "tldr_zh": "该论文针对医疗图像合成中的数据稀缺和隐私问题，提出了一种新模型，利用 fine-grained image-text alignment 和 anatomy-pathology prompting 来生成高度详细且准确的合成图像。该模型包括两个关键组件：anatomy-pathology prompting module，用于自动创建描述性提示；以及 fine-grained alignment-based synthesis module，通过预定义的 visual codebook 和提示之间的精细对齐，提取关键补丁作为视觉线索以辅助图像合成。实验在公共胸部 X 射线数据集上验证了方法的优越性，生成的合成图像能够精确保留语义信息，从而为各种医疗应用提供宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06835v1",
      "published_date": "2024-03-11 15:56:17 UTC",
      "updated_date": "2024-03-11 15:56:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:17:54.388248"
    },
    {
      "arxiv_id": "2403.06832v4",
      "title": "Noise-powered Multi-modal Knowledge Graph Representation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuo Chen",
        "Yin Fang",
        "Yichi Zhang",
        "Lingbing Guo",
        "Jiaoyan Chen",
        "Jeff Z. Pan",
        "Huajun Chen",
        "Wen Zhang"
      ],
      "abstract": "The rise of Multi-modal Pre-training highlights the necessity for a unified\nMulti-Modal Knowledge Graph (MMKG) representation learning framework. Such a\nframework is essential for embedding structured knowledge into multi-modal\nLarge Language Models effectively, alleviating issues like knowledge\nmisconceptions and multi-modal hallucinations. In this work, we explore the\nefficacy of models in accurately embedding entities within MMKGs through two\npivotal tasks: Multi-modal Knowledge Graph Completion (MKGC) and Multi-modal\nEntity Alignment (MMEA). Building on this foundation, we propose a novel SNAG\nmethod that utilizes a Transformer-based architecture equipped with\nmodality-level noise masking to robustly integrate multi-modal entity features\nin KGs. By incorporating specific training objectives for both MKGC and MMEA,\nour approach achieves SOTA performance across a total of ten datasets,\ndemonstrating its versatility. Moreover, SNAG can not only function as a\nstandalone model but also enhance other existing methods, providing stable\nperformance improvements. Code and data are available at\nhttps://github.com/zjukg/SNAG.",
      "tldr_zh": "该论文探讨了统一的 Multi-Modal Knowledge Graph (MMKG) 表示学习框架，以有效嵌入结构化知识到多模态大语言模型中，缓解知识误解和多模态幻觉问题。作者提出 SNAG 方法，使用 Transformer 架构结合模态级噪声掩码，robustly 整合多模态实体特征，并针对 Multi-modal Knowledge Graph Completion (MKGC) 和 Multi-modal Entity Alignment (MMEA) 任务设置特定训练目标。实验结果显示，SNAG 在十个数据集上达到 SOTA 性能，并可作为独立模型或增强现有方法，提供稳定的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025 Accepted, Repo is available at\n  https://github.com/zjukg/SNAG",
      "pdf_url": "http://arxiv.org/pdf/2403.06832v4",
      "published_date": "2024-03-11 15:48:43 UTC",
      "updated_date": "2025-01-15 06:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:18:05.282020"
    },
    {
      "arxiv_id": "2403.06828v3",
      "title": "NeuPAN: Direct Point Robot Navigation with End-to-End Model-based Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruihua Han",
        "Shuai Wang",
        "Shuaijun Wang",
        "Zeqing Zhang",
        "Jianjun Chen",
        "Shijie Lin",
        "Chengyang Li",
        "Chengzhong Xu",
        "Yonina C. Eldar",
        "Qi Hao",
        "Jia Pan"
      ],
      "abstract": "Navigating a nonholonomic robot in a cluttered, unknown environment requires\naccurate perception and precise motion control for real-time collision\navoidance. This paper presents NeuPAN: a real-time, highly accurate, map-free,\neasy-to-deploy, and environment-invariant robot motion planner. Leveraging a\ntightly coupled perception-to-control framework, NeuPAN has two key innovations\ncompared to existing approaches: 1) it directly maps raw point cloud data to a\nlatent distance feature space for collision-free motion generation, avoiding\nerror propagation from the perception to control pipeline; 2) it is\ninterpretable from an end-to-end model-based learning perspective. The crux of\nNeuPAN is solving an end-to-end mathematical model with numerous point-level\nconstraints using a plug-and-play (PnP) proximal alternating-minimization\nnetwork (PAN), incorporating neurons in the loop. This allows NeuPAN to\ngenerate real-time, physically interpretable motions. It seamlessly integrates\ndata and knowledge engines, and its network parameters can be fine-tuned via\nbackpropagation. We evaluate NeuPAN on a ground mobile robot, a wheel-legged\nrobot, and an autonomous vehicle, in extensive simulated and real-world\nenvironments. Results demonstrate that NeuPAN outperforms existing baselines in\nterms of accuracy, efficiency, robustness, and generalization capabilities\nacross various environments, including the cluttered sandbox, office, corridor,\nand parking lot. We show that NeuPAN works well in unknown and unstructured\nenvironments with arbitrarily shaped objects, transforming impassable paths\ninto passable ones.",
      "tldr_zh": "本研究提出 NeuPAN，一种端到端的模型学习框架，用于直接点机器人导航，实现实时、高精度、无地图的运动规划。NeuPAN 的关键创新包括：直接将原始点云数据映射到潜在距离特征空间以生成无碰撞运动，避免感知到控制管道的错误传播；以及使用 plug-and-play (PnP) proximal alternating-minimization network (PAN) 解决端到端数学模型，融入神经元循环以确保物理可解释性。实验在地面移动机器人、轮腿机器人和自动驾驶车辆上进行，结果显示 NeuPAN 在杂乱环境（如沙箱、办公室和停车场）中优于现有基线，提高了准确性、效率、鲁棒性和泛化能力，能够处理未知非结构化场景并转化不可通行路径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by TRO 2025; project website:\n  https://hanruihua.github.io/neupan_project/",
      "pdf_url": "http://arxiv.org/pdf/2403.06828v3",
      "published_date": "2024-03-11 15:44:38 UTC",
      "updated_date": "2025-02-11 15:47:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:18:17.359803"
    },
    {
      "arxiv_id": "2403.06826v1",
      "title": "In-context Exploration-Exploitation for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenwen Dai",
        "Federico Tomasi",
        "Sina Ghiassian"
      ],
      "abstract": "In-context learning is a promising approach for online policy learning of\noffline reinforcement learning (RL) methods, which can be achieved at inference\ntime without gradient optimization. However, this method is hindered by\nsignificant computational costs resulting from the gathering of large training\ntrajectory sets and the need to train large Transformer models. We address this\nchallenge by introducing an In-context Exploration-Exploitation (ICEE)\nalgorithm, designed to optimize the efficiency of in-context policy learning.\nUnlike existing models, ICEE performs an exploration-exploitation trade-off at\ninference time within a Transformer model, without the need for explicit\nBayesian inference. Consequently, ICEE can solve Bayesian optimization problems\nas efficiently as Gaussian process biased methods do, but in significantly less\ntime. Through experiments in grid world environments, we demonstrate that ICEE\ncan learn to solve new RL tasks using only tens of episodes, marking a\nsubstantial improvement over the hundreds of episodes needed by the previous\nin-context learning method.",
      "tldr_zh": "本文提出了一种名为 ICEE 的算法，用于优化 In-context Learning 在 Reinforcement Learning 中的在线策略学习问题，旨在减少大规模训练轨迹和 Transformer 模型训练的计算成本。ICEE 通过在推理时进行探索-exploitation 权衡，而无需显式 Bayesian inference，从而高效解决贝叶斯优化问题，与 Gaussian process 偏置方法相当但速度更快。在网格世界环境的实验中，ICEE 仅需数十个 episodes 即可学习新任务，显著优于传统方法所需的数百个 episodes。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06826v1",
      "published_date": "2024-03-11 15:43:14 UTC",
      "updated_date": "2024-03-11 15:43:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:18:28.237999"
    },
    {
      "arxiv_id": "2403.06817v2",
      "title": "Are Targeted Messages More Effective?",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Grohe",
        "Eran Rosenbluth"
      ],
      "abstract": "Graph neural networks (GNN) are deep learning architectures for graphs.\nEssentially, a GNN is a distributed message passing algorithm, which is\ncontrolled by parameters learned from data. It operates on the vertices of a\ngraph: in each iteration, vertices receive a message on each incoming edge,\naggregate these messages, and then update their state based on their current\nstate and the aggregated messages. The expressivity of GNNs can be\ncharacterised in terms of certain fragments of first-order logic with counting\nand the Weisfeiler-Lehman algorithm.\n  The core GNN architecture comes in two different versions. In the first\nversion, a message only depends on the state of the source vertex, whereas in\nthe second version it depends on the states of the source and target vertices.\nIn practice, both of these versions are used, but the theory of GNNs so far\nmostly focused on the first one. On the logical side, the two versions\ncorrespond to two fragments of first-order logic with counting that we call\nmodal and guarded.\n  The question whether the two versions differ in their expressivity has been\nmostly overlooked in the GNN literature and has only been asked recently\n(Grohe, LICS'23). We answer this question here. It turns out that the answer is\nnot as straightforward as one might expect. By proving that the modal and\nguarded fragment of first-order logic with counting have the same expressivity\nover labelled undirected graphs, we show that in a non-uniform setting the two\nGNN versions have the same expressivity. However, we also prove that in a\nuniform setting the second version is strictly more expressive.",
      "tldr_zh": "这篇论文探讨了图神经网络 (GNNs) 中两种消息传递机制的表达性差异：第一种仅依赖源顶点状态，第二种依赖源和目标顶点状态。作者将这些机制与 first-order logic with counting 的 modal 和 guarded 片段相对接，并通过理论证明，在非均匀设置下两者具有相同的表达性，而在均匀设置下，第二种机制更具表达性。研究结果表明，针对性消息在特定场景下更有效，为 GNNs 的设计和应用提供了重要理论指导。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG",
        "68T05, 68T07",
        "I.2.6"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06817v2",
      "published_date": "2024-03-11 15:34:57 UTC",
      "updated_date": "2024-05-19 11:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:18:40.887850"
    },
    {
      "arxiv_id": "2403.09713v2",
      "title": "A Hybrid Intelligence Method for Argument Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Michiel van der Meer",
        "Enrico Liscio",
        "Catholijn M. Jonker",
        "Aske Plaat",
        "Piek Vossen",
        "Pradeep K. Murukannaiah"
      ],
      "abstract": "Large-scale survey tools enable the collection of citizen feedback in opinion\ncorpora. Extracting the key arguments from a large and noisy set of opinions\nhelps in understanding the opinions quickly and accurately. Fully automated\nmethods can extract arguments but (1) require large labeled datasets that\ninduce large annotation costs and (2) work well for known viewpoints, but not\nfor novel points of view. We propose HyEnA, a hybrid (human + AI) method for\nextracting arguments from opinionated texts, combining the speed of automated\nprocessing with the understanding and reasoning capabilities of humans. We\nevaluate HyEnA on three citizen feedback corpora. We find that, on the one\nhand, HyEnA achieves higher coverage and precision than a state-of-the-art\nautomated method when compared to a common set of diverse opinions, justifying\nthe need for human insight. On the other hand, HyEnA requires less human effort\nand does not compromise quality compared to (fully manual) expert analysis,\ndemonstrating the benefit of combining human and artificial intelligence.",
      "tldr_zh": "这篇论文提出了 HyEnA，一种混合智能（Hybrid Intelligence）方法，用于从大规模意见文本中提取关键论点（Argument Mining），旨在结合 AI 的自动处理速度与人类的理解和推理能力。HyEnA 解决了全自动方法的局限性，包括减少对大型标注数据集的需求和更好地处理新观点。实验结果显示，在三个公民反馈语料库上，HyEnA 比最先进自动方法实现了更高的覆盖率和精确度，同时比完全手动专家分析需要更少人力且不降低质量。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in JAIR",
      "pdf_url": "http://arxiv.org/pdf/2403.09713v2",
      "published_date": "2024-03-11 15:15:27 UTC",
      "updated_date": "2024-08-01 11:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:18:51.748113"
    },
    {
      "arxiv_id": "2403.06786v1",
      "title": "Genetic Learning for Designing Sim-to-Real Data Augmentations",
      "title_zh": "翻译失败",
      "authors": [
        "Bram Vanherle",
        "Nick Michiels",
        "Frank Van Reeth"
      ],
      "abstract": "Data augmentations are useful in closing the sim-to-real domain gap when\ntraining on synthetic data. This is because they widen the training data\ndistribution, thus encouraging the model to generalize better to other domains.\nMany image augmentation techniques exist, parametrized by different settings,\nsuch as strength and probability. This leads to a large space of different\npossible augmentation policies. Some policies work better than others for\novercoming the sim-to-real gap for specific datasets, and it is unclear why.\nThis paper presents two different interpretable metrics that can be combined to\npredict how well a certain augmentation policy will work for a specific\nsim-to-real setting, focusing on object detection. We validate our metrics by\ntraining many models with different augmentation policies and showing a strong\ncorrelation with performance on real data. Additionally, we introduce\nGeneticAugment, a genetic programming method that can leverage these metrics to\nautomatically design an augmentation policy for a specific dataset without\nneeding to train a model.",
      "tldr_zh": "这篇论文探讨了数据增强（data augmentations）在缩小sim-to-real领域差距中的作用，提出两个可解释的指标来预测特定增强策略在物体检测（object detection）任务上的表现。作者通过实验训练多个模型，验证这些指标与真实数据性能之间的强相关性。论文还引入GeneticAugment，一种基于genetic programming的遗传编程方法，能自动为特定数据集设计最佳增强策略，而无需额外训练模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages; accepted at DMLR Workshop @ ICRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06786v1",
      "published_date": "2024-03-11 15:00:56 UTC",
      "updated_date": "2024-03-11 15:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:19:04.499747"
    },
    {
      "arxiv_id": "2403.06764v3",
      "title": "An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Chen",
        "Haozhe Zhao",
        "Tianyu Liu",
        "Shuai Bai",
        "Junyang Lin",
        "Chang Zhou",
        "Baobao Chang"
      ],
      "abstract": "In this study, we identify the inefficient attention phenomena in Large\nVision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5,\nQwenVL-Chat and Video-LLaVA. We find out that the attention computation over\nvisual tokens is of extreme inefficiency in the deep layers of popular LVLMs,\nsuggesting a need for a sparser approach compared to textual data handling. To\nthis end, we introduce FastV, a versatile plug-and-play method designed to\noptimize computational efficiency by learning adaptive attention patterns in\nearly layers and pruning visual tokens in subsequent ones. Our evaluations\ndemonstrate FastV's ability to dramatically reduce computational costs (e.g., a\n45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in a\nwide range of image and video understanding tasks. The computational efficiency\nand performance trade-off of FastV are highly customizable and\npareto-efficient. It can compress the FLOPs of a 13B-parameter model to achieve\na lower budget than that of a 7B-parameter model, while still maintaining\nsuperior performance. We believe FastV has practical values for deployment of\nLVLMs in edge devices and commercial models. Code is released at\nhttps://github.com/pkunlp-icler/FastV.",
      "tldr_zh": "这篇论文发现 Large Vision-Language Models (LVLMs) 在深层处理视觉标记时，注意力计算效率低下，导致计算资源浪费。针对此问题，研究者提出 FastV，一种通用的 plug-and-play 方法，通过在早期层学习自适应注意力模式，并在后续层修剪视觉标记来优化推理过程。实验结果显示，FastV 能显著减少计算成本（如为 LLaVA-1.5-13B 减少 45% 的 FLOPs），同时在图像和视频理解任务中保持出色性能，并提供高度可定制的 Pareto 有效的效率-性能权衡。该方法使大型模型在边缘设备和商业部署中更具实用价值。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024 (Oral), code is released at\n  https://github.com/pkunlp-icler/FastV,",
      "pdf_url": "http://arxiv.org/pdf/2403.06764v3",
      "published_date": "2024-03-11 14:35:32 UTC",
      "updated_date": "2024-09-02 05:48:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:19:17.471722"
    },
    {
      "arxiv_id": "2403.06754v2",
      "title": "ALaRM: Align Language Models via Hierarchical Rewards Modeling",
      "title_zh": "ALaRM：通过分层奖励建模对齐语言模型",
      "authors": [
        "Yuhang Lai",
        "Siyuan Wang",
        "Shujun Liu",
        "Xuanjing Huang",
        "Zhongyu Wei"
      ],
      "abstract": "We introduce ALaRM, the first framework modeling hierarchical rewards in\nreinforcement learning from human feedback (RLHF), which is designed to enhance\nthe alignment of large language models (LLMs) with human preferences. The\nframework addresses the limitations of current alignment approaches, which\noften struggle with the inconsistency and sparsity of human supervision\nsignals, by integrating holistic rewards with aspect-specific rewards. This\nintegration enables more precise and consistent guidance of language models\ntowards desired outcomes, particularly in complex and open text generation\ntasks. By employing a methodology that filters and combines multiple rewards\nbased on their consistency, the framework provides a reliable mechanism for\nimproving model alignment. We validate our approach through applications in\nlong-form question answering and machine translation tasks, employing\ngpt-3.5-turbo for pairwise comparisons, and demonstrate improvements over\nexisting baselines. Our work underscores the effectiveness of hierarchical\nrewards modeling in refining LLM training processes for better human preference\nalignment. We release our code at https://ALaRM-fdu.github.io.",
      "tldr_zh": "我们引入了 ALaRM 框架，这是第一个在强化学习从人类反馈 (RLHF) 中建模分层奖励的系统，旨在提升大型语言模型 (LLMs) 与人类偏好的对齐。该框架通过整合 holistic rewards 和 aspect-specific rewards，并基于一致性过滤和组合机制，提供更精确、一致的指导，避免了现有方法中人类监督信号的不一致性和稀疏性问题。在长形式问答和机器翻译任务上，使用 gpt-3.5-turbo 进行实验，ALaRM 比基线模型表现出显著改进，证明了分层奖励建模在优化 LLM 训练过程中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06754v2",
      "published_date": "2024-03-11 14:28:40 UTC",
      "updated_date": "2024-03-16 12:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:19:30.360173"
    },
    {
      "arxiv_id": "2403.06745v1",
      "title": "ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Shaojie Dai",
        "Xin Liu",
        "Ping Luo",
        "Yue Yu"
      ],
      "abstract": "Large language model (LLM) has achieved promising performance in multilingual\nmachine translation tasks through zero/few-shot prompts or prompt-tuning.\nHowever, due to the mixture of multilingual data during the pre-training of\nLLM, the LLM-based translation models face the off-target issue in both\nprompt-based methods, including a series of phenomena, namely instruction\nmisunderstanding, translation with wrong language and over-generation. For this\nissue, this paper introduces an\n\\textbf{\\underline{A}}uto-\\textbf{\\underline{C}}onstriction\n\\textbf{\\underline{T}}urning mechanism for \\textbf{\\underline{M}}ultilingual\n\\textbf{\\underline{N}}eural \\textbf{\\underline{M}}achine\n\\textbf{\\underline{T}}ranslation (\\model), which is a novel supervised\nfine-tuning mechanism and orthogonal to the traditional prompt-based methods.\nIn this method, \\model automatically constructs a constrained template in the\ntarget side by adding trigger tokens ahead of the ground truth. Furthermore,\ntrigger tokens can be arranged and combined freely to represent different task\nsemantics, and they can be iteratively updated to maximize the label\nlikelihood. Experiments are performed on WMT test sets with multiple metrics,\nand the experimental results demonstrate that \\model achieves substantially\nimproved performance across multiple translation directions and reduce the\noff-target phenomena in the translation.",
      "tldr_zh": "这篇论文针对大型语言模型（LLM）在多语言神经机器翻译（Multilingual Neural Machine Translation）中的off-target问题（如指令误解、翻译错误语言和过度生成），提出了ACT-MNMT机制，这是一种新型监督微调方法。ACT-MNMT通过在目标侧添加触发tokens自动构建约束模板，这些tokens可自由排列组合并迭代更新，以最大化标签可能性。实验结果显示，在WMT测试集上，该机制显著提升了多个翻译方向的性能，并有效减少了off-target现象。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06745v1",
      "published_date": "2024-03-11 14:10:57 UTC",
      "updated_date": "2024-03-11 14:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:19:39.909031"
    },
    {
      "arxiv_id": "2403.06735v1",
      "title": "Enhancing Image Caption Generation Using Reinforcement Learning with Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Adarsh N L",
        "Arun P V",
        "Aravindh N L"
      ],
      "abstract": "Research on generative models to produce human-aligned / human-preferred\noutputs has seen significant recent contributions. Between text and\nimage-generative models, we narrowed our focus to text-based generative models,\nparticularly to produce captions for images that align with human preferences.\nIn this research, we explored a potential method to amplify the performance of\nthe Deep Neural Network Model to generate captions that are preferred by\nhumans. This was achieved by integrating Supervised Learning and Reinforcement\nLearning with Human Feedback (RLHF) using the Flickr8k dataset. Also, a novel\nloss function that is capable of optimizing the model based on human feedback\nis introduced. In this paper, we provide a concise sketch of our approach and\nresults, hoping to contribute to the ongoing advances in the field of\nhuman-aligned generative AI models.",
      "tldr_zh": "本研究旨在提升图像标题生成模型的表现，使其输出更符合人类偏好。研究方法结合了Supervised Learning和Reinforcement Learning with Human Feedback (RLHF)，并使用Flickr8k数据集进行训练，同时引入了一个新颖的损失函数来基于人类反馈优化模型。实验结果显示，该方法显著改善了生成标题的质量，为人类对齐的生成式AI模型领域提供了重要贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 Pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06735v1",
      "published_date": "2024-03-11 13:57:05 UTC",
      "updated_date": "2024-03-11 13:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:19:51.080860"
    },
    {
      "arxiv_id": "2403.06734v1",
      "title": "Real-Time Multimodal Cognitive Assistant for Emergency Medical Services",
      "title_zh": "翻译失败",
      "authors": [
        "Keshara Weerasinghe",
        "Saahith Janapati",
        "Xueren Ge",
        "Sion Kim",
        "Sneha Iyer",
        "John A. Stankovic",
        "Homa Alemzadeh"
      ],
      "abstract": "Emergency Medical Services (EMS) responders often operate under\ntime-sensitive conditions, facing cognitive overload and inherent risks,\nrequiring essential skills in critical thinking and rapid decision-making. This\npaper presents CognitiveEMS, an end-to-end wearable cognitive assistant system\nthat can act as a collaborative virtual partner engaging in the real-time\nacquisition and analysis of multimodal data from an emergency scene and\ninteracting with EMS responders through Augmented Reality (AR) smart glasses.\nCognitiveEMS processes the continuous streams of data in real-time and\nleverages edge computing to provide assistance in EMS protocol selection and\nintervention recognition. We address key technical challenges in real-time\ncognitive assistance by introducing three novel components: (i) a Speech\nRecognition model that is fine-tuned for real-world medical emergency\nconversations using simulated EMS audio recordings, augmented with synthetic\ndata generated by large language models (LLMs); (ii) an EMS Protocol Prediction\nmodel that combines state-of-the-art (SOTA) tiny language models with EMS\ndomain knowledge using graph-based attention mechanisms; (iii) an EMS Action\nRecognition module which leverages multimodal audio and video data and protocol\npredictions to infer the intervention/treatment actions taken by the responders\nat the incident scene. Our results show that for speech recognition we achieve\nsuperior performance compared to SOTA (WER of 0.290 vs. 0.618) on\nconversational data. Our protocol prediction component also significantly\noutperforms SOTA (top-3 accuracy of 0.800 vs. 0.200) and the action recognition\nachieves an accuracy of 0.727, while maintaining an end-to-end latency of 3.78s\nfor protocol prediction on the edge and 0.31s on the server.",
      "tldr_zh": "本论文介绍了CognitiveEMS，一种实时可穿戴认知辅助系统，旨在为紧急医疗服务（EMS）响应者提供虚拟合作伙伴支持，通过AR智能眼镜实时获取和分析多模态数据（如音频和视频），并利用边缘计算辅助协议选择和干预识别。系统创新性地引入三个组件：(i) 基于模拟EMS音频和LLM生成合成数据的微调语音识别模型；(ii) 结合SOTA小型语言模型与图-based注意力机制的EMS协议预测模型；(iii) 利用多模态数据和协议预测进行动作识别的模块。实验结果显示，语音识别的WER为0.290，优于SOTA的0.618；协议预测的top-3准确率达0.800；动作识别准确率0.727，同时端到端延迟保持在3.78s（边缘）和0.31s（服务器），显著提升了EMS响应效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2403.06734v1",
      "published_date": "2024-03-11 13:56:57 UTC",
      "updated_date": "2024-03-11 13:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:20:06.277590"
    },
    {
      "arxiv_id": "2403.06725v4",
      "title": "Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning",
      "title_zh": "通过监督预训练和重要性机制微调",
      "authors": [
        "Hengyuan Zhang",
        "Zitao Liu",
        "Shuyan Huang",
        "Chenming Shang",
        "Bojun Zhan",
        "Yong Jiang"
      ],
      "abstract": "Knowledge tracing (KT) aims to estimate student's knowledge mastery based on\ntheir historical interactions. Recently, the deep learning based KT (DLKT)\napproaches have achieved impressive performance in the KT task. These DLKT\nmodels heavily rely on the large number of available student interactions.\nHowever, due to various reasons such as budget constraints and privacy\nconcerns, observed interactions are very limited in many real-world scenarios,\na.k.a, low-resource KT datasets. Directly training a DLKT model on a\nlow-resource KT dataset may lead to overfitting and it is difficult to choose\nthe appropriate deep neural architecture. Therefore, in this paper, we propose\na low-resource KT framework called LoReKT to address above challenges. Inspired\nby the prevalent \"pre-training and fine-tuning\" paradigm, we aim to learn\ntransferable parameters and representations from rich-resource KT datasets\nduring the pre-training stage and subsequently facilitate effective adaptation\nto low-resource KT datasets. Specifically, we simplify existing sophisticated\nDLKT model architectures with purely a stack of transformer decoders. We design\nan encoding mechanism to incorporate student interactions from multiple KT data\nsources and develop an importance mechanism to prioritize updating parameters\nwith high importance while constraining less important ones during the\nfine-tuning stage. We evaluate LoReKT on six public KT datasets and\nexperimental results demonstrate the superiority of our approach in terms of\nAUC and Accuracy. To encourage reproducible research, we make our data and code\npublicly available at https://github.com/rattlesnakey/LoReKT.",
      "tldr_zh": "这篇论文针对低资源知识追踪 (KT) 任务，提出了一种名为 LoReKT 的框架，以解决深度学习基于 KT (DLKT) 模型在数据有限场景下的过拟合问题。LoReKT 采用“预训练和微调”范式：在丰富资源 KT 数据集上进行监督预训练 (Supervised Pre-training)，使用简单的 Transformer Decoders 堆栈来学习可转移参数和表示；随后在微调阶段引入 Importance Mechanism 来优先更新高重要性参数，同时约束其他参数。实验结果显示，LoReKT 在六个公共 KT 数据集上显著提高了 AUC 和 Accuracy 性能，并公开代码以促进可重复研究。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "29 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06725v4",
      "published_date": "2024-03-11 13:44:43 UTC",
      "updated_date": "2024-10-25 10:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:20:17.917916"
    },
    {
      "arxiv_id": "2403.06677v1",
      "title": "Streamlining in the Riemannian Realm: Efficient Riemannian Optimization with Loopless Variance Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Yury Demidovich",
        "Grigory Malinovsky",
        "Peter Richtárik"
      ],
      "abstract": "In this study, we investigate stochastic optimization on Riemannian\nmanifolds, focusing on the crucial variance reduction mechanism used in both\nEuclidean and Riemannian settings. Riemannian variance-reduced methods usually\ninvolve a double-loop structure, computing a full gradient at the start of each\nloop. Determining the optimal inner loop length is challenging in practice, as\nit depends on strong convexity or smoothness constants, which are often unknown\nor hard to estimate. Motivated by Euclidean methods, we introduce the\nRiemannian Loopless SVRG (R-LSVRG) and PAGE (R-PAGE) methods. These methods\nreplace the outer loop with probabilistic gradient computation triggered by a\ncoin flip in each iteration, ensuring simpler proofs, efficient hyperparameter\nselection, and sharp convergence guarantees. Using R-PAGE as a framework for\nnon-convex Riemannian optimization, we demonstrate its applicability to various\nimportant settings. For example, we derive Riemannian MARINA (R-MARINA) for\ndistributed settings with communication compression, providing the best\ntheoretical communication complexity guarantees for non-convex distributed\noptimization over Riemannian manifolds. Experimental results support our\ntheoretical findings.",
      "tldr_zh": "本研究探讨了Riemannian manifolds上的随机优化，针对传统Riemannian方差减少方法的双循环结构问题，该结构依赖于未知的凸性和平滑常数导致内循环长度难以确定。作者提出Riemannian Loopless SVRG (R-LSVRG)和Riemannian PAGE (R-PAGE)方法，通过每次迭代的概率触发（如抛硬币）替换外循环，实现简化证明、易于超参数选择以及精确的收敛保证。实验结果验证了这些方法的有效性，并展示了R-PAGE框架在非凸优化中的应用，例如推导出Riemannian MARINA (R-MARINA)，为分布式通信压缩场景提供了最佳的理论通信复杂度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06677v1",
      "published_date": "2024-03-11 12:49:37 UTC",
      "updated_date": "2024-03-11 12:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:20:28.761866"
    },
    {
      "arxiv_id": "2403.06675v1",
      "title": "Poisoning Programs by Un-Repairing Code: Security Concerns of AI-generated Code",
      "title_zh": "翻译失败",
      "authors": [
        "Cristina Improta"
      ],
      "abstract": "AI-based code generators have gained a fundamental role in assisting\ndevelopers in writing software starting from natural language (NL). However,\nsince these large language models are trained on massive volumes of data\ncollected from unreliable online sources (e.g., GitHub, Hugging Face), AI\nmodels become an easy target for data poisoning attacks, in which an attacker\ncorrupts the training data by injecting a small amount of poison into it, i.e.,\nastutely crafted malicious samples. In this position paper, we address the\nsecurity of AI code generators by identifying a novel data poisoning attack\nthat results in the generation of vulnerable code. Next, we devise an extensive\nevaluation of how these attacks impact state-of-the-art models for code\ngeneration. Lastly, we discuss potential solutions to overcome this threat.",
      "tldr_zh": "这篇论文探讨了AI代码生成器的安全风险，特别是数据投毒攻击（data poisoning attacks）如何通过注入精心设计的恶意样本来破坏模型，导致生成易受攻击的代码。作者识别了一种新型攻击，即通过“反修复”（un-repairing）代码来操纵AI模型的训练数据，并对最先进代码生成模型进行了广泛评估，结果显示这些攻击显著降低了模型的安全性。最后，论文讨论了潜在解决方案，以缓解这一威胁并提升AI代码生成器的可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at The 1st IEEE International Workshop on Reliable and\n  Secure AI for Software Engineering (ReSAISE), co-located with ISSRE 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.06675v1",
      "published_date": "2024-03-11 12:47:04 UTC",
      "updated_date": "2024-03-11 12:47:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:20:40.886822"
    },
    {
      "arxiv_id": "2403.06674v1",
      "title": "Car Damage Detection and Patch-to-Patch Self-supervised Image Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Hanxiao Chen"
      ],
      "abstract": "Most computer vision applications aim to identify pixels in a scene and use\nthem for diverse purposes. One intriguing application is car damage detection\nfor insurance carriers which tends to detect all car damages by comparing both\npre-trip and post-trip images, even requiring two components: (i) car damage\ndetection; (ii) image alignment. Firstly, we implemented a Mask R-CNN model to\ndetect car damages on custom images. Whereas for the image alignment section,\nwe especially propose a novel self-supervised Patch-to-Patch SimCLR inspired\nalignment approach to find perspective transformations between custom pre/post\ncar rental images except for traditional computer vision methods.",
      "tldr_zh": "本论文提出了一种汽车损伤检测系统，旨在通过比较租车前后图像来识别所有损伤，包括两个关键组件：(i) 使用Mask R-CNN模型在自定义图像上检测汽车损伤；(ii) 引入一种新颖的自监督Patch-to-Patch SimCLR启发的方法，实现预/后图像之间的透视变换对齐，以替代传统计算机视觉技术。该方法通过自监督学习提升图像对齐的准确性，提高了损伤检测的可靠性。该研究为保险行业等应用提供了更高效的计算机视觉解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper has been accepted and given a poster presentation at\n  NeurIPS 2021 WiML Workshop\n  (https://nips.cc/virtual/2021/affinity-workshop/22882)",
      "pdf_url": "http://arxiv.org/pdf/2403.06674v1",
      "published_date": "2024-03-11 12:46:53 UTC",
      "updated_date": "2024-03-11 12:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:20:51.828852"
    },
    {
      "arxiv_id": "2403.06670v2",
      "title": "CEAT: Continual Expansion and Absorption Transformer for Non-Exemplar Class-Incremental Learning",
      "title_zh": "CEAT：持续扩展和吸收 Transformer 用于非示例类别增量学习",
      "authors": [
        "Xinyuan Gao",
        "Songlin Dong",
        "Yuhang He",
        "Xing Wei",
        "Yihong Gong"
      ],
      "abstract": "In real-world applications, dynamic scenarios require the models to possess\nthe capability to learn new tasks continuously without forgetting the old\nknowledge. Experience-Replay methods store a subset of the old images for joint\ntraining. In the scenario of more strict privacy protection, storing the old\nimages becomes infeasible, which leads to a more severe plasticity-stability\ndilemma and classifier bias. To meet the above challenges, we propose a new\narchitecture, named continual expansion and absorption transformer~(CEAT). The\nmodel can learn the novel knowledge by extending the expanded-fusion layers in\nparallel with the frozen previous parameters. After the task ends, we\nlosslessly absorb the extended parameters into the backbone to ensure that the\nnumber of parameters remains constant. To improve the learning ability of the\nmodel, we designed a novel prototype contrastive loss to reduce the overlap\nbetween old and new classes in the feature space. Besides, to address the\nclassifier bias towards the new classes, we propose a novel approach to\ngenerate the pseudo-features to correct the classifier. We experiment with our\nmethods on three standard Non-Exemplar Class-Incremental Learning~(NECIL)\nbenchmarks. Extensive experiments demonstrate that our model gets a significant\nimprovement compared with the previous works and achieves 5.38%, 5.20%, and\n4.92% improvement on CIFAR-100, TinyImageNet, and ImageNet-Subset.",
      "tldr_zh": "本文提出CEAT（Continual Expansion and Absorption Transformer）架构，用于Non-Exemplar Class-Incremental Learning，旨在让模型在不存储旧数据的情况下持续学习新任务，同时缓解塑性-稳定性困境和分类器偏差问题。CEAT通过扩展融合层并冻结旧参数来学习新知识，任务结束后无损吸收参数保持模型参数不变；此外，引入prototype contrastive loss减少旧新类在特征空间的重叠，并使用伪特征生成方法纠正分类器偏差。在CIFAR-100、TinyImageNet和ImageNet-Subset基准上，CEAT分别比现有方法提高了5.38%、5.20%和4.92%的性能，显著提升了持续学习效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06670v2",
      "published_date": "2024-03-11 12:40:12 UTC",
      "updated_date": "2024-03-12 03:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:21:05.859940"
    },
    {
      "arxiv_id": "2403.06660v1",
      "title": "FashionReGen: LLM-Empowered Fashion Report Generation",
      "title_zh": "FashionReGen：LLM 赋能的时尚报告生成",
      "authors": [
        "Yujuan Ding",
        "Yunshan Ma",
        "Wenqi Fan",
        "Yige Yao",
        "Tat-Seng Chua",
        "Qing Li"
      ],
      "abstract": "Fashion analysis refers to the process of examining and evaluating trends,\nstyles, and elements within the fashion industry to understand and interpret\nits current state, generating fashion reports. It is traditionally performed by\nfashion professionals based on their expertise and experience, which requires\nhigh labour cost and may also produce biased results for relying heavily on a\nsmall group of people. In this paper, to tackle the Fashion Report Generation\n(FashionReGen) task, we propose an intelligent Fashion Analyzing and Reporting\nsystem based the advanced Large Language Models (LLMs), debbed as GPT-FAR.\nSpecifically, it tries to deliver FashionReGen based on effective catwalk\nanalysis, which is equipped with several key procedures, namely, catwalk\nunderstanding, collective organization and analysis, and report generation. By\nposing and exploring such an open-ended, complex and domain-specific task of\nFashionReGen, it is able to test the general capability of LLMs in fashion\ndomain. It also inspires the explorations of more high-level tasks with\nindustrial significance in other domains. Video illustration and more materials\nof GPT-FAR can be found in https://github.com/CompFashion/FashionReGen.",
      "tldr_zh": "这篇论文针对时尚报告生成(FashionReGen)任务，提出了一种基于大型语言模型(LLMs)的智能系统GPT-FAR，以解决传统时尚分析依赖专业人士导致的高成本和偏见问题。该系统通过catwalk understanding（时装秀理解）、collective organization and analysis（集体组织和分析）以及report generation（报告生成）等关键步骤，实现高效的时尚趋势评估和报告输出。论文通过探索这一复杂、领域特定的任务，验证了LLMs在时尚领域的通用能力，并为其他行业的高级任务应用提供了新思路。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06660v1",
      "published_date": "2024-03-11 12:29:35 UTC",
      "updated_date": "2024-03-11 12:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:21:17.810116"
    },
    {
      "arxiv_id": "2403.06659v3",
      "title": "Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement",
      "title_zh": "零样本 ECG 分类：基于多模态学习和测试时临床知识增强",
      "authors": [
        "Che Liu",
        "Zhongwei Wan",
        "Cheng Ouyang",
        "Anand Shah",
        "Wenjia Bai",
        "Rossella Arcucci"
      ],
      "abstract": "Electrocardiograms (ECGs) are non-invasive diagnostic tools crucial for\ndetecting cardiac arrhythmic diseases in clinical practice. While ECG\nSelf-supervised Learning (eSSL) methods show promise in representation learning\nfrom unannotated ECG data, they often overlook the clinical knowledge that can\nbe found in reports. This oversight and the requirement for annotated samples\nfor downstream tasks limit eSSL's versatility. In this work, we address these\nissues with the Multimodal ECG Representation Learning (MERL}) framework.\nThrough multimodal learning on ECG records and associated reports, MERL is\ncapable of performing zero-shot ECG classification with text prompts,\neliminating the need for training data in downstream tasks. At test time, we\npropose the Clinical Knowledge Enhanced Prompt Engineering (CKEPE) approach,\nwhich uses Large Language Models (LLMs) to exploit external expert-verified\nclinical knowledge databases, generating more descriptive prompts and reducing\nhallucinations in LLM-generated content to boost zero-shot classification.\nBased on MERL, we perform the first benchmark across six public ECG datasets,\nshowing the superior performance of MERL compared against eSSL methods.\nNotably, MERL achieves an average AUC score of 75.2% in zero-shot\nclassification (without training data), 3.2% higher than linear probed eSSL\nmethods with 10\\% annotated training data, averaged across all six datasets.\nCode and models are available at https://github.com/cheliu-computation/MERL",
      "tldr_zh": "这篇论文提出了 Multimodal ECG Representation Learning (MERL) 框架，通过多模态学习 ECG 记录和相关临床报告，实现零样本 ECG 分类，从而无需下游任务的训练数据。论文引入了 Clinical Knowledge Enhanced Prompt Engineering (CKEPE) 方法，利用 Large Language Models (LLMs) 和外部临床知识数据库生成更精确的提示，减少 LLM 幻觉并提升分类性能。在六个公共 ECG 数据集上的首次基准测试中，MERL 实现了平均 AUC 得分为 75.2% 的零样本分类表现，比使用 10% 标注数据的 eSSL 方法高 3.2%。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted by ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06659v3",
      "published_date": "2024-03-11 12:28:55 UTC",
      "updated_date": "2024-07-02 16:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:21:29.456987"
    },
    {
      "arxiv_id": "2403.06642v2",
      "title": "TRAWL: External Knowledge-Enhanced Recommendation with LLM Assistance",
      "title_zh": "TRAWL：借助大语言模型的外部知识增强推荐",
      "authors": [
        "Weiqing Luo",
        "Chonggang Song",
        "Lingling Yi",
        "Gong Cheng"
      ],
      "abstract": "Combining semantic information with behavioral data is a crucial research\narea in recommender systems. A promising approach involves leveraging external\nknowledge to enrich behavioral-based recommender systems with abundant semantic\ninformation. However, this approach faces two primary challenges: denoising raw\nexternal knowledge and adapting semantic representations. To address these\nchallenges, we propose an External Knowledge-Enhanced Recommendation method\nwith LLM Assistance (TRAWL). This method utilizes large language models (LLMs)\nto extract relevant recommendation knowledge from raw external data and employs\na contrastive learning strategy for adapter training. Experiments on public\ndatasets and real-world online recommender systems validate the effectiveness\nof our approach.",
      "tldr_zh": "该研究探讨了推荐系统中结合语义信息和行为数据的关键问题，特别是如何利用外部知识来丰富推荐系统，但面临去噪原始知识和适应语义表示的挑战。为此，提出TRAWL方法，通过大型语言模型(LLMs)从原始外部数据中提取相关推荐知识，并采用对比学习策略进行适配器训练。实验在公共数据集和真实在线推荐系统中验证了该方法的有效性，提升了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06642v2",
      "published_date": "2024-03-11 12:04:20 UTC",
      "updated_date": "2024-05-24 09:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:21:39.043978"
    },
    {
      "arxiv_id": "2403.08828v3",
      "title": "People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior: Insights from Cognitive Science for Explainable AI",
      "title_zh": "人们在解释自动驾驶车辆的行为时，会赋予它们目的：来自认知科学的见解，用于可解释人工智能",
      "authors": [
        "Balint Gyevnar",
        "Stephanie Droop",
        "Tadeg Quillien",
        "Shay B. Cohen",
        "Neil R. Bramley",
        "Christopher G. Lucas",
        "Stefano V. Albrecht"
      ],
      "abstract": "It is often argued that effective human-centered explainable artificial\nintelligence (XAI) should resemble human reasoning. However, empirical\ninvestigations of how concepts from cognitive science can aid the design of XAI\nare lacking. Based on insights from cognitive science, we propose a framework\nof explanatory modes to analyze how people frame explanations, whether\nmechanistic, teleological, or counterfactual. Using the complex safety-critical\ndomain of autonomous driving, we conduct an experiment consisting of two\nstudies on (i) how people explain the behavior of a vehicle in 14 unique\nscenarios (N1=54) and (ii) how they perceive these explanations (N2=382),\ncurating the novel Human Explanations for Autonomous Driving Decisions (HEADD)\ndataset. Our main finding is that participants deem teleological explanations\nsignificantly better quality than counterfactual ones, with perceived teleology\nbeing the best predictor of perceived quality. Based on our results, we argue\nthat explanatory modes are an important axis of analysis when designing and\nevaluating XAI and highlight the need for a principled and empirically grounded\nunderstanding of the cognitive mechanisms of explanation. The HEADD dataset and\nour code are available at: https://datashare.ed.ac.uk/handle/10283/8930.",
      "tldr_zh": "该论文基于认知科学提出一个解释模式框架，用于分析可解释人工智能(XAI)中的解释类型，包括mechanistic、teleological和counterfactual模式。研究者通过两个实验（分别涉及54和382名参与者）考察人们如何解释自主车辆在14个独特场景中的行为，并创建了新的Human Explanations for Autonomous Driving Decisions (HEADD)数据集。主要发现是，参与者认为teleological解释的质量显著优于counterfactual解释，且感知到的teleology是解释质量的最佳预测因子。该工作强调了解释模式在XAI设计和评估中的重要性，并呼吁对解释的认知机制进行更原则性和经验性的研究。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.08828v3",
      "published_date": "2024-03-11 11:48:50 UTC",
      "updated_date": "2025-02-03 21:49:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:21:53.842433"
    },
    {
      "arxiv_id": "2403.06631v1",
      "title": "Evaluating the Energy Efficiency of Few-Shot Learning for Object Detection in Industrial Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Tsoumplekas",
        "Vladislav Li",
        "Ilias Siniosoglou",
        "Vasileios Argyriou",
        "Sotirios K. Goudos",
        "Ioannis D. Moscholios",
        "Panagiotis Radoglou-Grammatikis",
        "Panagiotis Sarigiannidis"
      ],
      "abstract": "In the ever-evolving era of Artificial Intelligence (AI), model performance\nhas constituted a key metric driving innovation, leading to an exponential\ngrowth in model size and complexity. However, sustainability and energy\nefficiency have been critical requirements during deployment in contemporary\nindustrial settings, necessitating the use of data-efficient approaches such as\nfew-shot learning. In this paper, to alleviate the burden of lengthy model\ntraining and minimize energy consumption, a finetuning approach to adapt\nstandard object detection models to downstream tasks is examined. Subsequently,\na thorough case study and evaluation of the energy demands of the developed\nmodels, applied in object detection benchmark datasets from volatile industrial\nenvironments is presented. Specifically, different finetuning strategies as\nwell as utilization of ancillary evaluation data during training are examined,\nand the trade-off between performance and efficiency is highlighted in this\nlow-data regime. Finally, this paper introduces a novel way to quantify this\ntrade-off through a customized Efficiency Factor metric.",
      "tldr_zh": "这篇论文评估了few-shot learning在工业环境物体检测中的能源效率，旨在通过数据高效方法减少模型训练负担和能源消耗。研究者考察了微调(finetuning)标准物体检测模型的多种策略，以及在低数据环境下使用辅助评估数据的影响，并通过基准数据集案例分析突出了性能与效率的权衡。最终，论文引入了一个自定义的Efficiency Factor指标来量化这一权衡，为可持续AI部署提供了新颖的评估框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.06631v1",
      "published_date": "2024-03-11 11:41:30 UTC",
      "updated_date": "2024-03-11 11:41:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:22:04.045793"
    },
    {
      "arxiv_id": "2403.06621v1",
      "title": "Forest Inspection Dataset for Aerial Semantic Segmentation and Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Bianca-Cerasela-Zelia Blaga",
        "Sergiu Nedevschi"
      ],
      "abstract": "Humans use UAVs to monitor changes in forest environments since they are\nlightweight and provide a large variety of surveillance data. However, their\ninformation does not present enough details for understanding the scene which\nis needed to assess the degree of deforestation. Deep learning algorithms must\nbe trained on large amounts of data to output accurate interpretations, but\nground truth recordings of annotated forest imagery are not available. To solve\nthis problem, we introduce a new large aerial dataset for forest inspection\nwhich contains both real-world and virtual recordings of natural environments,\nwith densely annotated semantic segmentation labels and depth maps, taken in\ndifferent illumination conditions, at various altitudes and recording angles.\nWe test the performance of two multi-scale neural networks for solving the\nsemantic segmentation task (HRNet and PointFlow network), studying the impact\nof the various acquisition conditions and the capabilities of transfer learning\nfrom virtual to real data. Our results showcase that the best results are\nobtained when the training is done on a dataset containing a large variety of\nscenarios, rather than separating the data into specific categories. We also\ndevelop a framework to assess the deforestation degree of an area.",
      "tldr_zh": "本研究引入了一个名为Forest Inspection Dataset的新型大型航空数据集，用于支持森林环境的语义分割和深度估计任务。该数据集包含真实和虚拟森林记录，提供密集标注的semantic segmentation标签和depth maps，并覆盖不同照明条件、altitude和记录角度，以解决现有数据缺乏的问题。研究者测试了HRNet和PointFlow network等多尺度神经网络进行semantic segmentation，探讨了采集条件的影响以及从虚拟到真实数据的transfer learning效果。结果显示，使用包含多种场景的混合数据集训练能获得最佳性能，并开发了一个框架来评估区域的森林砍伐程度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06621v1",
      "published_date": "2024-03-11 11:26:44 UTC",
      "updated_date": "2024-03-11 11:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:22:17.177805"
    },
    {
      "arxiv_id": "2403.06611v1",
      "title": "MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding",
      "title_zh": "翻译失败",
      "authors": [
        "Jiageng Wu",
        "Xian Wu",
        "Yefeng Zheng",
        "Jie Yang"
      ],
      "abstract": "With appropriate data selection and training techniques, Large Language\nModels (LLMs) have demonstrated exceptional success in various medical\nexaminations and multiple-choice questions. However, the application of LLMs in\nmedical dialogue generation-a task more closely aligned with actual medical\npractice-has been less explored. This gap is attributed to the insufficient\nmedical knowledge of LLMs, which leads to inaccuracies and hallucinated\ninformation in the generated medical responses. In this work, we introduce the\nMedical dialogue with Knowledge enhancement and clinical Pathway encoding\n(MedKP) framework, which integrates an external knowledge enhancement module\nthrough a medical knowledge graph and an internal clinical pathway encoding via\nmedical entities and physician actions. Evaluated with comprehensive metrics,\nour experiments on two large-scale, real-world online medical consultation\ndatasets (MedDG and KaMed) demonstrate that MedKP surpasses multiple baselines\nand mitigates the incidence of hallucinations, achieving a new\nstate-of-the-art. Extensive ablation studies further reveal the effectiveness\nof each component of MedKP. This enhancement advances the development of\nreliable, automated medical consultation responses using LLMs, thereby\nbroadening the potential accessibility of precise and real-time medical\nassistance.",
      "tldr_zh": "该研究提出MedKP框架，以提升Large Language Models (LLMs)在医疗对话生成中的表现，针对LLMs的知识不足和幻觉问题，通过外部知识增强模块（利用医疗知识图）和内部临床路径编码（基于医疗实体和医生动作）来整合相关信息。在MedDG和KaMed两个真实大型数据集上的实验显示，MedKP超越了多个基线模型，显著减少了幻觉现象，并达到了新的state-of-the-art水平。消融研究进一步验证了框架各组件的有效性，为可靠的自动化医疗咨询系统提供了重要进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06611v1",
      "published_date": "2024-03-11 10:57:45 UTC",
      "updated_date": "2024-03-11 10:57:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:22:28.320060"
    },
    {
      "arxiv_id": "2403.06609v2",
      "title": "Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds",
      "title_zh": "翻译失败",
      "authors": [
        "Jiageng WU",
        "Xian Wu",
        "Jie Yang"
      ],
      "abstract": "Clinical reasoning refers to the cognitive process that physicians employ in\nevaluating and managing patients. This process typically involves suggesting\nnecessary examinations, diagnosing patients' diseases, and deciding on\nappropriate therapies, etc. Accurate clinical reasoning requires extensive\nmedical knowledge and rich clinical experience, setting a high bar for\nphysicians. This is particularly challenging in developing countries due to the\noverwhelming number of patients and limited physician resources, contributing\nsignificantly to global health inequity and necessitating automated clinical\nreasoning approaches. Recently, the emergence of large language models (LLMs)\nsuch as ChatGPT and GPT-4 have demonstrated their potential in clinical\nreasoning. However, these LLMs are prone to hallucination problems, and the\nreasoning process of LLMs may not align with the clinical decision path of\nphysicians. In this study, we introduce a novel framework, In-Context Padding\n(ICP), designed to enhance LLMs with medical knowledge. Specifically, we infer\ncritical clinical reasoning elements (referred to as knowledge seeds) and use\nthese as anchors to guide the generation process of LLMs. Experiments on two\nclinical question datasets demonstrate that ICP significantly improves the\nclinical reasoning ability of LLMs.",
      "tldr_zh": "这篇论文探讨了临床推理（clinical reasoning）的挑战，即医生在评估和管理患者时需要广泛的医疗知识和经验，尤其在资源有限的发展中国家。研究提出了一种新框架In-Context Padding (ICP)，通过推断关键临床推理元素（knowledge seeds）并用其作为锚点，来指导大型语言模型(LLMs)的生成过程，从而缓解LLMs的幻觉问题和决策路径偏差。在两个临床问题数据集上的实验表明，ICP显著提升了LLMs的临床推理能力，为自动化医疗辅助提供了潜在解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06609v2",
      "published_date": "2024-03-11 10:53:20 UTC",
      "updated_date": "2024-06-08 04:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:22:40.698718"
    },
    {
      "arxiv_id": "2403.06601v2",
      "title": "Cross-domain and Cross-dimension Learning for Image-to-Graph Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander H. Berger",
        "Laurin Lux",
        "Suprosanna Shit",
        "Ivan Ezhov",
        "Georgios Kaissis",
        "Martin J. Menten",
        "Daniel Rueckert",
        "Johannes C. Paetzold"
      ],
      "abstract": "Direct image-to-graph transformation is a challenging task that involves\nsolving object detection and relationship prediction in a single model. Due to\nthis task's complexity, large training datasets are rare in many domains,\nmaking the training of deep-learning methods challenging. This data sparsity\nnecessitates transfer learning strategies akin to the state-of-the-art in\ngeneral computer vision. In this work, we introduce a set of methods enabling\ncross-domain and cross-dimension learning for image-to-graph transformers. We\npropose (1) a regularized edge sampling loss to effectively learn object\nrelations in multiple domains with different numbers of edges, (2) a domain\nadaptation framework for image-to-graph transformers aligning image- and\ngraph-level features from different domains, and (3) a projection function that\nallows using 2D data for training 3D transformers. We demonstrate our method's\nutility in cross-domain and cross-dimension experiments, where we utilize\nlabeled data from 2D road networks for simultaneous learning in vastly\ndifferent target domains. Our method consistently outperforms standard transfer\nlearning and self-supervised pretraining on challenging benchmarks, such as\nretinal or whole-brain vessel graph extraction.",
      "tldr_zh": "该论文针对图像到图形转换（image-to-graph transformation）的挑战，提出一种跨领域（cross-domain）和跨维度（cross-dimension）学习方法，以解决数据稀缺问题。研究引入了三种关键技术：regularized edge sampling loss 用于在不同领域学习物体关系、domain adaptation framework 用于对齐不同领域的图像和图形级别特征，以及projection function 允许使用2D数据训练3D transformers。实验结果显示，该方法在诸如视网膜或全脑血管图形提取的基准测试中，显著优于标准转移学习和自监督预训练策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06601v2",
      "published_date": "2024-03-11 10:48:56 UTC",
      "updated_date": "2024-12-05 15:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:22:54.476733"
    },
    {
      "arxiv_id": "2403.06592v3",
      "title": "Exploiting Style Latent Flows for Generalizing Deepfake Video Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jongwook Choi",
        "Taehoon Kim",
        "Yonghyun Jeong",
        "Seungryul Baek",
        "Jongwon Choi"
      ],
      "abstract": "This paper presents a new approach for the detection of fake videos, based on\nthe analysis of style latent vectors and their abnormal behavior in temporal\nchanges in the generated videos. We discovered that the generated facial videos\nsuffer from the temporal distinctiveness in the temporal changes of style\nlatent vectors, which are inevitable during the generation of temporally stable\nvideos with various facial expressions and geometric transformations. Our\nframework utilizes the StyleGRU module, trained by contrastive learning, to\nrepresent the dynamic properties of style latent vectors. Additionally, we\nintroduce a style attention module that integrates StyleGRU-generated features\nwith content-based features, enabling the detection of visual and temporal\nartifacts. We demonstrate our approach across various benchmark scenarios in\ndeepfake detection, showing its superiority in cross-dataset and\ncross-manipulation scenarios. Through further analysis, we also validate the\nimportance of using temporal changes of style latent vectors to improve the\ngenerality of deepfake video detection.",
      "tldr_zh": "本文提出了一种新的深假视频检测方法，通过分析风格潜在向量（style latent vectors）在时序变化中的异常行为来识别生成的假脸部视频。框架利用通过对比学习（contrastive learning）训练的 StyleGRU 模块来表示这些向量的动态特性，并引入风格注意力模块（style attention module）整合动态特征与内容特征，以检测视觉和时序伪造痕迹。该方法在各种基准场景中表现出色，尤其在跨数据集和跨操作场景中提升了检测泛化性，并验证了利用风格潜在向量时序变化的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint version, final version will be available at\n  https://openaccess.thecvf.com The IEEE / CVF Computer Vision and Pattern\n  Recognition Conference (CVPR) (2024) Published by: IEEE & CVF",
      "pdf_url": "http://arxiv.org/pdf/2403.06592v3",
      "published_date": "2024-03-11 10:35:58 UTC",
      "updated_date": "2024-05-20 13:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:23:05.894890"
    },
    {
      "arxiv_id": "2403.06586v2",
      "title": "ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Arrotta",
        "Claudio Bettini",
        "Gabriele Civitarese",
        "Michele Fiori"
      ],
      "abstract": "Context-aware Human Activity Recognition (HAR) is a hot research area in\nmobile computing, and the most effective solutions in the literature are based\non supervised deep learning models. However, the actual deployment of these\nsystems is limited by the scarcity of labeled data that is required for\ntraining. Neuro-Symbolic AI (NeSy) provides an interesting research direction\nto mitigate this issue, by infusing common-sense knowledge about human\nactivities and the contexts in which they can be performed into HAR deep\nlearning classifiers. Existing NeSy methods for context-aware HAR rely on\nknowledge encoded in logic-based models (e.g., ontologies) whose design,\nimplementation, and maintenance to capture new activities and contexts require\nsignificant human engineering efforts, technical knowledge, and domain\nexpertise. Recent works show that pre-trained Large Language Models (LLMs)\neffectively encode common-sense knowledge about human activities. In this work,\nwe propose ContextGPT: a novel prompt engineering approach to retrieve from\nLLMs common-sense knowledge about the relationship between human activities and\nthe context in which they are performed. Unlike ontologies, ContextGPT requires\nlimited human effort and expertise. An extensive evaluation carried out on two\npublic datasets shows how a NeSy model obtained by infusing common-sense\nknowledge from ContextGPT is effective in data scarcity scenarios, leading to\nsimilar (and sometimes better) recognition rates than logic-based approaches\nwith a fraction of the effort.",
      "tldr_zh": "本文提出 ContextGPT，一种创新的提示工程方法，通过从预训练 Large Language Models (LLMs) 中提取人类活动与上下文关系的常识知识，注入 Neuro-Symbolic AI (NeSy) 模型，以提升 Human Activity Recognition (HAR) 的性能。相较于依赖逻辑模型（如本体）的传统 NeSy 方法，ContextGPT 大大减少了设计和维护所需的人力、专业知识和领域专长。在两个公共数据集上的广泛评估显示，该方法在数据稀缺场景下表现出色，识别率与逻辑方法相当或更高，从而为高效的上下文感知 HAR 提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06586v2",
      "published_date": "2024-03-11 10:32:23 UTC",
      "updated_date": "2025-03-20 18:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:23:17.834781"
    },
    {
      "arxiv_id": "2403.06568v2",
      "title": "Better Understandings and Configurations in MaxSAT Local Search Solvers via Anytime Performance Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Furong Ye",
        "Chuan Luo",
        "Shaowei Cai"
      ],
      "abstract": "Though numerous solvers have been proposed for the MaxSAT problem, and the\nbenchmark environment such as MaxSAT Evaluations provides a platform for the\ncomparison of the state-of-the-art solvers, existing assessments were usually\nevaluated based on the quality, e.g., fitness, of the best-found solutions\nobtained within a given running time budget. However, concerning solely the\nfinal obtained solutions regarding specific time budgets may restrict us from\ncomprehending the behavior of the solvers along the convergence process. This\npaper demonstrates that Empirical Cumulative Distribution Functions can be used\nto compare MaxSAT stochastic local search solvers' anytime performance across\nmultiple problem instances and various time budgets. The assessment reveals\ndistinctions in solvers' performance and displays that the (dis)advantages of\nsolvers adjust along different running times. This work also exhibits that the\nquantitative and high variance assessment of anytime performance can guide\nmachines, i.e., automatic configurators, to search for better parameter\nsettings. Our experimental results show that the hyperparameter optimization\ntool, i.e., SMAC, can achieve better parameter settings of solvers when using\nthe anytime performance as the cost function, compared to using the metrics\nbased on the fitness of the best-found solutions.",
      "tldr_zh": "本文提出了一种通过 Empirical Cumulative Distribution Functions (ECDF) 分析 MaxSAT 随机局部搜索求解器的 anytime performance 的方法，以更全面地理解求解器在不同时间预算下的行为，而非仅关注最终解决方案的质量。研究发现，这种评估揭示了求解器性能的动态差异，并显示求解器的优势会随运行时间调整。实验结果表明，使用 anytime performance 作为成本函数，超参数优化工具如 SMAC 可以找到比传统适应度指标更好的参数设置，从而提升 MaxSAT 求解器的整体配置和性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06568v2",
      "published_date": "2024-03-11 10:10:35 UTC",
      "updated_date": "2025-02-04 10:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:23:30.086958"
    },
    {
      "arxiv_id": "2403.07039v1",
      "title": "From English to ASIC: Hardware Implementation with Large Language Model",
      "title_zh": "从英语到 ASIC：利用大型语言模型的硬件实现",
      "authors": [
        "Emil Goh",
        "Maoyang Xiang",
        "I-Chyn Wey",
        "T. Hui Teo"
      ],
      "abstract": "In the realm of ASIC engineering, the landscape has been significantly\nreshaped by the rapid development of LLM, paralleled by an increase in the\ncomplexity of modern digital circuits. This complexity has escalated the\nrequirements for HDL coding, necessitating a higher degree of precision and\nsophistication. However, challenges have been faced due to the\nless-than-optimal performance of modern language models in generating hardware\ndescription code, a situation further exacerbated by the scarcity of the\ncorresponding high-quality code datasets. These challenges have highlighted the\ngap between the potential of LLMs to revolutionize digital circuit design and\ntheir current capabilities in accurately interpreting and implementing hardware\nspecifications. To address these challenges, a strategy focusing on the\nfine-tuning of the leading-edge nature language model and the reshuffling of\nthe HDL code dataset has been developed. The fine-tuning aims to enhance\nmodels' proficiency in generating precise and efficient ASIC design, while the\ndataset reshuffling is intended to broaden the scope and improve the quality of\ntraining material. The model demonstrated significant improvements compared to\nthe base model, with approximately 10% to 20% increase in accuracy across a\nwide range of temperature for the pass@1 metric. This approach is expected to\nfacilitate a simplified and more efficient LLM-assisted framework for complex\ncircuit design, leveraging their capabilities to meet the sophisticated demands\nof HDL coding and thus streamlining the ASIC development process.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLM)在ASIC工程中的应用挑战，特别是由于数字电路复杂性和HDL代码数据集稀缺，导致模型在生成硬件描述代码方面性能不足。为解决这些问题，研究者提出了一种策略，包括对领先自然语言模型进行微调以及重组HDL代码数据集，以提高模型生成精确高效ASIC设计的准确性。实验结果显示，该方法使模型在pass@1指标上的准确率比基础模型提升了10%到20%。这种方法有望简化LLM辅助的复杂电路设计框架，优化整体ASIC开发过程。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AR",
      "comment": "15 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.07039v1",
      "published_date": "2024-03-11 09:57:16 UTC",
      "updated_date": "2024-03-11 09:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:23:41.795665"
    },
    {
      "arxiv_id": "2403.06545v1",
      "title": "ReStainGAN: Leveraging IHC to IF Stain Domain Translation for in-silico Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Winter",
        "Nicolas Triltsch",
        "Philipp Plewa",
        "Marco Rosati",
        "Thomas Padel",
        "Ross Hill",
        "Markus Schick",
        "Nicolas Brieu"
      ],
      "abstract": "The creation of in-silico datasets can expand the utility of existing\nannotations to new domains with different staining patterns in computational\npathology. As such, it has the potential to significantly lower the cost\nassociated with building large and pixel precise datasets needed to train\nsupervised deep learning models. We propose a novel approach for the generation\nof in-silico immunohistochemistry (IHC) images by disentangling morphology\nspecific IHC stains into separate image channels in immunofluorescence (IF)\nimages. The proposed approach qualitatively and quantitatively outperforms\nbaseline methods as proven by training nucleus segmentation models on the\ncreated in-silico datasets.",
      "tldr_zh": "本论文提出ReStainGAN方法，通过将IHC染色转化为IF图像的单独通道，实现形态特定染色的分离，从而生成in-silico数据集，以扩展现有注释到新染色领域并降低构建大型像素精确数据集的成本。该方法在定性和定量上优于基线方法，如通过训练核分割模型的实验所证明。整体而言，ReStainGAN为计算病理学中的监督深度学习模型提供了一种高效的数据生成策略。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.2.10, J.3, I.4.6"
      ],
      "primary_category": "eess.IV",
      "comment": "4 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.06545v1",
      "published_date": "2024-03-11 09:45:34 UTC",
      "updated_date": "2024-03-11 09:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:23:54.609829"
    },
    {
      "arxiv_id": "2403.10544v1",
      "title": "Process-Aware Analysis of Treatment Paths in Heart Failure Patients: A Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Harry H. Beyel",
        "Marlo Verket",
        "Viki Peeva",
        "Christian Rennert",
        "Marco Pegoraro",
        "Katharina Schütt",
        "Wil M. P. van der Aalst",
        "Nikolaus Marx"
      ],
      "abstract": "Process mining in healthcare presents a range of challenges when working with\ndifferent types of data within the healthcare domain. There is high diversity\nconsidering the variety of data collected from healthcare processes:\noperational processes given by claims data, a collection of events during\nsurgery, data related to pre-operative and post-operative care, and high-level\ndata collections based on regular ambulant visits with no apparent events. In\nthis case study, a data set from the last category is analyzed. We apply\nprocess-mining techniques on sparse patient heart failure data and investigate\nwhether an information gain towards several research questions is achievable.\nHere, available data are transformed into an event log format, and process\ndiscovery and conformance checking are applied. Additionally, patients are\nsplit into different cohorts based on comorbidities, such as diabetes and\nchronic kidney disease, and multiple statistics are compared between the\ncohorts. Conclusively, we apply decision mining to determine whether a patient\nwill have a cardiovascular outcome and whether a patient will die.",
      "tldr_zh": "这篇论文通过一个心脏衰竭患者案例研究，探讨了 process mining 在处理稀疏医疗数据时的挑战和应用。研究者将患者数据转换为事件日志格式，并应用 process discovery 和 conformance checking 技术来分析治疗路径。患者被分成基于共病的队列（如糖尿病或慢性肾病），并比较各队列的统计数据。最后，通过 decision mining 预测患者的心血管结果和死亡风险，结果表明这种方法能从稀疏数据中获得有价值的信息。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "10 pages, 3 figures, 9 tables, 31 references",
      "pdf_url": "http://arxiv.org/pdf/2403.10544v1",
      "published_date": "2024-03-11 09:33:21 UTC",
      "updated_date": "2024-03-11 09:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:24:06.550568"
    },
    {
      "arxiv_id": "2403.06535v1",
      "title": "Decentralized and Lifelong-Adaptive Multi-Agent Collaborative Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Tang",
        "Rui Ye",
        "Chenxin Xu",
        "Xiaowen Dong",
        "Siheng Chen",
        "Yanfeng Wang"
      ],
      "abstract": "Decentralized and lifelong-adaptive multi-agent collaborative learning aims\nto enhance collaboration among multiple agents without a central server, with\neach agent solving varied tasks over time. To achieve efficient collaboration,\nagents should: i) autonomously identify beneficial collaborative relationships\nin a decentralized manner; and ii) adapt to dynamically changing task\nobservations. In this paper, we propose DeLAMA, a decentralized multi-agent\nlifelong collaborative learning algorithm with dynamic collaboration graphs. To\npromote autonomous collaboration relationship learning, we propose a\ndecentralized graph structure learning algorithm, eliminating the need for\nexternal priors. To facilitate adaptation to dynamic tasks, we design a memory\nunit to capture the agents' accumulated learning history and knowledge, while\npreserving finite storage consumption. To further augment the system's\nexpressive capabilities and computational efficiency, we apply algorithm\nunrolling, leveraging the advantages of both mathematical optimization and\nneural networks. This allows the agents to `learn to collaborate' through the\nsupervision of training tasks. Our theoretical analysis verifies that\ninter-agent collaboration is communication efficient under a small number of\ncommunication rounds. The experimental results verify its ability to facilitate\nthe discovery of collaboration strategies and adaptation to dynamic learning\nscenarios, achieving a 98.80% reduction in MSE and a 188.87% improvement in\nclassification accuracy. We expect our work can serve as a foundational\ntechnique to facilitate future works towards an intelligent, decentralized, and\ndynamic multi-agent system. Code is available at\nhttps://github.com/ShuoTang123/DeLAMA.",
      "tldr_zh": "本论文提出DeLAMA，一种去中心化的多智能体终身协作学习算法，旨在让代理在无中央服务器的情况下自主识别有益协作关系并适应动态任务变化。该算法通过去中心化图结构学习来动态构建协作图、记忆单元捕获代理的积累知识（以有限存储实现），并采用算法unrolling结合数学优化和神经网络优势，提升系统表达力和计算效率。理论分析证明，代理间协作在少量通信轮次下通信高效；实验结果显示，DeLAMA在动态学习场景中实现了MSE减少98.80%和分类准确率提高188.87%，为智能、去中心化和动态多智能体系统的发展提供基础技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06535v1",
      "published_date": "2024-03-11 09:21:11 UTC",
      "updated_date": "2024-03-11 09:21:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:24:20.730705"
    },
    {
      "arxiv_id": "2403.06534v2",
      "title": "SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Li",
        "Xiang Li",
        "Weijie Li",
        "Qibin Hou",
        "Li Liu",
        "Ming-Ming Cheng",
        "Jian Yang"
      ],
      "abstract": "Synthetic Aperture Radar (SAR) object detection has gained significant\nattention recently due to its irreplaceable all-weather imaging capabilities.\nHowever, this research field suffers from both limited public datasets (mostly\ncomprising <2K images with only mono-category objects) and inaccessible source\ncode. To tackle these challenges, we establish a new benchmark dataset and an\nopen-source method for large-scale SAR object detection. Our dataset,\nSARDet-100K, is a result of intense surveying, collecting, and standardizing 10\nexisting SAR detection datasets, providing a large-scale and diverse dataset\nfor research purposes. To the best of our knowledge, SARDet-100K is the first\nCOCO-level large-scale multi-class SAR object detection dataset ever created.\nWith this high-quality dataset, we conducted comprehensive experiments and\nuncovered a crucial challenge in SAR object detection: the substantial\ndisparities between the pretraining on RGB datasets and finetuning on SAR\ndatasets in terms of both data domain and model structure. To bridge these\ngaps, we propose a novel Multi-Stage with Filter Augmentation (MSFA)\npretraining framework that tackles the problems from the perspective of data\ninput, domain transition, and model migration. The proposed MSFA method\nsignificantly enhances the performance of SAR object detection models while\ndemonstrating exceptional generalizability and flexibility across diverse\nmodels. This work aims to pave the way for further advancements in SAR object\ndetection. The dataset and code is available at\nhttps://github.com/zcablii/SARDet_100K.",
      "tldr_zh": "本研究针对合成孔径雷达（SAR）对象检测领域的公共数据集有限和代码不可访问的问题，构建了首个COCO级别的大型多类SAR数据集SARDet-100K，该数据集整合了10个现有SAR检测数据集，提供超过10万张图像以支持大规模研究。研究发现，RGB数据集预训练与SAR数据集微调之间存在显著的领域和模型结构差异，这阻碍了检测性能。针对这些挑战，提出了一种新型Multi-Stage with Filter Augmentation (MSFA)预训练框架，从数据输入、领域转换和模型迁移角度优化模型，提升SAR对象检测的准确性和泛化能力。实验结果显示，MSFA方法显著提高了模型性能，并展示了优秀的灵活性，为SAR对象检测领域的发展铺平道路；数据集和代码已在GitHub开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "22 Pages, 10 Figures, 9 Tables",
      "pdf_url": "http://arxiv.org/pdf/2403.06534v2",
      "published_date": "2024-03-11 09:20:40 UTC",
      "updated_date": "2024-09-30 08:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:24:30.728025"
    },
    {
      "arxiv_id": "2403.06524v1",
      "title": "Tactical Decision Making for Autonomous Trucks by Deep Reinforcement Learning with Total Cost of Operation Based Reward",
      "title_zh": "翻译失败",
      "authors": [
        "Deepthi Pathare",
        "Leo Laine",
        "Morteza Haghir Chehreghani"
      ],
      "abstract": "We develop a deep reinforcement learning framework for tactical decision\nmaking in an autonomous truck, specifically for Adaptive Cruise Control (ACC)\nand lane change maneuvers in a highway scenario. Our results demonstrate that\nit is beneficial to separate high-level decision-making processes and low-level\ncontrol actions between the reinforcement learning agent and the low-level\ncontrollers based on physical models. In the following, we study optimizing the\nperformance with a realistic and multi-objective reward function based on Total\nCost of Operation (TCOP) of the truck using different approaches; by adding\nweights to reward components, by normalizing the reward components and by using\ncurriculum learning techniques.",
      "tldr_zh": "本研究开发了一个深度强化学习框架，用于自动驾驶卡车的战术决策，具体针对高速公路场景中的自适应巡航控制(ACC)和变道操作。\n框架将高层决策过程与基于物理模型的低层控制分开，由强化学习代理负责高层决策，以提升整体性能。\n他们使用基于Total Cost of Operation (TCOP)的多目标奖励函数，并通过添加权重、归一化奖励组件以及课程学习技术进行优化。\n结果显示，这种分离和优化方法有助于实现更现实有效的决策。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06524v1",
      "published_date": "2024-03-11 08:58:42 UTC",
      "updated_date": "2024-03-11 08:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:24:42.772068"
    },
    {
      "arxiv_id": "2403.06520v1",
      "title": "How to Understand Named Entities: Using Common Sense for News Captioning",
      "title_zh": "如何理解命名实体：使用常识进行新闻字幕生成",
      "authors": [
        "Ning Xu",
        "Yanhui Wang",
        "Tingting Zhang",
        "Hongshuo Tian",
        "Mohan Kankanhalli",
        "An-An Liu"
      ],
      "abstract": "News captioning aims to describe an image with its news article body as\ninput. It greatly relies on a set of detected named entities, including\nreal-world people, organizations, and places. This paper exploits commonsense\nknowledge to understand named entities for news captioning. By ``understand'',\nwe mean correlating the news content with common sense in the wild, which helps\nan agent to 1) distinguish semantically similar named entities and 2) describe\nnamed entities using words outside of training corpora. Our approach consists\nof three modules: (a) Filter Module aims to clarify the common sense concerning\na named entity from two aspects: what does it mean? and what is it related to?,\nwhich divide the common sense into explanatory knowledge and relevant\nknowledge, respectively. (b) Distinguish Module aggregates explanatory\nknowledge from node-degree, dependency, and distinguish three aspects to\ndistinguish semantically similar named entities. (c) Enrich Module attaches\nrelevant knowledge to named entities to enrich the entity description by\ncommonsense information (e.g., identity and social position). Finally, the\nprobability distributions from both modules are integrated to generate the news\ncaptions. Extensive experiments on two challenging datasets (i.e., GoodNews and\nNYTimes) demonstrate the superiority of our method. Ablation studies and\nvisualization further validate its effectiveness in understanding named\nentities.",
      "tldr_zh": "本论文探讨了如何利用常识知识（common sense）理解命名实体（named entities）以提升新闻标题生成（news captioning）的效果。具体方法包括三个模块：Filter Module 用于区分解释性知识和相关知识，Distinguish Module 通过节点度、依赖关系和区分方面聚合知识来辨别语义相似的命名实体，以及 Enrich Module 通过附加相关常识（如身份和社会地位）来丰富实体描述。最终，将这些模块的概率分布整合以生成更准确的标题。在 GoodNews 和 NYTimes 数据集上的实验显示，该方法优于现有基准，并通过消融实验和可视化证明了其在理解命名实体方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06520v1",
      "published_date": "2024-03-11 08:52:52 UTC",
      "updated_date": "2024-03-11 08:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:24:55.127894"
    },
    {
      "arxiv_id": "2403.06517v2",
      "title": "Active Generation for Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Huang",
        "Jiaqi Liu",
        "Shan You",
        "Chang Xu"
      ],
      "abstract": "Recently, the growing capabilities of deep generative models have underscored\ntheir potential in enhancing image classification accuracy. However, existing\nmethods often demand the generation of a disproportionately large number of\nimages compared to the original dataset, while having only marginal\nimprovements in accuracy. This computationally expensive and time-consuming\nprocess hampers the practicality of such approaches. In this paper, we propose\nto address the efficiency of image generation by focusing on the specific needs\nand characteristics of the model. With a central tenet of active learning, our\nmethod, named ActGen, takes a training-aware approach to image generation. It\naims to create images akin to the challenging or misclassified samples\nencountered by the current model and incorporates these generated images into\nthe training set to augment model performance. ActGen introduces an attentive\nimage guidance technique, using real images as guides during the denoising\nprocess of a diffusion model. The model's attention on class prompt is\nleveraged to ensure the preservation of similar foreground object while\ndiversifying the background. Furthermore, we introduce a gradient-based\ngeneration guidance method, which employs two losses to generate more\nchallenging samples and prevent the generated images from being too similar to\npreviously generated ones. Experimental results on the CIFAR and ImageNet\ndatasets demonstrate that our method achieves better performance with a\nsignificantly reduced number of generated images. Code is available at\nhttps://github.com/hunto/ActGen.",
      "tldr_zh": "本论文针对现有图像生成方法在提升分类准确率时所需的大量图像和计算成本问题，提出了一种基于主动学习（Active Learning）的ActGen方法。该方法通过生成类似于模型当前误分类或挑战性样本的图像，并将其加入训练集，从而高效提升模型性能。ActGen引入Attentive Image Guidance技术，利用真实图像引导扩散模型的去噪过程，以保留相似的前景对象并多样化背景；同时，通过Gradient-based Generation Guidance方法使用两个损失函数，生成更具挑战性的样本并避免重复。实验结果显示，在CIFAR和ImageNet数据集上，ActGen实现了更好的分类性能，同时显著减少了生成的图像数量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06517v2",
      "published_date": "2024-03-11 08:45:31 UTC",
      "updated_date": "2024-08-15 05:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:25:08.391983"
    },
    {
      "arxiv_id": "2403.06514v2",
      "title": "Structure Your Data: Towards Semantic Graph Counterfactuals",
      "title_zh": "翻译失败",
      "authors": [
        "Angeliki Dimitriou",
        "Maria Lymperaiou",
        "Giorgos Filandrianos",
        "Konstantinos Thomas",
        "Giorgos Stamou"
      ],
      "abstract": "Counterfactual explanations (CEs) based on concepts are explanations that\nconsider alternative scenarios to understand which high-level semantic features\ncontributed to particular model predictions. In this work, we propose CEs based\non the semantic graphs accompanying input data to achieve more descriptive,\naccurate, and human-aligned explanations. Building upon state-of-the-art (SoTA)\nconceptual attempts, we adopt a model-agnostic edit-based approach and\nintroduce leveraging GNNs for efficient Graph Edit Distance (GED) computation.\nWith a focus on the visual domain, we represent images as scene graphs and\nobtain their GNN embeddings to bypass solving the NP-hard graph similarity\nproblem for all input pairs, an integral part of the CE computation process. We\napply our method to benchmark and real-world datasets with varying difficulty\nand availability of semantic annotations. Testing on diverse classifiers, we\nfind that our CEs outperform previous SoTA explanation models based on\nsemantics, including both white and black-box as well as conceptual and\npixel-level approaches. Their superiority is proven quantitatively and\nqualitatively, as validated by human subjects, highlighting the significance of\nleveraging semantic edges in the presence of intricate relationships. Our\nmodel-agnostic graph-based approach is widely applicable and easily extensible,\nproducing actionable explanations across different contexts.",
      "tldr_zh": "该论文提出了一种基于语义图的逆事实解释（Counterfactual explanations, CEs），旨在通过考虑高层次语义特征的替代场景，提供更具描述性、准确性和人类友好的模型解释。作者采用模型无关的编辑方法，利用 Graph Neural Networks (GNNs) 高效计算 Graph Edit Distance (GED)，并将图像表示为场景图，以避免解决 NP-hard 的图相似性问题。实验在基准和真实世界数据集上进行，结果显示，该方法在各种分类器（包括白盒和黑盒、概念和像素级模型）上优于现有状态-of-the-art 解释模型，并在定量、定性及人类验证中证明其优势。总之，这种图-based 方法具有广泛适用性和可扩展性，能生成可操作的解释，尤其适用于复杂关系的场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06514v2",
      "published_date": "2024-03-11 08:40:37 UTC",
      "updated_date": "2024-07-20 05:23:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:25:19.353102"
    },
    {
      "arxiv_id": "2403.06483v2",
      "title": "The negation of permutation mass function",
      "title_zh": "翻译失败",
      "authors": [
        "Yongchuan Tang",
        "Rongfei Li"
      ],
      "abstract": "Negation is an important perspective of knowledge representation. Existing\nnegation methods are mainly applied in probability theory, evidence theory and\ncomplex evidence theory. As a generalization of evidence theory, random\npermutation sets theory may represent information more precisely. However, how\nto apply the concept of negation to random permutation sets theory has not been\nstudied. In this paper, the negation of permutation mass function is proposed.\nMoreover, in the negation process, the convergence of proposed negation method\nis verified. The trends of uncertainty and dissimilarity after each negation\noperation are investigated. Numerical examples are used to demonstrate the\nrationality of the proposed method.",
      "tldr_zh": "本文提出了一种置换质量函数(permutation mass function)的否定(negation)方法，以扩展随机置换集理论(random permutation sets theory)在知识表示中的应用，该理论是证据理论(evidence theory)的推广，能更精确地处理信息。研究验证了该否定方法的收敛性(convergence)，并分析了否定操作后不确定性(uncertainty)和差异性(dissimilarity)的变化趋势。通过数值例子，证明了该方法的合理性和有效性。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06483v2",
      "published_date": "2024-03-11 07:44:59 UTC",
      "updated_date": "2024-03-13 02:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:25:31.137158"
    },
    {
      "arxiv_id": "2403.06479v2",
      "title": "Ada-Tracker: Soft Tissue Tracking via Inter-Frame and Adaptive-Template Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Guo",
        "Jiangliu Wang",
        "Zhaoshuo Li",
        "Tongyu Jia",
        "Qi Dou",
        "Yun-Hui Liu"
      ],
      "abstract": "Soft tissue tracking is crucial for computer-assisted interventions. Existing\napproaches mainly rely on extracting discriminative features from the template\nand videos to recover corresponding matches. However, it is difficult to adopt\nthese techniques in surgical scenes, where tissues are changing in shape and\nappearance throughout the surgery. To address this problem, we exploit optical\nflow to naturally capture the pixel-wise tissue deformations and adaptively\ncorrect the tracked template. Specifically, we first implement an inter-frame\nmatching mechanism to extract a coarse region of interest based on optical flow\nfrom consecutive frames. To accommodate appearance change and alleviate drift,\nwe then propose an adaptive-template matching method, which updates the tracked\ntemplate based on the reliability of the estimates. Our approach, Ada-Tracker,\nenjoys both short-term dynamics modeling by capturing local deformations and\nlong-term dynamics modeling by introducing global temporal compensation. We\nevaluate our approach on the public SurgT benchmark, which is generated from\nHamlyn, SCARED, and Kidney boundary datasets. The experimental results show\nthat Ada-Tracker achieves superior accuracy and performs more robustly against\nprior works. Code is available at https://github.com/wrld/Ada-Tracker.",
      "tldr_zh": "该研究针对手术场景中软组织形状和外观变化的问题，提出Ada-Tracker方法，通过optical flow捕捉像素级组织变形，并结合inter-frame matching和adaptive-template matching机制进行追踪。具体而言，该方法先提取连续帧的粗略感兴趣区域，然后根据估计可靠性动态更新追踪模板，以实现短期局部变形建模和长期全局时间补偿。在公开的SurgT基准数据集（包括Hamlyn、SCARED和Kidney boundary数据集）上实验表明，Ada-Tracker在准确性和鲁棒性方面均优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE International Conference on Robotics and Automation (ICRA) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06479v2",
      "published_date": "2024-03-11 07:42:40 UTC",
      "updated_date": "2024-05-24 08:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:25:42.786786"
    },
    {
      "arxiv_id": "2403.06466v1",
      "title": "RL-MSA: a Reinforcement Learning-based Multi-line bus Scheduling Approach",
      "title_zh": "RL-MSA：一种基于强化学习的多线路巴士调度方法",
      "authors": [
        "Yingzhuo Liu"
      ],
      "abstract": "Multiple Line Bus Scheduling Problem (MLBSP) is vital to save operational\ncost of bus company and guarantee service quality for passengers. Existing\napproaches typically generate a bus scheduling scheme in an offline manner and\nthen schedule buses according to the scheme. In practice, uncertain events such\nas traffic congestion occur frequently, which may make the pre-determined bus\nscheduling scheme infeasible. In this paper, MLBSP is modeled as a Markov\nDecision Process (MDP). A Reinforcement Learning-based Multi-line bus\nScheduling Approach (RL-MSA) is proposed for bus scheduling at both the offline\nand online phases. At the offline phase, deadhead decision is integrated into\nbus selection decision for the first time to simplify the learning problem. At\nthe online phase, deadhead decision is made through a time window mechanism\nbased on the policy learned at the offline phase. We develop several new and\nuseful state features including the features for control points, bus lines and\nbuses. A bus priority screening mechanism is invented to construct bus-related\nfeatures. Considering the interests of both the bus company and passengers, a\nreward function combining the final reward and the step-wise reward is devised.\nExperiments at the offline phase demonstrate that the number of buses used of\nRL-MSA is decreased compared with offline optimization approaches. At the\nonline phase, RL-MSA can cover all departure times in a timetable (i.e.,\nservice quality) without increasing the number of buses used (i.e., operational\ncost).",
      "tldr_zh": "该论文针对多线路公交调度问题（MLBSP）提出了一种基于强化学习（Reinforcement Learning）的框架RL-MSA，以应对不确定事件（如交通拥堵）对预定调度方案的影响。RL-MSA将MLBSP建模为Markov Decision Process (MDP)，在离线阶段首次将deadhead决策整合到公交选择决策中，以简化学习问题；在在线阶段，通过时间窗口机制基于离线策略进行deadhead决策，并引入新的状态特征和公交优先筛选机制。实验结果显示，RL-MSA在离线阶段减少了所需公交数量，而在线阶段能覆盖所有发车时间表（保障服务质量）而不增加运营成本（降低公司支出）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06466v1",
      "published_date": "2024-03-11 07:07:05 UTC",
      "updated_date": "2024-03-11 07:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:25:56.318705"
    },
    {
      "arxiv_id": "2403.06465v1",
      "title": "RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jianxun Lian",
        "Yuxuan Lei",
        "Xu Huang",
        "Jing Yao",
        "Wei Xu",
        "Xing Xie"
      ],
      "abstract": "This paper introduces RecAI, a practical toolkit designed to augment or even\nrevolutionize recommender systems with the advanced capabilities of Large\nLanguage Models (LLMs). RecAI provides a suite of tools, including Recommender\nAI Agent, Recommendation-oriented Language Models, Knowledge Plugin,\nRecExplainer, and Evaluator, to facilitate the integration of LLMs into\nrecommender systems from multifaceted perspectives. The new generation of\nrecommender systems, empowered by LLMs, are expected to be more versatile,\nexplainable, conversational, and controllable, paving the way for more\nintelligent and user-centric recommendation experiences. We hope the\nopen-source of RecAI can help accelerate evolution of new advanced recommender\nsystems. The source code of RecAI is available at\n\\url{https://github.com/microsoft/RecAI}.",
      "tldr_zh": "本论文介绍了 RecAI，这是一个利用 Large Language Models (LLMs) 来增强或革新推荐系统的实用工具包。RecAI 包含 Recommender AI Agent、Recommendation-oriented Language Models、Knowledge Plugin、RecExplainer 和 Evaluator 等组件，从多个角度支持 LLMs 与推荐系统的整合，使新一代推荐系统更具通用性、可解释性、对话性和可控性。开源代码可在 GitHub 上获取，有望加速智能用户导向推荐系统的演进。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "68T50"
      ],
      "primary_category": "cs.IR",
      "comment": "4 pages. Webconf 2024 demo track",
      "pdf_url": "http://arxiv.org/pdf/2403.06465v1",
      "published_date": "2024-03-11 07:07:02 UTC",
      "updated_date": "2024-03-11 07:07:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:26:07.052162"
    },
    {
      "arxiv_id": "2403.06448v2",
      "title": "Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weihang Su",
        "Changyue Wang",
        "Qingyao Ai",
        "Yiran HU",
        "Zhijing Wu",
        "Yujia Zhou",
        "Yiqun Liu"
      ],
      "abstract": "Hallucinations in large language models (LLMs) refer to the phenomenon of\nLLMs producing responses that are coherent yet factually inaccurate. This issue\nundermines the effectiveness of LLMs in practical applications, necessitating\nresearch into detecting and mitigating hallucinations of LLMs. Previous studies\nhave mainly concentrated on post-processing techniques for hallucination\ndetection, which tend to be computationally intensive and limited in\neffectiveness due to their separation from the LLM's inference process. To\novercome these limitations, we introduce MIND, an unsupervised training\nframework that leverages the internal states of LLMs for real-time\nhallucination detection without requiring manual annotations. Additionally, we\npresent HELM, a new benchmark for evaluating hallucination detection across\nmultiple LLMs, featuring diverse LLM outputs and the internal states of LLMs\nduring their inference process. Our experiments demonstrate that MIND\noutperforms existing state-of-the-art methods in hallucination detection.",
      "tldr_zh": "本研究针对大语言模型(LLMs)的幻觉(hallucinations)问题，即生成连贯但事实不准确的响应，提出MIND框架，这是一个无监督训练方法，利用LLMs的内部状态实现实时检测，而无需手动注解。MIND克服了传统后处理技术的计算密集和效果有限的缺点，同时引入HELM基准，用于评估多种LLMs的幻觉检测性能，包括多样化的输出和推理过程。实验结果显示，MIND在检测准确性上超越现有最先进方法，为LLMs的可靠应用提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06448v2",
      "published_date": "2024-03-11 05:51:03 UTC",
      "updated_date": "2024-06-10 05:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:26:19.794168"
    },
    {
      "arxiv_id": "2403.06447v1",
      "title": "CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Junda Wu",
        "Cheng-Chun Chang",
        "Tong Yu",
        "Zhankui He",
        "Jianing Wang",
        "Yupeng Hou",
        "Julian McAuley"
      ],
      "abstract": "The long-tail recommendation is a challenging task for traditional\nrecommender systems, due to data sparsity and data imbalance issues. The recent\ndevelopment of large language models (LLMs) has shown their abilities in\ncomplex reasoning, which can help to deduce users' preferences based on very\nfew previous interactions. However, since most LLM-based systems rely on items'\nsemantic meaning as the sole evidence for reasoning, the collaborative\ninformation of user-item interactions is neglected, which can cause the LLM's\nreasoning to be misaligned with task-specific collaborative information of the\ndataset. To further align LLMs' reasoning to task-specific user-item\ninteraction knowledge, we introduce collaborative retrieval-augmented LLMs,\nCoRAL, which directly incorporate collaborative evidence into the prompts.\nBased on the retrieved user-item interactions, the LLM can analyze shared and\ndistinct preferences among users, and summarize the patterns indicating which\ntypes of users would be attracted by certain items. The retrieved collaborative\nevidence prompts the LLM to align its reasoning with the user-item interaction\npatterns in the dataset. However, since the capacity of the input prompt is\nlimited, finding the minimally-sufficient collaborative information for\nrecommendation tasks can be challenging. We propose to find the optimal\ninteraction set through a sequential decision-making process and develop a\nretrieval policy learned through a reinforcement learning (RL) framework,\nCoRAL. Our experimental results show that CoRAL can significantly improve LLMs'\nreasoning abilities on specific recommendation tasks. Our analysis also reveals\nthat CoRAL can more efficiently explore collaborative information through\nreinforcement learning.",
      "tldr_zh": "该研究针对长尾推荐(long-tail recommendation)中的数据稀疏和不平衡问题，提出CoRAL框架，即协作检索增强的Large Language Models (LLMs)，通过检索用户-物品交互证据来增强LLMs的推理能力。CoRAL将协作信息融入提示中，分析用户间的共享和不同偏好，并总结用户类型与物品吸引力的模式，以更好地对齐LLMs的推理与任务特定的用户-物品交互知识。为优化检索过程，该框架采用强化学习(reinforcement learning, RL)来学习一个顺序决策策略，选取最有效的交互集。实验结果显示，CoRAL显著提升了LLMs在推荐任务上的性能，并更高效地探索协作信息。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.06447v1",
      "published_date": "2024-03-11 05:49:34 UTC",
      "updated_date": "2024-03-11 05:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:26:33.083470"
    },
    {
      "arxiv_id": "2403.07033v1",
      "title": "Interpreting What Typical Fault Signals Look Like via Prototype-matching",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Chen",
        "Xingjian Dong",
        "Zhike Peng"
      ],
      "abstract": "Neural networks, with powerful nonlinear mapping and classification\ncapabilities, are widely applied in mechanical fault diagnosis to ensure\nsafety. However, being typical black-box models, their application is limited\nin high-reliability-required scenarios. To understand the classification logic\nand explain what typical fault signals look like, the prototype matching\nnetwork (PMN) is proposed by combining the human-inherent prototype-matching\nwith autoencoder (AE). The PMN matches AE-extracted feature with each prototype\nand selects the most similar prototype as the prediction result. It has three\ninterpreting paths on classification logic, fault prototypes, and matching\ncontributions. Conventional diagnosis and domain generalization experiments\ndemonstrate its competitive diagnostic performance and distinguished advantages\nin representation learning. Besides, the learned typical fault signals (i.e.,\nsample-level prototypes) showcase the ability for denoising and extracting\nsubtle key features that experts find challenging to capture. This ability\nbroadens human understanding and provides a promising solution from\ninterpretability research to AI-for-Science.",
      "tldr_zh": "这篇论文针对神经网络在机械故障诊断中的黑盒问题，提出了一种原型匹配网络 (PMN)，将人类的原型匹配机制与自编码器 (AE) 结合，通过将 AE 提取的特征与原型匹配来实现预测，并提供分类逻辑、故障原型和匹配贡献的三个解释路径。实验结果显示，PMN 在常规诊断和领域泛化任务中表现出色的诊断性能，并在表示学习方面具有显著优势。学到的典型故障信号（样本级原型）能够实现去噪和提取专家难以捕捉的微妙关键特征，从而增强人类理解并为 AI-for-Science 的可解释性研究提供新方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 12 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.07033v1",
      "published_date": "2024-03-11 05:47:07 UTC",
      "updated_date": "2024-03-11 05:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:26:45.132933"
    },
    {
      "arxiv_id": "2404.07941v1",
      "title": "SiGNN: A Spike-induced Graph Neural Network for Dynamic Graph Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Chen",
        "Shuai Zheng",
        "Muhao Xu",
        "Zhenfeng Zhu",
        "Yao Zhao"
      ],
      "abstract": "In the domain of dynamic graph representation learning (DGRL), the efficient\nand comprehensive capture of temporal evolution within real-world networks is\ncrucial. Spiking Neural Networks (SNNs), known as their temporal dynamics and\nlow-power characteristic, offer an efficient solution for temporal processing\nin DGRL task. However, owing to the spike-based information encoding mechanism\nof SNNs, existing DGRL methods employed SNNs face limitations in their\nrepresentational capacity. Given this issue, we propose a novel framework named\nSpike-induced Graph Neural Network (SiGNN) for learning enhanced\nspatialtemporal representations on dynamic graphs. In detail, a harmonious\nintegration of SNNs and GNNs is achieved through an innovative Temporal\nActivation (TA) mechanism. Benefiting from the TA mechanism, SiGNN not only\neffectively exploits the temporal dynamics of SNNs but also adeptly circumvents\nthe representational constraints imposed by the binary nature of spikes.\nFurthermore, leveraging the inherent adaptability of SNNs, we explore an\nin-depth analysis of the evolutionary patterns within dynamic graphs across\nmultiple time granularities. This approach facilitates the acquisition of a\nmultiscale temporal node representation.Extensive experiments on various\nreal-world dynamic graph datasets demonstrate the superior performance of SiGNN\nin the node classification task.",
      "tldr_zh": "该研究针对动态图表示学习(DGRL)中捕捉真实网络时间演化的挑战，提出了一种创新框架SiGNN，将Spiking Neural Networks (SNNs)与Graph Neural Networks (GNNs)整合。SiGNN通过Temporal Activation (TA)机制有效利用SNNs的时间动态，同时规避了spike二进制编码的表示限制。框架还分析动态图在多个时间粒度的演化模式，生成多尺度时间节点表示。在真实数据集上的节点分类实验中，SiGNN展现出优越性能，证明了其在提升DGRL效率和准确性方面的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07941v1",
      "published_date": "2024-03-11 05:19:43 UTC",
      "updated_date": "2024-03-11 05:19:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:26:56.585818"
    },
    {
      "arxiv_id": "2403.06433v1",
      "title": "Fine-Grained Pillar Feature Encoding Via Spatio-Temporal Virtual Grid for 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Konyul Park",
        "Yecheol Kim",
        "Junho Koh",
        "Byungwoo Park",
        "Jun Won Choi"
      ],
      "abstract": "Developing high-performance, real-time architectures for LiDAR-based 3D\nobject detectors is essential for the successful commercialization of\nautonomous vehicles. Pillar-based methods stand out as a practical choice for\nonboard deployment due to their computational efficiency. However, despite\ntheir efficiency, these methods can sometimes underperform compared to\nalternative point encoding techniques such as Voxel-encoding or PointNet++. We\nargue that current pillar-based methods have not sufficiently captured the\nfine-grained distributions of LiDAR points within each pillar structure.\nConsequently, there exists considerable room for improvement in pillar feature\nencoding. In this paper, we introduce a novel pillar encoding architecture\nreferred to as Fine-Grained Pillar Feature Encoding (FG-PFE). FG-PFE utilizes\nSpatio-Temporal Virtual (STV) grids to capture the distribution of point clouds\nwithin each pillar across vertical, temporal, and horizontal dimensions.\nThrough STV grids, points within each pillar are individually encoded using\nVertical PFE (V-PFE), Temporal PFE (T-PFE), and Horizontal PFE (H-PFE). These\nencoded features are then aggregated through an Attentive Pillar Aggregation\nmethod. Our experiments conducted on the nuScenes dataset demonstrate that\nFG-PFE achieves significant performance improvements over baseline models such\nas PointPillar, CenterPoint-Pillar, and PillarNet, with only a minor increase\nin computational overhead.",
      "tldr_zh": "本论文针对 LiDAR-based 3D 对象检测，指出现有 pillar-based 方法虽计算效率高，但未充分捕捉点云在 pillar 中的细粒度分布，导致性能落后于 Voxel-encoding 或 PointNet++。作者提出 Fine-Grained Pillar Feature Encoding (FG-PFE) 架构，利用 Spatio-Temporal Virtual (STV) grids 在垂直、时间和水平维度捕捉点云分布，通过 Vertical PFE (V-PFE)、Temporal PFE (T-PFE) 和 Horizontal PFE (H-PFE) 进行编码，并采用 Attentive Pillar Aggregation 方法聚合特征。实验在 nuScenes 数据集上显示，FG-PFE 比基线模型如 PointPillar 和 CenterPoint-Pillar 显著提升性能，仅带来微小计算开销。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06433v1",
      "published_date": "2024-03-11 04:58:36 UTC",
      "updated_date": "2024-03-11 04:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:27:10.446655"
    },
    {
      "arxiv_id": "2403.07032v2",
      "title": "STARFlow: Spatial Temporal Feature Re-embedding with Attentive Learning for Real-world Scene Flow",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyang Lu",
        "Qinghan Chen",
        "Ming Cheng"
      ],
      "abstract": "Scene flow prediction is a crucial underlying task in understanding dynamic\nscenes as it offers fundamental motion information. However, contemporary scene\nflow methods encounter three major challenges. Firstly, flow estimation solely\nbased on local receptive fields lacks long-dependency matching of point pairs.\nTo address this issue, we propose global attentive flow embedding to match\nall-to-all point pairs in both feature space and Euclidean space, providing\nglobal initialization before local refinement. Secondly, there are deformations\nexisting in non-rigid objects after warping, which leads to variations in the\nspatiotemporal relation between the consecutive frames. For a more precise\nestimation of residual flow, a spatial temporal feature re-embedding module is\ndevised to acquire the sequence features after deformation. Furthermore,\nprevious methods perform poor generalization due to the significant domain gap\nbetween the synthesized and LiDAR-scanned datasets. We leverage novel domain\nadaptive losses to effectively bridge the gap of motion inference from\nsynthetic to real-world. Experiments demonstrate that our approach achieves\nstate-of-the-art performance across various datasets, with particularly\noutstanding results on real-world LiDAR-scanned datasets. Our code is available\nat https://github.com/O-VIGIA/StarFlow.",
      "tldr_zh": "该论文提出STARFlow框架，用于真实世界场景流预测，旨在解决现有方法在长依赖匹配、物体变形和领域差距方面的挑战。具体而言，该框架引入全局注意力流嵌入模块进行全对全点对匹配、空间-时间特征重新嵌入模块以精确估计残差流，以及新型领域自适应损失来桥接合成和真实LiDAR-scanned数据集的差距。实验结果表明，STARFlow在多个数据集上实现最先进性能，尤其在真实LiDAR-scanned数据集上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper was renamed to:\"SSRFlow: Semantic-aware Fusion with\n  Spatial Temporal Re-embedding for Real-world Scene Flow\" [arXiv:2408.07825]\n  and was accepted in 3DV 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.07032v2",
      "published_date": "2024-03-11 04:56:10 UTC",
      "updated_date": "2024-11-14 06:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:27:19.995176"
    },
    {
      "arxiv_id": "2403.06425v1",
      "title": "A Differential Geometric View and Explainability of GNN on Evolving Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yazheng Liu",
        "Xi Zhang",
        "Sihong Xie"
      ],
      "abstract": "Graphs are ubiquitous in social networks and biochemistry, where Graph Neural\nNetworks (GNN) are the state-of-the-art models for prediction. Graphs can be\nevolving and it is vital to formally model and understand how a trained GNN\nresponds to graph evolution. We propose a smooth parameterization of the GNN\npredicted distributions using axiomatic attribution, where the distributions\nare on a low-dimensional manifold within a high-dimensional embedding space. We\nexploit the differential geometric viewpoint to model distributional evolution\nas smooth curves on the manifold. We reparameterize families of curves on the\nmanifold and design a convex optimization problem to find a unique curve that\nconcisely approximates the distributional evolution for human interpretation.\nExtensive experiments on node classification, link prediction, and graph\nclassification tasks with evolving graphs demonstrate the better sparsity,\nfaithfulness, and intuitiveness of the proposed method over the\nstate-of-the-art methods.",
      "tldr_zh": "本论文从微分几何视角（differential geometric view）探讨了图神经网络（GNN）在演化图上的可解释性，提出一种平滑参数化GNN预测分布的方法，利用公理归因（axiomatic attribution）将分布置于高维嵌入空间中的低维流形上。作者将分布演化建模为流形上的平滑曲线，并通过重新参数化和凸优化问题（convex optimization problem）设计一个独特曲线，以简洁地近似演化过程，便于人类解读。在节点分类（node classification）、链接预测（link prediction）和图分类（graph classification）任务的实验中，该方法在稀疏性（sparsity）、忠实度（faithfulness）和直观性（intuitiveness）方面优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted into ICLR 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.06425v1",
      "published_date": "2024-03-11 04:26:18 UTC",
      "updated_date": "2024-03-11 04:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:27:33.705918"
    },
    {
      "arxiv_id": "2403.12999v1",
      "title": "Prompt Selection and Augmentation for Few Examples Code Generation in Large Language Model and its Application in Robotics Control",
      "title_zh": "翻译失败",
      "authors": [
        "On Tai Wu",
        "Frodo Kin Sun Chan",
        "Zunhao Zhang",
        "Yan Nei Law",
        "Benny Drescher",
        "Edmond Shiao Bun Lai"
      ],
      "abstract": "Few-shot prompting and step-by-step reasoning have enhanced the capabilities\nof Large Language Models (LLMs) in tackling complex tasks including code\ngeneration. In this paper, we introduce a prompt selection and augmentation\nalgorithm aimed at improving mathematical reasoning and robot arm operations.\nOur approach incorporates a multi-stage example augmentation scheme combined\nwith an example selection scheme. This algorithm improves LLM performance by\nselecting a set of examples that increase diversity, minimize redundancy, and\nincrease relevance to the question. When combined with the Program-of-Thought\nprompting, our algorithm demonstrates an improvement in performance on the\nGSM8K and SVAMP benchmarks, with increases of 0.3% and 1.1% respectively.\nFurthermore, in simulated tabletop environments, our algorithm surpasses the\nCode-as-Policies approach by achieving a 3.4% increase in successful task\ncompletions and a decrease of over 70% in the number of examples used. Its\nability to discard examples that contribute little to solving the problem\nreduces the inferencing time of an LLM-powered robotics system. This algorithm\nalso offers important benefits for industrial process automation by\nstreamlining the development and deployment process, reducing manual\nprogramming effort, and enhancing code reusability.",
      "tldr_zh": "本论文提出了一种提示选择和增强算法，用于提升 Large Language Models (LLMs) 在少样本代码生成中的性能，并将其应用于机器人控制。该算法结合多阶段示例增强方案和示例选择方案，通过增加示例多样性、减少冗余并提升相关性，与 Program-of-Thought 提示相结合，在 GSM8K 和 SVAMP 基准上分别提高了 0.3% 和 1.1% 的性能。在模拟机器人环境中，该方法比 Code-as-Policies 提升了 3.4% 的任务完成率，并减少了 70% 的示例数量，从而降低推理时间、简化工业自动化开发并提高代码可重用性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.12999v1",
      "published_date": "2024-03-11 04:13:29 UTC",
      "updated_date": "2024-03-11 04:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:27:45.697775"
    },
    {
      "arxiv_id": "2403.06420v2",
      "title": "RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models",
      "title_zh": "RLingua：使用大型语言模型改善机器人操控中强化学习的样本效率",
      "authors": [
        "Liangliang Chen",
        "Yutian Lei",
        "Shiyu Jin",
        "Ying Zhang",
        "Liangjun Zhang"
      ],
      "abstract": "Reinforcement learning (RL) has demonstrated its capability in solving\nvarious tasks but is notorious for its low sample efficiency. In this paper, we\npropose RLingua, a framework that can leverage the internal knowledge of large\nlanguage models (LLMs) to reduce the sample complexity of RL in robotic\nmanipulations. To this end, we first present a method for extracting the prior\nknowledge of LLMs by prompt engineering so that a preliminary rule-based robot\ncontroller for a specific task can be generated in a user-friendly manner.\nDespite being imperfect, the LLM-generated robot controller is utilized to\nproduce action samples during rollouts with a decaying probability, thereby\nimproving RL's sample efficiency. We employ TD3, the widely-used RL baseline\nmethod, and modify the actor loss to regularize the policy learning towards the\nLLM-generated controller. RLingua also provides a novel method of improving the\nimperfect LLM-generated robot controllers by RL. We demonstrate that RLingua\ncan significantly reduce the sample complexity of TD3 in four robot tasks of\npanda_gym and achieve high success rates in 12 sampled sparsely rewarded robot\ntasks in RLBench, where the standard TD3 fails. Additionally, We validated\nRLingua's effectiveness in real-world robot experiments through Sim2Real,\ndemonstrating that the learned policies are effectively transferable to real\nrobot tasks. Further details about our work are available at our project\nwebsite https://rlingua.github.io.",
      "tldr_zh": "该研究提出RLingua框架，利用大型语言模型(LLMs)的内部知识来提升强化学习(RL)在机器人操作中的样本效率。具体方法包括通过提示工程从LLMs提取先验知识生成初步规则-based机器人控制器，并在RL回合中使用衰减概率的动作样本，同时修改TD3算法的actor loss以引导政策学习。实验结果显示，RLingua显著降低了TD3在panda_gym的四个机器人任务中的样本复杂度，并在RLBench的12个稀疏奖励任务中实现了高成功率，而标准TD3则失败。通过Sim2Real验证，该框架的策略还能有效转移到真实机器人任务中。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06420v2",
      "published_date": "2024-03-11 04:13:26 UTC",
      "updated_date": "2024-03-19 17:52:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:27:58.701103"
    },
    {
      "arxiv_id": "2403.06410v1",
      "title": "A Logical Pattern Memory Pre-trained Model for Entailment Tree Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Li Yuan",
        "Yi Cai",
        "Haopeng Ren",
        "Jiexin Wang"
      ],
      "abstract": "Generating coherent and credible explanations remains a significant challenge\nin the field of AI. In recent years, researchers have delved into the\nutilization of entailment trees to depict explanations, which exhibit a\nreasoning process of how a hypothesis is deduced from the supporting facts.\nHowever, existing models often overlook the importance of generating\nintermediate conclusions with logical consistency from the given facts, leading\nto inaccurate conclusions and undermining the overall credibility of entailment\ntrees. To address this limitation, we propose the logical pattern memory\npre-trained model (LMPM). LMPM incorporates an external memory structure to\nlearn and store the latent representations of logical patterns, which aids in\ngenerating logically consistent conclusions. Furthermore, to mitigate the\ninfluence of logically irrelevant domain knowledge in the Wikipedia-based data,\nwe introduce an entity abstraction approach to construct the dataset for\npre-training LMPM. The experimental results highlight the effectiveness of our\napproach in improving the quality of entailment tree generation. By leveraging\nlogical entailment patterns, our model produces more coherent and reasonable\nconclusions that closely align with the underlying premises. Code and Data are\nreleased at https://github.com/YuanLi95/T5-LMPM",
      "tldr_zh": "该论文针对AI领域生成连贯可信解释的挑战，提出logical pattern memory pre-trained model (LMPM)，一种预训练模型，用于生成entailment trees以展示从事实推导出假设的推理过程。LMPM通过外部记忆结构学习和存储逻辑模式的潜在表示，确保中间结论的逻辑一致性，同时引入entity abstraction方法构建预训练数据集，以减少维基百科数据中无关领域知识的影响。实验结果表明，该模型显著提高了entailment trees的质量，使生成的结论更连贯合理，并提供了开源代码和数据以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted By Coling 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06410v1",
      "published_date": "2024-03-11 03:45:09 UTC",
      "updated_date": "2024-03-11 03:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:28:11.058358"
    },
    {
      "arxiv_id": "2403.06408v1",
      "title": "What Makes Quantization for Large Language Models Hard? An Empirical Study from the Lens of Perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuocheng Gong",
        "Jiahao Liu",
        "Jingang Wang",
        "Xunliang Cai",
        "Dongyan Zhao",
        "Rui Yan"
      ],
      "abstract": "Quantization has emerged as a promising technique for improving the memory\nand computational efficiency of large language models (LLMs). Though the\ntrade-off between performance and efficiency is well-known, there is still much\nto be learned about the relationship between quantization and LLM performance.\nTo shed light on this relationship, we propose a new perspective on\nquantization, viewing it as perturbations added to the weights and activations\nof LLMs. We call this approach \"the lens of perturbation\". Using this lens, we\nconduct experiments with various artificial perturbations to explore their\nimpact on LLM performance. Our findings reveal several connections between the\nproperties of perturbations and LLM performance, providing insights into the\nfailure cases of uniform quantization and suggesting potential solutions to\nimprove the robustness of LLM quantization. To demonstrate the significance of\nour findings, we implement a simple non-uniform quantization approach based on\nour insights. Our experiments show that this approach achieves minimal\nperformance degradation on both 4-bit weight quantization and 8-bit\nquantization for weights and activations. These results validate the\ncorrectness of our approach and highlight its potential to improve the\nefficiency of LLMs without sacrificing performance.",
      "tldr_zh": "这篇论文从扰动(perturbation)的视角研究大型语言模型(LLMs)量化的难点，通过实验性扰动探索量化对模型性能的影响。研究发现，扰动属性与LLM性能密切相关，这揭示了均匀量化(uniform quantization)的失败原因，并为改进量化鲁棒性提供了潜在解决方案。作者基于这些洞见，实现了简单的非均匀量化(non-uniform quantization)方法，并在4-bit权重量化及8-bit权重和激活量化中实现了最小性能下降。这些结果验证了该方法的有效性，并为提升LLMs的内存和计算效率提供了实用途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06408v1",
      "published_date": "2024-03-11 03:42:51 UTC",
      "updated_date": "2024-03-11 03:42:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:28:23.928804"
    },
    {
      "arxiv_id": "2403.09712v1",
      "title": "A Knowledge-Injected Curriculum Pretraining Framework for Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Lin",
        "Tianhuang Su",
        "Zhenya Huang",
        "Shangzi Xue",
        "Haifeng Liu",
        "Enhong Chen"
      ],
      "abstract": "Knowledge-based question answering (KBQA) is a key task in NLP research, and\nalso an approach to access the web data and knowledge, which requires\nexploiting knowledge graphs (KGs) for reasoning. In the literature, one\npromising solution for KBQA is to incorporate the pretrained language model\n(LM) with KGs by generating KG-centered pretraining corpus, which has shown its\nsuperiority. However, these methods often depend on specific techniques and\nresources to work, which may not always be available and restrict its\napplication. Moreover, existing methods focus more on improving language\nunderstanding with KGs, while neglect the more important human-like complex\nreasoning. To this end, in this paper, we propose a general Knowledge-Injected\nCurriculum Pretraining framework (KICP) to achieve comprehensive KG learning\nand exploitation for KBQA tasks, which is composed of knowledge injection (KI),\nknowledge adaptation (KA) and curriculum reasoning (CR). Specifically, the KI\nmodule first injects knowledge into the LM by generating KG-centered\npretraining corpus, and generalizes the process into three key steps that could\nwork with different implementations for flexible application. Next, the KA\nmodule learns knowledge from the generated corpus with LM equipped with an\nadapter as well as keeps its original natural language understanding ability to\nreduce the negative impacts of the difference between the generated and natural\ncorpus. Last, to enable the LM with complex reasoning, the CR module follows\nhuman reasoning patterns to construct three corpora with increasing\ndifficulties of reasoning, and further trains the LM from easy to hard in a\ncurriculum manner. We provide an implementation of the general framework, and\nevaluate the proposed KICP on four real-word datasets. The results demonstrate\nthat our framework can achieve higher performances.",
      "tldr_zh": "这篇论文提出了一种通用的知识注入课程预训练框架 (KICP)，旨在提升知识图谱问答 (KBQA) 的性能，通过整合预训练语言模型 (LM) 与知识图谱 (KGs) 来解决现有方法的资源依赖和推理不足问题。框架包括三个模块：知识注入 (KI) 模块生成 KG 中心的预训练语料，知识适应 (KA) 模块帮助 LM 学习知识同时保留自然语言理解能力，以及课程推理 (CR) 模块模拟人类推理模式，通过难度递增的语料库进行课程式训练。实验结果显示，KICP 在四个真实数据集上实现了更高的性能，突出了其在复杂推理方面的优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by WWW 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.09712v1",
      "published_date": "2024-03-11 03:42:03 UTC",
      "updated_date": "2024-03-11 03:42:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:28:34.911075"
    },
    {
      "arxiv_id": "2403.06398v3",
      "title": "On the Diminishing Returns of Width for Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Etash Guha",
        "Vihan Lakshman"
      ],
      "abstract": "While deep neural networks have demonstrated groundbreaking performance in\nvarious settings, these models often suffer from \\emph{catastrophic forgetting}\nwhen trained on new tasks in sequence. Several works have empirically\ndemonstrated that increasing the width of a neural network leads to a decrease\nin catastrophic forgetting but have yet to characterize the exact relationship\nbetween width and continual learning. We design one of the first frameworks to\nanalyze Continual Learning Theory and prove that width is directly related to\nforgetting in Feed-Forward Networks (FFN). Specifically, we demonstrate that\nincreasing network widths to reduce forgetting yields diminishing returns. We\nempirically verify our claims at widths hitherto unexplored in prior studies\nwhere the diminishing returns are clearly observed as predicted by our theory.",
      "tldr_zh": "本研究探讨了在Continual Learning中增加神经网络宽度对减少catastrophic forgetting的影响，证明了宽度与遗忘之间存在直接关系，但收益呈现diminishing returns。作者设计了首个分析框架，针对Feed-Forward Networks (FFN)进行理论证明，表明过宽网络虽能缓解遗忘，但效果递减。通过实验在之前未探索的宽度范围内验证了这一理论，为优化神经网络在连续学习中的设计提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages. ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06398v3",
      "published_date": "2024-03-11 03:19:45 UTC",
      "updated_date": "2024-06-18 21:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:28:46.624824"
    },
    {
      "arxiv_id": "2403.06397v2",
      "title": "DeepSafeMPC: Deep Learning-Based Model Predictive Control for Safe Multi-Agent Reinforcement Learning",
      "title_zh": "DeepSafeMPC：基于深度学习的模型预测控制，用于安全的多智能体强化学习",
      "authors": [
        "Xuefeng Wang",
        "Henglin Pu",
        "Hyung Jun Kim",
        "Husheng Li"
      ],
      "abstract": "Safe Multi-agent reinforcement learning (safe MARL) has increasingly gained\nattention in recent years, emphasizing the need for agents to not only optimize\nthe global return but also adhere to safety requirements through behavioral\nconstraints. Some recent work has integrated control theory with multi-agent\nreinforcement learning to address the challenge of ensuring safety. However,\nthere have been only very limited applications of Model Predictive Control\n(MPC) methods in this domain, primarily due to the complex and implicit\ndynamics characteristic of multi-agent environments. To bridge this gap, we\npropose a novel method called Deep Learning-Based Model Predictive Control for\nSafe Multi-Agent Reinforcement Learning (DeepSafeMPC). The key insight of\nDeepSafeMPC is leveraging a entralized deep learning model to well predict\nenvironmental dynamics. Our method applies MARL principles to search for\noptimal solutions. Through the employment of MPC, the actions of agents can be\nrestricted within safe states concurrently. We demonstrate the effectiveness of\nour approach using the Safe Multi-agent MuJoCo environment, showcasing\nsignificant advancements in addressing safety concerns in MARL.",
      "tldr_zh": "该研究针对安全多智能体强化学习（safe MARL）提出了一种新方法DeepSafeMPC，将深度学习与模型预测控制（MPC）相结合，旨在优化全局回报的同时确保代理行为符合安全约束。核心创新在于使用集中式深度学习模型精确预测多智能体环境的动态，并通过MARL原则搜索最优解，同时借助MPC限制代理动作在安全状态内。实验在Safe Multi-agent MuJoCo环境中验证了该方法的有效性，实现了显著的安全性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06397v2",
      "published_date": "2024-03-11 03:17:33 UTC",
      "updated_date": "2024-03-12 02:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:28:58.090808"
    },
    {
      "arxiv_id": "2403.06382v1",
      "title": "Pre-Trained Model Recommendation for Downstream Fine-tuning",
      "title_zh": "预训练模型推荐用于下游微调",
      "authors": [
        "Jiameng Bai",
        "Sai Wu",
        "Jie Song",
        "Junbo Zhao",
        "Gang Chen"
      ],
      "abstract": "As a fundamental problem in transfer learning, model selection aims to rank\noff-the-shelf pre-trained models and select the most suitable one for the new\ntarget task. Existing model selection techniques are often constrained in their\nscope and tend to overlook the nuanced relationships between models and tasks.\nIn this paper, we present a pragmatic framework \\textbf{Fennec}, delving into a\ndiverse, large-scale model repository while meticulously considering the\nintricate connections between tasks and models. The key insight is to map all\nmodels and historical tasks into a transfer-related subspace, where the\ndistance between model vectors and task vectors represents the magnitude of\ntransferability. A large vision model, as a proxy, infers a new task's\nrepresentation in the transfer space, thereby circumventing the computational\nburden of extensive forward passes. We also investigate the impact of the\ninherent inductive bias of models on transfer results and propose a novel\nmethod called \\textbf{archi2vec} to encode the intricate structures of models.\nThe transfer score is computed through straightforward vector arithmetic with a\ntime complexity of $\\mathcal{O}(1)$. Finally, we make a substantial\ncontribution to the field by releasing a comprehensive benchmark. We validate\nthe effectiveness of our framework through rigorous testing on two benchmarks.\nThe benchmark and the code will be publicly available in the near future.",
      "tldr_zh": "本论文提出了一种名为 Fennec 的框架，用于预训练模型的推荐（model selection），以优化下游微调任务的转移学习（transfer learning）。框架的核心方法是将模型和历史任务映射到迁移相关的子空间，使用大型视觉模型作为代理推断新任务表示，并引入 archi2vec 方法编码模型的固有归纳偏差（inherent inductive bias），从而通过简单向量运算以 O(1) 时间复杂度计算转移分数。实验在两个基准上验证了 Fennec 的有效性，并发布了全面的基准数据集，为模型选择提供实用工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06382v1",
      "published_date": "2024-03-11 02:24:32 UTC",
      "updated_date": "2024-03-11 02:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:29:13.254862"
    },
    {
      "arxiv_id": "2403.07028v1",
      "title": "An Efficient Learning-based Solver Comparable to Metaheuristics for the Capacitated Arc Routing Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Runze Guo",
        "Feng Xue",
        "Anlong Ming",
        "Nicu Sebe"
      ],
      "abstract": "Recently, neural networks (NN) have made great strides in combinatorial\noptimization. However, they face challenges when solving the capacitated arc\nrouting problem (CARP) which is to find the minimum-cost tour covering all\nrequired edges on a graph, while within capacity constraints. In tackling CARP,\nNN-based approaches tend to lag behind advanced metaheuristics, since they lack\ndirected arc modeling and efficient learning methods tailored for complex CARP.\nIn this paper, we introduce an NN-based solver to significantly narrow the gap\nwith advanced metaheuristics while exhibiting superior efficiency. First, we\npropose the direction-aware attention model (DaAM) to incorporate\ndirectionality into the embedding process, facilitating more effective\none-stage decision-making. Second, we design a supervised reinforcement\nlearning scheme that involves supervised pre-training to establish a robust\ninitial policy for subsequent reinforcement fine-tuning. It proves particularly\nvaluable for solving CARP that has a higher complexity than the node routing\nproblems (NRPs). Finally, a path optimization method is proposed to adjust the\ndepot return positions within the path generated by DaAM. Experiments\nillustrate that our approach surpasses heuristics and achieves decision quality\ncomparable to state-of-the-art metaheuristics for the first time while\nmaintaining superior efficiency.",
      "tldr_zh": "该研究提出了一种高效的基于神经网络（NN）的求解器，用于解决Capacitated Arc Routing Problem (CARP)，旨在与先进的元启发式(metaheuristics)算法在决策质量上相当，同时提升效率。论文引入Direction-Aware Attention Model (DaAM)，通过将方向性融入嵌入过程，实现更有效的单阶段决策；并设计了监督强化学习方案，包括监督预训练来建立稳健初始策略，随后进行强化微调，以应对CARP的高复杂度。实验结果显示，该方法超越了传统启发式算法，并在决策质量上首次与最先进的metaheuristics相当，同时保持更高的计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07028v1",
      "published_date": "2024-03-11 02:17:42 UTC",
      "updated_date": "2024-03-11 02:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:29:22.321287"
    },
    {
      "arxiv_id": "2403.06360v1",
      "title": "Human and Automatic Interpretation of Romanian Noun Compounds",
      "title_zh": "翻译失败",
      "authors": [
        "Ioana Marinescu",
        "Christiane Fellbaum"
      ],
      "abstract": "Determining the intended, context-dependent meanings of noun compounds like\n\"shoe sale\" and \"fire sale\" remains a challenge for NLP. Previous work has\nrelied on inventories of semantic relations that capture the different meanings\nbetween compound members. Focusing on Romanian compounds, whose morphosyntax\ndiffers from that of their English counterparts, we propose a new set of\nrelations and test it with human annotators and a neural net classifier.\nResults show an alignment of the network's predictions and human judgments,\neven where the human agreement rate is low. Agreement tracks with the frequency\nof the selected relations, regardless of structural differences. However, the\nmost frequently selected relation was none of the sixteen labeled semantic\nrelations, indicating the need for a better relation inventory.",
      "tldr_zh": "这篇论文探讨了NLP中名词复合词（如\"shoe sale\"）的语境相关含义解释挑战，聚焦于罗马尼亚语的形态句法差异。研究者提出了一套新的semantic relations，并通过人类标注者和neural net classifier进行测试。结果显示，分类器的预测与人类判断高度一致，即使人类一致性较低，且一致性主要取决于所选关系的频率；然而，最常选的关系是十六个标记semantic relations中的“无”，表明需要改进关系库存。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.06360v1",
      "published_date": "2024-03-11 01:18:00 UTC",
      "updated_date": "2024-03-11 01:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:29:34.627778"
    },
    {
      "arxiv_id": "2403.06356v1",
      "title": "Video Generation with Consistency Tuning",
      "title_zh": "视频生成中的一致性调优",
      "authors": [
        "Chaoyi Wang",
        "Yaozhe Song",
        "Yafeng Zhang",
        "Jun Pei",
        "Lijie Xia",
        "Jianpo Liu"
      ],
      "abstract": "Currently, various studies have been exploring generation of long videos.\nHowever, the generated frames in these videos often exhibit jitter and noise.\nTherefore, in order to generate the videos without these noise, we propose a\nnovel framework composed of four modules: separate tuning module, average\nfusion module, combined tuning module, and inter-frame consistency module. By\napplying our newly proposed modules subsequently, the consistency of the\nbackground and foreground in each video frames is optimized. Besides, the\nexperimental results demonstrate that videos generated by our method exhibit a\nhigh quality in comparison of the state-of-the-art methods.",
      "tldr_zh": "本文提出了一种名为Consistency Tuning的视频生成框架，以解决现有方法中生成的视频帧存在抖动和噪声的问题。该框架由四个模块组成：separate tuning module、average fusion module、combined tuning module 和 inter-frame consistency module，通过逐步应用这些模块优化视频帧中背景和前景的一致性。实验结果显示，该方法生成的视频质量高于最先进的技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06356v1",
      "published_date": "2024-03-11 01:11:28 UTC",
      "updated_date": "2024-03-11 01:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:29:45.715671"
    },
    {
      "arxiv_id": "2403.06349v1",
      "title": "MOAB: Multi-Modal Outer Arithmetic Block For Fusion Of Histopathological Images And Genetic Data For Brain Tumor Grading",
      "title_zh": "MOAB：多模态外层算术块，用于融合组织病理图像和遗传数据以进行脑肿瘤分级",
      "authors": [
        "Omnia Alwazzan",
        "Abbas Khan",
        "Ioannis Patras",
        "Gregory Slabaugh"
      ],
      "abstract": "Brain tumors are an abnormal growth of cells in the brain. They can be\nclassified into distinct grades based on their growth. Often grading is\nperformed based on a histological image and is one of the most significant\npredictors of a patients prognosis, the higher the grade, the more aggressive\nthe tumor. Correct diagnosis of a tumor grade remains challenging. Though\nhistopathological grading has been shown to be prognostic, results are subject\nto interobserver variability, even among experienced pathologists. Recently,\nthe World Health Organization reported that advances in molecular genetics have\nled to improvements in tumor classification. This paper seeks to integrate\nhistological images and genetic data for improved computer-aided diagnosis. We\npropose a novel Multi-modal Outer Arithmetic Block (MOAB) based on arithmetic\noperations to combine latent representations of the different modalities for\npredicting the tumor grade (Grade \\rom{2}, \\rom{3} and \\rom{4}). Extensive\nexperiments evaluate the effectiveness of our approach. By applying MOAB to The\nCancer Genome Atlas (TCGA) glioma dataset, we show that it can improve\nseparation between similar classes (Grade \\rom{2} and \\rom{3}) and outperform\nprior state-of-the-art grade classification techniques.",
      "tldr_zh": "本研究针对脑肿瘤分级面临的挑战，如组织病理图像（histopathological images）分析的观察者间变异性，提出整合组织病理图像和遗传数据（genetic data）来提升计算机辅助诊断准确性。作者引入了新型 Multi-Modal Outer Arithmetic Block (MOAB)，该模块基于算术运算融合不同模态的潜在表示，用于预测肿瘤等级（Grade II, III 和 IV）。在 The Cancer Genome Atlas (TCGA) 胶质瘤（glioma）数据集上的实验显示，MOAB 显著改善了类似类别（如 Grade II 和 III）之间的分离，并超过了现有最先进的技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06349v1",
      "published_date": "2024-03-11 00:33:28 UTC",
      "updated_date": "2024-03-11 00:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:29:58.882908"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 91,
  "processed_papers_count": 91,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T14:30:25.683355"
}