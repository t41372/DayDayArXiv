[
  {
    "arxiv_id": "2405.16728v1",
    "title": "Towards Multi-Task Multi-Modal Models: A Video Generative Perspective",
    "authors": [
      "Lijun Yu"
    ],
    "abstract": "Advancements in language foundation models have primarily fueled the recent\nsurge in artificial intelligence. In contrast, generative learning of\nnon-textual modalities, especially videos, significantly trails behind language\nmodeling. This thesis chronicles our endeavor to build multi-task models for\ngenerating videos and other modalities under diverse conditions, as well as for\nunderstanding and compression applications. Given the high dimensionality of\nvisual data, we pursue concise and accurate latent representations. Our\nvideo-native spatial-temporal tokenizers preserve high fidelity. We unveil a\nnovel approach to mapping bidirectionally between visual observation and\ninterpretable lexical terms. Furthermore, our scalable visual token\nrepresentation proves beneficial across generation, compression, and\nunderstanding tasks. This achievement marks the first instances of language\nmodels surpassing diffusion models in visual synthesis and a video tokenizer\noutperforming industry-standard codecs. Within these multi-modal latent spaces,\nwe study the design of multi-task generative models. Our masked multi-task\ntransformer excels at the quality, efficiency, and flexibility of video\ngeneration. We enable a frozen language model, trained solely on text, to\ngenerate visual content. Finally, we build a scalable generative multi-modal\ntransformer trained from scratch, enabling the generation of videos containing\nhigh-fidelity motion with the corresponding audio given diverse conditions.\nThroughout the course, we have shown the effectiveness of integrating multiple\ntasks, crafting high-fidelity latent representation, and generating multiple\nmodalities. This work suggests intriguing potential for future exploration in\ngenerating non-textual data and enabling real-time, interactive experiences\nacross various media forms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2405.16728v1",
    "published_date": "2024-05-26 23:56:45 UTC",
    "updated_date": "2024-05-26 23:56:45 UTC"
  },
  {
    "arxiv_id": "2405.16718v1",
    "title": "Amortized Active Causal Induction with Deep Reinforcement Learning",
    "authors": [
      "Yashas Annadani",
      "Panagiotis Tigas",
      "Stefan Bauer",
      "Adam Foster"
    ],
    "abstract": "We present Causal Amortized Active Structure Learning (CAASL), an active\nintervention design policy that can select interventions that are adaptive,\nreal-time and that does not require access to the likelihood. This policy, an\namortized network based on the transformer, is trained with reinforcement\nlearning on a simulator of the design environment, and a reward function that\nmeasures how close the true causal graph is to a causal graph posterior\ninferred from the gathered data. On synthetic data and a single-cell gene\nexpression simulator, we demonstrate empirically that the data acquired through\nour policy results in a better estimate of the underlying causal graph than\nalternative strategies. Our design policy successfully achieves amortized\nintervention design on the distribution of the training environment while also\ngeneralizing well to distribution shifts in test-time design environments.\nFurther, our policy also demonstrates excellent zero-shot generalization to\ndesign environments with dimensionality higher than that during training, and\nto intervention types that it has not been trained on.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16718v1",
    "published_date": "2024-05-26 23:14:37 UTC",
    "updated_date": "2024-05-26 23:14:37 UTC"
  },
  {
    "arxiv_id": "2405.16714v1",
    "title": "Crafting Interpretable Embeddings by Asking LLMs Questions",
    "authors": [
      "Vinamra Benara",
      "Chandan Singh",
      "John X. Morris",
      "Richard Antonello",
      "Ion Stoica",
      "Alexander G. Huth",
      "Jianfeng Gao"
    ],
    "abstract": "Large language models (LLMs) have rapidly improved text embeddings for a\ngrowing array of natural-language processing tasks. However, their opaqueness\nand proliferation into scientific domains such as neuroscience have created a\ngrowing need for interpretability. Here, we ask whether we can obtain\ninterpretable embeddings through LLM prompting. We introduce question-answering\nembeddings (QA-Emb), embeddings where each feature represents an answer to a\nyes/no question asked to an LLM. Training QA-Emb reduces to selecting a set of\nunderlying questions rather than learning model weights.\n  We use QA-Emb to flexibly generate interpretable models for predicting fMRI\nvoxel responses to language stimuli. QA-Emb significantly outperforms an\nestablished interpretable baseline, and does so while requiring very few\nquestions. This paves the way towards building flexible feature spaces that can\nconcretize and evaluate our understanding of semantic brain representations. We\nadditionally find that QA-Emb can be effectively approximated with an efficient\nmodel, and we explore broader applications in simple NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16714v1",
    "published_date": "2024-05-26 22:30:29 UTC",
    "updated_date": "2024-05-26 22:30:29 UTC"
  },
  {
    "arxiv_id": "2405.16712v1",
    "title": "Zamba: A Compact 7B SSM Hybrid Model",
    "authors": [
      "Paolo Glorioso",
      "Quentin Anthony",
      "Yury Tokpanov",
      "James Whittington",
      "Jonathan Pilault",
      "Adam Ibrahim",
      "Beren Millidge"
    ],
    "abstract": "In this technical report, we present Zamba, a novel 7B SSM-transformer hybrid\nmodel which achieves competitive performance against leading open-weight models\nat a comparable scale. Zamba is trained on 1T tokens from openly available\ndatasets and is the best non-transformer model at this scale. Zamba pioneers a\nunique architecture combining a Mamba backbone with a single shared attention\nmodule, thus obtaining the benefits of attention at minimal parameter cost. Due\nto its architecture, Zamba is significantly faster at inference than comparable\ntransformer models and requires substantially less memory for generation of\nlong sequences. Zamba is pretrained in two phases: the first phase is based on\nexisting web datasets, while the second one consists of annealing the model\nover high-quality instruct and synthetic datasets, and is characterized by a\nrapid learning rate decay. We open-source the weights and all checkpoints for\nZamba, through both phase 1 and annealing phases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16712v1",
    "published_date": "2024-05-26 22:23:02 UTC",
    "updated_date": "2024-05-26 22:23:02 UTC"
  },
  {
    "arxiv_id": "2405.16711v1",
    "title": "The AI-DEC: A Card-based Design Method for User-centered AI Explanations",
    "authors": [
      "Christine P Lee",
      "Min Kyung Lee",
      "Bilge Mutlu"
    ],
    "abstract": "Increasing evidence suggests that many deployed AI systems do not\nsufficiently support end-user interaction and information needs. Engaging\nend-users in the design of these systems can reveal user needs and\nexpectations, yet effective ways of engaging end-users in the AI explanation\ndesign remain under-explored. To address this gap, we developed a design\nmethod, called AI-DEC, that defines four dimensions of AI explanations that are\ncritical for the integration of AI systems -- communication content, modality,\nfrequency, and direction -- and offers design examples for end-users to design\nAI explanations that meet their needs. We evaluated this method through\nco-design sessions with workers in healthcare, finance, and management\nindustries who regularly use AI systems in their daily work. Findings indicate\nthat the AI-DEC effectively supported workers in designing explanations that\naccommodated diverse levels of performance and autonomy needs, which varied\ndepending on the AI system's workplace role and worker values. We discuss the\nimplications of using the AI-DEC for the user-centered design of AI\nexplanations in real-world systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16711v1",
    "published_date": "2024-05-26 22:18:38 UTC",
    "updated_date": "2024-05-26 22:18:38 UTC"
  },
  {
    "arxiv_id": "2406.01606v1",
    "title": "SymTax: Symbiotic Relationship and Taxonomy Fusion for Effective Citation Recommendation",
    "authors": [
      "Karan Goyal",
      "Mayank Goel",
      "Vikram Goyal",
      "Mukesh Mohania"
    ],
    "abstract": "Citing pertinent literature is pivotal to writing and reviewing a scientific\ndocument. Existing techniques mainly focus on the local context or the global\ncontext for recommending citations but fail to consider the actual human\ncitation behaviour. We propose SymTax, a three-stage recommendation\narchitecture that considers both the local and the global context, and\nadditionally the taxonomical representations of query-candidate tuples and the\nSymbiosis prevailing amongst them. SymTax learns to embed the infused\ntaxonomies in the hyperbolic space and uses hyperbolic separation as a latent\nfeature to compute query-candidate similarity. We build a novel and large\ndataset ArSyTa containing 8.27 million citation contexts and describe the\ncreation process in detail. We conduct extensive experiments and ablation\nstudies to demonstrate the effectiveness and design choice of each module in\nour framework. Also, combinatorial analysis from our experiments shed light on\nthe choice of language models (LMs) and fusion embedding, and the inclusion of\nsection heading as a signal. Our proposed module that captures the symbiotic\nrelationship solely leads to performance gains of 26.66% and 39.25% in Recall@5\nw.r.t. SOTA on ACL-200 and RefSeer datasets, respectively. The complete\nframework yields a gain of 22.56% in Recall@5 wrt SOTA on our proposed dataset.\nThe code and dataset are available at https://github.com/goyalkaraniit/SymTax",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted in ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01606v1",
    "published_date": "2024-05-26 21:51:58 UTC",
    "updated_date": "2024-05-26 21:51:58 UTC"
  },
  {
    "arxiv_id": "2406.00034v2",
    "title": "Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories",
    "authors": [
      "Tianlong Wang",
      "Xianfeng Jiao",
      "Yinghao Zhu",
      "Zhongzhi Chen",
      "Yifan He",
      "Xu Chu",
      "Junyi Gao",
      "Yasha Wang",
      "Liantao Ma"
    ],
    "abstract": "Recent studies have indicated that Large Language Models (LLMs) harbor an\ninherent understanding of truthfulness, yet often fail to consistently express\nit and generate false statements. This gap between \"knowing\" and \"telling\"\nposes a challenge for ensuring the truthfulness of generated content. Inspired\nby recent work on the practice of encoding human-interpretable concepts\nlinearly within large language models, we treat truthfulness as a specially\nlinearly encoded concept within LLMs, and introduce Adaptive Activation\nSteering (ACT), a tuning-free method that adaptively shifts LLM's activations\nin the \"truthful\" direction during inference. ACT addresses diverse categories\nof hallucinations by utilizing diverse truthfulness-related steering vectors\nand adjusting the steering intensity adaptively. Applied as an add-on across\nvarious models, ACT significantly improves truthfulness in LLaMA ($\\uparrow$\n142%), LLaMA2 ($\\uparrow$ 24%), Alpaca ($\\uparrow$ 36%), Vicuna ($\\uparrow$\n28%), LLaMA2-Chat ($\\uparrow$ 19%), and LLaMA3($\\uparrow$ 34%). Furthermore, we\nverify ACT's scalability across larger models (13B, 33B, 65B), underscoring the\nadaptability of ACT to large-scale language models. Our code is available at\nhttps://github.com/tianlwang/ACT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACM TheWebConf 2025 Conference (WWW 2025) Research Track",
    "pdf_url": "http://arxiv.org/pdf/2406.00034v2",
    "published_date": "2024-05-26 21:39:53 UTC",
    "updated_date": "2025-02-26 14:07:05 UTC"
  },
  {
    "arxiv_id": "2405.16693v1",
    "title": "Detection of decision-making manipulation in the pairwise comparisons method",
    "authors": [
      "Michał Strada",
      "Sebastian Ernst",
      "Jacek Szybowski",
      "Konrad Kułakowski"
    ],
    "abstract": "Most decision-making models, including the pairwise comparison method, assume\nthe decision-makers honesty. However, it is easy to imagine a situation where a\ndecision-maker tries to manipulate the ranking results. This paper presents\nthree simple manipulation methods in the pairwise comparison method. We then\ntry to detect these methods using appropriately constructed neural networks.\nExperimental results accompany the proposed solutions on the generated data,\nshowing a considerable manipulation detection level.",
    "categories": [
      "cs.AI",
      "cs.DM"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.16693v1",
    "published_date": "2024-05-26 20:58:12 UTC",
    "updated_date": "2024-05-26 20:58:12 UTC"
  },
  {
    "arxiv_id": "2407.12145v1",
    "title": "Adoption and Impact of ChatGPT in Computer Science Education: A Case Study on a Database Administration Course",
    "authors": [
      "Daniel López-Fernández",
      "Ricardo Vergaz"
    ],
    "abstract": "Contribution: The combination of ChatGPT with traditional learning resources\nis very effective in computer science education. High-performing students are\nthe ones who are using ChatGPT the most. So, a new digital trench could be\nrising between these students and those with lower degree of fundamentals and\nworse prompting skills, who may not take advantage of all the ChatGPT\npossibilities. Background: The irruption of GenAI such as ChatGPT has changed\nthe educational landscape. Therefore, methodological guidelines and more\nempirical experiences in computer science education are needed to better\nunderstand these tools and know how to use them to their fullest potential.\nResearch Questions: This article addresses three questions. The first two\nexplore the degree of use and perceived usefulness of ChatGPT among computer\nscience students to learn database administration, where as the third one\nexplore how the utilization of ChatGPT can impact academic performance.\nMethodology: This contribution presents an exploratory and correlational study\nconducted with 37 students who used ChatGPT as a support tool to learn database\nadministration. The student grades and a comprehensive questionnaire were\nemployed as research instruments. Findings: The obtained results indicate that\ntraditional learning resources, such as teacher explanations and student\nreports, were widely used and correlated positively with student grade. The\nusage and perceived utility of ChatGPT were moderate, but positive correlations\nbetween student grade and ChatGPT usage were found. Indeed, a significantly\nhigher use of this tool was identified among the group of outstanding students.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12145v1",
    "published_date": "2024-05-26 20:51:28 UTC",
    "updated_date": "2024-05-26 20:51:28 UTC"
  },
  {
    "arxiv_id": "2405.16671v2",
    "title": "Mixture of Latent Experts Using Tensor Products",
    "authors": [
      "Zhan Su",
      "Fengran Mo",
      "Prayag Tiwari",
      "Benyou Wang",
      "Jian-Yun Nie",
      "Jakob Grue Simonsen"
    ],
    "abstract": "In multi-task learning, the conventional approach involves training a model\non multiple tasks simultaneously. However, the training signals from different\ntasks can interfere with one another, potentially leading to \\textit{negative\ntransfer}. To mitigate this, we investigate if modular language models can\nfacilitate positive transfer and systematic generalization. Specifically, we\npropose a novel modular language model (\\texttt{TensorPoly}), that balances\nparameter efficiency with nuanced routing methods. For \\textit{modules}, we\nreparameterize Low-Rank Adaptation (\\texttt{LoRA}) by employing an entangled\ntensor through the use of tensor product operations and name the resulting\napproach \\texttt{TLoRA}. For \\textit{routing function}, we tailor two\ninnovative routing functions according to the granularity:\n\\texttt{TensorPoly-I} which directs to each rank within the entangled tensor\nwhile \\texttt{TensorPoly-II} offers a finer-grained routing approach targeting\neach order of the entangled tensor. The experimental results from the\nmulti-task T0-benchmark demonstrate that: 1) all modular LMs surpass the\ncorresponding dense approaches, highlighting the potential of modular language\nmodels to mitigate negative inference in multi-task learning and deliver\nsuperior outcomes. 2) \\texttt{TensorPoly-I} achieves higher parameter\nefficiency in adaptation and outperforms other modular LMs, which shows the\npotential of our approach in multi-task transfer learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/microsoft/mttl/tree/zs_code",
    "pdf_url": "http://arxiv.org/pdf/2405.16671v2",
    "published_date": "2024-05-26 19:25:08 UTC",
    "updated_date": "2024-12-05 19:03:06 UTC"
  },
  {
    "arxiv_id": "2405.20775v2",
    "title": "Medical MLLM is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models",
    "authors": [
      "Xijie Huang",
      "Xinyuan Wang",
      "Hantao Zhang",
      "Yinghao Zhu",
      "Jiawen Xi",
      "Jingkun An",
      "Hao Wang",
      "Hao Liang",
      "Chengwei Pan"
    ],
    "abstract": "Security concerns related to Large Language Models (LLMs) have been\nextensively explored, yet the safety implications for Multimodal Large Language\nModels (MLLMs), particularly in medical contexts (MedMLLMs), remain\ninsufficiently studied. This paper delves into the underexplored security\nvulnerabilities of MedMLLMs, especially when deployed in clinical environments\nwhere the accuracy and relevance of question-and-answer interactions are\ncritically tested against complex medical challenges. By combining existing\nclinical medical data with atypical natural phenomena, we define the mismatched\nmalicious attack (2M-attack) and introduce its optimized version, known as the\noptimized mismatched malicious attack (O2M-attack or 2M-optimization). Using\nthe voluminous 3MAD dataset that we construct, which covers a wide range of\nmedical image modalities and harmful medical scenarios, we conduct a\ncomprehensive analysis and propose the MCM optimization method, which\nsignificantly enhances the attack success rate on MedMLLMs. Evaluations with\nthis dataset and attack methods, including white-box attacks on LLaVA-Med and\ntransfer attacks (black-box) on four other SOTA models, indicate that even\nMedMLLMs designed with enhanced security features remain vulnerable to security\nbreaches. Our work underscores the urgent need for a concerted effort to\nimplement robust security measures and enhance the safety and efficacy of\nopen-source MedMLLMs, particularly given the potential severity of jailbreak\nattacks and other malicious or clinically significant exploits in medical\nsettings. Our code is available at https://github.com/dirtycomputer/O2M_attack.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.20775v2",
    "published_date": "2024-05-26 19:11:21 UTC",
    "updated_date": "2024-08-21 02:56:47 UTC"
  },
  {
    "arxiv_id": "2405.16661v2",
    "title": "RLSF: Reinforcement Learning via Symbolic Feedback",
    "authors": [
      "Piyush Jha",
      "Prithwish Jana",
      "Pranavkrishna Suresh",
      "Arnav Arora",
      "Vijay Ganesh"
    ],
    "abstract": "Reinforcement Learning with Human Feedback (RLHF) is considered a standard\napproach to fine-tuning Large Language Models (LLMs). However, such methods\noften face limitations such as unsound black-box reward models, difficulties in\ncollecting human preference data, and the reliance on sparse scalar rewards.\nThese methods often fall short when applied to tasks that require complex\ndomain-specific understanding.\n  To address these challenges, we propose a new fine-tuning paradigm we refer\nto as Reinforcement Learning via Symbolic Feedback (RLSF), which aims to\nimprove domain-specific understanding of LLMs more effectively than traditional\nreward signals. In the RLSF setting, the LLM being fine-tuned is considered an\nRL agent, while the environment is allowed access to reasoning or domain\nknowledge tools (e.g., solvers, provers, algebra systems, or knowledge bases).\nCrucially, in RLSF, these reasoning tools can provide feedback to the LLMs via\npoly-sized certificates (e.g., proofs), that characterize errors in the\nLLM-generated object with respect to some correctness specification. As a\nbonus, our RLSF approach does not require the reasoning systems we use to be\ndifferentiable. The ability of RLSF-based fine-tuning to leverage\ncertificate-generating symbolic tools enables sound fine-grained (token-level)\nreward signals to LLMs, and thus addresses the limitations of traditional\nreward models mentioned above.\n  Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs\noutperforms traditional approaches on five different applications, namely,\nprogram synthesis from natural language pseudo-code to programming language,\nthree chemistry tasks, and solving the Game of 24. A takeaway is that\nfine-tuning via RLSF enables relatively smaller LLMs to significantly\noutperform closed-source models that are orders of magnitude larger (e.g.,\nGPT-4).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16661v2",
    "published_date": "2024-05-26 18:49:59 UTC",
    "updated_date": "2024-10-05 23:17:18 UTC"
  },
  {
    "arxiv_id": "2405.16658v1",
    "title": "Acceleration of Grokking in Learning Arithmetic Operations via Kolmogorov-Arnold Representation",
    "authors": [
      "Yeachan Park",
      "Minseok Kim",
      "Yeoneung Kim"
    ],
    "abstract": "We propose novel methodologies aimed at accelerating the grokking phenomenon,\nwhich refers to the rapid increment of test accuracy after a long period of\noverfitting as reported in~\\cite{power2022grokking}. Focusing on the grokking\nphenomenon that arises in learning arithmetic binary operations via the\ntransformer model, we begin with a discussion on data augmentation in the case\nof commutative binary operations. To further accelerate, we elucidate\narithmetic operations through the lens of the Kolmogorov-Arnold (KA)\nrepresentation theorem, revealing its correspondence to the transformer\narchitecture: embedding, decoder block, and classifier. Observing the shared\nstructure between KA representations associated with binary operations, we\nsuggest various transfer learning mechanisms that expedite grokking. This\ninterpretation is substantiated through a series of rigorous experiments. In\naddition, our approach is successful in learning two nonstandard arithmetic\ntasks: composition of operations and a system of equations. Furthermore, we\nreveal that the model is capable of learning arithmetic operations using a\nlimited number of tokens under embedding transfer, which is supported by a set\nof experiments as well.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16658v1",
    "published_date": "2024-05-26 18:29:24 UTC",
    "updated_date": "2024-05-26 18:29:24 UTC"
  },
  {
    "arxiv_id": "2405.16655v1",
    "title": "Predicting Likely-Vulnerable Code Changes: Machine Learning-based Vulnerability Protections for Android Open Source Project",
    "authors": [
      "Keun Soo Yim"
    ],
    "abstract": "This paper presents a framework that selectively triggers security reviews\nfor incoming source code changes. Functioning as a review bot within a code\nreview service, the framework can automatically request additional security\nreviews at pre-submit time before the code changes are submitted to a source\ncode repository. Because performing such secure code reviews add cost, the\nframework employs a classifier trained to identify code changes with a high\nlikelihood of vulnerabilities. The online classifier leverages various types of\ninput features to analyze the review patterns, track the software engineering\nprocess, and mine specific text patterns within given code changes. The\nclassifier and its features are meticulously chosen and optimized using data\nfrom the submitted code changes and reported vulnerabilities in Android Open\nSource Project (AOSP). The evaluation results demonstrate that our\nVulnerability Prevention (VP) framework identifies approximately 80% of the\nvulnerability-inducing code changes in the dataset with a precision ratio of\naround 98% and a false positive rate of around 1.7%. We discuss the\nimplications of deploying the VP framework in multi-project settings and future\ndirections for Android security research. This paper explores and validates our\napproach to code change-granularity vulnerability prediction, offering a\npreventive technique for software security by preemptively detecting vulnerable\ncode changes before submission.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "This is a preprint of an article that has been submitted to a journal\n  for publication",
    "pdf_url": "http://arxiv.org/pdf/2405.16655v1",
    "published_date": "2024-05-26 18:17:46 UTC",
    "updated_date": "2024-05-26 18:17:46 UTC"
  },
  {
    "arxiv_id": "2405.16642v3",
    "title": "Fast TRAC: A Parameter-Free Optimizer for Lifelong Reinforcement Learning",
    "authors": [
      "Aneesh Muppidi",
      "Zhiyu Zhang",
      "Heng Yang"
    ],
    "abstract": "A key challenge in lifelong reinforcement learning (RL) is the loss of\nplasticity, where previous learning progress hinders an agent's adaptation to\nnew tasks. While regularization and resetting can help, they require precise\nhyperparameter selection at the outset and environment-dependent adjustments.\nBuilding on the principled theory of online convex optimization, we present a\nparameter-free optimizer for lifelong RL, called TRAC, which requires no tuning\nor prior knowledge about the distribution shifts. Extensive experiments on\nProcgen, Atari, and Gym Control environments show that TRAC works surprisingly\nwell-mitigating loss of plasticity and rapidly adapting to challenging\ndistribution shifts-despite the underlying optimization problem being nonconvex\nand nonstationary.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Code and Website:\n  https://computationalrobotics.seas.harvard.edu/TRAC/",
    "pdf_url": "http://arxiv.org/pdf/2405.16642v3",
    "published_date": "2024-05-26 17:38:44 UTC",
    "updated_date": "2024-10-30 13:54:18 UTC"
  },
  {
    "arxiv_id": "2405.16640v2",
    "title": "A Survey of Multimodal Large Language Model from A Data-centric Perspective",
    "authors": [
      "Tianyi Bai",
      "Hao Liang",
      "Binwang Wan",
      "Yanran Xu",
      "Xi Li",
      "Shiyu Li",
      "Ling Yang",
      "Bozhou Li",
      "Yifan Wang",
      "Bin Cui",
      "Ping Huang",
      "Jiulong Shan",
      "Conghui He",
      "Binhang Yuan",
      "Wentao Zhang"
    ],
    "abstract": "Multimodal large language models (MLLMs) enhance the capabilities of standard\nlarge language models by integrating and processing data from multiple\nmodalities, including text, vision, audio, video, and 3D environments. Data\nplays a pivotal role in the development and refinement of these models. In this\nsurvey, we comprehensively review the literature on MLLMs from a data-centric\nperspective. Specifically, we explore methods for preparing multimodal data\nduring the pretraining and adaptation phases of MLLMs. Additionally, we analyze\nthe evaluation methods for the datasets and review the benchmarks for\nevaluating MLLMs. Our survey also outlines potential future research\ndirections. This work aims to provide researchers with a detailed understanding\nof the data-driven aspects of MLLMs, fostering further exploration and\ninnovation in this field.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16640v2",
    "published_date": "2024-05-26 17:31:21 UTC",
    "updated_date": "2024-07-18 09:01:52 UTC"
  },
  {
    "arxiv_id": "2405.17507v1",
    "title": "Enhancing Sustainable Urban Mobility Prediction with Telecom Data: A Spatio-Temporal Framework Approach",
    "authors": [
      "ChungYi Lin",
      "Shen-Lung Tung",
      "Hung-Ting Su",
      "Winston H. Hsu"
    ],
    "abstract": "Traditional traffic prediction, limited by the scope of sensor data, falls\nshort in comprehensive traffic management. Mobile networks offer a promising\nalternative using network activity counts, but these lack crucial\ndirectionality. Thus, we present the TeltoMob dataset, featuring undirected\ntelecom counts and corresponding directional flows, to predict directional\nmobility flows on roadways. To address this, we propose a two-stage\nspatio-temporal graph neural network (STGNN) framework. The first stage uses a\npre-trained STGNN to process telecom data, while the second stage integrates\ndirectional and geographic insights for accurate prediction. Our experiments\ndemonstrate the framework's compatibility with various STGNN models and confirm\nits effectiveness. We also show how to incorporate the framework into\nreal-world transportation systems, enhancing sustainable urban mobility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 Figures, 5 Tables. Just accepted by IJCAI (to appear)",
    "pdf_url": "http://arxiv.org/pdf/2405.17507v1",
    "published_date": "2024-05-26 17:14:50 UTC",
    "updated_date": "2024-05-26 17:14:50 UTC"
  },
  {
    "arxiv_id": "2405.16630v1",
    "title": "Bayesian Inference with Deep Weakly Nonlinear Networks",
    "authors": [
      "Boris Hanin",
      "Alexander Zlokapa"
    ],
    "abstract": "We show at a physics level of rigor that Bayesian inference with a fully\nconnected neural network and a shaped nonlinearity of the form $\\phi(t) = t +\n\\psi t^3/L$ is (perturbatively) solvable in the regime where the number of\ntraining datapoints $P$ , the input dimension $N_0$, the network layer widths\n$N$, and the network depth $L$ are simultaneously large. Our results hold with\nweak assumptions on the data; the main constraint is that $P < N_0$. We provide\ntechniques to compute the model evidence and posterior to arbitrary order in\n$1/N$ and at arbitrary temperature. We report the following results from the\nfirst-order computation:\n  1. When the width $N$ is much larger than the depth $L$ and training set size\n$P$, neural network Bayesian inference coincides with Bayesian inference using\na kernel. The value of $\\psi$ determines the curvature of a sphere, hyperbola,\nor plane into which the training data is implicitly embedded under the feature\nmap.\n  2. When $LP/N$ is a small constant, neural network Bayesian inference departs\nfrom the kernel regime. At zero temperature, neural network Bayesian inference\nis equivalent to Bayesian inference using a data-dependent kernel, and $LP/N$\nserves as an effective depth that controls the extent of feature learning.\n  3. In the restricted case of deep linear networks ($\\psi=0$) and noisy data,\nwe show a simple data model for which evidence and generalization error are\noptimal at zero temperature. As $LP/N$ increases, both evidence and\ngeneralization further improve, demonstrating the benefit of depth in benign\noverfitting.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.PR",
      "physics.data-an"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16630v1",
    "published_date": "2024-05-26 17:08:04 UTC",
    "updated_date": "2024-05-26 17:08:04 UTC"
  },
  {
    "arxiv_id": "2405.16610v1",
    "title": "The devil is in discretization discrepancy. Robustifying Differentiable NAS with Single-Stage Searching Protocol",
    "authors": [
      "Konstanty Subbotko",
      "Wojciech Jablonski",
      "Piotr Bilinski"
    ],
    "abstract": "Neural Architecture Search (NAS) has been widely adopted to design neural\nnetworks for various computer vision tasks. One of its most promising\nsubdomains is differentiable NAS (DNAS), where the optimal architecture is\nfound in a differentiable manner. However, gradient-based methods suffer from\nthe discretization error, which can severely damage the process of obtaining\nthe final architecture. In our work, we first study the risk of discretization\nerror and show how it affects an unregularized supernet. Then, we present that\npenalizing high entropy, a common technique of architecture regularization, can\nhinder the supernet's performance. Therefore, to robustify the DNAS framework,\nwe introduce a novel single-stage searching protocol, which is not reliant on\ndecoding a continuous architecture. Our results demonstrate that this approach\noutperforms other DNAS methods by achieving 75.3% in the searching stage on the\nCityscapes validation dataset and attains performance 1.1% higher than the\noptimal network of DCNAS on the non-dense search space comprising short\nconnections. The entire training process takes only 5.5 GPU days due to the\nweight reuse, and yields a computationally efficient architecture.\nAdditionally, we propose a new dataset split procedure, which substantially\nimproves results and prevents architecture degeneration in DARTS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in CVPR-NAS 2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2405.16610v1",
    "published_date": "2024-05-26 15:44:53 UTC",
    "updated_date": "2024-05-26 15:44:53 UTC"
  },
  {
    "arxiv_id": "2405.16604v1",
    "title": "Intelligence as Computation",
    "authors": [
      "Oliver Brock"
    ],
    "abstract": "This paper proposes a specific conceptualization of intelligence as\ncomputation. This conceptualization is intended to provide a unified view for\nall disciplines of intelligence research. Already, it unifies several\nconceptualizations currently under investigation, including physical, neural,\nembodied, morphological, and mechanical intelligences. To achieve this, the\nproposed conceptualization explains the differences among existing views by\ndifferent computational paradigms, such as digital, analog, mechanical, or\nmorphological computation. Viewing intelligence as a composition of\ncomputations from different paradigms, the challenges posed by previous\nconceptualizations are resolved. Intelligence is hypothesized as a\nmulti-paradigmatic computation relying on specific computational principles.\nThese principles distinguish intelligence from other, non-intelligent\ncomputations. The proposed conceptualization implies a multi-disciplinary\nresearch agenda that is intended to lead to unified science of intelligence.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "68T01",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 0 figures, submitted for review to a journal",
    "pdf_url": "http://arxiv.org/pdf/2405.16604v1",
    "published_date": "2024-05-26 15:30:34 UTC",
    "updated_date": "2024-05-26 15:30:34 UTC"
  },
  {
    "arxiv_id": "2406.18842v3",
    "title": "The global landscape of academic guidelines for generative AI and Large Language Models",
    "authors": [
      "Junfeng Jiao",
      "Saleh Afroogh",
      "Kevin Chen",
      "David Atkinson",
      "Amit Dhurandhar"
    ],
    "abstract": "The integration of Generative Artificial Intelligence (GAI) and Large\nLanguage Models (LLMs) in academia has spurred a global discourse on their\npotential pedagogical benefits and ethical considerations. Positive reactions\nhighlight some potential, such as collaborative creativity, increased access to\neducation, and empowerment of trainers and trainees. However, negative\nreactions raise concerns about ethical complexities, balancing innovation and\nacademic integrity, unequal access, and misinformation risks. Through a\nsystematic survey and text-mining-based analysis of global and national\ndirectives, insights from independent research, and eighty university-level\nguidelines, this study provides a nuanced understanding of the opportunities\nand challenges posed by GAI and LLMs in education. It emphasizes the importance\nof balanced approaches that harness the benefits of these technologies while\naddressing ethical considerations and ensuring equitable access and educational\noutcomes. The paper concludes with recommendations for fostering responsible\ninnovation and ethical practices to guide the integration of GAI and LLMs in\nacademia.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18842v3",
    "published_date": "2024-05-26 15:28:24 UTC",
    "updated_date": "2025-03-18 16:42:30 UTC"
  },
  {
    "arxiv_id": "2405.16595v1",
    "title": "An Evolutionary Framework for Connect-4 as Test-Bed for Comparison of Advanced Minimax, Q-Learning and MCTS",
    "authors": [
      "Henry Taylor",
      "Leonardo Stella"
    ],
    "abstract": "A major challenge in decision making domains with large state spaces is to\neffectively select actions which maximize utility. In recent years, approaches\nsuch as reinforcement learning (RL) and search algorithms have been successful\nto tackle this issue, despite their differences. RL defines a learning\nframework that an agent explores and interacts with. Search algorithms provide\na formalism to search for a solution. However, it is often difficult to\nevaluate the performances of such approaches in a practical way. Motivated by\nthis problem, we focus on one game domain, i.e., Connect-4, and develop a novel\nevolutionary framework to evaluate three classes of algorithms: RL, Minimax and\nMonte Carlo tree search (MCTS). The contribution of this paper is threefold: i)\nwe implement advanced versions of these algorithms and provide a systematic\ncomparison with their standard counterpart, ii) we develop a novel evaluation\nframework, which we call the Evolutionary Tournament, and iii) we conduct an\nextensive evaluation of the relative performance of each algorithm to compare\nour findings. We evaluate different metrics and show that MCTS achieves the\nbest results in terms of win percentage, whereas Minimax and Q-Learning are\nranked in second and third place, respectively, although the latter is shown to\nbe the fastest to make a decision.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2405.16595v1",
    "published_date": "2024-05-26 15:11:45 UTC",
    "updated_date": "2024-05-26 15:11:45 UTC"
  },
  {
    "arxiv_id": "2405.16588v1",
    "title": "Attaining Human`s Desirable Outcomes in Human-AI Interaction via Structural Causal Games",
    "authors": [
      "Anjie Liu",
      "Jianhong Wang",
      "Haoxuan Li",
      "Xu Chen",
      "Jun Wang",
      "Samuel Kaski",
      "Mengyue Yang"
    ],
    "abstract": "In human-AI interaction, a prominent goal is to attain human`s desirable\noutcome with the assistance of AI agents, which can be ideally delineated as a\nproblem of seeking the optimal Nash Equilibrium that matches the human`s\ndesirable outcome. However, reaching the outcome is usually challenging due to\nthe existence of multiple Nash Equilibria that are related to the assisting\ntask but do not correspond to the human`s desirable outcome. To tackle this\nissue, we employ a theoretical framework called structural causal game (SCG) to\nformalize the human-AI interactive process. Furthermore, we introduce a\nstrategy referred to as pre-policy intervention on the SCG to steer AI agents\ntowards attaining the human`s desirable outcome. In more detail, a pre-policy\nis learned as a generalized intervention to guide the agents` policy selection,\nunder a transparent and interpretable procedure determined by the SCG. To make\nthe framework practical, we propose a reinforcement learning-like algorithm to\nsearch out this pre-policy. The proposed algorithm is tested in both gridworld\nenvironments and realistic dialogue scenarios with large language models,\ndemonstrating its adaptability in a broader class of problems and potential\neffectiveness in real-world situations.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "38 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.16588v1",
    "published_date": "2024-05-26 14:42:49 UTC",
    "updated_date": "2024-05-26 14:42:49 UTC"
  },
  {
    "arxiv_id": "2405.16587v2",
    "title": "Cost-Effective Online Multi-LLM Selection with Versatile Reward Models",
    "authors": [
      "Xiangxiang Dai",
      "Jin Li",
      "Xutong Liu",
      "Anqi Yu",
      "John C. S. Lui"
    ],
    "abstract": "With the rapid advancement of large language models (LLMs), the diversity of\nmulti-LLM tasks and the variability in their pricing structures have become\nincreasingly important, as costs can vary greatly between different LLMs. To\ntackle these challenges, we introduce the \\textit{C2MAB-V}, a\n\\underline{C}ost-effective \\underline{C}ombinatorial \\underline{M}ulti-armed\n\\underline{B}andit with \\underline{V}ersatile reward models for optimal LLM\nselection and usage. This online model differs from traditional static\napproaches or those reliant on a single LLM without cost consideration. With\nmultiple LLMs deployed on a scheduling cloud and a local server dedicated to\nhandling user queries, \\textit{C2MAB-V} facilitates the selection of multiple\nLLMs over a combinatorial search space, specifically tailored for various\ncollaborative task types with different reward models. Based on our designed\nonline feedback mechanism and confidence bound technique, \\textit{C2MAB-V} can\neffectively address the multi-LLM selection challenge by managing the\nexploration-exploitation trade-off across different models, while also\nbalancing cost and reward for diverse tasks. The NP-hard integer linear\nprogramming problem for selecting multiple LLMs with trade-off dilemmas is\naddressed by: i) decomposing the integer problem into a relaxed form by the\nlocal server, ii) utilizing a discretization rounding scheme that provides\noptimal LLM combinations by the scheduling cloud, and iii) continual online\nupdates based on feedback. Theoretically, we prove that \\textit{C2MAB-V} offers\nstrict guarantees over versatile reward models, matching state-of-the-art\nresults for regret and violations in some degenerate cases. Empirically, we\nshow that \\textit{C2MAB-V} effectively balances performance and cost-efficiency\nwith nine LLMs for three application scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 14 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2405.16587v2",
    "published_date": "2024-05-26 14:38:24 UTC",
    "updated_date": "2024-10-02 13:22:27 UTC"
  },
  {
    "arxiv_id": "2405.16585v1",
    "title": "Fair Federated Learning under Domain Skew with Local Consistency and Domain Diversity",
    "authors": [
      "Yuhang Chen",
      "Wenke Huang",
      "Mang Ye"
    ],
    "abstract": "Federated learning (FL) has emerged as a new paradigm for privacy-preserving\ncollaborative training. Under domain skew, the current FL approaches are biased\nand face two fairness problems. 1) Parameter Update Conflict: data disparity\namong clients leads to varying parameter importance and inconsistent update\ndirections. These two disparities cause important parameters to potentially be\noverwhelmed by unimportant ones of dominant updates. It consequently results in\nsignificant performance decreases for lower-performing clients. 2) Model\nAggregation Bias: existing FL approaches introduce unfair weight allocation and\nneglect domain diversity. It leads to biased model convergence objective and\ndistinct performance among domains. We discover a pronounced directional update\nconsistency in Federated Learning and propose a novel framework to tackle above\nissues. First, leveraging the discovered characteristic, we selectively discard\nunimportant parameter updates to prevent updates from clients with lower\nperformance overwhelmed by unimportant parameters, resulting in fairer\ngeneralization performance. Second, we propose a fair aggregation objective to\nprevent global model bias towards some domains, ensuring that the global model\ncontinuously aligns with an unbiased model. The proposed method is generic and\ncan be combined with other existing FL methods to enhance fairness.\nComprehensive experiments on Digits and Office-Caltech demonstrate the high\nfairness and performance of our method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CVPR2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16585v1",
    "published_date": "2024-05-26 14:29:10 UTC",
    "updated_date": "2024-05-26 14:29:10 UTC"
  },
  {
    "arxiv_id": "2405.16570v2",
    "title": "ID-to-3D: Expressive ID-guided 3D Heads via Score Distillation Sampling",
    "authors": [
      "Francesca Babiloni",
      "Alexandros Lattas",
      "Jiankang Deng",
      "Stefanos Zafeiriou"
    ],
    "abstract": "We propose ID-to-3D, a method to generate identity- and text-guided 3D human\nheads with disentangled expressions, starting from even a single casually\ncaptured in-the-wild image of a subject. The foundation of our approach is\nanchored in compositionality, alongside the use of task-specific 2D diffusion\nmodels as priors for optimization. First, we extend a foundational model with a\nlightweight expression-aware and ID-aware architecture, and create 2D priors\nfor geometry and texture generation, via fine-tuning only 0.2% of its available\ntraining parameters. Then, we jointly leverage a neural parametric\nrepresentation for the expressions of each subject and a multi-stage generation\nof highly detailed geometry and albedo texture. This combination of strong face\nidentity embeddings and our neural representation enables accurate\nreconstruction of not only facial features but also accessories and hair and\ncan be meshed to provide render-ready assets for gaming and telepresence. Our\nresults achieve an unprecedented level of identity-consistent and high-quality\ntexture and geometry generation, generalizing to a ``world'' of unseen 3D\nidentities, without relying on large 3D captured datasets of human assets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Explore our 3D results at: https://idto3d.github.io ; fixed broken\n  url to project page",
    "pdf_url": "http://arxiv.org/pdf/2405.16570v2",
    "published_date": "2024-05-26 13:36:45 UTC",
    "updated_date": "2024-05-28 09:36:06 UTC"
  },
  {
    "arxiv_id": "2405.16567v2",
    "title": "Automatic Jailbreaking of the Text-to-Image Generative AI Systems",
    "authors": [
      "Minseon Kim",
      "Hyomin Lee",
      "Boqing Gong",
      "Huishuai Zhang",
      "Sung Ju Hwang"
    ],
    "abstract": "Recent AI systems have shown extremely powerful performance, even surpassing\nhuman performance, on various tasks such as information retrieval, language\ngeneration, and image generation based on large language models (LLMs). At the\nsame time, there are diverse safety risks that can cause the generation of\nmalicious contents by circumventing the alignment in LLMs, which are often\nreferred to as jailbreaking. However, most of the previous works only focused\non the text-based jailbreaking in LLMs, and the jailbreaking of the\ntext-to-image (T2I) generation system has been relatively overlooked. In this\npaper, we first evaluate the safety of the commercial T2I generation systems,\nsuch as ChatGPT, Copilot, and Gemini, on copyright infringement with naive\nprompts. From this empirical study, we find that Copilot and Gemini block only\n12% and 17% of the attacks with naive prompts, respectively, while ChatGPT\nblocks 84% of them. Then, we further propose a stronger automated jailbreaking\npipeline for T2I generation systems, which produces prompts that bypass their\nsafety guards. Our automated jailbreaking framework leverages an LLM optimizer\nto generate prompts to maximize degree of violation from the generated images\nwithout any weight updates or gradient computation. Surprisingly, our simple\nyet effective approach successfully jailbreaks the ChatGPT with 11.0% block\nrate, making it generate copyrighted contents in 76% of the time. Finally, we\nexplore various defense strategies, such as post-generation filtering and\nmachine unlearning techniques, but found that they were inadequate, which\nsuggests the necessity of stronger defense mechanisms.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2405.16567v2",
    "published_date": "2024-05-26 13:32:24 UTC",
    "updated_date": "2024-05-28 06:37:00 UTC"
  },
  {
    "arxiv_id": "2405.16557v1",
    "title": "Scalable Numerical Embeddings for Multivariate Time Series: Enhancing Healthcare Data Representation Learning",
    "authors": [
      "Chun-Kai Huang",
      "Yi-Hsien Hsieh",
      "Ta-Jung Chien",
      "Li-Cheng Chien",
      "Shao-Hua Sun",
      "Tung-Hung Su",
      "Jia-Horng Kao",
      "Che Lin"
    ],
    "abstract": "Multivariate time series (MTS) data, when sampled irregularly and\nasynchronously, often present extensive missing values. Conventional\nmethodologies for MTS analysis tend to rely on temporal embeddings based on\ntimestamps that necessitate subsequent imputations, yet these imputed values\nfrequently deviate substantially from their actual counterparts, thereby\ncompromising prediction accuracy. Furthermore, these methods typically fail to\nprovide robust initial embeddings for values infrequently observed or even\nabsent within the training set, posing significant challenges to model\ngeneralizability. In response to these challenges, we propose SCAlable\nNumerical Embedding (SCANE), a novel framework that treats each feature value\nas an independent token, effectively bypassing the need for imputation. SCANE\nregularizes the traits of distinct feature embeddings and enhances\nrepresentational learning through a scalable embedding mechanism. Coupling\nSCANE with the Transformer Encoder architecture, we develop the Scalable\nnUMerical eMbeddIng Transformer (SUMMIT), which is engineered to deliver\nprecise predictive outputs for MTS characterized by prevalent missing entries.\nOur experimental validation, conducted across three disparate electronic health\nrecord (EHR) datasets marked by elevated missing value frequencies, confirms\nthe superior performance of SUMMIT over contemporary state-of-the-art\napproaches addressing similar challenges. These results substantiate the\nefficacy of SCANE and SUMMIT, underscoring their potential applicability across\na broad spectrum of MTS data analytical tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16557v1",
    "published_date": "2024-05-26 13:06:45 UTC",
    "updated_date": "2024-05-26 13:06:45 UTC"
  },
  {
    "arxiv_id": "2405.16552v1",
    "title": "SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation",
    "authors": [
      "Ziqin Luo",
      "Haixia Han",
      "Haokun Zhao",
      "Guochao Jiang",
      "Chengyu Du",
      "Tingyun Li",
      "Jiaqing Liang",
      "Deqing Yang",
      "Yanghua Xiao"
    ],
    "abstract": "Existing Large Language Models (LLMs) generate text through unidirectional\nautoregressive decoding methods to respond to various user queries. These\nmethods tend to consider token selection in a simple sequential manner, making\nit easy to fall into suboptimal options when encountering uncertain tokens,\nreferred to as chaotic points in our work. Many chaotic points exist in texts\ngenerated by LLMs, and they often significantly affect the quality of\nsubsequently generated tokens, which can interfere with LLMs' generation. This\npaper proposes Self-Evaluation Decoding, SED, a decoding method for enhancing\nmodel generation. Analogous to the human decision-making process, SED\nintegrates speculation and evaluation steps into the decoding process, allowing\nLLMs to make more careful decisions and thus optimize token selection at\nchaotic points. Experimental results across various tasks using different LLMs\ndemonstrate SED's effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The relevant code will be released in subsequent versions",
    "pdf_url": "http://arxiv.org/pdf/2405.16552v1",
    "published_date": "2024-05-26 12:43:18 UTC",
    "updated_date": "2024-05-26 12:43:18 UTC"
  },
  {
    "arxiv_id": "2405.16550v1",
    "title": "ReCODE: Modeling Repeat Consumption with Neural ODE",
    "authors": [
      "Sunhao Dai",
      "Changle Qu",
      "Sirui Chen",
      "Xiao Zhang",
      "Jun Xu"
    ],
    "abstract": "In real-world recommender systems, such as in the music domain, repeat\nconsumption is a common phenomenon where users frequently listen to a small set\nof preferred songs or artists repeatedly. The key point of modeling repeat\nconsumption is capturing the temporal patterns between a user's repeated\nconsumption of the items. Existing studies often rely on heuristic assumptions,\nsuch as assuming an exponential distribution for the temporal gaps. However,\ndue to the high complexity of real-world recommender systems, these pre-defined\ndistributions may fail to capture the intricate dynamic user consumption\npatterns, leading to sub-optimal performance. Drawing inspiration from the\nflexibility of neural ordinary differential equations (ODE) in capturing the\ndynamics of complex systems, we propose ReCODE, a novel model-agnostic\nframework that utilizes neural ODE to model repeat consumption. ReCODE\ncomprises two essential components: a user's static preference prediction\nmodule and the modeling of user dynamic repeat intention. By considering both\nimmediate choices and historical consumption patterns, ReCODE offers\ncomprehensive modeling of user preferences in the target context. Moreover,\nReCODE seamlessly integrates with various existing recommendation models,\nincluding collaborative-based and sequential-based models, making it easily\napplicable in different scenarios. Experimental results on two real-world\ndatasets consistently demonstrate that ReCODE significantly improves the\nperformance of base models and outperforms other baseline methods.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by SIGIR 2024 (Short Paper)",
    "pdf_url": "http://arxiv.org/pdf/2405.16550v1",
    "published_date": "2024-05-26 12:40:23 UTC",
    "updated_date": "2024-05-26 12:40:23 UTC"
  },
  {
    "arxiv_id": "2405.16542v1",
    "title": "Mamba4KT:An Efficient and Effective Mamba-based Knowledge Tracing Model",
    "authors": [
      "Yang Cao",
      "Wei Zhang"
    ],
    "abstract": "Knowledge tracing (KT) enhances student learning by leveraging past\nperformance to predict future performance. Current research utilizes models\nbased on attention mechanisms and recurrent neural network structures to\ncapture long-term dependencies and correlations between exercises, aiming to\nimprove model accuracy. Due to the growing amount of data in smart education\nscenarios, this poses a challenge in terms of time and space consumption for\nknowledge tracing models. However, existing research often overlooks the\nefficiency of model training and inference and the constraints of training\nresources. Recognizing the significance of prioritizing model efficiency and\nresource usage in knowledge tracing, we introduce Mamba4KT. This novel model is\nthe first to explore enhanced efficiency and resource utilization in knowledge\ntracing. We also examine the interpretability of the Mamba structure both\nsequence-level and exercise-level to enhance model interpretability.\nExperimental findings across three public datasets demonstrate that Mamba4KT\nachieves comparable prediction accuracy to state-of-the-art models while\nsignificantly improving training and inference efficiency and resource\nutilization. As educational data continues to grow, our work suggests a\npromising research direction for knowledge tracing that improves model\nprediction accuracy, model efficiency, resource utilization, and\ninterpretability simultaneously.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16542v1",
    "published_date": "2024-05-26 12:26:03 UTC",
    "updated_date": "2024-05-26 12:26:03 UTC"
  },
  {
    "arxiv_id": "2405.16538v1",
    "title": "Gamified AI Approch for Early Detection of Dementia",
    "authors": [
      "Paramita Kundu Maji",
      "Soubhik Acharya",
      "Priti Paul",
      "Sanjay Chakraborty",
      "Saikat Basu"
    ],
    "abstract": "This paper aims to develop a new deep learning-inspired gaming approach for\nearly detection of dementia. This research integrates a robust convolutional\nneural network (CNN)-based model for early dementia detection using health\nmetrics data as well as facial image data through a cognitive assessment-based\ngaming application. We have collected 1000 data samples of health metrics\ndataset from Apollo Diagnostic Center Kolkata that is labeled as either\ndemented or non-demented for the training of MOD-1D-CNN for the game level 1\nand another dataset of facial images containing 1800 facial data that are\nlabeled as either demented or non-demented is collected by our research team\nfor the training of MOD-2D-CNN model in-game level 2. In our work, the loss for\nthe proposed MOD-1D-CNN model is 0.2692 and the highest accuracy is 70.50% for\nidentifying the dementia traits using real-life health metrics data. Similarly,\nthe proposed MOD-2D-CNN model loss is 0.1755 and the highest accuracy is\nobtained here 95.72% for recognizing the dementia status using real-life\nface-based image data. Therefore, a rule-based weightage method is applied to\ncombine both the proposed methods to achieve the final decision. The MOD-1D-CNN\nand MOD-2D-CNN models are more lightweight and computationally efficient\nalternatives because they have a significantly lower number of parameters when\ncompared to the other state-of-the-art models. We have compared their\naccuracies and parameters with the other state-of-the-art deep learning models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "50 Pages, 29 Figures",
    "pdf_url": "http://arxiv.org/pdf/2405.16538v1",
    "published_date": "2024-05-26 12:01:30 UTC",
    "updated_date": "2024-05-26 12:01:30 UTC"
  },
  {
    "arxiv_id": "2407.11977v1",
    "title": "Building Better AI Agents: A Provocation on the Utilisation of Persona in LLM-based Conversational Agents",
    "authors": [
      "Guangzhi Sun",
      "Xiao Zhan",
      "Jose Such"
    ],
    "abstract": "The incorporation of Large Language Models (LLMs) such as the GPT series into\ndiverse sectors including healthcare, education, and finance marks a\nsignificant evolution in the field of artificial intelligence (AI). The\nincreasing demand for personalised applications motivated the design of\nconversational agents (CAs) to possess distinct personas. This paper commences\nby examining the rationale and implications of imbuing CAs with unique\npersonas, smoothly transitioning into a broader discussion of the\npersonalisation and anthropomorphism of CAs based on LLMs in the LLM era. We\ndelve into the specific applications where the implementation of a persona is\nnot just beneficial but critical for LLM-based CAs. The paper underscores the\nnecessity of a nuanced approach to persona integration, highlighting the\npotential challenges and ethical dilemmas that may arise. Attention is directed\ntowards the importance of maintaining persona consistency, establishing robust\nevaluation mechanisms, and ensuring that the persona attributes are effectively\ncomplemented by domain-specific knowledge.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by The international ACM Conversational User Interfaces\n  (CUI) conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11977v1",
    "published_date": "2024-05-26 11:36:48 UTC",
    "updated_date": "2024-05-26 11:36:48 UTC"
  },
  {
    "arxiv_id": "2405.16522v4",
    "title": "Multi-State TD Target for Model-Free Reinforcement Learning",
    "authors": [
      "Wuhao Wang",
      "Zhiyong Chen",
      "Lepeng Zhang"
    ],
    "abstract": "Temporal difference (TD) learning is a fundamental technique in reinforcement\nlearning that updates value estimates for states or state-action pairs using a\nTD target. This target represents an improved estimate of the true value by\nincorporating both immediate rewards and the estimated value of subsequent\nstates. Traditionally, TD learning relies on the value of a single subsequent\nstate. We propose an enhanced multi-state TD (MSTD) target that utilizes the\nestimated values of multiple subsequent states. Building on this new MSTD\nconcept, we develop complete actor-critic algorithms that include management of\nreplay buffers in two modes, and integrate with deep deterministic policy\noptimization (DDPG) and soft actor-critic (SAC). Experimental results\ndemonstrate that algorithms employing the MSTD target significantly improve\nlearning performance compared to traditional methods.The code is provided on\nGitHub.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05(Primary)"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.16522v4",
    "published_date": "2024-05-26 11:17:49 UTC",
    "updated_date": "2024-08-02 00:21:41 UTC"
  },
  {
    "arxiv_id": "2405.16511v1",
    "title": "SE3Set: Harnessing equivariant hypergraph neural networks for molecular representation learning",
    "authors": [
      "Hongfei Wu",
      "Lijun Wu",
      "Guoqing Liu",
      "Zhirong Liu",
      "Bin Shao",
      "Zun Wang"
    ],
    "abstract": "In this paper, we develop SE3Set, an SE(3) equivariant hypergraph neural\nnetwork architecture tailored for advanced molecular representation learning.\nHypergraphs are not merely an extension of traditional graphs; they are pivotal\nfor modeling high-order relationships, a capability that conventional\nequivariant graph-based methods lack due to their inherent limitations in\nrepresenting intricate many-body interactions. To achieve this, we first\nconstruct hypergraphs via proposing a new fragmentation method that considers\nboth chemical and three-dimensional spatial information of molecular system. We\nthen design SE3Set, which incorporates equivariance into the hypergragh neural\nnetwork. This ensures that the learned molecular representations are invariant\nto spatial transformations, thereby providing robustness essential for accurate\nprediction of molecular properties. SE3Set has shown performance on par with\nstate-of-the-art (SOTA) models for small molecule datasets like QM9 and MD17.\nIt excels on the MD22 dataset, achieving a notable improvement of approximately\n20% in accuracy across all molecules, which highlights the prevalence of\ncomplex many-body interactions in larger molecules. This exceptional\nperformance of SE3Set across diverse molecular structures underscores its\ntransformative potential in computational chemistry, offering a route to more\naccurate and physically nuanced modeling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16511v1",
    "published_date": "2024-05-26 10:43:16 UTC",
    "updated_date": "2024-05-26 10:43:16 UTC"
  },
  {
    "arxiv_id": "2405.16510v4",
    "title": "Planning with Multi-Constraints via Collaborative Language Agents",
    "authors": [
      "Cong Zhang",
      "Derrick Goh Xin Deik",
      "Dexun Li",
      "Hao Zhang",
      "Yong Liu"
    ],
    "abstract": "The rapid advancement of neural language models has sparked a new surge of\nintelligent agent research. Unlike traditional agents, large language\nmodel-based agents (LLM agents) have emerged as a promising paradigm for\nachieving artificial general intelligence (AGI) due to their superior reasoning\nand generalization capabilities. Effective planning is crucial for the success\nof LLM agents in real-world tasks, making it a highly pursued topic in the\ncommunity. Current planning methods typically translate tasks into executable\naction sequences. However, determining a feasible or optimal sequence for\ncomplex tasks with multiple constraints at fine granularity, which often\nrequires compositing long chains of heterogeneous actions, remains challenging.\nThis paper introduces Planning with Multi-Constraints (PMC), a zero-shot\nmethodology for collaborative LLM-based multi-agent systems that simplifies\ncomplex task planning with constraints by decomposing it into a hierarchy of\nsubordinate tasks. Each subtask is then mapped into executable actions. PMC was\nassessed on two constraint-intensive benchmarks, TravelPlanner and API-Bank.\nNotably, PMC achieved an average 42.68% success rate on TravelPlanner,\nsignificantly higher than GPT-4 (2.92%), and outperforming GPT-4 with ReAct on\nAPI-Bank by 13.64%, showing the immense potential of integrating LLM with\nmulti-agent systems. We also show that PMC works with small LLM as the planning\ncore, e.g., LLaMA-3.1-8B.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16510v4",
    "published_date": "2024-05-26 10:33:17 UTC",
    "updated_date": "2024-12-16 02:27:55 UTC"
  },
  {
    "arxiv_id": "2405.16507v6",
    "title": "Causal Concept Graph Models: Beyond Causal Opacity in Deep Learning",
    "authors": [
      "Gabriele Dominici",
      "Pietro Barbiero",
      "Mateo Espinosa Zarlenga",
      "Alberto Termine",
      "Martin Gjoreski",
      "Giuseppe Marra",
      "Marc Langheinrich"
    ],
    "abstract": "Causal opacity denotes the difficulty in understanding the \"hidden\" causal\nstructure underlying the decisions of deep neural network (DNN) models. This\nleads to the inability to rely on and verify state-of-the-art DNN-based\nsystems, especially in high-stakes scenarios. For this reason, circumventing\ncausal opacity in DNNs represents a key open challenge at the intersection of\ndeep learning, interpretability, and causality. This work addresses this gap by\nintroducing Causal Concept Graph Models (Causal CGMs), a class of interpretable\nmodels whose decision-making process is causally transparent by design. Our\nexperiments show that Causal CGMs can: (i) match the generalisation performance\nof causally opaque models, (ii) enable human-in-the-loop corrections to\nmispredicted intermediate reasoning steps, boosting not just downstream\naccuracy after corrections but also the reliability of the explanations\nprovided for specific instances, and (iii) support the analysis of\ninterventional and counterfactual scenarios, thereby improving the model's\ncausal interpretability and supporting the effective verification of its\nreliability and fairness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16507v6",
    "published_date": "2024-05-26 10:15:20 UTC",
    "updated_date": "2025-04-01 10:47:14 UTC"
  },
  {
    "arxiv_id": "2405.16496v2",
    "title": "Exploring a Multimodal Fusion-based Deep Learning Network for Detecting Facial Palsy",
    "authors": [
      "Heng Yim Nicole Oo",
      "Min Hun Lee",
      "Jeong Hoon Lim"
    ],
    "abstract": "Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessment by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes unstructured data (i.e. an image frame with facial line\nsegments) and structured data (i.e. features of facial expressions) to detect\nfacial palsy. We then contribute to a study to analyze the effect of different\ndata modalities and the benefits of a multimodal fusion-based approach using\nvideos of 21 facial palsy patients. Our experimental results show that among\nvarious data modalities (i.e. unstructured data - RGB images and images of\nfacial line segments and structured data - coordinates of facial landmarks and\nfeatures of facial expressions), the feed-forward neural network using features\nof facial expression achieved the highest precision of 76.22 while the\nResNet-based model using images of facial line segments achieved the highest\nrecall of 83.47. When we leveraged both images of facial line segments and\nfeatures of facial expressions, our multimodal fusion-based deep learning model\nslightly improved the precision score to 77.05 at the expense of a decrease in\nthe recall score.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "IJCAI 2024 4th AI for Ageless Aging Workshop (AIAA)",
    "pdf_url": "http://arxiv.org/pdf/2405.16496v2",
    "published_date": "2024-05-26 09:16:34 UTC",
    "updated_date": "2025-03-13 13:56:43 UTC"
  },
  {
    "arxiv_id": "2405.16489v2",
    "title": "Causal-aware Graph Neural Architecture Search under Distribution Shifts",
    "authors": [
      "Peiwen Li",
      "Xin Wang",
      "Zeyang Zhang",
      "Yijian Qin",
      "Ziwei Zhang",
      "Jialong Wang",
      "Yang Li",
      "Wenwu Zhu"
    ],
    "abstract": "Graph NAS has emerged as a promising approach for autonomously designing GNN\narchitectures by leveraging the correlations between graphs and architectures.\nExisting methods fail to generalize under distribution shifts that are\nubiquitous in real-world graph scenarios, mainly because the graph-architecture\ncorrelations they exploit might be spurious and varying across distributions.\nWe propose to handle the distribution shifts in the graph architecture search\nprocess by discovering and exploiting the causal relationship between graphs\nand architectures to search for the optimal architectures that can generalize\nunder distribution shifts. The problem remains unexplored with following\nchallenges: how to discover the causal graph-architecture relationship that has\nstable predictive abilities across distributions, and how to handle\ndistribution shifts with the discovered causal graph-architecture relationship\nto search the generalized graph architectures. To address these challenges, we\npropose Causal-aware Graph Neural Architecture Search (CARNAS), which is able\nto capture the causal graph-architecture relationship during the architecture\nsearch process and discover the generalized graph architecture under\ndistribution shifts. Specifically, we propose Disentangled Causal Subgraph\nIdentification to capture the causal subgraphs that have stable prediction\nabilities across distributions. Then, we propose Graph Embedding Intervention\nto intervene on causal subgraphs within the latent space, ensuring that these\nsubgraphs encapsulate essential features for prediction while excluding\nnon-causal elements. Additionally, we propose Invariant Architecture\nCustomization to reinforce the causal invariant nature of the causal subgraphs,\nwhich are utilized to tailor generalized graph architectures. Extensive\nexperiments demonstrate that CARNAS achieves advanced out-of-distribution\ngeneralization ability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16489v2",
    "published_date": "2024-05-26 08:55:22 UTC",
    "updated_date": "2024-12-30 11:28:31 UTC"
  },
  {
    "arxiv_id": "2405.16486v1",
    "title": "Decomposing the Neurons: Activation Sparsity via Mixture of Experts for Continual Test Time Adaptation",
    "authors": [
      "Rongyu Zhang",
      "Aosong Cheng",
      "Yulin Luo",
      "Gaole Dai",
      "Huanrui Yang",
      "Jiaming Liu",
      "Ran Xu",
      "Li Du",
      "Yuan Du",
      "Yanbing Jiang",
      "Shanghang Zhang"
    ],
    "abstract": "Continual Test-Time Adaptation (CTTA), which aims to adapt the pre-trained\nmodel to ever-evolving target domains, emerges as an important task for vision\nmodels. As current vision models appear to be heavily biased towards texture,\ncontinuously adapting the model from one domain distribution to another can\nresult in serious catastrophic forgetting. Drawing inspiration from the human\nvisual system's adeptness at processing both shape and texture according to the\nfamous Trichromatic Theory, we explore the integration of a\nMixture-of-Activation-Sparsity-Experts (MoASE) as an adapter for the CTTA task.\nGiven the distinct reaction of neurons with low/high activation to\ndomain-specific/agnostic features, MoASE decomposes the neural activation into\nhigh-activation and low-activation components with a non-differentiable Spatial\nDifferentiate Dropout (SDD). Based on the decomposition, we devise a multi-gate\nstructure comprising a Domain-Aware Gate (DAG) that utilizes domain information\nto adaptive combine experts that process the post-SDD sparse activations of\ndifferent strengths, and the Activation Sparsity Gate (ASG) that adaptively\nassigned feature selection threshold of the SDD for different experts for more\nprecise feature decomposition. Finally, we introduce a Homeostatic-Proximal\n(HP) loss to bypass the error accumulation problem when continuously adapting\nthe model. Extensive experiments on four prominent benchmarks substantiate that\nour methodology achieves state-of-the-art performance in both classification\nand segmentation CTTA tasks. Our code is now available at\nhttps://github.com/RoyZry98/MoASE-Pytorch.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16486v1",
    "published_date": "2024-05-26 08:51:39 UTC",
    "updated_date": "2024-05-26 08:51:39 UTC"
  },
  {
    "arxiv_id": "2405.16478v1",
    "title": "Vision-Based Approach for Food Weight Estimation from 2D Images",
    "authors": [
      "Chathura Wimalasiri",
      "Prasan Kumar Sahoo"
    ],
    "abstract": "In response to the increasing demand for efficient and non-invasive methods\nto estimate food weight, this paper presents a vision-based approach utilizing\n2D images. The study employs a dataset of 2380 images comprising fourteen\ndifferent food types in various portions, orientations, and containers. The\nproposed methodology integrates deep learning and computer vision techniques,\nspecifically employing Faster R-CNN for food detection and MobileNetV3 for\nweight estimation. The detection model achieved a mean average precision (mAP)\nof 83.41\\%, an average Intersection over Union (IoU) of 91.82\\%, and a\nclassification accuracy of 100\\%. For weight estimation, the model demonstrated\na root mean squared error (RMSE) of 6.3204, a mean absolute percentage error\n(MAPE) of 0.0640\\%, and an R-squared value of 98.65\\%. The study underscores\nthe potential applications of this technology in healthcare for nutrition\ncounseling, fitness and wellness for dietary intake assessment, and smart food\nstorage solutions to reduce waste. The results indicate that the combination of\nFaster R-CNN and MobileNetV3 provides a robust framework for accurate food\nweight estimation from 2D images, showcasing the synergy of computer vision and\ndeep learning in practical applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Six pages, Six figures, The final version of this paper is published\n  in IEEE Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.16478v1",
    "published_date": "2024-05-26 08:03:51 UTC",
    "updated_date": "2024-05-26 08:03:51 UTC"
  },
  {
    "arxiv_id": "2405.16475v3",
    "title": "Looks Too Good To Be True: An Information-Theoretic Analysis of Hallucinations in Generative Restoration Models",
    "authors": [
      "Regev Cohen",
      "Idan Kligvasser",
      "Ehud Rivlin",
      "Daniel Freedman"
    ],
    "abstract": "The pursuit of high perceptual quality in image restoration has driven the\ndevelopment of revolutionary generative models, capable of producing results\noften visually indistinguishable from real data. However, as their perceptual\nquality continues to improve, these models also exhibit a growing tendency to\ngenerate hallucinations - realistic-looking details that do not exist in the\nground truth images. Hallucinations in these models create uncertainty about\ntheir reliability, raising major concerns about their practical application.\nThis paper investigates this phenomenon through the lens of information theory,\nrevealing a fundamental tradeoff between uncertainty and perception. We\nrigorously analyze the relationship between these two factors, proving that the\nglobal minimal uncertainty in generative models grows in tandem with\nperception. In particular, we define the inherent uncertainty of the\nrestoration problem and show that attaining perfect perceptual quality entails\nat least twice this uncertainty. Additionally, we establish a relation between\ndistortion, uncertainty and perception, through which we prove the\naforementioned uncertainly-perception tradeoff induces the well-known\nperception-distortion tradeoff. We demonstrate our theoretical findings through\nexperiments with super-resolution and inpainting algorithms. This work uncovers\nfundamental limitations of generative models in achieving both high perceptual\nquality and reliable predictions for image restoration. Thus, we aim to raise\nawareness among practitioners about this inherent tradeoff, empowering them to\nmake informed decisions and potentially prioritize safety over perceptual\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16475v3",
    "published_date": "2024-05-26 07:58:51 UTC",
    "updated_date": "2024-10-25 19:40:30 UTC"
  },
  {
    "arxiv_id": "2405.16473v1",
    "title": "M$^3$CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought",
    "authors": [
      "Qiguang Chen",
      "Libo Qin",
      "Jin Zhang",
      "Zhi Chen",
      "Xiao Xu",
      "Wanxiang Che"
    ],
    "abstract": "Multi-modal Chain-of-Thought (MCoT) requires models to leverage knowledge\nfrom both textual and visual modalities for step-by-step reasoning, which gains\nincreasing attention. Nevertheless, the current MCoT benchmark still faces some\nchallenges: (1) absence of visual modal reasoning, (2) single-step visual modal\nreasoning, and (3) Domain missing, thereby hindering the development of MCoT.\nMotivated by this, we introduce a novel benchmark (M$^3$CoT) to address the\nabove challenges, advancing the multi-domain, multi-step, and multi-modal CoT.\nAdditionally, we conduct a thorough evaluation involving abundant MCoT\napproaches on Vision Large Language Models (VLLMs). In addition, we highlight\nthat the current VLLMs still struggle to correctly reason in M$^3$CoT and there\nremains a large gap between existing VLLMs and human performance in M$^3$CoT,\ndespite their superior results on previous MCoT benchmarks. To our knowledge,\nwe take the first meaningful step toward the multi-domain, multi-step, and\nmulti-modal scenario in MCoT. We hope that M$^3$CoT can serve as a valuable\nresource, providing a pioneering foundation in multi-domain, multi-step,\nmulti-modal chain-of-thought research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ACL2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.16473v1",
    "published_date": "2024-05-26 07:56:30 UTC",
    "updated_date": "2024-05-26 07:56:30 UTC"
  },
  {
    "arxiv_id": "2405.16460v1",
    "title": "Probabilistic Contrastive Learning with Explicit Concentration on the Hypersphere",
    "authors": [
      "Hongwei Bran Li",
      "Cheng Ouyang",
      "Tamaz Amiranashvili",
      "Matthew S. Rosen",
      "Bjoern Menze",
      "Juan Eugenio Iglesias"
    ],
    "abstract": "Self-supervised contrastive learning has predominantly adopted deterministic\nmethods, which are not suited for environments characterized by uncertainty and\nnoise. This paper introduces a new perspective on incorporating uncertainty\ninto contrastive learning by embedding representations within a spherical\nspace, inspired by the von Mises-Fisher distribution (vMF). We introduce an\nunnormalized form of vMF and leverage the concentration parameter, kappa, as a\ndirect, interpretable measure to quantify uncertainty explicitly. This approach\nnot only provides a probabilistic interpretation of the embedding space but\nalso offers a method to calibrate model confidence against varying levels of\ndata corruption and characteristics. Our empirical results demonstrate that the\nestimated concentration parameter correlates strongly with the degree of\nunforeseen data corruption encountered at test time, enables failure analysis,\nand enhances existing out-of-distribution detection methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "technical report",
    "pdf_url": "http://arxiv.org/pdf/2405.16460v1",
    "published_date": "2024-05-26 07:08:13 UTC",
    "updated_date": "2024-05-26 07:08:13 UTC"
  },
  {
    "arxiv_id": "2405.16456v1",
    "title": "Dominant Shuffle: A Simple Yet Powerful Data Augmentation for Time-series Prediction",
    "authors": [
      "Kai Zhao",
      "Zuojie He",
      "Alex Hung",
      "Dan Zeng"
    ],
    "abstract": "Recent studies have suggested frequency-domain Data augmentation (DA) is\neffec tive for time series prediction. Existing frequency-domain augmentations\ndisturb the original data with various full-spectrum noises, leading to excess\ndomain gap between augmented and original data. Although impressive performance\nhas been achieved in certain cases, frequency-domain DA has yet to be\ngeneralized to time series prediction datasets. In this paper, we found that\nfrequency-domain augmentations can be significantly improved by two\nmodifications that limit the perturbations. First, we found that limiting the\nperturbation to only dominant frequencies significantly outperforms\nfull-spectrum perturbations. Dominant fre quencies represent the main\nperiodicity and trends of the signal and are more important than other\nfrequencies. Second, we found that simply shuffling the dominant frequency\ncomponents is superior over sophisticated designed random perturbations.\nShuffle rearranges the original components (magnitudes and phases) and limits\nthe external noise. With these two modifications, we proposed dominant shuffle,\na simple yet effective data augmentation for time series prediction. Our method\nis very simple yet powerful and can be implemented with just a few lines of\ncode. Extensive experiments with eight datasets and six popular time series\nmodels demonstrate that our method consistently improves the baseline\nperformance under various settings and significantly outperforms other DA\nmethods. Code can be accessed at https://kaizhao.net/time-series.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "https://kaizhao.net/time-series",
    "pdf_url": "http://arxiv.org/pdf/2405.16456v1",
    "published_date": "2024-05-26 07:00:12 UTC",
    "updated_date": "2024-05-26 07:00:12 UTC"
  },
  {
    "arxiv_id": "2405.16453v1",
    "title": "A Slices Perspective for Incremental Nonparametric Inference in High Dimensional State Spaces",
    "authors": [
      "Moshe Shienman",
      "Ohad Levy-Or",
      "Michael Kaess",
      "Vadim Indelman"
    ],
    "abstract": "We introduce an innovative method for incremental nonparametric probabilistic\ninference in high-dimensional state spaces. Our approach leverages \\slices from\nhigh-dimensional surfaces to efficiently approximate posterior distributions of\nany shape. Unlike many existing graph-based methods, our \\slices perspective\neliminates the need for additional intermediate reconstructions, maintaining a\nmore accurate representation of posterior distributions. Additionally, we\npropose a novel heuristic to balance between accuracy and efficiency, enabling\nreal-time operation in nonparametric scenarios. In empirical evaluations on\nsynthetic and real-world datasets, our \\slices approach consistently\noutperforms other state-of-the-art methods. It demonstrates superior accuracy\nand achieves a significant reduction in computational complexity, often by an\norder of magnitude.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "8 Pages, 7 figures, Submitted to IEEE IROS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16453v1",
    "published_date": "2024-05-26 06:52:56 UTC",
    "updated_date": "2024-05-26 06:52:56 UTC"
  },
  {
    "arxiv_id": "2405.19366v2",
    "title": "ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text",
    "authors": [
      "Han Yu",
      "Peikun Guo",
      "Akane Sano"
    ],
    "abstract": "The utilization of deep learning on electrocardiogram (ECG) analysis has\nbrought the advanced accuracy and efficiency of cardiac healthcare diagnostics.\nBy leveraging the capabilities of deep learning in semantic understanding,\nespecially in feature extraction and representation learning, this study\nintroduces a new multimodal contrastive pretaining framework that aims to\nimprove the quality and robustness of learned representations of 12-lead ECG\nsignals. Our framework comprises two key components, including Cardio Query\nAssistant (CQA) and ECG Semantics Integrator(ESI). CQA integrates a\nretrieval-augmented generation (RAG) pipeline to leverage large language models\n(LLMs) and external medical knowledge to generate detailed textual descriptions\nof ECGs. The generated text is enriched with information about demographics and\nwaveform patterns. ESI integrates both contrastive and captioning loss to\npretrain ECG encoders for enhanced representations. We validate our approach\nthrough various downstream tasks, including arrhythmia detection and ECG-based\nsubject identification. Our experimental results demonstrate substantial\nimprovements over strong baselines in these tasks. These baselines encompass\nsupervised and self-supervised learning methods, as well as prior multimodal\npretraining approaches.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19366v2",
    "published_date": "2024-05-26 06:45:39 UTC",
    "updated_date": "2024-10-23 18:01:50 UTC"
  },
  {
    "arxiv_id": "2405.16450v3",
    "title": "Synthesizing Programmatic Reinforcement Learning Policies with Large Language Model Guided Search",
    "authors": [
      "Max Liu",
      "Chan-Hung Yu",
      "Wei-Hsu Lee",
      "Cheng-Wei Hung",
      "Yen-Chun Chen",
      "Shao-Hua Sun"
    ],
    "abstract": "Programmatic reinforcement learning (PRL) has been explored for representing\npolicies through programs as a means to achieve interpretability and\ngeneralization. Despite promising outcomes, current state-of-the-art PRL\nmethods are hindered by sample inefficiency, necessitating tens of millions of\nprogram-environment interactions. To tackle this challenge, we introduce a\nnovel LLM-guided search framework (LLM-GS). Our key insight is to leverage the\nprogramming expertise and common sense reasoning of LLMs to enhance the\nefficiency of assumption-free, random-guessing search methods. We address the\nchallenge of LLMs' inability to generate precise and grammatically correct\nprograms in domain-specific languages (DSLs) by proposing a Pythonic-DSL\nstrategy - an LLM is instructed to initially generate Python codes and then\nconvert them into DSL programs. To further optimize the LLM-generated programs,\nwe develop a search algorithm named Scheduled Hill Climbing, designed to\nefficiently explore the programmatic search space to improve the programs\nconsistently. Experimental results in the Karel domain demonstrate our LLM-GS\nframework's superior effectiveness and efficiency. Extensive ablation studies\nfurther verify the critical role of our Pythonic-DSL strategy and Scheduled\nHill Climbing algorithm. Moreover, we conduct experiments with two novel tasks,\nshowing that LLM-GS enables users without programming skills and knowledge of\nthe domain or DSL to describe the tasks in natural language to obtain\nperformant programs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16450v3",
    "published_date": "2024-05-26 06:33:48 UTC",
    "updated_date": "2025-03-11 12:52:28 UTC"
  },
  {
    "arxiv_id": "2405.16440v1",
    "title": "MambaTS: Improved Selective State Space Models for Long-term Time Series Forecasting",
    "authors": [
      "Xiuding Cai",
      "Yaoyao Zhu",
      "Xueyao Wang",
      "Yu Yao"
    ],
    "abstract": "In recent years, Transformers have become the de-facto architecture for\nlong-term sequence forecasting (LTSF), but faces challenges such as quadratic\ncomplexity and permutation invariant bias. A recent model, Mamba, based on\nselective state space models (SSMs), has emerged as a competitive alternative\nto Transformer, offering comparable performance with higher throughput and\nlinear complexity related to sequence length. In this study, we analyze the\nlimitations of current Mamba in LTSF and propose four targeted improvements,\nleading to MambaTS. We first introduce variable scan along time to arrange the\nhistorical information of all the variables together. We suggest that causal\nconvolution in Mamba is not necessary for LTSF and propose the Temporal Mamba\nBlock (TMB). We further incorporate a dropout mechanism for selective\nparameters of TMB to mitigate model overfitting. Moreover, we tackle the issue\nof variable scan order sensitivity by introducing variable permutation\ntraining. We further propose variable-aware scan along time to dynamically\ndiscover variable relationships during training and decode the optimal variable\nscan order by solving the shortest path visiting all nodes problem during\ninference. Extensive experiments conducted on eight public datasets demonstrate\nthat MambaTS achieves new state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16440v1",
    "published_date": "2024-05-26 05:50:17 UTC",
    "updated_date": "2024-05-26 05:50:17 UTC"
  },
  {
    "arxiv_id": "2405.16439v3",
    "title": "Multi-Agent Inverse Reinforcement Learning in Real World Unstructured Pedestrian Crowds",
    "authors": [
      "Rohan Chandra",
      "Haresh Karnan",
      "Negar Mehr",
      "Peter Stone",
      "Joydeep Biswas"
    ],
    "abstract": "Social robot navigation in crowded public spaces such as university campuses,\nrestaurants, grocery stores, and hospitals, is an increasingly important area\nof research. One of the core strategies for achieving this goal is to\nunderstand humans' intent--underlying psychological factors that govern their\nmotion--by learning their reward functions, typically via inverse reinforcement\nlearning (IRL). Despite significant progress in IRL, learning reward functions\nof multiple agents simultaneously in dense unstructured pedestrian crowds has\nremained intractable due to the nature of the tightly coupled social\ninteractions that occur in these scenarios \\textit{e.g.} passing,\nintersections, swerving, weaving, etc. In this paper, we present a new\nmulti-agent maximum entropy inverse reinforcement learning algorithm for real\nworld unstructured pedestrian crowds. Key to our approach is a simple, but\neffective, mathematical trick which we name the so-called\ntractability-rationality trade-off trick that achieves tractability at the cost\nof a slight reduction in accuracy. We compare our approach to the classical\nsingle-agent MaxEnt IRL as well as state-of-the-art trajectory prediction\nmethods on several datasets including the ETH, UCY, SCAND, JRDB, and a new\ndataset, called Speedway, collected at a busy intersection on a University\ncampus focusing on dense, complex agent interactions. Our key findings show\nthat, on the dense Speedway dataset, our approach ranks 1st among top 7\nbaselines with >2X improvement over single-agent IRL, and is competitive with\nstate-of-the-art large transformer-based encoder-decoder models on sparser\ndatasets such as ETH/UCY (ranks 3rd among top 7 baselines).",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16439v3",
    "published_date": "2024-05-26 05:48:21 UTC",
    "updated_date": "2025-03-26 21:19:58 UTC"
  },
  {
    "arxiv_id": "2405.16436v3",
    "title": "Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer",
    "authors": [
      "Zhihan Liu",
      "Miao Lu",
      "Shenao Zhang",
      "Boyi Liu",
      "Hongyi Guo",
      "Yingxiang Yang",
      "Jose Blanchet",
      "Zhaoran Wang"
    ],
    "abstract": "Aligning generative models with human preference via RLHF typically suffers\nfrom overoptimization, where an imperfectly learned reward model can misguide\nthe generative model to output undesired responses. We investigate this problem\nin a principled manner by identifying the source of the misalignment as a form\nof distributional shift and uncertainty in learning human preferences. To\nmitigate overoptimization, we first propose a theoretical algorithm that\nchooses the best policy for an adversarially chosen reward model; one that\nsimultaneously minimizes the maximum likelihood estimation of the loss and a\nreward penalty term. Here, the reward penalty term is introduced to prevent the\npolicy from choosing actions with spurious high proxy rewards, resulting in\nprovable sample efficiency of the algorithm under a partial coverage style\ncondition. Moving from theory to practice, the proposed algorithm further\nenjoys an equivalent but surprisingly easy-to-implement reformulation. Using\nthe equivalence between reward models and the corresponding optimal policy, the\nalgorithm features a simple objective that combines: (i) a preference\noptimization loss that directly aligns the policy with human preference, and\n(ii) a supervised learning loss that explicitly imitates the policy with a\n(suitable) baseline distribution. In the context of aligning large language\nmodels (LLM), this objective fuses the direct preference optimization (DPO)\nloss with the supervised fine-tuning (SFT) loss to help mitigate the\noveroptimization towards undesired responses, for which we name the algorithm\nRegularized Preference Optimization (RPO). Experiments of aligning LLMs\ndemonstrate the improved performance of RPO compared with DPO baselines. Our\nwork sheds light on the interplay between preference optimization and SFT in\ntuning LLMs with both theoretical guarantees and empirical evidence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by The Thirty-Eighth Annual Conference on Neural Information\n  Processing Systems. 31 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.16436v3",
    "published_date": "2024-05-26 05:38:50 UTC",
    "updated_date": "2024-12-04 08:15:35 UTC"
  },
  {
    "arxiv_id": "2405.16434v2",
    "title": "The Importance of Directional Feedback for LLM-based Optimizers",
    "authors": [
      "Allen Nie",
      "Ching-An Cheng",
      "Andrey Kolobov",
      "Adith Swaminathan"
    ],
    "abstract": "We study the potential of using large language models (LLMs) as an\ninteractive optimizer for solving maximization problems in a text space using\nnatural language and numerical feedback. Inspired by the classical optimization\nliterature, we classify the natural language feedback into directional and\nnon-directional, where the former is a generalization of the first-order\nfeedback to the natural language space. We find that LLMs are especially\ncapable of optimization when they are provided with {directional feedback}.\nBased on this insight, we design a new LLM-based optimizer that synthesizes\ndirectional feedback from the historical optimization trace to achieve reliable\nimprovement over iterations. Empirically, we show our LLM-based optimizer is\nmore stable and efficient in solving optimization problems, from maximizing\nmathematical functions to optimizing prompts for writing poems, compared with\nexisting techniques.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted and Presented at Foundation Models for Decision Making at\n  NeurIPS 2023 (December 15, 2023). Work completed from June 2023 to September\n  2023",
    "pdf_url": "http://arxiv.org/pdf/2405.16434v2",
    "published_date": "2024-05-26 05:22:35 UTC",
    "updated_date": "2024-06-20 16:10:50 UTC"
  },
  {
    "arxiv_id": "2405.16433v3",
    "title": "CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling",
    "authors": [
      "Chenhao Zhang",
      "Renhao Li",
      "Minghuan Tan",
      "Min Yang",
      "Jingwei Zhu",
      "Di Yang",
      "Jiahao Zhao",
      "Guancheng Ye",
      "Chengming Li",
      "Xiping Hu"
    ],
    "abstract": "Using large language models (LLMs) to assist psychological counseling is a\nsignificant but challenging task at present. Attempts have been made on\nimproving empathetic conversations or acting as effective assistants in the\ntreatment with LLMs. However, the existing datasets lack consulting knowledge,\nresulting in LLMs lacking professional consulting competence. Moreover, how to\nautomatically evaluate multi-turn dialogues within the counseling process\nremains an understudied area. To bridge the gap, we propose CPsyCoun, a\nreport-based multi-turn dialogue reconstruction and evaluation framework for\nChinese psychological counseling. To fully exploit psychological counseling\nreports, a two-phase approach is devised to construct high-quality dialogues\nwhile a comprehensive evaluation benchmark is developed for the effective\nautomatic evaluation of multi-turn psychological consultations. Competitive\nexperimental results demonstrate the effectiveness of our proposed framework in\npsychological counseling. We open-source the datasets and model for future\nresearch at https://github.com/CAS-SIAT-XinHai/CPsyCoun",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Appectped to Findings of ACL2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16433v3",
    "published_date": "2024-05-26 05:18:00 UTC",
    "updated_date": "2024-06-10 11:43:48 UTC"
  },
  {
    "arxiv_id": "2405.16424v1",
    "title": "Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making",
    "authors": [
      "Min Hun Lee",
      "Silvana Xin Yi Choo",
      "Shamala D/O Thilarajah"
    ],
    "abstract": "With advanced AI/ML, there has been growing research on explainable AI (XAI)\nand studies on how humans interact with AI and XAI for effective human-AI\ncollaborative decision-making. However, we still have a lack of understanding\nof how AI systems and XAI should be first presented to users without technical\nbackgrounds. In this paper, we present the findings of semi-structured\ninterviews with health professionals (n=12) and students (n=4) majoring in\nmedicine and health to study how to improve onboarding with AI and XAI. For the\ninterviews, we built upon human-AI interaction guidelines to create onboarding\nmaterials of an AI system for stroke rehabilitation assessment and AI\nexplanations and introduce them to the participants. Our findings reveal that\nbeyond presenting traditional performance metrics on AI, participants desired\nbenchmark information, the practical benefits of AI, and interaction trials to\nbetter contextualize AI performance, and refine the objectives and performance\nof AI. Based on these findings, we highlight directions for improving\nonboarding with AI and XAI and human-AI collaborative decision-making.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16424v1",
    "published_date": "2024-05-26 04:30:17 UTC",
    "updated_date": "2024-05-26 04:30:17 UTC"
  },
  {
    "arxiv_id": "2405.16422v1",
    "title": "AI-Generated Text Detection and Classification Based on BERT Deep Learning Algorithm",
    "authors": [
      "Hao Wang",
      "Jianwei Li",
      "Zhengyu Li"
    ],
    "abstract": "AI-generated text detection plays an increasingly important role in various\nfields. In this study, we developed an efficient AI-generated text detection\nmodel based on the BERT algorithm, which provides new ideas and methods for\nsolving related problems. In the data preprocessing stage, a series of steps\nwere taken to process the text, including operations such as converting to\nlowercase, word splitting, removing stop words, stemming extraction, removing\ndigits, and eliminating redundant spaces, to ensure data quality and accuracy.\nBy dividing the dataset into a training set and a test set in the ratio of 60%\nand 40%, and observing the changes in the accuracy and loss values during the\ntraining process, we found that the model performed well during the training\nprocess. The accuracy increases steadily from the initial 94.78% to 99.72%,\nwhile the loss value decreases from 0.261 to 0.021 and converges gradually,\nwhich indicates that the BERT model is able to detect AI-generated text with\nhigh accuracy and the prediction results are gradually approaching the real\nclassification results. Further analysis of the results of the training and\ntest sets reveals that in terms of loss value, the average loss of the training\nset is 0.0565, while the average loss of the test set is 0.0917, showing a\nslightly higher loss value. As for the accuracy, the average accuracy of the\ntraining set reaches 98.1%, while the average accuracy of the test set is\n97.71%, which is not much different from each other, indicating that the model\nhas good generalisation ability. In conclusion, the AI-generated text detection\nmodel based on the BERT algorithm proposed in this study shows high accuracy\nand stability in experiments, providing an effective solution for related\nfields.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16422v1",
    "published_date": "2024-05-26 04:26:07 UTC",
    "updated_date": "2024-05-26 04:26:07 UTC"
  },
  {
    "arxiv_id": "2405.16421v1",
    "title": "Towards Sustainable IoT: Challenges, Solutions, and Future Directions for Device Longevity",
    "authors": [
      "Ghazaleh Shirvani",
      "Saeid Ghasemshirazi"
    ],
    "abstract": "In an era dominated by the Internet of Things, ensuring the longevity and\nsustainability of IoT devices has emerged as a pressing concern. This study\nexplores the various complex difficulties which contributed to the early\ndecommissioning of IoT devices and suggests methods to improve their lifespan\nmanagement. By examining factors such as security vulnerabilities, user\nawareness gaps, and the influence of fashion-driven technology trends, the\npaper underscores the need for legislative interventions, consumer education,\nand industry accountability. Additionally, it explores innovative approaches to\nimproving IoT longevity, including the integration of sustainability\nconsiderations into architectural design through requirements engineering\nmethodologies. Furthermore, the paper discusses the potential of distributed\nledger technology, or blockchain, to promote transparent and decentralized\nprocesses for device provisioning and tracking. This study promotes a\nsustainable IoT ecosystem by integrating technology innovation, legal change,\nand social awareness to reduce environmental impact and enhance resilience for\nthe digital future",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16421v1",
    "published_date": "2024-05-26 04:05:01 UTC",
    "updated_date": "2024-05-26 04:05:01 UTC"
  },
  {
    "arxiv_id": "2405.17503v3",
    "title": "Code Repair with LLMs gives an Exploration-Exploitation Tradeoff",
    "authors": [
      "Hao Tang",
      "Keya Hu",
      "Jin Peng Zhou",
      "Sicheng Zhong",
      "Wei-Long Zheng",
      "Xujie Si",
      "Kevin Ellis"
    ],
    "abstract": "Iteratively improving and repairing source code with large language models\n(LLMs), known as refinement, has emerged as a popular way of generating\nprograms that would be too complex to construct in one shot. Given a bank of\ntest cases, together with a candidate program, an LLM can improve that program\nby being prompted with failed test cases. But it remains an open question how\nto best iteratively refine code, with prior work employing simple greedy or\nbreadth-first strategies. We show here that refinement exposes an\nexplore-exploit tradeoff: exploit by refining the program that passes the most\ntest cases, or explore by refining a lesser considered program. We frame this\nas an arm-acquiring bandit problem, which we solve with Thompson Sampling. The\nresulting LLM-based program synthesis algorithm is broadly applicable: Across\nloop invariant synthesis, visual reasoning puzzles, and competition programming\nproblems, we find that our new method can solve more problems using fewer\nlanguage model calls.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17503v3",
    "published_date": "2024-05-26 04:00:30 UTC",
    "updated_date": "2024-10-29 20:01:16 UTC"
  },
  {
    "arxiv_id": "2405.16419v2",
    "title": "Enhancing Feature Diversity Boosts Channel-Adaptive Vision Transformers",
    "authors": [
      "Chau Pham",
      "Bryan A. Plummer"
    ],
    "abstract": "Multi-Channel Imaging (MCI) contains an array of challenges for encoding\nuseful feature representations not present in traditional images. For example,\nimages from two different satellites may both contain RGB channels, but the\nremaining channels can be different for each imaging source. Thus, MCI models\nmust support a variety of channel configurations at test time. Recent work has\nextended traditional visual encoders for MCI, such as Vision Transformers\n(ViT), by supplementing pixel information with an encoding representing the\nchannel configuration. However, these methods treat each channel equally, i.e.,\nthey do not consider the unique properties of each channel type, which can\nresult in needless and potentially harmful redundancies in the learned\nfeatures. For example, if RGB channels are always present, the other channels\ncan focus on extracting information that cannot be captured by the RGB\nchannels. To this end, we propose DiChaViT, which aims to enhance the diversity\nin the learned features of MCI-ViT models. This is achieved through a novel\nchannel sampling strategy that encourages the selection of more distinct\nchannel sets for training. Additionally, we employ regularization and\ninitialization techniques to increase the likelihood that new information is\nlearned from each channel. Many of our improvements are architecture agnostic\nand can be incorporated into new architectures as they are developed.\nExperiments on both satellite and cell microscopy datasets, CHAMMI, JUMP-CP,\nand So2Sat, report DiChaViT yields a 1.5 - 5.0% gain over the state-of-the-art.\nOur code is publicly available at\nhttps://github.com/chaudatascience/diverse_channel_vit.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16419v2",
    "published_date": "2024-05-26 03:41:40 UTC",
    "updated_date": "2024-10-28 13:07:20 UTC"
  },
  {
    "arxiv_id": "2405.16418v2",
    "title": "Unraveling the Smoothness Properties of Diffusion Models: A Gaussian Mixture Perspective",
    "authors": [
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Yufa Zhou"
    ],
    "abstract": "Diffusion models have made rapid progress in generating high-quality samples\nacross various domains. However, a theoretical understanding of the Lipschitz\ncontinuity and second momentum properties of the diffusion process is still\nlacking. In this paper, we bridge this gap by providing a detailed examination\nof these smoothness properties for the case where the target data distribution\nis a mixture of Gaussians, which serves as a universal approximator for smooth\ndensities such as image data. We prove that if the target distribution is a\n$k$-mixture of Gaussians, the density of the entire diffusion process will also\nbe a $k$-mixture of Gaussians. We then derive tight upper bounds on the\nLipschitz constant and second momentum that are independent of the number of\nmixture components $k$. Finally, we apply our analysis to various diffusion\nsolvers, both SDE and ODE based, to establish concrete error guarantees in\nterms of the total variation distance and KL divergence between the target and\nlearned distributions. Our results provide deeper theoretical insights into the\ndynamics of the diffusion process under common data distributions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16418v2",
    "published_date": "2024-05-26 03:32:27 UTC",
    "updated_date": "2024-10-14 03:59:47 UTC"
  },
  {
    "arxiv_id": "2405.17502v1",
    "title": "Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach",
    "authors": [
      "Ziming Liu",
      "Longjian Liu",
      "Robert E. Heidel",
      "Xiaopeng Zhao"
    ],
    "abstract": "This article uses machine learning (ML) and explainable artificial\nintelligence (XAI) techniques to investigate the relationship between\nnutritional status and mortality rates associated with Alzheimers disease (AD).\nThe Third National Health and Nutrition Examination Survey (NHANES III)\ndatabase is employed for analysis. The random forest model is selected as the\nbase model for XAI analysis, and the Shapley Additive Explanations (SHAP)\nmethod is used to assess feature importance. The results highlight significant\nnutritional factors such as serum vitamin B12 and glycated hemoglobin. The\nstudy demonstrates the effectiveness of random forests in predicting AD\nmortality compared to other diseases. This research provides insights into the\nimpact of nutrition on AD and contributes to a deeper understanding of disease\nprogression.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.17502v1",
    "published_date": "2024-05-26 03:18:47 UTC",
    "updated_date": "2024-05-26 03:18:47 UTC"
  },
  {
    "arxiv_id": "2405.16413v1",
    "title": "Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models",
    "authors": [
      "Jiankun Wang",
      "Sumyeong Ahn",
      "Taykhoom Dalal",
      "Xiaodan Zhang",
      "Weishen Pan",
      "Qiannan Zhang",
      "Bin Chen",
      "Hiroko H. Dodge",
      "Fei Wang",
      "Jiayu Zhou"
    ],
    "abstract": "Alzheimer's disease (AD) is the fifth-leading cause of death among Americans\naged 65 and older. Screening and early detection of AD and related dementias\n(ADRD) are critical for timely intervention and for identifying clinical trial\nparticipants. The widespread adoption of electronic health records (EHRs)\noffers an important resource for developing ADRD screening tools such as\nmachine learning based predictive models. Recent advancements in large language\nmodels (LLMs) demonstrate their unprecedented capability of encoding knowledge\nand performing reasoning, which offers them strong potential for enhancing risk\nprediction. This paper proposes a novel pipeline that augments risk prediction\nby leveraging the few-shot inference power of LLMs to make predictions on cases\nwhere traditional supervised learning methods (SLs) may not excel.\nSpecifically, we develop a collaborative pipeline that combines SLs and LLMs\nvia a confidence-driven decision-making mechanism, leveraging the strengths of\nSLs in clear-cut cases and LLMs in more complex scenarios. We evaluate this\npipeline using a real-world EHR data warehouse from Oregon Health \\& Science\nUniversity (OHSU) Hospital, encompassing EHRs from over 2.5 million patients\nand more than 20 million patient encounters. Our results show that our proposed\napproach effectively combines the power of SLs and LLMs, offering significant\nimprovements in predictive performance. This advancement holds promise for\nrevolutionizing ADRD screening and early detection practices, with potential\nimplications for better strategies of patient management and thus improving\nhealthcare.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16413v1",
    "published_date": "2024-05-26 03:05:10 UTC",
    "updated_date": "2024-05-26 03:05:10 UTC"
  },
  {
    "arxiv_id": "2405.16411v2",
    "title": "Tensor Attention Training: Provably Efficient Learning of Higher-order Transformers",
    "authors": [
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Yufa Zhou"
    ],
    "abstract": "Tensor Attention, a multi-view attention that is able to capture high-order\ncorrelations among multiple modalities, can overcome the representational\nlimitations of classical matrix attention. However, the $O(n^3)$ time\ncomplexity of tensor attention poses a significant obstacle to its utilization\nin transformers, where $n$ is the input sequence length. In this work, we prove\nthat the backward gradient of tensor attention training can be computed in\nalmost linear time $n^{1+o(1)}$, the same complexity as its forward computation\nunder the bounded entries assumption. We provide a closed-form solution for the\ngradient and propose a fast computation method utilizing polynomial\napproximation methods and tensor algebraic techniques. Furthermore, we prove\nthe necessity and tightness of our assumption through hardness analysis,\nshowing that slightly weakening it renders the gradient problem unsolvable in\ntruly subcubic time. Our theoretical results establish the feasibility of\nefficient higher-order transformer training and may facilitate practical\napplications of tensor attention architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16411v2",
    "published_date": "2024-05-26 02:59:13 UTC",
    "updated_date": "2024-10-14 04:10:19 UTC"
  },
  {
    "arxiv_id": "2405.16409v1",
    "title": "Network Interdiction Goes Neural",
    "authors": [
      "Lei Zhang",
      "Zhiqian Chen",
      "Chang-Tien Lu",
      "Liang Zhao"
    ],
    "abstract": "Network interdiction problems are combinatorial optimization problems\ninvolving two players: one aims to solve an optimization problem on a network,\nwhile the other seeks to modify the network to thwart the first player's\nobjectives. Such problems typically emerge in an attacker-defender context,\nencompassing areas such as military operations, disease spread analysis, and\ncommunication network management. The primary bottleneck in network\ninterdiction arises from the high time complexity of using conventional exact\nsolvers and the challenges associated with devising efficient heuristic\nsolvers. GNNs, recognized as a cutting-edge methodology, have shown significant\neffectiveness in addressing single-level CO problems on graphs, such as the\ntraveling salesman problem, graph matching, and graph edit distance.\nNevertheless, network interdiction presents a bi-level optimization challenge,\nwhich current GNNs find difficult to manage. To address this gap, we represent\nnetwork interdiction problems as Mixed-Integer Linear Programming (MILP)\ninstances, then apply a multipartite GNN with sufficient representational\ncapacity to learn these formulations. This approach ensures that our neural\nnetwork is more compatible with the mathematical algorithms designed to solve\nnetwork interdiction problems, resulting in improved generalization. Through\ntwo distinct tasks, we demonstrate that our proposed method outperforms\ntheoretical baseline models and provides advantages over traditional exact\nsolvers.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16409v1",
    "published_date": "2024-05-26 02:34:26 UTC",
    "updated_date": "2024-05-26 02:34:26 UTC"
  },
  {
    "arxiv_id": "2405.16406v4",
    "title": "SpinQuant: LLM quantization with learned rotations",
    "authors": [
      "Zechun Liu",
      "Changsheng Zhao",
      "Igor Fedorov",
      "Bilge Soran",
      "Dhruv Choudhary",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra",
      "Yuandong Tian",
      "Tijmen Blankevoort"
    ],
    "abstract": "Post-training quantization (PTQ) techniques applied to weights, activations,\nand the KV cache greatly reduce memory usage, latency, and power consumption of\nLarge Language Models (LLMs), but may lead to large quantization errors when\noutliers are present. Rotating activation or weight matrices helps remove\noutliers and benefits quantization. In this work, we identify a collection of\napplicable rotation parameterizations that lead to identical outputs in\nfull-precision Transformer architectures while enhancing quantization accuracy.\nIn addition, we find that some random rotations lead to much better\nquantization than others, with an up to 13 points difference in downstream\nzero-shot reasoning performance. As a result, we propose SpinQuant, a novel\napproach that incorporates learned rotation matrices for optimal quantized\nnetwork accuracy. With 4-bit quantization of weight, activation, and KV-cache,\nSpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full\nprecision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by\n19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also\noutperforms concurrent work QuaRot, which applies random rotations to remove\noutliers. In particular, for LLaMA-3 8B models that are hard to quantize,\nSpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot.\nCode is available at https://github.com/facebookresearch/SpinQuant.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.16406v4",
    "published_date": "2024-05-26 02:15:49 UTC",
    "updated_date": "2025-02-20 06:07:00 UTC"
  },
  {
    "arxiv_id": "2405.16405v2",
    "title": "Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level",
    "authors": [
      "Runlin Lei",
      "Yuwei Hu",
      "Yuchen Ren",
      "Zhewei Wei"
    ],
    "abstract": "Graph Neural Networks (GNNs) excel across various applications but remain\nvulnerable to adversarial attacks, particularly Graph Injection Attacks (GIAs),\nwhich inject malicious nodes into the original graph and pose realistic\nthreats. Text-attributed graphs (TAGs), where nodes are associated with textual\nfeatures, are crucial due to their prevalence in real-world applications and\nare commonly used to evaluate these vulnerabilities. However, existing research\nonly focuses on embedding-level GIAs, which inject node embeddings rather than\nactual textual content, limiting their applicability and simplifying detection.\nIn this paper, we pioneer the exploration of GIAs at the text level, presenting\nthree novel attack designs that inject textual content into the graph. Through\ntheoretical and empirical analysis, we demonstrate that text interpretability,\na factor previously overlooked at the embedding level, plays a crucial role in\nattack strength. Among the designs we investigate, the Word-frequency-based\nText-level GIA (WTGIA) is particularly notable for its balance between\nperformance and interpretability. Despite the success of WTGIA, we discover\nthat defenders can easily enhance their defenses with customized text embedding\nmethods or large language model (LLM)--based predictors. These insights\nunderscore the necessity for further research into the potential and practical\nsignificance of text-level GIAs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16405v2",
    "published_date": "2024-05-26 02:12:02 UTC",
    "updated_date": "2024-11-01 12:15:36 UTC"
  },
  {
    "arxiv_id": "2405.16402v1",
    "title": "Assessing Empathy in Large Language Models with Real-World Physician-Patient Interactions",
    "authors": [
      "Man Luo",
      "Christopher J. Warren",
      "Lu Cheng",
      "Haidar M. Abdul-Muhsin",
      "Imon Banerjee"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into the healthcare domain\nhas the potential to significantly enhance patient care and support through the\ndevelopment of empathetic, patient-facing chatbots. This study investigates an\nintriguing question Can ChatGPT respond with a greater degree of empathy than\nthose typically offered by physicians? To answer this question, we collect a\nde-identified dataset of patient messages and physician responses from Mayo\nClinic and generate alternative replies using ChatGPT. Our analyses incorporate\nnovel empathy ranking evaluation (EMRank) involving both automated metrics and\nhuman assessments to gauge the empathy level of responses. Our findings\nindicate that LLM-powered chatbots have the potential to surpass human\nphysicians in delivering empathetic communication, suggesting a promising\navenue for enhancing patient care and reducing professional burnout. The study\nnot only highlights the importance of empathy in patient interactions but also\nproposes a set of effective automatic empathy ranking metrics, paving the way\nfor the broader adoption of LLMs in healthcare.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16402v1",
    "published_date": "2024-05-26 01:58:57 UTC",
    "updated_date": "2024-05-26 01:58:57 UTC"
  },
  {
    "arxiv_id": "2405.16393v2",
    "title": "Disentangling Foreground and Background Motion for Enhanced Realism in Human Video Generation",
    "authors": [
      "Jinlin Liu",
      "Kai Yu",
      "Mengyang Feng",
      "Xiefan Guo",
      "Miaomiao Cui"
    ],
    "abstract": "Recent advancements in human video synthesis have enabled the generation of\nhigh-quality videos through the application of stable diffusion models.\nHowever, existing methods predominantly concentrate on animating solely the\nhuman element (the foreground) guided by pose information, while leaving the\nbackground entirely static. Contrary to this, in authentic, high-quality\nvideos, backgrounds often dynamically adjust in harmony with foreground\nmovements, eschewing stagnancy. We introduce a technique that concurrently\nlearns both foreground and background dynamics by segregating their movements\nusing distinct motion representations. Human figures are animated leveraging\npose-based motion, capturing intricate actions. Conversely, for backgrounds, we\nemploy sparse tracking points to model motion, thereby reflecting the natural\ninteraction between foreground activity and environmental changes. Training on\nreal-world videos enhanced with this innovative motion depiction approach, our\nmodel generates videos exhibiting coherent movement in both foreground subjects\nand their surrounding contexts. To further extend video generation to longer\nsequences without accumulating errors, we adopt a clip-by-clip generation\nstrategy, introducing global features at each step. To ensure seamless\ncontinuity across these segments, we ingeniously link the final frame of a\nproduced clip with input noise to spawn the succeeding one, maintaining\nnarrative flow. Throughout the sequential generation process, we infuse the\nfeature representation of the initial reference image into the network,\neffectively curtailing any cumulative color inconsistencies that may otherwise\narise. Empirical evaluations attest to the superiority of our method in\nproducing videos that exhibit harmonious interplay between foreground actions\nand responsive background dynamics, surpassing prior methodologies in this\nregard.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16393v2",
    "published_date": "2024-05-26 00:53:26 UTC",
    "updated_date": "2024-05-28 05:25:00 UTC"
  },
  {
    "arxiv_id": "2405.16390v1",
    "title": "Safe and Balanced: A Framework for Constrained Multi-Objective Reinforcement Learning",
    "authors": [
      "Shangding Gu",
      "Bilgehan Sel",
      "Yuhao Ding",
      "Lu Wang",
      "Qingwei Lin",
      "Alois Knoll",
      "Ming Jin"
    ],
    "abstract": "In numerous reinforcement learning (RL) problems involving safety-critical\nsystems, a key challenge lies in balancing multiple objectives while\nsimultaneously meeting all stringent safety constraints. To tackle this issue,\nwe propose a primal-based framework that orchestrates policy optimization\nbetween multi-objective learning and constraint adherence. Our method employs a\nnovel natural policy gradient manipulation method to optimize multiple RL\nobjectives and overcome conflicting gradients between different tasks, since\nthe simple weighted average gradient direction may not be beneficial for\nspecific tasks' performance due to misaligned gradients of different task\nobjectives. When there is a violation of a hard constraint, our algorithm steps\nin to rectify the policy to minimize this violation. We establish theoretical\nconvergence and constraint violation guarantees in a tabular setting.\nEmpirically, our proposed method also outperforms prior state-of-the-art\nmethods on challenging safe multi-objective reinforcement learning tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16390v1",
    "published_date": "2024-05-26 00:42:10 UTC",
    "updated_date": "2024-05-26 00:42:10 UTC"
  },
  {
    "arxiv_id": "2405.16386v3",
    "title": "Variational Offline Multi-agent Skill Discovery",
    "authors": [
      "Jiayu Chen",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "abstract": "Skills are effective temporal abstractions established for sequential\ndecision making, which enable efficient hierarchical learning for long-horizon\ntasks and facilitate multi-task learning through their transferability. Despite\nextensive research, research gaps remain in multi-agent scenarios, particularly\nfor automatically extracting subgroup coordination patterns in a multi-agent\ntask. In this case, we propose two novel auto-encoder schemes: VO-MASD-3D and\nVO-MASD-Hier, to simultaneously capture subgroup- and temporal-level\nabstractions and form multi-agent skills, which firstly solves the\naforementioned challenge. An essential algorithm component of these schemes is\na dynamic grouping function that can automatically detect latent subgroups\nbased on agent interactions in a task. Further, our method can be applied to\noffline multi-task data, and the discovered subgroup skills can be transferred\nacross relevant tasks without retraining. Empirical evaluations on StarCraft\ntasks indicate that our approach significantly outperforms existing\nhierarchical multi-agent reinforcement learning (MARL) methods. Moreover,\nskills discovered using our method can effectively reduce the learning\ndifficulty in MARL scenarios with delayed and sparse reward signals. The\ncodebase is available at https://github.com/LucasCJYSDL/VOMASD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work will appear in the proceedings of IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.16386v3",
    "published_date": "2024-05-26 00:24:46 UTC",
    "updated_date": "2025-04-30 16:48:03 UTC"
  }
]