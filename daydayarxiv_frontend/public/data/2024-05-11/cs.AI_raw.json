[
  {
    "arxiv_id": "2405.07105v1",
    "title": "Overcoming systematic softening in universal machine learning interatomic potentials by fine-tuning",
    "authors": [
      "Bowen Deng",
      "Yunyeong Choi",
      "Peichen Zhong",
      "Janosh Riebesell",
      "Shashwat Anand",
      "Zhuohan Li",
      "KyuJung Jun",
      "Kristin A. Persson",
      "Gerbrand Ceder"
    ],
    "abstract": "Machine learning interatomic potentials (MLIPs) have introduced a new\nparadigm for atomic simulations. Recent advancements have seen the emergence of\nuniversal MLIPs (uMLIPs) that are pre-trained on diverse materials datasets,\nproviding opportunities for both ready-to-use universal force fields and robust\nfoundations for downstream machine learning refinements. However, their\nperformance in extrapolating to out-of-distribution complex atomic environments\nremains unclear. In this study, we highlight a consistent potential energy\nsurface (PES) softening effect in three uMLIPs: M3GNet, CHGNet, and MACE-MP-0,\nwhich is characterized by energy and force under-prediction in a series of\natomic-modeling benchmarks including surfaces, defects, solid-solution\nenergetics, phonon vibration modes, ion migration barriers, and general\nhigh-energy states.\n  We find that the PES softening behavior originates from a systematic\nunderprediction error of the PES curvature, which derives from the biased\nsampling of near-equilibrium atomic arrangements in uMLIP pre-training\ndatasets. We demonstrate that the PES softening issue can be effectively\nrectified by fine-tuning with a single additional data point. Our findings\nsuggest that a considerable fraction of uMLIP errors are highly systematic, and\ncan therefore be efficiently corrected. This result rationalizes the\ndata-efficient fine-tuning performance boost commonly observed with\nfoundational MLIPs. We argue for the importance of a comprehensive materials\ndataset with improved PES sampling for next-generation foundational MLIPs.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07105v1",
    "published_date": "2024-05-11 22:30:47 UTC",
    "updated_date": "2024-05-11 22:30:47 UTC"
  },
  {
    "arxiv_id": "2405.07101v1",
    "title": "Advanced Natural-based interaction for the ITAlian language: LLaMAntino-3-ANITA",
    "authors": [
      "Marco Polignano",
      "Pierpaolo Basile",
      "Giovanni Semeraro"
    ],
    "abstract": "In the pursuit of advancing natural language processing for the Italian\nlanguage, we introduce a state-of-the-art Large Language Model (LLM) based on\nthe novel Meta LLaMA-3 model: LLaMAntino-3-ANITA-8B-Inst-DPO-ITA. We fine-tuned\nthe original 8B parameters instruction tuned model using the Supervised\nFine-tuning (SFT) technique on the English and Italian language datasets in\norder to improve the original performance. Consequently, a Dynamic Preference\nOptimization (DPO) process has been used to align preferences, avoid dangerous\nand inappropriate answers, and limit biases and prejudices. Our model leverages\nthe efficiency of QLoRA to fine-tune the model on a smaller portion of the\noriginal model weights and then adapt the model specifically for the Italian\nlinguistic structure, achieving significant improvements in both performance\nand computational efficiency. Concurrently, DPO is employed to refine the\nmodel's output, ensuring that generated content aligns with quality answers.\nThe synergy between SFT, QLoRA's parameter efficiency and DPO's user-centric\noptimization results in a robust LLM that excels in a variety of tasks,\nincluding but not limited to text completion, zero-shot classification, and\ncontextual understanding. The model has been extensively evaluated over\nstandard benchmarks for the Italian and English languages, showing outstanding\nresults. The model is freely available over the HuggingFace hub and, examples\nof use can be found in our GitHub repository.\nhttps://huggingface.co/swap-uniba/LLaMAntino-3-ANITA-8B-Inst-DPO-ITA",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07101v1",
    "published_date": "2024-05-11 22:02:55 UTC",
    "updated_date": "2024-05-11 22:02:55 UTC"
  },
  {
    "arxiv_id": "2405.07098v2",
    "title": "Interpretable global minima of deep ReLU neural networks on sequentially separable data",
    "authors": [
      "Thomas Chen",
      "Patricia Mu√±oz Ewald"
    ],
    "abstract": "We explicitly construct zero loss neural network classifiers. We write the\nweight matrices and bias vectors in terms of cumulative parameters, which\ndetermine truncation maps acting recursively on input space. The configurations\nfor the training data considered are (i) sufficiently small, well separated\nclusters corresponding to each class, and (ii) equivalence classes which are\nsequentially linearly separable. In the best case, for $Q$ classes of data in\n$\\mathbb{R}^M$, global minimizers can be described with $Q(M+2)$ parameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math-ph",
      "math.MP",
      "math.OC",
      "stat.ML",
      "57R70, 62M45"
    ],
    "primary_category": "cs.LG",
    "comment": "AMS Latex, 22 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.07098v2",
    "published_date": "2024-05-11 21:29:40 UTC",
    "updated_date": "2024-09-16 18:55:22 UTC"
  },
  {
    "arxiv_id": "2405.07097v2",
    "title": "Diffusion models as probabilistic neural operators for recovering unobserved states of dynamical systems",
    "authors": [
      "Katsiaryna Haitsiukevich",
      "Onur Poyraz",
      "Pekka Marttinen",
      "Alexander Ilin"
    ],
    "abstract": "This paper explores the efficacy of diffusion-based generative models as\nneural operators for partial differential equations (PDEs). Neural operators\nare neural networks that learn a mapping from the parameter space to the\nsolution space of PDEs from data, and they can also solve the inverse problem\nof estimating the parameter from the solution. Diffusion models excel in many\ndomains, but their potential as neural operators has not been thoroughly\nexplored. In this work, we show that diffusion-based generative models exhibit\nmany properties favourable for neural operators, and they can effectively\ngenerate the solution of a PDE conditionally on the parameter or recover the\nunobserved parts of the system. We propose to train a single model adaptable to\nmultiple tasks, by alternating between the tasks during training. In our\nexperiments with multiple realistic dynamical systems, diffusion models\noutperform other neural operators. Furthermore, we demonstrate how the\nprobabilistic diffusion model can elegantly deal with systems which are only\npartially identifiable, by producing samples corresponding to the different\npossible solutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07097v2",
    "published_date": "2024-05-11 21:23:55 UTC",
    "updated_date": "2024-12-15 19:04:32 UTC"
  },
  {
    "arxiv_id": "2406.16891v1",
    "title": "Survey on Reasoning Capabilities and Accessibility of Large Language Models Using Biology-related Questions",
    "authors": [
      "Michael Ackerman"
    ],
    "abstract": "This research paper discusses the advances made in the past decade in\nbiomedicine and Large Language Models. To understand how the advances have been\nmade hand-in-hand with one another, the paper also discusses the integration of\nNatural Language Processing techniques and tools into biomedicine. Finally, the\ngoal of this paper is to expand on a survey conducted last year (2023) by\nintroducing a new list of questions and prompts for the top two language\nmodels. Through this survey, this paper seeks to quantify the improvement made\nin the reasoning abilities in LLMs and to what extent those improvements are\nfelt by the average user. Additionally, this paper seeks to extend research on\nretrieval of biological literature by prompting the LLM to answer open-ended\nquestions in great depth.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16891v1",
    "published_date": "2024-05-11 20:25:40 UTC",
    "updated_date": "2024-05-11 20:25:40 UTC"
  },
  {
    "arxiv_id": "2405.07087v1",
    "title": "Auditing an Automatic Grading Model with deep Reinforcement Learning",
    "authors": [
      "Aubrey Condor",
      "Zachary Pardos"
    ],
    "abstract": "We explore the use of deep reinforcement learning to audit an automatic short\nanswer grading (ASAG) model. Automatic grading may decrease the time burden of\nrating open-ended items for educators, but a lack of robust evaluation methods\nfor these models can result in uncertainty of their quality. Current\nstate-of-the-art ASAG models are configured to match human ratings from a\ntraining set, and researchers typically assess their quality with accuracy\nmetrics that signify agreement between model and human scores. In this paper,\nwe show that a high level of agreement to human ratings does not give\nsufficient evidence that an ASAG model is infallible. We train a reinforcement\nlearning agent to revise student responses with the objective of achieving a\nhigh rating from an automatic grading model in the least number of revisions.\nBy analyzing the agent's revised responses that achieve a high grade from the\nASAG model but would not be considered a high scoring responses according to a\nscoring rubric, we discover ways in which the automated grader can be\nexploited, exposing shortcomings in the grading model.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07087v1",
    "published_date": "2024-05-11 20:07:09 UTC",
    "updated_date": "2024-05-11 20:07:09 UTC"
  },
  {
    "arxiv_id": "2405.07076v2",
    "title": "Integrating Emotional and Linguistic Models for Ethical Compliance in Large Language Models",
    "authors": [
      "Edward Y. Chang"
    ],
    "abstract": "This research develops advanced methodologies for Large Language Models\n(LLMs) to better manage linguistic behaviors related to emotions and ethics. We\nintroduce DIKE, an adversarial framework that enhances the LLMs' ability to\ninternalize and reflect global human values, adapting to varied cultural\ncontexts to promote transparency and trust among users. The methodology\ninvolves detailed modeling of emotions, classification of linguistic behaviors,\nand implementation of ethical guardrails. Our innovative approaches include\nmapping emotions and behaviors using self-supervised learning techniques,\nrefining these guardrails through adversarial reviews, and systematically\nadjusting outputs to ensure ethical alignment. This framework establishes a\nrobust foundation for AI systems to operate with ethical integrity and cultural\nsensitivity, paving the way for more responsible and context-aware AI\ninteractions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 10 tables, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.07076v2",
    "published_date": "2024-05-11 19:26:00 UTC",
    "updated_date": "2024-05-14 03:08:12 UTC"
  },
  {
    "arxiv_id": "2405.13000v1",
    "title": "RAGE Against the Machine: Retrieval-Augmented LLM Explanations",
    "authors": [
      "Joel Rorseth",
      "Parke Godfrey",
      "Lukasz Golab",
      "Divesh Srivastava",
      "Jaroslaw Szlichta"
    ],
    "abstract": "This paper demonstrates RAGE, an interactive tool for explaining Large\nLanguage Models (LLMs) augmented with retrieval capabilities; i.e., able to\nquery external sources and pull relevant information into their input context.\nOur explanations are counterfactual in the sense that they identify parts of\nthe input context that, when removed, change the answer to the question posed\nto the LLM. RAGE includes pruning methods to navigate the vast space of\npossible explanations, allowing users to view the provenance of the produced\nanswers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICDE 2024 (Demonstration Track)",
    "pdf_url": "http://arxiv.org/pdf/2405.13000v1",
    "published_date": "2024-05-11 19:08:38 UTC",
    "updated_date": "2024-05-11 19:08:38 UTC"
  },
  {
    "arxiv_id": "2405.08019v1",
    "title": "AdaKD: Dynamic Knowledge Distillation of ASR models using Adaptive Loss Weighting",
    "authors": [
      "Shreyan Ganguly",
      "Roshan Nayak",
      "Rakshith Rao",
      "Ujan Deb",
      "Prathosh AP"
    ],
    "abstract": "Knowledge distillation, a widely used model compression technique, works on\nthe basis of transferring knowledge from a cumbersome teacher model to a\nlightweight student model. The technique involves jointly optimizing the task\nspecific and knowledge distillation losses with a weight assigned to them.\nDespite these weights playing a crucial role in the performance of the\ndistillation process, current methods provide equal weight to both losses,\nleading to suboptimal performance. In this paper, we propose Adaptive Knowledge\nDistillation, a novel technique inspired by curriculum learning to adaptively\nweigh the losses at instance level. This technique goes by the notion that\nsample difficulty increases with teacher loss. Our method follows a\nplug-and-play paradigm that can be applied on top of any task-specific and\ndistillation objectives. Experiments show that our method performs better than\nconventional knowledge distillation method and existing instance-level loss\nfunctions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08019v1",
    "published_date": "2024-05-11 15:06:24 UTC",
    "updated_date": "2024-05-11 15:06:24 UTC"
  },
  {
    "arxiv_id": "2405.07027v2",
    "title": "TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization",
    "authors": [
      "Zhen Tan",
      "Zongtan Zhou",
      "Yangbing Ge",
      "Zi Wang",
      "Xieyuanli Chen",
      "Dewen Hu"
    ],
    "abstract": "The reliance on accurate camera poses is a significant barrier to the\nwidespread deployment of Neural Radiance Fields (NeRF) models for 3D\nreconstruction and SLAM tasks. The existing method introduces monocular depth\npriors to jointly optimize the camera poses and NeRF, which fails to fully\nexploit the depth priors and neglects the impact of their inherent noise. In\nthis paper, we propose Truncated Depth NeRF (TD-NeRF), a novel approach that\nenables training NeRF from unknown camera poses - by jointly optimizing\nlearnable parameters of the radiance field and camera poses. Our approach\nexplicitly utilizes monocular depth priors through three key advancements: 1)\nwe propose a novel depth-based ray sampling strategy based on the truncated\nnormal distribution, which improves the convergence speed and accuracy of pose\nestimation; 2) to circumvent local minima and refine depth geometry, we\nintroduce a coarse-to-fine training strategy that progressively improves the\ndepth precision; 3) we propose a more robust inter-frame point constraint that\nenhances robustness against depth noise during training. The experimental\nresults on three datasets demonstrate that TD-NeRF achieves superior\nperformance in the joint optimization of camera pose and NeRF, surpassing prior\nworks, and generates more accurate depth geometry. The implementation of our\nmethod has been released at https://github.com/nubot-nudt/TD-NeRF.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07027v2",
    "published_date": "2024-05-11 14:57:42 UTC",
    "updated_date": "2024-10-07 08:28:43 UTC"
  },
  {
    "arxiv_id": "2405.08017v1",
    "title": "Translating Expert Intuition into Quantifiable Features: Encode Investigator Domain Knowledge via LLM for Enhanced Predictive Analytics",
    "authors": [
      "Phoebe Jing",
      "Yijing Gao",
      "Yuanhang Zhang",
      "Xianlong Zeng"
    ],
    "abstract": "In the realm of predictive analytics, the nuanced domain knowledge of\ninvestigators often remains underutilized, confined largely to subjective\ninterpretations and ad hoc decision-making. This paper explores the potential\nof Large Language Models (LLMs) to bridge this gap by systematically converting\ninvestigator-derived insights into quantifiable, actionable features that\nenhance model performance. We present a framework that leverages LLMs' natural\nlanguage understanding capabilities to encode these red flags into a structured\nfeature set that can be readily integrated into existing predictive models.\nThrough a series of case studies, we demonstrate how this approach not only\npreserves the critical human expertise within the investigative process but\nalso scales the impact of this knowledge across various prediction tasks. The\nresults indicate significant improvements in risk assessment and\ndecision-making accuracy, highlighting the value of blending human experiential\nknowledge with advanced machine learning techniques. This study paves the way\nfor more sophisticated, knowledge-driven analytics in fields where expert\ninsight is paramount.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08017v1",
    "published_date": "2024-05-11 13:23:43 UTC",
    "updated_date": "2024-05-11 13:23:43 UTC"
  },
  {
    "arxiv_id": "2405.07001v4",
    "title": "ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering",
    "authors": [
      "Yifan Wu",
      "Lutao Yan",
      "Leixian Shen",
      "Yunhai Wang",
      "Nan Tang",
      "Yuyu Luo"
    ],
    "abstract": "Chart question answering (ChartQA) tasks play a critical role in interpreting\nand extracting insights from visualization charts. While recent advancements in\nmultimodal large language models (MLLMs) like GPT-4o have shown promise in\nhigh-level ChartQA tasks, such as chart captioning, their effectiveness in\nlow-level ChartQA tasks (e.g., identifying correlations) remains underexplored.\nIn this paper, we address this gap by evaluating MLLMs on low-level ChartQA\nusing a newly curated dataset, ChartInsights, which consists of 22,347 (chart,\ntask, query, answer) covering 10 data analysis tasks across 7 chart types. We\nsystematically evaluate 19 advanced MLLMs, including 12 open-source and 7\nclosed-source models. The average accuracy rate across these models is 39.8%,\nwith GPT-4o achieving the highest accuracy at 69.17%. To further explore the\nlimitations of MLLMs in low-level ChartQA, we conduct experiments that alter\nvisual elements of charts (e.g., changing color schemes, adding image noise) to\nassess their impact on the task effectiveness. Furthermore, we propose a new\ntextual prompt strategy, Chain-of-Charts, tailored for low-level ChartQA tasks,\nwhich boosts performance by 14.41%, achieving an accuracy of 83.58%. Finally,\nincorporating a visual prompt strategy that directs attention to relevant\nvisual elements further improves accuracy to 84.32%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Conference Paper",
    "pdf_url": "http://arxiv.org/pdf/2405.07001v4",
    "published_date": "2024-05-11 12:33:46 UTC",
    "updated_date": "2024-11-06 13:56:28 UTC"
  },
  {
    "arxiv_id": "2407.10371v1",
    "title": "The Silent Curriculum: How Does LLM Monoculture Shape Educational Content and Its Accessibility?",
    "authors": [
      "Aman Priyanshu",
      "Supriti Vijay"
    ],
    "abstract": "As Large Language Models (LLMs) ascend in popularity, offering information\nwith unprecedented convenience compared to traditional search engines, we delve\ninto the intriguing possibility that a new, singular perspective is being\npropagated. We call this the \"Silent Curriculum,\" where our focus shifts\ntowards a particularly impressionable demographic: children, who are drawn to\nthe ease and immediacy of acquiring knowledge through these digital oracles. In\nthis exploration, we delve into the sociocultural ramifications of LLMs, which,\nthrough their nuanced responses, may be subtly etching their own stereotypes,\nan algorithmic or AI monoculture. We hypothesize that the convergence of\npre-training data, fine-tuning datasets, and analogous guardrails across models\nmay have birthed a distinct cultural lens. We unpack this concept through a\nshort experiment navigating children's storytelling, occupational-ethnic\nbiases, and self-diagnosed annotations, to find that there exists strong cosine\nsimilarity (0.87) of biases across these models, suggesting a similar\nperspective of ethnic stereotypes in occupations. This paper invites a\nreimagining of LLMs' societal role, especially as the new information\ngatekeepers, advocating for a paradigm shift towards diversity-rich landscapes\nover unintended monocultures.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "5 pages and 4 figures. Accepted at The Workshop on Global AI Cultures\n  at the International Conference on Learning Representations, 2024 (ICLR'24)",
    "pdf_url": "http://arxiv.org/pdf/2407.10371v1",
    "published_date": "2024-05-11 12:02:44 UTC",
    "updated_date": "2024-05-11 12:02:44 UTC"
  },
  {
    "arxiv_id": "2405.06981v1",
    "title": "AraSpell: A Deep Learning Approach for Arabic Spelling Correction",
    "authors": [
      "Mahmoud Salhab",
      "Faisal Abu-Khzam"
    ],
    "abstract": "Spelling correction is the task of identifying spelling mistakes, typos, and\ngrammatical mistakes in a given text and correcting them according to their\ncontext and grammatical structure. This work introduces \"AraSpell,\" a framework\nfor Arabic spelling correction using different seq2seq model architectures such\nas Recurrent Neural Network (RNN) and Transformer with artificial data\ngeneration for error injection, trained on more than 6.9 Million Arabic\nsentences. Thorough experimental studies provide empirical evidence of the\neffectiveness of the proposed approach, which achieved 4.8% and 1.11% word\nerror rate (WER) and character error rate (CER), respectively, in comparison\nwith labeled data of 29.72% WER and 5.03% CER. Our approach achieved 2.9% CER\nand 10.65% WER in comparison with labeled data of 10.02% CER and 50.94% WER.\nBoth of these results are obtained on a test set of 100K sentences.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06981v1",
    "published_date": "2024-05-11 10:36:28 UTC",
    "updated_date": "2024-05-11 10:36:28 UTC"
  },
  {
    "arxiv_id": "2405.06973v1",
    "title": "A Primer for Preferential Non-Monotonic Propositional Team Logics",
    "authors": [
      "Kai Sauerwald",
      "Juha Kontinen"
    ],
    "abstract": "This paper considers KLM-style preferential non-monotonic reasoning in the\nsetting of propositional team semantics. We show that team-based propositional\nlogics naturally give rise to cumulative non-monotonic entailment relations.\nMotivated by the non-classical interpretation of disjunction in team semantics,\nwe give a precise characterization for preferential models for propositional\ndependence logic satisfying all of System P postulates. Furthermore, we show\nhow classical entailment and dependence logic entailment can be expressed in\nterms of non-trivial preferential models.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "03B60",
      "I.2.3; F.4.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06973v1",
    "published_date": "2024-05-11 09:53:15 UTC",
    "updated_date": "2024-05-11 09:53:15 UTC"
  },
  {
    "arxiv_id": "2405.06972v2",
    "title": "A Machine Learning-based Approach for Solving Recurrence Relations and its use in Cost Analysis of Logic Programs",
    "authors": [
      "Louis Rustenholz",
      "Maximiliano Klemen",
      "Miguel √Ångel Carreira-Perpi√±√°n",
      "Pedro L√≥pez-Garc√≠a"
    ],
    "abstract": "Automatic static cost analysis infers information about the resources used by\nprograms without actually running them with concrete data, and presents such\ninformation as functions of input data sizes. Most of the analysis tools for\nlogic programs (and many for other languages), as CiaoPP, are based on setting\nup recurrence relations representing (bounds on) the computational cost of\npredicates, and solving them to find closed-form functions. Such recurrence\nsolving is a bottleneck in current tools: many of the recurrences that arise\nduring the analysis cannot be solved with state-of-the-art solvers, including\nComputer Algebra Systems (CASs), so that specific methods for different classes\nof recurrences need to be developed. We address such a challenge by developing\na novel, general approach for solving arbitrary, constrained recurrence\nrelations, that uses machine-learning (sparse-linear and symbolic) regression\ntechniques to guess a candidate closed-form function, and a combination of an\nSMT-solver and a CAS to check if it is actually a solution of the recurrence.\nOur prototype implementation and its experimental evaluation within the context\nof the CiaoPP system show quite promising results. Overall, for the considered\nbenchmarks, our approach outperforms state-of-the-art cost analyzers and\nrecurrence solvers, and solves recurrences that cannot be solved by them.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).",
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "primary_category": "cs.PL",
    "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). Extended, revised version of our work published in ICLP (Klemen et\n  al. 2023, arXiv:2309.07259). arXiv admin note: text overlap with\n  arXiv:2309.07259",
    "pdf_url": "http://arxiv.org/pdf/2405.06972v2",
    "published_date": "2024-05-11 09:51:36 UTC",
    "updated_date": "2024-08-29 23:21:57 UTC"
  },
  {
    "arxiv_id": "2407.10369v2",
    "title": "A Robust Governance for the AI Act: AI Office, AI Board, Scientific Panel, and National Authorities",
    "authors": [
      "Claudio Novelli",
      "Philipp Hacker",
      "Jessica Morley",
      "Jarle Trondal",
      "Luciano Floridi"
    ],
    "abstract": "Regulation is nothing without enforcement. This particularly holds for the\ndynamic field of emerging technologies. Hence, this article has two ambitions.\nFirst, it explains how the EU's new Artificial Intelligence Act (AIA) will be\nimplemented and enforced by various institutional bodies, thus clarifying the\ngovernance framework of the AIA. Second, it proposes a normative model of\ngovernance, providing recommendations to ensure uniform and coordinated\nexecution of the AIA and the fulfilment of the legislation. Taken together, the\narticle explores how the AIA may be implemented by national and EU\ninstitutional bodies, encompassing longstanding bodies, such as the European\nCommission, and those newly established under the AIA, such as the AI Office.\nIt investigates their roles across supranational and national levels,\nemphasizing how EU regulations influence institutional structures and\noperations. These regulations may not only directly dictate the structural\ndesign of institutions but also indirectly request administrative capacities\nneeded to enforce the AIA.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "European Journal of Risk Regulation, 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.10369v2",
    "published_date": "2024-05-11 09:22:16 UTC",
    "updated_date": "2024-10-26 09:35:34 UTC"
  },
  {
    "arxiv_id": "2405.06964v2",
    "title": "ManiFoundation Model for General-Purpose Robotic Manipulation of Contact Synthesis with Arbitrary Objects and Robots",
    "authors": [
      "Zhixuan Xu",
      "Chongkai Gao",
      "Zixuan Liu",
      "Gang Yang",
      "Chenrui Tie",
      "Haozhuo Zheng",
      "Haoyu Zhou",
      "Weikun Peng",
      "Debang Wang",
      "Tianrun Hu",
      "Tianyi Chen",
      "Zhouliang Yu",
      "Lin Shao"
    ],
    "abstract": "To substantially enhance robot intelligence, there is a pressing need to\ndevelop a large model that enables general-purpose robots to proficiently\nundertake a broad spectrum of manipulation tasks, akin to the versatile\ntask-planning ability exhibited by LLMs. The vast diversity in objects, robots,\nand manipulation tasks presents huge challenges. Our work introduces a\ncomprehensive framework to develop a foundation model for general robotic\nmanipulation that formalizes a manipulation task as contact synthesis.\nSpecifically, our model takes as input object and robot manipulator point\nclouds, object physical attributes, target motions, and manipulation region\nmasks. It outputs contact points on the object and associated contact forces or\npost-contact motions for robots to achieve the desired manipulation task. We\nperform extensive experiments both in the simulation and real-world settings,\nmanipulating articulated rigid objects, rigid objects, and deformable objects\nthat vary in dimensionality, ranging from one-dimensional objects like ropes to\ntwo-dimensional objects like cloth and extending to three-dimensional objects\nsuch as plasticine. Our model achieves average success rates of around 90\\%.\nSupplementary materials and videos are available on our project website at\nhttps://manifoundationmodel.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06964v2",
    "published_date": "2024-05-11 09:18:37 UTC",
    "updated_date": "2024-09-25 04:21:06 UTC"
  },
  {
    "arxiv_id": "2406.04350v1",
    "title": "Prompt-guided Precise Audio Editing with Diffusion Models",
    "authors": [
      "Manjie Xu",
      "Chenxing Li",
      "Duzhen zhang",
      "Dan Su",
      "Wei Liang",
      "Dong Yu"
    ],
    "abstract": "Audio editing involves the arbitrary manipulation of audio content through\nprecise control. Although text-guided diffusion models have made significant\nadvancements in text-to-audio generation, they still face challenges in finding\na flexible and precise way to modify target events within an audio track. We\npresent a novel approach, referred to as PPAE, which serves as a general module\nfor diffusion models and enables precise audio editing. The editing is based on\nthe input textual prompt only and is entirely training-free. We exploit the\ncross-attention maps of diffusion models to facilitate accurate local editing\nand employ a hierarchical local-global pipeline to ensure a smoother editing\nprocess. Experimental results highlight the effectiveness of our method in\nvarious editing tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.04350v1",
    "published_date": "2024-05-11 07:41:27 UTC",
    "updated_date": "2024-05-11 07:41:27 UTC"
  },
  {
    "arxiv_id": "2405.06932v1",
    "title": "Piccolo2: General Text Embedding with Multi-task Hybrid Loss Training",
    "authors": [
      "Junqin Huang",
      "Zhongjie Hu",
      "Zihao Jing",
      "Mengya Gao",
      "Yichao Wu"
    ],
    "abstract": "In this report, we introduce Piccolo2, an embedding model that surpasses\nother models in the comprehensive evaluation over 6 tasks on CMTEB benchmark,\nsetting a new state-of-the-art. Piccolo2 primarily leverages an efficient\nmulti-task hybrid loss training approach, effectively harnessing textual data\nand labels from diverse downstream tasks. In addition, Piccolo2 scales up the\nembedding dimension and uses MRL training to support more flexible vector\ndimensions. The latest information of piccolo models can be accessed via:\nhttps://huggingface.co/sensenova/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "tech report",
    "pdf_url": "http://arxiv.org/pdf/2405.06932v1",
    "published_date": "2024-05-11 06:32:08 UTC",
    "updated_date": "2024-05-11 06:32:08 UTC"
  },
  {
    "arxiv_id": "2405.06925v2",
    "title": "Semi-supervised Anomaly Detection via Adaptive Reinforcement Learning-Enabled Method with Causal Inference for Sensor Signals",
    "authors": [
      "Xiangwei Chen",
      "Ruliang Xiaoa",
      "Zhixia Zeng",
      "Zhipeng Qiu",
      "Shi Zhang",
      "Xin Du"
    ],
    "abstract": "Semi-supervised anomaly detection for sensor signals is critical in ensuring\nsystem reliability in smart manufacturing. However, existing methods rely\nheavily on data correlation, neglecting causality and leading to potential\nmisinterpretations due to confounding factors. Moreover, while current\nreinforcement learning-based methods can effectively identify known and unknown\nanomalies with limited labeled samples, these methods still face several\nchallenges, such as under-utilization of priori knowledge, lack of model\nflexibility, and deficient reward feedback during environmental interactions.\nTo address the above problems, this paper innovatively constructs a\ncounterfactual causal reinforcement learning model, termed Triple-Assisted\nCausal Reinforcement Learning Anomaly Detector (Tri-CRLAD). The model leverages\ncausal inference to extract the intrinsic causal feature in data, enhancing the\nagent's utilization of prior knowledge and improving its generalization\ncapability. In addition, Tri-CRLAD features a triple decision support\nmechanism, including a sampling strategy based on historical similarity, an\nadaptive threshold smoothing adjustment strategy, and an adaptive decision\nreward mechanism. These mechanisms further enhance the flexibility and\ngeneralization ability of the model, enabling it to effectively respond to\nvarious complex and dynamically changing environments. Experimental results\nacross seven diverse sensor signal datasets demonstrate that Tri-CRLAD\noutperforms nine state-of-the-art baseline methods. Notably, Tri-CRLAD achieves\nup to a 23\\% improvement in anomaly detection stability with minimal known\nanomaly samples, highlighting its potential in semi-supervised anomaly\ndetection scenarios. Our code is available at\nhttps://github.com/Aoudsung/Tri-CRLAD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06925v2",
    "published_date": "2024-05-11 06:10:05 UTC",
    "updated_date": "2024-05-16 14:17:10 UTC"
  },
  {
    "arxiv_id": "2405.08015v1",
    "title": "A Methodology-Oriented Study of Catastrophic Forgetting in Incremental Deep Neural Networks",
    "authors": [
      "Ashutosh Kumar",
      "Sonali Agarwal",
      "D Jude Hemanth"
    ],
    "abstract": "Human being and different species of animals having the skills to gather,\ntransferring knowledge, processing, fine-tune and generating information\nthroughout their lifetime. The ability of learning throughout their lifespan is\nreferred as continuous learning which is using neurocognition mechanism.\nConsequently, in real world computational system of incremental learning\nautonomous agents also needs such continuous learning mechanism which provide\nretrieval of information and long-term memory consolidation. However, the main\nchallenge in artificial intelligence is that the incremental learning of the\nautonomous agent when new data confronted. In such scenarios, the main concern\nis catastrophic forgetting(CF), i.e., while learning the sequentially, neural\nnetwork underfits the old data when it confronted with new data. To tackle this\nCF problem many numerous studied have been proposed, however it is very\ndifficult to compare their performance due to dissimilarity in their evaluation\nmechanism. Here we focus on the comparison of all algorithms which are having\nsimilar type of evaluation mechanism. Here we are comparing three types of\nincremental learning methods: (1) Exemplar based methods, (2) Memory based\nmethods, and (3) Network based method. In this survey paper, methodology\noriented study for catastrophic forgetting in incremental deep neural network\nis addressed. Furthermore, it contains the mathematical overview of impact-full\nmethods which can be help researchers to deal with CF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08015v1",
    "published_date": "2024-05-11 05:10:07 UTC",
    "updated_date": "2024-05-11 05:10:07 UTC"
  },
  {
    "arxiv_id": "2405.06915v1",
    "title": "Automating Creativity",
    "authors": [
      "Ming-Hui Huang",
      "Roland T. Rust"
    ],
    "abstract": "Generative AI (GenAI) has spurred the expectation of being creative, due to\nits ability to generate content, yet so far, its creativity has somewhat\ndisappointed, because it is trained using existing data following human\nintentions to generate outputs. The purpose of this paper is to explore what is\nrequired to evolve AI from generative to creative. Based on a reinforcement\nlearning approach and building upon various research streams of computational\ncreativity, we develop a triple prompt-response-reward engineering framework to\ndevelop the creative capability of GenAI. This framework consists of three\ncomponents: 1) a prompt model for expected creativity by developing\ndiscriminative prompts that are objectively, individually, or socially novel,\n2) a response model for observed creativity by generating surprising outputs\nthat are incrementally, disruptively, or radically innovative, and 3) a reward\nmodel for improving creativity over time by incorporating feedback from the AI,\nthe creator/manager, and/or the customers. This framework enables the\napplication of GenAI for various levels of creativity strategically.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "46 pages, 2 tables, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.06915v1",
    "published_date": "2024-05-11 05:05:10 UTC",
    "updated_date": "2024-05-11 05:05:10 UTC"
  },
  {
    "arxiv_id": "2405.06909v1",
    "title": "Fairness in Reinforcement Learning: A Survey",
    "authors": [
      "Anka Reuel",
      "Devin Ma"
    ],
    "abstract": "While our understanding of fairness in machine learning has significantly\nprogressed, our understanding of fairness in reinforcement learning (RL)\nremains nascent. Most of the attention has been on fairness in one-shot\nclassification tasks; however, real-world, RL-enabled systems (e.g., autonomous\nvehicles) are much more complicated in that agents operate in dynamic\nenvironments over a long period of time. To ensure the responsible development\nand deployment of these systems, we must better understand fairness in RL. In\nthis paper, we survey the literature to provide the most up-to-date snapshot of\nthe frontiers of fairness in RL. We start by reviewing where fairness\nconsiderations can arise in RL, then discuss the various definitions of\nfairness in RL that have been put forth thus far. We continue to highlight the\nmethodologies researchers used to implement fairness in single- and multi-agent\nRL systems before showcasing the distinct application domains that fair RL has\nbeen investigated in. Finally, we critically examine gaps in the literature,\nsuch as understanding fairness in the context of RLHF, that still need to be\naddressed in future work to truly operationalize fair RL in real-world systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "A.1; I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.06909v1",
    "published_date": "2024-05-11 04:36:46 UTC",
    "updated_date": "2024-05-11 04:36:46 UTC"
  },
  {
    "arxiv_id": "2405.06907v2",
    "title": "AIOS Compiler: LLM as Interpreter for Natural Language Programming and Flow Programming of AI Agents",
    "authors": [
      "Shuyuan Xu",
      "Zelong Li",
      "Kai Mei",
      "Yongfeng Zhang"
    ],
    "abstract": "Since their inception, programming languages have trended towards greater\nreadability and lower barriers for programmers. Following this trend, natural\nlanguage can be a promising type of programming language that provides great\nflexibility and usability and helps towards the democracy of programming.\nHowever, the inherent vagueness, ambiguity, and verbosity of natural language\npose significant challenges in developing an interpreter that can accurately\nunderstand the programming logic and execute instructions written in natural\nlanguage. Fortunately, recent advancements in Large Language Models (LLMs) have\ndemonstrated remarkable proficiency in interpreting complex natural language.\nInspired by this, we develop a novel system for Code Representation and\nExecution (CoRE), which employs LLM as interpreter to interpret and execute\nnatural language instructions. The proposed system unifies natural language\nprogramming, pseudo-code programming, and flow programming under the same\nrepresentation for constructing language agents, while LLM serves as the\ninterpreter to interpret and execute the agent programs. In this paper, we\nbegin with defining the programming syntax that structures natural language\ninstructions logically. During the execution, we incorporate external memory to\nminimize redundancy. Furthermore, we equip the designed interpreter with the\ncapability to invoke external tools, compensating for the limitations of LLM in\nspecialized domains or when accessing real-time information. This work is\nopen-source at https://github.com/agiresearch/CoRE,\nhttps://github.com/agiresearch/OpenAGI, and\nhttps://github.com/agiresearch/AIOS.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 6 figures, comments and suggestions are welcome",
    "pdf_url": "http://arxiv.org/pdf/2405.06907v2",
    "published_date": "2024-05-11 04:29:03 UTC",
    "updated_date": "2024-05-21 20:35:55 UTC"
  },
  {
    "arxiv_id": "2405.08013v1",
    "title": "CTRL: Continuous-Time Representation Learning on Temporal Heterogeneous Information Network",
    "authors": [
      "Chenglin Li",
      "Yuanzhen Xie",
      "Chenyun Yu",
      "Lei Cheng",
      "Bo Hu",
      "Zang Li",
      "Di Niu"
    ],
    "abstract": "Inductive representation learning on temporal heterogeneous graphs is crucial\nfor scalable deep learning on heterogeneous information networks (HINs) which\nare time-varying, such as citation networks. However, most existing approaches\nare not inductive and thus cannot handle new nodes or edges. Moreover, previous\ntemporal graph embedding methods are often trained with the temporal link\nprediction task to simulate the link formation process of temporal graphs,\nwhile ignoring the evolution of high-order topological structures on temporal\ngraphs. To fill these gaps, we propose a Continuous-Time Representation\nLearning (CTRL) model on temporal HINs. To preserve heterogeneous node features\nand temporal structures, CTRL integrates three parts in a single layer, they\nare 1) a \\emph{heterogeneous attention} unit that measures the semantic\ncorrelation between nodes, 2) a \\emph{edge-based Hawkes process} to capture\ntemporal influence between heterogeneous nodes, and 3) \\emph{dynamic\ncentrality} that indicates the dynamic importance of a node. We train the CTRL\nmodel with a future event (a subgraph) prediction task to capture the evolution\nof the high-order network structure. Extensive experiments have been conducted\non three benchmark datasets. The results demonstrate that our model\nsignificantly boosts performance and outperforms various state-of-the-art\napproaches. Ablation studies are conducted to demonstrate the effectiveness of\nthe model design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08013v1",
    "published_date": "2024-05-11 03:39:22 UTC",
    "updated_date": "2024-05-11 03:39:22 UTC"
  },
  {
    "arxiv_id": "2405.06890v1",
    "title": "TacoERE: Cluster-aware Compression for Event Relation Extraction",
    "authors": [
      "Yong Guan",
      "Xiaozhi Wang",
      "Lei Hou",
      "Juanzi Li",
      "Jeff Pan",
      "Jiaoyan Chen",
      "Freddy Lecue"
    ],
    "abstract": "Event relation extraction (ERE) is a critical and fundamental challenge for\nnatural language processing. Existing work mainly focuses on directly modeling\nthe entire document, which cannot effectively handle long-range dependencies\nand information redundancy. To address these issues, we propose a cluster-aware\ncompression method for improving event relation extraction (TacoERE), which\nexplores a compression-then-extraction paradigm. Specifically, we first\nintroduce document clustering for modeling event dependencies. It splits the\ndocument into intra- and inter-clusters, where intra-clusters aim to enhance\nthe relations within the same cluster, while inter-clusters attempt to model\nthe related events at arbitrary distances. Secondly, we utilize cluster\nsummarization to simplify and highlight important text content of clusters for\nmitigating information redundancy and event distance. We have conducted\nextensive experiments on both pre-trained language models, such as RoBERTa, and\nlarge language models, such as ChatGPT and GPT-4, on three ERE datasets, i.e.,\nMAVEN-ERE, EventStoryLine and HiEve. Experimental results demonstrate that\nTacoERE is an effective method for ERE.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06890v1",
    "published_date": "2024-05-11 03:06:08 UTC",
    "updated_date": "2024-05-11 03:06:08 UTC"
  },
  {
    "arxiv_id": "2405.06886v1",
    "title": "Event GDR: Event-Centric Generative Document Retrieval",
    "authors": [
      "Yong Guan",
      "Dingxiao Liu",
      "Jinchen Ma",
      "Hao Peng",
      "Xiaozhi Wang",
      "Lei Hou",
      "Ru Li"
    ],
    "abstract": "Generative document retrieval, an emerging paradigm in information retrieval,\nlearns to build connections between documents and identifiers within a single\nmodel, garnering significant attention. However, there are still two\nchallenges: (1) neglecting inner-content correlation during document\nrepresentation; (2) lacking explicit semantic structure during identifier\nconstruction. Nonetheless, events have enriched relations and well-defined\ntaxonomy, which could facilitate addressing the above two challenges. Inspired\nby this, we propose Event GDR, an event-centric generative document retrieval\nmodel, integrating event knowledge into this task. Specifically, we utilize an\nexchange-then-reflection method based on multi-agents for event knowledge\nextraction. For document representation, we employ events and relations to\nmodel the document to guarantee the comprehensiveness and inner-content\ncorrelation. For identifier construction, we map the events to well-defined\nevent taxonomy to construct the identifiers with explicit semantic structure.\nOur method achieves significant improvement over the baselines on two datasets,\nand also hopes to provide insights for future research.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted to WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06886v1",
    "published_date": "2024-05-11 02:55:11 UTC",
    "updated_date": "2024-05-11 02:55:11 UTC"
  },
  {
    "arxiv_id": "2405.06859v1",
    "title": "Reimplementation of Learning to Reweight Examples for Robust Deep Learning",
    "authors": [
      "Parth Patil",
      "Ben Boardley",
      "Jack Gardner",
      "Emily Loiselle",
      "Deerajkumar Parthipan"
    ],
    "abstract": "Deep neural networks (DNNs) have been used to create models for many complex\nanalysis problems like image recognition and medical diagnosis. DNNs are a\npopular tool within machine learning due to their ability to model complex\npatterns and distributions. However, the performance of these networks is\nhighly dependent on the quality of the data used to train the models. Two\ncharacteristics of these sets, noisy labels and training set biases, are known\nto frequently cause poor generalization performance as a result of overfitting\nto the training set. This paper aims to solve this problem using the approach\nproposed by Ren et al. (2018) using meta-training and online weight\napproximation. We will first implement a toy-problem to crudely verify the\nclaims made by the authors of Ren et al. (2018) and then venture into using the\napproach to solve a real world problem of Skin-cancer detection using an\nimbalanced image dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06859v1",
    "published_date": "2024-05-11 00:43:56 UTC",
    "updated_date": "2024-05-11 00:43:56 UTC"
  }
]