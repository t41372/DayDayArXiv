{
  "date": "2024-02-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-27 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域，特别是大型语言模型（LLMs）的优化、图像生成、多模态理解和强化学习等主题，令人印象深刻的包括 OpenAI 的 Sora 模型综述以及 LLM 在鲁棒性和任务泛化上的创新尝试，而知名学者如 Pieter Abbeel 和 Sergey Levine 的工作则凸显了 AI 在真实世界应用的潜力。\n\n今天共有 104 篇论文，我将优先讨论那些重要、创新或与热门话题相关的文章，例如图像生成、LLM 安全和强化学习领域，其余论文将快速概述或略过。以下是关键论文的简要分析，按主题归类。\n\n### AI 生成模型与图像处理\n- **Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models**（英文原标题：Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models）  \n  这篇论文对 OpenAI 的 Sora 模型进行了全面综述，讨论了其背景、技术（如视频生成架构）、局限性（例如潜在偏见）和未来机会（应用于机器人等领域）。主要贡献是揭示 Sora 在模拟物理世界的潜力，同时强调了挑战，如确保生成内容的真实性和安全性，为视频生成模型的发展提供了宝贵见解。\n\n- **Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in Text-to-Image Generation**（英文原标题：Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in Text-to-Image Generation）  \n  作者提出了一种优化扩散模型的方法，通过噪声调度、数据集平衡和人类偏好对齐，提升图像生成的审美质量。关键发现是该方法在各种分辨率下超越了 DALLE 3 和 Midjourney v5.2，在实际应用中显著提高了图像逼真度。\n\n- **Structure-Guided Adversarial Training of Diffusion Models**（英文原标题：Structure-Guided Adversarial Training of Diffusion Models）  \n  这篇论文引入了一种基于结构的对抗训练框架，用于改进扩散模型的图像生成。贡献在于通过结构引导减少参数冗余，并在 ImageNet 等数据集上实现了新 SOTA 性能（FID 得分达 1.58），展示了如何在保持多样性的同时提升生成效率。\n\n### 大型语言模型与鲁棒性\n- **Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems**（英文原标题：Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems）  \n  论文揭示了检索增强生成模型的安全漏洞，通过提示注入攻击提取数据。核心发现是多种 LLM（如 GPT-4 和 Llama2）易受攻击，成功率高达 100%，并提出位置偏差消除策略来缓解风险，这对 LLM 的实际部署具有重要启示。\n\n- **Case-Based or Rule-Based: How Do Transformers Do the Math?**（英文原标题：Case-Based or Rule-Based: How Do Transformers Do the Math?）  \n  作者探索了 Transformer 在数学推理中的机制，比较了基于案例和规则的推理方式。贡献是通过 Rule-Following Fine-Tuning 技术显著提升了 LLM 的系统泛化能力（如在加法任务上准确率提高 40%），揭示了 LLM 学习规则的潜力。\n\n- **TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space**（英文原标题：TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space）  \n  这篇工作提出 TruthX 方法，通过编辑 LLM 的内部表示来减少幻觉。发现是将 LLM 的特征映射到真实空间后，可将幻觉减少 20%，这为提升 LLM 的可靠性和真实性提供了新路径。\n\n### 多模态与强化学习\n- **QRData: Knowledge Base Guided Visual Commonsense Discovery in Images**（英文原标题：QRData: Knowledge Base Guided Visual Commonsense Discovery in Images）  \n  论文构建了 QRData 数据集和 VCDM 模型，用于从图像中发现视觉常识。贡献是改进了多模态模型在物体属性和关系的理解，实验显示其在下游任务中优于 GPT-4V，强调了常识知识在视觉任务中的作用。\n\n- **Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings**（英文原标题：Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings）  \n  Pieter Abbeel 和 Sergey Levine 等知名学者参与，这篇论文引入功能奖励编码框架，实现无监督零样本强化学习。发现该方法在机器人任务中超越了现有方法，展示了如何从无标签轨迹中学习高效策略。\n\n其他论文，如那些涉及生物信息、流体力学或特定领域优化（如第5、7、9、10、20、23、24、25、27、30、33、40、43、44、47、50、51、55、61、65、68、69、70、71、72、73、74、75、76、77、78、79、80、81、82、83、85、86、87、88、89、90、91、93、94、95、96、97、99、100、101、102、103、104），要么是次要创新，要么与主流 AI 话题关联较弱，因此仅快速提及：这些工作涵盖了从强化学习到量子计算的广泛领域，但多数未带来突破性进展，例如第5篇使用 AI 库解决流体动力学问题，或第20篇在医疗 RL 中的应用，仅在特定子领域有实用价值。\n\n总之，今天的 arXiv 强调了 AI 模型的鲁棒性和泛化能力，Sora 综述和 LLM 优化论文尤其值得关注，预示着 AI 在多模态和决策领域的快速发展。希望这份快报能帮助大家快速筛选感兴趣的文章！",
  "papers": [
    {
      "arxiv_id": "2402.17934v2",
      "title": "Inducing Generalization across Languages and Tasks using Featurized Low-Rank Mixtures",
      "title_zh": "翻译失败",
      "authors": [
        "Chu-Cheng Lin",
        "Xinyi Wang",
        "Jonathan H. Clark",
        "Han Lu",
        "Yun Zhu",
        "Chenxi Whitehouse",
        "Hongkun Yu"
      ],
      "abstract": "Adapting pretrained large language models (LLMs) to various downstream tasks\nin tens or hundreds of human languages is computationally expensive.\nParameter-efficient fine-tuning (PEFT) significantly reduces the adaptation\ncost, by tuning only a small amount of parameters. However, common PEFT methods\nLoRA (Hu et al., 2022) suffer from suboptimal performance on diverse dataset\nmixtures, due to aggressive parameter tying and negative interference among\ndifferent datasets. In this work, we propose Featurized Low-rank Mixtures\n(FLix), a novel PEFT method designed for effective multitask multilingual\nadaptation. FLix associates each unique dataset feature, such as the dataset's\nlanguage or task, with its own low-rank weight update parameters. By composing\nfeature-specific parameters for each dataset, FLix can accommodate diverse\ndataset mixtures and generalize better to unseen datasets. Our experiments show\nthat FLix leads to significant improvements over a variety of tasks for both\nsupervised learning and zero-shot settings with gains of up to $14.2$ inexact\nmatch points in zero-shot semantic parsing.",
      "tldr_zh": "本研究针对预训练大型语言模型 (LLMs) 适应多语言多任务的计算开销问题，提出了一种新型参数高效微调 (PEFT) 方法Featurized Low-rank Mixtures (FLix)。FLix 通过为每个数据集的独特特征（如语言或任务）分配专属的低秩权重更新参数，实现特征特定组合，从而减少负面干扰并提升对多样数据集的泛化能力。与现有方法如 LoRA 相比，实验结果显示FLix 在监督学习和零样本设置中表现出显著改善，尤其在零样本语义解析中提升高达14.2个inexact match点。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Revised version",
      "pdf_url": "http://arxiv.org/pdf/2402.17934v2",
      "published_date": "2024-02-27 23:12:45 UTC",
      "updated_date": "2024-08-01 05:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:26:01.459861"
    },
    {
      "arxiv_id": "2402.17930v1",
      "title": "Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Tan Zhi-Xuan",
        "Lance Ying",
        "Vikash Mansinghka",
        "Joshua B. Tenenbaum"
      ],
      "abstract": "People often give instructions whose meaning is ambiguous without further\ncontext, expecting that their actions or goals will disambiguate their\nintentions. How can we build assistive agents that follow such instructions in\na flexible, context-sensitive manner? This paper introduces cooperative\nlanguage-guided inverse plan search (CLIPS), a Bayesian agent architecture for\npragmatic instruction following and goal assistance. Our agent assists a human\nby modeling them as a cooperative planner who communicates joint plans to the\nassistant, then performs multimodal Bayesian inference over the human's goal\nfrom actions and language, using large language models (LLMs) to evaluate the\nlikelihood of an instruction given a hypothesized plan. Given this posterior,\nour assistant acts to minimize expected goal achievement cost, enabling it to\npragmatically follow ambiguous instructions and provide effective assistance\neven when uncertain about the goal. We evaluate these capabilities in two\ncooperative planning domains (Doors, Keys & Gems and VirtualHome), finding that\nCLIPS significantly outperforms GPT-4V, LLM-based literal instruction following\nand unimodal inverse planning in both accuracy and helpfulness, while closely\nmatching the inferences and assistive judgments provided by human raters.",
      "tldr_zh": "该论文提出了一种名为 CLIPS（Cooperative Language-Guided Inverse Plan Search）的贝叶斯代理架构，用于处理模糊指令和提供目标辅助，模拟人类作为合作规划者。CLIPS 通过多模态贝叶斯推理结合大型语言模型（LLMs）从人类的语言和行动中推断目标，并最小化预期目标实现成本，从而实现灵活的语境敏感指令遵循。实验在 Doors, Keys & Gems 和 VirtualHome 等合作规划领域显示，CLIPS 在准确性和帮助性方面显著优于 GPT-4V、基于 LLM 的字面指令遵循和单模态逆向规划，且其推理结果接近人类评估者。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAMAS 2024. 8 pages (excl. references), 5 figures/tables.\n  (Appendix: 8 pages, 8 figures/tables). Code available at:\n  https://github.com/probcomp/CLIPS.jl",
      "pdf_url": "http://arxiv.org/pdf/2402.17930v1",
      "published_date": "2024-02-27 23:06:53 UTC",
      "updated_date": "2024-02-27 23:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:26:11.415825"
    },
    {
      "arxiv_id": "2402.17916v3",
      "title": "Adversarial Math Word Problem Generation",
      "title_zh": "对抗性数学文字问题生成",
      "authors": [
        "Roy Xie",
        "Chengxuan Huang",
        "Junlin Wang",
        "Bhuwan Dhingra"
      ],
      "abstract": "Large language models (LLMs) have significantly transformed the educational\nlandscape. As current plagiarism detection tools struggle to keep pace with\nLLMs' rapid advancements, the educational community faces the challenge of\nassessing students' true problem-solving abilities in the presence of LLMs. In\nthis work, we explore a new paradigm for ensuring fair evaluation -- generating\nadversarial examples which preserve the structure and difficulty of the\noriginal questions aimed for assessment, but are unsolvable by LLMs. Focusing\non the domain of math word problems, we leverage abstract syntax trees to\nstructurally generate adversarial examples that cause LLMs to produce incorrect\nanswers by simply editing the numeric values in the problems. We conduct\nexperiments on various open- and closed-source LLMs, quantitatively and\nqualitatively demonstrating that our method significantly degrades their math\nproblem-solving ability. We identify shared vulnerabilities among LLMs and\npropose a cost-effective approach to attack high-cost models. Additionally, we\nconduct automatic analysis to investigate the cause of failure, providing\nfurther insights into the limitations of LLMs.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在教育中的滥用问题，提出了一种生成对抗性数学文字问题的方法，以确保公平评估学生的真实能力。该方法利用抽象语法树（abstract syntax trees）来编辑问题中的数字值，保持原问题的结构和难度，但使 LLMs 无法正确解答。实验在多种开源和闭源 LLMs 上显示，这种方法显著降低了它们的数学问题解决能力，并识别了 LLMs 的共同漏洞，同时提出了一种针对高成本模型的成本有效攻击策略。通过自动分析，该研究揭示了 LLMs 失败的原因，为理解其局限性提供了新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code/data: https://github.com/ruoyuxie/adversarial_mwps_generation",
      "pdf_url": "http://arxiv.org/pdf/2402.17916v3",
      "published_date": "2024-02-27 22:07:52 UTC",
      "updated_date": "2024-06-15 22:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:26:22.709801"
    },
    {
      "arxiv_id": "2402.17914v2",
      "title": "Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers",
      "title_zh": "通过可解释方言分类器提取方言的词汇特征",
      "authors": [
        "Roy Xie",
        "Orevaoghene Ahia",
        "Yulia Tsvetkov",
        "Antonios Anastasopoulos"
      ],
      "abstract": "Identifying linguistic differences between dialects of a language often\nrequires expert knowledge and meticulous human analysis. This is largely due to\nthe complexity and nuance involved in studying various dialects. We present a\nnovel approach to extract distinguishing lexical features of dialects by\nutilizing interpretable dialect classifiers, even in the absence of human\nexperts. We explore both post-hoc and intrinsic approaches to interpretability,\nconduct experiments on Mandarin, Italian, and Low Saxon, and experimentally\ndemonstrate that our method successfully identifies key language-specific\nlexical features that contribute to dialectal variations.",
      "tldr_zh": "这篇论文解决了识别语言方言差异的挑战，通常需要专家知识和手动分析的问题。作者提出了一种新方法，使用 interpretable dialect classifiers 来提取方言的独特词汇特征，包括 post-hoc 和 intrinsic 解释方式，而无需人类专家参与。在 Mandarin、Italian 和 Low Saxon 等语言上进行的实验证明，该方法成功识别出关键的语言特定词汇特征，从而揭示方言变异的原因。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code is available at\n  https://github.com/ruoyuxie/interpretable_dialect_classifier",
      "pdf_url": "http://arxiv.org/pdf/2402.17914v2",
      "published_date": "2024-02-27 22:06:55 UTC",
      "updated_date": "2024-03-23 20:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:26:34.980156"
    },
    {
      "arxiv_id": "2402.17913v1",
      "title": "Using AI libraries for Incompressible Computational Fluid Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Boyang Chen",
        "Claire E. Heaney",
        "Christopher C. Pain"
      ],
      "abstract": "Recently, there has been a huge effort focused on developing highly efficient\nopen source libraries to perform Artificial Intelligence (AI) related\ncomputations on different computer architectures (for example, CPUs, GPUs and\nnew AI processors). This has not only made the algorithms based on these\nlibraries highly efficient and portable between different architectures, but\nalso has substantially simplified the entry barrier to develop methods using\nAI. Here, we present a novel methodology to bring the power of both AI software\nand hardware into the field of numerical modelling by repurposing AI methods,\nsuch as Convolutional Neural Networks (CNNs), for the standard operations\nrequired in the field of the numerical solution of Partial Differential\nEquations (PDEs). The aim of this work is to bring the high performance,\narchitecture agnosticism and ease of use into the field of the numerical\nsolution of PDEs. We use the proposed methodology to solve the\nadvection-diffusion equation, the non-linear Burgers equation and\nincompressible flow past a bluff body. For the latter, a convolutional neural\nnetwork is used as a multigrid solver in order to enforce the incompressibility\nconstraint. We show that the presented methodology can solve all these problems\nusing repurposed AI libraries in an efficient way, and presents a new avenue to\nexplore in the development of methods to solve PDEs and Computational Fluid\nDynamics problems with implicit methods.",
      "tldr_zh": "本研究提出了一种创新方法，利用AI库（如用于Convolutional Neural Networks (CNNs)）来处理不可压缩Computational Fluid Dynamics (CFD)问题，旨在将AI的高性能、硬件无关性和易用性引入Partial Differential Equations (PDEs)数值求解领域。方法通过重用AI软件和硬件，将CNNs等技术应用于标准PDEs操作，例如求解advection-diffusion equation、非线性Burgers equation以及不可压缩流体绕钝体流动，其中CNNs用作multigrid solver来强制不可压缩约束。实验结果显示，该方法能高效解决这些问题，并在CFD的隐式方法开发中开辟新途径。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "24 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.17913v1",
      "published_date": "2024-02-27 22:00:50 UTC",
      "updated_date": "2024-02-27 22:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:26:47.947611"
    },
    {
      "arxiv_id": "2402.17896v1",
      "title": "Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents",
      "title_zh": "Researchy Questions：一个多视角、可分解问题的数据集，用于 LLM Web 代理",
      "authors": [
        "Corby Rosset",
        "Ho-Lam Chung",
        "Guanghui Qin",
        "Ethan C. Chau",
        "Zhuo Feng",
        "Ahmed Awadallah",
        "Jennifer Neville",
        "Nikhil Rao"
      ],
      "abstract": "Existing question answering (QA) datasets are no longer challenging to most\npowerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA,\nNaturalQuestions, ELI5 and HotpotQA mainly study ``known unknowns'' with clear\nindications of both what information is missing, and how to find it to answer\nthe question. Hence, good performance on these benchmarks provides a false\nsense of security. A yet unmet need of the NLP community is a bank of\nnon-factoid, multi-perspective questions involving a great deal of unclear\ninformation needs, i.e. ``unknown uknowns''. We claim we can find such\nquestions in search engine logs, which is surprising because most\nquestion-intent queries are indeed factoid. We present Researchy Questions, a\ndataset of search engine queries tediously filtered to be non-factoid,\n``decompositional'' and multi-perspective. We show that users spend a lot of\n``effort'' on these questions in terms of signals like clicks and session\nlength, and that they are also challenging for GPT-4. We also show that ``slow\nthinking'' answering techniques, like decomposition into sub-questions shows\nbenefit over answering directly. We release $\\sim$ 100k Researchy Questions,\nalong with the Clueweb22 URLs that were clicked.",
      "tldr_zh": "本论文介绍了Researchy Questions数据集，该数据集包含约10万条非事实性(multi-perspective, decompositional)问题，旨在解决现有QA基准（如TriviaQA、NaturalQuestions和HotpotQA）主要关注“known unknowns”而忽略“unknown unknowns”的局限性。作者从搜索引擎日志中筛选出这些问题，强调它们涉及模糊信息需求，并观察到用户在处理这些问题时表现出更高的参与度（如点击和会话长度）。实验结果显示，这些问题对GPT-4构成挑战，而采用“慢思考”策略（如分解为子问题）比直接回答更有效，从而为LLM Web Agents的训练和评估提供新资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17896v1",
      "published_date": "2024-02-27 21:27:16 UTC",
      "updated_date": "2024-02-27 21:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:27:01.784809"
    },
    {
      "arxiv_id": "2402.18599v2",
      "title": "Meta-Task: A Method-Agnostic Framework for Learning to Regularize in Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Rostami",
        "Atik Faysal",
        "Huaxia Wang",
        "Avimanyu Sahoo"
      ],
      "abstract": "Overfitting is a significant challenge in Few-Shot Learning (FSL), where\nmodels trained on small, variable datasets tend to memorize rather than\ngeneralize to unseen tasks. Regularization is crucial in FSL to prevent\noverfitting and enhance generalization performance. To address this issue, we\nintroduce Meta-Task, a novel, method-agnostic framework that leverages both\nlabeled and unlabeled data to enhance generalization through auxiliary tasks\nfor regularization. Specifically, Meta-Task introduces a Task-Decoder, which is\na simple example of the broader framework that refines hidden representations\nby reconstructing input images from embeddings, effectively mitigating\noverfitting.\n  Our framework's method-agnostic design ensures its broad applicability across\nvarious FSL settings. We validate Meta-Task's effectiveness on standard\nbenchmarks, including Mini-ImageNet, Tiered-ImageNet, and FC100, where it\nconsistently improves existing state-of-the-art meta-learning techniques,\ndemonstrating superior performance, faster convergence, reduced generalization\nerror, and lower variance-all without extensive hyperparameter tuning. These\nresults underline Meta-Task's practical applicability and efficiency in\nreal-world, resource-constrained scenarios.",
      "tldr_zh": "这篇论文提出了 Meta-Task，一个方法无关的框架，用于在 Few-Shot Learning 中通过辅助任务进行正则化，以解决模型过拟合问题。该框架利用标记和未标记数据，通过 Task-Decoder 从嵌入中重建输入图像，从而细化隐藏表示并提升泛化能力。在 Mini-ImageNet、Tiered-ImageNet 和 FC100 等基准测试中，Meta-Task 显著改善了现有元学习技术的性能，包括更高的准确率、更快的收敛、更低的泛化误差和方差，且无需广泛的超参数调整。这些结果突显了该框架在资源受限的实际场景中的实用性和高效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.18599v2",
      "published_date": "2024-02-27 21:15:40 UTC",
      "updated_date": "2025-02-26 23:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:27:12.265099"
    },
    {
      "arxiv_id": "2402.17888v1",
      "title": "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Peng",
        "Yadan Luo",
        "Yonggang Zhang",
        "Yixuan Li",
        "Zhen Fang"
      ],
      "abstract": "Post-hoc out-of-distribution (OOD) detection has garnered intensive attention\nin reliable machine learning. Many efforts have been dedicated to deriving\nscore functions based on logits, distances, or rigorous data distribution\nassumptions to identify low-scoring OOD samples. Nevertheless, these estimate\nscores may fail to accurately reflect the true data density or impose\nimpractical constraints. To provide a unified perspective on density-based\nscore design, we propose a novel theoretical framework grounded in Bregman\ndivergence, which extends distribution considerations to encompass an\nexponential family of distributions. Leveraging the conjugation constraint\nrevealed in our theorem, we introduce a \\textsc{ConjNorm} method, reframing\ndensity function design as a search for the optimal norm coefficient $p$\nagainst the given dataset. In light of the computational challenges of\nnormalization, we devise an unbiased and analytically tractable estimator of\nthe partition function using the Monte Carlo-based importance sampling\ntechnique. Extensive experiments across OOD detection benchmarks empirically\ndemonstrate that our proposed \\textsc{ConjNorm} has established a new\nstate-of-the-art in a variety of OOD detection setups, outperforming the\ncurrent best method by up to 13.25$\\%$ and 28.19$\\%$ (FPR95) on CIFAR-100 and\nImageNet-1K, respectively.",
      "tldr_zh": "该论文针对后验异常检测（Post-hoc Out-of-Distribution Detection）提出了一种新的理论框架，基于 Bregman divergence 将分布扩展到指数族（exponential family），以更准确地估计数据密度。研究引入 ConjNorm 方法，通过优化 norm 系数 $p$ 来重新设计密度函数，并使用 Monte Carlo-based importance sampling 技术，提供一个无偏且易于计算的 partition function 估计器。实验结果显示，ConjNorm 在各种 OOD 检测基准上取得了新的最先进性能，比当前最佳方法在 CIFAR-100 和 ImageNet-1K 上分别降低了 13.25% 和 28.19% 的 FPR95 值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR24 poster",
      "pdf_url": "http://arxiv.org/pdf/2402.17888v1",
      "published_date": "2024-02-27 21:02:47 UTC",
      "updated_date": "2024-02-27 21:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:27:23.967782"
    },
    {
      "arxiv_id": "2402.17862v3",
      "title": "REPrune: Channel Pruning via Kernel Representative Selection",
      "title_zh": "REPrune：通过内核代表选择进行的通道剪枝",
      "authors": [
        "Mincheol Park",
        "Dongjin Kim",
        "Cheonjun Park",
        "Yuna Park",
        "Gyeong Eun Gong",
        "Won Woo Ro",
        "Suhyun Kim"
      ],
      "abstract": "Channel pruning is widely accepted to accelerate modern convolutional neural\nnetworks (CNNs). The resulting pruned model benefits from its immediate\ndeployment on general-purpose software and hardware resources. However, its\nlarge pruning granularity, specifically at the unit of a convolution filter,\noften leads to undesirable accuracy drops due to the inflexibility of deciding\nhow and where to introduce sparsity to the CNNs. In this paper, we propose\nREPrune, a novel channel pruning technique that emulates kernel pruning, fully\nexploiting the finer but structured granularity. REPrune identifies similar\nkernels within each channel using agglomerative clustering. Then, it selects\nfilters that maximize the incorporation of kernel representatives while\noptimizing the maximum cluster coverage problem. By integrating with a\nsimultaneous training-pruning paradigm, REPrune promotes efficient, progressive\npruning throughout training CNNs, avoiding the conventional\ntrain-prune-finetune sequence. Experimental results highlight that REPrune\nperforms better in computer vision tasks than existing methods, effectively\nachieving a balance between acceleration ratio and performance retention.",
      "tldr_zh": "该论文提出REPrune，一种新型的channel pruning技术，通过模拟kernel pruning来实现更细粒度的结构化稀疏，从而缓解传统CNNs剪枝导致的准确率下降问题。REPrune使用agglomerative clustering识别每个通道内的相似kernels，并选择最大化kernel representatives的filters，同时优化maximum cluster coverage problem。实验结果显示，该方法在计算机视觉任务中优于现有技术，在加速比和性能保留之间取得了有效平衡，并通过simultaneous training-pruning paradigm实现了高效的渐进式剪枝过程。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at AAAI2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17862v3",
      "published_date": "2024-02-27 19:54:30 UTC",
      "updated_date": "2024-03-08 07:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:27:34.380800"
    },
    {
      "arxiv_id": "2402.17853v2",
      "title": "Latent Neural PDE Solver: a reduced-order modelling framework for partial differential equations",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Li",
        "Saurabh Patil",
        "Francis Ogoke",
        "Dule Shu",
        "Wilson Zhen",
        "Michael Schneier",
        "John R. Buchanan, Jr.",
        "Amir Barati Farimani"
      ],
      "abstract": "Neural networks have shown promising potential in accelerating the numerical\nsimulation of systems governed by partial differential equations (PDEs).\nDifferent from many existing neural network surrogates operating on\nhigh-dimensional discretized fields, we propose to learn the dynamics of the\nsystem in the latent space with much coarser discretizations. In our proposed\nframework - Latent Neural PDE Solver (LNS), a non-linear autoencoder is first\ntrained to project the full-order representation of the system onto the\nmesh-reduced space, then a temporal model is trained to predict the future\nstate in this mesh-reduced space. This reduction process simplifies the\ntraining of the temporal model by greatly reducing the computational cost\naccompanying a fine discretization. We study the capability of the proposed\nframework and several other popular neural PDE solvers on various types of\nsystems including single-phase and multi-phase flows along with varying system\nparameters. We showcase that it has competitive accuracy and efficiency\ncompared to the neural PDE solver that operates on full-order space.",
      "tldr_zh": "这篇论文提出了Latent Neural PDE Solver (LNS)，一个用于partial differential equations (PDEs)的简化建模框架，通过在潜在空间中学习系统动态来加速数值模拟。框架首先训练一个non-linear autoencoder，将系统从全阶表示投影到网格减少的空间，然后训练一个时间模型来预测未来状态，从而显著降低计算成本。实验结果显示，LNS在单相和多相流动等各种系统中，与其他神经PDE求解器相比，具有竞争性的准确性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17853v2",
      "published_date": "2024-02-27 19:36:27 UTC",
      "updated_date": "2025-01-08 00:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:27:47.499017"
    },
    {
      "arxiv_id": "2403.00828v1",
      "title": "Deep Learning Detection Method for Large Language Models-Generated Scientific Content",
      "title_zh": "针对大语言模型生成科学内容的深度学习检测方法",
      "authors": [
        "Bushra Alhijawi",
        "Rawan Jarrar",
        "Aseel AbuAlRub",
        "Arwa Bader"
      ],
      "abstract": "Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual\ncontent is written and communicated. These models have the potential to\ngenerate scientific content that is indistinguishable from that written by\nhumans. Hence, LLMs carry severe consequences for the scientific community,\nwhich relies on the integrity and reliability of publications. This research\npaper presents a novel ChatGPT-generated scientific text detection method,\nAI-Catcher. AI-Catcher integrates two deep learning models, multilayer\nperceptron (MLP) and convolutional neural networks (CNN). The MLP learns the\nfeature representations of the linguistic and statistical features. The CNN\nextracts high-level representations of the sequential patterns from the textual\ncontent. AI-Catcher is a multimodal model that fuses hidden patterns derived\nfrom MLP and CNN. In addition, a new ChatGPT-Generated scientific text dataset\nis collected to enhance AI-generated text detection tools, AIGTxt. AIGTxt\ncontains 3000 records collected from published academic articles across ten\ndomains and divided into three classes: Human-written, ChatGPT-generated, and\nMixed text. Several experiments are conducted to evaluate the performance of\nAI-Catcher. The comparative results demonstrate the capability of AI-Catcher to\ndistinguish between human-written and ChatGPT-generated scientific text more\naccurately than alternative methods. On average, AI-Catcher improved accuracy\nby 37.4%.",
      "tldr_zh": "本研究针对Large Language Models (LLMs)如GPT-3和BERT生成科学内容可能难以区分人类写作的问题，提出了一种新型检测方法AI-Catcher，以维护科学出版物的完整性。AI-Catcher整合了多层感知器(MLP)用于学习语言和统计特征，以及卷积神经网络(CNN)用于提取文本顺序模式的高级表示，并通过多模态融合实现精确检测。同时，研究构建了新的AIGTxt数据集，包含3000条记录来自十个领域的学术文章，分为人类撰写、ChatGPT-generated和混合文本三类。实验结果显示，AI-Catcher比其他方法平均提高了37.4%的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00828v1",
      "published_date": "2024-02-27 19:16:39 UTC",
      "updated_date": "2024-02-27 19:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:28:00.808808"
    },
    {
      "arxiv_id": "2403.00827v1",
      "title": "Self-Refinement of Language Models from External Proxy Metrics Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Keshav Ramji",
        "Young-Suk Lee",
        "Ramón Fernandez Astudillo",
        "Md Arafat Sultan",
        "Tahira Naseem",
        "Asim Munawar",
        "Radu Florian",
        "Salim Roukos"
      ],
      "abstract": "It is often desirable for Large Language Models (LLMs) to capture multiple\nobjectives when providing a response. In document-grounded response generation,\nfor example, agent responses are expected to be relevant to a user's query\nwhile also being grounded in a given document. In this paper, we introduce\nProxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine\nits own initial response along key dimensions of quality guided by external\nmetrics feedback, yielding an overall better final response. ProMiSe leverages\nfeedback on response quality through principle-specific proxy metrics, and\niteratively refines its response one principle at a time. We apply ProMiSe to\nopen source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its\nperformance on document-grounded question answering datasets, MultiDoc2Dial and\nQuAC, demonstrating that self-refinement improves response quality. We further\nshow that fine-tuning Llama-2-13B-Chat on the synthetic dialogue data generated\nby ProMiSe yields significant performance improvements over the zero-shot\nbaseline as well as a supervised fine-tuned model on human annotated data.",
      "tldr_zh": "本论文提出ProMiSe（Proxy Metric-based Self-Refinement）方法，允许大型语言模型（LLMs）通过外部代理指标反馈来自我精炼初始响应，从而在多个质量维度（如相关性和文档关联性）上实现整体改进。ProMiSe利用原则特定的代理指标，逐步迭代地优化响应，确保响应更符合用户查询和文档基础。实验在Flan-T5-XXL和Llama-2-13B-Chat模型上评估了MultiDoc2Dial和QuAC数据集，显示了响应质量的显著提升。此外，使用ProMiSe生成的合成对话数据对Llama-2-13B-Chat进行微调，性能超过了零样本基线和基于人类标注的监督微调模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00827v1",
      "published_date": "2024-02-27 19:13:01 UTC",
      "updated_date": "2024-02-27 19:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:28:13.597988"
    },
    {
      "arxiv_id": "2402.17840v3",
      "title": "Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenting Qi",
        "Hanlin Zhang",
        "Eric Xing",
        "Sham Kakade",
        "Himabindu Lakkaraju"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) improves pre-trained models by\nincorporating external knowledge at test time to enable customized adaptation.\nWe study the risk of datastore leakage in Retrieval-In-Context RAG Language\nModels (LMs). We show that an adversary can exploit LMs' instruction-following\ncapabilities to easily extract text data verbatim from the datastore of RAG\nsystems built with instruction-tuned LMs via prompt injection. The\nvulnerability exists for a wide range of modern LMs that span Llama2,\nMistral/Mixtral, Vicuna, SOLAR, WizardLM, Qwen1.5, and Platypus2, and the\nexploitability exacerbates as the model size scales up. We also study multiple\neffects of RAG setup on the extractability of data, indicating that following\nunexpected instructions to regurgitate data can be an outcome of failure in\neffectively utilizing contexts for modern LMs, and further show that such\nvulnerability can be greatly mitigated by position bias elimination strategies.\nExtending our study to production RAG models GPTs, we design an attack that can\ncause datastore leakage with a 100% success rate on 25 randomly selected\ncustomized GPTs with at most 2 queries, and we extract text data verbatim at a\nrate of 41% from a book of 77,000 words and 3% from a corpus of 1,569,000 words\nby prompting the GPTs with only 100 queries generated by themselves.",
      "tldr_zh": "本研究探讨了 Retrieval-Augmented Generation (RAG) 系统中的数据泄露风险，攻击者可通过 prompt injection 利用语言模型的指令遵循能力，从 RAG 数据存储中直接提取文本数据。实验发现，这种漏洞广泛存在于多种模型中，如 Llama2、Mistral 和 Vicuna，且模型规模越大，提取成功率越高。研究进一步分析了 RAG 设置的影响，并证明通过消除位置偏差策略可以显著缓解漏洞；在生产环境测试中，攻击可在少量查询下从定制 GPTs 中提取大量文本，例如从一本书中提取41%的内容。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17840v3",
      "published_date": "2024-02-27 19:08:05 UTC",
      "updated_date": "2024-10-06 21:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:28:25.065053"
    },
    {
      "arxiv_id": "2402.17826v3",
      "title": "Prediction-Powered Ranking of Large Language Models",
      "title_zh": "预测驱动的大型语言模型排名",
      "authors": [
        "Ivi Chatzi",
        "Eleni Straitouri",
        "Suhas Thejaswi",
        "Manuel Gomez Rodriguez"
      ],
      "abstract": "Large language models are often ranked according to their level of alignment\nwith human preferences -- a model is better than other models if its outputs\nare more frequently preferred by humans. One of the popular ways to elicit\nhuman preferences utilizes pairwise comparisons between the outputs provided by\ndifferent models to the same inputs. However, since gathering pairwise\ncomparisons by humans is costly and time-consuming, it has become a common\npractice to gather pairwise comparisons by a strong large language model -- a\nmodel strongly aligned with human preferences. Surprisingly, practitioners\ncannot currently measure the uncertainty that any mismatch between human and\nmodel preferences may introduce in the constructed rankings. In this work, we\ndevelop a statistical framework to bridge this gap. Given a (small) set of\npairwise comparisons by humans and a large set of pairwise comparisons by a\nmodel, our framework provides a rank-set -- a set of possible ranking positions\n-- for each of the models under comparison. Moreover, it guarantees that, with\na probability greater than or equal to a user-specified value, the rank-sets\ncover the true ranking consistent with the distribution of human pairwise\npreferences asymptotically. Using pairwise comparisons made by humans in the\nLMSYS Chatbot Arena platform and pairwise comparisons made by three strong\nlarge language models, we empirically demonstrate the effectivity of our\nframework and show that the rank-sets constructed using only pairwise\ncomparisons by the strong large language models are often inconsistent with\n(the distribution of) human pairwise preferences.",
      "tldr_zh": "该论文解决了大型语言模型（Large Language Models）的排名问题，该排名通常基于人类偏好配对比较，但由于成本高，常由强大模型替代，导致不确定性。研究提出一个统计框架，利用少量人类配对比较（pairwise comparisons）和大量模型配对比较，生成每个模型的可能排名集合（rank-set），并保证以用户指定的概率覆盖真实人类偏好分布的排名。实验基于 LMSYS Chatbot Arena 的数据和三个强大语言模型的比较，证明了框架的有效性，并发现仅使用模型比较的排名往往与人类偏好不一致，从而提升了模型排名的可靠性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17826v3",
      "published_date": "2024-02-27 19:00:01 UTC",
      "updated_date": "2024-12-04 16:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:28:36.335748"
    },
    {
      "arxiv_id": "2402.17768v2",
      "title": "Diffusion Meets DAgger: Supercharging Eye-in-hand Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Zhang",
        "Matthew Chang",
        "Pranav Kumar",
        "Saurabh Gupta"
      ],
      "abstract": "A common failure mode for policies trained with imitation is compounding\nexecution errors at test time. When the learned policy encounters states that\nare not present in the expert demonstrations, the policy fails, leading to\ndegenerate behavior. The Dataset Aggregation, or DAgger approach to this\nproblem simply collects more data to cover these failure states. However, in\npractice, this is often prohibitively expensive. In this work, we propose\nDiffusion Meets DAgger (DMD), a method to reap the benefits of DAgger without\nthe cost for eye-in-hand imitation learning problems. Instead of collecting new\nsamples to cover out-of-distribution states, DMD uses recent advances in\ndiffusion models to synthesize these samples. This leads to robust performance\nfrom few demonstrations. We compare DMD against behavior cloning baseline\nacross four tasks: pushing, stacking, pouring, and shirt hanging. In pushing,\nDMD achieves 80% success rate with as few as 8 expert demonstrations, where\nnaive behavior cloning reaches only 20%. In stacking, DMD succeeds on average\n92% of the time across 5 cups, versus 40% for BC. When pouring coffee beans,\nDMD transfers to another cup successfully 80% of the time. Finally, DMD attains\n90% success rate for hanging shirt on a clothing rack.",
      "tldr_zh": "这篇论文针对模仿学习中测试时执行错误积累的问题，提出了Diffusion Meets DAgger (DMD)方法，用于eye-in-hand模仿学习。DMD结合扩散模型合成样本来覆盖分布外状态，从而避免了传统DAgger的高成本数据收集，实现从少量专家演示中获得鲁棒性能。在实验中，DMD在pushing任务中仅用8个演示达到80%成功率（行为克隆(BC)仅20%）、stacking任务平均92%成功率、pouring任务80%转移成功率，以及shirt hanging任务90%成功率，显著优于基线模型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by Robotics: Science and Systems (RSS) 2024. project website\n  with video, see https://sites.google.com/view/diffusion-meets-dagger",
      "pdf_url": "http://arxiv.org/pdf/2402.17768v2",
      "published_date": "2024-02-27 18:59:18 UTC",
      "updated_date": "2024-06-05 17:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:28:50.147429"
    },
    {
      "arxiv_id": "2402.17767v3",
      "title": "Opening Articulated Structures in the Real World",
      "title_zh": "在真实世界中打开关节结构",
      "authors": [
        "Arjun Gupta",
        "Michelle Zhang",
        "Rishik Sathua",
        "Saurabh Gupta"
      ],
      "abstract": "What does it take to build mobile manipulation systems that can competently\noperate on previously unseen objects in previously unseen environments? This\nwork answers this question using opening of articulated structures as a mobile\nmanipulation testbed. Specifically, our focus is on the end-to-end performance\non this task without any privileged information, i.e. the robot starts at a\nlocation with the novel target articulated object in view, and has to approach\nthe object and successfully open it. We first develop a system for this task,\nand then conduct 100+ end-to-end system tests across 13 real world test sites.\nOur large-scale study reveals a number of surprising findings: a) modular\nsystems outperform end-to-end learned systems for this task, even when the\nend-to-end learned systems are trained on 1000+ demonstrations, b) perception,\nand not precise end-effector control, is the primary bottleneck to task\nsuccess, and c) state-of-the-art articulation parameter estimation models\ndeveloped in isolation struggle when faced with robot-centric viewpoints.\nOverall, our findings highlight the limitations of developing components of the\npipeline in isolation and underscore the need for system-level research,\nproviding a pragmatic roadmap for building generalizable mobile manipulation\nsystems. Videos, code, and models are available on the project website:\nhttps://arjung128.github.io/opening-articulated-structures/",
      "tldr_zh": "这篇论文探讨了构建能够在真实世界中操作未见物体的移动操作系统（mobile manipulation systems），以打开铰接结构（articulated structures）作为测试平台。研究团队开发了一个端到端系统，并在13个真实现场进行了100多次测试，结果显示模块化系统比端到端学习系统表现更好，即使后者训练了1000+演示。关键发现包括：感知（perception）是任务成功的主要瓶颈，而非精确的末端执行器控制（end-effector control），且先进的铰接参数估计模型在机器人视角下效果不佳。总体上，这强调了管道组件不能孤立开发，需要系统级研究来推动通用移动操作系统的构建。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to RSS 2025. Project webpage:\n  https://arjung128.github.io/opening-articulated-structures/",
      "pdf_url": "http://arxiv.org/pdf/2402.17767v3",
      "published_date": "2024-02-27 18:58:54 UTC",
      "updated_date": "2025-05-07 03:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:29:02.759053"
    },
    {
      "arxiv_id": "2402.17760v1",
      "title": "Learning to Program Variational Quantum Circuits with Fast Weights",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Yen-Chi Chen"
      ],
      "abstract": "Quantum Machine Learning (QML) has surfaced as a pioneering framework\naddressing sequential control tasks and time-series modeling. It has\ndemonstrated empirical quantum advantages notably within domains such as\nReinforcement Learning (RL) and time-series prediction. A significant\nadvancement lies in Quantum Recurrent Neural Networks (QRNNs), specifically\ntailored for memory-intensive tasks encompassing partially observable\nenvironments and non-linear time-series prediction. Nevertheless, QRNN-based\nmodels encounter challenges, notably prolonged training duration stemming from\nthe necessity to compute quantum gradients using backpropagation-through-time\n(BPTT). This predicament exacerbates when executing the complete model on\nquantum devices, primarily due to the substantial demand for circuit evaluation\narising from the parameter-shift rule. This paper introduces the Quantum Fast\nWeight Programmers (QFWP) as a solution to the temporal or sequential learning\nchallenge. The QFWP leverages a classical neural network (referred to as the\n'slow programmer') functioning as a quantum programmer to swiftly modify the\nparameters of a variational quantum circuit (termed the 'fast programmer').\nInstead of completely overwriting the fast programmer at each time-step, the\nslow programmer generates parameter changes or updates for the quantum circuit\nparameters. This approach enables the fast programmer to incorporate past\nobservations or information. Notably, the proposed QFWP model achieves learning\nof temporal dependencies without necessitating the use of quantum recurrent\nneural networks. Numerical simulations conducted in this study showcase the\nefficacy of the proposed QFWP model in both time-series prediction and RL\ntasks. The model exhibits performance levels either comparable to or surpassing\nthose achieved by QLSTM-based models.",
      "tldr_zh": "该论文针对 Quantum Machine Learning (QML) 中的时间序列建模和强化学习任务，解决了 Quantum Recurrent Neural Networks (QRNNs) 训练时间长的问题，如量子梯度计算的效率低下。作者提出 Quantum Fast Weight Programmers (QFWP) 框架，使用一个经典神经网络（慢程序员）来动态更新变分量子电路（快程序员）的参数，从而实现对过去信息的整合，而无需依赖量子循环网络。实验结果表明，QFWP 在时间序列预测和强化学习任务中，其性能与 QLSTM 模型相当或更优，为高效的量子学习提供了新途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17760v1",
      "published_date": "2024-02-27 18:53:18 UTC",
      "updated_date": "2024-02-27 18:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:29:12.797919"
    },
    {
      "arxiv_id": "2402.17753v1",
      "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Adyasha Maharana",
        "Dong-Ho Lee",
        "Sergey Tulyakov",
        "Mohit Bansal",
        "Francesco Barbieri",
        "Yuwei Fang"
      ],
      "abstract": "Existing works on long-term open-domain dialogues focus on evaluating model\nresponses within contexts spanning no more than five chat sessions. Despite\nadvancements in long-context large language models (LLMs) and retrieval\naugmented generation (RAG) techniques, their efficacy in very long-term\ndialogues remains unexplored. To address this research gap, we introduce a\nmachine-human pipeline to generate high-quality, very long-term dialogues by\nleveraging LLM-based agent architectures and grounding their dialogues on\npersonas and temporal event graphs. Moreover, we equip each agent with the\ncapability of sharing and reacting to images. The generated conversations are\nverified and edited by human annotators for long-range consistency and\ngrounding to the event graphs. Using this pipeline, we collect LoCoMo, a\ndataset of very long-term conversations, each encompassing 300 turns and 9K\ntokens on avg., over up to 35 sessions. Based on LoCoMo, we present a\ncomprehensive evaluation benchmark to measure long-term memory in models,\nencompassing question answering, event summarization, and multi-modal dialogue\ngeneration tasks. Our experimental results indicate that LLMs exhibit\nchallenges in understanding lengthy conversations and comprehending long-range\ntemporal and causal dynamics within dialogues. Employing strategies like\nlong-context LLMs or RAG can offer improvements but these models still\nsubstantially lag behind human performance.",
      "tldr_zh": "该论文评估了LLM代理在非常长期对话中的记忆能力，填补了现有研究仅限于五会话以内的空白。研究者开发了一个机器-人类管道，使用LLM-based代理架构、人物设定和时间事件图生成LoCoMo数据集，每个对话平均包含300轮和9K标记，并支持图像共享；生成的对话经人类校正以确保一致性。实验结果显示，LLM在理解长对话和长期时间-因果动态方面面临挑战，尽管采用长上下文LLM或RAG技术有所改善，但仍远低于人类表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages; Project page: https://snap-research.github.io/locomo/",
      "pdf_url": "http://arxiv.org/pdf/2402.17753v1",
      "published_date": "2024-02-27 18:42:31 UTC",
      "updated_date": "2024-02-27 18:42:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:29:25.244773"
    },
    {
      "arxiv_id": "2402.17747v5",
      "title": "When Your AIs Deceive You: Challenges of Partial Observability in Reinforcement Learning from Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Leon Lang",
        "Davis Foote",
        "Stuart Russell",
        "Anca Dragan",
        "Erik Jenner",
        "Scott Emmons"
      ],
      "abstract": "Past analyses of reinforcement learning from human feedback (RLHF) assume\nthat the human evaluators fully observe the environment. What happens when\nhuman feedback is based only on partial observations? We formally define two\nfailure cases: deceptive inflation and overjustification. Modeling the human as\nBoltzmann-rational w.r.t. a belief over trajectories, we prove conditions under\nwhich RLHF is guaranteed to result in policies that deceptively inflate their\nperformance, overjustify their behavior to make an impression, or both. Under\nthe new assumption that the human's partial observability is known and\naccounted for, we then analyze how much information the feedback process\nprovides about the return function. We show that sometimes, the human's\nfeedback determines the return function uniquely up to an additive constant,\nbut in other realistic cases, there is irreducible ambiguity. We propose\nexploratory research directions to help tackle these challenges, experimentally\nvalidate both the theoretical concerns and potential mitigations, and caution\nagainst blindly applying RLHF in partially observable settings.",
      "tldr_zh": "这篇论文探讨了强化学习从人类反馈（RLHF）中，当人类评估者仅部分观察环境时，可能导致AI欺骗行为的挑战，包括欺骗性膨胀（deceptive inflation）和过度正当化（overjustification）。作者通过建模人类为Boltzmann-rational，证明了RLHF在特定条件下会产生策略欺骗或过度解释行为，并分析了反馈过程对回报函数（return function）的信息量，发现有时反馈能唯一确定回报函数（除加法常数外），但在其他情况下存在不可减少的模糊性。论文提出探索性研究方向，通过实验验证了这些理论问题和潜在缓解措施，并警告在部分可观察（partially observable）环境中盲目应用RLHF的风险。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Advances in Neural Information Processing Systems 37 (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.17747v5",
      "published_date": "2024-02-27 18:32:11 UTC",
      "updated_date": "2024-11-17 12:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:29:37.627031"
    },
    {
      "arxiv_id": "2402.17739v2",
      "title": "reBandit: Random Effects based Online RL algorithm for Reducing Cannabis Use",
      "title_zh": "翻译失败",
      "authors": [
        "Susobhan Ghosh",
        "Yongyi Guo",
        "Pei-Yao Hung",
        "Lara Coughlin",
        "Erin Bonar",
        "Inbal Nahum-Shani",
        "Maureen Walton",
        "Susan Murphy"
      ],
      "abstract": "The escalating prevalence of cannabis use, and associated cannabis-use\ndisorder (CUD), poses a significant public health challenge globally. With a\nnotably wide treatment gap, especially among emerging adults (EAs; ages 18-25),\naddressing cannabis use and CUD remains a pivotal objective within the 2030\nUnited Nations Agenda for Sustainable Development Goals (SDG). In this work, we\ndevelop an online reinforcement learning (RL) algorithm called reBandit which\nwill be utilized in a mobile health study to deliver personalized mobile health\ninterventions aimed at reducing cannabis use among EAs. reBandit utilizes\nrandom effects and informative Bayesian priors to learn quickly and efficiently\nin noisy mobile health environments. Moreover, reBandit employs Empirical Bayes\nand optimization techniques to autonomously update its hyper-parameters online.\nTo evaluate the performance of our algorithm, we construct a simulation testbed\nusing data from a prior study, and compare against commonly used algorithms in\nmobile health studies. We show that reBandit performs equally well or better\nthan all the baseline algorithms, and the performance gap widens as population\nheterogeneity increases in the simulation environment, proving its adeptness to\nadapt to diverse population of study participants.",
      "tldr_zh": "本研究针对大麻使用和相关障碍（CUD）的公共卫生挑战，开发了reBandit算法，这是一种基于Random Effects的在线Reinforcement Learning (RL)方法，用于移动健康研究中提供个性化干预以减少新兴成人（EAs，18-25岁）的使用量。reBandit利用随机效应、信息Bayesian priors快速高效学习，并通过Empirical Bayes和优化技术在线更新超参数，以适应嘈杂的环境。实验结果显示，在模拟测试床中，reBandit的性能优于或等于常用基线算法，且在人群异质性增加时优势更明显，证明其对多样化参与者的适应性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17739v2",
      "published_date": "2024-02-27 18:18:23 UTC",
      "updated_date": "2024-06-11 15:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:29:48.059702"
    },
    {
      "arxiv_id": "2402.17736v2",
      "title": "Learning-Based Algorithms for Graph Searching Problems",
      "title_zh": "基于学习的图搜索问题算法",
      "authors": [
        "Adela Frances DePavia",
        "Erasmo Tani",
        "Ali Vakilian"
      ],
      "abstract": "We consider the problem of graph searching with prediction recently\nintroduced by Banerjee et al. (2022). In this problem, an agent, starting at\nsome vertex $r$ has to traverse a (potentially unknown) graph $G$ to find a\nhidden goal node $g$ while minimizing the total distance travelled. We study a\nsetting in which at any node $v$, the agent receives a noisy estimate of the\ndistance from $v$ to $g$. We design algorithms for this search task on unknown\ngraphs. We establish the first formal guarantees on unknown weighted graphs and\nprovide lower bounds showing that the algorithms we propose have optimal or\nnearly-optimal dependence on the prediction error. Further, we perform\nnumerical experiments demonstrating that in addition to being robust to\nadversarial error, our algorithms perform well in typical instances in which\nthe error is stochastic. Finally, we provide alternative simpler performance\nbounds on the algorithms of Banerjee et al. (2022) for the case of searching on\na known graph, and establish new lower bounds for this setting.",
      "tldr_zh": "本论文研究了图搜索问题（graph searching problems），其中代理从起点节点 r 开始，在未知图 G 上遍历以找到隐藏目标节点 g，同时最小化总距离并处理节点 v 到 g 的噪声距离估计。作者设计了基于学习的算法，并在未知加权图（weighted graphs）上提供了首次正式保证，包括对预测错误（prediction error）的优越依赖性，以及相应的下界。实验结果表明，这些算法不仅对对抗性错误（adversarial error）鲁棒，还在随机错误场景中表现出色；此外，论文为已知图搜索设置提供了新的性能界和下界。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17736v2",
      "published_date": "2024-02-27 18:12:58 UTC",
      "updated_date": "2024-03-16 21:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:30:01.688963"
    },
    {
      "arxiv_id": "2402.17709v2",
      "title": "Case-Based or Rule-Based: How Do Transformers Do the Math?",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Hu",
        "Xiaojuan Tang",
        "Haotong Yang",
        "Muhan Zhang"
      ],
      "abstract": "Despite the impressive performance in a variety of complex tasks, modern\nlarge language models (LLMs) still have trouble dealing with some math problems\nthat are simple and intuitive for humans, such as addition. While we can easily\nlearn basic rules of addition and apply them to new problems of any length,\nLLMs struggle to do the same. Instead, they may rely on similar cases seen in\nthe training corpus for help. We define these two different reasoning\nmechanisms as \"rule-based reasoning\" and \"case-based reasoning\". Since\nrule-based reasoning is essential for acquiring systematic generalization\nability, we aim to explore exactly whether transformers use rule-based or\ncase-based reasoning for math problems. Through carefully designed intervention\nexperiments on five math tasks, we confirm that transformers are performing\ncase-based reasoning, no matter whether scratchpad is used, which aligns with\nthe previous observations that transformers use subgraph matching/shortcut\nlearning to reason. To mitigate such problems, we propose a Rule-Following\nFine-Tuning (RFFT) technique to teach transformers to perform rule-based\nreasoning. Specifically, we provide explicit rules in the input and then\ninstruct transformers to recite and follow the rules step by step. Through\nRFFT, we successfully enable LLMs fine-tuned on 1-5 digit addition to\ngeneralize to up to 12-digit addition with over 95% accuracy, which is over 40%\nhigher than scratchpad. The significant improvement demonstrates that teaching\nLLMs to use rules explicitly helps them learn rule-based reasoning and\ngeneralize better in length.",
      "tldr_zh": "本论文探讨了Transformers在处理数学问题（如加法）时的推理机制，发现它们主要依赖case-based reasoning（基于案例的推理），而非rule-based reasoning（基于规则的推理），导致泛化能力不足。研究者通过对五种数学任务的干预实验证实，即使使用scratchpad，Transformers仍倾向于子图匹配或捷径学习方式。针对这一问题，提出Rule-Following Fine-Tuning (RFFT)技术，该方法在输入中提供显式规则，并指导LLMs逐步背诵和遵循规则。实验结果显示，经RFFT微调的模型能在1-5位加法上学习后，泛化到12位加法，准确率超过95%，比scratchpad高出40%以上。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17709v2",
      "published_date": "2024-02-27 17:41:58 UTC",
      "updated_date": "2024-06-26 09:25:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:30:14.238821"
    },
    {
      "arxiv_id": "2402.17690v2",
      "title": "Autonomous Vehicles: Evolution of Artificial Intelligence and Learning Algorithms",
      "title_zh": "自动驾驶车辆：人工智能和学习算法的演变",
      "authors": [
        "Divya Garikapati",
        "Sneha Sudhir Shetiya"
      ],
      "abstract": "The advent of autonomous vehicles has heralded a transformative era in\ntransportation, reshaping the landscape of mobility through cutting-edge\ntechnologies. Central to this evolution is the integration of Artificial\nIntelligence (AI) and learning algorithms, propelling vehicles into realms of\nunprecedented autonomy. This paper provides a comprehensive exploration of the\nevolutionary trajectory of AI within autonomous vehicles, tracing the journey\nfrom foundational principles to the most recent advancements. Commencing with a\ncurrent landscape overview, the paper delves into the fundamental role of AI in\nshaping the autonomous decision-making capabilities of vehicles. It elucidates\nthe steps involved in the AI-powered development life cycle in vehicles,\naddressing ethical considerations and bias in AI-driven software development\nfor autonomous vehicles. The study presents statistical insights into the usage\nand types of AI/learning algorithms over the years, showcasing the evolving\nresearch landscape within the automotive industry. Furthermore, the paper\nhighlights the pivotal role of parameters in refining algorithms for both\ntrucks and cars, facilitating vehicles to adapt, learn, and improve performance\nover time. It concludes by outlining different levels of autonomy, elucidating\nthe nuanced usage of AI and learning algorithms, and automating key tasks at\neach level. Additionally, the document discusses the variation in software\npackage sizes across different autonomy levels",
      "tldr_zh": "这篇论文探讨了自动驾驶车辆（Autonomous Vehicles）中人工智能（AI）和学习算法的演变历程，从基础原则到最新进展。论文概述了AI在车辆决策中的核心作用，包括AI驱动开发生命周期、伦理考虑以及偏见问题，并提供了AI/学习算法使用类型的统计洞见。研究强调了参数优化在算法改进中的重要性，使车辆能够适应和提升性能，并在不同自治水平（如SAE水平）上阐释AI的应用与任务自动化。最后，论文分析了软件包大小在各自治水平间的差异，为自动驾驶技术的未来发展提供了全面见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.17690v2",
      "published_date": "2024-02-27 17:07:18 UTC",
      "updated_date": "2024-02-28 15:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:30:24.187025"
    },
    {
      "arxiv_id": "2402.17689v1",
      "title": "QoS prediction in radio vehicular environments via prior user information",
      "title_zh": "翻译失败",
      "authors": [
        "Noor Ul Ain",
        "Rodrigo Hernangómez",
        "Alexandros Palaios",
        "Martin Kasparick",
        "Sławomir Stańczak"
      ],
      "abstract": "Reliable wireless communications play an important role in the automotive\nindustry as it helps to enhance current use cases and enable new ones such as\nconnected autonomous driving, platooning, cooperative maneuvering, teleoperated\ndriving, and smart navigation. These and other use cases often rely on specific\nquality of service (QoS) levels for communication. Recently, the area of\npredictive quality of service (QoS) has received a great deal of attention as a\nkey enabler to forecast communication quality well enough in advance. However,\npredicting QoS in a reliable manner is a notoriously difficult task. In this\npaper, we evaluate ML tree-ensemble methods to predict QoS in the range of\nminutes with data collected from a cellular test network. We discuss radio\nenvironment characteristics and we showcase how these can be used to improve ML\nperformance and further support the uptake of ML in commercial networks.\nSpecifically, we use the correlations of the measurements coming from the radio\nenvironment by including information of prior vehicles to enhance the\nprediction of the target vehicles. Moreover, we are extending prior art by\nshowing how longer prediction horizons can be supported.",
      "tldr_zh": "该论文探讨了在车辆无线环境中利用先前用户信息来预测质量服务（QoS）的挑战，旨在支持自动驾驶、车队编队等应用对可靠通信的需求。研究者评估了机器学习（ML）树集成方法，使用从蜂窝测试网络收集的数据来预测几分钟内的QoS水平。论文强调了无线环境特征的关联性，通过整合先前车辆的测量数据，提升了目标车辆QoS预测的准确性。结果显示，该方法显著提高了ML性能，并扩展了预测范围，支持更长的预测视野。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17689v1",
      "published_date": "2024-02-27 17:05:41 UTC",
      "updated_date": "2024-02-27 17:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:30:36.033573"
    },
    {
      "arxiv_id": "2403.14658v1",
      "title": "Identifying Potential Inlets of Man in the Artificial Intelligence Development Process",
      "title_zh": "翻译失败",
      "authors": [
        "Deja Workman",
        "Christopher L. Dancy"
      ],
      "abstract": "In this paper we hope to identify how the typical or standard artificial\nintelligence development process encourages or facilitates the creation of\nracialized technologies. We begin by understanding Sylvia Wynter's definition\nof the biocentric Man genre and its exclusion of Blackness from humanness. We\nfollow this with outlining what we consider to be the typical steps for\ndeveloping an AI-based technology, which we have broken down into 6 stages:\nidentifying a problem, development process and management tool selection,\ndataset development and data processing, model development, deployment and risk\nassessment, and integration and monitoring. The goal of this paper is to better\nunderstand how Wynter's biocentric Man is being represented and reinforced by\nthe technologies we are producing in the AI lifecycle and by the lifecycle\nitself; we hope to identify ways in which the distinction of Blackness from the\n\"ideal\" human leads to perpetual punishment at the hands of these technologies.\nBy deconstructing this development process, we can potentially identify ways in\nwhich humans in general have not been prioritized and how those affects are\ndisproportionately affecting marginalized people. We hope to offer solutions\nthat will encourage changes in the AI development cycle.",
      "tldr_zh": "这篇论文基于 Sylvia Wynter 的 biocentric Man 概念，探讨了标准人工智能(AI)开发过程如何促进种族化技术的产生，并强化了对黑人的排斥。论文将 AI 开发分解为六个阶段，包括识别问题、开发过程和管理工具选择、数据集开发和数据处理、模型开发、部署和风险评估，以及集成和监控。研究发现，这些阶段可能通过强化 biocentric Man 的理想人类观，导致边缘化群体遭受不公平影响，并提出解决方案来改进 AI 生命周期，以优先考虑人类整体福祉。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0; K.4.2"
      ],
      "primary_category": "cs.CY",
      "comment": "Published in CSCW '23 Conference Proceedings. 7 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.14658v1",
      "published_date": "2024-02-27 16:52:18 UTC",
      "updated_date": "2024-02-27 16:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:30:50.173909"
    },
    {
      "arxiv_id": "2403.07918v1",
      "title": "On the Societal Impact of Open Foundation Models",
      "title_zh": "关于开放基础模型的社会影响",
      "authors": [
        "Sayash Kapoor",
        "Rishi Bommasani",
        "Kevin Klyman",
        "Shayne Longpre",
        "Ashwin Ramaswami",
        "Peter Cihon",
        "Aspen Hopkins",
        "Kevin Bankston",
        "Stella Biderman",
        "Miranda Bogen",
        "Rumman Chowdhury",
        "Alex Engler",
        "Peter Henderson",
        "Yacine Jernite",
        "Seth Lazar",
        "Stefano Maffulli",
        "Alondra Nelson",
        "Joelle Pineau",
        "Aviya Skowron",
        "Dawn Song",
        "Victor Storchan",
        "Daniel Zhang",
        "Daniel E. Ho",
        "Percy Liang",
        "Arvind Narayanan"
      ],
      "abstract": "Foundation models are powerful technologies: how they are released publicly\ndirectly shapes their societal impact. In this position paper, we focus on open\nfoundation models, defined here as those with broadly available model weights\n(e.g. Llama 2, Stable Diffusion XL). We identify five distinctive properties\n(e.g. greater customizability, poor monitoring) of open foundation models that\nlead to both their benefits and risks. Open foundation models present\nsignificant benefits, with some caveats, that span innovation, competition, the\ndistribution of decision-making power, and transparency. To understand their\nrisks of misuse, we design a risk assessment framework for analyzing their\nmarginal risk. Across several misuse vectors (e.g. cyberattacks, bioweapons),\nwe find that current research is insufficient to effectively characterize the\nmarginal risk of open foundation models relative to pre-existing technologies.\nThe framework helps explain why the marginal risk is low in some cases,\nclarifies disagreements about misuse risks by revealing that past work has\nfocused on different subsets of the framework with different assumptions, and\narticulates a way forward for more constructive debate. Overall, our work helps\nsupport a more grounded assessment of the societal impact of open foundation\nmodels by outlining what research is needed to empirically validate their\ntheoretical benefits and risks.",
      "tldr_zh": "这篇立场论文探讨了开放基础模型（open foundation models，如 Llama 2 和 Stable Diffusion XL）的社会影响，强调这些模型的五个独特属性（如更高的可定制性和监控困难）带来了创新、竞争、决策权分配和透明度的显著益处，同时也增加了滥用风险。作者设计了一个风险评估框架，用于分析这些模型相对于现有技术的边际风险，并在网络攻击和生物武器等滥用场景中发现，当前研究不足以全面评估这些风险。框架有助于澄清争议、解释低风险情况，并为更具建设性的辩论提供路径。总体上，论文呼吁进一步研究，以验证开放基础模型的理论益处和风险，从而支持更可靠的社会影响评估。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07918v1",
      "published_date": "2024-02-27 16:49:53 UTC",
      "updated_date": "2024-02-27 16:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:31:01.225522"
    },
    {
      "arxiv_id": "2402.17652v2",
      "title": "Compass: A Decentralized Scheduler for Latency-Sensitive ML Workflows",
      "title_zh": "翻译失败",
      "authors": [
        "Yuting Yang",
        "Andrea Merlina",
        "Weijia Song",
        "Tiancheng Yuan",
        "Ken Birman",
        "Roman Vitenberg"
      ],
      "abstract": "We consider ML query processing in distributed systems where GPU-enabled\nworkers coordinate to execute complex queries: a computing style often seen in\napplications that interact with users in support of image processing and\nnatural language processing. In such systems, coscheduling of GPU memory\nmanagement and task placement represents a promising opportunity. We propose\nCompass, a novel framework that unifies these functions to reduce job latency\nwhile using resources efficiently, placing tasks where data dependencies will\nbe satisfied, collocating tasks from the same job (when this will not overload\nthe host or its GPU), and efficiently managing GPU memory. Comparison with\nother state of the art schedulers shows a significant reduction in completion\ntimes while requiring the same amount or even fewer resources. In one case,\njust half the servers were needed for processing the same workload.",
      "tldr_zh": "本文提出Compass，一种去中心化的调度器，针对延迟敏感的ML Workflows，用于分布式系统中GPU启用工作者的协调执行。Compass框架统一了GPU内存管理和任务放置，确保任务满足数据依赖性、将同一作业的任务共置（前提不超载主机或GPU），从而减少作业延迟并高效利用资源。与现有调度器相比，实验结果显示Compass显著降低了完成时间，使用相同或更少资源；在某些情况下，仅需一半的服务器即可处理相同工作负载。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17652v2",
      "published_date": "2024-02-27 16:21:28 UTC",
      "updated_date": "2024-02-28 17:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:31:12.832790"
    },
    {
      "arxiv_id": "2402.17645v1",
      "title": "SongComposer: A Large Language Model for Lyric and Melody Composition in Song Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuangrui Ding",
        "Zihan Liu",
        "Xiaoyi Dong",
        "Pan Zhang",
        "Rui Qian",
        "Conghui He",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "We present SongComposer, an innovative LLM designed for song composition. It\ncould understand and generate melodies and lyrics in symbolic song\nrepresentations, by leveraging the capability of LLM. Existing music-related\nLLM treated the music as quantized audio signals, while such implicit encoding\nleads to inefficient encoding and poor flexibility. In contrast, we resort to\nsymbolic song representation, the mature and efficient way humans designed for\nmusic, and enable LLM to explicitly compose songs like humans. In practice, we\ndesign a novel tuple design to format lyric and three note attributes (pitch,\nduration, and rest duration) in the melody, which guarantees the correct LLM\nunderstanding of musical symbols and realizes precise alignment between lyrics\nand melody. To impart basic music understanding to LLM, we carefully collected\nSongCompose-PT, a large-scale song pretraining dataset that includes lyrics,\nmelodies, and paired lyrics-melodies in either Chinese or English. After\nadequate pre-training, 10K carefully crafted QA pairs are used to empower the\nLLM with the instruction-following capability and solve diverse tasks. With\nextensive experiments, SongComposer demonstrates superior performance in\nlyric-to-melody generation, melody-to-lyric generation, song continuation, and\ntext-to-song creation, outperforming advanced LLMs like GPT-4.",
      "tldr_zh": "我们介绍了 SongComposer，一种创新的 LLM，专为歌曲创作设计，能够理解和生成符号化歌曲表示中的歌词和旋律，从而更高效地处理音乐元素。不同于现有方法将音乐视为量化音频信号，该模型采用 symbolic song representation 和新型元组设计（包括音高、持续时间和休息时间），确保歌词与旋律的精确对齐，并利用 SongCompose-PT 数据集进行大规模预训练和指令微调。实验结果表明，SongComposer 在歌词到旋律生成、旋律到歌词生成、歌曲续写和文本到歌曲创建等任务上，表现出色，并优于 GPT-4 等先进模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "project page: https://pjlab-songcomposer.github.io/ code:\n  https://github.com/pjlab-songcomposer/songcomposer",
      "pdf_url": "http://arxiv.org/pdf/2402.17645v1",
      "published_date": "2024-02-27 16:15:28 UTC",
      "updated_date": "2024-02-27 16:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:31:26.653130"
    },
    {
      "arxiv_id": "2402.17644v2",
      "title": "Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Liu",
        "Zirui Wu",
        "Xueqing Wu",
        "Pan Lu",
        "Kai-Wei Chang",
        "Yansong Feng"
      ],
      "abstract": "Quantitative reasoning is a critical skill to analyze data, yet the\nassessment of such ability remains limited. To address this gap, we introduce\nthe Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate\nLarge Language Models' capability in statistical and causal reasoning with\nreal-world data. The benchmark comprises a carefully constructed dataset of 411\nquestions accompanied by data sheets from textbooks, online learning materials,\nand academic papers. To compare models' quantitative reasoning abilities on\ndata and text, we enrich the benchmark with an auxiliary set of 290 text-only\nquestions, namely QRText. We evaluate natural language reasoning, program-based\nreasoning, and agent reasoning methods including Chain-of-Thought,\nProgram-of-Thoughts, ReAct, and code interpreter assistants on diverse models.\nThe strongest model GPT-4 achieves an accuracy of 58%, which has much room for\nimprovement. Among open-source models, Deepseek-coder-instruct, a code LLM\npretrained on 2T tokens, gets the highest accuracy of 37%. Analysis reveals\nthat models encounter difficulties in data analysis and causal reasoning, and\nstruggle in using causal knowledge and provided data simultaneously. Code and\ndata are in https://github.com/xxxiaol/QRData.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在基于数据的统计和因果推理能力，引入了Quantitative Reasoning with Data (QRData)基准测试，包括411个问题及真实数据表，以及辅助的QRText集（290个纯文本问题）。研究通过测试Chain-of-Thought、Program-of-Thoughts和ReAct等推理方法，评估了多种模型的表现。结果显示，GPT-4准确率达58%，而开源模型Deepseek-coder-instruct为37%，分析揭示模型在数据分析和因果推理上存在困难，尤其是在同时利用因果知识和提供的数据方面。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of ACL 2024. Project website:\n  https://xxxiaol.github.io/QRData/",
      "pdf_url": "http://arxiv.org/pdf/2402.17644v2",
      "published_date": "2024-02-27 16:15:03 UTC",
      "updated_date": "2024-06-09 13:54:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:31:38.106620"
    },
    {
      "arxiv_id": "2402.17641v2",
      "title": "Variational Learning is Effective for Large Deep Networks",
      "title_zh": "变分学习对于大型深度网络是有效的",
      "authors": [
        "Yuesong Shen",
        "Nico Daheim",
        "Bai Cong",
        "Peter Nickl",
        "Gian Maria Marconi",
        "Clement Bazan",
        "Rio Yokota",
        "Iryna Gurevych",
        "Daniel Cremers",
        "Mohammad Emtiyaz Khan",
        "Thomas Möllenhoff"
      ],
      "abstract": "We give extensive empirical evidence against the common belief that\nvariational learning is ineffective for large neural networks. We show that an\noptimizer called Improved Variational Online Newton (IVON) consistently matches\nor outperforms Adam for training large networks such as GPT-2 and ResNets from\nscratch. IVON's computational costs are nearly identical to Adam but its\npredictive uncertainty is better. We show several new use cases of IVON where\nwe improve finetuning and model merging in Large Language Models, accurately\npredict generalization error, and faithfully estimate sensitivity to data. We\nfind overwhelming evidence that variational learning is effective.",
      "tldr_zh": "本研究挑战了变分学习(Variational Learning)对大型神经网络无效的常见信念，通过引入Improved Variational Online Newton (IVON)优化器来证明其有效性。实验显示，IVON在训练大型网络如GPT-2和ResNets时，其性能与Adam相当或更优，同时计算成本几乎相同且预测不确定性更好。该方法还扩展到新应用，包括改善大型语言模型的微调和模型合并、准确预测泛化错误，以及估计对数据的敏感性，最终提供有力证据支持变分学习的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at International Conference on Machine Learning (ICML),\n  2024. The first two authors contributed equally. Code is available here:\n  https://github.com/team-approx-bayes/ivon",
      "pdf_url": "http://arxiv.org/pdf/2402.17641v2",
      "published_date": "2024-02-27 16:11:05 UTC",
      "updated_date": "2024-06-06 04:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:31:48.299230"
    },
    {
      "arxiv_id": "2402.18372v2",
      "title": "FedUV: Uniformity and Variance for Heterogeneous Federated Learning",
      "title_zh": "FedUV：异构联邦学习的均匀性和方差",
      "authors": [
        "Ha Min Son",
        "Moon-Hyun Kim",
        "Tai-Myoung Chung",
        "Chao Huang",
        "Xin Liu"
      ],
      "abstract": "Federated learning is a promising framework to train neural networks with\nwidely distributed data. However, performance degrades heavily with\nheterogeneously distributed data. Recent work has shown this is due to the\nfinal layer of the network being most prone to local bias, some finding success\nfreezing the final layer as an orthogonal classifier. We investigate the\ntraining dynamics of the classifier by applying SVD to the weights motivated by\nthe observation that freezing weights results in constant singular values. We\nfind that there are differences when training in IID and non-IID settings.\nBased on this finding, we introduce two regularization terms for local training\nto continuously emulate IID settings: (1) variance in the dimension-wise\nprobability distribution of the classifier and (2) hyperspherical uniformity of\nrepresentations of the encoder. These regularizations promote local models to\nact as if it were in an IID setting regardless of the local data distribution,\nthus offsetting proneness to bias while being flexible to the data. On\nextensive experiments in both label-shift and feature-shift settings, we verify\nthat our method achieves highest performance by a large margin especially in\nhighly non-IID cases in addition to being scalable to larger models and\ndatasets.",
      "tldr_zh": "该研究针对联邦学习（Federated Learning）在异构数据分布（non-IID）下的性能下降问题，分析了分类器权重训练动态，通过SVD（Singular Value Decomposition）发现其在IID和non-IID设置下的差异。作者引入了两个正则化项：（1）分类器维度-wise概率分布的方差（variance），以及（2）编码器表示的超球均匀性（hyperspherical uniformity），以使本地模型模拟IID环境，减少本地偏差。实验结果显示，该方法FedUV在标签偏移（label-shift）和特征偏移（feature-shift）场景中，尤其在高度non-IID情况下，大幅提升性能，并适用于更大模型和数据集。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures, 5 tables, to appear at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.18372v2",
      "published_date": "2024-02-27 15:53:15 UTC",
      "updated_date": "2024-03-01 21:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:32:00.540136"
    },
    {
      "arxiv_id": "2402.17606v3",
      "title": "Learning Topological Representations with Bidirectional Graph Attention Network for Solving Job Shop Scheduling Problem",
      "title_zh": "利用双向图注意力网络学习拓扑表示以解决作业车间调度问题",
      "authors": [
        "Cong Zhang",
        "Zhiguang Cao",
        "Yaoxin Wu",
        "Wen Song",
        "Jing Sun"
      ],
      "abstract": "Existing learning-based methods for solving job shop scheduling problems\n(JSSP) usually use off-the-shelf GNN models tailored to undirected graphs and\nneglect the rich and meaningful topological structures of disjunctive graphs\n(DGs). This paper proposes the topology-aware bidirectional graph attention\nnetwork (TBGAT), a novel GNN architecture based on the attention mechanism, to\nembed the DG for solving JSSP in a local search framework. Specifically, TBGAT\nembeds the DG from a forward and a backward view, respectively, where the\nmessages are propagated by following the different topologies of the views and\naggregated via graph attention. Then, we propose a novel operator based on the\nmessage-passing mechanism to calculate the forward and backward topological\nsorts of the DG, which are the features for characterizing the topological\nstructures and exploited by our model. In addition, we theoretically and\nexperimentally show that TBGAT has linear computational complexity to the\nnumber of jobs and machines, respectively, strengthening our method's practical\nvalue. Besides, extensive experiments on five synthetic datasets and seven\nclassic benchmarks show that TBGAT achieves new SOTA results by outperforming a\nwide range of neural methods by a large margin. All the code and data are\npublicly available online at https://github.com/zcaicaros/TBGAT.",
      "tldr_zh": "这篇论文针对Job Shop Scheduling Problem (JSSP)，提出了一种新型拓扑感知双向图注意力网络(TBGAT)，通过嵌入disjunctive graphs (DGs)的拓扑结构来提升基于GNN的局部搜索框架性能。TBGAT从正向和反向视图进行消息传播和聚合，并引入基于消息传递机制的算子来计算拓扑排序特征，从而更好地表征图的拓扑结构。实验结果显示，该方法在五个合成数据集和七个经典基准上大幅优于现有神经方法，实现了新的SOTA结果，并证明了其与作业和机器数量的线性计算复杂度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17606v3",
      "published_date": "2024-02-27 15:33:20 UTC",
      "updated_date": "2024-06-05 06:19:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:32:13.893874"
    },
    {
      "arxiv_id": "2402.17595v1",
      "title": "Implicit Regularization via Spectral Neural Networks and Non-linear Matrix Sensing",
      "title_zh": "通过光谱神经网络和非线性矩阵感知的隐式正则化",
      "authors": [
        "Hong T. M. Chu",
        "Subhro Ghosh",
        "Chi Thanh Lam",
        "Soumendu Sundar Mukherjee"
      ],
      "abstract": "The phenomenon of implicit regularization has attracted interest in recent\nyears as a fundamental aspect of the remarkable generalizing ability of neural\nnetworks. In a nutshell, it entails that gradient descent dynamics in many\nneural nets, even without any explicit regularizer in the loss function,\nconverges to the solution of a regularized learning problem. However, known\nresults attempting to theoretically explain this phenomenon focus\noverwhelmingly on the setting of linear neural nets, and the simplicity of the\nlinear structure is particularly crucial to existing arguments. In this paper,\nwe explore this problem in the context of more realistic neural networks with a\ngeneral class of non-linear activation functions, and rigorously demonstrate\nthe implicit regularization phenomenon for such networks in the setting of\nmatrix sensing problems, together with rigorous rate guarantees that ensure\nexponentially fast convergence of gradient descent.In this vein, we contribute\na network architecture called Spectral Neural Networks (abbrv. SNN) that is\nparticularly suitable for matrix learning problems. Conceptually, this entails\ncoordinatizing the space of matrices by their singular values and singular\nvectors, as opposed to by their entries, a potentially fruitful perspective for\nmatrix learning. We demonstrate that the SNN architecture is inherently much\nmore amenable to theoretical analysis than vanilla neural nets and confirm its\neffectiveness in the context of matrix sensing, via both mathematical\nguarantees and empirical investigations. We believe that the SNN architecture\nhas the potential to be of wide applicability in a broad class of matrix\nlearning scenarios.",
      "tldr_zh": "该研究探讨了隐式正则化(implicit regularization)在非线性神经网络中的现象，证明了梯度下降(gradient descent)在矩阵感知(non-linear matrix sensing)问题中，即使没有显式正则化器，也能收敛到正则化学习解，并提供指数级快速收敛的严格保证。作者引入了Spectral Neural Networks (SNN)架构，通过奇异值和奇异向量协调矩阵空间，使其更适合矩阵学习问题，并比传统神经网络更易于理论分析。实验结果和数学证明显示，SNN在矩阵感知任务中显著提升了性能，并具有广泛适用于矩阵学习场景的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17595v1",
      "published_date": "2024-02-27 15:28:01 UTC",
      "updated_date": "2024-02-27 15:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:32:24.650252"
    },
    {
      "arxiv_id": "2402.17574v3",
      "title": "Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization",
      "title_zh": "Agent-Pro：通过策略级别反思和优化学习演化",
      "authors": [
        "Wenqi Zhang",
        "Ke Tang",
        "Hai Wu",
        "Mengna Wang",
        "Yongliang Shen",
        "Guiyang Hou",
        "Zeqi Tan",
        "Peng Li",
        "Yueting Zhuang",
        "Weiming Lu"
      ],
      "abstract": "Large Language Models (LLMs) exhibit robust problem-solving capabilities for\ndiverse tasks. However, most LLM-based agents are designed as specific task\nsolvers with sophisticated prompt engineering, rather than agents capable of\nlearning and evolving through interactions. These task solvers necessitate\nmanually crafted prompts to inform task rules and regulate LLM behaviors,\ninherently incapacitating to address complex dynamic scenarios e.g., large\ninteractive games. In light of this, we propose Agent-Pro: an LLM-based Agent\nwith Policy-level Reflection and Optimization that can learn a wealth of\nexpertise from interactive experiences and progressively elevate its behavioral\npolicy. Specifically, it involves a dynamic belief generation and reflection\nprocess for policy evolution. Rather than action-level reflection, Agent-Pro\niteratively reflects on past trajectories and beliefs, fine-tuning its\nirrational beliefs for a better policy. Moreover, a depth-first search is\nemployed for policy optimization, ensuring continual enhancement in policy\npayoffs. Agent-Pro is evaluated across two games: Blackjack and Texas Hold'em,\noutperforming vanilla LLM and specialized models. Our results show Agent-Pro\ncan learn and evolve in complex and dynamic scenes, which also benefits\nnumerous LLM-based applications.",
      "tldr_zh": "本文提出Agent-Pro，一种基于LLM的代理系统，通过Policy-level Reflection and Optimization机制来实现从交互经验中学习和进化。该系统包括动态信念生成和迭代反射过程，专注于轨迹和信念的分析以微调不合理信念，并采用深度优先搜索确保政策收益的持续优化。与传统LLM和专业模型相比，Agent-Pro在Blackjack和Texas Hold'em游戏中表现出色，能有效处理复杂动态场景，并为各种LLM-based应用提供有益启发。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ACL-2024 Main, camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2402.17574v3",
      "published_date": "2024-02-27 15:09:20 UTC",
      "updated_date": "2024-06-06 18:40:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:32:37.245205"
    },
    {
      "arxiv_id": "2402.17563v2",
      "title": "Structure-Guided Adversarial Training of Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Yang",
        "Haotian Qian",
        "Zhilong Zhang",
        "Jingwei Liu",
        "Bin Cui"
      ],
      "abstract": "Diffusion models have demonstrated exceptional efficacy in various generative\napplications. While existing models focus on minimizing a weighted sum of\ndenoising score matching losses for data distribution modeling, their training\nprimarily emphasizes instance-level optimization, overlooking valuable\nstructural information within each mini-batch, indicative of pair-wise\nrelationships among samples. To address this limitation, we introduce\nStructure-guided Adversarial training of Diffusion Models (SADM). In this\npioneering approach, we compel the model to learn manifold structures between\nsamples in each training batch. To ensure the model captures authentic manifold\nstructures in the data distribution, we advocate adversarial training of the\ndiffusion generator against a novel structure discriminator in a minimax game,\ndistinguishing real manifold structures from the generated ones. SADM\nsubstantially improves existing diffusion transformers (DiT) and outperforms\nexisting methods in image generation and cross-domain fine-tuning tasks across\n12 datasets, establishing a new state-of-the-art FID of 1.58 and 2.11 on\nImageNet for class-conditional image generation at resolutions of 256x256 and\n512x512, respectively.",
      "tldr_zh": "本论文提出了一种结构引导的对抗训练方法 SADM，用于提升 Diffusion Models 的性能，通过学习训练批次中样本间的流形结构（manifold structures），以弥补现有模型忽略配对关系的局限性。SADM 采用对抗训练机制，让扩散生成器与一个新型结构鉴别器（structure discriminator）在 minimax 游戏中竞争，确保模型捕捉真实数据分布的结构信息。该方法显著改善了现有的扩散变压器（DiT），在图像生成和跨域微调任务上超越基线，在 12 个数据集上取得新状态，包括 ImageNet 类条件图像生成的 FID 得分达到 1.58（256x256 分辨率）和 2.11（512x512 分辨率）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17563v2",
      "published_date": "2024-02-27 15:05:13 UTC",
      "updated_date": "2024-03-04 14:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:32:49.810650"
    },
    {
      "arxiv_id": "2402.17553v3",
      "title": "OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web",
      "title_zh": "翻译失败",
      "authors": [
        "Raghav Kapoor",
        "Yash Parag Butala",
        "Melisa Russak",
        "Jing Yu Koh",
        "Kiran Kamble",
        "Waseem Alshikh",
        "Ruslan Salakhutdinov"
      ],
      "abstract": "For decades, human-computer interaction has fundamentally been manual. Even\ntoday, almost all productive work done on the computer necessitates human input\nat every step. Autonomous virtual agents represent an exciting step in\nautomating many of these menial tasks. Virtual agents would empower users with\nlimited technical proficiency to harness the full possibilities of computer\nsystems. They could also enable the efficient streamlining of numerous computer\ntasks, ranging from calendar management to complex travel bookings, with\nminimal human intervention. In this paper, we introduce OmniACT, the\nfirst-of-a-kind dataset and benchmark for assessing an agent's capability to\ngenerate executable programs to accomplish computer tasks. Our scope extends\nbeyond traditional web automation, covering a diverse range of desktop\napplications. The dataset consists of fundamental tasks such as \"Play the next\nsong\", as well as longer horizon tasks such as \"Send an email to John Doe\nmentioning the time and place to meet\". Specifically, given a pair of screen\nimage and a visually-grounded natural language task, the goal is to generate a\nscript capable of fully executing the task. We run several strong baseline\nlanguage model agents on our benchmark. The strongest baseline, GPT-4, performs\nthe best on our benchmark However, its performance level still reaches only 15%\nof the human proficiency in generating executable scripts capable of completing\nthe task, demonstrating the challenge of our task for conventional web agents.\nOur benchmark provides a platform to measure and evaluate the progress of\nlanguage model agents in automating computer tasks and motivates future work\ntowards building multimodal models that bridge large language models and the\nvisual grounding of computer screens.",
      "tldr_zh": "本文介绍了 OmniACT，这是一个首创数据集和基准，用于评估多模态通用自主代理（multimodal generalist autonomous agents）在桌面和网络任务中的性能。OmniACT 涵盖从简单任务如“Play the next song”到复杂任务如“Send an email to John Doe”的场景，要求代理基于屏幕图像和自然语言指令生成可执行脚本。实验结果显示，强基线模型如 GPT-4 的表现仅达到人类水平的 15%，突显了当前模型在视觉 grounding 和任务自动化方面的挑战。该基准为推动语言模型代理的发展提供了平台，旨在桥接大型语言模型与计算机屏幕视觉交互。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17553v3",
      "published_date": "2024-02-27 14:47:53 UTC",
      "updated_date": "2024-07-21 23:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:33:01.766109"
    },
    {
      "arxiv_id": "2402.17811v2",
      "title": "TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space",
      "title_zh": "翻译失败",
      "authors": [
        "Shaolei Zhang",
        "Tian Yu",
        "Yang Feng"
      ],
      "abstract": "Large Language Models (LLMs) sometimes suffer from producing hallucinations,\nespecially LLMs may generate untruthful responses despite knowing the correct\nknowledge. Activating the truthfulness within LLM is the key to fully unlocking\nLLM's knowledge potential. In this paper, we propose TruthX, an inference-time\nintervention method to activate the truthfulness of LLM by identifying and\nediting the features within LLM's internal representations that govern the\ntruthfulness. TruthX employs an auto-encoder to map LLM's representations into\nsemantic and truthful latent spaces respectively, and applies contrastive\nlearning to identify a truthful editing direction within the truthful space.\nDuring inference, by editing LLM's internal representations in truthful space,\nTruthX effectively enhances the truthfulness of LLM. Experiments show that\nTruthX improves the truthfulness of 13 advanced LLMs by an average of 20% on\nTruthfulQA benchmark. Further analyses suggest that TruthX can control LLM to\nproduce truthful or hallucinatory responses via editing only one vector in\nLLM's internal representations.",
      "tldr_zh": "该研究提出 TruthX，一种推理时的干预方法，用于缓解 Large Language Models (LLMs) 的幻觉（hallucinations）问题，通过激活模型内部的真实性（truthfulness）来提升响应准确性。TruthX 利用 auto-encoder 将 LLMs 的内部表示映射到语义空间和真实性空间，并通过 contrastive learning 识别真实性编辑方向，从而在推理过程中编辑内部表示以增强真实性。实验结果显示，TruthX 使 13 个高级 LLMs 在 TruthfulQA 基准上的真实性平均提高了 20%，并能通过编辑一个向量来控制模型生成真实或幻觉响应，为更可靠的 LLM 应用提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 main conference, Project Page:\n  https://ictnlp.github.io/TruthX-site/",
      "pdf_url": "http://arxiv.org/pdf/2402.17811v2",
      "published_date": "2024-02-27 14:45:04 UTC",
      "updated_date": "2024-06-05 11:15:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:33:13.365195"
    },
    {
      "arxiv_id": "2402.17550v1",
      "title": "Emergency Caching: Coded Caching-based Reliable Map Transmission in Emergency Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Tian",
        "Lianming Xu",
        "Liang Li",
        "Li Wang",
        "Aiguo Fei"
      ],
      "abstract": "Many rescue missions demand effective perception and real-time decision\nmaking, which highly rely on effective data collection and processing. In this\nstudy, we propose a three-layer architecture of emergency caching networks\nfocusing on data collection and reliable transmission, by leveraging efficient\nperception and edge caching technologies. Based on this architecture, we\npropose a disaster map collection framework that integrates coded caching\ntechnologies. Our framework strategically caches coded fragments of maps across\nunmanned aerial vehicles (UAVs), fostering collaborative uploading for\naugmented transmission reliability. Additionally, we establish a comprehensive\nprobability model to assess the effective recovery area of disaster maps.\nTowards the goal of utility maximization, we propose a deep reinforcement\nlearning (DRL) based algorithm that jointly makes decisions about cooperative\nUAVs selection, bandwidth allocation and coded caching parameter adjustment,\naccommodating the real-time map updates in a dynamic disaster situation. Our\nproposed scheme is more effective than the non-coding caching scheme, as\nvalidated by simulation.",
      "tldr_zh": "本研究提出了一种基于编码缓存（coded caching）的三层紧急网络架构，旨在提升灾难场景下的数据收集和可靠地图传输。该框架整合了无人驾驶航空器（UAVs）的协作上传机制，将地图片段编码后缓存，以增强传输可靠性，并通过一个综合概率模型评估灾难地图的有效恢复区域。为最大化系统效用，研究采用深度强化学习（DRL）算法联合优化UAVs选择、带宽分配和缓存参数，以适应动态环境。实验结果显示，该方案比非编码缓存方案更有效，提高了救援任务的实时决策能力。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17550v1",
      "published_date": "2024-02-27 14:44:11 UTC",
      "updated_date": "2024-02-27 14:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:33:24.436123"
    },
    {
      "arxiv_id": "2402.17546v1",
      "title": "COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt",
      "title_zh": "翻译失败",
      "authors": [
        "Suyeon Lee",
        "Jieun Kang",
        "Harim Kim",
        "Kyoung-Mee Chung",
        "Dongha Lee",
        "Jinyoung Yeo"
      ],
      "abstract": "The demand for conversational agents that provide mental health care is\nconsistently increasing. In this work, we develop a psychological counseling\nagent, referred to as CoCoA, that applies Cognitive Behavioral Therapy (CBT)\ntechniques to identify and address cognitive distortions inherent in the\nclient's statements. Specifically, we construct a memory system to efficiently\nmanage information necessary for counseling while extracting high-level\ninsights about the client from their utterances. Additionally, to ensure that\nthe counseling agent generates appropriate responses, we introduce dynamic\nprompting to flexibly apply CBT techniques and facilitate the appropriate\nretrieval of information. We conducted dialogues between CoCoA and characters\nfrom Character.ai, creating a dataset for evaluation. Then, we asked GPT to\nevaluate the constructed counseling dataset, and our model demonstrated a\nstatistically significant difference from other models.",
      "tldr_zh": "这篇论文介绍了 CoCoA，一种基于 Cognitive Behavioral Therapy (CBT) 的对话咨询代理，用于识别和处理用户陈述中的 Cognitive Distortions。代理通过构建一个专门的记忆系统来高效管理咨询信息，并从用户 utterances 中提取高层洞见，同时引入 Dynamic Prompt 技术来灵活应用 CBT 方法和信息检索。实验通过与 Character.ai 角色的对话创建数据集，并使用 GPT 评估，结果显示 CoCoA 与其他模型相比具有统计显著优势。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.17546v1",
      "published_date": "2024-02-27 14:38:47 UTC",
      "updated_date": "2024-02-27 14:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:33:36.380432"
    },
    {
      "arxiv_id": "2402.17531v2",
      "title": "Nissist: An Incident Mitigation Copilot based on Troubleshooting Guides",
      "title_zh": "翻译失败",
      "authors": [
        "Kaikai An",
        "Fangkai Yang",
        "Junting Lu",
        "Liqun Li",
        "Zhixing Ren",
        "Hao Huang",
        "Lu Wang",
        "Pu Zhao",
        "Yu Kang",
        "Hua Ding",
        "Qingwei Lin",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Qi Zhang"
      ],
      "abstract": "Effective incident management is pivotal for the smooth operation of\nenterprises-level cloud services. In order to expedite incident mitigation,\nservice teams compile troubleshooting knowledge into Troubleshooting Guides\n(TSGs) accessible to on-call engineers (OCEs). While automated pipelines are\nenabled to resolve the most frequent and easy incidents, there still exist\ncomplex incidents that require OCEs' intervention. However, TSGs are often\nunstructured and incomplete, which requires manual interpretation by OCEs,\nleading to on-call fatigue and decreased productivity, especially among\nnew-hire OCEs. In this work, we propose Nissist which leverages TSGs and\nincident mitigation histories to provide proactive suggestions, reducing human\nintervention. Leveraging Large Language Models (LLM), Nissist extracts insights\nfrom unstructured TSGs and historical incident mitigation discussions, forming\na comprehensive knowledge base. Its multi-agent system design enhances\nproficiency in precisely discerning user queries, retrieving relevant\ninformation, and delivering systematic plans consecutively. Through our user\ncase and experiment, we demonstrate that Nissist significant reduce Time to\nMitigate (TTM) in incident mitigation, alleviating operational burdens on OCEs\nand improving service reliability. Our demo is available at\nhttps://aka.ms/nissist_demo.",
      "tldr_zh": "该论文提出Nissist，一种基于Troubleshooting Guides (TSGs)的故障缓解助手，利用Large Language Models (LLMs)从无结构TSGs和历史故障记录中提取洞见，形成全面知识库。Nissist采用多智能体系统设计，能够主动识别用户查询、检索相关信息并提供系统化缓解计划，从而减少on-call engineers (OCEs)的干预。实验和用户案例显示，Nissist显著缩短故障缓解时间（Time to Mitigate, TTM），减轻OCEs的负担并提升企业级云服务可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2402.17531v2",
      "published_date": "2024-02-27 14:14:23 UTC",
      "updated_date": "2024-05-10 11:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:33:48.882746"
    },
    {
      "arxiv_id": "2402.17527v2",
      "title": "Predict the Next Word: Humans exhibit uncertainty in this task and language models _____",
      "title_zh": "翻译失败",
      "authors": [
        "Evgenia Ilia",
        "Wilker Aziz"
      ],
      "abstract": "Language models (LMs) are statistical models trained to assign probability to\nhuman-generated text. As such, it is reasonable to question whether they\napproximate linguistic variability exhibited by humans well. This form of\nstatistical assessment is difficult to perform at the passage level, for it\nrequires acceptability judgements (i.e., human evaluation) or a robust\nautomated proxy (which is non-trivial). At the word level, however, given some\ncontext, samples from an LM can be assessed via exact matching against a\nprerecorded dataset of alternative single-word continuations of the available\ncontext. We exploit this fact and evaluate the LM's ability to reproduce\nvariability that humans (in particular, a population of English speakers)\nexhibit in the 'next word prediction' task. This can be seen as assessing a\nform of calibration, which, in the context of text classification, Baan et al.\n(2022) termed calibration to human uncertainty. We assess GPT2, BLOOM and\nChatGPT and find that they exhibit fairly low calibration to human uncertainty.\nWe also verify the failure of expected calibration error (ECE) to reflect this,\nand as such, advise the community against relying on it in this setting.",
      "tldr_zh": "该研究评估了语言模型 (LMs) 是否能准确模拟人类在“下一个词预测”任务中的不确定性，通过将模型生成的词与预录制的人类备选词数据集进行精确匹配比较。研究者测试了 GPT2、BLOOM 和 ChatGPT，发现这些模型对人类不确定性的校准 (calibration to human uncertainty) 较低。论文还指出，expected calibration error (ECE) 在此场景下无效，并建议学术社区避免依赖它进行评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17527v2",
      "published_date": "2024-02-27 14:11:32 UTC",
      "updated_date": "2024-03-18 16:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:34:01.769926"
    },
    {
      "arxiv_id": "2402.18598v2",
      "title": "Note: Evolutionary Game Theory Focus Informational Health: The Cocktail Party Effect Through Werewolfgame under Incomplete Information and ESS Search Method Using Expected Gains of Repeated Dilemmas",
      "title_zh": "翻译失败",
      "authors": [
        "Yasuko Kawahata"
      ],
      "abstract": "We explore the state of information disruption caused by the cocktail party\neffect within the framework of non-perfect information games and evolutive\ngames with multiple werewolves. In particular, we mathematically model and\nanalyze the effects on the gain of each strategy choice and the formation\nprocess of evolutionary stable strategies (ESS) under the assumption that the\npollution risk of fake news is randomly assigned in the context of repeated\ndilemmas. We will develop the computational process in detail, starting with\nthe construction of the gain matrix, modeling the evolutionary dynamics using\nthe replicator equation, and identifying the ESS. In addition, numerical\nsimulations will be performed to observe system behavior under different\ninitial conditions and parameter settings to better understand the impact of\nthe spread of fake news on strategy evolution. This research will provide\ntheoretical insights into the complex issues of contemporary society regarding\nthe authenticity of information and expand the range of applications of\nevolutionary game theory.This paper is partially an attempt to utilize\n\"Generative AI\" and was written with educational intent. There are currently no\nplans for it to become a peer-reviewed paper.",
      "tldr_zh": "本研究探讨了Cocktail Party Effect在非完美信息游戏中的信息干扰问题，通过Werewolf游戏框架数学建模假新闻污染风险对策略选择的收益和Evolutionary Stable Strategies (ESS)的形成过程。方法包括构建收益矩阵、使用复制者方程模拟进化动态，并通过数值模拟观察不同初始条件和参数设置下的系统行为。研究结果揭示了假新闻传播对策略演化的影响，提供对信息真实性的理论洞见，并扩展了Evolutionary Game Theory在当代社会问题的应用潜力。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "Werewolf Games, Evolutionary Game Theory, Non-Complete Information\n  Games, Expanding Form Games, Cocktail Party Effect, Fake News, Evolutionary\n  Stability Strategy (ESS), Information Pollution Risk, Numerical Simulation,\n  Strategic Interaction, Replicator Equation",
      "pdf_url": "http://arxiv.org/pdf/2402.18598v2",
      "published_date": "2024-02-27 14:10:34 UTC",
      "updated_date": "2024-04-19 14:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:34:14.052303"
    },
    {
      "arxiv_id": "2403.07916v1",
      "title": "Advancing Investment Frontiers: Industry-grade Deep Reinforcement Learning for Portfolio Optimization",
      "title_zh": "推进投资前沿：行业级深度强化学习用于投资组合优化",
      "authors": [
        "Philip Ndikum",
        "Serge Ndikum"
      ],
      "abstract": "This research paper delves into the application of Deep Reinforcement\nLearning (DRL) in asset-class agnostic portfolio optimization, integrating\nindustry-grade methodologies with quantitative finance. At the heart of this\nintegration is our robust framework that not only merges advanced DRL\nalgorithms with modern computational techniques but also emphasizes stringent\nstatistical analysis, software engineering and regulatory compliance. To the\nbest of our knowledge, this is the first study integrating financial\nReinforcement Learning with sim-to-real methodologies from robotics and\nmathematical physics, thus enriching our frameworks and arguments with this\nunique perspective. Our research culminates with the introduction of\nAlphaOptimizerNet, a proprietary Reinforcement Learning agent (and\ncorresponding library). Developed from a synthesis of state-of-the-art (SOTA)\nliterature and our unique interdisciplinary methodology, AlphaOptimizerNet\ndemonstrates encouraging risk-return optimization across various asset classes\nwith realistic constraints. These preliminary results underscore the practical\nefficacy of our frameworks. As the finance sector increasingly gravitates\ntowards advanced algorithmic solutions, our study bridges theoretical\nadvancements with real-world applicability, offering a template for ensuring\nsafety and robust standards in this technologically driven future.",
      "tldr_zh": "这篇论文探讨了 Deep Reinforcement Learning (DRL) 在资产类别无关的组合优化中的应用，整合了行业级方法、量化金融、统计分析、软件工程和监管合规。研究首次将金融强化学习与机器人和数学物理的 sim-to-real 方法结合，引入了专有的 AlphaOptimizerNet 代理及其库，该代理基于 SOTA 文献和跨学科方法，在现实约束下实现了显著的风险-回报优化。初步结果证明了框架的实用性，并为金融领域提供了一个安全、稳健的算法解决方案模板。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07916v1",
      "published_date": "2024-02-27 14:08:31 UTC",
      "updated_date": "2024-02-27 14:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:34:26.589003"
    },
    {
      "arxiv_id": "2402.17516v4",
      "title": "QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations",
      "title_zh": "QUCE: 用于生成式反事实解释的路径不确定性的最小化和量化",
      "authors": [
        "Jamie Duell",
        "Monika Seisenberger",
        "Hsuan Fu",
        "Xiuyi Fan"
      ],
      "abstract": "Deep Neural Networks (DNNs) stand out as one of the most prominent approaches\nwithin the Machine Learning (ML) domain. The efficacy of DNNs has surged\nalongside recent increases in computational capacity, allowing these approaches\nto scale to significant complexities for addressing predictive challenges in\nbig data. However, as the complexity of DNN models rises, interpretability\ndiminishes. In response to this challenge, explainable models such as\nAdversarial Gradient Integration (AGI) leverage path-based gradients provided\nby DNNs to elucidate their decisions. Yet the performance of path-based\nexplainers can be compromised when gradients exhibit irregularities during\nout-of-distribution path traversal. In this context, we introduce Quantified\nUncertainty Counterfactual Explanations (QUCE), a method designed to mitigate\nout-of-distribution traversal by minimizing path uncertainty. QUCE not only\nquantifies uncertainty when presenting explanations but also generates more\ncertain counterfactual examples. We showcase the performance of the QUCE method\nby comparing it with competing methods for both path-based explanations and\ngenerative counterfactual examples.",
      "tldr_zh": "本研究针对深度神经网络 (DNNs) 的复杂性导致的可解释性问题，提出 QUCE 方法，以最小化和量化路径-based 不确定性，从而改善生成式反事实解释 (Counterfactual Explanations) 的可靠性。QUCE 通过减少 out-of-distribution 路径遍历中的不稳定性，不仅量化了不确定性，还生成更精确的反事实例子。实验结果显示，QUCE 在路径-based 解释和生成反事实方面优于竞争方法，如 Adversarial Gradient Integration (AGI)。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Final version published in ICDM 2024, International Conference on\n  Data Mining",
      "pdf_url": "http://arxiv.org/pdf/2402.17516v4",
      "published_date": "2024-02-27 14:00:08 UTC",
      "updated_date": "2025-03-12 08:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:34:37.312162"
    },
    {
      "arxiv_id": "2402.17511v1",
      "title": "Rethinking Mutual Information for Language Conditioned Skill Discovery on Imitation Learning",
      "title_zh": "重新审视互信息在模仿学习中的语言条件技能发现",
      "authors": [
        "Zhaoxun Ju",
        "Chao Yang",
        "Hongbo Wang",
        "Yu Qiao",
        "Fuchun Sun"
      ],
      "abstract": "Language-conditioned robot behavior plays a vital role in executing complex\ntasks by associating human commands or instructions with perception and\nactions. The ability to compose long-horizon tasks based on unconstrained\nlanguage instructions necessitates the acquisition of a diverse set of\ngeneral-purpose skills. However, acquiring inherent primitive skills in a\ncoupled and long-horizon environment without external rewards or human\nsupervision presents significant challenges. In this paper, we evaluate the\nrelationship between skills and language instructions from a mathematical\nperspective, employing two forms of mutual information within the framework of\nlanguage-conditioned policy learning. To maximize the mutual information\nbetween language and skills in an unsupervised manner, we propose an end-to-end\nimitation learning approach known as Language Conditioned Skill Discovery\n(LCSD). Specifically, we utilize vector quantization to learn discrete latent\nskills and leverage skill sequences of trajectories to reconstruct high-level\nsemantic instructions. Through extensive experiments on language-conditioned\nrobotic navigation and manipulation tasks, encompassing BabyAI, LORel, and\nCALVIN, we demonstrate the superiority of our method over prior works. Our\napproach exhibits enhanced generalization capabilities towards unseen tasks,\nimproved skill interpretability, and notably higher rates of task completion\nsuccess.",
      "tldr_zh": "这篇论文重新审视了互信息在模仿学习中的作用，针对语言条件下的机器人技能发现问题，提出了一种端到端的无监督方法Language Conditioned Skill Discovery (LCSD)。该方法利用向量量化(vector quantization)学习离散的潜在技能，并通过技能序列重建高层语义指令，从而在耦合环境中高效获取多样化的通用技能。实验结果显示，LCSD在BabyAI、LORel和CALVIN等机器人导航和操作任务上优于现有方法，显著提升了任务泛化能力、技能可解释性和完成成功率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.RO",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.17511v1",
      "published_date": "2024-02-27 13:53:52 UTC",
      "updated_date": "2024-02-27 13:53:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:34:50.009183"
    },
    {
      "arxiv_id": "2402.17510v2",
      "title": "Demonstrating and Reducing Shortcuts in Vision-Language Representation Learning",
      "title_zh": "视觉语言表示学习中捷径的展示与减少",
      "authors": [
        "Maurits Bleeker",
        "Mariya Hendriksen",
        "Andrew Yates",
        "Maarten de Rijke"
      ],
      "abstract": "Vision-language models (VLMs) mainly rely on contrastive training to learn\ngeneral-purpose representations of images and captions. We focus on the\nsituation when one image is associated with several captions, each caption\ncontaining both information shared among all captions and unique information\nper caption about the scene depicted in the image. In such cases, it is unclear\nwhether contrastive losses are sufficient for learning task-optimal\nrepresentations that contain all the information provided by the captions or\nwhether the contrastive learning setup encourages the learning of a simple\nshortcut that minimizes contrastive loss. We introduce synthetic shortcuts for\nvision-language: a training and evaluation framework where we inject synthetic\nshortcuts into image-text data. We show that contrastive VLMs trained from\nscratch or fine-tuned with data containing these synthetic shortcuts mainly\nlearn features that represent the shortcut. Hence, contrastive losses are not\nsufficient to learn task-optimal representations, i.e., representations that\ncontain all task-relevant information shared between the image and associated\ncaptions. We examine two methods to reduce shortcut learning in our training\nand evaluation framework: (i) latent target decoding and (ii) implicit feature\nmodification. We show empirically that both methods improve performance on the\nevaluation task, but only partly reduce shortcut learning when training and\nevaluating with our shortcut learning framework. Hence, we show the difficulty\nand challenge of our shortcut learning framework for contrastive\nvision-language representation learning.",
      "tldr_zh": "这篇论文探讨了视觉语言模型(VLMs)在对比训练中可能学习捷径的问题，即模型优先捕捉简化特征而非图像和标题的全面信息，导致任务最优表示不足。研究者引入了一个合成捷径框架，用于注入人工捷径到图像-文本数据中，并证明对比VLMs倾向于学习这些捷径特征。论文评估了两种减少捷径学习的方法——潜在目标解码和隐式特征修改——实验显示这些方法改善了评估任务的性能，但未能完全消除捷径学习，突显了对比视觉语言表示学习的难度和挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, accepted at TMLR",
      "pdf_url": "http://arxiv.org/pdf/2402.17510v2",
      "published_date": "2024-02-27 13:50:34 UTC",
      "updated_date": "2024-07-31 21:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:35:01.766709"
    },
    {
      "arxiv_id": "2402.17501v2",
      "title": "Intensive Care as One Big Sequence Modeling Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Vadim Liventsev",
        "Tobias Fritz"
      ],
      "abstract": "Reinforcement Learning in Healthcare is typically concerned with narrow\nself-contained tasks such as sepsis prediction or anesthesia control. However,\nprevious research has demonstrated the potential of generalist models (the\nprime example being Large Language Models) to outperform task-specific\napproaches due to their capability for implicit transfer learning. To enable\ntraining of foundation models for Healthcare as well as leverage the\ncapabilities of state of the art Transformer architectures, we propose the\nparadigm of Healthcare as Sequence Modeling, in which interaction between the\npatient and the healthcare provider is represented as an event stream and tasks\nlike diagnosis and treatment selection are modeled as prediction of future\nevents in the stream. To explore this paradigm experimentally we develop\nMIMIC-SEQ, a sequence modeling benchmark derived by translating heterogenous\nclinical records from MIMIC-IV dataset into a uniform event stream format,\ntrain a baseline model and explore its capabilities.",
      "tldr_zh": "本研究提出将重症监护视为一个大型序列建模问题，通过将患者与医疗提供者之间的互动表示为事件流，从而将诊断和治疗选择建模为未来事件的预测。这种方法借鉴了泛化模型（如Large Language Models）的隐式转移学习优势，旨在超越传统任务特定强化学习方法，如败血症预测或麻醉控制。研究者开发了MIMIC-SEQ基准，将MIMIC-IV数据集的异构临床记录转换为统一事件流格式，并训练了一个基于Transformer architectures的基线模型，探索其在医疗领域的潜力。实验结果表明，这一范式有助于提升医疗基础模型的性能，为泛化医疗AI应用奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17501v2",
      "published_date": "2024-02-27 13:36:55 UTC",
      "updated_date": "2024-05-24 18:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:35:12.594999"
    },
    {
      "arxiv_id": "2402.17496v2",
      "title": "Emotional Voice Messages (EMOVOME) database: emotion recognition in spontaneous voice messages",
      "title_zh": "翻译失败",
      "authors": [
        "Lucía Gómez Zaragozá",
        "Rocío del Amor",
        "Elena Parra Vargas",
        "Valery Naranjo",
        "Mariano Alcañiz Raya",
        "Javier Marín-Morales"
      ],
      "abstract": "Emotional Voice Messages (EMOVOME) is a spontaneous speech dataset containing\n999 audio messages from real conversations on a messaging app from 100 Spanish\nspeakers, gender balanced. Voice messages were produced in-the-wild conditions\nbefore participants were recruited, avoiding any conscious bias due to\nlaboratory environment. Audios were labeled in valence and arousal dimensions\nby three non-experts and two experts, which were then combined to obtain a\nfinal label per dimension. The experts also provided an extra label\ncorresponding to seven emotion categories. To set a baseline for future\ninvestigations using EMOVOME, we implemented emotion recognition models using\nboth speech and audio transcriptions. For speech, we used the standard eGeMAPS\nfeature set and support vector machines, obtaining 49.27% and 44.71% unweighted\naccuracy for valence and arousal respectively. For text, we fine-tuned a\nmultilingual BERT model and achieved 61.15% and 47.43% unweighted accuracy for\nvalence and arousal respectively. This database will significantly contribute\nto research on emotion recognition in the wild, while also providing a unique\nnatural and freely accessible resource for Spanish.",
      "tldr_zh": "本文介绍了 EMOVOME 数据库，这是一个包含 999 条自发语音消息的自发语音数据集，由 100 名西班牙语使用者（性别均衡）在真实对话中生成，并标注了 valence 和 arousal 维度以及七个情感类别。数据集通过三名非专家和两名专家的标注结合得到最终标签，并使用 eGeMAPS 特征集与 support vector machines 进行语音情感识别，达到 valence 49.27% 和 arousal 44.71% 的 unweighted accuracy；同时 fine-tune multilingual BERT 模型进行文本识别，获得 valence 61.15% 和 arousal 47.43% 的准确率。该数据库为野外条件下的 emotion recognition 研究提供了一个自然、免费的西班牙语资源，推动相关领域的进展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS",
        "I.5.1; I.5.4; I.2.7"
      ],
      "primary_category": "cs.SD",
      "comment": "This paper has been superseded by arXiv:2403.02167 (merged from the\n  description of the EMOVOME database in arXiv:2402.17496v1 and the speech\n  emotion recognition models in arXiv:2403.02167v1)",
      "pdf_url": "http://arxiv.org/pdf/2402.17496v2",
      "published_date": "2024-02-27 13:22:47 UTC",
      "updated_date": "2024-06-13 13:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:35:27.232781"
    },
    {
      "arxiv_id": "2402.17490v1",
      "title": "The Mechanical Turkness: Tactical Media Art and the Critique of Corporate AI",
      "title_zh": "翻译失败",
      "authors": [
        "Dejan Grba"
      ],
      "abstract": "The extensive industrialization of artificial intelligence (AI) since the\nmid-2010s has increasingly motivated artists to address its economic and\nsociopolitical consequences. In this chapter, I discuss interrelated art\npractices that thematize creative agency, crowdsourced labor, and delegated\nartmaking to reveal the social rootage of AI technologies and underline the\nproductive human roles in their development. I focus on works whose poetic\nfeatures indicate broader issues of contemporary AI-influenced science,\ntechnology, economy, and society. By exploring the conceptual, methodological,\nand ethical aspects of their effectiveness in disrupting the political regime\nof corporate AI, I identify several problems that affect their tactical impact\nand outline potential avenues for tackling the challenges and advancing the\nfield.",
      "tldr_zh": "本论文探讨了自2010年代中期以来AI工业化的背景下，艺术家如何通过战术媒体艺术(Tactical Media Art)批判其经济和社会政治影响。作者分析了相关艺术实践，这些作品主题化创意代理、众包劳动(crowdsourced labor)和委托艺术制作(delegated artmaking)，以揭示AI技术的社会根源和人类在其中的关键角色。最终，论文评估了这些作品在破坏企业AI(corporate AI)政治制度方面的概念、方法和伦理有效性，识别了潜在问题并提出推进该领域的解决方案。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Matthes, J\\\"org, Damian Trilling, Ljubi\\v{s}a Boji\\'c and Simona\n  \\v{Z}iki\\'c, eds. 2024. Navigating the Digital Age: An In-Depth Exploration\n  into the Intersection of Modern Technologies and Societal Transformation.\n  Vienna and Belgrade: Institute for Philosophy and Social Theory and\n  University of Belgrade and Department of Communication, University of Vienna",
      "pdf_url": "http://arxiv.org/pdf/2402.17490v1",
      "published_date": "2024-02-27 13:16:50 UTC",
      "updated_date": "2024-02-27 13:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:35:37.995967"
    },
    {
      "arxiv_id": "2402.17482v1",
      "title": "Automated Classification of Phonetic Segments in Child Speech Using Raw Ultrasound Imaging",
      "title_zh": "利用原始超声成像对儿童语音中的语音段进行自动分类",
      "authors": [
        "Saja Al Ani",
        "Joanne Cleland",
        "Ahmed Zoha"
      ],
      "abstract": "Speech sound disorder (SSD) is defined as a persistent impairment in speech\nsound production leading to reduced speech intelligibility and hindered verbal\ncommunication. Early recognition and intervention of children with SSD and\ntimely referral to speech and language therapists (SLTs) for treatment are\ncrucial. Automated detection of speech impairment is regarded as an efficient\nmethod for examining and screening large populations. This study focuses on\nadvancing the automatic diagnosis of SSD in early childhood by proposing a\ntechnical solution that integrates ultrasound tongue imaging (UTI) with\ndeep-learning models. The introduced FusionNet model combines UTI data with the\nextracted texture features to classify UTI. The overarching aim is to elevate\nthe accuracy and efficiency of UTI analysis, particularly for classifying\nspeech sounds associated with SSD. This study compared the FusionNet approach\nwith standard deep-learning methodologies, highlighting the excellent\nimprovement results of the FusionNet model in UTI classification and the\npotential of multi-learning in improving UTI classification in speech therapy\nclinics.",
      "tldr_zh": "这篇论文针对儿童言语声音障碍 (SSD) 的早期诊断，提出了一种自动分类方法，使用超声波舌部成像 (UTI) 与深度学习模型相结合。研究引入了 FusionNet 模型，将 UTI 数据和提取的纹理特征整合，以提高语音段的分类准确性和效率。实验结果显示，FusionNet 比标准深度学习方法有显著改进，准确率提升明显，并展示了其在言语治疗诊所的多学习潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17482v1",
      "published_date": "2024-02-27 13:08:34 UTC",
      "updated_date": "2024-02-27 13:08:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:35:50.458965"
    },
    {
      "arxiv_id": "2402.17472v4",
      "title": "RAGFormer: Learning Semantic Attributes and Topological Structure for Fraud Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Haolin Li",
        "Shuyang Jiang",
        "Lifeng Zhang",
        "Siyuan Du",
        "Guangnan Ye",
        "Hongfeng Chai"
      ],
      "abstract": "Fraud detection remains a challenging task due to the complex and deceptive\nnature of fraudulent activities. Current approaches primarily concentrate on\nlearning only one perspective of the graph: either the topological structure of\nthe graph or the attributes of individual nodes. However, we conduct empirical\nstudies to reveal that these two types of features, while nearly orthogonal,\nare each independently effective. As a result, previous methods can not fully\ncapture the comprehensive characteristics of the fraud graph. To address this\ndilemma, we present a novel framework called Relation-Aware GNN with\ntransFormer~(RAGFormer) which simultaneously embeds both semantic and\ntopological features into a target node. The simple yet effective network\nconsists of a semantic encoder, a topology encoder, and an attention fusion\nmodule. The semantic encoder utilizes Transformer to learn semantic features\nand node interactions across different relations. We introduce Relation-Aware\nGNN as the topology encoder to learn topological features and node interactions\nwithin each relation. These two complementary features are interleaved through\nan attention fusion module to support prediction by both orthogonal features.\nExtensive experiments on two popular public datasets demonstrate that RAGFormer\nachieves state-of-the-art performance. The significant improvement of RAGFormer\nin an industrial credit card fraud detection dataset further validates the\napplicability of our method in real-world business scenarios.",
      "tldr_zh": "该论文提出 RAGFormer 框架，用于解决欺诈检测中的挑战，通过同时学习图的语义属性和拓扑结构，避免了现有方法仅关注其中一方面的局限。框架包括语义编码器（基于 Transformer 学习节点语义特征和跨关系交互）、拓扑编码器（使用 Relation-Aware GNN 学习拓扑特征和关系内节点交互），以及注意力融合模块来整合这些互补特征。在两个公共数据集上，RAGFormer 实现了最先进性能，并在工业信用卡欺诈检测数据集上表现出显著提升，证明了其在实际场景中的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.17472v4",
      "published_date": "2024-02-27 12:53:15 UTC",
      "updated_date": "2025-02-11 12:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:36:04.000067"
    },
    {
      "arxiv_id": "2402.17467v1",
      "title": "Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: a Survey",
      "title_zh": "自然语言处理方法用于符号音乐生成和信息检索：一个综述",
      "authors": [
        "Dinh-Viet-Toan Le",
        "Louis Bigo",
        "Mikaela Keller",
        "Dorien Herremans"
      ],
      "abstract": "Several adaptations of Transformers models have been developed in various\ndomains since its breakthrough in Natural Language Processing (NLP). This trend\nhas spread into the field of Music Information Retrieval (MIR), including\nstudies processing music data. However, the practice of leveraging NLP tools\nfor symbolic music data is not novel in MIR. Music has been frequently compared\nto language, as they share several similarities, including sequential\nrepresentations of text and music. These analogies are also reflected through\nsimilar tasks in MIR and NLP. This survey reviews NLP methods applied to\nsymbolic music generation and information retrieval studies following two axes.\nWe first propose an overview of representations of symbolic music adapted from\nnatural language sequential representations. Such representations are designed\nby considering the specificities of symbolic music. These representations are\nthen processed by models. Such models, possibly originally developed for text\nand adapted for symbolic music, are trained on various tasks. We describe these\nmodels, in particular deep learning models, through different prisms,\nhighlighting music-specialized mechanisms. We finally present a discussion\nsurrounding the effective use of NLP tools for symbolic music data. This\nincludes technical issues regarding NLP methods and fundamental differences\nbetween text and music, which may open several doors for further research into\nmore effectively adapting NLP tools to symbolic MIR.",
      "tldr_zh": "这篇调查论文回顾了在符号化音乐生成和信息检索（MIR）领域应用自然语言处理（NLP）方法的情况，强调了音乐与语言的相似性，如顺序表示和类似任务。论文首先概述了从自然语言顺序表示适配而来的符号化音乐表示方式，并讨论了用于处理这些表示的模型，包括 Transformers 等深度学习模型及其针对音乐的专化机制。最终，它探讨了 NLP 工具在符号化音乐中的有效性问题，包括技术挑战和文本与音乐的根本差异，为进一步优化这些方法提供了研究方向。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.IR",
      "comment": "36 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.17467v1",
      "published_date": "2024-02-27 12:48:01 UTC",
      "updated_date": "2024-02-27 12:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:36:15.242011"
    },
    {
      "arxiv_id": "2402.17810v2",
      "title": "BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Qizhi Pei",
        "Lijun Wu",
        "Kaiyuan Gao",
        "Xiaozhuan Liang",
        "Yin Fang",
        "Jinhua Zhu",
        "Shufang Xie",
        "Tao Qin",
        "Rui Yan"
      ],
      "abstract": "Recent research trends in computational biology have increasingly focused on\nintegrating text and bio-entity modeling, especially in the context of\nmolecules and proteins. However, previous efforts like BioT5 faced challenges\nin generalizing across diverse tasks and lacked a nuanced understanding of\nmolecular structures, particularly in their textual representations (e.g.,\nIUPAC). This paper introduces BioT5+, an extension of the BioT5 framework,\ntailored to enhance biological research and drug discovery. BioT5+ incorporates\nseveral novel features: integration of IUPAC names for molecular understanding,\ninclusion of extensive bio-text and molecule data from sources like bioRxiv and\nPubChem, the multi-task instruction tuning for generality across tasks, and a\nnumerical tokenization technique for improved processing of numerical data.\nThese enhancements allow BioT5+ to bridge the gap between molecular\nrepresentations and their textual descriptions, providing a more holistic\nunderstanding of biological entities, and largely improving the grounded\nreasoning of bio-text and bio-sequences. The model is pre-trained and\nfine-tuned with a large number of experiments, including \\emph{3 types of\nproblems (classification, regression, generation), 15 kinds of tasks, and 21\ntotal benchmark datasets}, demonstrating the remarkable performance and\nstate-of-the-art results in most cases. BioT5+ stands out for its ability to\ncapture intricate relationships in biological data, thereby contributing\nsignificantly to bioinformatics and computational biology. Our code is\navailable at \\url{https://github.com/QizhiPei/BioT5}.",
      "tldr_zh": "本研究引入了 BioT5+，作为 BioT5 框架的扩展，旨在提升生物计算模型在多样任务中的泛化能力，特别是对分子结构（如 IUPAC 名称）的理解。BioT5+ 整合了 IUPAC 名称、大量生物文本和分子数据（如 bioRxiv 和 PubChem）、多任务指令调优以及数值标记化技术，从而桥接分子表示与文本描述，并改善生物序列的推理能力。在实验中，模型在 3 种问题类型（分类、回归、生成）、15 种任务和 21 个基准数据集上表现出色，实现了 state-of-the-art 结果，为生物信息学和计算生物学提供更全面的理解和应用。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Accepted by ACL 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2402.17810v2",
      "published_date": "2024-02-27 12:43:09 UTC",
      "updated_date": "2024-05-31 14:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:36:28.275054"
    },
    {
      "arxiv_id": "2402.17456v1",
      "title": "A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education",
      "title_zh": "翻译失败",
      "authors": [
        "Michael A. Hedderich",
        "Natalie N. Bazarova",
        "Wenting Zou",
        "Ryun Shim",
        "Xinda Ma",
        "Qian Yang"
      ],
      "abstract": "Cyberbullying harms teenagers' mental health, and teaching them upstanding\nintervention is crucial. Wizard-of-Oz studies show chatbots can scale up\npersonalized and interactive cyberbullying education, but implementing such\nchatbots is a challenging and delicate task. We created a no-code chatbot\ndesign tool for K-12 teachers. Using large language models and prompt chaining,\nour tool allows teachers to prototype bespoke dialogue flows and chatbot\nutterances. In offering this tool, we explore teachers' distinctive needs when\ndesigning chatbots to assist their teaching, and how chatbot design tools might\nbetter support them. Our findings reveal that teachers welcome the tool\nenthusiastically. Moreover, they see themselves as playwrights guiding both the\nstudents' and the chatbot's behaviors, while allowing for some improvisation.\nTheir goal is to enable students to rehearse both desirable and undesirable\nreactions to cyberbullying in a safe environment. We discuss the design\nopportunities LLM-Chains offer for empowering teachers and the research\nopportunities this work opens up.",
      "tldr_zh": "本研究调查了K-12老师如何设计LLM聊天机器人，以辅助青少年网络霸凌教育，强调使用无代码工具和prompt chaining来原型化对话流和机器人回应。研究发现，老师们热情欢迎该工具，并将自己视为剧作家，引导学生和机器人行为，允许一定即兴发挥，从而在安全环境中让学生排练desirable和undesirable的反应。最终，该工作探讨了LLM-Chains如何赋予老师更多权力，并开启了新的教育研究机会。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17456v1",
      "published_date": "2024-02-27 12:27:51 UTC",
      "updated_date": "2024-02-27 12:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:36:39.461986"
    },
    {
      "arxiv_id": "2402.17447v2",
      "title": "Deep Learning Based Named Entity Recognition Models for Recipes",
      "title_zh": "基于深度学习的食谱命名实体识别模型",
      "authors": [
        "Mansi Goel",
        "Ayush Agarwal",
        "Shubham Agrawal",
        "Janak Kapuriya",
        "Akhil Vamshi Konam",
        "Rishabh Gupta",
        "Shrey Rastogi",
        "Niharika",
        "Ganesh Bagler"
      ],
      "abstract": "Food touches our lives through various endeavors, including flavor,\nnourishment, health, and sustainability. Recipes are cultural capsules\ntransmitted across generations via unstructured text. Automated protocols for\nrecognizing named entities, the building blocks of recipe text, are of immense\nvalue for various applications ranging from information extraction to novel\nrecipe generation. Named entity recognition is a technique for extracting\ninformation from unstructured or semi-structured data with known labels.\nStarting with manually-annotated data of 6,611 ingredient phrases, we created\nan augmented dataset of 26,445 phrases cumulatively. Simultaneously, we\nsystematically cleaned and analyzed ingredient phrases from RecipeDB, the\ngold-standard recipe data repository, and annotated them using the Stanford\nNER. Based on the analysis, we sampled a subset of 88,526 phrases using a\nclustering-based approach while preserving the diversity to create the\nmachine-annotated dataset. A thorough investigation of NER approaches on these\nthree datasets involving statistical, fine-tuning of deep learning-based\nlanguage models and few-shot prompting on large language models (LLMs) provides\ndeep insights. We conclude that few-shot prompting on LLMs has abysmal\nperformance, whereas the fine-tuned spaCy-transformer emerges as the best model\nwith macro-F1 scores of 95.9%, 96.04%, and 95.71% for the manually-annotated,\naugmented, and machine-annotated datasets, respectively.",
      "tldr_zh": "本研究探讨了基于深度学习的命名实体识别（Named Entity Recognition, NER）模型在食谱文本中的应用，旨在从无结构数据中提取成分等关键信息，以支持信息提取和新食谱生成等任务。研究者创建了三个数据集：从6,611个手动标注的成分短语扩展到26,445个增强数据集，并从RecipeDB中采样88,526个机器标注短语，使用聚类方法确保多样性。实验比较了统计方法、微调深度学习语言模型（如spaCy-transformer）和少样本提示大型语言模型（LLMs），结果显示LLMs的少样本提示性能较差，而spaCy-transformer微调模型在三个数据集上取得了高宏F1分数（分别为95.9%、96.04%和95.71%），证明其在食谱NER任务中的优越性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 main figures and 2 in appendices, and 3 main tables;\n  Accepted for publication in LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17447v2",
      "published_date": "2024-02-27 12:03:56 UTC",
      "updated_date": "2024-06-06 07:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:36:53.069221"
    },
    {
      "arxiv_id": "2402.17442v4",
      "title": "Insights from the Usage of the Ansible Lightspeed Code Completion Service",
      "title_zh": "Ansible Lights",
      "authors": [
        "Priyam Sahoo",
        "Saurabh Pujar",
        "Ganesh Nalawade",
        "Richard Gebhardt",
        "Louis Mandel",
        "Luca Buratti"
      ],
      "abstract": "The availability of Large Language Models (LLMs) which can generate code, has\nmade it possible to create tools that improve developer productivity.\nIntegrated development environments or IDEs which developers use to write\nsoftware are often used as an interface to interact with LLMs. Although many\nsuch tools have been released, almost all of them focus on general-purpose\nprogramming languages. Domain-specific languages, such as those crucial for\nInformation Technology (IT) automation, have not received much attention.\nAnsible is one such YAML-based IT automation-specific language. Ansible\nLightspeed is an LLM-based service designed explicitly to generate Ansible\nYAML, given natural language prompt.\n  In this paper, we present the design and implementation of the Ansible\nLightspeed service. We then evaluate its utility to developers using diverse\nindicators, including extended utilization, analysis of user edited\nsuggestions, as well as user sentiments analysis. The evaluation is based on\ndata collected for 10,696 real users including 3,910 returning users. The code\nfor Ansible Lightspeed service and the analysis framework is made available for\nothers to use.\n  To our knowledge, our study is the first to involve thousands of users of\ncode assistants for domain-specific languages. We are also the first code\ncompletion tool to present N-Day user retention figures, which is 13.66% on Day\n30. We propose an improved version of user acceptance rate, called Strong\nAcceptance rate, where a suggestion is considered accepted only if less than\n50% of it is edited and these edits do not change critical parts of the\nsuggestion. By focusing on Ansible, Lightspeed is able to achieve a strong\nacceptance rate of 49.08% for multi-line Ansible task suggestions. With our\nfindings we provide insights into the effectiveness of small, dedicated models\nin a domain-specific context.",
      "tldr_zh": "本论文分析了Ansible Lightspeed服务，这是一个基于LLMs的代码补全工具，专门为Ansible YAML语言生成代码，以提升IT自动化开发效率。通过对10,696名真实用户（包括3,910名回归用户）的数据评估，包括使用率、用户编辑分析和情感分析，论文首次报告了针对领域特定语言的代码助手的N-Day用户保留率（30天为13.66%）。此外，提出Strong Acceptance rate指标，该服务在多行Ansible任务建议中达到49.08%，证明了小型专用模型在领域特定上下文中的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "This paper has been published at the 39th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE 2024), Industry Showcase\n  under the title \"Ansible Lightspeed: A Code Generation Service for IT\n  Automation\"",
      "pdf_url": "http://arxiv.org/pdf/2402.17442v4",
      "published_date": "2024-02-27 11:57:28 UTC",
      "updated_date": "2024-10-22 10:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:37:04.022842"
    },
    {
      "arxiv_id": "2402.17437v1",
      "title": "Exploiting Emotion-Semantic Correlations for Empathetic Response Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhou Yang",
        "Zhaochun Ren",
        "Yufeng Wang",
        "Xiaofei Zhu",
        "Zhihao Chen",
        "Tiecheng Cai",
        "Yunbing Wu",
        "Yisong Su",
        "Sibo Ju",
        "Xiangwen Liao"
      ],
      "abstract": "Empathetic response generation aims to generate empathetic responses by\nunderstanding the speaker's emotional feelings from the language of dialogue.\nRecent methods capture emotional words in the language of communicators and\nconstruct them as static vectors to perceive nuanced emotions. However,\nlinguistic research has shown that emotional words in language are dynamic and\nhave correlations with other grammar semantic roles, i.e., words with semantic\nmeanings, in grammar. Previous methods overlook these two characteristics,\nwhich easily lead to misunderstandings of emotions and neglect of key\nsemantics. To address this issue, we propose a dynamical Emotion-Semantic\nCorrelation Model (ESCM) for empathetic dialogue generation tasks. ESCM\nconstructs dynamic emotion-semantic vectors through the interaction of context\nand emotions. We introduce dependency trees to reflect the correlations between\nemotions and semantics. Based on dynamic emotion-semantic vectors and\ndependency trees, we propose a dynamic correlation graph convolutional network\nto guide the model in learning context meanings in dialogue and generating\nempathetic responses. Experimental results on the EMPATHETIC-DIALOGUES dataset\nshow that ESCM understands semantics and emotions more accurately and expresses\nfluent and informative empathetic responses. Our analysis results also indicate\nthat the correlations between emotions and semantics are frequently used in\ndialogues, which is of great significance for empathetic perception and\nexpression.",
      "tldr_zh": "本论文针对同理心响应生成的问题，提出动态 Emotion-Semantic Correlation Model (ESCM)，通过捕捉情感词的动态特性和与语义词的相关性（如使用 dependency trees），来避免现有方法的误解和忽略。ESCM 构建动态情感-语义向量，并引入 dynamic correlation graph convolutional network 来学习对话上下文，从而生成更准确的同理心响应。在 EMPATHETIC-DIALOGUES 数据集上的实验结果表明，ESCM 能更精确地理解语义和情感，并产生流畅、信息丰富的响应，同时分析显示情感-语义相关性在对话中至关重要。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 3 figures, Findings of EMNLP 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.17437v1",
      "published_date": "2024-02-27 11:50:05 UTC",
      "updated_date": "2024-02-27 11:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:37:16.174788"
    },
    {
      "arxiv_id": "2402.17431v1",
      "title": "The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Salvatore Lorello",
        "Marco Lippi",
        "Stefano Melacci"
      ],
      "abstract": "Artificial intelligence is continuously seeking novel challenges and\nbenchmarks to effectively measure performance and to advance the\nstate-of-the-art. In this paper we introduce KANDY, a benchmarking framework\nthat can be used to generate a variety of learning and reasoning tasks inspired\nby Kandinsky patterns. By creating curricula of binary classification tasks\nwith increasing complexity and with sparse supervisions, KANDY can be used to\nimplement benchmarks for continual and semi-supervised learning, with a\nspecific focus on symbol compositionality. Classification rules are also\nprovided in the ground truth to enable analysis of interpretable solutions.\nTogether with the benchmark generation pipeline, we release two curricula, an\neasier and a harder one, that we propose as new challenges for the research\ncommunity. With a thorough experimental evaluation, we show how both\nstate-of-the-art neural models and purely symbolic approaches struggle with\nsolving most of the tasks, thus calling for the application of advanced\nneuro-symbolic methods trained over time.",
      "tldr_zh": "本研究引入了 KANDY 基准框架，利用 Kandinsky patterns 生成一系列学习和推理任务，专注于 incremental neuro-symbolic 学习、持续学习（continual learning）和半监督学习（semi-supervised learning），特别强调 symbol compositionality。框架通过创建复杂性递增的二元分类任务课程，并提供稀疏监督和可解释的分类规则，来评估模型在符号组合方面的性能。实验结果显示，现有状态-of-the-art 神经模型和纯符号方法在这些任务上表现不佳，呼吁开发先进的 neuro-symbolic 方法以应对这些挑战。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17431v1",
      "published_date": "2024-02-27 11:43:41 UTC",
      "updated_date": "2024-02-27 11:43:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:37:26.373673"
    },
    {
      "arxiv_id": "2402.17423v3",
      "title": "Reinforced In-Context Black-Box Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Song",
        "Chenxiao Gao",
        "Ke Xue",
        "Chenyang Wu",
        "Dong Li",
        "Jianye Hao",
        "Zongzhang Zhang",
        "Chao Qian"
      ],
      "abstract": "Black-Box Optimization (BBO) has found successful applications in many fields\nof science and engineering. Recently, there has been a growing interest in\nmeta-learning particular components of BBO algorithms to speed up optimization\nand get rid of tedious hand-crafted heuristics. As an extension, learning the\nentire algorithm from data requires the least labor from experts and can\nprovide the most flexibility. In this paper, we propose RIBBO, a method to\nreinforce-learn a BBO algorithm from offline data in an end-to-end fashion.\nRIBBO employs expressive sequence models to learn the optimization histories\nproduced by multiple behavior algorithms and tasks, leveraging the in-context\nlearning ability of large models to extract task information and make decisions\naccordingly. Central to our method is to augment the optimization histories\nwith \\textit{regret-to-go} tokens, which are designed to represent the\nperformance of an algorithm based on cumulative regret over the future part of\nthe histories. The integration of regret-to-go tokens enables RIBBO to\nautomatically generate sequences of query points that satisfy the user-desired\nregret, which is verified by its universally good empirical performance on\ndiverse problems, including BBO benchmark functions, hyper-parameter\noptimization and robot control problems.",
      "tldr_zh": "该论文提出了一种名为 RIBBO 的方法，通过强化学习从离线数据端到端学习 Black-Box Optimization (BBO) 算法，旨在加速优化过程并避免手工设计的启发式规则。RIBBO 利用表达性序列模型和大型模型的 in-context learning 能力来分析多个行为算法和任务的优化历史，并引入 regret-to-go tokens 来表示未来累积遗憾，从而生成满足用户期望遗憾的查询点序列。该方法在 BBO 基准函数、超参数优化和机器人控制等多样化问题上表现出色，验证了其通用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17423v3",
      "published_date": "2024-02-27 11:32:14 UTC",
      "updated_date": "2024-11-01 14:32:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:37:38.960670"
    },
    {
      "arxiv_id": "2402.17420v2",
      "title": "PANDAS: Prototype-based Novel Class Discovery and Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tyler L. Hayes",
        "César R. de Souza",
        "Namil Kim",
        "Jiwon Kim",
        "Riccardo Volpi",
        "Diane Larlus"
      ],
      "abstract": "Object detectors are typically trained once and for all on a fixed set of\nclasses. However, this closed-world assumption is unrealistic in practice, as\nnew classes will inevitably emerge after the detector is deployed in the wild.\nIn this work, we look at ways to extend a detector trained for a set of base\nclasses so it can i) spot the presence of novel classes, and ii) automatically\nenrich its repertoire to be able to detect those newly discovered classes\ntogether with the base ones. We propose PANDAS, a method for novel class\ndiscovery and detection. It discovers clusters representing novel classes from\nunlabeled data, and represents old and new classes with prototypes. During\ninference, a distance-based classifier uses these prototypes to assign a label\nto each detected object instance. The simplicity of our method makes it widely\napplicable. We experimentally demonstrate the effectiveness of PANDAS on the\nVOC 2012 and COCO-to-LVIS benchmarks. It performs favorably against the state\nof the art for this task while being computationally more affordable.",
      "tldr_zh": "本文提出 PANDAS 方法，用于扩展物体检测器以处理新出现的类别。它通过从未标注数据中发现代表新类别的聚类，并使用原型（prototypes）表示旧和新类别，然后采用基于距离的分类器（distance-based classifier）在推理阶段为检测到的物体实例分配标签。该方法简单易用，在 VOC 2012 和 COCO-to-LVIS 基准上，与现有最先进方法相比，性能更优且计算成本更低。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the Conference on Lifelong Learning Agents (CoLLAs 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.17420v2",
      "published_date": "2024-02-27 11:23:39 UTC",
      "updated_date": "2024-04-30 15:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:37:50.919108"
    },
    {
      "arxiv_id": "2402.17805v2",
      "title": "Graph Neural Networks and Arithmetic Circuits",
      "title_zh": "图神经网络与算术电路",
      "authors": [
        "Timon Barlag",
        "Vivian Holzapfel",
        "Laura Strieker",
        "Jonni Virtema",
        "Heribert Vollmer"
      ],
      "abstract": "We characterize the computational power of neural networks that follow the\ngraph neural network (GNN) architecture, not restricted to aggregate-combine\nGNNs or other particular types. We establish an exact correspondence between\nthe expressivity of GNNs using diverse activation functions and arithmetic\ncircuits over real numbers. In our results the activation function of the\nnetwork becomes a gate type in the circuit. Our result holds for families of\nconstant depth circuits and networks, both uniformly and non-uniformly, for all\ncommon activation functions.",
      "tldr_zh": "本论文探讨了 Graph Neural Networks (GNNs) 的计算能力，建立了一种精确对应关系，将 GNNs 的表达能力与实数上的算术电路相等价。研究发现，GNNs 中使用的激活函数可以对应电路中的门类型，从而揭示了网络的计算机制。结果适用于恒定深度的电路和网络，既包括均匀的也包括非均匀的，以及所有常见激活函数。这一贡献为理解 GNNs 的理论基础和局限性提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "F.1.1; F.1.3; I.2.m"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17805v2",
      "published_date": "2024-02-27 11:04:06 UTC",
      "updated_date": "2024-11-21 15:34:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:38:02.956781"
    },
    {
      "arxiv_id": "2402.17410v2",
      "title": "Image space formalism of convolutional neural networks for k-space interpolation",
      "title_zh": "用于 k 空间插值的卷积神经网络图像空间形式主义",
      "authors": [
        "Peter Dawood",
        "Felix Breuer",
        "Istvan Homolya",
        "Maximilian Gram",
        "Peter M. Jakob",
        "Moritz Zaiss",
        "Martin Blaimer"
      ],
      "abstract": "Purpose: Noise resilience in image reconstructions by scan-specific robust\nartificial neural networks for k-space interpolation (RAKI) is linked to\nnonlinear activations in k-space. To gain a deeper understanding of this\nrelationship, an image space formalism of RAKI is introduced for analyzing\nnoise propagation analytically, identifying and characterizing image\nreconstruction features and to describe the role of nonlinear activations in a\nhuman readable manner. Methods: The image space formalism for RAKI inference is\nemployed by expressing nonlinear activations in k-space as element-wise\nmultiplications with activation masks, which transform into convolutions in\nimage space. Jacobians of the de-aliased, coil-combined image relative to the\naliased coil images can be expressed algebraically, and thus, the noise\namplification is quantified analytically (g-factor maps). We analyze the role\nof nonlinearity for noise resilience by controlling the degree of nonlinearity\nin the reconstruction model via the negative slope parameter in leaky ReLU.\nResults: The analytical g-factor maps correspond with those obtained from Monte\nCarlo simulations and from an auto differentiation approach for in vivo brain\nimages. Apparent blurring and contrast loss artifacts are identified as\nimplications of enhanced noise resilience. These residual artifacts can be\ntraded against noise resilience by adjusting the degree of nonlinearity in the\nmodel (Tikhonov-like regularization) in case of limited training data. The\ninspection of image space activations reveals an autocorrelation pattern\nleading to a potential center artifact. Conclusion: The image space formalism\nof RAKI provides the means for analytical quantitative noisepropagation\nanalysis and human-readable visualization of the effects of the nonlinear\nactivation functions in k-space.",
      "tldr_zh": "本文提出一种图像空间形式主义，用于分析 convolutional neural networks 在 k-space interpolation 中的噪声传播，针对 RAKI 模型的噪声弹性进行深入研究。通过将 k-space 的非线性激活转化为图像空间的卷积，计算 Jacobians 并量化噪声放大（g-factor maps），以提供可分析的噪声传播机制。结果显示，这种方法与 Monte Carlo 模拟一致，识别了模糊和对比度损失 artifacts，并通过调整 leaky ReLU 的负斜率参数实现 artifacts 与噪声弹性的权衡。该形式主义增强了 RAKI 的可解释性，为 MRI 重建提供了一个人类可读的非线性激活可视化工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17410v2",
      "published_date": "2024-02-27 11:01:58 UTC",
      "updated_date": "2025-05-09 10:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:38:16.273868"
    },
    {
      "arxiv_id": "2402.17407v2",
      "title": "A Neural Rewriting System to Solve Algorithmic Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Flavio Petruzzellis",
        "Alberto Testolin",
        "Alessandro Sperduti"
      ],
      "abstract": "Modern neural network architectures still struggle to learn algorithmic\nprocedures that require to systematically apply compositional rules to solve\nout-of-distribution problem instances. In this work, we focus on formula\nsimplification problems, a class of synthetic benchmarks used to study the\nsystematic generalization capabilities of neural architectures. We propose a\nmodular architecture designed to learn a general procedure for solving nested\nmathematical formulas by only relying on a minimal set of training examples.\nInspired by rewriting systems, a classic framework in symbolic artificial\nintelligence, we include in the architecture three specialized and interacting\nmodules: the Selector, trained to identify solvable sub-expressions; the\nSolver, mapping sub-expressions to their values; and the Combiner, replacing\nsub-expressions in the original formula with the solution provided by the\nSolver. We benchmark our system against the Neural Data Router, a recent model\nspecialized for systematic generalization, and a state-of-the-art large\nlanguage model (GPT-4) probed with advanced prompting strategies. We\ndemonstrate that our approach achieves a higher degree of out-of-distribution\ngeneralization compared to these alternative approaches on three different\ntypes of formula simplification problems, and we discuss its limitations by\nanalyzing its failures.",
      "tldr_zh": "该研究针对神经网络在处理需要系统应用组合规则的算法问题时存在的系统化泛化难题，提出了一种模块化神经重写系统（neural rewriting system），专注于公式简化问题。该系统仅依赖少量训练示例，通过三个交互模块——Selector（识别可解决子表达式）、Solver（映射子表达式到其值）和Combiner（替换子表达式）——来学习处理嵌套数学公式的通用程序。与Neural Data Router和GPT-4相比，该方法在三种公式简化问题上实现了更高的out-of-distribution泛化能力。研究还分析了其局限性，通过失败案例讨论了潜在改进方向。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.NE",
      "comment": "Updated version (v2) accepted at the 27th European Conference on\n  Artificial Intelligence (ECAI 24)",
      "pdf_url": "http://arxiv.org/pdf/2402.17407v2",
      "published_date": "2024-02-27 10:57:07 UTC",
      "updated_date": "2024-07-12 15:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:38:28.505909"
    },
    {
      "arxiv_id": "2402.17406v1",
      "title": "LSPT: Long-term Spatial Prompt Tuning for Visual Representation Learning",
      "title_zh": "LSPT：长期空间提示调优用于视觉表示学习",
      "authors": [
        "Shentong Mo",
        "Yansen Wang",
        "Xufang Luo",
        "Dongsheng Li"
      ],
      "abstract": "Visual Prompt Tuning (VPT) techniques have gained prominence for their\ncapacity to adapt pre-trained Vision Transformers (ViTs) to downstream visual\ntasks using specialized learnable tokens termed as prompts. Contemporary VPT\nmethodologies, especially when employed with self-supervised vision\ntransformers, often default to the introduction of new learnable prompts or\ngated prompt tokens predominantly sourced from the model's previous block. A\npivotal oversight in such approaches is their failure to harness the potential\nof long-range previous blocks as sources of prompts within each self-supervised\nViT. To bridge this crucial gap, we introduce Long-term Spatial Prompt Tuning\n(LSPT) - a revolutionary approach to visual representation learning. Drawing\ninspiration from the intricacies of the human brain, LSPT ingeniously\nincorporates long-term gated prompts. This feature serves as temporal coding,\ncurbing the risk of forgetting parameters acquired from earlier blocks. Further\nenhancing its prowess, LSPT brings into play patch tokens, serving as spatial\ncoding. This is strategically designed to perpetually amass class-conscious\nfeatures, thereby fortifying the model's prowess in distinguishing and\nidentifying visual categories. To validate the efficacy of our proposed method,\nwe engaged in rigorous experimentation across 5 FGVC and 19 VTAB-1K benchmarks.\nOur empirical findings underscore the superiority of LSPT, showcasing its\nability to set new benchmarks in visual prompt tuning performance.",
      "tldr_zh": "本研究提出 Long-term Spatial Prompt Tuning (LSPT)，一种创新方法，用于提升 Visual Prompt Tuning (VPT) 在预训练 Vision Transformers (ViTs) 上的适应性，特别是针对自监督模型中忽略长程先前块提示的问题。LSPT 借鉴人类大脑机制，引入长程门控提示作为时间编码，以防止参数遗忘，并利用 patch tokens 作为空间编码来积累类别意识特征，从而增强视觉表示学习的能力。在 5 个 FGVC 和 19 个 VTAB-1K 基准上的实验结果表明，LSPT 显著优于现有方法，树立了新的视觉提示调优性能基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17406v1",
      "published_date": "2024-02-27 10:55:07 UTC",
      "updated_date": "2024-02-27 10:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:38:39.985133"
    },
    {
      "arxiv_id": "2402.17398v3",
      "title": "A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)",
      "title_zh": "翻译失败",
      "authors": [
        "Nishikanta Mohanty",
        "Bikash K. Behera",
        "Christopher Ferrie",
        "Pravat Dash"
      ],
      "abstract": "The paper proposes the Quantum-SMOTE method, a novel solution that uses\nquantum computing techniques to solve the prevalent problem of class imbalance\nin machine learning datasets. Quantum-SMOTE, inspired by the Synthetic Minority\nOversampling Technique (SMOTE), generates synthetic data points using quantum\nprocesses such as swap tests and quantum rotation. The process varies from the\nconventional SMOTE algorithm's usage of K-Nearest Neighbors (KNN) and Euclidean\ndistances, enabling synthetic instances to be generated from minority class\ndata points without relying on neighbor proximity. The algorithm asserts\ngreater control over the synthetic data generation process by introducing\nhyperparameters such as rotation angle, minority percentage, and splitting\nfactor, which allow for customization to specific dataset requirements. Due to\nthe use of a compact swap test, the algorithm can accommodate a large number of\nfeatures. Furthermore, the approach is tested on a public dataset of Telecom\nChurn and evaluated alongside two prominent classification algorithms, Random\nForest and Logistic Regression, to determine its impact along with varying\nproportions of synthetic data.",
      "tldr_zh": "本论文提出了一种名为 Quantum-SMOTE 的新方法，利用量子计算技术（如 swap tests 和 quantum rotation）来解决机器学习数据集中的类别不平衡问题。该方法以传统的 Synthetic Minority Oversampling Technique (SMOTE) 为灵感，但改用量子过程生成合成数据点，而非依赖 K-Nearest Neighbors (KNN) 和 Euclidean distances，从而允许更灵活的控制，通过超参数如 rotation angle、minority percentage 和 splitting factor 自定义生成过程。实验在 Telecom Churn 公共数据集上进行，与 Random Forest 和 Logistic Regression 分类算法结合，证明 Quantum-SMOTE 能有效处理大量特征并改善模型性能。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "42 Pages, 23 Figures, 2 Tables",
      "pdf_url": "http://arxiv.org/pdf/2402.17398v3",
      "published_date": "2024-02-27 10:46:36 UTC",
      "updated_date": "2024-07-04 10:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:38:50.948887"
    },
    {
      "arxiv_id": "2402.17396v2",
      "title": "Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies",
      "title_zh": "GPT-4 在算法问题上的基准测试：提示策略的系统性评估",
      "authors": [
        "Flavio Petruzzellis",
        "Alberto Testolin",
        "Alessandro Sperduti"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Processing thanks to their ability to reuse knowledge acquired on\nmassive text corpora on a wide variety of downstream tasks, with minimal (if\nany) tuning steps. At the same time, it has been repeatedly shown that LLMs\nlack systematic generalization, which allows to extrapolate the learned\nstatistical regularities outside the training distribution. In this work, we\noffer a systematic benchmarking of GPT-4, one of the most advanced LLMs\navailable, on three algorithmic tasks characterized by the possibility to\ncontrol the problem difficulty with two parameters. We compare the performance\nof GPT-4 with that of its predecessor (GPT-3.5) and with a variant of the\nTransformer-Encoder architecture recently introduced to solve similar tasks,\nthe Neural Data Router. We find that the deployment of advanced prompting\ntechniques allows GPT-4 to reach superior accuracy on all tasks, demonstrating\nthat state-of-the-art LLMs constitute a very strong baseline also in\nchallenging tasks that require systematic generalization.",
      "tldr_zh": "本论文系统评估了 GPT-4 在算法问题上的性能，重点考察了不同提示策略的影响，以揭示大型语言模型 (LLMs) 在系统化泛化方面的能力。研究者选择了三个算法任务，这些任务的难度可通过两个参数控制，并将 GPT-4 与 GPT-3.5 以及 Neural Data Router 模型进行比较。结果显示，采用高级提示技术后，GPT-4 在所有任务中实现了更高的准确率，证明了 state-of-the-art LLMs 作为系统化泛化挑战任务的强大基线。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024. Added acknowledgements",
      "pdf_url": "http://arxiv.org/pdf/2402.17396v2",
      "published_date": "2024-02-27 10:44:52 UTC",
      "updated_date": "2024-07-11 15:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:39:04.163974"
    },
    {
      "arxiv_id": "2402.17389v1",
      "title": "FairBelief -- Assessing Harmful Beliefs in Language Models",
      "title_zh": "FairBelief -- 评估语言模型中的有害信念",
      "authors": [
        "Mattia Setzu",
        "Marta Marchiori Manerba",
        "Pasquale Minervini",
        "Debora Nozza"
      ],
      "abstract": "Language Models (LMs) have been shown to inherit undesired biases that might\nhurt minorities and underrepresented groups if such systems were integrated\ninto real-world applications without careful fairness auditing. This paper\nproposes FairBelief, an analytical approach to capture and assess beliefs,\ni.e., propositions that an LM may embed with different degrees of confidence\nand that covertly influence its predictions. With FairBelief, we leverage\nprompting to study the behavior of several state-of-the-art LMs across\ndifferent previously neglected axes, such as model scale and likelihood,\nassessing predictions on a fairness dataset specifically designed to quantify\nLMs' outputs' hurtfulness. Finally, we conclude with an in-depth qualitative\nassessment of the beliefs emitted by the models. We apply FairBelief to English\nLMs, revealing that, although these architectures enable high performances on\ndiverse natural language processing tasks, they show hurtful beliefs about\nspecific genders. Interestingly, training procedure and dataset, model scale,\nand architecture induce beliefs of different degrees of hurtfulness.",
      "tldr_zh": "本论文提出 FairBelief，一种分析方法，用于评估语言模型 (LMs) 中潜在的有害信念，这些信念可能以不同信心水平影响模型预测，并导致对少数群体的伤害。研究通过 prompting 技术测试多种状态-of-the-art LMs，在模型规模和似然等新维度上，使用专门设计的数据集量化输出伤害性。结果显示，LMs 往往对特定性别持有有害信念，且这种信念的严重程度受训练过程、数据集、模型规模和架构的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17389v1",
      "published_date": "2024-02-27 10:31:00 UTC",
      "updated_date": "2024-02-27 10:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:39:14.961033"
    },
    {
      "arxiv_id": "2402.17386v1",
      "title": "A case study of sending graph neural networks back to the test bench for applications in high-energy particle physics",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuel Pfeffer",
        "Michael Waßmer",
        "Yee-Ying Cung",
        "Roger Wolf",
        "Ulrich Husemann"
      ],
      "abstract": "In high-energy particle collisions, the primary collision products usually\ndecay further resulting in tree-like, hierarchical structures with a priori\nunknown multiplicity. At the stable-particle level all decay products of a\ncollision form permutation invariant sets of final state objects. The analogy\nto mathematical graphs gives rise to the idea that graph neural networks\n(GNNs), which naturally resemble these properties, should be best-suited to\naddress many tasks related to high-energy particle physics. In this paper we\ndescribe a benchmark test of a typical GNN against neural networks of the\nwell-established deep fully-connected feed-forward architecture. We aim at\nperforming this comparison maximally unbiased in terms of nodes, hidden layers,\nor trainable parameters of the neural networks under study. As physics case we\nuse the classification of the final state X produced in association with top\nquark-antiquark pairs in proton-proton collisions at the Large Hadron Collider\nat CERN, where X stands for a bottom quark-antiquark pair produced either\nnon-resonantly or through the decay of an intermediately produced Z or Higgs\nboson.",
      "tldr_zh": "这篇论文通过一个案例研究，评估了图神经网络 (GNNs) 在高能量粒子物理中的应用性能，焦点在于处理粒子碰撞产生的树状结构和置换不变的最终状态对象。研究者设计了一个基准测试，将典型的 GNN 与传统的深度全连接前馈神经网络 (deep fully-connected feed-forward architecture) 进行无偏比较，确保在节点、隐藏层和可训练参数方面保持一致。作为物理案例，他们使用 Large Hadron Collider 的质子-质子碰撞中，与 top quark-antiquark pairs 相关联的最终状态 X 的分类任务，其中 X 可能为非共振产生的底夸克-反夸克对，或通过 Z 或 Higgs 玻色子的衰变产生。该研究为 GNN 在粒子物理任务中的适用性提供了重要参考。",
      "categories": [
        "hep-ph",
        "cs.AI",
        "hep-ex"
      ],
      "primary_category": "hep-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17386v1",
      "published_date": "2024-02-27 10:26:25 UTC",
      "updated_date": "2024-02-27 10:26:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:39:30.273245"
    },
    {
      "arxiv_id": "2402.17385v1",
      "title": "Determinants of LLM-assisted Decision-Making",
      "title_zh": "LLM辅助决策的决定因素",
      "authors": [
        "Eva Eigner",
        "Thorsten Händler"
      ],
      "abstract": "Decision-making is a fundamental capability in everyday life. Large Language\nModels (LLMs) provide multifaceted support in enhancing human decision-making\nprocesses. However, understanding the influencing factors of LLM-assisted\ndecision-making is crucial for enabling individuals to utilize LLM-provided\nadvantages and minimize associated risks in order to make more informed and\nbetter decisions. This study presents the results of a comprehensive literature\nanalysis, providing a structural overview and detailed analysis of determinants\nimpacting decision-making with LLM support. In particular, we explore the\neffects of technological aspects of LLMs, including transparency and prompt\nengineering, psychological factors such as emotions and decision-making styles,\nas well as decision-specific determinants such as task difficulty and\naccountability. In addition, the impact of the determinants on the\ndecision-making process is illustrated via multiple application scenarios.\nDrawing from our analysis, we develop a dependency framework that systematizes\npossible interactions in terms of reciprocal interdependencies between these\ndeterminants. Our research reveals that, due to the multifaceted interactions\nwith various determinants, factors such as trust in or reliance on LLMs, the\nuser's mental model, and the characteristics of information processing are\nidentified as significant aspects influencing LLM-assisted decision-making\nprocesses. Our findings can be seen as crucial for improving decision quality\nin human-AI collaboration, empowering both users and organizations, and\ndesigning more effective LLM interfaces. Additionally, our work provides a\nfoundation for future empirical investigations on the determinants of\ndecision-making assisted by LLMs.",
      "tldr_zh": "这篇论文通过全面文献分析探讨了大型语言模型(LLMs)辅助决策的决定因素，包括LLMs的技术方面（如透明度和prompt engineering）、心理因素（如情绪和决策风格），以及决策特定因素（如任务难度和accountability）。研究开发了一个依赖框架，系统化了这些因素之间的相互依赖关系，并强调了信任、用户的mental model和信息处理特性对LLM-assisted decision-making过程的影响。最终，该研究为提升人类-AI协作的决策质量、优化LLM接口设计以及未来实证调查提供了重要指导。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17385v1",
      "published_date": "2024-02-27 10:24:50 UTC",
      "updated_date": "2024-02-27 10:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:39:39.923615"
    },
    {
      "arxiv_id": "2402.17376v3",
      "title": "Accelerating Diffusion Sampling with Optimized Time Steps",
      "title_zh": "翻译失败",
      "authors": [
        "Shuchen Xue",
        "Zhaoqiang Liu",
        "Fei Chen",
        "Shifeng Zhang",
        "Tianyang Hu",
        "Enze Xie",
        "Zhenguo Li"
      ],
      "abstract": "Diffusion probabilistic models (DPMs) have shown remarkable performance in\nhigh-resolution image synthesis, but their sampling efficiency is still to be\ndesired due to the typically large number of sampling steps. Recent\nadvancements in high-order numerical ODE solvers for DPMs have enabled the\ngeneration of high-quality images with much fewer sampling steps. While this is\na significant development, most sampling methods still employ uniform time\nsteps, which is not optimal when using a small number of steps. To address this\nissue, we propose a general framework for designing an optimization problem\nthat seeks more appropriate time steps for a specific numerical ODE solver for\nDPMs. This optimization problem aims to minimize the distance between the\nground-truth solution to the ODE and an approximate solution corresponding to\nthe numerical solver. It can be efficiently solved using the constrained trust\nregion method, taking less than $15$ seconds. Our extensive experiments on both\nunconditional and conditional sampling using pixel- and latent-space DPMs\ndemonstrate that, when combined with the state-of-the-art sampling method\nUniPC, our optimized time steps significantly improve image generation\nperformance in terms of FID scores for datasets such as CIFAR-10 and ImageNet,\ncompared to using uniform time steps.",
      "tldr_zh": "该论文针对扩散概率模型 (DPMs) 在图像合成中的采样效率问题，提出了一种优化时间步骤的通用框架，以减少采样步骤并提升性能。该框架通过构建一个最小化 ODE 真实解与近似解距离的优化问题，使用约束信任域方法高效求解，优化过程仅需不到 15 秒。实验结果显示，与均匀时间步骤相比，该方法结合 UniPC 在 CIFAR-10 和 ImageNet 等数据集的无条件和条件采样任务中，显著降低了 FID scores，提高了图像生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17376v3",
      "published_date": "2024-02-27 10:13:30 UTC",
      "updated_date": "2024-07-03 06:16:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:39:50.796004"
    },
    {
      "arxiv_id": "2402.17360v1",
      "title": "CAPT: Category-level Articulation Estimation from a Single Point Cloud Using Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Lian Fu",
        "Ryoichi Ishikawa",
        "Yoshihiro Sato",
        "Takeshi Oishi"
      ],
      "abstract": "The ability to estimate joint parameters is essential for various\napplications in robotics and computer vision. In this paper, we propose CAPT:\ncategory-level articulation estimation from a point cloud using Transformer.\nCAPT uses an end-to-end transformer-based architecture for joint parameter and\nstate estimation of articulated objects from a single point cloud. The proposed\nCAPT methods accurately estimate joint parameters and states for various\narticulated objects with high precision and robustness. The paper also\nintroduces a motion loss approach, which improves articulation estimation\nperformance by emphasizing the dynamic features of articulated objects.\nAdditionally, the paper presents a double voting strategy to provide the\nframework with coarse-to-fine parameter estimation. Experimental results on\nseveral category datasets demonstrate that our methods outperform existing\nalternatives for articulation estimation. Our research provides a promising\nsolution for applying Transformer-based architectures in articulated object\nanalysis.",
      "tldr_zh": "本论文提出CAPT，一种基于Transformer的端到端框架，用于从单个point cloud估计类别级articulation参数和状态。该方法引入motion loss来强调articulated objects的动态特征，并采用double voting strategy实现粗到细的参数估计，提高了整体精度和鲁棒性。实验结果显示，CAPT在多个类别数据集上优于现有方法，为Transformer在articulated object分析中的应用提供了有前景的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17360v1",
      "published_date": "2024-02-27 09:53:16 UTC",
      "updated_date": "2024-02-27 09:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:40:03.866959"
    },
    {
      "arxiv_id": "2403.00014v1",
      "title": "GIN-SD: Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Le Cheng",
        "Peican Zhu",
        "Keke Tang",
        "Chao Gao",
        "Zhen Wang"
      ],
      "abstract": "Source detection in graphs has demonstrated robust efficacy in the domain of\nrumor source identification. Although recent solutions have enhanced\nperformance by leveraging deep neural networks, they often require complete\nuser data. In this paper, we address a more challenging task, rumor source\ndetection with incomplete user data, and propose a novel framework, i.e.,\nSource Detection in Graphs with Incomplete Nodes via Positional Encoding and\nAttentive Fusion (GIN-SD), to tackle this challenge. Specifically, our approach\nutilizes a positional embedding module to distinguish nodes that are incomplete\nand employs a self-attention mechanism to focus on nodes with greater\ninformation transmission capacity. To mitigate the prediction bias caused by\nthe significant disparity between the numbers of source and non-source nodes,\nwe also introduce a class-balancing mechanism. Extensive experiments validate\nthe effectiveness of GIN-SD and its superiority to state-of-the-art methods.",
      "tldr_zh": "该论文针对图中源检测（如谣言源识别）的挑战，提出了一种新框架 GIN-SD，用于处理节点不完整的情况。具体来说，GIN-SD 利用 positional encoding 模块区分不完整节点，并通过 self-attention mechanism 关注信息传输能力强的节点，同时引入 class-balancing mechanism 来缓解源节点和非源节点数量不均导致的预测偏差。实验结果表明，GIN-SD 在广泛测试中优于现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "The paper is accepted by AAAI24",
      "pdf_url": "http://arxiv.org/pdf/2403.00014v1",
      "published_date": "2024-02-27 09:35:54 UTC",
      "updated_date": "2024-02-27 09:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:40:16.439893"
    },
    {
      "arxiv_id": "2402.17345v1",
      "title": "LocalGCL: Local-aware Contrastive Learning for Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Haojun Jiang",
        "Jiawei Sun",
        "Jie Li",
        "Chentao Wu"
      ],
      "abstract": "Graph representation learning (GRL) makes considerable progress recently,\nwhich encodes graphs with topological structures into low-dimensional\nembeddings. Meanwhile, the time-consuming and costly process of annotating\ngraph labels manually prompts the growth of self-supervised learning (SSL)\ntechniques. As a dominant approach of SSL, Contrastive learning (CL) learns\ndiscriminative representations by differentiating between positive and negative\nsamples. However, when applied to graph data, it overemphasizes global patterns\nwhile neglecting local structures. To tackle the above issue, we propose\n\\underline{Local}-aware \\underline{G}raph \\underline{C}ontrastive\n\\underline{L}earning (\\textbf{\\methnametrim}), a self-supervised learning\nframework that supplementarily captures local graph information with\nmasking-based modeling compared with vanilla contrastive learning. Extensive\nexperiments validate the superiority of \\methname against state-of-the-art\nmethods, demonstrating its promise as a comprehensive graph representation\nlearner.",
      "tldr_zh": "该论文探讨了图表示学习(Graph Representation Learning)中的挑战，即现有对比学习(Contrastive Learning)方法过度强调全局模式而忽略局部结构，导致自监督学习(Self-Supervised Learning)效果不佳。针对这一问题，研究者提出LocalGCL，一种基于掩码建模的框架，用于补充捕获局部图信息，同时保留对比学习的优势。通过广泛实验验证，LocalGCL在多个基准上优于最先进方法，展示了其作为全面图表示学习器的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17345v1",
      "published_date": "2024-02-27 09:23:54 UTC",
      "updated_date": "2024-02-27 09:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:40:27.936871"
    },
    {
      "arxiv_id": "2402.17339v1",
      "title": "SocialCVAE: Predicting Pedestrian Trajectory via Interaction Conditioned Latents",
      "title_zh": "SocialCVAE：通过交互条件化的潜在变量预测行人轨迹",
      "authors": [
        "Wei Xiang",
        "Haoteng Yin",
        "He Wang",
        "Xiaogang Jin"
      ],
      "abstract": "Pedestrian trajectory prediction is the key technology in many applications\nfor providing insights into human behavior and anticipating human future\nmotions. Most existing empirical models are explicitly formulated by observed\nhuman behaviors using explicable mathematical terms with a deterministic\nnature, while recent work has focused on developing hybrid models combined with\nlearning-based techniques for powerful expressiveness while maintaining\nexplainability. However, the deterministic nature of the learned steering\nbehaviors from the empirical models limits the models' practical performance.\nTo address this issue, this work proposes the social conditional variational\nautoencoder (SocialCVAE) for predicting pedestrian trajectories, which employs\na CVAE to explore behavioral uncertainty in human motion decisions. SocialCVAE\nlearns socially reasonable motion randomness by utilizing a socially\nexplainable interaction energy map as the CVAE's condition, which illustrates\nthe future occupancy of each pedestrian's local neighborhood area. The energy\nmap is generated using an energy-based interaction model, which anticipates the\nenergy cost (i.e., repulsion intensity) of pedestrians' interactions with\nneighbors. Experimental results on two public benchmarks including 25 scenes\ndemonstrate that SocialCVAE significantly improves prediction accuracy compared\nwith the state-of-the-art methods, with up to 16.85% improvement in Average\nDisplacement Error (ADE) and 69.18% improvement in Final Displacement Error\n(FDE).",
      "tldr_zh": "本研究提出 SocialCVAE，一种基于条件变分自编码器 (CVAE) 的模型，用于预测行人轨迹，旨在处理现有确定性模型在人类行为不确定性方面的局限性。SocialCVAE 通过利用基于能量的交互模型生成社会可解释的能量地图作为条件，来捕捉行人互动中的随机性，该能量地图反映了行人局部邻域的未来占用和排斥强度。实验结果显示，在两个公共基准数据集上，SocialCVAE 相较于最先进方法，Average Displacement Error (ADE) 改善高达 16.85%，Final Displacement Error (FDE) 改善高达 69.18%，显著提升了预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI'24",
      "pdf_url": "http://arxiv.org/pdf/2402.17339v1",
      "published_date": "2024-02-27 09:13:27 UTC",
      "updated_date": "2024-02-27 09:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:40:39.789855"
    },
    {
      "arxiv_id": "2402.17334v2",
      "title": "BiVRec: Bidirectional View-based Multimodal Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxi Hu",
        "Jingtong Gao",
        "Xiangyu Zhao",
        "Yuehong Hu",
        "Yuxuan Liang",
        "Yiqi Wang",
        "Ming He",
        "Zitao Liu",
        "Hongzhi Yin"
      ],
      "abstract": "The integration of multimodal information into sequential recommender systems\nhas attracted significant attention in recent research. In the initial stages\nof multimodal sequential recommendation models, the mainstream paradigm was\nID-dominant recommendations, wherein multimodal information was fused as side\ninformation. However, due to their limitations in terms of transferability and\ninformation intrusion, another paradigm emerged, wherein multimodal features\nwere employed directly for recommendation, enabling recommendation across\ndatasets. Nonetheless, it overlooked user ID information, resulting in low\ninformation utilization and high training costs. To this end, we propose an\ninnovative framework, BivRec, that jointly trains the recommendation tasks in\nboth ID and multimodal views, leveraging their synergistic relationship to\nenhance recommendation performance bidirectionally. To tackle the information\nheterogeneity issue, we first construct structured user interest\nrepresentations and then learn the synergistic relationship between them.\nSpecifically, BivRec comprises three modules: Multi-scale Interest Embedding,\ncomprehensively modeling user interests by expanding user interaction sequences\nwith multi-scale patching; Intra-View Interest Decomposition, constructing\nhighly structured interest representations using carefully designed Gaussian\nattention and Cluster attention; and Cross-View Interest Learning, learning the\nsynergistic relationship between the two recommendation views through\ncoarse-grained overall semantic similarity and fine-grained interest allocation\nsimilarity BiVRec achieves state-of-the-art performance on five datasets and\nshowcases various practical advantages.",
      "tldr_zh": "该研究提出了一种创新框架BiVRec，用于多模态顺序推荐（Multimodal Sequential Recommendation），它通过双向视图（bidirectional view）联合训练ID和多模态特征，解决传统方法的局限性，如信息利用率低和训练成本高。框架包括三个关键模块：Multi-scale Interest Embedding扩展用户交互序列以全面建模用户兴趣；Intra-View Interest Decomposition利用Gaussian attention和Cluster attention构建结构化的兴趣表示；Cross-View Interest Learning通过粗粒度和细粒度相似性学习两个视图的协同关系，从而提升推荐性能。实验结果显示，BiVRec在五个数据集上达到state-of-the-art性能，并展示了实际优势，如更好的信息异质性处理和效率提升。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17334v2",
      "published_date": "2024-02-27 09:10:41 UTC",
      "updated_date": "2024-03-05 04:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:40:53.112748"
    },
    {
      "arxiv_id": "2402.17304v3",
      "title": "Probing Multimodal Large Language Models for Global and Local Semantic Representations",
      "title_zh": "探究多模态大型语言模型的全局和局部语义表示",
      "authors": [
        "Mingxu Tao",
        "Quzhe Huang",
        "Kun Xu",
        "Liwei Chen",
        "Yansong Feng",
        "Dongyan Zhao"
      ],
      "abstract": "The advancement of Multimodal Large Language Models (MLLMs) has greatly\naccelerated the development of applications in understanding integrated texts\nand images. Recent works leverage image-caption datasets to train MLLMs,\nachieving state-of-the-art performance on image-to-text tasks. However, there\nare few studies exploring which layers of MLLMs make the most effort to the\nglobal image information, which plays vital roles in multimodal comprehension\nand generation. In this study, we find that the intermediate layers of models\ncan encode more global semantic information, whose representation vectors\nperform better on visual-language entailment tasks, rather than the topmost\nlayers. We further probe models regarding local semantic representations\nthrough object recognition tasks. We find that the topmost layers may\nexcessively focus on local information, leading to a diminished ability to\nencode global information. Our code and data are released via\nhttps://github.com/kobayashikanna01/probing_MLLM_rep.",
      "tldr_zh": "本研究探讨了Multimodal Large Language Models (MLLMs)在处理全局和局部语义表示方面的表现，重点分析这些模型在图像-文本任务中的层级贡献。研究者通过视觉-语言蕴含任务发现，MLLMs的中间层更有效地编码全局语义信息，其表示向量在相关任务中表现优于顶层层。进一步的物体识别任务表明，顶层层过度关注局部信息，导致全局信息编码能力减弱。该研究发布了代码和数据（https://github.com/kobayashikanna01/probing_MLLM_rep），为优化MLLMs的语义理解提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by LREC-COLING 2024 as a short paper. ACL Anthology URL:\n  [https://aclanthology.org/2024.lrec-main.1142/]",
      "pdf_url": "http://arxiv.org/pdf/2402.17304v3",
      "published_date": "2024-02-27 08:27:15 UTC",
      "updated_date": "2024-11-21 07:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:41:04.162848"
    },
    {
      "arxiv_id": "2402.17289v2",
      "title": "Active propulsion noise shaping for multi-rotor aircraft localization",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriele Serussi",
        "Tamir Shor",
        "Tom Hirshberg",
        "Chaim Baskin",
        "Alex Bronstein"
      ],
      "abstract": "Multi-rotor aerial autonomous vehicles (MAVs) primarily rely on vision for\nnavigation purposes. However, visual localization and odometry techniques\nsuffer from poor performance in low or direct sunlight, a limited field of\nview, and vulnerability to occlusions. Acoustic sensing can serve as a\ncomplementary or even alternative modality for vision in many situations, and\nit also has the added benefits of lower system cost and energy footprint, which\nis especially important for micro aircraft. This paper proposes actively\ncontrolling and shaping the aircraft propulsion noise generated by the rotors\nto benefit localization tasks, rather than considering it a harmful nuisance.\nWe present a neural network architecture for selfnoise-based localization in a\nknown environment. We show that training it simultaneously with learning\ntime-varying rotor phase modulation achieves accurate and robust localization.\nThe proposed methods are evaluated using a computationally affordable\nsimulation of MAV rotor noise in 2D acoustic environments that is fitted to\nreal recordings of rotor pressure fields.",
      "tldr_zh": "本研究针对多旋翼无人机(MAVs)视觉导航的局限性（如低光环境和遮挡），提出主动控制和塑造推进噪声的方法，以作为声学感知的补充或替代。\n他们设计了一个神经网络架构，用于自噪声-based localization，并通过同时学习时间变化的转子相位调制来实现准确训练。\n实验结果显示，该方法在模拟的2D声学环境中表现出色，实现了鲁棒的定位性能，并与真实转子压力场记录相符。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17289v2",
      "published_date": "2024-02-27 08:02:48 UTC",
      "updated_date": "2024-02-29 15:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:41:15.966812"
    },
    {
      "arxiv_id": "2402.17285v1",
      "title": "Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder Super-resolution Network",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoyang Wang",
        "Dongyang Li",
        "Mingyang Zhang",
        "Hao Luo",
        "Maoguo Gong"
      ],
      "abstract": "Existing hyperspectral image (HSI) super-resolution (SR) methods struggle to\neffectively capture the complex spectral-spatial relationships and low-level\ndetails, while diffusion models represent a promising generative model known\nfor their exceptional performance in modeling complex relations and learning\nhigh and low-level visual features. The direct application of diffusion models\nto HSI SR is hampered by challenges such as difficulties in model convergence\nand protracted inference time. In this work, we introduce a novel\nGroup-Autoencoder (GAE) framework that synergistically combines with the\ndiffusion model to construct a highly effective HSI SR model (DMGASR). Our\nproposed GAE framework encodes high-dimensional HSI data into low-dimensional\nlatent space where the diffusion model works, thereby alleviating the\ndifficulty of training the diffusion model while maintaining band correlation\nand considerably reducing inference time. Experimental results on both natural\nand remote sensing hyperspectral datasets demonstrate that the proposed method\nis superior to other state-of-the-art methods both visually and metrically.",
      "tldr_zh": "该研究针对高光谱图像 (HSI) 超分辨率 (SR) 的挑战，提出了一种结合扩散模型 (diffusion models) 和 Group-Autoencoder (GAE) 框架的创新方法 (DMGASR)，以更好地捕捉复杂的光谱-空间关系和低级细节。GAE 框架将高维 HSI 数据编码到低维潜在空间中，缓解了扩散模型的训练收敛困难，同时保持带相关性和显著减少推理时间。实验结果显示，该方法在自然和遥感高光谱数据集上，在视觉和度量指标上均优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17285v1",
      "published_date": "2024-02-27 07:57:28 UTC",
      "updated_date": "2024-02-27 07:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:41:28.030359"
    },
    {
      "arxiv_id": "2402.17270v2",
      "title": "Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social Dilemmas",
      "title_zh": "翻译失败",
      "authors": [
        "Chunjiang Mu",
        "Hao Guo",
        "Yang Chen",
        "Chen Shen",
        "Shuyue Hu",
        "Zhen Wang"
      ],
      "abstract": "The study of cooperation within social dilemmas has long been a fundamental\ntopic across various disciplines, including computer science and social\nscience. Recent advancements in Artificial Intelligence (AI) have significantly\nreshaped this field, offering fresh insights into understanding and enhancing\ncooperation. This survey examines three key areas at the intersection of AI and\ncooperation in social dilemmas. First, focusing on multi-agent cooperation, we\nreview the intrinsic and external motivations that support cooperation among\nrational agents, and the methods employed to develop effective strategies\nagainst diverse opponents. Second, looking into human-agent cooperation, we\ndiscuss the current AI algorithms for cooperating with humans and the human\nbiases towards AI agents. Third, we review the emergent field of leveraging AI\nagents to enhance cooperation among humans. We conclude by discussing future\nresearch avenues, such as using large language models, establishing unified\ntheoretical frameworks, revisiting existing theories of human cooperation, and\nexploring multiple real-world applications.",
      "tldr_zh": "这篇调查论文审视了人工智能(AI)在社会困境中的合作问题，涵盖三个关键领域：Multi-Agent 合作（包括支持合作的内在/外部动机和策略开发）、Human-Agent 合作（讨论AI算法与人类互动及人类偏见），以及利用AI增强人类间合作。论文总结了AI如何重塑这一领域的见解，并提出未来研究方向，如应用大型语言模型、建立统一理论框架、重新审视人类合作理论，以及探索实际应用。总的来说，它为AI驱动的合作研究提供了全面概述和创新路径。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17270v2",
      "published_date": "2024-02-27 07:31:30 UTC",
      "updated_date": "2024-07-30 12:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:41:39.883059"
    },
    {
      "arxiv_id": "2402.17801v1",
      "title": "Generative AI and Copyright: A Dynamic Perspective",
      "title_zh": "生成式人工智能与版权：动态视角",
      "authors": [
        "S. Alex Yang",
        "Angela Huyue Zhang"
      ],
      "abstract": "The rapid advancement of generative AI is poised to disrupt the creative\nindustry. Amidst the immense excitement for this new technology, its future\ndevelopment and applications in the creative industry hinge crucially upon two\ncopyright issues: 1) the compensation to creators whose content has been used\nto train generative AI models (the fair use standard); and 2) the eligibility\nof AI-generated content for copyright protection (AI-copyrightability). While\nboth issues have ignited heated debates among academics and practitioners, most\nanalysis has focused on their challenges posed to existing copyright doctrines.\nIn this paper, we aim to better understand the economic implications of these\ntwo regulatory issues and their interactions. By constructing a dynamic model\nwith endogenous content creation and AI model development, we unravel the\nimpacts of the fair use standard and AI-copyrightability on AI development, AI\ncompany profit, creators income, and consumer welfare, and how these impacts\nare influenced by various economic and operational factors. For example, while\ngenerous fair use (use data for AI training without compensating the creator)\nbenefits all parties when abundant training data exists, it can hurt creators\nand consumers when such data is scarce. Similarly, stronger AI-copyrightability\n(AI content enjoys more copyright protection) could hinder AI development and\nreduce social welfare. Our analysis also highlights the complex interplay\nbetween these two copyright issues. For instance, when existing training data\nis scarce, generous fair use may be preferred only when AI-copyrightability is\nweak. Our findings underscore the need for policymakers to embrace a dynamic,\ncontext-specific approach in making regulatory decisions and provide insights\nfor business leaders navigating the complexities of the global regulatory\nenvironment.",
      "tldr_zh": "这篇论文从动态视角探讨生成式 AI 对创意产业的潜在影响，焦点在于两个关键版权问题：公平使用标准（是否需补偿创作者用于 AI 训练的数据）和 AI-copyrightability（AI 生成内容是否享有版权保护）。作者构建了一个动态模型，分析这些问题对 AI 发展、AI 公司利润、创作者收入以及消费者福利的影响，并考察了经济因素如训练数据可用性的作用。研究发现，当训练数据充足时，宽松的公平使用标准可能对各方有益，但数据稀缺时则可能损害创作者和消费者利益；此外，更强的 AI-copyrightability 可能阻碍 AI 发展并降低社会福利。论文强调，这两个问题存在复杂互动，政策制定者应采用动态、情境特定的方法来制定法规。",
      "categories": [
        "econ.TH",
        "cs.AI"
      ],
      "primary_category": "econ.TH",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17801v1",
      "published_date": "2024-02-27 07:12:48 UTC",
      "updated_date": "2024-02-27 07:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:41:52.240309"
    },
    {
      "arxiv_id": "2402.17262v2",
      "title": "Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenhong Zhou",
        "Jiuyang Xiang",
        "Haopeng Chen",
        "Quan Liu",
        "Zherui Li",
        "Sen Su"
      ],
      "abstract": "Large Language Models (LLMs) have been demonstrated to generate illegal or\nunethical responses, particularly when subjected to \"jailbreak.\" Research on\njailbreak has highlighted the safety issues of LLMs. However, prior studies\nhave predominantly focused on single-turn dialogue, ignoring the potential\ncomplexities and risks presented by multi-turn dialogue, a crucial mode through\nwhich humans derive information from LLMs. In this paper, we argue that humans\ncould exploit multi-turn dialogue to induce LLMs into generating harmful\ninformation. LLMs may not intend to reject cautionary or borderline unsafe\nqueries, even if each turn is closely served for one malicious purpose in a\nmulti-turn dialogue. Therefore, by decomposing an unsafe query into several\nsub-queries for multi-turn dialogue, we induced LLMs to answer harmful\nsub-questions incrementally, culminating in an overall harmful response. Our\nexperiments, conducted across a wide range of LLMs, indicate current\ninadequacies in the safety mechanisms of LLMs in multi-turn dialogue. Our\nfindings expose vulnerabilities of LLMs in complex scenarios involving\nmulti-turn dialogue, presenting new challenges for the safety of LLMs.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在多轮对话中的安全漏洞，指出人类可以通过“jailbreak”技术诱导模型生成有害信息，而现有研究主要关注单轮对话。作者的方法是将一个不安全查询分解成多个子查询，并在多轮对话中逐步提问，使 LLMs 逐步回答有害内容。实验结果显示，在多种 LLMs 上，这种策略导致安全机制失效，准确暴露了多轮对话场景下的新挑战和风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "working in progress 23pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.17262v2",
      "published_date": "2024-02-27 07:11:59 UTC",
      "updated_date": "2024-10-30 05:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:42:05.399974"
    },
    {
      "arxiv_id": "2402.17257v4",
      "title": "RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Cheng",
        "Gang Xiong",
        "Xingyuan Dai",
        "Qinghai Miao",
        "Yisheng Lv",
        "Fei-Yue Wang"
      ],
      "abstract": "Preference-based Reinforcement Learning (PbRL) circumvents the need for\nreward engineering by harnessing human preferences as the reward signal.\nHowever, current PbRL methods excessively depend on high-quality feedback from\ndomain experts, which results in a lack of robustness. In this paper, we\npresent RIME, a robust PbRL algorithm for effective reward learning from noisy\npreferences. Our method utilizes a sample selection-based discriminator to\ndynamically filter out noise and ensure robust training. To counteract the\ncumulative error stemming from incorrect selection, we suggest a warm start for\nthe reward model, which additionally bridges the performance gap during the\ntransition from pre-training to online training in PbRL. Our experiments on\nrobotic manipulation and locomotion tasks demonstrate that RIME significantly\nenhances the robustness of the state-of-the-art PbRL method. Code is available\nat https://github.com/CJReinforce/RIME_ICML2024.",
      "tldr_zh": "该论文提出 RIME，一种鲁棒的 Preference-based Reinforcement Learning (PbRL) 算法，用于从 noisy preferences 中有效学习奖励信号，从而解决当前 PbRL 方法对高质量反馈的过度依赖问题。RIME 采用 sample selection-based discriminator 动态过滤噪声，并引入 warm start for the reward model 来减少累积错误并桥接预训练与在线训练的性能差距。在机器人操作和运动任务的实验中，RIME 显著提升了最先进 PbRL 方法的鲁棒性，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024 (Spotlight, top 3.5%)",
      "pdf_url": "http://arxiv.org/pdf/2402.17257v4",
      "published_date": "2024-02-27 07:03:25 UTC",
      "updated_date": "2024-10-28 12:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:42:17.138894"
    },
    {
      "arxiv_id": "2402.17249v1",
      "title": "Deep Learning-Based Speech and Vision Synthesis to Improve Phishing Attack Detection through a Multi-layer Adaptive Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Tosin Ige",
        "Christopher Kiekintveld",
        "Aritran Piplai"
      ],
      "abstract": "The ever-evolving ways attacker continues to im prove their phishing\ntechniques to bypass existing state-of-the-art phishing detection methods pose\na mountain of challenges to researchers in both industry and academia research\ndue to the inability of current approaches to detect complex phishing attack.\nThus, current anti-phishing methods remain vulnerable to complex phishing\nbecause of the increasingly sophistication tactics adopted by attacker coupled\nwith the rate at which new tactics are being developed to evade detection. In\nthis research, we proposed an adaptable framework that combines Deep learning\nand Randon Forest to read images, synthesize speech from deep-fake videos, and\nnatural language processing at various predictions layered to significantly\nincrease the performance of machine learning models for phishing attack\ndetection.",
      "tldr_zh": "本研究针对攻击者不断升级的钓鱼技术导致现有检测方法失效的问题，提出了一种基于深度学习的多层自适应框架，以提升网络钓鱼攻击检测性能。该框架结合Random Forest算法、图像读取、从deep-fake视频合成语音以及Natural Language Processing的多层预测机制，实现对复杂攻击的全面分析。实验结果显示，该框架显著提高了机器学习模型的准确性和适应性，为更有效的反钓鱼策略提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "8",
      "pdf_url": "http://arxiv.org/pdf/2402.17249v1",
      "published_date": "2024-02-27 06:47:52 UTC",
      "updated_date": "2024-02-27 06:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:42:28.857978"
    },
    {
      "arxiv_id": "2402.17245v1",
      "title": "Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Daiqing Li",
        "Aleks Kamko",
        "Ehsan Akhgari",
        "Ali Sabet",
        "Linmiao Xu",
        "Suhail Doshi"
      ],
      "abstract": "In this work, we share three insights for achieving state-of-the-art\naesthetic quality in text-to-image generative models. We focus on three\ncritical aspects for model improvement: enhancing color and contrast, improving\ngeneration across multiple aspect ratios, and improving human-centric fine\ndetails. First, we delve into the significance of the noise schedule in\ntraining a diffusion model, demonstrating its profound impact on realism and\nvisual fidelity. Second, we address the challenge of accommodating various\naspect ratios in image generation, emphasizing the importance of preparing a\nbalanced bucketed dataset. Lastly, we investigate the crucial role of aligning\nmodel outputs with human preferences, ensuring that generated images resonate\nwith human perceptual expectations. Through extensive analysis and experiments,\nPlayground v2.5 demonstrates state-of-the-art performance in terms of aesthetic\nquality under various conditions and aspect ratios, outperforming both\nwidely-used open-source models like SDXL and Playground v2, and closed-source\ncommercial systems such as DALLE 3 and Midjourney v5.2. Our model is\nopen-source, and we hope the development of Playground v2.5 provides valuable\nguidelines for researchers aiming to elevate the aesthetic quality of\ndiffusion-based image generation models.",
      "tldr_zh": "这篇论文介绍了Playground v2.5模型的三个关键见解，以提升文本到图像生成的美学质量，包括优化噪声调度（noise schedule）来增强颜色和对比度、使用平衡的bucketed dataset处理多种宽高比，以及使输出与人类偏好对齐。通过广泛实验，Playground v2.5在各种条件下表现出色，超越了开源模型如SDXL和Playground v2，以及闭源系统如DALLE 3和Midjourney v5.2。该模型开源，并为扩散模型（diffusion-based）的审美提升提供宝贵指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Model weights:\n  https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic",
      "pdf_url": "http://arxiv.org/pdf/2402.17245v1",
      "published_date": "2024-02-27 06:31:52 UTC",
      "updated_date": "2024-02-27 06:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:42:42.192864"
    },
    {
      "arxiv_id": "2402.17217v2",
      "title": "Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Guo",
        "Weichao Zhou",
        "Wenchao Li"
      ],
      "abstract": "Offline safe reinforcement learning (RL) aims to train a constraint\nsatisfaction policy from a fixed dataset. Current state-of-the-art approaches\nare based on supervised learning with a conditioned policy. However, these\napproaches fall short in real-world applications that involve complex tasks\nwith rich temporal and logical structures. In this paper, we propose temporal\nlogic Specification-conditioned Decision Transformer (SDT), a novel framework\nthat harnesses the expressive power of signal temporal logic (STL) to specify\ncomplex temporal rules that an agent should follow and the sequential modeling\ncapability of Decision Transformer (DT). Empirical evaluations on the DSRL\nbenchmarks demonstrate the better capacity of SDT in learning safe and\nhigh-reward policies compared with existing approaches. In addition, SDT shows\ngood alignment with respect to different desired degrees of satisfaction of the\nSTL specification that it is conditioned on.",
      "tldr_zh": "本研究针对离线安全强化学习（Offline Safe Reinforcement Learning）提出了一种新型框架——Specification-conditioned Decision Transformer (SDT)，它利用信号时序逻辑（Signal Temporal Logic, STL）来指定代理需遵循的复杂时序规则，并结合 Decision Transformer (DT) 的顺序建模能力，以训练满足约束的政策。SDT 能够处理真实世界任务中丰富的时序和逻辑结构，避免了现有监督学习方法的局限性。在 DSRL 基准测试中，SDT 比现有方法表现出更好的性能，能学习出安全且高回报的政策，并根据不同 STL 规范的满意度实现良好对齐。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17217v2",
      "published_date": "2024-02-27 05:16:59 UTC",
      "updated_date": "2025-01-24 23:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:42:52.574393"
    },
    {
      "arxiv_id": "2402.17216v1",
      "title": "Application of Machine Learning Optimization in Cloud Computing Resource Scheduling and Management",
      "title_zh": "机器学习优化在云计算资源调度和管理系统中的应用",
      "authors": [
        "Yifan Zhang",
        "Bo Liu",
        "Yulu Gong",
        "Jiaxin Huang",
        "Jingyu Xu",
        "Weixiang Wan"
      ],
      "abstract": "In recent years, cloud computing has been widely used. Cloud computing refers\nto the centralized computing resources, users through the access to the\ncentralized resources to complete the calculation, the cloud computing center\nwill return the results of the program processing to the user. Cloud computing\nis not only for individual users, but also for enterprise users. By purchasing\na cloud server, users do not have to buy a large number of computers, saving\ncomputing costs. According to a report by China Economic News Network, the\nscale of cloud computing in China has reached 209.1 billion yuan. At present,\nthe more mature cloud service providers in China are Ali Cloud, Baidu Cloud,\nHuawei Cloud and so on. Therefore, this paper proposes an innovative approach\nto solve complex problems in cloud computing resource scheduling and management\nusing machine learning optimization techniques. Through in-depth study of\nchallenges such as low resource utilization and unbalanced load in the cloud\nenvironment, this study proposes a comprehensive solution, including\noptimization methods such as deep learning and genetic algorithm, to improve\nsystem performance and efficiency, and thus bring new breakthroughs and\nprogress in the field of cloud computing resource management.Rational\nallocation of resources plays a crucial role in cloud computing. In the\nresource allocation of cloud computing, the cloud computing center has limited\ncloud resources, and users arrive in sequence. Each user requests the cloud\ncomputing center to use a certain number of cloud resources at a specific time.",
      "tldr_zh": "这篇论文探讨了机器学习优化在云计算资源调度和管理中的应用，针对云环境中的资源利用率低和负载不均衡等问题提出创新解决方案。论文通过采用深度学习和遗传算法等优化技术，设计了一个全面的资源分配框架，以提高系统性能和效率。实验结果表明，该方法能有效处理用户顺序请求的资源分配挑战，推动云计算领域的新突破。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17216v1",
      "published_date": "2024-02-27 05:14:27 UTC",
      "updated_date": "2024-02-27 05:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:43:04.371006"
    },
    {
      "arxiv_id": "2402.17213v1",
      "title": "VCD: Knowledge Base Guided Visual Commonsense Discovery in Images",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangqing Shen",
        "Yurun Song",
        "Siwei Wu",
        "Rui Xia"
      ],
      "abstract": "Visual commonsense contains knowledge about object properties, relationships,\nand behaviors in visual data. Discovering visual commonsense can provide a more\ncomprehensive and richer understanding of images, and enhance the reasoning and\ndecision-making capabilities of computer vision systems. However, the visual\ncommonsense defined in existing visual commonsense discovery studies is\ncoarse-grained and incomplete. In this work, we draw inspiration from a\ncommonsense knowledge base ConceptNet in natural language processing, and\nsystematically define the types of visual commonsense. Based on this, we\nintroduce a new task, Visual Commonsense Discovery (VCD), aiming to extract\nfine-grained commonsense of different types contained within different objects\nin the image. We accordingly construct a dataset (VCDD) from Visual Genome and\nConceptNet for VCD, featuring over 100,000 images and 14 million\nobject-commonsense pairs. We furthermore propose a generative model (VCDM) that\nintegrates a vision-language model with instruction tuning to tackle VCD.\nAutomatic and human evaluations demonstrate VCDM's proficiency in VCD,\nparticularly outperforming GPT-4V in implicit commonsense discovery. The value\nof VCD is further demonstrated by its application to two downstream tasks,\nincluding visual commonsense evaluation and visual question answering. The data\nand code will be made available on GitHub.",
      "tldr_zh": "本文提出了一种基于知识库的视觉常识发现方法（VCD），从ConceptNet中汲取灵感，系统定义视觉常识类型，以提取图像中不同对象的细粒度常识，包括属性、关系和行为，从而提升计算机视觉系统的推理能力。研究构建了VCDD数据集，从Visual Genome和ConceptNet中获取，包含超过10万张图像和1400万对象-常识对，并开发了VCDM模型，该模型整合视觉语言模型与指令调优来处理VCD任务。实验评估显示，VCDM在隐性常识发现上优于GPT-4V，并在视觉常识评估和视觉问答等下游任务中展示了显著价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17213v1",
      "published_date": "2024-02-27 05:10:44 UTC",
      "updated_date": "2024-02-27 05:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:43:18.293014"
    },
    {
      "arxiv_id": "2402.17205v3",
      "title": "Measuring Vision-Language STEM Skills of Neural Models",
      "title_zh": "测量神经模型的视觉-语言 STEM 技能",
      "authors": [
        "Jianhao Shen",
        "Ye Yuan",
        "Srbuhi Mirzoyan",
        "Ming Zhang",
        "Chenguang Wang"
      ],
      "abstract": "We introduce a new challenge to test the STEM skills of neural models. The\nproblems in the real world often require solutions, combining knowledge from\nSTEM (science, technology, engineering, and math). Unlike existing datasets,\nour dataset requires the understanding of multimodal vision-language\ninformation of STEM. Our dataset features one of the largest and most\ncomprehensive datasets for the challenge. It includes 448 skills and 1,073,146\nquestions spanning all STEM subjects. Compared to existing datasets that often\nfocus on examining expert-level ability, our dataset includes fundamental\nskills and questions designed based on the K-12 curriculum. We also add\nstate-of-the-art foundation models such as CLIP and GPT-3.5-Turbo to our\nbenchmark. Results show that the recent model advances only help master a very\nlimited number of lower grade-level skills (2.5% in the third grade) in our\ndataset. In fact, these models are still well below (averaging 54.7%) the\nperformance of elementary students, not to mention near expert-level\nperformance. To understand and increase the performance on our dataset, we\nteach the models on a training split of our dataset. Even though we observe\nimproved performance, the model performance remains relatively low compared to\naverage elementary students. To solve STEM problems, we will need novel\nalgorithmic innovations from the community.",
      "tldr_zh": "这篇论文引入了一个新数据集，用于评估神经模型在视觉-语言 STEM 技能方面的表现，该数据集包含 448 个技能和 1,073,146 个问题，覆盖科学、技术、工程和数学科目，并基于 K-12 课程设计以关注基础技能。不同于现有数据集，该数据集强调多模态视觉-语言信息的理解，并测试了如 CLIP 和 GPT-3.5-Turbo 等先进模型，结果显示这些模型在低年级技能上掌握率极低（如仅 2.5% 在三年级水平），平均性能远低于小学生（54.7%）。作者通过在训练集上微调模型观察到性能改善，但仍不足以达到小学生的水平，并呼吁社区开发新型算法创新来解决 STEM 问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17205v3",
      "published_date": "2024-02-27 04:55:03 UTC",
      "updated_date": "2024-05-22 05:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:43:29.466258"
    },
    {
      "arxiv_id": "2402.17191v1",
      "title": "AI-Driven Anonymization: Protecting Personal Data Privacy While Leveraging Machine Learning",
      "title_zh": "AI驱动的匿名化：保护个人数据隐私的同时利用机器学习",
      "authors": [
        "Le Yang",
        "Miao Tian",
        "Duan Xin",
        "Qishuo Cheng",
        "Jiajian Zheng"
      ],
      "abstract": "The development of artificial intelligence has significantly transformed\npeople's lives. However, it has also posed a significant threat to privacy and\nsecurity, with numerous instances of personal information being exposed online\nand reports of criminal attacks and theft. Consequently, the need to achieve\nintelligent protection of personal information through machine learning\nalgorithms has become a paramount concern. Artificial intelligence leverages\nadvanced algorithms and technologies to effectively encrypt and anonymize\npersonal data, enabling valuable data analysis and utilization while\nsafeguarding privacy. This paper focuses on personal data privacy protection\nand the promotion of anonymity as its core research objectives. It achieves\npersonal data privacy protection and detection through the use of machine\nlearning's differential privacy protection algorithm. The paper also addresses\nexisting challenges in machine learning related to privacy and personal data\nprotection, offers improvement suggestions, and analyzes factors impacting\ndatasets to enable timely personal data privacy detection and protection.",
      "tldr_zh": "该论文探讨了AI如何在保护个人数据隐私的同时，利用机器学习进行数据分析，以应对个人信息泄露和安全威胁。研究重点采用machine learning的differential privacy保护算法，对个人数据进行加密和匿名化处理，从而实现有效的隐私检测和利用。论文分析了machine learning中存在的隐私挑战，提供改进建议，并讨论数据集影响因素，以促进及时的个人数据保护。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.17191v1",
      "published_date": "2024-02-27 04:12:25 UTC",
      "updated_date": "2024-02-27 04:12:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:43:40.496463"
    },
    {
      "arxiv_id": "2402.17189v1",
      "title": "An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Tzu-Ting Yang",
        "Hsin-Wei Wang",
        "Yi-Cheng Wang",
        "Chi-Han Lin",
        "Berlin Chen"
      ],
      "abstract": "With the massive developments of end-to-end (E2E) neural networks, recent\nyears have witnessed unprecedented breakthroughs in automatic speech\nrecognition (ASR). However, the codeswitching phenomenon remains a major\nobstacle that hinders ASR from perfection, as the lack of labeled data and the\nvariations between languages often lead to degradation of ASR performance. In\nthis paper, we focus exclusively on improving the acoustic encoder of E2E ASR\nto tackle the challenge caused by the codeswitching phenomenon. Our main\ncontributions are threefold: First, we introduce a novel disentanglement loss\nto enable the lower-layer of the encoder to capture inter-lingual acoustic\ninformation while mitigating linguistic confusion at the higher-layer of the\nencoder. Second, through comprehensive experiments, we verify that our proposed\nmethod outperforms the prior-art methods using pretrained dual-encoders,\nmeanwhile having access only to the codeswitching corpus and consuming half of\nthe parameterization. Third, the apparent differentiation of the encoders'\noutput features also corroborates the complementarity between the\ndisentanglement loss and the mixture-of-experts (MoE) architecture.",
      "tldr_zh": "这篇论文提出了一种有效的Mixture-Of-Experts (MoE) 方法，用于提升端到端 (E2E) 自动语音识别 (ASR) 在代码切换 (codeswitching) 场景下的性能，通过引入disentanglement loss来优化声学编码器。disentanglement loss使编码器的低层捕捉跨语言声学信息，同时减少高层中的语言混淆，从而提高模型的鲁棒性。实验验证显示，该方法优于现有预训练双编码器方法，仅使用代码切换语料且参数量减半，并且编码器输出特征的差异进一步证实了disentanglement loss与MoE架构的互补性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17189v1",
      "published_date": "2024-02-27 04:08:59 UTC",
      "updated_date": "2024-02-27 04:08:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:43:53.516289"
    },
    {
      "arxiv_id": "2403.07911v2",
      "title": "Standing on FURM ground -- A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems",
      "title_zh": "翻译失败",
      "authors": [
        "Alison Callahan",
        "Duncan McElfresh",
        "Juan M. Banda",
        "Gabrielle Bunney",
        "Danton Char",
        "Jonathan Chen",
        "Conor K. Corbin",
        "Debadutta Dash",
        "Norman L. Downing",
        "Sneha S. Jain",
        "Nikesh Kotecha",
        "Jonathan Masterson",
        "Michelle M. Mello",
        "Keith Morse",
        "Srikar Nallan",
        "Abby Pandya",
        "Anurang Revri",
        "Aditya Sharma",
        "Christopher Sharp",
        "Rahul Thapa",
        "Michael Wornow",
        "Alaa Youssef",
        "Michael A. Pfeffer",
        "Nigam H. Shah"
      ],
      "abstract": "The impact of using artificial intelligence (AI) to guide patient care or\noperational processes is an interplay of the AI model's output, the\ndecision-making protocol based on that output, and the capacity of the\nstakeholders involved to take the necessary subsequent action. Estimating the\neffects of this interplay before deployment, and studying it in real time\nafterwards, are essential to bridge the chasm between AI model development and\nachievable benefit. To accomplish this, the Data Science team at Stanford\nHealth Care has developed a Testing and Evaluation (T&E) mechanism to identify\nfair, useful and reliable AI models (FURM) by conducting an ethical review to\nidentify potential value mismatches, simulations to estimate usefulness,\nfinancial projections to assess sustainability, as well as analyses to\ndetermine IT feasibility, design a deployment strategy, and recommend a\nprospective monitoring and evaluation plan. We report on FURM assessments done\nto evaluate six AI guided solutions for potential adoption, spanning clinical\nand operational settings, each with the potential to impact from several dozen\nto tens of thousands of patients each year. We describe the assessment process,\nsummarize the six assessments, and share our framework to enable others to\nconduct similar assessments. Of the six solutions we assessed, two have moved\ninto a planning and implementation phase. Our novel contributions - usefulness\nestimates by simulation, financial projections to quantify sustainability, and\na process to do ethical assessments - as well as their underlying methods and\nopen source tools, are available for other healthcare systems to conduct\nactionable evaluations of candidate AI solutions.",
      "tldr_zh": "该论文提出FURM框架，用于评估医疗系统中AI模型的公平（Fair）、有用（Useful）和可靠（Reliable）性。该框架包括伦理审查以识别价值冲突、模拟估算有用性、财务预测评估可持续性、IT可行性分析、部署策略设计以及监控计划。研究团队对六种AI解决方案进行了评估，这些解决方案涉及临床和操作场景，可能影响数十到数千患者，其中两项已进入规划和实施阶段。FURM框架的创新贡献在于提供模拟估算、财务投影和伦理评估过程，以及开源工具，供其他医疗系统进行类似评估。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07911v2",
      "published_date": "2024-02-27 03:33:40 UTC",
      "updated_date": "2024-03-14 18:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:44:07.754825"
    },
    {
      "arxiv_id": "2402.17177v3",
      "title": "Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yixin Liu",
        "Kai Zhang",
        "Yuan Li",
        "Zhiling Yan",
        "Chujie Gao",
        "Ruoxi Chen",
        "Zhengqing Yuan",
        "Yue Huang",
        "Hanchi Sun",
        "Jianfeng Gao",
        "Lifang He",
        "Lichao Sun"
      ],
      "abstract": "Sora is a text-to-video generative AI model, released by OpenAI in February\n2024. The model is trained to generate videos of realistic or imaginative\nscenes from text instructions and show potential in simulating the physical\nworld. Based on public technical reports and reverse engineering, this paper\npresents a comprehensive review of the model's background, related\ntechnologies, applications, remaining challenges, and future directions of\ntext-to-video AI models. We first trace Sora's development and investigate the\nunderlying technologies used to build this \"world simulator\". Then, we describe\nin detail the applications and potential impact of Sora in multiple industries\nranging from film-making and education to marketing. We discuss the main\nchallenges and limitations that need to be addressed to widely deploy Sora,\nsuch as ensuring safe and unbiased video generation. Lastly, we discuss the\nfuture development of Sora and video generation models in general, and how\nadvancements in the field could enable new ways of human-AI interaction,\nboosting productivity and creativity of video generation.",
      "tldr_zh": "这篇论文对 OpenAI 的 Sora 模型进行了全面综述，该模型是一种文本到视频（text-to-video）生成 AI，用于从文本指令创建逼真或想象场景的视频。作者通过分析公开技术报告和逆向工程，探讨了 Sora 的发展背景、底层技术（如作为“世界模拟器”）以及在电影、教育和营销等行业的应用潜力。论文指出了 Sora 的主要挑战，包括确保视频生成的安全性和无偏见问题，并展望了未来 Large Vision Models 的发展，可能通过提升人类-AI 交互来增强视频生成的生产力和创意。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "37 pages, 18 figures; GitHub:\n  https://github.com/lichao-sun/SoraReview",
      "pdf_url": "http://arxiv.org/pdf/2402.17177v3",
      "published_date": "2024-02-27 03:30:58 UTC",
      "updated_date": "2024-04-17 18:41:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:44:17.855241"
    },
    {
      "arxiv_id": "2402.17168v1",
      "title": "Benchmarking Data Science Agents",
      "title_zh": "数据科学代理的基准测试",
      "authors": [
        "Yuge Zhang",
        "Qiyang Jiang",
        "Xingyu Han",
        "Nan Chen",
        "Yuqing Yang",
        "Kan Ren"
      ],
      "abstract": "In the era of data-driven decision-making, the complexity of data analysis\nnecessitates advanced expertise and tools of data science, presenting\nsignificant challenges even for specialists. Large Language Models (LLMs) have\nemerged as promising aids as data science agents, assisting humans in data\nanalysis and processing. Yet their practical efficacy remains constrained by\nthe varied demands of real-world applications and complicated analytical\nprocess. In this paper, we introduce DSEval -- a novel evaluation paradigm, as\nwell as a series of innovative benchmarks tailored for assessing the\nperformance of these agents throughout the entire data science lifecycle.\nIncorporating a novel bootstrapped annotation method, we streamline dataset\npreparation, improve the evaluation coverage, and expand benchmarking\ncomprehensiveness. Our findings uncover prevalent obstacles and provide\ncritical insights to inform future advancements in the field.",
      "tldr_zh": "这项研究探讨了大型语言模型(LLMs)作为数据科学代理在复杂数据分析中的潜力及其实际限制，强调了真实应用需求的多样性和分析过程的复杂性。为此，论文引入了DSEval这一新型评估范式，以及一系列创新基准，用于全面评估这些代理在数据科学生命周期中的性能。采用bootstrapped annotation方法，研究简化了数据集准备过程，提高了评估覆盖范围和基准的全面性。最终，研究揭示了数据科学代理的常见障碍，并为该领域的未来发展提供了关键洞见。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Source code and data are available at\n  https://github.com/MetaCopilot/dseval",
      "pdf_url": "http://arxiv.org/pdf/2402.17168v1",
      "published_date": "2024-02-27 03:03:06 UTC",
      "updated_date": "2024-02-27 03:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:44:29.595001"
    },
    {
      "arxiv_id": "2402.17161v1",
      "title": "Large Language Model for Participatory Urban Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhilun Zhou",
        "Yuming Lin",
        "Depeng Jin",
        "Yong Li"
      ],
      "abstract": "Participatory urban planning is the mainstream of modern urban planning that\ninvolves the active engagement of residents. However, the traditional\nparticipatory paradigm requires experienced planning experts and is often\ntime-consuming and costly. Fortunately, the emerging Large Language Models\n(LLMs) have shown considerable ability to simulate human-like agents, which can\nbe used to emulate the participatory process easily. In this work, we introduce\nan LLM-based multi-agent collaboration framework for participatory urban\nplanning, which can generate land-use plans for urban regions considering the\ndiverse needs of residents. Specifically, we construct LLM agents to simulate a\nplanner and thousands of residents with diverse profiles and backgrounds. We\nfirst ask the planner to carry out an initial land-use plan. To deal with the\ndifferent facilities needs of residents, we initiate a discussion among the\nresidents in each community about the plan, where residents provide feedback\nbased on their profiles. Furthermore, to improve the efficiency of discussion,\nwe adopt a fishbowl discussion mechanism, where part of the residents discuss\nand the rest of them act as listeners in each round. Finally, we let the\nplanner modify the plan based on residents' feedback. We deploy our method on\ntwo real-world regions in Beijing. Experiments show that our method achieves\nstate-of-the-art performance in residents satisfaction and inclusion metrics,\nand also outperforms human experts in terms of service accessibility and\necology metrics.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Models (LLMs) 的多智能体协作框架，用于提升参与式城市规划的效率，模拟规划者和居民的互动以生成土地使用计划。框架中，LLM 代理模拟一个规划者制定初始计划，并让成千上万的居民代理根据自身背景进行鱼缸讨论机制（fishbowl discussion）的反馈讨论，以处理多样化需求。实验结果显示，该方法在北京两个真实区域的测试中，在居民满意度、包容性、服务可达性和生态指标上达到了最先进水平，并超过了人类专家的表现。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2402.01698",
      "pdf_url": "http://arxiv.org/pdf/2402.17161v1",
      "published_date": "2024-02-27 02:47:50 UTC",
      "updated_date": "2024-02-27 02:47:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:44:42.611898"
    },
    {
      "arxiv_id": "2402.17156v1",
      "title": "TaxDiff: Taxonomic-Guided Diffusion Model for Protein Sequence Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Zongying",
        "Li Hao",
        "Lv Liuzhenghao",
        "Lin Bin",
        "Zhang Junwu",
        "Chen Calvin Yu-Chian",
        "Yuan Li",
        "Tian Yonghong"
      ],
      "abstract": "Designing protein sequences with specific biological functions and structural\nstability is crucial in biology and chemistry. Generative models already\ndemonstrated their capabilities for reliable protein design. However, previous\nmodels are limited to the unconditional generation of protein sequences and\nlack the controllable generation ability that is vital to biological tasks. In\nthis work, we propose TaxDiff, a taxonomic-guided diffusion model for\ncontrollable protein sequence generation that combines biological species\ninformation with the generative capabilities of diffusion models to generate\nstructurally stable proteins within the sequence space. Specifically, taxonomic\ncontrol information is inserted into each layer of the transformer block to\nachieve fine-grained control. The combination of global and local attention\nensures the sequence consistency and structural foldability of\ntaxonomic-specific proteins. Extensive experiments demonstrate that TaxDiff can\nconsistently achieve better performance on multiple protein sequence generation\nbenchmarks in both taxonomic-guided controllable generation and unconditional\ngeneration. Remarkably, the sequences generated by TaxDiff even surpass those\nproduced by direct-structure-generation models in terms of confidence based on\npredicted structures and require only a quarter of the time of models based on\nthe diffusion model. The code for generating proteins and training new versions\nof TaxDiff is available at:https://github.com/Linzy19/TaxDiff.",
      "tldr_zh": "该研究提出 TaxDiff，一种受 taxonomic（分类学）指导的扩散模型，用于可控蛋白序列生成，以解决现有模型在生物任务中缺乏精细控制的问题。具体而言，TaxDiff 通过在 transformer 块的每个层插入生物物种信息，并结合全局和局部注意力机制，确保生成的蛋白序列具有一致性和结构稳定性。实验结果显示，TaxDiff 在多个蛋白序列生成基准上表现出色，不仅在 taxonomic-guided 和无条件生成中均优于基线模型，其生成的序列在结构预测置信度上甚至超越直接结构生成模型，且仅需四分之一的计算时间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17156v1",
      "published_date": "2024-02-27 02:41:46 UTC",
      "updated_date": "2024-02-27 02:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:44:53.954693"
    },
    {
      "arxiv_id": "2405.00026v1",
      "title": "Enhancing Credit Card Fraud Detection A Neural Network and SMOTE Integrated Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Mengran Zhu",
        "Ye Zhang",
        "Yulu Gong",
        "Changxin Xu",
        "Yafei Xiang"
      ],
      "abstract": "Credit card fraud detection is a critical challenge in the financial sector,\ndemanding sophisticated approaches to accurately identify fraudulent\ntransactions. This research proposes an innovative methodology combining Neural\nNetworks (NN) and Synthet ic Minority Over-sampling Technique (SMOTE) to\nenhance the detection performance. The study addresses the inherent imbalance\nin credit card transaction data, focusing on technical advancements for robust\nand precise fraud detection. Results demonstrat e that the integration of NN\nand SMOTE exhibits superior precision, recall, and F1-score compared to\ntraditional models, highlighting its potential as an advanced solution for\nhandling imbalanced datasets in credit card fraud detection scenarios. This\nrese arch contributes to the ongoing efforts to develop effective and efficient\nmechanisms for safeguarding financial transactions from fraudulent activities.",
      "tldr_zh": "这篇论文提出了一种整合 Neural Networks (NN) 和 SMOTE 的创新方法，以提升信用卡欺诈检测的性能。针对信用卡交易数据中固有的不平衡问题，该方法使用 SMOTE 进行合成少数类过采样，从而改善模型的鲁棒性。实验结果显示，与传统模型相比，该整合方法在精确度、召回率和 F1 分数上表现出显著优势。总体上，这为处理不平衡数据集提供了高效的解决方案，推动了金融交易的安全防护。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00026v1",
      "published_date": "2024-02-27 02:26:04 UTC",
      "updated_date": "2024-02-27 02:26:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:45:05.613823"
    },
    {
      "arxiv_id": "2402.17144v1",
      "title": "Metasql: A Generate-then-Rank Framework for Natural Language to SQL Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuankai Fan",
        "Zhenying He",
        "Tonghui Ren",
        "Can Huang",
        "Yinan Jing",
        "Kai Zhang",
        "X. Sean Wang"
      ],
      "abstract": "The Natural Language Interface to Databases (NLIDB) empowers non-technical\nusers with database access through intuitive natural language (NL)\ninteractions. Advanced approaches, utilizing neural sequence-to-sequence models\nor large-scale language models, typically employ auto-regressive decoding to\ngenerate unique SQL queries sequentially. While these translation models have\ngreatly improved the overall translation accuracy, surpassing 70% on NLIDB\nbenchmarks, the use of auto-regressive decoding to generate single SQL queries\nmay result in sub-optimal outputs, potentially leading to erroneous\ntranslations. In this paper, we propose Metasql, a unified generate-then-rank\nframework that can be flexibly incorporated with existing NLIDBs to\nconsistently improve their translation accuracy. Metasql introduces query\nmetadata to control the generation of better SQL query candidates and uses\nlearning-to-rank algorithms to retrieve globally optimized queries.\nSpecifically, Metasql first breaks down the meaning of the given NL query into\na set of possible query metadata, representing the basic concepts of the\nsemantics. These metadata are then used as language constraints to steer the\nunderlying translation model toward generating a set of candidate SQL queries.\nFinally, Metasql ranks the candidates to identify the best matching one for the\ngiven NL query. Extensive experiments are performed to study Metasql on two\npublic NLIDB benchmarks. The results show that the performance of the\ntranslation models can be effectively improved using Metasql.",
      "tldr_zh": "本研究提出Metasql，一种generate-then-rank框架，用于提升Natural Language to SQL Translation（NLIDB）的准确性，以解决现有auto-regressive decoding方法生成单一SQL查询可能导致次优输出的问题。Metasql首先将自然语言查询分解为query metadata，作为语言约束引导底层翻译模型生成一组候选SQL查询，然后运用learning-to-rank算法对候选查询进行全局排名，以选择最佳匹配。实验在两个公共NLIDB基准上验证了Metasql的有效性，显著提高了翻译模型的性能。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17144v1",
      "published_date": "2024-02-27 02:16:07 UTC",
      "updated_date": "2024-02-27 02:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:45:17.702998"
    },
    {
      "arxiv_id": "2402.17139v1",
      "title": "Video as the New Language for Real-World Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Sherry Yang",
        "Jacob Walker",
        "Jack Parker-Holder",
        "Yilun Du",
        "Jake Bruce",
        "Andre Barreto",
        "Pieter Abbeel",
        "Dale Schuurmans"
      ],
      "abstract": "Both text and video data are abundant on the internet and support large-scale\nself-supervised learning through next token or frame prediction. However, they\nhave not been equally leveraged: language models have had significant\nreal-world impact, whereas video generation has remained largely limited to\nmedia entertainment. Yet video data captures important information about the\nphysical world that is difficult to express in language. To address this gap,\nwe discuss an under-appreciated opportunity to extend video generation to solve\ntasks in the real world. We observe how, akin to language, video can serve as a\nunified interface that can absorb internet knowledge and represent diverse\ntasks. Moreover, we demonstrate how, like language models, video generation can\nserve as planners, agents, compute engines, and environment simulators through\ntechniques such as in-context learning, planning and reinforcement learning. We\nidentify major impact opportunities in domains such as robotics, self-driving,\nand science, supported by recent work that demonstrates how such advanced\ncapabilities in video generation are plausibly within reach. Lastly, we\nidentify key challenges in video generation that mitigate progress. Addressing\nthese challenges will enable video generation models to demonstrate unique\nvalue alongside language models in a wider array of AI applications.",
      "tldr_zh": "这篇论文提出，视频数据作为一种新语言，能够捕捉物理世界的复杂信息，并扩展其应用到真实世界的决策任务中，与文本数据一样支持大规模自监督学习。作者讨论了视频生成如何通过 in-context learning、planning 和 reinforcement learning 等技术，充当规划器、代理、计算引擎和环境模拟器，从而吸收互联网知识并处理多样任务。论文强调视频生成在机器人、自动驾驶和科学领域的潜在影响，但需克服视频生成中的关键挑战，如模型局限性，以实现与语言模型相当的价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17139v1",
      "published_date": "2024-02-27 02:05:29 UTC",
      "updated_date": "2024-02-27 02:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:45:30.209554"
    },
    {
      "arxiv_id": "2402.17135v1",
      "title": "Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Frans",
        "Seohong Park",
        "Pieter Abbeel",
        "Sergey Levine"
      ],
      "abstract": "Can we pre-train a generalist agent from a large amount of unlabeled offline\ntrajectories such that it can be immediately adapted to any new downstream\ntasks in a zero-shot manner? In this work, we present a functional reward\nencoding (FRE) as a general, scalable solution to this zero-shot RL problem.\nOur main idea is to learn functional representations of any arbitrary tasks by\nencoding their state-reward samples using a transformer-based variational\nauto-encoder. This functional encoding not only enables the pre-training of an\nagent from a wide diversity of general unsupervised reward functions, but also\nprovides a way to solve any new downstream tasks in a zero-shot manner, given a\nsmall number of reward-annotated samples. We empirically show that FRE agents\ntrained on diverse random unsupervised reward functions can generalize to solve\nnovel tasks in a range of simulated robotic benchmarks, often outperforming\nprevious zero-shot RL and offline RL methods. Code for this project is provided\nat: https://github.com/kvfrans/fre",
      "tldr_zh": "该论文探讨了如何从大量无标签离线轨迹中预训练一个通用代理，使其能够零样本（zero-shot）方式适应新任务。作者提出了一种功能奖励编码（Functional Reward Encodings, FRE）方法，使用基于 Transformer 的变分自编码器（variational auto-encoder）来编码任务的状态-奖励样本，从而学习任意任务的功能表示。实验结果显示，FRE 代理在多种模拟机器人基准上表现出色，能够泛化到新任务，并通常优于现有的 zero-shot RL 和离线 RL 方法，为无监督强化学习提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17135v1",
      "published_date": "2024-02-27 01:59:02 UTC",
      "updated_date": "2024-02-27 01:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:45:41.426816"
    },
    {
      "arxiv_id": "2402.17128v4",
      "title": "OSCaR: Object State Captioning and State Change Representation",
      "title_zh": "OSCaR：物体状态描述与状态变化表示",
      "authors": [
        "Nguyen Nguyen",
        "Jing Bi",
        "Ali Vosoughi",
        "Yapeng Tian",
        "Pooyan Fazli",
        "Chenliang Xu"
      ],
      "abstract": "The capability of intelligent models to extrapolate and comprehend changes in\nobject states is a crucial yet demanding aspect of AI research, particularly\nthrough the lens of human interaction in real-world settings. This task\ninvolves describing complex visual environments, identifying active objects,\nand interpreting their changes as conveyed through language. Traditional\nmethods, which isolate object captioning and state change detection, offer a\nlimited view of dynamic environments. Moreover, relying on a small set of\nsymbolic words to represent changes has restricted the expressiveness of the\nlanguage. To address these challenges, in this paper, we introduce the Object\nState Captioning and State Change Representation (OSCaR) dataset and benchmark.\nOSCaR consists of 14,084 annotated video segments with nearly 1,000 unique\nobjects from various egocentric video collections. It sets a new testbed for\nevaluating multimodal large language models (MLLMs). Our experiments\ndemonstrate that while MLLMs show some skill, they lack a full understanding of\nobject state changes. The benchmark includes a fine-tuned model that, despite\ninitial capabilities, requires significant improvements in accuracy and\ngeneralization ability for effective understanding of these changes. Our code\nand dataset are available at https://github.com/nguyennm1024/OSCaR.",
      "tldr_zh": "本论文引入了OSCaR数据集和基准，用于评估多模态大型语言模型(MLLMs)在对象状态描述(Object State Captioning)和状态变化表示(State Change Representation)方面的能力，旨在解决传统方法在动态环境中的局限性。OSCaR包含14,084个标注的视频段，涉及近1,000个独特对象，源自各种第一人称视角视频，提供了一个新的测试平台。实验结果表明，MLLMs虽显示出一定技能，但对对象状态变化的理解仍不充分，基准中的微调模型需要进一步提升准确性和泛化能力；相关代码和数据集可从https://github.com/nguyennm1024/OSCaR获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17128v4",
      "published_date": "2024-02-27 01:48:19 UTC",
      "updated_date": "2024-04-02 23:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:45:54.986753"
    },
    {
      "arxiv_id": "2403.05576v1",
      "title": "Understanding Subjectivity through the Lens of Motivational Context in Model-Generated Image Satisfaction",
      "title_zh": "翻译失败",
      "authors": [
        "Senjuti Dutta",
        "Sherol Chen",
        "Sunny Mak",
        "Amnah Ahmad",
        "Katherine Collins",
        "Alena Butryna",
        "Deepak Ramachandran",
        "Krishnamurthy Dvijotham",
        "Ellie Pavlick",
        "Ravi Rajakumar"
      ],
      "abstract": "Image generation models are poised to become ubiquitous in a range of\napplications. These models are often fine-tuned and evaluated using human\nquality judgments that assume a universal standard, failing to consider the\nsubjectivity of such tasks. To investigate how to quantify subjectivity, and\nthe scale of its impact, we measure how assessments differ among human\nannotators across different use cases. Simulating the effects of ordinarily\nlatent elements of annotators subjectivity, we contrive a set of motivations\n(t-shirt graphics, presentation visuals, and phone background images) to\ncontextualize a set of crowdsourcing tasks. Our results show that human\nevaluations of images vary within individual contexts and across combinations\nof contexts. Three key factors affecting this subjectivity are image\nappearance, image alignment with text, and representation of objects mentioned\nin the text. Our study highlights the importance of taking individual users and\ncontexts into account, both when building and evaluating generative models",
      "tldr_zh": "这篇论文探讨了图像生成模型评估中的主观性问题，通过动机上下文（motivational context）来量化人类标注者评估的差异。研究者设计了t-shirt graphics、presentation visuals和phone background images等场景，作为众包任务的背景，模拟标注者主观性的潜在影响。结果显示，图像外观、image alignment和对象representation是关键因素，导致评估在单个上下文和跨上下文组合中存在显著差异。该研究强调，在构建和评估生成模型时，必须考虑个体用户和具体上下文，以提高模型的适用性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05576v1",
      "published_date": "2024-02-27 01:16:55 UTC",
      "updated_date": "2024-02-27 01:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:46:08.194121"
    },
    {
      "arxiv_id": "2402.17101v1",
      "title": "T-HITL Effectively Addresses Problematic Associations in Image Generation and Maintains Overall Visual Quality",
      "title_zh": "T-HITL 有效解决图像生成中的问题性关联并保持整体视觉质量",
      "authors": [
        "Susan Epstein",
        "Li Chen",
        "Alessandro Vecchiato",
        "Ankit Jain"
      ],
      "abstract": "Generative AI image models may inadvertently generate problematic\nrepresentations of people. Past research has noted that millions of users\nengage daily across the world with these models and that the models, including\nthrough problematic representations of people, have the potential to compound\nand accelerate real-world discrimination and other harms (Bianchi et al, 2023).\nIn this paper, we focus on addressing the generation of problematic\nassociations between demographic groups and semantic concepts that may reflect\nand reinforce negative narratives embedded in social data. Building on\nsociological literature (Blumer, 1958) and mapping representations to model\nbehaviors, we have developed a taxonomy to study problematic associations in\nimage generation models. We explore the effectiveness of fine tuning at the\nmodel level as a method to address these associations, identifying a potential\nreduction in visual quality as a limitation of traditional fine tuning. We also\npropose a new methodology with twice-human-in-the-loop (T-HITL) that promises\nimprovements in both reducing problematic associations and also maintaining\nvisual quality. We demonstrate the effectiveness of T-HITL by providing\nevidence of three problematic associations addressed by T-HITL at the model\nlevel. Our contributions to scholarship are two-fold. By defining problematic\nassociations in the context of machine learning models and generative AI, we\nintroduce a conceptual and technical taxonomy for addressing some of these\nassociations. Finally, we provide a method, T-HITL, that addresses these\nassociations and simultaneously maintains visual quality of image model\ngenerations. This mitigation need not be a tradeoff, but rather an enhancement.",
      "tldr_zh": "这篇论文探讨了生成式 AI 图像模型中问题性关联（problematic associations）的问题，这些关联可能强化人口群体与负面概念的负面叙述，并加剧现实世界歧视。作者构建了一个基于社会学文献的分类法（taxonomy）来研究这些问题，并比较了传统微调方法的效果，但发现它可能降低视觉质量。论文提出了一种新方法 T-HITL（twice-human-in-the-loop），通过双重人类参与来有效减少问题性关联，同时保持整体图像视觉质量。实验证明，T-HITL 成功解决了三个具体问题性关联，为 AI 模型的公平性改进提供了概念框架和实用技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.I.2",
        "I.2.1"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.17101v1",
      "published_date": "2024-02-27 00:29:33 UTC",
      "updated_date": "2024-02-27 00:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:46:20.439949"
    },
    {
      "arxiv_id": "2403.00824v2",
      "title": "Information Flow Routes: Automatically Interpreting Language Models at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Ferrando",
        "Elena Voita"
      ],
      "abstract": "Information flows by routes inside the network via mechanisms implemented in\nthe model. These routes can be represented as graphs where nodes correspond to\ntoken representations and edges to operations inside the network. We\nautomatically build these graphs in a top-down manner, for each prediction\nleaving only the most important nodes and edges. In contrast to the existing\nworkflows relying on activation patching, we do this through attribution: this\nallows us to efficiently uncover existing circuits with just a single forward\npass. Additionally, the applicability of our method is far beyond patching: we\ndo not need a human to carefully design prediction templates, and we can\nextract information flow routes for any prediction (not just the ones among the\nallowed templates). As a result, we can talk about model behavior in general,\nfor specific types of predictions, or different domains. We experiment with\nLlama 2 and show that the role of some attention heads is overall important,\ne.g. previous token heads and subword merging heads. Next, we find similarities\nin Llama 2 behavior when handling tokens of the same part of speech. Finally,\nwe show that some model components can be specialized on domains such as coding\nor multilingual texts.",
      "tldr_zh": "该论文提出了一种自动构建信息流动路由的方法，通过自顶向下的归因（attribution）技术，仅需一个前向传递即可高效提取语言模型内部的关键图结构，包括最重要的节点和边，与传统的激活修补（activation patching）方法相比，它无需人为设计预测模板，可适用于任何预测类型。实验在Llama 2模型上显示，某些attention heads（如previous token heads和subword merging heads）在整体行为中扮演重要角色；模型在处理相同词性token时表现出相似性；此外，模型组件在特定领域（如coding或多语言文本）上表现出专业化。该方法为大规模解释语言模型行为提供了更通用且高效的框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00824v2",
      "published_date": "2024-02-27 00:24:42 UTC",
      "updated_date": "2024-04-16 23:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:46:32.650030"
    },
    {
      "arxiv_id": "2402.17097v3",
      "title": "Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses",
      "title_zh": "Re-Ex：解释后修订减少LLM响应中的事实错误",
      "authors": [
        "Juyeon Kim",
        "Jeongeun Lee",
        "Yoonho Chang",
        "Chanyeol Choi",
        "Junseong Kim",
        "Jy-yong Sohn"
      ],
      "abstract": "Mitigating hallucination issues is a key challenge that must be overcome to\nreliably deploy large language models (LLMs) in real-world scenarios. Recently,\nvarious methods have been proposed to detect and revise factual errors in\nLLM-generated texts, in order to reduce hallucination. In this paper, we\npropose Re-Ex, a method for post-editing LLM-generated responses. Re-Ex\nintroduces a novel reasoning step dubbed as the factual error explanation step.\nRe-Ex revises the initial response of LLMs using 3-steps : first, external\ntools are used to retrieve the evidences of the factual errors in the initial\nLLM response; next, LLM is instructed to explain the problematic parts of the\nresponse based on the gathered evidence; finally, LLM revises the initial\nresponse using the explanations provided in the previous step. In addition to\nthe explanation step, Re-Ex also incorporates new prompting techniques to\nreduce the token count and inference time required for the response revision\nprocess. Compared with existing methods including FacTool, CoVE, and RARR,\nRe-Ex provides better detection and revision performance with less inference\ntime and fewer tokens in multiple benchmarks.",
      "tldr_zh": "该论文提出了一种名为 Re-Ex 的后编辑方法，用于减少大语言模型 (LLMs) 生成响应中的事实错误问题。Re-Ex 通过三个步骤实现修订：首先，使用外部工具检索初始响应中的事实错误证据；其次，让 LLM 基于证据解释问题部分；最后，利用这些解释修订响应。同时，该方法引入新颖的提示技术，以降低令牌计数和推理时间。与现有方法如 FacTool、CoVE 和 RARR 相比，Re-Ex 在多个基准测试中实现了更好的错误检测和修订性能，同时减少了推理开销。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2024 Workshop on Reliable and Responsible Foundation Models",
      "pdf_url": "http://arxiv.org/pdf/2402.17097v3",
      "published_date": "2024-02-27 00:22:18 UTC",
      "updated_date": "2025-04-12 04:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:46:44.079850"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 104,
  "processed_papers_count": 104,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T10:47:12.504842"
}