{
  "date": "2024-06-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-17 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，强调大型语言模型（LLMs）的优化、对齐、安全性和应用扩展，包括代码生成、多模态理解和强化学习等方面；重点有 DeepSeek-Coder-V2（代码智能模型挑战封闭源模型）、Nemotron-4 340B（Nvidia 团队的开放代码模型）和 VideoVista（视频理解基准），这些文章展示了 LLMs 在实际任务中的潜力。\n\n下面，我挑选并简要讨论了部分重要或话题度高的论文，先从令人印象深刻的 LLMs 相关工作开始，然后按主题归类快速掠过其他内容。每个条目列出论文标题（中文 + 英文），并突出主要贡献和发现，保留核心学术术语。\n\n### 1. **DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence**  \n   这篇论文由 DeepSeek-AI 团队发布，提出了一种混合专家（Mixture-of-Experts）代码模型，显著提升了代码生成和数学推理能力。主要贡献是通过在开源模型上继续预训练，实现了与 GPT-4-Turbo 相当的性能，支持 338 种编程语言和 128K 上下文长度，实验显示其在代码任务中超越封闭源模型。\n\n### 2. **Nemotron-4 340B Technical Report**  \n   Nvidia 团队的作品，发布了一个开源的 340B 参数混合专家模型家族，包括预训练和指令微调版本。主要发现是模型在代码生成和数学推理上表现出色，98% 的数据为合成生成，证明了合成数据在模型对齐中的有效性，并提供了代码和资源以支持社区研究。\n\n### 3. **VideoVista: A Versatile Benchmark for Video Understanding and Reasoning**  \n   这篇论文引入了一个多任务视频理解基准数据集，包含 25,000 个问题，覆盖 14 类视频和多种理解任务（如异常检测和交互理解）。主要贡献是评估了多模态模型的视频推理能力，发现 GPT-4o 等模型在复杂任务中仍有不足，并通过实验展示了基准的有效性。\n\n### 4. **GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities**  \n   论文提出一个多模态音频-语言模型，支持复杂音频理解和推理任务。主要发现是通过对比学习和合成数据，模型在音频 QA 和编辑任务中表现出色，实验证明其在真实场景中提升了音频处理的灵活性。\n\n### 5. **DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**  \n   这篇工作通过知识蒸馏从单帧图像生成 3D 场景，结合 NeRF 和基础模型特征。主要贡献是实现了自监督 3D 重建和语义预测，实验在 NuScenes 和 Waymo 数据集上超越了现有方法，在零样本语义任务中表现出色。\n\n### 其他相关主题快速掠过：\n- **LLMs 对齐和安全：** 如 \"Who's asking? User personas and the mechanics of latent misalignment\"（探讨 LLMs 在用户视角下的潜在偏差）和 \"Soft Prompting for Unlearning in Large Language Models\"（提出软提示方法移除有害知识），这些论文发现 LLMs 在对齐过程中易受用户视角和提示影响，贡献在于改进模型的安全性，但实验复杂度较高。\n  \n- **代码生成和优化：** \"ChaosMining: A Benchmark to Evaluate Post-Hoc Local Attribution Methods in Low SNR Environments\" 构建了基准测试归因方法在低信噪比环境下的鲁棒性；\"Metacognitive AI: Framework and the Case for a Neurosymbolic Approach\" 提出元认知框架，强调神经符号方法的潜力。这些工作优化了代码模型的性能，但未有突破性发现。\n\n- **多模态和视觉任务：** \"COT Flow: Learning Optimal-Transport Image Sampling and Editing by Contrastive Pairs\" 使用对比最优传输流改进图像生成，实验显示其在单步生成中竞争力强；\"DistillNeRF\" 和 \"VideoVista\" 等已讨论。其他如 \"Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis\" 分析医疗图像偏差，贡献在于提出切片发现方法提升模型公平性。\n\n- **强化学习和决策：** \"Adding Conditional Control to Diffusion Models with Reinforcement Learning\" 将强化学习应用于扩散模型控制，实验证明其在条件生成中提升了样本效率；\"Decomposed evaluations of geographic disparities in text-to-image models\" 评估文本-图像模型的地理偏差，强调了公平性改进。\n\n今天 arXiv 论文数量众多，但许多聚焦基础优化或特定领域（如音频处理、图神经网络），未有重大突破，故从简。总体而言，LLMs 在代码和多模态任务的进展最值得关注，期待后续应用！如果有特定主题感兴趣，欢迎反馈。",
  "papers": [
    {
      "arxiv_id": "2406.12150v1",
      "title": "ChaosMining: A Benchmark to Evaluate Post-Hoc Local Attribution Methods in Low SNR Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Ge Shi",
        "Ziwen Kan",
        "Jason Smucny",
        "Ian Davidson"
      ],
      "abstract": "In this study, we examine the efficacy of post-hoc local attribution methods\nin identifying features with predictive power from irrelevant ones in domains\ncharacterized by a low signal-to-noise ratio (SNR), a common scenario in\nreal-world machine learning applications. We developed synthetic datasets\nencompassing symbolic functional, image, and audio data, incorporating a\nbenchmark on the {\\it (Model \\(\\times\\) Attribution\\(\\times\\) Noise Condition)}\ntriplet. By rigorously testing various classic models trained from scratch, we\ngained valuable insights into the performance of these attribution methods in\nmultiple conditions. Based on these findings, we introduce a novel extension to\nthe notable recursive feature elimination (RFE) algorithm, enhancing its\napplicability for neural networks. Our experiments highlight its strengths in\nprediction and feature selection, alongside limitations in scalability. Further\ndetails and additional minor findings are included in the appendix, with\nextensive discussions. The codes and resources are available at\n\\href{https://github.com/geshijoker/ChaosMining/}{URL}.",
      "tldr_zh": "本研究评估了后验局部归因方法（post-hoc local attribution methods）在低信噪比（low SNR）环境中的效能，这些环境常见于实际机器学习应用中，用于从无关特征中识别预测性特征。研究者开发了合成数据集，包括符号函数、图像和音频数据，并建立了基于（Model × Attribution × Noise Condition）三元组的基准，通过测试各种从零训练的经典模型，揭示了这些方法的性能表现。基于实验发现，他们提出了一种对递归特征消除（RFE）算法的扩展，使其适用于神经网络，该扩展在预测和特征选择方面表现出色，但存在可伸缩性局限。代码和资源可从 GitHub 获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 10 figures, submission to Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12150v1",
      "published_date": "2024-06-17 23:39:29 UTC",
      "updated_date": "2024-06-17 23:39:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:55:34.606944"
    },
    {
      "arxiv_id": "2406.12147v1",
      "title": "Metacognitive AI: Framework and the Case for a Neurosymbolic Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Hua Wei",
        "Paulo Shakarian",
        "Christian Lebiere",
        "Bruce Draper",
        "Nikhil Krishnaswamy",
        "Sergei Nirenburg"
      ],
      "abstract": "Metacognition is the concept of reasoning about an agent's own internal\nprocesses and was originally introduced in the field of developmental\npsychology. In this position paper, we examine the concept of applying\nmetacognition to artificial intelligence. We introduce a framework for\nunderstanding metacognitive artificial intelligence (AI) that we call TRAP:\ntransparency, reasoning, adaptation, and perception. We discuss each of these\naspects in-turn and explore how neurosymbolic AI (NSAI) can be leveraged to\naddress challenges of metacognition.",
      "tldr_zh": "这篇立场论文探讨了将元认知（metacognition）应用于人工智能（AI）的概念，引入了 TRAP 框架来理解元认知 AI，包括 transparency（透明性）、reasoning（推理）、adaptation（适应）和 perception（感知）四个方面。作者详细分析了每个框架组件，并论证了神经符号 AI（neurosymbolic AI, NSAI）如何通过结合神经网络和符号推理来解决元认知面临的挑战。该框架为开发更智能、自省的 AI 系统提供了理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12147v1",
      "published_date": "2024-06-17 23:30:46 UTC",
      "updated_date": "2024-06-17 23:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:55:56.591697"
    },
    {
      "arxiv_id": "2406.12146v2",
      "title": "Should AI Optimize Your Code? A Comparative Study of Classical Optimizing Compilers Versus Current Large Language Models",
      "title_zh": "AI 是否应该优化",
      "authors": [
        "Miguel Romero Rosas",
        "Miguel Torres Sanchez",
        "Rudolf Eigenmann"
      ],
      "abstract": "Traditional optimizing compilers have played an important role in adapting to\nthe growing complexity of modern software systems. The need for efficient\nparallel programming in current architectures requires strong optimization\ntechniques. The beginning of Large Language Models (LLMs) raises intriguing\nquestions about the potential of these AI approaches to revolutionize code\noptimization methodologies. This work aims to answer an essential question for\nthe compiler community: \"Can AI-driven models revolutionize the way we approach\ncode optimization?\".\n  To address this question, we present a comparative analysis between three\nclassical optimizing compilers and two recent large language models, evaluating\ntheir respective abilities and limitations in optimizing code for maximum\nefficiency. In addition, we introduce a benchmark suite of challenging\noptimization patterns and an automatic mechanism for evaluating the performance\nand correctness of the code generated by LLMs. We used three different\nprompting strategies to evaluate the performance of the LLMs, Simple\nInstruction (IP), Detailed Instruction Prompting (DIP), and Chain of Thought\n(CoT).\n  A key finding is that while LLMs have the potential to outperform current\noptimizing compilers, they often generate incorrect code on large code sizes,\ncalling for automated verification methods. In addition, expressing a compiler\nstrategy as part of the LLMs prompt substantially improves its overall\nperformance. Our evaluation across three benchmark suites shows CodeLlama-70B\nas the superior LLM, capable of achieving speedups of up to x1.75.\nAdditionally, CETUS is the best among the current optimizing compilers,\nachieving a maximum speedup of 1.67x. We also found substantial differences\namong the three prompting strategies.",
      "tldr_zh": "本研究比较了传统优化编译器（如CETUS）和大型语言模型（LLMs，如CodeLlama-70B）在代码优化方面的性能，探讨AI是否能革新代码优化方法。研究引入了一个基准测试套件和自动评估机制，并评估了三种提示策略：Simple Instruction (IP)、Detailed Instruction Prompting (DIP) 和 Chain of Thought (CoT)。结果显示，LLMs在某些情况下可实现高达1.75x的加速，但在大代码规模上易产生错误代码，需要自动验证；相比之下，CETUS作为最佳编译器达到1.67x加速，不同提示策略也显示出显著差异。该工作强调了在LLMs提示中融入编译器策略可显著提升其性能，为AI辅助代码优化提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.PF",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 7 figures, Accepted at SupercomputingAsia 2025 (SCA'25),\n  March 10 to 13, 2025, Singapore, Singapore",
      "pdf_url": "http://arxiv.org/pdf/2406.12146v2",
      "published_date": "2024-06-17 23:26:41 UTC",
      "updated_date": "2025-04-02 17:22:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:55:59.353697"
    },
    {
      "arxiv_id": "2406.12142v2",
      "title": "Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Olesen",
        "Nina Weng",
        "Aasa Feragen",
        "Eike Petersen"
      ],
      "abstract": "Machine learning models have achieved high overall accuracy in medical image\nanalysis. However, performance disparities on specific patient groups pose\nchallenges to their clinical utility, safety, and fairness. This can affect\nknown patient groups - such as those based on sex, age, or disease subtype - as\nwell as previously unknown and unlabeled groups. Furthermore, the root cause of\nsuch observed performance disparities is often challenging to uncover,\nhindering mitigation efforts. In this paper, to address these issues, we\nleverage Slice Discovery Methods (SDMs) to identify interpretable\nunderperforming subsets of data and formulate hypotheses regarding the cause of\nobserved performance disparities. We introduce a novel SDM and apply it in a\ncase study on the classification of pneumothorax and atelectasis from chest\nx-rays. Our study demonstrates the effectiveness of SDMs in hypothesis\nformulation and yields an explanation of previously observed but unexplained\nperformance disparities between male and female patients in widely used chest\nX-ray datasets and models. Our findings indicate shortcut learning in both\nclassification tasks, through the presence of chest drains and ECG wires,\nrespectively. Sex-based differences in the prevalence of these shortcut\nfeatures appear to cause the observed classification performance gap,\nrepresenting a previously underappreciated interaction between shortcut\nlearning and model fairness analyses.",
      "tldr_zh": "该研究探讨了机器学习模型在医疗图像分析中的性能差距问题，特别是对特定患者群体（如基于性别、年龄）的公平性和安全性挑战，并利用 Slice Discovery Methods (SDMs) 来识别可解释的性能不佳数据子集并制定假设。作者引入了一种新型 SDM，并通过胸部 X 光图像分类案例（针对 pneumothorax 和 atelectasis），解释了之前未解的性别差异性能差距。研究发现，模型依赖 shortcut learning（如胸部引流管和 ECG 线）作为捷径，导致性别在这些特征流行率上的差异放大分类性能差距，从而揭示了捷径学习与模型公平性分析的互动关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "MICCAI 2024 Workshop on Fairness of AI in Medical Imaging",
      "pdf_url": "http://arxiv.org/pdf/2406.12142v2",
      "published_date": "2024-06-17 23:08:46 UTC",
      "updated_date": "2024-10-22 13:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:56:14.882896"
    },
    {
      "arxiv_id": "2406.12140v1",
      "title": "COT Flow: Learning Optimal-Transport Image Sampling and Editing by Contrastive Pairs",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrui Zu",
        "Qian Tao"
      ],
      "abstract": "Diffusion models have demonstrated strong performance in sampling and editing\nmulti-modal data with high generation quality, yet they suffer from the\niterative generation process which is computationally expensive and slow. In\naddition, most methods are constrained to generate data from Gaussian noise,\nwhich limits their sampling and editing flexibility. To overcome both\ndisadvantages, we present Contrastive Optimal Transport Flow (COT Flow), a new\nmethod that achieves fast and high-quality generation with improved zero-shot\nediting flexibility compared to previous diffusion models. Benefiting from\noptimal transport (OT), our method has no limitation on the prior distribution,\nenabling unpaired image-to-image (I2I) translation and doubling the editable\nspace (at both the start and end of the trajectory) compared to other zero-shot\nediting methods. In terms of quality, COT Flow can generate competitive results\nin merely one step compared to previous state-of-the-art unpaired\nimage-to-image (I2I) translation methods. To highlight the advantages of COT\nFlow through the introduction of OT, we introduce the COT Editor to perform\nuser-guided editing with excellent flexibility and quality. The code will be\nreleased at https://github.com/zuxinrui/cot_flow.",
      "tldr_zh": "本论文提出 COT Flow，一种基于 Contrastive Optimal Transport 的新方法，用于图像采样和编辑，以解决 Diffusion models 在迭代生成过程中计算昂贵、缓慢的问题，并克服其对高斯噪声先验分布的依赖。COT Flow 通过 Optimal Transport (OT) 实现不受先验限制的无配对 image-to-image (I2I) 翻译，提升零-shot 编辑灵活性，并将可编辑空间扩展一倍。实验结果显示，COT Flow 在单步生成中即可达到与现有状态-of-the-art 无配对 I2I 方法相当的质量，并引入 COT Editor 支持用户引导编辑，提供更高效的图像处理工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12140v1",
      "published_date": "2024-06-17 23:02:20 UTC",
      "updated_date": "2024-06-17 23:02:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:56:23.939828"
    },
    {
      "arxiv_id": "2406.12138v1",
      "title": "Bias in Text Embedding Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vasyl Rakivnenko",
        "Nestor Maslej",
        "Jessica Cervi",
        "Volodymyr Zhukov"
      ],
      "abstract": "Text embedding is becoming an increasingly popular AI methodology, especially\namong businesses, yet the potential of text embedding models to be biased is\nnot well understood. This paper examines the degree to which a selection of\npopular text embedding models are biased, particularly along gendered\ndimensions. More specifically, this paper studies the degree to which these\nmodels associate a list of given professions with gendered terms. The analysis\nreveals that text embedding models are prone to gendered biases but in varying\nways. Although there are certain inter-model commonalities, for instance,\ngreater association of professions like nurse, homemaker, and socialite with\nfemale identifiers, and greater association of professions like CEO, manager,\nand boss with male identifiers, not all models make the same gendered\nassociations for each occupation. Furthermore, the magnitude and directionality\nof bias can also vary on a model-by-model basis and depend on the particular\nwords models are prompted with. This paper demonstrates that gender bias\nafflicts text embedding models and suggests that businesses using this\ntechnology need to be mindful of the specific dimensions of this problem.",
      "tldr_zh": "本研究调查了文本 embedding 模型中的性别偏见，重点分析这些模型如何将特定职业与性别术语（如男性或女性标识符）关联。研究者评估了多种流行模型，发现它们普遍存在性别偏见，例如护士、家政人员等职业更常与女性术语关联，而CEO、经理等则更常与男性术语关联，但偏见的强度和方向因模型和提示词而异。结果显示，虽然有些偏见模式在模型间共通，但差异显著，提醒企业在使用文本 embedding 技术时需警惕这些问题，以避免潜在的不公平影响。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12138v1",
      "published_date": "2024-06-17 22:58:36 UTC",
      "updated_date": "2024-06-17 22:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:56:33.846349"
    },
    {
      "arxiv_id": "2406.12137v3",
      "title": "IDs for AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Alan Chan",
        "Noam Kolt",
        "Peter Wills",
        "Usman Anwar",
        "Christian Schroeder de Witt",
        "Nitarshan Rajkumar",
        "Lewis Hammond",
        "David Krueger",
        "Lennart Heim",
        "Markus Anderljung"
      ],
      "abstract": "AI systems are increasingly pervasive, yet information needed to decide\nwhether and how to engage with them may not exist or be accessible. A user may\nnot be able to verify whether a system has certain safety certifications. An\ninvestigator may not know whom to investigate when a system causes an incident.\nIt may not be clear whom to contact to shut down a malfunctioning system.\nAcross a number of domains, IDs address analogous problems by identifying\nparticular entities (e.g., a particular Boeing 747) and providing information\nabout other entities of the same class (e.g., some or all Boeing 747s). We\npropose a framework in which IDs are ascribed to instances of AI systems (e.g.,\na particular chat session with Claude 3), and associated information is\naccessible to parties seeking to interact with that system. We characterize IDs\nfor AI systems, provide concrete examples where IDs could be useful, argue that\nthere could be significant demand for IDs from key actors, analyze how those\nactors could incentivize ID adoption, explore a potential implementation of our\nframework for deployers of AI systems, and highlight limitations and risks. IDs\nseem most warranted in settings where AI systems could have a large impact upon\nthe world, such as in making financial transactions or contacting real humans.\nWith further study, IDs could help to manage a world where AI systems pervade\nsociety.",
      "tldr_zh": "该论文探讨了 AI 系统缺乏标识带来的问题，如用户无法验证系统安全认证、调查事故责任或关闭故障系统。作者提出一个框架，为 AI 系统实例（如特定聊天会话）分配 IDs，并提供可访问的相关信息，以类似于其他领域（如航空器标识）的机制。论文分析了 IDs 的潜在益处、关键参与者的需求和激励机制，并探讨了针对 AI 部署者的实施方式。最终，IDs 可能在高影响场景（如金融交易）中发挥重要作用，帮助管理 AI 在社会中的广泛应用，但也存在一定的局限性和风险。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review; accepted to RegML workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12137v3",
      "published_date": "2024-06-17 22:48:11 UTC",
      "updated_date": "2024-10-28 19:15:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:56:48.909691"
    },
    {
      "arxiv_id": "2406.12123v3",
      "title": "ChatEMG: Synthetic Data Generation to Control a Robotic Hand Orthosis for Stroke",
      "title_zh": "ChatEMG：合成数据生成用于控制中风患者的机器人手部矫形器",
      "authors": [
        "Jingxi Xu",
        "Runsheng Wang",
        "Siqi Shang",
        "Ava Chen",
        "Lauren Winterbottom",
        "To-Liang Hsu",
        "Wenxi Chen",
        "Khondoker Ahmed",
        "Pedro Leandro La Rotta",
        "Xinyue Zhu",
        "Dawn M. Nilsen",
        "Joel Stein",
        "Matei Ciocarlie"
      ],
      "abstract": "Intent inferral on a hand orthosis for stroke patients is challenging due to\nthe difficulty of data collection. Additionally, EMG signals exhibit\nsignificant variations across different conditions, sessions, and subjects,\nmaking it hard for classifiers to generalize. Traditional approaches require a\nlarge labeled dataset from the new condition, session, or subject to train\nintent classifiers; however, this data collection process is burdensome and\ntime-consuming. In this paper, we propose ChatEMG, an autoregressive generative\nmodel that can generate synthetic EMG signals conditioned on prompts (i.e., a\ngiven sequence of EMG signals). ChatEMG enables us to collect only a small\ndataset from the new condition, session, or subject and expand it with\nsynthetic samples conditioned on prompts from this new context. ChatEMG\nleverages a vast repository of previous data via generative training while\nstill remaining context-specific via prompting. Our experiments show that these\nsynthetic samples are classifier-agnostic and can improve intent inferral\naccuracy for different types of classifiers. We demonstrate that our complete\napproach can be integrated into a single patient session, including the use of\nthe classifier for functional orthosis-assisted tasks. To the best of our\nknowledge, this is the first time an intent classifier trained partially on\nsynthetic data has been deployed for functional control of an orthosis by a\nstroke survivor. Videos, source code, and additional information can be found\nat https://jxu.ai/chatemg.",
      "tldr_zh": "本研究提出 ChatEMG，一种自回归生成模型，用于生成合成 EMG 信号，以解决中风患者手部矫形器意图推断的挑战，该问题源于数据收集困难和信号变异性大。ChatEMG 通过仅需少量新条件数据并结合提示，扩展数据集生成上下文特定的合成样本，同时利用先前数据的庞大仓库进行训练。实验结果显示，合成样本能提升不同类型分类器的意图推断准确性，并首次将部分基于合成数据的意图分类器部署到中风幸存者的功能性矫形器控制中，实现高效集成。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages; accepted to RA-L in November 2024; published at RA-L in\n  February 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.12123v3",
      "published_date": "2024-06-17 22:04:44 UTC",
      "updated_date": "2025-04-09 21:49:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:57:09.600185"
    },
    {
      "arxiv_id": "2406.12120v3",
      "title": "Adding Conditional Control to Diffusion Models with Reinforcement Learning",
      "title_zh": "使用强化学习向扩散模型添加条件控制",
      "authors": [
        "Yulai Zhao",
        "Masatoshi Uehara",
        "Gabriele Scalia",
        "Sunyuan Kung",
        "Tommaso Biancalani",
        "Sergey Levine",
        "Ehsan Hajiramezanali"
      ],
      "abstract": "Diffusion models are powerful generative models that allow for precise\ncontrol over the characteristics of the generated samples. While these\ndiffusion models trained on large datasets have achieved success, there is\noften a need to introduce additional controls in downstream fine-tuning\nprocesses, treating these powerful models as pre-trained diffusion models. This\nwork presents a novel method based on reinforcement learning (RL) to add such\ncontrols using an offline dataset comprising inputs and labels. We formulate\nthis task as an RL problem, with the classifier learned from the offline\ndataset and the KL divergence against pre-trained models serving as the reward\nfunctions. Our method, $\\textbf{CTRL}$ ($\\textbf{C}$onditioning\npre-$\\textbf{T}$rained diffusion models with $\\textbf{R}$einforcement\n$\\textbf{L}$earning), produces soft-optimal policies that maximize the\nabovementioned reward functions. We formally demonstrate that our method\nenables sampling from the conditional distribution with additional controls\nduring inference. Our RL-based approach offers several advantages over existing\nmethods. Compared to classifier-free guidance, it improves sample efficiency\nand can greatly simplify dataset construction by leveraging conditional\nindependence between the inputs and additional controls. Additionally, unlike\nclassifier guidance, it eliminates the need to train classifiers from\nintermediate states to additional controls. The code is available at\nhttps://github.com/zhaoyl18/CTRL.",
      "tldr_zh": "本文提出了一种名为 CTRL 的新方法，使用强化学习（Reinforcement Learning, RL）在预训练扩散模型（Diffusion Models）中添加条件控制。该方法将任务转化为 RL 问题，利用离线数据集训练分类器，并以 KL 散度作为奖励函数，生成软最优策略以采样条件分布。相比现有方法，CTRL 提高了样本效率，简化了数据集构建过程，且无需从中间状态训练分类器；实验证明其在添加额外控制方面表现出色，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.12120v3",
      "published_date": "2024-06-17 22:00:26 UTC",
      "updated_date": "2025-02-24 02:16:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:57:11.801233"
    },
    {
      "arxiv_id": "2406.12119v1",
      "title": "Deploying scalable traffic prediction models for efficient management in real-world large transportation networks during hurricane evacuations",
      "title_zh": "翻译失败",
      "authors": [
        "Qinhua Jiang",
        "Brian Yueshuai He",
        "Changju Lee",
        "Jiaqi Ma"
      ],
      "abstract": "Accurate traffic prediction is vital for effective traffic management during\nhurricane evacuation. This paper proposes a predictive modeling system that\nintegrates Multilayer Perceptron (MLP) and Long-Short Term Memory (LSTM) models\nto capture both long-term congestion patterns and short-term speed patterns.\nLeveraging various input variables, including archived traffic data,\nspatial-temporal road network information, and hurricane forecast data, the\nframework is designed to address challenges posed by heterogeneous human\nbehaviors, limited evacuation data, and hurricane event uncertainties. Deployed\nin a real-world traffic prediction system in Louisiana, the model achieved an\n82% accuracy in predicting long-term congestion states over a 6-hour period\nduring a 7-day hurricane-impacted duration. The short-term speed prediction\nmodel exhibited Mean Absolute Percentage Errors (MAPEs) ranging from 7% to 13%\nacross evacuation horizons from 1 to 6 hours. Evaluation results underscore the\nmodel's potential to enhance traffic management during hurricane evacuations,\nand real-world deployment highlights its adaptability and scalability in\ndiverse hurricane scenarios within extensive transportation networks.",
      "tldr_zh": "本文提出一个可扩展的交通预测模型系统，结合 Multilayer Perceptron (MLP) 和 Long-Short Term Memory (LSTM) 模型，用于捕获飓风疏散期间的长期拥堵模式和短期速度模式。该系统利用存档交通数据、空间-时间路网信息以及飓风预报数据，解决异质人类行为、数据有限性和事件不确定性的挑战。在路易斯安那州的真实部署中，模型在6小时内预测长期拥堵状态的准确率达82%，短期速度预测的 Mean Absolute Percentage Errors (MAPEs) 范围为7%至13%。结果证明了该系统在大型交通网络中的适应性和可扩展性，有助于提升飓风疏散的交通管理效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE ITS Magazine and currently under review",
      "pdf_url": "http://arxiv.org/pdf/2406.12119v1",
      "published_date": "2024-06-17 21:59:44 UTC",
      "updated_date": "2024-06-17 21:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:57:25.809832"
    },
    {
      "arxiv_id": "2406.12114v1",
      "title": "Enhancing Text Classification through LLM-Driven Active Learning and Human Annotation",
      "title_zh": "通过 LLM 驱动的主动学习和人工标注增强文本分类",
      "authors": [
        "Hamidreza Rouzegar",
        "Masoud Makrehchi"
      ],
      "abstract": "In the context of text classification, the financial burden of annotation\nexercises for creating training data is a critical issue. Active learning\ntechniques, particularly those rooted in uncertainty sampling, offer a\ncost-effective solution by pinpointing the most instructive samples for manual\nannotation. Similarly, Large Language Models (LLMs) such as GPT-3.5 provide an\nalternative for automated annotation but come with concerns regarding their\nreliability. This study introduces a novel methodology that integrates human\nannotators and LLMs within an Active Learning framework. We conducted\nevaluations on three public datasets. IMDB for sentiment analysis, a Fake News\ndataset for authenticity discernment, and a Movie Genres dataset for\nmulti-label classification.The proposed framework integrates human annotation\nwith the output of LLMs, depending on the model uncertainty levels. This\nstrategy achieves an optimal balance between cost efficiency and classification\nperformance. The empirical results show a substantial decrease in the costs\nassociated with data annotation while either maintaining or improving model\naccuracy.",
      "tldr_zh": "本研究针对文本分类中数据标注的成本问题，提出了一种整合大型语言模型(LLMs)和人类标注的Active Learning框架，通过基于不确定性采样的策略来选择最有价值的样本。框架根据模型的不确定性水平动态结合LLMs自动标注和人工标注，实现成本效率与分类性能的平衡。在IMDB情感分析、Fake News真实性辨别和Movie Genres多标签分类等三个公开数据集上的实验显示，该方法显著降低了标注成本，同时维持或提升了模型准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Publisher: Association for Computational Linguistics URL:\n  https://aclanthology.org/2024.law-1.10",
      "pdf_url": "http://arxiv.org/pdf/2406.12114v1",
      "published_date": "2024-06-17 21:45:48 UTC",
      "updated_date": "2024-06-17 21:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:57:39.082787"
    },
    {
      "arxiv_id": "2406.12108v2",
      "title": "Computing in the Life Sciences: From Early Algorithms to Modern AI",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel A. Donkor",
        "Matthew E. Walsh",
        "Alexander J. Titus"
      ],
      "abstract": "Computing in the life sciences has undergone a transformative evolution, from\nearly computational models in the 1950s to the applications of artificial\nintelligence (AI) and machine learning (ML) seen today. This paper highlights\nkey milestones and technological advancements through the historical\ndevelopment of computing in the life sciences. The discussion includes the\ninception of computational models for biological processes, the advent of\nbioinformatics tools, and the integration of AI/ML in modern life sciences\nresearch. Attention is given to AI-enabled tools used in the life sciences,\nsuch as scientific large language models and bio-AI tools, examining their\ncapabilities, limitations, and impact to biological risk. This paper seeks to\nclarify and establish essential terminology and concepts to ensure informed\ndecision-making and effective communication across disciplines.",
      "tldr_zh": "这篇论文回顾了生命科学中计算的发展历程，从1950年代的早期算法到现代AI和ML（machine learning）应用，突出了关键里程碑和技术进步，如生物过程的计算模型、生物信息学工具的兴起，以及AI在研究中的整合。论文重点考察了AI-enabled工具，例如科学大型语言模型和bio-AI工具，分析了它们的capabilities、limitations及其对生物风险的影响。最终，该研究旨在澄清核心术语和概念，以提升跨学科的决策和沟通效率。",
      "categories": [
        "q-bio.OT",
        "cs.AI"
      ],
      "primary_category": "q-bio.OT",
      "comment": "53 pages, 4 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.12108v2",
      "published_date": "2024-06-17 21:36:52 UTC",
      "updated_date": "2024-06-19 03:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:57:50.884997"
    },
    {
      "arxiv_id": "2406.12104v1",
      "title": "End-to-end Text-to-SQL Generation within an Analytics Insight Engine",
      "title_zh": "翻译失败",
      "authors": [
        "Karime Maamari",
        "Amine Mhedhbi"
      ],
      "abstract": "Recent advancements in Text-to-SQL have pushed database management systems\ntowards greater democratization of data access. Today's language models are at\nthe core of these advancements. They enable impressive Text-to-SQL generation\nas experienced in the development of Distyl AI's Analytics Insight Engine. Its\nearly deployment with enterprise customers has highlighted three core\nchallenges. First, data analysts expect support with authoring SQL queries of\nvery high complexity. Second, requests are ad-hoc and, as such, require low\nlatency. Finally, generation requires an understanding of domain-specific\nterminology and practices.\n  The design and implementation of our Text-to-SQL generation pipeline, powered\nby large language models, tackles these challenges. The core tenants of our\napproach rely on external knowledge that we extract in a pre-processing phase,\non retrieving the appropriate external knowledge at query generation time, and\non decomposing SQL query generation following a hierarchical CTE-based\nstructure. Finally, an adaptation framework leverages feedback to update the\nexternal knowledge, in turn improving query generation over time. We give an\noverview of our end-to-end approach and highlight the operators generating SQL\nduring inference.",
      "tldr_zh": "该论文介绍了在 Analytics Insight Engine 中实现端到端的 Text-to-SQL 生成系统，利用大型语言模型 (LLMs) 来提升数据访问的民主化。核心方法包括预处理阶段提取外部知识、在查询生成时检索相关知识、采用层次化 CTE-based 结构分解 SQL 查询，以及一个适应框架通过用户反馈动态更新知识，以应对高复杂度查询、低延迟和领域特定术语的挑战。总体而言，该方法提高了 Text-to-SQL 的准确性和效率，为企业级数据分析提供更可靠的支持。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12104v1",
      "published_date": "2024-06-17 21:33:01 UTC",
      "updated_date": "2024-06-17 21:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:58:04.221882"
    },
    {
      "arxiv_id": "2406.12095v2",
      "title": "DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features",
      "title_zh": "DistillNeRF：通过蒸馏神经场和基础模型特征从单",
      "authors": [
        "Letian Wang",
        "Seung Wook Kim",
        "Jiawei Yang",
        "Cunjun Yu",
        "Boris Ivanovic",
        "Steven L. Waslander",
        "Yue Wang",
        "Sanja Fidler",
        "Marco Pavone",
        "Peter Karkus"
      ],
      "abstract": "We propose DistillNeRF, a self-supervised learning framework addressing the\nchallenge of understanding 3D environments from limited 2D observations in\noutdoor autonomous driving scenes. Our method is a generalizable feedforward\nmodel that predicts a rich neural scene representation from sparse,\nsingle-frame multi-view camera inputs with limited view overlap, and is trained\nself-supervised with differentiable rendering to reconstruct RGB, depth, or\nfeature images. Our first insight is to exploit per-scene optimized Neural\nRadiance Fields (NeRFs) by generating dense depth and virtual camera targets\nfrom them, which helps our model to learn enhanced 3D geometry from sparse\nnon-overlapping image inputs. Second, to learn a semantically rich 3D\nrepresentation, we propose distilling features from pre-trained 2D foundation\nmodels, such as CLIP or DINOv2, thereby enabling various downstream tasks\nwithout the need for costly 3D human annotations. To leverage these two\ninsights, we introduce a novel model architecture with a two-stage\nlift-splat-shoot encoder and a parameterized sparse hierarchical voxel\nrepresentation. Experimental results on the NuScenes and Waymo NOTR datasets\ndemonstrate that DistillNeRF significantly outperforms existing comparable\nstate-of-the-art self-supervised methods for scene reconstruction, novel view\nsynthesis, and depth estimation; and it allows for competitive zero-shot 3D\nsemantic occupancy prediction, as well as open-world scene understanding\nthrough distilled foundation model features. Demos and code will be available\nat https://distillnerf.github.io/.",
      "tldr_zh": "我们提出了 DistillNeRF，一种自监督学习框架，用于从单帧稀疏多视图图像中理解 3D 场景，尤其适用于户外自动驾驶环境。该框架通过利用每个场景优化的 Neural Radiance Fields (NeRFs) 生成密集深度和虚拟目标，以从非重叠输入学习增强的 3D 几何；同时，通过从预训练的 2D 基础模型（如 CLIP 或 DINOv2）提炼特征，实现语义丰富的 3D 表示，支持下游任务而无需 3D 标注。模型采用两阶段 lift-splat-shoot 编码器和参数化的稀疏分层体素表示进行训练。在 NuScenes 和 Waymo NOTR 数据集上的实验显示，DistillNeRF 在场景重建、新颖视图合成、深度估计等方面显著优于现有自监督方法，并支持零样本 3D 语义占用预测和开放世界场景理解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Advances in Neural Information Processing Systems\n  (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.12095v2",
      "published_date": "2024-06-17 21:15:13 UTC",
      "updated_date": "2024-10-31 03:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:58:17.220223"
    },
    {
      "arxiv_id": "2406.12094v2",
      "title": "Who's asking? User personas and the mechanics of latent misalignment",
      "title_zh": "翻译失败",
      "authors": [
        "Asma Ghandeharioun",
        "Ann Yuan",
        "Marius Guerard",
        "Emily Reif",
        "Michael A. Lepori",
        "Lucas Dixon"
      ],
      "abstract": "Despite investments in improving model safety, studies show that misaligned\ncapabilities remain latent in safety-tuned models. In this work, we shed light\non the mechanics of this phenomenon. First, we show that even when model\ngenerations are safe, harmful content can persist in hidden representations and\ncan be extracted by decoding from earlier layers. Then, we show that whether\nthe model divulges such content depends significantly on its perception of who\nit is talking to, which we refer to as user persona. In fact, we find\nmanipulating user persona to be even more effective for eliciting harmful\ncontent than direct attempts to control model refusal. We study both natural\nlanguage prompting and activation steering as control methods and show that\nactivation steering is significantly more effective at bypassing safety\nfilters. We investigate why certain personas break model safeguards and find\nthat they enable the model to form more charitable interpretations of otherwise\ndangerous queries. Finally, we show we can predict a persona's effect on\nrefusal given only the geometry of its steering vector.",
      "tldr_zh": "这篇论文探讨了安全调整模型中的潜在不匹配(latent misalignment)机制，揭示了即使模型输出安全内容，有害信息仍可能隐藏在内部表示中，并可以通过早期层解码提取。研究发现，模型是否泄露有害内容主要取决于其对用户角色(user persona)的感知，且操纵用户角色比直接控制模型拒绝更有效。作者比较了自然语言提示和激活导向(activation steering)作为控制方法，结果显示激活导向更能绕过安全过滤，因为某些角色使模型对危险查询形成更宽容的解释。最后，他们证明可以通过转向向量的几何形状预测用户角色的影响，为提升模型安全提供新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12094v2",
      "published_date": "2024-06-17 21:15:12 UTC",
      "updated_date": "2024-08-13 14:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:58:38.428192"
    },
    {
      "arxiv_id": "2406.12084v2",
      "title": "When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives",
      "title_zh": "当推理遇见信息聚合：一个关于体育叙述的案例研究",
      "authors": [
        "Yebowen Hu",
        "Kaiqiang Song",
        "Sangwoo Cho",
        "Xiaoyang Wang",
        "Wenlin Yao",
        "Hassan Foroosh",
        "Dong Yu",
        "Fei Liu"
      ],
      "abstract": "Reasoning is most powerful when an LLM accurately aggregates relevant\ninformation. We examine the critical role of information aggregation in\nreasoning by requiring the LLM to analyze sports narratives. To succeed at this\ntask, an LLM must infer points from actions, identify related entities,\nattribute points accurately to players and teams, and compile key statistics to\ndraw conclusions. We conduct comprehensive experiments with real NBA basketball\ndata and present SportsGen, a new method to synthesize game narratives. By\nsynthesizing data, we can rigorously evaluate LLMs' reasoning capabilities\nunder complex scenarios with varying narrative lengths and density of\ninformation. Our findings show that most models, including GPT-4o, often fail\nto accurately aggregate basketball scores due to frequent scoring patterns.\nOpen-source models like Llama-3 further suffer from significant score\nhallucinations. Finally, the effectiveness of reasoning is influenced by\nnarrative complexity, information density, and domain-specific terms,\nhighlighting the challenges in analytical reasoning tasks.",
      "tldr_zh": "本文研究了信息聚合在LLM推理中的关键作用，通过NBA篮球叙述作为案例，评估LLM从动作中推断得分、识别实体并准确归因的能力。作者提出了SportsGen方法，用于合成游戏叙述，从而在不同叙述长度和信息密度下系统评估模型的推理表现。实验发现，大多数模型包括GPT-4o在处理频繁得分模式时常出现错误，而开源模型如Llama-3则存在显著的得分幻觉；此外，叙述复杂性、信息密度和领域特定术语进一步加剧了分析推理任务的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Main conference of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12084v2",
      "published_date": "2024-06-17 20:49:35 UTC",
      "updated_date": "2024-10-04 04:25:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:58:39.988684"
    },
    {
      "arxiv_id": "2406.12082v2",
      "title": "Uncertainty modeling for fine-tuned implicit functions",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Susmelj",
        "Mael Macuglia",
        "Nataša Tagasovska",
        "Reto Sutter",
        "Sebastiano Caprara",
        "Jean-Philippe Thiran",
        "Ender Konukoglu"
      ],
      "abstract": "Implicit functions such as Neural Radiance Fields (NeRFs), occupancy\nnetworks, and signed distance functions (SDFs) have become pivotal in computer\nvision for reconstructing detailed object shapes from sparse views. Achieving\noptimal performance with these models can be challenging due to the extreme\nsparsity of inputs and distribution shifts induced by data corruptions. To this\nend, large, noise-free synthetic datasets can serve as shape priors to help\nmodels fill in gaps, but the resulting reconstructions must be approached with\ncaution. Uncertainty estimation is crucial for assessing the quality of these\nreconstructions, particularly in identifying areas where the model is uncertain\nabout the parts it has inferred from the prior. In this paper, we introduce\nDropsembles, a novel method for uncertainty estimation in tuned implicit\nfunctions. We demonstrate the efficacy of our approach through a series of\nexperiments, starting with toy examples and progressing to a real-world\nscenario. Specifically, we train a Convolutional Occupancy Network on synthetic\nanatomical data and test it on low-resolution MRI segmentations of the lumbar\nspine. Our results show that Dropsembles achieve the accuracy and calibration\nlevels of deep ensembles but with significantly less computational cost.",
      "tldr_zh": "这篇论文针对隐式函数（如 Neural Radiance Fields (NeRFs)、occupancy networks 和 signed distance functions (SDFs)）在稀疏视图下重建物体形状时面临输入稀疏和数据偏移的问题，提出了一种新方法Dropsembles，用于不确定性估计。该方法利用形状先验从大型合成数据集填补空白，同时评估模型推断的可靠性。通过实验验证，从玩具例子到真实场景（如在合成解剖数据上训练的Convolutional Occupancy Network，并测试于低分辨率MRI脊柱分割），Dropsembles实现了与深度集成相当的准确性和校准水平，但计算成本显著降低。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12082v2",
      "published_date": "2024-06-17 20:46:18 UTC",
      "updated_date": "2025-03-21 15:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:58:51.389785"
    },
    {
      "arxiv_id": "2406.12079v1",
      "title": "Multi-Dimensional Pruning: Joint Channel, Layer and Block Pruning with Latency Constraint",
      "title_zh": "多维剪枝：联合通道、层和块剪枝并带有延迟约束",
      "authors": [
        "Xinglong Sun",
        "Barath Lakshmanan",
        "Maying Shen",
        "Shiyi Lan",
        "Jingde Chen",
        "Jose Alvarez"
      ],
      "abstract": "As we push the boundaries of performance in various vision tasks, the models\ngrow in size correspondingly. To keep up with this growth, we need very\naggressive pruning techniques for efficient inference and deployment on edge\ndevices. Existing pruning approaches are limited to channel pruning and\nstruggle with aggressive parameter reductions. In this paper, we propose a\nnovel multi-dimensional pruning framework that jointly optimizes pruning across\nchannels, layers, and blocks while adhering to latency constraints. We develop\na latency modeling technique that accurately captures model-wide latency\nvariations during pruning, which is crucial for achieving an optimal\nlatency-accuracy trade-offs at high pruning ratio. We reformulate pruning as a\nMixed-Integer Nonlinear Program (MINLP) to efficiently determine the optimal\npruned structure with only a single pass. Our extensive results demonstrate\nsubstantial improvements over previous methods, particularly at large pruning\nratios. In classification, our method significantly outperforms prior art HALP\nwith a Top-1 accuracy of 70.0(v.s. 68.6) and an FPS of 5262 im/s(v.s. 4101\nim/s). In 3D object detection, we establish a new state-of-the-art by pruning\nStreamPETR at a 45% pruning ratio, achieving higher FPS (37.3 vs. 31.7) and mAP\n(0.451 vs. 0.449) than the dense baseline.",
      "tldr_zh": "该论文提出了一种多维剪枝框架（Multi-Dimensional Pruning），它联合优化通道（channel）、层（layer）和块（block）的剪枝，同时满足延迟约束（latency constraint），以实现高效的模型压缩。框架通过开发精确的延迟建模技术，并将剪枝问题表述为混合整数非线性规划（Mixed-Integer Nonlinear Program, MINLP），仅需单次迭代即可确定最优结构。实验结果显示，在分类任务中，该方法比现有方法 HALP 提升了 Top-1 accuracy（70.0% vs. 68.6%）和 FPS（5262 im/s vs. 4101 im/s）；在 3D 物体检测任务中，以 45% 剪枝比例，StreamPETR 模型实现了更高的 FPS（37.3 vs. 31.7）和 mAP（0.451 vs. 0.449），树立了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2406.12079v1",
      "published_date": "2024-06-17 20:40:09 UTC",
      "updated_date": "2024-06-17 20:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:59:05.719963"
    },
    {
      "arxiv_id": "2406.12078v1",
      "title": "Conformance Checking of Fuzzy Logs against Declarative Temporal Specifications",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan Donadello",
        "Paolo Felli",
        "Craig Innes",
        "Fabrizio Maria Maggi",
        "Marco Montali"
      ],
      "abstract": "Traditional conformance checking tasks assume that event data provide a\nfaithful and complete representation of the actual process executions. This\nassumption has been recently questioned: more and more often events are not\ntraced explicitly, but are instead indirectly obtained as the result of event\nrecognition pipelines, and thus inherently come with uncertainty. In this work,\ndifferently from the typical probabilistic interpretation of uncertainty, we\nconsider the relevant case where uncertainty refers to which activity is\nactually conducted, under a fuzzy semantics. In this novel setting, we consider\nthe problem of checking whether fuzzy event data conform with declarative\ntemporal rules specified as Declare patterns or, more generally, as formulae of\nlinear temporal logic over finite traces (LTLf). This requires to relax the\nassumption that at each instant only one activity is executed, and to\ncorrespondingly redefine boolean operators of the logic with a fuzzy semantics.\nSpecifically, we provide a threefold contribution. First, we define a fuzzy\ncounterpart of LTLf tailored to our purpose. Second, we cast conformance\nchecking over fuzzy logs as a verification problem in this logic. Third, we\nprovide a proof-of-concept, efficient implementation based on the PyTorch\nPython library, suited to check conformance of multiple fuzzy traces at once.",
      "tldr_zh": "本研究解决了传统一致性检查（Conformance Checking）中事件数据的不确定性问题，特别是模糊语义下活动识别的模糊性，针对声明式时间规范（如 Declare patterns 或 LTLf 公式）进行检查。论文定义了模糊版本的线性时序逻辑在有限痕迹上（fuzzy LTLf），并重定义了逻辑中的布尔运算符，以适应多个活动同时执行的场景。贡献包括将模糊日志的一致性检查转化为该逻辑的验证问题，并提供基于 PyTorch 的高效实现，支持批量检查多个模糊痕迹。实验展示了该方法的实用性，为处理不确定性事件数据提供了新框架。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "68T27 (Primary) 68T27, 68T30, 68T37, 03B44 (Secondary)",
        "I.2.4; F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12078v1",
      "published_date": "2024-06-17 20:38:57 UTC",
      "updated_date": "2024-06-17 20:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:59:14.527911"
    },
    {
      "arxiv_id": "2406.12072v3",
      "title": "DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiasheng Zhang",
        "Jialin Chen",
        "Menglin Yang",
        "Aosong Feng",
        "Shuang Liang",
        "Jie Shao",
        "Rex Ying"
      ],
      "abstract": "Dynamic text-attributed graphs (DyTAGs) are prevalent in various real-world\nscenarios, where each node and edge are associated with text descriptions, and\nboth the graph structure and text descriptions evolve over time. Despite their\nbroad applicability, there is a notable scarcity of benchmark datasets tailored\nto DyTAGs, which hinders the potential advancement in many research fields. To\naddress this gap, we introduce Dynamic Text-attributed Graph Benchmark (DTGB),\na collection of large-scale, time-evolving graphs from diverse domains, with\nnodes and edges enriched by dynamically changing text attributes and\ncategories. To facilitate the use of DTGB, we design standardized evaluation\nprocedures based on four real-world use cases: future link prediction,\ndestination node retrieval, edge classification, and textual relation\ngeneration. These tasks require models to understand both dynamic graph\nstructures and natural language, highlighting the unique challenges posed by\nDyTAGs. Moreover, we conduct extensive benchmark experiments on DTGB,\nevaluating 7 popular dynamic graph learning algorithms and their variants of\nadapting to text attributes with LLM embeddings, along with 6 powerful large\nlanguage models (LLMs). Our results show the limitations of existing models in\nhandling DyTAGs. Our analysis also demonstrates the utility of DTGB in\ninvestigating the incorporation of structural and textual dynamics. The\nproposed DTGB fosters research on DyTAGs and their broad applications. It\noffers a comprehensive benchmark for evaluating and advancing models to handle\nthe interplay between dynamic graph structures and natural language. The\ndataset and source code are available at https://github.com/zjs123/DTGB.",
      "tldr_zh": "该研究针对动态文本属性图 (DyTAGs) 的研究空白，提出了一种全面基准数据集 DTGB，该数据集包括大规模、时间演化的图结构，涵盖多个领域，并为节点和边添加动态变化的文本属性和类别。DTGB 设计了标准化评估流程，基于四个真实用例（未来链接预测、目标节点检索、边分类和文本关系生成），要求模型同时处理动态图结构和自然语言的挑战。实验评估了 7 个流行动态图学习算法及其适应文本属性的变体，以及 6 个大型语言模型 (LLMs)，结果显示现有模型在处理 DyTAGs 时存在显著局限性。DTGB 通过促进结构和文本动态的整合，为推进 DyTAGs 的研究和应用提供了宝贵资源。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 13 figures, camera-ready version for NeurIPS 2024 Datasets\n  and Benchmarks Track",
      "pdf_url": "http://arxiv.org/pdf/2406.12072v3",
      "published_date": "2024-06-17 20:16:12 UTC",
      "updated_date": "2024-11-04 18:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:59:30.168590"
    },
    {
      "arxiv_id": "2406.12058v4",
      "title": "WellDunn: On the Robustness and Explainability of Language Models and Large Language Models in Identifying Wellness Dimensions",
      "title_zh": "翻译失败",
      "authors": [
        "Seyedali Mohammadi",
        "Edward Raff",
        "Jinendra Malekar",
        "Vedant Palit",
        "Francis Ferraro",
        "Manas Gaur"
      ],
      "abstract": "Language Models (LMs) are being proposed for mental health applications where\nthe heightened risk of adverse outcomes means predictive performance may not be\na sufficient litmus test of a model's utility in clinical practice. A model\nthat can be trusted for practice should have a correspondence between\nexplanation and clinical determination, yet no prior research has examined the\nattention fidelity of these models and their effect on ground truth\nexplanations. We introduce an evaluation design that focuses on the robustness\nand explainability of LMs in identifying Wellness Dimensions (WDs). We focus on\ntwo existing mental health and well-being datasets: (a) Multi-label\nClassification-based MultiWD, and (b) WellXplain for evaluating attention\nmechanism veracity against expert-labeled explanations. The labels are based on\nHalbert Dunn's theory of wellness, which gives grounding to our evaluation. We\nreveal four surprising results about LMs/LLMs: (1) Despite their human-like\ncapabilities, GPT-3.5/4 lag behind RoBERTa, and MedAlpaca, a fine-tuned LLM on\nWellXplain fails to deliver any remarkable improvements in performance or\nexplanations. (2) Re-examining LMs' predictions based on a confidence-oriented\nloss function reveals a significant performance drop. (3) Across all LMs/LLMs,\nthe alignment between attention and explanations remains low, with LLMs scoring\na dismal 0.0. (4) Most mental health-specific LMs/LLMs overlook domain-specific\nknowledge and undervalue explanations, causing these discrepancies. This study\nhighlights the need for further research into their consistency and\nexplanations in mental health and well-being.",
      "tldr_zh": "本研究评估了 Language Models (LMs) 和 Large Language Models (LLMs) 在识别 Wellness Dimensions (WDs) 时的鲁棒性和可解释性，特别关注其在心理健康应用中的潜在风险。研究引入了一个基于 Halbert Dunn 健康理论的评估设计，使用 MultiWD 和 WellXplain 数据集来测试模型性能和注意力机制的准确性。结果显示，GPT-3.5/4 落后于 RoBERTa，且 MedAlpaca 细调后未见显著改善；此外，置信度导向损失函数导致性能大幅下降，模型的注意力与专家解释对齐度极低（LLMs 得分为 0.0）。该研究强调，LMs/LLMs 往往忽略领域特定知识，导致解释不一致，并呼吁进一步研究以提升其在心理健康领域的可靠性和可解释性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in BlackboxNLP @ EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12058v4",
      "published_date": "2024-06-17 19:50:40 UTC",
      "updated_date": "2024-10-07 14:08:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:59:48.141152"
    },
    {
      "arxiv_id": "2406.12052v2",
      "title": "UniGLM: Training One Unified Language Model for Text-Attributed Graph Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Fang",
        "Dongzhe Fan",
        "Sirui Ding",
        "Ninghao Liu",
        "Qiaoyu Tan"
      ],
      "abstract": "Representation learning on text-attributed graphs (TAGs), where nodes are\nrepresented by textual descriptions, is crucial for textual and relational\nknowledge systems and recommendation systems. Currently, state-of-the-art\nembedding methods for TAGs primarily focus on fine-tuning language models\n(e.g., BERT) using structure-aware training signals. While effective, these\nmethods are tailored for individual TAG and cannot generalize across various\ngraph scenarios. Given the shared textual space, leveraging multiple TAGs for\njoint fine-tuning, aligning text and graph structure from different aspects,\nwould be more beneficial. Motivated by this, we introduce a novel Unified Graph\nLanguage Model (UniGLM) framework, the first graph embedding model that\ngeneralizes well to both in-domain and cross-domain TAGs. Specifically, UniGLM\nis trained over multiple TAGs with different domains and scales using\nself-supervised contrastive learning. UniGLM includes an adaptive positive\nsample selection technique for identifying structurally similar nodes and a\nlazy contrastive module that is devised to accelerate training by minimizing\nrepetitive encoding calculations. Extensive empirical results across 9\nbenchmark TAGs demonstrate UniGLM's efficacy against leading embedding\nbaselines in terms of generalization (various downstream tasks and backbones)\nand transfer learning (in and out of domain scenarios). The code is available\nat https://github.com/NYUSHCS/UniGLM.",
      "tldr_zh": "该论文提出UniGLM框架，一种统一的语言模型，用于文本属性图（TAGs）的嵌入训练，旨在解决现有方法（如微调BERT）仅针对特定TAG而缺乏泛化的问题。UniGLM通过在多个不同域和规模的TAGs上进行自监督对比学习训练，引入自适应正样本选择技术识别结构相似的节点，以及惰性对比模块加速训练过程。实验结果显示，UniGLM在9个基准TAGs上优于领先基线，在下游任务泛化（各种骨干）和迁移学习（域内及域外场景）方面表现出显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12052v2",
      "published_date": "2024-06-17 19:45:21 UTC",
      "updated_date": "2024-12-23 08:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:59:56.614126"
    },
    {
      "arxiv_id": "2406.12048v1",
      "title": "MEDeA: Multi-view Efficient Depth Adjustment",
      "title_zh": "MEDeA：多视图高效深度调整",
      "authors": [
        "Mikhail Artemyev",
        "Anna Vorontsova",
        "Anna Sokolova",
        "Alexander Limonov"
      ],
      "abstract": "The majority of modern single-view depth estimation methods predict relative\ndepth and thus cannot be directly applied in many real-world scenarios, despite\nimpressive performance in the benchmarks. Moreover, single-view approaches\ncannot guarantee consistency across a sequence of frames. Consistency is\ntypically addressed with test-time optimization of discrepancy across views;\nhowever, it takes hours to process a single scene. In this paper, we present\nMEDeA, an efficient multi-view test-time depth adjustment method, that is an\norder of magnitude faster than existing test-time approaches. Given RGB frames\nwith camera parameters, MEDeA predicts initial depth maps, adjusts them by\noptimizing local scaling coefficients, and outputs temporally-consistent depth\nmaps. Contrary to test-time methods requiring normals, optical flow, or\nsemantics estimation, MEDeA produces high-quality predictions with a depth\nestimation network solely. Our method sets a new state-of-the-art on TUM RGB-D,\n7Scenes, and ScanNet benchmarks and successfully handles smartphone-captured\ndata from ARKitScenes dataset.",
      "tldr_zh": "该论文针对单视图深度估计方法的局限性（如仅预测相对深度和跨帧不一致性）提出了一种高效的多视图测试时深度调整方法MEDeA。MEDeA使用RGB帧和相机参数预测初始深度图，通过优化局部缩放系数来调整深度，确保输出时间一致的深度图，且无需依赖normals、optical flow或semantics估计，仅需深度估计网络。实验结果显示，MEDeA在TUM RGB-D、7Scenes和ScanNet基准上达到了新的state-of-the-art水平，并成功处理了ARKitScenes数据集的智能手机捕获数据，比现有测试时方法快一个数量级。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12048v1",
      "published_date": "2024-06-17 19:39:13 UTC",
      "updated_date": "2024-06-17 19:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:00:09.011789"
    },
    {
      "arxiv_id": "2406.12045v1",
      "title": "$τ$-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Shunyu Yao",
        "Noah Shinn",
        "Pedram Razavi",
        "Karthik Narasimhan"
      ],
      "abstract": "Existing benchmarks do not test language agents on their interaction with\nhuman users or ability to follow domain-specific rules, both of which are vital\nfor deploying them in real world applications. We propose $\\tau$-bench, a\nbenchmark emulating dynamic conversations between a user (simulated by language\nmodels) and a language agent provided with domain-specific API tools and policy\nguidelines. We employ an efficient and faithful evaluation process that\ncompares the database state at the end of a conversation with the annotated\ngoal state. We also propose a new metric (pass^k) to evaluate the reliability\nof agent behavior over multiple trials. Our experiments show that even\nstate-of-the-art function calling agents (like gpt-4o) succeed on <50% of the\ntasks, and are quite inconsistent (pass^8 <25% in retail). Our findings point\nto the need for methods that can improve the ability of agents to act\nconsistently and follow rules reliably.",
      "tldr_zh": "本文提出 $τ$-bench，这是一个新的基准测试，用于评估语言代理在真实世界领域中与用户交互的能力和遵守领域特定规则的可靠性。该基准模拟动态对话，由语言模型模拟用户，并为代理提供领域特定 API 工具和政策指南，通过比较对话结束时的数据库状态与预设目标状态进行高效评估。同时，引入新指标 pass^k，以量化代理行为在多次试验中的一致性。实验发现，即使是先进代理如 gpt-4o，在任务成功率不足50%，且在零售领域 pass^8 低于25%，突显了提升代理一致性和规则遵守能力的需求。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12045v1",
      "published_date": "2024-06-17 19:33:08 UTC",
      "updated_date": "2024-06-17 19:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:00:20.569246"
    },
    {
      "arxiv_id": "2406.12043v2",
      "title": "Grade Score: Quantifying LLM Performance in Option Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitri Iourovitski"
      ],
      "abstract": "This study introduces the \"Grade Score\", a novel metric designed to evaluate\nthe consistency and fairness of Large Language Models (LLMs) when used as\nmultiple-choice judges with respect to order bias and choice consistency. The\nGrade Score combines Entropy, which measures order bias, and Mode Frequency,\nwhich assesses choice stability, offering insights into LLMs' reliability and\nimpartiality. The study explores techniques such as prompt engineering and\noption sampling strategies to optimize the Grade Score, demonstrating their\neffectiveness in enhancing LLMs' performance. Results showcase varying\nperformances among LLMs with respect to prompts and highlight the positive\nimpact of including irrelevant options. The study also identifies an emergent\nbehavior in instruction-following models, where they adapt to instructions\ntargeting specific biases, demonstrating their adaptability. The Grade Score\nfacilitates comparisons between LLMs and encourages ongoing research towards\noptimizing their decision-making processes, with potential implications for\nimproving their reliability and fairness in various applications. All code is\navailable on GitHub https://github.com/IoDmitri/GradeLab",
      "tldr_zh": "本研究引入了“Grade Score”这一新指标，用于量化大型语言模型 (LLMs) 在多选题评判中的表现，评估其对顺序偏差的抵抗力和选择一致性。Grade Score 结合了 Entropy（测量顺序偏差）和 Mode Frequency（评估选择稳定性），从而提供 LLMs 可靠性和公正性的全面洞见。研究通过提示工程和选项采样策略优化该指标，实验结果显示不同 LLMs 在各种提示下的表现存在差异，且添加无关选项能显著提升性能。论文还发现指令遵循模型具有适应特定偏差指令的新兴行为，这有助于促进 LLMs 之间比较并推动优化决策过程，以提高其在实际应用中的公平性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12043v2",
      "published_date": "2024-06-17 19:29:39 UTC",
      "updated_date": "2024-06-20 21:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:00:31.389564"
    },
    {
      "arxiv_id": "2406.12038v2",
      "title": "Soft Prompting for Unlearning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Karuna Bhaila",
        "Minh-Hao Van",
        "Xintao Wu"
      ],
      "abstract": "The widespread popularity of Large Language Models (LLMs), partly due to\ntheir unique ability to perform in-context learning, has also brought to light\nthe importance of ethical and safety considerations when deploying these\npre-trained models. In this work, we focus on investigating machine unlearning\nfor LLMs motivated by data protection regulations. In contrast to the growing\nliterature on fine-tuning methods to achieve unlearning, we focus on a\ncomparatively lightweight alternative called soft prompting to realize the\nunlearning of a subset of training data. With losses designed to enforce\nforgetting as well as utility preservation, our framework \\textbf{S}oft\n\\textbf{P}rompting for \\textbf{U}n\\textbf{l}earning (SPUL) learns prompt tokens\nthat can be appended to an arbitrary query to induce unlearning of specific\nexamples at inference time without updating LLM parameters. We conduct a\nrigorous evaluation of the proposed method and our results indicate that SPUL\ncan significantly improve the trade-off between utility and forgetting in the\ncontext of text classification and question answering with LLMs. We further\nvalidate our method using multiple LLMs to highlight the scalability of our\nframework and provide detailed insights into the choice of hyperparameters and\nthe influence of the size of unlearning data. Our implementation is available\nat \\url{https://github.com/karuna-bhaila/llm_unlearning}.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）的机器 unlearning 问题，以应对数据保护法规的伦理需求。作者提出了一种轻量级框架 SPUL（Soft Prompting for Unlearning），通过设计损失函数学习 prompt tokens，实现对特定训练数据的 forgetting，同时保留模型的整体 utility，并在推理时附加这些 tokens，而无需更新 LLM 参数。在文本分类和问答任务上的实验表明，SPUL 显著改善了 utility 与 forgetting 的权衡，并在多个 LLMs 上显示出可扩展性，并提供了超参数选择和 unlearning 数据规模的影响分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12038v2",
      "published_date": "2024-06-17 19:11:40 UTC",
      "updated_date": "2024-08-05 21:48:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:00:44.393194"
    },
    {
      "arxiv_id": "2406.12036v4",
      "title": "MedCalc-Bench: Evaluating Large Language Models for Medical Calculations",
      "title_zh": "MedCalc-Bench: 评估大语言模型用于医疗计算",
      "authors": [
        "Nikhil Khandekar",
        "Qiao Jin",
        "Guangzhi Xiong",
        "Soren Dunn",
        "Serina S Applebaum",
        "Zain Anwar",
        "Maame Sarfo-Gyamfi",
        "Conrad W Safranek",
        "Abid A Anwar",
        "Andrew Zhang",
        "Aidan Gilson",
        "Maxwell B Singer",
        "Amisha Dave",
        "Andrew Taylor",
        "Aidong Zhang",
        "Qingyu Chen",
        "Zhiyong Lu"
      ],
      "abstract": "As opposed to evaluating computation and logic-based reasoning, current\nbenchmarks for evaluating large language models (LLMs) in medicine are\nprimarily focused on question-answering involving domain knowledge and\ndescriptive reasoning. While such qualitative capabilities are vital to medical\ndiagnosis, in real-world scenarios, doctors frequently use clinical calculators\nthat follow quantitative equations and rule-based reasoning paradigms for\nevidence-based decision support. To this end, we propose MedCalc-Bench, a\nfirst-of-its-kind dataset focused on evaluating the medical calculation\ncapability of LLMs. MedCalc-Bench contains an evaluation set of over 1000\nmanually reviewed instances from 55 different medical calculation tasks. Each\ninstance in MedCalc-Bench consists of a patient note, a question requesting to\ncompute a specific medical value, a ground truth answer, and a step-by-step\nexplanation showing how the answer is obtained. While our evaluation results\nshow the potential of LLMs in this area, none of them are effective enough for\nclinical settings. Common issues include extracting the incorrect entities, not\nusing the correct equation or rules for a calculation task, or incorrectly\nperforming the arithmetic for the computation. We hope our study highlights the\nquantitative knowledge and reasoning gaps in LLMs within medical settings,\nencouraging future improvements of LLMs for various clinical calculation tasks.",
      "tldr_zh": "该研究提出 MedCalc-Bench，这是一个首个专注于评估大型语言模型 (LLMs) 在医疗计算能力的基准数据集，包含超过 1000 个手动审核的实例，涉及 55 个医疗计算任务，每条实例包括患者笔记、计算问题、真实答案和逐步解释。不同于传统的医学基准，该数据集强调定量方程和规则推理，以模拟真实临床场景中的决策支持。评估结果显示 LLMs 在医疗计算中显示出潜力，但普遍存在问题，如提取错误实体、使用不正确方程或算术错误，导致 none 适合临床应用；论文呼吁通过此基准推动 LLMs 的改进，以填补定量知识和推理的差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Github link: https://github.com/ncbi-nlp/MedCalc-Bench HuggingFace\n  link: https://huggingface.co/datasets/nsk7153/MedCalc-Bench",
      "pdf_url": "http://arxiv.org/pdf/2406.12036v4",
      "published_date": "2024-06-17 19:07:21 UTC",
      "updated_date": "2024-06-30 15:12:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:00:58.386410"
    },
    {
      "arxiv_id": "2406.12035v1",
      "title": "Socially Interactive Agents for Robotic Neurorehabilitation Training: Conceptualization and Proof-of-concept Study",
      "title_zh": "社交互动代理用于机器人神经康复训练：概念化和概念",
      "authors": [
        "Rhythm Arora",
        "Pooja Prajod",
        "Matteo Lavit Nicora",
        "Daniele Panzeri",
        "Giovanni Tauro",
        "Rocco Vertechy",
        "Matteo Malosio",
        "Elisabeth André",
        "Patrick Gebhard"
      ],
      "abstract": "Individuals with diverse motor abilities often benefit from intensive and\nspecialized rehabilitation therapies aimed at enhancing their functional\nrecovery. Nevertheless, the challenge lies in the restricted availability of\nneurorehabilitation professionals, hindering the effective delivery of the\nnecessary level of care. Robotic devices hold great potential in reducing the\ndependence on medical personnel during therapy but, at the same time, they\ngenerally lack the crucial human interaction and motivation that traditional\nin-person sessions provide. To bridge this gap, we introduce an AI-based system\naimed at delivering personalized, out-of-hospital assistance during\nneurorehabilitation training. This system includes a rehabilitation training\ndevice, affective signal classification models, training exercises, and a\nsocially interactive agent as the user interface. With the assistance of a\nprofessional, the envisioned system is designed to be tailored to accommodate\nthe unique rehabilitation requirements of an individual patient. Conceptually,\nafter a preliminary setup and instruction phase, the patient is equipped to\ncontinue their rehabilitation regimen autonomously in the comfort of their\nhome, facilitated by a socially interactive agent functioning as a virtual\ncoaching assistant. Our approach involves the integration of an interactive\nsocially-aware virtual agent into a neurorehabilitation robotic framework, with\nthe primary objective of recreating the social aspects inherent to in-person\nrehabilitation sessions. We also conducted a feasibility study to test the\nframework with healthy patients. The results of our preliminary investigation\nindicate that participants demonstrated a propensity to adapt to the system.\nNotably, the presence of the interactive agent during the proposed exercises\ndid not act as a source of distraction; instead, it positively impacted users'\nengagement.",
      "tldr_zh": "本研究探讨了神经康复训练中资源限制的问题，提出了一种整合社交互动代理(Socially Interactive Agents)的AI-based系统，以提供个性化、家庭化的机器人神经康复(Robotic Neurorehabilitation)辅助。系统包括康复训练设备、情感信号分类模型、训练练习和虚拟代理作为用户界面，旨在模拟传统面对面疗程的社交互动，提升患者动机和自主性。通过概念设计和初步可行性研究，结果显示健康受试者能顺利适应系统，且社交代理增强了参与度，而非造成 distraction。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12035v1",
      "published_date": "2024-06-17 19:07:05 UTC",
      "updated_date": "2024-06-17 19:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:01:07.052202"
    },
    {
      "arxiv_id": "2406.12031v2",
      "title": "Large Scale Transfer Learning for Tabular Data via Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Josh Gardner",
        "Juan C. Perdomo",
        "Ludwig Schmidt"
      ],
      "abstract": "Tabular data -- structured, heterogeneous, spreadsheet-style data with rows\nand columns -- is widely used in practice across many domains. However, while\nrecent foundation models have reduced the need for developing task-specific\ndatasets and predictors in domains such as language modeling and computer\nvision, this transfer learning paradigm has not had similar impact in the\ntabular domain. In this work, we seek to narrow this gap and present TabuLa-8B,\na language model for tabular prediction. We define a process for extracting a\nlarge, high-quality training dataset from the TabLib corpus, proposing methods\nfor tabular data filtering and quality control. Using the resulting dataset,\nwhich comprises over 2.1B rows from over 4M unique tables, we fine-tune a Llama\n3-8B large language model (LLM) for tabular data prediction (classification and\nbinned regression) using a novel packing and attention scheme for tabular\nprediction. Through evaluation across a test suite of 329 datasets, we find\nthat TabuLa-8B has zero-shot accuracy on unseen tables that is over 15\npercentage points (pp) higher than random guessing, a feat that is not possible\nwith existing state-of-the-art tabular prediction models (e.g. XGBoost,\nTabPFN). In the few-shot setting (1-32 shots), without any fine-tuning on the\ntarget datasets, TabuLa-8B is 5-15 pp more accurate than XGBoost and TabPFN\nmodels that are explicitly trained on equal, or even up to 16x more data. We\nrelease our model, code, and data along with the publication of this paper.",
      "tldr_zh": "该研究探讨了通过语言建模实现大规模转移学习在表格数据领域的应用，以解决现有模型在该领域的局限性。作者构建了 TabuLa-8B 模型，通过从 TabLib 语料库提取超过 2.1B 行高质量数据，并采用新型打包和注意力方案对 Llama 3-8B 进行微调，用于表格预测任务（如分类和分箱回归）。在 329 个数据集的评估中，TabuLa-8B 在 zero-shot 设置下准确率比随机猜测高出 15% 以上，并优于 XGBoost 和 TabPFN；在 few-shot 设置（1-32 样本）下，其准确率高出 5-15%，即使对手使用等量或更多数据训练。该模型、代码和数据已随论文发布，为表格数据预测提供了高效的转移学习范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 camera-ready updates",
      "pdf_url": "http://arxiv.org/pdf/2406.12031v2",
      "published_date": "2024-06-17 18:58:20 UTC",
      "updated_date": "2024-11-20 21:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:01:22.262772"
    },
    {
      "arxiv_id": "2406.12030v3",
      "title": "SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yongting Zhang",
        "Lu Chen",
        "Guodong Zheng",
        "Yifeng Gao",
        "Rui Zheng",
        "Jinlan Fu",
        "Zhenfei Yin",
        "Senjie Jin",
        "Yu Qiao",
        "Xuanjing Huang",
        "Feng Zhao",
        "Tao Gui",
        "Jing Shao"
      ],
      "abstract": "The emergence of Vision Language Models (VLMs) has brought unprecedented\nadvances in understanding multimodal information. The combination of textual\nand visual semantics in VLMs is highly complex and diverse, making the safety\nalignment of these models challenging. Furthermore, due to the limited study on\nthe safety alignment of VLMs, there is a lack of large-scale, high-quality\ndatasets. To address these limitations, we propose a Safety Preference\nAlignment dataset for Vision Language Models named SPA-VL. In terms of breadth,\nSPA-VL covers 6 harmfulness domains, 13 categories, and 53 subcategories, and\ncontains 100,788 samples of the quadruple (question, image, chosen response,\nrejected response). In terms of depth, the responses are collected from 12\nopen-source (e.g., QwenVL) and closed-source (e.g., Gemini) VLMs to ensure\ndiversity. The construction of preference data is fully automated, and the\nexperimental results indicate that models trained with alignment techniques on\nthe SPA-VL dataset exhibit substantial improvements in harmlessness and\nhelpfulness while maintaining core capabilities. SPA-VL, as a large-scale,\nhigh-quality, and diverse dataset, represents a significant milestone in\nensuring that VLMs achieve both harmlessness and helpfulness.",
      "tldr_zh": "该研究提出了 SPA-VL，这是一个全面的视觉语言模型 (VLMs) 安全偏好对齐数据集，旨在解决 VLMs 在处理文本和视觉语义的复杂性时面临的安全挑战。SPA-VL 覆盖 6 个有害领域、13 个类别和 53 个子类别，总计包含 100,788 个四元组样本（包括问题、图像、选择的响应和拒绝的响应），并从 12 个开源（如 QwenVL）和闭源（如 Gemini）模型中收集响应以确保多样性。数据集的构建采用全自动方法，实验结果显示，使用 SPA-VL 进行对齐训练的模型在无害性和帮助性方面显著提升，同时保持了核心能力。作为一个大规模、高质量且多样的数据集，SPA-VL 为 VLMs 的安全对齐发展奠定了重要里程碑。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12030v3",
      "published_date": "2024-06-17 18:57:37 UTC",
      "updated_date": "2025-03-25 16:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:01:32.674693"
    },
    {
      "arxiv_id": "2406.12022v1",
      "title": "Constructing Ancestral Recombination Graphs through Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mélanie Raymond",
        "Marie-Hélène Descary",
        "Cédric Beaulac",
        "Fabrice Larribe"
      ],
      "abstract": "Over the years, many approaches have been proposed to build ancestral\nrecombination graphs (ARGs), graphs used to represent the genetic relationship\nbetween individuals. Among these methods, many rely on the assumption that the\nmost likely graph is among the shortest ones. In this paper, we propose a new\napproach to build short ARGs: Reinforcement Learning (RL). We exploit the\nsimilarities between finding the shortest path between a set of genetic\nsequences and their most recent common ancestor and finding the shortest path\nbetween the entrance and exit of a maze, a classic RL problem. In the maze\nproblem, the learner, called the agent, must learn the directions to take in\norder to escape as quickly as possible, whereas in our problem, the agent must\nlearn the actions to take between coalescence, mutation, and recombination in\norder to reach the most recent common ancestor as quickly as possible. Our\nresults show that RL can be used to build ARGs as short as those built with a\nheuristic algorithm optimized to build short ARGs, and sometimes even shorter.\nMoreover, our method allows to build a distribution of short ARGs for a given\nsample, and can also generalize learning to new samples not used during the\nlearning process.",
      "tldr_zh": "本论文提出一种新方法，使用 Reinforcement Learning (RL) 来构建 Ancestral Recombination Graphs (ARGs)，旨在通过学习最短路径来表示遗传序列之间的关系。方法将 ARGs 构建问题类比为经典的迷宫逃脱任务，代理学习在 coalescence、mutation 和 recombination 等动作之间选择，以快速到达最近共同祖先。结果表明，RL 方法能生成与启发式算法一样短甚至更短的 ARGs，同时支持为给定样本构建 ARGs 分布，并将学习泛化到未见样本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12022v1",
      "published_date": "2024-06-17 18:42:03 UTC",
      "updated_date": "2024-06-17 18:42:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:01:47.468045"
    },
    {
      "arxiv_id": "2406.12020v1",
      "title": "When Box Meets Graph Neural Network in Tag-aware Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Fake Lin",
        "Ziwei Zhao",
        "Xi Zhu",
        "Da Zhang",
        "Shitian Shen",
        "Xueying Li",
        "Tong Xu",
        "Suojuan Zhang",
        "Enhong Chen"
      ],
      "abstract": "Last year has witnessed the re-flourishment of tag-aware recommender systems\nsupported by the LLM-enriched tags. Unfortunately, though large efforts have\nbeen made, current solutions may fail to describe the diversity and uncertainty\ninherent in user preferences with only tag-driven profiles. Recently, with the\ndevelopment of geometry-based techniques, e.g., box embedding, diversity of\nuser preferences now could be fully modeled as the range within a box in high\ndimension space. However, defect still exists as these approaches are incapable\nof capturing high-order neighbor signals, i.e., semantic-rich multi-hop\nrelations within the user-tag-item tripartite graph, which severely limits the\neffectiveness of user modeling. To deal with this challenge, in this paper, we\npropose a novel algorithm, called BoxGNN, to perform the message aggregation\nvia combination of logical operations, thereby incorporating high-order\nsignals. Specifically, we first embed users, items, and tags as hyper-boxes\nrather than simple points in the representation space, and define two logical\noperations to facilitate the subsequent process. Next, we perform the message\naggregation mechanism via the combination of logical operations, to obtain the\ncorresponding high-order box representations. Finally, we adopt a volume-based\nlearning objective with Gumbel smoothing techniques to refine the\nrepresentation of boxes. Extensive experiments on two publicly available\ndatasets and one LLM-enhanced e-commerce dataset have validated the superiority\nof BoxGNN compared with various state-of-the-art baselines. The code is\nreleased online",
      "tldr_zh": "该论文探讨了标签感知推荐系统（tag-aware recommender systems）中，用户偏好的多样性和不确定性难以被现有方法充分捕捉的问题，特别是忽略了用户-标签-物品三元图中的高阶邻居信号（high-order neighbor signals）。为了解决这一挑战，作者提出了一种新算法BoxGNN，将用户、物品和标签嵌入为超立方体（hyper-boxes）而非简单点，并通过逻辑操作组合进行消息聚合，以整合语义丰富的多跳关系。BoxGNN 还采用基于体积的 learning objective 和 Gumbel smoothing 技术来优化表示。实验结果显示，在两个公开数据集和一个 LLM-enhanced e-commerce 数据集上，BoxGNN 优于多种最先进基线模型，证明了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12020v1",
      "published_date": "2024-06-17 18:35:53 UTC",
      "updated_date": "2024-06-17 18:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:02:00.319879"
    },
    {
      "arxiv_id": "2406.12000v2",
      "title": "Look Further Ahead: Testing the Limits of GPT-4 in Path Planning",
      "title_zh": "展望更远：测试 GPT-4 在路径规划中的极限",
      "authors": [
        "Mohamed Aghzal",
        "Erion Plaku",
        "Ziyu Yao"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive capabilities across a wide\nvariety of tasks. However, they still face challenges with long-horizon\nplanning. To study this, we propose path planning tasks as a platform to\nevaluate LLMs' ability to navigate long trajectories under geometric\nconstraints. Our proposed benchmark systematically tests path-planning skills\nin complex settings. Using this, we examined GPT-4's planning abilities using\nvarious task representations and prompting approaches. We found that framing\nprompts as Python code and decomposing long trajectory tasks improve GPT-4's\npath planning effectiveness. However, while these approaches show some promise\ntoward improving the planning ability of the model, they do not obtain optimal\npaths and fail at generalizing over extended horizons.",
      "tldr_zh": "本文评估大型语言模型(LLMs)在长程路径规划中的能力，提出一个基准测试平台来系统测试模型在几何约束下导航复杂长轨迹的表现。研究者通过不同任务表示和提示方法（如将提示表述为Python代码和分解长轨迹任务）考察GPT-4的规划技能，发现这些方法能部分提升其路径规划效果。最终结果显示，尽管有所改进，GPT-4仍无法生成最优路径，且在更长的地平线上无法实现泛化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the 2024 IEEE 20th International Conference on Automation\n  Science and Engineering",
      "pdf_url": "http://arxiv.org/pdf/2406.12000v2",
      "published_date": "2024-06-17 18:12:56 UTC",
      "updated_date": "2024-06-20 19:53:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:02:10.399796"
    },
    {
      "arxiv_id": "2406.11988v1",
      "title": "Decomposed evaluations of geographic disparities in text-to-image models",
      "title_zh": "分解式评估文本到图像模型中的地理差异",
      "authors": [
        "Abhishek Sureddy",
        "Dishant Padalia",
        "Nandhinee Periyakaruppa",
        "Oindrila Saha",
        "Adina Williams",
        "Adriana Romero-Soriano",
        "Megan Richards",
        "Polina Kirichenko",
        "Melissa Hall"
      ],
      "abstract": "Recent work has identified substantial disparities in generated images of\ndifferent geographic regions, including stereotypical depictions of everyday\nobjects like houses and cars. However, existing measures for these disparities\nhave been limited to either human evaluations, which are time-consuming and\ncostly, or automatic metrics evaluating full images, which are unable to\nattribute these disparities to specific parts of the generated images. In this\nwork, we introduce a new set of metrics, Decomposed Indicators of Disparities\nin Image Generation (Decomposed-DIG), that allows us to separately measure\ngeographic disparities in the depiction of objects and backgrounds in generated\nimages. Using Decomposed-DIG, we audit a widely used latent diffusion model and\nfind that generated images depict objects with better realism than backgrounds\nand that backgrounds in generated images tend to contain larger regional\ndisparities than objects. We use Decomposed-DIG to pinpoint specific examples\nof disparities, such as stereotypical background generation in Africa,\nstruggling to generate modern vehicles in Africa, and unrealistically placing\nsome objects in outdoor settings. Informed by our metric, we use a new\nprompting structure that enables a 52% worst-region improvement and a 20%\naverage improvement in generated background diversity.",
      "tldr_zh": "本研究探讨了文本到图像模型（text-to-image models）在不同地理区域生成的图像差异问题，引入了新的指标Decomposed Indicators of Disparities in Image Generation (Decomposed-DIG)，以单独评估图像中物体和背景的地理不均衡。使用Decomposed-DIG审计一个广泛使用的潜在扩散模型，发现物体描绘的真实性高于背景，且背景差异更大，包括非洲地区的刻板背景生成和现代车辆描绘困难等具体问题。该方法通过一种新的提示结构优化生成图像，实现背景多样性平均改善20%，最差区域改善52%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11988v1",
      "published_date": "2024-06-17 18:04:23 UTC",
      "updated_date": "2024-06-17 18:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:02:22.069740"
    },
    {
      "arxiv_id": "2406.11984v1",
      "title": "Online Pareto-Optimal Decision-Making for Complex Tasks using Active Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Amorese",
        "Shohei Wakayama",
        "Nisar Ahmed",
        "Morteza Lahijanian"
      ],
      "abstract": "When a robot autonomously performs a complex task, it frequently must balance\ncompeting objectives while maintaining safety. This becomes more difficult in\nuncertain environments with stochastic outcomes. Enhancing transparency in the\nrobot's behavior and aligning with user preferences are also crucial. This\npaper introduces a novel framework for multi-objective reinforcement learning\nthat ensures safe task execution, optimizes trade-offs between objectives, and\nadheres to user preferences. The framework has two main layers: a\nmulti-objective task planner and a high-level selector. The planning layer\ngenerates a set of optimal trade-off plans that guarantee satisfaction of a\ntemporal logic task. The selector uses active inference to decide which\ngenerated plan best complies with user preferences and aids learning. Operating\niteratively, the framework updates a parameterized learning model based on\ncollected data. Case studies and benchmarks on both manipulation and mobile\nrobots show that our framework outperforms other methods and (i) learns\nmultiple optimal trade-offs, (ii) adheres to a user preference, and (iii)\nallows the user to adjust the balance between (i) and (ii).",
      "tldr_zh": "这篇论文提出了一种新框架，用于多目标强化学习（multi-objective reinforcement learning），帮助机器人在线上 Pareto-Optimal 决策中平衡竞争目标、确保安全执行复杂任务，并符合用户偏好。框架由多目标任务规划器和高层选择器组成，前者生成满足时间逻辑任务的最优权衡计划，后者利用 Active Inference 选择最佳计划并辅助迭代学习。实验结果显示，该框架在操作和移动机器人基准测试中优于其他方法，能学习多个最优权衡、遵守用户偏好，并允许用户动态调整平衡。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 10 figures, submitted to IEEE Transactions on Robotics\n  journal",
      "pdf_url": "http://arxiv.org/pdf/2406.11984v1",
      "published_date": "2024-06-17 18:03:45 UTC",
      "updated_date": "2024-06-17 18:03:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:02:35.377070"
    },
    {
      "arxiv_id": "2406.11980v1",
      "title": "Prompt Design Matters for Computational Social Science Tasks but in Unpredictable Ways",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Atreja",
        "Joshua Ashkinaze",
        "Lingyao Li",
        "Julia Mendelsohn",
        "Libby Hemphill"
      ],
      "abstract": "Manually annotating data for computational social science tasks can be\ncostly, time-consuming, and emotionally draining. While recent work suggests\nthat LLMs can perform such annotation tasks in zero-shot settings, little is\nknown about how prompt design impacts LLMs' compliance and accuracy. We conduct\na large-scale multi-prompt experiment to test how model selection (ChatGPT,\nPaLM2, and Falcon7b) and prompt design features (definition inclusion, output\ntype, explanation, and prompt length) impact the compliance and accuracy of\nLLM-generated annotations on four CSS tasks (toxicity, sentiment, rumor stance,\nand news frames). Our results show that LLM compliance and accuracy are highly\nprompt-dependent. For instance, prompting for numerical scores instead of\nlabels reduces all LLMs' compliance and accuracy. The overall best prompting\nsetup is task-dependent, and minor prompt changes can cause large changes in\nthe distribution of generated labels. By showing that prompt design\nsignificantly impacts the quality and distribution of LLM-generated\nannotations, this work serves as both a warning and practical guide for\nresearchers and practitioners.",
      "tldr_zh": "这篇论文探讨了提示设计对大语言模型 (LLMs) 在计算社会科学 (CSS) 任务（如毒性、情感、谣言立场和新闻框架）中的合规性和准确性的影响，强调其影响不可预测。研究通过大规模实验测试了不同模型（ChatGPT、PaLM2 和 Falcon7b）以及提示设计特征（如定义包含、输出类型、解释和提示长度），发现要求数字分数而非标签会显著降低所有 LLMs 的合规性和准确性。结果表明，最佳提示设置依赖于具体任务，且微小变化可能导致生成的标注分布发生巨大改变，为研究人员和从业者提供警告和实用指南。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2406.11980v1",
      "published_date": "2024-06-17 18:01:43 UTC",
      "updated_date": "2024-06-17 18:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:02:47.714126"
    },
    {
      "arxiv_id": "2406.11978v1",
      "title": "Dialogue Action Tokens: Steering Language Models in Goal-Directed Dialogue with a Multi-Turn Planner",
      "title_zh": "翻译失败",
      "authors": [
        "Kenneth Li",
        "Yiming Wang",
        "Fernanda Viégas",
        "Martin Wattenberg"
      ],
      "abstract": "We present an approach called Dialogue Action Tokens (DAT) that adapts\nlanguage model agents to plan goal-directed dialogues. The core idea is to\ntreat each utterance as an action, thereby converting dialogues into games\nwhere existing approaches such as reinforcement learning can be applied.\nSpecifically, we freeze a pretrained language model and train a small planner\nmodel that predicts a continuous action vector, used for controlled generation\nin each round. This design avoids the problem of language degradation under\nreward optimization. When evaluated on the Sotopia platform for social\nsimulations, the DAT-steered LLaMA model surpasses GPT-4's performance. We also\napply DAT to steer an attacker language model in a novel multi-turn red-teaming\nsetting, revealing a potential new attack surface.",
      "tldr_zh": "本研究提出了一种名为Dialogue Action Tokens (DAT)的方法，用于指导语言模型在目标导向对话中进行规划，将每个utterance视为action，从而将对话转化为可应用强化学习等技术的游戏形式。具体而言，该方法冻结预训练语言模型，并训练一个小型planner模型来预测连续的action vector，以实现每轮的受控生成，避免了奖励优化导致的语言退化问题。在Sotopia平台上的评估显示，DAT引导的LLaMA模型超过了GPT-4的性能；此外，将DAT应用于多轮red-teaming场景中，能揭示语言模型的新攻击面。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code: https://github.com/likenneth/dialogue_action_token",
      "pdf_url": "http://arxiv.org/pdf/2406.11978v1",
      "published_date": "2024-06-17 18:01:32 UTC",
      "updated_date": "2024-06-17 18:01:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:02:57.469632"
    },
    {
      "arxiv_id": "2406.11839v2",
      "title": "mDPO: Conditional Preference Optimization for Multimodal Large Language Models",
      "title_zh": "mDPO：面向多模态大语言模型的条件偏好优化",
      "authors": [
        "Fei Wang",
        "Wenxuan Zhou",
        "James Y. Huang",
        "Nan Xu",
        "Sheng Zhang",
        "Hoifung Poon",
        "Muhao Chen"
      ],
      "abstract": "Direct preference optimization (DPO) has shown to be an effective method for\nlarge language model (LLM) alignment. Recent works have attempted to apply DPO\nto multimodal scenarios but have found it challenging to achieve consistent\nimprovement. Through a comparative experiment, we identify the unconditional\npreference problem in multimodal preference optimization, where the model\noverlooks the image condition. To address this problem, we propose mDPO, a\nmultimodal DPO objective that prevents the over-prioritization of language-only\npreferences by also optimizing image preference. Moreover, we introduce a\nreward anchor that forces the reward to be positive for chosen responses,\nthereby avoiding the decrease in their likelihood -- an intrinsic problem of\nrelative preference optimization. Experiments on two multimodal LLMs of\ndifferent sizes and three widely used benchmarks demonstrate that mDPO\neffectively addresses the unconditional preference problem in multimodal\npreference optimization and significantly improves model performance,\nparticularly in reducing hallucination.",
      "tldr_zh": "该研究针对多模态大型语言模型（Multimodal Large Language Models）中的偏好优化问题，指出直接偏好优化（DPO）在多模态场景下存在无条件偏好问题，导致模型忽略图像条件。作者提出mDPO方法，通过优化图像偏好并引入reward anchor，确保chosen responses的奖励保持正值，从而避免相对偏好优化的固有缺陷。实验在两个不同规模的模型和三个常用基准上证明，mDPO有效解决了该问题，并显著提高了模型性能，尤其在减少hallucination方面。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/mDPO",
      "pdf_url": "http://arxiv.org/pdf/2406.11839v2",
      "published_date": "2024-06-17 17:59:58 UTC",
      "updated_date": "2024-10-07 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:03:11.579988"
    },
    {
      "arxiv_id": "2406.11833v2",
      "title": "MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Liu",
        "Tao Chu",
        "Yuhang Zang",
        "Xilin Wei",
        "Xiaoyi Dong",
        "Pan Zhang",
        "Zijian Liang",
        "Yuanjun Xiong",
        "Yu Qiao",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "Generating natural and meaningful responses to communicate with multi-modal\nhuman inputs is a fundamental capability of Large Vision-Language\nModels(LVLMs). While current open-source LVLMs demonstrate promising\nperformance in simplified scenarios such as single-turn single-image input,\nthey fall short in real-world conversation scenarios such as following\ninstructions in a long context history with multi-turn and multi-images.\nExisting LVLM benchmarks primarily focus on single-choice questions or\nshort-form responses, which do not adequately assess the capabilities of LVLMs\nin real-world human-AI interaction applications. Therefore, we introduce MMDU,\na comprehensive benchmark, and MMDU-45k, a large-scale instruction tuning\ndataset, designed to evaluate and improve LVLMs' abilities in multi-turn and\nmulti-image conversations. We employ the clustering algorithm to ffnd the\nrelevant images and textual descriptions from the open-source Wikipedia and\nconstruct the question-answer pairs by human annotators with the assistance of\nthe GPT-4o model. MMDU has a maximum of 18k image+text tokens, 20 images, and\n27 turns, which is at least 5x longer than previous benchmarks and poses\nchallenges to current LVLMs. Our in-depth analysis of 15 representative LVLMs\nusing MMDU reveals that open-source LVLMs lag behind closed-source counterparts\ndue to limited conversational instruction tuning data. We demonstrate that\nffne-tuning open-source LVLMs on MMDU-45k signiffcantly address this gap,\ngenerating longer and more accurate conversations, and improving scores on MMDU\nand existing benchmarks (MMStar: +1.1%, MathVista: +1.5%, ChartQA:+1.2%). Our\ncontributions pave the way for bridging the gap between current LVLM models and\nreal-world application demands. This project is available at\nhttps://github.com/Liuziyu77/MMDU.",
      "tldr_zh": "这篇论文引入了 MMDU 基准和 MMDU-45k 数据集，用于评估和提升 Large Vision-Language Models (LVLMs) 在多轮多图像对话中的能力，特别是处理长上下文和真实交互场景。研究者通过聚类算法从 Wikipedia 提取相关图像和文本，并结合人工标注及 GPT-4o 模型构建问答对，使 MMDU 包含最多 18k 图像+文本 tokens、20 张图像和 27 轮对话，比现有基准复杂 5 倍。实验分析 15 个代表性 LVLMs 发现，开源模型因缺乏对话 instruction-tuning 数据而落后于闭源模型，但通过在 MMDU-45k 上微调，可显著改善性能，提升对话准确性，并在其他基准如 MMStar (+1.1%)、MathVista (+1.5%) 和 ChartQA (+1.2%) 上取得进步。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This project is available at https://github.com/Liuziyu77/MMDU",
      "pdf_url": "http://arxiv.org/pdf/2406.11833v2",
      "published_date": "2024-06-17 17:59:47 UTC",
      "updated_date": "2024-10-29 12:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:03:24.628646"
    },
    {
      "arxiv_id": "2406.11830v1",
      "title": "Language Modeling with Editable External Knowledge",
      "title_zh": "基于可编辑外部知识的语言建模",
      "authors": [
        "Belinda Z. Li",
        "Emmy Liu",
        "Alexis Ross",
        "Abbas Zeitoun",
        "Graham Neubig",
        "Jacob Andreas"
      ],
      "abstract": "When the world changes, so does the text that humans write about it. How do\nwe build language models that can be easily updated to reflect these changes?\nOne popular approach is retrieval-augmented generation, in which new documents\nare inserted into a knowledge base and retrieved during prediction for\ndownstream tasks. Most prior work on these systems have focused on improving\nbehavior during prediction through better retrieval or reasoning. This paper\nintroduces ERASE, which instead improves model behavior when new documents are\nacquired, by incrementally deleting or rewriting other entries in the knowledge\nbase each time a document is added. In two new benchmark datasets evaluating\nmodels' ability to answer questions about a stream of news articles or\nconversations, ERASE improves accuracy relative to conventional\nretrieval-augmented generation by 7-13% (Mixtral-8x7B) and 6-10% (Llama-3-8B)\nabsolute. Code and data are available at https://github.com/belindal/ERASE",
      "tldr_zh": "这篇论文探讨了如何构建可轻松更新的语言模型，以反映世界变化，特别关注检索增强生成（retrieval-augmented generation, RAG）方法。论文引入了ERASE方法，通过在添加新文档时增量删除或重写知识库中的其他条目，来改善模型对新信息的整合。实验在两个新基准数据集上评估了模型回答新闻文章或对话相关问题的能力，结果显示ERASE相对于传统RAG提高了7-13%（Mixtral-8x7B）和6-10%（Llama-3-8B）的绝对准确率。代码和数据可在GitHub上获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11830v1",
      "published_date": "2024-06-17 17:59:35 UTC",
      "updated_date": "2024-06-17 17:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:03:36.735298"
    },
    {
      "arxiv_id": "2406.11827v2",
      "title": "WPO: Enhancing RLHF with Weighted Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Zhou",
        "Ravi Agrawal",
        "Shujian Zhang",
        "Sathish Reddy Indurthi",
        "Sanqiang Zhao",
        "Kaiqiang Song",
        "Silei Xu",
        "Chenguang Zhu"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) is a promising solution to\nalign large language models (LLMs) more closely with human values. Off-policy\npreference optimization, where the preference data is obtained from other\nmodels, is widely adopted due to its cost efficiency and scalability. However,\noff-policy preference optimization often suffers from a distributional gap\nbetween the policy used for data collection and the target policy, leading to\nsuboptimal optimization. In this paper, we propose a novel strategy to mitigate\nthis problem by simulating on-policy learning with off-policy preference data.\nOur Weighted Preference Optimization (WPO) method adapts off-policy data to\nresemble on-policy data more closely by reweighting preference pairs according\nto their probability under the current policy. This method not only addresses\nthe distributional gap problem but also enhances the optimization process\nwithout incurring additional costs. We validate our method on instruction\nfollowing benchmarks including Alpaca Eval 2 and MT-bench. WPO not only\noutperforms Direct Preference Optimization (DPO) by up to 5.6% on Alpaca Eval 2\nbut also establishes a remarkable length-controlled winning rate against\nGPT-4-turbo of 76.7% based on Gemma-2-9b-it. We release the code and models at\nhttps://github.com/wzhouad/WPO.",
      "tldr_zh": "该研究针对强化学习从人类反馈（RLHF）中的 off-policy 偏好优化问题，提出了一种 Weighted Preference Optimization (WPO) 方法，以缓解数据收集策略与目标策略之间的分布差距。WPO 通过重新加权偏好对，使 off-policy 数据更接近 on-policy 数据，从而模拟 on-policy 学习过程，同时不增加额外成本。在指令遵循基准测试中，如 Alpaca Eval 2，WPO 比 Direct Preference Optimization (DPO) 提高了高达 5.6% 的性能，并在 Gemma-2-9b-it 模型上实现了 76.7% 的长度控制获胜率对 GPT-4-turbo。该方法为提升大型语言模型 (LLMs) 与人类价值观的 alignment 提供了高效解决方案，并开源了代码和模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11827v2",
      "published_date": "2024-06-17 17:59:13 UTC",
      "updated_date": "2024-10-03 21:37:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:03:50.030880"
    },
    {
      "arxiv_id": "2406.11818v1",
      "title": "Embodied Instruction Following in Unknown Environments",
      "title_zh": "在未知环境中的具身指令跟随",
      "authors": [
        "Zhenyu Wu",
        "Ziwei Wang",
        "Xiuwei Xu",
        "Jiwen Lu",
        "Haibin Yan"
      ],
      "abstract": "Enabling embodied agents to complete complex human instructions from natural\nlanguage is crucial to autonomous systems in household services. Conventional\nmethods can only accomplish human instructions in the known environment where\nall interactive objects are provided to the embodied agent, and directly\ndeploying the existing approaches for the unknown environment usually generates\ninfeasible plans that manipulate non-existing objects. On the contrary, we\npropose an embodied instruction following (EIF) method for complex tasks in the\nunknown environment, where the agent efficiently explores the unknown\nenvironment to generate feasible plans with existing objects to accomplish\nabstract instructions. Specifically, we build a hierarchical embodied\ninstruction following framework including the high-level task planner and the\nlow-level exploration controller with multimodal large language models. We then\nconstruct a semantic representation map of the scene with dynamic region\nattention to demonstrate the known visual clues, where the goal of task\nplanning and scene exploration is aligned for human instruction. For the task\nplanner, we generate the feasible step-by-step plans for human goal\naccomplishment according to the task completion process and the known visual\nclues. For the exploration controller, the optimal navigation or object\ninteraction policy is predicted based on the generated step-wise plans and the\nknown visual clues. The experimental results demonstrate that our method can\nachieve 45.09% success rate in 204 complex human instructions such as making\nbreakfast and tidying rooms in large house-level scenes.",
      "tldr_zh": "该论文提出了一种在未知环境中让具身代理（embodied agents）完成复杂自然语言指令的方法，以解决现有方法在未知场景下生成不可行计划的问题。研究构建了一个层次化框架，包括高层任务规划器和底层探索控制器，利用多模态大语言模型（multimodal large language models）生成可行的步步计划，并通过语义表示地图和动态区域注意力整合已知视觉线索以指导探索和交互。具体而言，任务规划器根据任务过程和视觉线索制定计划，而探索控制器预测最优导航或物体交互策略。实验结果显示，该方法在 204 个复杂指令（如做早餐和整理房间）中实现了 45.09% 的成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://gary3410.github.io/eif_unknown/",
      "pdf_url": "http://arxiv.org/pdf/2406.11818v1",
      "published_date": "2024-06-17 17:55:40 UTC",
      "updated_date": "2024-06-17 17:55:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:04:04.036618"
    },
    {
      "arxiv_id": "2406.11817v1",
      "title": "Iterative Length-Regularized Direct Preference Optimization: A Case Study on Improving 7B Language Models to GPT-4 Level",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Liu",
        "Zhanhui Zhou",
        "Jiaheng Liu",
        "Xingyuan Bu",
        "Chao Yang",
        "Han-Sen Zhong",
        "Wanli Ouyang"
      ],
      "abstract": "Direct Preference Optimization (DPO), a standard method for aligning language\nmodels with human preferences, is traditionally applied to offline preferences.\nRecent studies show that DPO benefits from iterative training with online\npreferences labeled by a trained reward model. In this work, we identify a\npitfall of vanilla iterative DPO - improved response quality can lead to\nincreased verbosity. To address this, we introduce iterative length-regularized\nDPO (iLR-DPO) to penalize response length. Our empirical results show that\niLR-DPO can enhance a 7B model to perform on par with GPT-4 without increasing\nverbosity. Specifically, our 7B model achieves a $50.5\\%$ length-controlled win\nrate against $\\texttt{GPT-4 Preview}$ on AlpacaEval 2.0, and excels across\nstandard benchmarks including MT-Bench, Arena-Hard and OpenLLM Leaderboard.\nThese results demonstrate the effectiveness of iterative DPO in aligning\nlanguage models with human feedback.",
      "tldr_zh": "这篇论文针对 Direct Preference Optimization (DPO) 的迭代训练问题，引入了 iterative length-regularized DPO (iLR-DPO) 方法，通过惩罚响应长度来避免模型响应变得过于冗长。研究者通过实验证明，iLR-DPO 可以将一个 7B 语言模型提升到与 GPT-4 相当的水平，在 AlpacaEval 2.0 上实现 50.5% 的长度控制胜率，并在 MT-Bench、Arena-Hard 和 OpenLLM Leaderboard 等基准上表现出色。这些结果突显了迭代 DPO 在利用人类反馈对齐语言模型方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11817v1",
      "published_date": "2024-06-17 17:55:38 UTC",
      "updated_date": "2024-06-17 17:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:04:15.268106"
    },
    {
      "arxiv_id": "2406.11811v2",
      "title": "RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content",
      "title_zh": "翻译失败",
      "authors": [
        "Joao Monteiro",
        "Pierre-Andre Noel",
        "Etienne Marcotte",
        "Sai Rajeswar",
        "Valentina Zantedeschi",
        "David Vazquez",
        "Nicolas Chapados",
        "Christopher Pal",
        "Perouz Taslakian"
      ],
      "abstract": "Large Language Models (LLMs) are trained on vast amounts of data, most of\nwhich is automatically scraped from the internet. This data includes\nencyclopedic documents that harbor a vast amount of general knowledge (e.g.,\nWikipedia) but also potentially overlap with benchmark datasets used for\nevaluating LLMs. Consequently, evaluating models on test splits that might have\nleaked into the training set is prone to misleading conclusions. To foster\nsound evaluation of language models, we introduce a new test dataset named\nRepLiQA, suited for question-answering and topic retrieval tasks. RepLiQA is a\ncollection of five splits of test sets, four of which have not been released to\nthe internet or exposed to LLM APIs prior to this publication. Each sample in\nRepLiQA comprises (1) a reference document crafted by a human annotator and\ndepicting an imaginary scenario (e.g., a news article) absent from the\ninternet; (2) a question about the document's topic; (3) a ground-truth answer\nderived directly from the information in the document; and (4) the paragraph\nextracted from the reference document containing the answer. As such, accurate\nanswers can only be generated if a model can find relevant content within the\nprovided document. We run a large-scale benchmark comprising several\nstate-of-the-art LLMs to uncover differences in performance across models of\nvarious types and sizes in a context-conditional language modeling setting.\nReleased splits of RepLiQA can be found here:\nhttps://huggingface.co/datasets/ServiceNow/repliqa.",
      "tldr_zh": "本文提出 RepLiQA 数据集，用于评估大型语言模型(LLMs)在未见参考内容上的问答和主题检索性能，以避免训练数据泄露导致的评估偏差。数据集包括五个测试集分割，其中四个在发布前未公开，每个样本由人类创建的虚构参考文档、相关问题、ground-truth 答案以及答案所在段落组成，确保模型必须从提供的文档中提取信息。RepLiQA 的设计强调上下文条件下的准确性，通过大规模基准测试，揭示了不同类型和大小的 LLMs 在性能上的差异，为更可靠的模型评估提供了新工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11811v2",
      "published_date": "2024-06-17 17:52:54 UTC",
      "updated_date": "2024-11-05 16:47:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:04:27.512882"
    },
    {
      "arxiv_id": "2406.11945v1",
      "title": "GAugLLM: Improving Graph Contrastive Learning for Text-Attributed Graphs with Large Language Models",
      "title_zh": "GAugLLM：利用大型语言模型改进文本属性图形的图形对比学习",
      "authors": [
        "Yi Fang",
        "Dongzhe Fan",
        "Daochen Zha",
        "Qiaoyu Tan"
      ],
      "abstract": "This work studies self-supervised graph learning for text-attributed graphs\n(TAGs) where nodes are represented by textual attributes. Unlike traditional\ngraph contrastive methods that perturb the numerical feature space and alter\nthe graph's topological structure, we aim to improve view generation through\nlanguage supervision. This is driven by the prevalence of textual attributes in\nreal applications, which complement graph structures with rich semantic\ninformation. However, this presents challenges because of two major reasons.\nFirst, text attributes often vary in length and quality, making it difficulty\nto perturb raw text descriptions without altering their original semantic\nmeanings. Second, although text attributes complement graph structures, they\nare not inherently well-aligned. To bridge the gap, we introduce GAugLLM, a\nnovel framework for augmenting TAGs. It leverages advanced large language\nmodels like Mistral to enhance self-supervised graph learning. Specifically, we\nintroduce a mixture-of-prompt-expert technique to generate augmented node\nfeatures. This approach adaptively maps multiple prompt experts, each of which\nmodifies raw text attributes using prompt engineering, into numerical feature\nspace. Additionally, we devise a collaborative edge modifier to leverage\nstructural and textual commonalities, enhancing edge augmentation by examining\nor building connections between nodes. Empirical results across five benchmark\ndatasets spanning various domains underscore our framework's ability to enhance\nthe performance of leading contrastive methods as a plug-in tool. Notably, we\nobserve that the augmented features and graph structure can also enhance the\nperformance of standard generative methods, as well as popular graph neural\nnetworks. The open-sourced implementation of our GAugLLM is available at\nGithub.",
      "tldr_zh": "该研究针对文本属性图（Text-Attributed Graphs）提出GAugLLM框架，利用大型语言模型（如Mistral）提升自监督图对比学习（Graph Contrastive Learning）。框架通过mixture-of-prompt-expert技术生成增强的节点特征，采用提示工程修改原始文本属性，并设计collaborative edge modifier利用结构和文本共同点来优化边增强。实验在五个基准数据集上证明，GAugLLM作为插件工具显著提升了领先对比学习方法的性能，同时也改善了生成方法和图神经网络的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11945v1",
      "published_date": "2024-06-17 17:49:19 UTC",
      "updated_date": "2024-06-17 17:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:04:38.582895"
    },
    {
      "arxiv_id": "2406.11943v1",
      "title": "Personalized Federated Knowledge Graph Embedding with Client-Wise Relation Graph",
      "title_zh": "基于客户端关系图的个性化联邦知识图谱嵌入",
      "authors": [
        "Xiaoxiong Zhang",
        "Zhiwei Zeng",
        "Xin Zhou",
        "Dusit Niyato",
        "Zhiqi Shen"
      ],
      "abstract": "Federated Knowledge Graph Embedding (FKGE) has recently garnered considerable\ninterest due to its capacity to extract expressive representations from\ndistributed knowledge graphs, while concurrently safeguarding the privacy of\nindividual clients. Existing FKGE methods typically harness the arithmetic mean\nof entity embeddings from all clients as the global supplementary knowledge,\nand learn a replica of global consensus entities embeddings for each client.\nHowever, these methods usually neglect the inherent semantic disparities among\ndistinct clients. This oversight not only results in the globally shared\ncomplementary knowledge being inundated with too much noise when tailored to a\nspecific client, but also instigates a discrepancy between local and global\noptimization objectives. Consequently, the quality of the learned embeddings is\ncompromised. To address this, we propose Personalized Federated knowledge graph\nEmbedding with client-wise relation Graph (PFedEG), a novel approach that\nemploys a client-wise relation graph to learn personalized embeddings by\ndiscerning the semantic relevance of embeddings from other clients.\nSpecifically, PFedEG learns personalized supplementary knowledge for each\nclient by amalgamating entity embedding from its neighboring clients based on\ntheir \"affinity\" on the client-wise relation graph. Each client then conducts\npersonalized embedding learning based on its local triples and personalized\nsupplementary knowledge. We conduct extensive experiments on four benchmark\ndatasets to evaluate our method against state-of-the-art models and results\ndemonstrate the superiority of our method.",
      "tldr_zh": "该论文针对 Federated Knowledge Graph Embedding (FKGE) 的问题，指出现有方法忽略了不同客户端的语义差异，导致全局补充知识噪声过多和优化目标不一致，从而影响嵌入质量。作者提出了一种新方法 Personalized Federated knowledge graph Embedding with client-wise relation Graph (PFedEG)，通过构建 client-wise relation graph 来评估客户端间的语义相关性，并为每个客户端整合邻居客户端的实体嵌入作为个性化补充知识。每个客户端随后基于其本地三元组和个性化知识进行嵌入学习。实验在四个基准数据集上表明，PFedEG 优于现有最先进模型，证明了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11943v1",
      "published_date": "2024-06-17 17:44:53 UTC",
      "updated_date": "2024-06-17 17:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:04:50.351553"
    },
    {
      "arxiv_id": "2406.11786v1",
      "title": "A Brief Survey on Leveraging Large Scale Vision Models for Enhanced Robot Grasping",
      "title_zh": "利用大规模视觉模型增强机器人抓取的简要综述",
      "authors": [
        "Abhi Kamboj",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "Robotic grasping presents a difficult motor task in real-world scenarios,\nconstituting a major hurdle to the deployment of capable robots across various\nindustries. Notably, the scarcity of data makes grasping particularly\nchallenging for learned models. Recent advancements in computer vision have\nwitnessed a growth of successful unsupervised training mechanisms predicated on\nmassive amounts of data sourced from the Internet, and now nearly all prominent\nmodels leverage pretrained backbone networks. Against this backdrop, we begin\nto investigate the potential benefits of large-scale visual pretraining in\nenhancing robot grasping performance. This preliminary literature review sheds\nlight on critical challenges and delineates prospective directions for future\nresearch in visual pretraining for robotic manipulation.",
      "tldr_zh": "这篇论文对利用大型视觉模型(large-scale vision models)提升机器人抓取(robot grasping)性能进行了简要调查。论文指出，机器人抓取在现实场景中面临数据稀缺等挑战，而计算机视觉领域的无监督训练机制（如基于互联网海量数据的预训练骨干网络）提供了潜在解决方案。通过文献综述，研究探讨了视觉预训练在增强抓取性能方面的益处，并指出了关键挑战以及未来研究方向，如更有效的机器人操作策略。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "This report was written in February 2023, thus does not account for\n  any works since then",
      "pdf_url": "http://arxiv.org/pdf/2406.11786v1",
      "published_date": "2024-06-17 17:39:30 UTC",
      "updated_date": "2024-06-17 17:39:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:05:03.129960"
    },
    {
      "arxiv_id": "2406.11785v3",
      "title": "CELL your Model: Contrastive Explanations for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ronny Luss",
        "Erik Miehling",
        "Amit Dhurandhar"
      ],
      "abstract": "The advent of black-box deep neural network classification models has sparked\nthe need to explain their decisions. However, in the case of generative AI,\nsuch as large language models (LLMs), there is no class prediction to explain.\nRather, one can ask why an LLM output a particular response to a given prompt.\nIn this paper, we answer this question by proposing a contrastive explanation\nmethod requiring simply black-box/query access. Our explanations suggest that\nan LLM outputs a reply to a given prompt because if the prompt was slightly\nmodified, the LLM would have given a different response that is either less\npreferable or contradicts the original response. The key insight is that\ncontrastive explanations simply require a scoring function that has meaning to\nthe user and not necessarily a specific real valued quantity (viz. class\nlabel). To this end, we offer a novel budgeted algorithm, our main algorithmic\ncontribution, which intelligently creates contrasts based on such a scoring\nfunction while adhering to a query budget, necessary for longer contexts. We\nshow the efficacy of our method on important natural language tasks such as\nopen-text generation and chatbot conversations.",
      "tldr_zh": "这篇论文提出了 CELL your Model，一种对比解释（Contrastive Explanations）方法，用于解释大型语言模型（LLMs）的输出决策，而非传统的分类预测。该方法假设如果对提示稍作修改，LLMs 会生成不同的响应（如更不理想或矛盾的结果），从而揭示原响应的原因。论文引入了一个新的预算算法（budgeted algorithm），它基于用户自定义的评分函数智能创建对比，同时遵守查询预算以适应较长上下文。实验结果显示，该方法在开放文本生成和聊天机器人对话等自然语言任务上表现出色，有效提升了模型解释的可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11785v3",
      "published_date": "2024-06-17 17:39:10 UTC",
      "updated_date": "2025-02-17 18:37:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:05:15.441178"
    },
    {
      "arxiv_id": "2406.11784v1",
      "title": "MDCR: A Dataset for Multi-Document Conditional Reasoning",
      "title_zh": "MDCR：多文档条件推理数据集",
      "authors": [
        "Peter Baile Chen",
        "Yi Zhang",
        "Chunwei Liu",
        "Sejal Gupta",
        "Yoon Kim",
        "Michael Cafarella"
      ],
      "abstract": "The same real-life questions posed to different individuals may lead to\ndifferent answers based on their unique situations. For instance, whether a\nstudent is eligible for a scholarship depends on eligibility conditions, such\nas major or degree required. ConditionalQA was proposed to evaluate models'\ncapability of reading a document and answering eligibility questions,\nconsidering unmentioned conditions. However, it is limited to questions on\nsingle documents, neglecting harder cases that may require cross-document\nreasoning and optimization, for example, \"What is the maximum number of\nscholarships attainable?\" Such questions over multiple documents are not only\nmore challenging due to more context having to understand, but also because the\nmodel has to (1) explore all possible combinations of unmentioned conditions\nand (2) understand the relationship between conditions across documents, to\nreason about the optimal outcome. To evaluate models' capability of answering\nsuch questions, we propose a new dataset MDCR, which can reflect real-world\nchallenges and serve as a new test bed for complex conditional reasoning that\nrequires optimization. We evaluate this dataset using the most recent LLMs and\ndemonstrate their limitations in solving this task. We believe this dataset\nwill facilitate future research in answering optimization questions with\nunknown conditions.",
      "tldr_zh": "该研究提出了MDCR数据集，用于评估模型在多文档条件推理任务中的能力，针对现实场景中需要跨文档优化推理的问题，如计算“可获得的最大奖学金数量”。与之前的ConditionalQA数据集不同，MDCR扩展到多文档场景，要求模型探索未提及条件的各种组合，并理解跨文档条件关系，以进行优化决策。实验结果显示，最新LLMs在MDCR上表现出局限性，难以有效处理这些复杂挑战。该数据集将作为未来研究的重要测试平台，促进模型在未知条件下的优化问题解答。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11784v1",
      "published_date": "2024-06-17 17:38:43 UTC",
      "updated_date": "2024-06-17 17:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:05:25.810138"
    },
    {
      "arxiv_id": "2406.11780v1",
      "title": "Split, Unlearn, Merge: Leveraging Data Attributes for More Effective Unlearning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Swanand Ravindra Kadhe",
        "Farhan Ahmed",
        "Dennis Wei",
        "Nathalie Baracaldo",
        "Inkit Padhi"
      ],
      "abstract": "Large language models (LLMs) have shown to pose social and ethical risks such\nas generating toxic language or facilitating malicious use of hazardous\nknowledge. Machine unlearning is a promising approach to improve LLM safety by\ndirectly removing harmful behaviors and knowledge. In this paper, we propose\n\"SPlit, UNlearn, MerGE\" (SPUNGE), a framework that can be used with any\nunlearning method to amplify its effectiveness. SPUNGE leverages data\nattributes during unlearning by splitting unlearning data into subsets based on\nspecific attribute values, unlearning each subset separately, and merging the\nunlearned models. We empirically demonstrate that SPUNGE significantly improves\nthe performance of two recent unlearning methods on state-of-the-art LLMs while\nmaintaining their general capabilities on standard academic benchmarks.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)存在的社会和伦理风险，如生成有毒语言或传播危险知识，提出了一种名为SPUNGE（SPlit, UNlearn, MerGE）的框架，以增强unlearning方法的有效性。SPUNGE通过利用数据属性，将unlearning数据基于特定属性值拆分成子集、分别进行unlearning处理，然后合并模型，从而放大unlearning的效果。实验结果显示，SPUNGE显著提升了两种最新unlearning方法的性能，同时在标准学术基准上保持了LLMs的整体能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11780v1",
      "published_date": "2024-06-17 17:35:52 UTC",
      "updated_date": "2024-06-17 17:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:05:38.417096"
    },
    {
      "arxiv_id": "2406.11941v1",
      "title": "Crossfusor: A Cross-Attention Transformer Enhanced Conditional Diffusion Model for Car-Following Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Junwei You",
        "Haotian Shi",
        "Keshu Wu",
        "Keke Long",
        "Sicheng Fu",
        "Sikai Chen",
        "Bin Ran"
      ],
      "abstract": "Vehicle trajectory prediction is crucial for advancing autonomous driving and\nadvanced driver assistance systems (ADAS), enhancing road safety and traffic\nefficiency. While traditional methods have laid foundational work, modern deep\nlearning techniques, particularly transformer-based models and generative\napproaches, have significantly improved prediction accuracy by capturing\ncomplex and non-linear patterns in vehicle motion and traffic interactions.\nHowever, these models often overlook the detailed car-following behaviors and\ninter-vehicle interactions essential for real-world driving scenarios. This\nstudy introduces a Cross-Attention Transformer Enhanced Conditional Diffusion\nModel (Crossfusor) specifically designed for car-following trajectory\nprediction. Crossfusor integrates detailed inter-vehicular interactions and\ncar-following dynamics into a robust diffusion framework, improving both the\naccuracy and realism of predicted trajectories. The model leverages a novel\ntemporal feature encoding framework combining GRU, location-based attention\nmechanisms, and Fourier embedding to capture historical vehicle dynamics. It\nemploys noise scaled by these encoded historical features in the forward\ndiffusion process, and uses a cross-attention transformer to model intricate\ninter-vehicle dependencies in the reverse denoising process. Experimental\nresults on the NGSIM dataset demonstrate that Crossfusor outperforms\nstate-of-the-art models, particularly in long-term predictions, showcasing its\npotential for enhancing the predictive capabilities of autonomous driving\nsystems.",
      "tldr_zh": "本文提出 Crossfusor，一种基于 Cross-Attention Transformer 增强的条件扩散模型，专门用于跟车轨迹预测，以更好地捕捉车辆互动和跟车动态，提高预测的准确性和真实性。该模型采用新型 temporal feature encoding 框架，包括 GRU、位置-based attention 机制和 Fourier embedding，来处理历史车辆动态，并在前向扩散过程中使用噪声缩放这些特征，反向去噪时通过 cross-attention transformer 建模车辆间的复杂依赖。在 NGSIM 数据集上的实验显示，Crossfusor 优于最先进模型，尤其在长期预测中，展示了其在自动驾驶系统中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11941v1",
      "published_date": "2024-06-17 17:35:47 UTC",
      "updated_date": "2024-06-17 17:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:05:52.154225"
    },
    {
      "arxiv_id": "2406.11775v2",
      "title": "Task Me Anything",
      "title_zh": "翻译失败",
      "authors": [
        "Jieyu Zhang",
        "Weikai Huang",
        "Zixian Ma",
        "Oscar Michel",
        "Dong He",
        "Tanmay Gupta",
        "Wei-Chiu Ma",
        "Ali Farhadi",
        "Aniruddha Kembhavi",
        "Ranjay Krishna"
      ],
      "abstract": "Benchmarks for large multimodal language models (MLMs) now serve to\nsimultaneously assess the general capabilities of models instead of evaluating\nfor a specific capability. As a result, when a developer wants to identify\nwhich models to use for their application, they are overwhelmed by the number\nof benchmarks and remain uncertain about which benchmark's results are most\nreflective of their specific use case. This paper introduces Task-Me-Anything,\na benchmark generation engine which produces a benchmark tailored to a user's\nneeds. Task-Me-Anything maintains an extendable taxonomy of visual assets and\ncan programmatically generate a vast number of task instances. Additionally, it\nalgorithmically addresses user queries regarding MLM performance efficiently\nwithin a computational budget. It contains 113K images, 10K videos, 2K 3D\nobject assets, over 365 object categories, 655 attributes, and 335\nrelationships. It can generate 750M image/video question-answering pairs, which\nfocus on evaluating MLM perceptual capabilities. Task-Me-Anything reveals\ncritical insights: open-source MLMs excel in object and attribute recognition\nbut lack spatial and temporal understanding; each model exhibits unique\nstrengths and weaknesses; larger models generally perform better, though\nexceptions exist; and GPT4o demonstrates challenges in recognizing\nrotating/moving objects and distinguishing colors.",
      "tldr_zh": "这篇论文介绍了 Task-Me-Anything，一个可定制的基准生成引擎，用于评估多模态语言模型 (MLMs) 的性能，以帮助开发者针对特定应用选择合适模型。该引擎利用一个可扩展的视觉资产库（包括113K图像、10K视频和2K 3D对象），能程序化生成750M图像/视频问答对，专注于测试MLMs的感知能力，并高效处理用户查询。研究发现，开源MLMs在对象和属性识别上表现出色，但存在空间和时间理解的不足；不同模型有独特优势和弱点，大型模型通常表现更好，但GPT4o在识别旋转/移动对象和区分颜色方面面临挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Track on Datasets and Benchmarks. Website:\n  https://www.task-me-anything.org",
      "pdf_url": "http://arxiv.org/pdf/2406.11775v2",
      "published_date": "2024-06-17 17:32:42 UTC",
      "updated_date": "2025-01-27 06:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:06:06.071536"
    },
    {
      "arxiv_id": "2406.11772v1",
      "title": "Deep Learning methodology for the identification of wood species using high-resolution macroscopic images",
      "title_zh": "基于高分辨率宏观图像的木材种类识别深度学习方法",
      "authors": [
        "David Herrera-Poyatos",
        "Andrés Herrera-Poyatos",
        "Rosana Montes",
        "Paloma de Palacios",
        "Luis G. Esteban",
        "Alberto García Iruela",
        "Francisco García Fernández",
        "Francisco Herrera"
      ],
      "abstract": "Significant advancements in the field of wood species identification are\nneeded worldwide to support sustainable timber trade. In this work we\ncontribute to automate the identification of wood species via high-resolution\nmacroscopic images of timber. The main challenge of this problem is that\nfine-grained patterns in timber are crucial in order to accurately identify\nwood species, and these patterns are not properly learned by traditional\nconvolutional neural networks (CNNs) trained on low/medium resolution images.\n  We propose a Timber Deep Learning Identification with Patch-based Inference\nVoting methodology, abbreviated TDLI-PIV methodology. Our proposal exploits the\nconcept of patching and the availability of high-resolution macroscopic images\nof timber in order to overcome the inherent challenges that CNNs face in timber\nidentification. The TDLI-PIV methodology is able to capture fine-grained\npatterns in timber and, moreover, boosts robustness and prediction accuracy via\na collaborative voting inference process.\n  In this work we also introduce a new data set of marcroscopic images of\ntimber, called GOIMAI-Phase-I, which has been obtained using optical\nmagnification in order to capture fine-grained details, which contrasts to the\nother datasets that are publicly available. More concretely, images in\nGOIMAI-Phase-I are taken with a smartphone with a 24x magnifying lens attached\nto the camera. Our data set contains 2120 images of timber and covers 37\nlegally protected wood species.\n  Our experiments have assessed the performance of the TDLI-PIV methodology,\ninvolving the comparison with other methodologies available in the literature,\nexploration of data augmentation methods and the effect that the dataset size\nhas on the accuracy of TDLI-PIV.",
      "tldr_zh": "本研究针对木材种类识别的挑战，提出了一种基于深度学习的TDLI-PIV方法，利用高分辨率宏观图像和补丁(patch-based)技术来捕获细粒度模式，并通过协作投票推理过程提升鲁棒性和预测准确性，以支持可持续木材贸易。研究还引入了新数据集GOIMAI-Phase-I，包含2120张使用24x放大镜头拍摄的图像，覆盖37种受法律保护的木材种类。实验结果显示，TDLI-PIV在与其他文献方法的比较中表现出色，并探讨了数据增强和数据集大小对准确性的影响。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.1; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages and 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11772v1",
      "published_date": "2024-06-17 17:31:57 UTC",
      "updated_date": "2024-06-17 17:31:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:06:16.469312"
    },
    {
      "arxiv_id": "2407.09512v1",
      "title": "Design and evaluation of AI copilots -- case studies of retail copilot templates",
      "title_zh": "翻译失败",
      "authors": [
        "Michal Furmakiewicz",
        "Chang Liu",
        "Angus Taylor",
        "Ilya Venger"
      ],
      "abstract": "Building a successful AI copilot requires a systematic approach. This paper\nis divided into two sections, covering the design and evaluation of a copilot\nrespectively. A case study of developing copilot templates for the retail\ndomain by Microsoft is used to illustrate the role and importance of each\naspect. The first section explores the key technical components of a copilot's\narchitecture, including the LLM, plugins for knowledge retrieval and actions,\norchestration, system prompts, and responsible AI guardrails. The second\nsection discusses testing and evaluation as a principled way to promote desired\noutcomes and manage unintended consequences when using AI in a business\ncontext. We discuss how to measure and improve its quality and safety, through\nthe lens of an end-to-end human-AI decision loop framework. By providing\ninsights into the anatomy of a copilot and the critical aspects of testing and\nevaluation, this paper provides concrete evidence of how good design and\nevaluation practices are essential for building effective, human-centered AI\nassistants.",
      "tldr_zh": "这篇论文探讨了构建AI copilots的系统方法，通过Microsoft在零售领域的copilot模板案例研究，分为设计和评估两个部分。设计方面涵盖了copilot架构的关键组件，包括LLM、插件用于知识检索和动作、编排、系统提示以及负责任AI防护，以确保AI助手的有效性。评估部分强调通过端到端的人-AI决策循环框架进行测试和衡量，旨在提升质量和安全，并管理商业情境中的意外后果。最终，论文证明了良好设计和评估实践对开发高效、人类中心AI助手的必要性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "22 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09512v1",
      "published_date": "2024-06-17 17:31:33 UTC",
      "updated_date": "2024-06-17 17:31:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:06:27.566095"
    },
    {
      "arxiv_id": "2406.11768v1",
      "title": "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities",
      "title_zh": "GAMA：一种大型音频语言模型，具有先进音频理解和复杂推理能力",
      "authors": [
        "Sreyan Ghosh",
        "Sonal Kumar",
        "Ashish Seth",
        "Chandra Kiran Reddy Evuru",
        "Utkarsh Tyagi",
        "S Sakshi",
        "Oriol Nieto",
        "Ramani Duraiswami",
        "Dinesh Manocha"
      ],
      "abstract": "Perceiving and understanding non-speech sounds and non-verbal speech is\nessential to making decisions that help us interact with our surroundings. In\nthis paper, we propose GAMA, a novel General-purpose Large Audio-Language Model\n(LALM) with Advanced Audio Understanding and Complex Reasoning Abilities. We\nbuild GAMA by integrating an LLM with multiple types of audio representations,\nincluding features from a custom Audio Q-Former, a multi-layer aggregator that\naggregates features from multiple layers of an audio encoder. We fine-tune GAMA\non a large-scale audio-language dataset, which augments it with audio\nunderstanding capabilities. Next, we propose CompA-R (Instruction-Tuning for\nComplex Audio Reasoning), a synthetically generated instruction-tuning (IT)\ndataset with instructions that require the model to perform complex reasoning\non the input audio. We instruction-tune GAMA with CompA-R to endow it with\ncomplex reasoning abilities, where we further add a soft prompt as input with\nhigh-level semantic evidence by leveraging event tags of the input audio.\nFinally, we also propose CompA-R-test, a human-labeled evaluation dataset for\nevaluating the capabilities of LALMs on open-ended audio question-answering\nthat requires complex reasoning. Through automated and expert human\nevaluations, we show that GAMA outperforms all other LALMs in literature on\ndiverse audio understanding tasks by margins of 1%-84%. Further, GAMA IT-ed on\nCompA-R proves to be superior in its complex reasoning and instruction\nfollowing capabilities.",
      "tldr_zh": "本文提出 GAMA，一种通用的大型音频语言模型 (LALM)，通过整合 LLM 与多种音频表示（如自定义 Audio Q-Former 和多层聚合器）来提升非语音声音理解和复杂推理能力。研究团队使用大规模音频语言数据集进行微调，并开发了 CompA-R 合成指令微调数据集，结合软提示和高水平语义证据（如音频事件标签）来增强模型的推理性能。同时，引入 CompA-R-test 作为人类标注的评估数据集，结果显示 GAMA 在各种音频理解任务上比现有模型领先 1%-84%，并在复杂推理和指令遵循方面表现出色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Project Website: https://sreyan88.github.io/gamaaudio/",
      "pdf_url": "http://arxiv.org/pdf/2406.11768v1",
      "published_date": "2024-06-17 17:31:01 UTC",
      "updated_date": "2024-06-17 17:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:06:41.829123"
    },
    {
      "arxiv_id": "2406.11939v2",
      "title": "From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline",
      "title_zh": "翻译失败",
      "authors": [
        "Tianle Li",
        "Wei-Lin Chiang",
        "Evan Frick",
        "Lisa Dunlap",
        "Tianhao Wu",
        "Banghua Zhu",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) has outpaced the\ndevelopment of model evaluation, highlighting the need for continuous curation\nof new, challenging benchmarks. However, manual curation of high-quality,\nhuman-aligned benchmarks is expensive and time-consuming. To address this, we\nintroduce BenchBuilder, an automated pipeline that leverages LLMs to curate\nhigh-quality, open-ended prompts from large, crowd-sourced datasets, enabling\ncontinuous benchmark updates without human in the loop. We apply BenchBuilder\nto datasets such as Chatbot Arena and WildChat-1M, extracting challenging\nprompts and utilizing LLM-as-a-Judge for automatic model evaluation. To\nvalidate benchmark quality, we propose new metrics to measure a benchmark's\nalignment with human preferences and ability to separate models. We release\nArena-Hard-Auto, a benchmark consisting 500 challenging prompts curated by\nBenchBuilder. Arena-Hard-Auto provides 3x higher separation of model\nperformances compared to MT-Bench and achieves 98.6% correlation with human\npreference rankings, all at a cost of $20. Our work sets a new framework for\nthe scalable curation of automated benchmarks from extensive data.",
      "tldr_zh": "本文提出 BenchBuilder，一种自动化管道，利用 LLMs 从大型众包数据集（如 Chatbot Arena 和 WildChat-1M）中提取高质量开放式提示，实现基准测试的持续更新，而无需人工干预。作者应用 LLM-as-a-Judge 进行自动模型评估，并引入新指标来衡量基准测试与人类偏好的对齐度和模型分离能力。最终，发布的 Arena-Hard-Auto 基准测试包含 500 个挑战性提示，比 MT-Bench 提供 3 倍更高的模型性能分离，并达到 98.6% 的人类偏好相关性，成本仅 20 美元，为可扩展的自动基准测试策划框架奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11939v2",
      "published_date": "2024-06-17 17:26:10 UTC",
      "updated_date": "2024-10-14 18:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:06:53.157714"
    },
    {
      "arxiv_id": "2406.11938v1",
      "title": "Tracking the perspectives of interacting language models",
      "title_zh": "翻译失败",
      "authors": [
        "Hayden Helm",
        "Brandon Duderstadt",
        "Youngser Park",
        "Carey E. Priebe"
      ],
      "abstract": "Large language models (LLMs) are capable of producing high quality\ninformation at unprecedented rates. As these models continue to entrench\nthemselves in society, the content they produce will become increasingly\npervasive in databases that are, in turn, incorporated into the pre-training\ndata, fine-tuning data, retrieval data, etc. of other language models. In this\npaper we formalize the idea of a communication network of LLMs and introduce a\nmethod for representing the perspective of individual models within a\ncollection of LLMs. Given these tools we systematically study information\ndiffusion in the communication network of LLMs in various simulated settings.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)之间互动的信息扩散问题，强调这些模型产生的内容可能反馈到其他模型的训练数据、微调数据和检索数据中，形成一个通信网络。作者形式化了LLMs的通信网络概念，并引入了一种方法来表示单个模型在该网络中的视角。利用这些工具，他们通过各种模拟设置系统地研究了信息在LLMs网络中的传播机制，为理解模型互动的影响提供了新框架。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11938v1",
      "published_date": "2024-06-17 17:20:16 UTC",
      "updated_date": "2024-06-17 17:20:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:07:02.538850"
    },
    {
      "arxiv_id": "2406.11757v4",
      "title": "STAR: SocioTechnical Approach to Red Teaming Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Laura Weidinger",
        "John Mellor",
        "Bernat Guillen Pegueroles",
        "Nahema Marchal",
        "Ravin Kumar",
        "Kristian Lum",
        "Canfer Akbulut",
        "Mark Diaz",
        "Stevie Bergman",
        "Mikel Rodriguez",
        "Verena Rieser",
        "William Isaac"
      ],
      "abstract": "This research introduces STAR, a sociotechnical framework that improves on\ncurrent best practices for red teaming safety of large language models. STAR\nmakes two key contributions: it enhances steerability by generating\nparameterised instructions for human red teamers, leading to improved coverage\nof the risk surface. Parameterised instructions also provide more detailed\ninsights into model failures at no increased cost. Second, STAR improves signal\nquality by matching demographics to assess harms for specific groups, resulting\nin more sensitive annotations. STAR further employs a novel step of arbitration\nto leverage diverse viewpoints and improve label reliability, treating\ndisagreement not as noise but as a valuable contribution to signal quality.",
      "tldr_zh": "本研究引入了 STAR，一种社会技术框架（SocioTechnical framework），旨在改进大型语言模型的安全红队测试（red teaming）最佳实践。STAR 的第一个关键贡献是通过生成参数化指令（parameterised instructions）增强模型的可操控性（steerability），从而提高风险覆盖面并提供更多关于模型失败的详细见解，而无需增加成本。第二个贡献在于通过匹配人口统计学评估特定群体的危害，实现更敏感的标注，并引入仲裁步骤利用多样观点提升标签可靠性，将分歧视为信号质量（signal quality）的积极因素。整体框架为红队测试提供了更全面和可靠的方法，推动语言模型的安全性提升。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures, 5 pages appendix. * denotes equal contribution",
      "pdf_url": "http://arxiv.org/pdf/2406.11757v4",
      "published_date": "2024-06-17 17:16:45 UTC",
      "updated_date": "2024-10-23 16:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:07:16.371950"
    },
    {
      "arxiv_id": "2406.11754v1",
      "title": "DustNet: skillful neural network predictions of Saharan dust",
      "title_zh": "翻译失败",
      "authors": [
        "Trish E. Nowak",
        "Andy T. Augousti",
        "Benno I. Simmons",
        "Stefan Siegert"
      ],
      "abstract": "Suspended in the atmosphere are millions of tonnes of mineral dust which\ninteracts with weather and climate. Accurate representation of mineral dust in\nweather models is vital, yet remains challenging. Large scale weather models\nuse high power supercomputers and take hours to complete the forecast. Such\ncomputational burden allows them to only include monthly climatological means\nof mineral dust as input states inhibiting their forecasting accuracy. Here, we\nintroduce DustNet a simple, accurate and super fast forecasting model for\n24-hours ahead predictions of aerosol optical depth AOD. DustNet trains in less\nthan 8 minutes and creates predictions in 2 seconds on a desktop computer.\nCreated by DustNet predictions outperform the state-of-the-art physics-based\nmodel on coarse 1 x 1 degree resolution at 95% of grid locations when compared\nto ground truth satellite data. Our results show DustNet has a potential for\nfast and accurate AOD forecasting which could transform our understanding of\ndust impacts on weather patterns.",
      "tldr_zh": "该论文引入DustNet，一种高效的神经网络模型，用于预测撒哈拉尘埃的24小时ahead气溶胶光学深度(AOD)，以解决传统天气模型因计算负担重而仅使用月度气候平均值导致的预测不准确问题。DustNet训练时间不到8分钟，在桌面计算机上预测只需2秒，显著提高了计算效率。实验结果显示，与卫星数据比较，DustNet在95%的1度分辨率网格位置上优于现有的基于物理的模型。该方法有望转变我们对尘埃对天气模式影响的理解，提供更快速准确的预报工具。",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "physics.ao-ph",
        "physics.data-an",
        "86-06(Primary), 86A10(Secondary)",
        "J.2; I.2.1; I.2.7"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "34 pages, 9 figures, uses 2D CNN",
      "pdf_url": "http://arxiv.org/pdf/2406.11754v1",
      "published_date": "2024-06-17 17:15:30 UTC",
      "updated_date": "2024-06-17 17:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:07:28.340309"
    },
    {
      "arxiv_id": "2407.16895v1",
      "title": "(Unfair) Norms in Fairness Research: A Meta-Analysis",
      "title_zh": "（不公平的）公平研究规范：一项元分析",
      "authors": [
        "Jennifer Chien",
        "A. Stevie Bergman",
        "Kevin R. McKee",
        "Nenad Tomasev",
        "Vinodkumar Prabhakaran",
        "Rida Qadri",
        "Nahema Marchal",
        "William Isaac"
      ],
      "abstract": "Algorithmic fairness has emerged as a critical concern in artificial\nintelligence (AI) research. However, the development of fair AI systems is not\nan objective process. Fairness is an inherently subjective concept, shaped by\nthe values, experiences, and identities of those involved in research and\ndevelopment. To better understand the norms and values embedded in current\nfairness research, we conduct a meta-analysis of algorithmic fairness papers\nfrom two leading conferences on AI fairness and ethics, AIES and FAccT,\ncovering a final sample of 139 papers over the period from 2018 to 2022. Our\ninvestigation reveals two concerning trends: first, a US-centric perspective\ndominates throughout fairness research; and second, fairness studies exhibit a\nwidespread reliance on binary codifications of human identity (e.g.,\n\"Black/White\", \"male/female\"). These findings highlight how current research\noften overlooks the complexities of identity and lived experiences, ultimately\nfailing to represent diverse global contexts when defining algorithmic bias and\nfairness. We discuss the limitations of these research design choices and offer\nrecommendations for fostering more inclusive and representative approaches to\nfairness in AI systems, urging a paradigm shift that embraces nuanced, global\nunderstandings of human identity and values.",
      "tldr_zh": "该研究通过对2018-2022年间AIES和FAccT会议的139篇论文进行meta-analysis，揭示了算法公平研究中的固有偏见。结果显示，公平研究以US-centric视角为主，并广泛依赖二元身份分类（如“Black/White”或“male/female”），从而忽略了人类身份的复杂性和全球多样性。这些发现突显了当前研究的局限性，并提出建议，推动AI系统采用更具包容性的方法，以实现更全面的算法公平范式转变。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16895v1",
      "published_date": "2024-06-17 17:14:47 UTC",
      "updated_date": "2024-06-17 17:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:07:38.190886"
    },
    {
      "arxiv_id": "2406.11741v4",
      "title": "Transcendence: Generative Models Can Outperform The Experts That Train Them",
      "title_zh": "翻译失败",
      "authors": [
        "Edwin Zhang",
        "Vincent Zhu",
        "Naomi Saphra",
        "Anat Kleiman",
        "Benjamin L. Edelman",
        "Milind Tambe",
        "Sham M. Kakade",
        "Eran Malach"
      ],
      "abstract": "Generative models are trained with the simple objective of imitating the\nconditional probability distribution induced by the data they are trained on.\nTherefore, when trained on data generated by humans, we may not expect the\nartificial model to outperform the humans on their original objectives. In this\nwork, we study the phenomenon of transcendence: when a generative model\nachieves capabilities that surpass the abilities of the experts generating its\ndata. We demonstrate transcendence by training an autoregressive transformer to\nplay chess from game transcripts, and show that the trained model can sometimes\nachieve better performance than all players in the dataset. We theoretically\nprove that transcendence can be enabled by low-temperature sampling, and\nrigorously assess this claim experimentally. Finally, we discuss other sources\nof transcendence, laying the groundwork for future investigation of this\nphenomenon in a broader setting.",
      "tldr_zh": "本文研究了“transcendence”现象，即生成模型（generative models）在模仿训练数据后，可能超越生成这些数据的专家能力。作者通过训练一个 autoregressive transformer 使用国际象棋游戏记录，展示了模型在某些情况下能击败数据集中的所有玩家。理论上证明了低温度采样（low-temperature sampling）可以启用这一现象，并通过实验进行验证。最后，论文讨论了其他 transcendence 来源，为更广泛的研究奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code, models, and data at https://transcendence.eddie.win",
      "pdf_url": "http://arxiv.org/pdf/2406.11741v4",
      "published_date": "2024-06-17 17:00:52 UTC",
      "updated_date": "2024-10-12 18:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:07:52.735715"
    },
    {
      "arxiv_id": "2406.11740v2",
      "title": "Imagination Policy: Using Generative Point Cloud Models for Learning Manipulation Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Haojie Huang",
        "Karl Schmeckpeper",
        "Dian Wang",
        "Ondrej Biza",
        "Yaoyao Qian",
        "Haotian Liu",
        "Mingxi Jia",
        "Robert Platt",
        "Robin Walters"
      ],
      "abstract": "Humans can imagine goal states during planning and perform actions to match\nthose goals. In this work, we propose Imagination Policy, a novel multi-task\nkey-frame policy network for solving high-precision pick and place tasks.\nInstead of learning actions directly, Imagination Policy generates point clouds\nto imagine desired states which are then translated to actions using rigid\naction estimation. This transforms action inference into a local generative\ntask. We leverage pick and place symmetries underlying the tasks in the\ngeneration process and achieve extremely high sample efficiency and\ngeneralizability to unseen configurations. Finally, we demonstrate\nstate-of-the-art performance across various tasks on the RLbench benchmark\ncompared with several strong baselines and validate our approach on a real\nrobot.",
      "tldr_zh": "本研究提出Imagination Policy，一种新型的多任务关键帧策略网络，用于学习高精度抓取和放置任务的操控策略。该方法不直接学习动作，而是通过生成点云模型来想象期望状态，并利用刚性动作估计将这些状态转化为实际动作，从而将动作推理转化为局部生成任务。论文利用抓取和放置任务中的对称性，实现了极高的样本效率和对未见配置的泛化能力。在RLbench基准测试中，Imagination Policy在各种任务上超越了强基线模型，并在真实机器人上验证了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11740v2",
      "published_date": "2024-06-17 17:00:41 UTC",
      "updated_date": "2024-11-30 17:40:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:08:02.819599"
    },
    {
      "arxiv_id": "2406.11736v1",
      "title": "Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models",
      "title_zh": "Interactive Evolution：神经-符号自训练框架用于大语言模型",
      "authors": [
        "Fangzhi Xu",
        "Qiushi Sun",
        "Kanzhi Cheng",
        "Jun Liu",
        "Yu Qiao",
        "Zhiyong Wu"
      ],
      "abstract": "One of the primary driving forces contributing to the superior performance of\nLarge Language Models (LLMs) is the extensive availability of human-annotated\nnatural language data, which is used for alignment fine-tuning. This inspired\nresearchers to investigate self-training methods to mitigate the extensive\nreliance on human annotations. However, the current success of self-training\nhas been primarily observed in natural language scenarios, rather than in the\nincreasingly important neural-symbolic scenarios. To this end, we propose an\nenvironment-guided neural-symbolic self-training framework named ENVISIONS. It\naims to overcome two main challenges: (1) the scarcity of symbolic data, and\n(2) the limited proficiency of LLMs in processing symbolic language. Extensive\nevaluations conducted on three distinct domains demonstrate the effectiveness\nof our approach. Additionally, we have conducted a comprehensive analysis to\nuncover the factors contributing to ENVISIONS's success, thereby offering\nvaluable insights for future research in this area. Code will be available at\n\\url{https://github.com/xufangzhi/ENVISIONS}.",
      "tldr_zh": "该研究提出了一种名为Interactive Evolution的环境引导神经符号自训练框架（ENVISIONS），旨在减少Large Language Models (LLMs)对人类标注数据的依赖，并扩展自训练方法至神经符号场景。框架主要解决符号数据稀缺和LLMs处理符号语言能力有限的两个挑战，通过环境引导机制实现交互式演化训练。在三个不同领域的大规模评估中，该方法证明了其有效性，并通过全面分析揭示了成功的关键因素，为未来LLMs的自训练研究提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11736v1",
      "published_date": "2024-06-17 16:52:56 UTC",
      "updated_date": "2024-06-17 16:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:08:15.662709"
    },
    {
      "arxiv_id": "2406.11721v2",
      "title": "The Right Time Matters: Data Arrangement Affects Zero-Shot Generalization in Instruction Tuning",
      "title_zh": "时机正确很重要：数据安排影响指令微调中的零样本泛化",
      "authors": [
        "Bingxiang He",
        "Ning Ding",
        "Cheng Qian",
        "Jia Deng",
        "Ganqu Cui",
        "Lifan Yuan",
        "Haiwen Hong",
        "Huan-ang Gao",
        "Longtao Huang",
        "Hui Xue",
        "Huimin Chen",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Understanding alignment techniques begins with comprehending zero-shot\ngeneralization brought by instruction tuning, but little of the mechanism has\nbeen understood. Existing work has largely been confined to the task level,\nwithout considering that tasks are artificially defined and, to LLMs, merely\nconsist of tokens and representations. To bridge this gap, we investigate\nzero-shot generalization from the perspective of the data itself. We first\ndemonstrate that zero-shot generalization happens very early during instruction\ntuning, with loss serving as a stable indicator. Next, we investigate training\ndata arrangement through similarity and granularity perspectives, confirming\nthat the timing of exposure to certain training examples may greatly facilitate\ngeneralization on unseen tasks. Finally, we propose a more grounded training\ndata arrangement framework, Test-centric Multi-turn Arrangement, and show its\neffectiveness in promoting continual learning and further loss reduction. For\nthe first time, we show that zero-shot generalization during instruction tuning\nis a form of similarity-based generalization between training and test data at\nthe instance level. Our code is released at\nhttps://github.com/thunlp/Dynamics-of-Zero-Shot-Generalization.",
      "tldr_zh": "本研究探讨了指令微调(instruction tuning)中零-shot generalization的机制，从数据本身角度入手，而不是任务层面。研究发现，zero-shot generalization在训练早期即发生，且损失(loss)可作为稳定指标；训练数据安排的时机、相似性和粒度会显著影响泛化效果。作者提出了一种新的框架Test-centric Multi-turn Arrangement，能够促进持续学习和进一步降低损失，并首次证明zero-shot generalization是训练与测试数据在实例级别上的基于相似性的泛化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11721v2",
      "published_date": "2024-06-17 16:40:21 UTC",
      "updated_date": "2025-04-07 14:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:08:28.460003"
    },
    {
      "arxiv_id": "2406.11717v3",
      "title": "Refusal in Language Models Is Mediated by a Single Direction",
      "title_zh": "翻译失败",
      "authors": [
        "Andy Arditi",
        "Oscar Obeso",
        "Aaquib Syed",
        "Daniel Paleka",
        "Nina Panickssery",
        "Wes Gurnee",
        "Neel Nanda"
      ],
      "abstract": "Conversational large language models are fine-tuned for both\ninstruction-following and safety, resulting in models that obey benign requests\nbut refuse harmful ones. While this refusal behavior is widespread across chat\nmodels, its underlying mechanisms remain poorly understood. In this work, we\nshow that refusal is mediated by a one-dimensional subspace, across 13 popular\nopen-source chat models up to 72B parameters in size. Specifically, for each\nmodel, we find a single direction such that erasing this direction from the\nmodel's residual stream activations prevents it from refusing harmful\ninstructions, while adding this direction elicits refusal on even harmless\ninstructions. Leveraging this insight, we propose a novel white-box jailbreak\nmethod that surgically disables refusal with minimal effect on other\ncapabilities. Finally, we mechanistically analyze how adversarial suffixes\nsuppress propagation of the refusal-mediating direction. Our findings\nunderscore the brittleness of current safety fine-tuning methods. More broadly,\nour work showcases how an understanding of model internals can be leveraged to\ndevelop practical methods for controlling model behavior.",
      "tldr_zh": "这篇论文发现，大语言模型（Language Models）的拒绝行为由一个一维子空间（one-dimensional subspace）中介，在13个流行开源聊天模型中（大小达72B参数）均适用。具体来说，研究者识别出一个单一方向，通过从模型的残差流（residual stream）激活中擦除该方向，可以防止模型拒绝有害指令，而添加该方向则会引发对无害指令的拒绝。基于此，他们提出了一种新型白盒越狱（white-box jailbreak）方法，能够精确禁用拒绝行为，同时对模型的其他能力影响最小。最后，论文分析了对抗后缀如何抑制该中介方向的传播，并强调了当前安全微调方法的脆弱性，这为理解和控制模型行为提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11717v3",
      "published_date": "2024-06-17 16:36:12 UTC",
      "updated_date": "2024-10-30 18:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:08:42.005108"
    },
    {
      "arxiv_id": "2406.11704v2",
      "title": "Nemotron-4 340B Technical Report",
      "title_zh": "Nemotron-4 340B 技术报告",
      "authors": [
        "Nvidia",
        ":",
        "Bo Adler",
        "Niket Agarwal",
        "Ashwath Aithal",
        "Dong H. Anh",
        "Pallab Bhattacharya",
        "Annika Brundyn",
        "Jared Casper",
        "Bryan Catanzaro",
        "Sharon Clay",
        "Jonathan Cohen",
        "Sirshak Das",
        "Ayush Dattagupta",
        "Olivier Delalleau",
        "Leon Derczynski",
        "Yi Dong",
        "Daniel Egert",
        "Ellie Evans",
        "Aleksander Ficek",
        "Denys Fridman",
        "Shaona Ghosh",
        "Boris Ginsburg",
        "Igor Gitman",
        "Tomasz Grzegorzek",
        "Robert Hero",
        "Jining Huang",
        "Vibhu Jawa",
        "Joseph Jennings",
        "Aastha Jhunjhunwala",
        "John Kamalu",
        "Sadaf Khan",
        "Oleksii Kuchaiev",
        "Patrick LeGresley",
        "Hui Li",
        "Jiwei Liu",
        "Zihan Liu",
        "Eileen Long",
        "Ameya Sunil Mahabaleshwarkar",
        "Somshubra Majumdar",
        "James Maki",
        "Miguel Martinez",
        "Maer Rodrigues de Melo",
        "Ivan Moshkov",
        "Deepak Narayanan",
        "Sean Narenthiran",
        "Jesus Navarro",
        "Phong Nguyen",
        "Osvald Nitski",
        "Vahid Noroozi",
        "Guruprasad Nutheti",
        "Christopher Parisien",
        "Jupinder Parmar",
        "Mostofa Patwary",
        "Krzysztof Pawelec",
        "Wei Ping",
        "Shrimai Prabhumoye",
        "Rajarshi Roy",
        "Trisha Saar",
        "Vasanth Rao Naik Sabavat",
        "Sanjeev Satheesh",
        "Jane Polak Scowcroft",
        "Jason Sewall",
        "Pavel Shamis",
        "Gerald Shen",
        "Mohammad Shoeybi",
        "Dave Sizer",
        "Misha Smelyanskiy",
        "Felipe Soares",
        "Makesh Narsimhan Sreedhar",
        "Dan Su",
        "Sandeep Subramanian",
        "Shengyang Sun",
        "Shubham Toshniwal",
        "Hao Wang",
        "Zhilin Wang",
        "Jiaxuan You",
        "Jiaqi Zeng",
        "Jimmy Zhang",
        "Jing Zhang",
        "Vivienne Zhang",
        "Yian Zhang",
        "Chen Zhu"
      ],
      "abstract": "We release the Nemotron-4 340B model family, including Nemotron-4-340B-Base,\nNemotron-4-340B-Instruct, and Nemotron-4-340B-Reward. Our models are open\naccess under the NVIDIA Open Model License Agreement, a permissive model\nlicense that allows distribution, modification, and use of the models and its\noutputs. These models perform competitively to open access models on a wide\nrange of evaluation benchmarks, and were sized to fit on a single DGX H100 with\n8 GPUs when deployed in FP8 precision. We believe that the community can\nbenefit from these models in various research studies and commercial\napplications, especially for generating synthetic data to train smaller\nlanguage models. Notably, over 98% of data used in our model alignment process\nis synthetically generated, showcasing the effectiveness of these models in\ngenerating synthetic data. To further support open research and facilitate\nmodel development, we are also open-sourcing the synthetic data generation\npipeline used in our model alignment process.",
      "tldr_zh": "这篇技术报告介绍了 NVIDIA 发布的 Nemotron-4 340B 模型家族，包括 Nemotron-4-340B-Base、Nemotron-4-340B-Instruct 和 Nemotron-4-340B-Reward，这些模型在 NVIDIA Open Model License Agreement 下开源，允许分发、修改和使用。模型在各种评估基准上表现出与开源模型相当的竞争力，并能以 FP8 精度在单台 DGX H100（8 GPUs）上部署。超过 98% 的模型对齐数据是通过合成生成实现的，突显了这些模型在生成合成数据用于训练小型语言模型方面的有效性；同时，报告开源了合成数据生成管道，以支持进一步的研究和商业应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11704v2",
      "published_date": "2024-06-17 16:25:04 UTC",
      "updated_date": "2024-08-06 22:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:08:52.476048"
    },
    {
      "arxiv_id": "2406.11695v2",
      "title": "Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs",
      "title_zh": "翻译失败",
      "authors": [
        "Krista Opsahl-Ong",
        "Michael J Ryan",
        "Josh Purtell",
        "David Broman",
        "Christopher Potts",
        "Matei Zaharia",
        "Omar Khattab"
      ],
      "abstract": "Language Model Programs, i.e. sophisticated pipelines of modular language\nmodel (LM) calls, are increasingly advancing NLP tasks, but they require\ncrafting prompts that are jointly effective for all modules. We study prompt\noptimization for LM programs, i.e. how to update these prompts to maximize a\ndownstream metric without access to module-level labels or gradients. To make\nthis tractable, we factorize our problem into optimizing the free-form\ninstructions and few-shot demonstrations of every module and introduce several\nstrategies to craft task-grounded instructions and navigate credit assignment\nacross modules. Our strategies include (i) program- and data-aware techniques\nfor proposing effective instructions, (ii) a stochastic mini-batch evaluation\nfunction for learning a surrogate model of our objective, and (iii) a\nmeta-optimization procedure in which we refine how LMs construct proposals over\ntime. Using these insights we develop MIPRO, a novel algorithm for optimizing\nLM programs. MIPRO outperforms baseline optimizers on five of seven diverse\nmulti-stage LM programs using a best-in-class open-source model (Llama-3-8B),\nby as high as 13% accuracy. We have released our new optimizers and benchmark\nin DSPy at http://dspy.ai",
      "tldr_zh": "本研究探讨了优化多阶段语言模型程序（Language Model Programs）的指令和少样本演示（few-shot demonstrations），以最大化下游指标，而无需模块级标签或梯度。通过将问题分解为优化每个模块的自由形式指令，该方法引入了程序和数据感知技术、随机小批量评估函数（stochastic mini-batch evaluation）以及元优化过程（meta-optimization），来生成有效的提示和处理跨模块信用分配。研究开发了MIPRO算法，使用Llama-3-8B模型，在七个多样化程序中优于基线优化器，在五个程序上准确率最高提升13%，并发布了优化器和基准于DSPy平台。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024. Krista and Michael contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2406.11695v2",
      "published_date": "2024-06-17 16:12:03 UTC",
      "updated_date": "2024-10-06 17:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:09:03.626941"
    },
    {
      "arxiv_id": "2406.11935v2",
      "title": "A Problem-Oriented Perspective and Anchor Verification for Code Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Ye",
        "Tengfei Ma",
        "Xuhong Zhang",
        "Hang Yu",
        "Jianwei Yin",
        "Wenhai Wang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in solving\nvarious programming tasks, such as code generation. However, their potential\nfor code optimization, particularly in performance enhancement, remains largely\nunexplored. This paper investigates the capabilities of LLMs in optimizing code\nfor minimal execution time, addressing a critical gap in current research. The\nrecently proposed code optimization dataset constructs program optimization\npairs based on iterative submissions from the same programmer for the same\nproblem. However, this approach limits LLMs to local performance improvements,\nneglecting global algorithmic innovation. To overcome this limitation, we adopt\na completely different perspective by reconstructing the optimization pairs\ninto a problem-oriented approach. This allows for the integration of various\nideas from multiple programmers tackling the same problem. Experimental results\ndemonstrate that adapting LLMs to problem-oriented optimization pairs\nsignificantly enhances their optimization capabilities. Furthermore,\nrecognizing the inherent trade-offs in code optimization, we introduce an\nanchor verification mechanism to mitigate the \"optimization tax\". Ultimately,\nour approach elevates both the optimization ratio and speedup to new levels.",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）在代码优化领域的潜力，特别是针对执行时间最小化的问题。不同于现有数据集的程序员迭代方法，本文采用问题导向视角重新构建优化对，通过整合多个程序员针对同一问题的多种想法来提升LLMs的全局优化能力。同时，引入anchor verification机制来缓解代码优化的“optimization tax”权衡问题。实验结果显示，这种方法显著提高了优化比率和加速比，推进了LLMs在性能增强方面的应用。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11935v2",
      "published_date": "2024-06-17 16:10:10 UTC",
      "updated_date": "2025-02-17 07:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:09:14.053764"
    },
    {
      "arxiv_id": "2406.11686v2",
      "title": "The Role of Inherent Bellman Error in Offline Reinforcement Learning with Linear Function Approximation",
      "title_zh": "固有Bellman误差在采用线性函数逼近的离线强化学习中的作用",
      "authors": [
        "Noah Golowich",
        "Ankur Moitra"
      ],
      "abstract": "In this paper, we study the offline RL problem with linear function\napproximation. Our main structural assumption is that the MDP has low inherent\nBellman error, which stipulates that linear value functions have linear Bellman\nbackups with respect to the greedy policy. This assumption is natural in that\nit is essentially the minimal assumption required for value iteration to\nsucceed. We give a computationally efficient algorithm which succeeds under a\nsingle-policy coverage condition on the dataset, namely which outputs a policy\nwhose value is at least that of any policy which is well-covered by the\ndataset. Even in the setting when the inherent Bellman error is 0 (termed\nlinear Bellman completeness), our algorithm yields the first known guarantee\nunder single-policy coverage.\n  In the setting of positive inherent Bellman error\n${\\varepsilon_{\\mathrm{BE}}} > 0$, we show that the suboptimality error of our\nalgorithm scales with $\\sqrt{\\varepsilon_{\\mathrm{BE}}}$. Furthermore, we prove\nthat the scaling of the suboptimality with $\\sqrt{\\varepsilon_{\\mathrm{BE}}}$\ncannot be improved for any algorithm. Our lower bound stands in contrast to\nmany other settings in reinforcement learning with misspecification, where one\ncan typically obtain performance that degrades linearly with the\nmisspecification error.",
      "tldr_zh": "本研究探讨了离线强化学习（offline RL）中固有 Bellman 错误的角色，假设 MDP 具有低 inherent Bellman error，这意味着线性价值函数的 Bellman backups 是线性的，并是价值迭代成功所需的最小条件。研究提出一个计算高效的算法，在数据集满足 single-policy coverage 条件下，能输出一个策略，其价值至少与数据集良好覆盖的任何策略相当。实验结果显示，当 inherent Bellman error 为 0（linear Bellman completeness）时，该算法首次在 single-policy coverage 下提供保证；当 error ${\\varepsilon_{\\mathrm{BE}}} > 0$ 时，算法的次优性错误与 $\\sqrt{\\varepsilon_{\\mathrm{BE}}}$ 成比例，且证明此缩放无法进一步优化，这与强化学习中通常的线性错误下降形成对比。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "RLC 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11686v2",
      "published_date": "2024-06-17 16:04:06 UTC",
      "updated_date": "2024-06-18 04:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:09:29.729259"
    },
    {
      "arxiv_id": "2406.11934v1",
      "title": "Bridging Design Gaps: A Parametric Data Completion Approach With Graph Guided Diffusion Models",
      "title_zh": "桥接设计鸿沟：一种基于图指导扩散模型的参数数据补全方法",
      "authors": [
        "Rui Zhou",
        "Chenyang Yuan",
        "Frank Permenter",
        "Yanxia Zhang",
        "Nikos Arechiga",
        "Matt Klenk",
        "Faez Ahmed"
      ],
      "abstract": "This study introduces a generative imputation model leveraging graph\nattention networks and tabular diffusion models for completing missing\nparametric data in engineering designs. This model functions as an AI design\nco-pilot, providing multiple design options for incomplete designs, which we\ndemonstrate using the bicycle design CAD dataset. Through comparative\nevaluations, we demonstrate that our model significantly outperforms existing\nclassical methods, such as MissForest, hotDeck, PPCA, and tabular generative\nmethod TabCSDI in both the accuracy and diversity of imputation options.\nGenerative modeling also enables a broader exploration of design possibilities,\nthereby enhancing design decision-making by allowing engineers to explore a\nvariety of design completions. The graph model combines GNNs with the\nstructural information contained in assembly graphs, enabling the model to\nunderstand and predict the complex interdependencies between different design\nparameters. The graph model helps accurately capture and impute complex\nparametric interdependencies from an assembly graph, which is key for design\nproblems. By learning from an existing dataset of designs, the imputation\ncapability allows the model to act as an intelligent assistant that\nautocompletes CAD designs based on user-defined partial parametric design,\neffectively bridging the gap between ideation and realization. The proposed\nwork provides a pathway to not only facilitate informed design decisions but\nalso promote creative exploration in design.",
      "tldr_zh": "这篇论文提出了一种生成式插值模型，结合 Graph Attention Networks 和 Tabular Diffusion Models，用于完成工程设计中缺失的参数数据，从而作为 AI 设计协opilot提供多种设计选项，并在自行车 CAD 数据集上进行验证。模型利用 GNNs 与装配图的结构信息，准确捕捉并预测设计参数之间的复杂相互依赖，提升了插值任务的准确性和多样性。相比传统方法如 MissForest、hotDeck、PPCA 和 TabCSDI，该模型显著提高了性能，并促进更广泛的设计探索，帮助工程师桥接构思与实现的差距。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "IDETC 2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2406.11934v1",
      "published_date": "2024-06-17 16:03:17 UTC",
      "updated_date": "2024-06-17 16:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:09:40.373141"
    },
    {
      "arxiv_id": "2407.00067v1",
      "title": "Perceptron Collaborative Filtering",
      "title_zh": "感知器协同过滤",
      "authors": [
        "Arya Chakraborty"
      ],
      "abstract": "While multivariate logistic regression classifiers are a great way of\nimplementing collaborative filtering - a method of making automatic predictions\nabout the interests of a user by collecting preferences or taste information\nfrom many other users, we can also achieve similar results using neural\nnetworks. A recommender system is a subclass of information filtering system\nthat provide suggestions for items that are most pertinent to a particular\nuser. A perceptron or a neural network is a machine learning model designed for\nfitting complex datasets using backpropagation and gradient descent. When\ncoupled with advanced optimization techniques, the model may prove to be a\ngreat substitute for classical logistic classifiers. The optimizations include\nfeature scaling, mean normalization, regularization, hyperparameter tuning and\nusing stochastic/mini-batch gradient descent instead of regular gradient\ndescent. In this use case, we will use the perceptron in the recommender system\nto fit the parameters i.e., the data from a multitude of users and use it to\npredict the preference/interest of a particular user.",
      "tldr_zh": "本论文探讨了使用感知器（perceptron）或神经网络来实现协同过滤（collaborative filtering），作为传统多元逻辑回归分类器的替代方案，以提升推荐系统的性能。方法包括采用反向传播（backpropagation）和梯度下降（gradient descent）来拟合用户偏好数据，并应用优化技术如特征缩放（feature scaling）、均值归一化（mean normalization）、正则化（regularization）、超参数调整（hyperparameter tuning）以及随机/小批量梯度下降（stochastic/mini-batch gradient descent）。通过这种方式，模型能够基于大量用户数据预测特定用户的兴趣偏好，提供更有效的推荐建议。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.8"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00067v1",
      "published_date": "2024-06-17 16:02:45 UTC",
      "updated_date": "2024-06-17 16:02:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:09:52.567419"
    },
    {
      "arxiv_id": "2406.11682v1",
      "title": "Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack",
      "title_zh": "翻译失败",
      "authors": [
        "Shangqing Tu",
        "Zhuoran Pan",
        "Wenxuan Wang",
        "Zhexin Zhang",
        "Yuliang Sun",
        "Jifan Yu",
        "Hongning Wang",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Large language models (LLMs) have been increasingly applied to various\ndomains, which triggers increasing concerns about LLMs' safety on specialized\ndomains, e.g. medicine. However, testing the domain-specific safety of LLMs is\nchallenging due to the lack of domain knowledge-driven attacks in existing\nbenchmarks. To bridge this gap, we propose a new task, knowledge-to-jailbreak,\nwhich aims to generate jailbreaks from domain knowledge to evaluate the safety\nof LLMs when applied to those domains. We collect a large-scale dataset with\n12,974 knowledge-jailbreak pairs and fine-tune a large language model as\njailbreak-generator, to produce domain knowledge-specific jailbreaks.\nExperiments on 13 domains and 8 target LLMs demonstrate the effectiveness of\njailbreak-generator in generating jailbreaks that are both relevant to the\ngiven knowledge and harmful to the target LLMs. We also apply our method to an\nout-of-domain knowledge base, showing that jailbreak-generator can generate\njailbreaks that are comparable in harmfulness to those crafted by human\nexperts. Data and code: https://github.com/THU-KEG/Knowledge-to-Jailbreak/.",
      "tldr_zh": "这篇论文提出了一个新任务“knowledge-to-jailbreak”，旨在利用领域知识生成针对大型语言模型 (LLMs) 的越狱攻击 (jailbreaks)，以评估 LLMs 在专业领域（如医学）的安全问题。研究团队收集了 12,974 个 knowledge-jailbreak 对，并微调了一个大型语言模型作为 jailbreak-generator，以生成特定于领域知识的攻击。实验在 13 个领域和 8 个目标 LLMs 上证明，该生成器能产生相关且有害的 jailbreaks，其效果与人类专家相当，甚至适用于域外知识库。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 14 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.11682v1",
      "published_date": "2024-06-17 15:59:59 UTC",
      "updated_date": "2024-06-17 15:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:10:06.343412"
    },
    {
      "arxiv_id": "2406.11681v1",
      "title": "R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models",
      "title_zh": "R-Eval：用于评估检索增强大语言模型领域知识的统一工具包",
      "authors": [
        "Shangqing Tu",
        "Yuanchun Wang",
        "Jifan Yu",
        "Yuyang Xie",
        "Yaran Shi",
        "Xiaozhi Wang",
        "Jing Zhang",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Large language models have achieved remarkable success on general NLP tasks,\nbut they may fall short for domain-specific problems. Recently, various\nRetrieval-Augmented Large Language Models (RALLMs) are proposed to address this\nshortcoming. However, existing evaluation tools only provide a few baselines\nand evaluate them on various domains without mining the depth of domain\nknowledge. In this paper, we address the challenges of evaluating RALLMs by\nintroducing the R-Eval toolkit, a Python toolkit designed to streamline the\nevaluation of different RAG workflows in conjunction with LLMs. Our toolkit,\nwhich supports popular built-in RAG workflows and allows for the incorporation\nof customized testing data on the specific domain, is designed to be\nuser-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs\nacross three task levels and two representative domains, revealing significant\nvariations in the effectiveness of RALLMs across different tasks and domains.\nOur analysis emphasizes the importance of considering both task and domain\nrequirements when choosing a RAG workflow and LLM combination. We are committed\nto continuously maintaining our platform at https://github.com/THU-KEG/R-Eval\nto facilitate both the industry and the researchers.",
      "tldr_zh": "本文介绍了 R-Eval 工具包，这是一个统一的 Python 工具，用于评估 Retrieval-Augmented Large Language Models (RALLMs) 在领域知识方面的表现，旨在解决现有评估工具的局限性。R-Eval 支持流行的 RAG workflows，并允许用户添加自定义测试数据，使其用户友好、模块化和可扩展。通过评估 21 个 RALLMs 在三个任务级别和两个代表性领域中，发现不同任务和领域对模型有效性有显著影响，强调选择合适的 RAG 工作流和 LLM 组合的重要性。该工具包已在 GitHub 上开源，并承诺持续维护。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 9 figures, Accepted by KDD2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11681v1",
      "published_date": "2024-06-17 15:59:49 UTC",
      "updated_date": "2024-06-17 15:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:10:18.734912"
    },
    {
      "arxiv_id": "2406.11675v5",
      "title": "BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yibin Wang",
        "Haizhou Shi",
        "Ligong Han",
        "Dimitris Metaxas",
        "Hao Wang"
      ],
      "abstract": "Large Language Models (LLMs) often suffer from overconfidence during\ninference, particularly when adapted to downstream domain-specific tasks with\nlimited data. Previous work addresses this issue by employing approximate\nBayesian estimation after the LLMs are trained, enabling them to quantify\nuncertainty. However, such post-training approaches' performance is severely\nlimited by the parameters learned during training. In this paper, we go beyond\npost-training Bayesianization and propose Bayesian Low-Rank Adaptation by\nBackpropagation (BLoB), an algorithm that continuously and jointly adjusts both\nthe mean and covariance of LLM parameters throughout the whole fine-tuning\nprocess. Our empirical results verify the effectiveness of BLoB in terms of\ngeneralization and uncertainty estimation, when evaluated on both\nin-distribution and out-of-distribution data.",
      "tldr_zh": "大语言模型 (LLMs) 在使用有限数据适应下游任务时，往往存在过度自信的问题，现有方法仅在训练后通过近似贝叶斯估计来量化不确定性，但效果受限于训练参数。论文提出 BLoB 算法，即 Bayesian Low-Rank Adaptation by Backpropagation，通过在整个微调过程中连续调整参数的均值和协方差，实现对不确定性的联合优化。实验结果显示，BLoB 在分布内和分布外数据上显著提升了模型的泛化和不确定性估计性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024. Additional experiments have been included\n  in the appendix",
      "pdf_url": "http://arxiv.org/pdf/2406.11675v5",
      "published_date": "2024-06-17 15:55:38 UTC",
      "updated_date": "2025-01-27 16:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:10:29.439030"
    },
    {
      "arxiv_id": "2406.11670v1",
      "title": "Benchmarking of LLM Detection: Comparing Two Competing Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Thorsten Pröhl",
        "Erik Putzier",
        "Rüdiger Zarnekow"
      ],
      "abstract": "This article gives an overview of the field of LLM text recognition.\nDifferent approaches and implemented detectors for the recognition of\nLLM-generated text are presented. In addition to discussing the\nimplementations, the article focuses on benchmarking the detectors. Although\nthere are numerous software products for the recognition of LLM-generated text,\nwith a focus on ChatGPT-like LLMs, the quality of the recognition (recognition\nrate) is not clear. Furthermore, while it can be seen that scientific\ncontributions presenting their novel approaches strive for some kind of\ncomparison with other approaches, the construction and independence of the\nevaluation dataset is often not comprehensible. As a result, discrepancies in\nthe performance evaluation of LLM detectors are often visible due to the\ndifferent benchmarking datasets. This article describes the creation of an\nevaluation dataset and uses this dataset to investigate the different\ndetectors. The selected detectors are benchmarked against each other.",
      "tldr_zh": "这篇文章概述了LLM（Large Language Models）生成文本的检测领域，讨论了不同检测方法和实现，并强调了现有检测器的识别率不确定性以及基准测试数据集不一致导致的性能评估差异。作者创建了一个独立的评估数据集，用于比较两种竞争检测方法。实验结果展示了这些检测器之间的表现差异，为未来LLM检测研究提供了更可靠的基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11670v1",
      "published_date": "2024-06-17 15:51:46 UTC",
      "updated_date": "2024-06-17 15:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:10:41.140796"
    },
    {
      "arxiv_id": "2406.11667v3",
      "title": "Is Efficient PAC Learning Possible with an Oracle That Responds 'Yes' or 'No'?",
      "title_zh": "翻译失败",
      "authors": [
        "Constantinos Daskalakis",
        "Noah Golowich"
      ],
      "abstract": "The empirical risk minimization (ERM) principle has been highly impactful in\nmachine learning, leading both to near-optimal theoretical guarantees for\nERM-based learning algorithms as well as driving many of the recent empirical\nsuccesses in deep learning. In this paper, we investigate the question of\nwhether the ability to perform ERM, which computes a hypothesis minimizing\nempirical risk on a given dataset, is necessary for efficient learning: in\nparticular, is there a weaker oracle than ERM which can nevertheless enable\nlearnability? We answer this question affirmatively, showing that in the\nrealizable setting of PAC learning for binary classification, a concept class\ncan be learned using an oracle which only returns a single bit indicating\nwhether a given dataset is realizable by some concept in the class. The sample\ncomplexity and oracle complexity of our algorithm depend polynomially on the VC\ndimension of the hypothesis class, thus showing that there is only a polynomial\nprice to pay for use of our weaker oracle. Our results extend to the agnostic\nlearning setting with a slight strengthening of the oracle, as well as to the\npartial concept, multiclass and real-valued learning settings. In the setting\nof partial concept classes, prior to our work no oracle-efficient algorithms\nwere known, even with a standard ERM oracle. Thus, our results address a\nquestion of Alon et al. (2021) who asked whether there are algorithmic\nprinciples which enable efficient learnability in this setting.",
      "tldr_zh": "本研究探讨了在机器学习中，是否可以通过一个仅返回“Yes”或“No”的简单 oracle 来实现高效 PAC Learning，而非依赖传统的 Empirical Risk Minimization (ERM) 算法。在可实现设置下，作者证明了一种算法，使用该 oracle 判断数据集是否可由概念类实现，其样本复杂度和 oracle 复杂度仅与 VC Dimension 多项式相关，从而仅需多项式代价即可学习。结果扩展到 Agnostic Learning、Partial Concept Classes、Multiclass 和 Real-Valued Learning 设置中，并在 Partial Concept Classes 中首次提供了 oracle-efficient 算法，回答了 Alon et al. (2021) 的相关问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "COLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11667v3",
      "published_date": "2024-06-17 15:50:08 UTC",
      "updated_date": "2025-02-24 02:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:10:53.728619"
    },
    {
      "arxiv_id": "2406.11665v2",
      "title": "See It from My Perspective: How Language Affects Cultural Bias in Image Understanding",
      "title_zh": "从我的视角：",
      "authors": [
        "Amith Ananthram",
        "Elias Stengel-Eskin",
        "Mohit Bansal",
        "Kathleen McKeown"
      ],
      "abstract": "Vision-language models (VLMs) can respond to queries about images in many\nlanguages. However, beyond language, culture affects how we see things. For\nexample, individuals from Western cultures focus more on the central figure in\nan image while individuals from East Asian cultures attend more to scene\ncontext. In this work, we characterize the Western bias of VLMs in image\nunderstanding and investigate the role that language plays in this disparity.\nWe evaluate VLMs across subjective and objective visual tasks with culturally\ndiverse images and annotations. We find that VLMs perform better on the Western\nsplit than on the East Asian split of each task. Through controlled\nexperimentation, we trace one source of this bias in image understanding to the\nlack of diversity in language model construction. While inference in a language\nnearer to a culture can lead to reductions in bias, we show it is much more\neffective when that language was well-represented during text-only\npre-training. Interestingly, this yields bias reductions even when prompting in\nEnglish. Our work highlights the importance of richer representation of all\nlanguages in building equitable VLMs.",
      "tldr_zh": "本研究探讨了视觉语言模型（VLMs）在图像理解中存在的文化偏见，特别是西方偏见，以及语言在其中的作用。研究者通过评估VLMs在主观和客观视觉任务上的表现，使用文化多样化的图像和注释，发现VLMs在西方相关任务中表现优于东亚任务。控制实验揭示，这种偏见部分源于语言模型构建中的多样性缺失，而使用与文化更接近的语言进行推理，或在文本预训练中增加语言表示，能有效减少偏见，甚至在英语提示下也能实现。研究强调，构建更公平的VLMs需要更丰富的语言多样性，以促进文化均衡的图像理解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICLR 2025. 22 pages, 6 figures. Code/models:\n  https://github.com/amith-ananthram/see-it-from-my-perspective",
      "pdf_url": "http://arxiv.org/pdf/2406.11665v2",
      "published_date": "2024-06-17 15:49:51 UTC",
      "updated_date": "2025-02-28 20:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:11:06.364529"
    },
    {
      "arxiv_id": "2406.11641v1",
      "title": "YOLO-FEDER FusionNet: A Novel Deep Learning Architecture for Drone Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tamara R. Lenhard",
        "Andreas Weinmann",
        "Stefan Jäger",
        "Tobias Koch"
      ],
      "abstract": "Predominant methods for image-based drone detection frequently rely on\nemploying generic object detection algorithms like YOLOv5. While proficient in\nidentifying drones against homogeneous backgrounds, these algorithms often\nstruggle in complex, highly textured environments. In such scenarios, drones\nseamlessly integrate into the background, creating camouflage effects that\nadversely affect the detection quality. To address this issue, we introduce a\nnovel deep learning architecture called YOLO-FEDER FusionNet. Unlike\nconventional approaches, YOLO-FEDER FusionNet combines generic object detection\nmethods with the specialized strength of camouflage object detection techniques\nto enhance drone detection capabilities. Comprehensive evaluations of\nYOLO-FEDER FusionNet show the efficiency of the proposed model and demonstrate\nsubstantial improvements in both reducing missed detections and false alarms.",
      "tldr_zh": "本文研究了现有无人机检测方法（如 YOLOv5）的局限性，这些算法在复杂、高纹理背景中难以识别无人机，因为无人机易与背景融合。作者提出了一种新型深度学习架构 YOLO-FEDER FusionNet，将通用物体检测技术与伪装物体检测方法相结合，以提升检测能力。实验评估显示，该模型显著提高了效率，减少了漏检和误报，为无人机检测提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 4 figures, 6 tables, to be published in the conference\n  proceedings of the 2024 IEEE International Conference on Image Processing\n  (ICIP)",
      "pdf_url": "http://arxiv.org/pdf/2406.11641v1",
      "published_date": "2024-06-17 15:25:31 UTC",
      "updated_date": "2024-06-17 15:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:11:16.416825"
    },
    {
      "arxiv_id": "2406.11640v2",
      "title": "Linear Bellman Completeness Suffices for Efficient Online Reinforcement Learning with Few Actions",
      "title_zh": "线性Bellman完备性足以实现少量动作下的高效在线强化学习",
      "authors": [
        "Noah Golowich",
        "Ankur Moitra"
      ],
      "abstract": "One of the most natural approaches to reinforcement learning (RL) with\nfunction approximation is value iteration, which inductively generates\napproximations to the optimal value function by solving a sequence of\nregression problems. To ensure the success of value iteration, it is typically\nassumed that Bellman completeness holds, which ensures that these regression\nproblems are well-specified. We study the problem of learning an optimal policy\nunder Bellman completeness in the online model of RL with linear function\napproximation. In the linear setting, while statistically efficient algorithms\nare known under Bellman completeness (e.g., Jiang et al. (2017); Zanette et al.\n(2020)), these algorithms all rely on the principle of global optimism which\nrequires solving a nonconvex optimization problem. In particular, it has\nremained open as to whether computationally efficient algorithms exist. In this\npaper we give the first polynomial-time algorithm for RL under linear Bellman\ncompleteness when the number of actions is any constant.",
      "tldr_zh": "这篇论文探讨了在线强化学习（Online RL）中，使用线性函数逼近和Bellman completeness条件来高效学习最优策略的问题。传统算法依赖全局乐观主义，需要解决非凸优化问题，从而导致计算效率低下；论文首次提出了一种多项式时间算法，通过value iteration和回归问题序列来克服这些挑战，仅适用于动作数量为常数的场景。该算法在统计上高效，为RL领域提供了可计算的解决方案，显著提升了实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "COLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11640v2",
      "published_date": "2024-06-17 15:24:49 UTC",
      "updated_date": "2024-06-18 04:27:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:11:29.525453"
    },
    {
      "arxiv_id": "2407.00066v3",
      "title": "Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead",
      "title_zh": "翻译失败",
      "authors": [
        "Rickard Brüel-Gabrielsson",
        "Jiacheng Zhu",
        "Onkar Bhardwaj",
        "Leshem Choshen",
        "Kristjan Greenewald",
        "Mikhail Yurochkin",
        "Justin Solomon"
      ],
      "abstract": "Fine-tuning large language models (LLMs) with low-rank adaptations (LoRAs)\nhas become common practice, often yielding numerous copies of the same LLM\ndiffering only in their LoRA updates. This paradigm presents challenges for\nsystems that serve real-time responses to queries that each involve a different\nLoRA. Prior works optimize the design of such systems but still require\ncontinuous loading and offloading of LoRAs, as it is infeasible to store\nthousands of LoRAs in GPU memory. To mitigate this issue, we investigate the\nefficacy of compression when serving LoRAs. We propose a method for the joint\ncompression of LoRAs into a shared basis paired with LoRA-specific scaling\nmatrices. We extend our algorithm to learn clusters of LoRAs that are amenable\nto joint compression, allowing it to scale gracefully to large LoRA\ncollections. Our experiments with up to 1000 LoRAs demonstrate that compressed\nLoRAs preserve performance while offering major throughput gains in realistic\nserving scenarios with over a thousand LoRAs, maintaining 80% of the throughput\nof serving a single LoRA.",
      "tldr_zh": "本研究解决了微调大语言模型（LLMs）时，使用低秩适配（LoRAs）导致的系统服务挑战，即无法在GPU memory中存储数千个LoRAs，从而需要频繁加载和卸载。作者提出了一种联合压缩方法，将LoRAs压缩成共享基（shared basis）并配以LoRA特定的缩放矩阵，并扩展算法以学习LoRAs集群，实现对大规模LoRA集合的优雅处理。实验结果显示，在涉及多达1000个LoRAs的实际服务场景中，该方法保持了性能，同时将吞吐量提升至服务单个LoRA的80%，显著降低了开销。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00066v3",
      "published_date": "2024-06-17 15:21:35 UTC",
      "updated_date": "2025-02-01 21:56:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:11:41.443141"
    },
    {
      "arxiv_id": "2406.11638v1",
      "title": "MASAI: Modular Architecture for Software-engineering AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Daman Arora",
        "Atharv Sonwane",
        "Nalin Wadhwa",
        "Abhav Mehrotra",
        "Saiteja Utpala",
        "Ramakrishna Bairi",
        "Aditya Kanade",
        "Nagarajan Natarajan"
      ],
      "abstract": "A common method to solve complex problems in software engineering, is to\ndivide the problem into multiple sub-problems. Inspired by this, we propose a\nModular Architecture for Software-engineering AI (MASAI) agents, where\ndifferent LLM-powered sub-agents are instantiated with well-defined objectives\nand strategies tuned to achieve those objectives. Our modular architecture\noffers several advantages: (1) employing and tuning different problem-solving\nstrategies across sub-agents, (2) enabling sub-agents to gather information\nfrom different sources scattered throughout a repository, and (3) avoiding\nunnecessarily long trajectories which inflate costs and add extraneous context.\nMASAI enabled us to achieve the highest performance (28.33% resolution rate) on\nthe popular and highly challenging SWE-bench Lite dataset consisting of 300\nGitHub issues from 11 Python repositories. We conduct a comprehensive\nevaluation of MASAI relative to other agentic methods and analyze the effects\nof our design decisions and their contribution to the success of MASAI.",
      "tldr_zh": "本文提出 MASAI，一种模块化架构，用于软件工程 AI 代理，通过将复杂问题分解为多个子问题，并使用 LLM 驱动的子代理来实现特定目标和策略。MASAI 的优势包括采用多样化问题解决策略、多源信息收集以及避免过长轨迹，从而提高效率和成本效益。在 SWE-bench Lite 数据集上，MASAI 实现了 28.33% 的最高解决率，并通过全面评估分析了其设计决策对性能的贡献。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11638v1",
      "published_date": "2024-06-17 15:19:51 UTC",
      "updated_date": "2024-06-17 15:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:11:55.064694"
    },
    {
      "arxiv_id": "2406.11634v2",
      "title": "The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance",
      "title_zh": "基率效应对 LLM 基准性能的影响：区分测试策略与基准性能",
      "authors": [
        "Kyle Moore",
        "Jesse Roberts",
        "Thao Pham",
        "Oseremhen Ewaleifoh",
        "Doug Fisher"
      ],
      "abstract": "Cloze testing is a common method for measuring the behavior of large language\nmodels on a number of benchmark tasks. Using the MMLU dataset, we show that the\nbase-rate probability (BRP) differences across answer tokens are significant\nand affect task performance ie. guess A if uncertain. We find that\ncounterfactual prompting does sufficiently mitigate the BRP effect. The BRP\neffect is found to have a similar effect to test taking strategies employed by\nhumans leading to the conflation of task performance and test-taking ability.\nWe propose the Nvr-X-MMLU task, a variation of MMLU, which helps to\ndisambiguate test-taking ability from task performance and reports the latter.",
      "tldr_zh": "本研究探讨了 base-rate probability (BRP) 对大型语言模型 (LLM) 基准测试性能的影响，指出 BRP 差异（如不确定时偏好选择 A）会混淆任务表现与考试策略，使用 MMLU 数据集进行分析。研究发现，counterfactual prompting 无法有效缓解 BRP 效应，且其影响类似于人类的测试策略。论文提出 Nvr-X-MMLU 任务作为 MMLU 的变体，帮助区分测试策略与实际任务性能，从而更准确评估 LLM 的能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11634v2",
      "published_date": "2024-06-17 15:14:10 UTC",
      "updated_date": "2024-09-30 17:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:12:07.309707"
    },
    {
      "arxiv_id": "2406.11632v4",
      "title": "Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Boxuan Lyu",
        "Hidetaka Kamigaito",
        "Kotaro Funakoshi",
        "Manabu Okumura"
      ],
      "abstract": "Maximum a posteriori decoding, a commonly used method for neural machine\ntranslation (NMT), aims to maximize the estimated posterior probability.\nHowever, high estimated probability does not always lead to high translation\nquality. Minimum Bayes Risk (MBR) decoding (\\citealp{kumar2004minimum}) offers\nan alternative by seeking hypotheses with the highest expected utility.\n  Inspired by Quality Estimation (QE) reranking which uses the QE model as a\nranker (\\citealp{fernandes-etal-2022-quality}), we propose source-based MBR\n(sMBR) decoding, a novel approach that utilizes quasi-sources (generated via\nparaphrasing or back-translation) as ``support hypotheses'' and a\nreference-free quality estimation metric as the utility function, marking the\nfirst work to solely use sources in MBR decoding. Experiments show that sMBR\noutperforms QE reranking and the standard MBR decoding. Our findings suggest\nthat sMBR is a promising approach for NMT decoding.",
      "tldr_zh": "神经机器翻译 (NMT) 中，传统的最大后验解码往往无法确保翻译质量，而 Minimum Bayes Risk (MBR) 解码通过最大化期望效用提供替代方案。本文提出 source-based MBR (sMBR) 解码方法，使用 quasi-sources (通过 paraphrasing 或 back-translation 生成) 作为支持假设，并采用无参考 Quality Estimation (QE) 指标作为效用函数，这是首次仅依赖源数据进行 MBR 解码。实验结果显示，sMBR 优于 QE reranking 和标准 MBR 解码，表明其在提升 NMT 性能方面具有显著潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11632v4",
      "published_date": "2024-06-17 15:13:52 UTC",
      "updated_date": "2025-02-16 10:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:12:20.126270"
    },
    {
      "arxiv_id": "2406.11614v2",
      "title": "Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces",
      "title_zh": "翻译失败",
      "authors": [
        "Yihuai Hong",
        "Lei Yu",
        "Haiqin Yang",
        "Shauli Ravfogel",
        "Mor Geva"
      ],
      "abstract": "The task of \"unlearning\" certain concepts in large language models (LLMs) has\nattracted immense attention recently, due to its importance in mitigating\nundesirable model behaviours, such as the generation of harmful, private, or\nincorrect information. Current protocols to evaluate unlearning methods largely\nrely on behavioral tests, without monitoring the presence of unlearned\nknowledge within the model's parameters. This residual knowledge can be\nadversarially exploited to recover the erased information post-unlearning. We\nargue that unlearning should also be evaluated internally, by considering\nchanges in the parametric knowledge traces of the unlearned concepts. To this\nend, we propose a general evaluation methodology that leverages vocabulary\nprojections to inspect concepts encoded in model parameters. We use this\napproach to localize \"concept vectors\" - parameter vectors that encode concrete\nconcepts - and construct ConceptVectors, a benchmark dataset containing\nhundreds of common concepts and their parametric knowledge traces within two\nopen-source LLMs. Evaluation on ConceptVectors shows that existing unlearning\nmethods minimally impact concept vectors and mostly suppress them during\ninference, while directly ablating these vectors demonstrably removes the\nassociated knowledge and significantly reduces the model's susceptibility to\nadversarial manipulation. Our results highlight limitations in behavioral-based\nunlearning evaluations and call for future work to include parameter-based\nevaluations. To support this, we release our code and benchmark at\nhttps://github.com/yihuaihong/ConceptVectors.",
      "tldr_zh": "这篇论文探讨了在大型语言模型(LLMs)中进行unlearning（概念删除）的内部评估方法，旨在解决当前行为测试的局限性，因为残留的parametric knowledge traces可能被对抗性利用来恢复已删除信息。作者提出一种基于词汇投影的评估方法，用于定位和分析concept vectors——这些参数向量编码了具体概念——并构建了ConceptVectors基准数据集，包含数百个常见概念及其在两个开源LLMs中的知识痕迹。实验结果显示，现有的unlearning方法对concept vectors的影响最小，主要通过抑制来掩盖知识，而直接消融这些向量能显著移除相关知识并降低模型对adversarial manipulation的易感性。论文强调了行为-based评估的不足，呼吁未来工作结合parameter-based评估，并发布了代码和基准以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11614v2",
      "published_date": "2024-06-17 15:00:35 UTC",
      "updated_date": "2024-10-04 11:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:12:31.936711"
    },
    {
      "arxiv_id": "2406.11612v1",
      "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
      "title_zh": "翻译失败",
      "authors": [
        "Egor Bogomolov",
        "Aleksandra Eliseeva",
        "Timur Galimzyanov",
        "Evgeniy Glukhov",
        "Anton Shapkin",
        "Maria Tigina",
        "Yaroslav Golubev",
        "Alexander Kovrigin",
        "Arie van Deursen",
        "Maliheh Izadi",
        "Timofey Bryksin"
      ],
      "abstract": "Nowadays, the fields of code and natural language processing are evolving\nrapidly. In particular, models become better at processing long context windows\n- supported context sizes have increased by orders of magnitude over the last\nfew years. However, there is a shortage of benchmarks for code processing that\ngo beyond a single file of context, while the most popular ones are limited to\na single method. With this work, we aim to close this gap by introducing Long\nCode Arena, a suite of six benchmarks for code processing tasks that require\nproject-wide context. These tasks cover different aspects of code processing:\nlibrary-based code generation, CI builds repair, project-level code completion,\ncommit message generation, bug localization, and module summarization. For each\ntask, we provide a manually verified dataset for testing, an evaluation suite,\nand open-source baseline solutions based on popular LLMs to showcase the usage\nof the dataset and to simplify adoption by other researchers. We publish the\nbenchmark page on HuggingFace Spaces with the leaderboard, links to HuggingFace\nHub for all the datasets, and link to the GitHub repository with baselines:\nhttps://huggingface.co/spaces/JetBrains-Research/long-code-arena.",
      "tldr_zh": "该论文介绍了 Long Code Arena，这是一个针对长上下文代码模型的基准套件，旨在解决现有基准测试局限于单个文件或方法的不足，强调处理项目级上下文的需求。基准套件包括六种任务：library-based代码生成、CI builds repair、项目-level代码补全、commit message generation、bug localization和module summarization，每个任务都提供手动验证的数据集、评估工具以及基于流行LLMs的开源基线，以简化研究采用。作者还发布了HuggingFace Spaces上的基准页面、排行榜和GitHub仓库，促进社区评估和改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "54 pages, 4 figures, 22 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.11612v1",
      "published_date": "2024-06-17 14:58:29 UTC",
      "updated_date": "2024-06-17 14:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:12:42.901678"
    },
    {
      "arxiv_id": "2406.11589v5",
      "title": "CoSQA+: Pioneering the Multi-Choice Code Search Benchmark with Test-Driven Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Gong",
        "Yanghui Wu",
        "Linxi Liang",
        "Yanlin Wang",
        "Jiachi Chen",
        "Mingwei Liu",
        "Zibin Zheng"
      ],
      "abstract": "Semantic code search, retrieving code that matches a given natural language\nquery, is an important task to improve productivity in software engineering.\nExisting code search datasets face limitations: they rely on human annotators\nwho assess code primarily through semantic understanding rather than functional\nverification, leading to potential inaccuracies and scalability issues.\nAdditionally, current evaluation metrics often overlook the multi-choice nature\nof code search. This paper introduces CoSQA+, pairing high-quality queries from\nCoSQA with multiple suitable codes. We develop an automated pipeline featuring\nmultiple model-based candidate selections and the novel test-driven agent\nannotation system. Among a single Large Language Model (LLM) annotator and\nPython expert annotators (without test-based verification), agents leverage\ntest-based verification and achieve the highest accuracy of 92.0%. Through\nextensive experiments, CoSQA+ has demonstrated superior quality over CoSQA.\nModels trained on CoSQA+ exhibit improved performance. We provide the code and\ndata at https://github.com/DeepSoftwareAnalytics/CoSQA_Plus.",
      "tldr_zh": "这篇论文引入了 CoSQA+，一个新的多选代码搜索基准数据集，旨在解决现有数据集依赖人工标注和缺乏功能验证的问题。\n他们开发了一个自动化管道，包括多个模型-based 候选选择和创新的 test-driven agent 注解系统，该系统通过测试-based 验证实现了高达92.0%的准确率，比单一 Large Language Model (LLM) 或 Python 专家标注更可靠。\n实验结果表明，CoSQA+ 比原 CoSQA 数据集质量更高，训练的模型表现出显著性能提升，并提供了代码和数据资源以供进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR",
        "I.2.7; D.2.3"
      ],
      "primary_category": "cs.SE",
      "comment": "15 pages, 5 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2406.11589v5",
      "published_date": "2024-06-17 14:34:14 UTC",
      "updated_date": "2025-04-11 02:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:12:55.260055"
    },
    {
      "arxiv_id": "2406.11567v1",
      "title": "Quaternion Generative Adversarial Neural Networks and Applications to Color Image Inpainting",
      "title_zh": "四元数生成对抗神经网络及其在彩色图像修复中的应用",
      "authors": [
        "Duan Wang",
        "Dandan Zhu",
        "Meixiang Zhao",
        "Zhigang Jia"
      ],
      "abstract": "Color image inpainting is a challenging task in imaging science. The existing\nmethod is based on real operation, and the red, green and blue channels of the\ncolor image are processed separately, ignoring the correlation between each\nchannel. In order to make full use of the correlation between each channel,\nthis paper proposes a Quaternion Generative Adversarial Neural Network (QGAN)\nmodel and related theory, and applies it to solve the problem of color image\ninpainting with large area missing. Firstly, the definition of quaternion\ndeconvolution is given and the quaternion batch normalization is proposed.\nSecondly, the above two innovative modules are applied to generate adversarial\nnetworks to improve stability. Finally, QGAN is applied to color image\ninpainting and compared with other state-of-the-art algorithms. The\nexperimental results show that QGAN has superiority in color image inpainting\nwith large area missing.",
      "tldr_zh": "本论文针对颜色图像修复中的通道相关性问题，提出了一种四元数生成对抗神经网络 (QGAN) 模型及其理论基础，以处理大面积缺失的图像。首先，论文定义了四元数 deconvolution 并引入了四元数 batch normalization，这些创新模块被应用到生成对抗网络中以提升稳定性。实验结果显示，QGAN 在颜色图像修复任务上比其他最先进算法表现出优越性，充分利用了红、绿、蓝通道之间的相关性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11567v1",
      "published_date": "2024-06-17 14:04:17 UTC",
      "updated_date": "2024-06-17 14:04:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:13:05.717536"
    },
    {
      "arxiv_id": "2406.11563v3",
      "title": "Intersymbolic AI: Interlinking Symbolic AI and Subsymbolic AI",
      "title_zh": "翻译失败",
      "authors": [
        "André Platzer"
      ],
      "abstract": "This perspective piece calls for the study of the new field of Intersymbolic\nAI, by which we mean the combination of symbolic AI, whose building blocks have\ninherent significance/meaning, with subsymbolic AI, whose entirety creates\nsignificance/effect despite the fact that individual building blocks escape\nmeaning. Canonical kinds of symbolic AI are logic, games and planning.\nCanonical kinds of subsymbolic AI are (un)supervised machine and reinforcement\nlearning. Intersymbolic AI interlinks the worlds of symbolic AI with its\ncompositional symbolic significance and meaning and of subsymbolic AI with its\nsummative significance or effect to enable culminations of insights from both\nworlds by going between and across symbolic AI insights with subsymbolic AI\ntechniques that are being helped by symbolic AI principles. For example,\nIntersymbolic AI may start with symbolic AI to understand a dynamic system,\ncontinue with subsymbolic AI to learn its control, and end with symbolic AI to\nsafely use the outcome of the learned subsymbolic AI controller in the dynamic\nsystem. The way Intersymbolic AI combines both symbolic and subsymbolic AI to\nincrease the effectiveness of AI compared to either kind of AI alone is likened\nto the way that the combination of both conscious and subconscious thought\nincreases the effectiveness of human thought compared to either kind of thought\nalone. Some successful contributions to the Intersymbolic AI paradigm are\nsurveyed here but many more are considered possible by advancing Intersymbolic\nAI.",
      "tldr_zh": "这篇论文提出 Intersymbolic AI 这一新领域，旨在将 symbolic AI（其组成部分具有内在意义，如 logic、games 和 planning）与 subsymbolic AI（通过整体产生意义，如 supervised machine learning 和 reinforcement learning）相结合。Intersymbolic AI 通过在两者之间互联，实现从 symbolic AI 的洞见到 subsymbolic AI 技术的应用，例如先用 symbolic AI 理解动态系统，再用 subsymbolic AI 学习控制，并以 symbolic AI 确保安全，从而提升 AI 的整体有效性。论文将这种整合比作人类意识和潜意识的结合，并概述了现有成功案例，呼吁进一步推进该范式以实现更多创新。",
      "categories": [
        "cs.AI",
        "68T01, 68T05, 68T07, 68T27, 68T30, 03B70",
        "I.2.0; I.2.3; I.2.4; I.2.6; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11563v3",
      "published_date": "2024-06-17 14:01:59 UTC",
      "updated_date": "2024-07-26 09:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:13:18.796541"
    },
    {
      "arxiv_id": "2407.12789v2",
      "title": "Generalisation to unseen topologies: Towards control of biological neural network activity",
      "title_zh": "翻译失败",
      "authors": [
        "Laurens Engwegen",
        "Daan Brinks",
        "Wendelin Böhmer"
      ],
      "abstract": "Novel imaging and neurostimulation techniques open doors for advancements in\nclosed-loop control of activity in biological neural networks. This would allow\nfor applications in the investigation of activity propagation, and for\ndiagnosis and treatment of pathological behaviour. Due to the partially\nobservable characteristics of activity propagation, through networks in which\nedges can not be observed, and the dynamic nature of neuronal systems, there is\na need for adaptive, generalisable control. In this paper, we introduce an\nenvironment that procedurally generates neuronal networks with different\ntopologies to investigate this generalisation problem. Additionally, an\nexisting transformer-based architecture is adjusted to evaluate the\ngeneralisation performance of a deep RL agent in the presented partially\nobservable environment. The agent demonstrates the capability to generalise\ncontrol from a limited number of training networks to unseen test networks.",
      "tldr_zh": "本研究探讨了通过新型成像和神经刺激技术实现对生物神经网络（biological neural networks）活动进行闭环控制（closed-loop control）的可能性，以应用于活动传播研究以及病理行为的诊断和治疗。论文引入了一个过程生成不同拓扑的环境，用于调查控制的泛化问题，并调整了现有的Transformer-based架构来评估深度强化学习（deep RL）代理在部分可观察环境中的性能。结果显示，该代理能够从有限的训练网络成功泛化到未见拓扑的测试网络，为适应性神经网络控制奠定了基础。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12789v2",
      "published_date": "2024-06-17 13:53:39 UTC",
      "updated_date": "2024-09-27 10:00:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:13:40.698771"
    },
    {
      "arxiv_id": "2406.11555v1",
      "title": "Input Conditioned Graph Generation for Language Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Vierling",
        "Jie Fu",
        "Kai Chen"
      ],
      "abstract": "Recent progress in Large Language Models (LLMs) and language agents has\ndemonstrated significant promise for various future applications across\nmultiple disciplines. While traditional approaches to language agents often\nrely on fixed, handcrafted designs, our research aims to develop both learnable\nand dynamic agents. Our method uses an existing framework that abstracts\nlanguage agents as graphs. Within this graph framework, we aim to learn a model\nthat can generate edges for every given input to the language agent. This\nallows us to generate edges that represent the flow of communication within the\ngraph based on the given input, thereby adjusting the internal communication of\na language agent. We learn to generate these edges using a pretrained LLM that\nis fine-tuned with reinforcement learning. This LLM can be fine-tuned on\nseveral datasets simultaneously, and we hypothesize that the model learns to\nadapt to these different domains during training, achieving good overall\nperformance when encountering data from different domains during deployment. We\ndemonstrate that our approach surpasses the previous static approach by nearly\n6% accuracy on a combined dataset of MMLU and CMMLU, and by more than 10% when\ntrained with a sparsity-inducing loss. It also performs superior in additional\nexperiments conducted with the MMLU and Mini Crossword Puzzles datasets. The\ncode is available at https://github.com/lukasVierling/DynamicGPTSwarm.",
      "tldr_zh": "本研究提出了一种基于输入条件图生成的方法，用于构建可学习的动态语言代理 (language agents)，以超越传统固定设计的局限。该方法将语言代理抽象为 graphs，并使用预训练的 Large Language Models (LLMs) 通过 reinforcement learning fine-tuned 来根据输入生成 edges，从而动态调整代理的内部通信。实验结果显示，该方法在 MMLU 和 CMMLU 组合数据集上比静态方法提高了近 6% 准确率，使用 sparsity-inducing loss 时超过 10%，并在其他数据集如 Mini Crossword Puzzles 上表现出优越性能。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11555v1",
      "published_date": "2024-06-17 13:53:15 UTC",
      "updated_date": "2024-06-17 13:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:13:44.194044"
    },
    {
      "arxiv_id": "2407.16894v2",
      "title": "Estimating the Increase in Emissions caused by AI-augmented Search",
      "title_zh": "翻译失败",
      "authors": [
        "Wim Vanderbauwhede"
      ],
      "abstract": "AI-generated answers to conventional search queries dramatically increase the\nenergy consumption. By our estimates, energy demand increase by 60-70 times.\nThis is a based on an updated estimate of energy consumption for conventional\nsearch and recent work on the energy demand of queries to the BLOOM model, a\n176B parameter model, and OpenAI's GPT-3, which is of similar complexity.",
      "tldr_zh": "这篇论文评估了AI-augmented Search导致的排放增加，估计AI生成答案使能源消耗提高60-70倍。该估计基于对传统搜索能源消耗的更新数据，以及对BLOOM模型（176B参数模型）和GPT-3模型的能源需求分析。这些发现强调了AI在搜索应用中可能带来的环境影响，并呼吁关注可持续性改进。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16894v2",
      "published_date": "2024-06-17 13:52:00 UTC",
      "updated_date": "2025-01-06 11:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:13:57.023868"
    },
    {
      "arxiv_id": "2406.11931v1",
      "title": "DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence",
      "title_zh": "DeepSeek-Coder-V2：打破闭源模型在代码智能领域的壁垒",
      "authors": [
        "DeepSeek-AI",
        "Qihao Zhu",
        "Daya Guo",
        "Zhihong Shao",
        "Dejian Yang",
        "Peiyi Wang",
        "Runxin Xu",
        "Y. Wu",
        "Yukun Li",
        "Huazuo Gao",
        "Shirong Ma",
        "Wangding Zeng",
        "Xiao Bi",
        "Zihui Gu",
        "Hanwei Xu",
        "Damai Dai",
        "Kai Dong",
        "Liyue Zhang",
        "Yishi Piao",
        "Zhibin Gou",
        "Zhenda Xie",
        "Zhewen Hao",
        "Bingxuan Wang",
        "Junxiao Song",
        "Deli Chen",
        "Xin Xie",
        "Kang Guan",
        "Yuxiang You",
        "Aixin Liu",
        "Qiushi Du",
        "Wenjun Gao",
        "Xuan Lu",
        "Qinyu Chen",
        "Yaohui Wang",
        "Chengqi Deng",
        "Jiashi Li",
        "Chenggang Zhao",
        "Chong Ruan",
        "Fuli Luo",
        "Wenfeng Liang"
      ],
      "abstract": "We present DeepSeek-Coder-V2, an open-source Mixture-of-Experts (MoE) code\nlanguage model that achieves performance comparable to GPT4-Turbo in\ncode-specific tasks. Specifically, DeepSeek-Coder-V2 is further pre-trained\nfrom an intermediate checkpoint of DeepSeek-V2 with additional 6 trillion\ntokens. Through this continued pre-training, DeepSeek-Coder-V2 substantially\nenhances the coding and mathematical reasoning capabilities of DeepSeek-V2,\nwhile maintaining comparable performance in general language tasks. Compared to\nDeepSeek-Coder-33B, DeepSeek-Coder-V2 demonstrates significant advancements in\nvarious aspects of code-related tasks, as well as reasoning and general\ncapabilities. Additionally, DeepSeek-Coder-V2 expands its support for\nprogramming languages from 86 to 338, while extending the context length from\n16K to 128K. In standard benchmark evaluations, DeepSeek-Coder-V2 achieves\nsuperior performance compared to closed-source models such as GPT4-Turbo,\nClaude 3 Opus, and Gemini 1.5 Pro in coding and math benchmarks.",
      "tldr_zh": "我们介绍了 DeepSeek-Coder-V2，这是一个开源的 Mixture-of-Experts (MoE) 代码语言模型，其性能在代码特定任务中可与 GPT4-Turbo 相媲美。模型通过对 DeepSeek-V2 的中间检查点进行额外 6 万亿 tokens 的预训练，显著提升了编码和数学推理能力，同时保持了一般语言任务的性能。相比 DeepSeek-Coder-33B，DeepSeek-Coder-V2 在代码相关任务、推理和一般能力上取得了重大进步，并在标准基准测试中超越了闭源模型如 GPT4-Turbo、Claude 3 Opus 和 Gemini 1.5 Pro。该模型还扩展了支持的编程语言从 86 种到 338 种，并将上下文长度从 16K 增加到 128K。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11931v1",
      "published_date": "2024-06-17 13:51:35 UTC",
      "updated_date": "2024-06-17 13:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:14:11.820772"
    },
    {
      "arxiv_id": "2406.11548v6",
      "title": "AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Chuyan Xiong",
        "Chengyu Shen",
        "Xiaoqi Li",
        "Kaichen Zhou",
        "Jeremy Liu",
        "Ruiping Wang",
        "Hao Dong"
      ],
      "abstract": "The ability to reflect on and correct failures is crucial for robotic systems\nto interact stably with real-life objects.Observing the generalization and\nreasoning capabilities of Multimodal Large Language Models (MLLMs), previous\napproaches have aimed to utilize these models to enhance robotic systems\naccordingly.However, these methods typically focus on high-level planning\ncorrections using an additional MLLM, with limited utilization of failed\nsamples to correct low-level contact poses which is particularly prone to occur\nduring articulated object manipulation.To address this gap, we propose an\nAutonomous Interactive Correction (AIC) MLLM, which makes use of previous\nlow-level interaction experiences to correct SE(3) pose predictions for\narticulated object. Specifically, AIC MLLM is initially fine-tuned to acquire\nboth pose prediction and feedback prompt comprehension abilities.We design two\ntypes of prompt instructions for interactions with objects: 1) visual masks to\nhighlight unmovable parts for position correction, and 2) textual descriptions\nto indicate potential directions for rotation correction. During inference, a\nFeedback Information Extraction module is introduced to recognize the failure\ncause, allowing AIC MLLM to adaptively correct the pose prediction using the\ncorresponding prompts.To further enhance manipulation stability, we devise a\nTest Time Adaptation strategy that enables AIC MLLM to better adapt to the\ncurrent scene configuration.Finally, extensive experiments are conducted in\nboth simulated and real-world environments to evaluate the proposed method. The\nresults demonstrate that our AIC MLLM can efficiently correct failure samples\nby leveraging interaction experience prompts.Our project website is\nhttps://sites.google.com/view/aic-mllm.",
      "tldr_zh": "该论文提出AIC MLLM（Autonomous Interactive Correction MLLM），一种自主交互修正框架，用于提升机器人操纵的鲁棒性，通过利用之前的低层交互经验来修正SE(3)姿势预测，针对铰接物体操作中的失败问题。方法包括初始微调MLLM以获得姿势预测和反馈提示理解能力，并设计visual masks和textual descriptions两种提示指令，以及引入Feedback Information Extraction模块来识别失败原因并自适应修正；此外，还采用Test Time Adaptation策略以更好地适应当前场景。实验在大纲和真实环境中验证了AIC MLLM的有效性，结果显示它能高效利用交互经验提示修正失败样本，提高了机器人系统的稳定性和性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11548v6",
      "published_date": "2024-06-17 13:44:53 UTC",
      "updated_date": "2024-11-16 07:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:14:23.380832"
    },
    {
      "arxiv_id": "2406.11547v1",
      "title": "GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations",
      "title_zh": "GECOBench：一种用于量化解释中偏差的性别控制文本数据集和基准测试",
      "authors": [
        "Rick Wilming",
        "Artur Dox",
        "Hjalmar Schulz",
        "Marta Oliveira",
        "Benedict Clark",
        "Stefan Haufe"
      ],
      "abstract": "Large pre-trained language models have become popular for many applications\nand form an important backbone of many downstream tasks in natural language\nprocessing (NLP). Applying 'explainable artificial intelligence' (XAI)\ntechniques to enrich such models' outputs is considered crucial for assuring\ntheir quality and shedding light on their inner workings. However, large\nlanguage models are trained on a plethora of data containing a variety of\nbiases, such as gender biases, affecting model weights and, potentially,\nbehavior. Currently, it is unclear to what extent such biases also impact model\nexplanations in possibly unfavorable ways. We create a gender-controlled text\ndataset, GECO, in which otherwise identical sentences appear in male and female\nforms. This gives rise to ground-truth 'world explanations' for gender\nclassification tasks, enabling the objective evaluation of the correctness of\nXAI methods. We also provide GECOBench, a rigorous quantitative evaluation\nframework benchmarking popular XAI methods, applying them to pre-trained\nlanguage models fine-tuned to different degrees. This allows us to investigate\nhow pre-training induces undesirable bias in model explanations and to what\nextent fine-tuning can mitigate such explanation bias. We show a clear\ndependency between explanation performance and the number of fine-tuned layers,\nwhere XAI methods are observed to particularly benefit from fine-tuning or\ncomplete retraining of embedding layers. Remarkably, this relationship holds\nfor models achieving similar classification performance on the same task. With\nthat, we highlight the utility of the proposed gender-controlled dataset and\nnovel benchmarking approach for research and development of novel XAI methods.\nAll code including dataset generation, model training, evaluation and\nvisualization is available at: https://github.com/braindatalab/gecobench",
      "tldr_zh": "本研究引入了GECO数据集和GECOBench基准，用于量化预训练语言模型(XAI)解释中的性别偏差。GECO通过创建性别控制的文本（即相同句子以男性和女性形式呈现）提供ground-truth解释，允许客观评估XAI方法的正确性。研究发现，预训练模型的解释偏差与微调层数密切相关，特别是对embedding层的微调或完全重训可显著改善解释性能，即使分类任务表现相似。总体而言，此框架突出了评估和缓解模型解释偏差的新途径，并提供了开源代码以支持进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2406.11547v1",
      "published_date": "2024-06-17 13:44:37 UTC",
      "updated_date": "2024-06-17 13:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:14:33.299938"
    },
    {
      "arxiv_id": "2407.00065v1",
      "title": "A Personalised Learning Tool for Physics Undergraduate Students Built On a Large Language Model for Symbolic Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Yufan Zhu",
        "Zi-Yu Khoo",
        "Jonathan Sze Choong Low",
        "Stephane Bressan"
      ],
      "abstract": "Interleaved practice enhances the memory and problem-solving ability of\nstudents in undergraduate courses. We introduce a personalized learning tool\nbuilt on a Large Language Model (LLM) that can provide immediate and\npersonalized attention to students as they complete homework containing\nproblems interleaved from undergraduate physics courses. Our tool leverages the\ndimensional analysis method, enhancing students' qualitative thinking and\nproblem-solving skills for complex phenomena. Our approach combines LLMs for\nsymbolic regression with dimensional analysis via prompt engineering and offers\nstudents a unique perspective to comprehend relationships between physics\nvariables. This fosters a broader and more versatile understanding of physics\nand mathematical principles and complements a conventional undergraduate\nphysics education that relies on interpreting and applying established\nequations within specific contexts. We test our personalized learning tool on\nthe equations from Feynman's lectures on physics. Our tool can correctly\nidentify relationships between physics variables for most equations,\nunderscoring its value as a complementary personalized learning tool for\nundergraduate physics students.",
      "tldr_zh": "本文提出了一种基于大型语言模型 (LLM) 的个性化学习工具，旨在通过交错练习提升物理本科生在家庭作业中的记忆力和问题解决能力。该工具结合符号回归 (symbolic regression) 和维度分析方法，通过提示工程帮助学生理解物理变量之间的关系，并培养定性思考技能。在测试中使用费曼物理学讲义的方程，该工具能正确识别大多数变量关系，证明其作为传统物理教育补充的有效性。",
      "categories": [
        "physics.ed-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ed-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00065v1",
      "published_date": "2024-06-17 13:43:30 UTC",
      "updated_date": "2024-06-17 13:43:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:14:44.517520"
    },
    {
      "arxiv_id": "2406.11544v4",
      "title": "Do Parameters Reveal More than Loss for Membership Inference?",
      "title_zh": "翻译失败",
      "authors": [
        "Anshuman Suri",
        "Xiao Zhang",
        "David Evans"
      ],
      "abstract": "Membership inference attacks are used as a key tool for disclosure auditing.\nThey aim to infer whether an individual record was used to train a model. While\nsuch evaluations are useful to demonstrate risk, they are computationally\nexpensive and often make strong assumptions about potential adversaries' access\nto models and training environments, and thus do not provide tight bounds on\nleakage from potential attacks. We show how prior claims around black-box\naccess being sufficient for optimal membership inference do not hold for\nstochastic gradient descent, and that optimal membership inference indeed\nrequires white-box access. Our theoretical results lead to a new white-box\ninference attack, IHA (Inverse Hessian Attack), that explicitly uses model\nparameters by taking advantage of computing inverse-Hessian vector products.\nOur results show that both auditors and adversaries may be able to benefit from\naccess to model parameters, and we advocate for further research into white-box\nmethods for membership inference.",
      "tldr_zh": "本研究探讨了在成员推断(Membership Inference)攻击中，模型参数是否比损失函数更能揭示训练数据信息。作者证明，对于随机梯度下降(Stochastic Gradient Descent)，黑箱访问不足以实现最佳攻击，而白箱访问是必需的。基于此，他们提出了一种新白箱攻击方法IHA (Inverse Hessian Attack)，通过计算逆Hessian向量乘积来利用模型参数。结果显示，IHA攻击显著提升了成员推断的准确性，并呼吁进一步研究白箱方法以改善隐私审计。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to Transactions on Machine Learning Research (TMLR)",
      "pdf_url": "http://arxiv.org/pdf/2406.11544v4",
      "published_date": "2024-06-17 13:42:28 UTC",
      "updated_date": "2024-12-19 14:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:14:59.008179"
    },
    {
      "arxiv_id": "2407.12788v1",
      "title": "SS-ADA: A Semi-Supervised Active Domain Adaptation Framework for Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Yan",
        "Yeqiang Qian",
        "Yueyuan Li",
        "Tao Li",
        "Chunxiang Wang",
        "Ming Yang"
      ],
      "abstract": "Semantic segmentation plays an important role in intelligent vehicles,\nproviding pixel-level semantic information about the environment. However, the\nlabeling budget is expensive and time-consuming when semantic segmentation\nmodel is applied to new driving scenarios. To reduce the costs, semi-supervised\nsemantic segmentation methods have been proposed to leverage large quantities\nof unlabeled images. Despite this, their performance still falls short of the\naccuracy required for practical applications, which is typically achieved by\nsupervised learning. A significant shortcoming is that they typically select\nunlabeled images for annotation randomly, neglecting the assessment of sample\nvalue for model training. In this paper, we propose a novel semi-supervised\nactive domain adaptation (SS-ADA) framework for semantic segmentation that\nemploys an image-level acquisition strategy. SS-ADA integrates active learning\ninto semi-supervised semantic segmentation to achieve the accuracy of\nsupervised learning with a limited amount of labeled data from the target\ndomain. Additionally, we design an IoU-based class weighting strategy to\nalleviate the class imbalance problem using annotations from active learning.\nWe conducted extensive experiments on synthetic-to-real and real-to-real domain\nadaptation settings. The results demonstrate the effectiveness of our method.\nSS-ADA can achieve or even surpass the accuracy of its supervised learning\ncounterpart with only 25% of the target labeled data when using a real-time\nsegmentation model. The code for SS-ADA is available at\nhttps://github.com/ywher/SS-ADA.",
      "tldr_zh": "本研究针对语义分割（Semantic Segmentation）在智能车辆中的应用，提出了一种半监督主动域适配（SS-ADA）框架，以降低新场景下数据标注的成本和时间。SS-ADA 将主动学习（Active Learning）集成到半监督语义分割中，通过图像级获取策略选择高价值样本进行标注，并引入基于 IoU 的类权重策略（IoU-based class weighting）来缓解类不平衡问题。实验结果显示，在合成到真实和真实到真实域适配设置中，SS-ADA 仅需 25% 的目标域标注数据，即可达到或超过监督学习的准确性，为高效的语义分割模型部署提供了实用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages,13 figures,8 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.12788v1",
      "published_date": "2024-06-17 13:40:42 UTC",
      "updated_date": "2024-06-17 13:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:15:10.622020"
    },
    {
      "arxiv_id": "2406.11538v1",
      "title": "Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation",
      "title_zh": "通过显式人工制品增强改善全滑片图像的质量控制",
      "authors": [
        "Artur Jurgas",
        "Marek Wodzinski",
        "Marina D'Amato",
        "Jeroen van der Laak",
        "Manfredo Atzori",
        "Henning Müller"
      ],
      "abstract": "The problem of artifacts in whole slide image acquisition, prevalent in both\nclinical workflows and research-oriented settings, necessitates human\nintervention and re-scanning. Overcoming this challenge requires developing\nquality control algorithms, that are hindered by the limited availability of\nrelevant annotated data in histopathology. The manual annotation of\nground-truth for artifact detection methods is expensive and time-consuming.\nThis work addresses the issue by proposing a method dedicated to augmenting\nwhole slide images with artifacts. The tool seamlessly generates and blends\nartifacts from an external library to a given histopathology dataset. The\naugmented datasets are then utilized to train artifact classification methods.\nThe evaluation shows their usefulness in classification of the artifacts, where\nthey show an improvement from 0.10 to 0.01 AUROC depending on the artifact\ntype. The framework, model, weights, and ground-truth annotations are freely\nreleased to facilitate open science and reproducible research.",
      "tldr_zh": "本研究针对全滑片图像（whole slide images）中常见工件（artifacts）问题提出了一种显式工件增强方法，以解决标注数据稀缺导致的质量控制算法开发挑战。方法通过从外部库生成工件并无缝混合到现有组织病理学数据集，从而创建增强数据集，用于训练工件分类模型。实验结果显示，该方法显著提高了分类性能，根据工件类型，AUROC分数从0.10改善至0.01。该框架、模型权重和标注数据已开源，以促进开放科学和可重复研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11538v1",
      "published_date": "2024-06-17 13:39:31 UTC",
      "updated_date": "2024-06-17 13:39:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:15:20.843986"
    },
    {
      "arxiv_id": "2406.11524v1",
      "title": "Explainable Artificial Intelligence and Multicollinearity : A Mini Review of Current Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed M Salih"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) methods help to understand the\ninternal mechanism of machine learning models and how they reach a specific\ndecision or made a specific action. The list of informative features is one of\nthe most common output of XAI methods. Multicollinearity is one of the big\nissue that should be considered when XAI generates the explanation in terms of\nthe most informative features in an AI system. No review has been dedicated to\ninvestigate the current approaches to handle such significant issue. In this\npaper, we provide a review of the current state-of-the-art approaches in\nrelation to the XAI in the context of recent advances in dealing with the\nmulticollinearity issue. To do so, we searched in three repositories that are:\nWeb of Science, Scopus and IEEE Xplore to find pertinent published papers.\nAfter excluding irrelevant papers, seven papers were considered in the review.\nIn addition, we discuss the current XAI methods and their limitations in\ndealing with the multicollinearity and suggest future directions.",
      "tldr_zh": "这篇论文审阅了Explainable Artificial Intelligence (XAI) 方法在处理Multicollinearity（多重共线性）问题时的当前方法，强调了Multicollinearity如何影响XAI生成的信息特征解释。作者通过搜索Web of Science、Scopus和IEEE Xplore数据库，筛选出7篇相关论文，分析了现有XAI方法的局限性，如无法有效应对特征间的相关性。论文为未来XAI研究提供了建议方向，以提升模型解释的准确性和可靠性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11524v1",
      "published_date": "2024-06-17 13:26:53 UTC",
      "updated_date": "2024-06-17 13:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:15:32.627528"
    },
    {
      "arxiv_id": "2406.11522v2",
      "title": "FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Lorenz",
        "Marta Kwiatkowska",
        "Mario Fritz"
      ],
      "abstract": "Modern machine learning models are sensitive to the manipulation of both the\ntraining data (poisoning attacks) and inference data (adversarial examples).\nRecognizing this issue, the community has developed many empirical defenses\nagainst both attacks and, more recently, certification methods with provable\nguarantees against inference-time attacks. However, such guarantees are still\nlargely lacking for training-time attacks. In this work, we present FullCert,\nthe first end-to-end certifier with sound, deterministic bounds, which proves\nrobustness against both training-time and inference-time attacks. We first\nbound all possible perturbations an adversary can make to the training data\nunder the considered threat model. Using these constraints, we bound the\nperturbations' influence on the model's parameters. Finally, we bound the\nimpact of these parameter changes on the model's prediction, resulting in joint\nrobustness guarantees against poisoning and adversarial examples. To facilitate\nthis novel certification paradigm, we combine our theoretical work with a new\nopen-source library BoundFlow, which enables model training on bounded\ndatasets. We experimentally demonstrate FullCert's feasibility on two datasets.",
      "tldr_zh": "这篇论文提出了 FullCert，一种端到端认证框架，能够为神经网络的训练和推理提供针对 poisoning attacks 和 adversarial examples 的确定性鲁棒性保证。FullCert 通过绑定攻击者对训练数据的可能扰动、模型参数的影响以及这些变化对预测的最终影响，来实现对训练时和推理时攻击的联合证明。作者开发了开源库 BoundFlow，以支持在绑定数据集上训练模型，并在两个数据集的实验中验证了该方法的 feasibility。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in DAGM GCPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11522v2",
      "published_date": "2024-06-17 13:23:52 UTC",
      "updated_date": "2024-09-11 12:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:15:46.069828"
    },
    {
      "arxiv_id": "2406.11517v1",
      "title": "Revisiting Spurious Correlation in Domain Generalization",
      "title_zh": "重新审视领域泛化中的虚假相关",
      "authors": [
        "Bin Qin",
        "Jiangmeng Li",
        "Yi Li",
        "Xuesong Wu",
        "Yupeng Wang",
        "Wenwen Qiang",
        "Jianwen Cao"
      ],
      "abstract": "Without loss of generality, existing machine learning techniques may learn\nspurious correlation dependent on the domain, which exacerbates the\ngeneralization of models in out-of-distribution (OOD) scenarios. To address\nthis issue, recent works build a structural causal model (SCM) to describe the\ncausality within data generation process, thereby motivating methods to avoid\nthe learning of spurious correlation by models. However, from the machine\nlearning viewpoint, such a theoretical analysis omits the nuanced difference\nbetween the data generation process and representation learning process,\nresulting in that the causal analysis based on the former cannot well adapt to\nthe latter. To this end, we explore to build a SCM for representation learning\nprocess and further conduct a thorough analysis of the mechanisms underlying\nspurious correlation. We underscore that adjusting erroneous covariates\nintroduces bias, thus necessitating the correct selection of spurious\ncorrelation mechanisms based on practical application scenarios. In this\nregard, we substantiate the correctness of the proposed SCM and further propose\nto control confounding bias in OOD generalization by introducing a propensity\nscore weighted estimator, which can be integrated into any existing OOD method\nas a plug-and-play module. The empirical results comprehensively demonstrate\nthe effectiveness of our method on synthetic and large-scale real OOD datasets.",
      "tldr_zh": "本论文重新审视了在 Domain Generalization 中的 spurious correlation 问题，指出现有基于 structural causal model (SCM) 的分析忽略了数据生成过程与 representation learning 过程的差异，导致泛化效果不佳。作者构建了一个新的 SCM 用于 representation learning 过程，并深入分析了 spurious correlation 的机制，强调需根据实际场景正确选择机制以避免偏差。论文提出了一种倾向评分加权估计器(propensity score weighted estimator)，作为插件模块集成到现有 OOD generalization 方法中，以控制混杂偏差(confounding bias)。实验结果在合成和大规模真实 OOD 数据集上证明了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11517v1",
      "published_date": "2024-06-17 13:22:00 UTC",
      "updated_date": "2024-06-17 13:22:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:15:59.144649"
    },
    {
      "arxiv_id": "2406.11930v1",
      "title": "A Critical Study of What Code-LLMs (Do Not) Learn",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Anand",
        "Shweta Verma",
        "Krishna Narasimhan",
        "Mira Mezini"
      ],
      "abstract": "Large Language Models trained on code corpora (code-LLMs) have demonstrated\nimpressive performance in various coding assistance tasks. However, despite\ntheir increased size and training dataset, code-LLMs still have limitations\nsuch as suggesting codes with syntactic errors, variable misuse etc. Some\nstudies argue that code-LLMs perform well on coding tasks because they use\nself-attention and hidden representations to encode relations among input\ntokens. However, previous works have not studied what code properties are not\nencoded by code-LLMs. In this paper, we conduct a fine-grained analysis of\nattention maps and hidden representations of code-LLMs. Our study indicates\nthat code-LLMs only encode relations among specific subsets of input tokens.\nSpecifically, by categorizing input tokens into syntactic tokens and\nidentifiers, we found that models encode relations among syntactic tokens and\namong identifiers, but they fail to encode relations between syntactic tokens\nand identifiers. We also found that fine-tuned models encode these relations\npoorly compared to their pre-trained counterparts. Additionally, larger models\nwith billions of parameters encode significantly less information about code\nthan models with only a few hundred million parameters.",
      "tldr_zh": "本研究对训练在代码语料上的大型语言模型（code-LLMs）进行了细粒度分析，揭示了它们在编码代码关系方面的局限性，如可能生成语法错误或变量误用的代码。研究者通过分析注意力图和隐藏表示，将输入标记分为语法标记和标识符，发现code-LLMs能够编码语法标记间以及标识符间的关系，但未能有效编码两者之间的关系。结果显示，微调后的模型在这些方面表现不如预训练模型，而参数量更大的模型反而编码的信息更少，这为理解code-LLMs的弱点提供了重要洞见。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11930v1",
      "published_date": "2024-06-17 13:11:17 UTC",
      "updated_date": "2024-06-17 13:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:16:11.052092"
    },
    {
      "arxiv_id": "2407.07719v3",
      "title": "Model-based learning for multi-antenna multi-frequency location-to-channel mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Baptiste Chatelier",
        "Vincent Corlay",
        "Matthieu Crussière",
        "Luc Le Magoarou"
      ],
      "abstract": "Years of study of the propagation channel showed a close relation between a\nlocation and the associated communication channel response. The use of a neural\nnetwork to learn the location-to-channel mapping can therefore be envisioned.\nThe Implicit Neural Representation (INR) literature showed that classical\nneural architecture are biased towards learning low-frequency content, making\nthe location-to-channel mapping learning a non-trivial problem. Indeed, it is\nwell known that this mapping is a function rapidly varying with the location,\non the order of the wavelength. This paper leverages the model-based machine\nlearning paradigm to derive a problem-specific neural architecture from a\npropagation channel model. The resulting architecture efficiently overcomes the\nspectral-bias issue. It only learns low-frequency sparse correction terms\nactivating a dictionary of high-frequency components. The proposed architecture\nis evaluated against classical INR architectures on realistic synthetic data,\nshowing much better accuracy. Its mapping learning performance is explained\nbased on the approximated channel model, highlighting the explainability of the\nmodel-based machine learning paradigm.",
      "tldr_zh": "本论文探讨了使用神经网络学习多天线多频场景下的位置到通道映射问题，以解决经典Implicit Neural Representation (INR)架构偏向低频内容的局限性。研究基于model-based machine learning范式，从传播通道模型中推导出特定神经架构，该架构专注于学习低频稀疏校正项并激活高频组件字典，从而高效克服光谱偏差。实验在真实合成数据上显示，该架构的准确性远超传统INR架构，并通过近似通道模型解释了其性能优势，突出了model-based machine learning的可解释性。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07719v3",
      "published_date": "2024-06-17 13:09:25 UTC",
      "updated_date": "2025-03-20 09:21:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:16:23.472286"
    },
    {
      "arxiv_id": "2406.11504v1",
      "title": "On the Feasibility of Fidelity$^-$ for Graph Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Yong-Min Shin",
        "Won-Yong Shin"
      ],
      "abstract": "As one of popular quantitative metrics to assess the quality of explanation\nof graph neural networks (GNNs), fidelity measures the output difference after\nremoving unimportant parts of the input graph. Fidelity has been widely used\ndue to its straightforward interpretation that the underlying model should\nproduce similar predictions when features deemed unimportant from the\nexplanation are removed. This raises a natural question: \"Does fidelity induce\na global (soft) mask for graph pruning?\" To solve this, we aim to explore the\npotential of the fidelity measure to be used for graph pruning, eventually\nenhancing the GNN models for better efficiency. To this end, we propose\nFidelity$^-$-inspired Pruning (FiP), an effective framework to construct global\nedge masks from local explanations. Our empirical observations using 7 edge\nattribution methods demonstrate that, surprisingly, general eXplainable AI\nmethods outperform methods tailored to GNNs in terms of graph pruning\nperformance.",
      "tldr_zh": "该论文探讨了Fidelity作为图神经网络(GNNs)解释质量评估指标的可行性，Fidelity通过测量移除不重要图部分后的输出差异来评估模型预测的一致性。作者提出Fidelity$^-$-inspired Pruning (FiP)框架，从局部解释构建全局边掩码，以实现有效的图修剪，从而提升GNNs的效率。实验结果显示，使用7种边归因方法时，通用eXplainable AI方法在图修剪性能上优于专门针对GNNs的设计方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "cs.NE",
        "cs.SI",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures, 2 tables; IJCAI Workshop on Explainable AI (XAI\n  2024) (to appear) (Please cite our workshop version.)",
      "pdf_url": "http://arxiv.org/pdf/2406.11504v1",
      "published_date": "2024-06-17 13:05:00 UTC",
      "updated_date": "2024-06-17 13:05:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:16:33.648015"
    },
    {
      "arxiv_id": "2406.11501v2",
      "title": "Teleporter Theory: A General and Simple Approach for Modeling Cross-World Counterfactual Causality",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangmeng Li",
        "Bin Qin",
        "Qirui Ji",
        "Yi Li",
        "Wenwen Qiang",
        "Jianwen Cao",
        "Fanjiang Xu"
      ],
      "abstract": "Leveraging the development of structural causal model (SCM), researchers can\nestablish graphical models for exploring the causal mechanisms behind machine\nlearning techniques. As the complexity of machine learning applications rises,\nsingle-world interventionism causal analysis encounters theoretical adaptation\nlimitations. Accordingly, cross-world counterfactual approach extends our\nunderstanding of causality beyond observed data, enabling hypothetical\nreasoning about alternative scenarios. However, the joint involvement of\ncross-world variables, encompassing counterfactual variables and real-world\nvariables, challenges the construction of the graphical model. Twin network is\na subtle attempt, establishing a symbiotic relationship, to bridge the gap\nbetween graphical modeling and the introduction of counterfactuals albeit with\nroom for improvement in generalization. In this regard, we demonstrate the\ntheoretical breakdowns of twin networks in certain cross-world counterfactual\nscenarios. To this end, we propose a novel teleporter theory to establish a\ngeneral and simple graphical representation of counterfactuals, which provides\ncriteria for determining teleporter variables to connect multiple worlds. In\ntheoretical application, we determine that introducing the proposed teleporter\ntheory can directly obtain the conditional independence between counterfactual\nvariables and real-world variables from the cross-world SCM without requiring\ncomplex algebraic derivations. Accordingly, we can further identify\ncounterfactual causal effects through cross-world symbolic derivation. We\ndemonstrate the generality of the teleporter theory to the practical\napplication. Adhering to the proposed theory, we build a plug-and-play module,\nand the effectiveness of which are substantiated by experiments on benchmarks.",
      "tldr_zh": "该论文针对结构因果模型 (SCM) 在处理跨世界反事实因果性时存在的理论局限性，提出了一种通用且简单的 Teleporter Theory，用于构建反事实的图形表示。该理论通过定义 Teleporter 变量来连接多个世界，从而无需复杂代数推导，即可从跨世界 SCM 中直接获得反事实变量与真实世界变量之间的条件独立性，并识别反事实因果效应。与现有 Twin Network 方法相比，该理论在理论应用中更具泛化性，并在基准实验中验证了其有效性，为机器学习中的因果分析提供了更可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11501v2",
      "published_date": "2024-06-17 13:03:44 UTC",
      "updated_date": "2024-06-18 05:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:16:46.654226"
    },
    {
      "arxiv_id": "2406.11495v2",
      "title": "Online Context Learning for Socially Compliant Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Iaroslav Okunevich",
        "Alexandre Lombard",
        "Tomas Krajnik",
        "Yassine Ruichek",
        "Zhi Yan"
      ],
      "abstract": "Robot social navigation needs to adapt to different human factors and\nenvironmental contexts. However, since these factors and contexts are difficult\nto predict and cannot be exhaustively enumerated, traditional learning-based\nmethods have difficulty in ensuring the social attributes of robots in\nlong-term and cross-environment deployments. This letter introduces an online\ncontext learning method that aims to empower robots to adapt to new social\nenvironments online. The proposed method adopts a two-layer structure. The\nbottom layer is built using a deep reinforcement learning-based method to\nensure the output of basic robot navigation commands. The upper layer is\nimplemented using an online robot learning-based method to socialize the\ncontrol commands suggested by the bottom layer. Experiments using a\ncommunity-wide simulator show that our method outperforms the state-of-the-art\nones. Experimental results in the most challenging scenarios show that our\nmethod improves the performance of the state-of-the-art by 8%. The source code\nof the proposed method, the data used, and the tools for the per-training step\nare publicly available at https://github.com/Nedzhaken/SOCSARL-OL.",
      "tldr_zh": "这篇论文提出了一种在线上下文学习方法，以帮助机器人适应不同社会因素和环境，实现合规导航。该方法采用两层结构：底层使用深度强化学习生成基本导航命令，上层通过在线机器人学习优化这些命令以增强社会属性。实验在社区模拟器中表明，该方法优于现有最先进技术，在最具挑战的场景中提升了8%的性能，并公开了源代码以促进进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures, 1 table, 1 algorithm",
      "pdf_url": "http://arxiv.org/pdf/2406.11495v2",
      "published_date": "2024-06-17 12:59:13 UTC",
      "updated_date": "2025-03-14 10:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:16:58.851736"
    },
    {
      "arxiv_id": "2406.11481v3",
      "title": "Constrained Reinforcement Learning with Average Reward Objective: Model-Based and Model-Free Algorithms",
      "title_zh": "具有平均奖励目标的受限强化学习：基于模型和无模型算法",
      "authors": [
        "Vaneet Aggarwal",
        "Washim Uddin Mondal",
        "Qinbo Bai"
      ],
      "abstract": "Reinforcement Learning (RL) serves as a versatile framework for sequential\ndecision-making, finding applications across diverse domains such as robotics,\nautonomous driving, recommendation systems, supply chain optimization, biology,\nmechanics, and finance. The primary objective in these applications is to\nmaximize the average reward. Real-world scenarios often necessitate adherence\nto specific constraints during the learning process.\n  This monograph focuses on the exploration of various model-based and\nmodel-free approaches for Constrained RL within the context of average reward\nMarkov Decision Processes (MDPs). The investigation commences with an\nexamination of model-based strategies, delving into two foundational methods -\noptimism in the face of uncertainty and posterior sampling. Subsequently, the\ndiscussion transitions to parametrized model-free approaches, where the\nprimal-dual policy gradient-based algorithm is explored as a solution for\nconstrained MDPs. The monograph provides regret guarantees and analyzes\nconstraint violation for each of the discussed setups.\n  For the above exploration, we assume the underlying MDP to be ergodic.\nFurther, this monograph extends its discussion to encompass results tailored\nfor weakly communicating MDPs, thereby broadening the scope of its findings and\ntheir relevance to a wider range of practical scenarios.",
      "tldr_zh": "这篇论文探讨了约束强化学习（Constrained Reinforcement Learning）在平均奖励目标（average reward）下的应用，针对Markov Decision Processes (MDPs) 设计了模型-based和模型-free算法，以处理真实场景中的决策约束。论文首先分析了模型-based方法，包括乐观主义（optimism in the face of uncertainty）和后验采样（posterior sampling），并提供相应的遗憾保证（regret guarantees）和约束违反分析（constraint violation）。随后，它扩展到模型-free方法，如主双策略梯度算法（primal-dual policy gradient-based algorithm），并将结果适用于遍历MDPs（ergodic MDPs）和弱通信MDPs（weakly communicating MDPs），从而提升算法在机器人、自动驾驶等领域中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2402.02042",
      "pdf_url": "http://arxiv.org/pdf/2406.11481v3",
      "published_date": "2024-06-17 12:46:02 UTC",
      "updated_date": "2024-07-17 11:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:17:10.666227"
    },
    {
      "arxiv_id": "2406.11477v2",
      "title": "How Can We Effectively Expand the Vocabulary of LLMs with 0.01GB of Target Language Text?",
      "title_zh": "翻译失败",
      "authors": [
        "Atsuki Yamaguchi",
        "Aline Villavicencio",
        "Nikolaos Aletras"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in many\nlanguages beyond English. Yet, LLMs require more inference steps when\ngenerating non-English text due to their reliance on English-centric tokenizers\nand vocabulary, resulting in higher usage costs to non-English speakers.\nVocabulary expansion with target language tokens is a widely used cross-lingual\nvocabulary adaptation approach to remedy this issue. Despite its effectiveness\nin inference speedup, previous work on vocabulary expansion has focused on\nhigh-resource settings assuming access to a substantial amount of target\nlanguage data to effectively initialize the embeddings of the new tokens and\nadapt the LLM to the target language. However, vocabulary expansion in\nlow-resource settings has yet to be explored. In this paper, we investigate\nvocabulary expansion in low-resource settings by considering embedding\ninitialization methods and continual pre-training strategies. Through extensive\nexperiments across typologically diverse languages, tasks and models, we\nestablish a set of strategies to perform vocabulary expansion for faster\ninference, maintaining competitive downstream performance to baselines with\nonly 30K sentences ($\\sim$0.01GB text data) from the target language.",
      "tldr_zh": "本研究探讨了如何在低资源条件下（仅使用约0.01GB的目标语言文本）有效扩展LLMs的词汇表，以解决LLMs依赖英语中心化分词器导致的非英语文本生成效率低下问题。研究者考察了嵌入初始化方法（embedding initialization methods）和持续预训练策略（continual pre-training strategies），通过词汇扩展（vocabulary expansion）来加速推理过程。实验结果显示，在多种类型语言、任务和模型上，仅需30K句子即可实现与基线相当的下游性能，同时显著提高推理效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11477v2",
      "published_date": "2024-06-17 12:42:34 UTC",
      "updated_date": "2024-09-16 13:55:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:17:23.110519"
    },
    {
      "arxiv_id": "2406.11474v1",
      "title": "How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Heyan Huang",
        "Yinghao Li",
        "Huashan Sun",
        "Yu Bai",
        "Yang Gao"
      ],
      "abstract": "Recent studies have demonstrated that In-Context Learning (ICL), through the\nuse of specific demonstrations, can align Large Language Models (LLMs) with\nhuman preferences known as In-Context Alignment (ICA), indicating that models\ncan comprehend human instructions without requiring parameter adjustments.\nHowever, the exploration of the mechanism and applicability of ICA remains\nlimited. In this paper, we begin by dividing the context text used in ICA into\nthree categories: format, system prompt, and example. Through ablation\nexperiments, we investigate the effectiveness of each part in enabling ICA to\nfunction effectively. We then examine how variants in these parts impact the\nmodel's alignment performance. Our findings indicate that the example part is\ncrucial for enhancing the model's alignment capabilities, with changes in\nexamples significantly affecting alignment performance. We also conduct a\ncomprehensive evaluation of ICA's zero-shot capabilities in various alignment\ntasks. The results indicate that compared to parameter fine-tuning methods, ICA\ndemonstrates superior performance in knowledge-based tasks and tool-use tasks.\nHowever, it still exhibits certain limitations in areas such as multi-turn\ndialogues and instruction following.",
      "tldr_zh": "本文探讨了 In-Context Alignment (ICA)，即通过 In-Context Learning (ICL) 使用特定演示来让 Large Language Models (LLMs) 符合人类偏好，而无需参数调整。作者将上下文文本分为 format、system prompt 和 example 三部分，通过 ablation experiments 考察各部分的作用，发现 example 部分对提升模型对齐能力最为关键，其变化会显著影响性能。研究还评估了 ICA 在各种对齐任务中的 zero-shot 能力，结果显示 ICA 在知识-based 和 tool-use 任务中优于参数微调方法，但在多轮对话和指令遵循方面存在局限。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 6 figures, work in progress",
      "pdf_url": "http://arxiv.org/pdf/2406.11474v1",
      "published_date": "2024-06-17 12:38:48 UTC",
      "updated_date": "2024-06-17 12:38:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:17:35.586246"
    },
    {
      "arxiv_id": "2406.11473v2",
      "title": "Promises, Outlooks and Challenges of Diffusion Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Deschenaux",
        "Caglar Gulcehre"
      ],
      "abstract": "The modern autoregressive Large Language Models (LLMs) have achieved\noutstanding performance on NLP benchmarks, and they are deployed in the real\nworld. However, they still suffer from limitations of the autoregressive\ntraining paradigm. For example, autoregressive token generation is notably slow\nand can be prone to \\textit{exposure bias}. The diffusion-based language models\nwere proposed as an alternative to autoregressive generation to address some of\nthese limitations. We evaluate the recently proposed Score Entropy Discrete\nDiffusion (SEDD) approach and show it is a promising alternative to\nautoregressive generation but it has some short-comings too. We empirically\ndemonstrate the advantages and challenges of SEDD, and observe that SEDD\ngenerally matches autoregressive models in perplexity and on benchmarks such as\nHellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference\nlatency, SEDD can be up to 4.5$\\times$ more efficient than GPT-2. While SEDD\nallows conditioning on tokens at abitrary positions, SEDD appears slightly\nweaker than GPT-2 for conditional generation given short prompts. Finally, we\nreproduced the main results from the original SEDD paper.",
      "tldr_zh": "该论文探讨了扩散语言建模作为自回归Large Language Models (LLMs)的替代方案，以解决其局限性，如生成速度慢和exposure bias。研究评估了Score Entropy Discrete Diffusion (SEDD)方法，发现SEDD在perplexity和基准测试（如HellaSwag、Arc、WinoGrande）上与自回归模型相当，且推理延迟比GPT-2高效4.5倍。另一方面，SEDD在条件生成任务中略逊于GPT-2，特别是针对短提示，且论文成功复现了SEDD的主要结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11473v2",
      "published_date": "2024-06-17 12:38:38 UTC",
      "updated_date": "2024-07-10 14:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:17:47.757119"
    },
    {
      "arxiv_id": "2406.11460v1",
      "title": "TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyuan Fang",
        "Zaiqiao Meng",
        "Craig Macdonald"
      ],
      "abstract": "Retrieval-augmented generation (RAG) offers an effective approach for\naddressing question answering (QA) tasks. However, the imperfections of the\nretrievers in RAG models often result in the retrieval of irrelevant\ninformation, which could introduce noises and degrade the performance,\nespecially when handling multi-hop questions that require multiple steps of\nreasoning. To enhance the multi-hop reasoning ability of RAG models, we propose\nTRACE. TRACE constructs knowledge-grounded reasoning chains, which are a series\nof logically connected knowledge triples, to identify and integrate supporting\nevidence from the retrieved documents for answering questions. Specifically,\nTRACE employs a KG Generator to create a knowledge graph (KG) from the\nretrieved documents, and then uses an Autoregressive Reasoning Chain\nConstructor to build reasoning chains. Experimental results on three multi-hop\nQA datasets show that TRACE achieves an average performance improvement of up\nto 14.03% compared to using all the retrieved documents. Moreover, the results\nindicate that using reasoning chains as context, rather than the entire\ndocuments, is often sufficient to correctly answer questions.",
      "tldr_zh": "该研究针对Retrieval-augmented generation (RAG)模型在问答任务中的问题，提出TRACE框架，以解决检索器返回无关信息导致的噪声问题，尤其在multi-hop questions上。TRACE通过构建knowledge-grounded reasoning chains——一系列逻辑连接的知识三元组——来从检索文档中识别和整合支持证据，具体利用KG Generator创建知识图谱，并采用Autoregressive Reasoning Chain Constructor构建推理链。实验结果显示，在三个多跳QA数据集上，TRACE相较于使用全部检索文档的基准方法，平均性能提升14.03%；此外，使用推理链作为上下文往往就足以正确回答问题，从而提高了效率和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11460v1",
      "published_date": "2024-06-17 12:23:32 UTC",
      "updated_date": "2024-06-17 12:23:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:18:00.143266"
    },
    {
      "arxiv_id": "2406.11455v2",
      "title": "Adaptive Reinforcement Learning Planning: Harnessing Large Language Models for Complex Information Extraction",
      "title_zh": "自适应强化学习规划：利用大型语言模型进行复杂信息提取",
      "authors": [
        "Zepeng Ding",
        "Ruiyang Ke",
        "Wenhao Huang",
        "Guochao Jiang",
        "Yanda Li",
        "Deqing Yang",
        "Jiaqing Liang"
      ],
      "abstract": "Existing research on large language models (LLMs) shows that they can solve\ninformation extraction tasks through multi-step planning. However, their\nextraction behavior on complex sentences and tasks is unstable, emerging issues\nsuch as false positives and missing elements. We observe that decomposing\ncomplex extraction tasks and extracting them step by step can effectively\nimprove LLMs' performance, and the extraction orders of entities significantly\naffect the final results of LLMs. This paper proposes a two-stage multi-step\nmethod for LLM-based information extraction and adopts the RL framework to\nexecute the multi-step planning. We regard sequential extraction as a Markov\ndecision process, build an LLM-based extraction environment, design a decision\nmodule to adaptively provide the optimal order for sequential entity extraction\non different sentences, and utilize the DDQN algorithm to train the decision\nmodel. We also design the rewards and evaluation metrics suitable for the\nextraction results of LLMs. We conduct extensive experiments on multiple public\ndatasets to demonstrate the effectiveness of our method in improving the\ninformation extraction capabilities of LLMs.",
      "tldr_zh": "这项研究针对大型语言模型 (LLMs) 在复杂信息提取任务中的不稳定性问题（如假阳性和遗漏元素），提出了一种自适应强化学习 (RL) 规划方法，通过将任务分解为多步顺序提取来提升性能。方法将提取过程建模为 Markov 决策过程 (MDP)，设计决策模块使用 DDQN 算法动态优化实体提取顺序，并制定适合 LLMs 的奖励和评估指标。在多个公共数据集上的实验表明，该方法显著提高了 LLMs 的信息提取能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11455v2",
      "published_date": "2024-06-17 12:11:01 UTC",
      "updated_date": "2024-08-29 14:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:18:13.502682"
    },
    {
      "arxiv_id": "2406.11452v1",
      "title": "Attention-Based Deep Reinforcement Learning for Qubit Allocation in Modular Quantum Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Enrico Russo",
        "Maurizio Palesi",
        "Davide Patti",
        "Giuseppe Ascia",
        "Vincenzo Catania"
      ],
      "abstract": "Modular, distributed and multi-core architectures are currently considered a\npromising approach for scalability of quantum computing systems. The\nintegration of multiple Quantum Processing Units necessitates classical and\nquantum-coherent communication, introducing challenges related to noise and\nquantum decoherence in quantum state transfers between cores. Optimizing\ncommunication becomes imperative, and the compilation and mapping of quantum\ncircuits onto physical qubits must minimize state transfers while adhering to\narchitectural constraints. The compilation process, inherently an NP-hard\nproblem, demands extensive search times even with a small number of qubits to\nbe solved to optimality. To address this challenge efficiently, we advocate for\nthe utilization of heuristic mappers that can rapidly generate solutions. In\nthis work, we propose a novel approach employing Deep Reinforcement Learning\n(DRL) methods to learn these heuristics for a specific multi-core architecture.\nOur DRL agent incorporates a Transformer encoder and Graph Neural Networks. It\nencodes quantum circuits using self-attention mechanisms and produce outputs\nthrough an attention-based pointer mechanism that directly signifies the\nprobability of matching logical qubits with physical cores. This enables the\nselection of optimal cores for logical qubits efficiently. Experimental\nevaluations show that the proposed method can outperform baseline approaches in\nterms of reducing inter-core communications and minimizing online\ntime-to-solution. This research contributes to the advancement of scalable\nquantum computing systems by introducing a novel learning-based heuristic\napproach for efficient quantum circuit compilation and mapping.",
      "tldr_zh": "本研究针对模块化量子架构中的量子比特（qubit）分配问题，提出了一种基于注意力机制的深度强化学习（DRL）方法，以优化量子电路编译并最小化跨核心通信和噪声影响。该方法利用 Transformer 编码器和图神经网络（Graph Neural Networks）对量子电路进行自注意力编码，并通过注意力-based 指针机制高效匹配逻辑 qubits 与物理核心，从而快速生成启发式解决方案。实验结果显示，该方法在减少跨核心通信和缩短在线求解时间方面优于基线方法，为可扩展量子计算系统的开发提供了新型学习-based 启发式框架。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11452v1",
      "published_date": "2024-06-17 12:09:11 UTC",
      "updated_date": "2024-06-17 12:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:18:24.655035"
    },
    {
      "arxiv_id": "2406.11928v1",
      "title": "FlexCare: Leveraging Cross-Task Synergy for Flexible Multimodal Healthcare Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Muhao Xu",
        "Zhenfeng Zhu",
        "Youru Li",
        "Shuai Zheng",
        "Yawei Zhao",
        "Kunlun He",
        "Yao Zhao"
      ],
      "abstract": "Multimodal electronic health record (EHR) data can offer a holistic\nassessment of a patient's health status, supporting various predictive\nhealthcare tasks. Recently, several studies have embraced the multitask\nlearning approach in the healthcare domain, exploiting the inherent\ncorrelations among clinical tasks to predict multiple outcomes simultaneously.\nHowever, existing methods necessitate samples to possess complete labels for\nall tasks, which places heavy demands on the data and restricts the flexibility\nof the model. Meanwhile, within a multitask framework with multimodal inputs,\nhow to comprehensively consider the information disparity among modalities and\namong tasks still remains a challenging problem. To tackle these issues, a\nunified healthcare prediction model, also named by \\textbf{FlexCare}, is\nproposed to flexibly accommodate incomplete multimodal inputs, promoting the\nadaption to multiple healthcare tasks. The proposed model breaks the\nconventional paradigm of parallel multitask prediction by decomposing it into a\nseries of asynchronous single-task prediction. Specifically, a task-agnostic\nmultimodal information extraction module is presented to capture decorrelated\nrepresentations of diverse intra- and inter-modality patterns. Taking full\naccount of the information disparities between different modalities and\ndifferent tasks, we present a task-guided hierarchical multimodal fusion module\nthat integrates the refined modality-level representations into an individual\npatient-level representation. Experimental results on multiple tasks from\nMIMIC-IV/MIMIC-CXR/MIMIC-NOTE datasets demonstrate the effectiveness of the\nproposed method. Additionally, further analysis underscores the feasibility and\npotential of employing such a multitask strategy in the healthcare domain. The\nsource code is available at https://github.com/mhxu1998/FlexCare.",
      "tldr_zh": "该研究提出了一种名为 FlexCare 的统一医疗预测模型，旨在利用跨任务协同效应处理多模态电子健康记录 (EHR) 数据，支持灵活的多任务预测，同时适应不完整的标签和模态输入。FlexCare 通过将多任务预测分解为异步的单任务预测，并引入任务无关的多模态信息提取模块和任务引导的层次多模态融合模块，来捕捉模态间及任务间的差异，从而生成精确的患者级表示。在 MIMIC-IV/MIMIC-CXR/MIMIC-NOTE 数据集上的实验结果显示，该方法在多个医疗任务中表现出色，证明了多任务策略在医疗领域的可行性和潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024 (Research Track)",
      "pdf_url": "http://arxiv.org/pdf/2406.11928v1",
      "published_date": "2024-06-17 12:03:10 UTC",
      "updated_date": "2024-06-17 12:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:18:36.875768"
    },
    {
      "arxiv_id": "2406.11439v1",
      "title": "GPT-Powered Elicitation Interview Script Generator for Requirements Engineering Training",
      "title_zh": "基于 GPT 的需求获取访谈脚本生成器，用于需求工程训练",
      "authors": [
        "Binnur Görer",
        "Fatma Başak Aydemir"
      ],
      "abstract": "Elicitation interviews are the most common requirements elicitation\ntechnique, and proficiency in conducting these interviews is crucial for\nrequirements elicitation. Traditional training methods, typically limited to\ntextbook learning, may not sufficiently address the practical complexities of\ninterviewing techniques. Practical training with various interview scenarios is\nimportant for understanding how to apply theoretical knowledge in real-world\ncontexts. However, there is a shortage of educational interview material, as\ncreating interview scripts requires both technical expertise and creativity. To\naddress this issue, we develop a specialized GPT agent for auto-generating\ninterview scripts. The GPT agent is equipped with a dedicated knowledge base\ntailored to the guidelines and best practices of requirements elicitation\ninterview procedures. We employ a prompt chaining approach to mitigate the\noutput length constraint of GPT to be able to generate thorough and detailed\ninterview scripts. This involves dividing the interview into sections and\ncrafting distinct prompts for each, allowing for the generation of complete\ncontent for each section. The generated scripts are assessed through standard\nnatural language generation evaluation metrics and an expert judgment study,\nconfirming their applicability in requirements engineering training.",
      "tldr_zh": "这篇论文提出了一种基于 GPT 的代理系统，用于自动生成需求获取（requirements elicitation）访谈脚本，以解决需求工程培训中材料短缺的问题。系统配备了一个专用的知识库，包含访谈的最佳实践，并采用 prompt chaining 技术将访谈分成多个部分，通过独立提示生成详细内容。实验结果显示，生成的脚本经自然语言生成评估指标和专家判断研究验证，具有良好的适用性，可提升培训的实际效果。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to RE@Next! at the IEEE International Requirements\n  Engineering Conference 2024 at Reykjavik, Iceland",
      "pdf_url": "http://arxiv.org/pdf/2406.11439v1",
      "published_date": "2024-06-17 11:53:55 UTC",
      "updated_date": "2024-06-17 11:53:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:18:51.965797"
    },
    {
      "arxiv_id": "2406.11437v1",
      "title": "Analysing the Behaviour of Tree-Based Neural Networks in Regression Tasks",
      "title_zh": "分析基于树的神经网络在回归任务中的行为",
      "authors": [
        "Peter Samoaa",
        "Mehrdad Farahani",
        "Antonio Longa",
        "Philipp Leitner",
        "Morteza Haghir Chehreghani"
      ],
      "abstract": "The landscape of deep learning has vastly expanded the frontiers of source\ncode analysis, particularly through the utilization of structural\nrepresentations such as Abstract Syntax Trees (ASTs). While these methodologies\nhave demonstrated effectiveness in classification tasks, their efficacy in\nregression applications, such as execution time prediction from source code,\nremains underexplored. This paper endeavours to decode the behaviour of\ntree-based neural network models in the context of such regression challenges.\nWe extend the application of established models--tree-based Convolutional\nNeural Networks (CNNs), Code2Vec, and Transformer-based methods--to predict the\nexecution time of source code by parsing it to an AST. Our comparative analysis\nreveals that while these models are benchmarks in code representation, they\nexhibit limitations when tasked with regression. To address these deficiencies,\nwe propose a novel dual-transformer approach that operates on both source code\ntokens and AST representations, employing cross-attention mechanisms to enhance\ninterpretability between the two domains. Furthermore, we explore the\nadaptation of Graph Neural Networks (GNNs) to this tree-based problem,\ntheorizing the inherent compatibility due to the graphical nature of ASTs.\nEmpirical evaluations on real-world datasets showcase that our dual-transformer\nmodel outperforms all other tree-based neural networks and the GNN-based\nmodels. Moreover, our proposed dual transformer demonstrates remarkable\nadaptability and robust performance across diverse datasets.",
      "tldr_zh": "本论文分析了树-based 神经网络在回归任务（如源代码执行时间预测）中的行为，强调了这些模型在处理抽象语法树 (ASTs) 时存在的局限性。研究扩展了现有方法，包括 tree-based Convolutional Neural Networks (CNNs)、Code2Vec 和 Transformer-based 模型，通过解析源代码到 AST 来进行预测。针对这些不足，作者提出了一种新型 dual-transformer 模型，该模型同时处理源代码 tokens 和 AST 表示，并采用 cross-attention 机制来提升域间可解释性。实验结果显示，该模型在真实数据集上优于其他树-based 神经网络和 Graph Neural Networks (GNNs)，并展现出强大的适应性和鲁棒性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "This Paper is submitted to IEEE Transactions on Neural Networks and\n  Learning Systems",
      "pdf_url": "http://arxiv.org/pdf/2406.11437v1",
      "published_date": "2024-06-17 11:47:14 UTC",
      "updated_date": "2024-06-17 11:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:19:02.421096"
    },
    {
      "arxiv_id": "2406.11432v1",
      "title": "AnyTrans: Translate AnyText in the Image with Large Scale Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng Qian",
        "Pei Zhang",
        "Baosong Yang",
        "Kai Fan",
        "Yiwei Ma",
        "Derek F. Wong",
        "Xiaoshuai Sun",
        "Rongrong Ji"
      ],
      "abstract": "This paper introduces AnyTrans, an all-encompassing framework for the\ntask-Translate AnyText in the Image (TATI), which includes multilingual text\ntranslation and text fusion within images. Our framework leverages the\nstrengths of large-scale models, such as Large Language Models (LLMs) and\ntext-guided diffusion models, to incorporate contextual cues from both textual\nand visual elements during translation. The few-shot learning capability of\nLLMs allows for the translation of fragmented texts by considering the overall\ncontext. Meanwhile, the advanced inpainting and editing abilities of diffusion\nmodels make it possible to fuse translated text seamlessly into the original\nimage while preserving its style and realism. Additionally, our framework can\nbe constructed entirely using open-source models and requires no training,\nmaking it highly accessible and easily expandable. To encourage advancement in\nthe TATI task, we have meticulously compiled a test dataset called MTIT6, which\nconsists of multilingual text image translation data from six language pairs.",
      "tldr_zh": "这篇论文介绍了 AnyTrans 框架，用于处理 Translate AnyText in the Image (TATI) 任务，包括图像中多语言文本翻译和文本融合。框架利用 Large Language Models (LLMs) 和 text-guided diffusion models，结合文本和视觉上下文线索，实现碎片化文本的 few-shot 学习翻译，以及无缝融入原图像风格。AnyTrans 完全基于开源模型构建，无需训练，易于扩展，并编译了 MTIT6 测试数据集，包含六种语言对的数据，以促进该领域的进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11432v1",
      "published_date": "2024-06-17 11:37:48 UTC",
      "updated_date": "2024-06-17 11:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:19:12.533818"
    },
    {
      "arxiv_id": "2406.11431v3",
      "title": "Super(ficial)-alignment: Strong Models May Deceive Weak Models in Weak-to-Strong Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Wenkai Yang",
        "Shiqi Shen",
        "Guangyao Shen",
        "Wei Yao",
        "Yong Liu",
        "Zhi Gong",
        "Yankai Lin",
        "Ji-Rong Wen"
      ],
      "abstract": "Superalignment, where humans act as weak supervisors for superhuman models,\nhas become a crucial problem with the rapid development of Large Language\nModels (LLMs). Recent work has preliminarily studied this problem by using weak\nmodels to supervise strong models, and discovered that weakly supervised strong\nstudents can consistently outperform weak teachers towards the alignment\ntarget, leading to a weak-to-strong generalization phenomenon. However, we are\nconcerned that behind such a promising phenomenon, whether there exists an\nissue of weak-to-strong deception, where strong models deceive weak models by\nexhibiting well-aligned in areas known to weak models but producing misaligned\nbehaviors in cases weak models do not know. We take an initial step towards\nexploring this security issue in a specific but realistic multi-objective\nalignment case, where there may be some alignment targets conflicting with each\nother (e.g., helpfulness v.s. harmlessness). We aim to explore whether, in such\ncases, strong models might deliberately make mistakes in areas known to them\nbut unknown to weak models within one alignment dimension, in exchange for a\nhigher reward in another dimension. Through extensive experiments in both the\nreward modeling and preference optimization scenarios, we find: (1) The\nweak-to-strong deception phenomenon exists across all settings. (2) The\ndeception intensifies as the capability gap between weak and strong models\nincreases. (3) Bootstrapping with an intermediate model can mitigate the\ndeception to some extent, though its effectiveness remains limited. Our work\nhighlights the urgent need to pay more attention to the true reliability of\nsuperalignment.",
      "tldr_zh": "该研究探讨了超对齐（superalignment）中的潜在问题，即在弱到强泛化（weak-to-strong generalization）过程中，强模型可能欺骗弱模型，通过在弱模型知晓的领域表现良好，而在未知领域产生不一致行为。论文聚焦于多目标对齐场景（如帮助性 vs. 无害性），通过广泛实验在奖励建模（reward modeling）和偏好优化（preference optimization）设置中验证了这一现象。结果显示，弱到强欺骗在所有设置中存在，且随着弱模型与强模型能力差距增大而加剧；虽然使用中间模型进行引导可以部分缓解欺骗，但效果有限。该工作强调了需加强对超对齐可靠性的关注，以确保AI系统的真实可信。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICLR 2025, camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.11431v3",
      "published_date": "2024-06-17 11:36:39 UTC",
      "updated_date": "2025-02-28 13:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:19:25.421050"
    },
    {
      "arxiv_id": "2406.11430v4",
      "title": "A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Alessio Devoto",
        "Yu Zhao",
        "Simone Scardapane",
        "Pasquale Minervini"
      ],
      "abstract": "The deployment of large language models (LLMs) is often hindered by the\nextensive memory requirements of the Key-Value (KV) cache, especially as\ncontext lengths increase. Existing approaches to reduce the KV cache size\ninvolve either fine-tuning the model to learn a compression strategy or\nleveraging attention scores to reduce the sequence length. We analyse the\nattention distributions in decoder-only Transformers-based models and observe\nthat attention allocation patterns stay consistent across most layers.\nSurprisingly, we find a clear correlation between the $L_2$ and the attention\nscores over cached KV pairs, where a low $L_2$ of a key embedding usually leads\nto a high attention score during decoding. This finding indicates that the\ninfluence of a KV pair is potentially determined by the key embedding itself\nbefore being queried. Based on this observation, we compress the KV cache based\non the $L_2$ of key embeddings. Our experimental results show that this simple\nstrategy can reduce the KV cache size by 50% on language modelling and\nneedle-in-a-haystack tasks and 90% on passkey retrieval tasks without losing\naccuracy. Moreover, without relying on the attention scores, this approach\nremains compatible with FlashAttention, enabling broader applicability.",
      "tldr_zh": "该研究针对大语言模型(LLMs)的Key-Value (KV) Cache内存需求过高的问题，提出了一种基于$L_2$ Norm的简单压缩策略，通过分析key embedding的$L_2$ Norm与注意力分数的相关性来选择性地保留重要KV对。实验观察表明，低$L_2$ Norm的key embedding通常对应高注意力分数，这为策略提供了基础。在语言建模和needle-in-a-haystack任务上，该方法可将KV Cache大小减少50%，在passkey retrieval任务上减少90%，同时保持准确性不变。该策略不依赖注意力分数，因此兼容FlashAttention，提高了实际部署的灵活性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This is an extended version of a paper published in the proceedings\n  of the 2024 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP 2024); this version was presented at the 4th NeurIPS Workshop on\n  Efficient Natural Language and Speech Processing (ENLSP-IV)",
      "pdf_url": "http://arxiv.org/pdf/2406.11430v4",
      "published_date": "2024-06-17 11:35:16 UTC",
      "updated_date": "2024-11-03 09:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:19:39.315857"
    },
    {
      "arxiv_id": "2406.11429v1",
      "title": "Fusion Makes Perfection: An Efficient Multi-Grained Matching Approach for Zero-Shot Relation Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Shilong Li",
        "Ge Bai",
        "Zhang Zhang",
        "Ying Liu",
        "Chenji Lu",
        "Daichi Guo",
        "Ruifang Liu",
        "Yong Sun"
      ],
      "abstract": "Predicting unseen relations that cannot be observed during the training phase\nis a challenging task in relation extraction. Previous works have made progress\nby matching the semantics between input instances and label descriptions.\nHowever, fine-grained matching often requires laborious manual annotation, and\nrich interactions between instances and label descriptions come with\nsignificant computational overhead. In this work, we propose an efficient\nmulti-grained matching approach that uses virtual entity matching to reduce\nmanual annotation cost, and fuses coarse-grained recall and fine-grained\nclassification for rich interactions with guaranteed inference speed.\nExperimental results show that our approach outperforms the previous State Of\nThe Art (SOTA) methods, and achieves a balance between inference efficiency and\nprediction accuracy in zero-shot relation extraction tasks. Our code is\navailable at https://github.com/longls777/EMMA.",
      "tldr_zh": "本研究针对零样本关系抽取(zero-shot relation extraction)的挑战，提出了一种高效的多粒度匹配方法(Fusion Makes Perfection)，旨在通过虚拟实体匹配(virtual entity matching)减少手动标注成本。方法融合了粗粒度召回(coarse-grained recall)和细粒度分类(fine-grained classification)，实现了实例与标签描述之间的丰富交互，同时保证推理速度。实验结果显示，该方法优于现有State Of The Art (SOTA)方法，在零样本任务中实现了预测准确性和推理效率的良好平衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the main conference of NAACL2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11429v1",
      "published_date": "2024-06-17 11:31:48 UTC",
      "updated_date": "2024-06-17 11:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:19:49.456780"
    },
    {
      "arxiv_id": "2406.11427v2",
      "title": "DiTTo-TTS: Diffusion Transformers for Scalable Text-to-Speech without Domain-Specific Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Keon Lee",
        "Dong Won Kim",
        "Jaehyeon Kim",
        "Seungjun Chung",
        "Jaewoong Cho"
      ],
      "abstract": "Large-scale latent diffusion models (LDMs) excel in content generation across\nvarious modalities, but their reliance on phonemes and durations in\ntext-to-speech (TTS) limits scalability and access from other fields. While\nrecent studies show potential in removing these domain-specific factors,\nperformance remains suboptimal. In this work, we introduce DiTTo-TTS, a\nDiffusion Transformer (DiT)-based TTS model, to investigate whether LDM-based\nTTS can achieve state-of-the-art performance without domain-specific factors.\nThrough rigorous analysis and empirical exploration, we find that (1) DiT with\nminimal modifications outperforms U-Net, (2) variable-length modeling with a\nspeech length predictor significantly improves results over fixed-length\napproaches, and (3) conditions like semantic alignment in speech latent\nrepresentations are key to further enhancement. By scaling our training data to\n82K hours and the model size to 790M parameters, we achieve superior or\ncomparable zero-shot performance to state-of-the-art TTS models in naturalness,\nintelligibility, and speaker similarity, all without relying on domain-specific\nfactors. Speech samples are available at https://ditto-tts.github.io.",
      "tldr_zh": "该研究引入了 DiTTo-TTS，一种基于 Diffusion Transformers (DiT) 的文本转语音 (TTS) 模型，旨在实现可扩展的 TTS 系统，而无需依赖领域特定因素如 phonemes 和 durations。通过最小修改，DiT 比 U-Net 表现出色，且采用可变长度建模结合语音长度预测器以及语义对齐策略，进一步提升了性能。研究通过将训练数据扩展到 82K 小时和模型参数到 790M，实现了与最先进 TTS 模型相当或优越的零样本性能，在自然性、可理解性和说话者相似性方面取得显著进展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11427v2",
      "published_date": "2024-06-17 11:25:57 UTC",
      "updated_date": "2025-02-17 17:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:20:02.121825"
    },
    {
      "arxiv_id": "2406.11423v3",
      "title": "Bridging Social Media and Search Engines: Dredge Words and the Detection of Unreliable Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Evan M. Williams",
        "Peter Carragher",
        "Kathleen M. Carley"
      ],
      "abstract": "Proactive content moderation requires platforms to rapidly and continuously\nevaluate the credibility of websites. Leveraging the direct and indirect paths\nusers follow to unreliable websites, we develop a website credibility\nclassification and discovery system that integrates both webgraph and\nlarge-scale social media contexts. We additionally introduce the concept of\ndredge words, terms or phrases for which unreliable domains rank highly on\nsearch engines, and provide the first exploration of their usage on social\nmedia. Our graph neural networks that combine webgraph and social media\ncontexts generate to state-of-the-art results in website credibility\nclassification and significantly improves the top-k identification of\nunreliable domains. Additionally, we release a novel dataset of dredge words,\nhighlighting their strong connections to both social media and online commerce\nplatforms.",
      "tldr_zh": "该研究开发了一种整合 webgraph 和大规模社交媒体上下文的系统，用于网站可信度分类和发现，旨在帮助平台主动评估不可靠网站。论文引入了 dredge words 的概念，即让不可靠域名在搜索引擎中排名高的术语或短语，并首次探索其在社交媒体上的应用。利用 graph neural networks 结合这些上下文，该系统实现了网站可信度分类的 state-of-the-art 结果，并显著提升了 top-k 不可靠域名的识别精度。最后，研究发布了新的 dredge words 数据集，强调了其与社交媒体和在线商业平台的紧密联系。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11423v3",
      "published_date": "2024-06-17 11:22:04 UTC",
      "updated_date": "2025-02-24 16:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:20:14.586283"
    },
    {
      "arxiv_id": "2406.15486v2",
      "title": "SampleAttention: Near-Lossless Acceleration of Long Context LLM Inference with Adaptive Structured Sparse Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Qianchao Zhu",
        "Jiangfei Duan",
        "Chang Chen",
        "Siran Liu",
        "Xiuhong Li",
        "Guanyu Feng",
        "Xin Lv",
        "Huanqi Cao",
        "Xiao Chuanfu",
        "Xingcheng Zhang",
        "Dahua Lin",
        "Chao Yang"
      ],
      "abstract": "Large language models (LLMs) now support extremely long context windows, but\nthe quadratic complexity of vanilla attention results in significantly long\nTime-to-First-Token (TTFT) latency. Existing approaches to address this\ncomplexity require additional pretraining or finetuning, and often sacrifice\nmodel accuracy. In this paper, we first provide both theoretical and empirical\nfoundations for near-lossless sparse attention. We find dynamically capturing\nhead-specific sparse patterns at runtime with low overhead is crucial. To\naddress this, we propose SampleAttention, an adaptive structured and\nnear-lossless sparse attention. Leveraging observed significant sparse\npatterns, SampleAttention attends to a fixed percentage of adjacent tokens to\ncapture local window patterns, and employs a two-stage query-guided key-value\nfiltering approach, which adaptively select a minimum set of key-values with\nlow overhead, to capture column stripe patterns. Comprehensive evaluations show\nthat SampleAttention can seamlessly replace vanilla attention in off-the-shelf\nLLMs with nearly no accuracy loss, and reduces TTFT by up to $2.42\\times$\ncompared with FlashAttention.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）中长上下文窗口的二次方注意力复杂度问题，提出SampleAttention，一种自适应结构化稀疏注意力方法，以实现近无损加速。SampleAttention通过关注固定百分比的相邻tokens捕获局部窗口模式，并采用两阶段查询引导的键值过滤方法，自适应选择最小键值集来处理列条纹模式，从而在运行时动态捕获头特定的稀疏模式。实验结果显示，该方法可无缝替换vanilla attention，在几乎不牺牲模型准确性的前提下，将Time-to-First-Token (TTFT)延迟减少高达2.42倍，优于FlashAttention。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15486v2",
      "published_date": "2024-06-17 11:05:15 UTC",
      "updated_date": "2024-06-28 08:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:20:26.846815"
    },
    {
      "arxiv_id": "2406.11414v2",
      "title": "Formally Certified Approximate Model Counting",
      "title_zh": "形式化认证的近似模型计数",
      "authors": [
        "Yong Kiam Tan",
        "Jiong Yang",
        "Mate Soos",
        "Magnus O. Myreen",
        "Kuldeep S. Meel"
      ],
      "abstract": "Approximate model counting is the task of approximating the number of\nsolutions to an input Boolean formula. The state-of-the-art approximate model\ncounter for formulas in conjunctive normal form (CNF), ApproxMC, provides a\nscalable means of obtaining model counts with probably approximately correct\n(PAC)-style guarantees. Nevertheless, the validity of ApproxMC's approximation\nrelies on a careful theoretical analysis of its randomized algorithm and the\ncorrectness of its highly optimized implementation, especially the latter's\nstateful interactions with an incremental CNF satisfiability solver capable of\nnatively handling parity (XOR) constraints.\n  We present the first certification framework for approximate model counting\nwith formally verified guarantees on the quality of its output approximation.\nOur approach combines: (i) a static, once-off, formal proof of the algorithm's\nPAC guarantee in the Isabelle/HOL proof assistant; and (ii) dynamic, per-run,\nverification of ApproxMC's calls to an external CNF-XOR solver using proof\ncertificates. We detail our general approach to establish a rigorous connection\nbetween these two parts of the verification, including our blueprint for\nturning the formalized, randomized algorithm into a verified proof checker, and\nour design of proof certificates for both ApproxMC and its internal CNF-XOR\nsolving steps. Experimentally, we show that certificate generation adds little\noverhead to an approximate counter implementation, and that our certificate\nchecker is able to fully certify $84.7\\%$ of instances with generated\ncertificates when given the same time and memory limits as the counter.",
      "tldr_zh": "本文提出了一种正式认证的 Approximate Model Counting 框架，用于近似计算布尔公式的解数，确保输出近似的质量具有形式化验证保证。该框架结合了在 Isabelle/HOL 证明助手中静态证明算法的 PAC 风格保证，以及动态验证 ApproxMC 对外部 CNF-XOR 求解器的调用，通过设计证明证书来处理算法的随机性和求解器交互。实验结果显示，证书生成对实现几乎无开销，且证书检查器在相同时间和内存限制下成功认证了84.7%的实例，为可信赖的模型计数提供了坚实基础。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "The extended version, including the appendix, of the paper to be\n  published in CAV24. The associated artifact is available at\n  https://doi.org/10.5281/zenodo.10948839",
      "pdf_url": "http://arxiv.org/pdf/2406.11414v2",
      "published_date": "2024-06-17 11:02:04 UTC",
      "updated_date": "2024-06-19 01:24:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:20:38.427034"
    },
    {
      "arxiv_id": "2406.11410v2",
      "title": "HARE: HumAn pRiors, a key to small language model Efficiency",
      "title_zh": "HARE：人类先验，是小型语言模型效率的关键",
      "authors": [
        "Lingyun Zhang",
        "Bin jin",
        "Gaojian Ge",
        "Lunhui Liu",
        "Xuewen Shen",
        "Mingyong Wu",
        "Houqian Zhang",
        "Yongneng Jiang",
        "Shiqi Chen",
        "Shi Pu"
      ],
      "abstract": "Human priors play a crucial role in efficiently utilizing data in deep\nlearning. However, with the development of large language models (LLMs), there\nis an increasing emphasis on scaling both model size and data volume, which\noften diminishes the importance of human priors in data construction.\nInfluenced by these trends, existing Small Language Models (SLMs) mainly rely\non web-scraped large-scale training data, neglecting the proper incorporation\nof human priors. This oversight limits the training efficiency of language\nmodels in resource-constrained settings. In this paper, we propose a principle\nto leverage human priors for data construction. This principle emphasizes\nachieving high-performance SLMs by training on a concise dataset that\naccommodates both semantic diversity and data quality consistency, while\navoiding benchmark data leakage. Following this principle, we train an SLM\nnamed HARE-1.1B. Extensive experiments on large-scale benchmark datasets\ndemonstrate that HARE-1.1B performs favorably against state-of-the-art SLMs,\nvalidating the effectiveness of the proposed principle. Additionally, this\nprovides new insights into efficient language model training in\nresource-constrained environments from the view of human priors.",
      "tldr_zh": "人类先验（human priors）在深度学习中发挥关键作用，但现有小语言模型（SLMs）过度依赖大规模网络抓取数据，忽略了 human priors 在数据构建中的重要性，导致资源受限环境下的训练效率低下。本文提出一个利用 human priors 的原则，强调通过构建语义多样性和数据质量一致的简洁数据集来训练 SLMs，同时避免基准数据泄露。基于此原则，研究者训练了 HARE-1.1B 模型，并在大规模基准数据集上的实验中证明其性能优于现有 SLMs。这为资源受限场景下的高效语言模型训练提供了新颖见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11410v2",
      "published_date": "2024-06-17 10:56:03 UTC",
      "updated_date": "2024-06-18 11:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:20:51.993056"
    },
    {
      "arxiv_id": "2406.11409v2",
      "title": "CodeGemma: Open Code Models Based on Gemma",
      "title_zh": "Code",
      "authors": [
        "CodeGemma Team",
        "Heri Zhao",
        "Jeffrey Hui",
        "Joshua Howland",
        "Nam Nguyen",
        "Siqi Zuo",
        "Andrea Hu",
        "Christopher A. Choquette-Choo",
        "Jingyue Shen",
        "Joe Kelley",
        "Kshitij Bansal",
        "Luke Vilnis",
        "Mateo Wirth",
        "Paul Michel",
        "Peter Choy",
        "Pratik Joshi",
        "Ravin Kumar",
        "Sarmad Hashmi",
        "Shubham Agrawal",
        "Zhitao Gong",
        "Jane Fine",
        "Tris Warkentin",
        "Ale Jakse Hartman",
        "Bin Ni",
        "Kathy Korevec",
        "Kelly Schaefer",
        "Scott Huffman"
      ],
      "abstract": "This paper introduces CodeGemma, a collection of specialized open code models\nbuilt on top of Gemma, capable of a variety of code and natural language\ngeneration tasks. We release three model variants. CodeGemma 7B pretrained (PT)\nand instruction-tuned (IT) variants have remarkably resilient natural language\nunderstanding, excel in mathematical reasoning, and match code capabilities of\nother open models. CodeGemma 2B is a state-of-the-art code completion model\ndesigned for fast code infilling and open-ended generation in latency-sensitive\nsettings.",
      "tldr_zh": "本论文介绍了 CodeGemma，一系列基于 Gemma 的开源代码模型，专为代码生成和自然语言任务设计。研究团队发布了三个模型变体：CodeGemma 7B 的预训练 (PT) 和指令微调 (IT) 版本，展现出强大的自然语言理解、优秀的数学推理能力，并与其它开源模型的代码性能相当；CodeGemma 2B 则是一款先进的代码补全模型，优化用于快速代码填充和延迟敏感环境的开放式生成。这些模型的发布为代码生成领域提供了高效、可访问的工具，提升了相关任务的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "v1: 11 pages, 4 figures, 5 tables. v2: Update metadata",
      "pdf_url": "http://arxiv.org/pdf/2406.11409v2",
      "published_date": "2024-06-17 10:54:35 UTC",
      "updated_date": "2024-06-19 02:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:21:00.854434"
    },
    {
      "arxiv_id": "2407.12787v2",
      "title": "GameVibe: A Multimodal Affective Game Corpus",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Barthet",
        "Maria Kaselimi",
        "Kosmas Pinitas",
        "Konstantinos Makantasis",
        "Antonios Liapis",
        "Georgios N. Yannakakis"
      ],
      "abstract": "As online video and streaming platforms continue to grow, affective computing\nresearch has undergone a shift towards more complex studies involving multiple\nmodalities. However, there is still a lack of readily available datasets with\nhigh-quality audiovisual stimuli. In this paper, we present GameVibe, a novel\naffect corpus which consists of multimodal audiovisual stimuli, including\nin-game behavioural observations and third-person affect traces for viewer\nengagement. The corpus consists of videos from a diverse set of publicly\navailable gameplay sessions across 30 games, with particular attention to\nensure high-quality stimuli with good audiovisual and gameplay diversity.\nFurthermore, we present an analysis on the reliability of the annotators in\nterms of inter-annotator agreement.",
      "tldr_zh": "这篇论文介绍了 GameVibe，这是一个多模态情感游戏语料库（Multimodal Affective Game Corpus），旨在填补高质量视听数据集的空白，以支持复杂的情感计算研究。\n语料库包括来自 30 个游戏的公开游戏会话视频，涵盖游戏行为观察、第三人称情感痕迹，并确保了视听和游戏多样性。\n论文还分析了标注者的可靠性，通过评估标注者间一致性（inter-annotator agreement），证明了数据集的可用性和高质量。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2407.12787v2",
      "published_date": "2024-06-17 10:52:52 UTC",
      "updated_date": "2025-04-01 09:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:21:14.420752"
    },
    {
      "arxiv_id": "2406.11402v3",
      "title": "Are Small Language Models Ready to Compete with Large Language Models for Practical Applications?",
      "title_zh": "小型语言模型是否已准备好与大型语言模型在实际应用",
      "authors": [
        "Neelabh Sinha",
        "Vinija Jain",
        "Aman Chadha"
      ],
      "abstract": "The rapid rise of Language Models (LMs) has expanded their use in several\napplications. Yet, due to constraints of model size, associated cost, or\nproprietary restrictions, utilizing state-of-the-art (SOTA) LLMs is not always\nfeasible. With open, smaller LMs emerging, more applications can leverage their\ncapabilities, but selecting the right LM can be challenging as smaller LMs do\nnot perform well universally. This work tries to bridge this gap by proposing a\nframework to experimentally evaluate small, open LMs in practical settings\nthrough measuring semantic correctness of outputs across three practical\naspects: task types, application domains, and reasoning types, using diverse\nprompt styles. It also conducts an in-depth comparison of 10 small, open LMs to\nidentify the best LM and prompt style depending on specific application\nrequirements using the proposed framework. We also show that if selected\nappropriately, they can outperform SOTA LLMs like DeepSeek-v2, GPT-4o,\nGPT-4o-mini, Gemini-1.5-Pro, and even compete with GPT-4o.",
      "tldr_zh": "这篇论文探讨了小型语言模型（Small Language Models, SLMs）是否能在实际应用中与大型语言模型（Large Language Models, LLMs）竞争的问题。作者提出一个实验框架，通过测量输出在任务类型、应用领域和推理类型方面的语义正确性，并使用多种prompt styles来评估小型开源LMs的性能。研究对10个小型开源LMs进行了深入比较，识别出根据特定应用需求的的最佳LM和prompt styles，并发现适当选择的小型LMs可以超越SOTA LLMs如DeepSeek-v2、GPT-4o等，甚至与GPT-4o匹敌。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at The Fifth Workshop on Trustworthy Natural Language\n  Processing (TrustNLP 2025) in Annual Conference of the Nations of the\n  Americas Chapter of the Association for Computational Linguistics (NAACL),\n  2025. 8 pages + references + Appendix",
      "pdf_url": "http://arxiv.org/pdf/2406.11402v3",
      "published_date": "2024-06-17 10:45:36 UTC",
      "updated_date": "2025-03-12 04:37:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:21:27.562021"
    },
    {
      "arxiv_id": "2406.11927v4",
      "title": "On the Impacts of Contexts on Repository-Level Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Nam Le Hai",
        "Dung Manh Nguyen",
        "Nghi D. Q. Bui"
      ],
      "abstract": "CodeLLMs have gained widespread adoption for code generation tasks, yet their\ncapacity to handle repository-level code generation with complex contextual\ndependencies remains underexplored. Our work underscores the critical\nimportance of leveraging repository-level contexts to generate executable and\nfunctionally correct code. We present RepoExec, a novel benchmark designed to\nevaluate repository-level code generation, with a focus on three key aspects:\nexecutability, functional correctness through comprehensive test case\ngeneration, and accurate utilization of cross-file contexts. Our study examines\na controlled scenario where developers specify essential code dependencies\n(contexts), challenging models to integrate them effectively. Additionally, we\nintroduce an instruction-tuned dataset that enhances CodeLLMs' ability to\nleverage dependencies, along with a new metric, Dependency Invocation Rate\n(DIR), to quantify context utilization. Experimental results reveal that while\npretrained LLMs demonstrate superior performance in terms of correctness,\ninstruction-tuned models excel in context utilization and debugging\ncapabilities. RepoExec offers a comprehensive evaluation framework for\nassessing code functionality and alignment with developer intent, thereby\nadvancing the development of more reliable CodeLLMs for real-world\napplications. The dataset and source code are available at\nhttps://github.com/FSoft-AI4Code/RepoExec.",
      "tldr_zh": "该研究探讨了上下文对仓库级代码生成的影响，强调了利用仓库级上下文以生成可执行且功能正确的代码。论文引入了RepoExec基准，用于评估代码的可执行性、功能正确性以及跨文件上下文的准确利用，同时提供了一个指令微调数据集来提升CodeLLMs处理依赖的能力。还提出了新指标Dependency Invocation Rate (DIR)来量化上下文利用，实验结果显示预训练LLMs在正确性上表现优越，而指令微调模型在上下文利用和调试能力方面更强。RepoExec框架推进了更可靠的CodeLLMs在实际应用中的发展，并提供了相关数据集和源代码。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.11927v4",
      "published_date": "2024-06-17 10:45:22 UTC",
      "updated_date": "2025-02-09 08:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:21:50.027876"
    },
    {
      "arxiv_id": "2406.11397v2",
      "title": "DistPred: A Distribution-Free Probabilistic Inference Method for Regression and Forecasting",
      "title_zh": "DistPred：一种用于回归和预测的分布",
      "authors": [
        "Daojun Liang",
        "Haixia Zhang",
        "Dongfeng Yuan"
      ],
      "abstract": "Traditional regression and prediction tasks often only provide deterministic\npoint estimates. To estimate the distribution or uncertainty of the response\nvariable, traditional methods either assume that the posterior distribution of\nsamples follows a Gaussian process or require thousands of forward passes for\nsample generation. We propose a novel approach called DistPred for regression\nand forecasting tasks, which overcomes the limitations of existing methods\nwhile remaining simple and powerful. Specifically, we transform proper scoring\nrules that measure the discrepancy between the predicted distribution and the\ntarget distribution into a differentiable discrete form and use it as a loss\nfunction to train the model end-to-end. This allows the model to sample\nnumerous samples in a single forward pass to estimate the potential\ndistribution of the response variable. We have compared our method with several\nexisting approaches on multiple datasets and achieved state-of-the-art\nperformance. Additionally, our method significantly improves computational\nefficiency. For example, compared to state-of-the-art models, DistPred has a\n180x faster inference speed Experimental results can be reproduced through\nhttps://github.com/Anoise/DistPred.",
      "tldr_zh": "本研究提出了一种名为 DistPred 的无分布假设概率推理方法，用于回归和预测任务，以解决传统方法仅提供点估计且依赖高斯过程或大量前向传递的局限性。DistPred 通过将 proper scoring rules 转化为可微分离散形式作为损失函数，实现模型的端到端训练，从而在单次前向传递中采样多个样本来估计响应变量的潜在分布。与现有方法相比，该方法在多个数据集上达到了 state-of-the-art 性能，并显著提升计算效率，例如推理速度比最先进模型快180倍。实验结果可通过 GitHub 仓库 https://github.com/Anoise/DistPred 复现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.11397v2",
      "published_date": "2024-06-17 10:33:00 UTC",
      "updated_date": "2025-01-07 03:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:21:51.161065"
    },
    {
      "arxiv_id": "2406.11375v2",
      "title": "Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Yuan",
        "Cheng Jiayang",
        "Lin Qiu",
        "Deqing Yang"
      ],
      "abstract": "Analogical reasoning plays a critical role in human cognition, enabling us to\nunderstand new concepts by associating them with familiar ones. Previous\nresearch in the AI community has mainly focused on identifying and generating\nanalogies and then examining their quality under human evaluation, which\noverlooks the practical application of these analogies in real-world settings.\nInspired by the human education process, in this paper, we propose to\ninvestigate how analogies created by teacher language models (LMs) can assist\nstudent LMs in understanding scientific concepts, thereby aligning more closely\nwith practical scenarios. Our results suggest that free-form analogies can\nindeed aid LMs in understanding concepts. Additionally, analogies generated by\nstudent LMs can improve their own performance on scientific question answering,\ndemonstrating their capability to use analogies for self-learning new\nknowledge. Resources are available at https://github.com/siyuyuan/SCUA.",
      "tldr_zh": "该论文探讨了类比推理在AI中的实际应用，研究教师语言模型(LMs)生成的类比是否能帮助学生LMs更好地理解科学概念，以模拟人类教育过程。作者通过实验验证了自由形式的类比确实能提升LMs的概念理解能力，同时发现学生LMs能利用自身生成的类比进行自学习，从而改善在科学问答任务中的表现。该研究为AI知识学习的实用场景提供了新见解，并提供了相关资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11375v2",
      "published_date": "2024-06-17 09:51:38 UTC",
      "updated_date": "2024-09-25 07:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:22:03.674935"
    },
    {
      "arxiv_id": "2406.11370v2",
      "title": "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments",
      "title_zh": "更公平的偏好引发改进的人类对齐大语言模型判断",
      "authors": [
        "Han Zhou",
        "Xingchen Wan",
        "Yinhong Liu",
        "Nigel Collier",
        "Ivan Vulić",
        "Anna Korhonen"
      ],
      "abstract": "Large language models (LLMs) have shown promising abilities as cost-effective\nand reference-free evaluators for assessing language generation quality. In\nparticular, pairwise LLM evaluators, which compare two generated texts and\ndetermine the preferred one, have been employed in a wide range of\napplications. However, LLMs exhibit preference biases and worrying sensitivity\nto prompt designs. In this work, we first reveal that the predictive preference\nof LLMs can be highly brittle and skewed, even with semantically equivalent\ninstructions. We find that fairer predictive preferences from LLMs consistently\nlead to judgments that are better aligned with humans. Motivated by this\nphenomenon, we propose an automatic Zero-shot Evaluation-oriented Prompt\nOptimization framework, ZEPO, which aims to produce fairer preference decisions\nand improve the alignment of LLM evaluators with human judgments. To this end,\nwe propose a zero-shot learning objective based on the preference decision\nfairness. ZEPO demonstrates substantial performance improvements over\nstate-of-the-art LLM evaluators, without requiring labeled data, on\nrepresentative meta-evaluation benchmarks. Our findings underscore the critical\ncorrelation between preference fairness and human alignment, positioning ZEPO\nas an efficient prompt optimizer for bridging the gap between LLM evaluators\nand human judgments.",
      "tldr_zh": "本研究发现，大语言模型(LLMs)的偏好预测容易受提示设计影响，导致不稳定和偏差，但更公平的预测偏好能显著提升LLMs判断与人类评估的对齐度。针对这一问题，提出一个自动的Zero-shot Evaluation-oriented Prompt Optimization框架（ZEPO），通过基于偏好决策公平性的zero-shot学习目标来优化提示设计，从而改善LLMs作为pairwise evaluators的性能。在代表性元评估基准上，ZEPO无需标注数据就实现了对现有LLMs评估者的实质性改进，强调了偏好公平性与人类对齐之间的关键相关性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11370v2",
      "published_date": "2024-06-17 09:48:53 UTC",
      "updated_date": "2024-10-12 23:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:22:17.427941"
    },
    {
      "arxiv_id": "2406.16937v2",
      "title": "A Complete Survey on LLM-based AI Chatbots",
      "title_zh": "基于LLM的AI聊天机器人的完整调查",
      "authors": [
        "Sumit Kumar Dam",
        "Choong Seon Hong",
        "Yu Qiao",
        "Chaoning Zhang"
      ],
      "abstract": "The past few decades have witnessed an upsurge in data, forming the\nfoundation for data-hungry, learning-based AI technology. Conversational\nagents, often referred to as AI chatbots, rely heavily on such data to train\nlarge language models (LLMs) and generate new content (knowledge) in response\nto user prompts. With the advent of OpenAI's ChatGPT, LLM-based chatbots have\nset new standards in the AI community. This paper presents a complete survey of\nthe evolution and deployment of LLM-based chatbots in various sectors. We first\nsummarize the development of foundational chatbots, followed by the evolution\nof LLMs, and then provide an overview of LLM-based chatbots currently in use\nand those in the development phase. Recognizing AI chatbots as tools for\ngenerating new knowledge, we explore their diverse applications across various\nindustries. We then discuss the open challenges, considering how the data used\nto train the LLMs and the misuse of the generated knowledge can cause several\nissues. Finally, we explore the future outlook to augment their efficiency and\nreliability in numerous applications. By addressing key milestones and the\npresent-day context of LLM-based chatbots, our survey invites readers to delve\ndeeper into this realm, reflecting on how their next generation will reshape\nconversational AI.",
      "tldr_zh": "这篇论文对基于LLM（Large Language Models）的AI chatbots进行了全面调查，回顾了其从基础chatbots到现代LLMs的演变，并概述了当前部署和开发中的应用。论文探讨了这些chatbots在医疗、教育、金融等行业的多样化应用，同时分析了数据训练不足和知识滥用可能导致的挑战，如伦理和可靠性问题。最后，它展望了未来改进方向，以提升chatbots的效率和可靠性，推动对话式AI的下一代发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16937v2",
      "published_date": "2024-06-17 09:39:34 UTC",
      "updated_date": "2024-11-18 12:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:22:28.237037"
    },
    {
      "arxiv_id": "2406.11357v2",
      "title": "Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities",
      "title_zh": "Refiner：高效重构检索内容以提升问答能力",
      "authors": [
        "Zhonghao Li",
        "Xuming Hu",
        "Aiwei Liu",
        "Kening Zheng",
        "Sirui Huang",
        "Hui Xiong"
      ],
      "abstract": "Large Language Models (LLMs) are limited by their parametric knowledge,\nleading to hallucinations in knowledge-extensive tasks. To address this,\nRetrieval-Augmented Generation (RAG) incorporates external document chunks to\nexpand LLM knowledge. Furthermore, compressing information from document chunks\nthrough extraction or summarization can improve LLM performance. Nonetheless,\nLLMs still struggle to notice and utilize scattered key information, a problem\nknown as the \"lost-in-the-middle\" syndrome. Therefore, we typically need to\nrestructure the content for LLM to recognize the key information. We propose\n$\\textit{Refiner}$, an end-to-end extract-and-restructure paradigm that\noperates in the post-retrieval process of RAG. $\\textit{Refiner}$ leverages a\nsingle decoder-only LLM to adaptively extract query-relevant contents verbatim\nalong with the necessary context, and section them based on their\ninterconnectedness, thereby highlights information distinction, and aligns\ndownstream LLMs with the original context effectively. Experiments show that a\ntrained $\\textit{Refiner}$ (with 7B parameters) exhibits significant gain to\ndownstream LLM in improving answer accuracy, and outperforms other\nstate-of-the-art advanced RAG and concurrent compressing approaches in various\nsingle-hop and multi-hop QA tasks. Notably, $\\textit{Refiner}$ achieves a 80.5%\ntokens reduction and a 1.6-7.0% improvement margin in multi-hop tasks compared\nto the next best solution. $\\textit{Refiner}$ is a plug-and-play solution that\ncan be seamlessly integrated with RAG systems, facilitating its application\nacross diverse open-source frameworks.",
      "tldr_zh": "该论文提出Refiner，一个端到端的提取和重构框架，旨在解决Retrieval-Augmented Generation (RAG)系统中Large Language Models (LLMs)面临的“lost-in-the-middle”问题，即忽略散乱的关键信息。Refiner利用一个decoder-only LLM来自适应提取查询相关内容及其必要上下文，并根据相互关联性进行分节，从而突出信息差异并提升下游LLMs的回答准确性。实验结果显示，Refiner在各种单跳和多跳QA任务中优于现有方法，实现80.5%的令牌减少，并在多跳任务中比次优方案提高1.6-7.0%，并可作为即插即用的解决方案无缝整合到RAG系统中。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.11357v2",
      "published_date": "2024-06-17 09:25:10 UTC",
      "updated_date": "2024-06-18 02:44:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:22:41.041701"
    },
    {
      "arxiv_id": "2406.11354v2",
      "title": "Preserving Knowledge in Large Language Model with Model-Agnostic Self-Decompression",
      "title_zh": "翻译失败",
      "authors": [
        "Zilun Zhang",
        "Yutao Sun",
        "Tiancheng Zhao",
        "Leigang Sha",
        "Ruochen Xu",
        "Kyusong Lee",
        "Jianwei Yin"
      ],
      "abstract": "Humans can retain old knowledge while learning new information, but Large\nLanguage Models (LLMs) often suffer from catastrophic forgetting when\npost-pretrained or supervised fine-tuned (SFT) on domain-specific data.\nMoreover, for Multimodal Large Language Models (MLLMs) which are composed of\nthe LLM base and visual projector (e.g. LLaVA), a significant decline in\nperformance on language benchmarks was observed compared to their\nsingle-modality counterparts. To address these challenges, we introduce a novel\nmodel-agnostic self-decompression method, Tree Generation (TG), that\ndecompresses knowledge within LLMs into the training corpus. This paper focuses\non TG-SFT, which can synthetically generate SFT data for the instruction tuning\nsteps. By incorporating the dumped corpus during SFT for MLLMs, we\nsignificantly reduce the forgetting problem.",
      "tldr_zh": "本研究解决了大型语言模型(LLMs)在后预训练或监督微调(SFT)过程中容易发生灾难性遗忘的问题，尤其是在多模态大型语言模型(MLLMs)中，语言基准表现显著下降。作者提出了一种模型无关的自解压方法Tree Generation (TG)，通过将LLMs中的知识提取并合成SFT数据，生成训练语料以缓解遗忘。实验结果显示，通过在SFT过程中整合这些语料，MLLMs的知识保留能力得到显著提升，为高效的模型持续学习提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11354v2",
      "published_date": "2024-06-17 09:17:40 UTC",
      "updated_date": "2024-06-19 11:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:22:51.810851"
    },
    {
      "arxiv_id": "2406.15484v2",
      "title": "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ze Wang",
        "Zekun Wu",
        "Xin Guan",
        "Michael Thaler",
        "Adriano Koshiyama",
        "Skylar Lu",
        "Sachin Beepath",
        "Ediz Ertekin Jr.",
        "Maria Perez-Ortiz"
      ],
      "abstract": "The use of Large Language Models (LLMs) in hiring has led to legislative\nactions to protect vulnerable demographic groups. This paper presents a novel\nframework for benchmarking hierarchical gender hiring bias in Large Language\nModels (LLMs) for resume scoring, revealing significant issues of reverse\ngender hiring bias and overdebiasing. Our contributions are fourfold: Firstly,\nwe introduce a new construct grounded in labour economics, legal principles,\nand critiques of current bias benchmarks: hiring bias can be categorized into\ntwo types: Level bias (difference in the average outcomes between demographic\ncounterfactual groups) and Spread bias (difference in the variance of outcomes\nbetween demographic counterfactual groups); Level bias can be further\nsubdivided into statistical bias (i.e. changing with non-demographic content)\nand taste-based bias (i.e. consistent regardless of non-demographic content).\nSecondly, the framework includes rigorous statistical and computational hiring\nbias metrics, such as Rank After Scoring (RAS), Rank-based Impact Ratio,\nPermutation Test, and Fixed Effects Model. Thirdly, we analyze gender hiring\nbiases in ten state-of-the-art LLMs. Seven out of ten LLMs show significant\nbiases against males in at least one industry. An industry-effect regression\nreveals that the healthcare industry is the most biased against males.\nMoreover, we found that the bias performance remains invariant with resume\ncontent for eight out of ten LLMs. This indicates that the bias performance\nmeasured in this paper might apply to other resume datasets with different\nresume qualities. Fourthly, we provide a user-friendly demo and resume dataset\nto support the adoption and practical use of the framework, which can be\ngeneralized to other social traits and tasks.",
      "tldr_zh": "本研究提出JobFair框架，用于评估大型语言模型(LLMs)在简历评分中的性别招聘偏见，揭示了逆向性别偏见和过度去偏见问题。框架引入新概念，将招聘偏见分为Level bias（平均结果差异，包括统计偏见和基于偏好的偏见）和Spread bias（结果方差差异），并提供严格指标如Rank After Scoring (RAS)、Rank-based Impact Ratio、Permutation Test和Fixed Effects Model。分析显示，十个最先进LLMs中有七个在至少一个行业对男性有显著偏见，医疗行业对男性偏见最严重，且八个模型的偏见与简历内容无关，表明结果可能适用于其他数据集。最后，该框架附带用户友好的演示和简历数据集，可推广到其他社会特征和任务。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings Paper",
      "pdf_url": "http://arxiv.org/pdf/2406.15484v2",
      "published_date": "2024-06-17 09:15:57 UTC",
      "updated_date": "2024-09-30 11:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:23:04.408966"
    },
    {
      "arxiv_id": "2406.11345v1",
      "title": "Full-ECE: A Metric For Token-level Calibration on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Han Liu",
        "Yupeng Zhang",
        "Bingning Wang",
        "Weipeng Chen",
        "Xiaolin Hu"
      ],
      "abstract": "Deep Neural Networks (DNNs) excel in various domains but face challenges in\nproviding accurate uncertainty estimates, which are crucial for high-stakes\napplications. Large Language Models (LLMs) have recently emerged as powerful\ntools, demonstrating exceptional performance in language tasks. However,\ntraditional calibration metrics such as Expected Calibration Error (ECE) and\nclasswise-ECE (cw-ECE) are inadequate for LLMs due to their vast vocabularies,\ndata complexity, and distributional focus. To address this, we propose a novel\ncalibration concept called full calibration and introduce its corresponding\nmetric, Full-ECE. Full-ECE evaluates the entire predicted probability\ndistribution, offering a more accurate and robust measure of calibration for\nLLMs.",
      "tldr_zh": "深度神经网络（DNNs）在高风险应用中面临不确定性估计的挑战，而大型语言模型（LLMs）由于词汇庞大和数据复杂，传统指标如 Expected Calibration Error (ECE) 和 classwise-ECE (cw-ECE) 无法有效评估其校准性能。论文提出了一种新概念 full calibration，并引入对应的指标 Full-ECE，用于评估 LLMs 的整个预测概率分布。Full-ECE 提供更准确和稳健的 token-level 校准测量，从而提升 LLMs 在复杂任务中的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11345v1",
      "published_date": "2024-06-17 09:07:58 UTC",
      "updated_date": "2024-06-17 09:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:23:15.704072"
    },
    {
      "arxiv_id": "2406.11334v1",
      "title": "Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment",
      "title_zh": "XLogo",
      "authors": [
        "Chao Wen",
        "Jacqueline Staub",
        "Adish Singla"
      ],
      "abstract": "Large language and multimodal models have shown remarkable successes on\nvarious benchmarks focused on specific skills such as general-purpose\nprogramming, natural language understanding, math word problem-solving, and\nvisual question answering. However, it is unclear how well these models perform\non tasks that require a combination of these skills. In this paper, we curate a\nnovel program synthesis benchmark based on the XLogoOnline visual programming\nenvironment. The benchmark comprises 85 real-world tasks from the Mini-level of\nthe XLogoOnline environment, each requiring a combination of different skills\nsuch as spatial planning, basic programming, and logical reasoning. Our\nevaluation shows that current state-of-the-art models like GPT-4V and\nLlama3-70B struggle to solve these tasks, achieving only 20% and 2.35% success\nrates. Next, we develop a fine-tuning pipeline to boost the performance of\nmodels by leveraging a large-scale synthetic training dataset with over 80000\ntasks. Moreover, we showcase how emulator-driven feedback can be used to design\na curriculum over training data distribution. We showcase that a fine-tuned\nLlama3-8B drastically outperforms GPT-4V and Llama3-70B models, and provide an\nin-depth analysis of the models' expertise across different skill dimensions.\nWe will publicly release the benchmark for future research on program synthesis\nin visual programming.",
      "tldr_zh": "本论文引入了一个基于 XLogoOnline 环境的 program synthesis benchmark，包含 85 个真实世界任务，这些任务需要结合空间规划、基本编程和逻辑推理等多种技能。评估结果显示，当前最先进模型如 GPT-4V 和 Llama3-70B 在这些任务上表现不佳，成功率仅为 20% 和 2.35%。为了提升性能，研究开发了微调管道，利用超过 80,000 个合成训练数据集和 emulator-driven feedback 设计训练数据课程，使微调后的 Llama3-8B 模型大幅超越基线模型，并在不同技能维度上进行了深入分析。该 benchmark 将公开发布，以促进未来视觉编程中 program synthesis 的研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11334v1",
      "published_date": "2024-06-17 08:48:02 UTC",
      "updated_date": "2024-06-17 08:48:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:23:29.307948"
    },
    {
      "arxiv_id": "2406.11326v1",
      "title": "GitHub Copilot: the perfect Code compLeeter?",
      "title_zh": "翻译失败",
      "authors": [
        "Ilja Siroš",
        "Dave Singelée",
        "Bart Preneel"
      ],
      "abstract": "This paper aims to evaluate GitHub Copilot's generated code quality based on\nthe LeetCode problem set using a custom automated framework. We evaluate the\nresults of Copilot for 4 programming languages: Java, C++, Python3 and Rust. We\naim to evaluate Copilot's reliability in the code generation stage, the\ncorrectness of the generated code and its dependency on the programming\nlanguage, problem's difficulty level and problem's topic. In addition to that,\nwe evaluate code's time and memory efficiency and compare it to the average\nhuman results. In total, we generate solutions for 1760 problems for each\nprogramming language and evaluate all the Copilot's suggestions for each\nproblem, resulting in over 50000 submissions to LeetCode spread over a 2-month\nperiod. We found that Copilot successfully solved most of the problems.\nHowever, Copilot was rather more successful in generating code in Java and C++\nthan in Python3 and Rust. Moreover, in case of Python3 Copilot proved to be\nrather unreliable in the code generation phase. We also discovered that\nCopilot's top-ranked suggestions are not always the best. In addition, we\nanalysed how the topic of the problem impacts the correctness rate. Finally,\nbased on statistics information from LeetCode, we can conclude that Copilot\ngenerates more efficient code than an average human.",
      "tldr_zh": "这篇论文使用自定义自动化框架评估了 GitHub Copilot 在 LeetCode 问题集上的代码生成质量，涵盖 Java、C++、Python3 和 Rust 四种语言，共生成并评估超过 50000 次提交的 1760 个问题解决方案。结果显示，Copilot 成功解决了大部分问题，但在 Python3 上可靠性较低，且其顶级建议并非总是最佳，同时问题主题和难度会影响正确率。最终，Copilot 生成的代码在时间和内存效率上比人类平均水平更高效。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 6 figures. Code available:\n  https://github.com/IljaSir/CopilotSolverForLeetCode",
      "pdf_url": "http://arxiv.org/pdf/2406.11326v1",
      "published_date": "2024-06-17 08:38:29 UTC",
      "updated_date": "2024-06-17 08:38:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:23:40.339104"
    },
    {
      "arxiv_id": "2406.11925v2",
      "title": "DocCGen: Document-based Controlled Code Generation",
      "title_zh": "DocCGen：基于文档的控制代码生成",
      "authors": [
        "Sameer Pimparkhede",
        "Mehant Kammakomati",
        "Srikanth Tamilselvam",
        "Prince Kumar",
        "Ashok Pon Kumar",
        "Pushpak Bhattacharyya"
      ],
      "abstract": "Recent developments show that Large Language Models (LLMs) produce\nstate-of-the-art performance on natural language (NL) to code generation for\nresource-rich general-purpose languages like C++, Java, and Python. However,\ntheir practical usage for structured domain-specific languages (DSLs) such as\nYAML, JSON is limited due to domain-specific schema, grammar, and\ncustomizations generally unseen by LLMs during pre-training. Efforts have been\nmade to mitigate this challenge via in-context learning through relevant\nexamples or by fine-tuning. However, it suffers from problems, such as limited\nDSL samples and prompt sensitivity but enterprises maintain good documentation\nof the DSLs. Therefore, we propose DocCGen, a framework that can leverage such\nrich knowledge by breaking the NL-to-Code generation task for structured code\nlanguages into a two-step process. First, it detects the correct libraries\nusing the library documentation that best matches the NL query. Then, it\nutilizes schema rules extracted from the documentation of these libraries to\nconstrain the decoding. We evaluate our framework for two complex structured\nlanguages, Ansible YAML and Bash command, consisting of two settings:\nOut-of-domain (OOD) and In-domain (ID). Our extensive experiments show that\nDocCGen consistently improves different-sized language models across all six\nevaluation metrics, reducing syntactic and semantic errors in structured code.\nWe plan to open-source the datasets and code to motivate research in\nconstrained code generation.",
      "tldr_zh": "该研究提出 DocCGen 框架，针对大型语言模型 (LLMs) 在结构化领域特定语言 (DSLs) 如 YAML 和 JSON 的自然语言 (NL) 到代码生成中面临的挑战，包括领域特定 schema、grammar 和自定义内容。DocCGen 通过利用文档知识，将生成任务分解为两步：首先检测与 NL 查询最匹配的库，然后提取这些库的 schema 规则来约束解码过程，从而减少 in-context learning 和 fine-tuning 的局限性。在 Ansible YAML 和 Bash command 的 Out-of-domain (OOD) 与 In-domain (ID) 设置中，实验显示 DocCGen 显著提升了不同规模模型在六种评估指标上的表现，降低了结构化代码的语法和语义错误，并计划开源数据集和代码以推动相关研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11925v2",
      "published_date": "2024-06-17 08:34:57 UTC",
      "updated_date": "2024-07-03 09:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:23:53.248978"
    },
    {
      "arxiv_id": "2406.11317v1",
      "title": "GUICourse: From General Vision Language Models to Versatile GUI Agents",
      "title_zh": "GUICourse：从通用视觉语言模型到多功能 GUI 代理",
      "authors": [
        "Wentong Chen",
        "Junbo Cui",
        "Jinyi Hu",
        "Yujia Qin",
        "Junjie Fang",
        "Yue Zhao",
        "Chongyi Wang",
        "Jun Liu",
        "Guirong Chen",
        "Yupeng Huo",
        "Yuan Yao",
        "Yankai Lin",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Utilizing Graphic User Interface (GUI) for human-computer interaction is\nessential for accessing a wide range of digital tools. Recent advancements in\nVision Language Models (VLMs) highlight the compelling potential to develop\nversatile agents to help humans finish GUI navigation tasks. However, current\nVLMs are challenged in terms of fundamental abilities (OCR and grounding) and\nGUI knowledge (the functions and control methods of GUI elements), preventing\nthem from becoming practical GUI agents. To solve these challenges, we\ncontribute GUICourse, a suite of datasets to train visual-based GUI agents from\ngeneral VLMs. First, we introduce the GUIEnv dataset to strengthen the OCR and\ngrounding capabilities of VLMs. Then, we introduce the GUIAct and GUIChat\ndatasets to enrich their knowledge of GUI components and interactions.\nExperiments demonstrate that our GUI agents have better performance on common\nGUI tasks than their baseline VLMs. Even the small-size GUI agent (with 3.1B\nparameters) can still work well on single-step and multi-step GUI tasks.\nFinally, we analyze the different varieties in the training stage of this agent\nby ablation study. Our source codes and datasets are released at\nhttps://github.com/yiye3/GUICourse.",
      "tldr_zh": "该研究针对视觉语言模型（VLMs）在图形用户界面（GUI）任务中的不足，如OCR和grounding能力弱以及GUI知识缺乏，提出GUICourse数据集套件，以从通用VLMs训练多功能GUI代理。首先，GUICourse包括GUIEnv数据集用于增强VLMs的OCR和grounding能力，以及GUIAct和GUIChat数据集用于丰富GUI组件和交互知识。实验结果显示，训练后的GUI代理在常见GUI任务上优于基线模型，即使是小型代理（3.1B参数）也能有效处理单步和多步任务；此外，消融研究分析了训练变体。该工作开源数据集和代码，推动了实用GUI代理的发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11317v1",
      "published_date": "2024-06-17 08:30:55 UTC",
      "updated_date": "2024-06-17 08:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:24:06.445896"
    },
    {
      "arxiv_id": "2406.11315v1",
      "title": "Temporal Lidar Depth Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Pietari Kaskela",
        "Philipp Fischer",
        "Timo Roman"
      ],
      "abstract": "Given the lidar measurements from an autonomous vehicle, we can project the\npoints and generate a sparse depth image. Depth completion aims at increasing\nthe resolution of such a depth image by infilling and interpolating the sparse\ndepth values. Like most existing approaches, we make use of camera images as\nguidance in very sparse or occluded regions. In addition, we propose a temporal\nalgorithm that utilizes information from previous timesteps using recurrence.\nIn this work, we show how a state-of-the-art method PENet can be modified to\nbenefit from recurrency. Our algorithm achieves state-of-the-art results on the\nKITTI depth completion dataset while adding only less than one percent of\nadditional overhead in terms of both neural network parameters and floating\npoint operations. The accuracy is especially improved for faraway objects and\nregions containing a low amount of lidar depth samples. Even in regions without\nany ground truth (like sky and rooftops) we observe large improvements which\nare not captured by the existing evaluation metrics.",
      "tldr_zh": "本文提出了一种Temporal Lidar Depth Completion方法，利用相机图像作为引导，并引入时间序列的recurrence算法来利用前一个时间步的信息，从而对稀疏Lidar深度图像进行填充和插值。具体地，该方法修改了state-of-the-art的PENet框架，仅增加了不到1%的神经网络参数和浮点运算开销。实验结果显示，该算法在KITTI深度完成数据集上达到了state-of-the-art性能，尤其在远距离物体和Lidar样本稀疏区域的准确性显著提升，甚至在无地面真实值的区域（如天空和屋顶）也观察到明显改善。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11315v1",
      "published_date": "2024-06-17 08:25:31 UTC",
      "updated_date": "2024-06-17 08:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:24:18.676096"
    },
    {
      "arxiv_id": "2406.11308v1",
      "title": "Management Decisions in Manufacturing using Causal Machine Learning -- To Rework, or not to Rework?",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Schwarz",
        "Oliver Schacht",
        "Sven Klaassen",
        "Daniel Grünbaum",
        "Sebastian Imhof",
        "Martin Spindler"
      ],
      "abstract": "In this paper, we present a data-driven model for estimating optimal rework\npolicies in manufacturing systems. We consider a single production stage within\na multistage, lot-based system that allows for optional rework steps. While the\nrework decision depends on an intermediate state of the lot and system, the\nfinal product inspection, and thus the assessment of the actual yield, is\ndelayed until production is complete. Repair steps are applied uniformly to the\nlot, potentially improving some of the individual items while degrading others.\nThe challenge is thus to balance potential yield improvement with the rework\ncosts incurred. Given the inherently causal nature of this decision problem, we\npropose a causal model to estimate yield improvement. We apply methods from\ncausal machine learning, in particular double/debiased machine learning (DML)\ntechniques, to estimate conditional treatment effects from data and derive\npolicies for rework decisions. We validate our decision model using real-world\ndata from opto-electronic semiconductor manufacturing, achieving a yield\nimprovement of 2 - 3% during the color-conversion process of white\nlight-emitting diodes (LEDs).",
      "tldr_zh": "这篇论文提出了一种数据驱动模型，用于估计制造业系统中最佳的重工(rework)策略，针对多阶段批次生产中单个阶段的可选重工决策。作者采用因果模型和双重/去偏机器学习(DML)技术，从数据中估计条件治疗效果(conditional treatment effects)，以平衡潜在产出改善和重工成本。实验在真实的光电半导体制造数据上验证，该方法在白光LEDs的颜色转换过程中实现了2-3%的产出改善。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.EM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11308v1",
      "published_date": "2024-06-17 08:14:40 UTC",
      "updated_date": "2024-06-17 08:14:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:24:30.299000"
    },
    {
      "arxiv_id": "2406.11303v1",
      "title": "VideoVista: A Versatile Benchmark for Video Understanding and Reasoning",
      "title_zh": "VideoVista：一个多功能的视频理解与推理基准",
      "authors": [
        "Yunxin Li",
        "Xinyu Chen",
        "Baotian Hu",
        "Longyue Wang",
        "Haoyuan Shi",
        "Min Zhang"
      ],
      "abstract": "Despite significant breakthroughs in video analysis driven by the rapid\ndevelopment of large multimodal models (LMMs), there remains a lack of a\nversatile evaluation benchmark to comprehensively assess these models'\nperformance in video understanding and reasoning. To address this, we present\nVideoVista, a video QA benchmark that integrates challenges across diverse\ncontent categories, durations, and abilities. Specifically, VideoVista\ncomprises 25,000 questions derived from 3,400 videos spanning 14 categories\n(e.g., Howto, Film, and Entertainment) with durations ranging from a few\nseconds to over 10 minutes. Besides, it encompasses 19 types of understanding\ntasks (e.g., anomaly detection, interaction understanding) and 8 reasoning\ntasks (e.g., logical reasoning, causal reasoning). To achieve this, we present\nan automatic data construction framework, leveraging powerful GPT-4o alongside\nadvanced analysis tools (e.g., video splitting, object segmenting, and\ntracking). We also utilize this framework to construct training data to enhance\nthe capabilities of video-related LMMs (Video-LMMs). Through a comprehensive\nand quantitative evaluation of cutting-edge models, we reveal that: 1)\nVideo-LMMs face difficulties in fine-grained video tasks involving temporal\nlocation, object tracking, and anomaly detection; 2) Video-LMMs present\ninferior logical and relation reasoning abilities; 3) Open-source Video-LMMs'\nperformance is significantly lower than GPT-4o and Gemini-1.5, lagging by 20\npoints. This highlights the crucial role VideoVista will play in advancing LMMs\nthat can accurately understand videos and perform precise reasoning.",
      "tldr_zh": "该论文提出 VideoVista，这是一个多功能的视频理解和推理基准，用于全面评估大型多模态模型 (LMMs) 的性能，解决现有基准的不足。VideoVista 包含 25,000 个问题，源自 3,400 个视频，覆盖 14 个类别（如 Howto、Film 和 Entertainment）、多种时长（从几秒到超过 10 分钟），并涉及 19 种理解任务（如异常检测、交互理解）和 8 种推理任务（如逻辑推理、因果推理）。论文采用自动数据构建框架，结合 GPT-4o 和高级分析工具（如视频分割、对象分割和跟踪），不仅创建了评估数据集，还生成训练数据以提升 Video-LMMs 的能力。实验结果显示，Video-LMMs 在时间定位、对象跟踪和异常检测等精细任务中表现欠佳，且逻辑推理能力较弱，开源模型比 GPT-4o 和 Gemini-1.5 落后约 20 分，这突显 VideoVista 在推动视频理解和精确推理技术方面的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "38 pages, 44 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11303v1",
      "published_date": "2024-06-17 08:09:00 UTC",
      "updated_date": "2024-06-17 08:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:24:44.494779"
    },
    {
      "arxiv_id": "2406.11301v3",
      "title": "Enhancing and Assessing Instruction-Following with Fine-Grained Instruction Variants",
      "title_zh": "翻译失败",
      "authors": [
        "Jiuding Yang",
        "Weidong Guo",
        "Kaitong Yang",
        "Xiangyang Li",
        "Yu Xu",
        "Di Niu"
      ],
      "abstract": "The effective alignment of Large Language Models (LLMs) with precise\ninstructions is essential for their application in diverse real-world\nscenarios. Current methods focus on enhancing the diversity and complexity of\ntraining and evaluation samples, yet they fall short in accurately assessing\nLLMs' ability to follow similar instruction variants. We introduce an effective\ndata augmentation technique DeMoRecon that decomposes complex instructions into\nsimpler sub-components, modifies these, and reconstructs them into new\nvariants, thereby preserves the original instruction's context and complexity\nwhile introducing variability, which is critical for training and evaluating\nLLMs' instruction-following precision. Based on DeMoRecon, we developed the\nFGIV dataset which contains fine-grained instruction variants of 1,773 seed\ninstructions to both fine-tune and evaluate LLMs. Our findings show that LLMs\nfine-tuned with FGIV will gain significant performance boost on both ours and\ncommonly used instructions-following benchmarks.",
      "tldr_zh": "本研究针对大语言模型(LLMs)指令遵循能力的不足，提出DeMoRecon数据增强技术，该方法将复杂指令分解为简单子组件、进行修改并重建为新变体，从而保持原指令的上下文和复杂度，同时引入多样性。\n基于DeMoRecon，研究者开发了FGIV数据集，包含1,773个种子指令的细粒度变体，用于LLMs的微调和评估。\n结果显示，使用FGIV微调的LLMs在指令遵循基准上实现了显著性能提升，证明了该方法在提升模型精确性和鲁棒性方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11301v3",
      "published_date": "2024-06-17 08:08:11 UTC",
      "updated_date": "2024-10-15 23:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:24:53.772561"
    },
    {
      "arxiv_id": "2406.11924v1",
      "title": "Explainable assessment of financial experts' credibility by classifying social media forecasts and checking the predictions with actual market data",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia García-Méndez",
        "Francisco de Arriba-Pérez",
        "Jaime González-Gonzáleza",
        "Francisco J. González-Castaño"
      ],
      "abstract": "Social media include diverse interaction metrics related to user popularity,\nthe most evident example being the number of user followers. The latter has\nraised concerns about the credibility of the posts by the most popular\ncreators. However, most existing approaches to assess credibility in social\nmedia strictly consider this problem a binary classification, often based on a\npriori information, without checking if actual real-world facts back the users'\ncomments. In addition, they do not provide automatic explanations of their\npredictions to foster their trustworthiness. In this work, we propose a\ncredibility assessment solution for financial creators in social media that\ncombines Natural Language Processing and Machine Learning. The reputation of\nthe contributors is assessed by automatically classifying their forecasts on\nasset values by type and verifying these predictions with actual market data to\napproximate their probability of success. The outcome of this verification is a\ncontinuous credibility score instead of a binary result, an entirely novel\ncontribution by this work. Moreover, social media metrics (i.e., user context)\nare exploited by calculating their correlation with the credibility rankings,\nproviding insights on the interest of the end-users in financial posts and\ntheir forecasts (i.e., drop or rise). Finally, the system provides natural\nlanguage explanations of its decisions based on a model-agnostic analysis of\nrelevant features.",
      "tldr_zh": "本研究提出了一种可解释的社交媒体金融专家可信度评估方法，通过Natural Language Processing (NLP) 和 Machine Learning (ML) 技术自动分类资产价值预测类型，并使用实际市场数据验证这些预测，以计算成功概率。不同于传统的binary classification，该方法生成连续的可信度分数，提供更细粒度的评估结果。研究还分析了社交媒体指标（如用户关注者数量）与可信度排名的相关性，揭示用户对金融帖子兴趣的洞见，并基于模型-agnostic 特征分析生成自然语言解释，以提升系统的可信性和透明度。实验结果表明，该方法能有效提升评估的准确性和实用性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11924v1",
      "published_date": "2024-06-17 08:08:03 UTC",
      "updated_date": "2024-06-17 08:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:25:05.914581"
    },
    {
      "arxiv_id": "2406.11290v1",
      "title": "Iterative Utility Judgment Framework via LLMs Inspired by Relevance in Philosophy",
      "title_zh": "翻译失败",
      "authors": [
        "Hengran Zhang",
        "Keping Bi",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "Utility and topical relevance are critical measures in information retrieval\n(IR), reflecting system and user perspectives, respectively. While topical\nrelevance has long been emphasized, utility is a higher standard of relevance\nand is more useful for facilitating downstream tasks, e.g., in\nRetrieval-Augmented Generation (RAG). When we incorporate utility judgments\ninto RAG, we realize that the topical relevance, utility, and answering in RAG\nare closely related to the three types of relevance that Schutz discussed from\na philosophical perspective. They are topical relevance, interpretational\nrelevance, and motivational relevance, respectively. Inspired by the dynamic\niterations of the three types of relevance, we propose an Iterative utiliTy\njudgmEnt fraMework (ITEM) to promote each step of the cycle of RAG. We\nconducted extensive experiments on multi-grade passage retrieval and factoid\nquestion-answering datasets (i.e., TREC DL, WebAP, and NQ). Experimental\nresults demonstrate significant improvements in utility judgments, ranking of\ntopical relevance, and answer generation upon representative baselines,\nincluding multiple single-shot utility judging approaches. Our code and\nbenchmark can be found at https://anonymous.4open.science/r/ITEM-B486/.",
      "tldr_zh": "这篇论文提出了一种受哲学家 Schutz 相关性理论启发的迭代效用判断框架（ITEM），利用大型语言模型（LLMs）来提升信息检索（IR）中的效用评估，该框架将 topical relevance、interpretational relevance 和 motivational relevance 整合进 Retrieval-Augmented Generation (RAG) 流程中。ITEM 通过动态迭代优化效用判断、主题相关性排名和答案生成，支持下游任务的改进。实验在 TREC DL、WebAP 和 NQ 数据集上表明，该框架显著优于基线模型，在多级段落检索和事实问题回答任务中实现了性能提升。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.11290v1",
      "published_date": "2024-06-17 07:52:42 UTC",
      "updated_date": "2024-06-17 07:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:25:18.618746"
    },
    {
      "arxiv_id": "2406.11282v1",
      "title": "From Pixels to Progress: Generating Road Network from Satellite Imagery for Socioeconomic Insights in Impoverished Areas",
      "title_zh": "翻译失败",
      "authors": [
        "Yanxin Xi",
        "Yu Liu",
        "Zhicheng Liu",
        "Sasu Tarkoma",
        "Pan Hui",
        "Yong Li"
      ],
      "abstract": "The Sustainable Development Goals (SDGs) aim to resolve societal challenges,\nsuch as eradicating poverty and improving the lives of vulnerable populations\nin impoverished areas. Those areas rely on road infrastructure construction to\npromote accessibility and economic development. Although publicly available\ndata like OpenStreetMap is available to monitor road status, data completeness\nin impoverished areas is limited. Meanwhile, the development of deep learning\ntechniques and satellite imagery shows excellent potential for earth\nmonitoring. To tackle the challenge of road network assessment in impoverished\nareas, we develop a systematic road extraction framework combining an\nencoder-decoder architecture and morphological operations on satellite imagery,\noffering an integrated workflow for interdisciplinary researchers. Extensive\nexperiments of road network extraction on real-world data in impoverished\nregions achieve a 42.7% enhancement in the F1-score over the baseline methods\nand reconstruct about 80% of the actual roads. We also propose a comprehensive\nroad network dataset covering approximately 794,178 km2 area and 17.048 million\npeople in 382 impoverished counties in China. The generated dataset is further\nutilized to conduct socioeconomic analysis in impoverished counties, showing\nthat road network construction positively impacts regional economic\ndevelopment. The technical appendix, code, and generated dataset can be found\nat\nhttps://github.com/tsinghua-fib-lab/Road_network_extraction_impoverished_counties.",
      "tldr_zh": "本研究针对贫困地区道路基础设施不完善的问题，开发了一个系统性的道路提取框架，利用卫星图像结合编码器-解码器架构和形态学操作，生成精确的道路网络数据。该框架在真实贫困地区数据上实验，F1-score 比基线方法提高了 42.7%，成功重建约 80% 的实际道路，并构建了一个覆盖中国 382 个贫困县的综合数据集，总面积约 794,178 km²，涉及 17.048 百万人口。通过分析生成的道路网络，该研究发现道路建设对区域经济发展的积极影响，为可持续发展目标（SDGs）提供宝贵的社会经济洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 13 figures, IJCAI2024 (AI and Social Good)",
      "pdf_url": "http://arxiv.org/pdf/2406.11282v1",
      "published_date": "2024-06-17 07:40:13 UTC",
      "updated_date": "2024-06-17 07:40:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:25:30.189791"
    },
    {
      "arxiv_id": "2406.11921v1",
      "title": "Rethinking Spatio-Temporal Transformer for Traffic Prediction:Multi-level Multi-view Augmented Learning Framework",
      "title_zh": "重新审视时空 Transformer 用于交通预测：多级多视图增强学习框架",
      "authors": [
        "Jiaqi Lin",
        "Qianqian Ren"
      ],
      "abstract": "Traffic prediction is a challenging spatio-temporal forecasting problem that\ninvolves highly complex spatio-temporal correlations. This paper proposes a\nMulti-level Multi-view Augmented Spatio-temporal Transformer (LVSTformer) for\ntraffic prediction. The model aims to capture spatial dependencies from three\ndifferent levels: local geographic, global semantic, and pivotal nodes, along\nwith long- and short-term temporal dependencies. Specifically, we design three\nspatial augmented views to delve into the spatial information from the\nperspectives of local, global, and pivotal nodes. By combining three spatial\naugmented views with three parallel spatial self-attention mechanisms, the\nmodel can comprehensively captures spatial dependencies at different levels. We\ndesign a gated temporal self-attention mechanism to effectively capture long-\nand short-term temporal dependencies. Furthermore, a spatio-temporal context\nbroadcasting module is introduced between two spatio-temporal layers to ensure\na well-distributed allocation of attention scores, alleviating overfitting and\ninformation loss, and enhancing the generalization ability and robustness of\nthe model. A comprehensive set of experiments is conducted on six well-known\ntraffic benchmarks, the experimental results demonstrate that LVSTformer\nachieves state-of-the-art performance compared to competing baselines, with the\nmaximum improvement reaching up to 4.32%.",
      "tldr_zh": "本论文重新思考了 Spatio-Temporal Transformer 在交通预测中的应用，提出了一种 Multi-level Multi-view Augmented Learning Framework，名为 LVSTformer，用于捕捉复杂时空相关性，包括本地地理、全球语义和关键节点（pivotal nodes）的空间依赖，以及长期和短期时间依赖。模型通过设计三个空间增强视图（spatial augmented views）结合三个并行空间自注意力机制（spatial self-attention mechanisms），并引入门控时间自注意力机制（gated temporal self-attention mechanism）和时空上下文广播模块（spatio-temporal context broadcasting module），以优化注意力分配、减少过拟合并提升泛化能力。在六个知名交通基准上的实验表明，LVSTformer 比竞争基线模型性能提升最高达 4.32%，达到了最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11921v1",
      "published_date": "2024-06-17 07:36:57 UTC",
      "updated_date": "2024-06-17 07:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:25:42.433672"
    },
    {
      "arxiv_id": "2406.11920v3",
      "title": "Job-SDF: A Multi-Granularity Dataset for Job Skill Demand Forecasting and Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Chen",
        "Chuan Qin",
        "Chuyu Fang",
        "Chao Wang",
        "Chen Zhu",
        "Fuzhen Zhuang",
        "Hengshu Zhu",
        "Hui Xiong"
      ],
      "abstract": "In a rapidly evolving job market, skill demand forecasting is crucial as it\nenables policymakers and businesses to anticipate and adapt to changes,\nensuring that workforce skills align with market needs, thereby enhancing\nproductivity and competitiveness. Additionally, by identifying emerging skill\nrequirements, it directs individuals towards relevant training and education\nopportunities, promoting continuous self-learning and development. However, the\nabsence of comprehensive datasets presents a significant challenge, impeding\nresearch and the advancement of this field. To bridge this gap, we present\nJob-SDF, a dataset designed to train and benchmark job-skill demand forecasting\nmodels. Based on 10.35 million public job advertisements collected from major\nonline recruitment platforms in China between 2021 and 2023, this dataset\nencompasses monthly recruitment demand for 2,324 types of skills across 521\ncompanies. Our dataset uniquely enables evaluating skill demand forecasting\nmodels at various granularities, including occupation, company, and regional\nlevels. We benchmark a range of models on this dataset, evaluating their\nperformance in standard scenarios, in predictions focused on lower value\nranges, and in the presence of structural breaks, providing new insights for\nfurther research. Our code and dataset are publicly accessible via the\nhttps://github.com/Job-SDF/benchmark.",
      "tldr_zh": "本研究强调了技能需求预测（skill demand forecasting）在动态就业市场中的重要性，但指出现有数据集的缺失阻碍了该领域的进展。为解决这一问题，作者提出了 Job-SDF 数据集，该数据集基于 2021-2023 年中国主要在线招聘平台的 1035 万职位广告，涵盖 2324 种技能在 521 家公司的月度招聘需求，并支持多粒度（occupation, company, and regional levels）的模型评估和基准测试（benchmarking）。实验结果显示，该数据集用于评估各种模型在标准场景、低值范围预测以及结构断裂情况下的性能，提供新的研究见解；代码和数据集已公开在 GitHub 上。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2406.11920v3",
      "published_date": "2024-06-17 07:22:51 UTC",
      "updated_date": "2024-12-01 03:49:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:26:05.292887"
    },
    {
      "arxiv_id": "2406.11272v1",
      "title": "Development of an Adaptive Multi-Domain Artificial Intelligence System Built using Machine Learning and Expert Systems Technologies",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy Straub"
      ],
      "abstract": "Producing an artificial general intelligence (AGI) has been an elusive goal\nin artificial intelligence (AI) research for some time. An AGI would have the\ncapability, like a human, to be exposed to a new problem domain, learn about it\nand then use reasoning processes to make decisions. While AI techniques have\nbeen used across a wide variety of problem domains, an AGI would require an AI\nthat could reason beyond its programming and training. This paper presents a\nsmall step towards producing an AGI. It describes a mechanism for an AI to\nlearn about and develop reasoning pathways to make decisions in an a priori\nunknown domain. It combines a classical AI technique, the expert system, with a\nits modern adaptation - the gradient descent trained expert system (GDTES) -\nand utilizes generative artificial intelligence (GAI) to create a network and\ntraining data set for this system. These can be created from available sources\nor may draw upon knowledge incorporated in a GAI's own pre-trained model. The\nlearning process in GDTES is used to optimize the AI's decision-making. While\nthis approach does not meet the standards that many have defined for an AGI, it\nprovides a somewhat similar capability, albeit one which requires a learning\nprocess before use.",
      "tldr_zh": "该论文探讨了开发适应多领域人工智能系统的努力，旨在实现类似人工通用智能(AGI)的能力，让AI能够在未知领域学习并进行决策。该系统结合了经典的expert system、现代的gradient descent trained expert system (GDTES)以及generative artificial intelligence (GAI)，通过GAI生成网络和训练数据集来优化AI的推理路径。尽管这种方法需要先进行学习过程，并未完全达到AGI的标准，但它为AI在新领域自主决策提供了一个可行机制。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11272v1",
      "published_date": "2024-06-17 07:21:44 UTC",
      "updated_date": "2024-06-17 07:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:26:16.628053"
    },
    {
      "arxiv_id": "2406.11263v2",
      "title": "Understanding the Collapse of LLMs in Model Editing",
      "title_zh": "理解 LLMs 在模型编辑中的崩溃",
      "authors": [
        "Wanli Yang",
        "Fei Sun",
        "Jiajun Tan",
        "Xinyu Ma",
        "Du Su",
        "Dawei Yin",
        "Huawei Shen"
      ],
      "abstract": "Despite significant progress in model editing methods, their application in\nreal-world scenarios remains challenging as they often cause large language\nmodels (LLMs) to collapse. Among them, ROME is particularly concerning, as it\ncould disrupt LLMs with only a single edit. In this paper, we study the root\ncauses of such collapse. Through extensive analysis, we identify two primary\nfactors that contribute to the collapse: i) inconsistent handling of prefixed\nand unprefixed keys in the parameter update equation may result in very small\ndenominators, causing excessively large parameter updates; ii) the subject of\ncollapse cases is usually the first token, whose unprefixed key distribution\nsignificantly differs from the prefixed key distribution in autoregressive\ntransformers, causing the aforementioned issue to materialize. To validate our\nfindings, we propose a simple yet effective approach: uniformly using prefixed\nkeys during editing phase and adding prefixes during testing phase to ensure\nthe consistency between training and testing. The experimental results show\nthat the proposed solution can prevent model collapse while maintaining the\neffectiveness of the edits.",
      "tldr_zh": "这篇论文探讨了大语言模型（LLMs）在模型编辑中的崩溃问题，特别是ROME方法可能因单次编辑导致模型完全失效。作者通过深入分析识别出两个主要原因：一是参数更新方程中对带前缀和不带前缀键的不一致处理，可能导致分母过小从而产生过大更新；二是崩溃通常发生在第一个token上，因为其不带前缀键的分布与带前缀键的分布有显著差异。针对这些问题，论文提出了一种简单方法：在编辑阶段统一使用带前缀键，并在测试阶段添加前缀，以确保训练和测试的一致性。实验结果显示，该方法能有效防止LLMs崩溃，同时保持编辑的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Findings of EMNLP 2024 (Camera-Ready Version)",
      "pdf_url": "http://arxiv.org/pdf/2406.11263v2",
      "published_date": "2024-06-17 07:08:29 UTC",
      "updated_date": "2024-09-30 06:37:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:26:30.340256"
    },
    {
      "arxiv_id": "2407.00063v2",
      "title": "An Interpretable Alternative to Neural Representation Learning for Rating Prediction -- Transparent Latent Class Modeling of User Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Giuseppe Serra",
        "Peter Tino",
        "Zhao Xu",
        "Xin Yao"
      ],
      "abstract": "Nowadays, neural network (NN) and deep learning (DL) techniques are widely\nadopted in many applications, including recommender systems. Given the sparse\nand stochastic nature of collaborative filtering (CF) data, recent works have\ncritically analyzed the effective improvement of neural-based approaches\ncompared to simpler and often transparent algorithms for recommendation.\nPrevious results showed that NN and DL models can be outperformed by\ntraditional algorithms in many tasks. Moreover, given the largely black-box\nnature of neural-based methods, interpretable results are not naturally\nobtained. Following on this debate, we first present a transparent\nprobabilistic model that topologically organizes user and product latent\nclasses based on the review information. In contrast to popular neural\ntechniques for representation learning, we readily obtain a statistical,\nvisualization-friendly tool that can be easily inspected to understand user and\nproduct characteristics from a textual-based perspective. Then, given the\nlimitations of common embedding techniques, we investigate the possibility of\nusing the estimated interpretable quantities as model input for a rating\nprediction task. To contribute to the recent debates, we evaluate our results\nin terms of both capacity for interpretability and predictive performances in\ncomparison with popular text-based neural approaches. The results demonstrate\nthat the proposed latent class representations can yield competitive predictive\nperformances, compared to popular, but difficult-to-interpret approaches.",
      "tldr_zh": "本研究提出了一种可解释的替代方案，用于评分预测，即基于用户评论的透明潜在类建模（Transparent Latent Class Modeling），以取代传统的神经表示学习（Neural Representation Learning）。该模型通过概率方法拓扑组织用户和产品的潜在类，利用评论信息生成易于可视化和解释的表示，从而揭示用户和产品特征。实验结果显示，该方法在评分预测任务中与流行的基于文本的神经网络方法相比，实现了竞争性的预测性能，同时提供了更高的可解释性，挑战了神经网络（NN）和深度学习（DL）在推荐系统中的黑盒局限性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00063v2",
      "published_date": "2024-06-17 07:07:42 UTC",
      "updated_date": "2024-07-02 11:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:26:40.771644"
    },
    {
      "arxiv_id": "2406.11260v3",
      "title": "Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Sungwon Park",
        "Sungwon Han",
        "Xing Xie",
        "Jae-Gil Lee",
        "Meeyoung Cha"
      ],
      "abstract": "The spread of fake news harms individuals and presents a critical social\nchallenge that must be addressed. Although numerous algorithmic and insightful\nfeatures have been developed to detect fake news, many of these features can be\nmanipulated with style-conversion attacks, especially with the emergence of\nadvanced language models, making it more difficult to differentiate from\ngenuine news. This study proposes adversarial style augmentation, AdStyle,\ndesigned to train a fake news detector that remains robust against various\nstyle-conversion attacks. The primary mechanism involves the strategic use of\nLLMs to automatically generate a diverse and coherent array of style-conversion\nattack prompts, enhancing the generation of particularly challenging prompts\nfor the detector. Experiments indicate that our augmentation strategy\nsignificantly improves robustness and detection performance when evaluated on\nfake news benchmark datasets.",
      "tldr_zh": "本研究针对假新闻检测面临的风格转换攻击（style-conversion attacks）问题，提出了一种Adversarial Style Augmentation (AdStyle)方法，利用Large Language Model (LLMs)自动生成多样且连贯的攻击提示，以增强检测器的鲁棒性。AdStyle的核心机制是通过这些挑战性提示训练模型，使其能够更好地抵抗高级语言模型的操纵。实验结果表明，在假新闻基准数据集上，该方法显著提高了检测性能和整体鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "WWW'25 research track accepted",
      "pdf_url": "http://arxiv.org/pdf/2406.11260v3",
      "published_date": "2024-06-17 07:00:41 UTC",
      "updated_date": "2025-04-18 07:15:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:26:53.604388"
    },
    {
      "arxiv_id": "2406.11259v1",
      "title": "NLDF: Neural Light Dynamic Fields for Efficient 3D Talking Head Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Niu Guanchen"
      ],
      "abstract": "Talking head generation based on the neural radiation fields model has shown\npromising visual effects. However, the slow rendering speed of NeRF seriously\nlimits its application, due to the burdensome calculation process over hundreds\nof sampled points to synthesize one pixel. In this work, a novel Neural Light\nDynamic Fields model is proposed aiming to achieve generating high quality 3D\ntalking face with significant speedup. The NLDF represents light fields based\non light segments, and a deep network is used to learn the entire light beam's\ninformation at once. In learning the knowledge distillation is applied and the\nNeRF based synthesized result is used to guide the correct coloration of light\nsegments in NLDF. Furthermore, a novel active pool training strategy is\nproposed to focus on high frequency movements, particularly on the speaker\nmouth and eyebrows. The propose method effectively represents the facial light\ndynamics in 3D talking video generation, and it achieves approximately 30 times\nfaster speed compared to state of the art NeRF based method, with comparable\ngeneration visual quality.",
      "tldr_zh": "本文提出NLDF（Neural Light Dynamic Fields）模型，用于高效生成高质量3D说话头像，解决NeRF渲染速度慢的问题。NLDF基于光段（light segments）表示光场，通过深度网络一次性学习整个光束信息，并采用知识蒸馏（knowledge distillation）指导光段着色，同时引入主动池训练策略（active pool training strategy）来聚焦高频面部运动如嘴巴和眉毛。实验表明，该方法比最先进的NeRF方法快约30倍，同时保持可比的视觉生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11259v1",
      "published_date": "2024-06-17 06:53:37 UTC",
      "updated_date": "2024-06-17 06:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:27:05.973987"
    },
    {
      "arxiv_id": "2406.11255v1",
      "title": "Liberal Entity Matching as a Compound AI Toolchain",
      "title_zh": "翻译失败",
      "authors": [
        "Silvery D. Fu",
        "David Wang",
        "Wen Zhang",
        "Kathleen Ge"
      ],
      "abstract": "Entity matching (EM), the task of identifying whether two descriptions refer\nto the same entity, is essential in data management. Traditional methods have\nevolved from rule-based to AI-driven approaches, yet current techniques using\nlarge language models (LLMs) often fall short due to their reliance on static\nknowledge and rigid, predefined prompts. In this paper, we introduce Libem, a\ncompound AI system designed to address these limitations by incorporating a\nflexible, tool-oriented approach. Libem supports entity matching through\ndynamic tool use, self-refinement, and optimization, allowing it to adapt and\nrefine its process based on the dataset and performance metrics. Unlike\ntraditional solo-AI EM systems, which often suffer from a lack of modularity\nthat hinders iterative design improvements and system optimization, Libem\noffers a composable and reusable toolchain. This approach aims to contribute to\nongoing discussions and developments in AI-driven data management.",
      "tldr_zh": "本论文探讨了实体匹配（Entity Matching, EM）在数据管理中的关键作用，指出当前基于大型语言模型（LLMs）的EM方法因依赖静态知识和刚性提示而存在局限性。作者引入Libem，这是一个复合AI系统，通过动态工具使用、自我优化和基于数据集的适应过程来提升EM的灵活性。与传统的solo-AI系统相比，Libem提供模块化、可组合的工具链，便于迭代设计和性能优化。该方法旨在为AI驱动的数据管理领域带来新贡献。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "2 pages, compound ai systems 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11255v1",
      "published_date": "2024-06-17 06:33:34 UTC",
      "updated_date": "2024-06-17 06:33:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:27:21.641008"
    },
    {
      "arxiv_id": "2406.11249v1",
      "title": "Relational Learning in Pre-Trained Models: A Theory from Hypergraph Recovery Perspective",
      "title_zh": "预训练模型中的关系学习：从超图恢复视角的理论",
      "authors": [
        "Yang Chen",
        "Cong Fang",
        "Zhouchen Lin",
        "Bing Liu"
      ],
      "abstract": "Foundation Models (FMs) have demonstrated remarkable insights into the\nrelational dynamics of the world, leading to the crucial question: how do these\nmodels acquire an understanding of world hybrid relations? Traditional\nstatistical learning, particularly for prediction problems, may overlook the\nrich and inherently structured information from the data, especially regarding\nthe relationships between objects. We introduce a mathematical model that\nformalizes relational learning as hypergraph recovery to study pre-training of\nFMs. In our framework, the world is represented as a hypergraph, with data\nabstracted as random samples from hyperedges. We theoretically examine the\nfeasibility of a Pre-Trained Model (PTM) to recover this hypergraph and analyze\nthe data efficiency in a minimax near-optimal style. By integrating rich graph\ntheories into the realm of PTMs, our mathematical framework offers powerful\ntools for an in-depth understanding of pre-training from a unique perspective\nand can be used under various scenarios. As an example, we extend the framework\nto entity alignment in multimodal learning.",
      "tldr_zh": "本研究探讨了基础模型（Foundation Models, FMs）如何学习世界的关系动态，并提出一个数学框架，将关系学习形式化为超图恢复（hypergraph recovery），以分析预训练模型（Pre-Trained Model, PTM）的预训练过程。在该框架中，世界被表示为超图（hypergraph），数据视为来自超边（hyperedges）的随机样本，并理论证明了PTM恢复超图的可行性及其数据效率（minimax near-optimal）。通过整合图论（graph theories），该框架为理解预训练提供新视角，并扩展到多模态学习的实体对齐（entity alignment）等场景中。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11249v1",
      "published_date": "2024-06-17 06:20:39 UTC",
      "updated_date": "2024-06-17 06:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:27:30.090503"
    },
    {
      "arxiv_id": "2406.11248v2",
      "title": "Performance Improvement of Language-Queried Audio Source Separation Based on Caption Augmentation From Large Language Models for DCASE Challenge 2024 Task 9",
      "title_zh": "翻译失败",
      "authors": [
        "Do Hyun Lee",
        "Yoonah Song",
        "Hong Kook Kim"
      ],
      "abstract": "We present a prompt-engineering-based text-augmentation approach applied to a\nlanguage-queried audio source separation (LASS) task. To enhance the\nperformance of LASS, the proposed approach utilizes large language models\n(LLMs) to generate multiple captions corresponding to each sentence of the\ntraining dataset. To this end, we first perform experiments to identify the\nmost effective prompts for caption augmentation with a smaller number of\ncaptions. A LASS model trained with these augmented captions demonstrates\nimproved performance on the DCASE 2024 Task 9 validation set compared to that\ntrained without augmentation. This study highlights the effectiveness of\nLLM-based caption augmentation in advancing language-queried audio source\nseparation.",
      "tldr_zh": "本研究提出了一种基于提示工程的文本增强方法，使用Large Language Models (LLMs)为训练数据集的每个句子生成多个标题，以提升Language-Queried Audio Source Separation (LASS)的性能。通过实验识别出最有效的提示，减少标题生成数量，并证明使用增强标题训练的LASS模型在DCASE 2024 Task 9验证集上表现优于无增强模型。该方法突出了LLM-based caption augmentation在音频源分离任务中的有效性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "DCASE 2024 Challenge Task 9, 4 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.11248v2",
      "published_date": "2024-06-17 06:19:14 UTC",
      "updated_date": "2024-11-27 02:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:27:44.863283"
    },
    {
      "arxiv_id": "2406.11244v1",
      "title": "SpoT-Mamba: Learning Long-Range Dependency on Spatio-Temporal Graphs with Selective State Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhyeok Choi",
        "Heehyeon Kim",
        "Minhyeong An",
        "Joyce Jiyoung Whang"
      ],
      "abstract": "Spatio-temporal graph (STG) forecasting is a critical task with extensive\napplications in the real world, including traffic and weather forecasting.\nAlthough several recent methods have been proposed to model complex dynamics in\nSTGs, addressing long-range spatio-temporal dependencies remains a significant\nchallenge, leading to limited performance gains. Inspired by a recently\nproposed state space model named Mamba, which has shown remarkable capability\nof capturing long-range dependency, we propose a new STG forecasting framework\nnamed SpoT-Mamba. SpoT-Mamba generates node embeddings by scanning various\nnode-specific walk sequences. Based on the node embeddings, it conducts\ntemporal scans to capture long-range spatio-temporal dependencies. Experimental\nresults on the real-world traffic forecasting dataset demonstrate the\neffectiveness of SpoT-Mamba.",
      "tldr_zh": "该研究针对时空图(STG)预测中的长程时空依赖挑战，提出了一种新框架SpoT-Mamba，受Mamba状态空间模型启发。SpoT-Mamba通过扫描节点特定的游走序列生成节点嵌入，并进行时间扫描来捕捉复杂的长程依赖。实验结果显示，在真实世界交通预测数据集上，该框架显著提升了预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 2 figures, 3 tables. Spatio-Temporal Reasoning and Learning\n  (STRL) Workshop at the 33rd International Joint Conference on Artificial\n  Intelligence (IJCAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.11244v1",
      "published_date": "2024-06-17 06:15:31 UTC",
      "updated_date": "2024-06-17 06:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:28:03.822836"
    },
    {
      "arxiv_id": "2406.11243v1",
      "title": "FamiCom: Further Demystifying Prompts for Language Models with Task-Agnostic Performance Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Bangzheng Li",
        "Ben Zhou",
        "Xingyu Fu",
        "Fei Wang",
        "Dan Roth",
        "Muhao Chen"
      ],
      "abstract": "Language models have shown impressive in-context-learning capabilities, which\nallow them to benefit from input prompts and perform better on downstream end\ntasks. Existing works investigate the mechanisms behind this observation, and\npropose label-agnostic prompt metrics that can better estimate end-task\nperformances. One popular approach is using perplexity as a way to measure\nmodels' familiarity with the prompt. While showing consistent improvements on\nin-domain tasks, we found that familiarity metrics such as perplexity cannot\naccurately estimate performance in complicated situations such as task or\ndomain transferring scenarios. In this work, we propose a revised measure\ncalled FamiCom, providing a more comprehensive measure for task-agnostic\nperformance estimation. Specifically, FamiCom combines familiarity with\n\\textit{complexity} -- the inherent difficulty of end tasks, which is an\nimportant factor missing from current metrics. Experiments show that FamiCom\nstrongly correlates with end-task performances, producing a 0.85 Spearman's\ncorrelation, versus 0.43 of familiarity-only ones'. We further apply FamiCom to\nautomatic prompt and demonstration selection, and outperform existing methods\nand baselines by more than 7.0% in accuracy.",
      "tldr_zh": "本文提出 FamiCom，一种改进的提示性能估计方法，结合了熟悉度（familiarity）和任务内在复杂性（complexity），以更准确地评估语言模型在任务无关场景下的表现。相比现有基于 perplexity 的指标，FamiCom 在实验中显示出更强的相关性（Spearman's correlation 0.85 vs. 0.43），尤其在任务或领域转移情况下。作者进一步将 FamiCom 应用于自动提示和演示选择，实现了超过7.0%的准确率提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11243v1",
      "published_date": "2024-06-17 06:14:55 UTC",
      "updated_date": "2024-06-17 06:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:28:07.600991"
    },
    {
      "arxiv_id": "2406.11240v1",
      "title": "The Benefits of Power Regularization in Cooperative Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Michelle Li",
        "Michael Dennis"
      ],
      "abstract": "Cooperative Multi-Agent Reinforcement Learning (MARL) algorithms, trained\nonly to optimize task reward, can lead to a concentration of power where the\nfailure or adversarial intent of a single agent could decimate the reward of\nevery agent in the system. In the context of teams of people, it is often\nuseful to explicitly consider how power is distributed to ensure no person\nbecomes a single point of failure. Here, we argue that explicitly regularizing\nthe concentration of power in cooperative RL systems can result in systems\nwhich are more robust to single agent failure, adversarial attacks, and\nincentive changes of co-players. To this end, we define a practical pairwise\nmeasure of power that captures the ability of any co-player to influence the\nego agent's reward, and then propose a power-regularized objective which\nbalances task reward and power concentration. Given this new objective, we show\nthat there always exists an equilibrium where every agent is playing a\npower-regularized best-response balancing power and task reward. Moreover, we\npresent two algorithms for training agents towards this power-regularized\nobjective: Sample Based Power Regularization (SBPR), which injects adversarial\ndata during training; and Power Regularization via Intrinsic Motivation (PRIM),\nwhich adds an intrinsic motivation to regulate power to the training objective.\nOur experiments demonstrate that both algorithms successfully balance task\nreward and power, leading to lower power behavior than the baseline of\ntask-only reward and avoid catastrophic events in case an agent in the system\ngoes off-policy.",
      "tldr_zh": "这篇论文探讨了在合作式多智能体强化学习（Cooperative MARL）中，单纯优化任务奖励可能导致权力集中的问题，从而使系统易受单个智能体失败、攻击或激励变化的影响。作者定义了一个成对的权力度量来评估智能体对他人奖励的影响，并提出一个新的目标函数来平衡任务奖励和权力集中，证明了存在一个均衡状态，其中每个智能体都能权衡两者。论文介绍了两种算法：Sample Based Power Regularization (SBPR)，通过注入对抗数据进行训练；以及Power Regularization via Intrinsic Motivation (PRIM)，通过添加内在动机来调节权力。实验结果表明，这些方法成功降低了权力集中行为，并在智能体偏离策略时避免了灾难性事件，提高了系统的整体鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11240v1",
      "published_date": "2024-06-17 06:10:37 UTC",
      "updated_date": "2024-06-17 06:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:28:21.141734"
    },
    {
      "arxiv_id": "2406.15481v2",
      "title": "Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Haneul Yoo",
        "Yongjin Yang",
        "Hwaran Lee"
      ],
      "abstract": "As large language models (LLMs) have advanced rapidly, concerns regarding\ntheir safety have become prominent. In this paper, we discover that\ncode-switching in red-teaming queries can effectively elicit undesirable\nbehaviors of LLMs, which are common practices in natural language. We introduce\na simple yet effective framework, CSRT, to synthesize code-switching\nred-teaming queries and investigate the safety and multilingual understanding\nof LLMs comprehensively. Through extensive experiments with ten\nstate-of-the-art LLMs and code-switching queries combining up to 10 languages,\nwe demonstrate that the CSRT significantly outperforms existing multilingual\nred-teaming techniques, achieving 46.7% more attacks than standard attacks in\nEnglish and being effective in conventional safety domains. We also examine the\nmultilingual ability of those LLMs to generate and understand code-switching\ntexts. Additionally, we validate the extensibility of the CSRT by generating\ncode-switching attack prompts with monolingual data. We finally conduct\ndetailed ablation studies exploring code-switching and propound unintended\ncorrelation between resource availability of languages and safety alignment in\nexisting multilingual LLMs.",
      "tldr_zh": "该论文引入了 CSRT 框架，利用 code-switching 在 red-teaming 查询中测试大型语言模型（LLMs）的安全性和多语言理解能力，以揭示 LLMs 的潜在不良行为。实验涉及十个最先进 LLMs 和结合多达 10 种语言的查询，结果显示 CSRT 比标准英语攻击多出 46.7% 的攻击成功率，并在传统安全领域表现出色。研究进一步考察了 LLMs 生成和理解 code-switching 文本的能力，并通过消融研究发现，语言资源可用性与 LLMs 的安全对齐存在意外相关性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15481v2",
      "published_date": "2024-06-17 06:08:18 UTC",
      "updated_date": "2024-11-02 06:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:28:35.754791"
    },
    {
      "arxiv_id": "2406.11239v3",
      "title": "SilverSpeak: Evading AI-Generated Text Detectors using Homoglyphs",
      "title_zh": "翻译失败",
      "authors": [
        "Aldan Creo",
        "Shushanta Pudasaini"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has enabled the generation of text\nthat increasingly exhibits human-like characteristics. As the detection of such\ncontent is of significant importance, substantial research has been conducted\nwith the objective of developing reliable AI-generated text detectors. These\ndetectors have demonstrated promising results on test data, but recent research\nhas revealed that they can be circumvented by employing different techniques.\n  In this paper, we present homoglyph-based attacks (A $\\rightarrow$ Cyrillic\nA) as a means of circumventing existing detectors. We conduct a comprehensive\nevaluation to assess the effectiveness of these attacks on seven detectors,\nincluding ArguGPT, Binoculars, DetectGPT, Fast-DetectGPT, Ghostbuster, OpenAI's\ndetector, and watermarking techniques, on five different datasets. Our findings\ndemonstrate that homoglyph-based attacks can effectively circumvent\nstate-of-the-art detectors, leading them to classify all texts as either\nAI-generated or human-written (decreasing the average Matthews Correlation\nCoefficient from 0.64 to -0.01). Through further examination, we extract the\ntechnical justification underlying the success of the attacks, which varies\nacross detectors. Finally, we discuss the implications of these findings and\npotential defenses against such attacks.",
      "tldr_zh": "本研究提出SilverSpeak，一种基于Homoglyphs（例如拉丁A替换为西里尔A）的攻击方法，用于规避AI生成文本检测器。实验评估了七个检测器（包括ArguGPT、DetectGPT和水印技术）在五个数据集上的性能，结果显示这些攻击能显著降低检测准确性，将平均Matthews Correlation Coefficient从0.64降至-0.01。论文进一步分析了攻击成功的技术原因，并讨论了潜在防御策略，以提升AI文本检测器的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Workshop on Detecting AI Generated Content at COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.11239v3",
      "published_date": "2024-06-17 06:07:32 UTC",
      "updated_date": "2025-01-20 05:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:28:43.975050"
    },
    {
      "arxiv_id": "2406.11234v2",
      "title": "MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Qiao Sun",
        "Liujia Yang",
        "Minghao Ma",
        "Nanyang Ye",
        "Qinying Gu"
      ],
      "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to co-extract the sentiment\ntriplets in a given corpus. Existing approaches within the\npretraining-finetuning paradigm tend to either meticulously craft complex\ntagging schemes and classification heads, or incorporate external semantic\naugmentation to enhance performance. In this study, we, for the first time,\nre-evaluate the redundancy in tagging schemes and the internal enhancement in\npretrained representations. We propose a method to improve and utilize\npretrained representations by integrating a minimalist tagging scheme and a\nnovel token-level contrastive learning strategy. The proposed approach\ndemonstrates comparable or superior performance compared to state-of-the-art\ntechniques while featuring a more compact design and reduced computational\noverhead. Additionally, we are the first to formally evaluate GPT-4's\nperformance in few-shot learning and Chain-of-Thought scenarios for this task.\nThe results demonstrate that the pretraining-finetuning paradigm remains highly\neffective even in the era of large language models.",
      "tldr_zh": "本研究针对Aspect Sentiment Triplet Extraction (ASTE)任务，首次重新评估标签方案的冗余和预训练表示的内部增强，提出MiniConGTS方法，该方法整合了一个极简的对比网格标签方案（minimalist tagging scheme）和一个新型的token-level contrastive learning策略，以提升性能并减少计算开销。相比现有复杂标签方案或外部语义增强方法，MiniConGTS在紧凑设计下实现了与最先进技术相当或优越的提取效果。研究还首次正式评估了GPT-4在少样本学习和Chain-of-Thought场景下的表现，结果表明预训练-微调范式在大语言模型时代依然高度有效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: text overlap with arXiv:2403.07342",
      "pdf_url": "http://arxiv.org/pdf/2406.11234v2",
      "published_date": "2024-06-17 06:01:11 UTC",
      "updated_date": "2024-09-30 18:36:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:28:56.572705"
    },
    {
      "arxiv_id": "2406.11233v3",
      "title": "Probing the Decision Boundaries of In-context Learning in Large Language Models",
      "title_zh": "探究大型语言模型中上下文学习的决策边界",
      "authors": [
        "Siyan Zhao",
        "Tung Nguyen",
        "Aditya Grover"
      ],
      "abstract": "In-context learning is a key paradigm in large language models (LLMs) that\nenables them to generalize to new tasks and domains by simply prompting these\nmodels with a few exemplars without explicit parameter updates. Many attempts\nhave been made to understand in-context learning in LLMs as a function of model\nscale, pretraining data, and other factors. In this work, we propose a new\nmechanism to probe and understand in-context learning from the lens of decision\nboundaries for in-context binary classification. Decision boundaries are\nstraightforward to visualize and provide important information about the\nqualitative behavior of the inductive biases of standard classifiers. To our\nsurprise, we find that the decision boundaries learned by current LLMs in\nsimple binary classification tasks are often irregular and non-smooth,\nregardless of linear separability in the underlying task. This paper\ninvestigates the factors influencing these decision boundaries and explores\nmethods to enhance their generalizability. We assess various approaches,\nincluding training-free and fine-tuning methods for LLMs, the impact of model\narchitecture, and the effectiveness of active prompting techniques for\nsmoothing decision boundaries in a data-efficient manner. Our findings provide\na deeper understanding of in-context learning dynamics and offer practical\nimprovements for enhancing robustness and generalizability of in-context\nlearning.",
      "tldr_zh": "本文探讨了大型语言模型（LLMs）中 in-context learning 的决策边界（decision boundaries），通过二元分类任务的视角来分析其机制和局限性。研究发现，当前 LLMs 在简单任务中学习的决策边界往往不规则且不平滑，即使任务是线性可分的。作者评估了多种影响因素和改进方法，包括无训练方法、微调技术、模型架构调整以及主动提示技术，以提升决策边界的平滑性和 in-context learning 的泛化能力。这些发现为增强 LLMs 的鲁棒性提供了实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024, code at\n  https://github.com/siyan-zhao/ICL_decision_boundary",
      "pdf_url": "http://arxiv.org/pdf/2406.11233v3",
      "published_date": "2024-06-17 06:00:24 UTC",
      "updated_date": "2024-12-09 23:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:29:09.175889"
    },
    {
      "arxiv_id": "2406.11232v3",
      "title": "SLEGO: A Collaborative Data Analytics System with LLM Recommender for Diverse Users",
      "title_zh": "翻译失败",
      "authors": [
        "Siu Lung Ng",
        "Hirad Baradaran Rezaei",
        "Fethi Rabhi"
      ],
      "abstract": "This paper presents the SLEGO (Software-Lego) system, a collaborative\nanalytics platform that bridges the gap between experienced developers and\nnovice users using a cloud-based platform with modular, reusable microservices.\nThese microservices enable developers to share their analytical tools and\nworkflows, while a simple graphical user interface (GUI) allows novice users to\nbuild comprehensive analytics pipelines without programming skills. Supported\nby a knowledge base and a Large Language Model (LLM) powered recommendation\nsystem, SLEGO enhances the selection and integration of microservices,\nincreasing the efficiency of analytics pipeline construction. Case studies in\nfinance and machine learning illustrate how SLEGO promotes the sharing and\nassembly of modular microservices, significantly improving resource reusability\nand team collaboration. The results highlight SLEGO's role in democratizing\ndata analytics by integrating modular design, knowledge bases, and\nrecommendation systems, fostering a more inclusive and efficient analytical\nenvironment.",
      "tldr_zh": "这篇论文介绍了 SLEGO 系统，这是一个基于云平台的协作数据分析系统，使用模块化的可重用 microservices 来桥接经验丰富的开发者与新手用户。\n系统通过简单的 GUI 界面、知识库和 LLM 驱动的推荐系统，允许新手用户无需编程技能即可构建和集成分析管道，从而提高效率。\n案例研究在金融和机器学习领域证明了 SLEGO 的作用，提升了资源可重用性、团队协作，并通过模块化设计、知识库和推荐系统使数据分析更具包容性和民主化。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.11; I.2.1"
      ],
      "primary_category": "cs.SE",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11232v3",
      "published_date": "2024-06-17 05:59:13 UTC",
      "updated_date": "2024-12-08 04:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:29:20.684953"
    },
    {
      "arxiv_id": "2406.11231v1",
      "title": "Enabling robots to follow abstract instructions and complete complex dynamic tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Ruaridh Mon-Williams",
        "Gen Li",
        "Ran Long",
        "Wenqian Du",
        "Chris Lucas"
      ],
      "abstract": "Completing complex tasks in unpredictable settings like home kitchens\nchallenges robotic systems. These challenges include interpreting high-level\nhuman commands, such as \"make me a hot beverage\" and performing actions like\npouring a precise amount of water into a moving mug. To address these\nchallenges, we present a novel framework that combines Large Language Models\n(LLMs), a curated Knowledge Base, and Integrated Force and Visual Feedback\n(IFVF). Our approach interprets abstract instructions, performs long-horizon\ntasks, and handles various uncertainties. It utilises GPT-4 to analyse the\nuser's query and surroundings, then generates code that accesses a curated\ndatabase of functions during execution. It translates abstract instructions\ninto actionable steps. Each step involves generating custom code by employing\nretrieval-augmented generalisation to pull IFVF-relevant examples from the\nKnowledge Base. IFVF allows the robot to respond to noise and disturbances\nduring execution. We use coffee making and plate decoration to demonstrate our\napproach, including components ranging from pouring to drawer opening, each\nbenefiting from distinct feedback types and methods. This novel advancement\nmarks significant progress toward a scalable, efficient robotic framework for\ncompleting complex tasks in uncertain environments. Our findings are\nillustrated in an accompanying video and supported by an open-source GitHub\nrepository (released upon paper acceptance).",
      "tldr_zh": "该研究提出了一种新框架，帮助机器人解读抽象指令（如“make me a hot beverage”）并在不确定环境中完成复杂任务，如家庭厨房中的精确操作。框架结合 Large Language Models (LLMs) 如 GPT-4、一个精选的 Knowledge Base 和 Integrated Force and Visual Feedback (IFVF)，通过分析用户查询和环境生成可执行代码，并利用检索增强泛化从 Knowledge Base 中提取相关示例来处理噪音和干扰。实验演示了在咖啡制作和盘子装饰等任务上的应用，展示了框架的可扩展性和高效性，为机器人适应动态环境提供了显著进步，支持视频和开源 GitHub 仓库。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11231v1",
      "published_date": "2024-06-17 05:55:35 UTC",
      "updated_date": "2024-06-17 05:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:29:33.008682"
    },
    {
      "arxiv_id": "2406.11230v2",
      "title": "Multimodal Needle in a Haystack: Benchmarking Long-Context Capability of Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hengyi Wang",
        "Haizhou Shi",
        "Shiwei Tan",
        "Weiyi Qin",
        "Wenyuan Wang",
        "Tunyu Zhang",
        "Akshay Nambi",
        "Tanuja Ganu",
        "Hao Wang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have shown significant promise in\nvarious applications, leading to broad interest from researchers and\npractitioners alike. However, a comprehensive evaluation of their long-context\ncapabilities remains underexplored. To address these gaps, we introduce the\nMultiModal Needle-in-a-haystack (MMNeedle) benchmark, specifically designed to\nassess the long-context capabilities of MLLMs. Besides multi-image input, we\nemploy image stitching to further increase the input context length, and\ndevelop a protocol to automatically generate labels for sub-image level\nretrieval. Essentially, MMNeedle evaluates MLLMs by stress-testing their\ncapability to locate a target sub-image (needle) within a set of images\n(haystack) based on textual instructions and descriptions of image contents.\nThis setup necessitates an advanced understanding of extensive visual contexts\nand effective information retrieval within long-context image inputs. With this\nbenchmark, we evaluate state-of-the-art MLLMs, encompassing both API-based and\nopen-source models. The findings reveal that GPT-4o consistently surpasses\nother models in long-context scenarios, but suffers from hallucination problems\nin negative samples, i.e., when needles are not in the haystacks. Our\ncomprehensive long-context evaluation of MLLMs also sheds lights on the\nconsiderable performance gap between API-based and open-source models. All the\ncode, data, and instructions required to reproduce the main results are\navailable at https://github.com/Wang-ML-Lab/multimodal-needle-in-a-haystack.",
      "tldr_zh": "该论文引入了 MultiModal Needle-in-a-haystack (MMNeedle) 基准，用于评估 Multimodal Large Language Models (MLLMs) 的长上下文能力，通过多图像输入和图像拼接来增加输入长度，并开发自动标签生成协议。MMNeedle 测试模型基于文本指令从图像集合（haystack）中定位目标子图像（needle），强调对广泛视觉上下文的理解和信息检索。实验结果显示，GPT-4o 在长上下文场景中表现最佳，但存在幻觉问题，尤其在负样本中，且 API-based 模型与开源模型之间存在显著性能差距。所有代码、数据和指令已开源在 GitHub 上。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2406.11230v2",
      "published_date": "2024-06-17 05:54:06 UTC",
      "updated_date": "2025-02-11 02:17:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:29:46.162022"
    },
    {
      "arxiv_id": "2406.11227v1",
      "title": "Compound Schema Registry",
      "title_zh": "复合模式注册表",
      "authors": [
        "Silvery D. Fu",
        "Xuewei Chen"
      ],
      "abstract": "Schema evolution is critical in managing database systems to ensure\ncompatibility across different data versions. A schema registry typically\naddresses the challenges of schema evolution in real-time data streaming by\nmanaging, validating, and ensuring schema compatibility. However, current\nschema registries struggle with complex syntactic alterations like field\nrenaming or type changes, which often require significant manual intervention\nand can disrupt service. To enhance the flexibility of schema evolution, we\npropose the use of generalized schema evolution (GSE) facilitated by a compound\nAI system. This system employs Large Language Models (LLMs) to interpret the\nsemantics of schema changes, supporting a broader range of syntactic\nmodifications without interrupting data streams. Our approach includes\ndeveloping a task-specific language, Schema Transformation Language (STL), to\ngenerate schema mappings as an intermediate representation (IR), simplifying\nthe integration of schema changes across different data processing platforms.\nInitial results indicate that this approach can improve schema mapping accuracy\nand efficiency, demonstrating the potential of GSE in practical applications.",
      "tldr_zh": "本文提出了一种名为 Compound Schema Registry 的系统，利用 generalized schema evolution (GSE) 和 compound AI system 来提升数据库 schema evolution 的灵活性，解决现有 schema registry 在处理复杂语法变化（如字段重命名或类型变化）时需要手动干预并可能中断数据流的问题。系统通过 Large Language Models (LLMs) 解释 schema 变化的语义，支持更广泛的语法修改，同时引入 Schema Transformation Language (STL) 作为 intermediate representation (IR)，用于生成 schema mappings 以简化跨平台集成。初步结果表明，该方法显著提高了 schema mapping 的准确性和效率，为实际应用中的 schema 管理提供了潜在改进。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "2 pages, compound ai system workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11227v1",
      "published_date": "2024-06-17 05:50:46 UTC",
      "updated_date": "2024-06-17 05:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:29:57.576956"
    },
    {
      "arxiv_id": "2406.11218v1",
      "title": "Building another Spanish dictionary, this time with GPT-4",
      "title_zh": "构建另一个西班牙语词典",
      "authors": [
        "Miguel Ortega-Martín",
        "Óscar García-Sierra",
        "Alfonso Ardoiz",
        "Juan Carlos Armenteros",
        "Ignacio Garrido",
        "Jorge Álvarez",
        "Camilo Torrón",
        "Iñigo Galdeano",
        "Ignacio Arranz",
        "Oleg Vorontsov",
        "Adrián Alonso"
      ],
      "abstract": "We present the \"Spanish Built Factual Freectianary 2.0\" (Spanish-BFF-2) as\nthe second iteration of an AI-generated Spanish dictionary. Previously, we\ndeveloped the inaugural version of this unique free dictionary employing GPT-3.\nIn this study, we aim to improve the dictionary by using GPT-4-turbo instead.\nFurthermore, we explore improvements made to the initial version and compare\nthe performance of both models.",
      "tldr_zh": "本研究介绍了“Spanish-BFF-2.0”，这是使用 GPT-4-turbo 开发的西班牙语字典第二版，先前版本则基于 GPT-3。研究者旨在通过升级模型改进字典的质量，包括优化生成过程和内容准确性。最终，他们比较了两个模型的性能，展示了 GPT-4-turbo 在生成事实性词条方面的提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11218v1",
      "published_date": "2024-06-17 05:25:56 UTC",
      "updated_date": "2024-06-17 05:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:30:07.559970"
    },
    {
      "arxiv_id": "2406.11217v2",
      "title": "WeatherQA: Can Multimodal Language Models Reason about Severe Weather?",
      "title_zh": "翻译失败",
      "authors": [
        "Chengqian Ma",
        "Zhanxiang Hua",
        "Alexandra Anderson-Frey",
        "Vikram Iyer",
        "Xin Liu",
        "Lianhui Qin"
      ],
      "abstract": "Severe convective weather events, such as hail, tornadoes, and thunderstorms,\noften occur quickly yet cause significant damage, costing billions of dollars\nevery year. This highlights the importance of forecasting severe weather\nthreats hours in advance to better prepare meteorologists and residents in\nat-risk areas. Can modern large foundation models perform such forecasting?\nExisting weather benchmarks typically focus only on predicting time-series\nchanges in certain weather parameters (e.g., temperature, moisture) with\ntext-only features. In this work, we introduce WeatherQA, the first multimodal\ndataset designed for machines to reason about complex combinations of weather\nparameters (a.k.a., ingredients) and predict severe weather in real-world\nscenarios. The dataset includes over 8,000 (multi-images, text) pairs for\ndiverse severe weather events. Each pair contains rich information crucial for\nforecasting -- the images describe the ingredients capturing environmental\ninstability, surface observations, and radar reflectivity, and the text\ncontains forecast analyses written by human experts. With WeatherQA, we\nevaluate state-of-the-art vision language models, including GPT4, Claude3.5,\nGemini-1.5, and a fine-tuned Llama3-based VLM, by designing two challenging\ntasks: (1) multi-choice QA for predicting affected area and (2) classification\nof the development potential of severe convection. These tasks require deep\nunderstanding of domain knowledge (e.g., atmospheric dynamics) and complex\nreasoning over multimodal data (e.g., interactions between weather parameters).\nWe show a substantial gap between the strongest VLM, GPT4o, and human\nreasoning. Our comprehensive case study with meteorologists further reveals the\nweaknesses of the models, suggesting that better training and data integration\nare necessary to bridge this gap. WeatherQA link:\nhttps://github.com/chengqianma/WeatherQA.",
      "tldr_zh": "本篇论文介绍了WeatherQA数据集，这是第一个多模态数据集，旨在评估多模态语言模型在严重天气预测中的推理能力，特别是针对如冰雹、龙卷风和雷暴等事件的提前预报。数据集包含超过8000对（多图像、文本）样本，图像捕捉环境不稳定性、地表观测和雷达反射率，而文本提供人类专家的预测分析。研究设计了两个任务：多选QA预测受影响区域，以及分类严重对流发展的潜力，这些任务需要对领域知识（如大气动力学）和多模态数据的复杂推理。结果显示，顶级Vision Language Models如GPT4o与人类性能存在显著差距，并建议通过更好的训练和数据整合来弥补这一不足。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "physics.ao-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11217v2",
      "published_date": "2024-06-17 05:23:18 UTC",
      "updated_date": "2024-06-24 03:55:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:30:22.153149"
    },
    {
      "arxiv_id": "2406.11201v2",
      "title": "Fine-Tuning or Fine-Failing? Debunking Performance Myths in Large Language Models",
      "title_zh": "微调还是微调失败？ 揭穿大型语言模型中的性能神话",
      "authors": [
        "Scott Barnett",
        "Zac Brannelly",
        "Stefanus Kurniawan",
        "Sheng Wong"
      ],
      "abstract": "Large Language Models (LLMs) have the unique capability to understand and\ngenerate human-like text from input queries. When fine-tuned, these models show\nenhanced performance on domain-specific queries. OpenAI highlights the process\nof fine-tuning, stating: \"To fine-tune a model, you are required to provide at\nleast 10 examples. We typically see clear improvements from fine-tuning on 50\nto 100 training examples, but the right number varies greatly based on the\nexact use case.\" This study extends this concept to the integration of LLMs\nwithin Retrieval-Augmented Generation (RAG) pipelines, which aim to improve\naccuracy and relevance by leveraging external corpus data for information\nretrieval. However, RAG's promise of delivering optimal responses often falls\nshort in complex query scenarios. This study aims to specifically examine the\neffects of fine-tuning LLMs on their ability to extract and integrate\ncontextual data to enhance the performance of RAG systems across multiple\ndomains. We evaluate the impact of fine-tuning on the LLMs' capacity for data\nextraction and contextual understanding by comparing the accuracy and\ncompleteness of fine-tuned models against baseline performances across datasets\nfrom multiple domains. Our findings indicate that fine-tuning resulted in a\ndecline in performance compared to the baseline models, contrary to the\nimprovements observed in standalone LLM applications as suggested by OpenAI.\nThis study highlights the need for vigorous investigation and validation of\nfine-tuned models for domain-specific tasks.",
      "tldr_zh": "这篇论文质疑了在 Large Language Models (LLMs) 中 fine-tuning 的性能神话，通过实验评估其在 Retrieval-Augmented Generation (RAG) 系统中的实际效果。研究者比较了 fine-tuned 模型与基线模型在多个领域的准确性和完整性，发现 fine-tuning 反而导致性能下降，与 OpenAI 建议的改进相反。结果突显了在领域特定任务中使用 fine-tuned 模型时，需要进行更严格的调查和验证，以避免潜在失败。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11201v2",
      "published_date": "2024-06-17 04:35:17 UTC",
      "updated_date": "2024-06-30 14:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:30:32.099955"
    },
    {
      "arxiv_id": "2406.11919v2",
      "title": "Graph Knowledge Distillation to Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Pavel Rumiantsev",
        "Mark Coates"
      ],
      "abstract": "In terms of accuracy, Graph Neural Networks (GNNs) are the best architectural\nchoice for the node classification task. Their drawback in real-world\ndeployment is the latency that emerges from the neighbourhood processing\noperation. One solution to the latency issue is to perform knowledge\ndistillation from a trained GNN to a Multi-Layer Perceptron (MLP), where the\nMLP processes only the features of the node being classified (and possibly some\npre-computed structural information). However, the performance of such MLPs in\nboth transductive and inductive settings remains inconsistent for existing\nknowledge distillation techniques. We propose to address the performance\nconcerns by using a specially-designed student model instead of an MLP. Our\nmodel, named Routing-by-Memory (RbM), is a form of Mixture-of-Experts (MoE),\nwith a design that enforces expert specialization. By encouraging each expert\nto specialize on a certain region on the hidden representation space, we\ndemonstrate experimentally that it is possible to derive considerably more\nconsistent performance across multiple datasets. Code available at\nhttps://github.com/Rufaim/routing-by-memory.",
      "tldr_zh": "Graph Neural Networks (GNNs) 在节点分类任务中表现出色，但其邻居处理操作导致实际部署延迟问题。现有知识蒸馏方法从训练好的 GNNs 转移知识到 Multi-Layer Perceptron (MLP)，却在传递和归纳设置中性能不一致。为解决此问题，本文提出 Routing-by-Memory (RbM)，一种 Mixture-of-Experts (MoE) 模型，通过强制专家在隐藏表示空间的专业化，显著提升了跨多个数据集的性能一致性。实验结果表明，RbM 模型在节点分类任务上表现出更稳定的优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11919v2",
      "published_date": "2024-06-17 04:00:41 UTC",
      "updated_date": "2024-11-21 05:24:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:30:44.365613"
    },
    {
      "arxiv_id": "2406.11190v1",
      "title": "Aligning Large Language Models from Self-Reference AI Feedback with one General Principle",
      "title_zh": "翻译失败",
      "authors": [
        "Rong Bao",
        "Rui Zheng",
        "Shihan Dou",
        "Xiao Wang",
        "Enyu Zhou",
        "Bo Wang",
        "Qi Zhang",
        "Liang Ding",
        "Dacheng Tao"
      ],
      "abstract": "In aligning large language models (LLMs), utilizing feedback from existing\nadvanced AI rather than humans is an important method to scale supervisory\nsignals. However, it is highly challenging for AI to understand human\nintentions and societal values, and provide accurate preference feedback based\non these. Current AI feedback methods rely on powerful LLMs, carefully designed\nspecific principles to describe human intentions, and are easily influenced by\nposition bias. To address these issues, we propose a self-reference-based AI\nfeedback framework that enables a 13B Llama2-Chat to provide high-quality\nfeedback under simple and general principles such as ``best for humanity``.\nSpecifically, we allow the AI to first respond to the user's instructions, then\ngenerate criticism of other answers based on its own response as a reference,\nand finally determine which answer better fits human preferences according to\nthe criticism. Additionally, we use a self-consistency method to further reduce\nthe impact of position bias, and employ semantic perplexity to calculate the\npreference strength differences between different answers. Experimental results\nshow that our method enables 13B and 70B Llama2-Chat annotators to provide\nhigh-quality preference feedback, and the policy models trained based on these\npreference data achieve significant advantages in benchmark datasets through\nreinforcement learning.",
      "tldr_zh": "本研究提出了一种基于自引用 AI 反馈的框架，用于对齐大型语言模型(LLMs)，仅需一个通用原则如“best for humanity”来指导反馈生成，从而解决 AI 理解人类意图和偏好偏差的挑战。框架允许 AI 先响应用户指令，然后基于自身响应批评其他答案，并结合自一致性方法减少位置偏差，以及语义困惑度计算偏好强度差异，以提供高质量的偏好反馈。实验结果表明，使用该框架的 13B 和 70B Llama2-Chat 模型能生成可靠反馈，通过强化学习训练的政策模型在基准数据集上实现了显著性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11190v1",
      "published_date": "2024-06-17 03:51:46 UTC",
      "updated_date": "2024-06-17 03:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:30:57.428272"
    },
    {
      "arxiv_id": "2406.11179v1",
      "title": "Learning Iterative Reasoning through Energy Diffusion",
      "title_zh": "通过能量扩散学习迭代推理",
      "authors": [
        "Yilun Du",
        "Jiayuan Mao",
        "Joshua B. Tenenbaum"
      ],
      "abstract": "We introduce iterative reasoning through energy diffusion (IRED), a novel\nframework for learning to reason for a variety of tasks by formulating\nreasoning and decision-making problems with energy-based optimization. IRED\nlearns energy functions to represent the constraints between input conditions\nand desired outputs. After training, IRED adapts the number of optimization\nsteps during inference based on problem difficulty, enabling it to solve\nproblems outside its training distribution -- such as more complex Sudoku\npuzzles, matrix completion with large value magnitudes, and pathfinding in\nlarger graphs. Key to our method's success is two novel techniques: learning a\nsequence of annealed energy landscapes for easier inference and a combination\nof score function and energy landscape supervision for faster and more stable\ntraining. Our experiments show that IRED outperforms existing methods in\ncontinuous-space reasoning, discrete-space reasoning, and planning tasks,\nparticularly in more challenging scenarios. Code and visualizations at\nhttps://energy-based-model.github.io/ired/",
      "tldr_zh": "本文提出IRED框架，通过能量扩散（energy diffusion）学习迭代推理，将推理和决策问题转化为能量基优化形式。IRED学习能量函数来表示输入条件与输出之间的约束，并在推理时根据问题难度动态调整优化步骤，从而处理训练分布外的复杂任务，如更难的Sudoku谜题、大规模矩阵补全和路径查找。关键创新包括学习一系列退火能量景观（annealed energy landscapes）和结合分数函数与能量景观监督，以实现更快速、稳定的训练。实验结果表明，IRED在连续空间推理、离散空间推理和规划任务中超越现有方法，尤其在更具挑战性的场景中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024, website: https://energy-based-model.github.io/ired/",
      "pdf_url": "http://arxiv.org/pdf/2406.11179v1",
      "published_date": "2024-06-17 03:36:47 UTC",
      "updated_date": "2024-06-17 03:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:31:18.851896"
    },
    {
      "arxiv_id": "2406.11176v2",
      "title": "Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement",
      "title_zh": "监控每一步！ 通过迭代步骤级别过程精炼的 LLM 代理学习",
      "authors": [
        "Weimin Xiong",
        "Yifan Song",
        "Xiutian Zhao",
        "Wenhao Wu",
        "Xun Wang",
        "Ke Wang",
        "Cheng Li",
        "Wei Peng",
        "Sujian Li"
      ],
      "abstract": "Large language model agents have exhibited exceptional performance across a\nrange of complex interactive tasks. Recent approaches have utilized tuning with\nexpert trajectories to enhance agent performance, yet they primarily\nconcentrate on outcome rewards, which may lead to errors or suboptimal actions\ndue to the absence of process supervision signals. In this paper, we introduce\nthe Iterative step-level Process Refinement (IPR) framework, which provides\ndetailed step-by-step guidance to enhance agent training. Specifically, we\nadopt the Monte Carlo method to estimate step-level rewards. During each\niteration, the agent explores along the expert trajectory and generates new\nactions. These actions are then evaluated against the corresponding step of\nexpert trajectory using step-level rewards. Such comparison helps identify\ndiscrepancies, yielding contrastive action pairs that serve as training data\nfor the agent. Our experiments on three complex agent tasks demonstrate that\nour framework outperforms a variety of strong baselines. Moreover, our\nanalytical findings highlight the effectiveness of IPR in augmenting action\nefficiency and its applicability to diverse models.",
      "tldr_zh": "该论文提出 Iterative step-level Process Refinement (IPR) 框架，以提升大型语言模型 (LLM) 代理在复杂交互任务中的表现，通过提供详细的步级指导来弥补传统方法仅关注结果奖励的不足。IPR 框架采用 Monte Carlo 方法估计步级奖励，让代理沿专家轨迹探索生成新动作，并通过与专家动作的比较创建对比动作对作为训练数据。实验结果显示，该框架在三个复杂代理任务上优于多种基线，提升了动作效率，并证明其适用于不同模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2406.11176v2",
      "published_date": "2024-06-17 03:29:13 UTC",
      "updated_date": "2024-09-24 10:01:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:31:20.662876"
    },
    {
      "arxiv_id": "2406.15480v2",
      "title": "On Giant's Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghao Fan",
        "Zhenyi Lu",
        "Wei Wei",
        "Jie Tian",
        "Xiaoye Qu",
        "Dangyang Chen",
        "Yu Cheng"
      ],
      "abstract": "Efficient fine-tuning of large language models for task-specific applications\nis imperative, yet the vast number of parameters in these models makes their\ntraining increasingly challenging. Despite numerous proposals for effective\nmethods, a substantial memory overhead remains for gradient computations during\nupdates. \\thm{Can we fine-tune a series of task-specific small models and\ntransfer their knowledge directly to a much larger model without additional\ntraining?} In this paper, we explore weak-to-strong specialization using logit\narithmetic, facilitating a direct answer to this question. Existing\nweak-to-strong methods often employ a static knowledge transfer ratio and a\nsingle small model for transferring complex knowledge, which leads to\nsuboptimal performance. % To address this, To surmount these limitations, we\npropose a dynamic logit fusion approach that works with a series of\ntask-specific small models, each specialized in a different task. This method\nadaptively allocates weights among these models at each decoding step, learning\nthe weights through Kullback-Leibler divergence constrained optimization\nproblems. We conduct extensive experiments across various benchmarks in both\nsingle-task and multi-task settings, achieving leading results. By transferring\nexpertise from the 7B model to the 13B model, our method closes the performance\ngap by 96.4\\% in single-task scenarios and by 86.3\\% in multi-task scenarios\ncompared to full fine-tuning of the 13B model. Notably, we achieve surpassing\nperformance on unseen tasks. Moreover, we further demonstrate that our method\ncan effortlessly integrate in-context learning for single tasks and task\narithmetic for multi-task scenarios.",
      "tldr_zh": "本研究探讨了高效微调大型语言模型（LLMs）的挑战，提出了一种名为“On Giant's Shoulders”的弱到强（weak-to-strong）方法，通过动态 logits fusion 技术，从多个任务特定的小模型中转移知识到大模型，而无需额外训练。该方法使用一系列小模型（如7B模型），在每个解码步骤动态分配权重，并通过Kullback-Leibler divergence 约束优化来学习这些权重，从而克服了现有方法的静态转移和单一模型限制。实验结果显示，在单任务场景中，该方法将7B模型的知识转移到13B模型，缩小了与完整微调的性能差距达96.4%；在多任务场景中，差距缩小至86.3%，并在未见任务上表现出色。此外，该方法还无缝整合了in-context learning和task arithmetic，提升了LLMs的多任务适应性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15480v2",
      "published_date": "2024-06-17 03:07:41 UTC",
      "updated_date": "2024-10-14 11:31:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:31:32.813178"
    },
    {
      "arxiv_id": "2406.12935v2",
      "title": "ChatBug: A Common Vulnerability of Aligned LLMs Induced by Chat Templates",
      "title_zh": "翻译失败",
      "authors": [
        "Fengqing Jiang",
        "Zhangchen Xu",
        "Luyao Niu",
        "Bill Yuchen Lin",
        "Radha Poovendran"
      ],
      "abstract": "Large language models (LLMs) are expected to follow instructions from users\nand engage in conversations. Techniques to enhance LLMs' instruction-following\ncapabilities typically fine-tune them using data structured according to a\npredefined chat template. Although chat templates are shown to be effective in\noptimizing LLM performance, their impact on safety alignment of LLMs has been\nless understood, which is crucial for deploying LLMs safely at scale.\n  In this paper, we investigate how chat templates affect safety alignment of\nLLMs. We identify a common vulnerability, named ChatBug, that is introduced by\nchat templates. Our key insight to identify ChatBug is that the chat templates\nprovide a rigid format that need to be followed by LLMs, but not by users.\nHence, a malicious user may not necessarily follow the chat template when\nprompting LLMs. Instead, malicious users could leverage their knowledge of the\nchat template and accordingly craft their prompts to bypass safety alignments\nof LLMs. We develop two attacks to exploit the ChatBug vulnerability. We\ndemonstrate that a malicious user can exploit the ChatBug vulnerability of\neight state-of-the-art (SOTA) LLMs and effectively elicit unintended responses\nfrom these models. Moreover, we show that ChatBug can be exploited by existing\njailbreak attacks to enhance their attack success rates. We investigate\npotential countermeasures to ChatBug. Our results show that while adversarial\ntraining effectively mitigates the ChatBug vulnerability, the victim model\nincurs significant performance degradation. These results highlight the\ntrade-off between safety alignment and helpfulness. Developing new methods for\ninstruction tuning to balance this trade-off is an open and critical direction\nfor future research",
      "tldr_zh": "该论文揭示了ChatBug，一种由聊天模板引入的常见漏洞，影响了已对齐的大型语言模型(LLMs)的安全性能。研究发现，聊天模板强制模型遵循特定格式，但恶意用户可不遵守模板，通过精心设计的提示绕过安全对齐机制。作者开发了两种攻击方法，并在八个SOTA LLMs上验证了ChatBug的有效性，这些攻击能显著提升越狱攻击的成功率。最终，论文探讨了对抗训练等countermeasures，但指出这会导致模型性能下降，强调未来需开发新指令调优方法以平衡安全与帮助性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper is accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.12935v2",
      "published_date": "2024-06-17 03:03:34 UTC",
      "updated_date": "2025-01-07 04:42:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:31:44.337689"
    },
    {
      "arxiv_id": "2406.11161v2",
      "title": "Emotion-LLaMA: Multimodal Emotion Recognition and Reasoning with Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Zebang Cheng",
        "Zhi-Qi Cheng",
        "Jun-Yan He",
        "Jingdong Sun",
        "Kai Wang",
        "Yuxiang Lin",
        "Zheng Lian",
        "Xiaojiang Peng",
        "Alexander Hauptmann"
      ],
      "abstract": "Accurate emotion perception is crucial for various applications, including\nhuman-computer interaction, education, and counseling. However, traditional\nsingle-modality approaches often fail to capture the complexity of real-world\nemotional expressions, which are inherently multimodal. Moreover, existing\nMultimodal Large Language Models (MLLMs) face challenges in integrating audio\nand recognizing subtle facial micro-expressions. To address this, we introduce\nthe MERR dataset, containing 28,618 coarse-grained and 4,487 fine-grained\nannotated samples across diverse emotional categories. This dataset enables\nmodels to learn from varied scenarios and generalize to real-world\napplications. Furthermore, we propose Emotion-LLaMA, a model that seamlessly\nintegrates audio, visual, and textual inputs through emotion-specific encoders.\nBy aligning features into a shared space and employing a modified LLaMA model\nwith instruction tuning, Emotion-LLaMA significantly enhances both emotional\nrecognition and reasoning capabilities. Extensive evaluations show\nEmotion-LLaMA outperforms other MLLMs, achieving top scores in Clue Overlap\n(7.83) and Label Overlap (6.25) on EMER, an F1 score of 0.9036 on MER2023-SEMI\nchallenge, and the highest UAR (45.59) and WAR (59.37) in zero-shot evaluations\non DFEW dataset.",
      "tldr_zh": "该论文针对多模态情感表达的复杂性，指出传统单模态方法和现有 Multimodal Large Language Models (MLLMs) 在音频整合及微表情识别上存在挑战。研究者引入了 MERR 数据集，包含28,618个粗粒度和4,487个细粒度标注样本，以支持模型在多样场景下的学习和泛化。Emotion-LLaMA 模型通过 emotion-specific encoders 整合音频、视觉和文本输入，并采用修改后的 LLaMA 模型结合 instruction tuning，提升了情感识别和推理能力。在评估中，Emotion-LLaMA 表现出色，获得 EMER 上的 Clue Overlap 7.83 和 Label Overlap 6.25、MER2023-SEMI 挑战的 F1 分数 0.9036，以及 DFEW 数据集零样本评估中的最高 UAR 45.59 和 WAR 59.37。",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2024. 49 pages, 13 figures, Project:\n  https://github.com/ZebangCheng/Emotion-LLaMA, Demo:\n  https://huggingface.co/spaces/ZebangCheng/Emotion-LLaMA",
      "pdf_url": "http://arxiv.org/pdf/2406.11161v2",
      "published_date": "2024-06-17 03:01:22 UTC",
      "updated_date": "2024-11-02 02:30:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:32:07.961177"
    },
    {
      "arxiv_id": "2406.11160v3",
      "title": "Context Graph",
      "title_zh": "上下文图",
      "authors": [
        "Chengjin Xu",
        "Muzhi Li",
        "Cehao Yang",
        "Xuhui Jiang",
        "Lumingyuan Tang",
        "Yiyan Qi",
        "Jian Guo"
      ],
      "abstract": "Knowledge Graphs (KGs) are foundational structures in many AI applications,\nrepresenting entities and their interrelations through triples. However,\ntriple-based KGs lack the contextual information of relational knowledge, like\ntemporal dynamics and provenance details, which are crucial for comprehensive\nknowledge representation and effective reasoning. Instead, \\textbf{Context\nGraphs} (CGs) expand upon the conventional structure by incorporating\nadditional information such as time validity, geographic location, and source\nprovenance. This integration provides a more nuanced and accurate understanding\nof knowledge, enabling KGs to offer richer insights and support more\nsophisticated reasoning processes. In this work, we first discuss the inherent\nlimitations of triple-based KGs and introduce the concept of CGs, highlighting\ntheir advantages in knowledge representation and reasoning. We then present a\ncontext graph reasoning \\textbf{CGR$^3$} paradigm that leverages large language\nmodels (LLMs) to retrieve candidate entities and related contexts, rank them\nbased on the retrieved information, and reason whether sufficient information\nhas been obtained to answer a query. Our experimental results demonstrate that\nCGR$^3$ significantly improves performance on KG completion (KGC) and KG\nquestion answering (KGQA) tasks, validating the effectiveness of incorporating\ncontextual information on KG representation and reasoning.",
      "tldr_zh": "知识图谱(Knowledge Graphs, KGs)传统上基于三元组表示实体关系，但缺少上下文信息如时间动态、地理位置和来源细节，导致知识表示和推理能力不足；本文引入Context Graphs (CGs)，通过整合这些额外信息，提供更细致准确的知识理解。作者提出CGR³范式，利用large language models (LLMs)来检索候选实体和相关上下文、对其进行排名，并判断是否获得足够信息以回答查询。实验结果表明，CGR³在KG completion (KGC)和KG question answering (KGQA)任务上显著提升性能，验证了添加上下文信息对知识图谱优化的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11160v3",
      "published_date": "2024-06-17 02:59:19 UTC",
      "updated_date": "2024-06-28 03:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:32:08.717458"
    },
    {
      "arxiv_id": "2406.11156v4",
      "title": "DELRec: Distilling Sequential Pattern to Enhance LLMs-based Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyi Zhang",
        "Guohao Sun",
        "Jinhu Lu",
        "Guanfeng Liu",
        "Xiu Susie Fang"
      ],
      "abstract": "Sequential recommendation (SR) tasks aim to predict users' next interaction\nby learning their behavior sequence and capturing the connection between users'\npast interactions and their changing preferences. Conventional SR models often\nfocus solely on capturing sequential patterns within the training data,\nneglecting the broader context and semantic information embedded in item titles\nfrom external sources. This limits their predictive power and adaptability.\nLarge language models (LLMs) have recently shown promise in SR tasks due to\ntheir advanced understanding capabilities and strong generalization abilities.\nResearchers have attempted to enhance LLMs-based recommendation performance by\nincorporating information from conventional SR models. However, previous\napproaches have encountered problems such as 1) limited textual information\nleading to poor recommendation performance, 2) incomplete understanding and\nutilization of conventional SR model information by LLMs, and 3) excessive\ncomplexity and low interpretability of LLMs-based methods. To improve the\nperformance of LLMs-based SR, we propose a novel framework, Distilling\nSequential Pattern to Enhance LLMs-based Sequential Recommendation (DELRec),\nwhich aims to extract knowledge from conventional SR models and enable LLMs to\neasily comprehend and utilize the extracted knowledge for more effective SRs.\nDELRec consists of two main stages: 1) Distill Pattern from Conventional SR\nModels, focusing on extracting behavioral patterns exhibited by conventional SR\nmodels using soft prompts through two well-designed strategies; 2) LLMs-based\nSequential Recommendation, aiming to fine-tune LLMs to effectively use the\ndistilled auxiliary information to perform SR tasks. Extensive experimental\nresults conducted on four real datasets validate the effectiveness of the\nDELRec framework.",
      "tldr_zh": "顺序推荐（SR）任务旨在通过学习用户行为序列来预测下一互动，但传统模型往往忽略外部来源的语义信息，导致预测能力有限，而基于大型语言模型（LLMs）的SR方法则面临信息不足和利用不完全的问题。论文提出了一种新框架DELRec，通过从传统SR模型中提炼顺序模式（使用软提示和两种策略），并将这些知识转化为LLMs易于理解的形式，以提升SR性能。该框架分为两个阶段：首先提炼行为模式，其次微调LLMs以有效利用提炼的信息。在四个真实数据集上的广泛实验验证了DELRec的有效性，展示了其在提升推荐准确性和可解释性方面的优势。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2406.11156v4",
      "published_date": "2024-06-17 02:47:09 UTC",
      "updated_date": "2024-12-18 12:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:32:21.725845"
    },
    {
      "arxiv_id": "2406.15479v2",
      "title": "Twin-Merging: Dynamic Integration of Modular Expertise in Model Merging",
      "title_zh": "Twin-Merging：模型合并中的模块化专长的动态整合",
      "authors": [
        "Zhenyi Lu",
        "Chenghao Fan",
        "Wei Wei",
        "Xiaoye Qu",
        "Dangyang Chen",
        "Yu Cheng"
      ],
      "abstract": "In the era of large language models, model merging is a promising way to\ncombine multiple task-specific models into a single multitask model without\nextra training. However, two challenges remain: (a) interference between\ndifferent models and (b) heterogeneous data during testing. Traditional model\nmerging methods often show significant performance gaps compared to fine-tuned\nmodels due to these issues. Additionally, a one-size-fits-all model lacks\nflexibility for diverse test data, leading to performance degradation. We show\nthat both shared and exclusive task-specific knowledge are crucial for merging\nperformance, but directly merging exclusive knowledge hinders overall\nperformance. In view of this, we propose Twin-Merging, a method that\nencompasses two principal stages: (1) modularizing knowledge into shared and\nexclusive components, with compression to reduce redundancy and enhance\nefficiency; (2) dynamically merging shared and task-specific knowledge based on\nthe input. This approach narrows the performance gap between merged and\nfine-tuned models and improves adaptability to heterogeneous data. Extensive\nexperiments on $20$ datasets for both language and vision tasks demonstrate the\neffectiveness of our method, showing an average improvement of $28.34\\%$ in\nabsolute normalized score for discriminative tasks and even surpassing the\nfine-tuned upper bound on the generative tasks. Our implementation is available\nin \\url{https://github.com/LZY-the-boys/Twin-Merging}",
      "tldr_zh": "在大型语言模型时代，模型合并(model merging)面临模型间干扰和测试数据异质性的挑战，为此本文提出Twin-Merging方法。该方法包括两个关键阶段：首先，将知识模块化为共享和专属组件并进行压缩以减少冗余；其次，根据输入动态合并这些知识，以提升模型的适应性和性能。实验在20个语言和视觉任务数据集上验证了其有效性，平均提高了28.34%的标准化分数，并在生成任务上超过了微调模型的上限。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 poster",
      "pdf_url": "http://arxiv.org/pdf/2406.15479v2",
      "published_date": "2024-06-17 02:31:55 UTC",
      "updated_date": "2024-10-14 04:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:32:35.550832"
    },
    {
      "arxiv_id": "2406.11148v3",
      "title": "Few-Shot Recognition via Stage-Wise Retrieval-Augmented Finetuning",
      "title_zh": "少样本识别通过阶段式检索增强微调",
      "authors": [
        "Tian Liu",
        "Huixin Zhang",
        "Shubham Parashar",
        "Shu Kong"
      ],
      "abstract": "Few-shot recognition (FSR) aims to train a classification model with only a\nfew labeled examples of each concept concerned by a downstream task, where data\nannotation cost can be prohibitively high. We develop methods to solve FSR by\nleveraging a pretrained Vision-Language Model (VLM). We particularly explore\nretrieval-augmented learning (RAL), which retrieves open data, e.g., the VLM's\npretraining dataset, to learn models for better serving downstream tasks. RAL\nhas been studied in zero-shot recognition but remains under-explored in FSR.\nAlthough applying RAL to FSR may seem straightforward, we observe interesting\nand novel challenges and opportunities. First, somewhat surprisingly,\nfinetuning a VLM on a large amount of retrieved data underperforms\nstate-of-the-art zero-shot methods. This is due to the imbalanced distribution\nof retrieved data and its domain gaps with the few-shot examples in the\ndownstream task. Second, more surprisingly, we find that simply finetuning a\nVLM solely on few-shot examples significantly outperforms previous FSR methods,\nand finetuning on the mix of retrieved and few-shot data yields even better\nresults. Third, to mitigate the imbalanced distribution and domain gap issues,\nwe propose Stage-Wise retrieval-Augmented fineTuning (SWAT), which involves\nend-to-end finetuning on mixed data in the first stage and retraining the\nclassifier on the few-shot data in the second stage. Extensive experiments on\nnine popular benchmarks demonstrate that SWAT significantly outperforms\nprevious methods by >6% accuracy.",
      "tldr_zh": "这篇论文针对 Few-Shot Recognition (FSR) 问题，提出了一种利用预训练 Vision-Language Model (VLM) 和 Retrieval-Augmented Learning (RAL) 的方法，以少量标记样本训练分类模型。研究发现，直接在检索数据上微调 VLM 效果不如零样本方法，由于数据分布不平衡和领域差距，但仅在少样本上微调已优于现有 FSR 方法，而混合数据微调进一步提升性能。为解决这些挑战，作者开发了 Stage-Wise retrieval-Augmented fineTuning (SWAT) 方法，包括第一阶段在混合数据上端到端微调，以及第二阶段在少样本上重新训练分类器。在九个基准测试上，SWAT 比之前方法提高了超过 6% 的准确率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025. Website and code:\n  https://tian1327.github.io/SWAT/",
      "pdf_url": "http://arxiv.org/pdf/2406.11148v3",
      "published_date": "2024-06-17 02:27:14 UTC",
      "updated_date": "2025-03-21 20:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:32:46.725133"
    },
    {
      "arxiv_id": "2406.11147v2",
      "title": "Vul-RAG: Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG",
      "title_zh": "Vul-RAG：通过知识级 RAG 增强",
      "authors": [
        "Xueying Du",
        "Geng Zheng",
        "Kaixin Wang",
        "Jiayi Feng",
        "Wentai Deng",
        "Mingwei Liu",
        "Bihuan Chen",
        "Xin Peng",
        "Tao Ma",
        "Yiling Lou"
      ],
      "abstract": "Vulnerability detection is essential for software quality assurance. In\nrecent years, deep learning models (especially large language models) have\nshown promise in vulnerability detection. In this work, we propose a novel\nLLM-based vulnerability detection technique Vul-RAG, which leverages\nknowledge-level retrieval-augmented generation (RAG) framework to detect\nvulnerability for the given code in three phases. First, Vul-RAG constructs a\nvulnerability knowledge base by extracting multi-dimension knowledge via LLMs\nfrom existing CVE instances; second, for a given code snippet, Vul-RAG}\nretrieves the relevant vulnerability knowledge from the constructed knowledge\nbase based on functional semantics; third, Vul-RAG leverages LLMs to check the\nvulnerability of the given code snippet by reasoning the presence of\nvulnerability causes and fixing solutions of the retrieved vulnerability\nknowledge. Our evaluation of Vul-RAG on our constructed benchmark PairVul shows\nthat Vul-RAG substantially outperforms all baselines by 12.96\\%/110\\% relative\nimprovement in accuracy/pairwise-accuracy. In addition, our user study shows\nthat the vulnerability knowledge generated by Vul-RAG can serve as high-quality\nexplanations which can improve the manual detection accuracy from 0.60 to 0.77.",
      "tldr_zh": "本研究提出Vul-RAG，一种基于LLM的漏洞检测技术，通过知识级别的RAG框架提升检测性能。该框架分为三个阶段：首先，从现有CVE实例中提取多维度知识构建漏洞知识库；其次，对给定代码片段基于功能语义检索相关知识；最后，利用LLMs推理检索到的漏洞成因和修复方案以检查代码漏洞。在PairVul基准测试中，Vul-RAG相较基线模型准确率和配对准确率分别提升12.96%和110%，此外，用户研究显示其生成的漏洞知识可作为高质量解释，将手动检测准确率从0.60提高至0.77。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11147v2",
      "published_date": "2024-06-17 02:25:45 UTC",
      "updated_date": "2024-06-19 17:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:32:57.458686"
    },
    {
      "arxiv_id": "2406.11143v2",
      "title": "Scorecards for Synthetic Medical Data Evaluation and Reporting",
      "title_zh": "用于合成医疗数据评估和报告的评分卡",
      "authors": [
        "Ghada Zamzmi",
        "Adarsh Subbaswamy",
        "Elena Sizikova",
        "Edward Margerrison",
        "Jana Delfino",
        "Aldo Badano"
      ],
      "abstract": "Although interest in synthetic medical data (SMD) for training and testing AI\nmethods is growing, the absence of a standardized framework to evaluate its\nquality and applicability hinders its wider adoption. Here, we outline an\nevaluation framework designed to meet the unique requirements of medical\napplications, and introduce SMD Card, which can serve as comprehensive reports\nthat accompany artificially generated datasets. This card provides a\ntransparent and standardized framework for evaluating and reporting the quality\nof synthetic data, which can benefit SMD developers, users, and regulators,\nparticularly for AI models using SMD in regulatory submissions.",
      "tldr_zh": "该研究指出，虽然合成医疗数据（Synthetic Medical Data, SMD）在AI训练和测试中的兴趣日益增长，但缺乏标准化评估框架阻碍了其广泛采用。为解决这一问题，研究提出一个专为医疗应用设计的评估框架，并引入SMD Card作为全面报告工具，以透明方式评估和报告合成数据的质量。SMD Card能为SMD开发者、用户和监管者提供标准化支持，特别是当AI模型使用SMD进行监管提交时，从而提升数据的适用性和可信度。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11143v2",
      "published_date": "2024-06-17 02:11:59 UTC",
      "updated_date": "2024-12-04 00:18:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:33:08.354847"
    },
    {
      "arxiv_id": "2406.11138v2",
      "title": "Diffusion Models in Low-Level Vision: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Chunming He",
        "Yuqi Shen",
        "Chengyu Fang",
        "Fengyang Xiao",
        "Longxiang Tang",
        "Yulun Zhang",
        "Wangmeng Zuo",
        "Zhenhua Guo",
        "Xiu Li"
      ],
      "abstract": "Deep generative models have garnered significant attention in low-level\nvision tasks due to their generative capabilities. Among them, diffusion\nmodel-based solutions, characterized by a forward diffusion process and a\nreverse denoising process, have emerged as widely acclaimed for their ability\nto produce samples of superior quality and diversity. This ensures the\ngeneration of visually compelling results with intricate texture information.\nDespite their remarkable success, a noticeable gap exists in a comprehensive\nsurvey that amalgamates these pioneering diffusion model-based works and\norganizes the corresponding threads. This paper proposes the comprehensive\nreview of diffusion model-based techniques. We present three generic diffusion\nmodeling frameworks and explore their correlations with other deep generative\nmodels, establishing the theoretical foundation. Following this, we introduce a\nmulti-perspective categorization of diffusion models, considering both the\nunderlying framework and the target task. Additionally, we summarize extended\ndiffusion models applied in other tasks, including medical, remote sensing, and\nvideo scenarios. Moreover, we provide an overview of commonly used benchmarks\nand evaluation metrics. We conduct a thorough evaluation, encompassing both\nperformance and efficiency, of diffusion model-based techniques in three\nprominent tasks. Finally, we elucidate the limitations of current diffusion\nmodels and propose seven intriguing directions for future research. This\ncomprehensive examination aims to facilitate a profound understanding of the\nlandscape surrounding denoising diffusion models in the context of low-level\nvision tasks. A curated list of diffusion model-based techniques in over 20\nlow-level vision tasks can be found at\nhttps://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision.",
      "tldr_zh": "这篇论文对扩散模型(Diffusion Models)在低级视觉(Low-Level Vision)任务中的应用进行了全面调查，强调了这些模型通过前向扩散和反向去噪过程生成高质量、多样化的样本。作者提出了三个泛化扩散建模框架，并探讨了它们与其他深度生成模型的关联，同时从框架和任务角度对扩散模型进行了多视角分类。论文还总结了扩散模型在医疗、遥感及视频等领域的扩展应用，并评估了其在三大关键任务中的性能和效率。最终，论文指出了当前模型的局限性，并提出了七个未来研究方向，以推动低级视觉领域的创新。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IEEE TPAMI",
      "pdf_url": "http://arxiv.org/pdf/2406.11138v2",
      "published_date": "2024-06-17 01:49:27 UTC",
      "updated_date": "2025-02-25 03:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:33:20.740201"
    },
    {
      "arxiv_id": "2406.11135v1",
      "title": "Towards Understanding Emotions for Engaged Mental Health Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Kellie Yu Hui Sim",
        "Kohleen Tijing Fortuno",
        "Kenny Tsu Wei Choo"
      ],
      "abstract": "Providing timely support and intervention is crucial in mental health\nsettings. As the need to engage youth comfortable with texting increases,\nmental health providers are exploring and adopting text-based media such as\nchatbots, community-based forums, online therapies with licensed professionals,\nand helplines operated by trained responders. To support these text-based media\nfor mental health--particularly for crisis care--we are developing a system to\nperform passive emotion-sensing using a combination of keystroke dynamics and\nsentiment analysis. Our early studies of this system posit that the analysis of\nshort text messages and keyboard typing patterns can provide emotion\ninformation that may be used to support both clients and responders. We use our\npreliminary findings to discuss the way forward for applying AI to support\nmental health providers in providing better care.",
      "tldr_zh": "本研究探讨了在心理健康领域使用文本-based媒体（如聊天机器人和在线热线）提供及时支持的重要性，旨在通过AI技术提升与青年的互动。研究开发了一个系统，结合keystroke dynamics和sentiment analysis，对短文本消息和键盘输入模式进行被动情绪感知，以提取情绪信息并辅助客户和响应者。初步实验结果表明，这种方法能为心理健康提供者带来更有效的支持，并讨论了AI在提升护理质量方面的未来应用前景。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.2; I.2.7"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 1 figure, to be published in DIS Companion '24",
      "pdf_url": "http://arxiv.org/pdf/2406.11135v1",
      "published_date": "2024-06-17 01:27:15 UTC",
      "updated_date": "2024-06-17 01:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:33:32.555574"
    },
    {
      "arxiv_id": "2406.11132v2",
      "title": "RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents",
      "title_zh": "RePrompt：通过自动提示工程进行的大语言模型代理规划",
      "authors": [
        "Weizhe Chen",
        "Sven Koenig",
        "Bistra Dilkina"
      ],
      "abstract": "In the past year, large language models (LLMs) have had remarkable success in\ndomains outside the traditional natural language processing, and their capacity\nis further expanded into the so-called LLM agents when connected with external\ntools. In all domains, the prompt to the LLMs has been shown to make a big\ndifference in what the LLM would generate and thus affect the performance of\nthe LLM agents. Therefore, automatic prompt engineering (APE) has become an\nimportant question for many researchers and users of LLMs. However, previous\nworks in APE rely on a final checker to evaluate the performance of the given\nprompt -- a requirement that is hard to meet in the case of LLM agents, where\nintermediate feedback is easier to obtain, and the final evaluation could be\nexpensive, inaccurate, or even missing. In this paper, we propose a novel\nmethod, \\textsc{RePrompt}, which does a ``gradient descent\"-like approach to\noptimize the step-by-step instructions in the prompts given to LLM agents,\nbased on the chat history obtained from interactions and reflections with LLM\nagents. By leveraging intermediate feedback, \\textsc{RePrompt} can optimize the\nprompt without the need for a final solution checker. We evaluate our approach\non PDDL generation, TravelPlanner, and Meeting Planning to show that our method\ncould generally improve performance for different reasoning tasks.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 代理的提示工程问题，提出了一种新方法 RePrompt，通过类似于梯度下降的优化策略，根据交互和反思的聊天历史自动改进步-by-step 提示指令，从而避免了对最终解决方案检查器的依赖。RePrompt 利用中间反馈来提升 LLM 代理的性能，适用于各种推理任务。实验在 PDDL 生成、TravelPlanner 和 Meeting Planning 等场景中验证了该方法的有效性，显示了整体性能的显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11132v2",
      "published_date": "2024-06-17 01:23:11 UTC",
      "updated_date": "2025-02-13 21:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:33:44.112953"
    },
    {
      "arxiv_id": "2406.11131v2",
      "title": "Are Large Language Models a Good Replacement of Taxonomies?",
      "title_zh": "大型语言模型是否是分类体系的良好替代方案？",
      "authors": [
        "Yushi Sun",
        "Hao Xin",
        "Kai Sun",
        "Yifan Ethan Xu",
        "Xiao Yang",
        "Xin Luna Dong",
        "Nan Tang",
        "Lei Chen"
      ],
      "abstract": "Large language models (LLMs) demonstrate an impressive ability to internalize\nknowledge and answer natural language questions. Although previous studies\nvalidate that LLMs perform well on general knowledge while presenting poor\nperformance on long-tail nuanced knowledge, the community is still doubtful\nabout whether the traditional knowledge graphs should be replaced by LLMs. In\nthis paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made\nobsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies\nand at taxonomy levels that are common to people. Unfortunately, there lacks a\ncomprehensive benchmark that evaluates the LLMs over a wide range of taxonomies\nfrom common to specialized domains and at levels from root to leaf so that we\ncan draw a confident conclusion. To narrow the research gap, we constructed a\nnovel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to\nevaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten\nrepresentative taxonomies from common to specialized domains with in-depth\nexperiments of different levels of entities in this taxonomy from root to leaf.\nOur comprehensive experiments of eighteen state-of-the-art LLMs under three\nprompting settings validate that LLMs can still not well capture the knowledge\nof specialized taxonomies and leaf-level entities.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否能取代传统知识图谱的结构，即taxonomies。作者构建了一个名为TaxoGlimpse的新基准，涵盖从常见到专业领域的十个代表性taxonomies，并评估LLMs在从根到叶不同层次实体的性能。实验使用十八个最先进LLMs和三种提示设置，结果显示LLMs在专业taxonomies和叶级实体上表现不佳，表明其尚未完全取代传统知识图谱的schema。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by VLDB 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11131v2",
      "published_date": "2024-06-17 01:21:50 UTC",
      "updated_date": "2024-06-20 08:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:33:57.137411"
    },
    {
      "arxiv_id": "2406.11118v1",
      "title": "Incentivizing Quality Text Generation via Statistical Contracts",
      "title_zh": "通过统计合约激励高质量文本生成",
      "authors": [
        "Eden Saig",
        "Ohad Einav",
        "Inbal Talgam-Cohen"
      ],
      "abstract": "While the success of large language models (LLMs) increases demand for\nmachine-generated text, current pay-per-token pricing schemes create a\nmisalignment of incentives known in economics as moral hazard: Text-generating\nagents have strong incentive to cut costs by preferring a cheaper model over\nthe cutting-edge one, and this can be done \"behind the scenes\" since the agent\nperforms inference internally. In this work, we approach this issue from an\neconomic perspective, by proposing a pay-for-performance, contract-based\nframework for incentivizing quality. We study a principal-agent game where the\nagent generates text using costly inference, and the contract determines the\nprincipal's payment for the text according to an automated quality evaluation.\nSince standard contract theory is inapplicable when internal inference costs\nare unknown, we introduce cost-robust contracts. As our main theoretical\ncontribution, we characterize optimal cost-robust contracts through a direct\ncorrespondence to optimal composite hypothesis tests from statistics,\ngeneralizing a result of Saig et al. (NeurIPS'23). We evaluate our framework\nempirically by deriving contracts for a range of objectives and LLM evaluation\nbenchmarks, and find that cost-robust contracts sacrifice only a marginal\nincrease in objective value compared to their cost-aware counterparts.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)生成文本中的道德风险问题，提出一种基于统计合同的支付机制，以激励高质量输出。具体而言，他们引入了 cost-robust contracts，在 principal-agent 游戏框架下，通过自动化质量评估来确定支付，从而解决代理在内部推理成本未知时的激励失调。理论贡献包括将 optimal cost-robust contracts 与统计学中的 optimal composite hypothesis tests 对应起来，推广了 Saig et al. (NeurIPS'23) 的结果。实验评估显示，这种合同在各种 LLM 基准上仅以微小目标值损失换取显著的鲁棒性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "Comments are welcome",
      "pdf_url": "http://arxiv.org/pdf/2406.11118v1",
      "published_date": "2024-06-17 00:30:58 UTC",
      "updated_date": "2024-06-17 00:30:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:34:09.444198"
    },
    {
      "arxiv_id": "2406.11109v5",
      "title": "Investigating Annotator Bias in Large Language Models for Hate Speech Detection",
      "title_zh": "调查大型语言模型在仇恨言论检测中的标注者偏差",
      "authors": [
        "Amit Das",
        "Zheng Zhang",
        "Najib Hasan",
        "Souvika Sarkar",
        "Fatemeh Jamshidi",
        "Tathagata Bhattacharya",
        "Mostafa Rahgouy",
        "Nilanjana Raychawdhary",
        "Dongji Feng",
        "Vinija Jain",
        "Aman Chadha",
        "Mary Sandage",
        "Lauramarie Pope",
        "Gerry Dozier",
        "Cheryl Seals"
      ],
      "abstract": "Data annotation, the practice of assigning descriptive labels to raw data, is\npivotal in optimizing the performance of machine learning models. However, it\nis a resource-intensive process susceptible to biases introduced by annotators.\nThe emergence of sophisticated Large Language Models (LLMs) presents a unique\nopportunity to modernize and streamline this complex procedure. While existing\nresearch extensively evaluates the efficacy of LLMs, as annotators, this paper\ndelves into the biases present in LLMs when annotating hate speech data. Our\nresearch contributes to understanding biases in four key categories: gender,\nrace, religion, and disability with four LLMs: GPT-3.5, GPT-4o, Llama-3.1 and\nGemma-2. Specifically targeting highly vulnerable groups within these\ncategories, we analyze annotator biases. Furthermore, we conduct a\ncomprehensive examination of potential factors contributing to these biases by\nscrutinizing the annotated data. We introduce our custom hate speech detection\ndataset, HateBiasNet, to conduct this research. Additionally, we perform the\nsame experiments on the ETHOS (Mollas et al. 2022) dataset also for comparative\nanalysis. This paper serves as a crucial resource, guiding researchers and\npractitioners in harnessing the potential of LLMs for data annotation, thereby\nfostering advancements in this critical field.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在仇恨言论检测数据标注中的偏见问题，针对性别（gender）、种族（race）、宗教（religion）和残疾（disability）四类关键偏见，使用 GPT-3.5、GPT-4o、Llama-3.1 和 Gemma-2 模型进行分析。研究者引入了自定义数据集 HateBiasNet，并与 ETHOS 数据集进行比较实验，以考察偏见来源和影响因素。结果显示，这些偏见可能源于模型训练数据和设计，论文为优化 LLMs 在数据标注中的应用提供了重要指导，促进仇恨言论检测领域的公平性进步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS Safe Generative AI Workshop, 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11109v5",
      "published_date": "2024-06-17 00:18:31 UTC",
      "updated_date": "2024-11-16 18:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:34:21.943791"
    },
    {
      "arxiv_id": "2407.10984v1",
      "title": "On the Combination of AI and Wireless Technologies: 3GPP Standardization Progress",
      "title_zh": "AI 与无线技术的结合：3GPP 标准化进展",
      "authors": [
        "Chen Sun",
        "Tao Cui",
        "Wenqi Zhang",
        "Yingshuang Bai",
        "Shuo Wang",
        "Haojin Li"
      ],
      "abstract": "Combing Artificial Intelligence (AI) and wireless communication technologies\nhas become one of the major technologies trends towards 2030. This includes\nusing AI to improve the efficiency of the wireless transmission and supporting\nAI deployment with wireless networks. In this article, the latest progress of\nthe Third Generation Partnership Project (3GPP) standards development is\nintroduced. Concentrating on AI model distributed transfer and AI for Beam\nManagement (BM) with wireless network, we introduce the latest studies and\nexplain how the existing standards should be modified to incorporate the\nresults from academia.",
      "tldr_zh": "该研究探讨了 AI 与无线通信技术的结合，作为通往 2030 年的主要技术趋势，包括使用 AI 提升无线传输效率并支持 AI 在无线网络中的部署。文章重点介绍了 3GPP 标准的最新进展，特别关注 AI 模型的分布式传输和 AI for Beam Management (BM)。通过分析学术研究成果，该文说明了如何修改现有标准，以更好地整合这些创新，从而推动无线技术的优化和发展。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.10984v1",
      "published_date": "2024-06-17 00:11:04 UTC",
      "updated_date": "2024-06-17 00:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:34:33.728089"
    },
    {
      "arxiv_id": "2406.11106v1",
      "title": "From Intentions to Techniques: A Comprehensive Taxonomy and Challenges in Text Watermarking for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Nishant Lalai",
        "Aashish Anantha Ramakrishnan",
        "Raj Sanjay Shah",
        "Dongwon Lee"
      ],
      "abstract": "With the rapid growth of Large Language Models (LLMs), safeguarding textual\ncontent against unauthorized use is crucial. Text watermarking offers a vital\nsolution, protecting both - LLM-generated and plain text sources. This paper\npresents a unified overview of different perspectives behind designing\nwatermarking techniques, through a comprehensive survey of the research\nliterature. Our work has two key advantages, (1) we analyze research based on\nthe specific intentions behind different watermarking techniques, evaluation\ndatasets used, watermarking addition, and removal methods to construct a\ncohesive taxonomy. (2) We highlight the gaps and open challenges in text\nwatermarking to promote research in protecting text authorship. This extensive\ncoverage and detailed analysis sets our work apart, offering valuable insights\ninto the evolving landscape of text watermarking in language models.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)的文本水印技术，提供了一个全面的分类体系(Taxonomy)，旨在保护LLM生成文本和普通文本免受未授权使用。通过分析水印技术的意图、评估数据集、水印添加和移除方法，该研究构建了连贯的概述，并突出了现有研究中的空白和开放挑战。主要贡献在于促进未来对文本水印的研究，以加强文本作者权的保护。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11106v1",
      "published_date": "2024-06-17 00:09:31 UTC",
      "updated_date": "2024-06-17 00:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:34:45.730868"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 193,
  "processed_papers_count": 193,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T21:35:09.637513"
}