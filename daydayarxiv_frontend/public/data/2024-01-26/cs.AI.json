{
  "date": "2024-01-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-26 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 57 篇论文，主要聚焦 AI、机器学习、医疗和多模态模型等领域，重点包括大型语言模型（LLM）在内容分析和诊断中的创新应用、图神经网络的公平性和鲁棒性改进，以及医疗 AI 的实际潜力；令人印象深刻的文章有 Unlearning Traces（由 Masaru Isonuma 和 Ivan Titov 撰写，探讨语言模型的影响），以及 Enhancing Diagnostic Accuracy（利用 LLM 缓解认知偏差）。\n\n下面，我将挑选几篇重要的、话题度高的论文进行详细讨论（如 LLM 和医疗相关），并快速掠过其他次要文章。每个条目会列出论文标题（中文 + 英文），并简要描述核心贡献和发现。\n\n### 重点论文讨论\n\n**1. Unlearning Traces the Influential Training Data of Language Models（语言模型训练数据影响追踪）**  \n这篇论文由 Masaru Isonuma 和 Ivan Titov 撰写，即将在 ACL 2024 发表。论文提出 UnTrac 和 UnTrac-Inv 方法，通过梯度上升模拟“遗忘”特定数据集，评估其对语言模型性能的影响。主要贡献是高效评估训练数据的影响，而无需多次重训，显著提高准确性（比现有方法更精确），并应用于生成有毒或偏见内容的风险评估。这对 LLM 的安全性和可解释性有重要启示。\n\n**2. Scalable Qualitative Coding with LLMs: Chain-of-Thought Reasoning Matches Human Performance in Some Hermeneutic Tasks（使用 LLM 的可扩展定性编码：链式推理在某些诠释任务中匹配人类性能）**  \n论文探索 LLM（如 GPT-4）在文本内容分析中的潜力，通过链式推理（chain-of-thought）提升编码准确性。主要发现是 GPT-4 在 8/9 个代码上达到实质可靠性（Cohen's κ ≥ 0.6），优于 GPT-3.5；这为自动化内容分析提供高效工具，减少人类手动工作，并突显 LLM 在社会科学中的应用潜力。\n\n**3. Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias（通过多代理对话提升诊断准确性：使用大型语言模型缓解认知偏差）**  \n这篇医疗相关论文使用 LLM（如 GPT-4）构建多代理框架，模拟团队讨论以纠正临床决策偏差。主要贡献是框架将初始诊断准确率从 0% 提升到最终 80%（在 80 个模拟中），通过角色分工（如 devil's advocate）减少锚定偏差；这为 AI 在医疗决策中提供可行路径，提升诊断可靠性。\n\n**4. Large Language Model Adaptation for Financial Sentiment Analysis（大型语言模型在金融情感分析中的适应）**  \n论文聚焦 LLM 在金融领域的微调，提出针对金融文本的适应策略。主要发现是通过少量参数（<1.5B）微调，模型在情感分析中显著提升性能，并生成高质量合成数据；这为金融 NLP 应用提供高效方法，强调 LLM 的领域适应性。\n\n**5. FairSample: Training Fair and Accurate Graph Convolutional Neural Networks Efficiently（训练公平且准确的图卷积神经网络：FairSample 方法）**  \n在图神经网络（GCN）公平性方面，论文提出 FairSample 框架，通过图结构修正和强化学习采样策略缓解偏差。主要贡献是显著提升节点分类公平性，同时保持效率；这对处理偏置图数据（如社交网络）有实际价值，解决 GCN 在实际部署中的伦理问题。\n\n### 其他论文快速掠过\n以下论文主题多样，但相对次要，我仅列出标题（中文 + 英文）和简要贡献，不做深入分析。\n\n- **GenPluSSS: A Genetic Algorithm Based Plugin for Measured Subsurface Scattering Representation（遗传算法基于的次表面散射插件）**：提出 Blender 插件，使用遗传算法和 SVD 提升透光材料渲染效率，贡献在于高效可视化。\n- **Deep Learning with Tabular Data: A Self-supervised Approach（表格数据的深度学习：自监督方法）**：使用 TabTransformer 模型处理表格数据，自监督学习提升特征捕捉，贡献在于与基线模型比较的性能提升。\n- **Transfer Learning for the Prediction of Entity Modifiers in Clinical Text（临床文本实体修改器的迁移学习）**：应用于阿片类药物障碍检测，贡献是多任务 Transformer 提升修改器预测准确性。\n- **Do deep neural networks utilize the weight space efficiently?（深度神经网络是否高效利用权重空间？）**：提出参数减少方法，应用于 ViT 和 ResNet50，贡献在于保持性能的同时减半参数。\n- **Non-Consensual Synthetic Intimate Imagery: Prevalence, Attitudes, and Knowledge in 10 Countries（非 consensual 合成亲密图像：10 个国家的盛行率、态度和知识）**：调查深度伪造色情内容的社会影响，贡献是强调数字素养教育。\n- **Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model（基于风险感知学习成本模型的鲁棒查询优化）**：RDBMS 查询优化框架，贡献是提升鲁棒性。\n- **SCANIA Component X Dataset: A Real-World Multivariate Time Series Dataset for Predictive Maintenance（SCANIA Component X 数据集：用于预测性维护的多元时间序列数据集）**：发布卡车组件数据集，贡献在于支持机器学习应用。\n- **CAREForMe: Contextual Multi-Armed Bandit Recommendation Framework for Mental Health（心理健康的情境多臂赌博推荐框架）**：AI 推荐心理健康干预，贡献是结合移动感知和在线学习。\n- **Airavata: Introducing Hindi Instruction-tuned LLM（引入印地语指令调整 LLM）**：发布印地语 LLM，贡献是扩展 Indic 语言支持。\n- **On the Emergence of Symmetrical Reality（对称现实的出现）**：提出 AI 和虚拟现实框架，贡献是统一物理-虚拟表示。\n- **其他（如 Atmosphere、PepGB、GeoDecoder 等）**：这些论文涉及 IoT、药物发现和地图理解等领域，但影响力较小，仅贡献于特定技术改进，我在此不展开。\n\n今天的 arXiv 更新展示了 AI 在实际应用中的潜力，但也提醒我们关注公平性和鲁棒性问题。感兴趣的读者可查阅特定论文深入研究！",
  "papers": [
    {
      "arxiv_id": "2401.15245v1",
      "title": "GenPluSSS: A Genetic Algorithm Based Plugin for Measured Subsurface Scattering Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Barış Yıldırım",
        "Murat Kurt"
      ],
      "abstract": "This paper presents a plugin that adds a representation of homogeneous and\nheterogeneous, optically thick, translucent materials on the Blender 3D\nmodeling tool. The working principle of this plugin is based on a combination\nof Genetic Algorithm (GA) and Singular Value Decomposition (SVD)-based\nsubsurface scattering method (GenSSS). The proposed plugin has been implemented\nusing Mitsuba renderer, which is an open source rendering software. The\nproposed plugin has been validated on measured subsurface scattering data. It's\nshown that the proposed plugin visualizes homogeneous and heterogeneous\nsubsurface scattering effects, accurately, compactly and computationally\nefficiently.",
      "tldr_zh": "本论文提出了一种名为 GenPluSSS 的插件，利用 Genetic Algorithm (GA) 和 Singular Value Decomposition (SVD)-based subsurface scattering method (GenSSS)，在 Blender 3D 建模工具中实现同质和异质、光学稠密半透明材料的表示。插件通过结合 GA 和 SVD 方法，生成高效的子表面散射效果，并使用 Mitsuba 渲染器进行实现。该插件在测量的数据上进行验证，展示了准确、紧凑且计算高效的可视化性能，为3D 渲染中的材料模拟提供了实用工具。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15245v1",
      "published_date": "2024-01-26 23:31:53 UTC",
      "updated_date": "2024-01-26 23:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:32:44.584808"
    },
    {
      "arxiv_id": "2401.15241v2",
      "title": "Unlearning Traces the Influential Training Data of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Masaru Isonuma",
        "Ivan Titov"
      ],
      "abstract": "Identifying the training datasets that influence a language model's outputs\nis essential for minimizing the generation of harmful content and enhancing its\nperformance. Ideally, we can measure the influence of each dataset by removing\nit from training; however, it is prohibitively expensive to retrain a model\nmultiple times. This paper presents UnTrac: unlearning traces the influence of\na training dataset on the model's performance. UnTrac is extremely simple; each\ntraining dataset is unlearned by gradient ascent, and we evaluate how much the\nmodel's predictions change after unlearning. Furthermore, we propose a more\nscalable approach, UnTrac-Inv, which unlearns a test dataset and evaluates the\nunlearned model on training datasets. UnTrac-Inv resembles UnTrac, while being\nefficient for massive training datasets. In the experiments, we examine if our\nmethods can assess the influence of pretraining datasets on generating toxic,\nbiased, and untruthful content. Our methods estimate their influence much more\naccurately than existing methods while requiring neither excessive memory space\nnor multiple checkpoints.",
      "tldr_zh": "该研究提出UnTrac方法，通过unlearning技术（使用gradient ascent）来追踪语言模型训练数据的关键影响，从而减少有害内容生成并提升性能。UnTrac的核心在于针对每个训练数据集进行unlearning，并评估模型预测的变化，以量化其影响。论文进一步引入更高效的UnTrac-Inv变体，该方法unlearning一个测试数据集，然后在训练数据集上评估模型，适用于大规模数据集。实验结果显示，UnTrac及其变体在评估预训练数据集对毒性、偏见和不真实内容的影响时，比现有方法更准确，且无需过多内存或多个检查点。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, to appear in ACL2024 main conference (long paper)",
      "pdf_url": "http://arxiv.org/pdf/2401.15241v2",
      "published_date": "2024-01-26 23:17:31 UTC",
      "updated_date": "2024-06-13 16:28:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:32:57.208152"
    },
    {
      "arxiv_id": "2401.15238v1",
      "title": "Deep Learning with Tabular Data: A Self-supervised Approach",
      "title_zh": "表格数据的深度学习：一种自监督方法",
      "authors": [
        "Tirth Kiranbhai Vyas"
      ],
      "abstract": "We have described a novel approach for training tabular data using the\nTabTransformer model with self-supervised learning. Traditional machine\nlearning models for tabular data, such as GBDT are being widely used though our\npaper examines the effectiveness of the TabTransformer which is a Transformer\nbased model optimised specifically for tabular data. The TabTransformer\ncaptures intricate relationships and dependencies among features in tabular\ndata by leveraging the self-attention mechanism of Transformers. We have used a\nself-supervised learning approach in this study, where the TabTransformer\nlearns from unlabelled data by creating surrogate supervised tasks, eliminating\nthe need for the labelled data. The aim is to find the most effective\nTabTransformer model representation of categorical and numerical features. To\naddress the challenges faced during the construction of various input settings\ninto the Transformers. Furthermore, a comparative analysis is also been\nconducted to examine performance of the TabTransformer model against baseline\nmodels such as MLP and supervised TabTransformer.\n  The research has presented with a novel approach by creating various variants\nof TabTransformer model namely, Binned-TT, Vanilla-MLP-TT, MLP- based-TT which\nhas helped to increase the effective capturing of the underlying relationship\nbetween various features of the tabular dataset by constructing optimal inputs.\nAnd further we have employed a self-supervised learning approach in the form of\na masking-based unsupervised setting for tabular data. The findings shed light\non the best way to represent categorical and numerical features, emphasizing\nthe TabTransormer performance when compared to established machine learning\nmodels and other self-supervised learning methods.",
      "tldr_zh": "本研究提出了一种基于自监督学习(self-supervised learning)的创新方法，使用 TabTransformer 模型来训练表格数据。该方法通过自注意力机制(self-attention)捕捉表格特征间的复杂关系，并创建代理监督任务从无标签数据中学习，从而避免了对标注数据的依赖。研究还开发了 TabTransformer 的变体，如 Binned-TT、Vanilla-MLP-TT 和 MLP-based-TT，以优化特征表示，并通过比较分析显示，TabTransformer 在性能上优于基线模型如 GBDT 和 MLP，提升了表格数据的处理效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15238v1",
      "published_date": "2024-01-26 23:12:41 UTC",
      "updated_date": "2024-01-26 23:12:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:33:08.010109"
    },
    {
      "arxiv_id": "2401.15222v2",
      "title": "Transfer Learning for the Prediction of Entity Modifiers in Clinical Text: Application to Opioid Use Disorder Case Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullateef I. Almudaifer",
        "Whitney Covington",
        "JaMor Hairston",
        "Zachary Deitch",
        "Ankit Anand",
        "Caleb M. Carroll",
        "Estera Crisan",
        "William Bradford",
        "Lauren Walter",
        "Eaton Ellen",
        "Sue S. Feldman",
        "John D. Osborne"
      ],
      "abstract": "Background: The semantics of entities extracted from a clinical text can be\ndramatically altered by modifiers, including entity negation, uncertainty,\nconditionality, severity, and subject. Existing models for determining\nmodifiers of clinical entities involve regular expression or features weights\nthat are trained independently for each modifier.\n  Methods: We develop and evaluate a multi-task transformer architecture design\nwhere modifiers are learned and predicted jointly using the publicly available\nSemEval 2015 Task 14 corpus and a new Opioid Use Disorder (OUD) data set that\ncontains modifiers shared with SemEval as well as novel modifiers specific for\nOUD. We evaluate the effectiveness of our multi-task learning approach versus\npreviously published systems and assess the feasibility of transfer learning\nfor clinical entity modifiers when only a portion of clinical modifiers are\nshared.\n  Results: Our approach achieved state-of-the-art results on the ShARe corpus\nfrom SemEval 2015 Task 14, showing an increase of 1.1% on weighted accuracy,\n1.7% on unweighted accuracy, and 10% on micro F1 scores.\n  Conclusions: We show that learned weights from our shared model can be\neffectively transferred to a new partially matched data set, validating the use\nof transfer learning for clinical text modifiers",
      "tldr_zh": "该研究开发了一种多任务Transformer架构，用于预测临床文本中实体修改器（如否定、不确定性、条件性、严重性和主体），并将其应用于Opioid Use Disorder (OUD)病例检测。方法通过联合学习SemEval 2015 Task 14语料库和一个新OUD数据集，评估转移学习在部分共享修改器场景下的有效性。实验结果显示，该方法在ShARe语料库上实现了最先进性能，提高了加权准确率1.1%、非加权准确率1.7%和微F1分数10%。总之，该工作验证了转移学习在临床文本修改器预测中的可行性，为类似任务提供了新框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 2 figures, 6 tables. To be submitted to the Journal of\n  Biomedical Semantics",
      "pdf_url": "http://arxiv.org/pdf/2401.15222v2",
      "published_date": "2024-01-26 22:19:31 UTC",
      "updated_date": "2024-02-05 17:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:33:21.853930"
    },
    {
      "arxiv_id": "2401.16438v1",
      "title": "Do deep neural networks utilize the weight space efficiently?",
      "title_zh": "深度神经网络是否高效利用权重空间？",
      "authors": [
        "Onur Can Koyun",
        "Behçet Uğur Töreyin"
      ],
      "abstract": "Deep learning models like Transformers and Convolutional Neural Networks\n(CNNs) have revolutionized various domains, but their parameter-intensive\nnature hampers deployment in resource-constrained settings. In this paper, we\nintroduce a novel concept utilizes column space and row space of weight\nmatrices, which allows for a substantial reduction in model parameters without\ncompromising performance. Leveraging this paradigm, we achieve\nparameter-efficient deep learning models.. Our approach applies to both\nBottleneck and Attention layers, effectively halving the parameters while\nincurring only minor performance degradation. Extensive experiments conducted\non the ImageNet dataset with ViT and ResNet50 demonstrate the effectiveness of\nour method, showcasing competitive performance when compared to traditional\nmodels. This approach not only addresses the pressing demand for parameter\nefficient deep learning solutions but also holds great promise for practical\ndeployment in real-world scenarios.",
      "tldr_zh": "本研究探讨了深度神经网络是否高效利用权重空间，针对 Transformers 和 CNNs 等参数密集模型在资源受限环境下的部署挑战，提出了一种利用权重矩阵的列空间和行空间概念的新方法，以显著减少模型参数而不牺牲性能。该方法适用于 Bottleneck 和 Attention layers，能够将参数减少一半，同时仅导致轻微性能下降。在 ImageNet 数据集上进行的实验显示，ViT 和 ResNet50 模型在使用该方法后，与传统模型相比表现出竞争性性能，从而为实际场景中的参数高效深度学习解决方案提供了重要途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16438v1",
      "published_date": "2024-01-26 21:51:49 UTC",
      "updated_date": "2024-01-26 21:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:33:33.037652"
    },
    {
      "arxiv_id": "2402.01721v2",
      "title": "Non-Consensual Synthetic Intimate Imagery: Prevalence, Attitudes, and Knowledge in 10 Countries",
      "title_zh": "翻译失败",
      "authors": [
        "Rebecca Umbach",
        "Nicola Henry",
        "Gemma Beard",
        "Colleen Berryessa"
      ],
      "abstract": "Deepfake technologies have become ubiquitous, \"democratizing\" the ability to\nmanipulate photos and videos. One popular use of deepfake technology is the\ncreation of sexually explicit content, which can then be posted and shared\nwidely on the internet. Drawing on a survey of over 16,000 respondents in 10\ndifferent countries, this article examines attitudes and behaviors related to\n\"deepfake pornography\" as a specific form of non-consensual synthetic intimate\nimagery (NSII). Our study found that deepfake pornography behaviors were\nconsidered harmful by respondents, despite nascent societal awareness.\nRegarding the prevalence of deepfake porn victimization and perpetration, 2.2%\nof all respondents indicated personal victimization, and 1.8% all of\nrespondents indicated perpetration behaviors. Respondents from countries with\nspecific legislation still reported perpetration and victimization experiences,\nsuggesting NSII laws are inadequate to deter perpetration. Approaches to\nprevent and reduce harms may include digital literacy education, as well as\nenforced platform policies, practices, and tools which better detect, prevent,\nand respond to NSII content.",
      "tldr_zh": "这篇论文通过对10个国家超过16,000名受访者的调查，探讨了non-consensual synthetic intimate imagery (NSII)，特别是deepfake pornography的流行率、态度和知识。结果显示，2.2%的受访者报告自己是受害者，1.8%报告有过肇事行为，且即使在有特定立法的国家，这种行为仍未有效减少，表明现有法律不足以遏制。研究强调，受访者普遍认为deepfake pornography有害，并建议通过数字素养教育以及平台政策和工具来检测、预防和应对NSII内容，以减少相关危害。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01721v2",
      "published_date": "2024-01-26 21:51:49 UTC",
      "updated_date": "2024-02-13 22:26:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:33:46.029011"
    },
    {
      "arxiv_id": "2401.15210v2",
      "title": "Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model",
      "title_zh": "Ro",
      "authors": [
        "Amin Kamali",
        "Verena Kantere",
        "Calisto Zuzarte",
        "Vincent Corvinelli"
      ],
      "abstract": "Query optimizers in RDBMSs search for execution plans expected to be optimal\nfor given queries. They use parameter estimates, often inaccurate, and make\nassumptions that may not hold in practice. Consequently, they may select plans\nthat are suboptimal at runtime, if estimates and assumptions are not valid.\nTherefore, they do not sufficiently support robust query optimization. Using ML\nto improve data systems has shown promising results for query optimization.\nInspired by this, we propose Robust Query Optimizer, (Roq), a holistic\nframework based on a risk-aware learning approach. Roq includes a novel\nformalization of the notion of robustness in the context of query optimization\nand a principled approach for its quantification and measurement based on\napproximate probabilistic ML. It also includes novel strategies and algorithms\nfor query plan evaluation and selection. Roq includes a novel learned cost\nmodel that is designed to predict the cost of query execution and the\nassociated risks and performs query optimization accordingly. We demonstrate\nthat Roq provides significant improvements in robust query optimization\ncompared with the state-of-the-art.",
      "tldr_zh": "本文提出 Roq，一种基于风险感知学习成本模型的鲁棒查询优化框架，旨在解决传统 RDBMS 查询优化器因参数估计不准确而选择次优执行计划的问题。Roq 包括对查询优化鲁棒性的新定义、基于近似概率 ML 的量化方法，以及创新的查询计划评估和选择算法；其核心是新型学习成本模型，用于预测查询执行成本和相关风险。实验结果显示，Roq 与现有技术相比，在鲁棒查询优化方面取得了显著改进。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "14 pages, 9 figures, submitted to VLDB 2025",
      "pdf_url": "http://arxiv.org/pdf/2401.15210v2",
      "published_date": "2024-01-26 21:16:37 UTC",
      "updated_date": "2025-03-07 21:02:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:33:57.491818"
    },
    {
      "arxiv_id": "2401.15199v2",
      "title": "SCANIA Component X Dataset: A Real-World Multivariate Time Series Dataset for Predictive Maintenance",
      "title_zh": "SCANIA Component X 数据集：真实世界的多变量时间序列数据集，用于预测性维护",
      "authors": [
        "Zahra Kharazian",
        "Tony Lindgren",
        "Sindri Magnússon",
        "Olof Steinert",
        "Oskar Andersson Reyna"
      ],
      "abstract": "Predicting failures and maintenance time in predictive maintenance is\nchallenging due to the scarcity of comprehensive real-world datasets, and among\nthose available, few are of time series format. This paper introduces a\nreal-world, multivariate time series dataset collected exclusively from a\nsingle anonymized engine component (Component X) across a fleet of SCANIA\ntrucks. The dataset includes operational data, repair records, and\nspecifications related to Component X, while maintaining confidentiality\nthrough anonymization. It is well-suited for a range of machine learning\napplications, including classification, regression, survival analysis, and\nanomaly detection, particularly in predictive maintenance scenarios. The\ndataset's large population size, diverse features (in the form of histograms\nand numerical counters), and temporal information make it a unique resource in\nthe field. The objective of releasing this dataset is to give a broad range of\nresearchers the possibility of working with real-world data from an\ninternationally well-known company and introduce a standard benchmark to the\npredictive maintenance field, fostering reproducible research.",
      "tldr_zh": "这篇论文介绍了SCANIA Component X Dataset，这是一个真实世界的多变量时间序列数据集，专注于预测性维护领域。该数据集来自SCANIA卡车车队的一个匿名化引擎组件（Component X），包括操作数据、维修记录和组件规格，通过匿名化确保机密性。该数据集具有大规模样本、多样特征（如直方图和数值计数器）以及时间信息，适用于机器学习任务如分类、回归、生存分析和异常检测。发布该数据集的目的是为研究者提供国际知名公司的真实数据，建立预测性维护领域的标准基准，促进可重复研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.15199v2",
      "published_date": "2024-01-26 20:51:55 UTC",
      "updated_date": "2025-03-10 09:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:34:08.656177"
    },
    {
      "arxiv_id": "2401.15196v3",
      "title": "Regularized Q-Learning with Linear Function Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Xi",
        "Alfredo Garcia",
        "Petar Momcilovic"
      ],
      "abstract": "Regularized Markov Decision Processes serve as models of sequential decision\nmaking under uncertainty wherein the decision maker has limited information\nprocessing capacity and/or aversion to model ambiguity. With functional\napproximation, the convergence properties of learning algorithms for\nregularized MDPs (e.g. soft Q-learning) are not well understood because the\ncomposition of the regularized Bellman operator and a projection onto the span\nof basis vectors is not a contraction with respect to any norm. In this paper,\nwe consider a bi-level optimization formulation of regularized Q-learning with\nlinear functional approximation. The {\\em lower} level optimization problem\naims to identify a value function approximation that satisfies Bellman's\nrecursive optimality condition and the {\\em upper} level aims to find the\nprojection onto the span of basis vectors. This formulation motivates a\nsingle-loop algorithm with finite time convergence guarantees. The algorithm\noperates on two time-scales: updates to the projection of state-action values\nare `slow' in that they are implemented with a step size that is smaller than\nthe one used for `faster' updates of approximate solutions to Bellman's\nrecursive optimality equation. We show that, under certain assumptions, the\nproposed algorithm converges to a stationary point in the presence of Markovian\nnoise. In addition, we provide a performance guarantee for the policies derived\nfrom the proposed algorithm.",
      "tldr_zh": "这篇论文针对Regularized Markov Decision Processes (RMDPs)提出了一种使用Linear Function Approximation的Regularized Q-Learning算法，以处理决策者有限信息处理能力和模型模糊性问题。算法采用双层优化公式，其中下层优化求解满足Bellman递归最优性条件的价值函数逼近，上层优化寻找投影到基向量张成空间。实验结果表明，该单循环算法通过两时间尺度更新（较慢的投影更新和较快的Bellman方程近似解更新）在Markovian噪声下收敛到平稳点，并为从中导出的策略提供可靠的性能保证。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15196v3",
      "published_date": "2024-01-26 20:45:40 UTC",
      "updated_date": "2025-02-10 17:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:34:22.542026"
    },
    {
      "arxiv_id": "2401.15188v1",
      "title": "CAREForMe: Contextual Multi-Armed Bandit Recommendation Framework for Mental Health",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng Yu",
        "Narjes Nourzad",
        "Randye J. Semple",
        "Yixue Zhao",
        "Emily Zhou",
        "Bhaskar Krishnamachari"
      ],
      "abstract": "The COVID-19 pandemic has intensified the urgency for effective and\naccessible mental health interventions in people's daily lives. Mobile Health\n(mHealth) solutions, such as AI Chatbots and Mindfulness Apps, have gained\ntraction as they expand beyond traditional clinical settings to support daily\nlife. However, the effectiveness of current mHealth solutions is impeded by the\nlack of context-awareness, personalization, and modularity to foster their\nreusability. This paper introduces CAREForMe, a contextual multi-armed bandit\n(CMAB) recommendation framework for mental health. Designed with\ncontext-awareness, personalization, and modularity at its core, CAREForMe\nharnesses mobile sensing and integrates online learning algorithms with user\nclustering capability to deliver timely, personalized recommendations. With its\nmodular design, CAREForMe serves as both a customizable recommendation\nframework to guide future research, and a collaborative platform to facilitate\ninterdisciplinary contributions in mHealth research. We showcase CAREForMe's\nversatility through its implementation across various platforms (e.g., Discord,\nTelegram) and its customization to diverse recommendation features.",
      "tldr_zh": "本论文针对COVID-19背景下心理健康干预的紧迫需求，提出了CAREForMe框架，这是一种基于Contextual Multi-Armed Bandit (CMAB)的推荐系统，强调上下文感知、个性化及模块化设计。CAREForMe利用移动感知技术、在线学习算法和用户聚类功能，提供及时且个性化的心理健康推荐，从而提升mHealth解决方案的效能。通过其模块化结构，该框架可自定义应用于不同平台（如Discord、Telegram），并作为研究指导和跨学科协作平台，促进未来mHealth研究的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "MOBILESoft 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.15188v1",
      "published_date": "2024-01-26 20:18:25 UTC",
      "updated_date": "2024-01-26 20:18:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:34:34.256588"
    },
    {
      "arxiv_id": "2402.03355v2",
      "title": "Unlocking Criminal Hierarchies: A Survey, Experimental, and Comparative Exploration of Techniques for Identifying Leaders within Criminal Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Kamal Taha",
        "Abdulhadi Shoufan",
        "Aya Taha"
      ],
      "abstract": "This survey paper offers a thorough analysis of techniques and algorithms\nused in the identification of crime leaders within criminal networks. For each\ntechnique, the paper examines its effectiveness, limitations, potential for\nimprovement, and future prospects. The main challenge faced by existing survey\npapers focusing on algorithms for identifying crime leaders and predicting\ncrimes is effectively categorizing these algorithms. To address this\nlimitation, this paper proposes a new methodological taxonomy that\nhierarchically classifies algorithms into more detailed categories and specific\ntechniques. The paper includes empirical and experimental evaluations to rank\nthe different techniques. The combination of the methodological taxonomy,\nempirical evaluations, and experimental comparisons allows for a nuanced and\ncomprehensive understanding of the techniques and algorithms for identifying\ncrime leaders, assisting researchers in making informed decisions. Moreover,\nthe paper offers valuable insights into the future prospects of techniques for\nidentifying crime leaders, emphasizing potential advancements and opportunities\nfor further research. Here's an overview of our empirical analysis findings and\nexperimental insights, along with the solution we've devised: (1) PageRank and\nEigenvector centrality are reliable for mapping network connections, (2) Katz\nCentrality can effectively identify influential criminals through indirect\nlinks, stressing their significance in criminal networks, (3) current models\nfail to account for the specific impacts of criminal influence levels, the\nimportance of socio-economic context, and the dynamic nature of criminal\nnetworks and hierarchies, and (4) we propose enhancements, such as\nincorporating temporal dynamics and sentiment analysis to reflect the fluidity\nof criminal activities and relationships",
      "tldr_zh": "这篇调查论文系统分析了识别犯罪网络中领导者的技术与算法，包括它们的有效性、局限性和改进潜力。论文提出一个新的方法论 taxonomy（分类法），对这些算法进行分层分类，并通过实证和实验评估比较了不同技术，如PageRank和Eigenvector centrality在映射网络连接方面的可靠性，以及Katz Centrality在识别间接影响上的优势。研究发现，现有模型忽略了犯罪影响水平、社会经济背景和网络动态等问题，因此建议通过整合temporal dynamics（时间动态）和sentiment analysis（情感分析）来增强算法，为未来研究提供宝贵见解。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03355v2",
      "published_date": "2024-01-26 20:09:31 UTC",
      "updated_date": "2024-03-30 21:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:34:46.177165"
    },
    {
      "arxiv_id": "2402.10921v1",
      "title": "AM^2-EmoJE: Adaptive Missing-Modality Emotion Recognition in Conversation via Joint Embedding Learning",
      "title_zh": "AM^2-EmoJE：通过联合嵌入学习在对话中实现自适应缺失",
      "authors": [
        "Naresh Kumar Devulapally",
        "Sidharth Anand",
        "Sreyasee Das Bhattacharjee",
        "Junsong Yuan"
      ],
      "abstract": "Human emotion can be presented in different modes i.e., audio, video, and\ntext. However, the contribution of each mode in exhibiting each emotion is not\nuniform. Furthermore, the availability of complete mode-specific details may\nnot always be guaranteed in the test time. In this work, we propose AM^2-EmoJE,\na model for Adaptive Missing-Modality Emotion Recognition in Conversation via\nJoint Embedding Learning model that is grounded on two-fold contributions:\nFirst, a query adaptive fusion that can automatically learn the relative\nimportance of its mode-specific representations in a query-specific manner. By\nthis the model aims to prioritize the mode-invariant spatial query details of\nthe emotion patterns, while also retaining its mode-exclusive aspects within\nthe learned multimodal query descriptor. Second the multimodal joint embedding\nlearning module that explicitly addresses various missing modality scenarios in\ntest-time. By this, the model learns to emphasize on the correlated patterns\nacross modalities, which may help align the cross-attended mode-specific\ndescriptors pairwise within a joint-embedding space and thereby compensate for\nmissing modalities during inference. By leveraging the spatio-temporal details\nat the dialogue level, the proposed AM^2-EmoJE not only demonstrates superior\nperformance compared to the best-performing state-of-the-art multimodal\nmethods, by effectively leveraging body language in place of face expression,\nit also exhibits an enhanced privacy feature. By reporting around 2-5%\nimprovement in the weighted-F1 score, the proposed multimodal joint embedding\nmodule facilitates an impressive performance gain in a variety of\nmissing-modality query scenarios during test time.",
      "tldr_zh": "该论文提出 AM^2-EmoJE 模型，用于对话中的自适应缺失模式情绪识别，旨在处理音频、视频和文本模式的不均匀贡献以及测试时的模式缺失问题。该模型的核心包括查询自适应融合（query adaptive fusion），它自动学习模式在特定查询中的相对重要性，以优先模式不变的时空细节，同时保留模式独有的方面；以及多模态联合嵌入学习（multimodal joint embedding learning），通过强调跨模式相关模式来补偿缺失模态。实验结果显示，AM^2-EmoJE 在各种缺失模式场景中比最先进的多模态方法提高2-5%的 weighted-F1 分数，并通过使用身体语言代替面部表情增强了隐私保护。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10921v1",
      "published_date": "2024-01-26 19:57:26 UTC",
      "updated_date": "2024-01-26 19:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:34:59.118239"
    },
    {
      "arxiv_id": "2401.15170v2",
      "title": "Scalable Qualitative Coding with LLMs: Chain-of-Thought Reasoning Matches Human Performance in Some Hermeneutic Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Zackary Okun Dunivin"
      ],
      "abstract": "Qualitative coding, or content analysis, extracts meaning from text to\ndiscern quantitative patterns across a corpus of texts. Recently, advances in\nthe interpretive abilities of large language models (LLMs) offer potential for\nautomating the coding process (applying category labels to texts), thereby\nenabling human researchers to concentrate on more creative research aspects,\nwhile delegating these interpretive tasks to AI. Our case study comprises a set\nof socio-historical codes on dense, paragraph-long passages representative of a\nhumanistic study. We show that GPT-4 is capable of human-equivalent\ninterpretations, whereas GPT-3.5 is not. Compared to our human-derived gold\nstandard, GPT-4 delivers excellent intercoder reliability (Cohen's $\\kappa \\geq\n0.79$) for 3 of 9 codes, and substantial reliability ($\\kappa \\geq 0.6$) for 8\nof 9 codes. In contrast, GPT-3.5 greatly underperforms for all codes\n($mean(\\kappa) = 0.34$; $max(\\kappa) = 0.55$). Importantly, we find that coding\nfidelity improves considerably when the LLM is prompted to give rationale\njustifying its coding decisions (chain-of-thought reasoning). We present these\nand other findings along with a set of best practices for adapting traditional\ncodebooks for LLMs. Our results indicate that for certain codebooks,\nstate-of-the-art LLMs are already adept at large-scale content analysis.\nFurthermore, they suggest the next generation of models will likely render AI\ncoding a viable option for a majority of codebooks.",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)进行可扩展的定性编码（内容分析），旨在从文本中提取意义并识别模式，从而让人类研究者专注于创新方面。研究发现，通过链式思维推理(Chain-of-Thought Reasoning)提示，GPT-4在某些诠释任务中达到了人类水平的 intercoder reliability(Cohen's κ ≥ 0.79 for 3 of 9 codes，κ ≥ 0.6 for 8 of 9 codes)，而GPT-3.5的表现远逊色(平均κ = 0.34)。该论文提出了将传统代码书适应LLMs的最佳实践，并表明先进的LLMs已具备进行大规模内容分析的能力，预示着AI编码将成为未来主流选项。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15170v2",
      "published_date": "2024-01-26 19:25:43 UTC",
      "updated_date": "2024-02-12 23:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:35:12.748737"
    },
    {
      "arxiv_id": "2401.15075v1",
      "title": "Annotated Hands for Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Yang",
        "Atith N Gandhi",
        "Greg Turk"
      ],
      "abstract": "Generative models such as GANs and diffusion models have demonstrated\nimpressive image generation capabilities. Despite these successes, these\nsystems are surprisingly poor at creating images with hands. We propose a novel\ntraining framework for generative models that substantially improves the\nability of such systems to create hand images. Our approach is to augment the\ntraining images with three additional channels that provide annotations to\nhands in the image. These annotations provide additional structure that coax\nthe generative model to produce higher quality hand images. We demonstrate this\napproach on two different generative models: a generative adversarial network\nand a diffusion model. We demonstrate our method both on a new synthetic\ndataset of hand images and also on real photographs that contain hands. We\nmeasure the improved quality of the generated hands through higher confidence\nin finger joint identification using an off-the-shelf hand detector.",
      "tldr_zh": "该研究发现，生成模型如GANs和diffusion models在创建手部图像时表现较差，因此提出了一种新型训练框架来提升这些模型的手部生成能力。该框架通过为训练图像添加三个额外通道，提供手部注解，以增强图像结构并引导模型产生更高质量的手部图像。在GAN和diffusion models上进行实验，包括一个新的合成手部图像数据集和真实照片，结果显示生成的双手部图像质量显著提高，通过现成的手部检测器验证了更高的手指关节识别置信度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15075v1",
      "published_date": "2024-01-26 18:57:54 UTC",
      "updated_date": "2024-01-26 18:57:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:35:21.846707"
    },
    {
      "arxiv_id": "2402.01720v2",
      "title": "Deep Learning Based Amharic Chatbot for FAQs in Universities",
      "title_zh": "基于深度学习的阿姆哈拉语聊天机器人，用于大学常见问题",
      "authors": [
        "Goitom Ybrah Hailu",
        "Hadush Hailu",
        "Shishay Welay"
      ],
      "abstract": "University students often spend a considerable amount of time seeking answers\nto common questions from administrators or teachers. This can become tedious\nfor both parties, leading to a need for a solution. In response, this paper\nproposes a chatbot model that utilizes natural language processing and deep\nlearning techniques to answer frequently asked questions (FAQs) in the Amharic\nlanguage. Chatbots are computer programs that simulate human conversation\nthrough the use of artificial intelligence (AI), acting as a virtual assistant\nto handle questions and other tasks. The proposed chatbot program employs\ntokenization, normalization, stop word removal, and stemming to analyze and\ncategorize Amharic input sentences. Three machine learning model algorithms\nwere used to classify tokens and retrieve appropriate responses: Support Vector\nMachine (SVM), Multinomial Na\\\"ive Bayes, and deep neural networks implemented\nthrough TensorFlow, Keras, and NLTK. The deep learning model achieved the best\nresults with 91.55% accuracy and a validation loss of 0.3548 using an Adam\noptimizer and SoftMax activation function. The chatbot model was integrated\nwith Facebook Messenger and deployed on a Heroku server for 24-hour\naccessibility. The experimental results demonstrate that the chatbot framework\nachieved its objectives and effectively addressed challenges such as Amharic\nFidel variation, morphological variation, and lexical gaps. Future research\ncould explore the integration of Amharic WordNet to narrow the lexical gap and\nsupport more complex questions.",
      "tldr_zh": "这篇论文提出了一种基于深度学习的 Amharic 聊天机器人，用于回答大学常见问题 (FAQs)，旨在解决学生咨询问题耗时的问题。机器人采用自然语言处理技术，包括 tokenization、normalization、stop word removal 和 stemming，对 Amharic 输入进行预处理，并使用 Support Vector Machine (SVM)、Multinomial Naïve Bayes 和深度神经网络 (通过 TensorFlow、Keras 和 NLTK 实现) 进行分类，其中深度学习模型以 Adam optimizer 和 SoftMax 激活函数取得了 91.55% 的准确率和 0.3548 的验证损失。实验结果显示，该机器人成功整合到 Facebook Messenger 并部署在 Heroku 服务器上，有效处理了 Amharic 的 Fidel 变异、形态变异和词汇间隙等挑战。未来研究可探索整合 Amharic WordNet 以支持更复杂的查询。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01720v2",
      "published_date": "2024-01-26 18:37:21 UTC",
      "updated_date": "2024-11-05 18:45:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:35:36.311266"
    },
    {
      "arxiv_id": "2401.15043v3",
      "title": "Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Md Mushfiqur Rahman",
        "Mohammad Sabik Irbaz",
        "Kai North",
        "Michelle S. Williams",
        "Marcos Zampieri",
        "Kevin Lybarger"
      ],
      "abstract": "Objective: The reading level of health educational materials significantly\ninfluences the understandability and accessibility of the information,\nparticularly for minoritized populations. Many patient educational resources\nsurpass the reading level and complexity of widely accepted standards. There is\na critical need for high-performing text simplification models in health\ninformation to enhance dissemination and literacy. This need is particularly\nacute in cancer education, where effective prevention and screening education\ncan substantially reduce morbidity and mortality.\n  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel\ncorpus of cancer education materials tailored for health text simplification\nresearch, comprising educational content from the American Cancer Society,\nCenters for Disease Control and Prevention, and National Cancer Institute.\nUtilizing SimpleDC alongside the existing Med-EASi corpus, we explore Large\nLanguage Model (LLM)-based simplification methods, including fine-tuning,\nreinforcement learning (RL), reinforcement learning with human feedback (RLHF),\ndomain adaptation, and prompt-based approaches. Our experimentation encompasses\nLlama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a\nlightweight model adept at distinguishing between original and simplified\ntexts, thereby enhancing the model's effectiveness with unlabeled data.\n  Results: Fine-tuned Llama 2 models demonstrated high performance across\nvarious metrics. Our innovative RLHF reward function surpassed existing RL text\nsimplification reward functions in effectiveness. The results underscore that\nRL/RLHF can augment fine-tuning, facilitating model training on unlabeled text\nand improving performance.",
      "tldr_zh": "本研究针对健康教育材料的阅读水平问题，引入了SimpleDC语料库，这是一个针对消化系统癌症教育的平行注释语料库，旨在提升文本简化的可访问性。研究探索了基于Large Language Model (LLM)如Llama 2和GPT-4的简化方法，包括微调、Reinforcement Learning (RL)、RLHF、领域适应和提示-based方法，并提出一个新颖的RLHF奖励函数，利用轻量级模型区分原始和简化文本，以提升无标签数据的训练效果。结果显示，微调的Llama 2模型在多种指标上表现出色，而新RLHF奖励函数比现有方法更有效，证明RL/RLHF能显著增强文本简化模型的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in Journal of Biomedical Informatics, Volume 158, October\n  2024, 104727",
      "pdf_url": "http://arxiv.org/pdf/2401.15043v3",
      "published_date": "2024-01-26 18:13:57 UTC",
      "updated_date": "2024-11-10 19:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:35:48.206007"
    },
    {
      "arxiv_id": "2401.15042v4",
      "title": "PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models",
      "title_zh": "PROXYQA：一种用于评估大型语言模型长文本生成的替代框架",
      "authors": [
        "Haochen Tan",
        "Zhijiang Guo",
        "Zhan Shi",
        "Lu Xu",
        "Zhili Liu",
        "Yunlong Feng",
        "Xiaoguang Li",
        "Yasheng Wang",
        "Lifeng Shang",
        "Qun Liu",
        "Linqi Song"
      ],
      "abstract": "Large Language Models (LLMs) have succeeded remarkably in understanding\nlong-form contents. However, exploring their capability for generating\nlong-form contents, such as reports and articles, has been relatively\nunexplored and inadequately assessed by existing benchmarks. The prevalent\nevaluation methods, which predominantly rely on crowdsourcing, are recognized\nfor their labor-intensive nature and lack of efficiency, whereas automated\nmetrics, such as the ROUGE score, demonstrate discordance with human judgment\ncriteria. In this paper, we propose ProxyQA, an innovative framework dedicated\nto assessing long-text generation. ProxyQA comprises in-depth human-curated\nmeta-questions spanning various domains, each accompanied by specific\nproxy-questions with pre-annotated answers. LLMs are tasked to generate\nextensive content in response to these meta-questions, by engaging an evaluator\nand incorporating the generated texts as contextual background, ProxyQA\nassesses the generated content's quality through the evaluator's accuracy in\naddressing the proxy-questions. We examine multiple LLMs, emphasizing ProxyQA's\ndemanding nature as a high-quality assessment tool. Human evaluation\ndemonstrates that the proxy-question method is notably self-consistent and\naligns closely with human evaluative standards. The dataset and leaderboard is\navailable at \\url{https://proxy-qa.com}.",
      "tldr_zh": "本文提出PROXYQA框架，作为评估Large Language Models (LLMs)生成长文本（如报告和文章）的创新方法，解决了现有评估方法（如众包的劳动密集型和ROUGE score与人类判断不一致的问题）。该框架包括人类策划的meta-questions和预标注的proxy-questions，LLMs生成响应内容后，通过评估器对proxy-questions的回答准确性来量化生成文本的质量。实验结果显示，PROXYQA与人类评估高度一致，并证明其作为高效评估工具的有效性；相关数据集和排行榜可访问于https://proxy-qa.com。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2401.15042v4",
      "published_date": "2024-01-26 18:12:25 UTC",
      "updated_date": "2024-06-04 12:46:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:35:59.246305"
    },
    {
      "arxiv_id": "2401.15018v1",
      "title": "Enhancement of a Text-Independent Speaker Verification System by using Feature Combination and Parallel-Structure Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Kerlos Atia Abdalmalak",
        "Ascensión Gallardo-Antol'in"
      ],
      "abstract": "Speaker Verification (SV) systems involve mainly two individual stages:\nfeature extraction and classification. In this paper, we explore these two\nmodules with the aim of improving the performance of a speaker verification\nsystem under noisy conditions. On the one hand, the choice of the most\nappropriate acoustic features is a crucial factor for performing robust speaker\nverification. The acoustic parameters used in the proposed system are: Mel\nFrequency Cepstral Coefficients (MFCC), their first and second derivatives\n(Deltas and Delta- Deltas), Bark Frequency Cepstral Coefficients (BFCC),\nPerceptual Linear Predictive (PLP), and Relative Spectral Transform -\nPerceptual Linear Predictive (RASTA-PLP). In this paper, a complete comparison\nof different combinations of the previous features is discussed. On the other\nhand, the major weakness of a conventional Support Vector Machine (SVM)\nclassifier is the use of generic traditional kernel functions to compute the\ndistances among data points. However, the kernel function of an SVM has great\ninfluence on its performance. In this work, we propose the combination of two\nSVM-based classifiers with different kernel functions: Linear kernel and\nGaussian Radial Basis Function (RBF) kernel with a Logistic Regression (LR)\nclassifier. The combination is carried out by means of a parallel structure\napproach, in which different voting rules to take the final decision are\nconsidered. Results show that significant improvement in the performance of the\nSV system is achieved by using the combined features with the combined\nclassifiers either with clean speech or in the presence of noise. Finally, to\nenhance the system more in noisy environments, the inclusion of the multiband\nnoise removal technique as a preprocessing stage is proposed.",
      "tldr_zh": "本研究旨在提升文本无关演讲者验证（SV）系统的性能，特别是在嘈杂环境下，通过优化特征提取和分类模块。研究比较了多种声学特征的组合，包括 MFCC 及其导数（Deltas and Delta-Deltas）、BFCC、PLP 和 RASTA-PLP，以提高系统的鲁棒性；同时，提出了一种并行结构分类器，将线性核和 Gaussian RBF 核的 SVM 与 Logistic Regression (LR) 结合，并采用不同投票规则进行决策。实验结果显示，使用组合特征和分类器显著提高了 SV 系统的准确率，在干净语音和噪声环境中均有效；此外，添加多频带噪声去除技术作为预处理阶段进一步增强了系统在嘈杂条件下的表现。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15018v1",
      "published_date": "2024-01-26 17:19:59 UTC",
      "updated_date": "2024-01-26 17:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:36:11.075237"
    },
    {
      "arxiv_id": "2401.15006v2",
      "title": "Airavata: Introducing Hindi Instruction-tuned LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Jay Gala",
        "Thanmay Jayakumar",
        "Jaavid Aktar Husain",
        "Aswanth Kumar M",
        "Mohammed Safi Ur Rahman Khan",
        "Diptesh Kanojia",
        "Ratish Puduppully",
        "Mitesh M. Khapra",
        "Raj Dabre",
        "Rudra Murthy",
        "Anoop Kunchukuttan"
      ],
      "abstract": "We announce the initial release of \"Airavata,\" an instruction-tuned LLM for\nHindi. Airavata was created by fine-tuning OpenHathi with diverse,\ninstruction-tuning Hindi datasets to make it better suited for assistive tasks.\nAlong with the model, we also share the IndicInstruct dataset, which is a\ncollection of diverse instruction-tuning datasets to enable further research\nfor Indic LLMs. Additionally, we present evaluation benchmarks and a framework\nfor assessing LLM performance across tasks in Hindi. Currently, Airavata\nsupports Hindi, but we plan to expand this to all 22 scheduled Indic languages.\nYou can access all artifacts at https://ai4bharat.github.io/airavata.",
      "tldr_zh": "本研究介绍了 Airavata，一种针对印地语的 Instruction-tuned LLM，通过对 OpenHathi 模型使用多样化的印地语指令微调数据集进行微调，提升其在辅助任务中的性能。研究者同时发布了 IndicInstruct 数据集，用于支持印地语及其他印地语系 LLM 的进一步研究，并提供了评估基准和框架来衡量模型在印地语任务中的表现。目前，Airavata 支持印地语，并计划扩展至所有22种官方印地语，相关资源可通过指定链接访问。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2401.15006v2",
      "published_date": "2024-01-26 17:07:08 UTC",
      "updated_date": "2024-02-26 12:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:36:23.275086"
    },
    {
      "arxiv_id": "2401.15132v1",
      "title": "On the Emergence of Symmetrical Reality",
      "title_zh": "论对称现实的涌现",
      "authors": [
        "Zhenliang Zhang",
        "Zeyu Zhang",
        "Ziyuan Jiao",
        "Yao Su",
        "Hangxin Liu",
        "Wei Wang",
        "Song-Chun Zhu"
      ],
      "abstract": "Artificial intelligence (AI) has revolutionized human cognitive abilities and\nfacilitated the development of new AI entities capable of interacting with\nhumans in both physical and virtual environments. Despite the existence of\nvirtual reality, mixed reality, and augmented reality for several years,\nintegrating these technical fields remains a formidable challenge due to their\ndisparate application directions. The advent of AI agents, capable of\nautonomous perception and action, further compounds this issue by exposing the\nlimitations of traditional human-centered research approaches. It is imperative\nto establish a comprehensive framework that accommodates the dual perceptual\ncenters of humans and AI agents in both physical and virtual worlds. In this\npaper, we introduce the symmetrical reality framework, which offers a unified\nrepresentation encompassing various forms of physical-virtual amalgamations.\nThis framework enables researchers to better comprehend how AI agents can\ncollaborate with humans and how distinct technical pathways of physical-virtual\nintegration can be consolidated from a broader perspective. We then delve into\nthe coexistence of humans and AI, demonstrating a prototype system that\nexemplifies the operation of symmetrical reality systems for specific tasks,\nsuch as pouring water. Subsequently, we propose an instance of an AI-driven\nactive assistance service that illustrates the potential applications of\nsymmetrical reality. This paper aims to offer beneficial perspectives and\nguidance for researchers and practitioners in different fields, thus\ncontributing to the ongoing research about human-AI coexistence in both\nphysical and virtual environments.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在物理和虚拟环境中与人类互动的挑战，强调了虚拟现实、混合现实和增强现实等技术的整合难题，以及AI代理自主感知行为的局限性。为解决这些问题，作者引入了Symmetrical Reality框架，这是一个统一的表示方法，旨在容纳人类和AI代理的双重感知中心，并整合各种物理-虚拟结合形式。论文通过展示一个原型系统（如倒水任务）和一个AI驱动的主动辅助服务，示范了该框架如何促进人类-AI协作，并为相关领域的研究人员提供指导，推动物理和虚拟环境中的人类-AI共存研究。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "IEEE VR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.15132v1",
      "published_date": "2024-01-26 16:09:39 UTC",
      "updated_date": "2024-01-26 16:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:36:35.700610"
    },
    {
      "arxiv_id": "2401.14968v1",
      "title": "Atmosphere: Context and situational-aware collaborative IoT architecture for edge-fog-cloud computing",
      "title_zh": "Atmosphere: 上下文",
      "authors": [
        "Guadalupe Ortiz",
        "Meftah Zouai",
        "Okba Kazar",
        "Alfonso Garcia-de-Prado",
        "Juan Boubeta-Puig"
      ],
      "abstract": "The Internet of Things (IoT) has grown significantly in popularity,\naccompanied by increased capacity and lower cost of communications, and\noverwhelming development of technologies. At the same time, big data and\nreal-time data analysis have taken on great importance and have been\naccompanied by unprecedented interest in sharing data among citizens, public\nadministrations and other organisms, giving rise to what is known as the\nCollaborative Internet of Things. This growth in data and infrastructure must\nbe accompanied by a software architecture that allows its exploitation.\nAlthough there are various proposals focused on the exploitation of the IoT at\nedge, fog and/or cloud levels, it is not easy to find a software solution that\nexploits the three tiers together, taking maximum advantage not only of the\nanalysis of contextual and situational data at each tier, but also of two-way\ncommunications between adjacent ones. In this paper, we propose an architecture\nthat solves these deficiencies by proposing novel technologies which are\nappropriate for managing the resources of each tier: edge, fog and cloud. In\naddition, the fact that two-way communications along the three tiers of the\narchitecture is allowed considerably enriches the contextual and situational\ninformation in each layer, and substantially assists decision making in real\ntime. The paper illustrates the proposed software architecture through a case\nstudy of respiratory disease surveillance in hospitals. As a result, the\nproposed architecture permits efficient communications between the different\ntiers responding to the needs of these types of IoT scenarios.",
      "tldr_zh": "该论文提出了一种名为 Atmosphere 的协作 IoT 架构，旨在解决传统 edge-fog-cloud 计算中数据共享和实时分析的不足，通过整合上下文和情境感知机制来优化三层资源管理。架构引入创新技术，支持 edge、fog 和 cloud 之间的双向通信，从而增强数据利用和实时决策能力。论文通过医院呼吸疾病监测的案例研究验证了该架构的效率，展示了其在 IoT 场景中的实际应用潜力。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14968v1",
      "published_date": "2024-01-26 16:01:09 UTC",
      "updated_date": "2024-01-26 16:01:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:36:47.667337"
    },
    {
      "arxiv_id": "2401.14953v1",
      "title": "Learning Universal Predictors",
      "title_zh": "翻译失败",
      "authors": [
        "Jordi Grau-Moya",
        "Tim Genewein",
        "Marcus Hutter",
        "Laurent Orseau",
        "Grégoire Delétang",
        "Elliot Catt",
        "Anian Ruoss",
        "Li Kevin Wenliang",
        "Christopher Mattern",
        "Matthew Aitchison",
        "Joel Veness"
      ],
      "abstract": "Meta-learning has emerged as a powerful approach to train neural networks to\nlearn new tasks quickly from limited data. Broad exposure to different tasks\nleads to versatile representations enabling general problem solving. But, what\nare the limits of meta-learning? In this work, we explore the potential of\namortizing the most powerful universal predictor, namely Solomonoff Induction\n(SI), into neural networks via leveraging meta-learning to its limits. We use\nUniversal Turing Machines (UTMs) to generate training data used to expose\nnetworks to a broad range of patterns. We provide theoretical analysis of the\nUTM data generation processes and meta-training protocols. We conduct\ncomprehensive experiments with neural architectures (e.g. LSTMs, Transformers)\nand algorithmic data generators of varying complexity and universality. Our\nresults suggest that UTM data is a valuable resource for meta-learning, and\nthat it can be used to train neural networks capable of learning universal\nprediction strategies.",
      "tldr_zh": "本研究探讨了元学习（meta-learning）在训练神经网络快速学习新任务的潜力，特别针对实现 Solomonoff Induction (SI) 这种强大通用预测器的可能性。研究方法包括使用 Universal Turing Machines (UTMs) 生成多样化的训练数据，让神经网络（如 LSTMs 和 Transformers）暴露于广泛模式，并结合理论分析和实验协议。结果显示，UTM 数据作为元学习的宝贵资源，能有效训练神经网络学习通用预测策略，从而提升其在复杂任务中的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.14953v1",
      "published_date": "2024-01-26 15:37:16 UTC",
      "updated_date": "2024-01-26 15:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:37:00.130554"
    },
    {
      "arxiv_id": "2401.14948v1",
      "title": "Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training",
      "title_zh": "翻译失败",
      "authors": [
        "Shruthi Gowda",
        "Bahram Zonooz",
        "Elahe Arani"
      ],
      "abstract": "Adversarial training improves the robustness of neural networks against\nadversarial attacks, albeit at the expense of the trade-off between standard\nand robust generalization. To unveil the underlying factors driving this\nphenomenon, we examine the layer-wise learning capabilities of neural networks\nduring the transition from a standard to an adversarial setting. Our empirical\nfindings demonstrate that selectively updating specific layers while preserving\nothers can substantially enhance the network's learning capacity. We therefore\npropose CURE, a novel training framework that leverages a gradient prominence\ncriterion to perform selective conservation, updating, and revision of weights.\nImportantly, CURE is designed to be dataset- and architecture-agnostic,\nensuring its applicability across various scenarios. It effectively tackles\nboth memorization and overfitting issues, thus enhancing the trade-off between\nrobustness and generalization and additionally, this training approach also\naids in mitigating \"robust overfitting\". Furthermore, our study provides\nvaluable insights into the mechanisms of selective adversarial training and\noffers a promising avenue for future research.",
      "tldr_zh": "该研究探讨了对抗训练（adversarial training）在提升神经网络鲁棒性时，标准泛化和鲁棒泛化之间存在的权衡问题，通过分析层级学习能力发现选择性更新特定层可显著改善网络性能。作者提出CURE框架，利用梯度显著性标准（gradient prominence criterion）进行权重选择性保存、更新和修改，从而有效缓解记忆化和过拟合（overfitting）问题。实验结果表明，CURE在各种数据集和架构中均适用，能够显著提升泛化和鲁棒性的平衡，并缓解“robust overfitting”，为选择性对抗训练提供新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.14948v1",
      "published_date": "2024-01-26 15:33:39 UTC",
      "updated_date": "2024-01-26 15:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:37:12.520882"
    },
    {
      "arxiv_id": "2401.14933v1",
      "title": "SSDOnt: an Ontology for representing Single-Subject Design Studies",
      "title_zh": "翻译失败",
      "authors": [
        "Idoia Berges",
        "Jesús Bermúdez",
        "Arantza Illarramendi"
      ],
      "abstract": "Background: Single-Subject Design is used in several areas such as education\nand biomedicine. However, no suited formal vocabulary exists for annotating the\ndetailed configuration and the results of this type of research studies with\nthe appropriate granularity for looking for information about them. Therefore,\nthe search for those study designs relies heavily on a syntactical search on\nthe abstract, keywords or full text of the publications about the study, which\nentails some limitations. Objective: To present SSDOnt, a specific purpose\nontology for describing and annotating single-subject design studies, so that\ncomplex questions can be asked about them afterwards. Methods: The ontology was\ndeveloped following the NeOn methodology. Once the requirements of the ontology\nwere defined, a formal model was described in a Description Logic and later\nimplemented in the ontology language OWL 2 DL. Results: We show how the\nontology provides a reference model with a suitable terminology for the\nannotation and searching of single-subject design studies and their main\ncomponents, such as the phases, the intervention types, the outcomes and the\nresults. Some mappings with terms of related ontologies have been established.\nWe show as proof-of-concept that classes in the ontology can be easily extended\nto annotate more precise information about specific interventions and outcomes\nsuch as those related to autism. Moreover, we provide examples of some types of\nqueries that can be posed to the ontology. Conclusions: SSDOnt has achieved the\npurpose of covering the descriptions of the domain of single-subject research\nstudies.",
      "tldr_zh": "本文提出SSDOnt，这是一个专门用于表示Single-Subject Design Studies的本体，旨在解决现有词汇不足的问题，从而实现更精确的标注和复杂查询。开发过程采用NeOn methodology，先定义本体要求，然后用Description Logic建模并以OWL 2 DL实现。结果表明，SSDOnt提供了全面的术语体系来描述研究组件（如phases、intervention types、outcomes和results），并支持扩展和查询示例，提升了Single-Subject Design研究的检索效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This document is the Accepted Manuscript version of a Published Work\n  that appeared in final form in Methods of Information in Medicine 57(01/02) :\n  55-61 (2018), copyright 2018 Schattauer. To access the final edited and\n  published work see https://doi.org/10.3414/ME17-01-0109",
      "pdf_url": "http://arxiv.org/pdf/2401.14933v1",
      "published_date": "2024-01-26 15:11:31 UTC",
      "updated_date": "2024-01-26 15:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:37:24.829800"
    },
    {
      "arxiv_id": "2401.14931v2",
      "title": "Do LLMs Dream of Ontologies?",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Bombieri",
        "Paolo Fiorini",
        "Simone Paolo Ponzetto",
        "Marco Rospocher"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\ndiverse natural language processing tasks, yet their ability to memorize\nstructured knowledge remains underexplored. In this paper, we investigate the\nextent to which general-purpose pre-trained LLMs retain and correctly reproduce\nconcept identifier (ID)-label associations from publicly available ontologies.\nWe conduct a systematic evaluation across multiple ontological resources,\nincluding the Gene Ontology, Uberon, Wikidata, and ICD-10, using LLMs such as\nPythia-12B, Gemini-1.5-Flash, GPT-3.5, and GPT-4. Our findings reveal that only\na small fraction of ontological concepts is accurately memorized, with GPT-4\ndemonstrating the highest performance. To understand why certain concepts are\nmemorized more effectively than others, we analyze the relationship between\nmemorization accuracy and concept popularity on the Web. Our results indicate a\nstrong correlation between the frequency of a concept's occurrence online and\nthe likelihood of accurately retrieving its ID from the label. This suggests\nthat LLMs primarily acquire such knowledge through indirect textual exposure\nrather than directly from structured ontological resources. Furthermore, we\nintroduce new metrics to quantify prediction invariance, demonstrating that the\nstability of model responses across variations in prompt language and\ntemperature settings can serve as a proxy for estimating memorization\nrobustness.",
      "tldr_zh": "本文研究大型语言模型(LLMs)对本体(Ontologies)中结构化知识的记忆能力，特别是概念标识符(ID)-标签关联的保留和再现。研究通过系统评估Pythia-12B、Gemini-1.5-Flash、GPT-3.5和GPT-4在Gene Ontology、Uberon、Wikidata和ICD-10等资源上的表现，发现只有少部分概念被准确记忆，且GPT-4表现出色。结果显示，记忆准确率与概念在网络上的流行度强相关，表明LLMs主要依赖间接文本暴露而非直接结构化资源获取知识；此外，引入了预测不变性(prediction invariance)指标，作为评估记忆鲁棒性的新方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14931v2",
      "published_date": "2024-01-26 15:10:23 UTC",
      "updated_date": "2025-02-02 13:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:37:37.426176"
    },
    {
      "arxiv_id": "2401.14923v1",
      "title": "Reinforcement Learning Interventions on Boundedly Rational Human Agents in Frictionful Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Eura Nofshin",
        "Siddharth Swaroop",
        "Weiwei Pan",
        "Susan Murphy",
        "Finale Doshi-Velez"
      ],
      "abstract": "Many important behavior changes are frictionful; they require individuals to\nexpend effort over a long period with little immediate gratification. Here, an\nartificial intelligence (AI) agent can provide personalized interventions to\nhelp individuals stick to their goals. In these settings, the AI agent must\npersonalize rapidly (before the individual disengages) and interpretably, to\nhelp us understand the behavioral interventions. In this paper, we introduce\nBehavior Model Reinforcement Learning (BMRL), a framework in which an AI agent\nintervenes on the parameters of a Markov Decision Process (MDP) belonging to a\nboundedly rational human agent. Our formulation of the human decision-maker as\na planning agent allows us to attribute undesirable human policies (ones that\ndo not lead to the goal) to their maladapted MDP parameters, such as an\nextremely low discount factor. Furthermore, we propose a class of tractable\nhuman models that captures fundamental behaviors in frictionful tasks.\nIntroducing a notion of MDP equivalence specific to BMRL, we theoretically and\nempirically show that AI planning with our human models can lead to helpful\npolicies on a wide range of more complex, ground-truth humans.",
      "tldr_zh": "本研究探讨了 Reinforcement Learning 在帮助有界理性人类代理（Boundedly Rational Human Agents）处理摩擦性任务（Frictionful Tasks）时的干预策略，引入了 Behavior Model Reinforcement Learning (BMRL) 框架。BMRL 框架将人类决策者视为规划代理，通过调整其 Markov Decision Process (MDP) 参数（如折扣因子）来纠正不良策略，确保快速个性化干预。实验结果表明，该方法在复杂人类模型上能产生有效的政策，帮助人类坚持长期目标，并为可解释的行为干预提供了理论基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "In AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.14923v1",
      "published_date": "2024-01-26 14:59:48 UTC",
      "updated_date": "2024-01-26 14:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:37:49.833051"
    },
    {
      "arxiv_id": "2401.14915v2",
      "title": "Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students",
      "title_zh": "翻译失败",
      "authors": [
        "Chengbo Zheng",
        "Kangyu Yuan",
        "Bingcan Guo",
        "Reza Hadi Mogavi",
        "Zhenhui Peng",
        "Shuai Ma",
        "Xiaojuan Ma"
      ],
      "abstract": "The increasing use of Artificial Intelligence (AI) by students in learning\npresents new challenges for assessing their learning outcomes in project-based\nlearning (PBL). This paper introduces a co-design study to explore the\npotential of students' AI usage data as a novel material for PBL assessment. We\nconducted workshops with 18 college students, encouraging them to speculate an\nalternative world where they could freely employ AI in PBL while needing to\nreport this process to assess their skills and contributions. Our workshops\nyielded various scenarios of students' use of AI in PBL and ways of analyzing\nthese uses grounded by students' vision of education goal transformation. We\nalso found students with different attitudes toward AI exhibited distinct\npreferences in how to analyze and understand the use of AI. Based on these\nfindings, we discuss future research opportunities on student-AI interactions\nand understanding AI-enhanced learning.",
      "tldr_zh": "这篇论文探讨了人工智能 (AI) 在项目式学习 (PBL) 中的应用对评估学习成果带来的新挑战，并通过与 18 名大学生的共同设计 (co-design) 研讨会，探索使用学生的 AI 使用数据作为 PBL 评估的新材料。研讨会鼓励学生设想一个自由使用 AI 的世界，同时报告 AI 使用过程以评估技能和贡献，产生了各种 AI 在 PBL 中的应用场景和分析方法，这些方法基于学生对教育目标转变的愿景。研究发现，不同对 AI 态度的学生在分析 AI 使用方面表现出明显的偏好，并据此讨论了未来学生-AI 互动和 AI 增强学习的研究机会。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Conditionally accepted by CHI '24",
      "pdf_url": "http://arxiv.org/pdf/2401.14915v2",
      "published_date": "2024-01-26 14:49:29 UTC",
      "updated_date": "2024-01-29 14:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:38:01.186933"
    },
    {
      "arxiv_id": "2401.14876v2",
      "title": "Cross-Space Adaptive Filter: Integrating Graph Topology and Node Attributes for Alleviating the Over-smoothing Problem",
      "title_zh": "跨空间自适应滤波器：整合图拓扑和节点属性以缓解过平滑问题",
      "authors": [
        "Chen Huang",
        "Haoyang Li",
        "Yifan Zhang",
        "Wenqiang Lei",
        "Jiancheng Lv"
      ],
      "abstract": "The vanilla Graph Convolutional Network (GCN) uses a low-pass filter to\nextract low-frequency signals from graph topology, which may lead to the\nover-smoothing problem when GCN goes deep. To this end, various methods have\nbeen proposed to create an adaptive filter by incorporating an extra filter\n(e.g., a high-pass filter) extracted from the graph topology. However, these\nmethods heavily rely on topological information and ignore the node attribute\nspace, which severely sacrifices the expressive power of the deep GCNs,\nespecially when dealing with disassortative graphs. In this paper, we propose a\ncross-space adaptive filter, called CSF, to produce the adaptive-frequency\ninformation extracted from both the topology and attribute spaces.\nSpecifically, we first derive a tailored attribute-based high-pass filter that\ncan be interpreted theoretically as a minimizer for semi-supervised kernel\nridge regression. Then, we cast the topology-based low-pass filter as a\nMercer's kernel within the context of GCNs. This serves as a foundation for\ncombining it with the attribute-based filter to capture the adaptive-frequency\ninformation. Finally, we derive the cross-space filter via an effective\nmultiple-kernel learning strategy, which unifies the attribute-based high-pass\nfilter and the topology-based low-pass filter. This helps to address the\nover-smoothing problem while maintaining effectiveness. Extensive experiments\ndemonstrate that CSF not only successfully alleviates the over-smoothing\nproblem but also promotes the effectiveness of the node classification task.",
      "tldr_zh": "本文提出了一种跨空间自适应滤波器 CSF，用于整合图拓扑和节点属性，以缓解 Graph Convolutional Network (GCN) 中的 over-smoothing problem。CSF 通过推导基于属性的高通滤波器（解释为半监督核岭回归的优化器）和基于拓扑的低通滤波器（视为 Mercer 核），并采用多核学习策略将两者结合，提取自适应频率信息。实验结果显示，CSF 不仅有效缓解了过平滑问题，还显著提升了节点分类任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to WWW 2024. V2: update the results on GCN-BC based on our\n  rebuttal on OpenReview. Our code is available at\n  https://github.com/huangzichun/Cross-Space-Adaptive-Filter",
      "pdf_url": "http://arxiv.org/pdf/2401.14876v2",
      "published_date": "2024-01-26 14:02:29 UTC",
      "updated_date": "2024-02-10 08:58:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:38:12.905691"
    },
    {
      "arxiv_id": "2401.14856v1",
      "title": "Memory-Inspired Temporal Prompt Interaction for Text-Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyao Yu",
        "Hao Sun",
        "Ziwei Niu",
        "Rui Qin",
        "Zhenjia Bai",
        "Yen-Wei Chen",
        "Lanfen Lin"
      ],
      "abstract": "In recent years, large-scale pre-trained multimodal models (LMM) generally\nemerge to integrate the vision and language modalities, achieving considerable\nsuccess in various natural language processing and computer vision tasks. The\ngrowing size of LMMs, however, results in a significant computational cost for\nfine-tuning these models for downstream tasks. Hence, prompt-based interaction\nstrategy is studied to align modalities more efficiently. In this contex, we\npropose a novel prompt-based multimodal interaction strategy inspired by human\nmemory strategy, namely Memory-Inspired Temporal Prompt Interaction (MITP). Our\nproposed method involves in two stages as in human memory strategy: the\nacquiring stage, and the consolidation and activation stage. We utilize\ntemporal prompts on intermediate layers to imitate the acquiring stage,\nleverage similarity-based prompt interaction to imitate memory consolidation,\nand employ prompt generation strategy to imitate memory activation. The main\nstrength of our paper is that we interact the prompt vectors on intermediate\nlayers to leverage sufficient information exchange between modalities, with\ncompressed trainable parameters and memory usage. We achieve competitive\nresults on several datasets with relatively small memory usage and 2.0M of\ntrainable parameters (about 1% of the pre-trained foundation model).",
      "tldr_zh": "本研究提出了一种名为 Memory-Inspired Temporal Prompt Interaction (MITP) 的新策略，用于文本-图像分类任务，以解决大型预训练多模态模型 (LMM) 在细调时的计算成本问题。MITP 受人类记忆策略启发，分为获取阶段（使用 temporal prompts 在中间层模拟信息获取）、巩固阶段（通过基于相似度的提示交互模仿记忆巩固），以及激活阶段（采用提示生成策略模拟记忆激活）。这种方法在模态之间实现充分的信息交换，同时仅需 2.0M 可训练参数（约占预训练模型的 1%）和较低的内存使用。实验结果显示，MITP 在多个数据集上取得了与现有方法竞争的性能，证明了其高效性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14856v1",
      "published_date": "2024-01-26 13:36:12 UTC",
      "updated_date": "2024-01-26 13:36:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:38:25.304613"
    },
    {
      "arxiv_id": "2401.14831v3",
      "title": "The Machine Vision Iceberg Explained: Advancing Dynamic Testing by Considering Holistic Environmental Relations",
      "title_zh": "翻译失败",
      "authors": [
        "Hubert Padusinski",
        "Christian Steinhauser",
        "Thilo Braun",
        "Lennart Ries",
        "Eric Sax"
      ],
      "abstract": "Machine Vision (MV) is essential for solving driving automation. This paper\nexamines potential shortcomings in current MV testing strategies for highly\nautomated driving (HAD) systems. We argue for a more comprehensive\nunderstanding of the performance factors that must be considered during the MV\nevaluation process, noting that neglecting these factors can lead to\nsignificant risks. This is not only relevant to MV component testing, but also\nto integration testing. To illustrate this point, we draw an analogy to a ship\nnavigating towards an iceberg to show potential hidden challenges in current MV\ntesting strategies. The main contribution is a novel framework for black-box\ntesting which observes environmental relations. This means it is designed to\nenhance MV assessments by considering the attributes and surroundings of\nrelevant individual objects. The framework provides the identification of seven\ngeneral concerns about the object recognition of MV, which are not addressed\nadequately in established test processes. To detect these deficits based on\ntheir performance factors, we propose the use of a taxonomy called \"granularity\norders\" along with a graphical representation. This allows an identification of\nMV uncertainties across a range of driving scenarios. This approach aims to\nadvance the precision, efficiency, and completeness of testing procedures for\nMV.",
      "tldr_zh": "本论文探讨了机器视觉（MV）在高度自动驾驶（HAD）系统中的关键作用，指出当前测试策略忽略了环境关系等性能因素，可能导致重大风险，并通过“冰山”比喻揭示隐藏挑战。作者提出一个新型黑-box testing 框架，该框架关注相关对象的属性和环境关系，识别七个未充分处理的 MV 对象识别问题，并利用“granularity orders”分类和图形表示来检测不确定性。最终，该方法旨在提升 MV 测试的精确性、效率和完整性，为更可靠的自动驾驶系统评估提供基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.SE",
        "eess.IV"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted at IEEE ITSC 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.14831v3",
      "published_date": "2024-01-26 12:59:26 UTC",
      "updated_date": "2024-04-30 13:25:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:38:35.792812"
    },
    {
      "arxiv_id": "2401.14811v1",
      "title": "On the Limitations of Markovian Rewards to Express Multi-Objective, Risk-Sensitive, and Modal Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Joar Skalse",
        "Alessandro Abate"
      ],
      "abstract": "In this paper, we study the expressivity of scalar, Markovian reward\nfunctions in Reinforcement Learning (RL), and identify several limitations to\nwhat they can express. Specifically, we look at three classes of RL tasks;\nmulti-objective RL, risk-sensitive RL, and modal RL. For each class, we derive\nnecessary and sufficient conditions that describe when a problem in this class\ncan be expressed using a scalar, Markovian reward. Moreover, we find that\nscalar, Markovian rewards are unable to express most of the instances in each\nof these three classes. We thereby contribute to a more complete understanding\nof what standard reward functions can and cannot express. In addition to this,\nwe also call attention to modal problems as a new class of problems, since they\nhave so far not been given any systematic treatment in the RL literature. We\nalso briefly outline some approaches for solving some of the problems we\ndiscuss, by means of bespoke RL algorithms.",
      "tldr_zh": "本论文探讨了标量Markovian奖励函数在Reinforcement Learning (RL)中的表达能力限制，焦点是Multi-Objective RL、多目标RL、Risk-Sensitive RL、风险敏感RL和Modal RL、模态RL这三类任务。通过导出必要和充分条件，作者分析了这些任务何时能被标量Markovian奖励表达。研究发现，大多数实例无法用标量Markovian奖励函数表示，从而加深了对标准奖励函数局限性的理解。同时，论文首次系统引入Modal RL作为新问题类别，并简要概述了使用定制RL算法的潜在解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14811v1",
      "published_date": "2024-01-26 12:18:29 UTC",
      "updated_date": "2024-01-26 12:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:38:49.278937"
    },
    {
      "arxiv_id": "2401.14777v1",
      "title": "Large Language Model Adaptation for Financial Sentiment Analysis",
      "title_zh": "大型语言模型在金融情感分析中的适应",
      "authors": [
        "Pau Rodriguez Inserte",
        "Mariam Nakhlé",
        "Raheel Qader",
        "Gaetan Caillaut",
        "Jingshu Liu"
      ],
      "abstract": "Natural language processing (NLP) has recently gained relevance within\nfinancial institutions by providing highly valuable insights into companies and\nmarkets' financial documents. However, the landscape of the financial domain\npresents extra challenges for NLP, due to the complexity of the texts and the\nuse of specific terminology. Generalist language models tend to fall short in\ntasks specifically tailored for finance, even when using large language models\n(LLMs) with great natural language understanding and generative capabilities.\nThis paper presents a study on LLM adaptation methods targeted at the financial\ndomain and with high emphasis on financial sentiment analysis. To this purpose,\ntwo foundation models with less than 1.5B parameters have been adapted using a\nwide range of strategies. We show that through careful fine-tuning on both\nfinancial documents and instructions, these foundation models can be adapted to\nthe target domain. Moreover, we observe that small LLMs have comparable\nperformance to larger scale models, while being more efficient in terms of\nparameters and data. In addition to the models, we show how to generate\nartificial instructions through LLMs to augment the number of samples of the\ninstruction dataset.",
      "tldr_zh": "这篇论文探讨了Large Language Model (LLM) 在金融情绪分析中的适应方法，以应对金融领域文本复杂性和特定术语带来的挑战。研究者针对两个小于1.5B参数的基模型，采用多种细调策略，包括在金融文档和指令数据集上的训练，从而提升模型在目标领域的性能。结果表明，这些小型LLM的表现可与大型模型媲美，同时在参数和数据使用效率上更具优势；此外，论文还展示了如何利用LLM生成人工指令来扩充数据集，从而提高训练样本数量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14777v1",
      "published_date": "2024-01-26 11:04:01 UTC",
      "updated_date": "2024-01-26 11:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:39:00.315976"
    },
    {
      "arxiv_id": "2401.15124v1",
      "title": "Sensor-Based Data Acquisition via Ubiquitous Device to Detect Muscle Strength Training Activities",
      "title_zh": "翻译失败",
      "authors": [
        "E. Wianto",
        "H. Toba",
        "M. Malinda",
        "Chien-Hsu Chen"
      ],
      "abstract": "Maintaining a high quality of life through physical activities (PA) to\nprevent health decline is crucial. However, the relationship between\nindividuals health status, PA preferences, and motion factors is complex. PA\ndiscussions consistently show a positive correlation with healthy aging\nexperiences, but no explicit relation to specific types of musculoskeletal\nexercises. Taking advantage of the increasingly widespread existence of\nsmartphones, especially in Indonesia, this research utilizes embedded sensors\nfor Human Activity Recognition (HAR). Based on 25 participants data, performing\nnine types of selected motion, this study has successfully identified important\nsensor attributes that play important roles in the right and left hands for\nmuscle strength motions as the basis for developing machine learning models\nwith the LSTM algorithm.",
      "tldr_zh": "该研究探讨了利用智能手机内置传感器进行人类活动识别（HAR），以检测肌肉力量训练活动，从而支持健康老龄化和预防健康衰退。基于25名参与者的数据，该方法分析了九种特定动作，成功识别了左右手的关键传感器属性。研究开发了基于LSTM算法的机器学习模型，作为构建个性化肌肉训练系统的基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.1.2"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 4 figures, AHFE International Conference on Human Factors in\n  Design, Engineering, and Computing",
      "pdf_url": "http://arxiv.org/pdf/2401.15124v1",
      "published_date": "2024-01-26 10:44:44 UTC",
      "updated_date": "2024-01-26 10:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:39:11.060582"
    },
    {
      "arxiv_id": "2401.14749v1",
      "title": "Topology-Aware Exploration of Energy-Based Models Equilibrium: Toric QC-LDPC Codes and Hyperbolic MET QC-LDPC Codes",
      "title_zh": "翻译失败",
      "authors": [
        "Vasiliy Usatyuk",
        "Denis Sapozhnikov",
        "Sergey Egorov"
      ],
      "abstract": "This paper presents a method for achieving equilibrium in the ISING\nHamiltonian when confronted with unevenly distributed charges on an irregular\ngrid. Employing (Multi-Edge) QC-LDPC codes and the Boltzmann machine, our\napproach involves dimensionally expanding the system, substituting charges with\ncirculants, and representing distances through circulant shifts. This results\nin a systematic mapping of the charge system onto a space, transforming the\nirregular grid into a uniform configuration, applicable to Torical and Circular\nHyperboloid Topologies. The paper covers fundamental definitions and notations\nrelated to QC-LDPC Codes, Multi-Edge QC-LDPC codes, and the Boltzmann machine.\nIt explores the marginalization problem in code on the graph probabilistic\nmodels for evaluating the partition function, encompassing exact and\napproximate estimation techniques. Rigorous proof is provided for the\nattainability of equilibrium states for the Boltzmann machine under Torical and\nCircular Hyperboloid, paving the way for the application of our methodology.\nPractical applications of our approach are investigated in Finite Geometry\nQC-LDPC Codes, specifically in Material Science. The paper further explores its\neffectiveness in the realm of Natural Language Processing Transformer Deep\nNeural Networks, examining Generalized Repeat Accumulate Codes,\nSpatially-Coupled and Cage-Graph QC-LDPC Codes. The versatile and impactful\nnature of our topology-aware hardware-efficient quasi-cycle codes equilibrium\nmethod is showcased across diverse scientific domains without the use of\nspecific section delineations.",
      "tldr_zh": "这篇论文提出了一种拓扑感知方法，使用 QC-LDPC Codes 和 Boltzmann machine 来实现 ISING Hamiltonian 在不规则网格上的平衡，通过维度扩展和 circulant 替换，将电荷系统映射到均匀配置，并适用于 Toric 和 Circular Hyperboloid Topologies。论文详细定义了 QC-LDPC Codes 和 Multi-Edge QC-LDPC codes，探讨了图概率模型中的多边际问题及其分区函数的精确和近似估计，并证明了在这些拓扑下 Boltzmann machine 可以达到平衡状态。最终，该方法在材料科学中的 Finite Geometry QC-LDPC Codes 以及 Natural Language Processing 中的 Transformer 神经网络等领域展现了广泛应用，包括 Generalized Repeat Accumulate Codes 和 Spatially-Coupled QC-LDPC Codes。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "16 pages, 29 figures. arXiv admin note: text overlap with\n  arXiv:2307.15778",
      "pdf_url": "http://arxiv.org/pdf/2401.14749v1",
      "published_date": "2024-01-26 10:14:10 UTC",
      "updated_date": "2024-01-26 10:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:39:24.886800"
    },
    {
      "arxiv_id": "2401.14743v1",
      "title": "Synthetic Multimodal Dataset for Empowering Safety and Well-being in Home Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Takanori Ugai",
        "Shusaku Egami",
        "Swe Nwe Nwe Htun",
        "Kouji Kozaki",
        "Takahiro Kawamura",
        "Ken Fukuda"
      ],
      "abstract": "This paper presents a synthetic multimodal dataset of daily activities that\nfuses video data from a 3D virtual space simulator with knowledge graphs\ndepicting the spatiotemporal context of the activities. The dataset is\ndeveloped for the Knowledge Graph Reasoning Challenge for Social Issues\n(KGRC4SI), which focuses on identifying and addressing hazardous situations in\nthe home environment. The dataset is available to the public as a valuable\nresource for researchers and practitioners developing innovative solutions\nrecognizing human behaviors to enhance safety and well-being in",
      "tldr_zh": "这篇论文介绍了Synthetic Multimodal Dataset，一种合成多模态数据集，通过融合3D虚拟空间模拟器的视频数据和knowledge graphs，描绘日常活动的时空上下文。数据集是为Knowledge Graph Reasoning Challenge for Social Issues (KGRC4SI)开发的，旨在识别和解决家庭环境中的危险情况。公开提供的该数据集可作为宝贵资源，帮助研究人员和从业者开发创新解决方案，以识别人类行为并提升安全和福祉。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2 figures,4 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.14743v1",
      "published_date": "2024-01-26 10:05:41 UTC",
      "updated_date": "2024-01-26 10:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:39:36.169903"
    },
    {
      "arxiv_id": "2401.15123v1",
      "title": "Large Language Model Guided Knowledge Distillation for Time Series Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Liu",
        "Shibo He",
        "Qihang Zhou",
        "Shizhong Li",
        "Wenchao Meng"
      ],
      "abstract": "Self-supervised methods have gained prominence in time series anomaly\ndetection due to the scarcity of available annotations. Nevertheless, they\ntypically demand extensive training data to acquire a generalizable\nrepresentation map, which conflicts with scenarios of a few available samples,\nthereby limiting their performance. To overcome the limitation, we propose\n\\textbf{AnomalyLLM}, a knowledge distillation-based time series anomaly\ndetection approach where the student network is trained to mimic the features\nof the large language model (LLM)-based teacher network that is pretrained on\nlarge-scale datasets. During the testing phase, anomalies are detected when the\ndiscrepancy between the features of the teacher and student networks is large.\nTo circumvent the student network from learning the teacher network's feature\nof anomalous samples, we devise two key strategies. 1) Prototypical signals are\nincorporated into the student network to consolidate the normal feature\nextraction. 2) We use synthetic anomalies to enlarge the representation gap\nbetween the two networks. AnomalyLLM demonstrates state-of-the-art performance\non 15 datasets, improving accuracy by at least 14.5\\% in the UCR dataset.",
      "tldr_zh": "该研究提出了一种名为 AnomalyLLM 的时间序列异常检测方法，通过 Large Language Model (LLM) 引导的知识蒸馏来解决自监督模型在数据稀缺场景下的性能限制。学生网络被训练以模仿在大型数据集上预训练的 LLM 教师网络的特征，并在测试时通过两网络特征差异检测异常；为防止学生网络学习异常样本，引入原型信号强化正常特征提取，并使用合成异常扩大表示差距。实验结果显示，AnomalyLLM 在 15 个数据集上达到最先进性能，在 UCR 数据集上准确率至少提高 14.5%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.15123v1",
      "published_date": "2024-01-26 09:51:07 UTC",
      "updated_date": "2024-01-26 09:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:39:48.472586"
    },
    {
      "arxiv_id": "2401.15122v3",
      "title": "A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Shengchao Liu",
        "Weitao Du",
        "Hannan Xu",
        "Yanjing Li",
        "Zhuoxinran Li",
        "Vignesh Bhethanabotla",
        "Divin Yan",
        "Christian Borgs",
        "Anima Anandkumar",
        "Hongyu Guo",
        "Jennifer Chayes"
      ],
      "abstract": "In drug discovery, molecular dynamics (MD) simulation for protein-ligand\nbinding provides a powerful tool for predicting binding affinities, estimating\ntransport properties, and exploring pocket sites. There has been a long history\nof improving the efficiency of MD simulations through better numerical methods\nand, more recently, by utilizing machine learning (ML) methods. Yet, challenges\nremain, such as accurate modeling of extended-timescale simulations. To address\nthis issue, we propose NeuralMD, the first ML surrogate that can facilitate\nnumerical MD and provide accurate simulations in protein-ligand binding\ndynamics. We propose a principled approach that incorporates a novel\nphysics-informed multi-grained group symmetric framework. Specifically, we\npropose (1) the BindingNet model that satisfies group symmetry using vector\nframes and captures the multi-level protein-ligand interactions, and (2) an\naugmented neural differential equation solver that learns the trajectory under\nNewtonian mechanics. For the experiment, we design ten single-trajectory and\nthree multi-trajectory binding simulation tasks. We demonstrate the efficiency\nand effectiveness of NeuralMD, achieving over 1K$\\times$ speedup compared to\nstandard numerical MD simulations. NeuralMD also outperforms all other ML\napproaches, achieving up to 15$\\times$ reduction in reconstruction error and\n70% increase in validity. Additionally, we qualitatively illustrate that the\noscillations in the predicted trajectories align more closely with ground-truth\ndynamics than those of other machine-learning methods. We believe NeuralMD\npaves the foundation for a new research paradigm in simulating protein-ligand\ndynamics.",
      "tldr_zh": "本文提出 NeuralMD，一种机器学习（ML）代理，用于提升分子动力学（MD）模拟在蛋白质-配体结合动力学中的效率和准确性，解决长期模拟的挑战。NeuralMD 包括 BindingNet 模型，该模型通过向量框架实现群对称性并捕捉多层次相互作用，以及一个增强的神经微分方程求解器，基于牛顿力学学习轨迹。在实验中，NeuralMD 比标准 MD 模拟快 1000 倍，比其他 ML 方法减少重建错误 15 倍并提高有效性 70%，为蛋白质-配体动力学模拟开辟新研究范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM",
        "q-bio.QM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15122v3",
      "published_date": "2024-01-26 09:35:17 UTC",
      "updated_date": "2024-11-26 18:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:40:02.494048"
    },
    {
      "arxiv_id": "2401.14717v1",
      "title": "Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhan Wang",
        "Long Chen",
        "Aparna Khare",
        "Anirudh Raju",
        "Pranav Dheram",
        "Di He",
        "Minhua Wu",
        "Andreas Stolcke",
        "Venkatesh Ravichandran"
      ],
      "abstract": "We propose an approach for continuous prediction of turn-taking and\nbackchanneling locations in spoken dialogue by fusing a neural acoustic model\nwith a large language model (LLM). Experiments on the Switchboard human-human\nconversation dataset demonstrate that our approach consistently outperforms the\nbaseline models with single modality. We also develop a novel multi-task\ninstruction fine-tuning strategy to further benefit from LLM-encoded knowledge\nfor understanding the tasks and conversational contexts, leading to additional\nimprovements. Our approach demonstrates the potential of combined LLMs and\nacoustic models for a more natural and conversational interaction between\nhumans and speech-enabled AI agents.",
      "tldr_zh": "本研究提出了一种融合神经声学模型和大型语言模型(LLM)的approach，用于在口语对话中连续预测转话点(turn-taking)和回应对话点(backchanneling)。在Switchboard数据集上的实验显示，该方法比单一模态基线模型表现出色，显著提升了预测准确性。研究还开发了新型多任务指令微调策略，利用LLM的知识来更好地理解任务和对话上下文，进一步优化了性能。该approach展示了结合声学模型和LLM的潜力，有助于实现人类与语音AI代理之间更自然、流畅的互动。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in IEEE ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.14717v1",
      "published_date": "2024-01-26 08:59:07 UTC",
      "updated_date": "2024-01-26 08:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:40:12.847505"
    },
    {
      "arxiv_id": "2401.14707v2",
      "title": "AFD: Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement",
      "title_zh": "AFD: 通过特征解耦缓解特征差距以实现对抗鲁棒性",
      "authors": [
        "Nuoyan Zhou",
        "Dawei Zhou",
        "Decheng Liu",
        "Nannan Wang",
        "Xinbo Gao"
      ],
      "abstract": "Adversarial fine-tuning methods enhance adversarial robustness via\nfine-tuning the pre-trained model in an adversarial training manner. However,\nwe identify that some specific latent features of adversarial samples are\nconfused by adversarial perturbation and lead to an unexpectedly increasing gap\nbetween features in the last hidden layer of natural and adversarial samples.\nTo address this issue, we propose a disentanglement-based approach to\nexplicitly model and further remove the specific latent features. We introduce\na feature disentangler to separate out the specific latent features from the\nfeatures of the adversarial samples, thereby boosting robustness by eliminating\nthe specific latent features. Besides, we align clean features in the\npre-trained model with features of adversarial samples in the fine-tuned model,\nto benefit from the intrinsic features of natural samples. Empirical\nevaluations on three benchmark datasets demonstrate that our approach surpasses\nexisting adversarial fine-tuning methods and adversarial training baselines.",
      "tldr_zh": "该研究识别出对抗微调（Adversarial fine-tuning）过程中，特定潜在特征因对抗扰动而导致自然样本和对抗样本在最后一隐藏层特征间存在特征差距（feature gap），从而影响模型鲁棒性。为解决此问题，作者提出AFD方法，通过feature disentangler分离并移除对抗样本中的特定潜在特征，同时对齐预训练模型的干净特征（clean features）与微调模型的对抗样本特征，以提升整体鲁棒性。在三个基准数据集上的实证评估显示，AFD超越了现有的对抗微调方法和对抗训练基线。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.14707v2",
      "published_date": "2024-01-26 08:38:57 UTC",
      "updated_date": "2024-12-10 16:28:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:40:24.223690"
    },
    {
      "arxiv_id": "2402.01717v1",
      "title": "From RAG to QA-RAG: Integrating Generative AI for Pharmaceutical Regulatory Compliance Process",
      "title_zh": "翻译失败",
      "authors": [
        "Jaewoong Kim",
        "Moohong Min"
      ],
      "abstract": "Regulatory compliance in the pharmaceutical industry entails navigating\nthrough complex and voluminous guidelines, often requiring significant human\nresources. To address these challenges, our study introduces a chatbot model\nthat utilizes generative AI and the Retrieval Augmented Generation (RAG)\nmethod. This chatbot is designed to search for guideline documents relevant to\nthe user inquiries and provide answers based on the retrieved guidelines.\nRecognizing the inherent need for high reliability in this domain, we propose\nthe Question and Answer Retrieval Augmented Generation (QA-RAG) model. In\ncomparative experiments, the QA-RAG model demonstrated a significant\nimprovement in accuracy, outperforming all other baselines including\nconventional RAG methods. This paper details QA-RAG's structure and performance\nevaluation, emphasizing its potential for the regulatory compliance domain in\nthe pharmaceutical industry and beyond. We have made our work publicly\navailable for further research and development.",
      "tldr_zh": "本研究针对制药行业复杂的监管合规过程，提出了一种整合生成式 AI 和 Retrieval Augmented Generation (RAG) 的聊天机器人模型，以减少人力依赖。该模型引入 Question and Answer Retrieval Augmented Generation (QA-RAG) 改进版，通过检索相关指南文档并生成基于问题的答案，确保高可靠性。在比较实验中，QA-RAG 在准确性上显著优于传统 RAG 和其他基线模型，为制药监管合规领域提供高效工具，并公开了相关工作以推动进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "I.2.7; I.2.1; J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "Total number of pages: 9. Total number of figures: 2. For the source\n  code and experimental results of this paper, see\n  https://github.com/jwoongkim11/QA-RAG. For the dataset used in training and\n  evaluating the model, see https://huggingface.co/datasets/Jaymax/FDA\n  Pharmaceuticals FAQ",
      "pdf_url": "http://arxiv.org/pdf/2402.01717v1",
      "published_date": "2024-01-26 08:23:29 UTC",
      "updated_date": "2024-01-26 08:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:40:35.911710"
    },
    {
      "arxiv_id": "2401.14702v1",
      "title": "FairSample: Training Fair and Accurate Graph Convolutional Neural Networks Efficiently",
      "title_zh": "FairSample: 高效训练公平且准确的图卷积神经网络",
      "authors": [
        "Zicun Cong",
        "Shi Baoxu",
        "Shan Li",
        "Jaewon Yang",
        "Qi He",
        "Jian Pei"
      ],
      "abstract": "Fairness in Graph Convolutional Neural Networks (GCNs) becomes a more and\nmore important concern as GCNs are adopted in many crucial applications.\nSocietal biases against sensitive groups may exist in many real world graphs.\nGCNs trained on those graphs may be vulnerable to being affected by such\nbiases. In this paper, we adopt the well-known fairness notion of demographic\nparity and tackle the challenge of training fair and accurate GCNs efficiently.\nWe present an in-depth analysis on how graph structure bias, node attribute\nbias, and model parameters may affect the demographic parity of GCNs. Our\ninsights lead to FairSample, a framework that jointly mitigates the three types\nof biases. We employ two intuitive strategies to rectify graph structures.\nFirst, we inject edges across nodes that are in different sensitive groups but\nsimilar in node features. Second, to enhance model fairness and retain model\nquality, we develop a learnable neighbor sampling policy using reinforcement\nlearning. To address the bias in node features and model parameters, FairSample\nis complemented by a regularization objective to optimize fairness.",
      "tldr_zh": "该论文分析了图卷积神经网络 (GCNs) 在存在社会偏见的真实世界图上训练时，可能导致 demographic parity（人口统计平价）公平性问题的原因，包括图结构偏见、节点属性偏见和模型参数影响。针对这些挑战，作者提出了 FairSample 框架，通过注入跨敏感组但特征相似的边、采用强化学习开发可学习的邻居采样策略，以及添加正则化目标，共同缓解三种偏见。实验结果表明，FairSample 能高效训练出既公平又准确的 GCNs，从而提升模型在关键应用中的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by TKDE 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.14702v1",
      "published_date": "2024-01-26 08:17:12 UTC",
      "updated_date": "2024-01-26 08:17:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:40:49.060787"
    },
    {
      "arxiv_id": "2402.04267v1",
      "title": "Application analysis of ai technology combined with spiral CT scanning in early lung cancer screening",
      "title_zh": "翻译失败",
      "authors": [
        "Shulin Li",
        "Liqiang Yu",
        "Bo Liu",
        "Qunwei Lin",
        "Jiaxin Huang"
      ],
      "abstract": "At present, the incidence and fatality rate of lung cancer in China rank\nfirst among all malignant tumors. Despite the continuous development and\nimprovement of China's medical level, the overall 5-year survival rate of lung\ncancer patients is still lower than 20% and is staged. A number of studies have\nconfirmed that early diagnosis and treatment of early stage lung cancer is of\ngreat significance to improve the prognosis of patients. In recent years,\nartificial intelligence technology has gradually begun to be applied in\noncology. ai is used in cancer screening, clinical diagnosis, radiation therapy\n(image acquisition, at-risk organ segmentation, image calibration and delivery)\nand other aspects of rapid development. However, whether medical ai can be\nsocialized depends on the public's attitude and acceptance to a certain extent.\nHowever, at present, there are few studies on the diagnosis of early lung\ncancer by AI technology combined with SCT scanning. In view of this, this study\napplied the combined method in early lung cancer screening, aiming to find a\nsafe and efficient screening mode and provide a reference for clinical\ndiagnosis and treatment.",
      "tldr_zh": "本研究分析了AI技术与螺旋CT扫描结合在早期肺癌筛查中的应用，针对中国肺癌高发病率和死亡率（5年生存率低于20%）的问题，强调早期诊断对改善患者预后的重要性。该方法利用AI在癌症筛查和临床诊断中的优势，旨在开发一种安全高效的筛查模式，同时考虑公众对AI的接受度作为社会化因素。通过此研究，为临床诊断和治疗提供参考。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "physics.med-ph",
      "comment": "This article was accepted by Frontiers in Computing and Intelligent\n  Systems https://drpress.org/ojs/index.php/fcis/article/view/15781. arXiv\n  admin note: text overlap with arXiv:nlin/0508031 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2402.04267v1",
      "published_date": "2024-01-26 07:58:09 UTC",
      "updated_date": "2024-01-26 07:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:41:00.591028"
    },
    {
      "arxiv_id": "2401.14698v2",
      "title": "Under the Surface: Tracking the Artifactuality of LLM-Generated Data",
      "title_zh": "在表面之下：跟踪 LLM 生成数据的伪迹性",
      "authors": [
        "Debarati Das",
        "Karin De Langis",
        "Anna Martin-Boyle",
        "Jaehyung Kim",
        "Minhwa Lee",
        "Zae Myung Kim",
        "Shirley Anugrah Hayati",
        "Risako Owan",
        "Bin Hu",
        "Ritik Parkar",
        "Ryan Koo",
        "Jonginn Park",
        "Aahan Tyagi",
        "Libby Ferland",
        "Sanjali Roy",
        "Vincent Liu",
        "Dongyeop Kang"
      ],
      "abstract": "This work delves into the expanding role of large language models (LLMs) in\ngenerating artificial data. LLMs are increasingly employed to create a variety\nof outputs, including annotations, preferences, instruction prompts, simulated\ndialogues, and free text. As these forms of LLM-generated data often intersect\nin their application, they exert mutual influence on each other and raise\nsignificant concerns about the quality and diversity of the artificial data\nincorporated into training cycles, leading to an artificial data ecosystem. To\nthe best of our knowledge, this is the first study to aggregate various types\nof LLM-generated text data, from more tightly constrained data like \"task\nlabels\" to more lightly constrained \"free-form text\". We then stress test the\nquality and implications of LLM-generated artificial data, comparing it with\nhuman data across various existing benchmarks. Despite artificial data's\ncapability to match human performance, this paper reveals significant hidden\ndisparities, especially in complex tasks where LLMs often miss the nuanced\nunderstanding of intrinsic human-generated content. This study critically\nexamines diverse LLM-generated data and emphasizes the need for ethical\npractices in data creation and when using LLMs. It highlights the LLMs'\nshortcomings in replicating human traits and behaviors, underscoring the\nimportance of addressing biases and artifacts produced in LLM-generated content\nfor future research and development. All data and code are available on our\nproject page.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)生成的人工数据在质量和多样性方面的潜在问题，包括注解、偏好、指令提示、模拟对话和自由文本，这些数据相互影响形成了一个人工数据生态系统。研究首次聚合了从严格约束的任务标签到松散约束的自由文本等多种LLMs生成数据类型，并通过与人类数据在现有基准上的比较进行压力测试。结果显示，虽然人工数据能匹配人类性能，但在复杂任务中，LLMs往往忽略了人类内容的细微理解，导致隐藏的差异和人工制品(arifacts)。论文强调了在数据创建和使用LLMs时需采用道德实践，以解决偏见和局限性，并呼吁未来研究关注这些问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Core Authors: Debarati Das, Karin De Langis, Anna Martin-Boyle,\n  Jaehyung Kim, Minhwa Lee and Zae Myung Kim | Project lead : Debarati Das | PI\n  : Dongyeop Kang",
      "pdf_url": "http://arxiv.org/pdf/2401.14698v2",
      "published_date": "2024-01-26 07:53:27 UTC",
      "updated_date": "2024-01-30 05:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:41:14.108006"
    },
    {
      "arxiv_id": "2401.14696v1",
      "title": "Asymptotic Midpoint Mixup for Margin Balancing and Moderate Broadening",
      "title_zh": "翻译失败",
      "authors": [
        "Hoyong Kim",
        "Semi Lee",
        "Kangil Kim"
      ],
      "abstract": "In the feature space, the collapse between features invokes critical problems\nin representation learning by remaining the features undistinguished.\nInterpolation-based augmentation methods such as mixup have shown their\neffectiveness in relieving the collapse problem between different classes,\ncalled inter-class collapse. However, intra-class collapse raised in\ncoarse-to-fine transfer learning has not been discussed in the augmentation\napproach. To address them, we propose a better feature augmentation method,\nasymptotic midpoint mixup. The method generates augmented features by\ninterpolation but gradually moves them toward the midpoint of inter-class\nfeature pairs. As a result, the method induces two effects: 1) balancing the\nmargin for all classes and 2) only moderately broadening the margin until it\nholds maximal confidence. We empirically analyze the collapse effects by\nmeasuring alignment and uniformity with visualizing representations. Then, we\nvalidate the intra-class collapse effects in coarse-to-fine transfer learning\nand the inter-class collapse effects in imbalanced learning on long-tailed\ndatasets. In both tasks, our method shows better performance than other\naugmentation methods.",
      "tldr_zh": "本研究针对特征空间中的collapse问题，提出了一种改进的特征增强方法：asymptotic midpoint mixup，以缓解inter-class collapse和intra-class collapse。方法通过插值生成增强特征，并逐渐向inter-class特征对的中点移动，从而实现margin balancing（平衡所有类别的margin）和moderate broadening（适度拓宽margin，直到达到最大置信度）。实验结果显示，该方法在coarse-to-fine transfer learning和long-tailed datasets上的imbalanced learning任务中，均优于其他augmentation方法，并在通过alignment、uniformity测量和可视化表示中验证了collapse效果的改善。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14696v1",
      "published_date": "2024-01-26 07:36:57 UTC",
      "updated_date": "2024-01-26 07:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:41:24.542839"
    },
    {
      "arxiv_id": "2401.14694v3",
      "title": "TA-RNN: an Attention-based Time-aware Recurrent Neural Network Architecture for Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Al Olaimat",
        "Serdar Bozdag"
      ],
      "abstract": "Motivation: Electronic Health Records (EHR) represent a comprehensive\nresource of a patient's medical history. EHR are essential for utilizing\nadvanced technologies such as deep learning (DL), enabling healthcare providers\nto analyze extensive data, extract valuable insights, and make precise and\ndata-driven clinical decisions. DL methods such as Recurrent Neural Networks\n(RNN) have been utilized to analyze EHR to model disease progression and\npredict diagnosis. However, these methods do not address some inherent\nirregularities in EHR data such as irregular time intervals between clinical\nvisits. Furthermore, most DL models are not interpretable. In this study, we\npropose two interpretable DL architectures based on RNN, namely Time-Aware RNN\n(TA-RNN) and TA-RNN-Autoencoder (TA-RNN-AE) to predict patient's clinical\noutcome in EHR at next visit and multiple visits ahead, respectively. To\nmitigate the impact of irregular time intervals, we propose incorporating time\nembedding of the elapsed times between visits. For interpretability, we propose\nemploying a dual-level attention mechanism that operates between visits and\nfeatures within each visit.\n  Results: The results of the experiments conducted on Alzheimer's Disease\nNeuroimaging Initiative (ADNI) and National Alzheimer's Coordinating Center\n(NACC) datasets indicated superior performance of proposed models for\npredicting Alzheimer's Disease (AD) compared to state-of-the-art and baseline\napproaches based on F2 and sensitivity. Additionally, TA-RNN showed superior\nperformance on Medical Information Mart for Intensive Care (MIMIC-III) dataset\nfor mortality prediction. In our ablation study, we observed enhanced\npredictive performance by incorporating time embedding and attention\nmechanisms. Finally, investigating attention weights helped identify\ninfluential visits and features in predictions.",
      "tldr_zh": "本研究针对电子健康记录（EHR）数据中的不规则时间间隔和模型可解释性问题，提出了一种基于注意力机制的时序感知循环神经网络（TA-RNN）架构及其变体 TA-RNN-Autoencoder（TA-RNN-AE）。该方法通过融入时间嵌入来缓解临床访问间的不规则间隔，并采用双层注意力机制（在访问间和每个访问内的特征层面）提升模型的解释性，从而预测患者的下次或多个访问后的临床结果。实验在阿尔茨海默病神经影像倡议（ADNI）和国家阿尔茨海默协调中心（NACC）数据集上显示，TA-RNN 在预测阿尔茨海默病（AD）时，基于 F2 和灵敏度指标优于现有基线模型；此外，在医疗信息马特重症监护（MIMIC-III）数据集上，该模型在死亡率预测中也表现出色。消融研究证实，时间嵌入和注意力机制显著提升了预测性能，并通过分析注意力权重识别了关键影响因素。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14694v3",
      "published_date": "2024-01-26 07:34:53 UTC",
      "updated_date": "2024-04-03 23:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:41:37.874687"
    },
    {
      "arxiv_id": "2401.14665v1",
      "title": "PepGB: Facilitating peptide drug discovery via graph neural networks",
      "title_zh": "PepGB：通过图神经网络促进肽药物发现",
      "authors": [
        "Yipin Lei",
        "Xu Wang",
        "Meng Fang",
        "Han Li",
        "Xiang Li",
        "Jianyang Zeng"
      ],
      "abstract": "Peptides offer great biomedical potential and serve as promising drug\ncandidates. Currently, the majority of approved peptide drugs are directly\nderived from well-explored natural human peptides. It is quite necessary to\nutilize advanced deep learning techniques to identify novel peptide drugs in\nthe vast, unexplored biochemical space. Despite various in silico methods\nhaving been developed to accelerate peptide early drug discovery, existing\nmodels face challenges of overfitting and lacking generalizability due to the\nlimited size, imbalanced distribution and inconsistent quality of experimental\ndata. In this study, we propose PepGB, a deep learning framework to facilitate\npeptide early drug discovery by predicting peptide-protein interactions\n(PepPIs). Employing graph neural networks, PepGB incorporates a fine-grained\nperturbation module and a dual-view objective with contrastive learning-based\npeptide pre-trained representation to predict PepPIs. Through rigorous\nevaluations, we demonstrated that PepGB greatly outperforms baselines and can\naccurately identify PepPIs for novel targets and peptide hits, thereby\ncontributing to the target identification and hit discovery processes. Next, we\nderive an extended version, diPepGB, to tackle the bottleneck of modeling\nhighly imbalanced data prevalent in lead generation and optimization processes.\nUtilizing directed edges to represent relative binding strength between two\npeptide nodes, diPepGB achieves superior performance in real-world assays. In\nsummary, our proposed frameworks can serve as potent tools to facilitate\npeptide early drug discovery.",
      "tldr_zh": "本文提出 PepGB 框架，利用 graph neural networks 预测肽-蛋白质相互作用（PepPIs），以克服现有模型在肽药物发现中的过拟合和泛化性问题。PepGB 整合了 fine-grained perturbation module、dual-view objective 和 contrastive learning 的肽预训练表示，通过严格评估显著优于基线模型，能准确识别新目标和新肽。扩展版本 diPepGB 通过使用有向边表示相对结合强度，处理高度不平衡数据，在实际测试中表现出色。这些框架为肽早期药物发现中的靶点识别和候选物发现提供有力工具。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14665v1",
      "published_date": "2024-01-26 06:13:09 UTC",
      "updated_date": "2024-01-26 06:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:41:50.602944"
    },
    {
      "arxiv_id": "2401.15121v2",
      "title": "Expressive Power of ReLU and Step Networks under Floating-Point Operations",
      "title_zh": "ReLU 和阶跃网络在浮点运算下的表达能力",
      "authors": [
        "Yeachan Park",
        "Geonho Hwang",
        "Wonyeol Lee",
        "Sejun Park"
      ],
      "abstract": "The study of the expressive power of neural networks has investigated the\nfundamental limits of neural networks. Most existing results assume real-valued\ninputs and parameters as well as exact operations during the evaluation of\nneural networks. However, neural networks are typically executed on computers\nthat can only represent a tiny subset of the reals and apply inexact\noperations, i.e., most existing results do not apply to neural networks used in\npractice. In this work, we analyze the expressive power of neural networks\nunder a more realistic setup: when we use floating-point numbers and operations\nas in practice. Our first set of results assumes floating-point operations\nwhere the significand of a float is represented by finite bits but its exponent\ncan take any integer value. Under this setup, we show that neural networks\nusing a binary threshold unit or ReLU can memorize any finite input/output\npairs and can approximate any continuous function within an arbitrary error. In\nparticular, the number of parameters in our constructions for universal\napproximation and memorization coincides with that in classical results\nassuming exact mathematical operations. We also show similar results on\nmemorization and universal approximation when floating-point operations use\nfinite bits for both significand and exponent; these results are applicable to\nmany popular floating-point formats such as those defined in the IEEE 754\nstandard (e.g., 32-bit single-precision format) and bfloat16.",
      "tldr_zh": "本文分析了在浮点操作下，ReLU和Step网络的表达能力，填补了现有理论假设精确操作与实际计算机实现的差距。第一组结果假设浮点数的尾数用有限位表示但指数任意，证明这些网络能记忆任何有限输入/输出对，并以任意误差逼近任何连续函数，且所需参数数量与经典结果相当。第二组结果扩展到尾数和指数均有限位的浮点操作（如IEEE 754标准的32-bit single-precision格式），同样实现了记忆和通用逼近能力。该研究为实际神经网络的设计和应用提供了更可靠的理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15121v2",
      "published_date": "2024-01-26 05:59:40 UTC",
      "updated_date": "2024-07-16 01:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:42:01.916022"
    },
    {
      "arxiv_id": "2401.14636v1",
      "title": "Efficient Constraint Generation for Stochastic Shortest Path Problems",
      "title_zh": "随机最短路径问题的有效约束生成",
      "authors": [
        "Johannes Schmalz",
        "Felipe Trevizan"
      ],
      "abstract": "Current methods for solving Stochastic Shortest Path Problems (SSPs) find\nstates' costs-to-go by applying Bellman backups, where state-of-the-art methods\nemploy heuristics to select states to back up and prune. A fundamental\nlimitation of these algorithms is their need to compute the cost-to-go for\nevery applicable action during each state backup, leading to unnecessary\ncomputation for actions identified as sub-optimal. We present new connections\nbetween planning and operations research and, using this framework, we address\nthis issue of unnecessary computation by introducing an efficient version of\nconstraint generation for SSPs. This technique allows algorithms to ignore\nsub-optimal actions and avoid computing their costs-to-go. We also apply our\nnovel technique to iLAO* resulting in a new algorithm, CG-iLAO*. Our\nexperiments show that CG-iLAO* ignores up to 57% of iLAO*'s actions and it\nsolves problems up to 8x and 3x faster than LRTDP and iLAO*.",
      "tldr_zh": "本文针对 Stochastic Shortest Path Problems (SSPs) 的现有算法问题，提出了一种高效的约束生成技术，以避免在 Bellman backups 过程中计算次优动作的成本-to-go，从而减少不必要的计算。研究者将此技术应用于 iLAO* 算法，开发出新的 CG-iLAO* 算法。实验结果显示，CG-iLAO* 能忽略多达 57% 的动作，并比 LRTDP 和 iLAO* 分别快 8 倍和 3 倍，提高了 SSPs 求解的整体效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of AAAI 2024 paper",
      "pdf_url": "http://arxiv.org/pdf/2401.14636v1",
      "published_date": "2024-01-26 04:00:07 UTC",
      "updated_date": "2024-01-26 04:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:42:13.572953"
    },
    {
      "arxiv_id": "2401.14630v1",
      "title": "An Empirical Investigation of Domain Adaptation Ability for Chinese Spelling Check Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Wang",
        "Ruoqing Zhao",
        "Hongliang Dai",
        "Piji Li"
      ],
      "abstract": "Chinese Spelling Check (CSC) is a meaningful task in the area of Natural\nLanguage Processing (NLP) which aims at detecting spelling errors in Chinese\ntexts and then correcting these errors. However, CSC models are based on\npretrained language models, which are trained on a general corpus.\nConsequently, their performance may drop when confronted with downstream tasks\ninvolving domain-specific terms. In this paper, we conduct a thorough\nevaluation about the domain adaption ability of various typical CSC models by\nbuilding three new datasets encompassing rich domain-specific terms from the\nfinancial, medical, and legal domains. Then we conduct empirical investigations\nin the corresponding domain-specific test datasets to ascertain the\ncross-domain adaptation ability of several typical CSC models. We also test the\nperformance of the popular large language model ChatGPT. As shown in our\nexperiments, the performances of the CSC models drop significantly in the new\ndomains.",
      "tldr_zh": "这篇论文调查了 Chinese Spelling Check (CSC) 模型的领域适应能力，针对 CSC 模型基于一般语料训练而在领域特定任务中性能下降的问题。研究者构建了三个新数据集，涵盖金融、医疗和法律领域的专业术语，用于评估多种典型 CSC 模型的跨领域表现，并测试了大型语言模型 ChatGPT 的效果。实验结果显示，这些模型在新领域数据集上的准确率显著下降，突显了 CSC 模型在处理领域特定术语时的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICASSP2024",
      "pdf_url": "http://arxiv.org/pdf/2401.14630v1",
      "published_date": "2024-01-26 03:49:55 UTC",
      "updated_date": "2024-01-26 03:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:42:24.978587"
    },
    {
      "arxiv_id": "2401.15120v2",
      "title": "Incorporating simulated spatial context information improves the effectiveness of contrastive learning models",
      "title_zh": "整合模拟的空间上下文信息提高了对比学习模型的有效性",
      "authors": [
        "Lizhen Zhu",
        "James Z. Wang",
        "Wonseuk Lee",
        "Brad Wyble"
      ],
      "abstract": "Visual learning often occurs in a specific context, where an agent acquires\nskills through exploration and tracking of its location in a consistent\nenvironment. The historical spatial context of the agent provides a similarity\nsignal for self-supervised contrastive learning. We present a unique approach,\ntermed Environmental Spatial Similarity (ESS), that complements existing\ncontrastive learning methods. Using images from simulated, photorealistic\nenvironments as an experimental setting, we demonstrate that ESS outperforms\ntraditional instance discrimination approaches. Moreover, sampling additional\ndata from the same environment substantially improves accuracy and provides new\naugmentations. ESS allows remarkable proficiency in room classification and\nspatial prediction tasks, especially in unfamiliar environments. This learning\nparadigm has the potential to enable rapid visual learning in agents operating\nin new environments with unique visual characteristics. Potentially\ntransformative applications span from robotics to space exploration. Our proof\nof concept demonstrates improved efficiency over methods that rely on\nextensive, disconnected datasets.",
      "tldr_zh": "本研究提出了一种名为Environmental Spatial Similarity (ESS)的创新方法，通过整合模拟的空间上下文信息，增强对比学习(contrastive learning)模型的有效性。该方法利用代理在一致环境中的历史位置作为相似性信号，并在模拟逼真环境中进行实验，显著优于传统实例区分(instance discrimination)方法。结果显示，ESS在房间分类和空间预测任务中表现出色，尤其在新环境中能实现快速学习，且通过从同一环境采样更多数据，进一步提升准确率和数据增强效率。该方法比依赖大规模分离数据集的传统方法更高效，具有广阔应用潜力，如机器人和太空探索领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15120v2",
      "published_date": "2024-01-26 03:44:58 UTC",
      "updated_date": "2024-03-27 15:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:42:36.431873"
    },
    {
      "arxiv_id": "2402.09433v1",
      "title": "Electrical Behavior Association Mining for Household ShortTerm Energy Consumption Forecasting",
      "title_zh": "电力行为关联挖掘用于家庭短期能源消耗预测",
      "authors": [
        "Heyang Yu",
        "Yuxi Sun",
        "Yintao Liu",
        "Guangchao Geng",
        "Quanyuan Jiang"
      ],
      "abstract": "Accurate household short-term energy consumption forecasting (STECF) is\ncrucial for home energy management, but it is technically challenging, due to\nhighly random behaviors of individual residential users. To improve the\naccuracy of STECF on a day-ahead scale, this paper proposes an novel STECF\nmethodology that leverages association mining in electrical behaviors. First, a\nprobabilistic association quantifying and discovering method is proposed to\nmodel the pairwise behaviors association and generate associated clusters.\nThen, a convolutional neural network-gated recurrent unit (CNN-GRU) based\nforecasting is provided to explore the temporal correlation and enhance\naccuracy. The testing results demonstrate that this methodology yields a\nsignificant enhancement in the STECF.",
      "tldr_zh": "这篇论文针对家庭短期能源消耗预测（STECF）的准确性挑战，提出了一种新方法，通过电气行为关联挖掘（association mining）来处理用户行为的随机性。首先，作者开发了一种概率关联量化与发现方法，用于建模成对行为关联并生成关联集群。其次，利用 CNN-GRU 网络探索时间相关性，从而提升预测精度。测试结果表明，该方法显著提高了 STECF 的性能。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "eess.SP",
      "comment": "3 figures and 4 tables; This manuscript is submitted for possible\n  publication",
      "pdf_url": "http://arxiv.org/pdf/2402.09433v1",
      "published_date": "2024-01-26 03:23:09 UTC",
      "updated_date": "2024-01-26 03:23:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:42:48.813479"
    },
    {
      "arxiv_id": "2401.14617v2",
      "title": "A Systematic Literature Review on Explainability for Machine/Deep Learning-based Software Engineering Research",
      "title_zh": "针对基于机器学习/深度学习的软件工程研究的解释性系统文献综述",
      "authors": [
        "Sicong Cao",
        "Xiaobing Sun",
        "Ratnadira Widyasari",
        "David Lo",
        "Xiaoxue Wu",
        "Lili Bo",
        "Jiale Zhang",
        "Bin Li",
        "Wei Liu",
        "Di Wu",
        "Yixin Chen"
      ],
      "abstract": "The remarkable achievements of Artificial Intelligence (AI) algorithms,\nparticularly in Machine Learning (ML) and Deep Learning (DL), have fueled their\nextensive deployment across multiple sectors, including Software Engineering\n(SE). However, due to their black-box nature, these promising AI-driven SE\nmodels are still far from being deployed in practice. This lack of\nexplainability poses unwanted risks for their applications in critical tasks,\nsuch as vulnerability detection, where decision-making transparency is of\nparamount importance. This paper endeavors to elucidate this interdisciplinary\ndomain by presenting a systematic literature review of approaches that aim to\nimprove the explainability of AI models within the context of SE. The review\ncanvasses work appearing in the most prominent SE & AI conferences and\njournals, and spans 108 papers across 23 unique SE tasks. Based on three key\nResearch Questions (RQs), we aim to (1) summarize the SE tasks where XAI\ntechniques have shown success to date; (2) classify and analyze different XAI\ntechniques; and (3) investigate existing evaluation approaches. Based on our\nfindings, we identified a set of challenges remaining to be addressed in\nexisting studies, together with a set of guidelines highlighting potential\nopportunities we deemed appropriate and important for future work.",
      "tldr_zh": "这篇论文通过系统文献综述，探讨了基于 Machine Learning (ML) 和 Deep Learning (DL) 的 AI 模型在软件工程 (SE) 领域的解释性问题，强调了这些黑箱模型在关键任务（如漏洞检测）中部署的风险。研究分析了 108 篇论文，涵盖 23 个 SE 任务，并基于三个研究问题 (RQs) 总结了 XAI 技术在 SE 任务中的成功应用、不同 XAI 技术的分类与分析，以及现有评估方法。最终，论文识别了当前研究的挑战，并提出了未来工作的指导建议，以提升 AI 模型的可解释性和实际部署潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Under Review in ACM Computing Surveys (Major Revision)",
      "pdf_url": "http://arxiv.org/pdf/2401.14617v2",
      "published_date": "2024-01-26 03:20:40 UTC",
      "updated_date": "2025-02-05 16:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:43:01.379843"
    },
    {
      "arxiv_id": "2401.14616v1",
      "title": "Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse",
      "title_zh": "替代性演讲：补充反叙述的方法，用于更好的话语",
      "authors": [
        "Seungyoon Lee",
        "Dahyun Jung",
        "Chanjun Park",
        "Seolhwa Lee",
        "Heuiseok Lim"
      ],
      "abstract": "We introduce the concept of \"Alternative Speech\" as a new way to directly\ncombat hate speech and complement the limitations of counter-narrative. An\nalternative speech provides practical alternatives to hate speech in real-world\nscenarios by offering speech-level corrections to speakers while considering\nthe surrounding context and promoting speakers to reform. Further, an\nalternative speech can combat hate speech alongside counter-narratives,\noffering a useful tool to address social issues such as racial discrimination\nand gender inequality. We propose the new concept and provide detailed\nguidelines for constructing the necessary dataset. Through discussion, we\ndemonstrate that combining alternative speech and counter-narrative can be a\nmore effective strategy for combating hate speech by complementing specificity\nand guiding capacity of counter-narrative. This paper presents another\nperspective for dealing with hate speech, offering viable remedies to\ncomplement the constraints of current approaches to mitigating harmful bias.",
      "tldr_zh": "本论文引入“Alternative Speech”概念，作为对抗仇恨言论的新方法，旨在补充“counter-narrative”的局限性，通过提供实际的替代言论来纠正说话者在真实情境中的表达，同时考虑上下文并鼓励改革。研究者详细说明了构建相关数据集的指南，并讨论了“Alternative Speech”与“counter-narrative”相结合的优势，例如提升特异性和引导能力，从而更有效地解决社会问题如种族歧视和性别不平等。总体而言，该方法为处理仇恨言论提供了一个新视角，弥补现有策略的不足，并展示了潜在的实际应用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for The First Workshop on Data-Centric AI (DCAI) at ICDM\n  2023",
      "pdf_url": "http://arxiv.org/pdf/2401.14616v1",
      "published_date": "2024-01-26 03:16:54 UTC",
      "updated_date": "2024-01-26 03:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:43:13.182163"
    },
    {
      "arxiv_id": "2401.15119v1",
      "title": "Interpreting Time Series Transformer Models and Sensitivity Analysis of Population Age Groups to COVID-19 Infections",
      "title_zh": "时间序列 Transformer 模型的解释以及人群年龄组对 COVID-19 感染的敏感性分析",
      "authors": [
        "Md Khairul Islam",
        "Tyler Valentine",
        "Timothy Joowon Sue",
        "Ayush Karmacharya",
        "Luke Neil Benham",
        "Zhengguang Wang",
        "Kingsley Kim",
        "Judy Fox"
      ],
      "abstract": "Interpreting deep learning time series models is crucial in understanding the\nmodel's behavior and learning patterns from raw data for real-time\ndecision-making. However, the complexity inherent in transformer-based time\nseries models poses challenges in explaining the impact of individual features\non predictions. In this study, we leverage recent local interpretation methods\nto interpret state-of-the-art time series models. To use real-world datasets,\nwe collected three years of daily case data for 3,142 US counties. Firstly, we\ncompare six transformer-based models and choose the best prediction model for\nCOVID-19 infection. Using 13 input features from the last two weeks, we can\npredict the cases for the next two weeks. Secondly, we present an innovative\nway to evaluate the prediction sensitivity to 8 population age groups over\nhighly dynamic multivariate infection data. Thirdly, we compare our proposed\nperturbation-based interpretation method with related work, including a total\nof eight local interpretation methods. Finally, we apply our framework to\ntraffic and electricity datasets, demonstrating that our approach is generic\nand can be applied to other time-series domains.",
      "tldr_zh": "本研究聚焦于解释时间序列 Transformer 模型的行为，并分析 COVID-19 感染对不同人口年龄组的敏感性。研究者使用 3,142 个美国县的三年每日病例数据，比较六种 Transformer 模型，选出最佳模型，利用过去两周的 13 个输入特征预测未来两周的感染情况。论文提出了一种基于扰动的本地解释方法，与其他八种方法对比，评估了八个年龄组的预测敏感性；最终证明该框架在交通和电力等其他时间序列领域具有通用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.PE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15119v1",
      "published_date": "2024-01-26 02:58:59 UTC",
      "updated_date": "2024-01-26 02:58:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:43:24.981289"
    },
    {
      "arxiv_id": "2401.15118v2",
      "title": "GeoDecoder: Empowering Multimodal Map Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Qi",
        "Mian Dai",
        "Zixian Zheng",
        "Chao Wang"
      ],
      "abstract": "This paper presents GeoDecoder, a dedicated multimodal model designed for\nprocessing geospatial information in maps. Built on the BeitGPT architecture,\nGeoDecoder incorporates specialized expert modules for image and text\nprocessing. On the image side, GeoDecoder utilizes GaoDe Amap as the underlying\nbase map, which inherently encompasses essential details about road and\nbuilding shapes, relative positions, and other attributes. Through the\nutilization of rendering techniques, the model seamlessly integrates external\ndata and features such as symbol markers, drive trajectories, heatmaps, and\nuser-defined markers, eliminating the need for extra feature engineering. The\ntext module of GeoDecoder accepts various context texts and question prompts,\ngenerating text outputs in the style of GPT. Furthermore, the GPT-based model\nallows for the training and execution of multiple tasks within the same model\nin an end-to-end manner. To enhance map cognition and enable GeoDecoder to\nacquire knowledge about the distribution of geographic entities in Beijing, we\ndevised eight fundamental geospatial tasks and conducted pretraining of the\nmodel using large-scale text-image samples. Subsequently, rapid fine-tuning was\nperformed on three downstream tasks, resulting in significant performance\nimprovements. The GeoDecoder model demonstrates a comprehensive understanding\nof map elements and their associated operations, enabling efficient and\nhigh-quality application of diverse geospatial tasks in different business\nscenarios.",
      "tldr_zh": "本研究提出GeoDecoder，一种基于BeitGPT架构的多模态模型，专为处理地图中的地理空间信息而设计。该模型整合了图像专家模块（利用GaoDe Amap作为基础地图，通过渲染技术无缝添加外部数据如符号标记和热力图，无需额外特征工程）和文本模块（接受上下文和问题提示，生成类似GPT的输出），支持端到端训练多个任务。为提升地图认知，研究者设计了八个基本地理空间任务，使用大规模文本-图像样本进行预训练，并在三个下游任务上快速微调，实现了显著性能提升。GeoDecoder展示了全面理解地图元素及其操作的能力，有助于在不同业务场景中高效应用地理空间任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15118v2",
      "published_date": "2024-01-26 02:39:40 UTC",
      "updated_date": "2024-02-18 23:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:43:39.362998"
    },
    {
      "arxiv_id": "2401.14589v2",
      "title": "Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias",
      "title_zh": "通过多智能体对话提升诊断准确性：使用大型语言模型缓解认知偏差",
      "authors": [
        "Yu He Ke",
        "Rui Yang",
        "Sui An Lie",
        "Taylor Xin Yi Lim",
        "Hairil Rizal Abdullah",
        "Daniel Shu Wei Ting",
        "Nan Liu"
      ],
      "abstract": "Background: Cognitive biases in clinical decision-making significantly\ncontribute to errors in diagnosis and suboptimal patient outcomes. Addressing\nthese biases presents a formidable challenge in the medical field.\n  Objective: This study explores the role of large language models (LLMs) in\nmitigating these biases through the utilization of a multi-agent framework. We\nsimulate the clinical decision-making processes through multi-agent\nconversation and evaluate its efficacy in improving diagnostic accuracy.\n  Methods: A total of 16 published and unpublished case reports where cognitive\nbiases have resulted in misdiagnoses were identified from the literature. In\nthe multi-agent framework, we leveraged GPT-4 to facilitate interactions among\nfour simulated agents to replicate clinical team dynamics. Each agent has a\ndistinct role: 1) To make the final diagnosis after considering the\ndiscussions, 2) The devil's advocate and correct confirmation and anchoring\nbias, 3) The tutor and facilitator of the discussion to reduce premature\nclosure bias, and 4) To record and summarize the findings. A total of 80\nsimulations were evaluated for the accuracy of initial diagnosis, top\ndifferential diagnosis and final two differential diagnoses.\n  Results: In a total of 80 responses evaluating both initial and final\ndiagnoses, the initial diagnosis had an accuracy of 0% (0/80), but following\nmulti-agent discussions, the accuracy for the top differential diagnosis\nincreased to 71.3% (57/80), and for the final two differential diagnoses, to\n80.0% (64/80).\n  Conclusions: The framework demonstrated an ability to re-evaluate and correct\nmisconceptions, even in scenarios with misleading initial investigations. The\nLLM-driven multi-agent conversation framework shows promise in enhancing\ndiagnostic accuracy in diagnostically challenging medical scenarios.",
      "tldr_zh": "本研究探讨了利用大型语言模型(LLMs)构建多智能体对话框架，以缓解临床决策中的认知偏差，从而提升诊断准确性。方法涉及使用GPT-4模拟四个代理角色（包括最终诊断者、魔鬼倡导者、导师和记录者），对16个认知偏差导致误诊的案例进行80次模拟讨论。结果显示，初始诊断准确率为0%，但经过多智能体讨论后，顶级差异诊断准确率提高至71.3%，最终两个差异诊断准确率达80.0%。该框架证明了在诊断挑战性医疗场景中，通过重新评估和纠正误解，能够显著改善决策质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.14589v2",
      "published_date": "2024-01-26 01:35:50 UTC",
      "updated_date": "2024-05-12 05:28:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:43:50.560062"
    },
    {
      "arxiv_id": "2401.14571v2",
      "title": "Driving Towards Inclusion: A Systematic Review of AI-powered Accessibility Enhancements for People with Disability in Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Ashish Bastola",
        "Hao Wang",
        "Sayed Pedram Haeri Boroujeni",
        "Julian Brinkley",
        "Ata Jahangir Moshayedi",
        "Abolfazl Razi"
      ],
      "abstract": "This paper provides a comprehensive and, to our knowledge, the first review\nof inclusive human-computer interaction (HCI) within autonomous vehicles (AVs)\nand human-driven cars with partial autonomy, emphasizing accessibility and\nuser-centered design principles. We explore the current technologies and HCI\nsystems designed to enhance passenger experience, particularly for individuals\nwith accessibility needs. Key technologies discussed include brain-computer\ninterfaces, anthropomorphic interaction, virtual reality, augmented reality,\nmode adaptation, voice-activated interfaces, haptic feedback, etc. Each\ntechnology is evaluated for its role in creating an inclusive in-vehicle\nenvironment. Furthermore, we highlight recent interface designs by leading\ncompanies and review emerging concepts and prototypes under development or\ntesting, which show significant potential to address diverse accessibility\nrequirements. Safety considerations, ethical concerns, and adoption of AVs are\nother major issues that require thorough investigation. Building on these\nfindings, we propose an end-to-end design framework that addresses\naccessibility requirements across diverse user demographics, including older\nadults and individuals with physical or cognitive impairments. This work\nprovides actionable insights for designers, researchers, and policymakers\naiming to create safer and more comfortable environments in autonomous and\nregular vehicles accessible to all users.",
      "tldr_zh": "这篇论文首次进行全面系统综述，聚焦于 AI 驱动的无障碍增强技术在自动驾驶车辆 (AVs) 和部分自治车辆中为残疾人士提供的包容性人机交互 (HCI)。它评估了关键技术如 brain-computer interfaces、anthropomorphic interaction、virtual reality、augmented reality、mode adaptation、voice-activated interfaces 和 haptic feedback，在创建包容性车内环境中的作用，并讨论了安全考虑、伦理问题以及 AVs 的采用挑战。基于这些发现，论文提出一个端到端设计框架，针对不同用户群体（如老年人、身体或认知障碍者）的可访问性需求。最终，这为设计师、研究人员和政策制定者提供了可操作的见解，以打造更安全、舒适的车辆环境。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14571v2",
      "published_date": "2024-01-26 00:06:08 UTC",
      "updated_date": "2025-01-09 07:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:44:03.806047"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 57,
  "processed_papers_count": 57,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T00:44:36.398134"
}