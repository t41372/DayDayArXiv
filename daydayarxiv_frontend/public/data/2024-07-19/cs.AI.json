{
  "date": "2024-07-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-19 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于人工智能模型优化、LLM（Large Language Models）应用、多模态学习和医疗AI等领域，亮点包括LLM在电路设计和知识蒸馏的创新方法，以及知名学者如 Martin Wattenberg 和 Fernanda B. Viégas 的作品，这些研究展示了AI在实际应用中的潜力，如高效计算和可解释性提升。\n\n### 重点论文讨论\n我们挑选了最具影响力和话题度的论文，先从AI模型优化和LLM应用入手，这些领域有显著创新和实际影响。接下来，简要聊聊医疗AI和多模态学习的相关工作。最后，对其他论文快速掠过，聚焦核心贡献。\n\n#### 1. LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits（LaMAGIC: 基于语言模型的模拟集成电路拓扑生成）\n   这篇论文引入了 LaMAGIC 模型，通过监督微调的语言模型高效生成模拟电路拓扑，从自定义规范一次性优化设计。主要贡献是实现了高达96%的成功率，并证明了邻接矩阵表示在复杂电路中的适用性，展示了语言模型在图生成中的潜力。\n\n#### 2. Value Internalization: Learning and Generalizing from Social Reward（Value Internalization: 从社会奖励中学习和泛化）\n   作者 Frieda Rong 和 Max Kleiman-Weiner 探讨了强化学习中的价值内化模型，该模型使用内部社会奖励来维持和泛化行为，避免代理在无反馈时退化。关键发现是它能防止“奖励黑客”并在多代理环境中推广亲社会行为，为AI与人类价值观对齐提供基础。\n\n#### 3. Compact Language Models via Pruning and Knowledge Distillation（通过剪枝和知识蒸馏的紧凑语言模型）\n   这篇论文提出了一种高效压缩LLM的方法，通过深度、宽度和注意力剪枝结合知识蒸馏，从15B模型衍生出2-4倍缩减的模型（如8B和4B）。主要发现是它在MMLU基准上比从零训练提高16%，并开源了模型，显著降低了训练计算成本。\n\n#### 4. BOND: Aligning LLMs with Best-of-N Distillation（BOND: 通过Best-of-N蒸馏对齐LLM）\n   作者团队包括谷歌DeepMind的成员，提出BOND算法，使用Jeffreys散度平衡LLM生成分布，模仿Best-of-N采样而不增加推理开销。贡献在于它在摘要和摘要生成任务中优于其他RLHF算法，提升了LLM的鲁棒性。\n\n#### 5. ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities（ChatQA 2: 在长上下文和RAG能力上桥接专有LLM的差距）\n   这篇论文构建了基于Llama 3.0的ChatQA 2模型，支持128K上下文窗口，通过三阶段指令微调提升RAG和长上下文理解。关键发现是它在长序列任务中超越GPT-4-Turbo，并在开源代码中开源权重，展示了开源LLM的潜力。\n\n#### 6. Relational Composition in Neural Networks: A Survey and Call to Action（神经网络中的关系组合：调查与行动呼吁）\n   知名学者 Martin Wattenberg 和 Fernanda B. Viégas（Google研究人员）撰写的调查论文，分析了神经网络中特征向量的关系组合问题。贡献是总结了现有机制并呼吁更多实证研究，帮助理解神经网络如何处理结构化数据。\n\n#### 7. Improving Representation of High-frequency Components for Medical Visual Foundation Models（提升医疗视觉基础模型的高频组件表示）\n   这篇论文提出Frepa策略，通过高频掩码和对抗学习改善医疗图像中高频细节的表示。发现它在32个下游任务中提升了DSC和IoU（如视网膜血管分割提高15%），并适用于多种医疗模态，展示了更泛化的医疗AI模型。\n\n#### 8. CVE-LLM: Automatic vulnerability evaluation in medical device industry using large language models（CVE-LLM: 使用大语言模型的医疗设备漏洞自动评估）\n   论文引入LLM评估医疗设备漏洞，基于历史数据训练模型。贡献是提出人类-循环框架加速评估过程，并比较LLM效果，提升了医疗设备的安全性。\n\n#### 9. Advancing Chart Question Answering with Robust Chart Component Recognition（通过鲁棒图表组件识别提升图表问题回答）\n   这篇工作提出Chartformer框架和QDCAt机制，提升了图表QA的准确性。发现它在mAP和准确率上分别提高了3.2%和15.4%，适用于多模态视觉数据解释。\n\n#### 10. Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery（Discover-then-Name: 通过自动概念发现的无关任务概念瓶颈）\n   论文逆转传统CBM方法，先发现模型中的概念再命名。贡献是生成可解释特征，提升了CBM性能，并开源代码。\n\n其他论文如SQLfuse（SQL生成增强）、System-1.x（LLM规划平衡）、DEPICT（扩散模型解释）等，也涉及AI优化，但我们快速掠过：它们分别在文本到SQL、规划决策和图像解释中引入新方法，提升了效率和可解释性，但细节较技术化，不如上述论文话题度高。\n\n剩余论文多为特定领域应用，如图神经网络（GLAudio）、量子计算（The Extrapolation Power of Implicit Models）和网络安全（Is F1 Score Suboptimal），这些工作虽有贡献（如GLAudio在图数据上的波传播建模），但相对专业或重复性强，我们仅提及核心：它们在各自领域（如医疗图像分割、漏洞评估）提供了新框架或基准，但整体影响力不如AI核心主题显著。\n\n总之，今天的arXiv论文突显了AI的创新应用潜力，建议关注LLM优化和医疗AI方向，以推动实际落地。更多细节可查阅arXiv！",
  "papers": [
    {
      "arxiv_id": "2407.18269v2",
      "title": "LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits",
      "title_zh": "LaMAGIC：基于语言模型的模拟集成电路拓扑生成",
      "authors": [
        "Chen-Chia Chang",
        "Yikang Shen",
        "Shaoze Fan",
        "Jing Li",
        "Shun Zhang",
        "Ningyuan Cao",
        "Yiran Chen",
        "Xin Zhang"
      ],
      "abstract": "In the realm of electronic and electrical engineering, automation of analog\ncircuit is increasingly vital given the complexity and customized requirements\nof modern applications. However, existing methods only develop search-based\nalgorithms that require many simulation iterations to design a custom circuit\ntopology, which is usually a time-consuming process. To this end, we introduce\nLaMAGIC, a pioneering language model-based topology generation model that\nleverages supervised finetuning for automated analog circuit design. LaMAGIC\ncan efficiently generate an optimized circuit design from the custom\nspecification in a single pass. Our approach involves a meticulous development\nand analysis of various input and output formulations for circuit. These\nformulations can ensure canonical representations of circuits and align with\nthe autoregressive nature of LMs to effectively addressing the challenges of\nrepresenting analog circuits as graphs. The experimental results show that\nLaMAGIC achieves a success rate of up to 96\\% under a strict tolerance of 0.01.\nWe also examine the scalability and adaptability of LaMAGIC, specifically\ntesting its performance on more complex circuits. Our findings reveal the\nenhanced effectiveness of our adjacency matrix-based circuit formulation with\nfloating-point input, suggesting its suitability for handling intricate circuit\ndesigns. This research not only demonstrates the potential of language models\nin graph generation, but also builds a foundational framework for future\nexplorations in automated analog circuit design.",
      "tldr_zh": "该研究提出 LaMAGIC，一种基于语言模型的拓扑生成模型，用于自动化模拟集成电路设计，以解决现有搜索算法需多次模拟迭代的低效问题。LaMAGIC 通过监督微调和各种输入输出表述（如邻接矩阵带浮点输入），确保电路的规范表示，并实现从自定义规范到优化电路设计的单次生成。实验结果显示，该模型在严格容差（0.01）下成功率高达96%，并在复杂电路上表现出色，可扩展性强。该工作展示了语言模型在图生成中的潜力，并为未来自动化模拟电路设计奠定基础框架。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "Proceedings of the 41st International Conference on Machine Learning,\n  PMLR 235:6253-6262 https://proceedings.mlr.press/v235/chang24c.html",
      "pdf_url": "http://arxiv.org/pdf/2407.18269v2",
      "published_date": "2024-07-19 22:51:41 UTC",
      "updated_date": "2024-08-29 08:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:07:03.278976"
    },
    {
      "arxiv_id": "2407.14681v1",
      "title": "Value Internalization: Learning and Generalizing from Social Reward",
      "title_zh": "价值内化：从社会奖励中学习和泛化",
      "authors": [
        "Frieda Rong",
        "Max Kleiman-Weiner"
      ],
      "abstract": "Social rewards shape human behavior. During development, a caregiver guides a\nlearner's behavior towards culturally aligned goals and values. How do these\nbehaviors persist and generalize when the caregiver is no longer present, and\nthe learner must continue autonomously? Here, we propose a model of value\ninternalization where social feedback trains an internal social reward (ISR)\nmodel that generates internal rewards when social rewards are unavailable.\nThrough empirical simulations, we show that an ISR model prevents agents from\nunlearning socialized behaviors and enables generalization in\nout-of-distribution tasks. We characterize the implications of incomplete\ninternalization, akin to \"reward hacking\" on the ISR. Additionally, we show\nthat our model internalizes prosocial behavior in a multi-agent environment.\nOur work provides a foundation for understanding how humans acquire and\ngeneralize values and offers insights for aligning AI with human values.",
      "tldr_zh": "该研究探讨了社会奖励如何塑造人类行为，并提出一个价值内化模型，通过社会反馈训练内部社会奖励（ISR）模型，使代理在缺少外部指导时能生成内部奖励并维持行为。实验模拟显示，ISR 模型能防止代理遗忘社会化行为，并在分布外任务中实现泛化，同时揭示了不完全内化的风险，如“reward hacking”。此外，该模型在多智能体环境中成功内化亲社会行为，为理解人类价值获取和实现 AI 与人类价值对齐提供了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Reinforcement Learning Conference (RLC) 2024 & Cognitive Science\n  Conference Oral",
      "pdf_url": "http://arxiv.org/pdf/2407.14681v1",
      "published_date": "2024-07-19 21:53:33 UTC",
      "updated_date": "2024-07-19 21:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:07:14.985411"
    },
    {
      "arxiv_id": "2407.14679v2",
      "title": "Compact Language Models via Pruning and Knowledge Distillation",
      "title_zh": "通过修剪和知识蒸馏的紧凑语言模型",
      "authors": [
        "Saurav Muralidharan",
        "Sharath Turuvekere Sreenivas",
        "Raviraj Joshi",
        "Marcin Chochowski",
        "Mostofa Patwary",
        "Mohammad Shoeybi",
        "Bryan Catanzaro",
        "Jan Kautz",
        "Pavlo Molchanov"
      ],
      "abstract": "Large language models (LLMs) targeting different deployment scales and sizes\nare currently produced by training each variant from scratch; this is extremely\ncompute-intensive. In this paper, we investigate if pruning an existing LLM and\nthen re-training it with a fraction (<3%) of the original training data can be\na suitable alternative to repeated, full retraining. To this end, we develop a\nset of practical and effective compression best practices for LLMs that combine\ndepth, width, attention and MLP pruning with knowledge distillation-based\nretraining; we arrive at these best practices through a detailed empirical\nexploration of pruning strategies for each axis, methods to combine axes,\ndistillation strategies, and search techniques for arriving at optimal\ncompressed architectures. We use this guide to compress the Nemotron-4 family\nof LLMs by a factor of 2-4x, and compare their performance to similarly-sized\nmodels on a variety of language modeling tasks. Deriving 8B and 4B models from\nan already pretrained 15B model using our approach requires up to 40x fewer\ntraining tokens per model compared to training from scratch; this results in\ncompute cost savings of 1.8x for training the full model family (15B, 8B, and\n4B). Minitron models exhibit up to a 16% improvement in MMLU scores compared to\ntraining from scratch, perform comparably to other community models such as\nMistral 7B, Gemma 7B and Llama-3 8B, and outperform state-of-the-art\ncompression techniques from the literature. We have open-sourced Minitron model\nweights on Huggingface, with corresponding supplementary material including\nexample code available on GitHub.",
      "tldr_zh": "本论文探讨了通过修剪(pruning)和知识蒸馏(knowledge distillation)来压缩大型语言模型(LLMs)，以替代从零训练不同规模模型的计算密集方法。研究者开发了一套最佳实践，包括深度、宽度、注意力(attention)和MLP pruning相结合，并使用少于3%的原始训练数据进行重新训练，通过实证探索优化了策略和架构。实验结果显示，在Nemotron-4系列上，模型压缩2-4倍，训练成本节省1.8倍，MMLU分数较从零训练提高16%，性能与Mistral 7B、Gemma 7B和Llama-3 8B相当，并优于现有压缩技术；相关模型权重已在Huggingface开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14679v2",
      "published_date": "2024-07-19 21:47:57 UTC",
      "updated_date": "2024-11-04 17:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:07:28.689001"
    },
    {
      "arxiv_id": "2407.14664v2",
      "title": "Is $F_1$ Score Suboptimal for Cybersecurity Models? Introducing $C_{score}$, a Cost-Aware Alternative for Model Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Manish Marwah",
        "Asad Narayanan",
        "Stephan Jou",
        "Martin Arlitt",
        "Maria Pospelova"
      ],
      "abstract": "The cost of errors related to machine learning classifiers, namely, false\npositives and false negatives, are not equal and are application dependent. For\nexample, in cybersecurity applications, the cost of not detecting an attack is\nvery different from marking a benign activity as an attack. Various design\nchoices during machine learning model building, such as hyperparameter tuning\nand model selection, allow a data scientist to trade-off between these two\nerrors. However, most of the commonly used metrics to evaluate model quality,\nsuch as $F_1$ score, which is defined in terms of model precision and recall,\ntreat both these errors equally, making it difficult for users to optimize for\nthe actual cost of these errors. In this paper, we propose a new cost-aware\nmetric, $C_{score}$ based on precision and recall that can replace $F_1$ score\nfor model evaluation and selection. It includes a cost ratio that takes into\naccount the differing costs of handling false positives and false negatives. We\nderive and characterize the new cost metric, and compare it to $F_1$ score.\nFurther, we use this metric for model thresholding for five cybersecurity\nrelated datasets for multiple cost ratios. The results show an average cost\nsavings of 49%.",
      "tldr_zh": "本论文指出，$F_1$ score 在网络安全模型评估中存在不足，因为它未考虑假阳性(false positives)和假阴性(false negatives)的不同成本，导致优化不准确。作者提出了一种新的成本感知指标 $C_{score}$，基于 precision 和 recall，并纳入成本比率，以更好地评估和选择模型。论文对 $C_{score}$ 进行了推导和与 $F_1$ score 的比较，并在五个网络安全数据集上进行阈值调整实验，结果显示平均节省 49% 的成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14664v2",
      "published_date": "2024-07-19 21:01:19 UTC",
      "updated_date": "2024-07-31 15:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:07:40.743958"
    },
    {
      "arxiv_id": "2407.21038v1",
      "title": "Advancing Chart Question Answering with Robust Chart Component Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Hanwen Zheng",
        "Sijia Wang",
        "Chris Thomas",
        "Lifu Huang"
      ],
      "abstract": "Chart comprehension presents significant challenges for machine learning\nmodels due to the diverse and intricate shapes of charts. Existing multimodal\nmethods often overlook these visual features or fail to integrate them\neffectively for chart question answering (ChartQA). To address this, we\nintroduce Chartformer, a unified framework that enhances chart component\nrecognition by accurately identifying and classifying components such as bars,\nlines, pies, titles, legends, and axes. Additionally, we propose a novel\nQuestion-guided Deformable Co-Attention (QDCAt) mechanism, which fuses chart\nfeatures encoded by Chartformer with the given question, leveraging the\nquestion's guidance to ground the correct answer. Extensive experiments\ndemonstrate that the proposed approaches significantly outperform baseline\nmodels in chart component recognition and ChartQA tasks, achieving improvements\nof 3.2% in mAP and 15.4% in accuracy, respectively. These results underscore\nthe robustness of our solution for detailed visual data interpretation across\nvarious applications.",
      "tldr_zh": "该论文针对图表理解的挑战，提出Chartformer框架，以准确识别和分类图表组件（如bars、lines、pies、titles、legends和axes），从而提升机器学习模型在复杂视觉特征上的表现。论文引入Question-guided Deformable Co-Attention (QDCAt)机制，将Chartformer编码的图表特征与问题融合，利用问题指导来精准定位答案。实验结果显示，该方法在图表组件识别任务中mAP提高了3.2%，在ChartQA任务中准确率提升了15.4%，证明了其在各种应用中对视觉数据解释的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21038v1",
      "published_date": "2024-07-19 20:55:06 UTC",
      "updated_date": "2024-07-19 20:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:08:00.960921"
    },
    {
      "arxiv_id": "2407.14662v1",
      "title": "Relational Composition in Neural Networks: A Survey and Call to Action",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Wattenberg",
        "Fernanda B. Viégas"
      ],
      "abstract": "Many neural nets appear to represent data as linear combinations of \"feature\nvectors.\" Algorithms for discovering these vectors have seen impressive recent\nsuccess. However, we argue that this success is incomplete without an\nunderstanding of relational composition: how (or whether) neural nets combine\nfeature vectors to represent more complicated relationships. To facilitate\nresearch in this area, this paper offers a guided tour of various relational\nmechanisms that have been proposed, along with preliminary analysis of how such\nmechanisms might affect the search for interpretable features. We end with a\nseries of promising areas for empirical research, which may help determine how\nneural networks represent structured data.",
      "tldr_zh": "该论文调查了神经网络中关系组合(Relational Composition)的机制，强调虽然发现特征向量(Feature Vectors)的算法取得了显著成功，但神经网络在组合这些向量以表示更复杂关系方面仍存在不足。作者提供了对各种关系机制的指导性回顾，并初步分析了这些机制如何影响可解释特征的搜索。论文呼吁开展实证研究，以更好地理解神经网络如何处理结构化数据。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14662v1",
      "published_date": "2024-07-19 20:50:57 UTC",
      "updated_date": "2024-07-19 20:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:08:03.565466"
    },
    {
      "arxiv_id": "2407.14658v1",
      "title": "A New Lightweight Hybrid Graph Convolutional Neural Network -- CNN Scheme for Scene Classification using Object Detection Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Ayman Beghdadi",
        "Azeddine Beghdadi",
        "Mohib Ullah",
        "Faouzi Alaya Cheikh",
        "Malik Mallem"
      ],
      "abstract": "Scene understanding plays an important role in several high-level computer\nvision applications, such as autonomous vehicles, intelligent video\nsurveillance, or robotics. However, too few solutions have been proposed for\nindoor/outdoor scene classification to ensure scene context adaptability for\ncomputer vision frameworks. We propose the first Lightweight Hybrid Graph\nConvolutional Neural Network (LH-GCNN)-CNN framework as an add-on to object\ndetection models. The proposed approach uses the output of the CNN object\ndetection model to predict the observed scene type by generating a coherent\nGCNN representing the semantic and geometric content of the observed scene.\nThis new method, applied to natural scenes, achieves an efficiency of over 90\\%\nfor scene classification in a COCO-derived dataset containing a large number of\ndifferent scenes, while requiring fewer parameters than traditional CNN\nmethods. For the benefit of the scientific community, we will make the source\ncode publicly available: https://github.com/Aymanbegh/Hybrid-GCNN-CNN.",
      "tldr_zh": "本研究提出了一种新的 Lightweight Hybrid Graph Convolutional Neural Network (LH-GCNN)-CNN 方案，用于基于对象检测推理的场景分类，旨在提升计算机视觉框架在室内/户外场景的适应性。  \n该框架作为对象检测模型的附加组件，利用 CNN 的输出生成一个表示场景语义和几何内容的 GCNN，从而准确预测场景类型。  \n在 COCO 派生数据集上，该方法实现了超过 90% 的场景分类准确率，同时参数量远少于传统 CNN 方法，并将开源代码发布以供科学社区使用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14658v1",
      "published_date": "2024-07-19 20:34:40 UTC",
      "updated_date": "2024-07-19 20:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:08:15.754957"
    },
    {
      "arxiv_id": "2407.14651v3",
      "title": "Improving Representation of High-frequency Components for Medical Visual Foundation Models",
      "title_zh": "改善医疗视觉基础模型中高频分量的表示",
      "authors": [
        "Yuetan Chu",
        "Yilan Zhang",
        "Zhongyi Han",
        "Changchun Yang",
        "Longxi Zhou",
        "Gongning Luo",
        "Chao Huang",
        "Xin Gao"
      ],
      "abstract": "Foundation models have recently attracted significant attention for their\nimpressive generalizability across diverse downstream tasks. However, these\nmodels are demonstrated to exhibit great limitations in representing\nhigh-frequency components and fine-grained details. In many medical imaging\ntasks, the precise representation of such information is crucial due to the\ninherently intricate anatomical structures, sub-visual features, and complex\nboundaries involved. Consequently, the limited representation of prevalent\nfoundation models can result in significant performance degradation or even\nfailure in these tasks. To address these challenges, we propose a novel\npretraining strategy, named Frequency-advanced Representation Autoencoder\n(Frepa). Through high-frequency masking and low-frequency perturbation combined\nwith adversarial learning, Frepa encourages the encoder to effectively\nrepresent and preserve high-frequency components in the image embeddings.\nAdditionally, we introduce an innovative histogram-equalized image masking\nstrategy, extending the Masked Autoencoder approach beyond ViT to other\narchitectures such as Swin Transformer and convolutional networks. We develop\nFrepa across nine medical modalities and validate it on 32 downstream tasks for\nboth 2D images and 3D volume data. Without fine-tuning, Frepa can outperform\nother self-supervised pretraining methods and, in some cases, even surpasses\ntask-specific trained models. This improvement is particularly significant for\ntasks involving fine-grained details, such as achieving up to a +15% increase\nin DSC for retina vessel segmentation and a +7% increase in IoU for lung nodule\ndetection. Further experiments quantitatively reveal that Frepa enables\nsuperior high-frequency representations and preservation in the embeddings,\nunderscoring its potential for developing more generalized and universal\nmedical image foundation models.",
      "tldr_zh": "本研究针对视觉基础模型在表示高频组件和细粒度细节方面的局限性，提出了一种新型预训练策略——Frequency-advanced Representation Autoencoder (Frepa)，以提升其在医疗成像任务中的性能。Frepa 通过高频掩码、低频扰动以及对抗学习相结合的方式，鼓励编码器更好地保留图像中的高频信息，同时引入直方图均衡图像掩码策略，使其适用于 ViT、Swin Transformer 和卷积网络等架构。实验结果显示，Frepa 在九个医疗模式和32个下游任务（包括2D和3D数据）上超越了其他自监督预训练方法，并在细粒度任务中取得显著提升，如视网膜血管分割的DSC提高15%和肺结节检测的IoU提高7%，从而为开发更通用的医疗图像基础模型提供了潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14651v3",
      "published_date": "2024-07-19 20:05:10 UTC",
      "updated_date": "2025-03-03 09:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:08:27.507465"
    },
    {
      "arxiv_id": "2407.14640v1",
      "title": "CVE-LLM : Automatic vulnerability evaluation in medical device industry using large language models",
      "title_zh": "CVE-LLM：利用大型语言模型在医疗器械行业进行自动漏洞评估",
      "authors": [
        "Rikhiya Ghosh",
        "Oladimeji Farri",
        "Hans-Martin von Stockhausen",
        "Martin Schmitt",
        "George Marica Vasile"
      ],
      "abstract": "The healthcare industry is currently experiencing an unprecedented wave of\ncybersecurity attacks, impacting millions of individuals. With the discovery of\nthousands of vulnerabilities each month, there is a pressing need to drive the\nautomation of vulnerability assessment processes for medical devices,\nfacilitating rapid mitigation efforts. Generative AI systems have\nrevolutionized various industries, offering unparalleled opportunities for\nautomation and increased efficiency. This paper presents a solution leveraging\nLarge Language Models (LLMs) to learn from historical evaluations of\nvulnerabilities for the automatic assessment of vulnerabilities in the medical\ndevices industry. This approach is applied within the portfolio of a single\nmanufacturer, taking into account device characteristics, including existing\nsecurity posture and controls. The primary contributions of this paper are\nthreefold. Firstly, it provides a detailed examination of the best practices\nfor training a vulnerability Language Model (LM) in an industrial context.\nSecondly, it presents a comprehensive comparison and insightful analysis of the\neffectiveness of Language Models in vulnerability assessment. Finally, it\nproposes a new human-in-the-loop framework to expedite vulnerability evaluation\nprocesses.",
      "tldr_zh": "该论文提出CVE-LLM框架，利用Large Language Models (LLMs)从历史漏洞评估数据中学习，实现医疗设备行业的自动漏洞评估，以应对日益严重的网络安全攻击。论文的主要贡献包括：第一，提供工业环境中训练漏洞语言模型的最佳实践指导；第二，对LLMs在漏洞评估中的有效性进行全面比较和分析；第三，引入一个新的人机交互框架，以加速评估过程并提升效率。该方法考虑了设备特性、安全态势等因素，有望推动医疗设备漏洞缓解的自动化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14640v1",
      "published_date": "2024-07-19 19:34:17 UTC",
      "updated_date": "2024-07-19 19:34:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:08:38.758116"
    },
    {
      "arxiv_id": "2407.14631v2",
      "title": "Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Kamyab Karimi",
        "Ali Ghodratnama",
        "Reza Tavakkoli-Moghaddam"
      ],
      "abstract": "Breast cancer is not preventable because of its unknown causes. However, its\nearly diagnosis increases patients' recovery chances. Machine learning (ML) can\nbe utilized to improve treatment outcomes in healthcare operations while\ndiminishing costs and time. In this research, we suggest two novel feature\nselection (FS) methods based upon an imperialist competitive algorithm (ICA)\nand a bat algorithm (BA) and their combination with ML algorithms. This study\naims to enhance diagnostic models' efficiency and present a comprehensive\nanalysis to help clinical physicians make much more precise and reliable\ndecisions than before. K-nearest neighbors, support vector machine, decision\ntree, Naive Bayes, AdaBoost, linear discriminant analysis, random forest,\nlogistic regression, and artificial neural network are some of the methods\nemployed. This paper applied a distinctive integration of evaluation measures\nand ML algorithms using the wrapper feature selection based on ICA (WFSIC) and\nBA (WFSB) separately. We compared two proposed approaches for the performance\nof the classifiers. Also, we compared our best diagnostic model with previous\nworks reported in the literature survey. Experimentations were performed on the\nWisconsin diagnostic breast cancer dataset. Results reveal that the proposed\nframework that uses the BA with an accuracy of 99.12\\%, surpasses the framework\nusing the ICA and most previous works. Additionally, the RF classifier in the\napproach of FS based on BA emerges as the best model and outperforms others\nregarding its criteria. Besides, the results illustrate the role of our\ntechniques in reducing the dataset dimensions up to 90\\% and increasing the\nperformance of diagnostic models by over 99\\%. Moreover, the result\ndemonstrates that there are more critical features than the optimum dataset\nobtained by proposed FS approaches that have been selected by most ML models.",
      "tldr_zh": "本研究提出两种新的特征选择(FS)方法：基于帝国主义竞争算法(ICA)的WFSIC和基于蝙蝠算法(BA)的WFSB，旨在通过结合机器学习(ML)算法（如K-nearest neighbors、support vector machine和random forest）提升乳腺癌预测的准确性和效率。实验在Wisconsin诊断乳腺癌数据集上进行，结果显示BA框架的准确率达到99.12%，优于ICA方法和先前文献中的模型，同时将数据集维度减少高达90%。此外，该框架帮助识别更多关键特征，提高诊断模型性能超过99%，为临床医生提供更可靠的决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages, 3 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.14631v2",
      "published_date": "2024-07-19 19:07:53 UTC",
      "updated_date": "2024-08-07 21:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:08:52.678951"
    },
    {
      "arxiv_id": "2407.14622v1",
      "title": "BOND: Aligning LLMs with Best-of-N Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Pier Giuseppe Sessa",
        "Robert Dadashi",
        "Léonard Hussenot",
        "Johan Ferret",
        "Nino Vieillard",
        "Alexandre Ramé",
        "Bobak Shariari",
        "Sarah Perrin",
        "Abe Friesen",
        "Geoffrey Cideron",
        "Sertan Girgin",
        "Piotr Stanczyk",
        "Andrea Michi",
        "Danila Sinopalnikov",
        "Sabela Ramos",
        "Amélie Héliou",
        "Aliaksei Severyn",
        "Matt Hoffman",
        "Nikola Momchev",
        "Olivier Bachem"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) is a key driver of quality\nand safety in state-of-the-art large language models. Yet, a surprisingly\nsimple and strong inference-time strategy is Best-of-N sampling that selects\nthe best generation among N candidates. In this paper, we propose Best-of-N\nDistillation (BOND), a novel RLHF algorithm that seeks to emulate Best-of-N but\nwithout its significant computational overhead at inference time. Specifically,\nBOND is a distribution matching algorithm that forces the distribution of\ngenerations from the policy to get closer to the Best-of-N distribution. We use\nthe Jeffreys divergence (a linear combination of forward and backward KL) to\nbalance between mode-covering and mode-seeking behavior, and derive an\niterative formulation that utilizes a moving anchor for efficiency. We\ndemonstrate the effectiveness of our approach and several design choices\nthrough experiments on abstractive summarization and Gemma models. Aligning\nGemma policies with BOND outperforms other RLHF algorithms by improving results\non several benchmarks.",
      "tldr_zh": "本文提出BOND算法，一种新型的强化学习从人类反馈（RLHF）方法，用于对齐大型语言模型（LLMs），以模仿Best-of-N采样的生成质量，同时避免其推理时的计算开销。BOND通过分布匹配技术，使用Jeffreys divergence（结合前向和后向KL散度）来使策略生成的分布更接近Best-of-N分布，并采用迭代公式和移动锚点提升效率。在摘要生成和Gemma模型的实验中，BOND优于其他RLHF算法，在多个基准上取得了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14622v1",
      "published_date": "2024-07-19 18:38:25 UTC",
      "updated_date": "2024-07-19 18:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:09:08.824599"
    },
    {
      "arxiv_id": "2407.14605v1",
      "title": "ESCAPE: Energy-based Selective Adaptive Correction for Out-of-distribution 3D Human Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Bidulka",
        "Mohsen Gholami",
        "Jiannan Zheng",
        "Martin J. McKeown",
        "Z. Jane Wang"
      ],
      "abstract": "Despite recent advances in human pose estimation (HPE), poor generalization\nto out-of-distribution (OOD) data remains a difficult problem. While previous\nworks have proposed Test-Time Adaptation (TTA) to bridge the train-test domain\ngap by refining network parameters at inference, the absence of ground-truth\nannotations makes it highly challenging and existing methods typically increase\ninference times by one or more orders of magnitude. We observe that 1) not\nevery test time sample is OOD, and 2) HPE errors are significantly larger on\ndistal keypoints (wrist, ankle). To this end, we propose ESCAPE: a lightweight\ncorrection and selective adaptation framework which applies a fast,\nforward-pass correction on most data while reserving costly TTA for OOD data.\nThe free energy function is introduced to separate OOD samples from incoming\ndata and a correction network is trained to estimate the errors of pretrained\nbackbone HPE predictions on the distal keypoints. For OOD samples, we propose a\nnovel self-consistency adaptation loss to update the correction network by\nleveraging the constraining relationship between distal keypoints and proximal\nkeypoints (shoulders, hips), via a second ``reverse\" network. ESCAPE improves\nthe distal MPJPE of five popular HPE models by up to 7% on unseen data,\nachieves state-of-the-art results on two popular HPE benchmarks, and is\nsignificantly faster than existing adaptation methods.",
      "tldr_zh": "本文提出 ESCAPE，一种基于能量的选择性适应校正框架，用于解决人类姿势估计 (HPE) 在分布外 (OOD) 数据上的泛化问题。ESCAPE 通过 free energy function 识别 OOD 样本，并针对大多数数据应用快速前向传播校正，而仅对 OOD 数据使用 Test-Time Adaptation (TTA)；同时，训练校正网络估计远端关键点 (wrist, ankle) 的错误，并引入自一致性适应损失和反向网络，利用远端与近端关键点 (shoulders, hips) 的约束关系更新模型。实验结果显示，ESCAPE 改善了五种流行 HPE 模型的远端 MPJPE 指标高达 7%，在两个 HPE 基准上达到最先进性能，且推理速度远优于现有适应方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.6; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14605v1",
      "published_date": "2024-07-19 18:01:26 UTC",
      "updated_date": "2024-07-19 18:01:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:09:19.411879"
    },
    {
      "arxiv_id": "2407.14509v1",
      "title": "DEPICT: Diffusion-Enabled Permutation Importance for Image Classification Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Jabbour",
        "Gregory Kondas",
        "Ella Kazerooni",
        "Michael Sjoding",
        "David Fouhey",
        "Jenna Wiens"
      ],
      "abstract": "We propose a permutation-based explanation method for image classifiers.\nCurrent image-model explanations like activation maps are limited to\ninstance-based explanations in the pixel space, making it difficult to\nunderstand global model behavior. In contrast, permutation based explanations\nfor tabular data classifiers measure feature importance by comparing model\nperformance on data before and after permuting a feature. We propose an\nexplanation method for image-based models that permutes interpretable concepts\nacross dataset images. Given a dataset of images labeled with specific concepts\nlike captions, we permute a concept across examples in the text space and then\ngenerate images via a text-conditioned diffusion model. Feature importance is\nthen reflected by the change in model performance relative to unpermuted data.\nWhen applied to a set of concepts, the method generates a ranking of feature\nimportance. We show this approach recovers underlying model feature importance\non synthetic and real-world image classification tasks.",
      "tldr_zh": "我们提出 DEPICT，一种基于置换重要性(permutation importance)的解释方法，用于图像分类任务，以解决现有激活地图等方法仅限于实例级像素空间解释的局限性。该方法通过在数据集的文本空间置换可解释概念（如标题），然后利用文本条件扩散模型生成图像，并通过比较置换前后模型性能变化来量化特征重要性，从而生成特征重要性的排名。实验结果表明，DEPICT 在合成和真实世界图像分类任务上成功恢复了模型的底层特征重要性，提供更全面的全局模型行为理解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "36 pages, 18 figures, 9 tables, to be published in ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14509v1",
      "published_date": "2024-07-19 17:59:38 UTC",
      "updated_date": "2024-07-19 17:59:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:09:29.853060"
    },
    {
      "arxiv_id": "2407.14506v2",
      "title": "On Pre-training of Multimodal Language Models Customized for Chart Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Wan-Cyuan Fan",
        "Yen-Chun Chen",
        "Mengchen Liu",
        "Lu Yuan",
        "Leonid Sigal"
      ],
      "abstract": "Recent studies customizing Multimodal Large Language Models (MLLMs) for\ndomain-specific tasks have yielded promising results, especially in the field\nof scientific chart comprehension. These studies generally utilize visual\ninstruction tuning with specialized datasets to enhance question and answer\n(QA) accuracy within the chart domain. However, they often neglect the\nfundamental discrepancy between natural image-caption pre-training data and\ndigital chart image-QA data, particularly in the models' capacity to extract\nunderlying numeric values from charts. This paper tackles this oversight by\nexploring the training processes necessary to improve MLLMs' comprehension of\ncharts. We present three key findings: (1) Incorporating raw data values in\nalignment pre-training markedly improves comprehension of chart data. (2)\nReplacing images with their textual representation randomly during end-to-end\nfine-tuning transfer the language reasoning capability to chart interpretation\nskills. (3) Requiring the model to first extract the underlying chart data and\nthen answer the question in the fine-tuning can further improve the accuracy.\nConsequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chart\ncomprehension. CHOPINLLM effectively interprets various types of charts,\nincluding unannotated ones, while maintaining robust reasoning abilities.\nFurthermore, we establish a new benchmark to evaluate MLLMs' understanding of\ndifferent chart types across various comprehension levels. Experimental results\nshow that CHOPINLLM exhibits strong performance in understanding both annotated\nand unannotated charts across a wide range of types.",
      "tldr_zh": "本研究探讨了针对图表理解定制的多模态大语言模型 (MLLMs) 的预训练问题，强调了现有方法忽略自然图像-标题数据与数字图表图像-QA 数据之间的差异。关键发现包括：在对齐预训练中加入原始数据值可显著提升图表数据理解；在端到端微调中随机用文本表示替换图像，能将语言推理能力转移到图表解释；要求模型先提取图表底层数据再回答问题可进一步提高准确性。论文引入了 CHOPINLLM，一种专为深入图表理解设计的 MLLM，能够有效解读各种类型图表（包括未标注的），并保持强大推理能力。同时，研究建立了一个新基准，用于评估 MLLMs 在不同图表类型和理解水平上的表现，实验结果显示 CHOPINLLM 在标注和未标注图表上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14506v2",
      "published_date": "2024-07-19 17:58:36 UTC",
      "updated_date": "2024-07-31 21:01:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:09:43.461821"
    },
    {
      "arxiv_id": "2407.14499v2",
      "title": "Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Sukrut Rao",
        "Sweta Mahajan",
        "Moritz Böhle",
        "Bernt Schiele"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) have recently been proposed to address the\n'black-box' problem of deep neural networks, by first mapping images to a\nhuman-understandable concept space and then linearly combining concepts for\nclassification. Such models typically require first coming up with a set of\nconcepts relevant to the task and then aligning the representations of a\nfeature extractor to map to these concepts. However, even with powerful\nfoundational feature extractors like CLIP, there are no guarantees that the\nspecified concepts are detectable. In this work, we leverage recent advances in\nmechanistic interpretability and propose a novel CBM approach -- called\nDiscover-then-Name-CBM (DN-CBM) -- that inverts the typical paradigm: instead\nof pre-selecting concepts based on the downstream classification task, we use\nsparse autoencoders to first discover concepts learnt by the model, and then\nname them and train linear probes for classification. Our concept extraction\nstrategy is efficient, since it is agnostic to the downstream task, and uses\nconcepts already known to the model. We perform a comprehensive evaluation\nacross multiple datasets and CLIP architectures and show that our method yields\nsemantically meaningful concepts, assigns appropriate names to them that make\nthem easy to interpret, and yields performant and interpretable CBMs. Code\navailable at https://github.com/neuroexplicit-saar/discover-then-name.",
      "tldr_zh": "本研究提出了一种新型概念瓶颈模型（Concept Bottleneck Models, CBMs），名为 Discover-then-Name-CBM (DN-CBM)，通过逆转传统范式来解决深度神经网络的黑箱问题。具体而言，该方法先利用 sparse autoencoders 自动发现模型已学到的概念，然后对这些概念进行命名并训练线性探针用于分类，从而实现任务无关（task-agnostic）的概念提取。相比传统方法，DN-CBM 更高效，因为它依赖模型内在知识，而非预先定义任务相关概念。在多个数据集和 CLIP 架构上的全面评估显示，该方法生成了语义上意义丰富的概念，易于解释，并提升了 CBMs 的性能和可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "40 pages, 21 figures, 6 tables, European Conference on Computer\n  Vision (ECCV) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14499v2",
      "published_date": "2024-07-19 17:50:11 UTC",
      "updated_date": "2024-08-12 14:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:09:54.494089"
    },
    {
      "arxiv_id": "2407.14486v1",
      "title": "Explainable Post hoc Portfolio Management Financial Policy of a Deep Reinforcement Learning agent",
      "title_zh": "深度强化学习代理的可解释事后投资组合管理金融政策",
      "authors": [
        "Alejandra de la Rica Escudero",
        "Eduardo C. Garrido-Merchan",
        "Maria Coronado-Vaca"
      ],
      "abstract": "Financial portfolio management investment policies computed quantitatively by\nmodern portfolio theory techniques like the Markowitz model rely on a set on\nassumptions that are not supported by data in high volatility markets. Hence,\nquantitative researchers are looking for alternative models to tackle this\nproblem. Concretely, portfolio management is a problem that has been\nsuccessfully addressed recently by Deep Reinforcement Learning (DRL)\napproaches. In particular, DRL algorithms train an agent by estimating the\ndistribution of the expected reward of every action performed by an agent given\nany financial state in a simulator. However, these methods rely on Deep Neural\nNetworks model to represent such a distribution, that although they are\nuniversal approximator models, they cannot explain its behaviour, given by a\nset of parameters that are not interpretable. Critically, financial investors\npolicies require predictions to be interpretable, so DRL agents are not suited\nto follow a particular policy or explain their actions. In this work, we\ndeveloped a novel Explainable Deep Reinforcement Learning (XDRL) approach for\nportfolio management, integrating the Proximal Policy Optimization (PPO) with\nthe model agnostic explainable techniques of feature importance, SHAP and LIME\nto enhance transparency in prediction time. By executing our methodology, we\ncan interpret in prediction time the actions of the agent to assess whether\nthey follow the requisites of an investment policy or to assess the risk of\nfollowing the agent suggestions. To the best of our knowledge, our proposed\napproach is the first explainable post hoc portfolio management financial\npolicy of a DRL agent. We empirically illustrate our methodology by\nsuccessfully identifying key features influencing investment decisions, which\ndemonstrate the ability to explain the agent actions in prediction time.",
      "tldr_zh": "本研究针对传统投资组合管理方法（如Markowitz模型）在高波动市场中的失效问题，提出了一种可解释的Deep Reinforcement Learning (DRL)替代方案。作者开发了Explainable Deep Reinforcement Learning (XDRL)方法，将Proximal Policy Optimization (PPO)算法与模型无关解释技术SHAP和LIME结合，实现对代理动作的实时透明解释，从而评估投资决策的风险和合规性。该方法是首个后验解释的DRL代理投资组合管理策略，通过实验成功识别了影响决策的关键特征，证明了其在提升金融预测可解释性方面的有效性。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "q-fin.PM"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14486v1",
      "published_date": "2024-07-19 17:40:39 UTC",
      "updated_date": "2024-07-19 17:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:10:06.319374"
    },
    {
      "arxiv_id": "2407.14482v3",
      "title": "ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Xu",
        "Wei Ping",
        "Xianchao Wu",
        "Chejian Xu",
        "Zihan Liu",
        "Mohammad Shoeybi",
        "Bryan Catanzaro"
      ],
      "abstract": "In this work, we introduce ChatQA 2, an Llama 3.0-based model with a 128K\ncontext window, designed to bridge the gap between open-source LLMs and leading\nproprietary models (e.g., GPT-4-Turbo-2024-04-09) in long context understanding\nand retrieval-augmented generation (RAG) capabilities. These two capabilities\nare complementary to each other and essential for LLMs to process large volumes\nof information that cannot fit into a single prompt. We present a detailed\ncontinued training recipe to extend the context window of Llama3-70B-base from\n8K to 128K tokens, along with a three-stage instruction tuning process to\nenhance the model's instruction-following, RAG performance, and long-context\nunderstanding capabilities. Our results demonstrate that the\nLlama3-ChatQA-2-70B model outperforms most existing state-of-the-art models,\nincluding GPT-4-Turbo-2024-04-09, Qwen2-72B-Instruct, and\nLlama3.1-70B-Instruct, on ultra-long tasks beyond 100K tokens, as well as on\nthe RAG benchmark using only a 4K context window, showing the strong long\ncontext capability across varying sequence lengths. We further provide\nextensive comparisons between direct long-context and RAG solutions using the\nsame state-of-the-art long-context LLMs. Interestingly, we find that the\nperformance of strong long-context LLMs using RAG improves when retrieving a\nlarger number of chunks. With a large set of top-k chunks, RAG consistently\noutperforms direct long-context solution using the same state-of-the-art\nlong-context models (e.g., Llama3-ChatQA-2-70B and Qwen2-72B-Instruct) on both\n32K and 128K benchmarks. We open-source the model weights, training data, and\nthe evaluation setup for the for the community:\nhttps://chatqa2-project.github.io/",
      "tldr_zh": "本文介绍了 ChatQA 2，一款基于 Llama 3.0 的开源模型，扩展了上下文窗口至 128K 标记，旨在缩小开源 LLM 与专有模型（如 GPT-4-Turbo-2024-04-09）在长上下文理解和 RAG（检索增强生成）能力上的差距。研究采用详细的继续训练方法，将 Llama3-70B-base 的上下文从 8K 扩展到 128K，并通过三阶段指令微调提升模型的指令遵循、RAG 性能和长上下文处理能力。实验结果显示，Llama3-ChatQA-2-70B 在超过 100K 标记的任务和 RAG 基准上优于现有最先进模型，且使用 RAG 时检索更多 chunks 可以显著改善性能，使其在 32K 和 128K 基准上 consistently 优于直接长上下文方案。作者开源了模型权重、训练数据和评估设置，以供社区使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.14482v3",
      "published_date": "2024-07-19 17:35:47 UTC",
      "updated_date": "2025-02-14 20:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:10:20.963154"
    },
    {
      "arxiv_id": "2407.14467v2",
      "title": "Check-Eval: A Checklist-based Approach for Evaluating Text Quality",
      "title_zh": "Check-Eval：一种基于检查列表的文本质量评估方法",
      "authors": [
        "Jayr Pereira",
        "Andre Assumpcao",
        "Roberto Lotufo"
      ],
      "abstract": "Evaluating the quality of text generated by large language models (LLMs)\nremains a significant challenge. Traditional metrics often fail to align well\nwith human judgments, particularly in tasks requiring creativity and nuance. In\nthis paper, we propose \\textsc{Check-Eval}, a novel evaluation framework\nleveraging LLMs to assess the quality of generated text through a\nchecklist-based approach. \\textsc{Check-Eval} can be employed as both a\nreference-free and reference-dependent evaluation method, providing a\nstructured and interpretable assessment of text quality. The framework consists\nof two main stages: checklist generation and checklist evaluation. We validate\n\\textsc{Check-Eval} on two benchmark datasets: Portuguese Legal Semantic\nTextual Similarity and \\textsc{SummEval}. Our results demonstrate that\n\\textsc{Check-Eval} achieves higher correlations with human judgments compared\nto existing metrics, such as \\textsc{G-Eval} and \\textsc{GPTScore},\nunderscoring its potential as a more reliable and effective evaluation\nframework for natural language generation tasks. The code for our experiments\nis available at \\url{https://anonymous.4open.science/r/check-eval-0DB4}",
      "tldr_zh": "本研究针对评估大型语言模型 (LLMs) 生成文本质量的挑战，提出了一种新框架 Check-Eval，该框架利用 LLMs 通过基于清单的方法进行结构化和可解释的评估，支持无参考和有参考模式。Check-Eval 包括清单生成和清单评估两个主要阶段，在 Portuguese Legal Semantic Textual Similarity 和 SummEval 等基准数据集上进行验证。结果显示，该框架与人类判断的相关性高于现有指标如 G-Eval 和 GPTScore，证明其在自然语言生成任务中更可靠且有效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14467v2",
      "published_date": "2024-07-19 17:14:16 UTC",
      "updated_date": "2024-09-10 14:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:10:29.464153"
    },
    {
      "arxiv_id": "2407.14575v2",
      "title": "Regression prediction algorithm for energy consumption regression in cloud computing based on horned lizard algorithm optimised convolutional neural network-bidirectional gated recurrent unit",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyang Li",
        "Zinan Cao",
        "Qixuan Yu",
        "Xirui Tang"
      ],
      "abstract": "For this paper, a prediction study of cloud computing energy consumption was\nconducted by optimising the data regression algorithm based on the horned\nlizard optimisation algorithm for Convolutional Neural Networks-Bi-Directional\nGated Recurrent Units. Firstly, through Spearman correlation analysis of CPU,\nusage, memory usage, network traffic, power consumption, number of instructions\nexecuted, execution time and energy efficiency, we found that power consumption\nhas the highest degree of positive correlation with energy efficiency, while\nCPU usage has the highest degree of negative correlation with energy\nefficiency. In our experiments, we introduced a random forest model and an\noptimisation model based on the horned lizard optimisation algorithm for\ntesting, and the results show that the optimisation algorithm has better\nprediction results compared to the random forest model. Specifically, the mean\nsquare error (MSE) of the optimisation algorithm is 0.01 smaller than that of\nthe random forest model, and the mean absolute error (MAE) is 0.01 smaller than\nthat of the random forest.3 The results of the combined metrics show that the\noptimisation algorithm performs more accurately and reliably in predicting\nenergy efficiency. This research result provides new ideas and methods to\nimprove the energy efficiency of cloud computing systems. This research not\nonly expands the scope of application in the field of cloud computing, but also\nprovides a strong support for improving the energy use efficiency of the\nsystem.",
      "tldr_zh": "本论文提出了一种基于 horned lizard algorithm 优化 CNN-BiGRU 的回归预测算法，用于云计算能源消耗的预测分析。首先，通过 Spearman 相关分析，发现功率消耗与能源效率呈正相关，而 CPU 使用率与能源效率呈负相关。实验结果显示，该优化算法与随机森林模型相比，在 MSE 上降低了 0.01，在 MAE 上降低了 0.013，表现出更高的准确性和可靠性。该研究为提升云计算系统的能源效率提供了新方法和思路。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14575v2",
      "published_date": "2024-07-19 16:19:14 UTC",
      "updated_date": "2024-07-26 17:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:10:41.536184"
    },
    {
      "arxiv_id": "2407.14430v1",
      "title": "The Extrapolation Power of Implicit Models",
      "title_zh": "翻译失败",
      "authors": [
        "Juliette Decugis",
        "Alicia Y. Tsai",
        "Max Emerling",
        "Ashwin Ganesh",
        "Laurent El Ghaoui"
      ],
      "abstract": "In this paper, we investigate the extrapolation capabilities of implicit deep\nlearning models in handling unobserved data, where traditional deep neural\nnetworks may falter. Implicit models, distinguished by their adaptability in\nlayer depth and incorporation of feedback within their computational graph, are\nput to the test across various extrapolation scenarios: out-of-distribution,\ngeographical, and temporal shifts. Our experiments consistently demonstrate\nsignificant performance advantage with implicit models. Unlike their\nnon-implicit counterparts, which often rely on meticulous architectural design\nfor each task, implicit models demonstrate the ability to learn complex model\nstructures without the need for task-specific design, highlighting their\nrobustness in handling unseen data.",
      "tldr_zh": "本研究探讨了隐式模型在处理未观察数据时的外推能力，与传统深度神经网络相比，隐式模型通过灵活的层深度和反馈机制表现出显著优势。实验涵盖多种外推场景，包括 out-of-distribution、geographical shifts 和 temporal shifts，结果显示隐式模型在性能上领先于非隐式模型。隐式模型无需针对特定任务进行精细架构设计，即可学习复杂结构，并展现出更高的鲁棒性，从而更好地应对未见数据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Workshop on Explainable Artificial Intelligence (XAI)\n  at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14430v1",
      "published_date": "2024-07-19 16:01:37 UTC",
      "updated_date": "2024-07-19 16:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:10:51.862790"
    },
    {
      "arxiv_id": "2407.14417v2",
      "title": "Mixture of Experts with Mixture of Precisions for Tuning Quality of Service",
      "title_zh": "翻译失败",
      "authors": [
        "HamidReza Imani",
        "Abdolah Amirany",
        "Tarek El-Ghazawi"
      ],
      "abstract": "The increasing demand for deploying large Mixture-of-Experts (MoE) models in\nresource-constrained environments necessitates efficient approaches to address\ntheir high memory and computational requirements challenges. Moreover, given\nthat tasks come in different user-defined constraints and the available\nresources change over time in multi-tenant environments, it is necessary to\ndesign an approach which provides a flexible configuration space. This paper\npresents an adaptive serving approach for the efficient deployment of MoE\nmodels, capitalizing on partial quantization of the experts. By dynamically\ndetermining the number of quantized experts and their distribution across CPU\nand GPU, our approach explores the Pareto frontier and offers a fine-grained\nrange of configurations for tuning throughput and model quality. Our evaluation\non an NVIDIA A100 GPU using a Mixtral 8x7B MoE model for three language\nmodelling benchmarks demonstrates that the throughput of token generation can\nbe adjusted from 0.63 to 13.00 token per second. This enhancement comes with a\nmarginal perplexity increase of 3.81 to 4.00, 13.59 to 14.17, and 7.24 to 7.40\nfor WikiText2, PTB, and C4 datasets respectively under maximum quantization.\nThese results highlight the practical applicability of our approach in dynamic\nand accuracy-sensitive applications where both memory usage and output quality\nare important.",
      "tldr_zh": "这篇论文提出了一种自适应服务方法，用于在资源受限环境中高效部署 Mixture-of-Experts (MoE) 模型，通过部分量化 experts 和动态分配到 CPU/GPU 来优化服务质量。方法动态调整量化 experts 的数量和分布，探索 Pareto frontier 以提供细粒度的配置，平衡吞吐量和模型质量。实验结果显示，在 NVIDIA A100 GPU 上使用 Mixtral 8x7B 模型，吞吐量从 0.63 到 13.00 token/秒提升，而困惑度仅轻微增加（WikiText2: 3.81-4.00, PTB: 13.59-14.17, C4: 7.24-7.40），证明了该方法在动态和精度敏感应用中的实用价值。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14417v2",
      "published_date": "2024-07-19 15:42:49 UTC",
      "updated_date": "2024-09-09 16:34:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:11:07.205148"
    },
    {
      "arxiv_id": "2407.14414v2",
      "title": "System-1.x: Learning to Balance Fast and Slow Planning with Language Models",
      "title_zh": "System-1.x：使用语言模型学习平衡快速与缓慢规划",
      "authors": [
        "Swarnadeep Saha",
        "Archiki Prasad",
        "Justin Chih-Yao Chen",
        "Peter Hase",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "abstract": "Language models can be used to solve long-horizon planning problems in two\ndistinct modes: a fast 'System-1' mode, directly generating plans without any\nexplicit search or backtracking, and a slow 'System-2' mode, planning\nstep-by-step by explicitly searching over possible actions. While System-2 is\ntypically more effective, it is also more computationally expensive, making it\ninfeasible for long plans or large action spaces. Moreover, isolated System-1\nor 2 ignores the user's end goals, failing to provide ways to control the\nmodel's behavior. To this end, we propose the System-1.x Planner, a\ncontrollable planning framework with LLMs that is capable of generating hybrid\nplans and balancing between the two planning modes based on the difficulty of\nthe problem at hand. System-1.x consists of (i) a controller, (ii) a System-1\nPlanner, and (iii) a System-2 Planner. Based on a user-specified hybridization\nfactor (x) governing the mixture between System-1 and 2, the controller\ndecomposes a problem into sub-goals, and classifies them as easy or hard to be\nsolved by either System-1 or 2, respectively. We fine-tune all three components\non top of a single base LLM, requiring only search traces as supervision.\nExperiments with two diverse planning tasks -- Maze Navigation and Blocksworld\n-- show that our System-1.x Planner outperforms a System-1 Planner, a System-2\nPlanner trained to approximate A* search, and also a symbolic planner (A*). We\ndemonstrate the following key properties of our planner: (1) controllability:\nincreasing the hybridization factor (e.g., System-1.75 vs 1.5) performs more\nsearch, improving performance, (2) flexibility: by building a neuro-symbolic\nvariant with a neural System-1 and a symbolic System-2, we can use existing\nsymbolic methods, and (3) generalizability: by being able to learn from\ndifferent search algorithms, our method is robust to the choice of search\nalgorithm.",
      "tldr_zh": "本论文提出 System-1.x Planner，一种基于语言模型的规划框架，能够根据问题难度平衡快速的 System-1 模式（直接生成计划）和慢速的 System-2 模式（逐步搜索），从而解决长程规划问题。框架包括控制器、System-1 Planner 和 System-2 Planner，通过用户指定的混合因子 x 来分解任务为子目标，并分配给合适模式进行处理，所有组件在单一基线 LLM 上微调，仅需搜索轨迹作为监督。实验在 Maze Navigation 和 Blocksworld 任务上表明，System-1.x 优于纯 System-1、System-2 规划器以及 A* 算法，展示了其可控性（调整 x 可提升性能）、灵活性（支持神经-符号混合）和泛化性（适应不同搜索算法）。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 (Camera-Ready)",
      "pdf_url": "http://arxiv.org/pdf/2407.14414v2",
      "published_date": "2024-07-19 15:40:59 UTC",
      "updated_date": "2025-04-15 03:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:11:18.078711"
    },
    {
      "arxiv_id": "2407.14412v1",
      "title": "DEAL: Disentangle and Localize Concept-level Explanations for VLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tang Li",
        "Mengmeng Ma",
        "Xi Peng"
      ],
      "abstract": "Large pre-trained Vision-Language Models (VLMs) have become ubiquitous\nfoundational components of other models and downstream tasks. Although\npowerful, our empirical results reveal that such models might not be able to\nidentify fine-grained concepts. Specifically, the explanations of VLMs with\nrespect to fine-grained concepts are entangled and mislocalized. To address\nthis issue, we propose to DisEntAngle and Localize (DEAL) the concept-level\nexplanations for VLMs without human annotations. The key idea is encouraging\nthe concept-level explanations to be distinct while maintaining consistency\nwith category-level explanations. We conduct extensive experiments and ablation\nstudies on a wide range of benchmark datasets and vision-language models. Our\nempirical results demonstrate that the proposed method significantly improves\nthe concept-level explanations of the model in terms of disentanglability and\nlocalizability. Surprisingly, the improved explainability alleviates the\nmodel's reliance on spurious correlations, which further benefits the\nprediction accuracy.",
      "tldr_zh": "这篇论文发现，大型预训练视觉语言模型(VLMs)在细粒度概念解释上存在解释纠缠(entangled)和定位错误(mislocalized)的缺陷，导致无法准确识别概念。作者提出 DEAL 方法，通过鼓励概念级解释保持独立性(disentanglability)同时与类别级解释一致，来在无需人类标注的情况下改进这些解释。实验在多个基准数据集和 VLMs 上验证，DEAL 显著提升了解释的可分离性和可定位性(localizability)，并意外减少了模型对虚假相关性(spurious correlations)的依赖，从而提高了预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "In Proceedings of the European Conference on Computer Vision (ECCV),\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14412v1",
      "published_date": "2024-07-19 15:39:19 UTC",
      "updated_date": "2024-07-19 15:39:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:11:29.173829"
    },
    {
      "arxiv_id": "2407.14402v1",
      "title": "The Vision of Autonomic Computing: Can LLMs Make It a Reality?",
      "title_zh": "自治计算的愿景：LLMs 能使其成为现实吗？",
      "authors": [
        "Zhiyang Zhang",
        "Fangkai Yang",
        "Xiaoting Qin",
        "Jue Zhang",
        "Qingwei Lin",
        "Gong Cheng",
        "Dongmei Zhang",
        "Saravan Rajmohan",
        "Qi Zhang"
      ],
      "abstract": "The Vision of Autonomic Computing (ACV), proposed over two decades ago,\nenvisions computing systems that self-manage akin to biological organisms,\nadapting seamlessly to changing environments. Despite decades of research,\nachieving ACV remains challenging due to the dynamic and complex nature of\nmodern computing systems. Recent advancements in Large Language Models (LLMs)\noffer promising solutions to these challenges by leveraging their extensive\nknowledge, language understanding, and task automation capabilities. This paper\nexplores the feasibility of realizing ACV through an LLM-based multi-agent\nframework for microservice management. We introduce a five-level taxonomy for\nautonomous service maintenance and present an online evaluation benchmark based\non the Sock Shop microservice demo project to assess our framework's\nperformance. Our findings demonstrate significant progress towards achieving\nLevel 3 autonomy, highlighting the effectiveness of LLMs in detecting and\nresolving issues within microservice architectures. This study contributes to\nadvancing autonomic computing by pioneering the integration of LLMs into\nmicroservice management frameworks, paving the way for more adaptive and\nself-managing computing systems. The code will be made available at\nhttps://aka.ms/ACV-LLM.",
      "tldr_zh": "本研究探讨了Autonomic Computing (ACV)的愿景，即构建像生物体一样自我管理的计算系统，并评估Large Language Models (LLMs)是否能实现这一目标。论文提出一个基于LLMs的多智能体框架，用于微服务管理，结合五级自治维护分类法和基于Sock Shop项目的在线评估基准。实验结果显示，该框架已达到Level 3自治水平，在检测和解决微服务问题方面表现出色。该研究通过整合LLMs，推进了自适应和自管理计算系统的开发，并提供了开源代码以供进一步探索。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DC",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14402v1",
      "published_date": "2024-07-19 15:30:32 UTC",
      "updated_date": "2024-07-19 15:30:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:11:41.349866"
    },
    {
      "arxiv_id": "2407.14400v1",
      "title": "On the Impact of PRB Load Uncertainty Forecasting for Sustainable Open RAN",
      "title_zh": "关于 PRB 负载不确定性预测对可持续 Open RAN 的影响",
      "authors": [
        "Vaishnavi Kasuluru",
        "Luis Blanco",
        "Cristian J. Vaca-Rubio",
        "Engin Zeydan"
      ],
      "abstract": "The transition to sustainable Open Radio Access Network (O-RAN) architectures\nbrings new challenges for resource management, especially in predicting the\nutilization of Physical Resource Block (PRB)s. In this paper, we propose a\nnovel approach to characterize the PRB load using probabilistic forecasting\ntechniques. First, we provide background information on the O-RAN architecture\nand components and emphasize the importance of energy/power consumption models\nfor sustainable implementations. The problem statement highlights the need for\naccurate PRB load prediction to optimize resource allocation and power\nefficiency. We then investigate probabilistic forecasting techniques, including\nSimple-Feed-Forward (SFF), DeepAR, and Transformers, and discuss their\nlikelihood model assumptions. The simulation results show that DeepAR\nestimators predict the PRBs with less uncertainty and effectively capture the\ntemporal dependencies in the dataset compared to SFF- and Transformer-based\nmodels, leading to power savings. Different percentile selections can also\nincrease power savings, but at the cost of over-/under provisioning. At the\nsame time, the performance of the Long-Short Term Memory (LSTM) is shown to be\ninferior to the probabilistic estimators with respect to all error metrics.\nFinally, we outline the importance of probabilistic, prediction-based\ncharacterization for sustainable O-RAN implementations and highlight avenues\nfor future research.",
      "tldr_zh": "本文探讨了在可持续 Open RAN 架构中，Physical Resource Block (PRB) 负载不确定性预测对资源管理的影响，提出了一种基于概率预测技术的表征方法，以优化资源分配和功率效率。研究比较了 Simple-Feed-Forward (SFF)、DeepAR 和 Transformers 等模型，结果显示 DeepAR 模型在预测 PRB 负载时不确定性更低，能更好地捕捉时间依赖性，从而实现显著功率节省，而 Long-Short Term Memory (LSTM) 模型在所有错误指标上表现较差。不同百分位数的选择可进一步提升功率效率，但可能导致过度或不足配置。该方法为可持续 O-RAN 的实施提供了关键指导，并指出了未来研究的潜在方向。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14400v1",
      "published_date": "2024-07-19 15:25:20 UTC",
      "updated_date": "2024-07-19 15:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:11:54.742028"
    },
    {
      "arxiv_id": "2407.14394v2",
      "title": "TTT: A Temporal Refinement Heuristic for Tenuously Tractable Discrete Time Reachability Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Chelsea Sidrane",
        "Jana Tumova"
      ],
      "abstract": "Reachable set computation is an important tool for analyzing control systems.\nSimulating a control system can show general trends, but a formal tool like\nreachability analysis can provide guarantees of correctness. Reachability\nanalysis for complex control systems, e.g., with nonlinear dynamics and/or a\nneural network controller, is often either slow or overly conservative. To\naddress these challenges, much literature has focused on spatial refinement,\ni.e., tuning the discretization of the input sets and intermediate reachable\nsets. This paper introduces the idea of temporal refinement: automatically\nchoosing when along the horizon of the reachability problem to execute slow\nsymbolic queries which incur less approximation error versus fast concrete\nqueries which incur more approximation error. Temporal refinement can be\ncombined with other refinement approaches as an additional tool to trade off\ntractability and tightness in approximate reachable set computation. We\nintroduce a temporal refinement algorithm and demonstrate its effectiveness at\ncomputing approximate reachable sets for nonlinear systems with neural network\ncontrollers. We calculate reachable sets with varying computational budget and\nshow that our algorithm can generate approximate reachable sets with a similar\namount of error to the baseline in 20-70% less time.",
      "tldr_zh": "该论文针对复杂控制系统的可达集（reachable set）计算问题，引入了一种时间精化（temporal refinement）启发式方法，以解决现有分析方法在非线性动态和神经网络控制器（neural network controllers）下的速度慢和过度保守问题。方法通过自动选择在时间线上何时使用低误差的符号查询（symbolic queries）与高误差的具体查询（concrete queries），从而优化计算效率和精度。实验结果显示，该算法在计算非线性系统可达集时，能在20-70%的更短时间内产生与基线方法类似误差的近似结果，为可达性分析的实用性提供了新工具。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "To appear in the proceedings of the American Control Conference (ACC)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2407.14394v2",
      "published_date": "2024-07-19 15:16:25 UTC",
      "updated_date": "2025-05-06 16:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:12:06.091608"
    },
    {
      "arxiv_id": "2407.14387v1",
      "title": "GLAudio Listens to the Sound of the Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Aurelio Sulser",
        "Johann Wenckstern",
        "Clara Kuempel"
      ],
      "abstract": "We propose GLAudio: Graph Learning on Audio representation of the node\nfeatures and the connectivity structure. This novel architecture propagates the\nnode features through the graph network according to the discrete wave equation\nand then employs a sequence learning architecture to learn the target node\nfunction from the audio wave signal. This leads to a new paradigm of learning\non graph-structured data, in which information propagation and information\nprocessing are separated into two distinct steps. We theoretically characterize\nthe expressivity of our model, introducing the notion of the receptive field of\na vertex, and investigate our model's susceptibility to over-smoothing and\nover-squashing both theoretically as well as experimentally on various graph\ndatasets.",
      "tldr_zh": "本研究提出 GLAudio，一种基于音频表示的图学习方法，通过离散波方程（discrete wave equation）在图网络中传播节点特征，然后使用序列学习架构从音频波信号中学习目标节点函数，从而实现信息传播和信息处理的分离。  \n这种新范式改变了传统图结构数据学习方式，提升了模型的表达能力，并引入了顶点的感受野（receptive field）概念来理论分析模型性能。  \n实验结果显示，GLAudio 在各种图数据集上表现出对 over-smoothing 和 over-squashing 的较低敏感性，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14387v1",
      "published_date": "2024-07-19 15:13:22 UTC",
      "updated_date": "2024-07-19 15:13:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:12:17.442548"
    },
    {
      "arxiv_id": "2407.14384v1",
      "title": "The Sticky Path to Expressive Querying: Decidability of Navigational Queries under Existential Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Piotr Ostropolski-Nalewaja",
        "Sebastian Rudolph"
      ],
      "abstract": "Extensive research in the field of ontology-based query answering has led to\nthe identification of numerous fragments of existential rules (also known as\ntuple-generating dependencies) that exhibit decidable answering of atomic and\nconjunctive queries. Motivated by the increased theoretical and practical\ninterest in navigational queries, this paper considers the question for which\nof these fragments decidability of querying extends to regular path queries\n(RPQs). In fact, decidability of RPQs has recently been shown to generally hold\nfor the comprehensive family of all fragments that come with the guarantee of\nuniversal models being reasonably well-shaped (that is, being of finite\ncliquewidth). Yet, for the second major family of fragments, known as finite\nunification sets (short: fus), which are based on first-order-rewritability,\ncorresponding results have been largely elusive so far. We complete the picture\nby showing that RPQ answering over arbitrary fus rulesets is undecidable. On\nthe positive side, we establish that the problem is decidable for the prominent\nfus subclass of sticky rulesets, with the caveat that a very mild extension of\nthe RPQ formalism turns the problem undecidable again.",
      "tldr_zh": "这篇论文探讨了在 existential rules 下，导航查询（特别是 regular path queries, RPQs）的可判定性问题。研究发现，对于 finite unification sets (fus) 规则集，RPQ 回答是不可判定的，从而填补了这一领域的理论空白。同时，论文证明了 fus 的子类 sticky rulesets 在 RPQ 回答上是可判定的，但如果对 RPQ 形式稍作扩展，该问题又变得不可判定。这为 ontology-based query answering 的理论研究提供了重要见解。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14384v1",
      "published_date": "2024-07-19 15:11:09 UTC",
      "updated_date": "2024-07-19 15:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:12:29.145261"
    },
    {
      "arxiv_id": "2407.14377v1",
      "title": "Enhancing Cloud-Native Resource Allocation with Probabilistic Forecasting Techniques in O-RAN",
      "title_zh": "翻译失败",
      "authors": [
        "Vaishnavi Kasuluru",
        "Luis Blanco",
        "Engin Zeydan",
        "Albert Bel",
        "Angelos Antonopoulos"
      ],
      "abstract": "The need for intelligent and efficient resource provisioning for the\nproductive management of resources in real-world scenarios is growing with the\nevolution of telecommunications towards the 6G era. Technologies such as Open\nRadio Access Network (O-RAN) can help to build interoperable solutions for the\nmanagement of complex systems. Probabilistic forecasting, in contrast to\ndeterministic single-point estimators, can offer a different approach to\nresource allocation by quantifying the uncertainty of the generated\npredictions. This paper examines the cloud-native aspects of O-RAN together\nwith the radio App (rApp) deployment options. The integration of probabilistic\nforecasting techniques as a rApp in O-RAN is also emphasized, along with case\nstudies of real-world applications. Through a comparative analysis of\nforecasting models using the error metric, we show the advantages of Deep\nAutoregressive Recurrent network (DeepAR) over other deterministic\nprobabilistic estimators. Furthermore, the simplicity of Simple-Feed-Forward\n(SFF) leads to a fast runtime but does not capture the temporal dependencies of\nthe input data. Finally, we present some aspects related to the practical\napplicability of cloud-native O-RAN with probabilistic forecasting.",
      "tldr_zh": "这篇论文探讨了在 O-RAN 中应用概率预测技术来提升云原生资源分配效率，以应对 6G 时代电信系统复杂管理的挑战。研究强调了将概率预测作为 rApp 整合到 O-RAN 中的方法，并通过案例研究比较了不同模型的表现，结果显示 DeepAR 在准确率上比其他确定性估计器（如 SFF）提高了预测性能，尽管 SFF 具有更快的运行时间。最终，论文突出了这种方法在实际应用中的可行性，为智能资源管理提供了新的见解。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14377v1",
      "published_date": "2024-07-19 15:04:15 UTC",
      "updated_date": "2024-07-19 15:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:12:41.754846"
    },
    {
      "arxiv_id": "2407.14375v1",
      "title": "On the use of Probabilistic Forecasting for Network Analysis in Open RAN",
      "title_zh": "在 Open RAN 中使用概率预测进行网络分析",
      "authors": [
        "Vaishnavi Kasuluru",
        "Luis Blanco",
        "Engin Zeydan"
      ],
      "abstract": "Unlike other single-point Artificial Intelligence (AI)-based prediction\ntechniques, such as Long-Short Term Memory (LSTM), probabilistic forecasting\ntechniques (e.g., DeepAR and Transformer) provide a range of possible outcomes\nand associated probabilities that enable decision makers to make more informed\nand robust decisions. At the same time, the architecture of Open RAN has\nemerged as a revolutionary approach for mobile networks, aiming at openness,\ninteroperability and innovation in the ecosystem of RAN. In this paper, we\npropose the use of probabilistic forecasting techniques as a radio App (rApp)\nwithin the Open RAN architecture. We investigate and compare different\nprobabilistic and single-point forecasting methods and algorithms to estimate\nthe utilization and resource demands of Physical Resource Blocks (PRBs) of\ncellular base stations. Through our evaluations, we demonstrate the numerical\nadvantages of probabilistic forecasting techniques over traditional\nsingle-point forecasting methods and show that they are capable of providing\nmore accurate and reliable estimates. In particular, DeepAR clearly outperforms\nsingle-point forecasting techniques such as LSTM and Seasonal-Naive (SN)\nbaselines and other probabilistic forecasting techniques such as\nSimple-Feed-Forward (SFF) and Transformer neural networks.",
      "tldr_zh": "本论文探讨了在 Open RAN 架构中使用 Probabilistic Forecasting 技术作为 rApp，以提升移动网络分析的准确性和鲁棒性。研究比较了各种概率预测方法（如 DeepAR 和 Transformer）和单点预测方法（如 LSTM 和 Seasonal-Naive），用于估计蜂窝基站的 Physical Resource Blocks (PRBs) 利用率和资源需求。结果显示，Probabilistic Forecasting 技术在数值性能上优于传统方法，特别是 DeepAR 显著超过了 LSTM 等基线，提供更可靠的预测结果。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14375v1",
      "published_date": "2024-07-19 15:03:38 UTC",
      "updated_date": "2024-07-19 15:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:12:53.027384"
    },
    {
      "arxiv_id": "2407.14372v1",
      "title": "SCoPE: Evaluating LLMs for Software Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "José Gonçalves",
        "Tiago Dias",
        "Eva Maia",
        "Isabel Praça"
      ],
      "abstract": "In recent years, code security has become increasingly important, especially\nwith the rise of interconnected technologies. Detecting vulnerabilities early\nin the software development process has demonstrated numerous benefits.\nConsequently, the scientific community started using machine learning for\nautomated detection of source code vulnerabilities. This work explores and\nrefines the CVEFixes dataset, which is commonly used to train models for\ncode-related tasks, specifically the C/C++ subset. To this purpose, the Source\nCode Processing Engine (SCoPE), a framework composed of strategized techniques\nthat can be used to reduce the size and normalize C/C++ functions is presented.\nThe output generated by SCoPE was used to create a new version of CVEFixes.\nThis refined dataset was then employed in a feature representation analysis to\nassess the effectiveness of the tool's code processing techniques, consisting\nof fine-tuning three pre-trained LLMs for software vulnerability detection. The\nresults show that SCoPE successfully helped to identify 905 duplicates within\nthe evaluated subset. The LLM results corroborate with the literature regarding\ntheir suitability for software vulnerability detection, with the best model\nachieving 53% F1-score.",
      "tldr_zh": "该论文评估了大型语言模型(LLMs)在软件漏洞检测中的性能，重点通过优化 CVEFixes 数据集的 C/C++ 子集来实现。研究引入了 Source Code Processing Engine (SCoPE) 框架，该框架采用策略化的代码处理技术来减少函数大小并进行标准化，从而生成一个更精炼的数据集。实验结果表明，SCoPE 成功识别了 905 个重复项，而微调的三个预训练 LLMs 中表现最佳的模型在软件漏洞检测任务上达到了 53% 的 F1-score，这验证了 LLMs 在该领域的适用性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 3 figures, 1 table, published in DCAI 24 conference",
      "pdf_url": "http://arxiv.org/pdf/2407.14372v1",
      "published_date": "2024-07-19 15:02:00 UTC",
      "updated_date": "2024-07-19 15:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:13:06.693815"
    },
    {
      "arxiv_id": "2407.14364v2",
      "title": "Towards Assessing Data Replication in Music Generation with Music Similarity Metrics on Raw Audio",
      "title_zh": "翻译失败",
      "authors": [
        "Roser Batlle-Roca",
        "Wei-Hisang Liao",
        "Xavier Serra",
        "Yuki Mitsufuji",
        "Emilia Gómez"
      ],
      "abstract": "Recent advancements in music generation are raising multiple concerns about\nthe implications of AI in creative music processes, current business models and\nimpacts related to intellectual property management. A relevant discussion and\nrelated technical challenge is the potential replication and plagiarism of the\ntraining set in AI-generated music, which could lead to misuse of data and\nintellectual property rights violations. To tackle this issue, we present the\nMusic Replication Assessment (MiRA) tool: a model-independent open evaluation\nmethod based on diverse audio music similarity metrics to assess data\nreplication. We evaluate the ability of five metrics to identify exact\nreplication by conducting a controlled replication experiment in different\nmusic genres using synthetic samples. Our results show that the proposed\nmethodology can estimate exact data replication with a proportion higher than\n10%. By introducing the MiRA tool, we intend to encourage the open evaluation\nof music-generative models by researchers, developers, and users concerning\ndata replication, highlighting the importance of the ethical, social, legal,\nand economic consequences. Code and examples are available for reproducibility\npurposes.",
      "tldr_zh": "这篇论文针对AI音乐生成中的数据复制和知识产权风险，提出了Music Replication Assessment (MiRA)工具，这是一个模型无关的评估方法，基于多种Music Similarity Metrics对原始音频进行分析。通过控制实验在不同音乐流派中使用合成样本，测试了五个指标的性能，结果显示这些指标能检测超过10%的精确数据复制。该工具旨在鼓励研究者、开发者和用户对音乐生成模型进行公开评估，并突出相关伦理、社会、法律和经济影响。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at ISMIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14364v2",
      "published_date": "2024-07-19 14:52:11 UTC",
      "updated_date": "2024-08-01 11:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:13:17.268307"
    },
    {
      "arxiv_id": "2407.14361v1",
      "title": "FuzzTheREST: An Intelligent Automated Black-box RESTful API Fuzzer",
      "title_zh": "翻译失败",
      "authors": [
        "Tiago Dias",
        "Eva Maia",
        "Isabel Praça"
      ],
      "abstract": "Software's pervasive impact and increasing reliance in the era of digital\ntransformation raise concerns about vulnerabilities, emphasizing the need for\nsoftware security. Fuzzy testing is a dynamic analysis software testing\ntechnique that consists of feeding faulty input data to a System Under Test\n(SUT) and observing its behavior. Specifically regarding black-box RESTful API\ntesting, recent literature has attempted to automate this technique using\nheuristics to perform the input search and using the HTTP response status codes\nfor classification. However, most approaches do not keep track of code\ncoverage, which is important to validate the solution. This work introduces a\nblack-box RESTful API fuzzy testing tool that employs Reinforcement Learning\n(RL) for vulnerability detection. The fuzzer operates via the OpenAPI\nSpecification (OAS) file and a scenarios file, which includes information to\ncommunicate with the SUT and the sequences of functionalities to test,\nrespectively. To evaluate its effectiveness, the tool was tested on the\nPetstore API. The tool found a total of six unique vulnerabilities and achieved\n55\\% code coverage.",
      "tldr_zh": "该研究提出了一种智能自动化黑盒 RESTful API 模糊测试工具 FuzzTheREST，用于检测软件漏洞。工具采用 Reinforcement Learning (RL) 算法进行输入搜索和漏洞识别，通过 OpenAPI Specification (OAS) 文件和场景文件来操作系统并定义测试序列，与传统方法不同的是，它强调了代码覆盖率的追踪。实验在 Petstore API 上进行，发现了六个独特漏洞，并实现了 55% 的代码覆盖率。该工具有助于提升黑盒 RESTful API 测试的效率和全面性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 4 figures, published in DCAI 2024 conference, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.14361v1",
      "published_date": "2024-07-19 14:43:35 UTC",
      "updated_date": "2024-07-19 14:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:13:28.582012"
    },
    {
      "arxiv_id": "2407.14358v2",
      "title": "Stable Audio Open",
      "title_zh": "翻译失败",
      "authors": [
        "Zach Evans",
        "Julian D. Parker",
        "CJ Carr",
        "Zack Zukowski",
        "Josiah Taylor",
        "Jordi Pons"
      ],
      "abstract": "Open generative models are vitally important for the community, allowing for\nfine-tunes and serving as baselines when presenting new models. However, most\ncurrent text-to-audio models are private and not accessible for artists and\nresearchers to build upon. Here we describe the architecture and training\nprocess of a new open-weights text-to-audio model trained with Creative Commons\ndata. Our evaluation shows that the model's performance is competitive with the\nstate-of-the-art across various metrics. Notably, the reported FDopenl3 results\n(measuring the realism of the generations) showcase its potential for\nhigh-quality stereo sound synthesis at 44.1kHz.",
      "tldr_zh": "该研究强调了开放生成模型的重要性，特别是为文本到音频模型提供微调和基准。该团队开发了一个新的开放权重文本到音频模型，使用 Creative Commons 数据进行训练，并详细描述了其架构和训练过程。评估结果显示，该模型在各种指标上与最先进模型竞争，尤其在 FDopenl3 指标上表现出色，支持 44.1kHz 高质量立体声音合成。整体而言，此模型为艺术家和研究人员提供了可构建的资源，促进音频生成领域的创新。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Demo: https://stability-ai.github.io/stable-audio-open-demo/ Weights:\n  https://huggingface.co/stabilityai/stable-audio-open-1.0 Code:\n  https://github.com/Stability-AI/stable-audio-tools. arXiv admin note: text\n  overlap with arXiv:2404.10301",
      "pdf_url": "http://arxiv.org/pdf/2407.14358v2",
      "published_date": "2024-07-19 14:40:23 UTC",
      "updated_date": "2024-07-31 16:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:13:40.486728"
    },
    {
      "arxiv_id": "2407.14344v2",
      "title": "LLMs left, right, and center: Assessing GPT's capabilities to label political bias from web domains",
      "title_zh": "翻译失败",
      "authors": [
        "Raphael Hernandes",
        "Giulio Corsi"
      ],
      "abstract": "This research investigates whether OpenAI's GPT-4, a state-of-the-art large\nlanguage model, can accurately classify the political bias of news sources\nbased solely on their URLs. Given the subjective nature of political labels,\nthird-party bias ratings like those from Ad Fontes Media, AllSides, and Media\nBias/Fact Check (MBFC) are often used in research to analyze news source\ndiversity. This study aims to determine if GPT-4 can replicate these human\nratings on a seven-degree scale (\"far-left\" to \"far-right\"). The analysis\ncompares GPT-4's classifications against MBFC's, and controls for website\npopularity using Open PageRank scores. Findings reveal a high correlation\n($\\text{Spearman's } \\rho = .89$, $n = 5,877$, $p < 0.001$) between GPT-4's and\nMBFC's ratings, indicating the model's potential reliability. However, GPT-4\nabstained from classifying approximately $\\frac{2}{3}$ of the dataset. It is\nmore likely to abstain from rating unpopular websites, which also suffer from\nless accurate assessments. The LLM tends to avoid classifying sources that MBFC\nconsiders to be centrist, resulting in more polarized outputs. Finally, this\nanalysis shows a slight leftward skew in GPT's classifications compared to\nMBFC's. Therefore, while this paper suggests that while GPT-4 can be a\nscalable, cost-effective tool for political bias classification of news\nwebsites, its use should be as a complement to human judgment to mitigate\nbiases.",
      "tldr_zh": "该研究评估了 OpenAI 的 GPT-4 是否能基于新闻来源的 URL 准确分类其政治偏见，使用七度量表（从 \"far-left\" 到 \"far-right\"）并与 Media Bias/Fact Check (MBFC) 的评级进行比较，同时控制网站流行度通过 Open PageRank 分数。结果显示 GPT-4 与 MBFC 的评级高度相关（Spearman's ρ = 0.89, n=5,877, p<0.001），表明其潜在可靠性，但 GPT-4 拒绝分类约 2/3 的数据集，尤其是不受欢迎的网站，并倾向于避免 \"centrist\" 来源，导致输出更偏向两极。研究还发现 GPT-4 的分类存在轻微左倾偏差。作为主要贡献，该论文建议 GPT-4 可作为可扩展、成本有效的政治偏见分类工具，但应与人类判断结合以缓解偏差。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14344v2",
      "published_date": "2024-07-19 14:28:07 UTC",
      "updated_date": "2024-10-22 16:59:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:13:55.378117"
    },
    {
      "arxiv_id": "2407.14326v1",
      "title": "Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Zhao",
        "Jakub Prokop",
        "Javier Montalt Tordera",
        "Sadegh Mohammadi"
      ],
      "abstract": "Mammography is crucial for breast cancer surveillance and early diagnosis.\nHowever, analyzing mammography images is a demanding task for radiologists, who\noften review hundreds of mammograms daily, leading to overdiagnosis and\novertreatment. Computer-Aided Diagnosis (CAD) systems have been developed to\nassist in this process, but their capabilities, particularly in lesion\nsegmentation, remained limited. With the contemporary advances in deep learning\ntheir performance may be improved. Recently, vision-language diffusion models\nemerged, demonstrating outstanding performance in image generation and\ntransferability to various downstream tasks. We aim to harness their\ncapabilities for breast lesion segmentation in a panoptic setting, which\nencompasses both semantic and instance-level predictions. Specifically, we\npropose leveraging pretrained features from a Stable Diffusion model as inputs\nto a state-of-the-art panoptic segmentation architecture, resulting in accurate\ndelineation of individual breast lesions. To bridge the gap between natural and\nmedical imaging domains, we incorporated a mammography-specific MAM-E diffusion\nmodel and BiomedCLIP image and text encoders into this framework. We evaluated\nour approach on two recently published mammography datasets, CDD-CESM and\nVinDr-Mammo. For the instance segmentation task, we noted 40.25 AP0.1 and 46.82\nAP0.05, as well as 25.44 PQ0.1 and 26.92 PQ0.05. For the semantic segmentation\ntask, we achieved Dice scores of 38.86 and 40.92, respectively.",
      "tldr_zh": "本研究针对乳腺X光检查（Mammography）中放射科医生的工作负担和现有计算机辅助诊断（CAD）系统在病变分割方面的局限性，提出了一种基于Text-To-Image Diffusion Model的全景分割（Panoptic Segmentation）框架。方法利用预训练的Stable Diffusion模型特征作为输入，结合先进的分割架构，并融入专属乳腺模型MAM-E diffusion model和BiomedCLIP编码器，以适应医疗图像领域。实验在CDD-CESM和VinDr-Mammo数据集上评估，实例分割指标达到40.25 AP0.1和46.82 AP0.05，以及25.44 PQ0.1和26.92 PQ0.05；语义分割的Dice scores分别为38.86和40.92，展示了显著的分割性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 4 figures. Submitted to Deep Generative Models workshop @\n  MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14326v1",
      "published_date": "2024-07-19 14:04:05 UTC",
      "updated_date": "2024-07-19 14:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:14:06.316016"
    },
    {
      "arxiv_id": "2407.14314v1",
      "title": "EmoCAM: Toward Understanding What Drives CNN-based Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Youssef Doulfoukar",
        "Laurent Mertens",
        "Joost Vennekens"
      ],
      "abstract": "Convolutional Neural Networks are particularly suited for image analysis\ntasks, such as Image Classification, Object Recognition or Image Segmentation.\nLike all Artificial Neural Networks, however, they are \"black box\" models, and\nsuffer from poor explainability. This work is concerned with the specific\ndownstream task of Emotion Recognition from images, and proposes a framework\nthat combines CAM-based techniques with Object Detection on a corpus level to\nbetter understand on which image cues a particular model, in our case EmoNet,\nrelies to assign a specific emotion to an image. We demonstrate that the model\nmostly focuses on human characteristics, but also explore the pronounced effect\nof specific image modifications.",
      "tldr_zh": "这篇论文针对 CNN-based 情绪识别任务的解释性问题，提出 EmoCAM 框架，该框架结合 CAM-based techniques 和 Object Detection，在语料库级别上分析模型（如 EmoNet）依赖哪些图像线索来分配情绪标签。研究发现，模型主要关注人类特征作为关键线索，同时探讨了特定图像修改对识别结果的显著影响。通过这种方法，论文提升了对“黑盒”模型决策过程的理解，为改进情绪识别的可解释性提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14314v1",
      "published_date": "2024-07-19 13:47:02 UTC",
      "updated_date": "2024-07-19 13:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:14:17.391911"
    },
    {
      "arxiv_id": "2407.14309v2",
      "title": "How to Engage Your Readers? Generating Guiding Questions to Promote Active Reading",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Cui",
        "Vilém Zouhar",
        "Xiaoyu Zhang",
        "Mrinmaya Sachan"
      ],
      "abstract": "Using questions in written text is an effective strategy to enhance\nreadability. However, what makes an active reading question good, what the\nlinguistic role of these questions is, and what is their impact on human\nreading remains understudied. We introduce GuidingQ, a dataset of 10K in-text\nquestions from textbooks and scientific articles. By analyzing the dataset, we\npresent a comprehensive understanding of the use, distribution, and linguistic\ncharacteristics of these questions. Then, we explore various approaches to\ngenerate such questions using language models. Our results highlight the\nimportance of capturing inter-question relationships and the challenge of\nquestion position identification in generating these questions. Finally, we\nconduct a human study to understand the implication of such questions on\nreading comprehension. We find that the generated questions are of high quality\nand are almost as effective as human-written questions in terms of improving\nreaders' memorization and comprehension.",
      "tldr_zh": "这篇论文探讨了使用引导性问题提升文本可读性和促进主动阅读的有效性，引入了GuidingQ数据集，该数据集包含10K个来自教科书和科学文章的文本内问题。研究者通过分析数据集，揭示了这些问题的使用分布、语言特征，并探索了利用语言模型生成此类问题的多种方法，结果强调捕捉问题间关系和位置识别的挑战。最终，通过人类研究发现，生成的引导性问题质量高，能显著改善读者的记忆和理解，几乎与人工撰写的问题同样有效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14309v2",
      "published_date": "2024-07-19 13:42:56 UTC",
      "updated_date": "2024-07-29 01:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:14:30.012678"
    },
    {
      "arxiv_id": "2407.14306v2",
      "title": "Label-Free Model Failure Detection for Lidar-based Point Cloud Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Bogdoll",
        "Finn Sartoris",
        "Vincent Geppert",
        "Svetlana Pavlitska",
        "J. Marius Zöllner"
      ],
      "abstract": "Autonomous vehicles drive millions of miles on the road each year. Under such\ncircumstances, deployed machine learning models are prone to failure both in\nseemingly normal situations and in the presence of outliers. However, in the\ntraining phase, they are only evaluated on small validation and test sets,\nwhich are unable to reveal model failures due to their limited scenario\ncoverage. While it is difficult and expensive to acquire large and\nrepresentative labeled datasets for evaluation, large-scale unlabeled datasets\nare typically available. In this work, we introduce label-free model failure\ndetection for lidar-based point cloud segmentation, taking advantage of the\nabundance of unlabeled data available. We leverage different data\ncharacteristics by training a supervised and self-supervised stream for the\nsame task to detect failure modes. We perform a large-scale qualitative\nanalysis and present LidarCODA, the first publicly available dataset with\nlabeled anomalies in real-world lidar data, for an extensive quantitative\nanalysis.",
      "tldr_zh": "这篇论文针对激光雷达点云分割任务，提出了一种无标签模型失败检测方法，以解决自动驾驶车辆部署中模型在正常和异常场景下易失败的问题。方法利用丰富的无标签数据，通过训练一个监督流和一个自监督流来识别失败模式，从而利用不同数据特性进行检测。研究者进行了大规模定性分析，并发布了LidarCODA，这是首个公开的真实世界激光雷达数据异常标注数据集，用于全面的定量评估。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Daniel Bogdoll, Finn Sartoris, and Vincent Geppert contributed\n  equally. Accepted for publication at IV 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.14306v2",
      "published_date": "2024-07-19 13:36:35 UTC",
      "updated_date": "2025-04-24 09:40:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:14:41.060605"
    },
    {
      "arxiv_id": "2407.20250v1",
      "title": "Riemannian Geometry-Based EEG Approaches: A Literature Review",
      "title_zh": "基于黎曼几何的脑电图方法：文献综述",
      "authors": [
        "Imad Eddine Tibermacine",
        "Samuele Russo",
        "Ahmed Tibermacine",
        "Abdelaziz Rabehi",
        "Bachir Nail",
        "Kamel Kadri",
        "Christian Napoli"
      ],
      "abstract": "The application of Riemannian geometry in the decoding of brain-computer\ninterfaces (BCIs) has swiftly garnered attention because of its\nstraightforwardness, precision, and resilience, along with its aptitude for\ntransfer learning, which has been demonstrated through significant achievements\nin global BCI competitions. This paper presents a comprehensive review of\nrecent advancements in the integration of deep learning with Riemannian\ngeometry to enhance EEG signal decoding in BCIs. Our review updates the\nfindings since the last major review in 2017, comparing modern approaches that\nutilize deep learning to improve the handling of non-Euclidean data structures\ninherent in EEG signals. We discuss how these approaches not only tackle the\ntraditional challenges of noise sensitivity, non-stationarity, and lengthy\ncalibration times but also introduce novel classification frameworks and signal\nprocessing techniques to reduce these limitations significantly. Furthermore,\nwe identify current shortcomings and propose future research directions in\nmanifold learning and riemannian-based classification, focusing on practical\nimplementations and theoretical expansions, such as feature tracking on\nmanifolds, multitask learning, feature extraction, and transfer learning. This\nreview aims to bridge the gap between theoretical research and practical,\nreal-world applications, making sophisticated mathematical approaches\naccessible and actionable for BCI enhancements.",
      "tldr_zh": "这篇文献综述回顾了Riemannian geometry在脑机接口(BCI)中用于EEG信号解码的最新进展，特别是与deep learning的整合，以处理EEG信号的非Euclidean数据结构。论文比较了现代方法如何解决传统挑战，如噪声敏感性、非平稳性和校准时间长的问题，并引入了新型分类框架和信号处理技术，显著降低了这些限制。最终，作者指出了当前短缺，并提出未来研究方向，包括manifold learning、Riemannian-based分类、特征跟踪、多任务学习、特征提取和transfer learning，以桥接理论研究与实际BCI应用的差距。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20250v1",
      "published_date": "2024-07-19 13:28:29 UTC",
      "updated_date": "2024-07-19 13:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:15:03.852495"
    },
    {
      "arxiv_id": "2407.14295v1",
      "title": "CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units",
      "title_zh": "翻译失败",
      "authors": [
        "Yeeun Kang"
      ],
      "abstract": "Multilingual code-switching research is often hindered by the lack and\nlinguistically biased status of available datasets. To expand language\nrepresentation, we synthesize code-switching data by replacing intonation units\ndetected through PSST, a speech segmentation model fine-tuned from OpenAI's\nWhisper, using a speech-to-text translation dataset, CoVoST 2. With our\ndataset, CoVoSwitch, spanning 13 languages, we evaluate the code-switching\ntranslation performance of two multilingual translation models, M2M-100 418M\nand NLLB-200 600M. We reveal that the inclusion of code-switching units results\nin higher translation performance than monolingual settings and that models are\nbetter at code-switching translation into English than non-English. Further,\nlow-resource languages gain most from integration of code-switched units when\ntranslating into English but much less when translating into non-English.\nTranslations into low-resource languages also perform worse than even raw\ncode-switched inputs. We find that systems excel at copying English tokens but\nstruggle with non-English tokens, that the off-target problem in monolingual\nsettings is also relevant in code-switching settings, and that models\nhallucinate in code-switching translation by introducing words absent in both\nof the original source sentences. CoVoSwitch and code are available at\nhttps://github.com/sophiayk20/covoswitch.",
      "tldr_zh": "本文提出 CoVoSwitch 数据集，通过使用 PSST（基于 Whisper 微调的语音分割模型）检测语调单位，在 CoVoST 2 数据集基础上合成涵盖 13 种语言的代码-switching 数据，以缓解多语言代码-switching 研究中数据集缺乏和偏见问题。评估结果显示，M2M-100 418M 和 NLLB-200 600M 模型在包含代码-switching 单位时比单语设置表现出色，尤其在翻译成英语时性能更佳。研究发现，低资源语言在英语翻译中获益最大，但翻译成非英语时效果较差，且模型易于复制英语标记却在处理非英语标记时挣扎，并可能出现 hallucinate（幻觉）现象，如引入源句中不存在的词。CoVoSwitch 数据集及其代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 Student Research Workshop (ACL-SRW 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.14295v1",
      "published_date": "2024-07-19 13:26:35 UTC",
      "updated_date": "2024-07-19 13:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:15:19.230948"
    },
    {
      "arxiv_id": "2407.14280v2",
      "title": "How to Blend Concepts in Diffusion Models",
      "title_zh": "如何在扩散模型中融合概念",
      "authors": [
        "Lorenzo Olearo",
        "Giorgio Longari",
        "Simone Melzi",
        "Alessandro Raganato",
        "Rafael Peñaloza"
      ],
      "abstract": "For the last decade, there has been a push to use multi-dimensional (latent)\nspaces to represent concepts; and yet how to manipulate these concepts or\nreason with them remains largely unclear. Some recent methods exploit multiple\nlatent representations and their connection, making this research question even\nmore entangled. Our goal is to understand how operations in the latent space\naffect the underlying concepts. To that end, we explore the task of concept\nblending through diffusion models. Diffusion models are based on a connection\nbetween a latent representation of textual prompts and a latent space that\nenables image reconstruction and generation. This task allows us to try\ndifferent text-based combination strategies, and evaluate easily through a\nvisual analysis. Our conclusion is that concept blending through space\nmanipulation is possible, although the best strategy depends on the context of\nthe blend.",
      "tldr_zh": "这篇论文探讨了如何在扩散模型(diffusion models)中混合概念(concept blending)，旨在理解潜在空间(latent space)操作对概念的影响。\n研究者通过文本提示的组合策略和视觉分析，评估了不同混合方法在图像生成中的效果。\n结论是，概念混合通过空间操作是可能的，但最佳策略取决于具体情境。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14280v2",
      "published_date": "2024-07-19 13:05:57 UTC",
      "updated_date": "2024-09-22 07:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:15:27.463807"
    },
    {
      "arxiv_id": "2407.14274v2",
      "title": "Mixed-precision Neural Networks on RISC-V Cores: ISA extensions for Multi-Pumped Soft SIMD Operations",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgos Armeniakos",
        "Alexis Maras",
        "Sotirios Xydis",
        "Dimitrios Soudris"
      ],
      "abstract": "Recent advancements in quantization and mixed-precision approaches offers\nsubstantial opportunities to improve the speed and energy efficiency of Neural\nNetworks (NN). Research has shown that individual parameters with varying low\nprecision, can attain accuracies comparable to full-precision counterparts.\nHowever, modern embedded microprocessors provide very limited support for\nmixed-precision NNs regarding both Instruction Set Architecture (ISA)\nextensions and their hardware design for efficient execution of mixed-precision\noperations, i.e., introducing several performance bottlenecks due to numerous\ninstructions for data packing and unpacking, arithmetic unit under-utilizations\netc. In this work, we bring together, for the first time, ISA extensions\ntailored to mixed-precision hardware optimizations, targeting energy-efficient\nDNN inference on leading RISC-V CPU architectures. To this end, we introduce a\nhardware-software co-design framework that enables cooperative hardware design,\nmixed-precision quantization, ISA extensions and inference in cycle-accurate\nemulations. At hardware level, we firstly expand the ALU unit within our\nproof-of-concept micro-architecture to support configurable fine grained\nmixed-precision arithmetic operations. Subsequently, we implement multi-pumping\nto minimize execution latency, with an additional soft SIMD optimization\napplied for 2-bit operations. At the ISA level, three distinct MAC instructions\nare encoded extending the RISC-V ISA, and exposed up to the compiler level,\neach corresponding to a different mixed-precision operational mode. Our\nextensive experimental evaluation over widely used DNNs and datasets, such as\nCIFAR10 and ImageNet, demonstrates that our framework can achieve, on average,\n15x energy reduction for less than 1% accuracy loss and outperforms the\nISA-agnostic state-of-the-art RISC-V cores.",
      "tldr_zh": "本研究针对混合精度神经网络（Mixed-precision Neural Networks）在 RISC-V 处理器上的执行瓶颈，首次提出 ISA 扩展以支持多泵送（Multi-Pumped）和软 SIMD 操作，从而提升速度和能效。研究引入一个硬件-软件协同设计框架，包括扩展 ALU 支持细粒度混合精度运算、实现多泵送最小化延迟，以及添加三个新的 MAC 指令到 RISC-V ISA，以适应不同混合精度模式。实验结果显示，在 CIFAR10 和 ImageNet 等数据集上，该框架平均实现 15 倍能效提升，同时准确率损失不到 1%，并优于现有 RISC-V 核心。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted for publication at the 43rd International Conference on\n  Computer-Aided Design (ICCAD `24), Oct 27-31 2024, New Jersey, USA",
      "pdf_url": "http://arxiv.org/pdf/2407.14274v2",
      "published_date": "2024-07-19 12:54:04 UTC",
      "updated_date": "2024-08-13 11:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:15:40.365219"
    },
    {
      "arxiv_id": "2407.14262v1",
      "title": "Hyperparameter Optimization for Driving Strategies Based on Reinforcement Learning",
      "title_zh": "基于强化学习的驾驶策略超参数优化",
      "authors": [
        "Nihal Acharya Adde",
        "Hanno Gottschalk",
        "Andreas Ebert"
      ],
      "abstract": "This paper focuses on hyperparameter optimization for autonomous driving\nstrategies based on Reinforcement Learning. We provide a detailed description\nof training the RL agent in a simulation environment. Subsequently, we employ\nEfficient Global Optimization algorithm that uses Gaussian Process fitting for\nhyperparameter optimization in RL. Before this optimization phase, Gaussian\nprocess interpolation is applied to fit the surrogate model, for which the\nhyperparameter set is generated using Latin hypercube sampling. To accelerate\nthe evaluation, parallelization techniques are employed. Following the\nhyperparameter optimization procedure, a set of hyperparameters is identified,\nresulting in a noteworthy enhancement in overall driving performance. There is\na substantial increase of 4\\% when compared to existing manually tuned\nparameters and the hyperparameters discovered during the initialization process\nusing Latin hypercube sampling. After the optimization, we analyze the obtained\nresults thoroughly and conduct a sensitivity analysis to assess the robustness\nand generalization capabilities of the learned autonomous driving strategies.\nThe findings from this study contribute to the advancement of Gaussian process\nbased Bayesian optimization to optimize the hyperparameters for autonomous\ndriving in RL, providing valuable insights for the development of efficient and\nreliable autonomous driving systems.",
      "tldr_zh": "本文提出了一种针对基于 Reinforcement Learning 的自动驾驶策略的超参数优化方法，通过在模拟环境中训练 RL 代理，并使用 Efficient Global Optimization 算法结合 Gaussian Process fitting 来优化超参数。初始超参数集由 Latin hypercube sampling 生成，并通过 Gaussian process interpolation 拟合代理模型，同时采用并行化技术加速评估过程。优化后，获得的超参数使整体驾驶性能较手动调优参数提升 4%，并优于初始采样结果。研究还进行了敏感性分析，以验证策略的鲁棒性和泛化能力，并为 Gaussian process based Bayesian optimization 在自动驾驶系统中的应用提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted and accepted by LOD24 conference\n  https://lod2024.icas.events/",
      "pdf_url": "http://arxiv.org/pdf/2407.14262v1",
      "published_date": "2024-07-19 12:40:08 UTC",
      "updated_date": "2024-07-19 12:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:15:54.276121"
    },
    {
      "arxiv_id": "2408.03329v1",
      "title": "Coverage-aware and Reinforcement Learning Using Multi-agent Approach for HD Map QoS in a Realistic Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffrey Redondo",
        "Zhenhui Yuan",
        "Nauman Aslam",
        "Juan Zhang"
      ],
      "abstract": "One effective way to optimize the offloading process is by minimizing the\ntransmission time. This is particularly true in a Vehicular Adhoc Network\n(VANET) where vehicles frequently download and upload High-definition (HD) map\ndata which requires constant updates. This implies that latency and throughput\nrequirements must be guaranteed by the wireless system. To achieve this,\nadjustable contention windows (CW) allocation strategies in the standard\nIEEE802.11p have been explored by numerous researchers. Nevertheless, their\nimplementations demand alterations to the existing standard which is not always\ndesirable. To address this issue, we proposed a Q-Learning algorithm that\noperates at the application layer. Moreover, it could be deployed in any\nwireless network thereby mitigating the compatibility issues. The solution has\ndemonstrated a better network performance with relatively fewer optimization\nrequirements as compared to the Deep Q Network (DQN) and Actor-Critic\nalgorithms. The same is observed while evaluating the model in a multi-agent\nsetup showing higher performance compared to the single-agent setup.",
      "tldr_zh": "该论文针对车辆自组网(VANET)中高精度(HD)地图数据的传输优化问题，提出了一种基于 Q-Learning 的算法，以最小化传输时间并确保无线系统的延迟和吞吐量要求。该算法在应用层实现，无需修改 IEEE 802.11p 标准，从而提升兼容性和部署灵活性。实验结果表明，该方法在多智能体环境中比单智能体设置以及 Deep Q Network (DQN) 和 Actor-Critic 算法表现出更高的网络性能，并以较少的优化需求实现了更好的 QoS。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03329v1",
      "published_date": "2024-07-19 12:40:07 UTC",
      "updated_date": "2024-07-19 12:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:16:04.323096"
    },
    {
      "arxiv_id": "2407.14251v1",
      "title": "Personalized Multi-tier Federated Learning",
      "title_zh": "个性化的多层联邦学习",
      "authors": [
        "Sourasekhar Banerjee",
        "Ali Dadras",
        "Alp Yurtsever",
        "Monowar Bhuyan"
      ],
      "abstract": "The key challenge of personalized federated learning (PerFL) is to capture\nthe statistical heterogeneity properties of data with inexpensive\ncommunications and gain customized performance for participating devices. To\naddress these, we introduced personalized federated learning in multi-tier\narchitecture (PerMFL) to obtain optimized and personalized local models when\nthere are known team structures across devices. We provide theoretical\nguarantees of PerMFL, which offers linear convergence rates for smooth strongly\nconvex problems and sub-linear convergence rates for smooth non-convex\nproblems. We conduct numerical experiments demonstrating the robust empirical\nperformance of PerMFL, outperforming the state-of-the-art in multiple\npersonalized federated learning tasks.",
      "tldr_zh": "该研究针对个性化联邦学习(PerFL)的核心挑战，即在低成本通信下捕捉数据统计异质性并实现设备自定义性能，提出了一种多层架构的PerMFL框架。该框架针对设备间已知团队结构，优化并生成个性化的本地模型，并提供了理论保证，包括平滑强凸问题的线性收敛率和平滑非凸问题的子线性收敛率。实验结果显示，PerMFL在多个个性化联邦学习任务中表现优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14251v1",
      "published_date": "2024-07-19 12:31:15 UTC",
      "updated_date": "2024-07-19 12:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:16:15.290750"
    },
    {
      "arxiv_id": "2407.14239v1",
      "title": "KoMA: Knowledge-driven Multi-agent Framework for Autonomous Driving with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kemou Jiang",
        "Xuan Cai",
        "Zhiyong Cui",
        "Aoyong Li",
        "Yilong Ren",
        "Haiyang Yu",
        "Hao Yang",
        "Daocheng Fu",
        "Licheng Wen",
        "Pinlong Cai"
      ],
      "abstract": "Large language models (LLMs) as autonomous agents offer a novel avenue for\ntackling real-world challenges through a knowledge-driven manner. These\nLLM-enhanced methodologies excel in generalization and interpretability.\nHowever, the complexity of driving tasks often necessitates the collaboration\nof multiple, heterogeneous agents, underscoring the need for such LLM-driven\nagents to engage in cooperative knowledge sharing and cognitive synergy.\nDespite the promise of LLMs, current applications predominantly center around\nsingle agent scenarios. To broaden the horizons of knowledge-driven strategies\nand bolster the generalization capabilities of autonomous agents, we propose\nthe KoMA framework consisting of multi-agent interaction, multi-step planning,\nshared-memory, and ranking-based reflection modules to enhance multi-agents'\ndecision-making in complex driving scenarios. Based on the framework's\ngenerated text descriptions of driving scenarios, the multi-agent interaction\nmodule enables LLM agents to analyze and infer the intentions of surrounding\nvehicles, akin to human cognition. The multi-step planning module enables LLM\nagents to analyze and obtain final action decisions layer by layer to ensure\nconsistent goals for short-term action decisions. The shared memory module can\naccumulate collective experience to make superior decisions, and the\nranking-based reflection module can evaluate and improve agent behavior with\nthe aim of enhancing driving safety and efficiency. The KoMA framework not only\nenhances the robustness and adaptability of autonomous driving agents but also\nsignificantly elevates their generalization capabilities across diverse\nscenarios. Empirical results demonstrate the superiority of our approach over\ntraditional methods, particularly in its ability to handle complex,\nunpredictable driving environments without extensive retraining.",
      "tldr_zh": "该研究提出KoMA框架，一种基于大型语言模型(LLMs)的知识驱动多智能体系统，用于提升自动驾驶代理的决策能力。该框架包括多智能体交互模块（分析周围车辆意图）、多步规划模块（层级决策确保行动一致性）、共享内存模块（积累集体经验）以及基于排名的反思模块（评估并优化行为），从而实现代理间的合作知识共享和认知协同。实验结果显示，KoMA在复杂驾驶场景中显著优于传统方法，提高了代理的鲁棒性、适应性和泛化能力，而无需大量重新训练。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14239v1",
      "published_date": "2024-07-19 12:13:08 UTC",
      "updated_date": "2024-07-19 12:13:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:16:36.866979"
    },
    {
      "arxiv_id": "2407.14237v1",
      "title": "Hyper-Heuristics Can Profit From Global Variation Operators",
      "title_zh": "超启发式可以从全局变异算子中获益",
      "authors": [
        "Benjamin Doerr",
        "Johannes F. Lutzeyer"
      ],
      "abstract": "In recent work, Lissovoi, Oliveto, and Warwicker (Artificial Intelligence\n(2023)) proved that the Move Acceptance Hyper-Heuristic (MAHH) leaves the local\noptimum of the multimodal CLIFF benchmark with remarkable efficiency. The\n$O(n^3)$ runtime of the MAHH, for almost all cliff widths $d\\ge 2,$ is\nsignificantly better than the $\\Theta(n^d)$ runtime of simple elitist\nevolutionary algorithms (EAs) on CLIFF.\n  In this work, we first show that this advantage is specific to the CLIFF\nproblem and does not extend to the JUMP benchmark, the most prominent\nmulti-modal benchmark in the theory of randomized search heuristics. We prove\nthat for any choice of the MAHH selection parameter $p$, the expected runtime\nof the MAHH on a JUMP function with gap size $m = O(n^{1/2})$ is at least\n$\\Omega(n^{2m-1} / (2m-1)!)$. This is significantly slower than the $O(n^m)$\nruntime of simple elitist EAs. Encouragingly, we also show that replacing the\nlocal one-bit mutation operator in the MAHH with the global bit-wise mutation\noperator, commonly used in EAs, yields a runtime of $\\min\\{1,\nO(\\frac{e\\ln(n)}{m})^m\\} \\, O(n^m)$ on JUMP functions. This is at least as good\nas the runtime of simple elitist EAs. For larger values of $m$, this result\nproves an asymptotic performance gain over simple EAs. As our proofs reveal,\nthe MAHH profits from its ability to walk through the valley of lower objective\nvalues in moderate-size steps, always accepting inferior solutions. This is the\nfirst time that such an optimization behavior is proven via mathematical means.\nGenerally, our result shows that combining two ways of coping with local\noptima, global mutation and accepting inferior solutions, can lead to\nconsiderable performance gains.",
      "tldr_zh": "本研究分析了Move Acceptance Hyper-Heuristic (MAHH)算法在多模态基准上的性能，证明其在CLIFF函数上以O(n^3)运行时间高效离开局部最优，但对JUMP函数的预期运行时间至少为Ω(n^{2m-1} / (2m-1)!)，远慢于简单精英主义进化算法 (EAs) 的O(n^m)。作者发现，通过在MAHH中替换局部一比特突变操作符为全局位-wise突变操作符，可将JUMP函数的运行时间优化为min{1, O((e ln(n)/m)^m)} O(n^m)，在m较大时甚至优于EAs。总体上，这首次通过数学证明展示了MAHH接受劣等解并以中等步长穿越低值谷的机制，以及结合全局变异操作符带来的性能提升。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.NE",
      "comment": "Continues and significantly extends work presented in the GECCO 2023\n  conference paper arXiv:2304.10414",
      "pdf_url": "http://arxiv.org/pdf/2407.14237v1",
      "published_date": "2024-07-19 12:10:05 UTC",
      "updated_date": "2024-07-19 12:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:16:41.758104"
    },
    {
      "arxiv_id": "2407.14229v2",
      "title": "Words2Contact: Identifying Support Contacts from Verbal Instructions Using Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dionis Totsila",
        "Quentin Rouxel",
        "Jean-Baptiste Mouret",
        "Serena Ivaldi"
      ],
      "abstract": "This paper presents Words2Contact, a language-guided multi-contact placement\npipeline leveraging large language models and vision language models. Our\nmethod is a key component for language-assisted teleoperation and human-robot\ncooperation, where human operators can instruct the robots where to place their\nsupport contacts before whole-body reaching or manipulation using natural\nlanguage. Words2Contact transforms the verbal instructions of a human operator\ninto contact placement predictions; it also deals with iterative corrections,\nuntil the human is satisfied with the contact location identified in the\nrobot's field of view. We benchmark state-of-the-art LLMs and VLMs for size and\nperformance in contact prediction. We demonstrate the effectiveness of the\niterative correction process, showing that users, even naive, quickly learn how\nto instruct the system to obtain accurate locations. Finally, we validate\nWords2Contact in real-world experiments with the Talos humanoid robot,\ninstructed by human operators to place support contacts on different locations\nand surfaces to avoid falling when reaching for distant objects.",
      "tldr_zh": "本研究提出Words2Contact，一种基于大型语言模型(LLMs)和视觉语言模型(VLMs)的语言引导多接触点放置管道，用于语言辅助遥操作和人机合作。系统将人类操作员的自然语言指令转化为机器人支持接触点预测，并支持迭代修正过程，以确保接触位置准确。实验基准测试显示不同LLMs和VLMs在性能和大小上的表现，用户（包括新手）能快速学会指令系统以获得精确位置。最后，在Talos人形机器人上进行真实世界实验，验证了Words2Contact在帮助机器人放置支持接触点以避免摔倒时的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14229v2",
      "published_date": "2024-07-19 11:57:34 UTC",
      "updated_date": "2024-12-09 14:40:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:16:51.947579"
    },
    {
      "arxiv_id": "2407.14210v2",
      "title": "Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "José Daniel Pascual-Triana",
        "Alberto Fernández",
        "Paulo Novais",
        "Francisco Herrera"
      ],
      "abstract": "One of the key issues regarding classification problems in Trustworthy\nArtificial Intelligence is ensuring Fairness in the prediction of different\nclasses when protected (sensitive) features are present. Data quality is\ncritical in these cases, as biases in training data can be reflected in machine\nlearning, impacting human lives and failing to comply with current regulations.\nOne strategy to improve data quality and avoid these problems is preprocessing\nthe dataset. Instance selection via undersampling can foster balanced learning\nof classes and protected feature values. Performing undersampling in class\noverlap areas close to the decision boundary should bolster the impact on the\nclassifier. This work proposes Fair Overlap Number of Balls (Fair-ONB), an\nundersampling method that harnesses the data morphology of the different data\ngroups (obtained from the combination of classes and protected feature values)\nto perform guided undersampling in overlap areas. It employs attributes of the\nball coverage of the groups, such as the radius, number of covered instances\nand density, to select the most suitable areas for undersampling and reduce\nbias. Results show that the Fair-ONB method improves model Fairness with low\nimpact on the classifier's predictive performance.",
      "tldr_zh": "该研究针对可信赖人工智能（Trustworthy Artificial Intelligence）中的分类问题，提出了一种基于数据形态（data morphology）的 undersampling 方法——Fair Overlap Number of Balls (Fair-ONB)，旨在减少训练数据中的偏置（bias reduction）。Fair-ONB 通过分析类和保护特征（protected features）值的组合，在重叠区域（overlap areas）进行引导 undersampling，利用球覆盖（ball coverage）的属性如半径、覆盖实例数和密度来选择合适区域。实验结果显示，该方法显著提高了模型的 Fairness，同时对分类器的预测性能影响较小。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 tables, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14210v2",
      "published_date": "2024-07-19 11:16:02 UTC",
      "updated_date": "2024-09-23 16:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:17:04.201641"
    },
    {
      "arxiv_id": "2407.14202v2",
      "title": "SHS: Scorpion Hunting Strategy Swarm Algorithm",
      "title_zh": "SHS：蝎子狩猎策略群算法",
      "authors": [
        "Abhilash Singh",
        "Seyed Muhammad Hossein Mousavi",
        "Kumar Gaurav"
      ],
      "abstract": "We introduced the Scorpion Hunting Strategy (SHS), a novel population-based,\nnature-inspired optimisation algorithm. This algorithm draws inspiration from\nthe hunting strategy of scorpions, which identify, locate, and capture their\nprey using the alpha and beta vibration operators. These operators control the\nSHS algorithm's exploitation and exploration abilities. To formulate an\noptimisation method, we mathematically simulate these dynamic events and\nbehaviors. We evaluate the effectiveness of the SHS algorithm by employing 20\nbenchmark functions (including 10 conventional and 10 CEC2020 functions), using\nboth qualitative and quantitative analyses. Through a comparative analysis with\n12 state-of-the-art meta-heuristic algorithms, we demonstrate that the proposed\nSHS algorithm yields exceptionally promising results. These findings are\nfurther supported by statistically significant results obtained through the\nWilcoxon rank sum test. Additionally, the ranking of SHS, as determined by the\naverage rank derived from the Friedman test, positions it at the forefront when\ncompared to other algorithms. Going beyond theoretical validation, we showcase\nthe practical utility of the SHS algorithm by applying it to six distinct\nreal-world optimisation tasks. These applications illustrate the algorithm's\npotential in addressing complex optimisation challenges. In summary, this work\nnot only introduces the innovative SHS algorithm but also substantiates its\neffectiveness and versatility through rigorous benchmarking and real-world\nproblem-solving scenarios.",
      "tldr_zh": "本研究引入了Scorpion Hunting Strategy (SHS)，一种新型的基于自然启发的群优化算法，灵感来源于蝎子的狩猎策略。SHS算法通过alpha and beta vibration operators来控制exploration（探索）和exploitation（开发）能力，并通过数学模拟实现这些动态行为。在评估中，SHS在20个benchmark functions（包括10个传统函数和10个CEC2020函数）上表现突出，与12个最先进算法比较后显示出显著优势，并经Wilcoxon rank sum test和Friedman test统计验证。此外，该算法成功应用于6个真实世界优化任务，证明了其在复杂问题中的实用性和有效性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14202v2",
      "published_date": "2024-07-19 10:58:42 UTC",
      "updated_date": "2024-08-30 06:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:17:15.850723"
    },
    {
      "arxiv_id": "2407.14192v2",
      "title": "LeKUBE: A Legal Knowledge Update BEnchmark",
      "title_zh": "LeKUBE：法律知识更新基准",
      "authors": [
        "Changyue Wang",
        "Weihang Su",
        "Hu Yiran",
        "Qingyao Ai",
        "Yueyue Wu",
        "Cheng Luo",
        "Yiqun Liu",
        "Min Zhang",
        "Shaoping Ma"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have significantly shaped the\napplications of AI in multiple fields, including the studies of legal\nintelligence. Trained on extensive legal texts, including statutes and legal\ndocuments, the legal LLMs can capture important legal knowledge/concepts\neffectively and provide important support for downstream legal applications\nsuch as legal consultancy. Yet, the dynamic nature of legal statutes and\ninterpretations also poses new challenges to the use of LLMs in legal\napplications. Particularly, how to update the legal knowledge of LLMs\neffectively and efficiently has become an important research problem in\npractice. Existing benchmarks for evaluating knowledge update methods are\nmostly designed for the open domain and cannot address the specific challenges\nof the legal domain, such as the nuanced application of new legal knowledge,\nthe complexity and lengthiness of legal regulations, and the intricate nature\nof legal reasoning. To address this gap, we introduce the Legal Knowledge\nUpdate BEnchmark, i.e. LeKUBE, which evaluates knowledge update methods for\nlegal LLMs across five dimensions. Specifically, we categorize the needs of\nknowledge updates in the legal domain with the help of legal professionals, and\nthen hire annotators from law schools to create synthetic updates to the\nChinese Criminal and Civil Code as well as sets of questions of which the\nanswers would change after the updates. Through a comprehensive evaluation of\nstate-of-the-art knowledge update methods, we reveal a notable gap between\nexisting knowledge update methods and the unique needs of the legal domain,\nemphasizing the need for further research and development of knowledge update\nmechanisms tailored for legal LLMs.",
      "tldr_zh": "该研究引入了LeKUBE（Legal Knowledge Update BEnchmark），一个针对大型语言模型（LLMs）在法律领域知识更新的基准，以解决法律法规动态变化带来的挑战，如新知识的细微应用、法规复杂性和法律推理的复杂性。研究人员通过与法律专业人士合作，并雇佣法律学校的注释者，创建了对中国刑法和民法典的合成更新，以及相应的问题集，用于评估知识更新方法在五个维度的表现。实验结果显示，现有的知识更新方法无法充分适应法律领域的独特需求，强调了开发针对法律LLMs的专用更新机制的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14192v2",
      "published_date": "2024-07-19 10:40:10 UTC",
      "updated_date": "2024-11-12 11:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:17:28.781726"
    },
    {
      "arxiv_id": "2407.20248v2",
      "title": "LAPIS: Language Model-Augmented Police Investigation System",
      "title_zh": "LAPIS：语言模型增强的警察调查系统",
      "authors": [
        "Heedou Kim",
        "Dain Kim",
        "Jiwoo Lee",
        "Chanwoong Yoon",
        "Donghee Choi",
        "Mogan Gim",
        "Jaewoo Kang"
      ],
      "abstract": "Crime situations are race against time. An AI-assisted criminal investigation\nsystem, providing prompt but precise legal counsel is in need for police\nofficers. We introduce LAPIS (Language Model Augmented Police Investigation\nSystem), an automated system that assists police officers to perform rational\nand legal investigative actions. We constructed a finetuning dataset and\nretrieval knowledgebase specialized in crime investigation legal reasoning\ntask. We extended the dataset's quality by incorporating manual curation\nefforts done by a group of domain experts. We then finetuned the pretrained\nweights of a smaller Korean language model to the newly constructed dataset and\nintegrated it with the crime investigation knowledgebase retrieval approach.\nExperimental results show LAPIS' potential in providing reliable legal guidance\nfor police officers, even better than the proprietary GPT-4 model. Qualitative\nanalysis on the rationales generated by LAPIS demonstrate the model's reasoning\nability to leverage the premises and derive legally correct conclusions.",
      "tldr_zh": "本研究引入了LAPIS（Language Model-Augmented Police Investigation System），一个自动化系统，用于辅助警察进行合理且合法的犯罪调查行动，以提供及时精确的法律建议。研究团队构建了专门针对犯罪调查法律推理的finetuning数据集和retrieval knowledgebase，并通过专家手动整理提升数据集质量，然后对一个较小的韩语预训练模型进行微调，并与知识库检索方法整合。实验结果显示，LAPIS在提供可靠法律指导方面甚至优于专有模型GPT-4，且定性分析证明了模型的推理能力，能够有效利用前提得出正确的法律结论。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20248v2",
      "published_date": "2024-07-19 09:24:29 UTC",
      "updated_date": "2024-07-31 05:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:17:51.351784"
    },
    {
      "arxiv_id": "2407.14145v1",
      "title": "PassTSL: Modeling Human-Created Passwords through Two-Stage Learning",
      "title_zh": "PassTSL：通过两阶段学习建模人类创建的密码",
      "authors": [
        "Yangde Wang",
        "Haozhang Li",
        "Weidong Qiu",
        "Shujun Li",
        "Peng Tang"
      ],
      "abstract": "Textual passwords are still the most widely used user authentication\nmechanism. Due to the close connections between textual passwords and natural\nlanguages, advanced technologies in natural language processing (NLP) and\nmachine learning (ML) could be used to model passwords for different purposes\nsuch as studying human password-creation behaviors and developing more advanced\npassword cracking methods for informing better defence mechanisms. In this\npaper, we propose PassTSL (modeling human-created Passwords through Two-Stage\nLearning), inspired by the popular pretraining-finetuning framework in NLP and\ndeep learning (DL). We report how different pretraining settings affected\nPassTSL and proved its effectiveness by applying it to six large leaked\npassword databases. Experimental results showed that it outperforms five\nstate-of-the-art (SOTA) password cracking methods on password guessing by a\nsignificant margin ranging from 4.11% to 64.69% at the maximum point. Based on\nPassTSL, we also implemented a password strength meter (PSM), and our\nexperiments showed that it was able to estimate password strength more\naccurately, causing fewer unsafe errors (overestimating the password strength)\nthan two other SOTA PSMs when they produce the same rate of safe errors\n(underestimating the password strength): a neural-network based method and\nzxcvbn. Furthermore, we explored multiple finetuning settings, and our\nevaluations showed that, even a small amount of additional training data, e.g.,\nonly 0.1% of the pretrained data, can lead to over 3% improvement in password\nguessing on average. We also proposed a heuristic approach to selecting\nfinetuning passwords based on JS (Jensen-Shannon) divergence and experimental\nresults validated its usefulness. In summary, our contributions demonstrate the\npotential and feasibility of applying advanced NLP and ML methods to password\nmodeling and cracking.",
      "tldr_zh": "本文提出 PassTSL，一种通过两阶段学习（预训练-微调）的方法来建模人类创建的文本密码，借鉴 NLP 和 ML 框架，用于研究密码行为和提升破解技术。实验结果显示，PassTSL 在六个泄露密码数据库上优于五种 SOTA 密码破解方法，密码猜测性能最高提升64.69%。此外，基于 PassTSL 开发的密码强度计 (PSM) 更准确地评估密码强度，减少了不安全错误（高估强度）。研究还探索了微调设置，发现少量额外数据（如 0.1% 的预训练数据）即可平均提高3% 的猜测性能，并提出基于 JS divergence 的启发式策略来优化密码选择。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14145v1",
      "published_date": "2024-07-19 09:23:30 UTC",
      "updated_date": "2024-07-19 09:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:17:54.437334"
    },
    {
      "arxiv_id": "2407.20247v1",
      "title": "How Homogenizing the Channel-wise Magnitude Can Enhance EEG Classification Model?",
      "title_zh": "翻译失败",
      "authors": [
        "Huyen Ngo",
        "Khoi Do",
        "Duong Nguyen",
        "Viet Dung Nguyen",
        "Lan Dang"
      ],
      "abstract": "A significant challenge in the electroencephalogram EEG lies in the fact that\ncurrent data representations involve multiple electrode signals, resulting in\ndata redundancy and dominant lead information. However extensive research\nconducted on EEG classification focuses on designing model architectures\nwithout tackling the underlying issues. Otherwise, there has been a notable gap\nin addressing data preprocessing for EEG, leading to considerable computational\noverhead in Deep Learning (DL) processes. In light of these issues, we propose\na simple yet effective approach for EEG data pre-processing. Our method first\ntransforms the EEG data into an encoded image by an Inverted Channel-wise\nMagnitude Homogenization (ICWMH) to mitigate inter-channel biases. Next, we\napply the edge detection technique on the EEG-encoded image combined with skip\nconnection to emphasize the most significant transitions in the data while\npreserving structural and invariant information. By doing so, we can improve\nthe EEG learning process efficiently without using a huge DL network. Our\nexperimental evaluations reveal that we can significantly improve (i.e., from\n2% to 5%) over current baselines.",
      "tldr_zh": "这篇论文针对 EEG 分类中的数据冗余和主导导信息问题，提出了一种简单有效的预处理方法，以减少 Deep Learning (DL) 过程中的计算开销。方法首先使用 Inverted Channel-wise Magnitude Homogenization (ICWMH) 将 EEG 数据转化为编码图像，缓解通道间偏差；随后结合边缘检测技术与跳跃连接，强调数据中的显著过渡，同时保留结构和不变信息。该方法无需庞大 DL 网络即可提升学习效率，实验结果显示性能比基线模型提高了 2% 到 5%。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20247v1",
      "published_date": "2024-07-19 09:11:56 UTC",
      "updated_date": "2024-07-19 09:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:18:14.749882"
    },
    {
      "arxiv_id": "2408.01438v1",
      "title": "AI for All: Identifying AI incidents Related to Diversity and Inclusion",
      "title_zh": "翻译失败",
      "authors": [
        "Rifat Ara Shams",
        "Didar Zowghi",
        "Muneera Bano"
      ],
      "abstract": "The rapid expansion of Artificial Intelligence (AI) technologies has\nintroduced both significant advancements and challenges, with diversity and\ninclusion (D&I) emerging as a critical concern. Addressing D&I in AI is\nessential to reduce biases and discrimination, enhance fairness, and prevent\nadverse societal impacts. Despite its importance, D&I considerations are often\noverlooked, resulting in incidents marked by built-in biases and ethical\ndilemmas. Analyzing AI incidents through a D&I lens is crucial for identifying\ncauses of biases and developing strategies to mitigate them, ensuring fairer\nand more equitable AI technologies. However, systematic investigations of\nD&I-related AI incidents are scarce. This study addresses these challenges by\nidentifying and understanding D&I issues within AI systems through a manual\nanalysis of AI incident databases (AIID and AIAAIC). The research develops a\ndecision tree to investigate D&I issues tied to AI incidents and populate a\npublic repository of D&I-related AI incidents. The decision tree was validated\nthrough a card sorting exercise and focus group discussions. The research\ndemonstrates that almost half of the analyzed AI incidents are related to D&I,\nwith a notable predominance of racial, gender, and age discrimination. The\ndecision tree and resulting public repository aim to foster further research\nand responsible AI practices, promoting the development of inclusive and\nequitable AI systems.",
      "tldr_zh": "这篇论文探讨了人工智能 (AI) 技术中多样性和包容性 (D&I) 问题，通过分析 AI 事件数据库 (AIID 和 AIAAIC) 来识别与 D&I 相关的偏见和歧视事件。研究者开发了一个 decision tree 来系统调查这些问题，并通过 card sorting 练习和 focus group discussions 进行验证。结果显示，几乎一半的分析事件涉及 D&I 问题，主要以种族、性别和年龄歧视为主。该工作建立了公共仓库，以推动进一步研究和负责任的 AI 实践，促进更公平和包容的 AI 系统发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "25 pages, 9 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.01438v1",
      "published_date": "2024-07-19 08:54:56 UTC",
      "updated_date": "2024-07-19 08:54:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:18:18.556738"
    },
    {
      "arxiv_id": "2407.14120v1",
      "title": "The Cardinality of Identifying Code Sets for Soccer Ball Graph with Application to Remote Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Anna L. D. Latour",
        "Arunabha Sen",
        "Kaustav Basu",
        "Chenyang Zhou",
        "Kuldeep S. Meel"
      ],
      "abstract": "In the context of satellite monitoring of the earth, we can assume that the\nsurface of the earth is divided into a set of regions. We assume that the\nimpact of a big social/environmental event spills into neighboring regions.\nUsing Identifying Code Sets (ICSes), we can deploy sensors in such a way that\nthe region in which an event takes place can be uniquely identified, even with\nfewer sensors than regions. As Earth is almost a sphere, we use a soccer ball\nas a model. We construct a Soccer Ball Graph (SBG), and provide human-oriented,\nanalytical proofs that 1) the SBG has at least 26 ICSes of cardinality ten,\nimplying that there are at least 26 different ways to deploy ten satellites to\nmonitor the Earth and 2) that the cardinality of the minimum Identifying Code\nSet (MICS) for the SBG is at least nine. We then provide a machine-oriented\nformal proof that the cardinality of the MICS for the SBG is in fact ten,\nmeaning that one must deploy at least ten satellites to monitor the Earth in\nthe SBG model. We also provide machine-oriented proof that there are exactly 26\nICSes of cardinality ten for the SBG.",
      "tldr_zh": "本研究探讨了Identifying Code Sets (ICSes)在卫星遥感中的应用，旨在通过部署传感器监控地球表面事件，即使传感器数量少于区域也能唯一识别事件位置。论文使用Soccer Ball Graph (SBG)作为地球球体模型，提供人类导向和机器导向证明，证明SBG至少有26个基数为十的ICSes，并确切有26种方式部署十个卫星。结果显示，SBG的最小Identifying Code Set (MICS)的基数为十，这意味着至少需要十个卫星才能实现有效监控。",
      "categories": [
        "cs.AI",
        "I.2.3"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 5 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2407.14120v1",
      "published_date": "2024-07-19 08:36:44 UTC",
      "updated_date": "2024-07-19 08:36:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:18:39.179914"
    },
    {
      "arxiv_id": "2407.14114v1",
      "title": "A3Rank: Augmentation Alignment Analysis for Prioritizing Overconfident Failing Samples for Deep Learning Models",
      "title_zh": "A3Rank：增强对齐分析，用于优先排序深度学习模型中过度自信的失败样本",
      "authors": [
        "Zhengyuan Wei",
        "Haipeng Wang",
        "Qilin Zhou",
        "W. K. Chan"
      ],
      "abstract": "Sharpening deep learning models by training them with examples close to the\ndecision boundary is a well-known best practice. Nonetheless, these models are\nstill error-prone in producing predictions. In practice, the inference of the\ndeep learning models in many application systems is guarded by a rejector, such\nas a confidence-based rejector, to filter out samples with insufficient\nprediction confidence. Such confidence-based rejectors cannot effectively guard\nagainst failing samples with high confidence. Existing test case prioritization\ntechniques effectively distinguish confusing samples from confident samples to\nidentify failing samples among the confusing ones, yet prioritizing the failing\nones high among many confident ones is challenging. In this paper, we propose\n$A^3$Rank, a novel test case prioritization technique with augmentation\nalignment analysis, to address this problem. $A^3$Rank generates augmented\nversions of each test case and assesses the extent of the prediction result for\nthe test case misaligned with these of the augmented versions and vice versa.\nOur experiment shows that $A^3$Rank can effectively rank failing samples\nescaping from the checking of confidence-based rejectors, which significantly\noutperforms the peer techniques by 163.63\\% in the detection ratio of\ntop-ranked samples. We also provide a framework to construct a detector devoted\nto augmenting these rejectors to defend these failing samples, and our detector\ncan achieve a significantly higher defense success rate.",
      "tldr_zh": "本文提出 A3Rank，一种基于 augmentation alignment analysis 的测试案例优先排序技术，旨在针对深度学习模型中高置信度错误样本（overconfident failing samples）进行有效识别和优先处理。A3Rank 通过为每个测试样本生成增强版本，并评估原始样本与增强版本预测结果的对齐程度，来区分那些逃过 confidence-based rejector 检查的错误样本。实验结果显示，A3Rank 比现有技术提高了 163.63% 的检测比率，并提供了一个框架来构建增强型检测器，从而显著提升防御成功率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14114v1",
      "published_date": "2024-07-19 08:32:10 UTC",
      "updated_date": "2024-07-19 08:32:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:18:41.557717"
    },
    {
      "arxiv_id": "2407.14106v1",
      "title": "TorchGT: A Holistic System for Large-scale Graph Transformer Training",
      "title_zh": "TorchGT：大规模图变换器训练的整体系统",
      "authors": [
        "Meng Zhang",
        "Jie Sun",
        "Qinghao Hu",
        "Peng Sun",
        "Zeke Wang",
        "Yonggang Wen",
        "Tianwei Zhang"
      ],
      "abstract": "Graph Transformer is a new architecture that surpasses GNNs in graph\nlearning. While there emerge inspiring algorithm advancements, their practical\nadoption is still limited, particularly on real-world graphs involving up to\nmillions of nodes. We observe existing graph transformers fail on large-scale\ngraphs mainly due to heavy computation, limited scalability and inferior model\nquality. Motivated by these observations, we propose TorchGT, the first\nefficient, scalable, and accurate graph transformer training system. TorchGT\noptimizes training at different levels. At algorithm level, by harnessing the\ngraph sparsity, TorchGT introduces a Dual-interleaved Attention which is\ncomputation-efficient and accuracy-maintained. At runtime level, TorchGT scales\ntraining across workers with a communication-light Cluster-aware Graph\nParallelism. At kernel level, an Elastic Computation Reformation further\noptimizes the computation by reducing memory access latency in a dynamic way.\nExtensive experiments demonstrate that TorchGT boosts training by up to 62.7x\nand supports graph sequence lengths of up to 1M.",
      "tldr_zh": "该研究针对Graph Transformer在大型图学习中的计算密集、扩展性差和模型质量问题，提出TorchGT，这是一个高效、可扩展且准确的训练系统。TorchGT在算法层面引入Dual-interleaved Attention，利用图的稀疏性来优化计算效率，同时保持准确性；在运行时层面，通过Cluster-aware Graph Parallelism实现跨工作器的轻量通信扩展；在内核层面，Elastic Computation Reformation动态减少内存访问延迟。实验结果显示，TorchGT可以将训练速度提升高达62.7倍，并支持高达1M的图序列长度，为大规模Graph Transformer训练提供了实用解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "Proceedings of the International Conference for High Performance\n  Computing, Networking, Storage and Analysis (SC), 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14106v1",
      "published_date": "2024-07-19 08:21:42 UTC",
      "updated_date": "2024-07-19 08:21:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:18:52.352480"
    },
    {
      "arxiv_id": "2407.14100v1",
      "title": "ParamsDrag: Interactive Parameter Space Exploration via Image-Space Dragging",
      "title_zh": "ParamsDrag：通过图像空间拖拽进行交互式参数空间探索",
      "authors": [
        "Guan Li",
        "Yang Liu",
        "Guihua Shan",
        "Shiyu Cheng",
        "Weiqun Cao",
        "Junpeng Wang",
        "Ko-Chih Wang"
      ],
      "abstract": "Numerical simulation serves as a cornerstone in scientific modeling, yet the\nprocess of fine-tuning simulation parameters poses significant challenges.\nConventionally, parameter adjustment relies on extensive numerical simulations,\ndata analysis, and expert insights, resulting in substantial computational\ncosts and low efficiency. The emergence of deep learning in recent years has\nprovided promising avenues for more efficient exploration of parameter spaces.\nHowever, existing approaches often lack intuitive methods for precise parameter\nadjustment and optimization. To tackle these challenges, we introduce\nParamsDrag, a model that facilitates parameter space exploration through direct\ninteraction with visualizations. Inspired by DragGAN, our ParamsDrag model\noperates in three steps. First, the generative component of ParamsDrag\ngenerates visualizations based on the input simulation parameters. Second, by\ndirectly dragging structure-related features in the visualizations, users can\nintuitively understand the controlling effect of different parameters. Third,\nwith the understanding from the earlier step, users can steer ParamsDrag to\nproduce dynamic visual outcomes. Through experiments conducted on real-world\nsimulations and comparisons with state-of-the-art deep learning-based\napproaches, we demonstrate the efficacy of our solution.",
      "tldr_zh": "本研究提出ParamsDrag模型，通过图像空间拖拽实现数值模拟参数空间的交互式探索，解决了传统方法依赖大量模拟和数据分析导致的低效率问题。受DragGAN启发，ParamsDrag采用三步流程：首先基于输入参数生成可视化；其次，用户直接拖拽可视化中的结构相关特征，以直观理解参数的影响；最后，用户引导模型产生动态视觉结果。实验结果显示，该模型在真实模拟场景中比现有深度学习方法更有效，提升了参数调整的精确性和用户交互性。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "To be published in Proc. IEEE VIS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14100v1",
      "published_date": "2024-07-19 08:12:41 UTC",
      "updated_date": "2024-07-19 08:12:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:19:03.673558"
    },
    {
      "arxiv_id": "2407.14097v2",
      "title": "Forward-Forward Learning achieves Highly Selective Latent Representations for Out-of-Distribution Detection in Fully Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Erik B. Terres-Escudero",
        "Javier Del Ser",
        "Aitor Martínez-Seras",
        "Pablo Garcia-Bringas"
      ],
      "abstract": "In recent years, Artificial Intelligence (AI) models have achieved remarkable\nsuccess across various domains, yet challenges persist in two critical areas:\nensuring robustness against uncertain inputs and drastically increasing model\nefficiency during training and inference. Spiking Neural Networks (SNNs),\ninspired by biological systems, offer a promising avenue for overcoming these\nlimitations. By operating in an event-driven manner, SNNs achieve low energy\nconsumption and can naturally implement biological methods known for their high\nnoise tolerance. In this work, we explore the potential of the spiking\nForward-Forward Algorithm (FFA) to address these challenges, leveraging its\nrepresentational properties for both Out-of-Distribution (OoD) detection and\ninterpretability. To achieve this, we exploit the sparse and highly specialized\nneural latent space of FF networks to estimate the likelihood of a sample\nbelonging to the training distribution. Additionally, we propose a novel,\ngradient-free attribution method to detect features that drive a sample away\nfrom class distributions, addressing the challenges posed by the lack of\ngradients in most visual interpretability methods for spiking models. We\nevaluate our OoD detection algorithm on well-known image datasets (e.g.,\nOmniglot, Not-MNIST, CIFAR10), outperforming previous methods proposed in the\nrecent literature for OoD detection in spiking networks. Furthermore, our\nattribution method precisely identifies salient OoD features, such as artifacts\nor missing regions, hence providing a visual explanatory interface for the user\nto understand why unknown inputs are identified as such by the proposed method.",
      "tldr_zh": "该研究探讨了spiking Forward-Forward Algorithm (FFA)在Fully Spiking Neural Networks (SNNs)中的应用，旨在提升模型对不确定输入的鲁棒性和训练效率，同时实现Out-of-Distribution (OoD)检测和可解释性。通过利用FFA的稀疏高选择性神经潜在空间，研究者提出了一种基于潜在空间的OoD检测算法，以及一种新型无梯度归因方法，用于识别使样本偏离类分布的关键特征，如伪像或缺失区域。在Omniglot、Not-MNIST和CIFAR10等图像数据集上的实验中，该方法优于现有SNNs OoD检测技术，并提供视觉解释，帮助用户理解未知输入的检测原因。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14097v2",
      "published_date": "2024-07-19 08:08:17 UTC",
      "updated_date": "2025-02-19 12:14:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:19:17.987979"
    },
    {
      "arxiv_id": "2407.14095v2",
      "title": "People use fast, goal-directed simulation to reason about novel games",
      "title_zh": "翻译失败",
      "authors": [
        "Cedegao E. Zhang",
        "Katherine M. Collins",
        "Lionel Wong",
        "Mauricio Barba",
        "Adrian Weller",
        "Joshua B. Tenenbaum"
      ],
      "abstract": "People can evaluate features of problems and their potential solutions well\nbefore we can effectively solve them. When considering a game we have never\nplayed, for instance, we might infer whether it is likely to be challenging,\nfair, or fun simply from hearing the game rules, prior to deciding whether to\ninvest time in learning the game or trying to play it well. Many studies of\ngame play have focused on optimality and expertise, characterizing how people\nand computational models play based on moderate to extensive search and after\nplaying a game dozens (if not thousands or millions) of times. Here, we study\nhow people reason about a range of simple but novel Connect-N style board\ngames. We ask people to judge how fair and how fun the games are from very\nlittle experience: just thinking about the game for a minute or so, before they\nhave ever actually played with anyone else, and we propose a resource-limited\nmodel that captures their judgments using only a small number of partial game\nsimulations and almost no look-ahead search.",
      "tldr_zh": "本研究探讨人们如何通过快速、目标导向的 simulation 来评估新颖游戏的特性，例如挑战性、公平性和趣味性，而无需实际玩耍。研究者让参与者仅通过短暂思考（约一分钟）判断简单 Connect-N style board games 的公平性和趣味性，并提出一个 resource-limited model，该模型仅使用少量部分游戏模拟和几乎无前瞻搜索来捕捉这些判断。与以往专注于最优性和专家玩法的实验不同，该研究揭示了人们在有限资源下进行高效推理的能力，为理解人类决策过程提供了新见解。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.GT",
      "comment": "Accepted at CogSci 2024 as a talk",
      "pdf_url": "http://arxiv.org/pdf/2407.14095v2",
      "published_date": "2024-07-19 07:59:04 UTC",
      "updated_date": "2025-02-07 08:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:19:27.663658"
    },
    {
      "arxiv_id": "2407.14092v2",
      "title": "Integrated Push-and-Pull Update Model for Goal-Oriented Effective Communication",
      "title_zh": "针对目标导向有效通信的集成推拉更新模型",
      "authors": [
        "Pouya Agheli",
        "Nikolaos Pappas",
        "Petar Popovski",
        "Marios Kountouris"
      ],
      "abstract": "This paper studies decision-making for goal-oriented effective communication.\nWe consider an end-to-end status update system where a sensing agent (SA)\nobserves a source, generates and transmits updates to an actuation agent (AA),\nwhile the AA takes actions to accomplish a goal at the endpoint. We integrate\nthe push- and pull-based update communication models to obtain a push-and-pull\nmodel, which allows the transmission controller at the SA to decide to push an\nupdate to the AA and the query controller at the AA to pull updates by raising\nqueries at specific time instances. To gauge effectiveness, we utilize a grade\nof effectiveness (GoE) metric incorporating updates' freshness, usefulness, and\ntimeliness of actions as qualitative attributes. We then derive effect-aware\npolicies to maximize the expected discounted sum of updates' effectiveness\nsubject to induced costs. The effect-aware policy at the SA considers the\npotential effectiveness of communicated updates at the endpoint, while at the\nAA, it accounts for the probabilistic evolution of the source and importance of\ngenerated updates. Our results show the proposed push-and-pull model\noutperforms models solely based on push- or pull-based updates both in terms of\nefficiency and effectiveness. Additionally, using effect-aware policies at both\nagents enhances effectiveness compared to periodic and/or probabilistic\neffect-agnostic policies at either or both agents.",
      "tldr_zh": "本文提出了一种整合 push-and-pull 更新模型，用于目标导向的有效通信系统，其中感知代理 (SA) 主动推送更新，而执行代理 (AA) 通过查询拉取更新，以优化端到端任务决策。模型采用 Grade of Effectiveness (GoE) 指标评估更新的新鲜度、有用性和行动及时性，并推导了 effect-aware 策略来最大化预期的折扣和有效性总和，同时考虑成本。实验结果表明，该 push-and-pull 模型在效率和有效性上优于纯 push 或 pull 模型，且使用 effect-aware 策略比周期性或概率性策略显著提升性能。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.MA",
        "cs.NI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Submitted for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2407.14092v2",
      "published_date": "2024-07-19 07:57:31 UTC",
      "updated_date": "2025-01-15 15:44:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:19:41.032812"
    },
    {
      "arxiv_id": "2407.15873v1",
      "title": "CRMSP: A Semi-supervised Approach for Key Information Extraction with Class-Rebalancing and Merged Semantic Pseudo-Labeling",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Zhang",
        "Yonghong Song",
        "Pengcheng Guo",
        "Yangyang Hui"
      ],
      "abstract": "There is a growing demand in the field of KIE (Key Information Extraction) to\napply semi-supervised learning to save manpower and costs, as training document\ndata using fully-supervised methods requires labor-intensive manual annotation.\nThe main challenges of applying SSL in the KIE are (1) underestimation of the\nconfidence of tail classes in the long-tailed distribution and (2) difficulty\nin achieving intra-class compactness and inter-class separability of tail\nfeatures. To address these challenges, we propose a novel semi-supervised\napproach for KIE with Class-Rebalancing and Merged Semantic Pseudo-Labeling\n(CRMSP). Firstly, the Class-Rebalancing Pseudo-Labeling (CRP) module introduces\na reweighting factor to rebalance pseudo-labels, increasing attention to tail\nclasses. Secondly, we propose the Merged Semantic Pseudo-Labeling (MSP) module\nto cluster tail features of unlabeled data by assigning samples to Merged\nPrototypes (MP). Additionally, we designed a new contrastive loss specifically\nfor MSP. Extensive experimental results on three well-known benchmarks\ndemonstrate that CRMSP achieves state-of-the-art performance. Remarkably, CRMSP\nachieves 3.24% f1-score improvement over state-of-the-art on the CORD.",
      "tldr_zh": "该论文针对关键信息提取（KIE）领域的半监督学习（SSL）需求，提出了一种新方法 CRMSP，以解决长尾分布中尾类别的置信度低估和尾特征的类内紧凑性与类间可分性问题。CRMSP 包括 Class-Rebalancing Pseudo-Labeling (CRP) 模块，通过引入再加权因子来平衡伪标签并关注尾类别，以及 Merged Semantic Pseudo-Labeling (MSP) 模块，该模块通过分配样本到 Merged Prototypes (MP) 并设计特定对比损失来聚类尾特征。在三个基准数据集上的实验表明，CRMSP 取得了最先进性能，尤其在 CORD 数据集上 F1-score 提高了 3.24%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15873v1",
      "published_date": "2024-07-19 07:41:26 UTC",
      "updated_date": "2024-07-19 07:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:19:53.575727"
    },
    {
      "arxiv_id": "2407.14081v2",
      "title": "DisenSemi: Semi-supervised Graph Classification via Disentangled Representation Learning",
      "title_zh": "DisenSemi：通过解缠表示学习进行半监督图分类",
      "authors": [
        "Yifan Wang",
        "Xiao Luo",
        "Chong Chen",
        "Xian-Sheng Hua",
        "Ming Zhang",
        "Wei Ju"
      ],
      "abstract": "Graph classification is a critical task in numerous multimedia applications,\nwhere graphs are employed to represent diverse types of multimedia data,\nincluding images, videos, and social networks. Nevertheless, in real-world\nscenarios, labeled graph data can be limited or scarce. To address this issue,\nwe focus on the problem of semi-supervised graph classification, which involves\nboth supervised and unsupervised models learning from labeled and unlabeled\ndata. In contrast to recent approaches that transfer the entire knowledge from\nthe unsupervised model to the supervised one, we argue that an effective\ntransfer should only retain the relevant semantics that align well with the\nsupervised task. In this paper, we propose a novel framework named DisenSemi,\nwhich learns disentangled representation for semi-supervised graph\nclassification. Specifically, a disentangled graph encoder is proposed to\ngenerate factor-wise graph representations for both supervised and unsupervised\nmodels. Then we train two models via supervised objective and mutual\ninformation (MI)-based constraints respectively. To ensure the meaningful\ntransfer of knowledge from the unsupervised encoder to the supervised one, we\nfurther define an MI-based disentangled consistency regularization between two\nmodels and identify the corresponding rationale that aligns well with the\ncurrent graph classification task. Experimental results on a range of publicly\naccessible datasets reveal the effectiveness of our DisenSemi.",
      "tldr_zh": "这篇论文针对图分类（graph classification）中标记数据稀缺的问题，提出了一种名为DisenSemi的框架，通过分离表示学习（disentangled representation learning）实现半监督图分类（semi-supervised graph classification）。框架的核心是使用分离图编码器（disentangled graph encoder）生成因子级图表示（factor-wise graph representations），并分别通过监督目标和互信息（MI-based constraints）训练监督和无监督模型。作者引入了基于MI的分离一致性正则化（MI-based disentangled consistency regularization），确保仅转移与任务相关的知识，从而提高模型的有效性。实验结果显示，DisenSemi在多个公开数据集上表现出色，验证了其在多媒体数据应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.14081v2",
      "published_date": "2024-07-19 07:31:32 UTC",
      "updated_date": "2024-08-09 08:23:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:20:06.014858"
    },
    {
      "arxiv_id": "2407.14076v2",
      "title": "Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field",
      "title_zh": "领域特定的语言模型预训练：医疗领域的比较研究",
      "authors": [
        "Tobias Kerner"
      ],
      "abstract": "There are many cases where LLMs are used for specific tasks in a single\ndomain. These usually require less general, but more domain-specific knowledge.\nHighly capable, general-purpose state-of-the-art language models like GPT-4 or\nClaude-3-opus can often be used for such tasks, but they are very large and\ncannot be run locally, even if they were not proprietary. This can be a problem\nwhen working with sensitive data. This paper focuses on domain-specific and\nmixed-domain pretraining as potentially more efficient methods than general\npretraining for specialized language models. We will take a look at work\nrelated to domain-specific pretraining, specifically in the medical area, and\ncompare benchmark results of specialized language models to general-purpose\nlanguage models.",
      "tldr_zh": "本研究比较了领域特定预训练和通用预训练方法在医疗领域的应用，旨在为处理敏感数据提供更高效的语言模型（LLMs）解决方案。与大型通用模型如GPT-4或Claude-3-opus相比，这些方法允许本地运行并减少了隐私风险。论文回顾了相关工作，特别是医疗领域的案例，并通过基准测试发现，领域特定和混合领域预训练的模型在专业任务上表现出色，证明了其作为高效替代方案的优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.6; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14076v2",
      "published_date": "2024-07-19 07:12:43 UTC",
      "updated_date": "2024-07-28 07:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:20:16.013817"
    },
    {
      "arxiv_id": "2408.03327v1",
      "title": "Reconstruction of the shape of irregular rough particles from their interferometric images using a convolutional neural network",
      "title_zh": "翻译失败",
      "authors": [
        "Alexis Abad",
        "Alexandre Poux",
        "Alexis Boulet",
        "Marc Brunel"
      ],
      "abstract": "We have developed a convolutional neural network (CNN) to reconstruct the\nshape of irregular rough particles from their interferometric images. The CNN\nis based on a UNET architecture with residual block modules. The database has\nbeen constructed using the experimental patterns generated by perfectly known\npseudo-particles programmed on a Digital Micromirror Device (DMD) and under\nlaser illumination. The CNN has been trained on a basis of 18000 experimental\ninterferometric images using the AUSTRAL super computer (at CRIANN in\nNormandy). The CNN is tested in the case of centrosymmetric (stick, cross,\ndendrite) and non-centrosymmetric (like T, Y or L) particles. The size and the\n3D orientation of the programmed particles are random. The different shapes are\nreconstructed by the CNN with good accuracy. Using three angles of view, the 3D\nreconstruction of particles from three reconstructed faces can be further done.",
      "tldr_zh": "本研究开发了一种基于 UNET 架构的 convolutional neural network (CNN)，用于从干涉图像中重建不规则粗糙粒子的形状。CNN 利用残差块模块，并通过 Digital Micromirror Device (DMD) 和激光照明生成的实验数据库进行训练，该数据库包含 18000 个图像，并在 AUSTRAL 超级计算机上完成训练。实验测试显示，CNN 能准确重建中心对称（如棒、十字、树枝状）和非中心对称（如 T、Y 或 L）粒子的形状，即使粒子尺寸和 3D 取向随机变化；此外，使用三个视角可进一步实现粒子的 3D 重建。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03327v1",
      "published_date": "2024-07-19 07:03:36 UTC",
      "updated_date": "2024-07-19 07:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:20:28.597116"
    },
    {
      "arxiv_id": "2407.14073v3",
      "title": "LoAS: Fully Temporal-Parallel Dataflow for Dual-Sparse Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ruokai Yin",
        "Youngeun Kim",
        "Di Wu",
        "Priyadarshini Panda"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have gained significant research attention in\nthe last decade due to their potential to drive resource-constrained edge\ndevices. Though existing SNN accelerators offer high efficiency in processing\nsparse spikes with dense weights, opportunities are less explored in SNNs with\nsparse weights, i.e., dual-sparsity. In this work, we study the acceleration of\ndual-sparse SNNs, focusing on their core operation, sparse-matrix-sparse-matrix\nmultiplication (spMspM). We observe that naively running a dual-sparse SNN on\nexisting spMspM accelerators designed for dual-sparse Artificial Neural\nNetworks (ANNs) exhibits sub-optimal efficiency. The main challenge is that\nprocessing timesteps, a natural property of SNNs, introduces an extra loop to\nANN spMspM, leading to longer latency and more memory traffic. To address the\nproblem, we propose a fully temporal-parallel (FTP) dataflow, which minimizes\nboth data movement across timesteps and the end-to-end latency of dual-sparse\nSNNs. To maximize the efficiency of FTP dataflow, we propose an FTP-friendly\nspike compression mechanism that efficiently compresses single-bit spikes and\nensures contiguous memory access. We further propose an FTP-friendly inner-join\ncircuit that can lower the cost of the expensive prefix-sum circuits with\nalmost no throughput penalty. All the above techniques for FTP dataflow are\nencapsulated in LoAS, a Low-latency inference Accelerator for dual-sparse SNNs.\nWith FTP dataflow, compression, and inner-join, running dual-sparse SNN\nworkloads on LoAS demonstrates significant speedup (up to $8.51\\times$) and\nenergy reduction (up to $3.68\\times$) compared to running it on prior\ndual-sparse accelerators.",
      "tldr_zh": "这篇论文针对双稀疏 Spiking Neural Networks (SNNs) 的加速问题，提出了一种 Fully Temporal-Parallel (FTP) dataflow 框架，以最小化时间步间的数据移动和端到端延迟，从而提升双稀疏 SNNs 的效率。该框架的核心操作是 sparse-matrix-sparse-matrix multiplication (spMspM)，并引入 FTP-friendly spike compression 机制和 inner-join circuit 来优化单比特 spikes 的压缩和内存访问，同时降低计算成本。这些创新技术被整合进 LoAS 加速器中，实验结果显示 LoAS 在双稀疏 SNN 工作负载上比现有加速器实现高达 8.51 倍的速度提升和 3.68 倍的能量节省。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted to MICRO 2024. Will update with the camera-ready version\n  once ready. (Github: https://github.com/RuokaiYin/LoAS)",
      "pdf_url": "http://arxiv.org/pdf/2407.14073v3",
      "published_date": "2024-07-19 07:02:26 UTC",
      "updated_date": "2024-09-01 13:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:20:42.016658"
    },
    {
      "arxiv_id": "2407.14057v1",
      "title": "LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Qichen Fu",
        "Minsik Cho",
        "Thomas Merth",
        "Sachin Mehta",
        "Mohammad Rastegari",
        "Mahyar Najibi"
      ],
      "abstract": "The inference of transformer-based large language models consists of two\nsequential stages: 1) a prefilling stage to compute the KV cache of prompts and\ngenerate the first token, and 2) a decoding stage to generate subsequent\ntokens. For long prompts, the KV cache must be computed for all tokens during\nthe prefilling stage, which can significantly increase the time needed to\ngenerate the first token. Consequently, the prefilling stage may become a\nbottleneck in the generation process. An open question remains whether all\nprompt tokens are essential for generating the first token. To answer this, we\nintroduce a novel method, LazyLLM, that selectively computes the KV for tokens\nimportant for the next token prediction in both the prefilling and decoding\nstages. Contrary to static pruning approaches that prune the prompt at once,\nLazyLLM allows language models to dynamically select different subsets of\ntokens from the context in different generation steps, even though they might\nbe pruned in previous steps. Extensive experiments on standard datasets across\nvarious tasks demonstrate that LazyLLM is a generic method that can be\nseamlessly integrated with existing language models to significantly accelerate\nthe generation without fine-tuning. For instance, in the multi-document\nquestion-answering task, LazyLLM accelerates the prefilling stage of the LLama\n2 7B model by 2.34x while maintaining accuracy.",
      "tldr_zh": "这篇论文提出 LazyLLM，一种动态 token 修剪方法，用于优化长上下文大型语言模型(LLM)的推理过程，通过在预填充和解码阶段选择性地计算重要 token 的 KV cache，避免不必要的计算。不同于静态修剪，LazyLLM 允许模型在不同生成步骤动态选择 token 子集，从而提高灵活性和效率。实验在各种任务上验证了其有效性，例如在多文档问答任务中，LazyLLM 使 Llama 2 7B 模型的预填充阶段加速 2.34 倍，同时保持准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14057v1",
      "published_date": "2024-07-19 06:34:45 UTC",
      "updated_date": "2024-07-19 06:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:20:52.720919"
    },
    {
      "arxiv_id": "2407.14055v2",
      "title": "Quantum Hamiltonian Embedding of Images for Data Reuploading Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Peiyong Wang",
        "Casey R. Myers",
        "Lloyd C. L. Hollenberg",
        "Udaya Parampalli"
      ],
      "abstract": "When applying quantum computing to machine learning tasks, one of the first\nconsiderations is the design of the quantum machine learning model itself.\nConventionally, the design of quantum machine learning algorithms relies on the\n``quantisation\" of classical learning algorithms, such as using quantum linear\nalgebra to implement important subroutines of classical algorithms, if not the\nentire algorithm, seeking to achieve quantum advantage through possible\nrun-time accelerations brought by quantum computing. However, recent research\nhas started questioning whether quantum advantage via speedup is the right goal\nfor quantum machine learning [1]. Research also has been undertaken to exploit\nproperties that are unique to quantum systems, such as quantum contextuality,\nto better design quantum machine learning models [2]. In this paper, we take an\nalternative approach by incorporating the heuristics and empirical evidences\nfrom the design of classical deep learning algorithms to the design of quantum\nneural networks. We first construct a model based on the data reuploading\ncircuit [3] with the quantum Hamiltonian data embedding unitary [4]. Through\nnumerical experiments on images datasets, including the famous MNIST and\nFashionMNIST datasets, we demonstrate that our model outperforms the quantum\nconvolutional neural network (QCNN)[5] by a large margin (up to over 40% on\nMNIST test set). Based on the model design process and numerical results, we\nthen laid out six principles for designing quantum machine learning models,\nespecially quantum neural networks.",
      "tldr_zh": "这篇论文提出了一种将图像嵌入量子Hamiltonian的新方法，用于数据重上传分类器（Data Reuploading Classifiers），旨在借鉴经典深度学习算法的启发来设计量子神经网络模型，而不是依赖传统量子化方法追求速度优势。研究者构建了基于数据重上传电路（data reuploading circuit）和量子Hamiltonian数据嵌入酉变换（quantum Hamiltonian data embedding unitary）的模型，并在MNIST和FashionMNIST数据集上进行数值实验，结果显示该模型比量子卷积神经网络（QCNN）性能提升显著，在MNIST测试集上超过40%。最终，论文基于模型设计过程和实验结果，总结了六条设计量子机器学习模型，特别是量子神经网络的原则。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "11 figures, 31 pages. Code available on\n  https://github.com/peiyong-addwater/HamEmbedding. Author affiliation updated\n  for v2. Acknowledgements and funding information added for v2",
      "pdf_url": "http://arxiv.org/pdf/2407.14055v2",
      "published_date": "2024-07-19 06:31:22 UTC",
      "updated_date": "2024-08-01 02:19:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:21:05.036117"
    },
    {
      "arxiv_id": "2407.14568v1",
      "title": "SQLfuse: Enhancing Text-to-SQL Performance through Comprehensive LLM Synergy",
      "title_zh": "翻译失败",
      "authors": [
        "Tingkai Zhang",
        "Chaoyu Chen",
        "Cong Liao",
        "Jun Wang",
        "Xudong Zhao",
        "Hang Yu",
        "Jianchao Wang",
        "Jianguo Li",
        "Wenhui Shi"
      ],
      "abstract": "Text-to-SQL conversion is a critical innovation, simplifying the transition\nfrom complex SQL to intuitive natural language queries, especially significant\ngiven SQL's prevalence in the job market across various roles. The rise of\nLarge Language Models (LLMs) like GPT-3.5 and GPT-4 has greatly advanced this\nfield, offering improved natural language understanding and the ability to\ngenerate nuanced SQL statements. However, the potential of open-source LLMs in\nText-to-SQL applications remains underexplored, with many frameworks failing to\nleverage their full capabilities, particularly in handling complex database\nqueries and incorporating feedback for iterative refinement. Addressing these\nlimitations, this paper introduces SQLfuse, a robust system integrating\nopen-source LLMs with a suite of tools to enhance Text-to-SQL translation's\naccuracy and usability. SQLfuse features four modules: schema mining, schema\nlinking, SQL generation, and a SQL critic module, to not only generate but also\ncontinuously enhance SQL query quality. Demonstrated by its leading performance\non the Spider Leaderboard and deployment by Ant Group, SQLfuse showcases the\npractical merits of open-source LLMs in diverse business contexts.",
      "tldr_zh": "这篇论文介绍了 SQLfuse 系统，通过全面整合开源大型语言模型 (LLMs) 来提升 Text-to-SQL 性能，解决复杂数据库查询和反馈迭代的挑战。SQLfuse 包含四个关键模块：schema mining、schema linking、SQL generation 和 SQL critic module，这些模块协同工作以生成并持续优化 SQL 查询的准确性和可用性。实验结果显示，SQLfuse 在 Spider Leaderboard 上表现出领先性能，并已在 Ant Group 实际部署，证明了开源 LLMs 在商业应用中的实用价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14568v1",
      "published_date": "2024-07-19 06:01:57 UTC",
      "updated_date": "2024-07-19 06:01:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:21:21.050771"
    },
    {
      "arxiv_id": "2407.14047v1",
      "title": "OCTrack: Benchmarking the Open-Corpus Multi-Object Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Zekun Qian",
        "Ruize Han",
        "Wei Feng",
        "Junhui Hou",
        "Linqi Song",
        "Song Wang"
      ],
      "abstract": "We study a novel yet practical problem of open-corpus multi-object tracking\n(OCMOT), which extends the MOT into localizing, associating, and recognizing\ngeneric-category objects of both seen (base) and unseen (novel) classes, but\nwithout the category text list as prompt. To study this problem, the top\npriority is to build a benchmark. In this work, we build OCTrackB, a\nlarge-scale and comprehensive benchmark, to provide a standard evaluation\nplatform for the OCMOT problem. Compared to previous datasets, OCTrackB has\nmore abundant and balanced base/novel classes and the corresponding samples for\nevaluation with less bias. We also propose a new multi-granularity recognition\nmetric to better evaluate the generative object recognition in OCMOT. By\nconducting the extensive benchmark evaluation, we report and analyze the\nresults of various state-of-the-art methods, which demonstrate the rationale of\nOCMOT, as well as the usefulness and advantages of OCTrackB.",
      "tldr_zh": "这篇论文引入了 open-corpus multi-object tracking (OCMOT)，一种扩展 multi-object tracking (MOT) 的新问题，能够定位、关联和识别已见 (base) 和未见 (novel) 类别的泛化对象，而无需类别文本列表作为提示。作者构建了 OCTrackB，这是一个大规模、全面的基准数据集，包含更多平衡的 base/novel 类和样本，以减少评估偏差，并提出了一种新的 multi-granularity recognition metric 来更好地评估 OCMOT 中的生成对象识别。通过广泛的基准评估，他们报告并分析了各种最先进方法的性能，证明了 OCMOT 的合理性和 OCTrackB 的有用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14047v1",
      "published_date": "2024-07-19 05:58:01 UTC",
      "updated_date": "2024-07-19 05:58:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:21:30.970218"
    },
    {
      "arxiv_id": "2407.14044v2",
      "title": "ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?",
      "title_zh": "ECCO: 能否在不牺牲功能正确性的前提下改善模型生成的代码效率？",
      "authors": [
        "Siddhant Waghjale",
        "Vishruth Veerendranath",
        "Zora Zhiruo Wang",
        "Daniel Fried"
      ],
      "abstract": "Although large language models (LLMs) have been largely successful in\ngenerating functionally correct programs, conditioning models to produce\nefficient solutions while ensuring correctness remains a challenge. Further,\nunreliability in benchmarking code efficiency is a hurdle across varying\nhardware specifications for popular interpreted languages such as Python. In\nthis paper, we present ECCO, a reproducible benchmark for evaluating program\nefficiency via two paradigms: natural language (NL) based code generation and\nhistory-based code editing. On ECCO, we adapt and thoroughly investigate the\nthree most promising existing LLM-based approaches: in-context learning,\niterative refinement with execution or NL feedback, and fine-tuning conditioned\non execution and editing history. While most methods degrade functional\ncorrectness and moderately increase program efficiency, we find that adding\nexecution information often helps maintain functional correctness, and NL\nfeedback enhances more on efficiency. We release our benchmark to support\nfuture work on LLM-based generation of efficient code.",
      "tldr_zh": "这篇论文介绍了 ECCO，一个可重现的基准，用于评估大型语言模型(LLMs)在生成代码时是否能提高程序效率，同时不牺牲功能正确性。ECCO 通过自然语言(NL) 基于代码生成和历史基于代码编辑两种范式，调查了 in-context learning、迭代优化（使用执行或 NL 反馈）以及基于执行和编辑历史的 fine-tuning 等方法。研究发现，大多数方法会略微提升效率但可能降低功能正确性，而添加执行信息有助于维持正确性，NL 反馈则更有效地改善效率。作者发布了这一基准，以支持未来 LLM 生成高效代码的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024; Project Page: https://ecco-code-eff.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2407.14044v2",
      "published_date": "2024-07-19 05:47:40 UTC",
      "updated_date": "2024-10-09 22:20:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:21:41.927831"
    },
    {
      "arxiv_id": "2407.14567v2",
      "title": "Integrating Artificial Intelligence into Operating Systems: A Comprehensive Survey on Techniques, Applications, and Future Directions",
      "title_zh": "将人工智能集成到操作系统：技术、应用和未来方向的全面调查",
      "authors": [
        "Yifan Zhang",
        "Xinkui Zhao",
        "Ziying Li",
        "Jianwei Yin",
        "Lufei Zhang",
        "Zuoning Chen"
      ],
      "abstract": "In the era of the Internet of Everything, operating systems (OSs) face\nunprecedented challenges posed by an evolving application landscape and\nincreasingly heterogeneous hardware ecosystems. This shift toward increasingly\ndynamic and unpredictable operational contexts presents significant challenges\nfor both OS developers and users. Against this backdrop, the fusion of\nArtificial Intelligence (AI) with Operating Systems emerges as a critical\nfrontier for innovation. This survey delves into the intricate interplay\nbetween AI and OSs, illustrating how existing OS mechanisms combined with AI\nsignificantly elevate the performance, security, and efficiency of modern\noperating systems. We investigate a range of AI methodologies applied to\noptimize core OS functionalities and clarify the correlation to related\nstudies. Our analysis touches on the existing hurdles and prospective avenues\nin this interdisciplinary domain, underscoring the imperative for robust and\nseamless integration of AI capabilities into OS architectures.\n  Through an examination of illustrative case studies and cutting-edge\ndevelopments, we offer a thorough review of the current status of AI-OS\nintegration, accentuating its pivotal role in steering the evolution of\nadvanced computing paradigms. We also envision the promising prospects of\nIntelligent Operating Systems, debating how groundbreaking OS designs will\nusher in novel possibilities and highlight the central role that AI will assume\nin propelling these next-generation systems forward. This forward-thinking\noutlook illuminates the profound influence of AI on the foundational elements\nof computing, heralding the advent of a new epoch characterized by intelligent,\nself-adapting, and highly adaptive software ecosystems.",
      "tldr_zh": "这篇调查论文探讨了人工智能（AI）与操作系统（OSs）的整合，针对动态应用环境和异构硬件生态的挑战，展示了AI如何提升OS的性能、安全性和效率。作者分析了多种AI方法来优化OS核心功能，并通过相关研究和案例研究阐明了其应用价值，同时指出了现有障碍如整合复杂性。展望未来，该论文强调AI将在下一代智能OS的设计中发挥关键作用，推动自适应软件生态的发展。",
      "categories": [
        "cs.OS",
        "cs.AI"
      ],
      "primary_category": "cs.OS",
      "comment": "47 pages,12 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14567v2",
      "published_date": "2024-07-19 05:29:34 UTC",
      "updated_date": "2024-12-22 13:04:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:21:52.914716"
    },
    {
      "arxiv_id": "2407.14030v1",
      "title": "HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research",
      "title_zh": "HeCiX：整合知识图谱和大语言模型用于生物医学研究",
      "authors": [
        "Prerana Sanjay Kulkarni",
        "Muskaan Jain",
        "Disha Sheshanarayana",
        "Srinivasan Parthiban"
      ],
      "abstract": "Despite advancements in drug development strategies, 90% of clinical trials\nfail. This suggests overlooked aspects in target validation and drug\noptimization. In order to address this, we introduce HeCiX-KG,\nHetionet-Clinicaltrials neXus Knowledge Graph, a novel fusion of data from\nClinicalTrials.gov and Hetionet in a single knowledge graph. HeCiX-KG combines\ndata on previously conducted clinical trials from ClinicalTrials.gov, and\ndomain expertise on diseases and genes from Hetionet. This offers a thorough\nresource for clinical researchers. Further, we introduce HeCiX, a system that\nuses LangChain to integrate HeCiX-KG with GPT-4, and increase its usability.\nHeCiX shows high performance during evaluation against a range of clinically\nrelevant issues, proving this model to be promising for enhancing the\neffectiveness of clinical research. Thus, this approach provides a more\nholistic view of clinical trials and existing biological data.",
      "tldr_zh": "该研究针对药物开发中90%的临床试验失败问题，引入了HeCiX-KG，这是一个融合ClinicalTrials.gov（临床试验数据）和Hetionet（疾病与基因领域知识）的知识图谱，提供全面的资源支持临床研究。HeCiX系统则通过LangChain将HeCiX-KG与Large Language Models（如GPT-4）整合，提升了知识图谱的可用性和交互性。实验结果表明，HeCiX在多种临床相关问题上表现出高性能，有望为更有效的临床研究提供整体视角。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2407.14030v1",
      "published_date": "2024-07-19 05:04:24 UTC",
      "updated_date": "2024-07-19 05:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:22:06.034862"
    },
    {
      "arxiv_id": "2407.14024v1",
      "title": "TTA-OOD: Test-time Augmentation for Improving Out-of-Distribution Detection in Gastrointestinal Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Sandesh Pokhrel",
        "Sanjay Bhandari",
        "Eduard Vazquez",
        "Tryphon Lambrou",
        "Prashnna Gyawali",
        "Binod Bhattarai"
      ],
      "abstract": "Deep learning has significantly advanced the field of gastrointestinal\nvision, enhancing disease diagnosis capabilities. One major challenge in\nautomating diagnosis within gastrointestinal settings is the detection of\nabnormal cases in endoscopic images. Due to the sparsity of data, this process\nof distinguishing normal from abnormal cases has faced significant challenges,\nparticularly with rare and unseen conditions. To address this issue, we frame\nabnormality detection as an out-of-distribution (OOD) detection problem. In\nthis setup, a model trained on In-Distribution (ID) data, which represents a\nhealthy GI tract, can accurately identify healthy cases, while abnormalities\nare detected as OOD, regardless of their class. We introduce a test-time\naugmentation segment into the OOD detection pipeline, which enhances the\ndistinction between ID and OOD examples, thereby improving the effectiveness of\nexisting OOD methods with the same model. This augmentation shifts the pixel\nspace, which translates into a more distinct semantic representation for OOD\nexamples compared to ID examples. We evaluated our method against existing\nstate-of-the-art OOD scores, showing improvements with test-time augmentation\nover the baseline approach.",
      "tldr_zh": "本研究针对胃肠视觉领域中异常检测的挑战，将其 framing 为 Out-of-Distribution (OOD) 检测问题，以解决基于 In-Distribution (ID) 数据训练的模型在识别稀有或未见异常时的局限性。作者引入 Test-time Augmentation (TTA) 到 OOD 检测管道中，通过在测试时改变像素空间来增强 ID 和 OOD 示例在语义表示上的差异，从而提升现有 OOD 方法的区分能力。实验结果显示，TTA 显著改善了基线方法的性能，在胃肠内窥镜图像检测中提升了异常识别的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14024v1",
      "published_date": "2024-07-19 04:50:54 UTC",
      "updated_date": "2024-07-19 04:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:22:18.775797"
    },
    {
      "arxiv_id": "2407.14007v2",
      "title": "Multi-modal Relation Distillation for Unified 3D Representation Learning",
      "title_zh": "多模态关系蒸馏用于统一的3D表示学习",
      "authors": [
        "Huiqun Wang",
        "Yiping Bao",
        "Panwang Pan",
        "Zeming Li",
        "Xiao Liu",
        "Ruijie Yang",
        "Di Huang"
      ],
      "abstract": "Recent advancements in multi-modal pre-training for 3D point clouds have\ndemonstrated promising results by aligning heterogeneous features across 3D\nshapes and their corresponding 2D images and language descriptions. However,\ncurrent straightforward solutions often overlook intricate structural relations\namong samples, potentially limiting the full capabilities of multi-modal\nlearning. To address this issue, we introduce Multi-modal Relation Distillation\n(MRD), a tri-modal pre-training framework, which is designed to effectively\ndistill reputable large Vision-Language Models (VLM) into 3D backbones. MRD\naims to capture both intra-relations within each modality as well as\ncross-relations between different modalities and produce more discriminative 3D\nshape representations. Notably, MRD achieves significant improvements in\ndownstream zero-shot classification tasks and cross-modality retrieval tasks,\ndelivering new state-of-the-art performance.",
      "tldr_zh": "该论文提出了Multi-modal Relation Distillation (MRD)，一个三模态预训练框架，用于统一3D表示学习，通过从大型Vision-Language Models (VLM)中蒸馏知识到3D骨干网络，解决当前多模态预训练忽略样本间复杂结构关系的问题。MRD专注于捕捉每个模态内的intra-relations和不同模态间的cross-relations，从而生成更具区分性的3D形状表示。在下游任务中，该方法在零-shot classification和cross-modality retrieval任务上取得了显著改进，并达到了新的state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.14007v2",
      "published_date": "2024-07-19 03:43:48 UTC",
      "updated_date": "2024-09-18 06:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:22:30.926661"
    },
    {
      "arxiv_id": "2407.14565v1",
      "title": "Detecting and Characterising Mobile App Metamorphosis in Google Play Store",
      "title_zh": "在 Google Play Store 中检测并表征移动应用变形",
      "authors": [
        "D. Denipitiyage",
        "B. Silva",
        "K. Gunathilaka",
        "S. Seneviratne",
        "A. Mahanti",
        "A. Seneviratne",
        "S. Chawla"
      ],
      "abstract": "App markets have evolved into highly competitive and dynamic environments for\ndevelopers. While the traditional app life cycle involves incremental updates\nfor feature enhancements and issue resolution, some apps deviate from this norm\nby undergoing significant transformations in their use cases or market\npositioning. We define this previously unstudied phenomenon as 'app\nmetamorphosis'. In this paper, we propose a novel and efficient multi-modal\nsearch methodology to identify apps undergoing metamorphosis and apply it to\nanalyse two snapshots of the Google Play Store taken five years apart. Our\nmethodology uncovers various metamorphosis scenarios, including re-births,\nre-branding, re-purposing, and others, enabling comprehensive characterisation.\nAlthough these transformations may register as successful for app developers\nbased on our defined success score metric (e.g., re-branded apps performing\napproximately 11.3% better than an average top app), we shed light on the\nconcealed security and privacy risks that lurk within, potentially impacting\neven tech-savvy end-users.",
      "tldr_zh": "本研究定义了“app metamorphosis”现象，即移动应用在用途或市场定位上发生重大转变，并提出了一种新颖的多模态搜索方法ology来识别和表征此类应用。研究者将此方法应用于Google Play Store两个相隔五年的快照，揭示了各种转变场景，如re-births、re-branding和re-purposing等。结果显示，这些转变可能提升开发者成功（如re-branded apps比平均顶级应用高11.3%），但也暴露了潜在的安全和隐私风险，可能影响技术-savvy用户。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.SE",
      "comment": "15 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14565v1",
      "published_date": "2024-07-19 03:26:40 UTC",
      "updated_date": "2024-07-19 03:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:22:40.944889"
    },
    {
      "arxiv_id": "2407.13998v2",
      "title": "RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering",
      "title_zh": "RAG-QA Arena：评估长形式检索增强问答的领域鲁棒性",
      "authors": [
        "Rujun Han",
        "Yuhao Zhang",
        "Peng Qi",
        "Yumo Xu",
        "Jenyuan Wang",
        "Lan Liu",
        "William Yang Wang",
        "Bonan Min",
        "Vittorio Castelli"
      ],
      "abstract": "Question answering based on retrieval augmented generation (RAG-QA) is an\nimportant research topic in NLP and has a wide range of real-world\napplications. However, most existing datasets for this task are either\nconstructed using a single source corpus or consist of short extractive\nanswers, which fall short of evaluating large language model (LLM) based RAG-QA\nsystems on cross-domain generalization. To address these limitations, we create\nLong-form RobustQA (LFRQA), a new dataset comprising human-written long-form\nanswers that integrate short extractive answers from multiple documents into a\nsingle, coherent narrative, covering 26K queries and large corpora across seven\ndifferent domains. We further propose RAG-QA Arena by directly comparing\nmodel-generated answers against LFRQA's answers using LLMs as evaluators. We\nshow via extensive experiments that RAG-QA Arena and human judgments on answer\nquality are highly correlated. Moreover, only 41.3% of the most competitive\nLLM's answers are preferred to LFRQA's answers, demonstrating RAG-QA Arena as a\nchallenging evaluation platform for future research.",
      "tldr_zh": "这篇论文针对现有 RAG-QA 系统在跨域泛化上的局限性，创建了 Long-form RobustQA (LFRQA) 数据集，该数据集包含 26K 查询和七个不同领域的庞大语料库，并整合多个文档的短抽取式答案成连贯的长形式叙述。作者提出了 RAG-QA Arena 评估框架，使用 LLM 作为评估器直接比较模型生成的答案与 LFRQA 的答案。实验结果显示，该框架与人类判断的相关性很高，且即使是最先进的 LLM，其答案也仅在 41.3% 的情况下被优于 LFRQA 的答案。RAG-QA Arena 因此成为一个挑战性的平台，推动未来 RAG-QA 研究的改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13998v2",
      "published_date": "2024-07-19 03:02:51 UTC",
      "updated_date": "2024-10-03 00:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:22:56.455807"
    },
    {
      "arxiv_id": "2407.13993v3",
      "title": "LLAssist: Simple Tools for Automating Literature Review Using Large Language Models",
      "title_zh": "LLAssist：使用大型语言模型自动化文献综述的简单工具",
      "authors": [
        "Christoforus Yoga Haryanto"
      ],
      "abstract": "This paper introduces LLAssist, an open-source tool designed to streamline\nliterature reviews in academic research. In an era of exponential growth in\nscientific publications, researchers face mounting challenges in efficiently\nprocessing vast volumes of literature. LLAssist addresses this issue by\nleveraging Large Language Models (LLMs) and Natural Language Processing (NLP)\ntechniques to automate key aspects of the review process. Specifically, it\nextracts important information from research articles and evaluates their\nrelevance to user-defined research questions. The goal of LLAssist is to\nsignificantly reduce the time and effort required for comprehensive literature\nreviews, allowing researchers to focus more on analyzing and synthesizing\ninformation rather than on initial screening tasks. By automating parts of the\nliterature review workflow, LLAssist aims to help researchers manage the\ngrowing volume of academic publications more efficiently.",
      "tldr_zh": "本论文介绍了 LLAssist，这是一个开源工具，利用 Large Language Models (LLMs) 和 Natural Language Processing (NLP) 技术来自动化学术文献综述过程。LLAssist 能够从研究文章中提取关键信息，并评估其与用户定义的研究问题的相关性，从而显著减少文献筛选所需的时间和精力。最终，该工具帮助研究者更高效地管理学术出版物的爆炸式增长，专注于信息分析和合成。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "10 pages, 3 figures, 1 table, presented at the 51st International\n  Conference on Computers and Industrial Engineering (CIE51), 11 Dec 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13993v3",
      "published_date": "2024-07-19 02:48:54 UTC",
      "updated_date": "2024-12-20 12:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:23:03.772693"
    },
    {
      "arxiv_id": "2407.13989v3",
      "title": "Enhancing Graph Neural Networks with Limited Labeled Data by Actively Distilling Knowledge from Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Quan Li",
        "Tianxiang Zhao",
        "Lingwei Chen",
        "Junjie Xu",
        "Suhang Wang"
      ],
      "abstract": "Graphs are pervasive in the real-world, such as social network analysis,\nbioinformatics, and knowledge graphs. Graph neural networks (GNNs) have great\nability in node classification, a fundamental task on graphs. Unfortunately,\nconventional GNNs still face challenges in scenarios with few labeled nodes,\ndespite the prevalence of few-shot node classification tasks in real-world\napplications. To address this challenge, various approaches have been proposed,\nincluding graph meta-learning, transfer learning, and methods based on Large\nLanguage Models (LLMs). However, traditional meta-learning and transfer\nlearning methods often require prior knowledge from base classes or fail to\nexploit the potential advantages of unlabeled nodes. Meanwhile, LLM-based\nmethods may overlook the zero-shot capabilities of LLMs and rely heavily on the\nquality of generated contexts. In this paper, we propose a novel approach that\nintegrates LLMs and GNNs, leveraging the zero-shot inference and reasoning\ncapabilities of LLMs and employing a Graph-LLM-based active learning paradigm\nto enhance GNNs' performance. Extensive experiments demonstrate the\neffectiveness of our model in improving node classification accuracy with\nconsiderably limited labeled data, surpassing state-of-the-art baselines by\nsignificant margins.",
      "tldr_zh": "这篇论文针对图神经网络 (GNNs) 在少量标注数据下的节点分类任务提出了一种新方法，通过主动从大型语言模型 (LLMs) 提炼知识来提升性能。方法整合了 LLMs 的零样本推理能力和 GNNs，利用 Graph-LLM-based active learning 范式，充分利用未标注节点并避免传统方法的局限性。实验结果表明，该方法在各种真实图数据集上显著提高了节点分类准确率，比最先进基线模型有明显优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 Figures",
      "pdf_url": "http://arxiv.org/pdf/2407.13989v3",
      "published_date": "2024-07-19 02:34:10 UTC",
      "updated_date": "2024-09-04 17:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:23:18.162947"
    },
    {
      "arxiv_id": "2407.13968v1",
      "title": "Optimizing Agricultural Order Fulfillment Systems: A Hybrid Tree Search Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Pranay Thangeda",
        "Hoda Helmi",
        "Melkior Ornik"
      ],
      "abstract": "Efficient order fulfillment is vital in the agricultural industry,\nparticularly due to the seasonal nature of seed supply chains. This paper\naddresses the challenge of optimizing seed orders fulfillment in a centralized\nwarehouse where orders are processed in waves, taking into account the\nunpredictable arrival of seed stocks and strict order deadlines. We model the\nwave scheduling problem as a Markov decision process and propose an adaptive\nhybrid tree search algorithm that combines Monte Carlo tree search with\ndomain-specific knowledge to efficiently navigate the complex, dynamic\nenvironment of seed distribution. By leveraging historical data and stochastic\nmodeling, our method enables forecast-informed scheduling decisions that\nbalance immediate requirements with long-term operational efficiency. The key\nidea is that we can augment Monte Carlo tree search algorithm with\nproblem-specific side information that dynamically reduces the number of\ncandidate actions at each decision step to handle the large state and action\nspaces that render traditional solution methods computationally intractable.\nExtensive simulations with realistic parameters-including a diverse range of\nproducts, a high volume of orders, and authentic seasonal durations-demonstrate\nthat the proposed approach significantly outperforms existing industry standard\nmethods.",
      "tldr_zh": "这篇论文针对农业种子供应链的季节性挑战，优化订单履行系统，特别是处理波次订单的不确定库存和严格截止期限问题。作者将问题建模为Markov decision process，并提出一个混合树搜索算法，结合Monte Carlo tree search和领域特定知识，通过动态减少候选动作来应对大规模状态和动作空间。关键创新在于利用历史数据和随机建模，实现预测-informed的调度决策，以平衡短期需求和长期效率。模拟实验显示，该方法在真实参数下显著优于现有行业标准方法，提高了整体表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13968v1",
      "published_date": "2024-07-19 01:25:39 UTC",
      "updated_date": "2024-07-19 01:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:23:29.450907"
    },
    {
      "arxiv_id": "2407.13952v1",
      "title": "Knowledge Distillation Approaches for Accurate and Efficient Recommender System",
      "title_zh": "知识蒸馏方法用于准确且高效的推荐系统",
      "authors": [
        "SeongKu Kang"
      ],
      "abstract": "Despite its breakthrough in classification problems, Knowledge distillation\n(KD) to recommendation models and ranking problems has not been studied well in\nthe previous literature. This dissertation is devoted to developing knowledge\ndistillation methods for recommender systems to fully improve the performance\nof a compact model. We propose novel distillation methods designed for\nrecommender systems. The proposed methods are categorized according to their\nknowledge sources as follows: (1) Latent knowledge: we propose two methods that\ntransfer latent knowledge of user/item representation. They effectively\ntransfer knowledge of niche tastes with a balanced distillation strategy that\nprevents the KD process from being biased towards a small number of large\npreference groups. Also, we propose a new method that transfers user/item\nrelations in the representation space. The proposed method selectively\ntransfers essential relations considering the limited capacity of the compact\nmodel. (2) Ranking knowledge: we propose three methods that transfer ranking\nknowledge from the recommendation results. They formulate the KD process as a\nranking matching problem and transfer the knowledge via a listwise learning\nstrategy. Further, we present a new learning framework that compresses the\nranking knowledge of heterogeneous recommendation models. The proposed\nframework is developed to ease the computational burdens of model ensemble\nwhich is a dominant solution for many recommendation applications. We validate\nthe benefit of our proposed methods and frameworks through extensive\nexperiments. To summarize, this dissertation sheds light on knowledge\ndistillation approaches for a better accuracy-efficiency trade-off of the\nrecommendation models.",
      "tldr_zh": "这篇论文探讨了 Knowledge Distillation (KD) 在 Recommender System 中的应用，旨在通过知识转移提升紧凑模型的准确性和效率。论文提出多种新方法，包括基于 Latent knowledge 的策略（如转移用户/物品表示和关系知识，以平衡避免偏见）和基于 Ranking knowledge 的方法（如将 KD 视为排名匹配问题，并通过 listwise 学习框架压缩异构模型的知识，以减轻计算负担）。通过广泛实验，验证了这些方法的有效性，最终实现了推荐模型在准确性与效率间的更好权衡。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Doctoral Dissertation (2022)",
      "pdf_url": "http://arxiv.org/pdf/2407.13952v1",
      "published_date": "2024-07-19 00:01:18 UTC",
      "updated_date": "2024-07-19 00:01:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:23:42.749816"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 83,
  "processed_papers_count": 83,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T08:24:04.633026"
}