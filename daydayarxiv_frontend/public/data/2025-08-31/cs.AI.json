{
  "date": "2025-08-31",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æˆ‘æ˜¯ Gemini Enterpriseã€‚ä½œä¸ºä½ çš„ä¸“å±ç ”ç©¶åŠ©ç†ï¼Œæˆ‘ä»”ç»†é˜…è¯»äº†ä»Šå¤©æ›´æ–°çš„ 86 ç¯‡ arXiv è®ºæ–‡ã€‚\n\nä»Šå¤©çš„ arXiv æ›´æ–°å¯è°“æ˜¯**æ˜Ÿå…‰ç† ç† ä¸”æ–¹å‘æ˜ç¡®**ã€‚æˆ‘ä»¬çœ‹åˆ°è®¸å¤šé‡é‡çº§å­¦è€…ï¼ˆå¦‚ Matei Zaharia, Ion Stoica, Aditya Groverï¼‰å‘å¸ƒäº†å…³äºç³»ç»Ÿæ¶æ„å’Œç§‘å­¦ AI çš„æ–°ä½œã€‚\n\næ ¸å¿ƒè¶‹åŠ¿éå¸¸æ˜æ˜¾ï¼š**ä»å•çº¯çš„æ¨¡å‹è®­ç»ƒè½¬å‘â€œä»¥ Agent ä¸ºä¸­å¿ƒâ€çš„ç³»ç»Ÿè®¾è®¡**ï¼Œ**ç¥ç»ç¬¦å·ï¼ˆNeuro-Symbolicï¼‰æ¨ç†çš„å¤å…´**ï¼Œä»¥åŠ**å¤šæ¨¡æ€æ¨¡å‹åœ¨ä¸“ä¸šé¢†åŸŸï¼ˆå¦‚åŒ»ç–—ã€å¤©æ°”ï¼‰çš„æ·±åº¦è½åœ°ä¸å¯¹æ¯”**ã€‚\n\næ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-08-31 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n---\n\n### ğŸš€ é‡ç‚¹å…³æ³¨ï¼šå¤§ä½¬åŠ¨æ€ä¸ç³»ç»Ÿçº§å˜é©\n\n**1. Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First**\n**æ”¯æŒæˆ‘ä»¬çš„ AI éœ¸ä¸»ï¼šå°†æ•°æ®ç³»ç»Ÿé‡æ–°è®¾è®¡ä¸ºâ€œAgent ä¼˜å…ˆâ€**\n> **Authors:** Shu Liu, Matei Zaharia, Ion Stoica et al. (UC Berkeley & Databricks å›¢é˜Ÿ)\n> **Tags:** System, Agentic Workflow, Database\n- **æ ¸å¿ƒè§‚ç‚¹**ï¼šè¿™æ˜¯ä¸€ç¯‡æå…·å‰ç»æ€§çš„ Vision Paperã€‚ä½œè€…ï¼ˆåŒ…æ‹¬ Spark çš„åˆ›å§‹äººï¼‰è®¤ä¸ºï¼Œæœªæ¥çš„æ•°æ®ç³»ç»Ÿä¸»è¦è´Ÿè½½å°†ä¸å†æ˜¯äººç±»åˆ†æå¸ˆï¼Œè€Œæ˜¯ **LLM Agents**ã€‚\n- **å‘ç°**ï¼šAgents å¤„ç†æ•°æ®çš„æ–¹å¼è¢«ç§°ä¸º \"Agentic Speculation\"ï¼ˆä»£ç†æ¨æµ‹ï¼‰ï¼Œå…·æœ‰å¤§è§„æ¨¡ã€å¼‚æ„ã€å†—ä½™å’Œå¯å¼•å¯¼çš„ç‰¹å¾ã€‚\n- **è´¡çŒ®**ï¼šæ–‡ç« å‘¼åé‡æ–°è®¾è®¡æ•°æ®åº“æ¶æ„ï¼Œä»æŸ¥è¯¢æ¥å£åˆ°å­˜å‚¨å±‚ï¼Œéƒ½è¦é€‚åº” Agent çš„é«˜ååé‡æ¢ç´¢å’Œè®°å¿†éœ€æ±‚ã€‚è¿™æ˜¯åŸºç¡€è®¾æ–½é¢†åŸŸçš„ä¸‹ä¸€ä¸ªå¤§é£å£ã€‚\n\n**2. IndiaWeatherBench: A Dataset and Benchmark for Data-Driven Regional Weather Forecasting over India**\n**IndiaWeatherBenchï¼šå°åº¦åŒºåŸŸæ•°æ®é©±åŠ¨å¤©æ°”é¢„æŠ¥çš„æ•°æ®é›†ä¸åŸºå‡†**\n> **Authors:** Tung Nguyen, Aditya Grover et al.\n> **Tags:** AI for Science, Weather Forecasting\n- **æ ¸å¿ƒè§‚ç‚¹**ï¼šAI å¤©æ°”é¢„æŠ¥ç›®å‰å¤šå…³æ³¨å…¨çƒæ¨¡å‹ï¼ˆå¦‚ GraphCastï¼‰ï¼ŒåŒºåŸŸæ€§é«˜åˆ†è¾¨ç‡é¢„æŠ¥ç›¸å¯¹è¢«å¿½è§†ã€‚\n- **è´¡çŒ®**ï¼šç”± AI for Science é¢†åŸŸçŸ¥åå­¦è€… Aditya Grover å‚ä¸ï¼Œå‘å¸ƒäº†é’ˆå¯¹å°åº¦æ¬¡å¤§é™†çš„é«˜åˆ†è¾¨ç‡åŒºåŸŸé¢„æŠ¥åŸºå‡†ã€‚\n- **ä»·å€¼**ï¼šè¯„ä¼°äº† UNetsã€Transformers å’Œ Graph-based ç½‘ç»œåœ¨åŒºåŸŸé¢„æŠ¥ä¸­çš„è¡¨ç°ï¼Œä¸ºç¾å®³ç¼“è§£å’Œå¯æŒç»­å‘å±•æä¾›äº†é‡è¦å·¥å…·ã€‚\n\n---\n\n### ğŸ§  é€»è¾‘æ¨ç†ä¸ç¥ç»ç¬¦å· (Neuro-Symbolic)\n\n**3. CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs**\n**CoreThinkï¼šåˆ©ç”¨ LLM è¿›è¡Œé•¿ç¨‹ä»»åŠ¡æ¨ç†çš„ç¬¦å·æ¨ç†å±‚**\n> **Authors:** Jay Vaghasiya, Julian McAuley et al.\n- **æ ¸å¿ƒè§‚ç‚¹**ï¼šå½“å‰çš„æ€ç»´é“¾ï¼ˆCoTï¼‰æˆ–å¾®è°ƒåœ¨é•¿ç¨‹æ¨ç†ä¸­å­˜åœ¨æ”¶ç›Šé€’å‡ã€‚\n- **è´¡çŒ®**ï¼šæå‡ºäº† **General Symbolics** æ¨ç†å±‚ï¼Œæ— éœ€å¾®è°ƒå³å¯æå‡æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆã€å·¥å…·è°ƒç”¨å’Œè§„åˆ’ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚\n- **æˆç»©**ï¼šåœ¨ SWE-Bench Lite ä¸Šè¾¾åˆ°äº† 62.3% çš„ SOTA å‡†ç¡®ç‡ã€‚è¿™è¡¨æ˜å°†â€œæ…¢æ€è€ƒâ€å¤–åŒ…ç»™ç¬¦å·å±‚æ˜¯æ­£ç¡®çš„æ–¹å‘ã€‚\n\n**4. SATQuest: A Verifier for Logical Reasoning Evaluation and Reinforcement Fine-Tuning of LLMs**\n**SATQuestï¼šç”¨äº LLM é€»è¾‘æ¨ç†è¯„ä¼°å’Œå¼ºåŒ–å¾®è°ƒçš„éªŒè¯å™¨**\n> **Authors:** Yanxiao Zhao et al.\n- **æ–¹æ³•**ï¼šé€šè¿‡å°†é€»è¾‘é—®é¢˜è½¬åŒ–ä¸ºå¯æ»¡è¶³æ€§ï¼ˆSATï¼‰é—®é¢˜ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„æ¨ç†ä»»åŠ¡å¹¶åˆ©ç”¨ PySAT è¿›è¡Œå®¢è§‚éªŒè¯ã€‚\n- **ä½œç”¨**ï¼šè§£å†³ LLM é€»è¾‘æ¨ç†è¯„ä¼°éš¾çš„é—®é¢˜ï¼Œå¹¶åˆ©ç”¨éªŒè¯ç»“æœä½œä¸ºå¥–åŠ±ä¿¡å·è¿›è¡Œå¼ºåŒ–å¾®è°ƒï¼ˆReinforcement Fine-Tuningï¼‰ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\n---\n\n### âš¡ï¸ é«˜æ•ˆæ¶æ„ä¸æ¨¡å‹ä¼˜åŒ–\n\n**5. SCOUT: Toward Sub-Quadratic Attention via Segment Compression for Optimized Utility in Transformers**\n**SCOUTï¼šé€šè¿‡æ®µå‹ç¼©å®ç° Transformer çš„æ¬¡äºŒæ¬¡æ–¹æ³¨æ„åŠ›æœºåˆ¶**\n> **Authors:** Aref Jafari et al.\n- **ç—›ç‚¹**ï¼šTransformer çš„æ³¨æ„åŠ›æœºåˆ¶æ˜¯äºŒæ¬¡æ–¹å¤æ‚åº¦ï¼Œé•¿åºåˆ—å¤„ç†éš¾ï¼›Mamba ç­‰çº¿æ€§æ¨¡å‹è™½å¿«ä½†å®¹æ˜“ä¸¢å¤±é•¿ç¨‹ç»†èŠ‚ã€‚\n- **åˆ›æ–°**ï¼š**SCOUT** æ˜¯ä¸€ç§æ··åˆæ¶æ„ï¼Œå®ƒåœ¨å›ºå®šå¤§å°çš„æ®µå†…å‹ç¼© Tokenï¼Œç„¶åè®© Token åªå…³æ³¨è¿™äº›å‹ç¼©åçš„â€œæ£€æŸ¥ç‚¹â€ã€‚\n- **æ•ˆæœ**ï¼šåœ¨ä¿æŒ Transformer è¡¨è¾¾èƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°äº†æ¬¡äºŒæ¬¡æ–¹çš„å¤æ‚åº¦ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸ŠåŒ¹æ•Œå…¨æ³¨æ„åŠ›æ¨¡å‹ã€‚\n\n**6. MEPT: Mixture of Expert Prompt Tuning as a Manifold Mapper**\n**MEPTï¼šä½œä¸ºæµå½¢æ˜ å°„å™¨çš„æ··åˆä¸“å®¶æç¤ºå¾®è°ƒ**\n> **Authors:** Runjia Zeng et al.\n- **è§†è§’**ï¼šå°†â€œé¢„è®­ç»ƒ-å¾®è°ƒâ€è§†ä¸ºæµå½¢æ˜ å°„è¿‡ç¨‹ã€‚\n- **æ–¹æ³•**ï¼šç»“åˆ MoEï¼ˆæ··åˆä¸“å®¶ï¼‰æ¶æ„å’Œ Prompt Tuningï¼Œåˆ©ç”¨å¤šä¸ª Prompt ä¸“å®¶é€‚åº”å¤šæ ·åŒ–çš„æ•°æ®åˆ†å¸ƒã€‚\n- **æ•ˆæœ**ï¼šåœ¨ SuperGLUE ä¸Šæå‡äº†å‡†ç¡®ç‡ï¼ŒåŒæ—¶å‡å°‘äº†è¿‘ 80% çš„æ¿€æ´» Prompt æ•°é‡ï¼Œæ¯”å•çº¯çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ›´çµæ´»ã€‚\n\n---\n\n### ğŸ›¡ï¸ å¹»è§‰ã€å¯¹é½ä¸å¤šæ¨¡æ€å®‰å…¨\n\n**7. OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination**\n**OmniDPOï¼šè§£å†³å…¨æ¨¡æ€å¹»è§‰çš„åå¥½ä¼˜åŒ–æ¡†æ¶**\n> **Authors:** Junzhe Chen et al.\n- **é—®é¢˜**ï¼šåœ¨å…¨æ¨¡æ€ï¼ˆOmni-modalï¼‰æ¨¡å‹ä¸­ï¼Œæ–‡æœ¬å…ˆéªŒå¾€å¾€ä¸»å¯¼è§†è§‰å’Œå¬è§‰ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹å¿½ç•¥è§†é¢‘ä¸­éšå«çš„éŸ³é¢‘çº¿ç´¢ï¼Œäº§ç”Ÿå¹»è§‰ã€‚\n- **æ–¹æ³•**ï¼šæ„å»ºâ€œæ–‡æœ¬åå¥½â€å’Œâ€œå¤šæ¨¡æ€åå¥½â€æ ·æœ¬å¯¹ï¼Œåˆ©ç”¨ DPOï¼ˆç›´æ¥åå¥½ä¼˜åŒ–ï¼‰å¼ºåˆ¶æ¨¡å‹å…³æ³¨è§†å¬äº¤äº’ã€‚\n- **ç»“è®º**ï¼šæ˜¾è‘—å‡å°‘äº†è·¨æ¨¡æ€æ¨ç†æ—¶çš„å¹»è§‰ã€‚\n\n**8. Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias**\n**è‡ªä¿¡ã€æ ¡å‡†è¿˜æ˜¯åŒè°‹ï¼šæ¢ç©¶å®‰å…¨å¯¹é½ä¸æ„è¯†å½¢æ€åè§ä¹‹é—´çš„æƒè¡¡**\n> **Authors:** Sanjeeevan Selvaganapathy et al.\n- **äº‰è®®ç‚¹**ï¼šç»è¿‡å»æ¯’/å®‰å…¨å¯¹é½çš„æ¨¡å‹ï¼ˆCensoredï¼‰ä¸æœªå®¡æŸ¥æ¨¡å‹ï¼ˆUncensoredï¼‰åœ¨æ£€æµ‹ä»‡æ¨è¨€è®ºæ—¶è°æ›´å®¢è§‚ï¼Ÿ\n- **å‘ç°**ï¼š**Censored æ¨¡å‹å‡†ç¡®ç‡æ›´é«˜ï¼ˆ78.7% vs 64.1%ï¼‰**ï¼Œä½†ä¹Ÿè¡¨ç°å‡ºæ›´å¼ºçš„æ„è¯†å½¢æ€å›ºåŒ–ï¼›Uncensored æ¨¡å‹è™½ç„¶â€œè‡ªç”±â€ï¼Œä½†æ›´å®¹æ˜“å—æç¤ºè¯çš„æ„è¯†å½¢æ€æ¡†æ¶å½±å“è€Œæ”¹å˜ç«‹åœºã€‚\n\n---\n\n### ğŸ¥ åŒ»ç–— AIï¼šé€šæ‰ vs ä¸“æ‰\n\n**9. Can General-Purpose Omnimodels Compete with Specialists? A Case Study in Medical Image Segmentation**\n**é€šç”¨å…¨èƒ½æ¨¡å‹èƒ½ä¸ä¸“æ‰ç«äº‰å—ï¼ŸåŒ»å­¦å›¾åƒåˆ†å‰²æ¡ˆä¾‹ç ”ç©¶**\n> **Authors:** Yizhe Zhang et al.\n- **æµ‹è¯„**ï¼šå¯¹æ¯”äº† Geminiï¼ˆå…¨èƒ½æ¨¡å‹ï¼‰ä¸ä¸“ç”¨åŒ»å­¦åˆ†å‰²æ¨¡å‹åœ¨æ¯è‚‰ã€è§†ç½‘è†œè¡€ç®¡ç­‰ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚\n- **ç»“è®º**ï¼š**äº’è¡¥è€Œéæ›¿ä»£**ã€‚ä¸“æœ‰æ¨¡å‹åœ¨ç®€å•æ ·æœ¬ä¸Šè¡¨ç°æ›´å¥½ï¼Œä½†å…¨èƒ½æ¨¡å‹åœ¨â€œå›°éš¾â€æ ·æœ¬ä¸Šè¡¨ç°å‡ºæƒŠäººçš„é²æ£’æ€§ï¼Œä¸”æ•æ„Ÿåº¦æ›´é«˜ï¼ˆèƒ½å‘ç°äººç±»æ¼æ ‡çš„ç»†èŠ‚ï¼‰ã€‚\n\n**10. MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models**\n**MedCODï¼šåˆ©ç”¨ä¸°å¯Œè¯å…¸é“¾æ¡†æ¶å¢å¼º LLM çš„è‹±è¥¿åŒ»å­¦ç¿»è¯‘**\n> **Authors:** Md Shahidul Salim et al.\n- **æ–¹æ³•**ï¼šç»“åˆ UMLSï¼ˆç»Ÿä¸€åŒ»å­¦è¯­è¨€ç³»ç»Ÿï¼‰å’Œ LLM è‡ªèº«çš„çŸ¥è¯†åº“ï¼Œæ„å»ºç»“æ„åŒ–æç¤ºï¼Œå¢å¼ºåŒ»å­¦æœ¯è¯­çš„ç¿»è¯‘å‡†ç¡®æ€§ã€‚\n\n---\n\n### ğŸ¨ åˆ›æ„ã€éŸ³é¢‘ä¸è¶£å‘³ç ”ç©¶\n\n**11. It's-A-Me, Quantum Mario: Scalable Quantum Reinforcement Learning with Multi-Chip Ensembles**\n**æ˜¯æˆ‘ï¼Œé‡å­é©¬é‡Œå¥¥ï¼šåˆ©ç”¨å¤šèŠ¯ç‰‡é›†æˆçš„å¯æ‰©å±•é‡å­å¼ºåŒ–å­¦ä¹ **\n> **Authors:** Junghoon Justin Park et al.\n- **è¶£å‘³**ï¼šæ ‡é¢˜è‡´æ•¬é©¬é‡Œå¥¥ã€‚\n- **ç¡¬æ ¸**ï¼šä¸ºäº†è§£å†³é‡å­è®¡ç®—æœºæ¯”ç‰¹æ•°é™åˆ¶ï¼Œä½œè€…ç”¨å¤šä¸ªå°å‹é‡å­å·ç§¯ç¥ç»ç½‘ç»œï¼ˆQCNNï¼‰ç»„æˆ Ensembleï¼Œåœ¨ã€Šè¶…çº§é©¬é‡Œå¥¥å…„å¼Ÿã€‹ç¯å¢ƒä¸­æˆåŠŸè®­ç»ƒäº†é‡å­ Agentï¼Œè¡¨ç°ä¼˜äºå•èŠ¯ç‰‡æ¨¡å‹ã€‚\n\n**12. The Name-Free Gap: Policy-Aware Stylistic Control in Music Generation**\n**æ— åä¹‹å·®ï¼šéŸ³ä¹ç”Ÿæˆä¸­çš„ç­–ç•¥æ„ŸçŸ¥é£æ ¼æ§åˆ¶**\n> **Authors:** Ashwin Nagarajan et al.\n- **èƒŒæ™¯**ï¼šå‡ºäºç‰ˆæƒå’Œæ”¿ç­–ï¼Œå¾ˆå¤šæ¨¡å‹ç¦æ­¢åœ¨æç¤ºè¯ä¸­ä½¿ç”¨æ­Œæ‰‹åå­—ï¼ˆå¦‚ \"Style of Billie Eilish\"ï¼‰ã€‚\n- **å‘ç°**ï¼šä½œè€…å®šä¹‰äº†â€œName-Free Gapâ€ï¼Œå³ä½¿ç”¨æè¿°æ€§è¯æ±‡ï¼ˆå¦‚â€œç©ºçµâ€ã€â€œæç®€â€ï¼‰æ›¿ä»£äººååï¼Œé£æ ¼æ§åˆ¶åŠ›çš„ä¸‹é™ç¨‹åº¦ã€‚ç»“æœè¡¨æ˜ï¼Œåå­—ä»æ˜¯æœ€å¼ºçš„æ§åˆ¶ä¿¡å·ï¼Œä½†ç²¾å¿ƒè®¾è®¡çš„æè¿°ç¬¦å¯ä»¥å¼¥è¡¥éƒ¨åˆ†å·®è·ã€‚\n\n**13. TinyMusician: On-Device Music Generation**\n**TinyMusicianï¼šç«¯ä¾§éŸ³ä¹ç”Ÿæˆ**\n> **Authors:** Hainan Wang et al.\n- **è´¡çŒ®**ï¼šä» MusicGen è’¸é¦å‡ºçš„è½»é‡çº§æ¨¡å‹ï¼Œæ¨¡å‹å¤§å°å‡å°‘ 55%ï¼Œä¿ç•™äº† 93% çš„æ€§èƒ½ï¼Œé€‚åˆåœ¨æ‰‹æœºç­‰è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œã€‚\n\n---\n\n### ğŸ“ å…¶ä»–å€¼å¾—ä¸€ç¥çš„è®ºæ–‡\n\n*   **[RAG]** **Multimodal Iterative RAG (MI-RAG)** (#52): é’ˆå¯¹éœ€è¦å¤–éƒ¨çŸ¥è¯†çš„è§†è§‰é—®ç­”ï¼ˆVQAï¼‰ï¼Œæå‡ºè¿­ä»£å¼æ£€ç´¢å’Œæ¨ç†æ¡†æ¶ï¼Œæ¯”å•æ¬¡ RAG æ›´æ·±å…¥ã€‚\n*   **[Vision]** **Scoliosis1K-Pose** (#37): è„ŠæŸ±ä¾§å¼¯ç­›æŸ¥æ–°æ•°æ®é›†å’ŒåŒé‡è¡¨ç¤ºæ¡†æ¶ï¼Œåˆ©ç”¨å§¿æ€ä¼°è®¡è¾…åŠ©åŒ»ç–—è¯Šæ–­ã€‚\n*   **[Security]** **Clone What You Can't Steal** (#12): æ”»å‡»è€…å¯ä»¥é€šè¿‡ä¸åˆ° 10k æ¬¡æŸ¥è¯¢ï¼Œåˆ©ç”¨ Logit æ³„æ¼â€œå…‹éš†â€ä¸€ä¸ªé»‘ç›’ LLMï¼Œå¤ç°å…¶ 97.6% çš„éšè—å±‚å‡ ä½•ç»“æ„ã€‚\n*   **[Interface]** **A Multimodal GUI Architecture** (#35): æå‡ºä¸€ç§æ¶æ„ï¼Œè®© GUI åº”ç”¨é€šè¿‡ Model Context Protocol (MCP) å‘ LLM æš´éœ²å¯¼èˆªå›¾ï¼Œå®ç°çœŸæ­£çš„â€œè¯­éŸ³æ§åˆ¶ç•Œé¢â€ã€‚\n\n---\n\n**æ€»ç»“ï¼š** ä»Šå¤©çš„è®ºæ–‡è´¨é‡æé«˜ã€‚ä» **UC Berkeley æå‡ºçš„ Agent-First æ•°æ®åº“** åˆ° **Aditya Grover çš„æ°”è±¡åŸºå‡†**ï¼Œå†åˆ° **Neuro-Symbolic** åœ¨å®é™…ä»£ç ä»»åŠ¡ä¸­çš„ SOTA è¡¨ç°ï¼Œéƒ½åœ¨æš—ç¤º AI æ­£åœ¨ä»â€œèŠå¤©æœºå™¨äººâ€å‘â€œç³»ç»ŸåŒ–æ™ºèƒ½åŸºç¡€è®¾æ–½â€è½¬å‹ã€‚\n\nç¥é˜…è¯»æ„‰å¿«ï¼",
  "papers": [
    {
      "arxiv_id": "2509.01031v1",
      "title": "Reinforcement Learning Driven Generalizable Feature Representation for Cross-User Activity Recognition",
      "title_zh": "å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„é¢å‘è·¨ç”¨æˆ·æ´»åŠ¨è¯†åˆ«çš„å¯æ³›åŒ–ç‰¹å¾è¡¨ç¤º",
      "authors": [
        "Xiaozhou Ye",
        "Kevin I-Kai Wang"
      ],
      "abstract": "Human Activity Recognition (HAR) using wearable sensors is crucial for healthcare, fitness tracking, and smart environments, yet cross-user variability -- stemming from diverse motion patterns, sensor placements, and physiological traits -- hampers generalization in real-world settings. Conventional supervised learning methods often overfit to user-specific patterns, leading to poor performance on unseen users. Existing domain generalization approaches, while promising, frequently overlook temporal dependencies or depend on impractical domain-specific labels. We propose Temporal-Preserving Reinforcement Learning Domain Generalization (TPRL-DG), a novel framework that redefines feature extraction as a sequential decision-making process driven by reinforcement learning. TPRL-DG leverages a Transformer-based autoregressive generator to produce temporal tokens that capture user-invariant activity dynamics, optimized via a multi-objective reward function balancing class discrimination and cross-user invariance. Key innovations include: (1) an RL-driven approach for domain generalization, (2) autoregressive tokenization to preserve temporal coherence, and (3) a label-free reward design eliminating the need for target user annotations. Evaluations on the DSADS and PAMAP2 datasets show that TPRL-DG surpasses state-of-the-art methods in cross-user generalization, achieving superior accuracy without per-user calibration. By learning robust, user-invariant temporal patterns, TPRL-DG enables scalable HAR systems, facilitating advancements in personalized healthcare, adaptive fitness tracking, and context-aware environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TPRL-DGæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¯ç©¿æˆ´ä¼ æ„Ÿå™¨Human Activity Recognitionä¸­å› ç”¨æˆ·è¿åŠ¨æ¨¡å¼å’Œç”Ÿç†å·®å¼‚å¯¼è‡´çš„è·¨ç”¨æˆ·æ³›åŒ–éš¾é¢˜ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°å°†ç‰¹å¾æå–å®šä¹‰ä¸ºç”±Reinforcement Learningé©±åŠ¨çš„åºåˆ—å†³ç­–è¿‡ç¨‹ï¼Œå¹¶åˆ©ç”¨åŸºäºTransformerçš„è‡ªå›å½’ç”Ÿæˆå™¨æå–å…·æœ‰æ—¶é—´ç›¸å…³æ€§çš„ç”¨æˆ·ä¸å˜ç‰¹å¾ã€‚é€šè¿‡è®¾è®¡å¹³è¡¡ç±»åˆ«è¾¨åˆ«åŠ›ä¸è·¨ç”¨æˆ·ä¸å˜æ€§çš„å¤šç›®æ ‡å¥–åŠ±å‡½æ•°ï¼Œä»¥åŠæ— éœ€ç›®æ ‡ç”¨æˆ·æ ‡æ³¨çš„label-freeå¥–åŠ±æœºåˆ¶ï¼ŒTPRL-DGæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚åœ¨DSADSå’ŒPAMAP2æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ— éœ€é’ˆå¯¹æ–°ç”¨æˆ·è¿›è¡Œæ ¡å‡†çš„æƒ…å†µä¸‹ï¼Œå…¶è·¨ç”¨æˆ·æ³›åŒ–å‡†ç¡®ç‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„Domain Generalizationæ–¹æ³•ã€‚é€šè¿‡æ•è·ç¨³å¥çš„Temporal-Preservingç‰¹å¾è¡¨ç¤ºï¼Œè¯¥ç ”ç©¶ä¸ºå®ç°å¤§è§„æ¨¡ã€è‡ªé€‚åº”çš„æ™ºèƒ½å¥åº·ç›‘æµ‹å’Œç¯å¢ƒæ„ŸçŸ¥ç³»ç»Ÿå¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01031v1",
      "published_date": "2025-08-31 23:48:00 UTC",
      "updated_date": "2025-08-31 23:48:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:34:22.292188+00:00"
    },
    {
      "arxiv_id": "2509.01022v2",
      "title": "Symbolic Planning and Multi-Agent Path Finding in Extremely Dense Environments with Unassigned Agents",
      "title_zh": "æé«˜å¯†åº¦ç¯å¢ƒä¸‹å«æœªæŒ‡æ´¾æ™ºèƒ½ä½“çš„ç¬¦å·è§„åˆ’ä¸å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’",
      "authors": [
        "Bo Fu",
        "Zhe Chen",
        "Rahul Chandan",
        "Alex Barbosa",
        "Michael Caldara",
        "Joey Durham",
        "Federico Pecora"
      ],
      "abstract": "We introduce the Block Rearrangement Problem (BRaP), a challenging component of large warehouse management which involves rearranging storage blocks within dense grids to achieve a goal state. We formally define the BRaP as a graph search problem. Building on intuitions from sliding puzzle problems, we propose five search-based solution algorithms, leveraging joint configuration space search, classical planning, multi-agent pathfinding, and expert heuristics. We evaluate the five approaches empirically for plan quality and scalability. Despite the exponential relation between search space size and block number, our methods demonstrate efficiency in creating rearrangement plans for deeply buried blocks in up to 80x80 grids.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† Block Rearrangement Problem (BRaP)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å¤§å‹ä»“åº“ç®¡ç†ä¸­å¯†é›†ç½‘æ ¼å­˜å‚¨å—é‡æ’æŒ‘æˆ˜æå‡ºçš„æ–°é—®é¢˜æ¨¡å‹ï¼Œå¹¶å°†å…¶æ­£å¼å®šä¹‰ä¸ºå›¾æœç´¢ (graph search) é—®é¢˜ã€‚å€Ÿé‰´æ»‘åŠ¨æ‹¼å›¾ (sliding puzzle) é—®é¢˜çš„æ ¸å¿ƒç›´è§‰ï¼Œä½œè€…æå‡ºäº†äº”ç§åŸºäºæœç´¢çš„ç®—æ³•ï¼Œæ¶µç›–äº†è”åˆé…ç½®ç©ºé—´æœç´¢ (joint configuration space search)ã€ç»å…¸è§„åˆ’ (classical planning)ã€å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ (multi-agent pathfinding) åŠä¸“å®¶å¯å‘å¼ (expert heuristics) ç­‰æŠ€æœ¯ã€‚é€šè¿‡å¯¹è§„åˆ’è´¨é‡å’Œå¯æ‰©å±•æ€§çš„å®è¯è¯„ä¼°ï¼Œç ”ç©¶è¯æ˜äº†è¿™äº›æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡æœç´¢ç©ºé—´æ—¶çš„æœ‰æ•ˆæ€§ã€‚å³ä¾¿åœ¨å—æ•°é‡ä¸æœç´¢ç©ºé—´å‘ˆæŒ‡æ•°å…³ç³»çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•ä»èƒ½é«˜æ•ˆåœ°åœ¨é«˜è¾¾ 80x80 çš„ç½‘æ ¼ä¸­ä¸ºæ·±åŸ‹çš„å­˜å‚¨å—ç”Ÿæˆé‡æ’è®¡åˆ’ï¼Œä¸ºæç«¯å¯†é›†ç¯å¢ƒä¸‹çš„è‡ªåŠ¨åŒ–ç‰©æµæä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ä¸å®è·µæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI Conference on Artificial Intelligence (AAAI-26)",
      "pdf_url": "https://arxiv.org/pdf/2509.01022v2",
      "published_date": "2025-08-31 23:27:27 UTC",
      "updated_date": "2026-01-08 19:53:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:34:36.750001+00:00"
    },
    {
      "arxiv_id": "2509.01021v1",
      "title": "Quantum-like Coherence Derived from the Interaction between Chemical Reaction and Its Environment",
      "title_zh": "æºäºåŒ–å­¦ååº”ä¸å…¶ç¯å¢ƒç›¸äº’ä½œç”¨çš„ç±»é‡å­ç›¸å¹²æ€§",
      "authors": [
        "Yukio-Pegio Gunji",
        "Andrew Adamatzky",
        "Panagiotis Mougkogiannis",
        "Andrei Khrenikov"
      ],
      "abstract": "By uncovering the contrast between Artificial Intelligence and Natural-born Intelligence as a computational process, we define closed computing and open computing, and implement open computing within chemical reactions. This involves forming a mixture and invalidation of the computational process and the execution environment, which are logically distinct, and coalescing both to create a system that adjusts fluctuations. We model chemical reactions by considering the computation as the chemical reaction and the execution environment as the degree of aggregation of molecules that interact with the reactive environment. This results in a chemical reaction that progresses while repeatedly clustering and de-clustering, where concentration no longer holds significant meaning. Open computing is segmented into Token computing, which focuses on the individual behavior of chemical molecules, and Type computing, which focuses on normative behavior. Ultimately, both are constructed as an interplay between the two. In this system, Token computing demonstrates self-organizing critical phenomena, while Type computing exhibits quantum logic. Through their interplay, the recruitment of fluctuations is realized, giving rise to interactions between quantum logical subspaces corresponding to quantum coherence across different Hilbert spaces. As a result, spike waves are formed, enabling signal transmission. This occurrence may be termed quantum-like coherence, implying the source of enzymes responsible for controlling spike waves and biochemical rhythms.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹æ¯”äººå·¥æ™ºèƒ½ä¸è‡ªç„¶æ™ºèƒ½çš„è®¡ç®—å·®å¼‚ï¼Œå®šä¹‰äº†å°é—­è®¡ç®—(Closed computing)ä¸å¼€æ”¾è®¡ç®—(Open computing)çš„æ¦‚å¿µï¼Œå¹¶åœ¨åŒ–å­¦ååº”ç³»ç»Ÿä¸­å®ç°äº†å¼€æ”¾è®¡ç®—ã€‚ç ”ç©¶å°†åŒ–å­¦ååº”è¿‡ç¨‹å»ºæ¨¡ä¸ºè®¡ç®—ï¼Œå°†åˆ†å­èšé›†ç¨‹åº¦è§†ä¸ºæ‰§è¡Œç¯å¢ƒï¼Œæ„å»ºäº†ä¸€ä¸ªé€šè¿‡å›¢èšä¸è§£å›¢èšä¸æ–­è°ƒèŠ‚æ¶¨è½çš„åŠ¨æ€ç³»ç»Ÿã€‚å¼€æ”¾è®¡ç®—è¢«ç»†åˆ†ä¸ºå…³æ³¨ä¸ªä½“åˆ†å­è¡Œä¸ºçš„ä»¤ç‰Œè®¡ç®—(Token computing)ä¸å…³æ³¨è§„èŒƒè¡Œä¸ºçš„ç±»å‹è®¡ç®—(Type computing)ï¼Œé€šè¿‡ä¸¤è€…çš„äº¤äº’å®ç°å¯¹æ¶¨è½çš„æ‹›å‹Ÿã€‚åœ¨è¿™ä¸€ä½“ç³»ä¸­ï¼Œä»¤ç‰Œè®¡ç®—è¡¨ç°å‡ºè‡ªç»„ç»‡ä¸´ç•Œç°è±¡ï¼Œè€Œç±»å‹è®¡ç®—å±•ç°å‡ºé‡å­é€»è¾‘(Quantum logic)ï¼Œä¸¤è€…çš„è€¦åˆå¼•å‘äº†è·¨å¸Œå°”ä¼¯ç‰¹ç©ºé—´(Hilbert spaces)çš„å­ç©ºé—´äº¤äº’ã€‚è¿™ç§äº¤äº’äº§ç”Ÿäº†ç±»é‡å­ç›¸å¹²(Quantum-like coherence)ç°è±¡å¹¶å½¢æˆè„‰å†²æ³¢ï¼Œä»è€Œå®ç°ä¿¡å·ä¼ è¾“ã€‚è¯¥å‘ç°ä¸ºç†è§£æ§åˆ¶ç”ŸåŒ–èŠ‚å¾‹å’Œè„‰å†²æ³¢çš„é…¶ä¿ƒååº”æœºåˆ¶æä¾›äº†å…¨æ–°çš„ç‰©ç†åŒ–å­¦è§£é‡Šã€‚",
      "categories": [
        "cs.AI",
        "nlin.AO"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.01021v1",
      "published_date": "2025-08-31 23:21:32 UTC",
      "updated_date": "2025-08-31 23:21:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:34:29.491295+00:00"
    },
    {
      "arxiv_id": "2509.01016v1",
      "title": "Analysis of Error Sources in LLM-based Hypothesis Search for Few-Shot Rule Induction",
      "title_zh": "å°‘æ ·æœ¬è§„åˆ™å½’çº³ä¸­åŸºäº LLM çš„å‡è®¾æœç´¢é”™è¯¯æ¥æºåˆ†æ",
      "authors": [
        "Aishni Parab",
        "Hongjing Lu",
        "Ying Nian Wu",
        "Sumit Gulwani"
      ],
      "abstract": "Inductive reasoning enables humans to infer abstract rules from limited examples and apply them to novel situations. In this work, we compare an LLM-based hypothesis search framework with direct program generation approaches on few-shot rule induction tasks. Our findings show that hypothesis search achieves performance comparable to humans, while direct program generation falls notably behind. An error analysis reveals key bottlenecks in hypothesis generation and suggests directions for advancing program induction methods. Overall, this paper underscores the potential of LLM-based hypothesis search for modeling inductive reasoning and the challenges in building more efficient systems.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLM-basedï¼‰çš„å‡è®¾æœç´¢æ¡†æ¶åœ¨å°‘æ ·æœ¬è§„åˆ™å½’çº³ï¼ˆFew-Shot Rule Inductionï¼‰ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶å¯¹å…¶è¯¯å·®æ¥æºè¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ä½œè€…å°†è¯¥æ¡†æ¶ä¸ç›´æ¥ç”Ÿæˆç¨‹åºï¼ˆdirect program generationï¼‰çš„æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿäººç±»ä»æœ‰é™ç¤ºä¾‹ä¸­æ¨æ–­æŠ½è±¡è§„åˆ™å¹¶åº”ç”¨äºæ–°æƒ…å¢ƒçš„èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒåŸºäºå‡è®¾æœç´¢çš„æ–¹æ³•åœ¨æ€§èƒ½ä¸Šè¶³ä»¥ä¸äººç±»ç›¸åª²ç¾ï¼Œè€Œç›´æ¥ç”Ÿæˆç¨‹åºçš„æ–¹æ³•åˆ™è¡¨ç°å‡ºæ˜æ˜¾çš„å·®è·ã€‚é€šè¿‡è¯¯å·®åˆ†æï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†å‡è®¾ç”Ÿæˆï¼ˆhypothesis generationï¼‰é˜¶æ®µçš„å…³é”®ç“¶é¢ˆï¼Œå¹¶ä¸ºä¼˜åŒ–ç¨‹åºå½’çº³ï¼ˆprogram inductionï¼‰æ–¹æ³•æŒ‡æ˜äº†æ–¹å‘ã€‚æ€»ä½“è€Œè¨€ï¼Œæœ¬æ–‡è¯æ˜äº† LLM-based å‡è®¾æœç´¢åœ¨å»ºæ¨¡å½’çº³æ¨ç†æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶ç³»ç»Ÿé˜è¿°äº†æ„å»ºé«˜æ•ˆè§„åˆ™å½’çº³ç³»ç»Ÿæ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "This is the preprint version corresponding to our NeurIPS 2025 Workshop on Multimodal Algorithmic Reasoning submission",
      "pdf_url": "https://arxiv.org/pdf/2509.01016v1",
      "published_date": "2025-08-31 22:42:58 UTC",
      "updated_date": "2025-08-31 22:42:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:34:32.293748+00:00"
    },
    {
      "arxiv_id": "2509.00997v2",
      "title": "Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First",
      "title_zh": "æ”¯æŒæˆ‘ä»¬çš„ AI ä¸»å®°ï¼šé‡æ–°è®¾è®¡æ™ºèƒ½ä½“ä¼˜å…ˆçš„æ•°æ®ç³»ç»Ÿ",
      "authors": [
        "Shu Liu",
        "Soujanya Ponnapalli",
        "Shreya Shankar",
        "Sepanta Zeighami",
        "Alan Zhu",
        "Shubham Agarwal",
        "Ruiqi Chen",
        "Samion Suwito",
        "Shuo Yuan",
        "Ion Stoica",
        "Matei Zaharia",
        "Alvin Cheung",
        "Natacha Crooks",
        "Joseph E. Gonzalez",
        "Aditya G. Parameswaran"
      ],
      "abstract": "Large Language Model (LLM) agents, acting on their users' behalf to manipulate and analyze data, are likely to become the dominant workload for data systems in the future. When working with data, agents employ a high-throughput process of exploration and solution formulation for the given task, one we call agentic speculation. The sheer volume and inefficiencies of agentic speculation can pose challenges for present-day data systems. We argue that data systems need to adapt to more natively support agentic workloads. We take advantage of the characteristics of agentic speculation that we identify, i.e., scale, heterogeneity, redundancy, and steerability - to outline a number of new research opportunities for a new agent-first data systems architecture, ranging from new query interfaces, to new query processing techniques, to new agentic memory stores.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“ä½œä¸ºæœªæ¥æ•°æ®ç³»ç»Ÿä¸»è¦è´Ÿè½½çš„è¶‹åŠ¿ï¼Œå¹¶å°†å…¶ç‰¹æœ‰çš„é«˜ååé‡æ¢ç´¢ä¸æ–¹æ¡ˆåˆ¶å®šè¿‡ç¨‹å®šä¹‰ä¸º agentic speculationã€‚é‰´äºå½“å‰æ•°æ®ç³»ç»Ÿåœ¨å¤„ç†æ­¤ç±»å·¥ä½œè´Ÿè½½æ—¶é¢ä¸´çš„è§„æ¨¡ä¸æ•ˆç‡æŒ‘æˆ˜ï¼Œä½œè€…ä¸»å¼ æ•°æ®ç³»ç»Ÿéœ€å‘åŸç”Ÿæ”¯æŒæ™ºèƒ½ä½“çš„æ¶æ„è½¬å‹ã€‚è®ºæ–‡æ·±å…¥åˆ†æäº† agentic speculation çš„å››ä¸ªæ ¸å¿ƒç‰¹å¾ï¼Œå³ scaleã€heterogeneityã€redundancy å’Œ steerabilityï¼Œå¹¶æ®æ­¤æå‡ºäº† agent-first æ•°æ®ç³»ç»Ÿæ¶æ„çš„è®¾è®¡è“å›¾ã€‚è¯¥æ¶æ„æ¶µç›–äº†å…¨æ–°çš„æŸ¥è¯¢æ¥å£ã€åˆ›æ–°çš„æŸ¥è¯¢å¤„ç†æŠ€æœ¯ä»¥åŠä¸“é—¨çš„ agentic memory stores ç­‰ç ”ç©¶æ–¹å‘ã€‚é€šè¿‡è¿™äº›å˜é©ï¼Œç ”ç©¶æ—¨åœ¨ä¸ºæœªæ¥ç”±æ™ºèƒ½ä½“ä¸»å¯¼çš„æ•°æ®æ“ä½œä¸åˆ†æç¯å¢ƒæä¾›æ›´é«˜æ•ˆçš„ç³»ç»Ÿæ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00997v2",
      "published_date": "2025-08-31 21:19:40 UTC",
      "updated_date": "2025-12-06 06:56:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:34:35.853388+00:00"
    },
    {
      "arxiv_id": "2509.00996v2",
      "title": "MEPT: Mixture of Expert Prompt Tuning as a Manifold Mapper",
      "title_zh": "MEPTï¼šä½œä¸ºæµå½¢æ˜ å°„å™¨çš„æ··åˆä¸“å®¶æç¤ºå¾®è°ƒ",
      "authors": [
        "Runjia Zeng",
        "Guangyan Sun",
        "Qifan Wang",
        "Tong Geng",
        "Sohail Dianat",
        "Xiaotian Han",
        "Raghuveer Rao",
        "Xueling Zhang",
        "Cheng Han",
        "Lifu Huang",
        "Dongfang Liu"
      ],
      "abstract": "Considering deep neural networks as manifold mappers, the pretrain-then-fine-tune paradigm can be interpreted as a two-stage process: pretrain establishes a broad knowledge base, and fine-tune adjusts the model parameters to activate specific neural pathways to align with the target manifold. Although prior fine-tuning approaches demonstrate success, their rigid parameter space limits their ability to dynamically activate appropriate neural pathways, rendering them ill-equipped to adapt flexibly to the diverse and evolving data distributions. In light of this view, we propose a novel approach, Mixture of Expert Prompt Tuning (MEPT), as an effective and efficient manifold-mapping framework. MEPT leverages the Mixture of Experts architecture by integrating multiple prompt experts to adaptively learn diverse and non-stationary data distributions. Empirical evaluations demonstrate that MEPT outperforms several state-of-the-art parameter efficient baselines on SuperGLUE, achieving notable improvements in mean accuracy (e.g., 1.94%) while significantly reducing activated prompts by 79.25%. The effectiveness of MEPT is further supported by theoretical insights from manifold learning and validated through neural activation pathway visualization results. Our code is avaliable at https://runjia.tech/emnlp_mept/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MEPT (Mixture of Expert Prompt Tuning)ï¼Œå°†å…¶è§†ä½œä¸€ç§é«˜æ•ˆçš„æµå½¢æ˜ å°„å™¨ (Manifold Mapper)ï¼Œæ—¨åœ¨è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å¾®è°ƒé˜¶æ®µå› å‚æ•°ç©ºé—´åƒµåŒ–è€Œéš¾ä»¥åŠ¨æ€æ¿€æ´»ç¥ç»è·¯å¾„çš„é—®é¢˜ã€‚MEPT å€Ÿé‰´äº†ä¸“å®¶æ··åˆ (Mixture of Experts) æ¶æ„ï¼Œé€šè¿‡é›†æˆå¤šä¸ªæç¤ºä¸“å®¶ (Prompt Experts) æ¥é€‚åº”æ€§åœ°å­¦ä¹ å¤šæ ·ä¸”éå¹³ç¨³çš„æ•°æ®åˆ†å¸ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMEPT åœ¨ SuperGLUE åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºå¤šç§å…ˆè¿›çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œåœ¨å¹³å‡å‡†ç¡®ç‡æå‡ 1.94% çš„åŒæ—¶ï¼Œå°†æ¿€æ´»çš„æç¤ºæ•°é‡å¤§å¹…å‡å°‘äº† 79.25%ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜ç»“åˆæµå½¢å­¦ä¹ ç†è®ºæ·±å…¥æ¢è®¨äº† MEPT çš„æœ‰æ•ˆæ€§ï¼Œå¹¶é€šè¿‡ç¥ç»æ¿€æ´»è·¯å¾„çš„å¯è§†åŒ–éªŒè¯äº†å…¶åœ¨åŠ¨æ€é€‚é…æ–¹é¢çš„ä¼˜è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00996v2",
      "published_date": "2025-08-31 21:19:25 UTC",
      "updated_date": "2025-09-13 23:37:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:34:42.959359+00:00"
    },
    {
      "arxiv_id": "2509.00992v1",
      "title": "Online Decentralized Federated Multi-task Learning With Trustworthiness in Cyber-Physical Systems",
      "title_zh": "ä¿¡æ¯ç‰©ç†ç³»ç»Ÿä¸­å…·æœ‰å¯ä¿¡æ€§çš„åœ¨çº¿å»ä¸­å¿ƒåŒ–è”é‚¦å¤šä»»åŠ¡å­¦ä¹ ",
      "authors": [
        "Olusola Odeyomi",
        "Sofiat Olaosebikan",
        "Ajibuwa Opeyemi",
        "Oluwadoyinsola Ige"
      ],
      "abstract": "Multi-task learning is an effective way to address the challenge of model personalization caused by high data heterogeneity in federated learning. However, extending multi-task learning to the online decentralized federated learning setting is yet to be explored. The online decentralized federated learning setting considers many real-world applications of federated learning, such as autonomous systems, where clients communicate peer-to-peer and the data distribution of each client is time-varying. A more serious problem in real-world applications of federated learning is the presence of Byzantine clients. Byzantine-resilient approaches used in federated learning work only when the number of Byzantine clients is less than one-half the total number of clients. Yet, it is difficult to put a limit on the number of Byzantine clients within a system in reality. However, recent work in robotics shows that it is possible to exploit cyber-physical properties of a system to predict clients' behavior and assign a trust probability to received signals. This can help to achieve resiliency in the presence of a dominating number of Byzantine clients. Therefore, in this paper, we develop an online decentralized federated multi-task learning algorithm to provide model personalization and resiliency when the number of Byzantine clients dominates the number of honest clients. Our proposed algorithm leverages cyber-physical properties, such as the received signal strength in wireless systems or side information, to assign a trust probability to local models received from neighbors in each iteration. Our simulation results show that the proposed algorithm performs close to a Byzantine-free setting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Cyber-Physical Systems ä¸­é«˜æ•°æ®å¼‚è´¨æ€§ä¸åŠ¨æ€å˜åŒ–å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ Online Decentralized Federated Multi-task Learning ç®—æ³•ã€‚åœ¨ç°å®åº”ç”¨ä¸­ï¼Œå½“ Byzantine clients æ•°é‡å æ®ä¸»å¯¼åœ°ä½æ—¶ï¼Œä¼ ç»Ÿçš„ Byzantine-resilient æ–¹æ³•é€šå¸¸ä¼šå¤±æ•ˆã€‚ä¸ºåº”å¯¹è¿™ä¸€é—®é¢˜ï¼Œè¯¥ç®—æ³•å·§å¦™åˆ©ç”¨ Cyber-Physical ç³»ç»Ÿçš„ç‰©ç†ç‰¹æ€§ï¼ˆå¦‚æ¥æ”¶ä¿¡å·å¼ºåº¦ï¼‰æˆ–ä¾§ä¿¡æ¯ä¸ºé‚»å±…èŠ‚ç‚¹åˆ†é… Trust probabilityï¼Œä»¥æ­¤å®ç°æœ‰æ•ˆçš„ Model personalizationã€‚è¿™ä¸€æœºåˆ¶ç¡®ä¿äº†åœ¨æ¶æ„èŠ‚ç‚¹æ•°é‡æå¤§çš„æç«¯ç¯å¢ƒä¸‹ï¼Œç³»ç»Ÿä¾ç„¶èƒ½ä¿æŒæé«˜çš„é²æ£’æ€§ä¸éŸ§æ€§ã€‚ä»¿çœŸå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨ Byzantine æ”»å‡»ä¸¥é‡çš„åœºæ™¯ä¸‹è¡¨ç°æ¥è¿‘äº Byzantine-free è®¾å®šã€‚è¯¥é¡¹å·¥ä½œä¸ºå—é™ä¸”å……æ»¡ä¸ç¡®å®šæ€§çš„å»ä¸­å¿ƒåŒ–è”é‚¦å­¦ä¹ ç¯å¢ƒæä¾›äº†å…³é”®çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00992v1",
      "published_date": "2025-08-31 20:59:54 UTC",
      "updated_date": "2025-08-31 20:59:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:35:10.436827+00:00"
    },
    {
      "arxiv_id": "2509.05332v1",
      "title": "Integrated Simulation Framework for Adversarial Attacks on Autonomous Vehicles",
      "title_zh": "é¢å‘è‡ªåŠ¨é©¾é©¶æ±½è½¦å¯¹æŠ—æ”»å‡»çš„é›†æˆä»¿çœŸæ¡†æ¶",
      "authors": [
        "Christos Anagnostopoulos",
        "Ioulia Kapsali",
        "Alexandros Gkillas",
        "Nikos Piperigkos",
        "Aris S. Lalos"
      ],
      "abstract": "Autonomous vehicles (AVs) rely on complex perception and communication systems, making them vulnerable to adversarial attacks that can compromise safety. While simulation offers a scalable and safe environment for robustness testing, existing frameworks typically lack comprehensive supportfor modeling multi-domain adversarial scenarios. This paper introduces a novel, open-source integrated simulation framework designed to generate adversarial attacks targeting both perception and communication layers of AVs. The framework provides high-fidelity modeling of physical environments, traffic dynamics, and V2X networking, orchestrating these components through a unified core that synchronizes multiple simulators based on a single configuration file. Our implementation supports diverse perception-level attacks on LiDAR sensor data, along with communication-level threats such as V2X message manipulation and GPS spoofing. Furthermore, ROS 2 integration ensures seamless compatibility with third-party AV software stacks. We demonstrate the framework's effectiveness by evaluating the impact of generated adversarial scenarios on a state-of-the-art 3D object detector, revealing significant performance degradation under realistic conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼ˆAVsï¼‰æ„ŸçŸ¥ä¸é€šä¿¡ç³»ç»Ÿæ˜“å—å¯¹æŠ—æ€§æ”»å‡»ï¼ˆadversarial attacksï¼‰çš„å®‰å…¨å¨èƒï¼Œå¼€å‘äº†ä¸€ä¸ªå…¨æ–°çš„å¼€æºé›†æˆæ¨¡æ‹Ÿæ¡†æ¶ã€‚è¯¥æ¡†æ¶å¡«è¡¥äº†ç°æœ‰å·¥å…·åœ¨å¤šé¢†åŸŸå¯¹æŠ—åœºæ™¯å»ºæ¨¡æ–¹é¢çš„ç©ºç™½ï¼Œèƒ½å¤Ÿç”Ÿæˆé’ˆå¯¹æ„ŸçŸ¥å±‚ï¼ˆLiDARä¼ æ„Ÿå™¨æ•°æ®ï¼‰ä»¥åŠé€šä¿¡å±‚ï¼ˆV2Xæ¶ˆæ¯ç¯¡æ”¹å’ŒGPSæ¬ºéª—ï¼‰çš„ç»¼åˆæ€§æ”»å‡»ã€‚å…¶æ ¸å¿ƒç»„ä»¶é€šè¿‡å•ä¸€é…ç½®æ–‡ä»¶åŒæ­¥å¤šä¸ªæ¨¡æ‹Ÿå™¨ï¼Œå®ç°äº†ç‰©ç†ç¯å¢ƒã€äº¤é€šåŠ¨æ€ä¸V2Xç½‘ç»œçš„é«˜ä¿çœŸæ¨¡æ‹Ÿï¼Œå¹¶åˆ©ç”¨ROS 2é›†æˆç¡®ä¿äº†ä¸ç¬¬ä¸‰æ–¹è‡ªåŠ¨é©¾é©¶è½¯ä»¶æ ˆçš„æ— ç¼å…¼å®¹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶ç”Ÿæˆçš„å¯¹æŠ—åœºæ™¯å¯¼è‡´æœ€å…ˆè¿›çš„3Dç‰©ä½“æ£€æµ‹å™¨æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œè¯æ˜äº†å…¶åœ¨ç°å®æ¡ä»¶ä¸‹è¯„ä¼°ç³»ç»Ÿé²æ£’æ€§çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¼€å‘æ›´å®‰å…¨çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯æä¾›äº†æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05332v1",
      "published_date": "2025-08-31 20:53:08 UTC",
      "updated_date": "2025-08-31 20:53:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:34:56.939545+00:00"
    },
    {
      "arxiv_id": "2509.00987v1",
      "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation",
      "title_zh": "Causal MASï¼šé¢å‘å› æœå‘ç°ä¸æ•ˆåº”ä¼°è®¡çš„å¤§è¯­è¨€æ¨¡å‹æ¶æ„ç»¼è¿°",
      "authors": [
        "Adib Bazgir",
        "Amir Habibdoust",
        "Yuwen Zhang",
        "Xing Song"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning and generation tasks. However, their proficiency in complex causal reasoning, discovery, and estimation remains an area of active development, often hindered by issues like hallucination, reliance on spurious correlations, and difficulties in handling nuanced, domain-specific, or personalized causal relationships. Multi-agent systems, leveraging the collaborative or specialized abilities of multiple LLM-based agents, are emerging as a powerful paradigm to address these limitations. This review paper explores the burgeoning field of causal multi-agent LLMs. We examine how these systems are designed to tackle different facets of causality, including causal reasoning and counterfactual analysis, causal discovery from data, and the estimation of causal effects. We delve into the diverse architectural patterns and interaction protocols employed, from pipeline-based processing and debate frameworks to simulation environments and iterative refinement loops. Furthermore, we discuss the evaluation methodologies, benchmarks, and diverse application domains where causal multi-agent LLMs are making an impact, including scientific discovery, healthcare, fact-checking, and personalized systems. Finally, we highlight the persistent challenges, open research questions, and promising future directions in this synergistic field, aiming to provide a comprehensive overview of its current state and potential trajectory.",
      "tldr_zh": "è¯¥ç»¼è¿°æ¢è®¨äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(MAS)åœ¨è§£å†³å¤æ‚å› æœä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚é’ˆå¯¹LLMsåœ¨å› æœæ¨ç†ä¸­é¢ä¸´çš„å¹»è§‰ã€è™šå‡ç›¸å…³æ€§åŠé¢†åŸŸç‰¹å¼‚æ€§å¤„ç†å›°éš¾ç­‰å±€é™ï¼Œç ”ç©¶è€…åˆ©ç”¨å¤šæ™ºèƒ½ä½“çš„åä½œä¸ä¸“ä¸šèƒ½åŠ›æå‡ºäº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚æ–‡ç« è¯¦ç»†é˜è¿°äº†è¿™äº›ç³»ç»Ÿåœ¨å› æœæ¨ç†(Causal Reasoning)ã€åäº‹å®åˆ†æ(Counterfactual Analysis)ã€å› æœå‘ç°(Causal Discovery)åŠå› æœæ•ˆåº”ä¼°è®¡(Causal Effect Estimation)ç­‰æ–¹é¢çš„è®¾è®¡ã€‚åŒæ—¶ï¼Œç»¼è¿°æ·±å…¥åˆ†æäº†ä»æµæ°´çº¿å¤„ç†ã€è¾©è®ºæ¡†æ¶åˆ°æ¨¡æ‹Ÿç¯å¢ƒç­‰å¤šæ ·åŒ–çš„æ¶æ„æ¨¡å¼å’Œäº¤äº’åè®®ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜ä»‹ç»äº†ç›¸å…³çš„è¯„ä¼°åŸºå‡†ä»¥åŠåœ¨ç§‘å­¦å‘ç°ã€åŒ»ç–—ä¿å¥å’Œäº‹å®æ ¸æŸ¥ç­‰é¢†åŸŸçš„åº”ç”¨ç°çŠ¶ã€‚æœ€åï¼Œç ”ç©¶è€…æŒ‡å‡ºäº†è¯¥é¢†åŸŸçš„æŒç»­æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘ï¼Œä¸ºæ„å»ºå…·å¤‡é²æ£’å› æœèƒ½åŠ›çš„æ™ºèƒ½ç³»ç»Ÿæä¾›äº†å…¨é¢æ¦‚è§ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages. 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00987v1",
      "published_date": "2025-08-31 20:48:31 UTC",
      "updated_date": "2025-08-31 20:48:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:34:50.846567+00:00"
    },
    {
      "arxiv_id": "2509.05331v1",
      "title": "ForensicsData: A Digital Forensics Dataset for Large Language Models",
      "title_zh": "ForensicsDataï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„æ•°å­—å–è¯æ•°æ®é›†",
      "authors": [
        "Youssef Chakir",
        "Iyad Lahsen-Cherif"
      ],
      "abstract": "The growing complexity of cyber incidents presents significant challenges for digital forensic investigators, especially in evidence collection and analysis. Public resources are still limited because of ethical, legal, and privacy concerns, even though realistic datasets are necessary to support research and tool developments. To address this gap, we introduce ForensicsData, an extensive Question-Context-Answer (Q-C-A) dataset sourced from actual malware analysis reports. It consists of more than 5,000 Q-C-A triplets. A unique workflow was used to create the dataset, which extracts structured data, uses large language models (LLMs) to transform it into Q-C-A format, and then uses a specialized evaluation process to confirm its quality. Among the models evaluated, Gemini 2 Flash demonstrated the best performance in aligning generated content with forensic terminology. ForensicsData aims to advance digital forensics by enabling reproducible experiments and fostering collaboration within the research community.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°å­—å–è¯è°ƒæŸ¥ä¸­è¯æ®æ”¶é›†ä¸åˆ†æçš„å¤æ‚æ€§ï¼Œä»¥åŠç”±äºæ³•å¾‹ä¸éšç§é™åˆ¶å¯¼è‡´çš„å…¬å¼€èµ„æºåŒ®ä¹é—®é¢˜ï¼Œæ¨å‡ºäº†åä¸º ForensicsData çš„æ•°å­—å–è¯æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«è¶…è¿‡ 5,000 ä¸ªæºè‡ªçœŸå®æ¶æ„è½¯ä»¶åˆ†ææŠ¥å‘Šçš„é—®ç­”å¯¹ï¼ˆQuestion-Context-Answer, Q-C-Aï¼‰ï¼Œä¸“é—¨ç”¨äºæ”¯æŒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å–è¯é¢†åŸŸçš„ç ”ç©¶ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ä¸€å¥—ç‹¬ç‰¹çš„å·¥ä½œæµæå–ç»“æ„åŒ–æ•°æ®ï¼Œå¹¶é€šè¿‡ LLMs å°†å…¶è½¬åŒ–ä¸º Q-C-A æ ¼å¼ï¼Œæœ€åè¾…ä»¥ä¸“é—¨çš„è¯„ä¼°æµç¨‹ç¡®ä¿æ•°æ®è´¨é‡ã€‚åœ¨è¯„ä¼°çš„æ¨¡å‹ä¸­ï¼ŒGemini 2 Flash åœ¨ç”Ÿæˆå†…å®¹ä¸å–è¯æœ¯è¯­ï¼ˆforensic terminologyï¼‰çš„å¯¹é½æ–¹é¢è¡¨ç°æœ€ä¸ºå‡ºè‰²ã€‚ForensicsData æ—¨åœ¨é€šè¿‡æä¾›å¯é‡å¤å®éªŒçš„åŸºç¡€ï¼Œæ¨åŠ¨æ•°å­—å–è¯é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥ä¸ç¤¾åŒºåä½œã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to WiMob 2025 (21st International Conference on Wireless and Mobile Computing, Networking and Communications), Marrakesh, Morocco, Oct 20-22, 2025. 6 pages, 5 figures, 5 tables. IEEEtran conference format",
      "pdf_url": "https://arxiv.org/pdf/2509.05331v1",
      "published_date": "2025-08-31 19:58:24 UTC",
      "updated_date": "2025-08-31 19:58:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:35:21.939107+00:00"
    },
    {
      "arxiv_id": "2509.00975v2",
      "title": "Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning",
      "title_zh": "åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªæ¢ç´¢è¯­è¨€æ¨¡å‹ï¼šå®ç°æ—¶åºå›¾ä¸Šçš„å¯è§£é‡Šé“¾æ¥é¢„æµ‹",
      "authors": [
        "Zifeng Ding",
        "Shenyang Huang",
        "Zeyu Cao",
        "Emma Kondrup",
        "Zachary Yang",
        "Xingyue Huang",
        "Yuan Sui",
        "Zhangdie Yuan",
        "Yuqicheng Zhu",
        "Xianglong Hu",
        "Yuan He",
        "Farimah Poursafaei",
        "Michael Bronstein",
        "Andreas Vlachos"
      ],
      "abstract": "Forecasting future links is a central task in temporal graph (TG) reasoning, requiring models to leverage historical interactions to predict upcoming ones. Traditional neural approaches, such as temporal graph neural networks, achieve strong performance but lack explainability and cannot be applied to unseen graphs without retraining. Recent studies have begun to explore using large language models (LLMs) for graph reasoning, but most of them are constrained to static graphs or small synthetic TGs and lack the evaluation of the quality of reasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced Learning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that fine-tunes LLMs to perform explainable link forecasting on real-world TGs. ReaL-TG uses outcome-based reward to encourage models to self-explore reasoning strategies from graph structure and to produce explanations that directly justify their predictions. To enable evaluation on LLM-generated reasoning traces, we propose a new evaluation protocol combining ranking metrics with an LLM-as-a-Judge system that assesses both the quality of reasoning and the impact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning Qwen3-4B under our framework, show that it outperforms much larger frontier LLMs, including GPT-5 mini, on ranking metrics, while producing high-quality explanations confirmed by both the LLM judge and human evaluation.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹æ—¶åºå›¾(Temporal Graphs, TG)æ¨ç†ä¸­ä¼ ç»Ÿç¥ç»æ–¹æ³•ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œä»¥åŠç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†çœŸå®ä¸–ç•ŒåŠ¨æ€å›¾æ—¶é¢ä¸´æ¨ç†è½¨è¿¹è´¨é‡éš¾ä»¥è¯„ä¼°çš„é—®é¢˜ï¼Œæå‡ºäº†ReaL-TGæ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æŠ€æœ¯å¾®è°ƒLLMsï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨çœŸå®ä¸–ç•ŒTGä¸Šæ‰§è¡Œå¯è§£é‡Šçš„é“¾è·¯é¢„æµ‹(Link Forecasting)ã€‚ReaL-TGé€šè¿‡åŸºäºç»“æœçš„å¥–åŠ±(Outcome-based Reward)æœºåˆ¶ï¼Œæ¿€åŠ±æ¨¡å‹ä»å›¾ç»“æ„ä¸­è‡ªä¸»æ¢ç´¢æ¨ç†ç­–ç•¥ï¼Œå¹¶ç”Ÿæˆèƒ½ç›´æ¥æ”¯æ’‘å…¶é¢„æµ‹ç»“æœçš„è§£é‡Šæ€§æ–‡æœ¬ã€‚ä¸ºäº†é‡åŒ–è¯„ä¼°æ¨ç†è´¨é‡ï¼Œç ”ç©¶è€…è¿˜æå‡ºäº†ä¸€å¥—ç»“åˆæ’åºæŒ‡æ ‡ä¸LLM-as-a-Judgeç³»ç»Ÿçš„å…¨æ–°è¯„ä¼°åè®®ï¼Œä¸“é—¨ç”¨äºæ£€æµ‹æ¨ç†é€»è¾‘åŠå¹»è§‰å½±å“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºQwen3-4Bå¾®è°ƒçš„ReaL-TG-4Båœ¨æ’åºæŒ‡æ ‡ä¸Šè¶…è¶Šäº†GPT-5 miniç­‰æ›´å¤§å‹çš„å‰æ²¿æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒLLMè¯„å§”ä¸äººå·¥è¯„ä¼°å‡è¯å®è¯¥æ¨¡å‹èƒ½äº§ç”Ÿé«˜è´¨é‡çš„è§£é‡Šï¼Œæ˜¾è‘—æå‡äº†æ—¶åºå›¾é¢„æµ‹ä»»åŠ¡çš„å¯ä¿¡åº¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00975v2",
      "published_date": "2025-08-31 19:47:01 UTC",
      "updated_date": "2025-10-13 02:09:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:35:44.085092+00:00"
    },
    {
      "arxiv_id": "2509.00973v1",
      "title": "Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation",
      "title_zh": "å…‹éš†æ— æ³•çªƒå–ä¹‹ç‰©ï¼šåŸºäº Logit æ³„éœ²ä¸è’¸é¦çš„é»‘ç›’å¤§è¯­è¨€æ¨¡å‹å¤åˆ»",
      "authors": [
        "Kanchon Gharami",
        "Hansaka Aluvihare",
        "Shafika Showkat Moni",
        "Berker PekÃ¶z"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in mission-critical systems, facilitating tasks such as satellite operations, command-and-control, military decision support, and cyber defense. Many of these systems are accessed through application programming interfaces (APIs). When such APIs lack robust access controls, they can expose full or top-k logits, creating a significant and often overlooked attack surface. Prior art has mainly focused on reconstructing the output projection layer or distilling surface-level behaviors. However, regenerating a black-box model under tight query constraints remains underexplored. We address that gap by introducing a constrained replication pipeline that transforms partial logit leakage into a functional deployable substitute model clone. Our two-stage approach (i) reconstructs the output projection matrix by collecting top-k logits from under 10k black-box queries via singular value decomposition (SVD) over the logits, then (ii) distills the remaining architecture into compact student models with varying transformer depths, trained on an open source dataset. A 6-layer student recreates 97.6% of the 6-layer teacher model's hidden-state geometry, with only a 7.31% perplexity increase, and a 7.58 Negative Log-Likelihood (NLL). A 4-layer variant achieves 17.1% faster inference and 18.1% parameter reduction with comparable performance. The entire attack completes in under 24 graphics processing unit (GPU) hours and avoids triggering API rate-limit defenses. These results demonstrate how quickly a cost-limited adversary can clone an LLM, underscoring the urgent need for hardened inference APIs and secure on-premise defense deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å—é™æŸ¥è¯¢æ¡ä»¶ä¸‹é€šè¿‡ API æ³„éœ²çš„ logit ä¿¡æ¯å¯¹é»‘ç›’å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œå…‹éš†çš„æ”»å‡»è·¯å¾„ã€‚ä½œè€…æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µçš„å—é™å¤åˆ¶æµæ°´çº¿ï¼Œé¦–å…ˆåˆ©ç”¨ä¸åˆ° 1 ä¸‡æ¬¡æŸ¥è¯¢è·å–çš„ top-k logitsï¼Œé€šè¿‡å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSingular Value Decomposition, SVDï¼‰é‡å»ºè¾“å‡ºæŠ•å½±çŸ©é˜µã€‚éšåï¼Œè¯¥æ–¹æ³•å°†é»‘ç›’æ¨¡å‹æ¶æ„è’¸é¦ä¸ºä¸åŒæ·±åº¦çš„ç´§å‡‘å‹å­¦ç”Ÿæ¨¡å‹ï¼Œå®éªŒè¯æ˜ 6 å±‚å­¦ç”Ÿæ¨¡å‹èƒ½é‡æ„æ•™å¸ˆæ¨¡å‹ 97.6% çš„éšè—çŠ¶æ€å‡ ä½•ç»“æ„ã€‚æ­¤å¤–ï¼Œ4 å±‚å˜ä½“åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å®ç°äº† 17.1% çš„æ¨ç†åŠ é€Ÿï¼Œä¸”æ•´ä¸ªæ”»å‡»è¿‡ç¨‹åœ¨ 24 ä¸ª GPU å°æ—¶å†…å³å¯å®Œæˆå¹¶è§„é¿ API é€Ÿç‡é™åˆ¶ã€‚è¿™é¡¹ç ”ç©¶æ­ç¤ºäº†ä½æˆæœ¬å¯¹æ‰‹å…‹éš† LLM çš„å¯è¡Œæ€§ä¸é€Ÿåº¦ï¼Œå¼ºè°ƒäº†å¼ºåŒ–æ¨ç† API å®‰å…¨æ€§åŠéƒ¨ç½²æœ¬åœ°é˜²å¾¡æªæ–½çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages. Accepted for publication in the proceedings of 7th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (IEEE TPS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.00973v1",
      "published_date": "2025-08-31 19:38:24 UTC",
      "updated_date": "2025-08-31 19:38:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:35:43.787765+00:00"
    },
    {
      "arxiv_id": "2509.00971v2",
      "title": "CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs",
      "title_zh": "CoreThinkï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹é•¿æ—¶ç¨‹ä»»åŠ¡çš„ç¬¦å·æ¨ç†å±‚",
      "authors": [
        "Jay Vaghasiya",
        "Omkar Ghugarkar",
        "Vishvesh Bhat",
        "Vipul Dholaria",
        "Julian McAuley"
      ],
      "abstract": "We introduce CoreThink, a state-of-the-art Reasoning Layer built upon a novel reasoning method called General Symbolics. This approach diverges from reasoning paradigms such as test-time scaling, Supervised Fine-Tuning (SFT), and Reinforcement Learning with Verifiable Rewards (RLVR). CoreThink General Symbolic Reasoner (GSR) is specifically structured around three key use cases: tool-calling, code generation, and planning, demonstrating exemplary performance across a total of seven benchmarks in their respective areas. Notably, we are achieving SOTA scores of 66.66% on Livecodebench v6, 89% on Instruction-Following Evals, and 24.4% on ARC-AGI-2. We also present an agentic coding IDE, developed using the principles of General Symbolics, which achieves a state-of-the-art accuracy of 62.3% on SWE-Bench Lite. We are able to achieve these improvements without any fine-tuning or training costs. Our Reasoning Layer is designed to provide a pure performance uplift, ensuring that a model's accuracy on reasoning tasks is never negatively impacted. We argue that incumbent methods will eventually lead to diminishing returns in LLM performance, necessitating the development of new reasoning techniques. This technical report details our approach at a high level and the availability of the CoreThink models for reasoning-intensive use cases.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† CoreThinkï¼Œè¿™æ˜¯ä¸€ç§åŸºäºåä¸º General Symbolics çš„åˆ›æ–°æ¨ç†æ–¹æ³•æ„å»ºçš„æœ€å…ˆè¿›æ¨ç†å±‚ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹å¤„ç†é•¿ç¨‹ä»»åŠ¡ï¼ˆLong Horizon Tasksï¼‰çš„èƒ½åŠ›ã€‚ä¸ç°æœ‰çš„æµ‹è¯•æ—¶æ‰©å±•ã€ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¸¦æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ç­‰èŒƒå¼ä¸åŒï¼ŒCoreThink çš„é€šç”¨ç¬¦å·æ¨ç†å™¨ä¸“é—¨é’ˆå¯¹å·¥å…·è°ƒç”¨ã€ä»£ç ç”Ÿæˆå’Œè§„åˆ’ä¸‰å¤§åœºæ™¯è¿›è¡Œäº†ç»“æ„åŒ–è®¾è®¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ Livecodebench v6ã€Instruction-Following Evals ä»¥åŠ ARC-AGI-2 ç­‰å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†é¢†å…ˆçš„ SOTA æˆç»©ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨è¯¥åŸç†å¼€å‘çš„æ™ºèƒ½ç¼–ç  IDE åœ¨ SWE-Bench Lite ä¸Šè¾¾åˆ°äº† 62.3% çš„å‡†ç¡®ç‡ã€‚å…³é”®åœ¨äºï¼ŒCoreThink çš„æ€§èƒ½æå‡æ— éœ€ä»»ä½•å¾®è°ƒæˆ–è®­ç»ƒæˆæœ¬ï¼Œç¡®ä¿åœ¨æ˜¾è‘—å¢å¼ºæ¨ç†ä»»åŠ¡å‡†ç¡®æ€§çš„åŒæ—¶ä¸ä¼šå¯¹æ¨¡å‹äº§ç”Ÿè´Ÿé¢å½±å“ã€‚è¯¥ç ”ç©¶é€šè¿‡æŠ€æœ¯æŠ¥å‘Šå±•ç¤ºäº†åœ¨ä¼ ç»Ÿæ–¹æ³•è¾¹é™…æ•ˆç›Šé€’å‡çš„èƒŒæ™¯ä¸‹ï¼ŒGeneral Symbolics ä¸ºæ¨ç†å¯†é›†å‹åº”ç”¨æä¾›çš„ä¸€ç§é«˜æ•ˆä¸”é«˜æ€§èƒ½çš„æ–°å‹æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00971v2",
      "published_date": "2025-08-31 19:31:53 UTC",
      "updated_date": "2025-09-03 05:36:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:35:51.791957+00:00"
    },
    {
      "arxiv_id": "2509.00963v1",
      "title": "Who Gets Left Behind? Auditing Disability Inclusivity in Large Language Models",
      "title_zh": "è°è¢«é—å¿˜äº†ï¼Ÿå¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ®‹éšœåŒ…å®¹æ€§å®¡è®¡",
      "authors": [
        "Deepika Dash",
        "Yeshil Bangera",
        "Mithil Bangera",
        "Gouthami Vadithya",
        "Srikant Panda"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used for accessibility guidance, yet many disability groups remain underserved by their advice. To address this gap, we present taxonomy aligned benchmark1 of human validated, general purpose accessibility questions, designed to systematically audit inclusivity across disabilities. Our benchmark evaluates models along three dimensions: Question-Level Coverage (breadth within answers), Disability-Level Coverage (balance across nine disability categories), and Depth (specificity of support). Applying this framework to 17 proprietary and open-weight models reveals persistent inclusivity gaps: Vision, Hearing, and Mobility are frequently addressed, while Speech, Genetic/Developmental, Sensory-Cognitive, and Mental Health remain under served. Depth is similarly concentrated in a few categories but sparse elsewhere. These findings reveal who gets left behind in current LLM accessibility guidance and highlight actionable levers: taxonomy-aware prompting/training and evaluations that jointly audit breadth, balance, and depth.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æä¾›æ— éšœç¢å»ºè®®æ—¶å¯¹ä¸åŒæ®‹éšœç¾¤ä½“åŒ…å®¹æ€§ä¸è¶³çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªåŸºäºåˆ†ç±»æ³•(taxonomy)å¯¹é½çš„benchmarkï¼Œç”¨äºç³»ç»Ÿå®¡è®¡è·¨æ®‹éšœç±»åˆ«çš„åŒ…å®¹æ€§ã€‚è¯¥benchmarké€šè¿‡é—®é¢˜çº§è¦†ç›–åº¦(Question-Level Coverage)ã€æ®‹éšœçº§åˆ«è¦†ç›–åº¦(Disability-Level Coverage)å’Œæ·±åº¦(Depth)ä¸‰ä¸ªç»´åº¦ï¼Œå¯¹17ä¸ªå•†ä¸šå’Œå¼€æºæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚ç ”ç©¶å‘ç°å½“å‰çš„LLMså­˜åœ¨æ˜¾è‘—çš„åŒ…å®¹æ€§å·®è·ï¼šè§†è§‰(Vision)ã€å¬è§‰(Hearing)å’Œè‚¢ä½“è¡ŒåŠ¨(Mobility)å¾—åˆ°çš„å…³æ³¨è¾ƒå¤šï¼Œè€Œè¨€è¯­(Speech)ã€é—ä¼ /å‘è‚²(Genetic/Developmental)ã€æ„Ÿè§‰-è®¤çŸ¥(Sensory-Cognitive)å’Œå¿ƒç†å¥åº·(Mental Health)ç¾¤ä½“ä»å¤„äºæœåŠ¡ä¸è¶³çš„çŠ¶æ€ã€‚å®éªŒç»“æœæ˜¾ç¤ºæ”¯æŒçš„æ·±åº¦åŒæ ·åˆ†å¸ƒä¸å‡ï¼Œæ­ç¤ºäº†å½“å‰æ— éšœç¢æŒ‡å¯¼ä¸­çš„é—ç•™ç¾¤ä½“ã€‚æœ€åï¼Œç ”ç©¶æŒ‡å‡ºåˆ†ç±»æ³•æ„ŸçŸ¥æç¤º(taxonomy-aware prompting)å’Œå¤šç»´åº¦ç»¼åˆè¯„ä»·æ˜¯æ”¹å–„LLMsæ®‹éšœåŒ…å®¹æ€§çš„å…³é”®æ–¹å‘ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00963v1",
      "published_date": "2025-08-31 19:12:01 UTC",
      "updated_date": "2025-08-31 19:12:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:35:58.792420+00:00"
    },
    {
      "arxiv_id": "2509.00961v1",
      "title": "Ultra Strong Machine Learning: Teaching Humans Active Learning Strategies via Automated AI Explanations",
      "title_zh": "è¶…å¼ºæœºå™¨å­¦ä¹ ï¼šé€šè¿‡ AI è‡ªåŠ¨è§£é‡Šå‘äººç±»ä¼ æˆä¸»åŠ¨å­¦ä¹ ç­–ç•¥",
      "authors": [
        "Lun Ai",
        "Johannes Langer",
        "Ute Schmid",
        "Stephen Muggleton"
      ],
      "abstract": "Ultra Strong Machine Learning (USML) refers to symbolic learning systems that not only improve their own performance but can also teach their acquired knowledge to quantifiably improve human performance. In this work, we present LENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic method that combines symbolic program synthesis with large language models (LLMs) to automate the explanation of machine-learned logic programs in natural language. LENS addresses a key limitation of prior USML approaches by replacing hand-crafted explanation templates with scalable automated generation. Through systematic evaluation using multiple LLM judges and human validation, we demonstrate that LENS generates superior explanations compared to direct LLM prompting and hand-crafted templates. To investigate whether LENS can teach transferable active learning strategies, we carried out a human learning experiment across three related domains. Our results show no significant human performance improvements, suggesting that comprehensive LLM responses may overwhelm users for simpler problems rather than providing learning support. Our work provides a solid foundation for building effective USML systems to support human learning. The source code is available on: https://github.com/lun-ai/LENS.git.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Ultra Strong Machine Learning (USML) é¢†åŸŸï¼Œæå‡ºäº†LENS (Logic Programming Explanation via Neural Summarisation) è¿™ä¸€ç¥ç»ç¬¦å· (neuro-symbolic) æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡è‡ªåŠ¨åŒ–AIè§£é‡Šæ¥æå‡äººç±»çš„å­¦ä¹ èƒ½åŠ›ã€‚LENSç»“åˆäº†ç¬¦å·ç¨‹åºåˆæˆ (symbolic program synthesis) ä¸å¤§è¯­è¨€æ¨¡å‹ (LLMs)ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å°†æœºå™¨å­¦ä¹ çš„é€»è¾‘ç¨‹åºè½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€ï¼Œæœ‰æ•ˆè§£å†³äº†ä»¥å¾€ç³»ç»Ÿä¾èµ–æ‰‹å·¥æ¨¡æ¿ä¸”éš¾ä»¥æ‰©å±•çš„ç“¶é¢ˆã€‚ç³»ç»Ÿè¯„ä¼°è¯æ˜ï¼ŒLENSç”Ÿæˆçš„è§£é‡Šåœ¨è´¨é‡ä¸Šä¼˜äºç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹æç¤ºæˆ–é¢„è®¾æ¨¡æ¿ã€‚é€šè¿‡åœ¨ä¸‰ä¸ªç›¸å…³é¢†åŸŸçš„äººç±»å­¦ä¹ å®éªŒå‘ç°ï¼Œäººç±»åœ¨ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ä¸Šçš„è¡¨ç°å¹¶æœªå› AIè§£é‡Šè€Œæ˜¾è‘—æå‡ï¼Œè¿™æš—ç¤ºè¿‡äºè¯¦å°½çš„LLMå›å¤åœ¨å¤„ç†ç®€å•é—®é¢˜æ—¶å¯èƒ½åè€Œè®©ç”¨æˆ·æ„Ÿåˆ°è´Ÿæ‹…ã€‚è¯¥é¡¹å·¥ä½œä¸ºæ„å»ºèƒ½å¤ŸçœŸæ­£è¾…åŠ©äººç±»å­¦ä¹ çš„æœ‰æ•ˆUSMLç³»ç»Ÿæä¾›äº†é‡è¦çš„ç†è®ºä¸å®è¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00961v1",
      "published_date": "2025-08-31 19:04:31 UTC",
      "updated_date": "2025-08-31 19:04:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:36:22.600574+00:00"
    },
    {
      "arxiv_id": "2509.00958v1",
      "title": "A Hybrid Ai Framework For Strategic Patent Portfolio Pruning: Integrating Learning To-Rank And Market Need Analysis For Technology Transfer Optimization",
      "title_zh": "ç”¨äºæˆ˜ç•¥æ€§ä¸“åˆ©ç»„åˆç²¾ç®€çš„æ··åˆäººå·¥æ™ºèƒ½æ¡†æ¶ï¼šæ•´åˆæ’åºå­¦ä¹ ä¸å¸‚åœºéœ€æ±‚åˆ†æä»¥ä¼˜åŒ–æŠ€æœ¯è½¬ç§»",
      "authors": [
        "Manish Verma",
        "Vivek Sharma",
        "Vishal Singh"
      ],
      "abstract": "This paper introduces a novel, multi stage hybrid intelligence framework for pruning patent portfolios to identify high value assets for technology transfer. Current patent valuation methods often rely on retrospective indicators or manual, time intensive analysis. Our framework automates and deepens this process by combining a Learning to Rank (LTR) model, which evaluates patents against over 30 legal and commercial parameters, with a unique \"Need-Seed\" agent-based system. The \"Need Agent\" uses Natural Language Processing (NLP) to mine unstructured market and industry data, identifying explicit technological needs. Concurrently, the \"Seed Agent\" employs fine tuned Large Language Models (LLMs) to analyze patent claims and map their technological capabilities. The system generates a \"Core Ontology Framework\" that matches high potential patents (Seeds) to documented market demands (Needs), providing a strategic rationale for divestment decisions. We detail the architecture, including a dynamic parameter weighting system and a crucial Human in the-Loop (HITL) validation protocol, to ensure both adaptability and real-world credibility.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šé˜¶æ®µæ··åˆæ™ºèƒ½æ¡†æ¶ï¼Œç”¨äºæˆ˜ç•¥æ€§ä¸“åˆ©ç»„åˆä¿®å‰ª(patent portfolio pruning)ï¼Œæ—¨åœ¨è¯†åˆ«é«˜ä»·å€¼èµ„äº§ä»¥ä¼˜åŒ–æŠ€æœ¯è½¬ç§»ã€‚è¯¥æ¡†æ¶ç»“åˆäº†æ’åºå­¦ä¹ (Learning to Rank, LTR)æ¨¡å‹ï¼Œé€šè¿‡è¶…è¿‡30é¡¹æ³•å¾‹å’Œå•†ä¸šå‚æ•°å¯¹ä¸“åˆ©è¿›è¡Œè¯„ä¼°ã€‚ç³»ç»Ÿæ ¸å¿ƒé‡‡ç”¨äº†ç‹¬ç‰¹çš„â€œéœ€æ±‚-ç§å­â€(Need-Seed)æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œåˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†(NLP)æŒ–æ˜å¸‚åœºæ•°æ®ä¸­çš„æŠ€æœ¯éœ€æ±‚ï¼Œå¹¶ä½¿ç”¨å¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹(LLMs)åˆ†æä¸“åˆ©æƒåˆ©è¦æ±‚ã€‚é€šè¿‡æ„å»ºâ€œæ ¸å¿ƒæœ¬ä½“æ¡†æ¶â€(Core Ontology Framework)ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†é«˜æ½œåŠ›ä¸“åˆ©ä¸å¸‚åœºéœ€æ±‚çš„ç²¾å‡†åŒ¹é…ï¼Œä¸ºä¸“åˆ©å‰¥ç¦»å†³ç­–æä¾›äº†æˆ˜ç•¥ä¾æ®ã€‚æ­¤å¤–ï¼Œæ¡†æ¶è¿˜é›†æˆäº†åŠ¨æ€å‚æ•°æƒé‡ç³»ç»Ÿå’Œäººæœºå›ç¯(Human-in-the-Loop, HITL)éªŒè¯åè®®ï¼Œåœ¨è‡ªåŠ¨åŒ–å¤„ç†çš„åŒæ—¶ç¡®ä¿äº†è¯„ä¼°ç»“æœçš„ç°å®å¯ä¿¡åº¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: This version has been removed by arXiv administrators as the submitter did not have the right to agree to the license at the time of submission",
      "pdf_url": "https://arxiv.org/pdf/2509.00958v1",
      "published_date": "2025-08-31 18:43:18 UTC",
      "updated_date": "2025-08-31 18:43:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:36:03.794254+00:00"
    },
    {
      "arxiv_id": "2509.00955v1",
      "title": "ART: Adaptive Resampling-based Training for Imbalanced Classification",
      "title_zh": "ARTï¼šé¢å‘ä¸å¹³è¡¡åˆ†ç±»çš„è‡ªé€‚åº”é‡é‡‡æ ·è®­ç»ƒ",
      "authors": [
        "Arjun Basandrai",
        "Shourya Jain",
        "K. Ilanthenral"
      ],
      "abstract": "Traditional resampling methods for handling class imbalance typically uses fixed distributions, undersampling the majority or oversampling the minority. These static strategies ignore changes in class-wise learning difficulty, which can limit the overall performance of the model.\n  This paper proposes an Adaptive Resampling-based Training (ART) method that periodically updates the distribution of the training data based on the class-wise performance of the model. Specifically, ART uses class-wise macro F1 scores, computed at fixed intervals, to determine the degree of resampling to be performed.\n  Unlike instance-level difficulty modeling, which is noisy and outlier-sensitive, ART adapts at the class level. This allows the model to incrementally shift its attention towards underperforming classes in a way that better aligns with the optimization objective.\n  Results on diverse benchmarks, including Pima Indians Diabetes and Yeast dataset demonstrate that ART consistently outperforms both resampling-based and algorithm-level methods, including Synthetic Minority Oversampling Technique (SMOTE), NearMiss Undersampling, and Cost-sensitive Learning on binary as well as multi-class classification tasks with varying degrees of imbalance.\n  In most settings, these improvements are statistically significant. On tabular datasets, gains are significant under paired t-tests and Wilcoxon tests (p < 0.05), while results on text and image tasks remain favorable. Compared to training on the original imbalanced data, ART improves macro F1 by an average of 2.64 percentage points across all tested tabular datasets. Unlike existing methods, whose performance varies by task, ART consistently delivers the strongest macro F1, making it a reliable choice for imbalanced classification.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Adaptive Resampling-based Training (ART) çš„è‡ªé€‚åº”é‡é‡‡æ ·è®­ç»ƒæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå›ºå®šåˆ†å¸ƒé‡é‡‡æ ·å¿½è§†ç±»åˆ«å­¦ä¹ éš¾åº¦åŠ¨æ€å˜åŒ–çš„é—®é¢˜ã€‚ART é€šè¿‡å®šæœŸæ ¹æ®ç±»åˆ«çš„ macro F1 scores æ›´æ–°è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®å®æ—¶æ€§èƒ½è¡¨ç°åŠ¨æ€è°ƒæ•´å¯¹æ¬ ä½³ç±»åˆ«çš„å…³æ³¨åº¦ã€‚ä¸æ˜“å—å™ªå£°å’Œç¦»ç¾¤å€¼å½±å“çš„å®ä¾‹çº§å»ºæ¨¡ä¸åŒï¼ŒART åœ¨ç±»åˆ«å±‚çº§ (class level) è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ï¼Œä»è€Œä½¿è®­ç»ƒè¿‡ç¨‹ä¸ä¼˜åŒ–ç›®æ ‡æ›´å¥½åœ°å¯¹é½ã€‚åœ¨ Pima Indians Diabetes å’Œ Yeast ç­‰å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒART åœ¨å¤„ç†ä¸åŒç¨‹åº¦çš„ä¸å¹³è¡¡åˆ†ç±» (Imbalanced Classification) ä»»åŠ¡æ—¶ï¼Œå…¶è¡¨ç°ä¸€è‡´ä¼˜äº Synthetic Minority Oversampling Technique (SMOTE)ã€NearMiss Undersampling å’Œ Cost-sensitive Learning ç­‰ä¼ ç»Ÿæ–¹æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒART åœ¨è¡¨æ ¼æ•°æ®é›†ä¸Šå°†å¹³å‡ macro F1 æå‡äº† 2.64 ä¸ªç™¾åˆ†ç‚¹ï¼Œä¸”åœ¨ç»Ÿè®¡å­¦ä¸Šå…·æœ‰æ˜¾è‘—æ„ä¹‰ã€‚è¯¥ç ”ç©¶è¯æ˜äº† ART åœ¨æ–‡æœ¬ã€å›¾åƒåŠè¡¨æ ¼ç­‰å¤šç§ä»»åŠ¡ä¸­å‡å…·æœ‰å¼ºå¤§çš„ç¨³å¥æ€§å’Œå¯é æ€§ï¼Œæ˜¯è§£å†³ä¸å¹³è¡¡åˆ†ç±»é—®é¢˜çš„æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to SIGKDD'26",
      "pdf_url": "https://arxiv.org/pdf/2509.00955v1",
      "published_date": "2025-08-31 18:20:55 UTC",
      "updated_date": "2025-08-31 18:20:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:36:10.594272+00:00"
    },
    {
      "arxiv_id": "2509.00949v1",
      "title": "Structure and Destructure: Dual Forces in the Making of Knowledge Engines",
      "title_zh": "ç»“æ„ä¸è§£æ„ï¼šæ„å»ºçŸ¥è¯†å¼•æ“çš„åŒé‡åŠ›é‡",
      "authors": [
        "Yihong Chen"
      ],
      "abstract": "The making of knowledge engines in natural language processing has been shaped by two seemingly distinct paradigms: one grounded in structure, the other driven by massively available unstructured data. The structured paradigm leverages predefined symbolic interactions, such as knowledge graphs, as priors and designs models to capture them. In contrast, the unstructured paradigm centers on scaling transformer architectures with increasingly vast data and model sizes, as seen in modern large language models. Despite their divergence, this thesis seeks to establish conceptual connections bridging these paradigms. Two complementary forces, structure and destructure, emerge across both paradigms: structure organizes seen symbolic interactions, while destructure, through periodic embedding resets, improves model plasticity and generalization to unseen scenarios. These connections form a new recipe for developing general knowledge engines that can support transparent, controllable, and adaptable intelligent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è‡ªç„¶è¯­è¨€å¤„ç†ä¸­æ„å»ºçŸ¥è¯†å¼•æ“çš„ä¸¤å¤§ä¸»æµèŒƒå¼ï¼Œå³åŸºäºç¬¦å·äº¤äº’ï¼ˆå¦‚çŸ¥è¯†å›¾è°±ï¼‰çš„ç»“æ„åŒ–èŒƒå¼ä¸åŸºäºå¤§è§„æ¨¡æ— ç»“æ„æ•°æ®æ‰©å±•çš„éç»“æ„åŒ–èŒƒå¼ã€‚è®ºæ–‡åœ¨ä¸¤ç§èŒƒå¼ä¹‹é—´å»ºç«‹äº†æ¦‚å¿µçº½å¸¦ï¼Œå¹¶æå‡ºäº† **structure** ä¸ **destructure** ä¸¤ç§äº’è¡¥åŠ›é‡ï¼š**structure** ç”¨äºç»„ç»‡å·²è§çš„ç¬¦å·äº¤äº’ï¼Œè€Œ **destructure** åˆ™é€šè¿‡å‘¨æœŸæ€§çš„ Embedding é‡ç½®ï¼ˆembedding resetsï¼‰æ¥æå‡æ¨¡å‹çš„å¡‘æ€§ï¼ˆplasticityï¼‰ä»¥åŠå¯¹æœªçŸ¥åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›å…³è”ä¸ºå¼€å‘é€šç”¨çš„çŸ¥è¯†å¼•æ“æä¾›äº†å…¨æ–°æ–¹æ¡ˆï¼Œæ—¨åœ¨æ”¯æŒæ„å»ºæ›´åŠ é€æ˜ã€å¯æ§ä¸”å…·å¤‡é€‚åº”æ€§çš„æ™ºèƒ½ç³»ç»Ÿã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "PhD thesis. https://discovery.ucl.ac.uk/id/eprint/10211291/",
      "pdf_url": "https://arxiv.org/pdf/2509.00949v1",
      "published_date": "2025-08-31 17:57:20 UTC",
      "updated_date": "2025-08-31 17:57:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:36:19.981565+00:00"
    },
    {
      "arxiv_id": "2509.12213v1",
      "title": "Scaling Up Data Parallelism in Decentralized Deep Learning",
      "title_zh": "å»ä¸­å¿ƒåŒ–æ·±åº¦å­¦ä¹ ä¸­æ•°æ®å¹¶è¡Œçš„è§„æ¨¡æ‰©å±•",
      "authors": [
        "Bing Xie",
        "Junqi Yin",
        "Zhenyu Zhou",
        "Sarp Oral",
        "Feiyi Wang"
      ],
      "abstract": "Although it has been extensively explored in theory, decentralized learning is not yet green-lighted for production use, largely due to a lack of stability, scalability, and generality in large scale DNN training. To shed light on the production use of decentralized learning, this work studies decentralized data parallel training at scale. To this end, we introduce a benchmarking framework, namely DBench, to host both centralized and decentralized DNN training. Building upon DBench, we introduce a benchmarking methodology to uncover the correlations between model accuracy and the variances of parameter tensors by varying communication graphs and training scales. Based on the benchmarking results, we observe that, (1) Similar to centralized learning, decentralized data parallel training also presents the issues of scalability and generality when the training scales up; (2) The model accuracy of decentralized learning is correlated to the number of connections in a communication graph; (3) The model accuracy of decentralized learning is surprisingly sensitive to the variance of parameter tensors across model replicas. Built upon the observations, we propose Ada, a decentralized adaptive approach that performs large scale DNN training following a decentralized SGD method and adapting the communication graph in use dynamically throughout training iterations. We apply Ada on large scale training and observe that Ada can obtain the best convergence rates consistently in decentralized DNN training, and delivers equally or comparably good model accuracy for all sample applications as centralized learning does, even when training ResNet50 for ImageNet-1K on the scale of 1008 GPUs.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å»ä¸­å¿ƒåŒ–æ·±åº¦å­¦ä¹ åœ¨ç”Ÿäº§ç¯å¢ƒä¸‹ç¨³å®šæ€§ä¸å¯æ‰©å±•æ€§ä¸è¶³çš„é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥åŸºå‡†æµ‹è¯•æ¡†æ¶ DBench ç³»ç»Ÿç ”ç©¶äº†å¤§è§„æ¨¡å»ä¸­å¿ƒåŒ–æ•°æ®å¹¶è¡Œ(data parallel)è®­ç»ƒã€‚ç ”ç©¶æ­ç¤ºäº†å»ä¸­å¿ƒåŒ–å­¦ä¹ çš„å‡†ç¡®ç‡ä¸é€šä¿¡å›¾è¿æ¥æ•°åŠå‚æ•°å¼ é‡(parameter tensors)æ–¹å·®ä¹‹é—´çš„ç´§å¯†å…³è”ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œä½œè€…æå‡ºäº†ä¸€ç§è‡ªé€‚åº”å»ä¸­å¿ƒåŒ–æ–¹æ³• Adaï¼Œè¯¥æ–¹æ³•é‡‡ç”¨å»ä¸­å¿ƒåŒ– SGD å¹¶åœ¨è®­ç»ƒè¿­ä»£ä¸­æ ¹æ®çŠ¶æ€åŠ¨æ€è°ƒæ•´é€šä¿¡å›¾ã€‚å®éªŒè¡¨æ˜ï¼ŒAda åœ¨å„ç§ä»»åŠ¡ä¸­å‡èƒ½ä¿æŒä¼˜å¼‚çš„æ”¶æ•›é€Ÿåº¦ï¼Œå¹¶èƒ½æä¾›ä¸ä¸­å¿ƒåŒ–å­¦ä¹ ç›¸åª²ç¾çš„æ¨¡å‹å‡†ç¡®ç‡ã€‚ç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨ 1008 ä¸ª GPU å¯¹ ResNet50 è¿›è¡Œ ImageNet-1K è®­ç»ƒçš„å¤§è§„æ¨¡åœºæ™¯ä¸‹ï¼ŒAda ä¾ç„¶è¡¨ç°å“è¶Šï¼Œæœ‰æ•ˆæå‡äº†å»ä¸­å¿ƒåŒ–æ·±åº¦å­¦ä¹ åœ¨å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä¸­çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12213v1",
      "published_date": "2025-08-31 17:34:52 UTC",
      "updated_date": "2025-08-31 17:34:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:36:17.100707+00:00"
    },
    {
      "arxiv_id": "2509.05330v1",
      "title": "MVRS: The Multimodal Virtual Reality Stimuli-based Emotion Recognition Dataset",
      "title_zh": "MVRSï¼šåŸºäºå¤šæ¨¡æ€è™šæ‹Ÿç°å®åˆºæ¿€çš„æƒ…æ„Ÿè¯†åˆ«æ•°æ®é›†",
      "authors": [
        "Seyed Muhammad Hossein Mousavi",
        "Atiye Ilanloo"
      ],
      "abstract": "Automatic emotion recognition has become increasingly important with the rise of AI, especially in fields like healthcare, education, and automotive systems. However, there is a lack of multimodal datasets, particularly involving body motion and physiological signals, which limits progress in the field. To address this, the MVRS dataset is introduced, featuring synchronized recordings from 13 participants aged 12 to 60 exposed to VR based emotional stimuli (relaxation, fear, stress, sadness, joy). Data were collected using eye tracking (via webcam in a VR headset), body motion (Kinect v2), and EMG and GSR signals (Arduino UNO), all timestamp aligned. Participants followed a unified protocol with consent and questionnaires. Features from each modality were extracted, fused using early and late fusion techniques, and evaluated with classifiers to confirm the datasets quality and emotion separability, making MVRS a valuable contribution to multimodal affective computing.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† MVRS æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€è™šæ‹Ÿç°å®åˆºæ¿€ï¼ˆVirtual Reality Stimuliï¼‰çš„æƒ…æ„Ÿè¯†åˆ«æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³é¢†åŸŸå†…ç¼ºä¹ç»“åˆè‚¢ä½“è¿åŠ¨ï¼ˆBody motionï¼‰ä¸ç”Ÿç†ä¿¡å·ï¼ˆPhysiological signalsï¼‰æ•°æ®é›†çš„é—®é¢˜ã€‚ç ”ç©¶è®°å½•äº† 13 åå¹´é¾„åœ¨ 12 è‡³ 60 å²ä¹‹é—´çš„å‚ä¸è€…åœ¨é¢å¯¹æ”¾æ¾ã€ææƒ§ã€å‹åŠ›ã€æ‚²ä¼¤å’Œå–œæ‚¦äº”ç§ VR æƒ…æ„Ÿåˆºæ¿€æ—¶çš„åŒæ­¥ååº”ã€‚æ•°æ®é‡‡é›†æ¶µç›–äº†çœ¼åŠ¨è¿½è¸ªï¼ˆEye trackingï¼‰ã€é€šè¿‡ Kinect v2 è·å–çš„è‚¢ä½“è¿åŠ¨ï¼Œä»¥åŠåˆ©ç”¨ Arduino UNO è®°å½•çš„ EMG å’Œ GSR ç”Ÿç†ä¿¡å·ï¼Œå¹¶å®ç°äº†ä¸¥æ ¼çš„æ—¶é—´æˆ³å¯¹é½ã€‚ç ”ç©¶å›¢é˜Ÿæå–äº†å„æ¨¡æ€ç‰¹å¾ï¼Œé€šè¿‡æ—©æœŸèåˆï¼ˆEarly fusionï¼‰å’ŒåæœŸèåˆï¼ˆLate fusionï¼‰æŠ€æœ¯ï¼Œå¹¶ç»“åˆåˆ†ç±»å™¨éªŒè¯äº†æ•°æ®é›†çš„è´¨é‡åŠæƒ…æ„Ÿå¯åˆ†æ€§ã€‚å®éªŒç»“æœè¯æ˜äº† MVRS çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåŒ»ç–—ã€æ•™è‚²å’Œæ±½è½¦ç³»ç»Ÿç­‰å¤šæ¨¡æ€æƒ…æ„Ÿè®¡ç®—ï¼ˆMultimodal affective computingï¼‰åº”ç”¨åœºæ™¯æä¾›äº†é‡è¦çš„ç ”ç©¶åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05330v1",
      "published_date": "2025-08-31 17:20:53 UTC",
      "updated_date": "2025-08-31 17:20:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:36:57.849940+00:00"
    },
    {
      "arxiv_id": "2509.00936v1",
      "title": "UrbanInsight: A Distributed Edge Computing Framework with LLM-Powered Data Filtering for Smart City Digital Twins",
      "title_zh": "UrbanInsightï¼šé¢å‘æ™ºæ…§åŸå¸‚æ•°å­—å­ªç”Ÿã€åŸºäºå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨æ•°æ®è¿‡æ»¤çš„åˆ†å¸ƒå¼è¾¹ç¼˜è®¡ç®—æ¡†æ¶",
      "authors": [
        "Kishor Datta Gupta",
        "Md Manjurul Ahsan",
        "Mohd Ariful Haque",
        "Roy George",
        "Azmine Toushik Wasi"
      ],
      "abstract": "Cities today generate enormous streams of data from sensors, cameras, and connected infrastructure. While this information offers unprecedented opportunities to improve urban life, most existing systems struggle with scale, latency, and fragmented insights. This work introduces a framework that blends physics-informed machine learning, multimodal data fusion, and knowledge graph representation with adaptive, rule-based intelligence powered by large language models (LLMs). Physics-informed methods ground learning in real-world constraints, ensuring predictions remain meaningful and consistent with physical dynamics. Knowledge graphs act as the semantic backbone, integrating heterogeneous sensor data into a connected, queryable structure. At the edge, LLMs generate context-aware rules that adapt filtering and decision-making in real time, enabling efficient operation even under constrained resources. Together, these elements form a foundation for digital twin systems that go beyond passive monitoring to provide actionable insights. By uniting physics-based reasoning, semantic data fusion, and adaptive rule generation, this approach opens new possibilities for creating responsive, trustworthy, and sustainable smart infrastructures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† UrbanInsightï¼Œä¸€ç§é’ˆå¯¹æ™ºæ…§åŸå¸‚æ•°å­—å­ªç”Ÿ (Smart City Digital Twins) çš„åˆ†å¸ƒå¼è¾¹ç¼˜è®¡ç®— (Distributed Edge Computing) æ¡†æ¶ã€‚è¯¥æ–¹æ¡ˆæ—¨åœ¨åº”å¯¹åŸå¸‚æµ·é‡ä¼ æ„Ÿå™¨æ•°æ®æµå¸¦æ¥çš„æ‰©å±•æ€§ã€é«˜å»¶è¿Ÿä»¥åŠç¢ç‰‡åŒ–åˆ†ææŒ‘æˆ˜ã€‚æ¡†æ¶æ ¸å¿ƒé›†æˆäº†ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹  (Physics-informed Machine Learning) ä¸çŸ¥è¯†å›¾è°± (Knowledge Graphs) æŠ€æœ¯ï¼Œç¡®ä¿æ•°æ®é¢„æµ‹ç¬¦åˆç‰©ç†çº¦æŸå¹¶å®ç°å¼‚æ„ä¿¡æ¯çš„è¯­ä¹‰ç»Ÿä¸€ã€‚å…¶ç‹¬ç‰¹ä¹‹å¤„åœ¨äºåˆ©ç”¨è¾¹ç¼˜ä¾§çš„å¤§è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è‡ªé€‚åº”è¿‡æ»¤è§„åˆ™ï¼Œæ˜¾è‘—æå‡äº†èµ„æºå—é™ç¯å¢ƒä¸‹çš„å®æ—¶å†³ç­–èƒ½åŠ›ã€‚UrbanInsight æˆåŠŸå°†æ•°å­—å­ªç”Ÿç³»ç»Ÿä»ç®€å•çš„è¢«åŠ¨ç›‘æ§æå‡è‡³æä¾›å¯æ“ä½œæ´å¯Ÿçš„é«˜åº¦ã€‚é€šè¿‡èåˆç‰©ç†æ¨ç†ã€è¯­ä¹‰æ•°æ®èåˆä¸è‡ªé€‚åº”è§„åˆ™ç”ŸæˆæŠ€æœ¯ï¼Œè¯¥æ¡†æ¶ä¸ºæ„å»ºå“åº”è¿…é€Ÿã€å¯ä¿¡ä¸”å¯æŒç»­çš„æ™ºèƒ½åŸå¸‚åŸºç¡€è®¾æ–½æä¾›äº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00936v1",
      "published_date": "2025-08-31 17:10:31 UTC",
      "updated_date": "2025-08-31 17:10:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:13.156559+00:00"
    },
    {
      "arxiv_id": "2509.00935v1",
      "title": "SCOUT: Toward Sub-Quadratic Attention via Segment Compression for Optimized Utility in Transformers",
      "title_zh": "SCOUTï¼šé€šè¿‡åˆ†æ®µå‹ç¼©å®ç° Transformer çš„æ¬¡äºŒæ¬¡æ³¨æ„åŠ›ä¸æ•ˆç”¨ä¼˜åŒ–",
      "authors": [
        "Aref Jafari",
        "Yuhe Fan",
        "Benyamin Jamialahmadi",
        "Parsa Farinneya",
        "Boxing Chen",
        "Marzieh S. Tahaei"
      ],
      "abstract": "Transformers have demonstrated strong performance across a wide range of sequence modeling tasks, but their quadratic attention complexity limits scalability to long sequences. Linear models such as Mamba and sliding-window attention (SWA) address this by mixing tokens through recurrent or localized operations with fixed-size memory, achieving efficient inference. However, these methods risk degrading performance on long sequences due to their inability to retain detailed information from distant tokens. We propose SCOUT (Segment Compression for Optimized Utility in Transformers), a hybrid architecture that compresses tokens locally within fixed-size segments and applies attention only over these compressed representations. Each token embedding is first enriched via a linear local mixer, Mamba or SWA, that integrates recent context. Then, instead of attending to all previous tokens, each token sparsely attends to a small number of compressed checkpoint tokens that summarize the input history. This design retains much of the expressivity of full attention while substantially reducing the computational and memory cost. By attending to compressed history rather than all previous tokens, SCOUT incurs slightly higher memory than purely linear models, but its growth rate remains sub-quadratic and far more scalable than that of full Transformers. We analyze SCOUT's computational and memory efficiency and evaluate it empirically on long-context language modeling and reasoning tasks. SCOUT with both Mamba and SWA mixers outperforms strong long-sequence baselines under the same computational budget, matches full-attention Transformers on language modeling and common-sense reasoning tasks at 400M and 1.3B scales. Moreover, our SCOUT achieves higher end-to-end throughput than SOTA models, while delivering comparable results on long sequence benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SCOUTï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡åˆ†æ®µå‹ç¼©(Segment Compression)å®ç°æ¬¡äºŒæ¬¡æ³¨æ„åŠ›(Sub-Quadratic Attention)çš„æ··åˆæ¶æ„ï¼Œä»¥è§£å†³Transformeråœ¨é•¿åºåˆ—å¤„ç†ä¸­çš„è®¡ç®—ç“¶é¢ˆã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨Mambaæˆ–æ»‘åŠ¨çª—å£æ³¨æ„åŠ›(Sliding-Window Attention, SWA)ç­‰çº¿æ€§æœ¬åœ°æ··åˆå™¨(local mixer)æ•´åˆè¿‘æœŸä¸Šä¸‹æ–‡ã€‚éšåï¼Œæ¯ä¸ªtokenä¸å†å…³æ³¨æ‰€æœ‰å†å²tokenï¼Œè€Œæ˜¯ç¨€ç–åœ°å…³æ³¨æ€»ç»“äº†è¾“å…¥å†å²çš„å‹ç¼©æ£€æŸ¥ç‚¹token(compressed checkpoint tokens)ï¼Œåœ¨ä¿ç•™å…¨æ³¨æ„åŠ›è¡¨è¾¾èƒ½åŠ›çš„åŒæ—¶æ˜¾è‘—é™ä½äº†å†…å­˜æˆæœ¬ã€‚åˆ†æè¡¨æ˜ï¼ŒSCOUTçš„èµ„æºæ¶ˆè€—å¢é•¿ç‡ä¿æŒåœ¨æ¬¡äºŒæ¬¡æ°´å¹³ï¼Œæ¯”ä¼ ç»ŸTransformeræ›´å…·æ‰©å±•æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨400Må’Œ1.3Bå‚æ•°è§„æ¨¡ä¸‹ï¼ŒSCOUTåœ¨è¯­è¨€å»ºæ¨¡å’Œæ¨ç†ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰çš„é•¿åºåˆ—åŸºçº¿æ¨¡å‹ï¼Œå¹¶è¾¾åˆ°äº†å…¨æ³¨æ„åŠ›Transformerçš„æ€§èƒ½æ°´å¹³ã€‚æ­¤å¤–ï¼ŒSCOUTåœ¨é•¿åºåˆ—åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ¯”SOTAæ¨¡å‹æ›´é«˜çš„ç«¯åˆ°ç«¯ååé‡ï¼Œä¸ºé«˜æ•ˆå¤„ç†é•¿ä¸Šä¸‹æ–‡æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00935v1",
      "published_date": "2025-08-31 17:08:33 UTC",
      "updated_date": "2025-08-31 17:08:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:45.790349+00:00"
    },
    {
      "arxiv_id": "2509.00934v2",
      "title": "MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework",
      "title_zh": "MedCODï¼šåŸºäºå¢å¼ºå‹å­—å…¸é“¾æ¡†æ¶æå‡å¤§è¯­è¨€æ¨¡å‹çš„è‹±è¥¿åŒ»å­¦ç¿»è¯‘",
      "authors": [
        "Md Shahidul Salim",
        "Lian Fu",
        "Arav Adikesh Ramakrishnan",
        "Zonghai Yao",
        "Hong Yu"
      ],
      "abstract": "We present MedCOD (Medical Chain-of-Dictionary), a hybrid framework designed to improve English-to-Spanish medical translation by integrating domain-specific structured knowledge into large language models (LLMs). MedCOD integrates domain-specific knowledge from both the Unified Medical Language System (UMLS) and the LLM-as-Knowledge-Base (LLM-KB) paradigm to enhance structured prompting and fine-tuning. We constructed a parallel corpus of 2,999 English-Spanish MedlinePlus articles and a 100-sentence test set annotated with structured medical contexts. Four open-source LLMs (Phi-4, Qwen2.5-14B, Qwen2.5-7B, and LLaMA-3.1-8B) were evaluated using structured prompts that incorporated multilingual variants, medical synonyms, and UMLS-derived definitions, combined with LoRA-based fine-tuning. Experimental results demonstrate that MedCOD significantly improves translation quality across all models. For example, Phi-4 with MedCOD and fine-tuning achieved BLEU 44.23, chrF++ 28.91, and COMET 0.863, surpassing strong baseline models like GPT-4o and GPT-4o-mini. Ablation studies confirm that both MedCOD prompting and model adaptation independently contribute to performance gains, with their combination yielding the highest improvements. These findings highlight the potential of structured knowledge integration to enhance LLMs for medical translation tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MedCOD (Medical Chain-of-Dictionary)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å°†ç‰¹å®šé¢†åŸŸç»“æ„åŒ–çŸ¥è¯†é›†æˆåˆ°å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸­ä»¥æ”¹è¿›è‹±æ–‡åˆ°è¥¿ç­ç‰™æ–‡åŒ»å­¦ç¿»è¯‘çš„æ··åˆæ¡†æ¶ã€‚MedCOD æ•´åˆäº†æ¥è‡ªç»Ÿä¸€åŒ»å­¦è¯­è¨€ç³»ç»Ÿ (UMLS) å’Œ LLM-as-Knowledge-Base (LLM-KB) èŒƒå¼çš„é¢†åŸŸçŸ¥è¯†ï¼Œç”¨äºå¢å¼ºç»“æ„åŒ–æç¤ºè¯å’Œå¾®è°ƒè¿‡ç¨‹ã€‚ç ”ç©¶äººå‘˜æ„å»ºäº†åŒ…å« 2,999 ç¯‡ MedlinePlus æ–‡ç« çš„å¹³è¡Œè¯­æ–™åº“ï¼Œå¹¶åœ¨ Phi-4ã€Qwen2.5 å’Œ LLaMA-3.1 ç­‰å¼€æºæ¨¡å‹ä¸Šç»“åˆ LoRA æŠ€æœ¯è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMedCOD æ˜¾è‘—æå‡äº†ç¿»è¯‘è´¨é‡ï¼Œå…¶ä¸­ Phi-4 æ¨¡å‹åœ¨ç»“åˆè¯¥æ¡†æ¶ååœ¨ BLEUã€chrF++ å’Œ COMET ç­‰æŒ‡æ ‡ä¸Šå‡è¶…è¶Šäº† GPT-4o å’Œ GPT-4o-miniã€‚æ¶ˆèå®éªŒè¯å® MedCOD æç¤ºè¯ä¸æ¨¡å‹é€‚é…å‡å¯¹æ€§èƒ½æå‡æœ‰ç‹¬ç«‹è´¡çŒ®ï¼Œå±•ç¤ºäº†ç»“æ„åŒ–çŸ¥è¯†é›†æˆåœ¨åŒ»ç–—ç¿»è¯‘é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Findings of the Association for Computational Linguistics: EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00934v2",
      "published_date": "2025-08-31 17:04:09 UTC",
      "updated_date": "2025-09-19 02:16:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:22.566581+00:00"
    },
    {
      "arxiv_id": "2509.00930v1",
      "title": "SATQuest: A Verifier for Logical Reasoning Evaluation and Reinforcement Fine-Tuning of LLMs",
      "title_zh": "SATQuestï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹é€»è¾‘æ¨ç†è¯„ä¼°ä¸å¼ºåŒ–å¾®è°ƒçš„éªŒè¯å™¨",
      "authors": [
        "Yanxiao Zhao",
        "Yaqian Li",
        "Zihao Bo",
        "Rinyoichi Takezoe",
        "Haojia Hui",
        "Mo Guang",
        "Lei Ren",
        "Xiaolin Qin",
        "Kaiwen Long"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated remarkable general reasoning capabilities. However, systematically evaluating and enhancing these reasoning capabilities is challenging due to the lack of controllable and scalable tools for fine-grained analysis. Existing benchmarks and datasets often lack the necessary variable control for multi-dimensional, systematic analysis and training, or have narrow problem types and formats. To address these limitations, we introduce SATQuest, a systematic verifier designed to evaluate and enhance logical reasoning in LLMs by generating diverse, Satisfiability-based logical reasoning problems directly from Conjunctive Normal Form (CNF) instances. SATQuest structures these problems along three orthogonal dimensions: instance scale, problem type, and question format, employing randomized, SAT-based problem generation and objective answer verification via PySAT. This design mitigates memorization issues, allows for nuanced insights into reasoning performance, and enables effective reinforcement fine-tuning. Our extensive evaluation of various LLMs using SATQuest identified significant limitations in their logical reasoning, particularly in generalizing beyond familiar mathematical formats. Furthermore, we show that reinforcement fine-tuning with SATQuest rewards substantially improves targeted task performance and generalizes to more complex instances, while highlighting remaining challenges in cross-format adaptation. Through these demonstrations, we showcase SATQuest's potential as a foundational tool and a valuable starting point for advancing LLM logical reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SATQuestï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å’Œå¢å¼ºå¤§è¯­è¨€æ¨¡å‹ (LLMs) é€»è¾‘æ¨ç†èƒ½åŠ›çš„ç³»ç»ŸåŒ–éªŒè¯å™¨ã€‚ä¸ºäº†è§£å†³ç°æœ‰åŸºå‡†æµ‹è¯•ç¼ºä¹å¯æ§å˜é‡å’Œç»†ç²’åº¦åˆ†æå·¥å…·çš„é—®é¢˜ï¼ŒSATQuest åˆ©ç”¨åˆå–èŒƒå¼ (CNF) å®ä¾‹ç”Ÿæˆå¤šæ ·åŒ–çš„å¯æ»¡è¶³æ€§ (Satisfiability-based) æ¨ç†é—®é¢˜ã€‚è¯¥ç³»ç»Ÿä»å®ä¾‹è§„æ¨¡ã€é—®é¢˜ç±»å‹å’Œæé—®æ ¼å¼ä¸‰ä¸ªæ­£äº¤ç»´åº¦è¿›è¡Œè®¾è®¡ï¼Œå¹¶é€šè¿‡ PySAT å®ç°å®¢è§‚ç­”æ¡ˆéªŒè¯ï¼Œæœ‰æ•ˆç¼“è§£äº†æ¨¡å‹çš„è®°å¿†é—®é¢˜å¹¶æä¾›äº†æ·±å…¥çš„æ¨ç†æ´å¯Ÿã€‚å¯¹å¤šç§ LLMs çš„è¯„ä¼°æ­ç¤ºäº†å…¶åœ¨éç†Ÿæ‚‰æ•°å­¦æ ¼å¼æ³›åŒ–æ–¹é¢çš„æ˜¾è‘—å±€é™ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œåˆ©ç”¨ SATQuest è¿›è¡Œå¼ºåŒ–å¾®è°ƒ (Reinforcement Fine-Tuning) èƒ½æ˜¾è‘—æå‡æ¨¡å‹åœ¨ç›®æ ‡ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œå¹¶ä½¿å…¶å…·å¤‡å‘å¤æ‚å®ä¾‹æ³›åŒ–çš„èƒ½åŠ›ã€‚SATQuest ä¸ºæ¨è¿›å¤§è¯­è¨€æ¨¡å‹é€»è¾‘æ¨ç†çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªå…·æœ‰æ½œåŠ›çš„åŸºç¡€å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00930v1",
      "published_date": "2025-08-31 16:56:06 UTC",
      "updated_date": "2025-08-31 16:56:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:31.762291+00:00"
    },
    {
      "arxiv_id": "2509.06980v1",
      "title": "RLFactory: A Plug-and-Play Reinforcement Learning Post-Training Framework for LLM Multi-Turn Tool-Use",
      "title_zh": "RLFactoryï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹å¤šè½®å·¥å…·è°ƒç”¨çš„å³æ’å³ç”¨å¼ºåŒ–å­¦ä¹ åè®­ç»ƒæ¡†æ¶",
      "authors": [
        "Jiajun Chai",
        "Guojun Yin",
        "Zekun Xu",
        "Chuhuai Yue",
        "Yi Jia",
        "Siyu Xia",
        "Xiaohan Wang",
        "Jiwen Jiang",
        "Xiaoguang Li",
        "Chengqi Dong",
        "Hang He",
        "Wei Lin"
      ],
      "abstract": "Large language models excel at basic reasoning but struggle with tasks that require interaction with external tools. We present RLFactory, a plug-and-play reinforcement learning post-training framework for multi-round tool use. RLFactory tackles (i) tool-call stability and adaptability amid tool heterogeneity and interface issues via an asyncio-based asynchronous caller and a decoupled tool/training architecture, and (ii) diverse evaluation needs via a reward layer supporting rule-based, model-judgment, and tool-verification signals. It reconstructs the MDP by introducing observation markers from tool feedback, closing the loop among model, tools, and environment, and implements a generate-parse-invoke-update workflow for dynamic policy optimization. On Search-R1 with Qwen3-4B, RLFactory achieves a 0.486 test score on the Natural Questions (NQ) dataset, surpassing larger models trained with similar techniques (e.g., Qwen2.5-7B-Instruct-GRPO at 0.473), and increases training throughput by 6.8x. RLFactory provides a low-barrier, highly adaptable framework for strengthening multi-round tool use of LLMs in real-world scenarios. Code: https://github.com/Simple-Efficient/RL-Factory.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RLFactoryï¼Œè¿™æ˜¯ä¸€ä¸ªå³æ’å³ç”¨çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)åè®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šè½®å·¥å…·ä½¿ç”¨(multi-turn tool-use)èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³å·¥å…·å¼‚æ„æ€§å’Œæ¥å£å¸¦æ¥çš„ç¨³å®šæ€§ä¸é€‚é…æ€§æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†åŸºäºasyncioçš„å¼‚æ­¥è°ƒç”¨å™¨å’Œè§£è€¦çš„å·¥å…·/è®­ç»ƒæ¶æ„ã€‚RLFactoryé€šè¿‡å¼•å…¥æ”¯æŒè§„åˆ™ã€æ¨¡å‹åˆ¤å®šå’Œå·¥å…·éªŒè¯ä¿¡å·çš„å¥–åŠ±å±‚ï¼Œå¹¶åˆ©ç”¨å·¥å…·åé¦ˆçš„è§‚å¯Ÿæ ‡è®°(observation markers)é‡æ„äº†é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(MDP)ï¼Œå®ç°äº†â€œç”Ÿæˆ-è§£æ-è°ƒç”¨-æ›´æ–°â€çš„åŠ¨æ€ç­–ç•¥ä¼˜åŒ–å·¥ä½œæµã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ­è½½Qwen3-4Bçš„Search-R1åœ¨Natural Questions (NQ)æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºQwen2.5-7B-Instruct-GRPOç­‰æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼Œä¸”è®­ç»ƒååé‡æå‡äº†6.8å€ã€‚è¯¥æ¡†æ¶ä¸ºæå‡LLMsåœ¨ç°å®åœºæ™¯ä¸­çš„å¤šè½®å·¥å…·è°ƒç”¨èƒ½åŠ›æä¾›äº†ä¸€ç§ä½é—¨æ§›ã€é«˜æ•ˆä¸”é«˜åº¦é€‚é…çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06980v1",
      "published_date": "2025-08-31 16:47:31 UTC",
      "updated_date": "2025-08-31 16:47:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:26.855816+00:00"
    },
    {
      "arxiv_id": "2509.00928v2",
      "title": "Superposition in Graph Neural Networks",
      "title_zh": "å›¾ç¥ç»ç½‘ç»œä¸­çš„å åŠ ç°è±¡",
      "authors": [
        "Lukas Pertl",
        "Han Xuanyuan",
        "Pietro LiÃ²"
      ],
      "abstract": "Interpreting graph neural networks (GNNs) is difficult because message passing mixes signals and internal channels rarely align with human concepts. We study superposition, the sharing of directions by multiple features, directly in the latent space of GNNs. Using controlled experiments with unambiguous graph concepts, we extract features as (i) class-conditional centroids at the graph level and (ii) linear-probe directions at the node level, and then analyze their geometry with simple basis-invariant diagnostics. Across GCN/GIN/GAT we find: increasing width produces a phase pattern in overlap; topology imprints overlap onto node-level features that pooling partially remixes into task-aligned graph axes; sharper pooling increases axis alignment and reduces channel sharing; and shallow models can settle into metastable low-rank embeddings. These results connect representational geometry with concrete design choices (width, pooling, and final-layer activations) and suggest practical approaches for more interpretable GNNs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å›¾ç¥ç»ç½‘ç»œ(GNNs)æ½œç©ºé—´ä¸­çš„å åŠ (Superposition)ç°è±¡ï¼Œå³å¤šä¸ªç‰¹å¾å…±äº«ç¥ç»å…ƒæ–¹å‘çš„é—®é¢˜ï¼Œæ—¨åœ¨ç ´è§£å› æ¶ˆæ¯ä¼ é€’æœºåˆ¶å¯¼è‡´çš„æ¨¡å‹è§£é‡Šéš¾é¢˜ã€‚ç ”ç©¶è€…é€šè¿‡æ§åˆ¶å®éªŒæå–äº†å›¾çº§åˆ«çš„ç±»åˆ«æ¡ä»¶è´¨å¿ƒ(class-conditional centroids)å’ŒèŠ‚ç‚¹çº§åˆ«çš„çº¿æ€§æ¢æµ‹æ–¹å‘(linear-probe directions)ï¼Œå¹¶åˆ©ç”¨åŸºåº¦ä¸å˜è¯Šæ–­å·¥å…·åˆ†æå…¶å‡ ä½•æ¼”åŒ–ã€‚åœ¨GCNã€GINå’ŒGATç­‰æ¨¡å‹ä¸­ï¼Œç ”ç©¶å‘ç°å¢åŠ å®½åº¦ä¼šå¯¼è‡´ç‰¹å¾é‡å å‘ˆç°ç›¸ä½æ¨¡å¼ï¼Œè€Œæ‹“æ‰‘ç»“æ„ä¼šå°†è¿™ç§é‡å å°åˆ»åœ¨èŠ‚ç‚¹ç‰¹å¾ä¸­ï¼Œå¹¶é€šè¿‡æ± åŒ–(pooling)æ“ä½œé‡æ–°æ··åˆè‡³ä»»åŠ¡å¯¹é½çš„å›¾è½´ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ›´é”åˆ©çš„æ± åŒ–èƒ½æ˜¾è‘—æå‡è½´å¯¹é½åº¦å¹¶å‡å°‘é€šé“å…±äº«ï¼Œä¸”æµ…å±‚æ¨¡å‹å€¾å‘äºé™·å…¥äºšç¨³æ€çš„ä½ç§©åµŒå…¥(low-rank embeddings)ã€‚è¯¥å·¥ä½œæˆåŠŸå°†è¡¨ç¤ºå‡ ä½•(representational geometry)ä¸æ¨¡å‹å®½åº¦ã€æ± åŒ–æ–¹å¼åŠæ¿€æ´»å‡½æ•°ç­‰è®¾è®¡é€‰æ‹©ç›¸è”ç³»ï¼Œä¸ºè®¾è®¡æ›´é«˜å¯è§£é‡Šæ€§çš„GNNsæä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00928v2",
      "published_date": "2025-08-31 16:43:29 UTC",
      "updated_date": "2026-01-15 21:25:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:30.357854+00:00"
    },
    {
      "arxiv_id": "2509.04485v1",
      "title": "ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records",
      "title_zh": "ASCENDgptï¼šä¸€ç§åŸºäºç”µå­å¥åº·è®°å½•çš„å¿ƒè¡€ç®¡é£é™©é¢„æµ‹è¡¨å‹æ„ŸçŸ¥ Transformer æ¨¡å‹",
      "authors": [
        "Chris Sainsbury",
        "Andreas Karwath"
      ],
      "abstract": "We present ASCENDgpt, a transformer-based model specifically designed for cardiovascular risk prediction from longitudinal electronic health records (EHRs). Our approach introduces a novel phenotype-aware tokenization scheme that maps 47,155 raw ICD codes to 176 clinically meaningful phenotype tokens, achieving 99.6\\% consolidation of diagnosis codes while preserving semantic information. This phenotype mapping contributes to a total vocabulary of 10,442 tokens - a 77.9\\% reduction when compared with using raw ICD codes directly. We pretrain ASCENDgpt on sequences derived from 19402 unique individuals using a masked language modeling objective, then fine-tune for time-to-event prediction of five cardiovascular outcomes: myocardial infarction (MI), stroke, major adverse cardiovascular events (MACE), cardiovascular death, and all-cause mortality. Our model achieves excellent discrimination on the held-out test set with an average C-index of 0.816, demonstrating strong performance across all outcomes (MI: 0.792, stroke: 0.824, MACE: 0.800, cardiovascular death: 0.842, all-cause mortality: 0.824). The phenotype-based approach enables clinically interpretable predictions while maintaining computational efficiency. Our work demonstrates the effectiveness of domain-specific tokenization and pretraining for EHR-based risk prediction tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ASCENDgptï¼Œè¿™æ˜¯ä¸€ç§åŸºäºTransformerçš„æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºä»çºµå‘ç”µå­å¥åº·è®°å½•(Electronic Health Records, EHRs)ä¸­è¿›è¡Œå¿ƒè¡€ç®¡é£é™©é¢„æµ‹ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†ä¸€ç§åˆ›æ–°çš„è¡¨å‹æ„ŸçŸ¥åˆ†è¯æ–¹æ¡ˆ(phenotype-aware tokenization scheme)ï¼Œå°†47,155ä¸ªåŸå§‹ICD codesæ˜ å°„ä¸º176ä¸ªå…·æœ‰ä¸´åºŠæ„ä¹‰çš„è¡¨å‹æ ‡è®°(phenotype tokens)ï¼Œåœ¨ä¿ç•™è¯­ä¹‰ä¿¡æ¯çš„åŒæ—¶ä½¿æ€»è¯æ±‡é‡å‡å°‘äº†77.9%ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨19,402åä¸ªä½“çš„åºåˆ—æ•°æ®ä¸Šé€šè¿‡æ©ç è¯­è¨€å»ºæ¨¡(Masked Language Modeling)è¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶é’ˆå¯¹å¿ƒè‚Œæ¢—æ­»(MI)ã€ä¸­é£(stroke)ã€ä¸»è¦ä¸è‰¯å¿ƒè¡€ç®¡äº‹ä»¶(MACE)ç­‰äº”ç§å¿ƒè¡€ç®¡ç»“å±€çš„æ—¶é—´åˆ°äº‹ä»¶é¢„æµ‹(time-to-event prediction)è¿›è¡Œäº†å¾®è°ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒASCENDgptåœ¨æµ‹è¯•é›†ä¸Šå–å¾—äº†0.816çš„å¹³å‡C-indexï¼Œè¯æ˜äº†å…¶åœ¨å„é¡¹ç»“å±€é¢„æµ‹ä¸­çš„å“è¶Šæ€§èƒ½ã€‚è¯¥æ–¹æ³•ä¸ä»…å®ç°äº†å…·æœ‰ä¸´åºŠå¯è§£é‡Šæ€§çš„é¢„æµ‹ï¼Œè¿˜æ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ï¼Œå……åˆ†å±•ç¤ºäº†é¢†åŸŸç‰¹å®šåˆ†è¯å’Œé¢„è®­ç»ƒåœ¨å¤„ç†å¤æ‚EHRæ•°æ®ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04485v1",
      "published_date": "2025-08-31 16:43:07 UTC",
      "updated_date": "2025-08-31 16:43:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:43.786669+00:00"
    },
    {
      "arxiv_id": "2509.03540v2",
      "title": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction",
      "title_zh": "é€šè¿‡æ¨ç†é˜¶æ®µçŸ¥è¯†å›¾è°±æ„å»ºæå‡å¤§è¯­è¨€æ¨¡å‹çš„äº‹å®æ€§",
      "authors": [
        "Shanglin Wu",
        "Lihui Liu",
        "Jinho D. Choi",
        "Kai Shu"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with producing factually consistent answers due to limitations in their parametric memory. Retrieval-Augmented Generation (RAG) paradigms mitigate this issue by incorporating external knowledge at inference time. However, such methods typically handle knowledge as unstructured text, which reduces retrieval accuracy, hinders compositional reasoning, and amplifies the influence of irrelevant information on the factual consistency of LLM outputs. To overcome these limitations, we propose a novel framework that dynamically constructs and expands knowledge graphs (KGs) during inference, integrating both internal knowledge extracted from LLMs and external knowledge retrieved from external sources. Our method begins by extracting a seed KG from the question via prompting, followed by iterative expansion using the LLM's internal knowledge. The KG is then selectively refined through external retrieval, enhancing factual coverage and correcting inaccuracies. We evaluate our approach on three diverse Factual QA benchmarks, demonstrating consistent gains in factual accuracy over baselines. Our findings reveal that inference-time KG construction is a promising direction for enhancing LLM factuality in a structured, interpretable, and scalable manner.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åœ¨æ¨ç†é˜¶æ®µåŠ¨æ€æ„å»ºå’Œæ‰©å±•çŸ¥è¯†å›¾è°±(Knowledge Graphs, KGs)çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)å› å‚æ•°è®°å¿†é™åˆ¶åŠä¼ ç»Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)å¤„ç†éç»“æ„åŒ–æ–‡æœ¬å¯¼è‡´çš„æ£€ç´¢å‡†ç¡®ç‡ä½å’Œæ¨ç†å—é˜»ç­‰é—®é¢˜ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡æç¤ºè¯ä»é—®é¢˜ä¸­æå–åˆå§‹çŸ¥è¯†å›¾è°±(seed KG)ï¼Œéšååˆ©ç”¨LLMçš„å†…éƒ¨çŸ¥è¯†è¿›è¡Œè¿­ä»£æ‰©å±•ï¼Œå¹¶ç»“åˆå¤–éƒ¨æ£€ç´¢å¯¹å›¾è°±è¿›è¡Œé€‰æ‹©æ€§ç»†åŒ–ï¼Œä»¥å¢å¼ºäº‹å®è¦†ç›–å¹¶çº æ­£æ½œåœ¨é”™è¯¯ã€‚åœ¨ä¸‰ä¸ªä¸åŒçš„äº‹å®æ€§é—®ç­”(Factual QA)åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨äº‹å®å‡†ç¡®æ€§æ–¹é¢å§‹ç»ˆä¼˜äºç°æœ‰çš„åŸºå‡†æ¨¡å‹ã€‚ç ”ç©¶å‘ç°ï¼Œæ¨ç†æ—¶æ„å»ºçŸ¥è¯†å›¾è°±(Inference-time KG construction)ä¸ºä»¥ç»“æ„åŒ–ã€å¯è§£é‡Šä¸”å¯æ‰©å±•çš„æ–¹å¼å¢å¼ºLLMäº‹å®æ€§æä¾›äº†ä¸€ä¸ªæå…·å‰æ™¯çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03540v2",
      "published_date": "2025-08-31 16:36:40 UTC",
      "updated_date": "2025-10-07 20:15:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:48.558244+00:00"
    },
    {
      "arxiv_id": "2509.00923v1",
      "title": "Robust Deep Monte Carlo Counterfactual Regret Minimization: Addressing Theoretical Risks in Neural Fictitious Self-Play",
      "title_zh": "é²æ£’æ·±åº¦è’™ç‰¹å¡æ´›åäº‹å®åæ‚”æœ€å°åŒ–ï¼šåº”å¯¹ç¥ç»è™šæ„è‡ªåšå¼ˆä¸­çš„ç†è®ºé£é™©",
      "authors": [
        "Zakaria El Jaafari"
      ],
      "abstract": "Monte Carlo Counterfactual Regret Minimization (MCCFR) has emerged as a cornerstone algorithm for solving extensive-form games, but its integration with deep neural networks introduces scale-dependent challenges that manifest differently across game complexities. This paper presents a comprehensive analysis of how neural MCCFR component effectiveness varies with game scale and proposes an adaptive framework for selective component deployment. We identify that theoretical risks such as nonstationary target distribution shifts, action support collapse, variance explosion, and warm-starting bias have scale-dependent manifestation patterns, requiring different mitigation strategies for small versus large games. Our proposed Robust Deep MCCFR framework incorporates target networks with delayed updates, uniform exploration mixing, variance-aware training objectives, and comprehensive diagnostic monitoring. Through systematic ablation studies on Kuhn and Leduc Poker, we demonstrate scale-dependent component effectiveness and identify critical component interactions. The best configuration achieves final exploitability of 0.0628 on Kuhn Poker, representing a 60% improvement over the classical framework (0.156). On the more complex Leduc Poker domain, selective component usage achieves exploitability of 0.2386, a 23.5% improvement over the classical framework (0.3703) and highlighting the importance of careful component selection over comprehensive mitigation. Our contributions include: (1) a formal theoretical analysis of risks in neural MCCFR, (2) a principled mitigation framework with convergence guarantees, (3) comprehensive multi-scale experimental validation revealing scale-dependent component interactions, and (4) practical guidelines for deployment in larger games.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦è’™ç‰¹å¡æ´›åæ‚”æœ€å°åŒ–(MCCFR)ä¸æ·±åº¦ç¥ç»ç½‘ç»œç»“åˆæ—¶åœ¨ä¸åŒåšå¼ˆè§„æ¨¡ä¸‹è¡¨ç°å‡ºçš„éå¹³ç¨³ç›®æ ‡åˆ†å¸ƒåç§»(nonstationary target distribution shifts)ã€åŠ¨ä½œæ”¯æŒå´©æºƒ(action support collapse)ä»¥åŠæ–¹å·®çˆ†ç‚¸(variance explosion)ç­‰ç†è®ºé£é™©è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ä½œè€…æå‡ºäº† Robust Deep MCCFR æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥å»¶è¿Ÿæ›´æ–°çš„ç›®æ ‡ç½‘ç»œ(target networks)ã€å‡åŒ€æ¢ç´¢æ··åˆ(uniform exploration mixing)ã€æ–¹å·®æ„ŸçŸ¥è®­ç»ƒç›®æ ‡(variance-aware training objectives)ä»¥åŠç»¼åˆè¯Šæ–­ç›‘æ§æ¥å¢å¼ºç®—æ³•çš„é²æ£’æ€§ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿé’ˆå¯¹å°å‹å’Œå¤§å‹åšå¼ˆä¸­è¡¨ç°å‡ºçš„ä¸åŒé£é™©æ¨¡å¼é‡‡å–å·®å¼‚åŒ–çš„ç¼“è§£ç­–ç•¥ï¼Œå¹¶æä¾›äº†å…·æœ‰æ”¶æ•›ä¿è¯çš„åŸåˆ™æ€§ç¼“è§£æ¡†æ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ Kuhn Poker ä¸­ï¼Œæœ€ä¼˜é…ç½®çš„æœ€ç»ˆå¯å‰¥å‰Šæ€§(exploitability)è¾¾åˆ° 0.0628ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ¡†æ¶æå‡äº† 60%ã€‚åœ¨æ›´å¤æ‚çš„ Leduc Poker ä»»åŠ¡ä¸­ï¼Œé€šè¿‡é€‰æ‹©æ€§çš„ç»„ä»¶åº”ç”¨å®ç°äº† 0.2386 çš„å¯å‰¥å‰Šæ€§ï¼Œè¾ƒä¼ ç»Ÿæ¡†æ¶ä¼˜åŒ–äº† 23.5%ï¼Œçªæ˜¾äº†æ ¹æ®åšå¼ˆè§„æ¨¡è¿›è¡Œé’ˆå¯¹æ€§ç»„ä»¶é€‰æ‹©è€Œéç›²ç›®å †ç Œçš„é‡è¦æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ä»…ä¸ºæ·±åº¦ MCCFR çš„ç†è®ºé£é™©æä¾›äº†å½¢å¼åŒ–åˆ†æï¼Œè¿˜ä¸ºåœ¨æ›´å¤§è§„æ¨¡åšå¼ˆä¸­éƒ¨ç½²è¯¥ç®—æ³•æä¾›äº†å®ç”¨çš„æŒ‡å¯¼åŸåˆ™ã€‚",
      "categories": [
        "cs.AI",
        "cs.GT",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00923v1",
      "published_date": "2025-08-31 16:19:16 UTC",
      "updated_date": "2025-08-31 16:19:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:38:51.609527+00:00"
    },
    {
      "arxiv_id": "2509.00914v1",
      "title": "TinyMusician: On-Device Music Generation with Knowledge Distillation and Mixed Precision Quantization",
      "title_zh": "TinyMusicianï¼šåŸºäºçŸ¥è¯†è’¸é¦ä¸æ··åˆç²¾åº¦é‡åŒ–çš„ç«¯ä¾§éŸ³ä¹ç”Ÿæˆ",
      "authors": [
        "Hainan Wang",
        "Mehdi Hosseinzadeh",
        "Reza Rawassizadeh"
      ],
      "abstract": "The success of the generative model has gained unprecedented attention in the music generation area. Transformer-based architectures have set new benchmarks for model performance. However, their practical adoption is hindered by some critical challenges: the demand for massive computational resources and inference time, due to their large number of parameters. These obstacles make them infeasible to deploy on edge devices, such as smartphones and wearables, with limited computational resources. In this work, we present TinyMusician, a lightweight music generation model distilled from MusicGen (a State-of-the-art music generation model). TinyMusician integrates two innovations: (i) Stage-mixed Bidirectional and Skewed KL-Divergence and (ii) Adaptive Mixed-Precision Quantization. The experimental results demonstrate that TinyMusician retains 93% of the MusicGen-Small performance with 55% less model size. TinyMusician is the first mobile-deployable music generation model that eliminates cloud dependency while maintaining high audio fidelity and efficient resource usage",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TinyMusicianï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºè¾¹ç¼˜è®¾å¤‡è®¾è®¡çš„è½»é‡çº§éŸ³ä¹ç”Ÿæˆæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³åŸºäº Transformer çš„å¤§æ¨¡å‹å› è®¡ç®—èµ„æºéœ€æ±‚è¿‡é«˜è€Œéš¾ä»¥åœ¨æ™ºèƒ½æ‰‹æœºç­‰ç§»åŠ¨ç«¯éƒ¨ç½²çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹ä»¥å…ˆè¿›çš„ MusicGen ä¸ºæ•™å¸ˆæ¨¡å‹è¿›è¡ŒçŸ¥è¯†è’¸é¦ï¼Œå¹¶å¼•å…¥äº† Stage-mixed Bidirectional and Skewed KL-Divergence åˆ›æ–°æŠ€æœ¯ä»¥æå‡è’¸é¦æ•ˆæœã€‚åŒæ—¶ï¼ŒTinyMusician ç»“åˆäº† Adaptive Mixed-Precision Quantizationï¼ˆè‡ªé€‚åº”æ··åˆç²¾åº¦é‡åŒ–ï¼‰ç­–ç•¥ï¼Œåœ¨ä¿è¯æ¨ç†æ•ˆç‡çš„åŒæ—¶å¤§å¹…é™ä½äº†å‚æ•°é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTinyMusician åœ¨æ¨¡å‹ä½“ç§¯ç¼©å° 55% çš„æƒ…å†µä¸‹ï¼Œä¾ç„¶ä¿ç•™äº† MusicGen-Small 93% çš„æ€§èƒ½è¡¨ç°ã€‚ä½œä¸ºé¦–ä¸ªå¯ç›´æ¥åœ¨ç§»åŠ¨ç«¯éƒ¨ç½²çš„éŸ³ä¹ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒæˆåŠŸæ¶ˆé™¤äº†å¯¹äº‘ç«¯è®¡ç®—çš„ä¾èµ–ï¼Œå®ç°äº†é«˜éŸ³é¢‘ä¿çœŸåº¦ä¸é«˜æ•ˆèµ„æºåˆ©ç”¨çš„å¹³è¡¡ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "12 pages for main context, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00914v1",
      "published_date": "2025-08-31 15:57:13 UTC",
      "updated_date": "2025-08-31 15:57:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:37:57.391759+00:00"
    },
    {
      "arxiv_id": "2509.00905v2",
      "title": "Spotlighter: Revisiting Prompt Tuning from a Representative Mining View",
      "title_zh": "Spotlighterï¼šä»ä»£è¡¨æ€§æŒ–æ˜è§†è§’é‡æ–°å®¡è§†æç¤ºå¾®è°ƒ",
      "authors": [
        "Yutong Gao",
        "Maoyuan Shao",
        "Xinyang Huang",
        "Chuang Zhu",
        "Lijuan Sun",
        "Yu Weng",
        "Xuan Liu",
        "Guoshun Nan"
      ],
      "abstract": "CLIP's success has demonstrated that prompt tuning can achieve robust cross-modal semantic alignment for tasks ranging from open-domain recognition to fine-grained classification. However, redundant or weakly relevant feature components introduce noise and incur unnecessary computational costs. In this work, we propose Spotlighter, a lightweight token-selection framework that simultaneously enhances accuracy and efficiency in prompt tuning. Spotlighter evaluates each visual token's activation from both sample-wise and semantic-wise perspectives and retains only the top-scoring tokens for downstream prediction. A class-specific semantic memory bank of learned prototypes refines this selection, ensuring semantic representativeness and compensating for discarded features. To further prioritize informative signals, we introduce a two-level ranking mechanism that dynamically weights token--prototype interactions. Across 11 few-shot benchmarks, Spotlighter outperforms CLIP by up to 11.19\\% in harmonic mean accuracy and achieves up to 0.8K additional FPS, with only 21 extra parameters. These results establish Spotlighter as an effective and scalable baseline for prompt tuning. Code for our method will be available at https://github.com/greatest-gourmet/Spotlighter.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Spotlighterï¼Œä¸€ç§è½»é‡çº§çš„token-selectionæ¡†æ¶ï¼Œæ—¨åœ¨ä»ä»£è¡¨æ€§æŒ–æ˜çš„è§’åº¦ä¼˜åŒ–Prompt Tuningï¼Œè§£å†³å†—ä½™ç‰¹å¾å¸¦æ¥çš„å™ªå£°ä¸è®¡ç®—è´Ÿæ‹…ã€‚Spotlighteré€šè¿‡sample-wiseå’Œsemantic-wiseä¸¤ä¸ªç»´åº¦è¯„ä¼°æ¯ä¸ªè§†è§‰tokençš„æ¿€æ´»å€¼ï¼Œå¹¶ä»…ä¿ç•™å¾—åˆ†æœ€é«˜çš„éƒ¨åˆ†è¿›è¡Œä¸‹æ¸¸é¢„æµ‹ã€‚æ¡†æ¶ç»“åˆäº†åŒ…å«å­¦ä¹ åˆ°çš„prototypesçš„ç±»ç‰¹å®šsemantic memory bankï¼Œä»¥ç²¾ç‚¼é€‰æ‹©è¿‡ç¨‹å¹¶åˆ©ç”¨ä»£è¡¨æ€§è¯­ä¹‰è¡¥å¿è¢«ä¸¢å¼ƒçš„ç‰¹å¾ï¼ŒåŒæ—¶å¼•å…¥ä¸¤çº§æ’åæœºåˆ¶åŠ¨æ€åŠ æƒtokenä¸prototypeçš„äº¤äº’ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSpotlighteråœ¨11ä¸ªfew-shotåŸºå‡†æµ‹è¯•ä¸­ç›¸è¾ƒäºCLIPå°†è°ƒå’Œå¹³å‡å‡†ç¡®ç‡æå‡äº†é«˜è¾¾11.19%ï¼Œä¸”åœ¨ä»…å¢åŠ 21ä¸ªå‚æ•°çš„æƒ…å†µä¸‹å®ç°äº†æœ€é«˜0.8Kçš„FPSæå‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†Spotlighteråœ¨æ˜¾è‘—æå‡æ¨¡å‹ç²¾åº¦çš„åŒæ—¶ï¼Œèƒ½å¤§å¹…ä¼˜åŒ–æ¨ç†æ•ˆç‡ï¼Œä¸ºå®ç°é«˜æ•ˆä¸”å¯æ‰©å±•çš„Prompt Tuningå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as EMNLP 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2509.00905v2",
      "published_date": "2025-08-31 15:37:48 UTC",
      "updated_date": "2025-09-03 01:19:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:39:05.398388+00:00"
    },
    {
      "arxiv_id": "2509.00891v2",
      "title": "ChatCLIDS: Simulating Persuasive AI Dialogues to Promote Closed-Loop Insulin Adoption in Type 1 Diabetes Care",
      "title_zh": "ChatCLIDSï¼šé€šè¿‡æ¨¡æ‹Ÿè¯´æœæ€§AIå¯¹è¯ä¿ƒè¿›1å‹ç³–å°¿ç—…æŠ¤ç†ä¸­é—­ç¯èƒ°å²›ç´ ç³»ç»Ÿçš„é‡‡ç”¨",
      "authors": [
        "Zonghai Yao",
        "Talha Chafekar",
        "Junda Wang",
        "Shuo Han",
        "Feiyun Ouyang",
        "Junhui Qian",
        "Lingxi Li",
        "Hong Yu"
      ],
      "abstract": "Real-world adoption of closed-loop insulin delivery systems (CLIDS) in type 1 diabetes remains low, driven not by technical failure, but by diverse behavioral, psychosocial, and social barriers. We introduce ChatCLIDS, the first benchmark to rigorously evaluate LLM-driven persuasive dialogue for health behavior change. Our framework features a library of expert-validated virtual patients, each with clinically grounded, heterogeneous profiles and realistic adoption barriers, and simulates multi-turn interactions with nurse agents equipped with a diverse set of evidence-based persuasive strategies. ChatCLIDS uniquely supports longitudinal counseling and adversarial social influence scenarios, enabling robust, multi-dimensional evaluation. Our findings reveal that while larger and more reflective LLMs adapt strategies over time, all models struggle to overcome resistance, especially under realistic social pressure. These results highlight critical limitations of current LLMs for behavior change, and offer a high-fidelity, scalable testbed for advancing trustworthy persuasive AI in healthcare and beyond.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† ChatCLIDSï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºä¸¥æ ¼è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„è¯´æœæ€§å¯¹è¯åœ¨ä¿ƒè¿›å¥åº·è¡Œä¸ºæ”¹å˜æ–¹é¢è¡¨ç°çš„åŸºå‡†ã€‚é’ˆå¯¹ 1 å‹ç³–å°¿ç—…æ‚£è€…åœ¨é‡‡ç”¨é—­ç¯èƒ°å²›ç´ é€’é€ç³»ç»Ÿï¼ˆCLIDSï¼‰æ—¶é¢ä¸´çš„å¿ƒç†ä¸ç¤¾ä¼šéšœç¢ï¼Œè¯¥æ¡†æ¶æ„å»ºäº†ç”±ä¸“å®¶éªŒè¯ã€å…·æœ‰ä¸´åºŠèƒŒæ™¯ä¸”åŒ…å«çœŸå®é˜»ç¢å› ç´ çš„è™šæ‹Ÿæ‚£è€…åº“ã€‚é€šè¿‡æ¨¡æ‹ŸæŠ¤å£«æ™ºèƒ½ä½“åˆ©ç”¨è¯æ®æ”¯æŒçš„è¯´æœç­–ç•¥è¿›è¡Œå¤šè½®äº¤äº’ï¼ŒChatCLIDS æ”¯æŒçºµå‘å’¨è¯¢åŠå¯¹æŠ—æ€§ç¤¾ä¼šå½±å“åœºæ™¯ä¸‹çš„è¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡è§„æ¨¡æ›´å¤§ã€å…·å¤‡åæ€èƒ½åŠ›çš„æ¨¡å‹èƒ½éšæ—¶é—´è°ƒæ•´ç­–ç•¥ï¼Œä½†åœ¨å…‹æœæ‚£è€…æŠµè§¦æƒ…ç»ªåŠåº”å¯¹ç°å®ç¤¾ä¼šå‹åŠ›æ–¹é¢ï¼Œç°æœ‰æ¨¡å‹å‡è¡¨ç°æ¬ ä½³ã€‚è¯¥ç ”ç©¶æŒ‡å‡ºäº†å½“å‰ LLMs åœ¨è¡Œä¸ºæ”¹å˜é¢†åŸŸçš„å…³é”®å±€é™ï¼Œå¹¶ä¸ºæ¨åŠ¨åŒ»ç–—ä¿å¥åŠæ›´å¤šé¢†åŸŸçš„å¯ä¿¡è¯´æœæ€§äººå·¥æ™ºèƒ½æä¾›äº†ä¸€ä¸ªé«˜ä¿çœŸä¸”å¯æ‰©å±•çš„æµ‹è¯•åºŠ(testbed)ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Equal contribution for the first two authors",
      "pdf_url": "https://arxiv.org/pdf/2509.00891v2",
      "published_date": "2025-08-31 15:08:41 UTC",
      "updated_date": "2025-09-03 04:55:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:39:08.284230+00:00"
    },
    {
      "arxiv_id": "2509.00884v1",
      "title": "An Explainable Gaussian Process Auto-encoder for Tabular Data",
      "title_zh": "é¢å‘è¡¨æ ¼æ•°æ®çš„å¯è§£é‡Šé«˜æ–¯è¿‡ç¨‹è‡ªç¼–ç å™¨",
      "authors": [
        "Wei Zhang",
        "Brian Barr",
        "John Paisley"
      ],
      "abstract": "Explainable machine learning has attracted much interest in the community where the stakes are high. Counterfactual explanations methods have become an important tool in explaining a black-box model. The recent advances have leveraged the power of generative models such as an autoencoder. In this paper, we propose a novel method using a Gaussian process to construct the auto-encoder architecture for generating counterfactual samples. The resulting model requires fewer learnable parameters and thus is less prone to overfitting. We also introduce a novel density estimator that allows for searching for in-distribution samples. Furthermore, we introduce an algorithm for selecting the optimal regularization rate on density estimator while searching for counterfactuals. We experiment with our method in several large-scale tabular datasets and compare with other auto-encoder-based methods. The results show that our method is capable of generating diversified and in-distribution counterfactual samples.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜é£é™©é¢†åŸŸçš„æ¨¡å‹å¯è§£é‡Šæ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºGaussian process(é«˜æ–¯è¿‡ç¨‹)çš„è‡ªåŠ¨ç¼–ç å™¨æ¶æ„ï¼Œç”¨äºç”Ÿæˆåäº‹å®è§£é‡Š(Counterfactual explanations)ã€‚è¯¥æ¨¡å‹åˆ©ç”¨é«˜æ–¯è¿‡ç¨‹æ„å»ºè‡ªåŠ¨ç¼–ç å™¨ï¼Œç”±äºæ‰€éœ€çš„å­¦ä¹ å‚æ•°è¾ƒå°‘ï¼Œå› æ­¤åœ¨å¤„ç†è¡¨æ ¼æ•°æ®æ—¶æ›´ä¸æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆã€‚ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§æ–°å‹å¯†åº¦ä¼°è®¡å™¨(Density estimator)ï¼Œå¹¶é…å¥—å¼€å‘äº†ç”¨äºåœ¨æœç´¢åäº‹å®æ ·æœ¬æ—¶é€‰æ‹©æœ€ä½³æ­£åˆ™åŒ–ç‡çš„ç®—æ³•ï¼Œä»¥ç¡®ä¿ç”Ÿæˆæ ·æœ¬çš„åˆ†å¸ƒä¸€è‡´æ€§ã€‚åœ¨å¤šä¸ªå¤§è§„æ¨¡è¡¨æ ¼æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”å…¶ä»–åŸºäºè‡ªåŠ¨ç¼–ç å™¨çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´å…·å¤šæ ·æ€§ä¸”ç¬¦åˆæ•°æ®åˆ†å¸ƒçš„åäº‹å®æ ·æœ¬ï¼Œæœ‰æ•ˆæå‡äº†é»‘ç›’æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00884v1",
      "published_date": "2025-08-31 14:55:12 UTC",
      "updated_date": "2025-08-31 14:55:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:39:10.759658+00:00"
    },
    {
      "arxiv_id": "2509.00883v1",
      "title": "Accelerating Latency-Critical Applications with AI-Powered Semi-Automatic Fine-Grained Parallelization on SMT Processors",
      "title_zh": "åˆ©ç”¨ SMT å¤„ç†å™¨ä¸Šçš„ AI é©±åŠ¨åŠè‡ªåŠ¨ç»†ç²’åº¦å¹¶è¡ŒåŒ–åŠ é€Ÿå»¶è¿Ÿæ•æ„Ÿå‹åº”ç”¨",
      "authors": [
        "Denis Los",
        "Igor Petushkov"
      ],
      "abstract": "Latency-critical applications tend to show low utilization of functional units due to frequent cache misses and mispredictions during speculative execution in high-performance superscalar processors. However, due to significant impact on single-thread performance, Simultaneous Multithreading (SMT) technology is rarely used with heavy threads of latency-critical applications. In this paper, we explore utilization of SMT technology to support fine-grained parallelization of latency-critical applications. Following the advancements in the development of Large Language Models (LLMs), we introduce Aira, an AI-powered Parallelization Adviser. To implement Aira, we extend AI Coding Agent in Cursor IDE with additional tools connected through Model Context Protocol, enabling end-to-end AI Agent for parallelization. Additional connected tools enable LLM-guided hotspot detection, collection of dynamic dependencies with Dynamic Binary Instrumentation, SMT-aware performance simulation to estimate performance gains. We apply Aira with Relic parallel framework for fine-grained task parallelism on SMT cores to parallelize latency-critical benchmarks representing real-world applications used in industry. We show 17% geomean performance gain from parallelization of latency-critical benchmarks using Aira with Relic framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å»¶è¿Ÿæ•æ„Ÿå‹(Latency-critical)åº”ç”¨åœ¨é«˜æ€§èƒ½å¤„ç†å™¨ä¸­å› ç¼“å­˜ç¼ºå¤±å’Œåˆ†æ”¯é¢„æµ‹é”™è¯¯å¯¼è‡´åŠŸèƒ½å•å…ƒåˆ©ç”¨ç‡ä½çš„é—®é¢˜ï¼Œæ¢ç´¢äº†åˆ©ç”¨åŒæ—¶å¤šçº¿ç¨‹(SMT)æŠ€æœ¯å®ç°ç»†ç²’åº¦å¹¶è¡ŒåŒ–çš„æ–°è·¯å¾„ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº†AIé©±åŠ¨çš„å¹¶è¡ŒåŒ–é¡¾é—®å·¥å…·Airaï¼Œé€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®(MCP)æ‰©å±•äº†Cursor IDEä¸­çš„AIç¼–ç¨‹åŠ©æ‰‹ï¼Œå®ç°äº†ç«¯åˆ°ç«¯çš„å¹¶è¡ŒåŒ–åˆ†ææµç¨‹ã€‚Airaé›†æˆäº†å¤§è¯­è¨€æ¨¡å‹(LLMs)å¼•å¯¼çš„çƒ­ç‚¹æ£€æµ‹ã€åŸºäºåŠ¨æ€äºŒè¿›åˆ¶æ’æ¡©(DBI)çš„åŠ¨æ€ä¾èµ–æ”¶é›†ä»¥åŠæ„ŸçŸ¥SMTçš„æ€§èƒ½æ¨¡æ‹Ÿç­‰å…³é”®åŠŸèƒ½ã€‚é€šè¿‡å°†Airaä¸Relicå¹¶è¡Œæ¡†æ¶ç»“åˆï¼Œç ”ç©¶è€…åœ¨SMTæ ¸å¿ƒä¸Šå¯¹ä»£è¡¨çœŸå®å·¥ä¸šåœºæ™¯çš„åŸºå‡†æµ‹è¯•é›†è¿›è¡Œäº†ç»†ç²’åº¦ä»»åŠ¡å¹¶è¡ŒåŒ–å¤„ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨å»¶è¿Ÿæ•æ„ŸåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†17%çš„å‡ ä½•å¹³å‡æ€§èƒ½å¢ç›Šï¼Œæœ‰æ•ˆè¯æ˜äº†AIè¾…åŠ©çš„ç»†ç²’åº¦å¹¶è¡ŒåŒ–åœ¨æå‡å¤„ç†å™¨èµ„æºåˆ©ç”¨ç‡æ–¹é¢çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00883v1",
      "published_date": "2025-08-31 14:51:19 UTC",
      "updated_date": "2025-08-31 14:51:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:39:16.058471+00:00"
    },
    {
      "arxiv_id": "2510.06223v2",
      "title": "A Multimodal GUI Architecture for Interfacing with LLM-Based Conversational Assistants",
      "title_zh": "ä¸€ç§é¢å‘ LLM å¯¹è¯åŠ©æ‰‹çš„å¤šæ¨¡æ€ GUI å¯¹æ¥æ¶æ„",
      "authors": [
        "Hans G. W. van Dam"
      ],
      "abstract": "Advances in large language models (LLMs) and real-time speech recognition now make it possible to issue any graphical user interface (GUI) action through natural language and receive the corresponding system response directly through the GUI. Most production applications were never designed with speech in mind. This article provides a concrete architecture that enables GUIs to interface with LLM-based speech-enabled assistants.\n  The architecture makes an application's navigation graph and semantics available through the Model Context Protocol (MCP). The ViewModel, part of the MVVM (Model-View-ViewModel) pattern, exposes the application's capabilities to the assistant by supplying both tools applicable to a currently visible view and application-global tools extracted from the GUI tree router. This architecture facilitates full voice accessibility while ensuring reliable alignment between spoken input and the visual interface, accompanied by consistent feedback across modalities. It future-proofs apps for upcoming OS super assistants that employ computer use agents (CUAs) and natively consume MCP if an application provides it.\n  To address concerns about privacy and data security, the practical effectiveness of locally deployable, open-weight LLMs for speech-enabled multimodal UIs is evaluated. Findings suggest that recent smaller open-weight models approach the performance of leading proprietary models in overall accuracy and require enterprise-grade hardware for fast responsiveness.\n  A demo implementation of the proposed architecture can be found at https://github.com/hansvdam/langbar",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ GUI æ¶æ„ï¼Œæ—¨åœ¨è§£å†³å¤§å¤šæ•°ç”Ÿäº§åº”ç”¨ç¨‹åºåœ¨è®¾è®¡æ—¶æœªè€ƒè™‘è¯­éŸ³äº¤äº’ï¼Œä»è€Œéš¾ä»¥ä¸åŸºäº LLM çš„å¯¹è¯åŠ©æ‰‹å¯¹æ¥çš„é—®é¢˜ã€‚è¯¥æ¶æ„é€šè¿‡ Model Context Protocol (MCP) å…¬å¼€åº”ç”¨ç¨‹åºçš„å¯¼èˆªå›¾å’Œè¯­ä¹‰ï¼Œå¹¶åˆ©ç”¨ MVVM æ¨¡å¼ä¸­çš„ ViewModel å‘åŠ©æ‰‹æä¾›å½“å‰è§†å›¾å·¥å…·åŠä» GUI æ ‘è·¯ç”±æå–çš„å…¨å±€å·¥å…·ã€‚è¿™ç§è®¾è®¡ä¸ä»…å®ç°äº†å…¨è¯­éŸ³å¯è®¿é—®æ€§ï¼Œç¡®ä¿äº†å£å¤´è¾“å…¥ä¸è§†è§‰ç•Œé¢ä¹‹é—´çš„å¯é å¯¹é½ï¼Œè¿˜ä½¿åº”ç”¨èƒ½å¤Ÿé€‚é…æœªæ¥ä½¿ç”¨ computer use agents (CUAs) çš„æ“ä½œç³»ç»Ÿè¶…çº§åŠ©æ‰‹ã€‚é’ˆå¯¹éšç§å’Œå®‰å…¨éœ€æ±‚ï¼Œç ”ç©¶è¯„ä¼°äº†æœ¬åœ°éƒ¨ç½²çš„å¼€æº LLM (open-weight models)ï¼Œå‘ç°å°å‹æ¨¡å‹åœ¨å‡†ç¡®ç‡ä¸Šå·²æ¥è¿‘é¢†å…ˆçš„ä¸“æœ‰æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›æœ¬åœ°æ¨¡å‹åœ¨é…å¤‡ä¼ä¸šçº§ç¡¬ä»¶æ—¶èƒ½å¤Ÿæä¾›å¿«é€Ÿçš„å“åº”æ€§èƒ½ï¼Œä¸ºæ„å»ºå®‰å…¨ã€é«˜æ•ˆçš„è·¨æ¨¡æ€äº¤äº’ç•Œé¢æä¾›äº†æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "24 pages, 19 figures, code available at https://github.com/hansvdam/langbar",
      "pdf_url": "https://arxiv.org/pdf/2510.06223v2",
      "published_date": "2025-08-31 14:40:11 UTC",
      "updated_date": "2025-10-09 12:55:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:40:56.683906+00:00"
    },
    {
      "arxiv_id": "2509.05329v1",
      "title": "Optical Music Recognition of Jazz Lead Sheets",
      "title_zh": "çˆµå£«ä¹é¢†è°±çš„å…‰å­¦ä¹è°±è¯†åˆ«",
      "authors": [
        "Juan Carlos Martinez-Sevilla",
        "Francesco Foscarin",
        "Patricia Garcia-Iasci",
        "David Rizo",
        "Jorge Calvo-Zaragoza",
        "Gerhard Widmer"
      ],
      "abstract": "In this paper, we address the challenge of Optical Music Recognition (OMR) for handwritten jazz lead sheets, a widely used musical score type that encodes melody and chords. The task is challenging due to the presence of chords, a score component not handled by existing OMR systems, and the high variability and quality issues associated with handwritten images. Our contribution is two-fold. We present a novel dataset consisting of 293 handwritten jazz lead sheets of 163 unique pieces, amounting to 2021 total staves aligned with Humdrum **kern and MusicXML ground truth scores. We also supply synthetic score images generated from the ground truth. The second contribution is the development of an OMR model for jazz lead sheets. We discuss specific tokenisation choices related to our kind of data, and the advantages of using synthetic scores and pretrained models. We publicly release all code, data, and models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰‹å†™ Jazz Lead Sheets çš„ Optical Music Recognition (OMR) æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤ŸåŒæ—¶å¤„ç†æ—‹å¾‹ä¸å’Œå¼¦çš„æ–°å‹è¯†åˆ«æ–¹æ¡ˆã€‚ç”±äºæ‰‹å†™ä¹è°±å­˜åœ¨é«˜åº¦å˜å¼‚æ€§ä¸”ç°æœ‰ç³»ç»Ÿæ™®éç¼ºä¹å¯¹å’Œå¼¦ç»„ä»¶çš„å¤„ç†èƒ½åŠ›ï¼Œç ”ç©¶äººå‘˜è´¡çŒ®äº†ä¸€ä¸ªåŒ…å« 293 ä»½æ‰‹å†™ç¨¿ã€2021 è¡Œä¹è°±çš„å…¨æ–°æ•°æ®é›†ï¼Œå¹¶æä¾›äº†ä¸ Humdrum **kern å’Œ MusicXML å¯¹é½çš„ Ground Truthã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–è¯†åˆ«æ•ˆæœï¼Œç ”ç©¶è¿˜ç”Ÿæˆäº†åˆæˆä¹è°±å›¾åƒå¹¶å¼€å‘äº†ä¸“é—¨çš„ OMR æ¨¡å‹ã€‚é€šè¿‡æ¢è®¨é’ˆå¯¹æ€§çš„ Tokenisation ç­–ç•¥ä»¥åŠåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„ä¼˜åŠ¿ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæå‡äº†æ‰‹å†™çˆµå£«ä¹è°±çš„è¯†åˆ«ç²¾åº¦ã€‚ç›®å‰ï¼Œè¯¥ç ”ç©¶å·²å…¬å¼€å‘å¸ƒæ‰€æœ‰ä»£ç ã€æ•°æ®å’Œæ¨¡å‹ï¼Œä¸ºå¤æ‚éŸ³ä¹æ‰‹ç¨¿çš„æ•°å­—åŒ–ç ”ç©¶æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the 26th International Society for Music Information Retrieval Conference (ISMIR), 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.05329v1",
      "published_date": "2025-08-31 14:38:26 UTC",
      "updated_date": "2025-08-31 14:38:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:07.291962+00:00"
    },
    {
      "arxiv_id": "2509.00872v1",
      "title": "Pose as Clinical Prior: Learning Dual Representations for Scoliosis Screening",
      "title_zh": "å§¿æ€å³ä¸´åºŠå…ˆéªŒï¼šé¢å‘è„ŠæŸ±ä¾§å¼¯ç­›æŸ¥çš„åŒé‡è¡¨å¾å­¦ä¹ ",
      "authors": [
        "Zirui Zhou",
        "Zizhao Peng",
        "Dongyang Jin",
        "Chao Fan",
        "Fengwei An",
        "Shiqi Yu"
      ],
      "abstract": "Recent AI-based scoliosis screening methods primarily rely on large-scale silhouette datasets, often neglecting clinically relevant postural asymmetries-key indicators in traditional screening. In contrast, pose data provide an intuitive skeletal representation, enhancing clinical interpretability across various medical applications. However, pose-based scoliosis screening remains underexplored due to two main challenges: (1) the scarcity of large-scale, annotated pose datasets; and (2) the discrete and noise-sensitive nature of raw pose coordinates, which hinders the modeling of subtle asymmetries. To address these limitations, we introduce Scoliosis1K-Pose, a 2D human pose annotation set that extends the original Scoliosis1K dataset, comprising 447,900 frames of 2D keypoints from 1,050 adolescents. Building on this dataset, we introduce the Dual Representation Framework (DRF), which integrates a continuous skeleton map to preserve spatial structure with a discrete Postural Asymmetry Vector (PAV) that encodes clinically relevant asymmetry descriptors. A novel PAV-Guided Attention (PGA) module further uses the PAV as clinical prior to direct feature extraction from the skeleton map, focusing on clinically meaningful asymmetries. Extensive experiments demonstrate that DRF achieves state-of-the-art performance. Visualizations further confirm that the model leverages clinical asymmetry cues to guide feature extraction and promote synergy between its dual representations. The dataset and code are publicly available at https://zhouzi180.github.io/Scoliosis1K/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è„ŠæŸ±ä¾§å¼¯ç­›é€‰ï¼ˆScoliosis Screeningï¼‰æ¨¡å‹å¿½è§†ä¸´åºŠå§¿åŠ¿ä¸å¯¹ç§°ï¼ˆPostural Asymmetriesï¼‰è¿™ä¸€æ ¸å¿ƒæŒ‡æ ‡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„åŒé‡è¡¨ç¤ºæ¡†æ¶ï¼ˆDual Representation Framework, DRFï¼‰ã€‚ä¸ºè§£å†³å¤§è§„æ¨¡å§¿æ€æ•°æ®é›†åŒ®ä¹çš„æŒ‘æˆ˜ï¼Œä½œè€…é¦–å…ˆæ„å»ºäº†åŒ…å«1,050åé’å°‘å¹´ã€å…±447,900å¸§2Då…³é”®ç‚¹æ ‡æ³¨çš„Scoliosis1K-Poseæ•°æ®é›†ã€‚DRFæ¡†æ¶é€šè¿‡æ•´åˆè¿ç»­çš„éª¨éª¼å›¾ï¼ˆSkeleton Mapï¼‰å’Œç¦»æ•£çš„å§¿åŠ¿ä¸å¯¹ç§°å‘é‡ï¼ˆPostural Asymmetry Vector, PAVï¼‰ï¼Œå®ç°äº†ç©ºé—´ç»“æ„ä¿¡æ¯ä¸ä¸´åºŠä¸å¯¹ç§°æè¿°ç¬¦çš„ååŒå»ºæ¨¡ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†PAVå¼•å¯¼æ³¨æ„åŠ›æ¨¡å—ï¼ˆPAV-Guided Attention, PGAï¼‰ï¼Œå°†PAVä½œä¸ºä¸´åºŠå…ˆéªŒæ¥å¼•å¯¼æ¨¡å‹å…³æ³¨ä¸´åºŠç›¸å…³çš„ç‰¹å¾æå–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è„ŠæŸ±ä¾§å¼¯ç­›é€‰ä¸­å–å¾—äº†State-of-the-artçš„æ€§èƒ½ï¼Œå¹¶é€šè¿‡å¯è§†åŒ–éªŒè¯äº†ä¸´åºŠä¸å¯¹ç§°çº¿ç´¢åœ¨å¼•å¯¼ç‰¹å¾æå–ä¸­çš„é‡è¦ä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00872v1",
      "published_date": "2025-08-31 14:34:11 UTC",
      "updated_date": "2025-08-31 14:34:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:40:43.095921+00:00"
    },
    {
      "arxiv_id": "2509.02615v2",
      "title": "Radio Astronomy in the Era of Vision-Language Models: Prompt Sensitivity and Adaptation",
      "title_zh": "è§†è§‰-è¯­è¨€æ¨¡å‹æ—¶ä»£çš„å°„ç”µå¤©æ–‡å­¦ï¼šæç¤ºè¯æ•æ„Ÿæ€§ä¸é€‚é…",
      "authors": [
        "Mariia Drozdova",
        "Erica Lastufka",
        "Vitaliy Kinakh",
        "Taras Holotyak",
        "Daniel Schaerer",
        "Slava Voloshynovskiy"
      ],
      "abstract": "Vision-Language Models (VLMs), such as recent Qwen and Gemini models, are positioned as general-purpose AI systems capable of reasoning across domains. Yet their capabilities in scientific imaging, especially on unfamiliar and potentially previously unseen data distributions, remain poorly understood. In this work, we assess whether generic VLMs, presumed to lack exposure to astronomical corpora, can perform morphology-based classification of radio galaxies using the MiraBest FR-I/FR-II dataset. We explore prompting strategies using natural language and schematic diagrams, and, to the best of our knowledge, we are the first to introduce visual in-context examples within prompts in astronomy. Additionally, we evaluate lightweight supervised adaptation via LoRA fine-tuning. Our findings reveal three trends: (i) even prompt-based approaches can achieve good performance, suggesting that VLMs encode useful priors for unfamiliar scientific domains; (ii) however, outputs are highly unstable, i.e. varying sharply with superficial prompt changes such as layout, ordering, or decoding temperature, even when semantic content is held constant; and (iii) with just 15M trainable parameters and no astronomy-specific pretraining, fine-tuned Qwen-VL achieves near state-of-the-art performance (3% Error rate), rivaling domain-specific models. These results suggest that the apparent \"reasoning\" of VLMs often reflects prompt sensitivity rather than genuine inference, raising caution for their use in scientific domains. At the same time, with minimal adaptation, generic VLMs can rival specialized models, offering a promising but fragile tool for scientific discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†é€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)åœ¨ MiraBest FR-I/FR-II æ•°æ®é›†ä¸Šè¿›è¡Œ Radio Galaxies å½¢æ€åˆ†ç±»çš„èƒ½åŠ›ã€‚ç ”ç©¶è€…æ¢ç´¢äº†è‡ªç„¶è¯­è¨€ã€ç¤ºæ„å›¾ä»¥åŠè§†è§‰ä¸Šä¸‹æ–‡ç¤ºä¾‹(visual in-context examples)ç­‰æç¤ºç­–ç•¥ï¼Œå¹¶è¯„ä¼°äº†åˆ©ç”¨ LoRA è¿›è¡Œçš„è½»é‡åŒ–ç›‘ç£é€‚é…ã€‚å‘ç°è¡¨æ˜ï¼Œå³ä½¿æ˜¯åŸºäºæç¤ºçš„æ–¹æ³•ä¹Ÿèƒ½è·å¾—è‰¯å¥½æ€§èƒ½ï¼Œæš—ç¤º VLMs ç¼–ç äº†æœ‰ç”¨çš„ç§‘å­¦é¢†åŸŸå…ˆéªŒçŸ¥è¯†ã€‚ç„¶è€Œï¼Œæ¨¡å‹è¾“å‡ºè¡¨ç°å‡ºé«˜åº¦çš„ä¸ç¨³å®šæ€§ï¼Œææ˜“å—åˆ°å¸ƒå±€ã€é¡ºåºæˆ–è§£ç æ¸©åº¦(decoding temperature)ç­‰è¡¨å±‚æç¤ºå˜åŒ–çš„å¹²æ‰°ã€‚åœ¨ç»è¿‡å¾®è°ƒåï¼Œä»…æœ‰ 15M å¯è®­ç»ƒå‚æ•°çš„ Qwen-VL è¾¾åˆ°äº†è¿‘ä¹ SOTA çš„æ€§èƒ½ï¼Œé”™è¯¯ç‡ä»…ä¸º 3%ï¼Œè¶³ä»¥åª²ç¾é¢†åŸŸä¸“ç”¨æ¨¡å‹ã€‚ç ”ç©¶æœ€ç»ˆæé†’ï¼ŒVLMs è¡¨ç°å‡ºçš„â€œæ¨ç†â€å¾€å¾€åæ˜ çš„æ˜¯æç¤ºæ•æ„Ÿæ€§(prompt sensitivity)è€ŒéçœŸæ­£çš„æ¨æ–­ï¼Œåœ¨ç§‘å­¦å‘ç°ä¸­ä½¿ç”¨è¿™ç§è„†å¼±çš„å·¥å…·éœ€ä¿æŒè°¨æ…ã€‚",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "Machine Learning and the Physical Sciences Workshop, NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.02615v2",
      "published_date": "2025-08-31 14:31:47 UTC",
      "updated_date": "2025-11-12 14:01:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:40:59.492211+00:00"
    },
    {
      "arxiv_id": "2509.00866v2",
      "title": "Can General-Purpose Omnimodels Compete with Specialists? A Case Study in Medical Image Segmentation",
      "title_zh": "é€šç”¨å…¨èƒ½æ¨¡å‹èƒ½å¦åª²ç¾ä¸“ç”¨æ¨¡å‹ï¼Ÿä»¥åŒ»å­¦å›¾åƒåˆ†å‰²ä¸ºä¾‹çš„æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Yizhe Zhang",
        "Qiang Chen",
        "Tao Zhou"
      ],
      "abstract": "The emergence of powerful, general-purpose omnimodels capable of processing diverse data modalities has raised a critical question: can these ``jack-of-all-trades'' systems perform on par with highly specialized models in knowledge-intensive domains? This work investigates this question within the high-stakes field of medical image segmentation. We conduct a comparative study analyzing the zero-shot performance of a state-of-the-art omnimodel (Gemini, the ``Nano Banana'' model) against domain-specific deep learning models on three distinct tasks: polyp (endoscopy), retinal vessel (fundus), and breast tumor segmentation (ultrasound). Our study focuses on performance at the extremes by curating subsets of the ``easiest'' and ``hardest'' cases based on the specialist models' accuracy. Our findings reveal a nuanced and task-dependent landscape. For polyp and breast tumor segmentation, specialist models excel on easy samples, but the omnimodel demonstrates greater robustness on hard samples where specialists fail catastrophically. Conversely, for the fine-grained task of retinal vessel segmentation, the specialist model maintains superior performance across both easy and hard cases. Intriguingly, qualitative analysis suggests omnimodels may possess higher sensitivity, identifying subtle anatomical features missed by human annotators. Our results indicate that while current omnimodels are not yet a universal replacement for specialists, their unique strengths suggest a potential complementary role with specialist models, particularly in enhancing robustness on challenging edge cases.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šç”¨å‹å…¨èƒ½æ¨¡å‹(omnimodels)åœ¨åŒ»ç–—å›¾åƒåˆ†å‰²è¿™ä¸€é«˜çŸ¥è¯†å¯†é›†é¢†åŸŸä¸­èƒ½å¦ä¸ä¸“ä¸šåŒ–æ¨¡å‹(specialist models)ç›¸åª²ç¾ã€‚ç ”ç©¶é€‰å–äº†Gemini(Nano Bananaæ¨¡å‹)ä½œä¸ºå…¨èƒ½æ¨¡å‹ä»£è¡¨ï¼Œåœ¨æ¯è‚‰(polyp)ã€è§†ç½‘è†œè¡€ç®¡(retinal vessel)å’Œä¹³è…ºè‚¿ç˜¤(breast tumor)åˆ†å‰²ä»»åŠ¡ä¸Šï¼Œå¯¹æ¯”äº†å…¶zero-shotè¡¨ç°ä¸é¢†åŸŸç‰¹å®šæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨æ¯è‚‰å’Œä¹³è…ºè‚¿ç˜¤åˆ†å‰²ä¸­ï¼Œä¸“ä¸šæ¨¡å‹åœ¨ç®€å•æ ·æœ¬ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè€Œå…¨èƒ½æ¨¡å‹åœ¨ä¸“ä¸šæ¨¡å‹å¤±æ•ˆçš„æç«¯å›°éš¾æ ·æœ¬ä¸Šå±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§(robustness)ã€‚ç„¶è€Œï¼Œåœ¨è§†ç½‘è†œè¡€ç®¡åˆ†å‰²ç­‰ç²¾ç»†åŒ–ä»»åŠ¡ä¸­ï¼Œä¸“ä¸šæ¨¡å‹åœ¨å„ç±»æ ·æœ¬ä¸Šå‡ä¿æŒå¹³è¡¡é¢†å…ˆã€‚å®šæ€§åˆ†æè¿˜å‘ç°å…¨èƒ½æ¨¡å‹å¯èƒ½å…·å¤‡æ›´é«˜çš„æ•æ„Ÿåº¦ï¼Œèƒ½è¯†åˆ«å‡ºäººç±»æ ‡æ³¨è€…é—æ¼çš„ç»†å¾®è§£å‰–ç‰¹å¾ã€‚ç»“æœè¡¨æ˜å…¨èƒ½æ¨¡å‹ç›®å‰å°šä¸èƒ½å®Œå…¨å–ä»£ä¸“ä¸šæ¨¡å‹ï¼Œä½†åœ¨å¢å¼ºå¤„ç†æŒ‘æˆ˜æ€§è¾¹ç•Œæ¡ˆä¾‹çš„é²æ£’æ€§æ–¹é¢å…·æœ‰æ˜¾è‘—çš„äº’è¡¥æ½œåŠ›ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "15 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00866v2",
      "published_date": "2025-08-31 14:22:33 UTC",
      "updated_date": "2025-09-27 09:38:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:40:34.684732+00:00"
    },
    {
      "arxiv_id": "2509.04484v3",
      "title": "The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors",
      "title_zh": "ä¼˜ã€åŠ£ä¸å»ºè®¾æ€§ï¼šåŒè¡Œè¯„å®¡å¯¹ä½œè€…æ•ˆç”¨çš„è‡ªåŠ¨è¯„ä¼°",
      "authors": [
        "Abdelrahman Sadallah",
        "Tim BaumgÃ¤rtner",
        "Iryna Gurevych",
        "Ted Briscoe"
      ],
      "abstract": "Providing constructive feedback to paper authors is a core component of peer review. With reviewers increasingly having less time to perform reviews, automated support systems are required to ensure high reviewing quality, thus making the feedback in reviews useful for authors. To this end, we identify four key aspects of review comments (individual points in weakness sections of reviews) that drive the utility for authors: Actionability, Grounding & Specificity, Verifiability, and Helpfulness. To enable evaluation and development of models assessing review comments, we introduce the RevUtil dataset. We collect 1,430 human-labeled review comments and scale our data with 10k synthetically labeled comments for training purposes. The synthetic data additionally contains rationales, i.e., explanations for the aspect score of a review comment. Employing the RevUtil dataset, we benchmark fine-tuned models for assessing review comments on these aspects and generating rationales. Our experiments demonstrate that these fine-tuned models achieve agreement levels with humans comparable to, and in some cases exceeding, those of powerful closed models like GPT-4o. Our analysis further reveals that machine-generated reviews generally underperform human reviews on our four aspects.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•è‡ªåŠ¨è¯„ä¼°åŒè¡Œè¯„å®¡ï¼ˆPeer Reviewï¼‰å¯¹ä½œè€…çš„å®ç”¨æ€§ï¼Œæ—¨åœ¨åº”å¯¹å®¡ç¨¿äººæ—¶é—´å—é™å¯¼è‡´çš„è¯„å®¡è´¨é‡ä¸‹é™é—®é¢˜ã€‚ç ”ç©¶ç¡®å®šäº†è¡¡é‡è¯„å®¡è¯„è®ºå®ç”¨æ€§çš„å››ä¸ªå…³é”®ç»´åº¦ï¼šActionabilityã€Grounding & Specificityã€Verifiabilityä»¥åŠHelpfulnessã€‚ä¸ºæ­¤ï¼Œä½œè€…æ¨å‡ºäº†RevUtilæ•°æ®é›†ï¼ŒåŒ…å«1,430æ¡äººå·¥æ ‡æ³¨çš„è¯„è®ºä»¥åŠ1ä¸‡æ¡å¸¦æœ‰Rationalesçš„åˆæˆæ ‡æ³¨è¯„è®ºã€‚åˆ©ç”¨RevUtilæ•°æ®é›†ï¼Œç ”ç©¶äººå‘˜å¯¹å¾®è°ƒåçš„æ¨¡å‹åœ¨è¯„ä¼°è¯„è®ºå’Œç”Ÿæˆæ¨ç†æ–¹é¢çš„è¡¨ç°è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™äº›å¾®è°ƒæ¨¡å‹åœ¨ä¸äººç±»è¯„ä¼°çš„ä¸€è‡´æ€§ä¸Šå¯åª²ç¾ç”šè‡³è¶…è¶ŠGPT-4oç­‰å¤§å‹é—­æºæ¨¡å‹ã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼Œåœ¨æ‰€å®šä¹‰çš„å››ä¸ªå…³é”®ç»´åº¦ä¸Šï¼Œç›®å‰æœºå™¨ç”Ÿæˆçš„è¯„å®¡æŠ¥å‘Šè¡¨ç°æ™®éé€Šè‰²äºäººç±»æ’°å†™çš„è¯„å®¡æŠ¥å‘Šã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Main",
      "pdf_url": "https://arxiv.org/pdf/2509.04484v3",
      "published_date": "2025-08-31 14:19:07 UTC",
      "updated_date": "2025-09-22 08:57:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:40:57.093699+00:00"
    },
    {
      "arxiv_id": "2509.00862v1",
      "title": "Speech Command Recognition Using LogNNet Reservoir Computing for Embedded Systems",
      "title_zh": "åŸºäº LogNNet å‚¨å¤‡æ± è®¡ç®—çš„åµŒå…¥å¼ç³»ç»Ÿè¯­éŸ³å‘½ä»¤è¯†åˆ«",
      "authors": [
        "Yuriy Izotov",
        "Andrei Velichko"
      ],
      "abstract": "This paper presents a low-resource speech-command recognizer combining energy-based voice activity detection (VAD), an optimized Mel-Frequency Cepstral Coefficients (MFCC) pipeline, and the LogNNet reservoir-computing classifier. Using four commands from the Speech Commands da-taset downsampled to 8 kHz, we evaluate four MFCC aggregation schemes and find that adaptive binning (64-dimensional feature vector) offers the best accuracy-to-compactness trade-off. The LogNNet classifier with architecture 64:33:9:4 reaches 92.04% accuracy under speaker-independent evaluation, while requiring significantly fewer parameters than conventional deep learn-ing models. Hardware implementation on Arduino Nano 33 IoT (ARM Cor-tex-M0+, 48 MHz, 32 KB RAM) validates the practical feasibility, achieving ~90% real-time recognition accuracy while consuming only 18 KB RAM (55% utilization). The complete pipeline (VAD -> MFCC -> LogNNet) thus enables reliable on-device speech-command recognition under strict memory and compute limits, making it suitable for battery-powered IoT nodes, wire-less sensor networks, and hands-free control interfaces.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åµŒå…¥å¼ç³»ç»Ÿæå‡ºäº†ä¸€ç§ä½èµ„æºè¯­éŸ³å‘½ä»¤è¯†åˆ«å™¨ï¼Œé›†æˆäº†åŸºäºèƒ½é‡çš„ Voice Activity Detection (VAD)ã€ä¼˜åŒ–çš„ Mel-Frequency Cepstral Coefficients (MFCC) æµæ°´çº¿ä»¥åŠ LogNNet Reservoir Computing åˆ†ç±»å™¨ã€‚ç ”ç©¶é€šè¿‡å¯¹ Speech Commands æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œå‘ç°é‡‡ç”¨è‡ªé€‚åº”åˆ†ç®±ï¼ˆ64ç»´ç‰¹å¾å‘é‡ï¼‰çš„ MFCC èšåˆæ–¹æ¡ˆåœ¨å‡†ç¡®ç‡ä¸ç´§å‡‘æ€§ä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ã€‚é‡‡ç”¨ 64:33:9:4 æ¶æ„çš„ LogNNet åˆ†ç±»å™¨åœ¨ç‹¬ç«‹äºè¯´è¯äººçš„æµ‹è¯•ä¸­å®ç°äº† 92.04% çš„å‡†ç¡®ç‡ï¼Œä¸”å‚æ•°é‡è¿œå°‘äºä¼ ç»Ÿçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚åœ¨ Arduino Nano 33 IoT ç¡¬ä»¶å¹³å°ä¸Šçš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ¡ˆçš„å®ç”¨æ€§ï¼Œåœ¨ä»…å ç”¨ 18 KB RAMï¼ˆ55% åˆ©ç”¨ç‡ï¼‰çš„æƒ…å†µä¸‹è¾¾åˆ°äº†çº¦ 90% çš„å®æ—¶è¯†åˆ«å‡†ç¡®ç‡ã€‚è¯¥å®Œæ•´æµæ°´çº¿ï¼ˆVAD -> MFCC -> LogNNetï¼‰èƒ½å¤Ÿåœ¨ä¸¥æ ¼çš„å†…å­˜å’Œè®¡ç®—é™åˆ¶ä¸‹å®ç°å¯é çš„è®¾å¤‡ç«¯è¯­éŸ³è¯†åˆ«ï¼Œä¸ºç”µæ± ä¾›ç”µçš„ IoT èŠ‚ç‚¹ã€æ— çº¿ä¼ æ„Ÿå™¨ç½‘ç»œåŠå…ææ§åˆ¶ç•Œé¢æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "20 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00862v1",
      "published_date": "2025-08-31 14:16:09 UTC",
      "updated_date": "2025-08-31 14:16:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:27.192521+00:00"
    },
    {
      "arxiv_id": "2509.00852v1",
      "title": "Why it is worth making an effort with GenAI",
      "title_zh": "è®ºç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸­æŠ•å…¥åŠªåŠ›çš„ä»·å€¼",
      "authors": [
        "Yvonne Rogers"
      ],
      "abstract": "Students routinely use ChatGPT and the like now to help them with their homework, such as writing an essay. It takes less effort to complete and is easier to do than by hand. It can even produce as good if not better output than the student's own work. However, there is a growing concern that over-reliance on using GenAI in this way will stifle the development of learning writing and critical thinking skills. How might this trend be reversed? What if students were required to make more effort when using GenAI to do their homework? It might be more challenging, but the additional effort involved could result in them learning more and having a greater sense of achievement. This tension can be viewed as a form of effort paradox; where effort is both viewed as something to be avoided but at the same time is valued. Is it possible to let students learn sometimes with less and other times more effort? Students are already adept at the former but what about the latter? Could we design new kinds of AI tools that deliberately require more effort to use to deepen the learning experience? In this paper, I begin to outline what form these might take, for example, asking students to use a combination of GenAI tools with traditional learning approaches (e.g. note-taking while reading). I also discuss how else to design tools to think with that augments human cognition; where students learn more the skills of metacognition and reflection.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(GenAI)åœ¨å­¦ç”Ÿå­¦æœ¯ä»»åŠ¡ä¸­çš„åº”ç”¨ç°çŠ¶ï¼ŒæŒ‡å‡ºè™½ç„¶å…¶æå‡äº†æ•ˆç‡ï¼Œä½†è¿‡åº¦ä¾èµ–å¯èƒ½å‰Šå¼±å­¦ç”Ÿçš„å†™ä½œä¸æ‰¹åˆ¤æ€§æ€ç»´èƒ½åŠ›ã€‚åŸºäºåŠªåŠ›æ‚–è®º(effort paradox)çš„è§†è§’ï¼Œä½œè€…æå‡ºåº”å½“é€šè¿‡å¢åŠ ä½¿ç”¨GenAIæ—¶çš„åŠªåŠ›ç¨‹åº¦æ¥æ·±åŒ–å­¦ä¹ ä½“éªŒå¹¶å¢å¼ºæˆå°±æ„Ÿã€‚è®ºæ–‡æ¢è®¨äº†è®¾è®¡æ–°å‹AIå·¥å…·çš„å¯èƒ½æ€§ï¼Œæ—¨åœ¨é€šè¿‡åˆ»æ„å¼•å¯¼å­¦ç”ŸæŠ•å…¥æ›´å¤šç²¾åŠ›æ¥ä¿ƒè¿›æ·±åº¦å­¦ä¹ ã€‚å…·ä½“å»ºè®®åŒ…æ‹¬å°†GenAIä¸ä¼ ç»Ÿå­¦ä¹ æ–¹æ³•ï¼ˆå¦‚é˜…è¯»ç¬”è®°ï¼‰ç›¸ç»“åˆï¼Œä»¥åŠå¼€å‘èƒ½å¢å¼ºå…ƒè®¤çŸ¥(metacognition)å’Œåæ€èƒ½åŠ›çš„äººæœºåä½œå·¥å…·ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨å°†AIä½œä¸ºè¾…åŠ©æ€è€ƒçš„å·¥å…·ï¼Œä»è€Œåœ¨æå‡æ•ˆç‡çš„åŒæ—¶ç¡®ä¿æ ¸å¿ƒè®¤çŸ¥æŠ€èƒ½çš„æŒç»­å‘å±•ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "6 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.00852v1",
      "published_date": "2025-08-31 13:55:10 UTC",
      "updated_date": "2025-08-31 13:55:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:27.490692+00:00"
    },
    {
      "arxiv_id": "2509.00846v1",
      "title": "Causal SHAP: Feature Attribution with Dependency Awareness through Causal Discovery",
      "title_zh": "Causal SHAPï¼šåŸºäºå› æœå‘ç°çš„ä¾èµ–æ„ŸçŸ¥ç‰¹å¾å½’å› ",
      "authors": [
        "Woon Yee Ng",
        "Li Rong Wang",
        "Siyuan Liu",
        "Xiuyi Fan"
      ],
      "abstract": "Explaining machine learning (ML) predictions has become crucial as ML models are increasingly deployed in high-stakes domains such as healthcare. While SHapley Additive exPlanations (SHAP) is widely used for model interpretability, it fails to differentiate between causality and correlation, often misattributing feature importance when features are highly correlated. We propose Causal SHAP, a novel framework that integrates causal relationships into feature attribution while preserving many desirable properties of SHAP. By combining the Peter-Clark (PC) algorithm for causal discovery and the Intervention Calculus when the DAG is Absent (IDA) algorithm for causal strength quantification, our approach addresses the weakness of SHAP. Specifically, Causal SHAP reduces attribution scores for features that are merely correlated with the target, as validated through experiments on both synthetic and real-world datasets. This study contributes to the field of Explainable AI (XAI) by providing a practical framework for causal-aware model explanations. Our approach is particularly valuable in domains such as healthcare, where understanding true causal relationships is critical for informed decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹SHapley Additive exPlanations (SHAP) åœ¨å¤„ç†é«˜ç›¸å…³ç‰¹å¾æ—¶æ— æ³•åŒºåˆ†å› æœä¸ç›¸å…³æ€§ï¼Œä»è€Œå¯¼è‡´å½’å› åå·®çš„é—®é¢˜ï¼Œæå‡ºäº†Causal SHAPæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆå› æœå…³ç³»æ¥ä¼˜åŒ–ç‰¹å¾å½’å› ï¼Œå¹¶åœ¨æ”¹è¿›çš„åŒæ—¶ä¿ç•™äº†SHAPçš„ä¼˜è‰¯ç‰¹æ€§ã€‚ç ”ç©¶ç»“åˆäº†ç”¨äºå› æœå‘ç°çš„Peter-Clark (PC) ç®—æ³•ä»¥åŠåœ¨ç¼ºå°‘æœ‰å‘æ— ç¯å›¾æ—¶ç”¨äºé‡åŒ–å› æœå¼ºåº¦çš„Intervention Calculus when the DAG is Absent (IDA) ç®—æ³•ï¼Œä»è€Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»ŸSHAPçš„å±€é™æ€§ã€‚å®éªŒåœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡è¯æ˜ï¼ŒCausal SHAPèƒ½å¤Ÿæ˜¾è‘—é™ä½ä»…å…·æœ‰ç›¸å…³æ€§è€Œéå› æœæ€§ç‰¹å¾çš„å½’å› å¾—åˆ†ã€‚è¯¥ç ”ç©¶ä¸ºå¯è§£é‡Šäººå·¥æ™ºèƒ½ (XAI) é¢†åŸŸè´¡çŒ®äº†ä¸€ä¸ªå®ç”¨çš„å› æœæ„ŸçŸ¥è§£é‡Šæ¡†æ¶ï¼Œå¯¹äºåŒ»ç–—ä¿å¥ç­‰éœ€è¦ç²¾å‡†å› æœå†³ç­–çš„é«˜é£é™©é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in 2025 International Joint Conference on Neural Networks (IJCNN). IEEE, 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00846v1",
      "published_date": "2025-08-31 13:31:34 UTC",
      "updated_date": "2025-08-31 13:31:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:34.584783+00:00"
    },
    {
      "arxiv_id": "2509.00843v1",
      "title": "Look Beyond: Two-Stage Scene View Generation via Panorama and Video Diffusion",
      "title_zh": "Look Beyondï¼šåŸºäºå…¨æ™¯ä¸è§†é¢‘æ‰©æ•£çš„ä¸¤é˜¶æ®µåœºæ™¯è§†å›¾ç”Ÿæˆ",
      "authors": [
        "Xueyang Kang",
        "Zhengkang Xiang",
        "Zezheng Zhang",
        "Kourosh Khoshelham"
      ],
      "abstract": "Novel view synthesis (NVS) from a single image is highly ill-posed due to large unobserved regions, especially for views that deviate significantly from the input. While existing methods focus on consistency between the source and generated views, they often fail to maintain coherence and correct view alignment across long-range or looped trajectories. We propose a model that addresses this by decomposing single-view NVS into a 360-degree scene extrapolation followed by novel view interpolation. This design ensures long-term view and scene consistency by conditioning on keyframes extracted and warped from a generated panoramic representation. In the first stage, a panorama diffusion model learns the scene prior from the input perspective image. Perspective keyframes are then sampled and warped from the panorama and used as anchor frames in a pre-trained video diffusion model, which generates novel views through a proposed spatial noise diffusion process. Compared to prior work, our method produces globally consistent novel views -- even in loop closure scenarios -- while enabling flexible camera control. Experiments on diverse scene datasets demonstrate that our approach outperforms existing methods in generating coherent views along user-defined trajectories. Our implementation is available at https://github.com/YiGuYT/LookBeyond.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Look Beyondï¼Œè¿™æ˜¯ä¸€ç§å°†å•è§†å›¾æ–°è§†è§’åˆæˆ(Novel View Synthesis, NVS)åˆ†è§£ä¸º360åº¦åœºæ™¯å¤–æ¨å’Œæ–°è§†è§’æ’å€¼çš„ä¸¤é˜¶æ®µæ¡†æ¶ã€‚ä¸ºäº†è§£å†³ç°æœ‰æ–¹æ³•åœ¨é•¿è·ç¦»æˆ–é—­ç¯è½¨è¿¹ä¸­éš¾ä»¥ä¿æŒè§†å›¾ä¸€è‡´æ€§å’Œå¯¹é½çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¬¬ä¸€é˜¶æ®µåˆ©ç”¨å…¨æ™¯æ‰©æ•£æ¨¡å‹(Panorama Diffusion Model)ä»å•å¼ è¾“å…¥å›¾åƒä¸­å­¦ä¹ åœºæ™¯å…ˆéªŒã€‚ç¬¬äºŒé˜¶æ®µä»ç”Ÿæˆçš„å…¨æ™¯å›¾ä¸­æå–å¹¶æŠ•å½±å‡ºé€è§†å…³é”®å¸§ï¼Œå°†å…¶ä½œä¸ºé¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹(Video Diffusion Model)çš„é”šç‚¹ï¼Œå¹¶é€šè¿‡ç©ºé—´å™ªå£°æ‰©æ•£è¿‡ç¨‹ç”Ÿæˆæ–°è§†è§’ã€‚è¿™ç§è®¾è®¡ç¡®ä¿äº†é•¿æœŸè§†è§’å’Œåœºæ™¯çš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶å®ç°äº†çµæ´»çš„ç›¸æœºæ§åˆ¶ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§åœºæ™¯æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå°¤å…¶åœ¨ç”Ÿæˆå…¨å±€ä¸€è‡´ä¸”è¿è´¯çš„è§†è§’è½¨è¿¹æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages, 30 figures, 2025 ACM Multimedia",
      "pdf_url": "https://arxiv.org/pdf/2509.00843v1",
      "published_date": "2025-08-31 13:27:15 UTC",
      "updated_date": "2025-08-31 13:27:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:36.867120+00:00"
    },
    {
      "arxiv_id": "2509.00839v1",
      "title": "Adaptive Vehicle Speed Classification via BMCNN with Reinforcement Learning-Enhanced Acoustic Processing",
      "title_zh": "åŸºäºå¼ºåŒ–å­¦ä¹ å¢å¼ºå£°å­¦å¤„ç†ä¸ BMCNN çš„è‡ªé€‚åº”è½¦è¾†é€Ÿåº¦åˆ†ç±»",
      "authors": [
        "Yuli Zhang",
        "Pengfei Fan",
        "Ruiyuan Jiang",
        "Hankang Gu",
        "Dongyao Jia",
        "Xinheng Wang"
      ],
      "abstract": "Traffic congestion remains a pressing urban challenge, requiring intelligent transportation systems for real-time management. We present a hybrid framework that combines deep learning and reinforcement learning for acoustic vehicle speed classification. A dual-branch BMCNN processes MFCC and wavelet features to capture complementary frequency patterns. An attention-enhanced DQN adaptively selects the minimal number of audio frames and triggers early decisions once confidence thresholds are reached. Evaluations on IDMT-Traffic and our SZUR-Acoustic (Suzhou) datasets show 95.99% and 92.3% accuracy, with up to 1.63x faster average processing via early termination. Compared with A3C, DDDQN, SA2C, PPO, and TD3, the method provides a superior accuracy-efficiency trade-off and is suitable for real-time ITS deployment in heterogeneous urban environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆæ·±åº¦å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹ çš„æ··åˆæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å£°å­¦å¤„ç†å®ç°è‡ªé€‚åº”è½¦è¾†é€Ÿåº¦åˆ†ç±»ï¼Œä»¥åº”å¯¹åŸå¸‚äº¤é€šç®¡ç†çš„å®æ—¶æ€§éœ€æ±‚ã€‚è¯¥æ¡†æ¶åˆ©ç”¨åŒåˆ†æ”¯ BMCNN å¤„ç† MFCC å’Œå°æ³¢ç‰¹å¾ä»¥æ•è·äº’è¡¥çš„é¢‘ç‡æ¨¡å¼ï¼Œå¹¶ç»“åˆæ³¨æ„åŠ›å¢å¼ºçš„ DQN ç®—æ³•è‡ªé€‚åº”åœ°é€‰æ‹©æœ€å°‘éŸ³é¢‘å¸§ï¼Œåœ¨è¾¾åˆ°ç½®ä¿¡åº¦é˜ˆå€¼æ—¶è§¦å‘æ—©æœŸå†³ç­–ã€‚åœ¨ IDMT-Traffic å’Œä½œè€…è‡ªå»ºçš„ SZUR-Acoustic æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åˆ†åˆ«è¾¾åˆ°äº† 95.99% å’Œ 92.3% çš„å‡†ç¡®ç‡ï¼Œä¸”å¤„ç†é€Ÿåº¦æœ€é«˜æå‡äº† 1.63 å€ã€‚ä¸ A3Cã€DDDQNã€PPO å’Œ TD3 ç­‰ä¸»æµç®—æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®ç‡ä¸æ•ˆç‡ä¹‹é—´å–å¾—äº†æ›´ä¼˜çš„å¹³è¡¡ï¼Œä¸ºå¼‚æ„åŸå¸‚ç¯å¢ƒä¸‹çš„æ™ºèƒ½äº¤é€šç³»ç»Ÿ (ITS) å®æ—¶éƒ¨ç½²æä¾›äº†å¯é çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00839v1",
      "published_date": "2025-08-31 13:23:04 UTC",
      "updated_date": "2025-08-31 13:23:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:42.168068+00:00"
    },
    {
      "arxiv_id": "2509.00834v1",
      "title": "Neuro-Symbolic Predictive Process Monitoring",
      "title_zh": "ç¥ç»ç¬¦å·é¢„æµ‹æ€§æµç¨‹ç›‘æ§",
      "authors": [
        "Axel Mezini",
        "Elena Umili",
        "Ivan Donadello",
        "Fabrizio Maria Maggi",
        "Matteo Mancanelli",
        "Fabio Patrizi"
      ],
      "abstract": "This paper addresses the problem of suffix prediction in Business Process Management (BPM) by proposing a Neuro-Symbolic Predictive Process Monitoring (PPM) approach that integrates data-driven learning with temporal logic-based prior knowledge. While recent approaches leverage deep learning models for suffix prediction, they often fail to satisfy even basic logical constraints due to the absence of explicit integration of domain knowledge during training. We propose a novel method to incorporate Linear Temporal Logic over finite traces (LTLf) into the training process of autoregressive sequence predictors. Our approach introduces a differentiable logical loss function, defined using a soft approximation of LTLf semantics and the Gumbel-Softmax trick, which can be combined with standard predictive losses. This ensures the model learns to generate suffixes that are both accurate and logically consistent. Experimental evaluation on three real-world datasets shows that our method improves suffix prediction accuracy and compliance with temporal constraints. We also introduce two variants of the logic loss (local and global) and demonstrate their effectiveness under noisy and realistic settings. While developed in the context of BPM, our framework is applicable to any symbolic sequence generation task and contributes toward advancing Neuro-Symbolic AI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Business Process Management (BPM) ä¸­çš„ suffix prediction é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆæ•°æ®é©±åŠ¨å­¦ä¹ ä¸åŸºäº temporal logic å…ˆéªŒçŸ¥è¯†çš„ç¥ç»ç¬¦å· Neuro-Symbolic é¢„æµ‹è¿‡ç¨‹ç›‘æ§æ–¹æ³•ã€‚é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹å› ç¼ºä¹æ˜¾å¼é¢†åŸŸçŸ¥è¯†æ•´åˆè€Œéš¾ä»¥æ»¡è¶³é€»è¾‘çº¦æŸçš„æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•å°† Linear Temporal Logic over finite traces (LTLf) å¼•å…¥è‡ªå›å½’åºåˆ—é¢„æµ‹å™¨çš„è®­ç»ƒè¿‡ç¨‹ã€‚ç ”ç©¶é€šè¿‡ç»“åˆ LTLf è¯­ä¹‰çš„è½¯è¿‘ä¼¼ä¸ Gumbel-Softmax æŠ€å·§ï¼Œå®šä¹‰äº†å¯å¾®çš„é€»è¾‘æŸå¤±å‡½æ•° logical loss functionï¼Œå¹¶æå‡ºäº†å±€éƒ¨å’Œå…¨å±€ä¸¤ç§æŸå¤±å˜ä½“ã€‚åœ¨ä¸‰ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æå‡åç¼€é¢„æµ‹å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†ç”Ÿæˆç»“æœå¯¹æ—¶åºçº¦æŸçš„åˆè§„æ€§ã€‚è¯¥æ¡†æ¶ä¸ä»…é€‚ç”¨äºä¸šåŠ¡æµç¨‹ç›‘æ§ï¼Œè¿˜å¯æ‰©å±•è‡³é€šç”¨çš„ç¬¦å·åºåˆ—ç”Ÿæˆä»»åŠ¡ï¼Œä¸º Neuro-Symbolic AI é¢†åŸŸçš„ç ”ç©¶åšå‡ºäº†è´¡çŒ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00834v1",
      "published_date": "2025-08-31 13:07:17 UTC",
      "updated_date": "2025-08-31 13:07:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:41.362297+00:00"
    },
    {
      "arxiv_id": "2509.00826v1",
      "title": "Sequential Difference Maximization: Generating Adversarial Examples via Multi-Stage Optimization",
      "title_zh": "åºåˆ—å·®å¼‚æœ€å¤§åŒ–ï¼šåŸºäºå¤šé˜¶æ®µä¼˜åŒ–çš„å¯¹æŠ—æ ·æœ¬ç”Ÿæˆ",
      "authors": [
        "Xinlei Liu",
        "Tao Hu",
        "Peng Yi",
        "Weitao Han",
        "Jichao Xie",
        "Baolin Li"
      ],
      "abstract": "Efficient adversarial attack methods are critical for assessing the robustness of computer vision models. In this paper, we reconstruct the optimization objective for generating adversarial examples as \"maximizing the difference between the non-true labels' probability upper bound and the true label's probability,\" and propose a gradient-based attack method termed Sequential Difference Maximization (SDM). SDM establishes a three-layer optimization framework of \"cycle-stage-step.\" The processes between cycles and between iterative steps are respectively identical, while optimization stages differ in terms of loss functions: in the initial stage, the negative probability of the true label is used as the loss function to compress the solution space; in subsequent stages, we introduce the Directional Probability Difference Ratio (DPDR) loss function to gradually increase the non-true labels' probability upper bound by compressing the irrelevant labels' probabilities. Experiments demonstrate that compared with previous SOTA methods, SDM not only exhibits stronger attack performance but also achieves higher attack cost-effectiveness. Additionally, SDM can be combined with adversarial training methods to enhance their defensive effects. The code is available at https://github.com/X-L-Liu/SDM.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Sequential Difference Maximization (SDM)ï¼Œä¸€ç§åŸºäºæ¢¯åº¦ä¸”é‡‡ç”¨ä¸‰å±‚â€œå¾ªç¯-é˜¶æ®µ-æ­¥é•¿â€(cycle-stage-step) ä¼˜åŒ–æ¡†æ¶çš„å¯¹æŠ—æ ·æœ¬ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†ä¼˜åŒ–ç›®æ ‡é‡æ„ä¸ºâ€œæœ€å¤§åŒ–éçœŸæ ‡ç­¾æ¦‚ç‡ä¸Šé™ä¸çœŸæ ‡ç­¾æ¦‚ç‡ä¹‹é—´çš„å·®å¼‚â€ï¼Œæ—¨åœ¨æ›´é«˜æ•ˆåœ°è¯„ä¼°è®¡ç®—æœºè§†è§‰æ¨¡å‹çš„é²æ£’æ€§ã€‚åœ¨åˆå§‹é˜¶æ®µï¼ŒSDM ä½¿ç”¨çœŸæ ‡ç­¾çš„è´Ÿæ¦‚ç‡ä½œä¸ºæŸå¤±å‡½æ•°ä»¥å‹ç¼©è§£ç©ºé—´ï¼›éšåå¼•å…¥ Directional Probability Difference Ratio (DPDR) æŸå¤±å‡½æ•°ï¼Œé€šè¿‡å‹ç¼©æ— å…³æ ‡ç­¾çš„æ¦‚ç‡æ¥é€æ¸æé«˜éçœŸæ ‡ç­¾çš„æ¦‚ç‡ä¸Šé™ã€‚å®éªŒç»“æœè¯æ˜ï¼Œä¸ç°æœ‰çš„ SOTA æ–¹æ³•ç›¸æ¯”ï¼ŒSDM ä¸ä»…å±•ç¤ºäº†æ›´å¼ºçš„æ”»å‡»æ€§èƒ½ï¼Œè¿˜å®ç°äº†æ›´é«˜çš„æ”»å‡»æ€§ä»·æ¯”ã€‚æ­¤å¤–ï¼ŒSDM è¿˜å¯ä»¥ä¸å¯¹æŠ—è®­ç»ƒ (adversarial training) æ–¹æ³•ç›¸ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„é˜²å¾¡æ•ˆæœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 2 figures, 5 tables, CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00826v1",
      "published_date": "2025-08-31 12:52:49 UTC",
      "updated_date": "2025-08-31 12:52:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:50.262247+00:00"
    },
    {
      "arxiv_id": "2509.10493v2",
      "title": "Online Learning Based Efficient Resource Allocation for LoRaWAN Network",
      "title_zh": "åŸºäºåœ¨çº¿å­¦ä¹ çš„ LoRaWAN ç½‘ç»œé«˜æ•ˆèµ„æºåˆ†é…",
      "authors": [
        "Ruiqi Wang",
        "Wenjun Li",
        "Jing Ren",
        "Tongyu Song",
        "Xiong Wang",
        "Sheng Wang",
        "Shizhong Xu"
      ],
      "abstract": "The deployment of large-scale LoRaWAN networks requires jointly optimizing conflicting metrics like Packet Delivery Ratio (PDR) and Energy Efficiency (EE) by dynamically allocating transmission parameters, including Carrier Frequency, Spreading Factor, and Transmission Power. Existing methods often oversimplify this challenge, focusing on a single metric or lacking the adaptability needed for dynamic channel environments, leading to suboptimal performance. To address this, we propose two online learning-based resource allocation frameworks that intelligently navigate the PDR-EE trade-off. Our foundational proposal, D-LoRa, is a fully distributed framework that models the problem as a Combinatorial Multi-Armed Bandit. By decomposing the joint parameter selection and employing specialized, disaggregated reward functions, D-LoRa dramatically reduces learning complexity and enables nodes to autonomously adapt to network dynamics. To further enhance performance in LoRaWAN networks, we introduce CD-LoRa, a hybrid framework that integrates a lightweight, centralized initialization phase to perform a one-time, quasi-optimal channel assignment and action space pruning, thereby accelerating subsequent distributed learning. Extensive simulations and real-world field experiments demonstrate the superiority of our frameworks, showing that D-LoRa excels in non-stationary environments while CD-LoRa achieves the fastest convergence in stationary conditions. In physical deployments, our methods outperform state-of-the-art baselines, improving PDR by up to 10.8% and EE by 26.1%, confirming their practical effectiveness for scalable and efficient LoRaWAN networks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡ LoRaWAN ç½‘ç»œéƒ¨ç½²ä¸­ Packet Delivery Ratio (PDR) ä¸ Energy Efficiency (EE) æ€§èƒ½å†²çªåŠåŠ¨æ€ç¯å¢ƒé€‚åº”æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸¤ç§åŸºäºåœ¨çº¿å­¦ä¹ çš„èµ„æºåˆ†é…æ¡†æ¶ã€‚åŸºç¡€æ¡†æ¶ D-LoRa é‡‡ç”¨å®Œå…¨åˆ†å¸ƒå¼æ¶æ„ï¼Œå°†é—®é¢˜å»ºæ¨¡ä¸º Combinatorial Multi-Armed Banditï¼Œé€šè¿‡åˆ†è§£è”åˆå‚æ•°é€‰æ‹©å’Œåº”ç”¨ä¸“é—¨çš„å¥–åŠ±å‡½æ•°ï¼Œæ˜¾è‘—é™ä½äº†å­¦ä¹ å¤æ‚åº¦å¹¶æ”¯æŒèŠ‚ç‚¹è‡ªä¸»é€‚åº”ç½‘ç»œåŠ¨æ€ã€‚å¢å¼ºå‹æ¡†æ¶ CD-LoRa åˆ™ç»“åˆäº†è½»é‡çº§é›†ä¸­å¼åˆå§‹åŒ–é˜¶æ®µï¼Œé€šè¿‡é¢‘é“åˆ†é…å’ŒåŠ¨ä½œç©ºé—´å‰ªæåŠ é€Ÿåˆ†å¸ƒå¼å­¦ä¹ è¿‡ç¨‹ã€‚å®éªŒä¸å®åœ°éƒ¨ç½²ç»“æœæ˜¾ç¤ºï¼ŒD-LoRa åœ¨éå¹³ç¨³ç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè€Œ CD-LoRa åœ¨å¹³ç¨³æ¡ä»¶ä¸‹æ”¶æ•›é€Ÿåº¦æœ€å¿«ã€‚ç›¸æ¯”ç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œè¯¥æ–¹æ³•å°† PDR å’Œ EE åˆ†åˆ«æå‡äº† 10.8% å’Œ 26.1%ï¼Œæœ‰æ•ˆè¯æ˜äº†å…¶åœ¨æ„å»ºå¯æ‰©å±•ä¸”é«˜æ•ˆçš„ LoRaWAN ç½‘ç»œä¸­çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10493v2",
      "published_date": "2025-08-31 12:36:33 UTC",
      "updated_date": "2025-09-16 13:58:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:50.454155+00:00"
    },
    {
      "arxiv_id": "2509.00813v2",
      "title": "AImoclips: A Benchmark for Evaluating Emotion Conveyance in Text-to-Music Generation",
      "title_zh": "AImoclipsï¼šè¯„ä¼°æ–‡æœ¬åˆ°éŸ³ä¹ç”Ÿæˆä¸­æƒ…æ„Ÿä¼ è¾¾èƒ½åŠ›çš„åŸºå‡†",
      "authors": [
        "Gyehun Go",
        "Satbyul Han",
        "Ahyeon Choi",
        "Eunjin Choi",
        "Juhan Nam",
        "Jeong Mi Park"
      ],
      "abstract": "Recent advances in text-to-music (TTM) generation have enabled controllable and expressive music creation using natural language prompts. However, the emotional fidelity of TTM systems remains largely underexplored compared to human preference or text alignment. In this study, we introduce AImoclips, a benchmark for evaluating how well TTM systems convey intended emotions to human listeners, covering both open-source and commercial models. We selected 12 emotion intents spanning four quadrants of the valence-arousal space, and used six state-of-the-art TTM systems to generate over 1,000 music clips. A total of 111 participants rated the perceived valence and arousal of each clip on a 9-point Likert scale. Our results show that commercial systems tend to produce music perceived as more pleasant than intended, while open-source systems tend to perform the opposite. Emotions are more accurately conveyed under high-arousal conditions across all models. Additionally, all systems exhibit a bias toward emotional neutrality, highlighting a key limitation in affective controllability. This benchmark offers valuable insights into model-specific emotion rendering characteristics and supports future development of emotionally aligned TTM systems.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† AImoclipsï¼Œä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼° Text-to-Music (TTM) ç”Ÿæˆç³»ç»Ÿæƒ…æ„Ÿè¡¨è¾¾ä¿çœŸåº¦çš„åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶å›¢é˜Ÿé€‰å–äº†æ¶µç›– valence-arousal ç©ºé—´å››ä¸ªè±¡é™çš„ 12 ç§æƒ…æ„Ÿæ„å›¾ï¼Œå¹¶åˆ©ç”¨ 6 ä¸ªä»£è¡¨æ€§çš„å¼€æºåŠå•†ä¸š TTM ç³»ç»Ÿç”Ÿæˆäº† 1000 å¤šä¸ªéŸ³ä¹ç‰‡æ®µã€‚é€šè¿‡ 111 åå—è¯•è€…ä½¿ç”¨ 9-point Likert scale å¯¹éŸ³ä¹çš„æ•ˆä»·å’Œå”¤é†’åº¦è¿›è¡Œè¯„åˆ†ï¼Œç ”ç©¶å‘ç°å•†ä¸šæ¨¡å‹ç”Ÿæˆçš„éŸ³ä¹é€šå¸¸æ¯”é¢„æœŸæ›´ä»¤äººæ„‰æ‚¦ï¼Œè€Œå¼€æºæ¨¡å‹åˆ™è¡¨ç°å‡ºç›¸åè¶‹åŠ¿ã€‚å®éªŒæ­ç¤ºäº†æ‰€æœ‰æ¨¡å‹åœ¨é«˜ arousal æ¡ä»¶ä¸‹èƒ½æ›´å‡†ç¡®åœ°ä¼ è¾¾æƒ…æ„Ÿï¼Œä½†ä¹Ÿæ™®éå­˜åœ¨å‘æƒ…æ„Ÿä¸­ç«‹ï¼ˆemotional neutralityï¼‰åç§»çš„åå·®ã€‚è¯¥åŸºå‡†æµ‹è¯•æ­ç¤ºäº†å½“å‰ç³»ç»Ÿåœ¨ affective controllability æ–¹é¢çš„å±€é™æ€§ï¼Œä¸ºæœªæ¥å¼€å‘æƒ…æ„Ÿå¯¹é½çš„ TTM ç³»ç»Ÿæä¾›äº†å…³é”®è§è§£ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "to be published in HCMIR25: 3rd Workshop on Human-Centric Music Information Research",
      "pdf_url": "https://arxiv.org/pdf/2509.00813v2",
      "published_date": "2025-08-31 12:14:30 UTC",
      "updated_date": "2025-09-04 07:41:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:52.657956+00:00"
    },
    {
      "arxiv_id": "2509.00808v1",
      "title": "Adaptive Contrast Adjustment Module: A Clinically-Inspired Plug-and-Play Approach for Enhanced Fetal Plane Classification",
      "title_zh": "è‡ªé€‚åº”å¯¹æ¯”åº¦è°ƒèŠ‚æ¨¡å—ï¼šä¸€ç§å—ä¸´åºŠå¯å‘çš„å³æ’å³ç”¨å‹èƒå„¿åˆ‡é¢åˆ†ç±»å¢å¼ºæ–¹æ³•",
      "authors": [
        "Yang Chen",
        "Sanglin Zhao",
        "Baoyu Chen",
        "Mans Gustaf"
      ],
      "abstract": "Fetal ultrasound standard plane classification is essential for reliable prenatal diagnosis but faces inherent challenges, including low tissue contrast, boundary ambiguity, and operator-dependent image quality variations. To overcome these limitations, we propose a plug-and-play adaptive contrast adjustment module (ACAM), whose core design is inspired by the clinical practice of doctors adjusting image contrast to obtain clearer and more discriminative structural information. The module employs a shallow texture-sensitive network to predict clinically plausible contrast parameters, transforms input images into multiple contrast-enhanced views through differentiable mapping, and fuses them within downstream classifiers. Validated on a multi-center dataset of 12,400 images across six anatomical categories, the module consistently improves performance across diverse models, with accuracy of lightweight models increasing by 2.02 percent, accuracy of traditional models increasing by 1.29 percent, and accuracy of state-of-the-art models increasing by 1.15 percent. The innovation of the module lies in its content-aware adaptation capability, replacing random preprocessing with physics-informed transformations that align with sonographer workflows while improving robustness to imaging heterogeneity through multi-view fusion. This approach effectively bridges low-level image features with high-level semantics, establishing a new paradigm for medical image analysis under real-world image quality variations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†è‡ªé€‚åº”å¯¹æ¯”åº¦è°ƒèŠ‚æ¨¡å—(Adaptive Contrast Adjustment Module, ACAM)ï¼Œè¿™æ˜¯ä¸€ç§ä¸´åºŠå¯å‘å¼çš„å³æ’å³ç”¨æ¨¡å—ï¼Œæ—¨åœ¨è§£å†³èƒå„¿è¶…å£°æ ‡å‡†å¹³é¢åˆ†ç±»ä¸­ç»„ç»‡å¯¹æ¯”åº¦ä½ã€è¾¹ç•Œæ¨¡ç³ŠåŠå›¾åƒè´¨é‡æ³¢åŠ¨ç­‰å›ºæœ‰æŒ‘æˆ˜ã€‚è¯¥æ¨¡å—çš„è®¾è®¡çµæ„Ÿæºè‡ªåŒ»ç”Ÿæ‰‹åŠ¨è°ƒèŠ‚å¯¹æ¯”åº¦çš„ä¸´åºŠå®è·µï¼Œé€šè¿‡æµ…å±‚çº¹ç†æ•æ„Ÿç½‘ç»œ(shallow texture-sensitive network)é¢„æµ‹ä¸´åºŠåˆç†çš„å¯¹æ¯”åº¦å‚æ•°ï¼Œå¹¶åˆ©ç”¨å¯å¾®æ˜ å°„(differentiable mapping)å°†å›¾åƒè½¬åŒ–ä¸ºå¤šä¸ªå¢å¼ºè§†å›¾è¿›è¡Œå¤šè§†å›¾èåˆã€‚åœ¨åŒ…å«12,400å¼ å›¾åƒçš„å¤šä¸­å¿ƒæ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å—ä½¿è½»é‡åŒ–æ¨¡å‹å’ŒSOTAæ¨¡å‹çš„å‡†ç¡®ç‡åˆ†åˆ«æå‡äº†2.02%å’Œ1.15%ï¼Œå±•ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›å’Œå¯¹æˆåƒå¼‚è´¨æ€§çš„é²æ£’æ€§ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå†…å®¹æ„ŸçŸ¥çš„è‡ªé€‚åº”èƒ½åŠ›ï¼Œé€šè¿‡ç‰©ç†å¯å‘çš„å˜æ¢å–ä»£éšæœºé¢„å¤„ç†ï¼Œä½¿ç®—æ³•é€»è¾‘ä¸è¶…å£°åŒ»å¸ˆçš„ä¸´åºŠå·¥ä½œæµé«˜åº¦å¯¹é½ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°è¡”æ¥äº†ä½çº§å›¾åƒç‰¹å¾ä¸é«˜çº§è¯­ä¹‰ï¼Œä¸ºå¤„ç†ç°å®åœºæ™¯ä¸­å›¾åƒè´¨é‡æ³¢åŠ¨çš„åŒ»å­¦å½±åƒåˆ†æä»»åŠ¡å»ºç«‹äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00808v1",
      "published_date": "2025-08-31 11:46:51 UTC",
      "updated_date": "2025-08-31 11:46:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:41:58.637941+00:00"
    },
    {
      "arxiv_id": "2509.00806v1",
      "title": "CaresAI at BioCreative IX Track 1 -- LLM for Biomedical QA",
      "title_zh": "CaresAI å‚åŠ  BioCreative IX Track 1 â€”â€” é¢å‘ç”Ÿç‰©åŒ»å­¦é—®ç­”çš„å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Reem Abdel-Salam",
        "Mary Adewunmi",
        "Modinat A. Abayomi"
      ],
      "abstract": "Large language models (LLMs) are increasingly evident for accurate question answering across various domains. However, rigorous evaluation of their performance on complex question-answering (QA) capabilities is essential before deployment in real-world biomedical and healthcare applications. This paper presents our approach to the MedHopQA track of the BioCreative IX shared task, which focuses on multi-hop biomedical question answering involving diseases, genes, and chemicals. We adopt a supervised fine-tuning strategy leveraging LLaMA 3 8B, enhanced with a curated biomedical question-answer dataset compiled from external sources including BioASQ, MedQuAD, and TREC. Three experimental setups are explored: fine-tuning on combined short and long answers, short answers only, and long answers only. While our models demonstrate strong domain understanding, achieving concept-level accuracy scores of up to 0.8, their Exact Match (EM) scores remain significantly lower, particularly in the test phase. We introduce a two-stage inference pipeline for precise short-answer extraction to mitigate verbosity and improve alignment with evaluation metrics. Despite partial improvements, challenges persist in generating strictly formatted outputs. Our findings highlight the gap between semantic understanding and exact answer evaluation in biomedical LLM applications, motivating further research in output control and post-processing strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹BioCreative IXçš„MedHopQAä»»åŠ¡ï¼Œæ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ¶‰åŠç–¾ç—…ã€åŸºå› å’ŒåŒ–å­¦ç‰©è´¨çš„å¤šè·³ç”Ÿç‰©åŒ»å­¦é—®ç­”(multi-hop biomedical question answering)ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)ç­–ç•¥ï¼ŒåŸºäºLLaMA 3 8Bæ¨¡å‹å¹¶ç»“åˆäº†ä»BioASQã€MedQuADå’ŒTRECç­‰å¤–éƒ¨èµ„æºæ±‡ç¼–çš„ç”Ÿç‰©åŒ»å­¦é—®ç­”æ•°æ®é›†ã€‚å®éªŒæ¢ç´¢äº†é’ˆå¯¹çŸ­ç­”æ¡ˆã€é•¿ç­”æ¡ˆä»¥åŠä¸¤è€…ç»“åˆçš„ä¸‰ç§ä¸åŒå¾®è°ƒè®¾ç½®ï¼Œç»“æœæ˜¾ç¤ºæ¨¡å‹åœ¨æ¦‚å¿µçº§å‡†ç¡®ç‡(concept-level accuracy)ä¸Šæœ€é«˜è¾¾åˆ°äº†0.8ï¼Œå±•ç°äº†æå¼ºçš„é¢†åŸŸç†è§£èƒ½åŠ›ã€‚ç„¶è€Œï¼Œæ¨¡å‹åœ¨ç²¾ç¡®åŒ¹é…(Exact Match)å¾—åˆ†ä¸Šè¡¨ç°ç›¸å¯¹è¾ƒä½ï¼Œå°¤å…¶æ˜¯åœ¨æµ‹è¯•é˜¶æ®µæš´éœ²å‡ºè¾“å‡ºå†—é•¿å’Œæ ¼å¼å¯¹é½ç­‰æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶äººå‘˜å¼•å…¥äº†ä¸€ç§ä¸¤é˜¶æ®µæ¨ç†æµæ°´çº¿(two-stage inference pipeline)è¿›è¡Œç²¾ç¡®çš„çŸ­ç­”æ¡ˆæå–ï¼Œæ—¨åœ¨ç¼“è§£å†—ä½™å¹¶æé«˜ä¸è¯„ä¼°æŒ‡æ ‡çš„ä¸€è‡´æ€§ã€‚è¯¥ç ”ç©¶æœ€ç»ˆæ­ç¤ºäº†ç”Ÿç‰©åŒ»å­¦é¢†åŸŸLLMåº”ç”¨ä¸­è¯­ä¹‰ç†è§£ä¸ç²¾ç¡®ç­”æ¡ˆè¯„ä¼°ä¹‹é—´çš„å·®è·ï¼Œå¹¶å¼ºè°ƒäº†è¾“å‡ºæ§åˆ¶ä¸åå¤„ç†ç­–ç•¥åœ¨æœªæ¥ç ”ç©¶ä¸­çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the BioCreative IX Challenge and Workshop (BC9): Large Language Models for Clinical and Biomedical NLP at the International Joint Conference on Artificial Intelligence (IJCAI), Montreal, Canada, 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00806v1",
      "published_date": "2025-08-31 11:40:02 UTC",
      "updated_date": "2025-08-31 11:40:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:14.296234+00:00"
    },
    {
      "arxiv_id": "2509.00798v4",
      "title": "Multimodal Iterative RAG for Knowledge-Intensive Visual Question Answering",
      "title_zh": "é¢å‘çŸ¥è¯†å¯†é›†å‹è§†è§‰é—®ç­”çš„å¤šæ¨¡æ€è¿­ä»£ RAG",
      "authors": [
        "Changin Choi",
        "Wonseok Lee",
        "Jungmin Ko",
        "Wonjong Rhee"
      ],
      "abstract": "Recent advances in Multimodal Large Language Models~(MLLMs) have significantly enhanced the ability of these models in multimodal understanding and reasoning. However, the performance of MLLMs for knowledge-intensive visual questions, which require external knowledge beyond the visual content of an image, still remains limited. While Retrieval-Augmented Generation (RAG) has become a promising solution to provide models with external knowledge, its conventional single-pass framework often fails to gather sufficient knowledge. To overcome this limitation, we propose MI-RAG, a Multimodal Iterative RAG framework that leverages reasoning to enhance retrieval and incorporates knowledge synthesis to refine its understanding. At each iteration, the model formulates a reasoning-guided multi-query to explore multiple facets of knowledge. Subsequently, these queries drive a joint search across heterogeneous knowledge bases, retrieving diverse knowledge. This retrieved knowledge is then synthesized to enrich the reasoning record, progressively deepening the model's understanding. Experiments on challenging benchmarks, including Encyclopedic VQA, InfoSeek, and OK-VQA, show that MI-RAG significantly improves both retrieval recall and answer accuracy, establishing a scalable approach for compositional reasoning in knowledge-intensive VQA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹è§†è§‰é—®ç­”ï¼ˆKnowledge-intensive VQAï¼‰æ—¶å¤–éƒ¨çŸ¥è¯†è·å–ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº† MI-RAG è¿­ä»£å¼æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ã€‚MI-RAG é€šè¿‡æ¨ç†å¼•å¯¼çš„å¤šé‡æŸ¥è¯¢ï¼ˆReasoning-guided Multi-queryï¼‰åœ¨å¼‚æ„çŸ¥è¯†åº“ï¼ˆHeterogeneous Knowledge Basesï¼‰ä¸­è¿›è¡Œè·¨ç»´åº¦è”åˆæœç´¢ï¼Œæ—¨åœ¨å…‹æœä¼ ç»Ÿå•æ¬¡æ£€ç´¢æ¡†æ¶çš„å±€é™æ€§ã€‚åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹åˆ©ç”¨çŸ¥è¯†åˆæˆï¼ˆKnowledge Synthesisï¼‰æŠ€æœ¯ä¸æ–­ä¸°å¯Œæ¨ç†è®°å½•ï¼Œä»è€Œé€æ­¥æ·±åŒ–å¯¹å¤æ‚é—®é¢˜çš„ç†è§£ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMI-RAG åœ¨ Encyclopedic VQAã€InfoSeek å’Œ OK-VQA ç­‰å¤šä¸ªæŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†æ£€ç´¢å¬å›ç‡ï¼ˆRetrieval Recallï¼‰å’Œå›ç­”å‡†ç¡®åº¦ã€‚è¯¥æ–¹æ³•ä¸ºå¤šæ¨¡æ€ç¯å¢ƒä¸‹çš„ç»„åˆæ¨ç†ï¼ˆCompositional Reasoningï¼‰æä¾›äº†ä¸€ä¸ªå…·æœ‰è‰¯å¥½æ‰©å±•æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00798v4",
      "published_date": "2025-08-31 11:14:54 UTC",
      "updated_date": "2025-09-29 13:50:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:18.181509+00:00"
    },
    {
      "arxiv_id": "2509.00797v1",
      "title": "ProCause: Generating Counterfactual Outcomes to Evaluate Prescriptive Process Monitoring Methods",
      "title_zh": "ProCauseï¼šé€šè¿‡ç”Ÿæˆåäº‹å®ç»“æœè¯„ä¼°è§„èŒƒæ€§è¿‡ç¨‹ç›‘æ§æ–¹æ³•",
      "authors": [
        "Jakob De Moor",
        "Hans Weytjens",
        "Johannes De Smedt"
      ],
      "abstract": "Prescriptive Process Monitoring (PresPM) is the subfield of Process Mining that focuses on optimizing processes through real-time interventions based on event log data. Evaluating PresPM methods is challenging due to the lack of ground-truth outcomes for all intervention actions in datasets. A generative deep learning approach from the field of Causal Inference (CI), RealCause, has been commonly used to estimate the outcomes for proposed intervention actions to evaluate a new policy. However, RealCause overlooks the temporal dependencies in process data, and relies on a single CI model architecture, TARNet, limiting its effectiveness. To address both shortcomings, we introduce ProCause, a generative approach that supports both sequential (e.g., LSTMs) and non-sequential models while integrating multiple CI architectures (S-Learner, T-Learner, TARNet, and an ensemble). Our research using a simulator with known ground truths reveals that TARNet is not always the best choice; instead, an ensemble of models offers more consistent reliability, and leveraging LSTMs shows potential for improved evaluations when temporal dependencies are present. We further validate ProCause's practical effectiveness through a real-world data analysis, ensuring a more reliable evaluation of PresPM methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§„èŒƒæ€§è¿‡ç¨‹ç›‘æ§ (Prescriptive Process Monitoring, PresPM) é¢†åŸŸä¸­ç”±äºç¼ºä¹å¹²é¢„è¡ŒåŠ¨çš„åäº‹å®ç»“æœçœŸå®å€¼ (ground-truth) è€Œå¯¼è‡´æ–¹æ³•è¯„ä¼°å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ç”Ÿæˆå¼æ–¹æ³• ProCauseã€‚ProCause æ”¹è¿›äº†ç°æœ‰çš„ RealCause æ–¹æ³•ï¼Œä¸ä»…æ”¯æŒå¤„ç†è¿‡ç¨‹æ•°æ®ä¸­çš„æ—¶é—´ä¾èµ–æ€§ (temporal dependencies)ï¼Œè¿˜æ•´åˆäº†å¤šç§å› æœæ¨ç† (Causal Inference) æ¶æ„ï¼ŒåŒ…æ‹¬ S-Learnerã€T-Learnerã€TARNet ä»¥åŠé›†æˆæ¨¡å‹ (ensemble)ã€‚å®éªŒç ”ç©¶è¡¨æ˜ï¼Œå•ä¸€çš„ TARNet æ¶æ„å¹¶éæ€»æ˜¯æœ€ä½³é€‰æ‹©ï¼Œè€Œé›†æˆæ¨¡å‹å±•ç°äº†æ›´ä¸€è‡´çš„å¯é æ€§ï¼Œä¸”å¼•å…¥ LSTM åºåˆ—æ¨¡å‹èƒ½æœ‰æ•ˆæå‡å­˜åœ¨æ—¶é—´ä¾èµ–æ€§æ—¶çš„è¯„ä¼°æ•ˆæœã€‚é€šè¿‡åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„éªŒè¯ï¼ŒProCause èƒ½å¤Ÿä¸º PresPM æ–¹æ³•æä¾›æ›´å‡†ç¡®ã€å¯é çš„æ€§èƒ½è¯„ä¼°å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00797v1",
      "published_date": "2025-08-31 10:54:43 UTC",
      "updated_date": "2025-08-31 10:54:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:20.201310+00:00"
    },
    {
      "arxiv_id": "2509.00793v1",
      "title": "Sharpe Ratio Optimization in Markov Decision Processes",
      "title_zh": "é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸­çš„å¤æ™®æ¯”ç‡ä¼˜åŒ–",
      "authors": [
        "Shuai Ma",
        "Guangwu Liu",
        "Li Xia"
      ],
      "abstract": "Sharpe ratio (also known as reward-to-variability ratio) is a widely-used metric in finance, which measures the additional return at the cost of per unit of increased risk (standard deviation of return). However, the optimization of Sharpe ratio in Markov decision processes (MDPs) is challenging, because there exist two difficulties hindering the application of dynamic programming. One is that dynamic programming does not work for fractional objectives, and the other is that dynamic programming is invalid for risk metrics. In this paper, we study the Sharpe ratio optimization in infinite-horizon MDPs, considering both the long-run average and discounted settings. We address the first challenge with the Dinkelbachs transform, which converts the Sharpe ratio objective to a mean-squared-variance (M2V) objective. It is shown that the M2V optimization and the original Sharpe ratio optimization share the same optimal policy when the risk-sensitive parameter is equal to the optimal Sharpe ratio. For the second challenge, we develop an iterative algorithm to solve the M2V optimization which is similar to a mean-variance optimization in MDPs. We iteratively solve the M2V problem and obtain the associated Sharpe ratio that is used to update the risk-sensitive parameter in the next iteration of M2V problems. We show that such a sequence of Sharpe ratios derived is monotonically increasing and converges to the optimal Sharpe ratio. For both average and discounted MDP settings, we develop a policy iteration procedure and prove its convergence to the optimum. Numerical experiments are conducted for validation. To the best of our knowledge, our approach is the first that solves the Sharpe ratio optimization in MDPs with dynamic programming type algorithms. We believe that the proposed algorithm can shed light on solving MDPs with other fractional objectives.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åœ¨é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (Markov Decision Processes, MDPs) ä¸­ä¼˜åŒ– Sharpe ratio çš„é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³é‡‘èé¢†åŸŸè¡¡é‡å•ä½é£é™©è¶…é¢å›æŠ¥çš„å…³é”®æŒ‡æ ‡ä¼˜åŒ–æŒ‘æˆ˜ã€‚é’ˆå¯¹åŠ¨æ€è§„åˆ’ (Dynamic Programming) éš¾ä»¥ç›´æ¥å¤„ç†åˆ†å¼ç›®æ ‡å’Œé£é™©åº¦é‡çš„é—®é¢˜ï¼Œè®ºæ–‡åœ¨æ— é™æ—¶ç•Œ (Infinite-horizon) è®¾ç½®ä¸‹åŒæ—¶è€ƒè™‘äº†é•¿æœŸå¹³å‡å’ŒæŠ˜æ‰£å¥–åŠ±åœºæ™¯ã€‚ç ”ç©¶å¼•å…¥äº† Dinkelbach's transform å°† Sharpe ratio ç›®æ ‡è½¬åŒ–ä¸ºå‡å€¼-æ–¹å·® (Mean-Squared-Variance, M2V) ä¼˜åŒ–ç›®æ ‡ï¼Œå¹¶è¯æ˜äº†ä¸¤è€…åœ¨ç‰¹å®šé£é™©æ•æ„Ÿå‚æ•°ä¸‹å…±äº«ç›¸åŒçš„æœ€ä¼˜ç­–ç•¥ã€‚é€šè¿‡å¼€å‘ä¸€ç§è¿­ä»£ç®—æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¾ªç¯æ›´æ–°å‚æ•°å¹¶ç¡®ä¿ Sharpe ratio åºåˆ—å•è°ƒé€’å¢è‡³æœ€ä¼˜å€¼ã€‚è®ºæ–‡è¿˜æå‡ºäº†é€‚ç”¨äºä¸¤ç§ MDP è®¾ç½®çš„ç­–ç•¥è¿­ä»£ (Policy Iteration) è¿‡ç¨‹å¹¶è¯æ˜äº†å…¶æ”¶æ•›æ€§ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ï¼Œä½œä¸ºé¦–ä¸ªåˆ©ç”¨åŠ¨æ€è§„åˆ’ç±»ç®—æ³•è§£å†³ MDPs ä¸­ Sharpe ratio ä¼˜åŒ–çš„ç ”ç©¶ï¼Œå®ƒä¸ºå¤„ç†å…¶ä»–åˆ†å¼ç›®æ ‡ä¼˜åŒ–é—®é¢˜æä¾›äº†é‡è¦å€Ÿé‰´ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00793v1",
      "published_date": "2025-08-31 10:38:15 UTC",
      "updated_date": "2025-08-31 10:38:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:36.692026+00:00"
    },
    {
      "arxiv_id": "2509.04483v1",
      "title": "DecMetrics: Structured Claim Decomposition Scoring for Factually Consistent LLM Outputs",
      "title_zh": "DecMetricsï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºäº‹å®ä¸€è‡´æ€§çš„ç»“æ„åŒ–ä¸»å¼ åˆ†è§£è¯„åˆ†",
      "authors": [
        "Minghui Huang"
      ],
      "abstract": "Claim decomposition plays a crucial role in the fact-checking process by breaking down complex claims into simpler atomic components and identifying their unfactual elements. Despite its importance, current research primarily focuses on generative methods for decomposition, with insufficient emphasis on evaluating the quality of these decomposed atomic claims. To bridge this gap, we introduce \\textbf{DecMetrics}, which comprises three new metrics: \\texttt{COMPLETENESS}, \\texttt{CORRECTNESS}, and \\texttt{SEMANTIC ENTROPY}, designed to automatically assess the quality of claims produced by decomposition models. Utilizing these metrics, we develop a lightweight claim decomposition model, optimizing its performance through the integration of these metrics as a reward function. Through automatic evaluation, our approach aims to set a benchmark for claim decomposition, enhancing both the reliability and effectiveness of fact-checking systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº‹å®æ ¸æŸ¥ä¸­ä¸»å¼ åˆ†è§£(Claim decomposition)ç”Ÿæˆçš„åŸå­ä¸»å¼ ç¼ºä¹è´¨é‡è¯„ä¼°è¿™ä¸€ç°çŠ¶ï¼Œæå‡ºäº†DecMetricsè¯„ä¼°æ¡†æ¶ã€‚DecMetricsåŒ…å«äº†ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡ï¼šCOMPLETENESSã€CORRECTNESSå’ŒSEMANTIC ENTROPYï¼Œæ—¨åœ¨è‡ªåŠ¨è¡¡é‡åˆ†è§£æ¨¡å‹äº§ç”Ÿçš„ä¸»å¼ è´¨é‡ã€‚åˆ©ç”¨è¿™äº›æŒ‡æ ‡ä½œä¸ºå¥–åŠ±å‡½æ•°(Reward function)ï¼Œç ”ç©¶äººå‘˜å¼€å‘å¹¶ä¼˜åŒ–äº†ä¸€ä¸ªè½»é‡çº§çš„ä¸»å¼ åˆ†è§£æ¨¡å‹ï¼Œä»¥ç¡®ä¿å¤§è¯­è¨€æ¨¡å‹(LLMs)è¾“å‡ºçš„äº‹å®ä¸€è‡´æ€§(Factually consistent)ã€‚é€šè¿‡è‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œè¯¥æ–¹æ³•å¡«è¡¥äº†å½“å‰ç ”ç©¶è¿‡åº¦å…³æ³¨ç”Ÿæˆè€Œå¿½è§†è¯„ä¼°è´¨é‡çš„ç©ºç™½ï¼Œä¸ºåˆ†è§£ä»»åŠ¡å»ºç«‹äº†æ–°çš„åŸºå‡†ï¼Œæ˜¾è‘—å¢å¼ºäº†äº‹å®æ ¸æŸ¥ç³»ç»Ÿçš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04483v1",
      "published_date": "2025-08-31 10:22:54 UTC",
      "updated_date": "2025-08-31 10:22:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:27.392013+00:00"
    },
    {
      "arxiv_id": "2509.00783v1",
      "title": "LegalChainReasoner: A Legal Chain-guided Framework for Criminal Judicial Opinion Generation",
      "title_zh": "LegalChainReasonerï¼šåŸºäºæ³•å¾‹é“¾å¼•å¯¼çš„åˆ‘äº‹å¸æ³•æ„è§ç”Ÿæˆæ¡†æ¶",
      "authors": [
        "Weizhe Shi",
        "Qiqi Wang",
        "Yihong Pan",
        "Qian Liu",
        "Kaiqi Zhao"
      ],
      "abstract": "A criminal judicial opinion represents the judge's disposition of a case, including the decision rationale and sentencing. Automatically generating such opinions can assist in analyzing sentencing consistency and provide judges with references to similar past cases. However, current research typically approaches this task by dividing it into two isolated subtasks: legal reasoning and sentencing prediction. This separation often leads to inconsistency between the reasoning and predictions, failing to meet real-world judicial requirements. Furthermore, prior studies rely on manually curated knowledge to enhance applicability, yet such methods remain limited in practical deployment. To address these limitations and better align with legal practice, we propose a new LegalAI task: Judicial Opinion Generation, which simultaneously produces both legal reasoning and sentencing decisions. To achieve this, we introduce LegalChainReasoner, a framework that applies structured legal chains to guide the model through comprehensive case assessments. By integrating factual premises, composite legal conditions, and sentencing conclusions, our approach ensures flexible knowledge injection and end-to-end opinion generation. Experiments on two real-world and open-source Chinese legal case datasets demonstrate that our method outperforms baseline models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LegalChainReasonerï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³åˆ‘äº‹å¸æ³•æ–‡ä¹¦ç”Ÿæˆä¸­æ³•å¾‹æ¨ç†ä¸é‡åˆ‘é¢„æµ‹ä¹‹é—´ä¸ä¸€è‡´é—®é¢˜çš„æ³•å¾‹é“¾å¼•å¯¼æ¡†æ¶ã€‚ä¸ºäº†æ›´å¥½åœ°å¥‘åˆå¸æ³•å®è·µï¼Œç ”ç©¶è€…å®šä¹‰äº† Judicial Opinion Generation è¿™ä¸€å…¨æ–°çš„ LegalAI ä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹åŒæ­¥ç”Ÿæˆæ³•å¾‹æ¨ç†å’Œé‡åˆ‘ç»“æœã€‚LegalChainReasoner æ¡†æ¶é€šè¿‡åº”ç”¨ç»“æ„åŒ–çš„æ³•å¾‹é“¾æ¥å¼•å¯¼æ¨¡å‹è¿›è¡Œå…¨é¢çš„æ¡ˆä»¶è¯„ä¼°ï¼Œå…¶æ ¸å¿ƒåœ¨äºæ•´åˆäº‹å®å‰æã€å¤åˆæ³•å¾‹æ¡ä»¶å’Œé‡åˆ‘ç»“è®ºã€‚è¯¥æ–¹æ³•å®ç°äº†çµæ´»çš„çŸ¥è¯†æ³¨å…¥å’Œç«¯åˆ°ç«¯çš„æ„è§ç”Ÿæˆï¼Œå…‹æœäº†ä»¥å¾€ç ”ç©¶è¿‡åº¦ä¾èµ–æ‰‹åŠ¨ç­–åˆ’çŸ¥è¯†çš„å±€é™æ€§ã€‚åœ¨ä¸¤ä¸ªçœŸå®çš„å¼€æºä¸­æ–‡æ³•å¾‹æ¡ˆä¾‹æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œä¸ºæé«˜é‡åˆ‘ä¸€è‡´æ€§å’Œè¾…åŠ©æ³•å®˜å†³ç­–æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00783v1",
      "published_date": "2025-08-31 10:22:47 UTC",
      "updated_date": "2025-08-31 10:22:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:31.053111+00:00"
    },
    {
      "arxiv_id": "2509.04482v2",
      "title": "Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare",
      "title_zh": "èƒ½é‡æ™¯è§‚åŠ©åŠ›åŒ»ç–—æ£€ç´¢å¢å¼ºå¤§è¯­è¨€æ¨¡å‹å®ç°å¯é æ‹’ç­”",
      "authors": [
        "Ravi Shankar",
        "Sheng Wong",
        "Lin Li",
        "Magdalena Bachmann",
        "Alex Silverthorne",
        "Beth Albert",
        "Gabriel Davis Jones"
      ],
      "abstract": "Reliable abstention is critical for retrieval-augmented generation (RAG) systems, particularly in safety-critical domains such as women's health, where incorrect answers can lead to harm. We present an energy-based model (EBM) that learns a smooth energy landscape over a dense semantic corpus of 2.6M guideline-derived questions, enabling the system to decide when to generate or abstain. We benchmark the EBM against a calibrated softmax baseline and a k-nearest neighbour (kNN) density heuristic across both easy and hard abstention splits, where hard cases are semantically challenging near-distribution queries. The EBM achieves superior abstention performance abstention on semantically hard cases, reaching AUROC 0.961 versus 0.950 for softmax, while also reducing FPR@95 (0.235 vs 0.331). On easy negatives, performance is comparable across methods, but the EBM's advantage becomes most pronounced in safety-critical hard distributions. A comprehensive ablation with controlled negative sampling and fair data exposure shows that robustness stems primarily from the energy scoring head, while the inclusion or exclusion of specific negative types (hard, easy, mixed) sharpens decision boundaries but is not essential for generalisation to hard cases. These results demonstrate that energy-based abstention scoring offers a more reliable confidence signal than probability-based softmax confidence, providing a scalable and interpretable foundation for safe RAG systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—ä¿å¥ç­‰å®‰å…¨å…³é”®é¢†åŸŸä¸­æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿçš„å¯é å¼ƒæƒ(Abstention)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºèƒ½é‡æ¨¡å‹(Energy-Based Model, EBM)çš„æ–¹æ³•ã€‚è¯¥æ¨¡å‹é€šè¿‡åœ¨åŒ…å«260ä¸‡ä¸ªåŸºäºæŒ‡å—é—®é¢˜çš„å¯†é›†è¯­ä¹‰è¯­æ–™åº“ä¸Šå­¦ä¹ å¹³æ»‘çš„èƒ½é‡æ™¯è§‚(Energy Landscape)ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿæ›´å‡†ç¡®åœ°åˆ¤æ–­ä½•æ—¶ç”Ÿæˆå›ç­”æˆ–é€‰æ‹©å¼ƒæƒã€‚å®éªŒå°†EBMä¸æ ¡å‡†Softmax(Calibrated Softmax)åŠk-æœ€è¿‘é‚»(kNN)å¯†åº¦å¯å‘å¼æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ï¼Œç»“æœæ˜¾ç¤ºEBMåœ¨è¯­ä¹‰å›°éš¾æ¡ˆä¾‹ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…¶AUROCè¾¾åˆ°0.961ï¼Œä¸”æ˜¾è‘—é™ä½äº†FPR@95ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œç³»ç»Ÿçš„é²æ£’æ€§ä¸»è¦æºäºèƒ½é‡è¯„åˆ†å¤´ï¼Œè€Œéç‰¹å®šçš„è´Ÿé‡‡æ ·ç­–ç•¥ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åŸºäºèƒ½é‡çš„å¼ƒæƒè¯„åˆ†æ¯”ä¼ ç»Ÿçš„Softmaxç½®ä¿¡åº¦æ›´å¯é ï¼Œä¸ºæ„å»ºå®‰å…¨ã€å¯æ‰©å±•ä¸”å¯è§£é‡Šçš„åŒ»ç–—RAGç³»ç»Ÿæä¾›äº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04482v2",
      "published_date": "2025-08-31 10:20:48 UTC",
      "updated_date": "2025-09-08 14:04:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:35.795180+00:00"
    },
    {
      "arxiv_id": "2509.06979v1",
      "title": "Exploring Over-stationarization in Deep Learning-based Bus/Tram Arrival Time Prediction: Analysis and Non-stationary Effect Recovery",
      "title_zh": "æ¢ç©¶åŸºäºæ·±åº¦å­¦ä¹ çš„å…¬äº¤/æœ‰è½¨ç”µè½¦åˆ°ç«™æ—¶é—´é¢„æµ‹ä¸­çš„è¿‡å¹³ç¨³åŒ–ï¼šåˆ†æä¸éå¹³ç¨³æ•ˆåº”æ¢å¤",
      "authors": [
        "Zirui Li",
        "Bin Yang",
        "Meng Wang"
      ],
      "abstract": "Arrival time prediction (ATP) of public transport vehicles is essential in improving passenger experience and supporting traffic management. Deep learning has demonstrated outstanding performance in ATP due to its ability to model non-linear and temporal dynamics. In the multi-step ATP, non-stationary data will degrade the model performance due to the variation in variables' joint distribution along the temporal direction. Previous studies mainly applied normalization to eliminate the non-stationarity in time series, thereby achieving better predictability. However, the normalization may obscure useful characteristics inherent in non-stationarity, which is known as the over-stationarization. In this work, to trade off predictability and non-stationarity, a new approach for multi-step ATP, named non-stationary ATP ( NSATP), is proposed. The method consists of two stages: series stationarization and non-stationarity effect recovery. The first stage aims at improving the predictability. As for the latter, NSATP extends a state-of-the-art method from one-dimensional to two dimensional based models to capture the hidden periodicity in time series and designs a compensation module of over-stationarization by learning scaling and shifting factors from raw data. 125 days' public transport operational data of Dresden is collected for validation. Experimental results show that compared to baseline methods, the proposed NSATP can reduce RMSE, MAE, and MAPE by 2.37%, 1.22%, and 2.26% for trams and by 1.72%, 0.60%, and 1.17% for buses, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºæ·±åº¦å­¦ä¹ çš„å…¬äº¤/æœ‰è½¨ç”µè½¦åˆ°è¾¾æ—¶é—´é¢„æµ‹ (Arrival Time Prediction, ATP) ä¸­çš„è¿‡åº¦å¹³ç¨³åŒ– (Over-stationarization) é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿå½’ä¸€åŒ–æ–¹æ³•åœ¨æé«˜é¢„æµ‹èƒ½åŠ›çš„åŒæ—¶ä¼šæ©ç›–éå¹³ç¨³æ•°æ®ä¸­çš„æœ‰ç”¨ç‰¹å¾ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸ºéå¹³ç¨³ ATP (Non-stationary ATP, NSATP) çš„å¤šæ­¥é¢„æµ‹æ–°æ–¹æ³•ï¼Œç”±åºåˆ—å¹³ç¨³åŒ–å’Œéå¹³ç¨³æ•ˆåº”æ¢å¤ä¸¤ä¸ªé˜¶æ®µç»„æˆã€‚è¯¥æ–¹æ³•å°†ç°æœ‰å…ˆè¿›æŠ€æœ¯ä»ä¸€ç»´æ‰©å±•è‡³äºŒç»´æ¨¡å‹ä»¥æ•æ‰æ—¶é—´åºåˆ—ä¸­çš„éšè—å‘¨æœŸæ€§ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªé€šè¿‡å­¦ä¹ åŸå§‹æ•°æ®ç¼©æ”¾å’Œåç§»å› å­çš„è¡¥å¿æ¨¡å—æ¥è§£å†³è¿‡åº¦å¹³ç¨³åŒ–é—®é¢˜ã€‚åˆ©ç”¨å¾·ç´¯æ–¯é¡¿ (Dresden) 125 å¤©çš„å…¬å…±äº¤é€šè¿è¥æ•°æ®è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒNSATP åœ¨ RMSEã€MAE å’Œ MAPE æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†åœ¨å¤šæ­¥ ATP ä»»åŠ¡ä¸­æ¢å¤éå¹³ç¨³æ•ˆåº”å¯¹äºæå‡é¢„æµ‹ç²¾åº¦çš„é‡è¦æ€§ï¼Œä¸ºå…¬å…±äº¤é€šç®¡ç†æä¾›äº†æ›´å¯é çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06979v1",
      "published_date": "2025-08-31 09:50:03 UTC",
      "updated_date": "2025-08-31 09:50:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:39.883199+00:00"
    },
    {
      "arxiv_id": "2509.00768v2",
      "title": "Aligning Reasoning LLMs for Materials Discovery with Physics-aware Rejection Sampling",
      "title_zh": "åˆ©ç”¨ç‰©ç†æ„ŸçŸ¥æ‹’ç»é‡‡æ ·å¯¹é½é¢å‘ææ–™å‘ç°çš„æ¨ç†å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Lee Hyun",
        "Sohee Yoon",
        "Jinwoo Park",
        "Sue In Chae",
        "Seongeon Park",
        "Jooyeon Ahn",
        "Yebin Jung",
        "Youjung Chung",
        "Hogeun Chang",
        "Sujin Park",
        "Myeonginn Kang",
        "Jina Kim",
        "Ho-Gyeong Kim",
        "Myeonghun Jeong"
      ],
      "abstract": "AI-driven materials discovery that couples automated experimentation with algorithmic decision-making requires process aware recipe to property predictors that are accurate, calibrated, and physically admissible. We approach this as a reasoning problem with large reasoning models (LRMs). To instill reasoning capability into language models, we curate reasoning traces from a teacher model to train a student model. However, most training pipelines select reasoning traces using binary correctness or learned preference signals that poorly reflect physical admissibility. We introduce Physics-aware Rejection Sampling (PaRS), a training-time trace selection scheme that favors traces consistent with fundamental physics and numerically close to targets, with lightweight halting to control compute. We instantiate our framework with a large student model fine-tuned on traces synthesized by a larger teacher model, and evaluate under matched token budgets against various rejection sampling baselines. Our method improves accuracy and calibration, reduces physics-violation rates, and lowers sampling cost relative to baselines. These results indicate that modest, domain-aware constraints combined with trace-level selection provide a practical path toward reliable, efficient LRMs for process-aware property prediction and closed-loop materials design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºPhysics-aware Rejection Sampling (PaRS)çš„è®­ç»ƒé˜¶æ®µè½¨è¿¹é€‰æ‹©æ–¹æ¡ˆï¼Œæ—¨åœ¨æå‡æ¨ç†å¤§è¯­è¨€æ¨¡å‹(Large Reasoning Models, LRMs)åœ¨ææ–™å‘ç°é¢†åŸŸçš„ç‰©ç†ä¸€è‡´æ€§å’Œé¢„æµ‹ç²¾åº¦ã€‚é’ˆå¯¹ç°æœ‰è®­ç»ƒæµæ°´çº¿ä¸­åå¥½ä¿¡å·éš¾ä»¥åæ˜ ç‰©ç†å‡†åˆ™çš„é—®é¢˜ï¼ŒPaRSä¼˜å…ˆé€‰æ‹©ç¬¦åˆåŸºæœ¬ç‰©ç†å®šå¾‹ä¸”æ•°å€¼æ¥è¿‘ç›®æ ‡å±æ€§çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶å¼•å…¥è½»é‡åŒ–åœæœº(lightweight halting)æœºåˆ¶ä»¥ä¼˜åŒ–è®¡ç®—æˆæœ¬ã€‚ç ”ç©¶é€šè¿‡ä½¿ç”¨å¤§å‹æ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„æ¨ç†è½¨è¿¹å¾®è°ƒå­¦ç”Ÿæ¨¡å‹è¿›è¡ŒéªŒè¯ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å‡†ç¡®æ€§ã€æ ¡å‡†åº¦ä»¥åŠé™ä½ç‰©ç†è¿è§„ç‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒPaRSåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶é™ä½äº†é‡‡æ ·å¼€é”€ï¼Œè¯æ˜äº†ç»“åˆé¢†åŸŸæ„ŸçŸ¥çº¦æŸä¸è½¨è¿¹çº§é€‰æ‹©æ˜¯æ„å»ºå¯é ã€é«˜æ•ˆçš„æµç¨‹æ„ŸçŸ¥(process-aware)å±æ€§é¢„æµ‹åŠé—­ç¯ææ–™è®¾è®¡ç³»ç»Ÿçš„æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00768v2",
      "published_date": "2025-08-31 09:46:20 UTC",
      "updated_date": "2025-10-02 07:53:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:48.502179+00:00"
    },
    {
      "arxiv_id": "2509.00764v1",
      "title": "Low Power Approximate Multiplier Architecture for Deep Neural Networks",
      "title_zh": "é¢å‘æ·±åº¦ç¥ç»ç½‘ç»œçš„ä½åŠŸè€—è¿‘ä¼¼ä¹˜æ³•å™¨æ¶æ„",
      "authors": [
        "Pragun Jaswal",
        "L. Hemanth Krishna",
        "B. Srinivasu"
      ],
      "abstract": "This paper proposes an low power approximate multiplier architecture for deep neural network (DNN) applications. A 4:2 compressor, introducing only a single combination error, is designed and integrated into an 8x8 unsigned multiplier. This integration significantly reduces the usage of exact compressors while preserving low error rates. The proposed multiplier is employed within a custom convolution layer and evaluated on neural network tasks, including image recognition and denoising. Hardware evaluation demonstrates that the proposed design achieves up to 30.24% energy savings compared to the best among existing multipliers. In image denoising, the custom approximate convolution layer achieves improved Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM) compared to other approximate designs. Additionally, when applied to handwritten digit recognition, the model maintains high classification accuracy. These results demonstrate that the proposed architecture offers a favorable balance between energy efficiency and computational precision, making it suitable for low-power AI hardware implementations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºæ·±åº¦ç¥ç»ç½‘ç»œ(Deep Neural Network, DNN)çš„ä½åŠŸè€—è¿‘ä¼¼ä¹˜æ³•å™¨(Approximate Multiplier)æ¶æ„ã€‚ç ”ç©¶è€…è®¾è®¡äº†ä¸€ç§ä»…å¼•å…¥å•ä¸€ç»„åˆè¯¯å·®çš„ 4:2 å‹ç¼©å™¨(Compressor)ï¼Œå¹¶å°†å…¶é›†æˆåˆ° 8x8 æ— ç¬¦å·ä¹˜æ³•å™¨ä¸­ï¼Œåœ¨æ˜¾è‘—å‡å°‘ç²¾ç¡®å‹ç¼©å™¨ä½¿ç”¨çš„åŒæ—¶ä¿æŒäº†æä½çš„é”™è¯¯ç‡ã€‚è¯¥ä¹˜æ³•å™¨è¢«åº”ç”¨äºè‡ªå®šä¹‰å·ç§¯å±‚ï¼Œå¹¶åœ¨å›¾åƒè¯†åˆ«å’Œå»å™ªç­‰ç¥ç»ç½‘è·¯ä»»åŠ¡ä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚ç¡¬ä»¶è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æœ€ä¼˜è¿‘ä¼¼ä¹˜æ³•å™¨ç›¸æ¯”ï¼Œè¯¥è®¾è®¡æœ€é«˜å¯å®ç° 30.24% çš„èƒ½é‡èŠ‚çœã€‚åœ¨å›¾åƒå»å™ªä»»åŠ¡ä¸­ï¼Œè¯¥æ¶æ„åœ¨å³°å€¼ä¿¡å™ªæ¯”(PSNR)å’Œç»“æ„ç›¸ä¼¼æ€§(SSIM)æ–¹é¢å‡ä¼˜äºå…¶ä»–è¿‘ä¼¼è®¾è®¡ï¼Œå¹¶åœ¨æ‰‹å†™æ•°å­—è¯†åˆ«ä¸­ä¿æŒäº†é«˜åˆ†ç±»å‡†ç¡®ç‡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¶æ„åœ¨èƒ½æºæ•ˆç‡ä¸è®¡ç®—ç²¾åº¦ä¹‹é—´å–å¾—äº†ç†æƒ³çš„å¹³è¡¡ï¼Œéå¸¸é€‚åˆä½åŠŸè€—äººå·¥æ™ºèƒ½(AI)ç¡¬ä»¶çš„å®ç°ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00764v1",
      "published_date": "2025-08-31 09:25:42 UTC",
      "updated_date": "2025-08-31 09:25:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:42:54.986982+00:00"
    },
    {
      "arxiv_id": "2509.00761v2",
      "title": "L-MARS: Legal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Search",
      "title_zh": "L-MARSï¼šèåˆç¼–æ’å¼æ¨ç†ä¸æ™ºèƒ½ä½“åŒ–æœç´¢çš„æ³•å¾‹å¤šæ™ºèƒ½ä½“å·¥ä½œæµ",
      "authors": [
        "Ziqi Wang",
        "Boqin Yuan"
      ],
      "abstract": "We present L-MARS (Legal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Search), a system that reduces hallucination and uncertainty in legal question answering through coordinated multi-agent reasoning and retrieval. Unlike single-pass retrieval-augmented generation (RAG), L-MARS decomposes queries into subproblems, issues targeted searches across heterogeneous sources (Serper web, local RAG, CourtListener case law), and employs a Judge Agent to verify sufficiency, jurisdiction, and temporal validity before answer synthesis. This iterative reasoning-search-verification loop maintains coherence, filters noisy evidence, and grounds answers in authoritative law. We evaluated L-MARS on LegalSearchQA, a new benchmark of 200 up-to-date multiple choice legal questions in 2025. Results show that L-MARS substantially improves factual accuracy, reduces uncertainty, and achieves higher preference scores from both human experts and LLM-based judges. Our work demonstrates that multi-agent reasoning with agentic search offers a scalable and reproducible blueprint for deploying LLMs in high-stakes domains requiring precise legal retrieval and deliberation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†L-MARSï¼ˆLegal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Searchï¼‰ï¼Œæ—¨åœ¨é€šè¿‡åè°ƒçš„å¤šæ™ºèƒ½ä½“æ¨ç†å’Œæ£€ç´¢æŠ€æœ¯ï¼Œå‡å°‘æ³•å¾‹é—®ç­”ç³»ç»Ÿä¸­çš„å¹»è§‰(hallucination)å’Œä¸ç¡®å®šæ€§ã€‚ä¸åŒäºä¼ ç»Ÿçš„å•æ¬¡æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ï¼ŒL-MARSå°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œå¹¶åœ¨Serperã€æœ¬åœ°RAGåŠCourtListeneræ¡ˆä¾‹æ³•ç­‰å¼‚æ„æ•°æ®æºä¸­è¿›è¡Œé’ˆå¯¹æ€§æœç´¢ã€‚ç³»ç»Ÿå¼•å…¥äº†Judge Agentï¼Œåœ¨æœ€ç»ˆåˆæˆç­”æ¡ˆå‰ä¸¥æ ¼éªŒè¯ä¿¡æ¯çš„å……è¶³æ€§ã€ç®¡è¾–æƒ(jurisdiction)åŠæ—¶é—´æœ‰æ•ˆæ€§ã€‚è¿™ç§è¿­ä»£çš„æ¨ç†-æœç´¢-éªŒè¯å¾ªç¯ç¡®ä¿äº†é€»è¾‘ä¸€è‡´æ€§ï¼Œå¹¶èƒ½æœ‰æ•ˆè¿‡æ»¤å™ªå£°è¯æ®ï¼Œä½¿ç­”æ¡ˆæ ¹æ¤äºæƒå¨æ³•å¾‹æ¡æ–‡ã€‚ç ”ç©¶äººå‘˜åœ¨åŒ…å«200ä¸ª2025å¹´æœ€æ–°æ³•å¾‹é—®é¢˜çš„LegalSearchQAåŸºå‡†æµ‹è¯•ä¸Šå¯¹ç³»ç»Ÿè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒL-MARSæ˜¾è‘—æå‡äº†äº‹å®å‡†ç¡®æ€§ï¼Œé™ä½äº†ä¸ç¡®å®šæ€§ï¼Œå¹¶åœ¨äººç±»ä¸“å®¶å’ŒLLMè¯„å§”çš„åå¥½è¯„åˆ†ä¸­å‡è·å¾—æ›´é«˜è¯„ä»·ã€‚è¯¥å·¥ä½œè¯æ˜äº†å¤šæ™ºèƒ½ä½“æ¨ç†ç»“åˆä»£ç†æœç´¢(agentic search)ä¸ºæ³•å¾‹æ£€ç´¢ä¸å®¡è®®ç­‰é«˜é£é™©é¢†åŸŸæä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”å¯å¤åˆ¶çš„è“å›¾ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00761v2",
      "published_date": "2025-08-31 09:23:26 UTC",
      "updated_date": "2025-09-03 00:57:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:43:14.789312+00:00"
    },
    {
      "arxiv_id": "2509.00749v1",
      "title": "Causal Interpretation of Sparse Autoencoder Features in Vision",
      "title_zh": "è§†è§‰é¢†åŸŸä¸­ç¨€ç–è‡ªç¼–ç å™¨ç‰¹å¾çš„å› æœè§£é‡Š",
      "authors": [
        "Sangyu Han",
        "Yearim Kim",
        "Nojun Kwak"
      ],
      "abstract": "Understanding what sparse auto-encoder (SAE) features in vision transformers truly represent is usually done by inspecting the patches where a feature's activation is highest. However, self-attention mixes information across the entire image, so an activated patch often co-occurs with-but does not cause-the feature's firing. We propose Causal Feature Explanation (CaFE), which leverages Effective Receptive Field (ERF). We consider each activation of an SAE feature to be a target and apply input-attribution methods to identify the image patches that causally drive that activation. Across CLIP-ViT features, ERF maps frequently diverge from naive activation maps, revealing hidden context dependencies (e.g., a \"roaring face\" feature that requires the co-occurrence of eyes and nose, rather than merely an open mouth). Patch insertion tests confirm that CaFE more effectively recovers or suppresses feature activations than activation-ranked patches. Our results show that CaFE yields more faithful and semantically precise explanations of vision-SAE features, highlighting the risk of misinterpretation when relying solely on activation location.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Vision Transformers ä¸­çš„ Sparse Autoencoder (SAE) ç‰¹å¾è§£é‡Šé—®é¢˜ï¼Œæå‡ºäº† Causal Feature Explanation (CaFE) æ–¹æ³•ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸é€šè¿‡è§‚å¯Ÿæ¿€æ´»å€¼æœ€é«˜çš„å›¾åƒå—æ¥è§£é‡Šç‰¹å¾ï¼Œä½†ç”±äº Self-attention æœºåˆ¶ä¼šæ··åˆå…¨å±€ä¿¡æ¯ï¼Œè¿™äº›å›¾åƒå—å¾€å¾€åªæ˜¯ä¸ç‰¹å¾å…±ç°è€Œéäº’ä¸ºå› æœã€‚CaFE åˆ©ç”¨ Effective Receptive Field (ERF) å’Œè¾“å…¥å½’å› æ–¹æ³• (input-attribution methods)ï¼Œè¯†åˆ«å‡ºçœŸæ­£å› æœé©±åŠ¨ SAE ç‰¹å¾æ¿€æ´»çš„å›¾åƒå—ã€‚åœ¨ CLIP-ViT ç‰¹å¾çš„å®éªŒä¸­ï¼Œç ”ç©¶å‘ç° ERF å›¾å¸¸ä¸ä¼ ç»Ÿçš„æ¿€æ´»å›¾å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå¹¶æ­ç¤ºäº†éšè—çš„ä¸Šä¸‹æ–‡ä¾èµ–æ€§ï¼Œä¾‹å¦‚æŸäº›ç‰¹å¾éœ€è¦ç‰¹å®šéƒ¨ä½çš„åŒæ—¶å‡ºç°è€Œéå•ä¸€å±€éƒ¨ç‰¹å¾ã€‚é€šè¿‡å›¾åƒå—æ’å…¥æµ‹è¯• (Patch insertion tests)ï¼Œè¯æ˜äº† CaFE æ¯”åŸºäºæ¿€æ´»æ’åºçš„æ–¹æ³•èƒ½æ›´æœ‰æ•ˆåœ°æ¢å¤æˆ–æŠ‘åˆ¶ç‰¹å¾æ¿€æ´»ã€‚è¯¥æˆæœè¡¨æ˜ CaFE ä¸º vision-SAE ç‰¹å¾æä¾›äº†æ›´å…·å¿ å®æ€§å’Œè¯­ä¹‰ç²¾ç¡®æ€§çš„è§£é‡Šï¼ŒåŒæ—¶è­¦ç¤ºäº†ä»…ä¾èµ–æ¿€æ´»ä½ç½®å¯èƒ½å¯¼è‡´çš„è¯¯è§£é£é™©ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00749v1",
      "published_date": "2025-08-31 08:52:45 UTC",
      "updated_date": "2025-08-31 08:52:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:43:15.385804+00:00"
    },
    {
      "arxiv_id": "2509.00745v1",
      "title": "Enhancing Fairness in Skin Lesion Classification for Medical Diagnosis Using Prune Learning",
      "title_zh": "åˆ©ç”¨å‰ªæå­¦ä¹ æå‡åŒ»ç–—è¯Šæ–­ä¸­çš„çš®è‚¤ç—…å˜åˆ†ç±»å…¬å¹³æ€§",
      "authors": [
        "Kuniko Paxton",
        "Koorosh Aslansefat",
        "Dhavalkumar Thakker",
        "Yiannis Papadopoulos",
        "Tanaya Maslekar"
      ],
      "abstract": "Recent advances in deep learning have significantly improved the accuracy of skin lesion classification models, supporting medical diagnoses and promoting equitable healthcare. However, concerns remain about potential biases related to skin color, which can impact diagnostic outcomes. Ensuring fairness is challenging due to difficulties in classifying skin tones, high computational demands, and the complexity of objectively verifying fairness. To address these challenges, we propose a fairness algorithm for skin lesion classification that overcomes the challenges associated with achieving diagnostic fairness across varying skin tones. By calculating the skewness of the feature map in the convolution layer of the VGG (Visual Geometry Group) network and the patches and the heads of the Vision Transformer, our method reduces unnecessary channels related to skin tone, focusing instead on the lesion area. This approach lowers computational costs and mitigates bias without relying on conventional statistical methods. It potentially reduces model size while maintaining fairness, making it more practical for real-world applications.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹çš®è‚¤ç—…å˜åˆ†ç±»æ¨¡å‹åœ¨åŒ»ç–—è¯Šæ–­ä¸­å› è‚¤è‰²å·®å¼‚äº§ç”Ÿçš„å…¬å¹³æ€§åè§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå‰ªæå­¦ä¹  (Prune Learning) çš„å…¬å¹³æ€§ç®—æ³•ã€‚è¯¥ç®—æ³•é€šè¿‡è®¡ç®— VGG (Visual Geometry Group) å·ç§¯å±‚åŠ Vision Transformer çš„ Patch å’Œ Head ç‰¹å¾å›¾çš„ååº¦ (Skewness)ï¼Œè¯†åˆ«å¹¶å‰”é™¤ä¸çš®è‚¤è‰²è°ƒç›¸å…³çš„å†—ä½™é€šé“ï¼Œä½¿æ¨¡å‹æ›´ä¸“æ³¨äºç—…å˜åŒºåŸŸæœ¬èº«ã€‚è¿™ç§æ–¹æ³•åœ¨ä¸ä¾èµ–ä¼ ç»Ÿç»Ÿè®¡æ‰‹æ®µçš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆé™ä½äº†è®¡ç®—æˆæœ¬å¹¶å‡è½»äº†æ¨¡å‹åè§ã€‚è¯¥ç ”ç©¶ä¸ä»…èƒ½å‡å°æ¨¡å‹ä½“ç§¯ï¼Œè¿˜åœ¨ç¡®ä¿è¯Šæ–­å…¬å¹³æ€§çš„åŒæ—¶æå‡äº†å®é™…åº”ç”¨çš„è½åœ°æ½œåŠ›ï¼Œä¸ºå®ç°æ›´å…¬å¹³çš„åŒ»ç–—äººå·¥æ™ºèƒ½è¾…åŠ©è¯Šæ–­æä¾›äº†æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00745v1",
      "published_date": "2025-08-31 08:36:51 UTC",
      "updated_date": "2025-08-31 08:36:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:43:21.489300+00:00"
    },
    {
      "arxiv_id": "2509.00744v1",
      "title": "Quantum Causality: Resolving Simpson's Paradox with $\\mathcal{DO}$-Calculus",
      "title_zh": "é‡å­å› æœï¼šåˆ©ç”¨ $\\mathcal{DO}$ æ¼”ç®—åŒ–è§£è¾›æ™®æ£®æ‚–è®º",
      "authors": [
        "Pilsung Kang"
      ],
      "abstract": "Distinguishing correlation from causation is a fundamental challenge in machine intelligence, often representing a critical barrier to building robust and trustworthy systems. While Pearl's $\\mathcal{DO}$-calculus provides a rigorous framework for causal inference, a parallel challenge lies in its physical implementation. Here, we apply and experimentally validate a quantum algorithmic framework for performing causal interventions. Our approach maps causal networks onto quantum circuits where probabilistic links are encoded by controlled-rotation gates, and interventions are realized by a structural remodeling of the circuit -- a physical analogue to Pearl's ``graph surgery''. We demonstrate the method's efficacy by resolving Simpson's Paradox in a 3-qubit model, and show its scalability by quantifying confounding bias in a 10-qubit healthcare simulation. Critically, we provide a proof-of-principle experimental validation on an IonQ Aria quantum computer, successfully reproducing the paradox and its resolution in the presence of real-world noise. This work establishes a practical pathway for quantum causal inference, offering a new computational tool to address deep-rooted challenges in algorithmic fairness and explainable AI (XAI).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é‡å­è®¡ç®—åœ¨å› æœæ¨ç†ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨åˆ©ç”¨ $\\mathcal{DO}$-Calculus è§£å†³åŒºåˆ†ç›¸å…³æ€§ä¸å› æœæ€§çš„åŸºç¡€æŒ‘æˆ˜ã€‚ç ”ç©¶äººå‘˜æå‡ºå¹¶éªŒè¯äº†ä¸€ç§é‡å­ç®—æ³•æ¡†æ¶ï¼Œé€šè¿‡å°†å› æœç½‘ç»œæ˜ å°„åˆ°é‡å­ç”µè·¯ï¼Œåˆ©ç”¨å—æ§æ—‹è½¬é—¨(controlled-rotation gates)ç¼–ç æ¦‚ç‡è¿æ¥ï¼Œå¹¶ä»¥ç”µè·¯ç»“æ„é‡æ„ä½œä¸º Pearl â€œå›¾æ‰‹æœ¯â€(graph surgery)çš„ç‰©ç†æ¨¡æ‹Ÿæ¥å®ç°å¹²é¢„ã€‚å®éªŒåœ¨ 3-qubit æ¨¡å‹ä¸­æˆåŠŸè§£å†³äº† Simpson's Paradoxï¼Œå¹¶é€šè¿‡ 10-qubit åŒ»ç–—å¥åº·æ¨¡æ‹Ÿé‡åŒ–äº†æ··æ‚åå·®(confounding bias)ï¼Œå±•ç¤ºäº†æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ä¸å¯æ‰©å±•æ€§ã€‚å›¢é˜Ÿè¿›ä¸€æ­¥åœ¨ IonQ Aria é‡å­è®¡ç®—æœºä¸Šè¿›è¡Œäº†åŸç†éªŒè¯ï¼Œåœ¨çœŸå®å™ªå£°ç¯å¢ƒä¸‹æˆåŠŸé‡ç°äº†æ‚–è®ºåŠå…¶è§£å†³æ–¹æ¡ˆã€‚è¿™é¡¹å·¥ä½œä¸ºé‡å­å› æœæ¨ç†(quantum causal inference)å»ºç«‹äº†å®è·µè·¯å¾„ï¼Œä¸ºç®—æ³•å…¬å¹³æ€§å’Œå¯è§£é‡Šäººå·¥æ™ºèƒ½(XAI)æä¾›äº†å¼ºæœ‰åŠ›çš„è®¡ç®—å·¥å…·ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00744v1",
      "published_date": "2025-08-31 08:33:01 UTC",
      "updated_date": "2025-08-31 08:33:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:43:41.658192+00:00"
    },
    {
      "arxiv_id": "2509.00740v1",
      "title": "Efficient Graph Understanding with LLMs via Structured Context Injection",
      "title_zh": "åŸºäºç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥çš„å¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆå›¾ç†è§£",
      "authors": [
        "Govind Waghmare",
        "Sumedh BG",
        "Sonia Gupta",
        "Srikanta Bedathur"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong capabilities in solving problems across domains, including graph-related tasks traditionally addressed by symbolic or algorithmic methods. In this work, we present a framework for structured context injection, where task-specific information is systematically embedded in the input to guide LLMs in solving a wide range of graph problems. Our method does not require fine-tuning of LLMs, making it cost-efficient and lightweight. We observe that certain graph reasoning tasks remain challenging for LLMs unless they are mapped to conceptually grounded representations. However, achieving such mappings through fine-tuning or repeated multi-step querying can be expensive and inefficient. Our approach offers a practical alternative by injecting structured context directly into the input, enabling the LLM to implicitly align the task with grounded conceptual spaces. We evaluate the approach on multiple graph tasks using both lightweight and large models, highlighting the trade-offs between accuracy and computational cost. The results demonstrate consistent performance improvements, showing that structured input context can rival or surpass more complex approaches. Our findings underscore the value of structured context injection as an effective and scalable strategy for graph understanding with LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥ (Structured Context Injection) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†å›¾ç›¸å…³ä»»åŠ¡æ—¶é¢ä¸´çš„æ¨ç†æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨è¾“å…¥ä¸­ç³»ç»Ÿæ€§åœ°åµŒå…¥ç‰¹å®šä»»åŠ¡ä¿¡æ¯ï¼Œå¼•å¯¼ LLMs éšå¼åœ°å°†ä»»åŠ¡ä¸æ¥åœ°çš„æ¦‚å¿µç©ºé—´å¯¹é½ï¼Œä»è€Œæœ‰æ•ˆè§£å†³å¹¿æ³›çš„å›¾é—®é¢˜ã€‚ä¸ä¼ ç»Ÿçš„å¾®è°ƒ (Fine-tuning) æˆ–å¤šæ­¥æŸ¥è¯¢æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶æ— éœ€è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œå…·æœ‰ä½æˆæœ¬å’Œè½»é‡åŒ–çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚ç ”ç©¶è€…åœ¨å¤šç§å›¾ä»»åŠ¡ä¸Šå¯¹ä¸åŒè§„æ¨¡çš„æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œæ·±å…¥åˆ†æäº†å‡†ç¡®æ€§ä¸è®¡ç®—æˆæœ¬ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥èƒ½å¤ŸæŒç»­æå‡æ¨¡å‹æ€§èƒ½ï¼Œå…¶æ•ˆæœè¶³ä»¥åª²ç¾ç”šè‡³è¶…è¶Šæ›´ä¸ºå¤æ‚çš„ç°æœ‰æ–¹æ¡ˆã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†è¯¥æ–¹æ³•ä½œä¸ºä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„ç­–ç•¥ï¼Œåœ¨å¢å¼º LLMs çš„å›¾ç†è§£ (Graph Understanding) èƒ½åŠ›æ–¹é¢å…·æœ‰é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00740v1",
      "published_date": "2025-08-31 08:07:56 UTC",
      "updated_date": "2025-08-31 08:07:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:43:29.291208+00:00"
    },
    {
      "arxiv_id": "2509.00735v1",
      "title": "Task-Aware Adaptive Modulation: A Replay-Free and Resource-Efficient Approach For Continual Graph Learning",
      "title_zh": "ä»»åŠ¡æ„ŸçŸ¥è‡ªé€‚åº”è°ƒåˆ¶ï¼šä¸€ç§å…å›æ”¾ä¸”èµ„æºé«˜æ•ˆçš„æŒç»­å›¾å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Jingtao Liu",
        "Xinming Zhang"
      ],
      "abstract": "Continual Graph Learning(CGL)focuses on acquiring new knowledge while retaining previously learned information, essential for real-world graph applications. Current methods grapple with two main issues:1) The Stability-Plasticity Dilemma: Replay-based methods often create an imbalance between the Dilemma, while incurring significant storage costs.2) The Resource-Heavy Pre-training: Leading replay-free methods critically depend on extensively pre-trained backbones, this reliance imposes a substantial resource burden.In this paper, we argue that the key to overcoming these challenges lies not in replaying data or fine-tuning the entire network, but in dynamically modulating the internal computational flow of a frozen backbone. We posit that lightweight, task-specific modules can effectively steer a GNN's reasoning process. Motivated by this insight, we propose Task-Aware Adaptive Modulation(TAAM), a replay-free, resource-efficient approach that charts a new path for navigating the stability-plasticity dilemma. TAAM's core is its Neural Synapse Modulators(NSM), which are trained and then frozen for each task to store expert knowledge. A pivotal prototype-guided strategy governs these modulators: 1) For training, it initializes a new NSM by deep-copying from a similar past modulator to boost knowledge transfer. 2) For inference, it selects the most relevant frozen NSM for each task. These NSMs insert into a frozen GNN backbone to perform fine-grained, node-attentive modulation of its internal flow-different from the static perturbations of prior methods. Extensive experiments show that TAAM comprehensively outperforms state-of-the-art methods across six GCIL benchmark datasets. The code will be released upon acceptance of the paper.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Continual Graph Learning (CGL) ä¸­å­˜åœ¨çš„ç¨³å®šæ€§-å¡‘æ€§ä¸¤éš¾ (Stability-Plasticity Dilemma) ä»¥åŠé¢„è®­ç»ƒèµ„æºæ¶ˆè€—è¿‡å¤§ç­‰é—®é¢˜ï¼Œæå‡ºäº† Task-Aware Adaptive Modulation (TAAM) æ¡†æ¶ã€‚TAAM æ˜¯ä¸€ç§æ— éœ€é‡æ”¾ (replay-free) ä¸”èµ„æºé«˜æ•ˆçš„æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒåœ¨äºé€šè¿‡ Neural Synapse Modulators (NSM) åŠ¨æ€è°ƒèŠ‚å†»ç»“ GNN éª¨å¹²ç½‘ç»œçš„å†…éƒ¨è®¡ç®—æµã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨åŸå‹å¼•å¯¼ç­–ç•¥ (prototype-guided strategy) ä»ç›¸ä¼¼çš„å†å²æ¨¡å—ä¸­æ·±æ‹·è´çŸ¥è¯†ä»¥åˆå§‹åŒ–æ–°æ¨¡å—ï¼Œä»è€Œæœ‰æ•ˆä¿ƒè¿›çŸ¥è¯†è¿ç§»ï¼›åœ¨æ¨ç†é˜¶æ®µï¼Œåˆ™é€šè¿‡é€‰æ‹©æœ€ç›¸å…³çš„å†»ç»“ NSM æ¥å®ç°ç»†ç²’åº¦çš„èŠ‚ç‚¹æ³¨æ„åŠ›è°ƒèŠ‚ã€‚è¿™ç§æ–¹æ³•æ”¹å˜äº†ä»¥å¾€ä¾èµ–é‡æ”¾æ•°æ®æˆ–å¾®è°ƒå…¨ç½‘ç»œçš„æ¨¡å¼ï¼Œé€šè¿‡è½»é‡åŒ–çš„ä»»åŠ¡ç‰¹å®šæ¨¡å—å¼•å¯¼æ¨¡å‹æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTAAM åœ¨å…­ä¸ª GCIL åŸºå‡†æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸ºæŒç»­å›¾å­¦ä¹ æä¾›äº†ä¸€æ¡å…¼é¡¾æ€§èƒ½ä¸æ•ˆç‡çš„æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00735v1",
      "published_date": "2025-08-31 08:04:43 UTC",
      "updated_date": "2025-08-31 08:04:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:43:34.186086+00:00"
    },
    {
      "arxiv_id": "2509.10490v1",
      "title": "Distributed Gossip-GAN for Low-overhead CSI Feedback Training in FDD mMIMO-OFDM Systems",
      "title_zh": "FDD mMIMO-OFDM ç³»ç»Ÿä¸­åŸºäºåˆ†å¸ƒå¼ Gossip-GAN çš„ä½å¼€é”€ CSI åé¦ˆè®­ç»ƒ",
      "authors": [
        "Yuwen Cao",
        "Guijun Liu",
        "Tomoaki Ohtsuki",
        "Howard H. Yang",
        "Tony Q. S. Quek"
      ],
      "abstract": "The deep autoencoder (DAE) framework has turned out to be efficient in reducing the channel state information (CSI) feedback overhead in massive multiple-input multipleoutput (mMIMO) systems. However, these DAE approaches presented in prior works rely heavily on large-scale data collected through the base station (BS) for model training, thus rendering excessive bandwidth usage and data privacy issues, particularly for mMIMO systems. When considering users' mobility and encountering new channel environments, the existing CSI feedback models may often need to be retrained. Returning back to previous environments, however, will make these models perform poorly and face the risk of catastrophic forgetting. To solve the above challenging problems, we propose a novel gossiping generative adversarial network (Gossip-GAN)-aided CSI feedback training framework. Notably, Gossip-GAN enables the CSI feedback training with low-overhead while preserving users' privacy. Specially, each user collects a small amount of data to train a GAN model. Meanwhile, a fully distributed gossip-learning strategy is exploited to avoid model overfitting, and to accelerate the model training as well. Simulation results demonstrate that Gossip-GAN can i) achieve a similar CSI feedback accuracy as centralized training with real-world datasets, ii) address catastrophic forgetting challenges in mobile scenarios, and iii) greatly reduce the uplink bandwidth usage. Besides, our results show that the proposed approach possesses an inherent robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºGossip-GANçš„åˆ†å¸ƒå¼ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³FDD mMIMO-OFDMç³»ç»Ÿä¸­CSI feedbackè®­ç»ƒé¢ä¸´çš„é«˜å¸¦å®½å¼€é”€ã€æ•°æ®éšç§åŠç¾éš¾æ€§é—å¿˜(Catastrophic Forgetting)é—®é¢˜ã€‚è¯¥æ¡†æ¶å…è®¸æ¯ä¸ªç”¨æˆ·åˆ©ç”¨å°‘é‡æœ¬åœ°æ•°æ®è®­ç»ƒGANæ¨¡å‹ï¼Œå¹¶ç»“åˆå®Œå…¨åˆ†å¸ƒå¼çš„Gossip-learningç­–ç•¥ï¼Œåœ¨æ— éœ€å°†å¤§è§„æ¨¡æ•°æ®æ±‡æ€»è‡³åŸºç«™çš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆè®­ç»ƒã€‚è¿™ç§æœºåˆ¶ä¸ä»…æœ‰æ•ˆä¿æŠ¤äº†ç”¨æˆ·éšç§ï¼Œè¿˜é€šè¿‡èŠ‚ç‚¹é—´çš„ä¿¡æ¯äº¤æ¢é¿å…äº†æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œå¹¶æ˜¾è‘—åŠ é€Ÿäº†æ”¶æ•›è¿‡ç¨‹ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼ŒGossip-GANåœ¨CSI feedbackç²¾åº¦ä¸Šè¾¾åˆ°äº†ä¸é›†ä¸­å¼è®­ç»ƒç›¸å½“çš„æ°´å¹³ï¼ŒåŒæ—¶å¤§å¹…å‡å°‘äº†ä¸Šè¡Œé“¾è·¯å¸¦å®½çš„ä½¿ç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆåœ¨ç§»åŠ¨åœºæ™¯ä¸‹å±•ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹ç”±äºç¯å¢ƒå˜åŒ–å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é£é™©ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10490v1",
      "published_date": "2025-08-31 07:46:16 UTC",
      "updated_date": "2025-08-31 07:46:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:43:40.965329+00:00"
    },
    {
      "arxiv_id": "2509.00723v1",
      "title": "OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination",
      "title_zh": "OmniDPOï¼šåº”å¯¹å…¨æ¨¡æ€å¹»è§‰çš„åå¥½ä¼˜åŒ–æ¡†æ¶",
      "authors": [
        "Junzhe Chen",
        "Tianshu Zhang",
        "Shiyu Huang",
        "Yuwei Niu",
        "Chao Sun",
        "Rongzhou Zhang",
        "Guanyu Zhou",
        "Lijie Wen",
        "Xuming Hu"
      ],
      "abstract": "Recently, Omni-modal large language models (OLLMs) have sparked a new wave of research, achieving impressive results in tasks such as audio-video understanding and real-time environment perception. However, hallucination issues still persist. Similar to the bimodal setting, the priors from the text modality tend to dominate, leading OLLMs to rely more heavily on textual cues while neglecting visual and audio information. In addition, fully multimodal scenarios introduce new challenges. Most existing models align visual or auditory modalities with text independently during training, while ignoring the intrinsic correlations between video and its corresponding audio. This oversight results in hallucinations when reasoning requires interpreting hidden audio cues embedded in video content. To address these challenges, we propose OmniDPO, a preference-alignment framework designed to mitigate hallucinations in OLLMs. Specifically, OmniDPO incorporates two strategies: (1) constructing text-preference sample pairs to enhance the model's understanding of audio-video interactions; and (2) constructing multimodal-preference sample pairs to strengthen the model's attention to visual and auditory information. By tackling both challenges, OmniDPO effectively improves multimodal grounding and reduces hallucination. Experiments conducted on two OLLMs demonstrate that OmniDPO not only effectively mitigates multimodal hallucinations but also significantly enhances the models' reasoning capabilities across modalities. All code and datasets will be released upon paper acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¨æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(OLLMs)ä¸­æ™®éå­˜åœ¨çš„å¹»è§‰(hallucination)é—®é¢˜ï¼ŒæŒ‡å‡ºæ¨¡å‹å¾€å¾€è¿‡åº¦ä¾èµ–æ–‡æœ¬å…ˆéªŒè€Œå¿½è§†è§†å¬ä¿¡æ¯ï¼Œä¸”ç°æœ‰è®­ç»ƒæ–¹æ³•å¿½ç•¥äº†è§†é¢‘ä¸éŸ³é¢‘ä¹‹é—´çš„å†…åœ¨å…³è”ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†OmniDPOï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ç¼“è§£å…¨æ¨¡æ€å¹»è§‰çš„åå¥½å¯¹é½æ¡†æ¶(preference-alignment framework)ã€‚è¯¥æ¡†æ¶é€šè¿‡æ„å»ºæ–‡æœ¬åå¥½æ ·æœ¬å¯¹(text-preference sample pairs)æ¥å¢å¼ºæ¨¡å‹å¯¹éŸ³è§†é¢‘äº¤äº’çš„ç†è§£ï¼Œå¹¶åˆ©ç”¨å¤šæ¨¡æ€åå¥½æ ·æœ¬å¯¹(multimodal-preference sample pairs)æ¥å¼ºåŒ–æ¨¡å‹å¯¹è§†è§‰å’Œå¬è§‰ä¿¡æ¯çš„å…³æ³¨ã€‚é€šè¿‡è¿™ä¸¤é¡¹ç­–ç•¥ï¼ŒOmniDPOæœ‰æ•ˆæå‡äº†å¤šæ¨¡æ€å¯¹é½(multimodal grounding)èƒ½åŠ›å¹¶å‡å°‘äº†æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniDPOåœ¨ä¸¤ä¸ªä¸»æµOLLMsä¸Šå‡æ˜¾è‘—å‡è½»äº†å¤šæ¨¡æ€å¹»è§‰ç°è±¡ï¼Œå¹¶å¤§å¹…å¢å¼ºäº†æ¨¡å‹çš„è·¨æ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00723v1",
      "published_date": "2025-08-31 07:19:32 UTC",
      "updated_date": "2025-08-31 07:19:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:44:38.085978+00:00"
    },
    {
      "arxiv_id": "2509.00718v1",
      "title": "Exam Readiness Index (ERI): A Theoretical Framework for a Composite, Explainable Index",
      "title_zh": "å¤‡è€ƒå°±ç»ªæŒ‡æ•° (ERI)ï¼šä¸€ç§ç»¼åˆæ€§ã€å¯è§£é‡ŠæŒ‡æ•°çš„ç†è®ºæ¡†æ¶",
      "authors": [
        "Ananda Prakash Verma"
      ],
      "abstract": "We present a theoretical framework for an Exam Readiness Index (ERI): a composite, blueprint-aware score R in [0,100] that summarizes a learner's readiness for a high-stakes exam while remaining interpretable and actionable. The ERI aggregates six signals -- Mastery (M), Coverage (C), Retention (R), Pace (P), Volatility (V), and Endurance (E) -- each derived from a stream of practice and mock-test interactions. We formalize axioms for component maps and the composite, prove monotonicity, Lipschitz stability, and bounded drift under blueprint re-weighting, and show existence and uniqueness of the optimal linear composite under convex design constraints. We further characterize confidence bands via blueprint-weighted concentration and prove compatibility with prerequisite-admissible curricula (knowledge spaces / learning spaces). The paper focuses on theory; empirical study is left to future work.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†è€ƒè¯•å‡†å¤‡åº¦æŒ‡æ•°(Exam Readiness Index, ERI)çš„ç†è®ºæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§å–å€¼åœ¨[0,100]ä¹‹é—´çš„å¤åˆã€å¯è§£é‡Šä¸”å…·æœ‰æŒ‡å¯¼æ„ä¹‰çš„è¯„åˆ†ç³»ç»Ÿï¼Œæ—¨åœ¨è¯„ä¼°å­¦ä¹ è€…å¯¹é«˜åˆ©å®³è€ƒè¯•çš„å‡†å¤‡çŠ¶æ€ã€‚ERI ç»¼åˆäº†å…­ä¸ªæ ¸å¿ƒä¿¡å·ï¼šæŒæ¡ç¨‹åº¦(Mastery)ã€è¦†ç›–èŒƒå›´(Coverage)ã€è®°å¿†ä¿ç•™(Retention)ã€ä½œç­”é€Ÿåº¦(Pace)ã€æ³¢åŠ¨æ€§(Volatility)å’Œè€åŠ›(Endurance)ï¼Œè¿™äº›ä¿¡å·å‡æå–è‡ªç»ƒä¹ å’Œæ¨¡æ‹Ÿè€ƒè¯•çš„äº¤äº’æ•°æ®ã€‚ä½œè€…é€šè¿‡å½¢å¼åŒ–å…¬ç†ä½“ç³»è¯æ˜äº†è¯¥æŒ‡æ ‡çš„å•è°ƒæ€§(monotonicity)ã€Lipschitzç¨³å®šæ€§ä»¥åŠåœ¨è¯„ä»·è“å›¾é‡åŠ æƒä¸‹çš„æœ‰ç•Œæ¼‚ç§»(bounded drift)ï¼Œå¹¶ç¡®å®šäº†æœ€ä¼˜çº¿æ€§å¤åˆæŒ‡æ ‡çš„å­˜åœ¨æ€§ä¸å”¯ä¸€æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è“å›¾åŠ æƒé›†ä¸­åº¦åˆ»ç”»äº†ç½®ä¿¡åŒºé—´ï¼Œå¹¶ç¡®ä¿å…¶ä¸å‰ç½®çŸ¥è¯†è¯¾ç¨‹(knowledge spaces / learning spaces)ä¿æŒå…¼å®¹ã€‚è¯¥è®ºæ–‡ä¸“æ³¨äºç†è®ºæ¨å¯¼ä¸æ¨¡å‹æ„å»ºï¼Œä¸ºæœªæ¥å¯è§£é‡Šæ€§æ•™è‚²è¯„ä»·ä½“ç³»çš„å®è¯ç ”ç©¶æä¾›äº†åšå®çš„æ•°å­¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00718v1",
      "published_date": "2025-08-31 06:56:59 UTC",
      "updated_date": "2025-08-31 06:56:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:43:52.661105+00:00"
    },
    {
      "arxiv_id": "2509.00713v1",
      "title": "It's-A-Me, Quantum Mario: Scalable Quantum Reinforcement Learning with Multi-Chip Ensembles",
      "title_zh": "It's-A-Me, Quantum Marioï¼šåŸºäºå¤šèŠ¯ç‰‡é›†æˆçš„å¯æ‰©å±•é‡å­å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Junghoon Justin Park",
        "Huan-Hsin Tseng",
        "Shinjae Yoo",
        "Samuel Yen-Chi Chen",
        "Jiook Cha"
      ],
      "abstract": "Quantum reinforcement learning (QRL) promises compact function approximators with access to vast Hilbert spaces, but its practical progress is slowed by NISQ-era constraints such as limited qubits and noise accumulation. We introduce a multi-chip ensemble framework using multiple small Quantum Convolutional Neural Networks (QCNNs) to overcome these constraints. Our approach partitions complex, high-dimensional observations from the Super Mario Bros environment across independent quantum circuits, then classically aggregates their outputs within a Double Deep Q-Network (DDQN) framework. This modular architecture enables QRL in complex environments previously inaccessible to quantum agents, achieving superior performance and learning stability compared to classical baselines and single-chip quantum models. The multi-chip ensemble demonstrates enhanced scalability by reducing information loss from dimensionality reduction while remaining implementable on near-term quantum hardware, providing a practical pathway for applying QRL to real-world problems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ NISQ æ—¶ä»£é‡å­ä½å—é™å’Œå™ªå£°ç§¯ç´¯ç­‰åˆ¶çº¦å› ç´ ï¼Œæå‡ºäº†ä¸€ä¸ªå¤šèŠ¯ç‰‡é›†æˆ (multi-chip ensemble) æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å¯æ‰©å±•çš„é‡å­å¼ºåŒ–å­¦ä¹  (QRL)ã€‚è¯¥æ–¹æ³•é€šè¿‡å¤šä¸ªå°å‹é‡å­å·ç§¯ç¥ç»ç½‘ç»œ (QCNNs) å°†æ¥è‡ªã€Šè¶…çº§é©¬é‡Œå¥¥å…„å¼Ÿã€‹(Super Mario Bros) ç¯å¢ƒçš„é«˜ç»´å¤æ‚è§‚å¯Ÿæ•°æ®åˆ†é…åˆ°ç‹¬ç«‹çš„é‡å­ç”µè·¯ä¸­ï¼Œå¹¶åœ¨ Double Deep Q-Network (DDQN) æ¡†æ¶ä¸‹è¿›è¡Œç»å…¸èšåˆã€‚è¿™ç§æ¨¡å—åŒ–æ¶æ„ä½¿å¾—é‡å­æ™ºèƒ½ä½“èƒ½å¤Ÿå¤„ç†æ­¤å‰éš¾ä»¥è§¦åŠçš„å¤æ‚ç¯å¢ƒï¼Œåœ¨æ€§èƒ½å’Œå­¦ä¹ ç¨³å®šæ€§ä¸Šå‡ä¼˜äºç»å…¸åŸºå‡†å’Œå•èŠ¯ç‰‡é‡å­æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥é›†æˆæ–¹æ¡ˆæœ‰æ•ˆå‡å°‘äº†ç»´åº¦å‹ç¼©å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ï¼Œæ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†åœ¨è¿‘æœŸé‡å­ç¡¬ä»¶ä¸Šå®ç°å¤æ‚ä»»åŠ¡çš„å¯è¡Œæ€§ï¼Œä¸ºå°† QRL åº”ç”¨äºè§£å†³ç°å®ä¸–ç•Œé—®é¢˜æä¾›äº†ä¸€æ¡åˆ‡å®å¯è¡Œçš„è·¯å¾„ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00713v1",
      "published_date": "2025-08-31 06:15:55 UTC",
      "updated_date": "2025-08-31 06:15:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:44:01.386382+00:00"
    },
    {
      "arxiv_id": "2509.00710v1",
      "title": "On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations",
      "title_zh": "è®ºå¯éªŒè¯æ³•å¾‹æ¨ç†ï¼šåŸºäºå½¢å¼åŒ–çŸ¥è¯†è¡¨ç¤ºçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Albert Sadowski",
        "JarosÅ‚aw A. Chudziak"
      ],
      "abstract": "Legal reasoning requires both precise interpretation of statutory language and consistent application of complex rules, presenting significant challenges for AI systems. This paper introduces a modular multi-agent framework that decomposes legal reasoning into distinct knowledge acquisition and application stages. In the first stage, specialized agents extract legal concepts and formalize rules to create verifiable intermediate representations of statutes. The second stage applies this knowledge to specific cases through three steps: analyzing queries to map case facts onto the ontology schema, performing symbolic inference to derive logically entailed conclusions, and generating final answers using a programmatic implementation that operationalizes the ontological knowledge. This bridging of natural language understanding with symbolic reasoning provides explicit and verifiable inspection points, significantly enhancing transparency compared to end-to-end approaches. Evaluation on statutory tax calculation tasks demonstrates substantial improvements, with foundational models achieving 76.4\\% accuracy compared to 18.8\\% baseline performance, effectively narrowing the performance gap between reasoning and foundational models. These findings suggest that modular architectures with formalized knowledge representations can make sophisticated legal reasoning more accessible through computationally efficient models while enhancing consistency and explainability in AI legal reasoning, establishing a foundation for future research into more transparent, trustworthy, and effective AI systems for legal domain.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºå¯éªŒè¯æ³•å¾‹æ¨ç†çš„æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“æ¡†æ¶(Multi-Agent Framework)ï¼Œæ—¨åœ¨è§£å†³AIåœ¨æ³•å¾‹æ¡æ–‡è§£è¯»ä¸è§„åˆ™åº”ç”¨ä¸­çš„ç²¾ç¡®æ€§æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å°†æ³•å¾‹æ¨ç†åˆ†ä¸ºçŸ¥è¯†è·å–ä¸çŸ¥è¯†åº”ç”¨ä¸¤ä¸ªé˜¶æ®µï¼Œé¦–å…ˆé€šè¿‡ä¸“é—¨æ™ºèƒ½ä½“æå–æ³•å¾‹æ¦‚å¿µå¹¶å°†è§„åˆ™å½¢å¼åŒ–ä¸ºå¯éªŒè¯çš„ä¸­é—´è¡¨ç¤ºï¼Œéšåé€šè¿‡äº‹å®æ˜ å°„ã€ç¬¦å·æ¨ç†(Symbolic Inference)å’Œç¨‹åºåŒ–æ‰‹æ®µå¤„ç†å…·ä½“æ¡ˆä»¶ã€‚è¿™ç§å°†è‡ªç„¶è¯­è¨€ç†è§£ä¸ç¬¦å·æ¨ç†ç›¸ç»“åˆçš„æ¶æ„æä¾›äº†æ˜¾å¼çš„å®¡æŸ¥ç‚¹ï¼Œç›¸æ¯”ç«¯åˆ°ç«¯(End-to-End)æ¨¡å‹æ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿçš„é€æ˜åº¦ã€‚åœ¨æ³•å®šç¨åŠ¡è®¡ç®—ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼Œè¯¥æ–¹æ³•å°†åŸºç¡€æ¨¡å‹çš„å‡†ç¡®ç‡ä»18.8%æå‡è‡³76.4%ï¼Œæœ‰æ•ˆç¼©å°äº†æ¨ç†èƒ½åŠ›å·®è·ã€‚è¯¥æˆæœè¯æ˜äº†é€šè¿‡å½¢å¼åŒ–çŸ¥è¯†è¡¨ç¤ºçš„æ¨¡å—åŒ–æ¶æ„å¯ä»¥æ˜¾è‘—æå‡AIæ³•å¾‹æ¨ç†çš„ä¸€è‡´æ€§å’Œå¯è§£é‡Šæ€§ï¼Œä¸ºå¼€å‘æ›´é€æ˜ã€å¯é çš„æ³•å¾‹AIç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at the 34th ACM International Conference on Information and Knowledge Management (CIKM '25)",
      "pdf_url": "https://arxiv.org/pdf/2509.00710v1",
      "published_date": "2025-08-31 06:03:00 UTC",
      "updated_date": "2025-08-31 06:03:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:45:11.691203+00:00"
    },
    {
      "arxiv_id": "2509.00707v2",
      "title": "Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs",
      "title_zh": "å¥–åŠ±åŠ æƒé‡‡æ ·ï¼šå¢å¼ºæ©ç æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹çš„éè‡ªå›å½’ç‰¹æ€§",
      "authors": [
        "Daehoon Gwak",
        "Minseo Jung",
        "Junwoo Park",
        "Minho Park",
        "ChaeHun Park",
        "Junha Hyung",
        "Jaegul Choo"
      ],
      "abstract": "Masked diffusion models (MDMs) offer a promising non-autoregressive alternative for large language modeling. Standard decoding methods for MDMs, such as confidence-based sampling, select tokens independently based on individual token confidences at each diffusion step. However, we observe that this independent token selection often results in generation orders resembling sequential autoregressive processes, limiting the advantages of non-autoregressive modeling. To mitigate this pheonomenon, we propose Reward-Weighted Sampling (RWS), a novel decoding strategy that leverages an external reward model to provide a principled global signal during the iterative diffusion process. Specifically, at each diffusion step, RWS evaluates the quality of the entire intermediate sequence and scales token logits accordingly, guiding token selection by integrating global sequence-level coherence. This method selectively increases the confidence of tokens that initially have lower scores, thereby promoting a more non-autoregressive generation order. Furthermore, we provide theoretical justification showing that reward-weighted logit scaling induces beneficial rank reversals in token selection and consistently improves expected reward. Experiments demonstrate that RWS significantly promotes non-autoregressive generation orders, leading to improvements across multiple evaluation metrics. These results highlight the effectiveness of integrating global signals in enhancing both the non-autoregressive properties and overall performance of MDMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆMasked Diffusion Models, MDMsï¼‰ä¸­åŸºäºç½®ä¿¡åº¦çš„é‡‡æ ·å¯¼è‡´ç”Ÿæˆé¡ºåºè¶‹å‘äºè‡ªå›å½’è¿‡ç¨‹è¿™ä¸€å±€é™æ€§ï¼Œæå‡ºäº†å¥–åŠ±åŠ æƒé‡‡æ ·ï¼ˆReward-Weighted Sampling, RWSï¼‰è§£ç ç­–ç•¥ã€‚RWS é€šè¿‡å¼•å…¥å¤–éƒ¨å¥–åŠ±æ¨¡å‹ï¼ˆReward Modelï¼‰ï¼Œåœ¨æ‰©æ•£è¿­ä»£è¿‡ç¨‹ä¸­æä¾›å…¨å±€ä¿¡å·ï¼Œç”¨ä»¥è¯„ä¼°ä¸­é—´åºåˆ—çš„æ•´ä½“è´¨é‡å¹¶åŠ¨æ€ç¼©æ”¾ token çš„ logitsã€‚è¿™ç§æ–¹æ³•é€šè¿‡æ•´åˆå…¨å±€åºåˆ—çº§çš„è¿è´¯æ€§ï¼Œæœ‰æ•ˆæå‡äº†åˆå§‹è¯„åˆ†è¾ƒä½ token çš„ç½®ä¿¡åº¦ï¼Œä»è€Œä¿ƒè¿›äº†æ›´å…·éè‡ªå›å½’ç‰¹å¾çš„ç”Ÿæˆé¡ºåºã€‚ç†è®ºåˆ†æè¯æ˜ï¼Œå¥–åŠ±åŠ æƒ logit ç¼©æ”¾åœ¨ token é€‰æ‹©ä¸­å¼•å‘äº†æœ‰ç›Šçš„æ’åç¿»è½¬ï¼ˆrank reversalsï¼‰ï¼Œå¹¶æŒç»­æé«˜äº†é¢„æœŸå¥–åŠ±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRWS åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—å¢å¼ºäº† MDMs çš„éè‡ªå›å½’å±æ€§åŠæ•´ä½“ç”Ÿæˆæ€§èƒ½ï¼Œä¸ºå¢å¼ºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„å…¨å±€å»ºæ¨¡èƒ½åŠ›æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Main Paper (Long)",
      "pdf_url": "https://arxiv.org/pdf/2509.00707v2",
      "published_date": "2025-08-31 05:48:30 UTC",
      "updated_date": "2025-09-20 05:43:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:44:59.192608+00:00"
    },
    {
      "arxiv_id": "2509.00704v1",
      "title": "Why Pool When You Can Flow? Active Learning with GFlowNets",
      "title_zh": "ä½•å¿…æ± åŒ–ï¼Œè½¬å‘æµåŠ¨ï¼šåŸºäº GFlowNets çš„ä¸»åŠ¨å­¦ä¹ ",
      "authors": [
        "Renfei Zhang",
        "Mohit Pandey",
        "Artem Cherkasov",
        "Martin Ester"
      ],
      "abstract": "The scalability of pool-based active learning is limited by the computational cost of evaluating large unlabeled datasets, a challenge that is particularly acute in virtual screening for drug discovery. While active learning strategies such as Bayesian Active Learning by Disagreement (BALD) prioritize informative samples, it remains computationally intensive when scaled to libraries containing billions samples. In this work, we introduce BALD-GFlowNet, a generative active learning framework that circumvents this issue. Our method leverages Generative Flow Networks (GFlowNets) to directly sample objects in proportion to the BALD reward. By replacing traditional pool-based acquisition with generative sampling, BALD-GFlowNet achieves scalability that is independent of the size of the unlabeled pool. In our virtual screening experiment, we show that BALD-GFlowNet achieves a performance comparable to that of standard BALD baseline while generating more structurally diverse molecules, offering a promising direction for efficient and scalable molecular discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ± åŒ–å¼ä¸»åŠ¨å­¦ä¹ ï¼ˆPool-based Active Learningï¼‰åœ¨å¤„ç†è¯ç‰©å‘ç°ç­‰å¤§è§„æ¨¡æœªæ ‡è®°æ•°æ®é›†æ—¶é¢ä¸´çš„è®¡ç®—æ‰©å±•æ€§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºäº† BALD-GFlowNetï¼Œè¿™æ˜¯ä¸€ç§å°†è´å¶æ–¯ä¸»åŠ¨å­¦ä¹ ï¼ˆBayesian Active Learning by Disagreement, BALDï¼‰ä¸ç”Ÿæˆæµç½‘ç»œï¼ˆGFlowNetsï¼‰ç›¸ç»“åˆçš„ç”Ÿæˆå¼ä¸»åŠ¨å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨ GFlowNets ç›´æ¥æ ¹æ® BALD å¥–åŠ±æ¯”ä¾‹è¿›è¡Œé‡‡æ ·ï¼ŒæˆåŠŸå°†è·å–è¿‡ç¨‹ä»ä¾èµ–äºæ± å¤§å°çš„è¯„ä¼°è½¬å˜ä¸ºç”Ÿæˆå¼é‡‡æ ·ï¼Œå®ç°äº†ä¸æœªæ ‡è®°æ± è§„æ¨¡æ— å…³çš„å¯æ‰©å±•æ€§ã€‚åœ¨è™šæ‹Ÿç­›é€‰å®éªŒä¸­ï¼ŒBALD-GFlowNet ä¸ä»…åœ¨æ€§èƒ½ä¸Šä¸æ ‡å‡† BALD åŸºçº¿ç›¸å½“ï¼Œè¿˜ç”Ÿæˆäº†ç»“æ„æ›´åŠ å¤šæ ·åŒ–çš„åˆ†å­ã€‚è¿™é¡¹å·¥ä½œä¸ºé«˜æ•ˆã€å¤§è§„æ¨¡çš„åˆ†å­å‘ç°æä¾›äº†ä¸€ä¸ªå…·æœ‰æ½œåŠ›çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages; 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00704v1",
      "published_date": "2025-08-31 05:15:59 UTC",
      "updated_date": "2025-08-31 05:15:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:45:06.990372+00:00"
    },
    {
      "arxiv_id": "2509.00701v1",
      "title": "Unsupervised Dataset Cleaning Framework for Encrypted Traffic Classification",
      "title_zh": "é¢å‘åŠ å¯†æµé‡åˆ†ç±»çš„æ— ç›‘ç£æ•°æ®é›†æ¸…æ´—æ¡†æ¶",
      "authors": [
        "Kun Qiu",
        "Ying Wang",
        "Baoqian Li",
        "Wenjun Zhu"
      ],
      "abstract": "Traffic classification, a technique for assigning network flows to predefined categories, has been widely deployed in enterprise and carrier networks. With the massive adoption of mobile devices, encryption is increasingly used in mobile applications to address privacy concerns. Consequently, traditional methods such as Deep Packet Inspection (DPI) fail to distinguish encrypted traffic. To tackle this challenge, Artificial Intelligence (AI), in particular Machine Learning (ML), has emerged as a promising solution for encrypted traffic classification. A crucial prerequisite for any ML-based approach is traffic data cleaning, which removes flows that are not useful for training (e.g., irrelevant protocols, background activity, control-plane messages, and long-lived sessions). Existing cleaning solutions depend on manual inspection of every captured packet, making the process both costly and time-consuming. In this poster, we present an unsupervised framework that automatically cleans encrypted mobile traffic. Evaluation on real-world datasets shows that our framework incurs only a 2%~2.5% reduction in classification accuracy compared with manual cleaning. These results demonstrate that our method offers an efficient and effective preprocessing step for ML-based encrypted traffic classification.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ å¯†æµé‡åˆ†ç±»(Traffic classification)é¢†åŸŸä¸­æ·±åº¦æŠ¥æ–‡æ£€æµ‹(DPI)æŠ€æœ¯åœ¨å¤„ç†åŠ å¯†æ•°æ®æ—¶çš„å±€é™æ€§ï¼Œä»¥åŠç°æœ‰æœºå™¨å­¦ä¹ (Machine Learning)é¢„å¤„ç†æ–¹æ³•è¿‡åº¦ä¾èµ–äººå·¥æ¸…æ´—ã€æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„æ— ç›‘ç£(unsupervised)æ•°æ®é›†æ¸…æ´—æ¡†æ¶ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªåŠ¨ä»ç§»åŠ¨æµé‡ä¸­è¯†åˆ«å¹¶ç§»é™¤æ— å…³åè®®ã€èƒŒæ™¯æ´»åŠ¨ã€æ§åˆ¶å¹³é¢æ¶ˆæ¯åŠé•¿è¿æ¥ä¼šè¯ç­‰ä¸é€‚äºè®­ç»ƒçš„æ•°æ®æµï¼Œå®ç°äº†åŠ å¯†ç§»åŠ¨æµé‡çš„è‡ªåŠ¨åŒ–é¢„å¤„ç†ã€‚é€šè¿‡å¯¹ç§»åŠ¨åº”ç”¨äº§ç”Ÿçš„æµ·é‡æµé‡è¿›è¡Œè‡ªåŠ¨åŒ–è¿‡æ»¤ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—é™ä½äº†æ„å»ºé«˜è´¨é‡è®­ç»ƒæ•°æ®é›†çš„äººåŠ›æˆæœ¬ã€‚åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶ä¸è€—æ—¶è€—åŠ›çš„äººå·¥æ¸…æ´—ç›¸æ¯”ï¼Œåœ¨åˆ†ç±»å‡†ç¡®ç‡ä¸Šçš„æŸå¤±ä»…ä¸º2%è‡³2.5%ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ¡†æ¶åœ¨å¤„ç†å¤§è§„æ¨¡åŠ å¯†æµé‡æ—¶çš„æœ‰æ•ˆæ€§ä¸å®ç”¨ä»·å€¼ã€‚è¿™è¯æ˜äº†è¯¥æ–¹æ³•åœ¨ä¿è¯åˆ†ç±»æ•ˆæœçš„åŒæ—¶ï¼Œæå¤§åœ°æé«˜äº†æ•°æ®å‡†å¤‡é˜¶æ®µçš„æ•ˆç‡ï¼Œä¸ºåŸºäºæœºå™¨å­¦ä¹ çš„åŠ å¯†æµé‡åˆ†ç±»æä¾›äº†ä¸€ä¸ªé«˜æ•ˆä¸”å®ç”¨çš„é¢„å¤„ç†è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted in IEEE ICNP 2025 Poster",
      "pdf_url": "https://arxiv.org/pdf/2509.00701v1",
      "published_date": "2025-08-31 05:01:04 UTC",
      "updated_date": "2025-08-31 05:01:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:45:20.989123+00:00"
    },
    {
      "arxiv_id": "2509.00696v1",
      "title": "Queuing for Civility: Regulating Emotions and Reducing Toxicity in Digital Discourse",
      "title_zh": "ä»¥æ’é˜Ÿä¿ƒæ–‡æ˜ï¼šæ•°å­—è¯è¯­ä¸­çš„æƒ…ç»ªè°ƒèŠ‚ä¸æ¯’æ€§æŠ‘åˆ¶",
      "authors": [
        "Akriti Verma",
        "Shama Islam",
        "Valeh Moghaddam",
        "Adnan Anwar"
      ],
      "abstract": "The pervasiveness of online toxicity, including hate speech and trolling, disrupts digital interactions and online well-being. Previous research has mainly focused on post-hoc moderation, overlooking the real-time emotional dynamics of online conversations and the impact of users' emotions on others. This paper presents a graph-based framework to identify the need for emotion regulation within online conversations. This framework promotes self-reflection to manage emotional responses and encourage responsible behaviour in real time. Additionally, a comment queuing mechanism is proposed to address intentional trolls who exploit emotions to inflame conversations. This mechanism introduces a delay in publishing comments, giving users time to self-regulate before further engaging in the conversation and helping maintain emotional balance. Analysis of social media data from Twitter and Reddit demonstrates that the graph-based framework reduced toxicity by 12%, while the comment queuing mechanism decreased the spread of anger by 15%, with only 4% of comments being temporarily held on average. These findings indicate that combining real-time emotion regulation with delayed moderation can significantly improve well-being in online environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨çº¿å¯¹è¯ä¸­æ™®éå­˜åœ¨çš„æ¯’æ€§è¨€è®º(Toxicity)å’Œæƒ…ç»ªç®¡ç†ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨æå‡æ•°å­—è¯è¯­æ–‡æ˜åº¦çš„ç»¼åˆè°ƒèŠ‚æ¡†æ¶ã€‚è®ºæ–‡å¼€å‘äº†ä¸€ç§åŸºäºå›¾(Graph-based)çš„ç³»ç»Ÿæ¥è¯†åˆ«å®æ—¶çš„æƒ…ç»ªè°ƒèŠ‚éœ€æ±‚ï¼Œé€šè¿‡å¼•å¯¼ç”¨æˆ·è‡ªæˆ‘åæ€æ¥å‡å°‘å†²åŠ¨è¡Œä¸ºã€‚é’ˆå¯¹åˆ»æ„ç…½åŠ¨æƒ…ç»ªçš„å–·å­(Trolls)ï¼Œç ”ç©¶è®¾è®¡äº†è¯„è®ºæ’é˜Ÿæœºåˆ¶(Comment queuing mechanism)ï¼Œé€šè¿‡å¼•å…¥å‘å¸ƒå»¶è¿Ÿä¸ºç”¨æˆ·æä¾›è‡ªæˆ‘è°ƒèŠ‚çš„æ—¶é—´çª—å£ã€‚å¯¹Twitterå’ŒRedditæ•°æ®çš„å®éªŒåˆ†ææ˜¾ç¤ºï¼Œè¯¥å›¾æ¡†æ¶ä½¿æ¯’æ€§è¨€è®ºé™ä½äº†12%ï¼Œè€Œæ’é˜Ÿæœºåˆ¶åœ¨ä»…å¹³å‡æš‚ç¼“4%è¯„è®ºçš„å‰æä¸‹ï¼Œå°†æ„¤æ€’æƒ…ç»ªçš„ä¼ æ’­å‡å°‘äº†15%ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œç»“åˆå®æ—¶æƒ…ç»ªè°ƒèŠ‚ä¸å»¶è¿Ÿé€‚åº¦(Delayed moderation)èƒ½æ˜¾è‘—ä¼˜åŒ–åœ¨çº¿äº’åŠ¨ç¯å¢ƒå¹¶æå‡ç”¨æˆ·ç¦ç¥‰ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00696v1",
      "published_date": "2025-08-31 04:32:15 UTC",
      "updated_date": "2025-08-31 04:32:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:45:22.492321+00:00"
    },
    {
      "arxiv_id": "2509.00693v1",
      "title": "DELTA: Variational Disentangled Learning for Privacy-Preserving Data Reprogramming",
      "title_zh": "DELTAï¼šé¢å‘éšç§ä¿æŠ¤æ•°æ®é‡ç¼–ç¨‹çš„å˜åˆ†è§£è€¦å­¦ä¹ ",
      "authors": [
        "Arun Vignesh Malarkkan",
        "Haoyue Bai",
        "Anjali Kaushik",
        "Yanjie Fu"
      ],
      "abstract": "In real-world applications, domain data often contains identifiable or sensitive attributes, is subject to strict regulations (e.g., HIPAA, GDPR), and requires explicit data feature engineering for interpretability and transparency. Existing feature engineering primarily focuses on advancing downstream task performance, often risking privacy leakage. We generalize this learning task under such new requirements as Privacy-Preserving Data Reprogramming (PPDR): given a dataset, transforming features to maximize target attribute prediction accuracy while minimizing sensitive attribute prediction accuracy. PPDR poses challenges for existing systems: 1) generating high-utility feature transformations without being overwhelmed by a large search space, and 2) disentangling and eliminating sensitive information from utility-oriented features to reduce privacy inferability. To tackle these challenges, we propose DELTA, a two-phase variational disentangled generative learning framework. Phase I uses policy-guided reinforcement learning to discover feature transformations with downstream task utility, without any regard to privacy inferability. Phase II employs a variational LSTM seq2seq encoder-decoder with a utility-privacy disentangled latent space design and adversarial-causal disentanglement regularization to suppress privacy signals during feature generation. Experiments on eight datasets show DELTA improves predictive performance by ~9.3% and reduces privacy leakage by ~35%, demonstrating robust, privacy-aware data transformation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢†åŸŸæ•°æ®ä¸­çš„æ•æ„Ÿå±æ€§æ³„éœ²å’Œåˆè§„æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†éšç§ä¿æŠ¤æ•°æ®é‡ç¼–ç¨‹ (Privacy-Preserving Data Reprogramming, PPDR) ä»»åŠ¡ï¼Œæ—¨åœ¨æœ€å¤§åŒ–ç›®æ ‡å±æ€§é¢„æµ‹å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå°†æ•æ„Ÿå±æ€§çš„æ¨æ–­é£é™©é™è‡³æœ€ä½ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† DELTAï¼Œä¸€ç§ä¸¤é˜¶æ®µçš„å˜åˆ†è§£è€¦ç”Ÿæˆå­¦ä¹ æ¡†æ¶ (variational disentangled generative learning framework)ã€‚ç¬¬ä¸€é˜¶æ®µåˆ©ç”¨ç­–ç•¥å¼•å¯¼çš„å¼ºåŒ–å­¦ä¹  (policy-guided reinforcement learning) æ¥æœç´¢å…·æœ‰é«˜ä¸‹æ¸¸ä»»åŠ¡æ•ˆç”¨çš„ç‰¹å¾å˜æ¢ï¼›ç¬¬äºŒé˜¶æ®µåˆ™é‡‡ç”¨åŸºäºå˜åˆ† LSTM seq2seq çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œé€šè¿‡æ•ˆç”¨-éšç§è§£è€¦æ½œç©ºé—´å’Œå¯¹æŠ—å› æœè§£è€¦æ­£åˆ™åŒ– (adversarial-causal disentanglement regularization) åœ¨ç‰¹å¾ç”Ÿæˆè¿‡ç¨‹ä¸­æŠ‘åˆ¶éšç§ä¿¡å·ã€‚åœ¨å…«ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDELTA ä½¿é¢„æµ‹æ€§èƒ½æå‡äº†çº¦ 9.3%ï¼Œå¹¶æœ‰æ•ˆå‡å°‘äº†çº¦ 35% çš„éšç§æ³„éœ²ã€‚è¯¥æ–¹æ³•è¯æ˜äº†åœ¨ä¿éšœæ•°æ®è½¬æ¢é²æ£’æ€§çš„åŒæ—¶ï¼Œå®ç°é«˜æ•ˆéšç§ä¿æŠ¤ç‰¹å¾å·¥ç¨‹çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, 3 Tables. Accepted at IEEE International Conference on Data Mining (ICDM) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00693v1",
      "published_date": "2025-08-31 04:18:42 UTC",
      "updated_date": "2025-08-31 04:18:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:45:27.691234+00:00"
    },
    {
      "arxiv_id": "2509.00684v1",
      "title": "Valid Property-Enhanced Contrastive Learning for Targeted Optimization & Resampling for Novel Drug Design",
      "title_zh": "é¢å‘æ–°è¯è®¾è®¡å®šå‘ä¼˜åŒ–ä¸é‡é‡‡æ ·çš„æœ‰æ•ˆå±æ€§å¢å¼ºå¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Amartya Banerjee",
        "Somnath Kar",
        "Anirban Pal",
        "Debabrata Maiti"
      ],
      "abstract": "Efficiently steering generative models toward pharmacologically relevant regions of chemical space remains a major obstacle in molecular drug discovery under low-data regimes. We present VECTOR+: Valid-property-Enhanced Contrastive Learning for Targeted Optimization and Resampling, a framework that couples property-guided representation learning with controllable molecule generation. VECTOR+ applies to both regression and classification tasks and enables interpretable, data-efficient exploration of functional chemical space. We evaluate on two datasets: a curated PD-L1 inhibitor set (296 compounds with experimental $IC_{50}$ values) and a receptor kinase inhibitor set (2,056 molecules by binding mode). Despite limited training data, VECTOR+ generates novel, synthetically tractable candidates. Against PD-L1 (PDB 5J89), 100 of 8,374 generated molecules surpass a docking threshold of $-15.0$ kcal/mol, with the best scoring $-17.6$ kcal/mol compared to the top reference inhibitor ($-15.4$ kcal/mol). The best-performing molecules retain the conserved biphenyl pharmacophore while introducing novel motifs. Molecular dynamics (250 ns) confirm binding stability (ligand RMSD < $2.5$ angstroms). VECTOR+ generalizes to kinase inhibitors, producing compounds with stronger docking scores than established drugs such as brigatinib and sorafenib. Benchmarking against JT-VAE and MolGPT across docking, novelty, uniqueness, and Tanimoto similarity highlights the superior performance of our method. These results position our work as a robust, extensible approach for property-conditioned molecular design in low-data settings, bridging contrastive learning and generative modeling for reproducible, AI-accelerated discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸º VECTOR+ çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å°æ ·æœ¬æ•°æ®ç¯å¢ƒä¸‹åˆ†å­è¯ç‰©å‘ç°ä¸­ç”Ÿæˆæ¨¡å‹éš¾ä»¥é«˜æ•ˆå¼•å¯¼çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†å±æ€§å¼•å¯¼çš„è¡¨ç¤ºå­¦ä¹ ï¼ˆproperty-guided representation learningï¼‰ä¸å¯æ§åˆ†å­ç”Ÿæˆç›¸ç»“åˆï¼Œé€‚ç”¨äºå›å½’å’Œåˆ†ç±»ä»»åŠ¡ï¼Œå¹¶èƒ½å®ç°æ•°æ®é«˜æ•ˆçš„åŒ–å­¦ç©ºé—´æ¢ç´¢ã€‚åœ¨ PD-L1 æŠ‘åˆ¶å‰‚æ•°æ®é›†ä¸Šï¼ŒVECTOR+ åœ¨è®­ç»ƒæ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ç”Ÿæˆäº†å¤šç§æ–°å‹ä¸”å…·æœ‰åˆæˆå¯è¡Œæ€§çš„åˆ†å­ï¼Œå…¶ä¸­è¡¨ç°æœ€å¥½çš„åˆ†å­å¯¹æ¥åˆ†æ•°è¾¾åˆ° -17.6 kcal/molï¼Œä¼˜äºå‚è€ƒæŠ‘åˆ¶å‰‚ã€‚åˆ†å­åŠ¨åŠ›å­¦ï¼ˆMolecular dynamicsï¼‰æ¨¡æ‹Ÿè¿›ä¸€æ­¥è¯å®äº†ç”Ÿæˆåˆ†å­çš„ç»“åˆç¨³å®šæ€§ï¼Œä¸”è¯¥æ–¹æ³•åœ¨æ¿€é…¶æŠ‘åˆ¶å‰‚è®¾è®¡ä¸Šä¹Ÿå±•ç°å‡ºå¼ºäº brigatinib ç­‰ç°æœ‰è¯ç‰©çš„æ€§èƒ½ã€‚é€šè¿‡ä¸ JT-VAE å’Œ MolGPT çš„åŸºå‡†æµ‹è¯•å¯¹æ¯”ï¼ŒVECTOR+ åœ¨å¯¹æ¥åˆ†æ•°ã€æ–°é¢–æ€§å’Œå”¯ä¸€æ€§æ–¹é¢å‡è¡¨ç°å“è¶Šã€‚è¿™é¡¹å·¥ä½œä¸ºä½æ•°æ®åœºæ™¯ä¸‹çš„å±æ€§è°ƒèŠ‚åˆ†å­è®¾è®¡æä¾›äº†ä¸€ç§ç¨³å¥ä¸”å¯æ‰©å±•çš„æ–¹æ³•ï¼Œæœ‰æ•ˆè¡”æ¥äº†å¯¹æ¯”å­¦ä¹ ä¸ç”Ÿæˆæ¨¡å‹ï¼Œä¸º AI åŠ é€Ÿè¯ç‰©å‘ç°å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/amartya21/vector-drug-design.git",
      "pdf_url": "https://arxiv.org/pdf/2509.00684v1",
      "published_date": "2025-08-31 03:55:29 UTC",
      "updated_date": "2025-08-31 03:55:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:45:33.687744+00:00"
    },
    {
      "arxiv_id": "2509.00673v1",
      "title": "Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias in Language Models in Detecting Hate Speech",
      "title_zh": "è‡ªä¿¡ã€æ ¡å‡†è¿˜æ˜¯å…±è°‹ï¼šæ¢ç©¶è¯­è¨€æ¨¡å‹åœ¨ä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­å®‰å…¨å¯¹é½ä¸æ„è¯†å½¢æ€åè§ä¹‹é—´çš„æƒè¡¡",
      "authors": [
        "Sanjeeevan Selvaganapathy",
        "Mehwish Nasim"
      ],
      "abstract": "We investigate the efficacy of Large Language Models (LLMs) in detecting implicit and explicit hate speech, examining whether models with minimal safety alignment (uncensored) might provide more objective classification capabilities compared to their heavily-aligned (censored) counterparts. While uncensored models theoretically offer a less constrained perspective free from moral guardrails that could bias classification decisions, our results reveal a surprising trade-off: censored models significantly outperform their uncensored counterparts in both accuracy and robustness, achieving 78.7% versus 64.1% strict accuracy. However, this enhanced performance comes with its own limitation -- the safety alignment acts as a strong ideological anchor, making censored models resistant to persona-based influence, while uncensored models prove highly malleable to ideological framing. Furthermore, we identify critical failures across all models in understanding nuanced language such as irony. We also find alarming fairness disparities in performance across different targeted groups and systemic overconfidence that renders self-reported certainty unreliable. These findings challenge the notion of LLMs as objective arbiters and highlight the need for more sophisticated auditing frameworks that account for fairness, calibration, and ideological consistency.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ£€æµ‹æ˜¾æ€§å’Œéšæ€§ä»‡æ¨è¨€è®º (Hate Speech) æ–¹é¢çš„æ•ˆèƒ½ï¼Œé‡ç‚¹å¯¹æ¯”äº†ç»è¿‡å®‰å…¨å¯¹é½ (Safety Alignment) ä¸æœªç»å®¡æŸ¥ (Uncensored) æ¨¡å‹åœ¨åˆ†ç±»èƒ½åŠ›ä¸Šçš„æƒè¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡æœªç»å®¡æŸ¥çš„æ¨¡å‹ç†è®ºä¸Šæ›´å°‘å—é™ï¼Œä½†ç»è¿‡å®‰å…¨å¯¹é½çš„æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šæ˜¾è‘—å ä¼˜ï¼Œå…¶ä¸¥æ ¼å‡†ç¡®ç‡è¾¾åˆ° 78.7%ï¼Œè¿œé«˜äºåè€…çš„ 64.1%ã€‚ç„¶è€Œï¼Œè¿™ç§å¢å¼ºçš„æ€§èƒ½ä½¿å¯¹é½æ¨¡å‹äº§ç”Ÿäº†æ„è¯†å½¢æ€é”šå®šï¼Œä½¿å…¶èƒ½æŠµå¾¡ç‰¹å®šè§’è‰²èº«ä»½ (Persona) çš„å½±å“ï¼Œè€Œæœªç»å®¡æŸ¥çš„æ¨¡å‹åˆ™è¡¨ç°å‡ºæé«˜çš„æ„è¯†å½¢æ€å¯å¡‘æ€§ã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨è¯†åˆ«è®½åˆº (Irony) ç­‰å¾®å¦™è¯­è¨€æ—¶å‡å­˜åœ¨ä¸¥é‡ç¼ºé™·ï¼Œä¸”å­˜åœ¨è·¨ç¾¤ä½“çš„å…¬å¹³æ€§ (Fairness) å·®å¼‚ä»¥åŠç³»ç»Ÿæ€§è¿‡åº¦è‡ªä¿¡ (Overconfidence) é—®é¢˜ã€‚è¯¥ç ”ç©¶ç»“æœæŒ‘æˆ˜äº†æ¨¡å‹ä½œä¸ºå®¢è§‚ä»²è£è€…çš„ä¼ ç»Ÿè®¤çŸ¥ï¼Œå¹¶å¼ºè°ƒåœ¨æœªæ¥æ„å»ºå®¡è®¡æ¡†æ¶æ—¶å¿…é¡»ç»Ÿç­¹è€ƒè™‘å…¬å¹³æ€§ã€æ ¡å‡† (Calibration) å’Œæ„è¯†å½¢æ€çš„ä¸€è‡´æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00673v1",
      "published_date": "2025-08-31 03:00:55 UTC",
      "updated_date": "2025-08-31 03:00:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:45:38.497569+00:00"
    },
    {
      "arxiv_id": "2509.00670v1",
      "title": "PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces",
      "title_zh": "PyNoeticï¼šç”¨äºè„‘ç”µè„‘æœºæ¥å£æ— ä»£ç å¼€å‘çš„æ¨¡å—åŒ– Python æ¡†æ¶",
      "authors": [
        "Gursimran Singh",
        "Aviral Chharia",
        "Rahul Upadhyay",
        "Vinay Kumar",
        "Luca Longo"
      ],
      "abstract": "Electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) have emerged as a transformative technology with applications spanning robotics, virtual reality, medicine, and rehabilitation. However, existing BCI frameworks face several limitations, including a lack of stage-wise flexibility essential for experimental research, steep learning curves for researchers without programming expertise, elevated costs due to reliance on proprietary software, and a lack of all-inclusive features leading to the use of multiple external tools affecting research outcomes. To address these challenges, we present PyNoetic, a modular BCI framework designed to cater to the diverse needs of BCI research. PyNoetic is one of the very few frameworks in Python that encompasses the entire BCI design pipeline, from stimulus presentation and data acquisition to channel selection, filtering, feature extraction, artifact removal, and finally simulation and visualization. Notably, PyNoetic introduces an intuitive and end-to-end GUI coupled with a unique pick-and-place configurable flowchart for no-code BCI design, making it accessible to researchers with minimal programming experience. For advanced users, it facilitates the seamless integration of custom functionalities and novel algorithms with minimal coding, ensuring adaptability at each design stage. PyNoetic also includes a rich array of analytical tools such as machine learning models, brain-connectivity indices, systematic testing functionalities via simulation, and evaluation methods of novel paradigms. PyNoetic's strengths lie in its versatility for both offline and real-time BCI development, which streamlines the design process, allowing researchers to focus on more intricate aspects of BCI development and thus accelerate their research endeavors. Project Website: https://neurodiag.github.io/PyNoetic",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†PyNoeticï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºEEGè„‘æœºæ¥å£ï¼ˆBCIsï¼‰ç ”ç©¶è®¾è®¡çš„æ¨¡å—åŒ–Pythonæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å·¥å…·å­¦ä¹ æ›²çº¿é™¡å³­ã€æˆæœ¬é«˜æ˜‚åŠç¼ºä¹å…¨æµç¨‹çµæ´»æ€§ç­‰å±€é™æ€§ã€‚PyNoeticæ¶µç›–äº†ä»åˆºæ¿€å‘ˆç°ã€æ•°æ®é‡‡é›†ã€é€šé“é€‰æ‹©åˆ°ç‰¹å¾æå–å’Œå¯è§†åŒ–çš„å®Œæ•´è®¾è®¡ç®¡çº¿ï¼Œæ˜¯Pythonç”Ÿæ€ä¸­æå°‘æ•°èƒ½å¤Ÿæä¾›ç«¯åˆ°ç«¯æ”¯æŒçš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ç›´è§‚çš„GUIå’Œç‹¬ç‰¹çš„â€œå³æ’å³ç”¨â€æµç¨‹å›¾é…ç½®ï¼Œå®ç°äº†æ— ä»£ç ï¼ˆno-codeï¼‰çš„BCIå¼€å‘ï¼Œæå¤§é™ä½äº†éç¼–ç¨‹èƒŒæ™¯ç ”ç©¶è€…çš„å‡†å…¥é—¨æ§›ã€‚é’ˆå¯¹é«˜çº§ç”¨æˆ·ï¼Œå®ƒæ”¯æŒè‡ªå®šä¹‰ç®—æ³•çš„æ— ç¼é›†æˆï¼Œå¹¶é›†æˆäº†æœºå™¨å­¦ä¹ ï¼ˆmachine learningï¼‰æ¨¡å‹ã€è„‘è¿é€šæ€§æŒ‡æ ‡åŠç³»ç»Ÿä»¿çœŸæµ‹è¯•ç­‰ä¸°å¯Œå·¥å…·ã€‚PyNoeticå…·å¤‡ç¦»çº¿å’Œå®æ—¶ï¼ˆreal-timeï¼‰å¼€å‘çš„é€šç”¨æ€§ï¼Œé€šè¿‡ç®€åŒ–è®¾è®¡æµç¨‹ï¼Œæœ‰æ•ˆåŠ é€Ÿäº†è„‘æœºæ¥å£é¢†åŸŸåœ¨æœºå™¨äººã€åŒ»ç–—åŠåº·å¤ç­‰æ–¹å‘çš„ç ”ç©¶è¿›ç¨‹ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "eess.SP",
      "comment": "PLoS One 2025. Project Website: https://neurodiag.github.io/PyNoetic",
      "pdf_url": "https://arxiv.org/pdf/2509.00670v1",
      "published_date": "2025-08-31 02:49:12 UTC",
      "updated_date": "2025-08-31 02:49:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:46:21.855918+00:00"
    },
    {
      "arxiv_id": "2509.25197v1",
      "title": "Towards Repository-Level Program Verification with Large Language Models",
      "title_zh": "è¿ˆå‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä»“åº“çº§ç¨‹åºéªŒè¯",
      "authors": [
        "Si Cheng Zhong",
        "Xujie Si"
      ],
      "abstract": "Recent advancements in large language models (LLMs) suggest great promises in code and proof generations. However, scaling automated formal verification to real-world projects requires resolving cross-module dependencies and global contexts, which are crucial challenges overlooked by existing LLM-based methods with a special focus on targeting isolated, function-level verification tasks. To systematically explore and address the significant challenges of verifying entire software repositories, we introduce RVBench, the first verification benchmark explicitly designed for repository-level evaluation, constructed from four diverse and complex open-source Verus projects.\n  We further introduce RagVerus, an extensible framework that synergizes retrieval-augmented generation with context-aware prompting to automate proof synthesis for multi-module repositories. RagVerus triples proof pass rates on existing benchmarks under constrained model inference budgets, and achieves a 27% relative improvement on the more challenging RVBench benchmark, demonstrating a scalable and sample-efficient verification solution.",
      "tldr_zh": "é’ˆå¯¹ç›®å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å½¢å¼åŒ–éªŒè¯ä¸­éš¾ä»¥å¤„ç†è·¨æ¨¡å—ä¾èµ–å’Œå…¨å±€ä¸Šä¸‹æ–‡çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†RVBenchï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºä»“åº“çº§ï¼ˆrepository-levelï¼‰è¯„ä¼°è®¾è®¡çš„éªŒè¯åŸºå‡†ï¼Œç”±å››ä¸ªå¤æ‚çš„å¼€æºVerusé¡¹ç›®æ„å»ºã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†RagVerusæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä¸ä¸Šä¸‹æ–‡æ„ŸçŸ¥æç¤ºè¯ï¼Œå®ç°äº†å¤šæ¨¡å—ä»“åº“çš„è‡ªåŠ¨åŒ–è¯æ˜åˆæˆï¼ˆproof synthesisï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRagVerusåœ¨å—é™çš„æ¨ç†é¢„ç®—ä¸‹ï¼Œå°†ç°æœ‰åŸºå‡†çš„è¯æ˜é€šè¿‡ç‡æå‡äº†ä¸‰å€ã€‚åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„RVBenchä¸Šï¼ŒRagVeruså®ç°äº†27%çš„ç›¸å¯¹æ€§èƒ½æå‡ï¼Œä¸ºå¤§è§„æ¨¡è½¯ä»¶é¡¹ç›®çš„å½¢å¼åŒ–éªŒè¯æä¾›äº†ä¸€ç§å…·å¤‡å¯æ‰©å±•æ€§å’Œæ ·æœ¬æ•ˆç‡çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to LMPL 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.25197v1",
      "published_date": "2025-08-31 02:44:04 UTC",
      "updated_date": "2025-08-31 02:44:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:45:49.662889+00:00"
    },
    {
      "arxiv_id": "2509.00664v1",
      "title": "Fusion to Enhance: Fusion Visual Encoder to Enhance Multimodal Language Model",
      "title_zh": "Fusion to Enhanceï¼šèåˆè§†è§‰ç¼–ç å™¨å¢å¼ºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹",
      "authors": [
        "Yifei She",
        "Huangxuan Wu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have made significant progress in bridging visual perception with high-level textual reasoning. However, they face a fundamental contradiction: while excelling at complex semantic understanding, these models often fail at basic visual tasks that require precise detail perception. This deficiency primarily stems from the prevalent architectural reliance on a single vision encoder optimized for high-level semantic alignment, which inherently sacrifices the ability to capture fine-grained visual information. To address this issue, we introduce Fusion to Enhance (FtZ), a novel vision tower framework. FtZ moves beyond the single-encoder design by innovatively composing a semantically powerful anchor encoder with a perception-rich augmenting encoder via a lightweight Multi-Head Cross-Attention mechanism. Experimental results demonstrate that on several challenging benchmarks demanding fine-grained visual understanding, such as TextVQA, POPE, MMMU, MME and MM-Vet, our FtZ model significantly outperforms baselines that use only a single encoder or existing feature fusion methods. This work proves that composing heterogeneous expert encoders is an efficient and effective path to overcoming the visual perception bottleneck in current MLLMs, offering a new design paradigm for building next-generation AI systems with stronger perceptual capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å…·å¤‡å¤æ‚è¯­ä¹‰ç†è§£èƒ½åŠ›çš„åŒæ—¶ï¼Œå¾€å¾€åœ¨åŸºç¡€è§†è§‰æ„ŸçŸ¥ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œå¹¶å°†å…¶å½’å› äºå¯¹å•ä¸€è§†è§‰ç¼–ç å™¨çš„æ¶æ„ä¾èµ–ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç“¶é¢ˆï¼Œä½œè€…æå‡ºäº† Fusion to Enhance (FtZ) è§†è§‰å¡”æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å¼‚æ„ç¼–ç å™¨ç»„åˆå¢å¼ºæ¨¡å‹çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°åˆ©ç”¨è½»é‡çº§çš„ Multi-Head Cross-Attention æœºåˆ¶ï¼Œå°†å…·å¤‡å¼ºè¯­ä¹‰èƒ½åŠ›çš„ anchor encoder ä¸æ„ŸçŸ¥ä¿¡æ¯ä¸°å¯Œçš„ augmenting encoder è¿›è¡Œèåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ TextVQAã€POPEã€MMMUã€MME å’Œ MM-Vet ç­‰å¤šä¸ªå¼ºè°ƒç²¾ç»†è§†è§‰ç†è§£çš„æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸­ï¼ŒFtZ æ¨¡å‹æ˜¾è‘—ä¼˜äºå•ä¸€ç¼–ç å™¨æˆ–ç°æœ‰çš„ç‰¹å¾èåˆæ–¹æ³•ã€‚è¯¥å·¥ä½œè¯æ˜äº†ç»„åˆå¼‚æ„ä¸“å®¶ç¼–ç å™¨æ˜¯å…‹æœå½“å‰ MLLMs è§†è§‰æ„ŸçŸ¥ç“¶é¢ˆçš„é«˜æ•ˆè·¯å¾„ï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£ AI ç³»ç»Ÿæä¾›äº†å…¨æ–°çš„è®¾è®¡èŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00664v1",
      "published_date": "2025-08-31 02:22:57 UTC",
      "updated_date": "2025-08-31 02:22:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:46:37.689022+00:00"
    },
    {
      "arxiv_id": "2509.04481v2",
      "title": "Narrative-to-Scene Generation: An LLM-Driven Pipeline for 2D Game Environments",
      "title_zh": "å™äº‹åˆ°åœºæ™¯ç”Ÿæˆï¼šä¸€ç§é¢å‘2Dæ¸¸æˆç¯å¢ƒçš„å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨æµæ°´çº¿",
      "authors": [
        "Yi-Chun Chen",
        "Arnav Jhala"
      ],
      "abstract": "Recent advances in large language models (LLMs) enable compelling story generation, but connecting narrative text to playable visual environments remains an open challenge in procedural content generation (PCG). We present a lightweight pipeline that transforms short narrative prompts into a sequence of 2D tile-based game scenes, reflecting the temporal structure of stories. Given an LLM-generated narrative, our system identifies three key time frames, extracts spatial predicates in the form of \"Object-Relation-Object\" triples, and retrieves visual assets using affordance-aware semantic embeddings from the GameTileNet dataset. A layered terrain is generated using Cellular Automata, and objects are placed using spatial rules grounded in the predicate structure. We evaluated our system in ten diverse stories, analyzing tile-object matching, affordance-layer alignment, and spatial constraint satisfaction across frames. This prototype offers a scalable approach to narrative-driven scene generation and lays the foundation for future work on multi-frame continuity, symbolic tracking, and multi-agent coordination in story-centered PCG.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¨‹åºåŒ–å†…å®¹ç”Ÿæˆ (PCG) ä¸­å™äº‹æ–‡æœ¬ä¸å¯ç©è§†è§‰ç¯å¢ƒä¹‹é—´çš„è¿æ¥æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹ (LLM) é©±åŠ¨çš„è½»é‡çº§æµæ°´çº¿ï¼Œæ—¨åœ¨å°†ç®€çŸ­çš„å™äº‹æç¤ºè½¬åŒ–ä¸ºä¸€ç³»åˆ—åæ˜ æ•…äº‹æ—¶é—´ç»“æ„çš„ 2D ç“·ç –å¼ (tile-based) æ¸¸æˆåœºæ™¯ã€‚ç³»ç»Ÿé€šè¿‡ä» LLM ç”Ÿæˆçš„å™äº‹ä¸­æå–â€œå¯¹è±¡-å…³ç³»-å¯¹è±¡â€ (Object-Relation-Object) ä¸‰å…ƒç»„å½¢å¼çš„ç©ºé—´è°“è¯ï¼Œå¹¶åˆ©ç”¨ GameTileNet æ•°æ®é›†æä¾›çš„å…·å¤‡åŠŸèƒ½æ€§æ„ŸçŸ¥ (affordance-aware) çš„è¯­ä¹‰åµŒå…¥æŠ€æœ¯æ£€ç´¢è§†è§‰èµ„æºã€‚åœ¨åœºæ™¯æ„å»ºè¿‡ç¨‹ä¸­ï¼Œç ”ç©¶é‡‡ç”¨å…ƒèƒè‡ªåŠ¨æœº (Cellular Automata) ç”Ÿæˆåˆ†å±‚åœ°å½¢ï¼Œå¹¶ä¾æ®ç©ºé—´è§„åˆ™å°†å¯¹è±¡æ”¾ç½®åœ¨åŸºäºè°“è¯ç»“æ„çš„ç‰¹å®šä½ç½®ã€‚é€šè¿‡å¯¹åä¸ªä¸åŒæ•…äº‹çš„è¯„ä¼°ï¼Œå®éªŒæ·±å…¥åˆ†æäº†ç“¦ç‰‡å¯¹è±¡åŒ¹é…ã€åŠŸèƒ½å±‚å¯¹é½ä»¥åŠè·¨å¸§ç©ºé—´çº¦æŸçš„æ»¡è¶³æƒ…å†µã€‚è¯¥åŸå‹ä¸ºå™äº‹é©±åŠ¨çš„åœºæ™¯ç”Ÿæˆæä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ–¹æ³•ï¼Œå¹¶ä¸ºæœªæ¥å…³äºå¤šå¸§è¿è´¯æ€§ã€ç¬¦å·è·Ÿè¸ªå’Œå¤šæ™ºèƒ½ä½“åä½œçš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.GR",
      "comment": "Camera-ready version of a paper accepted at the AIIDE 2025 Workshop on Experimental AI in Games (EXAG)",
      "pdf_url": "https://arxiv.org/pdf/2509.04481v2",
      "published_date": "2025-08-31 01:45:56 UTC",
      "updated_date": "2025-12-31 23:32:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:46:44.993283+00:00"
    },
    {
      "arxiv_id": "2509.00654v1",
      "title": "The Name-Free Gap: Policy-Aware Stylistic Control in Music Generation",
      "title_zh": "æ— å§“åå·®è·ï¼šéŸ³ä¹ç”Ÿæˆä¸­ç­–ç•¥æ„ŸçŸ¥çš„é£æ ¼æ§åˆ¶",
      "authors": [
        "Ashwin Nagarajan",
        "Hao-Wen Dong"
      ],
      "abstract": "Text-to-music models capture broad attributes such as instrumentation or mood, but fine-grained stylistic control remains an open challenge. Existing stylization methods typically require retraining or specialized conditioning, which complicates reproducibility and limits policy compliance when artist names are restricted. We study whether lightweight, human-readable modifiers sampled from a large language model can provide a policy-robust alternative for stylistic control. Using MusicGen-small, we evaluate two artists: Billie Eilish (vocal pop) and Ludovico Einaudi (instrumental piano). For each artist, we use fifteen reference excerpts and evaluate matched seeds under three conditions: baseline prompts, artist-name prompts, and five descriptor sets. All prompts are generated using a large language model. Evaluation uses both VGGish and CLAP embeddings with distributional and per-clip similarity measures, including a new min-distance attribution metric. Results show that artist names are the strongest control signal across both artists, while name-free descriptors recover much of this effect. This highlights that existing safeguards such as the restriction of artist names in music generation prompts may not fully prevent style imitation. Cross-artist transfers reduce alignment, showing that descriptors encode targeted stylistic cues. We also present a descriptor table across ten contemporary artists to illustrate the breadth of the tokens. Together these findings define the name-free gap, the controllability difference between artist-name prompts and policy-compliant descriptors, shown through a reproducible evaluation protocol for prompt-level controllability.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ–‡æœ¬åˆ°éŸ³ä¹(text-to-music)æ¨¡å‹ä¸­çš„ç»†ç²’åº¦é£æ ¼æ§åˆ¶ï¼Œæ—¨åœ¨è§£å†³è‰ºæœ¯å®¶å§“åå—é™æ—¶çš„æ”¿ç­–åˆè§„æ€§ä¸é£æ ¼æ¨¡ä»¿ä¹‹é—´çš„çŸ›ç›¾ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨MusicGen-smallæ¨¡å‹ï¼Œè¯„ä¼°äº†ç”±å¤§è¯­è¨€æ¨¡å‹(LLM)ç”Ÿæˆçš„è½»é‡çº§ã€äººç±»å¯è¯»æè¿°ç¬¦ä½œä¸ºé£æ ¼æ§åˆ¶æ›¿ä»£æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚å®éªŒé’ˆå¯¹Billie Eilishå’ŒLudovico Einaudiä¸¤ä½è‰ºæœ¯å®¶ï¼Œé‡‡ç”¨VGGishå’ŒCLAPåµŒå…¥å‘é‡ä»¥åŠæ–°æå‡ºçš„æœ€å°è·ç¦»å½’å› åº¦é‡(min-distance attribution metric)è¿›è¡Œè¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶ç›´æ¥ä½¿ç”¨è‰ºæœ¯å®¶å§“åä»æ˜¯æœ€é«˜æ•ˆçš„ä¿¡å·ï¼Œä½†â€œæ— åâ€æè¿°ç¬¦èƒ½æ˜¾è‘—æ¢å¤å¤§éƒ¨åˆ†é£æ ¼ç‰¹å¾ï¼Œæ­ç¤ºäº†ç°æœ‰å®‰å…¨æœºåˆ¶åœ¨é˜²æ­¢é£æ ¼æ¨¡ä»¿(style imitation)æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥ç ”ç©¶æ­£å¼å®šä¹‰äº†â€œæ— åå·®è·â€(name-free gap)ï¼Œå³è‰ºæœ¯å®¶å§“åæç¤ºä¸åˆè§„æè¿°ç¬¦ä¹‹é—´çš„å¯æ§æ€§å·®å¼‚ï¼Œå¹¶æä¾›äº†ä¸€å¥—å¯é‡å¤çš„æç¤ºè¯çº§å¯æ§æ€§è¯„ä¼°åè®®ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00654v1",
      "published_date": "2025-08-31 01:27:16 UTC",
      "updated_date": "2025-08-31 01:27:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:47:02.895542+00:00"
    },
    {
      "arxiv_id": "2509.00653v1",
      "title": "IndiaWeatherBench: A Dataset and Benchmark for Data-Driven Regional Weather Forecasting over India",
      "title_zh": "IndiaWeatherBenchï¼šé¢å‘ India æ•°æ®é©±åŠ¨åŒºåŸŸå¤©æ°”é¢„æŠ¥çš„æ•°æ®é›†ä¸åŸºå‡†",
      "authors": [
        "Tung Nguyen",
        "Harkanwar Singh",
        "Nilay Naharas",
        "Lucas Bandarkar",
        "Aditya Grover"
      ],
      "abstract": "Regional weather forecasting is a critical problem for localized climate adaptation, disaster mitigation, and sustainable development. While machine learning has shown impressive progress in global weather forecasting, regional forecasting remains comparatively underexplored. Existing efforts often use different datasets and experimental setups, limiting fair comparison and reproducibility. We introduce IndiaWeatherBench, a comprehensive benchmark for data-driven regional weather forecasting focused on the Indian subcontinent. IndiaWeatherBench provides a curated dataset built from high-resolution regional reanalysis products, along with a suite of deterministic and probabilistic metrics to facilitate consistent training and evaluation. To establish strong baselines, we implement and evaluate a range of models across diverse architectures, including UNets, Transformers, and Graph-based networks, as well as different boundary conditioning strategies and training objectives. While focused on India, IndiaWeatherBench is easily extensible to other geographic regions. We open-source all raw and preprocessed datasets, model implementations, and evaluation pipelines to promote accessibility and future development. We hope IndiaWeatherBench will serve as a foundation for advancing regional weather forecasting research. Code is available at https://github.com/tung-nd/IndiaWeatherBench.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†IndiaWeatherBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹å°åº¦æ¬¡å¤§é™†åŒºåŸŸå¤©æ°”é¢„æŠ¥çš„ç»¼åˆæ€§åŸºå‡†å’Œæ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³åŒºåŸŸå°ºåº¦é¢„æµ‹åœ¨æ•°æ®é©±åŠ¨æ–¹æ³•ä¸­ç¼ºä¹ç»Ÿä¸€è¯„ä¼°æ ‡å‡†å’Œå¯å¤ç°æ€§çš„é—®é¢˜ã€‚è¯¥åŸºå‡†åˆ©ç”¨é«˜åˆ†è¾¨ç‡åŒºåŸŸå†åˆ†æäº§å“æ„å»ºäº†ç²¾é€‰æ•°æ®é›†ï¼Œå¹¶æ•´åˆäº†ä¸€ç³»åˆ—ç¡®å®šæ€§ä¸æ¦‚ç‡æ€§è¯„ä»·æŒ‡æ ‡ï¼Œä»¥æ”¯æŒæ¨¡å‹çš„æ ‡å‡†åŒ–è®­ç»ƒã€‚ç ”ç©¶äººå‘˜é€šè¿‡å®ç°å’Œè¯„ä¼°åŒ…æ‹¬UNetsã€Transformersä»¥åŠGraph-based networksåœ¨å†…çš„å¤šç§æ¨¡å‹æ¶æ„ï¼Œå»ºç«‹äº†å¼ºæœ‰åŠ›çš„åŸºå‡†è¡¨ç°ï¼Œå¹¶æ¢è®¨äº†ä¸åŒçš„è¾¹ç•Œæ¡ä»¶å¤„ç†ç­–ç•¥ã€‚å°½ç®¡è¯¥åŸºå‡†ä»¥å°åº¦ä¸ºæ ¸å¿ƒï¼Œä½†å…¶æ¡†æ¶è®¾è®¡å…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œå¯æ¨å¹¿è‡³å…¶ä»–åœ°ç†åŒºåŸŸã€‚è¯¥é¡¹ç›®å·²å…¨é¢å¼€æºåŸå§‹æ•°æ®ã€é¢„å¤„ç†æ•°æ®é›†åŠè¯„ä¼°ç®¡çº¿ï¼Œä¸ºæå‡åŒºåŸŸå¤©æ°”é¢„æŠ¥çš„ç ”ç©¶æ°´å¹³å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00653v1",
      "published_date": "2025-08-31 01:25:49 UTC",
      "updated_date": "2025-08-31 01:25:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:46:47.987461+00:00"
    },
    {
      "arxiv_id": "2509.00647v1",
      "title": "LLM-HyPZ: Hardware Vulnerability Discovery using an LLM-Assisted Hybrid Platform for Zero-Shot Knowledge Extraction and Refinement",
      "title_zh": "LLM-HyPZï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹è¾…åŠ©æ··åˆå¹³å°çš„é›¶æ ·æœ¬çŸ¥è¯†æŠ½å–ä¸ç²¾ç‚¼ç¡¬ä»¶æ¼æ´å‘ç°",
      "authors": [
        "Yu-Zheng Lin",
        "Sujan Ghimire",
        "Abhiram Nandimandalam",
        "Jonah Michael Camacho",
        "Unnati Tripathi",
        "Rony Macwan",
        "Sicong Shao",
        "Setareh Rafatirad",
        "Rozhin Yasaei",
        "Pratik Satam",
        "Soheil Salehi"
      ],
      "abstract": "The rapid growth of hardware vulnerabilities has created an urgent need for systematic and scalable analysis methods. Unlike software flaws, which are often patchable post-deployment, hardware weaknesses remain embedded across product lifecycles, posing persistent risks to processors, embedded devices, and IoT platforms. Existing efforts such as the MITRE CWE Hardware List (2021) relied on expert-driven Delphi surveys, which lack statistical rigor and introduce subjective bias, while large-scale data-driven foundations for hardware weaknesses have been largely absent. In this work, we propose LLM-HyPZ, an LLM-assisted hybrid framework for zero-shot knowledge extraction and refinement from vulnerability corpora. Our approach integrates zero-shot LLM classification, contextualized embeddings, unsupervised clustering, and prompt-driven summarization to mine hardware-related CVEs at scale. Applying LLM-HyPZ to the 2021-2024 CVE corpus (114,836 entries), we identified 1,742 hardware-related vulnerabilities. We distilled them into five recurring themes, including privilege escalation via firmware and BIOS, memory corruption in mobile and IoT systems, and physical access exploits. Benchmarking across seven LLMs shows that LLaMA 3.3 70B achieves near-perfect classification accuracy (99.5%) on a curated validation set. Beyond methodological contributions, our framework directly supported the MITRE CWE Most Important Hardware Weaknesses (MIHW) 2025 update by narrowing the candidate search space. Specifically, our pipeline surfaced 411 of the 1,026 CVEs used for downstream MIHW analysis, thereby reducing expert workload and accelerating evidence gathering. These results establish LLM-HyPZ as the first data-driven, scalable approach for systematically discovering hardware vulnerabilities, thereby bridging the gap between expert knowledge and real-world vulnerability evidence.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LLM-HyPZï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾…åŠ©çš„æ··åˆå¹³å°ï¼Œæ—¨åœ¨é€šè¿‡é›¶æ ·æœ¬çŸ¥è¯†æå–ï¼ˆZero-Shot Knowledge Extractionï¼‰å’Œç»†åŒ–æŠ€æœ¯å®ç°ç¡¬ä»¶æ¼æ´çš„ç³»ç»ŸåŒ–ä¸å¯æ‰©å±•åˆ†æã€‚è¯¥æ¡†æ¶æ•´åˆäº†é›¶æ ·æœ¬åˆ†ç±»ã€ä¸Šä¸‹æ–‡åµŒå…¥ï¼ˆContextualized Embeddingsï¼‰ã€æ— ç›‘ç£èšç±»å’Œæç¤ºé©±åŠ¨æ€»ç»“ç­‰æŠ€æœ¯ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿç¡¬ä»¶å¼±ç‚¹åˆ†æè¿‡åº¦ä¾èµ–ä¸“å®¶ä¸»è§‚ç»éªŒçš„é—®é¢˜ã€‚é€šè¿‡å¯¹ 2021-2024 å¹´è¶…è¿‡ 11 ä¸‡æ¡ CVE æ•°æ®çš„æŒ–æ˜ï¼Œè¯¥ç³»ç»ŸæˆåŠŸè¯†åˆ«å‡º 1,742 ä¸ªç¡¬ä»¶ç›¸å…³æ¼æ´ï¼Œå¹¶å°†å…¶å½’çº³ä¸ºå›ºä»¶æƒé™æå‡å’Œç‰©ç†è®¿é—®åˆ©ç”¨ç­‰äº”ä¸ªæ ¸å¿ƒä¸»é¢˜ã€‚åŸºå‡†æµ‹è¯•è¡¨æ˜ï¼ŒLLaMA 3.3 70B åœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº† 99.5% çš„æé«˜å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼ŒLLM-HyPZ å·²ç›´æ¥åº”ç”¨äº MITRE CWE 2025 å¹´åº¦é‡è¦ç¡¬ä»¶å¼±ç‚¹ï¼ˆMIHWï¼‰çš„æ›´æ–°å·¥ä½œï¼Œä¸ºå…¶æä¾›äº†å…³é”®çš„ä¸‹æ¸¸åˆ†ææ ·æœ¬å¹¶æ˜¾è‘—é™ä½äº†ä¸“å®¶å·¥ä½œé‡ã€‚ä½œä¸ºé¦–ä¸ªæ•°æ®é©±åŠ¨çš„ç¡¬ä»¶æ¼æ´å‘ç°æ–¹æ¡ˆï¼Œè¯¥ç ”ç©¶æˆåŠŸå¼¥è¡¥äº†ä¸“å®¶çŸ¥è¯†ä¸ç°å®ä¸–ç•Œæ¼æ´è¯æ®ä¹‹é—´çš„ç©ºç™½ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00647v1",
      "published_date": "2025-08-31 00:55:31 UTC",
      "updated_date": "2025-08-31 00:55:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:46:51.295001+00:00"
    },
    {
      "arxiv_id": "2509.00646v1",
      "title": "RAG-PRISM: A Personalized, Rapid, and Immersive Skill Mastery Framework with Adaptive Retrieval-Augmented Tutoring",
      "title_zh": "RAG-PRISMï¼šåŸºäºè‡ªé€‚åº”æ£€ç´¢å¢å¼ºè¾…å¯¼çš„ä¸ªæ€§åŒ–ã€å¿«é€Ÿä¸”æ²‰æµ¸å¼æŠ€èƒ½æŒæ¡æ¡†æ¶",
      "authors": [
        "Gaurangi Raul",
        "Yu-Zheng Lin",
        "Karan Patel",
        "Bono Po-Jen Shih",
        "Matthew W. Redondo",
        "Banafsheh Saber Latibari",
        "Jesus Pacheco",
        "Soheil Salehi",
        "Pratik Satam"
      ],
      "abstract": "The rapid digital transformation of Fourth Industrial Revolution (4IR) systems is reshaping workforce needs, widening skill gaps, especially for older workers. With growing emphasis on STEM skills such as robotics, automation, artificial intelligence (AI), and security, large-scale re-skilling and up-skilling are required. Training programs must address diverse backgrounds, learning styles, and motivations to improve persistence and success, while ensuring rapid, cost-effective workforce development through experiential learning. To meet these challenges, we present an adaptive tutoring framework that combines generative AI with Retrieval-Augmented Generation (RAG) to deliver personalized training. The framework leverages document hit rate and Mean Reciprocal Rank (MRR) to optimize content for each learner, and is benchmarked against human-generated training for alignment and relevance. We demonstrate the framework in 4IR cybersecurity learning by creating a synthetic QA dataset emulating trainee behavior, while RAG is tuned on curated cybersecurity materials. Evaluation compares its generated training with manually curated queries representing realistic student interactions. Responses are produced using large language models (LLMs) including GPT-3.5 and GPT-4, assessed for faithfulness and content alignment. GPT-4 achieves the best performance with 87% relevancy and 100% alignment. Results show this dual-mode approach enables the adaptive tutor to act as both a personalized topic recommender and content generator, offering a scalable solution for rapid, tailored learning in 4IR education and workforce development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RAG-PRISMï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³ç¬¬å››æ¬¡å·¥ä¸šé©å‘½ï¼ˆ4IRï¼‰èƒŒæ™¯ä¸‹åŠ³åŠ¨åŠ›æŠ€èƒ½ç¼ºå£ï¼Œç‰¹åˆ«æ˜¯STEMé¢†åŸŸå¤§è§„æ¨¡é‡æ–°åŸ¹è®­éœ€æ±‚çš„ä¸ªæ€§åŒ–ã€å¿«é€Ÿä¸”æ²‰æµ¸å¼çš„æŠ€èƒ½æŒæ¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generation, RAGï¼‰æŠ€æœ¯ï¼Œé€šè¿‡è‡ªé€‚åº”è¾…å¯¼ç³»ç»Ÿæä¾›é«˜åº¦å®šåˆ¶åŒ–çš„åŸ¹è®­å†…å®¹ã€‚ä¸ºäº†ä¼˜åŒ–å­¦ä¹ ä½“éªŒï¼ŒRAG-PRISMåˆ©ç”¨æ–‡æ¡£å‘½ä¸­ç‡ï¼ˆDocument hit rateï¼‰å’Œå¹³å‡å€’æ•°æ’åï¼ˆMean Reciprocal Rank, MRRï¼‰å¯¹å†…å®¹è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ä¸åŒå­¦ä¹ è€…çš„èƒŒæ™¯å’ŒåŠ¨æœºã€‚åœ¨ç½‘ç»œå®‰å…¨ï¼ˆCybersecurityï¼‰æ•™å­¦åœºæ™¯çš„è¯„ä¼°ä¸­ï¼Œå®éªŒå¯¹æ¯”äº†GPT-3.5å’ŒGPT-4ç­‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¡¨ç°ï¼Œå…¶ä¸­GPT-4å®ç°äº†87%çš„ç›¸å…³æ€§ï¼ˆRelevancyï¼‰å’Œ100%çš„ä¸€è‡´æ€§ï¼ˆAlignmentï¼‰ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™ç§åŒæ¨¡å¼æ–¹æ³•èƒ½å¤Ÿè®©ç³»ç»ŸåŒæ—¶æ‹…ä»»ä¸ªæ€§åŒ–ä¸»é¢˜æ¨èå™¨å’Œå†…å®¹ç”Ÿæˆå™¨ï¼Œä¸ºå·¥ä¸šé¢†åŸŸçš„åŠ³åŠ¨åŠ›å¼€å‘æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„è‡ªé€‚åº”å­¦ä¹ è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages, 5 figures, Accepted by IEEE FIE 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.00646v1",
      "published_date": "2025-08-31 00:54:57 UTC",
      "updated_date": "2025-08-31 00:54:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:47:22.148960+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 86,
  "processed_papers_count": 86,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T15:48:11.426968+00:00"
}