[
  {
    "arxiv_id": "2407.03545v2",
    "title": "On Evaluating Explanation Utility for Human-AI Decision Making in NLP",
    "authors": [
      "Fateme Hashemi Chaleshtori",
      "Atreya Ghosal",
      "Alexander Gill",
      "Purbid Bambroo",
      "Ana Marasović"
    ],
    "abstract": "Is explainability a false promise? This debate has emerged from the\ninsufficient evidence that explanations help people in situations they are\nintroduced for. More human-centered, application-grounded evaluations of\nexplanations are needed to settle this. Yet, with no established guidelines for\nsuch studies in NLP, researchers accustomed to standardized proxy evaluations\nmust discover appropriate measurements, tasks, datasets, and sensible models\nfor human-AI teams in their studies.\n  To aid with this, we first review existing metrics suitable for\napplication-grounded evaluation. We then establish criteria to select\nappropriate datasets, and using them, we find that only 4 out of over 50\ndatasets available for explainability research in NLP meet them. We then\ndemonstrate the importance of reassessing the state of the art to form and\nstudy human-AI teams: teaming people with models for certain tasks might only\nnow start to make sense, and for others, it remains unsound. Finally, we\npresent the exemplar studies of human-AI decision-making for one of the\nidentified tasks -- verifying the correctness of a legal claim given a\ncontract. Our results show that providing AI predictions, with or without\nexplanations, does not cause decision makers to speed up their work without\ncompromising performance. We argue for revisiting the setup of human-AI teams\nand improving automatic deferral of instances to AI, where explanations could\nplay a useful role.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Findings 2024; 10 pages main, 7 pages references, 32 pages\n  appendix",
    "pdf_url": "http://arxiv.org/pdf/2407.03545v2",
    "published_date": "2024-07-03 23:53:27 UTC",
    "updated_date": "2024-11-05 01:38:45 UTC"
  },
  {
    "arxiv_id": "2407.12836v1",
    "title": "OSPC: Artificial VLM Features for Hateful Meme Detection",
    "authors": [
      "Peter Grönquist"
    ],
    "abstract": "The digital revolution and the advent of the world wide web have transformed\nhuman communication, notably through the emergence of memes. While memes are a\npopular and straightforward form of expression, they can also be used to spread\nmisinformation and hate due to their anonymity and ease of use. In response to\nthese challenges, this paper introduces a solution developed by team 'Baseline'\nfor the AI Singapore Online Safety Prize Challenge. Focusing on computational\nefficiency and feature engineering, the solution achieved an AUROC of 0.76 and\nan accuracy of 0.69 on the test dataset. As key features, the solution\nleverages the inherent probabilistic capabilities of large Vision-Language\nModels (VLMs) to generate task-adapted feature encodings from text, and applies\na distilled quantization tailored to the specific cultural nuances present in\nSingapore. This type of processing and fine-tuning can be adapted to various\nvisual and textual understanding and classification tasks, and even applied on\nprivate VLMs such as OpenAI's GPT. Finally it can eliminate the need for\nextensive model training on large GPUs for resource constrained applications,\nalso offering a solution when little or no data is available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12836v1",
    "published_date": "2024-07-03 21:35:52 UTC",
    "updated_date": "2024-07-03 21:35:52 UTC"
  },
  {
    "arxiv_id": "2407.03518v4",
    "title": "Improving LLM Abilities in Idiomatic Translation",
    "authors": [
      "Sundesh Donthi",
      "Maximilian Spencer",
      "Om Patel",
      "Joon Doh",
      "Eid Rodan",
      "Kevin Zhu",
      "Sean O'Brien"
    ],
    "abstract": "For large language models (LLMs) like NLLB and GPT, translating idioms\nremains a challenge. Our goal is to enhance translation fidelity by improving\nLLM processing of idiomatic language while preserving the original linguistic\nstyle. This has a significant social impact, as it preserves cultural nuances\nand ensures translated texts retain their intent and emotional resonance,\nfostering better cross-cultural communication. Previous work has utilized\nknowledge bases like IdiomKB by providing the LLM with the meaning of an idiom\nto use in translation. Although this method yielded better results than a\ndirect translation, it is still limited in its ability to preserve idiomatic\nwriting style across languages. In this research, we expand upon the knowledge\nbase to find corresponding idioms in the target language. Our research performs\ntranslations using two methods: The first method employs the\nSentenceTransformers model to semantically generate cosine similarity scores\nbetween the meanings of the original and target language idioms, selecting the\nbest idiom (Cosine Similarity method). The second method uses an LLM to find a\ncorresponding idiom in the target language for use in the translation\n(LLM-generated idiom method). As a baseline, we performed a direct translation\nwithout providing additional information. Human evaluations on the English ->\nChinese, and Chinese -> English show the Cosine Similarity Lookup method\nout-performed others in all GPT4o translations. To further build upon IdiomKB,\nwe developed a low-resource Urdu dataset containing Urdu idioms and their\ntranslations. Despite dataset limitations, the Cosine Similarity Lookup method\nshows promise, potentially overcoming language barriers and enabling the\nexploration of diverse literary works in Chinese and Urdu.(LoResLM @ COLING\nPreprint)",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint for LoResLM Workshop at COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.03518v4",
    "published_date": "2024-07-03 21:34:26 UTC",
    "updated_date": "2025-01-23 04:04:22 UTC"
  },
  {
    "arxiv_id": "2407.03514v1",
    "title": "Towards Attention-based Contrastive Learning for Audio Spoof Detection",
    "authors": [
      "Chirag Goel",
      "Surya Koppisetti",
      "Ben Colman",
      "Ali Shahriyari",
      "Gaurav Bharaj"
    ],
    "abstract": "Vision transformers (ViT) have made substantial progress for classification\ntasks in computer vision. Recently, Gong et. al. '21, introduced\nattention-based modeling for several audio tasks. However, relatively\nunexplored is the use of a ViT for audio spoof detection task. We bridge this\ngap and introduce ViTs for this task. A vanilla baseline built on fine-tuning\nthe SSAST (Gong et. al. '22) audio ViT model achieves sub-optimal equal error\nrates (EERs). To improve performance, we propose a novel attention-based\ncontrastive learning framework (SSAST-CL) that uses cross-attention to aid the\nrepresentation learning. Experiments show that our framework successfully\ndisentangles the bonafide and spoof classes and helps learn better classifiers\nfor the task. With appropriate data augmentations policy, a model trained on\nour framework achieves competitive performance on the ASVSpoof 2021 challenge.\nWe provide comparisons and ablation studies to justify our claim.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Proc. INTERSPEECH 2023",
    "pdf_url": "http://arxiv.org/pdf/2407.03514v1",
    "published_date": "2024-07-03 21:25:12 UTC",
    "updated_date": "2024-07-03 21:25:12 UTC"
  },
  {
    "arxiv_id": "2407.03506v1",
    "title": "AntibotV: A Multilevel Behaviour-based Framework for Botnets Detection in Vehicular Networks",
    "authors": [
      "Rabah Rahal",
      "Abdelaziz Amara Korba",
      "Nacira Ghoualmi-Zine",
      "Yacine Challal",
      "Mohamed Yacine Ghamri-Doudane"
    ],
    "abstract": "Connected cars offer safety and efficiency for both individuals and fleets of\nprivate vehicles and public transportation companies. However, equipping\nvehicles with information and communication technologies raises privacy and\nsecurity concerns, which significantly threaten the user's data and life. Using\nbot malware, a hacker may compromise a vehicle and control it remotely, for\ninstance, he can disable breaks or start the engine remotely. In this paper,\nbesides in-vehicle attacks existing in the literature, we consider new zeroday\nbot malware attacks specific to the vehicular context, WSMP-Flood, and Geo-WSMP\nFlood. Then, we propose AntibotV, a multilevel behaviour-based framework for\nvehicular botnets detection in vehicular networks. The proposed framework\ncombines two main modules for attack detection, the first one monitors the\nvehicle's activity at the network level, whereas the second one monitors the\nin-vehicle activity. The two intrusion detection modules have been trained on a\nhistorical network and in-vehicle communication using decision tree algorithms.\nThe experimental results showed that the proposed framework outperforms\nexisting solutions, it achieves a detection rate higher than 97% and a false\npositive rate lower than 0.14%.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03506v1",
    "published_date": "2024-07-03 21:07:49 UTC",
    "updated_date": "2024-07-03 21:07:49 UTC"
  },
  {
    "arxiv_id": "2407.03502v1",
    "title": "AgentInstruct: Toward Generative Teaching with Agentic Flows",
    "authors": [
      "Arindam Mitra",
      "Luciano Del Corro",
      "Guoqing Zheng",
      "Shweti Mahajan",
      "Dany Rouhana",
      "Andres Codas",
      "Yadong Lu",
      "Wei-ge Chen",
      "Olga Vrousgos",
      "Corby Rosset",
      "Fillipe Silva",
      "Hamed Khanpour",
      "Yash Lara",
      "Ahmed Awadallah"
    ],
    "abstract": "Synthetic data is becoming increasingly important for accelerating the\ndevelopment of language models, both large and small. Despite several\nsuccessful use cases, researchers also raised concerns around model collapse\nand drawbacks of imitating other models. This discrepancy can be attributed to\nthe fact that synthetic data varies in quality and diversity. Effective use of\nsynthetic data usually requires significant human effort in curating the data.\nWe focus on using synthetic data for post-training, specifically creating data\nby powerful models to teach a new skill or behavior to another model, we refer\nto this setting as Generative Teaching. We introduce AgentInstruct, an\nextensible agentic framework for automatically creating large amounts of\ndiverse and high-quality synthetic data. AgentInstruct can create both the\nprompts and responses, using only raw data sources like text documents and code\nfiles as seeds. We demonstrate the utility of AgentInstruct by creating a post\ntraining dataset of 25M pairs to teach language models different skills, such\nas text editing, creative writing, tool usage, coding, reading comprehension,\netc. The dataset can be used for instruction tuning of any base model. We\npost-train Mistral-7b with the data. When comparing the resulting model Orca-3\nto Mistral-7b-Instruct (which uses the same base model), we observe significant\nimprovements across many benchmarks. For example, 40% improvement on AGIEval,\n19% improvement on MMLU, 54% improvement on GSM8K, 38% improvement on BBH and\n45% improvement on AlpacaEval. Additionally, it consistently outperforms other\nmodels such as LLAMA-8B-instruct and GPT-3.5-turbo.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03502v1",
    "published_date": "2024-07-03 21:01:12 UTC",
    "updated_date": "2024-07-03 21:01:12 UTC"
  },
  {
    "arxiv_id": "2407.03482v2",
    "title": "Domain-Aware Fine-Tuning of Foundation Models",
    "authors": [
      "Ugur Ali Kaplan",
      "Margret Keuper",
      "Anna Khoreva",
      "Dan Zhang",
      "Yumeng Li"
    ],
    "abstract": "Foundation models (FMs) have revolutionized computer vision, enabling\neffective learning across different domains. However, their performance under\ndomain shift is yet underexplored. This paper investigates the zero-shot domain\nadaptation potential of FMs by comparing different backbone architectures and\nintroducing novel domain-aware components that leverage domain related textual\nembeddings. We propose domain adaptive normalization, termed as Domino, which\nexplicitly leverages domain embeddings during fine-tuning, thus making the\nmodel domain aware. Ultimately, Domino enables more robust computer vision\nmodels that can adapt effectively to various unseen domains.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICML 2024 Workshop on Foundation Models in the Wild",
    "pdf_url": "http://arxiv.org/pdf/2407.03482v2",
    "published_date": "2024-07-03 20:10:55 UTC",
    "updated_date": "2024-07-10 13:27:20 UTC"
  },
  {
    "arxiv_id": "2407.03473v1",
    "title": "Exploring LGBTQ+ Bias in Generative AI Answers across Different Country and Religious Contexts",
    "authors": [
      "Lilla Vicsek",
      "Anna Vancsó",
      "Mike Zajko",
      "Judit Takacs"
    ],
    "abstract": "Previous discussions have highlighted the need for generative AI tools to\nbecome more culturally sensitive, yet often neglect the complexities of\nhandling content about minorities, who are perceived differently across\ncultures and religions. Our study examined how two generative AI systems\nrespond to homophobic statements with varying cultural and religious context\ninformation. Findings showed ChatGPT 3.5's replies exhibited cultural\nrelativism, in contrast to Bard's, which stressed human rights and provided\nmore support for LGBTQ+ issues. Both demonstrated significant change in\nresponses based on contextual information provided in the prompts, suggesting\nthat AI systems may adjust in their responses the degree and forms of support\nfor LGBTQ+ people according to information they receive about the user's\nbackground. The study contributes to understanding the social and ethical\nimplications of AI responses and argues that any work to make generative AI\noutputs more culturally diverse requires a grounding in fundamental human\nrights.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03473v1",
    "published_date": "2024-07-03 19:38:19 UTC",
    "updated_date": "2024-07-03 19:38:19 UTC"
  },
  {
    "arxiv_id": "2407.03469v1",
    "title": "Scaling Data-Driven Building Energy Modelling using Large Language Models",
    "authors": [
      "Sunil Khadka",
      "Liang Zhang"
    ],
    "abstract": "Building Management System (BMS) through a data-driven method always faces\ndata and model scalability issues. We propose a methodology to tackle the\nscalability challenges associated with the development of data-driven models\nfor BMS by using Large Language Models (LLMs). LLMs' code generation\nadaptability can enable broader adoption of BMS by \"automating the automation,\"\nparticularly the data handling and data-driven modeling processes. In this\npaper, we use LLMs to generate code that processes structured data from BMS and\nbuild data-driven models for BMS's specific requirements. This eliminates the\nneed for manual data and model development, reducing the time, effort, and cost\nassociated with this process. Our hypothesis is that LLMs can incorporate\ndomain knowledge about data science and BMS into data processing and modeling,\nensuring that the data-driven modeling is automated for specific requirements\nof different building types and control objectives, which also improves\naccuracy and scalability. We generate a prompt template following the framework\nof Machine Learning Operations so that the prompts are designed to\nsystematically generate Python code for data-driven modeling. Our case study\nindicates that bi-sequential prompting under the prompt template can achieve a\nhigh success rate of code generation and code accuracy, and significantly\nreduce human labor costs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03469v1",
    "published_date": "2024-07-03 19:34:24 UTC",
    "updated_date": "2024-07-03 19:34:24 UTC"
  },
  {
    "arxiv_id": "2407.03463v1",
    "title": "Precision at Scale: Domain-Specific Datasets On-Demand",
    "authors": [
      "Jesús M Rodríguez-de-Vera",
      "Imanol G Estepa",
      "Ignacio Sarasúa",
      "Bhalaji Nagarajan",
      "Petia Radeva"
    ],
    "abstract": "In the realm of self-supervised learning (SSL), conventional wisdom has\ngravitated towards the utility of massive, general domain datasets for\npretraining robust backbones. In this paper, we challenge this idea by\nexploring if it is possible to bridge the scale between general-domain datasets\nand (traditionally smaller) domain-specific datasets to reduce the current\nperformance gap. More specifically, we propose Precision at Scale (PaS), a\nnovel method for the autonomous creation of domain-specific datasets on-demand.\nThe modularity of the PaS pipeline enables leveraging state-of-the-art\nfoundational and generative models to create a collection of images of any\ngiven size belonging to any given domain with minimal human intervention.\nExtensive analysis in two complex domains, proves the superiority of PaS\ndatasets over existing traditional domain-specific datasets in terms of\ndiversity, scale, and effectiveness in training visual transformers and\nconvolutional neural networks. Most notably, we prove that automatically\ngenerated domain-specific datasets lead to better pretraining than large-scale\nsupervised datasets such as ImageNet-1k and ImageNet-21k. Concretely, models\ntrained on domain-specific datasets constructed by PaS pipeline, beat\nImageNet-1k pretrained backbones by at least 12% in all the considered domains\nand classification tasks and lead to better food domain performance than\nsupervised ImageNet-21k pretrain while being 12 times smaller. Code repository:\nhttps://github.com/jesusmolrdv/Precision-at-Scale/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.5.4; I.5.2; I.2.1; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03463v1",
    "published_date": "2024-07-03 19:17:42 UTC",
    "updated_date": "2024-07-03 19:17:42 UTC"
  },
  {
    "arxiv_id": "2407.03460v1",
    "title": "Collaborative Quest Completion with LLM-driven Non-Player Characters in Minecraft",
    "authors": [
      "Sudha Rao",
      "Weijia Xu",
      "Michael Xu",
      "Jorge Leandro",
      "Ken Lobb",
      "Gabriel DesGarennes",
      "Chris Brockett",
      "Bill Dolan"
    ],
    "abstract": "The use of generative AI in video game development is on the rise, and as the\nconversational and other capabilities of large language models continue to\nimprove, we expect LLM-driven non-player characters (NPCs) to become widely\ndeployed. In this paper, we seek to understand how human players collaborate\nwith LLM-driven NPCs to accomplish in-game goals. We design a minigame within\nMinecraft where a player works with two GPT4-driven NPCs to complete a quest.\nWe perform a user study in which 28 Minecraft players play this minigame and\nshare their feedback. On analyzing the game logs and recordings, we find that\nseveral patterns of collaborative behavior emerge from the NPCs and the human\nplayers. We also report on the current limitations of language-only models that\ndo not have rich game-state or visual understanding. We believe that this\npreliminary study and analysis will inform future game developers on how to\nbetter exploit these rapidly improving generative AI models for collaborative\nroles in games.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Wordplay workshop at ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.03460v1",
    "published_date": "2024-07-03 19:11:21 UTC",
    "updated_date": "2024-07-03 19:11:21 UTC"
  },
  {
    "arxiv_id": "2407.03446v1",
    "title": "Towards Asimov's Psychohistory: Harnessing Topological Data Analysis, Artificial Intelligence and Social Media data to Forecast Societal Trends",
    "authors": [
      "Isabela Rocha"
    ],
    "abstract": "In the age of big data and advanced computational methods, the prediction of\nlarge-scale social behaviors, reminiscent of Isaac Asimov's fictional science\nof Psychohistory, is becoming increasingly feasible. This paper consists of a\ntheoretical exploration of the integration of computational power and\nmathematical frameworks, particularly through Topological Data Analysis (TDA)\n(Carlsson, Vejdemo-Johansson, 2022) and Artificial Intelligence (AI), to\nforecast societal trends through social media data analysis. By examining\nsocial media as a reflective surface of collective human behavior through the\nsystematic behaviorist approach (Glenn, et al., 2016), I argue that these tools\nprovide unprecedented clarity into the dynamics of large communities. This\nstudy dialogues with Asimov's work, drawing parallels between his visionary\nconcepts and contemporary methodologies, illustrating how modern computational\ntechniques can uncover patterns and predict shifts in social behavior,\ncontributing to the emerging field of digital sociology -- or even,\nPsychohistory itself.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CY",
    "comment": "21 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03446v1",
    "published_date": "2024-07-03 18:44:36 UTC",
    "updated_date": "2024-07-03 18:44:36 UTC"
  },
  {
    "arxiv_id": "2407.12835v2",
    "title": "Regurgitative Training: The Value of Real Data in Training Large Language Models",
    "authors": [
      "Jinghui Zhang",
      "Dandan Qiao",
      "Mochen Yang",
      "Qiang Wei"
    ],
    "abstract": "What happens if we train a new Large Language Model (LLM) using data that are\nat least partially generated by other LLMs? The explosive success of LLMs means\nthat a substantial amount of content online will be generated by LLMs rather\nthan humans, which will inevitably enter the training datasets of\nnext-generation LLMs. We evaluate the implications of such \"regurgitative\ntraining\" on LLM performance. Through fine-tuning GPT-3.5 with data generated\neither by itself or by other LLMs in a machine translation task, we find strong\nevidence that regurgitative training clearly handicaps the performance of LLMs.\nThe same performance loss of regurgitative training is observed on transformer\nmodels that we train from scratch. We find suggestive evidence that the\nperformance disadvantage of regurgitative training can be attributed to at\nleast two mechanisms: (1) higher error rates and (2) lower lexical diversity in\nLLM-generated data as compared to real data. Based on these mechanisms, we\npropose and evaluate three different strategies to mitigate the performance\nloss of regurgitative training. First, we devise data-driven metrics to gauge\nthe quality of each LLM-generated data instance, and then carry out an ordered\ntraining process where high-quality data are added before low-quality ones.\nSecond, we combine data generated by multiple different LLMs (as an attempt to\nincrease lexical diversity). Third, we train an AI detection classifier to\ndifferentiate between LLM- and human-generated data, and include LLM-generated\ndata in the order of resemblance to human-generated data. All three strategies\ncan improve the performance of regurgitative training to some extent but are\nnot always able to fully close the gap from training with real data. Our\nresults highlight the value of real, human-generated data in training LLMs,\nwhich cannot be easily substituted by synthetic, LLM-generated data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12835v2",
    "published_date": "2024-07-03 18:42:55 UTC",
    "updated_date": "2024-07-25 16:50:58 UTC"
  },
  {
    "arxiv_id": "2407.11030v1",
    "title": "DLO: Dynamic Layer Operation for Efficient Vertical Scaling of LLMs",
    "authors": [
      "Zhen Tan",
      "Daize Dong",
      "Xinyu Zhao",
      "Jie Peng",
      "Yu Cheng",
      "Tianlong Chen"
    ],
    "abstract": "In this paper, we introduce Dynamic Layer Operations (DLO), a novel approach\nfor vertically scaling transformer-based Large Language Models (LLMs) by\ndynamically expanding, activating, or skipping layers using a sophisticated\nrouting policy based on layerwise feature similarity. Unlike traditional\nMixture-of-Experts (MoE) methods that focus on extending the model width, our\napproach targets model depth, addressing the redundancy observed across layer\nrepresentations for various input samples. Our framework is integrated with the\nSupervised Fine-Tuning (SFT) stage, eliminating the need for resource-intensive\nContinual Pre-Training (CPT). Experimental results demonstrate that DLO not\nonly outperforms the original unscaled models but also achieves comparable\nresults to densely expanded models with significantly improved efficiency. Our\nwork offers a promising direction for building efficient yet powerful LLMs. We\nwill release our implementation and model weights upon acceptance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11030v1",
    "published_date": "2024-07-03 18:34:08 UTC",
    "updated_date": "2024-07-03 18:34:08 UTC"
  },
  {
    "arxiv_id": "2407.15851v2",
    "title": "A Survey on Trustworthiness in Foundation Models for Medical Image Analysis",
    "authors": [
      "Congzhen Shi",
      "Ryan Rezai",
      "Jiaxi Yang",
      "Qi Dou",
      "Xiaoxiao Li"
    ],
    "abstract": "The rapid advancement of foundation models in medical imaging represents a\nsignificant leap toward enhancing diagnostic accuracy and personalized\ntreatment. However, the deployment of foundation models in healthcare\nnecessitates a rigorous examination of their trustworthiness, encompassing\nprivacy, robustness, reliability, explainability, and fairness. The current\nbody of survey literature on foundation models in medical imaging reveals\nconsiderable gaps, particularly in the area of trustworthiness. Additionally,\nexisting surveys on the trustworthiness of foundation models do not adequately\naddress their specific variations and applications within the medical imaging\ndomain. This survey aims to fill that gap by presenting a novel taxonomy of\nfoundation models used in medical imaging and analyzing the key motivations for\nensuring their trustworthiness. We review current research on foundation models\nin major medical imaging applications, focusing on segmentation, medical report\ngeneration, medical question and answering (Q\\&A), and disease diagnosis. These\nareas are highlighted because they have seen a relatively mature and\nsubstantial number of foundation models compared to other applications. We\nfocus on literature that discusses trustworthiness in medical image analysis\nmanuscripts. We explore the complex challenges of building trustworthy\nfoundation models for each application, summarizing current concerns and\nstrategies for enhancing trustworthiness. Furthermore, we examine the potential\nof these models to revolutionize patient care. Our analysis underscores the\nimperative for advancing towards trustworthy AI in medical image analysis,\nadvocating for a balanced approach that fosters innovation while ensuring\nethical and equitable healthcare delivery.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15851v2",
    "published_date": "2024-07-03 18:07:57 UTC",
    "updated_date": "2024-10-07 02:03:30 UTC"
  },
  {
    "arxiv_id": "2407.03418v1",
    "title": "HEMM: Holistic Evaluation of Multimodal Foundation Models",
    "authors": [
      "Paul Pu Liang",
      "Akshay Goindani",
      "Talha Chafekar",
      "Leena Mathur",
      "Haofei Yu",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "abstract": "Multimodal foundation models that can holistically process text alongside\nimages, video, audio, and other sensory modalities are increasingly used in a\nvariety of real-world applications. However, it is challenging to characterize\nand study progress in multimodal foundation models, given the range of possible\nmodeling decisions, tasks, and domains. In this paper, we introduce Holistic\nEvaluation of Multimodal Models (HEMM) to systematically evaluate the\ncapabilities of multimodal foundation models across a set of 3 dimensions:\nbasic skills, information flow, and real-world use cases. Basic multimodal\nskills are internal abilities required to solve problems, such as learning\ninteractions across modalities, fine-grained alignment, multi-step reasoning,\nand the ability to handle external knowledge. Information flow studies how\nmultimodal content changes during a task through querying, translation,\nediting, and fusion. Use cases span domain-specific challenges introduced in\nreal-world multimedia, affective computing, natural sciences, healthcare, and\nhuman-computer interaction applications. Through comprehensive experiments\nacross the 30 tasks in HEMM, we (1) identify key dataset dimensions (e.g.,\nbasic skills, information flows, and use cases) that pose challenges to today's\nmodels, and (2) distill performance trends regarding how different modeling\ndimensions (e.g., scale, pre-training data, multimodal alignment, pre-training,\nand instruction tuning objectives) influence performance. Our conclusions\nregarding challenging multimodal interactions, use cases, and tasks requiring\nreasoning and external knowledge, the benefits of data and model scale, and the\nimpacts of instruction tuning yield actionable insights for future work in\nmultimodal foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Code available at https://github.com/pliang279/HEMM",
    "pdf_url": "http://arxiv.org/pdf/2407.03418v1",
    "published_date": "2024-07-03 18:00:48 UTC",
    "updated_date": "2024-07-03 18:00:48 UTC"
  },
  {
    "arxiv_id": "2407.17490v1",
    "title": "AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents",
    "authors": [
      "Yuxiang Chai",
      "Siyuan Huang",
      "Yazhe Niu",
      "Han Xiao",
      "Liang Liu",
      "Dingyu Zhang",
      "Peng Gao",
      "Shuai Ren",
      "Hongsheng Li"
    ],
    "abstract": "AI agents have drawn increasing attention mostly on their ability to perceive\nenvironments, understand tasks, and autonomously achieve goals. To advance\nresearch on AI agents in mobile scenarios, we introduce the Android\nMulti-annotation EXpo (AMEX), a comprehensive, large-scale dataset designed for\ngeneralist mobile GUI-control agents. Their capabilities of completing complex\ntasks by directly interacting with the graphical user interface (GUI) on mobile\ndevices are trained and evaluated with the proposed dataset. AMEX comprises\nover 104K high-resolution screenshots from 110 popular mobile applications,\nwhich are annotated at multiple levels. Unlike existing mobile device-control\ndatasets, e.g., MoTIF, AitW, etc., AMEX includes three levels of annotations:\nGUI interactive element grounding, GUI screen and element functionality\ndescriptions, and complex natural language instructions, each averaging 13\nsteps with stepwise GUI-action chains. We develop this dataset from a more\ninstructive and detailed perspective, complementing the general settings of\nexisting datasets. Additionally, we develop a baseline model SPHINX Agent and\ncompare its performance across state-of-the-art agents trained on other\ndatasets. To facilitate further research, we open-source our dataset, models,\nand relevant evaluation tools. The project is available at\nhttps://yuxiangchai.github.io/AMEX/",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17490v1",
    "published_date": "2024-07-03 17:59:58 UTC",
    "updated_date": "2024-07-03 17:59:58 UTC"
  },
  {
    "arxiv_id": "2407.03321v2",
    "title": "Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages",
    "authors": [
      "Max Zuo",
      "Francisco Piedrahita Velez",
      "Xiaochen Li",
      "Michael L. Littman",
      "Stephen H. Bach"
    ],
    "abstract": "Recent works have explored using language models for planning problems. One\napproach examines translating natural language descriptions of planning tasks\ninto structured planning languages, such as the planning domain definition\nlanguage (PDDL). Existing evaluation methods struggle to ensure semantic\ncorrectness and rely on simple or unrealistic datasets. To bridge this gap, we\nintroduce \\textit{Planetarium}, a benchmark designed to evaluate language\nmodels' ability to generate PDDL code from natural language descriptions of\nplanning tasks. \\textit{Planetarium} features a novel PDDL equivalence\nalgorithm that flexibly evaluates the correctness of generated PDDL, along with\na dataset of 145,918 text-to-PDDL pairs across 73 unique state combinations\nwith varying levels of difficulty. Finally, we evaluate several API-access and\nopen-weight language models that reveal this task's complexity. For example,\n96.1\\% of the PDDL problem descriptions generated by GPT-4o are syntactically\nparseable, 94.4\\% are solvable, but only 24.8\\% are semantically correct,\nhighlighting the need for a more rigorous benchmark for this problem.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL Main Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.03321v2",
    "published_date": "2024-07-03 17:59:53 UTC",
    "updated_date": "2025-02-10 19:05:03 UTC"
  },
  {
    "arxiv_id": "2407.03311v3",
    "title": "Efficient Imitation Without Demonstrations via Value-Penalized Auxiliary Control from Examples",
    "authors": [
      "Trevor Ablett",
      "Bryan Chan",
      "Jayce Haoran Wang",
      "Jonathan Kelly"
    ],
    "abstract": "Common approaches to providing feedback in reinforcement learning are the use\nof hand-crafted rewards or full-trajectory expert demonstrations.\nAlternatively, one can use examples of completed tasks, but such an approach\ncan be extremely sample inefficient. We introduce value-penalized auxiliary\ncontrol from examples (VPACE), an algorithm that significantly improves\nexploration in example-based control by adding examples of simple auxiliary\ntasks and an above-success-level value penalty. Across both simulated and real\nrobotic environments, we show that our approach substantially improves learning\nefficiency for challenging tasks, while maintaining bounded value estimates.\nPreliminary results also suggest that VPACE may learn more efficiently than the\nmore common approaches of using full trajectories or true sparse rewards.\nProject site: https://papers.starslab.ca/vpace/ .",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to the IEEE International Conference on Robotics and\n  Automation (ICRA'25), Atlanta, USA, May 19-23, 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.03311v3",
    "published_date": "2024-07-03 17:54:11 UTC",
    "updated_date": "2025-03-02 02:45:57 UTC"
  },
  {
    "arxiv_id": "2407.03308v1",
    "title": "Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method",
    "authors": [
      "Sijie Xu",
      "Shenyan Zong",
      "Chang-Sheng Mei",
      "Guofeng Shen",
      "Yueran Zhao",
      "He Wang"
    ],
    "abstract": "Proton resonance frequency (PRF) based MR thermometry is essential for\nfocused ultrasound (FUS) thermal ablation therapies. This work aims to enhance\ntemporal resolution in dynamic MR temperature map reconstruction using an\nimproved deep learning method. The training-optimized methods and five\nclassical neural networks were applied on the 2-fold and 4-fold under-sampling\nk-space data to reconstruct the temperature maps. The enhanced training modules\nincluded offline/online data augmentations, knowledge distillation, and the\namplitude-phase decoupling loss function. The heating experiments were\nperformed by a FUS transducer on phantom and ex vivo tissues, respectively.\nThese data were manually under-sampled to imitate acceleration procedures and\ntrained in our method to get the reconstruction model. The additional dozen or\nso testing datasets were separately obtained for evaluating the real-time\nperformance and temperature accuracy. Acceleration factors of 1.9 and 3.7 were\nfound for 2 times and 4 times k-space under-sampling strategies and the\nResUNet-based deep learning reconstruction performed exceptionally well. In\n2-fold acceleration scenario, the RMSE of temperature map patches provided the\nvalues of 0.888 degree centigrade and 1.145 degree centigrade on phantom and ex\nvivo testing datasets. The DICE value of temperature areas enclosed by 43\ndegree centigrade isotherm was 0.809, and the Bland-Altman analysis showed a\nbias of -0.253 degree centigrade with the apart of plus or minus 2.16 degree\ncentigrade. In 4 times under-sampling case, these evaluating values decreased\nby approximately 10%. This study demonstrates that deep learning-based\nreconstruction can significantly enhance the accuracy and efficiency of MR\nthermometry for clinical FUS thermal therapies.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03308v1",
    "published_date": "2024-07-03 17:49:38 UTC",
    "updated_date": "2024-07-03 17:49:38 UTC"
  },
  {
    "arxiv_id": "2407.03300v1",
    "title": "DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents",
    "authors": [
      "Yilun Xu",
      "Gabriele Corso",
      "Tommi Jaakkola",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "abstract": "Diffusion models (DMs) have revolutionized generative learning. They utilize\na diffusion process to encode data into a simple Gaussian distribution.\nHowever, encoding a complex, potentially multimodal data distribution into a\nsingle continuous Gaussian distribution arguably represents an unnecessarily\nchallenging learning problem. We propose Discrete-Continuous Latent Variable\nDiffusion Models (DisCo-Diff) to simplify this task by introducing\ncomplementary discrete latent variables. We augment DMs with learnable discrete\nlatents, inferred with an encoder, and train DM and encoder end-to-end.\nDisCo-Diff does not rely on pre-trained networks, making the framework\nuniversally applicable. The discrete latents significantly simplify learning\nthe DM's complex noise-to-data mapping by reducing the curvature of the DM's\ngenerative ODE. An additional autoregressive transformer models the\ndistribution of the discrete latents, a simple step because DisCo-Diff requires\nonly few discrete variables with small codebooks. We validate DisCo-Diff on toy\ndata, several image synthesis tasks as well as molecular docking, and find that\nintroducing discrete latents consistently improves model performance. For\nexample, DisCo-Diff achieves state-of-the-art FID scores on class-conditioned\nImageNet-64/128 datasets with ODE sampler.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "project page: https://research.nvidia.com/labs/lpr/disco-diff",
    "pdf_url": "http://arxiv.org/pdf/2407.03300v1",
    "published_date": "2024-07-03 17:42:46 UTC",
    "updated_date": "2024-07-03 17:42:46 UTC"
  },
  {
    "arxiv_id": "2407.03297v2",
    "title": "Improved Noise Schedule for Diffusion Training",
    "authors": [
      "Tiankai Hang",
      "Shuyang Gu",
      "Xin Geng",
      "Baining Guo"
    ],
    "abstract": "Diffusion models have emerged as the de facto choice for generating\nhigh-quality visual signals across various domains. However, training a single\nmodel to predict noise across various levels poses significant challenges,\nnecessitating numerous iterations and incurring significant computational\ncosts. Various approaches, such as loss weighting strategy design and\narchitectural refinements, have been introduced to expedite convergence and\nimprove model performance. In this study, we propose a novel approach to design\nthe noise schedule for enhancing the training of diffusion models. Our key\ninsight is that the importance sampling of the logarithm of the Signal-to-Noise\nratio ($\\log \\text{SNR}$), theoretically equivalent to a modified noise\nschedule, is particularly beneficial for training efficiency when increasing\nthe sample frequency around $\\log \\text{SNR}=0$. This strategic sampling allows\nthe model to focus on the critical transition point between signal dominance\nand noise dominance, potentially leading to more robust and accurate\npredictions.We empirically demonstrate the superiority of our noise schedule\nover the standard cosine schedule.Furthermore, we highlight the advantages of\nour noise schedule design on the ImageNet benchmark, showing that the designed\nschedule consistently benefits different prediction targets. Our findings\ncontribute to the ongoing efforts to optimize diffusion models, potentially\npaving the way for more efficient and effective training paradigms in the field\nof generative AI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03297v2",
    "published_date": "2024-07-03 17:34:55 UTC",
    "updated_date": "2024-11-27 15:10:12 UTC"
  },
  {
    "arxiv_id": "2407.03291v2",
    "title": "VCHAR:Variance-Driven Complex Human Activity Recognition framework with Generative Representation",
    "authors": [
      "Yuan Sun",
      "Navid Salami Pargoo",
      "Taqiya Ehsan",
      "Zhao Zhang",
      "Jorge Ortiz"
    ],
    "abstract": "Complex human activity recognition (CHAR) remains a pivotal challenge within\nubiquitous computing, especially in the context of smart environments. Existing\nstudies typically require meticulous labeling of both atomic and complex\nactivities, a task that is labor-intensive and prone to errors due to the\nscarcity and inaccuracies of available datasets. Most prior research has\nfocused on datasets that either precisely label atomic activities or, at\nminimum, their sequence approaches that are often impractical in real world\nsettings.In response, we introduce VCHAR (Variance-Driven Complex Human\nActivity Recognition), a novel framework that treats the outputs of atomic\nactivities as a distribution over specified intervals. Leveraging generative\nmethodologies, VCHAR elucidates the reasoning behind complex activity\nclassifications through video-based explanations, accessible to users without\nprior machine learning expertise. Our evaluation across three publicly\navailable datasets demonstrates that VCHAR enhances the accuracy of complex\nactivity recognition without necessitating precise temporal or sequential\nlabeling of atomic activities. Furthermore, user studies confirm that VCHAR's\nexplanations are more intelligible compared to existing methods, facilitating a\nbroader understanding of complex activity recognition among non-experts.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03291v2",
    "published_date": "2024-07-03 17:24:36 UTC",
    "updated_date": "2024-08-06 15:14:01 UTC"
  },
  {
    "arxiv_id": "2407.03266v1",
    "title": "Do Quantum Neural Networks have Simplicity Bias?",
    "authors": [
      "Jessica Pointing"
    ],
    "abstract": "One hypothesis for the success of deep neural networks (DNNs) is that they\nare highly expressive, which enables them to be applied to many problems, and\nthey have a strong inductive bias towards solutions that are simple, known as\nsimplicity bias, which allows them to generalise well on unseen data because\nmost real-world data is structured (i.e. simple). In this work, we explore the\ninductive bias and expressivity of quantum neural networks (QNNs), which gives\nus a way to compare their performance to those of DNNs. Our results show that\nit is possible to have simplicity bias with certain QNNs, but we prove that\nthis type of QNN limits the expressivity of the QNN. We also show that it is\npossible to have QNNs with high expressivity, but they either have no inductive\nbias or a poor inductive bias and result in a worse generalisation performance\ncompared to DNNs. We demonstrate that an artificial (restricted) inductive bias\ncan be produced by intentionally restricting the expressivity of a QNN. Our\nresults suggest a bias-expressivity tradeoff. Our conclusion is that the QNNs\nwe studied can not generally offer an advantage over DNNs, because these QNNs\neither have a poor inductive bias or poor expressivity compared to DNNs.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "physics.app-ph"
    ],
    "primary_category": "quant-ph",
    "comment": "9 pages, 42 pages with appendices",
    "pdf_url": "http://arxiv.org/pdf/2407.03266v1",
    "published_date": "2024-07-03 16:56:08 UTC",
    "updated_date": "2024-07-03 16:56:08 UTC"
  },
  {
    "arxiv_id": "2407.03245v3",
    "title": "TieBot: Learning to Knot a Tie from Visual Demonstration through a Real-to-Sim-to-Real Approach",
    "authors": [
      "Weikun Peng",
      "Jun Lv",
      "Yuwei Zeng",
      "Haonan Chen",
      "Siheng Zhao",
      "Jichen Sun",
      "Cewu Lu",
      "Lin Shao"
    ],
    "abstract": "The tie-knotting task is highly challenging due to the tie's high deformation\nand long-horizon manipulation actions. This work presents TieBot, a\nReal-to-Sim-to-Real learning from visual demonstration system for the robots to\nlearn to knot a tie. We introduce the Hierarchical Feature Matching approach to\nestimate a sequence of tie's meshes from the demonstration video. With these\nestimated meshes used as subgoals, we first learn a teacher policy using\nprivileged information. Then, we learn a student policy with point cloud\nobservation by imitating teacher policy. Lastly, our pipeline applies learned\npolicy to real-world execution. We demonstrate the effectiveness of TieBot in\nsimulation and the real world. In the real-world experiment, a dual-arm robot\nsuccessfully knots a tie, achieving 50% success rate among 10 trials. Videos\ncan be found https://tiebots.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by CoRL 2024 as Oral presentation, camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2407.03245v3",
    "published_date": "2024-07-03 16:16:41 UTC",
    "updated_date": "2024-10-19 14:56:17 UTC"
  },
  {
    "arxiv_id": "2407.03227v2",
    "title": "Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning",
    "authors": [
      "Zhili Shen",
      "Pavlos Vougiouklis",
      "Chenxin Diao",
      "Kaustubh Vyas",
      "Yuanyi Ji",
      "Jeff Z. Pan"
    ],
    "abstract": "We focus on Text-to-SQL semantic parsing from the perspective of\nretrieval-augmented generation. Motivated by challenges related to the size of\ncommercial database schemata and the deployability of business intelligence\nsolutions, we propose $\\text{ASTReS}$ that dynamically retrieves input database\ninformation and uses abstract syntax trees to select few-shot examples for\nin-context learning.\n  Furthermore, we investigate the extent to which an in-parallel semantic\nparser can be leveraged for generating approximated versions of the expected\nSQL queries, to support our retrieval. We take this approach to the extreme--we\nadapt a model consisting of less than $500$M parameters, to act as an extremely\nefficient approximator, enhancing it with the ability to process schemata in a\nparallelised manner. We apply $\\text{ASTReS}$ to monolingual and cross-lingual\nbenchmarks for semantic parsing, showing improvements over state-of-the-art\nbaselines. Comprehensive experiments highlight the contribution of modules\ninvolved in this retrieval-augmented generation setting, revealing interesting\ndirections for future work.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2407.03227v2",
    "published_date": "2024-07-03 15:55:14 UTC",
    "updated_date": "2024-11-04 12:14:13 UTC"
  },
  {
    "arxiv_id": "2407.03224v1",
    "title": "PPO-based Dynamic Control of Uncertain Floating Platforms in the Zero-G Environment",
    "authors": [
      "Mahya Ramezani",
      "M. Amin Alandihallaj",
      "Andreas M. Hein"
    ],
    "abstract": "In the field of space exploration, floating platforms play a crucial role in\nscientific investigations and technological advancements. However, controlling\nthese platforms in zero-gravity environments presents unique challenges,\nincluding uncertainties and disturbances. This paper introduces an innovative\napproach that combines Proximal Policy Optimization (PPO) with Model Predictive\nControl (MPC) in the zero-gravity laboratory (Zero-G Lab) at the University of\nLuxembourg. This approach leverages PPO's reinforcement learning power and\nMPC's precision to navigate the complex control dynamics of floating platforms.\nUnlike traditional control methods, this PPO-MPC approach learns from MPC\npredictions, adapting to unmodeled dynamics and disturbances, resulting in a\nresilient control framework tailored to the zero-gravity environment.\nSimulations and experiments in the Zero-G Lab validate this approach,\nshowcasing the adaptability of the PPO agent. This research opens new\npossibilities for controlling floating platforms in zero-gravity settings,\npromising advancements in space exploration.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Pre-print version submitted to 2024 International Conference on\n  Robotics and Automation (ICRA)",
    "pdf_url": "http://arxiv.org/pdf/2407.03224v1",
    "published_date": "2024-07-03 15:51:06 UTC",
    "updated_date": "2024-07-03 15:51:06 UTC"
  },
  {
    "arxiv_id": "2407.03216v1",
    "title": "Learning Disentangled Representation in Object-Centric Models for Visual Dynamics Prediction via Transformers",
    "authors": [
      "Sanket Gandhi",
      "Atul",
      "Samanyu Mahajan",
      "Vishal Sharma",
      "Rushil Gupta",
      "Arnab Kumar Mondal",
      "Parag Singla"
    ],
    "abstract": "Recent work has shown that object-centric representations can greatly help\nimprove the accuracy of learning dynamics while also bringing interpretability.\nIn this work, we take this idea one step further, ask the following question:\n\"can learning disentangled representation further improve the accuracy of\nvisual dynamics prediction in object-centric models?\" While there has been some\nattempt to learn such disentangled representations for the case of static\nimages \\citep{nsb}, to the best of our knowledge, ours is the first work which\ntries to do this in a general setting for video, without making any specific\nassumptions about the kind of attributes that an object might have. The key\nbuilding block of our architecture is the notion of a {\\em block}, where\nseveral blocks together constitute an object. Each block is represented as a\nlinear combination of a given number of learnable concept vectors, which is\niteratively refined during the learning process. The blocks in our model are\ndiscovered in an unsupervised manner, by attending over object masks, in a\nstyle similar to discovery of slots \\citep{slot_attention}, for learning a\ndense object-centric representation. We employ self-attention via transformers\nover the discovered blocks to predict the next state resulting in discovery of\nvisual dynamics. We perform a series of experiments on several benchmark 2-D,\nand 3-D datasets demonstrating that our architecture (1) can discover\nsemantically meaningful blocks (2) help improve accuracy of dynamics prediction\ncompared to SOTA object-centric models (3) perform significantly better in OOD\nsetting where the specific attribute combinations are not seen earlier during\ntraining. Our experiments highlight the importance discovery of disentangled\nrepresentation for visual dynamics prediction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03216v1",
    "published_date": "2024-07-03 15:43:54 UTC",
    "updated_date": "2024-07-03 15:43:54 UTC"
  },
  {
    "arxiv_id": "2407.13067v1",
    "title": "Large Language Model Agents for Improving Engagement with Behavior Change Interventions: Application to Digital Mindfulness",
    "authors": [
      "Harsh Kumar",
      "Suhyeon Yoo",
      "Angela Zavaleta Bernuy",
      "Jiakai Shi",
      "Huayin Luo",
      "Joseph Williams",
      "Anastasia Kuzminykh",
      "Ashton Anderson",
      "Rachel Kornfield"
    ],
    "abstract": "Although engagement in self-directed wellness exercises typically declines\nover time, integrating social support such as coaching can sustain it. However,\ntraditional forms of support are often inaccessible due to the high costs and\ncomplex coordination. Large Language Models (LLMs) show promise in providing\nhuman-like dialogues that could emulate social support. Yet, in-depth, in situ\ninvestigations of LLMs to support behavior change remain underexplored. We\nconducted two randomized experiments to assess the impact of LLM agents on user\nengagement with mindfulness exercises. First, a single-session study, involved\n502 crowdworkers; second, a three-week study, included 54 participants. We\nexplored two types of LLM agents: one providing information and another\nfacilitating self-reflection. Both agents enhanced users' intentions to\npractice mindfulness. However, only the information-providing LLM, featuring a\nfriendly persona, significantly improved engagement with the exercises. Our\nfindings suggest that specific LLM agents may bridge the social support gap in\ndigital health interventions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2407.13067v1",
    "published_date": "2024-07-03 15:43:16 UTC",
    "updated_date": "2024-07-03 15:43:16 UTC"
  },
  {
    "arxiv_id": "2407.03210v2",
    "title": "Combining AI Control Systems and Human Decision Support via Robustness and Criticality",
    "authors": [
      "Walt Woods",
      "Alexander Grushin",
      "Simon Khan",
      "Alvaro Velasquez"
    ],
    "abstract": "AI-enabled capabilities are reaching the requisite level of maturity to be\ndeployed in the real world, yet do not always make correct or safe decisions.\nOne way of addressing these concerns is to leverage AI control systems\nalongside and in support of human decisions, relying on the AI control system\nin safe situations while calling on a human co-decider for critical situations.\nWe extend a methodology for adversarial explanations (AE) to state-of-the-art\nreinforcement learning frameworks, including MuZero. Multiple improvements to\nthe base agent architecture are proposed. We demonstrate how this technology\nhas two applications: for intelligent decision tools and to enhance training /\nlearning frameworks. In a decision support context, adversarial explanations\nhelp a user make the correct decision by highlighting those contextual factors\nthat would need to change for a different AI-recommended decision. As another\nbenefit of adversarial explanations, we show that the learned AI control system\ndemonstrates robustness against adversarial tampering. Additionally, we\nsupplement AE by introducing strategically similar autoencoders (SSAs) to help\nusers identify and understand all salient factors being considered by the AI\nsystem. In a training / learning framework, this technology can improve both\nthe AI's decisions and explanations through human interaction. Finally, to\nidentify when AI decisions would most benefit from human oversight, we tie this\ncombined system to our prior art on statistically verified analyses of the\ncriticality of decisions at any point in time.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03210v2",
    "published_date": "2024-07-03 15:38:57 UTC",
    "updated_date": "2024-10-09 02:16:02 UTC"
  },
  {
    "arxiv_id": "2407.03203v2",
    "title": "TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts",
    "authors": [
      "Ruida Wang",
      "Jipeng Zhang",
      "Yizhen Jia",
      "Rui Pan",
      "Shizhe Diao",
      "Renjie Pi",
      "Tong Zhang"
    ],
    "abstract": "Proving mathematical theorems using computer-verifiable formal languages like\nLean significantly impacts mathematical reasoning. One approach to formal\ntheorem proving involves generating complete proofs using Large Language Models\n(LLMs) based on Natural Language (NL) proofs. However, due to the scarcity of\naligned NL and Formal Language (FL) theorem-proving data most modern LLMs\nexhibit suboptimal performance.This scarcity results in a paucity of\nmethodologies for training LLMs and techniques to fully utilize their\ncapabilities in composing formal proofs. To address these challenges, this\npaper proposes TheoremLlama, an end-to-end framework that trains a\ngeneral-purpose LLM to be a Lean4 expert. TheoremLlama includes NL-FL dataset\ngeneration and bootstrapping method to obtain aligned dataset, curriculum\nlearning and block training techniques to train the model, and iterative proof\nwriting method to write Lean4 proofs that work together synergistically. Using\nthe dataset generation method in TheoremLlama, we provide Open Bootstrapped\nTheorems (OBT), an NL-FL aligned and bootstrapped dataset. Our novel NL-FL\nbootstrapping method, where NL proofs are integrated into Lean4 code for\ntraining datasets, leverages the NL reasoning ability of LLMs for formal\nreasoning. The TheoremLlama framework achieves cumulative accuracies of 36.48%\nand 33.61% on MiniF2F-Valid and Test datasets respectively, surpassing the\nGPT-4 baseline of 22.95% and 25.41%. Our code, model checkpoints, and the\ngenerated dataset is published in GitHub",
    "categories": [
      "cs.FL",
      "cs.AI"
    ],
    "primary_category": "cs.FL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03203v2",
    "published_date": "2024-07-03 15:36:18 UTC",
    "updated_date": "2024-10-04 03:06:26 UTC"
  },
  {
    "arxiv_id": "2407.03392v1",
    "title": "M5: A Whole Genome Bacterial Encoder at Single Nucleotide Resolution",
    "authors": [
      "Agust Egilsson"
    ],
    "abstract": "A linear attention mechanism is described to extend the context length of an\nencoder only transformer, called M5 in this report, to a multi-million single\nnucleotide resolution foundation model pretrained on bacterial whole genomes.\nThe linear attention mechanism used approximates a full quadratic attention\nmechanism tightly and has a simple and lightweight implementation for the use\ncase when the key-query embedding dimensionality is low. The M5-small model is\nentirely trained and tested on one A100 GPU with 40gb of memory up to 196K\nnucleotides during training and 2M nucleotides during testing. We test the\nperformance of the M5-small model and record notable improvements in\nperformance as whole genome bacterial sequence lengths are increased as well as\ndemonstrating the stability of the full multi-head attention approximation used\nas sequence length is increased.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "I.2"
    ],
    "primary_category": "q-bio.QM",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03392v1",
    "published_date": "2024-07-03 15:30:44 UTC",
    "updated_date": "2024-07-03 15:30:44 UTC"
  },
  {
    "arxiv_id": "2407.03188v2",
    "title": "MuDiT & MuSiT: Alignment with Colloquial Expression in Description-to-Song Generation",
    "authors": [
      "Zihao Wang",
      "Haoxuan Liu",
      "Jiaxing Yu",
      "Tao Zhang",
      "Yan Liu",
      "Kejun Zhang"
    ],
    "abstract": "Amid the rising intersection of generative AI and human artistic processes,\nthis study probes the critical yet less-explored terrain of alignment in\nhuman-centric automatic song composition. We propose a novel task of Colloquial\nDescription-to-Song Generation, which focuses on aligning the generated content\nwith colloquial human expressions. This task is aimed at bridging the gap\nbetween colloquial language understanding and auditory expression within an AI\nmodel, with the ultimate goal of creating songs that accurately satisfy human\nauditory expectations and structurally align with musical norms. Current\ndatasets are limited due to their narrow descriptive scope, semantic gaps and\ninaccuracies. To overcome data scarcity in this domain, we present the Caichong\nMusic Dataset (CaiMD). CaiMD is manually annotated by both professional\nmusicians and amateurs, offering diverse perspectives and a comprehensive\nunderstanding of colloquial descriptions. Unlike existing datasets pre-set with\nexpert annotations or auto-generated ones with inherent biases, CaiMD caters\nmore sufficiently to our purpose of aligning AI-generated music with widespread\nuser-desired results. Moreover, we propose an innovative single-stage framework\ncalled MuDiT/MuSiT for enabling effective human-machine alignment in song\ncreation. This framework not only achieves cross-modal comprehension between\ncolloquial language and auditory music perceptions but also ensures generated\nsongs align with user-desired results. MuDiT/MuSiT employs one DiT/SiT model\nfor end-to-end generation of musical components like melody, harmony, rhythm,\nvocals, and instrumentation. The approach ensures harmonious sonic cohesiveness\namongst all generated musical components, facilitating better resonance with\nhuman auditory expectations.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS",
      "68Txx(Primary)14F05, 91Fxx(Secondary)",
      "I.2.7; J.5"
    ],
    "primary_category": "cs.SD",
    "comment": "19 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03188v2",
    "published_date": "2024-07-03 15:12:36 UTC",
    "updated_date": "2024-07-11 03:32:44 UTC"
  },
  {
    "arxiv_id": "2407.03185v2",
    "title": "Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing",
    "authors": [
      "Egon Peršak",
      "Miguel F. Anjos",
      "Sebastian Lautz",
      "Aleksandar Kolev"
    ],
    "abstract": "We propose a transformer architecture for time series forecasting with a\nfocus on time series tokenisation and apply it to a real-world prediction\nproblem from the pricing domain. Our architecture aims to learn effective\nrepresentations at many scales across all available data simultaneously. The\nmodel contains a number of novel modules: a differentiated form of time series\npatching which employs multiple resolutions, a multiple-resolution module for\ntime-varying known variables, a mixer-based module for capturing cross-series\ninformation, and a novel output head with favourable scaling to account for the\nincreased number of tokens. We present an application of this model to a real\nworld prediction problem faced by the markdown team at a very large retailer.\nOn the experiments conducted our model outperforms in-house models and the\nselected existing deep learning architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03185v2",
    "published_date": "2024-07-03 15:07:16 UTC",
    "updated_date": "2025-04-21 08:58:24 UTC"
  },
  {
    "arxiv_id": "2407.03183v1",
    "title": "A Formal Model for Artificial Intelligence Applications in Automation Systems",
    "authors": [
      "Marvin Schieseck",
      "Philip Topalis",
      "Lasse Reinpold",
      "Felix Gehlhoff",
      "Alexander Fay"
    ],
    "abstract": "The integration of Artificial Intelligence (AI) into automation systems has\nthe potential to enhance efficiency and to address currently unsolved existing\ntechnical challenges. However, the industry-wide adoption of AI is hindered by\nthe lack of standardized documentation for the complex compositions of\nautomation systems, AI software, production hardware, and their\ninterdependencies. This paper proposes a formal model using standards and\nontologies to provide clear and structured documentation of AI applications in\nautomation systems. The proposed information model for artificial intelligence\nin automation systems (AIAS) utilizes ontology design patterns to map and link\nvarious aspects of automation systems and AI software. Validated through a\npractical example, the model demonstrates its effectiveness in improving\ndocumentation practices and aiding the sustainable implementation of AI in\nindustrial settings.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03183v1",
    "published_date": "2024-07-03 15:05:32 UTC",
    "updated_date": "2024-07-03 15:05:32 UTC"
  },
  {
    "arxiv_id": "2407.03180v1",
    "title": "A multi-objective combinatorial optimisation framework for large scale hierarchical population synthesis",
    "authors": [
      "Imran Mahmood",
      "Nicholas Bishop",
      "Anisoara Calinescu",
      "Michael Wooldridge",
      "Ioannis Zachos"
    ],
    "abstract": "In agent-based simulations, synthetic populations of agents are commonly used\nto represent the structure, behaviour, and interactions of individuals.\nHowever, generating a synthetic population that accurately reflects real\npopulation statistics is a challenging task, particularly when performed at\nscale. In this paper, we propose a multi objective combinatorial optimisation\ntechnique for large scale population synthesis. We demonstrate the\neffectiveness of our approach by generating a synthetic population for selected\nregions and validating it on contingency tables from real population data. Our\napproach supports complex hierarchical structures between individuals and\nhouseholds, is scalable to large populations and achieves minimal contigency\ntable reconstruction error. Hence, it provides a useful tool for policymakers\nand researchers for simulating the dynamics of complex populations.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03180v1",
    "published_date": "2024-07-03 15:01:12 UTC",
    "updated_date": "2024-07-03 15:01:12 UTC"
  },
  {
    "arxiv_id": "2407.03179v2",
    "title": "Motion meets Attention: Video Motion Prompts",
    "authors": [
      "Qixiang Chen",
      "Lei Wang",
      "Piotr Koniusz",
      "Tom Gedeon"
    ],
    "abstract": "Videos contain rich spatio-temporal information. Traditional methods for\nextracting motion, used in tasks such as action recognition, often rely on\nvisual contents rather than precise motion features. This phenomenon is\nreferred to as 'blind motion extraction' behavior, which proves inefficient in\ncapturing motions of interest due to a lack of motion-guided cues. Recently,\nattention mechanisms have enhanced many computer vision tasks by effectively\nhighlighting salient visual areas. Inspired by this, we propose a modified\nSigmoid function with learnable slope and shift parameters as an attention\nmechanism to modulate motion signals from frame differencing maps. This\napproach generates a sequence of attention maps that enhance the processing of\nmotion-related video content. To ensure temporal continuity and smoothness of\nthe attention maps, we apply pair-wise temporal attention variation\nregularization to remove unwanted motions (e.g., noise) while preserving\nimportant ones. We then perform Hadamard product between each pair of attention\nmaps and the original video frames to highlight the evolving motions of\ninterest over time. These highlighted motions, termed video motion prompts, are\nsubsequently used as inputs to the model instead of the original video frames.\nWe formalize this process as a motion prompt layer and incorporate the\nregularization term into the loss function to learn better motion prompts. This\nlayer serves as an adapter between the model and the video data, bridging the\ngap between traditional 'blind motion extraction' and the extraction of\nrelevant motions of interest. We show that our lightweight, plug-and-play\nmotion prompt layer seamlessly integrates into models like SlowFast, X3D, and\nTimeSformer, enhancing performance on benchmarks such as FineGym and MPII\nCooking 2.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the 16th Asian Conference on Machine Learning (ACML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.03179v2",
    "published_date": "2024-07-03 14:59:46 UTC",
    "updated_date": "2024-10-02 13:32:56 UTC"
  },
  {
    "arxiv_id": "2407.03391v1",
    "title": "Soft Begging: Modular and Efficient Shielding of LLMs against Prompt Injection and Jailbreaking based on Prompt Tuning",
    "authors": [
      "Simon Ostermann",
      "Kevin Baum",
      "Christoph Endres",
      "Julia Masloh",
      "Patrick Schramowski"
    ],
    "abstract": "Prompt injection (both direct and indirect) and jailbreaking are now\nrecognized as significant issues for large language models (LLMs), particularly\ndue to their potential for harm in application-integrated contexts. This\nextended abstract explores a novel approach to protecting LLMs from such\nattacks, termed \"soft begging.\" This method involves training soft prompts to\ncounteract the effects of corrupted prompts on the LLM's output. We provide an\noverview of prompt injections and jailbreaking, introduce the theoretical basis\nof the \"soft begging\" technique, and discuss an evaluation of its\neffectiveness.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03391v1",
    "published_date": "2024-07-03 14:52:09 UTC",
    "updated_date": "2024-07-03 14:52:09 UTC"
  },
  {
    "arxiv_id": "2407.03172v1",
    "title": "IMC 2024 Methods & Solutions Review",
    "authors": [
      "Shyam Gupta",
      "Dhanisha Sharma",
      "Songling Huang"
    ],
    "abstract": "For the past three years, Kaggle has been hosting the Image Matching\nChallenge, which focuses on solving a 3D image reconstruction problem using a\ncollection of 2D images. Each year, this competition fosters the development of\ninnovative and effective methodologies by its participants. In this paper, we\nintroduce an advanced ensemble technique that we developed, achieving a score\nof 0.153449 on the private leaderboard and securing the 160th position out of\nover 1,000 participants. Additionally, we conduct a comprehensive review of\nexisting methods and techniques employed by top-performing teams in the\ncompetition. Our solution, alongside the insights gathered from other leading\napproaches, contributes to the ongoing advancement in the field of 3D image\nreconstruction. This research provides valuable knowledge for future\nparticipants and researchers aiming to excel in similar image matching and\nreconstruction challenges.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CV",
    "comment": "8 Pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03172v1",
    "published_date": "2024-07-03 14:47:18 UTC",
    "updated_date": "2024-07-03 14:47:18 UTC"
  },
  {
    "arxiv_id": "2407.03157v2",
    "title": "Let the Code LLM Edit Itself When You Edit the Code",
    "authors": [
      "Zhenyu He",
      "Jun Zhang",
      "Shengjie Luo",
      "Jingjing Xu",
      "Zhi Zhang",
      "Di He"
    ],
    "abstract": "In this work, we investigate a typical scenario in code generation where a\ndeveloper edits existing code in real time and requests a code assistant, e.g.,\na large language model, to re-predict the next token or next line on the fly.\nNaively, the LLM needs to re-encode the entire KV cache to provide an accurate\nprediction. However, this process is computationally expensive, especially when\nthe sequence length is long. Simply encoding the edited subsequence and\nintegrating it to the original KV cache meets the temporal confusion problem,\nleading to significantly worse performance. We address this efficiency and\naccuracy trade-off by introducing \\underline{\\textbf{Positional\n\\textbf{I}ntegrity \\textbf{E}ncoding} (PIE). Building upon the rotary\npositional encoding, PIE first removes the rotary matrices in the Key cache\nthat introduce temporal confusion and then reapplies the correct rotary\nmatrices. This process ensures that positional relationships between tokens are\ncorrect and requires only a single round of matrix multiplication. We validate\nthe effectiveness of PIE through extensive experiments on the RepoBench-C-8k\ndataset, utilizing DeepSeek-Coder models with 1.3B, 6.7B, and 33B parameters.\nOur evaluation includes three real-world coding tasks: code insertion, code\ndeletion, and multi-place code editing. Results demonstrate that PIE reduces\ncomputational overhead by over 85% compared to the standard full recomputation\napproach across all model sizes and tasks while well approximating the model\nperformance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2407.03157v2",
    "published_date": "2024-07-03 14:34:03 UTC",
    "updated_date": "2025-03-04 13:01:07 UTC"
  },
  {
    "arxiv_id": "2407.03154v2",
    "title": "Reinforcement Learning for Sequence Design Leveraging Protein Language Models",
    "authors": [
      "Jithendaraa Subramanian",
      "Shivakanth Sujit",
      "Niloy Irtisam",
      "Umong Sain",
      "Riashat Islam",
      "Derek Nowrouzezahrai",
      "Samira Ebrahimi Kahou"
    ],
    "abstract": "Protein sequence design, determined by amino acid sequences, are essential to\nprotein engineering problems in drug discovery. Prior approaches have resorted\nto evolutionary strategies or Monte-Carlo methods for protein design, but often\nfail to exploit the structure of the combinatorial search space, to generalize\nto unseen sequences. In the context of discrete black box optimization over\nlarge search spaces, learning a mutation policy to generate novel sequences\nwith reinforcement learning is appealing. Recent advances in protein language\nmodels (PLMs) trained on large corpora of protein sequences offer a potential\nsolution to this problem by scoring proteins according to their biological\nplausibility (such as the TM-score). In this work, we propose to use PLMs as a\nreward function to generate new sequences. Yet the PLM can be computationally\nexpensive to query due to its large size. To this end, we propose an\nalternative paradigm where optimization can be performed on scores from a\nsmaller proxy model that is periodically finetuned, jointly while learning the\nmutation policy. We perform extensive experiments on various sequence lengths\nto benchmark RL-based approaches, and provide comprehensive evaluations along\nbiological plausibility and diversity of the protein. Our experimental results\ninclude favorable evaluations of the proposed sequences, along with high\ndiversity scores, demonstrating that RL is a strong candidate for biological\nsequence design. Finally, we provide a modular open source implementation can\nbe easily integrated in most RL training loops, with support for replacing the\nreward model with other PLMs, to spur further research in this domain. The code\nfor all experiments is provided in the supplementary material.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.03154v2",
    "published_date": "2024-07-03 14:31:36 UTC",
    "updated_date": "2024-11-16 17:48:19 UTC"
  },
  {
    "arxiv_id": "2407.03135v1",
    "title": "GMM-ResNext: Combining Generative and Discriminative Models for Speaker Verification",
    "authors": [
      "Hui Yan",
      "Zhenchun Lei",
      "Changhong Liu",
      "Yong Zhou"
    ],
    "abstract": "With the development of deep learning, many different network architectures\nhave been explored in speaker verification. However, most network architectures\nrely on a single deep learning architecture, and hybrid networks combining\ndifferent architectures have been little studied in ASV tasks. In this paper,\nwe propose the GMM-ResNext model for speaker verification. Conventional GMM\ndoes not consider the score distribution of each frame feature over all\nGaussian components and ignores the relationship between neighboring speech\nframes. So, we extract the log Gaussian probability features based on the raw\nacoustic features and use ResNext-based network as the backbone to extract the\nspeaker embedding. GMM-ResNext combines Generative and Discriminative Models to\nimprove the generalization ability of deep learning models and allows one to\nmore easily specify meaningful priors on model parameters. A two-path\nGMM-ResNext model based on two gender-related GMMs has also been proposed. The\nExperimental results show that the proposed GMM-ResNext achieves relative\nimprovements of 48.1\\% and 11.3\\% in EER compared with ResNet34 and ECAPA-TDNN\non VoxCeleb1-O test set.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03135v1",
    "published_date": "2024-07-03 14:14:18 UTC",
    "updated_date": "2024-07-03 14:14:18 UTC"
  },
  {
    "arxiv_id": "2407.03132v1",
    "title": "Speaker- and Text-Independent Estimation of Articulatory Movements and Phoneme Alignments from Speech",
    "authors": [
      "Tobias Weise",
      "Philipp Klumpp",
      "Kubilay Can Demir",
      "Paula Andrea Pérez-Toro",
      "Maria Schuster",
      "Elmar Noeth",
      "Bjoern Heismann",
      "Andreas Maier",
      "Seung Hee Yang"
    ],
    "abstract": "This paper introduces a novel combination of two tasks, previously treated\nseparately: acoustic-to-articulatory speech inversion (AAI) and\nphoneme-to-articulatory (PTA) motion estimation. We refer to this joint task as\nacoustic phoneme-to-articulatory speech inversion (APTAI) and explore two\ndifferent approaches, both working speaker- and text-independently during\ninference. We use a multi-task learning setup, with the end-to-end goal of\ntaking raw speech as input and estimating the corresponding articulatory\nmovements, phoneme sequence, and phoneme alignment. While both proposed\napproaches share these same requirements, they differ in their way of achieving\nphoneme-related predictions: one is based on frame classification, the other on\na two-staged training procedure and forced alignment. We reach competitive\nperformance of 0.73 mean correlation for the AAI task and achieve up to\napproximately 87% frame overlap compared to a state-of-the-art text-dependent\nphoneme force aligner.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "to be published in Interspeech 2024 proceedings",
    "pdf_url": "http://arxiv.org/pdf/2407.03132v1",
    "published_date": "2024-07-03 14:13:04 UTC",
    "updated_date": "2024-07-03 14:13:04 UTC"
  },
  {
    "arxiv_id": "2407.03131v4",
    "title": "MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition",
    "authors": [
      "Yanjie Cui",
      "Xiaohong Liu",
      "Jing Liang",
      "Yamin Fu"
    ],
    "abstract": "Electroencephalography (EEG), a technique that records electrical activity\nfrom the scalp using electrodes, plays a vital role in affective computing.\nHowever, fully utilizing the multi-domain characteristics of EEG signals\nremains a significant challenge. Traditional single-perspective analyses often\nfail to capture the complex interplay of temporal, frequency, and spatial\ndimensions in EEG data. To address this, we introduce a multi-view graph\ntransformer (MVGT) based on spatial relations that integrates information\nacross three domains: temporal dynamics from continuous series, frequency\nfeatures extracted from frequency bands, and inter-channel relationships\ncaptured through several spatial encodings. This comprehensive approach allows\nmodel to capture the nuanced properties inherent in EEG signals, enhancing its\nflexibility and representational power. Evaluation on publicly available\ndatasets demonstrates that MVGT surpasses state-of-the-art methods in\nperformance. The results highlight its ability to extract multi-domain\ninformation and effectively model inter-channel relationships, showcasing its\npotential for EEG-based emotion recognition tasks.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03131v4",
    "published_date": "2024-07-03 14:13:00 UTC",
    "updated_date": "2025-01-16 02:54:35 UTC"
  },
  {
    "arxiv_id": "2407.03125v2",
    "title": "Foundations and Frontiers of Graph Learning Theory",
    "authors": [
      "Yu Huang",
      "Min Zhou",
      "Menglin Yang",
      "Zhen Wang",
      "Muhan Zhang",
      "Jie Wang",
      "Hong Xie",
      "Hao Wang",
      "Defu Lian",
      "Enhong Chen"
    ],
    "abstract": "Recent advancements in graph learning have revolutionized the way to\nunderstand and analyze data with complex structures. Notably, Graph Neural\nNetworks (GNNs), i.e. neural network architectures designed for learning graph\nrepresentations, have become a popular paradigm. With these models being\nusually characterized by intuition-driven design or highly intricate\ncomponents, placing them within the theoretical analysis framework to distill\nthe core concepts, helps understand the key principles that drive the\nfunctionality better and guide further development. Given this surge in\ninterest, this article provides a comprehensive summary of the theoretical\nfoundations and breakthroughs concerning the approximation and learning\nbehaviors intrinsic to prevalent graph learning models. Encompassing\ndiscussions on fundamental aspects such as expressiveness power,\ngeneralization, optimization, and unique phenomena such as over-smoothing and\nover-squashing, this piece delves into the theoretical foundations and frontier\ndriving the evolution of graph learning. In addition, this article also\npresents several challenges and further initiates discussions on possible\nsolutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "35pages,273references. Github link:\n  https://github.com/minehly/awesome-paper-for-graph-learning-theory",
    "pdf_url": "http://arxiv.org/pdf/2407.03125v2",
    "published_date": "2024-07-03 14:07:41 UTC",
    "updated_date": "2024-07-08 01:22:37 UTC"
  },
  {
    "arxiv_id": "2407.03108v1",
    "title": "How Reliable and Stable are Explanations of XAI Methods?",
    "authors": [
      "José Ribeiro",
      "Lucas Cardoso",
      "Vitor Santos",
      "Eduardo Carvalho",
      "Níkolas Carneiro",
      "Ronnie Alves"
    ],
    "abstract": "Black box models are increasingly being used in the daily lives of human\nbeings living in society. Along with this increase, there has been the\nemergence of Explainable Artificial Intelligence (XAI) methods aimed at\ngenerating additional explanations regarding how the model makes certain\npredictions. In this sense, methods such as Dalex, Eli5, eXirt, Lofo and Shap\nemerged as different proposals and methodologies for generating explanations of\nblack box models in an agnostic way. Along with the emergence of these methods,\nquestions arise such as \"How Reliable and Stable are XAI Methods?\". With the\naim of shedding light on this main question, this research creates a pipeline\nthat performs experiments using the diabetes dataset and four different machine\nlearning models (LGBM, MLP, DT and KNN), creating different levels of\nperturbations of the test data and finally generates explanations from the\neXirt method regarding the confidence of the models and also feature relevances\nranks from all XAI methods mentioned, in order to measure their stability in\nthe face of perturbations. As a result, it was found that eXirt was able to\nidentify the most reliable models among all those used. It was also found that\ncurrent XAI methods are sensitive to perturbations, with the exception of one\nspecific method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 6 figures, submitted to BRACIS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.03108v1",
    "published_date": "2024-07-03 13:47:41 UTC",
    "updated_date": "2024-07-03 13:47:41 UTC"
  },
  {
    "arxiv_id": "2407.17489v1",
    "title": "Collective Attention in Human-AI Teams",
    "authors": [
      "Josie Zvelebilova",
      "Saiph Savage",
      "Christoph Riedl"
    ],
    "abstract": "How does the presence of an AI assistant affect the collective attention of a\nteam? We study 20 human teams of 3-4 individuals paired with one voice-only AI\nassistant during a challenging puzzle task. Teams are randomly assigned to an\nAI assistant with a human- or robotic-sounding voice that provides either\nhelpful or misleading information about the task. Treating each individual AI\ninterjection as a treatment intervention, we identify the causal effects of the\nAI on dynamic group processes involving language use. Our findings demonstrate\nthat the AI significantly affects what teams discuss, how they discuss it, and\nthe alignment of their mental models. Teams adopt AI-introduced language for\nboth terms directly related to the task and for peripheral terms, even when\nthey (a) recognize the unhelpful nature of the AI, (b) do not consider the AI a\ngenuine team member, and (c) do not trust the AI. The process of language\nadaptation appears to be automatic, despite doubts about the AI's competence.\nThe presence of an AI assistant significantly impacts team collective attention\nby modulating various aspects of shared cognition. This study contributes to\nhuman-AI teaming research by highlighting collective attention as a central\nmechanism through which AI systems in team settings influence team performance.\nUnderstanding this mechanism will help CSCW researchers design AI systems that\nenhance team collective intelligence by optimizing collective attention.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17489v1",
    "published_date": "2024-07-03 13:46:00 UTC",
    "updated_date": "2024-07-03 13:46:00 UTC"
  },
  {
    "arxiv_id": "2407.03094v2",
    "title": "Conformal Prediction for Causal Effects of Continuous Treatments",
    "authors": [
      "Maresa Schröder",
      "Dennis Frauen",
      "Jonas Schweisthal",
      "Konstantin Heß",
      "Valentyn Melnychuk",
      "Stefan Feuerriegel"
    ],
    "abstract": "Uncertainty quantification of causal effects is crucial for safety-critical\napplications such as personalized medicine. A powerful approach for this is\nconformal prediction, which has several practical benefits due to\nmodel-agnostic finite-sample guarantees. Yet, existing methods for conformal\nprediction of causal effects are limited to binary/discrete treatments and make\nhighly restrictive assumptions such as known propensity scores. In this work,\nwe provide a novel conformal prediction method for potential outcomes of\ncontinuous treatments. We account for the additional uncertainty introduced\nthrough propensity estimation so that our conformal prediction intervals are\nvalid even if the propensity score is unknown. Our contributions are\nthree-fold: (1) We derive finite-sample prediction intervals for potential\noutcomes of continuous treatments. (2) We provide an algorithm for calculating\nthe derived intervals. (3) We demonstrate the effectiveness of the conformal\nprediction intervals in experiments on synthetic and real-world datasets. To\nthe best of our knowledge, we are the first to propose conformal prediction for\ncontinuous treatments when the propensity score is unknown and must be\nestimated from data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03094v2",
    "published_date": "2024-07-03 13:34:33 UTC",
    "updated_date": "2024-10-23 10:09:10 UTC"
  },
  {
    "arxiv_id": "2407.03093v1",
    "title": "Revisiting the Performance of Deep Learning-Based Vulnerability Detection on Realistic Datasets",
    "authors": [
      "Partha Chakraborty",
      "Krishna Kanth Arumugam",
      "Mahmoud Alfadel",
      "Meiyappan Nagappan",
      "Shane McIntosh"
    ],
    "abstract": "The impact of software vulnerabilities on everyday software systems is\nsignificant. Despite deep learning models being proposed for vulnerability\ndetection, their reliability is questionable. Prior evaluations show high\nrecall/F1 scores of up to 99%, but these models underperform in practical\nscenarios, particularly when assessed on entire codebases rather than just the\nfixing commit. This paper introduces Real-Vul, a comprehensive dataset\nrepresenting real-world scenarios for evaluating vulnerability detection\nmodels. Evaluating DeepWukong, LineVul, ReVeal, and IVDetect shows a\nsignificant drop in performance, with precision decreasing by up to 95\npercentage points and F1 scores by up to 91 points. Furthermore, Model\nperformance fluctuates based on vulnerability characteristics, with better F1\nscores for information leaks or code injection than for path resolution or\npredictable return values. The results highlight a significant performance gap\nthat needs addressing before deploying deep learning-based vulnerability\ndetection in practical settings. Overfitting is identified as a key issue, and\nan augmentation technique is proposed, potentially improving performance by up\nto 30%. Contributions include a dataset creation approach for better model\nevaluation, Real-Vul dataset, and empirical evidence of deep learning models\nstruggling in real-world settings.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "D.2; I.2"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03093v1",
    "published_date": "2024-07-03 13:34:30 UTC",
    "updated_date": "2024-07-03 13:34:30 UTC"
  },
  {
    "arxiv_id": "2407.03086v2",
    "title": "Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation",
    "authors": [
      "Yujin Shin",
      "Kichang Lee",
      "Sungmin Lee",
      "You Rim Choi",
      "Hyung-Sin Kim",
      "JeongGil Ko"
    ],
    "abstract": "While federated learning leverages distributed client resources, it faces\nchallenges due to heterogeneous client capabilities. This necessitates\nallocating models suited to clients' resources and careful parameter\naggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel\nfederated learning framework for supporting client heterogeneity by combining a\nmulti-exit network architecture with hypernetwork-based model weight\ngeneration. This approach aligns the feature spaces of heterogeneous model\nlayers and resolves per-layer information disparity during weight aggregation.\nTo practically realize HypeMeFed, we also propose a low-rank factorization\napproach to minimize computation and memory overhead associated with\nhypernetworks. Our evaluations on a real-world heterogeneous device testbed\nindicate that \\system enhances accuracy by 5.12% over FedAvg, reduces the\nhypernetwork memory requirements by 98.22%, and accelerates its operations by\n1.86x compared to a naive hypernetwork approach. These results demonstrate\nHypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for\nfederated learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03086v2",
    "published_date": "2024-07-03 13:15:12 UTC",
    "updated_date": "2024-10-03 12:45:48 UTC"
  },
  {
    "arxiv_id": "2407.12831v2",
    "title": "Truth is Universal: Robust Detection of Lies in LLMs",
    "authors": [
      "Lennart Bürger",
      "Fred A. Hamprecht",
      "Boaz Nadler"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionised natural language processing,\nexhibiting impressive human-like capabilities. In particular, LLMs are capable\nof \"lying\", knowingly outputting false statements. Hence, it is of interest and\nimportance to develop methods to detect when LLMs lie. Indeed, several authors\ntrained classifiers to detect LLM lies based on their internal model\nactivations. However, other researchers showed that these classifiers may fail\nto generalise, for example to negated statements. In this work, we aim to\ndevelop a robust method to detect when an LLM is lying. To this end, we make\nthe following key contributions: (i) We demonstrate the existence of a\ntwo-dimensional subspace, along which the activation vectors of true and false\nstatements can be separated. Notably, this finding is universal and holds for\nvarious LLMs, including Gemma-7B, LLaMA2-13B, Mistral-7B and LLaMA3-8B. Our\nanalysis explains the generalisation failures observed in previous studies and\nsets the stage for more robust lie detection; (ii) Building upon (i), we\nconstruct an accurate LLM lie detector. Empirically, our proposed classifier\nachieves state-of-the-art performance, attaining 94% accuracy in both\ndistinguishing true from false factual statements and detecting lies generated\nin real-world scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 poster",
    "pdf_url": "http://arxiv.org/pdf/2407.12831v2",
    "published_date": "2024-07-03 13:01:54 UTC",
    "updated_date": "2024-10-21 08:55:49 UTC"
  },
  {
    "arxiv_id": "2407.03080v1",
    "title": "Artificial Inductive Bias for Synthetic Tabular Data Generation in Data-Scarce Scenarios",
    "authors": [
      "Patricia A. Apellániz",
      "Ana Jiménez",
      "Borja Arroyo Galende",
      "Juan Parras",
      "Santiago Zazo"
    ],
    "abstract": "While synthetic tabular data generation using Deep Generative Models (DGMs)\noffers a compelling solution to data scarcity and privacy concerns, their\neffectiveness relies on substantial training data, often unavailable in\nreal-world applications. This paper addresses this challenge by proposing a\nnovel methodology for generating realistic and reliable synthetic tabular data\nwith DGMs in limited real-data environments. Our approach proposes several ways\nto generate an artificial inductive bias in a DGM through transfer learning and\nmeta-learning techniques. We explore and compare four different methods within\nthis framework, demonstrating that transfer learning strategies like\npre-training and model averaging outperform meta-learning approaches, like\nModel-Agnostic Meta-Learning, and Domain Randomized Search. We validate our\napproach using two state-of-the-art DGMs, namely, a Variational Autoencoder and\na Generative Adversarial Network, to show that our artificial inductive bias\nfuels superior synthetic data quality, as measured by Jensen-Shannon\ndivergence, achieving relative gains of up to 50\\% when using our proposed\napproach. This methodology has broad applicability in various DGMs and machine\nlearning tasks, particularly in areas like healthcare and finance, where data\nscarcity is often a critical issue.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 6 Figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03080v1",
    "published_date": "2024-07-03 12:53:42 UTC",
    "updated_date": "2024-07-03 12:53:42 UTC"
  },
  {
    "arxiv_id": "2407.03070v1",
    "title": "Federated Learning for Zero-Day Attack Detection in 5G and Beyond V2X Networks",
    "authors": [
      "Abdelaziz Amara korba",
      "Abdelwahab Boualouache",
      "Bouziane Brik",
      "Rabah Rahal",
      "Yacine Ghamri-Doudane",
      "Sidi Mohammed Senouci"
    ],
    "abstract": "Deploying Connected and Automated Vehicles (CAVs) on top of 5G and Beyond\nnetworks (5GB) makes them vulnerable to increasing vectors of security and\nprivacy attacks. In this context, a wide range of advanced machine/deep\nlearning based solutions have been designed to accurately detect security\nattacks. Specifically, supervised learning techniques have been widely applied\nto train attack detection models. However, the main limitation of such\nsolutions is their inability to detect attacks different from those seen during\nthe training phase, or new attacks, also called zero-day attacks. Moreover,\ntraining the detection model requires significant data collection and labeling,\nwhich increases the communication overhead, and raises privacy concerns. To\naddress the aforementioned limits, we propose in this paper a novel detection\nmechanism that leverages the ability of the deep auto-encoder method to detect\nattacks relying only on the benign network traffic pattern. Using federated\nlearning, the proposed intrusion detection system can be trained with large and\ndiverse benign network traffic, while preserving the CAVs privacy, and\nminimizing the communication overhead. The in-depth experiment on a recent\nnetwork traffic dataset shows that the proposed system achieved a high\ndetection rate while minimizing the false positive rate, and the detection\ndelay.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03070v1",
    "published_date": "2024-07-03 12:42:31 UTC",
    "updated_date": "2024-07-03 12:42:31 UTC"
  },
  {
    "arxiv_id": "2407.03068v1",
    "title": "xApp Distillation: AI-based Conflict Mitigation in B5G O-RAN",
    "authors": [
      "Hakan Erdol",
      "Xiaoyang Wang",
      "Robert Piechocki",
      "George Oikonomou",
      "Arjun Parekh"
    ],
    "abstract": "The advancements of machine learning-based (ML) decision-making algorithms\ncreated various research and industrial opportunities. One of these areas is\nML-based near-real-time network management applications (xApps) in Open-Radio\nAccess Network (O-RAN). Normally, xApps are designed solely for the desired\nobjectives, and fine-tuned for deployment. However, telecommunication companies\ncan employ multiple xApps and deploy them in overlapping areas. Consider the\ndifferent design objectives of xApps, the deployment might cause conflicts. To\nprevent such conflicts, we proposed the xApp distillation method that distills\nknowledge from multiple xApps, then uses this knowledge to train a single model\nthat has retained the capabilities of Previous xApps. Performance evaluations\nshow that compared conflict mitigation schemes can cause up to six times more\nnetwork outages than xApp distillation in some cases.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "5 Pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03068v1",
    "published_date": "2024-07-03 12:40:20 UTC",
    "updated_date": "2024-07-03 12:40:20 UTC"
  },
  {
    "arxiv_id": "2407.03059v2",
    "title": "FairJob: A Real-World Dataset for Fairness in Online Systems",
    "authors": [
      "Mariia Vladimirova",
      "Federico Pavone",
      "Eustache Diemert"
    ],
    "abstract": "We introduce a fairness-aware dataset for job recommendations in advertising,\ndesigned to foster research in algorithmic fairness within real-world\nscenarios. It was collected and prepared to comply with privacy standards and\nbusiness confidentiality. An additional challenge is the lack of access to\nprotected user attributes such as gender, for which we propose a solution to\nobtain a proxy estimate. Despite being anonymized and including a proxy for a\nsensitive attribute, our dataset preserves predictive power and maintains a\nrealistic and challenging benchmark. This dataset addresses a significant gap\nin the availability of fairness-focused resources for high-impact domains like\nadvertising -- the actual impact being having access or not to precious\nemployment opportunities, where balancing fairness and utility is a common\nindustrial challenge. We also explore various stages in the advertising process\nwhere unfairness can occur and introduce a method to compute a fair utility\nmetric for the job recommendations in online systems case from a biased\ndataset. Experimental evaluations of bias mitigation techniques on the released\ndataset demonstrate potential improvements in fairness and the associated\ntrade-offs with utility.\n  The dataset is hosted at https://huggingface.co/datasets/criteo/FairJob.\nSource code for the experiments is hosted at\nhttps://github.com/criteo-research/FairJob-dataset/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024, 28 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03059v2",
    "published_date": "2024-07-03 12:30:39 UTC",
    "updated_date": "2024-11-01 06:45:23 UTC"
  },
  {
    "arxiv_id": "2407.03056v2",
    "title": "Improving Zero-shot Generalization of Learned Prompts via Unsupervised Knowledge Distillation",
    "authors": [
      "Marco Mistretta",
      "Alberto Baldrati",
      "Marco Bertini",
      "Andrew D. Bagdanov"
    ],
    "abstract": "Vision-Language Models (VLMs) demonstrate remarkable zero-shot generalization\nto unseen tasks, but fall short of the performance of supervised methods in\ngeneralizing to downstream tasks with limited data. Prompt learning is emerging\nas a parameter-efficient method for adapting VLMs, but state-of-the-art\napproaches require annotated samples. In this paper we propose a novel approach\nto prompt learning based on unsupervised knowledge distillation from more\npowerful models. Our approach, which we call Knowledge Distillation Prompt\nLearning (KDPL), can be integrated into existing prompt learning techniques and\neliminates the need for labeled examples during adaptation. Our experiments on\nmore than ten standard benchmark datasets demonstrate that KDPL is very\neffective at improving generalization of learned prompts for zero-shot domain\ngeneralization, zero-shot cross-dataset generalization, and zero-shot\nbase-to-novel class generalization problems. KDPL requires no ground-truth\nlabels for adaptation, and moreover we show that even in the absence of any\nknowledge of training class names it can be used to effectively transfer\nknowledge. The code is publicly available at https://github.com/miccunifi/KDPL.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication at ECCV24",
    "pdf_url": "http://arxiv.org/pdf/2407.03056v2",
    "published_date": "2024-07-03 12:24:40 UTC",
    "updated_date": "2024-07-30 11:56:43 UTC"
  },
  {
    "arxiv_id": "2407.03049v1",
    "title": "Enhancements for Real-Time Monte-Carlo Tree Search in General Video Game Playing",
    "authors": [
      "Dennis J. N. J. Soemers",
      "Chiara F. Sironi",
      "Torsten Schuster",
      "Mark H. M. Winands"
    ],
    "abstract": "General Video Game Playing (GVGP) is a field of Artificial Intelligence where\nagents play a variety of real-time video games that are unknown in advance.\nThis limits the use of domain-specific heuristics. Monte-Carlo Tree Search\n(MCTS) is a search technique for game playing that does not rely on\ndomain-specific knowledge. This paper discusses eight enhancements for MCTS in\nGVGP; Progressive History, N-Gram Selection Technique, Tree Reuse,\nBreadth-First Tree Initialization, Loss Avoidance, Novelty-Based Pruning,\nKnowledge-Based Evaluations, and Deterministic Game Detection. Some of these\nare known from existing literature, and are either extended or introduced in\nthe context of GVGP, and some are novel enhancements for MCTS. Most\nenhancements are shown to provide statistically significant increases in win\npercentages when applied individually. When combined, they increase the average\nwin percentage over sixty different games from 31.0% to 48.4% in comparison to\na vanilla MCTS implementation, approaching a level that is competitive with the\nbest agents of the GVG-AI competition in 2015.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Green Open Access version of conference paper published in 2016",
    "pdf_url": "http://arxiv.org/pdf/2407.03049v1",
    "published_date": "2024-07-03 12:18:28 UTC",
    "updated_date": "2024-07-03 12:18:28 UTC"
  },
  {
    "arxiv_id": "2407.03040v1",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "authors": [
      "Xia Hou",
      "Qifeng Li",
      "Jian Yang",
      "Tongliang Li",
      "Linzheng Chai",
      "Xianjie Wu",
      "Hangyuan Ji",
      "Zhoujun Li",
      "Jixuan Nie",
      "Jingbo Dun",
      "Wenfeng Song"
    ],
    "abstract": "Instruction tuning as an effective technique aligns the outputs of large\nlanguage models (LLMs) with human preference. But how to generate the seasonal\nmulti-turn dialogues from raw documents for instruction tuning still requires\nfurther exploration. In this paper, we present a novel framework named R2S that\nleverages the CoD-Chain of Dialogue logic to guide large language models (LLMs)\nin generating knowledge-intensive multi-turn dialogues for instruction tuning.\nBy integrating raw documents from both open-source datasets and domain-specific\nweb-crawled documents into a benchmark K-BENCH, we cover diverse areas such as\nWikipedia (English), Science (Chinese), and Artifacts (Chinese). Our approach\nfirst decides the logic flow of the current dialogue and then prompts LLMs to\nproduce key phrases for sourcing relevant response content. This methodology\nenables the creation of the G I NSTRUCT instruction dataset, retaining raw\ndocument knowledge within dialoguestyle interactions. Utilizing this dataset,\nwe fine-tune GLLM, a model designed to transform raw documents into structured\nmulti-turn dialogues, thereby injecting comprehensive domain knowledge into the\nSFT model for enhanced instruction tuning. This work signifies a stride towards\nrefining the adaptability and effectiveness of LLMs in processing and\ngenerating more accurate, contextually nuanced responses across various fields.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03040v1",
    "published_date": "2024-07-03 12:04:10 UTC",
    "updated_date": "2024-07-03 12:04:10 UTC"
  },
  {
    "arxiv_id": "2407.03035v1",
    "title": "NLP Sampling: Combining MCMC and NLP Methods for Diverse Constrained Sampling",
    "authors": [
      "Marc Toussaint",
      "Cornelius V. Braun",
      "Joaquim Ortiz-Haro"
    ],
    "abstract": "Generating diverse samples under hard constraints is a core challenge in many\nareas. With this work we aim to provide an integrative view and framework to\ncombine methods from the fields of MCMC, constrained optimization, as well as\nrobotics, and gain insights in their strengths from empirical evaluations. We\npropose NLP Sampling as a general problem formulation, propose a family of\nrestarting two-phase methods as a framework to integrated methods from across\nthe fields, and evaluate them on analytical and robotic manipulation planning\nproblems. Complementary to this, we provide several conceptual discussions,\ne.g. on the role of Lagrange parameters, global sampling, and the idea of a\nDiffused NLP and a corresponding model-based denoising sampler.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03035v1",
    "published_date": "2024-07-03 11:55:06 UTC",
    "updated_date": "2024-07-03 11:55:06 UTC"
  },
  {
    "arxiv_id": "2407.03034v1",
    "title": "Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging",
    "authors": [
      "Siying Xu",
      "Kerstin Hammernik",
      "Andreas Lingg",
      "Jens Kuebler",
      "Patrick Krumm",
      "Daniel Rueckert",
      "Sergios Gatidis",
      "Thomas Kuestner"
    ],
    "abstract": "Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment\nof heart morphology and function in clinical practice. However, MRI requires\nlong acquisition times, with recent deep learning-based methods showing great\npromise to accelerate imaging and enhance reconstruction quality. Existing\nnetworks exhibit some common limitations that constrain further acceleration\npossibilities, including single-domain learning, reliance on a single\nregularization term, and equal feature contribution. To address these\nlimitations, we propose to embed information from multiple domains, including\nlow-rank, image, and k-space, in a novel deep learning network for MRI\nreconstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch\nstructure, enabling independent learning in the k-space and image domain.\nCoupled information sharing layers realize the information exchange between\ndomains. Furthermore, we introduce attention mechanisms into the network to\nassign greater weights to more critical coils or important temporal frames.\nTraining and testing were conducted on an in-house dataset, including 91\ncardiovascular patients and 38 healthy subjects scanned with 2D cardiac Cine\nusing retrospective undersampling. Additionally, we evaluated A-LIKNet on the\nreal-time 8x prospectively undersampled data from the OCMR dataset. The results\ndemonstrate that our proposed A-LIKNet outperforms existing methods and\nprovides high-quality reconstructions. The network can effectively reconstruct\nhighly retrospectively undersampled dynamic MR images up to 24x accelerations,\nindicating its potential for single breath-hold imaging.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03034v1",
    "published_date": "2024-07-03 11:54:43 UTC",
    "updated_date": "2024-07-03 11:54:43 UTC"
  },
  {
    "arxiv_id": "2407.03026v1",
    "title": "Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition",
    "authors": [
      "Jinming Chen",
      "Jingyi Fang",
      "Yuanzhong Zheng",
      "Yaoxuan Wang",
      "Haojun Fei"
    ],
    "abstract": "Currently, end-to-end (E2E) speech recognition methods have achieved\npromising performance. However, auto speech recognition (ASR) models still face\nchallenges in recognizing multi-accent speech accurately. We propose a\nlayer-adapted fusion (LAF) model, called Qifusion-Net, which does not require\nany prior knowledge about the target accent. Based on dynamic chunk strategy,\nour approach enables streaming decoding and can extract frame-level acoustic\nfeature, facilitating fine-grained information fusion. Experiment results\ndemonstrate that our proposed methods outperform the baseline with relative\nreductions of 22.1$\\%$ and 17.2$\\%$ in character error rate (CER) across multi\naccent test datasets on KeSpeech and MagicData-RMAC.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "accpeted by interspeech 2014, 5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2407.03026v1",
    "published_date": "2024-07-03 11:35:52 UTC",
    "updated_date": "2024-07-03 11:35:52 UTC"
  },
  {
    "arxiv_id": "2407.03018v1",
    "title": "An Organism Starts with a Single Pix-Cell: A Neural Cellular Diffusion for High-Resolution Image Synthesis",
    "authors": [
      "Marawan Elbatel",
      "Konstantinos Kamnitsas",
      "Xiaomeng Li"
    ],
    "abstract": "Generative modeling seeks to approximate the statistical properties of real\ndata, enabling synthesis of new data that closely resembles the original\ndistribution. Generative Adversarial Networks (GANs) and Denoising Diffusion\nProbabilistic Models (DDPMs) represent significant advancements in generative\nmodeling, drawing inspiration from game theory and thermodynamics,\nrespectively. Nevertheless, the exploration of generative modeling through the\nlens of biological evolution remains largely untapped. In this paper, we\nintroduce a novel family of models termed Generative Cellular Automata (GeCA),\ninspired by the evolution of an organism from a single cell. GeCAs are\nevaluated as an effective augmentation tool for retinal disease classification\nacross two imaging modalities: Fundus and Optical Coherence Tomography (OCT).\nIn the context of OCT imaging, where data is scarce and the distribution of\nclasses is inherently skewed, GeCA significantly boosts the performance of 11\ndifferent ophthalmological conditions, achieving a 12% increase in the average\nF1 score compared to conventional baselines. GeCAs outperform both diffusion\nmethods that incorporate UNet or state-of-the art variants with\ntransformer-based denoising models, under similar parameter constraints. Code\nis available at: https://github.com/xmed-lab/GeCA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.03018v1",
    "published_date": "2024-07-03 11:26:09 UTC",
    "updated_date": "2024-07-03 11:26:09 UTC"
  },
  {
    "arxiv_id": "2407.12830v2",
    "title": "Knowledge-based Consistency Testing of Large Language Models",
    "authors": [
      "Sai Sathiesh Rajan",
      "Ezekiel Soremekun",
      "Sudipta Chattopadhyay"
    ],
    "abstract": "In this work, we systematically expose and measure the inconsistency and\nknowledge gaps of Large Language Models (LLMs). Specifically, we propose an\nautomated testing framework (called KonTest) which leverages a knowledge graph\nto construct test cases. KonTest probes and measures the inconsistencies in the\nLLM's knowledge of the world via a combination of semantically-equivalent\nqueries and test oracles (metamorphic or ontological oracle). KonTest further\nmitigates knowledge gaps via a weighted LLM model ensemble. Using four\nstate-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that\nKonTest generates 19.2% error inducing inputs (1917 errors from 9979 test\ninputs). It also reveals a 16.5% knowledge gap across all tested LLMs. A\nmitigation method informed by KonTest's test suite reduces LLM knowledge gap by\n32.48%. Our ablation study further shows that GPT3.5 is not suitable for\nknowledge-based consistency testing because it is only 60%-68% effective in\nknowledge construction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 4 figures, 8 tables, Accepted at EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2407.12830v2",
    "published_date": "2024-07-03 11:16:54 UTC",
    "updated_date": "2024-10-05 14:12:11 UTC"
  },
  {
    "arxiv_id": "2407.03007v1",
    "title": "What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks",
    "authors": [
      "Chengrui Huang",
      "Zhengliang Shi",
      "Yuntao Wen",
      "Xiuying Chen",
      "Peng Han",
      "Shen Gao",
      "Shuo Shang"
    ],
    "abstract": "Tool learning methods have enhanced the ability of large language models\n(LLMs) to interact with real-world applications. Many existing works fine-tune\nLLMs or design prompts to enable LLMs to select appropriate tools and correctly\ninvoke them to meet user requirements. However, it is observed in previous\nworks that the performance of tool learning varies from tasks, datasets,\ntraining settings, and algorithms. Without understanding the impact of these\nfactors, it can lead to inconsistent results, inefficient model deployment, and\nsuboptimal tool utilization, ultimately hindering the practical integration and\nscalability of LLMs in real-world scenarios. Therefore, in this paper, we\nexplore the impact of both internal and external factors on the performance of\ntool learning frameworks. Through extensive experiments on two benchmark\ndatasets, we find several insightful conclusions for future work, including the\nobservation that LLMs can benefit significantly from increased trial and\nexploration. We believe our empirical study provides a new perspective for\nfuture tool learning research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.03007v1",
    "published_date": "2024-07-03 11:06:05 UTC",
    "updated_date": "2024-07-03 11:06:05 UTC"
  },
  {
    "arxiv_id": "2407.03005v1",
    "title": "Human-like Linguistic Biases in Neural Speech Models: Phonetic Categorization and Phonotactic Constraints in Wav2Vec2.0",
    "authors": [
      "Marianne de Heer Kloots",
      "Willem Zuidema"
    ],
    "abstract": "What do deep neural speech models know about phonology? Existing work has\nexamined the encoding of individual linguistic units such as phonemes in these\nmodels. Here we investigate interactions between units. Inspired by classic\nexperiments on human speech perception, we study how Wav2Vec2 resolves\nphonotactic constraints. We synthesize sounds on an acoustic continuum between\n/l/ and /r/ and embed them in controlled contexts where only /l/, only /r/, or\nneither occur in English. Like humans, Wav2Vec2 models show a bias towards the\nphonotactically admissable category in processing such ambiguous sounds. Using\nsimple measures to analyze model internals on the level of individual stimuli,\nwe find that this bias emerges in early layers of the model's Transformer\nmodule. This effect is amplified by ASR finetuning but also present in fully\nself-supervised models. Our approach demonstrates how controlled stimulus\ndesigns can help localize specific linguistic knowledge in neural speech\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Interspeech 2024. For code and materials, see\n  https://github.com/mdhk/phonotactic-sensitivity",
    "pdf_url": "http://arxiv.org/pdf/2407.03005v1",
    "published_date": "2024-07-03 11:04:31 UTC",
    "updated_date": "2024-07-03 11:04:31 UTC"
  },
  {
    "arxiv_id": "2407.03004v2",
    "title": "SemioLLM: Evaluating Large Language Models for Diagnostic Reasoning from Unstructured Clinical Narratives in Epilepsy",
    "authors": [
      "Meghal Dani",
      "Muthu Jeyanthi Prakash",
      "Zeynep Akata",
      "Stefanie Liebe"
    ],
    "abstract": "Large Language Models (LLMs) have been shown to encode clinical knowledge.\nMany evaluations, however, rely on structured question-answer benchmarks,\noverlooking critical challenges of interpreting and reasoning about\nunstructured clinical narratives in real-world settings. Using free-text\nclinical descriptions, we present SemioLLM, an evaluation framework that\nbenchmarks 6 state-of-the-art models (GPT-3.5, GPT-4, Mixtral-8x7B, Qwen-72B,\nLlaMa2, LlaMa3) on a core diagnostic task in epilepsy. Leveraging a database of\n1,269 seizure descriptions, we show that most LLMs are able to accurately and\nconfidently generate probabilistic predictions of seizure onset zones in the\nbrain. Most models approach clinician-level performance after prompt\nengineering, with expert-guided chain-of-thought reasoning leading to the most\nconsistent improvements. Performance was further strongly modulated by clinical\nin-context impersonation, narrative length and language context (13.7%, 32.7%\nand 14.2% performance variation, respectively). However, expert analysis of\nreasoning outputs revealed that correct prediction can be based on hallucinated\nknowledge and deficient source citation accuracy, underscoring the need to\nimprove interpretability of LLMs in clinical use. Overall, SemioLLM provides a\nscalable, domain-adaptable framework for evaluating LLMs in clinical\ndisciplines where unstructured verbal descriptions encode diagnostic\ninformation. By identifying both the strengths and limitations of\nstate-of-the-art models, our work supports the development of clinically robust\nand globally applicable AI systems for healthcare.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03004v2",
    "published_date": "2024-07-03 11:02:12 UTC",
    "updated_date": "2025-04-23 14:25:46 UTC"
  },
  {
    "arxiv_id": "2407.02996v2",
    "title": "Are Large Language Models Consistent over Value-laden Questions?",
    "authors": [
      "Jared Moore",
      "Tanvi Deshpande",
      "Diyi Yang"
    ],
    "abstract": "Large language models (LLMs) appear to bias their survey answers toward\ncertain values. Nonetheless, some argue that LLMs are too inconsistent to\nsimulate particular values. Are they? To answer, we first define value\nconsistency as the similarity of answers across (1) paraphrases of one\nquestion, (2) related questions under one topic, (3) multiple-choice and\nopen-ended use-cases of one question, and (4) multilingual translations of a\nquestion to English, Chinese, German, and Japanese. We apply these measures to\nsmall and large, open LLMs including llama-3, as well as gpt-4o, using 8,000\nquestions spanning more than 300 topics. Unlike prior work, we find that models\nare relatively consistent across paraphrases, use-cases, translations, and\nwithin a topic. Still, some inconsistencies remain. Models are more consistent\non uncontroversial topics (e.g., in the U.S., \"Thanksgiving\") than on\ncontroversial ones (\"euthanasia\"). Base models are both more consistent\ncompared to fine-tuned models and are uniform in their consistency across\ntopics, while fine-tuned models are more inconsistent about some topics\n(\"euthanasia\") than others (\"women's rights\") like our human subjects (n=165).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 10 figures, In Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02996v2",
    "published_date": "2024-07-03 10:53:54 UTC",
    "updated_date": "2024-10-01 21:23:18 UTC"
  },
  {
    "arxiv_id": "2407.02994v4",
    "title": "MedPix 2.0: A Comprehensive Multimodal Biomedical Data set for Advanced AI Applications",
    "authors": [
      "Irene Siragusa",
      "Salvatore Contino",
      "Massimo La Ciura",
      "Rosario Alicata",
      "Roberto Pirrone"
    ],
    "abstract": "The increasing interest in developing Artificial Intelligence applications in\nthe medical domain, suffers from the lack of high-quality data set, mainly due\nto privacy-related issues. Moreover, the recent rising of Large Multimodal\nModels (LMM) leads to a need for multimodal medical data sets, where clinical\nreports and findings are attached to the corresponding CT or MR scans. This\npaper illustrates the entire workflow for building the data set MedPix 2.0.\nStarting from the well-known multimodal data set MedPix, mainly used by\nphysicians, nurses and healthcare students for Continuing Medical Education\npurposes, a semi-automatic pipeline was developed to extract visual and textual\ndata followed by a manual curing procedure where noisy samples were removed,\nthus creating a MongoDB database. Along with the data set, we developed a GUI\naimed at navigating efficiently the MongoDB instance, and obtaining the raw\ndata that can be easily used for training and/or fine-tuning LMMs. To enforce\nthis point, we also propose a CLIP-based model trained on MedPix 2.0 for\nscanning modality and location classification tasks. MedPix 2.0 is available on\nGitHub",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02994v4",
    "published_date": "2024-07-03 10:49:21 UTC",
    "updated_date": "2025-04-30 11:41:49 UTC"
  },
  {
    "arxiv_id": "2407.02987v2",
    "title": "LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models",
    "authors": [
      "Hayder Elesedy",
      "Pedro M. Esperança",
      "Silviu Vlad Oprea",
      "Mete Ozay"
    ],
    "abstract": "Guardrails have emerged as an alternative to safety alignment for content\nmoderation of large language models (LLMs). Existing model-based guardrails\nhave not been designed for resource-constrained computational portable devices,\nsuch as mobile phones, more and more of which are running LLM-based\napplications locally. We introduce LoRA-Guard, a parameter-efficient guardrail\nadaptation method that relies on knowledge sharing between LLMs and guardrail\nmodels. LoRA-Guard extracts language features from the LLMs and adapts them for\nthe content moderation task using low-rank adapters, while a dual-path design\nprevents any performance degradation on the generative task. We show that\nLoRA-Guard outperforms existing approaches with 100-1000x lower parameter\noverhead while maintaining accuracy, enabling on-device content moderation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02987v2",
    "published_date": "2024-07-03 10:38:40 UTC",
    "updated_date": "2024-12-18 16:07:28 UTC"
  },
  {
    "arxiv_id": "2407.02978v1",
    "title": "Mast Kalandar at SemEval-2024 Task 8: On the Trail of Textual Origins: RoBERTa-BiLSTM Approach to Detect AI-Generated Text",
    "authors": [
      "Jainit Sushil Bafna",
      "Hardik Mittal",
      "Suyash Sethia",
      "Manish Shrivastava",
      "Radhika Mamidi"
    ],
    "abstract": "Large Language Models (LLMs) have showcased impressive abilities in\ngenerating fluent responses to diverse user queries. However, concerns\nregarding the potential misuse of such texts in journalism, educational, and\nacademic contexts have surfaced. SemEval 2024 introduces the task of\nMultigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text\nDetection, aiming to develop automated systems for identifying\nmachine-generated text and detecting potential misuse. In this paper, we i)\npropose a RoBERTa-BiLSTM based classifier designed to classify text into two\ncategories: AI-generated or human ii) conduct a comparative study of our model\nwith baseline approaches to evaluate its effectiveness. This paper contributes\nto the advancement of automatic text detection systems in addressing the\nchallenges posed by machine-generated text misuse. Our architecture ranked 46th\non the official leaderboard with an accuracy of 80.83 among 125.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "SemEval-2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02978v1",
    "published_date": "2024-07-03 10:22:23 UTC",
    "updated_date": "2024-07-03 10:22:23 UTC"
  },
  {
    "arxiv_id": "2407.02977v1",
    "title": "Large Language Models as Evaluators for Scientific Synthesis",
    "authors": [
      "Julia Evans",
      "Jennifer D'Souza",
      "Sören Auer"
    ],
    "abstract": "Our study explores how well the state-of-the-art Large Language Models\n(LLMs), like GPT-4 and Mistral, can assess the quality of scientific summaries\nor, more fittingly, scientific syntheses, comparing their evaluations to those\nof human annotators. We used a dataset of 100 research questions and their\nsyntheses made by GPT-4 from abstracts of five related papers, checked against\nhuman quality ratings. The study evaluates both the closed-source GPT-4 and the\nopen-source Mistral model's ability to rate these summaries and provide reasons\nfor their judgments. Preliminary results show that LLMs can offer logical\nexplanations that somewhat match the quality ratings, yet a deeper statistical\nanalysis shows a weak correlation between LLM and human ratings, suggesting the\npotential and current limitations of LLMs in scientific synthesis evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "4 pages, forthcoming as part of the KONVENS 2024 proceedings\n  https://konvens-2024.univie.ac.at/",
    "pdf_url": "http://arxiv.org/pdf/2407.02977v1",
    "published_date": "2024-07-03 10:21:27 UTC",
    "updated_date": "2024-07-03 10:21:27 UTC"
  },
  {
    "arxiv_id": "2407.02969v1",
    "title": "Zero-X: A Blockchain-Enabled Open-Set Federated Learning Framework for Zero-Day Attack Detection in IoV",
    "authors": [
      "Abdelaziz Amara korba",
      "Abdelwahab Boualouache",
      "Yacine Ghamri-Doudane"
    ],
    "abstract": "The Internet of Vehicles (IoV) is a crucial technology for Intelligent\nTransportation Systems (ITS) that integrates vehicles with the Internet and\nother entities. The emergence of 5G and the forthcoming 6G networks presents an\nenormous potential to transform the IoV by enabling ultra-reliable,\nlow-latency, and high-bandwidth communications. Nevertheless, as connectivity\nexpands, cybersecurity threats have become a significant concern. The issue has\nbeen further exacerbated by the rising number of zero-day (0-day) attacks,\nwhich can exploit unknown vulnerabilities and bypass existing Intrusion\nDetection Systems (IDSs). In this paper, we propose Zero-X, an innovative\nsecurity framework that effectively detects both 0-day and N-day attacks. The\nframework achieves this by combining deep neural networks with Open-Set\nRecognition (OSR). Our approach introduces a novel scheme that uses blockchain\ntechnology to facilitate trusted and decentralized federated learning (FL) of\nthe ZeroX framework. This scheme also prioritizes privacy preservation,\nenabling both CAVs and Security Operation Centers (SOCs) to contribute their\nunique knowledge while protecting the privacy of their sensitive data. To the\nbest of our knowledge, this is the first work to leverage OSR in combination\nwith privacy-preserving FL to identify both 0-day and N-day attacks in the\nrealm of IoV. The in-depth experiments on two recent network traffic datasets\nshow that the proposed framework achieved a high detection rate while\nminimizing the false positive rate. Comparison with related work showed that\nthe Zero-X framework outperforms existing solutions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02969v1",
    "published_date": "2024-07-03 10:06:15 UTC",
    "updated_date": "2024-07-03 10:06:15 UTC"
  },
  {
    "arxiv_id": "2407.02968v1",
    "title": "Unified Anomaly Detection methods on Edge Device using Knowledge Distillation and Quantization",
    "authors": [
      "Sushovan Jena",
      "Arya Pulkit",
      "Kajal Singh",
      "Anoushka Banerjee",
      "Sharad Joshi",
      "Ananth Ganesh",
      "Dinesh Singh",
      "Arnav Bhavsar"
    ],
    "abstract": "With the rapid advances in deep learning and smart manufacturing in Industry\n4.0, there is an imperative for high-throughput, high-performance, and fully\nintegrated visual inspection systems. Most anomaly detection approaches using\ndefect detection datasets, such as MVTec AD, employ one-class models that\nrequire fitting separate models for each class. On the contrary, unified models\neliminate the need for fitting separate models for each class and significantly\nreduce cost and memory requirements. Thus, in this work, we experiment with\nconsidering a unified multi-class setup. Our experimental study shows that\nmulti-class models perform at par with one-class models for the standard MVTec\nAD dataset. Hence, this indicates that there may not be a need to learn\nseparate object/class-wise models when the object classes are significantly\ndifferent from each other, as is the case of the dataset considered.\nFurthermore, we have deployed three different unified lightweight architectures\non the CPU and an edge device (NVIDIA Jetson Xavier NX). We analyze the\nquantized multi-class anomaly detection models in terms of latency and memory\nrequirements for deployment on the edge device while comparing\nquantization-aware training (QAT) and post-training quantization (PTQ) for\nperformance at different precision widths. In addition, we explored two\ndifferent methods of calibration required in post-training scenarios and show\nthat one of them performs notably better, highlighting its importance for\nunsupervised tasks. Due to quantization, the performance drop in PTQ is further\ncompensated by QAT, which yields at par performance with the original 32-bit\nFloating point in two of the models considered.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CC",
      "cs.ET",
      "68T07",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.02968v1",
    "published_date": "2024-07-03 10:04:48 UTC",
    "updated_date": "2024-07-03 10:04:48 UTC"
  },
  {
    "arxiv_id": "2407.06085v1",
    "title": "LLMcap: Large Language Model for Unsupervised PCAP Failure Detection",
    "authors": [
      "Lukasz Tulczyjew",
      "Kinan Jarrah",
      "Charles Abondo",
      "Dina Bennett",
      "Nathanael Weill"
    ],
    "abstract": "The integration of advanced technologies into telecommunication networks\ncomplicates troubleshooting, posing challenges for manual error identification\nin Packet Capture (PCAP) data. This manual approach, requiring substantial\nresources, becomes impractical at larger scales. Machine learning (ML) methods\noffer alternatives, but the scarcity of labeled data limits accuracy. In this\nstudy, we propose a self-supervised, large language model-based (LLMcap) method\nfor PCAP failure detection. LLMcap leverages language-learning abilities and\nemploys masked language modeling to learn grammar, context, and structure.\nTested rigorously on various PCAPs, it demonstrates high accuracy despite the\nabsence of labeled data during training, presenting a promising solution for\nefficient network analysis. Index Terms: Network troubleshooting, Packet\nCapture Analysis, Self-Supervised Learning, Large Language Model, Network\nQuality of Service, Network Performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "Copyright 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
    "pdf_url": "http://arxiv.org/pdf/2407.06085v1",
    "published_date": "2024-07-03 09:59:27 UTC",
    "updated_date": "2024-07-03 09:59:27 UTC"
  },
  {
    "arxiv_id": "2407.02961v2",
    "title": "Towards a Scalable Reference-Free Evaluation of Generative Models",
    "authors": [
      "Azim Ospanov",
      "Jingwei Zhang",
      "Mohammad Jalali",
      "Xuenan Cao",
      "Andrej Bogdanov",
      "Farzan Farnia"
    ],
    "abstract": "While standard evaluation scores for generative models are mostly\nreference-based, a reference-dependent assessment of generative models could be\ngenerally difficult due to the unavailability of applicable reference datasets.\nRecently, the reference-free entropy scores, VENDI and RKE, have been proposed\nto evaluate the diversity of generated data. However, estimating these scores\nfrom data leads to significant computational costs for large-scale generative\nmodels. In this work, we leverage the random Fourier features framework to\nreduce the computational price and propose the Fourier-based Kernel Entropy\nApproximation (FKEA) method. We utilize FKEA's approximated eigenspectrum of\nthe kernel matrix to efficiently estimate the mentioned entropy scores.\nFurthermore, we show the application of FKEA's proxy eigenvectors to reveal the\nmethod's identified modes in evaluating the diversity of produced samples. We\nprovide a stochastic implementation of the FKEA assessment algorithm with a\ncomplexity $O(n)$ linearly growing with sample size $n$. We extensively\nevaluate FKEA's numerical performance in application to standard image, text,\nand video datasets. Our empirical results indicate the method's scalability and\ninterpretability applied to large-scale generative models. The codebase is\navailable at https://github.com/aziksh-ospanov/FKEA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02961v2",
    "published_date": "2024-07-03 09:54:58 UTC",
    "updated_date": "2024-11-05 18:16:21 UTC"
  },
  {
    "arxiv_id": "2407.02960v2",
    "title": "ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets",
    "authors": [
      "Ahmed Frikha",
      "Nassim Walha",
      "Ricardo Mendes",
      "Krishna Kanth Nakka",
      "Xue Jiang",
      "Xuebing Zhou"
    ],
    "abstract": "This work addresses the timely yet underexplored problem of performing\ninference and finetuning of a proprietary LLM owned by a model provider entity\non the confidential/private data of another data owner entity, in a way that\nensures the confidentiality of both the model and the data. Hereby, the\nfinetuning is conducted offsite, i.e., on the computation infrastructure of a\nthird-party cloud provider. We tackle this problem by proposing ObfuscaTune, a\nnovel, efficient and fully utility-preserving approach that combines a simple\nyet effective obfuscation technique with an efficient usage of confidential\ncomputing (only 5% of the model parameters are placed on TEE). We empirically\ndemonstrate the effectiveness of ObfuscaTune by validating it on GPT-2 models\nwith different sizes on four NLP benchmark datasets. Finally, we compare to a\nna\\\"ive version of our approach to highlight the necessity of using random\nmatrices with low condition numbers in our approach to reduce errors induced by\nthe obfuscation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at AAAI 2025 (PPAI Workshop)",
    "pdf_url": "http://arxiv.org/pdf/2407.02960v2",
    "published_date": "2024-07-03 09:54:08 UTC",
    "updated_date": "2025-01-12 16:22:04 UTC"
  },
  {
    "arxiv_id": "2407.02956v2",
    "title": "IncogniText: Privacy-enhancing Conditional Text Anonymization via LLM-based Private Attribute Randomization",
    "authors": [
      "Ahmed Frikha",
      "Nassim Walha",
      "Krishna Kanth Nakka",
      "Ricardo Mendes",
      "Xue Jiang",
      "Xuebing Zhou"
    ],
    "abstract": "In this work, we address the problem of text anonymization where the goal is\nto prevent adversaries from correctly inferring private attributes of the\nauthor, while keeping the text utility, i.e., meaning and semantics. We propose\nIncogniText, a technique that anonymizes the text to mislead a potential\nadversary into predicting a wrong private attribute value. Our empirical\nevaluation shows a reduction of private attribute leakage by more than 90%\nacross 8 different private attributes. Finally, we demonstrate the maturity of\nIncogniText for real-world applications by distilling its anonymization\ncapability into a set of LoRA parameters associated with an on-device model.\nOur results show the possibility of reducing privacy leakage by more than half\nwith limited impact on utility.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at NeurIPS 2024 - Safe GenAI Workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.02956v2",
    "published_date": "2024-07-03 09:49:03 UTC",
    "updated_date": "2025-02-02 16:51:13 UTC"
  },
  {
    "arxiv_id": "2407.02943v1",
    "title": "PII-Compass: Guiding LLM training data extraction prompts towards the target PII via grounding",
    "authors": [
      "Krishna Kanth Nakka",
      "Ahmed Frikha",
      "Ricardo Mendes",
      "Xue Jiang",
      "Xuebing Zhou"
    ],
    "abstract": "The latest and most impactful advances in large models stem from their\nincreased size. Unfortunately, this translates into an improved memorization\ncapacity, raising data privacy concerns. Specifically, it has been shown that\nmodels can output personal identifiable information (PII) contained in their\ntraining data. However, reported PIII extraction performance varies widely, and\nthere is no consensus on the optimal methodology to evaluate this risk,\nresulting in underestimating realistic adversaries. In this work, we\nempirically demonstrate that it is possible to improve the extractability of\nPII by over ten-fold by grounding the prefix of the manually constructed\nextraction prompt with in-domain data. Our approach, PII-Compass, achieves\nphone number extraction rates of 0.92%, 3.9%, and 6.86% with 1, 128, and 2308\nqueries, respectively, i.e., the phone number of 1 person in 15 is extractable.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02943v1",
    "published_date": "2024-07-03 09:20:04 UTC",
    "updated_date": "2024-07-03 09:20:04 UTC"
  },
  {
    "arxiv_id": "2407.02936v2",
    "title": "GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models",
    "authors": [
      "Zike Yuan",
      "Ming Liu",
      "Hui Wang",
      "Bing Qin"
    ],
    "abstract": "Evaluating the graph comprehension and reasoning abilities of Large Language\nModels (LLMs) is challenging and often incomplete. Existing benchmarks focus\nprimarily on pure graph understanding, lacking a comprehensive evaluation\nacross all graph types and detailed capability definitions. This paper presents\nGraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and\nreasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and\ntest models on pure graph and heterogeneous graphs, subdividing capabilities\ninto 10 distinct areas tested through 19 tasks. Our benchmark includes 11\ndatasets with 5,140 graphs of varying complexity. We evaluate four\nclosed-source and eight open-source LLMs, conducting thorough analyses from\nboth ability and task perspectives. Key findings reveal that OpenAI o1 model\nhas amazing comprehension and reasoning capabilities, semantic enrichment\nenhances reasoning performance, node ordering impacts task success, and the\nability to process longer texts does not necessarily improve graph\ncomprehension or reasoning.GraCoRe is open-sourced at\nhttps://github.com/ZIKEYUAN/GraCoRe",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02936v2",
    "published_date": "2024-07-03 09:12:38 UTC",
    "updated_date": "2025-02-26 09:17:32 UTC"
  },
  {
    "arxiv_id": "2407.11027v1",
    "title": "A robust three-way classifier with shadowed granular-balls based on justifiable granularity",
    "authors": [
      "Jie Yang",
      "Lingyun Xiaodiao",
      "Guoyin Wang",
      "Witold Pedrycz",
      "Shuyin Xia",
      "Qinghua Zhang",
      "Di Wu"
    ],
    "abstract": "The granular-ball (GB)-based classifier introduced by Xia, exhibits\nadaptability in creating coarse-grained information granules for input, thereby\nenhancing its generality and flexibility. Nevertheless, the current GB-based\nclassifiers rigidly assign a specific class label to each data instance and\nlacks of the necessary strategies to address uncertain instances. These\nfar-fetched certain classification approachs toward uncertain instances may\nsuffer considerable risks. To solve this problem, we construct a robust\nthree-way classifier with shadowed GBs for uncertain data. Firstly, combine\nwith information entropy, we propose an enhanced GB generation method with the\nprinciple of justifiable granularity. Subsequently, based on minimum\nuncertainty, a shadowed mapping is utilized to partition a GB into Core region,\nImportant region and Unessential region. Based on the constructed shadowed GBs,\nwe establish a three-way classifier to categorize data instances into certain\nclasses and uncertain case. Finally, extensive comparative experiments are\nconducted with 2 three-way classifiers, 3 state-of-the-art GB-based\nclassifiers, and 3 classical machine learning classifiers on 12 public\nbenchmark datasets. The results show that our model demonstrates robustness in\nmanaging uncertain data and effectively mitigates classification risks.\nFurthermore, our model almost outperforms the other comparison methods in both\neffectiveness and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11027v1",
    "published_date": "2024-07-03 08:54:45 UTC",
    "updated_date": "2024-07-03 08:54:45 UTC"
  },
  {
    "arxiv_id": "2407.02917v1",
    "title": "Towards Negotiative Dialogue for the Talkamatic Dialogue Manager",
    "authors": [
      "Staffan Larsson",
      "Alexander Berman",
      "David Hjelm"
    ],
    "abstract": "The paper describes a number of dialogue phenomena associated with\nnegotiative dialogue, as implemented in a development version of the Talkamatic\nDialogue Manager (TDM). This implementation is an initial step towards full\ncoverage of general features of negotiative dialogue in TDM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02917v1",
    "published_date": "2024-07-03 08:49:18 UTC",
    "updated_date": "2024-07-03 08:49:18 UTC"
  },
  {
    "arxiv_id": "2407.02913v1",
    "title": "SFC: Achieve Accurate Fast Convolution under Low-precision Arithmetic",
    "authors": [
      "Liulu He",
      "Yufei Zhao",
      "Rui Gao",
      "Yuan Du",
      "Li Du"
    ],
    "abstract": "Fast convolution algorithms, including Winograd and FFT, can efficiently\naccelerate convolution operations in deep models. However, these algorithms\ndepend on high-precision arithmetic to maintain inference accuracy, which\nconflicts with the model quantization. To resolve this conflict and further\nimprove the efficiency of quantized convolution, we proposes SFC, a new algebra\ntransform for fast convolution by extending the Discrete Fourier Transform\n(DFT) with symbolic computing, in which only additions are required to perform\nthe transformation at specific transform points, avoiding the calculation of\nirrational number and reducing the requirement for precision. Additionally, we\nenhance convolution efficiency by introducing correction terms to convert\ninvalid circular convolution outputs of the Fourier method into effective ones.\nThe numerical error analysis is presented for the first time in this type of\nwork and proves that our algorithms can provide a 3.68x multiplication\nreduction for 3x3 convolution, while the Winograd algorithm only achieves a\n2.25x reduction with similarly low numerical errors. Experiments carried out on\nbenchmarks and FPGA show that our new algorithms can further improve the\ncomputation efficiency of quantized models while maintaining accuracy,\nsurpassing both the quantization-alone method and existing works on fast\nconvolution quantization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "eess.IV",
      "eess.SP",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02913v1",
    "published_date": "2024-07-03 08:38:14 UTC",
    "updated_date": "2024-07-03 08:38:14 UTC"
  },
  {
    "arxiv_id": "2407.03387v3",
    "title": "ConCodeEval: Evaluating Large Language Models for Code Constraints in Domain-Specific Languages",
    "authors": [
      "Mehant Kammakomati",
      "Sameer Pimparkhede",
      "Srikanth Tamilselvam",
      "Prince Kumar",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "Recent work shows Large Language Models (LLMs) struggle to understand natural\nlanguage constraints for various text generation tasks in zero- and few-shot\nsettings. While, in the code domain, there is wide usage of constraints in code\nformat to maintain the integrity of code written in Domain-Specific Languages\n(DSLs) like JSON and YAML which are widely used for system-level programming\ntasks in enterprises. Given that LLMs are increasingly used for system-level\ncode tasks, evaluating if they can comprehend these code constraints is\ncrucial. However, no work has been done to evaluate their controllability over\ncode constraints. Hence, we introduce ConCodeEval, a first-of-its-kind\nbenchmark having two novel tasks for code constraints across five\nrepresentations. Our findings suggest that language models struggle with code\nconstraints. Code languages that perform excellently for normal code tasks do\nnot perform well when the same languages represent fine-grained constraints.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03387v3",
    "published_date": "2024-07-03 08:36:13 UTC",
    "updated_date": "2025-03-24 11:44:59 UTC"
  },
  {
    "arxiv_id": "2407.13782v1",
    "title": "Self-supervised ASR Models and Features For Dysarthric and Elderly Speech Recognition",
    "authors": [
      "Shujie Hu",
      "Xurong Xie",
      "Mengzhe Geng",
      "Zengrui Jin",
      "Jiajun Deng",
      "Guinan Li",
      "Yi Wang",
      "Mingyu Cui",
      "Tianzi Wang",
      "Helen Meng",
      "Xunying Liu"
    ],
    "abstract": "Self-supervised learning (SSL) based speech foundation models have been\napplied to a wide range of ASR tasks. However, their application to dysarthric\nand elderly speech via data-intensive parameter fine-tuning is confronted by\nin-domain data scarcity and mismatch. To this end, this paper explores a series\nof approaches to integrate domain fine-tuned SSL pre-trained models and their\nfeatures into TDNN and Conformer ASR systems for dysarthric and elderly speech\nrecognition. These include: a) input feature fusion between standard acoustic\nfrontends and domain fine-tuned SSL speech representations; b) frame-level\njoint decoding between TDNN systems separately trained using standard acoustic\nfeatures alone and those with additional domain fine-tuned SSL features; and c)\nmulti-pass decoding involving the TDNN/Conformer system outputs to be rescored\nusing domain fine-tuned pre-trained ASR models. In addition, fine-tuned SSL\nspeech features are used in acoustic-to-articulatory (A2A) inversion to\nconstruct multi-modal ASR systems. Experiments are conducted on four tasks: the\nEnglish UASpeech and TORGO dysarthric speech corpora; and the English\nDementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech datasets. The TDNN\nsystems constructed by integrating domain-adapted HuBERT, wav2vec2-conformer or\nmulti-lingual XLSR models and their features consistently outperform the\nstandalone fine-tuned SSL pre-trained models. These systems produced\nstatistically significant WER or CER reductions of 6.53%, 1.90%, 2.04% and\n7.97% absolute (24.10%, 23.84%, 10.14% and 31.39% relative) on the four tasks\nrespectively. Consistent improvements in Alzheimer's Disease detection accuracy\nare also obtained using the DementiaBank Pitt elderly speech recognition\noutputs.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
    "pdf_url": "http://arxiv.org/pdf/2407.13782v1",
    "published_date": "2024-07-03 08:33:39 UTC",
    "updated_date": "2024-07-03 08:33:39 UTC"
  },
  {
    "arxiv_id": "2407.02904v1",
    "title": "The Shortcomings of Force-from-Motion in Robot Learning",
    "authors": [
      "Elie Aljalbout",
      "Felix Frank",
      "Patrick van der Smagt",
      "Alexandros Paraschos"
    ],
    "abstract": "Robotic manipulation requires accurate motion and physical interaction\ncontrol. However, current robot learning approaches focus on motion-centric\naction spaces that do not explicitly give the policy control over the\ninteraction. In this paper, we discuss the repercussions of this choice and\nargue for more interaction-explicit action spaces in robot learning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.8; I.2.9"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02904v1",
    "published_date": "2024-07-03 08:23:02 UTC",
    "updated_date": "2024-07-03 08:23:02 UTC"
  },
  {
    "arxiv_id": "2407.02894v1",
    "title": "Translatotron-V(ison): An End-to-End Model for In-Image Machine Translation",
    "authors": [
      "Zhibin Lan",
      "Liqiang Niu",
      "Fandong Meng",
      "Jie Zhou",
      "Min Zhang",
      "Jinsong Su"
    ],
    "abstract": "In-image machine translation (IIMT) aims to translate an image containing\ntexts in source language into an image containing translations in target\nlanguage. In this regard, conventional cascaded methods suffer from issues such\nas error propagation, massive parameters, and difficulties in deployment and\nretaining visual characteristics of the input image. Thus, constructing\nend-to-end models has become an option, which, however, faces two main\nchallenges: 1) the huge modeling burden, as it is required to simultaneously\nlearn alignment across languages and preserve the visual characteristics of the\ninput image; 2) the difficulties of directly predicting excessively lengthy\npixel sequences. In this paper, we propose \\textit{Translatotron-V(ision)}, an\nend-to-end IIMT model consisting of four modules. In addition to an image\nencoder, and an image decoder, our model contains a target text decoder and an\nimage tokenizer. Among them, the target text decoder is used to alleviate the\nlanguage alignment burden, and the image tokenizer converts long sequences of\npixels into shorter sequences of visual tokens, preventing the model from\nfocusing on low-level visual features. Besides, we present a two-stage training\nframework for our model to assist the model in learning alignment across\nmodalities and languages. Finally, we propose a location-aware evaluation\nmetric called Structure-BLEU to assess the translation quality of the generated\nimages. Experimental results demonstrate that our model achieves competitive\nperformance compared to cascaded models with only 70.9\\% of parameters, and\nsignificantly outperforms the pixel-level end-to-end IIMT model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2407.02894v1",
    "published_date": "2024-07-03 08:15:39 UTC",
    "updated_date": "2024-07-03 08:15:39 UTC"
  },
  {
    "arxiv_id": "2407.02891v1",
    "title": "GPTQT: Quantize Large Language Models Twice to Push the Efficiency",
    "authors": [
      "Yipin Guo",
      "Yilin Lang",
      "Qinyuan Ren"
    ],
    "abstract": "Due to their large size, generative Large Language Models (LLMs) require\nsignificant computing and storage resources. This paper introduces a new\npost-training quantization method, GPTQT, to reduce memory usage and enhance\nprocessing speed by expressing the weight of LLM in 3bit/2bit. Practice has\nshown that minimizing the quantization error of weights is ineffective, leading\nto overfitting. Therefore, GPTQT employs a progressive two-step approach:\ninitially quantizing weights using Linear quantization to a relatively high\nbit, followed by converting obtained int weight to lower bit binary coding. A\nre-explore strategy is proposed to optimize initial scaling factor. During\ninference, these steps are merged into pure binary coding, enabling efficient\ncomputation. Testing across various models and datasets confirms GPTQT's\neffectiveness. Compared to the strong 3-bit quantization baseline, GPTQT\nfurther reduces perplexity by 4.01 on opt-66B and increases speed by 1.24 times\non opt-30b. The results on Llama2 show that GPTQT is currently the best binary\ncoding quantization method for such kind of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by 11th IEEE International Conference on Cybernetics and\n  Intelligent Systems",
    "pdf_url": "http://arxiv.org/pdf/2407.02891v1",
    "published_date": "2024-07-03 08:08:01 UTC",
    "updated_date": "2024-07-03 08:08:01 UTC"
  },
  {
    "arxiv_id": "2407.02888v1",
    "title": "Joint Optimization of Resource Allocation and Data Selection for Fast and Cost-Efficient Federated Edge Learning",
    "authors": [
      "Yunjian Jia",
      "Zhen Huang",
      "Jiping Yan",
      "Yulu Zhang",
      "Kun Luo",
      "Wanli Wen"
    ],
    "abstract": "Deploying federated learning at the wireless edge introduces federated edge\nlearning (FEEL). Given FEEL's limited communication resources and potential\nmislabeled data on devices, improper resource allocation or data selection can\nhurt convergence speed and increase training costs. Thus, to realize an\nefficient FEEL system, this paper emphasizes jointly optimizing resource\nallocation and data selection. Specifically, in this work, through rigorously\nmodeling the training process and deriving an upper bound on FEEL's one-round\nconvergence rate, we establish a problem of joint resource allocation and data\nselection, which, unfortunately, cannot be solved directly. Toward this end, we\nequivalently transform the original problem into a solvable form via a variable\nsubstitution and then break it into two subproblems, that is, the resource\nallocation problem and the data selection problem. The two subproblems are\nmixed-integer non-convex and integer non-convex problems, respectively, and\nachieving their optimal solutions is a challenging task. Based on the matching\ntheory and applying the convex-concave procedure and gradient projection\nmethods, we devise a low-complexity suboptimal algorithm for the two\nsubproblems, respectively. Finally, the superiority of our proposed scheme of\njoint resource allocation and data selection is validated by numerical results.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02888v1",
    "published_date": "2024-07-03 08:03:59 UTC",
    "updated_date": "2024-07-03 08:03:59 UTC"
  },
  {
    "arxiv_id": "2407.02884v1",
    "title": "Complex Event Recognition with Symbolic Register Transducers: Extended Technical Report",
    "authors": [
      "Elias Alevizos",
      "Alexander Artikis",
      "Georgios Paliouras"
    ],
    "abstract": "We present a system for Complex Event Recognition (CER) based on automata.\nWhile multiple such systems have been described in the literature, they\ntypically suffer from a lack of clear and denotational semantics, a limitation\nwhich often leads to confusion with respect to their expressive power. In order\nto address this issue, our system is based on an automaton model which is a\ncombination of symbolic and register automata. We extend previous work on these\ntypes of automata, in order to construct a formalism with clear semantics and a\ncorresponding automaton model whose properties can be formally investigated. We\ncall such automata Symbolic Register Transducers (SRT). We show that SRT are\nclosed under various operators, but are not in general closed under complement\nand they are not determinizable. However, they are closed under these\noperations when a window operator, quintessential in Complex Event Recognition,\nis used. We show how SRT can be used in CER in order to detect patterns upon\nstreams of events, using our framework that provides declarative and\ncompositional semantics, and that allows for a systematic treatment of such\nautomata. For SRT to work in pattern detection, we allow them to mark events\nfrom the input stream as belonging to a complex event or not, hence the name\n\"transducers\". We also present an implementation of SRT which can perform CER.\nWe compare our SRT-based CER engine against other state-of-the-art CER systems\nand show that it is both more expressive and more efficient.",
    "categories": [
      "cs.FL",
      "cs.AI",
      "cs.DB",
      "F.1.1; F.4.3; I.2.4"
    ],
    "primary_category": "cs.FL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2110.04032",
    "pdf_url": "http://arxiv.org/pdf/2407.02884v1",
    "published_date": "2024-07-03 07:59:13 UTC",
    "updated_date": "2024-07-03 07:59:13 UTC"
  },
  {
    "arxiv_id": "2407.02881v1",
    "title": "ShiftAddAug: Augment Multiplication-Free Tiny Neural Network with Hybrid Computation",
    "authors": [
      "Yipin Guo",
      "Zihao Li",
      "Yilin Lang",
      "Qinyuan Ren"
    ],
    "abstract": "Operators devoid of multiplication, such as Shift and Add, have gained\nprominence for their compatibility with hardware. However, neural networks\n(NNs) employing these operators typically exhibit lower accuracy compared to\nconventional NNs with identical structures. ShiftAddAug uses costly\nmultiplication to augment efficient but less powerful multiplication-free\noperators, improving performance without any inference overhead. It puts a\nShiftAdd tiny NN into a large multiplicative model and encourages it to be\ntrained as a sub-model to obtain additional supervision. In order to solve the\nweight discrepancy problem between hybrid operators, a new weight sharing\nmethod is proposed. Additionally, a novel two stage neural architecture search\nis used to obtain better augmentation effects for smaller but stronger\nmultiplication-free tiny neural networks. The superiority of ShiftAddAug is\nvalidated through experiments in image classification and semantic\nsegmentation, consistently delivering noteworthy enhancements. Remarkably, it\nsecures up to a 4.95% increase in accuracy on the CIFAR100 compared to its\ndirectly trained counterparts, even surpassing the performance of\nmultiplicative NNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by 2024 CVPR Workshop : Efficient Deep Learning for Computer\n  Vision",
    "pdf_url": "http://arxiv.org/pdf/2407.02881v1",
    "published_date": "2024-07-03 07:56:51 UTC",
    "updated_date": "2024-07-03 07:56:51 UTC"
  },
  {
    "arxiv_id": "2407.02880v2",
    "title": "Knowledge Composition using Task Vectors with Learned Anisotropic Scaling",
    "authors": [
      "Frederic Z. Zhang",
      "Paul Albert",
      "Cristian Rodriguez-Opazo",
      "Anton van den Hengel",
      "Ehsan Abbasnejad"
    ],
    "abstract": "Pre-trained models produce strong generic representations that can be adapted\nvia fine-tuning. The learned weight difference relative to the pre-trained\nmodel, known as a task vector, characterises the direction and stride of\nfine-tuning. The significance of task vectors is such that simple arithmetic\noperations on them can be used to combine diverse representations from\ndifferent domains. This paper builds on these properties of task vectors and\naims to answer (1) whether components of task vectors, particularly parameter\nblocks, exhibit similar characteristics, and (2) how such blocks can be used to\nenhance knowledge composition and transfer. To this end, we introduce aTLAS, an\nalgorithm that linearly combines parameter blocks with different learned\ncoefficients, resulting in anisotropic scaling at the task vector level. We\nshow that such linear combinations explicitly exploit the low intrinsic\ndimensionality of pre-trained models, with only a few coefficients being the\nlearnable parameters. Furthermore, composition of parameter blocks leverages\nthe already learned representations, thereby reducing the dependency on large\namounts of data. We demonstrate the effectiveness of our method in task\narithmetic, few-shot recognition and test-time adaptation, with supervised or\nunsupervised objectives. In particular, we show that (1) learned anisotropic\nscaling allows task vectors to be more disentangled, causing less interference\nin composition; (2) task vector composition excels with scarce or no labeled\ndata and is less prone to domain shift, thus leading to better\ngeneralisability; (3) mixing the most informative parameter blocks across\ndifferent task vectors prior to training can reduce the memory footprint and\nimprove the flexibility of knowledge transfer. Moreover, we show the potential\nof aTLAS as a PEFT method, particularly with less data, and demonstrate its\nscalibility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS'24",
    "pdf_url": "http://arxiv.org/pdf/2407.02880v2",
    "published_date": "2024-07-03 07:54:08 UTC",
    "updated_date": "2024-10-29 05:10:30 UTC"
  },
  {
    "arxiv_id": "2407.02878v2",
    "title": "Efficient Fusion and Task Guided Embedding for End-to-end Autonomous Driving",
    "authors": [
      "Yipin Guo",
      "Yilin Lang",
      "Qinyuan Ren"
    ],
    "abstract": "To address the challenges of sensor fusion and safety risk prediction,\ncontemporary closed-loop autonomous driving neural networks leveraging\nimitation learning typically require a substantial volume of parameters and\ncomputational resources to run neural networks. Given the constrained\ncomputational capacities of onboard vehicular computers, we introduce a compact\nyet potent solution named EfficientFuser. This approach employs EfficientViT\nfor visual information extraction and integrates feature maps via cross\nattention. Subsequently, it utilizes a decoder-only transformer for the\namalgamation of multiple features. For prediction purposes, learnable vectors\nare embedded as tokens to probe the association between the task and sensor\nfeatures through attention. Evaluated on the CARLA simulation platform,\nEfficientFuser demonstrates remarkable efficiency, utilizing merely 37.6% of\nthe parameters and 8.7% of the computations compared to the state-of-the-art\nlightweight method with only 0.4% lower driving score, and the safety score\nneared that of the leading safety-enhanced method, showcasing its efficacy and\npotential for practical deployment in autonomous driving systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Best Student Paper Award of the IEEE 13th Data-Driven Control and\n  Learning Systems Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.02878v2",
    "published_date": "2024-07-03 07:45:58 UTC",
    "updated_date": "2024-07-17 00:50:39 UTC"
  },
  {
    "arxiv_id": "2407.02870v2",
    "title": "Membership Inference Attacks Against Time-Series Models",
    "authors": [
      "Noam Koren",
      "Abigail Goldsteen",
      "Guy Amit",
      "Ariel Farkash"
    ],
    "abstract": "Analyzing time-series data that contains personal information, particularly\nin the medical field, presents serious privacy concerns. Sensitive health data\nfrom patients is often used to train machine learning models for diagnostics\nand ongoing care. Assessing the privacy risk of such models is crucial to\nmaking knowledgeable decisions on whether to use a model in production or share\nit with third parties. Membership Inference Attacks (MIA) are a key method for\nthis kind of evaluation, however time-series prediction models have not been\nthoroughly studied in this context. We explore existing MIA techniques on\ntime-series models, and introduce new features, focusing on the seasonality and\ntrend components of the data. Seasonality is estimated using a multivariate\nFourier transform, and a low-degree polynomial is used to approximate trends.\nWe applied these techniques to various types of time-series models, using\ndatasets from the health domain. Our results demonstrate that these new\nfeatures enhance the effectiveness of MIAs in identifying membership, improving\nthe understanding of privacy risks in medical data applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.02870v2",
    "published_date": "2024-07-03 07:34:49 UTC",
    "updated_date": "2024-09-22 10:35:09 UTC"
  },
  {
    "arxiv_id": "2407.02863v1",
    "title": "Fast maneuver recovery from aerial observation: trajectory clustering and outliers rejection",
    "authors": [
      "Nelson de Moura",
      "Augustin Gervreau-Mercier",
      "Fernando Garrido",
      "Fawzi Nashashibi"
    ],
    "abstract": "The implementation of road user models that realistically reproduce a\ncredible behavior in a multi-agentsimulation is still an open problem. A\ndata-driven approach consists on to deduce behaviors that may exist in real\nsituation to obtain different types of trajectories from a large set of\nobservations. The data, and its classification, could then be used to train\nmodels capable to extrapolate such behavior. Cars and two different types of\nVulnerable Road Users (VRU) will be considered by the trajectory clustering\nmethods proposed: pedestrians and cyclists. The results reported here evaluate\nmethods to extract well-defined trajectory classes from raw data without the\nuse of map information while also separating ''eccentric'' or incomplete\ntrajectories from the ones that are complete and representative in any\nscenario. Two environments will serve as test for the methods develop, three\ndifferent intersections and one roundabout. The resulting clusters of\ntrajectories can then be used for prediction or learning tasks or discarded if\nit is composed by outliers.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02863v1",
    "published_date": "2024-07-03 07:22:21 UTC",
    "updated_date": "2024-07-03 07:22:21 UTC"
  },
  {
    "arxiv_id": "2407.11026v2",
    "title": "Precise and Efficient Orbit Prediction in LEO with Machine Learning using Exogenous Variables",
    "authors": [
      "Francisco Caldas",
      "Cláudia Soares"
    ],
    "abstract": "The increasing volume of space objects in Earth's orbit presents a\nsignificant challenge for Space Situational Awareness (SSA). And in particular,\naccurate orbit prediction is crucial to anticipate the position and velocity of\nspace objects, for collision avoidance and space debris mitigation. When\nperforming Orbit Prediction (OP), it is necessary to consider the impact of\nnon-conservative forces, such as atmospheric drag and gravitational\nperturbations, that contribute to uncertainty around the future position of\nspacecraft and space debris alike. Conventional propagator methods like the\nSGP4 inadequately account for these forces, while numerical propagators are\nable to model the forces at a high computational cost. To address these\nlimitations, we propose an orbit prediction algorithm utilizing machine\nlearning. This algorithm forecasts state vectors on a spacecraft using past\npositions and environmental variables like atmospheric density from external\nsources. The orbital data used in the paper is gathered from precision\nephemeris data from the International Laser Ranging Service (ILRS), for the\nperiod of almost a year. We show how the use of machine learning and\ntime-series techniques can produce low positioning errors at a very low\ncomputational cost, thus significantly improving SSA capabilities by providing\nfaster and reliable orbit determination for an ever increasing number of space\nobjects.",
    "categories": [
      "cs.LG",
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "presented at IEEE WCCI CEC Congress 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11026v2",
    "published_date": "2024-07-03 07:12:33 UTC",
    "updated_date": "2024-07-27 22:07:42 UTC"
  },
  {
    "arxiv_id": "2407.11025v4",
    "title": "Backdoor Graph Condensation",
    "authors": [
      "Jiahao Wu",
      "Ning Lu",
      "Zeiyu Dai",
      "Kun Wang",
      "Wenqi Fan",
      "Shengcai Liu",
      "Qing Li",
      "Ke Tang"
    ],
    "abstract": "Graph condensation has recently emerged as a prevalent technique to improve\nthe training efficiency for graph neural networks (GNNs). It condenses a large\ngraph into a small one such that a GNN trained on this small synthetic graph\ncan achieve comparable performance to a GNN trained on the large graph.\nHowever, while existing graph condensation studies mainly focus on the best\ntrade-off between graph size and the GNNs' performance (model utility), they\noverlook the security issues of graph condensation. To bridge this gap, we\nfirst explore backdoor attack against the GNNs trained on the condensed graphs.\n  We introduce an effective backdoor attack against graph condensation, termed\nBGC. This attack aims to (1) preserve the condensed graph quality despite\ntrigger injection, and (2) ensure trigger efficacy through the condensation\nprocess, achieving a high attack success rate. Specifically, BGC consistently\nupdates triggers during condensation and targets representative nodes for\npoisoning. Extensive experiments demonstrate the effectiveness of our attack.\nBGC achieves a high attack success rate (close to 1.0) and good model utility\nin all cases. Furthermore, the results against multiple defense methods\ndemonstrate BGC's resilience under their defenses. Finally, we analyze the key\nhyperparameters that influence the attack performance. Our code is available\nat: https://github.com/JiahaoWuGit/BGC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "ICDE 2025 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2407.11025v4",
    "published_date": "2024-07-03 06:58:29 UTC",
    "updated_date": "2025-03-31 14:19:20 UTC"
  },
  {
    "arxiv_id": "2407.02842v1",
    "title": "MindBench: A Comprehensive Benchmark for Mind Map Structure Recognition and Analysis",
    "authors": [
      "Lei Chen",
      "Feng Yan",
      "Yujie Zhong",
      "Shaoxiang Chen",
      "Zequn Jie",
      "Lin Ma"
    ],
    "abstract": "Multimodal Large Language Models (MLLM) have made significant progress in the\nfield of document analysis. Despite this, existing benchmarks typically focus\nonly on extracting text and simple layout information, neglecting the complex\ninteractions between elements in structured documents such as mind maps and\nflowcharts. To address this issue, we introduce the new benchmark named\nMindBench, which not only includes meticulously constructed bilingual authentic\nor synthetic images, detailed annotations, evaluation metrics and baseline\nmodels, but also specifically designs five types of structured understanding\nand parsing tasks. These tasks include full parsing, partial parsing,\nposition-related parsing, structured Visual Question Answering (VQA), and\nposition-related VQA, covering key areas such as text recognition, spatial\nawareness, relationship discernment, and structured parsing. Extensive\nexperimental results demonstrate the substantial potential and significant room\nfor improvement in current models' ability to handle structured document\ninformation. We anticipate that the launch of MindBench will significantly\nadvance research and application development in structured document analysis\ntechnology. MindBench is available at:\nhttps://miasanlei.github.io/MindBench.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "technical report",
    "pdf_url": "http://arxiv.org/pdf/2407.02842v1",
    "published_date": "2024-07-03 06:39:18 UTC",
    "updated_date": "2024-07-03 06:39:18 UTC"
  },
  {
    "arxiv_id": "2407.02839v1",
    "title": "CRUISE on Quantum Computing for Feature Selection in Recommender Systems",
    "authors": [
      "Jiayang Niu",
      "Jie Li",
      "Ke Deng",
      "Yongli Ren"
    ],
    "abstract": "Using Quantum Computers to solve problems in Recommender Systems that\nclassical computers cannot address is a worthwhile research topic. In this\npaper, we use Quantum Annealers to address the feature selection problem in\nrecommendation algorithms. This feature selection problem is a Quadratic\nUnconstrained Binary Optimization(QUBO) problem. By incorporating\nCounterfactual Analysis, we significantly improve the performance of the\nitem-based KNN recommendation algorithm compared to using pure Mutual\nInformation. Extensive experiments have demonstrated that the use of\nCounterfactual Analysis holds great promise for addressing such problems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "accepted by QuantumCLEF 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02839v1",
    "published_date": "2024-07-03 06:34:56 UTC",
    "updated_date": "2024-07-03 06:34:56 UTC"
  },
  {
    "arxiv_id": "2407.02821v1",
    "title": "Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes",
    "authors": [
      "Negin Ashrafi",
      "Armin Abdollahi",
      "Greg Placencia",
      "Maryam Pishgar"
    ],
    "abstract": "Predicting critical health outcomes such as patient mortality and hospital\nreadmission is essential for improving survivability. However, healthcare\ndatasets have many concurrences that create complexities, leading to poor\npredictions. Consequently, pre-processing the data is crucial to improve its\nquality. In this study, we use an existing pre-processing algorithm,\nconcatenation, to improve data quality by decreasing the complexity of\ndatasets. Sixteen healthcare datasets were extracted from two databases - MIMIC\nIII and University of Illinois Hospital - converted to the event logs, they\nwere then fed into the concatenation algorithm. The pre-processed event logs\nwere then fed to the Split Miner (SM) algorithm to produce a process model.\nProcess model quality was evaluated before and after concatenation using the\nfollowing metrics: fitness, precision, F-Measure, and complexity. The\npre-processed event logs were also used as inputs to the Decay Replay Mining\n(DREAM) algorithm to predict critical outcomes. We compared predicted results\nbefore and after applying the concatenation algorithm using Area Under the\nCurve (AUC) and Confidence Intervals (CI). Results indicated that the\nconcatenation algorithm improved the quality of the process models and\npredictions of the critical health outcomes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02821v1",
    "published_date": "2024-07-03 05:45:09 UTC",
    "updated_date": "2024-07-03 05:45:09 UTC"
  },
  {
    "arxiv_id": "2407.02814v2",
    "title": "Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective",
    "authors": [
      "Zhaotian Weng",
      "Zijun Gao",
      "Jerone Andrews",
      "Jieyu Zhao"
    ],
    "abstract": "Vision-language models (VLMs) pre-trained on extensive datasets can\ninadvertently learn biases by correlating gender information with specific\nobjects or scenarios. Current methods, which focus on modifying inputs and\nmonitoring changes in the model's output probability scores, often struggle to\ncomprehensively understand bias from the perspective of model components. We\npropose a framework that incorporates causal mediation analysis to measure and\nmap the pathways of bias generation and propagation within VLMs. This approach\nallows us to identify the direct effects of interventions on model bias and the\nindirect effects of interventions on bias mediated through different model\ncomponents. Our results show that image features are the primary contributors\nto bias, with significantly higher impacts than text features, specifically\naccounting for 32.57% and 12.63% of the bias in the MSCOCO and PASCAL-SENTENCE\ndatasets, respectively. Notably, the image encoder's contribution surpasses\nthat of the text encoder and the deep fusion encoder. Further experimentation\nconfirms that contributions from both language and vision modalities are\naligned and non-conflicting. Consequently, focusing on blurring gender\nrepresentations within the image encoder, which contributes most to the model\nbias, reduces bias efficiently by 22.03% and 9.04% in the MSCOCO and\nPASCAL-SENTENCE datasets, respectively, with minimal performance loss or\nincreased computational demands.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02814v2",
    "published_date": "2024-07-03 05:19:45 UTC",
    "updated_date": "2024-10-07 22:38:25 UTC"
  },
  {
    "arxiv_id": "2407.02813v2",
    "title": "Data Overfitting for On-Device Super-Resolution with Dynamic Algorithm and Compiler Co-Design",
    "authors": [
      "Gen Li",
      "Zhihao Shu",
      "Jie Ji",
      "Minghai Qin",
      "Fatemeh Afghah",
      "Wei Niu",
      "Xiaolong Ma"
    ],
    "abstract": "Deep neural networks (DNNs) are frequently employed in a variety of computer\nvision applications. Nowadays, an emerging trend in the current video\ndistribution system is to take advantage of DNN's overfitting properties to\nperform video resolution upscaling. By splitting videos into chunks and\napplying a super-resolution (SR) model to overfit each chunk, this scheme of SR\nmodels plus video chunks is able to replace traditional video transmission to\nenhance video quality and transmission efficiency. However, many models and\nchunks are needed to guarantee high performance, which leads to tremendous\noverhead on model switching and memory footprints at the user end. To resolve\nsuch problems, we propose a Dynamic Deep neural network assisted by a\nContent-Aware data processing pipeline to reduce the model number down to one\n(Dy-DCA), which helps promote performance while conserving computational\nresources. Additionally, to achieve real acceleration on the user end, we\ndesigned a framework that optimizes dynamic features (e.g., dynamic shapes,\nsizes, and control flow) in Dy-DCA to enable a series of compilation\noptimizations, including fused code generation, static execution planning, etc.\nBy employing such techniques, our method achieves better PSNR and real-time\nperformance (33 FPS) on an off-the-shelf mobile phone. Meanwhile, assisted by\nour compilation optimization, we achieve a 1.7$\\times$ speedup while saving up\nto 1.61$\\times$ memory consumption. Code available in\nhttps://github.com/coulsonlee/Dy-DCA-ECCV2024.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02813v2",
    "published_date": "2024-07-03 05:17:26 UTC",
    "updated_date": "2024-07-12 03:39:05 UTC"
  },
  {
    "arxiv_id": "2407.02805v1",
    "title": "Efficient DNN-Powered Software with Fair Sparse Models",
    "authors": [
      "Xuanqi Gao",
      "Weipeng Jiang",
      "Juan Zhai",
      "Shiqing Ma",
      "Xiaoyu Zhang",
      "Chao Shen"
    ],
    "abstract": "With the emergence of the Software 3.0 era, there is a growing trend of\ncompressing and integrating large models into software systems, with\nsignificant societal implications. Regrettably, in numerous instances, model\ncompression techniques impact the fairness performance of these models and thus\nthe ethical behavior of DNN-powered software. One of the most notable example\nis the Lottery Ticket Hypothesis (LTH), a prevailing model pruning approach.\nThis paper demonstrates that fairness issue of LTHbased pruning arises from\nboth its subnetwork selection and training procedures, highlighting the\ninadequacy of existing remedies. To address this, we propose a novel pruning\nframework, Ballot, which employs a novel conflict-detection-based subnetwork\nselection to find accurate and fair subnetworks, coupled with a refined\ntraining process to attain a high-performance model, thereby improving the\nfairness of DNN-powered software. By means of this procedure, Ballot improves\nthe fairness of pruning by 38.00%, 33.91%, 17.96%, and 35.82% compared to\nstate-of-the-art baselines, namely Magnitude Pruning, Standard LTH,\nSafeCompress, and FairScratch respectively, based on our evaluation of five\npopular datasets and three widely used models. Our code is available at\nhttps://anonymous.4open.science/r/Ballot-506E.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02805v1",
    "published_date": "2024-07-03 04:52:28 UTC",
    "updated_date": "2024-07-03 04:52:28 UTC"
  },
  {
    "arxiv_id": "2407.02791v1",
    "title": "Model-Enhanced LLM-Driven VUI Testing of VPA Apps",
    "authors": [
      "Suwan Li",
      "Lei Bu",
      "Guangdong Bai",
      "Fuman Xie",
      "Kai Chen",
      "Chang Yue"
    ],
    "abstract": "The flourishing ecosystem centered around voice personal assistants (VPA),\nsuch as Amazon Alexa, has led to the booming of VPA apps. The largest app\nmarket Amazon skills store, for example, hosts over 200,000 apps. Despite their\npopularity, the open nature of app release and the easy accessibility of apps\nalso raise significant concerns regarding security, privacy and quality.\nConsequently, various testing approaches have been proposed to systematically\nexamine VPA app behaviors. To tackle the inherent lack of a visible user\ninterface in the VPA app, two strategies are employed during testing, i.e.,\nchatbot-style testing and model-based testing. The former often lacks effective\nguidance for expanding its search space, while the latter falls short in\ninterpreting the semantics of conversations to construct precise and\ncomprehensive behavior models for apps. In this work, we introduce Elevate, a\nmodel-enhanced large language model (LLM)-driven VUI testing framework. Elevate\nleverages LLMs' strong capability in natural language processing to compensate\nfor semantic information loss during model-based VUI testing. It operates by\nprompting LLMs to extract states from VPA apps' outputs and generate\ncontext-related inputs. During the automatic interactions with the app, it\nincrementally constructs the behavior model, which facilitates the LLM in\ngenerating inputs that are highly likely to discover new states. Elevate\nbridges the LLM and the behavior model with innovative techniques such as\nencoding behavior model into prompts and selecting LLM-generated inputs based\non the context relevance. Elevate is benchmarked on 4,000 real-world Alexa\nskills, against the state-of-the-art tester Vitas. It achieves 15% higher state\nspace coverage compared to Vitas on all types of apps, and exhibits significant\nadvancement in efficiency.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "13 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.02791v1",
    "published_date": "2024-07-03 03:36:05 UTC",
    "updated_date": "2024-07-03 03:36:05 UTC"
  },
  {
    "arxiv_id": "2407.15026v2",
    "title": "Benchmarking End-To-End Performance of AI-Based Chip Placement Algorithms",
    "authors": [
      "Zhihai Wang",
      "Zijie Geng",
      "Zhaojie Tu",
      "Jie Wang",
      "Yuxi Qian",
      "Zhexuan Xu",
      "Ziyan Liu",
      "Siyuan Xu",
      "Zhentao Tang",
      "Shixiong Kai",
      "Mingxuan Yuan",
      "Jianye Hao",
      "Bin Li",
      "Yongdong Zhang",
      "Feng Wu"
    ],
    "abstract": "The increasing complexity of modern very-large-scale integration (VLSI)\ndesign highlights the significance of Electronic Design Automation (EDA)\ntechnologies. Chip placement is a critical step in the EDA workflow, which\npositions chip modules on the canvas with the goal of optimizing performance,\npower, and area (PPA) metrics of final chip designs. Recent advances have\ndemonstrated the great potential of AI-based algorithms in enhancing chip\nplacement. However, due to the lengthy workflow of chip design, the evaluations\nof these algorithms often focus on intermediate surrogate metrics, which are\neasy to compute but frequently reveal a substantial misalignment with the\nend-to-end performance (i.e., the final design PPA). To address this challenge,\nwe introduce ChiPBench, which can effectively facilitate research in chip\nplacement within the AI community. ChiPBench is a comprehensive benchmark\nspecifically designed to evaluate the effectiveness of existing AI-based chip\nplacement algorithms in improving final design PPA metrics. Specifically, we\nhave gathered 20 circuits from various domains (e.g., CPU, GPU, and\nmicrocontrollers). These designs are compiled by executing the workflow from\nthe verilog source code, which preserves necessary physical implementation\nkits, enabling evaluations for the placement algorithms on their impacts on the\nfinal design PPA. We executed six state-of-the-art AI-based chip placement\nalgorithms on these designs and plugged the results of each single-point\nalgorithm into the physical implementation workflow to obtain the final PPA\nresults. Experimental results show that even if intermediate metric of a\nsingle-point algorithm is dominant, while the final PPA results are\nunsatisfactory. We believe that our benchmark will serve as an effective\nevaluation framework to bridge the gap between academia and industry.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "A comprehensive benchmark for AI-based chip placement algorithms\n  using end-to-end performance metrics",
    "pdf_url": "http://arxiv.org/pdf/2407.15026v2",
    "published_date": "2024-07-03 03:29:23 UTC",
    "updated_date": "2024-12-06 06:02:07 UTC"
  },
  {
    "arxiv_id": "2407.02783v1",
    "title": "52B to 1T: Lessons Learned via Tele-FLM Series",
    "authors": [
      "Xiang Li",
      "Yiqun Yao",
      "Xin Jiang",
      "Xuezhi Fang",
      "Chao Wang",
      "Xinzhang Liu",
      "Zihan Wang",
      "Yu Zhao",
      "Xin Wang",
      "Yuyao Huang",
      "Shuangyong Song",
      "Yongxiang Li",
      "Zheng Zhang",
      "Bo Zhao",
      "Aixin Sun",
      "Yequan Wang",
      "Zhongjiang He",
      "Zhongyuan Wang",
      "Xuelong Li",
      "Tiejun Huang"
    ],
    "abstract": "Large Language Models (LLMs) represent a significant stride toward Artificial\nGeneral Intelligence. As scaling laws underscore the potential of increasing\nmodel sizes, the academic community has intensified its investigations into\nLLMs with capacities exceeding 50 billion parameters. This technical report\nbuilds on our prior work with Tele-FLM (also known as FLM-2), a publicly\navailable 52-billion-parameter model. We delve into two primary areas: we first\ndiscuss our observation of Supervised Fine-tuning (SFT) on Tele-FLM-52B, which\nsupports the \"less is more\" approach for SFT data construction; second, we\ndemonstrate our experiments and analyses on the best practices for\nprogressively growing a model from 52 billion to 102 billion, and subsequently\nto 1 trillion parameters. We will open-source a 1T model checkpoint, namely\nTele-FLM-1T, to advance further training and research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "For the Tele-FLM-52B tech report, see also 2404.16645",
    "pdf_url": "http://arxiv.org/pdf/2407.02783v1",
    "published_date": "2024-07-03 03:21:02 UTC",
    "updated_date": "2024-07-03 03:21:02 UTC"
  },
  {
    "arxiv_id": "2407.02779v1",
    "title": "Croppable Knowledge Graph Embedding",
    "authors": [
      "Yushan Zhu",
      "Wen Zhang",
      "Zhiqiang Liu",
      "Mingyang Chen",
      "Lei Liang",
      "Huajun Chen"
    ],
    "abstract": "Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)\nto serve various artificial intelligence tasks. The suitable dimensions of the\nembeddings depend on the storage and computing conditions of the specific\napplication scenarios. Once a new dimension is required, a new KGE model needs\nto be trained from scratch, which greatly increases the training cost and\nlimits the efficiency and flexibility of KGE in serving various scenarios. In\nthis work, we propose a novel KGE training framework MED, through which we\ncould train once to get a croppable KGE model applicable to multiple scenarios\nwith different dimensional requirements, sub-models of the required dimensions\ncan be cropped out of it and used directly without any additional training. In\nMED, we propose a mutual learning mechanism to improve the low-dimensional\nsub-models performance and make the high-dimensional sub-models retain the\ncapacity that low-dimensional sub-models have, an evolutionary improvement\nmechanism to promote the high-dimensional sub-models to master the knowledge\nthat the low-dimensional sub-models can not learn, and a dynamic loss weight to\nbalance the multiple losses adaptively. Experiments on 3 KGE models over 4\nstandard KG completion datasets, 3 real application scenarios over a real-world\nlarge-scale KG, and the experiments of extending MED to the language model BERT\nshow the effectiveness, high efficiency, and flexible extensibility of MED.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02779v1",
    "published_date": "2024-07-03 03:10:25 UTC",
    "updated_date": "2024-07-03 03:10:25 UTC"
  },
  {
    "arxiv_id": "2407.02765v2",
    "title": "Graphon Particle Systems, Part II: Dynamics of Distributed Stochastic Continuum Optimization",
    "authors": [
      "Yan Chen",
      "Tao Li"
    ],
    "abstract": "We study the distributed optimization problem over a graphon with a continuum\nof nodes, which is regarded as the limit of the distributed networked\noptimization as the number of nodes goes to infinity. Each node has a private\nlocal cost function. The global cost function, which all nodes cooperatively\nminimize, is the integral of the local cost functions on the node set. We\npropose stochastic gradient descent and gradient tracking algorithms over the\ngraphon. We establish a general lemma for the upper bound estimation related to\na class of time-varying differential inequalities with negative linear terms,\nbased upon which, we prove that for both kinds of algorithms, the second\nmoments of the nodes' states are uniformly bounded. Especially, for the\nstochastic gradient tracking algorithm, we transform the convergence analysis\ninto the asymptotic property of coupled nonlinear differential inequalities\nwith time-varying coefficients and develop a decoupling method. For both kinds\nof algorithms, we show that by choosing the time-varying algorithm gains\nproperly, all nodes' states achieve $\\mathcal{L}^{\\infty}$-consensus for a\nconnected graphon. Furthermore, if the local cost functions are strongly\nconvex, then all nodes' states converge to the minimizer of the global cost\nfunction and the auxiliary states in the stochastic gradient tracking algorithm\nconverge to the gradient value of the global cost function at the minimizer\nuniformly in mean square.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "math.OC",
      "math.PR"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02765v2",
    "published_date": "2024-07-03 02:47:39 UTC",
    "updated_date": "2025-02-21 02:16:56 UTC"
  },
  {
    "arxiv_id": "2407.02762v1",
    "title": "SF-GNN: Self Filter for Message Lossless Propagation in Deep Graph Neural Network",
    "authors": [
      "Yushan Zhu",
      "Wen Zhang",
      "Yajing Xu",
      "Zhen Yao",
      "Mingyang Chen",
      "Huajun Chen"
    ],
    "abstract": "Graph Neural Network (GNN), with the main idea of encoding graph structure\ninformation of graphs by propagation and aggregation, has developed rapidly. It\nachieved excellent performance in representation learning of multiple types of\ngraphs such as homogeneous graphs, heterogeneous graphs, and more complex\ngraphs like knowledge graphs. However, merely stacking GNN layers may not\nimprove the model's performance and can even be detrimental. For the phenomenon\nof performance degradation in deep GNNs, we propose a new perspective. Unlike\nthe popular explanations of over-smoothing or over-squashing, we think the\nissue arises from the interference of low-quality node representations during\nmessage propagation. We introduce a simple and general method, SF-GNN, to\naddress this problem. In SF-GNN, we define two representations for each node,\none is the node representation that represents the feature of the node itself,\nand the other is the message representation specifically for propagating\nmessages to neighbor nodes. A self-filter module evaluates the quality of the\nnode representation and decides whether to integrate it into the message\npropagation based on this quality assessment. Experiments on node\nclassification tasks for both homogeneous and heterogeneous graphs, as well as\nlink prediction tasks on knowledge graphs, demonstrate that our method can be\napplied to various GNN models and outperforms state-of-the-art baseline methods\nin addressing deep GNN degradation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02762v1",
    "published_date": "2024-07-03 02:40:39 UTC",
    "updated_date": "2024-07-03 02:40:39 UTC"
  },
  {
    "arxiv_id": "2407.02759v1",
    "title": "Multi-Scenario Combination Based on Multi-Agent Reinforcement Learning to Optimize the Advertising Recommendation System",
    "authors": [
      "Yang Zhao",
      "Chang Zhou",
      "Jin Cao",
      "Yi Zhao",
      "Shaobo Liu",
      "Chiyu Cheng",
      "Xingchen Li"
    ],
    "abstract": "This paper explores multi-scenario optimization on large platforms using\nmulti-agent reinforcement learning (MARL). We address this by treating\nscenarios like search, recommendation, and advertising as a cooperative,\npartially observable multi-agent decision problem. We introduce the Multi-Agent\nRecurrent Deterministic Policy Gradient (MARDPG) algorithm, which aligns\ndifferent scenarios under a shared objective and allows for strategy\ncommunication to boost overall performance. Our results show marked\nimprovements in metrics such as click-through rate (CTR), conversion rate, and\ntotal sales, confirming our method's efficacy in practical settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by 2024 5th International Conference on Artificial\n  Intelligence and Electromechanical Automation IEEE (ISBN: 979-8-3503-6617-4)",
    "pdf_url": "http://arxiv.org/pdf/2407.02759v1",
    "published_date": "2024-07-03 02:33:20 UTC",
    "updated_date": "2024-07-03 02:33:20 UTC"
  },
  {
    "arxiv_id": "2407.02751v2",
    "title": "Emotion and Intent Joint Understanding in Multimodal Conversation: A Benchmarking Dataset",
    "authors": [
      "Rui Liu",
      "Haolin Zuo",
      "Zheng Lian",
      "Xiaofen Xing",
      "Björn W. Schuller",
      "Haizhou Li"
    ],
    "abstract": "Emotion and Intent Joint Understanding in Multimodal Conversation (MC-EIU)\naims to decode the semantic information manifested in a multimodal\nconversational history, while inferring the emotions and intents simultaneously\nfor the current utterance. MC-EIU is enabling technology for many\nhuman-computer interfaces. However, there is a lack of available datasets in\nterms of annotation, modality, language diversity, and accessibility. In this\nwork, we propose an MC-EIU dataset, which features 7 emotion categories, 9\nintent categories, 3 modalities, i.e., textual, acoustic, and visual content,\nand two languages, i.e., English and Mandarin. Furthermore, it is completely\nopen-source for free access. To our knowledge, MC-EIU is the first\ncomprehensive and rich emotion and intent joint understanding dataset for\nmultimodal conversation. Together with the release of the dataset, we also\ndevelop an Emotion and Intent Interaction (EI$^2$) network as a reference\nsystem by modeling the deep correlation between emotion and intent in the\nmultimodal conversation. With comparative experiments and ablation studies, we\ndemonstrate the effectiveness of the proposed EI$^2$ method on the MC-EIU\ndataset. The dataset and codes will be made available at:\nhttps://github.com/MC-EIU/MC-EIU.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 8 figures, 12 tables, NeurIPS 2024 Dataset and Benchmark\n  Track",
    "pdf_url": "http://arxiv.org/pdf/2407.02751v2",
    "published_date": "2024-07-03 01:56:00 UTC",
    "updated_date": "2024-07-04 15:13:24 UTC"
  },
  {
    "arxiv_id": "2407.02742v1",
    "title": "A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation",
    "authors": [
      "Nastaran Bassamzadeh",
      "Chhaya Methani"
    ],
    "abstract": "Natural Language to Code Generation has made significant progress in recent\nyears with the advent of Large Language Models(LLMs). While generation for\ngeneral-purpose languages like C, C++, and Python has improved significantly,\nLLMs struggle with custom function names in Domain Specific Languages or DSLs.\nThis leads to higher hallucination rates and syntax errors, specially for DSLs\nhaving a high number of custom function names. Additionally, constant updates\nto function names add to the challenge as LLMs need to stay up-to-date. In this\npaper, we present optimizations for using Retrieval Augmented Generation (or\nRAG) with LLMs for DSL generation along with an ablation study comparing these\nstrategies. We generated a train as well as test dataset with a DSL to\nrepresent automation tasks across roughly 700 APIs in public domain. We used\nthe training dataset to fine-tune a Codex model for this DSL. Our results\nshowed that the fine-tuned model scored the best on code similarity metric.\nWith our RAG optimizations, we achieved parity for similarity metric. The\ncompilation rate, however, showed that both the models still got the syntax\nwrong many times, with RAG-based method being 2 pts better. Conversely,\nhallucination rate for RAG model lagged by 1 pt for API names and by 2 pts for\nAPI parameter keys. We conclude that an optimized RAG model can match the\nquality of fine-tuned models and offer advantages for new, unseen APIs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "I.2.2; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "8 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2407.02742v1",
    "published_date": "2024-07-03 01:28:51 UTC",
    "updated_date": "2024-07-03 01:28:51 UTC"
  },
  {
    "arxiv_id": "2407.02731v1",
    "title": "Artificial intelligence and machine learning generated conjectures with TxGraffiti",
    "authors": [
      "Randy Davila"
    ],
    "abstract": "\\emph{TxGraffiti} is a machine learning and heuristic based artificial\nintelligence designed to automate the task of conjecturing in mathematics.\nSince its inception, TxGraffiti has generated many surprising conjectures\nleading to publication in respectable mathematical journals. In this paper we\noutline the machine learning and heuristic techniques implemented by\nTxGraffiti. We also recall its contributions to the mathematical literature and\nannounce a new online version of the program available for anyone curious to\nexplore conjectures in graph theory.",
    "categories": [
      "cs.AI",
      "math.CO"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2306.12917",
    "pdf_url": "http://arxiv.org/pdf/2407.02731v1",
    "published_date": "2024-07-03 01:03:09 UTC",
    "updated_date": "2024-07-03 01:03:09 UTC"
  },
  {
    "arxiv_id": "2407.02730v1",
    "title": "MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context",
    "authors": [
      "Zishan Gu",
      "Changchang Yin",
      "Fenglin Liu",
      "Ping Zhang"
    ],
    "abstract": "Large Vision Language Models (LVLMs) have recently achieved superior\nperformance in various tasks on natural image and text data, which inspires a\nlarge amount of studies for LVLMs fine-tuning and training. Despite their\nadvancements, there has been scant research on the robustness of these models\nagainst hallucination when fine-tuned on smaller datasets. In this study, we\nintroduce a new benchmark dataset, the Medical Visual Hallucination Test\n(MedVH), to evaluate the hallucination of domain-specific LVLMs. MedVH\ncomprises five tasks to evaluate hallucinations in LVLMs within the medical\ncontext, which includes tasks for comprehensive understanding of textual and\nvisual input, as well as long textual response generation. Our extensive\nexperiments with both general and medical LVLMs reveal that, although medical\nLVLMs demonstrate promising performance on standard medical tasks, they are\nparticularly susceptible to hallucinations, often more so than the general\nmodels, raising significant concerns about the reliability of these\ndomain-specific models. For medical LVLMs to be truly valuable in real-world\napplications, they must not only accurately integrate medical knowledge but\nalso maintain robust reasoning abilities to prevent hallucination. Our work\npaves the way for future evaluations of these studies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02730v1",
    "published_date": "2024-07-03 00:59:03 UTC",
    "updated_date": "2024-07-03 00:59:03 UTC"
  }
]