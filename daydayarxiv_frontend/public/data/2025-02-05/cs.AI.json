{
  "date": "2025-02-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-05 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 168 篇论文，主要聚焦于 AI 模型的推理、对齐和优化（如 LLM 在科学推理中的潜力）、视觉语言模型的应用、强化学习中的鲁棒性，以及特定领域的创新，如医学图像处理和量子计算。重点包括 AlphaGeometry2 在数学推理上的突破，以及高效 LLM 训练方法；令人印象深刻的文章有 Omni-DNA 和 Mol-LLM，它们展示了 LLM 在跨模态科学任务中的强大潜力，而知名学者如 Yann LeCun 的观点在相关讨论中被提及。\n\n下面，我将挑选并简要讨论今天的关键论文，先从重要、话题性和影响力大的文章入手（如 LLM 推理和多代理强化学习），并将相关主题归类讨论。其他较常规或小众论文（如某些纯理论模型或特定应用）将快速带过，只列出标题以控制篇幅。\n\n### LLM 推理与优化（重点主题）\n- **AlphaGeometry2: Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2**（英文原标题：AlphaGeometry2: Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2）  \n  这篇论文由 Quoc V. Le 等知名学者主导，提出 AlphaGeometry2 模型，在解决国际数学奥林匹克几何问题上超越了平均金牌选手水平，主要贡献是通过改进的搜索和 Gemini 架构，提升了数学推理的准确性和效率，实验结果显示其在 25 年几何问题集上的成功率从 54% 提高到 84%。\n  \n- **LIMO: Less is More for Reasoning**（英文原标题：LIMO: Less is More for Reasoning）  \n  作者 Ye 等提出 LIMO 框架，证明在预训练模型中，使用少量示例即可激发复杂推理能力，主要发现是通过最小示例训练，实现数学推理任务的性能提升，实验在 AIME 和 MATH 数据集上表现出色。\n\n- **PerPO: Perceptual Preference Optimization via Discriminative Rewarding**（英文原标题：PerPO: Perceptual Preference Optimization via Discriminative Rewarding）  \n  这篇论文探索视觉生成模型的公平性，贡献包括一种感知偏好优化方法，通过奖励机制减少偏置，实验显示在图像生成任务中显著提升了模型的鲁棒性和多样性。\n\n- **Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**（英文原标题：Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization）  \n  作者 Lee 等开发了 Mol-LLM，用于分子任务，关键创新是多模态训练和图结构优化，主要发现模型在分子生成和预测任务上超越了专业模型，展示了 LLM 在生物化学领域的潜力。\n\n- **OmniRL: In-Context Reinforcement Learning by Large-Scale Meta-Training in Randomized Worlds**（英文原标题：OmniRL: In-Context Reinforcement Learning by Large-Scale Meta-Training in Randomized Worlds）  \n  Wang 等提出 OmniRL 框架，通过大规模元训练实现强化学习的上下文学习，贡献在于高效的数据合成和建模方法，实验证明其在 Gymnasium 任务上无需微调即可泛化。\n\n其他 LLM 相关论文如 **GHOST: Gaussian Hypothesis Open-Set Technique** 和 **KDA: A Knowledge-Distilled Attacker** 等，快速带过：它们分别探讨了开放集检测和攻击生成，但影响力较小，仅在特定子领域有应用。\n\n### 视觉与多模态模型（相关主题）\n- **DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior**（英文原标题：DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior）  \n  Han 等提出 DC-VSR 方法，使用扩散模型提升视频超分辨率，关键贡献是空间-时间注意力机制，确保了视频的时空一致性，实验在视频重建任务上表现出色。\n\n- **REALEDIT: Reddit Edits As a Large-Scale Empirical Dataset for Image Transformations**（英文原标题：REALEDIT: Reddit Edits As a Large-Scale Empirical Dataset for Image Transformations）  \n  这篇论文构建了 REALEDIT 数据集，用于图像编辑任务，主要发现是基于真实用户编辑的数据提升了模型的泛化能力。\n\n其他视觉论文如 **TexLiDAR: Automated Text Understanding for Panoramic LiDAR Data** 等，快速带过：它们聚焦传感器数据处理，但未有突破性创新。\n\n### 强化学习与鲁棒性（重要主题）\n- **Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning**（英文原标题：Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning）  \n  Lee 等引入 Wolfpack 攻击框架，针对多代理强化学习的鲁棒性，贡献在于模拟协调攻击提升防御策略，实验证明其显著改善了代理的抗攻击能力。\n\n其他强化学习论文如 **Inducing Diversity in Differentiable Search Indexing** 等，快速带过：它们探讨了搜索优化，但主题较窄。\n\n### 医学与科学应用（话题性主题）\n- **MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation**（英文原标题：MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation）  \n  Kim 提出 MedBioLM，用于医学问答，关键创新是结合检索增强生成，实验显示其在生物医学任务上提升了准确性和事实性。\n\n其他医学论文如 **RadVLM: A Multitask Conversational Vision-Language Model for Radiology** 等，快速带过：它们在特定领域有应用，但整体影响有限。\n\n### 其他领域（快速掠过）\n其余论文覆盖量子计算、图神经网络和安全等领域，以列出标题为主：\n- **Emerging Practices in Frontier AI Safety Frameworks**（英文原标题：Emerging Practices in Frontier AI Safety Frameworks）\n- **A Unified Knowledge-Distillation and Semi-Supervised Learning Framework to Improve Industrial Ads Delivery Systems**（英文原标题：A Unified Knowledge-Distillation and Semi-Supervised Learning Framework to Improve Industrial Ads Delivery Systems）\n- **Energy & Force Regression on DFT Trajectories is Not Enough for Universal Machine Learning Interatomic Potentials**（英文原标题：Energy & Force Regression on DFT Trajectories is Not Enough for Universal Machine Learning Interatomic Potentials）\n- **Multimodal Transformer Models for Turn-taking Prediction**（英文原标题：Multimodal Transformer Models for Turn-taking Prediction）\n- **Safety Cases: A Scalable Approach to Frontier AI Safety**（英文原标题：Safety Cases: A Scalable Approach to Frontier AI Safety）\n\n这些论文主要探讨安全框架、广告优化和材料模拟，但未有重大突破，仅作为补充。\n\n今天的 arXiv 更新展示了 AI 领域的多样性与深度，LLM 在推理和应用上的进展尤为值得关注。明天的快报将继续追踪这些趋势！",
  "papers": [
    {
      "arxiv_id": "2502.03678v2",
      "title": "Reflection-Window Decoding: Text Generation with Selective Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Tang",
        "Zhenhao Chen",
        "Loka Li",
        "Xiangchen Song",
        "Yunlong Deng",
        "Yifan Shen",
        "Guangyi Chen",
        "Peter Spirtes",
        "Kun Zhang"
      ],
      "abstract": "The autoregressive decoding for text generation in large language models\n(LLMs), while widely used, is inherently suboptimal due to the lack of a\nbuilt-in mechanism to perform refinement and/or correction of the generated\ncontent. In this paper, we consider optimality in terms of the joint\nprobability over the generated response, when jointly considering all tokens at\nthe same time. We theoretically characterize the potential deviation of the\nautoregressively generated response from its globally optimal counterpart that\nis of the same length. Our analysis suggests that we need to be cautious when\nnoticeable uncertainty arises during text generation, which may signal the\nsub-optimality of the generation history. To address the pitfall of\nautoregressive decoding for text generation, we propose an approach that\nincorporates a sliding reflection window and a pausing criterion, such that\nrefinement and generation can be carried out interchangeably as the decoding\nproceeds. Our selective refinement framework strikes a balance between\nefficiency and optimality, and our extensive experimental results demonstrate\nthe effectiveness of our approach.",
      "tldr_zh": "这篇论文指出了大型语言模型（LLMs）中 autoregressive decoding 的局限性，即缺乏内置机制来精炼生成的文本，并通过理论分析揭示了其与全局最优响应的潜在偏差。作者提出 Reflection-Window Decoding 方法，使用滑动反射窗口和暂停标准，实现生成与选择性精炼的交替进行，从而在效率和最优性之间取得平衡。实验结果证明，该框架在文本生成任务中表现出色，有效提升了生成质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03678v2",
      "published_date": "2025-02-05 23:53:08 UTC",
      "updated_date": "2025-03-10 19:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:15:02.470605"
    },
    {
      "arxiv_id": "2502.04390v1",
      "title": "In Praise of Stubbornness: The Case for Cognitive-Dissonance-Aware Knowledge Updates in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Simone Clemente",
        "Zied Ben Houidi",
        "Alexis Huet",
        "Dario Rossi",
        "Giulio Franzese",
        "Pietro Michiardi"
      ],
      "abstract": "Despite remarkable capabilities, large language models (LLMs) struggle to\ncontinually update their knowledge without catastrophic forgetting. In\ncontrast, humans effortlessly integrate new information, detect conflicts with\nexisting beliefs, and selectively update their mental models. This paper\nintroduces a cognitive-inspired investigation paradigm to study continual\nknowledge updating in LLMs. We implement two key components inspired by human\ncognition: (1) Dissonance and Familiarity Awareness, analyzing model behavior\nto classify information as novel, familiar, or dissonant; and (2) Targeted\nNetwork Updates, which track neural activity to identify frequently used\n(stubborn) and rarely used (plastic) neurons. Through carefully designed\nexperiments in controlled settings, we uncover a number of empirical findings\ndemonstrating the potential of this approach. First, dissonance detection is\nfeasible using simple activation and gradient features, suggesting potential\nfor cognitive-inspired training. Second, we find that non-dissonant updates\nlargely preserve prior knowledge regardless of targeting strategy, revealing\ninherent robustness in LLM knowledge integration. Most critically, we discover\nthat dissonant updates prove catastrophically destructive to the model's\nknowledge base, indiscriminately affecting even information unrelated to the\ncurrent updates. This suggests fundamental limitations in how neural networks\nhandle contradictions and motivates the need for new approaches to knowledge\nupdating that better mirror human cognitive mechanisms.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在持续知识更新中面临的灾难性遗忘问题，并提出一个受人类认知启发的范式，以更好地模仿人类整合新信息和检测冲突的能力。论文引入了两个关键组件：Dissonance and Familiarity Awareness，用于分析模型行为将信息分类为新颖的、熟悉的或不和谐的；以及Targeted Network Updates，通过追踪神经活动识别频繁使用（stubborn）和少用（plastic）的神经元。实验结果显示，不和谐更新会严重破坏模型的知识基，甚至影响无关信息，而非不和谐更新能较好地保留先验知识，这突显了神经网络处理矛盾的根本局限性，并呼吁开发更符合人类认知机制的知识更新方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04390v1",
      "published_date": "2025-02-05 23:49:33 UTC",
      "updated_date": "2025-02-05 23:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:15:16.214515"
    },
    {
      "arxiv_id": "2502.03674v1",
      "title": "An Empirical Study of Methods for Small Object Detection from Satellite Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohui Yuan",
        "Aniv Chakravarty",
        "Lichuan Gu",
        "Zhenchun Wei",
        "Elinor Lichtenberg",
        "Tian Chen"
      ],
      "abstract": "This paper reviews object detection methods for finding small objects from\nremote sensing imagery and provides an empirical evaluation of four\nstate-of-the-art methods to gain insights into method performance and technical\nchallenges. In particular, we use car detection from urban satellite images and\nbee box detection from satellite images of agricultural lands as application\nscenarios. Drawing from the existing surveys and literature, we identify\nseveral top-performing methods for the empirical study. Public, high-resolution\nsatellite image datasets are used in our experiments.",
      "tldr_zh": "这篇论文通过实证研究审视了用于从卫星图像中检测小物体的object detection方法，并评估了四种最先进的方法，以揭示其性能和技术挑战。研究以城市卫星图像中的汽车检测和农业土地卫星图像中的蜂箱检测作为应用场景，从现有文献中选取了表现突出的方法进行测试。实验使用公共的高分辨率卫星图像数据集，提供了对方法有效性的宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03674v1",
      "published_date": "2025-02-05 23:40:54 UTC",
      "updated_date": "2025-02-05 23:40:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:15:26.746770"
    },
    {
      "arxiv_id": "2502.04389v1",
      "title": "Overcoming Vision Language Model Challenges in Diagram Understanding: A Proof-of-Concept with XML-Driven Large Language Models Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Shue Shiinoki",
        "Ryo Koshihara",
        "Hayato Motegi",
        "Masumi Morishige"
      ],
      "abstract": "Diagrams play a crucial role in visually conveying complex relationships and\nprocesses within business documentation. Despite recent advances in\nVision-Language Models (VLMs) for various image understanding tasks, accurately\nidentifying and extracting the structures and relationships depicted in\ndiagrams continues to pose significant challenges. This study addresses these\nchallenges by proposing a text-driven approach that bypasses reliance on VLMs'\nvisual recognition capabilities. Instead, it utilizes the editable source\nfiles--such as xlsx, pptx or docx--where diagram elements (e.g., shapes, lines,\nannotations) are preserved as textual metadata. In our proof-of-concept, we\nextracted diagram information from xlsx-based system design documents and\ntransformed the extracted shape data into textual input for Large Language\nModels (LLMs). This approach allowed the LLM to analyze relationships and\ngenerate responses to business-oriented questions without the bottleneck of\nimage-based processing. Experimental comparisons with a VLM-based method\ndemonstrated that the proposed text-driven framework yielded more accurate\nanswers for questions requiring detailed comprehension of diagram\nstructures.The results obtained in this study are not limited to the tested\n.xlsx files but can also be extended to diagrams in other documents with source\nfiles, such as Office pptx and docx formats. These findings highlight the\nfeasibility of circumventing VLM constraints through direct textual extraction\nfrom original source files. By enabling robust diagram understanding through\nLLMs, our method offers a promising path toward enhanced workflow efficiency\nand information analysis in real-world business scenarios.",
      "tldr_zh": "这篇论文解决了 Vision-Language Models (VLMs) 在图表理解中的挑战，如识别结构和关系的问题，通过提出一种基于文本驱动的 XML-Driven 方法。方法利用图表的源文件（如 xlsx、pptx 或 docx）提取文本元数据（如形状、线条和注释），然后将这些数据转化为 Large Language Models (LLMs) 的输入，实现对图表关系的分析和商业问题的回答。实验结果显示，与 VLM 方法相比，该框架在处理需要详细图表理解的问题时准确性更高，且可扩展到其他文档格式。该方法为绕过 VLM 限制、提升工作流效率和信息分析提供了可行路径。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "The related code is available at\n  \\url{https://github.com/galirage/spreadsheet-intelligence}, which provides\n  the core library developed for this research. The experimental code using\n  this library can be found at\n  \\url{https://github.com/galirage/XMLDriven-Diagram-Understanding}",
      "pdf_url": "http://arxiv.org/pdf/2502.04389v1",
      "published_date": "2025-02-05 23:40:26 UTC",
      "updated_date": "2025-02-05 23:40:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:15:39.727258"
    },
    {
      "arxiv_id": "2502.03671v1",
      "title": "Advancing Reasoning in Large Language Models: Promising Methods and Approaches",
      "title_zh": "大语言模型中推理的推进：有前景的方法和途径",
      "authors": [
        "Avinash Patil"
      ],
      "abstract": "Large Language Models (LLMs) have succeeded remarkably in various natural\nlanguage processing (NLP) tasks, yet their reasoning capabilities remain a\nfundamental challenge. While LLMs exhibit impressive fluency and factual\nrecall, their ability to perform complex reasoning-spanning logical deduction,\nmathematical problem-solving, commonsense inference, and multi-step\nreasoning-often falls short of human expectations. This survey provides a\ncomprehensive review of emerging techniques enhancing reasoning in LLMs. We\ncategorize existing methods into key approaches, including prompting strategies\n(e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought\nreasoning), architectural innovations (e.g., retrieval-augmented models,\nmodular reasoning networks, and neuro-symbolic integration), and learning\nparadigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement\nlearning, and self-supervised reasoning objectives). Additionally, we explore\nevaluation frameworks used to assess reasoning in LLMs and highlight open\nchallenges, such as hallucinations, robustness, and reasoning generalization\nacross diverse tasks. By synthesizing recent advancements, this survey aims to\nprovide insights into promising directions for future research and practical\napplications of reasoning-augmented LLMs.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（Large Language Models, LLMs）在推理能力上的不足，包括逻辑演绎、数学问题解决、常识推理和多步推理，并总结了提升这些能力的各种新兴技术。论文将方法分类为提示策略（如Chain-of-Thought reasoning、Self-Consistency和Tree-of-Thought reasoning）、架构创新（如retrieval-augmented models、modular reasoning networks和neuro-symbolic integration），以及学习范式（如fine-tuning with reasoning-specific datasets、reinforcement learning和self-supervised reasoning objectives）。此外，它审视了评估框架并指出了关键挑战，如hallucinations、robustness和推理在不同任务中的泛化问题。通过综合这些进展，论文为未来研究和应用提供宝贵的见解和方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 Pages, 1 Figure, IEEE Format",
      "pdf_url": "http://arxiv.org/pdf/2502.03671v1",
      "published_date": "2025-02-05 23:31:39 UTC",
      "updated_date": "2025-02-05 23:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:15:51.202470"
    },
    {
      "arxiv_id": "2502.18478v1",
      "title": "Beyond Self-Consistency: Loss-Balanced Perturbation-Based Regularization Improves Industrial-Scale Ads Ranking",
      "title_zh": "超越自我一致性：损失平衡的基于扰动的正则化改善工业规模广告排名",
      "authors": [
        "Ilqar Ramazanli",
        "Hamid Eghbalzadeh",
        "Xiaoyi Liu",
        "Yang Wang",
        "Jiaxiang Fu",
        "Kaushik Rangadurai",
        "Sem Park",
        "Bo Long",
        "Xue Feng"
      ],
      "abstract": "Perturbation-based regularization techniques address many challenges in\nindustrial-scale large models, particularly with sparse labels, and emphasize\nconsistency and invariance for perturbation in model predictions. One of the\npopular regularization techniques has been various forms of self-consistency,\nwhich involve making small modifications to input data while preserving\ncontextual information and enforcing similar predictions through auxiliary loss\nfunctions. In this work, we explore the first successful application of\nperturbation-based regularization algorithms in large-scale ads ranking models,\nand further propose a novel regularization algorithm, namely, Loss-Balanced\nSmall Perturbation Regularization (LSPR) that can be used in potentially any\ndeep learning model. We have successfully demonstrate that both\nSelf-Consistency Regularization approaches (SCR) and LSPR are scalable and can\nimprove ads delivery systems. By conducting industrial-scale experiments, and\nnumerical analysis, we additionally show that our proposed LSPR, performs\nconsistently better compared to SCR, across various groups and signal\navailability setups. Finally, we report a successful application of the\nproposed LSPR in a billion-scale industrial ranking system, which to the best\nof our knowledge, is the first of its kind, and it is specially designed to\naddress the various scalability challenges (e.g, various surfaces, geological\nlocations, clients and so on) as we will mention in this paper.",
      "tldr_zh": "这篇论文探讨了基于扰动的正则化技术在工业规模广告排名模型中的应用，超越了传统的 Self-Consistency Regularization (SCR)，以解决稀疏标签和模型一致性挑战。作者提出了一种新型算法，Loss-Balanced Small Perturbation Regularization (LSPR)，通过平衡损失函数和微小输入扰动来增强模型的鲁棒性和性能。实验结果显示，LSPR 在各种组别和信号可用性设置中比 SCR 更有效，并在十亿规模的工业排名系统中成功部署，显著改善了广告交付系统的可伸缩性和整体表现。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18478v1",
      "published_date": "2025-02-05 23:24:52 UTC",
      "updated_date": "2025-02-05 23:24:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:16:04.549568"
    },
    {
      "arxiv_id": "2502.03669v1",
      "title": "Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set",
      "title_zh": "翻译失败",
      "authors": [
        "Yikai Wu",
        "Haoyu Zhao",
        "Sanjeev Arora"
      ],
      "abstract": "AI methods, such as generative models and reinforcement learning, have\nrecently been applied to combinatorial optimization (CO) problems, especially\nNP-hard ones. This paper compares such GPU-based methods with classical\nCPU-based methods on Maximum Independent Set (MIS). Experiments on standard\ngraph families show that AI-based algorithms fail to outperform and, in many\ncases, to match the solution quality of the state-of-art classical solver KaMIS\nrunning on a single CPU. Some GPU-based methods even perform similarly to the\nsimplest heuristic, degree-based greedy. Even with post-processing techniques\nlike local search, AI-based methods still perform worse than CPU-based solvers.\n  We develop a new mode of analysis to reveal that non-backtracking AI methods,\ne.g. LTFT (which is based on GFlowNets), end up reasoning similarly to the\nsimplest degree-based greedy approach, and thus worse than KaMIS. We also find\nthat CPU-based algorithms, notably KaMIS, have strong performance on sparse\nrandom graphs, which appears to refute a well-known conjectured upper bound for\nefficient algorithms from Coja-Oghlan & Efthymiou (2015).",
      "tldr_zh": "该论文比较了AI methods（如生成模型和强化学习）与经典algorithms在Maximum Independent Set (MIS)问题上的性能。实验结果显示，在标准图族上，AI-based GPU算法未能超越或匹配CPU-based求解器KaMIS的解决方案质量，甚至有些表现类似简单的degree-based greedy启发式方法。即使应用后处理如local search，AI方法仍逊色于KaMIS。此外，作者开发了一种新分析模式，发现非回溯AI方法如基于GFlowNets的LTFT，其推理方式类似于简单贪婪算法，并揭示KaMIS在稀疏随机图上的强劲性能，挑战了Coja-Oghlan & Efthymiou (2015)的著名猜想。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 7 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.03669v1",
      "published_date": "2025-02-05 23:24:47 UTC",
      "updated_date": "2025-02-05 23:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:16:16.139438"
    },
    {
      "arxiv_id": "2503.04746v1",
      "title": "Emerging Practices in Frontier AI Safety Frameworks",
      "title_zh": "翻译失败",
      "authors": [
        "Marie Davidsen Buhl",
        "Ben Bucknall",
        "Tammy Masterson"
      ],
      "abstract": "As part of the Frontier AI Safety Commitments agreed to at the 2024 AI Seoul\nSummit, many AI developers agreed to publish a safety framework outlining how\nthey will manage potential severe risks associated with their systems. This\npaper summarises current thinking from companies, governments, and researchers\non how to write an effective safety framework. We outline three core areas of a\nsafety framework - risk identification and assessment, risk mitigation, and\ngovernance - and identify emerging practices within each area. As safety\nframeworks are novel and rapidly developing, we hope that this paper can serve\nboth as an overview of work to date and as a starting point for further\ndiscussion and innovation.",
      "tldr_zh": "这篇论文总结了公司在前沿AI安全框架(Frontier AI Safety Frameworks)方面的当前实践，特别是在2024 AI Seoul Summit的承诺下，AI开发者如何管理系统潜在的严重风险。论文概述了安全框架的三个核心领域：风险识别和评估(risk identification and assessment)、风险缓解(risk mitigation)，以及治理(governance)，并识别了每个领域的emerging practices。总体而言，该工作旨在为快速发展的安全框架提供概述，促进进一步的讨论和创新。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "38 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.04746v1",
      "published_date": "2025-02-05 23:22:57 UTC",
      "updated_date": "2025-02-05 23:22:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:16:26.610218"
    },
    {
      "arxiv_id": "2502.06834v1",
      "title": "A Unified Knowledge-Distillation and Semi-Supervised Learning Framework to Improve Industrial Ads Delivery Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Hamid Eghbalzadeh",
        "Yang Wang",
        "Rui Li",
        "Yuji Mo",
        "Qin Ding",
        "Jiaxiang Fu",
        "Liang Dai",
        "Shuo Gu",
        "Nima Noorshams",
        "Sem Park",
        "Bo Long",
        "Xue Feng"
      ],
      "abstract": "Industrial ads ranking systems conventionally rely on labeled impression\ndata, which leads to challenges such as overfitting, slower incremental gain\nfrom model scaling, and biases due to discrepancies between training and\nserving data. To overcome these issues, we propose a Unified framework for\nKnowledge-Distillation and Semi-supervised Learning (UKDSL) for ads ranking,\nempowering the training of models on a significantly larger and more diverse\ndatasets, thereby reducing overfitting and mitigating training-serving data\ndiscrepancies. We provide detailed formal analysis and numerical simulations on\nthe inherent miscalibration and prediction bias of multi-stage ranking systems,\nand show empirical evidence of the proposed framework's capability to mitigate\nthose. Compared to prior work, UKDSL can enable models to learn from a much\nlarger set of unlabeled data, hence, improving the performance while being\ncomputationally efficient. Finally, we report the successful deployment of\nUKDSL in an industrial setting across various ranking models, serving users at\nmulti-billion scale, across various surfaces, geological locations, clients,\nand optimize for various events, which to the best of our knowledge is the\nfirst of its kind in terms of the scale and efficiency at which it operates.",
      "tldr_zh": "该研究针对工业广告排名系统依赖标记数据的局限性（如过拟合、模型扩展增益缓慢以及训练和服务数据偏差），提出了一种统一的框架UKDSL（Unified framework for Knowledge-Distillation and Semi-Supervised Learning）。该框架结合Knowledge-Distillation和Semi-Supervised Learning技术，使模型能够在更大、更多样化的数据集上训练，从而减少过拟合并缓解预测偏差。实验分析和数值模拟证明了UKDSL的有效性，与现有方法相比，它显著提升了性能，同时保持计算效率，并在实际部署中服务数十亿用户，覆盖多种场景，这是首创规模的工业应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06834v1",
      "published_date": "2025-02-05 23:14:07 UTC",
      "updated_date": "2025-02-05 23:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:16:39.577110"
    },
    {
      "arxiv_id": "2502.03660v1",
      "title": "Energy & Force Regression on DFT Trajectories is Not Enough for Universal Machine Learning Interatomic Potentials",
      "title_zh": "翻译失败",
      "authors": [
        "Santiago Miret",
        "Kin Long Kelvin Lee",
        "Carmelo Gonzales",
        "Sajid Mannan",
        "N. M. Anoop Krishnan"
      ],
      "abstract": "Universal Machine Learning Interactomic Potentials (MLIPs) enable accelerated\nsimulations for materials discovery. However, current research efforts fail to\nimpactfully utilize MLIPs due to: 1. Overreliance on Density Functional Theory\n(DFT) for MLIP training data creation; 2. MLIPs' inability to reliably and\naccurately perform large-scale molecular dynamics (MD) simulations for diverse\nmaterials; 3. Limited understanding of MLIPs' underlying capabilities. To\naddress these shortcomings, we aargue that MLIP research efforts should\nprioritize: 1. Employing more accurate simulation methods for large-scale MLIP\ntraining data creation (e.g. Coupled Cluster Theory) that cover a wide range of\nmaterials design spaces; 2. Creating MLIP metrology tools that leverage\nlarge-scale benchmarking, visualization, and interpretability analyses to\nprovide a deeper understanding of MLIPs' inner workings; 3. Developing\ncomputationally efficient MLIPs to execute MD simulations that accurately model\na broad set of materials properties. Together, these interdisciplinary research\ndirections can help further the real-world application of MLIPs to accurately\nmodel complex materials at device scale.",
      "tldr_zh": "这篇论文指出，当前依赖密度函数理论(DFT)轨迹的能量和力回归方法不足以支持通用机器学习原子间势(MLIPs)，因为它过度依赖DFT、无法可靠地进行大规模分子动力学(MD)模拟，以及对MLIPs能力的理解有限。作者建议改进方向，包括采用更准确的模拟方法（如Coupled Cluster Theory）来创建覆盖广泛材料设计空间的大规模训练数据；开发MLIP测量工具，通过大规模基准测试、可视化和可解释性分析加深对MLIPs内部机制的理解；以及创建计算高效的MLIPs，以准确模拟多种材料属性。这些跨学科研究方向有助于推动MLIPs在现实应用中精确建模复杂材料的行为。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03660v1",
      "published_date": "2025-02-05 23:04:21 UTC",
      "updated_date": "2025-02-05 23:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:16:51.288014"
    },
    {
      "arxiv_id": "2503.16432v1",
      "title": "Multimodal Transformer Models for Turn-taking Prediction: Effects on Conversational Dynamics of Human-Agent Interaction during Cooperative Gameplay",
      "title_zh": "翻译失败",
      "authors": [
        "Young-Ho Bae",
        "Casey C. Bennett"
      ],
      "abstract": "This study investigates multimodal turn-taking prediction within human-agent\ninteractions (HAI), particularly focusing on cooperative gaming environments.\nIt comprises both model development and subsequent user study, aiming to refine\nour understanding and improve conversational dynamics in spoken dialogue\nsystems (SDSs). For the modeling phase, we introduce a novel transformer-based\ndeep learning (DL) model that simultaneously integrates multiple modalities -\ntext, vision, audio, and contextual in-game data to predict turn-taking events\nin real-time. Our model employs a Crossmodal Transformer architecture to\neffectively fuse information from these diverse modalities, enabling more\ncomprehensive turn-taking predictions. The model demonstrates superior\nperformance compared to baseline models, achieving 87.3% accuracy and 83.0%\nmacro F1 score. A human user study was then conducted to empirically evaluate\nthe turn-taking DL model in an interactive scenario with a virtual avatar while\nplaying the game \"Dont Starve Together\", comparing a control condition without\nturn-taking prediction (n=20) to an experimental condition with our model\ndeployed (n=40). Both conditions included a mix of English and Korean speakers,\nsince turn-taking cues are known to vary by culture. We then analyzed the\ninteraction quality, examining aspects such as utterance counts, interruption\nfrequency, and participant perceptions of the avatar. Results from the user\nstudy suggest that our multimodal turn-taking model not only enhances the\nfluidity and naturalness of human-agent conversations, but also maintains a\nbalanced conversational dynamic without significantly altering dialogue\nfrequency. The study provides in-depth insights into the influence of\nturn-taking abilities on user perceptions and interaction quality, underscoring\nthe potential for more contextually adaptive and responsive conversational\nagents.",
      "tldr_zh": "本研究探讨多模态 Transformer 模型在人类-代理互动（HAI）中的转接预测，特别针对合作游戏环境，以提升对话系统的对话动态。研究开发了一个基于 Crossmodal Transformer 的深度学习模型，融合文本、视觉、音频和游戏上下文数据，实现实时转接预测，并取得了87.3%的准确率和83.0%的宏 F1 分数，优于基线模型。随后，用户研究在游戏“Dont Starve Together”中比较了无预测控制组（n=20）和使用该模型的实验组（n=40），涉及英语和韩语使用者，结果显示模型显著提高了对话的流畅性和自然性，同时保持了平衡的对话动态。整体而言，该研究为开发更具适应性和响应性的对话代理提供了重要洞见。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "36 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.16432v1",
      "published_date": "2025-02-05 23:00:49 UTC",
      "updated_date": "2025-02-05 23:00:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:17:04.029627"
    },
    {
      "arxiv_id": "2503.04744v1",
      "title": "Safety Cases: A Scalable Approach to Frontier AI Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Hilton",
        "Marie Davidsen Buhl",
        "Tomek Korbak",
        "Geoffrey Irving"
      ],
      "abstract": "Safety cases - clear, assessable arguments for the safety of a system in a\ngiven context - are a widely-used technique across various industries for\nshowing a decision-maker (e.g. boards, customers, third parties) that a system\nis safe. In this paper, we cover how and why frontier AI developers might also\nwant to use safety cases. We then argue that writing and reviewing safety cases\nwould substantially assist in the fulfilment of many of the Frontier AI Safety\nCommitments. Finally, we outline open research questions on the methodology,\nimplementation, and technical details of safety cases.",
      "tldr_zh": "该论文介绍了 safety cases 作为一种清晰、可评估的论证方法，用于证明系统在特定环境下的安全性，已在多个行业广泛应用。作者讨论了前沿 AI 开发者如何及为何采用 safety cases，以提升 AI 系统的可信度和风险管理，并论证其能显著帮助履行 Frontier AI Safety Commitments。最后，论文概述了 safety cases 在方法论、实施和技术细节方面的开放研究问题，为进一步发展提供方向。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "18 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04744v1",
      "published_date": "2025-02-05 22:59:53 UTC",
      "updated_date": "2025-02-05 22:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:17:14.301843"
    },
    {
      "arxiv_id": "2503.04743v1",
      "title": "AI Safety is Stuck in Technical Terms -- A System Safety Response to the International AI Safety Report",
      "title_zh": "AI 安全被困在技术术语",
      "authors": [
        "Roel Dobbe"
      ],
      "abstract": "Safety has become the central value around which dominant AI governance\nefforts are being shaped. Recently, this culminated in the publication of the\nInternational AI Safety Report, written by 96 experts of which 30 nominated by\nthe Organisation for Economic Co-operation and Development (OECD), the European\nUnion (EU), and the United Nations (UN). The report focuses on the safety risks\nof general-purpose AI and available technical mitigation approaches. In this\nresponse, informed by a system safety perspective, I refl ect on the key\nconclusions of the report, identifying fundamental issues in the currently\ndominant technical framing of AI safety and how this frustrates meaningful\ndiscourse and policy efforts to address safety comprehensively. The system\nsafety discipline has dealt with the safety risks of software-based systems for\nmany decades, and understands safety risks in AI systems as sociotechnical and\nrequiring consideration of technical and non-technical factors and their\ninteractions. The International AI Safety report does identify the need for\nsystem safety approaches. Lessons, concepts and methods from system safety\nindeed provide an important blueprint for overcoming current shortcomings in\ntechnical approaches by integrating rather than adding on non-technical factors\nand interventions. I conclude with why building a system safety discipline can\nhelp us overcome limitations in the European AI Act, as well as how the\ndiscipline can help shape sustainable investments into Public Interest AI.",
      "tldr_zh": "该论文从系统安全视角回应国际 AI Safety 报告，指出当前 AI 安全讨论过度依赖技术框架，导致忽略了社会技术因素及其互动，从而阻碍全面政策制定。作者强调，系统安全学科已处理软件系统风险多年，能提供蓝图将技术和非技术因素整合，以更全面缓解 AI 系统的安全风险。实验和分析显示，这种方法有助于克服国际报告的局限性，并为欧洲 AI Act 的改进以及公共利益 AI 的可持续投资提供指导。通过构建系统安全学科，论文为更可靠的 AI 治理奠定基础。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "A response to the International AI Safety Report, which was released\n  in preparation for the AI Action Summit in Paris, February 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04743v1",
      "published_date": "2025-02-05 22:37:53 UTC",
      "updated_date": "2025-02-05 22:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:17:27.424821"
    },
    {
      "arxiv_id": "2502.03656v1",
      "title": "A Study in Dataset Distillation for Image Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Dietz",
        "Brian B. Moser",
        "Tobias Nauen",
        "Federico Raue",
        "Stanislav Frolov",
        "Andreas Dengel"
      ],
      "abstract": "Dataset distillation is the concept of condensing large datasets into smaller\nbut highly representative synthetic samples. While previous research has\nprimarily focused on image classification, its application to image\nSuper-Resolution (SR) remains underexplored. This exploratory work studies\nmultiple dataset distillation techniques applied to SR, including pixel- and\nlatent-space approaches under different aspects. Our experiments demonstrate\nthat a 91.12% dataset size reduction can be achieved while maintaining\ncomparable SR performance to the full dataset. We further analyze\ninitialization strategies and distillation methods to optimize memory\nefficiency and computational costs. Our findings provide new insights into\ndataset distillation for SR and set the stage for future advancements.",
      "tldr_zh": "这篇论文研究了数据集蒸馏(Dataset Distillation)技术在图像超分辨率(Image Super-Resolution)中的应用，旨在将大型数据集浓缩成更小的高代表性合成样本。研究者探索了像素空间和潜在空间下的多种蒸馏方法，并通过实验证明可以实现91.12%的数据集大小减少，同时保持与完整数据集相似的超分辨率性能。论文进一步分析了初始化策略和蒸馏优化，以提升内存效率和计算成本，并为图像超分辨率领域的数据集蒸馏提供了新见解和未来发展基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03656v1",
      "published_date": "2025-02-05 22:34:49 UTC",
      "updated_date": "2025-02-05 22:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:17:39.681771"
    },
    {
      "arxiv_id": "2502.03654v2",
      "title": "Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics",
      "title_zh": "Gompertz 线性单元：利用不对称性增强学习动态",
      "authors": [
        "Indrashis Das",
        "Mahmoud Safari",
        "Steven Adriaensen",
        "Frank Hutter"
      ],
      "abstract": "Activation functions are fundamental elements of deep learning architectures\nas they significantly influence training dynamics. ReLU, while widely used, is\nprone to the dying neuron problem, which has been mitigated by variants such as\nLeakyReLU, PReLU, and ELU that better handle negative neuron outputs. Recently,\nself-gated activations like GELU and Swish have emerged as state-of-the-art\nalternatives, leveraging their smoothness to ensure stable gradient flow and\nprevent neuron inactivity. In this work, we introduce the Gompertz Linear Unit\n(GoLU), a novel self-gated activation function defined as $\\mathrm{GoLU}(x) = x\n\\, \\mathrm{Gompertz}(x)$, where $\\mathrm{Gompertz}(x) = e^{-e^{-x}}$. The GoLU\nactivation leverages the right-skewed asymmetry in the Gompertz function to\nreduce variance in the latent space more effectively compared to GELU and\nSwish, while preserving robust gradient flow. Extensive experiments across\ndiverse tasks, including Image Classification, Language Modeling, Semantic\nSegmentation, Object Detection, Instance Segmentation, and Diffusion, highlight\nGoLU's superior performance relative to state-of-the-art activation functions,\nestablishing GoLU as a robust alternative to existing activation functions.",
      "tldr_zh": "本研究针对深度学习中激活函数的局限性（如ReLU的dying neuron问题），引入了Gompertz Linear Unit (GoLU)，一种新型自门控激活函数，定义为$\\mathrm{GoLU}(x) = x \\cdot \\mathrm{Gompertz}(x)$，其中$\\mathrm{Gompertz}(x) = e^{-e^{-x}}$。GoLU利用Gompertz函数的右偏不对称性，更有效地减少潜在空间的方差，同时确保稳定的梯度流。实验结果显示，在图像分类、语言建模、语义分割、目标检测、实例分割和扩散模型等任务上，GoLU的表现优于GELU和Swish等最先进激活函数，证明了其增强学习动态的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, excluding references and appendix; v2: slight improvement in\n  presentation. Equation (4) added, with proof in Appendix A. Appendices B\n  (Flipped Mish) and I (Machine Translation) added. Figure 9 added to Appendix\n  C. Appendix D extended with Heatmaps 12 and 13",
      "pdf_url": "http://arxiv.org/pdf/2502.03654v2",
      "published_date": "2025-02-05 22:32:22 UTC",
      "updated_date": "2025-05-21 15:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:17:52.865075"
    },
    {
      "arxiv_id": "2502.04388v1",
      "title": "Position: Emergent Machina Sapiens Urge Rethinking Multi-Agent Paradigms",
      "title_zh": "翻译失败",
      "authors": [
        "Hepeng Li",
        "Yuhong Liu",
        "Jun Yan"
      ],
      "abstract": "Artificially intelligent (AI) agents that are capable of autonomous learning\nand independent decision-making hold great promise for addressing complex\nchallenges across domains like transportation, energy systems, and\nmanufacturing. However, the surge in AI systems' design and deployment driven\nby various stakeholders with distinct and unaligned objectives introduces a\ncrucial challenge: how can uncoordinated AI systems coexist and evolve\nharmoniously in shared environments without creating chaos? To address this, we\nadvocate for a fundamental rethinking of existing multi-agent frameworks, such\nas multi-agent systems and game theory, which are largely limited to predefined\nrules and static objective structures. We posit that AI agents should be\nempowered to dynamically adjust their objectives, make compromises, form\ncoalitions, and safely compete or cooperate through evolving relationships and\nsocial feedback. Through this paper, we call for a shift toward the emergent,\nself-organizing, and context-aware nature of these systems.",
      "tldr_zh": "这篇论文强调，随着AI代理在交通、能源和制造等领域实现自主学习和决策，其目标不一致可能导致共享环境中混乱共存的问题，因此需要重新审视现有的multi-agent systems和game theory框架。作者主张赋予AI代理动态调整目标、进行妥协、形成coalitions以及通过演化关系和社会反馈安全竞争或合作的能力。这种转变将推动AI系统向更具emergent（涌现性）、self-organizing（自组织）和context-aware（上下文感知）的范式演进，从而实现更和谐的共存和发展。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04388v1",
      "published_date": "2025-02-05 22:20:15 UTC",
      "updated_date": "2025-02-05 22:20:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:18:03.434478"
    },
    {
      "arxiv_id": "2502.06833v1",
      "title": "Entropy Adaptive Decoding: Dynamic Model Switching for Efficient Inference",
      "title_zh": "熵自适应解码：动态模型切换用于高效推理",
      "authors": [
        "Toby Simonds"
      ],
      "abstract": "We present Entropy Adaptive Decoding (EAD), a novel approach for efficient\nlanguage model inference that dynamically switches between different-sized\nmodels based on prediction uncertainty. By monitoring rolling entropy in model\nlogit distributions, our method identifies text regions where a smaller model\nsuffices and switches to a larger model only when prediction uncertainty\nexceeds a threshold. Unlike speculative decoding approaches that maintain\nperfect output fidelity through verification, EAD accepts controlled output\ndivergence in exchange for computational efficiency. Our experiments on the\nMATH benchmark demonstrate remarkable efficiency gains across different model\nfamilies. Using the LLaMA family, we maintain 96.7\\% of the 11B model's\nperformance (50.4\\% vs 52.1\\%) while using it for only 43\\% of tokens,\ndecreasing computational cost by 41.5\\%. These gains become more pronounced\nwith larger size differentials in the Qwen family, where we achieve 92.9\\% of\nthe 14B model's performance (74.3\\% vs 80.0\\%) while using it for just 25\\% of\ntokens, decreasing computational cost by 67\\%. The consistency of these results\nacross model pairs suggests that language model computation can be\nsignificantly optimized by selectively deploying model capacity based on local\ngeneration complexity. Our findings indicate that current approaches to model\ninference may be unnecessarily conservative in their pursuit of perfect output\nfidelity, and that accepting minor performance trade-offs can enable dramatic\nreductions in computational costs.",
      "tldr_zh": "本研究提出了一种名为 Entropy Adaptive Decoding (EAD) 的方法，用于提升语言模型推理效率，通过监控模型 logit 分布的滚动熵动态切换不同大小的模型。\nEAD 在预测不确定性低于阈值时使用较小模型，以减少计算成本，同时接受受控的输出差异，而非追求完美输出一致性。\n实验在 MATH benchmark 上显示，使用 LLaMA 系列时，EAD 保持了 11B 模型的 96.7% 性能（50.4% vs 52.1%），仅使用大模型 43% 的 token，计算成本降低了 41.5%；在 Qwen 系列中，达到 14B 模型的 92.9% 性能（74.3% vs 80.0%），仅使用大模型 25% 的 token，成本降低了 67%。\n这些发现表明，语言模型计算可以通过基于本地生成复杂度的选择性模型部署实现显著优化，建议接受轻微性能权衡以大幅减少计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06833v1",
      "published_date": "2025-02-05 22:15:21 UTC",
      "updated_date": "2025-02-05 22:15:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:18:17.564790"
    },
    {
      "arxiv_id": "2502.05223v1",
      "title": "KDA: A Knowledge-Distilled Attacker for Generating Diverse Prompts to Jailbreak LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Buyun Liang",
        "Kwan Ho Ryan Chan",
        "Darshan Thaker",
        "Jinqi Luo",
        "René Vidal"
      ],
      "abstract": "Jailbreak attacks exploit specific prompts to bypass LLM safeguards, causing\nthe LLM to generate harmful, inappropriate, and misaligned content. Current\njailbreaking methods rely heavily on carefully designed system prompts and\nnumerous queries to achieve a single successful attack, which is costly and\nimpractical for large-scale red-teaming. To address this challenge, we propose\nto distill the knowledge of an ensemble of SOTA attackers into a single\nopen-source model, called Knowledge-Distilled Attacker (KDA), which is\nfinetuned to automatically generate coherent and diverse attack prompts without\nthe need for meticulous system prompt engineering. Compared to existing\nattackers, KDA achieves higher attack success rates and greater cost-time\nefficiency when targeting multiple SOTA open-source and commercial black-box\nLLMs. Furthermore, we conducted a quantitative diversity analysis of prompts\ngenerated by baseline methods and KDA, identifying diverse and ensemble attacks\nas key factors behind KDA's effectiveness and efficiency.",
      "tldr_zh": "该论文提出 KDA（Knowledge-Distilled Attacker），一种通过知识蒸馏技术从多个 SOTA 攻击者中提炼知识的模型，用于自动生成多样化的攻击提示，从而绕过 LLM 的安全机制（Jailbreak attacks）。与现有方法相比，KDA 无需精心设计的系统提示和大量查询，就能实现更高的攻击成功率和成本效率，在针对多种开源和商业黑箱 LLM 时表现出色。研究还通过定量多样性分析发现，提示的多样性和集成攻击是 KDA 有效性的关键因素，为大规模红队测试提供了更实用的工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05223v1",
      "published_date": "2025-02-05 21:50:34 UTC",
      "updated_date": "2025-02-05 21:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:18:27.371833"
    },
    {
      "arxiv_id": "2502.04387v1",
      "title": "FedP$^2$EFT: Federated Learning to Personalize Parameter Efficient Fine-Tuning for Multilingual LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Royson Lee",
        "Minyoung Kim",
        "Fady Rezk",
        "Rui Li",
        "Stylianos I. Venieris",
        "Timothy Hospedales"
      ],
      "abstract": "Federated learning (FL) has enabled the training of multilingual large\nlanguage models (LLMs) on diverse and decentralized multilingual data,\nespecially on low-resource languages. To improve client-specific performance,\npersonalization via the use of parameter-efficient fine-tuning (PEFT) modules\nsuch as LoRA is common. This involves a personalization strategy (PS), such as\nthe design of the PEFT adapter structures (e.g., in which layers to add LoRAs\nand what ranks) and choice of hyperparameters (e.g., learning rates) for\nfine-tuning. Instead of manual PS configuration, we propose FedP$^2$EFT, a\nfederated learning-to-personalize method for multilingual LLMs in cross-device\nFL settings. Unlike most existing PEFT structure selection methods, which are\nprone to overfitting low-data regimes, FedP$^2$EFT collaboratively learns the\noptimal personalized PEFT structure for each client via Bayesian sparse rank\nselection. Evaluations on both simulated and real-world multilingual FL\nbenchmarks demonstrate that FedP$^2$EFT largely outperforms existing\npersonalized fine-tuning methods, while complementing a range of existing FL\nmethods.",
      "tldr_zh": "该论文提出FedP²EFT，一种联邦学习(Federated Learning, FL)方法，用于个性化参数高效微调(Parameter Efficient Fine-Tuning, PEFT)多语言大型语言模型(Multilingual LLMs)，以提升客户端特定性能并处理低资源语言数据。不同于手动配置PEFT适配器结构（如LoRA的层级和秩），FedP²EFT通过Bayesian sparse rank selection协作学习每个客户端的最佳个性化结构，避免过度拟合低数据问题。在模拟和真实多语言FL基准测试中，该方法大幅优于现有个性化微调方法，并与多种FL技术互补。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.04387v1",
      "published_date": "2025-02-05 21:36:21 UTC",
      "updated_date": "2025-02-05 21:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:18:41.519011"
    },
    {
      "arxiv_id": "2502.03629v2",
      "title": "REALEDIT: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations",
      "title_zh": "REALEDIT：Reddit 编辑作为大规模实证图像变换数据集",
      "authors": [
        "Peter Sushko",
        "Ayana Bharadwaj",
        "Zhi Yang Lim",
        "Vasily Ilin",
        "Ben Caffee",
        "Dongping Chen",
        "Mohammadreza Salehi",
        "Cheng-Yu Hsieh",
        "Ranjay Krishna"
      ],
      "abstract": "Existing image editing models struggle to meet real-world demands. Despite\nexcelling in academic benchmarks, they have yet to be widely adopted for real\nuser needs. Datasets that power these models use artificial edits, lacking the\nscale and ecological validity necessary to address the true diversity of user\nrequests. We introduce REALEDIT, a large-scale image editing dataset with\nauthentic user requests and human-made edits sourced from Reddit. REALEDIT\nincludes a test set of 9300 examples to evaluate models on real user requests.\nOur results show that existing models fall short on these tasks, highlighting\nthe need for realistic training data. To address this, we introduce 48K\ntraining examples and train our REALEDIT model, achieving substantial gains -\noutperforming competitors by up to 165 Elo points in human judgment and 92\npercent relative improvement on the automated VIEScore metric. We deploy our\nmodel on Reddit, testing it on new requests, and receive positive feedback.\nBeyond image editing, we explore REALEDIT's potential in detecting edited\nimages by partnering with a deepfake detection non-profit. Finetuning their\nmodel on REALEDIT data improves its F1-score by 14 percentage points,\nunderscoring the dataset's value for broad applications.",
      "tldr_zh": "本文提出 REALEDIT，这是一个从 Reddit 收集的大规模真实图像编辑数据集，包含真实用户请求和人类编辑示例，以解决现有图像编辑模型在实际应用中的不足。数据集提供 9300 个测试示例和 48K 训练示例，训练的 REALEDIT 模型在人类判断中领先竞争对手高达 165 Elo points，并在 VIEScore 指标上实现 92% 的相对提升。实验结果表明，该数据集不仅提升了图像编辑性能，还在检测编辑图像（如 deepfake）方面通过微调提高了 F1-score 14 百分点，展示了其在更广泛应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.03629v2",
      "published_date": "2025-02-05 21:35:48 UTC",
      "updated_date": "2025-04-29 00:30:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:18:53.008688"
    },
    {
      "arxiv_id": "2502.03628v1",
      "title": "The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuowei Li",
        "Haizhou Shi",
        "Yunhe Gao",
        "Di Liu",
        "Zhenting Wang",
        "Yuxiao Chen",
        "Ting Liu",
        "Long Zhao",
        "Hao Wang",
        "Dimitris N. Metaxas"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) can reason effectively over both textual\nand visual inputs, but they tend to hallucinate syntactically coherent yet\nvisually ungrounded contents. In this paper, we investigate the internal\ndynamics of hallucination by examining the tokens logits rankings throughout\nthe generation process, revealing three key patterns in how LVLMs process\ninformation: (1) gradual visual information loss -- visually grounded tokens\ngradually become less favored throughout generation, and (2) early excitation\n-- semantically meaningful tokens achieve peak activation in the layers earlier\nthan the final layer. (3) hidden genuine information -- visually grounded\ntokens though not being eventually decided still retain relatively high\nrankings at inference. Based on these insights, we propose VISTA (Visual\nInformation Steering with Token-logit Augmentation), a training-free\ninference-time intervention framework that reduces hallucination while\npromoting genuine information. VISTA works by combining two complementary\napproaches: reinforcing visual information in activation space and leveraging\nearly layer activations to promote semantically meaningful decoding. Compared\nto existing methods, VISTA requires no external supervision and is applicable\nto various decoding strategies. Extensive experiments show that VISTA on\naverage reduces hallucination by abount 40% on evaluated open-ended generation\ntask, and it consistently outperforms existing methods on four benchmarks\nacross four architectures under three decoding strategies.",
      "tldr_zh": "本研究探讨了大型视觉语言模型(LVLMs)的幻觉(hallucination)问题，通过分析tokens的logits rankings，发现了三个关键模式：渐进的视觉信息丢失(visual information loss)、早期兴奋(early excitation)以及隐藏的真实信息(hidden genuine information)。为此，提出VISTA(Visual Information Steering with Token-logit Augmentation)，一个无需训练的推理时干预框架，结合强化激活空间的视觉信息和利用早期层激活来促进语义有意义的解码。实验结果显示，VISTA在开放生成任务中平均减少幻觉约40%，并在四个基准上超越现有方法，适用于多种架构和解码策略。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03628v1",
      "published_date": "2025-02-05 21:34:02 UTC",
      "updated_date": "2025-02-05 21:34:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:19:06.309611"
    },
    {
      "arxiv_id": "2502.03622v2",
      "title": "AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails",
      "title_zh": "翻译失败",
      "authors": [
        "Rei Meguro",
        "Ng S. T. Chong"
      ],
      "abstract": "Phishing attacks remain a significant threat in the digital age, yet\norganizations lack effective methods to tackle phishing attacks without leaking\nsensitive information. Phish bowl initiatives are a vital part of cybersecurity\nefforts against these attacks. However, traditional phish bowls require manual\nanonymization and are often limited to internal use. To overcome these\nlimitations, we introduce AdaPhish, an AI-powered phish bowl platform that\nautomatically anonymizes and analyzes phishing emails using large language\nmodels (LLMs) and vector databases. AdaPhish achieves real-time detection and\nadaptation to new phishing tactics while enabling long-term tracking of\nphishing trends. Through automated reporting, adaptive analysis, and real-time\nalerts, AdaPhish presents a scalable, collaborative solution for phishing\ndetection and cybersecurity education.",
      "tldr_zh": "该研究针对 phishing attacks 的威胁，提出 AdaPhish，一种 AI 驱动的适应性防御平台，使用 large language models (LLMs) 和 vector databases 自动 anonymize 和分析 phishing emails，以克服传统 phish bowl 的手动处理和内部限制问题。AdaPhish 支持实时检测、适应新 phishing 策略以及长期趋势跟踪，通过 automated reporting、adaptive analysis 和 real-time alerts 提供可扩展的协作解决方案。最后，该平台有助于提升 phishing detection 和 cybersecurity education 的效果。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 3 figures, 2 tables, accepted in 4th IEEE International\n  Conference on AI in Cybersecurity (ICAIC)",
      "pdf_url": "http://arxiv.org/pdf/2502.03622v2",
      "published_date": "2025-02-05 21:17:19 UTC",
      "updated_date": "2025-02-10 19:12:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:19:16.545161"
    },
    {
      "arxiv_id": "2502.18477v1",
      "title": "Recommendations Beyond Catalogs: Diffusion Models for Personalized Generation",
      "title_zh": "超越目录的推荐：扩散模型用于个性化生成",
      "authors": [
        "Gabriel Patron",
        "Zhiwei Xu",
        "Ishan Kapnadak",
        "Felipe Maia Polo"
      ],
      "abstract": "Modern recommender systems follow the guiding principle of serving the right\nuser, the right item at the right time. One of their main limitations is that\nthey are typically limited to items already in the catalog. We propose\nREcommendations BEyond CAtalogs, REBECA, a new class of probabilistic\ndiffusion-based recommender systems that synthesize new items tailored to\nindividual tastes rather than retrieve items from the catalog. REBECA combines\nefficient training in embedding space with a novel diffusion prior that only\nrequires users' past ratings of items. We evaluate REBECA on real-world data\nand propose novel personalization metrics for generative recommender systems.\nExtensive experiments demonstrate that REBECA produces high-quality,\npersonalized recommendations, generating images that align with users' unique\npreferences.",
      "tldr_zh": "本论文提出 REBECA，一种基于 diffusion models 的新型推荐系统，旨在超越传统目录限制，通过合成个性化新物品来满足用户独特偏好。该系统结合嵌入空间的效率训练和创新的 diffusion prior，仅需用户过去的评分数据即可生成推荐。实验在真实数据上验证，REBECA 产生高质量、与用户偏好高度一致的图像，并引入新的个性化指标，显著提升了推荐系统的性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18477v1",
      "published_date": "2025-02-05 21:11:47 UTC",
      "updated_date": "2025-02-05 21:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:19:27.888740"
    },
    {
      "arxiv_id": "2502.03614v1",
      "title": "A Novel Zero-Touch, Zero-Trust, AI/ML Enablement Framework for IoT Network Security",
      "title_zh": "翻译失败",
      "authors": [
        "Sushil Shakya",
        "Robert Abbas",
        "Sasa Maric"
      ],
      "abstract": "The IoT facilitates a connected, intelligent, and sustainable society;\ntherefore, it is imperative to protect the IoT ecosystem. The IoT-based 5G and\n6G will leverage the use of machine learning and artificial intelligence\n(ML/AI) more to pave the way for autonomous and collaborative secure IoT\nnetworks. Zero-touch, zero-trust IoT security with AI and machine learning (ML)\nenablement frameworks offers a powerful approach to securing the expanding\nlandscape of Internet of Things (IoT) devices. This paper presents a novel\nframework based on the integration of Zero Trust, Zero Touch, and AI/ML powered\nfor the detection, mitigation, and prevention of DDoS attacks in modern IoT\necosystems. The focus will be on the new integrated framework by establishing\nzero trust for all IoT traffic, fixed and mobile 5G/6G IoT network traffic, and\ndata security (quarantine-zero touch and dynamic policy enforcement). We\nperform a comparative analysis of five machine learning models, namely,\nXGBoost, Random Forest, K-Nearest Neighbors, Stochastic Gradient Descent, and\nNative Bayes, by comparing these models based on accuracy, precision, recall,\nF1-score, and ROC-AUC. Results show that the best performance in detecting and\nmitigating different DDoS vectors comes from the ensemble-based approaches.",
      "tldr_zh": "本论文提出一个新型框架，结合 Zero Trust、Zero Touch 和 AI/ML 技术，用于检测、缓解和预防 IoT 网络中的 DDoS 攻击，从而提升 IoT 生态系统的安全性。框架重点建立对所有 IoT 流量、5G/6G 网络数据进行零信任验证，并采用零触碰机制实现动态策略执行和数据隔离。研究者比较了五种机器学习模型，包括 XGBoost、Random Forest、K-Nearest Neighbors、Stochastic Gradient Descent 和 Naive Bayes，结果显示集成方法在准确率、精确率、召回率、F1-score 和 ROC-AUC 等指标上表现出最佳性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03614v1",
      "published_date": "2025-02-05 21:03:07 UTC",
      "updated_date": "2025-02-05 21:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:19:41.279447"
    },
    {
      "arxiv_id": "2503.15530v2",
      "title": "A Beautiful Mind: Principles and Strategies for AI-Augmented Human Reasoning",
      "title_zh": "A Beautiful Mind：AI增强人类推理的原则和策略",
      "authors": [
        "Sean Koon"
      ],
      "abstract": "Amidst the race to create more intelligent machines there is a risk that we\nwill rely on AI in ways that reduce our own agency as humans. To reduce this\nrisk, we could aim to create tools that prioritize and enhance the human role\nin human-AI interactions. This paper outlines a human-centered augmented\nreasoning paradigm by 1. Articulating fundamental principles for augmented\nreasoning tools, emphasizing their ergonomic, pre-conclusive, directable,\nexploratory, enhancing, and integrated nature; 2. Proposing a 'many tasks, many\ntools' approach to ensuring human influence and control, and 3. Offering\nexamples of interaction modes that can serve as bridges between human reasoning\nand AI algorithms.",
      "tldr_zh": "这篇论文探讨了在追求更智能AI的过程中，避免人类过度依赖AI而削弱自身能动性的风险，并提出以人为中心的人机增强推理范式。论文阐述了增强推理工具的基本原则，包括ergonomic（人体工程学）、pre-conclusive（预结论）、directable（可指导）、exploratory（探索性）、enhancing（增强性）和integrated（集成性）。此外，它建议采用“many tasks, many tools”的方法来确保人类的影响力和控制，并提供交互模式示例，作为人类推理与AI算法之间的桥梁，以优先提升人类在人机互动中的作用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "13 pages, 7062 words, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.15530v2",
      "published_date": "2025-02-05 20:57:29 UTC",
      "updated_date": "2025-04-11 03:41:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:19:52.023812"
    },
    {
      "arxiv_id": "2502.03608v1",
      "title": "(GG) MoE vs. MLP on Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Chernov"
      ],
      "abstract": "In recent years, significant efforts have been directed toward adapting\nmodern neural network architectures for tabular data. However, despite their\nlarger number of parameters and longer training and inference times, these\nmodels often fail to consistently outperform vanilla multilayer perceptron\n(MLP) neural networks. Moreover, MLP-based ensembles have recently demonstrated\nsuperior performance and efficiency compared to advanced deep learning methods.\nTherefore, rather than focusing on building deeper and more complex deep\nlearning models, we propose investigating whether MLP neural networks can be\nreplaced with more efficient architectures without sacrificing performance. In\nthis paper, we first introduce GG MoE, a mixture-of-experts (MoE) model with a\nGumbel-Softmax gating function. We then demonstrate that GG MoE with an\nembedding layer achieves the highest performance across $38$ datasets compared\nto standard MoE and MLP models. Finally, we show that both MoE and GG MoE\nutilize significantly fewer parameters than MLPs, making them a promising\nalternative for scaling and ensemble methods.",
      "tldr_zh": "本研究探讨了在表格数据上，混合专家(Mixture-of-Experts, MoE)模型是否能取代多层感知器(Multilayer Perceptron, MLP)以提高效率和性能。作者引入了GG MoE，一种采用Gumbel-Softmax门控函数的MoE变体，并结合嵌入层，在38个数据集上实现了比标准MoE和MLP更高的表现。结果显示，GG MoE在使用更少参数的情况下表现出色，为扩展和集成方法提供了更高效的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03608v1",
      "published_date": "2025-02-05 20:53:16 UTC",
      "updated_date": "2025-02-05 20:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:20:04.462852"
    },
    {
      "arxiv_id": "2502.03607v1",
      "title": "Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhao Liang",
        "Jacob K Christopher",
        "Sven Koenig",
        "Ferdinando Fioretto"
      ],
      "abstract": "Recent advances in diffusion models hold significant potential in robotics,\nenabling the generation of diverse and smooth trajectories directly from raw\nrepresentations of the environment. Despite this promise, applying diffusion\nmodels to motion planning remains challenging due to their difficulty in\nenforcing critical constraints, such as collision avoidance and kinematic\nfeasibility. These limitations become even more pronounced in Multi-Robot\nMotion Planning (MRMP), where multiple robots must coordinate in shared spaces.\nTo address this challenge, this work proposes Simultaneous MRMP Diffusion\n(SMD), a novel approach integrating constrained optimization into the diffusion\nsampling process to produce collision-free, kinematically feasible\ntrajectories. Additionally, the paper introduces a comprehensive MRMP benchmark\nto evaluate trajectory planning algorithms across scenarios with varying robot\ndensities, obstacle complexities, and motion constraints. Experimental results\nshow SMD consistently outperforms classical and learning-based motion planners,\nachieving higher success rates and efficiency in complex multi-robot\nenvironments.",
      "tldr_zh": "本研究探讨了 diffusion models 在多机器人运动规划（Multi-Robot Motion Planning, MRMP）中的应用，解决了这些模型在强制执行避障和运动学可行性约束方面的挑战。作者提出 Simultaneous MRMP Diffusion (SMD) 方法，将约束优化集成到 diffusion sampling 过程中，从而生成无碰撞且可行的轨迹。论文还引入了一个全面的 MRMP 基准，用于评估算法在不同机器人密度、障碍复杂度和运动约束场景下的性能；实验结果显示，SMD 比传统和基于学习的规划器表现出色，在复杂环境中实现了更高的成功率和效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03607v1",
      "published_date": "2025-02-05 20:51:28 UTC",
      "updated_date": "2025-02-05 20:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:20:16.285539"
    },
    {
      "arxiv_id": "2502.06832v2",
      "title": "Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach",
      "title_zh": "在混合专家中优化鲁棒性和准确性：一种双模型方法",
      "authors": [
        "Xu Zhang",
        "Kaidi Xu",
        "Ziqing Hu",
        "Ren Wang"
      ],
      "abstract": "Mixture of Experts (MoE) have shown remarkable success in leveraging\nspecialized expert networks for complex machine learning tasks. However, their\nsusceptibility to adversarial attacks presents a critical challenge for\ndeployment in robust applications. This paper addresses the critical question\nof how to incorporate robustness into MoEs while maintaining high natural\naccuracy. We begin by analyzing the vulnerability of MoE components, finding\nthat expert networks are notably more susceptible to adversarial attacks than\nthe router. Based on this insight, we propose a targeted robust training\ntechnique that integrates a novel loss function to enhance the adversarial\nrobustness of MoE, requiring only the robustification of one additional expert\nwithout compromising training or inference efficiency. Building on this, we\nintroduce a dual-model strategy that linearly combines a standard MoE model\nwith our robustified MoE model using a smoothing parameter. This approach\nallows for flexible control over the robustness-accuracy trade-off. We further\nprovide theoretical foundations by deriving certified robustness bounds for\nboth the single MoE and the dual-model. To push the boundaries of robustness\nand accuracy, we propose a novel joint training strategy JTDMoE for the\ndual-model. This joint training enhances both robustness and accuracy beyond\nwhat is achievable with separate models. Experimental results on CIFAR-10 and\nTinyImageNet datasets using ResNet18 and Vision Transformer (ViT) architectures\ndemonstrate the effectiveness of our proposed methods.",
      "tldr_zh": "这篇论文针对Mixture of Experts (MoE)模型在对抗攻击下的脆弱性，提出了一种双模型方法来优化鲁棒性和准确性。研究者首先分析了MoE组件的漏洞，发现专家网络比路由器更容易受攻击，并开发了针对性鲁棒训练技术，使用新损失函数强化一个额外专家，同时保持训练和推理效率。论文引入双模型策略，通过线性组合标准MoE模型和鲁棒化MoE模型的平滑参数，实现鲁棒性与准确性的灵活权衡，并为单MoE和双模型推导了认证鲁棒性边界。实验结果在CIFAR-10和TinyImageNet数据集上，使用ResNet18和Vision Transformer (ViT)架构，证明了该方法显著提升了鲁棒性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures, submitted to ICML 2025 (under review)",
      "pdf_url": "http://arxiv.org/pdf/2502.06832v2",
      "published_date": "2025-02-05 20:45:52 UTC",
      "updated_date": "2025-02-12 05:30:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:20:29.811737"
    },
    {
      "arxiv_id": "2502.10424v1",
      "title": "QuantSpec: Self-Speculative Decoding with Hierarchical Quantized KV Cache",
      "title_zh": "翻译失败",
      "authors": [
        "Rishabh Tiwari",
        "Haocheng Xi",
        "Aditya Tomar",
        "Coleman Hooper",
        "Sehoon Kim",
        "Maxwell Horton",
        "Mahyar Najibi",
        "Michael W. Mahoney",
        "Kurt Keutzer",
        "Amir Gholami"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being deployed on edge devices\nfor long-context settings, creating a growing need for fast and efficient\nlong-context inference. In these scenarios, the Key-Value (KV) cache is the\nprimary bottleneck in terms of both GPU memory and latency, as the full KV\ncache must be loaded for each decoding step. While speculative decoding is a\nwidely accepted technique to accelerate autoregressive decoding, existing\nmethods often struggle to achieve significant speedups due to inefficient KV\ncache optimization strategies and result in low acceptance rates. To address\nthese challenges, we propose a novel self-speculative decoding framework,\nQuantSpec, where the draft model shares the architecture of the target model\nbut employs a hierarchical 4-bit quantized KV cache and 4-bit quantized weights\nfor acceleration. QuantSpec maintains high acceptance rates ($>$90%) and\nreliably provides consistent end-to-end speedups upto $\\sim2.5\\times$,\noutperforming other self-speculative decoding methods that use sparse KV cache\nfor long-context LLM inference. QuantSpec also reduces the memory requirements\nby $\\sim 1.3\\times$ compared to these alternatives.",
      "tldr_zh": "该论文提出 QuantSpec，一种自推测性解码框架，针对大语言模型(LLMs)在长上下文推理中的 KV 缓存瓶颈问题，通过分层 4-bit 量化 KV 缓存和权重来加速推理过程。QuantSpec 的草稿模型与目标模型共享架构，确保高接受率（>90%），并实现高达约2.5倍的端到端加速，同时减少约1.3倍的内存需求。相比其他方法，该框架在长上下文 LLM 推理中表现出色，提供更高效的优化策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10424v1",
      "published_date": "2025-02-05 20:43:48 UTC",
      "updated_date": "2025-02-05 20:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:20:40.927600"
    },
    {
      "arxiv_id": "2503.04742v1",
      "title": "A case for specialisation in non-human entities",
      "title_zh": "非人类实体的专业化论证",
      "authors": [
        "El-Mahdi El-Mhamdi",
        "Lê-Nguyên Hoang",
        "Mariame Tighanimine"
      ],
      "abstract": "With the rise of large multi-modal AI models, fuelled by recent interest in\nlarge language models (LLMs), the notion of artificial general intelligence\n(AGI) went from being restricted to a fringe community, to dominate mainstream\nlarge AI development programs.\n  In contrast, in this paper, we make a \\emph{case for specialisation}, by\nreviewing the pitfalls of generality and stressing the industrial value of\nspecialised\n  systems.\n  Our contribution is threefold. First, we review the most widely accepted\narguments \\emph{against} specialisation, and discuss how their relevance in the\ncontext of human labour is actually an argument \\emph{for} specialisation in\nthe case of non human agents, be they algorithms or human organisations.\nSecond, we propose four arguments \\emph{in favor of} specialisation, ranging\nfrom machine learning robustness, to computer security, social sciences and\ncultural evolution.\n  Third, we finally make a case for \\emph{specification}, discuss how the\nmachine learning approach to AI has so far failed to catch up with good\npractices from safety-engineering and formal verification of software, and\ndiscuss how some emerging good practices in machine learning help reduce this\ngap.\n  In particular, we justify the need for \\emph{specified governance} for\nhard-to-specify systems.",
      "tldr_zh": "这篇论文主张在非人类实体（如算法或组织）中推行专业化（specialisation），而非追求人工通用智能（AGI），通过审视其工业价值和潜在优势来反驳当前主流AI发展趋势。作者首先分析了反对专业化的常见论点，并解释这些在人类劳动中适用的理由反而支持非人类实体的专业化；其次，提出四个支持专业化的论点，涵盖机器学习鲁棒性、计算机安全、社会科学和文化演化。最终，论文强调规格化（specification）的必要性，批评机器学习方法未能跟上安全工程和软件形式验证的良好实践，并呼吁实施指定的治理（specified governance）来管理复杂系统。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04742v1",
      "published_date": "2025-02-05 20:38:18 UTC",
      "updated_date": "2025-02-05 20:38:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:20:53.027594"
    },
    {
      "arxiv_id": "2502.04386v1",
      "title": "Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Guangyao Zheng",
        "Michael A. Jacobs",
        "Vladimir Braverman",
        "Vishwa S. Parekh"
      ],
      "abstract": "Self-supervised learning has revolutionized medical imaging by enabling\nefficient and generalizable feature extraction from large-scale unlabeled\ndatasets. Recently, self-supervised foundation models have been extended to\nthree-dimensional (3D) computed tomography (CT) data, generating compact,\ninformation-rich embeddings with 1408 features that achieve state-of-the-art\nperformance on downstream tasks such as intracranial hemorrhage detection and\nlung cancer risk forecasting. However, these embeddings have been shown to\nencode demographic information, such as age, sex, and race, which poses a\nsignificant risk to the fairness of clinical applications.\n  In this work, we propose a Variation Autoencoder (VAE) based adversarial\ndebiasing framework to transform these embeddings into a new latent space where\ndemographic information is no longer encoded, while maintaining the performance\nof critical downstream tasks. We validated our approach on the NLST lung cancer\nscreening dataset, demonstrating that the debiased embeddings effectively\neliminate multiple encoded demographic information and improve fairness without\ncompromising predictive accuracy for lung cancer risk at 1-year and 2-year\nintervals. Additionally, our approach ensures the embeddings are robust against\nadversarial bias attacks. These results highlight the potential of adversarial\ndebiasing techniques to ensure fairness and equity in clinical applications of\nself-supervised 3D CT embeddings, paving the way for their broader adoption in\nunbiased medical decision-making.",
      "tldr_zh": "该研究针对自监督学习生成的 3D CT 嵌入中编码的人口统计信息（如年龄、性别和种族）导致的公平性风险，提出了一种基于 Variation Autoencoder (VAE) 的对抗性去偏框架。\n该框架将嵌入转换为新的潜在空间，消除这些人口统计信息，同时保持下游任务（如肺癌风险预测）的预测准确性。\n在 NLST 肺癌筛查数据集上验证显示，去偏嵌入显著提高了公平性，并对对抗性偏见攻击具有鲁棒性，从而推动自监督 3D CT 嵌入在无偏医疗决策中的更广泛应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04386v1",
      "published_date": "2025-02-05 20:32:42 UTC",
      "updated_date": "2025-02-05 20:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:21:06.796883"
    },
    {
      "arxiv_id": "2502.03591v1",
      "title": "Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function",
      "title_zh": "翻译失败",
      "authors": [
        "Mehrdad Asadi",
        "Komi Sodoké",
        "Ian J. Gerard",
        "Marta Kersten-Oertel"
      ],
      "abstract": "In this work, we present a novel approach to multi-label chest X-ray (CXR)\nimage classification that enhances clinical interpretability while maintaining\na streamlined, single-model, single-run training pipeline. Leveraging the\nCheXpert dataset and VisualCheXbert-derived labels, we incorporate hierarchical\nlabel groupings to capture clinically meaningful relationships between\ndiagnoses. To achieve this, we designed a custom hierarchical binary\ncross-entropy (HBCE) loss function that enforces label dependencies using\neither fixed or data-driven penalty types. Our model achieved a mean area under\nthe receiver operating characteristic curve (AUROC) of 0.903 on the test set.\nAdditionally, we provide visual explanations and uncertainty estimations to\nfurther enhance model interpretability. All code, model configurations, and\nexperiment details are made available.",
      "tldr_zh": "本文提出了一种基于临床启发的层级多-label分类方法，用于胸部X光图像（CXR），通过自定义的hierarchical binary cross-entropy (HBCE)损失函数来强制标签依赖，并利用CheXpert数据集和VisualCheXbert-derived标签捕捉诊断间的临床关系。 该方法采用单模型单运行训练管道，显著提升了模型的临床可解释性。 实验结果显示，模型在测试集上达到了0.903的平均AUROC，并提供了视觉解释和不确定性估计。 所有代码、模型配置和实验细节均已公开，以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages with 3 figures, for associated implementation see\n  https://github.com/the-mercury/CIHMLC",
      "pdf_url": "http://arxiv.org/pdf/2502.03591v1",
      "published_date": "2025-02-05 20:15:06 UTC",
      "updated_date": "2025-02-05 20:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:21:16.476184"
    },
    {
      "arxiv_id": "2502.04385v2",
      "title": "TexLiDAR: Automated Text Understanding for Panoramic LiDAR Data",
      "title_zh": "翻译失败",
      "authors": [
        "Naor Cohen",
        "Roy Orfaig",
        "Ben-Zion Bobrovsky"
      ],
      "abstract": "Efforts to connect LiDAR data with text, such as LidarCLIP, have primarily\nfocused on embedding 3D point clouds into CLIP text-image space. However, these\napproaches rely on 3D point clouds, which present challenges in encoding\nefficiency and neural network processing. With the advent of advanced LiDAR\nsensors like Ouster OS1, which, in addition to 3D point clouds, produce fixed\nresolution depth, signal, and ambient panoramic 2D images, new opportunities\nemerge for LiDAR based tasks. In this work, we propose an alternative approach\nto connect LiDAR data with text by leveraging 2D imagery generated by the OS1\nsensor instead of 3D point clouds. Using the Florence 2 large model in a\nzero-shot setting, we perform image captioning and object detection. Our\nexperiments demonstrate that Florence 2 generates more informative captions and\nachieves superior performance in object detection tasks compared to existing\nmethods like CLIP. By combining advanced LiDAR sensor data with a large\npre-trained model, our approach provides a robust and accurate solution for\nchallenging detection scenarios, including real-time applications requiring\nhigh accuracy and robustness.",
      "tldr_zh": "该研究提出TexLiDAR，一种自动化文本理解方法，用于处理全景LiDAR数据，取代传统依赖3D点云的方法，转而利用Ouster OS1传感器生成的固定分辨率深度、信号和环境2D图像，以提升编码效率和神经网络处理。作者采用Florence 2大模型在零样本设置下进行图像描述和物体检测，实验显示其生成的描述更具信息性，并在物体检测任务上比CLIP等现有方法表现优越。总体而言，这种结合先进LiDAR数据的策略为高准确性和鲁棒性的实时应用提供了可靠解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04385v2",
      "published_date": "2025-02-05 19:41:06 UTC",
      "updated_date": "2025-02-21 16:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:21:29.039743"
    },
    {
      "arxiv_id": "2502.03571v2",
      "title": "A Multi-Task Learning Approach to Linear Multivariate Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Liran Nochumsohn",
        "Hedi Zisling",
        "Omri Azencot"
      ],
      "abstract": "Accurate forecasting of multivariate time series data is important in many\nengineering and scientific applications. Recent state-of-the-art works ignore\nthe inter-relations between variates, using their model on each variate\nindependently. This raises several research questions related to proper\nmodeling of multivariate data. In this work, we propose to view multivariate\nforecasting as a multi-task learning problem, facilitating the analysis of\nforecasting by considering the angle between task gradients and their balance.\nTo do so, we analyze linear models to characterize the behavior of tasks. Our\nanalysis suggests that tasks can be defined by grouping similar variates\ntogether, which we achieve via a simple clustering that depends on\ncorrelation-based similarities. Moreover, to balance tasks, we scale gradients\nwith respect to their prediction error. Then, each task is solved with a linear\nmodel within our MTLinear framework. We evaluate our approach on challenging\nbenchmarks in comparison to strong baselines, and we show it obtains on-par or\nbetter results on multivariate forecasting problems. The implementation is\navailable at: https://github.com/azencot-group/MTLinear",
      "tldr_zh": "本文提出一种基于多任务学习(multi-task learning)的线性多变量预测(multivariate forecasting)方法，以解决现有模型忽略变量间关系的问题。作者通过分析线性模型的行为，建议使用基于相关性相似度的聚类将相似变量分组定义任务，并通过预测错误缩放梯度来平衡各任务。实验结果显示，该方法在MTLinear框架下，在多个基准测试中与强基线相比，取得了相当或更好的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS 2025 (accepted)",
      "pdf_url": "http://arxiv.org/pdf/2502.03571v2",
      "published_date": "2025-02-05 19:34:23 UTC",
      "updated_date": "2025-03-15 08:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:21:39.880592"
    },
    {
      "arxiv_id": "2502.03568v2",
      "title": "Code Simulation as a Proxy for High-order Tasks in Large Language Models",
      "title_zh": "代码模拟作为大语言模型中高阶任务的代理",
      "authors": [
        "Emanuele La Malfa",
        "Christoph Weinhuber",
        "Orazio Torre",
        "Fangru Lin",
        "X. Angelo Huang",
        "Samuele Marro",
        "Anthony Cohn",
        "Nigel Shadbolt",
        "Michael Wooldridge"
      ],
      "abstract": "Many reasoning, planning, and problem-solving tasks share an intrinsic\nalgorithmic nature: correctly simulating each step is a sufficient condition to\nsolve them correctly. We collect pairs of naturalistic and synthetic reasoning\ntasks to assess the capabilities of Large Language Models (LLM). While\nnaturalistic tasks often require careful human handcrafting, we show that\nsynthetic data is, in many cases, a good proxy that is much easier to collect\nat scale. We leverage common constructs in programming as the counterpart of\nthe building blocks of naturalistic reasoning tasks, such as straight-line\nprograms, code that contains critical paths, and approximate and redundant\ninstructions. We further assess the capabilities of LLMs on sorting problems\nand repeated operations via sorting algorithms and nested loops. Our synthetic\ndatasets further reveal that while the most powerful LLMs exhibit relatively\nstrong execution capabilities, the process is fragile: it is negatively\naffected by memorisation and seems to rely heavily on pattern recognition. Our\ncontribution builds upon synthetically testing the reasoning capabilities of\nLLMs as a scalable complement to handcrafted human-annotated problems.",
      "tldr_zh": "这篇论文提出使用代码模拟作为大型语言模型(LLMs)处理高阶任务（如推理、规划和问题解决）的代理，通过收集自然任务和合成任务对来评估LLMs的能力。作者利用编程结构（如直线程序、关键路径代码和排序算法）作为这些任务的对应物，证明合成数据比手工设计更易于大规模获取。实验发现，虽然强大LLMs显示出较强的执行能力，但该过程脆弱，受记忆影响和模式识别依赖较大；整体贡献在于提供一种可扩展的合成测试方法，作为手工标注问题的补充。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2401.09074\n  Authors note: this article is a substantial revision of arXiv:2401.09074\n  (same team)",
      "pdf_url": "http://arxiv.org/pdf/2502.03568v2",
      "published_date": "2025-02-05 19:30:28 UTC",
      "updated_date": "2025-02-16 18:32:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:21:53.435297"
    },
    {
      "arxiv_id": "2502.04384v1",
      "title": "Enhancing Reasoning to Adapt Large Language Models for Domain-Specific Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Wen",
        "Xin Zhang"
      ],
      "abstract": "This paper presents SOLOMON, a novel Neuro-inspired Large Language Model\n(LLM) Reasoning Network architecture that enhances the adaptability of\nfoundation models for domain-specific applications. Through a case study in\nsemiconductor layout design, we demonstrate how SOLOMON enables swift\nadaptation of general-purpose LLMs to specialized tasks by leveraging Prompt\nEngineering and In-Context Learning techniques. Our experiments reveal the\nchallenges LLMs face in spatial reasoning and applying domain knowledge to\npractical problems. Results show that SOLOMON instances significantly\noutperform their baseline LLM counterparts and achieve performance comparable\nto state-of-the-art reasoning model, o1-preview. We discuss future research\ndirections for developing more adaptive AI systems that can continually learn,\nadapt, and evolve in response to new information and changing requirements.",
      "tldr_zh": "本论文提出 SOLOMON，一种受神经启发（Neuro-inspired）的 LLM Reasoning Network 架构，用于增强 Large Language Models (LLMs) 在特定领域应用的适应性。该框架通过 Prompt Engineering 和 In-Context Learning 技术，实现对通用模型的快速调整，并在半导体布局设计案例中解决了空间推理和领域知识应用的挑战。实验结果显示，SOLOMON 显著优于基线模型，并达到与 o1-preview 相当的性能水平；论文还探讨了未来 AI 系统持续学习和适应性发展的研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "68T09, 68T35, 68T45, 94C30",
        "I.2.7; I.2.11; B.7.2"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 Workshop AFM (Adaptive Foundation Models: Evolving AI\n  for Personalized and Efficient Learning)",
      "pdf_url": "http://arxiv.org/pdf/2502.04384v1",
      "published_date": "2025-02-05 19:27:24 UTC",
      "updated_date": "2025-02-05 19:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:22:04.936945"
    },
    {
      "arxiv_id": "2502.03545v1",
      "title": "Proportional Selection in Networks",
      "title_zh": "网络中的比例选择",
      "authors": [
        "Georgios Papasotiropoulos",
        "Oskar Skibski",
        "Piotr Skowron",
        "Tomasz Wąs"
      ],
      "abstract": "We address the problem of selecting $k$ representative nodes from a network,\naiming to achieve two objectives: identifying the most influential nodes and\nensuring the selection proportionally reflects the network's diversity. We\npropose two approaches to accomplish this, analyze them theoretically, and\ndemonstrate their effectiveness through a series of experiments.",
      "tldr_zh": "这篇论文探讨了在网络中选择 k 个代表性节点的问题，旨在识别最有影响力的节点并确保选择比例反映网络的多样性。研究者提出了两种方法，并对其进行了理论分析。实验结果证明了这些方法的有效性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03545v1",
      "published_date": "2025-02-05 19:02:20 UTC",
      "updated_date": "2025-02-05 19:02:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:22:15.183070"
    },
    {
      "arxiv_id": "2502.03544v2",
      "title": "Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2",
      "title_zh": "翻译失败",
      "authors": [
        "Yuri Chervonyi",
        "Trieu H. Trinh",
        "Miroslav Olšák",
        "Xiaomeng Yang",
        "Hoang Nguyen",
        "Marcelo Menegali",
        "Junehyuk Jung",
        "Vikas Verma",
        "Quoc V. Le",
        "Thang Luong"
      ],
      "abstract": "We present AlphaGeometry2, a significantly improved version of AlphaGeometry\nintroduced in Trinh et al. (2024), which has now surpassed an average gold\nmedalist in solving Olympiad geometry problems. To achieve this, we first\nextend the original AlphaGeometry language to tackle harder problems involving\nmovements of objects, and problems containing linear equations of angles,\nratios, and distances. This, together with support for non-constructive\nproblems, has markedly improved the coverage rate of the AlphaGeometry language\non International Math Olympiads (IMO) 2000-2024 geometry problems from 66% to\n88%. The search process of AlphaGeometry2 has also been greatly improved\nthrough the use of Gemini architecture for better language modeling, and a\nnovel knowledge-sharing mechanism that enables effective communication between\nsearch trees. Together with further enhancements to the symbolic engine and\nsynthetic data generation, we have significantly boosted the overall solving\nrate of AlphaGeometry2 to 84% for $\\textit{all}$ geometry problems over the\nlast 25 years, compared to 54% previously. AlphaGeometry2 was also part of the\nsystem that achieved silver-medal standard at IMO 2024\nhttps://dpmd.ai/imo-silver. Last but not least, we report progress towards\nusing AlphaGeometry2 as a part of a fully automated system that reliably solves\ngeometry problems directly from natural language input.",
      "tldr_zh": "本研究介绍了AlphaGeometry2，这是AlphaGeometry的改进版本，已在解决国际数学奥林匹克(IMO)几何问题上超越平均金牌得主表现。关键改进包括扩展语言支持以处理更复杂的问题，如物体运动、非构造性问题以及角度、比率和距离的线性方程，从而将IMO 2000-2024几何问题覆盖率从66%提高到88%。AlphaGeometry2采用Gemini架构提升语言建模，并引入知识共享机制优化搜索过程，同时增强符号引擎和合成数据生成，使整体解决率从54%提升至84%。此外，该系统在IMO 2024中帮助实现银牌标准，并正朝向基于自然语言输入的完全自动化几何问题解决系统发展。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 16 figures. V2: Clarified abstract, rewritten introduction,\n  updated results on diagram generation, added acknowledgement section",
      "pdf_url": "http://arxiv.org/pdf/2502.03544v2",
      "published_date": "2025-02-05 19:02:03 UTC",
      "updated_date": "2025-02-28 23:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:22:29.223580"
    },
    {
      "arxiv_id": "2502.03540v3",
      "title": "Path Planning for Masked Diffusion Model Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Fred Zhangzhi Peng",
        "Zachary Bezemek",
        "Sawan Patel",
        "Jarrid Rector-Brooks",
        "Sherwood Yao",
        "Alexander Tong",
        "Pranam Chatterjee"
      ],
      "abstract": "In this paper, we explore how token unmasking order influences generative\nquality in masked diffusion models (MDMs). We derive an expanded evidence lower\nbound (ELBO) that introduces a planner to select which tokens to unmask at each\nstep. Our analysis reveals that alternative unmasking strategies can enhance\ngeneration performance. Building on this, we propose Path Planning (P2), a\nsampling framework that uses a pre-trained BERT model or the denoiser itself to\nguide unmasking decisions. P2 generalizes all known MDM sampling strategies and\nsignificantly improves performance across diverse domains, including language\ngeneration (in-context learning, code generation, story infilling, mathematical\nreasoning, reverse curse correction) and biological sequence generation\n(protein and RNA sequences).",
      "tldr_zh": "本论文探讨了在 masked diffusion models (MDMs) 中，token unmasking 顺序对生成质量的影响，并推导了一个扩展的 evidence lower bound (ELBO) 来引入规划器，以优化 unmasking 策略。作者提出 Path Planning (P2) 框架，使用预训练的 BERT 模型或 denoiser 本身指导 unmasking 决策，该框架泛化了所有已知 MDM 采样方法。实验结果显示，P2 在多种领域（如语言生成中的 in-context learning、代码生成、故事填充、数学推理、reverse curse correction，以及生物序列生成如蛋白和 RNA 序列）中显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03540v3",
      "published_date": "2025-02-05 19:00:52 UTC",
      "updated_date": "2025-02-17 16:07:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:22:41.016734"
    },
    {
      "arxiv_id": "2502.03465v2",
      "title": "Seeing World Dynamics in a Nutshell",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuhong Shen",
        "Xuanyu Yi",
        "Mingbao Lin",
        "Hanwang Zhang",
        "Shuicheng Yan",
        "Xinchao Wang"
      ],
      "abstract": "We consider the problem of efficiently representing casually captured\nmonocular videos in a spatially- and temporally-coherent manner. While existing\napproaches predominantly rely on 2D/2.5D techniques treating videos as\ncollections of spatiotemporal pixels, they struggle with complex motions,\nocclusions, and geometric consistency due to absence of temporal coherence and\nexplicit 3D structure. Drawing inspiration from monocular video as a projection\nof the dynamic 3D world, we explore representing videos in their intrinsic 3D\nform through continuous flows of Gaussian primitives in space-time. In this\npaper, we propose NutWorld, a novel framework that efficiently transforms\nmonocular videos into dynamic 3D Gaussian representations in a single forward\npass. At its core, NutWorld introduces a structured spatial-temporal aligned\nGaussian (STAG) representation, enabling optimization-free scene modeling with\neffective depth and flow regularization. Through comprehensive experiments, we\ndemonstrate that NutWorld achieves high-fidelity video reconstruction quality\nwhile enabling various downstream applications in real-time. Demos and code\nwill be available at https://github.com/Nut-World/NutWorld.",
      "tldr_zh": "本论文探讨了高效表示随意捕捉的单目视频（monocular videos）的问题，旨在实现空间和时间连贯性，以解决现有2D/2.5D技术在处理复杂运动、遮挡和几何一致性方面的不足。研究提出NutWorld框架，通过将视频转化为动态3D Gaussian表示，并在单次前向传递中引入结构化的空间-时间对齐高斯（STAG）表示，实现无优化的场景建模，并结合深度和流动正则化。实验结果表明，NutWorld实现了高保真视频重建，并支持实时下游应用，如代码和演示已在GitHub上提供。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03465v2",
      "published_date": "2025-02-05 18:59:52 UTC",
      "updated_date": "2025-03-17 06:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:22:52.674686"
    },
    {
      "arxiv_id": "2502.04382v2",
      "title": "Sparse Autoencoders for Hypothesis Generation",
      "title_zh": "稀疏自动编码器",
      "authors": [
        "Rajiv Movva",
        "Kenny Peng",
        "Nikhil Garg",
        "Jon Kleinberg",
        "Emma Pierson"
      ],
      "abstract": "We describe HypotheSAEs, a general method to hypothesize interpretable\nrelationships between text data (e.g., headlines) and a target variable (e.g.,\nclicks). HypotheSAEs has three steps: (1) train a sparse autoencoder on text\nembeddings to produce interpretable features describing the data distribution,\n(2) select features that predict the target variable, and (3) generate a\nnatural language interpretation of each feature (e.g., \"mentions being\nsurprised or shocked\") using an LLM. Each interpretation serves as a hypothesis\nabout what predicts the target variable. Compared to baselines, our method\nbetter identifies reference hypotheses on synthetic datasets (at least +0.06 in\nF1) and produces more predictive hypotheses on real datasets (~twice as many\nsignificant findings), despite requiring 1-2 orders of magnitude less compute\nthan recent LLM-based methods. HypotheSAEs also produces novel discoveries on\ntwo well-studied tasks: explaining partisan differences in Congressional\nspeeches and identifying drivers of engagement with online headlines.",
      "tldr_zh": "本文提出 HypotheSAEs 方法，利用 Sparse Autoencoders 生成可解释的文本数据（如标题）和目标变量（如点击量）之间的假设关系。方法分为三步：首先在文本嵌入上训练 Sparse Autoencoders 以提取可解释特征；其次选择能预测目标变量的特征；最后使用 LLM 生成自然语言解释（如“mentions being surprised or shocked”），每个解释作为假设。相比基线方法，该方法在合成数据集上 F1 分数至少提高 0.06，在真实数据集上产生约两倍的显著发现，且计算量减少 1-2 个数量级。此外，HypotheSAEs 在解释国会演讲党派差异和识别在线标题参与驱动因素方面取得了新发现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "First two authors contributed equally; working paper. Code is\n  available at https://github.com/rmovva/HypotheSAEs",
      "pdf_url": "http://arxiv.org/pdf/2502.04382v2",
      "published_date": "2025-02-05 18:58:02 UTC",
      "updated_date": "2025-03-18 17:51:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:23:04.875773"
    },
    {
      "arxiv_id": "2502.03460v1",
      "title": "Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training",
      "title_zh": "翻译失败",
      "authors": [
        "Boyao Wang",
        "Rui Pan",
        "Shizhe Diao",
        "Xingyuan Pan",
        "Jipeng Zhang",
        "Renjie Pi",
        "Tong Zhang"
      ],
      "abstract": "Small language models (SLMs) have attracted considerable attention from both\nacademia and industry due to their broad range of applications in edge devices.\nTo obtain SLMs with strong performance, conventional approaches either\npre-train the models from scratch, which incurs substantial computational\ncosts, or compress/prune existing large language models (LLMs), which results\nin performance drops and falls short in comparison to pre-training. In this\npaper, we investigate the family of acceleration methods that involve both\nstructured pruning and model training. We found 1) layer-wise adaptive pruning\n(Adapt-Pruner) is extremely effective in LLMs and yields significant\nimprovements over existing pruning techniques, 2) adaptive pruning equipped\nwith further training leads to models comparable to those pre-training from\nscratch, 3) incremental pruning brings non-trivial performance gain by\ninterleaving pruning with training and only removing a small portion of neurons\n($\\sim$5%) at a time. Experimental results on LLaMA-3.1-8B demonstrate that\nAdapt-Pruner outperforms conventional pruning methods, such as LLM-Pruner,\nFLAP, and SliceGPT, by an average of 1%-7% in accuracy on commonsense\nbenchmarks. Additionally, Adapt-Pruner restores the performance of\nMobileLLM-125M to 600M on the MMLU benchmark with 200$\\times$ fewer tokens via\npruning from its larger counterparts, and discovers a new 1B model that\nsurpasses LLaMA-3.2-1B in multiple benchmarks.",
      "tldr_zh": "本文提出Adapt-Pruner，一种自适应结构化修剪方法，用于高效训练小语言模型（SLMs），以解决传统预训练成本高或修剪导致性能下降的问题。该方法通过层级自适应修剪（Adapt-Pruner）和增量修剪（每次仅移除约5%的神经元）结合模型训练，实现与从零预训练相当的性能，并在LLaMA-3.1-8B上比现有方法如LLM-Pruner、FLAP和SliceGPT平均提高1%-7%的准确率。此外，Adapt-Pruner通过从更大模型修剪，将MobileLLM-125M的性能提升至相当于600M水平，并发现了一个在新1B模型中超越LLaMA-3.2-1B的成果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03460v1",
      "published_date": "2025-02-05 18:57:40 UTC",
      "updated_date": "2025-02-05 18:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:23:17.552173"
    },
    {
      "arxiv_id": "2502.03450v1",
      "title": "A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)",
      "title_zh": "翻译失败",
      "authors": [
        "Yiye Chen",
        "Harpreet Sawhney",
        "Nicholas Gydé",
        "Yanan Jian",
        "Jack Saunders",
        "Patricio Vela",
        "Ben Lundell"
      ],
      "abstract": "Scene graphs have emerged as a structured and serializable environment\nrepresentation for grounded spatial reasoning with Large Language Models\n(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason\nframework for reasoning and planning with scene graphs. Our approach employs\ntwo cooperative, code-writing LLM agents: a (1) Reasoner for task planning and\ninformation queries generation, and a (2) Retriever for extracting\ncorresponding graph information following the queries. Two agents collaborate\niteratively, enabling sequential reasoning and adaptive attention to graph\ninformation. Unlike prior works, both agents are prompted only with the scene\ngraph schema rather than the full graph data, which reduces the hallucination\nby limiting input tokens, and drives the Reasoner to generate reasoning trace\nabstractly.Following the trace, the Retriever programmatically query the scene\ngraph data based on the schema understanding, allowing dynamic and global\nattention on the graph that enhances alignment between reasoning and retrieval.\nThrough experiments in multiple simulation environments, we show that our\nframework surpasses existing LLM-based approaches in numerical Q\\&A and\nplanning tasks, and can benefit from task-level few-shot examples, even in the\nabsence of agent-level demonstrations. Project code will be released.",
      "tldr_zh": "本文提出了一种 Schema-Guided Reason-while-Retrieve (SG-RwR) 框架，用于在 Scene Graphs 上进行推理和规划，以提升 Large Language Models (LLMs) 的空间推理能力。该框架采用两个合作 LLM 代理——Reasoner 负责任务规划和信息查询生成，以及 Retriever 负责根据查询提取图信息——通过迭代协作实现顺序推理和动态关注，仅依赖场景图 schema 而非完整数据，减少了幻觉并提高了推理与检索的 alignment。通过多模拟环境实验，SG-RwR 在数字 Q&A 和规划任务中超越现有 LLM 方法，并能从任务级少样本示例中获益，即使缺少代理级演示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03450v1",
      "published_date": "2025-02-05 18:50:38 UTC",
      "updated_date": "2025-02-05 18:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:23:28.719226"
    },
    {
      "arxiv_id": "2502.03512v2",
      "title": "YINYANG-ALIGN: Benchmarking Contradictory Objectives and Proposing Multi-Objective Optimization based DPO for Text-to-Image Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Amitava Das",
        "Yaswanth Narsupalli",
        "Gurpreet Singh",
        "Vinija Jain",
        "Vasu Sharma",
        "Suranjana Trivedy",
        "Aman Chadha",
        "Amit Sheth"
      ],
      "abstract": "Precise alignment in Text-to-Image (T2I) systems is crucial to ensure that\ngenerated visuals not only accurately encapsulate user intents but also conform\nto stringent ethical and aesthetic benchmarks. Incidents like the Google Gemini\nfiasco, where misaligned outputs triggered significant public backlash,\nunderscore the critical need for robust alignment mechanisms. In contrast,\nLarge Language Models (LLMs) have achieved notable success in alignment.\nBuilding on these advancements, researchers are eager to apply similar\nalignment techniques, such as Direct Preference Optimization (DPO), to T2I\nsystems to enhance image generation fidelity and reliability.\n  We present YinYangAlign, an advanced benchmarking framework that\nsystematically quantifies the alignment fidelity of T2I systems, addressing six\nfundamental and inherently contradictory design objectives. Each pair\nrepresents fundamental tensions in image generation, such as balancing\nadherence to user prompts with creative modifications or maintaining diversity\nalongside visual coherence. YinYangAlign includes detailed axiom datasets\nfeaturing human prompts, aligned (chosen) responses, misaligned (rejected)\nAI-generated outputs, and explanations of the underlying contradictions.",
      "tldr_zh": "该研究提出了YinYang-Align基准框架，用于评估Text-to-Image (T2I) 系统的对齐保真度，解决生成图像在准确反映用户意图、遵守道德标准和处理内在矛盾目标（如平衡提示遵守与创意修改）方面的挑战。框架系统量化了六个相互矛盾的设计目标，并提供详细的公理数据集，包括人类提示、对齐（chosen）响应、未对齐（rejected）输出及矛盾解释。作者进一步提出基于多目标优化的Direct Preference Optimization (DPO) 方法，旨在提升T2I系统的图像生成可靠性和忠实度，借鉴Large Language Models (LLMs)的成功经验。实验结果表明，此方法可有效缓解T2I对齐问题，如Google Gemini事件所示的风险。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03512v2",
      "published_date": "2025-02-05 18:46:20 UTC",
      "updated_date": "2025-02-10 02:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:23:40.673414"
    },
    {
      "arxiv_id": "2502.03444v1",
      "title": "Masked Autoencoders Are Effective Tokenizers for Diffusion Models",
      "title_zh": "掩码自动编码器是扩散模型的有效分词器",
      "authors": [
        "Hao Chen",
        "Yujin Han",
        "Fangyi Chen",
        "Xiang Li",
        "Yidong Wang",
        "Jindong Wang",
        "Ze Wang",
        "Zicheng Liu",
        "Difan Zou",
        "Bhiksha Raj"
      ],
      "abstract": "Recent advances in latent diffusion models have demonstrated their\neffectiveness for high-resolution image synthesis. However, the properties of\nthe latent space from tokenizer for better learning and generation of diffusion\nmodels remain under-explored. Theoretically and empirically, we find that\nimproved generation quality is closely tied to the latent distributions with\nbetter structure, such as the ones with fewer Gaussian Mixture modes and more\ndiscriminative features. Motivated by these insights, we propose MAETok, an\nautoencoder (AE) leveraging mask modeling to learn semantically rich latent\nspace while maintaining reconstruction fidelity. Extensive experiments validate\nour analysis, demonstrating that the variational form of autoencoders is not\nnecessary, and a discriminative latent space from AE alone enables\nstate-of-the-art performance on ImageNet generation using only 128 tokens.\nMAETok achieves significant practical improvements, enabling a gFID of 1.69\nwith 76x faster training and 31x higher inference throughput for 512x512\ngeneration. Our findings show that the structure of the latent space, rather\nthan variational constraints, is crucial for effective diffusion models. Code\nand trained models are released.",
      "tldr_zh": "本研究发现，扩散模型的生成质量与潜在空间的结构密切相关，例如更少的Gaussian Mixture模式和更具区分性的特征，从而提升图像合成性能。作者提出MAETok，一种基于Masked Autoencoders的自动编码器(AE)，通过掩码建模学习语义丰富的潜在空间，同时保持重建保真度，而无需变分形式。实验结果显示，MAETok在ImageNet生成任务中使用仅128个token即可达到最先进性能，实现gFID为1.69，并在512x512图像生成上训练速度快76倍、推理吞吐量高31倍，证明潜在空间结构比变分约束更关键。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03444v1",
      "published_date": "2025-02-05 18:42:04 UTC",
      "updated_date": "2025-02-05 18:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:23:52.697101"
    },
    {
      "arxiv_id": "2502.03438v2",
      "title": "BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Xin",
        "Chenguang Xi",
        "Jie Yang",
        "Feng Chen",
        "Hang Wu",
        "Xia Xiao",
        "Yifan Sun",
        "Shen Zheng",
        "Kai Shen"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have spurred growing\ninterest in automatic theorem proving using Lean4, where effective tree search\nmethods are crucial for navigating the underlying large proof search spaces.\nWhile the existing approaches primarily rely on value functions and/or Monte\nCarlo Tree Search (MCTS), the potential of simpler methods like Best-First Tree\nSearch (BFS) remains underexplored. In this paper, we investigate whether BFS\ncan achieve competitive performance in large-scale theorem proving tasks. We\npresent BFS-Prover, a scalable expert iteration framework, featuring three key\ninnovations. First, we implement strategic data filtering at each expert\niteration round, excluding problems solvable via beam search node expansion to\nfocus on harder cases. Second, we improve the sample efficiency of BFS through\nDirect Preference Optimization (DPO) applied to state-tactic pairs\nautomatically annotated with compiler error feedback, refining the LLM's policy\nto prioritize productive expansions. Third, we employ length normalization in\nBFS to encourage exploration of deeper proof paths. BFS-Prover achieves a\nstate-of-the-art score of $72.95\\%$ on the MiniF2F test set and therefore\nchallenges the perceived necessity of complex tree search methods,\ndemonstrating that BFS can achieve competitive performance when properly\nscaled. To facilitate further research and development in this area, we have\nopen-sourced our model at https://huggingface.co/bytedance-research/BFS-Prover.",
      "tldr_zh": "本论文提出 BFS-Prover，一种可扩展的 Best-First Tree Search (BFS) 框架，用于提升大型语言模型 (LLMs) 在 Lean4 自动定理证明中的性能，通过战略数据过滤、Direct Preference Optimization (DPO) 优化状态-策略对以及长度归一化来改进样本效率和探索深度。相比传统依赖价值函数或 Monte Carlo Tree Search (MCTS) 的方法，该框架专注于更难的问题，确保高效的证明路径扩展。实验结果显示，BFS-Prover 在 MiniF2F 测试集上达到 72.95% 的最先进分数，证明 BFS 在大规模任务中可与复杂方法竞争，并已开源模型以促进进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03438v2",
      "published_date": "2025-02-05 18:33:36 UTC",
      "updated_date": "2025-02-24 10:56:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:24:05.795949"
    },
    {
      "arxiv_id": "2502.03429v1",
      "title": "On Fairness of Unified Multimodal Large Language Model for Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Liu",
        "Hao Chen",
        "Jindong Wang",
        "Liwen Wang",
        "Bhiksha Raj Ramakrishnan",
        "Wensheng Zhang"
      ],
      "abstract": "Unified multimodal large language models (U-MLLMs) have demonstrated\nimpressive performance in visual understanding and generation in an end-to-end\npipeline. Compared with generation-only models (e.g., Stable Diffusion),\nU-MLLMs may raise new questions about bias in their outputs, which can be\naffected by their unified capabilities. This gap is particularly concerning\ngiven the under-explored risk of propagating harmful stereotypes. In this\npaper, we benchmark the latest U-MLLMs and find that most exhibit significant\ndemographic biases, such as gender and race bias. To better understand and\nmitigate this issue, we propose a locate-then-fix strategy, where we audit and\nshow how the individual model component is affected by bias. Our analysis shows\nthat bias originates primarily from the language model. More interestingly, we\nobserve a \"partial alignment\" phenomenon in U-MLLMs, where understanding bias\nappears minimal, but generation bias remains substantial. Thus, we propose a\nnovel balanced preference model to balance the demographic distribution with\nsynthetic data. Experiments demonstrate that our approach reduces demographic\nbias while preserving semantic fidelity. We hope our findings underscore the\nneed for more holistic interpretation and debiasing strategies of U-MLLMs in\nthe future.",
      "tldr_zh": "这篇论文探讨了统一多模态大语言模型 (U-MLLMs) 在图像生成中的公平性问题，发现大多数模型存在显著的人口统计学偏见，如性别和种族偏见，与生成-only 模型（如 Stable Diffusion）相比，这种偏见可能通过统一能力放大。研究者提出 locate-then-fix 策略，通过审计模型组件发现偏见主要源于语言模型，并观察到 partial alignment 现象，即理解偏见较小但生成偏见较大。为缓解此问题，他们引入了 balanced preference model，使用合成数据平衡人口统计分布，实验证明此方法能有效减少偏见同时保持语义保真。最终，论文呼吁未来需要更全面的解释和去偏策略来提升 U-MLLMs 的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03429v1",
      "published_date": "2025-02-05 18:21:03 UTC",
      "updated_date": "2025-02-05 18:21:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:24:17.325547"
    },
    {
      "arxiv_id": "2502.03426v1",
      "title": "TruePose: Human-Parsing-guided Attention Diffusion for Full-ID Preserving Pose Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihong Xu",
        "Dongxia Wang",
        "Peng Du",
        "Yang Cao",
        "Qing Guo"
      ],
      "abstract": "Pose-Guided Person Image Synthesis (PGPIS) generates images that maintain a\nsubject's identity from a source image while adopting a specified target pose\n(e.g., skeleton). While diffusion-based PGPIS methods effectively preserve\nfacial features during pose transformation, they often struggle to accurately\nmaintain clothing details from the source image throughout the diffusion\nprocess. This limitation becomes particularly problematic when there is a\nsubstantial difference between the source and target poses, significantly\nimpacting PGPIS applications in the fashion industry where clothing style\npreservation is crucial for copyright protection. Our analysis reveals that\nthis limitation primarily stems from the conditional diffusion model's\nattention modules failing to adequately capture and preserve clothing patterns.\nTo address this limitation, we propose human-parsing-guided attention\ndiffusion, a novel approach that effectively preserves both facial and clothing\nappearance while generating high-quality results. We propose a\nhuman-parsing-aware Siamese network that consists of three key components: dual\nidentical UNets (TargetNet for diffusion denoising and SourceNet for source\nimage embedding extraction), a human-parsing-guided fusion attention (HPFA),\nand a CLIP-guided attention alignment (CAA). The HPFA and CAA modules can embed\nthe face and clothes patterns into the target image generation adaptively and\neffectively. Extensive experiments on both the in-shop clothes retrieval\nbenchmark and the latest in-the-wild human editing dataset demonstrate our\nmethod's significant advantages over 13 baseline approaches for preserving both\nfacial and clothes appearance in the source image.",
      "tldr_zh": "论文提出 TruePose 方法，针对 Pose-Guided Person Image Synthesis (PGPIS) 的问题，通过 human-parsing-guided attention diffusion 有效保留源图像的面部和衣服细节，尤其在源目标姿势差异大时。该方法采用人类解析感知的 Siamese 网络，包括双重 UNet（TargetNet 用于扩散去噪，SourceNet 用于源图像嵌入提取）、HPFA（人类解析引导融合注意力）和 CAA（CLIP 引导注意力对齐）模块，实现自适应嵌入面部和衣服图案。在 in-shop 衣服检索基准和 in-the-wild 人类编辑数据集上的实验表明，TruePose 优于 13 个基线方法，在保留身份方面表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03426v1",
      "published_date": "2025-02-05 18:15:11 UTC",
      "updated_date": "2025-02-05 18:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:24:30.973278"
    },
    {
      "arxiv_id": "2502.04381v1",
      "title": "Limitations of Large Language Models in Clinical Problem-Solving Arising from Inflexible Reasoning",
      "title_zh": "大语言模型在临床问题解决中的局限性：源于不灵活的推理",
      "authors": [
        "Jonathan Kim",
        "Anna Podlasek",
        "Kie Shidara",
        "Feng Liu",
        "Ahmed Alaa",
        "Danilo Bernardo"
      ],
      "abstract": "Large Language Models (LLMs) have attained human-level accuracy on medical\nquestion-answer (QA) benchmarks. However, their limitations in navigating\nopen-ended clinical scenarios have recently been shown, raising concerns about\nthe robustness and generalizability of LLM reasoning across diverse, real-world\nmedical tasks. To probe potential LLM failure modes in clinical\nproblem-solving, we present the medical abstraction and reasoning corpus\n(M-ARC). M-ARC assesses clinical reasoning through scenarios designed to\nexploit the Einstellung effect -- the fixation of thought arising from prior\nexperience, targeting LLM inductive biases toward inflexible pattern matching\nfrom their training data rather than engaging in flexible reasoning. We find\nthat LLMs, including current state-of-the-art o1 and Gemini models, perform\npoorly compared to physicians on M-ARC, often demonstrating lack of commonsense\nmedical reasoning and a propensity to hallucinate. In addition, uncertainty\nestimation analyses indicate that LLMs exhibit overconfidence in their answers,\ndespite their limited accuracy. The failure modes revealed by M-ARC in LLM\nmedical reasoning underscore the need to exercise caution when deploying these\nmodels in clinical settings.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 在临床问题解决中的局限性，主要源于其刚性推理模式。研究者引入了医疗抽象和推理语料库 (M-ARC)，通过设计基于Einstellung effect（思维固化）的场景，测试LLMs 是否依赖训练数据模式匹配而非灵活推理。结果显示，包括o1和Gemini在内的LLMs 在M-ARC 上表现远逊于医生，常缺乏常识医疗推理并出现幻觉，且其不确定性分析揭示了LLMs 的过度自信问题。该发现强调，在临床环境中部署LLMs 时需谨慎，以避免潜在风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04381v1",
      "published_date": "2025-02-05 18:14:27 UTC",
      "updated_date": "2025-02-05 18:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:24:40.494730"
    },
    {
      "arxiv_id": "2502.03511v1",
      "title": "An Empirical Exploration of ChatGPT's Ability to Support Problem Formulation Tasks for Mission Engineering and a Documentation of its Performance Variability",
      "title_zh": "翻译失败",
      "authors": [
        "Max Ofsa",
        "Taylan G. Topcu"
      ],
      "abstract": "Systems engineering (SE) is evolving with the availability of generative\nartificial intelligence (AI) and the demand for a systems-of-systems\nperspective, formalized under the purview of mission engineering (ME) in the US\nDepartment of Defense. Formulating ME problems is challenging because they are\nopen-ended exercises that involve translation of ill-defined problems into\nwell-defined ones that are amenable for engineering development. It remains to\nbe seen to which extent AI could assist problem formulation objectives. To that\nend, this paper explores the quality and consistency of multi-purpose Large\nLanguage Models (LLM) in supporting ME problem formulation tasks, specifically\nfocusing on stakeholder identification. We identify a relevant reference\nproblem, a NASA space mission design challenge, and document ChatGPT-3.5's\nability to perform stakeholder identification tasks. We execute multiple\nparallel attempts and qualitatively evaluate LLM outputs, focusing on both\ntheir quality and variability. Our findings portray a nuanced picture. We find\nthat the LLM performs well in identifying human-focused stakeholders but poorly\nin recognizing external systems and environmental factors, despite explicit\nefforts to account for these. Additionally, LLMs struggle with preserving the\ndesired level of abstraction and exhibit a tendency to produce solution\nspecific outputs that are inappropriate for problem formulation. More\nimportantly, we document great variability among parallel threads, highlighting\nthat LLM outputs should be used with caution, ideally by adopting a stochastic\nview of their abilities. Overall, our findings suggest that, while ChatGPT\ncould reduce some expert workload, its lack of consistency and domain\nunderstanding may limit its reliability for problem formulation tasks.",
      "tldr_zh": "这篇论文实证探讨了 ChatGPT 在 Mission Engineering (ME) 问题制定任务中的表现，特别是利益相关者识别能力。研究采用一个 NASA 空间任务作为参考问题，通过多重平行尝试和定性评估，分析了 ChatGPT-3.5 的输出质量和变异性。结果显示，ChatGPT 擅长识别人类利益相关者，但对外部系统和环境因素识别较差，且难以保持适当的抽象水平，常输出不适用的解决方案。总体而言，虽然 ChatGPT 可减轻专家工作量，但其输出不一致性和领域理解不足，限制了其在 ME 任务中的可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 3 figures, submitted to Conference on Systems Engineering\n  Research (CSER)",
      "pdf_url": "http://arxiv.org/pdf/2502.03511v1",
      "published_date": "2025-02-05 17:58:23 UTC",
      "updated_date": "2025-02-05 17:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:24:53.182024"
    },
    {
      "arxiv_id": "2502.03403v1",
      "title": "Lightweight Authenticated Task Offloading in 6G-Cloud Vehicular Twin Networks",
      "title_zh": "6G-云车辆孪生网络中的轻量级认证任务卸载",
      "authors": [
        "Sarah Al-Shareeda",
        "Fusun Ozguner",
        "Keith Redmill",
        "Trung Q. Duong",
        "Berk Canberk"
      ],
      "abstract": "Task offloading management in 6G vehicular networks is crucial for\nmaintaining network efficiency, particularly as vehicles generate substantial\ndata. Integrating secure communication through authentication introduces\nadditional computational and communication overhead, significantly impacting\noffloading efficiency and latency. This paper presents a unified framework\nincorporating lightweight Identity-Based Cryptographic (IBC) authentication\ninto task offloading within cloud-based 6G Vehicular Twin Networks (VTNs).\nUtilizing Proximal Policy Optimization (PPO) in Deep Reinforcement Learning\n(DRL), our approach optimizes authenticated offloading decisions to minimize\nlatency and enhance resource allocation. Performance evaluation under varying\nnetwork sizes, task sizes, and data rates reveals that IBC authentication can\nreduce offloading efficiency by up to 50% due to the added overhead. Besides,\nincreasing network size and task size can further reduce offloading efficiency\nby up to 91.7%. As a countermeasure, increasing the transmission data rate can\nimprove the offloading performance by as much as 63%, even in the presence of\nauthentication overhead. The code for the simulations and experiments detailed\nin this paper is available on GitHub for further reference and reproducibility\n[1].",
      "tldr_zh": "这篇论文针对 6G 云基车联网双生网络 (Vehicular Twin Networks, VTNs) 中的任务卸载问题，提出一个整合轻量级 Identity-Based Cryptographic (IBC) 认证的统一框架，以缓解安全通信带来的计算和通信开销。框架利用 Proximal Policy Optimization (PPO) 在 Deep Reinforcement Learning (DRL) 中优化认证卸载决策，从而最小化延迟并提升资源分配效率。实验评估显示，IBC 认证可能导致卸载效率降低高达 50%，而增加网络规模或任务规模进一步加剧此问题至 91.7%；然而，提高传输数据率可改善性能达 63%，并提供 GitHub 代码以支持可复现性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 3 figures, IEEE Wireless Communications and Networking\n  Conference (WCNC2025), Milan, Italy, 24-27 March 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.03403v1",
      "published_date": "2025-02-05 17:43:55 UTC",
      "updated_date": "2025-02-05 17:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:25:05.834985"
    },
    {
      "arxiv_id": "2502.03397v1",
      "title": "SPRI: Aligning Large Language Models with Context-Situated Principles",
      "title_zh": "SPRI：通过情境化原则对大型语言模型进行对齐",
      "authors": [
        "Hongli Zhan",
        "Muneeza Azmat",
        "Raya Horesh",
        "Junyi Jessy Li",
        "Mikhail Yurochkin"
      ],
      "abstract": "Aligning Large Language Models to integrate and reflect human values,\nespecially for tasks that demand intricate human oversight, is arduous since it\nis resource-intensive and time-consuming to depend on human expertise for\ncontext-specific guidance. Prior work has utilized predefined sets of rules or\nprinciples to steer the behavior of models (Bai et al., 2022; Sun et al.,\n2023). However, these principles tend to be generic, making it challenging to\nadapt them to each individual input query or context. In this work, we present\nSituated-PRInciples (SPRI), a framework requiring minimal or no human effort\nthat is designed to automatically generate guiding principles in real-time for\neach input query and utilize them to align each response. We evaluate SPRI on\nthree tasks, and show that 1) SPRI can derive principles in a complex\ndomain-specific task that leads to on-par performance as expert-crafted ones;\n2) SPRI-generated principles lead to instance-specific rubrics that outperform\nprior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT data\nleads to substantial improvement on truthfulness. We release our code and model\ngenerations at https://github.com/honglizhan/SPRI-public.",
      "tldr_zh": "这篇论文提出了 SPRI（Situated-PRInciples）框架，用于对齐 Large Language Models，使其能自动生成实时、上下文相关的指导原则，从而减少对人类专家的依赖。SPRI 通过为每个输入查询创建特定原则来引导模型响应，并在三个任务上评估显示：其生成的原则在复杂领域任务中与专家手工原则性能相当，并优于现有 LLM-as-a-judge 框架；此外，使用 SPRI 生成的合成 SFT 数据显著提升了模型的真实性。作者开源了代码和模型生成，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03397v1",
      "published_date": "2025-02-05 17:32:29 UTC",
      "updated_date": "2025-02-05 17:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:25:17.618005"
    },
    {
      "arxiv_id": "2502.03396v1",
      "title": "Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Al-Shareeda",
        "Yasar Celik",
        "Bilge Bilgili",
        "Ahmed Al-Dubai",
        "Berk Canberk"
      ],
      "abstract": "Creating a Digital Twin (DT) for Healthcare Intelligent Transportation\nSystems (HITS) is a hot research trend focusing on enhancing HITS management,\nparticularly in emergencies where ambulance vehicles must arrive at the crash\nscene on time and track their real-time location is crucial to the medical\nauthorities. Despite the claim of real-time representation, a temporal\nmisalignment persists between the physical and virtual domains, leading to\ndiscrepancies in the ambulance's location representation. This study proposes\nintegrating AI predictive models, specifically Support Vector Regression (SVR)\nand Deep Neural Networks (DNN), within a constructed mock DT data pipeline\nframework to anticipate the medical vehicle's next location in the virtual\nworld. These models align virtual representations with their physical\ncounterparts, i.e., metaphorically offsetting the synchronization delay between\nthe two worlds. Trained meticulously on a historical geospatial dataset, SVR\nand DNN exhibit exceptional prediction accuracy in MATLAB and Python\nenvironments. Through various testing scenarios, we visually demonstrate the\nefficacy of our methodology, showcasing SVR and DNN's key role in significantly\nreducing the witnessed gap within the HITS's DT. This transformative approach\nenhances real-time synchronization in emergency HITS by approximately 88% to\n93%.",
      "tldr_zh": "该研究针对医疗智能交通系统(HITS)的数字孪生(DT)中，紧急车辆位置跟踪的时序不对齐问题，提出了一种基于AI的预测方法。方法整合Support Vector Regression (SVR)和Deep Neural Networks (DNN)模型，在模拟DT数据管道中利用历史地理空间数据集进行训练，以预测救护车的实时位置，从而减少物理和虚拟世界的同步延迟。实验结果显示，该方法在MATLAB和Python环境中显著提升了实时同步率，约提高88%到93%，为HITS紧急响应提供了更准确的定位支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 8 figures, 5th IEEE Middle East & North Africa\n  COMMunications Conference (MENACOMM'25), Lebanon Feb 20-23, 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.03396v1",
      "published_date": "2025-02-05 17:32:07 UTC",
      "updated_date": "2025-02-05 17:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:25:28.353124"
    },
    {
      "arxiv_id": "2502.03395v1",
      "title": "Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Issar Arab",
        "Rodrigo Benitez"
      ],
      "abstract": "Time series forecasting is essential for operational intelligence in the\nhospitality industry, and particularly challenging in large-scale, distributed\nsystems. This study evaluates the performance of statistical, machine learning\n(ML), deep learning, and foundation models in forecasting hourly sales over a\n14-day horizon using real-world data from a network of thousands of restaurants\nacross Germany. The forecasting solution includes features such as weather\nconditions, calendar events, and time-of-day patterns. Results demonstrate the\nstrong performance of ML-based meta-models and highlight the emerging potential\nof foundation models like Chronos and TimesFM, which deliver competitive\nperformance with minimal feature engineering, leveraging only the pre-trained\nmodel (zero-shot inference). Additionally, a hybrid PySpark-Pandas approach\nproves to be a robust solution for achieving horizontal scalability in\nlarge-scale deployments.",
      "tldr_zh": "这篇论文评估了统计方法、机器学习(ML)、深度学习和基础模型在酒店业时间序列预测中的性能，使用德国数千家餐厅的真实数据，预测14天内的小时销售额，并纳入天气条件、日历事件和时间模式等特征。结果显示，ML-based meta-models 表现出色，而基础模型如 Chronos 和 TimesFM 在零-shot inference 下即可实现竞争性性能，且无需大量特征工程。论文还提出混合 PySpark-Pandas 方法作为实现大规模部署中水平可伸缩性的可靠解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03395v1",
      "published_date": "2025-02-05 17:30:31 UTC",
      "updated_date": "2025-02-05 17:30:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:25:41.227762"
    },
    {
      "arxiv_id": "2502.05221v1",
      "title": "Blackout DIFUSCO",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Pyo Seo"
      ],
      "abstract": "This study explores the integration of Blackout Diffusion into the DIFUSCO\nframework for combinatorial optimization, specifically targeting the Traveling\nSalesman Problem (TSP). Inspired by the success of discrete-time diffusion\nmodels (D3PM) in maintaining structural integrity, we extend the paradigm to a\ncontinuous-time framework, leveraging the unique properties of Blackout\nDiffusion. Continuous-time modeling introduces smoother transitions and refined\ncontrol, hypothesizing enhanced solution quality over traditional discrete\nmethods. We propose three key improvements to enhance the diffusion process.\nFirst, we transition from a discrete-time-based model to a continuous-time\nframework, providing a more refined and flexible formulation. Second, we refine\nthe observation time scheduling to ensure a smooth and linear transformation\nthroughout the diffusion process, allowing for a more natural progression of\nstates. Finally, building upon the second improvement, we further enhance the\nreverse process by introducing finer time slices in regions that are\nparticularly challenging for the model, thereby improving accuracy and\nstability in the reconstruction phase. Although the experimental results did\nnot exceed the baseline performance, they demonstrate the effectiveness of\nthese methods in balancing simplicity and complexity, offering new insights\ninto diffusion-based combinatorial optimization. This work represents the first\napplication of Blackout Diffusion to combinatorial optimization, providing a\nfoundation for further advancements in this domain. * The code is available for\nreview at https://github.com/Giventicket/BlackoutDIFUSCO.",
      "tldr_zh": "本研究探索将 Blackout Diffusion 整合到 DIFUSCO 框架中，用于解决 Traveling Salesman Problem (TSP) 等组合优化问题，受 D3PM 启发，将其扩展到连续时间框架，以实现更平滑的过渡和精细控制。论文提出三个关键改进：从离散时间模型转向连续时间框架、优化观察时间调度以确保线性过程，以及在逆过程引入更精细的时间切片以提升准确性和稳定性。尽管实验结果未超过基线，但这些方法展示了在简单性和复杂性之间有效平衡的新见解，并首次将 Blackout Diffusion 应用于组合优化领域。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.05221v1",
      "published_date": "2025-02-05 17:24:33 UTC",
      "updated_date": "2025-02-05 17:24:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:27:45.591662"
    },
    {
      "arxiv_id": "2502.03387v1",
      "title": "LIMO: Less is More for Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yixin Ye",
        "Zhen Huang",
        "Yang Xiao",
        "Ethan Chern",
        "Shijie Xia",
        "Pengfei Liu"
      ],
      "abstract": "We present a fundamental discovery that challenges our understanding of how\ncomplex reasoning emerges in large language models. While conventional wisdom\nsuggests that sophisticated reasoning tasks demand extensive training data\n(>100,000 examples), we demonstrate that complex mathematical reasoning\nabilities can be effectively elicited with surprisingly few examples. Through\ncomprehensive experiments, our proposed model LIMO demonstrates unprecedented\nperformance in mathematical reasoning. With merely 817 curated training\nsamples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from\nprevious SFT-based models' 6.5% and 59.2% respectively, while only using 1% of\nthe training data required by previous approaches. LIMO demonstrates\nexceptional out-of-distribution generalization, achieving 40.5% absolute\nimprovement across 10 diverse benchmarks, outperforming models trained on 100x\nmore data, challenging the notion that SFT leads to memorization rather than\ngeneralization. Based on these results, we propose the Less-Is-More Reasoning\nHypothesis (LIMO Hypothesis): In foundation models where domain knowledge has\nbeen comprehensively encoded during pre-training, sophisticated reasoning\ncapabilities can emerge through minimal but precisely orchestrated\ndemonstrations of cognitive processes. This hypothesis posits that the\nelicitation threshold for complex reasoning is determined by two key factors:\n(1) the completeness of the model's encoded knowledge foundation during\npre-training, and (2) the effectiveness of post-training examples as \"cognitive\ntemplates\" that show the model how to utilize its knowledge base to solve\ncomplex reasoning tasks. To facilitate reproducibility and future research in\ndata-efficient reasoning, we release LIMO as a comprehensive open-source suite\nat https://github.com/GAIR-NLP/LIMO.",
      "tldr_zh": "本论文提出 LIMO 模型，挑战传统观点，即复杂推理任务需要大量训练数据（超过 10 万样本），证明通过仅 817 个精选样本即可显著提升数学推理能力。LIMO 在 AIME 上达到 57.1% 准确率、在 MATH 上达到 94.8%，比之前的 SFT 模型分别提升 50.6% 和 35.6%，并在 10 个基准上实现 40.5% 的绝对改进，优于使用 100 倍数据训练的模型。基于这些结果，论文提出 Less-Is-More Reasoning Hypothesis（LIMO Hypothesis），认为复杂推理的激发取决于预训练知识基础的完整性和后训练样本作为“cognitive templates”的有效性。为促进研究，该模型及其开源套件已发布在 https://github.com/GAIR-NLP/LIMO。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.03387v1",
      "published_date": "2025-02-05 17:23:45 UTC",
      "updated_date": "2025-02-05 17:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:26:04.430138"
    },
    {
      "arxiv_id": "2502.04380v1",
      "title": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenqing Ling",
        "Daoyuan Chen",
        "Liuyi Yao",
        "Yaliang Li",
        "Ying Shen"
      ],
      "abstract": "Fine-tuning large language models (LLMs) using diverse datasets is crucial\nfor enhancing their overall performance across various domains. In practical\nscenarios, existing methods based on modeling the mixture proportions of data\ncomposition often struggle with data whose domain labels are missing, imprecise\nor non-normalized, while methods based on data selection usually encounter\ndifficulties in balancing multi-domain performance. To address these\nchallenges, in this paper, we study the role of data diversity in enhancing the\noverall abilities of LLMs by empirically constructing contrastive data pools\nand theoretically deriving explanations for both inter- and intra-diversity.\nBuilding upon the insights gained, we propose a new method that gives the LLM a\ndual identity: an output model to cognitively probe and select data based on\ndiversity reward, as well as an input model to be tuned with the selected data.\nExtensive experiments show that the proposed method notably boosts performance\nacross domain-undetermined data and a series of foundational downstream tasks\nwhen applied to various advanced LLMs. We release our code and hope this study\ncan shed light on the understanding of data diversity and advance\nfeedback-driven data-model co-development for LLMs.",
      "tldr_zh": "本文提出了一种新方法，将数据多样性作为奖励机制，用于细调大型语言模型（LLMs），以应对域不确定数据（缺少标签或不准确）带来的挑战。该方法通过构建对比数据池并理论分析多样性（inter- and intra-diversity），让LLM兼具双重身份：作为输出模型基于多样性奖励选择数据，以及作为输入模型使用选中的数据进行训练。实验结果显示，该方法显著提升了LLMs在域不确定数据和多种下游任务上的性能，并开源代码以促进数据-模型共同发展的反馈驱动研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 15 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.04380v1",
      "published_date": "2025-02-05 17:21:01 UTC",
      "updated_date": "2025-02-05 17:21:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:26:16.276988"
    },
    {
      "arxiv_id": "2502.03383v1",
      "title": "Transformers and Their Roles as Time Series Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dennis Wu",
        "Yihan He",
        "Yuan Cao",
        "Jianqing Fan",
        "Han Liu"
      ],
      "abstract": "We give a comprehensive analysis of transformers as time series foundation\nmodels, focusing on their approximation and generalization capabilities. First,\nwe demonstrate that there exist transformers that fit an autoregressive model\non input univariate time series via gradient descent. We then analyze MOIRAI, a\nmultivariate time series foundation model capable of handling an arbitrary\nnumber of covariates. We prove that it is capable of automatically fitting\nautoregressive models with an arbitrary number of covariates, offering insights\ninto its design and empirical success. For generalization, we establish bounds\nfor pretraining when the data satisfies Dobrushin's condition. Experiments\nsupport our theoretical findings, highlighting the efficacy of transformers as\ntime series foundation models.",
      "tldr_zh": "本研究对 Transformers 作为时间序列基础模型的近似和泛化能力进行了全面分析。首先，证明存在 Transformers 通过 gradient descent 拟合输入单变量时间序列的自回归模型（autoregressive models）。其次，分析了 MOIRAI，这是一个多变量时间序列基础模型，能够自动适应任意数量协变量的自回归模型，并提供其设计和经验成功的关键见解。对于泛化能力，论文建立了数据满足 Dobrushin's condition 时预训练的边界，并通过实验验证了这些理论发现，突显了 Transformers 在时间序列任务中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "34 Pages, 2 Figures",
      "pdf_url": "http://arxiv.org/pdf/2502.03383v1",
      "published_date": "2025-02-05 17:18:55 UTC",
      "updated_date": "2025-02-05 17:18:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:26:27.842818"
    },
    {
      "arxiv_id": "2502.04379v1",
      "title": "Can Large Language Models Capture Video Game Engagement?",
      "title_zh": "翻译失败",
      "authors": [
        "David Melhart",
        "Matthew Barthet",
        "Georgios N. Yannakakis"
      ],
      "abstract": "Can out-of-the-box pretrained Large Language Models (LLMs) detect human\naffect successfully when observing a video? To address this question, for the\nfirst time, we evaluate comprehensively the capacity of popular LLMs to\nannotate and successfully predict continuous affect annotations of videos when\nprompted by a sequence of text and video frames in a multimodal fashion.\nParticularly in this paper, we test LLMs' ability to correctly label changes of\nin-game engagement in 80 minutes of annotated videogame footage from 20\nfirst-person shooter games of the GameVibe corpus. We run over 2,400\nexperiments to investigate the impact of LLM architecture, model size, input\nmodality, prompting strategy, and ground truth processing method on engagement\nprediction. Our findings suggest that while LLMs rightfully claim human-like\nperformance across multiple domains, they generally fall behind capturing\ncontinuous experience annotations provided by humans. We examine some of the\nunderlying causes for the relatively poor overall performance, highlight the\ncases where LLMs exceed expectations, and draw a roadmap for the further\nexploration of automated emotion labelling via LLMs.",
      "tldr_zh": "这篇论文评估了预训练的 Large Language Models (LLMs) 是否能成功检测人类在观看视频时的情感变化，特别是视频游戏参与度。研究者使用 GameVibe 语料库中的 80 分钟第一人称射击游戏视频，通过超过 2400 次实验测试了 LLM 架构、模型大小、输入模态（如多模态文本和视频帧）、提示策略以及地面实况处理方法的影响。结果表明，LLMs 在捕捉连续人类情感注解方面整体表现不如人类，但某些情况下超出预期，并为通过 LLMs 实现自动情感标记提供了未来路线图。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2502.04379v1",
      "published_date": "2025-02-05 17:14:47 UTC",
      "updated_date": "2025-02-05 17:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:26:40.989040"
    },
    {
      "arxiv_id": "2502.03369v1",
      "title": "Learning from Active Human Involvement through Proxy Value Propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenghao Peng",
        "Wenjie Mo",
        "Chenda Duan",
        "Quanyi Li",
        "Bolei Zhou"
      ],
      "abstract": "Learning from active human involvement enables the human subject to actively\nintervene and demonstrate to the AI agent during training. The interaction and\ncorrective feedback from human brings safety and AI alignment to the learning\nprocess. In this work, we propose a new reward-free active human involvement\nmethod called Proxy Value Propagation for policy optimization. Our key insight\nis that a proxy value function can be designed to express human intents,\nwherein state-action pairs in the human demonstration are labeled with high\nvalues, while those agents' actions that are intervened receive low values.\nThrough the TD-learning framework, labeled values of demonstrated state-action\npairs are further propagated to other unlabeled data generated from agents'\nexploration. The proxy value function thus induces a policy that faithfully\nemulates human behaviors. Human-in-the-loop experiments show the generality and\nefficiency of our method. With minimal modification to existing reinforcement\nlearning algorithms, our method can learn to solve continuous and discrete\ncontrol tasks with various human control devices, including the challenging\ntask of driving in Grand Theft Auto V. Demo video and code are available at:\nhttps://metadriverse.github.io/pvp",
      "tldr_zh": "本文提出了一种名为 Proxy Value Propagation 的无奖励方法，用于从主动人类参与中优化 AI 代理策略。该方法通过设计代理值函数，将人类示范的状态-动作对标记为高值，而被干预的代理动作标记为低值，并利用 TD-learning 框架将这些值传播到其他未标记数据，从而诱导策略忠实模仿人类行为。实验显示，该方法通用且高效，仅需最小修改现有强化学习算法，即可应用于连续和离散控制任务，包括 GTA V 的驾驶挑战，并提升了学习过程的安全性和 AI 一致性。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2023 Spotlight. Project page:\n  https://metadriverse.github.io/pvp",
      "pdf_url": "http://arxiv.org/pdf/2502.03369v1",
      "published_date": "2025-02-05 17:07:37 UTC",
      "updated_date": "2025-02-05 17:07:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:26:51.964505"
    },
    {
      "arxiv_id": "2502.03368v1",
      "title": "PalimpChat: Declarative and Interactive AI analytics",
      "title_zh": "PalimpChat：声明式和交互式 AI 分析",
      "authors": [
        "Chunwei Liu",
        "Gerardo Vitagliano",
        "Brandon Rose",
        "Matt Prinz",
        "David Andrew Samson",
        "Michael Cafarella"
      ],
      "abstract": "Thanks to the advances in generative architectures and large language models,\ndata scientists can now code pipelines of machine-learning operations to\nprocess large collections of unstructured data. Recent progress has seen the\nrise of declarative AI frameworks (e.g., Palimpzest, Lotus, and DocETL) to\nbuild optimized and increasingly complex pipelines, but these systems often\nremain accessible only to expert programmers. In this demonstration, we present\nPalimpChat, a chat-based interface to Palimpzest that bridges this gap by\nletting users create and run sophisticated AI pipelines through natural\nlanguage alone. By integrating Archytas, a ReAct-based reasoning agent, and\nPalimpzest's suite of relational and LLM-based operators, PalimpChat provides a\npractical illustration of how a chat interface can make declarative AI\nframeworks truly accessible to non-experts.\n  Our demo system is publicly available online. At SIGMOD'25, participants can\nexplore three real-world scenarios--scientific discovery, legal discovery, and\nreal estate search--or apply PalimpChat to their own datasets. In this paper,\nwe focus on how PalimpChat, supported by the Palimpzest optimizer, simplifies\ncomplex AI workflows such as extracting and analyzing biomedical data.",
      "tldr_zh": "该论文介绍了 PalimpChat，一个基于聊天界面的系统，旨在让非专家用户通过自然语言轻松创建和运行复杂的 AI 管道，从而提升声明式 AI 框架（如 Palimpzest）的可访问性。PalimpChat 整合了 Archytas（一个基于 ReAct 的推理代理）和 Palimpzest 的关系及 LLM 操作符，简化了处理非结构化数据的机器学习工作流。实验演示显示，该系统在真实场景中（如科学发现、法律发现和房地产搜索）有效优化 AI 分析，并特别突出其在提取和分析生物医学数据方面的实用性。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03368v1",
      "published_date": "2025-02-05 17:06:59 UTC",
      "updated_date": "2025-02-05 17:06:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:27:58.087770"
    },
    {
      "arxiv_id": "2502.03360v1",
      "title": "A Beam's Eye View to Fluence Maps 3D Network for Ultra Fast VMAT Radiotherapy Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Arberet",
        "Florin C. Ghesu",
        "Riqiang Gao",
        "Martin Kraus",
        "Jonathan Sackett",
        "Esa Kuusela",
        "Ali Kamen"
      ],
      "abstract": "Volumetric Modulated Arc Therapy (VMAT) revolutionizes cancer treatment by\nprecisely delivering radiation while sparing healthy tissues. Fluence maps\ngeneration, crucial in VMAT planning, traditionally involves complex and\niterative, and thus time consuming processes. These fluence maps are\nsubsequently leveraged for leaf-sequence. The deep-learning approach presented\nin this article aims to expedite this by directly predicting fluence maps from\npatient data. We developed a 3D network which we trained in a supervised way\nusing a combination of L1 and L2 losses, and RT plans generated by Eclipse and\nfrom the REQUITE dataset, taking the RT dose map as input and the fluence maps\ncomputed from the corresponding RT plans as target. Our network predicts\njointly the 180 fluence maps corresponding to the 180 control points (CP) of\nsingle arc VMAT plans. In order to help the network, we pre-process the input\ndose by computing the projections of the 3D dose map to the beam's eye view\n(BEV) of the 180 CPs, in the same coordinate system as the fluence maps. We\ngenerated over 2000 VMAT plans using Eclipse to scale up the dataset size.\nAdditionally, we evaluated various network architectures and analyzed the\nimpact of increasing the dataset size. We are measuring the performance in the\n2D fluence maps domain using image metrics (PSNR, SSIM), as well as in the 3D\ndose domain using the dose-volume histogram (DVH) on a validation dataset. The\nnetwork inference, which does not include the data loading and processing, is\nless than 20ms. Using our proposed 3D network architecture as well as\nincreasing the dataset size using Eclipse improved the fluence map\nreconstruction performance by approximately 8 dB in PSNR compared to a U-Net\narchitecture trained on the original REQUITE dataset. The resulting DVHs are\nvery close to the one of the input target dose.",
      "tldr_zh": "该研究提出了一种基于束的视角（BEV）的3D网络，用于加速Volumetric Modulated Arc Therapy（VMAT）放射治疗规划，通过直接从患者数据预测fluence maps，显著减少传统复杂迭代过程。网络采用监督学习，结合L1和L2损失训练，使用Eclipse生成的超过2000个VMAT计划扩展数据集，并通过预处理输入剂量图的BEV投影来提升预测准确性。实验结果显示，该网络的推理时间不到20ms，与U-Net基准相比，fluence maps重建的PSNR提高了约8dB，且生成的剂量体积直方图（DVH）与目标剂量高度一致。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03360v1",
      "published_date": "2025-02-05 16:56:17 UTC",
      "updated_date": "2025-02-05 16:56:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:28:09.186800"
    },
    {
      "arxiv_id": "2502.03359v2",
      "title": "GHOST: Gaussian Hypothesis Open-Set Technique",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Rabinowitz",
        "Steve Cruz",
        "Manuel Günther",
        "Terrance E. Boult"
      ],
      "abstract": "Evaluations of large-scale recognition methods typically focus on overall\nperformance. While this approach is common, it often fails to provide insights\ninto performance across individual classes, which can lead to fairness issues\nand misrepresentation. Addressing these gaps is crucial for accurately\nassessing how well methods handle novel or unseen classes and ensuring a fair\nevaluation. To address fairness in Open-Set Recognition (OSR), we demonstrate\nthat per-class performance can vary dramatically. We introduce Gaussian\nHypothesis Open Set Technique (GHOST), a novel hyperparameter-free algorithm\nthat models deep features using class-wise multivariate Gaussian distributions\nwith diagonal covariance matrices. We apply Z-score normalization to logits to\nmitigate the impact of feature magnitudes that deviate from the model's\nexpectations, thereby reducing the likelihood of the network assigning a high\nscore to an unknown sample. We evaluate GHOST across multiple ImageNet-1K\npre-trained deep networks and test it with four different unknown datasets.\nUsing standard metrics such as AUOSCR, AUROC and FPR95, we achieve\nstatistically significant improvements, advancing the state-of-the-art in\nlarge-scale OSR. Source code is provided online.",
      "tldr_zh": "该论文揭示了传统大规模识别方法在Open-Set Recognition (OSR)中忽略了每个类别的性能差异，导致公平性和评估偏差问题。作者提出GHOST，一种无超参数的算法，通过使用类-wise多元高斯分布（multivariate Gaussian distributions with diagonal covariance matrices）来建模深层特征，并应用Z-score normalization到logits，以减少特征幅度偏差并降低对未知样本的高分赋值风险。在ImageNet-1K预训练网络上，使用AUOSCR、AUROC和FPR95等指标进行评估，GHOST在四个未知数据集上实现了统计显著的性能提升，推进了OSR领域的状态。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AAAI Conference on Artificial Intelligence 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.03359v2",
      "published_date": "2025-02-05 16:56:14 UTC",
      "updated_date": "2025-02-10 17:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:28:20.666529"
    },
    {
      "arxiv_id": "2502.06831v1",
      "title": "No Location Left Behind: Measuring and Improving the Fairness of Implicit Representations for Earth Data",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Cai",
        "Randall Balestriero"
      ],
      "abstract": "Implicit neural representations (INRs) exhibit growing promise in addressing\nEarth representation challenges, ranging from emissions monitoring to climate\nmodeling. However, existing methods disproportionately prioritize global\naverage performance, whereas practitioners require fine-grained insights to\nunderstand biases and variations in these models. To bridge this gap, we\nintroduce FAIR-Earth: a first-of-its-kind dataset explicitly crafted to examine\nand challenge inequities in Earth representations. FAIR-Earth comprises various\nhigh-resolution Earth signals and uniquely aggregates extensive metadata along\nstratifications like landmass size and population density to assess the\nfairness of models. Evaluating state-of-the-art INRs across the various\nmodalities of FAIR-Earth, we uncover striking performance disparities. Certain\nsubgroups, especially those associated with high-frequency signals (e.g.,\nislands, coastlines), are consistently poorly modeled by existing methods. In\nresponse, we propose spherical wavelet encodings, building on previous spatial\nencoding research. Leveraging the multi-resolution capabilities of wavelets,\nour encodings yield consistent performance over various scales and locations,\noffering more accurate and robust representations of the biased subgroups.\nThese open-source contributions represent a crucial step towards the equitable\nassessment and deployment of Earth INRs.",
      "tldr_zh": "本研究探讨了隐式神经表示(INRs)在地球数据表示中的公平性问题，发现现有方法偏重全局平均性能，而忽略了特定子群（如岛屿和海岸线的高频信号）的表现差异。作者引入了FAIR-Earth数据集，该数据集包含高分辨率地球信号和元数据（如陆地大小和人口密度），用于评估模型的不公。针对这些问题，他们提出spherical wavelet encodings方法，利用小波的多分辨率能力，提供更一致、准确的表示，从而显著改善偏差子群的建模性能，并推动地球INRs的公平评估和开源部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06831v1",
      "published_date": "2025-02-05 16:51:13 UTC",
      "updated_date": "2025-02-05 16:51:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:28:40.543339"
    },
    {
      "arxiv_id": "2503.04741v1",
      "title": "Which Information should the UK and US AISI share with an International Network of AISIs? Opportunities, Risks, and a Tentative Proposal",
      "title_zh": "翻译失败",
      "authors": [
        "Lara Thurnherr"
      ],
      "abstract": "The UK AI Safety Institute (UK AISI) and its parallel organisation in the\nUnited States (US AISI) take up a unique position in the recently established\nInternational Network of AISIs. Both are in jurisdictions with frontier AI\ncompanies and are assuming leading roles in the international conversation on\nAI Safety. This paper argues that it is in the interest of both institutions to\nshare specific categories of information with the International Network of\nAISIs, deliberately abstain from sharing others and carefully evaluate sharing\nsome categories on a case by case basis, according to domestic priorities. The\npaper further proposes a provisional framework with which policymakers and\nresearchers can distinguish between these three cases, taking into account the\npotential benefits and risks of sharing specific categories of information,\nranging from pre-deployment evaluation results to evaluation standards. In an\neffort to further improve the research on AI policy relevant information\nsharing decisions, the paper emphasises the importance of continuously\nmonitoring fluctuating factors influencing sharing decisions and a more\nin-depth analysis of specific policy relevant information categories and\nadditional factors to consider in future research.",
      "tldr_zh": "这篇论文探讨了英国 AI 安全研究所 (UK AISI) 和美国 AI 安全研究所 (US AISI) 在 International Network of AISIs 中的独特角色，分析了分享信息的机会和风险。论文主张 UK AISI 和 US AISI 应分享特定信息类别（如预部署评估结果），避免分享其他类别，并根据国内优先级逐案评估某些信息。作者提出一个临时框架来区分这些情况，考虑潜在好处、风险和动态因素，并强调持续监控和未来对政策相关信息类别进行更深入研究的必要性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "12 Pages, 3 Tables, 2 Figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04741v1",
      "published_date": "2025-02-05 16:49:02 UTC",
      "updated_date": "2025-02-05 16:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:28:44.701234"
    },
    {
      "arxiv_id": "2502.03349v1",
      "title": "Robust Autonomy Emerges from Self-Play",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Cusumano-Towner",
        "David Hafner",
        "Alex Hertzberg",
        "Brody Huval",
        "Aleksei Petrenko",
        "Eugene Vinitsky",
        "Erik Wijmans",
        "Taylor Killian",
        "Stuart Bowers",
        "Ozan Sener",
        "Philipp Krähenbühl",
        "Vladlen Koltun"
      ],
      "abstract": "Self-play has powered breakthroughs in two-player and multi-player games.\nHere we show that self-play is a surprisingly effective strategy in another\ndomain. We show that robust and naturalistic driving emerges entirely from\nself-play in simulation at unprecedented scale -- 1.6~billion~km of driving.\nThis is enabled by Gigaflow, a batched simulator that can synthesize and train\non 42 years of subjective driving experience per hour on a single 8-GPU node.\nThe resulting policy achieves state-of-the-art performance on three independent\nautonomous driving benchmarks. The policy outperforms the prior state of the\nart when tested on recorded real-world scenarios, amidst human drivers, without\never seeing human data during training. The policy is realistic when assessed\nagainst human references and achieves unprecedented robustness, averaging 17.5\nyears of continuous driving between incidents in simulation.",
      "tldr_zh": "这篇论文展示了 self-play 策略在自动驾驶领域的应用，通过在模拟环境中进行 1.6 亿公里的自玩训练，成功产生了鲁棒且自然的驾驶策略。研究利用 Gigaflow 模拟器，每小时在单个 8-GPU 节点上合成和训练 42 年的主观驾驶经验，从而实现大规模高效训练。该策略在三个独立的 autonomous driving benchmarks 上达到了最先进性能，并在真实场景测试中超越了现有技术，且无需使用人类数据。最终，该策略展现出前所未有的鲁棒性，在模拟中平均可连续驾驶 17.5 年无事故，为自主驾驶的可靠发展提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03349v1",
      "published_date": "2025-02-05 16:41:05 UTC",
      "updated_date": "2025-02-05 16:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:28:57.591781"
    },
    {
      "arxiv_id": "2502.03341v1",
      "title": "Adaptive Variational Inference in Probabilistic Graphical Models: Beyond Bethe, Tree-Reweighted, and Convex Free Energies",
      "title_zh": "翻译失败",
      "authors": [
        "Harald Leisenberger",
        "Franz Pernkopf"
      ],
      "abstract": "Variational inference in probabilistic graphical models aims to approximate\nfundamental quantities such as marginal distributions and the partition\nfunction. Popular approaches are the Bethe approximation, tree-reweighted, and\nother types of convex free energies. These approximations are efficient but can\nfail if the model is complex and highly interactive. In this work, we analyze\ntwo classes of approximations that include the above methods as special cases:\nfirst, if the model parameters are changed; and second, if the entropy\napproximation is changed. We discuss benefits and drawbacks of either approach,\nand deduce from this analysis how a free energy approximation should ideally be\nconstructed. Based on our observations, we propose approximations that\nautomatically adapt to a given model and demonstrate their effectiveness for a\nrange of difficult problems.",
      "tldr_zh": "该论文探讨了变分推理（Variational inference）在概率图形模型（probabilistic graphical models）中用于近似边际分布和分区函数的核心问题，指出传统方法如 Bethe approximation、tree-reweighted 和 convex free energies 虽然高效，但容易在复杂交互模型中失效。作者分析了两种近似策略——改变模型参数或熵近似——并讨论了它们的优缺点，进而提出一种自动适应模型的自适应自由能近似方法。实验结果表明，该方法在多种困难问题上表现出色，提升了变分推理的适用性和有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "This work has been submitted to the Conference on Uncertainty in\n  Artificial Intelligence (UAI) 2025 for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2502.03341v1",
      "published_date": "2025-02-05 16:33:59 UTC",
      "updated_date": "2025-02-05 16:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:29:08.762582"
    },
    {
      "arxiv_id": "2502.03333v1",
      "title": "RadVLM: A Multitask Conversational Vision-Language Model for Radiology",
      "title_zh": "RadVLM：用于放射学的多任务对话视觉语言模型",
      "authors": [
        "Nicolas Deperrois",
        "Hidetoshi Matsuo",
        "Samuel Ruipérez-Campillo",
        "Moritz Vandenhirtz",
        "Sonia Laguna",
        "Alain Ryser",
        "Koji Fujimoto",
        "Mizuho Nishio",
        "Thomas M. Sutter",
        "Julia E. Vogt",
        "Jonas Kluckert",
        "Thomas Frauenfelder",
        "Christian Blüthgen",
        "Farhad Nooralahzadeh",
        "Michael Krauthammer"
      ],
      "abstract": "The widespread use of chest X-rays (CXRs), coupled with a shortage of\nradiologists, has driven growing interest in automated CXR analysis and\nAI-assisted reporting. While existing vision-language models (VLMs) show\npromise in specific tasks such as report generation or abnormality detection,\nthey often lack support for interactive diagnostic capabilities. In this work\nwe present RadVLM, a compact, multitask conversational foundation model\ndesigned for CXR interpretation. To this end, we curate a large-scale\ninstruction dataset comprising over 1 million image-instruction pairs\ncontaining both single-turn tasks -- such as report generation, abnormality\nclassification, and visual grounding -- and multi-turn, multi-task\nconversational interactions. After fine-tuning RadVLM on this instruction\ndataset, we evaluate it across different tasks along with re-implemented\nbaseline VLMs. Our results show that RadVLM achieves state-of-the-art\nperformance in conversational capabilities and visual grounding while remaining\ncompetitive in other radiology tasks. Ablation studies further highlight the\nbenefit of joint training across multiple tasks, particularly for scenarios\nwith limited annotated data. Together, these findings highlight the potential\nof RadVLM as a clinically relevant AI assistant, providing structured CXR\ninterpretation and conversational capabilities to support more effective and\naccessible diagnostic workflows.",
      "tldr_zh": "本文提出RadVLM，一种紧凑的多任务对话视觉语言模型(VLMs)，旨在提升胸部X光(CXRs)解释的交互式诊断能力，以应对放射科医生短缺和现有模型局限的问题。研究团队构建了一个超过100万图像-指令对的大规模数据集，包括单轮任务（如报告生成、异常分类和视觉 grounding）和多轮多任务对话，并通过微调RadVLM实现模型优化。实验结果显示，RadVLM在对话能力和视觉 grounding上达到最先进水平，并在其他放射学任务中保持竞争力，消融研究强调多任务联合训练对数据有限场景的益处。该模型有望作为临床AI助手，提供结构化的CXRs解释和对话支持，提升诊断流程的效率和可访问性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.03333v1",
      "published_date": "2025-02-05 16:27:02 UTC",
      "updated_date": "2025-02-05 16:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:29:21.564718"
    },
    {
      "arxiv_id": "2502.04377v1",
      "title": "MapFusion: A Novel BEV Feature Fusion Network for Multi-modal Map Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoshuai Hao",
        "Yunfeng Diao",
        "Mengchuan Wei",
        "Yifan Yang",
        "Peng Hao",
        "Rong Yin",
        "Hui Zhang",
        "Weiming Li",
        "Shu Zhao",
        "Yu Liu"
      ],
      "abstract": "Map construction task plays a vital role in providing precise and\ncomprehensive static environmental information essential for autonomous driving\nsystems. Primary sensors include cameras and LiDAR, with configurations varying\nbetween camera-only, LiDAR-only, or camera-LiDAR fusion, based on\ncost-performance considerations. While fusion-based methods typically perform\nbest, existing approaches often neglect modality interaction and rely on simple\nfusion strategies, which suffer from the problems of misalignment and\ninformation loss. To address these issues, we propose MapFusion, a novel\nmulti-modal Bird's-Eye View (BEV) feature fusion method for map construction.\nSpecifically, to solve the semantic misalignment problem between camera and\nLiDAR BEV features, we introduce the Cross-modal Interaction Transform (CIT)\nmodule, enabling interaction between two BEV feature spaces and enhancing\nfeature representation through a self-attention mechanism. Additionally, we\npropose an effective Dual Dynamic Fusion (DDF) module to adaptively select\nvaluable information from different modalities, which can take full advantage\nof the inherent information between different modalities. Moreover, MapFusion\nis designed to be simple and plug-and-play, easily integrated into existing\npipelines. We evaluate MapFusion on two map construction tasks, including\nHigh-definition (HD) map and BEV map segmentation, to show its versatility and\neffectiveness. Compared with the state-of-the-art methods, MapFusion achieves\n3.6% and 6.2% absolute improvements on the HD map construction and BEV map\nsegmentation tasks on the nuScenes dataset, respectively, demonstrating the\nsuperiority of our approach.",
      "tldr_zh": "本文提出 MapFusion，一种新型的多模态 Bird's-Eye View (BEV) 特征融合网络，用于自动驾驶系统的地图构建任务，以解决现有方法的模态交互不足、特征不对齐和信息丢失问题。具体地，该网络引入 Cross-modal Interaction Transform (CIT) 模块通过自注意力机制增强不同模态特征的交互，以及 Dual Dynamic Fusion (DDF) 模块来自适应选择有价值信息，使其简单易集成。在 nuScenes 数据集上，MapFusion 在 HD 地图构建和 BEV 地图分割任务上分别实现了 3.6% 和 6.2% 的绝对性能提升，展示了其优越性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04377v1",
      "published_date": "2025-02-05 16:25:45 UTC",
      "updated_date": "2025-02-05 16:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:29:34.095031"
    },
    {
      "arxiv_id": "2502.04376v1",
      "title": "MEETING DELEGATE: Benchmarking LLMs on Attending Meetings on Our Behalf",
      "title_zh": "翻译失败",
      "authors": [
        "Lingxiang Hu",
        "Shurun Yuan",
        "Xiaoting Qin",
        "Jue Zhang",
        "Qingwei Lin",
        "Dongmei Zhang",
        "Saravan Rajmohan",
        "Qi Zhang"
      ],
      "abstract": "In contemporary workplaces, meetings are essential for exchanging ideas and\nensuring team alignment but often face challenges such as time consumption,\nscheduling conflicts, and inefficient participation. Recent advancements in\nLarge Language Models (LLMs) have demonstrated their strong capabilities in\nnatural language generation and reasoning, prompting the question: can LLMs\neffectively delegate participants in meetings? To explore this, we develop a\nprototype LLM-powered meeting delegate system and create a comprehensive\nbenchmark using real meeting transcripts. Our evaluation reveals that GPT-4/4o\nmaintain balanced performance between active and cautious engagement\nstrategies. In contrast, Gemini 1.5 Pro tends to be more cautious, while Gemini\n1.5 Flash and Llama3-8B/70B display more active tendencies. Overall, about 60\\%\nof responses address at least one key point from the ground-truth. However,\nimprovements are needed to reduce irrelevant or repetitive content and enhance\ntolerance for transcription errors commonly found in real-world settings.\nAdditionally, we implement the system in practical settings and collect\nreal-world feedback from demos. Our findings underscore the potential and\nchallenges of utilizing LLMs as meeting delegates, offering valuable insights\ninto their practical application for alleviating the burden of meetings.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否能代理会议参与者，以解决工作场所会议的耗时、冲突和低效问题。研究团队开发了一个基于 LLMs 的会议代理系统原型，并使用真实会议记录创建基准测试。评估结果显示，GPT-4/4o 在主动和谨慎策略间保持平衡，而 Gemini 1.5 Pro 更倾向谨慎，Gemini 1.5 Flash 和 Llama3-8B/70B 则更主动；整体约 60% 的响应覆盖关键点，但需改进以减少无关内容和提升对转录错误的容忍度。该工作通过实际实施和反馈，突显了 LLMs 作为会议代理的潜力及其面临的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04376v1",
      "published_date": "2025-02-05 16:25:43 UTC",
      "updated_date": "2025-02-05 16:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:29:45.306245"
    },
    {
      "arxiv_id": "2502.03330v1",
      "title": "Controllable GUI Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Aryan Garg",
        "Yue Jiang",
        "Antti Oulasvirta"
      ],
      "abstract": "During the early stages of interface design, designers need to produce\nmultiple sketches to explore a design space. Design tools often fail to support\nthis critical stage, because they insist on specifying more details than\nnecessary. Although recent advances in generative AI have raised hopes of\nsolving this issue, in practice they fail because expressing loose ideas in a\nprompt is impractical. In this paper, we propose a diffusion-based approach to\nthe low-effort generation of interface sketches. It breaks new ground by\nallowing flexible control of the generation process via three types of inputs:\nA) prompts, B) wireframes, and C) visual flows. The designer can provide any\ncombination of these as input at any level of detail, and will get a diverse\ngallery of low-fidelity solutions in response. The unique benefit is that large\ndesign spaces can be explored rapidly with very little effort in\ninput-specification. We present qualitative results for various combinations of\ninput specifications. Additionally, we demonstrate that our model aligns more\naccurately with these specifications than other models.",
      "tldr_zh": "这篇论文针对界面设计早期阶段的探索难题，提出了一种基于扩散模型的生成方法，以支持低努力生成界面草图。该方法允许设计师通过 prompts、wireframes 和 visual flows 等三种输入灵活控制生成过程，并支持任意组合和详细程度，从而快速产出多样化的低保真度解决方案。结果表明，该方法能高效探索大型设计空间，并在准确性上优于其他模型。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03330v1",
      "published_date": "2025-02-05 16:25:35 UTC",
      "updated_date": "2025-02-05 16:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:29:56.810663"
    },
    {
      "arxiv_id": "2502.03325v1",
      "title": "ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Qiguang Chen",
        "Libo Qin",
        "Jinhao Liu",
        "Dengyun Peng",
        "Jiaqi Wang",
        "Mengkang Hu",
        "Zhi Chen",
        "Wanxiang Che",
        "Ting Liu"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have led to significant\nsuccesses across various applications, where the most noticeable is to a series\nof emerging capabilities, particularly in the areas of In-Context Learning\n(ICL) and Chain-of-Thought (CoT). To better understand and control model\nperformance, many studies have begun investigating the underlying causes of\nthese phenomena and their impact on task outcomes. However, existing\nexplanatory frameworks predominantly focus on isolating and explaining ICL and\nCoT independently, leading to an incomplete understanding of their combined\ninfluence on model performance. To address this gap, we propose the Electronic\nCircuit Model (ECM), which provides a foundation for developing scalable,\nlearnable policies and improving the management of AI-generated content.\nSpecifically, ECM conceptualizes model behavior as an electronic circuit: ICL\nis represented as semantic magnetic field to providing an additional voltage\nfollowing Faraday's Law, while CoT is modeled as series resistors to constrain\nthe model output performance following Ohm's Law. Experimental results\ndemonstrate that the ECM effectively predicts and explains LLM performance\nacross a variety of prompting strategies. Furthermore, we apply ECM to advanced\nreasoning strategy optimization on a series of tasks, such as the International\nOlympiad in Informatics (IOI) and the International Mathematical Olympiad\n(IMO), achieving competitive performance that surpasses nearly 80% of top human\ncompetitors.",
      "tldr_zh": "本文提出 Electronic Circuit Model (ECM)，一种统一框架，用于解释大型语言模型（LLMs）中 In-Context Learning (ICL) 和 Chain-of-Thought (CoT) 的出现，将 ICL 比作提供额外电压的语义磁场（遵循 Faraday's Law），并将 CoT 比作约束输出性能的串联电阻（遵循 Ohm's Law）。这种模型填补了现有研究中对 ICL 和 CoT 独立解释的空白，提供可扩展的学习策略来提升 AI 生成内容的管理。实验验证显示，ECM 能准确预测 LLM 在各种提示策略下的性能，并在 International Olympiad in Informatics (IOI) 和 International Mathematical Olympiad (IMO) 等任务上，超越近 80% 的顶级人类竞争者。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Manuscript",
      "pdf_url": "http://arxiv.org/pdf/2502.03325v1",
      "published_date": "2025-02-05 16:22:33 UTC",
      "updated_date": "2025-02-05 16:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:30:10.120775"
    },
    {
      "arxiv_id": "2502.03323v1",
      "title": "Out-of-Distribution Detection using Synthetic Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Momin Abbas",
        "Muneeza Azmat",
        "Raya Horesh",
        "Mikhail Yurochkin"
      ],
      "abstract": "Distinguishing in- and out-of-distribution (OOD) inputs is crucial for\nreliable deployment of classification systems. However, OOD data is typically\nunavailable or difficult to collect, posing a significant challenge for\naccurate OOD detection. In this work, we present a method that harnesses the\ngenerative capabilities of Large Language Models (LLMs) to create high-quality\nsynthetic OOD proxies, eliminating the dependency on any external OOD data\nsource. We study the efficacy of our method on classical text classification\ntasks such as toxicity detection and sentiment classification as well as\nclassification tasks arising in LLM development and deployment, such as\ntraining a reward model for RLHF and detecting misaligned generations.\nExtensive experiments on nine InD-OOD dataset pairs and various model sizes\nshow that our approach dramatically lowers false positive rates (achieving a\nperfect zero in some cases) while maintaining high accuracy on in-distribution\ntasks, outperforming baseline methods by a significant margin.",
      "tldr_zh": "本研究提出了一种使用 Large Language Models (LLMs) 生成合成 OOD 代理数据的方法，以解决 Out-of-Distribution (OOD) 检测中的数据获取挑战，从而无需依赖外部 OOD 数据源。该方法通过 LLMs 的生成能力创建高质量的合成数据，并应用于文本分类任务（如毒性检测和情感分类）以及 LLM 开发中的场景（如训练 RLHF 的奖励模型和检测不一致生成）。实验在九对 InD-OOD 数据集和各种模型大小上显示，该方法显著降低了假阳性率（某些情况下为零），同时保持了 InD 任务的高准确率，比基线方法有明显优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03323v1",
      "published_date": "2025-02-05 16:22:09 UTC",
      "updated_date": "2025-02-05 16:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:30:20.665783"
    },
    {
      "arxiv_id": "2502.03321v3",
      "title": "Simplifying Formal Proof-Generating Models with ChatGPT and Basic Searching Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Sangjun Han",
        "Taeil Hur",
        "Youngmi Hur",
        "Kathy Sangkyung Lee",
        "Myungyoon Lee",
        "Hyojae Lim"
      ],
      "abstract": "The challenge of formal proof generation has a rich history, but with modern\ntechniques, we may finally be at the stage of making actual progress in\nreal-life mathematical problems. This paper explores the integration of ChatGPT\nand basic searching techniques to simplify generating formal proofs, with a\nparticular focus on the miniF2F dataset. We demonstrate how combining a large\nlanguage model like ChatGPT with a formal language such as Lean, which has the\nadded advantage of being verifiable, enhances the efficiency and accessibility\nof formal proof generation. Despite its simplicity, our best-performing\nLean-based model surpasses all known benchmarks with a 31.15% pass rate. We\nextend our experiments to include other datasets and employ alternative\nlanguage models, showcasing our models' comparable performance in diverse\nsettings and allowing for a more nuanced analysis of our results. Our findings\noffer insights into AI-assisted formal proof generation, suggesting a promising\ndirection for future research in formal mathematical proof.",
      "tldr_zh": "本研究探讨了使用 ChatGPT 和基本搜索技术来简化正式证明生成（formal proof generation），特别针对 miniF2F 数据集，通过结合大型语言模型 ChatGPT 与可验证的正式语言 Lean，提升了证明过程的效率和可访问性。该方法尽管简单，却使基于 Lean's 模型在 miniF2F 上达到了 31.15% 的通过率，超过了所有已知基准，并在其他数据集和语言模型上展现出可比性能。研究结果为 AI 辅助正式证明生成提供了宝贵见解，并为未来数学证明领域的进展指出了有前景的方向。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "This manuscript was accepted for publication in the proceedings of\n  the Computing Conference 2025 (Springer LNNS). The Version of Record (VoR)\n  has not yet been published. This Accepted Manuscript does not reflect any\n  post-acceptance improvements or corrections. Use of this version is subject\n  to Springer Nature's Accepted Manuscript terms of use",
      "pdf_url": "http://arxiv.org/pdf/2502.03321v3",
      "published_date": "2025-02-05 16:21:10 UTC",
      "updated_date": "2025-02-19 06:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:30:33.571267"
    },
    {
      "arxiv_id": "2502.03304v1",
      "title": "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Qitao Tan",
        "Jun Liu",
        "Zheng Zhan",
        "Caiwei Ding",
        "Yanzhi Wang",
        "Jin Lu",
        "Geng Yuan"
      ],
      "abstract": "Large language models (LLMs) excel across various tasks, but standard\nfirst-order (FO) fine-tuning demands considerable memory, significantly\nlimiting real-world deployment. Recently, zeroth-order (ZO) optimization stood\nout as a promising memory-efficient training paradigm, avoiding backward passes\nand relying solely on forward passes for gradient estimation, making it\nattractive for resource-constrained scenarios. However, ZO method lags far\nbehind FO method in both convergence speed and accuracy. To bridge the gap, we\nintroduce a novel layer-wise divergence analysis that uncovers the distinct\nupdate pattern of FO and ZO optimization. Aiming to resemble the learning\ncapacity of FO method from the findings, we propose \\textbf{Di}vergence-driven\n\\textbf{Z}eroth-\\textbf{O}rder (\\textbf{DiZO}) optimization. DiZO conducts\ndivergence-driven layer adaptation by incorporating projections to ZO updates,\ngenerating diverse-magnitude updates precisely scaled to layer-wise individual\noptimization needs. Our results demonstrate that DiZO significantly reduces the\nneeded iterations for convergence without sacrificing throughput, cutting\ntraining GPU hours by up to 48\\% on various datasets. Moreover, DiZO\nconsistently outperforms the representative ZO baselines in fine-tuning\nRoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some\ncases, even surpasses memory-intensive FO fine-tuning.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)的微调问题，指出第一阶(FO)优化虽有效但内存需求过高，而零阶(ZO)优化虽内存高效却在收敛速度和准确性上落后。作者通过层级差异分析揭示FO和ZO优化的更新模式差异，并提出Divergence-driven Zeroth-Order (DiZO)优化方法，该方法通过加入投影生成适应层级需求的更新幅度，提升ZO优化的效率。实验结果显示，DiZO在RoBERTa-large、OPT-series和Llama-series模型上显著减少训练迭代次数，降低GPU小时高达48%，并在某些任务中超越FO微调的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03304v1",
      "published_date": "2025-02-05 16:03:17 UTC",
      "updated_date": "2025-02-05 16:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:30:44.867924"
    },
    {
      "arxiv_id": "2502.03298v1",
      "title": "MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters",
      "title_zh": "翻译失败",
      "authors": [
        "Amin Dada",
        "Osman Alperen Koras",
        "Marie Bauer",
        "Amanda Butler",
        "Kaleb E. Smith",
        "Jens Kleesiek",
        "Julian Friedrich"
      ],
      "abstract": "While increasing patients' access to medical documents improves medical care,\nthis benefit is limited by varying health literacy levels and complex medical\nterminology. Large language models (LLMs) offer solutions by simplifying\nmedical information. However, evaluating LLMs for safe and patient-friendly\ntext generation is difficult due to the lack of standardized evaluation\nresources. To fill this gap, we developed MeDiSumQA. MeDiSumQA is a dataset\ncreated from MIMIC-IV discharge summaries through an automated pipeline\ncombining LLM-based question-answer generation with manual quality checks. We\nuse this dataset to evaluate various LLMs on patient-oriented\nquestion-answering. Our findings reveal that general-purpose LLMs frequently\nsurpass biomedical-adapted models, while automated metrics correlate with human\njudgment. By releasing MeDiSumQA on PhysioNet, we aim to advance the\ndevelopment of LLMs to enhance patient understanding and ultimately improve\ncare outcomes.",
      "tldr_zh": "该研究开发了 MeDiSumQA 数据集，通过自动化管道从 MIMIC-IV 出院总结中生成患者导向的问答对，并结合 LLM 基于的生成和手动质量检查，以评估大型语言模型 (LLMs) 在简化医疗信息方面的性能。实验发现，通用 LLMs 通常优于生物医学适应模型，且自动化指标与人类判断高度相关。该数据集的发布到 PhysioNet 旨在推进 LLMs 的发展，提升患者对复杂医疗术语的理解，并最终改善护理效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03298v1",
      "published_date": "2025-02-05 15:56:37 UTC",
      "updated_date": "2025-02-05 15:56:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:30:57.549001"
    },
    {
      "arxiv_id": "2502.03292v1",
      "title": "ALPET: Active Few-shot Learning for Citation Worthiness Detection in Low-Resource Wikipedia Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Aida Halitaj",
        "Arkaitz Zubiaga"
      ],
      "abstract": "Citation Worthiness Detection (CWD) consists in determining which sentences,\nwithin an article or collection, should be backed up with a citation to\nvalidate the information it provides. This study, introduces ALPET, a framework\ncombining Active Learning (AL) and Pattern-Exploiting Training (PET), to\nenhance CWD for languages with limited data resources. Applied to Catalan,\nBasque, and Albanian Wikipedia datasets, ALPET outperforms the existing CCW\nbaseline while reducing the amount of labeled data in some cases above 80\\%.\nALPET's performance plateaus after 300 labeled samples, showing it suitability\nfor low-resource scenarios where large, labeled datasets are not common. While\nspecific active learning query strategies, like those employing K-Means\nclustering, can offer advantages, their effectiveness is not universal and\noften yields marginal gains over random sampling, particularly with smaller\ndatasets. This suggests that random sampling, despite its simplicity, remains a\nstrong baseline for CWD in constraint resource environments. Overall, ALPET's\nability to achieve high performance with fewer labeled samples makes it a\npromising tool for enhancing the verifiability of online content in\nlow-resource language settings.",
      "tldr_zh": "该研究提出ALPET框架，将Active Learning (AL)与Pattern-Exploiting Training (PET)相结合，用于Citation Worthiness Detection (CWD)，以识别Wikipedia文章中需要引用的句子，尤其针对Catalan、Basque和Albanian等低资源语言。ALPET在减少80%以上标注数据的情况下，超过了现有CCW基准模型，并在300个标注样本后达到性能平稳，证明其适用于数据稀缺的环境。实验显示，虽然特定AL查询策略如K-Means clustering可能带来轻微优势，但随机采样在小数据集上已足够有效，ALPET整体提升了低资源语言在线内容的verifiability。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 8 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.03292v1",
      "published_date": "2025-02-05 15:49:41 UTC",
      "updated_date": "2025-02-05 15:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:31:09.178793"
    },
    {
      "arxiv_id": "2502.05220v1",
      "title": "Aero-LLM: A Distributed Framework for Secure UAV Communication and Intelligent Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Balakrishnan Dharmalingam",
        "Rajdeep Mukherjee",
        "Brett Piggott",
        "Guohuan Feng",
        "Anyi Liu"
      ],
      "abstract": "Increased utilization of unmanned aerial vehicles (UAVs) in critical\noperations necessitates secure and reliable communication with Ground Control\nStations (GCS). This paper introduces Aero-LLM, a framework integrating\nmultiple Large Language Models (LLMs) to enhance UAV mission security and\noperational efficiency. Unlike conventional singular LLMs, Aero-LLM leverages\nmultiple specialized LLMs for various tasks, such as inferencing, anomaly\ndetection, and forecasting, deployed across onboard systems, edge, and cloud\nservers. This dynamic, distributed architecture reduces performance bottleneck\nand increases security capabilities. Aero-LLM's evaluation demonstrates\noutstanding task-specific metrics and robust defense against cyber threats,\nsignificantly enhancing UAV decision-making and operational capabilities and\nsecurity resilience against cyber attacks, setting a new standard for secure,\nintelligent UAV operations.",
      "tldr_zh": "本论文提出Aero-LLM框架，通过整合多个Large Language Models (LLMs)来提升无人驾驶航空器(UAVs)的安全通信和智能决策能力。\n该框架采用分布式架构，将专业化的LLMs部署在机载系统、边缘和云服务器上，用于处理任务如推理、异常检测和预测，从而减少性能瓶颈并增强安全性。\n实验结果显示，Aero-LLM在任务特定指标上表现出色，并显著提高了UAVs对网络威胁的防御能力，为安全的智能UAV操作树立了新标准。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This manuscript was accepted by the 1st International Workshop on\n  Integrated Sensing, Communication, and Computing in Internet of Things (IoT)\n  Systems at the The 33rd International Conference on Computer Communications\n  and Networks (ICCCN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2502.05220v1",
      "published_date": "2025-02-05 15:46:27 UTC",
      "updated_date": "2025-02-05 15:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:31:21.347748"
    },
    {
      "arxiv_id": "2502.03287v2",
      "title": "STEMS: Spatial-Temporal Mapping Tool For Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Sherif Eissa",
        "Sander Stuijk",
        "Floran De Putter",
        "Andrea Nardi-Dei",
        "Federico Corradi",
        "Henk Corporaal"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are promising bio-inspired third-generation\nneural networks. Recent research has trained deep SNN models with accuracy on\npar with Artificial Neural Networks (ANNs). Although the event-driven and\nsparse nature of SNNs show potential for more energy efficient computation than\nANNs, SNN neurons have internal states which evolve over time. Keeping track of\nSNN states can significantly increase data movement and storage requirements,\npotentially losing its advantages with respect to ANNs. This paper investigates\nthe energy effects of having neuron states, and how it is influenced by the\nchosen mapping to realistic hardware architectures with advanced memory\nhierarchies. Therefore, we develop STEMS, a mapping design space exploration\ntool for SNNs. STEMS models SNN's stateful behavior and explores intra-layer\nand inter-layer mapping optimizations to minimize data movement, considering\nboth spatial and temporal SNN dimensions. Using STEMS, we show up to 12x\nreduction in off-chip data movement and 5x reduction in energy (on top of\nintra-layer optimizations), on two event-based vision SNN benchmarks. Finally,\nneuron states may not be needed for all SNN layers. By optimizing neuron states\nfor one of our benchmarks, we show 20x reduction in neuron states and 1.4x\nbetter performance without accuracy loss.",
      "tldr_zh": "本研究探讨了Spiking Neural Networks (SNNs)中神经元状态对能效的影响，指出其内部状态可能增加数据移动和存储需求，从而削弱与Artificial Neural Networks (ANNs)相比的能效优势。为此，开发了STEMS，一种用于SNNs的映射设计空间探索工具，该工具建模SNNs的状态行为，并通过优化层内和层间空间-时间映射来最小化数据移动。实验结果显示，在两个基于事件的视觉SNN基准上，STEMS实现了高达12倍的芯片外数据移动减少和5倍的能量节省；此外，通过针对某些层优化神经元状态，实现了20倍的状态减少和1.4倍的性能提升，而不损失准确性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR",
        "cs.DC"
      ],
      "primary_category": "cs.NE",
      "comment": "24 pages, 23 figures, under review at IEEE TC",
      "pdf_url": "http://arxiv.org/pdf/2502.03287v2",
      "published_date": "2025-02-05 15:44:15 UTC",
      "updated_date": "2025-02-17 12:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:31:32.935266"
    },
    {
      "arxiv_id": "2502.06830v2",
      "title": "OrderFusion: Encoding Orderbook for End-to-End Probabilistic Intraday Electricity Price Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Runyao Yu",
        "Yuchen Tao",
        "Fabian Leimgruber",
        "Tara Esterl",
        "Jochen L. Cremer"
      ],
      "abstract": "Accurate and reliable probabilistic prediction of intraday electricity prices\nis essential to manage market uncertainties and support robust trading\nstrategies. However, current methods rely heavily on domain feature extraction\nand fail to capture the dynamics between buy and sell orders, limiting the\nability to form rich representations of the orderbook. Furthermore, these\nmethods often require training separate models for different quantiles and\nintroduce additional procedures-such as post-hoc quantile sorting or loss-based\npenalties-to address the quantile crossing issue, where predicted upper\nquantiles fall below lower ones. These steps are either decoupled from model\ntraining or introduce extra tuning complexity. To address these challenges, we\npropose an encoding method called OrderFusion and design a hierarchical\nmulti-quantile head. OrderFusion encodes the orderbook into a 2.5D\nrepresentation and employs a tailored jump cross-attention to model buy-sell\ndynamics without the need for domain feature extraction. The multi-quantile\nhead anchors on the median quantile and hierarchically estimates other\nquantiles through constrained residuals, ensuring monotonicity without\npost-processing or additional tuning. We conduct extensive experiments and\nablation studies on three key price indices (ID1, ID2, and ID3) using three\nyears of orderbook data from the German and Austrian markets. The results\ndemonstrate that our approach provides an accurate, reliable, and unified\nend-to-end framework for probabilistic intraday price prediction.",
      "tldr_zh": "该论文提出 OrderFusion 编码方法，用于端到端概率日内电力价格预测，以解决现有方法依赖领域特征提取、无法捕捉买卖订单动态以及处理分位数交叉问题的局限性。OrderFusion 将订单簿编码成 2.5D 表示，并采用定制的 jump cross-attention 机制建模买卖动态，而无需手动特征提取；同时，设计了分层 multi-quantile head，通过以中位数分位数为基础的约束残差估计算其他分位数，确保预测单调性且避免后处理。实验在德国和奥地利市场的三个关键价格指数（ID1、ID2、ID3）上使用三年订单簿数据进行验证，结果显示该框架提供准确、可靠的统一预测方案。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.CP",
      "comment": "20 pages, 3 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06830v2",
      "published_date": "2025-02-05 15:37:21 UTC",
      "updated_date": "2025-05-16 10:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:31:46.003926"
    },
    {
      "arxiv_id": "2502.03283v2",
      "title": "SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs",
      "title_zh": "SymAgent：一种神经符号自我学习代理框架，用于知识图谱上的复杂推理",
      "authors": [
        "Ben Liu",
        "Jihai Zhang",
        "Fangquan Lin",
        "Cheng Yang",
        "Min Peng",
        "Wotao Yin"
      ],
      "abstract": "Recent advancements have highlighted that Large Language Models (LLMs) are\nprone to hallucinations when solving complex reasoning problems, leading to\nerroneous results. To tackle this issue, researchers incorporate Knowledge\nGraphs (KGs) to improve the reasoning ability of LLMs. However, existing\nmethods face two limitations: 1) they typically assume that all answers to the\nquestions are contained in KGs, neglecting the incompleteness issue of KGs, and\n2) they treat the KG as a static repository and overlook the implicit logical\nreasoning structures inherent in KGs. In this paper, we introduce SymAgent, an\ninnovative neural-symbolic agent framework that achieves collaborative\naugmentation between KGs and LLMs. We conceptualize KGs as dynamic environments\nand transform complex reasoning tasks into a multi-step interactive process,\nenabling KGs to participate deeply in the reasoning process. SymAgent consists\nof two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages\nLLM's inductive reasoning capability to extract symbolic rules from KGs,\nguiding efficient question decomposition. The Agent-Executor autonomously\ninvokes predefined action tools to integrate information from KGs and external\ndocuments, addressing the issues of KG incompleteness. Furthermore, we design a\nself-learning framework comprising online exploration and offline iterative\npolicy updating phases, enabling the agent to automatically synthesize\nreasoning trajectories and improve performance. Experimental results\ndemonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields\nbetter or comparable performance compared to various strong baselines. Further\nanalysis reveals that our agent can identify missing triples, facilitating\nautomatic KG updates.",
      "tldr_zh": "该研究提出 SymAgent，一种神经符号自学习代理框架，旨在解决 Large Language Models (LLMs) 在复杂推理中易产生幻觉的问题，并通过将 Knowledge Graphs (KGs) 视为动态环境，实现 KGs 与 LLMs 的协作增强。SymAgent 包括 Agent-Planner 模块，利用 LLM 的归纳推理能力从 KGs 中提取符号规则以指导问题分解，以及 Agent-Executor 模块，自主调用动作工具整合 KGs 和外部文档信息，解决 KGs 的不完整性。该框架采用自学习机制，包括在线探索和离线迭代策略更新，允许代理自动合成推理轨迹并优化性能。实验结果表明，使用较弱 LLM 后端（如 7B 系列）的 SymAgent 性能优于或相当于是强基线，并能识别缺失三元组以促进 KGs 的自动更新。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03283v2",
      "published_date": "2025-02-05 15:37:05 UTC",
      "updated_date": "2025-02-18 07:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:31:58.701821"
    },
    {
      "arxiv_id": "2502.03275v1",
      "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "DiJia Su",
        "Hanlin Zhu",
        "Yingchen Xu",
        "Jiantao Jiao",
        "Yuandong Tian",
        "Qinqing Zheng"
      ],
      "abstract": "Large Language Models (LLMs) excel at reasoning and planning when trained on\nchainof-thought (CoT) data, where the step-by-step thought process is\nexplicitly outlined by text tokens. However, this results in lengthy inputs\nwhere many words support textual coherence rather than core reasoning\ninformation, and processing these inputs consumes substantial computation\nresources. In this work, we propose a hybrid representation of the reasoning\nprocess, where we partially abstract away the initial reasoning steps using\nlatent discrete tokens generated by VQ-VAE, significantly reducing the length\nof reasoning traces. We explore the use of latent trace abstractions in two\nscenarios: 1) training the model from scratch for the Keys-Finding Maze\nproblem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary\nincluding unseen latent tokens, for both logical and mathematical reasoning\nproblems. To facilitate effective learning, we introduce a simple training\nprocedure that randomly mixes latent and text tokens, which enables fast\nadaptation to new latent tokens. Our approach consistently outperforms the\nbaselines methods in various benchmarks.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs)处理chain-of-thought (CoT)数据时输入冗长和计算资源消耗的问题，提出了一种混合表示方法，即使用VQ-VAE生成的latent discrete tokens来抽象初始推理步骤，从而显著缩短推理痕迹。研究探索了在Keys-Finding Maze问题上从零训练模型，以及在逻辑和数学推理任务上微调LLMs的场景，并引入了随机混合latent和text tokens的简单训练过程，以实现快速适应新tokens。该方法在各种基准测试中 consistently outperforms 基线方法，展示了其在提升模型推理效率方面的优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03275v1",
      "published_date": "2025-02-05 15:33:00 UTC",
      "updated_date": "2025-02-05 15:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:32:09.611949"
    },
    {
      "arxiv_id": "2502.05219v1",
      "title": "Enabling External Scrutiny of AI Systems with Privacy-Enhancing Technologies",
      "title_zh": "翻译失败",
      "authors": [
        "Kendrea Beers",
        "Helen Toner"
      ],
      "abstract": "This article describes how technical infrastructure developed by the\nnonprofit OpenMined enables external scrutiny of AI systems without\ncompromising sensitive information.\n  Independent external scrutiny of AI systems provides crucial transparency\ninto AI development, so it should be an integral component of any approach to\nAI governance. In practice, external researchers have struggled to gain access\nto AI systems because of AI companies' legitimate concerns about security,\nprivacy, and intellectual property.\n  But now, privacy-enhancing technologies (PETs) have reached a new level of\nmaturity: end-to-end technical infrastructure developed by OpenMined combines\nseveral PETs into various setups that enable privacy-preserving audits of AI\nsystems. We showcase two case studies where this infrastructure has been\ndeployed in real-world governance scenarios: \"Understanding Social Media\nRecommendation Algorithms with the Christchurch Call\" and \"Evaluating Frontier\nModels with the UK AI Safety Institute.\" We describe types of scrutiny of AI\nsystems that could be facilitated by current setups and OpenMined's proposed\nfuture setups.\n  We conclude that these innovative approaches deserve further exploration and\nsupport from the AI governance community. Interested policymakers can focus on\nempowering researchers on a legal level.",
      "tldr_zh": "这篇文章探讨了如何利用Privacy-Enhancing Technologies (PETs)实现AI系统的外部审查，同时保护敏感信息。OpenMined非营利组织开发的端到端技术基础设施结合多种PETs，允许独立研究人员进行隐私保护的AI审计，从而解决AI公司对安全、隐私和知识产权的担忧。文章展示了两个真实案例：Christchurch Call中的社交媒体推荐算法审查，以及UK AI Safety Institute对前沿模型的评估，证明了这种方法的有效性。作者呼吁AI治理社区进一步探索和支持这些创新做法，并建议政策制定者从法律层面赋能研究人员。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05219v1",
      "published_date": "2025-02-05 15:31:11 UTC",
      "updated_date": "2025-02-05 15:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:32:21.427139"
    },
    {
      "arxiv_id": "2502.03274v1",
      "title": "A Scalable Approach to Probabilistic Neuro-Symbolic Verification",
      "title_zh": "一种针对概率神经符号验证的可扩展方法",
      "authors": [
        "Vasileios Manginas",
        "Nikolaos Manginas",
        "Edward Stevinson",
        "Sherwin Varghese",
        "Nikos Katzouris",
        "Georgios Paliouras",
        "Alessio Lomuscio"
      ],
      "abstract": "Neuro-Symbolic Artificial Intelligence (NeSy AI) has emerged as a promising\ndirection for integrating neural learning with symbolic reasoning. In the\nprobabilistic variant of such systems, a neural network first extracts a set of\nsymbols from sub-symbolic input, which are then used by a symbolic component to\nreason in a probabilistic manner towards answering a query. In this work, we\naddress the problem of formally verifying the robustness of such NeSy\nprobabilistic reasoning systems, therefore paving the way for their safe\ndeployment in critical domains. We analyze the complexity of solving this\nproblem exactly, and show that it is $\\mathrm{NP}^{\\# \\mathrm{P}}$-hard. To\novercome this issue, we propose the first approach for approximate,\nrelaxation-based verification of probabilistic NeSy systems. We demonstrate\nexperimentally that the proposed method scales exponentially better than\nsolver-based solutions and apply our technique to a real-world autonomous\ndriving dataset, where we verify a safety property under large input\ndimensionalities and network sizes.",
      "tldr_zh": "这篇论文提出了一种可扩展的方法，用于正式验证概率Neuro-Symbolic AI (NeSy AI) 系统的鲁棒性，以确保其在关键领域如自动驾驶中的安全部署。作者首先分析了精确验证问题的复杂性，证明其为NP^#P-hard，并开发了第一种基于松弛的近似验证方法，以提高计算效率。实验结果显示，该方法比基于求解器的解决方案扩展性高出指数级，并在真实世界的自动驾驶数据集上成功验证了安全属性，即使面对高输入维度和大型网络。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03274v1",
      "published_date": "2025-02-05 15:29:41 UTC",
      "updated_date": "2025-02-05 15:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:32:33.319457"
    },
    {
      "arxiv_id": "2502.03272v2",
      "title": "Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Schwab",
        "Mathias Pamminger",
        "Christian Kremser",
        "Markus Haltmeier",
        "Agnes Mayr"
      ],
      "abstract": "Purpose: To develop and evaluate a deep learning-based method that allows to\nperform myocardial infarct segmentation in a fully-automated way.\n  Materials and Methods: For this retrospective study, a cascaded framework of\ntwo and three-dimensional convolutional neural networks (CNNs), specialized on\nidentifying ischemic myocardial scars on late gadolinium enhancement (LGE)\ncardiac magnetic resonance (CMR) images, was trained on an in-house training\ndataset consisting of 144 examinations. On a separate test dataset from the\nsame institution, including images from 152 examinations obtained between 2021\nand 2023, a quantitative comparison between artificial intelligence (AI)-based\nsegmentations and manual segmentations was performed. Further, qualitative\nassessment of segmentation accuracy was evaluated for both human and\nAI-generated contours by two CMR experts in a blinded experiment.\n  Results: Excellent agreement could be found between manually and\nautomatically calculated infarct volumes ($\\rho_c$ = 0.9). The qualitative\nevaluation showed that compared to human-based measurements, the experts rated\nthe AI-based segmentations to better represent the actual extent of infarction\nsignificantly (p < 0.001) more often (33.4% AI, 25.1% human, 41.5% equal). On\nthe contrary, for segmentation of microvascular obstruction (MVO), manual\nmeasurements were still preferred (11.3% AI, 55.6% human, 33.1% equal).\n  Conclusion: This fully-automated segmentation pipeline enables CMR infarct\nsize to be calculated in a very short time and without requiring any\npre-processing of the input images while matching the segmentation quality of\ntrained human observers. In a blinded experiment, experts preferred automated\ninfarct segmentations more often than manual segmentations, paving the way for\na potential clinical application.",
      "tldr_zh": "本研究开发了一个基于深度学习的级联框架，使用二维和三维 CNNs，实现对临床心脏磁共振（CMR）图像中晚期钆增强（LGE）区域的心肌梗塞自动分割，无需预处理。实验在144例训练数据集上训练模型，并在152例独立测试数据集上进行AI与手动分割的定量和定性比较，结果显示AI分割与手动计算的梗塞体积高度一致（ρ_c = 0.9），且在盲实验中，专家更常认为AI分割更准确地代表梗塞范围（p < 0.001）。然而，在微血管梗塞（MVO）分割上，手动方法仍更受欢迎；总体而言，该管道可快速计算梗塞大小，并匹配人类观察者的质量，有望应用于临床实践。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03272v2",
      "published_date": "2025-02-05 15:29:28 UTC",
      "updated_date": "2025-03-19 10:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:32:45.393179"
    },
    {
      "arxiv_id": "2502.03270v2",
      "title": "When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaos Tsagkas",
        "Andreas Sochopoulos",
        "Duolikun Danier",
        "Sethu Vijayakumar",
        "Chris Xiaoxuan Lu",
        "Oisin Mac Aodha"
      ],
      "abstract": "The integration of pre-trained visual representations (PVRs) into visuo-motor\nrobot learning has emerged as a promising alternative to training visual\nencoders from scratch. However, PVRs face critical challenges in the context of\npolicy learning, including temporal entanglement and an inability to generalise\neven in the presence of minor scene perturbations. These limitations hinder\nperformance in tasks requiring temporal awareness and robustness to scene\nchanges. This work identifies these shortcomings and proposes solutions to\naddress them. First, we augment PVR features with temporal perception and a\nsense of task completion, effectively disentangling them in time. Second, we\nintroduce a module that learns to selectively attend to task-relevant local\nfeatures, enhancing robustness when evaluated on out-of-distribution scenes.\nOur experiments demonstrate significant performance improvements, particularly\nin PVRs trained with masking objectives, and validate the effectiveness of our\nenhancements in addressing PVR-specific limitations.",
      "tldr_zh": "该研究探讨了预训练视觉表示 (PVRs) 在视觉-运动机器人学习中的局限性，包括时间纠缠 (temporal entanglement) 和对场景微扰的泛化能力不足，这些问题导致在需要时间感知和鲁棒性的任务中表现不佳。为解决这些挑战，作者提出两种方法：一是增强 PVR 特征以加入时间感知和任务完成感，从而解开时间纠缠；二是引入一个选择性注意力模块，专注于任务相关的局部特征，以提升对分布外场景的鲁棒性。实验结果显示，这些改进显著提高了性能，尤其在采用掩码目标训练的 PVRs 上，验证了该方法的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://tsagkas.github.io/pvrobo/",
      "pdf_url": "http://arxiv.org/pdf/2502.03270v2",
      "published_date": "2025-02-05 15:25:46 UTC",
      "updated_date": "2025-05-05 09:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:32:56.829092"
    },
    {
      "arxiv_id": "2502.03238v2",
      "title": "Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Li Pan",
        "Yupei Zhang",
        "Qiushi Yang",
        "Tan Li",
        "Zhen Chen"
      ],
      "abstract": "Recently computer-aided diagnosis has demonstrated promising performance,\neffectively alleviating the workload of clinicians. However, the inherent\nsample imbalance among different diseases leads algorithms biased to the\nmajority categories, leading to poor performance for rare categories. Existing\nworks formulated this challenge as a long-tailed problem and attempted to\ntackle it by decoupling the feature representation and classification. Yet, due\nto the imbalanced distribution and limited samples from tail classes, these\nworks are prone to biased representation learning and insufficient classifier\ncalibration. To tackle these problems, we propose a new Long-tailed Medical\nDiagnosis (LMD) framework for balanced medical image classification on\nlong-tailed datasets. In the initial stage, we develop a Relation-aware\nRepresentation Learning (RRL) scheme to boost the representation ability by\nencouraging the encoder to capture intrinsic semantic features through\ndifferent data augmentations. In the subsequent stage, we propose an Iterative\nClassifier Calibration (ICC) scheme to calibrate the classifier iteratively.\nThis is achieved by generating a large number of balanced virtual features and\nfine-tuning the encoder using an Expectation-Maximization manner. The proposed\nICC compensates for minority categories to facilitate unbiased classifier\noptimization while maintaining the diagnostic knowledge in majority classes.\nComprehensive experiments on three public long-tailed medical datasets\ndemonstrate that our LMD framework significantly surpasses state-of-the-art\napproaches. The source code can be accessed at\nhttps://github.com/peterlipan/LMD.",
      "tldr_zh": "该研究针对医疗图像分类中的长尾问题（样本不平衡导致算法偏向多数类别），提出Long-tailed Medical Diagnosis (LMD)框架，以提升少数类别的诊断性能。框架包括Relation-aware Representation Learning (RRL)方案，通过不同数据增强鼓励编码器捕获内在语义特征，从而改善表示学习；以及Iterative Classifier Calibration (ICC)方案，通过生成平衡虚拟特征并采用Expectation-Maximization方式迭代微调编码器，实现无偏分类器优化，同时保留多数类别的诊断知识。在三个公共长尾医疗数据集上的实验显示，LMD框架显著超越最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been accepted in Computers in Biology and Medicine",
      "pdf_url": "http://arxiv.org/pdf/2502.03238v2",
      "published_date": "2025-02-05 14:57:23 UTC",
      "updated_date": "2025-02-07 18:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:33:09.860658"
    },
    {
      "arxiv_id": "2502.03231v1",
      "title": "The Other Side of the Coin: Unveiling the Downsides of Model Aggregation in Federated Learning from a Layer-peeled Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Guogang Zhu",
        "Xuefeng Liu",
        "Jianwei Niu",
        "Shaojie Tang",
        "Xinghao Wu"
      ],
      "abstract": "In federated learning (FL), model aggregation is a critical step by which\nmultiple clients share their knowledge with one another. However, it is also\nwidely recognized that the aggregated model, when sent back to each client,\nperforms poorly on local data until after several rounds of local training.\nThis temporary performance drop can potentially slow down the convergence of\nthe FL model. Most research in FL regards this performance drop as an inherent\ncost of knowledge sharing among clients and does not give it special attention.\nWhile some studies directly focus on designing techniques to alleviate the\nissue, an in-depth investigation of the reasons behind this performance drop\nhas yet to be conducted.To address this gap, we conduct a layer-peeled analysis\nof model aggregation across various datasets and model architectures. Our\nfindings reveal that the performance drop can be attributed to two major\nconsequences of the aggregation process: (1) it disrupts feature variability\nsuppression in deep neural networks (DNNs), and (2) it weakens the coupling\nbetween features and subsequent parameters.Based on these findings, we propose\nseveral simple yet effective strategies to mitigate the negative impacts of\nmodel aggregation while still enjoying the benefit it brings. To the best of\nour knowledge, our work is the first to conduct a layer-peeled analysis of\nmodel aggregation, potentially paving the way for the development of more\neffective FL algorithms.",
      "tldr_zh": "在联邦学习（Federated Learning, FL）中，模型聚合虽然促进知识共享，但会导致聚合模型在本地数据上暂时表现不佳，延缓收敛过程。作者通过逐层分析（layer-peeled analysis）对各种数据集和模型架构进行研究，发现这一性能下降主要源于两个方面：破坏深度神经网络（DNNs）的特征变异性抑制，以及削弱特征与后续参数之间的耦合。基于这些发现，论文提出了几种简单有效的策略来缓解模型聚合的负面影响，同时保留其益处，并为开发更有效的FL算法铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03231v1",
      "published_date": "2025-02-05 14:45:56 UTC",
      "updated_date": "2025-02-05 14:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:34:34.613278"
    },
    {
      "arxiv_id": "2502.03214v1",
      "title": "iVISPAR -- An Interactive Visual-Spatial Reasoning Benchmark for VLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Julius Mayer",
        "Mohamad Ballout",
        "Serwan Jassim",
        "Farbod Nosrat Nezami",
        "Elia Bruni"
      ],
      "abstract": "Vision-Language Models (VLMs) are known to struggle with spatial reasoning\nand visual alignment. To help overcome these limitations, we introduce iVISPAR,\nan interactive multi-modal benchmark designed to evaluate the spatial reasoning\ncapabilities of VLMs acting as agents. iVISPAR is based on a variant of the\nsliding tile puzzle-a classic problem that demands logical planning, spatial\nawareness, and multi-step reasoning. The benchmark supports visual 2D, 3D, and\ntext-based input modalities, enabling comprehensive assessments of VLMs'\nplanning and reasoning skills. We evaluate a broad suite of state-of-the-art\nopen-source and closed-source VLMs, comparing their performance while also\nproviding optimal path solutions and a human baseline to assess the task's\ncomplexity and feasibility for humans. Results indicate that while some VLMs\nperform well on simple spatial tasks, they encounter difficulties with more\ncomplex configurations and problem properties. Notably, while VLMs generally\nperform better in 2D vision compared to 3D or text-based representations, they\nconsistently fall short of human performance, illustrating the persistent\nchallenge of visual alignment. This highlights critical gaps in current VLM\ncapabilities, highlighting their limitations in achieving human-level\ncognition.",
      "tldr_zh": "本研究引入 iVISPAR，一种交互式多模态基准，用于评估视觉语言模型 (VLMs) 的空间推理能力，特别是解决其在空间推理和视觉对齐方面的局限。iVISPAR 基于滑动拼图游戏的变体，支持视觉 2D、3D 和文本输入模态，强调逻辑规划、空间意识和多步推理，并提供最优路径解决方案以及人类基线进行比较。实验结果显示，VLMs 在简单任务上表现较好，但遇复杂配置时困难重重，且在 2D 视觉中优于 3D 或文本表示，但整体仍远低于人类水平，突显了当前 VLMs 在视觉对齐和认知方面的关键缺陷。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03214v1",
      "published_date": "2025-02-05 14:29:01 UTC",
      "updated_date": "2025-02-05 14:29:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:33:33.536278"
    },
    {
      "arxiv_id": "2502.18474v1",
      "title": "A Contemporary Survey of Large Language Model Assisted Program Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayimei Wang",
        "Tao Ni",
        "Wei-Bin Lee",
        "Qingchuan Zhao"
      ],
      "abstract": "The increasing complexity of software systems has driven significant\nadvancements in program analysis, as traditional methods unable to meet the\ndemands of modern software development. To address these limitations, deep\nlearning techniques, particularly Large Language Models (LLMs), have gained\nattention due to their context-aware capabilities in code comprehension.\nRecognizing the potential of LLMs, researchers have extensively explored their\napplication in program analysis since their introduction. Despite existing\nsurveys on LLM applications in cybersecurity, comprehensive reviews\nspecifically addressing their role in program analysis remain scarce. In this\nsurvey, we systematically review the application of LLMs in program analysis,\ncategorizing the existing work into static analysis, dynamic analysis, and\nhybrid approaches. Moreover, by examining and synthesizing recent studies, we\nidentify future directions and challenges in the field. This survey aims to\ndemonstrate the potential of LLMs in advancing program analysis practices and\noffer actionable insights for security researchers seeking to enhance detection\nframeworks or develop domain-specific models.",
      "tldr_zh": "这篇调查论文探讨了 Large Language Models (LLMs) 在程序分析中的应用，旨在解决传统方法无法应对现代软件系统复杂性的问题。作者系统回顾了现有研究，将 LLMs 的应用分类为静态分析、动态分析和混合方法，并通过综合分析识别了未来方向和挑战。该调查展示了 LLMs 在提升程序分析实践方面的潜力，并为安全研究者提供可操作的见解，以增强检测框架或开发特定模型。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18474v1",
      "published_date": "2025-02-05 14:27:17 UTC",
      "updated_date": "2025-02-05 14:27:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:33:44.929204"
    },
    {
      "arxiv_id": "2502.03206v3",
      "title": "A Unified and General Humanoid Whole-Body Controller for Versatile Locomotion",
      "title_zh": "一种统一且通用的多功能运动人形机器人全身体控制器",
      "authors": [
        "Yufei Xue",
        "Wentao Dong",
        "Minghuan Liu",
        "Weinan Zhang",
        "Jiangmiao Pang"
      ],
      "abstract": "Locomotion is a fundamental skill for humanoid robots. However, most existing\nworks make locomotion a single, tedious, unextendable, and unconstrained\nmovement. This limits the kinematic capabilities of humanoid robots. In\ncontrast, humans possess versatile athletic abilities-running, jumping,\nhopping, and finely adjusting gait parameters such as frequency and foot\nheight. In this paper, we investigate solutions to bring such versatility into\nhumanoid locomotion and thereby propose HugWBC: a unified and general humanoid\nwhole-body controller for versatile locomotion. By designing a general command\nspace in the aspect of tasks and behaviors, along with advanced techniques like\nsymmetrical loss and intervention training for learning a whole-body humanoid\ncontrolling policy in simulation, HugWBC enables real-world humanoid robots to\nproduce various natural gaits, including walking, jumping, standing, and\nhopping, with customizable parameters such as frequency, foot swing height,\nfurther combined with different body height, waist rotation, and body pitch.\nBeyond locomotion, HugWBC also supports real-time interventions from external\nupper-body controllers like teleoperation, enabling loco-manipulation with\nprecision under any locomotive behavior. Extensive experiments validate the\nhigh tracking accuracy and robustness of HugWBC with/without upper-body\nintervention for all commands, and we further provide an in-depth analysis of\nhow the various commands affect humanoid movement and offer insights into the\nrelationships between these commands. To our knowledge, HugWBC is the first\nhumanoid whole-body controller that supports such versatile locomotion\nbehaviors with high robustness and flexibility.",
      "tldr_zh": "本论文提出 HugWBC，一种统一且通用的类人机器人全身控制器，旨在实现多样化的运动能力，如走、跳、站立和跳跃，并支持自定义参数包括频率、脚摆高度、身体高度、腰部旋转和身体倾斜。\n该控制器通过设计通用命令空间、结合对称损失和干预训练方法，在模拟环境中学习全身控制策略，并允许实时外部干预（如遥操作），实现精确的运动操控。\n实验结果显示，HugWBC 在各种命令下表现出高跟踪准确性和鲁棒性，并分析了命令对运动的影响，这是首个支持如此灵活和鲁棒的类人机器人运动控制器。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at RSS 2025. The first two authors contribute equally.\n  Project page: https://hugwbc.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2502.03206v3",
      "published_date": "2025-02-05 14:26:01 UTC",
      "updated_date": "2025-04-12 14:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:34:46.587367"
    },
    {
      "arxiv_id": "2502.03200v1",
      "title": "CORTEX: A Cost-Sensitive Rule and Tree Extraction Method",
      "title_zh": "翻译失败",
      "authors": [
        "Marija Kopanja",
        "Miloš Savić",
        "Luca Longo"
      ],
      "abstract": "Tree-based and rule-based machine learning models play pivotal roles in\nexplainable artificial intelligence (XAI) due to their unique ability to\nprovide explanations in the form of tree or rule sets that are easily\nunderstandable and interpretable, making them essential for applications in\nwhich trust in model decisions is necessary. These transparent models are\ntypically used in surrogate modeling, a post-hoc XAI approach for explaining\nthe logic of black-box models, enabling users to comprehend and trust complex\npredictive systems while maintaining competitive performance. This study\nproposes the Cost-Sensitive Rule and Tree Extraction (CORTEX) method, a novel\nrule-based XAI algorithm grounded in the multi-class cost-sensitive decision\ntree (CSDT) method. The original version of the CSDT is extended to\nclassification problems with more than two classes by inducing the concept of\nan n-dimensional class-dependent cost matrix. The performance of CORTEX as a\nrule-extractor XAI method is compared to other post-hoc tree and rule\nextraction methods across several datasets with different numbers of classes.\nSeveral quantitative evaluation metrics are employed to assess the\nexplainability of generated rule sets. Our findings demonstrate that CORTEX is\ncompetitive with other tree-based methods and can be superior to other\nrule-based methods across different datasets. The extracted rule sets suggest\nthe advantages of using the CORTEX method over other methods by producing\nsmaller rule sets with shorter rules on average across datasets with a diverse\nnumber of classes. Overall, the results underscore the potential of CORTEX as a\npowerful XAI tool for scenarios that require the generation of clear,\nhuman-understandable rules while maintaining good predictive performance.",
      "tldr_zh": "这篇论文提出了 CORTEX，一种基于多类成本敏感决策树 (CSDT) 的规则提取方法，用于可解释人工智能 (XAI)，旨在通过生成易懂的树状或规则集来解释黑盒模型。CORTEX 扩展了 CSDT 以处理多于两个类的分类问题，引入 n 维类依赖成本矩阵来优化规则生成。实验结果显示，CORTEX 在多个数据集上与树状方法竞争性强，并优于其他规则提取方法，产生更小、更短的规则集，同时保持良好的预测性能。这些发现突显了 CORTEX 在需要可信赖解释的场景中的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03200v1",
      "published_date": "2025-02-05 14:20:34 UTC",
      "updated_date": "2025-02-05 14:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:34:58.507919"
    },
    {
      "arxiv_id": "2502.03199v1",
      "title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jialiang Wu",
        "Yi Shen",
        "Sijia Liu",
        "Yi Tang",
        "Sen Song",
        "Xiaoyi Wang",
        "Longjun Cai"
      ],
      "abstract": "Despite their impressive capacities, Large language models (LLMs) often\nstruggle with the hallucination issue of generating inaccurate or fabricated\ncontent even when they possess correct knowledge. In this paper, we extend the\nexploration of the correlation between hidden-state prediction changes and\noutput factuality into a deeper, token-wise level. Based on the insights , we\npropose cross-layer Entropy eNhanced Decoding (END), a decoding method that\nmitigates hallucinations without requiring extra training. END leverages inner\nprobability changes across layers to individually quantify the factual\nknowledge required for each candidate token, and adjusts the final predicting\ndistribution to prioritize tokens with higher factuality. Experiments on both\nhallucination and QA benchmarks demonstrate that END significantly enhances the\ntruthfulness and informativeness of generated content while maintaining robust\nQA accuracy. Moreover, our work provides a deeper perspective on understanding\nthe correlations between inherent knowledge and output factuality.",
      "tldr_zh": "本研究针对大语言模型(LLMs)的幻觉问题，即生成不准确或虚构内容，提出了一种基于 token-wise 跨层熵的解码方法——cross-layer Entropy eNhanced Decoding (END)。END 通过分析层间概率变化来量化每个候选 token 的事实知识，并调整预测分布以优先选择事实性更高的 token，而无需额外训练。实验结果显示，该方法在幻觉和 QA 基准上显著提升了生成内容的真实性和信息性，同时保持了稳健的 QA 准确率。该工作还提供了对 LLMs 内在知识与输出事实性之间相关性的更深层理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2502.03199v1",
      "published_date": "2025-02-05 14:19:52 UTC",
      "updated_date": "2025-02-05 14:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:35:10.243826"
    },
    {
      "arxiv_id": "2502.15734v1",
      "title": "Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation",
      "title_zh": "Cache-Craft：管理块缓存以实现高效检索增强生成",
      "authors": [
        "Shubham Agarwal",
        "Sai Sundaresan",
        "Subrata Mitra",
        "Debabrata Mahapatra",
        "Archit Gupta",
        "Rounak Sharma",
        "Nirmal Joshua Kapu",
        "Tong Yu",
        "Shiv Saini"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) is often used with Large Language Models\n(LLMs) to infuse domain knowledge or user-specific information. In RAG, given a\nuser query, a retriever extracts chunks of relevant text from a knowledge base.\nThese chunks are sent to an LLM as part of the input prompt. Typically, any\ngiven chunk is repeatedly retrieved across user questions. However, currently,\nfor every question, attention-layers in LLMs fully compute the key values (KVs)\nrepeatedly for the input chunks, as state-of-the-art methods cannot reuse\nKV-caches when chunks appear at arbitrary locations with arbitrary contexts.\nNaive reuse leads to output quality degradation. This leads to potentially\nredundant computations on expensive GPUs and increases latency. In this work,\nwe propose Cache-Craft, a system for managing and reusing precomputed KVs\ncorresponding to the text chunks (we call chunk-caches) in RAG-based systems.\nWe present how to identify chunk-caches that are reusable, how to efficiently\nperform a small fraction of recomputation to fix the cache to maintain output\nquality, and how to efficiently store and evict chunk-caches in the hardware\nfor maximizing reuse while masking any overheads. With real production\nworkloads as well as synthetic datasets, we show that Cache-Craft reduces\nredundant computation by 51% over SOTA prefix-caching and 75% over full\nrecomputation. Additionally, with continuous batching on a real production\nworkload, we get a 1.6X speed up in throughput and a 2X reduction in end-to-end\nresponse latency over prefix-caching while maintaining quality, for both the\nLLaMA-3-8B and LLaMA-3-70B models.",
      "tldr_zh": "本文提出 Cache-Craft 系统，用于管理 chunk-caches 以优化 Retrieval-Augmented Generation (RAG) 在 Large Language Models (LLMs) 中的效率，解决重复计算 KV-caches 导致的冗余和延迟问题。Cache-Craft 通过识别可重用的 chunk-caches、进行少量重新计算来维护输出质量，以及高效存储和驱逐策略来最大化重用。实验结果显示，该系统比 SOTA prefix-caching 减少51%冗余计算，并在真实工作负载上为 LLaMA-3-8B 和 LLaMA-3-70B 模型实现1.6X吞吐量提升和2X端到端响应延迟降低，同时保持生成质量。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.OS"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted at SIGMOD 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.15734v1",
      "published_date": "2025-02-05 14:12:33 UTC",
      "updated_date": "2025-02-05 14:12:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:35:23.083029"
    },
    {
      "arxiv_id": "2502.03188v1",
      "title": "EuskañolDS: A Naturally Sourced Corpus for Basque-Spanish Code-Switching",
      "title_zh": "翻译失败",
      "authors": [
        "Maite Heredia",
        "Jeremy Barnes",
        "Aitor Soroa"
      ],
      "abstract": "Code-switching (CS) remains a significant challenge in Natural Language\nProcessing (NLP), mainly due a lack of relevant data. In the context of the\ncontact between the Basque and Spanish languages in the north of the Iberian\nPeninsula, CS frequently occurs in both formal and informal spontaneous\ninteractions. However, resources to analyse this phenomenon and support the\ndevelopment and evaluation of models capable of understanding and generating\ncode-switched language for this language pair are almost non-existent. We\nintroduce a first approach to develop a naturally sourced corpus for\nBasque-Spanish code-switching. Our methodology consists of identifying CS texts\nfrom previously available corpora using language identification models, which\nare then manually validated to obtain a reliable subset of CS instances. We\npresent the properties of our corpus and make it available under the name\nEuska\\~nolDS.",
      "tldr_zh": "该研究针对自然语言处理（NLP）中的代码切换（Code-Switching）挑战，强调了巴斯克语（Basque）和西班牙语（Spanish）在伊比利亚半岛北部常见混合现象，但相关数据资源匮乏。作者开发了 EuskañolDS 语料库，通过语言识别模型从现有语料库中识别代码切换文本，并进行手动验证以确保可靠性。该语料库从自然来源获取，并公开其属性，支持分析和评估处理该语言对的模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03188v1",
      "published_date": "2025-02-05 14:04:42 UTC",
      "updated_date": "2025-02-05 14:04:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:35:33.691828"
    },
    {
      "arxiv_id": "2502.06829v2",
      "title": "Convolution-Based Converter : A Weak-Prior Approach For Modeling Stochastic Processes Based On Conditional Density Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoran Pang",
        "Lin Wang",
        "Shuangrong Liu",
        "Shikun Tian",
        "WenHao Yue",
        "Xingshen Zhang",
        "Bo Yang"
      ],
      "abstract": "In this paper, a Convolution-Based Converter (CBC) is proposed to develop a\nmethodology for removing the strong or fixed priors in estimating the\nprobability distribution of targets based on observations in the stochastic\nprocess. Traditional approaches, e.g., Markov-based and Gaussian process-based\nmethods, typically leverage observations to estimate targets based on strong or\nfixed priors (such as Markov properties or Gaussian prior). However, the\neffectiveness of these methods depends on how well their prior assumptions\nalign with the characteristics of the problem. When the assumed priors are not\nsatisfied, these approaches may perform poorly or even become unusable. To\novercome the above limitation, we introduce the Convolution-Based converter\n(CBC), which implicitly estimates the conditional probability distribution of\ntargets without strong or fixed priors, and directly outputs the expected\ntrajectory of the stochastic process that satisfies the constraints from\nobservations. This approach reduces the dependence on priors, enhancing\nflexibility and adaptability in modeling stochastic processes when addressing\ndifferent problems. Experimental results demonstrate that our method\noutperforms existing baselines across multiple metrics.",
      "tldr_zh": "本研究提出了一种弱先验方法，Convolution-Based Converter (CBC)，用于基于条件密度估计建模随机过程，从而避免传统方法如 Markov-based 和 Gaussian process-based 方法对强或固定先验（如 Markov 属性或 Gaussian 先验）的依赖。这些传统方法在先验假设不匹配时性能低下，而 CBC 通过隐式估计目标的条件概率分布，直接输出满足观察约束的期望轨迹，提高了建模的灵活性和适应性。实验结果表明，CBC 在多个指标上优于现有基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06829v2",
      "published_date": "2025-02-05 13:59:34 UTC",
      "updated_date": "2025-04-03 15:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:35:45.372932"
    },
    {
      "arxiv_id": "2502.03508v1",
      "title": "Elucidation of the Concept of Consciousness from the Theory of Non-Human Communication Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Tagnin"
      ],
      "abstract": "This article focuses on elucidating the concept of consciousness from a\nrelational and post-phenomenological theory of non-human communication agents\n(ANHC). Specifically, we explore the contributions of Thomas Metzinger s Self\nModel Theory, Katherine Hayles conceptualizations of non-conscious cognitive\nprocesses centered on knowledge processing phenomena shared between biological\nand technical systems and Lenore and Manuel Blum s theoretical perspective on\ncomputation, which defines consciousness as an emergent phenomenon of complex\ncomputational systems, arising from the appropriate organization of their\ninorganic materiality. Building on interactions with non-human cognitive\nagents, among other factors, the explainability of sociotechnical systems\nchallenges the humanistic common sense of modern philosophy and science. This\ncritical integration of various approaches ultimately questions other concepts\nassociated with consciousness, such as autonomy, freedom, and mutual\nresponsibility. The aim is to contribute to a necessary discussion for\ndesigning new frameworks of understanding that pave the way toward an ethical\nand pragmatic approach to addressing contemporary challenges in the design,\nregulation, and interaction with ANHC. Such frameworks, in turn, enable a more\ninclusive and relational understanding of agency in an interconnected world.",
      "tldr_zh": "这篇论文从非人类通信代理（ANHC）的关系和后现象学理论角度，阐明意识的概念，探讨Thomas Metzinger的Self Model Theory、Katherine Hayles关于非意识认知过程的观点，以及Lenore和Manuel Blum将意识视为复杂计算系统涌现现象的理论。作者通过分析生物和技术系统共享的知识处理现象，挑战现代哲学和科学的传统人文常识，并质疑与意识相关的概念，如自治、自由和相互责任。最终，该研究旨在推动设计新的理解框架，促进ANHC的设计、监管和互动的伦理、务实方法，从而实现更具包容性和关系的代理理解。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Version febrero 2025, originalmente escrito en diciembre de 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.03508v1",
      "published_date": "2025-02-05 13:58:23 UTC",
      "updated_date": "2025-02-05 13:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:35:57.385907"
    },
    {
      "arxiv_id": "2502.03147v1",
      "title": "Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models",
      "title_zh": "通过检索增强大型语言模型在表格数据上的可扩展上下文学习",
      "authors": [
        "Xumeng Wen",
        "Shun Zheng",
        "Zhen Xu",
        "Yiming Sun",
        "Jiang Bian"
      ],
      "abstract": "Recent studies have shown that large language models (LLMs), when customized\nwith post-training on tabular data, can acquire general tabular in-context\nlearning (TabICL) capabilities. These models are able to transfer effectively\nacross diverse data schemas and different task domains. However, existing\nLLM-based TabICL approaches are constrained to few-shot scenarios due to the\nsequence length limitations of LLMs, as tabular instances represented in plain\ntext consume substantial tokens. To address this limitation and enable scalable\nTabICL for any data size, we propose retrieval-augmented LLMs tailored to\ntabular data. Our approach incorporates a customized retrieval module, combined\nwith retrieval-guided instruction-tuning for LLMs. This enables LLMs to\neffectively leverage larger datasets, achieving significantly improved\nperformance across 69 widely recognized datasets and demonstrating promising\nscaling behavior. Extensive comparisons with state-of-the-art tabular models\nreveal that, while LLM-based TabICL still lags behind well-tuned numeric models\nin overall performance, it uncovers powerful algorithms under limited contexts,\nenhances ensemble diversity, and excels on specific datasets. These unique\nproperties underscore the potential of language as a universal and accessible\ninterface for scalable tabular data learning.",
      "tldr_zh": "该研究提出了一种针对表格数据的检索增强大型语言模型（Retrieval-Augmented LLMs），以实现可扩展的表格上下文学习（TabICL），解决现有方法受限于小样本场景的问题。该方法结合定制的检索模块和检索引导的指令微调，允许 LLMs 有效利用更大数据集，并在 69 个广泛认可的数据集上显著提升性能。与最先进的表格模型相比，虽然 LLM-based TabICL 在整体表现上落后于优化过的数值模型，但它在有限上下文下揭示了强大算法、提高了集成多样性，并在特定数据集上表现出色，突显了语言作为通用接口在可扩展表格数据学习中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.03147v1",
      "published_date": "2025-02-05 13:16:41 UTC",
      "updated_date": "2025-02-05 13:16:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:36:10.786210"
    },
    {
      "arxiv_id": "2502.06828v1",
      "title": "Fine-Tuning Strategies for Continual Online EEG Motor Imagery Decoding: Insights from a Large-Scale Longitudinal Study",
      "title_zh": "持续在线 EEG 运动想象解码的微调策略：大规模纵向研究的见解",
      "authors": [
        "Martin Wimpff",
        "Bruno Aristimunha",
        "Sylvain Chevallier",
        "Bin Yang"
      ],
      "abstract": "This study investigates continual fine-tuning strategies for deep learning in\nonline longitudinal electroencephalography (EEG) motor imagery (MI) decoding\nwithin a causal setting involving a large user group and multiple sessions per\nparticipant. We are the first to explore such strategies across a large user\ngroup, as longitudinal adaptation is typically studied in the single-subject\nsetting with a single adaptation strategy, which limits the ability to\ngeneralize findings. First, we examine the impact of different fine-tuning\napproaches on decoder performance and stability. Building on this, we integrate\nonline test-time adaptation (OTTA) to adapt the model during deployment,\ncomplementing the effects of prior fine-tuning. Our findings demonstrate that\nfine-tuning that successively builds on prior subject-specific information\nimproves both performance and stability, while OTTA effectively adapts the\nmodel to evolving data distributions across consecutive sessions, enabling\ncalibration-free operation. These results offer valuable insights and\nrecommendations for future research in longitudinal online MI decoding and\nhighlight the importance of combining domain adaptation strategies for\nimproving BCI performance in real-world applications. Clinical Relevance: Our\ninvestigation enables more stable and efficient long-term motor imagery\ndecoding, which is critical for neurorehabilitation and assistive technologies.",
      "tldr_zh": "这篇论文探讨了持续微调策略在在线纵向 EEG 运动想象（MI）解码中的应用，通过大规模纵向研究首次在大型用户群体中评估这些策略。研究者比较了不同微调方法对解码器性能和稳定性的影响，并整合了在线测试时适应（OTTA）来实时适应模型部署期间的数据分布。结果表明，基于先前受试者信息的连续微调显著提升了性能和稳定性，而 OTTA 实现了无校准操作，支持脑机接口（BCI）在真实场景中的有效应用。这些发现为神经康复和辅助技术提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06828v1",
      "published_date": "2025-02-05 12:57:53 UTC",
      "updated_date": "2025-02-05 12:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:36:23.430724"
    },
    {
      "arxiv_id": "2502.03134v1",
      "title": "Gotham Dataset 2025: A Reproducible Large-Scale IoT Network Dataset for Intrusion Detection and Security Research",
      "title_zh": "翻译失败",
      "authors": [
        "Othmane Belarbi",
        "Theodoros Spyridopoulos",
        "Eirini Anthi",
        "Omer Rana",
        "Pietro Carnelli",
        "Aftab Khan"
      ],
      "abstract": "In this paper, a dataset of IoT network traffic is presented. Our dataset was\ngenerated by utilising the Gotham testbed, an emulated large-scale Internet of\nThings (IoT) network designed to provide a realistic and heterogeneous\nenvironment for network security research. The testbed includes 78 emulated IoT\ndevices operating on various protocols, including MQTT, CoAP, and RTSP. Network\ntraffic was captured in Packet Capture (PCAP) format using tcpdump, and both\nbenign and malicious traffic were recorded. Malicious traffic was generated\nthrough scripted attacks, covering a variety of attack types, such as Denial of\nService (DoS), Telnet Brute Force, Network Scanning, CoAP Amplification, and\nvarious stages of Command and Control (C&C) communication. The data were\nsubsequently processed in Python for feature extraction using the Tshark tool,\nand the resulting data was converted to Comma Separated Values (CSV) format and\nlabelled. The data repository includes the raw network traffic in PCAP format\nand the processed labelled data in CSV format. Our dataset was collected in a\ndistributed manner, where network traffic was captured separately for each IoT\ndevice at the interface between the IoT gateway and the device. Our dataset was\ncollected in a distributed manner, where network traffic was separately\ncaptured for each IoT device at the interface between the IoT gateway and the\ndevice. With its diverse traffic patterns and attack scenarios, this dataset\nprovides a valuable resource for developing Intrusion Detection Systems and\nsecurity mechanisms tailored to complex, large-scale IoT environments. The\ndataset is publicly available at Zenodo.",
      "tldr_zh": "本研究介绍了Gotham Dataset 2025，这是一个大规模、可重现的IoT网络流量数据集，旨在支持入侵检测和网络安全研究。该数据集利用Gotham测试床模拟了包含78个IoT设备的异构环境，捕获了良性和恶意流量，包括DoS、Telnet Brute Force、Network Scanning、CoAP Amplification以及Command and Control (C&C)通信等攻击类型。数据通过Python和Tshark工具处理成CSV格式，并提供原始PCAP格式，以分布式方式从IoT网关和设备接口捕获。该数据集为开发针对复杂IoT环境的入侵检测系统提供宝贵资源，并已在Zenodo上公开可用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "16 pages, 7 figures, 4 tables. Submitted at the Data in Brief journal",
      "pdf_url": "http://arxiv.org/pdf/2502.03134v1",
      "published_date": "2025-02-05 12:51:18 UTC",
      "updated_date": "2025-02-05 12:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:36:33.736933"
    },
    {
      "arxiv_id": "2502.05218v1",
      "title": "FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction",
      "title_zh": "FactorGCL：一种基于超图的因子模型，结合时序残差对比学习，用于股票收益预测",
      "authors": [
        "Yitong Duan",
        "Weiran Wang",
        "Jian Li"
      ],
      "abstract": "As a fundamental method in economics and finance, the factor model has been\nextensively utilized in quantitative investment. In recent years, there has\nbeen a paradigm shift from traditional linear models with expert-designed\nfactors to more flexible nonlinear machine learning-based models with\ndata-driven factors, aiming to enhance the effectiveness of these factor\nmodels. However, due to the low signal-to-noise ratio in market data, mining\neffective factors in data-driven models remains challenging. In this work, we\npropose a hypergraph-based factor model with temporal residual contrastive\nlearning (FactorGCL) that employs a hypergraph structure to better capture\nhigh-order nonlinear relationships among stock returns and factors. To mine\nhidden factors that supplement human-designed prior factors for predicting\nstock returns, we design a cascading residual hypergraph architecture, in which\nthe hidden factors are extracted from the residual information after removing\nthe influence of prior factors. Additionally, we propose a temporal residual\ncontrastive learning method to guide the extraction of effective and\ncomprehensive hidden factors by contrasting stock-specific residual information\nover different time periods. Our extensive experiments on real stock market\ndata demonstrate that FactorGCL not only outperforms existing state-of-the-art\nmethods but also mines effective hidden factors for predicting stock returns.",
      "tldr_zh": "这篇论文提出了一种基于超图(hypergraph)的因子模型 FactorGCL，用于提升股票回报预测的准确性，通过结合时间残差对比学习(temporal residual contrastive learning)来解决市场数据中低信噪比的挑战。模型采用级联残差超图架构，从去除先验因子影响后的残差信息中提取隐藏因子，并通过对比不同时间段的股票特定残差来指导有效因子挖掘。实验在真实股票市场数据上表明，FactorGCL 优于现有最先进方法，并成功挖掘出有效的隐藏因子以改善预测性能。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05218v1",
      "published_date": "2025-02-05 12:37:15 UTC",
      "updated_date": "2025-02-05 12:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:36:45.946845"
    },
    {
      "arxiv_id": "2502.03128v1",
      "title": "Metis: A Foundation Speech Generation Model with Masked Generative Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Yuancheng Wang",
        "Jiachen Zheng",
        "Junan Zhang",
        "Xueyao Zhang",
        "Huan Liao",
        "Zhizheng Wu"
      ],
      "abstract": "We introduce Metis, a foundation model for unified speech generation. Unlike\nprevious task-specific or multi-task models, Metis follows a pre-training and\nfine-tuning paradigm. It is pre-trained on large-scale unlabeled speech data\nusing masked generative modeling and then fine-tuned to adapt to diverse speech\ngeneration tasks. Specifically, 1) Metis utilizes two discrete speech\nrepresentations: SSL tokens derived from speech self-supervised learning (SSL)\nfeatures, and acoustic tokens directly quantized from waveforms. 2) Metis\nperforms masked generative pre-training on SSL tokens, utilizing 300K hours of\ndiverse speech data, without any additional condition. 3) Through fine-tuning\nwith task-specific conditions, Metis achieves efficient adaptation to various\nspeech generation tasks while supporting multimodal input, even when using\nlimited data and trainable parameters. Experiments demonstrate that Metis can\nserve as a foundation model for unified speech generation: Metis outperforms\nstate-of-the-art task-specific or multi-task systems across five speech\ngeneration tasks, including zero-shot text-to-speech, voice conversion, target\nspeaker extraction, speech enhancement, and lip-to-speech, even with fewer than\n20M trainable parameters or 300 times less training data. Audio samples are are\navailable at https://metis-demo.github.io/.",
      "tldr_zh": "我们介绍了 Metis，一种基于 masked generative pre-training 的语音生成基础模型，它采用预训练和微调范式，在 300K 小时无标签语音数据上进行训练，使用 SSL tokens 和 acoustic tokens 作为离散语音表示。Metis 通过任务特定条件微调，支持多模态输入，并高效适应各种语音生成任务，即使在数据和参数资源有限的情况下。实验结果显示，Metis 在零-shot text-to-speech、voice conversion、target speaker extraction、speech enhancement 和 lip-to-speech 等五种任务上，超越了最先进的任务特定或多任务系统，即使参数少于 20M 或训练数据少 300 倍。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03128v1",
      "published_date": "2025-02-05 12:36:21 UTC",
      "updated_date": "2025-02-05 12:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:36:58.696999"
    },
    {
      "arxiv_id": "2502.03123v2",
      "title": "Disentanglement in Difference: Directly Learning Semantically Disentangled Representations by Maximizing Inter-Factor Differences",
      "title_zh": "翻译失败",
      "authors": [
        "Xingshen Zhang",
        "Lin Wang",
        "Shuangrong Liu",
        "Xintao Lu",
        "Chaoran Pang",
        "Bo Yang"
      ],
      "abstract": "In this study, Disentanglement in Difference(DiD) is proposed to address the\ninherent inconsistency between the statistical independence of latent variables\nand the goal of semantic disentanglement in disentanglement representation\nlearning. Conventional disentanglement methods achieve disentanglement\nrepresentation by improving statistical independence among latent variables.\nHowever, the statistical independence of latent variables does not necessarily\nimply that they are semantically unrelated, thus, improving statistical\nindependence does not always enhance disentanglement performance. To address\nthe above issue, DiD is proposed to directly learn semantic differences rather\nthan the statistical independence of latent variables. In the DiD, a Difference\nEncoder is designed to measure the semantic differences; a contrastive loss\nfunction is established to facilitate inter-dimensional comparison. Both of\nthem allow the model to directly differentiate and disentangle distinct\nsemantic factors, thereby resolving the inconsistency between statistical\nindependence and semantic disentanglement. Experimental results on the dSprites\nand 3DShapes datasets demonstrate that the proposed DiD outperforms existing\nmainstream methods across various disentanglement metrics.",
      "tldr_zh": "本文提出Disentanglement in Difference (DiD)方法，直接通过最大化因子间差异来学习语义解缠结表示，解决传统方法中潜在变量统计独立性与语义无关性不一致的问题。DiD设计了Difference Encoder来测量语义差异，并引入contrastive loss function促进维度间的比较，从而实现对不同语义因素的直接区分和解缠结。在dSprites和3DShapes数据集上的实验显示，DiD在各种解缠结指标上优于现有主流方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03123v2",
      "published_date": "2025-02-05 12:30:41 UTC",
      "updated_date": "2025-04-03 15:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:37:09.583260"
    },
    {
      "arxiv_id": "2502.03120v2",
      "title": "At the Mahakumbh, Faith Met Tragedy: Computational Analysis of Stampede Patterns Using Machine Learning and NLP",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Pratap"
      ],
      "abstract": "This study employs machine learning, historical analysis, and natural\nlanguage processing (NLP) to examine recurring lethal stampedes at Indias mass\nreligious gatherings, focusing on the 2025 Mahakumbh tragedy in Prayagraj (48+\ndeaths) and its 1954 predecessor (700+ casualties). Through computational\nmodeling of crowd dynamics and administrative records, it investigates how\nsystemic vulnerabilities contribute to these disasters. Temporal trend analysis\nidentifies persistent choke points, with narrow riverbank access routes linked\nto 92% of past stampede sites and lethal crowd densities recurring during\nspiritually significant moments like Mauni Amavasya. NLP analysis of seven\ndecades of inquiry reports reveals cyclical administrative failures, where VIP\nroute prioritization diverted safety resources in both 1954 and 2025,\nexacerbating fatalities. Statistical modeling demonstrates how ritual urgency\noverrides risk perception, leading to panic propagation patterns that mirror\nhistorical incidents. Findings support the Institutional Amnesia Theory,\nhighlighting how disaster responses remain reactionary rather than preventive.\nBy correlating archival patterns with computational crowd behavior analysis,\nthis study frames stampedes as a collision of infrastructure limitations, socio\nspiritual urgency, and governance inertia, challenging disaster discourse to\naddress how spiritual economies normalize preventable mortality.",
      "tldr_zh": "本研究利用 Machine Learning、历史分析和 NLP 分析印度 Mahakumbh 宗教集会的致命踩踏事件，聚焦 1954 年（700+ 伤亡）和 2025 年（48+ 死亡）的悲剧，通过计算建模人群动态和行政记录揭示系统性漏洞，如狭窄河岸通道与 92% 的踩踏现场相关，以及在 Mauni Amavasya 等精神重要时刻的高密度人群。NLP 分析七十年的调查报告发现，循环的行政失败（如 VIP 路线优先转移安全资源）导致仪式紧迫性压倒风险感知，引发恐慌传播模式。研究支持 Institutional Amnesia Theory，强调灾难响应应从反应性转向预防性，并挑战灾难话语以解决基础设施限制、社会精神紧迫性和治理惰性如何使可预防死亡正常化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.03120v2",
      "published_date": "2025-02-05 12:27:29 UTC",
      "updated_date": "2025-02-24 02:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:37:23.694154"
    },
    {
      "arxiv_id": "2502.03118v1",
      "title": "Tell2Reg: Establishing spatial correspondence between images by the same language prompts",
      "title_zh": "Tell2Reg：通过相同的语言提示在图像之间建立空间对应关系",
      "authors": [
        "Wen Yan",
        "Qianye Yang",
        "Shiqi Huang",
        "Yipei Wang",
        "Shonit Punwani",
        "Mark Emberton",
        "Vasilis Stavrinides",
        "Yipeng Hu",
        "Dean Barratt"
      ],
      "abstract": "Spatial correspondence can be represented by pairs of segmented regions, such\nthat the image registration networks aim to segment corresponding regions\nrather than predicting displacement fields or transformation parameters. In\nthis work, we show that such a corresponding region pair can be predicted by\nthe same language prompt on two different images using the pre-trained large\nmultimodal models based on GroundingDINO and SAM. This enables a fully\nautomated and training-free registration algorithm, potentially generalisable\nto a wide range of image registration tasks. In this paper, we present\nexperimental results using one of the challenging tasks, registering\ninter-subject prostate MR images, which involves both highly variable intensity\nand morphology between patients. Tell2Reg is training-free, eliminating the\nneed for costly and time-consuming data curation and labelling that was\npreviously required for this registration task. This approach outperforms\nunsupervised learning-based registration methods tested, and has a performance\ncomparable to weakly-supervised methods. Additional qualitative results are\nalso presented to suggest that, for the first time, there is a potential\ncorrelation between language semantics and spatial correspondence, including\nthe spatial invariance in language-prompted regions and the difference in\nlanguage prompts between the obtained local and global correspondences. Code is\navailable at https://github.com/yanwenCi/Tell2Reg.git.",
      "tldr_zh": "该论文提出了 Tell2Reg 方法，通过相同的语言 prompts 在两张不同图像上使用预训练模型如 GroundingDINO 和 SAM，来预测对应的区域对，从而实现一种全自动、无需训练的图像配准算法。Tell2Reg 适用于各种图像配准任务，并在跨受试者前列腺 MR 图像配准中表现出色，优于无监督学习方法，并与弱监督方法性能相当。该方法消除了数据标注的成本，同时实验揭示了语言语义与空间对应的潜在相关性，包括语言提示的区域空间不变性和局部/全局对应差异。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "00B25",
        "I.2.7"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures, conference paper",
      "pdf_url": "http://arxiv.org/pdf/2502.03118v1",
      "published_date": "2025-02-05 12:25:02 UTC",
      "updated_date": "2025-02-05 12:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:37:34.619701"
    },
    {
      "arxiv_id": "2502.03111v1",
      "title": "Policies and Evaluation for Online Meeting Summarization",
      "title_zh": "在线会议总结的策略和评估",
      "authors": [
        "Felix Schneider",
        "Marco Turchi",
        "Alex Waibel"
      ],
      "abstract": "With more and more meetings moving to a digital domain, meeting summarization\nhas recently gained interest in both academic and commercial research. However,\nprior academic research focuses on meeting summarization as an offline task,\nperformed after the meeting concludes. In this paper, we perform the first\nsystematic study of online meeting summarization. For this purpose, we propose\nseveral policies for conducting online summarization. We discuss the unique\nchallenges of this task compared to the offline setting and define novel\nmetrics to evaluate latency and partial summary quality. The experiments on the\nAutoMin dataset show that 1) online models can produce strong summaries, 2) our\nmetrics allow a detailed analysis of different systems' quality-latency\ntrade-off, also taking into account intermediate outputs and 3) adaptive\npolicies perform better than fixed scheduled ones. These findings provide a\nstarting point for the wider research community to explore this important task.",
      "tldr_zh": "这篇论文首次系统研究了online meeting summarization，与传统的离线摘要不同，专注于会议进行中的实时摘要生成。作者提出了几种policies来应对独特挑战，如延迟和部分摘要质量，并定义了新metrics来评估系统性能。实验结果显示，在AutoMin dataset上，在线模型能产生高质量摘要，自适应policies比固定scheduled ones表现更好，并允许详细分析质量-延迟权衡。这些发现为研究社区探索这一重要任务提供了重要起点。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2502.03111v1",
      "published_date": "2025-02-05 12:15:00 UTC",
      "updated_date": "2025-02-05 12:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:37:45.496919"
    },
    {
      "arxiv_id": "2502.06827v1",
      "title": "Learning to Synthesize Compatible Fashion Items Using Semantic Alignment and Collocation Classification: An Outfit Generation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Dongliang Zhou",
        "Haijun Zhang",
        "Kai Yang",
        "Linlin Liu",
        "Han Yan",
        "Xiaofei Xu",
        "Zhao Zhang",
        "Shuicheng Yan"
      ],
      "abstract": "The field of fashion compatibility learning has attracted great attention\nfrom both the academic and industrial communities in recent years. Many studies\nhave been carried out for fashion compatibility prediction, collocated outfit\nrecommendation, artificial intelligence (AI)-enabled compatible fashion design,\nand related topics. In particular, AI-enabled compatible fashion design can be\nused to synthesize compatible fashion items or outfits in order to improve the\ndesign experience for designers or the efficacy of recommendations for\ncustomers. However, previous generative models for collocated fashion synthesis\nhave generally focused on the image-to-image translation between fashion items\nof upper and lower clothing. In this paper, we propose a novel outfit\ngeneration framework, i.e., OutfitGAN, with the aim of synthesizing a set of\ncomplementary items to compose an entire outfit, given one extant fashion item\nand reference masks of target synthesized items. OutfitGAN includes a semantic\nalignment module, which is responsible for characterizing the mapping\ncorrespondence between the existing fashion items and the synthesized ones, to\nimprove the quality of the synthesized images, and a collocation classification\nmodule, which is used to improve the compatibility of a synthesized outfit. In\norder to evaluate the performance of our proposed models, we built a\nlarge-scale dataset consisting of 20,000 fashion outfits. Extensive\nexperimental results on this dataset show that our OutfitGAN can synthesize\nphoto-realistic outfits and outperform state-of-the-art methods in terms of\nsimilarity, authenticity and compatibility measurements.",
      "tldr_zh": "本文提出OutfitGAN框架，用于给定一个现有时尚物品和目标物品的参考掩码，合成一整套互补的兼容时尚搭配，解决传统模型仅限于上衣和下衣图像转换的局限性。框架包括语义对齐模块(Semantic Alignment)来处理现有物品与合成物品的映射对应，提高图像质量，以及搭配分类模块(Collocation Classification)来提升整体兼容性。通过构建一个包含20,000时尚搭配的大规模数据集，实验结果表明OutfitGAN在相似性、真实性和兼容性指标上优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper was accepted by IEEE TNNLS",
      "pdf_url": "http://arxiv.org/pdf/2502.06827v1",
      "published_date": "2025-02-05 12:13:53 UTC",
      "updated_date": "2025-02-05 12:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:37:57.932024"
    },
    {
      "arxiv_id": "2502.06826v1",
      "title": "Transferring Graph Neural Networks for Soft Sensor Modeling using Process Topologies",
      "title_zh": "利用过程拓扑迁移图神经网络进行软传感器建模",
      "authors": [
        "Maximilian F. Theisen",
        "Gabrie M. H. Meesters",
        "Artur M. Schweidtmann"
      ],
      "abstract": "Data-driven soft sensors help in process operations by providing real-time\nestimates of otherwise hard- to-measure process quantities, e.g., viscosities\nor product concentrations. Currently, soft sensors need to be developed\nindividually per plant. Using transfer learning, machine learning-based soft\nsensors could be reused and fine-tuned across plants and applications. However,\ntransferring data-driven soft sensor models is in practice often not possible,\nbecause the fixed input structure of standard soft sensor models prohibits\ntransfer if, e.g., the sensor information is not identical in all plants. We\npropose a topology-aware graph neural network approach for transfer learning of\nsoft sensor models across multiple plants. In our method, plants are modeled as\ngraphs: Unit operations are nodes, streams are edges, and sensors are embedded\nas attributes. Our approach brings two advantages for transfer learning: First,\nwe not only include sensor data but also crucial information on the plant\ntopology. Second, the graph neural network algorithm is flexible with respect\nto its sensor inputs. This allows us to model data from different plants with\ndifferent sensor networks. We test the transfer learning capabilities of our\nmodeling approach on ammonia synthesis loops with different process topologies.\nWe build a soft sensor predicting the ammonia concentration in the product.\nAfter training on data from one process, we successfully transfer our soft\nsensor model to a previously unseen process with a different topology. Our\napproach promises to extend the data-driven soft sensors to cases to leverage\ndata from multiple plants.",
      "tldr_zh": "本研究针对数据驱动软传感器在不同工厂间的迁移难题，提出了一种基于过程拓扑的图神经网络(Graph Neural Networks)方法，以实现软传感器模型的复用和微调。方法将工厂建模为图结构，其中单元操作作为节点、流体流作为边、传感器数据作为属性，从而整合拓扑信息并灵活处理不同传感器输入。实验在氨合成回路的不同过程拓扑上进行，训练后成功将软传感器模型转移到未见过程，用于预测氨浓度。总体而言，该方法扩展了软传感器的应用潜力，允许利用多个工厂的数据提升实时估计性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06826v1",
      "published_date": "2025-02-05 12:10:22 UTC",
      "updated_date": "2025-02-05 12:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:38:10.932195"
    },
    {
      "arxiv_id": "2502.03104v1",
      "title": "Bellman Error Centering",
      "title_zh": "翻译失败",
      "authors": [
        "Xingguo Chen",
        "Yu Gong",
        "Shangdong Yang",
        "Wenhao Wang"
      ],
      "abstract": "This paper revisits the recently proposed reward centering algorithms\nincluding simple reward centering (SRC) and value-based reward centering (VRC),\nand points out that SRC is indeed the reward centering, while VRC is\nessentially Bellman error centering (BEC). Based on BEC, we provide the\ncentered fixpoint for tabular value functions, as well as the centered TD\nfixpoint for linear value function approximation. We design the on-policy CTD\nalgorithm and the off-policy CTDC algorithm, and prove the convergence of both\nalgorithms. Finally, we experimentally validate the stability of our proposed\nalgorithms. Bellman error centering facilitates the extension to various\nreinforcement learning algorithms.",
      "tldr_zh": "本论文重新审视了简单奖励中心化 (SRC) 和基于价值的奖励中心化 (VRC)，指出 SRC 是真正的奖励中心化，而 VRC 本质上是 Bellman Error Centering (BEC)。基于 BEC，该研究提供了表格价值函数的中心化固定点，以及线性价值函数逼近的中心化 TD 固定点。作者设计了 on-policy CTD 算法和 off-policy CTDC 算法，并证明了这些算法的收敛性。最后，通过实验验证了算法的稳定性，并强调 Bellman Error Centering 有助于扩展到各种强化学习算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03104v1",
      "published_date": "2025-02-05 12:03:03 UTC",
      "updated_date": "2025-02-05 12:03:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:38:22.627235"
    },
    {
      "arxiv_id": "2502.03505v1",
      "title": "Enhancing Free-hand 3D Photoacoustic and Ultrasound Reconstruction using Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "SiYeoul Lee",
        "SeonHo Kim",
        "Minkyung Seo",
        "SeongKyu Park",
        "Salehin Imrus",
        "Kambaluru Ashok",
        "DongEon Lee",
        "Chunsu Park",
        "SeonYeong Lee",
        "Jiye Kim",
        "Jae-Heung Yoo",
        "MinWoo Kim"
      ],
      "abstract": "This study introduces a motion-based learning network with a global-local\nself-attention module (MoGLo-Net) to enhance 3D reconstruction in handheld\nphotoacoustic and ultrasound (PAUS) imaging. Standard PAUS imaging is often\nlimited by a narrow field of view and the inability to effectively visualize\ncomplex 3D structures. The 3D freehand technique, which aligns sequential 2D\nimages for 3D reconstruction, faces significant challenges in accurate motion\nestimation without relying on external positional sensors. MoGLo-Net addresses\nthese limitations through an innovative adaptation of the self-attention\nmechanism, which effectively exploits the critical regions, such as\nfully-developed speckle area or high-echogenic tissue area within successive\nultrasound images to accurately estimate motion parameters. This facilitates\nthe extraction of intricate features from individual frames. Additionally, we\ndesigned a patch-wise correlation operation to generate a correlation volume\nthat is highly correlated with the scanning motion. A custom loss function was\nalso developed to ensure robust learning with minimized bias, leveraging the\ncharacteristics of the motion parameters. Experimental evaluations demonstrated\nthat MoGLo-Net surpasses current state-of-the-art methods in both quantitative\nand qualitative performance metrics. Furthermore, we expanded the application\nof 3D reconstruction technology beyond simple B-mode ultrasound volumes to\nincorporate Doppler ultrasound and photoacoustic imaging, enabling 3D\nvisualization of vasculature. The source code for this study is publicly\navailable at: https://github.com/guhong3648/US3D",
      "tldr_zh": "本文提出 MoGLo-Net，一种基于运动学习的深度学习网络，包含全局-局部 self-attention 模块，用于提升手持式光声和超声（PAUS）成像中的 3D 重建，解决视野狭窄和运动估计不准确等问题。该网络通过利用连续图像中的关键区域（如斑点或高回声组织）精确估计运动参数，并结合 patch-wise 相关操作和自定义损失函数，确保鲁棒性和最小偏差。实验结果表明，MoGLo-Net 在定量和定性指标上超越现有最先进方法，并扩展应用到多普勒超声和光声成像，实现血管的 3D 可视化。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03505v1",
      "published_date": "2025-02-05 11:59:23 UTC",
      "updated_date": "2025-02-05 11:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:38:35.171670"
    },
    {
      "arxiv_id": "2502.03504v1",
      "title": "Immersion for AI: Immersive Learning with Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Leonel Morgado"
      ],
      "abstract": "This work reflects upon what Immersion can mean from the perspective of an\nArtificial Intelligence (AI). Applying the lens of immersive learning theory,\nit seeks to understand whether this new perspective supports ways for AI\nparticipation in cognitive ecologies. By treating AI as a participant rather\nthan a tool, it explores what other participants (humans and other AIs) need to\nconsider in environments where AI can meaningfully engage and contribute to the\ncognitive ecology, and what the implications are for designing such learning\nenvironments. Drawing from the three conceptual dimensions of immersion -\nSystem, Narrative, and Agency - this work reinterprets AIs in immersive\nlearning contexts. It outlines practical implications for designing learning\nenvironments where AIs are surrounded by external digital services, can\ninterpret a narrative of origins, changes, and structural developments in data,\nand dynamically respond, making operational and tactical decisions that shape\nhuman-AI collaboration. Finally, this work suggests how these insights might\ninfluence the future of AI training, proposing that immersive learning theory\ncan inform the development of AIs capable of evolving beyond static models.\nThis paper paves the way for understanding AI as an immersive learner and\nparticipant in evolving human-AI cognitive ecosystems.",
      "tldr_zh": "这篇论文从AI视角探讨“沉浸(Immersive Learning)”的含义，应用沉浸学习理论分析AI如何作为参与者融入认知生态(Cognitive Ecologies)。通过System、Narrative和Agency三个维度，论文重新诠释AI在学习环境中的角色，并提出设计原则，使AI能够与外部数字服务互动、解读数据叙事，并进行动态决策以增强人类-AI协作。最终，论文建议这些见解可指导AI训练的未来发展，帮助AI超越静态模型，成为活跃的参与者。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.HC",
        "I.2.0; H.5.0; K.3.0"
      ],
      "primary_category": "q-bio.NC",
      "comment": "16 pages. To be published in the Proceedings of the 11th Annual\n  International Conference of the Immersive Learning Research Network\n  (iLRN2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.03504v1",
      "published_date": "2025-02-05 11:51:02 UTC",
      "updated_date": "2025-02-05 11:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:38:46.362849"
    },
    {
      "arxiv_id": "2502.03092v1",
      "title": "E-3SFC: Communication-Efficient Federated Learning with Double-way Features Synthesizing",
      "title_zh": "E-3SFC：通信高效的联邦学习与双向特征合成",
      "authors": [
        "Yuhao Zhou",
        "Yuxin Tian",
        "Mingjia Shi",
        "Yuanxi Li",
        "Yanan Sun",
        "Qing Ye",
        "Jiancheng Lv"
      ],
      "abstract": "The exponential growth in model sizes has significantly increased the\ncommunication burden in Federated Learning (FL). Existing methods to alleviate\nthis burden by transmitting compressed gradients often face high compression\nerrors, which slow down the model's convergence. To simultaneously achieve high\ncompression effectiveness and lower compression errors, we study the gradient\ncompression problem from a novel perspective. Specifically, we propose a\nsystematical algorithm termed Extended Single-Step Synthetic Features\nCompressing (E-3SFC), which consists of three sub-components, i.e., the\nSingle-Step Synthetic Features Compressor (3SFC), a double-way compression\nalgorithm, and a communication budget scheduler. First, we regard the process\nof gradient computation of a model as decompressing gradients from\ncorresponding inputs, while the inverse process is considered as compressing\nthe gradients. Based on this, we introduce a novel gradient compression method\ntermed 3SFC, which utilizes the model itself as a decompressor, leveraging\ntraining priors such as model weights and objective functions. 3SFC compresses\nraw gradients into tiny synthetic features in a single-step simulation,\nincorporating error feedback to minimize overall compression errors. To further\nreduce communication overhead, 3SFC is extended to E-3SFC, allowing double-way\ncompression and dynamic communication budget scheduling. Our theoretical\nanalysis under both strongly convex and non-convex conditions demonstrates that\n3SFC achieves linear and sub-linear convergence rates with aggregation noise.\nExtensive experiments across six datasets and six models reveal that 3SFC\noutperforms state-of-the-art methods by up to 13.4% while reducing\ncommunication costs by 111.6 times. These findings suggest that 3SFC can\nsignificantly enhance communication efficiency in FL without compromising model\nperformance.",
      "tldr_zh": "该论文针对联邦学习(Federated Learning, FL)中模型大小增长导致的通信负担问题，提出了一种高效算法E-3SFC，通过双向特征合成压缩来减少梯度传输错误。E-3SFC包括三个子组件：Single-Step Synthetic Features Compressor (3SFC)，它将梯度计算视为解压缩过程，利用模型权重和目标函数在单步中压缩梯度为合成特征，并通过错误反馈最小化压缩误差；此外，还整合双向压缩和动态通信预算调度以进一步降低开销。理论分析显示，3SFC在强凸和非凸条件下实现了线性或次线性收敛率，实验在六个数据集和六个模型上证明了其优越性，比现有方法提高高达13.4%，并将通信成本减少111.6倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by TNNLS. arXiv admin note: text overlap with\n  arXiv:2302.13562",
      "pdf_url": "http://arxiv.org/pdf/2502.03092v1",
      "published_date": "2025-02-05 11:31:21 UTC",
      "updated_date": "2025-02-05 11:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:38:58.790770"
    },
    {
      "arxiv_id": "2502.04371v1",
      "title": "PerPO: Perceptual Preference Optimization via Discriminative Rewarding",
      "title_zh": "翻译失败",
      "authors": [
        "Zining Zhu",
        "Liang Zhao",
        "Kangheng Lin",
        "Jinze Yang",
        "En Yu",
        "Chenglong Liu",
        "Haoran Wei",
        "Jianjian Sun",
        "Zheng Ge",
        "Xiangyu Zhang"
      ],
      "abstract": "This paper presents Perceptual Preference Optimization (PerPO), a perception\nalignment method aimed at addressing the visual discrimination challenges in\ngenerative pre-trained multimodal large language models (MLLMs). To align MLLMs\nwith human visual perception process, PerPO employs discriminative rewarding to\ngather diverse negative samples, followed by listwise preference optimization\nto rank them.By utilizing the reward as a quantitative margin for ranking, our\nmethod effectively bridges generative preference optimization and\ndiscriminative empirical risk minimization. PerPO significantly enhances MLLMs'\nvisual discrimination capabilities while maintaining their generative\nstrengths, mitigates image-unconditional reward hacking, and ensures consistent\nperformance across visual tasks. This work marks a crucial step towards more\nperceptually aligned and versatile MLLMs. We also hope that PerPO will\nencourage the community to rethink MLLM alignment strategies.",
      "tldr_zh": "本研究提出Perceptual Preference Optimization (PerPO)，一种通过discriminative rewarding的感知对齐方法，用于解决多模态大语言模型(MLLMs)在视觉鉴别方面的挑战。PerPO通过收集多样化负样本并应用listwise preference optimization进行排名，利用reward作为定量边际来桥接generative preference optimization和discriminative empirical risk minimization，从而提升MLLMs的视觉鉴别能力，同时保持其生成性能并缓解image-unconditional reward hacking。实验结果显示，PerPO在视觉任务中实现了性能的一致性，这标志着MLLMs更符合感知对齐的重要进展，并鼓励社区重新审视MLLMs的对齐策略。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04371v1",
      "published_date": "2025-02-05 11:28:11 UTC",
      "updated_date": "2025-02-05 11:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:39:09.692686"
    },
    {
      "arxiv_id": "2502.03086v1",
      "title": "Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing",
      "title_zh": "翻译失败",
      "authors": [
        "Salvatore Sinno",
        "Markus Bertl",
        "Arati Sahoo",
        "Bhavika Bhalgamiya",
        "Thomas Groß",
        "Nicholas Chancellor"
      ],
      "abstract": "This study explores the implementation of large Quantum Restricted Boltzmann\nMachines (QRBMs), a key advancement in Quantum Machine Learning (QML), as\ngenerative models on D-Wave's Pegasus quantum hardware to address dataset\nimbalance in Intrusion Detection Systems (IDS). By leveraging Pegasus's\nenhanced connectivity and computational capabilities, a QRBM with 120 visible\nand 120 hidden units was successfully embedded, surpassing the limitations of\ndefault embedding tools. The QRBM synthesized over 1.6 million attack samples,\nachieving a balanced dataset of over 4.2 million records. Comparative\nevaluations with traditional balancing methods, such as SMOTE and\nRandomOversampler, revealed that QRBMs produced higher-quality synthetic\nsamples, significantly improving detection rates, precision, recall, and F1\nscore across diverse classifiers. The study underscores the scalability and\nefficiency of QRBMs, completing balancing tasks in milliseconds. These findings\nhighlight the transformative potential of QML and QRBMs as next-generation\ntools in data preprocessing, offering robust solutions for complex\ncomputational challenges in modern information systems.",
      "tldr_zh": "本研究探讨了大型 Quantum Restricted Boltzmann Machines (QRBMs) 作为生成模型的实现，利用 D-Wave 的 Pegasus 量子硬件来解决 Intrusion Detection Systems (IDS) 中的数据集不平衡问题。研究成功嵌入了一个包含 120 个可见单元和 120 个隐藏单元的 QRBM，生成超过 1.6 百万攻击样本，从而创建了超过 4.2 百万的平衡数据集。相比传统方法如 SMOTE 和 RandomOversampler，QRBMs 产生的合成样本质量更高，显著提高了检测率、精确率、召回率和 F1 分数，并在毫秒内完成任务，突显了 Quantum Machine Learning (QML) 在数据预处理中的可扩展性和变革潜力。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "quant-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "accapted at IEEE International Conference on Next Generation\n  Information System Engineering",
      "pdf_url": "http://arxiv.org/pdf/2502.03086v1",
      "published_date": "2025-02-05 11:25:27 UTC",
      "updated_date": "2025-02-05 11:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:39:22.966172"
    },
    {
      "arxiv_id": "2502.03503v1",
      "title": "Two in context learning tasks with complex functions",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Naim",
        "Nicholas Asher"
      ],
      "abstract": "We examine two in context learning (ICL) tasks with mathematical functions in\nseveral train and test settings for transformer models. Our study generalizes\nwork on linear functions by showing that small transformers, even models with\nattention layers only, can approximate arbitrary polynomial functions and hence\ncontinuous functions under certain conditions. Our models also can approximate\npreviously unseen classes of polynomial functions, as well as the zeros of\ncomplex functions. Our models perform far better on this task than LLMs like\nGPT4 and involve complex reasoning when provided with suitable training data\nand methods. Our models also have important limitations; they fail to\ngeneralize outside of training distributions and so don't learn class forms of\nfunctions. We explain why this is so.",
      "tldr_zh": "本研究考察了两个 in-context learning (ICL) 任务，使用复杂数学函数在 transformer 模型的多种训练和测试设置中。结果显示，小型 transformer 模型（甚至仅包含注意力层）能够在特定条件下逼近任意多项式函数（polynomial functions）和连续函数（continuous functions），并能处理之前未见函数类别以及复杂函数的零点。相比于 GPT4 等 LLMs，这些模型在任务上表现出色并涉及复杂推理，但存在局限性：无法泛化到训练分布之外，且不会学习函数的类别形式，该研究也解释了这些限制的原因。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03503v1",
      "published_date": "2025-02-05 11:03:36 UTC",
      "updated_date": "2025-02-05 11:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:39:34.753724"
    },
    {
      "arxiv_id": "2502.03502v1",
      "title": "DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Janghyeok Han",
        "Gyujin Sim",
        "Geonung Kim",
        "Hyunseung Lee",
        "Kyuha Choi",
        "Youngseok Han",
        "Sunghyun Cho"
      ],
      "abstract": "Video super-resolution (VSR) aims to reconstruct a high-resolution (HR) video\nfrom a low-resolution (LR) counterpart. Achieving successful VSR requires\nproducing realistic HR details and ensuring both spatial and temporal\nconsistency. To restore realistic details, diffusion-based VSR approaches have\nrecently been proposed. However, the inherent randomness of diffusion, combined\nwith their tile-based approach, often leads to spatio-temporal inconsistencies.\nIn this paper, we propose DC-VSR, a novel VSR approach to produce spatially and\ntemporally consistent VSR results with realistic textures. To achieve spatial\nand temporal consistency, DC-VSR adopts a novel Spatial Attention Propagation\n(SAP) scheme and a Temporal Attention Propagation (TAP) scheme that propagate\ninformation across spatio-temporal tiles based on the self-attention mechanism.\nTo enhance high-frequency details, we also introduce Detail-Suppression\nSelf-Attention Guidance (DSSAG), a novel diffusion guidance scheme.\nComprehensive experiments demonstrate that DC-VSR achieves spatially and\ntemporally consistent, high-quality VSR results, outperforming previous\napproaches.",
      "tldr_zh": "该论文提出DC-VSR，一种基于视频扩散先验的视频超分辨率（Video Super-Resolution）方法，旨在从低分辨率视频重建空间和时间一致的高分辨率视频，同时解决现有扩散模型的随机性导致的不一致问题。\nDC-VSR引入Spatial Attention Propagation (SAP)和Temporal Attention Propagation (TAP)方案，通过自注意机制在时空平铺间传播信息，以确保一致性；此外，还采用Detail-Suppression Self-Attention Guidance (DSSAG)来增强高频细节。\n实验表明，DC-VSR在多个基准上优于先前方法，生成高质量且空间、时间一致的视频超分辨率结果。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "eess.IV",
      "comment": "Equal contributions from first two authors",
      "pdf_url": "http://arxiv.org/pdf/2502.03502v1",
      "published_date": "2025-02-05 10:15:00 UTC",
      "updated_date": "2025-02-05 10:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:39:47.551957"
    },
    {
      "arxiv_id": "2502.03047v2",
      "title": "Kozax: Flexible and Scalable Genetic Programming in JAX",
      "title_zh": "翻译失败",
      "authors": [
        "Sigur de Vries",
        "Sander W. Keemink",
        "Marcel A. J. van Gerven"
      ],
      "abstract": "Genetic programming is an optimization algorithm inspired by evolution which\nautomatically evolves the structure of interpretable computer programs. The\nfitness evaluation in genetic programming suffers from high computational\nrequirements, limiting the performance on difficult problems. Consequently,\nthere is no efficient genetic programming framework that is usable for a wide\nrange of tasks. To this end, we developed Kozax, a genetic programming\nframework that evolves symbolic expressions for arbitrary problems. We\nimplemented Kozax using JAX, a framework for high-performance and scalable\nmachine learning, which allows the fitness evaluation to scale efficiently to\nlarge populations or datasets on GPU. Furthermore, Kozax offers constant\noptimization, custom operator definition and simultaneous evolution of multiple\ntrees. We demonstrate successful applications of Kozax to discover equations of\nnatural laws, recover equations of hidden dynamic variables, evolve a control\npolicy and optimize an objective function. Overall, Kozax provides a general,\nfast, and scalable library to optimize white-box solutions in the realm of\nscientific computing.",
      "tldr_zh": "本论文介绍了 Kozax，一种灵活且可扩展的遗传编程(Genetic Programming)框架，使用 JAX 实现，以解决传统框架在适应度评估(Fitness evaluation)中计算需求高的难题。Kozax 通过 JAX 的高性能机制，使其在 GPU 上高效扩展大型种群或数据集，并支持常量优化、自定义操作符定义以及多树同时进化。实验结果显示，Kozax 成功应用于发现自然定律方程、恢复隐藏动态变量方程、进化控制策略和优化目标函数，提供了通用、快速且可扩展的库，用于科学计算中的白盒解决方案。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "6 figures, 3 tables, 1 algorithm, 13 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.03047v2",
      "published_date": "2025-02-05 10:12:17 UTC",
      "updated_date": "2025-04-15 13:55:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:40:00.900008"
    },
    {
      "arxiv_id": "2502.03038v2",
      "title": "The Cake that is Intelligence and Who Gets to Bake it: An AI Analogy and its Implications for Participation",
      "title_zh": "智能的蛋糕以及谁来烘焙它：一个 AI 比喻及其对参与",
      "authors": [
        "Martin Mundt",
        "Anaelia Ovalle",
        "Felix Friedrich",
        "A Pranav",
        "Subarnaduti Paul",
        "Manuel Brack",
        "Kristian Kersting",
        "William Agnew"
      ],
      "abstract": "In a widely popular analogy by Turing Award Laureate Yann LeCun, machine\nintelligence has been compared to cake - where unsupervised learning forms the\nbase, supervised learning adds the icing, and reinforcement learning is the\ncherry on top. We expand this 'cake that is intelligence' analogy from a simple\nstructural metaphor to the full life-cycle of AI systems, extending it to\nsourcing of ingredients (data), conception of recipes (instructions), the\nbaking process (training), and the tasting and selling of the cake (evaluation\nand distribution). Leveraging our re-conceptualization, we describe each step's\nentailed social ramifications and how they are bounded by statistical\nassumptions within machine learning. Whereas these technical foundations and\nsocial impacts are deeply intertwined, they are often studied in isolation,\ncreating barriers that restrict meaningful participation. Our\nre-conceptualization paves the way to bridge this gap by mapping where\ntechnical foundations interact with social outcomes, highlighting opportunities\nfor cross-disciplinary dialogue. Finally, we conclude with actionable\nrecommendations at each stage of the metaphorical AI cake's life-cycle,\nempowering prospective AI practitioners, users, and researchers, with increased\nawareness and ability to engage in broader AI discourse.",
      "tldr_zh": "这篇论文扩展了 Yann LeCun 的机器智能蛋糕比喻，将 unsupervised learning 作为基底、supervised learning 作为糖霜、reinforcement learning 作为顶部的樱桃，并延伸到 AI 系统的完整生命周期，包括数据来源（ingredients）、指令制定（recipes）、训练过程（baking）以及评估与分发（tasting and selling）。论文分析了每个阶段的技术基础（如统计假设）与社会影响的相互交织，强调这些因素常被孤立研究，导致参与障碍。最终，通过重新概念化，论文映射出技术与社会结果的交互点，并提供行动推荐，以促进跨学科对话并增强 AI 从业者、用户和研究者的参与能力。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03038v2",
      "published_date": "2025-02-05 09:51:19 UTC",
      "updated_date": "2025-02-06 11:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:40:13.060199"
    },
    {
      "arxiv_id": "2502.06824v1",
      "title": "Neural Network-based Vehicular Channel Estimation Performance: Effect of Noise in the Training Set",
      "title_zh": "基于神经网络的车辆通道估计性能：训练集中的噪声影响",
      "authors": [
        "Simbarashe Aldrin Ngorima",
        "Albert Helberg",
        "Marelie H. Davel"
      ],
      "abstract": "Vehicular communication systems face significant challenges due to high\nmobility and rapidly changing environments, which affect the channel over which\nthe signals travel. To address these challenges, neural network (NN)-based\nchannel estimation methods have been suggested. These methods are primarily\ntrained on high signal-to-noise ratio (SNR) with the assumption that training a\nNN in less noisy conditions can result in good generalisation. This study\nexamines the effectiveness of training NN-based channel estimators on mixed SNR\ndatasets compared to training solely on high SNR datasets, as seen in several\nrelated works. Estimators evaluated in this work include an architecture that\nuses convolutional layers and self-attention mechanisms; a method that employs\ntemporal convolutional networks and data pilot-aided estimation; two methods\nthat combine classical methods with multilayer perceptrons; and the current\nstate-of-the-art model that combines Long-Short-Term Memory networks with data\npilot-aided and temporal averaging methods as post processing. Our results\nindicate that using only high SNR data for training is not always optimal, and\nthe SNR range in the training dataset should be treated as a hyperparameter\nthat can be adjusted for better performance. This is illustrated by the better\nperformance of some models in low SNR conditions when trained on the mixed SNR\ndataset, as opposed to when trained exclusively on high SNR data.",
      "tldr_zh": "这篇论文探讨了基于 Neural Network (NN) 的车辆信道估计性能，重点分析训练集中的 Signal-to-Noise Ratio (SNR) 噪声对模型泛化能力的影响。研究比较了多种 NN 架构（如使用卷积层和自注意力机制的模型、时间卷积网络，以及结合 LSTM 的状态-of-the-art 方法）在高 SNR 数据集和混合 SNR 数据集上的训练效果。结果显示，仅使用高 SNR 数据训练并非总是最优，将 SNR 范围视为超参数进行调整，能显著提升模型在低 SNR 环境下的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "Primary"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 Figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06824v1",
      "published_date": "2025-02-05 09:29:01 UTC",
      "updated_date": "2025-02-05 09:29:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:40:22.936837"
    },
    {
      "arxiv_id": "2502.03500v1",
      "title": "Efficient Image Restoration via Latent Consistency Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Elad Cohen",
        "Idan Achituve",
        "Idit Diamant",
        "Arnon Netzer",
        "Hai Victor Habi"
      ],
      "abstract": "Recent advances in generative image restoration (IR) have demonstrated\nimpressive results. However, these methods are hindered by their substantial\nsize and computational demands, rendering them unsuitable for deployment on\nedge devices. This work introduces ELIR, an Efficient Latent Image Restoration\nmethod. ELIR operates in latent space by first predicting the latent\nrepresentation of the minimum mean square error (MMSE) estimator and then\ntransporting this estimate to high-quality images using a latent consistency\nflow-based model. Consequently, ELIR is more than 4x faster compared to the\nstate-of-the-art diffusion and flow-based approaches. Moreover, ELIR is also\nmore than 4x smaller, making it well-suited for deployment on\nresource-constrained edge devices. Comprehensive evaluations of various image\nrestoration tasks show that ELIR achieves competitive results, effectively\nbalancing distortion and perceptual quality metrics while offering improved\nefficiency in terms of memory and computation.",
      "tldr_zh": "本研究提出了一种高效图像恢复方法 ELIR，通过在潜在空间中预测最小均方误差 (MMSE) 估计器的潜在表示，并使用 latent consistency flow-based model 将其传输到高质量图像，从而实现图像恢复。相比 state-of-the-art 的 diffusion 和 flow-based approaches，ELIR 的速度和模型大小均提高了 4 倍以上，使其特别适合资源受限的边缘设备部署。在各种图像恢复任务的全面评估中，ELIR 取得了竞争性的性能，实现了 distortion 和 perceptual quality 指标的良好平衡。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "eess.IV",
      "comment": "21 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.03500v1",
      "published_date": "2025-02-05 09:24:49 UTC",
      "updated_date": "2025-02-05 09:24:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:40:34.281858"
    },
    {
      "arxiv_id": "2502.03499v1",
      "title": "Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning",
      "title_zh": "Omni-DNA：用于跨模态和多任务学习的统一基因组基础模型",
      "authors": [
        "Zehui Li",
        "Vallijah Subasri",
        "Yifei Shen",
        "Dongsheng Li",
        "Yiren Zhao",
        "Guy-Bart Stan",
        "Caihua Shan"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate remarkable generalizability across\ndiverse tasks, yet genomic foundation models (GFMs) still require separate\nfinetuning for each downstream application, creating significant overhead as\nmodel sizes grow. Moreover, existing GFMs are constrained by rigid output\nformats, limiting their applicability to various genomic tasks. In this work,\nwe revisit the transformer-based auto-regressive models and introduce Omni-DNA,\na family of cross-modal multi-task models ranging from 20 million to 1 billion\nparameters. Our approach consists of two stages: (i) pretraining on DNA\nsequences with next token prediction objective, and (ii) expanding the\nmulti-modal task-specific tokens and finetuning for multiple downstream tasks\nsimultaneously. When evaluated on the Nucleotide Transformer and GB benchmarks,\nOmni-DNA achieves state-of-the-art performance on 18 out of 26 tasks. Through\nmulti-task finetuning, Omni-DNA addresses 10 acetylation and methylation tasks\nat once, surpassing models trained on each task individually. Finally, we\ndesign two complex genomic tasks, DNA2Function and Needle-in-DNA, which map DNA\nsequences to textual functional descriptions and images, respectively,\nindicating Omni-DNA's cross-modal capabilities to broaden the scope of genomic\napplications. All the models are available through\nhttps://huggingface.co/collections/zehui127",
      "tldr_zh": "该研究提出Omni-DNA，一种统一的基因组基础模型（GFMs），旨在解决现有模型需单独微调下游任务的开销问题，并支持跨模态和多任务学习。该模型采用两阶段方法：首先在DNA序列上进行预训练，使用下一个标记预测目标；其次扩展多模态任务特定标记，并同时微调多个任务。在Nucleotide Transformer和GB基准测试中，Omni-DNA在26个任务中领先18个，并能同时处理10个乙酰化和甲基化任务，优于独立训练模型；此外，它展示了跨模态能力，如通过DNA2Function和Needle-in-DNA任务将DNA序列映射到文本或图像描述。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03499v1",
      "published_date": "2025-02-05 09:20:52 UTC",
      "updated_date": "2025-02-05 09:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:40:46.742930"
    },
    {
      "arxiv_id": "2502.03014v1",
      "title": "xai_evals : A Framework for Evaluating Post-Hoc Local Explanation Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Pratinav Seth",
        "Yashwardhan Rathore",
        "Neeraj Kumar Singh",
        "Chintan Chitroda",
        "Vinay Kumar Sankarapu"
      ],
      "abstract": "The growing complexity of machine learning and deep learning models has led\nto an increased reliance on opaque \"black box\" systems, making it difficult to\nunderstand the rationale behind predictions. This lack of transparency is\nparticularly challenging in high-stakes applications where interpretability is\nas important as accuracy. Post-hoc explanation methods are commonly used to\ninterpret these models, but they are seldom rigorously evaluated, raising\nconcerns about their reliability. The Python package xai_evals addresses this\nby providing a comprehensive framework for generating, benchmarking, and\nevaluating explanation methods across both tabular and image data modalities.\nIt integrates popular techniques like SHAP, LIME, Grad-CAM, Integrated\nGradients (IG), and Backtrace, while supporting evaluation metrics such as\nfaithfulness, sensitivity, and robustness. xai_evals enhances the\ninterpretability of machine learning models, fostering transparency and trust\nin AI systems. The library is open-sourced at\nhttps://pypi.org/project/xai-evals/ .",
      "tldr_zh": "该论文介绍了 xai_evals，一个用于评估事后局部解释方法（post-hoc local explanation methods）的全面框架，旨在解决机器学习模型的“黑箱”问题，提高高风险应用中的透明度。该框架支持表格和图像数据，通过整合 SHAP、LIME、Grad-CAM、Integrated Gradients (IG) 和 Backtrace 等流行技术，并使用 faithfulness、sensitivity 和 robustness 等指标进行基准测试和评估。xai_evals 增强了机器学习模型的解释性，促进 AI 系统的可信度和信任，并已开源在 https://pypi.org/project/xai-evals/。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03014v1",
      "published_date": "2025-02-05 09:17:48 UTC",
      "updated_date": "2025-02-05 09:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:41:00.122058"
    },
    {
      "arxiv_id": "2502.10422v1",
      "title": "DA-LIF: Dual Adaptive Leaky Integrate-and-Fire Model for Deep Spiking Neural Networks",
      "title_zh": "DA-LIF：双自适应漏集成放电模型用于深度脉冲神经网络",
      "authors": [
        "Tianqing Zhang",
        "Kairong Yu",
        "Jian Zhang",
        "Hongwei Wang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are valued for their ability to process\nspatio-temporal information efficiently, offering biological plausibility, low\nenergy consumption, and compatibility with neuromorphic hardware. However, the\ncommonly used Leaky Integrate-and-Fire (LIF) model overlooks neuron\nheterogeneity and independently processes spatial and temporal information,\nlimiting the expressive power of SNNs. In this paper, we propose the Dual\nAdaptive Leaky Integrate-and-Fire (DA-LIF) model, which introduces spatial and\ntemporal tuning with independently learnable decays. Evaluations on both static\n(CIFAR10/100, ImageNet) and neuromorphic datasets (CIFAR10-DVS, DVS128 Gesture)\ndemonstrate superior accuracy with fewer timesteps compared to state-of-the-art\nmethods. Importantly, DA-LIF achieves these improvements with minimal\nadditional parameters, maintaining low energy consumption. Extensive ablation\nstudies further highlight the robustness and effectiveness of the DA-LIF model.",
      "tldr_zh": "本研究提出了一种Dual Adaptive Leaky Integrate-and-Fire (DA-LIF)模型，用于Deep Spiking Neural Networks (SNNs)，通过引入空间和时间调谐以及独立可学习的衰减，来解决传统Leaky Integrate-and-Fire (LIF)模型忽略神经元异质性和独立处理时空信息的局限性。实验在静态数据集（如CIFAR10/100和ImageNet）以及神经形态数据集（如CIFAR10-DVS和DVS128 Gesture）上表明，DA-LIF在更少的时步内实现了比现有方法更高的准确率，同时仅增加微小参数并保持低能耗。消融研究进一步验证了DA-LIF的鲁棒性和有效性，为高效的SNNs应用提供了新途径。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted by ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10422v1",
      "published_date": "2025-02-05 09:02:07 UTC",
      "updated_date": "2025-02-05 09:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:41:11.217646"
    },
    {
      "arxiv_id": "2502.03004v1",
      "title": "MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation",
      "title_zh": "MedBioLM：利用微调的大型语言模型和检索增强生成优化医学与生物学问答",
      "authors": [
        "Seonok Kim"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nnatural language processing tasks. However, their application to specialized\ndomains such as medicine and biology requires further optimization to ensure\nfactual accuracy, reliability, and contextual depth. We introduce MedBioLM, a\ndomain-adapted biomedical question-answering model designed to enhance both\nshort-form and long-form queries. By integrating fine-tuning and\nretrieval-augmented generation (RAG), MedBioLM dynamically incorporates\ndomain-specific knowledge, improving reasoning abilities and factual accuracy.\nTo evaluate its effectiveness, we fine-tuned the model on diverse biomedical QA\ndatasets, covering structured multiple-choice assessments and complex clinical\nreasoning tasks. Fine-tuning significantly improves accuracy on benchmark\ndatasets, while RAG enhances factual consistency. These results highlight the\npotential of domain-optimized LLMs in advancing biomedical research, medical\neducation, and clinical decision support.",
      "tldr_zh": "我们介绍了 MedBioLM，这是一个针对医学和生物学问答的优化模型，通过 fine-tuning 大型语言模型 (LLMs) 和检索增强生成 (RAG) 动态整合领域特定知识，从而提升推理能力和事实准确性。该模型在多样化的生物医学 QA 数据集上进行微调，包括多选题和复杂临床推理任务，结果显示准确性显著提高，且 RAG 增强了事实一致性。总体而言，MedBioLM 展示了领域优化 LLMs 在生物医学研究、医疗教育和临床决策支持中的巨大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03004v1",
      "published_date": "2025-02-05 08:58:35 UTC",
      "updated_date": "2025-02-05 08:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:41:22.268932"
    },
    {
      "arxiv_id": "2502.02988v1",
      "title": "Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons",
      "title_zh": "翻译失败",
      "authors": [
        "Renjun Hu",
        "Yi Cheng",
        "Libin Meng",
        "Jiaxin Xia",
        "Yi Zong",
        "Xing Shi",
        "Wei Lin"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has opened new\npossibilities for their adoption as evaluative judges. This paper introduces\nThemis, a fine-tuned LLM judge that delivers sophisticated context-aware\nevaluations. We provide a comprehensive overview of the development pipeline\nfor Themis, highlighting its scenario-dependent evaluation prompts and two\nnovel methods for controlled instruction generation. These designs enable\nThemis to effectively distill evaluative skills from teacher models, while\nretaining flexibility for continuous development. We introduce two\nhuman-labeled benchmarks for meta-evaluation, demonstrating that Themis can\nachieve high alignment with human preferences in an economical manner.\nAdditionally, we explore insights into the LLM-as-a-judge paradigm, revealing\nnuances in performance and the varied effects of reference answers. Notably, we\nobserve that pure knowledge distillation from strong LLMs, though common, does\nnot guarantee performance improvement through scaling. We propose a mitigation\nstrategy based on instruction-following difficulty. Furthermore, we provide\npractical guidelines covering data balancing, prompt customization,\nmulti-objective training, and metric aggregation. We aim for our method and\nfindings, along with the fine-tuning data, benchmarks, and model checkpoints,\nto support future research and development in this area.",
      "tldr_zh": "这篇论文介绍了 Themis，一个微调的 LLM 评判模型，用于提供复杂的上下文感知评估，旨在提升大型语言模型在评估任务中的性能。研究者详细阐述了 Themis 的开发管道，包括场景依赖的评估提示和两种新型控制指令生成方法，这些设计有助于从教师模型中提炼评估技能，同时保持灵活性。通过两个人类标记的基准，Themis 展示了高的人类偏好一致性，并揭示了 LLM-as-a-judge 范式的洞见，如单纯知识蒸馏不保证性能提升，并提出基于指令遵循难度的缓解策略。最终，论文提供了实用指南（如数据平衡和提示自定义），并分享微调数据、基准和模型检查点，以支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted at WWW'25 (Industrial Track), extended version",
      "pdf_url": "http://arxiv.org/pdf/2502.02988v1",
      "published_date": "2025-02-05 08:35:55 UTC",
      "updated_date": "2025-02-05 08:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:41:35.600957"
    },
    {
      "arxiv_id": "2502.02982v2",
      "title": "MobileA3gent: Training Mobile GUI Agents Using Decentralized Self-Sourced Data from Diverse Users",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Wang",
        "Mengying Yuan",
        "Zijie Yu",
        "Guangyi Liu",
        "Rui Ye",
        "Tian Jin",
        "Siheng Chen",
        "Yanfeng Wang"
      ],
      "abstract": "The advancement of mobile GUI agents has opened new opportunities for\nautomating tasks on mobile devices. Training these agents requires large-scale\nhigh-quality data, which is prohibitively expensive when relying on human\nlabor. Given the vast population of global mobile phone users, if automated\ndata collection from them becomes feasible, the resulting data volume and the\nsubsequently trained mobile agents could reach unprecedented levels.\nNevertheless, two major challenges arise: (1) extracting user instructions\nwithout human intervention and (2) utilizing distributed user data while\npreserving privacy. To tackle these challenges, we propose MobileA3gent, a\ncollaborative framework that trains mobile GUI Agents using decentralized\nself-sourced data from diverse users. The framework comprises two components,\neach targeting a specific challenge: (1) Auto-Annotation, which enables the\nautomatic collection of high-quality datasets during users' routine phone usage\nwith minimal cost. (2) FedVLM-A, which enhances federated VLM training under\nnon-IID distributions by incorporating adapted global aggregation based on both\nepisode-level and step-level variability. Extensive experiments prove that\nMobileA3gent achieves superior performance over traditional approaches at only\n1% of the cost, highlighting its potential for real-world applications",
      "tldr_zh": "这篇论文提出了 MobileA3gent 框架，用于利用来自多样化用户的分布式自源数据训练移动 GUI Agents，从而降低数据收集成本。框架包括 Auto-Annotation 组件，用于在用户日常使用手机时自动提取高质量数据集，以及 FedVLM-A 组件，通过基于 episode-level 和 step-level 变异的适应性全局聚合处理 non-IID 分布的联邦学习。实验结果表明，MobileA3gent 在仅 1% 的成本下，性能显著优于传统方法，具有广阔的实际应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02982v2",
      "published_date": "2025-02-05 08:26:17 UTC",
      "updated_date": "2025-05-20 07:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:41:46.328652"
    },
    {
      "arxiv_id": "2502.07803v1",
      "title": "Reasoning-as-Logic-Units: Scaling Test-Time Reasoning in Large Language Models Through Logic Unit Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Cheryl Li",
        "Tianyuan Xu",
        "Yiwen Guo"
      ],
      "abstract": "Chain-of-Thought (CoT) prompting has shown promise in enhancing the reasoning\ncapabilities of large language models (LLMs) by generating natural language\n(NL) rationales that lead to the final answer. However, it struggles with\nnumerical computation, which has somehow led to the development of\nprogram-aided techniques. Despite their potential, a persistent challenge\nremains: inconsistencies between LLM-reported reasoning steps and the logic in\ngenerated programs, which we term ``reasoning hallucinations.\" This stems from\nthe inherent ambiguities of NL and the statistical nature of LLMs, which often\nlack rigorous logical coherence. To address this challenge, we propose a novel\ntest-time scaling framework, Reasoning-as-Logic-Units (RaLU), which constructs\na more reliable reasoning path by aligning logical units between the generated\nprogram and their corresponding NL descriptions. By decomposing the initially\ngenerated program into discrete units using static analysis, RaLU engages in an\niterative dialogue with the LLM to judge, refine, and explain each unit. A\nrewind-and-correct mechanism ensures alignment between code statements and task\nrequirements in each unit, ultimately forming a cohesive reasoning path under\nthe program's logic, from which the model reaches a final solution. Our\nexperiments demonstrate that RaLU significantly outperforms existing baselines\nin mathematical reasoning (GSM8K, MATH) and algorithmic reasoning (HumanEval+,\nMBPP+), underscoring its potential to advance LLM reasoning and programming by\noffering enhanced accuracy and interpretability.",
      "tldr_zh": "该论文针对大语言模型 (LLMs) 在 Chain-of-Thought (CoT) 提示中的推理幻觉问题，提出了一种新型测试时扩展框架：Reasoning-as-Logic-Units (RaLU)。RaLU 通过静态分析将生成的程序分解成离散逻辑单元，并通过迭代对话与 LLM 互动，包括判断、精炼和解释每个单元，以及 rewind-and-correct 机制，确保代码语句与任务需求一致，从而构建可靠的推理路径。实验结果显示，RaLU 在数学推理基准 (GSM8K, MATH) 和算法推理基准 (HumanEval+, MBPP+) 上显著优于现有基线，提升了推理的准确性和可解释性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07803v1",
      "published_date": "2025-02-05 08:23:18 UTC",
      "updated_date": "2025-02-05 08:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:41:59.641408"
    },
    {
      "arxiv_id": "2502.02975v3",
      "title": "TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics",
      "title_zh": "TGB-Seq 基准：用复杂的序列动态",
      "authors": [
        "Lu Yi",
        "Jie Peng",
        "Yanping Zheng",
        "Fengran Mo",
        "Zhewei Wei",
        "Yuhang Ye",
        "Yue Zixuan",
        "Zengfeng Huang"
      ],
      "abstract": "Future link prediction is a fundamental challenge in various real-world\ndynamic systems. To address this, numerous temporal graph neural networks\n(temporal GNNs) and benchmark datasets have been developed. However, these\ndatasets often feature excessive repeated edges and lack complex sequential\ndynamics, a key characteristic inherent in many real-world applications such as\nrecommender systems and ``Who-To-Follow'' on social networks. This oversight\nhas led existing methods to inadvertently downplay the importance of learning\nsequential dynamics, focusing primarily on predicting repeated edges.\n  In this study, we demonstrate that existing methods, such as GraphMixer and\nDyGFormer, are inherently incapable of learning simple sequential dynamics,\nsuch as ``a user who has followed OpenAI and Anthropic is more likely to follow\nAI at Meta next.'' Motivated by this issue, we introduce the Temporal Graph\nBenchmark with Sequential Dynamics (TGB-Seq), a new benchmark carefully curated\nto minimize repeated edges, challenging models to learn sequential dynamics and\ngeneralize to unseen edges. TGB-Seq comprises large real-world datasets\nspanning diverse domains, including e-commerce interactions, movie ratings,\nbusiness reviews, social networks, citation networks and web link networks.\nBenchmarking experiments reveal that current methods usually suffer significant\nperformance degradation and incur substantial training costs on TGB-Seq, posing\nnew challenges and opportunities for future research. TGB-Seq datasets,\nleaderboards, and example codes are available at https://tgb-seq.github.io/.",
      "tldr_zh": "该研究指出了现有时间图神经网络（temporal GNNs）在未来链接预测任务中存在的不足，即基准数据集往往包含过多重复边，而忽略了复杂序列动态，如社交网络中的用户跟随模式，导致模型无法有效学习这些动态。  \n为此，论文引入了TGB-Seq基准，这是一个精心设计的测试集，减少重复边并强调序列动态学习，涵盖电商互动、电影评分、社交网络、引用网络和网页链接等真实领域数据集。  \n实验结果显示，现有方法如GraphMixer和DyGFormer在TGB-Seq上性能显著下降，并面临高训练成本，这为未来temporal GNNs研究提供了新挑战；相关数据集、排行榜和代码可访问https://tgb-seq.github.io/。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "published at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02975v3",
      "published_date": "2025-02-05 08:20:19 UTC",
      "updated_date": "2025-03-15 11:05:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:42:11.375939"
    },
    {
      "arxiv_id": "2502.02966v1",
      "title": "FACTER: Fairness-Aware Conformal Thresholding and Prompt Engineering for Enabling Fair LLM-Based Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Arya Fayyazi",
        "Mehdi Kamal",
        "Massoud Pedram"
      ],
      "abstract": "We propose FACTER, a fairness-aware framework for LLM-based recommendation\nsystems that integrates conformal prediction with dynamic prompt engineering.\nBy introducing an adaptive semantic variance threshold and a\nviolation-triggered mechanism, FACTER automatically tightens fairness\nconstraints whenever biased patterns emerge. We further develop an adversarial\nprompt generator that leverages historical violations to reduce repeated\ndemographic biases without retraining the LLM. Empirical results on MovieLens\nand Amazon show that FACTER substantially reduces fairness violations (up to\n95.5%) while maintaining strong recommendation accuracy, revealing semantic\nvariance as a potent proxy of bias.",
      "tldr_zh": "我们提出了 FACTER，一种关注公平性的框架，用于 LLM 基于的推荐系统，通过整合 conformal prediction 和动态 prompt engineering 来处理偏差问题。该框架引入自适应语义方差阈值以及违反触发机制，能自动收紧公平约束，并利用对抗性 prompt 生成器基于历史违反减少人口统计偏差，而无需重新训练 LLM。在 MovieLens 和 Amazon 数据集上的实验显示，FACTOR 将公平违反减少高达 95.5%，同时保持推荐准确性，并揭示语义方差作为偏差的强大代理。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02966v1",
      "published_date": "2025-02-05 08:07:04 UTC",
      "updated_date": "2025-02-05 08:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:42:22.748459"
    },
    {
      "arxiv_id": "2502.02963v1",
      "title": "(Neural-Symbolic) Machine Learning for Inconsistency Measurement",
      "title_zh": "翻译失败",
      "authors": [
        "Sven Weinzierl",
        "Carl Cora"
      ],
      "abstract": "We present machine-learning-based approaches for determining the\n\\emph{degree} of inconsistency -- which is a numerical value -- for\npropositional logic knowledge bases. Specifically, we present regression- and\nneural-based models that learn to predict the values that the inconsistency\nmeasures $\\incmi$ and $\\incat$ would assign to propositional logic knowledge\nbases. Our main motivation is that computing these values conventionally can be\nhard complexity-wise. As an important addition, we use specific postulates,\nthat is, properties, of the underlying inconsistency measures to infer symbolic\nrules, which we combine with the learning-based models in the form of\nconstraints. We perform various experiments and show that a) predicting the\ndegree values is feasible in many situations, and b) including the symbolic\nconstraints deduced from the rationality postulates increases the prediction\nquality.",
      "tldr_zh": "该论文提出使用机器学习方法，包括回归和 neural-based models，来预测命题逻辑知识库的不一致度量 $\\incmi$ 和 $\\incat$ 的数值，从而解决传统计算的复杂度问题。研究者利用不一致度量的理性 postulates 推导出符号规则，并将这些规则作为约束与学习模型结合，以提升预测准确性。实验结果显示，这种方法在多种情况下可行，且加入符号约束显著提高了预测质量。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02963v1",
      "published_date": "2025-02-05 08:00:30 UTC",
      "updated_date": "2025-02-05 08:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:42:35.064525"
    },
    {
      "arxiv_id": "2502.02955v1",
      "title": "ReachAgent: Enhancing Mobile Agent via Page Reaching and Operation",
      "title_zh": "ReachAgent：通过页面到达和操作增强移动代理",
      "authors": [
        "Qinzhuo Wu",
        "Wei Liu",
        "Jian Luan",
        "Bin Wang"
      ],
      "abstract": "Recently, mobile AI agents have gained increasing attention. Given a task,\nmobile AI agents can interact with mobile devices in multiple steps and finally\nform a GUI flow that solves the task. However, existing agents tend to focus on\nmost task-relevant elements at each step, leading to local optimal solutions\nand ignoring the overall GUI flow. To address this issue, we constructed a\ntraining dataset called MobileReach, which breaks the task into page reaching\nand operation subtasks. Furthermore, we propose ReachAgent, a two-stage\nframework that focuses on improving its task-completion abilities. It utilizes\nthe page reaching and page operation subtasks, along with reward-based\npreference GUI flows, to further enhance the agent. Experimental results show\nthat ReachAgent significantly improves the IoU Acc and Text Acc by 7.12% and\n7.69% on the step-level and 4.72% and 4.63% on the task-level compared to the\nSOTA agent. Our data and code will be released upon acceptance.",
      "tldr_zh": "该研究针对移动 AI 代理在任务执行中存在的局部最优问题，构建了 MobileReach 数据集，将任务分解为页面到达（page reaching）和操作（operation）子任务。ReachAgent 提出了一种两阶段框架，通过整合这些子任务和基于奖励的偏好 GUI 流程，显著提升代理的任务完成能力。实验结果显示，与 SOTA 代理相比，ReachAgent 在步级 IoU Acc 和 Text Acc 分别提高了 7.12% 和 7.69%，在任务级提高了 4.72% 和 4.63%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02955v1",
      "published_date": "2025-02-05 07:35:23 UTC",
      "updated_date": "2025-02-05 07:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:42:46.128724"
    },
    {
      "arxiv_id": "2502.02951v1",
      "title": "VQA-Levels: A Hierarchical Approach for Classifying Questions in VQA",
      "title_zh": "VQA-Levels：一种用于 VQA 中问题分类的分层方法",
      "authors": [
        "Madhuri Latha Madaka",
        "Chakravarthy Bhagvati"
      ],
      "abstract": "Designing datasets for Visual Question Answering (VQA) is a difficult and\ncomplex task that requires NLP for parsing and computer vision for analysing\nthe relevant aspects of the image for answering the question asked. Several\nbenchmark datasets have been developed by researchers but there are many issues\nwith using them for methodical performance tests. This paper proposes a new\nbenchmark dataset -- a pilot version called VQA-Levels is ready now -- for\ntesting VQA systems systematically and assisting researchers in advancing the\nfield. The questions are classified into seven levels ranging from direct\nanswers based on low-level image features (without needing even a classifier)\nto those requiring high-level abstraction of the entire image content. The\nquestions in the dataset exhibit one or many of ten properties. Each is\ncategorised into a specific level from 1 to 7. Levels 1 - 3 are directly on the\nvisual content while the remaining levels require extra knowledge about the\nobjects in the image. Each question generally has a unique one or two-word\nanswer. The questions are 'natural' in the sense that a human is likely to ask\nsuch a question when seeing the images. An example question at Level 1 is,\n``What is the shape of the red colored region in the image?\" while at Level 7,\nit is, ``Why is the man cutting the paper?\". Initial testing of the proposed\ndataset on some of the existing VQA systems reveals that their success is high\non Level 1 (low level features) and Level 2 (object classification) questions,\nleast on Level 3 (scene text) followed by Level 6 (extrapolation) and Level 7\n(whole scene analysis) questions. The work in this paper will go a long way to\nsystematically analyze VQA systems.",
      "tldr_zh": "本论文提出一个新的基准数据集VQA-Levels，用于系统测试Visual Question Answering (VQA)系统，并帮助研究者推进该领域。数据集将问题分类为7个级别，从基于低级图像特征的直接答案（Level 1）到需要高水平抽象和额外知识的复杂问题（Level 7），问题还体现出多种属性如对象分类和场景分析。每个问题设计为自然且简短，示例包括Level 1的“What is the shape of the red colored region in the image?”和Level 7的“Why is the man cutting the paper?”。初步测试显示，现有的VQA系统在Level 1（低级特征）和Level 2（对象分类）上表现良好，但在Level 3（场景文本）、Level 6（外推）和Level 7（整体场景分析）上成功率较低，从而为系统分析VQA系统的性能提供了重要工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02951v1",
      "published_date": "2025-02-05 07:28:36 UTC",
      "updated_date": "2025-02-05 07:28:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:42:58.675941"
    },
    {
      "arxiv_id": "2502.02945v1",
      "title": "LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction",
      "title_zh": "LLM-KT：使用即插即用指令对齐大型语言模型与知识追踪",
      "authors": [
        "Ziwei Wang",
        "Jie Zhou",
        "Qin Chen",
        "Min Zhang",
        "Bo Jiang",
        "Aimin Zhou",
        "Qinchun Bai",
        "Liang He"
      ],
      "abstract": "The knowledge tracing (KT) problem is an extremely important topic in\npersonalized education, which aims to predict whether students can correctly\nanswer the next question based on their past question-answer records. Prior\nwork on this task mainly focused on learning the sequence of behaviors based on\nthe IDs or textual information. However, these studies usually fail to capture\nstudents' sufficient behavioral patterns without reasoning with rich world\nknowledge about questions. In this paper, we propose a large language models\n(LLMs)-based framework for KT, named \\texttt{\\textbf{LLM-KT}}, to integrate the\nstrengths of LLMs and traditional sequence interaction models. For task-level\nalignment, we design Plug-and-Play instruction to align LLMs with KT,\nleveraging LLMs' rich knowledge and powerful reasoning capacity. For\nmodality-level alignment, we design the plug-in context and sequence to\nintegrate multiple modalities learned by traditional methods. To capture the\nlong context of history records, we present a plug-in context to flexibly\ninsert the compressed context embedding into LLMs using question-specific and\nconcept-specific tokens. Furthermore, we introduce a plug-in sequence to\nenhance LLMs with sequence interaction behavior representation learned by\ntraditional sequence models using a sequence adapter. Extensive experiments\nshow that \\texttt{\\textbf{LLM-KT}} obtains state-of-the-art performance on four\ntypical datasets by comparing it with approximately 20 strong baselines.",
      "tldr_zh": "本文提出LLM-KT框架，将Large Language Models (LLMs)与Knowledge Tracing (KT)任务对齐，旨在通过LLMs的丰富知识和推理能力更好地预测学生的答题表现。框架包括任务级对齐的Plug-and-Play Instruction，以及模态级对齐的plug-in context和plug-in sequence，分别用于处理历史记录的长上下文和整合传统序列模型的行为表示。实验结果显示，LLM-KT在四个典型数据集上超越了约20个强基线，取得了最先进性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02945v1",
      "published_date": "2025-02-05 07:21:49 UTC",
      "updated_date": "2025-02-05 07:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:43:10.871747"
    },
    {
      "arxiv_id": "2502.04366v1",
      "title": "Contrastive Token-level Explanations for Graph-based Rumour Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Wai Kit Chin",
        "Roy Ka-Wei Lee"
      ],
      "abstract": "The widespread use of social media has accelerated the dissemination of\ninformation, but it has also facilitated the spread of harmful rumours, which\ncan disrupt economies, influence political outcomes, and exacerbate public\nhealth crises, such as the COVID-19 pandemic. While Graph Neural Network\n(GNN)-based approaches have shown significant promise in automated rumour\ndetection, they often lack transparency, making their predictions difficult to\ninterpret. Existing graph explainability techniques fall short in addressing\nthe unique challenges posed by the dependencies among feature dimensions in\nhigh-dimensional text embeddings used in GNN-based models. In this paper, we\nintroduce Contrastive Token Layerwise Relevance Propagation (CT-LRP), a novel\nframework designed to enhance the explainability of GNN-based rumour detection.\nCT-LRP extends current graph explainability methods by providing token-level\nexplanations that offer greater granularity and interpretability. We evaluate\nthe effectiveness of CT-LRP across multiple GNN models trained on three\npublicly available rumour detection datasets, demonstrating that it\nconsistently produces high-fidelity, meaningful explanations, paving the way\nfor more robust and trustworthy rumour detection systems.",
      "tldr_zh": "这篇论文针对社交媒体谣言传播的危害（如经济、政治和公共健康影响），提出Contrastive Token Layerwise Relevance Propagation (CT-LRP)框架，以提升GNN (Graph Neural Network)-based谣言检测的可解释性。CT-LRP扩展现有图解释方法，提供更细粒度的token-level解释，解决高维文本嵌入中特征维度依赖性的挑战。通过在多个GNN模型和三个公开数据集上的实验，框架证明了其高保真度和意义，为构建更可靠的谣言检测系统奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2502.04366v1",
      "published_date": "2025-02-05 07:14:11 UTC",
      "updated_date": "2025-02-05 07:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:43:22.809658"
    },
    {
      "arxiv_id": "2502.04365v1",
      "title": "AI-Based Thermal Video Analysis in Privacy-Preserving Healthcare: A Case Study on Detecting Time of Birth",
      "title_zh": "基于AI的热成像视频分析在保护隐私的医疗保健中：检测出生时间的案例研究",
      "authors": [
        "Jorge García-Torres",
        "Øyvind Meinich-Bache",
        "Siren Rettedal",
        "Kjersti Engan"
      ],
      "abstract": "Approximately 10% of newborns need some assistance to start breathing and 5\\%\nproper ventilation. It is crucial that interventions are initiated as soon as\npossible after birth. Accurate documentation of Time of Birth (ToB) is thereby\nessential for documenting and improving newborn resuscitation performance.\nHowever, current clinical practices rely on manual recording of ToB, typically\nwith minute precision. In this study, we present an AI-driven, video-based\nsystem for automated ToB detection using thermal imaging, designed to preserve\nthe privacy of healthcare providers and mothers by avoiding the use of\nidentifiable visual data. Our approach achieves 91.4% precision and 97.4%\nrecall in detecting ToB within thermal video clips during performance\nevaluation. Additionally, our system successfully identifies ToB in 96% of test\ncases with an absolute median deviation of 1 second compared to manual\nannotations. This method offers a reliable solution for improving ToB\ndocumentation and enhancing newborn resuscitation outcomes.",
      "tldr_zh": "本研究提出了一种基于 AI 的热成像视频分析系统，用于隐私保护型医疗场景中自动检测新生儿的出生时间 (Time of Birth, ToB)，以解决当前手动记录精确度不足的问题。该系统利用 thermal imaging 避免使用可识别视觉数据，确保医疗提供者和母亲的隐私安全。在性能评估中，该方法在 ToB 检测中实现了 91.4% 的 precision 和 97.4% 的 recall，并在 96% 的测试案例中与手动标注相比，绝对中位偏差仅为 1 秒。该创新方案可显著提升 ToB 文档准确性，并改善新生儿复苏干预效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper accepted in 2025 IEEE International Symposium on Biomedical\n  Imaging (ISBI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.04365v1",
      "published_date": "2025-02-05 07:01:49 UTC",
      "updated_date": "2025-02-05 07:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:43:34.080992"
    },
    {
      "arxiv_id": "2502.02928v1",
      "title": "Large Language Model Guided Self-Debugging Code Generation",
      "title_zh": "大型语言模型引导的自我调试代码生成",
      "authors": [
        "Muntasir Adnan",
        "Zhiwei Xu",
        "Carlos C. N. Kuhn"
      ],
      "abstract": "Automated code generation is gaining significant importance in intelligent\ncomputer programming and system deployment. However, current approaches often\nface challenges in computational efficiency and lack robust mechanisms for code\nparsing and error correction. In this work, we propose a novel framework,\nPyCapsule, with a simple yet effective two-agent pipeline and efficient\nself-debugging modules for Python code generation. PyCapsule features\nsophisticated prompt inference, iterative error handling, and case testing,\nensuring high generation stability, safety, and correctness. Empirically,\nPyCapsule achieves up to 5.7% improvement of success rate on HumanEval, 10.3%\non HumanEval-ET, and 24.4% on BigCodeBench compared to the state-of-art\nmethods. We also observe a decrease in normalized success rate given more\nself-debugging attempts, potentially affected by limited and noisy error\nfeedback in retention. PyCapsule demonstrates broader impacts on advancing\nlightweight and efficient code generation for artificial intelligence systems.",
      "tldr_zh": "这篇论文提出了一种名为 PyCapsule 的新型框架，利用大型语言模型指导的自调试机制，针对 Python 代码生成问题，提供一个简单高效的两智能体管道，包括提示推理、迭代错误处理和案例测试，以提升代码生成的稳定、安全和正确性。实验结果显示，PyCapsule 在 HumanEval 上成功率提高 5.7%，在 HumanEval-ET 上提高 10.3%，在 BigCodeBench 上提高 24.4%，优于现有最先进方法。然而，研究观察到更多的自调试尝试可能因有限和嘈杂的错误反馈而降低标准化成功率，该框架为 AI 系统推进轻量级代码生成带来更广泛影响。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02928v1",
      "published_date": "2025-02-05 06:43:40 UTC",
      "updated_date": "2025-02-05 06:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:43:47.010684"
    },
    {
      "arxiv_id": "2502.02924v1",
      "title": "TopoCL: Topological Contrastive Learning for Time Series",
      "title_zh": "TopoCL: 用于时间序列的拓扑对比学习",
      "authors": [
        "Namwoo Kim",
        "Hyungryul Baik",
        "Yoonjin Yoon"
      ],
      "abstract": "Universal time series representation learning is challenging but valuable in\nreal-world applications such as classification, anomaly detection, and\nforecasting. Recently, contrastive learning (CL) has been actively explored to\ntackle time series representation. However, a key challenge is that the data\naugmentation process in CL can distort seasonal patterns or temporal\ndependencies, inevitably leading to a loss of semantic information. To address\nthis challenge, we propose Topological Contrastive Learning for time series\n(TopoCL). TopoCL mitigates such information loss by incorporating persistent\nhomology, which captures the topological characteristics of data that remain\ninvariant under transformations. In this paper, we treat the temporal and\ntopological properties of time series data as distinct modalities.\nSpecifically, we compute persistent homology to construct topological features\nof time series data, representing them in persistence diagrams. We then design\na neural network to encode these persistent diagrams. Our approach jointly\noptimizes CL within the time modality and time-topology correspondence,\npromoting a comprehensive understanding of both temporal semantics and\ntopological properties of time series. We conduct extensive experiments on four\ndownstream tasks-classification, anomaly detection, forecasting, and transfer\nlearning. The results demonstrate that TopoCL achieves state-of-the-art\nperformance.",
      "tldr_zh": "该论文提出TopoCL，一种针对时间序列的拓扑对比学习方法，旨在解决传统对比学习（CL）中数据增强导致的季节模式和时间依赖性信息丢失问题。通过整合persistent homology捕捉拓扑特性，这些特性在数据变换下保持不变，将时间序列视为时间模态和拓扑模态，并设计神经网络编码persistent diagrams以联合优化CL和时间-拓扑对应性。实验结果显示，TopoCL在分类、异常检测、预测和迁移学习等四个下游任务上实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to TNNLS (under review)",
      "pdf_url": "http://arxiv.org/pdf/2502.02924v1",
      "published_date": "2025-02-05 06:37:35 UTC",
      "updated_date": "2025-02-05 06:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:43:58.427866"
    },
    {
      "arxiv_id": "2502.02920v1",
      "title": "Adaptive Budget Optimization for Multichannel Advertising Using Combinatorial Bandits",
      "title_zh": "使用组合多臂老虎机的多",
      "authors": [
        "Briti Gangopadhyay",
        "Zhao Wang",
        "Alberto Silvio Chiappa",
        "Shingo Takamatsu"
      ],
      "abstract": "Effective budget allocation is crucial for optimizing the performance of\ndigital advertising campaigns. However, the development of practical budget\nallocation algorithms remain limited, primarily due to the lack of public\ndatasets and comprehensive simulation environments capable of verifying the\nintricacies of real-world advertising. While multi-armed bandit (MAB)\nalgorithms have been extensively studied, their efficacy diminishes in\nnon-stationary environments where quick adaptation to changing market dynamics\nis essential. In this paper, we advance the field of budget allocation in\ndigital advertising by introducing three key contributions. First, we develop a\nsimulation environment designed to mimic multichannel advertising campaigns\nover extended time horizons, incorporating logged real-world data. Second, we\npropose an enhanced combinatorial bandit budget allocation strategy that\nleverages a saturating mean function and a targeted exploration mechanism with\nchange-point detection. This approach dynamically adapts to changing market\nconditions, improving allocation efficiency by filtering target regions based\non domain knowledge. Finally, we present both theoretical analysis and\nempirical results, demonstrating that our method consistently outperforms\nbaseline strategies, achieving higher rewards and lower regret across multiple\nreal-world campaigns.",
      "tldr_zh": "本论文探讨了数字广告中预算分配的优化问题，指出多臂赌博机(MAB)算法在非平稳环境中适应性不足，无法快速应对市场动态变化。研究者开发了一个模拟环境来模仿多渠道广告活动，使用真实日志数据；并提出了一种增强的组合赌博机(Combinatorial Bandits)策略，结合饱和均值函数(saturating mean function)、针对性探索机制和变化点检测(change-point detection)，以动态调整预算分配并提高效率。理论分析和实证结果表明，该方法在多个真实广告活动中显著优于基线策略，实现了更高奖励和更低遗憾(regret)。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02920v1",
      "published_date": "2025-02-05 06:29:52 UTC",
      "updated_date": "2025-02-05 06:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:44:11.217766"
    },
    {
      "arxiv_id": "2502.02917v2",
      "title": "Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework",
      "title_zh": "通过离线强化学习的交互式符号回归：一个共同设计框架",
      "authors": [
        "Yuan Tian",
        "Wenqi Zhou",
        "Michele Viscione",
        "Hao Dong",
        "David Kammer",
        "Olga Fink"
      ],
      "abstract": "Symbolic Regression (SR) holds great potential for uncovering underlying\nmathematical and physical relationships from observed data. However, the vast\ncombinatorial space of possible expressions poses significant challenges for\nboth online search methods and pre-trained transformer models. Additionally,\ncurrent state-of-the-art approaches typically do not consider the integration\nof domain experts' prior knowledge and do not support iterative interactions\nwith the model during the equation discovery process. To address these\nchallenges, we propose the Symbolic Q-network (Sym-Q), an advanced interactive\nframework for large-scale symbolic regression. Unlike previous large-scale\ntransformer-based SR approaches, Sym-Q leverages reinforcement learning without\nrelying on a transformer-based decoder. This formulation allows the agent to\nlearn through offline reinforcement learning using any type of tree encoder,\nenabling more efficient training and inference. Furthermore, we propose a\nco-design mechanism, where the reinforcement learning-based Sym-Q facilitates\neffective interaction with domain experts at any stage of the equation\ndiscovery process. Users can dynamically modify generated nodes of the\nexpression, collaborating with the agent to tailor the mathematical expression\nto best fit the problem and align with the assumed physical laws, particularly\nwhen there is prior partial knowledge of the expected behavior. Our experiments\ndemonstrate that the pre-trained Sym-Q surpasses existing SR algorithms on the\nchallenging SSDNC benchmark. Moreover, we experimentally show on real-world\ncases that its performance can be further enhanced by the interactive co-design\nmechanism, with Sym-Q achieving greater performance gains than other\nstate-of-the-art models. Our reproducible code is available at\nhttps://github.com/EPFL-IMOS/Sym-Q.",
      "tldr_zh": "这篇论文提出 Symbolic Q-network (Sym-Q)，一个基于离线强化学习的交互式框架，用于解决符号回归 (SR) 在处理大规模表达式空间时的挑战。Sym-Q 采用树编码器进行高效训练和推理，并引入 co-design 机制，允许领域专家在等式发现过程中实时互动和修改表达式节点，以整合先验知识。实验结果表明，Sym-Q 在 SSDNC 基准上超越现有算法，通过交互机制在真实案例中进一步提升性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "This work should not be a new submission but instead should be an\n  update to my existing article, arXiv:2402.05306",
      "pdf_url": "http://arxiv.org/pdf/2502.02917v2",
      "published_date": "2025-02-05 06:26:49 UTC",
      "updated_date": "2025-02-11 00:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:44:22.182098"
    },
    {
      "arxiv_id": "2502.04364v1",
      "title": "Lost in Edits? A $λ$-Compass for AIGC Provenance",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao You",
        "Bryan Hooi",
        "Yiwei Wang",
        "Euijin Choo",
        "Ming-Hsuan Yang",
        "Junsong Yuan",
        "Zi Huang",
        "Yujun Cai"
      ],
      "abstract": "Recent advancements in diffusion models have driven the growth of text-guided\nimage editing tools, enabling precise and iterative modifications of\nsynthesized content. However, as these tools become increasingly accessible,\nthey also introduce significant risks of misuse, emphasizing the critical need\nfor robust attribution methods to ensure content authenticity and traceability.\nDespite the creative potential of such tools, they pose significant challenges\nfor attribution, particularly in adversarial settings where edits can be\nlayered to obscure an image's origins. We propose LambdaTracer, a novel\nlatent-space attribution method that robustly identifies and differentiates\nauthentic outputs from manipulated ones without requiring any modifications to\ngenerative or editing pipelines. By adaptively calibrating reconstruction\nlosses, LambdaTracer remains effective across diverse iterative editing\nprocesses, whether automated through text-guided editing tools such as\nInstructPix2Pix and ControlNet or performed manually with editing software such\nas Adobe Photoshop. Extensive experiments reveal that our method consistently\noutperforms baseline approaches in distinguishing maliciously edited images,\nproviding a practical solution to safeguard ownership, creativity, and\ncredibility in the open, fast-evolving AI ecosystems.",
      "tldr_zh": "该论文探讨了扩散模型驱动的文本引导图像编辑工具所带来的滥用风险，强调了需要稳健的归属方法来确保AIGC（AI 生成内容）的真实性和可追溯性。作者提出LambdaTracer，一种新型latent-space attribution方法，通过自适应校准reconstruction losses来识别和区分真实图像与恶意编辑图像，而无需修改生成或编辑管道。实验结果显示，LambdaTracer在处理诸如InstructPix2Pix、ControlNet和Adobe Photoshop的迭代编辑时，显著优于基线方法，为保护内容所有权、创意和可信度提供了实用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04364v1",
      "published_date": "2025-02-05 06:24:25 UTC",
      "updated_date": "2025-02-05 06:24:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:44:34.459002"
    },
    {
      "arxiv_id": "2502.02912v1",
      "title": "MobiCLR: Mobility Time Series Contrastive Learning for Urban Region Representations",
      "title_zh": "MobiCLR：用于城市区域表示的移动性时间序列对比学习",
      "authors": [
        "Namwoo Kim",
        "Takahiro Yabe",
        "Chanyoung Park",
        "Yoonjin Yoon"
      ],
      "abstract": "Recently, learning effective representations of urban regions has gained\nsignificant attention as a key approach to understanding urban dynamics and\nadvancing smarter cities. Existing approaches have demonstrated the potential\nof leveraging mobility data to generate latent representations, providing\nvaluable insights into the intrinsic characteristics of urban areas. However,\nincorporating the temporal dynamics and detailed semantics inherent in human\nmobility patterns remains underexplored. To address this gap, we propose a\nnovel urban region representation learning model, Mobility Time Series\nContrastive Learning for Urban Region Representations (MobiCLR), designed to\ncapture semantically meaningful embeddings from inflow and outflow mobility\npatterns. MobiCLR uses contrastive learning to enhance the discriminative power\nof its representations, applying an instance-wise contrastive loss to capture\ndistinct flow-specific characteristics. Additionally, we develop a regularizer\nto align output features with these flow-specific representations, enabling a\nmore comprehensive understanding of mobility dynamics. To validate our model,\nwe conduct extensive experiments in Chicago, New York, and Washington, D.C. to\npredict income, educational attainment, and social vulnerability. The results\ndemonstrate that our model outperforms state-of-the-art models.",
      "tldr_zh": "该研究提出了一种新型城市区域表示学习模型MobiCLR，利用流动性时间序列对比学习（Contrastive Learning）从流入和流出流动性模式中捕获语义丰富的嵌入，以更好地理解城市动态。MobiCLR采用实例级对比损失来增强表示的区分能力，并引入一个正则化器来对齐输出特征，从而全面捕捉流动特性的时间动态和语义细节。在芝加哥、纽约和华盛顿特区的实验中，该模型在预测收入、教育水平和社会脆弱性方面优于现有最先进模型，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Information Sciences (under review)",
      "pdf_url": "http://arxiv.org/pdf/2502.02912v1",
      "published_date": "2025-02-05 06:18:43 UTC",
      "updated_date": "2025-02-05 06:18:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:44:45.364093"
    },
    {
      "arxiv_id": "2502.02909v1",
      "title": "SPARC: Subspace-Aware Prompt Adaptation for Robust Continual Learning in LLMs",
      "title_zh": "SPARC：子空间感知提示适应用于大型语言模型中的鲁棒持续学习",
      "authors": [
        "Dinithi Jayasuriya",
        "Sina Tayebati",
        "Davide Ettori",
        "Ranganath Krishnan",
        "Amit Ranjan Trivedi"
      ],
      "abstract": "We propose SPARC, a lightweight continual learning framework for large\nlanguage models (LLMs) that enables efficient task adaptation through prompt\ntuning in a lower-dimensional space. By leveraging principal component analysis\n(PCA), we identify a compact subspace of the training data. Optimizing prompts\nin this lower-dimensional space enhances training efficiency, as it focuses\nupdates on the most relevant features while reducing computational overhead.\nFurthermore, since the model's internal structure remains unaltered, the\nextensive knowledge gained from pretraining is fully preserved, ensuring that\npreviously learned information is not compromised during adaptation. Our method\nachieves high knowledge retention in both task-incremental and\ndomain-incremental continual learning setups while fine-tuning only 0.04% of\nthe model's parameters. Additionally, by integrating LoRA, we enhance\nadaptability to computational constraints, allowing for a tradeoff between\naccuracy and training cost. Experiments on the SuperGLUE benchmark demonstrate\nthat our PCA-based prompt tuning combined with LoRA maintains full knowledge\nretention while improving accuracy, utilizing only 1% of the model's\nparameters. These results establish our approach as a scalable and\nresource-efficient solution for continual learning in LLMs.",
      "tldr_zh": "我们提出 SPARC，一种轻量级的持续学习框架，用于大型语言模型 (LLMs)，通过在较低维子空间进行提示调优 (prompt tuning) 来实现高效任务适应。利用主成分分析 (PCA)，框架识别训练数据的紧凑子空间，优化提示以聚焦相关特征，减少计算开销并完整保留预训练知识。实验结果显示，SPARC 在 SuperGLUE 基准测试中，仅微调模型参数的 0.04% 便在任务增量和领域增量设置中保持高知识保留，并通过整合 LoRA 提升准确性，提供精度与成本的灵活权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02909v1",
      "published_date": "2025-02-05 06:11:55 UTC",
      "updated_date": "2025-02-05 06:11:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:44:58.596725"
    },
    {
      "arxiv_id": "2502.02903v1",
      "title": "What is in a name? Mitigating Name Bias in Text Embeddings via Anonymization",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Manchanda",
        "Pannaga Shivaswamy"
      ],
      "abstract": "Text-embedding models often exhibit biases arising from the data on which\nthey are trained. In this paper, we examine a hitherto unexplored bias in\ntext-embeddings: bias arising from the presence of $\\textit{names}$ such as\npersons, locations, organizations etc. in the text. Our study shows how the\npresence of $\\textit{name-bias}$ in text-embedding models can potentially lead\nto erroneous conclusions in assessment of thematic similarity.Text-embeddings\ncan mistakenly indicate similarity between texts based on names in the text,\neven when their actual semantic content has no similarity or indicate\ndissimilarity simply because of the names in the text even when the texts match\nsemantically. We first demonstrate the presence of name bias in different\ntext-embedding models and then propose $\\textit{text-anonymization}$ during\ninference which involves removing references to names, while preserving the\ncore theme of the text. The efficacy of the anonymization approach is\ndemonstrated on two downstream NLP tasks, achieving significant performance\ngains. Our simple and training-optimization-free approach offers a practical\nand easily implementable solution to mitigate name bias.",
      "tldr_zh": "这篇论文探讨了文本嵌入模型（text-embeddings）中的name bias问题，即模型因文本中人名、地名或组织名等存在而错误评估主题相似性，导致语义无关的文本被误判为相似或不同。研究者首先证明了name bias在多种文本嵌入模型中的普遍性，然后提出text-anonymization方法，通过在推理阶段移除名字引用同时保留文本核心主题，来缓解这种偏差。该方法在两个下游NLP任务上实现了显著性能提升，提供了一个简单、无需额外训练优化的实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02903v1",
      "published_date": "2025-02-05 05:54:49 UTC",
      "updated_date": "2025-02-05 05:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:45:09.928863"
    },
    {
      "arxiv_id": "2502.02901v2",
      "title": "Policy Abstraction and Nash Refinement in Tree-Exploiting PSRO",
      "title_zh": "翻译失败",
      "authors": [
        "Christine Konicki",
        "Mithun Chakraborty",
        "Michael P. Wellman"
      ],
      "abstract": "Policy Space Response Oracles (PSRO) interleaves empirical game-theoretic\nanalysis with deep reinforcement learning (DRL) to solve games too complex for\ntraditional analytic methods. Tree-exploiting PSRO (TE-PSRO) is a variant of\nthis approach that iteratively builds a coarsened empirical game model in\nextensive form using data obtained from querying a simulator that represents a\ndetailed description of the game. We make two main methodological advances to\nTE-PSRO that enhance its applicability to complex games of imperfect\ninformation. First, we introduce a scalable representation for the empirical\ngame tree where edges correspond to implicit policies learned through DRL.\nThese policies cover conditions in the underlying game abstracted in the game\nmodel, supporting sustainable growth of the tree over epochs. Second, we\nleverage extensive form in the empirical model by employing refined Nash\nequilibria to direct strategy exploration. To enable this, we give a modular\nand scalable algorithm based on generalized backward induction for computing a\nsubgame perfect equilibrium (SPE) in an imperfect-information game. We\nexperimentally evaluate our approach on a suite of games including an\nalternating-offer bargaining game with outside offers; our results demonstrate\nthat TE-PSRO converges toward equilibrium faster when new strategies are\ngenerated based on SPE rather than Nash equilibrium, and with reasonable\ntime/memory requirements for the growing empirical model.",
      "tldr_zh": "本文提出对 Tree-exploiting PSRO (TE-PSRO) 的两项改进，以增强其在复杂不完美信息博弈中的适用性：首先，引入一种可扩展的经验博弈树表示，其中边对应于通过深度强化学习 (DRL) 学习的隐式策略，支持博弈树的可持续增长；其次，利用详尽形式并采用精炼的 Nash 均衡来指导策略探索，并提供一个基于广义后向归纳的模块化算法计算子博弈完美均衡 (SPE)。实验在包括交替报价讨价还价博弈在内的游戏套件上显示，该方法使 TE-PSRO 比基于 Nash 均衡的版本更快收敛到均衡，且在时间和内存需求上更合理。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02901v2",
      "published_date": "2025-02-05 05:48:16 UTC",
      "updated_date": "2025-02-15 06:14:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:45:24.389172"
    },
    {
      "arxiv_id": "2502.02896v1",
      "title": "A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Bradley P. Allen",
        "Paul T. Groth"
      ],
      "abstract": "Evaluating large language models (LLMs) for tasks like fact extraction in\nsupport of knowledge graph construction frequently involves computing accuracy\nmetrics using a ground truth benchmark based on a knowledge graph (KG). These\nevaluations assume that errors represent factual disagreements. However, human\ndiscourse frequently features metalinguistic disagreement, where agents differ\nnot on facts but on the meaning of the language used to express them. Given the\ncomplexity of natural language processing and generation using LLMs, we ask: do\nmetalinguistic disagreements occur between LLMs and KGs? Based on an\ninvestigation using the T-REx knowledge alignment dataset, we hypothesize that\nmetalinguistic disagreement does in fact occur between LLMs and KGs, with\npotential relevance for the practice of knowledge graph engineering. We propose\na benchmark for evaluating the detection of factual and metalinguistic\ndisagreements between LLMs and KGs. An initial proof of concept of such a\nbenchmark is available on Github.",
      "tldr_zh": "这篇论文探讨了评估大型语言模型（LLMs）时，传统基于知识图谱（Knowledge Graphs, KGs）的准确性指标可能忽略元语言分歧（Metalinguistic Disagreements），即LLMs和KGs在事实一致但语言表达上存在差异的问题。作者通过对T-REx知识对齐数据集的调查，证实了这种分歧的存在，并提出一个基准用于检测LLMs和KGs之间的事实分歧和元语言分歧。 该基准的初步实现已在Github上发布，有助于提升知识图谱工程的实践和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 2 tables, to appear in Reham Alharbi, Jacopo de Berardinis,\n  Paul Groth, Albert Mero\\~no-Pe\\~nuela, Elena Simperl, Valentina Tamma (eds.),\n  ISWC 2024 Special Session on Harmonising Generative AI and Semantic Web\n  Technologies. CEUR-WS.org (forthcoming), for associated code and data see\n  https://github.com/bradleypallen/trex-metalinguistic-disagreement",
      "pdf_url": "http://arxiv.org/pdf/2502.02896v1",
      "published_date": "2025-02-05 05:37:26 UTC",
      "updated_date": "2025-02-05 05:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:45:34.043008"
    },
    {
      "arxiv_id": "2503.11658v1",
      "title": "Circuit Diagram Retrieval Based on Hierarchical Circuit Graph Representation",
      "title_zh": "基于分层电路图表示的电路图检索",
      "authors": [
        "Ming Gao",
        "Ruichen Qiu",
        "Zeng Hui Chang",
        "Kanjian Zhang",
        "Haikun Wei",
        "Hong Cai Chen"
      ],
      "abstract": "In the domain of analog circuit design, the retrieval of circuit diagrams has\ndrawn a great interest, primarily due to its vital role in the consultation of\nlegacy designs and the detection of design plagiarism. Existing image retrieval\ntechniques are adept at handling natural images, which converts images into\nfeature vectors and retrieval similar images according to the closeness of\nthese vectors. Nonetheless, these approaches exhibit limitations when applied\nto the more specialized and intricate domain of circuit diagrams. This paper\npresents a novel approach to circuit diagram retrieval by employing a graph\nrepresentation of circuit diagrams, effectively reformulating the retrieval\ntask as a graph retrieval problem. The proposed methodology consists of two\nprincipal components: a circuit diagram recognition algorithm designed to\nextract the circuit components and topological structure of the circuit using\nproposed GAM-YOLO model and a 2-step connected domain filtering algorithm, and\na hierarchical retrieval strategy based on graph similarity and different graph\nrepresentation methods for analog circuits. Our methodology pioneers the\nutilization of graph representation in the retrieval of circuit diagrams,\nincorporating topological features that are commonly overlooked by standard\nimage retrieval methods. The results of our experiments substantiate the\nefficacy of our approach in retrieving circuit diagrams across of different\ntypes.",
      "tldr_zh": "本文提出了一种基于分层电路图表示的检索方法，将电路图检索转化为图检索问题，以解决传统图像检索技术在模拟电路设计领域的局限性，如忽略拓扑结构。方法包括使用 GAM-YOLO 模型和 2-step 连接域过滤算法来提取电路组件及拓扑结构，以及基于图相似度的分层检索策略。实验结果显示，该方法在不同类型电路图的检索中表现出色，首次强调了图表示的效能，提升了检索准确性和实用性。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "11 pages, 10 figures, 7 tables, under review paper",
      "pdf_url": "http://arxiv.org/pdf/2503.11658v1",
      "published_date": "2025-02-05 05:05:53 UTC",
      "updated_date": "2025-02-05 05:05:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:45:46.245917"
    },
    {
      "arxiv_id": "2502.04362v1",
      "title": "LLMs can be easily Confused by Instructional Distractions",
      "title_zh": "翻译失败",
      "authors": [
        "Yerin Hwang",
        "Yongil Kim",
        "Jahyun Koo",
        "Taegwan Kang",
        "Hyunkyung Bae",
        "Kyomin Jung"
      ],
      "abstract": "Despite the fact that large language models (LLMs) show exceptional skill in\ninstruction following tasks, this strength can turn into a vulnerability when\nthe models are required to disregard certain instructions.\nInstruction-following tasks typically involve a clear task description and\ninput text containing the target data to be processed. However, when the input\nitself resembles an instruction, confusion may arise, even if there is explicit\nprompting to distinguish between the task instruction and the input. We refer\nto this phenomenon as instructional distraction. In this paper, we introduce a\nnovel benchmark, named DIM-Bench, specifically designed to assess LLMs'\nperformance under instructional distraction. The benchmark categorizes\nreal-world instances of instructional distraction and evaluates LLMs across\nfour instruction tasks: rewriting, proofreading, translation, and style\ntransfer -- alongside five input tasks: reasoning, code generation,\nmathematical reasoning, bias detection, and question answering. Our\nexperimental results reveal that even the most advanced LLMs are susceptible to\ninstructional distraction, often failing to accurately follow user intent in\nsuch cases.",
      "tldr_zh": "本研究揭示了大语言模型（LLMs）在指令遵循任务中容易受到指令干扰（instructional distraction）的困扰，即使有明确提示，模型也可能混淆任务指令和输入内容。研究者引入了DIM-Bench基准，该基准分类真实世界的干扰实例，并评估LLMs在重写、校对、翻译和风格转换等四种指令任务，以及推理、代码生成、数学推理、偏差检测和问答等五种输入任务上的性能。实验结果显示，即使是最先进的LLMs也经常无法准确遵循用户意图，突显了这一漏洞的普遍性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.04362v1",
      "published_date": "2025-02-05 04:52:57 UTC",
      "updated_date": "2025-02-05 04:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:45:59.667082"
    },
    {
      "arxiv_id": "2502.02885v3",
      "title": "Expertized Caption Auto-Enhancement for Video-Text Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Baoyao Yang",
        "Junxiang Chen",
        "Wanyun Li",
        "Wenbin Yao",
        "Yang Zhou"
      ],
      "abstract": "Video-text retrieval has been stuck in the information mismatch caused by\npersonalized and inadequate textual descriptions of videos. The substantial\ninformation gap between the two modalities hinders an effective cross-modal\nrepresentation alignment, resulting in ambiguous retrieval results. Although\ntext rewriting methods have been proposed to broaden text expressions, the\nmodality gap remains significant, as the text representation space is hardly\nexpanded with insufficient semantic enrichment.Instead, this paper turns to\nenhancing visual presentation, bridging video expression closer to textual\nrepresentation via caption generation and thereby facilitating video-text\nmatching.While multimodal large language models (mLLM) have shown a powerful\ncapability to convert video content into text, carefully crafted prompts are\nessential to ensure the reasonableness and completeness of the generated\ncaptions. Therefore, this paper proposes an automatic caption enhancement\nmethod that improves expression quality and mitigates empiricism in augmented\ncaptions through self-learning.Additionally, an expertized caption selection\nmechanism is designed and introduced to customize augmented captions for each\nvideo, further exploring the utilization potential of caption augmentation.Our\nmethod is entirely data-driven, which not only dispenses with heavy data\ncollection and computation workload but also improves self-adaptability by\ncircumventing lexicon dependence and introducing personalized matching. The\nsuperiority of our method is validated by state-of-the-art results on various\nbenchmarks, specifically achieving Top-1 recall accuracy of 68.5% on MSR-VTT,\n68.1% on MSVD, and 62.0% on DiDeMo. Our code is publicly available at\nhttps://github.com/CaryXiang/ECA4VTR.",
      "tldr_zh": "这篇论文针对视频-文本检索中的信息不匹配问题，提出了一种自动标题增强方法，通过利用多模态大语言模型 (mLLM) 生成高质量标题，并通过自学习机制改善表达完整性和减少主观偏差。论文引入专家化标题选择机制，为每个视频定制增强标题，从而桥接视频和文本模态的语义差距，实现更有效的跨模态表示对齐。该方法在 MSR-VTT、MSVD 和 DiDeMo 等基准上取得了最先进结果，Top-1 召回准确率分别为 68.5%、68.1% 和 62.0%，并展示了其数据驱动的优势，无需大量额外数据收集。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "H.3.3; I.2.10; I.2.7; H.5.1"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02885v3",
      "published_date": "2025-02-05 04:51:46 UTC",
      "updated_date": "2025-04-08 15:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:46:10.686755"
    },
    {
      "arxiv_id": "2502.02883v2",
      "title": "SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions",
      "title_zh": "SensorChat：在长期多模态传感器交互中回答定性和定量问题",
      "authors": [
        "Xiaofan Yu",
        "Lanxiang Hu",
        "Benjamin Reichman",
        "Dylan Chu",
        "Rushil Chandrupatla",
        "Xiyuan Zhang",
        "Larry Heck",
        "Tajana Rosing"
      ],
      "abstract": "Natural language interaction with sensing systems is crucial for addressing\nusers' personal concerns and providing health-related insights into their daily\nlives. When a user asks a question, the system automatically analyzes the full\nhistory of sensor data, extracts relevant information, and generates an\nappropriate response. However, existing systems are limited to short-duration\n(e.g., one minute) or low-frequency (e.g., daily step count) sensor data. In\naddition, they struggle with quantitative questions that require precise\nnumerical answers. In this work, we introduce SensorChat, the first end-to-end\nQA system designed for daily life monitoring using long-duration,\nhigh-frequency time series data. Given raw sensor signals spanning multiple\ndays and a user-defined natural language question, SensorChat generates\nsemantically meaningful responses that directly address user concerns.\nSensorChat effectively handles both quantitative questions that require\nnumerical precision and qualitative questions that require high-level reasoning\nto infer subjective insights. To achieve this, SensorChat uses an innovative\nthree-stage pipeline including question decomposition, sensor data query, and\nanswer assembly. The first and third stages leverage Large Language Models\n(LLMs) to interpret human queries and generate responses. The intermediate\nquerying stage extracts relevant information from the complete sensor data\nhistory. Real-world implementation demonstrate SensorChat's capability for\nreal-time interactions on a cloud server while also being able to run entirely\non edge platforms after quantization. Comprehensive QA evaluations show that\nSensorChat achieves up to 93% higher answer accuracy than state-of-the-art\nsystems on quantitative questions. Additionally, a user study with eight\nvolunteers highlights SensorChat's effectiveness in answering qualitative and\nopen-ended questions.",
      "tldr_zh": "该研究引入了SensorChat，一种端到端QA系统，旨在通过自然语言处理长期、高频的多模态传感器数据，回答用户的问题并提供日常健康洞见。SensorChat采用创新的三阶段管道，包括问题分解（使用Large Language Models (LLMs)）、传感器数据查询和答案组装，从而有效处理定量问题（如需要数值精度的查询）和定性问题（如需要高级推理的主观洞见）。实验结果显示，SensorChat在定量问题上比现有系统准确率提高93%，并通过八名志愿者的用户研究证明其在实时交互和开放问题回答方面的实用性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.02883v2",
      "published_date": "2025-02-05 04:41:59 UTC",
      "updated_date": "2025-05-15 06:31:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:46:22.324828"
    },
    {
      "arxiv_id": "2502.06820v2",
      "title": "LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning",
      "title_zh": "LoCA：位置感知余弦适应用于参数高效微调",
      "authors": [
        "Zhekai Du",
        "Yinjie Min",
        "Jingjing Li",
        "Ke Lu",
        "Changliang Zou",
        "Liuhua Peng",
        "Tingjin Chu",
        "Mingming Gong"
      ],
      "abstract": "Low-rank adaptation (LoRA) has become a prevalent method for adapting\npre-trained large language models to downstream tasks. However, the simple\nlow-rank decomposition form may constrain the hypothesis space. To address this\nlimitation, we introduce Location-aware Cosine Adaptation (LoCA), a novel\nfrequency-domain parameter-efficient fine-tuning method based on inverse\nDiscrete Cosine Transform (iDCT) with selective locations of learnable\ncomponents. We begin with a comprehensive theoretical comparison between\nfrequency-domain and low-rank decompositions for fine-tuning pre-trained large\nmodels. Our analysis reveals that frequency-domain decomposition with carefully\nselected frequency components can surpass the expressivity of traditional\nlow-rank-based methods. Furthermore, we demonstrate that iDCT offers a more\nefficient implementation compared to inverse Discrete Fourier Transform (iDFT),\nallowing for better selection and tuning of frequency components while\nmaintaining equivalent expressivity to the optimal iDFT-based adaptation. By\nemploying finite-difference approximation to estimate gradients for discrete\nlocations of learnable coefficients on the DCT spectrum, LoCA dynamically\nselects the most informative frequency components during training. Experiments\non diverse language and vision fine-tuning tasks demonstrate that LoCA offers\nenhanced parameter efficiency while maintains computational feasibility\ncomparable to low-rank-based methods.",
      "tldr_zh": "本研究提出了一种名为 LoCA 的位置感知余弦适应方法，用于参数高效微调预训练的大型语言模型。LoCA 基于逆离散余弦变换 (iDCT) 和选择性频率组件的位置学习，相比传统低秩分解 (如 LoRA) 提供了更强的表达能力，通过有限差分逼近动态选择最有信息量的频率组件。理论分析显示，频域分解在适当选择组件时可超越低秩方法，而 iDCT 比逆离散傅里叶变换 (iDFT) 更高效。在语言和视觉任务的实验中，LoCA 实现了更高的参数效率，同时保持与低秩方法相当的计算可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06820v2",
      "published_date": "2025-02-05 04:14:34 UTC",
      "updated_date": "2025-04-29 09:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:46:34.741115"
    },
    {
      "arxiv_id": "2502.02874v1",
      "title": "Vertical Federated Learning for Failure-Cause Identification in Disaggregated Microwave Networks",
      "title_zh": "垂直联邦学习用于解耦微波网络中的故障原因识别",
      "authors": [
        "Fatih Temiz",
        "Memedhe Ibrahimi",
        "Francesco Musumeci",
        "Claudio Passera",
        "Massimo Tornatore"
      ],
      "abstract": "Machine Learning (ML) has proven to be a promising solution to provide novel\nscalable and efficient fault management solutions in modern 5G-and-beyond\ncommunication networks. In the context of microwave networks, ML-based\nsolutions have received significant attention. However, current solutions can\nonly be applied to monolithic scenarios in which a single entity (e.g., an\noperator) manages the entire network. As current network architectures move\ntowards disaggregated communication platforms in which multiple operators and\nvendors collaborate to achieve cost-efficient and reliable network management,\nnew ML-based approaches for fault management must tackle the challenges of\nsharing business-critical information due to potential conflicts of interest.\nIn this study, we explore the application of Federated Learning in\ndisaggregated microwave networks for failure-cause identification using a real\nmicrowave hardware failure dataset. In particular, we investigate the\napplication of two Vertical Federated Learning (VFL), namely using Split Neural\nNetworks (SplitNNs) and Federated Learning based on Gradient Boosting Decision\nTrees (FedTree), on different multi-vendor deployment scenarios, and we compare\nthem to a centralized scenario where data is managed by a single entity. Our\nexperimental results show that VFL-based scenarios can achieve F1-Scores\nconsistently within at most a 1% gap with respect to a centralized scenario,\nregardless of the deployment strategies or model types, while also ensuring\nminimal leakage of sensitive-data.",
      "tldr_zh": "本研究探讨了在分层微波网络中应用Vertical Federated Learning (VFL)来识别故障原因，旨在解决多供应商场景下数据共享的隐私挑战，同时提升5G及后续网络的故障管理效率。论文比较了使用Split Neural Networks (SplitNNs)和Federated Learning based on Gradient Boosting Decision Trees (FedTree)的VFL方法，与集中式场景进行对比。实验结果显示，VFL在不同部署策略下能实现F1-Scores与集中式场景相差不超过1%，同时有效减少敏感数据泄露，为分层网络的可靠管理提供了可扩展的ML解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages, 7 figure, IEEE ICC 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02874v1",
      "published_date": "2025-02-05 04:09:15 UTC",
      "updated_date": "2025-02-05 04:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:46:45.753840"
    },
    {
      "arxiv_id": "2502.02871v1",
      "title": "Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning",
      "title_zh": "观点：多模态大语言模型能够显著推进科学推理",
      "authors": [
        "Yibo Yan",
        "Shen Wang",
        "Jiahao Huo",
        "Jingheng Ye",
        "Zhendong Chu",
        "Xuming Hu",
        "Philip S. Yu",
        "Carla Gomes",
        "Bart Selman",
        "Qingsong Wen"
      ],
      "abstract": "Scientific reasoning, the process through which humans apply logic, evidence,\nand critical thinking to explore and interpret scientific phenomena, is\nessential in advancing knowledge reasoning across diverse fields. However,\ndespite significant progress, current scientific reasoning models still\nstruggle with generalization across domains and often fall short of multimodal\nperception. Multimodal Large Language Models (MLLMs), which integrate text,\nimages, and other modalities, present an exciting opportunity to overcome these\nlimitations and enhance scientific reasoning. Therefore, this position paper\nargues that MLLMs can significantly advance scientific reasoning across\ndisciplines such as mathematics, physics, chemistry, and biology. First, we\npropose a four-stage research roadmap of scientific reasoning capabilities, and\nhighlight the current state of MLLM applications in scientific reasoning,\nnoting their ability to integrate and reason over diverse data types. Second,\nwe summarize the key challenges that remain obstacles to achieving MLLM's full\npotential. To address these challenges, we propose actionable insights and\nsuggestions for the future. Overall, our work offers a novel perspective on\nMLLM integration with scientific reasoning, providing the LLM community with a\nvaluable vision for achieving Artificial General Intelligence (AGI).",
      "tldr_zh": "这篇立场论文（Position Paper）主张Multimodal Large Language Models (MLLMs)能够显著提升科学推理能力，通过整合文本、图像等模态来解决当前模型在跨领域泛化和多模态感知方面的不足。论文提出一个四阶段研究路线图，概述MLLMs在数学、物理、化学和生物等领域的应用现状，并强调其整合多样数据类型进行推理的优势。为应对关键挑战，如泛化限制和模态整合难题，论文提供可操作的见解和建议，旨在为实现Artificial General Intelligence (AGI)提供新视角和愿景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02871v1",
      "published_date": "2025-02-05 04:05:27 UTC",
      "updated_date": "2025-02-05 04:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:46:57.746340"
    },
    {
      "arxiv_id": "2502.02869v1",
      "title": "OmniRL: In-Context Reinforcement Learning by Large-Scale Meta-Training in Randomized Worlds",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Wang",
        "Pengtao Shao",
        "Yiming Zhang",
        "Bo Yu",
        "Shaoshan Liu",
        "Ning Ding",
        "Yang Cao",
        "Yu Kang",
        "Haifeng Wang"
      ],
      "abstract": "We introduce OmniRL, a highly generalizable in-context reinforcement learning\n(ICRL) model that is meta-trained on hundreds of thousands of diverse tasks.\nThese tasks are procedurally generated by randomizing state transitions and\nrewards within Markov Decision Processes. To facilitate this extensive\nmeta-training, we propose two key innovations: 1. An efficient data synthesis\npipeline for ICRL, which leverages the interaction histories of diverse\nbehavior policies; and 2. A novel modeling framework that integrates both\nimitation learning and reinforcement learning (RL) within the context, by\nincorporating prior knowledge. For the first time, we demonstrate that\nin-context learning (ICL) alone, without any gradient-based fine-tuning, can\nsuccessfully tackle unseen Gymnasium tasks through imitation learning, online\nRL, or offline RL. Additionally, we show that achieving generalized ICRL\ncapabilities-unlike task identification-oriented few-shot learning-critically\ndepends on long trajectories generated by variant tasks and diverse behavior\npolicies. By emphasizing the potential of ICL and departing from pre-training\nfocused on acquiring specific skills, we further underscore the significance of\nmeta-training aimed at cultivating the ability of ICL itself.",
      "tldr_zh": "我们介绍了 OmniRL，一种高度可泛化的 In-Context Reinforcement Learning (ICRL) 模型，通过在成千上万的随机化 Markov Decision Processes (MDPs) 任务上进行大规模元训练，实现对多样化环境的泛化能力。该模型引入两个关键创新：一个高效的数据合成管道，利用多样化行为策略的交互历史生成数据，以及一个整合 Imitation Learning 和 Reinforcement Learning (RL) 的建模框架，以结合先验知识。实验首次证明，In-Context Learning (ICL) 单独无需基于梯度的微调，就能处理未见过的 Gymnasium 任务，包括模仿学习、在线 RL 或离线 RL。研究强调，实现泛化的 ICRL 依赖于长轨迹和多样化策略，并突出元训练在培养 ICL 能力方面的核心意义。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.02869v1",
      "published_date": "2025-02-05 03:59:13 UTC",
      "updated_date": "2025-02-05 03:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:47:29.797239"
    },
    {
      "arxiv_id": "2502.02867v2",
      "title": "Domain-Invariant Per-Frame Feature Extraction for Cross-Domain Imitation Learning with Visual Observations",
      "title_zh": "翻译失败",
      "authors": [
        "Minung Kim",
        "Kawon Lee",
        "Jungmo Kim",
        "Sungho Choi",
        "Seungyul Han"
      ],
      "abstract": "Imitation learning (IL) enables agents to mimic expert behavior without\nreward signals but faces challenges in cross-domain scenarios with\nhigh-dimensional, noisy, and incomplete visual observations. To address this,\nwe propose Domain-Invariant Per-Frame Feature Extraction for Imitation Learning\n(DIFF-IL), a novel IL method that extracts domain-invariant features from\nindividual frames and adapts them into sequences to isolate and replicate\nexpert behaviors. We also introduce a frame-wise time labeling technique to\nsegment expert behaviors by timesteps and assign rewards aligned with temporal\ncontexts, enhancing task performance. Experiments across diverse visual\nenvironments demonstrate the effectiveness of DIFF-IL in addressing complex\nvisual tasks.",
      "tldr_zh": "本文提出 DIFF-IL 方法，用于解决模仿学习（Imitation Learning, IL）在跨领域场景中的挑战，特别是处理高维、嘈杂和不完整的视觉观察。该方法通过提取领域不变的每帧特征（Domain-Invariant Per-Frame Feature Extraction）并将其适应成序列，来隔离和复制专家行为，同时引入帧级时间标记技术（frame-wise time labeling）来分割行为并分配与时间上下文对齐的奖励。实验结果显示，DIFF-IL 在多样视觉环境中显著提升了复杂任务的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages main, 19 pages appendix with reference. Submitted to ICML\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02867v2",
      "published_date": "2025-02-05 03:52:36 UTC",
      "updated_date": "2025-02-14 11:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:47:22.026609"
    },
    {
      "arxiv_id": "2502.02866v1",
      "title": "A Systematic Approach for Assessing Large Language Models' Test Case Generation Capability",
      "title_zh": "系统评估大语言模型测试用例生成能力的途径",
      "authors": [
        "Hung-Fu Chang",
        "Mohammad Shokrolah Shirazi"
      ],
      "abstract": "Software testing ensures the quality and reliability of software products,\nbut manual test case creation is labor-intensive. With the rise of large\nlanguage models (LLMs), there is growing interest in unit test creation with\nLLMs. However, effective assessment of LLM-generated test cases is limited by\nthe lack of standardized benchmarks that comprehensively cover diverse\nprogramming scenarios. To address the assessment of LLM's test case generation\nability and lacking dataset for evaluation, we propose the Generated Benchmark\nfrom Control-Flow Structure and Variable Usage Composition (GBCV) approach,\nwhich systematically generates programs used for evaluating LLMs' test\ngeneration capabilities. By leveraging basic control-flow structures and\nvariable usage, GBCV provides a flexible framework to create a spectrum of\nprograms ranging from simple to complex. Because GPT-4o and GPT-3-Turbo are\npublicly accessible models, to present real-world regular user's use case, we\nuse GBCV to assess LLM performance on them. Our findings indicate that GPT-4o\nperforms better on complex program structures, while all models effectively\ndetect boundary values in simple conditions but face challenges with arithmetic\ncomputations. This study highlights the strengths and limitations of LLMs in\ntest generation, provides a benchmark framework, and suggests directions for\nfuture improvement.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在测试用例生成方面的评估不足，提出了一种系统方法——GBCV（Generated Benchmark from Control-Flow Structure and Variable Usage Composition）。GBCV 通过利用基本控制流结构和变量使用来生成从简单到复杂的程序，作为评估基准，从而全面覆盖多样编程场景。实验结果显示，GPT-4o 在复杂程序结构上表现优于 GPT-3-Turbo，而所有模型在简单条件下的边界值检测有效，但算术计算方面存在挑战。该方法突出了 LLMs 的优势和局限性，并为未来测试生成能力的改进提供了方向。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.5; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02866v1",
      "published_date": "2025-02-05 03:51:44 UTC",
      "updated_date": "2025-02-05 03:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:47:34.827059"
    },
    {
      "arxiv_id": "2502.02863v2",
      "title": "OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change",
      "title_zh": "OceanChat: 虚拟对话AI代理对可持续态度和行为改变的影响",
      "authors": [
        "Pat Pataranutaporn",
        "Alexander Doudkin",
        "Pattie Maes"
      ],
      "abstract": "Marine ecosystems face unprecedented threats from climate change and plastic\npollution, yet traditional environmental education often struggles to translate\nawareness into sustained behavioral change. This paper presents OceanChat, an\ninteractive system leveraging large language models to create conversational AI\nagents represented as animated marine creatures -- specifically a beluga whale,\na jellyfish, and a seahorse -- designed to promote environmental behavior (PEB)\nand foster awareness through personalized dialogue. Through a between-subjects\nexperiment (N=900), we compared three conditions: (1) Static Scientific\nInformation, providing conventional environmental education through text and\nimages; (2) Static Character Narrative, featuring first-person storytelling\nfrom 3D-rendered marine creatures; and (3) Conversational Character Narrative,\nenabling real-time dialogue with AI-powered marine characters. Our analysis\nrevealed that the Conversational Character Narrative condition significantly\nincreased behavioral intentions and sustainable choice preferences compared to\nstatic approaches. The beluga whale character demonstrated consistently\nstronger emotional engagement across multiple measures, including perceived\nanthropomorphism and empathy. However, impacts on deeper measures like climate\npolicy support and psychological distance were limited, highlighting the\ncomplexity of shifting entrenched beliefs. Our work extends research on\nsustainability interfaces facilitating PEB and offers design principles for\ncreating emotionally resonant, context-aware AI characters. By balancing\nanthropomorphism with species authenticity, OceanChat demonstrates how\ninteractive narratives can bridge the gap between environmental knowledge and\nreal-world behavior change.",
      "tldr_zh": "这篇论文介绍了 OceanChat 系统，该系统利用大型语言模型创建对话 AI 代理（如 beluga whale、jellyfish 和 seahorse），通过个性化对话促进环境行为（PEB）和可持续态度改变，以应对海洋生态威胁。研究通过一个 N=900 的实验比较了静态科学信息、静态角色叙事和对话角色叙事三种条件，结果显示对话角色叙事显著提高了行为意图和可持续选择偏好，其中 beluga whale 角色在 anthropomorphism 和 empathy 方面表现出色。虽然后者对 climate policy support 和 psychological distance 的影响有限，但该工作扩展了可持续界面研究，并提供了设计原则，强调平衡 anthropomorphism 与 species authenticity 以桥接环境知识与实际行为改变。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 18 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.02863v2",
      "published_date": "2025-02-05 03:45:33 UTC",
      "updated_date": "2025-05-21 10:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:47:47.186968"
    },
    {
      "arxiv_id": "2502.02862v2",
      "title": "Learning Generalizable Features for Tibial Plateau Fracture Segmentation Using Masked Autoencoder and Limited Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Peiyan Yue",
        "Die Cai",
        "Chu Guo",
        "Mengxing Liu",
        "Jun Xia",
        "Yi Wang"
      ],
      "abstract": "Accurate automated segmentation of tibial plateau fractures (TPF) from\ncomputed tomography (CT) requires large amounts of annotated data to train deep\nlearning models, but obtaining such annotations presents unique challenges. The\nprocess demands expert knowledge to identify diverse fracture patterns, assess\nseverity, and account for individual anatomical variations, making the\nannotation process highly time-consuming and expensive. Although\nsemi-supervised learning methods can utilize unlabeled data, existing\napproaches often struggle with the complexity and variability of fracture\nmorphologies, as well as limited generalizability across datasets. To tackle\nthese issues, we propose an effective training strategy based on masked\nautoencoder (MAE) for the accurate TPF segmentation in CT. Our method leverages\nMAE pretraining to capture global skeletal structures and fine-grained fracture\ndetails from unlabeled data, followed by fine-tuning with a small set of\nlabeled data. This strategy reduces the dependence on extensive annotations\nwhile enhancing the model's ability to learn generalizable and transferable\nfeatures. The proposed method is evaluated on an in-house dataset containing\n180 CT scans with TPF. Experimental results demonstrate that our method\nconsistently outperforms semi-supervised methods, achieving an average Dice\nsimilarity coefficient (DSC) of 95.81%, average symmetric surface distance\n(ASSD) of 1.91mm, and Hausdorff distance (95HD) of 9.42mm with only 20\nannotated cases. Moreover, our method exhibits strong transferability when\napplying to another public pelvic CT dataset with hip fractures, highlighting\nits potential for broader applications in fracture segmentation tasks.",
      "tldr_zh": "该研究针对胫骨平台骨折（TPF）分割的挑战，提出了一种基于Masked Autoencoder (MAE)的训练策略，利用无标签数据进行预训练以捕获全局骨骼结构和细粒度骨折细节，随后用少量标注数据微调，从而减少对大量标注的依赖并提升模型的泛化性。  \n实验在包含180个CT扫描的内部数据集上进行，仅使用20个标注病例，该方法就超过了现有半监督方法，实现了平均Dice similarity coefficient (DSC) 95.81%、average symmetric surface distance (ASSD) 1.91mm和Hausdorff distance (95HD) 9.42mm的出色性能。  \n此外，该方法在另一个公共骨盆CT数据集上展示了强转移性，表明其在各种骨折分割任务中的潜在应用价值。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages, 6 figures. Accepted to IEEE EMBC 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02862v2",
      "published_date": "2025-02-05 03:44:52 UTC",
      "updated_date": "2025-04-09 05:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:47:59.935303"
    },
    {
      "arxiv_id": "2502.15732v1",
      "title": "Data Wrangling Task Automation Using Code-Generating Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ashlesha Akella",
        "Krishnasuri Narayanam"
      ],
      "abstract": "Ensuring data quality in large tabular datasets is a critical challenge,\ntypically addressed through data wrangling tasks. Traditional statistical\nmethods, though efficient, cannot often understand the semantic context and\ndeep learning approaches are resource-intensive, requiring task and\ndataset-specific training. To overcome these shortcomings, we present an\nautomated system that utilizes large language models to generate executable\ncode for tasks like missing value imputation, error detection, and error\ncorrection. Our system aims to identify inherent patterns in the data while\nleveraging external knowledge, effectively addressing both memory-dependent and\nmemory-independent tasks.",
      "tldr_zh": "该论文针对大型表格数据集的数据 wrangling 任务（如缺失值填充、错误检测和错误修正）提出了一种自动化系统，使用代码生成语言模型来生成可执行代码。传统统计方法虽高效但无法理解语义上下文，而深度学习方法资源密集且需特定训练，该系统则通过识别数据固有模式并整合外部知识，解决了这些局限。实验结果表明，该系统能有效处理记忆依赖和非记忆依赖任务，提升数据质量保障的效率和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2025 Demo",
      "pdf_url": "http://arxiv.org/pdf/2502.15732v1",
      "published_date": "2025-02-05 03:36:29 UTC",
      "updated_date": "2025-02-05 03:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:48:09.418689"
    },
    {
      "arxiv_id": "2502.02844v2",
      "title": "Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sunwoo Lee",
        "Jaebak Hwang",
        "Yonghyeon Jo",
        "Seungyul Han"
      ],
      "abstract": "Traditional robust methods in multi-agent reinforcement learning (MARL) often\nstruggle against coordinated adversarial attacks in cooperative scenarios. To\naddress this limitation, we propose the Wolfpack Adversarial Attack framework,\ninspired by wolf hunting strategies, which targets an initial agent and its\nassisting agents to disrupt cooperation. Additionally, we introduce the\nWolfpack-Adversarial Learning for MARL (WALL) framework, which trains robust\nMARL policies to defend against the proposed Wolfpack attack by fostering\nsystem-wide collaboration. Experimental results underscore the devastating\nimpact of the Wolfpack attack and the significant robustness improvements\nachieved by WALL.",
      "tldr_zh": "本文提出 Wolfpack Adversarial Attack 框架，灵感来源于狼群狩猎策略，针对多智能体强化学习(MARL)中的合作场景，通过攻击初始代理及其辅助代理来破坏系统协调。针对这一问题，作者引入 WALL (Wolfpack-Adversarial Learning for MARL) 框架，用于训练鲁棒的 MARL 策略，强调系统级合作以防御此类攻击。实验结果显示，Wolfpack 攻击对传统方法具有毁灭性影响，而 WALL 框架显著提升了 MARL 的整体鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages main, 21 pages appendix with reference. Submitted to ICML\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02844v2",
      "published_date": "2025-02-05 02:59:23 UTC",
      "updated_date": "2025-02-14 13:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:48:22.494838"
    },
    {
      "arxiv_id": "2502.06816v1",
      "title": "DeepCell: Multiview Representation Learning for Post-Mapping Netlists",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyuan Shi",
        "Chengyu Ma",
        "Ziyang Zheng",
        "Lingfeng Zhou",
        "Hongyang Pan",
        "Wentao Jiang",
        "Fan Yang",
        "Xiaoyan Yang",
        "Zhufei Chu",
        "Qiang Xu"
      ],
      "abstract": "Representation learning for post-mapping (PM) netlists is a critical\nchallenge in Electronic Design Automation (EDA), driven by the diverse and\ncomplex nature of modern circuit designs. Existing approaches focus on\nintermediate representations like And-Inverter Graphs (AIGs), limiting their\napplicability to post-synthesis stages. We introduce DeepCell, a multiview\nrepresentation learning framework that integrates structural and functional\ninsights from both PM netlists and AIGs to learn rich, generalizable\nembeddings. At its core, DeepCell employs the novel Mask Circuit Modeling (MCM)\nmechanism, which refines PM netlist representations in a self-supervised manner\nusing pretrained AIG encoders. DeepCell sets a new benchmark in PM netlist\nrepresentation, outperforming existing methods in predictive accuracy and\nreconstruction fidelity. To validate its efficacy, we apply DeepCell to\nfunctional Engineering Change Orders (ECO), achieving significant reductions in\npatch generation costs and runtime while improving patch quality.",
      "tldr_zh": "该论文针对电子设计自动化 (EDA) 中的后映射 (Post-Mapping) 网表表示学习挑战，提出 DeepCell 框架——一种多视图表示学习方法，通过整合 PM 网表和 And-Inverter Graphs (AIGs) 的结构与功能洞见，学习出丰富且可泛化的嵌入表示。DeepCell 的核心是新型 Mask Circuit Modeling (MCM) 机制，利用自监督学习和预训练 AIG 编码器来细化 PM 网表表示。实验验证显示，DeepCell 在预测准确性和重建保真度上优于现有方法，并在功能 Engineering Change Orders (ECO) 应用中实现了补丁生成成本和运行时间的显著降低，同时提高了补丁质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06816v1",
      "published_date": "2025-02-05 02:39:47 UTC",
      "updated_date": "2025-02-05 02:39:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:48:35.956978"
    },
    {
      "arxiv_id": "2502.02834v2",
      "title": "Task-Aware Virtual Training: Enhancing Generalization in Meta-Reinforcement Learning for Out-of-Distribution Tasks",
      "title_zh": "任务感知虚拟训练：增强元强化学习中",
      "authors": [
        "Jeongmo Kim",
        "Yisak Park",
        "Minung Kim",
        "Seungyul Han"
      ],
      "abstract": "Meta reinforcement learning aims to develop policies that generalize to\nunseen tasks sampled from a task distribution. While context-based meta-RL\nmethods improve task representation using task latents, they often struggle\nwith out-of-distribution (OOD) tasks. To address this, we propose Task-Aware\nVirtual Training (TAVT), a novel algorithm that accurately captures task\ncharacteristics for both training and OOD scenarios using metric-based\nrepresentation learning. Our method successfully preserves task characteristics\nin virtual tasks and employs a state regularization technique to mitigate\noverestimation errors in state-varying environments. Numerical results\ndemonstrate that TAVT significantly enhances generalization to OOD tasks across\nvarious MuJoCo and MetaWorld environments.",
      "tldr_zh": "元强化学习（Meta reinforcement learning）旨在开发能泛化到未见任务的策略，但基于上下文的方法往往在处理 out-of-distribution (OOD) 任务时表现不佳。论文提出 Task-Aware Virtual Training (TAVT)，一个新算法，通过基于度量的表示学习准确捕捉任务特征，并适用于训练和 OOD 场景。该方法在虚拟任务中保留任务特性，并采用状态正则化技术来减少环境变化中的过估计错误。实验结果显示，TAVT 在 MuJoCo 和 MetaWorld 环境中显著提升了对 OOD 任务的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages main paper, 19 pages appendices with reference, Submitted to\n  ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02834v2",
      "published_date": "2025-02-05 02:31:50 UTC",
      "updated_date": "2025-02-14 11:19:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:48:47.981898"
    },
    {
      "arxiv_id": "2502.04361v1",
      "title": "Predicting 3D Motion from 2D Video for Behavior-Based VR Biometrics",
      "title_zh": "基于 2D 视频预测 3D 运动，用于行为驱动的 VR 生物识别",
      "authors": [
        "Mingjun Li",
        "Natasha Kholgade Banerjee",
        "Sean Banerjee"
      ],
      "abstract": "Critical VR applications in domains such as healthcare, education, and\nfinance that use traditional credentials, such as PIN, password, or\nmulti-factor authentication, stand the chance of being compromised if a\nmalicious person acquires the user credentials or if the user hands over their\ncredentials to an ally. Recently, a number of approaches on user authentication\nhave emerged that use motions of VR head-mounted displays (HMDs) and hand\ncontrollers during user interactions in VR to represent the user's behavior as\na VR biometric signature. One of the fundamental limitations of behavior-based\napproaches is that current on-device tracking for HMDs and controllers lacks\ncapability to perform tracking of full-body joint articulation, losing key\nsignature data encapsulated by the user articulation. In this paper, we propose\nan approach that uses 2D body joints, namely shoulder, elbow, wrist, hip, knee,\nand ankle, acquired from the right side of the participants using an external\n2D camera. Using a Transformer-based deep neural network, our method uses the\n2D data of body joints that are not tracked by the VR device to predict past\nand future 3D tracks of the right controller, providing the benefit of\naugmenting 3D knowledge in authentication. Our approach provides a minimum\nequal error rate (EER) of 0.025, and a maximum EER drop of 0.040 over prior\nwork that uses single-unit 3D trajectory as the input.",
      "tldr_zh": "该论文针对 VR 生物特征认证的安全问题，提出一种从 2D 视频预测 3D 动作的方法，以解决现有 VR 设备无法追踪全身体节的局限性。主要方法使用外部 2D 相机捕获参与者右侧身体关节（如肩、肘、手腕、髋、膝、踝）的 2D 数据，并通过 Transformer-based 深度神经网络预测过去和未来的 3D 手柄轨迹，从而增强认证的准确性和鲁棒性。实验结果显示，该方法的最低等错误率 (EER) 为 0.025，比先前仅使用单单位 3D 轨迹的方法降低了最多 0.040，为基于行为的 VR 认证提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE AIxVR 2025: 7th International Conference on Artificial\n  Intelligence & extended and Virtual Reality",
      "pdf_url": "http://arxiv.org/pdf/2502.04361v1",
      "published_date": "2025-02-05 02:19:23 UTC",
      "updated_date": "2025-02-05 02:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:48:59.519176"
    },
    {
      "arxiv_id": "2502.03492v1",
      "title": "Teaching Language Models to Critique via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihui Xie",
        "Jie chen",
        "Liyu Chen",
        "Weichao Mao",
        "Jingjing Xu",
        "Lingpeng Kong"
      ],
      "abstract": "Teaching large language models (LLMs) to critique and refine their outputs is\ncrucial for building systems that can iteratively improve, yet it is\nfundamentally limited by the ability to provide accurate judgments and\nactionable suggestions. In this work, we study LLM critics for code generation\nand propose $\\texttt{CTRL}$, a framework for $\\texttt{C}$ritic\n$\\texttt{T}$raining via $\\texttt{R}$einforcement $\\texttt{L}$earning, which\ntrains a critic model to generate feedback that maximizes correction\nperformance for a fixed generator model without human supervision. Our results\ndemonstrate that critics trained with $\\texttt{CTRL}$ significantly enhance\npass rates and mitigate compounding errors across both base and stronger\ngenerator models. Furthermore, we show that these critic models act as accurate\ngenerative reward models and enable test-time scaling through iterative\ncritique-revision, achieving up to 106.1% relative improvements across\nchallenging code generation benchmarks.",
      "tldr_zh": "这篇论文提出 CTRL 框架，通过强化学习训练大型语言模型（LLMs）的批评者模块，旨在帮助模型在代码生成任务中提供准确反馈和改进输出，而无需人工监督。CTRL 让批评者模型针对固定生成器模型生成优化反馈，从而最大化修正性能并减少错误积累。实验结果显示，该方法显著提升了代码生成的通过率，并在挑战性基准测试中实现了高达 106.1% 的相对改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03492v1",
      "published_date": "2025-02-05 02:18:46 UTC",
      "updated_date": "2025-02-05 02:18:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:49:10.577892"
    },
    {
      "arxiv_id": "2503.04740v1",
      "title": "PRISM: Perspective Reasoning for Integrated Synthesis and Mediation as a Multi-Perspective Framework for AI Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Diamond"
      ],
      "abstract": "In this work, we propose Perspective Reasoning for Integrated Synthesis and\nMediation (PRISM), a multiple-perspective framework for addressing persistent\nchallenges in AI alignment such as conflicting human values and specification\ngaming. Grounded in cognitive science and moral psychology, PRISM organizes\nmoral concerns into seven \"basis worldviews\", each hypothesized to capture a\ndistinct dimension of human moral cognition, ranging from survival-focused\nreflexes through higher-order integrative perspectives. It then applies a\nPareto-inspired optimization scheme to reconcile competing priorities without\nreducing them to a single metric. Under the assumption of reliable context\nvalidation for robust use, the framework follows a structured workflow that\nelicits viewpoint-specific responses, synthesizes them into a balanced outcome,\nand mediates remaining conflicts in a transparent and iterative manner. By\nreferencing layered approaches to moral cognition from cognitive science, moral\npsychology, and neuroscience, PRISM clarifies how different moral drives\ninteract and systematically documents and mediates ethical tradeoffs. We\nillustrate its efficacy through real outputs produced by a working prototype,\napplying PRISM to classic alignment problems in domains such as public health\npolicy, workplace automation, and education. By anchoring AI deliberation in\nthese human vantage points, PRISM aims to bound interpretive leaps that might\notherwise drift into non-human or machine-centric territory. We briefly outline\nfuture directions, including real-world deployments and formal verifications,\nwhile maintaining the core focus on multi-perspective synthesis and conflict\nmediation.",
      "tldr_zh": "本研究提出 PRISM 框架（Perspective Reasoning for Integrated Synthesis and Mediation），作为一种多视角方法，用于解决 AI alignment 中的挑战，如冲突的人类价值观和 specification gaming。PRISM 基于认知科学和道德心理学，将道德关切组织成七个 basis worldviews，这些视角覆盖从生存反射到高级整合的人类道德认知维度，并采用 Pareto-inspired optimization 方案来调和竞争优先级，而非简化成单一指标。框架的工作流程包括提取观点特定响应、合成平衡结果以及透明迭代调解冲突，通过原型应用展示了其在公共健康政策、工作场所自动化和教育领域的功效，最终旨在使 AI 决策更贴合人类视角，并为未来部署和正式验证铺平道路。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "90C29, 68T05",
        "I.2.11; I.2.4"
      ],
      "primary_category": "cs.CY",
      "comment": "104 pages, 5 figures. Preprint on AI alignment presenting PRISM: a\n  multi-perspective framework that organizes moral concerns into seven basis\n  worldviews and uses Pareto-inspired synthesis to reconcile conflicting human\n  values and specification gaming. Grounded in cognitive science and moral\n  psychology",
      "pdf_url": "http://arxiv.org/pdf/2503.04740v1",
      "published_date": "2025-02-05 02:13:57 UTC",
      "updated_date": "2025-02-05 02:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:49:23.815981"
    },
    {
      "arxiv_id": "2502.03490v2",
      "title": "Examining Two Hop Reasoning Through Information Content Scaling",
      "title_zh": "通过信息内容缩放考察两跳推理",
      "authors": [
        "David Johnston",
        "Nora Belrose"
      ],
      "abstract": "Prior work has found that transformers have an inconsistent ability to learn\nto answer latent two-hop questions -- questions of the form \"Who is Bob's\nmother's boss?\" We study why this is the case by examining how transformers'\ncapacity to learn datasets of two-hop questions and answers (two-hop QA) scales\nwith their size, motivated by prior work on transformer knowledge capacity for\nsimple factual memorization. We find that capacity scaling and generalization\nboth support the hypothesis that latent two-hop QA requires transformers to\nlearn each fact twice, while two-hop QA with chain of thought does not. We also\nshow that with appropriate dataset parameters, it is possible to \"trap\" very\nsmall models in a regime where they memorize answers to two-hop questions\nindependently, even though they would perform better if they could learn to\nanswer them with function composition. Our findings show that measurement of\ncapacity scaling can complement existing interpretability methods, though there\nare challenges in using it for this purpose.",
      "tldr_zh": "本文通过信息内容缩放（Information Content Scaling）研究Transformer模型学习两跳问答（two-hop QA）的能力随模型大小的变化。研究发现，潜在的两跳QA需要模型重复学习每个事实两次，而采用Chain of Thought的方法则能避免此问题，从而提升泛化性能。同时，实验显示，通过调整数据集参数，可以使小型模型陷入独立记忆答案的模式，即使函数组合能带来更好表现。这些发现表明，容量扩展测量可作为可解释性方法的补充，但也存在应用挑战。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03490v2",
      "published_date": "2025-02-05 02:13:04 UTC",
      "updated_date": "2025-03-21 03:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:49:35.540748"
    },
    {
      "arxiv_id": "2502.02817v1",
      "title": "A Decade of Action Quality Assessment: Largest Systematic Survey of Trends, Challenges, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yin",
        "Paritosh Parmar",
        "Daoliang Xu",
        "Yang Zhang",
        "Tianyou Zheng",
        "Weiwei Fu"
      ],
      "abstract": "Action Quality Assessment (AQA) -- the ability to quantify the quality of\nhuman motion, actions, or skill levels and provide feedback -- has far-reaching\nimplications in areas such as low-cost physiotherapy, sports training, and\nworkforce development. As such, it has become a critical field in computer\nvision & video understanding over the past decade. Significant progress has\nbeen made in AQA methodologies, datasets, & applications, yet a pressing need\nremains for a comprehensive synthesis of this rapidly evolving field. In this\npaper, we present a thorough survey of the AQA landscape, systematically\nreviewing over 200 research papers using the preferred reporting items for\nsystematic reviews & meta-analyses (PRISMA) framework. We begin by covering\nfoundational concepts & definitions, then move to general frameworks &\nperformance metrics, & finally discuss the latest advances in methodologies &\ndatasets. This survey provides a detailed analysis of research trends,\nperformance comparisons, challenges, & future directions. Through this work, we\naim to offer a valuable resource for both newcomers & experienced researchers,\npromoting further exploration & progress in AQA. Data are available at\nhttps://haoyin116.github.io/Survey_of_AQA/",
      "tldr_zh": "这篇论文对过去十年的 Action Quality Assessment (AQA) 领域进行了最大规模的系统调查，涵盖了研究趋势、挑战和未来方向，强调 AQA 在物理疗法、体育训练和工作发展等领域的应用。作者使用 PRISMA 框架系统审查了超过 200 篇论文，讨论了基础概念、一般框架、性能指标以及最新方法和数据集。调查分析了研究进展、性能比较和关键挑战，并为新手和经验丰富的研究人员提供宝贵资源，促进 AQA 领域的进一步探索，相关数据可从 https://haoyin116.github.io/Survey_of_AQA/ 获取。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "36 Pages, 20 Figures, 12 Tables",
      "pdf_url": "http://arxiv.org/pdf/2502.02817v1",
      "published_date": "2025-02-05 01:33:24 UTC",
      "updated_date": "2025-02-05 01:33:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:49:47.463680"
    },
    {
      "arxiv_id": "2502.02810v1",
      "title": "Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization",
      "title_zh": "Mol-LLM：改进图结构利用的通用分子大语言模型",
      "authors": [
        "Chanhui Lee",
        "Yuheon Song",
        "YongJun Jeong",
        "Hanbum Ko",
        "Rodrigo Hormazabal",
        "Sehui Han",
        "Kyunghoon Bae",
        "Sungbin Lim",
        "Sungwoong Kim"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have motivated the\ndevelopment of general LLMs for molecular tasks. While several studies have\ndemonstrated that fine-tuned LLMs can achieve impressive benchmark\nperformances, they are far from genuine generalist molecular LLMs due to a lack\nof fundamental understanding of molecular structure. Specifically, when given\nmolecular task instructions, LLMs trained with naive next-token prediction\ntraining assign similar likelihood scores to both original and negatively\ncorrupted molecules, revealing their lack of molecular structure understanding\nthat is crucial for reliable and general molecular LLMs. To overcome this\nlimitation and obtain a true generalist molecular LLM, we introduce a novel\nmulti-modal training method based on a thorough multi-modal instruction tuning\nas well as a molecular structure preference optimization between chosen and\nrejected graphs. On various molecular benchmarks, the proposed generalist\nmolecular LLM, called Mol-LLM, achieves state-of-the-art performances among\ngeneralist LLMs on most tasks, at the same time, surpassing or comparable to\nstate-of-the-art specialist LLMs. Moreover, Mol-LLM also shows superior\ngeneralization performances in reaction prediction tasks, demonstrating the\neffect of the molecular structure understanding for generalization perspective.",
      "tldr_zh": "本研究针对现有Large Language Models (LLMs) 在分子任务中缺乏分子结构理解的问题，提出Mol-LLM，一种改进图结构利用的通用分子LLM。Mol-LLM 通过新型多模态训练方法，包括彻底的多模态指令微调和分子结构偏好优化（在chosen和rejected graphs之间），来提升模型对分子结构的根本理解。实验结果显示，Mol-LLM 在各种分子基准测试中，超越其他通用LLM 并与专业LLM 相当或优于后者，并在反应预测任务中表现出色泛化性能，证明了分子结构理解对可靠性和泛化性的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02810v1",
      "published_date": "2025-02-05 01:14:12 UTC",
      "updated_date": "2025-02-05 01:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:49:59.120879"
    },
    {
      "arxiv_id": "2502.02797v1",
      "title": "Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting",
      "title_zh": "在微调中增加容易样本的权重以减轻遗忘",
      "authors": [
        "Sunny Sanyal",
        "Hayden Prairie",
        "Rudrajit Das",
        "Ali Kavis",
        "Sujay Sanghavi"
      ],
      "abstract": "Fine-tuning a pre-trained model on a downstream task often degrades its\noriginal capabilities, a phenomenon known as \"catastrophic forgetting\". This is\nespecially an issue when one does not have access to the data and recipe used\nto develop the pre-trained model. Under this constraint, most existing methods\nfor mitigating forgetting are inapplicable. To address this challenge, we\npropose a sample weighting scheme for the fine-tuning data solely based on the\npre-trained model's losses. Specifically, we upweight the easy samples on which\nthe pre-trained model's loss is low and vice versa to limit the drift from the\npre-trained model. Our approach is orthogonal and yet complementary to existing\nmethods; while such methods mostly operate on parameter or gradient space, we\nconcentrate on the sample space. We theoretically analyze the impact of\nfine-tuning with our method in a linear setting, showing that it stalls\nlearning in a certain subspace which inhibits overfitting to the target task.\nWe empirically demonstrate the efficacy of our method on both language and\nvision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our\nmethod results in only a $0.8\\%$ drop in accuracy on GSM8K (another math\ndataset) compared to standard fine-tuning, while preserving $5.4\\%$ more\naccuracy on the pre-training datasets. Our code is publicly available at\nhttps://github.com/sanyalsunny111/FLOW_finetuning .",
      "tldr_zh": "本研究针对微调预训练模型时出现的灾难性遗忘（catastrophic forgetting）问题，提出了一种基于预训练模型损失的样本加权方案。具体而言，该方案对预训练模型损失低的易样本（easy samples）增加权重，同时减少难样本权重，以限制模型从预训练状态的漂移。理论分析表明，该方法在线性设置中能阻止某些子空间的学习，从而抑制过度拟合。实验结果显示，在语言和视觉任务上，该方法有效减少遗忘，例如微调 Gemma 2 2B 时，仅导致 GSM8K 准确率下降 0.8%，并比标准微调多保留 5.4% 的预训练数据集准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "49 pages, 4 figures, 12 tables. Code available at\n  https://github.com/sanyalsunny111/FLOW_finetuning",
      "pdf_url": "http://arxiv.org/pdf/2502.02797v1",
      "published_date": "2025-02-05 00:49:59 UTC",
      "updated_date": "2025-02-05 00:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:50:14.549714"
    },
    {
      "arxiv_id": "2502.02789v2",
      "title": "Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyu Liu",
        "Beidi Chen",
        "Ce Zhang"
      ],
      "abstract": "Improving time-to-first-token (TTFT) is an essentially important objective in\nmodern large language model (LLM) inference engines. Optimizing TTFT directly\nresults in higher maximal QPS and meets the requirements of many critical\napplications. However, boosting TTFT is notoriously challenging since it is\ncompute-bounded and the performance bottleneck shifts from the self-attention\nthat many prior works focus on to the MLP part. In this work, we present\nSpecPrefill, a training free framework that accelerates the inference TTFT for\nboth long and medium context queries based on the following insight: LLMs are\ngeneralized enough to preserve the quality given only a carefully chosen subset\nof prompt tokens. At its core, SpecPrefill leverages a lightweight model to\nspeculate locally important tokens based on the context. These tokens, along\nwith the necessary positional information, are then sent to the main model for\nprocessing. We evaluate SpecPrefill with a diverse set of tasks, followed by a\ncomprehensive benchmarking of performance improvement both in a real end-to-end\nsetting and ablation studies. SpecPrefill manages to serve\nLlama-3.1-405B-Instruct-FP8 with up to 7$\\times$ maximal end-to-end QPS on real\ndownstream tasks and 7.66$\\times$ TTFT improvement.",
      "tldr_zh": "该研究提出SpecPrefill框架，一种无需训练的轻量级方法，用于加速大型语言模型(LLM)的time-to-first-token(TTFT)，以提升最大QPS并解决计算瓶颈从self-attention转移到MLP部分的问题。SpecPrefill的核心是利用轻量级模型估计算法上下文中的本地重要tokens，并将这些tokens及其位置信息发送到主模型处理，从而在保持输出质量的同时减少计算开销。实验结果显示，在各种任务上，SpecPrefill使Llama-3.1-405B-Instruct-FP8的端到端QPS提高高达7倍，TTFT改善达7.66倍。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (ICML 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.02789v2",
      "published_date": "2025-02-05 00:22:06 UTC",
      "updated_date": "2025-05-19 18:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:50:23.229187"
    },
    {
      "arxiv_id": "2502.02788v1",
      "title": "Inducing Diversity in Differentiable Search Indexing",
      "title_zh": "翻译失败",
      "authors": [
        "Abhijeet Phatak",
        "Jayant Sachdev",
        "Sean D Rosario",
        "Swati Kirti",
        "Chittaranjan Tripathy"
      ],
      "abstract": "Differentiable Search Indexing (DSI) is a recent paradigm for information\nretrieval which uses a transformer-based neural network architecture as the\ndocument index to simplify the retrieval process. A differentiable index has\nmany advantages enabling modifications, updates or extensions to the index. In\nthis work, we explore balancing relevance and novel information content\n(diversity) for training DSI systems inspired by Maximal Marginal Relevance\n(MMR), and show the benefits of our approach over the naive DSI training. We\npresent quantitative and qualitative evaluations of relevance and diversity\nmeasures obtained using our method on NQ320K and MSMARCO datasets in comparison\nto naive DSI. With our approach, it is possible to achieve diversity without\nany significant impact to relevance. Since we induce diversity while training\nDSI, the trained model has learned to diversify while being relevant. This\nobviates the need for a post-processing step to induce diversity in the recall\nset as typically performed using MMR. Our approach will be useful for\nInformation Retrieval problems where both relevance and diversity are important\nsuch as in sub-topic retrieval. Our work can also be easily be extended to the\nincremental DSI settings which would enable fast updates to the index while\nretrieving a diverse recall set.",
      "tldr_zh": "本研究探讨了在 Differentiable Search Indexing (DSI) 中引入多样性，以平衡检索的相关性和新颖信息内容。受 Maximal Marginal Relevance (MMR) 启发，作者提出了一种训练方法，在 DSI 系统训练过程中同时优化相关性和多样性，避免了传统后处理步骤。实验在 NQ320K 和 MSMARCO 数据集上显示，该方法显著提升了多样性，同时相关性几乎不受影响。总体而言，此方法为需要兼顾相关性和多样性的信息检索任务（如子主题检索）提供了高效解决方案，并易于扩展到增量 DSI 设置中。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02788v1",
      "published_date": "2025-02-05 00:21:17 UTC",
      "updated_date": "2025-02-05 00:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:50:35.631874"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 170,
  "processed_papers_count": 170,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T07:50:56.286552"
}