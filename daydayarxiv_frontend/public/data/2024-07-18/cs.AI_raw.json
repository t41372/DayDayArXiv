[
  {
    "arxiv_id": "2407.13948v2",
    "title": "Assurance of AI Systems From a Dependability Perspective",
    "authors": [
      "Robin Bloomfield",
      "John Rushby"
    ],
    "abstract": "We outline the principles of classical assurance for computer-based systems\nthat pose significant risks. We then consider application of these principles\nto systems that employ Artificial Intelligence (AI) and Machine Learning (ML).\n  A key element in this \"dependability\" perspective is a requirement to have\nnear-complete understanding of the behavior of critical components, and this is\nconsidered infeasible for AI and ML. Hence the dependability perspective aims\nto minimize trust in AI and ML elements by using \"defense in depth\" with a\nhierarchy of less complex systems, some of which may be highly assured\nconventionally engineered components, to \"guard\" them. This may be contrasted\nwith the \"trustworthy\" perspective that seeks to apply assurance to the AI and\nML elements themselves.\n  In cyber-physical and many other systems, it is difficult to provide guards\nthat do not depend on AI and ML to perceive their environment (e.g., other\nvehicles sharing the road with a self-driving car), so both perspectives are\nneeded and there is a continuum or spectrum between them. We focus on\narchitectures toward the dependability end of the continuum and invite others\nto consider additional points along the spectrum.\n  For guards that require perception using AI and ML, we examine ways to\nminimize the trust placed in these elements; they include diversity, defense in\ndepth, explanations, and micro-ODDs. We also examine methods to enforce\nacceptable behavior, given a model of the world. These include classical\ncyber-physical calculations and envelopes, and normative rules based on\noverarching principles, constitutions, ethics, or reputation. We apply our\nperspective to autonomous systems, AI systems for specific functions, generic\nAI such as Large Language Models, and to Artificial General Intelligence (AGI),\nand we propose current best practice and an agenda for research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13948v2",
    "published_date": "2024-07-18 23:55:43 UTC",
    "updated_date": "2024-08-07 22:40:12 UTC"
  },
  {
    "arxiv_id": "2407.13943v1",
    "title": "Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction",
    "authors": [
      "Suma Bailis",
      "Jane Friedhoff",
      "Feiyang Chen"
    ],
    "abstract": "This paper introduces Werewolf Arena, a novel framework for evaluating large\nlanguage models (LLMs) through the lens of the classic social deduction game,\nWerewolf. In Werewolf Arena, LLMs compete against each other, navigating the\ngame's complex dynamics of deception, deduction, and persuasion. The framework\nintroduces a dynamic turn-taking system based on bidding, mirroring real-world\ndiscussions where individuals strategically choose when to speak. We\ndemonstrate the framework's utility through an arena-style tournament featuring\nGemini and GPT models. Our results reveal distinct strengths and weaknesses in\nthe models' strategic reasoning and communication. These findings highlight\nWerewolf Arena's potential as a challenging and scalable LLM benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.13943v1",
    "published_date": "2024-07-18 23:41:05 UTC",
    "updated_date": "2024-07-18 23:41:05 UTC"
  },
  {
    "arxiv_id": "2407.13930v1",
    "title": "RT-Pose: A 4D Radar Tensor-based 3D Human Pose Estimation and Localization Benchmark",
    "authors": [
      "Yuan-Hao Ho",
      "Jen-Hao Cheng",
      "Sheng Yao Kuan",
      "Zhongyu Jiang",
      "Wenhao Chai",
      "Hsiang-Wei Huang",
      "Chih-Lung Lin",
      "Jenq-Neng Hwang"
    ],
    "abstract": "Traditional methods for human localization and pose estimation (HPE), which\nmainly rely on RGB images as an input modality, confront substantial\nlimitations in real-world applications due to privacy concerns. In contrast,\nradar-based HPE methods emerge as a promising alternative, characterized by\ndistinctive attributes such as through-wall recognition and privacy-preserving,\nrendering the method more conducive to practical deployments. This paper\npresents a Radar Tensor-based human pose (RT-Pose) dataset and an open-source\nbenchmarking framework. The RT-Pose dataset comprises 4D radar tensors, LiDAR\npoint clouds, and RGB images, and is collected for a total of 72k frames across\n240 sequences with six different complexity-level actions. The 4D radar tensor\nprovides raw spatio-temporal information, differentiating it from other radar\npoint cloud-based datasets. We develop an annotation process using RGB images\nand LiDAR point clouds to accurately label 3D human skeletons. In addition, we\npropose HRRadarPose, the first single-stage architecture that extracts the\nhigh-resolution representation of 4D radar tensors in 3D space to aid human\nkeypoint estimation. HRRadarPose outperforms previous radar-based HPE work on\nthe RT-Pose benchmark. The overall HRRadarPose performance on the RT-Pose\ndataset, as reflected in a mean per joint position error (MPJPE) of 9.91cm,\nindicates the persistent challenges in achieving accurate HPE in complex\nreal-world scenarios. RT-Pose is available at\nhttps://huggingface.co/datasets/uwipl/RT-Pose.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13930v1",
    "published_date": "2024-07-18 22:46:35 UTC",
    "updated_date": "2024-07-18 22:46:35 UTC"
  },
  {
    "arxiv_id": "2407.13929v2",
    "title": "Unmasking Social Bots: How Confident Are We?",
    "authors": [
      "James Giroux",
      "Ariyarathne Gangani",
      "Alexander C. Nwala",
      "Cristiano Fanelli"
    ],
    "abstract": "Social bots remain a major vector for spreading disinformation on social\nmedia and a menace to the public. Despite the progress made in developing\nmultiple sophisticated social bot detection algorithms and tools, bot detection\nremains a challenging, unsolved problem that is fraught with uncertainty due to\nthe heterogeneity of bot behaviors, training data, and detection algorithms.\nDetection models often disagree on whether to label the same account as bot or\nhuman-controlled. However, they do not provide any measure of uncertainty to\nindicate how much we should trust their results. We propose to address both bot\ndetection and the quantification of uncertainty at the account level - a novel\nfeature of this research. This dual focus is crucial as it allows us to\nleverage additional information related to the quantified uncertainty of each\nprediction, thereby enhancing decision-making and improving the reliability of\nbot classifications. Specifically, our approach facilitates targeted\ninterventions for bots when predictions are made with high confidence and\nsuggests caution (e.g., gathering more data) when predictions are uncertain.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "15 pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.13929v2",
    "published_date": "2024-07-18 22:33:52 UTC",
    "updated_date": "2025-03-02 18:17:11 UTC"
  },
  {
    "arxiv_id": "2407.13926v2",
    "title": "Report on the Conference on Ethical and Responsible Design in the National AI Institutes: A Summary of Challenges",
    "authors": [
      "Sherri Lynn Conklin",
      "Sue Bae",
      "Gaurav Sett",
      "Michael Hoffmann",
      "Justin B. Biddle"
    ],
    "abstract": "In May 2023, the Georgia Tech Ethics, Technology, and Human Interaction\nCenter organized the Conference on Ethical and Responsible Design in the\nNational AI Institutes. Representatives from the National AI Research\nInstitutes that had been established as of January 2023 were invited to attend;\nresearchers representing 14 Institutes attended and participated. The\nconference focused on three questions: What are the main challenges that the\nNational AI Institutes are facing with regard to the responsible design of AI\nsystems? What are promising lines of inquiry to address these challenges? What\nare possible points of collaboration? Over the course of the conference, a\nrevised version of the first question became a focal point: What are the\nchallenges that the Institutes face in identifying ethical and responsible\ndesign practices and in implementing them in the AI development process? This\ndocument summarizes the challenges that representatives from the Institutes in\nattendance highlighted.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.13926v2",
    "published_date": "2024-07-18 22:30:08 UTC",
    "updated_date": "2024-11-12 19:41:21 UTC"
  },
  {
    "arxiv_id": "2407.13922v2",
    "title": "Synthetic Counterfactual Faces",
    "authors": [
      "Guruprasad V Ramesh",
      "Harrison Rosenberg",
      "Ashish Hooda",
      "Shimaa Ahmed Kassem Fawaz"
    ],
    "abstract": "Computer vision systems have been deployed in various applications involving\nbiometrics like human faces. These systems can identify social media users,\nsearch for missing persons, and verify identity of individuals. While computer\nvision models are often evaluated for accuracy on available benchmarks, more\nannotated data is necessary to learn about their robustness and fairness\nagainst semantic distributional shifts in input data, especially in face data.\nAmong annotated data, counterfactual examples grant strong explainability\ncharacteristics. Because collecting natural face data is prohibitively\nexpensive, we put forth a generative AI-based framework to construct targeted,\ncounterfactual, high-quality synthetic face data. Our synthetic data pipeline\nhas many use cases, including face recognition systems sensitivity evaluations\nand image understanding system probes. The pipeline is validated with multiple\nuser studies. We showcase the efficacy of our face generation pipeline on a\nleading commercial vision model. We identify facial attributes that cause\nvision systems to fail.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper under review. Full text and results will be updated after\n  acceptance",
    "pdf_url": "http://arxiv.org/pdf/2407.13922v2",
    "published_date": "2024-07-18 22:22:49 UTC",
    "updated_date": "2024-07-29 18:29:50 UTC"
  },
  {
    "arxiv_id": "2407.13920v1",
    "title": "DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention",
    "authors": [
      "Xiaoya Tang",
      "Bodong Zhang",
      "Beatrice S. Knudsen",
      "Tolga Tasdizen"
    ],
    "abstract": "We here propose a novel hierarchical transformer model that adeptly\nintegrates the feature extraction capabilities of Convolutional Neural Networks\n(CNNs) with the advanced representational potential of Vision Transformers\n(ViTs). Addressing the lack of inductive biases and dependence on extensive\ntraining datasets in ViTs, our model employs a CNN backbone to generate\nhierarchical visual representations. These representations are then adapted for\ntransformer input through an innovative patch tokenization. We also introduce a\n'scale attention' mechanism that captures cross-scale dependencies,\ncomplementing patch attention to enhance spatial understanding and preserve\nglobal perception. Our approach significantly outperforms baseline models on\nsmall and medium-sized medical datasets, demonstrating its efficiency and\ngeneralizability. The components are designed as plug-and-play for different\nCNN architectures and can be adapted for multiple applications. The code is\navailable at https://github.com/xiaoyatang/DuoFormer.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.13920v1",
    "published_date": "2024-07-18 22:15:35 UTC",
    "updated_date": "2024-07-18 22:15:35 UTC"
  },
  {
    "arxiv_id": "2407.13917v1",
    "title": "LinSATNet: The Positive Linear Satisfiability Neural Networks",
    "authors": [
      "Runzhong Wang",
      "Yunhao Zhang",
      "Ziao Guo",
      "Tianyi Chen",
      "Xiaokang Yang",
      "Junchi Yan"
    ],
    "abstract": "Encoding constraints into neural networks is attractive. This paper studies\nhow to introduce the popular positive linear satisfiability to neural networks.\nWe propose the first differentiable satisfiability layer based on an extension\nof the classic Sinkhorn algorithm for jointly encoding multiple sets of\nmarginal distributions. We further theoretically characterize the convergence\nproperty of the Sinkhorn algorithm for multiple marginals. In contrast to the\nsequential decision e.g.\\ reinforcement learning-based solvers, we showcase our\ntechnique in solving constrained (specifically satisfiability) problems by\none-shot neural networks, including i) a neural routing solver learned without\nsupervision of optimal solutions; ii) a partial graph matching network handling\ngraphs with unmatchable outliers on both sides; iii) a predictive network for\nfinancial portfolios with continuous constraints. To our knowledge, there\nexists no one-shot neural solver for these scenarios when they are formulated\nas satisfiability problems. Source code is available at\nhttps://github.com/Thinklab-SJTU/LinSATNet",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "This is a revised version of our ICML'23 publication that fixes a\n  minor issue in Eq (11). In Proceedings of the 40th International Conference\n  on Machine Learning (ICML'23)",
    "pdf_url": "http://arxiv.org/pdf/2407.13917v1",
    "published_date": "2024-07-18 22:05:21 UTC",
    "updated_date": "2024-07-18 22:05:21 UTC"
  },
  {
    "arxiv_id": "2407.13906v1",
    "title": "Crafting Efficient Fine-Tuning Strategies for Large Language Models",
    "authors": [
      "Michael Oliver",
      "Guan Wang"
    ],
    "abstract": "This paper addresses the challenges of efficiently fine-tuning large language\nmodels (LLMs) by exploring data efficiency and hyperparameter optimization. We\ninvestigate the minimum data required for effective fine-tuning and propose a\nnovel hyperparameter optimization method that leverages early-stage model\nperformance. Our experiments demonstrate that fine-tuning with as few as 200\nsamples can improve model accuracy from 70\\% to 88\\% in a product attribute\nextraction task. We identify a saturation point of approximately 6,500 samples,\nbeyond which additional data yields diminishing returns. Our proposed bayesian\nhyperparameter optimization method, which evaluates models at 20\\% of total\ntraining time, correlates strongly with final model performance, with 4 out of\n5 top early-stage models remaining in the top 5 at completion. This approach\nled to a 2\\% improvement in accuracy over baseline models when evaluated on an\nindependent test set. These findings offer actionable insights for\npractitioners, potentially reducing computational load and dependency on\nextensive datasets while enhancing overall performance of fine-tuned LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13906v1",
    "published_date": "2024-07-18 21:36:00 UTC",
    "updated_date": "2024-07-18 21:36:00 UTC"
  },
  {
    "arxiv_id": "2408.00005v1",
    "title": "Framework for Curating Speech Datasets and Evaluating ASR Systems: A Case Study for Polish",
    "authors": [
      "Michał Junczyk"
    ],
    "abstract": "Speech datasets available in the public domain are often underutilized\nbecause of challenges in discoverability and interoperability. A comprehensive\nframework has been designed to survey, catalog, and curate available speech\ndatasets, which allows replicable evaluation of automatic speech recognition\n(ASR) systems. A case study focused on the Polish language was conducted; the\nframework was applied to curate more than 24 datasets and evaluate 25\ncombinations of ASR systems and models. This research constitutes the most\nextensive comparison to date of both commercial and free ASR systems for the\nPolish language. It draws insights from 600 system-model-test set evaluations,\nmarking a significant advancement in both scale and comprehensiveness. The\nresults of surveys and performance comparisons are available as interactive\ndashboards (https://huggingface.co/spaces/amu-cai/pl-asr-leaderboard) along\nwith curated datasets (https://huggingface.co/datasets/amu-cai/pl-asr-bigos-v2,\nhttps://huggingface.co/datasets/pelcra/pl-asr-pelcra-for-bigos) and the open\nchallenge call (https://poleval.pl/tasks/task3). Tools used for evaluation are\nopen-sourced (https://github.com/goodmike31/pl-asr-bigos-tools), facilitating\nreplication and adaptation for other languages, as well as continuous expansion\nwith new datasets and systems.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "I.2.7"
    ],
    "primary_category": "eess.AS",
    "comment": "Submitted to NeurIPS 2024 Datasets and Benchmarks Track",
    "pdf_url": "http://arxiv.org/pdf/2408.00005v1",
    "published_date": "2024-07-18 21:32:12 UTC",
    "updated_date": "2024-07-18 21:32:12 UTC"
  },
  {
    "arxiv_id": "2407.13896v1",
    "title": "Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset",
    "authors": [
      "Yi Sheng",
      "Junhuan Yang",
      "Jinyang Li",
      "James Alaina",
      "Xiaowei Xu",
      "Yiyu Shi",
      "Jingtong Hu",
      "Weiwen Jiang",
      "Lei Yang"
    ],
    "abstract": "As Artificial Intelligence (AI) increasingly integrates into our daily lives,\nfairness has emerged as a critical concern, particularly in medical AI, where\ndatasets often reflect inherent biases due to social factors like the\nunderrepresentation of marginalized communities and socioeconomic barriers to\ndata collection. Traditional approaches to mitigating these biases have focused\non data augmentation and the development of fairness-aware training algorithms.\nHowever, this paper argues that the architecture of neural networks, a core\ncomponent of Machine Learning (ML), plays a crucial role in ensuring fairness.\nWe demonstrate that addressing fairness effectively requires a holistic\napproach that simultaneously considers data, algorithms, and architecture.\nUtilizing Automated ML (AutoML) technology, specifically Neural Architecture\nSearch (NAS), we introduce a novel framework, BiaslessNAS, designed to achieve\nfair outcomes in analyzing skin lesion datasets. BiaslessNAS incorporates\nfairness considerations at every stage of the NAS process, leading to the\nidentification of neural networks that are not only more accurate but also\nsignificantly fairer. Our experiments show that BiaslessNAS achieves a 2.55%\nincrease in accuracy and a 65.50% improvement in fairness compared to\ntraditional NAS methods, underscoring the importance of integrating fairness\ninto neural network architecture for better outcomes in medical AI\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "MICCAI",
    "pdf_url": "http://arxiv.org/pdf/2407.13896v1",
    "published_date": "2024-07-18 20:49:57 UTC",
    "updated_date": "2024-07-18 20:49:57 UTC"
  },
  {
    "arxiv_id": "2407.13891v2",
    "title": "High Risk of Political Bias in Black Box Emotion Inference Models",
    "authors": [
      "Hubert Plisiecki",
      "Paweł Lenartowicz",
      "Maria Flakus",
      "Artur Pokropek"
    ],
    "abstract": "This paper investigates the presence of political bias in emotion inference\nmodels used for sentiment analysis (SA) in social science research. Machine\nlearning models often reflect biases in their training data, impacting the\nvalidity of their outcomes. While previous research has highlighted gender and\nrace biases, our study focuses on political bias - an underexplored yet\npervasive issue that can skew the interpretation of text data across a wide\narray of studies. We conducted a bias audit on a Polish sentiment analysis\nmodel developed in our lab. By analyzing valence predictions for names and\nsentences involving Polish politicians, we uncovered systematic differences\ninfluenced by political affiliations. Our findings indicate that annotations by\nhuman raters propagate political biases into the model's predictions. To\nmitigate this, we pruned the training dataset of texts mentioning these\npoliticians and observed a reduction in bias, though not its complete\nelimination. Given the significant implications of political bias in SA, our\nstudy emphasizes caution in employing these models for social science research.\nWe recommend a critical examination of SA results and propose using\nlexicon-based systems as a more ideologically neutral alternative. This paper\nunderscores the necessity for ongoing scrutiny and methodological adjustments\nto ensure the reliability and impartiality of the use of machine learning in\nacademic and applied contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13891v2",
    "published_date": "2024-07-18 20:31:07 UTC",
    "updated_date": "2024-11-21 06:07:13 UTC"
  },
  {
    "arxiv_id": "2407.14564v1",
    "title": "APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy",
    "authors": [
      "Yi Sheng",
      "Hanchen Wang",
      "Yipei Liu",
      "Junhuan Yang",
      "Weiwen Jiang",
      "Youzuo Lin",
      "Lei Yang"
    ],
    "abstract": "Ultrasound computed tomography (USCT) is a promising technique that achieves\nsuperior medical imaging reconstruction resolution by fully leveraging waveform\ninformation, outperforming conventional ultrasound methods. Despite its\nadvantages, high-quality USCT reconstruction relies on extensive data\nacquisition by a large number of transducers, leading to increased costs,\ncomputational demands, extended patient scanning times, and manufacturing\ncomplexities. To mitigate these issues, we propose a new USCT method called\nAPS-USCT, which facilitates imaging with sparse data, substantially reducing\ndependence on high-cost dense data acquisition. Our APS-USCT method consists of\ntwo primary components: APS-wave and APS-FWI. The APS-wave component, an\nencoder-decoder system, preprocesses the waveform data, converting sparse data\ninto dense waveforms to augment sample density prior to reconstruction. The\nAPS-FWI component, utilizing the InversionNet, directly reconstructs the speed\nof sound (SOS) from the ultrasound waveform data. We further improve the\nmodel's performance by incorporating Squeeze-and-Excitation (SE) Blocks and\nsource encoding techniques. Testing our method on a breast cancer dataset\nyielded promising results. It demonstrated outstanding performance with an\naverage Structural Similarity Index (SSIM) of 0.8431. Notably, over 82% of\nsamples achieved an SSIM above 0.8, with nearly 61% exceeding 0.85,\nhighlighting the significant potential of our approach in improving USCT image\nreconstruction by efficiently utilizing sparse data.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "MICCAI",
    "pdf_url": "http://arxiv.org/pdf/2407.14564v1",
    "published_date": "2024-07-18 20:30:41 UTC",
    "updated_date": "2024-07-18 20:30:41 UTC"
  },
  {
    "arxiv_id": "2407.13862v2",
    "title": "Enhancing Worldwide Image Geolocation by Ensembling Satellite-Based Ground-Level Attribute Predictors",
    "authors": [
      "Michael J. Bianco",
      "David Eigen",
      "Michael Gormish"
    ],
    "abstract": "We examine the challenge of estimating the location of a single ground-level\nimage in the absence of GPS or other location metadata. Currently, geolocation\nsystems are evaluated by measuring the Great Circle Distance between the\npredicted location and ground truth. Because this measurement only uses a\nsingle point, it cannot assess the distribution of predictions by geolocation\nsystems. Evaluation of a distribution of potential locations (areas) is\nrequired when there are follow-on procedures to further narrow down or verify\nthe location. This is especially important in poorly-sampled regions e.g. rural\nand wilderness areas.\n  In this paper, we introduce a novel metric, Recall vs Area (RvA), which\nmeasures the accuracy of estimated distributions of locations. RvA treats image\ngeolocation results similarly to document retrieval, measuring recall as a\nfunction of area: For a ranked list of (possibly discontiguous) predicted\nregions, we measure the area required for accumulated regions to contain the\nground truth coordinate. This produces a curve similar to a precision-recall\ncurve, where \"precision\" is replaced by square kilometers area, enabling\nevaluation for different downstream search area budgets.\n  Following from this view of the problem, we then examine an ensembling\napproach to global-scale image geolocation, which incorporates information from\nmultiple sources, and can readily incorporate multiple models, attribute\npredictors, and data sources. We study its effectiveness by combining the\ngeolocation models GeoEstimation and the current state-of-the-art, GeoCLIP,\nwith attribute predictors based on Oak Ridge National Laboratory LandScan and\nEuropean Space Agency Climate Change Initiative Land Cover. We find significant\nimprovements in image geolocation for areas that are under-represented in the\ntraining set, particularly non-urban areas, on both Im2GPS3k and Street View\nimages.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13862v2",
    "published_date": "2024-07-18 19:15:52 UTC",
    "updated_date": "2024-09-17 21:17:54 UTC"
  },
  {
    "arxiv_id": "2407.14562v2",
    "title": "Thought-Like-Pro: Enhancing Reasoning of Large Language Models through Self-Driven Prolog-based Chain-of-Thought",
    "authors": [
      "Xiaoyu Tan",
      "Yongxin Deng",
      "Xihe Qiu",
      "Weidi Xu",
      "Chao Qu",
      "Wei Chu",
      "Yinghui Xu",
      "Yuan Qi"
    ],
    "abstract": "Large language models (LLMs) have shown exceptional performance as\ngeneral-purpose assistants, excelling across a variety of reasoning tasks. This\nachievement represents a significant step toward achieving artificial general\nintelligence (AGI). Despite these advancements, the effectiveness of LLMs often\nhinges on the specific prompting strategies employed, and there remains a lack\nof a robust framework to facilitate learning and generalization across diverse\nreasoning tasks. To address these challenges, we introduce a novel learning\nframework, THOUGHT-LIKE-PRO In this framework, we utilize imitation learning to\nimitate the Chain-of-Thought (CoT) process which is verified and translated\nfrom reasoning trajectories generated by a symbolic Prolog logic engine. This\nframework proceeds in a self-driven manner, that enables LLMs to formulate\nrules and statements from given instructions and leverage the symbolic Prolog\nengine to derive results. Subsequently, LLMs convert Prolog-derived successive\nreasoning trajectories into natural language CoT for imitation learning. Our\nempirical findings indicate that our proposed approach substantially enhances\nthe reasoning abilities of LLMs and demonstrates robust generalization across\nout-of-distribution reasoning tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14562v2",
    "published_date": "2024-07-18 18:52:10 UTC",
    "updated_date": "2024-08-10 06:54:20 UTC"
  },
  {
    "arxiv_id": "2407.15871v3",
    "title": "Semantic Prototypes: Enhancing Transparency Without Black Boxes",
    "authors": [
      "Orfeas Menis-Mastromichalakis",
      "Giorgos Filandrianos",
      "Jason Liartis",
      "Edmund Dervakos",
      "Giorgos Stamou"
    ],
    "abstract": "As machine learning (ML) models and datasets increase in complexity, the\ndemand for methods that enhance explainability and interpretability becomes\nparamount. Prototypes, by encapsulating essential characteristics within data,\noffer insights that enable tactical decision-making and enhance transparency.\nTraditional prototype methods often rely on sub-symbolic raw data and opaque\nlatent spaces, reducing explainability and increasing the risk of\nmisinterpretations. This paper presents a novel framework that utilizes\nsemantic descriptions to define prototypes and provide clear explanations,\neffectively addressing the shortcomings of conventional methods. Our approach\nleverages concept-based descriptions to cluster data on the semantic level,\nensuring that prototypes not only represent underlying properties intuitively\nbut are also straightforward to interpret. Our method simplifies the\ninterpretative process and effectively bridges the gap between complex data\nstructures and human cognitive processes, thereby enhancing transparency and\nfostering trust. Our approach outperforms existing widely-used prototype\nmethods in facilitating human understanding and informativeness, as validated\nthrough a user survey.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted for publication as a full paper at the\n  33rd ACM International Conference on Information and Knowledge Management\n  (CIKM 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.15871v3",
    "published_date": "2024-07-18 18:42:58 UTC",
    "updated_date": "2024-08-19 15:58:03 UTC"
  },
  {
    "arxiv_id": "2407.18965v1",
    "title": "Generative AI Augmented Induction-based Formal Verification",
    "authors": [
      "Aman Kumar",
      "Deepak Narayan Gadde"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) has demonstrated its capabilities\nin the present world that reduce human effort significantly. It utilizes deep\nlearning techniques to create original and realistic content in terms of text,\nimages, code, music, and video. Researchers have also shown the capabilities of\nmodern Large Language Models (LLMs) used by GenAI models that can be used to\naid hardware development. Formal verification is a mathematical-based proof\nmethod used to exhaustively verify the correctness of a design. In this paper,\nwe demonstrate how GenAI can be used in induction-based formal verification to\nincrease the verification throughput.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear at the 37th IEEE International System-on-Chip Conference,\n  Sep 16-19 2024, Dresden, Germany",
    "pdf_url": "http://arxiv.org/pdf/2407.18965v1",
    "published_date": "2024-07-18 18:36:41 UTC",
    "updated_date": "2024-07-18 18:36:41 UTC"
  },
  {
    "arxiv_id": "2407.13833v2",
    "title": "Phi-3 Safety Post-Training: Aligning Language Models with a \"Break-Fix\" Cycle",
    "authors": [
      "Emman Haider",
      "Daniel Perez-Becker",
      "Thomas Portet",
      "Piyush Madan",
      "Amit Garg",
      "Atabak Ashfaq",
      "David Majercak",
      "Wen Wen",
      "Dongwoo Kim",
      "Ziyi Yang",
      "Jianwen Zhang",
      "Hiteshi Sharma",
      "Blake Bullwinkel",
      "Martin Pouliot",
      "Amanda Minnich",
      "Shiven Chawla",
      "Solianna Herrera",
      "Shahed Warreth",
      "Maggie Engler",
      "Gary Lopez",
      "Nina Chikanov",
      "Raja Sekhar Rao Dheekonda",
      "Bolor-Erdene Jagdagdorj",
      "Roman Lutz",
      "Richard Lundeen",
      "Tori Westerhoff",
      "Pete Bryan",
      "Christian Seifert",
      "Ram Shankar Siva Kumar",
      "Andrew Berkley",
      "Alex Kessler"
    ],
    "abstract": "Recent innovations in language model training have demonstrated that it is\npossible to create highly performant models that are small enough to run on a\nsmartphone. As these models are deployed in an increasing number of domains, it\nis critical to ensure that they are aligned with human preferences and safety\nconsiderations. In this report, we present our methodology for safety aligning\nthe Phi-3 series of language models. We utilized a \"break-fix\" cycle,\nperforming multiple rounds of dataset curation, safety post-training,\nbenchmarking, red teaming, and vulnerability identification to cover a variety\nof harm areas in both single and multi-turn scenarios. Our results indicate\nthat this approach iteratively improved the performance of the Phi-3 models\nacross a wide range of responsible AI benchmarks. Finally, we include\nadditional red teaming strategies and evaluations that were used to test the\nsafety behavior of Phi-3.5-mini and Phi-3.5-MoE, which were optimized for\nmultilingual capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13833v2",
    "published_date": "2024-07-18 18:06:59 UTC",
    "updated_date": "2024-08-23 00:04:31 UTC"
  },
  {
    "arxiv_id": "2407.13768v1",
    "title": "Addressing Imbalance for Class Incremental Learning in Medical Image Classification",
    "authors": [
      "Xuze Hao",
      "Wenqian Ni",
      "Xuhao Jiang",
      "Weimin Tan",
      "Bo Yan"
    ],
    "abstract": "Deep convolutional neural networks have made significant breakthroughs in\nmedical image classification, under the assumption that training samples from\nall classes are simultaneously available. However, in real-world medical\nscenarios, there's a common need to continuously learn about new diseases,\nleading to the emerging field of class incremental learning (CIL) in the\nmedical domain. Typically, CIL suffers from catastrophic forgetting when\ntrained on new classes. This phenomenon is mainly caused by the imbalance\nbetween old and new classes, and it becomes even more challenging with\nimbalanced medical datasets. In this work, we introduce two simple yet\neffective plug-in methods to mitigate the adverse effects of the imbalance.\nFirst, we propose a CIL-balanced classification loss to mitigate the classifier\nbias toward majority classes via logit adjustment. Second, we propose a\ndistribution margin loss that not only alleviates the inter-class overlap in\nembedding space but also enforces the intra-class compactness. We evaluate the\neffectiveness of our method with extensive experiments on three benchmark\ndatasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our\napproach outperforms state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13768v1",
    "published_date": "2024-07-18 17:59:44 UTC",
    "updated_date": "2024-07-18 17:59:44 UTC"
  },
  {
    "arxiv_id": "2407.13765v2",
    "title": "Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data",
    "authors": [
      "Charles Jin",
      "Martin Rinard"
    ],
    "abstract": "As language models (LMs) deliver increasing performance on a range of NLP\ntasks, probing classifiers have become an indispensable technique in the effort\nto better understand their inner workings. A typical setup involves (1)\ndefining an auxiliary task consisting of a dataset of text annotated with\nlabels, then (2) supervising small classifiers to predict the labels from the\nrepresentations of a pretrained LM as it processed the dataset. A high probing\naccuracy is interpreted as evidence that the LM has learned to perform the\nauxiliary task as an unsupervised byproduct of its original pretraining\nobjective. Despite the widespread usage of probes, however, the robust design\nand analysis of probing experiments remains a challenge. We develop a formal\nperspective on probing using structural causal models (SCM). Specifically,\ngiven an SCM which explains the distribution of tokens observed during\ntraining, we frame the central hypothesis as whether the LM has learned to\nrepresent the latent variables of the SCM. Empirically, we extend a recent\nstudy of LMs in the context of a synthetic grid-world navigation task, where\nhaving an exact model of the underlying causal structure allows us to draw\nstrong inferences from the result of probing experiments. Our techniques\nprovide robust empirical evidence for the ability of LMs to induce the latent\nconcepts underlying text.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13765v2",
    "published_date": "2024-07-18 17:59:27 UTC",
    "updated_date": "2024-07-31 05:57:07 UTC"
  },
  {
    "arxiv_id": "2407.14561v4",
    "title": "NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals",
    "authors": [
      "Jaden Fiotto-Kaufman",
      "Alexander R. Loftus",
      "Eric Todd",
      "Jannik Brinkmann",
      "Koyena Pal",
      "Dmitrii Troitskii",
      "Michael Ripa",
      "Adam Belfki",
      "Can Rager",
      "Caden Juang",
      "Aaron Mueller",
      "Samuel Marks",
      "Arnab Sen Sharma",
      "Francesca Lucchetti",
      "Nikhil Prakash",
      "Carla Brodley",
      "Arjun Guha",
      "Jonathan Bell",
      "Byron C. Wallace",
      "David Bau"
    ],
    "abstract": "We introduce NNsight and NDIF, technologies that work in tandem to enable\nscientific study of the representations and computations learned by very large\nneural networks. NNsight is an open-source system that extends PyTorch to\nintroduce deferred remote execution. The National Deep Inference Fabric (NDIF)\nis a scalable inference service that executes NNsight requests, allowing users\nto share GPU resources and pretrained models. These technologies are enabled by\nthe Intervention Graph, an architecture developed to decouple experimental\ndesign from model runtime. Together, this framework provides transparent and\nefficient access to the internals of deep neural networks such as very large\nlanguage models (LLMs) without imposing the cost or complexity of hosting\ncustomized models individually. We conduct a quantitative survey of the machine\nlearning literature that reveals a growing gap in the study of the internals of\nlarge-scale AI. We demonstrate the design and use of our framework to address\nthis gap by enabling a range of research methods on huge models. Finally, we\nconduct benchmarks to compare performance with previous approaches.\n  Code, documentation, and tutorials are available at https://nnsight.net/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Code at https://nnsight.net",
    "pdf_url": "http://arxiv.org/pdf/2407.14561v4",
    "published_date": "2024-07-18 17:59:01 UTC",
    "updated_date": "2025-04-01 16:04:53 UTC"
  },
  {
    "arxiv_id": "2407.14560v1",
    "title": "Automated and Holistic Co-design of Neural Networks and ASICs for Enabling In-Pixel Intelligence",
    "authors": [
      "Shubha R. Kharel",
      "Prashansa Mukim",
      "Piotr Maj",
      "Grzegorz W. Deptuch",
      "Shinjae Yoo",
      "Yihui Ren",
      "Soumyajit Mandal"
    ],
    "abstract": "Extreme edge-AI systems, such as those in readout ASICs for radiation\ndetection, must operate under stringent hardware constraints such as\nmicron-level dimensions, sub-milliwatt power, and nanosecond-scale speed while\nproviding clear accuracy advantages over traditional architectures. Finding\nideal solutions means identifying optimal AI and ASIC design choices from a\ndesign space that has explosively expanded during the merger of these domains,\ncreating non-trivial couplings which together act upon a small set of solutions\nas constraints tighten. It is impractical, if not impossible, to manually\ndetermine ideal choices among possibilities that easily exceed billions even in\nsmall-size problems. Existing methods to bridge this gap have leveraged\ntheoretical understanding of hardware to f architecture search. However, the\nassumptions made in computing such theoretical metrics are too idealized to\nprovide sufficient guidance during the difficult search for a practical\nimplementation. Meanwhile, theoretical estimates for many other crucial metrics\n(like delay) do not even exist and are similarly variable, dependent on\nparameters of the process design kit (PDK). To address these challenges, we\npresent a study that employs intelligent search using multi-objective Bayesian\noptimization, integrating both neural network search and ASIC synthesis in the\nloop. This approach provides reliable feedback on the collective impact of all\ncross-domain design choices. We showcase the effectiveness of our approach by\nfinding several Pareto-optimal design choices for effective and efficient\nneural networks that perform real-time feature extraction from input pulses\nwithin the individual pixels of a readout ASIC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.14560v1",
    "published_date": "2024-07-18 17:58:05 UTC",
    "updated_date": "2024-07-18 17:58:05 UTC"
  },
  {
    "arxiv_id": "2407.13760v1",
    "title": "Neural Network Tire Force Modeling for Automated Drifting",
    "authors": [
      "Nicholas Drake Broadbent",
      "Trey Weber",
      "Daiki Mori",
      "J. Christian Gerdes"
    ],
    "abstract": "Automated drifting presents a challenge problem for vehicle control,\nrequiring models and control algorithms that can precisely handle nonlinear,\ncoupled tire forces at the friction limits. We present a neural network\narchitecture for predicting front tire lateral force as a drop-in replacement\nfor physics-based approaches. With a full-scale automated vehicle purpose-built\nfor the drifting application, we deploy these models in a nonlinear model\npredictive controller tuned for tracking a reference drifting trajectory, for\ndirect comparisons of model performance. The neural network tire model exhibits\nsignificantly improved path tracking performance over the brush tire model in\ncases where front-axle braking force is applied, suggesting the neural\nnetwork's ability to express previously unmodeled, latent dynamics in the\ndrifting condition.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "16th International Symposium on Advanced Vehicle Control (AVEC).\n  September 2nd-6th, 2024. Milan, Italy",
    "pdf_url": "http://arxiv.org/pdf/2407.13760v1",
    "published_date": "2024-07-18 17:58:01 UTC",
    "updated_date": "2024-07-18 17:58:01 UTC"
  },
  {
    "arxiv_id": "2407.13757v1",
    "title": "Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models",
    "authors": [
      "Zhuo Chen",
      "Jiawei Liu",
      "Haotan Liu",
      "Qikai Cheng",
      "Fan Zhang",
      "Wei Lu",
      "Xiaozhong Liu"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is applied to solve hallucination\nproblems and real-time constraints of large language models, but it also\ninduces vulnerabilities against retrieval corruption attacks. Existing research\nmainly explores the unreliability of RAG in white-box and closed-domain QA\ntasks. In this paper, we aim to reveal the vulnerabilities of\nRetrieval-Enhanced Generative (RAG) models when faced with black-box attacks\nfor opinion manipulation. We explore the impact of such attacks on user\ncognition and decision-making, providing new insight to enhance the reliability\nand security of RAG models. We manipulate the ranking results of the retrieval\nmodel in RAG with instruction and use these results as data to train a\nsurrogate model. By employing adversarial retrieval attack methods to the\nsurrogate model, black-box transfer attacks on RAG are further realized.\nExperiments conducted on opinion datasets across multiple topics show that the\nproposed attack strategy can significantly alter the opinion polarity of the\ncontent generated by RAG. This demonstrates the model's vulnerability and, more\nimportantly, reveals the potential negative impact on user cognition and\ndecision-making, making it easier to mislead users into accepting incorrect or\nbiased information.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2407.13757v1",
    "published_date": "2024-07-18 17:55:55 UTC",
    "updated_date": "2024-07-18 17:55:55 UTC"
  },
  {
    "arxiv_id": "2407.13751v1",
    "title": "Temporal Representation Learning for Stock Similarities and Its Applications in Investment Management",
    "authors": [
      "Yoontae Hwang",
      "Stefan Zohren",
      "Yongjae Lee"
    ],
    "abstract": "In the era of rapid globalization and digitalization, accurate identification\nof similar stocks has become increasingly challenging due to the non-stationary\nnature of financial markets and the ambiguity in conventional regional and\nsector classifications. To address these challenges, we examine SimStock, a\nnovel temporal self-supervised learning framework that combines techniques from\nself-supervised learning (SSL) and temporal domain generalization to learn\nrobust and informative representations of financial time series data. The\nprimary focus of our study is to understand the similarities between stocks\nfrom a broader perspective, considering the complex dynamics of the global\nfinancial landscape. We conduct extensive experiments on four real-world\ndatasets with thousands of stocks and demonstrate the effectiveness of SimStock\nin finding similar stocks, outperforming existing methods. The practical\nutility of SimStock is showcased through its application to various investment\nstrategies, such as pairs trading, index tracking, and portfolio optimization,\nwhere it leads to superior performance compared to conventional methods. Our\nfindings empirically examine the potential of data-driven approach to enhance\ninvestment decision-making and risk management practices by leveraging the\npower of temporal self-supervised learning in the face of the ever-changing\nglobal financial landscape.",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13751v1",
    "published_date": "2024-07-18 17:54:13 UTC",
    "updated_date": "2024-07-18 17:54:13 UTC"
  },
  {
    "arxiv_id": "2407.13744v1",
    "title": "LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation",
    "authors": [
      "David Schlangen"
    ],
    "abstract": "Natural Language Processing has moved rather quickly from modelling specific\ntasks to taking more general pre-trained models and fine-tuning them for\nspecific tasks, to a point where we now have what appear to be inherently\ngeneralist models. This paper argues that the resultant loss of clarity on what\nthese models model leads to metaphors like \"artificial general intelligences\"\nthat are not helpful for evaluating their strengths and weaknesses. The\nproposal is to see their generality, and their potential value, in their\nability to approximate specialist function, based on a natural language\nspecification. This framing brings to the fore questions of the quality of the\napproximation, but beyond that, also questions of discoverability, stability,\nand protectability of these functions. As the paper will show, this framing\nhence brings together in one conceptual framework various aspects of\nevaluation, both from a practical and a theoretical perspective, as well as\nquestions often relegated to a secondary status (such as \"prompt injection\" and\n\"jailbreaking\").",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13744v1",
    "published_date": "2024-07-18 17:49:56 UTC",
    "updated_date": "2024-07-18 17:49:56 UTC"
  },
  {
    "arxiv_id": "2407.13742v1",
    "title": "CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications",
    "authors": [
      "Mirza Masfiqur Rahman",
      "Imtiaz Karim",
      "Elisa Bertino"
    ],
    "abstract": "In recent years, there has been a growing focus on scrutinizing the security\nof cellular networks, often attributing security vulnerabilities to issues in\nthe underlying protocol design descriptions. These protocol design\nspecifications, typically extensive documents that are thousands of pages long,\ncan harbor inaccuracies, underspecifications, implicit assumptions, and\ninternal inconsistencies. In light of the evolving landscape, we introduce\nCellularLint--a semi-automatic framework for inconsistency detection within the\nstandards of 4G and 5G, capitalizing on a suite of natural language processing\ntechniques. Our proposed method uses a revamped few-shot learning mechanism on\ndomain-adapted large language models. Pre-trained on a vast corpus of cellular\nnetwork protocols, this method enables CellularLint to simultaneously detect\ninconsistencies at various levels of semantics and practical use cases. In\ndoing so, CellularLint significantly advances the automated analysis of\nprotocol specifications in a scalable fashion. In our investigation, we focused\non the Non-Access Stratum (NAS) and the security specifications of 4G and 5G\nnetworks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After\nverification of these inconsistencies on open-source implementations and 17\ncommercial devices, we confirm that they indeed have a substantial impact on\ndesign decisions, potentially leading to concerns related to privacy,\nintegrity, availability, and interoperability.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at USENIX Security 24",
    "pdf_url": "http://arxiv.org/pdf/2407.13742v1",
    "published_date": "2024-07-18 17:48:46 UTC",
    "updated_date": "2024-07-18 17:48:46 UTC"
  },
  {
    "arxiv_id": "2407.13739v1",
    "title": "Scaling Granite Code Models to 128K Context",
    "authors": [
      "Matt Stallone",
      "Vaibhav Saxena",
      "Leonid Karlinsky",
      "Bridget McGinn",
      "Tim Bula",
      "Mayank Mishra",
      "Adriana Meza Soria",
      "Gaoyuan Zhang",
      "Aditya Prasad",
      "Yikang Shen",
      "Saptha Surendran",
      "Shanmukha Guttula",
      "Hima Patel",
      "Parameswaran Selvam",
      "Xuan-Hong Dang",
      "Yan Koyfman",
      "Atin Sood",
      "Rogerio Feris",
      "Nirmit Desai",
      "David D. Cox",
      "Ruchir Puri",
      "Rameswar Panda"
    ],
    "abstract": "This paper introduces long-context Granite code models that support effective\ncontext windows of up to 128K tokens. Our solution for scaling context length\nof Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight\ncontinual pretraining by gradually increasing its RoPE base frequency with\nrepository-level file packing and length-upsampled long-context data.\nAdditionally, we also release instruction-tuned models with long-context\nsupport which are derived by further finetuning the long context base models on\na mix of permissively licensed short and long-context instruction-response\npairs. While comparing to the original short-context Granite code models, our\nlong-context models achieve significant improvements on long-context tasks\nwithout any noticeable performance degradation on regular code completion\nbenchmarks (e.g., HumanEval). We release all our long-context Granite code\nmodels under an Apache 2.0 license for both research and commercial use.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13739v1",
    "published_date": "2024-07-18 17:46:02 UTC",
    "updated_date": "2024-07-18 17:46:02 UTC"
  },
  {
    "arxiv_id": "2407.13734v1",
    "title": "Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review",
    "authors": [
      "Masatoshi Uehara",
      "Yulai Zhao",
      "Tommaso Biancalani",
      "Sergey Levine"
    ],
    "abstract": "This tutorial provides a comprehensive survey of methods for fine-tuning\ndiffusion models to optimize downstream reward functions. While diffusion\nmodels are widely known to provide excellent generative modeling capability,\npractical applications in domains such as biology require generating samples\nthat maximize some desired metric (e.g., translation efficiency in RNA, docking\nscore in molecules, stability in protein). In these cases, the diffusion model\ncan be optimized not only to generate realistic samples but also to explicitly\nmaximize the measure of interest. Such methods are based on concepts from\nreinforcement learning (RL). We explain the application of various RL\nalgorithms, including PPO, differentiable optimization, reward-weighted MLE,\nvalue-weighted sampling, and path consistency learning, tailored specifically\nfor fine-tuning diffusion models. We aim to explore fundamental aspects such as\nthe strengths and limitations of different RL-based fine-tuning algorithms\nacross various scenarios, the benefits of RL-based fine-tuning compared to\nnon-RL-based approaches, and the formal objectives of RL-based fine-tuning\n(target distributions). Additionally, we aim to examine their connections with\nrelated topics such as classifier guidance, Gflownets, flow-based diffusion\nmodels, path integral control theory, and sampling from unnormalized\ndistributions such as MCMC. The code of this tutorial is available at\nhttps://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "We plan to add more content/codes. Please let us know if there are\n  any comments",
    "pdf_url": "http://arxiv.org/pdf/2407.13734v1",
    "published_date": "2024-07-18 17:35:32 UTC",
    "updated_date": "2024-07-18 17:35:32 UTC"
  },
  {
    "arxiv_id": "2407.13717v2",
    "title": "CoDefeater: Using LLMs To Find Defeaters in Assurance Cases",
    "authors": [
      "Usman Gohar",
      "Michael C. Hunter",
      "Robyn R. Lutz",
      "Myra B. Cohen"
    ],
    "abstract": "Constructing assurance cases is a widely used, and sometimes required,\nprocess toward demonstrating that safety-critical systems will operate safely\nin their planned environment. To mitigate the risk of errors and missing edge\ncases, the concept of defeaters - arguments or evidence that challenge claims\nin an assurance case - has been introduced. Defeaters can provide timely\ndetection of weaknesses in the arguments, prompting further investigation and\ntimely mitigations. However, capturing defeaters relies on expert judgment,\nexperience, and creativity and must be done iteratively due to evolving\nrequirements and regulations. This paper proposes CoDefeater, an automated\nprocess to leverage large language models (LLMs) for finding defeaters. Initial\nresults on two systems show that LLMs can efficiently find known and unforeseen\nfeasible defeaters to support safety analysts in enhancing the completeness and\nconfidence of assurance cases.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "ASE 2024 NIER",
    "pdf_url": "http://arxiv.org/pdf/2407.13717v2",
    "published_date": "2024-07-18 17:16:35 UTC",
    "updated_date": "2024-08-16 17:43:57 UTC"
  },
  {
    "arxiv_id": "2407.13711v2",
    "title": "FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning",
    "authors": [
      "Tristan Cinquin",
      "Marvin Pförtner",
      "Vincent Fortuin",
      "Philipp Hennig",
      "Robert Bamler"
    ],
    "abstract": "Laplace approximations are popular techniques for endowing deep networks with\nepistemic uncertainty estimates as they can be applied without altering the\npredictions of the trained network, and they scale to large models and\ndatasets. While the choice of prior strongly affects the resulting posterior\ndistribution, computational tractability and lack of interpretability of the\nweight space typically limit the Laplace approximation to isotropic Gaussian\npriors, which are known to cause pathological behavior as depth increases. As a\nremedy, we directly place a prior on function space. More precisely, since\nLebesgue densities do not exist on infinite-dimensional function spaces, we\nrecast training as finding the so-called weak mode of the posterior measure\nunder a Gaussian process (GP) prior restricted to the space of functions\nrepresentable by the neural network. Through the GP prior, one can express\nstructured and interpretable inductive biases, such as regularity or\nperiodicity, directly in function space, while still exploiting the implicit\ninductive biases that allow deep networks to generalize. After model\nlinearization, the training objective induces a negative log-posterior density\nto which we apply a Laplace approximation, leveraging highly scalable methods\nfrom matrix-free linear algebra. Our method provides improved results where\nprior knowledge is abundant (as is the case in many scientific inference\ntasks). At the same time, it stays competitive for black-box supervised\nlearning problems, where neural networks typically excel.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13711v2",
    "published_date": "2024-07-18 17:08:58 UTC",
    "updated_date": "2024-10-31 09:58:47 UTC"
  },
  {
    "arxiv_id": "2407.21037v1",
    "title": "An Application of Large Language Models to Coding Negotiation Transcripts",
    "authors": [
      "Ray Friedman",
      "Jaewoo Cho",
      "Jeanne Brett",
      "Xuhui Zhan",
      "Ningyu Han",
      "Sriram Kannan",
      "Yingxiang Ma",
      "Jesse Spencer-Smith",
      "Elisabeth Jäckel",
      "Alfred Zerres",
      "Madison Hooper",
      "Katie Babbit",
      "Manish Acharya",
      "Wendi Adair",
      "Soroush Aslani",
      "Tayfun Aykaç",
      "Chris Bauman",
      "Rebecca Bennett",
      "Garrett Brady",
      "Peggy Briggs",
      "Cheryl Dowie",
      "Chase Eck",
      "Igmar Geiger",
      "Frank Jacob",
      "Molly Kern",
      "Sujin Lee",
      "Leigh Anne Liu",
      "Wu Liu",
      "Jeffrey Loewenstein",
      "Anne Lytle",
      "Li Ma",
      "Michel Mann",
      "Alexandra Mislin",
      "Tyree Mitchell",
      "Hannah Martensen née Nagler",
      "Amit Nandkeolyar",
      "Mara Olekalns",
      "Elena Paliakova",
      "Jennifer Parlamis",
      "Jason Pierce",
      "Nancy Pierce",
      "Robin Pinkley",
      "Nathalie Prime",
      "Jimena Ramirez-Marin",
      "Kevin Rockmann",
      "William Ross",
      "Zhaleh Semnani-Azad",
      "Juliana Schroeder",
      "Philip Smith",
      "Elena Stimmer",
      "Roderick Swaab",
      "Leigh Thompson",
      "Cathy Tinsley",
      "Ece Tuncel",
      "Laurie Weingart",
      "Robert Wilken",
      "JingJing Yao",
      "Zhi-Xue Zhang"
    ],
    "abstract": "In recent years, Large Language Models (LLM) have demonstrated impressive\ncapabilities in the field of natural language processing (NLP). This paper\nexplores the application of LLMs in negotiation transcript analysis by the\nVanderbilt AI Negotiation Lab. Starting in September 2022, we applied multiple\nstrategies using LLMs from zero shot learning to fine tuning models to\nin-context learning). The final strategy we developed is explained, along with\nhow to access and use the model. This study provides a sense of both the\nopportunities and roadblocks for the implementation of LLMs in real life\napplications and offers a model for how LLMs can be applied to coding in other\nfields.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21037v1",
    "published_date": "2024-07-18 17:05:59 UTC",
    "updated_date": "2024-07-18 17:05:59 UTC"
  },
  {
    "arxiv_id": "2407.13700v1",
    "title": "Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift",
    "authors": [
      "Qingyuan Zeng",
      "Yunpeng Gong",
      "Min Jiang"
    ],
    "abstract": "Studying adversarial attacks on artificial intelligence (AI) systems helps\ndiscover model shortcomings, enabling the construction of a more robust system.\nMost existing adversarial attack methods only concentrate on single-task\nsingle-model or single-task cross-model scenarios, overlooking the multi-task\ncharacteristic of artificial intelligence systems. As a result, most of the\nexisting attacks do not pose a practical threat to a comprehensive and\ncollaborative AI system. However, implementing cross-task attacks is highly\ndemanding and challenging due to the difficulty in obtaining the real labels of\ndifferent tasks for the same picture and harmonizing the loss functions across\ndifferent tasks. To address this issue, we propose a self-supervised Cross-Task\nAttack framework (CTA), which utilizes co-attention and anti-attention maps to\ngenerate cross-task adversarial perturbation. Specifically, the co-attention\nmap reflects the area to which different visual task models pay attention,\nwhile the anti-attention map reflects the area that different visual task\nmodels neglect. CTA generates cross-task perturbations by shifting the\nattention area of samples away from the co-attention map and closer to the\nanti-attention map. We conduct extensive experiments on multiple vision tasks\nand the experimental results confirm the effectiveness of the proposed design\nfor adversarial attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Has been accepted by IJCNN2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13700v1",
    "published_date": "2024-07-18 17:01:10 UTC",
    "updated_date": "2024-07-18 17:01:10 UTC"
  },
  {
    "arxiv_id": "2407.13699v2",
    "title": "A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice",
    "authors": [
      "Shaina Raza",
      "Mizanur Rahman",
      "Safiullah Kamawal",
      "Armin Toroghi",
      "Ananya Raval",
      "Farshad Navah",
      "Amirmohammad Kazemeini"
    ],
    "abstract": "Recommender Systems (RS) play an integral role in enhancing user experiences\nby providing personalized item suggestions. This survey reviews the progress in\nRS inclusively from 2017 to 2024, effectively connecting theoretical advances\nwith practical applications. We explore the development from traditional RS\ntechniques like content-based and collaborative filtering to advanced methods\ninvolving deep learning, graph-based models, reinforcement learning, and large\nlanguage models. We also discuss specialized systems such as context-aware,\nreview-based, and fairness-aware RS. The primary goal of this survey is to\nbridge theory with practice. It addresses challenges across various sectors,\nincluding e-commerce, healthcare, and finance, emphasizing the need for\nscalable, real-time, and trustworthy solutions. Through this survey, we promote\nstronger partnerships between academic research and industry practices. The\ninsights offered by this survey aim to guide industry professionals in\noptimizing RS deployment and to inspire future research directions, especially\nin addressing emerging technological and societal trends\\footnote. The survey\nresources are available in the public GitHub repository\nhttps://github.com/VectorInstitute/Recommender-Systems-Survey. (Recommender\nsystems, large language models, chatgpt, responsible AI)",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "we quarterly update of this literature",
    "pdf_url": "http://arxiv.org/pdf/2407.13699v2",
    "published_date": "2024-07-18 17:00:53 UTC",
    "updated_date": "2025-02-23 02:49:17 UTC"
  },
  {
    "arxiv_id": "2407.13689v1",
    "title": "Shaded Route Planning Using Active Segmentation and Identification of Satellite Images",
    "authors": [
      "Longchao Da",
      "Rohan Chhibba",
      "Rushabh Jaiswal",
      "Ariane Middel",
      "Hua Wei"
    ],
    "abstract": "Heatwaves pose significant health risks, particularly due to prolonged\nexposure to high summer temperatures. Vulnerable groups, especially pedestrians\nand cyclists on sun-exposed sidewalks, motivate the development of a route\nplanning method that incorporates somatosensory temperature effects through\nshade ratio consideration. This paper is the first to introduce a pipeline that\nutilizes segmentation foundation models to extract shaded areas from\nhigh-resolution satellite images. These areas are then integrated into a\nmulti-layered road map, enabling users to customize routes based on a balance\nbetween distance and shade exposure, thereby enhancing comfort and health\nduring outdoor activities. Specifically, we construct a graph-based\nrepresentation of the road map, where links indicate connectivity and are\nupdated with shade ratio data for dynamic route planning. This system is\nalready implemented online, with a video demonstration, and will be\nspecifically adapted to assist travelers during the 2024 Olympic Games in\nParis.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV",
      "68T45, 68U35",
      "I.2.10; I.4.8"
    ],
    "primary_category": "cs.CY",
    "comment": "Paper accepted to CIKM24 demo track",
    "pdf_url": "http://arxiv.org/pdf/2407.13689v1",
    "published_date": "2024-07-18 16:57:11 UTC",
    "updated_date": "2024-07-18 16:57:11 UTC"
  },
  {
    "arxiv_id": "2407.13680v1",
    "title": "HPix: Generating Vector Maps from Satellite Images",
    "authors": [
      "Aditya Taparia",
      "Keshab Nath"
    ],
    "abstract": "Vector maps find widespread utility across diverse domains due to their\ncapacity to not only store but also represent discrete data boundaries such as\nbuilding footprints, disaster impact analysis, digitization, urban planning,\nlocation points, transport links, and more. Although extensive research exists\non identifying building footprints and road types from satellite imagery, the\ngeneration of vector maps from such imagery remains an area with limited\nexploration. Furthermore, conventional map generation techniques rely on\nlabor-intensive manual feature extraction or rule-based approaches, which\nimpose inherent limitations. To surmount these limitations, we propose a novel\nmethod called HPix, which utilizes modified Generative Adversarial Networks\n(GANs) to generate vector tile map from satellite images. HPix incorporates two\nhierarchical frameworks: one operating at the global level and the other at the\nlocal level, resulting in a comprehensive model. Through empirical evaluations,\nour proposed approach showcases its effectiveness in producing highly accurate\nand visually captivating vector tile maps derived from satellite images. We\nfurther extend our study's application to include mapping of road intersections\nand building footprints cluster based on their area.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13680v1",
    "published_date": "2024-07-18 16:54:02 UTC",
    "updated_date": "2024-07-18 16:54:02 UTC"
  },
  {
    "arxiv_id": "2407.13677v1",
    "title": "PASTA: Controllable Part-Aware Shape Generation with Autoregressive Transformers",
    "authors": [
      "Songlin Li",
      "Despoina Paschalidou",
      "Leonidas Guibas"
    ],
    "abstract": "The increased demand for tools that automate the 3D content creation process\nled to tremendous progress in deep generative models that can generate diverse\n3D objects of high fidelity. In this paper, we present PASTA, an autoregressive\ntransformer architecture for generating high quality 3D shapes. PASTA comprises\ntwo main components: An autoregressive transformer that generates objects as a\nsequence of cuboidal primitives and a blending network, implemented with a\ntransformer decoder that composes the sequences of cuboids and synthesizes high\nquality meshes for each object. Our model is trained in two stages: First we\ntrain our autoregressive generative model using only annotated cuboidal parts\nas supervision and next, we train our blending network using explicit 3D\nsupervision, in the form of watertight meshes. Evaluations on various ShapeNet\nobjects showcase the ability of our model to perform shape generation from\ndiverse inputs \\eg from scratch, from a partial object, from text and images,\nas well size-guided generation, by explicitly conditioning on a bounding box\nthat defines the object's boundaries. Moreover, as our model considers the\nunderlying part-based structure of a 3D object, we are able to select a\nspecific part and produce shapes with meaningful variations of this part. As\nevidenced by our experiments, our model generates 3D shapes that are both more\nrealistic and diverse than existing part-based and non part-based methods,\nwhile at the same time is simpler to implement and train.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13677v1",
    "published_date": "2024-07-18 16:52:45 UTC",
    "updated_date": "2024-07-18 16:52:45 UTC"
  },
  {
    "arxiv_id": "2407.14559v1",
    "title": "Predicting Star Scientists in the Field of Artificial Intelligence: A Machine Learning Approach",
    "authors": [
      "Koosha Shirouyeh",
      "Andrea Schiffauerova",
      "Ashkan Ebadi"
    ],
    "abstract": "Star scientists are highly influential researchers who have made significant\ncontributions to their field, gained widespread recognition, and often\nattracted substantial research funding. They are critical for the advancement\nof science and innovation, and they have a significant influence on the\ntransfer of knowledge and technology to industry. Identifying potential star\nscientists before their performance becomes outstanding is important for\nrecruitment, collaboration, networking, or research funding decisions. Using\nmachine learning techniques, this study proposes a model to predict star\nscientists in the field of artificial intelligence while highlighting features\nrelated to their success. Our results confirm that rising stars follow\ndifferent patterns compared to their non-rising stars counterparts in almost\nall the early-career features. We also found that certain features such as\ngender and ethnic diversity play important roles in scientific collaboration\nand that they can significantly impact an author's career development and\nsuccess. The most important features in predicting star scientists in the field\nof artificial intelligence were the number of articles, group discipline\ndiversity, and weighted degree centrality. The proposed approach offers\nvaluable insights for researchers, practitioners, and funding agencies\ninterested in identifying and supporting talented researchers.",
    "categories": [
      "cs.OH",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.OH",
    "comment": "21 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.14559v1",
    "published_date": "2024-07-18 16:50:18 UTC",
    "updated_date": "2024-07-18 16:50:18 UTC"
  },
  {
    "arxiv_id": "2407.13647v2",
    "title": "Weak-to-Strong Reasoning",
    "authors": [
      "Yuqing Yang",
      "Yan Ma",
      "Pengfei Liu"
    ],
    "abstract": "When large language models (LLMs) exceed human-level capabilities, it becomes\nincreasingly challenging to provide full-scale and accurate supervision for\nthese models. Weak-to-strong learning, which leverages a less capable model to\nunlock the latent abilities of a stronger model, proves valuable in this\ncontext. Yet, the efficacy of this approach for complex reasoning tasks is\nstill untested. Furthermore, tackling reasoning tasks under the weak-to-strong\nsetting currently lacks efficient methods to avoid blindly imitating the weak\nsupervisor including its errors. In this paper, we introduce a progressive\nlearning framework that enables the strong model to autonomously refine its\ntraining data, without requiring input from either a more advanced model or\nhuman-annotated data. This framework begins with supervised fine-tuning on a\nselective small but high-quality dataset, followed by preference optimization\non contrastive samples identified by the strong model itself. Extensive\nexperiments on the GSM8K and MATH datasets demonstrate that our method\nsignificantly enhances the reasoning capabilities of Llama2-70b using three\nseparate weak models. This method is further validated in a forward-looking\nexperimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b\non the highly challenging OlympicArena dataset. This work paves the way for a\nmore scalable and sophisticated strategy to enhance AI reasoning powers. All\nrelevant code and resources are available in\n\\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13647v2",
    "published_date": "2024-07-18 16:25:17 UTC",
    "updated_date": "2024-10-01 05:28:54 UTC"
  },
  {
    "arxiv_id": "2407.13638v1",
    "title": "A Comparative Study on Automatic Coding of Medical Letters with Explainability",
    "authors": [
      "Jamie Glen",
      "Lifeng Han",
      "Paul Rayson",
      "Goran Nenadic"
    ],
    "abstract": "This study aims to explore the implementation of Natural Language Processing\n(NLP) and machine learning (ML) techniques to automate the coding of medical\nletters with visualised explainability and light-weighted local computer\nsettings. Currently in clinical settings, coding is a manual process that\ninvolves assigning codes to each condition, procedure, and medication in a\npatient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There\nare preliminary research on automatic coding in this field using\nstate-of-the-art ML models; however, due to the complexity and size of the\nmodels, the real-world deployment is not achieved. To further facilitate the\npossibility of automatic coding practice, we explore some solutions in a local\ncomputer setting; in addition, we explore the function of explainability for\ntransparency of AI models. We used the publicly available MIMIC-III database\nand the HAN/HLAN network models for ICD code prediction purposes. We also\nexperimented with the mapping between ICD and SNOMED CT knowledge bases. In our\nexperiments, the models provided useful information for 97.98\\% of codes. The\nresult of this investigation can shed some light on implementing automatic\nclinical coding in practice, such as in hospital settings, on the local\ncomputers used by clinicians , project page\n\\url{https://github.com/Glenj01/Medical-Coding}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "working paper",
    "pdf_url": "http://arxiv.org/pdf/2407.13638v1",
    "published_date": "2024-07-18 16:12:47 UTC",
    "updated_date": "2024-07-18 16:12:47 UTC"
  },
  {
    "arxiv_id": "2407.13813v1",
    "title": "A review of handcrafted and deep radiomics in neurological diseases: transitioning from oncology to clinical neuroimaging",
    "authors": [
      "Elizaveta Lavrova",
      "Henry C. Woodruff",
      "Hamza Khan",
      "Eric Salmon",
      "Philippe Lambin",
      "Christophe Phillips"
    ],
    "abstract": "Medical imaging technologies have undergone extensive development, enabling\nnon-invasive visualization of clinical information. The traditional review of\nmedical images by clinicians remains subjective, time-consuming, and prone to\nhuman error. With the recent availability of medical imaging data,\nquantification have become important goals in the field. Radiomics, a\nmethodology aimed at extracting quantitative information from imaging data, has\nemerged as a promising approach to uncover hidden biological information and\nsupport decision-making in clinical practice. This paper presents a review of\nthe radiomic pipeline from the clinical neuroimaging perspective, providing a\ndetailed overview of each step with practical advice. It discusses the\napplication of handcrafted and deep radiomics in neuroimaging, stratified by\nneurological diagnosis. Although radiomics shows great potential for increasing\ndiagnostic precision and improving treatment quality in neurology, several\nlimitations hinder its clinical implementation. Addressing these challenges\nrequires collaborative efforts, advancements in image harmonization methods,\nand the establishment of reproducible and standardized pipelines with\ntransparent reporting. By overcoming these obstacles, radiomics can\nsignificantly impact clinical neurology and enhance patient care.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13813v1",
    "published_date": "2024-07-18 16:12:07 UTC",
    "updated_date": "2024-07-18 16:12:07 UTC"
  },
  {
    "arxiv_id": "2407.13623v3",
    "title": "Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies",
    "authors": [
      "Chaofan Tao",
      "Qian Liu",
      "Longxu Dou",
      "Niklas Muennighoff",
      "Zhongwei Wan",
      "Ping Luo",
      "Min Lin",
      "Ngai Wong"
    ],
    "abstract": "Research on scaling large language models (LLMs) has primarily focused on\nmodel parameters and training data size, overlooking the role of vocabulary\nsize. We investigate how vocabulary size impacts LLM scaling laws by training\nmodels ranging from 33M to 3B parameters on up to 500B characters with various\nvocabulary configurations. We propose three complementary approaches for\npredicting the compute-optimal vocabulary size: IsoFLOPs analysis, derivative\nestimation, and parametric fit of the loss function. Our approaches converge on\nthe conclusion that the optimal vocabulary size depends on the compute budget,\nwith larger models requiring larger vocabularies. Most LLMs, however, use\ninsufficient vocabulary sizes. For example, we predict that the optimal\nvocabulary size of Llama2-70B should have been at least 216K, 7 times larger\nthan its vocabulary of 32K. We validate our predictions empirically by training\nmodels with 3B parameters across different FLOPs budgets. Adopting our\npredicted optimal vocabulary size consistently improves downstream performance\nover commonly used vocabulary sizes. By increasing the vocabulary size from the\nconventional 32K to 43K, we improve performance on ARC-Challenge from 29.1 to\n32.0 with the same 2.3e21 FLOPs. Our work highlights the importance of jointly\nconsidering tokenization and model scaling for efficient pre-training. The code\nand demo are available at https://github.com/sail-sg/scaling-with-vocab and\nhttps://hf.co/spaces/sail/scaling-with-vocab-demo.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13623v3",
    "published_date": "2024-07-18 15:58:54 UTC",
    "updated_date": "2024-11-01 02:41:36 UTC"
  },
  {
    "arxiv_id": "2407.13622v1",
    "title": "Misspecified $Q$-Learning with Sparse Linear Function Approximation: Tight Bounds on Approximation Error",
    "authors": [
      "Ally Yalei Du",
      "Lin F. Yang",
      "Ruosong Wang"
    ],
    "abstract": "The recent work by Dong & Yang (2023) showed for misspecified sparse linear\nbandits, one can obtain an $O\\left(\\epsilon\\right)$-optimal policy using a\npolynomial number of samples when the sparsity is a constant, where $\\epsilon$\nis the misspecification error. This result is in sharp contrast to misspecified\nlinear bandits without sparsity, which require an exponential number of samples\nto get the same guarantee. In order to study whether the analog result is\npossible in the reinforcement learning setting, we consider the following\nproblem: assuming the optimal $Q$-function is a $d$-dimensional linear function\nwith sparsity $k$ and misspecification error $\\epsilon$, whether we can obtain\nan $O\\left(\\epsilon\\right)$-optimal policy using number of samples polynomially\nin the feature dimension $d$. We first demonstrate why the standard approach\nbased on Bellman backup or the existing optimistic value function elimination\napproach such as OLIVE (Jiang et al., 2017) achieves suboptimal guarantees for\nthis problem. We then design a novel elimination-based algorithm to show one\ncan obtain an $O\\left(H\\epsilon\\right)$-optimal policy with sample complexity\npolynomially in the feature dimension $d$ and planning horizon $H$. Lastly, we\ncomplement our upper bound with an $\\widetilde{\\Omega}\\left(H\\epsilon\\right)$\nsuboptimality lower bound, giving a complete picture of this problem.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.13622v1",
    "published_date": "2024-07-18 15:58:04 UTC",
    "updated_date": "2024-07-18 15:58:04 UTC"
  },
  {
    "arxiv_id": "2408.01431v2",
    "title": "Building an Ethical and Trustworthy Biomedical AI Ecosystem for the Translational and Clinical Integration of Foundational Models",
    "authors": [
      "Simha Sankar Baradwaj",
      "Destiny Gilliland",
      "Jack Rincon",
      "Henning Hermjakob",
      "Yu Yan",
      "Irsyad Adam",
      "Gwyneth Lemaster",
      "Dean Wang",
      "Karol Watson",
      "Alex Bui",
      "Wei Wang",
      "Peipei Ping"
    ],
    "abstract": "Foundational Models (FMs) are gaining increasing attention in the biomedical\nAI ecosystem due to their ability to represent and contextualize multimodal\nbiomedical data. These capabilities make FMs a valuable tool for a variety of\ntasks, including biomedical reasoning, hypothesis generation, and interpreting\ncomplex imaging data. In this review paper, we address the unique challenges\nassociated with establishing an ethical and trustworthy biomedical AI\necosystem, with a particular focus on the development of FMs and their\ndownstream applications. We explore strategies that can be implemented\nthroughout the biomedical AI pipeline to effectively tackle these challenges,\nensuring that these FMs are translated responsibly into clinical and\ntranslational settings. Additionally, we emphasize the importance of key\nstewardship and co-design principles that not only ensure robust regulation but\nalso guarantee that the interests of all stakeholders, especially those\ninvolved in or affected by these clinical and translational applications are\nadequately represented. We aim to empower the biomedical AI community to\nharness these models responsibly and effectively. As we navigate this exciting\nfrontier, our collective commitment to ethical stewardship, co-design, and\nresponsible translation will be instrumental in ensuring that the evolution of\nFMs truly enhances patient care and medical decision making, ultimately leading\nto a more equitable and trustworthy biomedical AI ecosystem.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.01431v2",
    "published_date": "2024-07-18 15:57:58 UTC",
    "updated_date": "2024-08-14 02:28:09 UTC"
  },
  {
    "arxiv_id": "2407.13621v2",
    "title": "Differential Privacy Mechanisms in Neural Tangent Kernel Regression",
    "authors": [
      "Jiuxiang Gu",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "Training data privacy is a fundamental problem in modern Artificial\nIntelligence (AI) applications, such as face recognition, recommendation\nsystems, language generation, and many others, as it may contain sensitive user\ninformation related to legal issues. To fundamentally understand how privacy\nmechanisms work in AI applications, we study differential privacy (DP) in the\nNeural Tangent Kernel (NTK) regression setting, where DP is one of the most\npowerful tools for measuring privacy under statistical learning, and NTK is one\nof the most popular analysis frameworks for studying the learning mechanisms of\ndeep neural networks. In our work, we can show provable guarantees for both\ndifferential privacy and test accuracy of our NTK regression. Furthermore, we\nconduct experiments on the basic image classification dataset CIFAR10 to\ndemonstrate that NTK regression can preserve good accuracy under a modest\nprivacy budget, supporting the validity of our analysis. To our knowledge, this\nis the first work to provide a DP guarantee for NTK regression.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.13621v2",
    "published_date": "2024-07-18 15:57:55 UTC",
    "updated_date": "2024-11-02 05:30:20 UTC"
  },
  {
    "arxiv_id": "2407.13609v1",
    "title": "Training-free Composite Scene Generation for Layout-to-Image Synthesis",
    "authors": [
      "Jiaqi Liu",
      "Tao Huang",
      "Chang Xu"
    ],
    "abstract": "Recent breakthroughs in text-to-image diffusion models have significantly\nadvanced the generation of high-fidelity, photo-realistic images from textual\ndescriptions. Yet, these models often struggle with interpreting spatial\narrangements from text, hindering their ability to produce images with precise\nspatial configurations. To bridge this gap, layout-to-image generation has\nemerged as a promising direction. However, training-based approaches are\nlimited by the need for extensively annotated datasets, leading to high data\nacquisition costs and a constrained conceptual scope. Conversely, training-free\nmethods face challenges in accurately locating and generating semantically\nsimilar objects within complex compositions. This paper introduces a novel\ntraining-free approach designed to overcome adversarial semantic intersections\nduring the diffusion conditioning phase. By refining intra-token loss with\nselective sampling and enhancing the diffusion process with attention\nredistribution, we propose two innovative constraints: 1) an inter-token\nconstraint that resolves token conflicts to ensure accurate concept synthesis;\nand 2) a self-attention constraint that improves pixel-to-pixel relationships.\nOur evaluations confirm the effectiveness of leveraging layout information for\nguiding the diffusion process, generating content-rich images with enhanced\nfidelity and complexity. Code is available at\nhttps://github.com/Papple-F/csg.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13609v1",
    "published_date": "2024-07-18 15:48:07 UTC",
    "updated_date": "2024-07-18 15:48:07 UTC"
  },
  {
    "arxiv_id": "2407.13597v1",
    "title": "PLANTS: A Novel Problem and Dataset for Summarization of Planning-Like (PL) Tasks",
    "authors": [
      "Vishal Pallagani",
      "Biplav Srivastava",
      "Nitin Gupta"
    ],
    "abstract": "Text summarization is a well-studied problem that deals with deriving\ninsights from unstructured text consumed by humans, and it has found extensive\nbusiness applications. However, many real-life tasks involve generating a\nseries of actions to achieve specific goals, such as workflows, recipes,\ndialogs, and travel plans. We refer to them as planning-like (PL) tasks noting\nthat the main commonality they share is control flow information. which may be\npartially specified. Their structure presents an opportunity to create more\npractical summaries to help users make quick decisions. We investigate this\nobservation by introducing a novel plan summarization problem, presenting a\ndataset, and providing a baseline method for generating PL summaries. Using\nquantitative metrics and qualitative user studies to establish baselines, we\nevaluate the plan summaries from our method and large language models. We\nbelieve the novel problem and dataset can reinvigorate research in\nsummarization, which some consider as a solved problem.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13597v1",
    "published_date": "2024-07-18 15:36:02 UTC",
    "updated_date": "2024-07-18 15:36:02 UTC"
  },
  {
    "arxiv_id": "2408.01430v2",
    "title": "SUSTechGAN: Image Generation for Object Detection in Adverse Conditions of Autonomous Driving",
    "authors": [
      "Gongjin Lan",
      "Yang Peng",
      "Qi Hao",
      "Chengzhong Xu"
    ],
    "abstract": "Autonomous driving significantly benefits from data-driven deep neural\nnetworks. However, the data in autonomous driving typically fits the\nlong-tailed distribution, in which the critical driving data in adverse\nconditions is hard to collect. Although generative adversarial networks (GANs)\nhave been applied to augment data for autonomous driving, generating driving\nimages in adverse conditions is still challenging. In this work, we propose a\nnovel framework, SUSTechGAN, with customized dual attention modules,\nmulti-scale generators, and a novel loss function to generate driving images\nfor improving object detection of autonomous driving in adverse conditions. We\ntest the SUSTechGAN and the well-known GANs to generate driving images in\nadverse conditions of rain and night and apply the generated images to retrain\nobject detection networks. Specifically, we add generated images into the\ntraining datasets to retrain the well-known YOLOv5 and evaluate the improvement\nof the retrained YOLOv5 for object detection in adverse conditions. The\nexperimental results show that the generated driving images by our SUSTechGAN\nsignificantly improved the performance of retrained YOLOv5 in rain and night\nconditions, which outperforms the well-known GANs. The open-source code, video\ndescription and datasets are available on the page 1 to facilitate image\ngeneration development in autonomous driving under adverse conditions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01430v2",
    "published_date": "2024-07-18 15:32:25 UTC",
    "updated_date": "2024-12-21 07:21:14 UTC"
  },
  {
    "arxiv_id": "2407.13578v2",
    "title": "How Reliable are LLMs as Knowledge Bases? Re-thinking Facutality and Consistency",
    "authors": [
      "Danna Zheng",
      "Mirella Lapata",
      "Jeff Z. Pan"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly explored as knowledge bases\n(KBs), yet current evaluation methods focus too narrowly on knowledge\nretention, overlooking other crucial criteria for reliable performance. In this\nwork, we rethink the requirements for evaluating reliable LLM-as-KB usage and\nhighlight two essential factors: factuality, ensuring accurate responses to\nseen and unseen knowledge, and consistency, maintaining stable answers to\nquestions about the same knowledge. We introduce UnseenQA, a dataset designed\nto assess LLM performance on unseen knowledge, and propose new criteria and\nmetrics to quantify factuality and consistency, leading to a final reliability\nscore. Our experiments on 26 LLMs reveal several challenges regarding their use\nas KBs, underscoring the need for more principled and comprehensive evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13578v2",
    "published_date": "2024-07-18 15:20:18 UTC",
    "updated_date": "2024-12-16 11:23:14 UTC"
  },
  {
    "arxiv_id": "2407.13559v1",
    "title": "Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting Recognition",
    "authors": [
      "Gagan Bhatia",
      "El Moatez Billah Nagoudi",
      "Fakhraddin Alwajih",
      "Muhammad Abdul-Mageed"
    ],
    "abstract": "Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR)\npose unique challenges due to the cursive and context-sensitive nature of the\nArabic script. This study introduces Qalam, a novel foundation model designed\nfor Arabic OCR and HWR, built on a SwinV2 encoder and RoBERTa decoder\narchitecture. Our model significantly outperforms existing methods, achieving a\nWord Error Rate (WER) of just 0.80% in HWR tasks and 1.18% in OCR tasks. We\ntrain Qalam on a diverse dataset, including over 4.5 million images from Arabic\nmanuscripts and a synthetic dataset comprising 60k image-text pairs. Notably,\nQalam demonstrates exceptional handling of Arabic diacritics, a critical\nfeature in Arabic scripts. Furthermore, it shows a remarkable ability to\nprocess high-resolution inputs, addressing a common limitation in current OCR\nsystems. These advancements underscore Qalam's potential as a leading solution\nfor Arabic script recognition, offering a significant leap in accuracy and\nefficiency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13559v1",
    "published_date": "2024-07-18 14:31:09 UTC",
    "updated_date": "2024-07-18 14:31:09 UTC"
  },
  {
    "arxiv_id": "2407.13535v3",
    "title": "Visuospatial navigation without distance, prediction, integration, or maps",
    "authors": [
      "Patrick Govoni",
      "Pawel Romanczuk"
    ],
    "abstract": "Navigation is controlled by at least two partially dissociable, concurrently\ndeveloped systems in the brain. The cognitive map informs an organism of its\nlocation and bearing, updated by distance-based prediction and vestibular\nintegration. Response-based systems, on the other hand, directly evaluate\nmovement decisions from immediate percepts. Here we demonstrate the sufficiency\nof visual response-based decision-making in a classic open field navigation\ntask often assumed to require a cognitive map. Three distinct strategies emerge\nto robustly navigate to a hidden goal, each conferring contextual tradeoffs, as\nwell as aligning with behavior observed with rodents, insects, fish, and sperm\ncells. We propose reframing navigation from the bottom-up, without assuming\nonline access to computationally expensive top-down representations, to better\nexplain behavior under energetic or attentional constraints.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13535v3",
    "published_date": "2024-07-18 14:07:44 UTC",
    "updated_date": "2025-02-13 14:01:10 UTC"
  },
  {
    "arxiv_id": "2407.13524v1",
    "title": "Enhancing Source-Free Domain Adaptive Object Detection with Low-confidence Pseudo Label Distillation",
    "authors": [
      "Ilhoon Yoon",
      "Hyeongjun Kwon",
      "Jin Kim",
      "Junyoung Park",
      "Hyunsung Jang",
      "Kwanghoon Sohn"
    ],
    "abstract": "Source-Free domain adaptive Object Detection (SFOD) is a promising strategy\nfor deploying trained detectors to new, unlabeled domains without accessing\nsource data, addressing significant concerns around data privacy and\nefficiency. Most SFOD methods leverage a Mean-Teacher (MT) self-training\nparadigm relying heavily on High-confidence Pseudo Labels (HPL). However, these\nHPL often overlook small instances that undergo significant appearance changes\nwith domain shifts. Additionally, HPL ignore instances with low confidence due\nto the scarcity of training samples, resulting in biased adaptation toward\nfamiliar instances from the source domain. To address this limitation, we\nintroduce the Low-confidence Pseudo Label Distillation (LPLD) loss within the\nMean-Teacher based SFOD framework. This novel approach is designed to leverage\nthe proposals from Region Proposal Network (RPN), which potentially encompasses\nhard-to-detect objects in unfamiliar domains. Initially, we extract HPL using a\nstandard pseudo-labeling technique and mine a set of Low-confidence Pseudo\nLabels (LPL) from proposals generated by RPN, leaving those that do not overlap\nsignificantly with HPL. These LPL are further refined by leveraging\nclass-relation information and reducing the effect of inherent noise for the\nLPLD loss calculation. Furthermore, we use feature distance to adaptively\nweight the LPLD loss to focus on LPL containing a larger foreground area. Our\nmethod outperforms previous SFOD methods on four cross-domain object detection\nbenchmarks. Extensive experiments demonstrate that our LPLD loss leads to\neffective adaptation by reducing false negatives and facilitating the use of\ndomain-invariant knowledge from the source model. Code is available at\nhttps://github.com/junia3/LPLD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13524v1",
    "published_date": "2024-07-18 13:58:42 UTC",
    "updated_date": "2024-07-18 13:58:42 UTC"
  },
  {
    "arxiv_id": "2407.13505v2",
    "title": "Robots Can Multitask Too: Integrating a Memory Architecture and LLMs for Enhanced Cross-Task Robot Action Generation",
    "authors": [
      "Hassan Ali",
      "Philipp Allgeuer",
      "Carlo Mazzola",
      "Giulia Belgiovine",
      "Burak Can Kaplan",
      "Lukáš Gajdošech",
      "Stefan Wermter"
    ],
    "abstract": "Large Language Models (LLMs) have been recently used in robot applications\nfor grounding LLM common-sense reasoning with the robot's perception and\nphysical abilities. In humanoid robots, memory also plays a critical role in\nfostering real-world embodiment and facilitating long-term interactive\ncapabilities, especially in multi-task setups where the robot must remember\nprevious task states, environment states, and executed actions. In this paper,\nwe address incorporating memory processes with LLMs for generating cross-task\nrobot actions, while the robot effectively switches between tasks. Our proposed\ndual-layered architecture features two LLMs, utilizing their complementary\nskills of reasoning and following instructions, combined with a memory model\ninspired by human cognition. Our results show a significant improvement in\nperformance over a baseline of five robotic tasks, demonstrating the potential\nof integrating memory with LLMs for combining the robot's action and perception\nfor adaptive task execution.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13505v2",
    "published_date": "2024-07-18 13:38:21 UTC",
    "updated_date": "2024-10-11 08:58:20 UTC"
  },
  {
    "arxiv_id": "2407.13493v4",
    "title": "Training Foundation Models as Data Compression: On Information, Model Weights and Copyright Law",
    "authors": [
      "Giorgio Franceschelli",
      "Claudia Cevenini",
      "Mirco Musolesi"
    ],
    "abstract": "The training process of foundation models as for other classes of deep\nlearning systems is based on minimizing the reconstruction error over a\ntraining set. For this reason, they are susceptible to the memorization and\nsubsequent reproduction of training samples. In this paper, we introduce a\ntraining-as-compressing perspective, wherein the model's weights embody a\ncompressed representation of the training data. From a copyright standpoint,\nthis point of view implies that the weights can be considered a reproduction\nor, more likely, a derivative work of a potentially protected set of works. We\ninvestigate the technical and legal challenges that emerge from this framing of\nthe copyright of outputs generated by foundation models, including their\nimplications for practitioners and researchers. We demonstrate that adopting an\ninformation-centric approach to the problem presents a promising pathway for\ntackling these emerging complex legal issues.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Spotlight presentation at GenLaw'24, see\n  https://www.genlaw.org/2024-icml-papers#training-foundation-models-as-data-compression-on-information-model-weights-and-copyright-law",
    "pdf_url": "http://arxiv.org/pdf/2407.13493v4",
    "published_date": "2024-07-18 13:23:16 UTC",
    "updated_date": "2025-03-12 14:54:13 UTC"
  },
  {
    "arxiv_id": "2407.13492v3",
    "title": "Enhancing Biomedical Knowledge Discovery for Diseases: An Open-Source Framework Applied on Rett Syndrome and Alzheimer's Disease",
    "authors": [
      "Christos Theodoropoulos",
      "Andrei Catalin Coman",
      "James Henderson",
      "Marie-Francine Moens"
    ],
    "abstract": "The ever-growing volume of biomedical publications creates a critical need\nfor efficient knowledge discovery. In this context, we introduce an open-source\nend-to-end framework designed to construct knowledge around specific diseases\ndirectly from raw text. To facilitate research in disease-related knowledge\ndiscovery, we create two annotated datasets focused on Rett syndrome and\nAlzheimer's disease, enabling the identification of semantic relations between\nbiomedical entities. Extensive benchmarking explores various ways to represent\nrelations and entity representations, offering insights into optimal modeling\nstrategies for semantic relation detection and highlighting language models'\ncompetence in knowledge discovery. We also conduct probing experiments using\ndifferent layer representations and attention scores to explore transformers'\nability to capture semantic relations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in IEEE Access, doi: 10.1109/ACCESS.2024.3509714",
    "pdf_url": "http://arxiv.org/pdf/2407.13492v3",
    "published_date": "2024-07-18 13:20:53 UTC",
    "updated_date": "2024-12-04 17:05:02 UTC"
  },
  {
    "arxiv_id": "2407.13490v1",
    "title": "Combining Constraint Programming Reasoning with Large Language Model Predictions",
    "authors": [
      "Florian Régin",
      "Elisabetta De Maria",
      "Alexandre Bonlarron"
    ],
    "abstract": "Constraint Programming (CP) and Machine Learning (ML) face challenges in text\ngeneration due to CP's struggle with implementing \"meaning'' and ML's\ndifficulty with structural constraints. This paper proposes a solution by\ncombining both approaches and embedding a Large Language Model (LLM) in CP. The\nLLM handles word generation and meaning, while CP manages structural\nconstraints. This approach builds on GenCP, an improved version of On-the-fly\nConstraint Programming Search (OTFS) using LLM-generated domains. Compared to\nBeam Search (BS), a standard NLP method, this combined approach (GenCP with\nLLM) is faster and produces better results, ensuring all constraints are\nsatisfied. This fusion of CP and ML presents new possibilities for enhancing\ntext generation under constraints.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at The 30th International Conference on Principles and\n  Practice of Constraint Programming (CP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.13490v1",
    "published_date": "2024-07-18 13:15:55 UTC",
    "updated_date": "2024-07-18 13:15:55 UTC"
  },
  {
    "arxiv_id": "2408.01429v1",
    "title": "An Agile Adaptation Method for Multi-mode Vehicle Communication Networks",
    "authors": [
      "Shiwen He",
      "Kanghong Chen",
      "Shiyue Huang",
      "Wei Huang",
      "Zhenyu An"
    ],
    "abstract": "This paper focuses on discovering the impact of communication mode allocation\non communication efficiency in the vehicle communication networks. To be\nspecific, Markov decision process and reinforcement learning are applied to\nestablish an agile adaptation mechanism for multi-mode communication devices\naccording to the driving scenarios and business requirements. Then, Q-learning\nis used to train the agile adaptation reinforcement learning model and output\nthe trained model. By learning the best actions to take in different states to\nmaximize the cumulative reward, and avoiding the problem of poor adaptation\neffect caused by inaccurate delay measurement in unstable communication\nscenarios. The experiments show that the proposed scheme can quickly adapt to\ndynamic vehicle networking environment, while achieving high concurrency and\ncommunication efficiency.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01429v1",
    "published_date": "2024-07-18 13:04:34 UTC",
    "updated_date": "2024-07-18 13:04:34 UTC"
  },
  {
    "arxiv_id": "2407.13480v1",
    "title": "Risk-Aware Vehicle Trajectory Prediction Under Safety-Critical Scenarios",
    "authors": [
      "Qingfan Wang",
      "Dongyang Xu",
      "Gaoyuan Kuang",
      "Chen Lv",
      "Shengbo Eben Li",
      "Bingbing Nie"
    ],
    "abstract": "Trajectory prediction is significant for intelligent vehicles to achieve\nhigh-level autonomous driving, and a lot of relevant research achievements have\nbeen made recently. Despite the rapid development, most existing studies solely\nfocused on normal safe scenarios while largely neglecting safety-critical\nscenarios, particularly those involving imminent collisions. This oversight may\nresult in autonomous vehicles lacking the essential predictive ability in such\nsituations, posing a significant threat to safety. To tackle these, this paper\nproposes a risk-aware trajectory prediction framework tailored to\nsafety-critical scenarios. Leveraging distinctive hazardous features, we\ndevelop three core risk-aware components. First, we introduce a\nrisk-incorporated scene encoder, which augments conventional encoders with\nquantitative risk information to achieve risk-aware encoding of hazardous scene\ncontexts. Next, we incorporate endpoint-risk-combined intention queries as\nprediction priors in the decoder to ensure that the predicted multimodal\ntrajectories cover both various spatial intentions and risk levels. Lastly, an\nauxiliary risk prediction task is implemented for the ultimate risk-aware\nprediction. Furthermore, to support model training and performance evaluation,\nwe introduce a safety-critical trajectory prediction dataset and tailored\nevaluation metrics. We conduct comprehensive evaluations and compare our model\nwith several SOTA models. Results demonstrate the superior performance of our\nmodel, with a significant improvement in most metrics. This prediction\nadvancement enables autonomous vehicles to execute correct collision avoidance\nmaneuvers under safety-critical scenarios, eventually enhancing road traffic\nsafety.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13480v1",
    "published_date": "2024-07-18 13:00:01 UTC",
    "updated_date": "2024-07-18 13:00:01 UTC"
  },
  {
    "arxiv_id": "2407.13463v1",
    "title": "End-To-End Clinical Trial Matching with Large Language Models",
    "authors": [
      "Dyke Ferber",
      "Lars Hilgers",
      "Isabella C. Wiest",
      "Marie-Elisabeth Leßmann",
      "Jan Clusmann",
      "Peter Neidlinger",
      "Jiefu Zhu",
      "Georg Wölflein",
      "Jacqueline Lammert",
      "Maximilian Tschochohei",
      "Heiko Böhme",
      "Dirk Jäger",
      "Mihaela Aldea",
      "Daniel Truhn",
      "Christiane Höper",
      "Jakob Nikolas Kather"
    ],
    "abstract": "Matching cancer patients to clinical trials is essential for advancing\ntreatment and patient care. However, the inconsistent format of medical free\ntext documents and complex trial eligibility criteria make this process\nextremely challenging and time-consuming for physicians. We investigated\nwhether the entire trial matching process - from identifying relevant trials\namong 105,600 oncology-related clinical trials on clinicaltrials.gov to\ngenerating criterion-level eligibility matches - could be automated using Large\nLanguage Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic\nHealth Records (EHRs), we demonstrate that our approach identifies relevant\ncandidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%\nwhen matching patient-level information at the criterion level against a\nbaseline defined by human experts. Utilizing LLM feedback reveals that 39.3%\ncriteria that were initially considered incorrect are either ambiguous or\ninaccurately annotated, leading to a total model accuracy of 92.7% after\nrefining our human baseline. In summary, we present an end-to-end pipeline for\nclinical trial matching using LLMs, demonstrating high precision in screening\nand matching trials to individual patients, even outperforming the performance\nof qualified medical doctors. Our fully end-to-end pipeline can operate\nautonomously or with human supervision and is not restricted to oncology,\noffering a scalable solution for enhancing patient-trial matching in real-world\nsettings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "149 pages, including Supplements. 3 Main Figures",
    "pdf_url": "http://arxiv.org/pdf/2407.13463v1",
    "published_date": "2024-07-18 12:36:26 UTC",
    "updated_date": "2024-07-18 12:36:26 UTC"
  },
  {
    "arxiv_id": "2407.13439v1",
    "title": "Reducing Barriers to the Use of Marginalised Music Genres in AI",
    "authors": [
      "Nick Bryan-Kinns",
      "Zijin Li"
    ],
    "abstract": "AI systems for high quality music generation typically rely on extremely\nlarge musical datasets to train the AI models. This creates barriers to\ngenerating music beyond the genres represented in dominant datasets such as\nWestern Classical music or pop music. We undertook a 4 month international\nresearch project summarised in this paper to explore the eXplainable AI (XAI)\nchallenges and opportunities associated with reducing barriers to using\nmarginalised genres of music with AI models. XAI opportunities identified\nincluded topics of improving transparency and control of AI models, explaining\nthe ethics and bias of AI models, fine tuning large models with small datasets\nto reduce bias, and explaining style-transfer opportunities with AI models.\nParticipants in the research emphasised that whilst it is hard to work with\nsmall datasets such as marginalised music and AI, such approaches strengthen\ncultural representation of underrepresented cultures and contribute to\naddressing issues of bias of deep learning models. We are now building on this\nproject to bring together a global International Responsible AI Music community\nand invite people to join our network.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "In Proceedings of Explainable AI for the Arts Workshop 2024 (XAIxArts\n  2024) arXiv:2406.14485",
    "pdf_url": "http://arxiv.org/pdf/2407.13439v1",
    "published_date": "2024-07-18 12:10:04 UTC",
    "updated_date": "2024-07-18 12:10:04 UTC"
  },
  {
    "arxiv_id": "2407.13431v3",
    "title": "Improving Out-of-Distribution Generalization of Trajectory Prediction for Autonomous Driving via Polynomial Representations",
    "authors": [
      "Yue Yao",
      "Shengchao Yan",
      "Daniel Goehring",
      "Wolfram Burgard",
      "Joerg Reichardt"
    ],
    "abstract": "Robustness against Out-of-Distribution (OoD) samples is a key performance\nindicator of a trajectory prediction model. However, the development and\nranking of state-of-the-art (SotA) models are driven by their In-Distribution\n(ID) performance on individual competition datasets. We present an OoD testing\nprotocol that homogenizes datasets and prediction tasks across two large-scale\nmotion datasets. We introduce a novel prediction algorithm based on polynomial\nrepresentations for agent trajectory and road geometry on both the input and\noutput sides of the model. With a much smaller model size, training effort, and\ninference time, we reach near SotA performance for ID testing and significantly\nimprove robustness in OoD testing. Within our OoD testing protocol, we further\nstudy two augmentation strategies of SotA models and their effects on model\ngeneralization. Highlighting the contrast between ID and OoD performance, we\nsuggest adding OoD testing to the evaluation criteria of trajectory prediction\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13431v3",
    "published_date": "2024-07-18 12:00:32 UTC",
    "updated_date": "2025-01-25 17:38:56 UTC"
  },
  {
    "arxiv_id": "2407.13429v1",
    "title": "Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information",
    "authors": [
      "Fedor Sergeev",
      "Paola Malsot",
      "Gunnar Rätsch",
      "Vincent Fortuin"
    ],
    "abstract": "Knowing which features of a multivariate time series to measure and when is a\nkey task in medicine, wearables, and robotics. Better acquisition policies can\nreduce costs while maintaining or even improving the performance of downstream\npredictors. Inspired by the maximization of conditional mutual information, we\npropose an approach to train acquirers end-to-end using only the downstream\nloss. We show that our method outperforms random acquisition policy, matches a\nmodel with an unrestrained budget, but does not yet overtake a static\nacquisition strategy. We highlight the assumptions and outline avenues for\nfuture work.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the ICML 2024 Next Generation of Sequence Modeling\n  Architectures (NGSM) Workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.13429v1",
    "published_date": "2024-07-18 11:54:34 UTC",
    "updated_date": "2024-07-18 11:54:34 UTC"
  },
  {
    "arxiv_id": "2407.13427v3",
    "title": "DeepClair: Utilizing Market Forecasts for Effective Portfolio Selection",
    "authors": [
      "Donghee Choi",
      "Jinkyu Kim",
      "Mogan Gim",
      "Jinho Lee",
      "Jaewoo Kang"
    ],
    "abstract": "Utilizing market forecasts is pivotal in optimizing portfolio selection\nstrategies. We introduce DeepClair, a novel framework for portfolio selection.\nDeepClair leverages a transformer-based time-series forecasting model to\npredict market trends, facilitating more informed and adaptable portfolio\ndecisions. To integrate the forecasting model into a deep reinforcement\nlearning-driven portfolio selection framework, we introduced a two-step\nstrategy: first, pre-training the time-series model on market data, followed by\nfine-tuning the portfolio selection architecture using this model.\nAdditionally, we investigated the optimization technique, Low-Rank Adaptation\n(LoRA), to enhance the pre-trained forecasting model for fine-tuning in\ninvestment scenarios. This work bridges market forecasting and portfolio\nselection, facilitating the advancement of investment strategies.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "CIKM 2024 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2407.13427v3",
    "published_date": "2024-07-18 11:51:03 UTC",
    "updated_date": "2024-08-16 06:54:26 UTC"
  },
  {
    "arxiv_id": "2407.13419v1",
    "title": "From Words to Worlds: Compositionality for Cognitive Architectures",
    "authors": [
      "Ruchira Dhar",
      "Anders Søgaard"
    ],
    "abstract": "Large language models (LLMs) are very performant connectionist systems, but\ndo they exhibit more compositionality? More importantly, is that part of why\nthey perform so well? We present empirical analyses across four LLM families\n(12 models) and three task categories, including a novel task introduced below.\nOur findings reveal a nuanced relationship in learning of compositional\nstrategies by LLMs -- while scaling enhances compositional abilities,\ninstruction tuning often has a reverse effect. Such disparity brings forth some\nopen issues regarding the development and improvement of large language models\nin alignment with human cognitive capacities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML 2024 Workshop on LLMs & Cognition",
    "pdf_url": "http://arxiv.org/pdf/2407.13419v1",
    "published_date": "2024-07-18 11:42:13 UTC",
    "updated_date": "2024-07-18 11:42:13 UTC"
  },
  {
    "arxiv_id": "2407.13408v1",
    "title": "DISCOVER: A Data-driven Interactive System for Comprehensive Observation, Visualization, and ExploRation of Human Behaviour",
    "authors": [
      "Dominik Schiller",
      "Tobias Hallmen",
      "Daksitha Withanage Don",
      "Elisabeth André",
      "Tobias Baur"
    ],
    "abstract": "Understanding human behavior is a fundamental goal of social sciences, yet\nits analysis presents significant challenges. Conventional methodologies\nemployed for the study of behavior, characterized by labor-intensive data\ncollection processes and intricate analyses, frequently hinder comprehensive\nexploration due to their time and resource demands. In response to these\nchallenges, computational models have proven to be promising tools that help\nresearchers analyze large amounts of data by automatically identifying\nimportant behavioral indicators, such as social signals. However, the\nwidespread adoption of such state-of-the-art computational models is impeded by\ntheir inherent complexity and the substantial computational resources necessary\nto run them, thereby constraining accessibility for researchers without\ntechnical expertise and adequate equipment. To address these barriers, we\nintroduce DISCOVER -- a modular and flexible, yet user-friendly software\nframework specifically developed to streamline computational-driven data\nexploration for human behavior analysis. Our primary objective is to\ndemocratize access to advanced computational methodologies, thereby enabling\nresearchers across disciplines to engage in detailed behavioral analysis\nwithout the need for extensive technical proficiency. In this paper, we\ndemonstrate the capabilities of DISCOVER using four exemplary data exploration\nworkflows that build on each other: Interactive Semantic Content Exploration,\nVisual Inspection, Aided Annotation, and Multimodal Scene Search. By\nillustrating these workflows, we aim to emphasize the versatility and\naccessibility of DISCOVER as a comprehensive framework and propose a set of\nblueprints that can serve as a general starting point for exploratory data\nanalysis.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "J.4"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13408v1",
    "published_date": "2024-07-18 11:28:52 UTC",
    "updated_date": "2024-07-18 11:28:52 UTC"
  },
  {
    "arxiv_id": "2407.13399v3",
    "title": "Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization",
    "authors": [
      "Audrey Huang",
      "Wenhao Zhan",
      "Tengyang Xie",
      "Jason D. Lee",
      "Wen Sun",
      "Akshay Krishnamurthy",
      "Dylan J. Foster"
    ],
    "abstract": "Language model alignment methods such as reinforcement learning from human\nfeedback (RLHF) have led to impressive advances in language model capabilities,\nbut are limited by a widely observed phenomenon known as overoptimization,\nwhere the quality of the language model degrades over the course of the\nalignment process. As the model optimizes performance with respect to an\noffline reward model, it overfits to inaccuracies and drifts away from\npreferred responses covered by the data. To discourage such distribution shift,\nKL-regularization is widely employed in existing offline alignment methods, but\noveroptimization continues to harm performance. Lending theoretical insight\ninto the source of these empirical observations, we first show that the\nKL-regularization is too weak to prevent overfitting, then raise the following\nquestion: is it possible to design an efficient algorithm that is provably\nrobust to overoptimization?\n  We address this question with a new algorithm for offline alignment,\n$\\chi^2$-Preference Optimization ($\\chi$PO). $\\chi$PO is a one-line change to\nDirect Preference Optimization (DPO; Rafailov et al., 2023), which only\ninvolves modifying the logarithmic link function in the DPO objective. Despite\nthis minimal change, $\\chi$PO implicitly implements the principle of pessimism\nin the face of uncertainty via regularization with the $\\chi^2$-divergence --\nwhich quantifies uncertainty more effectively than KL-regularization -- and\nprovably alleviates overoptimization, achieving sample-complexity guarantees\nbased on single-policy concentrability -- the gold standard in offline\nreinforcement learning. $\\chi$PO's simplicity and strong guarantees make it the\nfirst practical and general-purpose offline alignment algorithm that is\nprovably robust to overoptimization.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13399v3",
    "published_date": "2024-07-18 11:08:40 UTC",
    "updated_date": "2025-02-18 17:16:55 UTC"
  },
  {
    "arxiv_id": "2407.19072v1",
    "title": "Configural processing as an optimized strategy for robust object recognition in neural networks",
    "authors": [
      "Hojin Jang",
      "Pawan Sinha",
      "Xavier Boix"
    ],
    "abstract": "Configural processing, the perception of spatial relationships among an\nobject's components, is crucial for object recognition. However, the teleology\nand underlying neurocomputational mechanisms of such processing are still\nelusive, notwithstanding decades of research. We hypothesized that processing\nobjects via configural cues provides a more robust means to recognizing them\nrelative to local featural cues. We evaluated this hypothesis by devising\nidentification tasks with composite letter stimuli and comparing different\nneural network models trained with either only local or configural cues\navailable. We found that configural cues yielded more robust performance to\ngeometric transformations such as rotation or scaling. Furthermore, when both\nfeatures were simultaneously available, configural cues were favored over local\nfeatural cues. Layerwise analysis revealed that the sensitivity to configural\ncues emerged later relative to local feature cues, possibly contributing to the\nrobustness to pixel-level transformations. Notably, this configural processing\noccurred in a purely feedforward manner, without the need for recurrent\ncomputations. Our findings with letter stimuli were successfully extended to\nnaturalistic face images. Thus, our study provides neurocomputational evidence\nthat configural processing emerges in a na\\\"ive network based on task\ncontingencies, and is beneficial for robust object processing under varying\nviewing conditions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19072v1",
    "published_date": "2024-07-18 10:39:14 UTC",
    "updated_date": "2024-07-18 10:39:14 UTC"
  },
  {
    "arxiv_id": "2407.13377v1",
    "title": "Linear-Complexity Self-Supervised Learning for Speech Processing",
    "authors": [
      "Shucong Zhang",
      "Titouan Parcollet",
      "Rogier van Dalen",
      "Sourav Bhattacharya"
    ],
    "abstract": "Self-supervised learning (SSL) models usually require weeks of pre-training\nwith dozens of high-end GPUs. These models typically have a multi-headed\nself-attention (MHSA) context encoder. However, MHSA takes quadratic time and\nspace in the input length, contributing to the high pre-training cost.\nLinear-complexity alternatives to MHSA have been proposed. For instance, in\nsupervised training, the SummaryMixing model is the first to outperform MHSA\nacross multiple speech processing tasks. However, these cheaper alternatives\nhave not been explored for SSL yet. This paper studies a linear-complexity\ncontext encoder for SSL for the first time. With better or equivalent\nperformance for the downstream tasks of the MP3S benchmark, SummaryMixing\nreduces the pre-training time and peak VRAM of wav2vec 2.0 model by 18% and by\n23%, respectively, leading to the pre-training of a 155M wav2vec 2.0 model\nfinished within one week with 4 Tesla A100 GPUs. Code is available at\nhttps://github.com/SamsungLabs/SummaryMixing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13377v1",
    "published_date": "2024-07-18 10:34:33 UTC",
    "updated_date": "2024-07-18 10:34:33 UTC"
  },
  {
    "arxiv_id": "2408.00004v1",
    "title": "Handling Numeric Expressions in Automatic Speech Recognition",
    "authors": [
      "Christian Huber",
      "Alexander Waibel"
    ],
    "abstract": "This paper addresses the problem of correctly formatting numeric expressions\nin automatic speech recognition (ASR) transcripts. This is challenging since\nthe expected transcript format depends on the context, e.g., 1945 (year) vs.\n19:45 (timestamp). We compare cascaded and end-to-end approaches to recognize\nand format numeric expression, such as years, timestamps, currency amounts, and\nquantities. For the end-to-end approach we employed a data generation strategy\nusing a large language model (LLM) together with a text to speech (TTS) model\nto generate adaptation data. The results on our test dataset show that while\napproaches based on LLMs perform well on recognizing formatted numeric\nexpressions, adapted end-to-end models offer competitive performance with the\nadvantage of lower latency and inference cost.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00004v1",
    "published_date": "2024-07-18 09:46:19 UTC",
    "updated_date": "2024-07-18 09:46:19 UTC"
  },
  {
    "arxiv_id": "2407.13320v1",
    "title": "Deep Reinforcement Learning for Multi-Objective Optimization: Enhancing Wind Turbine Energy Generation while Mitigating Noise Emissions",
    "authors": [
      "Martín de Frutos",
      "Oscar A. Marino",
      "David Huergo",
      "Esteban Ferrer"
    ],
    "abstract": "We develop a torque-pitch control framework using deep reinforcement learning\nfor wind turbines to optimize the generation of wind turbine energy while\nminimizing operational noise. We employ a double deep Q-learning, coupled to a\nblade element momentum solver, to enable precise control over wind turbine\nparameters. In addition to the blade element momentum, we use the wind turbine\nacoustic model of Brooks Pope and Marcolini. Through training with simple\nwinds, the agent learns optimal control policies that allow efficient control\nfor complex turbulent winds. Our experiments demonstrate that the reinforcement\nlearning is able to find optima at the Pareto front, when maximizing energy\nwhile minimizing noise. In addition, the adaptability of the reinforcement\nlearning agent to changing turbulent wind conditions, underscores its efficacy\nfor real-world applications. We validate the methodology using a SWT2.3-93 wind\nturbine with a rated power of 2.3 MW. We compare the reinforcement learning\ncontrol to classic controls to show that they are comparable when not taking\ninto account noise emissions. When including a maximum limit of 45 dB to the\nnoise produced (100 meters downwind of the turbine), the extracted yearly\nenergy decreases by 22%. The methodology is flexible and allows for easy tuning\nof the objectives and constraints through the reward definitions, resulting in\na flexible multi-objective optimization framework for wind turbine control.\nOverall, our findings highlight the potential of RL-based control strategies to\nimprove wind turbine efficiency while mitigating noise pollution, thus\nadvancing sustainable energy generation technologies",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13320v1",
    "published_date": "2024-07-18 09:21:51 UTC",
    "updated_date": "2024-07-18 09:21:51 UTC"
  },
  {
    "arxiv_id": "2407.13313v2",
    "title": "Sortability of Time Series Data",
    "authors": [
      "Christopher Lohse",
      "Jonas Wahl"
    ],
    "abstract": "Evaluating the performance of causal discovery algorithms that aim to find\ncausal relationships between time-dependent processes remains a challenging\ntopic. In this paper, we show that certain characteristics of datasets, such as\nvarsortability (Reisach et al. 2021) and $R^2$-sortability (Reisach et al.\n2023), also occur in datasets for autocorrelated stationary time series. We\nillustrate this empirically using four types of data: simulated data based on\nSVAR models and Erd\\H{o}s-R\\'enyi graphs, the data used in the 2019\ncausality-for-climate challenge (Runge et al. 2019), real-world river stream\ndatasets, and real-world data generated by the Causal Chamber of (Gamella et\nal. 2024). To do this, we adapt var- and $R^2$-sortability to time series data.\nWe also investigate the extent to which the performance of score-based causal\ndiscovery methods goes hand in hand with high sortability. Arguably, our most\nsurprising finding is that the investigated real-world datasets exhibit high\nvarsortability and low $R^2$-sortability indicating that scales may carry a\nsignificant amount of causal information.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Contribution for the Causal Inference for Time Series Data Workshop\n  at the 40th Conference on Uncertainty in Artificial Intelligence (CI4TS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.13313v2",
    "published_date": "2024-07-18 09:15:39 UTC",
    "updated_date": "2024-07-23 14:34:47 UTC"
  },
  {
    "arxiv_id": "2407.13301v2",
    "title": "CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis",
    "authors": [
      "Junying Chen",
      "Chi Gui",
      "Anningzhe Gao",
      "Ke Ji",
      "Xidong Wang",
      "Xiang Wan",
      "Benyou Wang"
    ],
    "abstract": "The field of medical diagnosis has undergone a significant transformation\nwith the advent of large language models (LLMs), yet the challenges of\ninterpretability within these models remain largely unaddressed. This study\nintroduces Chain-of-Diagnosis (CoD) to enhance the interpretability of\nLLM-based medical diagnostics. CoD transforms the diagnostic process into a\ndiagnostic chain that mirrors a physician's thought process, providing a\ntransparent reasoning pathway. Additionally, CoD outputs the disease confidence\ndistribution to ensure transparency in decision-making. This interpretability\nmakes model diagnostics controllable and aids in identifying critical symptoms\nfor inquiry through the entropy reduction of confidences. With CoD, we\ndeveloped DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental\nresults demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic\nbenchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring\ncontrollability in diagnostic rigor.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13301v2",
    "published_date": "2024-07-18 09:06:27 UTC",
    "updated_date": "2024-09-15 08:43:17 UTC"
  },
  {
    "arxiv_id": "2407.15869v1",
    "title": "Long Input Sequence Network for Long Time Series Forecasting",
    "authors": [
      "Chao Ma",
      "Yikai Hou",
      "Xiang Li",
      "Yinggang Sun",
      "Haining Yu"
    ],
    "abstract": "Short fixed-length inputs are the main bottleneck of deep learning methods in\nlong time-series forecasting tasks. Prolonging input length causes overfitting,\nrapidly deteriorating accuracy. Our research indicates that the overfitting is\na combination reaction of the multi-scale pattern coupling in time series and\nthe fixed focusing scale of current models. First, we find that the patterns\nexhibited by a time series across various scales are reflective of its\nmulti-periodic nature, where each scale corresponds to specific period length.\nSecond, We find that the token size predominantly dictates model behavior, as\nit determines the scale at which the model focuses and the context size it can\naccommodate. Our idea is to decouple the multi-scale temporal patterns of time\nseries and to model each pattern with its corresponding period length as token\nsize. We introduced a novel series-decomposition module(MPSD), and a\nMulti-Token Pattern Recognition neural network(MTPR), enabling the model to\nhandle \\textit{inputs up to $10\\times$ longer}. Sufficient context enhances\nperformance(\\textit{38% maximum precision improvement}), and the decoupling\napproach offers \\textit{Low complexity($0.22\\times$ cost)} and \\textit{high\ninterpretability}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.15869v1",
    "published_date": "2024-07-18 08:43:12 UTC",
    "updated_date": "2024-07-18 08:43:12 UTC"
  },
  {
    "arxiv_id": "2407.13285v1",
    "title": "Collaborative real-time vision-based device for olive oil production monitoring",
    "authors": [
      "Matija Šuković",
      "Igor Jovančević"
    ],
    "abstract": "This paper proposes an innovative approach to improving quality control of\nolive oil manufacturing and preventing damage to the machinery caused by\nforeign objects. We developed a computer-vision-based system that monitors the\ninput of an olive grinder and promptly alerts operators if a foreign object is\ndetected, indicating it by using guided lasers, audio, and visual cues.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.13285v1",
    "published_date": "2024-07-18 08:37:08 UTC",
    "updated_date": "2024-07-18 08:37:08 UTC"
  },
  {
    "arxiv_id": "2407.13268v2",
    "title": "Mixture of Experts based Multi-task Supervise Learning from Crowds",
    "authors": [
      "Tao Han",
      "Huaixuan Shi",
      "Xinyi Ding",
      "Xiao Ma",
      "Huamao Gu",
      "Yili Fang"
    ],
    "abstract": "Existing truth inference methods in crowdsourcing aim to map redundant labels\nand items to the ground truth. They treat the ground truth as hidden variables\nand use statistical or deep learning-based worker behavior models to infer the\nground truth. However, worker behavior models that rely on ground truth hidden\nvariables overlook workers' behavior at the item feature level, leading to\nimprecise characterizations and negatively impacting the quality of truth\ninference. This paper proposes a new paradigm of multi-task supervised learning\nfrom crowds, which eliminates the need for modeling of items's ground truth in\nworker behavior models. Within this paradigm, we propose a worker behavior\nmodel at the item feature level called Mixture of Experts based Multi-task\nSupervised Learning from Crowds (MMLC). Two truth inference strategies are\nproposed within MMLC. The first strategy, named MMLC-owf, utilizes clustering\nmethods in the worker spectral space to identify the projection vector of the\noracle worker. Subsequently, the labels generated based on this vector are\nconsidered as the inferred truth. The second strategy, called MMLC-df, employs\nthe MMLC model to fill the crowdsourced data, which can enhance the\neffectiveness of existing truth inference methods. Experimental results\ndemonstrate that MMLC-owf outperforms state-of-the-art methods and MMLC-df\nenhances the quality of existing truth inference methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13268v2",
    "published_date": "2024-07-18 08:21:31 UTC",
    "updated_date": "2025-03-12 15:25:11 UTC"
  },
  {
    "arxiv_id": "2407.13264v1",
    "title": "Underwater Acoustic Signal Denoising Algorithms: A Survey of the State-of-the-art",
    "authors": [
      "Ruobin Gao",
      "Maohan Liang",
      "Heng Dong",
      "Xuewen Luo",
      "P. N. Suganthan"
    ],
    "abstract": "This paper comprehensively reviews recent advances in underwater acoustic\nsignal denoising, an area critical for improving the reliability and clarity of\nunderwater communication and monitoring systems. Despite significant progress\nin the field, the complex nature of underwater environments poses unique\nchallenges that complicate the denoising process. We begin by outlining the\nfundamental challenges associated with underwater acoustic signal processing,\nincluding signal attenuation, noise variability, and the impact of\nenvironmental factors. The review then systematically categorizes and discusses\nvarious denoising algorithms, such as conventional, decomposition-based, and\nlearning-based techniques, highlighting their applications, advantages, and\nlimitations. Evaluation metrics and experimental datasets are also reviewed.\nThe paper concludes with a list of open questions and recommendations for\nfuture research directions, emphasizing the need for developing more robust\ndenoising techniques that can adapt to the dynamic underwater acoustic\nenvironment.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13264v1",
    "published_date": "2024-07-18 08:14:59 UTC",
    "updated_date": "2024-07-18 08:14:59 UTC"
  },
  {
    "arxiv_id": "2407.13241v1",
    "title": "NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations",
    "authors": [
      "Hao Bai",
      "Yi Hong"
    ],
    "abstract": "Regression on medical image sequences can capture temporal image pattern\nchanges and predict images at missing or future time points. However, existing\ngeodesic regression methods limit their regression performance by a strong\nunderlying assumption of linear dynamics, while diffusion-based methods have\nhigh computational costs and lack constraints to preserve image topology. In\nthis paper, we propose an optimization-based new framework called NODER, which\nleverages neural ordinary differential equations to capture complex underlying\ndynamics and reduces its high computational cost of handling high-dimensional\nimage volumes by introducing the latent space. We compare our NODER with two\nrecent regression methods, and the experimental results on ADNI and ACDC\ndatasets demonstrate that our method achieves the state-of-the-art performance\nin 3D image regression. Our model needs only a couple of images in a sequence\nfor prediction, which is practical, especially for clinical situations where\nextremely limited image time series are available for analysis. Our source code\nis available at https://github.com/ZedKing12138/NODER-pytorch.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "MICCAI2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13241v1",
    "published_date": "2024-07-18 07:50:46 UTC",
    "updated_date": "2024-07-18 07:50:46 UTC"
  },
  {
    "arxiv_id": "2407.13237v1",
    "title": "LLM-Empowered State Representation for Reinforcement Learning",
    "authors": [
      "Boyuan Wang",
      "Yun Qu",
      "Yuhang Jiang",
      "Jianzhun Shao",
      "Chang Liu",
      "Wenming Yang",
      "Xiangyang Ji"
    ],
    "abstract": "Conventional state representations in reinforcement learning often omit\ncritical task-related details, presenting a significant challenge for value\nnetworks in establishing accurate mappings from states to task rewards.\nTraditional methods typically depend on extensive sample learning to enrich\nstate representations with task-specific information, which leads to low sample\nefficiency and high time costs. Recently, surging knowledgeable large language\nmodels (LLM) have provided promising substitutes for prior injection with\nminimal human intervention. Motivated by this, we propose LLM-Empowered State\nRepresentation (LESR), a novel approach that utilizes LLM to autonomously\ngenerate task-related state representation codes which help to enhance the\ncontinuity of network mappings and facilitate efficient training. Experimental\nresults demonstrate LESR exhibits high sample efficiency and outperforms\nstate-of-the-art baselines by an average of 29% in accumulated reward in Mujoco\ntasks and 30% in success rates in Gym-Robotics tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13237v1",
    "published_date": "2024-07-18 07:47:51 UTC",
    "updated_date": "2024-07-18 07:47:51 UTC"
  },
  {
    "arxiv_id": "2407.13218v3",
    "title": "LiNR: Model Based Neural Retrieval on GPUs at LinkedIn",
    "authors": [
      "Fedor Borisyuk",
      "Qingquan Song",
      "Mingzhou Zhou",
      "Ganesh Parameswaran",
      "Madhu Arun",
      "Siva Popuri",
      "Tugrul Bingol",
      "Zhuotao Pei",
      "Kuang-Hsuan Lee",
      "Lu Zheng",
      "Qizhan Shao",
      "Ali Naqvi",
      "Sen Zhou",
      "Aman Gupta"
    ],
    "abstract": "This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval\nsystem. LiNR supports a billion-sized index on GPU models. We discuss our\nexperiences and challenges in creating scalable, differentiable search indexes\nusing TensorFlow and PyTorch at production scale. In LiNR, both items and model\nweights are integrated into the model binary. Viewing index construction as a\nform of model training, we describe scaling our system for large indexes,\nincorporating full scans and efficient filtering. A key focus is on enabling\nattribute-based pre-filtering for exhaustive GPU searches, addressing the\ncommon challenge of post-filtering in KNN searches that often reduces system\nquality. We further provide multi-embedding retrieval algorithms and strategies\nfor tackling cold start issues in retrieval. Our advancements in supporting\nlarger indexes through quantization are also discussed. We believe LiNR\nrepresents one of the industry's first Live-updated model-based retrieval\nindexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR\nhas contributed to a 3% relative increase in professional daily active users.\nWe envisage LiNR as a step towards integrating retrieval and ranking into a\nsingle GPU model, simplifying complex infrastructures and enabling end-to-end\noptimization of the entire differentiable infrastructure through gradient\ndescent.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13218v3",
    "published_date": "2024-07-18 07:04:33 UTC",
    "updated_date": "2024-08-07 16:57:06 UTC"
  },
  {
    "arxiv_id": "2407.13806v1",
    "title": "Revisiting Attention for Multivariate Time Series Forecasting",
    "authors": [
      "Haixiang Wu"
    ],
    "abstract": "Current Transformer methods for Multivariate Time-Series Forecasting (MTSF)\nare all based on the conventional attention mechanism. They involve sequence\nembedding and performing a linear projection of Q, K, and V, and then computing\nattention within this latent space. We have never delved into the attention\nmechanism to explore whether such a mapping space is optimal for MTSF. To\ninvestigate this issue, this study first proposes Frequency Spectrum attention\n(FSatten), a novel attention mechanism based on the frequency domain space. It\nemploys the Fourier transform for embedding and introduces Multi-head Spectrum\nScaling (MSS) to replace the conventional linear mapping of Q and K. FSatten\ncan accurately capture the periodic dependencies between sequences and\noutperform the conventional attention without changing mainstream\narchitectures. We further design a more general method dubbed Scaled Orthogonal\nattention (SOatten). We propose an orthogonal embedding and a Head-Coupling\nConvolution (HCC) based on the neighboring similarity bias to guide the model\nin learning comprehensive dependency patterns. Experiments show that FSatten\nand SOatten surpass the SOTA which uses conventional attention, making it a\ngood alternative as a basic attention mechanism for MTSF. The codes and log\nfiles will be released at: https://github.com/Joeland4/FSatten-SOatten.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13806v1",
    "published_date": "2024-07-18 06:28:20 UTC",
    "updated_date": "2024-07-18 06:28:20 UTC"
  },
  {
    "arxiv_id": "2407.13195v4",
    "title": "Scalable Thompson Sampling via Ensemble++ Agent",
    "authors": [
      "Yingru Li",
      "Jiawei Xu",
      "Baoxiang Wang",
      "Zhi-Quan Luo"
    ],
    "abstract": "Thompson Sampling is a principled method for balancing exploration and\nexploitation, but its real-world adoption is impeded by the high computational\noverhead of posterior maintenance in large-scale or non-conjugate settings.\nEnsemble-based approaches offer partial remedies, but often require a large\nensemble size. This paper proposes the Ensemble++, a scalable agent that\nsidesteps these limitations by a shared-factor ensemble update architecture and\na random linear combination scheme. We theoretically justify that in linear\nbandits, Ensemble++ agent only needs an ensemble size of $\\Theta(d \\log T)$ to\nachieve regret guarantees comparable to exact Thompson Sampling. Further, to\nhandle nonlinear rewards and complex environments. we introduce a neural\nextension that replaces fixed features with a learnable representation,\npreserving the same underlying objective via gradient-based updates. Empirical\nresults confirm that Ensemble++ agent excel in both sample efficiency and\ncomputational scalability across linear and nonlinear environments, including\nGPT-based contextual bandits.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.13195v4",
    "published_date": "2024-07-18 06:16:09 UTC",
    "updated_date": "2025-02-01 04:04:46 UTC"
  },
  {
    "arxiv_id": "2407.13194v1",
    "title": "Robust Multivariate Time Series Forecasting against Intra- and Inter-Series Transitional Shift",
    "authors": [
      "Hui He",
      "Qi Zhang",
      "Kun Yi",
      "Xiaojun Xue",
      "Shoujin Wang",
      "Liang Hu",
      "Longbing Cao"
    ],
    "abstract": "The non-stationary nature of real-world Multivariate Time Series (MTS) data\npresents forecasting models with a formidable challenge of the time-variant\ndistribution of time series, referred to as distribution shift. Existing\nstudies on the distribution shift mostly adhere to adaptive normalization\ntechniques for alleviating temporal mean and covariance shifts or time-variant\nmodeling for capturing temporal shifts. Despite improving model generalization,\nthese normalization-based methods often assume a time-invariant transition\nbetween outputs and inputs but disregard specific intra-/inter-series\ncorrelations, while time-variant models overlook the intrinsic causes of the\ndistribution shift. This limits model expressiveness and interpretability of\ntackling the distribution shift for MTS forecasting. To mitigate such a\ndilemma, we present a unified Probabilistic Graphical Model to Jointly\ncapturing intra-/inter-series correlations and modeling the time-variant\ntransitional distribution, and instantiate a neural framework called JointPGM\nfor non-stationary MTS forecasting. Specifically, JointPGM first employs\nmultiple Fourier basis functions to learn dynamic time factors and designs two\ndistinct learners: intra-series and inter-series learners. The intra-series\nlearner effectively captures temporal dynamics by utilizing temporal gates,\nwhile the inter-series learner explicitly models spatial dynamics through\nmulti-hop propagation, incorporating Gumbel-softmax sampling. These two types\nof series dynamics are subsequently fused into a latent variable, which is\ninversely employed to infer time factors, generate final prediction, and\nperform reconstruction. We validate the effectiveness and efficiency of\nJointPGM through extensive experiments on six highly non-stationary MTS\ndatasets, achieving state-of-the-art forecasting performance of MTS\nforecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68Txx",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.13194v1",
    "published_date": "2024-07-18 06:16:03 UTC",
    "updated_date": "2024-07-18 06:16:03 UTC"
  },
  {
    "arxiv_id": "2407.13182v1",
    "title": "SpaDiT: Diffusion Transformer for Spatial Gene Expression Prediction using scRNA-seq",
    "authors": [
      "Xiaoyu Li",
      "Fangfang Zhu",
      "Wenwen Min"
    ],
    "abstract": "The rapid development of spatial transcriptomics (ST) technologies is\nrevolutionizing our understanding of the spatial organization of biological\ntissues. Current ST methods, categorized into next-generation sequencing-based\n(seq-based) and fluorescence in situ hybridization-based (image-based) methods,\noffer innovative insights into the functional dynamics of biological tissues.\nHowever, these methods are limited by their cellular resolution and the\nquantity of genes they can detect. To address these limitations, we propose\nSpaDiT, a deep learning method that utilizes a diffusion generative model to\nintegrate scRNA-seq and ST data for the prediction of undetected genes. By\nemploying a Transformer-based diffusion model, SpaDiT not only accurately\npredicts unknown genes but also effectively generates the spatial structure of\nST genes. We have demonstrated the effectiveness of SpaDiT through extensive\nexperiments on both seq-based and image-based ST data. SpaDiT significantly\ncontributes to ST gene prediction methods with its innovative approach.\nCompared to eight leading baseline methods, SpaDiT achieved state-of-the-art\nperformance across multiple metrics, highlighting its substantial\nbioinformatics contribution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13182v1",
    "published_date": "2024-07-18 05:40:50 UTC",
    "updated_date": "2024-07-18 05:40:50 UTC"
  },
  {
    "arxiv_id": "2407.13170v1",
    "title": "Unified-EGformer: Exposure Guided Lightweight Transformer for Mixed-Exposure Image Enhancement",
    "authors": [
      "Eashan Adhikarla",
      "Kai Zhang",
      "Rosaura G. VidalMata",
      "Manjushree Aithal",
      "Nikhil Ambha Madhusudhana",
      "John Nicholson",
      "Lichao Sun",
      "Brian D. Davison"
    ],
    "abstract": "Despite recent strides made by AI in image processing, the issue of mixed\nexposure, pivotal in many real-world scenarios like surveillance and\nphotography, remains inadequately addressed. Traditional image enhancement\ntechniques and current transformer models are limited with primary focus on\neither overexposure or underexposure. To bridge this gap, we introduce the\nUnified-Exposure Guided Transformer (Unified-EGformer). Our proposed solution\nis built upon advanced transformer architectures, equipped with local\npixel-level refinement and global refinement blocks for color correction and\nimage-wide adjustments. We employ a guided attention mechanism to precisely\nidentify exposure-compromised regions, ensuring its adaptability across various\nreal-world conditions. U-EGformer, with a lightweight design featuring a memory\nfootprint (peak memory) of only $\\sim$1134 MB (0.1 Million parameters) and an\ninference time of 95 ms (9.61x faster than the average), is a viable choice for\nreal-time applications such as surveillance and autonomous navigation.\nAdditionally, our model is highly generalizable, requiring minimal fine-tuning\nto handle multiple tasks and datasets with a single architecture.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under submission",
    "pdf_url": "http://arxiv.org/pdf/2407.13170v1",
    "published_date": "2024-07-18 05:18:43 UTC",
    "updated_date": "2024-07-18 05:18:43 UTC"
  },
  {
    "arxiv_id": "2407.13168v1",
    "title": "SciCode: A Research Coding Benchmark Curated by Scientists",
    "authors": [
      "Minyang Tian",
      "Luyu Gao",
      "Shizhuo Dylan Zhang",
      "Xinan Chen",
      "Cunwei Fan",
      "Xuefei Guo",
      "Roland Haas",
      "Pan Ji",
      "Kittithat Krongchon",
      "Yao Li",
      "Shengyan Liu",
      "Di Luo",
      "Yutao Ma",
      "Hao Tong",
      "Kha Trinh",
      "Chenyu Tian",
      "Zihan Wang",
      "Bohao Wu",
      "Yanyu Xiong",
      "Shengzhu Yin",
      "Minhui Zhu",
      "Kilian Lieret",
      "Yanxin Lu",
      "Genglin Liu",
      "Yufeng Du",
      "Tianhua Tao",
      "Ofir Press",
      "Jamie Callan",
      "Eliu Huerta",
      "Hao Peng"
    ],
    "abstract": "Since language models (LMs) now outperform average humans on many challenging\ntasks, it has become increasingly difficult to develop challenging,\nhigh-quality, and realistic evaluations. We address this issue by examining\nLMs' capabilities to generate code for solving real scientific research\nproblems. Incorporating input from scientists and AI researchers in 16 diverse\nnatural science sub-fields, including mathematics, physics, chemistry, biology,\nand materials science, we created a scientist-curated coding benchmark,\nSciCode. The problems in SciCode naturally factorize into multiple subproblems,\neach involving knowledge recall, reasoning, and code synthesis. In total,\nSciCode contains 338 subproblems decomposed from 80 challenging main problems.\nIt offers optional descriptions specifying useful scientific background\ninformation and scientist-annotated gold-standard solutions and test cases for\nevaluation. Claude3.5-Sonnet, the best-performing model among those tested, can\nsolve only 4.6% of the problems in the most realistic setting. We believe that\nSciCode demonstrates both contemporary LMs' progress towards becoming helpful\nscientific assistants and sheds light on the development and evaluation of\nscientific AI in the future.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 9 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.13168v1",
    "published_date": "2024-07-18 05:15:24 UTC",
    "updated_date": "2024-07-18 05:15:24 UTC"
  },
  {
    "arxiv_id": "2407.13164v1",
    "title": "Translate-and-Revise: Boosting Large Language Models for Constrained Translation",
    "authors": [
      "Pengcheng Huang",
      "Yongyu Mu",
      "Yuzhang Wu",
      "Bei Li",
      "Chunyang Xiao",
      "Tong Xiao",
      "Jingbo Zhu"
    ],
    "abstract": "Imposing constraints on machine translation systems presents a challenging\nissue because these systems are not trained to make use of constraints in\ngenerating adequate, fluent translations. In this paper, we leverage the\ncapabilities of large language models (LLMs) for constrained translation, given\nthat LLMs can easily adapt to this task by taking translation instructions and\nconstraints as prompts. However, LLMs cannot always guarantee the adequacy of\ntranslation, and, in some cases, ignore the given constraints. This is in part\nbecause LLMs might be overly confident in their predictions, overriding the\ninfluence of the constraints. To overcome this overiding behaviour, we propose\nto add a revision process that encourages LLMs to correct the outputs by\nprompting them about the constraints that have not yet been met. We evaluate\nour approach on four constrained translation tasks, encompassing both lexical\nand structural constraints in multiple constraint domains. Experiments show\n15\\% improvement in constraint-based translation accuracy over standard LLMs\nand the approach also significantly outperforms neural machine translation\n(NMT) state-of-the-art methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.13164v1",
    "published_date": "2024-07-18 05:08:09 UTC",
    "updated_date": "2024-07-18 05:08:09 UTC"
  },
  {
    "arxiv_id": "2407.13163v2",
    "title": "ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems",
    "authors": [
      "Yi Zhang",
      "Ruihong Qiu",
      "Jiajun Liu",
      "Sen Wang"
    ],
    "abstract": "Offline reinforcement learning (RL) is an effective tool for real-world\nrecommender systems with its capacity to model the dynamic interest of users\nand its interactive nature. Most existing offline RL recommender systems focus\non model-based RL through learning a world model from offline data and building\nthe recommendation policy by interacting with this model. Although these\nmethods have made progress in the recommendation performance, the effectiveness\nof model-based offline RL methods is often constrained by the accuracy of the\nestimation of the reward model and the model uncertainties, primarily due to\nthe extreme discrepancy between offline logged data and real-world data in user\ninteractions with online platforms. To fill this gap, a more accurate reward\nmodel and uncertainty estimation are needed for the model-based RL methods. In\nthis paper, a novel model-based Reward Shaping in Offline Reinforcement\nLearning for Recommender Systems, ROLeR, is proposed for reward and uncertainty\nestimation in recommendation systems. Specifically, a non-parametric reward\nshaping method is designed to refine the reward model. In addition, a flexible\nand more representative uncertainty penalty is designed to fit the needs of\nrecommendation systems. Extensive experiments conducted on four benchmark\ndatasets showcase that ROLeR achieves state-of-the-art performance compared\nwith existing baselines. The source code can be downloaded at\nhttps://github.com/ArronDZhang/ROLeR.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "CIKM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13163v2",
    "published_date": "2024-07-18 05:07:11 UTC",
    "updated_date": "2025-05-12 05:47:47 UTC"
  },
  {
    "arxiv_id": "2407.13157v1",
    "title": "Learning Camouflaged Object Detection from Noisy Pseudo Label",
    "authors": [
      "Jin Zhang",
      "Ruiheng Zhang",
      "Yanjiao Shi",
      "Zhe Cao",
      "Nian Liu",
      "Fahad Shahbaz Khan"
    ],
    "abstract": "Existing Camouflaged Object Detection (COD) methods rely heavily on\nlarge-scale pixel-annotated training sets, which are both time-consuming and\nlabor-intensive. Although weakly supervised methods offer higher annotation\nefficiency, their performance is far behind due to the unclear visual\ndemarcations between foreground and background in camouflaged images. In this\npaper, we explore the potential of using boxes as prompts in camouflaged scenes\nand introduce the first weakly semi-supervised COD method, aiming for\nbudget-efficient and high-precision camouflaged object segmentation with an\nextremely limited number of fully labeled images. Critically, learning from\nsuch limited set inevitably generates pseudo labels with serious noisy pixels.\nTo address this, we propose a noise correction loss that facilitates the\nmodel's learning of correct pixels in the early learning stage, and corrects\nthe error risk gradients dominated by noisy pixels in the memorization stage,\nultimately achieving accurate segmentation of camouflaged objects from noisy\nlabels. When using only 20% of fully labeled data, our method shows superior\nperformance over the state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2407.13157v1",
    "published_date": "2024-07-18 04:53:51 UTC",
    "updated_date": "2024-07-18 04:53:51 UTC"
  },
  {
    "arxiv_id": "2408.02073v1",
    "title": "Case-based reasoning approach for diagnostic screening of children with developmental delays",
    "authors": [
      "Zichen Song",
      "Jiakang Li",
      "Songning Lai",
      "Sitan Huang"
    ],
    "abstract": "According to the World Health Organization, the population of children with\ndevelopmental delays constitutes approximately 6% to 9% of the total\npopulation. Based on the number of newborns in Huaibei, Anhui Province, China,\nin 2023 (94,420), it is estimated that there are about 7,500 cases (suspected\ncases of developmental delays) of suspicious cases annually. Early\nidentification and appropriate early intervention for these children can\nsignificantly reduce the wastage of medical resources and societal costs.\nInternational research indicates that the optimal period for intervention in\nchildren with developmental delays is before the age of six, with the golden\ntreatment period being before three and a half years of age. Studies have shown\nthat children with developmental delays who receive early intervention exhibit\nsignificant improvement in symptoms; some may even fully recover. This research\nadopts a hybrid model combining a CNN-Transformer model with Case-Based\nReasoning (CBR) to enhance the screening efficiency for children with\ndevelopmental delays. The CNN-Transformer model is an excellent model for image\nfeature extraction and recognition, effectively identifying features in bone\nage images to determine bone age. CBR is a technique for solving problems based\non similar cases; it solves current problems based on past experiences, similar\nto how humans solve problems through learning from experience. Given CBR's\nmemory capability to judge and compare new cases based on previously stored old\ncases, it is suitable for application in support systems with latent and\nvariable characteristics. Therefore, this study utilizes the\nCNN-Transformer-CBR to establish a screening system for children with\ndevelopmental delays, aiming to improve screening efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02073v1",
    "published_date": "2024-07-18 04:28:52 UTC",
    "updated_date": "2024-07-18 04:28:52 UTC"
  },
  {
    "arxiv_id": "2408.00794v1",
    "title": "CCSRP: Robust Pruning of Spiking Neural Networks through Cooperative Coevolution",
    "authors": [
      "Zichen Song",
      "Jiakang Li",
      "Songning Lai",
      "Sitan Huang"
    ],
    "abstract": "Spiking neural networks (SNNs) have shown promise in various dynamic visual\ntasks, yet those ready for practical deployment often lack the compactness and\nrobustness essential in resource-limited and safety-critical settings. Prior\nresearch has predominantly concentrated on enhancing the compactness or\nrobustness of artificial neural networks through strategies like network\npruning and adversarial training, with little exploration into similar\nmethodologies for SNNs. Robust pruning of SNNs aims to reduce computational\noverhead while preserving both accuracy and robustness. Current robust pruning\napproaches generally necessitate expert knowledge and iterative experimentation\nto establish suitable pruning criteria or auxiliary modules, thus constraining\ntheir broader application. Concurrently, evolutionary algorithms (EAs) have\nbeen employed to automate the pruning of artificial neural networks, delivering\nremarkable outcomes yet overlooking the aspect of robustness. In this work, we\npropose CCSRP, an innovative robust pruning method for SNNs, underpinned by\ncooperative co-evolution. Robust pruning is articulated as a tri-objective\noptimization challenge, striving to balance accuracy, robustness, and\ncompactness concurrently, resolved through a cooperative co-evolutionary\npruning framework that independently prunes filters across layers using EAs.\nOur experiments on CIFAR-10 and SVHN demonstrate that CCSRP can match or exceed\nthe performance of the latest methodologies.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00794v1",
    "published_date": "2024-07-18 04:28:16 UTC",
    "updated_date": "2024-07-18 04:28:16 UTC"
  },
  {
    "arxiv_id": "2407.13146v2",
    "title": "PG-Rainbow: Using Distributional Reinforcement Learning in Policy Gradient Methods",
    "authors": [
      "WooJae Jeon",
      "KangJun Lee",
      "Jeewoo Lee"
    ],
    "abstract": "This paper introduces PG-Rainbow, a novel algorithm that incorporates a\ndistributional reinforcement learning framework with a policy gradient\nalgorithm. Existing policy gradient methods are sample inefficient and rely on\nthe mean of returns when calculating the state-action value function,\nneglecting the distributional nature of returns in reinforcement learning\ntasks. To address this issue, we use an Implicit Quantile Network that provides\nthe quantile information of the distribution of rewards to the critic network\nof the Proximal Policy Optimization algorithm. We show empirical results that\nthrough the integration of reward distribution information into the policy\nnetwork, the policy agent acquires enhanced capabilities to comprehensively\nevaluate the consequences of potential actions in a given state, facilitating\nmore sophisticated and informed decision-making processes. We evaluate the\nperformance of the proposed algorithm in the Atari-2600 game suite, simulated\nvia the Arcade Learning Environment (ALE).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13146v2",
    "published_date": "2024-07-18 04:18:52 UTC",
    "updated_date": "2024-07-19 02:00:01 UTC"
  },
  {
    "arxiv_id": "2407.13122v1",
    "title": "MO-EMT-NAS: Multi-Objective Continuous Transfer of Architectural Knowledge Between Tasks from Different Datasets",
    "authors": [
      "Peng Liao",
      "XiLu Wang",
      "Yaochu Jin",
      "WenLi Du"
    ],
    "abstract": "Deploying models across diverse devices demands tradeoffs among multiple\nobjectives due to different resource constraints. Arguably, due to the small\nmodel trap problem in multi-objective neural architecture search (MO-NAS) based\non a supernet, existing approaches may fail to maintain large models. Moreover,\nmulti-tasking neural architecture search (MT-NAS) excels in handling multiple\ntasks simultaneously, but most existing efforts focus on tasks from the same\ndataset, limiting their practicality in real-world scenarios where multiple\ntasks may come from distinct datasets. To tackle the above challenges, we\npropose a Multi-Objective Evolutionary Multi-Tasking framework for NAS\n(MO-EMT-NAS) to achieve architectural knowledge transfer across tasks from\ndifferent datasets while finding Pareto optimal architectures for\nmulti-objectives, model accuracy and computational efficiency. To alleviate the\nsmall model trap issue, we introduce an auxiliary objective that helps maintain\nmultiple larger models of similar accuracy. Moreover, the computational\nefficiency is further enhanced by parallelizing the training and validation of\nthe weight-sharing-based supernet. Experimental results on seven datasets with\ntwo, three, and four task combinations show that MO-EMT-NAS achieves a better\nminimum classification error while being able to offer flexible trade-offs\nbetween model performance and complexity, compared to the state-of-the-art\nsingle-objective MT-NAS algorithms. The runtime of MO-EMT-NAS is reduced by\n59.7% to 77.7%, compared to the corresponding multi-objective single-task\napproaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13122v1",
    "published_date": "2024-07-18 03:12:35 UTC",
    "updated_date": "2024-07-18 03:12:35 UTC"
  },
  {
    "arxiv_id": "2407.13113v1",
    "title": "Multiobjective Vehicle Routing Optimization with Time Windows: A Hybrid Approach Using Deep Reinforcement Learning and NSGA-II",
    "authors": [
      "Rixin Wu",
      "Ran Wang",
      "Jie Hao",
      "Qiang Wu",
      "Ping Wang",
      "Dusit Niyato"
    ],
    "abstract": "This paper proposes a weight-aware deep reinforcement learning (WADRL)\napproach designed to address the multiobjective vehicle routing problem with\ntime windows (MOVRPTW), aiming to use a single deep reinforcement learning\n(DRL) model to solve the entire multiobjective optimization problem. The\nNon-dominated sorting genetic algorithm-II (NSGA-II) method is then employed to\noptimize the outcomes produced by the WADRL, thereby mitigating the limitations\nof both approaches. Firstly, we design an MOVRPTW model to balance the\nminimization of travel cost and the maximization of customer satisfaction.\nSubsequently, we present a novel DRL framework that incorporates a\ntransformer-based policy network. This network is composed of an encoder\nmodule, a weight embedding module where the weights of the objective functions\nare incorporated, and a decoder module. NSGA-II is then utilized to optimize\nthe solutions generated by WADRL. Finally, extensive experimental results\ndemonstrate that our method outperforms the existing and traditional methods.\nDue to the numerous constraints in VRPTW, generating initial solutions of the\nNSGA-II algorithm can be time-consuming. However, using solutions generated by\nthe WADRL as initial solutions for NSGA-II significantly reduces the time\nrequired for generating initial solutions. Meanwhile, the NSGA-II algorithm can\nenhance the quality of solutions generated by WADRL, resulting in solutions\nwith better scalability. Notably, the weight-aware strategy significantly\nreduces the training time of DRL while achieving better results, enabling a\nsingle DRL model to solve the entire multiobjective optimization problem.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages; Under Review; Submitted to IEEE Transactions on Intelligent\n  Transportation Systems",
    "pdf_url": "http://arxiv.org/pdf/2407.13113v1",
    "published_date": "2024-07-18 02:46:06 UTC",
    "updated_date": "2024-07-18 02:46:06 UTC"
  },
  {
    "arxiv_id": "2407.13101v2",
    "title": "Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with an Iterative Approach",
    "authors": [
      "Zhouyu Jiang",
      "Mengshu Sun",
      "Lei Liang",
      "Zhiqiang Zhang"
    ],
    "abstract": "Multi-hop question answering is a challenging task with distinct industrial\nrelevance, and Retrieval-Augmented Generation (RAG) methods based on large\nlanguage models (LLMs) have become a popular approach to tackle this task.\nOwing to the potential inability to retrieve all necessary information in a\nsingle iteration, a series of iterative RAG methods has been recently\ndeveloped, showing significant performance improvements. However, existing\nmethods still face two critical challenges: context overload resulting from\nmultiple rounds of retrieval, and over-planning and repetitive planning due to\nthe lack of a recorded retrieval trajectory. In this paper, we propose a novel\niterative RAG method called ReSP, equipped with a dual-function summarizer.\nThis summarizer compresses information from retrieved documents, targeting both\nthe overarching question and the current sub-question concurrently.\nExperimental results on the multi-hop question-answering datasets HotpotQA and\n2WikiMultihopQA demonstrate that our method significantly outperforms the\nstate-of-the-art, and exhibits excellent robustness concerning context length.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by WWW2025 Agent4IR Workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.13101v2",
    "published_date": "2024-07-18 02:19:00 UTC",
    "updated_date": "2025-01-30 04:51:41 UTC"
  },
  {
    "arxiv_id": "2408.01428v1",
    "title": "Transferable Adversarial Facial Images for Privacy Protection",
    "authors": [
      "Minghui Li",
      "Jiangxiong Wang",
      "Hao Zhang",
      "Ziqi Zhou",
      "Shengshan Hu",
      "Xiaobing Pei"
    ],
    "abstract": "The success of deep face recognition (FR) systems has raised serious privacy\nconcerns due to their ability to enable unauthorized tracking of users in the\ndigital world. Previous studies proposed introducing imperceptible adversarial\nnoises into face images to deceive those face recognition models, thus\nachieving the goal of enhancing facial privacy protection. Nevertheless, they\nheavily rely on user-chosen references to guide the generation of adversarial\nnoises, and cannot simultaneously construct natural and highly transferable\nadversarial face images in black-box scenarios. In light of this, we present a\nnovel face privacy protection scheme with improved transferability while\nmaintain high visual quality. We propose shaping the entire face space directly\ninstead of exploiting one kind of facial characteristic like makeup information\nto integrate adversarial noises. To achieve this goal, we first exploit global\nadversarial latent search to traverse the latent space of the generative model,\nthereby creating natural adversarial face images with high transferability. We\nthen introduce a key landmark regularization module to preserve the visual\nidentity information. Finally, we investigate the impacts of various kinds of\nlatent spaces and find that $\\mathcal{F}$ latent space benefits the trade-off\nbetween visual naturalness and adversarial transferability. Extensive\nexperiments over two datasets demonstrate that our approach significantly\nenhances attack transferability while maintaining high visual quality,\noutperforming state-of-the-art methods by an average 25% improvement in deep FR\nmodels and 10% improvement on commercial FR APIs, including Face++, Aliyun, and\nTencent.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.01428v1",
    "published_date": "2024-07-18 02:16:11 UTC",
    "updated_date": "2024-07-18 02:16:11 UTC"
  },
  {
    "arxiv_id": "2407.13091v1",
    "title": "On Causally Disentangled State Representation Learning for Reinforcement Learning based Recommender Systems",
    "authors": [
      "Siyu Wang",
      "Xiaocong Chen",
      "Lina Yao"
    ],
    "abstract": "In Reinforcement Learning-based Recommender Systems (RLRS), the complexity\nand dynamism of user interactions often result in high-dimensional and noisy\nstate spaces, making it challenging to discern which aspects of the state are\ntruly influential in driving the decision-making process. This issue is\nexacerbated by the evolving nature of user preferences and behaviors, requiring\nthe recommender system to adaptively focus on the most relevant information for\ndecision-making while preserving generaliability. To tackle this problem, we\nintroduce an innovative causal approach for decomposing the state and\nextracting \\textbf{C}ausal-\\textbf{I}n\\textbf{D}ispensable \\textbf{S}tate\nRepresentations (CIDS) in RLRS. Our method concentrates on identifying the\n\\textbf{D}irectly \\textbf{A}ction-\\textbf{I}nfluenced \\textbf{S}tate Variables\n(DAIS) and \\textbf{A}ction-\\textbf{I}nfluence \\textbf{A}ncestors (AIA), which\nare essential for making effective recommendations. By leveraging conditional\nmutual information, we develop a framework that not only discerns the causal\nrelationships within the generative process but also isolates critical state\nvariables from the typically dense and high-dimensional state representations.\nWe provide theoretical evidence for the identifiability of these variables.\nThen, by making use of the identified causal relationship, we construct\ncausal-indispensable state representations, enabling the training of policies\nover a more advantageous subset of the agent's state space. We demonstrate the\nefficacy of our approach through extensive experiments, showcasing our method\noutperforms state-of-the-art methods.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13091v1",
    "published_date": "2024-07-18 01:41:05 UTC",
    "updated_date": "2024-07-18 01:41:05 UTC"
  },
  {
    "arxiv_id": "2407.13089v2",
    "title": "MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking",
    "authors": [
      "Ting-Chih Chen",
      "Chia-Wei Tang",
      "Chris Thomas"
    ],
    "abstract": "Fact-checking real-world claims often requires reviewing multiple multimodal\ndocuments to assess a claim's truthfulness, which is a highly laborious and\ntime-consuming task. In this paper, we present a summarization model designed\nto generate claim-specific summaries useful for fact-checking from multimodal,\nmulti-document datasets. The model takes inputs in the form of documents,\nimages, and a claim, with the objective of assisting in fact-checking tasks. We\nintroduce a dynamic perceiver-based model that can handle inputs from multiple\nmodalities of arbitrary lengths. To train our model, we leverage a novel\nreinforcement learning-based entailment objective to generate summaries that\nprovide evidence distinguishing between different truthfulness labels. To\nassess the efficacy of our approach, we conduct experiments on both an existing\nbenchmark and a new dataset of multi-document claims that we contribute. Our\napproach outperforms the SOTA approach by 4.6% in the claim verification task\non the MOCHEG dataset and demonstrates strong performance on our new\nMulti-News-Fact-Checking dataset.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 7 figures, The 62nd Annual Meeting of the Association for\n  Computational Linguistics",
    "pdf_url": "http://arxiv.org/pdf/2407.13089v2",
    "published_date": "2024-07-18 01:33:20 UTC",
    "updated_date": "2024-09-20 03:44:00 UTC"
  },
  {
    "arxiv_id": "2407.18961v3",
    "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains",
    "authors": [
      "Guoli Yin",
      "Haoping Bai",
      "Shuang Ma",
      "Feng Nan",
      "Yanchao Sun",
      "Zhaoyang Xu",
      "Shen Ma",
      "Jiarui Lu",
      "Xiang Kong",
      "Aonan Zhang",
      "Dian Ang Yap",
      "Yizhe zhang",
      "Karsten Ahnert",
      "Vik Kamath",
      "Mathias Berglund",
      "Dominic Walsh",
      "Tobias Gindele",
      "Juergen Wiest",
      "Zhengfeng Lai",
      "Xiaoming Wang",
      "Jiulong Shan",
      "Meng Cao",
      "Ruoming Pang",
      "Zirui Wang"
    ],
    "abstract": "Recent advances in large language models (LLMs) have increased the demand for\ncomprehensive benchmarks to evaluate their capabilities as human-like agents.\nExisting benchmarks, while useful, often focus on specific application\nscenarios, emphasizing task completion but failing to dissect the underlying\nskills that drive these outcomes. This lack of granularity makes it difficult\nto deeply discern where failures stem from. Additionally, setting up these\nenvironments requires considerable effort, and issues of unreliability and\nreproducibility sometimes arise, especially in interactive tasks. To address\nthese limitations, we introduce the Massive Multitask Agent Understanding\n(MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need\nfor complex environment setups. It evaluates models across five domains,\nincluding Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine\nLearning coding, Contest-level programming and Mathematics, and covers five\nessential capabilities: Understanding, Reasoning, Planning, Problem-solving,\nand Self-correction. With a total of 20 meticulously designed tasks\nencompassing over 3K distinct prompts, MMAU provides a comprehensive framework\nfor evaluating the strengths and limitations of LLM agents. By testing 18\nrepresentative models on MMAU, we provide deep and insightful analyses.\nUltimately, MMAU not only sheds light on the capabilities and limitations of\nLLM agents but also enhances the interpretability of their performance.\nDatasets and evaluation scripts of MMAU are released at\nhttps://github.com/apple/axlearn/tree/main/docs/research/mmau.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18961v3",
    "published_date": "2024-07-18 00:58:41 UTC",
    "updated_date": "2024-08-15 21:32:57 UTC"
  },
  {
    "arxiv_id": "2407.13078v1",
    "title": "Enhancing Temporal Action Localization: Advanced S6 Modeling with Recurrent Mechanism",
    "authors": [
      "Sangyoun Lee",
      "Juho Jung",
      "Changdae Oh",
      "Sunghee Yun"
    ],
    "abstract": "Temporal Action Localization (TAL) is a critical task in video analysis,\nidentifying precise start and end times of actions. Existing methods like CNNs,\nRNNs, GCNs, and Transformers have limitations in capturing long-range\ndependencies and temporal causality. To address these challenges, we propose a\nnovel TAL architecture leveraging the Selective State Space Model (S6). Our\napproach integrates the Feature Aggregated Bi-S6 block, Dual Bi-S6 structure,\nand a recurrent mechanism to enhance temporal and channel-wise dependency\nmodeling without increasing parameter complexity. Extensive experiments on\nbenchmark datasets demonstrate state-of-the-art results with mAP scores of\n74.2% on THUMOS-14, 42.9% on ActivityNet, 29.6% on FineAction, and 45.8% on\nHACS. Ablation studies validate our method's effectiveness, showing that the\nDual structure in the Stem module and the recurrent mechanism outperform\ntraditional approaches. Our findings demonstrate the potential of S6-based\nmodels in TAL tasks, paving the way for future research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 3 figures, Preprint",
    "pdf_url": "http://arxiv.org/pdf/2407.13078v1",
    "published_date": "2024-07-18 00:57:37 UTC",
    "updated_date": "2024-07-18 00:57:37 UTC"
  }
]