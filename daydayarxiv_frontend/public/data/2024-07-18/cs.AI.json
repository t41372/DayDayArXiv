{
  "date": "2024-07-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-18 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 安全、LLM 评估、医疗图像处理、强化学习和多模态生成等领域，亮点包括 AI 系统可靠性研究（如著名学者 Robin Bloomfield 和 John Rushby 的工作）、LLM 在复杂任务中的应用，以及高效的医疗 AI 框架，这些论文展示了 AI 在实际应用中的潜力。\n\n### 重点论文讨论\n我将优先讨论主题相关性强、潜在影响大的论文，并将它们归类讨论。以下挑选了部分令人印象深刻的论文，先聊 AI 安全和 LLM 相关主题，再涉及医疗和强化学习。\n\n**1. Assurance of AI Systems From a Dependability Perspective（AI 系统可靠性从可依赖性视角）**  \n这篇由 Robin Bloomfield 和 John Rushby 等著名学者撰写的论文，探讨了 AI 和机器学习系统的可依赖性设计。主要贡献是通过“defense in depth”策略（如分层守卫机制）减少对 AI 组件的依赖，发现了传统和可信赖视角的结合能更好地处理复杂系统，如自动驾驶。论文强调了在 AI 系统中最小化信任并增强行为理解的必要性，对于 AI 安全领域有重要启发。\n\n**2. Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction（Werewolf Arena: 通过社会推演评估大型语言模型的案例研究）**  \n这篇论文引入了一个新框架 Werewolf Arena，用于评估 LLM（如 Gemini 和 GPT 模型）在欺骗、推理和说服方面的能力。主要发现是通过竞技式比赛揭示模型的策略优势和弱点，如在动态讨论中的表现。该框架作为 LLM 基准，具有高可扩展性和实际应用潜力，突出了 LLM 在复杂交互任务中的挑战。\n\n**4. Unmasking Social Bots: How Confident Are We?（揭露社交机器人：我们有多确定？）**  \n论文针对社交媒体中的机器人检测问题，提出了一种结合不确定性量化的方法。主要贡献是同时处理检测和置信度评估，发现模型间不一致性可以通过额外数据缓解。该方法提升了社交机器人分类的可靠性，对反 disinformation 领域有实际价值。\n\n**5. Report on the Conference on Ethical and Responsible Design in the National AI Institutes: A Summary of Challenges（国家 AI 研究所伦理和负责任设计会议报告：挑战总结）**  \n这篇报告总结了 AI 伦理挑战，如在开发过程中的伦理实践。主要发现是 AI 研究所面临识别和实施伦理设计的难题，并提出了潜在合作点。该论文强调了 AI 负责任设计的紧迫性，具有政策和学术影响。\n\n**11. Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset（皮肤病变数据集上神经网络的公平性：数据-算法-架构协同优化）**  \n论文提出 BiaslessNAS 框架，用于优化医疗 AI 的公平性。主要贡献是通过 Neural Architecture Search 实现准确性提升 2.55% 和公平性改善 65.50%，发现架构设计对医疗 AI 偏差至关重要。该工作在医疗公平领域有显著启发。\n\n**13. APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy（APS-USCT: 通过 AI-物理协同的超声计算断层成像处理稀疏数据）**  \n这篇论文开发了 APS-USCT 方法，用于处理稀疏超声数据。主要发现是通过 AI 模型生成密集波形，实现 SSIM 达 0.8431 的高分辨率重建。该方法降低了医疗成像成本，对癌症检测等应用有实际价值。\n\n**15. Thought-Like-Pro: Enhancing Reasoning of Large Language Models through Self-Driven Prolog-based Chain-of-Thought（Thought-Like-Pro: 通过自驱动 Prolog 链式思考增强大型语言模型的推理）**  \n论文引入自驱动框架，使用 Prolog 逻辑增强 LLM 推理。主要贡献是模仿学习提升了模型在复杂任务中的泛化能力，发现无需人工标注即可实现高效推理。该方法在 AI 推理优化中具有创新性。\n\n**18. Phi-3 Safety Post-Training: Aligning Language Models with a \"Break-Fix\" Cycle（Phi-3 安全后训练：通过“破坏-修复”循环对齐语言模型）**  \n这篇论文描述了 Phi-3 系列模型的安全对齐过程。主要发现是通过迭代数据集优化和基准测试，提高了模型在责任 AI 基准上的性能。该工作展示了 LLM 安全训练的实用框架。\n\n### 其他相关论文简述\n剩余论文覆盖了机器人学、图像生成和强化学习等领域，但由于篇幅有限，我快速掠过非核心部分：\n- **论文 3 (RT-Pose: A 4D Radar Tensor-based 3D Human Pose Estimation and Localization Benchmark)**：提出 RT-Pose 数据集和 HRRadarPose 模型，用于雷达-based 人体姿势估计，发现 MPJPE 仅 9.91cm，提升了隐私保护的实时应用。\n- **论文 7 (DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention)**：开发了 DuoFormer 模型，结合 CNN 和 Transformer 提升医疗图像处理，发现小数据集上表现优于基线。\n- **论文 23 (Neural Network Tire Force Modeling for Automated Drifting)**：使用神经网络建模轮胎力，提升自动漂移控制，发现比传统模型更准确。\n- **论文 39 (Weak-to-Strong Reasoning)**：提出弱到强推理框架，提升 LLM 在数学任务中的性能，发现样本效率显著提高。\n- **论文 42 (Revisiting Attention for Multivariate Time Series Forecasting)**：引入 FSatten 和 SOatten 注意力机制，优化时间序列预测，发现长序列输入下精度提升 38%。\n\n其他论文（如纯编程工具或特定领域优化）虽有贡献，但主题较零散或不具广泛影响力，故从简不详述。如果您对特定领域感兴趣，可以进一步查询。\n\n今天的快报展示了 AI 在安全和应用领域的进展，期待这些研究推动更可靠的 AI 系统！",
  "papers": [
    {
      "arxiv_id": "2407.13948v2",
      "title": "Assurance of AI Systems From a Dependability Perspective",
      "title_zh": "从",
      "authors": [
        "Robin Bloomfield",
        "John Rushby"
      ],
      "abstract": "We outline the principles of classical assurance for computer-based systems\nthat pose significant risks. We then consider application of these principles\nto systems that employ Artificial Intelligence (AI) and Machine Learning (ML).\n  A key element in this \"dependability\" perspective is a requirement to have\nnear-complete understanding of the behavior of critical components, and this is\nconsidered infeasible for AI and ML. Hence the dependability perspective aims\nto minimize trust in AI and ML elements by using \"defense in depth\" with a\nhierarchy of less complex systems, some of which may be highly assured\nconventionally engineered components, to \"guard\" them. This may be contrasted\nwith the \"trustworthy\" perspective that seeks to apply assurance to the AI and\nML elements themselves.\n  In cyber-physical and many other systems, it is difficult to provide guards\nthat do not depend on AI and ML to perceive their environment (e.g., other\nvehicles sharing the road with a self-driving car), so both perspectives are\nneeded and there is a continuum or spectrum between them. We focus on\narchitectures toward the dependability end of the continuum and invite others\nto consider additional points along the spectrum.\n  For guards that require perception using AI and ML, we examine ways to\nminimize the trust placed in these elements; they include diversity, defense in\ndepth, explanations, and micro-ODDs. We also examine methods to enforce\nacceptable behavior, given a model of the world. These include classical\ncyber-physical calculations and envelopes, and normative rules based on\noverarching principles, constitutions, ethics, or reputation. We apply our\nperspective to autonomous systems, AI systems for specific functions, generic\nAI such as Large Language Models, and to Artificial General Intelligence (AGI),\nand we propose current best practice and an agenda for research.",
      "tldr_zh": "这篇论文从 Dependability 视角探讨 AI 系统保障的原则，强调通过“Defense in Depth”策略使用层级化系统来减少对 AI 和 ML 元素的信任，从而应对关键组件行为理解的挑战。论文对比了这种方法与直接保障 AI 元素的“Trustworthy”视角，指出在网络物理系统中需结合两者，并提出最小化信任的技术，如多样性、解释和微型 ODDs，以及强制行为规范的机制。最终，论文应用于自主系统、特定功能 AI、大语言模型和 AGI，并建议当前最佳实践和研究议程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13948v2",
      "published_date": "2024-07-18 23:55:43 UTC",
      "updated_date": "2024-08-07 22:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:45:03.830888"
    },
    {
      "arxiv_id": "2407.13943v1",
      "title": "Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction",
      "title_zh": "Werewolf Arena：通过社会演绎进行LLM评估",
      "authors": [
        "Suma Bailis",
        "Jane Friedhoff",
        "Feiyang Chen"
      ],
      "abstract": "This paper introduces Werewolf Arena, a novel framework for evaluating large\nlanguage models (LLMs) through the lens of the classic social deduction game,\nWerewolf. In Werewolf Arena, LLMs compete against each other, navigating the\ngame's complex dynamics of deception, deduction, and persuasion. The framework\nintroduces a dynamic turn-taking system based on bidding, mirroring real-world\ndiscussions where individuals strategically choose when to speak. We\ndemonstrate the framework's utility through an arena-style tournament featuring\nGemini and GPT models. Our results reveal distinct strengths and weaknesses in\nthe models' strategic reasoning and communication. These findings highlight\nWerewolf Arena's potential as a challenging and scalable LLM benchmark.",
      "tldr_zh": "这篇论文介绍了 Werewolf Arena 框架，通过经典的社会推演游戏 Werewolf 来评估大型语言模型 (LLMs)。框架让 LLMs 相互竞争，处理游戏中的欺骗、推演和说服动态，并采用基于竞标的动态回合制系统，以模拟现实讨论中的战略发言。实验通过 Gemini 和 GPT 模型的锦标赛揭示了这些模型在战略推理和沟通方面的优势与劣势，突显了 Werewolf Arena 作为一种挑战性和可扩展的 LLM 基准测试的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.13943v1",
      "published_date": "2024-07-18 23:41:05 UTC",
      "updated_date": "2024-07-18 23:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:45:16.366854"
    },
    {
      "arxiv_id": "2407.13930v1",
      "title": "RT-Pose: A 4D Radar Tensor-based 3D Human Pose Estimation and Localization Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan-Hao Ho",
        "Jen-Hao Cheng",
        "Sheng Yao Kuan",
        "Zhongyu Jiang",
        "Wenhao Chai",
        "Hsiang-Wei Huang",
        "Chih-Lung Lin",
        "Jenq-Neng Hwang"
      ],
      "abstract": "Traditional methods for human localization and pose estimation (HPE), which\nmainly rely on RGB images as an input modality, confront substantial\nlimitations in real-world applications due to privacy concerns. In contrast,\nradar-based HPE methods emerge as a promising alternative, characterized by\ndistinctive attributes such as through-wall recognition and privacy-preserving,\nrendering the method more conducive to practical deployments. This paper\npresents a Radar Tensor-based human pose (RT-Pose) dataset and an open-source\nbenchmarking framework. The RT-Pose dataset comprises 4D radar tensors, LiDAR\npoint clouds, and RGB images, and is collected for a total of 72k frames across\n240 sequences with six different complexity-level actions. The 4D radar tensor\nprovides raw spatio-temporal information, differentiating it from other radar\npoint cloud-based datasets. We develop an annotation process using RGB images\nand LiDAR point clouds to accurately label 3D human skeletons. In addition, we\npropose HRRadarPose, the first single-stage architecture that extracts the\nhigh-resolution representation of 4D radar tensors in 3D space to aid human\nkeypoint estimation. HRRadarPose outperforms previous radar-based HPE work on\nthe RT-Pose benchmark. The overall HRRadarPose performance on the RT-Pose\ndataset, as reflected in a mean per joint position error (MPJPE) of 9.91cm,\nindicates the persistent challenges in achieving accurate HPE in complex\nreal-world scenarios. RT-Pose is available at\nhttps://huggingface.co/datasets/uwipl/RT-Pose.",
      "tldr_zh": "本论文介绍了 RT-Pose 数据集和基准框架，用于基于 4D Radar Tensor 的 3D 人体姿态估计 (HPE) 和定位，以克服传统 RGB 图像方法的隐私问题。数据集包含 72k 帧的 4D Radar Tensor、LiDAR 点云和 RGB 图像，涵盖六种不同复杂度的动作，并通过 RGB 和 LiDAR 进行精确的 3D 人体骨骼标注。论文提出 HRRadarPose 架构，这是首个单阶段模型，从 4D Radar Tensor 中提取高分辨率 3D 表示来提升关键点估计性能，在 RT-Pose 基准上实现 MPJPE 为 9.91cm 的结果，比现有雷达-based HPE 方法表现更好，但复杂真实场景下仍存在准确性挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13930v1",
      "published_date": "2024-07-18 22:46:35 UTC",
      "updated_date": "2024-07-18 22:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:45:28.969983"
    },
    {
      "arxiv_id": "2407.13929v2",
      "title": "Unmasking Social Bots: How Confident Are We?",
      "title_zh": "翻译失败",
      "authors": [
        "James Giroux",
        "Ariyarathne Gangani",
        "Alexander C. Nwala",
        "Cristiano Fanelli"
      ],
      "abstract": "Social bots remain a major vector for spreading disinformation on social\nmedia and a menace to the public. Despite the progress made in developing\nmultiple sophisticated social bot detection algorithms and tools, bot detection\nremains a challenging, unsolved problem that is fraught with uncertainty due to\nthe heterogeneity of bot behaviors, training data, and detection algorithms.\nDetection models often disagree on whether to label the same account as bot or\nhuman-controlled. However, they do not provide any measure of uncertainty to\nindicate how much we should trust their results. We propose to address both bot\ndetection and the quantification of uncertainty at the account level - a novel\nfeature of this research. This dual focus is crucial as it allows us to\nleverage additional information related to the quantified uncertainty of each\nprediction, thereby enhancing decision-making and improving the reliability of\nbot classifications. Specifically, our approach facilitates targeted\ninterventions for bots when predictions are made with high confidence and\nsuggests caution (e.g., gathering more data) when predictions are uncertain.",
      "tldr_zh": "这篇论文探讨了 social bots 在社交媒体上传播虚假信息的挑战，强调现有 bot detection 算法因机器人行为多样性和模型差异而存在不确定性，导致分类结果不一致。研究提出了一种创新方法，不仅进行账户级别的 social bots 检测，还量化每个预测的不确定性，以提升决策可靠性。具体而言，该方法允许对高置信度预测实施针对干预，而对不确定预测建议谨慎措施，如收集更多数据，从而改善 bot 分类的准确性和可信度。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "15 pages, 6 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.13929v2",
      "published_date": "2024-07-18 22:33:52 UTC",
      "updated_date": "2025-03-02 18:17:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:45:37.710826"
    },
    {
      "arxiv_id": "2407.13926v2",
      "title": "Report on the Conference on Ethical and Responsible Design in the National AI Institutes: A Summary of Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Sherri Lynn Conklin",
        "Sue Bae",
        "Gaurav Sett",
        "Michael Hoffmann",
        "Justin B. Biddle"
      ],
      "abstract": "In May 2023, the Georgia Tech Ethics, Technology, and Human Interaction\nCenter organized the Conference on Ethical and Responsible Design in the\nNational AI Institutes. Representatives from the National AI Research\nInstitutes that had been established as of January 2023 were invited to attend;\nresearchers representing 14 Institutes attended and participated. The\nconference focused on three questions: What are the main challenges that the\nNational AI Institutes are facing with regard to the responsible design of AI\nsystems? What are promising lines of inquiry to address these challenges? What\nare possible points of collaboration? Over the course of the conference, a\nrevised version of the first question became a focal point: What are the\nchallenges that the Institutes face in identifying ethical and responsible\ndesign practices and in implementing them in the AI development process? This\ndocument summarizes the challenges that representatives from the Institutes in\nattendance highlighted.",
      "tldr_zh": "2023 年 5 月，佐治亚理工学院的 Ethics, Technology, and Human Interaction Center 组织了“Ethical and Responsible Design in the National AI Institutes”会议，邀请了 14 个国家 AI 研究所的代表参与讨论。会议聚焦于 AI 系统在负责任设计方面的主要挑战、潜在研究方向以及合作机会，并将焦点调整为研究所们在识别和实施 Ethical and Responsible Design 实践时的困难。报告总结了与会代表强调的这些挑战，包括在 AI 开发过程中应用道德标准的障碍。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.13926v2",
      "published_date": "2024-07-18 22:30:08 UTC",
      "updated_date": "2024-11-12 19:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:45:53.325967"
    },
    {
      "arxiv_id": "2407.13922v2",
      "title": "Synthetic Counterfactual Faces",
      "title_zh": "合成反事实人脸",
      "authors": [
        "Guruprasad V Ramesh",
        "Harrison Rosenberg",
        "Ashish Hooda",
        "Shimaa Ahmed Kassem Fawaz"
      ],
      "abstract": "Computer vision systems have been deployed in various applications involving\nbiometrics like human faces. These systems can identify social media users,\nsearch for missing persons, and verify identity of individuals. While computer\nvision models are often evaluated for accuracy on available benchmarks, more\nannotated data is necessary to learn about their robustness and fairness\nagainst semantic distributional shifts in input data, especially in face data.\nAmong annotated data, counterfactual examples grant strong explainability\ncharacteristics. Because collecting natural face data is prohibitively\nexpensive, we put forth a generative AI-based framework to construct targeted,\ncounterfactual, high-quality synthetic face data. Our synthetic data pipeline\nhas many use cases, including face recognition systems sensitivity evaluations\nand image understanding system probes. The pipeline is validated with multiple\nuser studies. We showcase the efficacy of our face generation pipeline on a\nleading commercial vision model. We identify facial attributes that cause\nvision systems to fail.",
      "tldr_zh": "这篇论文针对计算机视觉系统在人脸生物识别中的鲁棒性和公平性问题，提出了一种基于生成AI的框架，用于生成高质量的合成反事实(counterfactual)人脸数据，以模拟语义分布偏移场景。框架的管道支持面部识别系统的敏感性评估和图像理解系统的测试，并通过多个用户研究进行验证。在领先的商业视觉模型上，该方法证明了其有效性，并识别出某些面部属性会导致系统失败，从而提升了模型的可解释性和改进潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper under review. Full text and results will be updated after\n  acceptance",
      "pdf_url": "http://arxiv.org/pdf/2407.13922v2",
      "published_date": "2024-07-18 22:22:49 UTC",
      "updated_date": "2024-07-29 18:29:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:46:03.207948"
    },
    {
      "arxiv_id": "2407.13920v1",
      "title": "DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention",
      "title_zh": "DuoFormer：通过局部和全局注意力利用分层视觉表示",
      "authors": [
        "Xiaoya Tang",
        "Bodong Zhang",
        "Beatrice S. Knudsen",
        "Tolga Tasdizen"
      ],
      "abstract": "We here propose a novel hierarchical transformer model that adeptly\nintegrates the feature extraction capabilities of Convolutional Neural Networks\n(CNNs) with the advanced representational potential of Vision Transformers\n(ViTs). Addressing the lack of inductive biases and dependence on extensive\ntraining datasets in ViTs, our model employs a CNN backbone to generate\nhierarchical visual representations. These representations are then adapted for\ntransformer input through an innovative patch tokenization. We also introduce a\n'scale attention' mechanism that captures cross-scale dependencies,\ncomplementing patch attention to enhance spatial understanding and preserve\nglobal perception. Our approach significantly outperforms baseline models on\nsmall and medium-sized medical datasets, demonstrating its efficiency and\ngeneralizability. The components are designed as plug-and-play for different\nCNN architectures and can be adapted for multiple applications. The code is\navailable at https://github.com/xiaoyatang/DuoFormer.git.",
      "tldr_zh": "本研究提出了一种新型层次化 transformer 模型 DuoFormer，通过整合 Convolutional Neural Networks (CNNs) 的特征提取能力和 Vision Transformers (ViTs) 的高级表示潜力，解决了 ViTs 在缺乏归纳偏差和依赖大量训练数据方面的局限性。模型使用 CNN 骨干生成层次化视觉表示，并通过创新的 patch tokenization 适应 transformer 输入，同时引入 'scale attention' 机制来捕捉跨尺度依赖，补充 patch attention 以提升空间理解和全局感知。该方法在小型和中型医疗数据集上显著优于基线模型，展示了高效性和通用性，且组件设计为即插即用，适用于不同 CNN 架构和多种应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.13920v1",
      "published_date": "2024-07-18 22:15:35 UTC",
      "updated_date": "2024-07-18 22:15:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:46:14.402558"
    },
    {
      "arxiv_id": "2407.13917v1",
      "title": "LinSATNet: The Positive Linear Satisfiability Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Runzhong Wang",
        "Yunhao Zhang",
        "Ziao Guo",
        "Tianyi Chen",
        "Xiaokang Yang",
        "Junchi Yan"
      ],
      "abstract": "Encoding constraints into neural networks is attractive. This paper studies\nhow to introduce the popular positive linear satisfiability to neural networks.\nWe propose the first differentiable satisfiability layer based on an extension\nof the classic Sinkhorn algorithm for jointly encoding multiple sets of\nmarginal distributions. We further theoretically characterize the convergence\nproperty of the Sinkhorn algorithm for multiple marginals. In contrast to the\nsequential decision e.g.\\ reinforcement learning-based solvers, we showcase our\ntechnique in solving constrained (specifically satisfiability) problems by\none-shot neural networks, including i) a neural routing solver learned without\nsupervision of optimal solutions; ii) a partial graph matching network handling\ngraphs with unmatchable outliers on both sides; iii) a predictive network for\nfinancial portfolios with continuous constraints. To our knowledge, there\nexists no one-shot neural solver for these scenarios when they are formulated\nas satisfiability problems. Source code is available at\nhttps://github.com/Thinklab-SJTU/LinSATNet",
      "tldr_zh": "这篇论文提出了 LinSATNet，一种将 Positive Linear Satisfiability 整合到神经网络中的框架，用于高效编码约束问题。作者设计了第一个基于扩展 Sinkhorn algorithm 的可微可满足性层，能够同时处理多个边际分布集，并理论证明了该算法的多边际收敛性。与传统的顺序决策方法不同，该框架实现了 one-shot 神经网络求解，包括无监督神经路由求解器、处理两侧异常点的部分图匹配网络，以及满足连续约束的金融投资组合预测网络。这些创新为复杂约束问题的神经网络求解提供了新途径。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "This is a revised version of our ICML'23 publication that fixes a\n  minor issue in Eq (11). In Proceedings of the 40th International Conference\n  on Machine Learning (ICML'23)",
      "pdf_url": "http://arxiv.org/pdf/2407.13917v1",
      "published_date": "2024-07-18 22:05:21 UTC",
      "updated_date": "2024-07-18 22:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:46:26.834995"
    },
    {
      "arxiv_id": "2407.13906v1",
      "title": "Crafting Efficient Fine-Tuning Strategies for Large Language Models",
      "title_zh": "为大型语言模型设计高效",
      "authors": [
        "Michael Oliver",
        "Guan Wang"
      ],
      "abstract": "This paper addresses the challenges of efficiently fine-tuning large language\nmodels (LLMs) by exploring data efficiency and hyperparameter optimization. We\ninvestigate the minimum data required for effective fine-tuning and propose a\nnovel hyperparameter optimization method that leverages early-stage model\nperformance. Our experiments demonstrate that fine-tuning with as few as 200\nsamples can improve model accuracy from 70\\% to 88\\% in a product attribute\nextraction task. We identify a saturation point of approximately 6,500 samples,\nbeyond which additional data yields diminishing returns. Our proposed bayesian\nhyperparameter optimization method, which evaluates models at 20\\% of total\ntraining time, correlates strongly with final model performance, with 4 out of\n5 top early-stage models remaining in the top 5 at completion. This approach\nled to a 2\\% improvement in accuracy over baseline models when evaluated on an\nindependent test set. These findings offer actionable insights for\npractitioners, potentially reducing computational load and dependency on\nextensive datasets while enhancing overall performance of fine-tuned LLMs.",
      "tldr_zh": "这篇论文探讨了高效微调大型语言模型（LLMs）的策略，重点关注数据效率和超参数优化。研究者调查了微调所需的最少数据量，发现使用仅200个样本即可将模型准确率从70%提高到88%，并确定约6500个样本为饱和点，此后额外数据收益递减。他们提出了一种新型贝叶斯超参数优化方法，通过在训练时间的20%时评估模型，与最终性能高度相关，导致比基线模型提高2%的准确率。这些发现为从业者提供了实用见解，帮助减少计算负载和对大规模数据集的依赖，同时提升LLMs的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13906v1",
      "published_date": "2024-07-18 21:36:00 UTC",
      "updated_date": "2024-07-18 21:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:46:39.317271"
    },
    {
      "arxiv_id": "2408.00005v1",
      "title": "Framework for Curating Speech Datasets and Evaluating ASR Systems: A Case Study for Polish",
      "title_zh": "翻译失败",
      "authors": [
        "Michał Junczyk"
      ],
      "abstract": "Speech datasets available in the public domain are often underutilized\nbecause of challenges in discoverability and interoperability. A comprehensive\nframework has been designed to survey, catalog, and curate available speech\ndatasets, which allows replicable evaluation of automatic speech recognition\n(ASR) systems. A case study focused on the Polish language was conducted; the\nframework was applied to curate more than 24 datasets and evaluate 25\ncombinations of ASR systems and models. This research constitutes the most\nextensive comparison to date of both commercial and free ASR systems for the\nPolish language. It draws insights from 600 system-model-test set evaluations,\nmarking a significant advancement in both scale and comprehensiveness. The\nresults of surveys and performance comparisons are available as interactive\ndashboards (https://huggingface.co/spaces/amu-cai/pl-asr-leaderboard) along\nwith curated datasets (https://huggingface.co/datasets/amu-cai/pl-asr-bigos-v2,\nhttps://huggingface.co/datasets/pelcra/pl-asr-pelcra-for-bigos) and the open\nchallenge call (https://poleval.pl/tasks/task3). Tools used for evaluation are\nopen-sourced (https://github.com/goodmike31/pl-asr-bigos-tools), facilitating\nreplication and adaptation for other languages, as well as continuous expansion\nwith new datasets and systems.",
      "tldr_zh": "这篇论文提出一个全面框架，用于调查、目录化和整理公共语音数据集，以实现自动语音识别（ASR）系统的可复制评估。针对波兰语的案例研究中，该框架整理了超过24个数据集，并评估了25种ASR系统和模型组合，共进行了600次系统-模型-测试集评估，这是迄今为止对波兰语商业和免费ASR系统的最大规模比较。研究成果包括交互式仪表板（https://huggingface.co/spaces/amu-cai/pl-asr-leaderboard）、整理的数据集和开源工具（https://github.com/goodmike31/pl-asr-bigos-tools），便于其他语言的复制和扩展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "I.2.7"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to NeurIPS 2024 Datasets and Benchmarks Track",
      "pdf_url": "http://arxiv.org/pdf/2408.00005v1",
      "published_date": "2024-07-18 21:32:12 UTC",
      "updated_date": "2024-07-18 21:32:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:46:50.333165"
    },
    {
      "arxiv_id": "2407.13896v1",
      "title": "Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Sheng",
        "Junhuan Yang",
        "Jinyang Li",
        "James Alaina",
        "Xiaowei Xu",
        "Yiyu Shi",
        "Jingtong Hu",
        "Weiwen Jiang",
        "Lei Yang"
      ],
      "abstract": "As Artificial Intelligence (AI) increasingly integrates into our daily lives,\nfairness has emerged as a critical concern, particularly in medical AI, where\ndatasets often reflect inherent biases due to social factors like the\nunderrepresentation of marginalized communities and socioeconomic barriers to\ndata collection. Traditional approaches to mitigating these biases have focused\non data augmentation and the development of fairness-aware training algorithms.\nHowever, this paper argues that the architecture of neural networks, a core\ncomponent of Machine Learning (ML), plays a crucial role in ensuring fairness.\nWe demonstrate that addressing fairness effectively requires a holistic\napproach that simultaneously considers data, algorithms, and architecture.\nUtilizing Automated ML (AutoML) technology, specifically Neural Architecture\nSearch (NAS), we introduce a novel framework, BiaslessNAS, designed to achieve\nfair outcomes in analyzing skin lesion datasets. BiaslessNAS incorporates\nfairness considerations at every stage of the NAS process, leading to the\nidentification of neural networks that are not only more accurate but also\nsignificantly fairer. Our experiments show that BiaslessNAS achieves a 2.55%\nincrease in accuracy and a 65.50% improvement in fairness compared to\ntraditional NAS methods, underscoring the importance of integrating fairness\ninto neural network architecture for better outcomes in medical AI\napplications.",
      "tldr_zh": "该论文探讨了AI在医疗领域的公平性问题，特别是皮肤病数据集中的偏见问题，强调需要同时优化数据、算法和神经网络架构。作者提出BiaslessNAS框架，利用AutoML和Neural Architecture Search (NAS)技术，将公平性融入NAS过程的每个阶段，以开发更准确且公平的神经网络。在皮肤病数据集上的实验显示，BiaslessNAS相比传统NAS方法，准确率提高了2.55%，公平性提升了65.50%，为医疗AI应用提供了更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "MICCAI",
      "pdf_url": "http://arxiv.org/pdf/2407.13896v1",
      "published_date": "2024-07-18 20:49:57 UTC",
      "updated_date": "2024-07-18 20:49:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:47:02.483850"
    },
    {
      "arxiv_id": "2407.13891v2",
      "title": "High Risk of Political Bias in Black Box Emotion Inference Models",
      "title_zh": "黑箱情感推理模型中的政治偏差高风险",
      "authors": [
        "Hubert Plisiecki",
        "Paweł Lenartowicz",
        "Maria Flakus",
        "Artur Pokropek"
      ],
      "abstract": "This paper investigates the presence of political bias in emotion inference\nmodels used for sentiment analysis (SA) in social science research. Machine\nlearning models often reflect biases in their training data, impacting the\nvalidity of their outcomes. While previous research has highlighted gender and\nrace biases, our study focuses on political bias - an underexplored yet\npervasive issue that can skew the interpretation of text data across a wide\narray of studies. We conducted a bias audit on a Polish sentiment analysis\nmodel developed in our lab. By analyzing valence predictions for names and\nsentences involving Polish politicians, we uncovered systematic differences\ninfluenced by political affiliations. Our findings indicate that annotations by\nhuman raters propagate political biases into the model's predictions. To\nmitigate this, we pruned the training dataset of texts mentioning these\npoliticians and observed a reduction in bias, though not its complete\nelimination. Given the significant implications of political bias in SA, our\nstudy emphasizes caution in employing these models for social science research.\nWe recommend a critical examination of SA results and propose using\nlexicon-based systems as a more ideologically neutral alternative. This paper\nunderscores the necessity for ongoing scrutiny and methodological adjustments\nto ensure the reliability and impartiality of the use of machine learning in\nacademic and applied contexts.",
      "tldr_zh": "这篇论文探讨了黑箱情感推理模型（emotion inference models）在情感分析（SA）中的政治偏见风险，这些偏见可能源于训练数据并影响社会科学研究的结果。研究者对一个波兰情感分析模型进行了偏见审计，通过分析涉及政客名字和句子的情感预测，发现模型预测存在系统性差异，受政治派别影响，且这种偏见主要来自人类标注者。实验显示，修剪训练数据集以删除相关文本能部分减少偏见，但无法完全消除。论文强调在使用这些模型时需谨慎审查结果，并推荐采用基于词汇的系统（lexicon-based systems）作为更中立的选择，以提升机器学习在学术中的可靠性和公正性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13891v2",
      "published_date": "2024-07-18 20:31:07 UTC",
      "updated_date": "2024-11-21 06:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:47:16.392141"
    },
    {
      "arxiv_id": "2407.14564v1",
      "title": "APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Sheng",
        "Hanchen Wang",
        "Yipei Liu",
        "Junhuan Yang",
        "Weiwen Jiang",
        "Youzuo Lin",
        "Lei Yang"
      ],
      "abstract": "Ultrasound computed tomography (USCT) is a promising technique that achieves\nsuperior medical imaging reconstruction resolution by fully leveraging waveform\ninformation, outperforming conventional ultrasound methods. Despite its\nadvantages, high-quality USCT reconstruction relies on extensive data\nacquisition by a large number of transducers, leading to increased costs,\ncomputational demands, extended patient scanning times, and manufacturing\ncomplexities. To mitigate these issues, we propose a new USCT method called\nAPS-USCT, which facilitates imaging with sparse data, substantially reducing\ndependence on high-cost dense data acquisition. Our APS-USCT method consists of\ntwo primary components: APS-wave and APS-FWI. The APS-wave component, an\nencoder-decoder system, preprocesses the waveform data, converting sparse data\ninto dense waveforms to augment sample density prior to reconstruction. The\nAPS-FWI component, utilizing the InversionNet, directly reconstructs the speed\nof sound (SOS) from the ultrasound waveform data. We further improve the\nmodel's performance by incorporating Squeeze-and-Excitation (SE) Blocks and\nsource encoding techniques. Testing our method on a breast cancer dataset\nyielded promising results. It demonstrated outstanding performance with an\naverage Structural Similarity Index (SSIM) of 0.8431. Notably, over 82% of\nsamples achieved an SSIM above 0.8, with nearly 61% exceeding 0.85,\nhighlighting the significant potential of our approach in improving USCT image\nreconstruction by efficiently utilizing sparse data.",
      "tldr_zh": "这篇论文提出了 APS-USCT 方法，通过 AI-Physic Synergy 技术，实现基于稀疏数据的 Ultrasound Computed Tomography (USCT)，以降低数据采集成本、计算需求和扫描时间。APS-USCT 包括两个核心组件：APS-wave（一个编码器-解码器系统，用于将稀疏波形数据转换为密集波形，提高样本密度）和 APS-FWI（利用 InversionNet 从波形数据直接重建声速）。此外，方法还整合了 Squeeze-and-Excitation (SE) Blocks 和源编码技术，以提升性能。在乳腺癌数据集上的实验显示，平均 Structural Similarity Index (SSIM) 达到 0.8431，且超过 82% 的样本 SSIM 高于 0.8，证明了该方法在高效 USCT 图像重建方面的显著潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "MICCAI",
      "pdf_url": "http://arxiv.org/pdf/2407.14564v1",
      "published_date": "2024-07-18 20:30:41 UTC",
      "updated_date": "2024-07-18 20:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:47:28.661299"
    },
    {
      "arxiv_id": "2407.13862v2",
      "title": "Enhancing Worldwide Image Geolocation by Ensembling Satellite-Based Ground-Level Attribute Predictors",
      "title_zh": "翻译失败",
      "authors": [
        "Michael J. Bianco",
        "David Eigen",
        "Michael Gormish"
      ],
      "abstract": "We examine the challenge of estimating the location of a single ground-level\nimage in the absence of GPS or other location metadata. Currently, geolocation\nsystems are evaluated by measuring the Great Circle Distance between the\npredicted location and ground truth. Because this measurement only uses a\nsingle point, it cannot assess the distribution of predictions by geolocation\nsystems. Evaluation of a distribution of potential locations (areas) is\nrequired when there are follow-on procedures to further narrow down or verify\nthe location. This is especially important in poorly-sampled regions e.g. rural\nand wilderness areas.\n  In this paper, we introduce a novel metric, Recall vs Area (RvA), which\nmeasures the accuracy of estimated distributions of locations. RvA treats image\ngeolocation results similarly to document retrieval, measuring recall as a\nfunction of area: For a ranked list of (possibly discontiguous) predicted\nregions, we measure the area required for accumulated regions to contain the\nground truth coordinate. This produces a curve similar to a precision-recall\ncurve, where \"precision\" is replaced by square kilometers area, enabling\nevaluation for different downstream search area budgets.\n  Following from this view of the problem, we then examine an ensembling\napproach to global-scale image geolocation, which incorporates information from\nmultiple sources, and can readily incorporate multiple models, attribute\npredictors, and data sources. We study its effectiveness by combining the\ngeolocation models GeoEstimation and the current state-of-the-art, GeoCLIP,\nwith attribute predictors based on Oak Ridge National Laboratory LandScan and\nEuropean Space Agency Climate Change Initiative Land Cover. We find significant\nimprovements in image geolocation for areas that are under-represented in the\ntraining set, particularly non-urban areas, on both Im2GPS3k and Street View\nimages.",
      "tldr_zh": "本研究探讨了在缺乏GPS等元数据的情况下，对单张地面图像进行全球图像地理定位（image geolocation）的挑战，提出了一种新评估指标Recall vs Area (RvA)，用于衡量预测位置分布的准确性，类似于精确率-召回率曲线但以面积（如平方公里）取代精确率，以适应下游搜索需求。  \n作者采用集成方法（ensembling approach），结合GeoEstimation和GeoCLIP等模型，以及基于卫星数据的属性预测器如Oak Ridge National Laboratory LandScan和European Space Agency Climate Change Initiative Land Cover，从而整合多源信息提升定位性能。  \n实验结果显示，该方法显著改善了训练数据中欠采样区域（如非城市和荒野地区）的图像地理定位准确性，在Im2GPS3k和Street View数据集上取得了明显提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13862v2",
      "published_date": "2024-07-18 19:15:52 UTC",
      "updated_date": "2024-09-17 21:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:47:38.792732"
    },
    {
      "arxiv_id": "2407.14562v2",
      "title": "Thought-Like-Pro: Enhancing Reasoning of Large Language Models through Self-Driven Prolog-based Chain-of-Thought",
      "title_zh": "Thought-L",
      "authors": [
        "Xiaoyu Tan",
        "Yongxin Deng",
        "Xihe Qiu",
        "Weidi Xu",
        "Chao Qu",
        "Wei Chu",
        "Yinghui Xu",
        "Yuan Qi"
      ],
      "abstract": "Large language models (LLMs) have shown exceptional performance as\ngeneral-purpose assistants, excelling across a variety of reasoning tasks. This\nachievement represents a significant step toward achieving artificial general\nintelligence (AGI). Despite these advancements, the effectiveness of LLMs often\nhinges on the specific prompting strategies employed, and there remains a lack\nof a robust framework to facilitate learning and generalization across diverse\nreasoning tasks. To address these challenges, we introduce a novel learning\nframework, THOUGHT-LIKE-PRO In this framework, we utilize imitation learning to\nimitate the Chain-of-Thought (CoT) process which is verified and translated\nfrom reasoning trajectories generated by a symbolic Prolog logic engine. This\nframework proceeds in a self-driven manner, that enables LLMs to formulate\nrules and statements from given instructions and leverage the symbolic Prolog\nengine to derive results. Subsequently, LLMs convert Prolog-derived successive\nreasoning trajectories into natural language CoT for imitation learning. Our\nempirical findings indicate that our proposed approach substantially enhances\nthe reasoning abilities of LLMs and demonstrates robust generalization across\nout-of-distribution reasoning tasks.",
      "tldr_zh": "该研究提出了一种名为 Thought-Like-Pro 的新框架，旨在通过自我驱动的 Prolog 逻辑引擎增强 Large Language Models (LLMs) 的推理能力，以解决现有模型在多样化推理任务中学习和泛化不足的问题。该框架利用模仿学习 (imitation learning) 来模仿从 Prolog 引擎生成的 Chain-of-Thought (CoT) 推理轨迹，允许 LLMs 从指令中制定规则、推导结果，并将这些轨迹转化为自然语言形式的 CoT。实验结果显示，该方法显著提高了 LLMs 的推理性能，并在分布外 (out-of-distribution) 任务上展现出强大的泛化能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14562v2",
      "published_date": "2024-07-18 18:52:10 UTC",
      "updated_date": "2024-08-10 06:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:47:51.218865"
    },
    {
      "arxiv_id": "2407.15871v3",
      "title": "Semantic Prototypes: Enhancing Transparency Without Black Boxes",
      "title_zh": "翻译失败",
      "authors": [
        "Orfeas Menis-Mastromichalakis",
        "Giorgos Filandrianos",
        "Jason Liartis",
        "Edmund Dervakos",
        "Giorgos Stamou"
      ],
      "abstract": "As machine learning (ML) models and datasets increase in complexity, the\ndemand for methods that enhance explainability and interpretability becomes\nparamount. Prototypes, by encapsulating essential characteristics within data,\noffer insights that enable tactical decision-making and enhance transparency.\nTraditional prototype methods often rely on sub-symbolic raw data and opaque\nlatent spaces, reducing explainability and increasing the risk of\nmisinterpretations. This paper presents a novel framework that utilizes\nsemantic descriptions to define prototypes and provide clear explanations,\neffectively addressing the shortcomings of conventional methods. Our approach\nleverages concept-based descriptions to cluster data on the semantic level,\nensuring that prototypes not only represent underlying properties intuitively\nbut are also straightforward to interpret. Our method simplifies the\ninterpretative process and effectively bridges the gap between complex data\nstructures and human cognitive processes, thereby enhancing transparency and\nfostering trust. Our approach outperforms existing widely-used prototype\nmethods in facilitating human understanding and informativeness, as validated\nthrough a user survey.",
      "tldr_zh": "该论文针对机器学习 (ML) 模型和数据集的复杂性，提出了一种名为 Semantic Prototypes 的新框架，以提升模型的 explainability 和 interpretability，而无需依赖黑盒机制。传统原型方法依赖于 sub-symbolic 原始数据和不透明的 latent spaces，导致解释性不足，该框架改用基于概念的语义描述在语义层面聚类数据，使原型更直观且易于人类理解。实验结果通过用户调查显示，该方法在促进人类理解和信息性方面优于现有原型方法，从而增强了透明度和信任。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for publication as a full paper at the\n  33rd ACM International Conference on Information and Knowledge Management\n  (CIKM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.15871v3",
      "published_date": "2024-07-18 18:42:58 UTC",
      "updated_date": "2024-08-19 15:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:48:02.463549"
    },
    {
      "arxiv_id": "2407.18965v1",
      "title": "Generative AI Augmented Induction-based Formal Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Kumar",
        "Deepak Narayan Gadde"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) has demonstrated its capabilities\nin the present world that reduce human effort significantly. It utilizes deep\nlearning techniques to create original and realistic content in terms of text,\nimages, code, music, and video. Researchers have also shown the capabilities of\nmodern Large Language Models (LLMs) used by GenAI models that can be used to\naid hardware development. Formal verification is a mathematical-based proof\nmethod used to exhaustively verify the correctness of a design. In this paper,\nwe demonstrate how GenAI can be used in induction-based formal verification to\nincrease the verification throughput.",
      "tldr_zh": "本文提出了一种利用 Generative AI (GenAI) 增强基于归纳的形式验证方法，旨在提高硬件设计验证的效率。研究利用现代 Large Language Models (LLMs) 的能力，帮助生成内容并辅助形式验证过程，从而减少人类手动努力。实验结果显示，这种方法显著提升了验证吞吐量，为硬件开发提供了更高效的数学证明工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at the 37th IEEE International System-on-Chip Conference,\n  Sep 16-19 2024, Dresden, Germany",
      "pdf_url": "http://arxiv.org/pdf/2407.18965v1",
      "published_date": "2024-07-18 18:36:41 UTC",
      "updated_date": "2024-07-18 18:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:48:18.312913"
    },
    {
      "arxiv_id": "2407.13833v2",
      "title": "Phi-3 Safety Post-Training: Aligning Language Models with a \"Break-Fix\" Cycle",
      "title_zh": "翻译失败",
      "authors": [
        "Emman Haider",
        "Daniel Perez-Becker",
        "Thomas Portet",
        "Piyush Madan",
        "Amit Garg",
        "Atabak Ashfaq",
        "David Majercak",
        "Wen Wen",
        "Dongwoo Kim",
        "Ziyi Yang",
        "Jianwen Zhang",
        "Hiteshi Sharma",
        "Blake Bullwinkel",
        "Martin Pouliot",
        "Amanda Minnich",
        "Shiven Chawla",
        "Solianna Herrera",
        "Shahed Warreth",
        "Maggie Engler",
        "Gary Lopez",
        "Nina Chikanov",
        "Raja Sekhar Rao Dheekonda",
        "Bolor-Erdene Jagdagdorj",
        "Roman Lutz",
        "Richard Lundeen",
        "Tori Westerhoff",
        "Pete Bryan",
        "Christian Seifert",
        "Ram Shankar Siva Kumar",
        "Andrew Berkley",
        "Alex Kessler"
      ],
      "abstract": "Recent innovations in language model training have demonstrated that it is\npossible to create highly performant models that are small enough to run on a\nsmartphone. As these models are deployed in an increasing number of domains, it\nis critical to ensure that they are aligned with human preferences and safety\nconsiderations. In this report, we present our methodology for safety aligning\nthe Phi-3 series of language models. We utilized a \"break-fix\" cycle,\nperforming multiple rounds of dataset curation, safety post-training,\nbenchmarking, red teaming, and vulnerability identification to cover a variety\nof harm areas in both single and multi-turn scenarios. Our results indicate\nthat this approach iteratively improved the performance of the Phi-3 models\nacross a wide range of responsible AI benchmarks. Finally, we include\nadditional red teaming strategies and evaluations that were used to test the\nsafety behavior of Phi-3.5-mini and Phi-3.5-MoE, which were optimized for\nmultilingual capabilities.",
      "tldr_zh": "该研究介绍了针对 Phi-3 系列语言模型的安全后训练方法，采用 \"break-fix\" 循环来确保模型与人类偏好和安全考虑一致。方法包括多次迭代的数据集整理、安全后训练、基准测试、红队测试(red teaming)和漏洞识别，覆盖单轮和多轮场景中的各种危害领域。结果表明，这种迭代方法显著提高了 Phi-3 模型在负责任 AI 基准(responsible AI benchmarks)上的性能，并针对 Phi-3.5-mini 和 Phi-3.5-MoE 进行了额外的红队策略优化，以提升其多语言能力的安全性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13833v2",
      "published_date": "2024-07-18 18:06:59 UTC",
      "updated_date": "2024-08-23 00:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:48:30.141774"
    },
    {
      "arxiv_id": "2407.13768v1",
      "title": "Addressing Imbalance for Class Incremental Learning in Medical Image Classification",
      "title_zh": "解决医疗图像分类中类别增量学习的失衡问题",
      "authors": [
        "Xuze Hao",
        "Wenqian Ni",
        "Xuhao Jiang",
        "Weimin Tan",
        "Bo Yan"
      ],
      "abstract": "Deep convolutional neural networks have made significant breakthroughs in\nmedical image classification, under the assumption that training samples from\nall classes are simultaneously available. However, in real-world medical\nscenarios, there's a common need to continuously learn about new diseases,\nleading to the emerging field of class incremental learning (CIL) in the\nmedical domain. Typically, CIL suffers from catastrophic forgetting when\ntrained on new classes. This phenomenon is mainly caused by the imbalance\nbetween old and new classes, and it becomes even more challenging with\nimbalanced medical datasets. In this work, we introduce two simple yet\neffective plug-in methods to mitigate the adverse effects of the imbalance.\nFirst, we propose a CIL-balanced classification loss to mitigate the classifier\nbias toward majority classes via logit adjustment. Second, we propose a\ndistribution margin loss that not only alleviates the inter-class overlap in\nembedding space but also enforces the intra-class compactness. We evaluate the\neffectiveness of our method with extensive experiments on three benchmark\ndatasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our\napproach outperforms state-of-the-art methods.",
      "tldr_zh": "该研究针对医疗图像分类中的类增量学习（CIL）问题，解决了训练新类时因旧类和新类不平衡导致的灾难性遗忘现象，尤其在不平衡医疗数据集上。作者提出两个简单有效的插件方法：CIL-balanced classification loss，通过logit adjustment减轻分类器对多数类的偏见；以及distribution margin loss，用于缓解嵌入空间中的类间重叠并增强类内紧凑性。在CCH5000、HAM10000和EyePACS三个基准数据集上的广泛实验表明，该方法优于现有最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13768v1",
      "published_date": "2024-07-18 17:59:44 UTC",
      "updated_date": "2024-07-18 17:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:48:38.522987"
    },
    {
      "arxiv_id": "2407.13765v2",
      "title": "Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data",
      "title_zh": "翻译失败",
      "authors": [
        "Charles Jin",
        "Martin Rinard"
      ],
      "abstract": "As language models (LMs) deliver increasing performance on a range of NLP\ntasks, probing classifiers have become an indispensable technique in the effort\nto better understand their inner workings. A typical setup involves (1)\ndefining an auxiliary task consisting of a dataset of text annotated with\nlabels, then (2) supervising small classifiers to predict the labels from the\nrepresentations of a pretrained LM as it processed the dataset. A high probing\naccuracy is interpreted as evidence that the LM has learned to perform the\nauxiliary task as an unsupervised byproduct of its original pretraining\nobjective. Despite the widespread usage of probes, however, the robust design\nand analysis of probing experiments remains a challenge. We develop a formal\nperspective on probing using structural causal models (SCM). Specifically,\ngiven an SCM which explains the distribution of tokens observed during\ntraining, we frame the central hypothesis as whether the LM has learned to\nrepresent the latent variables of the SCM. Empirically, we extend a recent\nstudy of LMs in the context of a synthetic grid-world navigation task, where\nhaving an exact model of the underlying causal structure allows us to draw\nstrong inferences from the result of probing experiments. Our techniques\nprovide robust empirical evidence for the ability of LMs to induce the latent\nconcepts underlying text.",
      "tldr_zh": "这篇论文从结构化因果模型（SCM）的角度，正式化了语言模型（LMs）中的潜在因果探测（Latent Causal Probing）方法，以更好地理解LMs的内部表示。研究者将probing实验框架化为测试LMs是否学会了表示SCM的潜在变量，从而解决传统probing实验的设计和分析挑战。在一个合成网格世界导航任务的实验中，他们提供了稳健的经验证据，证明LMs能够有效诱导文本背后的潜在概念。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13765v2",
      "published_date": "2024-07-18 17:59:27 UTC",
      "updated_date": "2024-07-31 05:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:48:50.202697"
    },
    {
      "arxiv_id": "2407.14561v4",
      "title": "NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals",
      "title_zh": "翻译失败",
      "authors": [
        "Jaden Fiotto-Kaufman",
        "Alexander R. Loftus",
        "Eric Todd",
        "Jannik Brinkmann",
        "Koyena Pal",
        "Dmitrii Troitskii",
        "Michael Ripa",
        "Adam Belfki",
        "Can Rager",
        "Caden Juang",
        "Aaron Mueller",
        "Samuel Marks",
        "Arnab Sen Sharma",
        "Francesca Lucchetti",
        "Nikhil Prakash",
        "Carla Brodley",
        "Arjun Guha",
        "Jonathan Bell",
        "Byron C. Wallace",
        "David Bau"
      ],
      "abstract": "We introduce NNsight and NDIF, technologies that work in tandem to enable\nscientific study of the representations and computations learned by very large\nneural networks. NNsight is an open-source system that extends PyTorch to\nintroduce deferred remote execution. The National Deep Inference Fabric (NDIF)\nis a scalable inference service that executes NNsight requests, allowing users\nto share GPU resources and pretrained models. These technologies are enabled by\nthe Intervention Graph, an architecture developed to decouple experimental\ndesign from model runtime. Together, this framework provides transparent and\nefficient access to the internals of deep neural networks such as very large\nlanguage models (LLMs) without imposing the cost or complexity of hosting\ncustomized models individually. We conduct a quantitative survey of the machine\nlearning literature that reveals a growing gap in the study of the internals of\nlarge-scale AI. We demonstrate the design and use of our framework to address\nthis gap by enabling a range of research methods on huge models. Finally, we\nconduct benchmarks to compare performance with previous approaches.\n  Code, documentation, and tutorials are available at https://nnsight.net/.",
      "tldr_zh": "本研究引入了 NNsight 和 NDIF 技术，以民主化方式访问开放权重基础模型的内部，旨在促进对大型神经网络（如 LLMs）的表示和计算进行科学研究。NNsight 是一个开源系统，扩展了 PyTorch 以支持延迟远程执行，而 NDIF 则是一个可扩展的推理服务，允许用户共享 GPU 资源和预训练模型，通过 Intervention Graph 架构将实验设计与模型运行解耦。研究通过定量调查揭示了当前机器学习文献中对大规模 AI 内部研究的差距，并展示了该框架如何启用各种研究方法，同时基准测试证明了其性能优于以往方法。代码和文档可通过 https://nnsight.net/ 获得。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code at https://nnsight.net",
      "pdf_url": "http://arxiv.org/pdf/2407.14561v4",
      "published_date": "2024-07-18 17:59:01 UTC",
      "updated_date": "2025-04-01 16:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:49:04.164101"
    },
    {
      "arxiv_id": "2407.14560v1",
      "title": "Automated and Holistic Co-design of Neural Networks and ASICs for Enabling In-Pixel Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Shubha R. Kharel",
        "Prashansa Mukim",
        "Piotr Maj",
        "Grzegorz W. Deptuch",
        "Shinjae Yoo",
        "Yihui Ren",
        "Soumyajit Mandal"
      ],
      "abstract": "Extreme edge-AI systems, such as those in readout ASICs for radiation\ndetection, must operate under stringent hardware constraints such as\nmicron-level dimensions, sub-milliwatt power, and nanosecond-scale speed while\nproviding clear accuracy advantages over traditional architectures. Finding\nideal solutions means identifying optimal AI and ASIC design choices from a\ndesign space that has explosively expanded during the merger of these domains,\ncreating non-trivial couplings which together act upon a small set of solutions\nas constraints tighten. It is impractical, if not impossible, to manually\ndetermine ideal choices among possibilities that easily exceed billions even in\nsmall-size problems. Existing methods to bridge this gap have leveraged\ntheoretical understanding of hardware to f architecture search. However, the\nassumptions made in computing such theoretical metrics are too idealized to\nprovide sufficient guidance during the difficult search for a practical\nimplementation. Meanwhile, theoretical estimates for many other crucial metrics\n(like delay) do not even exist and are similarly variable, dependent on\nparameters of the process design kit (PDK). To address these challenges, we\npresent a study that employs intelligent search using multi-objective Bayesian\noptimization, integrating both neural network search and ASIC synthesis in the\nloop. This approach provides reliable feedback on the collective impact of all\ncross-domain design choices. We showcase the effectiveness of our approach by\nfinding several Pareto-optimal design choices for effective and efficient\nneural networks that perform real-time feature extraction from input pulses\nwithin the individual pixels of a readout ASIC.",
      "tldr_zh": "该研究针对极端边缘 AI 系统（如辐射检测的读取 ASICs）的硬件约束（包括微米级尺寸、亚毫瓦功率和纳秒级速度），提出了一种自动化整体共设计方法，以实现 In-Pixel Intelligence。方法采用多目标贝叶斯优化（multi-objective Bayesian optimization）进行智能搜索，将神经网络搜索和 ASIC 合成整合到循环中，提供跨领域设计选择的可靠反馈。实验结果展示了几个 Pareto-optimal 设计方案，能够在读取 ASIC 的单个像素内高效进行实时特征提取，显著提升了系统性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14560v1",
      "published_date": "2024-07-18 17:58:05 UTC",
      "updated_date": "2024-07-18 17:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:49:14.064240"
    },
    {
      "arxiv_id": "2407.13760v1",
      "title": "Neural Network Tire Force Modeling for Automated Drifting",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Drake Broadbent",
        "Trey Weber",
        "Daiki Mori",
        "J. Christian Gerdes"
      ],
      "abstract": "Automated drifting presents a challenge problem for vehicle control,\nrequiring models and control algorithms that can precisely handle nonlinear,\ncoupled tire forces at the friction limits. We present a neural network\narchitecture for predicting front tire lateral force as a drop-in replacement\nfor physics-based approaches. With a full-scale automated vehicle purpose-built\nfor the drifting application, we deploy these models in a nonlinear model\npredictive controller tuned for tracking a reference drifting trajectory, for\ndirect comparisons of model performance. The neural network tire model exhibits\nsignificantly improved path tracking performance over the brush tire model in\ncases where front-axle braking force is applied, suggesting the neural\nnetwork's ability to express previously unmodeled, latent dynamics in the\ndrifting condition.",
      "tldr_zh": "本研究针对自动漂移(Automated Drifting)的车辆控制挑战，提出了一种神经网络(Neural Network)架构，用于预测前轮横向力，以取代传统的物理模型。\n该模型被部署在非线性模型预测控制器(Nonlinear Model Predictive Controller)中，用于跟踪参考漂移轨迹，并与刷子轮胎模型(Brush Tire Model)进行直接比较。\n实验结果显示，当应用前轴制动力时，神经网络轮胎模型的路径跟踪性能显著提升，超过了基准模型。\n这表明神经网络能够捕捉到漂移条件下之前未建模的潜在动态(Latent Dynamics)。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "16th International Symposium on Advanced Vehicle Control (AVEC).\n  September 2nd-6th, 2024. Milan, Italy",
      "pdf_url": "http://arxiv.org/pdf/2407.13760v1",
      "published_date": "2024-07-18 17:58:01 UTC",
      "updated_date": "2024-07-18 17:58:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:49:27.700863"
    },
    {
      "arxiv_id": "2407.13757v1",
      "title": "Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models",
      "title_zh": "黑盒意见操纵攻击：针对大语言模型检索增强生成的攻击",
      "authors": [
        "Zhuo Chen",
        "Jiawei Liu",
        "Haotan Liu",
        "Qikai Cheng",
        "Fan Zhang",
        "Wei Lu",
        "Xiaozhong Liu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) is applied to solve hallucination\nproblems and real-time constraints of large language models, but it also\ninduces vulnerabilities against retrieval corruption attacks. Existing research\nmainly explores the unreliability of RAG in white-box and closed-domain QA\ntasks. In this paper, we aim to reveal the vulnerabilities of\nRetrieval-Enhanced Generative (RAG) models when faced with black-box attacks\nfor opinion manipulation. We explore the impact of such attacks on user\ncognition and decision-making, providing new insight to enhance the reliability\nand security of RAG models. We manipulate the ranking results of the retrieval\nmodel in RAG with instruction and use these results as data to train a\nsurrogate model. By employing adversarial retrieval attack methods to the\nsurrogate model, black-box transfer attacks on RAG are further realized.\nExperiments conducted on opinion datasets across multiple topics show that the\nproposed attack strategy can significantly alter the opinion polarity of the\ncontent generated by RAG. This demonstrates the model's vulnerability and, more\nimportantly, reveals the potential negative impact on user cognition and\ndecision-making, making it easier to mislead users into accepting incorrect or\nbiased information.",
      "tldr_zh": "这篇论文探讨了Retrieval-Augmented Generation (RAG) 模型在黑箱攻击下的脆弱性，重点揭示了攻击者如何通过操纵意见来影响大型语言模型的生成输出。研究方法包括使用指令篡改检索模型的排名结果，训练代理模型并应用对抗性检索攻击，实现黑箱转移攻击。实验结果显示，在多个主题的意见数据集上，这种攻击策略能显著改变RAG生成内容的意见极性，可能误导用户认知和决策，为提升RAG模型的可靠性和安全性提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2407.13757v1",
      "published_date": "2024-07-18 17:55:55 UTC",
      "updated_date": "2024-07-18 17:55:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:49:42.765158"
    },
    {
      "arxiv_id": "2407.13751v1",
      "title": "Temporal Representation Learning for Stock Similarities and Its Applications in Investment Management",
      "title_zh": "股票相似性的时序表示学习及其在投资管理中的应用",
      "authors": [
        "Yoontae Hwang",
        "Stefan Zohren",
        "Yongjae Lee"
      ],
      "abstract": "In the era of rapid globalization and digitalization, accurate identification\nof similar stocks has become increasingly challenging due to the non-stationary\nnature of financial markets and the ambiguity in conventional regional and\nsector classifications. To address these challenges, we examine SimStock, a\nnovel temporal self-supervised learning framework that combines techniques from\nself-supervised learning (SSL) and temporal domain generalization to learn\nrobust and informative representations of financial time series data. The\nprimary focus of our study is to understand the similarities between stocks\nfrom a broader perspective, considering the complex dynamics of the global\nfinancial landscape. We conduct extensive experiments on four real-world\ndatasets with thousands of stocks and demonstrate the effectiveness of SimStock\nin finding similar stocks, outperforming existing methods. The practical\nutility of SimStock is showcased through its application to various investment\nstrategies, such as pairs trading, index tracking, and portfolio optimization,\nwhere it leads to superior performance compared to conventional methods. Our\nfindings empirically examine the potential of data-driven approach to enhance\ninvestment decision-making and risk management practices by leveraging the\npower of temporal self-supervised learning in the face of the ever-changing\nglobal financial landscape.",
      "tldr_zh": "该研究针对金融市场的非平稳性和传统分类模糊性，提出了一种新型时序自监督学习框架SimStock，结合自监督学习(SSL)和时序域泛化技术，以学习金融时间序列数据的鲁棒表示，从而更全面地识别股票相似性。在四种真实世界数据集上的广泛实验中，SimStock在发现相似股票方面优于现有方法。论文进一步展示了其在投资策略中的实际应用，如配对交易、指数跟踪和投资组合优化，实现了比传统方法更优异的性能，证明了数据驱动方法在提升投资决策和风险管理中的潜力。",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13751v1",
      "published_date": "2024-07-18 17:54:13 UTC",
      "updated_date": "2024-07-18 17:54:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:49:50.943459"
    },
    {
      "arxiv_id": "2407.13744v1",
      "title": "LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation",
      "title_zh": "LLMs 作为函数逼近器：术语、分类法和评估问题",
      "authors": [
        "David Schlangen"
      ],
      "abstract": "Natural Language Processing has moved rather quickly from modelling specific\ntasks to taking more general pre-trained models and fine-tuning them for\nspecific tasks, to a point where we now have what appear to be inherently\ngeneralist models. This paper argues that the resultant loss of clarity on what\nthese models model leads to metaphors like \"artificial general intelligences\"\nthat are not helpful for evaluating their strengths and weaknesses. The\nproposal is to see their generality, and their potential value, in their\nability to approximate specialist function, based on a natural language\nspecification. This framing brings to the fore questions of the quality of the\napproximation, but beyond that, also questions of discoverability, stability,\nand protectability of these functions. As the paper will show, this framing\nhence brings together in one conceptual framework various aspects of\nevaluation, both from a practical and a theoretical perspective, as well as\nquestions often relegated to a secondary status (such as \"prompt injection\" and\n\"jailbreaking\").",
      "tldr_zh": "这篇论文讨论了大型语言模型（LLMs）从特定任务模型向通用模型演变的趋势，批评了“人工通用智能”等隐喻对评估其优势和劣势的局限性。作者提出将LLMs视为函数逼近器（Function Approximators），基于自然语言规范来逼近专业功能，这有助于突出评估中的逼近质量、发现性（discoverability）、稳定性和保护性（protectability）。这种框架整合了实际和理论评估方面，包括提示注入（prompt injection）和越狱（jailbreaking）等次要问题，提供了一个统一的术语和分类（Terminology, Taxonomy）体系来指导未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13744v1",
      "published_date": "2024-07-18 17:49:56 UTC",
      "updated_date": "2024-07-18 17:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:50:01.693933"
    },
    {
      "arxiv_id": "2407.13742v1",
      "title": "CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications",
      "title_zh": "CellularLint：一种系统方法用于识别蜂窝网络规范中不一致行为",
      "authors": [
        "Mirza Masfiqur Rahman",
        "Imtiaz Karim",
        "Elisa Bertino"
      ],
      "abstract": "In recent years, there has been a growing focus on scrutinizing the security\nof cellular networks, often attributing security vulnerabilities to issues in\nthe underlying protocol design descriptions. These protocol design\nspecifications, typically extensive documents that are thousands of pages long,\ncan harbor inaccuracies, underspecifications, implicit assumptions, and\ninternal inconsistencies. In light of the evolving landscape, we introduce\nCellularLint--a semi-automatic framework for inconsistency detection within the\nstandards of 4G and 5G, capitalizing on a suite of natural language processing\ntechniques. Our proposed method uses a revamped few-shot learning mechanism on\ndomain-adapted large language models. Pre-trained on a vast corpus of cellular\nnetwork protocols, this method enables CellularLint to simultaneously detect\ninconsistencies at various levels of semantics and practical use cases. In\ndoing so, CellularLint significantly advances the automated analysis of\nprotocol specifications in a scalable fashion. In our investigation, we focused\non the Non-Access Stratum (NAS) and the security specifications of 4G and 5G\nnetworks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After\nverification of these inconsistencies on open-source implementations and 17\ncommercial devices, we confirm that they indeed have a substantial impact on\ndesign decisions, potentially leading to concerns related to privacy,\nintegrity, availability, and interoperability.",
      "tldr_zh": "本研究针对蜂窝网络协议规范中的不准确、不完整和内部不一致问题，提出 CellularLint 框架，这是一个半自动系统，利用自然语言处理(NLP)技术、领域适配的大型语言模型(LLMs)和改进的少样本学习机制来检测 4G 和 5G 标准的语义和实际用例不一致。CellularLint 在 Non-Access Stratum (NAS) 和安全规范上进行了分析，成功识别出 157 个不一致，准确率达到 82.67%。通过对开源实现和 17 种商业设备的验证，这些不一致被证实可能导致隐私、完整性、可用性和互操作性方面的潜在风险，从而为协议分析提供可扩展的自动化解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at USENIX Security 24",
      "pdf_url": "http://arxiv.org/pdf/2407.13742v1",
      "published_date": "2024-07-18 17:48:46 UTC",
      "updated_date": "2024-07-18 17:48:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:52:08.374814"
    },
    {
      "arxiv_id": "2407.13739v1",
      "title": "Scaling Granite Code Models to 128K Context",
      "title_zh": "扩展 Granite 代码模型至 128K 上下文",
      "authors": [
        "Matt Stallone",
        "Vaibhav Saxena",
        "Leonid Karlinsky",
        "Bridget McGinn",
        "Tim Bula",
        "Mayank Mishra",
        "Adriana Meza Soria",
        "Gaoyuan Zhang",
        "Aditya Prasad",
        "Yikang Shen",
        "Saptha Surendran",
        "Shanmukha Guttula",
        "Hima Patel",
        "Parameswaran Selvam",
        "Xuan-Hong Dang",
        "Yan Koyfman",
        "Atin Sood",
        "Rogerio Feris",
        "Nirmit Desai",
        "David D. Cox",
        "Ruchir Puri",
        "Rameswar Panda"
      ],
      "abstract": "This paper introduces long-context Granite code models that support effective\ncontext windows of up to 128K tokens. Our solution for scaling context length\nof Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight\ncontinual pretraining by gradually increasing its RoPE base frequency with\nrepository-level file packing and length-upsampled long-context data.\nAdditionally, we also release instruction-tuned models with long-context\nsupport which are derived by further finetuning the long context base models on\na mix of permissively licensed short and long-context instruction-response\npairs. While comparing to the original short-context Granite code models, our\nlong-context models achieve significant improvements on long-context tasks\nwithout any noticeable performance degradation on regular code completion\nbenchmarks (e.g., HumanEval). We release all our long-context Granite code\nmodels under an Apache 2.0 license for both research and commercial use.",
      "tldr_zh": "本文介绍了扩展Granite代码模型至128K tokens上下文窗口的long-context版本，通过轻量级持续预训练方法（如逐渐增加RoPE基频率、仓库级文件打包和长度上采样长上下文数据）将Granite 3B/8B模型的上下文长度从2K/4K提升至128K。研究者还发布了基于这些模型的指令微调版本，使用短和长上下文指令-响应对进行进一步微调。结果显示，与原短上下文模型相比，新模型在长上下文任务上显著提升性能，同时在常规代码完成基准（如HumanEval）上无明显下降。所有模型以Apache 2.0许可证发布，支持研究和商业应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13739v1",
      "published_date": "2024-07-18 17:46:02 UTC",
      "updated_date": "2024-07-18 17:46:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:50:36.970352"
    },
    {
      "arxiv_id": "2407.13734v1",
      "title": "Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review",
      "title_zh": "翻译失败",
      "authors": [
        "Masatoshi Uehara",
        "Yulai Zhao",
        "Tommaso Biancalani",
        "Sergey Levine"
      ],
      "abstract": "This tutorial provides a comprehensive survey of methods for fine-tuning\ndiffusion models to optimize downstream reward functions. While diffusion\nmodels are widely known to provide excellent generative modeling capability,\npractical applications in domains such as biology require generating samples\nthat maximize some desired metric (e.g., translation efficiency in RNA, docking\nscore in molecules, stability in protein). In these cases, the diffusion model\ncan be optimized not only to generate realistic samples but also to explicitly\nmaximize the measure of interest. Such methods are based on concepts from\nreinforcement learning (RL). We explain the application of various RL\nalgorithms, including PPO, differentiable optimization, reward-weighted MLE,\nvalue-weighted sampling, and path consistency learning, tailored specifically\nfor fine-tuning diffusion models. We aim to explore fundamental aspects such as\nthe strengths and limitations of different RL-based fine-tuning algorithms\nacross various scenarios, the benefits of RL-based fine-tuning compared to\nnon-RL-based approaches, and the formal objectives of RL-based fine-tuning\n(target distributions). Additionally, we aim to examine their connections with\nrelated topics such as classifier guidance, Gflownets, flow-based diffusion\nmodels, path integral control theory, and sampling from unnormalized\ndistributions such as MCMC. The code of this tutorial is available at\nhttps://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq",
      "tldr_zh": "这篇论文提供了一个全面的教程和回顾，聚焦于使用强化学习（RL）方法微调扩散模型（diffusion models），以优化下游奖励函数，从而生成最大化特定指标的样本，如RNA的翻译效率或分子对接分数。论文详细解释了多种RL算法的应用，包括PPO、微分优化（differentiable optimization）、reward-weighted MLE、value-weighted sampling和path consistency learning，这些方法帮助扩散模型不仅生成真实样本，还能显式提升目标指标。作者探讨了这些算法的优势、局限性，以及与非RL方法的比较（如classifier guidance和Gflownets），并分析了其正式目标（target distributions）和与其他领域的联系，如路径积分控制理论（path integral control theory）和MCMC采样。总的来说，该工作为生物等领域应用提供了实用指导，并附有代码资源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "We plan to add more content/codes. Please let us know if there are\n  any comments",
      "pdf_url": "http://arxiv.org/pdf/2407.13734v1",
      "published_date": "2024-07-18 17:35:32 UTC",
      "updated_date": "2024-07-18 17:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:50:49.306562"
    },
    {
      "arxiv_id": "2407.13717v2",
      "title": "CoDefeater: Using LLMs To Find Defeaters in Assurance Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Usman Gohar",
        "Michael C. Hunter",
        "Robyn R. Lutz",
        "Myra B. Cohen"
      ],
      "abstract": "Constructing assurance cases is a widely used, and sometimes required,\nprocess toward demonstrating that safety-critical systems will operate safely\nin their planned environment. To mitigate the risk of errors and missing edge\ncases, the concept of defeaters - arguments or evidence that challenge claims\nin an assurance case - has been introduced. Defeaters can provide timely\ndetection of weaknesses in the arguments, prompting further investigation and\ntimely mitigations. However, capturing defeaters relies on expert judgment,\nexperience, and creativity and must be done iteratively due to evolving\nrequirements and regulations. This paper proposes CoDefeater, an automated\nprocess to leverage large language models (LLMs) for finding defeaters. Initial\nresults on two systems show that LLMs can efficiently find known and unforeseen\nfeasible defeaters to support safety analysts in enhancing the completeness and\nconfidence of assurance cases.",
      "tldr_zh": "本论文提出CoDefeater，一种利用大型语言模型(LLMs)自动识别assurance cases中defeaters的流程，以帮助检测安全关键系统的潜在弱点和缺失边际情况。传统上，捕捉defeaters依赖专家判断和迭代过程，而CoDefeater通过LLMs实现自动化，高效生成已知和未预见的可行defeaters。初步实验在两个系统中显示，该方法显著提升了assurance cases的完整性和信心，为安全分析师提供有力支持。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "ASE 2024 NIER",
      "pdf_url": "http://arxiv.org/pdf/2407.13717v2",
      "published_date": "2024-07-18 17:16:35 UTC",
      "updated_date": "2024-08-16 17:43:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:50:50.463846"
    },
    {
      "arxiv_id": "2407.13711v2",
      "title": "FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning",
      "title_zh": "FSP-Laplace：贝叶斯深度学习中函数空间先验的 Laplace 逼近",
      "authors": [
        "Tristan Cinquin",
        "Marvin Pförtner",
        "Vincent Fortuin",
        "Philipp Hennig",
        "Robert Bamler"
      ],
      "abstract": "Laplace approximations are popular techniques for endowing deep networks with\nepistemic uncertainty estimates as they can be applied without altering the\npredictions of the trained network, and they scale to large models and\ndatasets. While the choice of prior strongly affects the resulting posterior\ndistribution, computational tractability and lack of interpretability of the\nweight space typically limit the Laplace approximation to isotropic Gaussian\npriors, which are known to cause pathological behavior as depth increases. As a\nremedy, we directly place a prior on function space. More precisely, since\nLebesgue densities do not exist on infinite-dimensional function spaces, we\nrecast training as finding the so-called weak mode of the posterior measure\nunder a Gaussian process (GP) prior restricted to the space of functions\nrepresentable by the neural network. Through the GP prior, one can express\nstructured and interpretable inductive biases, such as regularity or\nperiodicity, directly in function space, while still exploiting the implicit\ninductive biases that allow deep networks to generalize. After model\nlinearization, the training objective induces a negative log-posterior density\nto which we apply a Laplace approximation, leveraging highly scalable methods\nfrom matrix-free linear algebra. Our method provides improved results where\nprior knowledge is abundant (as is the case in many scientific inference\ntasks). At the same time, it stays competitive for black-box supervised\nlearning problems, where neural networks typically excel.",
      "tldr_zh": "该论文提出 FSP-Laplace 方法，通过在 function space 上应用 priors 来改进 Bayesian Deep Learning 中的 Laplace approximation，从而解决传统 isotropic Gaussian priors 在深度网络中导致的病态问题。具体而言，该方法将训练视为在 Gaussian process (GP) prior 下寻找 weak mode 的后验分布，允许直接表达结构化的 inductive biases，如 regularity 或 periodicity，同时保留神经网络的隐式泛化能力。实验结果显示，该方法在 prior knowledge 丰富的科学推理任务中表现优异，提供更好的 epistemic uncertainty 估计，并在黑箱监督学习问题上保持竞争力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13711v2",
      "published_date": "2024-07-18 17:08:58 UTC",
      "updated_date": "2024-10-31 09:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:52:20.489986"
    },
    {
      "arxiv_id": "2407.21037v1",
      "title": "An Application of Large Language Models to Coding Negotiation Transcripts",
      "title_zh": "翻译失败",
      "authors": [
        "Ray Friedman",
        "Jaewoo Cho",
        "Jeanne Brett",
        "Xuhui Zhan",
        "Ningyu Han",
        "Sriram Kannan",
        "Yingxiang Ma",
        "Jesse Spencer-Smith",
        "Elisabeth Jäckel",
        "Alfred Zerres",
        "Madison Hooper",
        "Katie Babbit",
        "Manish Acharya",
        "Wendi Adair",
        "Soroush Aslani",
        "Tayfun Aykaç",
        "Chris Bauman",
        "Rebecca Bennett",
        "Garrett Brady",
        "Peggy Briggs",
        "Cheryl Dowie",
        "Chase Eck",
        "Igmar Geiger",
        "Frank Jacob",
        "Molly Kern",
        "Sujin Lee",
        "Leigh Anne Liu",
        "Wu Liu",
        "Jeffrey Loewenstein",
        "Anne Lytle",
        "Li Ma",
        "Michel Mann",
        "Alexandra Mislin",
        "Tyree Mitchell",
        "Hannah Martensen née Nagler",
        "Amit Nandkeolyar",
        "Mara Olekalns",
        "Elena Paliakova",
        "Jennifer Parlamis",
        "Jason Pierce",
        "Nancy Pierce",
        "Robin Pinkley",
        "Nathalie Prime",
        "Jimena Ramirez-Marin",
        "Kevin Rockmann",
        "William Ross",
        "Zhaleh Semnani-Azad",
        "Juliana Schroeder",
        "Philip Smith",
        "Elena Stimmer",
        "Roderick Swaab",
        "Leigh Thompson",
        "Cathy Tinsley",
        "Ece Tuncel",
        "Laurie Weingart",
        "Robert Wilken",
        "JingJing Yao",
        "Zhi-Xue Zhang"
      ],
      "abstract": "In recent years, Large Language Models (LLM) have demonstrated impressive\ncapabilities in the field of natural language processing (NLP). This paper\nexplores the application of LLMs in negotiation transcript analysis by the\nVanderbilt AI Negotiation Lab. Starting in September 2022, we applied multiple\nstrategies using LLMs from zero shot learning to fine tuning models to\nin-context learning). The final strategy we developed is explained, along with\nhow to access and use the model. This study provides a sense of both the\nopportunities and roadblocks for the implementation of LLMs in real life\napplications and offers a model for how LLMs can be applied to coding in other\nfields.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在谈判转录编码中的应用，由 Vanderbilt AI Negotiation Lab 进行。研究从 2022 年 9 月开始，测试了多种策略，包括零样本学习 (zero shot learning)、模型微调 (fine tuning) 和 in-context learning，最终开发了一种可访问的最终策略。论文总结了 LLMs 在实际应用中的机会和障碍，并为其他领域应用 LLMs 进行编码任务提供了参考模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21037v1",
      "published_date": "2024-07-18 17:05:59 UTC",
      "updated_date": "2024-07-18 17:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:52:36.145072"
    },
    {
      "arxiv_id": "2407.13700v1",
      "title": "Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift",
      "title_zh": "跨任务攻击：基于注意力转移的自监督生成框架",
      "authors": [
        "Qingyuan Zeng",
        "Yunpeng Gong",
        "Min Jiang"
      ],
      "abstract": "Studying adversarial attacks on artificial intelligence (AI) systems helps\ndiscover model shortcomings, enabling the construction of a more robust system.\nMost existing adversarial attack methods only concentrate on single-task\nsingle-model or single-task cross-model scenarios, overlooking the multi-task\ncharacteristic of artificial intelligence systems. As a result, most of the\nexisting attacks do not pose a practical threat to a comprehensive and\ncollaborative AI system. However, implementing cross-task attacks is highly\ndemanding and challenging due to the difficulty in obtaining the real labels of\ndifferent tasks for the same picture and harmonizing the loss functions across\ndifferent tasks. To address this issue, we propose a self-supervised Cross-Task\nAttack framework (CTA), which utilizes co-attention and anti-attention maps to\ngenerate cross-task adversarial perturbation. Specifically, the co-attention\nmap reflects the area to which different visual task models pay attention,\nwhile the anti-attention map reflects the area that different visual task\nmodels neglect. CTA generates cross-task perturbations by shifting the\nattention area of samples away from the co-attention map and closer to the\nanti-attention map. We conduct extensive experiments on multiple vision tasks\nand the experimental results confirm the effectiveness of the proposed design\nfor adversarial attacks.",
      "tldr_zh": "本论文提出了一种自监督的 Cross-Task Attack (CTA) 框架，针对 AI 系统多任务特性的对抗攻击问题，解决现有方法忽略跨任务场景的局限性。CTA 通过 co-attention map（不同视觉任务模型关注的区域）和 anti-attention map（模型忽略的区域）来生成对抗扰动，实现样本注意力从 co-attention map 向 anti-attention map 的转移，从而在不需真实标签的情况下实现跨任务攻击。实验结果显示，该框架在多个视觉任务上表现出色，有效揭示了 AI 系统的漏洞并有助于构建更稳健的模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Has been accepted by IJCNN2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13700v1",
      "published_date": "2024-07-18 17:01:10 UTC",
      "updated_date": "2024-07-18 17:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:52:45.886569"
    },
    {
      "arxiv_id": "2407.13699v2",
      "title": "A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice",
      "title_zh": "推荐系统的全面综述：从理论到实践的过渡",
      "authors": [
        "Shaina Raza",
        "Mizanur Rahman",
        "Safiullah Kamawal",
        "Armin Toroghi",
        "Ananya Raval",
        "Farshad Navah",
        "Amirmohammad Kazemeini"
      ],
      "abstract": "Recommender Systems (RS) play an integral role in enhancing user experiences\nby providing personalized item suggestions. This survey reviews the progress in\nRS inclusively from 2017 to 2024, effectively connecting theoretical advances\nwith practical applications. We explore the development from traditional RS\ntechniques like content-based and collaborative filtering to advanced methods\ninvolving deep learning, graph-based models, reinforcement learning, and large\nlanguage models. We also discuss specialized systems such as context-aware,\nreview-based, and fairness-aware RS. The primary goal of this survey is to\nbridge theory with practice. It addresses challenges across various sectors,\nincluding e-commerce, healthcare, and finance, emphasizing the need for\nscalable, real-time, and trustworthy solutions. Through this survey, we promote\nstronger partnerships between academic research and industry practices. The\ninsights offered by this survey aim to guide industry professionals in\noptimizing RS deployment and to inspire future research directions, especially\nin addressing emerging technological and societal trends\\footnote. The survey\nresources are available in the public GitHub repository\nhttps://github.com/VectorInstitute/Recommender-Systems-Survey. (Recommender\nsystems, large language models, chatgpt, responsible AI)",
      "tldr_zh": "这篇综述全面回顾了Recommender Systems从2017年到2024年的进展，旨在桥接理论与实践，帮助实现个性化推荐。论文探讨了从传统方法如content-based和collaborative filtering到先进技术的演变，包括deep learning、graph-based models、reinforcement learning和large language models，以及context-aware、review-based和fairness-aware系统。重点强调了在e-commerce、healthcare和finance等领域的实际挑战，提出需要开发scalable、real-time和trustworthy解决方案，以促进学术研究与行业应用的合作，并为未来优化和研究方向提供指导。资源可在GitHub仓库https://github.com/VectorInstitute/Recommender-Systems-Survey获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "we quarterly update of this literature",
      "pdf_url": "http://arxiv.org/pdf/2407.13699v2",
      "published_date": "2024-07-18 17:00:53 UTC",
      "updated_date": "2025-02-23 02:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:53:08.233920"
    },
    {
      "arxiv_id": "2407.13689v1",
      "title": "Shaded Route Planning Using Active Segmentation and Identification of Satellite Images",
      "title_zh": "基于主动分割和卫星图像识别的遮阴路线规划",
      "authors": [
        "Longchao Da",
        "Rohan Chhibba",
        "Rushabh Jaiswal",
        "Ariane Middel",
        "Hua Wei"
      ],
      "abstract": "Heatwaves pose significant health risks, particularly due to prolonged\nexposure to high summer temperatures. Vulnerable groups, especially pedestrians\nand cyclists on sun-exposed sidewalks, motivate the development of a route\nplanning method that incorporates somatosensory temperature effects through\nshade ratio consideration. This paper is the first to introduce a pipeline that\nutilizes segmentation foundation models to extract shaded areas from\nhigh-resolution satellite images. These areas are then integrated into a\nmulti-layered road map, enabling users to customize routes based on a balance\nbetween distance and shade exposure, thereby enhancing comfort and health\nduring outdoor activities. Specifically, we construct a graph-based\nrepresentation of the road map, where links indicate connectivity and are\nupdated with shade ratio data for dynamic route planning. This system is\nalready implemented online, with a video demonstration, and will be\nspecifically adapted to assist travelers during the 2024 Olympic Games in\nParis.",
      "tldr_zh": "该论文针对热浪带来的健康风险，提出了一种考虑阴凉比例的路线规划方法，以帮助行人和骑行者在户外活动中平衡距离和shade exposure，提升舒适度和健康。研究首次引入一个管道，利用segmentation foundation models从高分辨率卫星图像中提取阴凉区域，并将这些区域整合到一个多层道路地图中。接着，通过构建graph-based representation更新道路链接的shade ratio数据，实现动态路线规划。该系统已在线部署，并计划为2024年巴黎奥运会提供适应性支持。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV",
        "68T45, 68U35",
        "I.2.10; I.4.8"
      ],
      "primary_category": "cs.CY",
      "comment": "Paper accepted to CIKM24 demo track",
      "pdf_url": "http://arxiv.org/pdf/2407.13689v1",
      "published_date": "2024-07-18 16:57:11 UTC",
      "updated_date": "2024-07-18 16:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:53:18.376200"
    },
    {
      "arxiv_id": "2407.13680v1",
      "title": "HPix: Generating Vector Maps from Satellite Images",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Taparia",
        "Keshab Nath"
      ],
      "abstract": "Vector maps find widespread utility across diverse domains due to their\ncapacity to not only store but also represent discrete data boundaries such as\nbuilding footprints, disaster impact analysis, digitization, urban planning,\nlocation points, transport links, and more. Although extensive research exists\non identifying building footprints and road types from satellite imagery, the\ngeneration of vector maps from such imagery remains an area with limited\nexploration. Furthermore, conventional map generation techniques rely on\nlabor-intensive manual feature extraction or rule-based approaches, which\nimpose inherent limitations. To surmount these limitations, we propose a novel\nmethod called HPix, which utilizes modified Generative Adversarial Networks\n(GANs) to generate vector tile map from satellite images. HPix incorporates two\nhierarchical frameworks: one operating at the global level and the other at the\nlocal level, resulting in a comprehensive model. Through empirical evaluations,\nour proposed approach showcases its effectiveness in producing highly accurate\nand visually captivating vector tile maps derived from satellite images. We\nfurther extend our study's application to include mapping of road intersections\nand building footprints cluster based on their area.",
      "tldr_zh": "本论文提出HPix方法，使用修改后的Generative Adversarial Networks (GANs)从卫星图像生成矢量地图，以解决传统手动特征提取或规则-based方法的局限性。HPix采用两个层次框架——全局和本地级别——来处理离散数据边界，如建筑轮廓和道路类型，确保生成的地图准确且视觉吸引人。实验评估证明，该方法在矢量地图生成上表现出色，并扩展应用到道路交叉口和建筑轮廓聚类的映射中。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13680v1",
      "published_date": "2024-07-18 16:54:02 UTC",
      "updated_date": "2024-07-18 16:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:53:22.408607"
    },
    {
      "arxiv_id": "2407.13677v1",
      "title": "PASTA: Controllable Part-Aware Shape Generation with Autoregressive Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Songlin Li",
        "Despoina Paschalidou",
        "Leonidas Guibas"
      ],
      "abstract": "The increased demand for tools that automate the 3D content creation process\nled to tremendous progress in deep generative models that can generate diverse\n3D objects of high fidelity. In this paper, we present PASTA, an autoregressive\ntransformer architecture for generating high quality 3D shapes. PASTA comprises\ntwo main components: An autoregressive transformer that generates objects as a\nsequence of cuboidal primitives and a blending network, implemented with a\ntransformer decoder that composes the sequences of cuboids and synthesizes high\nquality meshes for each object. Our model is trained in two stages: First we\ntrain our autoregressive generative model using only annotated cuboidal parts\nas supervision and next, we train our blending network using explicit 3D\nsupervision, in the form of watertight meshes. Evaluations on various ShapeNet\nobjects showcase the ability of our model to perform shape generation from\ndiverse inputs \\eg from scratch, from a partial object, from text and images,\nas well size-guided generation, by explicitly conditioning on a bounding box\nthat defines the object's boundaries. Moreover, as our model considers the\nunderlying part-based structure of a 3D object, we are able to select a\nspecific part and produce shapes with meaningful variations of this part. As\nevidenced by our experiments, our model generates 3D shapes that are both more\nrealistic and diverse than existing part-based and non part-based methods,\nwhile at the same time is simpler to implement and train.",
      "tldr_zh": "本文提出 PASTA，一种基于 Autoregressive Transformers 的架构，用于可控的基于部分结构的 3D 形状生成。PASTA 包括一个自回归 Transformer 生成立方体原语序列，以及一个混合网络（blending network）来组合这些序列并合成高质量网格，训练过程分两阶段：先使用标注的立方体部分监督，然后用 watertight meshes 进行显式 3D 监督。实验在 ShapeNet 对象上显示，该模型能从零开始、部分对象、文本或图像生成形状，并支持大小引导生成，其生成的形状比现有基于部分和非基于部分方法更真实、多样，且实现更简单。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13677v1",
      "published_date": "2024-07-18 16:52:45 UTC",
      "updated_date": "2024-07-18 16:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:53:41.014915"
    },
    {
      "arxiv_id": "2407.14559v1",
      "title": "Predicting Star Scientists in the Field of Artificial Intelligence: A Machine Learning Approach",
      "title_zh": "预测人工智能领域明星科学家：一种机器学习方法",
      "authors": [
        "Koosha Shirouyeh",
        "Andrea Schiffauerova",
        "Ashkan Ebadi"
      ],
      "abstract": "Star scientists are highly influential researchers who have made significant\ncontributions to their field, gained widespread recognition, and often\nattracted substantial research funding. They are critical for the advancement\nof science and innovation, and they have a significant influence on the\ntransfer of knowledge and technology to industry. Identifying potential star\nscientists before their performance becomes outstanding is important for\nrecruitment, collaboration, networking, or research funding decisions. Using\nmachine learning techniques, this study proposes a model to predict star\nscientists in the field of artificial intelligence while highlighting features\nrelated to their success. Our results confirm that rising stars follow\ndifferent patterns compared to their non-rising stars counterparts in almost\nall the early-career features. We also found that certain features such as\ngender and ethnic diversity play important roles in scientific collaboration\nand that they can significantly impact an author's career development and\nsuccess. The most important features in predicting star scientists in the field\nof artificial intelligence were the number of articles, group discipline\ndiversity, and weighted degree centrality. The proposed approach offers\nvaluable insights for researchers, practitioners, and funding agencies\ninterested in identifying and supporting talented researchers.",
      "tldr_zh": "本研究使用机器学习方法，提出一个模型来预测人工智能领域的 star scientists，通过分析早期职业特征如文章数量、组学科多样性和加权度中心性。结果显示，star scientists 在这些特征上与非 star scientists 存在显著差异，且性别和民族多样性对科学合作和职业发展有重要影响。该方法为招聘、合作和研究资助决策提供宝贵洞见，帮助识别和支持潜在人才。",
      "categories": [
        "cs.OH",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.OH",
      "comment": "21 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.14559v1",
      "published_date": "2024-07-18 16:50:18 UTC",
      "updated_date": "2024-07-18 16:50:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:53:44.549157"
    },
    {
      "arxiv_id": "2407.13647v2",
      "title": "Weak-to-Strong Reasoning",
      "title_zh": "弱到强推理",
      "authors": [
        "Yuqing Yang",
        "Yan Ma",
        "Pengfei Liu"
      ],
      "abstract": "When large language models (LLMs) exceed human-level capabilities, it becomes\nincreasingly challenging to provide full-scale and accurate supervision for\nthese models. Weak-to-strong learning, which leverages a less capable model to\nunlock the latent abilities of a stronger model, proves valuable in this\ncontext. Yet, the efficacy of this approach for complex reasoning tasks is\nstill untested. Furthermore, tackling reasoning tasks under the weak-to-strong\nsetting currently lacks efficient methods to avoid blindly imitating the weak\nsupervisor including its errors. In this paper, we introduce a progressive\nlearning framework that enables the strong model to autonomously refine its\ntraining data, without requiring input from either a more advanced model or\nhuman-annotated data. This framework begins with supervised fine-tuning on a\nselective small but high-quality dataset, followed by preference optimization\non contrastive samples identified by the strong model itself. Extensive\nexperiments on the GSM8K and MATH datasets demonstrate that our method\nsignificantly enhances the reasoning capabilities of Llama2-70b using three\nseparate weak models. This method is further validated in a forward-looking\nexperimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b\non the highly challenging OlympicArena dataset. This work paves the way for a\nmore scalable and sophisticated strategy to enhance AI reasoning powers. All\nrelevant code and resources are available in\n\\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.",
      "tldr_zh": "本研究探讨了当大型语言模型（LLMs）超过人类能力时，如何通过弱到强学习（weak-to-strong learning）提升其推理性能，而无需更先进模型或人工标注。作者提出一个渐进式学习框架，让强模型自主改进训练数据，包括先在小而高质量的数据集上进行监督微调（supervised fine-tuning），然后通过强模型自身识别的对比样本进行偏好优化（preference optimization）。实验结果显示，该方法显著提升了 Llama2-70b 在 GSM8K 和 MATH 数据集上的推理能力，使用三个弱模型作为监督；在 OlympicArena 数据集的测试中，Llama3-8b-instruct 成功指导 Llama3-70b，证明了框架的有效性。该工作为可扩展的 AI 推理策略铺平道路，并提供了相关代码资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13647v2",
      "published_date": "2024-07-18 16:25:17 UTC",
      "updated_date": "2024-10-01 05:28:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:53:57.383059"
    },
    {
      "arxiv_id": "2407.13638v1",
      "title": "A Comparative Study on Automatic Coding of Medical Letters with Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Jamie Glen",
        "Lifeng Han",
        "Paul Rayson",
        "Goran Nenadic"
      ],
      "abstract": "This study aims to explore the implementation of Natural Language Processing\n(NLP) and machine learning (ML) techniques to automate the coding of medical\nletters with visualised explainability and light-weighted local computer\nsettings. Currently in clinical settings, coding is a manual process that\ninvolves assigning codes to each condition, procedure, and medication in a\npatient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There\nare preliminary research on automatic coding in this field using\nstate-of-the-art ML models; however, due to the complexity and size of the\nmodels, the real-world deployment is not achieved. To further facilitate the\npossibility of automatic coding practice, we explore some solutions in a local\ncomputer setting; in addition, we explore the function of explainability for\ntransparency of AI models. We used the publicly available MIMIC-III database\nand the HAN/HLAN network models for ICD code prediction purposes. We also\nexperimented with the mapping between ICD and SNOMED CT knowledge bases. In our\nexperiments, the models provided useful information for 97.98\\% of codes. The\nresult of this investigation can shed some light on implementing automatic\nclinical coding in practice, such as in hospital settings, on the local\ncomputers used by clinicians , project page\n\\url{https://github.com/Glenj01/Medical-Coding}.",
      "tldr_zh": "这篇论文比较了使用 Natural Language Processing (NLP) 和 machine learning (ML) 技术自动编码医疗信函的方法，强调可视化可解释性和轻量级本地计算机设置，以解决手动编码的低效问题。研究利用 MIMIC-III 数据库和 HAN/HLAN 网络模型进行 ICD 代码预测，并实验了 ICD 与 SNOMED CT 知识库的映射。结果显示，模型为 97.98% 的代码提供了有用信息，这有助于在医院等实际场景中实现透明且可部署的自动临床编码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "working paper",
      "pdf_url": "http://arxiv.org/pdf/2407.13638v1",
      "published_date": "2024-07-18 16:12:47 UTC",
      "updated_date": "2024-07-18 16:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:54:09.035341"
    },
    {
      "arxiv_id": "2407.13813v1",
      "title": "A review of handcrafted and deep radiomics in neurological diseases: transitioning from oncology to clinical neuroimaging",
      "title_zh": "翻译失败",
      "authors": [
        "Elizaveta Lavrova",
        "Henry C. Woodruff",
        "Hamza Khan",
        "Eric Salmon",
        "Philippe Lambin",
        "Christophe Phillips"
      ],
      "abstract": "Medical imaging technologies have undergone extensive development, enabling\nnon-invasive visualization of clinical information. The traditional review of\nmedical images by clinicians remains subjective, time-consuming, and prone to\nhuman error. With the recent availability of medical imaging data,\nquantification have become important goals in the field. Radiomics, a\nmethodology aimed at extracting quantitative information from imaging data, has\nemerged as a promising approach to uncover hidden biological information and\nsupport decision-making in clinical practice. This paper presents a review of\nthe radiomic pipeline from the clinical neuroimaging perspective, providing a\ndetailed overview of each step with practical advice. It discusses the\napplication of handcrafted and deep radiomics in neuroimaging, stratified by\nneurological diagnosis. Although radiomics shows great potential for increasing\ndiagnostic precision and improving treatment quality in neurology, several\nlimitations hinder its clinical implementation. Addressing these challenges\nrequires collaborative efforts, advancements in image harmonization methods,\nand the establishment of reproducible and standardized pipelines with\ntransparent reporting. By overcoming these obstacles, radiomics can\nsignificantly impact clinical neurology and enhance patient care.",
      "tldr_zh": "这篇论文回顾了handcrafted radiomics和deep radiomics在neurological diseases中的应用，探讨从oncology到clinical neuroimaging的过渡。作者详细概述了radiomic管道的每个步骤，包括数据提取、特征量化及实用建议，并总结了这些方法在不同神经诊断中的潜力，如提高诊断精度和治疗质量。尽管radiomics显示出显著优势，但临床实施面临图像协调、标准化和可重复性等挑战，未来需通过协作努力来克服这些障碍，以增强临床神经学和患者护理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13813v1",
      "published_date": "2024-07-18 16:12:07 UTC",
      "updated_date": "2024-07-18 16:12:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:54:21.533792"
    },
    {
      "arxiv_id": "2407.13623v3",
      "title": "Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies",
      "title_zh": "词汇表的缩",
      "authors": [
        "Chaofan Tao",
        "Qian Liu",
        "Longxu Dou",
        "Niklas Muennighoff",
        "Zhongwei Wan",
        "Ping Luo",
        "Min Lin",
        "Ngai Wong"
      ],
      "abstract": "Research on scaling large language models (LLMs) has primarily focused on\nmodel parameters and training data size, overlooking the role of vocabulary\nsize. We investigate how vocabulary size impacts LLM scaling laws by training\nmodels ranging from 33M to 3B parameters on up to 500B characters with various\nvocabulary configurations. We propose three complementary approaches for\npredicting the compute-optimal vocabulary size: IsoFLOPs analysis, derivative\nestimation, and parametric fit of the loss function. Our approaches converge on\nthe conclusion that the optimal vocabulary size depends on the compute budget,\nwith larger models requiring larger vocabularies. Most LLMs, however, use\ninsufficient vocabulary sizes. For example, we predict that the optimal\nvocabulary size of Llama2-70B should have been at least 216K, 7 times larger\nthan its vocabulary of 32K. We validate our predictions empirically by training\nmodels with 3B parameters across different FLOPs budgets. Adopting our\npredicted optimal vocabulary size consistently improves downstream performance\nover commonly used vocabulary sizes. By increasing the vocabulary size from the\nconventional 32K to 43K, we improve performance on ARC-Challenge from 29.1 to\n32.0 with the same 2.3e21 FLOPs. Our work highlights the importance of jointly\nconsidering tokenization and model scaling for efficient pre-training. The code\nand demo are available at https://github.com/sail-sg/scaling-with-vocab and\nhttps://hf.co/spaces/sail/scaling-with-vocab-demo.",
      "tldr_zh": "该研究探讨了词汇表大小对大型语言模型(LLMs)缩放定律的影响，强调了以往主要关注模型参数和训练数据规模的不足。作者通过训练33M至3B参数的模型，使用高达500B字符的数据和不同词汇表配置，提出了三种方法（IsoFLOPs分析、衍生估计和损失函数参数拟合）来预测计算最优词汇表大小，结果显示更大模型需要更大词汇表，例如Llama2-70B的最优词汇表应至少为216K，是其32K的7倍。实验验证表明，采用预测的最优词汇表（如从32K增加到43K）可显著提升下游性能，例如在相同2.3e21 FLOPs下，ARC-Challenge分数从29.1提高到32.0。该工作突出了在LLMs预训练中联合考虑分词和模型缩放的重要性，以实现更高效的训练。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13623v3",
      "published_date": "2024-07-18 15:58:54 UTC",
      "updated_date": "2024-11-01 02:41:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:54:34.501216"
    },
    {
      "arxiv_id": "2407.13622v1",
      "title": "Misspecified $Q$-Learning with Sparse Linear Function Approximation: Tight Bounds on Approximation Error",
      "title_zh": "翻译失败",
      "authors": [
        "Ally Yalei Du",
        "Lin F. Yang",
        "Ruosong Wang"
      ],
      "abstract": "The recent work by Dong & Yang (2023) showed for misspecified sparse linear\nbandits, one can obtain an $O\\left(\\epsilon\\right)$-optimal policy using a\npolynomial number of samples when the sparsity is a constant, where $\\epsilon$\nis the misspecification error. This result is in sharp contrast to misspecified\nlinear bandits without sparsity, which require an exponential number of samples\nto get the same guarantee. In order to study whether the analog result is\npossible in the reinforcement learning setting, we consider the following\nproblem: assuming the optimal $Q$-function is a $d$-dimensional linear function\nwith sparsity $k$ and misspecification error $\\epsilon$, whether we can obtain\nan $O\\left(\\epsilon\\right)$-optimal policy using number of samples polynomially\nin the feature dimension $d$. We first demonstrate why the standard approach\nbased on Bellman backup or the existing optimistic value function elimination\napproach such as OLIVE (Jiang et al., 2017) achieves suboptimal guarantees for\nthis problem. We then design a novel elimination-based algorithm to show one\ncan obtain an $O\\left(H\\epsilon\\right)$-optimal policy with sample complexity\npolynomially in the feature dimension $d$ and planning horizon $H$. Lastly, we\ncomplement our upper bound with an $\\widetilde{\\Omega}\\left(H\\epsilon\\right)$\nsuboptimality lower bound, giving a complete picture of this problem.",
      "tldr_zh": "本论文探讨了在misspecified $Q$-Learning设置下，使用sparse linear function approximation的强化学习问题，假设最优$Q$-function具有sparsity $k$和misspecification error $\\epsilon$。标准方法如Bellman backup和OLIVE算法无法提供最优保证，因此作者设计了一种新型elimination-based算法，能够在多项式样本复杂度（相对于特征维度$d$和规划地平线$H$）下获得$O(H\\epsilon)$最优策略。论文还提供了$\\widetilde{\\Omega}(H\\epsilon)$的suboptimality下界，证明了这些边界的紧凑性，从而为misspecified sparse linear reinforcement learning提供了完整的理论分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.13622v1",
      "published_date": "2024-07-18 15:58:04 UTC",
      "updated_date": "2024-07-18 15:58:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:54:48.217289"
    },
    {
      "arxiv_id": "2408.01431v2",
      "title": "Building an Ethical and Trustworthy Biomedical AI Ecosystem for the Translational and Clinical Integration of Foundational Models",
      "title_zh": "构建一个道德且可信的生物医学 AI 生态系统，用于基础模型的转化和临床",
      "authors": [
        "Simha Sankar Baradwaj",
        "Destiny Gilliland",
        "Jack Rincon",
        "Henning Hermjakob",
        "Yu Yan",
        "Irsyad Adam",
        "Gwyneth Lemaster",
        "Dean Wang",
        "Karol Watson",
        "Alex Bui",
        "Wei Wang",
        "Peipei Ping"
      ],
      "abstract": "Foundational Models (FMs) are gaining increasing attention in the biomedical\nAI ecosystem due to their ability to represent and contextualize multimodal\nbiomedical data. These capabilities make FMs a valuable tool for a variety of\ntasks, including biomedical reasoning, hypothesis generation, and interpreting\ncomplex imaging data. In this review paper, we address the unique challenges\nassociated with establishing an ethical and trustworthy biomedical AI\necosystem, with a particular focus on the development of FMs and their\ndownstream applications. We explore strategies that can be implemented\nthroughout the biomedical AI pipeline to effectively tackle these challenges,\nensuring that these FMs are translated responsibly into clinical and\ntranslational settings. Additionally, we emphasize the importance of key\nstewardship and co-design principles that not only ensure robust regulation but\nalso guarantee that the interests of all stakeholders, especially those\ninvolved in or affected by these clinical and translational applications are\nadequately represented. We aim to empower the biomedical AI community to\nharness these models responsibly and effectively. As we navigate this exciting\nfrontier, our collective commitment to ethical stewardship, co-design, and\nresponsible translation will be instrumental in ensuring that the evolution of\nFMs truly enhances patient care and medical decision making, ultimately leading\nto a more equitable and trustworthy biomedical AI ecosystem.",
      "tldr_zh": "这篇评论论文探讨了基础模型 (Foundational Models, FMs) 在生物医学 AI 生态系统中的应用，强调其在处理多模态数据、生物医学推理和图像解释方面的潜力，同时指出了建立伦理和可信赖生态系统的独特挑战。论文提出了一系列策略，包括在生物医学 AI 管道中实施负责任的开发和应用方法，以及采用关键的管理和共同设计原则，以确保 FMs 的临床和翻译整合代表所有利益相关者的利益。最终，该研究旨在指导生物医学 AI 社区负责任地利用 FMs，提升患者护理和医疗决策，推动一个更公平、可信赖的生态系统。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.01431v2",
      "published_date": "2024-07-18 15:57:58 UTC",
      "updated_date": "2024-08-14 02:28:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:54:57.956807"
    },
    {
      "arxiv_id": "2407.13621v2",
      "title": "Differential Privacy Mechanisms in Neural Tangent Kernel Regression",
      "title_zh": "差分隐私机制在神经切向核回归中",
      "authors": [
        "Jiuxiang Gu",
        "Yingyu Liang",
        "Zhizhou Sha",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "Training data privacy is a fundamental problem in modern Artificial\nIntelligence (AI) applications, such as face recognition, recommendation\nsystems, language generation, and many others, as it may contain sensitive user\ninformation related to legal issues. To fundamentally understand how privacy\nmechanisms work in AI applications, we study differential privacy (DP) in the\nNeural Tangent Kernel (NTK) regression setting, where DP is one of the most\npowerful tools for measuring privacy under statistical learning, and NTK is one\nof the most popular analysis frameworks for studying the learning mechanisms of\ndeep neural networks. In our work, we can show provable guarantees for both\ndifferential privacy and test accuracy of our NTK regression. Furthermore, we\nconduct experiments on the basic image classification dataset CIFAR10 to\ndemonstrate that NTK regression can preserve good accuracy under a modest\nprivacy budget, supporting the validity of our analysis. To our knowledge, this\nis the first work to provide a DP guarantee for NTK regression.",
      "tldr_zh": "本研究探讨了在 Neural Tangent Kernel (NTK) 回归中应用 Differential Privacy (DP) 机制，以保护 AI 应用（如面部识别和推荐系统）中敏感训练数据的隐私。研究通过理论分析提供了 NTK 回归的 DP 保证，同时确保了测试准确性，并在 CIFAR10 图像分类数据集上进行实验，证明了在适度隐私预算下模型能保持良好性能。作为首个为 NTK 回归提供 DP 保证的工作，此研究为深度神经网络的学习机制和隐私保护提供了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.13621v2",
      "published_date": "2024-07-18 15:57:55 UTC",
      "updated_date": "2024-11-02 05:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:55:10.046226"
    },
    {
      "arxiv_id": "2407.13609v1",
      "title": "Training-free Composite Scene Generation for Layout-to-Image Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Liu",
        "Tao Huang",
        "Chang Xu"
      ],
      "abstract": "Recent breakthroughs in text-to-image diffusion models have significantly\nadvanced the generation of high-fidelity, photo-realistic images from textual\ndescriptions. Yet, these models often struggle with interpreting spatial\narrangements from text, hindering their ability to produce images with precise\nspatial configurations. To bridge this gap, layout-to-image generation has\nemerged as a promising direction. However, training-based approaches are\nlimited by the need for extensively annotated datasets, leading to high data\nacquisition costs and a constrained conceptual scope. Conversely, training-free\nmethods face challenges in accurately locating and generating semantically\nsimilar objects within complex compositions. This paper introduces a novel\ntraining-free approach designed to overcome adversarial semantic intersections\nduring the diffusion conditioning phase. By refining intra-token loss with\nselective sampling and enhancing the diffusion process with attention\nredistribution, we propose two innovative constraints: 1) an inter-token\nconstraint that resolves token conflicts to ensure accurate concept synthesis;\nand 2) a self-attention constraint that improves pixel-to-pixel relationships.\nOur evaluations confirm the effectiveness of leveraging layout information for\nguiding the diffusion process, generating content-rich images with enhanced\nfidelity and complexity. Code is available at\nhttps://github.com/Papple-F/csg.git.",
      "tldr_zh": "该论文提出了一种无需训练的布局到图像合成方法，旨在解决文本到图像扩散模型在处理空间安排时的局限性问题，特别是语义交集和对象定位的挑战。通过改进 intra-token loss 的选择性采样和注意力重分布，该方法引入了 inter-token constraint 和 self-attention constraint，以确保概念合成准确并优化像素间关系。实验结果表明，该方法能生成保真度更高、内容更丰富的复合场景图像，证明了利用布局信息指导扩散过程的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13609v1",
      "published_date": "2024-07-18 15:48:07 UTC",
      "updated_date": "2024-07-18 15:48:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:55:22.161048"
    },
    {
      "arxiv_id": "2407.13597v1",
      "title": "PLANTS: A Novel Problem and Dataset for Summarization of Planning-Like (PL) Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Vishal Pallagani",
        "Biplav Srivastava",
        "Nitin Gupta"
      ],
      "abstract": "Text summarization is a well-studied problem that deals with deriving\ninsights from unstructured text consumed by humans, and it has found extensive\nbusiness applications. However, many real-life tasks involve generating a\nseries of actions to achieve specific goals, such as workflows, recipes,\ndialogs, and travel plans. We refer to them as planning-like (PL) tasks noting\nthat the main commonality they share is control flow information. which may be\npartially specified. Their structure presents an opportunity to create more\npractical summaries to help users make quick decisions. We investigate this\nobservation by introducing a novel plan summarization problem, presenting a\ndataset, and providing a baseline method for generating PL summaries. Using\nquantitative metrics and qualitative user studies to establish baselines, we\nevaluate the plan summaries from our method and large language models. We\nbelieve the novel problem and dataset can reinvigorate research in\nsummarization, which some consider as a solved problem.",
      "tldr_zh": "该论文引入了PLANTS，这是一个针对planning-like (PL) tasks（如工作流、食谱、对话和旅行计划）的全新摘要问题和数据集，这些任务共享部分指定的控制流信息，以帮助用户快速决策。作者提出了一种基线方法来生成PL摘要，并通过定量指标和定性用户研究评估了其性能，与大型语言模型进行了比较。实验结果显示，该方法为摘要研究提供了新视角，旨在重新激发这一领域的创新，因为摘要问题被一些人视为已解决。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13597v1",
      "published_date": "2024-07-18 15:36:02 UTC",
      "updated_date": "2024-07-18 15:36:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:55:34.056795"
    },
    {
      "arxiv_id": "2408.01430v2",
      "title": "SUSTechGAN: Image Generation for Object Detection in Adverse Conditions of Autonomous Driving",
      "title_zh": "SUSTechGAN：用于自动驾驶不利条件下的对象检测图像生成",
      "authors": [
        "Gongjin Lan",
        "Yang Peng",
        "Qi Hao",
        "Chengzhong Xu"
      ],
      "abstract": "Autonomous driving significantly benefits from data-driven deep neural\nnetworks. However, the data in autonomous driving typically fits the\nlong-tailed distribution, in which the critical driving data in adverse\nconditions is hard to collect. Although generative adversarial networks (GANs)\nhave been applied to augment data for autonomous driving, generating driving\nimages in adverse conditions is still challenging. In this work, we propose a\nnovel framework, SUSTechGAN, with customized dual attention modules,\nmulti-scale generators, and a novel loss function to generate driving images\nfor improving object detection of autonomous driving in adverse conditions. We\ntest the SUSTechGAN and the well-known GANs to generate driving images in\nadverse conditions of rain and night and apply the generated images to retrain\nobject detection networks. Specifically, we add generated images into the\ntraining datasets to retrain the well-known YOLOv5 and evaluate the improvement\nof the retrained YOLOv5 for object detection in adverse conditions. The\nexperimental results show that the generated driving images by our SUSTechGAN\nsignificantly improved the performance of retrained YOLOv5 in rain and night\nconditions, which outperforms the well-known GANs. The open-source code, video\ndescription and datasets are available on the page 1 to facilitate image\ngeneration development in autonomous driving under adverse conditions.",
      "tldr_zh": "本研究针对自动驾驶中数据长尾分布问题，提出SUSTechGAN框架，用于生成恶劣条件（如雨天和夜间）下的驾驶图像，以增强物体检测性能。SUSTechGAN 整合了自定义双注意力模块、多尺度生成器和新型损失函数，旨在高效生成高质量图像，并将其添加到训练数据集以重新训练YOLOv5模型。实验结果显示，SUSTechGAN生成的图像显著提升了YOLOv5在恶劣条件下的检测准确率，优于现有GANs，并提供了开源代码和数据集以促进相关研究发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01430v2",
      "published_date": "2024-07-18 15:32:25 UTC",
      "updated_date": "2024-12-21 07:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:55:44.472111"
    },
    {
      "arxiv_id": "2407.13578v2",
      "title": "How Reliable are LLMs as Knowledge Bases? Re-thinking Facutality and Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Danna Zheng",
        "Mirella Lapata",
        "Jeff Z. Pan"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly explored as knowledge bases\n(KBs), yet current evaluation methods focus too narrowly on knowledge\nretention, overlooking other crucial criteria for reliable performance. In this\nwork, we rethink the requirements for evaluating reliable LLM-as-KB usage and\nhighlight two essential factors: factuality, ensuring accurate responses to\nseen and unseen knowledge, and consistency, maintaining stable answers to\nquestions about the same knowledge. We introduce UnseenQA, a dataset designed\nto assess LLM performance on unseen knowledge, and propose new criteria and\nmetrics to quantify factuality and consistency, leading to a final reliability\nscore. Our experiments on 26 LLMs reveal several challenges regarding their use\nas KBs, underscoring the need for more principled and comprehensive evaluation.",
      "tldr_zh": "本研究重新审视大型语言模型（LLMs）作为知识库（KBs）的可靠性，强调评估不应仅限于知识保留，还需关注 factuality（事实准确性）和 consistency（一致性）。作者引入 UnseenQA 数据集来测试 LLMs 对未见知识的响应，并提出新标准和指标来量化 factuality 和 consistency，最终计算出一个整体可靠性分数。实验结果显示，在 26 个 LLMs 上存在显著挑战，突显了需要更全面、原则化的评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13578v2",
      "published_date": "2024-07-18 15:20:18 UTC",
      "updated_date": "2024-12-16 11:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:55:57.869866"
    },
    {
      "arxiv_id": "2407.13559v1",
      "title": "Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Gagan Bhatia",
        "El Moatez Billah Nagoudi",
        "Fakhraddin Alwajih",
        "Muhammad Abdul-Mageed"
      ],
      "abstract": "Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR)\npose unique challenges due to the cursive and context-sensitive nature of the\nArabic script. This study introduces Qalam, a novel foundation model designed\nfor Arabic OCR and HWR, built on a SwinV2 encoder and RoBERTa decoder\narchitecture. Our model significantly outperforms existing methods, achieving a\nWord Error Rate (WER) of just 0.80% in HWR tasks and 1.18% in OCR tasks. We\ntrain Qalam on a diverse dataset, including over 4.5 million images from Arabic\nmanuscripts and a synthetic dataset comprising 60k image-text pairs. Notably,\nQalam demonstrates exceptional handling of Arabic diacritics, a critical\nfeature in Arabic scripts. Furthermore, it shows a remarkable ability to\nprocess high-resolution inputs, addressing a common limitation in current OCR\nsystems. These advancements underscore Qalam's potential as a leading solution\nfor Arabic script recognition, offering a significant leap in accuracy and\nefficiency.",
      "tldr_zh": "本研究针对阿拉伯脚本的草书和上下文敏感特性，提出了Qalam，一种多模态大型语言模型(LLM)，用于阿拉伯光学字符识别(OCR)和手写识别(HWR)。Qalam采用SwinV2编码器和RoBERTa解码器架构，并在超过4.5百万图像的手稿数据集以及60k合成图像-文本对上进行训练。实验结果显示，该模型在HWR任务中实现Word Error Rate (WER)仅为0.80%，在OCR任务中为1.18%，显著优于现有方法。Qalam还出色处理阿拉伯diacritics并支持高分辨率输入，提供了一个高效准确的阿拉伯脚本识别解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13559v1",
      "published_date": "2024-07-18 14:31:09 UTC",
      "updated_date": "2024-07-18 14:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:56:10.569200"
    },
    {
      "arxiv_id": "2407.13535v3",
      "title": "Visuospatial navigation without distance, prediction, integration, or maps",
      "title_zh": "无需距离、预测、整合或地图的视觉空间导航",
      "authors": [
        "Patrick Govoni",
        "Pawel Romanczuk"
      ],
      "abstract": "Navigation is controlled by at least two partially dissociable, concurrently\ndeveloped systems in the brain. The cognitive map informs an organism of its\nlocation and bearing, updated by distance-based prediction and vestibular\nintegration. Response-based systems, on the other hand, directly evaluate\nmovement decisions from immediate percepts. Here we demonstrate the sufficiency\nof visual response-based decision-making in a classic open field navigation\ntask often assumed to require a cognitive map. Three distinct strategies emerge\nto robustly navigate to a hidden goal, each conferring contextual tradeoffs, as\nwell as aligning with behavior observed with rodents, insects, fish, and sperm\ncells. We propose reframing navigation from the bottom-up, without assuming\nonline access to computationally expensive top-down representations, to better\nexplain behavior under energetic or attentional constraints.",
      "tldr_zh": "该论文探讨了大脑中不依赖距离预测、前庭整合或认知地图（cognitive map）的视觉空间导航（visuospatial navigation），强调基于响应的决策系统（response-based systems）通过即时感知直接评估运动选择。研究在经典开放场导航任务中证明了三种不同的策略足以实现稳健的隐藏目标导航，每种策略具有上下文权衡，并与啮齿动物、昆虫、鱼类和精子细胞的行为相符。主要贡献在于建议从底部向上重新框架导航模型，以更好地解释能量或注意力约束下的行为，而非依赖计算密集的顶部向下表示。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13535v3",
      "published_date": "2024-07-18 14:07:44 UTC",
      "updated_date": "2025-02-13 14:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:56:23.396238"
    },
    {
      "arxiv_id": "2407.13524v1",
      "title": "Enhancing Source-Free Domain Adaptive Object Detection with Low-confidence Pseudo Label Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Ilhoon Yoon",
        "Hyeongjun Kwon",
        "Jin Kim",
        "Junyoung Park",
        "Hyunsung Jang",
        "Kwanghoon Sohn"
      ],
      "abstract": "Source-Free domain adaptive Object Detection (SFOD) is a promising strategy\nfor deploying trained detectors to new, unlabeled domains without accessing\nsource data, addressing significant concerns around data privacy and\nefficiency. Most SFOD methods leverage a Mean-Teacher (MT) self-training\nparadigm relying heavily on High-confidence Pseudo Labels (HPL). However, these\nHPL often overlook small instances that undergo significant appearance changes\nwith domain shifts. Additionally, HPL ignore instances with low confidence due\nto the scarcity of training samples, resulting in biased adaptation toward\nfamiliar instances from the source domain. To address this limitation, we\nintroduce the Low-confidence Pseudo Label Distillation (LPLD) loss within the\nMean-Teacher based SFOD framework. This novel approach is designed to leverage\nthe proposals from Region Proposal Network (RPN), which potentially encompasses\nhard-to-detect objects in unfamiliar domains. Initially, we extract HPL using a\nstandard pseudo-labeling technique and mine a set of Low-confidence Pseudo\nLabels (LPL) from proposals generated by RPN, leaving those that do not overlap\nsignificantly with HPL. These LPL are further refined by leveraging\nclass-relation information and reducing the effect of inherent noise for the\nLPLD loss calculation. Furthermore, we use feature distance to adaptively\nweight the LPLD loss to focus on LPL containing a larger foreground area. Our\nmethod outperforms previous SFOD methods on four cross-domain object detection\nbenchmarks. Extensive experiments demonstrate that our LPLD loss leads to\neffective adaptation by reducing false negatives and facilitating the use of\ndomain-invariant knowledge from the source model. Code is available at\nhttps://github.com/junia3/LPLD.",
      "tldr_zh": "该研究针对 Source-Free Domain Adaptive Object Detection (SFOD) 的局限性，提出了一种基于 Low-confidence Pseudo Label Distillation (LPLD) 损失的增强方法，以解决现有 Mean-Teacher (MT) 框架中 High-confidence Pseudo Labels (HPL) 忽略小实例和低置信度目标的问题。方法利用 Region Proposal Network (RPN) 生成的提案来挖掘和精炼 Low-confidence Pseudo Labels (LPL)，通过类关系信息减少噪声，并采用特征距离自适应加权损失，以更好地捕捉域移位下的难检测对象。实验结果显示，该方法在四个跨域对象检测基准上超越了先前的 SFOD 模型，显著减少了假阴性和提升了域不变知识的利用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13524v1",
      "published_date": "2024-07-18 13:58:42 UTC",
      "updated_date": "2024-07-18 13:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:56:37.444582"
    },
    {
      "arxiv_id": "2407.13505v2",
      "title": "Robots Can Multitask Too: Integrating a Memory Architecture and LLMs for Enhanced Cross-Task Robot Action Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan Ali",
        "Philipp Allgeuer",
        "Carlo Mazzola",
        "Giulia Belgiovine",
        "Burak Can Kaplan",
        "Lukáš Gajdošech",
        "Stefan Wermter"
      ],
      "abstract": "Large Language Models (LLMs) have been recently used in robot applications\nfor grounding LLM common-sense reasoning with the robot's perception and\nphysical abilities. In humanoid robots, memory also plays a critical role in\nfostering real-world embodiment and facilitating long-term interactive\ncapabilities, especially in multi-task setups where the robot must remember\nprevious task states, environment states, and executed actions. In this paper,\nwe address incorporating memory processes with LLMs for generating cross-task\nrobot actions, while the robot effectively switches between tasks. Our proposed\ndual-layered architecture features two LLMs, utilizing their complementary\nskills of reasoning and following instructions, combined with a memory model\ninspired by human cognition. Our results show a significant improvement in\nperformance over a baseline of five robotic tasks, demonstrating the potential\nof integrating memory with LLMs for combining the robot's action and perception\nfor adaptive task execution.",
      "tldr_zh": "本研究提出了一种整合记忆架构和大型语言模型(LLMs)的双层框架，旨在提升机器人处理多任务场景的能力，使其能有效切换任务并生成跨任务动作。该框架利用两个LLMs的互补技能——一个负责推理，另一个负责遵循指令，并结合受人类认知启发的记忆模型，帮助机器人记住任务状态、环境状态和已执行动作。实验结果显示，该方法在五个机器人任务上显著优于基线模型，证明了记忆与LLMs整合的潜力，可增强机器人的感知和适应性执行。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13505v2",
      "published_date": "2024-07-18 13:38:21 UTC",
      "updated_date": "2024-10-11 08:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:56:46.926482"
    },
    {
      "arxiv_id": "2407.13493v4",
      "title": "Training Foundation Models as Data Compression: On Information, Model Weights and Copyright Law",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Franceschelli",
        "Claudia Cevenini",
        "Mirco Musolesi"
      ],
      "abstract": "The training process of foundation models as for other classes of deep\nlearning systems is based on minimizing the reconstruction error over a\ntraining set. For this reason, they are susceptible to the memorization and\nsubsequent reproduction of training samples. In this paper, we introduce a\ntraining-as-compressing perspective, wherein the model's weights embody a\ncompressed representation of the training data. From a copyright standpoint,\nthis point of view implies that the weights can be considered a reproduction\nor, more likely, a derivative work of a potentially protected set of works. We\ninvestigate the technical and legal challenges that emerge from this framing of\nthe copyright of outputs generated by foundation models, including their\nimplications for practitioners and researchers. We demonstrate that adopting an\ninformation-centric approach to the problem presents a promising pathway for\ntackling these emerging complex legal issues.",
      "tldr_zh": "本文将基础模型的训练过程视为数据压缩，强调模型权重是对训练数据的压缩表示，从而可能导致模型记忆和再现训练样本的问题。作者从版权角度分析了这些权重是否构成对受保护作品的再现或衍生作品，探讨了由此引发的技术与法律挑战，包括对从业者和研究者的影响。最终，论文提出采用信息中心方法作为处理这些复杂问题的可行路径。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Spotlight presentation at GenLaw'24, see\n  https://www.genlaw.org/2024-icml-papers#training-foundation-models-as-data-compression-on-information-model-weights-and-copyright-law",
      "pdf_url": "http://arxiv.org/pdf/2407.13493v4",
      "published_date": "2024-07-18 13:23:16 UTC",
      "updated_date": "2025-03-12 14:54:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:56:58.491727"
    },
    {
      "arxiv_id": "2407.13492v3",
      "title": "Enhancing Biomedical Knowledge Discovery for Diseases: An Open-Source Framework Applied on Rett Syndrome and Alzheimer's Disease",
      "title_zh": "增强疾病的生物医学知识发现：应用于 Rett Syndrome 和 Alzheimer's Disease 的开源框架",
      "authors": [
        "Christos Theodoropoulos",
        "Andrei Catalin Coman",
        "James Henderson",
        "Marie-Francine Moens"
      ],
      "abstract": "The ever-growing volume of biomedical publications creates a critical need\nfor efficient knowledge discovery. In this context, we introduce an open-source\nend-to-end framework designed to construct knowledge around specific diseases\ndirectly from raw text. To facilitate research in disease-related knowledge\ndiscovery, we create two annotated datasets focused on Rett syndrome and\nAlzheimer's disease, enabling the identification of semantic relations between\nbiomedical entities. Extensive benchmarking explores various ways to represent\nrelations and entity representations, offering insights into optimal modeling\nstrategies for semantic relation detection and highlighting language models'\ncompetence in knowledge discovery. We also conduct probing experiments using\ndifferent layer representations and attention scores to explore transformers'\nability to capture semantic relations.",
      "tldr_zh": "这篇论文引入了一个开源端到端框架，用于从原始文本中构建特定疾病的知识，从而提升生物医学知识发现效率。框架应用于Rett syndrome和Alzheimer's disease，创建了两个标注数据集，以识别生物医学实体之间的semantic relations。研究通过广泛的基准测试和探测实验，探索了关系和实体表示的多种策略，并突出了language models在知识发现中的能力，以及transformers捕捉semantic relations的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in IEEE Access, doi: 10.1109/ACCESS.2024.3509714",
      "pdf_url": "http://arxiv.org/pdf/2407.13492v3",
      "published_date": "2024-07-18 13:20:53 UTC",
      "updated_date": "2024-12-04 17:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:57:09.977172"
    },
    {
      "arxiv_id": "2407.13490v1",
      "title": "Combining Constraint Programming Reasoning with Large Language Model Predictions",
      "title_zh": "结合约束编程推理与大型语言模型预测",
      "authors": [
        "Florian Régin",
        "Elisabetta De Maria",
        "Alexandre Bonlarron"
      ],
      "abstract": "Constraint Programming (CP) and Machine Learning (ML) face challenges in text\ngeneration due to CP's struggle with implementing \"meaning'' and ML's\ndifficulty with structural constraints. This paper proposes a solution by\ncombining both approaches and embedding a Large Language Model (LLM) in CP. The\nLLM handles word generation and meaning, while CP manages structural\nconstraints. This approach builds on GenCP, an improved version of On-the-fly\nConstraint Programming Search (OTFS) using LLM-generated domains. Compared to\nBeam Search (BS), a standard NLP method, this combined approach (GenCP with\nLLM) is faster and produces better results, ensuring all constraints are\nsatisfied. This fusion of CP and ML presents new possibilities for enhancing\ntext generation under constraints.",
      "tldr_zh": "这篇论文探讨了 Constraint Programming (CP) 在实现“含义”方面的困难和 Machine Learning (ML) 在处理结构约束时的挑战，提出了一种将 Large Language Model (LLM) 嵌入 CP 的创新方法。LLM 负责单词生成和含义解释，而 CP 则管理结构约束，该方法基于 GenCP，这是一种改进的 On-the-fly Constraint Programming Search (OTFS)。实验结果显示，与 Beam Search (BS) 相比，这种结合方法更快、效果更好，并确保所有约束得到满足，从而为受约束的文本生成开辟了新可能性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at The 30th International Conference on Principles and\n  Practice of Constraint Programming (CP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.13490v1",
      "published_date": "2024-07-18 13:15:55 UTC",
      "updated_date": "2024-07-18 13:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:57:25.270522"
    },
    {
      "arxiv_id": "2408.01429v1",
      "title": "An Agile Adaptation Method for Multi-mode Vehicle Communication Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Shiwen He",
        "Kanghong Chen",
        "Shiyue Huang",
        "Wei Huang",
        "Zhenyu An"
      ],
      "abstract": "This paper focuses on discovering the impact of communication mode allocation\non communication efficiency in the vehicle communication networks. To be\nspecific, Markov decision process and reinforcement learning are applied to\nestablish an agile adaptation mechanism for multi-mode communication devices\naccording to the driving scenarios and business requirements. Then, Q-learning\nis used to train the agile adaptation reinforcement learning model and output\nthe trained model. By learning the best actions to take in different states to\nmaximize the cumulative reward, and avoiding the problem of poor adaptation\neffect caused by inaccurate delay measurement in unstable communication\nscenarios. The experiments show that the proposed scheme can quickly adapt to\ndynamic vehicle networking environment, while achieving high concurrency and\ncommunication efficiency.",
      "tldr_zh": "本论文探讨了通信模式分配对车辆通信网络效率的影响，提出了一种基于Markov决策过程和强化学习的敏捷适应机制，用于多模式通信设备。方法通过Q-learning训练模型，根据驾驶场景和业务需求优化动作选择，从而最大化累积奖励并避免不稳定通信环境中延迟测量不准确的问题。实验结果表明，该方案能快速适应动态车辆网络环境，实现高并发和通信效率的提升。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01429v1",
      "published_date": "2024-07-18 13:04:34 UTC",
      "updated_date": "2024-07-18 13:04:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:57:33.440698"
    },
    {
      "arxiv_id": "2407.13480v1",
      "title": "Risk-Aware Vehicle Trajectory Prediction Under Safety-Critical Scenarios",
      "title_zh": "在安全关键场景下的风险感知车辆轨迹预测",
      "authors": [
        "Qingfan Wang",
        "Dongyang Xu",
        "Gaoyuan Kuang",
        "Chen Lv",
        "Shengbo Eben Li",
        "Bingbing Nie"
      ],
      "abstract": "Trajectory prediction is significant for intelligent vehicles to achieve\nhigh-level autonomous driving, and a lot of relevant research achievements have\nbeen made recently. Despite the rapid development, most existing studies solely\nfocused on normal safe scenarios while largely neglecting safety-critical\nscenarios, particularly those involving imminent collisions. This oversight may\nresult in autonomous vehicles lacking the essential predictive ability in such\nsituations, posing a significant threat to safety. To tackle these, this paper\nproposes a risk-aware trajectory prediction framework tailored to\nsafety-critical scenarios. Leveraging distinctive hazardous features, we\ndevelop three core risk-aware components. First, we introduce a\nrisk-incorporated scene encoder, which augments conventional encoders with\nquantitative risk information to achieve risk-aware encoding of hazardous scene\ncontexts. Next, we incorporate endpoint-risk-combined intention queries as\nprediction priors in the decoder to ensure that the predicted multimodal\ntrajectories cover both various spatial intentions and risk levels. Lastly, an\nauxiliary risk prediction task is implemented for the ultimate risk-aware\nprediction. Furthermore, to support model training and performance evaluation,\nwe introduce a safety-critical trajectory prediction dataset and tailored\nevaluation metrics. We conduct comprehensive evaluations and compare our model\nwith several SOTA models. Results demonstrate the superior performance of our\nmodel, with a significant improvement in most metrics. This prediction\nadvancement enables autonomous vehicles to execute correct collision avoidance\nmaneuvers under safety-critical scenarios, eventually enhancing road traffic\nsafety.",
      "tldr_zh": "这篇论文提出了一种风险感知（risk-aware）轨迹预测框架，针对自动驾驶车辆在安全关键（safety-critical）场景下的预测挑战，强调了现有方法忽略即将碰撞等高风险情况的问题。该框架包括三个核心组件：风险整合场景编码器（risk-incorporated scene encoder）以量化风险信息增强场景编码、端点风险结合意图查询（endpoint-risk-combined intention queries）确保预测轨迹覆盖多种空间意图和风险水平，以及辅助风险预测任务以实现全面的风险感知预测。为支持模型训练和评估，论文引入了一个安全关键轨迹预测数据集和专用评估指标。实验结果显示，该框架在大多数指标上显著优于现有SOTA模型，帮助自动驾驶车辆在高风险场景中执行有效的碰撞避让，提升整体交通安全。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13480v1",
      "published_date": "2024-07-18 13:00:01 UTC",
      "updated_date": "2024-07-18 13:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:57:48.642999"
    },
    {
      "arxiv_id": "2407.13463v1",
      "title": "End-To-End Clinical Trial Matching with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dyke Ferber",
        "Lars Hilgers",
        "Isabella C. Wiest",
        "Marie-Elisabeth Leßmann",
        "Jan Clusmann",
        "Peter Neidlinger",
        "Jiefu Zhu",
        "Georg Wölflein",
        "Jacqueline Lammert",
        "Maximilian Tschochohei",
        "Heiko Böhme",
        "Dirk Jäger",
        "Mihaela Aldea",
        "Daniel Truhn",
        "Christiane Höper",
        "Jakob Nikolas Kather"
      ],
      "abstract": "Matching cancer patients to clinical trials is essential for advancing\ntreatment and patient care. However, the inconsistent format of medical free\ntext documents and complex trial eligibility criteria make this process\nextremely challenging and time-consuming for physicians. We investigated\nwhether the entire trial matching process - from identifying relevant trials\namong 105,600 oncology-related clinical trials on clinicaltrials.gov to\ngenerating criterion-level eligibility matches - could be automated using Large\nLanguage Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic\nHealth Records (EHRs), we demonstrate that our approach identifies relevant\ncandidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%\nwhen matching patient-level information at the criterion level against a\nbaseline defined by human experts. Utilizing LLM feedback reveals that 39.3%\ncriteria that were initially considered incorrect are either ambiguous or\ninaccurately annotated, leading to a total model accuracy of 92.7% after\nrefining our human baseline. In summary, we present an end-to-end pipeline for\nclinical trial matching using LLMs, demonstrating high precision in screening\nand matching trials to individual patients, even outperforming the performance\nof qualified medical doctors. Our fully end-to-end pipeline can operate\nautonomously or with human supervision and is not restricted to oncology,\noffering a scalable solution for enhancing patient-trial matching in real-world\nsettings.",
      "tldr_zh": "该论文提出了一种使用Large Language Models (LLMs)实现癌症患者与临床试验端到端匹配的方法，以解决医疗文本格式不一致和资格标准复杂导致的匹配难题。研究利用GPT-4o和51个合成Electronic Health Records (EHRs)，从10.56万个肿瘤学临床试验中识别相关试验，准确率达93.3%，并在标准级别匹配中实现88.0%的初步准确率；通过LLM反馈，修正39.3%的模糊或标注错误后，总准确率提升至92.7%。该方法不仅高精度地筛选和匹配试验，甚至超过医生的表现，提供了一个可自主或人类监督的、可扩展管道，适用于各种医疗场景而非仅限于肿瘤学。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "149 pages, including Supplements. 3 Main Figures",
      "pdf_url": "http://arxiv.org/pdf/2407.13463v1",
      "published_date": "2024-07-18 12:36:26 UTC",
      "updated_date": "2024-07-18 12:36:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:58:02.401737"
    },
    {
      "arxiv_id": "2407.13439v1",
      "title": "Reducing Barriers to the Use of Marginalised Music Genres in AI",
      "title_zh": "减少在 AI 中使用",
      "authors": [
        "Nick Bryan-Kinns",
        "Zijin Li"
      ],
      "abstract": "AI systems for high quality music generation typically rely on extremely\nlarge musical datasets to train the AI models. This creates barriers to\ngenerating music beyond the genres represented in dominant datasets such as\nWestern Classical music or pop music. We undertook a 4 month international\nresearch project summarised in this paper to explore the eXplainable AI (XAI)\nchallenges and opportunities associated with reducing barriers to using\nmarginalised genres of music with AI models. XAI opportunities identified\nincluded topics of improving transparency and control of AI models, explaining\nthe ethics and bias of AI models, fine tuning large models with small datasets\nto reduce bias, and explaining style-transfer opportunities with AI models.\nParticipants in the research emphasised that whilst it is hard to work with\nsmall datasets such as marginalised music and AI, such approaches strengthen\ncultural representation of underrepresented cultures and contribute to\naddressing issues of bias of deep learning models. We are now building on this\nproject to bring together a global International Responsible AI Music community\nand invite people to join our network.",
      "tldr_zh": "这篇论文探讨了 AI 音乐生成系统依赖大型数据集（如西方古典或流行音乐）所带来的问题，导致边缘化音乐流派的生成障碍。研究团队开展了一个为期 4 个月的国际项目，使用 eXplainable AI (XAI) 识别机会，包括提升 AI 模型的透明度和控制、解释伦理与偏见、通过小数据集微调模型减少偏见，以及探索风格转移功能。参与者强调，尽管处理小数据集（如边缘化音乐）具有挑战，但此方法能加强未被代表文化的文化表示，并缓解深度学习模型的偏见问题。未来，作者计划建立一个全球国际负责任 AI 音乐社区，并邀请更多人参与。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "In Proceedings of Explainable AI for the Arts Workshop 2024 (XAIxArts\n  2024) arXiv:2406.14485",
      "pdf_url": "http://arxiv.org/pdf/2407.13439v1",
      "published_date": "2024-07-18 12:10:04 UTC",
      "updated_date": "2024-07-18 12:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:58:12.464037"
    },
    {
      "arxiv_id": "2407.13431v3",
      "title": "Improving Out-of-Distribution Generalization of Trajectory Prediction for Autonomous Driving via Polynomial Representations",
      "title_zh": "通过多项式表示改善自动驾驶轨迹预测的分布外泛化",
      "authors": [
        "Yue Yao",
        "Shengchao Yan",
        "Daniel Goehring",
        "Wolfram Burgard",
        "Joerg Reichardt"
      ],
      "abstract": "Robustness against Out-of-Distribution (OoD) samples is a key performance\nindicator of a trajectory prediction model. However, the development and\nranking of state-of-the-art (SotA) models are driven by their In-Distribution\n(ID) performance on individual competition datasets. We present an OoD testing\nprotocol that homogenizes datasets and prediction tasks across two large-scale\nmotion datasets. We introduce a novel prediction algorithm based on polynomial\nrepresentations for agent trajectory and road geometry on both the input and\noutput sides of the model. With a much smaller model size, training effort, and\ninference time, we reach near SotA performance for ID testing and significantly\nimprove robustness in OoD testing. Within our OoD testing protocol, we further\nstudy two augmentation strategies of SotA models and their effects on model\ngeneralization. Highlighting the contrast between ID and OoD performance, we\nsuggest adding OoD testing to the evaluation criteria of trajectory prediction\nmodels.",
      "tldr_zh": "该论文针对自动驾驶轨迹预测模型的Out-of-Distribution (OoD)鲁棒性问题，提出了一种标准化OoD测试协议，以统一不同数据集和预测任务。研究引入基于多项式表示的预测算法，用于处理代理轨迹和道路几何的输入输出，从而实现模型尺寸更小、训练和推理效率更高，同时在In-Distribution (ID)测试中达到接近State-of-the-Art (SotA)性能，并在OoD测试中显著提升泛化能力。作者还探讨了SotA模型的两种增强策略及其对模型泛化的影响，并建议将OoD测试纳入轨迹预测模型的评估标准，以突出ID和OoD性能之间的对比。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13431v3",
      "published_date": "2024-07-18 12:00:32 UTC",
      "updated_date": "2025-01-25 17:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:58:25.820854"
    },
    {
      "arxiv_id": "2407.13429v1",
      "title": "Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information",
      "title_zh": "翻译失败",
      "authors": [
        "Fedor Sergeev",
        "Paola Malsot",
        "Gunnar Rätsch",
        "Vincent Fortuin"
      ],
      "abstract": "Knowing which features of a multivariate time series to measure and when is a\nkey task in medicine, wearables, and robotics. Better acquisition policies can\nreduce costs while maintaining or even improving the performance of downstream\npredictors. Inspired by the maximization of conditional mutual information, we\npropose an approach to train acquirers end-to-end using only the downstream\nloss. We show that our method outperforms random acquisition policy, matches a\nmodel with an unrestrained budget, but does not yet overtake a static\nacquisition strategy. We highlight the assumptions and outline avenues for\nfuture work.",
      "tldr_zh": "在医学、可穿戴设备和机器人领域，动态获取多变量时间序列特征至关重要，因为它能降低测量成本同时维持或提升下游预测器的性能。论文提出了一种基于最大化条件互信息（conditional mutual information）的方法，通过端到端训练获取策略，仅使用下游损失来优化决策。实验结果表明，该方法优于随机获取策略，并与无预算限制模型相当，但尚未超过静态策略；论文还突出了相关假设并概述了未来工作方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the ICML 2024 Next Generation of Sequence Modeling\n  Architectures (NGSM) Workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.13429v1",
      "published_date": "2024-07-18 11:54:34 UTC",
      "updated_date": "2024-07-18 11:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:58:36.623738"
    },
    {
      "arxiv_id": "2407.13427v3",
      "title": "DeepClair: Utilizing Market Forecasts for Effective Portfolio Selection",
      "title_zh": "DeepClair：利用市场预测进行有效投资组合选择",
      "authors": [
        "Donghee Choi",
        "Jinkyu Kim",
        "Mogan Gim",
        "Jinho Lee",
        "Jaewoo Kang"
      ],
      "abstract": "Utilizing market forecasts is pivotal in optimizing portfolio selection\nstrategies. We introduce DeepClair, a novel framework for portfolio selection.\nDeepClair leverages a transformer-based time-series forecasting model to\npredict market trends, facilitating more informed and adaptable portfolio\ndecisions. To integrate the forecasting model into a deep reinforcement\nlearning-driven portfolio selection framework, we introduced a two-step\nstrategy: first, pre-training the time-series model on market data, followed by\nfine-tuning the portfolio selection architecture using this model.\nAdditionally, we investigated the optimization technique, Low-Rank Adaptation\n(LoRA), to enhance the pre-trained forecasting model for fine-tuning in\ninvestment scenarios. This work bridges market forecasting and portfolio\nselection, facilitating the advancement of investment strategies.",
      "tldr_zh": "本文提出 DeepClair 框架，利用市场预测来优化投资组合选择策略。该框架采用基于 Transformer 的时间序列预测模型来预测市场趋势，并通过一个两步策略将其整合到深度强化学习驱动的投资组合选择中：首先在市场数据上预训练模型，然后使用该模型进行微调。此外，引入 Low-Rank Adaptation (LoRA) 技术来增强预训练模型在投资场景中的适应性。该工作桥接了市场预测和投资组合选择，促进了更有效的投资策略发展。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "CIKM 2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2407.13427v3",
      "published_date": "2024-07-18 11:51:03 UTC",
      "updated_date": "2024-08-16 06:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:58:48.801123"
    },
    {
      "arxiv_id": "2407.13419v1",
      "title": "From Words to Worlds: Compositionality for Cognitive Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Ruchira Dhar",
        "Anders Søgaard"
      ],
      "abstract": "Large language models (LLMs) are very performant connectionist systems, but\ndo they exhibit more compositionality? More importantly, is that part of why\nthey perform so well? We present empirical analyses across four LLM families\n(12 models) and three task categories, including a novel task introduced below.\nOur findings reveal a nuanced relationship in learning of compositional\nstrategies by LLMs -- while scaling enhances compositional abilities,\ninstruction tuning often has a reverse effect. Such disparity brings forth some\nopen issues regarding the development and improvement of large language models\nin alignment with human cognitive capacities.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否具备更多组合性 (compositionality)，并分析这是否是其高性能的原因。研究通过对四个 LLM 家族的 12 个模型进行实证分析，涵盖三个任务类别（包括一个新任务），揭示了 LLMs 在学习组合策略方面的复杂关系：模型规模的扩大能提升组合能力，而指令微调 (instruction tuning) 往往会产生相反效果。这些发现引发了关于 LLMs 发展与人类认知能力对齐的开放问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICML 2024 Workshop on LLMs & Cognition",
      "pdf_url": "http://arxiv.org/pdf/2407.13419v1",
      "published_date": "2024-07-18 11:42:13 UTC",
      "updated_date": "2024-07-18 11:42:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:59:01.076703"
    },
    {
      "arxiv_id": "2407.13408v1",
      "title": "DISCOVER: A Data-driven Interactive System for Comprehensive Observation, Visualization, and ExploRation of Human Behaviour",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Schiller",
        "Tobias Hallmen",
        "Daksitha Withanage Don",
        "Elisabeth André",
        "Tobias Baur"
      ],
      "abstract": "Understanding human behavior is a fundamental goal of social sciences, yet\nits analysis presents significant challenges. Conventional methodologies\nemployed for the study of behavior, characterized by labor-intensive data\ncollection processes and intricate analyses, frequently hinder comprehensive\nexploration due to their time and resource demands. In response to these\nchallenges, computational models have proven to be promising tools that help\nresearchers analyze large amounts of data by automatically identifying\nimportant behavioral indicators, such as social signals. However, the\nwidespread adoption of such state-of-the-art computational models is impeded by\ntheir inherent complexity and the substantial computational resources necessary\nto run them, thereby constraining accessibility for researchers without\ntechnical expertise and adequate equipment. To address these barriers, we\nintroduce DISCOVER -- a modular and flexible, yet user-friendly software\nframework specifically developed to streamline computational-driven data\nexploration for human behavior analysis. Our primary objective is to\ndemocratize access to advanced computational methodologies, thereby enabling\nresearchers across disciplines to engage in detailed behavioral analysis\nwithout the need for extensive technical proficiency. In this paper, we\ndemonstrate the capabilities of DISCOVER using four exemplary data exploration\nworkflows that build on each other: Interactive Semantic Content Exploration,\nVisual Inspection, Aided Annotation, and Multimodal Scene Search. By\nillustrating these workflows, we aim to emphasize the versatility and\naccessibility of DISCOVER as a comprehensive framework and propose a set of\nblueprints that can serve as a general starting point for exploratory data\nanalysis.",
      "tldr_zh": "该论文针对人类行为分析面临的挑战，如传统方法耗时费力和计算模型的复杂性，引入了 DISCOVER 系统——一个模块化、灵活且用户友好的软件框架，旨在简化计算驱动的数据探索并降低技术门槛。DISCOVER 的核心目标是让跨学科研究人员无需专业技能即可进行详细的行为分析，通过四个示例工作流（Interactive Semantic Content Exploration、Visual Inspection、Aided Annotation 和 Multimodal Scene Search）来展示其多功能性。最终，该系统提供了一套通用蓝图，作为探索性数据分析的起点，促进行为研究的民主化。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "J.4"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13408v1",
      "published_date": "2024-07-18 11:28:52 UTC",
      "updated_date": "2024-07-18 11:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:59:13.902619"
    },
    {
      "arxiv_id": "2407.13399v3",
      "title": "Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization",
      "title_zh": "纠正 KL 正则化的神话：通过卡方偏好优化实现无需过度优化的直接对齐",
      "authors": [
        "Audrey Huang",
        "Wenhao Zhan",
        "Tengyang Xie",
        "Jason D. Lee",
        "Wen Sun",
        "Akshay Krishnamurthy",
        "Dylan J. Foster"
      ],
      "abstract": "Language model alignment methods such as reinforcement learning from human\nfeedback (RLHF) have led to impressive advances in language model capabilities,\nbut are limited by a widely observed phenomenon known as overoptimization,\nwhere the quality of the language model degrades over the course of the\nalignment process. As the model optimizes performance with respect to an\noffline reward model, it overfits to inaccuracies and drifts away from\npreferred responses covered by the data. To discourage such distribution shift,\nKL-regularization is widely employed in existing offline alignment methods, but\noveroptimization continues to harm performance. Lending theoretical insight\ninto the source of these empirical observations, we first show that the\nKL-regularization is too weak to prevent overfitting, then raise the following\nquestion: is it possible to design an efficient algorithm that is provably\nrobust to overoptimization?\n  We address this question with a new algorithm for offline alignment,\n$\\chi^2$-Preference Optimization ($\\chi$PO). $\\chi$PO is a one-line change to\nDirect Preference Optimization (DPO; Rafailov et al., 2023), which only\ninvolves modifying the logarithmic link function in the DPO objective. Despite\nthis minimal change, $\\chi$PO implicitly implements the principle of pessimism\nin the face of uncertainty via regularization with the $\\chi^2$-divergence --\nwhich quantifies uncertainty more effectively than KL-regularization -- and\nprovably alleviates overoptimization, achieving sample-complexity guarantees\nbased on single-policy concentrability -- the gold standard in offline\nreinforcement learning. $\\chi$PO's simplicity and strong guarantees make it the\nfirst practical and general-purpose offline alignment algorithm that is\nprovably robust to overoptimization.",
      "tldr_zh": "本文论文揭示了KL-regularization在语言模型对齐中不足以防止overoptimization问题，特别是在RLHF方法中导致模型性能下降。作者提出χPO（Chi-Squared Preference Optimization）算法，这是对Direct Preference Optimization (DPO) 的简单修改，仅需调整对数链接函数，使用χ²-divergence来更有效地量化不确定性，从而实现对overoptimization的缓解。χPO 隐式引入了不确定性下的悲观原则，提供基于single-policy concentrability的样本复杂度保证。总体而言，该算法是首个实用且理论上鲁棒的离线对齐方法，为语言模型优化提供了新路径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13399v3",
      "published_date": "2024-07-18 11:08:40 UTC",
      "updated_date": "2025-02-18 17:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:59:25.315829"
    },
    {
      "arxiv_id": "2407.19072v1",
      "title": "Configural processing as an optimized strategy for robust object recognition in neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hojin Jang",
        "Pawan Sinha",
        "Xavier Boix"
      ],
      "abstract": "Configural processing, the perception of spatial relationships among an\nobject's components, is crucial for object recognition. However, the teleology\nand underlying neurocomputational mechanisms of such processing are still\nelusive, notwithstanding decades of research. We hypothesized that processing\nobjects via configural cues provides a more robust means to recognizing them\nrelative to local featural cues. We evaluated this hypothesis by devising\nidentification tasks with composite letter stimuli and comparing different\nneural network models trained with either only local or configural cues\navailable. We found that configural cues yielded more robust performance to\ngeometric transformations such as rotation or scaling. Furthermore, when both\nfeatures were simultaneously available, configural cues were favored over local\nfeatural cues. Layerwise analysis revealed that the sensitivity to configural\ncues emerged later relative to local feature cues, possibly contributing to the\nrobustness to pixel-level transformations. Notably, this configural processing\noccurred in a purely feedforward manner, without the need for recurrent\ncomputations. Our findings with letter stimuli were successfully extended to\nnaturalistic face images. Thus, our study provides neurocomputational evidence\nthat configural processing emerges in a na\\\"ive network based on task\ncontingencies, and is beneficial for robust object processing under varying\nviewing conditions.",
      "tldr_zh": "本文研究了配置处理（configural processing）作为一种优化策略，以提升神经网络在物体识别中的鲁棒性。作者设计了识别任务，使用复合字母刺激训练神经网络模型，比较仅依赖局部特征线索与配置线索的效果，发现配置线索对几何变换（如旋转或缩放）更具耐受性，且当两者同时可用时，网络优先选择配置线索。层级分析显示，配置线索的敏感性在网络较晚层出现，并以纯前馈（feedforward）方式实现，最终实验扩展到自然面部图像，证明这种处理策略能基于任务条件自发出现，提高物体识别在不同观看条件下的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19072v1",
      "published_date": "2024-07-18 10:39:14 UTC",
      "updated_date": "2024-07-18 10:39:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:59:37.530358"
    },
    {
      "arxiv_id": "2407.13377v1",
      "title": "Linear-Complexity Self-Supervised Learning for Speech Processing",
      "title_zh": "线性复杂度自监督学习用于语音处理",
      "authors": [
        "Shucong Zhang",
        "Titouan Parcollet",
        "Rogier van Dalen",
        "Sourav Bhattacharya"
      ],
      "abstract": "Self-supervised learning (SSL) models usually require weeks of pre-training\nwith dozens of high-end GPUs. These models typically have a multi-headed\nself-attention (MHSA) context encoder. However, MHSA takes quadratic time and\nspace in the input length, contributing to the high pre-training cost.\nLinear-complexity alternatives to MHSA have been proposed. For instance, in\nsupervised training, the SummaryMixing model is the first to outperform MHSA\nacross multiple speech processing tasks. However, these cheaper alternatives\nhave not been explored for SSL yet. This paper studies a linear-complexity\ncontext encoder for SSL for the first time. With better or equivalent\nperformance for the downstream tasks of the MP3S benchmark, SummaryMixing\nreduces the pre-training time and peak VRAM of wav2vec 2.0 model by 18% and by\n23%, respectively, leading to the pre-training of a 155M wav2vec 2.0 model\nfinished within one week with 4 Tesla A100 GPUs. Code is available at\nhttps://github.com/SamsungLabs/SummaryMixing.",
      "tldr_zh": "本论文提出了一种线性复杂度的自监督学习（Self-Supervised Learning, SSL）方法，用于语音处理领域，以解决传统多头自注意力（MHSA）上下文编码器导致的预训练成本高问题。作者首次将线性复杂度替代方案，如SummaryMixing，应用于SSL框架中，并证明其在MP3S基准下游任务上表现优于或等效于MHSA，同时将wav2vec 2.0模型的预训练时间和峰值VRAM分别减少18%和23%。这一创新使得一个155M参数的wav2vec 2.0模型能在4个Tesla A100 GPU上仅用一周时间完成预训练，并提供了开源代码以促进进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13377v1",
      "published_date": "2024-07-18 10:34:33 UTC",
      "updated_date": "2024-07-18 10:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:59:49.811564"
    },
    {
      "arxiv_id": "2408.00004v1",
      "title": "Handling Numeric Expressions in Automatic Speech Recognition",
      "title_zh": "自动语音识别中数字表达式的处理",
      "authors": [
        "Christian Huber",
        "Alexander Waibel"
      ],
      "abstract": "This paper addresses the problem of correctly formatting numeric expressions\nin automatic speech recognition (ASR) transcripts. This is challenging since\nthe expected transcript format depends on the context, e.g., 1945 (year) vs.\n19:45 (timestamp). We compare cascaded and end-to-end approaches to recognize\nand format numeric expression, such as years, timestamps, currency amounts, and\nquantities. For the end-to-end approach we employed a data generation strategy\nusing a large language model (LLM) together with a text to speech (TTS) model\nto generate adaptation data. The results on our test dataset show that while\napproaches based on LLMs perform well on recognizing formatted numeric\nexpressions, adapted end-to-end models offer competitive performance with the\nadvantage of lower latency and inference cost.",
      "tldr_zh": "这篇论文探讨了在自动语音识别 (ASR) 中正确格式化数字表达的问题，例如年份 (e.g., 1945) 与时间戳 (e.g., 19:45) 之间的上下文依赖挑战。作者比较了级联 (cascaded) 和端到端 (end-to-end) 方法，其中端到端方法通过利用大型语言模型 (LLM) 和文本到语音 (TTS) 模型生成适应数据来识别和格式化数字表达，如货币金额和数量。实验结果表明，虽然基于 LLM 的方法在识别性能上表现出色，但适应后的端到端模型提供了竞争性表现，同时降低了延迟和推理成本。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.00004v1",
      "published_date": "2024-07-18 09:46:19 UTC",
      "updated_date": "2024-07-18 09:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:00:02.342926"
    },
    {
      "arxiv_id": "2407.13320v1",
      "title": "Deep Reinforcement Learning for Multi-Objective Optimization: Enhancing Wind Turbine Energy Generation while Mitigating Noise Emissions",
      "title_zh": "深度强化学习用于多目标优化：增强风力涡轮机能量生成同时减轻噪声排放",
      "authors": [
        "Martín de Frutos",
        "Oscar A. Marino",
        "David Huergo",
        "Esteban Ferrer"
      ],
      "abstract": "We develop a torque-pitch control framework using deep reinforcement learning\nfor wind turbines to optimize the generation of wind turbine energy while\nminimizing operational noise. We employ a double deep Q-learning, coupled to a\nblade element momentum solver, to enable precise control over wind turbine\nparameters. In addition to the blade element momentum, we use the wind turbine\nacoustic model of Brooks Pope and Marcolini. Through training with simple\nwinds, the agent learns optimal control policies that allow efficient control\nfor complex turbulent winds. Our experiments demonstrate that the reinforcement\nlearning is able to find optima at the Pareto front, when maximizing energy\nwhile minimizing noise. In addition, the adaptability of the reinforcement\nlearning agent to changing turbulent wind conditions, underscores its efficacy\nfor real-world applications. We validate the methodology using a SWT2.3-93 wind\nturbine with a rated power of 2.3 MW. We compare the reinforcement learning\ncontrol to classic controls to show that they are comparable when not taking\ninto account noise emissions. When including a maximum limit of 45 dB to the\nnoise produced (100 meters downwind of the turbine), the extracted yearly\nenergy decreases by 22%. The methodology is flexible and allows for easy tuning\nof the objectives and constraints through the reward definitions, resulting in\na flexible multi-objective optimization framework for wind turbine control.\nOverall, our findings highlight the potential of RL-based control strategies to\nimprove wind turbine efficiency while mitigating noise pollution, thus\nadvancing sustainable energy generation technologies",
      "tldr_zh": "本文提出了一种基于 Deep Reinforcement Learning 的扭矩-俯仰控制框架，用于优化风力涡轮机的能量生成同时最小化操作噪音。框架采用 Double Deep Q-Learning 算法，结合 Blade Element Momentum solver 和 Brooks Pope and Marcolini 的声学模型，通过简单风况训练代理，使其能适应复杂湍流风况并找到 Pareto front 上最优解。实验验证显示，与经典控制相比，该方法在不考虑噪音时性能相当，但当噪音限制在45 dB时，每年能量提取减少22%。总体而言，这一灵活的 RL 框架通过奖励定义轻松调整目标，提升了风力涡轮机效率并减少噪音污染，促进可持续能源技术发展。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13320v1",
      "published_date": "2024-07-18 09:21:51 UTC",
      "updated_date": "2024-07-18 09:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:00:15.210769"
    },
    {
      "arxiv_id": "2407.13313v2",
      "title": "Sortability of Time Series Data",
      "title_zh": "时间序列",
      "authors": [
        "Christopher Lohse",
        "Jonas Wahl"
      ],
      "abstract": "Evaluating the performance of causal discovery algorithms that aim to find\ncausal relationships between time-dependent processes remains a challenging\ntopic. In this paper, we show that certain characteristics of datasets, such as\nvarsortability (Reisach et al. 2021) and $R^2$-sortability (Reisach et al.\n2023), also occur in datasets for autocorrelated stationary time series. We\nillustrate this empirically using four types of data: simulated data based on\nSVAR models and Erd\\H{o}s-R\\'enyi graphs, the data used in the 2019\ncausality-for-climate challenge (Runge et al. 2019), real-world river stream\ndatasets, and real-world data generated by the Causal Chamber of (Gamella et\nal. 2024). To do this, we adapt var- and $R^2$-sortability to time series data.\nWe also investigate the extent to which the performance of score-based causal\ndiscovery methods goes hand in hand with high sortability. Arguably, our most\nsurprising finding is that the investigated real-world datasets exhibit high\nvarsortability and low $R^2$-sortability indicating that scales may carry a\nsignificant amount of causal information.",
      "tldr_zh": "本研究探讨了时间序列数据中因果发现算法的性能评估问题，重点考察varsortability和R²-sortability等数据集特性在自相关平稳时间序列中的表现。作者将这些特性适应到时间序列数据，并通过四种数据类型进行实证分析，包括基于SVAR models和Erdős-Rényi graphs的模拟数据、气候挑战数据集、河流流数据以及Causal Chamber生成的真实数据。结果显示，基于分数的因果发现方法的性能与高sortability密切相关，而调查的真实数据集表现出高varsortability和低R²-sortability，这表明数据规模可能携带重要因果信息。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Contribution for the Causal Inference for Time Series Data Workshop\n  at the 40th Conference on Uncertainty in Artificial Intelligence (CI4TS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.13313v2",
      "published_date": "2024-07-18 09:15:39 UTC",
      "updated_date": "2024-07-23 14:34:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:00:28.046602"
    },
    {
      "arxiv_id": "2407.13301v2",
      "title": "CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis",
      "title_zh": "CoD：利用诊断链实现可解释医疗代理",
      "authors": [
        "Junying Chen",
        "Chi Gui",
        "Anningzhe Gao",
        "Ke Ji",
        "Xidong Wang",
        "Xiang Wan",
        "Benyou Wang"
      ],
      "abstract": "The field of medical diagnosis has undergone a significant transformation\nwith the advent of large language models (LLMs), yet the challenges of\ninterpretability within these models remain largely unaddressed. This study\nintroduces Chain-of-Diagnosis (CoD) to enhance the interpretability of\nLLM-based medical diagnostics. CoD transforms the diagnostic process into a\ndiagnostic chain that mirrors a physician's thought process, providing a\ntransparent reasoning pathway. Additionally, CoD outputs the disease confidence\ndistribution to ensure transparency in decision-making. This interpretability\nmakes model diagnostics controllable and aids in identifying critical symptoms\nfor inquiry through the entropy reduction of confidences. With CoD, we\ndeveloped DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental\nresults demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic\nbenchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring\ncontrollability in diagnostic rigor.",
      "tldr_zh": "本研究提出 Chain-of-Diagnosis (CoD) 方法，以提升大型语言模型 (LLMs) 在医疗诊断中的可解释性，通过将诊断过程转化为一个模仿医生思维的诊断链，提供透明的推理路径和疾病置信度分布。CoD 还通过置信度熵减少来识别关键症状，确保诊断过程的可控性。基于 CoD，研究团队开发了 DiagnosisGPT，能诊断 9604 种疾病，并在实验基准测试中优于其他 LLMs，同时实现了可解释性和可控性的平衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13301v2",
      "published_date": "2024-07-18 09:06:27 UTC",
      "updated_date": "2024-09-15 08:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:00:39.093997"
    },
    {
      "arxiv_id": "2407.15869v1",
      "title": "Long Input Sequence Network for Long Time Series Forecasting",
      "title_zh": "长输入序列网络用于长时序预测",
      "authors": [
        "Chao Ma",
        "Yikai Hou",
        "Xiang Li",
        "Yinggang Sun",
        "Haining Yu"
      ],
      "abstract": "Short fixed-length inputs are the main bottleneck of deep learning methods in\nlong time-series forecasting tasks. Prolonging input length causes overfitting,\nrapidly deteriorating accuracy. Our research indicates that the overfitting is\na combination reaction of the multi-scale pattern coupling in time series and\nthe fixed focusing scale of current models. First, we find that the patterns\nexhibited by a time series across various scales are reflective of its\nmulti-periodic nature, where each scale corresponds to specific period length.\nSecond, We find that the token size predominantly dictates model behavior, as\nit determines the scale at which the model focuses and the context size it can\naccommodate. Our idea is to decouple the multi-scale temporal patterns of time\nseries and to model each pattern with its corresponding period length as token\nsize. We introduced a novel series-decomposition module(MPSD), and a\nMulti-Token Pattern Recognition neural network(MTPR), enabling the model to\nhandle \\textit{inputs up to $10\\times$ longer}. Sufficient context enhances\nperformance(\\textit{38% maximum precision improvement}), and the decoupling\napproach offers \\textit{Low complexity($0.22\\times$ cost)} and \\textit{high\ninterpretability}.",
      "tldr_zh": "该论文针对深度学习在长期时间序列预测中的输入长度瓶颈问题，指出过拟合源于多尺度模式耦合和模型固定聚焦尺度。研究者引入了系列分解模块(MPSD)和多令牌模式识别神经网络(MTPR)，通过解耦时间序列的多尺度模式并以对应周期长度的token size建模，实现对输入序列长达原先10倍的处理。实验结果显示，该方法提升了最大精度38%，降低了计算复杂度至0.22倍，并提高了模型的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.15869v1",
      "published_date": "2024-07-18 08:43:12 UTC",
      "updated_date": "2024-07-18 08:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:00:51.801257"
    },
    {
      "arxiv_id": "2407.13285v1",
      "title": "Collaborative real-time vision-based device for olive oil production monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Matija Šuković",
        "Igor Jovančević"
      ],
      "abstract": "This paper proposes an innovative approach to improving quality control of\nolive oil manufacturing and preventing damage to the machinery caused by\nforeign objects. We developed a computer-vision-based system that monitors the\ninput of an olive grinder and promptly alerts operators if a foreign object is\ndetected, indicating it by using guided lasers, audio, and visual cues.",
      "tldr_zh": "这篇论文提出了一种基于计算机视觉的实时协作设备，用于监控橄榄油生产过程，以提升质量控制并防止外来物体对机器造成损坏。该系统通过实时监测橄榄研磨机的输入，一旦检测到外来物体，便会立即通过引导激光、音频和视觉提示警报操作员。这种创新方法有助于提高生产安全性和效率，减少潜在设备故障的风险。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.13285v1",
      "published_date": "2024-07-18 08:37:08 UTC",
      "updated_date": "2024-07-18 08:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:01:02.911945"
    },
    {
      "arxiv_id": "2407.13268v2",
      "title": "Mixture of Experts based Multi-task Supervise Learning from Crowds",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Han",
        "Huaixuan Shi",
        "Xinyi Ding",
        "Xiao Ma",
        "Huamao Gu",
        "Yili Fang"
      ],
      "abstract": "Existing truth inference methods in crowdsourcing aim to map redundant labels\nand items to the ground truth. They treat the ground truth as hidden variables\nand use statistical or deep learning-based worker behavior models to infer the\nground truth. However, worker behavior models that rely on ground truth hidden\nvariables overlook workers' behavior at the item feature level, leading to\nimprecise characterizations and negatively impacting the quality of truth\ninference. This paper proposes a new paradigm of multi-task supervised learning\nfrom crowds, which eliminates the need for modeling of items's ground truth in\nworker behavior models. Within this paradigm, we propose a worker behavior\nmodel at the item feature level called Mixture of Experts based Multi-task\nSupervised Learning from Crowds (MMLC). Two truth inference strategies are\nproposed within MMLC. The first strategy, named MMLC-owf, utilizes clustering\nmethods in the worker spectral space to identify the projection vector of the\noracle worker. Subsequently, the labels generated based on this vector are\nconsidered as the inferred truth. The second strategy, called MMLC-df, employs\nthe MMLC model to fill the crowdsourced data, which can enhance the\neffectiveness of existing truth inference methods. Experimental results\ndemonstrate that MMLC-owf outperforms state-of-the-art methods and MMLC-df\nenhances the quality of existing truth inference methods.",
      "tldr_zh": "本文提出了一种新的多任务监督学习从众包（Multi-task Supervised Learning from Crowds）范式，以解决现有真相推断方法忽略工人行为在项目特征水平上的问题，从而避免了对项目真实真相的建模需求。核心方法是基于 Mixture of Experts 的模型 MMLC，该模型包括两种策略：MMLC-owf 通过在工人谱空间中使用聚类方法识别预言家工作者的投影向量来推断真相；MMLC-df 则通过填充众包数据来增强现有真相推断方法的有效性。实验结果显示，MMLC-owf 优于最先进方法，而 MMLC-df 显著提高了这些方法的整体质量。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13268v2",
      "published_date": "2024-07-18 08:21:31 UTC",
      "updated_date": "2025-03-12 15:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:01:18.045727"
    },
    {
      "arxiv_id": "2407.13264v1",
      "title": "Underwater Acoustic Signal Denoising Algorithms: A Survey of the State-of-the-art",
      "title_zh": "水下声学信号去噪算法：现有技术的综述",
      "authors": [
        "Ruobin Gao",
        "Maohan Liang",
        "Heng Dong",
        "Xuewen Luo",
        "P. N. Suganthan"
      ],
      "abstract": "This paper comprehensively reviews recent advances in underwater acoustic\nsignal denoising, an area critical for improving the reliability and clarity of\nunderwater communication and monitoring systems. Despite significant progress\nin the field, the complex nature of underwater environments poses unique\nchallenges that complicate the denoising process. We begin by outlining the\nfundamental challenges associated with underwater acoustic signal processing,\nincluding signal attenuation, noise variability, and the impact of\nenvironmental factors. The review then systematically categorizes and discusses\nvarious denoising algorithms, such as conventional, decomposition-based, and\nlearning-based techniques, highlighting their applications, advantages, and\nlimitations. Evaluation metrics and experimental datasets are also reviewed.\nThe paper concludes with a list of open questions and recommendations for\nfuture research directions, emphasizing the need for developing more robust\ndenoising techniques that can adapt to the dynamic underwater acoustic\nenvironment.",
      "tldr_zh": "这篇论文对水下声学信号去噪算法进行了全面综述，旨在提升水下通信和监测系统的可靠性和清晰度。论文首先概述了水下声学信号处理的根本挑战，包括信号衰减、噪声变异性和环境因素的影响，然后系统分类讨论了传统、基于分解和基于学习的去噪算法，并分析了它们的应用优势、局限性以及相关的评估指标和实验数据集。最终，论文指出了领域的开放问题，并推荐未来研究方向，强调开发更鲁棒的自适应去噪技术以应对动态水下环境。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13264v1",
      "published_date": "2024-07-18 08:14:59 UTC",
      "updated_date": "2024-07-18 08:14:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:01:27.716708"
    },
    {
      "arxiv_id": "2407.13241v1",
      "title": "NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations",
      "title_zh": "NODER：基于神经常微分方程的图像序列回归",
      "authors": [
        "Hao Bai",
        "Yi Hong"
      ],
      "abstract": "Regression on medical image sequences can capture temporal image pattern\nchanges and predict images at missing or future time points. However, existing\ngeodesic regression methods limit their regression performance by a strong\nunderlying assumption of linear dynamics, while diffusion-based methods have\nhigh computational costs and lack constraints to preserve image topology. In\nthis paper, we propose an optimization-based new framework called NODER, which\nleverages neural ordinary differential equations to capture complex underlying\ndynamics and reduces its high computational cost of handling high-dimensional\nimage volumes by introducing the latent space. We compare our NODER with two\nrecent regression methods, and the experimental results on ADNI and ACDC\ndatasets demonstrate that our method achieves the state-of-the-art performance\nin 3D image regression. Our model needs only a couple of images in a sequence\nfor prediction, which is practical, especially for clinical situations where\nextremely limited image time series are available for analysis. Our source code\nis available at https://github.com/ZedKing12138/NODER-pytorch.",
      "tldr_zh": "本论文提出NODER框架，利用Neural Ordinary Differential Equations（ODEs）对医学图像序列进行回归，旨在捕捉复杂动态变化并预测缺失或未来图像，同时通过引入潜在空间（latent space）降低高维图像的计算成本。\n与现有测地回归和扩散方法相比，NODER克服了线性动态假设和计算效率问题，在ADNI和ACDC数据集上的实验显示其在3D图像回归中达到了最先进性能。\n该方法仅需序列中的少数图像即可实现准确预测，特别适用于临床场景中数据有限的实际应用，并提供了开源代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MICCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13241v1",
      "published_date": "2024-07-18 07:50:46 UTC",
      "updated_date": "2024-07-18 07:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:01:40.544661"
    },
    {
      "arxiv_id": "2407.13237v1",
      "title": "LLM-Empowered State Representation for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Boyuan Wang",
        "Yun Qu",
        "Yuhang Jiang",
        "Jianzhun Shao",
        "Chang Liu",
        "Wenming Yang",
        "Xiangyang Ji"
      ],
      "abstract": "Conventional state representations in reinforcement learning often omit\ncritical task-related details, presenting a significant challenge for value\nnetworks in establishing accurate mappings from states to task rewards.\nTraditional methods typically depend on extensive sample learning to enrich\nstate representations with task-specific information, which leads to low sample\nefficiency and high time costs. Recently, surging knowledgeable large language\nmodels (LLM) have provided promising substitutes for prior injection with\nminimal human intervention. Motivated by this, we propose LLM-Empowered State\nRepresentation (LESR), a novel approach that utilizes LLM to autonomously\ngenerate task-related state representation codes which help to enhance the\ncontinuity of network mappings and facilitate efficient training. Experimental\nresults demonstrate LESR exhibits high sample efficiency and outperforms\nstate-of-the-art baselines by an average of 29% in accumulated reward in Mujoco\ntasks and 30% in success rates in Gym-Robotics tasks.",
      "tldr_zh": "传统强化学习中的状态表示常忽略关键任务细节，导致价值网络难以准确映射状态到奖励，且依赖大量样本学习，效率低下。针对此问题，本文提出LLM-Empowered State Representation (LESR)方法，利用大型语言模型(LLM)自主生成任务相关的状态表示代码，提升网络映射的连续性和训练效率。实验结果显示，LESR在Mujoco任务中累积奖励比最先进基线平均提高29%，并在Gym-Robotics任务中成功率平均提升30%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13237v1",
      "published_date": "2024-07-18 07:47:51 UTC",
      "updated_date": "2024-07-18 07:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:01:51.181089"
    },
    {
      "arxiv_id": "2407.13218v3",
      "title": "LiNR: Model Based Neural Retrieval on GPUs at LinkedIn",
      "title_zh": "翻译失败",
      "authors": [
        "Fedor Borisyuk",
        "Qingquan Song",
        "Mingzhou Zhou",
        "Ganesh Parameswaran",
        "Madhu Arun",
        "Siva Popuri",
        "Tugrul Bingol",
        "Zhuotao Pei",
        "Kuang-Hsuan Lee",
        "Lu Zheng",
        "Qizhan Shao",
        "Ali Naqvi",
        "Sen Zhou",
        "Aman Gupta"
      ],
      "abstract": "This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval\nsystem. LiNR supports a billion-sized index on GPU models. We discuss our\nexperiences and challenges in creating scalable, differentiable search indexes\nusing TensorFlow and PyTorch at production scale. In LiNR, both items and model\nweights are integrated into the model binary. Viewing index construction as a\nform of model training, we describe scaling our system for large indexes,\nincorporating full scans and efficient filtering. A key focus is on enabling\nattribute-based pre-filtering for exhaustive GPU searches, addressing the\ncommon challenge of post-filtering in KNN searches that often reduces system\nquality. We further provide multi-embedding retrieval algorithms and strategies\nfor tackling cold start issues in retrieval. Our advancements in supporting\nlarger indexes through quantization are also discussed. We believe LiNR\nrepresents one of the industry's first Live-updated model-based retrieval\nindexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR\nhas contributed to a 3% relative increase in professional daily active users.\nWe envisage LiNR as a step towards integrating retrieval and ranking into a\nsingle GPU model, simplifying complex infrastructures and enabling end-to-end\noptimization of the entire differentiable infrastructure through gradient\ndescent.",
      "tldr_zh": "这篇论文介绍了 LiNR 系统，这是 LinkedIn 基于 GPU 的神经检索系统，支持十亿级索引，通过 TensorFlow 和 PyTorch 构建可扩展、可微分搜索索引。LiNR 将索引构建视为模型训练过程，整合项目和模型权重，并采用属性-based pre-filtering、多嵌入检索算法以及量化技术来处理 KNN searches 中的后过滤问题和冷启动挑战。实验结果显示，在 LinkedIn Feed 的非网络帖子推荐应用中，LiNR 带来了 3% 的专业日活跃用户相对增长，并为将检索和排名整合到单一 GPU 模型中，实现端到端通过 gradient descent 优化提供了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13218v3",
      "published_date": "2024-07-18 07:04:33 UTC",
      "updated_date": "2024-08-07 16:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:02:06.168964"
    },
    {
      "arxiv_id": "2407.13806v1",
      "title": "Revisiting Attention for Multivariate Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Haixiang Wu"
      ],
      "abstract": "Current Transformer methods for Multivariate Time-Series Forecasting (MTSF)\nare all based on the conventional attention mechanism. They involve sequence\nembedding and performing a linear projection of Q, K, and V, and then computing\nattention within this latent space. We have never delved into the attention\nmechanism to explore whether such a mapping space is optimal for MTSF. To\ninvestigate this issue, this study first proposes Frequency Spectrum attention\n(FSatten), a novel attention mechanism based on the frequency domain space. It\nemploys the Fourier transform for embedding and introduces Multi-head Spectrum\nScaling (MSS) to replace the conventional linear mapping of Q and K. FSatten\ncan accurately capture the periodic dependencies between sequences and\noutperform the conventional attention without changing mainstream\narchitectures. We further design a more general method dubbed Scaled Orthogonal\nattention (SOatten). We propose an orthogonal embedding and a Head-Coupling\nConvolution (HCC) based on the neighboring similarity bias to guide the model\nin learning comprehensive dependency patterns. Experiments show that FSatten\nand SOatten surpass the SOTA which uses conventional attention, making it a\ngood alternative as a basic attention mechanism for MTSF. The codes and log\nfiles will be released at: https://github.com/Joeland4/FSatten-SOatten.",
      "tldr_zh": "本研究重新审视了Transformer在多变量时间序列预测(MTSF)中的传统注意力机制，质疑其潜在映射空间是否最优，并提出两种新型注意力机制作为替代。Frequency Spectrum attention (FSatten)基于频率域空间，使用Fourier transform进行序列嵌入，并引入Multi-head Spectrum Scaling (MSS)来替换传统的Q和K线性映射，从而准确捕获序列间的周期依赖。Scaled Orthogonal attention (SOatten)进一步设计了正交嵌入和Head-Coupling Convolution (HCC)，利用邻域相似性偏差学习全面的依赖模式。实验结果显示，FSatten和SOatten超越了使用传统注意力的SOTA模型，提供了一个更有效的MTSF基础机制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13806v1",
      "published_date": "2024-07-18 06:28:20 UTC",
      "updated_date": "2024-07-18 06:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:02:26.886712"
    },
    {
      "arxiv_id": "2407.13195v4",
      "title": "Scalable Thompson Sampling via Ensemble++ Agent",
      "title_zh": "基于 Ensemble++ Agent 的可扩展 Thompson Sampling",
      "authors": [
        "Yingru Li",
        "Jiawei Xu",
        "Baoxiang Wang",
        "Zhi-Quan Luo"
      ],
      "abstract": "Thompson Sampling is a principled method for balancing exploration and\nexploitation, but its real-world adoption is impeded by the high computational\noverhead of posterior maintenance in large-scale or non-conjugate settings.\nEnsemble-based approaches offer partial remedies, but often require a large\nensemble size. This paper proposes the Ensemble++, a scalable agent that\nsidesteps these limitations by a shared-factor ensemble update architecture and\na random linear combination scheme. We theoretically justify that in linear\nbandits, Ensemble++ agent only needs an ensemble size of $\\Theta(d \\log T)$ to\nachieve regret guarantees comparable to exact Thompson Sampling. Further, to\nhandle nonlinear rewards and complex environments. we introduce a neural\nextension that replaces fixed features with a learnable representation,\npreserving the same underlying objective via gradient-based updates. Empirical\nresults confirm that Ensemble++ agent excel in both sample efficiency and\ncomputational scalability across linear and nonlinear environments, including\nGPT-based contextual bandits.",
      "tldr_zh": "本文提出 Ensemble++ 代理，以解决 Thompson Sampling 在大规模或非共轭环境中计算开销大的问题，通过共享因子 ensemble 更新架构和随机线性组合方案实现高效平衡探索与利用。理论证明显示，在 linear bandits 中，Ensemble++ 仅需 Θ(d log T) 的 ensemble 大小即可达到与精确 Thompson Sampling 相当的 regret guarantees。对于非线性奖励和复杂环境，该方法引入神经扩展，使用可学习的表示并通过梯度-based 更新保持相同目标。实证结果表明，Ensemble++ 在 linear 和 nonlinear 环境（包括 GPT-based contextual bandits）中表现出色的样本效率和计算可伸缩性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "47 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.13195v4",
      "published_date": "2024-07-18 06:16:09 UTC",
      "updated_date": "2025-02-01 04:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:02:40.763093"
    },
    {
      "arxiv_id": "2407.13194v1",
      "title": "Robust Multivariate Time Series Forecasting against Intra- and Inter-Series Transitional Shift",
      "title_zh": "针对系列内部和系列之间转移偏移的鲁棒多变量时间序列预测",
      "authors": [
        "Hui He",
        "Qi Zhang",
        "Kun Yi",
        "Xiaojun Xue",
        "Shoujin Wang",
        "Liang Hu",
        "Longbing Cao"
      ],
      "abstract": "The non-stationary nature of real-world Multivariate Time Series (MTS) data\npresents forecasting models with a formidable challenge of the time-variant\ndistribution of time series, referred to as distribution shift. Existing\nstudies on the distribution shift mostly adhere to adaptive normalization\ntechniques for alleviating temporal mean and covariance shifts or time-variant\nmodeling for capturing temporal shifts. Despite improving model generalization,\nthese normalization-based methods often assume a time-invariant transition\nbetween outputs and inputs but disregard specific intra-/inter-series\ncorrelations, while time-variant models overlook the intrinsic causes of the\ndistribution shift. This limits model expressiveness and interpretability of\ntackling the distribution shift for MTS forecasting. To mitigate such a\ndilemma, we present a unified Probabilistic Graphical Model to Jointly\ncapturing intra-/inter-series correlations and modeling the time-variant\ntransitional distribution, and instantiate a neural framework called JointPGM\nfor non-stationary MTS forecasting. Specifically, JointPGM first employs\nmultiple Fourier basis functions to learn dynamic time factors and designs two\ndistinct learners: intra-series and inter-series learners. The intra-series\nlearner effectively captures temporal dynamics by utilizing temporal gates,\nwhile the inter-series learner explicitly models spatial dynamics through\nmulti-hop propagation, incorporating Gumbel-softmax sampling. These two types\nof series dynamics are subsequently fused into a latent variable, which is\ninversely employed to infer time factors, generate final prediction, and\nperform reconstruction. We validate the effectiveness and efficiency of\nJointPGM through extensive experiments on six highly non-stationary MTS\ndatasets, achieving state-of-the-art forecasting performance of MTS\nforecasting.",
      "tldr_zh": "本研究针对多变量时间序列 (Multivariate Time Series, MTS) 的非平稳特性及其分布偏移 (distribution shift)，特别是 intra-series 和 inter-series 转移问题，指出现有归一化技术和时间变异模型的局限性，如忽略特定相关性和内在原因。作者提出一个统一的 Probabilistic Graphical Model，用于同时捕捉 intra-/inter-series 相关性并建模时间变异的转移分布，并实例化为 JointPGM 框架，该框架利用多个 Fourier basis functions 学习动态时间因素，设计 intra-series 学习器（通过 temporal gates 捕捉时间动态）和 inter-series 学习器（通过 multi-hop propagation 和 Gumbel-softmax sampling 建模空间动态），并融合这些动态生成预测和重建。实验在六个高度非平稳的 MTS 数据集上验证了 JointPGM 的有效性，实现了最先进的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68Txx",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.13194v1",
      "published_date": "2024-07-18 06:16:03 UTC",
      "updated_date": "2024-07-18 06:16:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:02:52.238541"
    },
    {
      "arxiv_id": "2407.13182v1",
      "title": "SpaDiT: Diffusion Transformer for Spatial Gene Expression Prediction using scRNA-seq",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Li",
        "Fangfang Zhu",
        "Wenwen Min"
      ],
      "abstract": "The rapid development of spatial transcriptomics (ST) technologies is\nrevolutionizing our understanding of the spatial organization of biological\ntissues. Current ST methods, categorized into next-generation sequencing-based\n(seq-based) and fluorescence in situ hybridization-based (image-based) methods,\noffer innovative insights into the functional dynamics of biological tissues.\nHowever, these methods are limited by their cellular resolution and the\nquantity of genes they can detect. To address these limitations, we propose\nSpaDiT, a deep learning method that utilizes a diffusion generative model to\nintegrate scRNA-seq and ST data for the prediction of undetected genes. By\nemploying a Transformer-based diffusion model, SpaDiT not only accurately\npredicts unknown genes but also effectively generates the spatial structure of\nST genes. We have demonstrated the effectiveness of SpaDiT through extensive\nexperiments on both seq-based and image-based ST data. SpaDiT significantly\ncontributes to ST gene prediction methods with its innovative approach.\nCompared to eight leading baseline methods, SpaDiT achieved state-of-the-art\nperformance across multiple metrics, highlighting its substantial\nbioinformatics contribution.",
      "tldr_zh": "该研究提出SpaDiT，一种基于扩散生成模型的深度学习方法，用于整合scRNA-seq和空间转录组学(ST)数据，以预测未检测到的基因表达。SpaDiT采用Transformer-based扩散模型，不仅准确预测未知基因，还能生成ST基因的空间结构，从而解决现有seq-based和image-based ST方法的细胞分辨率和基因检测数量限制。通过广泛实验，SpaDiT在seq-based和image-based数据上表现出色，与八种领先基线方法相比，在多个指标上实现了最先进性能，为生物信息学领域贡献了创新性工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13182v1",
      "published_date": "2024-07-18 05:40:50 UTC",
      "updated_date": "2024-07-18 05:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:03:05.117018"
    },
    {
      "arxiv_id": "2407.13170v1",
      "title": "Unified-EGformer: Exposure Guided Lightweight Transformer for Mixed-Exposure Image Enhancement",
      "title_zh": "Unified-EGformer：曝光引导轻量级 Transformer 用于混合曝光图像增强",
      "authors": [
        "Eashan Adhikarla",
        "Kai Zhang",
        "Rosaura G. VidalMata",
        "Manjushree Aithal",
        "Nikhil Ambha Madhusudhana",
        "John Nicholson",
        "Lichao Sun",
        "Brian D. Davison"
      ],
      "abstract": "Despite recent strides made by AI in image processing, the issue of mixed\nexposure, pivotal in many real-world scenarios like surveillance and\nphotography, remains inadequately addressed. Traditional image enhancement\ntechniques and current transformer models are limited with primary focus on\neither overexposure or underexposure. To bridge this gap, we introduce the\nUnified-Exposure Guided Transformer (Unified-EGformer). Our proposed solution\nis built upon advanced transformer architectures, equipped with local\npixel-level refinement and global refinement blocks for color correction and\nimage-wide adjustments. We employ a guided attention mechanism to precisely\nidentify exposure-compromised regions, ensuring its adaptability across various\nreal-world conditions. U-EGformer, with a lightweight design featuring a memory\nfootprint (peak memory) of only $\\sim$1134 MB (0.1 Million parameters) and an\ninference time of 95 ms (9.61x faster than the average), is a viable choice for\nreal-time applications such as surveillance and autonomous navigation.\nAdditionally, our model is highly generalizable, requiring minimal fine-tuning\nto handle multiple tasks and datasets with a single architecture.",
      "tldr_zh": "本研究针对混合曝光图像增强问题（如监控和摄影中的过曝或欠曝），提出了Unified-EGformer，一种轻量级Transformer模型。该模型结合局部像素级精炼和全局精炼块，以及引导注意力机制（guided attention mechanism），实现精确的颜色校正和图像整体调整。Unified-EGformer在内存占用仅约1134 MB（0.1 Million参数）和推理时间95 ms（比平均快9.61倍）的情况下，表现出色，适用于实时应用；此外，它具有高度可泛化性，只需最小微调即可处理多种任务和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under submission",
      "pdf_url": "http://arxiv.org/pdf/2407.13170v1",
      "published_date": "2024-07-18 05:18:43 UTC",
      "updated_date": "2024-07-18 05:18:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:03:15.067937"
    },
    {
      "arxiv_id": "2407.13168v1",
      "title": "SciCode: A Research Coding Benchmark Curated by Scientists",
      "title_zh": "翻译失败",
      "authors": [
        "Minyang Tian",
        "Luyu Gao",
        "Shizhuo Dylan Zhang",
        "Xinan Chen",
        "Cunwei Fan",
        "Xuefei Guo",
        "Roland Haas",
        "Pan Ji",
        "Kittithat Krongchon",
        "Yao Li",
        "Shengyan Liu",
        "Di Luo",
        "Yutao Ma",
        "Hao Tong",
        "Kha Trinh",
        "Chenyu Tian",
        "Zihan Wang",
        "Bohao Wu",
        "Yanyu Xiong",
        "Shengzhu Yin",
        "Minhui Zhu",
        "Kilian Lieret",
        "Yanxin Lu",
        "Genglin Liu",
        "Yufeng Du",
        "Tianhua Tao",
        "Ofir Press",
        "Jamie Callan",
        "Eliu Huerta",
        "Hao Peng"
      ],
      "abstract": "Since language models (LMs) now outperform average humans on many challenging\ntasks, it has become increasingly difficult to develop challenging,\nhigh-quality, and realistic evaluations. We address this issue by examining\nLMs' capabilities to generate code for solving real scientific research\nproblems. Incorporating input from scientists and AI researchers in 16 diverse\nnatural science sub-fields, including mathematics, physics, chemistry, biology,\nand materials science, we created a scientist-curated coding benchmark,\nSciCode. The problems in SciCode naturally factorize into multiple subproblems,\neach involving knowledge recall, reasoning, and code synthesis. In total,\nSciCode contains 338 subproblems decomposed from 80 challenging main problems.\nIt offers optional descriptions specifying useful scientific background\ninformation and scientist-annotated gold-standard solutions and test cases for\nevaluation. Claude3.5-Sonnet, the best-performing model among those tested, can\nsolve only 4.6% of the problems in the most realistic setting. We believe that\nSciCode demonstrates both contemporary LMs' progress towards becoming helpful\nscientific assistants and sheds light on the development and evaluation of\nscientific AI in the future.",
      "tldr_zh": "本研究引入了 SciCode，这是一个由科学家策划的编码基准，用于评估语言模型 (LMs) 在解决真实科学研究问题的代码生成能力，涵盖数学、物理、化学、生物学和材料科学等 16 个子领域。SciCode 包含 80 个主要问题分解成的 338 个子问题，每个子问题涉及知识回忆、推理和代码合成，并提供可选的科学背景信息、科学家标注的金标准解决方案和测试用例。实验结果显示，最先进的模型 Claude3.5-Sonnet 在最现实设置下仅解决 4.6% 的问题，突显了 LMs 在科学领域的局限性。该基准不仅展示了当代 LMs 作为科学助手的潜在进步，还为未来科学 AI 的发展和评估提供了宝贵指导。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 9 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.13168v1",
      "published_date": "2024-07-18 05:15:24 UTC",
      "updated_date": "2024-07-18 05:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:03:29.776710"
    },
    {
      "arxiv_id": "2407.13164v1",
      "title": "Translate-and-Revise: Boosting Large Language Models for Constrained Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Pengcheng Huang",
        "Yongyu Mu",
        "Yuzhang Wu",
        "Bei Li",
        "Chunyang Xiao",
        "Tong Xiao",
        "Jingbo Zhu"
      ],
      "abstract": "Imposing constraints on machine translation systems presents a challenging\nissue because these systems are not trained to make use of constraints in\ngenerating adequate, fluent translations. In this paper, we leverage the\ncapabilities of large language models (LLMs) for constrained translation, given\nthat LLMs can easily adapt to this task by taking translation instructions and\nconstraints as prompts. However, LLMs cannot always guarantee the adequacy of\ntranslation, and, in some cases, ignore the given constraints. This is in part\nbecause LLMs might be overly confident in their predictions, overriding the\ninfluence of the constraints. To overcome this overiding behaviour, we propose\nto add a revision process that encourages LLMs to correct the outputs by\nprompting them about the constraints that have not yet been met. We evaluate\nour approach on four constrained translation tasks, encompassing both lexical\nand structural constraints in multiple constraint domains. Experiments show\n15\\% improvement in constraint-based translation accuracy over standard LLMs\nand the approach also significantly outperforms neural machine translation\n(NMT) state-of-the-art methods.",
      "tldr_zh": "这篇论文提出“Translate-and-Revise”方法，利用大型语言模型 (LLMs) 来提升约束翻译的性能，通过将翻译指令和约束作为提示来适应任务。方法的核心是添加一个修正过程，提示 LLMs 针对未满足的约束（如词汇或结构约束）进行输出校正，以缓解 LLMs 的过度自信问题。实验结果显示，该方法在四个约束翻译任务上比标准 LLMs 提高了 15% 的准确率，并显著优于神经机器翻译 (NMT) 的现有先进方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.13164v1",
      "published_date": "2024-07-18 05:08:09 UTC",
      "updated_date": "2024-07-18 05:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:03:38.780923"
    },
    {
      "arxiv_id": "2407.13163v2",
      "title": "ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zhang",
        "Ruihong Qiu",
        "Jiajun Liu",
        "Sen Wang"
      ],
      "abstract": "Offline reinforcement learning (RL) is an effective tool for real-world\nrecommender systems with its capacity to model the dynamic interest of users\nand its interactive nature. Most existing offline RL recommender systems focus\non model-based RL through learning a world model from offline data and building\nthe recommendation policy by interacting with this model. Although these\nmethods have made progress in the recommendation performance, the effectiveness\nof model-based offline RL methods is often constrained by the accuracy of the\nestimation of the reward model and the model uncertainties, primarily due to\nthe extreme discrepancy between offline logged data and real-world data in user\ninteractions with online platforms. To fill this gap, a more accurate reward\nmodel and uncertainty estimation are needed for the model-based RL methods. In\nthis paper, a novel model-based Reward Shaping in Offline Reinforcement\nLearning for Recommender Systems, ROLeR, is proposed for reward and uncertainty\nestimation in recommendation systems. Specifically, a non-parametric reward\nshaping method is designed to refine the reward model. In addition, a flexible\nand more representative uncertainty penalty is designed to fit the needs of\nrecommendation systems. Extensive experiments conducted on four benchmark\ndatasets showcase that ROLeR achieves state-of-the-art performance compared\nwith existing baselines. The source code can be downloaded at\nhttps://github.com/ArronDZhang/ROLeR.",
      "tldr_zh": "该论文针对离线强化学习(Offline RL)在推荐系统中的挑战，提出了一种新型框架ROLeR，以改进奖励模型的准确性和不确定性估计。ROLeR采用非参数奖励整形方法来精炼奖励模型，并设计了一个灵活的不确定性惩罚机制，以更好地适应推荐系统的用户交互动态。实验结果显示，在四个基准数据集上，ROLeR与现有基线相比取得了最先进性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13163v2",
      "published_date": "2024-07-18 05:07:11 UTC",
      "updated_date": "2025-05-12 05:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:04:00.345562"
    },
    {
      "arxiv_id": "2407.13157v1",
      "title": "Learning Camouflaged Object Detection from Noisy Pseudo Label",
      "title_zh": "从嘈杂伪标签中学习伪装物体检测",
      "authors": [
        "Jin Zhang",
        "Ruiheng Zhang",
        "Yanjiao Shi",
        "Zhe Cao",
        "Nian Liu",
        "Fahad Shahbaz Khan"
      ],
      "abstract": "Existing Camouflaged Object Detection (COD) methods rely heavily on\nlarge-scale pixel-annotated training sets, which are both time-consuming and\nlabor-intensive. Although weakly supervised methods offer higher annotation\nefficiency, their performance is far behind due to the unclear visual\ndemarcations between foreground and background in camouflaged images. In this\npaper, we explore the potential of using boxes as prompts in camouflaged scenes\nand introduce the first weakly semi-supervised COD method, aiming for\nbudget-efficient and high-precision camouflaged object segmentation with an\nextremely limited number of fully labeled images. Critically, learning from\nsuch limited set inevitably generates pseudo labels with serious noisy pixels.\nTo address this, we propose a noise correction loss that facilitates the\nmodel's learning of correct pixels in the early learning stage, and corrects\nthe error risk gradients dominated by noisy pixels in the memorization stage,\nultimately achieving accurate segmentation of camouflaged objects from noisy\nlabels. When using only 20% of fully labeled data, our method shows superior\nperformance over the state-of-the-art methods.",
      "tldr_zh": "本研究针对 Camouflaged Object Detection (COD) 的数据标注问题，提出一种弱半监督方法，使用 boxes 作为提示，仅需极少的全标注图像（如 20%）即可实现高效且高精度的 camouflaged object segmentation。针对从噪声伪标签中学习带来的挑战，该方法引入 noise correction loss，帮助模型在早期阶段优先学习正确像素，并在后续记忆阶段修正噪声像素主导的错误梯度。实验结果表明，该方法在性能上优于现有最先进方法，为降低 COD 训练成本提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.13157v1",
      "published_date": "2024-07-18 04:53:51 UTC",
      "updated_date": "2024-07-18 04:53:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:04:07.118172"
    },
    {
      "arxiv_id": "2408.02073v1",
      "title": "Case-based reasoning approach for diagnostic screening of children with developmental delays",
      "title_zh": "基于案例推理的方法，用于发育迟缓儿童的诊断筛查",
      "authors": [
        "Zichen Song",
        "Jiakang Li",
        "Songning Lai",
        "Sitan Huang"
      ],
      "abstract": "According to the World Health Organization, the population of children with\ndevelopmental delays constitutes approximately 6% to 9% of the total\npopulation. Based on the number of newborns in Huaibei, Anhui Province, China,\nin 2023 (94,420), it is estimated that there are about 7,500 cases (suspected\ncases of developmental delays) of suspicious cases annually. Early\nidentification and appropriate early intervention for these children can\nsignificantly reduce the wastage of medical resources and societal costs.\nInternational research indicates that the optimal period for intervention in\nchildren with developmental delays is before the age of six, with the golden\ntreatment period being before three and a half years of age. Studies have shown\nthat children with developmental delays who receive early intervention exhibit\nsignificant improvement in symptoms; some may even fully recover. This research\nadopts a hybrid model combining a CNN-Transformer model with Case-Based\nReasoning (CBR) to enhance the screening efficiency for children with\ndevelopmental delays. The CNN-Transformer model is an excellent model for image\nfeature extraction and recognition, effectively identifying features in bone\nage images to determine bone age. CBR is a technique for solving problems based\non similar cases; it solves current problems based on past experiences, similar\nto how humans solve problems through learning from experience. Given CBR's\nmemory capability to judge and compare new cases based on previously stored old\ncases, it is suitable for application in support systems with latent and\nvariable characteristics. Therefore, this study utilizes the\nCNN-Transformer-CBR to establish a screening system for children with\ndevelopmental delays, aiming to improve screening efficiency.",
      "tldr_zh": "本研究针对儿童发育迟缓问题（影响约6%至9%的人口），强调早期干预（如在三岁半前）的关键作用，以减少医疗资源和社会成本。研究提出了一种混合模型，将CNN-Transformer用于骨龄图像的特征提取和识别，并结合Case-Based Reasoning (CBR)技术，通过借鉴类似案例的经验进行诊断决策。该方法构建了CNN-Transformer-CBR筛查系统，旨在显著提高儿童发育迟缓的诊断效率，并为潜在的自主支持系统提供新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02073v1",
      "published_date": "2024-07-18 04:28:52 UTC",
      "updated_date": "2024-07-18 04:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:04:25.908847"
    },
    {
      "arxiv_id": "2408.00794v1",
      "title": "CCSRP: Robust Pruning of Spiking Neural Networks through Cooperative Coevolution",
      "title_zh": "CC",
      "authors": [
        "Zichen Song",
        "Jiakang Li",
        "Songning Lai",
        "Sitan Huang"
      ],
      "abstract": "Spiking neural networks (SNNs) have shown promise in various dynamic visual\ntasks, yet those ready for practical deployment often lack the compactness and\nrobustness essential in resource-limited and safety-critical settings. Prior\nresearch has predominantly concentrated on enhancing the compactness or\nrobustness of artificial neural networks through strategies like network\npruning and adversarial training, with little exploration into similar\nmethodologies for SNNs. Robust pruning of SNNs aims to reduce computational\noverhead while preserving both accuracy and robustness. Current robust pruning\napproaches generally necessitate expert knowledge and iterative experimentation\nto establish suitable pruning criteria or auxiliary modules, thus constraining\ntheir broader application. Concurrently, evolutionary algorithms (EAs) have\nbeen employed to automate the pruning of artificial neural networks, delivering\nremarkable outcomes yet overlooking the aspect of robustness. In this work, we\npropose CCSRP, an innovative robust pruning method for SNNs, underpinned by\ncooperative co-evolution. Robust pruning is articulated as a tri-objective\noptimization challenge, striving to balance accuracy, robustness, and\ncompactness concurrently, resolved through a cooperative co-evolutionary\npruning framework that independently prunes filters across layers using EAs.\nOur experiments on CIFAR-10 and SVHN demonstrate that CCSRP can match or exceed\nthe performance of the latest methodologies.",
      "tldr_zh": "本研究针对Spiking Neural Networks (SNNs)在资源有限和安全关键环境中部署时存在的紧凑性和鲁棒性问题，提出了一种创新方法CCSRP，通过Cooperative Coevolution实现SNNs的鲁棒剪枝。CCSRP将剪枝问题表述为三目标优化挑战，即同时平衡准确性、鲁棒性和紧凑性，并利用Evolutionary Algorithms (EAs)独立剪枝各层的过滤器，避免了传统方法依赖专家知识和迭代实验的局限。实验结果显示，在CIFAR-10和SVHN数据集上，CCSRP的性能可与或超过最新方法，显著提升了SNNs的实用性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.00794v1",
      "published_date": "2024-07-18 04:28:16 UTC",
      "updated_date": "2024-07-18 04:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:04:27.880908"
    },
    {
      "arxiv_id": "2407.13146v2",
      "title": "PG-Rainbow: Using Distributional Reinforcement Learning in Policy Gradient Methods",
      "title_zh": "翻译失败",
      "authors": [
        "WooJae Jeon",
        "KangJun Lee",
        "Jeewoo Lee"
      ],
      "abstract": "This paper introduces PG-Rainbow, a novel algorithm that incorporates a\ndistributional reinforcement learning framework with a policy gradient\nalgorithm. Existing policy gradient methods are sample inefficient and rely on\nthe mean of returns when calculating the state-action value function,\nneglecting the distributional nature of returns in reinforcement learning\ntasks. To address this issue, we use an Implicit Quantile Network that provides\nthe quantile information of the distribution of rewards to the critic network\nof the Proximal Policy Optimization algorithm. We show empirical results that\nthrough the integration of reward distribution information into the policy\nnetwork, the policy agent acquires enhanced capabilities to comprehensively\nevaluate the consequences of potential actions in a given state, facilitating\nmore sophisticated and informed decision-making processes. We evaluate the\nperformance of the proposed algorithm in the Atari-2600 game suite, simulated\nvia the Arcade Learning Environment (ALE).",
      "tldr_zh": "本论文提出 PG-Rainbow 算法，将 Distributional Reinforcement Learning 框架整合到 Policy Gradient Methods 中，以解决现有方法样本效率低和仅依赖回报均值的问题。\n该算法使用 Implicit Quantile Network 向 Proximal Policy Optimization (PPO) 的批评者网络提供回报分布的 quantile 信息，帮助代理更全面评估动作后果并提升决策过程。\n实验在 Atari-2600 游戏套件上通过 Arcade Learning Environment (ALE) 进行评估，结果显示 PG-Rainbow 显著提高了代理的性能和决策能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13146v2",
      "published_date": "2024-07-18 04:18:52 UTC",
      "updated_date": "2024-07-19 02:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:04:42.119744"
    },
    {
      "arxiv_id": "2407.13122v1",
      "title": "MO-EMT-NAS: Multi-Objective Continuous Transfer of Architectural Knowledge Between Tasks from Different Datasets",
      "title_zh": "MO-EMT-NAS：多目标连续架构知识在不同数据集任务之间的转移",
      "authors": [
        "Peng Liao",
        "XiLu Wang",
        "Yaochu Jin",
        "WenLi Du"
      ],
      "abstract": "Deploying models across diverse devices demands tradeoffs among multiple\nobjectives due to different resource constraints. Arguably, due to the small\nmodel trap problem in multi-objective neural architecture search (MO-NAS) based\non a supernet, existing approaches may fail to maintain large models. Moreover,\nmulti-tasking neural architecture search (MT-NAS) excels in handling multiple\ntasks simultaneously, but most existing efforts focus on tasks from the same\ndataset, limiting their practicality in real-world scenarios where multiple\ntasks may come from distinct datasets. To tackle the above challenges, we\npropose a Multi-Objective Evolutionary Multi-Tasking framework for NAS\n(MO-EMT-NAS) to achieve architectural knowledge transfer across tasks from\ndifferent datasets while finding Pareto optimal architectures for\nmulti-objectives, model accuracy and computational efficiency. To alleviate the\nsmall model trap issue, we introduce an auxiliary objective that helps maintain\nmultiple larger models of similar accuracy. Moreover, the computational\nefficiency is further enhanced by parallelizing the training and validation of\nthe weight-sharing-based supernet. Experimental results on seven datasets with\ntwo, three, and four task combinations show that MO-EMT-NAS achieves a better\nminimum classification error while being able to offer flexible trade-offs\nbetween model performance and complexity, compared to the state-of-the-art\nsingle-objective MT-NAS algorithms. The runtime of MO-EMT-NAS is reduced by\n59.7% to 77.7%, compared to the corresponding multi-objective single-task\napproaches.",
      "tldr_zh": "本研究提出 MO-EMT-NAS 框架，这是一种多目标进化多任务神经架构搜索 (MO-EMT-NAS) 方法，用于在不同数据集的任务之间转移架构知识，同时优化模型准确性和计算效率。框架通过引入辅助目标来缓解多目标神经架构搜索 (MO-NAS) 中的小模型陷阱问题，并通过并行化训练和验证来提升计算效率。实验结果显示，在七个数据集上处理二至四个任务组合时，MO-EMT-NAS 比现有单目标多任务神经架构搜索 (MT-NAS) 算法实现了更低的分类错误率、更灵活的性能与复杂度权衡，并将运行时间减少了 59.7% 到 77.7%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13122v1",
      "published_date": "2024-07-18 03:12:35 UTC",
      "updated_date": "2024-07-18 03:12:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:04:54.993889"
    },
    {
      "arxiv_id": "2407.13113v1",
      "title": "Multiobjective Vehicle Routing Optimization with Time Windows: A Hybrid Approach Using Deep Reinforcement Learning and NSGA-II",
      "title_zh": "多目标车辆路径优化问题（含时间",
      "authors": [
        "Rixin Wu",
        "Ran Wang",
        "Jie Hao",
        "Qiang Wu",
        "Ping Wang",
        "Dusit Niyato"
      ],
      "abstract": "This paper proposes a weight-aware deep reinforcement learning (WADRL)\napproach designed to address the multiobjective vehicle routing problem with\ntime windows (MOVRPTW), aiming to use a single deep reinforcement learning\n(DRL) model to solve the entire multiobjective optimization problem. The\nNon-dominated sorting genetic algorithm-II (NSGA-II) method is then employed to\noptimize the outcomes produced by the WADRL, thereby mitigating the limitations\nof both approaches. Firstly, we design an MOVRPTW model to balance the\nminimization of travel cost and the maximization of customer satisfaction.\nSubsequently, we present a novel DRL framework that incorporates a\ntransformer-based policy network. This network is composed of an encoder\nmodule, a weight embedding module where the weights of the objective functions\nare incorporated, and a decoder module. NSGA-II is then utilized to optimize\nthe solutions generated by WADRL. Finally, extensive experimental results\ndemonstrate that our method outperforms the existing and traditional methods.\nDue to the numerous constraints in VRPTW, generating initial solutions of the\nNSGA-II algorithm can be time-consuming. However, using solutions generated by\nthe WADRL as initial solutions for NSGA-II significantly reduces the time\nrequired for generating initial solutions. Meanwhile, the NSGA-II algorithm can\nenhance the quality of solutions generated by WADRL, resulting in solutions\nwith better scalability. Notably, the weight-aware strategy significantly\nreduces the training time of DRL while achieving better results, enabling a\nsingle DRL model to solve the entire multiobjective optimization problem.",
      "tldr_zh": "这篇论文提出了一种 weight-aware deep reinforcement learning (WADRL) 方法，用于解决 multiobjective vehicle routing problem with time windows (MOVRPTW)，旨在通过单一 DRL 模型平衡旅行成本最小化和客户满意度最大化。方法采用基于 Transformer 的框架，包括 encoder、weight embedding 和 decoder 模块，以整合目标函数权重。接着，利用 Non-dominated sorting genetic algorithm-II (NSGA-II) 优化 WADRL 生成的解决方案，从而克服两者局限，提升整体效率。实验结果显示，该混合方法优于现有和传统方法，显著减少了训练时间并提高了解决方案的质量和可扩展性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages; Under Review; Submitted to IEEE Transactions on Intelligent\n  Transportation Systems",
      "pdf_url": "http://arxiv.org/pdf/2407.13113v1",
      "published_date": "2024-07-18 02:46:06 UTC",
      "updated_date": "2024-07-18 02:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:05:04.972750"
    },
    {
      "arxiv_id": "2407.13101v2",
      "title": "Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with an Iterative Approach",
      "title_zh": "检索、总结、规划：通过迭代方法推进多跳问答",
      "authors": [
        "Zhouyu Jiang",
        "Mengshu Sun",
        "Lei Liang",
        "Zhiqiang Zhang"
      ],
      "abstract": "Multi-hop question answering is a challenging task with distinct industrial\nrelevance, and Retrieval-Augmented Generation (RAG) methods based on large\nlanguage models (LLMs) have become a popular approach to tackle this task.\nOwing to the potential inability to retrieve all necessary information in a\nsingle iteration, a series of iterative RAG methods has been recently\ndeveloped, showing significant performance improvements. However, existing\nmethods still face two critical challenges: context overload resulting from\nmultiple rounds of retrieval, and over-planning and repetitive planning due to\nthe lack of a recorded retrieval trajectory. In this paper, we propose a novel\niterative RAG method called ReSP, equipped with a dual-function summarizer.\nThis summarizer compresses information from retrieved documents, targeting both\nthe overarching question and the current sub-question concurrently.\nExperimental results on the multi-hop question-answering datasets HotpotQA and\n2WikiMultihopQA demonstrate that our method significantly outperforms the\nstate-of-the-art, and exhibits excellent robustness concerning context length.",
      "tldr_zh": "本论文针对多跳问题回答（Multi-hop Question Answering）的挑战，提出了一种新型迭代 RAG（Retrieval-Augmented Generation）方法ReSP，以解决现有方法的上下文过载（context overload）和过度规划问题。ReSP 配备了一个双功能总结器（dual-function summarizer），它同时压缩检索文档的信息，针对整体问题和当前子问题进行处理，从而提升信息利用效率。实验结果在HotpotQA和2WikiMultihopQA数据集上表明，ReSP显著优于最先进方法，并在上下文长度方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by WWW2025 Agent4IR Workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.13101v2",
      "published_date": "2024-07-18 02:19:00 UTC",
      "updated_date": "2025-01-30 04:51:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:05:18.568755"
    },
    {
      "arxiv_id": "2408.01428v1",
      "title": "Transferable Adversarial Facial Images for Privacy Protection",
      "title_zh": "可转移对抗面部图像用于隐私保护",
      "authors": [
        "Minghui Li",
        "Jiangxiong Wang",
        "Hao Zhang",
        "Ziqi Zhou",
        "Shengshan Hu",
        "Xiaobing Pei"
      ],
      "abstract": "The success of deep face recognition (FR) systems has raised serious privacy\nconcerns due to their ability to enable unauthorized tracking of users in the\ndigital world. Previous studies proposed introducing imperceptible adversarial\nnoises into face images to deceive those face recognition models, thus\nachieving the goal of enhancing facial privacy protection. Nevertheless, they\nheavily rely on user-chosen references to guide the generation of adversarial\nnoises, and cannot simultaneously construct natural and highly transferable\nadversarial face images in black-box scenarios. In light of this, we present a\nnovel face privacy protection scheme with improved transferability while\nmaintain high visual quality. We propose shaping the entire face space directly\ninstead of exploiting one kind of facial characteristic like makeup information\nto integrate adversarial noises. To achieve this goal, we first exploit global\nadversarial latent search to traverse the latent space of the generative model,\nthereby creating natural adversarial face images with high transferability. We\nthen introduce a key landmark regularization module to preserve the visual\nidentity information. Finally, we investigate the impacts of various kinds of\nlatent spaces and find that $\\mathcal{F}$ latent space benefits the trade-off\nbetween visual naturalness and adversarial transferability. Extensive\nexperiments over two datasets demonstrate that our approach significantly\nenhances attack transferability while maintaining high visual quality,\noutperforming state-of-the-art methods by an average 25% improvement in deep FR\nmodels and 10% improvement on commercial FR APIs, including Face++, Aliyun, and\nTencent.",
      "tldr_zh": "该研究针对深度面部识别（FR）系统的隐私风险，提出了一种新型对抗面部图像生成方案，以提升隐私保护效果。该方法通过全局对抗潜在搜索（adversarial latent search）直接塑造整个面部空间，生成自然且高转移性的对抗图像，同时引入关键地标正则化模块（landmark regularization module）来保留视觉身份信息。实验在两个数据集上表明，该方案显著提高了攻击转移性，在深度FR模型上平均提升25%，在商业FR API（如Face++、Aliyun和Tencent）上提升10%，优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01428v1",
      "published_date": "2024-07-18 02:16:11 UTC",
      "updated_date": "2024-07-18 02:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:05:28.324564"
    },
    {
      "arxiv_id": "2407.13091v1",
      "title": "On Causally Disentangled State Representation Learning for Reinforcement Learning based Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Wang",
        "Xiaocong Chen",
        "Lina Yao"
      ],
      "abstract": "In Reinforcement Learning-based Recommender Systems (RLRS), the complexity\nand dynamism of user interactions often result in high-dimensional and noisy\nstate spaces, making it challenging to discern which aspects of the state are\ntruly influential in driving the decision-making process. This issue is\nexacerbated by the evolving nature of user preferences and behaviors, requiring\nthe recommender system to adaptively focus on the most relevant information for\ndecision-making while preserving generaliability. To tackle this problem, we\nintroduce an innovative causal approach for decomposing the state and\nextracting \\textbf{C}ausal-\\textbf{I}n\\textbf{D}ispensable \\textbf{S}tate\nRepresentations (CIDS) in RLRS. Our method concentrates on identifying the\n\\textbf{D}irectly \\textbf{A}ction-\\textbf{I}nfluenced \\textbf{S}tate Variables\n(DAIS) and \\textbf{A}ction-\\textbf{I}nfluence \\textbf{A}ncestors (AIA), which\nare essential for making effective recommendations. By leveraging conditional\nmutual information, we develop a framework that not only discerns the causal\nrelationships within the generative process but also isolates critical state\nvariables from the typically dense and high-dimensional state representations.\nWe provide theoretical evidence for the identifiability of these variables.\nThen, by making use of the identified causal relationship, we construct\ncausal-indispensable state representations, enabling the training of policies\nover a more advantageous subset of the agent's state space. We demonstrate the\nefficacy of our approach through extensive experiments, showcasing our method\noutperforms state-of-the-art methods.",
      "tldr_zh": "本研究针对基于强化学习（Reinforcement Learning）的推荐系统（RLRS）中，高维噪声状态空间和动态用户偏好带来的决策挑战，提出了一种因果分解方法来学习因果不可或缺的状态表示（Causal-Indispensable State Representations, CIDS）。该方法通过识别直接受动作影响的状态变量（Directly Action-Influenced State Variables, DAIS）和动作影响祖先（Action-Influence Ancestors, AIA），并利用条件互信息（conditional mutual information）来辨识因果关系，从而构建更有效的状态子空间。研究提供了这些变量的可识别性理论证明，并在广泛实验中证明，该方法优于现有技术，提升了推荐系统的决策性能。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13091v1",
      "published_date": "2024-07-18 01:41:05 UTC",
      "updated_date": "2024-07-18 01:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:05:40.115517"
    },
    {
      "arxiv_id": "2407.13089v2",
      "title": "MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking",
      "title_zh": "MetaSumPerceiver：多模态多文档证据摘要用于",
      "authors": [
        "Ting-Chih Chen",
        "Chia-Wei Tang",
        "Chris Thomas"
      ],
      "abstract": "Fact-checking real-world claims often requires reviewing multiple multimodal\ndocuments to assess a claim's truthfulness, which is a highly laborious and\ntime-consuming task. In this paper, we present a summarization model designed\nto generate claim-specific summaries useful for fact-checking from multimodal,\nmulti-document datasets. The model takes inputs in the form of documents,\nimages, and a claim, with the objective of assisting in fact-checking tasks. We\nintroduce a dynamic perceiver-based model that can handle inputs from multiple\nmodalities of arbitrary lengths. To train our model, we leverage a novel\nreinforcement learning-based entailment objective to generate summaries that\nprovide evidence distinguishing between different truthfulness labels. To\nassess the efficacy of our approach, we conduct experiments on both an existing\nbenchmark and a new dataset of multi-document claims that we contribute. Our\napproach outperforms the SOTA approach by 4.6% in the claim verification task\non the MOCHEG dataset and demonstrates strong performance on our new\nMulti-News-Fact-Checking dataset.",
      "tldr_zh": "本文提出 MetaSumPerceiver 模型，用于从多模态多文档数据集生成针对特定声明的证据摘要，以辅助事实核查任务。该模型基于动态 Perceiver 处理任意长度的多模态输入（如文档和图像），并采用新型强化学习-based entailment 目标训练，确保生成的摘要能区分不同真实性标签。在实验中，该方法在 MOCHEG 数据集上将声明验证任务准确率比现有最佳方法提高 4.6%，并在新数据集 Multi-News-Fact-Checking 上表现出色。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 7 figures, The 62nd Annual Meeting of the Association for\n  Computational Linguistics",
      "pdf_url": "http://arxiv.org/pdf/2407.13089v2",
      "published_date": "2024-07-18 01:33:20 UTC",
      "updated_date": "2024-09-20 03:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:05:53.162759"
    },
    {
      "arxiv_id": "2407.18961v3",
      "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Guoli Yin",
        "Haoping Bai",
        "Shuang Ma",
        "Feng Nan",
        "Yanchao Sun",
        "Zhaoyang Xu",
        "Shen Ma",
        "Jiarui Lu",
        "Xiang Kong",
        "Aonan Zhang",
        "Dian Ang Yap",
        "Yizhe zhang",
        "Karsten Ahnert",
        "Vik Kamath",
        "Mathias Berglund",
        "Dominic Walsh",
        "Tobias Gindele",
        "Juergen Wiest",
        "Zhengfeng Lai",
        "Xiaoming Wang",
        "Jiulong Shan",
        "Meng Cao",
        "Ruoming Pang",
        "Zirui Wang"
      ],
      "abstract": "Recent advances in large language models (LLMs) have increased the demand for\ncomprehensive benchmarks to evaluate their capabilities as human-like agents.\nExisting benchmarks, while useful, often focus on specific application\nscenarios, emphasizing task completion but failing to dissect the underlying\nskills that drive these outcomes. This lack of granularity makes it difficult\nto deeply discern where failures stem from. Additionally, setting up these\nenvironments requires considerable effort, and issues of unreliability and\nreproducibility sometimes arise, especially in interactive tasks. To address\nthese limitations, we introduce the Massive Multitask Agent Understanding\n(MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need\nfor complex environment setups. It evaluates models across five domains,\nincluding Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine\nLearning coding, Contest-level programming and Mathematics, and covers five\nessential capabilities: Understanding, Reasoning, Planning, Problem-solving,\nand Self-correction. With a total of 20 meticulously designed tasks\nencompassing over 3K distinct prompts, MMAU provides a comprehensive framework\nfor evaluating the strengths and limitations of LLM agents. By testing 18\nrepresentative models on MMAU, we provide deep and insightful analyses.\nUltimately, MMAU not only sheds light on the capabilities and limitations of\nLLM agents but also enhances the interpretability of their performance.\nDatasets and evaluation scripts of MMAU are released at\nhttps://github.com/apple/axlearn/tree/main/docs/research/mmau.",
      "tldr_zh": "该研究引入了 MMAU 基准，这是一个全面的评估框架，用于测试大型语言模型 (LLMs) 作为人类-like 代理的能力，旨在解决现有基准的局限性，如任务导向偏见和环境设置复杂问题。MMAU 涵盖五个领域（包括 Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine Learning coding, Contest-level programming 和 Mathematics），并评估五个关键能力（Understanding, Reasoning, Planning, Problem-solving 和 Self-correction），通过20个精心设计的离线任务和超过3K个提示进行测试。实验中，研究者评估了18个代表性模型，提供深入分析，揭示了LLM代理的强项与局限性，并提升了性能的可解释性。数据集和评估脚本已在GitHub开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.18961v3",
      "published_date": "2024-07-18 00:58:41 UTC",
      "updated_date": "2024-08-15 21:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:06:08.092836"
    },
    {
      "arxiv_id": "2407.13078v1",
      "title": "Enhancing Temporal Action Localization: Advanced S6 Modeling with Recurrent Mechanism",
      "title_zh": "增强时序动作定位：高级 S6 建模与循环机制",
      "authors": [
        "Sangyoun Lee",
        "Juho Jung",
        "Changdae Oh",
        "Sunghee Yun"
      ],
      "abstract": "Temporal Action Localization (TAL) is a critical task in video analysis,\nidentifying precise start and end times of actions. Existing methods like CNNs,\nRNNs, GCNs, and Transformers have limitations in capturing long-range\ndependencies and temporal causality. To address these challenges, we propose a\nnovel TAL architecture leveraging the Selective State Space Model (S6). Our\napproach integrates the Feature Aggregated Bi-S6 block, Dual Bi-S6 structure,\nand a recurrent mechanism to enhance temporal and channel-wise dependency\nmodeling without increasing parameter complexity. Extensive experiments on\nbenchmark datasets demonstrate state-of-the-art results with mAP scores of\n74.2% on THUMOS-14, 42.9% on ActivityNet, 29.6% on FineAction, and 45.8% on\nHACS. Ablation studies validate our method's effectiveness, showing that the\nDual structure in the Stem module and the recurrent mechanism outperform\ntraditional approaches. Our findings demonstrate the potential of S6-based\nmodels in TAL tasks, paving the way for future research.",
      "tldr_zh": "该论文针对Temporal Action Localization (TAL)任务提出了一种新型架构，以解决现有方法（如CNNs、RNNs、GCNs和Transformers）在捕捉长程依赖性和时间因果关系方面的局限性。研究引入了Selective State Space Model (S6)，结合Feature Aggregated Bi-S6 block、Dual Bi-S6 structure和recurrent mechanism，提升了时间和通道依赖建模，同时保持参数复杂度不变。实验在基准数据集上取得了最先进成果，包括THUMOS-14的74.2% mAP、ActivityNet的42.9% mAP、FineAction的29.6% mAP和HACS的45.8% mAP；消融研究进一步证实了Dual structure和recurrent mechanism的有效性，为S6-based模型在TAL任务中的应用开辟了新路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 3 figures, Preprint",
      "pdf_url": "http://arxiv.org/pdf/2407.13078v1",
      "published_date": "2024-07-18 00:57:37 UTC",
      "updated_date": "2024-07-18 00:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:06:19.681734"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 99,
  "processed_papers_count": 99,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T08:06:43.436586"
}