{
  "date": "2025-01-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-24 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 101 篇论文，主要聚焦 AI 和大型语言模型（LLM）的优化、多代理协作、医疗图像处理以及高效机器学习方法等领域。重点包括 LLM 在数学推理和多代理系统中的突破性进展，以及高效的视觉和生物医学应用；令人印象深刻的文章有 \"Humanity's Last Exam\"，它测试 LLM 在人类知识极限上的性能；有名学者如 Andrew Ng 参与的医疗 AI 论文也值得关注。\n\n以下是今日论文的精选摘要，我将优先讨论重要、相关或有话题度的文章（如 AI 安全、LLM 优化和医疗应用），并快速掠过其他较常规的论文。每篇论文的标题以中文 + 英文形式列出，重点突出核心贡献和发现。\n\n### 重点论文讨论\n\n1. **Humanity's Last Exam（人类最后的考试）**  \n   这篇论文提出一个多模态基准测试，评估 LLM 在人类知识前沿的性能，包括数学、人文和自然科学。贡献：创建了 2500 个问题的数据集，揭示当前 LLM 在封闭式问题上远低于人类专家水平，强调 LLM 能力的局限性。该研究由众多作者参与，包括知名学者如 Andrew Ng，对 LLM 评估领域有重大影响。\n\n2. **RL + Transformer = A General-Purpose Problem Solver（RL + Transformer = 通用问题求解器）**  \n   论文探索强化学习（RL）和 Transformer 的结合，开发 In-Context Reinforcement Learning（ICRL），使模型能自学解决新问题。贡献：模型在未见环境中表现出色，实现了高效元学习（meta-learning），并展示了鲁棒性和适应性，标志着 LLM 向通用智能迈进。\n\n3. **Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game（多代理 KTO：强化大型语言模型在语言游戏中的战略互动）**  \n   通过 Kahneman-Tversky Optimization（KTO），论文优化多代理 LLM 在社交游戏（如 Werewolf）中的协作。贡献：模型在多代理系统中实现 61% 的胜率，超越 GPT-4o 和传统 RL 代理，展示了 LLM 在动态交互中的潜力。\n\n4. **OpenAI's Approach to External Red Teaming for AI Models and Systems（OpenAI 的外部红队测试方法）**  \n   OpenAI 作者讨论红队测试在 AI 风险评估中的作用。贡献：提出标准化红队设计，包括风险发现和指标丰富，提升 AI 安全性和可信度。该论文由 OpenAI 团队发布，具有实际部署价值。\n\n5. **FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks（FedAGHN：使用注意力图超网络的个性化联邦学习）**  \n   论文提出 FedAGHN 框架，优化联邦学习中的数据异质性。贡献：通过注意力机制动态捕捉客户端协作关系，提高模型个性化精度，在基准数据集上平均提升 23.8% 准确率，适用于隐私敏感的分布式场景。\n\n6. **LLM4DistReconfig: A Fine-tuned Large Language Model for Power Distribution Network Reconfiguration（LLM4DistReconfig：用于电力分配网络重构的微调大型语言模型）**  \n   利用微调 LLM 解决电力网络重构问题。贡献：模型预测最优配置，减少系统损失并加速推理，在实际数据集上表现优异，扩展 LLM 到能源管理领域。\n\n7. **CASE-Bench: Context-Aware SafEty Benchmark for Large Language Models（CASE-Bench：面向大型语言模型的上下文感知安全基准）**  \n   论文引入上下文感知安全基准测试 LLM。贡献：基于 Contextual Integrity 理论设计基准，揭示上下文对安全判断的影响，实验显示人类判断与 LLM 响应存在明显不匹配，促进 AI 安全评估。\n\n8. **ExPerT: Effective and Explainable Evaluation of Personalized Long-Form Text Generation（ExPerT：个性化长文本生成的有效且可解释评估）**  \n   提出 ExPerT 框架评估 LLM 的个性化文本生成。贡献：使用 LLM 提取原子方面并匹配评估，提高了 7.2% 与人类判断的一致性，并提供细粒度解释，提升文本生成的可解释性。\n\n9. **ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte Assessment in Breast Cancer（ECTIL：乳腺癌中标签高效的肿瘤浸润淋巴细胞计算评估）**  \n   Andrew Ng 等作者开发高效标签模型评估乳腺癌。贡献：使用深度学习提取特征，训练集减少百倍仍保持高准确率（AUC=0.85），并与临床数据关联，提高癌症诊断效率。\n\n10. **Point-LN: A Lightweight Framework for Efficient Point Cloud Classification（Point-LN：高效点云分类的轻量框架）**  \n    论文提出轻量点云分类框架 Point-LN。贡献：结合非参数位置编码和可学习分类器，在基准数据集上实现高效分类，减少计算开销，是资源受限设备的实用方案。\n\n### 其他论文快速掠过\n其余论文涉及主题如图像重建、强化学习和推荐系统，但相对常规或不那么前沿，以下简要概述：\n- **Motion-enhancement to Echocardiography Segmentation（运动增强心超图像分割）**：使用时序注意力模块改善心脏图像分割，贡献：提升分割准确率，适用于医疗图像处理。\n- **SwiftPrune: Hessian-Free Weight Pruning for Large Language Models（SwiftPrune：无 Hessian 矩阵的 LLM 权重剪枝）**：提出高效剪枝方法，贡献：加速 LLM 压缩，平均提速 12.29 倍。\n- **GraPPI: A Retrieve-Divide-Solve GraphRAG Framework（GraPPI：检索-划分-求解的 GraphRAG 框架）**：用于蛋白质交互探索，贡献：分解分析路径，提高药物发现效率。\n- **STAMP: Scalable Task And Model-agnostic Collaborative Perception（STAMP：可扩展任务和模型无关的协作感知）**：优化多代理视觉协作，贡献：减少计算成本，提升自动驾驶性能。\n- 其他如 **VarDrop**（时间序列预测优化）、**Dreamweaver**（视频世界模型学习）和 **TFG-Flow**（多模态生成引导）等，均聚焦高效算法改进，但细节较琐碎，仅提升特定任务效率。\n\n总之，今天的论文突显 AI 模型的优化和实际应用潜力，LLM 在推理和协作上的进展尤其引人注目。感兴趣的读者可关注这些前沿主题，助力 AI 研究！（约 800 字）",
  "papers": [
    {
      "arxiv_id": "2501.14980v1",
      "title": "A Deep State Space Model for Rainfall-Runoff Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Yihan Wang",
        "Lujun Zhang",
        "Annan Yu",
        "N. Benjamin Erichson",
        "Tiantian Yang"
      ],
      "abstract": "The classical way of studying the rainfall-runoff processes in the water\ncycle relies on conceptual or physically-based hydrologic models. Deep learning\n(DL) has recently emerged as an alternative and blossomed in hydrology\ncommunity for rainfall-runoff simulations. However, the decades-old Long\nShort-Term Memory (LSTM) network remains the benchmark for this task,\noutperforming newer architectures like Transformers. In this work, we propose a\nState Space Model (SSM), specifically the Frequency Tuned Diagonal State Space\nSequence (S4D-FT) model, for rainfall-runoff simulations. The proposed S4D-FT\nis benchmarked against the established LSTM and a physically-based Sacramento\nSoil Moisture Accounting model across 531 watersheds in the contiguous United\nStates (CONUS). Results show that S4D-FT is able to outperform the LSTM model\nacross diverse regions. Our pioneering introduction of the S4D-FT for\nrainfall-runoff simulations challenges the dominance of LSTM in the hydrology\ncommunity and expands the arsenal of DL tools available for hydrological\nmodeling.",
      "tldr_zh": "本研究提出了一种基于 State Space Model 的深度学习模型，即 Frequency Tuned Diagonal State Space Sequence (S4D-FT)，用于模拟降雨-径流过程，以替代传统的概念或物理基础水文模型。S4D-FT 与经典的 Long Short-Term Memory (LSTM) 网络以及 Sacramento Soil Moisture Accounting 模型在 531 个美国本土流域进行比较，结果显示 S4D-FT 在不同区域的表现优于 LSTM。这项工作挑战了 LSTM 在水文社区的基准地位，并扩展了深度学习工具在水文建模中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14980v1",
      "published_date": "2025-01-24 23:31:42 UTC",
      "updated_date": "2025-01-24 23:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:47:33.571312"
    },
    {
      "arxiv_id": "2501.14970v1",
      "title": "AI-driven Wireless Positioning: Fundamentals, Standards, State-of-the-art, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Guangjin Pan",
        "Yuan Gao",
        "Yilin Gao",
        "Zhiyong Zhong",
        "Xiaoyu Yang",
        "Xinyu Guo",
        "Shugong Xu"
      ],
      "abstract": "Wireless positioning technologies hold significant value for applications in\nautonomous driving, extended reality (XR), unmanned aerial vehicles (UAVs), and\nmore. With the advancement of artificial intelligence (AI), leveraging AI to\nenhance positioning accuracy and robustness has emerged as a field full of\npotential. Driven by the requirements and functionalities defined in the 3rd\nGeneration Partnership Project (3GPP) standards, AI/machine learning (ML)-based\npositioning is becoming a key technology to overcome the limitations of\ntraditional methods. This paper begins with an introduction to the fundamentals\nof AI and wireless positioning, covering AI models, algorithms, positioning\napplications, emerging wireless technologies, and the basics of positioning\ntechniques. Subsequently, focusing on standardization progress, we provide a\ncomprehensive review of the evolution of 3GPP positioning standards, with an\nemphasis on the integration of AI/ML technologies in recent and upcoming\nreleases. Based on the AI/ML-assisted positioning and direct AI/ML positioning\nschemes outlined in the standards, we conduct an in-depth investigation of\nrelated research. we focus on state-of-the-art (SOTA) research in AI-based\nline-of-sight (LOS)/non-line-of-sight (NLOS) detection, time of arrival\n(TOA)/time difference of arrival (TDOA) estimation, and angle estimation\ntechniques. For Direct AI/ML Positioning, we explore SOTA advancements in\nfingerprint-based positioning, knowledge-assisted AI positioning, and channel\ncharting-based positioning. Furthermore, we introduce publicly available\ndatasets for wireless positioning and conclude by summarizing the challenges\nand opportunities of AI-driven wireless positioning.",
      "tldr_zh": "这篇论文探讨了AI驱动的无线定位技术的基础、标准、现状及挑战，强调AI在提升定位准确性和鲁棒性方面的潜力，尤其在自动驾驶、XR和UAV等应用中。该文首先介绍AI模型、算法、无线定位基础及技术，然后详述3GPP标准的演进及其对AI/ML在定位中的整合，包括AI/ML辅助定位（如LOS/NLOS检测、TOA/TDOA估计）和直接AI/ML定位（如指纹定位、知识辅助定位）。最终，论文总结了SOTA研究、公开数据集，并指出了AI驱动无线定位的挑战与机遇，如数据隐私和泛化能力问题。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "32 pages. This work has been submitted to the IEEE for possible\n  publication",
      "pdf_url": "http://arxiv.org/pdf/2501.14970v1",
      "published_date": "2025-01-24 23:09:11 UTC",
      "updated_date": "2025-01-24 23:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:47:44.640885"
    },
    {
      "arxiv_id": "2502.14869v1",
      "title": "Envisioning Stakeholder-Action Pairs to Mitigate Negative Impacts of AI: A Participatory Approach to Inform Policy Making",
      "title_zh": "翻译失败",
      "authors": [
        "Julia Barnett",
        "Kimon Kieslich",
        "Natali Helberger",
        "Nicholas Diakopoulos"
      ],
      "abstract": "The potential for negative impacts of AI has rapidly become more pervasive\naround the world, and this has intensified a need for responsible AI\ngovernance. While many regulatory bodies endorse risk-based approaches and a\nmultitude of risk mitigation practices are proposed by companies and academic\nscholars, these approaches are commonly expert-centered and thus lack the\ninclusion of a significant group of stakeholders. Ensuring that AI policies\nalign with democratic expectations requires methods that prioritize the voices\nand needs of those impacted. In this work we develop a participative and\nforward-looking approach to inform policy-makers and academics that grounds the\nneeds of lay stakeholders at the forefront and enriches the development of risk\nmitigation strategies. Our approach (1) maps potential mitigation and\nprevention strategies of negative AI impacts that assign responsibility to\nvarious stakeholders, (2) explores the importance and prioritization thereof in\nthe eyes of laypeople, and (3) presents these insights in policy fact sheets,\ni.e., a digestible format for informing policy processes. We emphasize that\nthis approach is not targeted towards replacing policy-makers; rather our aim\nis to present an informative method that enriches mitigation strategies and\nenables a more participatory approach to policy development.",
      "tldr_zh": "该论文提出了一种参与式方法，以缓解AI负面影响并告知政策制定者，通过将普通利益相关者的需求置于首位。该方法包括（1）映射负面AI影响的缓解和预防策略，并分配责任给不同stakeholders，（2）探索这些策略的重要性并由laypeople进行优先排序，以及（3）将见解总结为policy fact sheets，以便于政策过程使用。与传统expert-centered方法不同，这种approach强调包容性，并非取代政策制定者，而是丰富风险mitigation策略，促进更民主的AI治理。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages + supplementary information and appendix",
      "pdf_url": "http://arxiv.org/pdf/2502.14869v1",
      "published_date": "2025-01-24 22:57:18 UTC",
      "updated_date": "2025-01-24 22:57:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:47:56.461974"
    },
    {
      "arxiv_id": "2501.14960v2",
      "title": "LLM4DistReconfig: A Fine-tuned Large Language Model for Power Distribution Network Reconfiguration",
      "title_zh": "翻译失败",
      "authors": [
        "Panayiotis Christou",
        "Md. Zahidul Islam",
        "Yuzhang Lin",
        "Jingwei Xiong"
      ],
      "abstract": "Power distribution networks are evolving due to the integration of DERs and\nincreased customer participation. To maintain optimal operation, minimize\nlosses, and meet varying load demands, frequent network reconfiguration is\nnecessary. Traditionally, the reconfiguration task relies on optimization\nsoftware and expert operators, but as systems grow more complex, faster and\nmore adaptive solutions are required without expert intervention. Data-driven\nreconfiguration is gaining traction for its accuracy, speed, and robustness\nagainst incomplete network data. LLMs, with their ability to capture complex\npatterns, offer a promising approach for efficient and responsive network\nreconfiguration in evolving complex power networks.\n  In this work, we introduce LLM4DistReconfig, a deep learning-based approach\nutilizing a fine-tuned LLM to solve the distribution network reconfiguration\nproblem. By carefully crafting prompts and designing a custom loss function, we\ntrain the LLM with inputs representing network parameters such as buses,\navailable lines, open lines, node voltages, and system loss. The model then\npredicts optimal reconfigurations by outputting updated network configurations\nthat minimize system loss while meeting operational constraints. Our approach\nsignificantly reduces inference time compared to classical algorithms, allowing\nfor near real-time optimal reconfiguration after training. Experimental results\nshow that our method generates optimal configurations minimizing system loss\nfor five individual and a combined test dataset. It also produces minimal\ninvalid edges, no cycles, or subgraphs across all datasets, fulfilling\ndomain-specific needs. Additionally, the generated responses contain less than\n5% improper outputs on seen networks and satisfactory results on unseen\nnetworks, demonstrating its effectiveness and reliability for the\nreconfiguration task.",
      "tldr_zh": "这篇论文提出了 LLM4DistReconfig，一种基于微调的大型语言模型（LLM），用于解决电力分配网络重新配置问题，以应对 DERs（分布式能源）整合和负载需求变化带来的挑战。方法通过精心设计提示和自定义损失函数，训练模型以网络参数（如总线、可用线路、节点电压和系统损失）作为输入，输出最优配置以最小化系统损失并满足操作约束。实验结果显示，该方法显著缩短了推理时间，实现近实时优化，并在多个数据集上生成最优配置，减少无效边、无循环或子图，且输出错误率低于5%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in NAACL 2025 Conference Main Track",
      "pdf_url": "http://arxiv.org/pdf/2501.14960v2",
      "published_date": "2025-01-24 22:46:14 UTC",
      "updated_date": "2025-02-08 06:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:48:09.755934"
    },
    {
      "arxiv_id": "2501.14959v1",
      "title": "The Curious Case of Arbitrariness in Machine Learning",
      "title_zh": "机器学习中的任意性奇特案例",
      "authors": [
        "Prakhar Ganesh",
        "Afaf Taik",
        "Golnoosh Farnadi"
      ],
      "abstract": "Algorithmic modelling relies on limited information in data to extrapolate\noutcomes for unseen scenarios, often embedding an element of arbitrariness in\nits decisions. A perspective on this arbitrariness that has recently gained\ninterest is multiplicity-the study of arbitrariness across a set of \"good\nmodels\", i.e., those likely to be deployed in practice. In this work, we\nsystemize the literature on multiplicity by: (a) formalizing the terminology\naround model design choices and their contribution to arbitrariness, (b)\nexpanding the definition of multiplicity to incorporate underrepresented forms\nbeyond just predictions and explanations, (c) clarifying the distinction\nbetween multiplicity and other traditional lenses of arbitrariness, i.e.,\nuncertainty and variance, and (d) distilling the benefits and potential risks\nof multiplicity into overarching trends, situating it within the broader\nlandscape of responsible AI. We conclude by identifying open research questions\nand highlighting emerging trends in this young but rapidly growing area of\nresearch.",
      "tldr_zh": "本研究探讨了机器学习中算法建模的任意性（arbitrariness），重点关注多重性（multiplicity）——即在“一组好模型”中分析决策的任意性。作者系统化了相关文献，通过形式化模型设计选择及其对任意性的贡献、扩展多重性的定义以涵盖预测和解释之外的形式，以及澄清多重性与不确定性（uncertainty）和方差（variance）的区别。最终，论文提炼了多重性的益处和潜在风险，将其置于负责任 AI（responsible AI）的 broader 景观中，并指出了开放研究问题和新兴趋势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14959v1",
      "published_date": "2025-01-24 22:45:09 UTC",
      "updated_date": "2025-01-24 22:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:48:21.506528"
    },
    {
      "arxiv_id": "2501.14956v1",
      "title": "ExPerT: Effective and Explainable Evaluation of Personalized Long-Form Text Generation",
      "title_zh": "ExPerT：个性化长文本生成的有效且可解释评估",
      "authors": [
        "Alireza Salemi",
        "Julian Killingback",
        "Hamed Zamani"
      ],
      "abstract": "Evaluating personalized text generated by large language models (LLMs) is\nchallenging, as only the LLM user, i.e., prompt author, can reliably assess the\noutput, but re-engaging the same individuals across studies is infeasible. This\npaper addresses the challenge of evaluating personalized text generation by\nintroducing ExPerT, an explainable reference-based evaluation framework. ExPerT\nleverages an LLM to extract atomic aspects and their evidence from the\ngenerated and reference texts, match the aspects, and evaluate their alignment\nbased on content and writing style -- two key attributes in personalized text\ngeneration. Additionally, ExPerT generates detailed, fine-grained explanations\nfor every step of the evaluation process, enhancing transparency and\ninterpretability. Our experiments demonstrate that ExPerT achieves a 7.2%\nrelative improvement in alignment with human judgments compared to the\nstate-of-the-art text generation evaluation methods. Furthermore, human\nevaluators rated the usability of ExPerT's explanations at 4.7 out of 5,\nhighlighting its effectiveness in making evaluation decisions more\ninterpretable.",
      "tldr_zh": "这篇论文提出 ExPerT，一种有效且可解释的框架，用于评估大型语言模型 (LLMs) 生成的个性化长文本，解决评估依赖提示作者的挑战。ExPerT 利用 LLM 从生成文本和参考文本中提取 atomic aspects 和证据，进行匹配，并基于内容和写作风格评估对齐，同时生成细粒度解释以提升透明度。实验显示，ExPerT 比现有方法在与人类判断一致性上提高了 7.2%，且其解释的可用性评分达到 4.7/5。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14956v1",
      "published_date": "2025-01-24 22:44:22 UTC",
      "updated_date": "2025-01-24 22:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:48:33.101808"
    },
    {
      "arxiv_id": "2502.08655v1",
      "title": "Personalizing Education through an Adaptive LMS with Integrated LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle Spriggs",
        "Meng Cheng Lau",
        "Kalpdrum Passi"
      ],
      "abstract": "The widespread adoption of large language models (LLMs) marks a\ntransformative era in technology, especially within the educational sector.\nThis paper explores the integration of LLMs within learning management systems\n(LMSs) to develop an adaptive learning management system (ALMS) personalized\nfor individual learners across various educational stages. Traditional LMSs,\nwhile facilitating the distribution of educational materials, fall short in\naddressing the nuanced needs of diverse student populations, particularly in\nsettings with limited instructor availability. Our proposed system leverages\nthe flexibility of AI to provide a customizable learning environment that\nadjusts to each user's evolving needs. By integrating a suite of\ngeneral-purpose and domain-specific LLMs, this system aims to minimize common\nissues such as factual inaccuracies and outdated information, characteristic of\ngeneral LLMs like OpenAI's ChatGPT. This paper details the development of an\nALMS that not only addresses privacy concerns and the limitations of existing\neducational tools but also enhances the learning experience by maintaining\nengagement through personalized educational content.",
      "tldr_zh": "这篇论文探讨了将大型语言模型(LLMs)整合到学习管理系统(LMS)中，以开发适应性学习管理系统(ALMS)，为不同教育阶段的学习者提供个性化教育。传统LMS无法充分满足多样化学生需求，该系统利用AI动态调整学习环境，结合通用和领域特定LLMs来减少事实错误、过时信息并处理隐私问题。最终，该ALMS通过个性化内容提升学习参与度和整体体验，为教育领域提供了更高效、可定制的工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.08655v1",
      "published_date": "2025-01-24 22:42:57 UTC",
      "updated_date": "2025-01-24 22:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:48:44.777163"
    },
    {
      "arxiv_id": "2501.14954v1",
      "title": "MISCON: A Mission-Driven Conversational Consultant for Pre-Venture Entrepreneurs in Food Deserts",
      "title_zh": "翻译失败",
      "authors": [
        "Subhasis Dasgupta",
        "Hans Taparia",
        "Laura Schmidt",
        "Amarnath Gupta"
      ],
      "abstract": "This work-in-progress report describes MISCON, a conversational consultant\nbeing developed for a public mission project called NOURISH. With MISCON,\naspiring small business owners in a food-insecure region and their advisors in\nCommunity-based organizations would be able to get information, recommendation\nand analysis regarding setting up food businesses. MISCON conversations are\nmodeled as state machine that uses a heterogeneous knowledge graph as well as\nseveral analytical tools and services including a variety of LLMs. In this\nshort report, we present the functional architecture and some design\nconsiderations behind MISCON.",
      "tldr_zh": "这篇论文介绍了 MISCON，一种使命驱动的对话式顾问，旨在为食品沙漠地区的预创业企业家及其社区顾问提供关于建立食品业务的信息、推荐和分析。MISCON 通过状态机建模对话，整合 heterogeneous knowledge graph 以及多种分析工具和服务，包括各种 LLMs，以实现高效的交互。报告详细阐述了 MISCON 的功能架构和设计考虑，为 NOURISH 公共项目提供支持，推动食品不安全区域的创业生态发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "K.4.2; I.2.7; H.5.2"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages. Acccepted for AAAI 2025 Workshop on AI for Public Missions,\n  March 3rd, 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14954v1",
      "published_date": "2025-01-24 22:39:49 UTC",
      "updated_date": "2025-01-24 22:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:48:56.304180"
    },
    {
      "arxiv_id": "2501.14942v1",
      "title": "Force-Based Robotic Imitation Learning: A Two-Phase Approach for Construction Assembly Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Hengxu You",
        "Yang Ye",
        "Tianyu Zhou",
        "Jing Du"
      ],
      "abstract": "The drive for efficiency and safety in construction has boosted the role of\nrobotics and automation. However, complex tasks like welding and pipe insertion\npose challenges due to their need for precise adaptive force control, which\ncomplicates robotic training. This paper proposes a two-phase system to improve\nrobot learning, integrating human-derived force feedback. The first phase\ncaptures real-time data from operators using a robot arm linked with a virtual\nsimulator via ROS-Sharp. In the second phase, this feedback is converted into\nrobotic motion instructions, using a generative approach to incorporate force\nfeedback into the learning process. This method's effectiveness is demonstrated\nthrough improved task completion times and success rates. The framework\nsimulates realistic force-based interactions, enhancing the training data's\nquality for precise robotic manipulation in construction tasks.",
      "tldr_zh": "该研究提出了一种基于力的机器人模仿学习方法，针对建筑装配任务如焊接和管道插入，采用两阶段方法来整合人类操作员的力反馈。第一阶段通过机器人臂与虚拟模拟器利用ROS-Sharp捕获实时数据；第二阶段将这些反馈转换为机器人运动指令，并采用生成式方法融入学习过程。该方法显著提高了任务完成时间和成功率，同时通过模拟真实的力-based交互，提升了训练数据的质量，从而为建筑领域的精确机器人操作提供了更可靠的框架。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "36 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.14942v1",
      "published_date": "2025-01-24 22:01:23 UTC",
      "updated_date": "2025-01-24 22:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:49:08.193541"
    },
    {
      "arxiv_id": "2501.14940v3",
      "title": "CASE-Bench: Context-Aware SafEty Benchmark for Large Language Models",
      "title_zh": "CASE-Bench：针对大型语言模型的上下文感知安全基准",
      "authors": [
        "Guangzhi Sun",
        "Xiao Zhan",
        "Shutong Feng",
        "Philip C. Woodland",
        "Jose Such"
      ],
      "abstract": "Aligning large language models (LLMs) with human values is essential for\ntheir safe deployment and widespread adoption. Current LLM safety benchmarks\noften focus solely on the refusal of individual problematic queries, which\noverlooks the importance of the context where the query occurs and may cause\nundesired refusal of queries under safe contexts that diminish user experience.\nAddressing this gap, we introduce CASE-Bench, a Context-Aware SafEty Benchmark\nthat integrates context into safety assessments of LLMs. CASE-Bench assigns\ndistinct, formally described contexts to categorized queries based on\nContextual Integrity theory. Additionally, in contrast to previous studies\nwhich mainly rely on majority voting from just a few annotators, we recruited a\nsufficient number of annotators necessary to ensure the detection of\nstatistically significant differences among the experimental conditions based\non power analysis. Our extensive analysis using CASE-Bench on various\nopen-source and commercial LLMs reveals a substantial and significant influence\nof context on human judgments (p<0.0001 from a z-test), underscoring the\nnecessity of context in safety evaluations. We also identify notable mismatches\nbetween human judgments and LLM responses, particularly in commercial models\nwithin safe contexts.",
      "tldr_zh": "本研究指出，现有的LLM安全基准主要关注拒绝问题查询，却忽略了查询的上下文，导致在安全环境中不必要地拒绝查询，影响用户体验。为解决这一问题，研究团队引入了CASE-Bench，一种基于Contextual Integrity理论的上下文感知安全基准，该基准为分类查询分配正式描述的上下文，并通过功率分析确保足够的标注者以检测统计显著差异。在对各种开源和商业LLMs的广泛分析中，研究发现上下文对人类判断有显著影响（z检验p<0.0001），并揭示了LLM响应与人类判断之间的明显不匹配，尤其在商业模型的安全上下文中。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.14940v3",
      "published_date": "2025-01-24 21:55:14 UTC",
      "updated_date": "2025-02-07 10:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:49:20.626926"
    },
    {
      "arxiv_id": "2501.14936v2",
      "title": "Context-Aware Neural Gradient Mapping for Fine-Grained Instruction Processing",
      "title_zh": "上下文感知神经梯度映射用于细粒度指令处理",
      "authors": [
        "David Boldo",
        "Lily Pemberton",
        "Gabriel Thistledown",
        "Jacob Fairchild",
        "Felix Kowalski"
      ],
      "abstract": "The integration of contextual embeddings into the optimization processes of\nlarge language models is an advancement in natural language processing. The\nContext-Aware Neural Gradient Mapping framework introduces a dynamic gradient\nadjustment mechanism, incorporating contextual embeddings directly into the\noptimization process. This approach facilitates real-time parameter\nadjustments, enhancing task-specific generalization even in the presence of\nsparse or noisy data inputs. The mathematical foundation of this framework\nrelies on gradient descent modifications, where contextual embeddings are\nderived from a supplementary neural network trained to map input features to\noptimal adaptation gradients. By employing differential geometry principles,\nhigh-dimensional input dependencies are encoded into low-dimensional gradient\nmanifolds, enabling efficient adaptation without necessitating the retraining\nof the entire model. Empirical evaluations demonstrate that the proposed\nframework consistently outperforms baseline models across various metrics,\nincluding accuracy, robustness to noise, and computational efficiency. The\nintegration of context-specific embeddings allows for a more complex\nunderstanding of language, thereby improving the model's ability to handle\ndiverse linguistic phenomena. Furthermore, the computational efficiency\nachieved through this method demonstrates its scalability for large-scale\nlanguage models operating under diverse constraints.",
      "tldr_zh": "本研究提出 Context-Aware Neural Gradient Mapping 框架，用于细粒度指令处理的优化，旨在将上下文嵌入直接整合到大型语言模型的梯度下降过程中。该框架通过动态梯度调整机制和辅助神经网络，从输入特征映射到最佳适应梯度，并利用微分几何原则将高维输入依赖编码到低维梯度流形中，实现高效模型适应，而无需重新训练整个模型。实验结果显示，该框架在准确性、抗噪声性和计算效率方面均优于基线模型，提升了模型对多样语言现象的泛化能力和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship",
      "pdf_url": "http://arxiv.org/pdf/2501.14936v2",
      "published_date": "2025-01-24 21:49:24 UTC",
      "updated_date": "2025-04-24 12:49:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:49:33.306926"
    },
    {
      "arxiv_id": "2501.14934v1",
      "title": "Temporal Binding Foundation Model for Material Property Recognition via Tactile Sequence Perception",
      "title_zh": "通过触觉序列感知的时序绑定基础模型",
      "authors": [
        "Hengxu You",
        "Tianyu Zhou",
        "Jing Du"
      ],
      "abstract": "Robots engaged in complex manipulation tasks require robust material property\nrecognition to ensure adaptability and precision. Traditionally, visual data\nhas been the primary source for object perception; however, it often proves\ninsufficient in scenarios where visibility is obstructed or detailed\nobservation is needed. This gap highlights the necessity of tactile sensing as\na complementary or primary input for material recognition. Tactile data becomes\nparticularly essential in contact-rich, small-scale manipulations where subtle\ndeformations and surface interactions cannot be accurately captured by vision\nalone. This letter presents a novel approach leveraging a temporal binding\nfoundation model for tactile sequence understanding to enhance material\nproperty recognition. By processing tactile sensor data with a temporal focus,\nthe proposed system captures the sequential nature of tactile interactions,\nsimilar to human fingertip perception. Additionally, this letter demonstrates\nthat, through tailored and specific design, the foundation model can more\neffectively capture temporal information embedded in tactile sequences,\nadvancing material property understanding. Experimental results validate the\nmodel's capability to capture these temporal patterns, confirming its utility\nfor material property recognition in visually restricted scenarios. This work\nunderscores the necessity of embedding advanced tactile data processing\nframeworks within robotic systems to achieve truly embodied and responsive\nmanipulation capabilities.",
      "tldr_zh": "本论文提出一种基于“temporal binding foundation model”的新方法，用于通过触觉序列感知（tactile sequence perception）提升机器人对材料属性的识别能力，以应对视觉数据在视线受阻或精细操控场景中的不足。模型通过处理触觉传感器数据的时序特性，模拟人类指尖感知的顺序互动，并通过定制设计更有效地捕捉嵌入的temporal信息。实验结果验证了该模型在捕捉时间模式方面的优越性，适用于视觉受限环境，从而为机器人实现更具适应性和响应性的复杂操控任务奠定基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "4 pages,",
      "pdf_url": "http://arxiv.org/pdf/2501.14934v1",
      "published_date": "2025-01-24 21:47:38 UTC",
      "updated_date": "2025-01-24 21:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:49:45.908122"
    },
    {
      "arxiv_id": "2501.14932v1",
      "title": "Explaining Categorical Feature Interactions Using Graph Covariance and LLMs",
      "title_zh": "使用图协方差和大型语言模型解释分类特征交互",
      "authors": [
        "Cencheng Shen",
        "Darren Edge",
        "Jonathan Larson",
        "Carey E. Priebe"
      ],
      "abstract": "Modern datasets often consist of numerous samples with abundant features and\nassociated timestamps. Analyzing such datasets to uncover underlying events\ntypically requires complex statistical methods and substantial domain\nexpertise. A notable example, and the primary data focus of this paper, is the\nglobal synthetic dataset from the Counter Trafficking Data Collaborative (CTDC)\n-- a global hub of human trafficking data containing over 200,000 anonymized\nrecords spanning from 2002 to 2022, with numerous categorical features for each\nrecord. In this paper, we propose a fast and scalable method for analyzing and\nextracting significant categorical feature interactions, and querying large\nlanguage models (LLMs) to generate data-driven insights that explain these\ninteractions. Our approach begins with a binarization step for categorical\nfeatures using one-hot encoding, followed by the computation of graph\ncovariance at each time. This graph covariance quantifies temporal changes in\ndependence structures within categorical data and is established as a\nconsistent dependence measure under the Bernoulli distribution. We use this\nmeasure to identify significant feature pairs, such as those with the most\nfrequent trends over time or those exhibiting sudden spikes in dependence at\nspecific moments. These extracted feature pairs, along with their timestamps,\nare subsequently passed to an LLM tasked with generating potential explanations\nof the underlying events driving these dependence changes. The effectiveness of\nour method is demonstrated through extensive simulations, and its application\nto the CTDC dataset reveals meaningful feature pairs and potential data stories\nunderlying the observed feature interactions.",
      "tldr_zh": "该论文提出了一种快速可扩展的方法，用于分析分类特征交互（categorical feature interactions），并利用大语言模型（LLMs）生成数据驱动的洞见，针对如 Counter Trafficking Data Collaborative (CTDC) 数据集等复杂时间序列数据集。方法包括对分类特征进行二值化处理（使用 one-hot encoding），随后计算每个时间点的图协方差（graph covariance）作为一种伯努瓦分布下的依赖度量，以识别显著特征对，如时间趋势或依赖峰值。最终，将这些特征对和时间戳输入 LLMs 生成潜在事件解释；实验通过模拟和 CTDC 数据集应用证明了方法的有效性，揭示了有意义的特征交互和数据故事。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "18 pages main + 6 pages appendix",
      "pdf_url": "http://arxiv.org/pdf/2501.14932v1",
      "published_date": "2025-01-24 21:41:26 UTC",
      "updated_date": "2025-01-24 21:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:49:57.505086"
    },
    {
      "arxiv_id": "2502.00034v1",
      "title": "Towards Efficient Multi-Objective Optimisation for Real-World Power Grid Topology Control",
      "title_zh": "面向现实世界电力网格拓扑控制的高效多目标优化",
      "authors": [
        "Yassine El Manyari",
        "Anton R. Fuxjager",
        "Stefan Zahlner",
        "Joost Van Dijk",
        "Alberto Castagna",
        "Davide Barbieri",
        "Jan Viebahn",
        "Marcel Wasserer"
      ],
      "abstract": "Power grid operators face increasing difficulties in the control room as the\nincrease in energy demand and the shift to renewable energy introduce new\ncomplexities in managing congestion and maintaining a stable supply. Effective\ngrid topology control requires advanced tools capable of handling\nmulti-objective trade-offs. While Reinforcement Learning (RL) offers a\npromising framework for tackling such challenges, existing Multi-Objective\nReinforcement Learning (MORL) approaches fail to scale to the large state and\naction spaces inherent in real-world grid operations. Here we present a\ntwo-phase, efficient and scalable Multi-Objective Optimisation (MOO) method\ndesigned for grid topology control, combining an efficient RL learning phase\nwith a rapid planning phase to generate day-ahead plans for unseen scenarios.\nWe validate our approach using historical data from TenneT, a European\nTransmission System Operator (TSO), demonstrating minimal deployment time,\ngenerating day-ahead plans within 4-7 minutes with strong performance. These\nresults underline the potential of our scalable method to support real-world\npower grid management, offering a practical, computationally efficient, and\ntime-effective tool for operational planning. Based on current congestion costs\nand inefficiencies in grid operations, adopting our approach by TSOs could\npotentially save millions of euros annually, providing a compelling economic\nincentive for its integration in the control room.",
      "tldr_zh": "本研究针对电力网格控制面临的复杂挑战（如能源需求增长和可再生能源转型导致的拥堵管理问题），提出了一种高效且可扩展的 Multi-Objective Optimisation (MOO) 方法，以解决现有 Multi-Objective Reinforcement Learning (MORL) 算法在大型状态和动作空间中的扩展性不足问题。该方法采用两阶段设计：第一阶段进行高效的 RL 学习，第二阶段快速规划生成针对未见场景的提前一天计划。实验使用欧洲传输系统运营商 TenneT 的历史数据验证，显示该方法能在 4-7 分钟内生成高质量计划，并可能每年为电网运营节省数百万欧元，提供实用的操作规划工具。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00034v1",
      "published_date": "2025-01-24 21:40:19 UTC",
      "updated_date": "2025-01-24 21:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:50:10.050229"
    },
    {
      "arxiv_id": "2501.14929v1",
      "title": "Motion-enhancement to Echocardiography Segmentation via Inserting a Temporal Attention Module: An Efficient, Adaptable, and Scalable Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Kamrul Hasan",
        "Guang Yang",
        "Choon Hwai Yap"
      ],
      "abstract": "Cardiac anatomy segmentation is essential for clinical assessment of cardiac\nfunction and disease diagnosis to inform treatment and intervention. In\nperforming segmentation, deep learning (DL) algorithms improved accuracy\nsignificantly compared to traditional image processing approaches. More\nrecently, studies showed that enhancing DL segmentation with motion information\ncan further improve it. A range of methods for injecting motion information has\nbeen proposed, but many of them increase the dimensionality of input images\n(which is computationally expensive) or have not used an optimal method to\ninsert motion information, such as non-DL registration, non-attention-based\nnetworks or single-headed attention. Here, we present a novel,\ncomputation-efficient alternative where a novel, scalable temporal attention\nmodule (TAM) extracts temporal feature interactions multiple times and where\nTAM has a multi-headed, KQV projection cross-attention architecture. The module\ncan be seamlessly integrated into a wide range of existing CNN- or\nTransformer-based networks, providing novel flexibility for inclusion in future\nimplementations. Extensive evaluations on different cardiac datasets, 2D\nechocardiography (CAMUS), and 3D echocardiography (MITEA) demonstrate the\nmodel's effectiveness when integrated into well-established backbone networks\nlike UNet, FCN8s, UNetR, SwinUNetR, and the recent I2UNet. We further find that\nthe optimized TAM-enhanced FCN8s network performs well compared to contemporary\nalternatives. Our results confirm TAM's robustness, scalability, and\ngeneralizability across diverse datasets and backbones.",
      "tldr_zh": "本研究提出了一种高效、可适应和可扩展的方法，通过插入一个新型临时注意力模块（TAM）来增强超声心动图分割的性能，TAM利用多头KQV投影交叉注意力架构多次提取临时特征交互，从而更好地融入运动信息，而无需增加输入图像维度或依赖非最优方法。TAM可无缝集成到各种现有网络中，如UNet、FCN8s、UNetR、SwinUNetR和I2UNet，提高了分割准确性。实验在2D（CAMUS）和3D（MITEA）心脏数据集上验证了该方法的有效性，优化后的TAM增强FCN8s网络比当代替代方案表现更优，并展示了其鲁棒性、可扩展性和跨数据集的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14929v1",
      "published_date": "2025-01-24 21:35:24 UTC",
      "updated_date": "2025-01-24 21:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:50:22.213623"
    },
    {
      "arxiv_id": "2501.14928v1",
      "title": "Decision Making in Changing Environments: Robustness, Query-Based Learning, and Differential Privacy",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Chen",
        "Alexander Rakhlin"
      ],
      "abstract": "We study the problem of interactive decision making in which the underlying\nenvironment changes over time subject to given constraints. We propose a\nframework, which we call \\textit{hybrid Decision Making with Structured\nObservations} (hybrid DMSO), that provides an interpolation between the\nstochastic and adversarial settings of decision making. Within this framework,\nwe can analyze local differentially private (LDP) decision making, query-based\nlearning (in particular, SQ learning), and robust and smooth decision making\nunder the same umbrella, deriving upper and lower bounds based on variants of\nthe Decision-Estimation Coefficient (DEC). We further establish strong\nconnections between the DEC's behavior, the SQ dimension, local minimax\ncomplexity, learnability, and joint differential privacy. To showcase the\nframework's power, we provide new results for contextual bandits under the LDP\nconstraint.",
      "tldr_zh": "本研究探讨了在环境变化下的交互决策问题，提出了一种混合框架 hybrid Decision Making with Structured Observations (hybrid DMSO)，它介于随机和对抗性设置之间，允许分析本地差分隐私 (LDP)、基于查询的学习 (SQ learning) 以及鲁棒和平滑决策。框架利用 Decision-Estimation Coefficient (DEC) 的变体来推导上界和下界，并建立了 DEC 与 SQ 维度、本地 minimax 复杂度、可学习性和联合差分隐私之间的紧密联系。通过这一框架，论文提供了 LDP 约束下 contextual bandits 的新结果，增强了决策算法的鲁棒性和隐私保护。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14928v1",
      "published_date": "2025-01-24 21:31:50 UTC",
      "updated_date": "2025-01-24 21:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:50:32.540808"
    },
    {
      "arxiv_id": "2503.16431v1",
      "title": "OpenAI's Approach to External Red Teaming for AI Models and Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Lama Ahmad",
        "Sandhini Agarwal",
        "Michael Lampe",
        "Pamela Mishkin"
      ],
      "abstract": "Red teaming has emerged as a critical practice in assessing the possible\nrisks of AI models and systems. It aids in the discovery of novel risks, stress\ntesting possible gaps in existing mitigations, enriching existing quantitative\nsafety metrics, facilitating the creation of new safety measurements, and\nenhancing public trust and the legitimacy of AI risk assessments. This white\npaper describes OpenAI's work to date in external red teaming and draws some\nmore general conclusions from this work. We describe the design considerations\nunderpinning external red teaming, which include: selecting composition of red\nteam, deciding on access levels, and providing guidance required to conduct red\nteaming. Additionally, we show outcomes red teaming can enable such as input\ninto risk assessment and automated evaluations. We also describe the\nlimitations of external red teaming, and how it can fit into a broader range of\nAI model and system evaluations. Through these contributions, we hope that AI\ndevelopers and deployers, evaluation creators, and policymakers will be able to\nbetter design red teaming campaigns and get a deeper look into how external red\nteaming can fit into model deployment and evaluation processes. These methods\nare evolving and the value of different methods continues to shift as the\necosystem around red teaming matures and models themselves improve as tools for\nred teaming.",
      "tldr_zh": "这篇白皮书介绍了 OpenAI 在外部 Red Teaming 方面的做法，用于评估 AI 模型和系统的潜在风险。论文强调 Red Teaming 可以发现新风险、测试现有缓解措施的漏洞、丰富安全指标并提升公众信任，并详细描述了设计考虑，如选择红队组成、决定访问级别和提供指导。实验和应用结果显示，Red Teaming 可输入风险评估和自动化评估，但也存在局限性，需要融入更广泛的 AI 评估框架中，以帮助开发者、评估者和政策制定者优化相关活动。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16431v1",
      "published_date": "2025-01-24 20:54:48 UTC",
      "updated_date": "2025-01-24 20:54:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:50:45.563807"
    },
    {
      "arxiv_id": "2501.14912v1",
      "title": "Feasible Learning",
      "title_zh": "可行学习",
      "authors": [
        "Juan Ramirez",
        "Ignacio Hounie",
        "Juan Elenter",
        "Jose Gallego-Posada",
        "Meraj Hashemizadeh",
        "Alejandro Ribeiro",
        "Simon Lacoste-Julien"
      ],
      "abstract": "We introduce Feasible Learning (FL), a sample-centric learning paradigm where\nmodels are trained by solving a feasibility problem that bounds the loss for\neach training sample. In contrast to the ubiquitous Empirical Risk Minimization\n(ERM) framework, which optimizes for average performance, FL demands\nsatisfactory performance on every individual data point. Since any model that\nmeets the prescribed performance threshold is a valid FL solution, the choice\nof optimization algorithm and its dynamics play a crucial role in shaping the\nproperties of the resulting solutions. In particular, we study a primal-dual\napproach which dynamically re-weights the importance of each sample during\ntraining. To address the challenge of setting a meaningful threshold in\npractice, we introduce a relaxation of FL that incorporates slack variables of\nminimal norm. Our empirical analysis, spanning image classification, age\nregression, and preference optimization in large language models, demonstrates\nthat models trained via FL can learn from data while displaying improved tail\nbehavior compared to ERM, with only a marginal impact on average performance.",
      "tldr_zh": "我们引入了 Feasible Learning (FL)，一种以样本为中心的学习框架，通过解决可行性问题确保每个训练样本的损失在预设边界内，与传统的 Empirical Risk Minimization (ERM) 不同，它强调每个数据点的满意性能而非平均性能。该方法采用 primal-dual 优化算法动态重新加权样本的重要性，并引入最小范数的松弛变量来简化阈值设置。实证分析显示，在图像分类、年龄回归和大型语言模型的偏好优化任务中，FL 模型显著改善了尾部行为，同时对平均性能的影响微乎其微。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at AISTATS 2025. Code available at\n  https://github.com/juan43ramirez/feasible-learning",
      "pdf_url": "http://arxiv.org/pdf/2501.14912v1",
      "published_date": "2025-01-24 20:39:38 UTC",
      "updated_date": "2025-01-24 20:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:50:57.360904"
    },
    {
      "arxiv_id": "2501.14892v2",
      "title": "Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Luo",
        "Jian Zhang",
        "Chujun Li"
      ],
      "abstract": "In knowledge-intensive tasks, especially in high-stakes domains like medicine\nand law, it is critical not only to retrieve relevant information but also to\nprovide causal reasoning and explainability. Large language models (LLMs) have\nachieved remarkable performance in natural language understanding and\ngeneration tasks. However, they often suffer from limitations such as\ndifficulty in incorporating new knowledge, generating hallucinations, and\nexplaining their reasoning process. To address these challenges, integrating\nknowledge graphs with Graph Retrieval-Augmented Generation (Graph RAG) has\nemerged as an effective solution. Traditional Graph RAG methods often rely on\nsimple graph traversal or semantic similarity, which do not capture causal\nrelationships or align well with the model's internal reasoning steps. This\npaper proposes a novel pipeline that filters large knowledge graphs to\nemphasize cause-effect edges, aligns the retrieval process with the model's\nchain-of-thought (CoT), and enhances reasoning through multi-stage path\nimprovements. Experiments on medical question-answering tasks show consistent\ngains, with up to a 10\\% absolute improvement across multiple large language\nmodels (LLMs). This approach demonstrates the value of combining causal\nreasoning with stepwise retrieval, leading to more interpretable and logically\ngrounded solutions for complex queries.",
      "tldr_zh": "本论文探讨了如何提升Graph-Augmented LLMs在知识密集型任务中的复杂推理能力，特别是通过整合因果图谱来解决LLMs的知识整合困难、幻觉生成和推理解释问题。研究提出了一种新管道，包括过滤知识图谱以强调因果边（cause-effect edges）、将检索过程与模型的Chain-of-Thought (CoT)对齐，以及通过多阶段路径改进增强推理步骤。实验在医疗问答任务上显示，该方法为多个LLMs带来了高达10%的绝对性能提升，证明了结合因果推理和逐步检索的可解释性和逻辑价值。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.14892v2",
      "published_date": "2025-01-24 19:31:06 UTC",
      "updated_date": "2025-03-17 14:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:51:09.169235"
    },
    {
      "arxiv_id": "2501.14719v1",
      "title": "Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?",
      "title_zh": "翻译失败",
      "authors": [
        "Ipek Baris Schlicht",
        "Zhixue Zhao",
        "Burcu Sayin",
        "Lucie Flek",
        "Paolo Rosso"
      ],
      "abstract": "Equitable access to reliable health information is vital for public health,\nbut the quality of online health resources varies by language, raising concerns\nabout inconsistencies in Large Language Models (LLMs) for healthcare. In this\nstudy, we examine the consistency of responses provided by LLMs to\nhealth-related questions across English, German, Turkish, and Chinese. We\nlargely expand the HealthFC dataset by categorizing health-related questions by\ndisease type and broadening its multilingual scope with Turkish and Chinese\ntranslations. We reveal significant inconsistencies in responses that could\nspread healthcare misinformation. Our main contributions are 1) a multilingual\nhealth-related inquiry dataset with meta-information on disease categories, and\n2) a novel prompt-based evaluation workflow that enables sub-dimensional\ncomparisons between two languages through parsing. Our findings highlight key\nchallenges in deploying LLM-based tools in multilingual contexts and emphasize\nthe need for improved cross-lingual alignment to ensure accurate and equitable\nhealthcare information.",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）在英语、德语、土耳其语和中文等语言中对健康相关问题的回答一致性，揭示了语言差异可能导致医疗误传的风险。研究者扩展了 HealthFC 数据集，按疾病类型分类并添加了土耳其语和中文翻译，以评估跨语言响应的准确性和一致性。主要贡献包括构建一个多语言健康问题数据集（包含疾病类别元信息）和开发一个基于提示的评估工作流，用于通过解析进行两种语言的子维度比较。结果显示，LLMs 存在显著不一致性，强调了在多语言环境中部署 LLM 工具的挑战，并呼吁加强跨语言对齐以确保公平可靠的医疗信息。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages. Short paper appeared at 47th European Conference on\n  Information Retrieval (ECIR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.14719v1",
      "published_date": "2025-01-24 18:51:26 UTC",
      "updated_date": "2025-01-24 18:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:51:22.666223"
    },
    {
      "arxiv_id": "2501.14700v4",
      "title": "An Attentive Graph Agent for Topology-Adaptive Cyber Defence",
      "title_zh": "翻译失败",
      "authors": [
        "Ilya Orson Sandoval",
        "Isaac Symes Thompson",
        "Vasilios Mavroudis",
        "Chris Hicks"
      ],
      "abstract": "As cyber threats grow increasingly sophisticated, reinforcement learning (RL)\nis emerging as a promising technique to create intelligent and adaptive cyber\ndefense systems. However, most existing autonomous defensive agents have\noverlooked the inherent graph structure of computer networks subject to cyber\nattacks, potentially missing critical information and constraining their\nadaptability. To overcome these limitations, we developed a custom version of\nthe Cyber Operations Research Gym (CybORG) environment, encoding network state\nas a directed graph with realistic low-level features. We employ a Graph\nAttention Network (GAT) architecture to process node, edge, and global\nfeatures, and adapt its output to be compatible with policy gradient methods in\nRL. Our GAT-based approach offers key advantages over flattened alternatives:\npolicies that demonstrate resilience to certain types of unexpected dynamic\nnetwork topology changes, reasonable generalisation to networks of varying\nsizes within the same structural distribution, and interpretable defensive\nactions grounded in tangible network properties. We demonstrate that GAT\ndefensive policies can be trained using our low-level directed graph\nobservations, even when unexpected connections arise during simulation.\nEvaluations across networks of different sizes, but consistent subnetwork\nstructure, show our policies achieve comparable performance to policies trained\nspecifically for each network configuration. Our study contributes to the\ndevelopment of robust cyber defence systems that can better adapt to real-world\nnetwork security challenges.",
      "tldr_zh": "这篇论文提出了一种基于 Graph Attention Network (GAT) 的智能代理，用于拓扑自适应网络防御，以应对日益复杂的网络威胁。作者开发了自定义的 Cyber Operations Research Gym (CybORG) 环境，将网络状态编码为有向图，并使用 GAT 处理节点、边和全局特征，使其与强化学习 (RL) 的策略梯度方法兼容。相比传统平坦方法，该代理显示出对动态网络拓扑变化的弹性、不同网络规模的泛化能力，以及基于网络属性的可解释防御行动。实验结果证明，该方法在模拟环境中实现了鲁棒性能，并为适应真实网络安全挑战的防御系统提供了重要贡献。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Draft requires substantial revision",
      "pdf_url": "http://arxiv.org/pdf/2501.14700v4",
      "published_date": "2025-01-24 18:22:37 UTC",
      "updated_date": "2025-04-16 03:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:51:34.003453"
    },
    {
      "arxiv_id": "2501.16382v1",
      "title": "GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwen Li",
        "Xiang 'Anthony' Chen",
        "Youngseung Jeon"
      ],
      "abstract": "Drug discovery (DD) has tremendously contributed to maintaining and improving\npublic health. Hypothesizing that inhibiting protein misfolding can slow\ndisease progression, researchers focus on target identification (Target ID) to\nfind protein structures for drug binding. While Large Language Models (LLMs)\nand Retrieval-Augmented Generation (RAG) frameworks have accelerated drug\ndiscovery, integrating models into cohesive workflows remains challenging. We\nconducted a user study with drug discovery researchers to identify the\napplicability of LLMs and RAGs in Target ID. We identified two main findings:\n1) an LLM should provide multiple Protein-Protein Interactions (PPIs) based on\nan initial protein and protein candidates that have a therapeutic impact; 2)\nthe model must provide the PPI and relevant explanations for better\nunderstanding. Based on these observations, we identified three limitations in\nprevious approaches for Target ID: 1) semantic ambiguity, 2) lack of\nexplainability, and 3) short retrieval units. To address these issues, we\npropose GraPPI, a large-scale knowledge graph (KG)-based retrieve-divide-solve\nagent pipeline RAG framework to support large-scale PPI signaling pathway\nexploration in understanding therapeutic impacts by decomposing the analysis of\nentire PPI pathways into sub-tasks focused on the analysis of PPI edges.",
      "tldr_zh": "该研究针对药物发现（DD）中的目标识别（Target ID）挑战，提出 GraPPI 框架，这是一个基于大规模知识图谱（KG）的 Retrieve-Divide-Solve GraphRAG 管道，用于探索蛋白质-蛋白质相互作用（PPIs）。通过用户研究，论文识别出现有方法的三大限制：语义模糊性、缺乏可解释性和检索单位过短，并通过将 PPI 通路分析分解为子任务（如 PPI 边分析）来解决这些问题。GraPPI 支持大规模 PPI 信号通路探索，提高了治疗影响的理解和模型的可解释性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "14 pages; 5 figures. Published as a finding at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16382v1",
      "published_date": "2025-01-24 18:16:53 UTC",
      "updated_date": "2025-01-24 18:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:51:46.928546"
    },
    {
      "arxiv_id": "2501.14694v1",
      "title": "Towards Automated Self-Supervised Learning for Truly Unsupervised Graph Anomaly Detection",
      "title_zh": "迈向自动化的自监督学习，用于真正无监督的图异常检测",
      "authors": [
        "Zhong Li",
        "Yuhang Wang",
        "Matthijs van Leeuwen"
      ],
      "abstract": "Self-supervised learning (SSL) is an emerging paradigm that exploits\nsupervisory signals generated from the data itself, and many recent studies\nhave leveraged SSL to conduct graph anomaly detection. However, we empirically\nfound that three important factors can substantially impact detection\nperformance across datasets: 1) the specific SSL strategy employed; 2) the\ntuning of the strategy's hyperparameters; and 3) the allocation of combination\nweights when using multiple strategies. Most SSL-based graph anomaly detection\nmethods circumvent these issues by arbitrarily or selectively (i.e., guided by\nlabel information) choosing SSL strategies, hyperparameter settings, and\ncombination weights. While an arbitrary choice may lead to subpar performance,\nusing label information in an unsupervised setting is label information leakage\nand leads to severe overestimation of a method's performance. Leakage has been\ncriticized as \"one of the top ten data mining mistakes\", yet many recent\nstudies on SSL-based graph anomaly detection have been using label information\nto select hyperparameters. To mitigate this issue, we propose to use an\ninternal evaluation strategy (with theoretical analysis) to select\nhyperparameters in SSL for unsupervised anomaly detection. We perform extensive\nexperiments using 10 recent SSL-based graph anomaly detection algorithms on\nvarious benchmark datasets, demonstrating both the prior issues with\nhyperparameter selection and the effectiveness of our proposed strategy.",
      "tldr_zh": "该研究指出，现有的基于自监督学习(SSL)的图异常检测方法存在关键问题，包括SSL策略选择、超参数调优和组合权重的不当处理，这些往往依赖标签信息导致性能过估和信息泄露。论文提出一种内部评估策略（配以理论分析），用于在真正无监督设置下自动选择SSL超参数，从而避免标签信息泄露。实验在多个基准数据集上评估了10种最新SSL-based图异常检测算法，结果证明了现有问题的严重性和新策略的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Manuscript submitted to Data Mining and Knowledge Discovery in May\n  2024 for possible publication. This is the revised version submitted in\n  January 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14694v1",
      "published_date": "2025-01-24 18:13:44 UTC",
      "updated_date": "2025-01-24 18:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:51:56.874432"
    },
    {
      "arxiv_id": "2501.14693v1",
      "title": "Rethinking Table Instruction Tuning",
      "title_zh": "重新审视表格指令微调",
      "authors": [
        "Naihao Deng",
        "Rada Mihalcea"
      ],
      "abstract": "Recent advances in table understanding have focused on instruction-tuning\nlarge language models (LLMs) for table-related tasks. However, existing\nresearch has overlooked the impact of hyperparameter choices and lacks a\ncomprehensive evaluation of the out-of-domain table understanding ability and\nthe general capabilities of these table LLMs. In this paper, we evaluate these\nabilities in existing table LLMs, and reveal significant declines in both\nout-of-domain table understanding and general capabilities compared to their\nbase models. Through systematic analysis, we show that hyperparameters, such as\nlearning rate, can significantly influence both table-specific and general\ncapabilities. Contrary to the existing table instruction-tuning works, we\ndemonstrate that smaller learning rates and fewer training instances can\nenhance table understanding while preserving general capabilities. Based on our\nfindings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8B\nInstruct, which achieves performance on par with, or surpassing GPT-3.5 and\nGPT-4 on table tasks, while maintaining strong out-of-domain generalization and\ngeneral capabilities. Our findings highlight the potential for reduced data\nannotation costs and more efficient model development through careful\nhyperparameter selection.",
      "tldr_zh": "本文重新审视了表指令微调（Table Instruction Tuning），发现现有方法忽略了超参数（如学习率）的影响，导致模型在领域外表理解能力和一般能力上显著下降。作者通过系统分析证明，使用更小的学习率和更少的训练实例可以提升表理解性能，同时保留模型的一般能力。基于这些发现，他们引入了 TAMA 模型，该模型从 LLaMA 3.1 8B Instruct 微调而来，在表任务上达到或超过 GPT-3.5 和 GPT-4 的表现，并展现出强的领域外泛化。总之，此研究突出了通过优化超参数来减少数据标注成本并实现高效模型开发的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14693v1",
      "published_date": "2025-01-24 18:06:07 UTC",
      "updated_date": "2025-01-24 18:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:52:11.297587"
    },
    {
      "arxiv_id": "2501.14689v1",
      "title": "Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI",
      "title_zh": "设计计算机视觉系统用于医疗应用的方法：数据、架构和AI",
      "authors": [
        "Dmitry Ryabtsev",
        "Boris Vasilyev",
        "Sergey Shershakov"
      ],
      "abstract": "This paper introduces an innovative software system for fundus image analysis\nthat deliberately diverges from the conventional screening approach, opting not\nto predict specific diagnoses. Instead, our methodology mimics the diagnostic\nprocess by thoroughly analyzing both normal and pathological features of fundus\nstructures, leaving the ultimate decision-making authority in the hands of\nhealthcare professionals. Our initiative addresses the need for objective\nclinical analysis and seeks to automate and enhance the clinical workflow of\nfundus image examination. The system, from its overarching architecture to the\nmodular analysis design powered by artificial intelligence (AI) models, aligns\nseamlessly with ophthalmological practices. Our unique approach utilizes a\ncombination of state-of-the-art deep learning methods and traditional computer\nvision algorithms to provide a comprehensive and nuanced analysis of fundus\nstructures. We present a distinctive methodology for designing medical\napplications, using our system as an illustrative example. Comprehensive\nverification and validation results demonstrate the efficacy of our approach in\nrevolutionizing fundus image analysis, with potential applications across\nvarious medical domains.",
      "tldr_zh": "这篇论文提出了一种设计计算机视觉 (CV) 系统的方法，专注于医疗应用，特别是眼底图像分析，避免直接预测具体诊断，而是通过分析眼底结构的正常和病理特征来辅助医生决策。系统采用模块化架构，结合人工智能 (AI) 模型、先进深度学习方法和传统计算机视觉算法，提供客观的临床分析并优化眼科工作流程。作为医疗应用设计的示例，该方法展示了如何无缝整合技术与临床实践。验证结果证明了系统的有效性，并具有扩展到其他医疗领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14689v1",
      "published_date": "2025-01-24 18:02:32 UTC",
      "updated_date": "2025-01-24 18:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:52:22.004097"
    },
    {
      "arxiv_id": "2501.14687v1",
      "title": "Decoding Generalization from Memorization in Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Simran Ketha",
        "Venkatakrishnan Ramaswamy"
      ],
      "abstract": "Overparameterized Deep Neural Networks that generalize well have been key to\nthe dramatic success of Deep Learning in recent years. The reasons for their\nremarkable ability to generalize are not well understood yet. It has also been\nknown that deep networks possess the ability to memorize training data, as\nevidenced by perfect or high training accuracies on models trained with\ncorrupted data that have class labels shuffled to varying degrees.\nConcomitantly, such models are known to generalize poorly, i.e. they suffer\nfrom poor test accuracies, due to which it is thought that the act of\nmemorizing substantially degrades the ability to generalize. It has, however,\nbeen unclear why the poor generalization that accompanies such memorization,\ncomes about. One possibility is that in the process of training with corrupted\ndata, the layers of the network irretrievably reorganize their representations\nin a manner that makes generalization difficult. The other possibility is that\nthe network retains significant ability to generalize, but the trained network\nsomehow chooses to readout in a manner that is detrimental to generalization.\nHere, we provide evidence for the latter possibility by demonstrating,\nempirically, that such models possess information in their representations for\nsubstantially improved generalization, even in the face of memorization.\nFurthermore, such generalization abilities can be easily decoded from the\ninternals of the trained model, and we build a technique to do so from the\noutputs of specific layers of the network. We demonstrate results on multiple\nmodels trained with a number of standard datasets.",
      "tldr_zh": "该研究探讨了深度神经网络（Deep Neural Networks）在记忆训练数据时如何影响泛化能力，挑战了传统观点，即记忆会不可逆地破坏泛化。作者通过实验证据表明，即使模型记忆了被破坏的数据（如标签打乱），其内部表示中仍保留了显著的泛化信息，而问题在于网络的输出读取方式。论文开发了一种从特定网络层输出解码泛化能力的技术，并在多个标准数据集上验证了这一方法，为理解网络泛化机制提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14687v1",
      "published_date": "2025-01-24 18:01:27 UTC",
      "updated_date": "2025-01-24 18:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:52:33.743049"
    },
    {
      "arxiv_id": "2501.14685v1",
      "title": "Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST",
      "title_zh": "翻译失败",
      "authors": [
        "Fuping Wu",
        "Bartlomiej W. Papiez"
      ],
      "abstract": "Foundation models are widely employed in medical image analysis, due to their\nhigh adaptability and generalizability for downstream tasks. With the\nincreasing number of foundation models being released, model selection has\nbecome an important issue. In this work, we study the capabilities of\nfoundation models in medical image classification tasks by conducting a\nbenchmark study on the MedMNIST dataset. Specifically, we adopt various\nfoundation models ranging from convolutional to Transformer-based models and\nimplement both end-to-end training and linear probing for all classification\ntasks. The results demonstrate the significant potential of these pre-trained\nmodels when transferred for medical image classification. We further conduct\nexperiments with different image sizes and various sizes of training data. By\nanalyzing all the results, we provide preliminary, yet useful insights and\nconclusions on this topic.",
      "tldr_zh": "该研究通过对 MedMNIST 数据集的基准研究，重新审视 foundation models 在医疗图像分类中的适应性和泛化能力，涵盖从卷积到 Transformer-based models 的各种模型。研究采用 end-to-end training 和 linear probing 方法进行实验，评估模型在不同图像大小和训练数据规模下的表现。结果表明，这些预训练模型在转移学习中显示出显著潜力，并提供了关于模型选择的有用洞见和初步结论。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "submitted to MIDL2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14685v1",
      "published_date": "2025-01-24 18:01:07 UTC",
      "updated_date": "2025-01-24 18:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:52:45.252004"
    },
    {
      "arxiv_id": "2501.14679v5",
      "title": "Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Rongzhao He",
        "Weihao Zheng",
        "Leilei Zhao",
        "Ying Wang",
        "Dalin Zhu",
        "Dan Wu",
        "Bin Hu"
      ],
      "abstract": "Attention-based methods have demonstrated exceptional performance in\nmodelling long-range dependencies on spherical cortical surfaces, surpassing\ntraditional Geometric Deep Learning (GDL) models. However, their extensive\ninference time and high memory demands pose challenges for application to large\ndatasets with limited computing resources. Inspired by the state space model in\ncomputer vision, we introduce the attention-free Vision Mamba (Vim) to\nspherical surfaces, presenting a domain-agnostic architecture for analyzing\ndata on spherical manifolds. Our method achieves surface patching by\nrepresenting spherical data as a sequence of triangular patches derived from a\nsubdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated on\nmultiple neurodevelopmental phenotype regression tasks using cortical surface\nmetrics from neonatal brains. Experimental results demonstrate that SiM\noutperforms both attention- and GDL-based methods, delivering 4.8 times faster\ninference and achieving 91.7% lower memory consumption compared to the Surface\nVision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivity\nanalysis further underscores the potential of SiM to identify subtle cognitive\ndevelopmental patterns. The code is available at\nhttps://github.com/Rongzhao-He/surface-vision-mamba.",
      "tldr_zh": "该研究提出Surface Vision Mamba (SiM)，一种基于Bidirectional State Space Model的无注意力架构，用于高效表示和分析球面流形数据，旨在解决注意力机制模型在计算资源上的高需求问题。\nSiM通过将球面数据表示为从细分正二十面体派生的三角形补丁序列，实现对数据序列的处理。\n在新生儿大脑皮层指标的神经发育表型回归任务中，SiM优于基于注意力和Geometric Deep Learning (GDL)的方法，提供4.8倍的推理速度和91.7%的内存节省。\n此外，敏感性分析表明SiM能有效识别微妙的认知发育模式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14679v5",
      "published_date": "2025-01-24 17:57:06 UTC",
      "updated_date": "2025-02-20 07:37:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:52:58.627555"
    },
    {
      "arxiv_id": "2501.14678v1",
      "title": "A Predictive Approach for Enhancing Accuracy in Remote Robotic Surgery Using Informer Model",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Hanif Lashari",
        "Shakil Ahmed",
        "Wafa Batayneh",
        "Ashfaq Khokhar"
      ],
      "abstract": "Precise and real-time estimation of the robotic arm's position on the\npatient's side is essential for the success of remote robotic surgery in\nTactile Internet (TI) environments. This paper presents a prediction model\nbased on the Transformer-based Informer framework for accurate and efficient\nposition estimation. Additionally, it combines a Four-State Hidden Markov Model\n(4-State HMM) to simulate realistic packet loss scenarios. The proposed\napproach addresses challenges such as network delays, jitter, and packet loss\nto ensure reliable and precise operation in remote surgical applications. The\nmethod integrates the optimization problem into the Informer model by embedding\nconstraints such as energy efficiency, smoothness, and robustness into its\ntraining process using a differentiable optimization layer. The Informer\nframework uses features such as ProbSparse attention, attention distilling, and\na generative-style decoder to focus on position-critical features while\nmaintaining a low computational complexity of O(L log L). The method is\nevaluated using the JIGSAWS dataset, achieving a prediction accuracy of over 90\npercent under various network scenarios. A comparison with models such as TCN,\nRNN, and LSTM demonstrates the Informer framework's superior performance in\nhandling position prediction and meeting real-time requirements, making it\nsuitable for Tactile Internet-enabled robotic surgery.",
      "tldr_zh": "这篇论文提出了一种基于 Informer model 的预测方法，以提升 Tactile Internet 环境下的远程机器人手术中机械臂位置估计的准确性和实时性。方法结合 Four-State Hidden Markov Model (4-State HMM) 模拟数据包丢失场景，并通过可微优化层将能量效率、光滑性和鲁棒性等约束嵌入 Informer 模型的训练过程，利用 ProbSparse attention 和 generative-style decoder 实现低计算复杂度 O(L log L)。实验在 JIGSAWS 数据集上显示，该方法在各种网络条件下预测准确率超过 90%，并在与 TCN、RNN 和 LSTM 模型的比较中表现出显著优势，为可靠的远程手术应用提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14678v1",
      "published_date": "2025-01-24 17:57:00 UTC",
      "updated_date": "2025-01-24 17:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:53:10.399259"
    },
    {
      "arxiv_id": "2501.14673v1",
      "title": "State Space Models for Extractive Summarization in Low Resource Scenarios",
      "title_zh": "状态空间模型在低资源场景下的提取式摘要",
      "authors": [
        "Nisrine Ait Khayi"
      ],
      "abstract": "Extractive summarization involves selecting the most relevant sentences from\na text. Recently, researchers have focused on advancing methods to improve\nstate-of-the-art results in low-resource settings. Motivated by these\nadvancements, we propose the MPoincareSum method. This method applies the Mamba\nstate space model to generate the semantics of reviews and sentences, which are\nthen concatenated. A Poincare compression is used to select the most meaningful\nfeatures, followed by the application of a linear layer to predict sentence\nrelevance based on the corresponding review. Finally, we paraphrase the\nrelevant sentences to create the final summary. To evaluate the effectiveness\nof MPoincareSum, we conducted extensive experiments using the Amazon review\ndataset. The performance of the method was assessed using ROUGE scores. The\nexperimental results demonstrate that MPoincareSum outperforms several existing\napproaches in the literature",
      "tldr_zh": "本文提出 MPoincareSum 方法，利用 Mamba 状态空间模型生成评论和句子的语义，并通过 Poincare compression 选择关键特征，结合线性层预测句子相关性，最后改述相关句子以生成提取式摘要，适用于低资源场景。  \n该方法针对 Amazon 评论数据集进行实验，使用 ROUGE scores 评估，结果显示 MPoincareSum 优于现有方法。  \n这项研究为状态空间模型（State Space Models）在提取式摘要中的应用提供了新思路，尤其在资源有限的环境中。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14673v1",
      "published_date": "2025-01-24 17:49:34 UTC",
      "updated_date": "2025-01-24 17:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:53:21.947986"
    },
    {
      "arxiv_id": "2501.14661v1",
      "title": "Neural-Symbolic Message Passing with Dynamic Pruning",
      "title_zh": "神经符号消息传递与动态剪枝",
      "authors": [
        "Chongzhi Zhang",
        "Junhao Zheng",
        "Zhiping Peng",
        "Qianli Ma"
      ],
      "abstract": "Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs) is a\nchallenging task. Recently, a line of message-passing-based research has been\nproposed to solve CQA. However, they perform unsatisfactorily on negative\nqueries and fail to address the noisy messages between variable nodes in the\nquery graph. Moreover, they offer little interpretability and require complex\nquery data and resource-intensive training. In this paper, we propose a\nNeural-Symbolic Message Passing (NSMP) framework based on pre-trained neural\nlink predictors. By introducing symbolic reasoning and fuzzy logic, NSMP can\ngeneralize to arbitrary existential first order logic queries without requiring\ntraining while providing interpretable answers. Furthermore, we introduce a\ndynamic pruning strategy to filter out noisy messages between variable nodes.\nExperimental results show that NSMP achieves a strong performance.\nAdditionally, through complexity analysis and empirical verification, we\ndemonstrate the superiority of NSMP in inference time over the current\nstate-of-the-art neural-symbolic method. Compared to this approach, NSMP\ndemonstrates faster inference times across all query types on benchmark\ndatasets, with speedup ranging from 2$\\times$ to over 150$\\times$.",
      "tldr_zh": "该论文提出了一种Neural-Symbolic Message Passing (NSMP)框架，用于处理不完整Knowledge Graphs (KGs)上的Complex Query Answering (CQA)任务，通过结合预训练的神经链接预测器、symbolic reasoning和fuzzy logic，实现无需训练即可泛化到任意存在性一阶逻辑查询，并提供可解释的答案。NSMP引入dynamic pruning策略来过滤查询图中变量节点之间的噪声消息，从而提升查询准确性和效率。实验结果显示，NSMP在基准数据集上性能强劲，且推理时间比当前最先进的神经-符号方法快2倍到150倍以上，证明了其在速度和可解释性方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 5 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.14661v1",
      "published_date": "2025-01-24 17:30:17 UTC",
      "updated_date": "2025-01-24 17:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:53:32.828851"
    },
    {
      "arxiv_id": "2501.14654v2",
      "title": "MedAgentBench: A Realistic Virtual EHR Environment to Benchmark Medical LLM Agents",
      "title_zh": "MedAgentBench：一个真实的虚拟 EHR 环境，用于基准测试医疗 LLM 代理",
      "authors": [
        "Yixing Jiang",
        "Kameron C. Black",
        "Gloria Geng",
        "Danny Park",
        "James Zou",
        "Andrew Y. Ng",
        "Jonathan H. Chen"
      ],
      "abstract": "Recent large language models (LLMs) have demonstrated significant\nadvancements, particularly in their ability to serve as agents thereby\nsurpassing their traditional role as chatbots. These agents can leverage their\nplanning and tool utilization capabilities to address tasks specified at a high\nlevel. However, a standardized dataset to benchmark the agent capabilities of\nLLMs in medical applications is currently lacking, making the evaluation of\nLLMs on complex tasks in interactive healthcare environments challenging. To\naddress this gap, we introduce MedAgentBench, a broad evaluation suite designed\nto assess the agent capabilities of large language models within medical\nrecords contexts. MedAgentBench encompasses 300 patient-specific\nclinically-derived tasks from 10 categories written by human physicians,\nrealistic profiles of 100 patients with over 700,000 data elements, a\nFHIR-compliant interactive environment, and an accompanying codebase. The\nenvironment uses the standard APIs and communication infrastructure used in\nmodern EMR systems, so it can be easily migrated into live EMR systems.\nMedAgentBench presents an unsaturated agent-oriented benchmark that current\nstate-of-the-art LLMs exhibit some ability to succeed at. The best model\n(Claude 3.5 Sonnet v2) achieves a success rate of 69.67%. However, there is\nstill substantial space for improvement which gives the community a next\ndirection to optimize. Furthermore, there is significant variation in\nperformance across task categories. MedAgentBench establishes this and is\npublicly available at https://github.com/stanfordmlgroup/MedAgentBench ,\noffering a valuable framework for model developers to track progress and drive\ncontinuous improvements in the agent capabilities of large language models\nwithin the medical domain.",
      "tldr_zh": "本文引入 MedAgentBench，这是一个现实虚拟 EHR 环境，用于基准测试大型语言模型 (LLMs) 在医疗领域的代理能力，填补了评估 LLMs 在交互式医疗任务中的标准化数据集空白。该基准套件包含 300 个由人类医生编写的患者特定任务、100 个患者配置文件（超过 700,000 个数据元素）、FHIR 兼容的交互环境和配套代码库，便于迁移到实际 EMR 系统。实验结果显示，最先进模型 Claude 3.5 Sonnet v2 的成功率为 69.67%，但在不同任务类别间存在显著性能差异，表明仍有优化空间。MedAgentBench 作为公开框架，将帮助模型开发者跟踪进步并推动 LLMs 在医疗领域的持续改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14654v2",
      "published_date": "2025-01-24 17:21:01 UTC",
      "updated_date": "2025-02-12 05:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:53:47.080269"
    },
    {
      "arxiv_id": "2501.14653v1",
      "title": "Federated Domain Generalization with Data-free On-server Gradient Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Trong-Binh Nguyen",
        "Minh-Duong Nguyen",
        "Jinsun Park",
        "Quoc-Viet Pham",
        "Won Joo Hwang"
      ],
      "abstract": "Domain Generalization (DG) aims to learn from multiple known source domains a\nmodel that can generalize well to unknown target domains. One of the key\napproaches in DG is training an encoder which generates domain-invariant\nrepresentations. However, this approach is not applicable in Federated Domain\nGeneralization (FDG), where data from various domains are distributed across\ndifferent clients. In this paper, we introduce a novel approach, dubbed\nFederated Learning via On-server Matching Gradient (FedOMG), which can\n\\emph{efficiently leverage domain information from distributed domains}.\nSpecifically, we utilize the local gradients as information about the\ndistributed models to find an invariant gradient direction across all domains\nthrough gradient inner product maximization. The advantages are two-fold: 1)\nFedOMG can aggregate the characteristics of distributed models on the\ncentralized server without incurring any additional communication cost, and 2)\nFedOMG is orthogonal to many existing FL/FDG methods, allowing for additional\nperformance improvements by being seamlessly integrated with them. Extensive\nexperimental evaluations on various settings to demonstrate the robustness of\nFedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA\nbaselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and\nCIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome).",
      "tldr_zh": "该论文针对 Federated Domain Generalization (FDG) 问题，提出了一种名为 Federated Learning via On-server Matching Gradient (FedOMG) 的新方法，该方法通过服务器上的梯度内积最大化，利用本地梯度信息来找到跨分布式领域的领域不变梯度方向，而无需额外通信成本。FedOMG 的优势在于它能高效聚合分布式模型特性，并与现有 FL/FDG 方法无缝整合以进一步提升性能。在多个基准数据集（如 MNIST、EMNIST、CIFAR-10、CIFAR-100、PACS、VLCS 和 OfficeHome）上的实验表明，该方法超过了现有最先进基线，展示了其鲁棒性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "68Q32, 68Q32",
        "I.4.0; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 15 figures, ICLR",
      "pdf_url": "http://arxiv.org/pdf/2501.14653v1",
      "published_date": "2025-01-24 17:20:22 UTC",
      "updated_date": "2025-01-24 17:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:53:58.590258"
    },
    {
      "arxiv_id": "2501.14856v2",
      "title": "Noise-conditioned Energy-based Annealed Rewards (NEAR): A Generative Framework for Imitation Learning from Observation",
      "title_zh": "翻译失败",
      "authors": [
        "Anish Abhijit Diwan",
        "Julen Urain",
        "Jens Kober",
        "Jan Peters"
      ],
      "abstract": "This paper introduces a new imitation learning framework based on\nenergy-based generative models capable of learning complex, physics-dependent,\nrobot motion policies through state-only expert motion trajectories. Our\nalgorithm, called Noise-conditioned Energy-based Annealed Rewards (NEAR),\nconstructs several perturbed versions of the expert's motion data distribution\nand learns smooth, and well-defined representations of the data distribution's\nenergy function using denoising score matching. We propose to use these learnt\nenergy functions as reward functions to learn imitation policies via\nreinforcement learning. We also present a strategy to gradually switch between\nthe learnt energy functions, ensuring that the learnt rewards are always\nwell-defined in the manifold of policy-generated samples. We evaluate our\nalgorithm on complex humanoid tasks such as locomotion and martial arts and\ncompare it with state-only adversarial imitation learning algorithms like\nAdversarial Motion Priors (AMP). Our framework sidesteps the optimisation\nchallenges of adversarial imitation learning techniques and produces results\ncomparable to AMP in several quantitative metrics across multiple imitation\nsettings.",
      "tldr_zh": "本文提出了一种新的模仿学习框架 Noise-conditioned Energy-based Annealed Rewards (NEAR)，基于能量基生成模型，从仅状态的专家运动轨迹中学习复杂的、依赖物理的机器人运动策略。NEAR 通过构建专家数据的扰动版本，并使用去噪分数匹配学习数据分布的能量函数，将这些函数作为奖励函数结合强化学习来训练模仿策略，同时采用逐步切换策略确保奖励函数在策略生成样本上始终定义良好。在实验中，NEAR 在人形任务如运动和武术上与 Adversarial Motion Priors (AMP) 等算法在多个量化指标上表现相当，同时规避了对抗性模仿学习的优化挑战。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted as a conference paper at the International Conference on\n  Learning Representations (ICLR) 2025. Revised to include review feedback",
      "pdf_url": "http://arxiv.org/pdf/2501.14856v2",
      "published_date": "2025-01-24 17:15:49 UTC",
      "updated_date": "2025-02-12 10:36:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:54:10.132111"
    },
    {
      "arxiv_id": "2501.14644v1",
      "title": "Whisper D-SGD: Correlated Noise Across Agents for Differentially Private Decentralized Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Angelo Rodio",
        "Zheng Chen",
        "Erik G. Larsson"
      ],
      "abstract": "Decentralized learning enables distributed agents to train a shared machine\nlearning model through local computation and peer-to-peer communication.\nAlthough each agent retains its dataset locally, the communication of local\nmodels can still expose private information to adversaries. To mitigate these\nthreats, local differential privacy (LDP) injects independent noise per agent,\nbut it suffers a larger utility gap than central differential privacy (CDP). We\nintroduce Whisper D-SGD, a novel covariance-based approach that generates\ncorrelated privacy noise across agents, unifying several state-of-the-art\nmethods as special cases. By leveraging network topology and mixing weights,\nWhisper D-SGD optimizes the noise covariance to achieve network-wide noise\ncancellation. Experimental results show that Whisper D-SGD cancels more noise\nthan existing pairwise-correlation schemes, substantially narrowing the CDP-LDP\ngap and improving model performance under the same privacy guarantees.",
      "tldr_zh": "这篇论文提出了Whisper D-SGD，一种基于协方差的方法，用于差分隐私（Differentially Private）的去中心化学习（Decentralized Learning），通过在代理间生成相关隐私噪声来解决传统本地差分隐私（LDP）实用性不如中心差分隐私（CDP）的缺点。该方法利用网络拓扑和混合权重优化噪声协方差，实现网络级噪声取消，并将现有几种先进方案统一为特例。实验结果显示，Whisper D-SGD 比现有的成对相关方案取消更多噪声，显著缩小了CDP-LDP差距，并在相同隐私保证下提升了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2501.14644v1",
      "published_date": "2025-01-24 17:05:00 UTC",
      "updated_date": "2025-01-24 17:05:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:54:21.842724"
    },
    {
      "arxiv_id": "2501.17178v3",
      "title": "Tuning LLM Judge Design Decisions for 1/1000 of the Cost",
      "title_zh": "翻译失败",
      "authors": [
        "David Salinas",
        "Omar Swelam",
        "Frank Hutter"
      ],
      "abstract": "Evaluating Large Language Models (LLMs) often requires costly human\nannotations. To address this, LLM-based judges have been proposed, which\ncompare the outputs of two LLMs enabling the ranking of models without human\nintervention. While several approaches have been proposed, many confounding\nfactors are present between different papers. For instance the model, the\nprompt and other hyperparameters are typically changed at the same time making\napple-to-apple comparisons challenging. In this paper, we propose to\nsystematically analyze and tune hyperparameter of LLM judges. To alleviate the\nhigh cost of evaluating a judge, we propose to leverage multi-objective\nmulti-fidelity which allows to find judges that trades accuracy for cost and\nalso reduce significantly the cost of the search. Our method identifies judges\nthat not only outperform existing benchmarks in accuracy and cost-efficiency\nbut also utilize open-weight models, ensuring greater accessibility and\nreproducibility.",
      "tldr_zh": "这篇论文针对评估大型语言模型 (LLMs) 的高成本问题，提出系统分析和调整 LLM-based judges 的超参数，以实现无需人类干预的模型输出比较。作者引入多目标多保真度 (multi-objective multi-fidelity) 方法，优化 judges 的设计，使其在准确性和成本之间权衡，同时将搜索成本降低至原来的 1/1000。实验结果表明，该方法开发的 judges 不仅在准确性和效率上优于现有基准，还使用开源模型，确保了更高的可访问性和可重复性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17178v3",
      "published_date": "2025-01-24 17:01:14 UTC",
      "updated_date": "2025-03-18 09:09:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:54:34.119888"
    },
    {
      "arxiv_id": "2501.14634v1",
      "title": "Recommending Actionable Strategies: A Semantic Approach to Integrating Analytical Frameworks with Decision Heuristics",
      "title_zh": "推荐可行动策略：一种语义方法，用于整合分析框架与决策启发式",
      "authors": [
        "Renato Ghisellini",
        "Remo Pareschi",
        "Marco Pedroni",
        "Giovanni Battista Raggi"
      ],
      "abstract": "We present a novel approach for recommending actionable strategies by\nintegrating strategic frameworks with decision heuristics through semantic\nanalysis. While strategy frameworks provide systematic models for assessment\nand planning, and decision heuristics encode experiential knowledge,these\ntraditions have historically remained separate. Our methodology bridges this\ngap using advanced natural language processing (NLP), demonstrated through\nintegrating frameworks like the 6C model with the Thirty-Six Stratagems. The\napproach employs vector space representations and semantic similarity\ncalculations to map framework parameters to heuristic patterns, supported by a\ncomputational architecture that combines deep semantic processing with\nconstrained use of Large Language Models. By processing both primary content\nand secondary elements (diagrams, matrices) as complementary linguistic\nrepresentations, we demonstrate effectiveness through corporate strategy case\nstudies. The methodology generalizes to various analytical frameworks and\nheuristic sets, culminating in a plug-and-play architecture for generating\nrecommender systems that enable cohesive integration of strategic frameworks\nand decision heuristics into actionable guidance.",
      "tldr_zh": "本文提出一种新方法，通过语义分析将战略框架（如6C model）和决策启发式（如Thirty-Six Stratagems）整合起来，以推荐可行动策略，从而桥接两者间的历史鸿沟。方法采用高级NLP技术，包括向量空间表示和语义相似性计算，将框架参数映射到启发式模式，并结合深度语义处理与受限Large Language Models的计算架构。实验通过企业战略案例研究证明了该方法的有效性，并构建了一个可泛化的即插即用推荐系统，提供统一的行动指导。",
      "categories": [
        "cs.AI",
        "I.2.7; J.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14634v1",
      "published_date": "2025-01-24 16:53:37 UTC",
      "updated_date": "2025-01-24 16:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:54:46.373569"
    },
    {
      "arxiv_id": "2501.14630v2",
      "title": "Extracting Problem Structure with LLMs for Optimized SAT Local Search",
      "title_zh": "翻译失败",
      "authors": [
        "André Schidler",
        "Stefan Szeider"
      ],
      "abstract": "Local search preprocessing makes Conflict-Driven Clause Learning (CDCL)\nsolvers faster by providing high-quality starting points and modern SAT solvers\nhave incorporated this technique into their preprocessing steps. However, these\ntools rely on basic strategies that miss the structural patterns in problems.\nWe present a method that applies Large Language Models (LLMs) to analyze\nPython-based encoding code. This reveals hidden structural patterns in how\nproblems convert into SAT. Our method automatically generates specialized local\nsearch algorithms that find these patterns and use them to create strong\ninitial assignments. This works for any problem instance from the same encoding\ntype. Our tests show encouraging results, achieving faster solving times\ncompared to baseline preprocessing systems.",
      "tldr_zh": "本研究提出了一种使用 LLMs 分析 Python 编码的方法，以提取 SAT 问题中的隐藏结构模式，从而优化本地搜索预处理。相比传统策略，该方法能自动生成专门的本地搜索算法，利用这些模式创建高质量的初始赋值，提升 CDCL 求解器的效率。该方法适用于同一编码类型的任何问题实例，实验显示其比基线预处理系统实现了更快的求解时间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14630v2",
      "published_date": "2025-01-24 16:49:08 UTC",
      "updated_date": "2025-02-04 13:55:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:54:57.774294"
    },
    {
      "arxiv_id": "2501.14622v3",
      "title": "ACT-JEPA: Novel Joint-Embedding Predictive Architecture for Efficient Policy Representation Learning",
      "title_zh": "ACT-JEPA：新颖的联合嵌入预测架构，用于高效策略表示学习",
      "authors": [
        "Aleksandar Vujinovic",
        "Aleksandar Kovacevic"
      ],
      "abstract": "Learning efficient representations for decision-making policies is a\nchallenge in imitation learning (IL). Current IL methods require expert\ndemonstrations, which are expensive to collect. Consequently, they often have\nunderdeveloped world models. Self-supervised learning (SSL) offers an\nalternative by allowing models to learn from diverse, unlabeled data, including\nfailures. However, SSL methods often operate in raw input space, making them\ninefficient. In this work, we propose ACT-JEPA, a novel architecture that\nintegrates IL and SSL to enhance policy representations. We train a policy to\npredict (1) action sequences and (2) abstract observation sequences. The first\nobjective uses action chunking to improve action prediction and reduce\ncompounding errors. The second objective extends this idea of chunking by\npredicting abstract observation sequences. We utilize Joint-Embedding\nPredictive Architecture to predict in abstract representation space, allowing\nthe model to filter out irrelevant details, improve efficiency, and develop a\nrobust world model. Our experiments show that ACT-JEPA improves the quality of\nrepresentations by learning temporal environment dynamics. Additionally, the\nmodel's ability to predict abstract observation sequences results in\nrepresentations that effectively generalize to action sequence prediction.\nACT-JEPA performs on par with established baselines across a range of\ndecision-making tasks.",
      "tldr_zh": "这篇论文提出了ACT-JEPA，一种新型的Joint-Embedding Predictive Architecture，用于高效的政策表示学习，旨在解决Imitation Learning (IL)中依赖昂贵专家演示的问题，并整合Self-Supervised Learning (SSL)以从无标签数据中学习。方法包括训练策略预测动作序列（通过动作分块减少累积错误）和抽象观察序列（在抽象表示空间中预测，以过滤无关细节并构建稳健的世界模型）。实验结果显示，ACT-JEPA通过学习时间环境动态提升了表示质量，实现有效泛化，并在各种决策任务中与基准模型表现相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14622v3",
      "published_date": "2025-01-24 16:41:41 UTC",
      "updated_date": "2025-04-02 11:15:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:55:10.337915"
    },
    {
      "arxiv_id": "2501.14610v1",
      "title": "Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently Enhance Speech Separation in Real-World Listening Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Feyisayo Olalere",
        "Kiki van der Heijden",
        "Christiaan H. Stronks",
        "Jeroen Briaire",
        "Johan HM Frijns",
        "Marcel van Gerven"
      ],
      "abstract": "Speech separation approaches for single-channel, dry speech mixtures have\nsignificantly improved. However, real-world spatial and reverberant acoustic\nenvironments remain challenging, limiting the effectiveness of these approaches\nfor assistive hearing devices like cochlear implants (CIs). To address this, we\nquantify the impact of real-world acoustic scenes on speech separation and\nexplore how spatial cues can enhance separation quality efficiently. We analyze\nperformance based on implicit spatial cues (inherent in the acoustic input and\nlearned by the model) and explicit spatial cues (manually calculated spatial\nfeatures added as auxiliary inputs). Our findings show that spatial cues (both\nimplicit and explicit) improve separation for mixtures with spatially separated\nand nearby talkers. Furthermore, spatial cues enhance separation when spectral\ncues are ambiguous, such as when voices are similar. Explicit spatial cues are\nparticularly beneficial when implicit spatial cues are weak. For instance,\nsingle CI microphone recordings provide weaker implicit spatial cues than\nbilateral CIs, but even single CIs benefit from explicit cues. These results\nemphasize the importance of training models on real-world data to improve\ngeneralizability in everyday listening scenarios. Additionally, our statistical\nanalyses offer insights into how data properties influence model performance,\nsupporting the development of efficient speech separation approaches for CIs\nand other assistive devices in real-world settings.",
      "tldr_zh": "本研究探讨了在真实世界声学环境中，利用人工耳蜗(CIs)麦克风的空间线索来提升语音分离效率，以应对混响和空间挑战。研究比较了隐式空间线索（从声学输入中学习）和显式空间线索（手动计算的辅助特征），发现两者都能改善说话者分离效果，尤其在声音相似或空间位置模糊时，显式线索更为有效。结果显示，训练模型使用真实世界数据可显著提高泛化性，并为开发高效的CIs和其他助听设备提供关键见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14610v1",
      "published_date": "2025-01-24 16:30:58 UTC",
      "updated_date": "2025-01-24 16:30:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:55:22.591233"
    },
    {
      "arxiv_id": "2502.14868v1",
      "title": "Unlocking the Black Box: Analysing the EU Artificial Intelligence Act's Framework for Explainability in AI",
      "title_zh": "揭开黑箱：分析欧盟人工智能法案中人工智能解释性的框架",
      "authors": [
        "Georgios Pavlidis"
      ],
      "abstract": "The lack of explainability of Artificial Intelligence (AI) is one of the\nfirst obstacles that the industry and regulators must overcome to mitigate the\nrisks associated with the technology. The need for eXplainable AI (XAI) is\nevident in fields where accountability, ethics and fairness are critical, such\nas healthcare, credit scoring, policing and the criminal justice system. At the\nEU level, the notion of explainability is one of the fundamental principles\nthat underpin the AI Act, though the exact XAI techniques and requirements are\nstill to be determined and tested in practice. This paper explores various\napproaches and techniques that promise to advance XAI, as well as the\nchallenges of implementing the principle of explainability in AI governance and\npolicies. Finally, the paper examines the integration of XAI into EU law,\nemphasising the issues of standard setting, oversight, and enforcement.",
      "tldr_zh": "这篇论文分析了AI缺乏可解释性（XAI）所带来的风险，并强调了在医疗、信用评分、警务和刑事司法等领域中责任、伦理和公平性的重要性。论文探讨了各种推进XAI的方法和技术，以及在AI治理和政策中实施可解释性原则的挑战，包括标准制定、监督和执行问题。最终，它考察了XAI如何整合到欧盟人工智能法案（EU Artificial Intelligence Act）中，为未来AI监管提供关键见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14868v1",
      "published_date": "2025-01-24 16:30:19 UTC",
      "updated_date": "2025-01-24 16:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:55:33.279061"
    },
    {
      "arxiv_id": "2501.18616v1",
      "title": "STAMP: Scalable Task And Model-agnostic Collaborative Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangbo Gao",
        "Runsheng Xu",
        "Jiachen Li",
        "Ziran Wang",
        "Zhiwen Fan",
        "Zhengzhong Tu"
      ],
      "abstract": "Perception is crucial for autonomous driving, but single-agent perception is\noften constrained by sensors' physical limitations, leading to degraded\nperformance under severe occlusion, adverse weather conditions, and when\ndetecting distant objects. Multi-agent collaborative perception offers a\nsolution, yet challenges arise when integrating heterogeneous agents with\nvarying model architectures. To address these challenges, we propose STAMP, a\nscalable task- and model-agnostic, collaborative perception pipeline for\nheterogeneous agents. STAMP utilizes lightweight adapter-reverter pairs to\ntransform Bird's Eye View (BEV) features between agent-specific and shared\nprotocol domains, enabling efficient feature sharing and fusion. This approach\nminimizes computational overhead, enhances scalability, and preserves model\nsecurity. Experiments on simulated and real-world datasets demonstrate STAMP's\ncomparable or superior accuracy to state-of-the-art models with significantly\nreduced computational costs. As a first-of-its-kind task- and model-agnostic\nframework, STAMP aims to advance research in scalable and secure mobility\nsystems towards Level 5 autonomy. Our project page is at\nhttps://xiangbogaobarry.github.io/STAMP and the code is available at\nhttps://github.com/taco-group/STAMP.",
      "tldr_zh": "该论文提出 STAMP，一种可扩展的任务和模型无关的协作感知框架，旨在解决自动驾驶中单代理感知的局限性，如严重遮挡、恶劣天气和远距离物体检测问题。STAMP 通过轻量级 adapter-reverter 对在代理特定和共享协议域之间转换 Bird's Eye View (BEV) 特征，实现异构代理间的高效特征共享和融合，从而减少计算开销并提升系统可扩展性和安全性。实验在模拟和真实数据集上表明，STAMP 的准确性与最先进模型相当或优于它们，同时显著降低计算成本，为推进可扩展、安全的移动系统向 Level 5 autonomy 发展提供了新框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper is accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.18616v1",
      "published_date": "2025-01-24 16:27:28 UTC",
      "updated_date": "2025-01-24 16:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:55:47.148491"
    },
    {
      "arxiv_id": "2501.14603v1",
      "title": "Age and Power Minimization via Meta-Deep Reinforcement Learning in UAV Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Sankani Sarathchandra",
        "Eslam Eldeeb",
        "Mohammad Shehab",
        "Hirley Alves",
        "Konstantin Mikhaylov",
        "Mohamed-Slim Alouini"
      ],
      "abstract": "Age-of-information (AoI) and transmission power are crucial performance\nmetrics in low energy wireless networks, where information freshness is of\nparamount importance. This study examines a power-limited internet of things\n(IoT) network supported by a flying unmanned aerial vehicle(UAV) that collects\ndata. Our aim is to optimize the UAV flight trajectory and scheduling policy to\nminimize a varying AoI and transmission power combination. To tackle this\nvariation, this paper proposes a meta-deep reinforcement learning (RL) approach\nthat integrates deep Q-networks (DQNs) with model-agnostic meta-learning\n(MAML). DQNs determine optimal UAV decisions, while MAML enables scalability\nacross varying objective functions. Numerical results indicate that the\nproposed algorithm converges faster and adapts to new objectives more\neffectively than traditional deep RL methods, achieving minimal AoI and\ntransmission power overall.",
      "tldr_zh": "这篇论文研究了在无人机（UAV）支持的低能耗物联网（IoT）网络中，通过优化飞行轨迹和调度策略来最小化信息新鲜度（Age-of-Information, AoI）和传输功率的组合。作者提出了一种meta-deep reinforcement learning方法，结合深度Q网络（DQNs）用于决策和模型无关元学习（MAML）以实现对不同目标函数的适应性扩展。实验结果表明，该算法比传统深度强化学习方法收敛更快、更高效，最终实现了AoI和传输功率的整体最小化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14603v1",
      "published_date": "2025-01-24 16:17:53 UTC",
      "updated_date": "2025-01-24 16:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:55:58.445149"
    },
    {
      "arxiv_id": "2501.18614v1",
      "title": "Review and Recommendations for using Artificial Intelligence in Intracoronary Optical Coherence Tomography Analysis",
      "title_zh": "在冠状动脉内光学相干断层扫描分析中使用人工智能的回顾与推荐",
      "authors": [
        "Xu Chen",
        "Yuan Huang",
        "Benn Jessney",
        "Jason Sangha",
        "Sophie Gu",
        "Carola-Bibiane Schönlieb",
        "Martin Bennett",
        "Michael Roberts"
      ],
      "abstract": "Artificial intelligence (AI) methodologies hold great promise for the rapid\nand accurate diagnosis of coronary artery disease (CAD) from intravascular\noptical coherent tomography (IVOCT) images. Numerous papers have been published\ndescribing AI-based models for different diagnostic tasks, yet it remains\nunclear which models have potential clinical utility and have been properly\nvalidated. This systematic review considered published literature between\nJanuary 2015 and February 2023 describing AI-based diagnosis of CAD using\nIVOCT. Our search identified 5,576 studies, with 513 included after initial\nscreening and 35 studies included in the final systematic review after quality\nscreening. Our findings indicate that most of the identified models are not\ncurrently suitable for clinical use, primarily due to methodological flaws and\nunderlying biases. To address these issues, we provide recommendations to\nimprove model quality and research practices to enhance the development of\nclinically useful AI products.",
      "tldr_zh": "这篇论文系统综述了使用Artificial Intelligence (AI)分析Intracoronary Optical Coherence Tomography (IVOCT)图像以诊断Coronary Artery Disease (CAD)的研究现状。作者搜索了2015年1月至2023年2月间的文献，共筛选出35篇高质量研究，并评估了这些AI模型的临床适用性。结果显示，大多数模型因方法论缺陷和潜在偏见而无法实际应用于临床。论文提供了具体推荐，以提升模型质量和研究实践，从而促进AI在CAD诊断中的可靠发展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18614v1",
      "published_date": "2025-01-24 16:06:32 UTC",
      "updated_date": "2025-01-24 16:06:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:56:09.646773"
    },
    {
      "arxiv_id": "2501.14851v2",
      "title": "JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Michael K. Chen",
        "Xikun Zhang",
        "Dacheng Tao"
      ],
      "abstract": "Logical reasoning is a critical component of Large Language Models (LLMs),\nand substantial research efforts in recent years have aimed to enhance their\ndeductive reasoning capabilities. However, existing deductive reasoning\nbenchmarks, which are crucial for evaluating and advancing LLMs, are inadequate\ndue to their lack of task complexity, presence of prior knowledge as a\nconfounder, and superficial error analysis. To address these deficiencies, we\nintroduce JustLogic, a synthetically generated deductive reasoning benchmark\ndesigned for rigorous evaluation of LLMs. JustLogic is (i) highly complex,\ncapable of generating a diverse range of linguistic patterns, vocabulary, and\nargument structures; (ii) prior knowledge independent, eliminating the\nadvantage of models possessing prior knowledge and ensuring that only deductive\nreasoning is used to answer questions; and (iii) capable of in-depth error\nanalysis on the heterogeneous effects of reasoning depth and argument form on\nmodel accuracy. Our experimental results on JustLogic reveal that (i)\nstate-of-the-art (SOTA) reasoning LLMs perform on par or better than the human\naverage but significantly worse than the human ceiling, and (ii) SOTA\nnon-reasoning models still underperform the human average. All code and data\nare available at https://github.com/michaelchen-lab/JustLogic",
      "tldr_zh": "该研究指出，现有的演绎推理基准存在任务复杂度低、先验知识干扰和错误分析不足等问题，因此引入 JustLogic，这是一个合成生成的全面基准，用于评估 Large Language Models (LLMs) 的演绎推理能力。JustLogic 具有高度复杂性，能生成多样化的语言模式、词汇和论证结构，同时确保独立于先验知识，并支持对推理深度和论证形式的影响进行深入错误分析。实验结果显示，state-of-the-art (SOTA) 推理 LLMs 的性能与人类平均水平相当或略优，但远低于人类上限，而 SOTA 非推理模型则显著落后于人类平均水平。该基准的代码和数据已公开在 GitHub 上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14851v2",
      "published_date": "2025-01-24 15:49:10 UTC",
      "updated_date": "2025-05-09 05:26:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:56:22.101806"
    },
    {
      "arxiv_id": "2501.14850v1",
      "title": "On the locality bias and results in the Long Range Arena",
      "title_zh": "关于 Long Range Arena 中的局部偏差及其结果",
      "authors": [
        "Pablo Miralles-González",
        "Javier Huertas-Tato",
        "Alejandro Martín",
        "David Camacho"
      ],
      "abstract": "The Long Range Arena (LRA) benchmark was designed to evaluate the performance\nof Transformer improvements and alternatives in long-range dependency modeling\ntasks. The Transformer and its main variants performed poorly on this\nbenchmark, and a new series of architectures such as State Space Models (SSMs)\ngained some traction, greatly outperforming Transformers in the LRA. Recent\nwork has shown that with a denoising pre-training phase, Transformers can\nachieve competitive results in the LRA with these new architectures. In this\nwork, we discuss and explain the superiority of architectures such as MEGA and\nSSMs in the Long Range Arena, as well as the recent improvement in the results\nof Transformers, pointing to the positional and local nature of the tasks. We\nshow that while the LRA is a benchmark for long-range dependency modeling, in\nreality most of the performance comes from short-range dependencies. Using\ntraining techniques to mitigate data inefficiency, Transformers are able to\nreach state-of-the-art performance with proper positional encoding. In\naddition, with the same techniques, we were able to remove all restrictions\nfrom SSM convolutional kernels and learn fully parameterized convolutions\nwithout decreasing performance, suggesting that the design choices behind SSMs\nsimply added inductive biases and learning efficiency for these particular\ntasks. Our insights indicate that LRA results should be interpreted with\ncaution and call for a redesign of the benchmark.",
      "tldr_zh": "该研究分析了 Long Range Arena (LRA) 基准测试中的局部偏差问题，指出尽管 LRA 旨在评估 Transformer 和替代架构如 State Space Models (SSMs) 在长距离依赖建模中的性能，但实际表现主要依赖短距离依赖。作者通过训练技巧（如去噪预训练和适当的 positional encoding）使 Transformer 达到最先进水平，并证明 SSMs 的优势源于其归纳偏差和学习效率，而非核心设计。结果显示，这些见解表明 LRA 结果需谨慎解读，并呼吁对基准测试进行重新设计。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14850v1",
      "published_date": "2025-01-24 15:34:50 UTC",
      "updated_date": "2025-01-24 15:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:56:34.354137"
    },
    {
      "arxiv_id": "2501.14577v3",
      "title": "ZETA: Leveraging Z-order Curves for Efficient Top-k Attention",
      "title_zh": "ZETA：利用 Z-order 曲线实现高效 Top-k 注意力",
      "authors": [
        "Qiuhao Zeng",
        "Jerry Huang",
        "Peng Lu",
        "Gezheng Xu",
        "Boxing Chen",
        "Charles Ling",
        "Boyu Wang"
      ],
      "abstract": "Over recent years, the Transformer has become a fundamental building block\nfor sequence modeling architectures. Yet at its core is the use of\nself-attention, whose memory and computational cost grow quadratically with the\nsequence length $N$, rendering it prohibitively expensive for long sequences. A\npromising approach is top-$k$ attention, which selects only the $k$ most\nrelevant tokens and achieves performance comparable to vanilla self-attention\nwhile significantly reducing space and computational demands. However, causal\nmasks require the current query token to only attend to past tokens, preventing\nthe existing top-$k$ attention method from efficiently searching for the most\nrelevant tokens in parallel, thereby limiting training efficiency. In this\nwork, we propose ZETA, leveraging \\textbf{Z}-Order Curves for\n\\textbf{E}fficient \\textbf{T}op-$k$ \\textbf{A}ttention, to enable parallel\nquerying of past tokens for entire sequences. % in both space and time\ncomplexity of $\\mathcal{O}(N \\log N)$. We first theoretically show that the\nchoice of key and query dimensions involves a trade-off between the curse of\ndimensionality and the preservation of relative distances after projection. In\nlight of this insight, we propose reducing the dimensionality of keys and\nqueries in contrast to values and further leverage $Z$-order curves to map\nlow-dimensional keys and queries into \\emph{one}-dimensional space, which\npermits parallel sorting, thereby largely improving the efficiency for top-$k$\ntoken selection. Experimental results demonstrate that ZETA matches the\nperformance of standard attention on the synthetic \\textsc{Multi-Query\nAssociative Recall} task and outperforms attention and its variants on\n\\textsc{Long Range Arena} and \\textsc{WikiText-103} language modeling.",
      "tldr_zh": "这篇论文提出 ZETA 方法，利用 Z-order Curves 优化 Top-k Attention，以解决 Transformer 模型中自注意力的计算和内存成本随序列长度 N 平方增长的问题。ZETA 通过降低 key 和 query 的维度，并将它们映射到一维空间以实现并行排序和查询，实现了 O(N log N) 的复杂度，并在因果掩码下提高了训练效率。实验结果表明，ZETA 在 Multi-Query Associative Recall 任务上与标准注意力性能相当，并在 Long Range Arena 和 WikiText-103 语言建模任务上优于其他注意力变体。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 4 figures, accepted in International Conference on Learning\n  Representations (ICLR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14577v3",
      "published_date": "2025-01-24 15:33:05 UTC",
      "updated_date": "2025-04-01 04:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:56:46.545713"
    },
    {
      "arxiv_id": "2501.14568v1",
      "title": "Hybrid Quantum-Classical Multi-Agent Pathfinding",
      "title_zh": "混合量子-经典多智能体路径规划",
      "authors": [
        "Thore Gerlach",
        "Loong Kuan Lee",
        "Frédéric Barbaresco",
        "Nico Piatkowski"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) focuses on determining conflict-free paths\nfor multiple agents navigating through a shared space to reach specified goal\nlocations. This problem becomes computationally challenging, particularly when\nhandling large numbers of agents, as frequently encountered in practical\napplications like coordinating autonomous vehicles. Quantum computing (QC) is a\npromising candidate in overcoming such limits. However, current quantum\nhardware is still in its infancy and thus limited in terms of computing power\nand error robustness. In this work, we present the first optimal hybrid\nquantum-classical MAPF algorithm which is based on branch-and-cut-and-prize. QC\nis integrated by iteratively solving QUBO problems, based on conflict graphs.\nExperiments on actual quantum hardware and results on benchmark data suggest\nthat our approach dominates previous QUBO formulations and baseline MAPF\nsolvers.",
      "tldr_zh": "这篇论文针对 Multi-Agent Path Finding (MAPF) 的计算挑战，提出了一种混合量子-经典算法，用于为多个代理在共享空间中找到无冲突路径，尤其适用于大规模场景如自主车辆协调。算法基于 branch-and-cut-and-prize 方法，通过迭代解决 QUBO 问题（基于冲突图）来整合 Quantum Computing (QC)，以克服当前量子硬件的局限性。实验结果表明，该方法在实际量子硬件和基准数据上优于现有 QUBO 公式和 MAPF 求解器，提供了一个更高效的优化解决方案。",
      "categories": [
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14568v1",
      "published_date": "2025-01-24 15:20:09 UTC",
      "updated_date": "2025-01-24 15:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:56:58.290230"
    },
    {
      "arxiv_id": "2501.16380v1",
      "title": "UDiTQC: U-Net-Style Diffusion Transformer for Quantum Circuit Synthesis",
      "title_zh": "UDiTQC：U-Net 风格的扩散 Transformer 用于量子电路合成",
      "authors": [
        "Zhiwei Chen",
        "Hao Tang"
      ],
      "abstract": "Quantum computing is a transformative technology with wide-ranging\napplications, and efficient quantum circuit generation is crucial for unlocking\nits full potential. Current diffusion model approaches based on U-Net\narchitectures, while promising, encounter challenges related to computational\nefficiency and modeling global context. To address these issues, we propose\nUDiT,a novel U-Net-style Diffusion Transformer architecture, which combines\nU-Net's strengths in multi-scale feature extraction with the Transformer's\nability to model global context. We demonstrate the framework's effectiveness\non two tasks: entanglement generation and unitary compilation, where UDiTQC\nconsistently outperforms existing methods. Additionally, our framework supports\ntasks such as masking and editing circuits to meet specific physical property\nrequirements. This dual advancement, improving quantum circuit synthesis and\nrefining generative model architectures, marks a significant milestone in the\nconvergence of quantum computing and machine learning research.",
      "tldr_zh": "该论文提出 UDiTQC，一种基于 U-Net 风格的扩散 Transformer 架构，用于量子电路合成，以解决传统 U-Net 模型在计算效率和全局上下文建模方面的挑战。UDiT 结合 U-Net 的多尺度特征提取优势与 Transformer 的全局建模能力，在纠缠生成和幺正编译任务上表现出色，比现有方法性能更优，并支持电路掩码和编辑以满足特定物理属性需求。该框架的创新不仅提升了量子电路合成的效率，还标志着量子计算与机器学习研究融合的重要里程碑。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16380v1",
      "published_date": "2025-01-24 15:15:50 UTC",
      "updated_date": "2025-01-24 15:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:57:09.621952"
    },
    {
      "arxiv_id": "2501.14546v1",
      "title": "Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite Images by Poverty Level: Advancing Tools for Social Science Research",
      "title_zh": "利用 ChatGPT 的多模态视觉能力对卫星图像按贫困水平进行排名：推进社会科学研究工具",
      "authors": [
        "Hamid Sarmadi",
        "Ola Hall",
        "Thorsteinn Rögnvaldsson",
        "Mattias Ohlsson"
      ],
      "abstract": "This paper investigates the novel application of Large Language Models (LLMs)\nwith vision capabilities to analyze satellite imagery for village-level poverty\nprediction. Although LLMs were originally designed for natural language\nunderstanding, their adaptability to multimodal tasks, including geospatial\nanalysis, has opened new frontiers in data-driven research. By leveraging\nadvancements in vision-enabled LLMs, we assess their ability to provide\ninterpretable, scalable, and reliable insights into human poverty from\nsatellite images. Using a pairwise comparison approach, we demonstrate that\nChatGPT can rank satellite images based on poverty levels with accuracy\ncomparable to domain experts. These findings highlight both the promise and the\nlimitations of LLMs in socioeconomic research, providing a foundation for their\nintegration into poverty assessment workflows. This study contributes to the\nongoing exploration of unconventional data sources for welfare analysis and\nopens pathways for cost-effective, large-scale poverty monitoring.",
      "tldr_zh": "这篇论文探讨了利用ChatGPT的多模态视觉能力，通过配对比较方法对卫星图像按贫困水平进行排序，从而预测村庄级别的贫困情况。研究证明，ChatGPT在这一任务中的准确率可与领域专家相当，同时提供可解释、可扩展和可靠的洞见。论文突出了LLMs在社会经济研究中的前景与局限性，并为整合这些模型到贫困评估工作流中提供了基础，促进了成本有效的、大规模贫困监测工具的开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14546v1",
      "published_date": "2025-01-24 14:49:00 UTC",
      "updated_date": "2025-01-24 14:49:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:57:22.289014"
    },
    {
      "arxiv_id": "2501.14544v2",
      "title": "Distributed Conformal Prediction via Message Passing",
      "title_zh": "通过消息传递的分布式保形预测",
      "authors": [
        "Haifeng Wen",
        "Hong Xing",
        "Osvaldo Simeone"
      ],
      "abstract": "Post-hoc calibration of pre-trained models is critical for ensuring reliable\ninference, especially in safety-critical domains such as healthcare. Conformal\nPrediction (CP) offers a robust post-hoc calibration framework, providing\ndistribution-free statistical coverage guarantees for prediction sets by\nleveraging held-out datasets. In this work, we address a decentralized setting\nwhere each device has limited calibration data and can communicate only with\nits neighbors over an arbitrary graph topology. We propose two\nmessage-passing-based approaches for achieving reliable inference via CP:\nquantile-based distributed conformal prediction (Q-DCP) and histogram-based\ndistributed conformal prediction (H-DCP). Q-DCP employs distributed quantile\nregression enhanced with tailored smoothing and regularization terms to\naccelerate convergence, while H-DCP uses a consensus-based histogram estimation\napproach. Through extensive experiments, we investigate the trade-offs between\nhyperparameter tuning requirements, communication overhead, coverage\nguarantees, and prediction set sizes across different network topologies. The\ncode of our work is released on:\nhttps://github.com/HaifengWen/Distributed-Conformal-Prediction.",
      "tldr_zh": "该研究针对预训练模型的后验校准问题，提出了一种基于消息传递的分布式 Conformal Prediction (CP) 框架，以在去中心化环境中实现可靠的预测集覆盖保证。方法包括 Q-DCP，利用分布式分位数回归并添加平滑和正则化术语来加速收敛，以及 H-DCP，通过基于共识的直方图估计方法处理有限校准数据。实验结果显示，该框架在不同网络拓扑下平衡了超参数调整、通信开销、覆盖保证和预测集大小的权衡，并提供了开源代码以支持进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14544v2",
      "published_date": "2025-01-24 14:47:42 UTC",
      "updated_date": "2025-05-21 13:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:57:33.254875"
    },
    {
      "arxiv_id": "2501.14540v1",
      "title": "VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Callewaert",
        "Simon Vandevelde",
        "Joost Vennekens"
      ],
      "abstract": "A recent approach to neurosymbolic reasoning is to explicitly combine the\nstrengths of large language models (LLMs) and symbolic solvers to tackle\ncomplex reasoning tasks. However, current approaches face significant\nlimitations, including poor generalizability due to task-specific prompts,\ninefficiencies caused by the lack of separation between knowledge and queries,\nand restricted inferential capabilities. These shortcomings hinder their\nscalability and applicability across diverse domains. In this paper, we\nintroduce VERUS-LM, a novel framework designed to address these challenges.\nVERUS-LM employs a generic prompting mechanism, clearly separates domain\nknowledge from queries, and supports a wide range of different logical\nreasoning tasks. This framework enhances adaptability, reduces computational\ncost, and allows for richer forms of reasoning, such as optimization and\nconstraint satisfaction. We show that our approach succeeds in diverse\nreasoning on a novel dataset, markedly outperforming LLMs. Additionally, our\nsystem achieves competitive results on common reasoning benchmarks when\ncompared to other state-of-the-art approaches, and significantly surpasses them\non the difficult AR-LSAT dataset. By pushing the boundaries of hybrid\nreasoning, VERUS-LM represents a significant step towards more versatile\nneurosymbolic AI systems",
      "tldr_zh": "本研究针对现有神经符号推理方法的问题（如任务特定提示导致的泛化性差、知识和查询未分离的效率低下，以及推理能力限制），提出了一种多功能框架VERUS-LM。该框架通过通用提示机制、清晰分离领域知识和查询，以及支持多种逻辑推理任务（如优化和约束满足），增强了适应性和计算效率。实验结果显示，VERUS-LM在新数据集上显著优于LLMs，并在常见基准测试中与最先进方法竞争，同时在AR-LSAT数据集上大幅超越它们。总体而言，VERUS-LM推动了混合推理的发展，为更通用的neurosymbolic AI系统奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14540v1",
      "published_date": "2025-01-24 14:45:21 UTC",
      "updated_date": "2025-01-24 14:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:57:46.359899"
    },
    {
      "arxiv_id": "2501.14513v2",
      "title": "ABPT: Amended Backpropagation through Time with Partially Differentiable Rewards",
      "title_zh": "翻译失败",
      "authors": [
        "Fanxing Li",
        "Fangyu Sun",
        "Tianbao Zhang",
        "Danping Zou"
      ],
      "abstract": "Quadrotor control policies can be trained with high performance using the\nexact gradients of the rewards to directly optimize policy parameters via\nbackpropagation-through-time (BPTT). However, designing a fully differentiable\nreward architecture is often challenging. Partially differentiable rewards will\nresult in biased gradient propagation that degrades training performance. To\novercome this limitation, we propose Amended Backpropagation-through-Time\n(ABPT), a novel approach that mitigates gradient bias while preserving the\ntraining efficiency of BPTT. ABPT combines 0-step and N-step returns,\neffectively reducing the bias by leveraging value gradients from the learned\nQ-value function. Additionally, it adopts entropy regularization and state\ninitialization mechanisms to encourage exploration during training. We evaluate\nABPT on four representative quadrotor flight tasks \\li{in both real world and\nsimulation}. Experimental results demonstrate that ABPT converges significantly\nfaster and achieves higher ultimate rewards than existing learning algorithms,\nparticularly in tasks involving partially differentiable rewards. The code will\nbe released at http://github.com/Fanxing-LI/ABPT.",
      "tldr_zh": "本论文针对四旋翼无人机控制策略训练中，部分可微奖励导致 BPTT (Backpropagation through Time) 梯度偏差的问题，提出了一种新方法 ABPT (Amended Backpropagation-through-Time)。ABPT 通过结合 0-step 和 N-step returns，利用从 Q-value function 学得的价值梯度来减少偏差，同时引入 entropy regularization 和状态初始化机制以增强探索能力。在模拟和真实世界的四个代表性飞行任务上，实验结果显示 ABPT 比现有算法收敛更快并实现更高奖励，特别适用于部分可微奖励场景；代码将在 GitHub 上开源。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14513v2",
      "published_date": "2025-01-24 14:18:22 UTC",
      "updated_date": "2025-05-21 11:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:57:59.669556"
    },
    {
      "arxiv_id": "2501.14492v1",
      "title": "RealCritic: Towards Effectiveness-Driven Evaluation of Language Model Critiques",
      "title_zh": "RealCritic：面向有效性驱动的语言模型批评评估",
      "authors": [
        "Zhengyang Tang",
        "Ziniu Li",
        "Zhenyang Xiao",
        "Tian Ding",
        "Ruoyu Sun",
        "Benyou Wang",
        "Dayiheng Liu",
        "Fei Huang",
        "Tianyu Liu",
        "Bowen Yu",
        "Junyang Lin"
      ],
      "abstract": "Critiques are important for enhancing the performance of Large Language\nModels (LLMs), enabling both self-improvement and constructive feedback for\nothers by identifying flaws and suggesting improvements. However, evaluating\nthe critique capabilities of LLMs presents a significant challenge due to the\nopen-ended nature of the task. In this work, we introduce a new benchmark\ndesigned to assess the critique capabilities of LLMs. Unlike existing\nbenchmarks, which typically function in an open-loop fashion, our approach\nemploys a closed-loop methodology that evaluates the quality of corrections\ngenerated from critiques. Moreover, the benchmark incorporates features such as\nself-critique, cross-critique, and iterative critique, which are crucial for\ndistinguishing the abilities of advanced reasoning models from more classical\nones. We implement this benchmark using eight challenging reasoning tasks. We\nhave several interesting findings. First, despite demonstrating comparable\nperformance in direct chain-of-thought generation, classical LLMs significantly\nlag behind the advanced reasoning-based model o1-mini across all critique\nscenarios. Second, in self-critique and iterative critique settings, classical\nLLMs may even underperform relative to their baseline capabilities. We hope\nthat this benchmark will serve as a valuable resource to guide future\nadvancements. The code and data are available at\n\\url{https://github.com/tangzhy/RealCritic}.",
      "tldr_zh": "该研究提出RealCritic基准，旨在通过有效性驱动的方法评估大型语言模型（LLMs）的批评能力（critiques），以解决这一任务的开放性挑战。不同于传统的开放循环基准，RealCritic采用闭环方法（closed-loop methodology），评估批评生成的修正质量，并纳入self-critique、cross-critique和iterative critique等特征，使用八个挑战性推理任务进行测试。实验发现，尽管在直接chain-of-thought生成中表现类似，但经典LLMs在所有批评场景中显著落后于先进模型o1-mini；在self-critique和iterative critique设置中，经典LLMs甚至低于其基线性能。该基准有望指导未来LLMs改进，并提供了相关代码和数据资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14492v1",
      "published_date": "2025-01-24 13:48:10 UTC",
      "updated_date": "2025-01-24 13:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:58:10.042156"
    },
    {
      "arxiv_id": "2501.14483v1",
      "title": "Registration of Longitudinal Liver Examinations for Tumor Progress Assessment",
      "title_zh": "纵向肝脏检查的配准用于肿瘤进展评估",
      "authors": [
        "Walid Yassine",
        "Martin Charachon",
        "Céline Hudelot",
        "Roberto Ardon"
      ],
      "abstract": "Assessing cancer progression in liver CT scans is a clinical challenge,\nrequiring a comparison of scans at different times for the same patient.\nPractitioners must identify existing tumors, compare them with prior exams,\nidentify new tumors, and evaluate overall disease evolution. This process is\nparticularly complex in liver examinations due to misalignment between exams\ncaused by several factors. Indeed, longitudinal liver examinations can undergo\ndifferent non-pathological and pathological changes due to non-rigid\ndeformations, the appearance or disappearance of pathologies, and other\nvariations. In such cases, existing registration approaches, mainly based on\nintrinsic features may distort tumor regions, biasing the tumor progress\nevaluation step and the corresponding diagnosis. This work proposes a\nregistration method based only on geometrical and anatomical information from\nliver segmentation, aimed at aligning longitudinal liver images for aided\ndiagnosis. The proposed method is trained and tested on longitudinal liver CT\nscans, with 317 patients for training and 53 for testing. Our experimental\nresults support our claims by showing that our method is better than other\nregistration techniques by providing a smoother deformation while preserving\nthe tumor burden (total volume of tissues considered as tumor) within the\nvolume. Qualitative results emphasize the importance of smooth deformations in\npreserving tumor appearance.",
      "tldr_zh": "本文提出了一种基于肝脏分割的几何和解剖信息进行 longitudinal liver examinations 注册的方法，旨在解决肝脏 CT scans 中肿瘤进展评估的挑战，这些挑战源于扫描间的非刚性变形和病变变化，导致现有 registration 技术可能扭曲肿瘤区域。不同于基于内在特征的传统方法，该方法仅使用肝脏分割数据来实现图像对齐，从而提供更平滑的变形并保留肿瘤 burden（总肿瘤体积）。实验在 317 个患者训练集和 53 个测试集上进行，结果显示该方法优于其他技术，在定性评估中突出其在保持肿瘤外观方面的优势，为临床诊断提供更可靠的辅助。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14483v1",
      "published_date": "2025-01-24 13:35:59 UTC",
      "updated_date": "2025-01-24 13:35:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:58:23.176814"
    },
    {
      "arxiv_id": "2501.14474v1",
      "title": "The Pseudo-Dimension of Contracts",
      "title_zh": "合约的伪维",
      "authors": [
        "Paul Duetting",
        "Michal Feldman",
        "Tomasz Ponitka",
        "Ermis Soumalias"
      ],
      "abstract": "Algorithmic contract design studies scenarios where a principal incentivizes\nan agent to exert effort on her behalf. In this work, we focus on settings\nwhere the agent's type is drawn from an unknown distribution, and formalize an\noffline learning framework for learning near-optimal contracts from sample\nagent types. A central tool in our analysis is the notion of pseudo-dimension\nfrom statistical learning theory. Beyond its role in establishing upper bounds\non the sample complexity, pseudo-dimension measures the intrinsic complexity of\na class of contracts, offering a new perspective on the tradeoffs between\nsimplicity and optimality in contract design. Our main results provide\nessentially optimal tradeoffs between pseudo-dimension and representation error\n(defined as the loss in principal's utility) with respect to linear and bounded\ncontracts. Using these tradeoffs, we derive sample- and time-efficient learning\nalgorithms, and demonstrate their near-optimality by providing almost matching\nlower bounds on the sample complexity. Conversely, for unbounded contracts, we\nprove an impossibility result showing that no learning algorithm exists.\n  Finally, we extend our techniques in three important ways. First, we provide\nrefined pseudo-dimension and sample complexity guarantees for the combinatorial\nactions model, revealing a novel connection between the number of critical\nvalues and sample complexity. Second, we extend our results to menus of\ncontracts, showing that their pseudo-dimension scales linearly with the menu\nsize. Third, we adapt our algorithms to the online learning setting, where we\nshow that, a polynomial number of type samples suffice to learn near-optimal\nbounded contracts. Combined with prior work, this establishes a formal\nseparation between expert advice and bandit feedback for this setting.",
      "tldr_zh": "这篇论文研究算法合约设计，聚焦于代理人类型来自未知分布的场景，形式化了一个离线学习框架，从样本代理人类型中学习近优合约。论文引入伪维（pseudo-dimension）作为核心工具，不仅用于评估样本复杂度，还揭示了合约类内在复杂性与简单性与最优性之间的权衡。主要结果提供了伪维与表示误差（representation error）的基本最优权衡，开发了样本和时间高效的学习算法，并为线性及有界合约证明了近似最优性，同时证明无界合约的学习不可能。论文进一步扩展到组合动作模型、合约菜单（其伪维线性随菜单大小增长）和在线学习设置，展示了多项式样本数量即可学习近优有界合约，并与专家建议和 Bandit 反馈建立了正式分离。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14474v1",
      "published_date": "2025-01-24 13:13:50 UTC",
      "updated_date": "2025-01-24 13:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:58:35.553717"
    },
    {
      "arxiv_id": "2501.14469v2",
      "title": "Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design",
      "title_zh": "翻译失败",
      "authors": [
        "Taehan Kim",
        "Wonduk Seo"
      ],
      "abstract": "Global climate change has reduced crop resilience and pesticide efficacy,\nmaking reliance on synthetic pesticides inevitable, even though their\nwidespread use poses significant health and environmental risks. While these\npesticides remain a key tool in pest management, previous machine-learning\napplications in pesticide and agriculture have focused on classification or\nregression, leaving the fundamental challenge of generating new molecular\nstructures or designing novel candidates unaddressed. In this paper, we propose\nPesti-Gen, a novel generative model based on variational auto-encoders,\ndesigned to create pesticide candidates with optimized properties for the first\ntime. Specifically, Pesti-Gen leverages a two-stage learning process: an\ninitial pre-training phase that captures a generalized chemical structure\nrepresentation, followed by a fine-tuning stage that incorporates\ntoxicity-specific information. The model simultaneously optimizes over multiple\ntoxicity metrics, such as (1) livestock toxicity and (2) aqua toxicity to\ngenerate environmentally friendly pesticide candidates. Notably, Pesti-Gen\nachieves approximately 68\\% structural validity in generating new molecular\nstructures, demonstrating the model's effectiveness in producing optimized and\nfeasible pesticide candidates, thereby providing a new way for safer and more\nsustainable pest management solutions.",
      "tldr_zh": "该论文提出 Pesti-Gen，一种基于 Variational Auto-Encoders 的生成模型，用于首次设计毒性优化的农药候选物，以应对气候变化下合成农药的健康和环境风险。模型采用两阶段学习过程：先进行预训练捕获通用的化学结构表示，然后微调整合特定毒性指标，如 livestock toxicity 和 aqua toxicity，从而生成环境友好的分子结构。实验结果显示，Pesti-Gen 在生成新分子时实现了约 68% 的结构有效性，为更安全可持续的害虫管理提供创新解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the RECOMB 2025 Poster Track",
      "pdf_url": "http://arxiv.org/pdf/2501.14469v2",
      "published_date": "2025-01-24 13:00:54 UTC",
      "updated_date": "2025-03-14 06:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:58:46.285867"
    },
    {
      "arxiv_id": "2501.14459v1",
      "title": "Interpretability Analysis of Domain Adapted Dense Retrievers",
      "title_zh": "领域适配密集检索器的可解释性分析",
      "authors": [
        "Goksenin Yuksel",
        "Jaap Kamps"
      ],
      "abstract": "Dense retrievers have demonstrated significant potential for neural\ninformation retrieval; however, they exhibit a lack of robustness to domain\nshifts, thereby limiting their efficacy in zero-shot settings across diverse\ndomains. Previous research has investigated unsupervised domain adaptation\ntechniques to adapt dense retrievers to target domains. However, these studies\nhave not focused on explainability analysis to understand how such adaptations\nalter the model's behavior. In this paper, we propose utilizing the integrated\ngradients framework to develop an interpretability method that provides both\ninstance-based and ranking-based explanations for dense retrievers. To generate\nthese explanations, we introduce a novel baseline that reveals both query and\ndocument attributions. This method is used to analyze the effects of domain\nadaptation on input attributions for query and document tokens across two\ndatasets: the financial question answering dataset (FIQA) and the biomedical\ninformation retrieval dataset (TREC-COVID). Our visualizations reveal that\ndomain-adapted models focus more on in-domain terminology compared to\nnon-adapted models, exemplified by terms such as \"hedge,\" \"gold,\" \"corona,\" and\n\"disease.\" This research addresses how unsupervised domain adaptation\ntechniques influence the behavior of dense retrievers when adapted to new\ndomains. Additionally, we demonstrate that integrated gradients are a viable\nchoice for explaining and analyzing the internal mechanisms of these opaque\nneural models.",
      "tldr_zh": "该研究分析了领域适应（domain adaptation）后的密集检索器（dense retrievers）的可解释性问题，提出使用集成梯度（integrated gradients）框架开发一种方法，提供基于实例和排名的解释。\n他们引入了一个新基线来揭示查询和文档归因，并在 FIQA 和 TREC-COVID 数据集上评估领域适应的影响。\n结果显示，领域适应模型更关注领域特定术语，如 \"hedge\"、\"gold\"、\"corona\" 和 \"disease\"，从而提升了模型在跨领域任务中的鲁棒性。\n这项工作证明了集成梯度是解释密集检索器内部机制的有效工具，为未来模型适应和优化提供了洞见。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14459v1",
      "published_date": "2025-01-24 12:42:53 UTC",
      "updated_date": "2025-01-24 12:42:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:58:58.651937"
    },
    {
      "arxiv_id": "2501.18612v3",
      "title": "Deeply Optimizing the SAT Solver for the IC3 Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Su",
        "Qiusong Yang",
        "Yiwei Ci",
        "Yingcheng Li",
        "Tianjun Bu",
        "Ziyu Huang"
      ],
      "abstract": "The IC3 algorithm, also known as PDR, is a SAT-based model checking algorithm\nthat has significantly influenced the field in recent years due to its\nefficiency, scalability, and completeness. It utilizes SAT solvers to solve a\nseries of SAT queries associated with relative induction. In this paper, we\nintroduce several optimizations for the SAT solver in IC3 based on our\nobservations of the unique characteristics of these SAT queries. By observing\nthat SAT queries do not necessarily require decisions on all variables, we\ncompute a subset of variables that need to be decided before each solving\nprocess while ensuring that the result remains unaffected. Additionally, noting\nthat the overhead of binary heap operations in VSIDS is non-negligible, we\nreplace the binary heap with buckets to achieve constant-time operations.\nFurthermore, we support temporary clauses without the need to allocate a new\nactivation variable for each solving process, thereby eliminating the need to\nreset solvers. We developed a novel lightweight CDCL SAT solver, GipSAT, which\nintegrates these optimizations. A comprehensive evaluation highlights the\nperformance improvements achieved by GipSAT. Specifically, the GipSAT-based IC3\ndemonstrates an average speedup of 3.61 times in solving time compared to the\nIC3 implementation based on MiniSat.",
      "tldr_zh": "本文针对 IC3 算法（也称 PDR）中的 SAT 查询，基于其独特特性提出几项优化：计算变量子集以减少决策需求、用桶替换 VSIDS 中的二进制堆实现常数时间操作，以及支持临时子句避免求解器重置。作者开发了新型轻量级 CDCL SAT 求解器 GipSAT，集成了这些优化。实验评估显示，基于 GipSAT 的 IC3 在求解时间上比基于 MiniSat 的 IC3 平均加速 3.61 倍，从而提升了模型检查算法的效率和可扩展性。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18612v3",
      "published_date": "2025-01-24 12:40:43 UTC",
      "updated_date": "2025-05-21 01:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:59:10.707820"
    },
    {
      "arxiv_id": "2501.14443v1",
      "title": "Learning more with the same effort: how randomization improves the robustness of a robotic deep reinforcement learning agent",
      "title_zh": "翻译失败",
      "authors": [
        "Lucía Güitta-López",
        "Jaime Boal",
        "Álvaro J. López-López"
      ],
      "abstract": "The industrial application of Deep Reinforcement Learning (DRL) is frequently\nslowed down because of the inability to generate the experience required to\ntrain the models. Collecting data often involves considerable time and economic\neffort that is unaffordable in most cases. Fortunately, devices like robots can\nbe trained with synthetic experience thanks to virtual environments. With this\napproach, the sample efficiency problems of artificial agents are mitigated,\nbut another issue arises: the need for efficiently transferring the synthetic\nexperience into the real world (sim-to-real).\n  This paper analyzes the robustness of a state-of-the-art sim-to-real\ntechnique known as progressive neural networks (PNNs) and studies how adding\ndiversity to the synthetic experience can complement it. To better understand\nthe drivers that lead to a lack of robustness, the robotic agent is still\ntested in a virtual environment to ensure total control on the divergence\nbetween the simulated and real models.\n  The results show that a PNN-like agent exhibits a substantial decrease in its\nrobustness at the beginning of the real training phase. Randomizing certain\nvariables during simulation-based training significantly mitigates this issue.\nOn average, the increase in the model's accuracy is around 25% when diversity\nis introduced in the training process. This improvement can be translated into\na decrease in the required real experience for the same final robustness\nperformance. Notwithstanding, adding real experience to agents should still be\nbeneficial regardless of the quality of the virtual experience fed into the\nagent.",
      "tldr_zh": "这篇论文探讨了如何通过在模拟训练中引入随机性来提升机器人 Deep Reinforcement Learning (DRL) 代理的鲁棒性，以解决 sim-to-real 转移中的问题。研究分析了 progressive neural networks (PNNs) 的表现，发现代理在真实训练初期鲁棒性显著下降，但通过随机化某些变量，模型准确率平均提高了 25%。这一改进减少了所需真实经验量，同时强调即使虚拟经验质量高，添加真实经验仍能进一步提升性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.RO",
      "comment": "This article was accepted and published in Applied Intelligence\n  (10.1007/s10489-022-04227-3)",
      "pdf_url": "http://arxiv.org/pdf/2501.14443v1",
      "published_date": "2025-01-24 12:23:12 UTC",
      "updated_date": "2025-01-24 12:23:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:01:15.537954"
    },
    {
      "arxiv_id": "2501.14406v2",
      "title": "Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Wu",
        "Jia Hu",
        "Geyong Min",
        "Shiqiang Wang"
      ],
      "abstract": "Pre-trained Language Models (PLMs) have demonstrated their superiority and\nversatility in modern Natural Language Processing (NLP), effectively adapting\nto various downstream tasks through further fine-tuning. Federated\nParameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution\nto address privacy and efficiency challenges in distributed training for PLMs\non resource-constrained local devices. However, our measurements reveal two key\nlimitations of FedPEFT: heterogeneous data across devices leads to significant\nperformance degradation, and a fixed parameter configuration results in\ncommunication inefficiency. To overcome these limitations, we propose FedARA, a\nnovel Adaptive Rank Allocation framework for federated parameter-efficient\nfine-tuning of language models. Specifically, FedARA employs truncated Singular\nValue Decomposition (SVD) adaptation to enhance similar feature representation\nacross clients, significantly mitigating the adverse effects of data\nheterogeneity. Subsequently, it utilizes dynamic rank allocation to\nprogressively identify critical ranks, effectively improving communication\nefficiency. Lastly, it leverages rank-based module pruning to automatically\nremove inactive modules, steadily reducing local computational cost and memory\nusage in each federated learning round. Extensive experiments show that FedARA\nconsistently outperforms baselines by an average of 6.95% to 8.49% across\nvarious datasets and models under heterogeneous data while significantly\nimproving communication efficiency by 2.40$ \\times$. Moreover, experiments on\nvarious edge devices demonstrate substantial decreases in total training time\nand energy consumption by up to 48.90% and 46.95%, respectively.",
      "tldr_zh": "这篇论文提出了 FedARA，一种自适应 rank 分配框架，用于解决 Federated Parameter-Efficient Fine-Tuning (FedPEFT) 在预训练语言模型 (PLMs) 的联邦学习中面临的设备数据异质性和通信效率问题。FedARA 通过 truncated Singular Value Decomposition (SVD) 适应增强客户端特征表示的相似性、动态 rank 分配识别关键参数以优化通信效率，以及 rank-based module pruning 自动移除不活跃模块来降低本地计算成本和内存使用。实验结果显示，FedARA 在异质数据条件下比基线模型平均提高 6.95% 到 8.49% 的性能，同时通信效率提升 2.40 倍，并在边缘设备上将训练时间和能量消耗分别减少高达 48.90% 和 46.95%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14406v2",
      "published_date": "2025-01-24 11:19:07 UTC",
      "updated_date": "2025-03-01 17:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:01:27.866744"
    },
    {
      "arxiv_id": "2501.14400v1",
      "title": "SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shengjie Wang",
        "Jiacheng You",
        "Yihang Hu",
        "Jiongye Li",
        "Yang Gao"
      ],
      "abstract": "Real-world tasks such as garment manipulation and table rearrangement demand\nrobots to perform generalizable, highly precise, and long-horizon actions.\nAlthough imitation learning has proven to be an effective approach for teaching\nrobots new skills, large amounts of expert demonstration data are still\nindispensible for these complex tasks, resulting in high sample complexity and\ncostly data collection. To address this, we propose Semantic Keypoint Imitation\nLearning (SKIL), a framework which automatically obtain semantic keypoints with\nhelp of vision foundation models, and forms the descriptor of semantic\nkeypoints that enables effecient imitation learning of complex robotic tasks\nwith significantly lower sample complexity. In real world experiments, SKIL\ndoubles the performance of baseline methods in tasks such as picking a cup or\nmouse, while demonstrating exceptional robustness to variations in objects,\nenvironmental changes, and distractors. For long-horizon tasks like hanging a\ntowel on a rack where previous methods fail completely, SKIL achieves a mean\nsuccess rate of 70\\% with as few as 30 demonstrations. Furthermore, SKIL\nnaturally supports cross-embodiment learning due to its semantic keypoints\nabstraction, our experiments demonstrate that even human videos bring\nconsiderable improvement to the learning performance. All these results\ndemonstrate the great success of SKIL in achieving data-efficint generalizable\nrobotic learning. Visualizations and code are available at:\nhttps://skil-robotics.github.io/SKIL-robotics/.",
      "tldr_zh": "该论文提出 SKIL（Semantic Keypoint Imitation Learning），一种数据高效的模仿学习框架，旨在解决机器人执行可泛化、高精度和长期任务时所需的庞大数据问题。SKIL 通过视觉基础模型自动获取语义关键点并形成描述符，从而实现复杂机器人任务的低样本复杂性学习。在真实实验中，SKIL 在任务如拿起杯子或鼠标上使基线方法性能翻倍，并对物体变化、环境干扰表现出强鲁棒性；对于长期任务如挂毛巾，它仅需30个演示即可达到70%的成功率。此外，SKIL 支持跨实体学习（cross-embodiment learning），甚至利用人类视频显著提升学习性能，展示了其在数据高效可泛化机器人学习中的巨大潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "22 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14400v1",
      "published_date": "2025-01-24 11:11:53 UTC",
      "updated_date": "2025-01-24 11:11:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:01:41.345801"
    },
    {
      "arxiv_id": "2501.14399v1",
      "title": "Handling Heterophily in Recommender Systems with Wavelet Hypergraph Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Darnbi Sakong",
        "Thanh Tam Nguyen"
      ],
      "abstract": "Recommender systems are pivotal in delivering personalised user experiences\nacross various domains. However, capturing the heterophily patterns and the\nmulti-dimensional nature of user-item interactions poses significant\nchallenges. To address this, we introduce FWHDNN (Fusion-based Wavelet\nHypergraph Diffusion Neural Networks), an innovative framework aimed at\nadvancing representation learning in hypergraph-based recommendation tasks. The\nmodel incorporates three key components: (1) a cross-difference relation\nencoder leveraging heterophily-aware hypergraph diffusion to adapt\nmessage-passing for diverse class labels, (2) a multi-level cluster-wise\nencoder employing wavelet transform-based hypergraph neural network layers to\ncapture multi-scale topological relationships, and (3) an integrated\nmulti-modal fusion mechanism that combines structural and textual information\nthrough intermediate and late-fusion strategies. Extensive experiments on\nreal-world datasets demonstrate that FWHDNN surpasses state-of-the-art methods\nin accuracy, robustness, and scalability in capturing high-order\ninterconnections between users and items.",
      "tldr_zh": "该论文针对推荐系统中异质性（heterophily）模式和多维用户-物品交互的挑战，提出了一种创新框架FWHDNN（Fusion-based Wavelet Hypergraph Diffusion Neural Networks），用于提升超图-based 推荐任务中的表示学习。该框架的核心组件包括：异质性感知的超图扩散编码器以适应消息传递、多级基于小波变换（wavelet transform）的超图神经网络层以捕捉多尺度拓扑关系，以及多模态融合机制来整合结构和文本信息。实验在真实数据集上证明，FWHDNN在准确性、鲁棒性和可扩展性上超过了现有方法，尤其在捕捉高阶用户-物品互连方面。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14399v1",
      "published_date": "2025-01-24 11:08:29 UTC",
      "updated_date": "2025-01-24 11:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:01:51.710813"
    },
    {
      "arxiv_id": "2501.14846v5",
      "title": "Wormhole Memory: A Rubik's Cube for Cross-Dialogue Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Libo Wang"
      ],
      "abstract": "In view of the gap in the current large language model in sharing memory\nacross dialogues, this research proposes a wormhole memory module (WMM) to\nrealize memory as a Rubik's cube that can be arbitrarily retrieved between\ndifferent dialogues. Through simulation experiments, the researcher built an\nexperimental framework based on the Python environment and used setting memory\nbarriers to simulate the current situation where memories between LLMs\ndialogues are difficult to share. The CoQA development data set was imported\ninto the experiment, and the feasibility of its cross-dialogue memory retrieval\nfunction was verified for WMM's nonlinear indexing and dynamic retrieval, and a\ncomparative analysis was conducted with the capabilities of Titans and MemGPT\nmemory modules. Experimental results show that WMM demonstrated the ability to\nretrieve memory across dialogues and the stability of quantitative indicators\nin eight experiments. It contributes new technical approaches to the\noptimization of memory management of LLMs and provides experience for the\npractical application in the future.",
      "tldr_zh": "本研究针对大语言模型(LLMs)跨对话共享记忆的不足，提出Wormhole Memory Module (WMM)，将其比作魔方，支持非线性索引和动态检索，以实现不同对话间的任意记忆访问。实验框架基于Python环境，通过设置记忆障碍模拟当前LLMs限制，并使用CoQA数据集验证WMM的功能，同时与Titans和MemGPT模块进行比较。结果表明，WMM在八个实验中展示了稳定的跨对话检索能力和定量指标优势，为LLMs记忆管理优化提供新技术和实际应用经验。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "The experimental process and code have been uploaded to the Github\n  repository, the link is:\n  https://github.com/brucewang123456789/GeniusTrail/tree/main/Wormhole%20Memory%20Module",
      "pdf_url": "http://arxiv.org/pdf/2501.14846v5",
      "published_date": "2025-01-24 10:49:45 UTC",
      "updated_date": "2025-04-12 16:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:02:02.808770"
    },
    {
      "arxiv_id": "2501.16379v1",
      "title": "FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarui Song",
        "Yunheng Shen",
        "Chengbin Hou",
        "Pengyu Wang",
        "Jinbao Wang",
        "Ke Tang",
        "Hairong Lv"
      ],
      "abstract": "Personalized Federated Learning (PFL) aims to address the statistical\nheterogeneity of data across clients by learning the personalized model for\neach client. Among various PFL approaches, the personalized aggregation-based\napproach conducts parameter aggregation in the server-side aggregation phase to\ngenerate personalized models, and focuses on learning appropriate collaborative\nrelationships among clients for aggregation. However, the collaborative\nrelationships vary in different scenarios and even at different stages of the\nFL process. To this end, we propose Personalized Federated Learning with\nAttentive Graph HyperNetworks (FedAGHN), which employs Attentive Graph\nHyperNetworks (AGHNs) to dynamically capture fine-grained collaborative\nrelationships and generate client-specific personalized initial models.\nSpecifically, AGHNs empower graphs to explicitly model the client-specific\ncollaborative relationships, construct collaboration graphs, and introduce\ntunable attentive mechanism to derive the collaboration weights, so that the\npersonalized initial models can be obtained by aggregating parameters over the\ncollaboration graphs. Extensive experiments can demonstrate the superiority of\nFedAGHN. Moreover, a series of visualizations are presented to explore the\neffectiveness of collaboration graphs learned by FedAGHN.",
      "tldr_zh": "个性化联邦学习 (PFL) 旨在处理客户端数据统计异质性，通过为每个客户端学习个性化模型，但现有方法难以适应动态变化的协作关系。论文提出 FedAGHN，使用 Attentive Graph HyperNetworks (AGHNs) 动态捕获细粒度的客户端协作关系，构建协作图并引入注意力机制来聚合参数，从而生成客户端特定的个性化初始模型。实验结果表明 FedAGHN 在性能上优于基线方法，并通过可视化探索了协作图的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16379v1",
      "published_date": "2025-01-24 10:48:30 UTC",
      "updated_date": "2025-01-24 10:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:02:15.529907"
    },
    {
      "arxiv_id": "2501.14379v1",
      "title": "ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer",
      "title_zh": "翻译失败",
      "authors": [
        "Yoni Schirris",
        "Rosie Voorthuis",
        "Mark Opdam",
        "Marte Liefaard",
        "Gabe S Sonke",
        "Gwen Dackus",
        "Vincent de Jong",
        "Yuwei Wang",
        "Annelot Van Rossum",
        "Tessa G Steenbruggen",
        "Lars C Steggink",
        "Liesbeth G. E. de Vries",
        "Marc van de Vijver",
        "Roberto Salgado",
        "Efstratios Gavves",
        "Paul J van Diest",
        "Sabine C Linn",
        "Jonas Teuwen",
        "Renee Menezes",
        "Marleen Kok",
        "Hugo Horlings"
      ],
      "abstract": "The level of tumour-infiltrating lymphocytes (TILs) is a prognostic factor\nfor patients with (triple-negative) breast cancer (BC). Computational TIL\nassessment (CTA) has the potential to assist pathologists in this\nlabour-intensive task, but current CTA models rely heavily on many detailed\nannotations. We propose and validate a fundamentally simpler deep learning\nbased CTA that can be trained in only ten minutes on hundredfold fewer\npathologist annotations. We collected whole slide images (WSIs) with TILs\nscores and clinical data of 2,340 patients with BC from six cohorts including\nthree randomised clinical trials. Morphological features were extracted from\nwhole slide images (WSIs) using a pathology foundation model. Our\nlabel-efficient Computational stromal TIL assessment model (ECTIL) directly\nregresses the TILs score from these features. ECTIL trained on only a few\nhundred samples (ECTIL-TCGA) showed concordance with the pathologist over five\nheterogeneous external cohorts (r=0.54-0.74, AUROC=0.80-0.94). Training on all\nslides of five cohorts (ECTIL-combined) improved results on a held-out test set\n(r=0.69, AUROC=0.85). Multivariable Cox regression analyses indicated that\nevery 10% increase of ECTIL scores was associated with improved overall\nsurvival independent of clinicopathological variables (HR 0.86, p<0.01),\nsimilar to the pathologist score (HR 0.87, p<0.001). We demonstrate that ECTIL\nis highly concordant with an expert pathologist and obtains a similar hazard\nratio. ECTIL has a fundamentally simpler design than existing methods and can\nbe trained on orders of magnitude fewer annotations. Such a CTA may be used to\npre-screen patients for, e.g., immunotherapy clinical trial inclusion, or as a\ntool to assist clinicians in the diagnostic work-up of patients with BC. Our\nmodel is available under an open source licence\n(https://github.com/nki-ai/ectil).",
      "tldr_zh": "本研究提出ECTIL，一种标签高效的计算TIL（Tumour Infiltrating Lymphocyte）评估模型，用于乳腺癌患者预后分析，仅需百倍减少的标注（数百样本）和10分钟训练时间。ECTIL利用病理基础模型从全滑玻图像（WSIs）提取形态特征，直接回归TIL分数，并在六个队列的2340名患者数据上进行多中心验证，结果显示模型与专家病理学家高度一致（r=0.54-0.74, AUROC=0.80-0.94）。多变量Cox回归分析表明，每增加10%的ECTIL分数，与整体生存率改善显著相关（HR 0.86, p<0.01），类似于专家评分。ECTIL的设计更简单、开源可用（https://github.com/nki-ai/ectil），可作为辅助工具预筛患者或支持临床诊断。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Under review. 54 pages including supplementary materials, 2 main\n  tables, 3 main figures, 14 supplementary figures, 4 supplementary tables",
      "pdf_url": "http://arxiv.org/pdf/2501.14379v1",
      "published_date": "2025-01-24 10:28:05 UTC",
      "updated_date": "2025-01-24 10:28:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:02:29.697666"
    },
    {
      "arxiv_id": "2501.14371v1",
      "title": "DRESSing Up LLM: Efficient Stylized Question-Answering via Style Subspace Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Ma",
        "Yifeng Xu",
        "Yang Lin",
        "Tianlong Wang",
        "Xu Chu",
        "Xin Gao",
        "Junfeng Zhao",
        "Yasha Wang"
      ],
      "abstract": "We introduce DRESS, a novel approach for generating stylized large language\nmodel (LLM) responses through representation editing. Existing methods like\nprompting and fine-tuning are either insufficient for complex style adaptation\nor computationally expensive, particularly in tasks like NPC creation or\ncharacter role-playing. Our approach leverages the over-parameterized nature of\nLLMs to disentangle a style-relevant subspace within the model's representation\nspace to conduct representation editing, ensuring a minimal impact on the\noriginal semantics. By applying adaptive editing strengths, we dynamically\nadjust the steering vectors in the style subspace to maintain both stylistic\nfidelity and semantic integrity. We develop two stylized QA benchmark datasets\nto validate the effectiveness of DRESS, and the results demonstrate significant\nimprovements compared to baseline methods such as prompting and ITI. In short,\nDRESS is a lightweight, train-free solution for enhancing LLMs with flexible\nand effective style control, making it particularly useful for developing\nstylized conversational agents. Codes and benchmark datasets are available at\nhttps://github.com/ArthurLeoM/DRESS-LLM.",
      "tldr_zh": "我们提出DRESS，一种通过表示编辑(representation editing)来生成风格化LLM响应的创新方法，能够高效适应复杂风格，同时避免对原始语义的重大影响。DRESS利用LLM的过参数化特性，分离出风格相关的子空间，并应用自适应编辑强度动态调整转向向量，以平衡风格忠实性和语义完整性。该方法在两个新开发的风格化QA基准数据集上，比基线方法如提示和ITI显著提升性能，提供了一个轻量级、无需训练的解决方案，适用于开发风格化对话代理。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2501.14371v1",
      "published_date": "2025-01-24 10:04:53 UTC",
      "updated_date": "2025-01-24 10:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:02:38.716590"
    },
    {
      "arxiv_id": "2501.14360v1",
      "title": "In System Alignments we Trust! Explainable Alignments via Projections",
      "title_zh": "我们信任",
      "authors": [
        "Dominique Sommers",
        "Natalia Sidorova",
        "Boudewijn van Dongen"
      ],
      "abstract": "Alignments are a well-known process mining technique for reconciling system\nlogs and normative process models. Evidence of certain behaviors in a real\nsystem may only be present in one representation - either a log or a model -\nbut not in the other. Since for processes in which multiple entities, like\nobjects and resources, are involved in the activities, their interactions\naffect the behavior and are therefore essential to take into account in the\nalignments.\n  Additionally, both logged and modeled representations of reality may be\nimprecise and only partially represent some of these entities, but not all. In\nthis paper, we introduce the concept of \"relaxations\" through projections for\nalignments to deal with partially correct models and logs. Relaxed alignments\nhelp to distinguish between trustworthy and untrustworthy content of the two\nrepresentations (the log and the model) to achieve a better understanding of\nthe underlying process and expose quality issues.",
      "tldr_zh": "该论文探讨了Alignments作为一种过程挖掘技术，用于协调系统日志和规范过程模型，尤其在涉及多个实体（如对象和资源）的复杂过程中。论文引入了“relaxations”通过projections的概念，处理日志和模型可能不精确或仅部分代表实体的问题，从而创建relaxed alignments。这样的方法有助于区分日志和模型中可信与不可信的内容，提升对底层过程的理解，并暴露潜在的质量问题。",
      "categories": [
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14360v1",
      "published_date": "2025-01-24 09:47:17 UTC",
      "updated_date": "2025-01-24 09:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:02:49.472766"
    },
    {
      "arxiv_id": "2501.14346v2",
      "title": "HorNets: Learning from Discrete and Continuous Signals with Routing Neural Networks",
      "title_zh": "HorNets：通过路由神经网络从离散和连续信号中学习",
      "authors": [
        "Boshko Koloski",
        "Nada Lavrač",
        "Blaž Škrlj"
      ],
      "abstract": "Construction of neural network architectures suitable for learning from both\ncontinuous and discrete tabular data is a challenging research endeavor.\nContemporary high-dimensional tabular data sets are often characterized by a\nrelatively small instance count, requiring data-efficient learning. We propose\nHorNets (Horn Networks), a neural network architecture with state-of-the-art\nperformance on synthetic and real-life data sets from scarce-data tabular\ndomains. HorNets are based on a clipped polynomial-like activation function,\nextended by a custom discrete-continuous routing mechanism that decides which\npart of the neural network to optimize based on the input's cardinality. By\nexplicitly modeling parts of the feature combination space or combining whole\nspace in a linear attention-like manner, HorNets dynamically decide which mode\nof operation is the most suitable for a given piece of data with no explicit\nsupervision. This architecture is one of the few approaches that reliably\nretrieves logical clauses (including noisy XNOR) and achieves state-of-the-art\nclassification performance on 14 real-life biomedical high-dimensional data\nsets. HorNets are made freely available under a permissive license alongside a\nsynthetic generator of categorical benchmarks.",
      "tldr_zh": "该研究提出HorNets，一种先进的神经网络架构，旨在高效学习高维连续和离散表格数据，尤其适用于样本量小的场景。HorNets采用剪切的多项式似激活函数，并引入自定义的离散-连续routing机制，根据输入的cardinality动态决定优化网络的哪一部分，从而在特征组合空间中显式建模或以线性attention-like方式结合。实验结果显示，HorNets在合成和14个真实生物医学数据集上实现最先进分类性能，能够可靠检索逻辑子句（包括噪声XNOR），并提供开源实现和合成基准生成器。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the ACML conference journal track with the Machine\n  Learning journal. The first and the last authors share an equal contribution",
      "pdf_url": "http://arxiv.org/pdf/2501.14346v2",
      "published_date": "2025-01-24 09:17:57 UTC",
      "updated_date": "2025-02-13 17:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:03:02.679997"
    },
    {
      "arxiv_id": "2501.14844v2",
      "title": "Unmasking Conversational Bias in AI Multiagent Systems",
      "title_zh": "揭露 AI 多智能体系统中的对话偏见",
      "authors": [
        "Erica Coppolillo",
        "Giuseppe Manco",
        "Luca Maria Aiello"
      ],
      "abstract": "Detecting biases in the outputs produced by generative models is essential to\nreduce the potential risks associated with their application in critical\nsettings. However, the majority of existing methodologies for identifying\nbiases in generated text consider the models in isolation and neglect their\ncontextual applications. Specifically, the biases that may arise in multi-agent\nsystems involving generative models remain under-researched. To address this\ngap, we present a framework designed to quantify biases within multi-agent\nsystems of conversational Large Language Models (LLMs). Our approach involves\nsimulating small echo chambers, where pairs of LLMs, initialized with aligned\nperspectives on a polarizing topic, engage in discussions. Contrary to\nexpectations, we observe significant shifts in the stance expressed in the\ngenerated messages, particularly within echo chambers where all agents\ninitially express conservative viewpoints, in line with the well-documented\npolitical bias of many LLMs toward liberal positions. Crucially, the bias\nobserved in the echo-chamber experiment remains undetected by current\nstate-of-the-art bias detection methods that rely on questionnaires. This\nhighlights a critical need for the development of a more sophisticated toolkit\nfor bias detection and mitigation for AI multi-agent systems. The code to\nperform the experiments is publicly available at\nhttps://anonymous.4open.science/r/LLMsConversationalBias-7725.",
      "tldr_zh": "该研究提出一个框架，用于量化对话式 Large Language Models (LLMs) 在多智能体系统中的偏见问题，填补了现有方法忽略上下文应用的空白。方法涉及模拟小型 echo chambers，让成对的 LLMs 在有争议话题上讨论，这些模型初始时持有相同的观点。实验发现，生成的对话中观点会显著偏移，特别是当所有代理初始为保守立场时，会向自由主义倾斜，但这种偏见无法被当前先进的问卷式检测方法识别，强调了开发更复杂的多智能体偏见检测和缓解工具的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14844v2",
      "published_date": "2025-01-24 09:10:02 UTC",
      "updated_date": "2025-02-02 14:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:03:14.451125"
    },
    {
      "arxiv_id": "2501.14334v2",
      "title": "Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts",
      "title_zh": "翻译失败",
      "authors": [
        "Clément Desroches",
        "Martin Chauvin",
        "Louis Ladan",
        "Caroline Vateau",
        "Simon Gosset",
        "Philippe Cordier"
      ],
      "abstract": "The rapid growth of artificial intelligence (AI), particularly Large Language\nModels (LLMs), has raised concerns regarding its global environmental impact\nthat extends beyond greenhouse gas emissions to include consideration of\nhardware fabrication and end-of-life processes. The opacity from major\nproviders hinders companies' abilities to evaluate their AI-related\nenvironmental impacts and achieve net-zero targets.\n  In this paper, we propose a methodology to estimate the environmental impact\nof a company's AI portfolio, providing actionable insights without\nnecessitating extensive AI and Life-Cycle Assessment (LCA) expertise. Results\nconfirm that large generative AI models consume up to 4600x more energy than\ntraditional models. Our modelling approach, which accounts for increased AI\nusage, hardware computing efficiency, and changes in electricity mix in line\nwith IPCC scenarios, forecasts AI electricity use up to 2030. Under a high\nadoption scenario, driven by widespread Generative AI and agents adoption\nassociated to increasingly complex models and frameworks, AI electricity use is\nprojected to rise by a factor of 24.4.\n  Mitigating the environmental impact of Generative AI by 2030 requires\ncoordinated efforts across the AI value chain. Isolated measures in hardware\nefficiency, model efficiency, or grid improvements alone are insufficient. We\nadvocate for standardized environmental assessment frameworks, greater\ntransparency from the all actors of the value chain and the introduction of a\n\"Return on Environment\" metric to align AI development with net-zero goals.",
      "tldr_zh": "该研究探讨了人工智能（AI）可持续扩展的困境，通过一个前瞻性研究评估企业AI环境影响。论文提出了一种方法来估计公司AI组合的环境足迹，无需深厚的AI和生命周期评估（LCA）专业知识，结果显示大型生成AI模型的能源消耗比传统模型高出4600倍。模型预测显示，到2030年，在高采用场景下，AI电力使用可能增加24.4倍，考虑因素包括AI使用增长、硬件效率和电力混合变化。作者强调，需要AI价值链的协调努力，包括标准化环境评估框架、提升透明度和引入“Return on Environment”指标，以实现净零目标。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14334v2",
      "published_date": "2025-01-24 08:58:49 UTC",
      "updated_date": "2025-01-27 14:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:03:26.553718"
    },
    {
      "arxiv_id": "2501.14322v1",
      "title": "Relative Layer-Wise Relevance Propagation: a more Robust Neural Networks eXplaination",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Nyiri",
        "Olivier Gibaru"
      ],
      "abstract": "Machine learning methods are solving very successfully a plethora of tasks,\nbut they have the disadvantage of not providing any information about their\ndecision. Consequently, estimating the reasoning of the system provides\nadditional information. For this, Layer-Wise Relevance Propagation (LRP) is one\nof the methods in eXplainable Machine Learning (XML). Its purpose is to provide\ncontributions of any neural network output in the domain of its input. The main\ndrawback of current methods is mainly due to division by small values. To\novercome this problem, we provide a new definition called Relative LRP where\nthe classical conservation law is satisfied up to a multiplicative factor but\nwithout divisions by small values except for Resnet skip connection. In this\narticle, we will focus on image classification. This allows us to visualize the\ncontributions of a pixel to the predictions of a multi-layer neural network.\nPixel contributions provide a focus to further analysis on regions of potential\ninterest. R-LRP can be applied for any dense, CNN or residual neural networks.\nMoreover, R-LRP doesn't need any hyperparameters to tune contrary to other LRP\nmethods. We then compare the R-LRP method on different datasets with simple\nCNN, VGG16, VGG19 and Resnet50 networks.",
      "tldr_zh": "这篇论文提出了Relative LRP（R-LRP），一种改进的Layer-Wise Relevance Propagation方法，旨在提升神经网络解释的鲁棒性，解决传统LRP方法中除以小值导致的问题。R-LRP通过满足乘法因子下的守恒定律，避免了除以小值的缺陷（除了Resnet的跳跃连接），并适用于图像分类任务，可视化像素对预测的贡献。相比传统方法，R-LRP不需要任何超参数调优，并可应用于密集、CNN或残差神经网络，如简单CNN、VGG16、VGG19和Resnet50。实验结果显示，R-LRP在不同数据集上提供了更可靠的解释性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2012.14501,\n  arXiv:1605.01713 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2501.14322v1",
      "published_date": "2025-01-24 08:34:22 UTC",
      "updated_date": "2025-01-24 08:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:03:39.582452"
    },
    {
      "arxiv_id": "2501.17176v3",
      "title": "Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Ballestero-Ribó",
        "Daniel Ortiz-Martínez"
      ],
      "abstract": "The dream of achieving a student-teacher ratio of 1:1 is closer than ever\nthanks to the emergence of large language models (LLMs). One potential\napplication of these models in the educational field would be to provide\nfeedback to students in university introductory programming courses, so that a\nstudent struggling to solve a basic implementation problem could seek help from\nan LLM available 24/7. This article focuses on studying three aspects related\nto such an application. First, the performance of two well-known models,\nGPT-3.5T and GPT-4T, in providing feedback to students is evaluated. The\nempirical results showed that GPT-4T performs much better than GPT-3.5T,\nhowever, it is not yet ready for use in a real-world scenario. This is due to\nthe possibility of generating incorrect information that potential users may\nnot always be able to detect. Second, the article proposes a carefully designed\nprompt using in-context learning techniques that allows automating important\nparts of the evaluation process, as well as providing a lower bound for the\nfraction of feedbacks containing incorrect information, saving time and effort.\nThis was possible because the resulting feedback has a programmatically\nanalyzable structure that incorporates diagnostic information about the LLM's\nperformance in solving the requested task. Third, the article also suggests a\npossible strategy for implementing a practical learning tool based on LLMs,\nwhich is rooted on the proposed prompting techniques. This strategy opens up a\nwhole range of interesting possibilities from a pedagogical perspective.",
      "tldr_zh": "该研究探讨了使用大型语言模型（LLMs）如 GPT-3.5T 和 GPT-4T 作为编程课程教学助手的潜力，以实现 1:1 师生比。评估结果显示，GPT-4T 在提供学生反馈方面远优于 GPT-3.5T，但仍可能生成错误信息，不适合实际应用。论文提出了一种基于提示（prompt）的设计，利用 in-context learning 技术自动化评估过程，并估算反馈中错误信息的下限，从而节省时间并提供 LLM 性能诊断。最终，该策略为基于 LLMs 的教育工具实施提供了实用路径，从教学角度扩展了新可能性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17176v3",
      "published_date": "2025-01-24 08:15:05 UTC",
      "updated_date": "2025-05-04 13:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:03:51.072360"
    },
    {
      "arxiv_id": "2501.14310v1",
      "title": "Permutation-based multi-objective evolutionary feature selection for high-dimensional data",
      "title_zh": "翻译失败",
      "authors": [
        "Raquel Espinosa",
        "Gracia Sánchez",
        "José Palma",
        "Fernando Jiménez"
      ],
      "abstract": "Feature selection is a critical step in the analysis of high-dimensional\ndata, where the number of features often vastly exceeds the number of samples.\nEffective feature selection not only improves model performance and\ninterpretability but also reduces computational costs and mitigates the risk of\noverfitting. In this context, we propose a novel feature selection method for\nhigh-dimensional data, based on the well-known permutation feature importance\napproach, but extending it to evaluate subsets of attributes rather than\nindividual features. This extension more effectively captures how interactions\namong features influence model performance. The proposed method employs a\nmulti-objective evolutionary algorithm to search for candidate feature subsets,\nwith the objectives of maximizing the degradation in model performance when the\nselected features are shuffled, and minimizing the cardinality of the feature\nsubset. The effectiveness of our method has been validated on a set of 24\npublicly available high-dimensional datasets for classification and regression\ntasks, and compared against 9 well-established feature selection methods\ndesigned for high-dimensional problems, including the conventional permutation\nfeature importance method. The results demonstrate the ability of our approach\nin balancing accuracy and computational efficiency, providing a powerful tool\nfor feature selection in complex, high-dimensional datasets.",
      "tldr_zh": "本研究针对高维数据特征选择问题，提出了一种基于permutation feature importance的新方法，该方法扩展到评估特征子集而非单个特征，以更好地捕捉特征间的交互影响。\n该方法利用multi-objective evolutionary algorithm进行优化搜索，目标是最大化特征子集置换对模型性能的负面影响，同时最小化子集的cardinality，从而实现性能提升和计算效率的平衡。\n实验在24个公开的高维数据集上验证，与9种现有方法比较，结果表明该方法在分类和回归任务中表现出色，提供了一个高效的特征选择工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14310v1",
      "published_date": "2025-01-24 08:11:28 UTC",
      "updated_date": "2025-01-24 08:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:04:02.819832"
    },
    {
      "arxiv_id": "2501.14308v1",
      "title": "Learning Primitive Relations for Compositional Zero-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Insu Lee",
        "Jiseob Kim",
        "Kyuhong Shim",
        "Byonghyo Shim"
      ],
      "abstract": "Compositional Zero-Shot Learning (CZSL) aims to identify unseen state-object\ncompositions by leveraging knowledge learned from seen compositions. Existing\napproaches often independently predict states and objects, overlooking their\nrelationships. In this paper, we propose a novel framework, learning primitive\nrelations (LPR), designed to probabilistically capture the relationships\nbetween states and objects. By employing the cross-attention mechanism, LPR\nconsiders the dependencies between states and objects, enabling the model to\ninfer the likelihood of unseen compositions. Experimental results demonstrate\nthat LPR outperforms state-of-the-art methods on all three CZSL benchmark\ndatasets in both closed-world and open-world settings. Through qualitative\nanalysis, we show that LPR leverages state-object relationships for unseen\ncomposition prediction.",
      "tldr_zh": "这篇论文针对 Compositional Zero-Shot Learning (CZSL) 提出了一种新框架 Learning Primitive Relations (LPR)，旨在通过概率方式捕捉状态和对象之间的关系，以识别未见组合。LPR 利用 cross-attention mechanism 来考虑状态和对象的依赖性，从而提升模型对未见组合的推断能力。实验结果显示，LPR 在三个 CZSL 基准数据集上，在封闭世界和开放世界设置中均超过了最先进方法，并通过定性分析验证了其对状态-对象关系的有效利用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14308v1",
      "published_date": "2025-01-24 08:10:05 UTC",
      "updated_date": "2025-01-24 08:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:04:15.217119"
    },
    {
      "arxiv_id": "2501.14305v1",
      "title": "A Zero-Shot LLM Framework for Automatic Assignment Grading in Higher Education",
      "title_zh": "翻译失败",
      "authors": [
        "Calvin Yeung",
        "Jeff Yu",
        "King Chau Cheung",
        "Tat Wing Wong",
        "Chun Man Chan",
        "Kin Chi Wong",
        "Keisuke Fujii"
      ],
      "abstract": "Automated grading has become an essential tool in education technology due to\nits ability to efficiently assess large volumes of student work, provide\nconsistent and unbiased evaluations, and deliver immediate feedback to enhance\nlearning. However, current systems face significant limitations, including the\nneed for large datasets in few-shot learning methods, a lack of personalized\nand actionable feedback, and an overemphasis on benchmark performance rather\nthan student experience. To address these challenges, we propose a Zero-Shot\nLarge Language Model (LLM)-Based Automated Assignment Grading (AAG) system.\nThis framework leverages prompt engineering to evaluate both computational and\nexplanatory student responses without requiring additional training or\nfine-tuning. The AAG system delivers tailored feedback that highlights\nindividual strengths and areas for improvement, thereby enhancing student\nlearning outcomes. Our study demonstrates the system's effectiveness through\ncomprehensive evaluations, including survey responses from higher education\nstudents that indicate significant improvements in motivation, understanding,\nand preparedness compared to traditional grading methods. The results validate\nthe AAG system's potential to transform educational assessment by prioritizing\nlearning experiences and providing scalable, high-quality feedback.",
      "tldr_zh": "这篇论文提出了一种基于 Zero-Shot Large Language Model (LLM) 的自动作业评分框架 (AAG)，旨在解决现有系统在数据需求、个性化反馈不足和过度关注基准性能等问题上存在的局限性。该框架利用 Prompt Engineering 技术评估学生的计算和解释性响应，无需额外训练或微调，就能提供针对性的反馈，突出个人优势和改进领域。实验评估包括学生调查，结果显示 AAG 系统相较传统方法显著提升了学生的动机、理解和准备度，展示了其在高等教育中实现可扩展、高质量评估的潜力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14305v1",
      "published_date": "2025-01-24 08:01:41 UTC",
      "updated_date": "2025-01-24 08:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:04:26.912830"
    },
    {
      "arxiv_id": "2501.14304v2",
      "title": "MASTER: A Multi-Agent System with LLM Specialized MCTS",
      "title_zh": "MASTER：一种基于",
      "authors": [
        "Bingzheng Gan",
        "Yufan Zhao",
        "Tianyi Zhang",
        "Jing Huang",
        "Yusu Li",
        "Shu Xian Teo",
        "Changwang Zhang",
        "Wei Shi"
      ],
      "abstract": "Large Language Models (LLM) are increasingly being explored for\nproblem-solving tasks. However, their strategic planning capability is often\nviewed with skepticism. Recent studies have incorporated the Monte Carlo Tree\nSearch (MCTS) algorithm to augment the planning capacity of LLM. Despite its\npotential, MCTS relies on extensive sampling simulations to approximate the\ntrue reward distribution, which leads to two primary issues. Firstly, MCTS is\neffective for tasks like the Game of Go, where simulation results can yield\nobjective rewards (e.g., 1 for a win and 0 for a loss). However, for tasks such\nas question answering, the result of a simulation is the answer to the\nquestion, which cannot yield an objective reward without the ground truth.\nSecondly, obtaining statistically significant reward estimations typically\nrequires a sample size exceeding 30 simulations, resulting in excessive token\nusage and time consumption. To address these challenges, we present the\nMulti-Agent System with Tactical Execution and Reasoning using LLM Specialized\nMCTS (MASTER), a novel framework that coordinates agent recruitment and\ncommunication through LLM specialized MCTS. This system autonomously adjusts\nthe number of agents based on task complexity and ensures focused communication\namong them. Comprehensive experiments across various tasks demonstrate the\neffectiveness of our proposed framework. It achieves 76% accuracy on HotpotQA\nand 80% on WebShop, setting new state-of-the-art performance on these datasets.",
      "tldr_zh": "该研究针对 Large Language Models (LLM) 在问题解决中的战略规划不足，特别是 Monte Carlo Tree Search (MCTS) 的采样模拟过多导致的效率问题，提出了一种新型多智能体系统 MASTER。MASTER 通过 LLM Specialized MCTS 来协调代理招募和通信，自主调整代理数量以适应任务复杂度，并确保代理间聚焦交互。实验结果显示，该框架在 HotpotQA 上实现 76% 准确率，在 WebShop 上达到 80%，在多个任务上取得了新的状态-of-the-art 性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by main NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14304v2",
      "published_date": "2025-01-24 08:01:11 UTC",
      "updated_date": "2025-02-04 06:26:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:04:38.291932"
    },
    {
      "arxiv_id": "2501.14300v1",
      "title": "Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph",
      "title_zh": "Fast Think",
      "authors": [
        "Xujian Liang",
        "Zhaoquan Gu"
      ],
      "abstract": "Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes\nthe naive RAG system a step further by integrating graph information, such as\nknowledge graph (KGs), into large-scale language models (LLMs) to mitigate\nhallucination. However, existing GRAG still encounter limitations: 1) simple\nparadigms usually fail with the complex problems due to the narrow and shallow\ncorrelations capture from KGs 2) methods of strong coupling with KGs tend to be\nhigh computation cost and time consuming if the graph is dense. In this paper,\nwe propose the Fast Think-on-Graph (FastToG), an innovative paradigm for\nenabling LLMs to think ``community by community\" within KGs. To do this,\nFastToG employs community detection for deeper correlation capture and two\nstages community pruning - coarse and fine pruning for faster retrieval.\nFurthermore, we also develop two Community-to-Text methods to convert the graph\nstructure of communities into textual form for better understanding by LLMs.\nExperimental results demonstrate the effectiveness of FastToG, showcasing\nhigher accuracy, faster reasoning, and better explainability compared to the\nprevious works.",
      "tldr_zh": "本论文提出Fast Think-on-Graph (FastToG)，一种创新范式，用于增强大型语言模型 (LLMs) 在知识图谱 (KGs) 上的推理能力，以解决现有Graph Retrieval Augmented Generation (GRAG) 的局限性，如关联捕获狭窄浅显和高计算成本。FastToG 通过社区检测捕获更深的相关性，并采用两阶段社区修剪（coarse and fine pruning）加速检索，同时开发两种Community-to-Text 方法将图结构转换为文本，便于LLMs理解。实验结果显示，FastToG 比先前工作实现了更高的准确率、更快的推理速度以及更好的可解释性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14300v1",
      "published_date": "2025-01-24 07:47:40 UTC",
      "updated_date": "2025-01-24 07:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:04:51.698146"
    },
    {
      "arxiv_id": "2501.14294v3",
      "title": "Examining Alignment of Large Language Models through Representative Heuristics: The Case of Political Stereotypes",
      "title_zh": "翻译失败",
      "authors": [
        "Sullam Jeoung",
        "Yubin Ge",
        "Haohan Wang",
        "Jana Diesner"
      ],
      "abstract": "Examining the alignment of large language models (LLMs) has become\nincreasingly important, e.g., when LLMs fail to operate as intended. This study\nexamines the alignment of LLMs with human values for the domain of politics.\nPrior research has shown that LLM-generated outputs can include political\nleanings and mimic the stances of political parties on various issues. However,\nthe extent and conditions under which LLMs deviate from empirical positions are\ninsufficiently examined. To address this gap, we analyze the factors that\ncontribute to LLMs' deviations from empirical positions on political issues,\naiming to quantify these deviations and identify the conditions that cause\nthem.\n  Drawing on findings from cognitive science about representativeness\nheuristics, i.e., situations where humans lean on representative attributes of\na target group in a way that leads to exaggerated beliefs, we scrutinize LLM\nresponses through this heuristics' lens. We conduct experiments to determine\nhow LLMs inflate predictions about political parties, which results in\nstereotyping. We find that while LLMs can mimic certain political parties'\npositions, they often exaggerate these positions more than human survey\nrespondents do. Also, LLMs tend to overemphasize representativeness more than\nhumans. This study highlights the susceptibility of LLMs to representativeness\nheuristics, suggesting a potential vulnerability of LLMs that facilitates\npolitical stereotyping. We also test prompt-based mitigation strategies,\nfinding that strategies that can mitigate representative heuristics in humans\nare also effective in reducing the influence of representativeness on\nLLM-generated responses.",
      "tldr_zh": "本研究考察了大型语言模型（LLMs）的对齐性，聚焦于政治领域的代表性启发式（representativeness heuristics）如何导致政治刻板印象（political stereotypes）。通过实验，研究者发现LLMs在预测政党立场时往往比人类调查受访者更夸张地夸大这些立场，并过度强调代表性属性，从而加剧偏差。论文量化了这些偏差，并证明基于提示的缓解策略（如认知科学中针对人类的策略）能有效减少代表性启发式对LLMs输出影响，为提升LLMs的政治中立性提供了实用见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14294v3",
      "published_date": "2025-01-24 07:24:23 UTC",
      "updated_date": "2025-03-02 06:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:05:03.440972"
    },
    {
      "arxiv_id": "2501.14288v2",
      "title": "A Comprehensive Framework for Semantic Similarity Analysis of Human and AI-Generated Text Using Transformer Architectures and Ensemble Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Lifu Gao",
        "Ziwei Liu",
        "Qi Zhang"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has made detecting\nAI-generated text an increasingly critical challenge. Traditional methods often\nfail to capture the nuanced semantic differences between human and\nmachine-generated content. We therefore propose a novel approach based on\nsemantic similarity analysis, leveraging a multi-layered architecture that\ncombines a pre-trained DeBERTa-v3-large model, Bi-directional LSTMs, and linear\nattention pooling to capture both local and global semantic patterns. To\nenhance performance, we employ advanced input and output augmentation\ntechniques such as sector-level context integration and wide output\nconfigurations. These techniques enable the model to learn more discriminative\nfeatures and generalize across diverse domains. Experimental results show that\nthis approach works better than traditional methods, proving its usefulness for\nAI-generated text detection and other text comparison tasks.",
      "tldr_zh": "该研究提出一个全面框架，用于分析人类和 AI 生成文本的语义相似性，旨在解决传统方法无法捕捉细微语义差异的问题。该框架结合预训练的 DeBERTa-v3-large 模型、Bi-directional LSTMs 和线性注意力池化，构建多层架构来捕捉局部和全局语义模式，并通过 sector-level context integration 和 wide output configurations 等增强技术提升特征区分性和跨领域泛化能力。实验结果显示，该方法优于传统方法，在 AI 生成文本检测和其他文本比较任务中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14288v2",
      "published_date": "2025-01-24 07:07:37 UTC",
      "updated_date": "2025-01-31 02:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:05:14.150811"
    },
    {
      "arxiv_id": "2501.14278v2",
      "title": "Active Learning for Continual Learning: Keeping the Past Alive in the Present",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyun Park",
        "Dongmin Park",
        "Jae-Gil Lee"
      ],
      "abstract": "Continual learning (CL) enables deep neural networks to adapt to\never-changing data distributions. In practice, there may be scenarios where\nannotation is costly, leading to active continual learning (ACL), which\nperforms active learning (AL) for the CL scenarios when reducing the labeling\ncost by selecting the most informative subset is preferable. However,\nconventional AL strategies are not suitable for ACL, as they focus solely on\nlearning the new knowledge, leading to catastrophic forgetting of previously\nlearned tasks. Therefore, ACL requires a new AL strategy that can balance the\nprevention of catastrophic forgetting and the ability to quickly learn new\ntasks. In this paper, we propose AccuACL, Accumulated informativeness-based\nActive Continual Learning, by the novel use of the Fisher information matrix as\na criterion for sample selection, derived from a theoretical analysis of the\nFisher-optimality preservation properties within the framework of ACL, while\nalso addressing the scalability issue of Fisher information-based AL. Extensive\nexperiments demonstrate that AccuACL significantly outperforms AL baselines\nacross various CL algorithms, increasing the average accuracy and forgetting by\n23.8% and 17.0%, respectively, on average.",
      "tldr_zh": "这篇论文探讨了在Continual Learning (CL)场景中应用Active Learning (AL)以减少标注成本，同时避免灾难性遗忘问题。作者提出AccuACL，一种基于Accumulated informativeness的Active Continual Learning (ACL)方法，使用Fisher information matrix作为样本选择标准，以平衡新任务学习和过去知识保留。方法通过理论分析Fisher-optimality在ACL框架中的特性，并解决了Fisher信息基于AL的可扩展性问题。实验结果显示，AccuACL在多种CL算法上显著优于基准模型，平均准确率提高23.8%，遗忘率降低17.0%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14278v2",
      "published_date": "2025-01-24 06:46:58 UTC",
      "updated_date": "2025-04-21 07:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:05:26.702908"
    },
    {
      "arxiv_id": "2501.14276v1",
      "title": "Global Semantic-Guided Sub-image Feature Weight Allocation in High-Resolution Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Liang",
        "Xu Li",
        "Xiaolei Chen",
        "Haotian Chen",
        "Yi Zheng",
        "Chenghang Lai",
        "Bin Li",
        "Xiangyang Xue"
      ],
      "abstract": "As the demand for high-resolution image processing in Large Vision-Language\nModels (LVLMs) grows, sub-image partitioning has become a popular approach for\nmitigating visual information loss associated with fixed-resolution processing.\nHowever, existing partitioning methods uniformly process sub-images, resulting\nin suboptimal image understanding. In this work, we reveal that the sub-images\nwith higher semantic relevance to the entire image encapsulate richer visual\ninformation for preserving the model's visual understanding ability. Therefore,\nwe propose the Global Semantic-guided Weight Allocator (GSWA) module, which\ndynamically allocates weights to sub-images based on their relative information\ndensity, emulating human visual attention mechanisms. This approach enables the\nmodel to focus on more informative regions, overcoming the limitations of\nuniform treatment. We integrate GSWA into the InternVL2-2B framework to create\nSleighVL, a lightweight yet high-performing model. Extensive experiments\ndemonstrate that SleighVL outperforms models with comparable parameters and\nremains competitive with larger models. Our work provides a promising direction\nfor more efficient and contextually aware high-resolution image processing in\nLVLMs, advancing multimodal system development.",
      "tldr_zh": "本研究针对 Large Vision-Language Models (LVLMs) 中高分辨率图像处理的挑战，指出现有子图像分区方法因均匀处理而导致图像理解不佳。论文提出 Global Semantic-guided Weight Allocator (GSWA) 模块，通过动态根据子图像的语义相关性和信息密度分配权重，模仿人类视觉注意机制，从而增强模型对关键区域的关注。作者将 GSWA 整合到 InternVL2-2B 框架中，开发出 SleighVL 模型，实验结果显示其在性能上超越同参数模型，并与更大模型竞争。该方法为高效、上下文感知的高分辨率图像处理提供新方向，促进多模态系统的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 10 figures and tables",
      "pdf_url": "http://arxiv.org/pdf/2501.14276v1",
      "published_date": "2025-01-24 06:42:06 UTC",
      "updated_date": "2025-01-24 06:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:05:38.192974"
    },
    {
      "arxiv_id": "2501.14275v1",
      "title": "Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Sadegh Mahdavi",
        "Muchen Li",
        "Kaiwen Liu",
        "Christos Thrampoulidis",
        "Leonid Sigal",
        "Renjie Liao"
      ],
      "abstract": "Advances in Large Language Models (LLMs) have sparked interest in their\nability to solve Olympiad-level math problems. However, the training and\nevaluation of these models are constrained by the limited size and quality of\navailable datasets, as creating large-scale data for such advanced problems\nrequires extensive effort from human experts. In addition, current benchmarks\nare prone to contamination, leading to unreliable evaluations. In this paper,\nwe present an automated pipeline that leverages the rich resources of the Art\nof Problem Solving (AoPS) forum, which predominantly features Olympiad-level\nproblems and community-driven solutions. Using open-source LLMs, we develop a\nmethod to extract question-answer pairs from the forum, resulting in\nAoPS-Instruct, a dataset of more than 600,000 high-quality QA pairs. Our\nexperiments demonstrate that fine-tuning LLMs on AoPS-Instruct improves their\nreasoning abilities across various benchmarks. Moreover, we build an automatic\npipeline that introduces LiveAoPSBench, an evolving evaluation set with\ntimestamps, derived from the latest forum data, providing a\ncontamination-resistant benchmark for assessing LLM performance. Notably, we\nobserve a significant decline in LLM performance over time, suggesting their\nsuccess on older examples may stem from pre-training exposure rather than true\nreasoning ability. Our work presents a scalable approach to creating and\nmaintaining large-scale, high-quality datasets for advanced math reasoning,\noffering valuable insights into the capabilities and limitations of LLMs in\nthis domain. Our benchmark and code is available at\nhttps://github.com/DSL-Lab/aops",
      "tldr_zh": "该研究解决了大型语言模型（LLMs）在处理奥林匹克级数学问题时的训练和评估挑战，通过利用 Art of Problem Solving (AoPS) 论坛资源开发了一个自动化管道。研究者提取了超过60万高质量问题-答案对，创建了AoPS-Instruct数据集，并使用它微调LLMs，从而提升了模型在各种基准上的推理能力。同时，他们构建了LiveAoPSBench，一个基于最新论坛数据的演化评估集，具有时间戳特性，以抵抗数据污染。实验发现，LLMs的性能随时间下降，表明其成功可能源于预训练暴露而非真正的推理能力，这为创建可扩展的高质量数据集提供了宝贵洞察。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14275v1",
      "published_date": "2025-01-24 06:39:38 UTC",
      "updated_date": "2025-01-24 06:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:05:51.441739"
    },
    {
      "arxiv_id": "2501.14269v2",
      "title": "Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Shengzhe Zhang",
        "Liyi Chen",
        "Dazhong Shen",
        "Chao Wang",
        "Hui Xiong"
      ],
      "abstract": "Multi-modal sequential recommendation (SR) leverages multi-modal data to\nlearn more comprehensive item features and user preferences than traditional SR\nmethods, which has become a critical topic in both academia and industry.\nExisting methods typically focus on enhancing multi-modal information utility\nthrough adaptive modality fusion to capture the evolving of user preference\nfrom user-item interaction sequences. However, most of them overlook the\ninterference caused by redundant interest-irrelevant information contained in\nrich multi-modal data. Additionally, they primarily rely on implicit temporal\ninformation based solely on chronological ordering, neglecting explicit\ntemporal signals that could more effectively represent dynamic user interest\nover time. To address these limitations, we propose a Hierarchical time-aware\nMixture of experts for multi-modal Sequential Recommendation (HM4SR) with a\ntwo-level Mixture of Experts (MoE) and a multi-task learning strategy.\nSpecifically, the first MoE, named Interactive MoE, extracts essential user\ninterest-related information from the multi-modal data of each item. Then, the\nsecond MoE, termed Temporal MoE, captures user dynamic interests by introducing\nexplicit temporal embeddings from timestamps in modality encoding. To further\naddress data sparsity, we propose three auxiliary supervision tasks:\nsequence-level category prediction (CP) for item feature understanding,\ncontrastive learning on ID (IDCL) to align sequence context with user\ninterests, and placeholder contrastive learning (PCL) to integrate temporal\ninformation with modalities for dynamic interest modeling. Extensive\nexperiments on four public datasets verify the effectiveness of HM4SR compared\nto several state-of-the-art approaches.",
      "tldr_zh": "本文提出 Hierarchical time-aware Mixture of Experts for multi-modal Sequential Recommendation (HM4SR)，一种用于多模态序列推荐的层次化时间感知框架，旨在解决现有方法忽略多模态数据中冗余信息干扰和仅依赖隐式时间信号的问题。HM4SR 采用两级 Mixture of Experts (MoE)：Interactive MoE 从物品的多模态数据中提取用户兴趣相关信息，Temporal MoE 通过显式时间嵌入（如时间戳）捕捉动态用户兴趣。框架还整合多任务学习策略，包括序列级别的类别预测 (CP)、ID 对比学习 (IDCL) 和占位符对比学习 (PCL)，以缓解数据稀疏性。在四个公开数据集上的实验显示，HM4SR 比现有方法表现出色，验证了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14269v2",
      "published_date": "2025-01-24 06:26:50 UTC",
      "updated_date": "2025-01-30 02:05:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:06:03.776955"
    },
    {
      "arxiv_id": "2501.14268v1",
      "title": "Pre-train and Fine-tune: Recommenders as Large Models",
      "title_zh": "预训练和微调：推荐系统作为大型模型",
      "authors": [
        "Zhenhao Jiang",
        "Chenghao Chen",
        "Hao Feng",
        "Yu Yang",
        "Jin Liu",
        "Jie Zhang",
        "Jia Jia",
        "Ning Hu"
      ],
      "abstract": "In reality, users have different interests in different periods, regions,\nscenes, etc. Such changes in interest are so drastic that they are difficult to\nbe captured by recommenders. Existing multi-domain learning can alleviate this\nproblem. However, the structure of the industrial recommendation system is\ncomplex, the amount of data is huge, and the training cost is extremely high,\nso it is difficult to modify the structure of the industrial recommender and\nre-train it. To fill this gap, we consider recommenders as large pre-trained\nmodels and fine-tune them. We first propose the theory of the information\nbottleneck for fine-tuning and present an explanation for the fine-tuning\ntechnique in recommenders. To tailor for recommendation, we design an\ninformation-aware adaptive kernel (IAK) technique to fine-tune the pre-trained\nrecommender. Specifically, we define fine-tuning as two phases: knowledge\ncompression and knowledge matching and let the training stage of IAK explicitly\napproximate these two phases. Our proposed approach designed from the essence\nof fine-tuning is well interpretable. Extensive online and offline experiments\nshow the superiority of our proposed method. Besides, we also share unique and\nimportant lessons we learned when deploying the method in a large-scale online\nplatform. We also present the potential issues of fine-tuning techniques in\nrecommendation systems and the corresponding solutions. The recommender with\nIAK technique has been deployed on the homepage of a billion-scale online food\nplatform for several months and has yielded considerable profits in our\nbusiness.",
      "tldr_zh": "本论文提出将推荐系统视为大型预训练模型，通过预训练和微调来应对用户兴趣在不同时期、地区或场景下的剧烈变化，避免了直接修改复杂工业系统的成本。作者引入信息瓶颈理论来解释微调机制，并设计了信息感知自适应内核(IAK)技术，将微调分为知识压缩和知识匹配两个阶段，以提升推荐准确性。实验结果显示，该方法在离线和在线环境中优于现有基线，并在亿级在线食品平台上部署后产生了显著的商业利润，同时论文分享了潜在问题及其解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WWW2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14268v1",
      "published_date": "2025-01-24 06:18:12 UTC",
      "updated_date": "2025-01-24 06:18:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:06:16.122233"
    },
    {
      "arxiv_id": "2501.16378v1",
      "title": "Internal Activation Revision: Safeguarding Vision Language Models Without Parameter Update",
      "title_zh": "内部激活修正：无需参数更新的视觉语言模型安全保障",
      "authors": [
        "Qing Li",
        "Jiahui Geng",
        "Zongxiong Chen",
        "Kun Song",
        "Lei Ma",
        "Fakhri Karray"
      ],
      "abstract": "Vision-language models (VLMs) demonstrate strong multimodal capabilities but\nhave been found to be more susceptible to generating harmful content compared\nto their backbone large language models (LLMs). Our investigation reveals that\nthe integration of images significantly shifts the model's internal activations\nduring the forward pass, diverging from those triggered by textual input.\nMoreover, the safety alignments of LLMs embedded within VLMs are not\nsufficiently robust to handle the activations discrepancies, making the models\nvulnerable to even the simplest jailbreaking attacks. To address this issue, we\npropose an \\textbf{internal activation revision} approach that efficiently\nrevises activations during generation, steering the model toward safer outputs.\nOur framework incorporates revisions at both the layer and head levels,\noffering control over the model's generation at varying levels of granularity.\nIn addition, we explore three strategies for constructing positive and negative\nsamples and two approaches for extracting revision vectors, resulting in\ndifferent variants of our method. Comprehensive experiments demonstrate that\nthe internal activation revision method significantly improves the safety of\nwidely used VLMs, reducing attack success rates by an average of 48.94\\%,\n34.34\\%, 43.92\\%, and 52.98\\% on SafeBench, Safe-Unsafe, Unsafe, and\nMM-SafetyBench, respectively, while minimally impacting model helpfulness.",
      "tldr_zh": "本研究发现，Vision-language models (VLMs) 比 backbone large language models (LLMs) 更容易生成有害内容，这是由于图像输入导致内部激活偏移，且 LLMs 的安全对齐无法有效应对。针对这一问题，提出 internal activation revision 方法，通过在生成过程中不更新参数而在层级和头部级别修改激活，从而实现对模型输出的精细控制，并探索多种正负样本构建和修正向量提取策略。实验结果显示，该方法显著提升了 VLMs 的安全性，在 SafeBench、Safe-Unsafe、Unsafe 和 MM-SafetyBench 等基准上平均降低了攻击成功率 48.94%、34.34%、43.92% 和 52.98%，同时对模型的帮助性影响最小。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16378v1",
      "published_date": "2025-01-24 06:17:22 UTC",
      "updated_date": "2025-01-24 06:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:06:28.630279"
    },
    {
      "arxiv_id": "2501.14250v1",
      "title": "Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors",
      "title_zh": "Sir",
      "authors": [
        "Yi Zhao",
        "Youzhi Zhang"
      ],
      "abstract": "Large language models (LLMs) are widely used in real-world applications,\nraising concerns about their safety and trustworthiness. While red-teaming with\njailbreak prompts exposes the vulnerabilities of LLMs, current efforts focus\nprimarily on single-turn attacks, overlooking the multi-turn strategies used by\nreal-world adversaries. Existing multi-turn methods rely on static patterns or\npredefined logical chains, failing to account for the dynamic strategies during\nattacks. We propose Siren, a learning-based multi-turn attack framework\ndesigned to simulate real-world human jailbreak behaviors. Siren consists of\nthree stages: (1) training set construction utilizing Turn-Level LLM feedback\n(Turn-MF), (2) post-training attackers with supervised fine-tuning (SFT) and\ndirect preference optimization (DPO), and (3) interactions between the\nattacking and target LLMs. Experiments demonstrate that Siren achieves an\nattack success rate (ASR) of 90% with LLaMA-3-8B as the attacker against\nGemini-1.5-Pro as the target model, and 70% with Mistral-7B against GPT-4o,\nsignificantly outperforming single-turn baselines. Moreover, Siren with a\n7B-scale model achieves performance comparable to a multi-turn baseline that\nleverages GPT-4o as the attacker, while requiring fewer turns and employing\ndecomposition strategies that are better semantically aligned with attack\ngoals. We hope Siren inspires the development of stronger defenses against\nadvanced multi-turn jailbreak attacks under realistic scenarios. Code is\navailable at https://github.com/YiyiyiZhao/siren. Warning: This paper contains\npotentially harmful text.",
      "tldr_zh": "该研究提出 Siren，一种基于学习的 multi-turn 攻击框架，用于模拟真实人类 jailbreak 行为，以评估 LLMs 的安全性和可信度。Siren 包括三个阶段：利用 Turn-Level LLM feedback (Turn-MF) 构建训练集、通过 supervised fine-tuning (SFT) 和 direct preference optimization (DPO) 后训练攻击者，以及攻击者和目标 LLM 之间的交互。实验结果显示，Siren 实现了高达 90% 的 attack success rate (ASR) 对 Gemini-1.5-Pro 和 70% 对 GPT-4o，显著优于单轮基线，且使用 7B-scale 模型即可达到与 GPT-4o 相当的性能，同时减少轮次并提升策略的语义对齐。该框架旨在激发更强的 multi-turn 防御发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14250v1",
      "published_date": "2025-01-24 05:31:27 UTC",
      "updated_date": "2025-01-24 05:31:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:06:39.767434"
    },
    {
      "arxiv_id": "2501.14249v7",
      "title": "Humanity's Last Exam",
      "title_zh": "人类的最后考试",
      "authors": [
        "Long Phan",
        "Alice Gatti",
        "Ziwen Han",
        "Nathaniel Li",
        "Josephina Hu",
        "Hugh Zhang",
        "Chen Bo Calvin Zhang",
        "Mohamed Shaaban",
        "John Ling",
        "Sean Shi",
        "Michael Choi",
        "Anish Agrawal",
        "Arnav Chopra",
        "Adam Khoja",
        "Ryan Kim",
        "Richard Ren",
        "Jason Hausenloy",
        "Oliver Zhang",
        "Mantas Mazeika",
        "Dmitry Dodonov",
        "Tung Nguyen",
        "Jaeho Lee",
        "Daron Anderson",
        "Mikhail Doroshenko",
        "Alun Cennyth Stokes",
        "Mobeen Mahmood",
        "Oleksandr Pokutnyi",
        "Oleg Iskra",
        "Jessica P. Wang",
        "John-Clark Levin",
        "Mstyslav Kazakov",
        "Fiona Feng",
        "Steven Y. Feng",
        "Haoran Zhao",
        "Michael Yu",
        "Varun Gangal",
        "Chelsea Zou",
        "Zihan Wang",
        "Serguei Popov",
        "Robert Gerbicz",
        "Geoff Galgon",
        "Johannes Schmitt",
        "Will Yeadon",
        "Yongki Lee",
        "Scott Sauers",
        "Alvaro Sanchez",
        "Fabian Giska",
        "Marc Roth",
        "Søren Riis",
        "Saiteja Utpala",
        "Noah Burns",
        "Gashaw M. Goshu",
        "Mohinder Maheshbhai Naiya",
        "Chidozie Agu",
        "Zachary Giboney",
        "Antrell Cheatom",
        "Francesco Fournier-Facio",
        "Sarah-Jane Crowson",
        "Lennart Finke",
        "Zerui Cheng",
        "Jennifer Zampese",
        "Ryan G. Hoerr",
        "Mark Nandor",
        "Hyunwoo Park",
        "Tim Gehrunger",
        "Jiaqi Cai",
        "Ben McCarty",
        "Alexis C Garretson",
        "Edwin Taylor",
        "Damien Sileo",
        "Qiuyu Ren",
        "Usman Qazi",
        "Lianghui Li",
        "Jungbae Nam",
        "John B. Wydallis",
        "Pavel Arkhipov",
        "Jack Wei Lun Shi",
        "Aras Bacho",
        "Chris G. Willcocks",
        "Hangrui Cao",
        "Sumeet Motwani",
        "Emily de Oliveira Santos",
        "Johannes Veith",
        "Edward Vendrow",
        "Doru Cojoc",
        "Kengo Zenitani",
        "Joshua Robinson",
        "Longke Tang",
        "Yuqi Li",
        "Joshua Vendrow",
        "Natanael Wildner Fraga",
        "Vladyslav Kuchkin",
        "Andrey Pupasov Maksimov",
        "Pierre Marion",
        "Denis Efremov",
        "Jayson Lynch",
        "Kaiqu Liang",
        "Aleksandar Mikov",
        "Andrew Gritsevskiy",
        "Julien Guillod",
        "Gözdenur Demir",
        "Dakotah Martinez",
        "Ben Pageler",
        "Kevin Zhou",
        "Saeed Soori",
        "Ori Press",
        "Henry Tang",
        "Paolo Rissone",
        "Sean R. Green",
        "Lina Brüssel",
        "Moon Twayana",
        "Aymeric Dieuleveut",
        "Joseph Marvin Imperial",
        "Ameya Prabhu",
        "Jinzhou Yang",
        "Nick Crispino",
        "Arun Rao",
        "Dimitri Zvonkine",
        "Gabriel Loiseau",
        "Mikhail Kalinin",
        "Marco Lukas",
        "Ciprian Manolescu",
        "Nate Stambaugh",
        "Subrata Mishra",
        "Tad Hogg",
        "Carlo Bosio",
        "Brian P Coppola",
        "Julian Salazar",
        "Jaehyeok Jin",
        "Rafael Sayous",
        "Stefan Ivanov",
        "Philippe Schwaller",
        "Shaipranesh Senthilkuma",
        "Andres M Bran",
        "Andres Algaba",
        "Kelsey Van den Houte",
        "Lynn Van Der Sypt",
        "Brecht Verbeken",
        "David Noever",
        "Alexei Kopylov",
        "Benjamin Myklebust",
        "Bikun Li",
        "Lisa Schut",
        "Evgenii Zheltonozhskii",
        "Qiaochu Yuan",
        "Derek Lim",
        "Richard Stanley",
        "Tong Yang",
        "John Maar",
        "Julian Wykowski",
        "Martí Oller",
        "Anmol Sahu",
        "Cesare Giulio Ardito",
        "Yuzheng Hu",
        "Ariel Ghislain Kemogne Kamdoum",
        "Alvin Jin",
        "Tobias Garcia Vilchis",
        "Yuexuan Zu",
        "Martin Lackner",
        "James Koppel",
        "Gongbo Sun",
        "Daniil S. Antonenko",
        "Steffi Chern",
        "Bingchen Zhao",
        "Pierrot Arsene",
        "Joseph M Cavanagh",
        "Daofeng Li",
        "Jiawei Shen",
        "Donato Crisostomi",
        "Wenjin Zhang",
        "Ali Dehghan",
        "Sergey Ivanov",
        "David Perrella",
        "Nurdin Kaparov",
        "Allen Zang",
        "Ilia Sucholutsky",
        "Arina Kharlamova",
        "Daniil Orel",
        "Vladislav Poritski",
        "Shalev Ben-David",
        "Zachary Berger",
        "Parker Whitfill",
        "Michael Foster",
        "Daniel Munro",
        "Linh Ho",
        "Shankar Sivarajan",
        "Dan Bar Hava",
        "Aleksey Kuchkin",
        "David Holmes",
        "Alexandra Rodriguez-Romero",
        "Frank Sommerhage",
        "Anji Zhang",
        "Richard Moat",
        "Keith Schneider",
        "Zakayo Kazibwe",
        "Don Clarke",
        "Dae Hyun Kim",
        "Felipe Meneguitti Dias",
        "Sara Fish",
        "Veit Elser",
        "Tobias Kreiman",
        "Victor Efren Guadarrama Vilchis",
        "Immo Klose",
        "Ujjwala Anantheswaran",
        "Adam Zweiger",
        "Kaivalya Rawal",
        "Jeffery Li",
        "Jeremy Nguyen",
        "Nicolas Daans",
        "Haline Heidinger",
        "Maksim Radionov",
        "Václav Rozhoň",
        "Vincent Ginis",
        "Christian Stump",
        "Niv Cohen",
        "Rafał Poświata",
        "Josef Tkadlec",
        "Alan Goldfarb",
        "Chenguang Wang",
        "Piotr Padlewski",
        "Stanislaw Barzowski",
        "Kyle Montgomery",
        "Ryan Stendall",
        "Jamie Tucker-Foltz",
        "Jack Stade",
        "T. Ryan Rogers",
        "Tom Goertzen",
        "Declan Grabb",
        "Abhishek Shukla",
        "Alan Givré",
        "John Arnold Ambay",
        "Archan Sen",
        "Muhammad Fayez Aziz",
        "Mark H Inlow",
        "Hao He",
        "Ling Zhang",
        "Younesse Kaddar",
        "Ivar Ängquist",
        "Yanxu Chen",
        "Harrison K Wang",
        "Kalyan Ramakrishnan",
        "Elliott Thornley",
        "Antonio Terpin",
        "Hailey Schoelkopf",
        "Eric Zheng",
        "Avishy Carmi",
        "Ethan D. L. Brown",
        "Kelin Zhu",
        "Max Bartolo",
        "Richard Wheeler",
        "Martin Stehberger",
        "Peter Bradshaw",
        "JP Heimonen",
        "Kaustubh Sridhar",
        "Ido Akov",
        "Jennifer Sandlin",
        "Yury Makarychev",
        "Joanna Tam",
        "Hieu Hoang",
        "David M. Cunningham",
        "Vladimir Goryachev",
        "Demosthenes Patramanis",
        "Michael Krause",
        "Andrew Redenti",
        "David Aldous",
        "Jesyin Lai",
        "Shannon Coleman",
        "Jiangnan Xu",
        "Sangwon Lee",
        "Ilias Magoulas",
        "Sandy Zhao",
        "Ning Tang",
        "Michael K. Cohen",
        "Orr Paradise",
        "Jan Hendrik Kirchner",
        "Maksym Ovchynnikov",
        "Jason O. Matos",
        "Adithya Shenoy",
        "Michael Wang",
        "Yuzhou Nie",
        "Anna Sztyber-Betley",
        "Paolo Faraboschi",
        "Robin Riblet",
        "Jonathan Crozier",
        "Shiv Halasyamani",
        "Shreyas Verma",
        "Prashant Joshi",
        "Eli Meril",
        "Ziqiao Ma",
        "Jérémy Andréoletti",
        "Raghav Singhal",
        "Jacob Platnick",
        "Volodymyr Nevirkovets",
        "Luke Basler",
        "Alexander Ivanov",
        "Seri Khoury",
        "Nils Gustafsson",
        "Marco Piccardo",
        "Hamid Mostaghimi",
        "Qijia Chen",
        "Virendra Singh",
        "Tran Quoc Khánh",
        "Paul Rosu",
        "Hannah Szlyk",
        "Zachary Brown",
        "Himanshu Narayan",
        "Aline Menezes",
        "Jonathan Roberts",
        "William Alley",
        "Kunyang Sun",
        "Arkil Patel",
        "Max Lamparth",
        "Anka Reuel",
        "Linwei Xin",
        "Hanmeng Xu",
        "Jacob Loader",
        "Freddie Martin",
        "Zixuan Wang",
        "Andrea Achilleos",
        "Thomas Preu",
        "Tomek Korbak",
        "Ida Bosio",
        "Fereshteh Kazemi",
        "Ziye Chen",
        "Biró Bálint",
        "Eve J. Y. Lo",
        "Jiaqi Wang",
        "Maria Inês S. Nunes",
        "Jeremiah Milbauer",
        "M Saiful Bari",
        "Zihao Wang",
        "Behzad Ansarinejad",
        "Yewen Sun",
        "Stephane Durand",
        "Hossam Elgnainy",
        "Guillaume Douville",
        "Daniel Tordera",
        "George Balabanian",
        "Hew Wolff",
        "Lynna Kvistad",
        "Hsiaoyun Milliron",
        "Ahmad Sakor",
        "Murat Eron",
        "Andrew Favre D. O.",
        "Shailesh Shah",
        "Xiaoxiang Zhou",
        "Firuz Kamalov",
        "Sherwin Abdoli",
        "Tim Santens",
        "Shaul Barkan",
        "Allison Tee",
        "Robin Zhang",
        "Alessandro Tomasiello",
        "G. Bruno De Luca",
        "Shi-Zhuo Looi",
        "Vinh-Kha Le",
        "Noam Kolt",
        "Jiayi Pan",
        "Emma Rodman",
        "Jacob Drori",
        "Carl J Fossum",
        "Niklas Muennighoff",
        "Milind Jagota",
        "Ronak Pradeep",
        "Honglu Fan",
        "Jonathan Eicher",
        "Michael Chen",
        "Kushal Thaman",
        "William Merrill",
        "Moritz Firsching",
        "Carter Harris",
        "Stefan Ciobâcă",
        "Jason Gross",
        "Rohan Pandey",
        "Ilya Gusev",
        "Adam Jones",
        "Shashank Agnihotri",
        "Pavel Zhelnov",
        "Mohammadreza Mofayezi",
        "Alexander Piperski",
        "David K. Zhang",
        "Kostiantyn Dobarskyi",
        "Roman Leventov",
        "Ignat Soroko",
        "Joshua Duersch",
        "Vage Taamazyan",
        "Andrew Ho",
        "Wenjie Ma",
        "William Held",
        "Ruicheng Xian",
        "Armel Randy Zebaze",
        "Mohanad Mohamed",
        "Julian Noah Leser",
        "Michelle X Yuan",
        "Laila Yacar",
        "Johannes Lengler",
        "Katarzyna Olszewska",
        "Claudio Di Fratta",
        "Edson Oliveira",
        "Joseph W. Jackson",
        "Andy Zou",
        "Muthu Chidambaram",
        "Timothy Manik",
        "Hector Haffenden",
        "Dashiell Stander",
        "Ali Dasouqi",
        "Alexander Shen",
        "Bita Golshani",
        "David Stap",
        "Egor Kretov",
        "Mikalai Uzhou",
        "Alina Borisovna Zhidkovskaya",
        "Nick Winter",
        "Miguel Orbegozo Rodriguez",
        "Robert Lauff",
        "Dustin Wehr",
        "Colin Tang",
        "Zaki Hossain",
        "Shaun Phillips",
        "Fortuna Samuele",
        "Fredrik Ekström",
        "Angela Hammon",
        "Oam Patel",
        "Faraz Farhidi",
        "George Medley",
        "Forough Mohammadzadeh",
        "Madellene Peñaflor",
        "Haile Kassahun",
        "Alena Friedrich",
        "Rayner Hernandez Perez",
        "Daniel Pyda",
        "Taom Sakal",
        "Omkar Dhamane",
        "Ali Khajegili Mirabadi",
        "Eric Hallman",
        "Kenchi Okutsu",
        "Mike Battaglia",
        "Mohammad Maghsoudimehrabani",
        "Alon Amit",
        "Dave Hulbert",
        "Roberto Pereira",
        "Simon Weber",
        "Handoko",
        "Anton Peristyy",
        "Stephen Malina",
        "Mustafa Mehkary",
        "Rami Aly",
        "Frank Reidegeld",
        "Anna-Katharina Dick",
        "Cary Friday",
        "Mukhwinder Singh",
        "Hassan Shapourian",
        "Wanyoung Kim",
        "Mariana Costa",
        "Hubeyb Gurdogan",
        "Harsh Kumar",
        "Chiara Ceconello",
        "Chao Zhuang",
        "Haon Park",
        "Micah Carroll",
        "Andrew R. Tawfeek",
        "Stefan Steinerberger",
        "Daattavya Aggarwal",
        "Michael Kirchhof",
        "Linjie Dai",
        "Evan Kim",
        "Johan Ferret",
        "Jainam Shah",
        "Yuzhou Wang",
        "Minghao Yan",
        "Krzysztof Burdzy",
        "Lixin Zhang",
        "Antonio Franca",
        "Diana T. Pham",
        "Kang Yong Loh",
        "Joshua Robinson",
        "Abram Jackson",
        "Paolo Giordano",
        "Philipp Petersen",
        "Adrian Cosma",
        "Jesus Colino",
        "Colin White",
        "Jacob Votava",
        "Vladimir Vinnikov",
        "Ethan Delaney",
        "Petr Spelda",
        "Vit Stritecky",
        "Syed M. Shahid",
        "Jean-Christophe Mourrat",
        "Lavr Vetoshkin",
        "Koen Sponselee",
        "Renas Bacho",
        "Zheng-Xin Yong",
        "Florencia de la Rosa",
        "Nathan Cho",
        "Xiuyu Li",
        "Guillaume Malod",
        "Orion Weller",
        "Guglielmo Albani",
        "Leon Lang",
        "Julien Laurendeau",
        "Dmitry Kazakov",
        "Fatimah Adesanya",
        "Julien Portier",
        "Lawrence Hollom",
        "Victor Souza",
        "Yuchen Anna Zhou",
        "Julien Degorre",
        "Yiğit Yalın",
        "Gbenga Daniel Obikoya",
        "Rai",
        "Filippo Bigi",
        "M. C. Boscá",
        "Oleg Shumar",
        "Kaniuar Bacho",
        "Gabriel Recchia",
        "Mara Popescu",
        "Nikita Shulga",
        "Ngefor Mildred Tanwie",
        "Thomas C. H. Lux",
        "Ben Rank",
        "Colin Ni",
        "Matthew Brooks",
        "Alesia Yakimchyk",
        "Huanxu",
        "Liu",
        "Stefano Cavalleri",
        "Olle Häggström",
        "Emil Verkama",
        "Joshua Newbould",
        "Hans Gundlach",
        "Leonor Brito-Santana",
        "Brian Amaro",
        "Vivek Vajipey",
        "Rynaa Grover",
        "Ting Wang",
        "Yosi Kratish",
        "Wen-Ding Li",
        "Sivakanth Gopi",
        "Andrea Caciolai",
        "Christian Schroeder de Witt",
        "Pablo Hernández-Cámara",
        "Emanuele Rodolà",
        "Jules Robins",
        "Dominic Williamson",
        "Vincent Cheng",
        "Brad Raynor",
        "Hao Qi",
        "Ben Segev",
        "Jingxuan Fan",
        "Sarah Martinson",
        "Erik Y. Wang",
        "Kaylie Hausknecht",
        "Michael P. Brenner",
        "Mao Mao",
        "Christoph Demian",
        "Peyman Kassani",
        "Xinyu Zhang",
        "David Avagian",
        "Eshawn Jessica Scipio",
        "Alon Ragoler",
        "Justin Tan",
        "Blake Sims",
        "Rebeka Plecnik",
        "Aaron Kirtland",
        "Omer Faruk Bodur",
        "D. P. Shinde",
        "Yan Carlos Leyva Labrador",
        "Zahra Adoul",
        "Mohamed Zekry",
        "Ali Karakoc",
        "Tania C. B. Santos",
        "Samir Shamseldeen",
        "Loukmane Karim",
        "Anna Liakhovitskaia",
        "Nate Resman",
        "Nicholas Farina",
        "Juan Carlos Gonzalez",
        "Gabe Maayan",
        "Earth Anderson",
        "Rodrigo De Oliveira Pena",
        "Elizabeth Kelley",
        "Hodjat Mariji",
        "Rasoul Pouriamanesh",
        "Wentao Wu",
        "Ross Finocchio",
        "Ismail Alarab",
        "Joshua Cole",
        "Danyelle Ferreira",
        "Bryan Johnson",
        "Mohammad Safdari",
        "Liangti Dai",
        "Siriphan Arthornthurasuk",
        "Isaac C. McAlister",
        "Alejandro José Moyano",
        "Alexey Pronin",
        "Jing Fan",
        "Angel Ramirez-Trinidad",
        "Yana Malysheva",
        "Daphiny Pottmaier",
        "Omid Taheri",
        "Stanley Stepanic",
        "Samuel Perry",
        "Luke Askew",
        "Raúl Adrián Huerta Rodríguez",
        "Ali M. R. Minissi",
        "Ricardo Lorena",
        "Krishnamurthy Iyer",
        "Arshad Anil Fasiludeen",
        "Ronald Clark",
        "Josh Ducey",
        "Matheus Piza",
        "Maja Somrak",
        "Eric Vergo",
        "Juehang Qin",
        "Benjámin Borbás",
        "Eric Chu",
        "Jack Lindsey",
        "Antoine Jallon",
        "I. M. J. McInnis",
        "Evan Chen",
        "Avi Semler",
        "Luk Gloor",
        "Tej Shah",
        "Marc Carauleanu",
        "Pascal Lauer",
        "Tran Đuc Huy",
        "Hossein Shahrtash",
        "Emilien Duc",
        "Lukas Lewark",
        "Assaf Brown",
        "Samuel Albanie",
        "Brian Weber",
        "Warren S. Vaz",
        "Pierre Clavier",
        "Yiyang Fan",
        "Gabriel Poesia Reis e Silva",
        "Long",
        "Lian",
        "Marcus Abramovitch",
        "Xi Jiang",
        "Sandra Mendoza",
        "Murat Islam",
        "Juan Gonzalez",
        "Vasilios Mavroudis",
        "Justin Xu",
        "Pawan Kumar",
        "Laxman Prasad Goswami",
        "Daniel Bugas",
        "Nasser Heydari",
        "Ferenc Jeanplong",
        "Thorben Jansen",
        "Antonella Pinto",
        "Archimedes Apronti",
        "Abdallah Galal",
        "Ng Ze-An",
        "Ankit Singh",
        "Tong Jiang",
        "Joan of Arc Xavier",
        "Kanu Priya Agarwal",
        "Mohammed Berkani",
        "Gang Zhang",
        "Zhehang Du",
        "Benedito Alves de Oliveira Junior",
        "Dmitry Malishev",
        "Nicolas Remy",
        "Taylor D. Hartman",
        "Tim Tarver",
        "Stephen Mensah",
        "Gautier Abou Loume",
        "Wiktor Morak",
        "Farzad Habibi",
        "Sarah Hoback",
        "Will Cai",
        "Javier Gimenez",
        "Roselynn Grace Montecillo",
        "Jakub Łucki",
        "Russell Campbell",
        "Asankhaya Sharma",
        "Khalida Meer",
        "Shreen Gul",
        "Daniel Espinosa Gonzalez",
        "Xavier Alapont",
        "Alex Hoover",
        "Gunjan Chhablani",
        "Freddie Vargus",
        "Arunim Agarwal",
        "Yibo Jiang",
        "Deepakkumar Patil",
        "David Outevsky",
        "Kevin Joseph Scaria",
        "Rajat Maheshwari",
        "Abdelkader Dendane",
        "Priti Shukla",
        "Ashley Cartwright",
        "Sergei Bogdanov",
        "Niels Mündler",
        "Sören Möller",
        "Luca Arnaboldi",
        "Kunvar Thaman",
        "Muhammad Rehan Siddiqi",
        "Prajvi Saxena",
        "Himanshu Gupta",
        "Tony Fruhauff",
        "Glen Sherman",
        "Mátyás Vincze",
        "Siranut Usawasutsakorn",
        "Dylan Ler",
        "Anil Radhakrishnan",
        "Innocent Enyekwe",
        "Sk Md Salauddin",
        "Jiang Muzhen",
        "Aleksandr Maksapetyan",
        "Vivien Rossbach",
        "Chris Harjadi",
        "Mohsen Bahaloohoreh",
        "Claire Sparrow",
        "Jasdeep Sidhu",
        "Sam Ali",
        "Song Bian",
        "John Lai",
        "Eric Singer",
        "Justine Leon Uro",
        "Greg Bateman",
        "Mohamed Sayed",
        "Ahmed Menshawy",
        "Darling Duclosel",
        "Dario Bezzi",
        "Yashaswini Jain",
        "Ashley Aaron",
        "Murat Tiryakioglu",
        "Sheeshram Siddh",
        "Keith Krenek",
        "Imad Ali Shah",
        "Jun Jin",
        "Scott Creighton",
        "Denis Peskoff",
        "Zienab EL-Wasif",
        "Ragavendran P V",
        "Michael Richmond",
        "Joseph McGowan",
        "Tejal Patwardhan",
        "Hao-Yu Sun",
        "Ting Sun",
        "Nikola Zubić",
        "Samuele Sala",
        "Stephen Ebert",
        "Jean Kaddour",
        "Manuel Schottdorf",
        "Dianzhuo Wang",
        "Gerol Petruzella",
        "Alex Meiburg",
        "Tilen Medved",
        "Ali ElSheikh",
        "S Ashwin Hebbar",
        "Lorenzo Vaquero",
        "Xianjun Yang",
        "Jason Poulos",
        "Vilém Zouhar",
        "Sergey Bogdanik",
        "Mingfang Zhang",
        "Jorge Sanz-Ros",
        "David Anugraha",
        "Yinwei Dai",
        "Anh N. Nhu",
        "Xue Wang",
        "Ali Anil Demircali",
        "Zhibai Jia",
        "Yuyin Zhou",
        "Juncheng Wu",
        "Mike He",
        "Nitin Chandok",
        "Aarush Sinha",
        "Gaoxiang Luo",
        "Long Le",
        "Mickaël Noyé",
        "Michał Perełkiewicz",
        "Ioannis Pantidis",
        "Tianbo Qi",
        "Soham Sachin Purohit",
        "Letitia Parcalabescu",
        "Thai-Hoa Nguyen",
        "Genta Indra Winata",
        "Edoardo M. Ponti",
        "Hanchen Li",
        "Kaustubh Dhole",
        "Jongee Park",
        "Dario Abbondanza",
        "Yuanli Wang",
        "Anupam Nayak",
        "Diogo M. Caetano",
        "Antonio A. W. L. Wong",
        "Maria del Rio-Chanona",
        "Dániel Kondor",
        "Pieter Francois",
        "Ed Chalstrey",
        "Jakob Zsambok",
        "Dan Hoyer",
        "Jenny Reddish",
        "Jakob Hauser",
        "Francisco-Javier Rodrigo-Ginés",
        "Suchandra Datta",
        "Maxwell Shepherd",
        "Thom Kamphuis",
        "Qizheng Zhang",
        "Hyunjun Kim",
        "Ruiji Sun",
        "Jianzhu Yao",
        "Franck Dernoncourt",
        "Satyapriya Krishna",
        "Sina Rismanchian",
        "Bonan Pu",
        "Francesco Pinto",
        "Yingheng Wang",
        "Kumar Shridhar",
        "Kalon J. Overholt",
        "Glib Briia",
        "Hieu Nguyen",
        "David",
        "Soler Bartomeu",
        "Tony CY Pang",
        "Adam Wecker",
        "Yifan Xiong",
        "Fanfei Li",
        "Lukas S. Huber",
        "Joshua Jaeger",
        "Romano De Maddalena",
        "Xing Han Lù",
        "Yuhui Zhang",
        "Claas Beger",
        "Patrick Tser Jern Kon",
        "Sean Li",
        "Vivek Sanker",
        "Ming Yin",
        "Yihao Liang",
        "Xinlu Zhang",
        "Ankit Agrawal",
        "Li S. Yifei",
        "Zechen Zhang",
        "Mu Cai",
        "Yasin Sonmez",
        "Costin Cozianu",
        "Changhao Li",
        "Alex Slen",
        "Shoubin Yu",
        "Hyun Kyu Park",
        "Gabriele Sarti",
        "Marcin Briański",
        "Alessandro Stolfo",
        "Truong An Nguyen",
        "Mike Zhang",
        "Yotam Perlitz",
        "Jose Hernandez-Orallo",
        "Runjia Li",
        "Amin Shabani",
        "Felix Juefei-Xu",
        "Shikhar Dhingra",
        "Orr Zohar",
        "My Chiffon Nguyen",
        "Alexander Pondaven",
        "Abdurrahim Yilmaz",
        "Xuandong Zhao",
        "Chuanyang Jin",
        "Muyan Jiang",
        "Stefan Todoran",
        "Xinyao Han",
        "Jules Kreuer",
        "Brian Rabern",
        "Anna Plassart",
        "Martino Maggetti",
        "Luther Yap",
        "Robert Geirhos",
        "Jonathon Kean",
        "Dingsu Wang",
        "Sina Mollaei",
        "Chenkai Sun",
        "Yifan Yin",
        "Shiqi Wang",
        "Rui Li",
        "Yaowen Chang",
        "Anjiang Wei",
        "Alice Bizeul",
        "Xiaohan Wang",
        "Alexandre Oliveira Arrais",
        "Kushin Mukherjee",
        "Jorge Chamorro-Padial",
        "Jiachen Liu",
        "Xingyu Qu",
        "Junyi Guan",
        "Adam Bouyamourn",
        "Shuyu Wu",
        "Martyna Plomecka",
        "Junda Chen",
        "Mengze Tang",
        "Jiaqi Deng",
        "Shreyas Subramanian",
        "Haocheng Xi",
        "Haoxuan Chen",
        "Weizhi Zhang",
        "Yinuo Ren",
        "Haoqin Tu",
        "Sejong Kim",
        "Yushun Chen",
        "Sara Vera Marjanović",
        "Junwoo Ha",
        "Grzegorz Luczyna",
        "Jeff J. Ma",
        "Zewen Shen",
        "Dawn Song",
        "Cedegao E. Zhang",
        "Zhun Wang",
        "Gaël Gendron",
        "Yunze Xiao",
        "Leo Smucker",
        "Erica Weng",
        "Kwok Hao Lee",
        "Zhe Ye",
        "Stefano Ermon",
        "Ignacio D. Lopez-Miguel",
        "Theo Knights",
        "Anthony Gitter",
        "Namkyu Park",
        "Boyi Wei",
        "Hongzheng Chen",
        "Kunal Pai",
        "Ahmed Elkhanany",
        "Han Lin",
        "Philipp D. Siedler",
        "Jichao Fang",
        "Ritwik Mishra",
        "Károly Zsolnai-Fehér",
        "Xilin Jiang",
        "Shadab Khan",
        "Jun Yuan",
        "Rishab Kumar Jain",
        "Xi Lin",
        "Mike Peterson",
        "Zhe Wang",
        "Aditya Malusare",
        "Maosen Tang",
        "Isha Gupta",
        "Ivan Fosin",
        "Timothy Kang",
        "Barbara Dworakowska",
        "Kazuki Matsumoto",
        "Guangyao Zheng",
        "Gerben Sewuster",
        "Jorge Pretel Villanueva",
        "Ivan Rannev",
        "Igor Chernyavsky",
        "Jiale Chen",
        "Deepayan Banik",
        "Ben Racz",
        "Wenchao Dong",
        "Jianxin Wang",
        "Laila Bashmal",
        "Duarte V. Gonçalves",
        "Wei Hu",
        "Kaushik Bar",
        "Ondrej Bohdal",
        "Atharv Singh Patlan",
        "Shehzaad Dhuliawala",
        "Caroline Geirhos",
        "Julien Wist",
        "Yuval Kansal",
        "Bingsen Chen",
        "Kutay Tire",
        "Atak Talay Yücel",
        "Brandon Christof",
        "Veerupaksh Singla",
        "Zijian Song",
        "Sanxing Chen",
        "Jiaxin Ge",
        "Kaustubh Ponkshe",
        "Isaac Park",
        "Tianneng Shi",
        "Martin Q. Ma",
        "Joshua Mak",
        "Sherwin Lai",
        "Antoine Moulin",
        "Zhuo Cheng",
        "Zhanda Zhu",
        "Ziyi Zhang",
        "Vaidehi Patil",
        "Ketan Jha",
        "Qiutong Men",
        "Jiaxuan Wu",
        "Tianchi Zhang",
        "Bruno Hebling Vieira",
        "Alham Fikri Aji",
        "Jae-Won Chung",
        "Mohammed Mahfoud",
        "Ha Thi Hoang",
        "Marc Sperzel",
        "Wei Hao",
        "Kristof Meding",
        "Sihan Xu",
        "Vassilis Kostakos",
        "Davide Manini",
        "Yueying Liu",
        "Christopher Toukmaji",
        "Jay Paek",
        "Eunmi Yu",
        "Arif Engin Demircali",
        "Zhiyi Sun",
        "Ivan Dewerpe",
        "Hongsen Qin",
        "Roman Pflugfelder",
        "James Bailey",
        "Johnathan Morris",
        "Ville Heilala",
        "Sybille Rosset",
        "Zishun Yu",
        "Peter E. Chen",
        "Woongyeong Yeo",
        "Eeshaan Jain",
        "Ryan Yang",
        "Sreekar Chigurupati",
        "Julia Chernyavsky",
        "Sai Prajwal Reddy",
        "Subhashini Venugopalan",
        "Hunar Batra",
        "Core Francisco Park",
        "Hieu Tran",
        "Guilherme Maximiano",
        "Genghan Zhang",
        "Yizhuo Liang",
        "Hu Shiyu",
        "Rongwu Xu",
        "Rui Pan",
        "Siddharth Suresh",
        "Ziqi Liu",
        "Samaksh Gulati",
        "Songyang Zhang",
        "Peter Turchin",
        "Christopher W. Bartlett",
        "Christopher R. Scotese",
        "Phuong M. Cao",
        "Aakaash Nattanmai",
        "Gordon McKellips",
        "Anish Cheraku",
        "Asim Suhail",
        "Ethan Luo",
        "Marvin Deng",
        "Jason Luo",
        "Ashley Zhang",
        "Kavin Jindel",
        "Jay Paek",
        "Kasper Halevy",
        "Allen Baranov",
        "Michael Liu",
        "Advaith Avadhanam",
        "David Zhang",
        "Vincent Cheng",
        "Brad Ma",
        "Evan Fu",
        "Liam Do",
        "Joshua Lass",
        "Hubert Yang",
        "Surya Sunkari",
        "Vishruth Bharath",
        "Violet Ai",
        "James Leung",
        "Rishit Agrawal",
        "Alan Zhou",
        "Kevin Chen",
        "Tejas Kalpathi",
        "Ziqi Xu",
        "Gavin Wang",
        "Tyler Xiao",
        "Erik Maung",
        "Sam Lee",
        "Ryan Yang",
        "Roy Yue",
        "Ben Zhao",
        "Julia Yoon",
        "Sunny Sun",
        "Aryan Singh",
        "Ethan Luo",
        "Clark Peng",
        "Tyler Osbey",
        "Taozhi Wang",
        "Daryl Echeazu",
        "Hubert Yang",
        "Timothy Wu",
        "Spandan Patel",
        "Vidhi Kulkarni",
        "Vijaykaarti Sundarapandiyan",
        "Ashley Zhang",
        "Andrew Le",
        "Zafir Nasim",
        "Srikar Yalam",
        "Ritesh Kasamsetty",
        "Soham Samal",
        "Hubert Yang",
        "David Sun",
        "Nihar Shah",
        "Abhijeet Saha",
        "Alex Zhang",
        "Leon Nguyen",
        "Laasya Nagumalli",
        "Kaixin Wang",
        "Alan Zhou",
        "Aidan Wu",
        "Jason Luo",
        "Anwith Telluri",
        "Summer Yue",
        "Alexandr Wang",
        "Dan Hendrycks"
      ],
      "abstract": "Benchmarks are important tools for tracking the rapid advancements in large\nlanguage model (LLM) capabilities. However, benchmarks are not keeping pace in\ndifficulty: LLMs now achieve over 90\\% accuracy on popular benchmarks like\nMMLU, limiting informed measurement of state-of-the-art LLM capabilities. In\nresponse, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at\nthe frontier of human knowledge, designed to be the final closed-ended academic\nbenchmark of its kind with broad subject coverage. HLE consists of 2,500\nquestions across dozens of subjects, including mathematics, humanities, and the\nnatural sciences. HLE is developed globally by subject-matter experts and\nconsists of multiple-choice and short-answer questions suitable for automated\ngrading. Each question has a known solution that is unambiguous and easily\nverifiable, but cannot be quickly answered via internet retrieval.\nState-of-the-art LLMs demonstrate low accuracy and calibration on HLE,\nhighlighting a significant gap between current LLM capabilities and the expert\nhuman frontier on closed-ended academic questions. To inform research and\npolicymaking upon a clear understanding of model capabilities, we publicly\nrelease HLE at https://lastexam.ai.",
      "tldr_zh": "该论文指出，现有的LLM基准测试（如MMLU）已无法有效评估模型能力，因为LLM在这些测试中达到90%以上的准确率。作者引入了Humanity's Last Exam (HLE)，一个多模态基准，包含2500个跨数学、人文和自然科学的封闭式问题，由全球专家开发，确保答案不易通过互联网检索且便于自动评分。实验结果显示，当前最先进的LLM在HLE上准确率和校准度均较低，突显了模型与人类专家知识水平的显著差距。为推动研究和政策制定，论文公开发布了HLE，网址为https://lastexam.ai。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14249v7",
      "published_date": "2025-01-24 05:27:46 UTC",
      "updated_date": "2025-04-19 21:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:06:51.580991"
    },
    {
      "arxiv_id": "2501.14238v2",
      "title": "Point-LN: A Lightweight Framework for Efficient Point Cloud Classification Using Non-Parametric Positional Encoding",
      "title_zh": "Point-LN：一种轻量级框架，用于高效点云分类，使用非参数位置编码",
      "authors": [
        "Marzieh Mohammadi",
        "Amir Salarpour",
        "Pedram MohajerAnsari"
      ],
      "abstract": "We introduce Point-LN, a novel lightweight framework engineered for efficient\n3D point cloud classification. Point-LN integrates essential non-parametric\ncomponents-such as Farthest Point Sampling (FPS), k-Nearest Neighbors (k-NN),\nand non-learnable positional encoding-with a streamlined learnable classifier\nthat significantly enhances classification accuracy while maintaining a minimal\nparameter footprint. This hybrid architecture ensures low computational costs\nand rapid inference speeds, making Point-LN ideal for real-time and\nresource-constrained applications. Comprehensive evaluations on benchmark\ndatasets, including ModelNet40 and ScanObjectNN, demonstrate that Point-LN\nachieves competitive performance compared to state-of-the-art methods, all\nwhile offering exceptional efficiency. These results establish Point-LN as a\nrobust and scalable solution for diverse point cloud classification tasks,\nhighlighting its potential for widespread adoption in various computer vision\napplications.",
      "tldr_zh": "我们引入了 Point-LN，一种轻量级框架，旨在通过非参数组件如 Farthest Point Sampling (FPS)、k-Nearest Neighbors (k-NN) 和非可学习的 positional encoding，与一个精简的可学习分类器相结合，实现高效的 3D 点云分类。Point-LN 的混合架构确保了低计算成本和快速推理速度，特别适合实时和资源受限应用。在 ModelNet40 和 ScanObjectNN 等基准数据集上的全面评估表明，Point-LN 性能与最先进方法相当，同时提供卓越的效率，确立了其作为稳健、可扩展点云分类解决方案的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted for presentation at the 29th\n  International Computer Conference, Computer Society of Iran (CSICC) 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14238v2",
      "published_date": "2025-01-24 04:50:16 UTC",
      "updated_date": "2025-02-01 18:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:07:02.997121"
    },
    {
      "arxiv_id": "2501.14228v1",
      "title": "Detection and Classification of Acute Lymphoblastic Leukemia Utilizing Deep Transfer Learning",
      "title_zh": "利用深度迁移学习的急性淋巴细胞白血病检测与分类",
      "authors": [
        "Md. Abu Ahnaf Mollick",
        "Md. Mahfujur Rahman",
        "D. M. Asadujjaman",
        "Abdullah Tamim",
        "Nosin Anjum Dristi",
        "Md. Takbir Hossen"
      ],
      "abstract": "A mutation in the DNA of a single cell that compromises its function\ninitiates leukemia,leading to the overproduction of immature white blood cells\nthat encroach upon the space required for the generation of healthy blood\ncells.Leukemia is treatable if identified in its initial stages. However,its\ndiagnosis is both arduous and time consuming. This study proposes a novel\napproach for diagnosing leukemia across four stages Benign,Early,Pre,and Pro\nusing deep learning techniques.We employed two Convolutional Neural Network\n(CNN) models as MobileNetV2 with an altered head and a custom model. The custom\nmodel consists of multiple convolutional layers,each paired with corresponding\nmax pooling layers.We utilized MobileNetV2 with ImageNet weights,adjusting the\nhead to integrate the final results.The dataset used is the publicly available\n\"Acute Lymphoblastic Leukemia (ALL) Image Dataset\", and we applied the\nSynthetic Minority Oversampling Technique (SMOTE) to augment and balance the\ntraining dataset.The custom model achieved an accuracy of 98.6%, while\nMobileNetV2 attained a superior accuracy of 99.69%. The pretrained model showed\npromising results,indicating an increased likelihood of real-world application.",
      "tldr_zh": "本研究针对急性淋巴细胞白血病（Acute Lymphoblastic Leukemia）的检测和分类，利用Deep Transfer Learning提出了一种新方法，以诊断其四个阶段（Benign, Early, Pre, and Pro）。该方法采用了两个Convolutional Neural Network (CNN) 模型：MobileNetV2（使用ImageNet预训练权重并修改头部分）和一个自定义模型，后者包括多层卷积层与最大池化层；同时应用Synthetic Minority Oversampling Technique (SMOTE) 对Acute Lymphoblastic Leukemia (ALL) Image Dataset进行数据增强和平衡。实验结果显示，自定义模型达到98.6%的准确率，而MobileNetV2实现了更高的99.69%准确率。该方法展示了在实际应用中的潜力，为白血病的早期诊断提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 4 figures, Submitted to UCICS",
      "pdf_url": "http://arxiv.org/pdf/2501.14228v1",
      "published_date": "2025-01-24 04:16:03 UTC",
      "updated_date": "2025-01-24 04:16:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:07:15.472049"
    },
    {
      "arxiv_id": "2501.16377v1",
      "title": "Optimal Signal Decomposition-based Multi-Stage Learning for Battery Health Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Vijay Babu Pamshetti",
        "Wei Zhang",
        "King Jet Tseng",
        "Bor Kiat Ng",
        "Qingyu Yan"
      ],
      "abstract": "Battery health estimation is fundamental to ensure battery safety and reduce\ncost. However, achieving accurate estimation has been challenging due to the\nbatteries' complex nonlinear aging patterns and capacity regeneration\nphenomena. In this paper, we propose OSL, an optimal signal decomposition-based\nmulti-stage machine learning for battery health estimation. OSL treats battery\nsignals optimally. It uses optimized variational mode decomposition to extract\ndecomposed signals capturing different frequency bands of the original battery\nsignals. It also incorporates a multi-stage learning process to analyze both\nspatial and temporal battery features effectively. An experimental study is\nconducted with a public battery aging dataset. OSL demonstrates exceptional\nperformance with a mean error of just 0.26%. It significantly outperforms\ncomparison algorithms, both those without and those with suboptimal signal\ndecomposition and analysis. OSL considers practical battery challenges and can\nbe integrated into real-world battery management systems, offering a good\nimpact on battery monitoring and optimization.",
      "tldr_zh": "本论文针对电池复杂非线性老化模式和容量再生现象，提出OSL（Optimal Signal Decomposition-based Multi-Stage Learning）方法，用于精确的电池健康估计。OSL采用optimized variational mode decomposition对电池信号进行最优分解，以提取不同频带的信号，并结合multi-stage learning过程有效分析空间和时间特征。实验在公共电池老化数据集上显示，OSL的平均误差仅为0.26%，显著优于其他算法，并可集成到实际电池管理系统中，提升电池监控和优化效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.16377v1",
      "published_date": "2025-01-24 04:13:55 UTC",
      "updated_date": "2025-01-24 04:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:07:26.405960"
    },
    {
      "arxiv_id": "2501.14225v2",
      "title": "Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game",
      "title_zh": "翻译失败",
      "authors": [
        "Rong Ye",
        "Yongxin Zhang",
        "Yikai Zhang",
        "Haoyu Kuang",
        "Zhongyu Wei",
        "Peng Sun"
      ],
      "abstract": "Achieving Artificial General Intelligence (AGI) requires AI agents that can\nnot only make stratigic decisions but also engage in flexible and meaningful\ncommunication. Inspired by Wittgenstein's language game theory in Philosophical\nInvestigations, we propose that language agents can learn through in-context\ninteraction rather than traditional multi-stage frameworks that separate\ndecision-making from language expression. Using Werewolf, a social deduction\ngame that tests language understanding, strategic interaction, and\nadaptability, we develop the Multi-agent Kahneman & Tversky's Optimization\n(MaKTO). MaKTO engages diverse models in extensive gameplay to generate\nunpaired desirable and unacceptable responses, then employs KTO to refine the\nmodel's decision-making process. In 9-player Werewolf games, MaKTO achieves a\n61% average win rate across various models, outperforming GPT-4o and two-stage\nRL agents by relative improvements of 23.0% and 10.9%, respectively. Notably,\nMaKTO also demonstrates human-like performance, winning 60% against expert\nplayers and showing only 49% detectability in Turing-style blind tests.",
      "tldr_zh": "该论文提出 Multi-agent KTO (MaKTO)，一种基于 Wittgenstein 语言游戏理论的方法，让大型语言模型通过 in-context 互动学习强化战略决策和沟通，而非传统的多阶段框架。MaKTO 在 Werewolf 游戏中训练多智能体生成 desirable 和 unacceptable 响应，并使用 KTO 优化模型的决策过程，以提升语言理解、战略互动和适应性。实验结果显示，MaKTO 在 9 人 Werewolf 游戏中平均胜率达 61%，较 GPT-4o 和两阶段 RL agents 分别提升 23.0% 和 10.9%，并在对专家玩家的测试中胜率达 60%，Turing-style blind tests 中的检测率仅 49%，展现出接近人类水平的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Code and data will be available at\n  https://reneeye.github.io/MaKTO.html",
      "pdf_url": "http://arxiv.org/pdf/2501.14225v2",
      "published_date": "2025-01-24 04:09:03 UTC",
      "updated_date": "2025-03-13 03:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:07:40.989129"
    },
    {
      "arxiv_id": "2501.14224v1",
      "title": "Top Ten Challenges Towards Agentic Neural Graph Databases",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Bai",
        "Zihao Wang",
        "Yukun Zhou",
        "Hang Yin",
        "Weizhi Fei",
        "Qi Hu",
        "Zheye Deng",
        "Jiayang Cheng",
        "Tianshi Zheng",
        "Hong Ting Tsang",
        "Yisen Gao",
        "Zhongwei Xie",
        "Yufei Li",
        "Lixin Fan",
        "Binhang Yuan",
        "Wei Wang",
        "Lei Chen",
        "Xiaofang Zhou",
        "Yangqiu Song"
      ],
      "abstract": "Graph databases (GDBs) like Neo4j and TigerGraph excel at handling\ninterconnected data but lack advanced inference capabilities. Neural Graph\nDatabases (NGDBs) address this by integrating Graph Neural Networks (GNNs) for\npredictive analysis and reasoning over incomplete or noisy data. However, NGDBs\nrely on predefined queries and lack autonomy and adaptability. This paper\nintroduces Agentic Neural Graph Databases (Agentic NGDBs), which extend NGDBs\nwith three core functionalities: autonomous query construction, neural query\nexecution, and continuous learning. We identify ten key challenges in realizing\nAgentic NGDBs: semantic unit representation, abductive reasoning, scalable\nquery execution, and integration with foundation models like large language\nmodels (LLMs). By addressing these challenges, Agentic NGDBs can enable\nintelligent, self-improving systems for modern data-driven applications, paving\nthe way for adaptable and autonomous data management solutions.",
      "tldr_zh": "该论文讨论了图数据库（Graph Databases, GDBs）如 Neo4j 和 TigerGraph 的局限性，以及 Neural Graph Databases (NGDBs) 通过整合 Graph Neural Networks (GNNs) 来提升预测分析和推理能力的改进，但 NGDBs 仍依赖预定义查询，缺乏自主性和适应性。论文引入 Agentic Neural Graph Databases (Agentic NGDBs)，扩展了 NGDBs 的三个核心功能：自主查询构建、神经查询执行和持续学习，以实现更智能的数据管理。作者识别了十个关键挑战，包括 semantic unit representation、abductive reasoning、scalable query execution 和与 foundation models 如 large language models (LLMs) 的整合，这些挑战的解决将推动自适应、自治的数据驱动应用的发展。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "12 Pages",
      "pdf_url": "http://arxiv.org/pdf/2501.14224v1",
      "published_date": "2025-01-24 04:06:50 UTC",
      "updated_date": "2025-01-24 04:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:07:51.314285"
    },
    {
      "arxiv_id": "2501.14216v3",
      "title": "TFG-Flow: Training-free Guidance in Multimodal Generative Flow",
      "title_zh": "TFG-Flow：多模态生成流中的",
      "authors": [
        "Haowei Lin",
        "Shanda Li",
        "Haotian Ye",
        "Yiming Yang",
        "Stefano Ermon",
        "Yitao Liang",
        "Jianzhu Ma"
      ],
      "abstract": "Given an unconditional generative model and a predictor for a target property\n(e.g., a classifier), the goal of training-free guidance is to generate samples\nwith desirable target properties without additional training. As a highly\nefficient technique for steering generative models toward flexible outcomes,\ntraining-free guidance has gained increasing attention in diffusion models.\nHowever, existing methods only handle data in continuous spaces, while many\nscientific applications involve both continuous and discrete data (referred to\nas multimodality). Another emerging trend is the growing use of the simple and\ngeneral flow matching framework in building generative foundation models, where\nguided generation remains under-explored. To address this, we introduce\nTFG-Flow, a novel training-free guidance method for multimodal generative flow.\nTFG-Flow addresses the curse-of-dimensionality while maintaining the property\nof unbiased sampling in guiding discrete variables. We validate TFG-Flow on\nfour molecular design tasks and show that TFG-Flow has great potential in drug\ndesign by generating molecules with desired properties.",
      "tldr_zh": "这篇论文提出了 TFG-Flow，一种无需额外训练的指导方法，用于多模态生成流模型，能够处理连续和离散数据，从而解决现有方法在科学应用中的局限性。TFG-Flow 通过克服 curse-of-dimensionality 并保持离散变量的无偏 sampling，实现高效的引导生成。实验在四个分子设计任务上验证了其有效性，尤其在药物设计中展示了生成具有理想属性的分子的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14216v3",
      "published_date": "2025-01-24 03:44:16 UTC",
      "updated_date": "2025-03-18 07:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:08:03.896205"
    },
    {
      "arxiv_id": "2501.14210v1",
      "title": "PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location Prediction",
      "title_zh": "PuzzleGPT：",
      "authors": [
        "Hammad Ayyubi",
        "Xuande Feng",
        "Junzhang Liu",
        "Xudong Lin",
        "Zhecan Wang",
        "Shih-Fu Chang"
      ],
      "abstract": "The task of predicting time and location from images is challenging and\nrequires complex human-like puzzle-solving ability over different clues. In\nthis work, we formalize this ability into core skills and implement them using\ndifferent modules in an expert pipeline called PuzzleGPT. PuzzleGPT consists of\na perceiver to identify visual clues, a reasoner to deduce prediction\ncandidates, a combiner to combinatorially combine information from different\nclues, a web retriever to get external knowledge if the task can't be solved\nlocally, and a noise filter for robustness. This results in a zero-shot,\ninterpretable, and robust approach that records state-of-the-art performance on\ntwo datasets -- TARA and WikiTilo. PuzzleGPT outperforms large VLMs such as\nBLIP-2, InstructBLIP, LLaVA, and even GPT-4V, as well as automatically\ngenerated reasoning pipelines like VisProg, by at least 32% and 38%,\nrespectively. It even rivals or surpasses finetuned models.",
      "tldr_zh": "该论文提出PuzzleGPT框架，旨在模拟人类谜题解决能力，从图像中预测时间和位置。该框架将核心技能形式化为模块化专家管道，包括Perceiver识别视觉线索、Reasoner推断预测候选、Combiner组合线索信息、Web Retriever获取外部知识，以及Noise Filter提升鲁棒性，从而实现zero-shot、可解释的预测方法。在TARA和WikiTilo数据集上，PuzzleGPT超越大型VLMs如BLIP-2、InstructBLIP、LLaVA和GPT-4V至少32%，并优于自动生成推理管道VisProg至少38%，甚至与微调模型相当或更胜一筹。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2501.14210v1",
      "published_date": "2025-01-24 03:28:37 UTC",
      "updated_date": "2025-01-24 03:28:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:08:15.318735"
    },
    {
      "arxiv_id": "2501.14204v1",
      "title": "Dynamic Token Reduction during Generation for Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Liang",
        "Chaofeng Guan",
        "Jiaying Lu",
        "Huiyao Chen",
        "Huan Wang",
        "Haoji Hu"
      ],
      "abstract": "Vision-Language Models (VLMs) have achieved notable success in multimodal\ntasks but face practical limitations due to the quadratic complexity of decoder\nattention mechanisms and autoregressive generation. Existing methods like FASTV\nand VTW have achieved notable results in reducing redundant visual tokens, but\nthese approaches focus on pruning tokens in a single forward pass without\nsystematically analyzing the redundancy of visual tokens throughout the entire\ngeneration process. In this paper, we introduce a dynamic pruning strategy\ntailored for VLMs, namedDynamic Rate (DyRate), which progressively adjusts the\ncompression rate during generation. Our analysis of the distribution of\nattention reveals that the importance of visual tokens decreases throughout the\ngeneration process, inspiring us to adopt a more aggressive compression rate.\nBy integrating a lightweight predictor based on attention distribution, our\napproach enables flexible adjustment of pruning rates based on the attention\ndistribution. Our experimental results demonstrate that our method not only\nreduces computational demands but also maintains the quality of responses.",
      "tldr_zh": "本研究针对视觉语言模型(VLMs)在生成过程中的二次方复杂度问题，提出一种动态修剪策略Dynamic Rate (DyRate)，通过分析注意力分布逐步调整视觉标记的压缩率，以减少冗余。DyRate发现视觉标记的重要性在生成过程中递减，并整合基于注意力分布的轻量级预测器，实现灵活的修剪率调整。实验结果显示，该方法显著降低了计算需求，同时保持了响应质量，并优于现有方法如FASTV和VTW。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14204v1",
      "published_date": "2025-01-24 03:20:37 UTC",
      "updated_date": "2025-01-24 03:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:08:27.292890"
    },
    {
      "arxiv_id": "2501.14199v1",
      "title": "Coordinating Ride-Pooling with Public Transit using Reward-Guided Conservative Q-Learning: An Offline Training and Online Fine-Tuning Reinforcement Learning Framework",
      "title_zh": "使用奖励引导的保守 Q-Learning 协调拼车与公共交通：一个离线训练和在线微调的强化学习框架",
      "authors": [
        "Yulong Hu",
        "Tingting Dong",
        "Sen Li"
      ],
      "abstract": "This paper introduces a novel reinforcement learning (RL) framework, termed\nReward-Guided Conservative Q-learning (RG-CQL), to enhance coordination between\nride-pooling and public transit within a multimodal transportation network. We\nmodel each ride-pooling vehicle as an agent governed by a Markov Decision\nProcess (MDP) and propose an offline training and online fine-tuning RL\nframework to learn the optimal operational decisions of the multimodal\ntransportation systems, including rider-vehicle matching, selection of drop-off\nlocations for passengers, and vehicle routing decisions, with improved data\nefficiency. During the offline training phase, we develop a Conservative Double\nDeep Q Network (CDDQN) as the action executor and a supervised learning-based\nreward estimator, termed the Guider Network, to extract valuable insights into\naction-reward relationships from data batches. In the online fine-tuning phase,\nthe Guider Network serves as an exploration guide, aiding CDDQN in effectively\nand conservatively exploring unknown state-action pairs. The efficacy of our\nalgorithm is demonstrated through a realistic case study using real-world data\nfrom Manhattan. We show that integrating ride-pooling with public transit\noutperforms two benchmark cases solo rides coordinated with transit and\nride-pooling without transit coordination by 17% and 22% in the achieved system\nrewards, respectively. Furthermore, our innovative offline training and online\nfine-tuning framework offers a remarkable 81.3% improvement in data efficiency\ncompared to traditional online RL methods with adequate exploration budgets,\nwith a 4.3% increase in total rewards and a 5.6% reduction in overestimation\nerrors. Experimental results further demonstrate that RG-CQL effectively\naddresses the challenges of transitioning from offline to online RL in\nlarge-scale ride-pooling systems integrated with transit.",
      "tldr_zh": "这篇论文提出了一种名为 Reward-Guided Conservative Q-Learning (RG-CQL) 的强化学习框架，用于协调乘车拼车和公共交通在多模式交通网络中的运作，每个车辆被建模为 Markov Decision Process (MDP) 代理。框架包括离线训练阶段（使用 Conservative Double Deep Q Network (CDDQN) 作为动作执行器和 Guider Network 作为奖励估计器，以从数据中提取动作-奖励关系）和在线微调阶段（Guider Network 指导 CDDQN 进行保守探索）。实验在曼哈顿的真实数据案例中证明，RG-CQL 比基准方案（如单独乘车与公共交通协调或无协调的乘车拼车）提高了系统奖励17%和22%，并在数据效率上比传统在线强化学习方法提升81.3%，同时减少了过估计错误。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14199v1",
      "published_date": "2025-01-24 03:05:04 UTC",
      "updated_date": "2025-01-24 03:05:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:08:39.825698"
    },
    {
      "arxiv_id": "2501.14194v1",
      "title": "ENTER: Event Based Interpretable Reasoning for VideoQA",
      "title_zh": "ENTER：基于事件的视频问答可解释推理",
      "authors": [
        "Hammad Ayyubi",
        "Junzhang Liu",
        "Ali Asgarov",
        "Zaber Ibn Abdul Hakim",
        "Najibul Haque Sarker",
        "Zhecan Wang",
        "Chia-Wei Tang",
        "Hani Alomari",
        "Md. Atabuzzaman",
        "Xudong Lin",
        "Naveen Reddy Dyava",
        "Shih-Fu Chang",
        "Chris Thomas"
      ],
      "abstract": "In this paper, we present ENTER, an interpretable Video Question Answering\n(VideoQA) system based on event graphs. Event graphs convert videos into\ngraphical representations, where video events form the nodes and event-event\nrelationships (temporal/causal/hierarchical) form the edges. This structured\nrepresentation offers many benefits: 1) Interpretable VideoQA via generated\ncode that parses event-graph; 2) Incorporation of contextual visual information\nin the reasoning process (code generation) via event graphs; 3) Robust VideoQA\nvia Hierarchical Iterative Update of the event graphs. Existing interpretable\nVideoQA systems are often top-down, disregarding low-level visual information\nin the reasoning plan generation, and are brittle. While bottom-up approaches\nproduce responses from visual data, they lack interpretability. Experimental\nresults on NExT-QA, IntentQA, and EgoSchema demonstrate that not only does our\nmethod outperform existing top-down approaches while obtaining competitive\nperformance against bottom-up approaches, but more importantly, offers superior\ninterpretability and explainability in the reasoning process.",
      "tldr_zh": "本研究提出ENTER，一种基于事件图(Event graphs)的可解释VideoQA系统，将视频事件作为节点，事件间的时间、因果和层次关系作为边，从而实现结构化的视频问答。ENTER通过生成的代码解析事件图，融入上下文视觉信息并采用层次化迭代更新，提升了VideoQA的解释性和鲁棒性，与现有自上而下方法相比，它避免了忽略低级视觉信息的局限，同时在自下而上方法中提供了更好的可解释性。在NExT-QA、IntentQA和EgoSchema数据集上的实验表明，该方法优于自上而下方法，并在性能上与自下而上方法竞争，同时显著提升了推理过程的解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14194v1",
      "published_date": "2025-01-24 02:56:59 UTC",
      "updated_date": "2025-01-24 02:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:08:53.290821"
    },
    {
      "arxiv_id": "2504.03643v1",
      "title": "Potential Indicator for Continuous Emotion Arousal by Dynamic Neural Synchrony",
      "title_zh": "翻译失败",
      "authors": [
        "Guandong Pan",
        "Zhaobang Wu",
        "Yaqian Yang",
        "Xin Wang",
        "Longzhao Liu",
        "Zhiming Zheng",
        "Shaoting Tang"
      ],
      "abstract": "The need for automatic and high-quality emotion annotation is paramount in\napplications such as continuous emotion recognition and video highlight\ndetection, yet achieving this through manual human annotations is challenging.\nInspired by inter-subject correlation (ISC) utilized in neuroscience, this\nstudy introduces a novel Electroencephalography (EEG) based ISC methodology\nthat leverages a single-electrode and feature-based dynamic approach. Our\ncontributions are three folds. Firstly, we reidentify two potent emotion\nfeatures suitable for classifying emotions-first-order difference (FD) an\ndifferential entropy (DE). Secondly, through the use of overall correlation\nanalysis, we demonstrate the heterogeneous synchronized performance of\nelectrodes. This performance aligns with neural emotion patterns established in\nprior studies, thus validating the effectiveness of our approach. Thirdly, by\nemploying a sliding window correlation technique, we showcase the significant\nconsistency of dynamic ISCs across various features or key electrodes in each\nanalyzed film clip. Our findings indicate the method's reliability in capturing\nconsistent, dynamic shared neural synchrony among individuals, triggered by\nevocative film stimuli. This underscores the potential of our approach to serve\nas an indicator of continuous human emotion arousal. The implications of this\nresearch are significant for advancements in affective computing and the\nbroader neuroscience field, suggesting a streamlined and effective tool for\nemotion analysis in real-world applications.",
      "tldr_zh": "本研究针对情感标注的挑战，提出了一种基于 Electroencephalography (EEG) 的 inter-subject correlation (ISC) 方法，使用单电极和基于特征的动态方法来实现自动、高质量的连续情感识别。贡献包括重新识别 first-order difference (FD) 和 differential entropy (DE) 作为有效的情感分类特征，并通过整体相关性分析和滑动窗口相关性技术，验证了电极的异质同步性能及其在电影刺激下的动态一致性。结果表明，该方法能可靠捕获个体间的共享神经同步，作为连续情感唤起的潜在指标，为情感计算和神经科学领域提供高效工具。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03643v1",
      "published_date": "2025-01-24 02:54:28 UTC",
      "updated_date": "2025-01-24 02:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:09:02.907173"
    },
    {
      "arxiv_id": "2501.14189v1",
      "title": "Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Saaduddin Mahmud",
        "Dorian Benhamou Goldfajn",
        "Shlomo Zilberstein"
      ],
      "abstract": "Distributed Constraint Optimization Problems (DCOPs) offer a powerful\nframework for multi-agent coordination but often rely on labor-intensive,\nmanual problem construction. To address this, we introduce VL-DCOPs, a\nframework that takes advantage of large multimodal foundation models (LFMs) to\nautomatically generate constraints from both visual and linguistic\ninstructions. We then introduce a spectrum of agent archetypes for solving\nVL-DCOPs: from a neuro-symbolic agent that delegates some of the algorithmic\ndecisions to an LFM, to a fully neural agent that depends entirely on an LFM\nfor coordination. We evaluate these agent archetypes using state-of-the-art\nLLMs (large language models) and VLMs (vision language models) on three novel\nVL-DCOP tasks and compare their respective advantages and drawbacks. Lastly, we\ndiscuss how this work extends to broader frontier challenges in the DCOP\nliterature.",
      "tldr_zh": "这篇论文提出 VL-DCOPs 框架，利用大型多模态基础模型 (LFMs) 从视觉和语言指令自动生成约束，解决 Distributed Constraint Optimization Problems (DCOPs) 中依赖手动构建的劳动密集问题。框架引入了多种代理类型（agent archetypes），包括神经符号代理 (neuro-symbolic agent) 部分委托 LFM 进行算法决策，以及完全神经代理 (fully neural agent) 完全依赖 LFM 进行多代理协调。作者使用最先进的 LLMs (large language models) 和 VLMs (vision language models) 在三个新颖的 VL-DCOP 任务上评估这些代理类型，并比较了它们的优势（如自动化程度）和缺点（如潜在的可靠性问题）。最后，该工作讨论了其对 DCOP 文献中更广泛前沿挑战的扩展潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14189v1",
      "published_date": "2025-01-24 02:50:21 UTC",
      "updated_date": "2025-01-24 02:50:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:09:15.897795"
    },
    {
      "arxiv_id": "2501.16376v2",
      "title": "SwiftPrune: Hessian-Free Weight Pruning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Kang",
        "Yang Shi",
        "Mei We",
        "Jun He",
        "Jianchao Yang",
        "Zeyu Xue",
        "Jing Feng",
        "Xinwang Liu"
      ],
      "abstract": "Post-training pruning, as one of the key techniques for compressing large\nlanguage models, plays a vital role in lightweight model deployment and model\nsparsity. However, current mainstream pruning methods dependent on the Hessian\nmatrix face significant limitations in both pruning speed and practical\neffectiveness due to the computationally intensive nature of second-order\nderivative calculations. This paper presents SwiftPrune, a novel Hessian-free\nweight pruning method that achieves hardware-efficient model compression\nthrough two key innovations: 1) SwiftPrune eliminates the need for\ncomputationally intensive Hessian matrix calculations by introducing a\ncontribution-based weight metric, which evaluates the importance of weights\nwithout relying on second-order derivatives. 2) we employ the Exponentially\nWeighted Moving Average (EWMA) technique to bypass weight sorting, enabling the\nselection of weights that contribute most to LLM accuracy and further reducing\ntime complexity. Our approach is extended to support structured sparsity\npruning, facilitating efficient execution on modern hardware accelerators. We\nvalidate the SwiftPrune on three LLMs (namely LLaMA2, LLaMA3, and Pythia),\ndemonstrating that it significantly enhances compression performance. The\nexperimental findings reveal that SwiftPrune completes the pruning process\nwithin seconds, achieving an average speedup of 12.29x (up to 56.02x) over\nexisting SOTA approaches.",
      "tldr_zh": "SwiftPrune 提出了一种无 Hessian 矩阵的权重修剪方法，用于压缩大型语言模型（Large Language Models），旨在解决传统方法计算密集导致的速度和效率问题。该方法通过引入基于贡献的权重指标来评估权重重要性，并采用指数加权移动平均（Exponentially Weighted Moving Average, EWMA）技术跳过权重排序，从而减少时间复杂度并支持结构化稀疏修剪。在 LLaMA2、LLaMA3 和 Pythia 等模型上的实验验证显示，SwiftPrune 显著提升压缩性能，可在几秒内完成修剪过程，比现有最先进方法平均加速 12.29 倍（最高 56.02 倍）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16376v2",
      "published_date": "2025-01-24 02:50:13 UTC",
      "updated_date": "2025-05-19 00:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:09:27.737773"
    },
    {
      "arxiv_id": "2501.14183v2",
      "title": "VarDrop: Enhancing Training Efficiency by Reducing Variate Redundancy in Periodic Time Series Forecasting",
      "title_zh": "VarDrop：通过减少变量冗余提升周期性",
      "authors": [
        "Junhyeok Kang",
        "Yooju Shin",
        "Jae-Gil Lee"
      ],
      "abstract": "Variate tokenization, which independently embeds each variate as separate\ntokens, has achieved remarkable improvements in multivariate time series\nforecasting. However, employing self-attention with variate tokens incurs a\nquadratic computational cost with respect to the number of variates, thus\nlimiting its training efficiency for large-scale applications. To address this\nissue, we propose VarDrop, a simple yet efficient strategy that reduces the\ntoken usage by omitting redundant variate tokens during training. VarDrop\nadaptively excludes redundant tokens within a given batch, thereby reducing the\nnumber of tokens used for dot-product attention while preserving essential\ninformation. Specifically, we introduce k-dominant frequency hashing (k-DFH),\nwhich utilizes the ranked dominant frequencies in the frequency domain as a\nhash value to efficiently group variate tokens exhibiting similar periodic\nbehaviors. Then, only representative tokens in each group are sampled through\nstratified sampling. By performing sparse attention with these selected tokens,\nthe computational cost of scaled dot-product attention is significantly\nalleviated. Experiments conducted on public benchmark datasets demonstrate that\nVarDrop outperforms existing efficient baselines.",
      "tldr_zh": "该论文提出VarDrop策略，以解决多变量时间序列预测中variate tokenization导致的自注意力机制计算成本过高问题，通过省略冗余variate tokens来提升训练效率。VarDrop引入k-dominant frequency hashing (k-DFH)方法，利用频率域的dominant frequencies对tokens进行分组，并通过分层采样选择代表性tokens进行稀疏注意力，从而保留关键信息同时降低计算开销。在公共基准数据集上的实验显示，VarDrop在性能上优于现有高效基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14183v2",
      "published_date": "2025-01-24 02:22:59 UTC",
      "updated_date": "2025-02-03 05:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:09:39.265401"
    },
    {
      "arxiv_id": "2501.14176v1",
      "title": "RL + Transformer = A General-Purpose Problem Solver",
      "title_zh": "翻译失败",
      "authors": [
        "Micah Rentschler",
        "Jesse Roberts"
      ],
      "abstract": "What if artificial intelligence could not only solve problems for which it\nwas trained but also learn to teach itself to solve new problems (i.e.,\nmeta-learn)? In this study, we demonstrate that a pre-trained transformer\nfine-tuned with reinforcement learning over multiple episodes develops the\nability to solve problems that it has never encountered before - an emergent\nability called In-Context Reinforcement Learning (ICRL). This powerful\nmeta-learner not only excels in solving unseen in-distribution environments\nwith remarkable sample efficiency, but also shows strong performance in\nout-of-distribution environments. In addition, we show that it exhibits\nrobustness to the quality of its training data, seamlessly stitches together\nbehaviors from its context, and adapts to non-stationary environments. These\nbehaviors demonstrate that an RL-trained transformer can iteratively improve\nupon its own solutions, making it an excellent general-purpose problem solver.",
      "tldr_zh": "本研究探索了将预训练 Transformer 与强化学习（RL）结合的框架，使其不仅能解决训练问题，还能通过 In-Context Reinforcement Learning (ICRL) 自我学习解决未见过的新问题。ICRL 展示了高样本效率，在分布内和分布外环境上表现出色，并对训练数据质量具有鲁棒性，能够整合上下文行为并适应非平稳环境。实验结果表明，这种 RL-trained Transformer 可以迭代改进解决方案，从而成为一个优秀的通用问题求解器。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14176v1",
      "published_date": "2025-01-24 01:55:20 UTC",
      "updated_date": "2025-01-24 01:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:09:50.855013"
    },
    {
      "arxiv_id": "2501.14174v5",
      "title": "Dreamweaver: Learning Compositional World Models from Pixels",
      "title_zh": "Dreamweaver：从像素学习组合式世界模型",
      "authors": [
        "Junyeob Baek",
        "Yi-Fu Wu",
        "Gautam Singh",
        "Sungjin Ahn"
      ],
      "abstract": "Humans have an innate ability to decompose their perceptions of the world\ninto objects and their attributes, such as colors, shapes, and movement\npatterns. This cognitive process enables us to imagine novel futures by\nrecombining familiar concepts. However, replicating this ability in artificial\nintelligence systems has proven challenging, particularly when it comes to\nmodeling videos into compositional concepts and generating unseen, recomposed\nfutures without relying on auxiliary data, such as text, masks, or bounding\nboxes. In this paper, we propose Dreamweaver, a neural architecture designed to\ndiscover hierarchical and compositional representations from raw videos and\ngenerate compositional future simulations. Our approach leverages a novel\nRecurrent Block-Slot Unit (RBSU) to decompose videos into their constituent\nobjects and attributes. In addition, Dreamweaver uses a multi-future-frame\nprediction objective to capture disentangled representations for dynamic\nconcepts more effectively as well as static concepts. In experiments, we\ndemonstrate our model outperforms current state-of-the-art baselines for world\nmodeling when evaluated under the DCI framework across multiple datasets.\nFurthermore, we show how the modularized concept representations of our model\nenable compositional imagination, allowing the generation of novel videos by\nrecombining attributes from previously seen objects.\ncun-bjy.github.io/dreamweaver-website",
      "tldr_zh": "该论文提出Dreamweaver，一种从像素视频中学习组合世界模型（Compositional World Models）的神经架构，旨在模拟人类将感知分解为对象和属性（如颜色、形状、运动模式）并生成新颖重组视频的能力，而无需依赖辅助数据如文本或边界框。核心方法包括Recurrent Block-Slot Unit (RBSU)，用于将视频分解为层次化对象和属性，以及多未来帧预测（multi-future-frame prediction）目标，以捕获动态和静态概念的分离表示。实验结果显示，Dreamweaver在DCI框架下超越现有基线模型，在多个数据集上表现出色，并通过模块化概念表示实现组合想象，生成之前未见过的视频。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14174v5",
      "published_date": "2025-01-24 01:50:19 UTC",
      "updated_date": "2025-04-10 13:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:10:04.074064"
    },
    {
      "arxiv_id": "2501.14172v2",
      "title": "UltraLightSqueezeNet: A Deep Learning Architecture for Malaria Classification with up to 54x fewer trainable parameters for resource constrained devices",
      "title_zh": "翻译失败",
      "authors": [
        "Suresh Babu Nettur",
        "Shanthi Karpurapu",
        "Unnati Nettur",
        "Likhit Sagar Gajja",
        "Sravanthy Myneni",
        "Akhil Dusi",
        "Lalithya Posham"
      ],
      "abstract": "Lightweight deep learning approaches for malaria detection have gained\nattention for their potential to enhance diagnostics in resource constrained\nenvironments. For our study, we selected SqueezeNet1.1 as it is one of the most\npopular lightweight architectures. SqueezeNet1.1 is a later version of\nSqueezeNet1.0 and is 2.4 times more computationally efficient than the original\nmodel. We proposed and implemented three ultra-lightweight architecture\nvariants to SqueezeNet1.1 architecture, namely Variant 1 (one fire module),\nVariant 2 (two fire modules), and Variant 3 (four fire modules), which are even\nmore compact than SqueezeNetV1.1 (eight fire modules). These models were\nimplemented to evaluate the best performing variant that achieves superior\ncomputational efficiency without sacrificing accuracy in malaria blood cell\nclassification. The models were trained and evaluated using the NIH Malaria\ndataset. We assessed each model's performance based on metrics including\naccuracy, recall, precision, F1-score, and Area Under the Curve (AUC). The\nresults show that the SqueezeNet1.1 model achieves the highest performance\nacross all metrics, with a classification accuracy of 97.12%. Variant 3 (four\nfire modules) offers a competitive alternative, delivering almost identical\nresults (accuracy 96.55%) with a 6x reduction in computational overhead\ncompared to SqueezeNet1.1. Variant 2 and Variant 1 perform slightly lower than\nVariant 3, with Variant 2 (two fire modules) reducing computational overhead by\n28x, and Variant 1 (one fire module) achieving a 54x reduction in trainable\nparameters compared to SqueezeNet1.1. These findings demonstrate that our\nSqueezeNet1.1 architecture variants provide a flexible approach to malaria\ndetection, enabling the selection of a variant that balances resource\nconstraints and performance.",
      "tldr_zh": "本研究提出 UltraLightSqueezeNet 的三个变体，基于 SqueezeNet1.1 架构，通过减少 fire modules（分别为一个、两个和四个）来大幅降低可训练参数数量，从而适配资源受限设备的疟疾血细胞分类任务。实验使用 NIH Malaria 数据集评估模型性能，指标包括准确率、召回率、精确率、F1-score 和 AUC，结果显示 SqueezeNet1.1 达到 97.12% 的最高准确率，而 Variant 3 以 96.55% 的准确率实现了 6 倍计算开销减少。总体而言，这些变体提供灵活选择，帮助平衡计算效率和分类性能，为疟疾检测在资源有限环境中的应用奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Corresponding authors: Shanthi Karpurapu\n  (shanthi.karpurapu@gmail.com), Suresh Babu Nettur (nettursuresh@gmail.com)\n  Shanthi Karpurapu and Suresh Babu Nettur are co-first authors",
      "pdf_url": "http://arxiv.org/pdf/2501.14172v2",
      "published_date": "2025-01-24 01:44:48 UTC",
      "updated_date": "2025-01-31 21:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:10:16.571960"
    },
    {
      "arxiv_id": "2501.14166v1",
      "title": "Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Cong-Duy Nguyen",
        "Xiaobao Wu",
        "Thong Nguyen",
        "Shuai Zhao",
        "Khoi Le",
        "Viet-Anh Nguyen",
        "Feng Yichao",
        "Anh Tuan Luu"
      ],
      "abstract": "Previous research on multimodal entity linking (MEL) has primarily employed\ncontrastive learning as the primary objective. However, using the rest of the\nbatch as negative samples without careful consideration, these studies risk\nleveraging easy features and potentially overlook essential details that make\nentities unique. In this work, we propose JD-CCL (Jaccard Distance-based\nConditional Contrastive Learning), a novel approach designed to enhance the\nability to match multimodal entity linking models. JD-CCL leverages\nmeta-information to select negative samples with similar attributes, making the\nlinking task more challenging and robust. Additionally, to address the\nlimitations caused by the variations within the visual modality among mentions\nand entities, we introduce a novel method, CVaCPT (Contextual Visual-aid\nControllable Patch Transform). It enhances visual representations by\nincorporating multi-view synthetic images and contextual textual\nrepresentations to scale and shift patch representations. Experimental results\non benchmark MEL datasets demonstrate the strong effectiveness of our approach.",
      "tldr_zh": "本研究针对多模态实体链接 (MEL) 的对比学习方法存在的问题，即使用批次中的其他样本作为负样本可能忽略实体独特性，提出了一种新型方法 JD-CCL (Jaccard Distance-based Conditional Contrastive Learning)。JD-CCL 通过利用元信息选择具有类似属性的负样本，使链接任务更具挑战性和鲁棒性，以提升模型的匹配能力。同时，引入 CVaCPT (Contextual Visual-aid Controllable Patch Transform) 来处理视觉模态的变异问题，该方法通过整合多视图合成图像和上下文文本表示来增强视觉表示。实验结果在基准 MEL 数据集上展示了该方法的显著有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14166v1",
      "published_date": "2025-01-24 01:35:10 UTC",
      "updated_date": "2025-01-24 01:35:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:10:27.749950"
    },
    {
      "arxiv_id": "2501.14165v1",
      "title": "LoCoML: A Framework for Real-World ML Inference Pipelines",
      "title_zh": "翻译失败",
      "authors": [
        "Kritin Maddireddy",
        "Santhosh Kotekal Methukula",
        "Chandrasekar Sridhar",
        "Karthik Vaidhyanathan"
      ],
      "abstract": "The widespread adoption of machine learning (ML) has brought forth diverse\nmodels with varying architectures, and data requirements, introducing new\nchallenges in integrating these systems into real-world applications.\nTraditional solutions often struggle to manage the complexities of connecting\nheterogeneous models, especially when dealing with varied technical\nspecifications. These limitations are amplified in large-scale, collaborative\nprojects where stakeholders contribute models with different technical\nspecifications. To address these challenges, we developed LoCoML, a low-code\nframework designed to simplify the integration of diverse ML models within the\ncontext of the \\textit{Bhashini Project} - a large-scale initiative aimed at\nintegrating AI-driven language technologies such as automatic speech\nrecognition, machine translation, text-to-speech, and optical character\nrecognition to support seamless communication across more than 20 languages.\nInitial evaluations show that LoCoML adds only a small amount of computational\nload, making it efficient and effective for large-scale ML integration. Our\npractical insights show that a low-code approach can be a practical solution\nfor connecting multiple ML models in a collaborative environment.",
      "tldr_zh": "该研究介绍了LoCoML，一种低代码框架，旨在简化真实世界机器学习(ML)推理管道中异构模型的整合，解决传统方法在处理不同架构和数据需求时的复杂性问题。LoCoML特别适用于大规模协作项目，如Bhashini Project，该项目整合AI驱动的语言技术（如自动语音识别、机器翻译、文本到语音和光学字符识别），支持20多种语言的无缝通信。初步评估显示，LoCoML仅增加了少量计算负载，同时证明低代码方法是连接多个ML模型的实用解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "The paper has been accepted for presentation at the 4th International\n  Conference on AI Engineering (CAIN) 2025 co-located with 47th IEEE/ACM\n  International Conference on Software Engineering (ICSE) 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14165v1",
      "published_date": "2025-01-24 01:35:08 UTC",
      "updated_date": "2025-01-24 01:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:10:38.989796"
    },
    {
      "arxiv_id": "2501.14158v2",
      "title": "Advancing MRI Reconstruction: A Systematic Review of Deep Learning and Compressed Sensing Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Mojtaba Safari",
        "Zach Eidex",
        "Chih-Wei Chang",
        "Richard L. J. Qiu",
        "Xiaofeng Yang"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a non-invasive imaging modality and\nprovides comprehensive anatomical and functional insights into the human body.\nHowever, its long acquisition times can lead to patient discomfort, motion\nartifacts, and limiting real-time applications. To address these challenges,\nstrategies such as parallel imaging have been applied, which utilize multiple\nreceiver coils to speed up the data acquisition process. Additionally,\ncompressed sensing (CS) is a method that facilitates image reconstruction from\nsparse data, significantly reducing image acquisition time by minimizing the\namount of data collection needed. Recently, deep learning (DL) has emerged as a\npowerful tool for improving MRI reconstruction. It has been integrated with\nparallel imaging and CS principles to achieve faster and more accurate MRI\nreconstructions. This review comprehensively examines DL-based techniques for\nMRI reconstruction. We categorize and discuss various DL-based methods,\nincluding end-to-end approaches, unrolled optimization, and federated learning,\nhighlighting their potential benefits. Our systematic review highlights\nsignificant contributions and underscores the potential of DL in MRI\nreconstruction. Additionally, we summarize key results and trends in DL-based\nMRI reconstruction, including quantitative metrics, the dataset, acceleration\nfactors, and the progress of and research interest in DL techniques over time.\nFinally, we discuss potential future directions and the importance of DL-based\nMRI reconstruction in advancing medical imaging. To facilitate further research\nin this area, we provide a GitHub repository that includes up-to-date DL-based\nMRI reconstruction publications and public\ndatasets-https://github.com/mosaf/Awesome-DL-based-CS-MRI.",
      "tldr_zh": "这篇系统综述探讨了深度学习(DL)和压缩感知(CS)在磁共振成像(MRI)重建中的整合，以解决MRI采集时间长导致的患者不适和图像伪影等问题。论文对DL-based方法进行了分类讨论，包括端到端方法、展开优化和联邦学习，并总结了关键结果如定量指标、数据集和加速因子，以及DL技术的发展趋势。最终，该综述强调了DL在推进医疗成像中的潜力，并提供了未来研究方向及一个GitHub仓库（https://github.com/mosaf/Awesome-DL-based-CS-MRI）以支持相关资源共享。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2405.00241",
      "pdf_url": "http://arxiv.org/pdf/2501.14158v2",
      "published_date": "2025-01-24 01:07:58 UTC",
      "updated_date": "2025-02-01 14:38:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:10:51.576973"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 108,
  "processed_papers_count": 108,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T03:11:12.313573"
}