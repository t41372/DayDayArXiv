{
  "date": "2024-06-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-03 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了大量 AI 相关论文，焦点在于强化学习、LLM 优化与应用、图神经网络以及跨领域融合（如医疗和图像处理），其中令人印象深刻的是 Caroline Uhler 的因果发现方法和 Xin Yao 的进化计算应用，它们展示了高效的理论框架和实际潜力。\n\n### 重点论文讨论\n今天的核心论文多聚焦 AI 和机器学习领域，我挑选了最具话题度和影响力的几篇进行详细解读，先从热门主题入手，再快速掠过其他。以下按主题分组，相关论文放在一起聊。\n\n#### LLM 和生成模型优化\n- **Skywork-MoE：混合专家语言模型的训练技术（Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models）**  \n  这篇论文由 Yahui Zhou 等作者提出，探讨了混合专家（MoE）模型的训练策略，包括门控逻辑归一化和自适应辅助损失系数。贡献在于提升了 MoE 模型的性能和效率，在压缩数据集上训练后，模型在各种基准上表现出色，显著降低了计算开销。\n\n- **SemCoder：基于全面语义推理的代码语言模型训练（SemCoder: Training Code Language Models with Comprehensive Semantics Reasoning）**  \n  Yangruibo Ding 等研究了代码 LLM 的语义理解，提出通过单向推理（monologue reasoning）增强模型对代码动态状态的捕捉。发现在于它能生成更准确的代码，并应用于调试和修复，实验在代码生成任务上超越了 GPT-3.5。\n\n这些论文突出了 LLM 的高效训练和应用潜力，相关工作如 \"Dragonfly\"（多分辨率图像生成）也展示了 LLM 在视觉任务中的扩展，但后者更侧重多模态融合，我这里快速掠过。\n\n#### 强化学习和决策优化\n- **多代理强化学习在放射治疗中的应用（Multi-Agent Reinforcement Learning Meets Leaf Sequencing in Radiotherapy）**  \n  Riqiang Gao 等作者将多代理强化学习应用于放射治疗叶片序列优化，提出 Reinforced Leaf Sequencer (RLS) 模型。关键发现是它减少了荧光重建错误并加速收敛，实验在真实数据集上优于传统优化方法。\n\n- **基于函数空间的目标网络学习（Learning the Target Network in Function Space）**  \n  Kavosh Asadi 等设计了 Lookahead-Replicate (LR) 算法，用于强化学习的价值函数逼近。贡献在于它在函数空间保持等价性，提高了 Atari 基准的性能，相比传统方法更鲁棒。\n\n- **图状态空间模型（GraphSSM: State Space Models on Temporal Graphs）**  \n  Jintang Li 等扩展了状态空间模型到时序图，引入拉普拉斯正则化以捕捉图动态。发现在于它在时序图任务中提升了预测准确性，证明了状态空间模型在图神经网络中的潜力。\n\n强化学习论文较多，如 \"Causal Prompting Reinforcement Learning\"，它们强调了因果推理和代理协作，但非核心的（如一些特定应用）我只简要提及，以控制篇幅。\n\n#### 医疗和生物应用\n- **基于深度学习的帕金森病早期检测（PPINtonus: Early Detection of Parkinson's Disease Using Deep-Learning Tonal Analysis）**  \n  Varun Reddy 提出使用深度学习分析语音音调检测帕金森病。贡献在于它通过简单语音测试（120秒）实现高准确率（92.5%），为低资源地区提供廉价诊断工具。\n\n- **TCMBench：评估 LLM 在中医领域的基准（TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine）**  \n  Wenjing Yue 等构建了中医基准数据集，并提出 TCMScore 指标。发现在于 LLM 在中医问答中表现不佳，但通过知识增强（如 AGKA 方法）可提升准确性，适用于中医临床。\n\n这些论文展示了 AI 在医疗中的实际价值，其他如药物生成模型我快速掠过，因为它们更偏向特定技术细节。\n\n#### 其他值得注意的论文\n- **因果发现的简化方法（Causal Discovery with Fewer Conditional Independence Tests）**  \n  Caroline Uhler 的工作减少了条件独立性测试数量，提出 Causal Consistent Partition Graph (CCPG)。主要贡献是高效学习因果图，适合大规模应用。\n\n- **进化计算在 AI 设计中的应用（Evolutionary Computation for the Design and Enrichment of General-Purpose Artificial Intelligence Systems）**  \n  Xin Yao 等作者探讨了进化计算在通用 AI 系统中的作用。发现在于它提升了 AI 的适应性和效率，实验验证了其在复杂任务中的潜力。\n\n其余论文，如一些图像处理或纯理论工作（如 \"animal2vec\" 或 \"VerilogReader\"），虽然有创新（如多模态数据处理），但影响力较小，我这里只简要掠过：它们提供了工具或数据集，但未涉及核心 AI 挑战。\n\n今天的 arXiv 快报聚焦 AI 创新，强调了 LLM 和强化学习的实用性。如果你对某个领域感兴趣，建议优先查看上述论文！（总字数控制在合理范围内，聚焦精华）",
  "papers": [
    {
      "arxiv_id": "2406.01853v1",
      "title": "Multi-Agent Reinforcement Learning Meets Leaf Sequencing in Radiotherapy",
      "title_zh": "翻译失败",
      "authors": [
        "Riqiang Gao",
        "Florin C. Ghesu",
        "Simon Arberet",
        "Shahab Basiri",
        "Esa Kuusela",
        "Martin Kraus",
        "Dorin Comaniciu",
        "Ali Kamen"
      ],
      "abstract": "In contemporary radiotherapy planning (RTP), a key module leaf sequencing is\npredominantly addressed by optimization-based approaches. In this paper, we\npropose a novel deep reinforcement learning (DRL) model termed as Reinforced\nLeaf Sequencer (RLS) in a multi-agent framework for leaf sequencing. The RLS\nmodel offers improvements to time-consuming iterative optimization steps via\nlarge-scale training and can control movement patterns through the design of\nreward mechanisms. We have conducted experiments on four datasets with four\nmetrics and compared our model with a leading optimization sequencer. Our\nfindings reveal that the proposed RLS model can achieve reduced fluence\nreconstruction errors, and potential faster convergence when integrated in an\noptimization planner. Additionally, RLS has shown promising results in a full\nartificial intelligence RTP pipeline. We hope this pioneer multi-agent RL leaf\nsequencer can foster future research on machine learning for RTP.",
      "tldr_zh": "该论文提出了一种名为Reinforced Leaf Sequencer (RLS)的多智能体深度强化学习 (DRL) 模型，用于放射治疗规划 (RTP) 中的叶片序列问题，以取代传统的优化方法。RLS 通过大规模训练和奖励机制设计来控制叶片运动模式，从而减少迭代优化时间并提高效率。实验在四个数据集上与领先优化序列器比较，结果显示 RLS 显著降低了流畅重建错误，并实现了更快的收敛速度，在全人工智能 RTP 管道中表现出色。该工作有望推动 Multi-Agent Reinforcement Learning 在 RTP 领域的未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01853v1",
      "published_date": "2024-06-03 23:55:20 UTC",
      "updated_date": "2024-06-03 23:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:15:43.370691"
    },
    {
      "arxiv_id": "2406.01838v2",
      "title": "Learning the Target Network in Function Space",
      "title_zh": "翻译失败",
      "authors": [
        "Kavosh Asadi",
        "Yao Liu",
        "Shoham Sabach",
        "Ming Yin",
        "Rasool Fakoor"
      ],
      "abstract": "We focus on the task of learning the value function in the reinforcement\nlearning (RL) setting. This task is often solved by updating a pair of online\nand target networks while ensuring that the parameters of these two networks\nare equivalent. We propose Lookahead-Replicate (LR), a new value-function\napproximation algorithm that is agnostic to this parameter-space equivalence.\nInstead, the LR algorithm is designed to maintain an equivalence between the\ntwo networks in the function space. This value-based equivalence is obtained by\nemploying a new target-network update. We show that LR leads to a convergent\nbehavior in learning the value function. We also present empirical results\ndemonstrating that LR-based target-network updates significantly improve deep\nRL on the Atari benchmark.",
      "tldr_zh": "这篇论文针对强化学习（RL）中的价值函数学习问题，提出了一种新的算法Lookahead-Replicate (LR)，它通过在函数空间中维护在线网络和目标网络的等价，而不是传统的参数空间等价，来实现更有效的更新方法。LR算法采用一个新的目标网络更新策略，确保价值函数学习的收敛行为。实验结果显示，该方法在Atari基准上显著提升了深度RL的表现，证明了其在RL任务中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to International Conference on Machine Learning (ICML24)",
      "pdf_url": "http://arxiv.org/pdf/2406.01838v2",
      "published_date": "2024-06-03 23:10:35 UTC",
      "updated_date": "2024-09-23 02:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:15:53.937308"
    },
    {
      "arxiv_id": "2406.01835v1",
      "title": "An Open Multilingual System for Scoring Readability of Wikipedia",
      "title_zh": "翻译失败",
      "authors": [
        "Mykola Trokhymovych",
        "Indira Sen",
        "Martin Gerlach"
      ],
      "abstract": "With over 60M articles, Wikipedia has become the largest platform for open\nand freely accessible knowledge. While it has more than 15B monthly visits, its\ncontent is believed to be inaccessible to many readers due to the lack of\nreadability of its text. However, previous investigations of the readability of\nWikipedia have been restricted to English only, and there are currently no\nsystems supporting the automatic readability assessment of the 300+ languages\nin Wikipedia. To bridge this gap, we develop a multilingual model to score the\nreadability of Wikipedia articles. To train and evaluate this model, we create\na novel multilingual dataset spanning 14 languages, by matching articles from\nWikipedia to simplified Wikipedia and online children encyclopedias. We show\nthat our model performs well in a zero-shot scenario, yielding a ranking\naccuracy of more than 80% across 14 languages and improving upon previous\nbenchmarks. These results demonstrate the applicability of the model at scale\nfor languages in which there is no ground-truth data available for model\nfine-tuning. Furthermore, we provide the first overview on the state of\nreadability in Wikipedia beyond English.",
      "tldr_zh": "该研究开发了一个开源多语言系统，用于评估 Wikipedia 文章的可读性，以解决其内容对许多读者不友好的问题。研究者创建了一个新颖的多语言数据集，涵盖 14 种语言，通过匹配 Wikipedia 文章与简化版 Wikipedia 以及在线儿童百科来训练模型。在零-shot 场景下，该模型的排名准确率超过 80%，优于先前基准，并首次提供了 Wikipedia 可读性在英语以外语言的全面概述。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01835v1",
      "published_date": "2024-06-03 23:07:18 UTC",
      "updated_date": "2024-06-03 23:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:16:06.429541"
    },
    {
      "arxiv_id": "2406.01833v2",
      "title": "CAFO: Feature-Centric Explanation on Time Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeho Kim",
        "Seok-Ju Hahn",
        "Yoontae Hwang",
        "Junghye Lee",
        "Seulki Lee"
      ],
      "abstract": "In multivariate time series (MTS) classification, finding the important\nfeatures (e.g., sensors) for model performance is crucial yet challenging due\nto the complex, high-dimensional nature of MTS data, intricate temporal\ndynamics, and the necessity for domain-specific interpretations. Current\nexplanation methods for MTS mostly focus on time-centric explanations, apt for\npinpointing important time periods but less effective in identifying key\nfeatures. This limitation underscores the pressing need for a feature-centric\napproach, a vital yet often overlooked perspective that complements\ntime-centric analysis. To bridge this gap, our study introduces a novel\nfeature-centric explanation and evaluation framework for MTS, named CAFO\n(Channel Attention and Feature Orthgonalization). CAFO employs a\nconvolution-based approach with channel attention mechanisms, incorporating a\ndepth-wise separable channel attention module (DepCA) and a QR\ndecomposition-based loss for promoting feature-wise orthogonality. We\ndemonstrate that this orthogonalization enhances the separability of attention\ndistributions, thereby refining and stabilizing the ranking of feature\nimportance. This improvement in feature-wise ranking enhances our understanding\nof feature explainability in MTS. Furthermore, we develop metrics to evaluate\nglobal and class-specific feature importance. Our framework's efficacy is\nvalidated through extensive empirical analyses on two major public benchmarks\nand real-world datasets, both synthetic and self-collected, specifically\ndesigned to highlight class-wise discriminative features. The results confirm\nCAFO's robustness and informative capacity in assessing feature importance in\nMTS classification tasks. This study not only advances the understanding of\nfeature-centric explanations in MTS but also sets a foundation for future\nexplorations in feature-centric explanations.",
      "tldr_zh": "在多变量时间序列 (MTS) 分类中，现有方法多关注时间-centric 解释，而忽略了 feature-centric 解释的必要性，该论文引入了 CAFO 框架，以识别关键特征（如传感器）并提升解释准确性。CAFO 采用 convolution-based  approach、depth-wise separable channel attention module (DepCA) 和 QR decomposition-based loss 来促进 feature-wise orthogonality，从而增强 attention distributions 的分离性和特征重要性排名稳定性。实验结果显示，CAFO 在公共基准和真实数据集上表现出色，验证了其鲁棒性，并为 MTS 中的 feature-centric 解释提供了新基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to KDD 2024 Research Track",
      "pdf_url": "http://arxiv.org/pdf/2406.01833v2",
      "published_date": "2024-06-03 23:06:45 UTC",
      "updated_date": "2024-06-12 01:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:16:21.513914"
    },
    {
      "arxiv_id": "2406.01832v1",
      "title": "A Robust Filter for Marker-less Multi-person Tracking in Human-Robot Interaction Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Enrico Martini",
        "Harshil Parekh",
        "Shaoting Peng",
        "Nicola Bombieri",
        "Nadia Figueroa"
      ],
      "abstract": "Pursuing natural and marker-less human-robot interaction (HRI) has been a\nlong-standing robotics research focus, driven by the vision of seamless\ncollaboration without physical markers. Marker-less approaches promise an\nimproved user experience, but state-of-the-art struggles with the challenges\nposed by intrinsic errors in human pose estimation (HPE) and depth cameras.\nThese errors can lead to issues such as robot jittering, which can\nsignificantly impact the trust users have in collaborative systems. We propose\na filtering pipeline that refines incomplete 3D human poses from an HPE\nbackbone and a single RGB-D camera to address these challenges, solving for\nocclusions that can degrade the interaction. Experimental results show that\nusing the proposed filter leads to more consistent and noise-free motion\nrepresentation, reducing unexpected robot movements and enabling smoother\ninteraction.",
      "tldr_zh": "该论文针对无标记多人追踪在人机交互（HRI）场景中的挑战，提出一个鲁棒过滤管道，以解决人体姿势估计（HPE）和深度相机固有错误导致的机器人抖动问题。过滤管道利用 HPE 骨干和单个 RGB-D 相机对不完整的 3D 人体姿势进行精炼，并处理遮挡问题，从而提高交互的稳定性和可靠性。实验结果表明，该方法显著减少了意外机器人运动，提供更一致、无噪声的运动表示，实现更平滑的 HRI 体验。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "Published by and copyright protected by IEEE, 6 pages, 3 figures,\n  33rd IEEE International Conference on Robot & Human Interactive Communication\n  (RO-MAN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.01832v1",
      "published_date": "2024-06-03 22:59:53 UTC",
      "updated_date": "2024-06-03 22:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:16:30.590470"
    },
    {
      "arxiv_id": "2406.01829v2",
      "title": "FaçAID: A Transformer Model for Neuro-Symbolic Facade Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksander Plocharski",
        "Jan Swidzinski",
        "Joanna Porter-Sobieraj",
        "Przemyslaw Musialski"
      ],
      "abstract": "We introduce a neuro-symbolic transformer-based model that converts flat,\nsegmented facade structures into procedural definitions using a custom-designed\nsplit grammar. To facilitate this, we first develop a semi-complex split\ngrammar tailored for architectural facades and then generate a dataset\ncomprising of facades alongside their corresponding procedural representations.\nThis dataset is used to train our transformer model to convert segmented, flat\nfacades into the procedural language of our grammar. During inference, the\nmodel applies this learned transformation to new facade segmentations,\nproviding a procedural representation that users can adjust to generate varied\nfacade designs. This method not only automates the conversion of static facade\nimages into dynamic, editable procedural formats but also enhances the design\nflexibility, allowing for easy modifications.",
      "tldr_zh": "本研究引入了 FaçAID，一种基于 Transformer 的 neuro-symbolic 模型，用于将平面分割的建筑立面结构转换为自定义 split grammar 的程序化定义。研究团队首先开发了针对建筑立面的半复杂 split grammar，并生成了一个包含立面及其程序化表示的数据集，用于训练 Transformer 模型。模型在推理过程中可将新立面分割转换为可编辑的程序化格式，从而自动化静态图像的转换，并增强设计灵活性，允许用户轻松调整生成多样化的立面设计。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.NE",
        "I.3.5; I.2.2; I.4.5"
      ],
      "primary_category": "cs.GR",
      "comment": "11 pages, 11 figures, in ACM SIGGRAPH Asia 2024 Conference Papers\n  Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2406.01829v2",
      "published_date": "2024-06-03 22:56:40 UTC",
      "updated_date": "2024-09-13 09:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:16:43.098938"
    },
    {
      "arxiv_id": "2406.01825v2",
      "title": "EMOE: Expansive Matching of Experts for Robust Uncertainty Based Rejection",
      "title_zh": "翻译失败",
      "authors": [
        "Yunni Qu",
        "James Wellnitz",
        "Alexander Tropsha",
        "Junier Oliva"
      ],
      "abstract": "Expansive Matching of Experts (EMOE) is a novel method that utilizes\nsupport-expanding, extrapolatory pseudo-labeling to improve prediction and\nuncertainty based rejection on out-of-distribution (OOD) points. We propose an\nexpansive data augmentation technique that generates OOD instances in a latent\nspace, and an empirical trial based approach to filter out augmented expansive\npoints for pseudo-labeling. EMOE utilizes a diverse set of multiple base\nexperts as pseudo-labelers on the augmented data to improve OOD performance\nthrough a shared MLP with multiple heads (one per expert). We demonstrate that\nEMOE achieves superior performance compared to state-of-the-art methods on\ntabular data.",
      "tldr_zh": "EMOE 是一种新颖的方法，通过支持扩展和外推伪标签技术，改善了对分布外（OOD）点的预测以及基于不确定性的拒绝机制。该方法包括在潜在空间生成 OOD 实例的扩展数据增强技术，以及使用经验试探方法过滤增强点，并利用多个基础专家作为伪标签器，通过共享的 MLP（多层感知器）及其多个头来提升性能。实验结果表明，EMOE 在表格数据上比现有最先进方法表现出优越的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01825v2",
      "published_date": "2024-06-03 22:37:45 UTC",
      "updated_date": "2024-06-05 03:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:16:55.008860"
    },
    {
      "arxiv_id": "2406.01823v1",
      "title": "Causal Discovery with Fewer Conditional Independence Tests",
      "title_zh": "减少条件独立性测试的因果发现",
      "authors": [
        "Kirankumar Shiragur",
        "Jiaqi Zhang",
        "Caroline Uhler"
      ],
      "abstract": "Many questions in science center around the fundamental problem of\nunderstanding causal relationships. However, most constraint-based causal\ndiscovery algorithms, including the well-celebrated PC algorithm, often incur\nan exponential number of conditional independence (CI) tests, posing\nlimitations in various applications. Addressing this, our work focuses on\ncharacterizing what can be learned about the underlying causal graph with a\nreduced number of CI tests. We show that it is possible to a learn a coarser\nrepresentation of the hidden causal graph with a polynomial number of tests.\nThis coarser representation, named Causal Consistent Partition Graph (CCPG),\ncomprises of a partition of the vertices and a directed graph defined over its\ncomponents. CCPG satisfies consistency of orientations and additional\nconstraints which favor finer partitions. Furthermore, it reduces to the\nunderlying causal graph when the causal graph is identifiable. As a\nconsequence, our results offer the first efficient algorithm for recovering the\ntrue causal graph with a polynomial number of tests, in special cases where the\ncausal graph is fully identifiable through observational data and potentially\nadditional interventions.",
      "tldr_zh": "本研究针对因果发现问题，提出了一种减少条件独立性 (CI) 测试数量的方法，以克服传统算法如 PC algorithm 的指数级测试限制。研究引入 Causal Consistent Partition Graph (CCPG)，这是一种顶点分区的粗粒度表示，结合有向图和方向一致性约束，能用多项式数量的测试学习潜在因果图。结果显示，在因果图可识别的特殊情况下，此方法可高效恢复真实因果图，为基于观察数据和干预的因果分析提供更可行的算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01823v1",
      "published_date": "2024-06-03 22:27:09 UTC",
      "updated_date": "2024-06-03 22:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:17:05.101606"
    },
    {
      "arxiv_id": "2406.01820v1",
      "title": "Finding Lottery Tickets in Vision Models via Data-driven Spectral Foresight Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Iurada",
        "Marco Ciccone",
        "Tatiana Tommasi"
      ],
      "abstract": "Recent advances in neural network pruning have shown how it is possible to\nreduce the computational costs and memory demands of deep learning models\nbefore training. We focus on this framework and propose a new pruning at\ninitialization algorithm that leverages the Neural Tangent Kernel (NTK) theory\nto align the training dynamics of the sparse network with that of the dense\none. Specifically, we show how the usually neglected data-dependent component\nin the NTK's spectrum can be taken into account by providing an analytical\nupper bound to the NTK's trace obtained by decomposing neural networks into\nindividual paths. This leads to our Path eXclusion (PX), a foresight pruning\nmethod designed to preserve the parameters that mostly influence the NTK's\ntrace. PX is able to find lottery tickets (i.e. good paths) even at high\nsparsity levels and largely reduces the need for additional training. When\napplied to pre-trained models it extracts subnetworks directly usable for\nseveral downstream tasks, resulting in performance comparable to those of the\ndense counterpart but with substantial cost and computational savings. Code\navailable at: https://github.com/iurada/px-ntk-pruning",
      "tldr_zh": "本论文提出了一种基于数据驱动的谱前瞻剪枝方法，用于在视觉模型中发现 lottery tickets，从而在训练前减少神经网络的计算成本和内存需求。该方法利用 Neural Tangent Kernel (NTK) 理论，通过分析 NTK 光谱中数据依赖组件的跟踪上界，将神经网络分解为单个路径，并引入 Path eXclusion (PX) 算法来保留对 NTK 跟踪影响最大的参数。实验结果显示，PX 即使在高稀疏度下也能找到高效子网络，显著减少额外训练需求，并在下游任务上实现与密集模型相当的性能，同时大幅节省计算资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted CVPR 2024 - https://iurada.github.io/PX",
      "pdf_url": "http://arxiv.org/pdf/2406.01820v1",
      "published_date": "2024-06-03 22:19:42 UTC",
      "updated_date": "2024-06-03 22:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:17:19.283679"
    },
    {
      "arxiv_id": "2406.01813v1",
      "title": "Diffusion Boosted Trees",
      "title_zh": "翻译失败",
      "authors": [
        "Xizewen Han",
        "Mingyuan Zhou"
      ],
      "abstract": "Combining the merits of both denoising diffusion probabilistic models and\ngradient boosting, the diffusion boosting paradigm is introduced for tackling\nsupervised learning problems. We develop Diffusion Boosted Trees (DBT), which\ncan be viewed as both a new denoising diffusion generative model parameterized\nby decision trees (one single tree for each diffusion timestep), and a new\nboosting algorithm that combines the weak learners into a strong learner of\nconditional distributions without making explicit parametric assumptions on\ntheir density forms. We demonstrate through experiments the advantages of DBT\nover deep neural network-based diffusion models as well as the competence of\nDBT on real-world regression tasks, and present a business application (fraud\ndetection) of DBT for classification on tabular data with the ability of\nlearning to defer.",
      "tldr_zh": "该论文引入了diffusion boosting范式，将denoising diffusion probabilistic models和gradient boosting的优点相结合，用于处理监督学习问题。作者开发了Diffusion Boosted Trees (DBT)，这是一种新颖的denoising diffusion生成模型，由决策树参数化（每个diffusion timestep一个树），同时作为一种boosting算法，将弱学习器整合成强学习器，而不需显式假设密度形式。实验结果表明，DBT在回归任务上优于基于深度神经网络的diffusion模型，并在实际应用如欺诈检测的分类任务中表现出色，支持learning to defer功能。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.AP",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01813v1",
      "published_date": "2024-06-03 22:11:38 UTC",
      "updated_date": "2024-06-03 22:11:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:17:31.134078"
    },
    {
      "arxiv_id": "2406.01812v1",
      "title": "Memory Capacity Analysis of Time-delay Reservoir Computing Based on Silicon Microring Resonator Nonlinearities",
      "title_zh": "翻译失败",
      "authors": [
        "Bernard J. Giron Castro",
        "Christophe Peucheret",
        "Francesco Da Ros"
      ],
      "abstract": "Silicon microring resonators (MRRs) have shown strong potential in acting as\nthe nonlinear nodes of photonic reservoir computing (RC) schemes. By using\nnonlinearities within a silicon MRR, such as the ones caused by free-carrier\ndispersion (FCD) and thermo-optic (TO) effects, it is possible to map the input\ndata of the RC to a higher dimensional space. Furthermore, by adding an\nexternal waveguide between the through and add ports of the MRR, it is possible\nto implement a time-delay RC (TDRC) with enhanced memory. The input from the\nthrough port is fed back into the add port of the ring with the delay applied\nby the external waveguide effectively adding memory. In a TDRC, the nodes are\nmultiplexed in time, and their respective time evolutions are detected at the\ndrop port. The performance of MRR-based TDRC is highly dependent on the amount\nof nonlinearity in the MRR. The nonlinear effects, in turn, are dependent on\nthe physical properties of the MRR as they determine the lifetime of the\neffects. Another factor to take into account is the stability of the MRR\nresponse, as strong time-domain discontinuities at the drop port are known to\nemerge from FCD nonlinearities due to self-pulsing (high nonlinear behaviour).\nHowever, quantifying the right amount of nonlinearity that RC needs for a\ncertain task in order to achieve optimum performance is challenging. Therefore,\nfurther analysis is required to fully understand the nonlinear dynamics of this\nTDRC setup. Here, we quantify the nonlinear and linear memory capacity of the\npreviously described microring-based TDRC scheme, as a function of the time\nconstants of the generated carriers and the thermal of the TO effects. We\nanalyze the properties of the TDRC dynamics that generate the parameter space,\nin terms of input signal power and frequency detuning range, over which\nconventional RC tasks can be satisfactorily performed by the TDRC scheme.",
      "tldr_zh": "这篇论文分析了基于Silicon Microring Resonators (MRRs)非线性性的Time-Delay Reservoir Computing (TDRC)的记忆容量问题，通过Free-Carrier Dispersion (FCD)和Thermo-Optic (TO)效应将输入数据映射到更高维空间，并利用外部波导增强TDRC的记忆功能。研究方法包括量化TDRC的非线性记忆容量和线性记忆容量，作为FCD和TO效应时间常数的函数，同时考察输入信号功率和频率失谐范围对系统动态的影响。结果显示，这些分析有助于识别适合常规Reservoir Computing (RC)任务的最佳参数空间，确保TDRC在非线性动态下的稳定性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "physics.optics"
      ],
      "primary_category": "cs.NE",
      "comment": "12 pages, 12 figures. Proceedings SPIE Europe 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01812v1",
      "published_date": "2024-06-03 22:10:25 UTC",
      "updated_date": "2024-06-03 22:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:17:55.377114"
    },
    {
      "arxiv_id": "2406.01806v1",
      "title": "Contextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation",
      "title_zh": "上下文化序列似然：用于自然语言生成的增强置信度分数",
      "authors": [
        "Zhen Lin",
        "Shubhendu Trivedi",
        "Jimeng Sun"
      ],
      "abstract": "The advent of large language models (LLMs) has dramatically advanced the\nstate-of-the-art in numerous natural language generation tasks. For LLMs to be\napplied reliably, it is essential to have an accurate measure of their\nconfidence. Currently, the most commonly used confidence score function is the\nlikelihood of the generated sequence, which, however, conflates semantic and\nsyntactic components. For instance, in question-answering (QA) tasks, an\nawkward phrasing of the correct answer might result in a lower probability\nprediction. Additionally, different tokens should be weighted differently\ndepending on the context. In this work, we propose enhancing the predicted\nsequence probability by assigning different weights to various tokens using\nattention values elicited from the base LLM. By employing a validation set, we\ncan identify the relevant attention heads, thereby significantly improving the\nreliability of the vanilla sequence probability confidence measure. We refer to\nthis new score as the Contextualized Sequence Likelihood (CSL). CSL is easy to\nimplement, fast to compute, and offers considerable potential for further\nimprovement with task-specific prompts. Across several QA datasets and a\ndiverse array of LLMs, CSL has demonstrated significantly higher reliability\nthan state-of-the-art baselines in predicting generation quality, as measured\nby the AUROC or AUARC.",
      "tldr_zh": "这篇论文针对大语言模型(LLMs)在自然语言生成中的置信度问题，提出了Contextualized Sequence Likelihood (CSL)方法，以解决传统序列似然分数混淆语义和句法组件的局限性。CSL通过从基线LLMs中提取注意力值，对不同标记赋予上下文相关的权重，并利用验证集识别关键注意力头，从而显著提升置信度分数的准确性。该方法易于实现、计算高效，并在多个问答(QA)数据集上测试，显示出比最先进基线更高的可靠性，如在AUROC和AUARC指标上的显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01806v1",
      "published_date": "2024-06-03 21:55:07 UTC",
      "updated_date": "2024-06-03 21:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:18:07.663996"
    },
    {
      "arxiv_id": "2406.01805v2",
      "title": "TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting",
      "title_zh": "TabMDA：使用带有上下文子集选择的Transformer进行表格流形数据增强，适用于任何分类器",
      "authors": [
        "Andrei Margeloiu",
        "Adrián Bazaga",
        "Nikola Simidjievski",
        "Pietro Liò",
        "Mateja Jamnik"
      ],
      "abstract": "Tabular data is prevalent in many critical domains, yet it is often\nchallenging to acquire in large quantities. This scarcity usually results in\npoor performance of machine learning models on such data. Data augmentation, a\ncommon strategy for performance improvement in vision and language tasks,\ntypically underperforms for tabular data due to the lack of explicit symmetries\nin the input space. To overcome this challenge, we introduce TabMDA, a novel\nmethod for manifold data augmentation on tabular data. This method utilises a\npre-trained in-context model, such as TabPFN, to map the data into an embedding\nspace. TabMDA performs label-invariant transformations by encoding the data\nmultiple times with varied contexts. This process explores the learned\nembedding space of the underlying in-context models, thereby enlarging the\ntraining dataset. TabMDA is a training-free method, making it applicable to any\nclassifier. We evaluate TabMDA on five standard classifiers and observe\nsignificant performance improvements across various tabular datasets. Our\nresults demonstrate that TabMDA provides an effective way to leverage\ninformation from pre-trained in-context models to enhance the performance of\ndownstream classifiers. Code is available at\nhttps://github.com/AdrianBZG/TabMDA.",
      "tldr_zh": "该论文提出 TabMDA，一种新型的表格数据流形数据增强方法，用于解决表格数据稀缺导致机器学习模型性能不佳的问题。TabMDA 利用预训练的 in-context 模型（如 TabPFN）将数据映射到嵌入空间，通过标签不变变换和多次编码来探索该空间，从而扩大训练数据集。该方法是训练-free 的，可应用于任何分类器，实验在五种标准分类器和多种表格数据集上观察到显著性能提升，最终证明了 TabMDA 有效利用预训练模型信息来提升下游分类器的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at 1st ICML Workshop on In-Context Learning (ICL @ ICML\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.01805v2",
      "published_date": "2024-06-03 21:51:13 UTC",
      "updated_date": "2024-07-29 15:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:18:09.471878"
    },
    {
      "arxiv_id": "2406.02625v1",
      "title": "Progressive Inference: Explaining Decoder-Only Sequence Classification Models Using Intermediate Predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjay Kariyappa",
        "Freddy Lécué",
        "Saumitra Mishra",
        "Christopher Pond",
        "Daniele Magazzeni",
        "Manuela Veloso"
      ],
      "abstract": "This paper proposes Progressive Inference - a framework to compute input\nattributions to explain the predictions of decoder-only sequence classification\nmodels. Our work is based on the insight that the classification head of a\ndecoder-only Transformer model can be used to make intermediate predictions by\nevaluating them at different points in the input sequence. Due to the causal\nattention mechanism, these intermediate predictions only depend on the tokens\nseen before the inference point, allowing us to obtain the model's prediction\non a masked input sub-sequence, with negligible computational overheads. We\ndevelop two methods to provide sub-sequence level attributions using this\ninsight. First, we propose Single Pass-Progressive Inference (SP-PI), which\ncomputes attributions by taking the difference between consecutive intermediate\npredictions. Second, we exploit a connection with Kernel SHAP to develop Multi\nPass-Progressive Inference (MP-PI). MP-PI uses intermediate predictions from\nmultiple masked versions of the input to compute higher quality attributions.\nOur studies on a diverse set of models trained on text classification tasks\nshow that SP-PI and MP-PI provide significantly better attributions compared to\nprior work.",
      "tldr_zh": "这篇论文提出了 Progressive Inference 框架，用于解释 decoder-only 序列分类模型的预测，通过利用中间预测来计算输入归因。该框架基于因果注意力机制，允许在输入序列的不同点评估预测，而仅依赖于之前标记的子序列。论文开发了两种方法：Single Pass-Progressive Inference (SP-PI)，通过连续中间预测的差异计算归因；以及 Multi Pass-Progressive Inference (MP-PI)，结合 Kernel SHAP 和多个掩码输入版本来获得更高质量的归因。在文本分类任务上的实验显示，SP-PI 和 MP-PI 比现有方法提供了显著更好的归因性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02625v1",
      "published_date": "2024-06-03 21:48:57 UTC",
      "updated_date": "2024-06-03 21:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:18:21.762866"
    },
    {
      "arxiv_id": "2406.01793v2",
      "title": "Towards the Transferability of Rewards Recovered via Regularized Inverse Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Schlaginhaufen",
        "Maryam Kamgarpour"
      ],
      "abstract": "Inverse reinforcement learning (IRL) aims to infer a reward from expert\ndemonstrations, motivated by the idea that the reward, rather than the policy,\nis the most succinct and transferable description of a task [Ng et al., 2000].\nHowever, the reward corresponding to an optimal policy is not unique, making it\nunclear if an IRL-learned reward is transferable to new transition laws in the\nsense that its optimal policy aligns with the optimal policy corresponding to\nthe expert's true reward. Past work has addressed this problem only under the\nassumption of full access to the expert's policy, guaranteeing transferability\nwhen learning from two experts with the same reward but different transition\nlaws that satisfy a specific rank condition [Rolland et al., 2022]. In this\nwork, we show that the conditions developed under full access to the expert's\npolicy cannot guarantee transferability in the more practical scenario where we\nhave access only to demonstrations of the expert. Instead of a binary rank\ncondition, we propose principal angles as a more refined measure of similarity\nand dissimilarity between transition laws. Based on this, we then establish two\nkey results: 1) a sufficient condition for transferability to any transition\nlaws when learning from at least two experts with sufficiently different\ntransition laws, and 2) a sufficient condition for transferability to local\nchanges in the transition law when learning from a single expert. Furthermore,\nwe also provide a probably approximately correct (PAC) algorithm and an\nend-to-end analysis for learning transferable rewards from demonstrations of\nmultiple experts.",
      "tldr_zh": "这篇论文探讨了逆强化学习（IRL）的奖励转移性问题，即从专家演示中推断的奖励是否能在新转移法则下保持最优策略一致。作者指出，过去基于完全访问专家策略的条件（如特定秩条件）无法应用于仅拥有专家演示的实际场景，而是提出使用主角度（principal angles）作为转移法则之间相似性的更精确度量。论文建立了两个关键结果：一是从至少两个专家（转移法则足够不同）的演示中学习时，向任意转移法则的转移性充分条件；二是从单个专家演示中学习时，向转移法则局部变化的转移性充分条件。此外，作者提供了一个 PAC（probably approximately correct）算法，并进行了端到端分析，以从多个专家演示中学习可转移奖励。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "The Thirty-Eighth Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.01793v2",
      "published_date": "2024-06-03 21:18:08 UTC",
      "updated_date": "2025-02-03 22:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:18:33.755164"
    },
    {
      "arxiv_id": "2406.01789v1",
      "title": "AI-based Classification of Customer Support Tickets: State of the Art and Implementation with AutoML",
      "title_zh": "翻译失败",
      "authors": [
        "Mario Truss",
        "Stephan Boehm"
      ],
      "abstract": "Automation of support ticket classification is crucial to improve customer\nsupport performance and shortening resolution time for customer inquiries. This\nresearch aims to test the applicability of automated machine learning (AutoML)\nas a technology to train a machine learning model (ML model) that can classify\nsupport tickets. The model evaluation conducted in this research shows that\nAutoML can be used to train ML models with good classification performance.\nMoreover, this paper fills a research gap by providing new insights into\ndeveloping AI solutions without a dedicated professional by utilizing AutoML,\nwhich makes this technology more accessible for companies without specialized\nAI departments and staff.",
      "tldr_zh": "本研究探讨了使用自动机器学习 (AutoML) 来分类客户支持票证，以提升支持性能并缩短问题解决时间。研究通过实验评估了 AutoML 训练机器学习模型 (ML model) 的适用性，结果显示该模型在分类任务中表现出色。该工作填补了研究空白，提供新见解，帮助没有专业 AI 团队的公司轻松开发 AI 解决方案，从而使这项技术更易于推广。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "I.2; I.2.7; K.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01789v1",
      "published_date": "2024-06-03 21:13:02 UTC",
      "updated_date": "2024-06-03 21:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:18:41.970807"
    },
    {
      "arxiv_id": "2406.01786v1",
      "title": "Recent Advances in Data-Driven Business Process Management",
      "title_zh": "翻译失败",
      "authors": [
        "Lars Ackermann",
        "Martin Käppel",
        "Laura Marcus",
        "Linda Moder",
        "Sebastian Dunzer",
        "Markus Hornsteiner",
        "Annina Liessmann",
        "Yorck Zisgen",
        "Philip Empl",
        "Lukas-Valentin Herm",
        "Nicolas Neis",
        "Julian Neuberger",
        "Leo Poss",
        "Myriam Schaschek",
        "Sven Weinzierl",
        "Niklas Wördehoff",
        "Stefan Jablonski",
        "Agnes Koschmider",
        "Wolfgang Kratsch",
        "Martin Matzner",
        "Stefanie Rinderle-Ma",
        "Maximilian Röglinger",
        "Stefan Schönig",
        "Axel Winkelmann"
      ],
      "abstract": "The rapid development of cutting-edge technologies, the increasing volume of\ndata and also the availability and processability of new types of data sources\nhas led to a paradigm shift in data-based management and decision-making. Since\nbusiness processes are at the core of organizational work, these developments\nheavily impact BPM as a crucial success factor for organizations. In view of\nthis emerging potential, data-driven business process management has become a\nrelevant and vibrant research area. Given the complexity and\ninterdisciplinarity of the research field, this position paper therefore\npresents research insights regarding data-driven BPM.",
      "tldr_zh": "近年来，随着前沿技术的快速发展、数据量的激增以及新数据源的可获取性和可处理性，数据管理决策出现了范式转变，这深刻影响了业务流程管理(BPM)作为组织成功的关键因素。该论文作为一篇位置论文(position paper)，强调数据驱动的BPM已成为一个活跃且多学科的研究领域，并呈现了相关研究见解。通过探讨这些进展，论文旨在为组织利用数据优化BPM提供指导和洞见。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "68U35 68T07 68T07, 68U35, 68T01",
        "H.4.1; I.2.1; I.2.6; I.2.7; H.2.8; K.6.1"
      ],
      "primary_category": "cs.DB",
      "comment": "position paper, 34 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01786v1",
      "published_date": "2024-06-03 21:05:59 UTC",
      "updated_date": "2024-06-03 21:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:19:05.353484"
    },
    {
      "arxiv_id": "2406.01782v1",
      "title": "Multi-agent assignment via state augmented reinforcement learning",
      "title_zh": "翻译失败",
      "authors": [
        "Leopoldo Agorio",
        "Sean Van Alen",
        "Miguel Calvo-Fullana",
        "Santiago Paternain",
        "Juan Andres Bazerque"
      ],
      "abstract": "We address the conflicting requirements of a multi-agent assignment problem\nthrough constrained reinforcement learning, emphasizing the inadequacy of\nstandard regularization techniques for this purpose. Instead, we recur to a\nstate augmentation approach in which the oscillation of dual variables is\nexploited by agents to alternate between tasks. In addition, we coordinate the\nactions of the multiple agents acting on their local states through these\nmultipliers, which are gossiped through a communication network, eliminating\nthe need to access other agent states. By these means, we propose a distributed\nmulti-agent assignment protocol with theoretical feasibility guarantees that we\ncorroborate in a monitoring numerical experiment.",
      "tldr_zh": "这篇论文针对多智能体分配问题，使用状态增强的强化学习（state augmented reinforcement learning）来处理冲突需求，强调标准正则化技术的不 adequacy，转而通过双变量（dual variables）的振荡让智能体在任务间切换。作者设计了一种分布式协议，通过通信网络 gossip 乘子（multipliers）协调智能体行动，避免访问其他智能体的本地状态，从而实现有效的多智能体协作。该方法提供了理论可行性保证，并在数值实验中得到验证。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SY",
        "93E35"
      ],
      "primary_category": "eess.SY",
      "comment": "12 pages, 3 figures, 6th Annual Conference on Learning for Dynamics\n  and Control",
      "pdf_url": "http://arxiv.org/pdf/2406.01782v1",
      "published_date": "2024-06-03 20:56:12 UTC",
      "updated_date": "2024-06-03 20:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:19:08.306689"
    },
    {
      "arxiv_id": "2407.17590v1",
      "title": "Is computational creativity flourishing on the dead internet?",
      "title_zh": "翻译失败",
      "authors": [
        "Terence Broad"
      ],
      "abstract": "The dead internet theory is a conspiracy theory that states that all\ninteractions and posts on social media are no longer being made by real people,\nbut rather by autonomous bots. While the theory is obviously not true, an\nincreasing amount of posts on social media have been made by bots optimised to\ngain followers and drive engagement on social media platforms. This paper looks\nat the recent phenomenon of these bots, analysing their behaviour through the\nlens of computational creativity to investigate the question: is computational\ncreativity flourishing on the dead internet?",
      "tldr_zh": "这篇论文探讨了“dead internet theory”（一种认为社交媒体互动主要由机器人而非真人主导的阴谋论），虽然该理论不真实，但它突显了社交平台上由优化算法驱动的bots日益增多。论文通过计算创造性（computational creativity）的视角分析这些bots的行为，包括它们如何生成内容以提升关注和互动。研究结果表明，这种机器人主导的现象可能标志着计算创造性在“dead internet”环境中悄然兴盛，为理解自动化内容生成的社会影响提供了新见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.17590v1",
      "published_date": "2024-06-03 20:15:06 UTC",
      "updated_date": "2024-06-03 20:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:19:19.927787"
    },
    {
      "arxiv_id": "2406.01762v1",
      "title": "Non-Asymptotic Analysis for Single-Loop (Natural) Actor-Critic with Compatible Function Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Yudan Wang",
        "Yue Wang",
        "Yi Zhou",
        "Shaofeng Zou"
      ],
      "abstract": "Actor-critic (AC) is a powerful method for learning an optimal policy in\nreinforcement learning, where the critic uses algorithms, e.g., temporal\ndifference (TD) learning with function approximation, to evaluate the current\npolicy and the actor updates the policy along an approximate gradient direction\nusing information from the critic. This paper provides the \\textit{tightest}\nnon-asymptotic convergence bounds for both the AC and natural AC (NAC)\nalgorithms. Specifically, existing studies show that AC converges to an\n$\\epsilon+\\varepsilon_{\\text{critic}}$ neighborhood of stationary points with\nthe best known sample complexity of $\\mathcal{O}(\\epsilon^{-2})$ (up to a log\nfactor), and NAC converges to an\n$\\epsilon+\\varepsilon_{\\text{critic}}+\\sqrt{\\varepsilon_{\\text{actor}}}$\nneighborhood of the global optimum with the best known sample complexity of\n$\\mathcal{O}(\\epsilon^{-3})$, where $\\varepsilon_{\\text{critic}}$ is the\napproximation error of the critic and $\\varepsilon_{\\text{actor}}$ is the\napproximation error induced by the insufficient expressive power of the\nparameterized policy class. This paper analyzes the convergence of both AC and\nNAC algorithms with compatible function approximation. Our analysis eliminates\nthe term $\\varepsilon_{\\text{critic}}$ from the error bounds while still\nachieving the best known sample complexities. Moreover, we focus on the\nchallenging single-loop setting with a single Markovian sample trajectory. Our\nmajor technical novelty lies in analyzing the stochastic bias due to\npolicy-dependent and time-varying compatible function approximation in the\ncritic, and handling the non-ergodicity of the MDP due to the single Markovian\nsample trajectory. Numerical results are also provided in the appendix.",
      "tldr_zh": "这篇论文对单循环 Actor-Critic (AC) 和 Natural AC (NAC) 算法进行了非渐近收敛分析，使用 compatible function approximation 来优化收敛界限。研究的主要贡献是消除了批评家近似错误 (ε_critic) 的影响，同时保持了最佳样本复杂度：AC 收敛到 ε 邻域的样本复杂度为 O(ε^{-2})，NAC 收敛到全局最优的样本复杂度为 O(ε^{-3})。在单循环设置中，论文处理了政策依赖和时间变化的随机偏差，以及 Markovian 样本轨迹导致的 MDP 非平稳性，并通过附录中的数值结果验证了分析的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01762v1",
      "published_date": "2024-06-03 20:05:04 UTC",
      "updated_date": "2024-06-03 20:05:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:19:33.953224"
    },
    {
      "arxiv_id": "2406.01759v2",
      "title": "From Latent to Lucid: Transforming Knowledge Graph Embeddings into Interpretable Structures with KGEPrisma",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Wehner",
        "Chrysa Iliopoulou",
        "Ute Schmid",
        "Tarek R. Besold"
      ],
      "abstract": "In this paper, we introduce a post-hoc and local explainable AI method\ntailored for Knowledge Graph Embedding (KGE) models. These models are essential\nto Knowledge Graph Completion yet criticized for their opaque, black-box\nnature. Despite their significant success in capturing the semantics of\nknowledge graphs through high-dimensional latent representations, their\ninherent complexity poses substantial challenges to explainability. While\nexisting methods like Kelpie use resource-intensive perturbation to explain KGE\nmodels, our approach directly decodes the latent representations encoded by KGE\nmodels, leveraging the smoothness of the embeddings, which follows the\nprinciple that similar embeddings reflect similar behaviours within the\nKnowledge Graph, meaning that nodes are similarly embedded because their graph\nneighbourhood looks similar. This principle is commonly referred to as\nsmoothness. By identifying symbolic structures, in the form of triples, within\nthe subgraph neighborhoods of similarly embedded entities, our method\nidentifies the statistical regularities on which the models rely and translates\nthese insights into human-understandable symbolic rules and facts. This bridges\nthe gap between the abstract representations of KGE models and their predictive\noutputs, offering clear, interpretable insights. Key contributions include a\nnovel post-hoc and local explainable AI method for KGE models that provides\nimmediate, faithful explanations without retraining, facilitating real-time\napplication on large-scale knowledge graphs. The method's flexibility enables\nthe generation of rule-based, instance-based, and analogy-based explanations,\nmeeting diverse user needs. Extensive evaluations show the effectiveness of our\napproach in delivering faithful and well-localized explanations, enhancing the\ntransparency and trustworthiness of KGE models.",
      "tldr_zh": "本研究提出了一种后验（post-hoc）和局部（local）可解释 AI 方法，名为 KGEPrisma，用于将 Knowledge Graph Embedding (KGE) 模型的潜表示（latent representations）转化为可解释的符号结构，解决 KGE 模型黑箱性质带来的解释性挑战。该方法利用嵌入的平滑性（smoothness）原理，通过直接解码相似嵌入实体的子图邻域，识别符号结构（如 triples），并转化为人类可理解的规则和事实，从而提供即时、忠实的解释，而无需重新训练模型。关键贡献包括生成基于规则、实例和类比的多种解释形式，支持大规模知识图的实时应用；广泛评估证明，该方法能提供精确且有效的解释，提升了 KGE 模型的透明度和可信度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01759v2",
      "published_date": "2024-06-03 19:54:11 UTC",
      "updated_date": "2025-05-07 12:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:19:47.753978"
    },
    {
      "arxiv_id": "2406.01757v1",
      "title": "Position: Cracking the Code of Cascading Disparity Towards Marginalized Communities",
      "title_zh": "翻译失败",
      "authors": [
        "Golnoosh Farnadi",
        "Mohammad Havaei",
        "Negar Rostamzadeh"
      ],
      "abstract": "The rise of foundation models holds immense promise for advancing AI, but\nthis progress may amplify existing risks and inequalities, leaving marginalized\ncommunities behind. In this position paper, we discuss that disparities towards\nmarginalized communities - performance, representation, privacy, robustness,\ninterpretability and safety - are not isolated concerns but rather\ninterconnected elements of a cascading disparity phenomenon. We contrast\nfoundation models with traditional models and highlight the potential for\nexacerbated disparity against marginalized communities. Moreover, we emphasize\nthe unique threat of cascading impacts in foundation models, where\ninterconnected disparities can trigger long-lasting negative consequences,\nspecifically to the people on the margin. We define marginalized communities\nwithin the machine learning context and explore the multifaceted nature of\ndisparities. We analyze the sources of these disparities, tracing them from\ndata creation, training and deployment procedures to highlight the complex\ntechnical and socio-technical landscape. To mitigate the pressing crisis, we\nconclude with a set of calls to action to mitigate disparity at its source.",
      "tldr_zh": "这篇立场论文（position paper）探讨了基础模型（foundation models）在AI领域的进展可能如何放大现有风险和不平等，特别对边缘化社区（marginalized communities）造成级联不平等（cascading disparity），包括性能、表示、隐私、鲁棒性、可解释性和安全性的相互关联问题。作者对比了基础模型与传统模型，分析了这些不平等的来源，从数据创建、训练到部署过程，揭示了复杂的技​​术和社会技术因素。最终，论文呼吁采取行动，从源头缓解这些不平等，以避免长期负面后果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.01757v1",
      "published_date": "2024-06-03 19:52:41 UTC",
      "updated_date": "2024-06-03 19:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:19:59.283718"
    },
    {
      "arxiv_id": "2406.01755v1",
      "title": "Sparser, Better, Deeper, Stronger: Improving Sparse Training with Exact Orthogonal Initialization",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandra Irena Nowak",
        "Łukasz Gniecki",
        "Filip Szatkowski",
        "Jacek Tabor"
      ],
      "abstract": "Static sparse training aims to train sparse models from scratch, achieving\nremarkable results in recent years. A key design choice is given by the sparse\ninitialization, which determines the trainable sub-network through a binary\nmask. Existing methods mainly select such mask based on a predefined dense\ninitialization. Such an approach may not efficiently leverage the mask's\npotential impact on the optimization. An alternative direction, inspired by\nresearch into dynamical isometry, is to introduce orthogonality in the sparse\nsubnetwork, which helps in stabilizing the gradient signal. In this work, we\npropose Exact Orthogonal Initialization (EOI), a novel sparse orthogonal\ninitialization scheme based on composing random Givens rotations. Contrary to\nother existing approaches, our method provides exact (not approximated)\northogonality and enables the creation of layers with arbitrary densities. We\ndemonstrate the superior effectiveness and efficiency of EOI through\nexperiments, consistently outperforming common sparse initialization\ntechniques. Our method enables training highly sparse 1000-layer MLP and CNN\nnetworks without residual connections or normalization techniques, emphasizing\nthe crucial role of weight initialization in static sparse training alongside\nsparse mask selection. The code is available at\nhttps://github.com/woocash2/sparser-better-deeper-stronger",
      "tldr_zh": "本文提出 Exact Orthogonal Initialization (EOI)，一种基于随机 Givens rotations 的新型稀疏初始化方案，用于提升静态稀疏训练（Static sparse training）的性能，通过提供精确正交性来稳定梯度信号并支持任意密度的层。相比现有方法，EOI 在实验中表现出色，能够 consistently outperforming 常见稀疏初始化技术。结果显示，该方法成功训练了高度稀疏的 1000 层 MLP 和 CNN 网络，而无需 residual connections 或 normalization 技术，进一步强调了权重初始化在稀疏训练中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01755v1",
      "published_date": "2024-06-03 19:44:47 UTC",
      "updated_date": "2024-06-03 19:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:20:11.723661"
    },
    {
      "arxiv_id": "2406.06575v1",
      "title": "Ask-EDA: A Design Assistant Empowered by LLM, Hybrid RAG and Abbreviation De-hallucination",
      "title_zh": "翻译失败",
      "authors": [
        "Luyao Shi",
        "Michael Kazda",
        "Bradley Sears",
        "Nick Shropshire",
        "Ruchir Puri"
      ],
      "abstract": "Electronic design engineers are challenged to find relevant information\nefficiently for a myriad of tasks within design construction, verification and\ntechnology development. Large language models (LLM) have the potential to help\nimprove productivity by serving as conversational agents that effectively\nfunction as subject-matter experts. In this paper we demonstrate Ask-EDA, a\nchat agent designed to serve as a 24x7 expert available to provide guidance to\ndesign engineers. Ask-EDA leverages LLM, hybrid retrieval augmented generation\n(RAG) and abbreviation de-hallucination (ADH) techniques to deliver more\nrelevant and accurate responses. We curated three evaluation datasets, namely\nq2a-100, cmds-100 and abbr-100. Each dataset is tailored to assess a distinct\naspect: general design question answering, design command handling and\nabbreviation resolution. We demonstrated that hybrid RAG offers over a 40%\nimprovement in Recall on the q2a-100 dataset and over a 60% improvement on the\ncmds-100 dataset compared to not using RAG, while ADH yields over a 70%\nenhancement in Recall on the abbr-100 dataset. The evaluation results show that\nAsk-EDA can effectively respond to design-related inquiries.",
      "tldr_zh": "该论文介绍了Ask-EDA，一种基于LLM的电子设计助手，利用Hybrid RAG和Abbreviation De-hallucination (ADH)技术，帮助工程师高效处理设计建设、验证和技术开发中的查询。Ask-EDA通过混合检索增强生成提升响应相关性和准确性，并构建了三个专用数据集（q2a-100、cmds-100和abbr-100）来评估其在一般问题回答、设计命令处理和缩写解析方面的性能。实验结果显示，Hybrid RAG使q2a-100和cmds-100数据集的Recall分别提升超过40%和60%，而ADH使abbr-100数据集的Recall提升超过70%，证明了Ask-EDA在提升设计工程师生产力方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted paper at The First IEEE International Workshop on LLM-Aided\n  Design, 2024 (LAD 24)",
      "pdf_url": "http://arxiv.org/pdf/2406.06575v1",
      "published_date": "2024-06-03 19:40:28 UTC",
      "updated_date": "2024-06-03 19:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:20:24.120868"
    },
    {
      "arxiv_id": "2406.02622v1",
      "title": "Safeguarding Large Language Models: A Survey",
      "title_zh": "保护大型语言模型：一项综述",
      "authors": [
        "Yi Dong",
        "Ronghui Mu",
        "Yanghao Zhang",
        "Siqi Sun",
        "Tianle Zhang",
        "Changshun Wu",
        "Gaojie Jin",
        "Yi Qi",
        "Jinwei Hu",
        "Jie Meng",
        "Saddek Bensalem",
        "Xiaowei Huang"
      ],
      "abstract": "In the burgeoning field of Large Language Models (LLMs), developing a robust\nsafety mechanism, colloquially known as \"safeguards\" or \"guardrails\", has\nbecome imperative to ensure the ethical use of LLMs within prescribed\nboundaries. This article provides a systematic literature review on the current\nstatus of this critical mechanism. It discusses its major challenges and how it\ncan be enhanced into a comprehensive mechanism dealing with ethical issues in\nvarious contexts. First, the paper elucidates the current landscape of\nsafeguarding mechanisms that major LLM service providers and the open-source\ncommunity employ. This is followed by the techniques to evaluate, analyze, and\nenhance some (un)desirable properties that a guardrail might want to enforce,\nsuch as hallucinations, fairness, privacy, and so on. Based on them, we review\ntechniques to circumvent these controls (i.e., attacks), to defend the attacks,\nand to reinforce the guardrails. While the techniques mentioned above represent\nthe current status and the active research trends, we also discuss several\nchallenges that cannot be easily dealt with by the methods and present our\nvision on how to implement a comprehensive guardrail through the full\nconsideration of multi-disciplinary approach, neural-symbolic method, and\nsystems development lifecycle.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）的安全机制（guardrails），旨在确保LLMs在伦理边界内使用。论文系统回顾了当前的安全措施，包括主要提供者和开源社区的实践，以及评估和增强技术（如针对hallucinations、fairness和privacy等属性）。此外，它分析了潜在攻击、防御策略和强化方法，并指出现有挑战，提出通过多学科方法、神经符号方法和系统开发生命周期构建全面guardrail的愿景。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "under review. arXiv admin note: text overlap with arXiv:2402.01822",
      "pdf_url": "http://arxiv.org/pdf/2406.02622v1",
      "published_date": "2024-06-03 19:27:46 UTC",
      "updated_date": "2024-06-03 19:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:20:37.679824"
    },
    {
      "arxiv_id": "2406.06574v1",
      "title": "Towards Transparency: Exploring LLM Trainings Datasets through Visual Topic Modeling and Semantic Frame",
      "title_zh": "翻译失败",
      "authors": [
        "Charles de Dampierre",
        "Andrei Mogoutov",
        "Nicolas Baumard"
      ],
      "abstract": "LLMs are now responsible for making many decisions on behalf of humans: from\nanswering questions to classifying things, they have become an important part\nof everyday life. While computation and model architecture have been rapidly\nexpanding in recent years, the efforts towards curating training datasets are\nstill in their beginnings. This underappreciation of training datasets has led\nLLMs to create biased and low-quality content. In order to solve that issue, we\npresent Bunka, a software that leverages AI and Cognitive Science to improve\nthe refinement of textual datasets. We show how Topic Modeling coupled with\n2-dimensional Cartography can increase the transparency of datasets. We then\nshow how the same Topic Modeling techniques can be applied to Preferences\ndatasets to accelerate the fine-tuning process and increase the capacities of\nthe model on different benchmarks. Lastly, we show how using Frame Analysis can\ngive insights into existing biases in the training corpus. Overall, we argue\nthat we need better tools to explore and increase the quality and transparency\nof LLMs training datasets.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）的训练数据集问题，指出数据集的不足导致模型产生偏见和低质量内容，从而强调了提高透明度的必要性。作者引入了 Bunka 软件，该工具结合 AI 和认知科学，通过 Topic Modeling 与 2-dimensional Cartography 来提升数据集的透明度，并将这些技术应用于偏好数据集以加速微调过程和提升模型在基准测试中的性能。此外，使用 Frame Analysis 分析揭示了训练语料中的潜在偏见，主张开发更好的工具来优化 LLMs 训练数据集的质量和透明度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06574v1",
      "published_date": "2024-06-03 18:44:13 UTC",
      "updated_date": "2024-06-03 18:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:20:47.161929"
    },
    {
      "arxiv_id": "2406.01698v3",
      "title": "Demystifying AI Platform Design for Distributed Inference of Next-Generation LLM models",
      "title_zh": "揭秘下一代 LLM 模型分布式推理的 AI 平台设计",
      "authors": [
        "Abhimanyu Bambhaniya",
        "Ritik Raj",
        "Geonhwa Jeong",
        "Souvik Kundu",
        "Sudarshan Srinivasan",
        "Suvinay Subramanian",
        "Midhilesh Elavazhagan",
        "Madhu Kumar",
        "Tushar Krishna"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance across a wide\nrange of applications, often outperforming human experts. However, deploying\nthese gigantic models efficiently for diverse inference use cases requires\ncarefully designed hardware platforms with ample computing, memory, and network\nresources. With constant innovation in LLM serving optimizations and model\narchitecture evolving at breakneck speed, the hardware requirements to meet\nService Level Objectives (SLOs) remain an open research question.\n  To answer the question, we present an analytical tool, GenZ, to efficiently\nnavigate the relationship between diverse LLM model architectures(Dense, GQA,\nMoE, Mamba), LLM serving optimizations(Chunking, Speculative decoding,\nquanitization), and AI platform design parameters. Our tool estimates LLM\ninference performance metrics for the given scenario. We have validated against\nreal hardware platforms running various different LLM models, achieving a max\ngeomean error of 5.82.We use GenZ to identify compute, memory capacity, memory\nbandwidth, network latency, and network bandwidth requirements across diverse\nLLM inference use cases. We also study diverse architectural choices in use\ntoday (inspired by LLM serving platforms from several vendors) to help inform\ncomputer architects designing next-generation AI hardware accelerators and\nplatforms. The trends and insights derived from GenZ can guide AI engineers\ndeploying LLMs as well as computer architects designing next-generation\nhardware accelerators and platforms. Ultimately, this work sheds light on the\nplatform design considerations for unlocking the full potential of large\nlanguage models across a spectrum of applications. The source code is available\nat https://github.com/abhibambhaniya/GenZ-LLM-Analyzer . Users can also be\ntried it on at https://genz-llm-analyzer.streamlit.app/ without any setup on\nyour web browser.",
      "tldr_zh": "本论文探讨了部署下一代大型语言模型(LLMs)进行分布式推理的AI平台设计挑战，强调了硬件资源（如计算、内存和网络）的优化需求。作者引入了GenZ分析工具，该工具能够评估不同LLM架构(Dense、GQA、MoE、Mamba)和优化技术(Chunking、Speculative decoding、quantization)与平台参数之间的关系，并预测推理性能指标。经与真实硬件验证，GenZ的最大几何平均误差为5.82%，从而识别出各种推理场景下的计算容量、内存带宽、网络延迟和带宽要求。该研究为AI工程师部署LLMs以及计算机架构师设计下一代硬件加速器提供了关键洞见和指导趋势。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "19 Pages, https://github.com/abhibambhaniya/GenZ-LLM-Analyzer,\n  https://genz-llm-analyzer.streamlit.app/",
      "pdf_url": "http://arxiv.org/pdf/2406.01698v3",
      "published_date": "2024-06-03 18:00:50 UTC",
      "updated_date": "2025-05-15 02:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:22:52.350751"
    },
    {
      "arxiv_id": "2406.01662v2",
      "title": "Few-Shot Classification of Interactive Activities of Daily Living (InteractADL)",
      "title_zh": "翻译失败",
      "authors": [
        "Zane Durante",
        "Robathan Harries",
        "Edward Vendrow",
        "Zelun Luo",
        "Yuta Kyuragi",
        "Kazuki Kozuka",
        "Li Fei-Fei",
        "Ehsan Adeli"
      ],
      "abstract": "Understanding Activities of Daily Living (ADLs) is a crucial step for\ndifferent applications including assistive robots, smart homes, and healthcare.\nHowever, to date, few benchmarks and methods have focused on complex ADLs,\nespecially those involving multi-person interactions in home environments. In\nthis paper, we propose a new dataset and benchmark, InteractADL, for\nunderstanding complex ADLs that involve interaction between humans (and\nobjects). Furthermore, complex ADLs occurring in home environments comprise a\nchallenging long-tailed distribution due to the rarity of multi-person\ninteractions, and pose fine-grained visual recognition tasks due to the\npresence of semantically and visually similar classes. To address these issues,\nwe propose a novel method for fine-grained few-shot video classification called\nName Tuning that enables greater semantic separability by learning optimal\nclass name vectors. We show that Name Tuning can be combined with existing\nprompt tuning strategies to learn the entire input text (rather than only\nlearning the prompt or class names) and demonstrate improved performance for\nfew-shot classification on InteractADL and 4 other fine-grained visual\nclassification benchmarks. For transparency and reproducibility, we release our\ncode at https://github.com/zanedurante/vlm_benchmark.",
      "tldr_zh": "本论文提出InteractADL数据集和基准，用于理解涉及多人互动的复杂日常生活活动（ADLs），这些活动在家庭环境中呈现长尾分布和细粒度视觉识别挑战。针对这些问题，论文引入了一种新方法Name Tuning，通过学习最优类别名称向量来提升语义可分性，并将其与现有提示调整（Prompt Tuning）策略结合，实现在少样本视频分类中的整体输入文本学习。实验结果显示，Name Tuning在InteractADL以及其他4个细粒度视觉分类基准上显著提高了分类性能。最后，论文公开了代码以确保透明性和可重复性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01662v2",
      "published_date": "2024-06-03 17:59:55 UTC",
      "updated_date": "2024-10-16 23:00:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:21:11.265549"
    },
    {
      "arxiv_id": "2406.01592v2",
      "title": "Text-guided Controllable Mesh Refinement for Interactive 3D Modeling",
      "title_zh": "文本引导的可控",
      "authors": [
        "Yun-Chun Chen",
        "Selena Ling",
        "Zhiqin Chen",
        "Vladimir G. Kim",
        "Matheus Gadelha",
        "Alec Jacobson"
      ],
      "abstract": "We propose a novel technique for adding geometric details to an input coarse\n3D mesh guided by a text prompt. Our method is composed of three stages. First,\nwe generate a single-view RGB image conditioned on the input coarse geometry\nand the input text prompt. This single-view image generation step allows the\nuser to pre-visualize the result and offers stronger conditioning for\nsubsequent multi-view generation. Second, we use our novel multi-view normal\ngeneration architecture to jointly generate six different views of the normal\nimages. The joint view generation reduces inconsistencies and leads to sharper\ndetails. Third, we optimize our mesh with respect to all views and generate a\nfine, detailed geometry as output. The resulting method produces an output\nwithin seconds and offers explicit user control over the coarse structure,\npose, and desired details of the resulting 3D mesh.",
      "tldr_zh": "本文提出了一种基于文本提示的交互式 3D 建模技术，名为 Text-guided Controllable Mesh Refinement，用于在粗糙 3D 网格上添加几何细节。该方法分为三个阶段：首先生成单视图 RGB image 以预览结果并增强条件；其次采用多视图 normal generation 架构联合生成六个视图的法线图像，以减少不一致性和提升细节锐利度；最后通过针对所有视图优化网格，快速输出精细几何。整体方法在几秒内完成，提供用户对网格粗糙结构、姿态和细节的显式控制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "SIGGRAPH Asia 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01592v2",
      "published_date": "2024-06-03 17:59:43 UTC",
      "updated_date": "2024-09-11 00:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:21:27.274736"
    },
    {
      "arxiv_id": "2406.01588v1",
      "title": "nn2poly: An R Package for Converting Neural Networks into Interpretable Polynomials",
      "title_zh": "nn2poly：用于将神经网络转换为可解释多项式的 R 包",
      "authors": [
        "Pablo Morala",
        "Jenny Alexandra Cifuentes",
        "Rosa E. Lillo",
        "Iñaki Ucar"
      ],
      "abstract": "The nn2poly package provides the implementation in R of the NN2Poly method to\nexplain and interpret feed-forward neural networks by means of polynomial\nrepresentations that predict in an equivalent manner as the original\nnetwork.Through the obtained polynomial coefficients, the effect and importance\nof each variable and their interactions on the output can be represented. This\ncapabiltiy of capturing interactions is a key aspect usually missing from most\nExplainable Artificial Intelligence (XAI) methods, specially if they rely on\nexpensive computations that can be amplified when used on large neural\nnetworks. The package provides integration with the main deep learning\nframework packages in R (tensorflow and torch), allowing an user-friendly\napplication of the NN2Poly algorithm. Furthermore, nn2poly provides\nimplementation of the required weight constraints to be used during the network\ntraining in those same frameworks. Other neural networks packages can also be\nused by including their weights in list format. Polynomials obtained with\nnn2poly can also be used to predict with new data or be visualized through its\nown plot method. Simulations are provided exemplifying the usage of the package\nalongside with a comparison with other approaches available in R to interpret\nneural networks.",
      "tldr_zh": "nn2poly 是一个 R 包，实现了 NN2Poly 方法，将前馈神经网络转换为等效的多项式表示，从而提升网络的可解释性。\n通过多项式系数，用户可以分析每个变量及其交互对输出结果的影响，这弥补了传统 Explainable Artificial Intelligence (XAI) 方法在捕捉交互方面的不足，尤其适用于大型网络以避免高计算成本。\n该包与 R 中的 tensorflow 和 torch 框架无缝集成，提供权重约束、预测和可视化功能，并通过模拟示例与其它解释方法进行了比较。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01588v1",
      "published_date": "2024-06-03 17:59:30 UTC",
      "updated_date": "2024-06-03 17:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:21:36.522752"
    },
    {
      "arxiv_id": "2406.01586v2",
      "title": "ManiCM: Real-time 3D Diffusion Policy via Consistency Model for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Guanxing Lu",
        "Zifeng Gao",
        "Tianxing Chen",
        "Wenxun Dai",
        "Ziwei Wang",
        "Wenbo Ding",
        "Yansong Tang"
      ],
      "abstract": "Diffusion models have been verified to be effective in generating complex\ndistributions from natural images to motion trajectories. Recent\ndiffusion-based methods show impressive performance in 3D robotic manipulation\ntasks, whereas they suffer from severe runtime inefficiency due to multiple\ndenoising steps, especially with high-dimensional observations. To this end, we\npropose a real-time robotic manipulation model named ManiCM that imposes the\nconsistency constraint to the diffusion process, so that the model can generate\nrobot actions in only one-step inference. Specifically, we formulate a\nconsistent diffusion process in the robot action space conditioned on the point\ncloud input, where the original action is required to be directly denoised from\nany point along the ODE trajectory. To model this process, we design a\nconsistency distillation technique to predict the action sample directly\ninstead of predicting the noise within the vision community for fast\nconvergence in the low-dimensional action manifold. We evaluate ManiCM on 31\nrobotic manipulation tasks from Adroit and Metaworld, and the results\ndemonstrate that our approach accelerates the state-of-the-art method by 10\ntimes in average inference speed while maintaining competitive average success\nrate.",
      "tldr_zh": "该研究提出ManiCM，一种基于Consistency Model的实时3D扩散策略，用于机器人操作，以解决传统Diffusion Models在高维观察下多步去噪导致的运行效率问题。该模型在机器人动作空间中施加一致性约束，并通过Consistency Distillation技术直接从点云输入预测动作样本，实现一步推理。实验结果显示，在Adroit和Metaworld的31个机器人操作任务上，ManiCM将最先进方法的平均推理速度提高了10倍，同时保持了竞争性的平均成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "https://manicm-fast.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.01586v2",
      "published_date": "2024-06-03 17:59:23 UTC",
      "updated_date": "2025-03-26 09:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:23:07.410302"
    },
    {
      "arxiv_id": "2406.01661v2",
      "title": "A Diffusion Model Framework for Unsupervised Neural Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastian Sanokowski",
        "Sepp Hochreiter",
        "Sebastian Lehner"
      ],
      "abstract": "Learning to sample from intractable distributions over discrete sets without\nrelying on corresponding training data is a central problem in a wide range of\nfields, including Combinatorial Optimization. Currently, popular deep\nlearning-based approaches rely primarily on generative models that yield exact\nsample likelihoods. This work introduces a method that lifts this restriction\nand opens the possibility to employ highly expressive latent variable models\nlike diffusion models. Our approach is conceptually based on a loss that upper\nbounds the reverse Kullback-Leibler divergence and evades the requirement of\nexact sample likelihoods. We experimentally validate our approach in data-free\nCombinatorial Optimization and demonstrate that our method achieves a new\nstate-of-the-art on a wide range of benchmark problems.",
      "tldr_zh": "这篇论文提出了一种扩散模型（Diffusion Model）框架，用于无监督神经组合优化（Unsupervised Neural Combinatorial Optimization），旨在从不可处理的离散集合分布中采样，而不依赖训练数据。方法基于一个损失函数，该函数上界了反向 Kullback-Leibler divergence，避免了对精确样本似然的依赖，从而支持高度表达性的潜在变量模型。实验结果表明，该方法在多种无数据组合优化基准问题上达到了新的最先进（state-of-the-art）性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01661v2",
      "published_date": "2024-06-03 17:55:02 UTC",
      "updated_date": "2024-08-08 12:17:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:23:17.492977"
    },
    {
      "arxiv_id": "2406.01575v2",
      "title": "Contextual Bilevel Reinforcement Learning for Incentive Alignment",
      "title_zh": "上下文双层强化学习用于激励对齐",
      "authors": [
        "Vinzenz Thoma",
        "Barna Pasztor",
        "Andreas Krause",
        "Giorgia Ramponi",
        "Yifan Hu"
      ],
      "abstract": "The optimal policy in various real-world strategic decision-making problems\ndepends both on the environmental configuration and exogenous events. For these\nsettings, we introduce Contextual Bilevel Reinforcement Learning (CB-RL), a\nstochastic bilevel decision-making model, where the lower level consists of\nsolving a contextual Markov Decision Process (CMDP). CB-RL can be viewed as a\nStackelberg Game where the leader and a random context beyond the leader's\ncontrol together decide the setup of many MDPs that potentially multiple\nfollowers best respond to. This framework extends beyond traditional bilevel\noptimization and finds relevance in diverse fields such as RLHF, tax design,\nreward shaping, contract theory and mechanism design. We propose a stochastic\nHyper Policy Gradient Descent (HPGD) algorithm to solve CB-RL, and demonstrate\nits convergence. Notably, HPGD uses stochastic hypergradient estimates, based\non observations of the followers' trajectories. Therefore, it allows followers\nto use any training procedure and the leader to be agnostic of the specific\nalgorithm, which aligns with various real-world scenarios. We further consider\nthe setting when the leader can influence the training of followers and propose\nan accelerated algorithm. We empirically demonstrate the performance of our\nalgorithm for reward shaping and tax design.",
      "tldr_zh": "该论文引入了Contextual Bilevel Reinforcement Learning (CB-RL)，一个随机双层决策框架，用于处理依赖环境配置和外生事件的战略决策问题，如Stackelberg Game中领导者与随机上下文共同设置多个Markov Decision Process (MDP)。CB-RL扩展了传统双层优化，适用于RLHF、税收设计、奖励塑造等领域。作者提出Stochastic Hyper Policy Gradient Descent (HPGD)算法，利用跟随者轨迹的随机超梯度估计来实现收敛，并允许领导者对跟随者的训练过程保持 agnostic。实验结果显示，HPGD在奖励塑造和税收设计任务中表现出色，当领导者能影响跟随者训练时，还可通过加速算法进一步提升性能。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "math.OC",
      "comment": "60 pages, 21 Figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01575v2",
      "published_date": "2024-06-03 17:54:39 UTC",
      "updated_date": "2024-12-08 17:04:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:23:32.394803"
    },
    {
      "arxiv_id": "2406.01660v4",
      "title": "Self-Improving Robust Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Eugene Choi",
        "Arash Ahmadian",
        "Matthieu Geist",
        "Oilvier Pietquin",
        "Mohammad Gheshlaghi Azar"
      ],
      "abstract": "Online and offline RLHF methods, such as PPO and DPO, have been highly\nsuccessful in aligning AI with human preferences. Despite their success,\nhowever, these methods suffer from fundamental limitations: (a) Models trained\nwith RLHF can learn from mistakes or negative examples through RL mechanism or\ncontrastive loss during training. However, at inference time, they lack an\ninnate self-improvement mechanism for error corrections. (b) The optimal\nsolution of existing methods is highly task-dependent, making it difficult for\nthem to generalize to new tasks. To address these challenges, we propose\nSelf-Improving Robust Preference Optimization (SRPO), a practical and\nmathematically principled offline RLHF framework. The key idea behind SRPO is\nto cast the problem of learning from human preferences as a self-improvement\nprocess, mathematically formulated as a min-max objective that jointly\noptimizes a self-improvement policy and a generative policy in an adversarial\nfashion. Crucially, the solution for this optimization problem is independent\nof the training task, which makes it robust to its changes. We then show that\nthis objective can be reformulated as a non-adversarial offline loss, which can\nbe efficiently optimized using standard supervised learning techniques at\nscale. To demonstrate SRPO's effectiveness, we evaluate it using AI Win-Rate\n(WR) against human (GOLD) completions. When tested on the XSum dataset, SRPO\noutperforms DPO by a margin of 15% after 5 self revisions, achieving an\nimpressive 90% WR. Moreover, on the challenging Arena-Hard prompts, SRPO\noutperforms both DPO and IPO (by 4% without revision and 6% after a single\nrevision), reaching a 56% WR against against Llama-3.1-8B-Instruct.",
      "tldr_zh": "本研究针对现有RLHF方法（如PPO和DPO）的局限性，提出Self-Improving Robust Preference Optimization (SRPO)，一个离线RLHF框架，以解决模型在推理时缺乏自我改进机制以及对新任务泛化能力不足的问题。SRPO将学习人类偏好问题转化为一个min-max优化目标，通过对抗式训练联合优化自我改进策略和生成策略，使其解决方案独立于具体任务，从而增强鲁棒性。该框架可重构为非对抗的离线损失，利用标准监督学习技术高效优化；在实验中，SRPO在XSum数据集上经过5次自我修订比DPO高出15%，达到90%的AI Win-Rate (WR)；而在Arena-Hard提示上，无修订时比DPO和IPO高4%，单次修订后高6%，达到56%的WR对Llama-3.1-8B-Instruct。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01660v4",
      "published_date": "2024-06-03 17:53:25 UTC",
      "updated_date": "2025-04-11 23:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:23:44.977888"
    },
    {
      "arxiv_id": "2406.01562v1",
      "title": "A New View on Planning in Online Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Roice",
        "Parham Mohammad Panahi",
        "Scott M. Jordan",
        "Adam White",
        "Martha White"
      ],
      "abstract": "This paper investigates a new approach to model-based reinforcement learning\nusing background planning: mixing (approximate) dynamic programming updates and\nmodel-free updates, similar to the Dyna architecture. Background planning with\nlearned models is often worse than model-free alternatives, such as Double DQN,\neven though the former uses significantly more memory and computation. The\nfundamental problem is that learned models can be inaccurate and often generate\ninvalid states, especially when iterated many steps. In this paper, we avoid\nthis limitation by constraining background planning to a set of (abstract)\nsubgoals and learning only local, subgoal-conditioned models. This goal-space\nplanning (GSP) approach is more computationally efficient, naturally\nincorporates temporal abstraction for faster long-horizon planning and avoids\nlearning the transition dynamics entirely. We show that our GSP algorithm can\npropagate value from an abstract space in a manner that helps a variety of base\nlearners learn significantly faster in different domains.",
      "tldr_zh": "这篇论文提出了一种新的在线强化学习规划方法，名为目标空间规划(Goal-Space Planning, GSP)，通过将背景规划限制在抽象子目标上，并仅学习局部子目标条件模型，避免了传统学习模型的准确性和无效状态问题。相比于无模型方法如Double DQN，GSP方法更高效地整合了时间抽象(temporal abstraction)，无需学习完整的过渡动态，从而加速长 horizons 规划。实验结果显示，GSP算法能从抽象空间传播价值，帮助各种基础学习器在不同领域显著加快学习速度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Planning and Reinforcement Learning Workshop at\n  ICAPS 2024. arXiv admin note: text overlap with arXiv:2206.02902",
      "pdf_url": "http://arxiv.org/pdf/2406.01562v1",
      "published_date": "2024-06-03 17:45:19 UTC",
      "updated_date": "2024-06-03 17:45:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:24:04.379834"
    },
    {
      "arxiv_id": "2406.01561v4",
      "title": "Guided Score identity Distillation for Data-Free One-Step Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyuan Zhou",
        "Zhendong Wang",
        "Huangjie Zheng",
        "Hai Huang"
      ],
      "abstract": "Diffusion-based text-to-image generation models trained on extensive\ntext-image pairs have demonstrated the ability to produce photorealistic images\naligned with textual descriptions. However, a significant limitation of these\nmodels is their slow sample generation process, which requires iterative\nrefinement through the same network. To overcome this, we introduce a data-free\nguided distillation method that enables the efficient distillation of\npretrained Stable Diffusion models without access to the real training data,\noften restricted due to legal, privacy, or cost concerns. This method enhances\nScore identity Distillation (SiD) with Long and Short Classifier-Free Guidance\n(LSG), an innovative strategy that applies Classifier-Free Guidance (CFG) not\nonly to the evaluation of the pretrained diffusion model but also to the\ntraining and evaluation of the fake score network. We optimize a model-based\nexplicit score matching loss using a score-identity-based approximation\nalongside our proposed guidance strategies for practical computation. By\nexclusively training with synthetic images generated by its one-step generator,\nour data-free distillation method rapidly improves FID and CLIP scores,\nachieving state-of-the-art FID performance while maintaining a competitive CLIP\nscore. Notably, the one-step distillation of Stable Diffusion 1.5 achieves an\nFID of 8.15 on the COCO-2014 validation set, a record low value under the\ndata-free setting. Our code and checkpoints are available at\nhttps://github.com/mingyuanzhou/SiD-LSG.",
      "tldr_zh": "该研究提出了一种数据无关（data-free）的引导蒸馏方法，用于优化文本到图像生成模型，解决扩散模型如 Stable Diffusion 的慢速迭代问题。方法通过增强 Score identity Distillation (SiD) 技术，引入 Long and Short Classifier-Free Guidance (LSG) 策略，将 Classifier-Free Guidance (CFG) 应用于预训练模型的评估、假分数网络的训练和评估，并优化基于 score-identity 的显式分数匹配损失。实验结果显示，该方法仅使用合成图像训练，即可显著提升生成效率和质量，在 COCO-2014 验证集上实现 FID 8.15 的 state-of-the-art 性能，同时保持竞争性的 CLIP 分数。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025; fixed typos in Table 1; Code and model checkpoints\n  available at https://github.com/mingyuanzhou/SiD-LSG; More efficient code\n  using AMP is coming soon",
      "pdf_url": "http://arxiv.org/pdf/2406.01561v4",
      "published_date": "2024-06-03 17:44:11 UTC",
      "updated_date": "2025-02-08 17:46:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:24:05.820081"
    },
    {
      "arxiv_id": "2406.01552v1",
      "title": "Learning equivariant tensor functions with applications to sparse vector recovery",
      "title_zh": "学习等变张量函数及其在稀疏向量恢复中的应用",
      "authors": [
        "Wilson G. Gregory",
        "Josué Tonelli-Cueto",
        "Nicholas F. Marshall",
        "Andrew S. Lee",
        "Soledad Villar"
      ],
      "abstract": "This work characterizes equivariant polynomial functions from tuples of\ntensor inputs to tensor outputs. Loosely motivated by physics, we focus on\nequivariant functions with respect to the diagonal action of the orthogonal\ngroup on tensors. We show how to extend this characterization to other linear\nalgebraic groups, including the Lorentz and symplectic groups.\n  Our goal behind these characterizations is to define equivariant machine\nlearning models. In particular, we focus on the sparse vector estimation\nproblem. This problem has been broadly studied in the theoretical computer\nscience literature, and explicit spectral methods, derived by techniques from\nsum-of-squares, can be shown to recover sparse vectors under certain\nassumptions. Our numerical results show that the proposed equivariant machine\nlearning models can learn spectral methods that outperform the best\ntheoretically known spectral methods in some regimes. The experiments also\nsuggest that learned spectral methods can solve the problem in settings that\nhave not yet been theoretically analyzed.\n  This is an example of a promising direction in which theory can inform\nmachine learning models and machine learning models could inform theory.",
      "tldr_zh": "本研究表征了张量输入到张量输出的等变多项式函数，特别是针对正交群的对角作用，并扩展到其他线性代数群如洛伦兹群和辛群，旨在为等变机器学习模型提供理论基础。论文将这些表征应用于稀疏向量恢复问题，通过学习等变模型来开发谱方法(Spectral methods)，这些方法在某些条件下优于现有理论方法。实验结果显示，该模型不仅在已知场景中提升性能，还能在尚未理论分析的设置中有效恢复稀疏向量，体现了理论与机器学习之间的互惠关系。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01552v1",
      "published_date": "2024-06-03 17:32:43 UTC",
      "updated_date": "2024-06-03 17:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:24:17.913008"
    },
    {
      "arxiv_id": "2406.01549v2",
      "title": "An Information Bottleneck Perspective for Effective Noise Filtering on Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Zhu",
        "Xiaocheng Feng",
        "Xiyuan Du",
        "Yuxuan Gu",
        "Weijiang Yu",
        "Haotian Wang",
        "Qianglong Chen",
        "Zheng Chu",
        "Jingchang Chen",
        "Bing Qin"
      ],
      "abstract": "Retrieval-augmented generation integrates the capabilities of large language\nmodels with relevant information retrieved from an extensive corpus, yet\nencounters challenges when confronted with real-world noisy data. One recent\nsolution is to train a filter module to find relevant content but only achieve\nsuboptimal noise compression. In this paper, we propose to introduce the\ninformation bottleneck theory into retrieval-augmented generation. Our approach\ninvolves the filtration of noise by simultaneously maximizing the mutual\ninformation between compression and ground output, while minimizing the mutual\ninformation between compression and retrieved passage. In addition, we derive\nthe formula of information bottleneck to facilitate its application in novel\ncomprehensive evaluations, the selection of supervised fine-tuning data, and\nthe construction of reinforcement learning rewards. Experimental results\ndemonstrate that our approach achieves significant improvements across various\nquestion answering datasets, not only in terms of the correctness of answer\ngeneration but also in the conciseness with $2.5\\%$ compression rate.",
      "tldr_zh": "本文从信息瓶颈（Information Bottleneck）理论视角出发，解决检索增强生成（Retrieval-Augmented Generation）中噪声数据的过滤问题。方法通过最大化压缩内容与ground output之间的互信息，同时最小化压缩内容与检索段落之间的互信息，实现有效的噪声压缩。论文还导出了信息瓶颈公式，用于全面评估、监督微调数据选择和强化学习奖励构建。实验结果显示，该方法在多种问答数据集上显著提升了答案生成的正确性和简洁性，实现了2.5%的压缩率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01549v2",
      "published_date": "2024-06-03 17:31:06 UTC",
      "updated_date": "2024-07-04 14:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:24:30.514761"
    },
    {
      "arxiv_id": "2406.01548v3",
      "title": "How to discretize continuous state-action spaces in Q-learning: A symbolic control approach",
      "title_zh": "如何在 Q 学习中离散化连续状态-动作空间：一种符号控制方法",
      "authors": [
        "Sadek Belamfedel Alaoui",
        "Adnane Saoud"
      ],
      "abstract": "Q-learning is widely recognized as an effective approach for synthesizing\ncontrollers to achieve specific goals. However, handling challenges posed by\ncontinuous state-action spaces remains an ongoing research focus. This paper\npresents a systematic analysis that highlights a major drawback in space\ndiscretization methods. To address this challenge, the paper proposes a\nsymbolic model that represents behavioral relations, such as alternating\nsimulation from abstraction to the controlled system. This relation allows for\nseamless application of the synthesized controller based on abstraction to the\noriginal system. Introducing a novel Q-learning technique for symbolic models,\nthe algorithm yields two Q-tables encoding optimal policies. Theoretical\nanalysis demonstrates that these Q-tables serve as both upper and lower bounds\non the Q-values of the original system with continuous spaces. Additionally,\nthe paper explores the correlation between the parameters of the space\nabstraction and the loss in Q-values. The resulting algorithm facilitates\nachieving optimality within an arbitrary accuracy, providing control over the\ntrade-off between accuracy and computational complexity. The obtained results\nprovide valuable insights for selecting appropriate learning parameters and\nrefining the controller. The engineering relevance of the proposed Q-learning\nbased symbolic model is illustrated through two case studies.",
      "tldr_zh": "这篇论文分析了 Q-learning 在处理连续状态-动作空间时的挑战，特别是现有空间离散化方法的缺点，并提出了一种基于符号模型（symbolic model）的控制方法，利用行为关系如交替模拟（alternating simulation）来桥接抽象系统与原系统。论文引入了一种新型 Q-learning 技术，生成两个 Q-tables 来编码最优策略，这些 Q-tables 理论上分别作为原系统 Q-值的上界和下界。研究还探讨了空间抽象参数与 Q-值损失的相关性，允许用户在任意精度内实现最优性，同时平衡精度和计算复杂度，并通过两个案例研究展示了该方法的工程应用价值。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "math.DS"
      ],
      "primary_category": "eess.SY",
      "comment": "Q-learning, Symbolic control, Abstraction",
      "pdf_url": "http://arxiv.org/pdf/2406.01548v3",
      "published_date": "2024-06-03 17:30:42 UTC",
      "updated_date": "2024-06-05 22:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:24:43.283733"
    },
    {
      "arxiv_id": "2406.01544v2",
      "title": "Validity Learning on Failures: Mitigating the Distribution Shift in Autonomous Vehicle Planning",
      "title_zh": "基于失败的有效性学习：缓解自动驾驶车辆规划中的分布偏移",
      "authors": [
        "Fazel Arasteh",
        "Mohammed Elmahgiubi",
        "Behzad Khamidehi",
        "Hamidreza Mirkhani",
        "Weize Zhang",
        "Cao Tongtong",
        "Kasra Rezaee"
      ],
      "abstract": "The planning problem constitutes a fundamental aspect of the autonomous\ndriving framework. Recent strides in representation learning have empowered\nvehicles to comprehend their surrounding environments, thereby facilitating the\nintegration of learning-based planning strategies. Among these approaches,\nImitation Learning stands out due to its notable training efficiency. However,\ntraditional Imitation Learning methodologies encounter challenges associated\nwith the co-variate shift phenomenon. We propose Validity Learning on Failures,\nVL(on failure), as a remedy to address this issue. The essence of our method\nlies in deploying a pre-trained planner across diverse scenarios. Instances\nwhere the planner deviates from its immediate objectives, such as maintaining a\nsafe distance from obstacles or adhering to traffic rules, are flagged as\nfailures. The states corresponding to these failures are compiled into a new\ndataset, termed the failure dataset. Notably, the absence of expert annotations\nfor this data precludes the applicability of standard imitation learning\napproaches. To facilitate learning from the closed-loop mistakes, we introduce\nthe VL objective which aims to discern valid trajectories within the current\nenvironmental context. Experimental evaluations conducted on both reactive\nCARLA simulation and non-reactive log-replay simulations reveal substantial\nenhancements in closed-loop metrics such as \\textit{Score, Progress}, and\nSuccess Rate, underscoring the effectiveness of the proposed methodology.\nFurther evaluations against the Bench2Drive benchmark demonstrate that VL(on\nfailure) outperforms the state-of-the-art methods by a large margin.",
      "tldr_zh": "本研究针对自动驾驶规划中的分布偏移问题（co-variate shift），提出了Validity Learning on Failures（VL(on failure)）方法，以缓解Imitation Learning的传统挑战。该方法通过在多样场景中部署预训练规划器，识别失败实例（如未保持安全距离或违反交通规则），并创建失败数据集，然后引入VL目标来区分当前环境中的有效轨迹。实验结果显示，在CARLA模拟和Bench2Drive基准测试中，该方法显著提升了闭环指标，包括Score、Progress和Success Rate，并大幅优于现有最先进方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01544v2",
      "published_date": "2024-06-03 17:25:18 UTC",
      "updated_date": "2024-09-23 19:47:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:25:04.622772"
    },
    {
      "arxiv_id": "2406.01538v2",
      "title": "What Are Large Language Models Mapping to in the Brain? A Case Against Over-Reliance on Brain Scores",
      "title_zh": "大型语言模型在大脑中映射到什么？反对过度依赖脑分数的案例",
      "authors": [
        "Ebrahim Feghhi",
        "Nima Hadidi",
        "Bryan Song",
        "Idan A. Blank",
        "Jonathan C. Kao"
      ],
      "abstract": "Given the remarkable capabilities of large language models (LLMs), there has\nbeen a growing interest in evaluating their similarity to the human brain. One\napproach towards quantifying this similarity is by measuring how well a model\npredicts neural signals, also called \"brain score\". Internal representations\nfrom LLMs achieve state-of-the-art brain scores, leading to speculation that\nthey share computational principles with human language processing. This\ninference is only valid if the subset of neural activity predicted by LLMs\nreflects core elements of language processing. Here, we question this\nassumption by analyzing three neural datasets used in an impactful study on\nLLM-to-brain mappings, with a particular focus on an fMRI dataset where\nparticipants read short passages. We first find that when using shuffled\ntrain-test splits, as done in previous studies with these datasets, a trivial\nfeature that encodes temporal autocorrelation not only outperforms LLMs but\nalso accounts for the majority of neural variance that LLMs explain. We\ntherefore use contiguous splits moving forward. Second, we explain the\nsurprisingly high brain scores of untrained LLMs by showing they do not account\nfor additional neural variance beyond two simple features: sentence length and\nsentence position. This undermines evidence used to claim that the transformer\narchitecture biases computations to be more brain-like. Third, we find that\nbrain scores of trained LLMs on this dataset can largely be explained by\nsentence length, position, and pronoun-dereferenced static word embeddings; a\nsmall, additional amount is explained by sense-specific embeddings and\ncontextual representations of sentence structure. We conclude that\nover-reliance on brain scores can lead to over-interpretations of similarity\nbetween LLMs and brains, and emphasize the importance of deconstructing what\nLLMs are mapping to in neural signals.",
      "tldr_zh": "该研究质疑了使用“brain scores”（脑分数）来评估大型语言模型（LLMs）与人类大脑相似性的可靠性，指出这种方法可能过度依赖简单特征而非核心语言处理原理。通过分析三个神经数据集，特别是fMRI数据集，作者发现随机训练测试分割时，一个编码时间自相关的琐碎特征不仅优于LLMs，还解释了大部分神经方差。进一步实验显示，未训练LLMs的高脑分数主要由句子长度和位置等简单特征驱动，而训练LLMs的脑分数也可由这些特征加上静态词嵌入和上下文表示解释。作者强调，过度依赖脑分数可能导致对LLMs与大脑映射的过度解读，呼吁更深入地分解神经信号中的相关性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures in the main paper",
      "pdf_url": "http://arxiv.org/pdf/2406.01538v2",
      "published_date": "2024-06-03 17:13:27 UTC",
      "updated_date": "2024-06-20 20:35:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:25:18.053109"
    },
    {
      "arxiv_id": "2406.06572v2",
      "title": "Graph Neural Network Enhanced Retrieval for Question Answering of LLMs",
      "title_zh": "图神经网络增强检索用于大型语言模型的问答系统",
      "authors": [
        "Zijian Li",
        "Qingyan Guo",
        "Jiawei Shao",
        "Lei Song",
        "Jiang Bian",
        "Jun Zhang",
        "Rui Wang"
      ],
      "abstract": "Retrieval augmented generation has revolutionized large language model (LLM)\noutputs by providing factual supports. Nevertheless, it struggles to capture\nall the necessary knowledge for complex reasoning questions. Existing retrieval\nmethods typically divide reference documents into passages, treating them in\nisolation. These passages, however, are often interrelated, such as passages\nthat are contiguous or share the same keywords. Therefore, it is crucial to\nrecognize such relatedness for enhancing the retrieval process. In this paper,\nwe propose a novel retrieval method, called GNN-Ret, which leverages graph\nneural networks (GNNs) to enhance retrieval by exploiting the relatedness\nbetween passages. Specifically, we first construct a graph of passages by\nconnecting passages that are structure-related or keyword-related. A graph\nneural network (GNN) is then leveraged to exploit the relationships between\npassages and improve the retrieval of supporting passages. Furthermore, we\nextend our method to handle multi-hop reasoning questions using a recurrent\ngraph neural network (RGNN), named RGNN-Ret. At each step, RGNN-Ret integrates\nthe graphs of passages from previous steps, thereby enhancing the retrieval of\nsupporting passages. Extensive experiments on benchmark datasets demonstrate\nthat GNN-Ret achieves higher accuracy for question answering with a single\nquery of LLMs than strong baselines that require multiple queries, and RGNN-Ret\nfurther improves accuracy and achieves state-of-the-art performance, with up to\n10.4% accuracy improvement on the 2WikiMQA dataset.",
      "tldr_zh": "该论文针对检索增强生成（Retrieval Augmented Generation）在处理复杂推理问题时的知识捕获不足问题，提出了一种新型检索方法GNN-Ret，利用Graph Neural Network (GNN)来利用段落间的相关性（如结构或关键词关联）。具体方法包括构建段落图并通过GNN改进支持段落的检索，同时扩展为RGNN-Ret，使用Recurrent Graph Neural Network (RGNN)处理多跳推理问题，通过整合前一步的图来提升检索准确性。实验结果显示，GNN-Ret在单查询下比强基线模型表现更好，而RGNN-Ret进一步提升了准确率，在2WikiMQA数据集上实现了高达10.4%的改进，达到最先进水平。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2406.06572v2",
      "published_date": "2024-06-03 17:07:46 UTC",
      "updated_date": "2024-10-18 08:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:25:30.485636"
    },
    {
      "arxiv_id": "2406.02618v2",
      "title": "Immunocto: a massive immune cell database auto-generated for histopathology",
      "title_zh": "Immunocto：一个庞大的自动生成免疫细胞数据库，用于组织病理学",
      "authors": [
        "Mikaël Simard",
        "Zhuoyan Shen",
        "Konstantin Bräutigam",
        "Rasha Abu-Eid",
        "Maria A. Hawkins",
        "Charles-Antoine Collins-Fekete"
      ],
      "abstract": "With the advent of novel cancer treatment options such as immunotherapy,\nstudying the tumour immune micro-environment (TIME) is crucial to inform on\nprognosis and understand potential response to therapeutic agents. A key\napproach to characterising the TIME may be through combining (1) digitised\nmicroscopic high-resolution optical images of hematoxylin and eosin (H&E)\nstained tissue sections obtained in routine histopathology examinations with\n(2) automated immune cell detection and classification methods. In this work,\nwe introduce a workflow to automatically generate robust single cell contours\nand labels from dually stained tissue sections with H&E and multiplexed\nimmunofluorescence (IF) markers. The approach harnesses the Segment Anything\nModel and requires minimal human intervention compared to existing single cell\ndatabases. With this methodology, we create Immunocto, a massive, multi-million\nautomatically generated database of 6,848,454 human cells and objects,\nincluding 2,282,818 immune cells distributed across 4 subtypes: CD4$^+$ T cell\nlymphocytes, CD8$^+$ T cell lymphocytes, CD20$^+$ B cell lymphocytes, and\nCD68$^+$/CD163$^+$ macrophages. For each cell, we provide a 64$\\times$64\npixels$^2$ H&E image at $\\mathbf{40}\\times$ magnification, along with a binary\nmask of the nucleus and a label. The database, which is made publicly\navailable, can be used to train models to study the TIME on routine H&E slides.\nWe show that deep learning models trained on Immunocto result in\nstate-of-the-art performance for lymphocyte detection. The approach\ndemonstrates the benefits of using matched H&E and IF data to generate robust\ndatabases for computational pathology applications.",
      "tldr_zh": "本研究引入了Immunocto，一种大规模免疫细胞数据库，通过自动化工作流程从H&E染色和multiplexed immunofluorescence (IF)标记的组织切片中生成单细胞轮廓和标签，利用Segment Anything Model实现最小的人工干预。数据库包含6,848,454个人类细胞和物体，其中包括2,282,818个免疫细胞，分为CD4+ T细胞、CD8+ T细胞、CD20+ B细胞和CD68+/CD163+巨噬细胞等4个亚型，并为每个细胞提供64×64像素的H&E图像、核二进制掩码和标签。实验结果显示，使用Immunocto训练的深度学习模型在淋巴细胞检测上达到了state-of-the-art性能，为研究Tumor Immune Micro-environment (TIME)和在常规H&E切片上应用计算病理学提供了强大工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02618v2",
      "published_date": "2024-06-03 17:03:58 UTC",
      "updated_date": "2025-02-28 11:06:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:25:53.034697"
    },
    {
      "arxiv_id": "2406.01514v3",
      "title": "Decoupled Alignment for Robust Plug-and-Play Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Haozheng Luo",
        "Jiahao Yu",
        "Wenxin Zhang",
        "Jialong Li",
        "Jerry Yao-Chieh Hu",
        "Xinyu Xing",
        "Han Liu"
      ],
      "abstract": "We introduce a low-resource safety enhancement method for aligning large\nlanguage models (LLMs) without the need for supervised fine-tuning (SFT) or\nreinforcement learning from human feedback (RLHF). Our main idea is to exploit\nknowledge distillation to extract the alignment information from existing\nwell-aligned LLMs and integrate it into unaligned LLMs in a plug-and-play\nfashion. Methodology, we employ delta debugging to identify the critical\ncomponents of knowledge necessary for effective distillation. On the harmful\nquestion dataset, our method significantly enhances the average defense success\nrate by approximately 14.41%, reaching as high as 51.39%, in 17 unaligned\npre-trained LLMs, without compromising performance.",
      "tldr_zh": "本研究提出了一种低资源安全增强方法，用于对齐大型语言模型 (LLMs)，无需监督微调 (SFT) 或强化学习从人类反馈 (RLHF)。该方法通过知识蒸馏 (knowledge distillation) 从已对齐的 LLMs 中提取对齐信息，并利用 delta debugging 识别关键组件，以 plug-and-play 方式整合到未对齐的 LLMs 中。实验结果显示，在有害问题数据集上，该方法将 17 个未对齐预训练 LLMs 的平均防御成功率提高了约 14.41%，最高达 51.39%，同时不损害模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01514v3",
      "published_date": "2024-06-03 16:46:18 UTC",
      "updated_date": "2024-06-06 04:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:25:56.073925"
    },
    {
      "arxiv_id": "2406.06571v5",
      "title": "SUBLLM: A Novel Efficient Architecture with Token Sequence Subsampling for LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Quandong Wang",
        "Yuxuan Yuan",
        "Xiaoyu Yang",
        "Ruike Zhang",
        "Kang Zhao",
        "Wei Liu",
        "Jian Luan",
        "Daniel Povey",
        "Bin Wang"
      ],
      "abstract": "While Large Language Models (LLMs) have achieved remarkable success in\nvarious fields, the efficiency of training and inference remains a major\nchallenge. To address this issue, we propose SUBLLM, short for\nSubsampling-Upsampling-Bypass Large Language Model, an innovative architecture\nthat extends the core decoder-only framework by incorporating subsampling,\nupsampling, and bypass modules. The subsampling modules are responsible for\nshortening the sequence, while the upsampling modules restore the sequence\nlength, and the bypass modules enhance convergence. In comparison to LLaMA, the\nproposed SUBLLM exhibits significant enhancements in both training and\ninference speeds as well as memory usage, while maintaining competitive\nfew-shot performance. During training, SUBLLM increases speeds by 26% and cuts\nmemory by 10GB per GPU. In inference, it boosts speeds by up to 37% and reduces\nmemory by 1GB per GPU. The training and inference speeds can be enhanced by 34%\nand 52% respectively when the context window is expanded to 8192. Our code is\navailable at https://github.com/XiaoMi/subllm.",
      "tldr_zh": "本文提出SUBLLM，一种创新的Large Language Models (LLMs)架构，通过token序列subsampling、upsampling和bypass模块扩展了传统的decoder-only框架，以提升训练和推理效率。Subsampling模块负责缩短序列长度，upsampling模块恢复序列，而bypass模块增强模型收敛。相比LLaMA，SUBLLM在训练中速度提高26%并减少10GB/GPU内存，在推理中速度提升37%并节省1GB/GPU内存；当上下文窗口扩展到8192时，训练和推理速度可分别提高34%和52%，同时保持竞争性的few-shot performance。开源代码可访问https://github.com/XiaoMi/subllm。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures, accepted by ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06571v5",
      "published_date": "2024-06-03 16:43:04 UTC",
      "updated_date": "2024-08-23 08:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:26:07.027013"
    },
    {
      "arxiv_id": "2406.01506v3",
      "title": "The Geometry of Categorical and Hierarchical Concepts in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kiho Park",
        "Yo Joong Choe",
        "Yibo Jiang",
        "Victor Veitch"
      ],
      "abstract": "The linear representation hypothesis is the informal idea that semantic\nconcepts are encoded as linear directions in the representation spaces of large\nlanguage models (LLMs). Previous work has shown how to make this notion precise\nfor representing binary concepts that have natural contrasts (e.g., {male,\nfemale}) as directions in representation space. However, many natural concepts\ndo not have natural contrasts (e.g., whether the output is about an animal). In\nthis work, we show how to extend the formalization of the linear representation\nhypothesis to represent features (e.g., is_animal) as vectors. This allows us\nto immediately formalize the representation of categorical concepts as\npolytopes in the representation space. Further, we use the formalization to\nprove a relationship between the hierarchical structure of concepts and the\ngeometry of their representations. We validate these theoretical results on the\nGemma and LLaMA-3 large language models, estimating representations for 900+\nhierarchically related concepts using data from WordNet.",
      "tldr_zh": "本研究扩展了线性表示假设（linear representation hypothesis），将语义概念在大型语言模型（LLMs）表示空间中的表示从有自然对比的二元概念（如{male, female}）扩展到无自然对比的特征（如 is_animal），形式化为向量和多面体（polytopes）。作者证明了概念的层次结构与它们在表示空间中的几何关系，并将分类概念形式化为多面体。实验在 Gemma 和 LLaMA-3 模型上使用 WordNet 中的900+ 层次相关概念进行验证，证实了这些理论结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for an oral presentation at ICLR 2025. Best Paper Award at\n  the ICML 2024 Workshop on Mechanistic Interpretability. Code is available at\n  https://github.com/KihoPark/LLM_Categorical_Hierarchical_Representations",
      "pdf_url": "http://arxiv.org/pdf/2406.01506v3",
      "published_date": "2024-06-03 16:34:01 UTC",
      "updated_date": "2025-02-18 02:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:26:17.103920"
    },
    {
      "arxiv_id": "2406.16906v1",
      "title": "REST: Efficient and Accelerated EEG Seizure Analysis through Residual State Updates",
      "title_zh": "翻译失败",
      "authors": [
        "Arshia Afzal",
        "Grigorios Chrysos",
        "Volkan Cevher",
        "Mahsa Shoaran"
      ],
      "abstract": "EEG-based seizure detection models face challenges in terms of inference\nspeed and memory efficiency, limiting their real-time implementation in\nclinical devices. This paper introduces a novel graph-based residual state\nupdate mechanism (REST) for real-time EEG signal analysis in applications such\nas epileptic seizure detection. By leveraging a combination of graph neural\nnetworks and recurrent structures, REST efficiently captures both non-Euclidean\ngeometry and temporal dependencies within EEG data. Our model demonstrates high\naccuracy in both seizure detection and classification tasks. Notably, REST\nachieves a remarkable 9-fold acceleration in inference speed compared to\nstate-of-the-art models, while simultaneously demanding substantially less\nmemory than the smallest model employed for this task. These attributes\nposition REST as a promising candidate for real-time implementation in clinical\ndevices, such as Responsive Neurostimulation or seizure alert systems.",
      "tldr_zh": "本论文提出了一种高效的 EEG 癫痫发作分析机制 REST，通过基于图的残差状态更新（residual state updates）来解决现有模型在推理速度和内存效率上的挑战。REST 结合 graph neural networks 和 recurrent structures，有效捕捉 EEG 数据中的非欧几何和时间依赖性，从而实现高准确性的癫痫发作检测和分类。实验结果显示，REST 比最先进模型推理速度提高了 9 倍，同时大幅减少内存需求，使其成为临床设备如 Responsive Neurostimulation 或癫痫警报系统的理想实时实现方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted paper at International Confrence on Machine Learning (ICML\n  2024). Visit our website: https://arshiaafzal.github.io/REST/",
      "pdf_url": "http://arxiv.org/pdf/2406.16906v1",
      "published_date": "2024-06-03 16:30:19 UTC",
      "updated_date": "2024-06-03 16:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:26:40.952470"
    },
    {
      "arxiv_id": "2406.12888v1",
      "title": "A Space Group Symmetry Informed Network for O(3) Equivariant Crystal Tensor Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Keqiang Yan",
        "Alexandra Saxton",
        "Xiaofeng Qian",
        "Xiaoning Qian",
        "Shuiwang Ji"
      ],
      "abstract": "We consider the prediction of general tensor properties of crystalline\nmaterials, including dielectric, piezoelectric, and elastic tensors. A key\nchallenge here is how to make the predictions satisfy the unique tensor\nequivariance to O(3) group and invariance to crystal space groups. To this end,\nwe propose a General Materials Tensor Network (GMTNet), which is carefully\ndesigned to satisfy the required symmetries. To evaluate our method, we curate\na dataset and establish evaluation metrics that are tailored to the intricacies\nof crystal tensor predictions. Experimental results show that our GMTNet not\nonly achieves promising performance on crystal tensors of various orders but\nalso generates predictions fully consistent with the intrinsic crystal\nsymmetries. Our code is publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS).",
      "tldr_zh": "该论文针对晶体材料的张量属性预测（如介电、压电和弹性张量）提出了一种 General Materials Tensor Network (GMTNet)，该网络基于空间群对称性设计，确保预测满足 O(3) 等变性和晶体空间群不变性。GMTNet 通过精心构建的结构，不仅实现了各种阶张量的精确预测，还确保输出完全符合晶体固有对称性。为评估该方法，作者创建了专用数据集和指标，实验结果显示其性能优于基线模型，且代码已开源在 AIRS 库（https://github.com/divelab/AIRS）。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.atom-ph"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "This paper has been accepted to ICML 24 as a poster. You are\n  encouraged to cite the conference version of this paper",
      "pdf_url": "http://arxiv.org/pdf/2406.12888v1",
      "published_date": "2024-06-03 16:26:16 UTC",
      "updated_date": "2024-06-03 16:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:26:42.723761"
    },
    {
      "arxiv_id": "2406.01481v1",
      "title": "Learning from Streaming Data when Users Choose",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyan Su",
        "Sarah Dean"
      ],
      "abstract": "In digital markets comprised of many competing services, each user chooses\nbetween multiple service providers according to their preferences, and the\nchosen service makes use of the user data to incrementally improve its model.\nThe service providers' models influence which service the user will choose at\nthe next time step, and the user's choice, in return, influences the model\nupdate, leading to a feedback loop. In this paper, we formalize the above\ndynamics and develop a simple and efficient decentralized algorithm to locally\nminimize the overall user loss. Theoretically, we show that our algorithm\nasymptotically converges to stationary points of of the overall loss almost\nsurely. We also experimentally demonstrate the utility of our algorithm with\nreal world data.",
      "tldr_zh": "本研究探讨了数字市场中，用户根据偏好选择服务提供者时形成的反馈 loop，用户选择会影响服务模型的更新，而模型又反向影响未来选择。论文形式化了这一动态，并提出一个简单、高效的 decentralized algorithm，用于局部最小化整体用户损失。理论上，该算法几乎肯定地渐进收敛到整体损失的 stationary points。实验结果使用真实数据证明了算法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML24",
      "pdf_url": "http://arxiv.org/pdf/2406.01481v1",
      "published_date": "2024-06-03 16:07:52 UTC",
      "updated_date": "2024-06-03 16:07:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:26:53.381991"
    },
    {
      "arxiv_id": "2406.16905v1",
      "title": "Optimising Random Forest Machine Learning Algorithms for User VR Experience Prediction Based on Iterative Local Search-Sparrow Search Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Xirui Tang",
        "Feiyang Li",
        "Zinan Cao",
        "Qixuan Yu",
        "Yulu Gong"
      ],
      "abstract": "In this paper, an improved method for VR user experience prediction is\ninvestigated by introducing a sparrow search algorithm and a random forest\nalgorithm improved by an iterative local search-optimised sparrow search\nalgorithm. The study firstly conducted a statistical analysis of the data, and\nthen trained and tested using the traditional random forest model, the random\nforest model improved by the sparrow search algorithm, and the random forest\nalgorithm improved based on the iterative local search-sparrow search\nalgorithm, respectively. The results show that the traditional random forest\nmodel has a prediction accuracy of 93% on the training set but only 73.3% on\nthe test set, which is poor in generalisation; whereas the model improved by\nthe sparrow search algorithm has a prediction accuracy of 94% on the test set,\nwhich is improved compared with the traditional model. What is more noteworthy\nis that the improved model based on the iterative local search-sparrow search\nalgorithm achieves 100% accuracy on both the training and test sets, which is\nsignificantly better than the other two methods. These research results provide\nnew ideas and methods for VR user experience prediction, especially the\nimproved model based on the iterative local search-sparrow search algorithm\nperforms well and is able to more accurately predict and classify the user's VR\nexperience. In the future, the application of this method in other fields can\nbe further explored, and its effectiveness can be verified through real cases\nto promote the development of AI technology in the field of user experience.",
      "tldr_zh": "本研究优化了Random Forest机器学习算法，用于预测VR用户体验，引入了Sparrow Search Algorithm（SSA）和基于Iterative Local Search（ILS）优化的SSA方法。实验比较了传统Random Forest模型（训练集准确率93%、测试集73.3%）、SSA改进模型（测试集94%）以及ILS-SSA改进模型（训练集和测试集均达100%准确率），后者显著提升了预测准确性和泛化能力。这些结果为VR用户体验预测提供了新思路，并建议未来扩展到其他领域以验证其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16905v1",
      "published_date": "2024-06-03 15:58:26 UTC",
      "updated_date": "2024-06-03 15:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:27:07.007033"
    },
    {
      "arxiv_id": "2406.01468v2",
      "title": "Understanding Token Probability Encoding in Output Embeddings",
      "title_zh": "理解输出嵌入中的标记概率编码",
      "authors": [
        "Hakaze Cho",
        "Yoshihiro Sakai",
        "Kenshiro Tanaka",
        "Mariko Kato",
        "Naoya Inoue"
      ],
      "abstract": "In this paper, we investigate the output token probability information in the\noutput embedding of language models. We find an approximate common log-linear\nencoding of output token probabilities within the output embedding vectors and\nempirically demonstrate that it is accurate and sparse. As a causality\nexamination, we steer the encoding in output embedding to modify the output\nprobability distribution accurately. Moreover, the sparsity we find in output\nprobability encoding suggests that a large number of dimensions in the output\nembedding do not contribute to causal language modeling. Therefore, we attempt\nto delete the output-unrelated dimensions and find more than 30% of the\ndimensions can be deleted without significant movement in output distribution\nand sequence generation. Additionally, in the pre-training dynamics of language\nmodels, we find that the output embeddings capture the corpus token frequency\ninformation in early steps, even before an obvious convergence of parameters\nstarts.",
      "tldr_zh": "本研究探讨了语言模型中输出嵌入（output embedding）中的 token 概率编码，发现了一种准确且稀疏的常用对数线性编码（common log-linear encoding）。通过因果性检查（causality examination），研究者成功操纵该编码来精确修改输出概率分布，并证明超过30%的输出嵌入维度可被删除，而不显著影响输出分布和序列生成。实验结果显示，这种稀疏性源于这些维度与因果语言建模无关，从而优化了模型效率。此外，在语言模型预训练早期，输出嵌入已捕获语料库 token 频率信息，即使参数尚未明显收敛。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 17 figures, 3 tables. COLING 2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2406.01468v2",
      "published_date": "2024-06-03 15:57:29 UTC",
      "updated_date": "2024-12-11 13:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:27:22.424727"
    },
    {
      "arxiv_id": "2406.01462v2",
      "title": "The Importance of Online Data: Understanding Preference Fine-tuning via Coverage",
      "title_zh": "在线数据的的重要性：通过覆盖率理解偏好微调",
      "authors": [
        "Yuda Song",
        "Gokul Swamy",
        "Aarti Singh",
        "J. Andrew Bagnell",
        "Wen Sun"
      ],
      "abstract": "Learning from human preference data has emerged as the dominant paradigm for\nfine-tuning large language models (LLMs). The two most common families of\ntechniques -- online reinforcement learning (RL) such as Proximal Policy\nOptimization (PPO) and offline contrastive methods such as Direct Preference\nOptimization (DPO) -- were positioned as equivalent in prior work due to the\nfact that both have to start from the same offline preference dataset. To\nfurther expand our theoretical understanding of the similarities and\ndifferences between online and offline techniques for preference fine-tuning,\nwe conduct a rigorous analysis through the lens of dataset coverage, a concept\nthat captures how the training data covers the test distribution and is widely\nused in RL. We prove that a global coverage condition is both necessary and\nsufficient for offline contrastive methods to converge to the optimal policy,\nbut a weaker partial coverage condition suffices for online RL methods. This\nseparation provides one explanation of why online RL methods can perform better\nthan offline methods, especially when the offline preference data is not\ndiverse enough. Finally, motivated by our preceding theoretical observations,\nwe derive a hybrid preference optimization (HyPO) algorithm that uses offline\ndata for contrastive-based preference optimization and online data for KL\nregularization. Theoretically and empirically, we demonstrate that HyPO is more\nperformant than its pure offline counterpart DPO, while still preserving its\ncomputation and memory efficiency.",
      "tldr_zh": "本文分析了在线强化学习（如 PPO）和离线对比方法（如 DPO）在微调大型语言模型（LLMs）的偏好数据学习中的差异，通过数据集覆盖率（coverage）概念进行严格理论分析。研究证明，离线方法需要全局覆盖率才能收敛到最优策略，而在线 RL 方法只需更弱的部分覆盖率，从而解释了在线方法在数据多样性不足时的性能优势。基于这一发现，作者提出了一种混合偏好优化算法（HyPO），结合离线数据用于对比优化和在线数据用于 KL 正则化。理论与实验结果表明，HyPO 比纯离线 DPO 更具性能，同时保持计算和内存效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01462v2",
      "published_date": "2024-06-03 15:51:04 UTC",
      "updated_date": "2024-07-16 16:51:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:27:43.639582"
    },
    {
      "arxiv_id": "2406.01460v2",
      "title": "MLIP: Efficient Multi-Perspective Language-Image Pretraining with Exhaustive Data Utilization",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Zhang",
        "Qi Zhang",
        "Zixuan Gong",
        "Yiwei Shi",
        "Yepeng Liu",
        "Duoqian Miao",
        "Yang Liu",
        "Ke Liu",
        "Kun Yi",
        "Wei Fan",
        "Liang Hu",
        "Changwei Wang"
      ],
      "abstract": "Contrastive Language-Image Pretraining (CLIP) has achieved remarkable\nsuccess, leading to rapid advancements in multimodal studies. However, CLIP\nfaces a notable challenge in terms of inefficient data utilization. It relies\non a single contrastive supervision for each image-text pair during\nrepresentation learning, disregarding a substantial amount of valuable\ninformation that could offer richer supervision. Additionally, the retention of\nnon-informative tokens leads to increased computational demands and time costs,\nparticularly in CLIP's ViT image encoder. To address these issues, we propose\nMulti-Perspective Language-Image Pretraining (MLIP). In MLIP, we leverage the\nfrequency transform's sensitivity to both high and low-frequency variations,\nwhich complements the spatial domain's sensitivity limited to low-frequency\nvariations only. By incorporating frequency transforms and token-level\nalignment, we expand CILP's single supervision into multi-domain and\nmulti-level supervision, enabling a more thorough exploration of informative\nimage features. Additionally, we introduce a token merging method guided by\ncomprehensive semantics from the frequency and spatial domains. This allows us\nto merge tokens to multi-granularity tokens with a controllable compression\nrate to accelerate CLIP. Extensive experiments validate the effectiveness of\nour design.",
      "tldr_zh": "该论文针对 Contrastive Language-Image Pretraining (CLIP) 的数据利用效率低和计算成本高问题，提出了 Multi-Perspective Language-Image Pretraining (MLIP) 方法，通过频率变换和 token-level alignment 将单一对比监督扩展为多域（frequency 和 spatial）和多级监督，从而更全面地挖掘图像特征。MLIP 还引入了基于频率和空间域语义的 token merging 技术，实现可控压缩率以加速 CLIP 的 ViT 图像编码器。实验结果证明，MLIP 显著提升了模型性能和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01460v2",
      "published_date": "2024-06-03 15:49:11 UTC",
      "updated_date": "2024-06-04 07:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:27:47.382714"
    },
    {
      "arxiv_id": "2406.06569v1",
      "title": "Enhancing Clinical Documentation with Synthetic Data: Leveraging Generative Models for Improved Accuracy",
      "title_zh": "使用合成数据增强临床文档：利用生成模型提高准确性",
      "authors": [
        "Anjanava Biswas",
        "Wrick Talukdar"
      ],
      "abstract": "Accurate and comprehensive clinical documentation is crucial for delivering\nhigh-quality healthcare, facilitating effective communication among providers,\nand ensuring compliance with regulatory requirements. However, manual\ntranscription and data entry processes can be time-consuming, error-prone, and\nsusceptible to inconsistencies, leading to incomplete or inaccurate medical\nrecords. This paper proposes a novel approach to augment clinical documentation\nby leveraging synthetic data generation techniques to generate realistic and\ndiverse clinical transcripts. We present a methodology that combines\nstate-of-the-art generative models, such as Generative Adversarial Networks\n(GANs) and Variational Autoencoders (VAEs), with real-world clinical transcript\nand other forms of clinical data to generate synthetic transcripts. These\nsynthetic transcripts can then be used to supplement existing documentation\nworkflows, providing additional training data for natural language processing\nmodels and enabling more accurate and efficient transcription processes.\nThrough extensive experiments on a large dataset of anonymized clinical\ntranscripts, we demonstrate the effectiveness of our approach in generating\nhigh-quality synthetic transcripts that closely resemble real-world data.\nQuantitative evaluation metrics, including perplexity scores and BLEU scores,\nas well as qualitative assessments by domain experts, validate the fidelity and\nutility of the generated synthetic transcripts. Our findings highlight\nsynthetic data generation's potential to address clinical documentation\nchallenges, improving patient care, reducing administrative burdens, and\nenhancing healthcare system efficiency.",
      "tldr_zh": "本研究针对临床文档的准确性和完整性问题，提出了一种利用合成数据生成技术来提升文档质量的方法。该方法结合Generative Adversarial Networks (GANs)和Variational Autoencoders (VAEs)等生成模型，与真实临床数据相结合，生成逼真的合成转录，以补充现有文档流程并为Natural Language Processing (NLP)模型提供更多训练数据。通过在大型匿名临床数据集上的实验，研究证明了合成转录的高质量表现，包括在perplexity scores和BLEU scores上的优异结果，以及专家的定性评估。该方法有助于改善患者护理、减轻行政负担，并提升医疗系统效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06569v1",
      "published_date": "2024-06-03 15:49:03 UTC",
      "updated_date": "2024-06-03 15:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:27:56.273741"
    },
    {
      "arxiv_id": "2407.08745v1",
      "title": "Evolutionary Computation for the Design and Enrichment of General-Purpose Artificial Intelligence Systems: Survey and Prospects",
      "title_zh": "进化计算用于通用人工智能系统的设计和增强：综述与展望",
      "authors": [
        "Javier Poyatos",
        "Javier Del Ser",
        "Salvador Garcia",
        "Hisao Ishibuchi",
        "Daniel Molina",
        "Isaac Triguero",
        "Bing Xue",
        "Xin Yao",
        "Francisco Herrera"
      ],
      "abstract": "In Artificial Intelligence, there is an increasing demand for adaptive models\ncapable of dealing with a diverse spectrum of learning tasks, surpassing the\nlimitations of systems devised to cope with a single task. The recent emergence\nof General-Purpose Artificial Intelligence Systems (GPAIS) poses model\nconfiguration and adaptability challenges at far greater complexity scales than\nthe optimal design of traditional Machine Learning models. Evolutionary\nComputation (EC) has been a useful tool for both the design and optimization of\nMachine Learning models, endowing them with the capability to configure and/or\nadapt themselves to the task under consideration. Therefore, their application\nto GPAIS is a natural choice. This paper aims to analyze the role of EC in the\nfield of GPAIS, exploring the use of EC for their design or enrichment. We also\nmatch GPAIS properties to Machine Learning areas in which EC has had a notable\ncontribution, highlighting recent milestones of EC for GPAIS. Furthermore, we\ndiscuss the challenges of harnessing the benefits of EC for GPAIS, presenting\ndifferent strategies to both design and improve GPAIS with EC, covering\ntangential areas, identifying research niches, and outlining potential research\ndirections for EC and GPAIS.",
      "tldr_zh": "这篇论文调查了Evolutionary Computation (EC) 在General-Purpose Artificial Intelligence Systems (GPAIS) 的设计和优化中的作用，强调EC 如何帮助这些系统适应多样化的学习任务，超越传统机器学习模型的局限。作者通过匹配GPAIS 属性与EC 的贡献领域，回顾了EC 在GPAIS 方面的关键里程石，并讨论了面临的挑战，如模型复杂性。论文提出多种策略来利用EC 设计和改进GPAIS，包括探索相关领域、识别研究空白，并概述未来的研究方向。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08745v1",
      "published_date": "2024-06-03 15:47:17 UTC",
      "updated_date": "2024-06-03 15:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:28:08.240010"
    },
    {
      "arxiv_id": "2406.01455v3",
      "title": "Automatic Fused Multimodal Deep Learning for Plant Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Alfreds Lapkovskis",
        "Natalia Nefedova",
        "Ali Beikmohammadi"
      ],
      "abstract": "Plant classification is vital for ecological conservation and agricultural\nproductivity, enhancing our understanding of plant growth dynamics and aiding\nspecies preservation. The advent of deep learning (DL) techniques has\nrevolutionized this field by enabling autonomous feature extraction,\nsignificantly reducing the dependence on manual expertise. However,\nconventional DL models often rely solely on single data sources, failing to\ncapture the full biological diversity of plant species comprehensively. Recent\nresearch has turned to multimodal learning to overcome this limitation by\nintegrating multiple data types, which enriches the representation of plant\ncharacteristics. This shift introduces the challenge of determining the optimal\npoint for modality fusion. In this paper, we introduce a pioneering multimodal\nDL-based approach for plant classification with automatic modality fusion.\nUtilizing the multimodal fusion architecture search, our method integrates\nimages from multiple plant organs -- flowers, leaves, fruits, and stems -- into\na cohesive model. To address the lack of multimodal datasets, we contributed\nMultimodal-PlantCLEF, a restructured version of the PlantCLEF2015 dataset\ntailored for multimodal tasks. Our method achieves 82.61% accuracy on 979\nclasses of Multimodal-PlantCLEF, surpassing state-of-the-art methods and\noutperforming late fusion by 10.33%. Through the incorporation of multimodal\ndropout, our approach demonstrates strong robustness to missing modalities. We\nvalidate our model against established benchmarks using standard performance\nmetrics and McNemar's test, further underscoring its superiority.",
      "tldr_zh": "本研究提出了一种自动融合多模态深度学习方法，用于植物识别，以解决传统单模态模型无法全面捕捉植物生物多样性的问题。该方法利用 multimodal fusion architecture search 整合花朵、叶子、果实和茎等器官的图像，并构建了 Multimodal-PlantCLEF 数据集作为多模态任务的基准。实验结果显示，该模型在 979 类植物上达到 82.61% 的准确率，比最先进方法更优越，并通过 multimodal dropout 显著提升了对缺失模态的鲁棒性。验证使用标准性能指标和 McNemar's test 进一步证实了其 superiority。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01455v3",
      "published_date": "2024-06-03 15:43:29 UTC",
      "updated_date": "2025-01-18 12:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:28:24.136750"
    },
    {
      "arxiv_id": "2406.01424v2",
      "title": "Universal In-Context Approximation By Prompting Fully Recurrent Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandar Petrov",
        "Tom A. Lamb",
        "Alasdair Paren",
        "Philip H. S. Torr",
        "Adel Bibi"
      ],
      "abstract": "Zero-shot and in-context learning enable solving tasks without model\nfine-tuning, making them essential for developing generative model solutions.\nTherefore, it is crucial to understand whether a pretrained model can be\nprompted to approximate any function, i.e., whether it is a universal\nin-context approximator. While it was recently shown that transformer models do\npossess this property, these results rely on their attention mechanism. Hence,\nthese findings do not apply to fully recurrent architectures like RNNs, LSTMs,\nand the increasingly popular SSMs. We demonstrate that RNNs, LSTMs, GRUs,\nLinear RNNs, and linear gated architectures such as Mamba and Hawk/Griffin can\nalso serve as universal in-context approximators. To streamline our argument,\nwe introduce a programming language called LSRL that compiles to these fully\nrecurrent architectures. LSRL may be of independent interest for further\nstudies of fully recurrent models, such as constructing interpretability\nbenchmarks. We also study the role of multiplicative gating and observe that\narchitectures incorporating such gating (e.g., LSTMs, GRUs, Hawk/Griffin) can\nimplement certain operations more stably, making them more viable candidates\nfor practical in-context universal approximation.",
      "tldr_zh": "本研究探讨了是否可以通过提示使完全循环模型（如 RNNs、LSTMs、GRUs、Linear RNNs 和线性门控架构如 Mamba 和 Hawk/Griffin）成为通用上下文近似器，从而无需微调即可近似任何函数。研究者引入了 LSRL 编程语言来简化论证，该语言可编译到这些架构中，并为进一步研究完全循环模型提供基准。结果显示，这些模型具备通用上下文近似能力，而带有乘法门控的架构（如 LSTMs 和 GRUs）在实现某些操作时更稳定，更适用于实际场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at NeurIPS 2024, Code at\n  https://github.com/AleksandarPetrov/LSRL",
      "pdf_url": "http://arxiv.org/pdf/2406.01424v2",
      "published_date": "2024-06-03 15:25:13 UTC",
      "updated_date": "2024-10-10 16:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:28:33.360728"
    },
    {
      "arxiv_id": "2406.01423v2",
      "title": "Value Improved Actor Critic Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Yaniv Oren",
        "Moritz A. Zanger",
        "Pascal R. van der Vaart",
        "Mustafa Mert Celikok",
        "Matthijs T. J. Spaan",
        "Wendelin Bohmer"
      ],
      "abstract": "To learn approximately optimal acting policies for decision problems, modern\nActor Critic algorithms rely on deep Neural Networks (DNNs) to parameterize the\nacting policy and greedification operators to iteratively improve it. The\nreliance on DNNs suggests an improvement that is gradient based, which is per\nstep much less greedy than the improvement possible by greedier operators such\nas the greedy update used by Q-learning algorithms. On the other hand, slow and\nsteady changes to the policy can also be beneficial for the stability of the\nlearning process, resulting in a tradeoff between greedification and stability.\nTo address this tradeoff, we propose to extend the standard framework of actor\ncritic algorithms with value-improvement: a second greedification operator\napplied only when updating the policy's value estimate. In this framework the\nagent can evaluate non-parameterized policies and perform much greedier updates\nwhile maintaining the steady gradient-based improvement to the parameterized\nacting policy. We prove that this approach converges in the popular analysis\nscheme of Generalized Policy Iteration in the finite-horizon domain.\nEmpirically, incorporating value-improvement into the popular off-policy\nactor-critic algorithms TD3 and SAC significantly improves or matches\nperformance over their respective baselines, across different environments from\nthe DeepMind continuous control domain, with negligible compute and\nimplementation cost.",
      "tldr_zh": "这篇论文提出了一种改进的 Actor Critic 算法，通过引入 value-improvement 操作来平衡贪婪更新和学习稳定性，解决传统算法在决策问题中改进策略速度较慢的问题。该方法在更新策略的价值估计时应用额外的贪婪操作，以评估非参数化策略，同时保持对参数化策略的梯度-based 改进。论文证明了这种框架在 Generalized Policy Iteration 的有限地平线域中能够收敛。实证结果显示，在 DeepMind 连续控制环境上，将 value-improvement 整合到 TD3 和 SAC 算法中，能显著提升或匹配基准性能，且计算成本 negligible。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01423v2",
      "published_date": "2024-06-03 15:24:15 UTC",
      "updated_date": "2025-03-11 11:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:28:45.115932"
    },
    {
      "arxiv_id": "2406.01421v1",
      "title": "Problematizing AI Omnipresence in Landscape Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Phillip Fernberg",
        "Zihao Zhang"
      ],
      "abstract": "This position paper argues for, and offers, a critical lens through which to\nexamine the current AI frenzy in the landscape architecture profession. In it,\nthe authors propose five archetypes or mental modes that landscape architects\nmight inhabit when thinking about AI. Rather than limiting judgments of AI use\nto a single axis of acceleration, these archetypes and corresponding narratives\nexist along a relational spectrum and are permeable, allowing LAs to take on\nand switch between them according to context. We model these relationships\nbetween the archetypes and their contributions to AI advancement using a causal\nloop diagram (CLD), and with those interactions argue that more nuanced ways of\napproaching AI might also open new modes of practice in the new digital\neconomy.",
      "tldr_zh": "这篇立场论文批判性地审视了 AI 在景观建筑领域的泛在性（AI Omnipresence），提出了一种新的分析视角。作者定义了五个 archetypes（原型）或 mental modes（心理模式），这些沿一个 relational spectrum（关系谱系）分布，并具有 permeable（可渗透）特性，允许景观建筑师根据上下文切换思维方式。论文使用 causal loop diagram (CLD) 建模这些原型间的互动，主张这种细微方法能促进更 nuanced（细致的）AI 应用，并在数字经济中开辟新的实践模式。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01421v1",
      "published_date": "2024-06-03 15:20:05 UTC",
      "updated_date": "2024-06-03 15:20:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:28:56.329228"
    },
    {
      "arxiv_id": "2407.08744v1",
      "title": "Toward Efficient Deep Spiking Neuron Networks:A Survey On Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Xie",
        "Ge Yang",
        "Wenjuan Gao"
      ],
      "abstract": "With the rapid development of deep learning, Deep Spiking Neural Networks\n(DSNNs) have emerged as promising due to their unique spike event processing\nand asynchronous computation. When deployed on neuromorphic chips, DSNNs offer\nsignificant power advantages over Deep Artificial Neural Networks (DANNs) and\neliminate time and energy consuming multiplications due to the binary nature of\nspikes (0 or 1). Additionally, DSNNs excel in processing temporal information,\nmaking them potentially superior for handling temporal data compared to DANNs.\nHowever, their deep network structure and numerous parameters result in high\ncomputational costs and energy consumption, limiting real-life deployment. To\nenhance DSNNs efficiency, researchers have adapted methods from DANNs, such as\npruning, quantization, and knowledge distillation, and developed specific\ntechniques like reducing spike firing and pruning time steps. While previous\nsurveys have covered DSNNs algorithms, hardware deployment, and general\noverviews, focused research on DSNNs compression and efficiency has been\nlacking. This survey addresses this gap by concentrating on efficient DSNNs and\ntheir compression methods. It begins with an exploration of DSNNs' biological\nbackground and computational units, highlighting differences from DANNs. It\nthen delves into various compression methods, including pruning, quantization,\nknowledge distillation, and reducing spike firing, and concludes with\nsuggestions for future research directions.",
      "tldr_zh": "本调查论文探讨了深度脉冲神经网络 (DSNNs) 的压缩方法，以提升其效率。DSNNs 凭借脉冲事件处理和异步计算，在神经形态芯片上比深度人工神经网络 (DANNs) 具有更低的功耗优势，并擅长处理时间信息，但其复杂结构导致高计算成本。论文回顾了从 DANNs 借鉴的压缩技术，如 pruning、quantization 和 knowledge distillation，以及特定方法如减少 spike firing，并填补了现有调查的空白，最后提出未来研究方向。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08744v1",
      "published_date": "2024-06-03 15:11:54 UTC",
      "updated_date": "2024-06-03 15:11:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:29:08.341583"
    },
    {
      "arxiv_id": "2406.01402v1",
      "title": "Mixture of Rationale: Multi-Modal Reasoning Mixture for Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Li",
        "Linjun Shou",
        "Xuejun Liu"
      ],
      "abstract": "Zero-shot visual question answering (VQA) is a challenging task that requires\nreasoning across modalities. While some existing methods rely on a single\nrationale within the Chain of Thoughts (CoT) framework, they may fall short of\ncapturing the complexity of the VQA problem. On the other hand, some other\nmethods that use multiple rationales may still suffer from low diversity, poor\nmodality alignment, and inefficient retrieval and fusion. In response to these\nchallenges, we propose \\emph{Mixture of Rationales (MoR)}, a novel multi-modal\nreasoning method that mixes multiple rationales for VQA. MoR uses a single\nfrozen Vision-and-Language Pre-trained Models (VLPM) model to {dynamically\ngenerate, retrieve and fuse multi-modal thoughts}. We evaluate MoR on two\nchallenging VQA datasets, i.e. NLVR2 and OKVQA, with two representative\nbackbones OFA and VL-T5. MoR achieves a 12.43\\% accuracy improvement on NLVR2,\nand a 2.45\\% accuracy improvement on OKVQA-S( the science and technology\ncategory of OKVQA).",
      "tldr_zh": "本研究针对零样本视觉问答 (Zero-shot VQA) 的跨模态推理挑战，提出了一种新型方法 Mixture of Rationales (MoR)，它通过混合多个推理链来解决现有 Chain of Thoughts (CoT) 方法的局限性，如低多样性、模态对齐问题和低效检索融合。MoR 利用一个冻结的 Vision-and-Language Pre-trained Models (VLPM) 模型，动态生成、检索和融合多模态思考，从而提升推理效率和准确性。在 NLVR2 和 OKVQA 数据集上实验表明，使用 OFA 和 VL-T5 作为骨干模型，MoR 分别实现了 12.43% 和 2.45% 的准确率提升。该方法为多模态推理提供了更可靠的框架，促进了 VQA 任务的性能优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01402v1",
      "published_date": "2024-06-03 15:04:47 UTC",
      "updated_date": "2024-06-03 15:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:29:23.791943"
    },
    {
      "arxiv_id": "2406.01394v4",
      "title": "PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqian Zeng",
        "Jianwei Wang",
        "Junyao Yang",
        "Zhengdong Lu",
        "Huiping Zhuang",
        "Cen Chen"
      ],
      "abstract": "The widespread usage of online Large Language Models (LLMs) inference\nservices has raised significant privacy concerns about the potential exposure\nof private information in user inputs to malicious eavesdroppers. Existing\nprivacy protection methods for LLMs suffer from either insufficient privacy\nprotection, performance degradation, or large inference time overhead. To\naddress these limitations, we propose PrivacyRestore, a plug-and-play method to\nprotect the privacy of user inputs during LLM inference. The server first\ntrains restoration vectors for each privacy span and then release to clients.\nPrivacy span is defined as a contiguous sequence of tokens within a text that\ncontain private information. The client then aggregate restoration vectors of\nall privacy spans in the input into a single meta restoration vector which is\nlater sent to the server side along with the input without privacy spans.The\nprivate information is restored via activation steering during inference.\nFurthermore, we prove that PrivacyRestore inherently prevents the linear growth\nof the privacy budget.We create three datasets, covering medical and legal\ndomains, to evaluate the effectiveness of privacy preserving methods. The\nexperimental results show that PrivacyRestore effectively protects private\ninformation and maintain acceptable levels of performance and inference\noverhead.",
      "tldr_zh": "这篇论文提出了 PrivacyRestore，一种即插即用的方法，用于保护大语言模型(LLMs)推理过程中用户输入的隐私问题。方法包括服务器端为隐私段（包含私人信息的连续 token 序列）训练恢复向量，并由客户端聚合成元恢复向量后发送到服务器，同时移除隐私段进行推理；随后，通过 activation steering 技术在服务器端恢复私人信息。该方法还证明了其内在机制能防止隐私预算的线性增长。实验结果显示，在三个医疗和法律领域的自定义数据集上，PrivacyRestore 有效保护了私人信息，同时维持了可接受的性能和推理开销。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01394v4",
      "published_date": "2024-06-03 14:57:39 UTC",
      "updated_date": "2024-12-26 03:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:29:44.633054"
    },
    {
      "arxiv_id": "2406.01389v2",
      "title": "RL in Latent MDPs is Tractable: Online Guarantees via Off-Policy Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongyeol Kwon",
        "Shie Mannor",
        "Constantine Caramanis",
        "Yonathan Efroni"
      ],
      "abstract": "In many real-world decision problems there is partially observed, hidden or\nlatent information that remains fixed throughout an interaction. Such decision\nproblems can be modeled as Latent Markov Decision Processes (LMDPs), where a\nlatent variable is selected at the beginning of an interaction and is not\ndisclosed to the agent. In the last decade, there has been significant progress\nin solving LMDPs under different structural assumptions. However, for general\nLMDPs, there is no known learning algorithm that provably matches the existing\nlower bound (Kwon et al., 2021). We introduce the first sample-efficient\nalgorithm for LMDPs without any additional structural assumptions. Our result\nbuilds off a new perspective on the role of off-policy evaluation guarantees\nand coverage coefficients in LMDPs, a perspective, that has been overlooked in\nthe context of exploration in partially observed environments. Specifically, we\nestablish a novel off-policy evaluation lemma and introduce a new coverage\ncoefficient for LMDPs. Then, we show how these can be used to derive\nnear-optimal guarantees of an optimistic exploration algorithm. These results,\nwe believe, can be valuable for a wide range of interactive learning problems\nbeyond LMDPs, and especially, for partially observed environments.",
      "tldr_zh": "这篇论文解决了强化学习（RL）在 Latent Markov Decision Processes (LMDPs) 中的挑战，LMDPs 涉及交互开始时隐藏的潜在变量。作者引入了第一个无需额外结构假设的样本高效算法，通过新的 off-policy evaluation lemma 和 coverage coefficient 来优化探索策略。实验证明，该算法可提供近似最优的在线保证，并有望扩展到更广泛的部分观察环境交互学习问题中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Fixed typos + alpha",
      "pdf_url": "http://arxiv.org/pdf/2406.01389v2",
      "published_date": "2024-06-03 14:51:27 UTC",
      "updated_date": "2024-06-26 15:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:29:45.822355"
    },
    {
      "arxiv_id": "2406.01651v3",
      "title": "FusionDTI: Fine-grained Binding Discovery with Token-level Fusion for Drug-Target Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaohan Meng",
        "Zaiqiao Meng",
        "Ke Yuan",
        "Iadh Ounis"
      ],
      "abstract": "Predicting drug-target interaction (DTI) is critical in the drug discovery\nprocess. Despite remarkable advances in recent DTI models through the\nintegration of representations from diverse drug and target encoders, such\nmodels often struggle to capture the fine-grained interactions between drugs\nand protein, i.e. the binding of specific drug atoms (or substructures) and key\namino acids of proteins, which is crucial for understanding the binding\nmechanisms and optimising drug design. To address this issue, this paper\nintroduces a novel model, called FusionDTI, which uses a token-level Fusion\nmodule to effectively learn fine-grained information for Drug-Target\nInteraction. In particular, our FusionDTI model uses the SELFIES representation\nof drugs to mitigate sequence fragment invalidation and incorporates the\nstructure-aware (SA) vocabulary of target proteins to address the limitation of\namino acid sequences in structural information, additionally leveraging\npre-trained language models extensively trained on large-scale biomedical\ndatasets as encoders to capture the complex information of drugs and targets.\nExperiments on three well-known benchmark datasets show that our proposed\nFusionDTI model achieves the best performance in DTI prediction compared with\nseven existing state-of-the-art baselines. Furthermore, our case study\nindicates that FusionDTI could highlight the potential binding sites, enhancing\nthe explainability of the DTI prediction.",
      "tldr_zh": "这篇论文针对药物-靶点交互(DTI)预测的挑战，提出了一种新模型FusionDTI，通过token-level Fusion模块来捕捉药物和蛋白质的细粒度结合信息，例如特定药物原子或子结构与关键氨基酸的交互。模型采用SELFIES表示药物以避免序列片段无效问题，并结合structure-aware (SA)词汇表和在大型生物医学数据集上预训练的语言模型作为编码器，以更好地处理目标蛋白的结构信息。实验结果显示，FusionDTI在三个基准数据集上优于七个现有最先进基线模型，并在案例研究中证明了其突出潜在结合位点的能力，从而提升了DTI预测的可解释性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "q-bio.QM",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01651v3",
      "published_date": "2024-06-03 14:48:54 UTC",
      "updated_date": "2024-10-07 21:22:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:29:59.509027"
    },
    {
      "arxiv_id": "2406.01384v3",
      "title": "Extending Structural Causal Models for Autonomous Vehicles to Simplify Temporal System Construction & Enable Dynamic Interactions Between Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Rhys Howard",
        "Lars Kunze"
      ],
      "abstract": "In this work we aim to bridge the divide between autonomous vehicles and\ncausal reasoning. Autonomous vehicles have come to increasingly interact with\nhuman drivers, and in many cases may pose risks to the physical or mental\nwell-being of those they interact with. Meanwhile causal models, despite their\ninherent transparency and ability to offer contrastive explanations, have found\nlimited usage within such systems. As such, we first identify the challenges\nthat have limited the integration of structural causal models within autonomous\nvehicles. We then introduce a number of theoretical extensions to the\nstructural causal model formalism in order to tackle these challenges. This\naugments these models to possess greater levels of modularisation and\nencapsulation, as well presenting temporal causal model representation with\nconstant space complexity. We also prove through the extensions we have\nintroduced that dynamically mutable sets (e.g. varying numbers of autonomous\nvehicles across time) can be used within a structural causal model while\nmaintaining a relaxed form of causal stationarity. Finally we discuss the\napplication of the extensions in the context of the autonomous vehicle and\nservice robotics domain along with potential directions for future work.",
      "tldr_zh": "这篇论文旨在桥接自动驾驶车辆(Autonomous Vehicles)和因果推理之间的鸿沟，通过扩展结构因果模型(Structural Causal Models)来简化时间系统构建并启用代理之间的动态交互。作者首先识别了整合这些模型的挑战，包括模块化和封装不足，以及处理动态可变集的复杂性，然后引入理论扩展以提升模型的模块化、封装和时间表示，同时保持松弛的因果平稳性(Causal Stationarity)。这些扩展证明了其在支持可变代理集方面的有效性，并讨论了在自动驾驶车辆和服务机器人领域的潜在应用及未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "cs.SE",
        "D.1.5; D.2.11; G.2.2; I.2.9; J.2"
      ],
      "primary_category": "cs.AI",
      "comment": "30 Pages = 13 Pages (Main Content) + 4 Pages (References) + 13 Pages\n  (Appendix), 15 Figures = 5 Figures (Main Content) + 10 (Appendix), To be\n  published in the Proceedings of the 2025 Causal Learning and Reasoning\n  Conference, Update upload of accepted paper version",
      "pdf_url": "http://arxiv.org/pdf/2406.01384v3",
      "published_date": "2024-06-03 14:47:05 UTC",
      "updated_date": "2025-03-18 05:14:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:30:12.506175"
    },
    {
      "arxiv_id": "2406.01382v1",
      "title": "Do Large Language Models Perform the Way People Expect? Measuring the Human Generalization Function",
      "title_zh": "翻译失败",
      "authors": [
        "Keyon Vafa",
        "Ashesh Rambachan",
        "Sendhil Mullainathan"
      ],
      "abstract": "What makes large language models (LLMs) impressive is also what makes them\nhard to evaluate: their diversity of uses. To evaluate these models, we must\nunderstand the purposes they will be used for. We consider a setting where\nthese deployment decisions are made by people, and in particular, people's\nbeliefs about where an LLM will perform well. We model such beliefs as the\nconsequence of a human generalization function: having seen what an LLM gets\nright or wrong, people generalize to where else it might succeed. We collect a\ndataset of 19K examples of how humans make generalizations across 79 tasks from\nthe MMLU and BIG-Bench benchmarks. We show that the human generalization\nfunction can be predicted using NLP methods: people have consistent structured\nways to generalize. We then evaluate LLM alignment with the human\ngeneralization function. Our results show that -- especially for cases where\nthe cost of mistakes is high -- more capable models (e.g. GPT-4) can do worse\non the instances people choose to use them for, exactly because they are not\naligned with the human generalization function.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 的性能是否符合人们的预期，引入“人类泛化函数”概念来衡量人们基于LLMs在特定任务上的表现如何推断其在其他任务上的适用性。研究者收集了19K个例子，涵盖MMLU和BIG-Bench等79个基准任务，并使用NLP方法预测人类的一致性结构化泛化方式。结果显示，更先进的模型如GPT-4在高风险错误场景中可能表现更差，因为其未与人类泛化函数对齐，导致人们在部署决策上出现偏差。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01382v1",
      "published_date": "2024-06-03 14:45:21 UTC",
      "updated_date": "2024-06-03 14:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:30:22.313998"
    },
    {
      "arxiv_id": "2406.01650v1",
      "title": "TAGMol: Target-Aware Gradient-guided Molecule Generation",
      "title_zh": "TAGMol: 目标感知梯度引导分子生成",
      "authors": [
        "Vineeth Dorna",
        "D. Subhalingam",
        "Keshav Kolluru",
        "Shreshth Tuli",
        "Mrityunjay Singh",
        "Saurabh Singal",
        "N. M. Anoop Krishnan",
        "Sayan Ranu"
      ],
      "abstract": "3D generative models have shown significant promise in structure-based drug\ndesign (SBDD), particularly in discovering ligands tailored to specific target\nbinding sites. Existing algorithms often focus primarily on ligand-target\nbinding, characterized by binding affinity. Moreover, models trained solely on\ntarget-ligand distribution may fall short in addressing the broader objectives\nof drug discovery, such as the development of novel ligands with desired\nproperties like drug-likeness, and synthesizability, underscoring the\nmultifaceted nature of the drug design process. To overcome these challenges,\nwe decouple the problem into molecular generation and property prediction. The\nlatter synergistically guides the diffusion sampling process, facilitating\nguided diffusion and resulting in the creation of meaningful molecules with the\ndesired properties. We call this guided molecular generation process as TAGMol.\nThrough experiments on benchmark datasets, TAGMol demonstrates superior\nperformance compared to state-of-the-art baselines, achieving a 22% improvement\nin average Vina Score and yielding favorable outcomes in essential auxiliary\nproperties. This establishes TAGMol as a comprehensive framework for drug\ngeneration.",
      "tldr_zh": "本文提出TAGMol，一种目标感知梯度引导分子生成方法，针对结构-based drug design (SBDD) 中的挑战，将分子生成与属性预测解耦，并使用属性预测来指导扩散采样过程，从而生成兼具高binding affinity、drug-likeness和synthesizability的分子。相比现有算法，TAGMol在基准数据集上实现了平均Vina Score提高22%，并在其他辅助属性上表现出色。总体而言，这为药物发现提供了一个全面且高效的框架。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01650v1",
      "published_date": "2024-06-03 14:43:54 UTC",
      "updated_date": "2024-06-03 14:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:30:34.414703"
    },
    {
      "arxiv_id": "2406.01377v1",
      "title": "Multi-Agent Transfer Learning via Temporal Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Zeng",
        "Joseph Campbell",
        "Simon Stepputtis",
        "Katia Sycara"
      ],
      "abstract": "This paper introduces a novel transfer learning framework for deep\nmulti-agent reinforcement learning. The approach automatically combines\ngoal-conditioned policies with temporal contrastive learning to discover\nmeaningful sub-goals. The approach involves pre-training a goal-conditioned\nagent, finetuning it on the target domain, and using contrastive learning to\nconstruct a planning graph that guides the agent via sub-goals. Experiments on\nmulti-agent coordination Overcooked tasks demonstrate improved sample\nefficiency, the ability to solve sparse-reward and long-horizon problems, and\nenhanced interpretability compared to baselines. The results highlight the\neffectiveness of integrating goal-conditioned policies with unsupervised\ntemporal abstraction learning for complex multi-agent transfer learning.\nCompared to state-of-the-art baselines, our method achieves the same or better\nperformances while requiring only 21.7% of the training samples.",
      "tldr_zh": "本论文提出了一种新型转移学习框架，用于深度多智能体强化学习（multi-agent reinforcement learning），通过结合目标条件策略（goal-conditioned policies）和时间对比学习（temporal contrastive learning）来自动发现有意义的子目标。该框架包括预训练目标条件代理、在目标域上微调，以及使用对比学习构建规划图以通过子目标引导代理。实验在多智能体协调任务Overcooked上显示，该方法显著提高了样本效率，能够有效解决稀疏奖励和长 horizons 问题，并提升了可解释性。与最先进基线相比，该方法在性能相当或更优的情况下，仅需21.7%的训练样本。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01377v1",
      "published_date": "2024-06-03 14:42:14 UTC",
      "updated_date": "2024-06-03 14:42:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:30:45.550814"
    },
    {
      "arxiv_id": "2406.01364v1",
      "title": "BELLS: A Framework Towards Future Proof Benchmarks for the Evaluation of LLM Safeguards",
      "title_zh": "翻译失败",
      "authors": [
        "Diego Dorn",
        "Alexandre Variengien",
        "Charbel-Raphaël Segerie",
        "Vincent Corruble"
      ],
      "abstract": "Input-output safeguards are used to detect anomalies in the traces produced\nby Large Language Models (LLMs) systems. These detectors are at the core of\ndiverse safety-critical applications such as real-time monitoring, offline\nevaluation of traces, and content moderation. However, there is no widely\nrecognized methodology to evaluate them. To fill this gap, we introduce the\nBenchmarks for the Evaluation of LLM Safeguards (BELLS), a structured\ncollection of tests, organized into three categories: (1) established failure\ntests, based on already-existing benchmarks for well-defined failure modes,\naiming to compare the performance of current input-output safeguards; (2)\nemerging failure tests, to measure generalization to never-seen-before failure\nmodes and encourage the development of more general safeguards; (3) next-gen\narchitecture tests, for more complex scaffolding (such as LLM-agents and\nmulti-agent systems), aiming to foster the development of safeguards that could\nadapt to future applications for which no safeguard currently exists.\nFurthermore, we implement and share the first next-gen architecture test, using\nthe MACHIAVELLI environment, along with an interactive visualization of the\ndataset.",
      "tldr_zh": "本研究引入了BELLS框架，这是一个用于评估LLM（Large Language Models）安全措施的基准测试集，旨在提供一个未来导向的方法来检测LLM系统中的异常输出。BELLS将测试分为三类：（1）已建立的失败测试，基于现有基准评估已知失败模式；（2）新兴失败测试，测试对新颖失败模式的泛化能力；（3）下一代架构测试，针对复杂系统如LLM-agents和多智能体系统，以推动适应未来应用的防护发展。此外，研究实现了首个下一代架构测试，使用MACHIAVELLI环境，并共享了交互式数据集可视化工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01364v1",
      "published_date": "2024-06-03 14:32:30 UTC",
      "updated_date": "2024-06-03 14:32:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:30:57.230226"
    },
    {
      "arxiv_id": "2406.01649v1",
      "title": "CoLa-DCE -- Concept-guided Latent Diffusion Counterfactual Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Franz Motzkus",
        "Christian Hellert",
        "Ute Schmid"
      ],
      "abstract": "Recent advancements in generative AI have introduced novel prospects and\npractical implementations. Especially diffusion models show their strength in\ngenerating diverse and, at the same time, realistic features, positioning them\nwell for generating counterfactual explanations for computer vision models.\nAnswering \"what if\" questions of what needs to change to make an image\nclassifier change its prediction, counterfactual explanations align well with\nhuman understanding and consequently help in making model behavior more\ncomprehensible. Current methods succeed in generating authentic\ncounterfactuals, but lack transparency as feature changes are not directly\nperceivable. To address this limitation, we introduce Concept-guided Latent\nDiffusion Counterfactual Explanations (CoLa-DCE). CoLa-DCE generates\nconcept-guided counterfactuals for any classifier with a high degree of control\nregarding concept selection and spatial conditioning. The counterfactuals\ncomprise an increased granularity through minimal feature changes. The\nreference feature visualization ensures better comprehensibility, while the\nfeature localization provides increased transparency of \"where\" changed \"what\".\nWe demonstrate the advantages of our approach in minimality and\ncomprehensibility across multiple image classification models and datasets and\nprovide insights into how our CoLa-DCE explanations help comprehend model\nerrors like misclassification cases.",
      "tldr_zh": "这篇论文引入了 CoLa-DCE，一种概念引导的潜空间扩散模型，用于生成逆事实解释（counterfactual explanations），以提升计算机视觉模型的可解释性，特别是针对图像分类器的“如果改变什么”问题。CoLa-DCE 通过概念选择和空间条件，实现高控制度的逆事实生成，并通过最小特征变化、参考特征可视化和特征定位，提高了透明度和可理解性。实验结果显示，该方法在多个图像分类模型和数据集上表现出色，在最小性和可理解性方面优于现有方法，并有助于分析模型错误如误分类情况。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01649v1",
      "published_date": "2024-06-03 14:27:46 UTC",
      "updated_date": "2024-06-03 14:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:31:10.042812"
    },
    {
      "arxiv_id": "2406.01648v1",
      "title": "Consciousness defined: requirements for biological and artificial general intelligence",
      "title_zh": "意识的定义：生物和人工通用智能的要求",
      "authors": [
        "Craig I. McKenzie"
      ],
      "abstract": "Consciousness is notoriously hard to define with objective terms. An\nobjective definition of consciousness is critically needed so that we might\naccurately understand how consciousness and resultant choice behaviour may\narise in biological or artificial systems. Many theories have integrated\nneurobiological and psychological research to explain how consciousness might\narise, but few, if any, outline what is fundamentally required to generate\nconsciousness. To identify such requirements, I examine current theories of\nconsciousness and corresponding scientific research to generate a new\ndefinition of consciousness from first principles. Critically, consciousness is\nthe apparatus that provides the ability to make decisions, but it is not\ndefined by the decision itself. As such, a definition of consciousness does not\nrequire choice behaviour or an explicit awareness of temporality despite both\nbeing well-characterised outcomes of conscious thought. Rather, requirements\nfor consciousness include: at least some capability for perception, a memory\nfor the storage of such perceptual information which in turn provides a\nframework for an imagination with which a sense of self can be capable of\nmaking decisions based on possible and desired futures. Thought experiments and\nobservable neurological phenomena demonstrate that these components are\nfundamentally required of consciousness, whereby the loss of any one component\nremoves the capability for conscious thought. Identifying these requirements\nprovides a new definition for consciousness by which we can objectively\ndetermine consciousness in any conceivable agent, such as non-human animals and\nartificially intelligent systems.",
      "tldr_zh": "本论文从第一原则出发，提出一个客观的consciousness定义，旨在阐明其在biological和artificial general intelligence系统中的必要条件。作者审视现有consciousness理论和科学研究，确定关键要求包括感知能力、记忆存储、想象框架以及自我感，这些组件共同支持决策过程，而非决策本身。思想实验和神经学现象证明，若缺少任何组件，consciousness将无法实现；这一定义为评估非人类动物和人工智能代理的意识提供了一个可操作的标准。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "16 pages, 1 figure, 2 tables, 74 references",
      "pdf_url": "http://arxiv.org/pdf/2406.01648v1",
      "published_date": "2024-06-03 14:20:56 UTC",
      "updated_date": "2024-06-03 14:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:31:23.388924"
    },
    {
      "arxiv_id": "2406.01355v1",
      "title": "Differentially Private Fine-Tuning of Diffusion Models",
      "title_zh": "基于差分隐私的扩散模型微调",
      "authors": [
        "Yu-Lin Tsai",
        "Yizhe Li",
        "Zekai Chen",
        "Po-Yu Chen",
        "Chia-Mu Yu",
        "Xuebin Ren",
        "Francois Buet-Golfouse"
      ],
      "abstract": "The integration of Differential Privacy (DP) with diffusion models (DMs)\npresents a promising yet challenging frontier, particularly due to the\nsubstantial memorization capabilities of DMs that pose significant privacy\nrisks. Differential privacy offers a rigorous framework for safeguarding\nindividual data points during model training, with Differential Privacy\nStochastic Gradient Descent (DP-SGD) being a prominent implementation.\nDiffusion method decomposes image generation into iterative steps,\ntheoretically aligning well with DP's incremental noise addition. Despite the\nnatural fit, the unique architecture of DMs necessitates tailored approaches to\neffectively balance privacy-utility trade-off. Recent developments in this\nfield have highlighted the potential for generating high-quality synthetic data\nby pre-training on public data (i.e., ImageNet) and fine-tuning on private\ndata, however, there is a pronounced gap in research on optimizing the\ntrade-offs involved in DP settings, particularly concerning parameter\nefficiency and model scalability. Our work addresses this by proposing a\nparameter-efficient fine-tuning strategy optimized for private diffusion\nmodels, which minimizes the number of trainable parameters to enhance the\nprivacy-utility trade-off. We empirically demonstrate that our method achieves\nstate-of-the-art performance in DP synthesis, significantly surpassing previous\nbenchmarks on widely studied datasets (e.g., with only 0.47M trainable\nparameters, achieving a more than 35% improvement over the previous\nstate-of-the-art with a small privacy budget on the CelebA-64 dataset).\nAnonymous codes available at https://anonymous.4open.science/r/DP-LORA-F02F.",
      "tldr_zh": "本研究探讨了在差分隐私(Differential Privacy, DP)框架下对扩散模型(Diffusion Models, DMs)进行微调，以缓解DMs的记忆能力带来的隐私风险。论文提出了一种参数高效的微调策略，通过最小化可训练参数（如仅0.47M参数）来优化隐私-实用性权衡，同时结合DP-SGD方法进行训练。实验结果显示，该策略在CelebA-64等数据集上实现了最先进性能，比先前基准提升超过35%，为高效的私有数据合成提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 5 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.01355v1",
      "published_date": "2024-06-03 14:18:04 UTC",
      "updated_date": "2024-06-03 14:18:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:31:35.575826"
    },
    {
      "arxiv_id": "2406.01352v2",
      "title": "Position: An Inner Interpretability Framework for AI Inspired by Lessons from Cognitive Neuroscience",
      "title_zh": "翻译失败",
      "authors": [
        "Martina G. Vilas",
        "Federico Adolfi",
        "David Poeppel",
        "Gemma Roig"
      ],
      "abstract": "Inner Interpretability is a promising emerging field tasked with uncovering\nthe inner mechanisms of AI systems, though how to develop these mechanistic\ntheories is still much debated. Moreover, recent critiques raise issues that\nquestion its usefulness to advance the broader goals of AI. However, it has\nbeen overlooked that these issues resemble those that have been grappled with\nin another field: Cognitive Neuroscience. Here we draw the relevant connections\nand highlight lessons that can be transferred productively between fields.\nBased on these, we propose a general conceptual framework and give concrete\nmethodological strategies for building mechanistic explanations in AI inner\ninterpretability research. With this conceptual framework, Inner\nInterpretability can fend off critiques and position itself on a productive\npath to explain AI systems.",
      "tldr_zh": "该论文提出一个名为“Position”的内部分析框架（Inner Interpretability），旨在揭示 AI 系统的内部机制，并从认知神经科学（Cognitive Neuroscience）的经验中汲取教训，以应对当前领域的争议和批评。作者强调，这些问题类似于认知神经科学曾面临的挑战，并通过建立通用概念框架和具体方法策略，来构建 AI 的机制解释。最终，该框架有助于 Inner Interpretability 抵御质疑，并为解释 AI 系统提供一个高效路径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01352v2",
      "published_date": "2024-06-03 14:16:56 UTC",
      "updated_date": "2024-07-31 13:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:31:46.147150"
    },
    {
      "arxiv_id": "2406.01333v1",
      "title": "Probing Language Models for Pre-training Data Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenhua Liu",
        "Tong Zhu",
        "Chuanyuan Tan",
        "Haonan Lu",
        "Bing Liu",
        "Wenliang Chen"
      ],
      "abstract": "Large Language Models (LLMs) have shown their impressive capabilities, while\nalso raising concerns about the data contamination problems due to privacy\nissues and leakage of benchmark datasets in the pre-training phase. Therefore,\nit is vital to detect the contamination by checking whether an LLM has been\npre-trained on the target texts. Recent studies focus on the generated texts\nand compute perplexities, which are superficial features and not reliable. In\nthis study, we propose to utilize the probing technique for pre-training data\ndetection by examining the model's internal activations. Our method is simple\nand effective and leads to more trustworthy pre-training data detection.\nAdditionally, we propose ArxivMIA, a new challenging benchmark comprising arxiv\nabstracts from Computer Science and Mathematics categories. Our experiments\ndemonstrate that our method outperforms all baselines, and achieves\nstate-of-the-art performance on both WikiMIA and ArxivMIA, with additional\nexperiments confirming its efficacy (Our code and dataset are available at\nhttps://github.com/zhliu0106/probing-lm-data).",
      "tldr_zh": "本研究探讨了检测大型语言模型 (LLMs) 是否在预训练阶段使用目标文本的问题，以解决数据污染带来的隐私和基准数据集泄露风险。现有方法依赖生成的文本和困惑度 (perplexities) 等浅层特征，缺乏可靠性；为此，作者提出了一种利用 probing 技术的方法，通过检查模型的内部激活 (internal activations) 来实现更可信的预训练数据检测。研究还引入了新的基准 ArxivMIA（包含计算机科学和数学领域的 arXiv 摘要），实验结果显示，该方法在 WikiMIA 和 ArxivMIA 上优于所有基线，达到了最先进性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL-2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2406.01333v1",
      "published_date": "2024-06-03 13:58:04 UTC",
      "updated_date": "2024-06-03 13:58:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:31:58.538821"
    },
    {
      "arxiv_id": "2406.01329v1",
      "title": "Transferring Domain Knowledge with (X)AI-Based Learning Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Spitzer",
        "Niklas Kühl",
        "Marc Goutier",
        "Manuel Kaschura",
        "Gerhard Satzger"
      ],
      "abstract": "In numerous high-stakes domains, training novices via conventional learning\nsystems does not suffice. To impart tacit knowledge, experts' hands-on guidance\nis imperative. However, training novices by experts is costly and\ntime-consuming, increasing the need for alternatives. Explainable artificial\nintelligence (XAI) has conventionally been used to make black-box artificial\nintelligence systems interpretable. In this work, we utilize XAI as an\nalternative: An (X)AI system is trained on experts' past decisions and is then\nemployed to teach novices by providing examples coupled with explanations. In a\nstudy with 249 participants, we measure the effectiveness of such an approach\nfor a classification task. We show that (X)AI-based learning systems are able\nto induce learning in novices and that their cognitive styles moderate\nlearning. Thus, we take the first steps to reveal the impact of XAI on human\nlearning and point AI developers to future options to tailor the design of\n(X)AI-based learning systems.",
      "tldr_zh": "该研究探讨了如何利用可解释人工智能（XAI）来转移领域知识，以解决传统学习系统在高风险领域训练新手的不足问题。作者提出一种（X）AI-based学习系统，该系统基于专家过去的决策进行训练，并通过提供例子和解释来指导新手。在一项涉及249名参与者的分类任务实验中，结果显示这种系统能有效促进新手的学习，且学习效果受参与者认知风格的影响。该方法为未来设计定制化的（X)AI-based学习系统提供了新方向。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Thirty-Second European Conference on Information Systems (ECIS 2024),\n  Paphos, Cyprus",
      "pdf_url": "http://arxiv.org/pdf/2406.01329v1",
      "published_date": "2024-06-03 13:56:30 UTC",
      "updated_date": "2024-06-03 13:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:32:10.366416"
    },
    {
      "arxiv_id": "2406.01321v1",
      "title": "Sequence-to-Sequence Multi-Modal Speech In-Painting",
      "title_zh": "翻译失败",
      "authors": [
        "Mahsa Kadkhodaei Elyaderani",
        "Shahram Shirani"
      ],
      "abstract": "Speech in-painting is the task of regenerating missing audio contents using\nreliable context information. Despite various recent studies in multi-modal\nperception of audio in-painting, there is still a need for an effective\ninfusion of visual and auditory information in speech in-painting. In this\npaper, we introduce a novel sequence-to-sequence model that leverages the\nvisual information to in-paint audio signals via an encoder-decoder\narchitecture. The encoder plays the role of a lip-reader for facial recordings\nand the decoder takes both encoder outputs as well as the distorted audio\nspectrograms to restore the original speech. Our model outperforms an\naudio-only speech in-painting model and has comparable results with a recent\nmulti-modal speech in-painter in terms of speech quality and intelligibility\nmetrics for distortions of 300 ms to 1500 ms duration, which proves the\neffectiveness of the introduced multi-modality in speech in-painting.",
      "tldr_zh": "本论文提出了一种sequence-to-sequence多模态语音修复（speech in-painting）模型，通过融合视觉和听觉信息来再生缺失的音频内容。模型采用encoder-decoder架构，其中encoder充当lip-reader处理面部录像，decoder则结合encoder输出和扭曲音频spectrograms来恢复原始语音。该方法在300 ms至1500 ms的扭曲持续时间内，优于音频-only模型，并在语音质量和intelligibility指标上与现有多模态模型表现相当，证明了多模态融合的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01321v1",
      "published_date": "2024-06-03 13:42:10 UTC",
      "updated_date": "2024-06-03 13:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:32:23.820262"
    },
    {
      "arxiv_id": "2406.01317v3",
      "title": "The Intelligible and Effective Graph Neural Additive Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Maya Bechler-Speicher",
        "Amir Globerson",
        "Ran Gilad-Bachrach"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as the predominant approach for\nlearning over graph-structured data. However, most GNNs operate as black-box\nmodels and require post-hoc explanations, which may not suffice in high-stakes\nscenarios where transparency is crucial. In this paper, we present a GNN that\nis interpretable by design. Our model, Graph Neural Additive Network (GNAN), is\na novel extension of the interpretable class of Generalized Additive Models,\nand can be visualized and fully understood by humans. GNAN is designed to be\nfully interpretable, offering both global and local explanations at the feature\nand graph levels through direct visualization of the model. These\nvisualizations describe exactly how the model uses the relationships between\nthe target variable, the features, and the graph. We demonstrate the\nintelligibility of GNANs in a series of examples on different tasks and\ndatasets. In addition, we show that the accuracy of GNAN is on par with\nblack-box GNNs, making it suitable for critical applications where transparency\nis essential, alongside high accuracy.",
      "tldr_zh": "本研究针对图神经网络 (GNNs) 的黑盒特性问题，提出了一种可解释设计的新模型：Graph Neural Additive Network (GNAN)。GNAN 基于 Generalized Additive Models 的扩展，通过直接可视化提供特征和图级别的全局及局部解释，帮助理解模型如何利用目标变量、特征和图结构之间的关系。实验结果显示，GNAN 在各种任务和数据集上表现出色，其准确性与传统黑盒 GNNs 相当，使其适用于需要高透明度的关键应用场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01317v3",
      "published_date": "2024-06-03 13:29:36 UTC",
      "updated_date": "2024-12-06 18:25:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:32:34.103681"
    },
    {
      "arxiv_id": "2406.06567v2",
      "title": "DHA: Learning Decoupled-Head Attention from Transformer Checkpoints via Adaptive Heads Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yilong Chen",
        "Linhao Zhang",
        "Junyuan Shang",
        "Zhenyu Zhang",
        "Tingwen Liu",
        "Shuohuan Wang",
        "Yu Sun"
      ],
      "abstract": "Large language models (LLMs) with billions of parameters demonstrate\nimpressive performance. However, the widely used Multi-Head Attention (MHA) in\nLLMs incurs substantial computational and memory costs during inference. While\nsome efforts have optimized attention mechanisms by pruning heads or sharing\nparameters among heads, these methods often lead to performance degradation or\nnecessitate substantial continued pre-training costs to restore performance.\nBased on the analysis of attention redundancy, we design a Decoupled-Head\nAttention (DHA) mechanism. DHA adaptively configures group sharing for key\nheads and value heads across various layers, achieving a better balance between\nperformance and efficiency. Inspired by the observation of clustering similar\nheads, we propose to progressively transform the MHA checkpoint into the DHA\nmodel through linear fusion of similar head parameters step by step, retaining\nthe parametric knowledge of the MHA checkpoint. We construct DHA models by\ntransforming various scales of MHA checkpoints given target head budgets. Our\nexperiments show that DHA remarkably requires a mere 0.25\\% of the original\nmodel's pre-training budgets to achieve 97.6\\% of performance while saving 75\\%\nof KV cache. Compared to Group-Query Attention (GQA), DHA achieves a 5$\\times$\ntraining acceleration, a maximum of 13.93\\% performance improvement under\n0.01\\% pre-training budget, and 4\\% relative improvement under 0.05\\%\npre-training budget.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)中 Multi-Head Attention (MHA) 的高计算和内存成本，提出了一种 Decoupled-Head Attention (DHA) 机制，通过自适应配置 key heads 和 value heads 的分组共享，实现性能与效率的平衡。DHA 基于注意力冗余分析，采用线性融合类似 heads 参数的逐步转换方法，从 MHA 检查点迁移知识，仅需 0.25% 的原始预训练预算即可保留 97.6% 的性能，同时节省 75% 的 KV cache。与 Group-Query Attention (GQA) 相比，DHA 实现了 5 倍训练加速，并在极低预训练预算下提升最多 13.93% 的性能。实验结果证明了 DHA 在优化 Transformer 模型方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024 10 pages, 9 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.06567v2",
      "published_date": "2024-06-03 13:28:43 UTC",
      "updated_date": "2024-12-07 13:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:32:47.443071"
    },
    {
      "arxiv_id": "2406.01316v2",
      "title": "Enhancing Inertial Hand based HAR through Joint Representation of Language, Pose and Synthetic IMUs",
      "title_zh": "翻译失败",
      "authors": [
        "Vitor Fortes Rey",
        "Lala Shakti Swarup Ray",
        "Xia Qingxin",
        "Kaishun Wu",
        "Paul Lukowicz"
      ],
      "abstract": "Due to the scarcity of labeled sensor data in HAR, prior research has turned\nto video data to synthesize Inertial Measurement Units (IMU) data, capitalizing\non its rich activity annotations. However, generating IMU data from videos\npresents challenges for HAR in real-world settings, attributed to the poor\nquality of synthetic IMU data and its limited efficacy in subtle, fine-grained\nmotions. In this paper, we propose Multi$^3$Net, our novel multi-modal,\nmultitask, and contrastive-based framework approach to address the issue of\nlimited data. Our pretraining procedure uses videos from online repositories,\naiming to learn joint representations of text, pose, and IMU simultaneously. By\nemploying video data and contrastive learning, our method seeks to enhance\nwearable HAR performance, especially in recognizing subtle activities.Our\nexperimental findings validate the effectiveness of our approach in improving\nHAR performance with IMU data. We demonstrate that models trained with\nsynthetic IMU data generated from videos using our method surpass existing\napproaches in recognizing fine-grained activities.",
      "tldr_zh": "该研究针对人体活动识别（HAR）中标记传感器数据稀缺的问题，提出 Multi³Net 框架，该框架是一种多模态、多任务和基于对比学习的方法，通过利用在线视频数据来学习文本、姿态和合成 IMU（Inertial Measurement Units）的联合表示，从而提升可穿戴 HAR 性能。Multi³Net 采用预训练过程来处理合成 IMU 数据质量差和细粒度动作识别的挑战，特别是针对微妙活动。实验结果显示，使用该方法生成的合成 IMU 数据训练的模型在识别细粒度活动时，超过了现有方法的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ISWC 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01316v2",
      "published_date": "2024-06-03 13:28:42 UTC",
      "updated_date": "2024-07-27 13:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:33:09.818901"
    },
    {
      "arxiv_id": "2406.01314v1",
      "title": "Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization",
      "title_zh": "计算高效的医疗",
      "authors": [
        "Firas Khader",
        "Omar S. M. El Nahhas",
        "Tianyu Han",
        "Gustav Müller-Franzes",
        "Sven Nebelung",
        "Jakob Nikolas Kather",
        "Daniel Truhn"
      ],
      "abstract": "The Transformer model has been pivotal in advancing fields such as natural\nlanguage processing, speech recognition, and computer vision. However, a\ncritical limitation of this model is its quadratic computational and memory\ncomplexity relative to the sequence length, which constrains its application to\nlonger sequences. This is especially crucial in medical imaging where\nhigh-resolution images can reach gigapixel scale. Efforts to address this issue\nhave predominantely focused on complex techniques, such as decomposing the\nsoftmax operation integral to the Transformer's architecture. This paper\naddresses this quadratic computational complexity of Transformer models and\nintroduces a remarkably simple and effective method that circumvents this issue\nby eliminating the softmax function from the attention mechanism and adopting a\nsequence normalization technique for the key, query, and value tokens. Coupled\nwith a reordering of matrix multiplications this approach reduces the memory-\nand compute complexity to a linear scale. We evaluate this approach across\nvarious medical imaging datasets comprising fundoscopic, dermascopic,\nradiologic and histologic imaging data. Our findings highlight that these\nmodels exhibit a comparable performance to traditional transformer models,\nwhile efficiently handling longer sequences.",
      "tldr_zh": "本文针对Transformer模型在医疗图像分类中的二次方计算和内存复杂度问题，提出了一种简单有效的解决方案：去除注意力机制中的softmax函数，并采用sequence normalization技术处理key、query和value tokens，同时重新排序矩阵乘法，以将复杂度降为线性级别。该方法在眼底、皮肤镜、放射学和组织学等医疗图像数据集上进行评估，结果显示其性能与传统Transformer模型相当，但能更高效处理长序列，从而提升了高分辨率图像处理的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01314v1",
      "published_date": "2024-06-03 13:27:08 UTC",
      "updated_date": "2024-06-03 13:27:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:33:10.738210"
    },
    {
      "arxiv_id": "2406.01309v3",
      "title": "REvolve: Reward Evolution with Large Language Models using Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Rishi Hazra",
        "Alkis Sygkounas",
        "Andreas Persson",
        "Amy Loutfi",
        "Pedro Zuidberg Dos Martires"
      ],
      "abstract": "Designing effective reward functions is crucial to training reinforcement\nlearning (RL) algorithms. However, this design is non-trivial, even for domain\nexperts, due to the subjective nature of certain tasks that are hard to\nquantify explicitly. In recent works, large language models (LLMs) have been\nused for reward generation from natural language task descriptions, leveraging\ntheir extensive instruction tuning and commonsense understanding of human\nbehavior. In this work, we hypothesize that LLMs, guided by human feedback, can\nbe used to formulate reward functions that reflect human implicit knowledge. We\nstudy this in three challenging settings -- autonomous driving, humanoid\nlocomotion, and dexterous manipulation -- wherein notions of ``good\" behavior\nare tacit and hard to quantify. To this end, we introduce REvolve, a truly\nevolutionary framework that uses LLMs for reward design in RL. REvolve\ngenerates and refines reward functions by utilizing human feedback to guide the\nevolution process, effectively translating implicit human knowledge into\nexplicit reward functions for training (deep) RL agents. Experimentally, we\ndemonstrate that agents trained on REvolve-designed rewards outperform other\nstate-of-the-art baselines.",
      "tldr_zh": "该论文探讨了设计强化学习（RL）算法奖励函数的挑战，特别是主观任务的量化难题，并提出使用大型语言模型（LLMs）结合人类反馈来生成和优化奖励函数。研究引入 REvolve 框架，这是一个进化式框架，通过人类反馈指导 LLMs 翻译隐性知识为显性奖励函数，并在自动驾驶、人形运动和灵巧操作等场景中进行实验。结果显示，使用 REvolve 设计的奖励训练的 RL 代理性能优于现有基线方法。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Published in ICLR 2025. Project page:\n  https://rishihazra.github.io/REvolve",
      "pdf_url": "http://arxiv.org/pdf/2406.01309v3",
      "published_date": "2024-06-03 13:23:27 UTC",
      "updated_date": "2025-04-06 20:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:33:25.178133"
    },
    {
      "arxiv_id": "2406.01304v3",
      "title": "CodeR: Issue Resolving with Multi-Agent and Task Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Chen",
        "Shaoxin Lin",
        "Muhan Zeng",
        "Daoguang Zan",
        "Jian-Gang Wang",
        "Anton Cheshkov",
        "Jun Sun",
        "Hao Yu",
        "Guoliang Dong",
        "Artem Aliev",
        "Jie Wang",
        "Xiao Cheng",
        "Guangtai Liang",
        "Yuchi Ma",
        "Pan Bian",
        "Tao Xie",
        "Qianxiang Wang"
      ],
      "abstract": "GitHub issue resolving recently has attracted significant attention from\nacademia and industry. SWE-bench is proposed to measure the performance in\nresolving issues. In this paper, we propose CodeR, which adopts a multi-agent\nframework and pre-defined task graphs to Repair & Resolve reported bugs and add\nnew features within code Repository. On SWE-bench lite, CodeR is able to solve\n28.33% of issues, when submitting only once for each issue. We examine the\nperformance impact of each design of CodeR and offer insights to advance this\nresearch direction.",
      "tldr_zh": "该研究提出了 CodeR，一种基于 multi-agent 框架和预定义 task graphs 的方法，用于自动修复 GitHub 报告的 bug 并添加新功能。CodeR 框架旨在提升软件工程问题的解决效率，在 SWE-bench lite 测试中，仅提交一次便成功解决了 28.33% 的问题。论文还分析了各设计组件对性能的影响，并提供见解以推动该研究方向的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "https://github.com/NL2Code/CodeR",
      "pdf_url": "http://arxiv.org/pdf/2406.01304v3",
      "published_date": "2024-06-03 13:13:35 UTC",
      "updated_date": "2024-06-11 03:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:33:35.548232"
    },
    {
      "arxiv_id": "2406.01288v2",
      "title": "Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses",
      "title_zh": "改进的少样本越狱攻击能够",
      "authors": [
        "Xiaosen Zheng",
        "Tianyu Pang",
        "Chao Du",
        "Qian Liu",
        "Jing Jiang",
        "Min Lin"
      ],
      "abstract": "Recently, Anil et al. (2024) show that many-shot (up to hundreds of)\ndemonstrations can jailbreak state-of-the-art LLMs by exploiting their\nlong-context capability. Nevertheless, is it possible to use few-shot\ndemonstrations to efficiently jailbreak LLMs within limited context sizes?\nWhile the vanilla few-shot jailbreaking may be inefficient, we propose improved\ntechniques such as injecting special system tokens like [/INST] and employing\ndemo-level random search from a collected demo pool. These simple techniques\nresult in surprisingly effective jailbreaking against aligned LLMs (even with\nadvanced defenses). For examples, our method achieves >80% (mostly >95%) ASRs\non Llama-2-7B and Llama-3-8B without multiple restarts, even if the models are\nenhanced by strong defenses such as perplexity detection and/or SmoothLLM,\nwhich is challenging for suffix-based jailbreaking. In addition, we conduct\ncomprehensive and elaborate (e.g., making sure to use correct system prompts)\nevaluations against other aligned LLMs and advanced defenses, where our method\nconsistently achieves nearly 100% ASRs. Our code is available at\nhttps://github.com/sail-sg/I-FSJ.",
      "tldr_zh": "这篇论文提出改进的 few-shot jailbreaking 技术，能够在有限上下文长度下高效绕过对齐的大型语言模型（LLMs）及其防御机制，相比传统方法更具针对性。关键方法包括注入特殊系统标记（如 [/INST]）和从演示池中进行演示级随机搜索，这些简单技巧显著提升了攻击成功率（ASR）。实验结果显示，该方法在 Llama-2-7B 和 Llama-3-8B 等模型上实现超过 80%（多数超过 95%）的 ASR，即使面对高级防御如 perplexity detection 和 SmoothLLM 也能保持近 100% 的有效性，为评估和强化 LLMs 安全提供了新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01288v2",
      "published_date": "2024-06-03 12:59:17 UTC",
      "updated_date": "2024-10-30 12:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:33:48.525247"
    },
    {
      "arxiv_id": "2406.01647v2",
      "title": "An Analysis under a Unified Fomulation of Learning Algorithms with Output Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Mooho Song",
        "Jay-Yoon Lee"
      ],
      "abstract": "Neural networks (NN) perform well in diverse tasks, but sometimes produce\nnonsensical results to humans. Most NN models \"solely\" learn from (input,\noutput) pairs, occasionally conflicting with human knowledge. Many studies\nindicate injecting human knowledge by reducing output constraints during\ntraining can improve model performance and reduce constraint violations. While\nthere have been several attempts to compare different existing algorithms under\nthe same programming framework, nonetheless, there has been no previous work\nthat categorizes learning algorithms with output constraints in a unified\nmanner. Our contributions are as follows: (1) We categorize the previous\nstudies based on three axes: type of constraint loss used (e.g. probabilistic\nsoft logic, REINFORCE), exploration strategy of constraint-violating examples,\nand integration mechanism of learning signals from main task and constraint.\n(2) We propose new algorithms to integrate the information of main task and\nconstraint injection, inspired by continual-learning algorithms. (3)\nFurthermore, we propose the $H\\beta$-score as a metric for considering the main\ntask metric and constraint violation simultaneously. To provide a thorough\nanalysis, we examine all the algorithms on three NLP tasks: natural language\ninference (NLI), synthetic transduction examples (STE), and semantic role\nlabeling (SRL). We explore and reveal the key factors of various algorithms\nassociated with achieving high $H\\beta$-scores.",
      "tldr_zh": "该论文分析了带有输出约束的学习算法，通过一个统一框架解决神经网络（NN）在学习（输入、输出）对时可能违反人类知识的问题。主要贡献包括：基于三个轴（约束损失类型如 probabilistic soft logic 和 REINFORCE、探索策略以及学习信号集成机制）对现有研究进行分类，并提出受 continual-learning 算法启发的新算法来整合主任务和约束信息。此外，论文引入 $H\\beta$-score 作为同时评估主任务指标和约束违规的度量，并在三个 NLP 任务（natural language inference (NLI)、synthetic transduction examples (STE) 和 semantic role labeling (SRL)）上进行实验，揭示了影响高 $H\\beta$-scores 的关键因素。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01647v2",
      "published_date": "2024-06-03 12:58:29 UTC",
      "updated_date": "2024-08-21 11:55:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:34:00.196975"
    },
    {
      "arxiv_id": "2406.01285v1",
      "title": "Large Language Models as Recommender Systems: A Study of Popularity Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Malte Lichtenberg",
        "Alexander Buchholz",
        "Pola Schwöbel"
      ],
      "abstract": "The issue of popularity bias -- where popular items are disproportionately\nrecommended, overshadowing less popular but potentially relevant items --\nremains a significant challenge in recommender systems. Recent advancements\nhave seen the integration of general-purpose Large Language Models (LLMs) into\nthe architecture of such systems. This integration raises concerns that it\nmight exacerbate popularity bias, given that the LLM's training data is likely\ndominated by popular items. However, it simultaneously presents a novel\nopportunity to address the bias via prompt tuning. Our study explores this\ndichotomy, examining whether LLMs contribute to or can alleviate popularity\nbias in recommender systems. We introduce a principled way to measure\npopularity bias by discussing existing metrics and proposing a novel metric\nthat fulfills a series of desiderata. Based on our new metric, we compare a\nsimple LLM-based recommender to traditional recommender systems on a movie\nrecommendation task. We find that the LLM recommender exhibits less popularity\nbias, even without any explicit mitigation.",
      "tldr_zh": "这篇论文探讨了在推荐系统中使用大型语言模型（LLMs）对流行度偏差（popularity bias）的影响，流行度偏差是指流行项被过度推荐而忽略了潜在相关但不流行的项。研究者分析了LLMs整合可能加剧偏差的风险，同时通过提示调整（prompt tuning）探索缓解策略，并引入了一个新指标来精确测量这种偏差。实验结果显示，在电影推荐任务中，简单的LLMs推荐系统比传统系统表现出更少的流行度偏差，即使未采用任何显式缓解措施。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at Gen-IR@SIGIR24 workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.01285v1",
      "published_date": "2024-06-03 12:53:37 UTC",
      "updated_date": "2024-06-03 12:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:34:12.065963"
    },
    {
      "arxiv_id": "2406.01283v1",
      "title": "Focus on the Core: Efficient Attention via Pruned Token Compression for Document Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Jungmin Yun",
        "Mihyeon Kim",
        "Youngbin Kim"
      ],
      "abstract": "Transformer-based models have achieved dominant performance in numerous NLP\ntasks. Despite their remarkable successes, pre-trained transformers such as\nBERT suffer from a computationally expensive self-attention mechanism that\ninteracts with all tokens, including the ones unfavorable to classification\nperformance. To overcome these challenges, we propose integrating two\nstrategies: token pruning and token combining. Token pruning eliminates less\nimportant tokens in the attention mechanism's key and value as they pass\nthrough the layers. Additionally, we adopt fuzzy logic to handle uncertainty\nand alleviate potential mispruning risks arising from an imbalanced\ndistribution of each token's importance. Token combining, on the other hand,\ncondenses input sequences into smaller sizes in order to further compress the\nmodel. By integrating these two approaches, we not only improve the model's\nperformance but also reduce its computational demands. Experiments with various\ndatasets demonstrate superior performance compared to baseline models,\nespecially with the best improvement over the existing BERT model, achieving\n+5%p in accuracy and +5.6%p in F1 score. Additionally, memory cost is reduced\nto 0.61x, and a speedup of 1.64x is achieved.",
      "tldr_zh": "本研究针对 Transformer 模型如 BERT 在文档分类任务中自注意力机制的计算开销问题，提出了一种整合 token pruning 和 token combining 的高效注意力方法。Token pruning 通过去除不重要 tokens 并采用 fuzzy logic 处理不确定性和避免错误修剪，从而优化注意力机制；Token combining 则进一步压缩输入序列以减少模型大小。实验结果显示，该方法在各种数据集上比基线 BERT 模型提升 5% 准确率和 5.6% F1 分数，同时将内存消耗降低至 0.61x 并实现 1.64x 的速度提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2023 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.01283v1",
      "published_date": "2024-06-03 12:51:52 UTC",
      "updated_date": "2024-06-03 12:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:34:24.449821"
    },
    {
      "arxiv_id": "2406.01278v1",
      "title": "fruit-SALAD: A Style Aligned Artwork Dataset to reveal similarity perception in image embeddings",
      "title_zh": "fruit-SALAD：一种用于揭示图像嵌入中相似性感知",
      "authors": [
        "Tillmann Ohm",
        "Andres Karjus",
        "Mikhail Tamm",
        "Maximilian Schich"
      ],
      "abstract": "The notion of visual similarity is essential for computer vision, and in\napplications and studies revolving around vector embeddings of images. However,\nthe scarcity of benchmark datasets poses a significant hurdle in exploring how\nthese models perceive similarity. Here we introduce Style Aligned Artwork\nDatasets (SALADs), and an example of fruit-SALAD with 10,000 images of fruit\ndepictions. This combined semantic category and style benchmark comprises 100\ninstances each of 10 easy-to-recognize fruit categories, across 10 easy\ndistinguishable styles. Leveraging a systematic pipeline of generative image\nsynthesis, this visually diverse yet balanced benchmark demonstrates salient\ndifferences in semantic category and style similarity weights across various\ncomputational models, including machine learning models, feature extraction\nalgorithms, and complexity measures, as well as conceptual models for\nreference. This meticulously designed dataset offers a controlled and balanced\nplatform for the comparative analysis of similarity perception. The SALAD\nframework allows the comparison of how these models perform semantic category\nand style recognition task to go beyond the level of anecdotal knowledge,\nmaking it robustly quantifiable and qualitatively interpretable.",
      "tldr_zh": "本文引入了Style Aligned Artwork Datasets (SALADs)，以fruit-SALAD为例，这是一个包含10,000张水果图像的基准数据集，用于揭示图像 embeddings 中相似性感知的差异。数据集涵盖10个水果类别和10个风格，每个类别有100张图像，通过系统化的生成图像合成管道创建，确保视觉多样性和平衡。该框架允许对机器学习模型、特征提取算法等进行比较分析，量化评估它们在语义类别和风格相似性权重上的表现，提供更可靠和可解释的洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01278v1",
      "published_date": "2024-06-03 12:47:48 UTC",
      "updated_date": "2024-06-03 12:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:34:45.705815"
    },
    {
      "arxiv_id": "2406.01275v1",
      "title": "Lifting Factor Graphs with Some Unknown Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Malte Luttermann",
        "Ralf Möller",
        "Marcel Gehrke"
      ],
      "abstract": "Lifting exploits symmetries in probabilistic graphical models by using a\nrepresentative for indistinguishable objects, allowing to carry out query\nanswering more efficiently while maintaining exact answers. In this paper, we\ninvestigate how lifting enables us to perform probabilistic inference for\nfactor graphs containing factors whose potentials are unknown. We introduce the\nLifting Factor Graphs with Some Unknown Factors (LIFAGU) algorithm to identify\nsymmetric subgraphs in a factor graph containing unknown factors, thereby\nenabling the transfer of known potentials to unknown potentials to ensure a\nwell-defined semantics and allow for (lifted) probabilistic inference.",
      "tldr_zh": "本论文探讨了在概率图形模型中利用 lifting 技术处理包含未知因子的因子图（Factor Graphs），以更高效地进行概率推理，同时保持精确性。研究引入了 LIFAGU 算法，该算法通过识别因子图中的对称子图（Symmetric Subgraphs），将已知 potentials 转移到未知 potentials，确保模型语义清晰并支持提升式概率推理（Lifted Probabilistic Inference）。这一方法为处理不确定性场景的查询回答提供了新的框架，提升了推理效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Proceedings of the 17th European Conference on\n  Symbolic and Quantitative Approaches to Reasoning with Uncertainty\n  (ECSQARU-23)",
      "pdf_url": "http://arxiv.org/pdf/2406.01275v1",
      "published_date": "2024-06-03 12:44:55 UTC",
      "updated_date": "2024-06-03 12:44:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:34:48.028082"
    },
    {
      "arxiv_id": "2406.01646v1",
      "title": "iKAN: Global Incremental Learning with KAN for Human Activity Recognition Across Heterogeneous Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Mengxi Liu",
        "Sizhen Bian",
        "Bo Zhou",
        "Paul Lukowicz"
      ],
      "abstract": "This work proposes an incremental learning (IL) framework for wearable sensor\nhuman activity recognition (HAR) that tackles two challenges simultaneously:\ncatastrophic forgetting and non-uniform inputs. The scalable framework, iKAN,\npioneers IL with Kolmogorov-Arnold Networks (KAN) to replace multi-layer\nperceptrons as the classifier that leverages the local plasticity and global\nstability of splines. To adapt KAN for HAR, iKAN uses task-specific feature\nbranches and a feature redistribution layer. Unlike existing IL methods that\nprimarily adjust the output dimension or the number of classifier nodes to\nadapt to new tasks, iKAN focuses on expanding the feature extraction branches\nto accommodate new inputs from different sensor modalities while maintaining\nconsistent dimensions and the number of classifier outputs. Continual learning\nacross six public HAR datasets demonstrated the iKAN framework's incremental\nlearning performance, with a last performance of 84.9\\% (weighted F1 score) and\nan average incremental performance of 81.34\\%, which significantly outperforms\nthe two existing incremental learning methods, such as EWC (51.42\\%) and\nexperience replay (59.92\\%).",
      "tldr_zh": "本研究提出 iKAN 框架，用于可穿戴传感器的人类活动识别 (HAR)，它首次将 Kolmogorov-Arnold Networks (KAN) 应用于增量学习 (IL)，以同时解决灾难性遗忘和非均匀输入问题。iKAN 通过任务特定的特征分支和特征重分布层替换多层感知器 (multi-layer perceptrons)，利用样条的局部可塑性和全局稳定性，适应不同传感器模态的输入，同时保持分类器输出的一致性。在六个公共 HAR 数据集上的实验中，iKAN 实现了 84.9% 的最终性能 (weighted F1 score) 和 81.34% 的平均增量性能，显著优于现有方法如 EWC (51.42%) 和经验回放 (59.92%)。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "This work is submitted to Ubicomp/ISWC24 and is under review",
      "pdf_url": "http://arxiv.org/pdf/2406.01646v1",
      "published_date": "2024-06-03 12:33:27 UTC",
      "updated_date": "2024-06-03 12:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:35:01.462072"
    },
    {
      "arxiv_id": "2406.01645v1",
      "title": "FNP: Fourier Neural Processes for Arbitrary-Resolution Data Assimilation",
      "title_zh": "FNP：傅立叶神经过程用于任意分辨率数据同化",
      "authors": [
        "Kun Chen",
        "Tao Chen",
        "Peng Ye",
        "Hao Chen",
        "Kang Chen",
        "Tao Han",
        "Wanli Ouyang",
        "Lei Bai"
      ],
      "abstract": "Data assimilation is a vital component in modern global medium-range weather\nforecasting systems to obtain the best estimation of the atmospheric state by\ncombining the short-term forecast and observations. Recently, AI-based data\nassimilation approaches have attracted increasing attention for their\nsignificant advantages over traditional techniques in terms of computational\nconsumption. However, existing AI-based data assimilation methods can only\nhandle observations with a specific resolution, lacking the compatibility and\ngeneralization ability to assimilate observations with other resolutions.\nConsidering that complex real-world observations often have different\nresolutions, we propose the \\textit{\\textbf{Fourier Neural Processes}} (FNP)\nfor \\textit{arbitrary-resolution data assimilation} in this paper. Leveraging\nthe efficiency of the designed modules and flexible structure of neural\nprocesses, FNP achieves state-of-the-art results in assimilating observations\nwith varying resolutions, and also exhibits increasing advantages over the\ncounterparts as the resolution and the amount of observations increase.\nMoreover, our FNP trained on a fixed resolution can directly handle the\nassimilation of observations with out-of-distribution resolutions and the\nobservational information reconstruction task without additional fine-tuning,\ndemonstrating its excellent generalization ability across data resolutions as\nwell as across tasks.",
      "tldr_zh": "本文提出Fourier Neural Processes (FNP)，一种用于任意分辨率数据同化的新方法，旨在解决现有AI-based数据同化技术在处理不同观察分辨率时的兼容性和泛化能力不足问题。FNP通过结合高效的Fourier模块和神经过程的灵活结构，实现了在各种分辨率下吸收观察数据的状态-of-the-art性能，并在分辨率和数据量增加时表现出显著优势。实验结果表明，FNP在固定分辨率上训练后，可直接处理分布外分辨率的观察数据和信息重建任务，无需额外微调，展示了优秀的跨分辨率和跨任务泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01645v1",
      "published_date": "2024-06-03 12:24:24 UTC",
      "updated_date": "2024-06-03 12:24:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:35:12.790945"
    },
    {
      "arxiv_id": "2406.01256v1",
      "title": "Augmented Commonsense Knowledge for Remote Object Grounding",
      "title_zh": "增强的常识知识用于远程对象接地",
      "authors": [
        "Bahram Mohammadi",
        "Yicong Hong",
        "Yuankai Qi",
        "Qi Wu",
        "Shirui Pan",
        "Javen Qinfeng Shi"
      ],
      "abstract": "The vision-and-language navigation (VLN) task necessitates an agent to\nperceive the surroundings, follow natural language instructions, and act in\nphoto-realistic unseen environments. Most of the existing methods employ the\nentire image or object features to represent navigable viewpoints. However,\nthese representations are insufficient for proper action prediction, especially\nfor the REVERIE task, which uses concise high-level instructions, such as\n''Bring me the blue cushion in the master bedroom''. To address enhancing\nrepresentation, we propose an augmented commonsense knowledge model (ACK) to\nleverage commonsense information as a spatio-temporal knowledge graph for\nimproving agent navigation. Specifically, the proposed approach involves\nconstructing a knowledge base by retrieving commonsense information from\nConceptNet, followed by a refinement module to remove noisy and irrelevant\nknowledge. We further present ACK which consists of knowledge graph-aware\ncross-modal and concept aggregation modules to enhance visual representation\nand visual-textual data alignment by integrating visible objects, commonsense\nknowledge, and concept history, which includes object and knowledge temporal\ninformation. Moreover, we add a new pipeline for the commonsense-based\ndecision-making process which leads to more accurate local action prediction.\nExperimental results demonstrate our proposed model noticeably outperforms the\nbaseline and archives the state-of-the-art on the REVERIE benchmark.",
      "tldr_zh": "本论文针对视觉和语言导航(VLN)任务中的远程对象定位问题，提出了一种增强常识知识(Augmented Commonsense Knowledge)模型(ACK)，旨在通过整合常识信息来改善代理的视觉表示和行动预测。具体地，ACK从ConceptNet检索常识信息构建知识图谱，并通过知识图谱感知的跨模态模块和概念聚合模块，结合可见对象、常识知识及历史信息，增强视觉-文本数据对齐和局部决策准确性。实验结果显示，该模型在REVERIE基准上显著优于基线方法，并达到了最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01256v1",
      "published_date": "2024-06-03 12:12:33 UTC",
      "updated_date": "2024-06-03 12:12:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:35:26.739598"
    },
    {
      "arxiv_id": "2406.01255v1",
      "title": "On the Nonlinearity of Layer Normalization",
      "title_zh": "论层归一化的非线性",
      "authors": [
        "Yunhao Ni",
        "Yuxin Guo",
        "Junlong Jia",
        "Lei Huang"
      ],
      "abstract": "Layer normalization (LN) is a ubiquitous technique in deep learning but our\ntheoretical understanding to it remains elusive. This paper investigates a new\ntheoretical direction for LN, regarding to its nonlinearity and representation\ncapacity. We investigate the representation capacity of a network with\nlayerwise composition of linear and LN transformations, referred to as LN-Net.\nWe theoretically show that, given $m$ samples with any label assignment, an\nLN-Net with only 3 neurons in each layer and $O(m)$ LN layers can correctly\nclassify them. We further show the lower bound of the VC dimension of an\nLN-Net. The nonlinearity of LN can be amplified by group partition, which is\nalso theoretically demonstrated with mild assumption and empirically supported\nby our experiments. Based on our analyses, we consider to design neural\narchitecture by exploiting and amplifying the nonlinearity of LN, and the\neffectiveness is supported by our experiments.",
      "tldr_zh": "这篇论文探讨了Layer Normalization (LN) 的非线性及其在深度学习中的表示能力。研究者分析了LN-Net，一种由线性变换和LN层组成的网络结构，证明了即使每个层仅需3个神经元和O(m)个LN层，该网络也能正确分类m个样本的任意标签分配，并给出了LN-Net的VC dimension下界。通过理论分析和实验验证，论文显示LN的非线性可以通过group partition放大，从而设计出更有效的神经网络架构，实验结果证实了这一方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "42 pages, accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01255v1",
      "published_date": "2024-06-03 12:11:34 UTC",
      "updated_date": "2024-06-03 12:11:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:35:37.243712"
    },
    {
      "arxiv_id": "2406.01253v2",
      "title": "animal2vec and MeerKAT: A self-supervised transformer for rare-event raw audio input and a large-scale reference dataset for bioacoustics",
      "title_zh": "翻译失败",
      "authors": [
        "Julian C. Schäfer-Zimmermann",
        "Vlad Demartsev",
        "Baptiste Averly",
        "Kiran Dhanjal-Adams",
        "Mathieu Duteil",
        "Gabriella Gall",
        "Marius Faiß",
        "Lily Johnson-Ulrich",
        "Dan Stowell",
        "Marta B. Manser",
        "Marie A. Roch",
        "Ariana Strandburg-Peshkin"
      ],
      "abstract": "Bioacoustic research, vital for understanding animal behavior, conservation,\nand ecology, faces a monumental challenge: analyzing vast datasets where animal\nvocalizations are rare. While deep learning techniques are becoming standard,\nadapting them to bioacoustics remains difficult. We address this with\nanimal2vec, an interpretable large transformer model, and a self-supervised\ntraining scheme tailored for sparse and unbalanced bioacoustic data. It learns\nfrom unlabeled audio and then refines its understanding with labeled data.\nFurthermore, we introduce and publicly release MeerKAT: Meerkat Kalahari Audio\nTranscripts, a dataset of meerkat (Suricata suricatta) vocalizations with\nmillisecond-resolution annotations, the largest labeled dataset on non-human\nterrestrial mammals currently available. Our model outperforms existing methods\non MeerKAT and the publicly available NIPS4Bplus birdsong dataset. Moreover,\nanimal2vec performs well even with limited labeled data (few-shot learning).\nanimal2vec and MeerKAT provide a new reference point for bioacoustic research,\nenabling scientists to analyze large amounts of data even with scarce ground\ntruth information.",
      "tldr_zh": "本研究针对生物声学中动物发声稀少的数据挑战，提出 animal2vec——一个可解释的 self-supervised Transformer 模型，以及配套的自监督训练方案，用于处理稀疏和不平衡的原始音频输入。该模型先从未标记音频学习，然后通过标记数据微调，提升在 few-shot learning 场景下的性能。同时，研究团队公开了 MeerKAT 数据集，这是目前最大的非人类陆地哺乳动物发声数据集，包含猫鼬(Suricata suricatta)的毫秒级标注。实验结果显示，animal2vec 在 MeerKAT 和 NIPS4Bplus 鸟鸣数据集上优于现有方法，为生物声学研究提供新参考点，即使标记数据稀缺也能有效分析大量数据。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "q-bio.QM",
        "stat.AP"
      ],
      "primary_category": "cs.SD",
      "comment": "Code available at: https://github.com/livingingroups/animal2vec |\n  Dataset available at: https://doi.org/10.17617/3.0J0DYB",
      "pdf_url": "http://arxiv.org/pdf/2406.01253v2",
      "published_date": "2024-06-03 12:11:01 UTC",
      "updated_date": "2024-07-26 07:39:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:36:00.853101"
    },
    {
      "arxiv_id": "2406.01252v3",
      "title": "Towards Scalable Automated Alignment of LLMs: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Boxi Cao",
        "Keming Lu",
        "Xinyu Lu",
        "Jiawei Chen",
        "Mengjie Ren",
        "Hao Xiang",
        "Peilin Liu",
        "Yaojie Lu",
        "Ben He",
        "Xianpei Han",
        "Le Sun",
        "Hongyu Lin",
        "Bowen Yu"
      ],
      "abstract": "Alignment is the most critical step in building large language models (LLMs)\nthat meet human needs. With the rapid development of LLMs gradually surpassing\nhuman capabilities, traditional alignment methods based on human-annotation are\nincreasingly unable to meet the scalability demands. Therefore, there is an\nurgent need to explore new sources of automated alignment signals and technical\napproaches. In this paper, we systematically review the recently emerging\nmethods of automated alignment, attempting to explore how to achieve effective,\nscalable, automated alignment once the capabilities of LLMs exceed those of\nhumans. Specifically, we categorize existing automated alignment methods into 4\nmajor categories based on the sources of alignment signals and discuss the\ncurrent status and potential development of each category. Additionally, we\nexplore the underlying mechanisms that enable automated alignment and discuss\nthe essential factors that make automated alignment technologies feasible and\neffective from the fundamental role of alignment.",
      "tldr_zh": "本论文调查了大型语言模型（LLMs）的对齐问题，强调传统基于人工标注的方法无法满足模型能力快速提升时的可扩展性需求。作者将现有的自动化对齐方法分为4大类，根据对齐信号来源进行分类，并讨论了每类的现状、潜在发展和底层机制。论文还探讨了使自动化对齐技术可行和有效的关键因素，为实现高效、可扩展的LLMs对齐提供了系统性见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper List: https://github.com/cascip/awesome-auto-alignment",
      "pdf_url": "http://arxiv.org/pdf/2406.01252v3",
      "published_date": "2024-06-03 12:10:26 UTC",
      "updated_date": "2024-09-03 07:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:36:03.049914"
    },
    {
      "arxiv_id": "2406.01250v1",
      "title": "DumpKV: Learning based lifetime aware garbage collection for key value separation in LSM-tree",
      "title_zh": "翻译失败",
      "authors": [
        "Zhutao Zhuang",
        "Xinqi Zeng",
        "Zhiguang Chen"
      ],
      "abstract": "Key\\-value separation is used in LSM\\-tree to stored large value in separate\nlog files to reduce write amplification, but requires garbage collection to\ngarbage collect invalid values. Existing garbage collection techniques in\nLSM\\-tree typically adopt static parameter based garbage collection to garbage\ncollect obsolete values which struggles to achieve low write amplification and\nit's challenging to find proper parameter for garbage collection triggering. In\nthis work we introduce DumpKV, which introduces learning based lifetime aware\ngarbage collection with dynamic lifetime adjustment to do efficient garbage\ncollection to achieve lower write amplification. DumpKV manages large values\nusing trained lightweight model with features suitable for various application\nbased on past write access information of keys to give lifetime prediction for\neach individual key to enable efficient garbage collection. To reduce\ninterference to write throughput DumpKV conducts feature collection during\nL0\\-L1 compaction leveraging the fact that LSM\\-tree is small under KV\nseparation. Experimental results show that DumpKV achieves lower write\namplification by 38\\%\\-73\\% compared to existing key\\-value separation garbage\ncollection LSM\\-tree stores with small feature storage overhead.",
      "tldr_zh": "该论文针对LSM-tree中的Key-value separation机制提出DumpKV框架，以解决现有基于静态参数的garbage collection效率低下、写amplification高等问题。DumpKV引入学习based lifetime aware garbage collection，通过训练轻量模型基于键的过去写访问信息动态预测每个键的寿命，实现高效垃圾回收。为了减少对写吞吐量的干扰，该框架在L0-L1 compaction期间收集特征。实验结果显示，DumpKV相比现有方法降低了38%-73%的写amplification，同时保持了小的特征存储开销。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "Hi",
      "pdf_url": "http://arxiv.org/pdf/2406.01250v1",
      "published_date": "2024-06-03 12:07:22 UTC",
      "updated_date": "2024-06-03 12:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:36:14.155578"
    },
    {
      "arxiv_id": "2406.01213v1",
      "title": "Improving Pseudo Labels with Global-Local Denoising Framework for Cross-lingual Named Entity Recognition",
      "title_zh": "通过全局-局部去噪框架改进伪标签，用于跨语言命名实体识别",
      "authors": [
        "Zhuojun Ding",
        "Wei Wei",
        "Xiaoye Qu",
        "Dangyang Chen"
      ],
      "abstract": "Cross-lingual named entity recognition (NER) aims to train an NER model for\nthe target language leveraging only labeled source language data and unlabeled\ntarget language data. Prior approaches either perform label projection on\ntranslated source language data or employ a source model to assign pseudo\nlabels for target language data and train a target model on these\npseudo-labeled data to generalize to the target language. However, these\nautomatic labeling procedures inevitably introduce noisy labels, thus leading\nto a performance drop. In this paper, we propose a Global-Local Denoising\nframework (GLoDe) for cross-lingual NER. Specifically, GLoDe introduces a\nprogressive denoising strategy to rectify incorrect pseudo labels by leveraging\nboth global and local distribution information in the semantic space. The\nrefined pseudo-labeled target language data significantly improves the model's\ngeneralization ability. Moreover, previous methods only consider improving the\nmodel with language-agnostic features, however, we argue that target\nlanguage-specific features are also important and should never be ignored. To\nthis end, we employ a simple auxiliary task to achieve this goal. Experimental\nresults on two benchmark datasets with six target languages demonstrate that\nour proposed GLoDe significantly outperforms current state-of-the-art methods.",
      "tldr_zh": "本论文针对跨语言命名实体识别 (Cross-lingual NER) 的问题，提出了一种 Global-Local Denoising 框架 (GLoDe)，通过渐进式去噪策略利用全局和局部分布信息来修正伪标签 (pseudo labels)，从而提升模型在目标语言上的泛化能力。GLoDe 不仅优化了伪标签质量，还引入一个简单辅助任务来强调目标语言特定特征的重要性，以弥补现有方法的不足。在两个基准数据集上针对六种目标语言的实验结果表明，GLoDe 显著优于当前最先进方法，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01213v1",
      "published_date": "2024-06-03 11:29:19 UTC",
      "updated_date": "2024-06-03 11:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:36:26.219782"
    },
    {
      "arxiv_id": "2407.13960v1",
      "title": "Using Artificial Intelligence to Accelerate Collective Intelligence: Policy Synth and Smarter Crowdsourcing",
      "title_zh": "利用人工智能加速集体智能：Policy Synth 和 Smarter Crowdsourcing",
      "authors": [
        "Róbert Bjarnason",
        "Dane Gambrell",
        "Joshua Lanthier-Welch"
      ],
      "abstract": "In an era characterized by rapid societal changes and complex challenges,\ninstitutions' traditional methods of problem-solving in the public sector are\nincreasingly proving inadequate. In this study, we present an innovative and\neffective model for how institutions can use artificial intelligence to enable\ngroups of people to generate effective solutions to urgent problems more\nefficiently. We describe a proven collective intelligence method, called\nSmarter Crowdsourcing, which is designed to channel the collective intelligence\nof those with expertise about a problem into actionable solutions through\ncrowdsourcing. Then we introduce Policy Synth, an innovative toolkit which\nleverages AI to make the Smarter Crowdsourcing problem-solving approach both\nmore scalable, more effective and more efficient. Policy Synth is crafted using\na human-centric approach, recognizing that AI is a tool to enhance human\nintelligence and creativity, not replace it. Based on a real-world case study\ncomparing the results of expert crowdsourcing alone with expert sourcing\nsupported by Policy Synth AI agents, we conclude that Smarter Crowdsourcing\nwith Policy Synth presents an effective model for integrating the collective\nwisdom of human experts and the computational power of AI to enhance and scale\nup public problem-solving processes. While many existing approaches view AI as\na tool to make crowdsourcing and deliberative processes better and more\nefficient, Policy Synth goes a step further, recognizing that AI can also be\nused to synthesize the findings from engagements together with research to\ndevelop evidence-based solutions and policies. The study offers practical tools\nand insights for institutions looking to engage communities effectively in\naddressing urgent societal challenges.",
      "tldr_zh": "本研究探讨了如何利用人工智能（AI）加速集体智能，以应对公共部门复杂问题的传统方法不足。论文介绍了 Smarter Crowdsourcing 一种通过众包引导专家智慧生成可行动解决方案的方法，并推出了 Policy Synth 工具包，该工具基于人为中心设计，使用 AI 提升众包过程的可扩展性、有效性和效率。基于真实案例研究，相比单纯专家众包，Policy Synth 支持的模式显著提高了问题解决效率，并能合成研究发现以开发基于证据的解决方案。该方法为机构提供实用工具，帮助整合人类专家智慧与 AI 计算能力，增强应对社会挑战的能力。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2; H.4; J.4"
      ],
      "primary_category": "cs.CY",
      "comment": "51 pages, 23 figures, Submitted for ACM Collective Intelligence\n  Conference 2024, Parallel Track Presentation, Boston, MA, USA",
      "pdf_url": "http://arxiv.org/pdf/2407.13960v1",
      "published_date": "2024-06-03 11:27:23 UTC",
      "updated_date": "2024-06-03 11:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:36:40.419919"
    },
    {
      "arxiv_id": "2406.01203v1",
      "title": "Scaling Up Deep Clustering Methods Beyond ImageNet-1K",
      "title_zh": "将深度聚类方法扩展到 ImageNet-1K 之外",
      "authors": [
        "Nikolas Adaloglou",
        "Felix Michels",
        "Kaspar Senft",
        "Diana Petrusheva",
        "Markus Kollmann"
      ],
      "abstract": "Deep image clustering methods are typically evaluated on small-scale balanced\nclassification datasets while feature-based $k$-means has been applied on\nproprietary billion-scale datasets. In this work, we explore the performance of\nfeature-based deep clustering approaches on large-scale benchmarks whilst\ndisentangling the impact of the following data-related factors: i) class\nimbalance, ii) class granularity, iii) easy-to-recognize classes, and iv) the\nability to capture multiple classes. Consequently, we develop multiple new\nbenchmarks based on ImageNet21K. Our experimental analysis reveals that\nfeature-based $k$-means is often unfairly evaluated on balanced datasets.\nHowever, deep clustering methods outperform $k$-means across most large-scale\nbenchmarks. Interestingly, $k$-means underperforms on easy-to-classify\nbenchmarks by large margins. The performance gap, however, diminishes on the\nhighest data regimes such as ImageNet21K. Finally, we find that non-primary\ncluster predictions capture meaningful classes (i.e. coarser classes).",
      "tldr_zh": "本文研究了深度聚类方法在ImageNet21K等大规模基准上的性能，分析了类不平衡、类粒度、易识别类以及捕获多个类等数据因素的影响。研究者开发了基于ImageNet21K的多个新基准，并发现深度聚类方法在大多数大规模数据集上优于基于特征的k-means聚类。实验结果显示，k-means在易分类任务上表现落后，但在高数据规模如ImageNet21K上性能差距缩小，且非主要聚类预测能捕获更粗的类。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2406.01203v1",
      "published_date": "2024-06-03 11:13:27 UTC",
      "updated_date": "2024-06-03 11:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:36:50.516816"
    },
    {
      "arxiv_id": "2406.01198v1",
      "title": "Automatic Essay Multi-dimensional Scoring with Fine-tuning and Multiple Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Sun",
        "Rong Wang"
      ],
      "abstract": "Automated essay scoring (AES) involves predicting a score that reflects the\nwriting quality of an essay. Most existing AES systems produce only a single\noverall score. However, users and L2 learners expect scores across different\ndimensions (e.g., vocabulary, grammar, coherence) for English essays in\nreal-world applications. To address this need, we have developed two models\nthat automatically score English essays across multiple dimensions by employing\nfine-tuning and other strategies on two large datasets. The results demonstrate\nthat our systems achieve impressive performance in evaluation using three\ncriteria: precision, F1 score, and Quadratic Weighted Kappa. Furthermore, our\nsystem outperforms existing methods in overall scoring.",
      "tldr_zh": "这篇论文提出了一种自动作文评分（Automated Essay Scoring, AES）系统，能够为英文作文提供多维度评分（如词汇、语法和连贯性），以满足用户和 L2 学习者的需求。研究团队通过 fine-tuning 和 multiple regression 等策略，在两个大型数据集上训练了两个模型。结果显示，该系统在 precision、F1 score 和 Quadratic Weighted Kappa 等指标上表现出色，并整体上优于现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01198v1",
      "published_date": "2024-06-03 10:59:50 UTC",
      "updated_date": "2024-06-03 10:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:37:11.092002"
    },
    {
      "arxiv_id": "2406.01196v1",
      "title": "3D WholeBody Pose Estimation based on Semantic Graph Attention Network and Distance Information",
      "title_zh": "基于语义图注意力网络和距离信息的3D全身姿势估计",
      "authors": [
        "Sihan Wen",
        "Xiantan Zhu",
        "Zhiming Tan"
      ],
      "abstract": "In recent years, a plethora of diverse methods have been proposed for 3D pose\nestimation. Among these, self-attention mechanisms and graph convolutions have\nboth been proven to be effective and practical methods. Recognizing the\nstrengths of those two techniques, we have developed a novel Semantic Graph\nAttention Network which can benefit from the ability of self-attention to\ncapture global context, while also utilizing the graph convolutions to handle\nthe local connectivity and structural constraints of the skeleton. We also\ndesign a Body Part Decoder that assists in extracting and refining the\ninformation related to specific segments of the body. Furthermore, our approach\nincorporates Distance Information, enhancing our model's capability to\ncomprehend and accurately predict spatial relationships. Finally, we introduce\na Geometry Loss who makes a critical constraint on the structural skeleton of\nthe body, ensuring that the model's predictions adhere to the natural limits of\nhuman posture. The experimental results validate the effectiveness of our\napproach, demonstrating that every element within the system is essential for\nimproving pose estimation outcomes. With comparison to state-of-the-art, the\nproposed work not only meets but exceeds the existing benchmarks.",
      "tldr_zh": "本文提出了一种基于 Semantic Graph Attention Network 的 3D 全身姿态估计方法，该网络结合了 self-attention 的全局上下文捕捉能力和 graph convolutions 的局部连接与结构约束，以提升姿态预测的准确性。同时，引入了 Body Part Decoder 用于提取和精炼身体特定部位的相关信息，以及 Distance Information 和 Geometry Loss 来增强空间关系理解和确保预测符合人体骨骼的自然限制。实验结果验证了该方法的有效性，每个组件均对改善姿态估计至关重要，并超过了现有 state-of-the-art 基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01196v1",
      "published_date": "2024-06-03 10:59:00 UTC",
      "updated_date": "2024-06-03 10:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:37:14.240800"
    },
    {
      "arxiv_id": "2406.01189v3",
      "title": "MultiMax: Sparse and Multi-Modal Attention Learning",
      "title_zh": "MultiMax：稀疏与多模态注意力学习",
      "authors": [
        "Yuxuan Zhou",
        "Mario Fritz",
        "Margret Keuper"
      ],
      "abstract": "SoftMax is a ubiquitous ingredient of modern machine learning algorithms. It\nmaps an input vector onto a probability simplex and reweights the input by\nconcentrating the probability mass at large entries. Yet, as a smooth\napproximation to the Argmax function, a significant amount of probability mass\nis distributed to other, residual entries, leading to poor interpretability and\nnoise. Although sparsity can be achieved by a family of SoftMax variants, they\noften require an alternative loss function and do not preserve multi-modality.\nWe show that this trade-off between multi-modality and sparsity limits the\nexpressivity of SoftMax as well as its variants. We provide a solution to this\ntension between objectives by proposing a piece-wise differentiable function,\ntermed MultiMax, which adaptively modulates the output distribution according\nto input entry range. Through comprehensive analysis and evaluation, we show\nthat MultiMax successfully produces a distribution that supresses irrelevant\nentries while preserving multimodality, with benefits in image classification,\nlanguage modeling and machine translation. The code is available at\nhttps://github.com/ZhouYuxuanYX/MultiMax.",
      "tldr_zh": "本论文探讨了SoftMax在机器学习中的局限性，即其作为Argmax函数的平滑近似会导致过多概率质量分配给无关条目，从而影响解释性和准确性，而现有SoftMax变体在实现稀疏性时往往牺牲多模态。作者提出MultiMax，一种分段可微函数，能够根据输入条目范围自适应调节输出分布，从而同时实现稀疏性和多模态保留。实验结果显示，MultiMax在图像分类、语言建模和机器翻译任务中表现出色，提升了模型的表达力和性能，相关代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01189v3",
      "published_date": "2024-06-03 10:51:43 UTC",
      "updated_date": "2025-01-08 07:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:37:29.151485"
    },
    {
      "arxiv_id": "2406.01183v2",
      "title": "Automatic Input Feature Relevance via Spectral Neural Networks",
      "title_zh": "通过谱神经网络的输入特征自动相关性确定",
      "authors": [
        "Lorenzo Chicchi",
        "Lorenzo Buffoni",
        "Diego Febbe",
        "Lorenzo Giambagli",
        "Raffaele Marino",
        "Duccio Fanelli"
      ],
      "abstract": "In machine learning practice it is often useful to identify relevant input\nfeatures, so as to obtain compact dataset for more efficient numerical\nhandling. On the other hand, by isolating key input elements, ranked according\ntheir respective degree of relevance, can help to elaborate on the process of\ndecision making. Here, we propose a novel method to estimate the relative\nimportance of the input components for a Deep Neural Network. This is achieved\nby leveraging on a spectral re-parametrization of the optimization process.\nEigenvalues associated to input nodes provide in fact a robust proxy to gauge\nthe relevance of the supplied entry features. Notably, the spectral features\nranking is performed automatically, as a byproduct of the network training,\nwith no additional processing to be carried out. The technique is successfully\nchallenged against both synthetic and real data.",
      "tldr_zh": "该论文提出了一种通过谱神经网络（Spectral Neural Networks）自动评估输入特征相关性的新方法，以简化数据集并提升机器学习决策过程的可解释性。方法利用谱重参数化（spectral re-parametrization）在网络训练过程中，借助输入节点的特征值（eigenvalues）作为特征重要性的代理指标，实现无需额外处理的自动排名。在合成和真实数据上的实验验证表明，该技术有效，显著提高了输入特征的识别准确性。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01183v2",
      "published_date": "2024-06-03 10:39:12 UTC",
      "updated_date": "2025-05-05 07:48:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:37:38.958617"
    },
    {
      "arxiv_id": "2406.01179v2",
      "title": "Are AI-Generated Text Detectors Robust to Adversarial Perturbations?",
      "title_zh": "AI 生成的文本检测器对对抗性扰动是否鲁棒？",
      "authors": [
        "Guanhua Huang",
        "Yuchen Zhang",
        "Zhe Li",
        "Yongjian You",
        "Mingze Wang",
        "Zhouwang Yang"
      ],
      "abstract": "The widespread use of large language models (LLMs) has sparked concerns about\nthe potential misuse of AI-generated text, as these models can produce content\nthat closely resembles human-generated text. Current detectors for AI-generated\ntext (AIGT) lack robustness against adversarial perturbations, with even minor\nchanges in characters or words causing a reversal in distinguishing between\nhuman-created and AI-generated text. This paper investigates the robustness of\nexisting AIGT detection methods and introduces a novel detector, the Siamese\nCalibrated Reconstruction Network (SCRN). The SCRN employs a reconstruction\nnetwork to add and remove noise from text, extracting a semantic representation\nthat is robust to local perturbations. We also propose a siamese calibration\ntechnique to train the model to make equally confidence predictions under\ndifferent noise, which improves the model's robustness against adversarial\nperturbations. Experiments on four publicly available datasets show that the\nSCRN outperforms all baseline methods, achieving 6.5\\%-18.25\\% absolute\naccuracy improvement over the best baseline method under adversarial attacks.\nMoreover, it exhibits superior generalizability in cross-domain, cross-genre,\nand mixed-source scenarios. The code is available at\n\\url{https://github.com/CarlanLark/Robust-AIGC-Detector}.",
      "tldr_zh": "该研究调查了AI生成文本（AIGT）检测器的鲁棒性，发现现有方法对对抗性扰动（adversarial perturbations）高度敏感，即使微小改动就可能导致检测失效。为此，论文提出了一种新型检测器Siamese Calibrated Reconstruction Network (SCRN)，它通过重建网络添加和移除噪声来提取鲁棒的语义表示，并采用siamese calibration技术训练模型，使其在不同噪声条件下保持一致的置信度，从而提升对抗性鲁棒性。实验在四个公开数据集上显示，SCRN在对抗攻击下比最佳基线方法提高6.5%至18.25%的绝对准确率，并在跨域、跨类型和混合来源场景中表现出色泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2406.01179v2",
      "published_date": "2024-06-03 10:21:48 UTC",
      "updated_date": "2024-06-26 12:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:37:51.245986"
    },
    {
      "arxiv_id": "2406.01168v2",
      "title": "How Ethical Should AI Be? How AI Alignment Shapes the Risk Preferences of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Shumiao Ouyang",
        "Hayong Yun",
        "Xingjian Zheng"
      ],
      "abstract": "This study examines the risk preferences of Large Language Models (LLMs) and\nhow aligning them with human ethical standards affects their economic\ndecision-making. Analyzing 30 LLMs reveals a range of inherent risk profiles,\nfrom risk-averse to risk-seeking. We find that aligning LLMs with human values,\nfocusing on harmlessness, helpfulness, and honesty, shifts them towards risk\naversion. While some alignment improves investment forecast accuracy, excessive\nalignment leads to overly cautious predictions, potentially resulting in severe\nunderinvestment. Our findings highlight the need for a nuanced approach that\nbalances ethical alignment with the specific requirements of economic domains\nwhen using LLMs in finance.",
      "tldr_zh": "这篇研究探讨了AI对齐如何影响大型语言模型(LLMs)的风险偏好，并分析其在经济决策中的作用。研究者评估了30个LLMs，发现这些模型的固有风险特征从风险厌恶到风险寻求不等，而将LLMs与人类伦理标准（如无害性、帮助性和诚实性）对齐，会使其整体转向风险厌恶。适度对齐可提升投资预测的准确性，但过度对齐可能导致过于谨慎的预测，从而引发严重投资不足。最终，研究强调在金融领域使用LLMs时，需要平衡伦理对齐与具体经济需求。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.HC",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01168v2",
      "published_date": "2024-06-03 10:05:25 UTC",
      "updated_date": "2024-08-01 21:28:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:38:05.096732"
    },
    {
      "arxiv_id": "2406.01149v1",
      "title": "Agnostic Learning of Mixed Linear Regressions with EM and AM Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Avishek Ghosh",
        "Arya Mazumdar"
      ],
      "abstract": "Mixed linear regression is a well-studied problem in parametric statistics\nand machine learning. Given a set of samples, tuples of covariates and labels,\nthe task of mixed linear regression is to find a small list of linear\nrelationships that best fit the samples. Usually it is assumed that the label\nis generated stochastically by randomly selecting one of two or more linear\nfunctions, applying this chosen function to the covariates, and potentially\nintroducing noise to the result. In that situation, the objective is to\nestimate the ground-truth linear functions up to some parameter error. The\npopular expectation maximization (EM) and alternating minimization (AM)\nalgorithms have been previously analyzed for this.\n  In this paper, we consider the more general problem of agnostic learning of\nmixed linear regression from samples, without such generative models. In\nparticular, we show that the AM and EM algorithms, under standard conditions of\nseparability and good initialization, lead to agnostic learning in mixed linear\nregression by converging to the population loss minimizers, for suitably\ndefined loss functions. In some sense, this shows the strength of AM and EM\nalgorithms that converges to ``optimal solutions'' even in the absence of\nrealizable generative models.",
      "tldr_zh": "本文探讨了混合线性回归（mixed linear regression）的无假设学习（agnostic learning）问题，不依赖于传统的生成模型假设。研究者分析了期望最大化（EM）算法和交替最小化（AM）算法，在可分离性和良好初始化条件下，这些算法能收敛到总体损失函数的最小化器，从而实现对样本的有效拟合。该工作证明了EM和AM算法的鲁棒性，即使在没有可实现生成模型的情况下，也能找到近似最优解，为更广泛的机器学习应用提供了理论基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "stat.ML",
      "comment": "To appear in ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01149v1",
      "published_date": "2024-06-03 09:43:24 UTC",
      "updated_date": "2024-06-03 09:43:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:38:16.168257"
    },
    {
      "arxiv_id": "2406.02616v5",
      "title": "Adaptive Layer Splitting for Wireless LLM Inference in Edge Computing: A Model-Based Reinforcement Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Chen",
        "Rongpeng Li",
        "Xiaoxue Yu",
        "Zhifeng Zhao",
        "Honggang Zhang"
      ],
      "abstract": "Optimizing the deployment of large language models (LLMs) in edge computing\nenvironments is critical for enhancing privacy and computational efficiency.\nToward efficient wireless LLM inference in edge computing, this study\ncomprehensively analyzes the impact of different splitting points in mainstream\nopen-source LLMs. On this basis, this study introduces a framework taking\ninspiration from model-based reinforcement learning (MBRL) to determine the\noptimal splitting point across the edge and user equipment (UE). By\nincorporating a reward surrogate model, our approach significantly reduces the\ncomputational cost of frequent performance evaluations. Extensive simulations\ndemonstrate that this method effectively balances inference performance and\ncomputational load under varying network conditions, providing a robust\nsolution for LLM deployment in decentralized settings.",
      "tldr_zh": "这篇论文针对边缘计算环境中无线LLM推理的部署优化，分析了主流开源LLMs的不同层分割点对隐私和计算效率的影响。作者引入了一个基于模型的强化学习(MBRL)框架，通过奖励代理模型动态确定最佳分割点，从而显著降低频繁性能评估的计算成本。模拟实验显示，该方法在不同网络条件下有效平衡了推理性能和计算负载，为分散式LLM部署提供了可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02616v5",
      "published_date": "2024-06-03 09:41:42 UTC",
      "updated_date": "2024-09-11 11:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:38:38.517719"
    },
    {
      "arxiv_id": "2406.01140v2",
      "title": "Logical Reasoning with Relation Network for Inductive Knowledge Graph Completion",
      "title_zh": "基于关系网络的逻辑推理用于",
      "authors": [
        "Qinggang Zhang",
        "Keyu Duan",
        "Junnan Dong",
        "Pai Zheng",
        "Xiao Huang"
      ],
      "abstract": "Inductive knowledge graph completion (KGC) aims to infer the missing relation\nfor a set of newly-coming entities that never appeared in the training set.\nSuch a setting is more in line with reality, as real-world KGs are constantly\nevolving and introducing new knowledge. Recent studies have shown promising\nresults using message passing over subgraphs to embed newly-coming entities for\ninductive KGC. However, the inductive capability of these methods is usually\nlimited by two key issues. (i) KGC always suffers from data sparsity, and the\nsituation is even exacerbated in inductive KGC where new entities often have\nfew or no connections to the original KG. (ii) Cold-start problem. It is over\ncoarse-grained for accurate KG reasoning to generate representations for new\nentities by gathering the local information from few neighbors. To this end, we\npropose a novel iNfOmax RelAtion Network, namely NORAN, for inductive KG\ncompletion. It aims to mine latent relation patterns for inductive KG\ncompletion. Specifically, by centering on relations, NORAN provides a hyper\nview towards KG modeling, where the correlations between relations can be\nnaturally captured as entity-independent logical evidence to conduct inductive\nKGC. Extensive experiment results on five benchmarks show that our framework\nsubstantially outperforms the state-of-the-art KGC methods.",
      "tldr_zh": "该论文针对Inductive Knowledge Graph Completion (KGC)的问题，提出了一种新框架iNfOmax RelAtion Network (NORAN)，旨在为新实体推断缺失关系。该方法以关系为中心，提供一个超视图（hyper view）来捕捉关系间的相关性，作为实体独立的逻辑证据，从而缓解数据稀疏性和冷启动问题。实验在五个基准数据集上显示，NORAN显著优于现有最先进的方法，提升了归纳KGC的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30th SIGKDD Conference on Knowledge Discovery and Data Mining",
      "pdf_url": "http://arxiv.org/pdf/2406.01140v2",
      "published_date": "2024-06-03 09:30:43 UTC",
      "updated_date": "2024-07-22 02:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:38:42.925009"
    },
    {
      "arxiv_id": "2406.01139v1",
      "title": "Depth-Bounded Epistemic Planning",
      "title_zh": "深度受限的认识论规划",
      "authors": [
        "Thomas Bolander",
        "Alessandro Burigana",
        "Marco Montali"
      ],
      "abstract": "In this paper, we propose a novel algorithm for epistemic planning based on\ndynamic epistemic logic (DEL). The novelty is that we limit the depth of\nreasoning of the planning agent to an upper bound b, meaning that the planning\nagent can only reason about higher-order knowledge to at most (modal) depth b.\nThe algorithm makes use of a novel type of canonical b-bisimulation contraction\nguaranteeing unique minimal models with respect to b-bisimulation. We show our\ndepth-bounded planning algorithm to be sound. Additionally, we show it to be\ncomplete with respect to planning tasks having a solution within bound b of\nreasoning depth (and hence the iterative bound-deepening variant is complete in\nthe standard sense). For bound b of reasoning depth, the algorithm is shown to\nbe (b + 1)-EXPTIME complete, and furthermore fixed-parameter tractable in the\nnumber of agents and atoms. We present both a tree search and a graph search\nvariant of the algorithm, and we benchmark an implementation of the tree search\nversion against a baseline epistemic planner.",
      "tldr_zh": "本文提出了一种基于动态认识逻辑 (DEL) 的深度限制认识规划算法 (depth-bounded epistemic planning)，将规划代理的推理深度限制为上限 b，从而仅处理至多 (modal) 深度 b 的高阶知识。算法引入了新型的 b-bisimulation contraction，以确保唯一的最小模型，并证明其正确 (sound) 且在推理深度不超过 b 的任务中完备 (complete)。此外，该算法在 b 深度下为 (b + 1)-EXPTIME 完备，并在代理数和原子数上固定参数可处理 (fixed-parameter tractable)，并通过树搜索和图搜索变体进行了基准测试，与基线规划器进行了比较。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01139v1",
      "published_date": "2024-06-03 09:30:28 UTC",
      "updated_date": "2024-06-03 09:30:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:38:52.584110"
    },
    {
      "arxiv_id": "2406.01136v2",
      "title": "Towards Practical Single-shot Motion Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantinos Roditakis",
        "Spyridon Thermos",
        "Nikolaos Zioulis"
      ],
      "abstract": "Despite the recent advances in the so-called \"cold start\" generation from\ntext prompts, their needs in data and computing resources, as well as the\nambiguities around intellectual property and privacy concerns pose certain\ncounterarguments for their utility. An interesting and relatively unexplored\nalternative has been the introduction of unconditional synthesis from a single\nsample, which has led to interesting generative applications. In this paper we\nfocus on single-shot motion generation and more specifically on accelerating\nthe training time of a Generative Adversarial Network (GAN). In particular, we\ntackle the challenge of GAN's equilibrium collapse when using mini-batch\ntraining by carefully annealing the weights of the loss functions that prevent\nmode collapse. Additionally, we perform statistical analysis in the generator\nand discriminator models to identify correlations between training stages and\nenable transfer learning. Our improved GAN achieves competitive quality and\ndiversity on the Mixamo benchmark when compared to the original GAN\narchitecture and a single-shot diffusion model, while being up to x6.8 faster\nin training time from the former and x1.75 from the latter. Finally, we\ndemonstrate the ability of our improved GAN to mix and compose motion with a\nsingle forward pass. Project page available at\nhttps://moverseai.github.io/single-shot.",
      "tldr_zh": "本论文探讨了单样本运动合成的实用性问题，针对传统生成模型（如基于文本提示的“cold start”生成）的数据需求和隐私担忧提出无条件单样本合成为替代方案。研究通过改进Generative Adversarial Network (GAN)，包括调整损失函数权重以防止模式崩溃，以及对生成器和判别器模型进行统计分析以启用transfer learning，从而显著加速训练过程。结果表明，改进的GAN在Mixamo benchmark上与原GAN和single-shot diffusion model相比，质量和多样性保持竞争力，同时训练时间分别快6.8倍和1.75倍；此外，该模型还能通过单次前向传递实现运动混合和组合。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024, AI for 3D Generation Workshop, Project page:\n  https://moverseai.github.io/single-shot",
      "pdf_url": "http://arxiv.org/pdf/2406.01136v2",
      "published_date": "2024-06-03 09:27:57 UTC",
      "updated_date": "2024-06-04 09:02:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:39:04.892233"
    },
    {
      "arxiv_id": "2406.01131v1",
      "title": "Favi-Score: A Measure for Favoritism in Automated Preference Ratings for Generative AI Evaluation",
      "title_zh": "Favi-Score：生成式 AI 评估中自动偏好评级的偏袒测量",
      "authors": [
        "Pius von Däniken",
        "Jan Deriu",
        "Don Tuggener",
        "Mark Cieliebak"
      ],
      "abstract": "Generative AI systems have become ubiquitous for all kinds of modalities,\nwhich makes the issue of the evaluation of such models more pressing. One\npopular approach is preference ratings, where the generated outputs of\ndifferent systems are shown to evaluators who choose their preferences. In\nrecent years the field shifted towards the development of automated (trained)\nmetrics to assess generated outputs, which can be used to create preference\nratings automatically. In this work, we investigate the evaluation of the\nmetrics themselves, which currently rely on measuring the correlation to human\njudgments or computing sign accuracy scores.\n  These measures only assess how well the metric agrees with the human ratings.\nHowever, our research shows that this does not tell the whole story. Most\nmetrics exhibit a disagreement with human system assessments which is often\nskewed in favor of particular text generation systems, exposing a degree of\nfavoritism in automated metrics. This paper introduces a formal definition of\nfavoritism in preference metrics, and derives the Favi-Score, which measures\nthis phenomenon. In particular we show that favoritism is strongly related to\nerrors in final system rankings. Thus, we propose that preference-based metrics\nought to be evaluated on both sign accuracy scores and favoritism.",
      "tldr_zh": "该研究探讨了生成式 AI 评估中自动化偏好评级（automated preference ratings）的偏好性问题，指出现有评估方法（如相关性和 sign accuracy scores）仅关注指标与人类判断的一致性，却忽略了对特定系统的偏好（favoritism）。论文正式定义了 favoritism，并引入 Favi-Score 作为一种量化衡量指标，帮助识别自动化指标的偏差。实验结果显示，favoritism 与系统排名的错误密切相关，因此建议在评估偏好-based 指标时，同时考虑 sign accuracy scores 和 favoritism，以提升评估的公平性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ACL Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2406.01131v1",
      "published_date": "2024-06-03 09:20:46 UTC",
      "updated_date": "2024-06-03 09:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:39:15.271152"
    },
    {
      "arxiv_id": "2406.01126v1",
      "title": "TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjing Yue",
        "Xiaoling Wang",
        "Wei Zhu",
        "Ming Guan",
        "Huanran Zheng",
        "Pengfei Wang",
        "Changzhi Sun",
        "Xin Ma"
      ],
      "abstract": "Large language models (LLMs) have performed remarkably well in various\nnatural language processing tasks by benchmarking, including in the Western\nmedical domain. However, the professional evaluation benchmarks for LLMs have\nyet to be covered in the traditional Chinese medicine(TCM) domain, which has a\nprofound history and vast influence. To address this research gap, we introduce\nTCM-Bench, an comprehensive benchmark for evaluating LLM performance in TCM. It\ncomprises the TCM-ED dataset, consisting of 5,473 questions sourced from the\nTCM Licensing Exam (TCMLE), including 1,300 questions with authoritative\nanalysis. It covers the core components of TCMLE, including TCM basis and\nclinical practice. To evaluate LLMs beyond accuracy of question answering, we\npropose TCMScore, a metric tailored for evaluating the quality of answers\ngenerated by LLMs for TCM related questions. It comprehensively considers the\nconsistency of TCM semantics and knowledge. After conducting comprehensive\nexperimental analyses from diverse perspectives, we can obtain the following\nfindings: (1) The unsatisfactory performance of LLMs on this benchmark\nunderscores their significant room for improvement in TCM. (2) Introducing\ndomain knowledge can enhance LLMs' performance. However, for in-domain models\nlike ZhongJing-TCM, the quality of generated analysis text has decreased, and\nwe hypothesize that their fine-tuning process affects the basic LLM\ncapabilities. (3) Traditional metrics for text generation quality like Rouge\nand BertScore are susceptible to text length and surface semantic ambiguity,\nwhile domain-specific metrics such as TCMScore can further supplement and\nexplain their evaluation results. These findings highlight the capabilities and\nlimitations of LLMs in the TCM and aim to provide a more profound assistance to\nmedical research.",
      "tldr_zh": "本研究引入了 TCMBench，这是一个全面基准，用于评估大型语言模型（Large Language Models, LLMs）在传统中医（Traditional Chinese Medicine, TCM）领域的性能。它包括 TCM-ED 数据集，该数据集基于 TCM Licensing Exam 包含 5,473 个问题（其中 1,300 个带有权威分析），覆盖中医基础和临床实践，并提出 TCMScore 指标来评估答案的语义一致性和知识质量。实验分析发现，LLMs 在 TCMBench 上的表现不尽如人意，引入领域知识能提升性能，但可能影响某些模型的基本能力；此外，传统指标如 Rouge 和 BertScore 易受文本长度和语义模糊影响，而 TCMScore 提供更精确的补充评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01126v1",
      "published_date": "2024-06-03 09:11:13 UTC",
      "updated_date": "2024-06-03 09:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:39:30.284248"
    },
    {
      "arxiv_id": "2406.01116v1",
      "title": "Accelerating Heterogeneous Federated Learning with Closed-form Classifiers",
      "title_zh": "使用闭式形式分类器加速异构联邦学习",
      "authors": [
        "Eros Fanì",
        "Raffaello Camoriano",
        "Barbara Caputo",
        "Marco Ciccone"
      ],
      "abstract": "Federated Learning (FL) methods often struggle in highly statistically\nheterogeneous settings. Indeed, non-IID data distributions cause client drift\nand biased local solutions, particularly pronounced in the final classification\nlayer, negatively impacting convergence speed and accuracy. To address this\nissue, we introduce Federated Recursive Ridge Regression (Fed3R). Our method\nfits a Ridge Regression classifier computed in closed form leveraging\npre-trained features. Fed3R is immune to statistical heterogeneity and is\ninvariant to the sampling order of the clients. Therefore, it proves\nparticularly effective in cross-device scenarios. Furthermore, it is fast and\nefficient in terms of communication and computation costs, requiring up to two\norders of magnitude fewer resources than the competitors. Finally, we propose\nto leverage the Fed3R parameters as an initialization for a softmax classifier\nand subsequently fine-tune the model using any FL algorithm (Fed3R with\nFine-Tuning, Fed3R+FT). Our findings also indicate that maintaining a fixed\nclassifier aids in stabilizing the training and learning more discriminative\nfeatures in cross-device settings. Official website: https://fed-3r.github.io/.",
      "tldr_zh": "这篇论文针对 Federated Learning (FL) 在统计异构环境中面临的客户端漂移和偏置局部解决方案问题，提出 Federated Recursive Ridge Regression (Fed3R) 方法。Fed3R 通过闭式形式的 Ridge Regression 分类器利用预训练特征，实现对异构性的免疫，并对客户端采样顺序不变，在跨设备场景中表现出色，同时大幅降低通信和计算成本。作者进一步建议使用 Fed3R 参数初始化 softmax 分类器进行微调 (Fed3R+FT)，从而稳定训练过程并提升特征辨别力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024 - https://fed-3r.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.01116v1",
      "published_date": "2024-06-03 08:52:06 UTC",
      "updated_date": "2024-06-03 08:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:39:41.018672"
    },
    {
      "arxiv_id": "2406.02615v1",
      "title": "A hybrid numerical methodology coupling Reduced Order Modeling and Graph Neural Networks for non-parametric geometries: applications to structural dynamics problems",
      "title_zh": "一种耦合 Reduced Order",
      "authors": [
        "Victor Matray",
        "Faisal Amlani",
        "Frédéric Feyel",
        "David Néron"
      ],
      "abstract": "This work introduces a new approach for accelerating the numerical analysis\nof time-domain partial differential equations (PDEs) governing complex physical\nsystems. The methodology is based on a combination of a classical reduced-order\nmodeling (ROM) framework and recently-introduced Graph Neural Networks (GNNs),\nwhere the latter is trained on highly heterogeneous databases of varying\nnumerical discretization sizes. The proposed techniques are shown to be\nparticularly suitable for non-parametric geometries, ultimately enabling the\ntreatment of a diverse range of geometries and topologies. Performance studies\nare presented in an application context related to the design of aircraft seats\nand their corresponding mechanical responses to shocks, where the main\nmotivation is to reduce the computational burden and enable the rapid design\niteration for such problems that entail non-parametric geometries. The methods\nproposed here are straightforwardly applicable to other scientific or\nengineering problems requiring a large number of finite element-based numerical\nsimulations, with the potential to significantly enhance efficiency while\nmaintaining reasonable accuracy.",
      "tldr_zh": "这篇论文提出了一种结合 Reduced Order Modeling (ROM) 和 Graph Neural Networks (GNNs) 的混合数值方法，用于加速时间域偏微分方程 (PDEs) 的分析，特别是针对非参数几何问题。方法通过在高度异构数据库上训练 GNNs，实现对各种几何和拓扑的处理，从而显著降低计算负担。实验应用于飞机座椅设计及其对冲击的机械响应，展示了该方法在提高设计迭代效率的同时保持合理准确性。该框架可扩展到其他依赖大量有限元模拟的科学或工程领域，进一步提升整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.class-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02615v1",
      "published_date": "2024-06-03 08:51:25 UTC",
      "updated_date": "2024-06-03 08:51:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:39:53.311017"
    },
    {
      "arxiv_id": "2406.01114v1",
      "title": "Globally Interpretable Classifiers via Boolean Formulas with Dynamic Propositions",
      "title_zh": "翻译失败",
      "authors": [
        "Reijo Jaakkola",
        "Tomi Janhunen",
        "Antti Kuusisto",
        "Masood Feyzbakhsh Rankooh",
        "Miikka Vilander"
      ],
      "abstract": "Interpretability and explainability are among the most important challenges\nof modern artificial intelligence, being mentioned even in various legislative\nsources. In this article, we develop a method for extracting immediately human\ninterpretable classifiers from tabular data. The classifiers are given in the\nform of short Boolean formulas built with propositions that can either be\ndirectly extracted from categorical attributes or dynamically computed from\nnumeric ones. Our method is implemented using Answer Set Programming. We\ninvestigate seven datasets and compare our results to ones obtainable by\nstate-of-the-art classifiers for tabular data, namely, XGBoost and random\nforests. Over all datasets, the accuracies obtainable by our method are similar\nto the reference methods. The advantage of our classifiers in all cases is that\nthey are very short and immediately human intelligible as opposed to the\nblack-box nature of the reference methods.",
      "tldr_zh": "这篇论文提出了一种通过动态命题的Boolean formulas构建全局可解释分类器的方法，用于从表格数据中提取立即可理解的模型。分类器由短小的布尔公式组成，这些公式直接从分类属性提取或从数值属性动态计算，并使用Answer Set Programming实现。在七个数据集上的实验表明，该方法的准确率与XGBoost和random forests相当，但其关键优势在于分类器简短且易于人类解读，避免了参考方法的黑盒特性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "I.2.6; F.4.1; I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01114v1",
      "published_date": "2024-06-03 08:46:17 UTC",
      "updated_date": "2024-06-03 08:46:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:40:03.975812"
    },
    {
      "arxiv_id": "2406.02614v2",
      "title": "Frequency Enhanced Pre-training for Cross-city Few-shot Traffic Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanyu Liu",
        "Jianrong Ding",
        "Guanjie Zheng"
      ],
      "abstract": "The field of Intelligent Transportation Systems (ITS) relies on accurate\ntraffic forecasting to enable various downstream applications. However,\ndeveloping cities often face challenges in collecting sufficient training\ntraffic data due to limited resources and outdated infrastructure. Recognizing\nthis obstacle, the concept of cross-city few-shot forecasting has emerged as a\nviable approach. While previous cross-city few-shot forecasting methods ignore\nthe frequency similarity between cities, we have made an observation that the\ntraffic data is more similar in the frequency domain between cities. Based on\nthis fact, we propose a \\textbf{F}requency \\textbf{E}nhanced\n\\textbf{P}re-training Framework for \\textbf{Cross}-city Few-shot Forecasting\n(\\textbf{FEPCross}). FEPCross has a pre-training stage and a fine-tuning stage.\nIn the pre-training stage, we propose a novel Cross-Domain Spatial-Temporal\nEncoder that incorporates the information of the time and frequency domain and\ntrains it with self-supervised tasks encompassing reconstruction and\ncontrastive objectives. In the fine-tuning stage, we design modules to enrich\ntraining samples and maintain a momentum-updated graph structure, thereby\nmitigating the risk of overfitting to the few-shot training data. Empirical\nevaluations performed on real-world traffic datasets validate the exceptional\nefficacy of FEPCross, outperforming existing approaches of diverse categories\nand demonstrating characteristics that foster the progress of cross-city\nfew-shot forecasting.",
      "tldr_zh": "本研究针对智能交通系统（ITS）中发展中城市数据不足的问题，提出了一种频率增强预训练框架（FEPCross），用于跨城市少样本交通预测（cross-city few-shot forecasting）。FEPCross 通过观察交通数据在频率域（frequency domain）间的相似性，在预训练阶段引入 Cross-Domain Spatial-Temporal Encoder 结合时间和频率信息，并使用自监督任务（如重建和对比目标）进行训练；在微调阶段，设计模块丰富样本并维护动量更新的图结构，以避免过拟合。实验结果显示，FEPCross 在真实交通数据集上显著优于现有方法，推动了跨城市少样本预测的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ECMLPKDD 2024 (Research Track)",
      "pdf_url": "http://arxiv.org/pdf/2406.02614v2",
      "published_date": "2024-06-03 08:42:00 UTC",
      "updated_date": "2024-06-06 01:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:40:20.180778"
    },
    {
      "arxiv_id": "2406.01103v1",
      "title": "Advancing DRL Agents in Commercial Fighting Games: Training, Integration, and Agent-Human Alignment",
      "title_zh": "在商业格斗游戏中推进 DRL 代理：训练、集成及代理-人类对齐",
      "authors": [
        "Chen Zhang",
        "Qiang He",
        "Zhou Yuan",
        "Elvis S. Liu",
        "Hong Wang",
        "Jian Zhao",
        "Yang Wang"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) agents have demonstrated impressive success\nin a wide range of game genres. However, existing research primarily focuses on\noptimizing DRL competence rather than addressing the challenge of prolonged\nplayer interaction. In this paper, we propose a practical DRL agent system for\nfighting games named Sh\\=ukai, which has been successfully deployed to Naruto\nMobile, a popular fighting game with over 100 million registered users.\nSh\\=ukai quantifies the state to enhance generalizability, introducing\nHeterogeneous League Training (HELT) to achieve balanced competence,\ngeneralizability, and training efficiency. Furthermore, Sh\\=ukai implements\nspecific rewards to align the agent's behavior with human expectations.\nSh\\=ukai's ability to generalize is demonstrated by its consistent competence\nacross all characters, even though it was trained on only 13% of them.\nAdditionally, HELT exhibits a remarkable 22% improvement in sample efficiency.\nSh\\=ukai serves as a valuable training partner for players in Naruto Mobile,\nenabling them to enhance their abilities and skills.",
      "tldr_zh": "本论文提出了一种名为 Shūkai 的 DRL 代理系统，用于商业格斗游戏，如 Naruto Mobile，以解决现有研究中忽略玩家长期互动的挑战。系统通过量化状态和引入 Heterogeneous League Training (HELT) 方法，实现了代理的平衡能力、泛化性和训练效率，其中 HELT 显著提高了 22% 的样本效率。Shūkai 还设计了特定奖励机制，以确保代理行为与人类期望对齐，即使仅在 13% 的角色上训练，它也能在所有角色上表现出一致的泛化能力。作为实际应用，Shūkai 已部署到 Naruto Mobile，帮助玩家提升技能和能力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accept at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01103v1",
      "published_date": "2024-06-03 08:39:15 UTC",
      "updated_date": "2024-06-03 08:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:40:29.429042"
    },
    {
      "arxiv_id": "2406.01099v2",
      "title": "Deep reinforcement learning for weakly coupled MDP's with continuous actions",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Robledo",
        "Urtzi Ayesta",
        "Konstantin Avrachenkov"
      ],
      "abstract": "This paper introduces the Lagrange Policy for Continuous Actions (LPCA), a\nreinforcement learning algorithm specifically designed for weakly coupled MDP\nproblems with continuous action spaces. LPCA addresses the challenge of\nresource constraints dependent on continuous actions by introducing a Lagrange\nrelaxation of the weakly coupled MDP problem within a neural network framework\nfor Q-value computation. This approach effectively decouples the MDP, enabling\nefficient policy learning in resource-constrained environments. We present two\nvariations of LPCA: LPCA-DE, which utilizes differential evolution for global\noptimization, and LPCA-Greedy, a method that incrementally and greadily selects\nactions based on Q-value gradients. Comparative analysis against other\nstate-of-the-art techniques across various settings highlight LPCA's robustness\nand efficiency in managing resource allocation while maximizing rewards.",
      "tldr_zh": "本论文提出 LPCA（Lagrange Policy for Continuous Actions）算法，用于处理弱耦合 MDP（Markov Decision Processes）问题中的连续动作空间及其资源约束挑战。LPCA 通过引入 Lagrange 松弛机制并结合神经网络框架计算 Q-value，有效解耦 MDP 并实现高效策略学习。论文还开发了两个变体：LPCA-DE 利用差分进化进行全局优化，以及 LPCA-Greedy 通过 Q-value 梯度贪婪选择动作。实验比较显示，LPCA 在各种设置下表现出色，能更鲁棒地管理资源分配并最大化奖励。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "ACM SIGMETRICS / ASMTA 2024, Jun 2024, Venise, Italy",
      "pdf_url": "http://arxiv.org/pdf/2406.01099v2",
      "published_date": "2024-06-03 08:34:32 UTC",
      "updated_date": "2024-06-12 06:51:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:40:41.107083"
    },
    {
      "arxiv_id": "2406.18570v1",
      "title": "It's a Feature, Not a Bug: Measuring Creative Fluidity in Image Generators",
      "title_zh": "这是个特性，不是个 bug：测量图像生成器中的创造性流动性",
      "authors": [
        "Aditi Ramaswamy",
        "Melane Navaratnarajah",
        "Hana Chockler"
      ],
      "abstract": "With the rise of freely available image generators, AI-generated art has\nbecome the centre of a series of heated debates, one of which concerns the\nconcept of human creativity. Can an image generation AI exhibit ``creativity''\nof the same type that artists do, and if so, how does that manifest? Our paper\nattempts to define and empirically measure one facet of creative behavior in\nAI, by conducting an experiment to quantify the \"fluidity of prompt\ninterpretation\", or just \"fluidity\", in a series of selected popular image\ngenerators. To study fluidity, we (1) introduce a clear definition for it, (2)\ncreate chains of auto-generated prompts and images seeded with an initial\n\"ground-truth: image, (3) measure these chains' breakage points using\npreexisting visual and semantic metrics, and (4) use both statistical tests and\nvisual explanations to study these chains and determine whether the image\ngenerators used to produce them exhibit significant fluidity.",
      "tldr_zh": "本论文探讨AI图像生成器是否能展现与人类艺术家相似的“creative fluidity”（创造性流动性），并通过实验定义和量化这一概念。研究方法包括：创建基于初始图像的提示和图像链，使用现有视觉和语义指标测量链的断裂点，并应用统计测试及视觉解释分析这些链。结果显示，这种方法能有效评估图像生成器在提示解释方面的灵活性，为AI创意行为的实证研究提供新框架。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18570v1",
      "published_date": "2024-06-03 08:31:29 UTC",
      "updated_date": "2024-06-03 08:31:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:40:52.891871"
    },
    {
      "arxiv_id": "2406.02613v1",
      "title": "ACCO: Accumulate while you Communicate, Hiding Communications in Distributed LLM Training",
      "title_zh": "翻译失败",
      "authors": [
        "Adel Nabli",
        "Louis Fournier",
        "Pierre Erbacher",
        "Louis Serrano",
        "Eugene Belilovsky",
        "Edouard Oyallon"
      ],
      "abstract": "Training Large Language Models (LLMs) relies heavily on distributed\nimplementations, employing multiple GPUs to compute stochastic gradients on\nmodel replicas in parallel. However, synchronizing gradients in data parallel\nsettings induces a communication overhead increasing with the number of\ndistributed workers, which can impede the efficiency gains of parallelization.\nTo address this challenge, optimization algorithms reducing inter-worker\ncommunication have emerged, such as local optimization methods used in\nFederated Learning. While effective in minimizing communication overhead, these\nmethods incur significant memory costs, hindering scalability: in addition to\nextra momentum variables, if communications are only allowed between multiple\nlocal optimization steps, then the optimizer's states cannot be sharded among\nworkers. In response, we propose $\\textbf{AC}$cumulate while\n$\\textbf{CO}$mmunicate ($\\texttt{ACCO}$), a memory-efficient optimization\nalgorithm tailored for distributed training of LLMs. $\\texttt{ACCO}$ allows to\nshard optimizer states across workers, overlaps gradient computations and\ncommunications to conceal communication costs, and accommodates heterogeneous\nhardware. Our method relies on a novel technique to mitigate the one-step delay\ninherent in parallel execution of gradient computations and communications,\neliminating the need for warmup steps and aligning with the training dynamics\nof standard distributed optimization while converging faster in terms of\nwall-clock time. We demonstrate the effectiveness of $\\texttt{ACCO}$ on several\nLLMs training and fine-tuning tasks.",
      "tldr_zh": "该论文针对分布式大型语言模型 (LLMs) 训练中同步梯度导致的通信开销问题，提出了一种内存高效的优化算法 ACCO（Accumulate while you Communicate）。ACCO 通过允许优化器状态在工作者间分片、重叠梯度计算和通信来隐藏通信成本，并支持异构硬件，同时引入一种新技巧缓解并行执行中的一步延迟，避免预热步骤。实验结果显示，ACCO 在多个 LLMs 训练和微调任务上实现了更快的壁时收敛速度，提升了分布式训练的效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02613v1",
      "published_date": "2024-06-03 08:23:45 UTC",
      "updated_date": "2024-06-03 08:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:41:04.192061"
    },
    {
      "arxiv_id": "2406.02612v1",
      "title": "Is Data Valuation Learnable and Interpretable?",
      "title_zh": "数据估值是否可学习且可解释？",
      "authors": [
        "Ou Wu",
        "Weiyao Zhu",
        "Mengyang Li"
      ],
      "abstract": "Measuring the value of individual samples is critical for many data-driven\ntasks, e.g., the training of a deep learning model. Recent literature witnesses\nthe substantial efforts in developing data valuation methods. The primary data\nvaluation methodology is based on the Shapley value from game theory, and\nvarious methods are proposed along this path. {Even though Shapley value-based\nvaluation has solid theoretical basis, it is entirely an experiment-based\napproach and no valuation model has been constructed so far.} In addition,\ncurrent data valuation methods ignore the interpretability of the output\nvalues, despite an interptable data valuation method is of great helpful for\napplications such as data pricing. This study aims to answer an important\nquestion: is data valuation learnable and interpretable? A learned valuation\nmodel have several desirable merits such as fixed number of parameters and\nknowledge reusability. An intrepretable data valuation model can explain why a\nsample is valuable or invaluable. To this end, two new data value modeling\nframeworks are proposed, in which a multi-layer perception~(MLP) and a new\nregression tree are utilized as specific base models for model training and\ninterpretability, respectively. Extensive experiments are conducted on\nbenchmark datasets. {The experimental results provide a positive answer for the\nquestion.} Our study opens up a new technical path for the assessing of data\nvalues. Large data valuation models can be built across many different\ndata-driven tasks, which can promote the widespread application of data\nvaluation.",
      "tldr_zh": "该论文探讨数据估值的可学习性和可解释性问题，指出现有基于Shapley value的方法虽理论稳固，但缺乏模型构建和输出解释。作者提出两个新框架：一个使用多层感知器(MLP)作为基模型进行数据价值学习，另一个采用新回归树提供可解释性分析。实验在基准数据集上验证了这些框架的有效性，证明数据估值是可学习的，并为构建大型跨任务估值模型铺平道路，促进其在数据定价等应用中的广泛使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02612v1",
      "published_date": "2024-06-03 08:13:47 UTC",
      "updated_date": "2024-06-03 08:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:41:19.141209"
    },
    {
      "arxiv_id": "2406.01086v1",
      "title": "Effective Subset Selection Through The Lens of Neural Network Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Noga Bar",
        "Raja Giryes"
      ],
      "abstract": "Having large amounts of annotated data significantly impacts the\neffectiveness of deep neural networks. However, the annotation task can be very\nexpensive in some domains, such as medical data. Thus, it is important to\nselect the data to be annotated wisely, which is known as the subset selection\nproblem. We investigate the relationship between subset selection and neural\nnetwork pruning, which is more widely studied, and establish a correspondence\nbetween them. Leveraging insights from network pruning, we propose utilizing\nthe norm criterion of neural network features to improve subset selection\nmethods. We empirically validate our proposed strategy on various networks and\ndatasets, demonstrating enhanced accuracy. This shows the potential of\nemploying pruning tools for subset selection.",
      "tldr_zh": "该研究探讨了在数据标注成本高昂的领域（如医疗）中，如何通过有效的子集选择（subset selection）来优化深度神经网络的性能。作者建立了subset selection与神经网络修剪（neural network pruning）之间的对应关系，并提出利用神经网络特征的norm criterion来改进subset selection方法。实验结果显示，该策略在多种网络和数据集上显著提升了准确率，证明了使用pruning工具进行数据选择的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01086v1",
      "published_date": "2024-06-03 08:12:32 UTC",
      "updated_date": "2024-06-03 08:12:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:41:30.739712"
    },
    {
      "arxiv_id": "2406.01085v1",
      "title": "FedAdOb: Privacy-Preserving Federated Deep Learning with Adaptive Obfuscation",
      "title_zh": "翻译失败",
      "authors": [
        "Hanlin Gu",
        "Jiahuan Luo",
        "Yan Kang",
        "Yuan Yao",
        "Gongxi Zhu",
        "Bowen Li",
        "Lixin Fan",
        "Qiang Yang"
      ],
      "abstract": "Federated learning (FL) has emerged as a collaborative approach that allows\nmultiple clients to jointly learn a machine learning model without sharing\ntheir private data. The concern about privacy leakage, albeit demonstrated\nunder specific conditions, has triggered numerous follow-up research in\ndesigning powerful attacking methods and effective defending mechanisms aiming\nto thwart these attacking methods. Nevertheless, privacy-preserving mechanisms\nemployed in these defending methods invariably lead to compromised model\nperformances due to a fixed obfuscation applied to private data or gradients.\nIn this article, we, therefore, propose a novel adaptive obfuscation mechanism,\ncoined FedAdOb, to protect private data without yielding original model\nperformances. Technically, FedAdOb utilizes passport-based adaptive obfuscation\nto ensure data privacy in both horizontal and vertical federated learning\nsettings. The privacy-preserving capabilities of FedAdOb, specifically with\nregard to private features and labels, are theoretically proven through\nTheorems 1 and 2. Furthermore, extensive experimental evaluations conducted on\nvarious datasets and network architectures demonstrate the effectiveness of\nFedAdOb by manifesting its superior trade-off between privacy preservation and\nmodel performance, surpassing existing methods.",
      "tldr_zh": "该论文针对联邦学习（Federated Learning, FL）中隐私泄露的风险，提出了一种名为 FedAdOb 的自适应混淆机制，以保护私有数据而不降低模型性能。FedAdOb 利用基于护照的适应性混淆技术，适用于水平和垂直 FL 设置，并通过定理 1 和 2 理论证明了其对私有特征和标签的隐私保护能力。实验结果显示，在多种数据集和网络架构上，FedAdOb 实现了现有方法无法匹敌的隐私保护与模型性能权衡平衡。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01085v1",
      "published_date": "2024-06-03 08:12:09 UTC",
      "updated_date": "2024-06-03 08:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:41:43.278080"
    },
    {
      "arxiv_id": "2406.01079v1",
      "title": "Object Aware Egocentric Online Action Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Joungbin An",
        "Yunsu Park",
        "Hyolim Kang",
        "Seon Joo Kim"
      ],
      "abstract": "Advancements in egocentric video datasets like Ego4D, EPIC-Kitchens, and\nEgo-Exo4D have enriched the study of first-person human interactions, which is\ncrucial for applications in augmented reality and assisted living. Despite\nthese advancements, current Online Action Detection methods, which efficiently\ndetect actions in streaming videos, are predominantly designed for exocentric\nviews and thus fail to capitalize on the unique perspectives inherent to\negocentric videos. To address this gap, we introduce an Object-Aware Module\nthat integrates egocentric-specific priors into existing OAD frameworks,\nenhancing first-person footage interpretation. Utilizing object-specific\ndetails and temporal dynamics, our module improves scene understanding in\ndetecting actions. Validated extensively on the Epic-Kitchens 100 dataset, our\nwork can be seamlessly integrated into existing models with minimal overhead\nand bring consistent performance enhancements, marking an important step\nforward in adapting action detection systems to egocentric video analysis.",
      "tldr_zh": "该研究针对现有 Online Action Detection (OAD) 方法主要适用于 exocentric 视图而无法充分利用 egocentric 视频独特视角的问题，提出了一种 Object-Aware Module。该模块整合 egocentric-specific priors，通过对象特定细节和时间动态来提升第一人称视角视频中动作检测的场景理解。在 Epic-Kitchens 100 数据集上的广泛验证显示，该模块可无缝整合到现有框架中，并带来一致的性能提升，为增强现实和辅助生活应用中的动作检测提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR First Joint Egocentric Vision Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01079v1",
      "published_date": "2024-06-03 07:58:40 UTC",
      "updated_date": "2024-06-03 07:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:41:55.300069"
    },
    {
      "arxiv_id": "2406.01076v1",
      "title": "Estimating Canopy Height at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Pauls",
        "Max Zimmer",
        "Una M. Kelly",
        "Martin Schwartz",
        "Sassan Saatchi",
        "Philippe Ciais",
        "Sebastian Pokutta",
        "Martin Brandt",
        "Fabian Gieseke"
      ],
      "abstract": "We propose a framework for global-scale canopy height estimation based on\nsatellite data. Our model leverages advanced data preprocessing techniques,\nresorts to a novel loss function designed to counter geolocation inaccuracies\ninherent in the ground-truth height measurements, and employs data from the\nShuttle Radar Topography Mission to effectively filter out erroneous labels in\nmountainous regions, enhancing the reliability of our predictions in those\nareas. A comparison between predictions and ground-truth labels yields an MAE /\nRMSE of 2.43 / 4.73 (meters) overall and 4.45 / 6.72 (meters) for trees taller\nthan five meters, which depicts a substantial improvement compared to existing\nglobal-scale maps. The resulting height map as well as the underlying framework\nwill facilitate and enhance ecological analyses at a global scale, including,\nbut not limited to, large-scale forest and biomass monitoring.",
      "tldr_zh": "本研究提出一个基于卫星数据的全球规模树冠高度估计框架，利用高级数据预处理技术、新颖损失函数来应对地面真实测量中的地理定位不准确问题，并通过Shuttle Radar Topography Mission数据过滤山区错误标签，从而提升预测可靠性。  \n与现有全球地图相比，该框架的性能显著改善，整体MAE / RMSE为2.43 / 4.73米，对于高于五米的树木则为4.45 / 6.72米。  \n该高度地图和框架将促进全球生态分析，包括大规模森林和生物质监测。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML Camera-Ready, 17 pages, 14 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.01076v1",
      "published_date": "2024-06-03 07:53:38 UTC",
      "updated_date": "2024-06-03 07:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:42:09.374695"
    },
    {
      "arxiv_id": "2406.01072v1",
      "title": "Towards Efficient Deep Spiking Neural Networks Construction with Spiking Activity based Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Yaxin Li",
        "Qi Xu",
        "Jiangrong Shen",
        "Hongming Xu",
        "Long Chen",
        "Gang Pan"
      ],
      "abstract": "The emergence of deep and large-scale spiking neural networks (SNNs)\nexhibiting high performance across diverse complex datasets has led to a need\nfor compressing network models due to the presence of a significant number of\nredundant structural units, aiming to more effectively leverage their low-power\nconsumption and biological interpretability advantages. Currently, most model\ncompression techniques for SNNs are based on unstructured pruning of individual\nconnections, which requires specific hardware support. Hence, we propose a\nstructured pruning approach based on the activity levels of convolutional\nkernels named Spiking Channel Activity-based (SCA) network pruning framework.\nInspired by synaptic plasticity mechanisms, our method dynamically adjusts the\nnetwork's structure by pruning and regenerating convolutional kernels during\ntraining, enhancing the model's adaptation to the current target task. While\nmaintaining model performance, this approach refines the network architecture,\nultimately reducing computational load and accelerating the inference process.\nThis indicates that structured dynamic sparse learning methods can better\nfacilitate the application of deep SNNs in low-power and high-efficiency\nscenarios.",
      "tldr_zh": "本研究针对深度脉冲神经网络 (SNNs) 中冗余结构的问题，提出了一种基于 Spiking Channel Activity-based (SCA) 的结构化修剪框架，以提升网络的效率和适应性。该方法受突触可塑性机制启发，在训练过程中动态修剪和再生卷积 kernels，从而优化网络架构，同时维持模型性能。实验结果表明，SCA 框架显著减少了计算负载并加速了推理过程，最终促进了 SNNs 在低功耗和高效率场景中的实际应用。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01072v1",
      "published_date": "2024-06-03 07:44:37 UTC",
      "updated_date": "2024-06-03 07:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:42:31.581522"
    },
    {
      "arxiv_id": "2406.06566v4",
      "title": "Natural Language Interaction with a Household Electricity Knowledge-based Digital Twin",
      "title_zh": "翻译失败",
      "authors": [
        "Carolina Fortuna",
        "Vid Hanžel",
        "Blaž Bertalanič"
      ],
      "abstract": "Domain specific digital twins, representing a digital replica of various\nsegments of the smart grid, are foreseen as able to model, simulate, and\ncontrol the respective segments. At the same time, knowledge-based digital\ntwins, coupled with AI, may also empower humans to understand aspects of the\nsystem through natural language interaction in view of planning and policy\nmaking. This paper is the first to assess and report on the potential of\nRetrieval Augmented Generation (RAG) question answers related to household\nelectrical energy measurement aspects leveraging a knowledge-based energy\ndigital twin. Relying on the recently published electricity consumption\nknowledge graph that actually represents a knowledge-based digital twin, we\nstudy the capabilities of ChatGPT, Gemini and Llama in answering electricity\nrelated questions. Furthermore, we compare the answers with the ones generated\nthrough a RAG techniques that leverages an existing electricity knowledge-based\ndigital twin. Our findings illustrate that the RAG approach not only reduces\nthe incidence of incorrect information typically generated by LLMs but also\nsignificantly improves the quality of the output by grounding responses in\nverifiable data. This paper details our methodology, presents a comparative\nanalysis of responses with and without RAG, and discusses the implications of\nour findings for future applications of AI in specialized sectors like energy\ndata analysis.",
      "tldr_zh": "这篇论文评估了 Retrieval Augmented Generation (RAG) 在基于知识的数字孪生（knowledge-based digital twins）中的应用，专注于通过自然语言交互理解家庭电力测量方面的问题。研究方法包括利用现有的电力消耗知识图谱，比较 ChatGPT、Gemini 和 Llama 等 LLMs 的回答性能，并发现 RAG 技术能显著减少错误信息并提升输出质量。结果显示，RAG 使模型响应更可靠，并基于可验证数据进行改进。该研究为 AI 在能源数据分析等专业领域的未来应用提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IEEE SmartGridComm'24",
      "pdf_url": "http://arxiv.org/pdf/2406.06566v4",
      "published_date": "2024-06-03 07:44:32 UTC",
      "updated_date": "2024-08-16 07:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:42:32.916553"
    },
    {
      "arxiv_id": "2406.01065v1",
      "title": "Causal prompting model-based offline reinforcement learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xuehui Yu",
        "Yi Guan",
        "Rujia Shen",
        "Xin Li",
        "Chen Tang",
        "Jingchi Jiang"
      ],
      "abstract": "Model-based offline Reinforcement Learning (RL) allows agents to fully\nutilise pre-collected datasets without requiring additional or unethical\nexplorations. However, applying model-based offline RL to online systems\npresents challenges, primarily due to the highly suboptimal (noise-filled) and\ndiverse nature of datasets generated by online systems. To tackle these issues,\nwe introduce the Causal Prompting Reinforcement Learning (CPRL) framework,\ndesigned for highly suboptimal and resource-constrained online scenarios. The\ninitial phase of CPRL involves the introduction of the Hidden-Parameter Block\nCausal Prompting Dynamic (Hip-BCPD) to model environmental dynamics. This\napproach utilises invariant causal prompts and aligns hidden parameters to\ngeneralise to new and diverse online users. In the subsequent phase, a single\npolicy is trained to address multiple tasks through the amalgamation of\nreusable skills, circumventing the need for training from scratch. Experiments\nconducted across datasets with varying levels of noise, including\nsimulation-based and real-world offline datasets from the Dnurse APP,\ndemonstrate that our proposed method can make robust decisions in\nout-of-distribution and noisy environments, outperforming contemporary\nalgorithms. Additionally, we separately verify the contributions of Hip-BCPDs\nand the skill-reuse strategy to the robustness of performance. We further\nanalyse the visualised structure of Hip-BCPD and the interpretability of\nsub-skills. We released our source code and the first ever real-world medical\ndataset for precise medical decision-making tasks.",
      "tldr_zh": "本研究提出 Causal Prompting Reinforcement Learning (CPRL) 框架，用于解决模型-based offline Reinforcement Learning (RL) 在在线系统中面临的挑战，如数据集的次优性和多样性。CPRL 包括两个关键阶段：首先引入 Hidden-Parameter Block Causal Prompting Dynamic (Hip-BCPD) 来建模环境动态，通过不变的因果提示和隐藏参数实现对新用户的泛化；其次，通过合并可重用技能训练单一策略，以处理多个任务并避免从零开始训练。实验在各种噪声水平的数据集上进行，包括模拟和真实世界 Dnurse APP 数据，显示 CPRL 在分布外和噪声环境中表现出色，比现有算法性能更优越。该框架的贡献通过验证 Hip-BCPD 和技能重用策略的鲁棒性得到证实，并发布了源代码和首个真实世界医疗数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01065v1",
      "published_date": "2024-06-03 07:28:57 UTC",
      "updated_date": "2024-06-03 07:28:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:42:45.336020"
    },
    {
      "arxiv_id": "2406.04373v1",
      "title": "VerilogReader: LLM-Aided Hardware Test Generation",
      "title_zh": "VerilogReader: LLM辅助的硬件测试生成",
      "authors": [
        "Ruiyang Ma",
        "Yuxin Yang",
        "Ziqian Liu",
        "Jiaxi Zhang",
        "Min Li",
        "Junhua Huang",
        "Guojie Luo"
      ],
      "abstract": "Test generation has been a critical and labor-intensive process in hardware\ndesign verification. Recently, the emergence of Large Language Model (LLM) with\ntheir advanced understanding and inference capabilities, has introduced a novel\napproach. In this work, we investigate the integration of LLM into the Coverage\nDirected Test Generation (CDG) process, where the LLM functions as a Verilog\nReader. It accurately grasps the code logic, thereby generating stimuli that\ncan reach unexplored code branches. We compare our framework with random\ntesting, using our self-designed Verilog benchmark suite. Experiments\ndemonstrate that our framework outperforms random testing on designs within the\nLLM's comprehension scope. Our work also proposes prompt engineering\noptimizations to augment LLM's understanding scope and accuracy.",
      "tldr_zh": "该研究提出 VerilogReader 框架，利用大语言模型 (LLM) 辅助硬件设计验证中的测试生成过程，LLM 作为 Verilog Reader 准确理解代码逻辑并生成能覆盖未探索分支的测试刺激。相比随机测试，该框架在自设计的 Verilog 基准套件上表现出色，尤其在 LLM 理解范围内的设计中性能更优。研究还通过提示工程优化提升了 LLM 的理解范围和准确性，为高效的 Coverage Directed Test Generation (CDG) 提供了新方法。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04373v1",
      "published_date": "2024-06-03 07:20:51 UTC",
      "updated_date": "2024-06-03 07:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:42:59.132081"
    },
    {
      "arxiv_id": "2406.02610v1",
      "title": "MoFormer: Multi-objective Antimicrobial Peptide Generation Based on Conditional Transformer Joint Multi-modal Fusion Descriptor",
      "title_zh": "翻译失败",
      "authors": [
        "Li Wang",
        "Xiangzheng Fu",
        "Jiahao Yang",
        "Xinyi Zhang",
        "Xiucai Ye",
        "Yiping Liu",
        "Tetsuya Sakurai",
        "Xiangxiang Zeng"
      ],
      "abstract": "Deep learning holds a big promise for optimizing existing peptides with more\ndesirable properties, a critical step towards accelerating new drug discovery.\nDespite the recent emergence of several optimized Antimicrobial peptides(AMP)\ngeneration methods, multi-objective optimizations remain still quite\nchallenging for the idealism-realism tradeoff. Here, we establish a\nmulti-objective AMP synthesis pipeline (MoFormer) for the simultaneous\noptimization of multi-attributes of AMPs. MoFormer improves the desired\nattributes of AMP sequences in a highly structured latent space, guided by\nconditional constraints and fine-grained multi-descriptor.We show that MoFormer\noutperforms existing methods in the generation task of enhanced antimicrobial\nactivity and minimal hemolysis. We also utilize a Pareto-based non-dominated\nsorting algorithm and proxies based on large model fine-tuning to\nhierarchically rank the candidates. We demonstrate substantial property\nimprovement using MoFormer from two perspectives: (1) employing molecular\nsimulations and scoring interactions among amino acids to decipher the\nstructure and functionality of AMPs; (2) visualizing latent space to examine\nthe qualities and distribution features, verifying an effective means to\nfacilitate multi-objective optimization AMPs with design constraints",
      "tldr_zh": "本文提出MoFormer框架，一种基于条件Transformer和联合多模态融合描述符的多目标抗菌肽(AMPs)生成方法，旨在同时优化AMPs的多属性，如增强抗菌活性和最小化溶血，以加速新药发现。MoFormer在高度结构化的潜在空间中，通过条件约束和细粒度多描述符指导序列改进，并利用Pareto-based非主导排序算法及大型模型微调代理进行候选分层排名。实验结果显示，MoFormer优于现有方法，并在分子模拟、氨基酸互动评分及潜在空间可视化中验证了其在属性提升方面的实质有效性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02610v1",
      "published_date": "2024-06-03 07:17:18 UTC",
      "updated_date": "2024-06-03 07:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:43:09.562760"
    },
    {
      "arxiv_id": "2406.01056v1",
      "title": "Virtual avatar generation models as world navigators",
      "title_zh": "翻译失败",
      "authors": [
        "Sai Mandava"
      ],
      "abstract": "We introduce SABR-CLIMB, a novel video model simulating human movement in\nrock climbing environments using a virtual avatar. Our diffusion transformer\npredicts the sample instead of noise in each diffusion step and ingests entire\nvideos to output complete motion sequences. By leveraging a large proprietary\ndataset, NAV-22M, and substantial computational resources, we showcase a proof\nof concept for a system to train general-purpose virtual avatars for complex\ntasks in robotics, sports, and healthcare.",
      "tldr_zh": "本研究引入了SABR-CLIMB，一种新型视频模型，用于模拟人类在攀岩环境中的运动，通过虚拟头像生成器作为世界导航器。模型采用diffusion transformer技术，在每个扩散步骤中预测样本而非噪声，并处理整个视频以输出完整的运动序列。通过利用大型专有数据集NAV-22M和大量计算资源，该系统展示了训练通用虚拟头像的证明概念。最终，这为机器人、体育和医疗等领域提供复杂任务的虚拟导航解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01056v1",
      "published_date": "2024-06-03 07:10:15 UTC",
      "updated_date": "2024-06-03 07:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:43:20.984968"
    },
    {
      "arxiv_id": "2406.01047v1",
      "title": "An Advanced Reinforcement Learning Framework for Online Scheduling of Deferrable Workloads in Cloud Computing",
      "title_zh": "一个先进的强化学习框架，用于云计算中可延期工作负载的在线调度",
      "authors": [
        "Hang Dong",
        "Liwen Zhu",
        "Zhao Shan",
        "Bo Qiao",
        "Fangkai Yang",
        "Si Qin",
        "Chuan Luo",
        "Qingwei Lin",
        "Yuwen Yang",
        "Gurpreet Virdi",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Thomas Moscibroda"
      ],
      "abstract": "Efficient resource utilization and perfect user experience usually conflict\nwith each other in cloud computing platforms. Great efforts have been invested\nin increasing resource utilization but trying not to affect users' experience\nfor cloud computing platforms. In order to better utilize the remaining pieces\nof computing resources spread over the whole platform, deferrable jobs are\nprovided with a discounted price to users. For this type of deferrable jobs,\nusers are allowed to submit jobs that will run for a specific uninterrupted\nduration in a flexible range of time in the future with a great discount. With\nthese deferrable jobs to be scheduled under the remaining capacity after\ndeploying those on-demand jobs, it remains a challenge to achieve high resource\nutilization and meanwhile shorten the waiting time for users as much as\npossible in an online manner. In this paper, we propose an online deferrable\njob scheduling method called \\textit{Online Scheduling for DEferrable jobs in\nCloud} (\\OSDEC{}), where a deep reinforcement learning model is adopted to\nlearn the scheduling policy, and several auxiliary tasks are utilized to\nprovide better state representations and improve the performance of the model.\nWith the integrated reinforcement learning framework, the proposed method can\nwell plan the deployment schedule and achieve a short waiting time for users\nwhile maintaining a high resource utilization for the platform. The proposed\nmethod is validated on a public dataset and shows superior performance.",
      "tldr_zh": "该论文针对云计算中可延迟作业(deferrable jobs)的在线调度问题，提出了一种先进的强化学习框架 OSDEC，以平衡高资源利用率和用户等待时间。OSDEC 采用深度强化学习(deep reinforcement learning)模型来学习调度策略，并整合辅助任务来优化状态表示和模型性能，从而实现高效的部署规划。实验在公共数据集上验证，该方法显著缩短了用户等待时间，同时维持了高资源利用率，表现出色。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01047v1",
      "published_date": "2024-06-03 06:55:26 UTC",
      "updated_date": "2024-06-03 06:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:43:34.008379"
    },
    {
      "arxiv_id": "2406.01045v1",
      "title": "Decompose, Enrich, and Extract! Schema-aware Event Extraction using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Fatemeh Shiri",
        "Van Nguyen",
        "Farhad Moghimifar",
        "John Yoo",
        "Gholamreza Haffari",
        "Yuan-Fang Li"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate significant capabilities in\nprocessing natural language data, promising efficient knowledge extraction from\ndiverse textual sources to enhance situational awareness and support\ndecision-making. However, concerns arise due to their susceptibility to\nhallucination, resulting in contextually inaccurate content. This work focuses\non harnessing LLMs for automated Event Extraction, introducing a new method to\naddress hallucination by decomposing the task into Event Detection and Event\nArgument Extraction. Moreover, the proposed method integrates dynamic\nschema-aware augmented retrieval examples into prompts tailored for each\nspecific inquiry, thereby extending and adapting advanced prompting techniques\nsuch as Retrieval-Augmented Generation. Evaluation findings on prominent event\nextraction benchmarks and results from a synthesized benchmark illustrate the\nmethod's superior performance compared to baseline approaches.",
      "tldr_zh": "本文提出一种名为“Decompose, Enrich, and Extract”的新方法，利用 LLMs 进行 schema-aware 的 Event Extraction，以减少 hallucination 问题。该方法将任务分解为 Event Detection 和 Event Argument Extraction，并通过整合动态 schema-aware augmented retrieval examples 到 prompts 中，扩展了 Retrieval-Augmented Generation 等技术。在多个基准测试中，该方法在性能上优于基线方法，展示了其在自动化知识提取和决策支持方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01045v1",
      "published_date": "2024-06-03 06:55:10 UTC",
      "updated_date": "2024-06-03 06:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:43:44.804244"
    },
    {
      "arxiv_id": "2406.01044v1",
      "title": "Nuclear Medicine Artificial Intelligence in Action: The Bethesda Report (AI Summit 2024)",
      "title_zh": "翻译失败",
      "authors": [
        "Arman Rahmim",
        "Tyler J. Bradshaw",
        "Guido Davidzon",
        "Joyita Dutta",
        "Georges El Fakhri",
        "Munir Ghesani",
        "Nicolas A. Karakatsanis",
        "Quanzheng Li",
        "Chi Liu",
        "Emilie Roncali",
        "Babak Saboury",
        "Tahir Yusufaly",
        "Abhinav K. Jha"
      ],
      "abstract": "The 2nd SNMMI Artificial Intelligence (AI) Summit, organized by the SNMMI AI\nTask Force, took place in Bethesda, MD, on February 29 - March 1, 2024.\nBringing together various community members and stakeholders, and following up\non a prior successful 2022 AI Summit, the summit theme was: AI in Action. Six\nkey topics included (i) an overview of prior and ongoing efforts by the AI task\nforce, (ii) emerging needs and tools for computational nuclear oncology, (iii)\nnew frontiers in large language and generative models, (iv) defining the value\nproposition for the use of AI in nuclear medicine, (v) open science including\nefforts for data and model repositories, and (vi) issues of reimbursement and\nfunding. The primary efforts, findings, challenges, and next steps are\nsummarized in this manuscript.",
      "tldr_zh": "本报告总结了2024年2月29日至3月1日在Bethesda举办的第2届SNMMI Artificial Intelligence (AI) Summit，主题为“AI in Action”，旨在推动AI在核医学领域的应用。会议涵盖了六个关键主题，包括AI任务力的过去努力和当前进展、计算核肿瘤学的新需求和工具、大语言模型及生成模型的前沿发展、AI在核医学的价值主张、开放科学中的数据和模型仓库努力，以及报销和资助问题。参与者讨论了主要成果、挑战，并提出了未来的行动步骤，为AI在核医学的实际部署提供了宝贵见解。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01044v1",
      "published_date": "2024-06-03 06:54:38 UTC",
      "updated_date": "2024-06-03 06:54:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:43:58.544942"
    },
    {
      "arxiv_id": "2406.18569v1",
      "title": "FLOW: Fusing and Shuffling Global and Local Views for Cross-User Human Activity Recognition with IMUs",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Qiu",
        "Tao Zhu",
        "Furong Duan",
        "Kevin I-Kai Wang",
        "Liming Chen",
        "Mingxing Nie",
        "Mingxing Nie"
      ],
      "abstract": "Inertial Measurement Unit (IMU) sensors are widely employed for Human\nActivity Recognition (HAR) due to their portability, energy efficiency, and\ngrowing research interest. However, a significant challenge for IMU-HAR models\nis achieving robust generalization performance across diverse users. This\nlimitation stems from substantial variations in data distribution among\nindividual users. One primary reason for this distribution disparity lies in\nthe representation of IMU sensor data in the local coordinate system, which is\nsusceptible to subtle user variations during IMU wearing. To address this\nissue, we propose a novel approach that extracts a global view representation\nbased on the characteristics of IMU data, effectively alleviating the data\ndistribution discrepancies induced by wearing styles. To validate the efficacy\nof the global view representation, we fed both global and local view data into\nmodel for experiments. The results demonstrate that global view data\nsignificantly outperforms local view data in cross-user experiments.\nFurthermore, we propose a Multi-view Supervised Network (MVFNet) based on\nShuffling to effectively fuse local view and global view data. It supervises\nthe feature extraction of each view through view division and view shuffling,\nso as to avoid the model ignoring important features as much as possible.\nExtensive experiments conducted on OPPORTUNITY and PAMAP2 datasets demonstrate\nthat the proposed algorithm outperforms the current state-of-the-art methods in\ncross-user HAR.",
      "tldr_zh": "这项研究针对 Inertial Measurement Unit (IMU) 传感器在 Human Activity Recognition (HAR) 中的应用，解决了跨用户场景下模型泛化性能差的问题，该问题主要源于用户佩戴方式导致的数据分布差异。研究提出一种新方法，通过提取基于 IMU 数据的全局视图表示来缓解这些差异，并在实验中证明全局视图在跨用户测试中显著优于本地视图。为有效融合本地和全局视图，作者开发了 Multi-view Supervised Network (MVFNet)，该网络利用视图划分和视图 shuffling 监督特征提取，避免忽略关键特征。在 OPPORTUNITY 和 PAMAP2 数据集上的广泛实验显示，该算法在跨用户 HAR 任务中超越了现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18569v1",
      "published_date": "2024-06-03 06:52:18 UTC",
      "updated_date": "2024-06-03 06:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:44:13.145076"
    },
    {
      "arxiv_id": "2406.01040v1",
      "title": "Synthetic Data Generation for 3D Myocardium Deformation Analysis",
      "title_zh": "用于 3D 心肌变形分析的合成数据生成",
      "authors": [
        "Shahar Zuler",
        "Dan Raviv"
      ],
      "abstract": "Accurate analysis of 3D myocardium deformation using high-resolution\ncomputerized tomography (CT) datasets with ground truth (GT) annotations is\ncrucial for advancing cardiovascular imaging research. However, the scarcity of\nsuch datasets poses a significant challenge for developing robust myocardium\ndeformation analysis models. To address this, we propose a novel approach to\nsynthetic data generation for enriching cardiovascular imaging datasets.\n  We introduce a synthetic data generation method, enriched with crucial GT 3D\noptical flow annotations. We outline the data preparation from a cardiac\nfour-dimensional (4D) CT scan, selection of parameters, and the subsequent\ncreation of synthetic data from the same or other sources of 3D cardiac CT data\nfor training.\n  Our work contributes to overcoming the limitations imposed by the scarcity of\nhigh-resolution CT datasets with precise annotations, thereby facilitating the\ndevelopment of accurate and reliable myocardium deformation analysis algorithms\nfor clinical applications and diagnostics.\n  Our code is available at:\nhttp://www.github.com/shaharzuler/cardio_volume_skewer",
      "tldr_zh": "本论文针对高分辨率 CT 数据集稀缺的问题，提出了一种合成数据生成方法，用于3D心肌变形分析，以提供带有ground truth (GT) 3D光学流注解的丰富数据集。该方法从4D CT扫描准备数据，选择适当参数，并利用相同或其他来源的3D心脏CT数据创建合成训练样本，从而克服数据不足的限制。实验结果表明，此方法有助于开发更准确可靠的心肌变形分析算法，支持临床诊断和应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01040v1",
      "published_date": "2024-06-03 06:40:53 UTC",
      "updated_date": "2024-06-03 06:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:44:21.762532"
    },
    {
      "arxiv_id": "2406.01032v1",
      "title": "LLM and GNN are Complementary: Distilling LLM for Multimodal Graph Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Xu",
        "Zongyu Wu",
        "Minhua Lin",
        "Xiang Zhang",
        "Suhang Wang"
      ],
      "abstract": "Recent progress in Graph Neural Networks (GNNs) has greatly enhanced the\nability to model complex molecular structures for predicting properties.\nNevertheless, molecular data encompasses more than just graph structures,\nincluding textual and visual information that GNNs do not handle well. To\nbridge this gap, we present an innovative framework that utilizes multimodal\nmolecular data to extract insights from Large Language Models (LLMs). We\nintroduce GALLON (Graph Learning from Large Language Model Distillation), a\nframework that synergizes the capabilities of LLMs and GNNs by distilling\nmultimodal knowledge into a unified Multilayer Perceptron (MLP). This method\nintegrates the rich textual and visual data of molecules with the structural\nanalysis power of GNNs. Extensive experiments reveal that our distilled MLP\nmodel notably improves the accuracy and efficiency of molecular property\npredictions.",
      "tldr_zh": "该研究指出，Graph Neural Networks (GNNs) 虽擅长处理分子图结构，但无法有效利用文本和视觉信息，因此提出 GALLON 框架，通过从 Large Language Models (LLMs) 中蒸馏多模态知识，将这些信息与 GNN 的结构分析能力整合到一个统一的 Multilayer Perceptron (MLP) 模型中。GALLON 框架实现了 LLM 和 GNN 的互补协同，提升了分子属性预测的整体性能。实验结果显示，该方法显著提高了预测准确性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01032v1",
      "published_date": "2024-06-03 06:33:51 UTC",
      "updated_date": "2024-06-03 06:33:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:44:34.047256"
    },
    {
      "arxiv_id": "2406.01641v3",
      "title": "Reciprocal Reward Influence Encourages Cooperation From Self-Interested Agents",
      "title_zh": "互惠奖励影响鼓励自我利益代理的合作",
      "authors": [
        "John L. Zhou",
        "Weizhe Hong",
        "Jonathan C. Kao"
      ],
      "abstract": "Cooperation between self-interested individuals is a widespread phenomenon in\nthe natural world, but remains elusive in interactions between artificially\nintelligent agents. Instead, naive reinforcement learning algorithms typically\nconverge to Pareto-dominated outcomes in even the simplest of social dilemmas.\nAn emerging literature on opponent shaping has demonstrated the ability to\nreach prosocial outcomes by influencing the learning of other agents. However,\nsuch methods differentiate through the learning step of other agents or\noptimize for meta-game dynamics, which rely on privileged access to opponents'\nlearning algorithms or exponential sample complexity, respectively. To provide\na learning rule-agnostic and sample-efficient alternative, we introduce\nReciprocators, reinforcement learning agents which are intrinsically motivated\nto reciprocate the influence of opponents' actions on their returns. This\napproach seeks to modify other agents' $Q$-values by increasing their return\nfollowing beneficial actions (with respect to the Reciprocator) and decreasing\nit after detrimental actions, guiding them towards mutually beneficial actions\nwithout directly differentiating through a model of their policy. We show that\nReciprocators can be used to promote cooperation in temporally extended social\ndilemmas during simultaneous learning. Our code is available at\nhttps://github.com/johnlyzhou/reciprocator/.",
      "tldr_zh": "本研究探讨了在强化学习（Reinforcement Learning）中，如何促使自私代理（self-interested agents）在社会困境（social dilemmas）中实现合作。论文引入了 Reciprocators 代理，通过内在动机来回报对手行为对自身回报的影响，即通过增加对手有益行为的 Q-values 或减少有害行为的 Q-values，引导他们朝向互惠策略，而无需依赖对手的学习规则或高样本复杂度。实验结果显示，Reciprocators 能在时间扩展的社会困境中有效促进合作，提供了一种学习规则无关（learning rule-agnostic）和样本高效的替代方法。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01641v3",
      "published_date": "2024-06-03 06:07:27 UTC",
      "updated_date": "2025-01-14 23:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:44:45.607880"
    },
    {
      "arxiv_id": "2406.06565v2",
      "title": "MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures",
      "title_zh": "MixEval：从LLM基准测试混合中衍生群体智慧",
      "authors": [
        "Jinjie Ni",
        "Fuzhao Xue",
        "Xiang Yue",
        "Yuntian Deng",
        "Mahir Shah",
        "Kabir Jain",
        "Graham Neubig",
        "Yang You"
      ],
      "abstract": "Evaluating large language models (LLMs) is challenging. Traditional\nground-truth-based benchmarks fail to capture the comprehensiveness and nuance\nof real-world queries, while LLM-as-judge benchmarks suffer from grading biases\nand limited query quantity. Both of them may also become contaminated over\ntime. User-facing evaluation, such as Chatbot Arena, provides reliable signals\nbut is costly and slow. In this work, we propose MixEval, a new paradigm for\nestablishing efficient, gold-standard LLM evaluation by strategically mixing\noff-the-shelf benchmarks. It bridges (1) comprehensive and well-distributed\nreal-world user queries and (2) efficient and fairly-graded ground-truth-based\nbenchmarks, by matching queries mined from the web with similar queries from\nexisting benchmarks. Based on MixEval, we further build MixEval-Hard, which\noffers more room for model improvement. Our benchmarks' advantages lie in (1) a\n0.96 model ranking correlation with Chatbot Arena arising from the highly\nimpartial query distribution and grading mechanism, (2) fast, cheap, and\nreproducible execution (6% of the time and cost of MMLU), and (3) dynamic\nevaluation enabled by the rapid and stable data update pipeline. We provide\nextensive meta-evaluation and analysis for our and existing LLM benchmarks to\ndeepen the community's understanding of LLM evaluation and guide future\nresearch directions.",
      "tldr_zh": "这篇论文解决了大型语言模型(LLMs)评估的挑战，包括传统基准的局限性（如不全面和易污染）和LLM-as-judge方法的偏见问题。作者提出MixEval，一种新范式，通过混合现成基准并将网络挖掘的查询与类似基准查询匹配，结合全面的用户查询和高效的评分机制。实验结果显示，MixEval与Chatbot Arena的模型排名相关性高达0.96%，执行时间和成本仅为MMLU的6%，并支持动态更新，从而为可靠的LLM评估提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06565v2",
      "published_date": "2024-06-03 05:47:05 UTC",
      "updated_date": "2024-10-12 14:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:44:58.699765"
    },
    {
      "arxiv_id": "2406.01012v1",
      "title": "Attention-based Iterative Decomposition for Tensor Product Representation",
      "title_zh": "基于注意力的迭代分解用于张量乘积表示",
      "authors": [
        "Taewon Park",
        "Inchul Choi",
        "Minho Lee"
      ],
      "abstract": "In recent research, Tensor Product Representation (TPR) is applied for the\nsystematic generalization task of deep neural networks by learning the\ncompositional structure of data. However, such prior works show limited\nperformance in discovering and representing the symbolic structure from unseen\ntest data because their decomposition to the structural representations was\nincomplete. In this work, we propose an Attention-based Iterative Decomposition\n(AID) module designed to enhance the decomposition operations for the\nstructured representations encoded from the sequential input data with TPR. Our\nAID can be easily adapted to any TPR-based model and provides enhanced\nsystematic decomposition through a competitive attention mechanism between\ninput features and structured representations. In our experiments, AID shows\neffectiveness by significantly improving the performance of TPR-based prior\nworks on the series of systematic generalization tasks. Moreover, in the\nquantitative and qualitative evaluations, AID produces more compositional and\nwell-bound structural representations than other works.",
      "tldr_zh": "该研究针对Tensor Product Representation (TPR) 在深度神经网络系统化泛化任务中存在的分解不完整问题，提出了一种Attention-based Iterative Decomposition (AID) 模块，以增强从顺序输入数据中编码的结构化表示。AID 通过输入特征与结构化表示之间的竞争性注意力机制，提供更有效的系统化分解，并可轻松整合到任何TPR-based模型中。实验结果表明，AID 显著提升了TPR-based模型在系统化泛化任务上的性能，并在定量和定性评估中生成了更组合性和良好绑定的结构化表示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01012v1",
      "published_date": "2024-06-03 05:46:52 UTC",
      "updated_date": "2024-06-03 05:46:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:45:12.325622"
    },
    {
      "arxiv_id": "2406.01011v1",
      "title": "Multi-Object Tracking based on Imaging Radar 3D Object Detection",
      "title_zh": "基于成像雷达的3D物体检测多目标跟踪",
      "authors": [
        "Patrick Palmer",
        "Martin Krüger",
        "Richard Altendorfer",
        "Torsten Bertram"
      ],
      "abstract": "Effective tracking of surrounding traffic participants allows for an accurate\nstate estimation as a necessary ingredient for prediction of future behavior\nand therefore adequate planning of the ego vehicle trajectory. One approach for\ndetecting and tracking surrounding traffic participants is the combination of a\nlearning based object detector with a classical tracking algorithm. Learning\nbased object detectors have been shown to work adequately on lidar and camera\ndata, while learning based object detectors using standard radar data input\nhave proven to be inferior. Recently, with the improvements to radar sensor\ntechnology in the form of imaging radars, the object detection performance on\nradar was greatly improved but is still limited compared to lidar sensors due\nto the sparsity of the radar point cloud. This presents a unique challenge for\nthe task of multi-object tracking. The tracking algorithm must overcome the\nlimited detection quality while generating consistent tracks. To this end, a\ncomparison between different multi-object tracking methods on imaging radar\ndata is required to investigate its potential for downstream tasks. The work at\nhand compares multiple approaches and analyzes their limitations when applied\nto imaging radar data. Furthermore, enhancements to the presented approaches in\nthe form of probabilistic association algorithms are considered for this task.",
      "tldr_zh": "本文研究了基于imaging radar的3D object detection在multi-object tracking中的应用，强调了雷达点云稀疏性导致的检测质量问题，从而影响交通参与者跟踪和车辆轨迹规划。论文比较了多种multi-object tracking方法，分析了它们在imaging radar数据上的局限性，并探讨了probabilistic association algorithms作为增强策略，以生成更一致的跟踪轨迹。主要贡献在于揭示了imaging radar在下游任务中的潜力，并为改进跟踪算法提供了见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Presented at: 9. International ATZ-Live Automated Driving 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01011v1",
      "published_date": "2024-06-03 05:46:23 UTC",
      "updated_date": "2024-06-03 05:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:45:23.404077"
    },
    {
      "arxiv_id": "2406.06564v3",
      "title": "SwitchLoRA: Switched Low-Rank Adaptation Can Learn Full-Rank Information",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiye Zhou",
        "Shucheng Wang",
        "Jun Xu"
      ],
      "abstract": "In the training of large language models, parameter-efficient techniques such\nas LoRA optimize memory usage and reduce communication overhead and memory\nusage during the fine-tuning phase. However, applying such techniques directly\nduring the pre-training phase results in poor performance, primarily because\nthe premature implementation of low-rank training significantly reduces model\naccuracy. Existing methods like ReLoRA and GaLore have attempted to address\nthis challenge by updating the low-rank subspace. However, they still fall\nshort of achieving the accuracy of full-rank training. Specifically, ReLoRA\nrestricts the frequency of updates to preserve optimizer states consistency,\nhindering its ability to closely approximate full-rank training behavior.\nMeanwhile, GaLore relies on Singular Value Decomposition (SVD) to approximate\nthe full-rank space, which introduces accuracy loss during the approximation\nprocess. In this paper, we introduce SwitchLoRA, a parameter-efficient training\ntechnique that frequently and smoothly replaces the trainable parameters of\nLoRA adapters with alternative parameters. SwitchLoRA updates the low-rank\nsubspace incrementally, targeting only a few dimensions at a time to minimize\nthe impact on optimizer states. This allows a higher update frequency, thereby\nenhancing accuracy by enabling the updated parameters to more closely mimic\nfull-rank behavior during the pre-training phase. Our results demonstrate that\nSwitchLoRA actually surpasses full-rank training, reducing perplexity from\n15.23 to 15.01 on the LLaMA 1.3B model, while also cutting communication\noverhead by 54\\% and memory usage by 13\\%. Furthermore, after full fine-tuning\nthe SwitchLoRA pre-trained model and the full-rank pre-trained model on the\nGLUE benchmark, the SwitchLoRA pre-trained model showed an average accuracy\ngain of about 1\\% over the full-rank pre-trained model.",
      "tldr_zh": "本文提出 SwitchLoRA，一种改进的低秩适应技术，用于大型语言模型的预训练阶段，通过频繁且平滑地替换 LoRA 适配器的可训练参数，逐步更新低秩子空间，以最小化对优化器状态的影响并更接近全秩训练的行为。相比现有方法如 ReLoRA 和 GaLore，SwitchLoRA 实现了更高的更新频率，提升了模型准确性。实验结果显示，在 LLaMA 1.3B 模型上，SwitchLoRA 将 perplexity 从 15.23 降低到 15.01，同时减少了 54% 的通信开销和 13% 的内存使用；在 GLUE benchmark 全细调后，其预训练模型比全秩预训练模型平均准确率提高了约 1%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "SwitchLoRA introduces an innovative parameter-efficient training\n  method that dynamically switches parameters throughout the entire training\n  period, achieving significant memory and communication overhead while\n  preserving accuracy",
      "pdf_url": "http://arxiv.org/pdf/2406.06564v3",
      "published_date": "2024-06-03 05:40:34 UTC",
      "updated_date": "2025-01-02 17:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:45:39.272892"
    },
    {
      "arxiv_id": "2406.01006v2",
      "title": "SemCoder: Training Code Language Models with Comprehensive Semantics Reasoning",
      "title_zh": "SemCoder：使用全面语义推理训练代码语言模型",
      "authors": [
        "Yangruibo Ding",
        "Jinjun Peng",
        "Marcus J. Min",
        "Gail Kaiser",
        "Junfeng Yang",
        "Baishakhi Ray"
      ],
      "abstract": "Code Large Language Models (Code LLMs) have excelled at tasks like code\ncompletion but often miss deeper semantics such as execution effects and\ndynamic states. This paper aims to bridge the gap between Code LLMs' reliance\non static text data and the need for semantic understanding for complex tasks\nlike debugging and program repair. We introduce a novel strategy, monologue\nreasoning, to train Code LLMs to reason comprehensive semantics, encompassing\nhigh-level functional descriptions, local execution effects of individual\nstatements, and overall input/output behavior, thereby linking static code text\nwith dynamic execution states. We begin by collecting PyX, a clean Python\ncorpus of fully executable code samples with functional descriptions and test\ncases. We propose training Code LLMs not only to write code but also to\nunderstand code semantics by reasoning about key properties, constraints, and\nexecution behaviors using natural language, mimicking human verbal debugging,\ni.e., rubber-duck debugging. This approach led to the development of SemCoder,\na Code LLM with only 6.7B parameters, which shows competitive performance with\nGPT-3.5-turbo on code generation and execution reasoning tasks. SemCoder\nachieves 79.3% on HumanEval (GPT-3.5-turbo: 76.8%), 63.6% on CRUXEval-I\n(GPT-3.5-turbo: 50.3%), and 63.9% on CRUXEval-O (GPT-3.5-turbo: 59.0%). We also\nstudy the effectiveness of SemCoder's monologue-style execution reasoning\ncompared to concrete scratchpad reasoning, showing that our approach integrates\nsemantics from multiple dimensions more smoothly. Finally, we demonstrate the\npotential of applying learned semantics to improve Code LLMs' debugging and\nself-refining capabilities. Our data, code, and models are available at:\nhttps://github.com/ARiSE-Lab/SemCoder.",
      "tldr_zh": "本论文针对Code LLMs在代码补全等任务上表现优异，但缺乏对执行效果和动态状态等深层语义理解的问题，提出了一种名为monologue reasoning的训练策略，以桥接静态文本依赖与语义推理需求。研究者收集了PyX数据集——一个包含可执行Python代码样本、功能描述和测试用例的语料库，并训练模型通过自然语言推理代码的关键属性、约束和行为，模仿rubber-duck debugging的方式。结果，开发的SemCoder模型（仅6.7B参数）在HumanEval上达到79.3%、CRUXEval-I上63.6%和CRUXEval-O上63.9%的性能，优于或媲美GPT-3.5-turbo，并证明了其monologue-style推理在整合多维度语义方面的优势，最终提升了Code LLMs的调试和自精炼能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 Camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2406.01006v2",
      "published_date": "2024-06-03 05:36:57 UTC",
      "updated_date": "2024-10-31 23:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:45:51.505839"
    },
    {
      "arxiv_id": "2406.00983v1",
      "title": "Take its Essence, Discard its Dross! Debiasing for Toxic Language Detection via Counterfactual Causal Effect",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Lu",
        "Bo Xu",
        "Xiaokun Zhang",
        "Kaiyuan Liu",
        "Dongyu Zhang",
        "Liang Yang",
        "Hongfei Lin"
      ],
      "abstract": "Current methods of toxic language detection (TLD) typically rely on specific\ntokens to conduct decisions, which makes them suffer from lexical bias, leading\nto inferior performance and generalization. Lexical bias has both \"useful\" and\n\"misleading\" impacts on understanding toxicity. Unfortunately, instead of\ndistinguishing between these impacts, current debiasing methods typically\neliminate them indiscriminately, resulting in a degradation in the detection\naccuracy of the model. To this end, we propose a Counterfactual Causal\nDebiasing Framework (CCDF) to mitigate lexical bias in TLD. It preserves the\n\"useful impact\" of lexical bias and eliminates the \"misleading impact\".\nSpecifically, we first represent the total effect of the original sentence and\nbiased tokens on decisions from a causal view. We then conduct counterfactual\ninference to exclude the direct causal effect of lexical bias from the total\neffect. Empirical evaluations demonstrate that the debiased TLD model\nincorporating CCDF achieves state-of-the-art performance in both accuracy and\nfairness compared to competitive baselines applied on several vanilla models.\nThe generalization capability of our model outperforms current debiased models\nfor out-of-distribution data.",
      "tldr_zh": "本文针对毒性语言检测(TLD)中的词汇偏差(lexical bias)问题，提出Counterfactual Causal Debiasing Framework (CCDF)，该框架通过反事实因果推理保留词汇偏差的“有用影响”并消除“误导影响”。具体方法包括从因果视角分析原句和偏差tokens的总效应，然后进行反事实推理以排除直接因果效应。实验结果表明，CCDF增强的TLD模型在准确性、公平性和泛化能力上均优于现有基准，尤其在分布外(out-of-distribution)数据上实现了最先进性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00983v1",
      "published_date": "2024-06-03 04:34:30 UTC",
      "updated_date": "2024-06-03 04:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:46:01.548763"
    },
    {
      "arxiv_id": "2406.00977v2",
      "title": "Dragonfly: Multi-Resolution Zoom-In Encoding Enhances Vision-Language Models",
      "title_zh": "Dragonfly：多分辨率缩放编码增强视觉语言模型",
      "authors": [
        "Rahul Thapa",
        "Kezhen Chen",
        "Ian Covert",
        "Rahul Chalamala",
        "Ben Athiwaratkun",
        "Shuaiwen Leon Song",
        "James Zou"
      ],
      "abstract": "Recent advances in vision-language models (VLMs) have demonstrated the\nadvantages of processing images at higher resolutions and utilizing multi-crop\nfeatures to preserve native resolution details. However, despite these\nimprovements, existing vision transformers (ViTs) still struggle to capture\nfine-grained details from less prominent objects, charts, and embedded text,\nlimiting their effectiveness in certain tasks. In this paper, we extend recent\nhigh-resolution and multi-crop techniques by not only preserving the native\nresolution, but zooming in beyond it and extracting features from a large\nnumber of image sub-crops. This enhancement allows our model to better capture\nfine-grained details, overcoming the limitations of current ViTs. To manage the\nincreased token count and computational complexity, we demonstrate that a\nsimple mean-pooling aggregation over tokens is effective. Our model, Dragonfly,\nachieves competitive performance on general-domain tasks such as ScienceQA and\nAI2D, and excels in tasks requiring fine-grained image understanding, including\nTextVQA and ChartQA. Among models in the 7-8B parameter range, Dragonfly\nconsistently ranks at the top across ten general-domain benchmarks, achieving\nthe highest or second-highest scores in most cases, outperforming models that\nare significantly larger or trained on larger datasets. Our biomedical model,\nDragonfly-Med, sets new benchmarks on several medical tasks, achieving 91.6%\naccuracy on SLAKE (compared to 84.8% for Med-Gemini), a 67.1% token F1 score on\nPath-VQA (compared to 62.7% for Med-PaLM M), and state-of-the-art results\nacross the majority of image captioning tasks. Overall, our work highlights the\npersistent challenge of engineering visual representations with\nfixed-resolution ViTs, and proposes a simple yet effective solution to address\nthis issue and boost performance in both general and specialized domains.",
      "tldr_zh": "本论文提出 Dragonfly 模型，通过多分辨率缩放编码和从大量图像子裁剪中提取特征，增强视觉语言模型 (VLMs) 对细粒度细节（如物体、图表和文本）的捕获能力，同时采用简单的均值池化聚合来管理增加的 token 数量和计算复杂度。实验结果显示，Dragonfly 在一般领域任务如 ScienceQA 和 AI2D 上表现竞争，在细粒度任务如 TextVQA 和 ChartQA 上表现出色，并在 7-8B 参数范围的模型中排名第一或第二，优于更大模型。生物医学版本 Dragonfly-Med 则在医疗任务上设置新基准，如 SLAKE 的 91.6% 准确率和 Path-VQA 的 67.1% token F1 分数，证明了该方法在解决固定分辨率 Vision Transformers (ViTs) 挑战方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00977v2",
      "published_date": "2024-06-03 04:17:12 UTC",
      "updated_date": "2024-10-14 23:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:46:16.466729"
    },
    {
      "arxiv_id": "2406.00975v2",
      "title": "Luna: An Evaluation Foundation Model to Catch Language Model Hallucinations with High Accuracy and Low Cost",
      "title_zh": "Luna：一种用于以高准确性和低成本捕捉语言模型幻觉的评估基础模型",
      "authors": [
        "Masha Belyi",
        "Robert Friel",
        "Shuai Shao",
        "Atindriyo Sanyal"
      ],
      "abstract": "Retriever Augmented Generation (RAG) systems have become pivotal in enhancing\nthe capabilities of language models by incorporating external knowledge\nretrieval mechanisms. However, a significant challenge in deploying these\nsystems in industry applications is the detection and mitigation of\nhallucinations: instances where the model generates information that is not\ngrounded in the retrieved context. Addressing this issue is crucial for\nensuring the reliability and accuracy of responses generated by large language\nmodels (LLMs) in diverse industry settings. Current hallucination detection\ntechniques fail to deliver accuracy, low latency, and low cost simultaneously.\nWe introduce Luna: a DeBERTA-large (440M) encoder, finetuned for hallucination\ndetection in RAG settings. We demonstrate that Luna outperforms GPT-3.5 and\ncommercial evaluation frameworks on the hallucination detection task, with 97%\nand 91% reduction in cost and latency, respectively. Luna is lightweight and\ngeneralizes across multiple industry verticals and out-of-domain data, making\nit an ideal candidate for industry LLM applications.",
      "tldr_zh": "该论文介绍了Luna，一种基于DeBERTA-large (440M)编码器的评估基础模型，旨在高效检测Retriever Augmented Generation (RAG)系统中的hallucinations问题，同时实现高准确率、低成本和低延迟。Luna通过针对RAG场景的微调，超越了GPT-3.5和商业框架，在hallucination检测任务上表现出色。实验结果显示，Luna将成本和延迟分别降低了97%和91%，并展现出良好的泛化能力，适用于多个行业垂直领域和领域外数据，从而提升工业LLM应用的可靠性和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00975v2",
      "published_date": "2024-06-03 04:14:21 UTC",
      "updated_date": "2024-06-05 15:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:46:25.798864"
    },
    {
      "arxiv_id": "2406.02609v2",
      "title": "Less is More: Pseudo-Label Filtering for Continual Test-Time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayao Tan",
        "Fan Lyu",
        "Chenggong Ni",
        "Tingliang Feng",
        "Fuyuan Hu",
        "Zhang Zhang",
        "Shaochuang Zhao",
        "Liang Wang"
      ],
      "abstract": "Continual Test-Time Adaptation (CTTA) aims to adapt a pre-trained model to a\nsequence of target domains during the test phase without accessing the source\ndata. To adapt to unlabeled data from unknown domains, existing methods rely on\nconstructing pseudo-labels for all samples and updating the model through\nself-training. However, these pseudo-labels often involve noise, leading to\ninsufficient adaptation. To improve the quality of pseudo-labels, we propose a\npseudo-label selection method for CTTA, called Pseudo Labeling Filter (PLF).\nThe key idea of PLF is to keep selecting appropriate thresholds for\npseudo-labels and identify reliable ones for self-training. Specifically, we\npresent three principles for setting thresholds during continuous domain\nlearning, including initialization, growth and diversity. Based on these\nprinciples, we design Self-Adaptive Thresholding to filter pseudo-labels.\nAdditionally, we introduce a Class Prior Alignment (CPA) method to encourage\nthe model to make diverse predictions for unknown domain samples. Through\nextensive experiments, PLF outperforms current state-of-the-art methods,\nproving its effectiveness in CTTA.",
      "tldr_zh": "这篇论文针对 Continual Test-Time Adaptation (CTTA) 的挑战，提出了一种伪标签过滤方法 Pseudo Labeling Filter (PLF)，旨在通过动态选择阈值来筛选可靠的伪标签，从而改善自训练过程并减少噪声影响。PLF 基于初始化、增长和多样性三原则设计了 Self-Adaptive Thresholding 机制，并引入 Class Prior Alignment (CPA) 方法以鼓励模型对未知域样本进行多样化预测。实验结果显示，PLF 比现有最先进方法性能提升显著，证明了其在 CTTA 任务中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2310.03335 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2406.02609v2",
      "published_date": "2024-06-03 04:09:36 UTC",
      "updated_date": "2024-07-12 08:15:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:46:40.934772"
    },
    {
      "arxiv_id": "2406.06563v1",
      "title": "Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tianwen Wei",
        "Bo Zhu",
        "Liang Zhao",
        "Cheng Cheng",
        "Biye Li",
        "Weiwei Lü",
        "Peng Cheng",
        "Jianhao Zhang",
        "Xiaoyu Zhang",
        "Liang Zeng",
        "Xiaokun Wang",
        "Yutuan Ma",
        "Rui Hu",
        "Shuicheng Yan",
        "Han Fang",
        "Yahui Zhou"
      ],
      "abstract": "In this technical report, we introduce the training methodologies implemented\nin the development of Skywork-MoE, a high-performance mixture-of-experts (MoE)\nlarge language model (LLM) with 146 billion parameters and 16 experts. It is\ninitialized from the pre-existing dense checkpoints of our Skywork-13B model.\nWe explore the comparative effectiveness of upcycling versus training from\nscratch initializations. Our findings suggest that the choice between these two\napproaches should consider both the performance of the existing dense\ncheckpoints and the MoE training budget. We highlight two innovative\ntechniques: gating logit normalization, which improves expert diversification,\nand adaptive auxiliary loss coefficients, allowing for layer-specific\nadjustment of auxiliary loss coefficients. Our experimental results validate\nthe effectiveness of these methods. Leveraging these techniques and insights,\nwe trained our upcycled Skywork-MoE on a condensed subset of our SkyPile\ncorpus. The evaluation results demonstrate that our model delivers strong\nperformance across a wide range of benchmarks.",
      "tldr_zh": "本报告深入探讨了 Skywork-MoE 的训练技术，这是一个基于 Mixture-of-Experts (MoE) 的 146 亿参数大型语言模型 (LLM)，从现有 Skywork-13B 的密集检查点初始化。研究比较了 upcycling 与从头训练的有效性，并引入了两个创新方法：gating logit normalization 以提升专家多样性，以及 adaptive auxiliary loss coefficients 以实现层级调整辅助损失系数。实验结果验证了这些技术的优势，Skywork-MoE 在精简的 SkyPile 语料上训练后，在多种基准测试中表现出强劲性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06563v1",
      "published_date": "2024-06-03 03:58:41 UTC",
      "updated_date": "2024-06-03 03:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:46:50.431012"
    },
    {
      "arxiv_id": "2407.13942v1",
      "title": "Harmful Suicide Content Detection",
      "title_zh": "有害自杀内容检测",
      "authors": [
        "Kyumin Park",
        "Myung Jae Baik",
        "YeongJun Hwang",
        "Yen Shin",
        "HoJae Lee",
        "Ruda Lee",
        "Sang Min Lee",
        "Je Young Hannah Sun",
        "Ah Rah Lee",
        "Si Yeun Yoon",
        "Dong-ho Lee",
        "Jihyung Moon",
        "JinYeong Bak",
        "Kyunghyun Cho",
        "Jong-Woo Paik",
        "Sungjoon Park"
      ],
      "abstract": "Harmful suicide content on the Internet is a significant risk factor inducing\nsuicidal thoughts and behaviors among vulnerable populations. Despite global\nefforts, existing resources are insufficient, specifically in high-risk regions\nlike the Republic of Korea. Current research mainly focuses on understanding\nnegative effects of such content or suicide risk in individuals, rather than on\nautomatically detecting the harmfulness of content. To fill this gap, we\nintroduce a harmful suicide content detection task for classifying online\nsuicide content into five harmfulness levels. We develop a multi-modal\nbenchmark and a task description document in collaboration with medical\nprofessionals, and leverage large language models (LLMs) to explore efficient\nmethods for moderating such content. Our contributions include proposing a\nnovel detection task, a multi-modal Korean benchmark with expert annotations,\nand suggesting strategies using LLMs to detect illegal and harmful content.\nOwing to the potential harm involved, we publicize our implementations and\nbenchmark, incorporating an ethical verification process.",
      "tldr_zh": "该研究针对互联网上有害自杀内容对易感人群的潜在风险（如诱发自杀想法），提出了一种新的检测任务，将在线自杀内容分类为五级危害性，以填补现有资源不足的空白，特别是针对韩国等高风险地区。研究者与医疗专业人士合作，开发了一个多模态基准数据集和任务描述文档，并利用Large Language Models (LLMs)探索高效的内容审核策略。贡献包括提出这一新型检测任务、构建专家注解的韩国多模态基准，以及公开实现方式，同时纳入道德验证过程以减少潜在危害。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "30 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.13942v1",
      "published_date": "2024-06-03 03:43:44 UTC",
      "updated_date": "2024-06-03 03:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:47:02.103065"
    },
    {
      "arxiv_id": "2406.00965v5",
      "title": "HBTP: Heuristic Behavior Tree Planning with Large Language Model Reasoning",
      "title_zh": "HBTP: 基于大语言模型推理的启发式行为树规划",
      "authors": [
        "Yishuai Cai",
        "Xinglin Chen",
        "Yunxin Mao",
        "Minglong Li",
        "Shaowu Yang",
        "Wenjing Yang",
        "Ji Wang"
      ],
      "abstract": "Behavior Trees (BTs) are increasingly becoming a popular control structure in\nrobotics due to their modularity, reactivity, and robustness. In terms of BT\ngeneration methods, BT planning shows promise for generating reliable BTs.\nHowever, the scalability of BT planning is often constrained by prolonged\nplanning times in complex scenarios, largely due to a lack of domain knowledge.\nIn contrast, pre-trained Large Language Models (LLMs) have demonstrated task\nreasoning capabilities across various domains, though the correctness and\nsafety of their planning remain uncertain. This paper proposes integrating BT\nplanning with LLM reasoning, introducing Heuristic Behavior Tree Planning\n(HBTP)-a reliable and efficient framework for BT generation. The key idea in\nHBTP is to leverage LLMs for task-specific reasoning to generate a heuristic\npath, which BT planning can then follow to expand efficiently. We first\nintroduce the heuristic BT expansion process, along with two heuristic variants\ndesigned for optimal planning and satisficing planning, respectively. Then, we\npropose methods to address the inaccuracies of LLM reasoning, including action\nspace pruning and reflective feedback, to further enhance both reasoning\naccuracy and planning efficiency. Experiments demonstrate the theoretical\nbounds of HBTP, and results from four datasets confirm its practical\neffectiveness in everyday service robot applications.",
      "tldr_zh": "本论文提出Heuristic Behavior Tree Planning (HBTP)框架，将Large Language Models (LLMs)与Behavior Trees (BTs)规划相结合，解决BTs在复杂机器人场景中规划时间长和缺乏领域知识的问题。HBTP的关键在于利用LLMs进行任务特定推理生成启发式路径，并开发两种变体分别针对最优规划和满意规划，同时通过行动空间修剪和反射反馈机制来提升LLMs推理的准确性。实验在四个服务机器人数据集上验证了HBTP的有效性，展示了其理论边界并显著提高了规划的可靠性和效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00965v5",
      "published_date": "2024-06-03 03:38:56 UTC",
      "updated_date": "2025-03-07 08:27:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:47:14.536716"
    },
    {
      "arxiv_id": "2406.06562v1",
      "title": "Achieving Sparse Activation in Small Language Models",
      "title_zh": "实现小型语言模型中的稀疏激活",
      "authors": [
        "Jifeng Song",
        "Kai Huang",
        "Xiangyu Yin",
        "Boyuan Yang",
        "Wei Gao"
      ],
      "abstract": "Sparse activation, which selectively activates only an input-dependent set of\nneurons in inference, is a useful technique to reduce the computing cost of\nLarge Language Models (LLMs) without retraining or adaptation efforts. However,\nwhether it can be applied to the recently emerging Small Language Models (SLMs)\nremains questionable, because SLMs are generally less over-parameterized than\nLLMs. In this paper, we aim to achieve sparse activation in SLMs. We first show\nthat the existing sparse activation schemes in LLMs that build on neurons'\noutput magnitudes cannot be applied to SLMs, and activating neurons based on\ntheir attribution scores is a better alternative. Further, we demonstrated and\nquantified the large errors of existing attribution metrics when being used for\nsparse activation, due to the interdependency among attribution scores of\nneurons across different layers. Based on these observations, we proposed a new\nattribution metric that can provably correct such errors and achieve precise\nsparse activation. Experiments over multiple popular SLMs and datasets show\nthat our approach can achieve 80% sparsification ratio with <5% model accuracy\nloss, comparable to the sparse activation achieved in LLMs. The source code is\navailable at: https://github.com/pittisl/Sparse-Activation.",
      "tldr_zh": "本研究探讨了在小型语言模型（SLMs）中实现稀疏激活（sparse activation），以减少计算成本，而无需重新训练。作者发现，现有的基于神经元输出幅度的稀疏激活方案不适用于 SLMs，因此改用基于归因分数（attribution scores）的激活方法，并量化了现有归因指标在层间依赖性下的错误。论文提出了一种新的归因指标，能够修正这些错误，实现精确的稀疏激活。实验结果显示，在多个 SLMs 和数据集上，该方法实现了 80% 的稀疏化比率，同时模型准确率损失小于 5%，与大型语言模型（LLMs）中的效果相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.06562v1",
      "published_date": "2024-06-03 03:21:49 UTC",
      "updated_date": "2024-06-03 03:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:47:26.316961"
    },
    {
      "arxiv_id": "2406.00954v1",
      "title": "Annotation Guidelines-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Shiqi Liu",
        "Sannyuya Liu",
        "Lele Sha",
        "Zijie Zeng",
        "Dragan Gasevic",
        "Zhi Liu"
      ],
      "abstract": "Various machine learning approaches have gained significant popularity for\nthe automated classification of educational text to identify indicators of\nlearning engagement -- i.e. learning engagement classification (LEC). LEC can\noffer comprehensive insights into human learning processes, attracting\nsignificant interest from diverse research communities, including Natural\nLanguage Processing (NLP), Learning Analytics, and Educational Data Mining.\nRecently, Large Language Models (LLMs), such as ChatGPT, have demonstrated\nremarkable performance in various NLP tasks. However, their comprehensive\nevaluation and improvement approaches in LEC tasks have not been thoroughly\ninvestigated. In this study, we propose the Annotation Guidelines-based\nKnowledge Augmentation (AGKA) approach to improve LLMs. AGKA employs GPT 4.0 to\nretrieve label definition knowledge from annotation guidelines, and then\napplies the random under-sampler to select a few typical examples.\nSubsequently, we conduct a systematic evaluation benchmark of LEC, which\nincludes six LEC datasets covering behavior classification (question and\nurgency level), emotion classification (binary and epistemic emotion), and\ncognition classification (opinion and cognitive presence). The study results\ndemonstrate that AGKA can enhance non-fine-tuned LLMs, particularly GPT 4.0 and\nLlama 3 70B. GPT 4.0 with AGKA few-shot outperforms full-shot fine-tuned models\nsuch as BERT and RoBERTa on simple binary classification datasets. However, GPT\n4.0 lags in multi-class tasks that require a deep understanding of complex\nsemantic information. Notably, Llama 3 70B with AGKA is a promising combination\nbased on open-source LLM, because its performance is on par with closed-source\nGPT 4.0 with AGKA. In addition, LLMs struggle to distinguish between labels\nwith similar names in multi-class classification.",
      "tldr_zh": "本研究提出了一种基于标注指南的知识增强方法（Annotation Guidelines-based Knowledge Augmentation, AGKA），旨在提升大型语言模型（Large Language Models, LLMs）在教育文本分类任务中的性能，特别是学习参与度分类（LEC）。AGKA 通过利用 GPT 4.0 从标注指南中提取标签定义知识，并结合随机欠采样选择少量典型示例，来增强 LLMs 的知识库。研究在六个 LEC 数据集上进行系统评估，包括行为分类（如问题和紧急级别）、情感分类（如二元和认识情感）以及认知分类（如意见和认知存在）。结果显示，AGKA 显著提高了非微调 LLMs 的表现，例如 GPT 4.0 在二元分类任务上优于全微调的 BERT 和 RoBERTa，但在大语言模型处理多类任务时，仍存在区分相似标签的挑战。总的来说，AGKA 证明了开源模型如 Llama 3 70B 的潜力，其性能可与闭源 GPT 4.0 相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The manuscript has been submitted for peer review to the IEEE\n  Transactions on Learning Technologies",
      "pdf_url": "http://arxiv.org/pdf/2406.00954v1",
      "published_date": "2024-06-03 03:09:01 UTC",
      "updated_date": "2024-06-03 03:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:47:42.165718"
    },
    {
      "arxiv_id": "2406.00944v3",
      "title": "A Theory for Token-Level Harmonization in Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shicheng Xu",
        "Liang Pang",
        "Huawei Shen",
        "Xueqi Cheng"
      ],
      "abstract": "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance\nlarge language models (LLMs). Studies show that while RAG provides valuable\nexternal information (benefit), it may also mislead LLMs (detriment) with noisy\nor incorrect retrieved texts. Although many existing methods attempt to\npreserve benefit and avoid detriment, they lack a theoretical explanation for\nRAG. The benefit and detriment in the next token prediction of RAG remain a\nblack box that cannot be quantified or compared in an explainable manner, so\nexisting methods are data-driven, need additional utility evaluators or\npost-hoc. This paper takes the first step towards providing a theory to explain\nand trade off the benefit and detriment in RAG. First, we model RAG as the\nfusion between distribution of LLMs knowledge and distribution of retrieved\ntexts. Then, we formalize the trade-off between the value of external knowledge\n(benefit) and its potential risk of misleading LLMs (detriment) in next token\nprediction of RAG by distribution difference in this fusion. Finally, we prove\nthat the actual effect of RAG on the token, which is the comparison between\nbenefit and detriment, can be predicted without any training or accessing the\nutility of retrieval. Based on our theory, we propose a practical novel method,\nTok-RAG, which achieves collaborative generation between the pure LLM and RAG\nat token level to preserve benefit and avoid detriment. Experiments in\nreal-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\neffectiveness of our method and support our theoretical findings.",
      "tldr_zh": "本论文提出了一种针对检索增强生成（RAG）的理论框架，用于解释和权衡外部知识带来的益处（benefit）和潜在误导风险（detriment）。该框架将 RAG 建模为大型语言模型（LLMs）知识分布与检索文本分布的融合，并通过分布差异形式化在下一个 token 预测中的权衡关系，从而无需训练或评估即可预测 RAG 的实际效果。基于此理论，作者开发了新方法 Tok-RAG，在 token 级别实现纯 LLM 与 RAG 的协作生成，以保留益处并避免风险。实验在真实任务中使用 OPT、LLaMA-2 和 Mistral 等模型，证明了该方法的有效性，并支持了理论发现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.00944v3",
      "published_date": "2024-06-03 02:56:14 UTC",
      "updated_date": "2025-02-28 03:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:47:52.197900"
    },
    {
      "arxiv_id": "2406.00943v2",
      "title": "State Space Models on Temporal Graphs: A First-Principles Study",
      "title_zh": "翻译失败",
      "authors": [
        "Jintang Li",
        "Ruofan Wu",
        "Xinzhou Jin",
        "Boqun Ma",
        "Liang Chen",
        "Zibin Zheng"
      ],
      "abstract": "Over the past few years, research on deep graph learning has shifted from\nstatic graphs to temporal graphs in response to real-world complex systems that\nexhibit dynamic behaviors. In practice, temporal graphs are formalized as an\nordered sequence of static graph snapshots observed at discrete time points.\nSequence models such as RNNs or Transformers have long been the predominant\nbackbone networks for modeling such temporal graphs. Yet, despite the promising\nresults, RNNs struggle with long-range dependencies, while transformers are\nburdened by quadratic computational complexity. Recently, state space models\n(SSMs), which are framed as discretized representations of an underlying\ncontinuous-time linear dynamical system, have garnered substantial attention\nand achieved breakthrough advancements in independent sequence modeling. In\nthis work, we undertake a principled investigation that extends SSM theory to\ntemporal graphs by integrating structural information into the online\napproximation objective via the adoption of a Laplacian regularization term.\nThe emergent continuous-time system introduces novel algorithmic challenges,\nthereby necessitating our development of GraphSSM, a graph state space model\nfor modeling the dynamics of temporal graphs. Extensive experimental results\ndemonstrate the effectiveness of our GraphSSM framework across various temporal\ngraph benchmarks.",
      "tldr_zh": "该研究探讨了状态空间模型(SSMs)在时间图上的应用，针对传统序列模型如RNN和Transformer在处理时间图动态时的局限性（如RNN的长距离依赖问题和Transformer的计算复杂度）。作者从第一性原理出发，将SSMs扩展到时间图，通过引入Laplacian regularization术语整合结构信息，开发了GraphSSM框架来建模时间图的连续时间系统。实验结果显示，GraphSSM在多个时间图基准上表现出色，证明了其在动态图学习中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00943v2",
      "published_date": "2024-06-03 02:56:11 UTC",
      "updated_date": "2024-10-29 11:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:48:03.681415"
    },
    {
      "arxiv_id": "2406.00083v2",
      "title": "BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models",
      "title_zh": "BadRAG：识别大语言模型检索增强生成中的漏洞",
      "authors": [
        "Jiaqi Xue",
        "Mengxin Zheng",
        "Yebowen Hu",
        "Fei Liu",
        "Xun Chen",
        "Qian Lou"
      ],
      "abstract": "Large Language Models (LLMs) are constrained by outdated information and a\ntendency to generate incorrect data, commonly referred to as \"hallucinations.\"\nRetrieval-Augmented Generation (RAG) addresses these limitations by combining\nthe strengths of retrieval-based methods and generative models. This approach\ninvolves retrieving relevant information from a large, up-to-date dataset and\nusing it to enhance the generation process, leading to more accurate and\ncontextually appropriate responses. Despite its benefits, RAG introduces a new\nattack surface for LLMs, particularly because RAG databases are often sourced\nfrom public data, such as the web. In this paper, we propose \\TrojRAG{} to\nidentify the vulnerabilities and attacks on retrieval parts (RAG database) and\ntheir indirect attacks on generative parts (LLMs). Specifically, we identify\nthat poisoning several customized content passages could achieve a retrieval\nbackdoor, where the retrieval works well for clean queries but always returns\ncustomized poisoned adversarial queries. Triggers and poisoned passages can be\nhighly customized to implement various attacks. For example, a trigger could be\na semantic group like \"The Republican Party, Donald Trump, etc.\" Adversarial\npassages can be tailored to different contents, not only linked to the triggers\nbut also used to indirectly attack generative LLMs without modifying them.\nThese attacks can include denial-of-service attacks on RAG and semantic\nsteering attacks on LLM generations conditioned by the triggers. Our\nexperiments demonstrate that by just poisoning 10 adversarial passages can\ninduce 98.2\\% success rate to retrieve the adversarial passages. Then, these\npassages can increase the reject ratio of RAG-based GPT-4 from 0.01\\% to 74.6\\%\nor increase the rate of negative responses from 0.22\\% to 72\\% for targeted\nqueries.",
      "tldr_zh": "这篇论文探讨了Retrieval-Augmented Generation (RAG)系统中的漏洞，RAG通过检索外部数据集来缓解Large Language Models (LLMs)的幻觉问题，但这也引入了新的攻击面。作者提出TrojRAG方法，识别针对RAG数据库的攻击，例如通过毒化少量内容（如特定触发器\" The Republican Party, Donald Trump, etc.\"）创建检索后门，使系统在正常查询下表现正常，但针对攻击查询返回毒化内容。攻击机制可间接影响LLMs，导致拒绝服务攻击或语义引导攻击。实验结果显示，仅毒化10个段落即可使检索成功率达98.2%，并将RAG-based GPT-4的拒绝率从0.01%提高到74.6%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00083v2",
      "published_date": "2024-06-03 02:25:33 UTC",
      "updated_date": "2024-06-06 13:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:48:19.034644"
    },
    {
      "arxiv_id": "2406.00938v1",
      "title": "A Synergistic Approach In Network Intrusion Detection By Neurosymbolic AI",
      "title_zh": "翻译失败",
      "authors": [
        "Alice Bizzarri",
        "Chung-En Yu",
        "Brian Jalaian",
        "Fabrizio Riguzzi",
        "Nathaniel D. Bastian"
      ],
      "abstract": "The prevailing approaches in Network Intrusion Detection Systems (NIDS) are\noften hampered by issues such as high resource consumption, significant\ncomputational demands, and poor interpretability. Furthermore, these systems\ngenerally struggle to identify novel, rapidly changing cyber threats. This\npaper delves into the potential of incorporating Neurosymbolic Artificial\nIntelligence (NSAI) into NIDS, combining deep learning's data-driven strengths\nwith symbolic AI's logical reasoning to tackle the dynamic challenges in\ncybersecurity, which also includes detailed NSAI techniques introduction for\ncyber professionals to explore the potential strengths of NSAI in NIDS. The\ninclusion of NSAI in NIDS marks potential advancements in both the detection\nand interpretation of intricate network threats, benefiting from the robust\npattern recognition of neural networks and the interpretive prowess of symbolic\nreasoning. By analyzing network traffic data types and machine learning\narchitectures, we illustrate NSAI's distinctive capability to offer more\nprofound insights into network behavior, thereby improving both detection\nperformance and the adaptability of the system. This merging of technologies\nnot only enhances the functionality of traditional NIDS but also sets the stage\nfor future developments in building more resilient, interpretable, and dynamic\ndefense mechanisms against advanced cyber threats. The continued progress in\nthis area is poised to transform NIDS into a system that is both responsive to\nknown threats and anticipatory of emerging, unseen ones.",
      "tldr_zh": "本研究探讨了将 Neurosymbolic AI (NSAI) 整合到 Network Intrusion Detection Systems (NIDS) 中的协同方法，以解决传统系统的高资源消耗、计算需求大、可解释性差以及对新型网络威胁识别不足的问题。NSAI 通过结合深度学习的模式识别能力和符号 AI 的逻辑推理能力，提升了系统对复杂网络行为的检测和解释。实验分析显示，这种融合不仅提高了检测性能和系统适应性，还为构建更具韧性、动态的网络防御机制奠定了基础，使 NIDS 能够更好地应对已知和潜在威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00938v1",
      "published_date": "2024-06-03 02:24:01 UTC",
      "updated_date": "2024-06-03 02:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:48:29.093834"
    },
    {
      "arxiv_id": "2407.01577v1",
      "title": "MOT: A Mixture of Actors Reinforcement Learning Method by Optimal Transport for Algorithmic Trading",
      "title_zh": "MOT：一种通过最优传输的混合代理强化学习方法，用于算法交易",
      "authors": [
        "Xi Cheng",
        "Jinghao Zhang",
        "Yunan Zeng",
        "Wenfang Xue"
      ],
      "abstract": "Algorithmic trading refers to executing buy and sell orders for specific\nassets based on automatically identified trading opportunities. Strategies\nbased on reinforcement learning (RL) have demonstrated remarkable capabilities\nin addressing algorithmic trading problems. However, the trading patterns\ndiffer among market conditions due to shifted distribution data. Ignoring\nmultiple patterns in the data will undermine the performance of RL. In this\npaper, we propose MOT,which designs multiple actors with disentangled\nrepresentation learning to model the different patterns of the market.\nFurthermore, we incorporate the Optimal Transport (OT) algorithm to allocate\nsamples to the appropriate actor by introducing a regularization loss term.\nAdditionally, we propose Pretrain Module to facilitate imitation learning by\naligning the outputs of actors with expert strategy and better balance the\nexploration and exploitation of RL. Experimental results on real futures market\ndata demonstrate that MOT exhibits excellent profit capabilities while\nbalancing risks. Ablation studies validate the effectiveness of the components\nof MOT.",
      "tldr_zh": "该论文针对算法交易中强化学习 (RL) 面临的挑战，即市场条件变化导致数据分布偏移和多种交易模式问题，提出了一种混合 actors 方法 MOT。MOT 通过 disentangled representation learning 设计多个 actors 来建模不同市场模式，并利用 Optimal Transport (OT) 算法引入正则化损失项，以分配样本到合适的 actors；此外，还引入 Pretrain Module 来通过模仿学习对齐 actors 输出与专家策略，从而平衡 RL 的探索和利用。在真实期货市场数据上的实验显示，MOT 表现出优秀的盈利能力并有效管理风险，消融实验进一步验证了其组件的有效性。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.TR",
      "comment": "13 pages, 5 figures, PAKDD2024 accepted",
      "pdf_url": "http://arxiv.org/pdf/2407.01577v1",
      "published_date": "2024-06-03 01:42:52 UTC",
      "updated_date": "2024-06-03 01:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:48:40.951618"
    },
    {
      "arxiv_id": "2406.00922v3",
      "title": "MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive Clinical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyue Stella Li",
        "Vidhisha Balachandran",
        "Shangbin Feng",
        "Jonathan S. Ilgen",
        "Emma Pierson",
        "Pang Wei Koh",
        "Yulia Tsvetkov"
      ],
      "abstract": "Users typically engage with LLMs interactively, yet most existing benchmarks\nevaluate them in a static, single-turn format, posing reliability concerns in\ninteractive scenarios. We identify a key obstacle towards reliability: LLMs are\ntrained to answer any question, even with incomplete context or insufficient\nknowledge. In this paper, we propose to change the static paradigm to an\ninteractive one, develop systems that proactively ask questions to gather more\ninformation and respond reliably, and introduce an benchmark - MediQ - to\nevaluate question-asking ability in LLMs. MediQ simulates clinical interactions\nconsisting of a Patient System and an adaptive Expert System; with potentially\nincomplete initial information, the Expert refrains from making diagnostic\ndecisions when unconfident, and instead elicits missing details via follow-up\nquestions. We provide a pipeline to convert single-turn medical benchmarks into\nan interactive format. Our results show that directly prompting\nstate-of-the-art LLMs to ask questions degrades performance, indicating that\nadapting LLMs to proactive information-seeking settings is nontrivial. We\nexperiment with abstention strategies to better estimate model confidence and\ndecide when to ask questions, improving diagnostic accuracy by 22.3%; however,\nperformance still lags compared to an (unrealistic in practice) upper bound\nwith complete information upfront. Further analyses show improved interactive\nperformance with filtering irrelevant contexts and reformatting conversations.\nOverall, we introduce a novel problem towards LLM reliability, an interactive\nMediQ benchmark and a novel question-asking system, and highlight directions to\nextend LLMs' information-seeking abilities in critical domains.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在交互场景中的可靠性问题，提出一种主动提问系统和MediQ基准，以提升临床推理的准确性。MediQ模拟临床交互，包括Patient System和adaptive Expert System，当信息不完整时，Expert通过后续问题收集细节，而不是仓促诊断；研究还提供了一个管道，将单轮医疗基准转换为交互格式。实验结果显示，直接提示LLMs提问会降低性能，但结合abstention strategies（模型信心估计策略）可提高诊断准确率22.3%；进一步分析表明，过滤无关上下文和优化对话格式能改善效果，为扩展LLMs的信息获取能力提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.00922v3",
      "published_date": "2024-06-03 01:32:52 UTC",
      "updated_date": "2024-11-07 18:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:48:52.578718"
    },
    {
      "arxiv_id": "2406.02608v1",
      "title": "PPINtonus: Early Detection of Parkinson's Disease Using Deep-Learning Tonal Analysis",
      "title_zh": "PPINtonus：利用深度学习音调分析的帕金森病早期检测",
      "authors": [
        "Varun Reddy"
      ],
      "abstract": "PPINtonus is a system for the early detection of Parkinson's Disease (PD)\nutilizing deep-learning tonal analysis, providing a cost-effective and\naccessible alternative to traditional neurological examinations. Partnering\nwith the Parkinson's Voice Project (PVP), PPINtonus employs a semi-supervised\nconditional generative adversarial network to generate synthetic data points,\nenhancing the training dataset for a multi-layered deep neural network.\nCombined with PRAAT phonetics software, this network accurately assesses\nbiomedical voice measurement values from a simple 120-second vocal test\nperformed with a standard microphone in typical household noise conditions. The\nmodel's performance was validated using a confusion matrix, achieving an\nimpressive 92.5 \\% accuracy with a low false negative rate. PPINtonus\ndemonstrated a precision of 92.7 \\%, making it a reliable tool for early PD\ndetection. The non-intrusive and efficient methodology of PPINtonus can\nsignificantly benefit developing countries by enabling early diagnosis and\nimproving the quality of life for millions of PD patients through timely\nintervention and management.",
      "tldr_zh": "本研究引入了 PPINtonus 系统，利用 deep-learning tonal analysis 实现帕金森病（PD）的早期检测，提供一种经济实惠且易于获取的替代传统神经检查的方法。系统通过与 Parkinson's Voice Project 合作，使用 semi-supervised conditional generative adversarial network 生成合成数据，以增强 multi-layered deep neural network 的训练，并结合 PRAAT 软件分析从标准麦克风采集的 120 秒语音测试数据。结果显示，该模型在混淆矩阵验证中达到 92.5% accuracy 和 92.7% precision，并具有低假阴性率，从而为发展中国家提供非侵入式早期诊断工具，提升 PD 患者的及时干预和生活质量。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02608v1",
      "published_date": "2024-06-03 01:07:42 UTC",
      "updated_date": "2024-06-03 01:07:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:49:05.176060"
    },
    {
      "arxiv_id": "2406.00914v1",
      "title": "Wasserstein gradient flow for optimal probability measure decomposition",
      "title_zh": "Wasserstein 梯度流用于最优概率测度分解",
      "authors": [
        "Jiangze Han",
        "Christopher Thomas Ryan",
        "Xin T. Tong"
      ],
      "abstract": "We examine the infinite-dimensional optimization problem of finding a\ndecomposition of a probability measure into K probability sub-measures to\nminimize specific loss functions inspired by applications in clustering and\nuser grouping. We analytically explore the structures of the support of optimal\nsub-measures and introduce algorithms based on Wasserstein gradient flow,\ndemonstrating their convergence. Numerical results illustrate the\nimplementability of our algorithms and provide further insights.",
      "tldr_zh": "该论文研究了将一个概率测度分解成 K 个子概率测度，以最小化受聚类和用户分组启发的特定损失函数的无限维优化问题。作者分析了最优子测度支持的结构，并引入了基于 Wasserstein gradient flow 的算法，证明了这些算法的收敛性。数值实验展示了算法的可实现性，并提供了进一步的洞见。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00914v1",
      "published_date": "2024-06-03 00:47:32 UTC",
      "updated_date": "2024-06-03 00:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:49:15.114762"
    },
    {
      "arxiv_id": "2406.01638v5",
      "title": "TimeCMA: Towards LLM-Empowered Multivariate Time Series Forecasting via Cross-Modality Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxi Liu",
        "Qianxiong Xu",
        "Hao Miao",
        "Sun Yang",
        "Lingzheng Zhang",
        "Cheng Long",
        "Ziyue Li",
        "Rui Zhao"
      ],
      "abstract": "Multivariate time series forecasting (MTSF) aims to learn temporal dynamics\namong variables to forecast future time series. Existing statistical and deep\nlearning-based methods suffer from limited learnable parameters and small-scale\ntraining data. Recently, large language models (LLMs) combining time series\nwith textual prompts have achieved promising performance in MTSF. However, we\ndiscovered that current LLM-based solutions fall short in learning disentangled\nembeddings. We introduce TimeCMA, an intuitive yet effective framework for MTSF\nvia cross-modality alignment. Specifically, we present a dual-modality encoding\nwith two branches: the time series encoding branch extracts disentangled yet\nweak time series embeddings, and the LLM-empowered encoding branch wraps the\nsame time series with text as prompts to obtain entangled yet robust prompt\nembeddings. As a result, such a cross-modality alignment retrieves both\ndisentangled and robust time series embeddings, \"the best of two worlds\", from\nthe prompt embeddings based on time series and prompt modality similarities. As\nanother key design, to reduce the computational costs from time series with\ntheir length textual prompts, we design an effective prompt to encourage the\nmost essential temporal information to be encapsulated in the last token: only\nthe last token is passed to downstream prediction. We further store the last\ntoken embeddings to accelerate inference speed. Extensive experiments on eight\nreal datasets demonstrate that TimeCMA outperforms state-of-the-arts.",
      "tldr_zh": "本研究针对多变量时间序列预测 (Multivariate Time Series Forecasting, MTSF) 的局限性，提出 TimeCMA 框架，利用大型语言模型 (LLMs) 通过跨模态对齐来提升预测性能。具体而言，框架采用双模态编码，包括时间序列编码分支提取解耦嵌入，以及 LLM 增强分支生成鲁棒提示嵌入，从而从提示嵌入中获取最佳的解耦和鲁棒时间序列表示；同时，通过优化提示设计仅使用最后一个 token 并存储嵌入，以减少计算成本。实验在八个真实数据集上表明，TimeCMA 优于现有最先进方法，显著提高了预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as an Oral Presentation at AAAI 2025 (Main Technical Track)",
      "pdf_url": "http://arxiv.org/pdf/2406.01638v5",
      "published_date": "2024-06-03 00:27:29 UTC",
      "updated_date": "2025-03-29 08:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T15:49:28.783198"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 160,
  "processed_papers_count": 160,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T15:49:55.938773"
}