[
  {
    "arxiv_id": "2404.05908v1",
    "title": "Interpretability in Symbolic Regression: a benchmark of Explanatory Methods using the Feynman data set",
    "authors": [
      "Guilherme Seidyo Imai Aldeia",
      "Fabricio Olivetti de Franca"
    ],
    "abstract": "In some situations, the interpretability of the machine learning models plays\na role as important as the model accuracy. Interpretability comes from the need\nto trust the prediction model, verify some of its properties, or even enforce\nthem to improve fairness. Many model-agnostic explanatory methods exists to\nprovide explanations for black-box models. In the regression task, the\npractitioner can use white-boxes or gray-boxes models to achieve more\ninterpretable results, which is the case of symbolic regression. When using an\nexplanatory method, and since interpretability lacks a rigorous definition,\nthere is a need to evaluate and compare the quality and different explainers.\nThis paper proposes a benchmark scheme to evaluate explanatory methods to\nexplain regression models, mainly symbolic regression models. Experiments were\nperformed using 100 physics equations with different interpretable and\nnon-interpretable regression methods and popular explanation methods,\nevaluating the performance of the explainers performance with several\nexplanation measures. In addition, we further analyzed four benchmarks from the\nGP community. The results have shown that Symbolic Regression models can be an\ninteresting alternative to white-box and black-box models that is capable of\nreturning accurate models with appropriate explanations. Regarding the\nexplainers, we observed that Partial Effects and SHAP were the most robust\nexplanation models, with Integrated Gradients being unstable only with\ntree-based models. This benchmark is publicly available for further\nexperiments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages, 10 figures. This is a post peer-review, pre-copyedit\n  version of an article published in Genetic Programming and Evolvable Machines\n  Volume 23, pages 309-349, (2022). The final version is available on\n  https://link.springer.com/article/10.1007/s10710-022-09435-x",
    "pdf_url": "http://arxiv.org/pdf/2404.05908v1",
    "published_date": "2024-04-08 23:46:59 UTC",
    "updated_date": "2024-04-08 23:46:59 UTC"
  },
  {
    "arxiv_id": "2404.05903v1",
    "title": "Natural Learning",
    "authors": [
      "Hadi Fanaee-T"
    ],
    "abstract": "We introduce Natural Learning (NL), a novel algorithm that elevates the\nexplainability and interpretability of machine learning to an extreme level. NL\nsimplifies decisions into intuitive rules, like \"We rejected your loan because\nyour income, employment status, and age collectively resemble a rejected\nprototype more than an accepted prototype.\" When applied to real-life datasets,\nNL produces impressive results. For example, in a colon cancer dataset with\n1545 patients and 10935 genes, NL achieves 98.1% accuracy, comparable to DNNs\nand RF, by analyzing just 3 genes of test samples against 2 discovered\nprototypes. Similarly, in the UCI's WDBC dataset, NL achieves 98.3% accuracy\nusing only 7 features and 2 prototypes. Even on the MNIST dataset (0 vs. 1), NL\nachieves 99.5% accuracy with only 3 pixels from 2 prototype images. NL is\ninspired by prototype theory, an old concept in cognitive psychology suggesting\nthat people learn single sparse prototypes to categorize objects. Leveraging\nthis relaxed assumption, we redesign Support Vector Machines (SVM), replacing\nits mathematical formulation with a fully nearest-neighbor-based solution, and\nto address the curse of dimensionality, we utilize locality-sensitive hashing.\nFollowing theory's generalizability principle, we propose a recursive method to\nprune non-core features. As a result, NL efficiently discovers the sparsest\nprototypes in O(n^2pL) with high parallelization capacity in terms of n.\nEvaluation of NL with 17 benchmark datasets shows its significant\noutperformance compared to decision trees and logistic regression, two methods\nwidely favored in healthcare for their interpretability. Moreover, NL achieves\nperformance comparable to finetuned black-box models such as deep neural\nnetworks and random forests in 40% of cases, with only a 1-2% lower average\naccuracy. The code is available via http://natural-learning.cc.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.05903v1",
    "published_date": "2024-04-08 23:15:41 UTC",
    "updated_date": "2024-04-08 23:15:41 UTC"
  },
  {
    "arxiv_id": "2404.05902v1",
    "title": "WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents",
    "authors": [
      "Michael Lutz",
      "Arth Bohra",
      "Manvel Saroyan",
      "Artem Harutyunyan",
      "Giovanni Campagna"
    ],
    "abstract": "In the realm of web agent research, achieving both generalization and\naccuracy remains a challenging problem. Due to high variance in website\nstructure, existing approaches often fail. Moreover, existing fine-tuning and\nin-context learning techniques fail to generalize across multiple websites. We\nintroduce Wilbur, an approach that uses a differentiable ranking model and a\nnovel instruction synthesis technique to optimally populate a black-box large\nlanguage model's prompt with task demonstrations from previous runs. To\nmaximize end-to-end success rates, we also propose an intelligent backtracking\nmechanism that learns and recovers from its mistakes. Finally, we show that our\nranking model can be trained on data from a generative auto-curriculum which\nsamples representative goals from an LLM, runs the agent, and automatically\nevaluates it, with no manual annotation. Wilbur achieves state-of-the-art\nresults on the WebVoyager benchmark, beating text-only models by 8% overall,\nand up to 36% on certain websites. On the same benchmark, Wilbur is within 5%\nof a strong multi-modal model despite only receiving textual inputs, and\nfurther analysis reveals a substantial number of failures are due to\nengineering challenges of operating the web.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05902v1",
    "published_date": "2024-04-08 23:10:47 UTC",
    "updated_date": "2024-04-08 23:10:47 UTC"
  },
  {
    "arxiv_id": "2404.05894v4",
    "title": "Learning Heuristics for Transit Network Design and Improvement with Deep Reinforcement Learning",
    "authors": [
      "Andrew Holliday",
      "Ahmed El-Geneidy",
      "Gregory Dudek"
    ],
    "abstract": "Transit agencies world-wide face tightening budgets and declining ridership.\nTo maintain quality of service while cutting costs, efficient transit network\ndesign is essential. But planning a network of public transit routes is a\nchallenging optimization problem. The most successful approaches to date use\nmetaheuristic algorithms to search through the space of possible transit\nnetworks by applying low-level heuristics that randomly alter routes in a\nnetwork. The design of these low-level heuristics has a major impact on the\nquality of the result. In this paper we use deep reinforcement learning with\ngraph neural nets to learn low-level heuristics for an evolutionary algorithm,\ninstead of designing them manually. These learned heuristics improve the\nalgorithm's results on benchmark synthetic cities with 70 nodes or more, and\nachieve new state-of-the-art results the challenging Mumford benchmark. They\nalso improve upon a simulation of the real transit network in the city of\nLaval, Canada, by as much as 52% and 25% on two key metrics, and offer cost\nsavings of up to 19% over the city's existing transit network.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "In preparation for submission to a journal",
    "pdf_url": "http://arxiv.org/pdf/2404.05894v4",
    "published_date": "2024-04-08 22:40:57 UTC",
    "updated_date": "2025-02-22 15:55:18 UTC"
  },
  {
    "arxiv_id": "2404.05893v5",
    "title": "Use of a Structured Knowledge Base Enhances Metadata Curation by Large Language Models",
    "authors": [
      "Sowmya S. Sundaram",
      "Benjamin Solomon",
      "Avani Khatri",
      "Anisha Laumas",
      "Purvesh Khatri",
      "Mark A. Musen"
    ],
    "abstract": "Metadata play a crucial role in ensuring the findability, accessibility,\ninteroperability, and reusability of datasets. This paper investigates the\npotential of large language models (LLMs), specifically GPT-4, to improve\nadherence to metadata standards. We conducted experiments on 200 random data\nrecords describing human samples relating to lung cancer from the NCBI\nBioSample repository, evaluating GPT-4's ability to suggest edits for adherence\nto metadata standards. We computed the adherence accuracy of field name-field\nvalue pairs through a peer review process, and we observed a marginal average\nimprovement in adherence to the standard data dictionary from 79% to 80%\n(p<0.5). We then prompted GPT-4 with domain information in the form of the\ntextual descriptions of CEDAR templates and recorded a significant improvement\nto 97% from 79% (p<0.01). These results indicate that, while LLMs may not be\nable to correct legacy metadata to ensure satisfactory adherence to standards\nwhen unaided, they do show promise for use in automated metadata curation when\nintegrated with a structured knowledge base",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05893v5",
    "published_date": "2024-04-08 22:29:53 UTC",
    "updated_date": "2025-02-20 21:57:27 UTC"
  },
  {
    "arxiv_id": "2404.05892v4",
    "title": "Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence",
    "authors": [
      "Bo Peng",
      "Daniel Goldstein",
      "Quentin Anthony",
      "Alon Albalak",
      "Eric Alcaide",
      "Stella Biderman",
      "Eugene Cheah",
      "Xingjian Du",
      "Teddy Ferdinan",
      "Haowen Hou",
      "Przemysław Kazienko",
      "Kranthi Kiran GV",
      "Jan Kocoń",
      "Bartłomiej Koptyra",
      "Satyapriya Krishna",
      "Ronald McClelland Jr.",
      "Jiaju Lin",
      "Niklas Muennighoff",
      "Fares Obeid",
      "Atsushi Saito",
      "Guangyu Song",
      "Haoqin Tu",
      "Cahya Wirawan",
      "Stanisław Woźniak",
      "Ruichong Zhang",
      "Bingchen Zhao",
      "Qihang Zhao",
      "Peng Zhou",
      "Jian Zhu",
      "Rui-Jie Zhu"
    ],
    "abstract": "We present Eagle (RWKV-5) and Finch (RWKV-6), sequence models improving upon\nthe RWKV (RWKV-4) architecture. Our architectural design advancements include\nmulti-headed matrix-valued states and a dynamic recurrence mechanism that\nimprove expressivity while maintaining the inference efficiency characteristics\nof RNNs. We introduce a new multilingual corpus with 1.12 trillion tokens and a\nfast tokenizer based on greedy matching for enhanced multilinguality. We\ntrained four Eagle models, ranging from 0.46 to 7.5 billion parameters, and two\nFinch models with 1.6 and 3.1 billion parameters and find that they achieve\ncompetitive performance across a wide variety of benchmarks. We release all our\nmodels on HuggingFace under the Apache 2.0 license. Models at:\nhttps://huggingface.co/RWKV Training code at: https://github.com/RWKV/RWKV-LM\nInference code at: https://github.com/RWKV/ChatRWKV Time-parallel training code\nat: https://github.com/RWKV/RWKV-infctx-trainer",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05892v4",
    "published_date": "2024-04-08 22:20:59 UTC",
    "updated_date": "2024-09-26 22:39:08 UTC"
  },
  {
    "arxiv_id": "2404.05891v2",
    "title": "Condition Monitoring with Incomplete Data: An Integrated Variational Autoencoder and Distance Metric Framework",
    "authors": [
      "Maryam Ahang",
      "Mostafa Abbasi",
      "Todd Charter",
      "Homayoun Najjaran"
    ],
    "abstract": "Condition monitoring of industrial systems is crucial for ensuring safety and\nmaintenance planning, yet notable challenges arise in real-world settings due\nto the limited or non-existent availability of fault samples. This paper\nintroduces an innovative solution to this problem by proposing a new method for\nfault detection and condition monitoring for unseen data. Adopting an approach\ninspired by zero-shot learning, our method can identify faults and assign a\nrelative health index to various operational conditions. Typically, we have\nplenty of data on normal operations, some data on compromised conditions, and\nvery few (if any) samples of severe faults. We use a variational autoencoder to\ncapture the probabilistic distribution of previously seen and new unseen\nconditions. The health status is determined by comparing each sample's\ndeviation from a normal operation reference distribution in the latent space.\nFaults are detected by establishing a threshold for the health indexes,\nallowing the model to identify severe, unseen faults with high accuracy, even\namidst noise. We validate our approach using the run-to-failure IMS-bearing\ndataset and compare it with other methods. The health indexes generated by our\nmodel closely match the established descriptive model of bearing wear,\nattesting to the robustness and reliability of our method. These findings\nhighlight the potential of our methodology in augmenting fault detection\ncapabilities within industrial domains, thereby contributing to heightened\nsafety protocols and optimized maintenance practices.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted in the 2024 IEEE 20th International Conference on Automation\n  Science and Engineering (CASE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.05891v2",
    "published_date": "2024-04-08 22:20:23 UTC",
    "updated_date": "2024-06-27 21:54:40 UTC"
  },
  {
    "arxiv_id": "2404.05875v1",
    "title": "CodecLM: Aligning Language Models with Tailored Synthetic Data",
    "authors": [
      "Zifeng Wang",
      "Chun-Liang Li",
      "Vincent Perot",
      "Long T. Le",
      "Jin Miao",
      "Zizhao Zhang",
      "Chen-Yu Lee",
      "Tomas Pfister"
    ],
    "abstract": "Instruction tuning has emerged as the key in aligning large language models\n(LLMs) with specific task instructions, thereby mitigating the discrepancy\nbetween the next-token prediction objective and users' actual goals. To reduce\nthe labor and time cost to collect or annotate data by humans, researchers\nstart to explore the use of LLMs to generate instruction-aligned synthetic\ndata. Recent works focus on generating diverse instructions and applying LLM to\nincrease instruction complexity, often neglecting downstream use cases. It\nremains unclear how to tailor high-quality data to elicit better\ninstruction-following abilities in different target instruction distributions\nand LLMs. To this end, we introduce CodecLM, a general framework for adaptively\ngenerating high-quality synthetic data for LLM alignment with different\ndownstream instruction distributions and LLMs. Drawing on the Encode-Decode\nprinciples, we use LLMs as codecs to guide the data generation process. We\nfirst encode seed instructions into metadata, which are concise keywords\ngenerated on-the-fly to capture the target instruction distribution, and then\ndecode metadata to create tailored instructions. We also introduce Self-Rubrics\nand Contrastive Filtering during decoding to tailor data-efficient samples.\nExtensive experiments on four open-domain instruction following benchmarks\nvalidate the effectiveness of CodecLM over the current state-of-the-arts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05875v1",
    "published_date": "2024-04-08 21:15:36 UTC",
    "updated_date": "2024-04-08 21:15:36 UTC"
  },
  {
    "arxiv_id": "2404.05868v2",
    "title": "Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning",
    "authors": [
      "Ruiqi Zhang",
      "Licong Lin",
      "Yu Bai",
      "Song Mei"
    ],
    "abstract": "Large Language Models (LLMs) often memorize sensitive, private, or\ncopyrighted data during pre-training. LLM unlearning aims to eliminate the\ninfluence of undesirable data from the pre-trained model while preserving the\nmodel's utilities on other tasks. Several practical methods have recently been\nproposed for LLM unlearning, mostly based on gradient ascent (GA) on the loss\nof undesirable data. However, on certain unlearning tasks, these methods either\nfail to effectively unlearn the target data or suffer from catastrophic\ncollapse -- a drastic degradation of the model's utilities.\n  In this paper, we propose Negative Preference Optimization (NPO), a simple\nalignment-inspired method that could efficiently and effectively unlearn a\ntarget dataset. We theoretically show that the progression toward catastrophic\ncollapse by minimizing the NPO loss is exponentially slower than GA. Through\nexperiments on synthetic data and the benchmark TOFU dataset, we demonstrate\nthat NPO-based methods achieve a better balance between unlearning the\nundesirable data and maintaining the model's utilities. We also observe that\nNPO-based methods generate more sensible outputs than GA-based methods, whose\noutputs are often gibberish. Remarkably, on TOFU, NPO-based methods are the\nfirst to achieve reasonable unlearning results in forgetting 50% (or more) of\nthe training data, whereas existing methods already struggle with forgetting\n10% of training data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05868v2",
    "published_date": "2024-04-08 21:05:42 UTC",
    "updated_date": "2024-10-10 22:00:41 UTC"
  },
  {
    "arxiv_id": "2404.05840v3",
    "title": "Attention-Driven Multi-Agent Reinforcement Learning: Enhancing Decisions with Expertise-Informed Tasks",
    "authors": [
      "Andre R Kuroswiski",
      "Annie S Wu",
      "Angelo Passaro"
    ],
    "abstract": "In this paper, we introduce an alternative approach to enhancing Multi-Agent\nReinforcement Learning (MARL) through the integration of domain knowledge and\nattention-based policy mechanisms. Our methodology focuses on the incorporation\nof domain-specific expertise into the learning process, which simplifies the\ndevelopment of collaborative behaviors. This approach aims to reduce the\ncomplexity and learning overhead typically associated with MARL by enabling\nagents to concentrate on essential aspects of complex tasks, thus optimizing\nthe learning curve. The utilization of attention mechanisms plays a key role in\nour model. It allows for the effective processing of dynamic context data and\nnuanced agent interactions, leading to more refined decision-making. Applied in\nstandard MARL scenarios, such as the Stanford Intelligent Systems Laboratory\n(SISL) Pursuit and Multi-Particle Environments (MPE) Simple Spread, our method\nhas been shown to improve both learning efficiency and the effectiveness of\ncollaborative behaviors. The results indicate that our attention-based approach\ncan be a viable approach for improving the efficiency of MARL training process,\nintegrating domain-specific knowledge at the action level.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper was published at Proceedings of FLAIRS-37, May 19-21,\n  Sandestin Beach, FL. The proceedings version is available at\n  https://journals.flvc.org/FLAIRS/issue/view/6284",
    "pdf_url": "http://arxiv.org/pdf/2404.05840v3",
    "published_date": "2024-04-08 20:06:33 UTC",
    "updated_date": "2024-05-17 16:01:54 UTC"
  },
  {
    "arxiv_id": "2404.05829v2",
    "title": "SambaLingo: Teaching Large Language Models New Languages",
    "authors": [
      "Zoltan Csaki",
      "Bo Li",
      "Jonathan Li",
      "Qiantong Xu",
      "Pian Pawakapan",
      "Leon Zhang",
      "Yun Du",
      "Hengyu Zhao",
      "Changran Hu",
      "Urmish Thakker"
    ],
    "abstract": "Despite the widespread availability of LLMs, there remains a substantial gap\nin their capabilities and availability across diverse languages. One approach\nto address these issues has been to take an existing pre-trained LLM and\ncontinue to train it on new languages. While prior works have experimented with\nlanguage adaptation, many questions around best practices and methodology have\nnot been covered. In this paper, we present a comprehensive investigation into\nthe adaptation of LLMs to new languages. Our study covers the key components in\nthis process, including vocabulary extension, direct preference optimization\nand the data scarcity problem for human alignment in low-resource languages. We\nscale these experiments across 9 languages and 2 parameter scales (7B and 70B).\nWe compare our models against Llama 2, Aya-101, XGLM, BLOOM and existing\nlanguage experts, outperforming all prior published baselines. Additionally,\nall evaluation code and checkpoints are made public to facilitate future\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.05829v2",
    "published_date": "2024-04-08 19:48:36 UTC",
    "updated_date": "2024-07-17 20:30:56 UTC"
  },
  {
    "arxiv_id": "2404.05825v1",
    "title": "LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding",
    "authors": [
      "Mingrui Wu",
      "Sheng Cao"
    ],
    "abstract": "Recently embedding-based retrieval or dense retrieval have shown state of the\nart results, compared with traditional sparse or bag-of-words based approaches.\nThis paper introduces a model-agnostic doc-level embedding framework through\nlarge language model (LLM) augmentation. In addition, it also improves some\nimportant components in the retrieval model training process, such as negative\nsampling, loss function, etc. By implementing this LLM-augmented retrieval\nframework, we have been able to significantly improve the effectiveness of\nwidely-used retriever models such as Bi-encoders (Contriever, DRAGON) and\nlate-interaction models (ColBERTv2), thereby achieving state-of-the-art results\non LoTTE datasets and BEIR datasets.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05825v1",
    "published_date": "2024-04-08 19:29:07 UTC",
    "updated_date": "2024-04-08 19:29:07 UTC"
  },
  {
    "arxiv_id": "2404.05809v1",
    "title": "Self-Labeling in Multivariate Causality and Quantification for Adaptive Machine Learning",
    "authors": [
      "Yutian Ren",
      "Aaron Haohua Yen",
      "G. P. Li"
    ],
    "abstract": "Adaptive machine learning (ML) aims to allow ML models to adapt to\never-changing environments with potential concept drift after model deployment.\nTraditionally, adaptive ML requires a new dataset to be manually labeled to\ntailor deployed models to altered data distributions. Recently, an interactive\ncausality based self-labeling method was proposed to autonomously associate\ncausally related data streams for domain adaptation, showing promising results\ncompared to traditional feature similarity-based semi-supervised learning.\nSeveral unanswered research questions remain, including self-labeling's\ncompatibility with multivariate causality and the quantitative analysis of the\nauxiliary models used in the self-labeling. The auxiliary models, the\ninteraction time model (ITM) and the effect state detector (ESD), are vital to\nthe success of self-labeling. This paper further develops the self-labeling\nframework and its theoretical foundations to address these research questions.\nA framework for the application of self-labeling to multivariate causal graphs\nis proposed using four basic causal relationships, and the impact of non-ideal\nITM and ESD performance is analyzed. A simulated experiment is conducted based\non a multivariate causal graph, validating the proposed theory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05809v1",
    "published_date": "2024-04-08 18:16:22 UTC",
    "updated_date": "2024-04-08 18:16:22 UTC"
  },
  {
    "arxiv_id": "2404.05720v1",
    "title": "Language-Independent Representations Improve Zero-Shot Summarization",
    "authors": [
      "Vladimir Solovyev",
      "Danni Liu",
      "Jan Niehues"
    ],
    "abstract": "Finetuning pretrained models on downstream generation tasks often leads to\ncatastrophic forgetting in zero-shot conditions. In this work, we focus on\nsummarization and tackle the problem through the lens of language-independent\nrepresentations. After training on monolingual summarization, we perform\nzero-shot transfer to new languages or language pairs. We first show naively\nfinetuned models are highly language-specific in both output behavior and\ninternal representations, resulting in poor zero-shot performance. Next, we\npropose query-key (QK) finetuning to decouple task-specific knowledge from the\npretrained language generation abilities. Then, after showing downsides of the\nstandard adversarial language classifier, we propose a balanced variant that\nmore directly enforces language-agnostic representations. Moreover, our\nqualitative analyses show removing source language identity correlates to\nzero-shot summarization performance. Our code is openly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05720v1",
    "published_date": "2024-04-08 17:56:43 UTC",
    "updated_date": "2024-04-08 17:56:43 UTC"
  },
  {
    "arxiv_id": "2404.05783v2",
    "title": "A Survey on Responsible Generative AI: What to Generate and What Not",
    "authors": [
      "Jindong Gu"
    ],
    "abstract": "In recent years, generative AI (GenAI), like large language models and\ntext-to-image models, has received significant attention across various\ndomains. However, ensuring the responsible generation of content by these\nmodels is crucial for their real-world applicability. This raises an\ninteresting question: What should responsible GenAI generate, and what should\nit not? To answer the question, this paper investigates the practical\nresponsible requirements of both textual and visual generative models,\noutlining five key considerations: generating truthful content, avoiding toxic\ncontent, refusing harmful instruction, leaking no training data-related\ncontent, and ensuring generated content identifiable. Specifically, we review\nrecent advancements and challenges in addressing these requirements. Besides,\nwe discuss and emphasize the importance of responsible GenAI across healthcare,\neducation, finance, and artificial general intelligence domains. Through a\nunified perspective on both textual and visual generative models, this paper\naims to provide insights into practical safety-related issues and further\nbenefit the community in building responsible GenAI.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CY",
    "comment": "77 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.05783v2",
    "published_date": "2024-04-08 17:53:21 UTC",
    "updated_date": "2024-09-03 16:23:55 UTC"
  },
  {
    "arxiv_id": "2404.05717v3",
    "title": "SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing",
    "authors": [
      "Jing Gu",
      "Nanxuan Zhao",
      "Wei Xiong",
      "Qing Liu",
      "Zhifei Zhang",
      "He Zhang",
      "Jianming Zhang",
      "HyunJoon Jung",
      "Yilin Wang",
      "Xin Eric Wang"
    ],
    "abstract": "Effective editing of personal content holds a pivotal role in enabling\nindividuals to express their creativity, weaving captivating narratives within\ntheir visual stories, and elevate the overall quality and impact of their\nvisual content. Therefore, in this work, we introduce SwapAnything, a novel\nframework that can swap any objects in an image with personalized concepts\ngiven by the reference, while keeping the context unchanged. Compared with\nexisting methods for personalized subject swapping, SwapAnything has three\nunique advantages: (1) precise control of arbitrary objects and parts rather\nthan the main subject, (2) more faithful preservation of context pixels, (3)\nbetter adaptation of the personalized concept to the image. First, we propose\ntargeted variable swapping to apply region control over latent feature maps and\nswap masked variables for faithful context preservation and initial semantic\nconcept swapping. Then, we introduce appearance adaptation, to seamlessly adapt\nthe semantic concept into the original image in terms of target location,\nshape, style, and content during the image generation process. Extensive\nresults on both human and automatic evaluation demonstrate significant\nimprovements of our approach over baseline methods on personalized swapping.\nFurthermore, SwapAnything shows its precise and faithful swapping abilities\nacross single object, multiple objects, partial object, and cross-domain\nswapping tasks. SwapAnything also achieves great performance on text-based\nswapping and tasks beyond swapping such as object insertion.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024, 23 pages, 14 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.05717v3",
    "published_date": "2024-04-08 17:52:29 UTC",
    "updated_date": "2024-10-03 17:56:42 UTC"
  },
  {
    "arxiv_id": "2404.05695v2",
    "title": "Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer",
    "authors": [
      "Xinyang Gu",
      "Yen-Jen Wang",
      "Jianyu Chen"
    ],
    "abstract": "Humanoid-Gym is an easy-to-use reinforcement learning (RL) framework based on\nNvidia Isaac Gym, designed to train locomotion skills for humanoid robots,\nemphasizing zero-shot transfer from simulation to the real-world environment.\nHumanoid-Gym also integrates a sim-to-sim framework from Isaac Gym to Mujoco\nthat allows users to verify the trained policies in different physical\nsimulations to ensure the robustness and generalization of the policies. This\nframework is verified by RobotEra's XBot-S (1.2-meter tall humanoid robot) and\nXBot-L (1.65-meter tall humanoid robot) in a real-world environment with\nzero-shot sim-to-real transfer. The project website and source code can be\nfound at: https://sites.google.com/view/humanoid-gym/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05695v2",
    "published_date": "2024-04-08 17:26:28 UTC",
    "updated_date": "2024-05-18 10:00:30 UTC"
  },
  {
    "arxiv_id": "2404.05694v2",
    "title": "Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding",
    "authors": [
      "Ahmad Idrissi-Yaghir",
      "Amin Dada",
      "Henning Schäfer",
      "Kamyar Arzideh",
      "Giulia Baldini",
      "Jan Trienes",
      "Max Hasin",
      "Jeanette Bewersdorff",
      "Cynthia S. Schmidt",
      "Marie Bauer",
      "Kaleb E. Smith",
      "Jiang Bian",
      "Yonghui Wu",
      "Jörg Schlötterer",
      "Torsten Zesch",
      "Peter A. Horn",
      "Christin Seifert",
      "Felix Nensa",
      "Jens Kleesiek",
      "Christoph M. Friedrich"
    ],
    "abstract": "Recent advances in natural language processing (NLP) can be largely\nattributed to the advent of pre-trained language models such as BERT and\nRoBERTa. While these models demonstrate remarkable performance on general\ndatasets, they can struggle in specialized domains such as medicine, where\nunique domain-specific terminologies, domain-specific abbreviations, and\nvarying document structures are common. This paper explores strategies for\nadapting these models to domain-specific requirements, primarily through\ncontinuous pre-training on domain-specific data. We pre-trained several German\nmedical language models on 2.4B tokens derived from translated public English\nmedical data and 3B tokens of German clinical data. The resulting models were\nevaluated on various German downstream tasks, including named entity\nrecognition (NER), multi-label classification, and extractive question\nanswering. Our results suggest that models augmented by clinical and\ntranslation-based pre-training typically outperform general domain models in\nmedical contexts. We conclude that continuous pre-training has demonstrated the\nability to match or even exceed the performance of clinical models trained from\nscratch. Furthermore, pre-training on clinical data or leveraging translated\ntexts have proven to be reliable methods for domain adaptation in medical NLP\ntasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05694v2",
    "published_date": "2024-04-08 17:24:04 UTC",
    "updated_date": "2024-05-08 08:53:53 UTC"
  },
  {
    "arxiv_id": "2404.05689v2",
    "title": "Automated discovery of symbolic laws governing skill acquisition from naturally occurring data",
    "authors": [
      "Sannyuya Liu",
      "Qing Li",
      "Xiaoxuan Shen",
      "Jianwen Sun",
      "Zongkai Yang"
    ],
    "abstract": "Skill acquisition is a key area of research in cognitive psychology as it\nencompasses multiple psychological processes. The laws discovered under\nexperimental paradigms are controversial and lack generalizability. This paper\naims to unearth the laws of skill learning from large-scale training log data.\nA two-stage algorithm was developed to tackle the issues of unobservable\ncognitive states and algorithmic explosion in searching. Initially a deep\nlearning model is employed to determine the learner's cognitive state and\nassess the feature importance. Subsequently, symbolic regression algorithms are\nutilized to parse the neural network model into algebraic equations.\nExperimental results show the algorithm can accurately restore preset laws\nwithin a noise range in continuous feedback settings. When applied to Lumosity\ntraining data, the method outperforms traditional and recent models in fitness\nterms. The study reveals two new forms of skill acquisition laws and reaffirms\nsome previous findings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05689v2",
    "published_date": "2024-04-08 17:15:37 UTC",
    "updated_date": "2024-05-27 06:48:09 UTC"
  },
  {
    "arxiv_id": "2404.05688v2",
    "title": "David and Goliath: An Empirical Evaluation of Attacks and Defenses for QNNs at the Deep Edge",
    "authors": [
      "Miguel Costa",
      "Sandro Pinto"
    ],
    "abstract": "ML is shifting from the cloud to the edge. Edge computing reduces the surface\nexposing private data and enables reliable throughput guarantees in real-time\napplications. Of the panoply of devices deployed at the edge,\nresource-constrained MCUs, e.g., Arm Cortex-M, are more prevalent, orders of\nmagnitude cheaper, and less power-hungry than application processors or GPUs.\nThus, enabling intelligence at the deep edge is the zeitgeist, with researchers\nfocusing on unveiling novel approaches to deploy ANNs on these constrained\ndevices. Quantization is a well-established technique that has proved effective\nin enabling the deployment of neural networks on MCUs; however, it is still an\nopen question to understand the robustness of QNNs in the face of adversarial\nexamples.\n  To fill this gap, we empirically evaluate the effectiveness of attacks and\ndefenses from (full-precision) ANNs on (constrained) QNNs. Our evaluation\nincludes three QNNs targeting TinyML applications, ten attacks, and six\ndefenses. With this study, we draw a set of interesting findings. First,\nquantization increases the point distance to the decision boundary and leads\nthe gradient estimated by some attacks to explode or vanish. Second,\nquantization can act as a noise attenuator or amplifier, depending on the noise\nmagnitude, and causes gradient misalignment. Regarding adversarial defenses, we\nconclude that input pre-processing defenses show impressive results on small\nperturbations; however, they fall short as the perturbation increases. At the\nsame time, train-based defenses increase the average point distance to the\ndecision boundary, which holds after quantization. However, we argue that\ntrain-based defenses still need to smooth the quantization-shift and gradient\nmisalignment phenomenons to counteract adversarial example transferability to\nQNNs. All artifacts are open-sourced to enable independent validation of\nresults.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05688v2",
    "published_date": "2024-04-08 17:14:32 UTC",
    "updated_date": "2024-05-02 20:09:15 UTC"
  },
  {
    "arxiv_id": "2404.16047v1",
    "title": "From \"AI\" to Probabilistic Automation: How Does Anthropomorphization of Technical Systems Descriptions Influence Trust?",
    "authors": [
      "Nanna Inie",
      "Stefania Druga",
      "Peter Zukerman",
      "Emily M. Bender"
    ],
    "abstract": "This paper investigates the influence of anthropomorphized descriptions of\nso-called \"AI\" (artificial intelligence) systems on people's self-assessment of\ntrust in the system. Building on prior work, we define four categories of\nanthropomorphization (1. Properties of a cognizer, 2. Agency, 3. Biological\nmetaphors, and 4. Properties of a communicator). We use a survey-based approach\n(n=954) to investigate whether participants are likely to trust one of two\n(fictitious) \"AI\" systems by randomly assigning people to see either an\nanthropomorphized or a de-anthropomorphized description of the systems. We find\nthat participants are no more likely to trust anthropomorphized over\nde-anthropmorphized product descriptions overall. The type of product or system\nin combination with different anthropomorphic categories appears to exert\ngreater influence on trust than anthropomorphizing language alone, and age is\nthe only demographic factor that significantly correlates with people's\npreference for anthropomorphized or de-anthropomorphized descriptions. When\nelaborating on their choices, participants highlight factors such as lesser of\ntwo evils, lower or higher stakes contexts, and human favoritism as driving\nmotivations when choosing between product A and B, irrespective of whether they\nsaw an anthropomorphized or a de-anthropomorphized description of the product.\nOur results suggest that \"anthropomorphism\" in \"AI\" descriptions is an\naggregate concept that may influence different groups differently, and provide\nnuance to the discussion of whether anthropomorphization leads to higher trust\nand over-reliance by the general public in systems sold as \"AI\".",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to FAccT 2024. arXiv admin note: text overlap with\n  arXiv:2403.05957",
    "pdf_url": "http://arxiv.org/pdf/2404.16047v1",
    "published_date": "2024-04-08 17:01:09 UTC",
    "updated_date": "2024-04-08 17:01:09 UTC"
  },
  {
    "arxiv_id": "2404.05659v3",
    "title": "VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain",
    "authors": [
      "Khai Le-Duc"
    ],
    "abstract": "Due to privacy restrictions, there's a shortage of publicly available speech\nrecognition datasets in the medical domain. In this work, we present VietMed -\na Vietnamese speech recognition dataset in the medical domain comprising 16h of\nlabeled medical speech, 1000h of unlabeled medical speech and 1200h of\nunlabeled general-domain speech. To our best knowledge, VietMed is by far the\nworld's largest public medical speech recognition dataset in 7 aspects: total\nduration, number of speakers, diseases, recording conditions, speaker roles,\nunique medical terms and accents. VietMed is also by far the largest public\nVietnamese speech dataset in terms of total duration. Additionally, we are the\nfirst to present a medical ASR dataset covering all ICD-10 disease groups and\nall accents within a country. Moreover, we release the first public large-scale\npre-trained models for Vietnamese ASR, w2v2-Viet and XLSR-53-Viet, along with\nthe first public large-scale fine-tuned models for medical ASR. Even without\nany medical data in unsupervised pre-training, our best pre-trained model\nXLSR-53-Viet generalizes very well to the medical domain by outperforming\nstate-of-the-art XLSR-53, from 51.8% to 29.6% WER on test set (a relative\nreduction of more than 40%). All code, data and models are made publicly\navailable: https://github.com/leduckhai/MultiMed/tree/master/VietMed.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "LREC-COLING 2024 (Oral), 24 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.05659v3",
    "published_date": "2024-04-08 16:43:52 UTC",
    "updated_date": "2025-04-04 15:06:21 UTC"
  },
  {
    "arxiv_id": "2404.05656v2",
    "title": "Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid Framework",
    "authors": [
      "Shahidur Rahoman Sohag",
      "Sai Zhang",
      "Min Xian",
      "Shoukun Sun",
      "Fei Xu",
      "Zhegang Ma"
    ],
    "abstract": "Industry-wide nuclear power plant operating experience is a critical source\nof raw data for performing parameter estimations in reliability and risk\nmodels. Much operating experience information pertains to failure events and is\nstored as reports containing unstructured data, such as narratives. Event\nreports are essential for understanding how failures are initiated and\npropagated, including the numerous causal relations involved. Causal relation\nextraction using deep learning represents a significant frontier in the field\nof natural language processing (NLP), and is crucial since it enables the\ninterpretation of intricate narratives and connections contained within vast\namounts of written information. This paper proposed a hybrid framework for\ncausality detection and extraction from nuclear licensee event reports. The\nmain contributions include: (1) we compiled an LER corpus with 20,129 text\nsamples for causality analysis, (2) developed an interactive tool for labeling\ncause effect pairs, (3) built a deep-learning-based approach for causal\nrelation detection, and (4) developed a knowledge based cause-effect extraction\napproach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05656v2",
    "published_date": "2024-04-08 16:39:34 UTC",
    "updated_date": "2024-04-22 15:25:20 UTC"
  },
  {
    "arxiv_id": "2404.05648v1",
    "title": "Resistive Memory-based Neural Differential Equation Solver for Score-based Diffusion Model",
    "authors": [
      "Jichang Yang",
      "Hegan Chen",
      "Jia Chen",
      "Songqi Wang",
      "Shaocong Wang",
      "Yifei Yu",
      "Xi Chen",
      "Bo Wang",
      "Xinyuan Zhang",
      "Binbin Cui",
      "Yi Li",
      "Ning Lin",
      "Meng Xu",
      "Yi Li",
      "Xiaoxin Xu",
      "Xiaojuan Qi",
      "Zhongrui Wang",
      "Xumeng Zhang",
      "Dashan Shang",
      "Han Wang",
      "Qi Liu",
      "Kwang-Ting Cheng",
      "Ming Liu"
    ],
    "abstract": "Human brains image complicated scenes when reading a novel. Replicating this\nimagination is one of the ultimate goals of AI-Generated Content (AIGC).\nHowever, current AIGC methods, such as score-based diffusion, are still\ndeficient in terms of rapidity and efficiency. This deficiency is rooted in the\ndifference between the brain and digital computers. Digital computers have\nphysically separated storage and processing units, resulting in frequent data\ntransfers during iterative calculations, incurring large time and energy\noverheads. This issue is further intensified by the conversion of inherently\ncontinuous and analog generation dynamics, which can be formulated by neural\ndifferential equations, into discrete and digital operations. Inspired by the\nbrain, we propose a time-continuous and analog in-memory neural differential\nequation solver for score-based diffusion, employing emerging resistive memory.\nThe integration of storage and computation within resistive memory synapses\nsurmount the von Neumann bottleneck, benefiting the generative speed and energy\nefficiency. The closed-loop feedback integrator is time-continuous, analog, and\ncompact, physically implementing an infinite-depth neural network. Moreover,\nthe software-hardware co-design is intrinsically robust to analog noise. We\nexperimentally validate our solution with 180 nm resistive memory in-memory\ncomputing macros. Demonstrating equivalent generative quality to the software\nbaseline, our system achieved remarkable enhancements in generative speed for\nboth unconditional and conditional generation tasks, by factors of 64.8 and\n156.5, respectively. Moreover, it accomplished reductions in energy consumption\nby factors of 5.2 and 4.1. Our approach heralds a new horizon for hardware\nsolutions in edge computing for generative AI applications.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05648v1",
    "published_date": "2024-04-08 16:34:35 UTC",
    "updated_date": "2024-04-08 16:34:35 UTC"
  },
  {
    "arxiv_id": "2404.08684v1",
    "title": "Is English the New Programming Language? How About Pseudo-code Engineering?",
    "authors": [
      "Gian Alexandre Michaelsen",
      "Renato P. dos Santos"
    ],
    "abstract": "Background: The integration of artificial intelligence (AI) into daily life,\nparticularly through chatbots utilizing natural language processing (NLP),\npresents both revolutionary potential and unique challenges. This intended to\ninvestigate how different input forms impact ChatGPT, a leading language model\nby OpenAI, performance in understanding and executing complex, multi-intention\ntasks. Design: Employing a case study methodology supplemented by discourse\nanalysis, the research analyzes ChatGPT's responses to inputs varying from\nnatural language to pseudo-code engineering. The study specifically examines\nthe model's proficiency across four categories: understanding of intentions,\ninterpretability, completeness, and creativity. Setting and Participants: As a\ntheoretical exploration of AI interaction, this study focuses on the analysis\nof structured and unstructured inputs processed by ChatGPT, without direct\nhuman participants. Data collection and analysis: The research utilizes\nsynthetic case scenarios, including the organization of a \"weekly meal plan\"\nand a \"shopping list,\" to assess ChatGPT's response to prompts in both natural\nlanguage and pseudo-code engineering. The analysis is grounded in the\nidentification of patterns, contradictions, and unique response elements across\ndifferent input formats. Results: Findings reveal that pseudo-code engineering\ninputs significantly enhance the clarity and determinism of ChatGPT's\nresponses, reducing ambiguity inherent in natural language. Enhanced natural\nlanguage, structured through prompt engineering techniques, similarly improves\nthe model's interpretability and creativity. Conclusions: The study underscores\nthe potential of pseudo-code engineering in refining human-AI interaction and\nachieving more deterministic, concise, and direct outcomes, advocating for its\nbroader application across disciplines requiring precise AI responses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.CY",
      "J.4; K.3; I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08684v1",
    "published_date": "2024-04-08 16:28:52 UTC",
    "updated_date": "2024-04-08 16:28:52 UTC"
  },
  {
    "arxiv_id": "2404.05639v1",
    "title": "Investigating the Impact of Quantization on Adversarial Robustness",
    "authors": [
      "Qun Li",
      "Yuan Meng",
      "Chen Tang",
      "Jiacheng Jiang",
      "Zhi Wang"
    ],
    "abstract": "Quantization is a promising technique for reducing the bit-width of deep\nmodels to improve their runtime performance and storage efficiency, and thus\nbecomes a fundamental step for deployment. In real-world scenarios, quantized\nmodels are often faced with adversarial attacks which cause the model to make\nincorrect inferences by introducing slight perturbations. However, recent\nstudies have paid less attention to the impact of quantization on the model\nrobustness. More surprisingly, existing studies on this topic even present\ninconsistent conclusions, which prompted our in-depth investigation. In this\npaper, we conduct a first-time analysis of the impact of the quantization\npipeline components that can incorporate robust optimization under the settings\nof Post-Training Quantization and Quantization-Aware Training. Through our\ndetailed analysis, we discovered that this inconsistency arises from the use of\ndifferent pipelines in different studies, specifically regarding whether robust\noptimization is performed and at which quantization stage it occurs. Our\nresearch findings contribute insights into deploying more secure and robust\nquantized networks, assisting practitioners in reference for scenarios with\nhigh-security requirements and limited resources.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2024 Workshop PML4LRS",
    "pdf_url": "http://arxiv.org/pdf/2404.05639v1",
    "published_date": "2024-04-08 16:20:15 UTC",
    "updated_date": "2024-04-08 16:20:15 UTC"
  },
  {
    "arxiv_id": "2404.05624v1",
    "title": "LTNER: Large Language Model Tagging for Named Entity Recognition with Contextualized Entity Marking",
    "authors": [
      "Faren Yan",
      "Peng Yu",
      "Xin Chen"
    ],
    "abstract": "The use of LLMs for natural language processing has become a popular trend in\nthe past two years, driven by their formidable capacity for context\ncomprehension and learning, which has inspired a wave of research from\nacademics and industry professionals. However, for certain NLP tasks, such as\nNER, the performance of LLMs still falls short when compared to supervised\nlearning methods. In our research, we developed a NER processing framework\ncalled LTNER that incorporates a revolutionary Contextualized Entity Marking\nGen Method. By leveraging the cost-effective GPT-3.5 coupled with context\nlearning that does not require additional training, we significantly improved\nthe accuracy of LLMs in handling NER tasks. The F1 score on the CoNLL03 dataset\nincreased from the initial 85.9% to 91.9%, approaching the performance of\nsupervised fine-tuning. This outcome has led to a deeper understanding of the\npotential of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.05624v1",
    "published_date": "2024-04-08 15:54:02 UTC",
    "updated_date": "2024-04-08 15:54:02 UTC"
  },
  {
    "arxiv_id": "2404.05613v1",
    "title": "Deep Representation Learning for Multi-functional Degradation Modeling of Community-dwelling Aging Population",
    "authors": [
      "Suiyao Chen",
      "Xinyi Liu",
      "Yulei Li",
      "Jing Wu",
      "Handong Yao"
    ],
    "abstract": "As the aging population grows, particularly for the baby boomer generation,\nthe United States is witnessing a significant increase in the elderly\npopulation experiencing multifunctional disabilities. These disabilities,\nstemming from a variety of chronic diseases, injuries, and impairments, present\na complex challenge due to their multidimensional nature, encompassing both\nphysical and cognitive aspects. Traditional methods often use univariate\nregression-based methods to model and predict single degradation conditions and\nassume population homogeneity, which is inadequate to address the complexity\nand diversity of aging-related degradation. This study introduces a novel\nframework for multi-functional degradation modeling that captures the\nmultidimensional (e.g., physical and cognitive) and heterogeneous nature of\nelderly disabilities. Utilizing deep learning, our approach predicts health\ndegradation scores and uncovers latent heterogeneity from elderly health\nhistories, offering both efficient estimation and explainable insights into the\ndiverse effects and causes of aging-related degradation. A real-case study\ndemonstrates the effectiveness and marks a pivotal contribution to accurately\nmodeling the intricate dynamics of elderly degradation, and addresses the\nhealthcare challenges in the aging population.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05613v1",
    "published_date": "2024-04-08 15:40:22 UTC",
    "updated_date": "2024-04-08 15:40:22 UTC"
  },
  {
    "arxiv_id": "2404.05605v1",
    "title": "Graph Neural Networks Automated Design and Deployment on Device-Edge Co-Inference Systems",
    "authors": [
      "Ao Zhou",
      "Jianlei Yang",
      "Tong Qiao",
      "Yingjie Qi",
      "Zhi Yang",
      "Weisheng Zhao",
      "Chunming Hu"
    ],
    "abstract": "The key to device-edge co-inference paradigm is to partition models into\ncomputation-friendly and computation-intensive parts across the device and the\nedge, respectively. However, for Graph Neural Networks (GNNs), we find that\nsimply partitioning without altering their structures can hardly achieve the\nfull potential of the co-inference paradigm due to various\ncomputational-communication overheads of GNN operations over heterogeneous\ndevices. We present GCoDE, the first automatic framework for GNN that\ninnovatively Co-designs the architecture search and the mapping of each\noperation on Device-Edge hierarchies. GCoDE abstracts the device communication\nprocess into an explicit operation and fuses the search of architecture and the\noperations mapping in a unified space for joint-optimization. Also, the\nperformance-awareness approach, utilized in the constraint-based search process\nof GCoDE, enables effective evaluation of architecture efficiency in diverse\nheterogeneous systems. We implement the co-inference engine and runtime\ndispatcher in GCoDE to enhance the deployment efficiency. Experimental results\nshow that GCoDE can achieve up to $44.9\\times$ speedup and $98.2\\%$ energy\nreduction compared to existing approaches across various applications and\nsystem configurations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by DAC'24",
    "pdf_url": "http://arxiv.org/pdf/2404.05605v1",
    "published_date": "2024-04-08 15:25:25 UTC",
    "updated_date": "2024-04-08 15:25:25 UTC"
  },
  {
    "arxiv_id": "2404.05603v1",
    "title": "Self-Explainable Affordance Learning with Embodied Caption",
    "authors": [
      "Zhipeng Zhang",
      "Zhimin Wei",
      "Guolei Sun",
      "Peng Wang",
      "Luc Van Gool"
    ],
    "abstract": "In the field of visual affordance learning, previous methods mainly used\nabundant images or videos that delineate human behavior patterns to identify\naction possibility regions for object manipulation, with a variety of\napplications in robotic tasks. However, they encounter a main challenge of\naction ambiguity, illustrated by the vagueness like whether to beat or carry a\ndrum, and the complexities involved in processing intricate scenes. Moreover,\nit is important for human intervention to rectify robot errors in time. To\naddress these issues, we introduce Self-Explainable Affordance learning (SEA)\nwith embodied caption. This innovation enables robots to articulate their\nintentions and bridge the gap between explainable vision-language caption and\nvisual affordance learning. Due to a lack of appropriate dataset, we unveil a\npioneering dataset and metrics tailored for this task, which integrates images,\nheatmaps, and embodied captions. Furthermore, we propose a novel model to\neffectively combine affordance grounding with self-explanation in a simple but\nefficient manner. Extensive quantitative and qualitative experiments\ndemonstrate our method's effectiveness.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05603v1",
    "published_date": "2024-04-08 15:22:38 UTC",
    "updated_date": "2024-04-08 15:22:38 UTC"
  },
  {
    "arxiv_id": "2404.05779v2",
    "title": "Data Readiness for AI: A 360-Degree Survey",
    "authors": [
      "Kaveen Hiniduma",
      "Suren Byna",
      "Jean Luca Bez"
    ],
    "abstract": "Artificial Intelligence (AI) applications critically depend on data. Poor\nquality data produces inaccurate and ineffective AI models that may lead to\nincorrect or unsafe use. Evaluation of data readiness is a crucial step in\nimproving the quality and appropriateness of data usage for AI. R&D efforts\nhave been spent on improving data quality. However, standardized metrics for\nevaluating data readiness for use in AI training are still evolving. In this\nstudy, we perform a comprehensive survey of metrics used to verify data\nreadiness for AI training. This survey examines more than 140 papers published\nby ACM Digital Library, IEEE Xplore, journals such as Nature, Springer, and\nScience Direct, and online articles published by prominent AI experts. This\nsurvey aims to propose a taxonomy of data readiness for AI (DRAI) metrics for\nstructured and unstructured datasets. We anticipate that this taxonomy will\nlead to new standards for DRAI metrics that will be used for enhancing the\nquality, accuracy, and fairness of AI training and inference.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0; E.m"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages, 3 figures, 2 tables, submitted to ACM Computing Surveys",
    "pdf_url": "http://arxiv.org/pdf/2404.05779v2",
    "published_date": "2024-04-08 15:19:57 UTC",
    "updated_date": "2024-11-27 18:44:07 UTC"
  },
  {
    "arxiv_id": "2404.05569v3",
    "title": "360$^\\circ$REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System",
    "authors": [
      "Shen Gao",
      "Hao Li",
      "Chengrui Huang",
      "Quan Tu",
      "Zhiliang Tian",
      "Minlie Huang",
      "Shuo Shang"
    ],
    "abstract": "Large language model agents have demonstrated remarkable advancements across\nvarious complex tasks. Recent works focus on optimizing the agent team or\nemploying self-reflection to iteratively solve complex tasks. Since these\nagents are all based on the same LLM, only conducting self-evaluation or\nremoving underperforming agents does not substantively enhance the capability\nof the agents. We argue that a comprehensive evaluation and accumulating\nexperience from evaluation feedback is an effective approach to improving\nsystem performance. In this paper, we propose Reusable Experience Accumulation\nwith 360$^\\circ$ Assessment (360$^\\circ$REA), a hierarchical multi-agent\nframework inspired by corporate organizational practices. The framework employs\na novel 360$^\\circ$ performance assessment method for multi-perspective\nperformance evaluation with fine-grained assessment. To enhance the capability\nof agents in addressing complex tasks, we introduce dual-level experience pool\nfor agents to accumulate experience through fine-grained assessment. Extensive\nexperiments on complex task datasets demonstrate the effectiveness of\n360$^\\circ$REA.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05569v3",
    "published_date": "2024-04-08 14:43:13 UTC",
    "updated_date": "2025-03-06 12:54:37 UTC"
  },
  {
    "arxiv_id": "2404.05567v1",
    "title": "Dense Training, Sparse Inference: Rethinking Training of Mixture-of-Experts Language Models",
    "authors": [
      "Bowen Pan",
      "Yikang Shen",
      "Haokun Liu",
      "Mayank Mishra",
      "Gaoyuan Zhang",
      "Aude Oliva",
      "Colin Raffel",
      "Rameswar Panda"
    ],
    "abstract": "Mixture-of-Experts (MoE) language models can reduce computational costs by\n2-4$\\times$ compared to dense models without sacrificing performance, making\nthem more efficient in computation-bounded scenarios. However, MoE models\ngenerally require 2-4$\\times$ times more parameters to achieve comparable\nperformance to a dense model, which incurs larger GPU memory requirements and\nmakes MoE models less efficient in I/O-bounded scenarios like autoregressive\ngeneration. In this work, we propose a hybrid dense training and sparse\ninference framework for MoE models (DS-MoE) which achieves strong computation\nand parameter efficiency by employing dense computation across all experts\nduring training and sparse computation during inference. Our experiments on\ntraining LLMs demonstrate that our DS-MoE models are more parameter-efficient\nthan standard sparse MoEs and are on par with dense models in terms of total\nparameter size and performance while being computationally cheaper (activating\n30-40% of the model's parameters). Performance tests using vLLM show that our\nDS-MoE-6B model runs up to $1.86\\times$ faster than similar dense models like\nMistral-7B, and between $1.50\\times$ and $1.71\\times$ faster than comparable\nMoEs, such as DeepSeekMoE-16B and Qwen1.5-MoE-A2.7B.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05567v1",
    "published_date": "2024-04-08 14:39:49 UTC",
    "updated_date": "2024-04-08 14:39:49 UTC"
  },
  {
    "arxiv_id": "2404.05555v2",
    "title": "On the Convergence of Continual Learning with Adaptive Methods",
    "authors": [
      "Seungyub Han",
      "Yeongmo Kim",
      "Taehyun Cho",
      "Jungwoo Lee"
    ],
    "abstract": "One of the objectives of continual learning is to prevent catastrophic\nforgetting in learning multiple tasks sequentially, and the existing solutions\nhave been driven by the conceptualization of the plasticity-stability dilemma.\nHowever, the convergence of continual learning for each sequential task is less\nstudied so far. In this paper, we provide a convergence analysis of\nmemory-based continual learning with stochastic gradient descent and empirical\nevidence that training current tasks causes the cumulative degradation of\nprevious tasks. We propose an adaptive method for nonconvex continual learning\n(NCCL), which adjusts step sizes of both previous and current tasks with the\ngradients. The proposed method can achieve the same convergence rate as the SGD\nmethod when the catastrophic forgetting term which we define in the paper is\nsuppressed at each iteration. Further, we demonstrate that the proposed\nalgorithm improves the performance of continual learning over existing methods\nfor several image classification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the Thirty-Ninth Conference on Uncertainty in\n  Artificial Intelligence (UAI 2023), see\n  https://proceedings.mlr.press/v216/han23a.html",
    "pdf_url": "http://arxiv.org/pdf/2404.05555v2",
    "published_date": "2024-04-08 14:28:27 UTC",
    "updated_date": "2024-04-15 08:44:13 UTC"
  },
  {
    "arxiv_id": "2404.05553v3",
    "title": "Alljoined1 -- A dataset for EEG-to-Image decoding",
    "authors": [
      "Jonathan Xu",
      "Bruno Aristimunha",
      "Max Emanuel Feucht",
      "Emma Qian",
      "Charles Liu",
      "Tazik Shahjahan",
      "Martyna Spyra",
      "Steven Zifan Zhang",
      "Nicholas Short",
      "Jioh Kim",
      "Paula Perdomo",
      "Ricky Renfeng Mao",
      "Yashvir Sabharwal",
      "Michael Ahedor Moaz Shoura",
      "Adrian Nestor"
    ],
    "abstract": "We present Alljoined1, a dataset built specifically for EEG-to-Image\ndecoding. Recognizing that an extensive and unbiased sampling of neural\nresponses to visual stimuli is crucial for image reconstruction efforts, we\ncollected data from 8 participants looking at 10,000 natural images each. We\nhave currently gathered 46,080 epochs of brain responses recorded with a\n64-channel EEG headset. The dataset combines response-based stimulus timing,\nrepetition between blocks and sessions, and diverse image classes with the goal\nof improving signal quality. For transparency, we also provide data quality\nscores. We publicly release the dataset and all code at\nhttps://linktr.ee/alljoined1.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "I.5.1; I.6.3; I.2.6; K.3.2"
    ],
    "primary_category": "q-bio.NC",
    "comment": "8 Pages, 6 Figures",
    "pdf_url": "http://arxiv.org/pdf/2404.05553v3",
    "published_date": "2024-04-08 14:21:34 UTC",
    "updated_date": "2024-05-14 04:47:45 UTC"
  },
  {
    "arxiv_id": "2404.05545v2",
    "title": "Evaluating Interventional Reasoning Capabilities of Large Language Models",
    "authors": [
      "Tejas Kasetty",
      "Divyat Mahajan",
      "Gintare Karolina Dziugaite",
      "Alexandre Drouin",
      "Dhanya Sridhar"
    ],
    "abstract": "Numerous decision-making tasks require estimating causal effects under\ninterventions on different parts of a system. As practitioners consider using\nlarge language models (LLMs) to automate decisions, studying their causal\nreasoning capabilities becomes crucial. A recent line of work evaluates LLMs\nability to retrieve commonsense causal facts, but these evaluations do not\nsufficiently assess how LLMs reason about interventions. Motivated by the role\nthat interventions play in causal inference, in this paper, we conduct\nempirical analyses to evaluate whether LLMs can accurately update their\nknowledge of a data-generating process in response to an intervention. We\ncreate benchmarks that span diverse causal graphs (e.g., confounding,\nmediation) and variable types, and enable a study of intervention-based\nreasoning. These benchmarks allow us to isolate the ability of LLMs to\naccurately predict changes resulting from their ability to memorize facts or\nfind other shortcuts. We evaluate six LLMs on the benchmarks, finding that GPT\nmodels show promising accuracy at predicting the intervention effects.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.05545v2",
    "published_date": "2024-04-08 14:15:56 UTC",
    "updated_date": "2024-12-22 12:22:53 UTC"
  },
  {
    "arxiv_id": "2404.05540v1",
    "title": "OPSD: an Offensive Persian Social media Dataset and its baseline evaluations",
    "authors": [
      "Mehran Safayani",
      "Amir Sartipi",
      "Amir Hossein Ahmadi",
      "Parniyan Jalali",
      "Amir Hossein Mansouri",
      "Mohammad Bisheh-Niasar",
      "Zahra Pourbahman"
    ],
    "abstract": "The proliferation of hate speech and offensive comments on social media has\nbecome increasingly prevalent due to user activities. Such comments can have\ndetrimental effects on individuals' psychological well-being and social\nbehavior. While numerous datasets in the English language exist in this domain,\nfew equivalent resources are available for Persian language. To address this\ngap, this paper introduces two offensive datasets. The first dataset comprises\nannotations provided by domain experts, while the second consists of a large\ncollection of unlabeled data obtained through web crawling for unsupervised\nlearning purposes. To ensure the quality of the former dataset, a meticulous\nthree-stage labeling process was conducted, and kappa measures were computed to\nassess inter-annotator agreement. Furthermore, experiments were performed on\nthe dataset using state-of-the-art language models, both with and without\nemploying masked language modeling techniques, as well as machine learning\nalgorithms, in order to establish the baselines for the dataset using\ncontemporary cutting-edge approaches. The obtained F1-scores for the\nthree-class and two-class versions of the dataset were 76.9% and 89.9% for\nXLM-RoBERTa, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 5 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.05540v1",
    "published_date": "2024-04-08 14:08:56 UTC",
    "updated_date": "2024-04-08 14:08:56 UTC"
  },
  {
    "arxiv_id": "2404.05534v1",
    "title": "Ordre public exceptions for algorithmic surveillance patents",
    "authors": [
      "Alina Wernick"
    ],
    "abstract": "This chapter explores the role of patent protection in algorithmic\nsurveillance and whether ordre public exceptions from patentability should\napply to such patents, due to their potential to enable human rights\nviolations. It concludes that in most cases, it is undesirable to exclude\nalgorithmic surveillance patents from patentability, as the patent system is\nill-equipped to evaluate the impacts of the exploitation of such technologies.\nFurthermore, the disclosure of such patents has positive externalities from the\nsocietal perspective by opening the black box of surveillance for public\nscrutiny.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.05534v1",
    "published_date": "2024-04-08 14:00:50 UTC",
    "updated_date": "2024-04-08 14:00:50 UTC"
  },
  {
    "arxiv_id": "2404.05530v2",
    "title": "Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data",
    "authors": [
      "Tim Baumgärtner",
      "Yang Gao",
      "Dana Alon",
      "Donald Metzler"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a popular method for\naligning Language Models (LM) with human values and preferences. RLHF requires\na large number of preference pairs as training data, which are often used in\nboth the Supervised Fine-Tuning and Reward Model training and therefore\npublicly available datasets are commonly used. In this work, we study to what\nextent a malicious actor can manipulate the LMs generations by poisoning the\npreferences, i.e., injecting poisonous preference pairs into these datasets and\nthe RLHF training process. We propose strategies to build poisonous preference\npairs and test their performance by poisoning two widely used preference\ndatasets. Our results show that preference poisoning is highly effective:\ninjecting a small amount of poisonous data (1-5\\% of the original dataset), we\ncan effectively manipulate the LM to generate a target entity in a target\nsentiment (positive or negative). The findings from our experiments also shed\nlight on strategies to defend against the preference poisoning attack.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05530v2",
    "published_date": "2024-04-08 13:59:02 UTC",
    "updated_date": "2024-08-06 14:30:31 UTC"
  },
  {
    "arxiv_id": "2404.05777v2",
    "title": "IA2: Leveraging Instance-Aware Index Advisor with Reinforcement Learning for Diverse Workloads",
    "authors": [
      "Taiyi Wang",
      "Eiko Yoneki"
    ],
    "abstract": "This study introduces the Instance-Aware Index Advisor (IA2), a novel deep\nreinforcement learning (DRL)-based approach for optimizing index selection in\ndatabases facing large action spaces of potential candidates. IA2 introduces\nthe Twin Delayed Deep Deterministic Policy Gradient - Temporal Difference\nState-Wise Action Refinery (TD3-TD-SWAR) model, enabling efficient index\nselection by understanding workload-index dependencies and employing adaptive\naction masking. This method includes a comprehensive workload model, enhancing\nits ability to adapt to unseen workloads and ensuring robust performance across\ndiverse database environments. Evaluation on benchmarks such as TPC-H reveals\nIA2's suggested indexes' performance in enhancing runtime, securing a 40%\nreduction in runtime for complex TPC-H workloads compared to scenarios without\nindexes, and delivering a 20% improvement over existing state-of-the-art\nDRL-based index advisors.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "EuroMLSys 24, April 22, 2024, Athens, Greece",
    "pdf_url": "http://arxiv.org/pdf/2404.05777v2",
    "published_date": "2024-04-08 13:40:26 UTC",
    "updated_date": "2024-04-10 08:23:48 UTC"
  },
  {
    "arxiv_id": "2404.05508v1",
    "title": "Synergy of Large Language Model and Model Driven Engineering for Automated Development of Centralized Vehicular Systems",
    "authors": [
      "Nenad Petrovic",
      "Fengjunjie Pan",
      "Krzysztof Lebioda",
      "Vahid Zolfaghari",
      "Sven Kirchner",
      "Nils Purschke",
      "Muhammad Aqib Khan",
      "Viktor Vorobev",
      "Alois Knoll"
    ],
    "abstract": "We present a prototype of a tool leveraging the synergy of model driven\nengineering (MDE) and Large Language Models (LLM) for the purpose of software\ndevelopment process automation in the automotive industry. In this approach,\nthe user-provided input is free form textual requirements, which are first\ntranslated to Ecore model instance representation using an LLM, which is\nafterwards checked for consistency using Object Constraint Language (OCL)\nrules. After successful consistency check, the model instance is fed as input\nto another LLM for the purpose of code generation. The generated code is\nevaluated in a simulated environment using CARLA simulator connected to an\nexample centralized vehicle architecture, in an emergency brake scenario.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "D.2.1; D.2.2; D.2.4; I.2.7; I.2.2; I.7.0"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05508v1",
    "published_date": "2024-04-08 13:28:11 UTC",
    "updated_date": "2024-04-08 13:28:11 UTC"
  },
  {
    "arxiv_id": "2404.05502v1",
    "title": "PetKaz at SemEval-2024 Task 3: Advancing Emotion Classification with an LLM for Emotion-Cause Pair Extraction in Conversations",
    "authors": [
      "Roman Kazakov",
      "Kseniia Petukhova",
      "Ekaterina Kochmar"
    ],
    "abstract": "In this paper, we present our submission to the SemEval-2023 Task~3 \"The\nCompetition of Multimodal Emotion Cause Analysis in Conversations\", focusing on\nextracting emotion-cause pairs from dialogs. Specifically, our approach relies\non combining fine-tuned GPT-3.5 for emotion classification and a BiLSTM-based\nneural network to detect causes. We score 2nd in the ranking for Subtask 1,\ndemonstrating the effectiveness of our approach through one of the highest\nweighted-average proportional F1 scores recorded at 0.264.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 7 figures, 2 tables, to be published in the Proceedings of\n  the 18th International Workshop on Semantic Evaluation (SemEval-2024), for\n  associated code, see https://github.com/sachertort/petkaz-semeval-ecac",
    "pdf_url": "http://arxiv.org/pdf/2404.05502v1",
    "published_date": "2024-04-08 13:25:03 UTC",
    "updated_date": "2024-04-08 13:25:03 UTC"
  },
  {
    "arxiv_id": "2404.05501v1",
    "title": "Data Science In Olfaction",
    "authors": [
      "Vivek Agarwal",
      "Joshua Harvey",
      "Dmitry Rinberg",
      "Vasant Dhar"
    ],
    "abstract": "Advances in neural sensing technology are making it possible to observe the\nolfactory process in great detail. In this paper, we conceptualize smell from a\nData Science and AI perspective, that relates the properties of odorants to how\nthey are sensed and analyzed in the olfactory system from the nose to the\nbrain. Drawing distinctions to color vision, we argue that smell presents\nunique measurement challenges, including the complexity of stimuli, the high\ndimensionality of the sensory apparatus, as well as what constitutes ground\ntruth. In the face of these challenges, we argue for the centrality of\nodorant-receptor interactions in developing a theory of olfaction. Such a\ntheory is likely to find widespread industrial applications, and enhance our\nunderstanding of smell, and in the longer-term, how it relates to other senses\nand language. As an initial use case of the data, we present results using\nmachine learning-based classification of neural responses to odors as they are\nrecorded in the mouse olfactory bulb with calcium imaging.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "20 pages, 10 Figures, 2 Appendix, 1 Table",
    "pdf_url": "http://arxiv.org/pdf/2404.05501v1",
    "published_date": "2024-04-08 13:25:02 UTC",
    "updated_date": "2024-04-08 13:25:02 UTC"
  },
  {
    "arxiv_id": "2404.05499v3",
    "title": "Guiding Large Language Models to Generate Computer-Parsable Content",
    "authors": [
      "Jiaye Wang"
    ],
    "abstract": "We propose a method to guide Large Language Models (LLMs) in generating\nstructured content adhering to specific conventions without fine-tuning. By\nutilizing coroutine-based content generation constraints through a pre-agreed\ncontext-free grammar (CFG), LLMs are directed during decoding to produce formal\nlanguage compliant outputs. This enhances stability and consistency in\ngenerating target data structures, types, or instructions, reducing application\ndevelopment complexities. Experimentally, error rates of GPT-2 and Gemma exceed\n95% for DSLs longer than 36 and 282 tokens, respectively. We introduce\nYieldLang, a coroutine-based DSL generation framework, and evaluate it with\nLLMs on various tasks including JSON and Mermaid flowchart generation. Compared\nto benchmarks, our approach improves accuracy by 1.09 to 11.6 times, with LLMs\nrequiring only about 16.5% of the samples to generate JSON effectively. This\nenhances usability of LLM-generated content for computer programs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "44 pages, 39 figures, 8 tables, Chinese version:\n  https://chinaxiv.org/abs/202403.00340",
    "pdf_url": "http://arxiv.org/pdf/2404.05499v3",
    "published_date": "2024-04-08 13:22:24 UTC",
    "updated_date": "2024-04-21 14:45:28 UTC"
  },
  {
    "arxiv_id": "2404.05483v1",
    "title": "PetKaz at SemEval-2024 Task 8: Can Linguistics Capture the Specifics of LLM-generated Text?",
    "authors": [
      "Kseniia Petukhova",
      "Roman Kazakov",
      "Ekaterina Kochmar"
    ],
    "abstract": "In this paper, we present our submission to the SemEval-2024 Task 8\n\"Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text\nDetection\", focusing on the detection of machine-generated texts (MGTs) in\nEnglish. Specifically, our approach relies on combining embeddings from the\nRoBERTa-base with diversity features and uses a resampled training set. We\nscore 12th from 124 in the ranking for Subtask A (monolingual track), and our\nresults show that our approach is generalizable across unseen models and\ndomains, achieving an accuracy of 0.91.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 3 figures, 5 tables, to be published in the Proceedings of\n  the 18th International Workshop on Semantic Evaluation (SemEval-2024), for\n  associated code, see https://github.com/sachertort/petkaz-semeval-m4",
    "pdf_url": "http://arxiv.org/pdf/2404.05483v1",
    "published_date": "2024-04-08 13:05:02 UTC",
    "updated_date": "2024-04-08 13:05:02 UTC"
  },
  {
    "arxiv_id": "2405.18437v1",
    "title": "Transductive Zero-Shot and Few-Shot CLIP",
    "authors": [
      "Ségolène Martin",
      "Yunshi Huang",
      "Fereshteh Shakeri",
      "Jean-Christophe Pesquet",
      "Ismail Ben Ayed"
    ],
    "abstract": "Transductive inference has been widely investigated in few-shot image\nclassification, but completely overlooked in the recent, fast growing\nliterature on adapting vision-langage models like CLIP. This paper addresses\nthe transductive zero-shot and few-shot CLIP classification challenge, in which\ninference is performed jointly across a mini-batch of unlabeled query samples,\nrather than treating each instance independently. We initially construct\ninformative vision-text probability features, leading to a classification\nproblem on the unit simplex set. Inspired by Expectation-Maximization (EM), our\noptimization-based classification objective models the data probability\ndistribution for each class using a Dirichlet law. The minimization problem is\nthen tackled with a novel block Majorization-Minimization algorithm, which\nsimultaneously estimates the distribution parameters and class assignments.\nExtensive numerical experiments on 11 datasets underscore the benefits and\nefficacy of our batch inference approach.On zero-shot tasks with test batches\nof 75 samples, our approach yields near 20% improvement in ImageNet accuracy\nover CLIP's zero-shot performance. Additionally, we outperform state-of-the-art\nmethods in the few-shot setting. The code is available at:\nhttps://github.com/SegoleneMartin/transductive-CLIP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR), Jun 2024, Seattle (USA), Washington, United States",
    "pdf_url": "http://arxiv.org/pdf/2405.18437v1",
    "published_date": "2024-04-08 12:44:31 UTC",
    "updated_date": "2024-04-08 12:44:31 UTC"
  },
  {
    "arxiv_id": "2404.05458v1",
    "title": "Teaching Higher-Order Logic Using Isabelle",
    "authors": [
      "Simon Tobias Lund",
      "Jørgen Villadsen"
    ],
    "abstract": "We present a formalization of higher-order logic in the Isabelle proof\nassistant, building directly on the foundational framework Isabelle/Pure and\ndeveloped to be as small and readable as possible. It should therefore serve as\na good introduction for someone looking into learning about higher-order logic\nand proof assistants, without having to study the much more complex\nIsabelle/HOL with heavier automation. To showcase our development and approach\nwe explain a sample proof, describe the axioms and rules of our higher-order\nlogic, and discuss our experience with teaching the subject in a classroom\nsetting.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "F.4; I.2.3; K.3.1"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ThEdu'23, arXiv:2404.03709",
    "pdf_url": "http://arxiv.org/pdf/2404.05458v1",
    "published_date": "2024-04-08 12:40:27 UTC",
    "updated_date": "2024-04-08 12:40:27 UTC"
  },
  {
    "arxiv_id": "2404.05440v1",
    "title": "Tree Search-Based Policy Optimization under Stochastic Execution Delay",
    "authors": [
      "David Valensi",
      "Esther Derman",
      "Shie Mannor",
      "Gal Dalal"
    ],
    "abstract": "The standard formulation of Markov decision processes (MDPs) assumes that the\nagent's decisions are executed immediately. However, in numerous realistic\napplications such as robotics or healthcare, actions are performed with a delay\nwhose value can even be stochastic. In this work, we introduce stochastic\ndelayed execution MDPs, a new formalism addressing random delays without\nresorting to state augmentation. We show that given observed delay values, it\nis sufficient to perform a policy search in the class of Markov policies in\norder to reach optimal performance, thus extending the deterministic fixed\ndelay case. Armed with this insight, we devise DEZ, a model-based algorithm\nthat optimizes over the class of Markov policies. DEZ leverages Monte-Carlo\ntree search similar to its non-delayed variant EfficientZero to accurately\ninfer future states from the action queue. Thus, it handles delayed execution\nwhile preserving the sample efficiency of EfficientZero. Through a series of\nexperiments on the Atari suite, we demonstrate that although the previous\nbaseline outperforms the naive method in scenarios with constant delay, it\nunderperforms in the face of stochastic delays. In contrast, our approach\nsignificantly outperforms the baselines, for both constant and stochastic\ndelays. The code is available at http://github.com/davidva1/Delayed-EZ .",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05440v1",
    "published_date": "2024-04-08 12:19:04 UTC",
    "updated_date": "2024-04-08 12:19:04 UTC"
  },
  {
    "arxiv_id": "2404.05427v3",
    "title": "AutoCodeRover: Autonomous Program Improvement",
    "authors": [
      "Yuntong Zhang",
      "Haifeng Ruan",
      "Zhiyu Fan",
      "Abhik Roychoudhury"
    ],
    "abstract": "Researchers have made significant progress in automating the software\ndevelopment process in the past decades. Recent progress in Large Language\nModels (LLMs) has significantly impacted the development process, where\ndevelopers can use LLM-based programming assistants to achieve automated\ncoding. Nevertheless, software engineering involves the process of program\nimprovement apart from coding, specifically to enable software maintenance\n(e.g. bug fixing) and software evolution (e.g. feature additions). In this\npaper, we propose an automated approach for solving GitHub issues to\nautonomously achieve program improvement. In our approach called AutoCodeRover,\nLLMs are combined with sophisticated code search capabilities, ultimately\nleading to a program modification or patch. In contrast to recent LLM agent\napproaches from AI researchers and practitioners, our outlook is more software\nengineering oriented. We work on a program representation (abstract syntax\ntree) as opposed to viewing a software project as a mere collection of files.\nOur code search exploits the program structure in the form of classes/methods\nto enhance LLM's understanding of the issue's root cause, and effectively\nretrieve a context via iterative search. The use of spectrum-based fault\nlocalization using tests, further sharpens the context, as long as a test-suite\nis available. Experiments on SWE-bench-lite (300 real-life GitHub issues) show\nincreased efficacy in solving GitHub issues (19% on SWE-bench-lite), which is\nhigher than the efficacy of the recently reported SWE-agent. In addition,\nAutoCodeRover achieved this efficacy with significantly lower cost (on average,\n$0.43 USD), compared to other baselines. We posit that our workflow enables\nautonomous software engineering, where, in future, auto-generated code from\nLLMs can be autonomously improved.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "To appear in ISSTA 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05427v3",
    "published_date": "2024-04-08 11:55:09 UTC",
    "updated_date": "2024-07-25 16:54:41 UTC"
  },
  {
    "arxiv_id": "2404.05424v2",
    "title": "What Are the Odds? Improving the foundations of Statistical Model Checking",
    "authors": [
      "Tobias Meggendorfer",
      "Maximilian Weininger",
      "Patrick Wienhöft"
    ],
    "abstract": "Markov decision processes (MDPs) are a fundamental model for decision making\nunder uncertainty. They exhibit non-deterministic choice as well as\nprobabilistic uncertainty. Traditionally, verification algorithms assume exact\nknowledge of the probabilities that govern the behaviour of an MDP. As this\nassumption is often unrealistic in practice, statistical model checking (SMC)\nwas developed in the past two decades. It allows to analyse MDPs with unknown\ntransition probabilities and provide probably approximately correct (PAC)\nguarantees on the result. Model-based SMC algorithms sample the MDP and build a\nmodel of it by estimating all transition probabilities, essentially for every\ntransition answering the question: ``What are the odds?'' However, so far the\nstatistical methods employed by the state of the art SMC algorithms are quite\nnaive. Our contribution are several fundamental improvements to those methods:\nOn the one hand, we survey statistics literature for better concentration\ninequalities; on the other hand, we propose specialised approaches that exploit\nour knowledge of the MDP. Our improvements are generally applicable to many\nkinds of problem statements because they are largely independent of the\nsetting. Moreover, our experimental evaluation shows that they lead to\nsignificant gains, reducing the number of samples that the SMC algorithm has to\ncollect by up to two orders of magnitude.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05424v2",
    "published_date": "2024-04-08 11:47:46 UTC",
    "updated_date": "2025-04-17 14:33:17 UTC"
  },
  {
    "arxiv_id": "2404.05423v1",
    "title": "Residual Chain Prediction for Autonomous Driving Path Planning",
    "authors": [
      "Liguo Zhou",
      "Yirui Zhou",
      "Huaming Liu",
      "Alois Knoll"
    ],
    "abstract": "In the rapidly evolving field of autonomous driving systems, the refinement\nof path planning algorithms is paramount for navigating vehicles through\ndynamic environments, particularly in complex urban scenarios. Traditional path\nplanning algorithms, which are heavily reliant on static rules and manually\ndefined parameters, often fall short in such contexts, highlighting the need\nfor more adaptive, learning-based approaches. Among these, behavior cloning\nemerges as a noteworthy strategy for its simplicity and efficiency, especially\nwithin the realm of end-to-end path planning. However, behavior cloning faces\nchallenges, such as covariate shift when employing traditional Manhattan\ndistance as the metric. Addressing this, our study introduces the novel concept\nof Residual Chain Loss. Residual Chain Loss dynamically adjusts the loss\ncalculation process to enhance the temporal dependency and accuracy of\npredicted path points, significantly improving the model's performance without\nadditional computational overhead. Through testing on the nuScenes dataset, we\nunderscore the method's substantial advancements in addressing covariate shift,\nfacilitating dynamic loss adjustments, and ensuring seamless integration with\nend-to-end path planning frameworks. Our findings highlight the potential of\nResidual Chain Loss to revolutionize planning component of autonomous driving\nsystems, marking a significant step forward in the quest for level 5 autonomous\ndriving system.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.05423v1",
    "published_date": "2024-04-08 11:43:40 UTC",
    "updated_date": "2024-04-08 11:43:40 UTC"
  },
  {
    "arxiv_id": "2404.05417v1",
    "title": "Indexing Analytics to Instances: How Integrating a Dashboard can Support Design Education",
    "authors": [
      "Ajit Jain",
      "Andruid Kerne",
      "Nic Lupfer",
      "Gabriel Britain",
      "Aaron Perrine",
      "Yoonsuck Choe",
      "John Keyser",
      "Ruihong Huang",
      "Jinsil Seo",
      "Annie Sungkajun",
      "Robert Lightfoot",
      "Timothy McGuire"
    ],
    "abstract": "We investigate how to use AI-based analytics to support design education. The\nanalytics at hand measure multiscale design, that is, students' use of space\nand scale to visually and conceptually organize their design work. With the\ngoal of making the analytics intelligible to instructors, we developed a\nresearch artifact integrating a design analytics dashboard with design\ninstances, and the design environment that students use to create them. We\ntheorize about how Suchman's notion of mutual intelligibility requires\ncontextualized investigation of AI in order to develop findings about how\nanalytics work for people. We studied the research artifact in 5 situated\ncourse contexts, in 3 departments. A total of 236 students used the multiscale\ndesign environment. The 9 instructors who taught those students experienced the\nanalytics via the new research artifact.\n  We derive findings from a qualitative analysis of interviews with instructors\nregarding their experiences. Instructors reflected on how the analytics and\ntheir presentation in the dashboard have the potential to affect design\neducation. We develop research implications addressing: (1) how indexing design\nanalytics in the dashboard to actual design work instances helps design\ninstructors reflect on what they mean and, more broadly, is a technique for how\nAI-based design analytics can support instructors' assessment and feedback\nexperiences in situated course contexts; and (2) how multiscale design\nanalytics, in particular, have the potential to support design education. By\nindexing, we mean linking which provides context, here connecting the numbers\nof the analytics with visually annotated design work instances.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "H.5.2"
    ],
    "primary_category": "cs.HC",
    "comment": "22 pages, 4 figures, Submitted to ACM DIS",
    "pdf_url": "http://arxiv.org/pdf/2404.05417v1",
    "published_date": "2024-04-08 11:33:58 UTC",
    "updated_date": "2024-04-08 11:33:58 UTC"
  },
  {
    "arxiv_id": "2404.05415v2",
    "title": "Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations",
    "authors": [
      "Yiming Li",
      "Xueqing Peng",
      "Jianfu Li",
      "Xu Zuo",
      "Suyuan Peng",
      "Donghong Pei",
      "Cui Tao",
      "Hua Xu",
      "Na Hong"
    ],
    "abstract": "In acupuncture therapy, the accurate location of acupoints is essential for\nits effectiveness. The advanced language understanding capabilities of large\nlanguage models (LLMs) like Generative Pre-trained Transformers (GPT) present a\nsignificant opportunity for extracting relations related to acupoint locations\nfrom textual knowledge sources. This study aims to compare the performance of\nGPT with traditional deep learning models (Long Short-Term Memory (LSTM) and\nBidirectional Encoder Representations from Transformers for Biomedical Text\nMining (BioBERT)) in extracting acupoint-related location relations and assess\nthe impact of pretraining and fine-tuning on GPT's performance. We utilized the\nWorld Health Organization Standard Acupuncture Point Locations in the Western\nPacific Region (WHO Standard) as our corpus, which consists of descriptions of\n361 acupoints. Five types of relations ('direction_of,' 'distance_of,'\n'part_of,' 'near_acupoint,' and 'located_near') (n= 3,174) between acupoints\nwere annotated. Five models were compared: BioBERT, LSTM, pre-trained GPT-3.5,\nfine-tuned GPT-3.5, as well as pre-trained GPT-4. Performance metrics included\nmicro-average exact match precision, recall, and F1 scores. Our results\ndemonstrate that fine-tuned GPT-3.5 consistently outperformed other models in\nF1 scores across all relation types. Overall, it achieved the highest\nmicro-average F1 score of 0.92. This study underscores the effectiveness of\nLLMs like GPT in extracting relations related to acupoint locations, with\nimplications for accurately modeling acupuncture knowledge and promoting\nstandard implementation in acupuncture training and practice. The findings also\ncontribute to advancing informatics applications in traditional and\ncomplementary medicine, showcasing the potential of LLMs in natural language\nprocessing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05415v2",
    "published_date": "2024-04-08 11:33:00 UTC",
    "updated_date": "2024-04-15 00:45:32 UTC"
  },
  {
    "arxiv_id": "2404.05406v2",
    "title": "PerkwE_COQA: Enhanced Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models",
    "authors": [
      "Pardis Moradbeiki",
      "Nasser Ghadiri"
    ],
    "abstract": "Smart cities need the involvement of their residents to enhance quality of\nlife. Conversational query-answering is an emerging approach for user\nengagement. There is an increasing demand of an advanced conversational\nquestion-answering that goes beyond classic systems. Existing approaches have\nshown that LLMs offer promising capabilities for CQA, but may struggle to\ncapture the nuances of conversational contexts. The new approach involves\nunderstanding the content and engaging in a multi-step conversation with the\nuser to fulfill their needs. This paper presents a novel method to elevate the\nperformance of Persian Conversational question-answering (CQA) systems. It\ncombines the strengths of Large Language Models (LLMs) with contextual keyword\nextraction. Our method extracts keywords specific to the conversational flow,\nproviding the LLM with additional context to understand the user's intent and\ngenerate more relevant and coherent responses. We evaluated the effectiveness\nof this combined approach through various metrics, demonstrating significant\nimprovements in CQA performance compared to an LLM-only baseline. The proposed\nmethod effectively handles implicit questions, delivers contextually relevant\nanswers, and tackles complex questions that rely heavily on conversational\ncontext. The findings indicate that our method outperformed the evaluation\nbenchmarks up to 8% higher than existing methods and the LLM-only baseline.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 68T07",
      "J.3; I.2.7; I.2.1"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05406v2",
    "published_date": "2024-04-08 11:14:58 UTC",
    "updated_date": "2024-04-15 12:38:33 UTC"
  },
  {
    "arxiv_id": "2404.05405v1",
    "title": "Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws",
    "authors": [
      "Zeyuan Allen-Zhu",
      "Yuanzhi Li"
    ],
    "abstract": "Scaling laws describe the relationship between the size of language models\nand their capabilities. Unlike prior studies that evaluate a model's capability\nvia loss or benchmarks, we estimate the number of knowledge bits a model\nstores. We focus on factual knowledge represented as tuples, such as (USA,\ncapital, Washington D.C.) from a Wikipedia page. Through multiple controlled\ndatasets, we establish that language models can and only can store 2 bits of\nknowledge per parameter, even when quantized to int8, and such knowledge can be\nflexibly extracted for downstream applications. Consequently, a 7B model can\nstore 14B bits of knowledge, surpassing the English Wikipedia and textbooks\ncombined based on our estimation.\n  More broadly, we present 12 results on how (1) training duration, (2) model\narchitecture, (3) quantization, (4) sparsity constraints such as MoE, and (5)\ndata signal-to-noise ratio affect a model's knowledge storage capacity. Notable\ninsights include:\n  * The GPT-2 architecture, with rotary embedding, matches or even surpasses\nLLaMA/Mistral architectures in knowledge storage, particularly over shorter\ntraining durations. This arises because LLaMA/Mistral uses GatedMLP, which is\nless stable and harder to train.\n  * Prepending training data with domain names (e.g., wikipedia.org)\nsignificantly increases a model's knowledge capacity. Language models can\nautonomously identify and prioritize domains rich in knowledge, optimizing\ntheir storage capacity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05405v1",
    "published_date": "2024-04-08 11:11:31 UTC",
    "updated_date": "2024-04-08 11:11:31 UTC"
  },
  {
    "arxiv_id": "2404.05403v2",
    "title": "SoK: On Gradient Leakage in Federated Learning",
    "authors": [
      "Jiacheng Du",
      "Jiahui Hu",
      "Zhibo Wang",
      "Peng Sun",
      "Neil Zhenqiang Gong",
      "Kui Ren",
      "Chun Chen"
    ],
    "abstract": "Federated learning (FL) facilitates collaborative model training among\nmultiple clients without raw data exposure. However, recent studies have shown\nthat clients' private training data can be reconstructed from shared gradients\nin FL, a vulnerability known as gradient inversion attacks (GIAs). While GIAs\nhave demonstrated effectiveness under \\emph{ideal settings and auxiliary\nassumptions}, their actual efficacy against \\emph{practical FL systems} remains\nunder-explored. To address this gap, we conduct a comprehensive study on GIAs\nin this work. We start with a survey of GIAs that establishes a timeline to\ntrace their evolution and develops a systematization to uncover their inherent\nthreats. By rethinking GIA in practical FL systems, three fundamental aspects\ninfluencing GIA's effectiveness are identified: \\textit{training setup},\n\\textit{model}, and \\textit{post-processing}. Guided by these aspects, we\nperform extensive theoretical and empirical evaluations of SOTA GIAs across\ndiverse settings. Our findings highlight that GIA is notably\n\\textit{constrained}, \\textit{fragile}, and \\textit{easily defensible}.\nSpecifically, GIAs exhibit inherent limitations against practical local\ntraining settings. Additionally, their effectiveness is highly sensitive to the\ntrained model, and even simple post-processing techniques applied to gradients\ncan serve as effective defenses. Our work provides crucial insights into the\nlimited threats of GIAs in practical FL systems. By rectifying prior\nmisconceptions, we hope to inspire more accurate and realistic investigations\non this topic.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to USENIX Security'25",
    "pdf_url": "http://arxiv.org/pdf/2404.05403v2",
    "published_date": "2024-04-08 11:05:45 UTC",
    "updated_date": "2025-02-05 03:07:53 UTC"
  },
  {
    "arxiv_id": "2404.05399v2",
    "title": "SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety",
    "authors": [
      "Paul Röttger",
      "Fabio Pernisi",
      "Bertie Vidgen",
      "Dirk Hovy"
    ],
    "abstract": "The last two years have seen a rapid growth in concerns around the safety of\nlarge language models (LLMs). Researchers and practitioners have met these\nconcerns by creating an abundance of datasets for evaluating and improving LLM\nsafety. However, much of this work has happened in parallel, and with very\ndifferent goals in mind, ranging from the mitigation of near-term risks around\nbias and toxic content generation to the assessment of longer-term catastrophic\nrisk potential. This makes it difficult for researchers and practitioners to\nfind the most relevant datasets for their use case, and to identify gaps in\ndataset coverage that future work may fill. To remedy these issues, we conduct\na first systematic review of open datasets for evaluating and improving LLM\nsafety. We review 144 datasets, which we identified through an iterative and\ncommunity-driven process over the course of several months. We highlight\npatterns and trends, such as a trend towards fully synthetic datasets, as well\nas gaps in dataset coverage, such as a clear lack of non-English and\nnaturalistic datasets. We also examine how LLM safety datasets are used in\npractice -- in LLM release publications and popular LLM benchmarks -- finding\nthat current evaluation practices are highly idiosyncratic and make use of only\na small fraction of available datasets. Our contributions are based on\nSafetyPrompts.com, a living catalogue of open datasets for LLM safety, which we\nplan to update continuously as the field of LLM safety develops.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at AAAI 2025 (Special Track on AI Alignment)",
    "pdf_url": "http://arxiv.org/pdf/2404.05399v2",
    "published_date": "2024-04-08 10:57:25 UTC",
    "updated_date": "2025-01-10 09:54:54 UTC"
  },
  {
    "arxiv_id": "2404.05393v4",
    "title": "PAT: Pixel-wise Adaptive Training for Long-tailed Segmentation",
    "authors": [
      "Khoi Do",
      "Duong Nguyen",
      "Nguyen H. Tran",
      "Viet Dung Nguyen"
    ],
    "abstract": "Beyond class frequency, we recognize the impact of class-wise relationships\namong various class-specific predictions and the imbalance in label masks on\nlong-tailed segmentation learning. To address these challenges, we propose an\ninnovative Pixel-wise Adaptive Training (PAT) technique tailored for\nlong-tailed segmentation. PAT has two key features: 1) class-wise gradient\nmagnitude homogenization, and 2) pixel-wise class-specific loss adaptation\n(PCLA). First, the class-wise gradient magnitude homogenization helps alleviate\nthe imbalance among label masks by ensuring equal consideration of the\nclass-wise impact on model updates. Second, PCLA tackles the detrimental impact\nof both rare classes within the long-tailed distribution and inaccurate\npredictions from previous training stages by encouraging learning classes with\nlow prediction confidence and guarding against forgetting classes with high\nconfidence. This combined approach fosters robust learning while preventing the\nmodel from forgetting previously learned knowledge. PAT exhibits significant\nperformance improvements, surpassing the current state-of-the-art by 2.2% in\nthe NyU dataset. Moreover, it enhances overall pixel-wise accuracy by 2.85% and\nintersection over union value by 2.07%, with a particularly notable declination\nof 0.39% in detecting rare classes compared to Balance Logits Variation, as\ndemonstrated on the three popular datasets, i.e., OxfordPetIII, CityScape, and\nNYU.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05393v4",
    "published_date": "2024-04-08 10:52:29 UTC",
    "updated_date": "2024-10-20 16:20:16 UTC"
  },
  {
    "arxiv_id": "2404.05388v3",
    "title": "An AI System Evaluation Framework for Advancing AI Safety: Terminology, Taxonomy, Lifecycle Mapping",
    "authors": [
      "Boming Xia",
      "Qinghua Lu",
      "Liming Zhu",
      "Zhenchang Xing"
    ],
    "abstract": "The advent of advanced AI underscores the urgent need for comprehensive\nsafety evaluations, necessitating collaboration across communities (i.e., AI,\nsoftware engineering, and governance). However, divergent practices and\nterminologies across these communities, combined with the complexity of AI\nsystems-of which models are only a part-and environmental affordances (e.g.,\naccess to tools), obstruct effective communication and comprehensive\nevaluation. This paper proposes a framework for AI system evaluation comprising\nthree components: 1) harmonised terminology to facilitate communication across\ncommunities involved in AI safety evaluation; 2) a taxonomy identifying\nessential elements for AI system evaluation; 3) a mapping between AI lifecycle,\nstakeholders, and requisite evaluations for accountable AI supply chain. This\nframework catalyses a deeper discourse on AI system evaluation beyond\nmodel-centric approaches.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "1st ACM International Conference on AI-powered Software (AIware)",
    "pdf_url": "http://arxiv.org/pdf/2404.05388v3",
    "published_date": "2024-04-08 10:49:59 UTC",
    "updated_date": "2024-05-15 06:19:04 UTC"
  },
  {
    "arxiv_id": "2404.05384v1",
    "title": "Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance",
    "authors": [
      "Dazhong Shen",
      "Guanglu Song",
      "Zeyue Xue",
      "Fu-Yun Wang",
      "Yu Liu"
    ],
    "abstract": "Classifier-Free Guidance (CFG) has been widely used in text-to-image\ndiffusion models, where the CFG scale is introduced to control the strength of\ntext guidance on the whole image space. However, we argue that a global CFG\nscale results in spatial inconsistency on varying semantic strengths and\nsuboptimal image quality. To address this problem, we present a novel approach,\nSemantic-aware Classifier-Free Guidance (S-CFG), to customize the guidance\ndegrees for different semantic units in text-to-image diffusion models.\nSpecifically, we first design a training-free semantic segmentation method to\npartition the latent image into relatively independent semantic regions at each\ndenoising step. In particular, the cross-attention map in the denoising U-net\nbackbone is renormalized for assigning each patch to the corresponding token,\nwhile the self-attention map is used to complete the semantic regions. Then, to\nbalance the amplification of diverse semantic units, we adaptively adjust the\nCFG scales across different semantic regions to rescale the text guidance\ndegrees into a uniform level. Finally, extensive experiments demonstrate the\nsuperiority of S-CFG over the original CFG strategy on various text-to-image\ndiffusion models, without requiring any extra training cost. our codes are\navailable at https://github.com/SmilesDZgk/S-CFG.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by CVPR-2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05384v1",
    "published_date": "2024-04-08 10:45:29 UTC",
    "updated_date": "2024-04-08 10:45:29 UTC"
  },
  {
    "arxiv_id": "2404.05348v1",
    "title": "Iterative Refinement Strategy for Automated Data Labeling: Facial Landmark Diagnosis in Medical Imaging",
    "authors": [
      "Yu-Hsi Chen"
    ],
    "abstract": "Automated data labeling techniques are crucial for accelerating the\ndevelopment of deep learning models, particularly in complex medical imaging\napplications. However, ensuring accuracy and efficiency remains challenging.\nThis paper presents iterative refinement strategies for automated data labeling\nin facial landmark diagnosis to enhance accuracy and efficiency for deep\nlearning models in medical applications, including dermatology, plastic\nsurgery, and ophthalmology. Leveraging feedback mechanisms and advanced\nalgorithms, our approach iteratively refines initial labels, reducing reliance\non manual intervention while improving label quality. Through empirical\nevaluation and case studies, we demonstrate the effectiveness of our proposed\nstrategies in deep learning tasks across medical imaging domains. Our results\nhighlight the importance of iterative refinement in automated data labeling to\nenhance the capabilities of deep learning systems in medical imaging\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05348v1",
    "published_date": "2024-04-08 09:33:40 UTC",
    "updated_date": "2024-04-08 09:33:40 UTC"
  },
  {
    "arxiv_id": "2404.05337v1",
    "title": "Towards Objectively Benchmarking Social Intelligence for Language Agents at Action Level",
    "authors": [
      "Chenxu Wang",
      "Bin Dai",
      "Huaping Liu",
      "Baoyuan Wang"
    ],
    "abstract": "Prominent large language models have exhibited human-level performance in\nmany domains, even enabling the derived agents to simulate human and social\ninteractions. While practical works have substantiated the practicability of\ngrounding language agents in sandbox simulation or embodied simulators, current\nsocial intelligence benchmarks either stay at the language level or use\nsubjective metrics. In pursuit of a more realistic and objective evaluation, we\nintroduce the Social Tasks in Sandbox Simulation (STSS) benchmark, which\nassesses language agents \\textbf{objectively} at the \\textbf{action level} by\nscrutinizing the goal achievements within the multi-agent simulation.\nAdditionally, we sample conversation scenarios to build a language-level\nbenchmark to provide an economically prudent preliminary evaluation and align\nwith prevailing benchmarks. To gauge the significance of agent architecture, we\nimplement a target-driven planning (TDP) module as an adjunct to the existing\nagent. Our evaluative findings highlight that the STSS benchmark is challenging\nfor state-of-the-art language agents. Furthermore, it effectively discriminates\nbetween distinct language agents, suggesting its usefulness as a benchmark for\nevaluating both language models and agent architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05337v1",
    "published_date": "2024-04-08 09:25:32 UTC",
    "updated_date": "2024-04-08 09:25:32 UTC"
  },
  {
    "arxiv_id": "2404.05324v1",
    "title": "Back to the Future: GNN-based NO$_2$ Forecasting via Future Covariates",
    "authors": [
      "Antonio Giganti",
      "Sara Mandelli",
      "Paolo Bestagini",
      "Umberto Giuriato",
      "Alessandro D'Ausilio",
      "Marco Marcon",
      "Stefano Tubaro"
    ],
    "abstract": "Due to the latest environmental concerns in keeping at bay contaminants\nemissions in urban areas, air pollution forecasting has been rising the\nforefront of all researchers around the world. When predicting pollutant\nconcentrations, it is common to include the effects of environmental factors\nthat influence these concentrations within an extended period, like traffic,\nmeteorological conditions and geographical information. Most of the existing\napproaches exploit this information as past covariates, i.e., past exogenous\nvariables that affected the pollutant but were not affected by it. In this\npaper, we present a novel forecasting methodology to predict NO$_2$\nconcentration via both past and future covariates. Future covariates are\nrepresented by weather forecasts and future calendar events, which are already\nknown at prediction time. In particular, we deal with air quality observations\nin a city-wide network of ground monitoring stations, modeling the data\nstructure and estimating the predictions with a Spatiotemporal Graph Neural\nNetwork (STGNN). We propose a conditioning block that embeds past and future\ncovariates into the current observations. After extracting meaningful\nspatiotemporal representations, these are fused together and projected into the\nforecasting horizon to generate the final prediction. To the best of our\nknowledge, it is the first time that future covariates are included in time\nseries predictions in a structured way. Remarkably, we find that conditioning\non future weather information has a greater impact than considering past\ntraffic conditions. We release our code implementation at\nhttps://github.com/polimi-ispl/MAGCRN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 4 figures, 1 table, accepted at IEEE-IGARSS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05324v1",
    "published_date": "2024-04-08 09:13:16 UTC",
    "updated_date": "2024-04-08 09:13:16 UTC"
  },
  {
    "arxiv_id": "2404.05290v1",
    "title": "MindSet: Vision. A toolbox for testing DNNs on key psychological experiments",
    "authors": [
      "Valerio Biscione",
      "Dong Yin",
      "Gaurav Malhotra",
      "Marin Dujmovic",
      "Milton L. Montero",
      "Guillermo Puebla",
      "Federico Adolfi",
      "Rachel F. Heaton",
      "John E. Hummel",
      "Benjamin D. Evans",
      "Karim Habashy",
      "Jeffrey S. Bowers"
    ],
    "abstract": "Multiple benchmarks have been developed to assess the alignment between deep\nneural networks (DNNs) and human vision. In almost all cases these benchmarks\nare observational in the sense they are composed of behavioural and brain\nresponses to naturalistic images that have not been manipulated to test\nhypotheses regarding how DNNs or humans perceive and identify objects. Here we\nintroduce the toolbox MindSet: Vision, consisting of a collection of image\ndatasets and related scripts designed to test DNNs on 30 psychological\nfindings. In all experimental conditions, the stimuli are systematically\nmanipulated to test specific hypotheses regarding human visual perception and\nobject recognition. In addition to providing pre-generated datasets of images,\nwe provide code to regenerate these datasets, offering many configurable\nparameters which greatly extend the dataset versatility for different research\ncontexts, and code to facilitate the testing of DNNs on these image datasets\nusing three different methods (similarity judgments, out-of-distribution\nclassification, and decoder method), accessible at\nhttps://github.com/MindSetVision/mindset-vision. We test ResNet-152 on each of\nthese methods as an example of how the toolbox can be used.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05290v1",
    "published_date": "2024-04-08 08:28:19 UTC",
    "updated_date": "2024-04-08 08:28:19 UTC"
  },
  {
    "arxiv_id": "2404.05272v2",
    "title": "Pricing Strategies for Different Accuracy Models from the Same Dataset Based on Generalized Hotelling's Law",
    "authors": [
      "Jie Liu",
      "Tao Feng",
      "Yan Jiang",
      "Peizheng Wang",
      "Chao Wu"
    ],
    "abstract": "We consider a scenario where a seller possesses a dataset $D$ and trains it\ninto models of varying accuracies for sale in the market. Due to the\nreproducibility of data, the dataset can be reused to train models with\ndifferent accuracies, and the training cost is independent of the sales volume.\nThese two characteristics lead to fundamental differences between the data\ntrading market and traditional trading markets. The introduction of different\nmodels into the market inevitably gives rise to competition. However, due to\nthe varying accuracies of these models, traditional multi-oligopoly games are\nnot applicable. We consider a generalized Hotelling's law, where the accuracy\nof the models is abstracted as distance. Buyers choose to purchase models based\non a trade-off between accuracy and price, while sellers determine their\npricing strategies based on the market's demand. We present two pricing\nstrategies: static pricing strategy and dynamic pricing strategy, and we focus\non the static pricing strategy. We propose static pricing mechanisms based on\nvarious market conditions and provide an example. Finally, we demonstrate that\nour pricing strategy remains robust in the context of incomplete information\ngames.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05272v2",
    "published_date": "2024-04-08 08:02:18 UTC",
    "updated_date": "2025-03-29 08:49:42 UTC"
  },
  {
    "arxiv_id": "2404.05259v1",
    "title": "Cellular automata, many-valued logic, and deep neural networks",
    "authors": [
      "Yani Zhang",
      "Helmut Bölcskei"
    ],
    "abstract": "We develop a theory characterizing the fundamental capability of deep neural\nnetworks to learn, from evolution traces, the logical rules governing the\nbehavior of cellular automata (CA). This is accomplished by first establishing\na novel connection between CA and Lukasiewicz propositional logic. While binary\nCA have been known for decades to essentially perform operations in Boolean\nlogic, no such relationship exists for general CA. We demonstrate that\nmany-valued (MV) logic, specifically Lukasiewicz propositional logic,\nconstitutes a suitable language for characterizing general CA as logical\nmachines. This is done by interpolating CA transition functions to continuous\npiecewise linear functions, which, by virtue of the McNaughton theorem, yield\nformulae in MV logic characterizing the CA. Recognizing that deep rectified\nlinear unit (ReLU) networks realize continuous piecewise linear functions, it\nfollows that these formulae are naturally extracted from CA evolution traces by\ndeep ReLU networks. A corresponding algorithm together with a software\nimplementation is provided. Finally, we show that the dynamical behavior of CA\ncan be realized by recurrent neural networks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05259v1",
    "published_date": "2024-04-08 07:49:52 UTC",
    "updated_date": "2024-04-08 07:49:52 UTC"
  },
  {
    "arxiv_id": "2404.05256v2",
    "title": "StyleForge: Enhancing Text-to-Image Synthesis for Any Artistic Styles with Dual Binding",
    "authors": [
      "Junseo Park",
      "Beomseok Ko",
      "Hyeryung Jang"
    ],
    "abstract": "Recent advancements in text-to-image models, such as Stable Diffusion, have\nshowcased their ability to create visual images from natural language prompts.\nHowever, existing methods like DreamBooth struggle with capturing arbitrary art\nstyles due to the abstract and multifaceted nature of stylistic attributes. We\nintroduce Single-StyleForge, a novel approach for personalized text-to-image\nsynthesis across diverse artistic styles. Using approximately 15 to 20 images\nof the target style, Single-StyleForge establishes a foundational binding of a\nunique token identifier with a broad range of attributes of the target style.\nAdditionally, auxiliary images are incorporated for dual binding that guides\nthe consistent representation of crucial elements such as people within the\ntarget style. Furthermore, we present Multi-StyleForge, which enhances image\nquality and text alignment by binding multiple tokens to partial style\nattributes. Experimental evaluations across six distinct artistic styles\ndemonstrate significant improvements in image quality and perceptual fidelity,\nas measured by FID, KID, and CLIP scores.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 12 figuers",
    "pdf_url": "http://arxiv.org/pdf/2404.05256v2",
    "published_date": "2024-04-08 07:43:23 UTC",
    "updated_date": "2024-07-17 06:15:10 UTC"
  },
  {
    "arxiv_id": "2404.08001v1",
    "title": "Xiwu: A Basis Flexible and Learnable LLM for High Energy Physics",
    "authors": [
      "Zhengde Zhang",
      "Yiyu Zhang",
      "Haodong Yao",
      "Jianwen Luo",
      "Rui Zhao",
      "Bo Huang",
      "Jiameng Zhao",
      "Yipu Liao",
      "Ke Li",
      "Lina Zhao",
      "Jun Cao",
      "Fazhi Qi",
      "Changzheng Yuan"
    ],
    "abstract": "Large Language Models (LLMs) are undergoing a period of rapid updates and\nchanges, with state-of-the-art (SOTA) model frequently being replaced. When\napplying LLMs to a specific scientific field, it's challenging to acquire\nunique domain knowledge while keeping the model itself advanced. To address\nthis challenge, a sophisticated large language model system named as Xiwu has\nbeen developed, allowing you switch between the most advanced foundation models\nand quickly teach the model domain knowledge. In this work, we will report on\nthe best practices for applying LLMs in the field of high-energy physics (HEP),\nincluding: a seed fission technology is proposed and some data collection and\ncleaning tools are developed to quickly obtain domain AI-Ready dataset; a\njust-in-time learning system is implemented based on the vector store\ntechnology; an on-the-fly fine-tuning system has been developed to facilitate\nrapid training under a specified foundation model. The results show that Xiwu\ncan smoothly switch between foundation models such as LLaMA, Vicuna, ChatGLM\nand Grok-1. The trained Xiwu model is significantly outperformed the benchmark\nmodel on the HEP knowledge question-and-answering and code generation. This\nstrategy significantly enhances the potential for growth of our model's\nperformance, with the hope of surpassing GPT-4 as it evolves with the\ndevelopment of open-source models. This work provides a customized LLM for the\nfield of HEP, while also offering references for applying LLM to other fields,\nthe corresponding codes are available on Github.",
    "categories": [
      "hep-ph",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "hep-ex",
      "physics.comp-ph",
      "I.2.7"
    ],
    "primary_category": "hep-ph",
    "comment": "15 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.08001v1",
    "published_date": "2024-04-08 07:37:31 UTC",
    "updated_date": "2024-04-08 07:37:31 UTC"
  },
  {
    "arxiv_id": "2404.05243v1",
    "title": "Product Description and QA Assisted Self-Supervised Opinion Summarization",
    "authors": [
      "Tejpalsingh Siledar",
      "Rupasai Rangaraju",
      "Sankara Sri Raghava Ravindra Muddu",
      "Suman Banerjee",
      "Amey Patil",
      "Sudhanshu Shekhar Singh",
      "Muthusamy Chelliah",
      "Nikesh Garera",
      "Swaprava Nath",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "In e-commerce, opinion summarization is the process of summarizing the\nconsensus opinions found in product reviews. However, the potential of\nadditional sources such as product description and question-answers (QA) has\nbeen considered less often. Moreover, the absence of any supervised training\ndata makes this task challenging. To address this, we propose a novel synthetic\ndataset creation (SDC) strategy that leverages information from reviews as well\nas additional sources for selecting one of the reviews as a pseudo-summary to\nenable supervised training. Our Multi-Encoder Decoder framework for Opinion\nSummarization (MEDOS) employs a separate encoder for each source, enabling\neffective selection of information while generating the summary. For\nevaluation, due to the unavailability of test sets with additional sources, we\nextend the Amazon, Oposum+, and Flipkart test sets and leverage ChatGPT to\nannotate summaries. Experiments across nine test sets demonstrate that the\ncombination of our SDC approach and MEDOS model achieves on average a 14.5%\nimprovement in ROUGE-1 F1 over the SOTA. Moreover, comparative analysis\nunderlines the significance of incorporating additional sources for generating\nmore informative summaries. Human evaluations further indicate that MEDOS\nscores relatively higher in coherence and fluency with 0.41 and 0.5 (-1 to 1)\nrespectively, compared to existing models. To the best of our knowledge, we are\nthe first to generate opinion summaries leveraging additional sources in a\nself-supervised setting.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05243v1",
    "published_date": "2024-04-08 07:15:06 UTC",
    "updated_date": "2024-04-08 07:15:06 UTC"
  },
  {
    "arxiv_id": "2404.05235v2",
    "title": "Novelty Heuristics, Multi-Queue Search, and Portfolios for Numeric Planning",
    "authors": [
      "Dillon Z. Chen",
      "Sylvie Thiébaux"
    ],
    "abstract": "Heuristic search is a powerful approach for solving planning problems and\nnumeric planning is no exception. In this paper, we boost the performance of\nheuristic search for numeric planning with various powerful techniques\northogonal to improving heuristic informedness: numeric novelty heuristics, the\nManhattan distance heuristic, and exploring the use of multi-queue search and\nportfolios for combining heuristics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of SoCS 2024 paper",
    "pdf_url": "http://arxiv.org/pdf/2404.05235v2",
    "published_date": "2024-04-08 07:01:35 UTC",
    "updated_date": "2024-04-11 15:00:15 UTC"
  },
  {
    "arxiv_id": "2404.05776v1",
    "title": "Forecasting Electric Vehicle Battery Output Voltage: A Predictive Modeling Approach",
    "authors": [
      "Narayana Darapaneni",
      "Ashish K",
      "Ullas M S",
      "Anwesh Reddy Paduri"
    ],
    "abstract": "The battery management system plays a vital role in ensuring the safety and\ndependability of electric and hybrid vehicles. It is responsible for various\nfunctions, including state evaluation, monitoring, charge control, and cell\nbalancing, all integrated within the BMS. Nonetheless, due to the uncertainties\nsurrounding battery performance, implementing these functionalities poses\nsignificant challenges. In this study, we explore the latest approaches for\nassessing battery states, highlight notable advancements in battery management\nsystems (BMS), address existing issues with current BMS technology, and put\nforth possible solutions for predicting battery charging voltage.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05776v1",
    "published_date": "2024-04-08 06:47:03 UTC",
    "updated_date": "2024-04-08 06:47:03 UTC"
  },
  {
    "arxiv_id": "2404.05224v1",
    "title": "Iof-maint -- Modular maintenance ontology",
    "authors": [
      "Melinda Hodkiewicz",
      "Caitlin Woods",
      "Matt Selway",
      "Markus Stumptner"
    ],
    "abstract": "In this paper we present a publicly-available maintenance ontology\n(Iof-maint). Iof-maint is a modular ontology aligned with the Industrial\nOntology Foundry Core (IOF Core) and contains 20 classes and 2 relations. It\nprovides a set of maintenance-specific terms used in a wide variety of\npractical data-driven use cases. Iof-maint supports OWL DL reasoning, is\ndocumented, and is actively maintained on GitHub. In this paper, we describe\nthe evolution of the Iof-maint reference ontology based on the extraction of\ncommon concepts identified in a number of application ontologies working with\nindustry maintenance work order, procedure and failure mode data.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05224v1",
    "published_date": "2024-04-08 06:40:03 UTC",
    "updated_date": "2024-04-08 06:40:03 UTC"
  },
  {
    "arxiv_id": "2404.05223v2",
    "title": "ITA-ECBS: A Bounded-Suboptimal Algorithm for the Combined Target-Assignment and Path-Finding Problem",
    "authors": [
      "Yimin Tang",
      "Sven Koenig",
      "Jiaoyang Li"
    ],
    "abstract": "Multi-Agent Path Finding (MAPF), i.e., finding collision-free paths for\nmultiple robots, plays a critical role in many applications. Sometimes,\nassigning a target to each agent also presents a challenge. The Combined\nTarget-Assignment and Path-Finding (TAPF) problem, a variant of MAPF, requires\none to simultaneously assign targets to agents and plan collision-free paths\nfor agents. Several algorithms, including CBM, CBS-TA, and ITA-CBS, optimally\nsolve the TAPF problem, with ITA-CBS being the leading algorithm for minimizing\nflowtime. However, the only existing bounded-suboptimal algorithm ECBS-TA is\nderived from CBS-TA rather than ITA-CBS. So, it faces the same issues as\nCBS-TA, such as searching through multiple constraint trees and spending too\nmuch time on finding the next-best target assignment. We introduce ITA-ECBS,\nthe first bounded-suboptimal variant of ITA-CBS. Transforming ITA-CBS to its\nbounded-suboptimal variant is challenging because different constraint tree\nnodes can have different assignments of targets to agents. ITA-ECBS uses focal\nsearch to achieve efficiency and determines target assignments based on a new\nlower bound matrix. We show that it runs faster than ECBS-TA in 87.42% of\n54,033 test cases.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05223v2",
    "published_date": "2024-04-08 06:36:42 UTC",
    "updated_date": "2024-04-21 09:55:23 UTC"
  },
  {
    "arxiv_id": "2404.05221v2",
    "title": "LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models",
    "authors": [
      "Shibo Hao",
      "Yi Gu",
      "Haotian Luo",
      "Tianyang Liu",
      "Xiyan Shao",
      "Xinyuan Wang",
      "Shuhua Xie",
      "Haodi Ma",
      "Adithya Samavedhi",
      "Qiyue Gao",
      "Zhen Wang",
      "Zhiting Hu"
    ],
    "abstract": "Generating accurate step-by-step reasoning is essential for Large Language\nModels (LLMs) to address complex problems and enhance robustness and\ninterpretability. Despite the flux of research on developing advanced reasoning\napproaches, systematically analyzing the diverse LLMs and reasoning strategies\nin generating reasoning chains remains a significant challenge. The\ndifficulties stem from the lack of two key elements: (1) an automatic method\nfor evaluating the generated reasoning chains on different tasks, and (2) a\nunified formalism and implementation of the diverse reasoning approaches for\nsystematic comparison. This paper aims to close the gap: (1) We introduce\nAutoRace for fully automated reasoning chain evaluation. Existing metrics rely\non expensive human annotations or pre-defined LLM prompts not adaptable to\ndifferent tasks. In contrast, AutoRace automatically creates detailed\nevaluation criteria tailored for each task, and uses GPT-4 for accurate\nevaluation following the criteria. (2) We develop LLM Reasoners, a library for\nstandardized modular implementation of existing and new reasoning algorithms,\nunder a unified formulation of the search, reward, and world model components.\nWith the new evaluation and library, (3) we conduct extensive study of\ndifferent reasoning approaches (e.g., CoT, ToT, RAP). The analysis reveals\ninteresting findings about different factors contributing to reasoning,\nincluding the reward-guidance, breadth-vs-depth in search, world model, and\nprompt formats, etc.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Project website: https://www.llm-reasoners.net/",
    "pdf_url": "http://arxiv.org/pdf/2404.05221v2",
    "published_date": "2024-04-08 06:35:09 UTC",
    "updated_date": "2024-08-11 22:20:19 UTC"
  },
  {
    "arxiv_id": "2404.05218v1",
    "title": "Multi-agent Long-term 3D Human Pose Forecasting via Interaction-aware Trajectory Conditioning",
    "authors": [
      "Jaewoo Jeong",
      "Daehee Park",
      "Kuk-Jin Yoon"
    ],
    "abstract": "Human pose forecasting garners attention for its diverse applications.\nHowever, challenges in modeling the multi-modal nature of human motion and\nintricate interactions among agents persist, particularly with longer\ntimescales and more agents. In this paper, we propose an interaction-aware\ntrajectory-conditioned long-term multi-agent human pose forecasting model,\nutilizing a coarse-to-fine prediction approach: multi-modal global trajectories\nare initially forecasted, followed by respective local pose forecasts\nconditioned on each mode. In doing so, our Trajectory2Pose model introduces a\ngraph-based agent-wise interaction module for a reciprocal forecast of local\nmotion-conditioned global trajectory and trajectory-conditioned local pose. Our\nmodel effectively handles the multi-modality of human motion and the complexity\nof long-term multi-agent interactions, improving performance in complex\nenvironments. Furthermore, we address the lack of long-term (6s+) multi-agent\n(5+) datasets by constructing a new dataset from real-world images and 2D\nannotations, enabling a comprehensive evaluation of our proposed model.\nState-of-the-art prediction performance on both complex and simpler datasets\nconfirms the generalized effectiveness of our method. The code is available at\nhttps://github.com/Jaewoo97/T2P.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 CVPR Highlight",
    "pdf_url": "http://arxiv.org/pdf/2404.05218v1",
    "published_date": "2024-04-08 06:15:13 UTC",
    "updated_date": "2024-04-08 06:15:13 UTC"
  },
  {
    "arxiv_id": "2404.05213v1",
    "title": "Evaluation of an LLM in Identifying Logical Fallacies: A Call for Rigor When Adopting LLMs in HCI Research",
    "authors": [
      "Gionnieve Lim",
      "Simon T. Perrault"
    ],
    "abstract": "There is increasing interest in the adoption of LLMs in HCI research.\nHowever, LLMs may often be regarded as a panacea because of their powerful\ncapabilities with an accompanying oversight on whether they are suitable for\ntheir intended tasks. We contend that LLMs should be adopted in a critical\nmanner following rigorous evaluation. Accordingly, we present the evaluation of\nan LLM in identifying logical fallacies that will form part of a digital\nmisinformation intervention. By comparing to a labeled dataset, we found that\nGPT-4 achieves an accuracy of 0.79, and for our intended use case that excludes\ninvalid or unidentified instances, an accuracy of 0.90. This gives us the\nconfidence to proceed with the application of the LLM while keeping in mind the\nareas where it still falls short. The paper describes our evaluation approach,\nresults and reflections on the use of the LLM for our intended task.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05213v1",
    "published_date": "2024-04-08 06:00:14 UTC",
    "updated_date": "2024-04-08 06:00:14 UTC"
  },
  {
    "arxiv_id": "2404.05188v2",
    "title": "Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging",
    "authors": [
      "Tianshuo Cong",
      "Delong Ran",
      "Zesen Liu",
      "Xinlei He",
      "Jinyuan Liu",
      "Yichen Gong",
      "Qi Li",
      "Anyu Wang",
      "Xiaoyun Wang"
    ],
    "abstract": "Model merging is a promising lightweight model empowerment technique that\ndoes not rely on expensive computing devices (e.g., GPUs) or require the\ncollection of specific training data. Instead, it involves editing different\nupstream model parameters to absorb their downstream task capabilities.\nHowever, uncertified model merging can infringe upon the Intellectual Property\n(IP) rights of the original upstream models. In this paper, we conduct the\nfirst study on the robustness of IP protection methods under model merging\nscenarios. Specifically, we investigate two state-of-the-art IP protection\ntechniques: Quantization Watermarking and Instructional Fingerprint, along with\nvarious advanced model merging technologies, such as Task Arithmetic,\nTIES-MERGING, and so on. Experimental results indicate that current Large\nLanguage Model (LLM) watermarking techniques cannot survive in the merged\nmodels, whereas model fingerprinting techniques can. Our research aims to\nhighlight that model merging should be an indispensable consideration in the\nrobustness assessment of model IP protection techniques, thereby promoting the\nhealthy development of the open-source LLM community. Our code is available at\nhttps://github.com/ThuCCSLab/MergeGuard.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by ACM CCS-LAMPS 2024 (Best Paper Award)",
    "pdf_url": "http://arxiv.org/pdf/2404.05188v2",
    "published_date": "2024-04-08 04:30:33 UTC",
    "updated_date": "2024-11-04 10:42:01 UTC"
  },
  {
    "arxiv_id": "2404.05182v1",
    "title": "DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model",
    "authors": [
      "Chao Gao",
      "Sai Qian Zhang"
    ],
    "abstract": "To enhance the performance of large language models (LLM) on downstream\ntasks, one solution is to fine-tune certain LLM parameters and make it better\nalign with the characteristics of the training dataset. This process is\ncommonly known as parameter-efficient fine-tuning (PEFT). Due to the scale of\nLLM, PEFT operations are usually executed in the public environment (e.g.,\ncloud server). This necessitates the sharing of sensitive user data across\npublic environments, thereby raising potential privacy concerns. To tackle\nthese challenges, we propose a distributed PEFT framework called DLoRA. DLoRA\nenables scalable PEFT operations to be performed collaboratively between the\ncloud and user devices. Coupled with the proposed Kill and Revive algorithm,\nthe evaluation results demonstrate that DLoRA can significantly reduce the\ncomputation and communication workload over the user devices while achieving\nsuperior accuracy and privacy protection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05182v1",
    "published_date": "2024-04-08 04:14:02 UTC",
    "updated_date": "2024-04-08 04:14:02 UTC"
  },
  {
    "arxiv_id": "2404.05180v2",
    "title": "GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery",
    "authors": [
      "Zhiyuan Yang",
      "Ryan Rad"
    ],
    "abstract": "Solar Photovoltaic (PV) technology is increasingly recognized as a pivotal\nsolution in the global pursuit of clean and renewable energy. This technology\naddresses the urgent need for sustainable energy alternatives by converting\nsolar power into electricity without greenhouse gas emissions. It not only\ncurtails global carbon emissions but also reduces reliance on finite,\nnon-renewable energy sources. In this context, monitoring solar panel farms\nbecomes essential for understanding and facilitating the worldwide shift toward\nclean energy. This study contributes to this effort by developing the first\ncomprehensive global dataset of multispectral satellite imagery of solar panel\nfarms. This dataset is intended to form the basis for training robust machine\nlearning models, which can accurately map and analyze the expansion and\ndistribution of solar panel farms globally. The insights gained from this\nendeavor will be instrumental in guiding informed decision-making for a\nsustainable energy future. https://github.com/yzyly1992/GloSoFarID",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05180v2",
    "published_date": "2024-04-08 04:10:50 UTC",
    "updated_date": "2024-08-26 16:13:30 UTC"
  },
  {
    "arxiv_id": "2404.05774v1",
    "title": "STMGF: An Effective Spatial-Temporal Multi-Granularity Framework for Traffic Forecasting",
    "authors": [
      "Zhengyang Zhao",
      "Haitao Yuan",
      "Nan Jiang",
      "Minxiao Chen",
      "Ning Liu",
      "Zengxiang Li"
    ],
    "abstract": "Accurate Traffic Prediction is a challenging task in intelligent\ntransportation due to the spatial-temporal aspects of road networks. The\ntraffic of a road network can be affected by long-distance or long-term\ndependencies where existing methods fall short in modeling them. In this paper,\nwe introduce a novel framework known as Spatial-Temporal Multi-Granularity\nFramework (STMGF) to enhance the capture of long-distance and long-term\ninformation of the road networks. STMGF makes full use of different granularity\ninformation of road networks and models the long-distance and long-term\ninformation by gathering information in a hierarchical interactive way.\nFurther, it leverages the inherent periodicity in traffic sequences to refine\nprediction results by matching with recent traffic data. We conduct experiments\non two real-world datasets, and the results demonstrate that STMGF outperforms\nall baseline models and achieves state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05774v1",
    "published_date": "2024-04-08 03:38:52 UTC",
    "updated_date": "2024-04-08 03:38:52 UTC"
  },
  {
    "arxiv_id": "2404.05143v1",
    "title": "Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation",
    "authors": [
      "Rohan Deepak Ajwani",
      "Zining Zhu",
      "Jonathan Rose",
      "Frank Rudzicz"
    ],
    "abstract": "Transformer-based Large Language Models (LLMs) have shown exceptional\nlanguage generation capabilities in response to text-based prompts. However,\ncontrolling the direction of generation via textual prompts has been\nchallenging, especially with smaller models. In this work, we explore the use\nof Prompt Tuning to achieve controlled language generation. Generated text is\nsteered using prompt embeddings, which are trained using a small language\nmodel, used as a discriminator. Moreover, we demonstrate that these prompt\nembeddings can be trained with a very small dataset, with as low as a few\nhundred training examples. Our method thus offers a data and parameter\nefficient solution towards controlling language model outputs. We carry out\nextensive evaluation on four datasets: SST-5 and Yelp (sentiment analysis),\nGYAFC (formality) and JIGSAW (toxic language). Finally, we demonstrate the\nefficacy of our method towards mitigating harmful, toxic, and biased text\ngenerated by language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 figures, Presented at Deployable AI Workshop at AAAI-2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05143v1",
    "published_date": "2024-04-08 01:54:28 UTC",
    "updated_date": "2024-04-08 01:54:28 UTC"
  },
  {
    "arxiv_id": "2404.05136v1",
    "title": "Self-Supervised Multi-Object Tracking with Path Consistency",
    "authors": [
      "Zijia Lu",
      "Bing Shuai",
      "Yanbei Chen",
      "Zhenlin Xu",
      "Davide Modolo"
    ],
    "abstract": "In this paper, we propose a novel concept of path consistency to learn robust\nobject matching without using manual object identity supervision. Our key idea\nis that, to track a object through frames, we can obtain multiple different\nassociation results from a model by varying the frames it can observe, i.e.,\nskipping frames in observation. As the differences in observations do not alter\nthe identities of objects, the obtained association results should be\nconsistent. Based on this rationale, we generate multiple observation paths,\neach specifying a different set of frames to be skipped, and formulate the Path\nConsistency Loss that enforces the association results are consistent across\ndifferent observation paths. We use the proposed loss to train our object\nmatching model with only self-supervision. By extensive experiments on three\ntracking datasets (MOT17, PersonPath22, KITTI), we demonstrate that our method\noutperforms existing unsupervised methods with consistent margins on various\nevaluation metrics, and even achieves performance close to supervised methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05136v1",
    "published_date": "2024-04-08 01:29:10 UTC",
    "updated_date": "2024-04-08 01:29:10 UTC"
  }
]