[
  {
    "arxiv_id": "2501.02683v2",
    "title": "From Superficial Patterns to Semantic Understanding: Fine-Tuning Language Models on Contrast Sets",
    "authors": [
      "Daniel Petrov"
    ],
    "abstract": "Large-scale pre-trained language models have demonstrated high performance on\nstandard datasets for natural language inference (NLI) tasks. Unfortunately,\nthese evaluations can be misleading, as although the models can perform well on\nin-distribution data, they perform poorly on out-of-distribution test sets,\nsuch as contrast sets. Contrast sets consist of perturbed instances of data\nthat have very minor, but meaningful, changes to the input that alter the gold\nlabel, revealing how models can learn superficial patterns in the training data\nrather than learning more sophisticated language nuances. As an example, the\nELECTRA-small language model achieves nearly 90% accuracy on an SNLI dataset\nbut drops to 75% when tested on an out-of-distribution contrast set. The\nresearch carried out in this study explores how the robustness of a language\nmodel can be improved by exposing it to small amounts of more complex contrast\nsets during training to help it better learn language patterns. With this\napproach, the model recovers performance and achieves nearly 90% accuracy on\ncontrast sets, highlighting the importance of diverse and challenging training\ndata.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02683v2",
    "published_date": "2025-01-05 23:19:55 UTC",
    "updated_date": "2025-01-08 01:27:30 UTC"
  },
  {
    "arxiv_id": "2501.03282v1",
    "title": "From Aleatoric to Epistemic: Exploring Uncertainty Quantification Techniques in Artificial Intelligence",
    "authors": [
      "Tianyang Wang",
      "Yunze Wang",
      "Jun Zhou",
      "Benji Peng",
      "Xinyuan Song",
      "Charles Zhang",
      "Xintian Sun",
      "Qian Niu",
      "Junyu Liu",
      "Silin Chen",
      "Keyu Chen",
      "Ming Li",
      "Pohsun Feng",
      "Ziqian Bi",
      "Ming Liu",
      "Yichao Zhang",
      "Cheng Fei",
      "Caitlyn Heqi Yin",
      "Lawrence KQ Yan"
    ],
    "abstract": "Uncertainty quantification (UQ) is a critical aspect of artificial\nintelligence (AI) systems, particularly in high-risk domains such as\nhealthcare, autonomous systems, and financial technology, where decision-making\nprocesses must account for uncertainty. This review explores the evolution of\nuncertainty quantification techniques in AI, distinguishing between aleatoric\nand epistemic uncertainties, and discusses the mathematical foundations and\nmethods used to quantify these uncertainties. We provide an overview of\nadvanced techniques, including probabilistic methods, ensemble learning,\nsampling-based approaches, and generative models, while also highlighting\nhybrid approaches that integrate domain-specific knowledge. Furthermore, we\nexamine the diverse applications of UQ across various fields, emphasizing its\nimpact on decision-making, predictive accuracy, and system robustness. The\nreview also addresses key challenges such as scalability, efficiency, and\nintegration with explainable AI, and outlines future directions for research in\nthis rapidly developing area. Through this comprehensive survey, we aim to\nprovide a deeper understanding of UQ's role in enhancing the reliability,\nsafety, and trustworthiness of AI systems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.03282v1",
    "published_date": "2025-01-05 23:14:47 UTC",
    "updated_date": "2025-01-05 23:14:47 UTC"
  },
  {
    "arxiv_id": "2501.04046v1",
    "title": "Traits of a Leader: User Influence Level Prediction through Sociolinguistic Modeling",
    "authors": [
      "Denys Katerenchuk",
      "Rivka Levitan"
    ],
    "abstract": "Recognition of a user's influence level has attracted much attention as human\ninteractions move online. Influential users have the ability to sway others'\nopinions to achieve some goals. As a result, predicting users' level of\ninfluence can help to understand social networks, forecast trends, prevent\nmisinformation, etc. However, predicting user influence is a challenging\nproblem because the concept of influence is specific to a situation or a\ndomain, and user communications are limited to text. In this work, we define\nuser influence level as a function of community endorsement and develop a model\nthat significantly outperforms the baseline by leveraging demographic and\npersonality data. This approach consistently improves RankDCG scores across\neight different domains.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.04046v1",
    "published_date": "2025-01-05 22:37:19 UTC",
    "updated_date": "2025-01-05 22:37:19 UTC"
  },
  {
    "arxiv_id": "2501.02680v1",
    "title": "From thermodynamics to protein design: Diffusion models for biomolecule generation towards autonomous protein engineering",
    "authors": [
      "Wen-ran Li",
      "Xavier F. Cadet",
      "David Medina-Ortiz",
      "Mehdi D. Davari",
      "Ramanathan Sowdhamini",
      "Cedric Damour",
      "Yu Li",
      "Alain Miranville",
      "Frederic Cadet"
    ],
    "abstract": "Protein design with desirable properties has been a significant challenge for\nmany decades. Generative artificial intelligence is a promising approach and\nhas achieved great success in various protein generation tasks. Notably,\ndiffusion models stand out for their robust mathematical foundations and\nimpressive generative capabilities, offering unique advantages in certain\napplications such as protein design. In this review, we first give the\ndefinition and characteristics of diffusion models and then focus on two\nstrategies: Denoising Diffusion Probabilistic Models and Score-based Generative\nModels, where DDPM is the discrete form of SGM. Furthermore, we discuss their\napplications in protein design, peptide generation, drug discovery, and\nprotein-ligand interaction. Finally, we outline the future perspectives of\ndiffusion models to advance autonomous protein design and engineering. The E(3)\ngroup consists of all rotations, reflections, and translations in\nthree-dimensions. The equivariance on the E(3) group can keep the physical\nstability of the frame of each amino acid as much as possible, and we reflect\non how to keep the diffusion model E(3) equivariant for protein generation.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02680v1",
    "published_date": "2025-01-05 22:36:43 UTC",
    "updated_date": "2025-01-05 22:36:43 UTC"
  },
  {
    "arxiv_id": "2501.02666v2",
    "title": "Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network for Personalized Micro-Video Recommendation",
    "authors": [
      "Jinkun Han",
      "Wei Li",
      "Zhipeng Cai",
      "Yingshu Li"
    ],
    "abstract": "Micro-video recommendation is attracting global attention and becoming a\npopular daily service for people of all ages. Recently, Graph Neural\nNetworks-based micro-video recommendation has displayed performance improvement\nfor many kinds of recommendation tasks. However, the existing works fail to\nfully consider the characteristics of micro-videos, such as the high timeliness\nof news nature micro-video recommendation and sequential interactions of\nfrequently changed interests. In this paper, a novel Multi-aggregator\nTime-warping Heterogeneous Graph Neural Network (MTHGNN) is proposed for\npersonalized news nature micro-video recommendation based on sequential\nsessions, where characteristics of micro-videos are comprehensively studied,\nusers' preference is mined via multi-aggregator, the temporal and dynamic\nchanges of users' preference are captured, and timeliness is considered.\nThrough the comparison with the state-of-the-arts, the experimental results\nvalidate the superiority of our MTHGNN model.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02666v2",
    "published_date": "2025-01-05 21:14:35 UTC",
    "updated_date": "2025-03-21 16:08:18 UTC"
  },
  {
    "arxiv_id": "2501.02654v2",
    "title": "Tougher Text, Smarter Models: Raising the Bar for Adversarial Defence Benchmarks",
    "authors": [
      "Yang Wang",
      "Chenghua Lin"
    ],
    "abstract": "Recent advancements in natural language processing have highlighted the\nvulnerability of deep learning models to adversarial attacks. While various\ndefence mechanisms have been proposed, there is a lack of comprehensive\nbenchmarks that evaluate these defences across diverse datasets, models, and\ntasks. In this work, we address this gap by presenting an extensive benchmark\nfor textual adversarial defence that significantly expands upon previous work.\nOur benchmark incorporates a wide range of datasets, evaluates state-of-the-art\ndefence mechanisms, and extends the assessment to include critical tasks such\nas single-sentence classification, similarity and paraphrase identification,\nnatural language inference, and commonsense reasoning. This work not only\nserves as a valuable resource for researchers and practitioners in the field of\nadversarial robustness but also identifies key areas for future research in\ntextual adversarial defence. By establishing a new standard for benchmarking in\nthis domain, we aim to accelerate progress towards more robust and reliable\nnatural language processing systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Will be presented as an oral in-person presentation at the conference\n  of COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.02654v2",
    "published_date": "2025-01-05 20:39:52 UTC",
    "updated_date": "2025-01-08 14:53:41 UTC"
  },
  {
    "arxiv_id": "2501.02649v1",
    "title": "Tighnari: Multi-modal Plant Species Prediction Based on Hierarchical Cross-Attention Using Graph-Based and Vision Backbone-Extracted Features",
    "authors": [
      "Haixu Liu",
      "Penghao Jiang",
      "Zerui Tao",
      "Muyan Wan",
      "Qiuzhuang Sun"
    ],
    "abstract": "Predicting plant species composition in specific spatiotemporal contexts\nplays an important role in biodiversity management and conservation, as well as\nin improving species identification tools. Our work utilizes 88,987 plant\nsurvey records conducted in specific spatiotemporal contexts across Europe. We\nalso use the corresponding satellite images, time series data, climate time\nseries, and other rasterized environmental data such as land cover, human\nfootprint, bioclimatic, and soil variables as training data to train the model\nto predict the outcomes of 4,716 plant surveys. We propose a feature\nconstruction and result correction method based on the graph structure. Through\ncomparative experiments, we select the best-performing backbone networks for\nfeature extraction in both temporal and image modalities. In this process, we\nbuilt a backbone network based on the Swin-Transformer Block for extracting\ntemporal Cubes features. We then design a hierarchical cross-attention\nmechanism capable of robustly fusing features from multiple modalities. During\ntraining, we adopt a 10-fold cross-fusion method based on fine-tuning and use a\nThreshold Top-K method for post-processing. Ablation experiments demonstrate\nthe improvements in model performance brought by our proposed solution\npipeline.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR GeolifeCLEF",
    "pdf_url": "http://arxiv.org/pdf/2501.02649v1",
    "published_date": "2025-01-05 20:30:07 UTC",
    "updated_date": "2025-01-05 20:30:07 UTC"
  },
  {
    "arxiv_id": "2501.02648v2",
    "title": "Representation Learning of Lab Values via Masked AutoEncoder",
    "authors": [
      "David Restrepo",
      "Chenwei Wu",
      "Yueran Jia",
      "Jaden K. Sun",
      "Jack Gallifant",
      "Catherine G. Bielick",
      "Yugang Jia",
      "Leo A. Celi"
    ],
    "abstract": "Accurate imputation of missing laboratory values in electronic health records\n(EHRs) is critical to enable robust clinical predictions and reduce biases in\nAI systems in healthcare. Existing methods, such as variational autoencoders\n(VAEs) and decision tree-based approaches such as XGBoost, struggle to model\nthe complex temporal and contextual dependencies in EHR data, mainly in\nunderrepresented groups. In this work, we propose Lab-MAE, a novel\ntransformer-based masked autoencoder framework that leverages self-supervised\nlearning for the imputation of continuous sequential lab values. Lab-MAE\nintroduces a structured encoding scheme that jointly models laboratory test\nvalues and their corresponding timestamps, enabling explicit capturing temporal\ndependencies. Empirical evaluation on the MIMIC-IV dataset demonstrates that\nLab-MAE significantly outperforms the state-of-the-art baselines such as\nXGBoost across multiple metrics, including root mean square error (RMSE),\nR-squared (R2), and Wasserstein distance (WD). Notably, Lab-MAE achieves\nequitable performance across demographic groups of patients, advancing fairness\nin clinical predictions. We further investigate the role of follow-up\nlaboratory values as potential shortcut features, revealing Lab-MAE's\nrobustness in scenarios where such data is unavailable. The findings suggest\nthat our transformer-based architecture, adapted to the characteristics of the\nEHR data, offers a foundation model for more accurate and fair clinical\nimputation models. In addition, we measure and compare the carbon footprint of\nLab-MAE with the baseline XGBoost model, highlighting its environmental\nrequirements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages main text, 8 appendix",
    "pdf_url": "http://arxiv.org/pdf/2501.02648v2",
    "published_date": "2025-01-05 20:26:49 UTC",
    "updated_date": "2025-01-09 11:17:01 UTC"
  },
  {
    "arxiv_id": "2501.02647v1",
    "title": "Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions",
    "authors": [
      "Ellis Solaiman",
      "Christa Awad"
    ],
    "abstract": "This paper critically reviews the integration of Artificial Intelligence (AI)\nand blockchain technologies in the context of Medical Internet of Things\n(MedIoT) applications, where they collectively promise to revolutionize\nhealthcare delivery. By examining current research, we underscore AI's\npotential in advancing diagnostics and patient care, alongside blockchain's\ncapacity to bolster data security and patient privacy. We focus particularly on\nthe imperative to cultivate trust and ensure reliability within these systems.\nOur review highlights innovative solutions for managing healthcare data and\nchallenges such as ensuring scalability, maintaining privacy, and promoting\nethical practices within the MedIoT domain. We present a vision for integrating\nAI-driven insights with blockchain security in healthcare, offering a\ncomprehensive review of current research and future directions. We conclude\nwith a set of identified research gaps and propose that addressing these is\ncrucial for achieving the dependable, secure, and patient -centric MedIoT\napplications of tomorrow.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02647v1",
    "published_date": "2025-01-05 20:21:22 UTC",
    "updated_date": "2025-01-05 20:21:22 UTC"
  },
  {
    "arxiv_id": "2501.02629v2",
    "title": "Layer-Level Self-Exposure and Patch: Affirmative Token Mitigation for Jailbreak Attack Defense",
    "authors": [
      "Yang Ouyang",
      "Hengrui Gu",
      "Shuhang Lin",
      "Wenyue Hua",
      "Jie Peng",
      "Bhavya Kailkhura",
      "Meijun Gao",
      "Tianlong Chen",
      "Kaixiong Zhou"
    ],
    "abstract": "As large language models (LLMs) are increasingly deployed in diverse\napplications, including chatbot assistants and code generation, aligning their\nbehavior with safety and ethical standards has become paramount. However,\njailbreak attacks, which exploit vulnerabilities to elicit unintended or\nharmful outputs, threaten LLMs' safety significantly. In this paper, we\nintroduce Layer-AdvPatcher, a novel methodology designed to defend against\njailbreak attacks by utilizing an unlearning strategy to patch specific layers\nwithin LLMs through self-augmented datasets. Our insight is that certain\nlayer(s), tend to produce affirmative tokens when faced with harmful prompts.\nBy identifying these layers and adversarially exposing them to generate more\nharmful data, one can understand their inherent and diverse vulnerabilities to\nattacks. With these exposures, we then \"unlearn\" these issues, reducing the\nimpact of affirmative tokens and hence minimizing jailbreak risks while keeping\nthe model's responses to safe queries intact. We conduct extensive experiments\non two models, four benchmark datasets, and multiple state-of-the-art jailbreak\nattacks to demonstrate the efficacy of our approach. Results indicate that our\nframework reduces the harmfulness and attack success rate of jailbreak attacks\nwithout compromising utility for benign queries compared to recent defense\nmethods. Our code is publicly available at:\nhttps://github.com/oyy2000/LayerAdvPatcher",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages, 4 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2501.02629v2",
    "published_date": "2025-01-05 19:06:03 UTC",
    "updated_date": "2025-02-12 04:55:19 UTC"
  },
  {
    "arxiv_id": "2501.02628v1",
    "title": "Cracks in The Stack: Hidden Vulnerabilities and Licensing Risks in LLM Pre-Training Datasets",
    "authors": [
      "Mahmoud Jahanshahi",
      "Audris Mockus"
    ],
    "abstract": "A critical part of creating code suggestion systems is the pre-training of\nLarge Language Models on vast amounts of source code and natural language text,\noften of questionable origin or quality. This may contribute to the presence of\nbugs and vulnerabilities in code generated by LLMs. While efforts to identify\nbugs at or after code generation exist, it is preferable to pre-train or\nfine-tune LLMs on curated, high-quality, and compliant datasets. The need for\nvast amounts of training data necessitates that such curation be automated,\nminimizing human intervention.\n  We propose an automated source code autocuration technique that leverages the\ncomplete version history of open-source software projects to improve the\nquality of training data. This approach leverages the version history of all\nOSS projects to identify training data samples that have been modified or have\nundergone changes in at least one OSS project, and pinpoint a subset of samples\nthat include fixes for bugs or vulnerabilities. We evaluate this method using\nThe Stack v2 dataset, and find that 17% of the code versions in the dataset\nhave newer versions, with 17% of those representing bug fixes, including 2.36%\naddressing known CVEs. The deduplicated version of Stack v2 still includes\nblobs vulnerable to 6,947 known CVEs. Furthermore, 58% of the blobs in the\ndataset were never modified after creation, suggesting they likely represent\nsoftware with minimal or no use. Misidentified blob origins present an\nadditional challenge, as they lead to the inclusion of non-permissively\nlicensed code, raising serious compliance concerns.\n  By addressing these issues, the training of new models can avoid perpetuating\nbuggy code patterns or license violations. We expect our results to inspire\nprocess improvements for automated data curation, with the potential to enhance\nthe reliability of outputs generated by AI tools.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted in the Second International Workshop on Large Language\n  Models for Code (LLM4Code 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.02628v1",
    "published_date": "2025-01-05 18:54:25 UTC",
    "updated_date": "2025-01-05 18:54:25 UTC"
  },
  {
    "arxiv_id": "2501.02621v1",
    "title": "LLMs Help Alleviate the Cross-Subject Variability in Brain Signal and Language Alignment",
    "authors": [
      "Yifei Liu",
      "Hengwei Ye",
      "Shuhang Li"
    ],
    "abstract": "Decoding human activity from EEG signals has long been a popular research\ntopic. While recent studies have increasingly shifted focus from single-subject\nto cross-subject analysis, few have explored the model's ability to perform\nzero-shot predictions on EEG signals from previously unseen subjects. This\nresearch aims to investigate whether deep learning methods can capture\nsubject-independent semantic information inherent in human EEG signals. Such\ninsights are crucial for Brain-Computer Interfaces (BCI) because, on one hand,\nthey demonstrate the model's robustness against subject-specific temporal\nbiases, and on the other, they significantly enhance the generalizability of\ndownstream tasks. We employ Large Language Models (LLMs) as denoising agents to\nextract subject-independent semantic features from noisy EEG signals.\nExperimental results, including ablation studies, highlight the pivotal role of\nLLMs in decoding subject-independent semantic information from noisy EEG data.\nWe hope our findings will contribute to advancing BCI research and assist both\nacademia and industry in applying EEG signals to a broader range of\napplications.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02621v1",
    "published_date": "2025-01-05 18:29:39 UTC",
    "updated_date": "2025-01-05 18:29:39 UTC"
  },
  {
    "arxiv_id": "2501.02600v1",
    "title": "TAPAS: Thermal- and Power-Aware Scheduling for LLM Inference in Cloud Platforms",
    "authors": [
      "Jovan Stojkovic",
      "Chaojie Zhang",
      "Íñigo Goiri",
      "Esha Choukse",
      "Haoran Qiu",
      "Rodrigo Fonseca",
      "Josep Torrellas",
      "Ricardo Bianchini"
    ],
    "abstract": "The rising demand for generative large language models (LLMs) poses\nchallenges for thermal and power management in cloud datacenters. Traditional\ntechniques often are inadequate for LLM inference due to the fine-grained,\nmillisecond-scale execution phases, each with distinct performance, thermal,\nand power profiles. Additionally, LLM inference workloads are sensitive to\nvarious configuration parameters (e.g., model parallelism, size, and\nquantization) that involve trade-offs between performance, temperature, power,\nand output quality. Moreover, clouds often co-locate SaaS and IaaS workloads,\neach with different levels of visibility and flexibility. We propose TAPAS, a\nthermal- and power-aware framework designed for LLM inference clusters in the\ncloud. TAPAS enhances cooling and power oversubscription capabilities, reducing\nthe total cost of ownership (TCO) while effectively handling emergencies (e.g.,\ncooling and power failures). The system leverages historical temperature and\npower data, along with the adaptability of SaaS workloads, to: (1) efficiently\nplace new GPU workload VMs within cooling and power constraints, (2) route LLM\ninference requests across SaaS VMs, and (3) reconfigure SaaS VMs to manage load\nspikes and emergency situations. Our evaluation on a large GPU cluster\ndemonstrates significant reductions in thermal and power throttling events,\nboosting system efficiency.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02600v1",
    "published_date": "2025-01-05 16:51:17 UTC",
    "updated_date": "2025-01-05 16:51:17 UTC"
  },
  {
    "arxiv_id": "2501.02599v1",
    "title": "Empowering Bengali Education with AI: Solving Bengali Math Word Problems through Transformer Models",
    "authors": [
      "Jalisha Jashim Era",
      "Bidyarthi Paul",
      "Tahmid Sattar Aothoi",
      "Mirazur Rahman Zim",
      "Faisal Muhammad Shah"
    ],
    "abstract": "Mathematical word problems (MWPs) involve the task of converting textual\ndescriptions into mathematical equations. This poses a significant challenge in\nnatural language processing, particularly for low-resource languages such as\nBengali. This paper addresses this challenge by developing an innovative\napproach to solving Bengali MWPs using transformer-based models, including\nBasic Transformer, mT5, BanglaT5, and mBART50. To support this effort, the\n\"PatiGonit\" dataset was introduced, containing 10,000 Bengali math problems,\nand these models were fine-tuned to translate the word problems into equations\naccurately. The evaluation revealed that the mT5 model achieved the highest\naccuracy of 97.30%, demonstrating the effectiveness of transformer models in\nthis domain. This research marks a significant step forward in Bengali natural\nlanguage processing, offering valuable methodologies and resources for\neducational AI tools. By improving math education, it also supports the\ndevelopment of advanced problem-solving skills for Bengali-speaking students.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02599v1",
    "published_date": "2025-01-05 16:50:55 UTC",
    "updated_date": "2025-01-05 16:50:55 UTC"
  },
  {
    "arxiv_id": "2501.03279v1",
    "title": "Revolutionizing Encrypted Traffic Classification with MH-Net: A Multi-View Heterogeneous Graph Model",
    "authors": [
      "Haozhen Zhang",
      "Haodong Yue",
      "Xi Xiao",
      "Le Yu",
      "Qing Li",
      "Zhen Ling",
      "Ye Zhang"
    ],
    "abstract": "With the growing significance of network security, the classification of\nencrypted traffic has emerged as an urgent challenge. Traditional byte-based\ntraffic analysis methods are constrained by the rigid granularity of\ninformation and fail to fully exploit the diverse correlations between bytes.\nTo address these limitations, this paper introduces MH-Net, a novel approach\nfor classifying network traffic that leverages multi-view heterogeneous traffic\ngraphs to model the intricate relationships between traffic bytes. The essence\nof MH-Net lies in aggregating varying numbers of traffic bits into multiple\ntypes of traffic units, thereby constructing multi-view traffic graphs with\ndiverse information granularities. By accounting for different types of byte\ncorrelations, such as header-payload relationships, MH-Net further endows the\ntraffic graph with heterogeneity, significantly enhancing model performance.\nNotably, we employ contrastive learning in a multi-task manner to strengthen\nthe robustness of the learned traffic unit representations. Experiments\nconducted on the ISCX and CIC-IoT datasets for both the packet-level and\nflow-level traffic classification tasks demonstrate that MH-Net achieves the\nbest overall performance compared to dozens of SOTA methods.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by AAAI 2025. The code is available at\n  https://github.com/ViktorAxelsen/MH-Net. arXiv admin note: text overlap with\n  arXiv:2402.07501",
    "pdf_url": "http://arxiv.org/pdf/2501.03279v1",
    "published_date": "2025-01-05 16:50:41 UTC",
    "updated_date": "2025-01-05 16:50:41 UTC"
  },
  {
    "arxiv_id": "2501.02593v3",
    "title": "Evolving Skeletons: Motion Dynamics in Action Recognition",
    "authors": [
      "Jushang Qiu",
      "Lei Wang"
    ],
    "abstract": "Skeleton-based action recognition has gained significant attention for its\nability to efficiently represent spatiotemporal information in a lightweight\nformat. Most existing approaches use graph-based models to process skeleton\nsequences, where each pose is represented as a skeletal graph structured around\nhuman physical connectivity. Among these, the Spatiotemporal Graph\nConvolutional Network (ST-GCN) has become a widely used framework.\nAlternatively, hypergraph-based models, such as the Hyperformer, capture\nhigher-order correlations, offering a more expressive representation of complex\njoint interactions. A recent advancement, termed Taylor Videos, introduces\nmotion-enhanced skeleton sequences by embedding motion concepts, providing a\nfresh perspective on interpreting human actions in skeleton-based action\nrecognition. In this paper, we conduct a comprehensive evaluation of both\ntraditional skeleton sequences and Taylor-transformed skeletons using ST-GCN\nand Hyperformer models on the NTU-60 and NTU-120 datasets. We compare skeletal\ngraph and hypergraph representations, analyzing static poses against\nmotion-injected poses. Our findings highlight the strengths and limitations of\nTaylor-transformed skeletons, demonstrating their potential to enhance motion\ndynamics while exposing current challenges in fully using their benefits. This\nstudy underscores the need for innovative skeletal modelling techniques to\neffectively handle motion-rich data and advance the field of action\nrecognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the Companion Proceedings of the ACM Web Conference (WWW\n  Companion 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.02593v3",
    "published_date": "2025-01-05 16:16:10 UTC",
    "updated_date": "2025-02-24 04:02:55 UTC"
  },
  {
    "arxiv_id": "2501.02584v1",
    "title": "Efficient Architectures for High Resolution Vision-Language Models",
    "authors": [
      "Miguel Carvalho",
      "Bruno Martins"
    ],
    "abstract": "Vision-Language Models (VLMs) have recently experienced significant\nadvancements. However, challenges persist in the accurate recognition of fine\ndetails within high resolution images, which limits performance in multiple\ntasks. This work introduces Pheye, a novel architecture that efficiently\nprocesses high-resolution images while training fewer parameters than similarly\nsized VLMs. Notably, Pheye achieves a high efficiency while maintaining strong\nperformance, particularly in tasks that demand fine-grained image understanding\nand/or the handling of scene-text.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.02584v1",
    "published_date": "2025-01-05 15:41:26 UTC",
    "updated_date": "2025-01-05 15:41:26 UTC"
  },
  {
    "arxiv_id": "2501.02572v1",
    "title": "Energy Optimization of Multi-task DNN Inference in MEC-assisted XR Devices: A Lyapunov-Guided Reinforcement Learning Approach",
    "authors": [
      "Yanzan Sun",
      "Jiacheng Qiu",
      "Guangjin Pan",
      "Shugong Xu",
      "Shunqing Zhang",
      "Xiaoyun Wang",
      "Shuangfeng Han"
    ],
    "abstract": "Extended reality (XR), blending virtual and real worlds, is a key application\nof future networks. While AI advancements enhance XR capabilities, they also\nimpose significant computational and energy challenges on lightweight XR\ndevices. In this paper, we developed a distributed queue model for multi-task\nDNN inference, addressing issues of resource competition and queue coupling. In\nresponse to the challenges posed by the high energy consumption and limited\nresources of XR devices, we designed a dual time-scale joint optimization\nstrategy for model partitioning and resource allocation, formulated as a\nbi-level optimization problem. This strategy aims to minimize the total energy\nconsumption of XR devices while ensuring queue stability and adhering to\ncomputational and communication resource constraints. To tackle this problem,\nwe devised a Lyapunov-guided Proximal Policy Optimization algorithm, named\nLyaPPO. Numerical results demonstrate that the LyaPPO algorithm outperforms the\nbaselines, achieving energy conservation of 24.79% to 46.14% under varying\nresource capacities. Specifically, the proposed algorithm reduces the energy\nconsumption of XR devices by 24.29% to 56.62% compared to baseline algorithms.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI",
    "comment": "13 pages, 7 figures. This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2501.02572v1",
    "published_date": "2025-01-05 15:07:41 UTC",
    "updated_date": "2025-01-05 15:07:41 UTC"
  },
  {
    "arxiv_id": "2501.02570v1",
    "title": "Decoding fMRI Data into Captions using Prefix Language Modeling",
    "authors": [
      "Vyacheslav Shen",
      "Kassymzhomart Kunanbayev",
      "Dae-Shik Kim"
    ],
    "abstract": "With the advancements in Large Language and Latent Diffusion models, brain\ndecoding has achieved remarkable results in recent years. The works on the NSD\ndataset, with stimuli images from the COCO dataset, leverage the embeddings\nfrom the CLIP model for image reconstruction and GIT for captioning. However,\nthe current captioning approach introduces the challenge of potential data\ncontamination given that the GIT model was trained on the COCO dataset. In this\nwork, we present an alternative method for decoding brain signals into image\ncaptions by predicting a DINOv2 model's embedding of an image from the\ncorresponding fMRI signal and then providing its [CLS] token as the prefix to\nthe GPT-2 language model which decreases computational requirements\nconsiderably. Additionally, instead of commonly used Linear Regression, we\nexplore 3D Convolutional Neural Network mapping of fMRI signals to image\nembedding space for better accounting positional information of voxels.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 2 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2501.02570v1",
    "published_date": "2025-01-05 15:06:25 UTC",
    "updated_date": "2025-01-05 15:06:25 UTC"
  },
  {
    "arxiv_id": "2501.02564v3",
    "title": "Balanced Multi-view Clustering",
    "authors": [
      "Zhenglai Li",
      "Jun Wang",
      "Chang Tang",
      "Xinzhong Zhu",
      "Wei Zhang",
      "Xinwang Liu"
    ],
    "abstract": "Multi-view clustering (MvC) aims to integrate information from different\nviews to enhance the capability of the model in capturing the underlying data\nstructures. The widely used joint training paradigm in MvC is potentially not\nfully leverage the multi-view information, since the imbalanced and\nunder-optimized view-specific features caused by the uniform learning objective\nfor all views. For instance, particular views with more discriminative\ninformation could dominate the learning process in the joint training paradigm,\nleading to other views being under-optimized. To alleviate this issue, we first\nanalyze the imbalanced phenomenon in the joint-training paradigm of multi-view\nclustering from the perspective of gradient descent for each view-specific\nfeature extractor. Then, we propose a novel balanced multi-view clustering\n(BMvC) method, which introduces a view-specific contrastive regularization\n(VCR) to modulate the optimization of each view. Concretely, VCR preserves the\nsample similarities captured from the joint features and view-specific ones\ninto the clustering distributions corresponding to view-specific features to\nenhance the learning process of view-specific feature extractors. Additionally,\na theoretical analysis is provided to illustrate that VCR adaptively modulates\nthe magnitudes of gradients for updating the parameters of view-specific\nfeature extractors to achieve a balanced multi-view learning procedure. In such\na manner, BMvC achieves a better trade-off between the exploitation of\nview-specific patterns and the exploration of view-invariance patterns to fully\nlearn the multi-view information for the clustering task. Finally, a set of\nexperiments are conducted to verify the superiority of the proposed method\ncompared with state-of-the-art approaches on eight benchmark MvC datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02564v3",
    "published_date": "2025-01-05 14:42:47 UTC",
    "updated_date": "2025-02-04 11:01:02 UTC"
  },
  {
    "arxiv_id": "2501.02559v1",
    "title": "KM-UNet KAN Mamba UNet for medical image segmentation",
    "authors": [
      "Yibo Zhang"
    ],
    "abstract": "Medical image segmentation is a critical task in medical imaging analysis.\nTraditional CNN-based methods struggle with modeling long-range dependencies,\nwhile Transformer-based models, despite their success, suffer from quadratic\ncomputational complexity. To address these limitations, we propose KM-UNet, a\nnovel U-shaped network architecture that combines the strengths of\nKolmogorov-Arnold Networks (KANs) and state-space models (SSMs). KM-UNet\nleverages the Kolmogorov-Arnold representation theorem for efficient feature\nrepresentation and SSMs for scalable long-range modeling, achieving a balance\nbetween accuracy and computational efficiency. We evaluate KM-UNet on five\nbenchmark datasets: ISIC17, ISIC18, CVC, BUSI, and GLAS. Experimental results\ndemonstrate that KM-UNet achieves competitive performance compared to\nstate-of-the-art methods in medical image segmentation tasks. To the best of\nour knowledge, KM-UNet is the first medical image segmentation framework\nintegrating KANs and SSMs. This work provides a valuable baseline and new\ninsights for the development of more efficient and interpretable medical image\nsegmentation systems. The code is open source at\nhttps://github.com/2760613195/KM_UNet\n  Keywords:KAN,Manba, state-space models,UNet, Medical image segmentation, Deep\nlearning",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02559v1",
    "published_date": "2025-01-05 14:21:07 UTC",
    "updated_date": "2025-01-05 14:21:07 UTC"
  },
  {
    "arxiv_id": "2501.02548v1",
    "title": "AMM: Adaptive Modularized Reinforcement Model for Multi-city Traffic Signal Control",
    "authors": [
      "Zherui Huang",
      "Yicheng Liu",
      "Chumeng Liang",
      "Guanjie Zheng"
    ],
    "abstract": "Traffic signal control (TSC) is an important and widely studied direction.\nRecently, reinforcement learning (RL) methods have been used to solve TSC\nproblems and achieve superior performance over conventional TSC methods.\nHowever, applying RL methods to the real world is challenging due to the huge\ncost of experiments in real-world traffic environments. One possible solution\nis TSC domain adaptation, which adapts trained models to target environments\nand reduces the number of interactions and the training cost. However, existing\nTSC domain adaptation methods still face two major issues: the lack of\nconsideration for differences across cities and the low utilization of\nmulti-city data.\n  To solve aforementioned issues, we propose an approach named Adaptive\nModularized Model (AMM). By modularizing TSC problems and network models, we\novercome the challenge of possible changes in environmental observations. We\nalso aggregate multi-city experience through meta-learning. We conduct\nextensive experiments on different cities and show that AMM can achieve\nexcellent performance with limited interactions in target environments and\noutperform existing methods. We also demonstrate the feasibility and\ngeneralizability of our method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02548v1",
    "published_date": "2025-01-05 13:59:08 UTC",
    "updated_date": "2025-01-05 13:59:08 UTC"
  },
  {
    "arxiv_id": "2501.02546v1",
    "title": "TreeMatch: A Fully Unsupervised WSD System Using Dependency Knowledge on a Specific Domain",
    "authors": [
      "Andrew Tran",
      "Chris Bowes",
      "David Brown",
      "Ping Chen",
      "Max Choly",
      "Wei Ding"
    ],
    "abstract": "Word sense disambiguation (WSD) is one of the main challenges in\nComputational Linguistics. TreeMatch is a WSD system originally developed using\ndata from SemEval 2007 Task 7 (Coarse-grained English All-words Task) that has\nbeen adapted for use in SemEval 2010 Task 17 (All-words Word Sense\nDisambiguation on a Specific Domain). The system is based on a fully\nunsupervised method using dependency knowledge drawn from a domain specific\nknowledge base that was built for this task. When evaluated on the task, the\nsystem precision performs above the Most Frequent Selection baseline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02546v1",
    "published_date": "2025-01-05 13:56:04 UTC",
    "updated_date": "2025-01-05 13:56:04 UTC"
  },
  {
    "arxiv_id": "2501.02535v1",
    "title": "A completely uniform transformer for parity",
    "authors": [
      "Alexander Kozachinskiy",
      "Tomasz Steifer"
    ],
    "abstract": "We construct a 3-layer constant-dimension transformer, recognizing the parity\nlanguage, where neither parameter matrices nor the positional encoding depend\non the input length. This improves upon a construction of Chiang and Cholak who\nuse a positional encoding, depending on the input length (but their\nconstruction has 2 layers).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.02535v1",
    "published_date": "2025-01-05 13:32:13 UTC",
    "updated_date": "2025-01-05 13:32:13 UTC"
  },
  {
    "arxiv_id": "2501.02532v1",
    "title": "Evaluating Large Language Models Against Human Annotators in Latent Content Analysis: Sentiment, Political Leaning, Emotional Intensity, and Sarcasm",
    "authors": [
      "Ljubisa Bojic",
      "Olga Zagovora",
      "Asta Zelenkauskaite",
      "Vuk Vukovic",
      "Milan Cabarkapa",
      "Selma Veseljević Jerkovic",
      "Ana Jovančevic"
    ],
    "abstract": "In the era of rapid digital communication, vast amounts of textual data are\ngenerated daily, demanding efficient methods for latent content analysis to\nextract meaningful insights. Large Language Models (LLMs) offer potential for\nautomating this process, yet comprehensive assessments comparing their\nperformance to human annotators across multiple dimensions are lacking. This\nstudy evaluates the reliability, consistency, and quality of seven\nstate-of-the-art LLMs, including variants of OpenAI's GPT-4, Gemini, Llama, and\nMixtral, relative to human annotators in analyzing sentiment, political\nleaning, emotional intensity, and sarcasm detection. A total of 33 human\nannotators and eight LLM variants assessed 100 curated textual items,\ngenerating 3,300 human and 19,200 LLM annotations, with LLMs evaluated across\nthree time points to examine temporal consistency. Inter-rater reliability was\nmeasured using Krippendorff's alpha, and intra-class correlation coefficients\nassessed consistency over time. The results reveal that both humans and LLMs\nexhibit high reliability in sentiment analysis and political leaning\nassessments, with LLMs demonstrating higher internal consistency than humans.\nIn emotional intensity, LLMs displayed higher agreement compared to humans,\nthough humans rated emotional intensity significantly higher. Both groups\nstruggled with sarcasm detection, evidenced by low agreement. LLMs showed\nexcellent temporal consistency across all dimensions, indicating stable\nperformance over time. This research concludes that LLMs, especially GPT-4, can\neffectively replicate human analysis in sentiment and political leaning,\nalthough human expertise remains essential for emotional intensity\ninterpretation. The findings demonstrate the potential of LLMs for consistent\nand high-quality performance in certain areas of latent content analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.02532v1",
    "published_date": "2025-01-05 13:28:15 UTC",
    "updated_date": "2025-01-05 13:28:15 UTC"
  },
  {
    "arxiv_id": "2501.02523v1",
    "title": "Face-MakeUp: Multimodal Facial Prompts for Text-to-Image Generation",
    "authors": [
      "Dawei Dai",
      "Mingming Jia",
      "Yinxiu Zhou",
      "Hang Xing",
      "Chenghang Li"
    ],
    "abstract": "Facial images have extensive practical applications. Although the current\nlarge-scale text-image diffusion models exhibit strong generation capabilities,\nit is challenging to generate the desired facial images using only text prompt.\nImage prompts are a logical choice. However, current methods of this type\ngenerally focus on general domain. In this paper, we aim to optimize image\nmakeup techniques to generate the desired facial images. Specifically, (1) we\nbuilt a dataset of 4 million high-quality face image-text pairs\n(FaceCaptionHQ-4M) based on LAION-Face to train our Face-MakeUp model; (2) to\nmaintain consistency with the reference facial image, we extract/learn\nmulti-scale content features and pose features for the facial image,\nintegrating these into the diffusion model to enhance the preservation of\nfacial identity features for diffusion models. Validation on two face-related\ntest datasets demonstrates that our Face-MakeUp can achieve the best\ncomprehensive performance.All codes are available\nat:https://github.com/ddw2AIGROUP2CQUPT/Face-MakeUp",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02523v1",
    "published_date": "2025-01-05 12:46:31 UTC",
    "updated_date": "2025-01-05 12:46:31 UTC"
  },
  {
    "arxiv_id": "2501.02521v1",
    "title": "Remote Inference over Dynamic Links via Adaptive Rate Deep Task-Oriented Vector Quantization",
    "authors": [
      "Eyal Fishel",
      "May Malka",
      "Shai Ginzach",
      "Nir Shlezinger"
    ],
    "abstract": "A broad range of technologies rely on remote inference, wherein data acquired\nis conveyed over a communication channel for inference in a remote server.\nCommunication between the participating entities is often carried out over\nrate-limited channels, necessitating data compression for reducing latency.\nWhile deep learning facilitates joint design of the compression mapping along\nwith encoding and inference rules, existing learned compression mechanisms are\nstatic, and struggle in adapting their resolution to changes in channel\nconditions and to dynamic links. To address this, we propose Adaptive Rate\nTask-Oriented Vector Quantization (ARTOVeQ), a learned compression mechanism\nthat is tailored for remote inference over dynamic links. ARTOVeQ is based on\ndesigning nested codebooks along with a learning algorithm employing\nprogressive learning. We show that ARTOVeQ extends to support low-latency\ninference that is gradually refined via successive refinement principles, and\nthat it enables the simultaneous usage of multiple resolutions when conveying\nhigh-dimensional data. Numerical results demonstrate that the proposed scheme\nyields remote deep inference that operates with multiple rates, supports a\nbroad range of bit budgets, and facilitates rapid inference that gradually\nimproves with more bits exchanged, while approaching the performance of\nsingle-rate deep quantization methods.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "13 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.02521v1",
    "published_date": "2025-01-05 12:38:13 UTC",
    "updated_date": "2025-01-05 12:38:13 UTC"
  },
  {
    "arxiv_id": "2502.00005v1",
    "title": "A Study about Distribution and Acceptance of Conversational Agents for Mental Health in Germany: Keep the Human in the Loop?",
    "authors": [
      "Christina Lukas"
    ],
    "abstract": "Good mental health enables individuals to cope with the normal stresses of\nlife. In Germany, approximately one-quarter of the adult population is affected\nby mental illnesses. Teletherapy and digital health applications are available\nto bridge gaps in care and relieve healthcare professionals. The acceptance of\nthese tools is a strongly influencing factor for their effectiveness, which\nalso needs to be evaluated for AI-based conversational agents (CAs) (e. g.\nChatGPT, Siri) to assess the risks and potential for integration into\ntherapeutic practice. This study investigates the perspectives of both the\ngeneral population and healthcare professionals with the following questions:\n1. How frequently are CAs used for mental health? 2. How high is the acceptance\nof CAs in the field of mental health? 3. To what extent is the use of CAs in\ncounselling, diagnosis, and treatment acceptable? To address these questions,\ntwo quantitative online surveys were conducted with 444 participants from the\ngeneral population and 351 healthcare professionals. Statistical analyses show\nthat 27 % of the surveyed population already confide their concerns to CAs. Not\nonly experience with this technology but also experience with telemedicine\nshows a higher acceptance among both groups for using CAs for mental health.\nAdditionally, participants from the general population were more likely to\nsupport CAs as companions controlled by healthcare professionals rather than as\nadditional experts for the professionals. CAs have the potential to support\nmental health, particularly in counselling. Future research should examine the\ninfluence of different communication media and further possibilities of\naugmented intelligence. With the right balance between technology and human\ncare, integration into patient-professional interaction can be achieved.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Master's thesis",
    "pdf_url": "http://arxiv.org/pdf/2502.00005v1",
    "published_date": "2025-01-05 12:20:18 UTC",
    "updated_date": "2025-01-05 12:20:18 UTC"
  },
  {
    "arxiv_id": "2501.02508v1",
    "title": "PTEENet: Post-Trained Early-Exit Neural Networks Augmentation for Inference Cost Optimization",
    "authors": [
      "Assaf Lahiany",
      "Yehudit Aperstein"
    ],
    "abstract": "For many practical applications, a high computational cost of inference over\ndeep network architectures might be unacceptable. A small degradation in the\noverall inference accuracy might be a reasonable price to pay for a significant\nreduction in the required computational resources. In this work, we describe a\nmethod for introducing \"shortcuts\" into the DNN feedforward inference process\nby skipping costly feedforward computations whenever possible. The proposed\nmethod is based on the previously described BranchyNet (Teerapittayanon et al.,\n2016) and the EEnet (Demir, 2019) architectures that jointly train the main\nnetwork and early exit branches. We extend those methods by attaching branches\nto pre-trained models and, thus, eliminating the need to alter the original\nweights of the network. We also suggest a new branch architecture based on\nconvolutional building blocks to allow enough training capacity when applied on\nlarge DNNs. The proposed architecture includes confidence heads that are used\nfor predicting the confidence level in the corresponding early exits. By\ndefining adjusted thresholds on these confidence extensions, we can control in\nreal-time the amount of data exiting from each branch and the overall tradeoff\nbetween speed and accuracy of our model. In our experiments, we evaluate our\nmethod using image datasets (SVHN and CIFAR10) and several DNN architectures\n(ResNet, DenseNet, VGG) with varied depth. Our results demonstrate that the\nproposed method enables us to reduce the average inference computational cost\nand further controlling the tradeoff between the model accuracy and the\ncomputation cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02508v1",
    "published_date": "2025-01-05 11:35:08 UTC",
    "updated_date": "2025-01-05 11:35:08 UTC"
  },
  {
    "arxiv_id": "2501.02504v1",
    "title": "Watch Video, Catch Keyword: Context-aware Keyword Attention for Moment Retrieval and Highlight Detection",
    "authors": [
      "Sung Jin Um",
      "Dongjin Kim",
      "Sangmin Lee",
      "Jung Uk Kim"
    ],
    "abstract": "The goal of video moment retrieval and highlight detection is to identify\nspecific segments and highlights based on a given text query. With the rapid\ngrowth of video content and the overlap between these tasks, recent works have\naddressed both simultaneously. However, they still struggle to fully capture\nthe overall video context, making it challenging to determine which words are\nmost relevant. In this paper, we present a novel Video Context-aware Keyword\nAttention module that overcomes this limitation by capturing keyword variation\nwithin the context of the entire video. To achieve this, we introduce a video\ncontext clustering module that provides concise representations of the overall\nvideo context, thereby enhancing the understanding of keyword dynamics.\nFurthermore, we propose a keyword weight detection module with keyword-aware\ncontrastive learning that incorporates keyword information to enhance\nfine-grained alignment between visual and textual features. Extensive\nexperiments on the QVHighlights, TVSum, and Charades-STA benchmarks demonstrate\nthat our proposed method significantly improves performance in moment retrieval\nand highlight detection tasks compared to existing approaches. Our code is\navailable at: https://github.com/VisualAIKHU/Keyword-DETR",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.02504v1",
    "published_date": "2025-01-05 11:01:27 UTC",
    "updated_date": "2025-01-05 11:01:27 UTC"
  },
  {
    "arxiv_id": "2501.02497v2",
    "title": "Test-Time Compute: from System-1 Thinking to System-2 Thinking",
    "authors": [
      "Yixin Ji",
      "Juntao Li",
      "Hai Ye",
      "Kaixin Wu",
      "Kai Yao",
      "Jia Xu",
      "Linjian Mo",
      "Min Zhang"
    ],
    "abstract": "The remarkable performance of the o1 model in complex reasoning demonstrates\nthat test-time compute scaling can further unlock the model's potential,\nenabling powerful System-2 thinking. However, there is still a lack of\ncomprehensive surveys for test-time compute scaling. We trace the concept of\ntest-time compute back to System-1 models. In System-1 models, test-time\ncompute addresses distribution shifts and improves robustness and\ngeneralization through parameter updating, input modification, representation\nediting, and output calibration. In System-2 models, it enhances the model's\nreasoning ability to solve complex problems through repeated sampling,\nself-correction, and tree search. We organize this survey according to the\ntrend of System-1 to System-2 thinking, highlighting the key role of test-time\ncompute in the transition from System-1 models to weak System-2 models, and\nthen to strong System-2 models. We also point out a few possible future\ndirections.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2501.02497v2",
    "published_date": "2025-01-05 10:24:20 UTC",
    "updated_date": "2025-03-03 07:16:16 UTC"
  },
  {
    "arxiv_id": "2501.03276v1",
    "title": "ComMer: a Framework for Compressing and Merging User Data for Personalization",
    "authors": [
      "Yoel Zeldes",
      "Amir Zait",
      "Ilia Labzovsky",
      "Danny Karmon",
      "Efrat Farkash"
    ],
    "abstract": "Large Language Models (LLMs) excel at a wide range of tasks, but adapting\nthem to new data, particularly for personalized applications, poses significant\nchallenges due to resource and computational constraints. Existing methods\neither rely on exposing fresh data to the model through the prompt, which is\nlimited by context size and computationally expensive at inference time, or\nfine-tuning, which incurs substantial training and update costs. In this paper,\nwe introduce ComMer - Compress and Merge - a novel framework that efficiently\npersonalizes LLMs by compressing users' documents into compact representations,\nwhich are then merged and fed into a frozen LLM. We evaluate ComMer on two\ntypes of personalization tasks - personalized skill learning, using the tweet\nparaphrasing dataset and the personalized news headline generation dataset from\nthe LaMP benchmark, and knowledge-intensive, using the PerLTQA dataset. Our\nexperiments demonstrate that in constrained inference budget scenarios ComMer\nachieves superior quality in skill learning tasks, while highlighting\nlimitations in knowledge-intensive settings due to the loss of detailed\ninformation. These results offer insights into trade-offs and potential\noptimizations in multi-document compression for personalization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.03276v1",
    "published_date": "2025-01-05 09:57:03 UTC",
    "updated_date": "2025-01-05 09:57:03 UTC"
  },
  {
    "arxiv_id": "2501.02491v1",
    "title": "Rethinking IDE Customization for Enhanced HAX: A Hyperdimensional Perspective",
    "authors": [
      "Roham Koohestani",
      "Maliheh Izadi"
    ],
    "abstract": "As Integrated Development Environments (IDEs) increasingly integrate\nArtificial Intelligence, Software Engineering faces both benefits like\nproductivity gains and challenges like mismatched user preferences. We propose\nHyper-Dimensional (HD) vector spaces to model Human-Computer Interaction,\nfocusing on user actions, stylistic preferences, and project context. These\ncontributions aim to inspire further research on applying HD computing in IDE\ndesign.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at the 2nd Workshop on Integrated Development Environments\n  (the IDE Workshop) co-located with ICSE '25",
    "pdf_url": "http://arxiv.org/pdf/2501.02491v1",
    "published_date": "2025-01-05 09:53:50 UTC",
    "updated_date": "2025-01-05 09:53:50 UTC"
  },
  {
    "arxiv_id": "2501.02486v2",
    "title": "LLMPC: Large Language Model Predictive Control",
    "authors": [
      "Gabriel Maher"
    ],
    "abstract": "Recent advancements in prompting techniques for Large Language Models (LLMs)\nhave improved their reasoning, planning, and action abilities. This paper\nexamines these prompting techniques through the lens of model predictive\ncontrol (MPC). We show that LLMs act as implicit planning cost function\nminimizers when planning prompts are used. We propose a unified MPC framework\nfor planning with LLMs and demonstrate improved performance over few shot\nprompting on several planning benchmarks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02486v2",
    "published_date": "2025-01-05 09:37:23 UTC",
    "updated_date": "2025-02-25 02:25:39 UTC"
  },
  {
    "arxiv_id": "2501.02481v4",
    "title": "Representation Convergence: Mutual Distillation is Secretly a Form of Regularization",
    "authors": [
      "Zhengpeng Xie",
      "Jiahang Cao",
      "Qiang Zhang",
      "Jianxiong Zhang",
      "Changwei Wang",
      "Renjing Xu"
    ],
    "abstract": "In this paper, we argue that mutual distillation between reinforcement\nlearning policies serves as an implicit regularization, preventing them from\noverfitting to irrelevant features. We highlight two key contributions: (a)\nTheoretically, for the first time, we prove that enhancing the policy\nrobustness to irrelevant features leads to improved generalization performance.\n(b) Empirically, we demonstrate that mutual distillation between policies\ncontributes to such robustness, enabling the spontaneous emergence of invariant\nrepresentations over pixel inputs. Overall, our findings challenge the\nconventional view of distillation as merely a means of knowledge transfer,\noffering a novel perspective on the generalization in deep reinforcement\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02481v4",
    "published_date": "2025-01-05 09:06:17 UTC",
    "updated_date": "2025-05-15 12:40:27 UTC"
  },
  {
    "arxiv_id": "2501.02471v2",
    "title": "Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine",
    "authors": [
      "Yishen Liu",
      "Shengda Luo",
      "Zishao Zhong",
      "Tongtong Wu",
      "Jianguo Zhang",
      "Peiyao Ou",
      "Yong Liang",
      "Liang Liu",
      "Hudan Pan"
    ],
    "abstract": "Large language models (LLMs) primarily trained on English texts, often face\nbiases and inaccuracies in Chinese contexts. Their limitations are pronounced\nin fields like Traditional Chinese Medicine (TCM), where cultural and clinical\nsubtleties are vital, further hindered by a lack of domain-specific data, such\nas rheumatoid arthritis (RA). To address these issues, this paper introduces\nHengqin-RA-v1, the first large language model specifically tailored for TCM\nwith a focus on diagnosing and treating RA. We also present HQ-GCM-RA-C1, a\ncomprehensive RA-specific dataset curated from ancient Chinese medical\nliterature, classical texts, and modern clinical studies. This dataset empowers\nHengqin-RA-v1 to deliver accurate and culturally informed responses,\neffectively bridging the gaps left by general-purpose models. Extensive\nexperiments demonstrate that Hengqin-RA-v1 outperforms state-of-the-art models,\neven surpassing the diagnostic accuracy of TCM practitioners in certain cases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures, AAAI-2025 Workshop",
    "pdf_url": "http://arxiv.org/pdf/2501.02471v2",
    "published_date": "2025-01-05 07:46:51 UTC",
    "updated_date": "2025-03-27 06:39:45 UTC"
  },
  {
    "arxiv_id": "2501.02464v2",
    "title": "Depth Any Camera: Zero-Shot Metric Depth Estimation from Any Camera",
    "authors": [
      "Yuliang Guo",
      "Sparsh Garg",
      "S. Mahdi H. Miangoleh",
      "Xinyu Huang",
      "Liu Ren"
    ],
    "abstract": "While recent depth foundation models exhibit strong zero-shot generalization,\nachieving accurate metric depth across diverse camera types-particularly those\nwith large fields of view (FoV) such as fisheye and 360-degree cameras-remains\na significant challenge. This paper presents Depth Any Camera (DAC), a powerful\nzero-shot metric depth estimation framework that extends a perspective-trained\nmodel to effectively handle cameras with varying FoVs. The framework is\ndesigned to ensure that all existing 3D data can be leveraged, regardless of\nthe specific camera types used in new applications. Remarkably, DAC is trained\nexclusively on perspective images but generalizes seamlessly to fisheye and\n360-degree cameras without the need for specialized training data. DAC employs\nEqui-Rectangular Projection (ERP) as a unified image representation, enabling\nconsistent processing of images with diverse FoVs. Its core components include\npitch-aware Image-to-ERP conversion with efficient online augmentation to\nsimulate distorted ERP patches from undistorted inputs, FoV alignment\noperations to enable effective training across a wide range of FoVs, and\nmulti-resolution data augmentation to further address resolution disparities\nbetween training and testing. DAC achieves state-of-the-art zero-shot metric\ndepth estimation, improving $\\delta_1$ accuracy by up to 50% on multiple\nfisheye and 360-degree datasets compared to prior metric depth foundation\nmodels, demonstrating robust generalization across camera types.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02464v2",
    "published_date": "2025-01-05 07:22:40 UTC",
    "updated_date": "2025-03-16 18:28:32 UTC"
  },
  {
    "arxiv_id": "2501.02461v1",
    "title": "FedRSClip: Federated Learning for Remote Sensing Scene Classification Using Vision-Language Models",
    "authors": [
      "Hui Lin",
      "Chao Zhang",
      "Danfeng Hong",
      "Kexin Dong",
      "Congcong Wen"
    ],
    "abstract": "Remote sensing data is often distributed across multiple institutions, and\ndue to privacy concerns and data-sharing restrictions, leveraging large-scale\ndatasets in a centralized training framework is challenging. Federated learning\noffers a promising solution by enabling collaborative model training across\ndistributed data sources without requiring data centralization. However,\ncurrent Vision-Language Models (VLMs), which typically contain billions of\nparameters, pose significant communication challenges for traditional federated\nlearning approaches based on model parameter updates, as they would incur\nsubstantial communication costs. In this paper, we propose FedRSCLIP, the first\nfederated learning framework designed for remote sensing image classification\nbased on a VLM, specifically CLIP. FedRSCLIP addresses the challenges of data\nheterogeneity and large-scale model transmission in federated environments by\nintroducing Prompt Learning, which optimizes only a small set of tunable\nparameters. The framework introduces a dual-prompt mechanism, comprising Shared\nPrompts for global knowledge sharing and Private Prompts for client-specific\nadaptation. To maintain semantic coherence between shared and private prompts,\nwe propose the Dual Prompt Alignment Constraint to balance global consistency\nand local adaptability across diverse client distributions. Additionally, to\nenhance cross-modal representation learning, we introduce the Cross-Modal\nFeature Alignment Constraint to align multimodal features between text and\nimage prompts. To validate the effectiveness of our proposed model, we\nconstruct a Fed-RSIC dataset based on three existing remote sensing image\nclassification datasets, specifically designed to simulate various federated\nlearning configurations. Experimental results demonstrate the effectiveness and\nsuperiority of FedRSCLIP in remote sensing image classification.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02461v1",
    "published_date": "2025-01-05 07:10:27 UTC",
    "updated_date": "2025-01-05 07:10:27 UTC"
  },
  {
    "arxiv_id": "2501.02451v1",
    "title": "Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales",
    "authors": [
      "Zijie Cheng",
      "Boxuan Li",
      "André Altmann",
      "Pearse A Keane",
      "Yukun Zhou"
    ],
    "abstract": "Contrastive learning, a prominent approach within self-supervised learning,\nhas demonstrated significant effectiveness in developing generalizable models\nfor various applications involving natural images. However, recent research\nindicates that these successes do not necessarily extend to the medical imaging\ndomain. In this paper, we investigate the reasons for this suboptimal\nperformance and hypothesize that the dense distribution of medical images poses\nchallenges to the pretext tasks in contrastive learning, particularly in\nconstructing positive and negative pairs. We explore model performance under\ndifferent augmentation strategies and compare the results to those achieved\nwith strong augmentations. Our study includes six publicly available datasets\ncovering multiple clinically relevant tasks. We further assess the model's\ngeneralizability through external evaluations. The model pre-trained with weak\naugmentation outperforms those with strong augmentation, improving AUROC from\n0.838 to 0.848 and AUPR from 0.523 to 0.597 on MESSIDOR2, and showing similar\nenhancements across other datasets. Our findings suggest that optimizing the\nscale of augmentation is critical for enhancing the efficacy of contrastive\nlearning in medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02451v1",
    "published_date": "2025-01-05 06:08:08 UTC",
    "updated_date": "2025-01-05 06:08:08 UTC"
  },
  {
    "arxiv_id": "2501.02446v1",
    "title": "RTLMarker: Protecting LLM-Generated RTL Copyright via a Hardware Watermarking Framework",
    "authors": [
      "Kun Wang",
      "Kaiyan Chang",
      "Mengdi Wang",
      "Xinqi Zou",
      "Haobo Xu",
      "Yinhe Han",
      "Ying Wang"
    ],
    "abstract": "Recent advances of large language models in the field of Verilog generation\nhave raised several ethical and security concerns, such as code copyright\nprotection and dissemination of malicious code. Researchers have employed\nwatermarking techniques to identify codes generated by large language models.\nHowever, the existing watermarking works fail to protect RTL code copyright due\nto the significant syntactic and semantic differences between RTL code and\nsoftware code in languages such as Python. This paper proposes a hardware\nwatermarking framework RTLMarker that embeds watermarks into RTL code and\ndeeper into the synthesized netlist. We propose a set of rule-based Verilog\ncode transformations , ensuring the watermarked RTL code's syntactic and\nsemantic correctness. In addition, we consider an inherent tradeoff between\nwatermark transparency and watermark effectiveness and jointly optimize them.\nThe results demonstrate RTLMarker's superiority over the baseline in RTL code\nwatermarking.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02446v1",
    "published_date": "2025-01-05 05:38:28 UTC",
    "updated_date": "2025-01-05 05:38:28 UTC"
  },
  {
    "arxiv_id": "2501.02441v1",
    "title": "A Statistical Hypothesis Testing Framework for Data Misappropriation Detection in Large Language Models",
    "authors": [
      "Yinpeng Cai",
      "Lexin Li",
      "Linjun Zhang"
    ],
    "abstract": "Large Language Models (LLMs) are rapidly gaining enormous popularity in\nrecent years. However, the training of LLMs has raised significant privacy and\nlegal concerns, particularly regarding the inclusion of copyrighted materials\nin their training data without proper attribution or licensing, which falls\nunder the broader issue of data misappropriation. In this article, we focus on\na specific problem of data misappropriation detection, namely, to determine\nwhether a given LLM has incorporated data generated by another LLM. To address\nthis issue, we propose embedding watermarks into the copyrighted training data\nand formulating the detection of data misappropriation as a hypothesis testing\nproblem. We develop a general statistical testing framework, construct a\npivotal statistic, determine the optimal rejection threshold, and explicitly\ncontrol the type I and type II errors. Furthermore, we establish the asymptotic\noptimality properties of the proposed tests, and demonstrate its empirical\neffectiveness through intensive numerical experiments.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "29 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.02441v1",
    "published_date": "2025-01-05 04:47:42 UTC",
    "updated_date": "2025-01-05 04:47:42 UTC"
  },
  {
    "arxiv_id": "2501.03273v1",
    "title": "Strategic Fusion Optimizes Transformer Compression",
    "authors": [
      "Md Shoaibur Rahman"
    ],
    "abstract": "This study investigates transformer model compression by systematically\npruning its layers. We evaluated 14 pruning strategies across nine diverse\ndatasets, including 12 strategies based on different signals obtained from\nlayer activations, mutual information, gradients, weights, and attention. To\naddress the limitations of single-signal strategies, we introduced two fusion\nstrategies, linear regression and random forest, which combine individual\nstrategies (i.e., strategic fusion), for more informed pruning decisions.\nAdditionally, we applied knowledge distillation to mitigate any accuracy loss\nduring layer pruning. Our results reveal that random forest strategic fusion\noutperforms individual strategies in seven out of nine datasets and achieves\nnear-optimal performance in the other two. The distilled random forest\nsurpasses the original accuracy in six datasets and mitigates accuracy drops in\nthe remaining three. Knowledge distillation also improves the accuracy-to-size\nratio by an average factor of 18.84 across all datasets. Supported by\nmathematical foundations and biological analogies, our findings suggest that\nstrategically combining multiple signals can lead to efficient, high-performing\ntransformer models for resource-constrained applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 1 table, 8 figures; will be submitted to ICML 2025; codes\n  will be made public after acceptance",
    "pdf_url": "http://arxiv.org/pdf/2501.03273v1",
    "published_date": "2025-01-05 04:46:14 UTC",
    "updated_date": "2025-01-05 04:46:14 UTC"
  },
  {
    "arxiv_id": "2501.02438v1",
    "title": "Efficient Deployment of Large Language Models on Resource-constrained Devices",
    "authors": [
      "Zhiwei Yao",
      "Yang Xu",
      "Hongli Xu",
      "Yunming Liao",
      "Zuan Xie"
    ],
    "abstract": "Deploying Large Language Models (LLMs) on resource-constrained (or weak)\ndevices presents significant challenges due to limited resources and\nheterogeneous data distribution. To address the data concern, it is necessary\nto fine-tune LLMs using on-device private data for various downstream tasks.\nWhile Federated Learning (FL) offers a promising privacy-preserving solution,\nexisting fine-tuning methods retain the original LLM size, leaving issues of\nhigh inference latency and excessive memory demands unresolved. Hence, we\ndesign FedSpine, an FL framework that combines Parameter- Efficient Fine-Tuning\n(PEFT) with structured pruning for efficient deployment of LLMs on\nresource-constrained devices. Specifically, FedSpine introduces an iterative\nprocess to prune and tune the parameters of LLMs. To mitigate the impact of\ndevice heterogeneity, an online Multi-Armed Bandit (MAB) algorithm is employed\nto adaptively determine different pruning ratios and LoRA ranks for\nheterogeneous devices without any prior knowledge of their computing and\ncommunication capabilities. As a result, FedSpine maintains higher inference\naccuracy while improving fine-tuning efficiency. Experimental results conducted\non a physical platform with 80 devices demonstrate that FedSpine can speed up\nfine-tuning by 1.4$\\times$-6.9$\\times$ and improve final accuracy by 0.4%-4.5%\nunder the same sparsity level compared to other baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02438v1",
    "published_date": "2025-01-05 04:38:11 UTC",
    "updated_date": "2025-01-05 04:38:11 UTC"
  },
  {
    "arxiv_id": "2501.03272v1",
    "title": "Backdoor Token Unlearning: Exposing and Defending Backdoors in Pretrained Language Models",
    "authors": [
      "Peihai Jiang",
      "Xixiang Lyu",
      "Yige Li",
      "Jing Ma"
    ],
    "abstract": "Supervised fine-tuning has become the predominant method for adapting large\npretrained models to downstream tasks. However, recent studies have revealed\nthat these models are vulnerable to backdoor attacks, where even a small number\nof malicious samples can successfully embed backdoor triggers into the model.\nWhile most existing defense methods focus on post-training backdoor defense,\nefficiently defending against backdoor attacks during training phase remains\nlargely unexplored. To address this gap, we propose a novel defense method\ncalled Backdoor Token Unlearning (BTU), which proactively detects and\nneutralizes trigger tokens during the training stage. Our work is based on two\nkey findings: 1) backdoor learning causes distinctive differences between\nbackdoor token parameters and clean token parameters in word embedding layers,\nand 2) the success of backdoor attacks heavily depends on backdoor token\nparameters. The BTU defense leverages these properties to identify aberrant\nembedding parameters and subsequently removes backdoor behaviors using a\nfine-grained unlearning technique. Extensive evaluations across three datasets\nand four types of backdoor attacks demonstrate that BTU effectively defends\nagainst these threats while preserving the model's performance on primary\ntasks. Our code is available at https://github.com/XDJPH/BTU.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.03272v1",
    "published_date": "2025-01-05 03:22:13 UTC",
    "updated_date": "2025-01-05 03:22:13 UTC"
  },
  {
    "arxiv_id": "2501.02409v2",
    "title": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations",
    "authors": [
      "Zaikang Lin",
      "Sei Chang",
      "Aaron Zweig",
      "Minseo Kang",
      "Elham Azizi",
      "David A. Knowles"
    ],
    "abstract": "Modern high-throughput biological datasets with thousands of perturbations\nprovide the opportunity for large-scale discovery of causal graphs that\nrepresent the regulatory interactions between genes. Differentiable causal\ngraphical models have been proposed to infer a gene regulatory network (GRN)\nfrom large scale interventional datasets, capturing the causal gene regulatory\nrelationships from genetic perturbations. However, existing models are limited\nin their expressivity and scalability while failing to address the dynamic\nnature of biological processes such as cellular differentiation. We propose\nPerturbODE, a novel framework that incorporates biologically informative neural\nordinary differential equations (neural ODEs) to model cell state trajectories\nunder perturbations and derive the causal GRN from the neural ODE's parameters.\nWe demonstrate PerturbODE's efficacy in trajectory prediction and GRN inference\nacross simulated and real over-expression datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "q-bio.MN",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.02409v2",
    "published_date": "2025-01-05 01:04:23 UTC",
    "updated_date": "2025-02-01 05:30:20 UTC"
  },
  {
    "arxiv_id": "2501.03271v3",
    "title": "DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization",
    "authors": [
      "Amitava Das",
      "Suranjana Trivedy",
      "Danush Khanna",
      "Rajarshi Roy",
      "Gurpreet Singh",
      "Basab Ghosh",
      "Yaswanth Narsupalli",
      "Vinija Jain",
      "Vasu Sharma",
      "Aishwarya Naresh Reganti",
      "Aman Chadha"
    ],
    "abstract": "The rapid rise of large language models (LLMs) has unlocked many applications\nbut also underscores the challenge of aligning them with diverse values and\npreferences. Direct Preference Optimization (DPO) is central to alignment but\nconstrained by fixed divergences and limited feature transformations. We\npropose DPO-Kernels, which integrates kernel methods to address these issues\nthrough four key contributions: (i) Kernelized Representations with polynomial,\nRBF, Mahalanobis, and spectral kernels for richer transformations, plus a\nhybrid loss combining embedding-based and probability-based objectives; (ii)\nDivergence Alternatives (Jensen-Shannon, Hellinger, Renyi, Bhattacharyya,\nWasserstein, and f-divergences) for greater stability; (iii) Data-Driven\nSelection metrics that automatically choose the best kernel-divergence pair;\nand (iv) a Hierarchical Mixture of Kernels for both local precision and global\nmodeling. Evaluations on 12 datasets demonstrate state-of-the-art performance\nin factuality, safety, reasoning, and instruction following. Grounded in\nHeavy-Tailed Self-Regularization, DPO-Kernels maintains robust generalization\nfor LLMs, offering a comprehensive resource for further alignment research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T45"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.03271v3",
    "published_date": "2025-01-05 00:08:52 UTC",
    "updated_date": "2025-01-20 04:24:56 UTC"
  }
]