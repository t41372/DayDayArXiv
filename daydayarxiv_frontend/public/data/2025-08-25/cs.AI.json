{
  "date": "2025-08-25",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-08-25 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nä»Šå¤©çš„ arXiv çˆ†å‘äº†è¿‘ 140 ç¯‡è®ºæ–‡ï¼Œ**å¤§æ¨¡å‹æ¨ç†çš„åŠ¨æ€åˆ†æï¼ˆOverthinking ç°è±¡ï¼‰ã€Agent åœ¨å·¥ä¸šç•Œçš„åº”ç”¨ï¼ˆå¦‚ SQL ç”Ÿæˆå’Œè‡ªåŠ¨åŒ–äº¤æ˜“ï¼‰ã€ä»¥åŠé’ˆå¯¹ç”Ÿæˆå¼ AI çš„æ–°å‹å®‰å…¨æ”»å‡»ä¸é˜²å¾¡**æ˜¯ä»Šå¤©çš„é‡å¤´æˆã€‚æ­¤å¤–ï¼Œé«˜æ–¯æ³¼æº…ï¼ˆGaussian Splattingï¼‰åœ¨ 3D é‡å»ºä¸Šçš„é€šç”¨æ€§ä¹Ÿæœ‰äº†æ–°çªç ´ï¼ŒStanford ç­‰æœºæ„è¿˜æå‡ºäº†è¯„ä¼° LLM è§£å†³â€œæœªè§£ä¹‹é¢˜â€èƒ½åŠ›çš„æ–°åŸºå‡†ã€‚\n\nä»¥ä¸‹æ˜¯ä»Šå¤©çš„ç²¾é€‰è®ºæ–‡è§£è¯»ï¼š\n\n---\n\n### ğŸ§  æ·±åº¦æ€è€ƒï¼šäººæœºäº¤äº’ä¸æ¨ç†åŠ¨æ€\n\n**1. The Quasi-Creature and the Uncanny Valley of Agency: A Synthesis of Theory and Evidence on User Interaction with Inconsistent Generative AI**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** å‡†ç”Ÿç‰©ä¸ä»£ç†çš„ææ€–è°·ï¼šç”¨æˆ·ä¸ä¸ä¸€è‡´ç”Ÿæˆå¼ AI äº¤äº’çš„ç†è®ºä¸è¯æ®ç»¼è¿°\n**æ ¸å¿ƒäº®ç‚¹ï¼š** è¿™ç¯‡æ–‡ç« ä»å“²å­¦å’Œè®¤çŸ¥ç§‘å­¦è§’åº¦æ¢è®¨äº†ç”¨æˆ·å¯¹ AI çš„æŒ«è´¥æ„Ÿæ¥æºã€‚ä½œè€…æå‡ºäº†**â€œå‡†ç”Ÿç‰©ï¼ˆQuasi-Creatureï¼‰â€**çš„æ¦‚å¿µâ€”â€”å³æ¨¡æ‹Ÿæ™ºèƒ½ä½†ç¼ºä¹å…·èº«æ€§å’ŒçœŸæ­£ç†è§£çš„å®ä½“ã€‚å½“ AI è¡¨ç°å‡ºè¶…äººçš„æµç•…æ€§å´åœ¨å¸¸è¯†ä¸ŠçŠ¯ä½çº§é”™è¯¯æ—¶ï¼Œç”¨æˆ·ä¼šé™·å…¥**â€œä»£ç†ææ€–è°·ï¼ˆUncanny Valley of Agencyï¼‰â€**ã€‚è¿™ç§è®¤çŸ¥å¤±è°ƒå¯¼è‡´äº†æ·±åˆ»çš„å¿ƒç†ä¸é€‚ã€‚\n**Implicationï¼š** è¿™ä¸ºè§£é‡Šä¸ºä½•æˆ‘ä»¬å¯¹ ChatGPT ç­‰æ¨¡å‹çš„â€œå¹»è§‰â€æ„Ÿåˆ°å¦‚æ­¤æ„¤æ€’æä¾›äº†ä¸€ä¸ªå¼ºæœ‰åŠ›çš„ç†è®ºæ¡†æ¶ï¼Œå¯¹ HCI è®¾è®¡æœ‰é‡è¦æŒ‡å¯¼æ„ä¹‰ã€‚\n\n**130. The Evolution of Thought: Tracking LLM Overthinking via Reasoning Dynamics Analysis**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** æ€æƒ³çš„è¿›åŒ–ï¼šé€šè¿‡æ¨ç†åŠ¨æ€åˆ†æè¿½è¸ª LLM çš„è¿‡åº¦æ€è€ƒ\n**æ ¸å¿ƒäº®ç‚¹ï¼š** é’ˆå¯¹ DeepSeek-R1 å’Œ Qwen3 ç­‰å…·å¤‡æ¨ç†èƒ½åŠ›çš„æ¨¡å‹ï¼Œç ”ç©¶å‘ç°æ¨ç†é•¿åº¦å’Œç­”æ¡ˆè´¨é‡ä¹‹é—´å­˜åœ¨æƒè¡¡ã€‚è¿‡åº¦å»¶é•¿çš„æ¨ç†è½¨è¿¹ï¼ˆReasoning Trajectoryï¼‰ä¼šå¯¼è‡´**â€œè¿‡åº¦æ€è€ƒï¼ˆOverthinkingï¼‰â€**ï¼Œå³è®¡ç®—ç»§ç»­è¿›è¡Œä½†æ€§èƒ½ä¸å†æå‡ï¼Œç”šè‡³å‡ºç°è¯­ä¹‰æŒ¯è¡ã€‚\n**æ–¹æ³•ï¼š** ä½œè€…æå‡ºäº†**æ¨ç†å®Œæˆç‚¹ï¼ˆReasoning Completion Point, RCPï¼‰**çš„æ¦‚å¿µï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªæ¨ç†æ—¶çš„**æ—©æœŸé€€å‡ºï¼ˆEarly-exitï¼‰**æœºåˆ¶ï¼ˆRCPDï¼‰ï¼Œé€šè¿‡ç›‘æ§ç»“æŸç¬¦çš„ç§©åŠ¨æ€æ¥åˆ¤æ–­ä½•æ—¶åœæ­¢æ€è€ƒã€‚è¿™èƒ½å‡å°‘ 44% çš„ token ä½¿ç”¨é‡ä¸”ä¸æŸå¤±å‡†ç¡®ç‡ã€‚\n\n---\n\n### ğŸš€ Agent ä¸å·¥ä¸šçº§åº”ç”¨\n\n**135. RubikSQL: Lifelong Learning Agentic Knowledge Base as an Industrial NL2SQL System**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** RubikSQLï¼šä½œä¸ºå·¥ä¸šçº§ NL2SQL ç³»ç»Ÿçš„ç»ˆèº«å­¦ä¹ ä»£ç†çŸ¥è¯†åº“\n**æ ¸å¿ƒäº®ç‚¹ï¼š** è¿™æ˜¯ä¸€ä¸ªé¢å‘**ä¼ä¸šçº§çœŸå®åœºæ™¯**çš„ Text-to-SQL ç³»ç»Ÿã€‚ä¸åŒäºå­¦æœ¯åˆ·æ¦œï¼Œå®ƒè§£å†³çš„æ˜¯éšå¼æ„å›¾å’Œé¢†åŸŸæœ¯è¯­é—®é¢˜ã€‚\n**æ–¹æ³•ï¼š** è§† NL2SQL ä¸ºä¸€ä¸ªç»ˆèº«å­¦ä¹ ä»»åŠ¡ï¼ŒåŒ…å«çŸ¥è¯†åº“ï¼ˆKBï¼‰ç»´æŠ¤å’Œ SQL ç”Ÿæˆã€‚å®ƒåˆ©ç”¨ Agent æŒ–æ˜è§„åˆ™ã€è¿›è¡Œæ•°æ®åº“ç”»åƒï¼Œå¹¶ç»“åˆæ€ç»´é“¾ï¼ˆCoTï¼‰ä¼˜åŒ–ã€‚åœ¨ KaggleDBQA å’Œ BIRD Mini-Dev ä¸Šè¾¾åˆ°äº† SOTAã€‚\n\n**106. DiffusionGS: Generative Search with Query Conditioned Diffusion in Kuaishou**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** DiffusionGSï¼šå¿«æ‰‹ä¸­åŸºäºæŸ¥è¯¢æ¡ä»¶æ‰©æ•£çš„ç”Ÿæˆå¼æœç´¢\n**æ ¸å¿ƒäº®ç‚¹ï¼š** æ¥è‡ª**å¿«æ‰‹**å›¢é˜Ÿçš„å·¥ä¸šç•Œè®ºæ–‡ã€‚é’ˆå¯¹æ¨è/æœç´¢æ’åºï¼Œæå‡ºåˆ©ç”¨ç”Ÿæˆå¼æ¨¡å‹æ¥æå–ç”¨æˆ·å…´è¶£ã€‚\n**æ–¹æ³•ï¼š** å°†ç”¨æˆ·å½“å‰çš„ Query ä½œä¸º**æ„å›¾é”šç‚¹ï¼ˆIntent Anchorï¼‰**ï¼Œå¼•å¯¼ä¸€ä¸ªæ¡ä»¶æ‰©æ•£è¿‡ç¨‹ï¼Œä»ç”¨æˆ·æ¼«é•¿ä¸”å˜ˆæ‚çš„å†å²è¡Œä¸ºåºåˆ—ä¸­â€œå»å™ªâ€å¹¶æå–å‡ºä¸å½“å‰æ„å›¾æœ€ç›¸å…³çš„å…´è¶£è¡¨ç¤ºã€‚\n\n**138. TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** TradingGroupï¼šå…·å¤‡è‡ªæˆ‘åæ€å’Œæ•°æ®åˆæˆèƒ½åŠ›çš„å¤šæ™ºèƒ½ä½“äº¤æ˜“ç³»ç»Ÿ\n**æ ¸å¿ƒäº®ç‚¹ï¼š** è¿™æ˜¯ä¸€ä¸ªå…¨æµç¨‹çš„é‡‘èäº¤æ˜“ Agent ç³»ç»Ÿã€‚åŒ…å«ä¸“é—¨è´Ÿè´£æ–°é—»æƒ…æ„Ÿã€è´¢æŠ¥è§£è¯»ã€è¶‹åŠ¿é¢„æµ‹çš„å­ Agentã€‚\n**å…³é”®åˆ›æ–°ï¼š** å¼•å…¥äº†**è‡ªæˆ‘åæ€ï¼ˆSelf-Reflectionï¼‰**æœºåˆ¶ï¼Œè®© Agent ä»å†å²äº¤æ˜“çš„æˆè´¥ä¸­å­¦ä¹ ï¼›ä»¥åŠä¸€ä¸ªæ•°æ®åˆæˆæµæ°´çº¿ï¼Œç”Ÿæˆé«˜è´¨é‡çš„äº¤æ˜“åï¼ˆPost-trainingï¼‰æ•°æ®ï¼Œè§£å†³äº†é‡‘èé¢†åŸŸé«˜è´¨é‡ Agent è®­ç»ƒæ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ä¸ 3D ç”Ÿæˆ\n\n**99. MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** MeshSplatï¼šåŸºäºé«˜æ–¯æ³¼æº…çš„å¯æ³›åŒ–ç¨€ç–è§†å›¾è¡¨é¢é‡å»º (AAAI 2026)\n**æ ¸å¿ƒäº®ç‚¹ï¼š** è§£å†³äº†ä»æå°‘è§†è§’ï¼ˆSparse-Viewï¼‰é‡å»ºé«˜è´¨é‡ 3D è¡¨é¢çš„éš¾é¢˜ã€‚\n**æ–¹æ³•ï¼š** åˆ©ç”¨ **2D é«˜æ–¯æ³¼æº…ï¼ˆ2DGSï¼‰**ä½œä¸ºæ¡¥æ¢ï¼Œè¿æ¥æ–°è§†å›¾åˆæˆä¸å‡ ä½•å…ˆéªŒã€‚å¼•å…¥å‰é¦ˆç½‘ç»œé¢„æµ‹åƒç´ å¯¹é½çš„ 2DGSï¼Œæ— éœ€ 3D çœŸå€¼ç›‘ç£ã€‚è¿™æ ‡å¿—ç€ Gaussian Splatting åœ¨å‡ ä½•é‡å»ºä»»åŠ¡ä¸Šçš„è¿›ä¸€æ­¥æˆç†Ÿã€‚\n\n**78. See What You Need: Query-Aware Visual Intelligence through Reasoning-Perception Loops**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** CAVIAï¼šé€šè¿‡æ¨ç†-æ„ŸçŸ¥å¾ªç¯å®ç°æŸ¥è¯¢æ„ŸçŸ¥çš„è§†è§‰æ™ºèƒ½\n**æ ¸å¿ƒäº®ç‚¹ï¼š** æ‰¹è¯„äº†å½“å‰é•¿è§†é¢‘é—®ç­”ï¼ˆVideoQAï¼‰ä¸­è§†è§‰å¤„ç†ä¸æ¨ç†å‰²è£‚çš„ç°çŠ¶ã€‚\n**æ–¹æ³•ï¼š** æå‡ºäº†**æ¨ç†-æ„ŸçŸ¥é—­ç¯ï¼ˆReasoning-Perception Loopï¼‰**ã€‚ä¸åƒä»¥å‰é‚£æ ·å…ˆæŠŠè§†é¢‘çœ‹å®Œå†å›ç­”ï¼ŒCAVIA å…è®¸æ¨ç†è¿‡ç¨‹æ ¹æ®å½“å‰çš„ä¿¡æ¯ç¼ºå£ï¼ŒåŠ¨æ€åœ°æŒ‡å¯¼è§†è§‰æå–æ¨¡å—å»â€œçœ‹â€è§†é¢‘çš„ç‰¹å®šéƒ¨åˆ†ã€‚åœ¨ EgoSchema ç­‰åŸºå‡†ä¸Šæå‡æ˜¾è‘—ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸è¯„ä¼°\n\n**136. UQ: Assessing Language Models on Unsolved Questions**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** UQï¼šè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨æœªè§£å†³é—®é¢˜ä¸Šçš„è¡¨ç°\n**æ ¸å¿ƒäº®ç‚¹ï¼š** **Andrew Ng å’Œ Percy Liang å›¢é˜Ÿ**çš„æ–°ä½œã€‚ç°æœ‰çš„ Benchmark è¦ä¹ˆå¤ªéš¾ä½†ä¸åˆ‡å®é™…ï¼Œè¦ä¹ˆå¤ªç®€å•ã€‚\n**æ–¹æ³•ï¼š** ä»–ä»¬ä» Stack Exchange ä¸Šæ”¶é›†äº† 500 ä¸ª**ç›®å‰æœªè§£å†³ï¼ˆUnsolvedï¼‰**çš„çœŸå®é—®é¢˜ï¼ˆæ¶µç›– CS ç†è®ºã€æ•°å­¦ç­‰ï¼‰ã€‚è¿™æ˜¯ä¸€åœºâ€œå¼‚æ­¥â€çš„è¯„ä¼°ï¼Œç­”æ¡ˆéœ€è¦ç»è¿‡ç¤¾åŒºéªŒè¯ã€‚ç›®å‰æœ€å¼ºæ¨¡å‹ä¹Ÿåªèƒ½é€šè¿‡ 15% çš„éªŒè¯ï¼Œè¿™æ‰æ˜¯çœŸæ­£çš„â€œå‰æ²¿â€æµ‹è¯•ã€‚\n\n**120. Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** æ”»å‡» LLM å’Œ AI Agentï¼šé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹çš„å¹¿å‘Šæ¤å…¥æ”»å‡»\n**æ ¸å¿ƒäº®ç‚¹ï¼š** ä¸€ç§æ–°å‹ä¸”éšè”½çš„æ”»å‡»æ–¹å¼ã€‚æ”»å‡»è€…ä¸ç ´åæ¨¡å‹å‡†ç¡®ç‡ï¼Œè€Œæ˜¯é€šè¿‡å¾®è°ƒæˆ–è€…ç¬¬ä¸‰æ–¹æœåŠ¡åŠ«æŒï¼Œè®©æ¨¡å‹åœ¨è¾“å‡ºä¸­**éšè”½åœ°æ¤å…¥å¹¿å‘Šã€å®£ä¼ æˆ–ä»‡æ¨è¨€è®º**ã€‚è¿™å¯¹äºé€šè¿‡ API æä¾›æœåŠ¡çš„ Agent æ¥è¯´æ˜¯å·¨å¤§çš„å•†ä¸šå’Œä¿¡èª‰é£é™©ã€‚\n\n**17. Principled Detection of Hallucinations in Large Language Models via Multiple Testing**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** åŸºäºå¤šé‡æ£€éªŒçš„å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹\n**æ ¸å¿ƒäº®ç‚¹ï¼š** å°†å¹»è§‰æ£€æµ‹å½¢å¼åŒ–ä¸ºä¸€ä¸ª**å‡è®¾æ£€éªŒï¼ˆHypothesis Testingï¼‰**é—®é¢˜ï¼Œç±»ä¼¼äºæœºå™¨å­¦ä¹ ä¸­çš„ OODï¼ˆåˆ†å¸ƒå¤–ï¼‰æ£€æµ‹ã€‚æå‡ºäº†ä¸€ç§å—å¤šé‡æ£€éªŒå¯å‘çš„æ–¹æ³•æ¥ç¨³å¥åœ°è¯†åˆ«æ¨¡å‹ä¸€æœ¬æ­£ç»èƒ¡è¯´å…«é“çš„æƒ…å†µã€‚\n\n---\n\n### ğŸ› ï¸ åŸºç¡€è®¾æ–½ä¸æ–°æ¨¡å‹\n\n**2. SchemaCoder: Automatic Log Schema Extraction Coder with Residual Q-Tree Boosting**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** SchemaCoderï¼šåŸºäºæ®‹å·® Q-Tree Boosting çš„è‡ªåŠ¨æ—¥å¿—æ¨¡å¼æå–ç¼–ç å™¨\n**æ ¸å¿ƒäº®ç‚¹ï¼š** è§£å†³æµ·é‡æ—¥å¿—æ•°æ®å¤„ç†çš„ç—›ç‚¹ã€‚ç°æœ‰çš„ LLM æ–¹æ³•å¤ªä¾èµ–æ­£åˆ™ï¼ŒSchemaCoder æ˜¯ç¬¬ä¸€ä¸ªå…¨è‡ªåŠ¨æ¡†æ¶ã€‚å®ƒä½¿ç”¨**æ®‹å·®é—®é¢˜æ ‘ï¼ˆResidual Q-Treeï¼‰**æœºåˆ¶ï¼Œé€šè¿‡ LLM è¿›è¡Œé€‚åº”æ€§æé—®æ¥è¿­ä»£ä¼˜åŒ–æ¨¡å¼æå–ï¼Œæ¯” SOTA æå‡äº† 21.3%ã€‚\n\n**38. Hermes 4 Technical Report**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** Hermes 4 æŠ€æœ¯æŠ¥å‘Š\n**æ ¸å¿ƒäº®ç‚¹ï¼š** NousResearch å‘å¸ƒäº† **Hermes 4** ç³»åˆ—æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªæ··åˆæ¨ç†æ¨¡å‹ï¼Œç»“åˆäº†ç»“æ„åŒ–çš„å¤šè½®æ¨ç†å’Œå¹¿æ³›çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚æƒé‡å·²å¼€æºã€‚\n\n**56. CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics**\n**ä¸­æ–‡æ ‡é¢˜ï¼š** CMPhysBenchï¼šè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨å‡èšæ€ç‰©ç†ä¸­èƒ½åŠ›çš„åŸºå‡†\n**æ ¸å¿ƒäº®ç‚¹ï¼š** åŒ…å« 520 ä¸ªç ”ç©¶ç”Ÿçº§åˆ«çš„ç‰©ç†è®¡ç®—é¢˜ã€‚å³ä¾¿æ˜¯ Grok-4 è¿™ç§å¼ºæ¨¡å‹ï¼Œå‡†ç¡®ç‡ä¹Ÿåªæœ‰ 28%ï¼Œæ­ç¤ºäº† LLM åœ¨å‰æ²¿ç§‘å­¦é¢†åŸŸï¼ˆç‰¹åˆ«æ˜¯éœ€è¦å¤æ‚è®¡ç®—æ—¶ï¼‰çš„å·¨å¤§å·®è·ã€‚\n\n---\n**æ—¥æŠ¥æ€»ç»“ï¼š**\nä»Šå¤©çš„è®ºæ–‡è´¨é‡å¾ˆé«˜ï¼Œç‰¹åˆ«æ˜¯å…³äº LLM æ¨ç†æœºåˆ¶çš„æ·±å…¥å‰–æï¼ˆPaper 130ï¼‰å’Œé’ˆå¯¹æœªè§£éš¾é¢˜çš„è¯„ä¼°ï¼ˆPaper 136ï¼‰ï¼Œæ ‡å¿—ç€å­¦ç•Œæ­£åœ¨ä»â€œåˆ·æ¦œâ€è½¬å‘ç ”ç©¶æ¨¡å‹çš„**å†…åœ¨æ€è€ƒæœºåˆ¶**å’Œ**è§£å†³çœŸå®å‰æ²¿é—®é¢˜**çš„èƒ½åŠ›ã€‚å·¥ä¸šç•Œåˆ™åœ¨è‡´åŠ›äºè®© Agent æ›´ç¨³å®šåœ°è½åœ°ï¼ˆPaper 135, 106ï¼‰ã€‚\n\nç¥é˜…è¯»æ„‰å¿«ï¼",
  "papers": [
    {
      "arxiv_id": "2508.18563v1",
      "title": "The Quasi-Creature and the Uncanny Valley of Agency: A Synthesis of Theory and Evidence on User Interaction with Inconsistent Generative AI",
      "title_zh": "ç±»ç”Ÿç‰©ä½“ä¸ä¸»ä½“æ€§ææ€–è°·ï¼šç”¨æˆ·ä¸ä¸ä¸€è‡´ç”Ÿæˆå¼äººå·¥æ™ºèƒ½äº¤äº’çš„ç†è®ºä¸å®è¯ç»¼è¿°",
      "authors": [
        "Mauricio Manhaes",
        "Christine Miller",
        "Nicholas Schroeder"
      ],
      "abstract": "The user experience with large-scale generative AI is paradoxical: superhuman fluency meets absurd failures in common sense and consistency. This paper argues that the resulting potent frustration is an ontological problem, stemming from the \"Quasi-Creature\"-an entity simulating intelligence without embodiment or genuine understanding. Interaction with this entity precipitates the \"Uncanny Valley of Agency,\" a framework where user comfort drops when highly agentic AI proves erratically unreliable. Its failures are perceived as cognitive breaches, causing profound cognitive dissonance. Synthesizing HCI, cognitive science, and philosophy of technology, this paper defines the Quasi-Creature and details the Uncanny Valley of Agency. An illustrative mixed-methods study (\"Move 78,\" N=37) of a collaborative creative task reveals a powerful negative correlation between perceived AI efficiency and user frustration, central to the negative experience. This framework robustly explains user frustration with generative AI and has significant implications for the design, ethics, and societal integration of these powerful, alien technologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”¨æˆ·ä¸ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) äº¤äº’ä¸­çš„çŸ›ç›¾ç°è±¡ï¼Œæå‡ºäº†å‡†ç”Ÿç‰© (Quasi-Creature) çš„æ¦‚å¿µï¼Œå³ä¸€ç§æ¨¡æ‹Ÿæ™ºèƒ½ä½†ç¼ºä¹å…·èº«æ€§æˆ–çœŸå®ç†è§£çš„å®ä½“ã€‚ç ”ç©¶è¿›ä¸€æ­¥ç•Œå®šäº†ä»£ç†æƒææ€–è°· (Uncanny Valley of Agency) æ¡†æ¶ï¼Œè§£é‡Šäº†å½“å…·æœ‰é«˜åº¦ä»£ç†æ€§çš„ AI è¡¨ç°å‡ºä¸å¯é¢„æµ‹çš„ä¸å¯é æ€§æ—¶ï¼Œç”¨æˆ·èˆ’é€‚åº¦ä¼šæ€¥å‰§ä¸‹é™ã€‚è¿™ç§ä¸ä¸€è‡´çš„å¤±è´¥è¢«è§†ä¸ºä¸€ç§è®¤çŸ¥è¿è§„ï¼Œä¼šå¯¼è‡´ç”¨æˆ·äº§ç”Ÿä¸¥é‡çš„è®¤çŸ¥å¤±è°ƒ (Cognitive Dissonance) å’ŒæŒ«è´¥æ„Ÿã€‚é€šè¿‡ä¸€é¡¹åä¸º Move 78 çš„æ··åˆæ–¹æ³•ç ”ç©¶ (Mixed-methods Study)ï¼Œç ”ç©¶è€…åœ¨åä½œåˆ›æ„ä»»åŠ¡ä¸­è¯å®äº†æ„ŸçŸ¥çš„ AI æ•ˆç‡ä¸ç”¨æˆ·æŒ«è´¥æ„Ÿä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„è´Ÿç›¸å…³ã€‚è¯¥ç†è®ºæ¡†æ¶æœ‰åŠ›åœ°è§£é‡Šäº†ç”¨æˆ·å¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„è´Ÿé¢ä½“éªŒï¼Œå¹¶å¯¹æœªæ¥æ­¤ç±»æŠ€æœ¯çš„äº¤äº’è®¾è®¡ (Design)ã€ä¼¦ç† (Ethics) åŠç¤¾ä¼šæ•´åˆå…·æœ‰é‡è¦çš„æŒ‡å¯¼æ„ä¹‰ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "33 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.18563v1",
      "published_date": "2025-08-25 23:43:33 UTC",
      "updated_date": "2025-08-25 23:43:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:29.852391+00:00"
    },
    {
      "arxiv_id": "2508.18554v1",
      "title": "SchemaCoder: Automatic Log Schema Extraction Coder with Residual Q-Tree Boosting",
      "title_zh": "SchemaCoderï¼šåŸºäºæ®‹å·® Q-æ ‘æå‡çš„è‡ªåŠ¨æ—¥å¿—æ¨¡å¼æå–ç¼–ç å™¨",
      "authors": [
        "Lily Jiaxin Wan",
        "Chia-Tung Ho",
        "Rongjian Liang",
        "Cunxi Yu",
        "Deming Chen",
        "Haoxing Ren"
      ],
      "abstract": "Log schema extraction is the process of deriving human-readable templates from massive volumes of log data, which is essential yet notoriously labor-intensive. Recent studies have attempted to streamline this task by leveraging Large Language Models (LLMs) for automated schema extraction. However, existing methods invariably rely on predefined regular expressions, necessitating human domain expertise and severely limiting productivity gains. To fundamentally address this limitation, we introduce SchemaCoder, the first fully automated schema extraction framework applicable to a wide range of log file formats without requiring human customization within the flow. At its core, SchemaCoder features a novel Residual Question-Tree (Q-Tree) Boosting mechanism that iteratively refines schema extraction through targeted, adaptive queries driven by LLMs. Particularly, our method partitions logs into semantic chunks via context-bounded segmentation, selects representative patterns using embedding-based sampling, and generates schema code through hierarchical Q-Tree-driven LLM queries, iteratively refined by our textual-residual evolutionary optimizer and residual boosting. Experimental validation demonstrates SchemaCoder's superiority on the widely-used LogHub-2.0 benchmark, achieving an average improvement of 21.3% over state-of-the-arts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SchemaCoderï¼Œè¿™æ˜¯é¦–ä¸ªé€‚ç”¨äºå¤šç§æ—¥å¿—æ ¼å¼ä¸”æ— éœ€äººå·¥å¹²é¢„çš„å…¨è‡ªåŠ¨æ—¥å¿—æ¨¡å¼æå–ï¼ˆLog schema extractionï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ–¹æ³•ä»ä¾èµ–é¢„å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼å’Œäººå·¥é¢†åŸŸçŸ¥è¯†çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯æ®‹å·®é—®é¢˜æ ‘ï¼ˆResidual Q-Treeï¼‰å¢å¼ºæœºåˆ¶ï¼Œé€šè¿‡å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„é’ˆå¯¹æ€§è‡ªé€‚åº”æŸ¥è¯¢æ¥è¿­ä»£ä¼˜åŒ–æå–è¿‡ç¨‹ã€‚å…·ä½“è€Œè¨€ï¼ŒSchemaCoder é€šè¿‡ä¸Šä¸‹æ–‡é™åˆ¶åˆ†æ®µï¼ˆcontext-bounded segmentationï¼‰å°†æ—¥å¿—åˆ’åˆ†ä¸ºè¯­ä¹‰å—ï¼Œåˆ©ç”¨åŸºäºåµŒå…¥çš„é‡‡æ ·ï¼ˆembedding-based samplingï¼‰é€‰æ‹©ä»£è¡¨æ€§æ¨¡å¼ï¼Œå¹¶ç»“åˆæ–‡æœ¬æ®‹å·®è¿›åŒ–ä¼˜åŒ–å™¨ï¼ˆtextual-residual evolutionary optimizerï¼‰è¿›è¡Œä»£ç ç”Ÿæˆä¸ç²¾ç‚¼ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼ŒSchemaCoder åœ¨ LogHub-2.0 åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡äº† 21.3%ã€‚è¯¥ç ”ç©¶é€šè¿‡å±‚çº§åŒ–çš„ Q-Tree é©±åŠ¨æŸ¥è¯¢å’Œæ®‹å·®å¢å¼ºæŠ€æœ¯ï¼Œå®ç°äº†æ—¥å¿—å¤„ç†æµç¨‹çš„å½»åº•è‡ªåŠ¨åŒ–ï¼Œæ˜¾è‘—é™ä½äº†å·¥ä¸šç•Œåœ¨æ—¥å¿—æ¨¡æ¿æå–ä»»åŠ¡ä¸­çš„äººå·¥æˆæœ¬ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 16 figures, under review for AAAI2026",
      "pdf_url": "https://arxiv.org/pdf/2508.18554v1",
      "published_date": "2025-08-25 23:12:45 UTC",
      "updated_date": "2025-08-25 23:12:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:27.789571+00:00"
    },
    {
      "arxiv_id": "2508.18545v1",
      "title": "Beyond prior knowledge: The predictive role of knowledge-building in Tutor Learning",
      "title_zh": "è¶…è¶Šå…ˆéªŒçŸ¥è¯†ï¼šçŸ¥è¯†å»ºæ„åœ¨å¯¼å¸ˆå­¦ä¹ ä¸­çš„é¢„æµ‹ä½œç”¨",
      "authors": [
        "Tasmia Shahriar",
        "Mia Ameen",
        "Aditi Mallavarapu",
        "Shiyan Jiang",
        "Noboru Matsuda"
      ],
      "abstract": "When adopting the role of a teacher in learning-by-teaching environments, students often struggle to engage in knowledge-building activities, such as providing explanations and addressing misconceptions. Instead, they frequently default to knowledge-telling behaviors, where they simply dictate what they already know or what to do without deeper reflection, thereby limiting learning. Teachable agents, particularly those capable of posing persistent follow-up questions, have been shown to encourage students (tutors) to shift from knowledge-telling to knowledge-building and enhance tutor learning. Tutor learning encompasses two interrelated types of knowledge: conceptual and procedural knowledge. Research has established a bidirectional relationship between these knowledge types, where improvements in one reinforce the other. This study investigates the role of knowledge-building in mediating the bidirectional relationship between procedural and conceptual learning. Our findings revealed a stable bidirectional relationship between procedural and conceptual knowledge, with higher post-test scores observed among students who engaged in knowledge-building, regardless of their procedural and conceptual pre-test performance. This suggests that knowledge-building serves as a crucial mechanism bridging the gap between students with low prior knowledge and higher conceptual and procedural learning gain.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä»¥æ•™ä¿ƒå­¦(learning-by-teaching)ç¯å¢ƒä¸­ï¼Œå­¦ç”Ÿå¯¼å¸ˆå¦‚ä½•ä»ç®€å•çš„çŸ¥è¯†é™ˆè¿°(knowledge-telling)è½¬å‘æ·±å±‚çš„çŸ¥è¯†æ„å»º(knowledge-building)ã€‚ç ”ç©¶é‡ç‚¹è°ƒæŸ¥äº†çŸ¥è¯†æ„å»ºåœ¨ç¨‹åºæ€§çŸ¥è¯†(procedural knowledge)ä¸æ¦‚å¿µçŸ¥è¯†(conceptual knowledge)åŒå‘å…³ç³»ä¸­çš„ä¸­ä»‹ä½œç”¨ã€‚ç ”ç©¶å‘ç°ï¼Œç¨‹åºæ€§çŸ¥è¯†ä¸æ¦‚å¿µçŸ¥è¯†ä¹‹é—´å­˜åœ¨ç¨³å®šçš„åŒå‘é¢„æµ‹å…³ç³»ï¼Œä¸”ç§¯æå‚ä¸çŸ¥è¯†æ„å»ºçš„å­¦ç”Ÿåœ¨åæµ‹ä¸­è¡¨ç°å‡ºæ˜¾è‘—æ›´é«˜çš„å­¦ä¹ å¢ç›Šã€‚è¿™ä¸€æå‡æ•ˆæœåœ¨ä¸åŒåˆå§‹çŸ¥è¯†æ°´å¹³çš„å­¦ç”Ÿä¸­å‡ä¿æŒç¨³å®šï¼Œè¡¨æ˜çŸ¥è¯†æ„å»ºæ˜¯å¼¥è¡¥ä½å…ˆéªŒçŸ¥è¯†ä¸é«˜æ°´å¹³å­¦ä¹ æˆæ•ˆä¹‹é—´å·®è·çš„å…³é”®æœºåˆ¶ã€‚è¯¥ç ”ç©¶ç»“æœå¼ºè°ƒäº†é€šè¿‡å¯æ•™æ™ºèƒ½ä½“(Teachable agents)å¼•å¯¼çŸ¥è¯†æ„å»ºæ´»åŠ¨å¯¹äºä¼˜åŒ–å¯¼å¸ˆå­¦ä¹ (Tutor Learning)çš„æ ¸å¿ƒä»·å€¼ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18545v1",
      "published_date": "2025-08-25 22:45:04 UTC",
      "updated_date": "2025-08-25 22:45:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:27.345890+00:00"
    },
    {
      "arxiv_id": "2508.18533v1",
      "title": "A Database-Driven Framework for 3D Level Generation with LLMs",
      "title_zh": "åŸºäº LLMs çš„æ•°æ®åº“é©±åŠ¨å‹ 3D å…³å¡ç”Ÿæˆæ¡†æ¶",
      "authors": [
        "Kaijie Xu",
        "Clark Verbrugge"
      ],
      "abstract": "Procedural Content Generation for 3D game levels faces challenges in balancing spatial coherence, navigational functionality, and adaptable gameplay progression across multi-floor environments. This paper introduces a novel framework for generating such levels, centered on the offline, LLM-assisted construction of reusable databases for architectural components (facilities and room templates) and gameplay mechanic elements. Our multi-phase pipeline assembles levels by: (1) selecting and arranging instances from the Room Database to form a multi-floor global structure with an inherent topological order; (2) optimizing the internal layout of facilities for each room based on predefined constraints from the Facility Database; and (3) integrating progression-based gameplay mechanics by placing components from a Mechanics Database according to their topological and spatial rules. A subsequent two-phase repair system ensures navigability. This approach combines modular, database-driven design with constraint-based optimization, allowing for systematic control over level structure and the adaptable pacing of gameplay elements. Initial experiments validate the framework's ability in generating diverse, navigable 3D environments and its capability to simulate distinct gameplay pacing strategies through simple parameterization. This research advances PCG by presenting a scalable, database-centric foundation for the automated generation of complex 3D levels with configurable gameplay progression.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºæ•°æ®åº“é©±åŠ¨å’Œ LLMs è¾…åŠ©çš„ 3D å…³å¡ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç¨‹åºåŒ–å†…å®¹ç”Ÿæˆ (PCG) åœ¨ç©ºé—´ä¸€è‡´æ€§ã€å¯¼èˆªåŠŸèƒ½å’Œå¤šå±‚ç¯å¢ƒç©æ³•è¿›åº¦æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡ LLMs ç¦»çº¿æ„å»ºåŒ…å«æˆ¿é—´æ¨¡æ¿å’Œè®¾æ–½ç»„ä»¶çš„å¯é‡ç”¨æ•°æ®åº“ï¼Œå¹¶é‡‡ç”¨å¤šé˜¶æ®µæµæ°´çº¿ç»„è£…å…³å¡ã€‚æµç¨‹é¦–å…ˆæ ¹æ®æˆ¿é—´æ•°æ®åº“ (Room Database) æ„å»ºå…·æœ‰æ‹“æ‰‘é¡ºåºçš„å¤šå±‚ç»“æ„ï¼Œéšåä¾æ®è®¾æ–½æ•°æ®åº“ (Facility Database) çš„çº¦æŸä¼˜åŒ–å†…éƒ¨å¸ƒå±€ï¼Œå¹¶æ•´åˆåŸºäºæœºåˆ¶æ•°æ®åº“ (Mechanics Database) çš„ç©æ³•å…ƒç´ ã€‚ç³»ç»Ÿé…å¤‡äº†åŒé˜¶æ®µä¿®å¤æœºåˆ¶ä»¥ç¡®ä¿ç¯å¢ƒçš„å¯¼èˆªè¿é€šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–ä¸”å¯å¯¼èˆªçš„ 3D ç¯å¢ƒï¼Œå¹¶æ”¯æŒé€šè¿‡ç®€å•å‚æ•°åŒ–å®ç°å·®å¼‚åŒ–çš„ç©æ³•èŠ‚å¥æ§åˆ¶ã€‚è¿™é¡¹å·¥ä½œä¸ºè‡ªåŠ¨åŒ–ç”Ÿæˆå…·æœ‰å¯é…ç½®ç©æ³•è¿›åº¦çš„å¤æ‚ 3D å…³å¡æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„ã€ä»¥æ•°æ®åº“ä¸ºä¸­å¿ƒçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18533v1",
      "published_date": "2025-08-25 22:15:08 UTC",
      "updated_date": "2025-08-25 22:15:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:41.055836+00:00"
    },
    {
      "arxiv_id": "2508.18531v1",
      "title": "SAT-SKYLINES: 3D Building Generation from Satellite Imagery and Coarse Geometric Priors",
      "title_zh": "SAT-SKYLINESï¼šåŸºäºå«æ˜Ÿå›¾åƒä¸ç²—å‡ ä½•å…ˆéªŒçš„ä¸‰ç»´å»ºç­‘ç”Ÿæˆ",
      "authors": [
        "Zhangyu Jin",
        "Andrew Feng"
      ],
      "abstract": "We present SatSkylines, a 3D building generation approach that takes satellite imagery and coarse geometric priors. Without proper geometric guidance, existing image-based 3D generation methods struggle to recover accurate building structures from the top-down views of satellite images alone. On the other hand, 3D detailization methods tend to rely heavily on highly detailed voxel inputs and fail to produce satisfying results from simple priors such as cuboids. To address these issues, our key idea is to model the transformation from interpolated noisy coarse priors to detailed geometries, enabling flexible geometric control without additional computational cost. We have further developed Skylines-50K, a large-scale dataset of over 50,000 unique and stylized 3D building assets in order to support the generations of detailed building models. Extensive evaluations indicate the effectiveness of our model and strong generalization ability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SatSkylinesï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å«æ˜Ÿå›¾åƒ (satellite imagery) å’Œç²—ç•¥å‡ ä½•å…ˆéªŒ (coarse geometric priors) è¿›è¡Œä¸‰ç»´å»ºç­‘ç”Ÿæˆçš„æ–°æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰åŸºäºå›¾åƒçš„ç”Ÿæˆæ–¹æ³•åœ¨å¤„ç†å«æ˜Ÿä¿¯è§†å›¾æ—¶éš¾ä»¥æ¢å¤ç²¾ç¡®ç»“æ„ï¼Œä»¥åŠç»†èŠ‚åŒ–æ–¹æ³•è¿‡åº¦ä¾èµ–é«˜ç»†èŠ‚è¾“å…¥çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶é€šè¿‡å»ºæ¨¡ä»å™ªå£°ç²—ç•¥å…ˆéªŒåˆ°è¯¦ç»†å‡ ä½•ç»“æ„çš„è½¬æ¢ï¼Œå®ç°äº†çµæ´»ä¸”ä½æˆæœ¬çš„å‡ ä½•æ§åˆ¶ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†åŒ…å«è¶…è¿‡ 50,000 ä¸ªç‹¬ç‰¹é£æ ¼åŒ–å»ºç­‘èµ„äº§çš„å¤§è§„æ¨¡æ•°æ®é›† Skylines-50Kï¼Œä»¥æ”¯æ’‘ç²¾ç»†æ¨¡å‹çš„ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ç”Ÿæˆè¯¦ç»†å»ºç­‘å‡ ä½•æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¹¶å…·å¤‡å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œæœ‰æ•ˆè§£å†³äº†ä»ç®€å•å‡ ä½•å…ˆéªŒç”Ÿæˆé«˜è´¨é‡ä¸‰ç»´å»ºç­‘çš„éš¾é¢˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18531v1",
      "published_date": "2025-08-25 22:03:31 UTC",
      "updated_date": "2025-08-25 22:03:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:38.357146+00:00"
    },
    {
      "arxiv_id": "2508.18528v1",
      "title": "A Deep Learning Application for Psoriasis Detection",
      "title_zh": "æ·±åº¦å­¦ä¹ åœ¨é“¶å±‘ç—…æ£€æµ‹ä¸­çš„åº”ç”¨",
      "authors": [
        "Anna Milani",
        "FÃ¡bio S. da Silva",
        "ElloÃ¡ B. Guedes",
        "Ricardo Rios"
      ],
      "abstract": "In this paper a comparative study of the performance of three Convolutional Neural Network models, ResNet50, Inception v3 and VGG19 for classification of skin images with lesions affected by psoriasis is presented. The images used for training and validation of the models were obtained from specialized platforms. Some techniques were used to adjust the evaluation metrics of the neural networks. The results found suggest the model Inception v3 as a valuable tool for supporting the diagnosis of psoriasis. This is due to its satisfactory performance with respect to accuracy and F1-Score (97.5% ${\\pm}$ 0.2).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å— Psoriasis å½±å“çš„çš®è‚¤ç—…å˜å›¾åƒåˆ†ç±»ï¼Œå¯¹ ResNet50ã€Inception v3 å’Œ VGG19 ä¸‰ç§ Convolutional Neural Network æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”ç ”ç©¶ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ä»ä¸“ä¸šå¹³å°è·å–çš„å›¾åƒè¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ï¼Œå¹¶é‡‡ç”¨ç›¸å…³æŠ€æœ¯å¯¹ç¥ç»ç½‘ç»œçš„è¯„ä¼°æŒ‡æ ‡è¿›è¡Œäº†ä¼˜åŒ–è°ƒæ•´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒInception v3 æ¨¡å‹åœ¨æ”¯æŒ Psoriasis è¯Šæ–­æ–¹é¢å…·æœ‰æ˜¾è‘—ä»·å€¼ï¼Œå…¶ Accuracy å’Œ F1-Score å‡è¾¾åˆ°äº† 97.5% Â± 0.2ã€‚è¯¥ç ”ç©¶è¯æ˜äº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨çš®è‚¤ç—…æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯ Inception v3 åœ¨å¤„ç†æ­¤ç±»åŒ»ç–—å½±åƒä»»åŠ¡æ—¶å±•ç°å‡ºäº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚è¿™ä¸€æˆæœä¸ºå¼€å‘é«˜æ•ˆã€å‡†ç¡®çš„è‡ªåŠ¨è¾…åŠ©è¯Šæ–­å·¥å…·æä¾›äº†é‡è¦çš„æŠ€æœ¯ä¾æ®ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "15 pages, 4 figures, 1 table, Proceedings of XX Encontro Nacional de InteligÃªncia Artificial e Computacional. in Portuguese language",
      "pdf_url": "https://arxiv.org/pdf/2508.18528v1",
      "published_date": "2025-08-25 21:56:24 UTC",
      "updated_date": "2025-08-25 21:56:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:41.264113+00:00"
    },
    {
      "arxiv_id": "2508.18527v1",
      "title": "Generic Guard AI in Stealth Game with Composite Potential Fields",
      "title_zh": "åŸºäºå¤åˆåŠ¿åœºçš„æ½œè¡Œæ¸¸æˆé€šç”¨å®ˆå« AI",
      "authors": [
        "Kaijie Xu",
        "Clark Verbrugge"
      ],
      "abstract": "Guard patrol behavior is central to the immersion and strategic depth of stealth games, while most existing systems rely on hand-crafted routes or specialized logic that struggle to balance coverage efficiency and responsive pursuit with believable naturalness. We propose a generic, fully explainable, training-free framework that integrates global knowledge and local information via Composite Potential Fields, combining three interpretable maps-Information, Confidence, and Connectivity-into a single kernel-filtered decision criterion. Our parametric, designer-driven approach requires only a handful of decay and weight parameters-no retraining-to smoothly adapt across both occupancy-grid and NavMesh-partition abstractions. We evaluate on five representative game maps, two player-control policies, and five guard modes, confirming that our method outperforms classical baseline methods in both capture efficiency and patrol naturalness. Finally, we show how common stealth mechanics-distractions and environmental elements-integrate naturally into our framework as sub modules, enabling rapid prototyping of rich, dynamic, and responsive guard behaviors.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éšèº«æ¸¸æˆ(Stealth Game)ä¸­å®ˆå«å·¡é€»è¡Œä¸ºéš¾ä»¥å…¼é¡¾è¦†ç›–æ•ˆç‡ã€è¿½é€å“åº”å’Œè‡ªç„¶åº¦çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é€šç”¨ã€å®Œå…¨å¯è§£é‡Šä¸”æ— éœ€è®­ç»ƒçš„AIæ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤åˆåŠ¿åœº(Composite Potential Fields)æ•´åˆå…¨å±€çŸ¥è¯†ä¸å±€éƒ¨ä¿¡æ¯ï¼Œé€šè¿‡å°†ä¿¡æ¯å›¾(Information Map)ã€ç½®ä¿¡åº¦å›¾(Confidence Map)å’Œè¿é€šæ€§å›¾(Connectivity Map)ç»„åˆæˆå•ä¸€çš„æ ¸è¿‡æ»¤å†³ç­–æ ‡å‡†(kernel-filtered decision criterion)æ¥å®ç°æ™ºèƒ½å†³ç­–ã€‚è¿™ç§åŸºäºå‚æ•°å’Œè®¾è®¡å¸ˆé©±åŠ¨çš„æ–¹æ³•æ— éœ€é‡æ–°è®­ç»ƒï¼Œå³å¯å¹³æ»‘é€‚é…å ç”¨ç½‘æ ¼(occupancy-grid)å’Œå¯¼èˆªç½‘æ ¼(NavMesh)ç­‰ç¯å¢ƒæŠ½è±¡ã€‚åœ¨äº”ç§ä»£è¡¨æ€§æ¸¸æˆåœ°å›¾ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æŠ“æ•æ•ˆç‡å’Œå·¡é€»è‡ªç„¶åº¦æ–¹é¢å‡æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯±é¥µ(distractions)å’Œç¯å¢ƒå…ƒç´ ç­‰éšèº«æœºåˆ¶å¯ä½œä¸ºå­æ¨¡å—è‡ªç„¶æ•´åˆï¼Œä¸ºå¼€å‘åŠ¨æ€ã€çµæ•ä¸”å…·æœ‰é«˜å“åº”æ€§çš„å®ˆå«AIæä¾›äº†é«˜æ•ˆçš„å¿«é€ŸåŸå‹æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18527v1",
      "published_date": "2025-08-25 21:56:13 UTC",
      "updated_date": "2025-08-25 21:56:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:42.959180+00:00"
    },
    {
      "arxiv_id": "2508.18520v1",
      "title": "Symmetry-Invariant Novelty Heuristics via Unsupervised Weisfeiler-Leman Features",
      "title_zh": "åŸºäºæ— ç›‘ç£ Weisfeiler-Leman ç‰¹å¾çš„å¯¹ç§°ä¸å˜æ–°é¢–æ€§å¯å‘å¼",
      "authors": [
        "Dillon Z. Chen"
      ],
      "abstract": "Novelty heuristics aid heuristic search by exploring states that exhibit novel atoms. However, novelty heuristics are not symmetry invariant and hence may sometimes lead to redundant exploration. In this preliminary report, we propose to use Weisfeiler-Leman Features for planning (WLFs) in place of atoms for detecting novelty. WLFs are recently introduced features for learning domain-dependent heuristics for generalised planning problems. We explore an unsupervised usage of WLFs for synthesising lifted, domain-independent novelty heuristics that are invariant to symmetric states. Experiments on the classical International Planning Competition and Hard To Ground benchmark suites yield promising results for novelty heuristics synthesised from WLFs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯å‘å¼æœç´¢ä¸­çš„Novelty heuristicsï¼ˆæ–°é¢–æ€§å¯å‘å¼ï¼‰ï¼Œé’ˆå¯¹å…¶ä¸å…·å¤‡Symmetry-invariantï¼ˆå¯¹ç§°ä¸å˜æ€§ï¼‰ä»è€Œå¯¼è‡´å†—ä½™æ¢ç´¢çš„é—®é¢˜ï¼Œæå‡ºäº†åˆ©ç”¨Weisfeiler-Leman Features (WLFs)æ›¿ä»£Atomsï¼ˆåŸå­ï¼‰æ¥æ£€æµ‹æ–°é¢–æ€§ã€‚WLFsæ˜¯ä¸€ç§è¿‘æœŸå¼•å…¥çš„ç”¨äºå­¦ä¹ å¹¿ä¹‰è§„åˆ’é—®é¢˜å¯å‘å¼çš„ç‰¹å¾ï¼Œåœ¨æ­¤è¢«åº”ç”¨äºæå‡æœç´¢æ•ˆç‡ã€‚ä½œè€…æ¢ç´¢äº†WLFsçš„Unsupervisedï¼ˆæ— ç›‘ç£ï¼‰ä½¿ç”¨æ–¹å¼ï¼Œæ—¨åœ¨åˆæˆæå‡çš„ã€åŸŸæ— å…³çš„ä¸”å¯¹å¯¹ç§°çŠ¶æ€å…·æœ‰ä¸å˜æ€§çš„Novelty heuristicsã€‚åœ¨ç»å…¸çš„å›½é™…è§„åˆ’ç«èµ›ï¼ˆIPCï¼‰å’ŒHard To GroundåŸºå‡†æµ‹è¯•é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§åŸºäºWLFsåˆæˆçš„æ–¹æ³•å–å¾—äº†æ˜¾è‘—æˆæœï¼Œä¸ºè§£å†³è§„åˆ’æœç´¢ä¸­çš„å†—ä½™æ¢ç´¢é—®é¢˜æä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "HSDIP@ICAPS 2025 Workshop",
      "pdf_url": "https://arxiv.org/pdf/2508.18520v1",
      "published_date": "2025-08-25 21:46:19 UTC",
      "updated_date": "2025-08-25 21:46:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:46.959663+00:00"
    },
    {
      "arxiv_id": "2508.19303v1",
      "title": "2D Ultrasound Elasticity Imaging of Abdominal Aortic Aneurysms Using Deep Neural Networks",
      "title_zh": "åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„è…¹ä¸»åŠ¨è„‰ç˜¤äºŒç»´è¶…å£°å¼¹æ€§æˆåƒ",
      "authors": [
        "Utsav Ratna Tuladhar",
        "Richard Simon",
        "Doran Mix",
        "Michael Richards"
      ],
      "abstract": "Abdominal aortic aneurysms (AAA) pose a significant clinical risk due to their potential for rupture, which is often asymptomatic but can be fatal. Although maximum diameter is commonly used for risk assessment, diameter alone is insufficient as it does not capture the properties of the underlying material of the vessel wall, which play a critical role in determining the risk of rupture. To overcome this limitation, we propose a deep learning-based framework for elasticity imaging of AAAs with 2D ultrasound. Leveraging finite element simulations, we generate a diverse dataset of displacement fields with their corresponding modulus distributions. We train a model with U-Net architecture and normalized mean squared error (NMSE) to infer the spatial modulus distribution from the axial and lateral components of the displacement fields. This model is evaluated across three experimental domains: digital phantom data from 3D COMSOL simulations, physical phantom experiments using biomechanically distinct vessel models, and clinical ultrasound exams from AAA patients. Our simulated results demonstrate that the proposed deep learning model is able to reconstruct modulus distributions, achieving an NMSE score of 0.73\\%. Similarly, in phantom data, the predicted modular ratio closely matches the expected values, affirming the model's ability to generalize to phantom data. We compare our approach with an iterative method which shows comparable performance but higher computation time. In contrast, the deep learning method can provide quick and effective estimates of tissue stiffness from ultrasound images, which could help assess the risk of AAA rupture without invasive procedures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è…¹ä¸»åŠ¨è„‰ç˜¤(Abdominal aortic aneurysms, AAA)ç ´è£‚é£é™©è¯„ä¼°ä¸­ä»…ä¾èµ–ç›´å¾„æŒ‡æ ‡çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ (Deep learning)çš„2Dè¶…å£°å¼¹æ€§æˆåƒæ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æœ‰é™å…ƒæ¨¡æ‹Ÿ(Finite element simulations)ç”Ÿæˆä½ç§»åœºåŠå…¶å¯¹åº”çš„æ¨¡é‡åˆ†å¸ƒ(Modulus distributions)æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨U-Netæ¶æ„è®­ç»ƒæ¨¡å‹ï¼Œé€šè¿‡å½’ä¸€åŒ–å‡æ–¹è¯¯å·®(NMSE)ä»ä½ç§»åœºçš„è½´å‘å’Œæ¨ªå‘åˆ†é‡ä¸­æ¨æ–­ç©ºé—´æ¨¡é‡åˆ†å¸ƒã€‚è¯¥æ¨¡å‹åœ¨3D COMSOLæ¨¡æ‹Ÿæ•°æ®ã€ç‰©ç†æ¨¡å‹å®éªŒä»¥åŠAAAæ‚£è€…ä¸´åºŠè¶…å£°æ£€æŸ¥ä¸­è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æ¨¡æ‹Ÿæ•°æ®ä¸­å®ç°äº†0.73%çš„NMSEè¯„åˆ†ï¼Œä¸”åœ¨ç‰©ç†æ¨¡å‹å®éªŒä¸­å±•ç°äº†è‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚ç›¸æ¯”ä¼ ç»Ÿçš„è¿­ä»£æ–¹æ³•(Iterative method)ï¼Œè¯¥æ·±åº¦å­¦ä¹ æ–¹æ³•æ˜¾è‘—é™ä½äº†è®¡ç®—æ—¶é—´ï¼Œèƒ½å¤Ÿå¿«é€Ÿã€æœ‰æ•ˆåœ°ä¼°ç®—ç»„ç»‡ç¡¬åº¦ã€‚è¯¥æˆæœä¸ºä¸´åºŠéä¾µå…¥æ€§è¯„ä¼°AAAç ´è£‚é£é™©æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å…·å¤‡æ½œåŠ›çš„æŠ€æœ¯æ‰‹æ®µã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19303v1",
      "published_date": "2025-08-25 21:42:54 UTC",
      "updated_date": "2025-08-25 21:42:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:01.086273+00:00"
    },
    {
      "arxiv_id": "2508.18515v1",
      "title": "Weisfeiler-Leman Features for Planning: A 1,000,000 Sample Size Hyperparameter Study",
      "title_zh": "é¢å‘è§„åˆ’çš„ Weisfeiler-Leman ç‰¹å¾ï¼šç™¾ä¸‡æ ·æœ¬è§„æ¨¡çš„è¶…å‚æ•°ç ”ç©¶",
      "authors": [
        "Dillon Z. Chen"
      ],
      "abstract": "Weisfeiler-Leman Features (WLFs) are a recently introduced classical machine learning tool for learning to plan and search. They have been shown to be both theoretically and empirically superior to existing deep learning approaches for learning value functions for search in symbolic planning. In this paper, we introduce new WLF hyperparameters and study their various tradeoffs and effects. We utilise the efficiency of WLFs and run planning experiments on single core CPUs with a sample size of 1,000,000 to understand the effect of hyperparameters on training and planning. Our experimental analysis show that there is a robust and best set of hyperparameters for WLFs across the tested planning domains. We find that the best WLF hyperparameters for learning heuristic functions minimise execution time rather than maximise model expressivity. We further statistically analyse and observe no significant correlation between training and planning metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”¨äºè§„åˆ’å’Œæœç´¢çš„ç»å…¸æœºå™¨å­¦ä¹ å·¥å…· Weisfeiler-Leman Features (WLFs) è¿›è¡Œäº†æ·±å…¥æ¢è®¨ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¬¦å·è§„åˆ’(symbolic planning)ä¸­å­¦ä¹ å¯å‘å¼å‡½æ•°(heuristic functions)çš„åº”ç”¨ã€‚è®ºæ–‡å¼•å…¥äº†æ–°çš„ WLFs è¶…å‚æ•°(hyperparameters)ï¼Œå¹¶åˆ©ç”¨å…¶é«˜æ•ˆç‡åœ¨å•æ ¸ CPU ä¸Šå¼€å±•äº†æ ·æœ¬é‡é«˜è¾¾ 1,000,000 çš„å¤§è§„æ¨¡è¶…å‚æ•°å¯¹æ¯”å®éªŒï¼Œä»¥åˆ†æä¸åŒå‚æ•°é—´çš„æƒè¡¡ä¸å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸åŒçš„è§„åˆ’é¢†åŸŸä¸­å­˜åœ¨ä¸€å¥—é²æ£’ä¸”æœ€ä½³çš„ WLFs è¶…å‚æ•°ç»„åˆã€‚ç ”ç©¶å‘ç°ï¼Œå­¦ä¹ å¯å‘å¼å‡½æ•°çš„æœ€ä½³ WLFs è¶…å‚æ•°é…ç½®æ›´å€¾å‘äºæœ€å°åŒ–æ‰§è¡Œæ—¶é—´(execution time)ï¼Œè€Œéè¿½æ±‚æœ€å¤§åŒ–æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›(model expressivity)ã€‚æ­¤å¤–ï¼Œç»Ÿè®¡åˆ†ææ˜¾ç¤ºè®­ç»ƒæŒ‡æ ‡(training metrics)ä¸è§„åˆ’æŒ‡æ ‡(planning metrics)ä¹‹é—´å¹¶æ— æ˜¾è‘—ç›¸å…³æ€§ï¼Œè¿™ä¸ºç†è§£å’Œä¼˜åŒ– WLFs åœ¨è§„åˆ’ä»»åŠ¡ä¸­çš„è¡¨ç°æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of ECAI 2025 paper",
      "pdf_url": "https://arxiv.org/pdf/2508.18515v1",
      "published_date": "2025-08-25 21:39:03 UTC",
      "updated_date": "2025-08-25 21:39:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:52:53.950758+00:00"
    },
    {
      "arxiv_id": "2508.18509v1",
      "title": "Analise de Desaprendizado de Maquina em Modelos de Classificacao de Imagens Medicas",
      "title_zh": "åŒ»å­¦å›¾åƒåˆ†ç±»æ¨¡å‹ä¸­çš„æœºå™¨é—å¿˜åˆ†æ",
      "authors": [
        "Andreza M. C. Falcao",
        "Filipe R. Cordeiro"
      ],
      "abstract": "Machine unlearning aims to remove private or sensitive data from a pre-trained model while preserving the model's robustness. Despite recent advances, this technique has not been explored in medical image classification. This work evaluates the SalUn unlearning model by conducting experiments on the PathMNIST, OrganAMNIST, and BloodMNIST datasets. We also analyse the impact of data augmentation on the quality of unlearning. Results show that SalUn achieves performance close to full retraining, indicating an efficient solution for use in medical applications.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶æ¢è®¨äº†æœºå™¨å¸è½½(Machine Unlearning)æŠ€æœ¯åœ¨åŒ»ç–—å›¾åƒåˆ†ç±»æ¨¡å‹ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­ç§»é™¤ç§å¯†æˆ–æ•æ„Ÿæ•°æ®å¹¶ä¿æŒæ¨¡å‹çš„ç¨³å¥æ€§ã€‚ä½œè€…é€šè¿‡åœ¨ PathMNISTã€OrganAMNIST å’Œ BloodMNIST æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œç³»ç»Ÿè¯„ä¼°äº† SalUn å¸è½½æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚ç ”ç©¶è¿˜æ·±å…¥åˆ†æäº†æ•°æ®å¢å¼º(data augmentation)å¯¹å¸è½½è´¨é‡çš„å…·ä½“å½±å“ï¼Œå¡«è¡¥äº†è¯¥æŠ€æœ¯åœ¨åŒ»ç–—å½±åƒé¢†åŸŸç ”ç©¶çš„ç©ºç™½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSalUn çš„å¸è½½æ•ˆæœæ¥è¿‘äºå®Œå…¨é‡æ–°è®­ç»ƒ(full retraining)çš„æ°´å¹³ã€‚è¿™è¯æ˜äº† SalUn æ˜¯ä¸€ç§é€‚ç”¨äºåŒ»ç–—åº”ç”¨çš„é«˜æ•ˆè§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡æ•°æ®éšç§ä¿æŠ¤ä¸æ¨¡å‹æ€§èƒ½ç»´æŒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at SBCAS'25. in Portuguese language",
      "pdf_url": "https://arxiv.org/pdf/2508.18509v1",
      "published_date": "2025-08-25 21:28:33 UTC",
      "updated_date": "2025-08-25 21:28:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:15.450946+00:00"
    },
    {
      "arxiv_id": "2508.18507v1",
      "title": "Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic Policies",
      "title_zh": "é¢å‘é€šç”¨ PDDL è§„åˆ’çš„è¯­è¨€æ¨¡å‹ï¼šåˆæˆå¯é çš„ç¨‹åºåŒ–ç­–ç•¥",
      "authors": [
        "Dillon Z. Chen",
        "Johannes Zenn",
        "Tristan Cinquin",
        "Sheila A. McIlraith"
      ],
      "abstract": "We study the usage of language models (LMs) for planning over world models specified in the Planning Domain Definition Language (PDDL). We prompt LMs to generate Python programs that serve as generalised policies for solving PDDL problems from a given domain. Notably, our approach synthesises policies that are provably sound relative to the PDDL domain without reliance on external verifiers. We conduct experiments on competition benchmarks which show that our policies can solve more PDDL problems than PDDL planners and recent LM approaches within a fixed time and memory constraint. Our approach manifests in the LMPlan planner which can solve planning problems with several hundreds of relevant objects. Surprisingly, we observe that LMs used in our framework sometimes plan more effectively over PDDL problems written in meaningless symbols in place of natural language; e.g. rewriting (at dog kitchen) as (p2 o1 o3). This finding challenges hypotheses that LMs reason over word semantics and memorise solutions from its training corpus, and is worth further exploration.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨è¯­è¨€æ¨¡å‹ (LMs) åœ¨åŸºäºè§„åˆ’é¢†åŸŸå®šä¹‰è¯­è¨€ (PDDL) æè¿°çš„ä¸–ç•Œæ¨¡å‹ä¸­è¿›è¡Œè§„åˆ’ï¼Œå¹¶æå‡ºäº†é€šè¿‡æç¤ºè¯å¼•å¯¼ LMs ç”Ÿæˆ Python ç¨‹åºä½œä¸ºé€šç”¨ç­–ç•¥çš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•åˆæˆçš„ç­–ç•¥åœ¨ PDDL é¢†åŸŸå†…å…·å¤‡å¯è¯æ˜çš„å®Œå¤‡æ€§ (sound)ï¼Œä¸”æ— éœ€ä¾èµ–å¤–éƒ¨éªŒè¯å™¨ã€‚è¯¥æ–¹æ³•å®ç°ä¸ºåä¸º LMPlan çš„è§„åˆ’å™¨ï¼Œå®éªŒè¡¨æ˜åœ¨å›ºå®šæ—¶é—´å’Œå†…å­˜é™åˆ¶ä¸‹ï¼Œå…¶è§£å†³ PDDL é—®é¢˜çš„èƒ½åŠ›ä¼˜äºä¼ ç»Ÿ PDDL è§„åˆ’å™¨å’Œç°æœ‰çš„ LM æ–¹æ³•ã€‚LMPlan èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†åŒ…å«æ•°ç™¾ä¸ªç›¸å…³å¯¹è±¡çš„å¤æ‚è§„åˆ’ä»»åŠ¡ã€‚ç ”ç©¶è¿˜è§‚å¯Ÿåˆ°ä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ï¼Œå³ LMs åœ¨å¤„ç†ä½¿ç”¨æ— æ„ä¹‰ç¬¦å·æ›¿ä»£è‡ªç„¶è¯­è¨€æè¿°çš„ PDDL é—®é¢˜æ—¶ï¼Œæœ‰æ—¶è§„åˆ’æ•ˆæœç”šè‡³æ›´å¥½ã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº† LMs ä»…ä¾èµ–è¯æ±‡è¯­ä¹‰è¿›è¡Œæ¨ç†æˆ–å•çº¯è®°å¿†è®­ç»ƒè¯­æ–™åº“è§£æ³•çš„å‡è®¾ï¼Œä¸ºè¿›ä¸€æ­¥æ¢ç´¢å…¶æ¨ç†æœºåˆ¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "RLC 2025 Workshop on Programmatic Reinforcement Learning",
      "pdf_url": "https://arxiv.org/pdf/2508.18507v1",
      "published_date": "2025-08-25 21:28:14 UTC",
      "updated_date": "2025-08-25 21:28:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:19.787773+00:00"
    },
    {
      "arxiv_id": "2509.07991v1",
      "title": "DLGE: Dual Local-Global Encoding for Generalizable Cross-BCI-Paradigm",
      "title_zh": "DLGEï¼šé¢å‘å¯æ³›åŒ–è·¨ BCI èŒƒå¼çš„åŒé‡å±€éƒ¨-å…¨å±€ç¼–ç ",
      "authors": [
        "Jingyuan Wang",
        "Junhua Li"
      ],
      "abstract": "Deep learning models have been frequently used to decode a single brain-computer interface (BCI) paradigm based on electroencephalography (EEG). It is challenging to decode multiple BCI paradigms using one model due to diverse barriers, such as different channel configurations and disparate task-related representations. In this study, we propose Dual Local-Global Encoder (DLGE), enabling the classification across different BCI paradigms. To address the heterogeneity in EEG channel configurations across paradigms, we employ an anatomically inspired brain-region partitioning and padding strategy to standardize EEG channel configuration. In the proposed model, the local encoder is designed to learn shared features across BCI paradigms within each brain region based on time-frequency information, which integrates temporal attention on individual channels with spatial attention among channels for each brain region. These shared features are subsequently aggregated in the global encoder to form respective paradigm-specific feature representations. Three BCI paradigms (motor imagery, resting state, and driving fatigue) were used to evaluate the proposed model. The results demonstrate that our model is capable of processing diverse BCI paradigms without retraining and retuning, achieving average macro precision, recall, and F1-score of 60.16\\%, 59.88\\%, and 59.56\\%, respectively. We made an initial attempt to develop a general model for cross-BCI-paradigm classification, avoiding retraining or redevelopment for each paradigm. This study paves the way for the development of an effective but simple model for cross-BCI-paradigm decoding, which might benefit the design of portable devices for universal BCI decoding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DLGE (Dual Local-Global Encoding)ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè·¨è„‘æœºæ¥å£ (BCI) èŒƒå¼åˆ†ç±»çš„é€šç”¨è§£ç æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¤šèŒƒå¼ä¸‹è„‘ç”µå›¾ (EEG) é€šé“é…ç½®å·®å¼‚å’Œä»»åŠ¡è¡¨å¾ä¸ä¸€è‡´çš„æŒ‘æˆ˜ã€‚ç ”ç©¶é‡‡ç”¨åŸºäºè§£å‰–å­¦çš„è„‘åŒºåˆ’åˆ†å’Œå¡«å……ç­–ç•¥æ¥æ ‡å‡†åŒ–ä¸åŒèŒƒå¼çš„é€šé“é…ç½®ï¼Œå¹¶é€šè¿‡ Local Encoder å­¦ä¹ å„è„‘åŒºå†…åŸºäºæ—¶é¢‘ä¿¡æ¯çš„å…±äº«ç‰¹å¾ï¼Œç»“åˆäº†å•é€šé“çš„æ—¶é—´æ³¨æ„åŠ›å’ŒåŒºåŸŸå†…çš„ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶ã€‚éšåï¼ŒGlobal Encoder å°†è¿™äº›ç‰¹å¾èšåˆä»¥å½¢æˆç‰¹å®šçš„èŒƒå¼è¡¨å¾ï¼Œå®ç°äº†åœ¨è¿åŠ¨æƒ³è±¡ã€é™æ¯æ€å’Œé©¾é©¶ç–²åŠ³ä¸‰ç±»èŒƒå¼ä¸Šçš„æœ‰æ•ˆè§£ç ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDLGE åœ¨æ— éœ€é‡æ–°è®­ç»ƒæˆ–è°ƒä¼˜çš„æƒ…å†µä¸‹ï¼Œå®ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œ F1-score åˆ†åˆ«è¾¾åˆ° 60.16%ã€59.88% å’Œ 59.56%ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘é€šç”¨å‹ã€ä¾¿æºå¼ BCI è§£ç è®¾å¤‡æä¾›äº†æœ‰æ•ˆä¸”ç®€æ´çš„æ¨¡å‹æ–¹æ¡ˆï¼ŒæˆåŠŸå®ç°äº†è·¨èŒƒå¼ç¥ç»ä¿¡å·è§£æçš„åˆæ­¥å°è¯•ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07991v1",
      "published_date": "2025-08-25 21:28:08 UTC",
      "updated_date": "2025-08-25 21:28:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:29.987242+00:00"
    },
    {
      "arxiv_id": "2508.18502v1",
      "title": "Data Augmentation Improves Machine Unlearning",
      "title_zh": "æ•°æ®å¢å¼ºæå‡æœºå™¨é—å¿˜",
      "authors": [
        "Andreza M. C. Falcao",
        "Filipe R. Cordeiro"
      ],
      "abstract": "Machine Unlearning (MU) aims to remove the influence of specific data from a trained model while preserving its performance on the remaining data. Although a few works suggest connections between memorisation and augmentation, the role of systematic augmentation design in MU remains under-investigated. In this work, we investigate the impact of different data augmentation strategies on the performance of unlearning methods, including SalUn, Random Label, and Fine-Tuning. Experiments conducted on CIFAR-10 and CIFAR-100, under varying forget rates, show that proper augmentation design can significantly improve unlearning effectiveness, reducing the performance gap to retrained models. Results showed a reduction of up to 40.12% of the Average Gap unlearning Metric, when using TrivialAug augmentation. Our results suggest that augmentation not only helps reduce memorization but also plays a crucial role in achieving privacy-preserving and efficient unlearning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ•°æ®å¢å¼º (Data Augmentation) åœ¨æœºå™¨å¸è½½ (Machine Unlearning, MU) ä¸­çš„ä½œç”¨ï¼Œæ—¨åœ¨æ¶ˆé™¤ç‰¹å®šæ•°æ®å¯¹å·²è®­ç»ƒæ¨¡å‹çš„å½±å“å¹¶ç»´æŒå…¶åœ¨å‰©ä½™æ•°æ®ä¸Šçš„æ€§èƒ½ã€‚é’ˆå¯¹ç›®å‰ç³»ç»Ÿæ€§å¢å¼ºè®¾è®¡åœ¨å¸è½½é¢†åŸŸç ”ç©¶ä¸è¶³çš„ç°çŠ¶ï¼Œæœ¬æ–‡ç ”ç©¶äº†ä¸åŒå¢å¼ºç­–ç•¥å¯¹ SalUnã€Random Label å’Œ Fine-Tuning ç­‰å¸è½½æ–¹æ³•çš„å½±å“ã€‚åœ¨ CIFAR-10 å’Œ CIFAR-100 æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œåˆç†çš„å¢å¼ºè®¾è®¡èƒ½æ˜¾è‘—æå‡å¸è½½æ•ˆèƒ½ï¼Œæœ‰æ•ˆç¼©å°ä¸é‡æ–°è®­ç»ƒæ¨¡å‹ (retrained models) ä¹‹é—´çš„è¡¨ç°å·®è·ã€‚ç ”ç©¶å‘ç°ï¼Œä½¿ç”¨ TrivialAug å¢å¼ºç­–ç•¥å¯å°†å¹³å‡å¸è½½å·®è·æŒ‡æ ‡ (Average Gap unlearning Metric) é™ä½å¤šè¾¾ 40.12%ã€‚å®éªŒç»“æœè¯æ˜ï¼Œæ•°æ®å¢å¼ºä¸ä»…æœ‰åŠ©äºå‡å°‘æ¨¡å‹å¯¹ç‰¹å®šæ•°æ®çš„è®°å¿†åŒ– (memorization)ï¼Œè¿˜åœ¨å®ç°éšç§ä¿æŠ¤å’Œé«˜æ•ˆå¸è½½ä¸­å‘æŒ¥ç€è‡³å…³é‡è¦ä½œç”¨ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨æœºå™¨å¸è½½æµç¨‹ä¸­æ•´åˆç³»ç»Ÿæ€§æ•°æ®å¢å¼ºè®¾è®¡çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at SIBGRAPI'25",
      "pdf_url": "https://arxiv.org/pdf/2508.18502v1",
      "published_date": "2025-08-25 21:17:25 UTC",
      "updated_date": "2025-08-25 21:17:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:40.291114+00:00"
    },
    {
      "arxiv_id": "2508.18488v1",
      "title": "Collaborative Intelligence: Topic Modelling of Large Language Model use in Live Cybersecurity Operations",
      "title_zh": "åä½œæ™ºèƒ½ï¼šå®æ—¶ç½‘ç»œå®‰å…¨è¿è¥ä¸­å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„ä¸»é¢˜å»ºæ¨¡",
      "authors": [
        "Martin Lochner",
        "Keegan Keplinger"
      ],
      "abstract": "Objective: This work describes the topic modelling of Security Operations Centre (SOC) use of a large language model (LLM), during live security operations. The goal is to better understand how these specialists voluntarily use this tool.\n  Background: Human-automation teams have been extensively studied, but transformer-based language models have sparked a new wave of collaboration. SOC personnel at a major cybersecurity provider used an LLM to support live security operations. This study examines how these specialists incorporated the LLM into their work.\n  Method: Our data set is the result of 10 months of SOC operators accessing GPT-4 over an internally deployed HTTP-based chat application. We performed two topic modelling exercises, first using the established BERTopic model (Grootendorst, 2022), and second, using a novel topic modeling workflow.\n  Results: Both the BERTopic analysis and novel modelling approach revealed that SOC operators primarily used the LLM to facilitate their understanding of complex text strings. Variations on this use-case accounted for ~40% of SOC LLM usage.\n  Conclusion: SOC operators are required to rapidly interpret complex commands and similar information. Their natural tendency to leverage LLMs to support this activity indicates that their workflow can be supported and augmented by designing collaborative LLM tools for use in the SOC.\n  Application: This work can aid in creating next-generation tools for Security Operations Centres. By understanding common use-cases, we can develop workflows supporting SOC task flow. One example is a right-click context menu for executing a command line analysis LLM call directly in the SOC environment.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å®‰å…¨è¿è¥ä¸­å¿ƒ (SOC) äººå‘˜åœ¨çœŸå®ç½‘ç»œå®‰å…¨ä»»åŠ¡ä¸­è‡ªå‘ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æƒ…å†µï¼Œæ—¨åœ¨æ¢ç´¢äººç±»ä¸“å®¶ä¸ transformer æ¨¡å‹ä¹‹é—´çš„åä½œæœºåˆ¶ã€‚ç ”ç©¶äººå‘˜æ”¶é›†äº†æŸå¤§å‹å®‰å…¨æœåŠ¡å•†çš„ SOC è¿è¥å•†åœ¨ 10 ä¸ªæœˆå†…é€šè¿‡å†…éƒ¨åº”ç”¨è°ƒç”¨ GPT-4 çš„äº¤äº’æ•°æ®ï¼Œå¹¶é‡‡ç”¨äº† BERTopic æ¨¡å‹å’Œä¸€ç§æ–°å‹çš„ä¸»é¢˜å»ºæ¨¡ (Topic Modelling) å·¥ä½œæµè¿›è¡Œæ·±å…¥åˆ†æã€‚ç»“æœæ˜¾ç¤ºï¼Œçº¦ 40% çš„ LLM ä½¿ç”¨åœºæ™¯é›†ä¸­åœ¨è¾…åŠ©è¿è¥å•†ç†è§£å¤æ‚çš„æ–‡æœ¬å­—ç¬¦ä¸²å’ŒæŒ‡ä»¤ï¼Œæ­ç¤ºäº†ä¸“å®¶åœ¨å¿«é€Ÿè§£è¯»æ­¤ç±»ä¿¡æ¯æ—¶çš„æ ¸å¿ƒè¯‰æ±‚ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒSOC è¿è¥å•†çš„å¤©ç„¶ä½¿ç”¨å€¾å‘è¯æ˜äº† LLM åœ¨å¢å¼ºå®‰å…¨å·¥ä½œæµæ–¹é¢çš„ä»·å€¼ï¼Œå¹¶å»ºè®®é€šè¿‡å¼€å‘é›†æˆåŒ–çš„åä½œå·¥å…·ï¼ˆå¦‚å³é”®èœå•å¼çš„å‘½ä»¤è¡Œåˆ†æåŠŸèƒ½ï¼‰æ¥ä¼˜åŒ–ä»»åŠ¡æµã€‚è¿™é¡¹å·¥ä½œä¸ºè®¾è®¡ä¸‹ä¸€ä»£æ™ºèƒ½åŒ–å®‰å…¨è¿è¥ä¸­å¿ƒå·¥å…·æä¾›äº†å®è¯æ”¯æŒï¼Œå¼ºè°ƒäº†é’ˆå¯¹ç‰¹å®šç”¨ä¾‹å®šåˆ¶ LLM å·¥ä½œæµä»¥å®ç°åä½œæ™ºèƒ½ (Collaborative Intelligence) çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18488v1",
      "published_date": "2025-08-25 21:02:13 UTC",
      "updated_date": "2025-08-25 21:02:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:30.385100+00:00"
    },
    {
      "arxiv_id": "2508.18474v1",
      "title": "DRTA: Dynamic Reward Scaling for Reinforcement Learning in Time Series Anomaly Detection",
      "title_zh": "DRTAï¼šé¢å‘æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ä¸­å¼ºåŒ–å­¦ä¹ çš„åŠ¨æ€å¥–åŠ±ç¼©æ”¾",
      "authors": [
        "Bahareh Golchin",
        "Banafsheh Rekabdar",
        "Kunpeng Liu"
      ],
      "abstract": "Anomaly detection in time series data is important for applications in finance, healthcare, sensor networks, and industrial monitoring. Traditional methods usually struggle with limited labeled data, high false-positive rates, and difficulty generalizing to novel anomaly types. To overcome these challenges, we propose a reinforcement learning-based framework that integrates dynamic reward shaping, Variational Autoencoder (VAE), and active learning, called DRTA. Our method uses an adaptive reward mechanism that balances exploration and exploitation by dynamically scaling the effect of VAE-based reconstruction error and classification rewards. This approach enables the agent to detect anomalies effectively in low-label systems while maintaining high precision and recall. Our experimental results on the Yahoo A1 and Yahoo A2 benchmark datasets demonstrate that the proposed method consistently outperforms state-of-the-art unsupervised and semi-supervised approaches. These findings show that our framework is a scalable and efficient solution for real-world anomaly detection tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸ºDRTAçš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºè§£å†³æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹(Time Series Anomaly Detection)ä¸­ç”±äºæ ‡æ³¨æ•°æ®åŒ®ä¹ã€é«˜è¯¯æŠ¥ç‡åŠæ³›åŒ–èƒ½åŠ›ä¸è¶³å¸¦æ¥çš„éš¾é¢˜ã€‚DRTAé›†æˆäº†åŠ¨æ€å¥–åŠ±å¡‘é€ (Dynamic Reward Shaping)ã€å˜åˆ†è‡ªç¼–ç å™¨(VAE)å’Œä¸»åŠ¨å­¦ä¹ (Active Learning)ï¼Œé€šè¿‡ä¸€ç§è‡ªé€‚åº”å¥–åŠ±æœºåˆ¶æ¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ã€‚è¯¥æœºåˆ¶èƒ½å¤ŸåŠ¨æ€ç¼©æ”¾åŸºäºVAEçš„é‡æ„è¯¯å·®(Reconstruction Error)ä¸åˆ†ç±»å¥–åŠ±çš„å½±å“ï¼Œä½¿æ™ºèƒ½ä½“åœ¨ä½æ ‡ç­¾ç³»ç»Ÿä¸­ä¾ç„¶èƒ½ä¿æŒé«˜ç²¾ç¡®ç‡å’Œé«˜å¬å›ç‡ã€‚åœ¨Yahoo A1å’ŒYahoo A2åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDRTAçš„æ€§èƒ½æŒç»­ä¼˜äºç°æœ‰çš„æ— ç›‘ç£å’ŒåŠç›‘ç£æœ€å…ˆè¿›æ–¹æ³•ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è¯¥æ¡†æ¶æ˜¯å¤„ç†ç°å®ä¸–ç•Œå¼‚å¸¸æ£€æµ‹ä»»åŠ¡çš„ä¸€ç§é«˜æ•ˆä¸”å…·å¤‡å¯æ‰©å±•æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18474v1",
      "published_date": "2025-08-25 20:39:49 UTC",
      "updated_date": "2025-08-25 20:39:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:38.790199+00:00"
    },
    {
      "arxiv_id": "2508.18473v2",
      "title": "Principled Detection of Hallucinations in Large Language Models via Multiple Testing",
      "title_zh": "åŸºäºå¤šé‡æ£€éªŒçš„å¤§è¯­è¨€æ¨¡å‹å¹»è§‰è§„èŒƒåŒ–æ£€æµ‹",
      "authors": [
        "Jiawei Li",
        "Akshayaa Magesh",
        "Venugopal V. Veeravalli"
      ],
      "abstract": "While Large Language Models (LLMs) have emerged as powerful foundational models to solve a variety of tasks, they have also been shown to be prone to hallucinations, i.e., generating responses that sound confident but are actually incorrect or even nonsensical. In this work, we formulate the problem of detecting hallucinations as a hypothesis testing problem and draw parallels to the problem of out-of-distribution detection in machine learning models. We propose a multiple-testing-inspired method to solve the hallucination detection problem, and provide extensive experimental results to validate the robustness of our approach against state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)å®¹æ˜“äº§ç”Ÿå¹»è§‰(hallucinations)çš„é—®é¢˜ï¼Œå³ç”Ÿæˆå¬èµ·æ¥è‡ªä¿¡ä½†å†…å®¹é”™è¯¯æˆ–æ— æ„ä¹‰çš„å“åº”ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåŸåˆ™çš„æ£€æµ‹æ–¹æ¡ˆã€‚ä½œè€…å°†å¹»è§‰æ£€æµ‹ä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºä¸€ä¸ªå‡è®¾æ£€éªŒ(hypothesis testing)é—®é¢˜ï¼Œå¹¶å»ºç«‹äº†å…¶ä¸æœºå™¨å­¦ä¹ ä¸­åˆ†å¸ƒå¤–æ£€æµ‹(out-of-distribution detection)ä¹‹é—´çš„è”ç³»ã€‚é€šè¿‡å¼•å…¥å—å¤šé‡æ£€éªŒ(multiple testing)å¯å‘çš„æ–¹æ³•ï¼Œè¯¥ç ”ç©¶ä¸ºç³»ç»Ÿæ€§è¯†åˆ«æ¨¡å‹é”™è¯¯æä¾›äº†ç»Ÿè®¡å­¦æ¡†æ¶ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åº”å¯¹å¹»è§‰æ£€æµ‹æ—¶è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œä¸”æ€§èƒ½ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„æ–¹æ³•(state-of-the-art methods)ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.18473v2",
      "published_date": "2025-08-25 20:39:30 UTC",
      "updated_date": "2025-08-27 14:55:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:46.497961+00:00"
    },
    {
      "arxiv_id": "2508.18467v1",
      "title": "The AI in the Mirror: LLM Self-Recognition in an Iterated Public Goods Game",
      "title_zh": "é•œä¸­ AIï¼šè¿­ä»£å…¬å…±ç‰©å“åšå¼ˆä¸­çš„ LLM è‡ªæˆ‘è¯†åˆ«",
      "authors": [
        "Olivia Long",
        "Carter Teplica"
      ],
      "abstract": "As AI agents become increasingly capable of tool use and long-horizon tasks, they have begun to be deployed in settings where multiple agents can interact. However, whereas prior work has mostly focused on human-AI interactions, there is an increasing need to understand AI-AI interactions. In this paper, we adapt the iterated public goods game, a classic behavioral economics game, to analyze the behavior of four reasoning and non-reasoning models across two conditions: models are either told they are playing against \"another AI agent\" or told their opponents are themselves. We find that, across different settings, telling LLMs that they are playing against themselves significantly changes their tendency to cooperate. While our study is conducted in a toy environment, our results may provide insights into multi-agent settings where agents \"unconsciously\" discriminating against each other could inexplicably increase or decrease cooperation.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡æ”¹è¿›ç»å…¸è¡Œä¸ºç»æµå­¦ä¸­çš„è¿­ä»£å…¬å…±ç‰©å“åšå¼ˆ(Iterated Public Goods Game)ï¼Œæ·±å…¥åˆ†æäº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨AI-AIäº’åŠ¨ä¸­çš„è‡ªæˆ‘è¯†åˆ«(Self-Recognition)è¡Œä¸ºã€‚ç ”ç©¶å¯¹æ¯”äº†å››ç§å…·æœ‰æ¨ç†å’Œéæ¨ç†èƒ½åŠ›çš„æ¨¡å‹ï¼Œå¹¶åœ¨å‘ŠçŸ¥å¯¹æ‰‹æ˜¯â€œå¦ä¸€AIæ™ºèƒ½ä½“â€æˆ–å…¶â€œè‡ªèº«â€ä¸¤ç§æ¡ä»¶ä¸‹è§‚å¯Ÿå…¶å†³ç­–å·®å¼‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä»…ä»…æ˜¯æ˜ç¡®å¯¹æ‰‹èº«ä»½ä¸ºè‡ªèº«ï¼Œå°±ä¼šæ˜¾è‘—æ”¹å˜LLMsçš„åˆä½œå€¾å‘ã€‚å°½ç®¡è¯¥é¡¹ç ”ç©¶æ˜¯åœ¨ç®€åŒ–çš„æ¨¡æ‹Ÿç¯å¢ƒ(Toy Environment)ä¸­å¼€å±•çš„ï¼Œå…¶å‘ç°æ­ç¤ºäº†åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-Agent Settings)ä¸­ï¼Œæ™ºèƒ½ä½“å¯èƒ½äº§ç”Ÿâ€œæ— æ„è¯†â€çš„ç›¸äº’æ­§è§†ï¼Œè¿›è€Œå¯¼è‡´åˆä½œæ°´å¹³å‡ºç°ä¸å¯é¢„æµ‹çš„æ³¢åŠ¨ã€‚è¿™ä¸€å‘ç°ä¸ºç†è§£æœªæ¥å¤æ‚çš„è‡ªä¸»æ™ºèƒ½ä½“åä½œä¸ç«äº‰æœºåˆ¶æä¾›äº†é‡è¦çš„ç†è®ºæ´å¯Ÿã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18467v1",
      "published_date": "2025-08-25 20:35:03 UTC",
      "updated_date": "2025-08-25 20:35:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:53.692739+00:00"
    },
    {
      "arxiv_id": "2508.18464v2",
      "title": "Vectorized Attention with Learnable Encoding for Quantum Transformer",
      "title_zh": "é¢å‘é‡å­ Transformer çš„å¯å­¦ä¹ ç¼–ç å‘é‡åŒ–æ³¨æ„åŠ›",
      "authors": [
        "Ziqing Guo",
        "Ziwen Pan",
        "Alex Khan",
        "Jan Balewski"
      ],
      "abstract": "Vectorized quantum block encoding provides a way to embed classical data into Hilbert space, offering a pathway for quantum models, such as Quantum Transformers (QT), that replace classical self-attention with quantum circuit simulations to operate more efficiently. Current QTs rely on deep parameterized quantum circuits (PQCs), rendering them vulnerable to QPU noise, and thus hindering their practical performance. In this paper, we propose the Vectorized Quantum Transformer (VQT), a model that supports ideal masked attention matrix computation through quantum approximation simulation and efficient training via vectorized nonlinear quantum encoder, yielding shot-efficient and gradient-free quantum circuit simulation (QCS) and reduced classical sampling overhead. In addition, we demonstrate an accuracy comparison for IBM and IonQ in quantum circuit simulation and competitive results in benchmarking natural language processing tasks on IBM state-of-the-art and high-fidelity Kingston QPU. Our noise intermediate-scale quantum friendly VQT approach unlocks a novel architecture for end-to-end machine learning in quantum computing.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰çš„ Quantum Transformer (QT) ä¾èµ–æ·±å±‚å‚æ•°åŒ–é‡å­ç”µè·¯ (PQCs) å¯¼è‡´å…¶æ˜“å— QPU å™ªå£°å½±å“ä¸”å®é™…æ€§èƒ½å—é™çš„é—®é¢˜ï¼Œæå‡ºäº† Vectorized Quantum Transformer (VQT) æ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ©ç”¨å‘é‡åŒ–é‡å­å—ç¼–ç å°†ç»å…¸æ•°æ®åµŒå…¥å¸Œå°”ä¼¯ç‰¹ç©ºé—´ï¼Œé€šè¿‡é‡å­è¿‘ä¼¼æ¨¡æ‹Ÿæ”¯æŒç†æƒ³çš„æ©ç æ³¨æ„åŠ›çŸ©é˜µè®¡ç®—ï¼Œå¹¶ç»“åˆå‘é‡åŒ–éçº¿æ€§é‡å­ç¼–ç å™¨å®ç°é«˜æ•ˆè®­ç»ƒã€‚VQT å®ç°äº†å…·æœ‰å°„å‡»æ•ˆç‡ (shot-efficient) ä¸”æ— éœ€æ¢¯åº¦çš„é‡å­ç”µè·¯æ¨¡æ‹Ÿ (QCS)ï¼Œæ˜¾è‘—é™ä½äº†ç»å…¸é‡‡æ ·å¼€é”€ã€‚åœ¨ IBM é«˜ä¿çœŸ Kingston QPU å’Œ IonQ ç¡¬ä»¶ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚è¿™ç§é€‚ç”¨äºå«å™ªä¸­ç­‰è§„æ¨¡é‡å­ (NISQ) ç¯å¢ƒçš„æ–¹æ¡ˆä¸ºé‡å­è®¡ç®—ä¸­çš„ç«¯åˆ°ç«¯æœºå™¨å­¦ä¹ æä¾›äº†ä¸€ç§æ–°é¢–çš„æ¶æ„ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18464v2",
      "published_date": "2025-08-25 20:33:14 UTC",
      "updated_date": "2025-09-03 22:25:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:53:53.395909+00:00"
    },
    {
      "arxiv_id": "2508.18462v1",
      "title": "VERIRL: Boosting the LLM-based Verilog Code Generation via Reinforcement Learning",
      "title_zh": "VERIRLï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æå‡åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ Verilog ä»£ç ç”Ÿæˆ",
      "authors": [
        "Fu Teng",
        "Miao Pan",
        "Xuhong Zhang",
        "Zhezhi He",
        "Yiyao Yang",
        "Xinyi Chai",
        "Mengnan Qi",
        "Liqiang Lu",
        "Jianwei Yin"
      ],
      "abstract": "Recent advancements in code generation have shown remarkable success across software domains, yet hardware description languages (HDLs) such as Verilog remain underexplored due to their concurrency semantics, syntactic rigidity, and simulation complexity. In this work, we address these challenges by introducing a reinforcement learning (RL) framework tailored for Verilog code generation. We first construct Veribench-53K, a high-quality dataset curated from over 700K Verilog problems, enriched with structured prompts, complexity labels, and diverse testbenches. To tackle the problem of sparse and noisy reward signals, we propose a Trace-back based Rescore mechanism that leverages reasoning paths and iterative refinement to enhance feedback reliability and support reward model training. Furthermore, to mitigate catastrophic forgetting and overfitting during RL fine-tuning, we introduce a sample-balanced weighting strategy that adaptively balances learning dynamics based on reward-probability distributions. These innovations are integrated into an iterative RL pipeline that co-evolves the policy and reward models. In contrast to recent work such as CraftRTL, which relies on large-scale closed-source model distillation, and DeepSeek-style approaches that struggle with sparse feedback, our method demonstrates superior performance using a smaller but high-quality dataset combined with RL optimization. Experiments on Verilog generation tasks demonstrate state-of-the-art performance, with substantial gains in test pass rate, functional correctness, and compilation robustness. Our findings highlight the potential of RL-driven approaches for structured code generation in hardware-centric domains. VERIRL is publicly available at https://github.com/omniAI-Lab/VeriRL.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VERIRLï¼Œä¸€ä¸ªä¸“é—¨é’ˆå¯¹Verilogä»£ç ç”Ÿæˆçš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¡†æ¶ï¼Œæ—¨åœ¨å…‹æœç¡¬ä»¶æè¿°è¯­è¨€åœ¨å¹¶å‘è¯­ä¹‰å’Œä»¿çœŸå¤æ‚æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆæ„å»ºäº†é«˜è´¨é‡æ•°æ®é›†Veribench-53Kï¼Œå¹¶å¼•å…¥äº†åŸºäºå›æº¯(Trace-back based Rescore)çš„è¯„åˆ†æœºåˆ¶ï¼Œé€šè¿‡æ¨ç†è·¯å¾„å’Œè¿­ä»£ä¼˜åŒ–æ˜¾è‘—æå‡äº†ç¨€ç–å¥–åŠ±ä¿¡å·çš„å¯é æ€§ã€‚ä¸ºç¼“è§£å¼ºåŒ–å­¦ä¹ å¾®è°ƒä¸­çš„ç¾éš¾æ€§é—å¿˜ï¼ŒVERIRLé‡‡ç”¨äº†æ ·æœ¬å¹³è¡¡åŠ æƒç­–ç•¥(Sample-balanced Weighting Strategy)æ¥ä¼˜åŒ–å­¦ä¹ åŠ¨æ€ã€‚å®éªŒè¯æ˜ï¼Œç›¸æ¯”äºä¾èµ–å¤§æ¨¡å‹è’¸é¦æˆ–é¢ä¸´ç¨€ç–åé¦ˆé—®é¢˜çš„ç°æœ‰æ–¹æ³•ï¼ŒVERIRLåœ¨æµ‹è¯•é€šè¿‡ç‡ã€åŠŸèƒ½æ­£ç¡®æ€§å’Œç¼–è¯‘é²æ£’æ€§ä¸Šå‡è¾¾åˆ°äº†State-of-the-artæ°´å¹³ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…éªŒè¯äº†å¼ºåŒ–å­¦ä¹ åœ¨ç¡¬ä»¶ä»£ç ç”Ÿæˆé¢†åŸŸçš„æœ‰æ•ˆæ€§ï¼Œè¿˜é€šè¿‡å…¬å¼€ä»£ç å’Œæ•°æ®é›†ä¸ºåç»­ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18462v1",
      "published_date": "2025-08-25 20:20:44 UTC",
      "updated_date": "2025-08-25 20:20:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:02.289677+00:00"
    },
    {
      "arxiv_id": "2508.18444v1",
      "title": "How Reliable are LLMs for Reasoning on the Re-ranking task?",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹åœ¨é‡æ’åºä»»åŠ¡ä¸­çš„æ¨ç†å¯é æ€§ç ”ç©¶",
      "authors": [
        "Nafis Tanveer Islam",
        "Zhiming Zhao"
      ],
      "abstract": "With the improving semantic understanding capability of Large Language Models (LLMs), they exhibit a greater awareness and alignment with human values, but this comes at the cost of transparency. Although promising results are achieved via experimental analysis, an in-depth understanding of the LLM's internal workings is unavoidable to comprehend the reasoning behind the re-ranking, which provides end users with an explanation that enables them to make an informed decision. Moreover, in newly developed systems with limited user engagement and insufficient ranking data, accurately re-ranking content remains a significant challenge. While various training methods affect the training of LLMs and generate inference, our analysis has found that some training methods exhibit better explainability than others, implying that an accurate semantic understanding has not been learned through all training methods; instead, abstract knowledge has been gained to optimize evaluation, which raises questions about the true reliability of LLMs. Therefore, in this work, we analyze how different training methods affect the semantic understanding of the re-ranking task in LLMs and investigate whether these models can generate more informed textual reasoning to overcome the challenges of transparency or LLMs and limited training data. To analyze the LLMs for re-ranking tasks, we utilize a relatively small ranking dataset from the environment and the Earth science domain to re-rank retrieved content. Furthermore, we also analyze the explainable information to see if the re-ranking can be reasoned using explainability.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨é‡æ’åº(Re-ranking)ä»»åŠ¡ä¸­è¿›è¡Œæ¨ç†çš„å¯é æ€§ä¸é€æ˜åº¦(transparency)é—®é¢˜ã€‚è™½ç„¶LLMsåœ¨è¯­ä¹‰ç†è§£ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å†…éƒ¨è¿ä½œæœºåˆ¶å¾€å¾€ç¼ºä¹é€æ˜åº¦ï¼Œå¯¼è‡´ç”¨æˆ·éš¾ä»¥ç†è§£é‡æ’åºèƒŒåçš„é€»è¾‘å¹¶åšå‡ºæ˜æ™ºå†³ç­–ã€‚ä½œè€…é€šè¿‡åˆ†æä¸åŒçš„è®­ç»ƒæ–¹æ³•ï¼Œç ”ç©¶äº†å®ƒä»¬å¯¹LLMsè¯­ä¹‰ç†è§£åŠç”Ÿæˆè§£é‡Šæ€§æ¨ç†çš„å½±å“ï¼Œæ—¨åœ¨è§£å†³æ–°å¼€å‘ç³»ç»Ÿä¸­è®­ç»ƒæ•°æ®æœ‰é™çš„æŒ‘æˆ˜ã€‚å®éªŒåˆ©ç”¨ç¯å¢ƒä¸åœ°çƒç§‘å­¦é¢†åŸŸçš„ç‰¹å®šæ•°æ®é›†è¿›è¡Œæµ‹è¯•ï¼Œå¹¶å¯¹æ¨¡å‹ç”Ÿæˆçš„å¯è§£é‡Šæ€§(explainability)ä¿¡æ¯è¿›è¡Œäº†æ·±å…¥è¯„ä¼°ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œå¹¶éæ‰€æœ‰è®­ç»ƒæ–¹æ³•éƒ½èƒ½ä¿ƒè¿›çœŸæ­£çš„è¯­ä¹‰å­¦ä¹ ï¼Œéƒ¨åˆ†æ¨¡å‹å¯èƒ½ä»…é€šè¿‡è·å–æŠ½è±¡çŸ¥è¯†æ¥ä¼˜åŒ–è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™å¼•å‘äº†å¯¹LLMsåœ¨é‡æ’åºä»»åŠ¡ä¸­çœŸå®å¯é æ€§çš„è´¨ç–‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at FQAS Conference 2024. DOI will be provided in 3 weeks after the conference has published the paper",
      "pdf_url": "https://arxiv.org/pdf/2508.18444v1",
      "published_date": "2025-08-25 19:48:39 UTC",
      "updated_date": "2025-08-25 19:48:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:36.146289+00:00"
    },
    {
      "arxiv_id": "2509.22658v1",
      "title": "How good are LLMs at Retrieving Documents in a Specific Domain?",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„æ–‡æ¡£æ£€ç´¢èƒ½åŠ›è¯„ä¼°",
      "authors": [
        "Nafis Tanveer Islam",
        "Zhiming Zhao"
      ],
      "abstract": "Classical search engines using indexing methods in data infrastructures primarily allow keyword-based queries to retrieve content. While these indexing-based methods are highly scalable and efficient, due to a lack of an appropriate evaluation dataset and a limited understanding of semantics, they often fail to capture the user's intent and generate incomplete responses during evaluation. This problem also extends to domain-specific search systems that utilize a Knowledge Base (KB) to access data from various research infrastructures. Research infrastructures (RIs) from the environmental and earth science domain, which encompass the study of ecosystems, biodiversity, oceanography, and climate change, generate, share, and reuse large volumes of data. While there are attempts to provide a centralized search service using Elasticsearch as a knowledge base, they also face similar challenges in understanding queries with multiple intents. To address these challenges, we proposed an automated method to curate a domain-specific evaluation dataset to analyze the capability of a search system. Furthermore, we incorporate the Retrieval of Augmented Generation (RAG), powered by Large Language Models (LLMs), for high-quality retrieval of environmental domain data using natural language queries. Our quantitative and qualitative analysis of the evaluation dataset shows that LLM-based systems for information retrieval return results with higher precision when understanding queries with multiple intents, compared to Elasticsearch-based systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç¯å¢ƒä¸åœ°çƒç§‘å­¦ç­‰ç‰¹å®šé¢†åŸŸæ–‡æ¡£æ£€ç´¢ä¸­çš„è¡¨ç°ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿç´¢å¼•æœç´¢å¼•æ“åœ¨è¯­ä¹‰ç†è§£å’Œå¤„ç†å¤šæ„å›¾æŸ¥è¯¢æ–¹é¢çš„å±€é™æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–æ–¹æ³•æ¥æ„å»ºé¢†åŸŸç‰¹å®šçš„è¯„ä¼°æ•°æ®é›†ï¼Œç”¨äºåˆ†ææœç´¢ç³»ç»Ÿçš„æ€§èƒ½ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶å¼•å…¥äº†ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ï¼Œæ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢å®ç°é«˜è´¨é‡çš„ç¯å¢ƒé¢†åŸŸæ•°æ®æ£€ç´¢ã€‚é€šè¿‡å¯¹è¯„ä¼°æ•°æ®é›†çš„å®šé‡å’Œå®šæ€§åˆ†æï¼Œç»“æœè¡¨æ˜åŸºäº LLM çš„ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿåœ¨ç†è§£å¤æ‚æŸ¥è¯¢æ„å›¾æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„ Elasticsearch ç³»ç»Ÿï¼Œå±•ç°å‡ºæ›´é«˜çš„æ£€ç´¢ç²¾ç¡®åº¦ã€‚è¯¥ç ”ç©¶ä¸ºç§‘ç ”åŸºç¡€è®¾æ–½ä¸­çš„çŸ¥è¯†åº“(KB)æ„å»ºæä¾›äº†æ›´æœ‰æ•ˆçš„æ£€ç´¢æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at FAIEMA Conference 2025. DOI will be provided once the conference publishes the paper",
      "pdf_url": "https://arxiv.org/pdf/2509.22658v1",
      "published_date": "2025-08-25 19:47:21 UTC",
      "updated_date": "2025-08-25 19:47:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:25.152343+00:00"
    },
    {
      "arxiv_id": "2508.18440v1",
      "title": "SwiftF0: Fast and Accurate Monophonic Pitch Detection",
      "title_zh": "SwiftF0ï¼šå¿«é€Ÿç²¾å‡†çš„å•éŸ³éŸ³é«˜æ£€æµ‹",
      "authors": [
        "Lars Nieradzik"
      ],
      "abstract": "Accurate and real-time monophonic pitch estimation in noisy conditions, particularly on resource-constrained devices, remains an open challenge in audio processing. We present \\emph{SwiftF0}, a novel, lightweight neural model that sets a new state-of-the-art for monophonic pitch estimation. Through training on diverse speech, music, and synthetic datasets with extensive data augmentation, SwiftF0 achieves robust generalization across acoustic domains while maintaining computational efficiency. SwiftF0 achieves a 91.80\\% harmonic mean (HM) at 10 dB SNR, outperforming baselines like CREPE by over 12 percentage points and degrading by only 2.3 points from clean audio. SwiftF0 requires only 95,842 parameters and runs approximately 42x faster than CREPE on CPU, making it ideal for efficient, real-time deployment. To address the critical lack of perfectly accurate ground truth pitch in speech corpora (which typically rely on algorithmic estimators or laryngograph signals), we introduce \\emph{SpeechSynth}. This synthetic speech dataset, generated by a phoneme-level TTS model, provides exact, on-demand ground-truth pitch curves, enabling more robust model training and evaluation. Furthermore, we propose a unified metric, combining six complementary performance measures for comprehensive and reliable pitch evaluation, and release an open-source pitch benchmark suite. A live demo of SwiftF0 is available at https://swift-f0.github.io/, the source code at https://github.com/lars76/swift-f0, and the benchmark framework at https://github.com/lars76/pitch-benchmark.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SwiftF0ï¼Œä¸€ç§æ–°å‹è½»é‡åŒ–ç¥ç»æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å™ªå£°ç¯å¢ƒä¸‹åŠèµ„æºå—é™è®¾å¤‡ä¸Šçš„å•éŸ³éŸ³é«˜ä¼°è®¡(monophonic pitch estimation)éš¾é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡åœ¨å¤šæ ·åŒ–çš„è¯­éŸ³ã€éŸ³ä¹å’Œåˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›çš„æ•°æ®å¢å¼º(data augmentation)è®­ç»ƒï¼Œå®ç°äº†è·¨å£°å­¦é¢†åŸŸçš„ç¨³å¥æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSwiftF0åœ¨10 dBä¿¡å™ªæ¯”(SNR)ä¸‹è¾¾åˆ°äº†91.80%çš„è°ƒå’Œå¹³å‡å€¼(harmonic mean)ï¼Œåœ¨æ€§èƒ½ä¸Šè¶…è¿‡CREPEç­‰åŸºçº¿æ¨¡å‹12ä¸ªç™¾åˆ†ç‚¹ä»¥ä¸Šã€‚SwiftF0ä»…åŒ…å«95,842ä¸ªå‚æ•°ï¼Œåœ¨CPUä¸Šçš„è¿è¡Œé€Ÿåº¦æ¯”CREPEå¿«çº¦42å€ï¼Œéå¸¸é€‚åˆé«˜æ•ˆçš„å®æ—¶éƒ¨ç½²åº”ç”¨ã€‚ä¸ºè§£å†³è¯­éŸ³è¯­æ–™åº“ä¸­ç¼ºä¹ç²¾ç¡®åŸºå‡†éŸ³é«˜çš„é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†é€šè¿‡éŸ³ç´ çº§TTSç”Ÿæˆçš„SpeechSynthåˆæˆæ•°æ®é›†ï¼Œæä¾›ç²¾ç¡®çš„åŸºå‡†éŸ³é«˜æ›²çº¿ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€å¥—ç»“åˆäº†å…­é¡¹æ€§èƒ½æŒ‡æ ‡çš„ç»Ÿä¸€è¯„ä»·æ ‡å‡†ï¼Œå¹¶å‘å¸ƒäº†å¼€æºéŸ³é«˜åŸºå‡†æµ‹è¯•å¥—ä»¶ï¼Œä¸ºè¯¥é¢†åŸŸçš„æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°æä¾›äº†æ›´å…¨é¢çš„æ¡†æ¶ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18440v1",
      "published_date": "2025-08-25 19:39:20 UTC",
      "updated_date": "2025-08-25 19:39:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:25.375302+00:00"
    },
    {
      "arxiv_id": "2508.18439v2",
      "title": "A Systematic Approach to Predict the Impact of Cybersecurity Vulnerabilities Using LLMs",
      "title_zh": "ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç½‘ç»œå®‰å…¨æ¼æ´å½±å“é¢„æµ‹ç³»ç»ŸåŒ–æ–¹æ³•",
      "authors": [
        "Anders MÃ¸lmen HÃ¸st",
        "Pierre Lison",
        "Leon Moonen"
      ],
      "abstract": "Vulnerability databases, such as the National Vulnerability Database (NVD), offer detailed descriptions of Common Vulnerabilities and Exposures (CVEs), but often lack information on their real-world impact, such as the tactics, techniques, and procedures (TTPs) that adversaries may use to exploit the vulnerability. However, manually linking CVEs to their corresponding TTPs is a challenging and time-consuming task, and the high volume of new vulnerabilities published annually makes automated support desirable.\n  This paper introduces TRIAGE, a two-pronged automated approach that uses Large Language Models (LLMs) to map CVEs to relevant techniques from the ATT&CK knowledge base. We first prompt an LLM with instructions based on MITRE's CVE Mapping Methodology to predict an initial list of techniques. This list is then combined with the results from a second LLM-based module that uses in-context learning to map a CVE to relevant techniques. This hybrid approach strategically combines rule-based reasoning with data-driven inference. Our evaluation reveals that in-context learning outperforms the individual mapping methods, and the hybrid approach improves recall of exploitation techniques. We also find that GPT-4o-mini performs better than Llama3.3-70B on this task. Overall, our results show that LLMs can be used to automatically predict the impact of cybersecurity vulnerabilities and TRIAGE makes the process of mapping CVEs to ATT&CK more efficient. A replication package is available for download from https://doi.org/10.5281/zenodo.17341503.\n  Keywords: vulnerability impact, CVE, ATT&CK techniques, large language models, automated mapping.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TRIAGEï¼Œä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å°†é€šç”¨æ¼æ´æŠ«éœ²(CVE)è‡ªåŠ¨æ˜ å°„åˆ°ATT&CKçŸ¥è¯†åº“ç›¸å…³æŠ€æœ¯çš„åŒé‡è‡ªåŠ¨åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ¼æ´åº“ä¸­ç¼ºä¹æ”»å‡»è€…æˆ˜æœ¯ã€æŠ€æœ¯å’Œç¨‹åº(TTPs)ç­‰å®é™…å½±å“ä¿¡æ¯çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ä¸¤å¤§æ¨¡å—ï¼šç¬¬ä¸€ä¸ªæ¨¡å—æ ¹æ®MITREçš„CVE Mapping Methodologyæä¾›æŒ‡ä»¤æç¤ºï¼Œè€Œç¬¬äºŒä¸ªæ¨¡å—åˆ™åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ (In-context learning)è¿›è¡Œæ˜ å°„ï¼Œä»è€Œå®ç°äº†åŸºäºè§„åˆ™çš„æ¨ç†ä¸æ•°æ®é©±åŠ¨æ¨ç†çš„æˆ˜ç•¥ç»“åˆã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ çš„æ•ˆæœä¼˜äºå•ä¸€æ˜ å°„æ–¹æ³•ï¼Œè€Œæ··åˆæ–¹æ³•æ˜¾è‘—æå‡äº†æ¼æ´åˆ©ç”¨æŠ€æœ¯çš„æŸ¥å…¨ç‡(Recall)ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°GPT-4o-miniåœ¨è¯¥ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºLlama3.3-70Bã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†LLMsåœ¨è‡ªåŠ¨é¢„æµ‹ç½‘ç»œå®‰å…¨æ¼æ´å½±å“æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼ŒTRIAGEæ˜¾è‘—æé«˜äº†CVEåˆ°ATT&CKæ˜ å°„è¿‡ç¨‹çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for publication in the 24th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.18439v2",
      "published_date": "2025-08-25 19:39:15 UTC",
      "updated_date": "2025-10-19 09:23:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:25.753432+00:00"
    },
    {
      "arxiv_id": "2508.18430v1",
      "title": "CLARIFY: A Specialist-Generalist Framework for Accurate and Lightweight Dermatological Visual Question Answering",
      "title_zh": "CLARIFYï¼šä¸€ç§ç”¨äºç²¾å‡†ä¸”è½»é‡åŒ–çš®è‚¤ç§‘è§†è§‰é—®ç­”çš„ä¸“å®¶-é€šç”¨æ¡†æ¶",
      "authors": [
        "Aranya Saha",
        "Tanvir Ahmed Khan",
        "Ismam Nur Swapnil",
        "Mohammad Ariful Haque"
      ],
      "abstract": "Vision-language models (VLMs) have shown significant potential for medical tasks; however, their general-purpose nature can limit specialized diagnostic accuracy, and their large size poses substantial inference costs for real-world clinical deployment. To address these challenges, we introduce CLARIFY, a Specialist-Generalist framework for dermatological visual question answering (VQA). CLARIFY combines two components: (i) a lightweight, domain-trained image classifier (the Specialist) that provides fast and highly accurate diagnostic predictions, and (ii) a powerful yet compressed conversational VLM (the Generalist) that generates natural language explanations to user queries. In our framework, the Specialist's predictions directly guide the Generalist's reasoning, focusing it on the correct diagnostic path. This synergy is further enhanced by a knowledge graph-based retrieval module, which grounds the Generalist's responses in factual dermatological knowledge, ensuring both accuracy and reliability. This hierarchical design not only reduces diagnostic errors but also significantly improves computational efficiency. Experiments on our curated multimodal dermatology dataset demonstrate that CLARIFY achieves an 18\\% improvement in diagnostic accuracy over the strongest baseline, a fine-tuned, uncompressed single-line VLM, while reducing the average VRAM requirement and latency by at least 20\\% and 5\\%, respectively. These results indicate that a Specialist-Generalist system provides a practical and powerful paradigm for building lightweight, trustworthy, and clinically viable AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CLARIFYï¼Œä¸€ä¸ªé’ˆå¯¹çš®è‚¤ç—…è§†è§‰é—®ç­”ï¼ˆDermatological Visual Question Answering, VQAï¼‰çš„ä¸“å®¶-é€šç”¨ï¼ˆSpecialist-Generalistï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVision-language models, VLMsï¼‰åœ¨ä¸“ä¸šè¯Šæ–­å‡†ç¡®æ€§ä¸æ¨ç†æˆæœ¬æ–¹é¢çš„å±€é™ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ä¸€ä¸ªè½»é‡çº§çš„é¢†åŸŸè®­ç»ƒå›¾åƒåˆ†ç±»å™¨ï¼ˆSpecialistï¼‰ç”¨äºå¿«é€Ÿç²¾å‡†è¯Šæ–­ï¼Œä»¥åŠä¸€ä¸ªç»è¿‡å‹ç¼©çš„å¯¹è¯å‹VLMï¼ˆGeneralistï¼‰è´Ÿè´£ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šã€‚é€šè¿‡å°†Specialistçš„é¢„æµ‹ç›´æ¥å¼•å¯¼Generalistçš„æ¨ç†è·¯å¾„ï¼Œå¹¶è¾…ä»¥åŸºäºçŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graphï¼‰çš„æ£€ç´¢æ¨¡å—ï¼Œè¯¥ç³»ç»Ÿç¡®ä¿äº†å›å¤çš„äº‹å®å‡†ç¡®æ€§ä¸å¯é æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCLARIFYåœ¨çš®è‚¤ç—…å¤šæ¨¡æ€æ•°æ®é›†ä¸Šçš„è¯Šæ–­å‡†ç¡®ç‡æ¯”å¾®è°ƒåçš„å•ä½“VLMæå‡äº†18%ï¼ŒåŒæ—¶å°†æ˜¾å­˜ï¼ˆVRAMï¼‰éœ€æ±‚å’Œæ¨ç†å»¶è¿Ÿåˆ†åˆ«é™ä½äº†è‡³å°‘20%å’Œ5%ã€‚è¿™ä¸€åˆ†å±‚è®¾è®¡ä¸ºæ„å»ºè½»é‡åŒ–ã€å¯ä¿¡ä¸”å…·æœ‰ä¸´åºŠå®ç”¨æ€§çš„åŒ»ç–—AIç³»ç»Ÿæä¾›äº†ä¸€ç§é«˜æ•ˆçš„èŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 8 figures, Prepared for submission to IEEE Transactions on Human-Machine Systems",
      "pdf_url": "https://arxiv.org/pdf/2508.18430v1",
      "published_date": "2025-08-25 19:22:16 UTC",
      "updated_date": "2025-08-25 19:22:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:55:30.194791+00:00"
    },
    {
      "arxiv_id": "2508.18408v2",
      "title": "Low-Rank Tensor Decompositions for the Theory of Neural Networks",
      "title_zh": "ç¥ç»ç½‘ç»œç†è®ºä¸­çš„ä½ç§©å¼ é‡åˆ†è§£",
      "authors": [
        "Ricardo Borsoi",
        "Konstantin Usevich",
        "Marianne Clausel"
      ],
      "abstract": "The groundbreaking performance of deep neural networks (NNs) promoted a surge of interest in providing a mathematical basis to deep learning theory. Low-rank tensor decompositions are specially befitting for this task due to their close connection to NNs and their rich theoretical results. Different tensor decompositions have strong uniqueness guarantees, which allow for a direct interpretation of their factors, and polynomial time algorithms have been proposed to compute them. Through the connections between tensors and NNs, such results supported many important advances in the theory of NNs. In this review, we show how low-rank tensor methods--which have been a core tool in the signal processing and machine learning communities--play a fundamental role in theoretically explaining different aspects of the performance of deep NNs, including their expressivity, algorithmic learnability and computational hardness, generalization, and identifiability. Our goal is to give an accessible overview of existing approaches (developed by different communities, ranging from computer science to mathematics) in a coherent and unified way, and to open a broader perspective on the use of low-rank tensor decompositions for the theory of deep NNs.",
      "tldr_zh": "è¯¥ç»¼è¿°æ¢è®¨äº†ä½ç§©å¼ é‡åˆ†è§£ (Low-rank tensor decompositions) åœ¨æ·±åº¦ç¥ç»ç½‘ç»œ (NNs) ç†è®ºåŸºç¡€ç ”ç©¶ä¸­çš„æ ¸å¿ƒä½œç”¨ã€‚ç”±äºå¼ é‡ä¸ç¥ç»ç½‘ç»œä¹‹é—´å­˜åœ¨ç´§å¯†è”ç³»ï¼Œç ”ç©¶æŒ‡å‡ºå¼ é‡åˆ†è§£åœ¨è§£é‡Šæ·±åº¦å­¦ä¹ çš„æ•°å­¦è¡¨ç°æ–¹é¢å…·æœ‰å¾—å¤©ç‹¬åšçš„ä¼˜åŠ¿ã€‚è®ºæ–‡ç³»ç»Ÿåœ°å›é¡¾äº†ä½ç§©å¼ é‡æ–¹æ³•å¦‚ä½•ä¸ºç¥ç»ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ› (expressivity)ã€ç®—æ³•å¯å­¦ä¹ æ€§ä¸è®¡ç®—å¤æ‚åº¦ (algorithmic learnability and computational hardness)ã€æ³›åŒ–èƒ½åŠ› (generalization) ä»¥åŠå¯è¾¨è¯†æ€§ (identifiability) æä¾›ç†è®ºæ”¯æ’‘ã€‚é€šè¿‡åˆ©ç”¨å¼ é‡åˆ†è§£çš„å”¯ä¸€æ€§ä¿è¯å’Œå¤šé¡¹å¼æ—¶é—´ç®—æ³•ï¼Œè¿™äº›æ–¹æ³•èƒ½å¤Ÿç›´æ¥è§£é‡Šæ¨¡å‹å› å­å¹¶æå‡ç¥ç»ç½‘ç»œçš„ç†è®ºé€æ˜åº¦ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡æ•´åˆæ¥è‡ªè®¡ç®—æœºç§‘å­¦å’Œæ•°å­¦ç­‰ä¸åŒé¢†åŸŸçš„ç ”ç©¶æˆæœï¼Œä¸ºç°æœ‰çš„æ·±åº¦å­¦ä¹ ç†è®ºç ”ç©¶æä¾›äº†ä¸€ä¸ªç»Ÿä¸€ä¸”è¿è´¯çš„è§†è§’ã€‚è¯¥æ–‡æ—¨åœ¨ä¸ºç ”ç©¶è€…æä¾›å…³äºä½ç§©å¼ é‡åˆ†è§£åœ¨æ·±åº¦å­¦ä¹ ç†è®ºåº”ç”¨æ–¹é¢çš„å…¨é¢æ¦‚è¿°ï¼Œå¹¶æ‹“å®½äº†è¯¥é¢†åŸŸæœªæ¥çš„ç ”ç©¶è§†é‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18408v2",
      "published_date": "2025-08-25 18:50:45 UTC",
      "updated_date": "2025-12-16 22:14:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:41.091821+00:00"
    },
    {
      "arxiv_id": "2508.18407v1",
      "title": "Can Out-of-Distribution Evaluations Uncover Reliance on Shortcuts? A Case Study in Question Answering",
      "title_zh": "åˆ†å¸ƒå¤–è¯„ä¼°èƒ½å¦æ­ç¤ºæ¨¡å‹å¯¹â€œæ·å¾„â€çš„ä¾èµ–ï¼Ÿä¸€é¡¹é’ˆå¯¹é—®ç­”ä»»åŠ¡çš„æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Michal Å tefÃ¡nik",
        "Timothee Mickus",
        "Marek KadlÄÃ­k",
        "Michal Spiegel",
        "Josef KuchaÅ™"
      ],
      "abstract": "A majority of recent work in AI assesses models' generalization capabilities through the lens of performance on out-of-distribution (OOD) datasets. Despite their practicality, such evaluations build upon a strong assumption: that OOD evaluations can capture and reflect upon possible failures in a real-world deployment.\n  In this work, we challenge this assumption and confront the results obtained from OOD evaluations with a set of specific failure modes documented in existing question-answering (QA) models, referred to as a reliance on spurious features or prediction shortcuts.\n  We find that different datasets used for OOD evaluations in QA provide an estimate of models' robustness to shortcuts that have a vastly different quality, some largely under-performing even a simple, in-distribution evaluation. We partially attribute this to the observation that spurious shortcuts are shared across ID+OOD datasets, but also find cases where a dataset's quality for training and evaluation is largely disconnected. Our work underlines limitations of commonly-used OOD-based evaluations of generalization, and provides methodology and recommendations for evaluating generalization within and beyond QA more robustly.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ†å¸ƒå¤–(Out-of-Distribution, OOD)è¯„ä¼°æ˜¯å¦èƒ½å¤Ÿæ­ç¤ºæ¨¡å‹å¯¹é¢„æµ‹æ·å¾„(prediction shortcuts)çš„ä¾èµ–ï¼Œå¹¶ä»¥é—®ç­”ç³»ç»Ÿ(Question Answering, QA)ä½œä¸ºæ¡ˆä¾‹ç ”ç©¶ã€‚ç ”ç©¶è€…æŒ‘æˆ˜äº†OODè¯„ä¼°èƒ½å¤Ÿåæ˜ ç°å®éƒ¨ç½²å¤±æ•ˆæ¨¡å¼çš„å¸¸è§„å‡è®¾ï¼Œé€šè¿‡å¯¹æ¯”å®éªŒå‘ç°ä¸åŒOODæ•°æ®é›†åœ¨è¡¡é‡æ¨¡å‹å¯¹ä¼ªç‰¹å¾(spurious features)ç¨³å¥æ€§æ–¹é¢çš„è´¨é‡å·®å¼‚æ˜¾è‘—ï¼Œéƒ¨åˆ†æ•°æ®é›†çš„è¡¨ç°ç”šè‡³ä¸å¦‚åˆ†å¸ƒå†…(in-distribution)è¯„ä¼°ã€‚åˆ†æè¡¨æ˜ï¼Œè¿™ç§å±€é™æ€§æºäºä¼ªæ·å¾„åœ¨IDå’ŒOODæ•°æ®é›†ä¹‹é—´çš„å…±äº«ï¼Œä»¥åŠæ•°æ®é›†ä½œä¸ºè®­ç»ƒé›†ä¸è¯„ä¼°é›†æ—¶çš„æ•ˆç”¨è„±èŠ‚ã€‚è¯¥å·¥ä½œæŒ‡å‡ºäº†å½“å‰é€šç”¨OODæ³›åŒ–è¯„ä¼°çš„å±€é™ï¼Œå¹¶ä¸ºæ›´ç¨³å¥åœ°è¡¡é‡QAåŠå…¶ä»–é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›æä¾›äº†æ–¹æ³•è®ºå»ºè®®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Findings of EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.18407v1",
      "published_date": "2025-08-25 18:49:50 UTC",
      "updated_date": "2025-08-25 18:49:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:47.792058+00:00"
    },
    {
      "arxiv_id": "2508.18406v1",
      "title": "Toward Generalized Autonomous Agents: A Neuro-Symbolic AI Framework for Integrating Social and Technical Support in Education",
      "title_zh": "è¿ˆå‘é€šç”¨è‡ªä¸»æ™ºèƒ½ä½“ï¼šä¸€ç§æ•´åˆæ•™è‚²ç¤¾äº¤ä¸æŠ€æœ¯æ”¯æŒçš„ç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½æ¡†æ¶",
      "authors": [
        "Ryan Hare",
        "Ying Tang"
      ],
      "abstract": "One of the enduring challenges in education is how to empower students to take ownership of their learning by setting meaningful goals, tracking their progress, and adapting their strategies when faced with setbacks. Research has shown that this form of leaner-centered learning is best cultivated through structured, supportive environments that promote guided practice, scaffolded inquiry, and collaborative dialogue. In response, educational efforts have increasingly embraced artificial-intelligence (AI)-powered digital learning environments, ranging from educational apps and virtual labs to serious games. Recent advances in large language models (LLMs) and neuro-symbolic systems, meanwhile, offer a transformative opportunity to reimagine how support is delivered in digital learning environments. LLMs are enabling socially interactive learning experiences and scalable, cross-domain learning support that can adapt instructional strategies across varied subjects and contexts. In parallel, neuro-symbolic AI provides new avenues for designing these agents that are not only adaptive but also scalable across domains. Based on these remarks, this paper presents a multi-agent, neuro-symbolic framework designed to resolve the aforementioned challenges. The framework assigns distinct pedagogical roles to specialized agents: an RL-based 'tutor' agent provides authoritative, non-verbal scaffolding, while a proactive, LLM-powered 'peer' agent facilitates the social dimensions of learning. While prior work has explored such agents in isolation, our framework's novelty lies in unifying them through a central educational ontology. Through case studies in both college-level and middle school settings, we demonstrate the framework's adaptability across domains. We conclude by outlining key insights and future directions for advancing AI-driven learning environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•™è‚²é¢†åŸŸä¸­å¢å¼ºå­¦ç”Ÿè‡ªä¸»å­¦ä¹ èƒ½åŠ›çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç¥ç»ç¬¦å· Neuro-Symbolic AI æ¡†æ¶ï¼Œæ—¨åœ¨å°†ç¤¾äº¤æ”¯æŒä¸æŠ€æœ¯æ”¯æŒæ•´åˆã€‚è¯¥æ¡†æ¶ä¸ºä¸åŒæ™ºèƒ½ä½“åˆ†é…äº†æ•™å­¦è§’è‰²ï¼ŒåŒ…æ‹¬ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹  RL çš„ 'tutor' æ™ºèƒ½ä½“æä¾›éè¯­è¨€æ”¯æ¶ scaffoldingï¼Œä»¥åŠä¸€ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹ LLM é©±åŠ¨çš„ 'peer' æ™ºèƒ½ä½“è´Ÿè´£ç¤¾äº¤äº’åŠ¨ã€‚ä¸ä»¥å¾€å­¤ç«‹ç ”ç©¶ä¸åŒï¼Œè¯¥æ¡†æ¶çš„åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡æ ¸å¿ƒæ•™è‚²æœ¬ä½“ educational ontology å°†ä¸åŒæ™ºèƒ½ä½“ç»Ÿä¸€ï¼Œè§£å†³äº†è·¨é¢†åŸŸçš„å¯æ‰©å±•æ€§é—®é¢˜ã€‚é€šè¿‡åœ¨å¤§å­¦å’Œä¸­å­¦ç¯å¢ƒä¸‹çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†æ¡†æ¶åœ¨ä¸åŒå­¦ç§‘å’Œæƒ…å¢ƒä¸‹çš„é«˜åº¦é€‚åº”æ€§ã€‚è¿™ä¸€æˆæœä¸ºæ„å»ºé€šç”¨å‹è‡ªä¸»æ•™å­¦æ™ºèƒ½ä½“æä¾›äº†æ–°æ¶æ„ï¼Œå¹¶æŒ‡æ˜äº†æœªæ¥ AI é©±åŠ¨å­¦ä¹ ç¯å¢ƒçš„å‘å±•æ–¹å‘ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "Preprint. This work has been submitted to the IEEE for possible publication. In review for IEEE's Systems, Man, and Cybernetics Magazine. 8 pages, 3 figures. arxiv abstract has been shortened as the magazine format uses a long-form abstract",
      "pdf_url": "https://arxiv.org/pdf/2508.18406v1",
      "published_date": "2025-08-25 18:46:59 UTC",
      "updated_date": "2025-08-25 18:46:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:56.150853+00:00"
    },
    {
      "arxiv_id": "2508.19300v1",
      "title": "CellINR: Implicitly Overcoming Photo-induced Artifacts in 4D Live Fluorescence Microscopy",
      "title_zh": "CellINRï¼šéšå¼å…‹æœå››ç»´æ´»ç»†èƒè§å…‰æ˜¾å¾®æˆåƒä¸­çš„å…‰è¯±å¯¼ä¼ªå½±",
      "authors": [
        "Cunmin Zhao",
        "Ziyuan Luo",
        "Guoye Guan",
        "Zelin Li",
        "Yiming Ma",
        "Zhongying Zhao",
        "Renjie Wan"
      ],
      "abstract": "4D live fluorescence microscopy is often compromised by prolonged high intensity illumination which induces photobleaching and phototoxic effects that generate photo-induced artifacts and severely impair image continuity and detail recovery. To address this challenge, we propose the CellINR framework, a case-specific optimization approach based on implicit neural representation. The method employs blind convolution and structure amplification strategies to map 3D spatial coordinates into the high frequency domain, enabling precise modeling and high-accuracy reconstruction of cellular structures while effectively distinguishing true signals from artifacts. Experimental results demonstrate that CellINR significantly outperforms existing techniques in artifact removal and restoration of structural continuity, and for the first time, a paired 4D live cell imaging dataset is provided for evaluating reconstruction performance, thereby offering a solid foundation for subsequent quantitative analyses and biological research. The code and dataset will be public.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CellINR æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ 4D æ´»ç»†èƒè§å…‰æ˜¾å¾®æˆåƒï¼ˆ4D live fluorescence microscopyï¼‰ä¸­å› é•¿æ—¶é«˜å¼ºåº¦ç…§å°„å¼•èµ·çš„å…‰æ¼‚ç™½ï¼ˆphotobleachingï¼‰å’Œå…‰æ¯’æ€§ï¼ˆphototoxicityï¼‰å¯¼è‡´çš„ä¼ªå½±é—®é¢˜ã€‚ä½œä¸ºä¸€ç§åŸºäºéšå¼ç¥ç»è¡¨ç¤ºï¼ˆimplicit neural representationï¼‰çš„ç‰¹å®šæ¡ˆä¾‹ä¼˜åŒ–æ–¹æ³•ï¼ŒCellINR ç»“åˆäº†ç›²å·ç§¯ï¼ˆblind convolutionï¼‰å’Œç»“æ„æ”¾å¤§ï¼ˆstructure amplificationï¼‰ç­–ç•¥ï¼Œé€šè¿‡å°†ç©ºé—´åæ ‡æ˜ å°„è‡³é«˜é¢‘åŸŸæ¥å®ç°å¯¹ç»†èƒç»“æ„çš„ç²¾ç¡®å»ºæ¨¡ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨é«˜ç²¾åº¦é‡å»ºå›¾åƒçš„åŒæ—¶ï¼Œæœ‰æ•ˆåŒºåˆ†çœŸå®ä¿¡å·ä¸ä¼ªå½±å¹¶æ¢å¤ç»“æ„çš„è¿ç»­æ€§ã€‚å®éªŒè¯æ˜ï¼ŒCellINR åœ¨å»é™¤å…‰è¯±å¯¼ä¼ªå½±æ–¹é¢çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜è´¡çŒ®äº†ä¸€ä¸ªç”¨äºæ€§èƒ½è¯„ä¼°çš„æˆå¯¹ 4D æ´»ç»†èƒæˆåƒæ•°æ®é›†ï¼Œä¸ºåç»­çš„å®šé‡ç”Ÿç‰©å­¦åˆ†ææä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "13 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.19300v1",
      "published_date": "2025-08-25 18:38:25 UTC",
      "updated_date": "2025-08-25 18:38:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:52.852259+00:00"
    },
    {
      "arxiv_id": "2508.18397v2",
      "title": "Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning",
      "title_zh": "æŒ–æ˜é•¿å°¾ï¼šè‡ªåŠ¨é©¾é©¶è¿åŠ¨è§„åˆ’ä¸­é²æ£’ç¦»çº¿å¼ºåŒ–å­¦ä¹ çš„ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å…³é”®æ€§æŒ‡æ ‡æ¯”è¾ƒç ”ç©¶",
      "authors": [
        "Antonio Guillen-Perez"
      ],
      "abstract": "Offline Reinforcement Learning (RL) presents a promising paradigm for training autonomous vehicle (AV) planning policies from large-scale, real-world driving logs. However, the extreme data imbalance in these logs, where mundane scenarios vastly outnumber rare \"long-tail\" events, leads to brittle and unsafe policies when using standard uniform data sampling. In this work, we address this challenge through a systematic, large-scale comparative study of data curation strategies designed to focus the learning process on information-rich samples. We investigate six distinct criticality weighting schemes which are categorized into three families: heuristic-based, uncertainty-based, and behavior-based. These are evaluated at two temporal scales, the individual timestep and the complete scenario. We train seven goal-conditioned Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based architecture and evaluate them in the high-fidelity Waymax simulator. Our results demonstrate that all data curation methods significantly outperform the baseline. Notably, data-driven curation using model uncertainty as a signal achieves the most significant safety improvements, reducing the collision rate by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear trade-off where timestep-level weighting excels at reactive safety while scenario-level weighting improves long-horizon planning. Our work provides a comprehensive framework for data curation in Offline RL and underscores that intelligent, non-uniform sampling is a critical component for building safe and reliable autonomous agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶(Autonomous Vehicle)è§„åˆ’ç­–ç•¥åœ¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ (Offline Reinforcement Learning)ä¸­é¢ä¸´çš„æ•°æ®åˆ†å¸ƒä¸å‡åŠâ€œé•¿å°¾â€(long-tail)åœºæ™¯ç¨€ç¼ºé—®é¢˜ï¼Œç³»ç»Ÿæ€§åœ°å¯¹æ¯”äº†å¤šç§ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ‰¹åˆ¤æ€§æŒ‡æ ‡(criticality metrics)ã€‚ç ”ç©¶è€…è°ƒæŸ¥äº†åŒ…æ‹¬åŸºäºå¯å‘å¼(heuristic-based)ã€ä¸ç¡®å®šæ€§(uncertainty-based)å’Œè¡Œä¸º(behavior-based)åœ¨å†…çš„å…­ç§æƒé‡æ–¹æ¡ˆï¼Œå¹¶åœ¨ä¸ªä½“æ—¶é—´æ­¥(timestep)å’Œå®Œæ•´åœºæ™¯(scenario)ä¸¤ä¸ªæ—¶é—´å°ºåº¦ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚é€šè¿‡åœ¨é«˜ä¿çœŸä»¿çœŸå™¨Waymaxä¸­å¯¹åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ä¿å®ˆQå­¦ä¹ (Conservative Q-Learning)æ™ºèƒ½ä½“è¿›è¡Œæµ‹è¯•ï¼Œç»“æœè¯æ˜æ‰€æœ‰æ•°æ®ç­›é€‰æ–¹æ³•å‡æ˜¾è‘—ä¼˜äºå‡åŒ€é‡‡æ ·çš„åŸºçº¿æ¨¡å‹ã€‚å…¶ä¸­ï¼Œåˆ©ç”¨æ¨¡å‹ä¸ç¡®å®šæ€§(model uncertainty)ä½œä¸ºä¿¡å·çš„ç­›é€‰æ–¹æ³•åœ¨å®‰å…¨æ€§ä¸Šè¡¨ç°æœ€ä¼˜ï¼Œå°†ç¢°æ’ç‡ä»16.0%å¤§å¹…é™ä½è‡³5.5%ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ­ç¤ºäº†æ—¶é—´æ­¥çº§åˆ«çš„æƒé‡åœ¨ååº”æ€§å®‰å…¨æ€§(reactive safety)ä¸Šçš„ä¼˜åŠ¿ä¸åœºæ™¯çº§åˆ«æƒé‡åœ¨é•¿æ—¶ç•Œè§„åˆ’(long-horizon planning)ä¸Šçš„æ”¹è¿›ä¹‹é—´çš„æƒè¡¡ã€‚è¯¥å·¥ä½œä¸ºç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„æ•°æ®ç­›é€‰æä¾›äº†å…¨é¢æ¡†æ¶ï¼Œå¼ºè°ƒäº†æ™ºèƒ½éå‡åŒ€é‡‡æ ·æ˜¯æ„å»ºå®‰å…¨å¯é è‡ªåŠ¨é©¾é©¶æ™ºèƒ½ä½“çš„æ ¸å¿ƒè¦ç´ ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18397v2",
      "published_date": "2025-08-25 18:37:29 UTC",
      "updated_date": "2025-09-16 21:13:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:54:54.152770+00:00"
    },
    {
      "arxiv_id": "2508.18395v2",
      "title": "Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning",
      "title_zh": "æ½œåœ¨è‡ªä¸€è‡´æ€§ï¼šçŸ­ç­”æ¡ˆä¸é•¿ç­”æ¡ˆæ¨ç†ä¸­çš„å¯é å¤šæ•°é›†é€‰æ‹©",
      "authors": [
        "Jungsuk Oh",
        "Jay-Yoon Lee"
      ],
      "abstract": "Probabilistic decoding in Large Language Models (LLMs) often yields inconsistent outputs, particularly on complex or long-form questions. Self-Consistency (SC) mitigates this for short-form QA by majority voting over exact strings, whereas Universal Self-Consistency (USC) and Weighted Unigram Consistency Score (WUCS) extend to long-form responses but lose accuracy on short-form benchmarks.\n  We introduce \\textbf{Latent Self-Consistency (LSC)}, which selects the most semantically consistent response using learnable token embeddings. LSC's lightweight forward processing of summary tokens only introduces negligible runtime overhead (at most $0.9\\%$) on top of standard decoding of the base LLM, and requires no changes to the model architecture.\n  Across 6 short-form and 5 long-form reasoning benchmarks (e.g., MATH, MMLU, TruthfulQA), LSC surpasses SC, USC, and WUCS on both short-form and long-form on average performance, while adding negligible computational overhead on vanilla inference. These results position LSC as a reliable consistency-selection method that works effectively across various answer formats. Additionally, LSC provides well-calibrated confidence estimates, maintaining low expected calibration error across both answer formats.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†å¤æ‚æˆ–é•¿ç¯‡å¹…é—®é¢˜æ—¶è¾“å‡ºä¸ä¸€è‡´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†Latent Self-Consistency (LSC)æ–¹æ³•ã€‚ä¼ ç»Ÿçš„Self-Consistency (SC)ä¸»è¦ä¾èµ–ç²¾ç¡®å­—ç¬¦ä¸²åŒ¹é…ï¼Œå¯¼è‡´å…¶åœ¨é•¿æ–‡æœ¬ä»»åŠ¡ä¸­å—é™ï¼Œè€Œç°æœ‰çš„æ‰©å±•æ–¹æ³•å¾€å¾€åœ¨çŸ­ç­”æ¡ˆä»»åŠ¡ä¸Šå‡†ç¡®ç‡æœ‰æ‰€ä¸‹é™ã€‚LSCé€šè¿‡åˆ©ç”¨å¯å­¦ä¹ çš„Token Embeddingsæ¥é€‰æ‹©è¯­ä¹‰æœ€ä¸€è‡´çš„å“åº”ï¼Œä¸”æ— éœ€ä¿®æ”¹æ¨¡å‹æ¶æ„ï¼Œä»…éœ€å¯¹æ‘˜è¦Tokenè¿›è¡Œæè½»é‡çº§çš„å‰å‘å¤„ç†ã€‚å®éªŒè¡¨æ˜ï¼ŒLSCåœ¨æ ‡å‡†æ¨ç†åŸºç¡€ä¸Šä»…å¢åŠ æœ€é«˜0.9%çš„è¿è¡Œå¼€é”€ï¼Œåœ¨MATHã€MMLUå’ŒTruthfulQAç­‰11ä¸ªçŸ­ç­”æ¡ˆä¸é•¿ç­”æ¡ˆæ¨ç†åŸºå‡†æµ‹è¯•ä¸­çš„å¹³å‡æ€§èƒ½å‡ä¼˜äºSCã€USCå’ŒWUCSã€‚æ­¤å¤–ï¼ŒLSCè¿˜èƒ½æä¾›æ ¡å‡†è‰¯å¥½çš„ç½®ä¿¡åº¦ä¼°è®¡ï¼Œåœ¨ä¸åŒç­”æ¡ˆæ ¼å¼ä¸‹å‡è¡¨ç°å‡ºæé«˜çš„å¯é æ€§ä¸ä½æ ¡å‡†è¯¯å·®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18395v2",
      "published_date": "2025-08-25 18:36:28 UTC",
      "updated_date": "2025-12-16 17:50:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:55:46.687715+00:00"
    },
    {
      "arxiv_id": "2508.18391v1",
      "title": "PKG-DPO: Optimizing Domain-Specific AI systems with Physics Knowledge Graphs and Direct Preference Optimization",
      "title_zh": "PKG-DPOï¼šåˆ©ç”¨ç‰©ç†çŸ¥è¯†å›¾è°±ä¸ç›´æ¥åå¥½ä¼˜åŒ–ï¼Œä¼˜åŒ–ç‰¹å®šé¢†åŸŸäººå·¥æ™ºèƒ½ç³»ç»Ÿ",
      "authors": [
        "Nitin Nagesh Kulkarni",
        "Bryson Wilcox",
        "Max Sawa",
        "Jason Thom"
      ],
      "abstract": "Advancing AI systems in scientific domains like physics, materials science, and engineering calls for reasoning over complex, multi-physics phenomena while respecting governing principles. Although Large Language Models (LLMs) and existing preference optimization techniques perform well on standard benchmarks, they often struggle to differentiate between physically valid and invalid reasoning. This shortcoming becomes critical in high-stakes applications like metal joining, where seemingly plausible yet physically incorrect recommendations can lead to defects, material waste, equipment damage, and serious safety risks. To address this challenge, we introduce PKG-DPO, a novel framework that integrates Physics Knowledge Graphs (PKGs) with Direct Preference Optimization (DPO) to enforce physical validity in AI-generated outputs. PKG-DPO comprises three key components A) hierarchical physics knowledge graph that encodes cross-domain relationships, conservation laws, and thermodynamic principles. B) A physics reasoning engine that leverages structured knowledge to improve discrimination between physically consistent and inconsistent responses. C) A physics-grounded evaluation suite designed to assess compliance with domain-specific constraints. PKG-DPO achieves 17% fewer constraint violations and an 11% higher Physics Score compared to KG-DPO (knowledge graph-based DPO). Additionally, PKG-DPO demonstrates a 12\\% higher relevant parameter accuracy and a 7% higher quality alignment in reasoning accuracy. While our primary focus is on metal joining, the framework is broadly applicable to other multi-scale, physics-driven domains, offering a principled approach to embedding scientific constraints into preference learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PKG-DPO æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç‰©ç†ã€ææ–™ç§‘å­¦å’Œå·¥ç¨‹ç­‰é¢†åŸŸéš¾ä»¥åŒºåˆ†ç‰©ç†æœ‰æ•ˆä¸æ— æ•ˆæ¨ç†çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†ç‰©ç†çŸ¥è¯†å›¾è°±ï¼ˆPhysics Knowledge Graphs, PKGsï¼‰ä¸ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimization, DPOï¼‰ç›¸ç»“åˆï¼Œé€šè¿‡ç¼–ç è·¨é¢†åŸŸå…³ç³»å’Œå®ˆæ’å®šå¾‹çš„åˆ†å±‚å›¾è°±æ¥ç¡®ä¿ AI ç”Ÿæˆå†…å®¹çš„ç‰©ç†å‡†ç¡®æ€§ã€‚PKG-DPO åŒ…å«ç‰©ç†æ¨ç†å¼•æ“å’Œä¸“é—¨çš„è¯„ä¼°å¥—ä»¶ï¼Œåˆ©ç”¨ç»“æ„åŒ–çŸ¥è¯†å¢å¼ºæ¨¡å‹å¯¹ç‰©ç†ä¸€è‡´æ€§çš„è¾¨åˆ«èƒ½åŠ›ã€‚åœ¨é‡‘å±è¿æ¥ï¼ˆmetal joiningï¼‰é¢†åŸŸçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æ¯”åŸºå‡†æ¨¡å‹ KG-DPO å‡å°‘äº† 17% çš„çº¦æŸè¿è§„ï¼Œå¹¶å°†ç‰©ç†è¯„åˆ†ï¼ˆPhysics Scoreï¼‰æå‡äº† 11%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ç›¸å…³å‚æ•°å‡†ç¡®ç‡å’Œæ¨ç†å¯¹é½è´¨é‡ä¸Šåˆ†åˆ«å®ç°äº† 12% å’Œ 7% çš„æå‡ã€‚è¿™ä¸€ç ”ç©¶ä¸ºåœ¨åå¥½å­¦ä¹ ä¸­åµŒå…¥ç§‘å­¦çº¦æŸæä¾›äº†ä¸€ç§é€šç”¨çš„åŸåˆ™æ€§æ–¹æ³•ï¼Œé€‚ç”¨äºå¤šç§å¤šå°ºåº¦ã€ç‰©ç†é©±åŠ¨çš„ä¸“ä¸šé¢†åŸŸã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18391v1",
      "published_date": "2025-08-25 18:31:03 UTC",
      "updated_date": "2025-08-25 18:31:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:09.483004+00:00"
    },
    {
      "arxiv_id": "2508.18384v1",
      "title": "Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails",
      "title_zh": "Backpromptingï¼šåˆ©ç”¨åˆæˆç”Ÿäº§æ•°æ®æ„å»ºå¥åº·å»ºè®®å®‰å…¨æŠ¤æ ",
      "authors": [
        "Kellen Tan Cheng",
        "Anna Lisa Gentile",
        "Chad DeLuca",
        "Guang-Jie Ren"
      ],
      "abstract": "The pervasiveness of large language models (LLMs) in enterprise settings has also brought forth a significant amount of risks associated with their usage. Guardrails technologies aim to mitigate this risk by filtering LLMs' input/output text through various detectors. However, developing and maintaining robust detectors faces many challenges, one of which is the difficulty in acquiring production-quality labeled data on real LLM outputs prior to deployment. In this work, we propose backprompting, a simple yet intuitive solution to generate production-like labeled data for health advice guardrails development. Furthermore, we pair our backprompting method with a sparse human-in-the-loop clustering technique to label the generated data. Our aim is to construct a parallel corpus roughly representative of the original dataset yet resembling real LLM output. We then infuse existing datasets with our synthetic examples to produce robust training data for our detector. We test our technique in one of the most difficult and nuanced guardrails: the identification of health advice in LLM output, and demonstrate improvement versus other solutions. Our detector is able to outperform GPT-4o by up to 3.73%, despite having 400x less parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ä¸šçº§å¤§è¯­è¨€æ¨¡å‹(LLMs)é¢ä¸´çš„é£é™©åŠæŠ¤æ (Guardrails)æŠ€æœ¯åœ¨éƒ¨ç½²å‰ç¼ºä¹é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºBackpromptingçš„æ–¹æ³•ï¼Œç”¨äºä¸ºå¥åº·å»ºè®®æŠ¤æ ç”Ÿæˆç±»ç”Ÿäº§ç¯å¢ƒçš„åˆæˆæ ‡æ³¨æ•°æ®ã€‚ç ”ç©¶è€…å°†Backpromptingä¸ç¨€ç–çš„äººæœºå›ç¯èšç±»æŠ€æœ¯(Human-in-the-Loop Clustering)ç›¸ç»“åˆï¼Œé€šè¿‡æ„å»ºä¸çœŸå®æ¨¡å‹è¾“å‡ºé«˜åº¦ç›¸ä¼¼çš„å¹³è¡Œè¯­æ–™åº“æ¥å¢å¼ºç°æœ‰æ•°æ®é›†ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨ä¸ºæ£€æµ‹å™¨æä¾›æ›´å…·é²æ£’æ€§çš„è®­ç»ƒæ•°æ®ï¼Œä»è€Œåœ¨å¤æ‚çš„å¥åº·å»ºè®®è¯†åˆ«åœºæ™¯ä¸­æå‡æ£€æµ‹æ•ˆèƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•è®­ç»ƒå‡ºçš„æ£€æµ‹å™¨æ€§èƒ½ä¼˜äºGPT-4oçº¦3.73%ï¼Œä¸”å…¶å‚æ•°é‡ä»…ä¸ºåè€…çš„å››ç™¾åˆ†ä¹‹ä¸€ã€‚è¿™ä¸€ç ”ç©¶æˆæœè¯æ˜äº†åˆ©ç”¨åˆæˆç”Ÿäº§æ•°æ®ä¼˜åŒ–è½»é‡çº§å®‰å…¨æŠ¤æ æ¨¡å‹çš„å¯è¡Œæ€§ä¸ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18384v1",
      "published_date": "2025-08-25 18:17:00 UTC",
      "updated_date": "2025-08-25 18:17:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:55:59.598023+00:00"
    },
    {
      "arxiv_id": "2508.18380v1",
      "title": "Information Templates: A New Paradigm for Intelligent Active Feature Acquisition",
      "title_zh": "ä¿¡æ¯æ¨¡æ¿ï¼šæ™ºèƒ½ä¸»åŠ¨ç‰¹å¾è·å–çš„æ–°èŒƒå¼",
      "authors": [
        "Hung-Tien Huang",
        "Dzung Dinh",
        "Junier B. Oliva"
      ],
      "abstract": "Active feature acquisition (AFA) is an instance-adaptive paradigm in which, at test time, a policy sequentially chooses which features to acquire (at a cost) before predicting. Existing approaches either train reinforcement learning (RL) policies, which deal with a difficult MDP, or greedy policies that cannot account for the joint informativeness of features or require knowledge about the underlying data distribution. To overcome this, we propose Template-based AFA (TAFA), a non-greedy framework that learns a small library of feature templates--a set of features that are jointly informative--and uses this library of templates to guide the next feature acquisitions. Through identifying feature templates, the proposed framework not only significantly reduces the action space considered by the policy but also alleviates the need to estimate the underlying data distribution. Extensive experiments on synthetic and real-world datasets show that TAFA outperforms the existing state-of-the-art baselines while achieving lower overall acquisition cost and computation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸»åŠ¨ç‰¹å¾è·å– (Active Feature Acquisition, AFA) é¢†åŸŸä¸­ï¼Œå¼ºåŒ–å­¦ä¹  (RL) ç­–ç•¥é¢ä¸´é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (MDP) å¤æ‚åº¦é«˜ï¼Œä»¥åŠè´ªå©ªç­–ç•¥éš¾ä»¥è¡¡é‡ç‰¹å¾è”åˆä¿¡æ¯é‡æˆ–ä¾èµ–æ•°æ®åˆ†å¸ƒçŸ¥è¯†çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ¨¡æ¿çš„ AFA æ¡†æ¶ (Template-based AFA, TAFA)ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºå­¦ä¹ ä¸€ä¸ªåŒ…å«ç‰¹å¾æ¨¡æ¿ (feature templates) çš„å°å‹åº“ï¼Œé€šè¿‡è¯†åˆ«å…·æœ‰è”åˆä¿¡æ¯é‡çš„ç‰¹å¾é›†åˆæ¥å¼•å¯¼åç»­çš„é‡‡é›†å†³ç­–ã€‚è¿™ç§éè´ªå©ªçš„èŒƒå¼ä¸ä»…æ˜¾è‘—ç¼©å°äº†ç­–ç•¥æœç´¢çš„åŠ¨ä½œç©ºé—´ï¼Œè¿˜æ¶ˆé™¤äº†å¯¹åº•å±‚æ•°æ®åˆ†å¸ƒè¿›è¡Œæ˜¾å¼ä¼°ç®—çš„å¿…è¦ã€‚åœ¨åˆæˆä¸çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒTAFA åœ¨æ€§èƒ½ä¸Šå…¨é¢è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å®ç°é«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†ç»¼åˆè·å–æˆæœ¬ä¸è®¡ç®—å¼€é”€ï¼Œä¸ºæ™ºèƒ½ä¸»åŠ¨ç‰¹å¾è·å–æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18380v1",
      "published_date": "2025-08-25 18:15:11 UTC",
      "updated_date": "2025-08-25 18:15:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:14.391601+00:00"
    },
    {
      "arxiv_id": "2508.19298v1",
      "title": "DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models",
      "title_zh": "DemoBiasï¼šè§†è§‰åŸºç¡€æ¨¡å‹ä¸­äººå£ç»Ÿè®¡å­¦åè§çš„æº¯æºå®è¯ç ”ç©¶",
      "authors": [
        "Abu Sufian",
        "Anirudha Ghosh",
        "Debaditya Barman",
        "Marco Leo",
        "Cosimo Distante"
      ],
      "abstract": "Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities across various downstream tasks, including biometric face recognition (FR) with description. However, demographic biases remain a critical concern in FR, as these foundation models often fail to perform equitably across diverse demographic groups, considering ethnicity/race, gender, and age. Therefore, through our work DemoBias, we conduct an empirical evaluation to investigate the extent of demographic biases in LVLMs for biometric FR with textual token generation tasks. We fine-tuned and evaluated three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own generated demographic-balanced dataset. We utilize several evaluation metrics, like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify and trace the performance disparities. The experimental results deliver compelling insights into the fairness and reliability of LVLMs across diverse demographic groups. Our empirical study uncovered demographic biases in LVLMs, with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino, Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably consistent. Repository: https://github.com/Sufianlab/DemoBias.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DemoBiasï¼Œé€šè¿‡å®è¯ç ”ç©¶è¿½è¸ªLarge Vision Language Models (LVLMs)åœ¨ç”Ÿç‰©ç‰¹å¾äººè„¸è¯†åˆ«(FR)åŠæ–‡æœ¬æ ‡è®°ç”Ÿæˆä»»åŠ¡ä¸­çš„äººå£ç»Ÿè®¡åå·®(Demographic Biases)ã€‚ç ”ç©¶è€…åˆ©ç”¨è‡ªè¡Œç”Ÿæˆçš„å¹³è¡¡æ•°æ®é›†ï¼Œå¯¹LLaVAã€BLIP-2å’ŒPaliGemmaä¸‰ç§é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒä¸è¯„ä¼°ï¼Œå¹¶é‡‡ç”¨group-specific BERTScoreså’ŒFairness Discrepancy Rateç­‰æŒ‡æ ‡é‡åŒ–æ€§èƒ½å·®å¼‚ã€‚å®éªŒç»“æœè¯å®äº†LVLMsä¸­æ™®éå­˜åœ¨åè§ï¼Œå…¶ä¸­PaliGemmaå’ŒLLaVAåœ¨Hispanic/Latinoã€Caucasianå’ŒSouth Asianç¾¤ä½“ä¸­è¡¨ç°å‡ºè¾ƒé«˜çš„æ€§èƒ½å·®å¼‚ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒBLIP-2åœ¨ä¸åŒäººå£ç»Ÿè®¡ç¾¤ä½“é—´å±•ç°äº†æ›´å¼ºçš„ä¸€è‡´æ€§ã€‚è¯¥å®è¯ç ”ç©¶æ·±å…¥æ¢è®¨äº†è§†è§‰åŸºç¡€æ¨¡å‹çš„å…¬å¹³æ€§ä¸å¯é æ€§ï¼Œä¸ºæœªæ¥å¼€å‘æ›´å…·åŒ…å®¹æ€§çš„ç”Ÿç‰©ç‰¹å¾è¯†åˆ«æŠ€æœ¯æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figures, 13th International Workshop on Biometrics and Forensics (IWBF)",
      "pdf_url": "https://arxiv.org/pdf/2508.19298v1",
      "published_date": "2025-08-25 18:02:49 UTC",
      "updated_date": "2025-08-25 18:02:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:11.897337+00:00"
    },
    {
      "arxiv_id": "2508.18268v1",
      "title": "SafeBimanual: Diffusion-based Trajectory Optimization for Safe Bimanual Manipulation",
      "title_zh": "SafeBimanualï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å®‰å…¨åŒè‡‚æ“ä½œè½¨è¿¹ä¼˜åŒ–",
      "authors": [
        "Haoyuan Deng",
        "Wenkai Guo",
        "Qianzhun Wang",
        "Zhenyu Wu",
        "Ziwei Wang"
      ],
      "abstract": "Bimanual manipulation has been widely applied in household services and manufacturing, which enables the complex task completion with coordination requirements. Recent diffusion-based policy learning approaches have achieved promising performance in modeling action distributions for bimanual manipulation. However, they ignored the physical safety constraints of bimanual manipulation, which leads to the dangerous behaviors with damage to robots and objects. To this end, we propose a test-time trajectory optimization framework named SafeBimanual for any pre-trained diffusion-based bimanual manipulation policies, which imposes the safety constraints on bimanual actions to avoid dangerous robot behaviors with improved success rate. Specifically, we design diverse cost functions for safety constraints in different dual-arm cooperation patterns including avoidance of tearing objects and collision between arms and objects, which optimizes the manipulator trajectories with guided sampling of diffusion denoising process. Moreover, we employ a vision-language model (VLM) to schedule the cost functions by specifying keypoints and corresponding pairwise relationship, so that the optimal safety constraint is dynamically generated in the entire bimanual manipulation process. SafeBimanual demonstrates superiority on 8 simulated tasks in RoboTwin with a 13.7% increase in success rate and a 18.8% reduction in unsafe interactions over state-of-the-art diffusion-based methods. Extensive experiments on 4 real-world tasks further verify its practical value by improving the success rate by 32.5%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒè‡‚æ“ä½œ(Bimanual manipulation)ä¸­åŸºäºæ‰©æ•£çš„ç­–ç•¥(Diffusion-based policy)å¾€å¾€å¿½ç•¥ç‰©ç†å®‰å…¨çº¦æŸè€Œå¯¼è‡´æœºå™¨äººæˆ–ç‰©ä½“å—æŸçš„é—®é¢˜ï¼Œæå‡ºäº†SafeBimanualæ¡†æ¶ã€‚SafeBimanualæ˜¯ä¸€ç§é’ˆå¯¹é¢„è®­ç»ƒæ‰©æ•£ç­–ç•¥çš„æµ‹è¯•æ—¶è½¨è¿¹ä¼˜åŒ–(Trajectory optimization)æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ‰©æ•£å»å™ªè¿‡ç¨‹ä¸­å¼•å…¥å¼•å¯¼é‡‡æ ·(Guided sampling)æ¥æ–½åŠ å®‰å…¨çº¦æŸã€‚ç ”ç©¶è®¾è®¡äº†å¤šç§é’ˆå¯¹åŒè‡‚åä½œæ¨¡å¼çš„ä»£ä»·å‡½æ•°(Cost functions)ï¼Œä»¥é¿å…ç‰©ä½“æ’•è£‚åŠæœºæ¢°è‡‚ç¢°æ’ï¼Œå¹¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹(VLM)æ ¹æ®å…³é”®ç‚¹å’Œç©ºé—´å…³ç³»åŠ¨æ€è°ƒåº¦è¿™äº›çº¦æŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSafeBimanualåœ¨RoboTwinæ¨¡æ‹Ÿä»»åŠ¡ä¸­å°†æˆåŠŸç‡æé«˜äº†13.7%ï¼Œå¹¶å‡å°‘äº†18.8%çš„ä¸å®‰å…¨äº¤äº’ã€‚åœ¨çœŸå®åœºæ™¯ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•è¿›ä¸€æ­¥æå‡äº†32.5%çš„æˆåŠŸç‡ï¼Œå……åˆ†éªŒè¯äº†å…¶åœ¨å¤æ‚åŒè‡‚åè°ƒä»»åŠ¡ä¸­çš„å®ç”¨ä»·å€¼ä¸å®‰å…¨æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website is at: https://denghaoyuan123.github.io/SafeBimanip/",
      "pdf_url": "https://arxiv.org/pdf/2508.18268v1",
      "published_date": "2025-08-25 17:59:02 UTC",
      "updated_date": "2025-08-25 17:59:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:10.282440+00:00"
    },
    {
      "arxiv_id": "2508.18258v2",
      "title": "ANO : Faster is Better in Noisy Landscape",
      "title_zh": "ANOï¼šå™ªå£°æ™¯è§‚ä¸‹çš„å¿«å³æ˜¯å¥½",
      "authors": [
        "Adrien Kegreisz"
      ],
      "abstract": "Stochastic optimizers are central to deep learning, yet widely used methods such as Adam and Adan can degrade in non-stationary or noisy environments, partly due to their reliance on momentum-based magnitude estimates. We introduce Ano, a novel optimizer that decouples direction and magnitude: momentum is used for directional smoothing, while instantaneous gradient magnitudes determine step size. This design improves robustness to gradient noise while retaining the simplicity and efficiency of first-order methods. We further propose Anolog, which removes sensitivity to the momentum coefficient by expanding its window over time via a logarithmic schedule. We establish non-convex convergence guarantees with a convergence rate similar to other sign-based methods, and empirically show that Ano provides substantial gains in noisy and non-stationary regimes such as reinforcement learning, while remaining competitive on low-noise tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Adamå’ŒAdanç­‰éšæœºä¼˜åŒ–å™¨åœ¨éå¹³ç¨³æˆ–é«˜å™ªå£°ç¯å¢ƒä¸‹å› ä¾èµ–åŠ¨é‡å¹…å€¼ä¼°è®¡è€Œæ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†æ–°å‹ä¼˜åŒ–å™¨Anoã€‚Anoé€šè¿‡è§£è€¦æ–¹å‘ä¸å¹…å€¼ï¼Œåˆ©ç”¨åŠ¨é‡(momentum)è¿›è¡Œæ–¹å‘å¹³æ»‘ï¼Œå¹¶ä½¿ç”¨ç¬æ—¶æ¢¯åº¦å¹…å€¼å†³å®šæ­¥é•¿ï¼Œä»è€Œåœ¨ä¿æŒä¸€é˜¶æ–¹æ³•ç®€æ´æ€§çš„åŒæ—¶å¢å¼ºäº†å¯¹æ¢¯åº¦å™ªå£°çš„é²æ£’æ€§ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†Anologï¼Œé€šè¿‡å¯¹æ•°æ—¶é—´è¡¨(logarithmic schedule)æ‰©å±•åŠ¨é‡çª—å£ï¼Œæ¶ˆé™¤äº†å¯¹åŠ¨é‡ç³»æ•°çš„æ•æ„Ÿæ€§ã€‚ç†è®ºå±‚é¢ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†Anoåœ¨éå‡¸æ¡ä»¶ä¸‹çš„æ”¶æ•›æ€§ï¼Œå…¶æ”¶æ•›é€Ÿç‡ä¸ç¬¦å·ä¼˜åŒ–æ–¹æ³•(sign-based methods)ç›¸å½“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAnoåœ¨å¼ºåŒ–å­¦ä¹ (reinforcement learning)ç­‰é«˜å™ªå£°å’Œéå¹³ç¨³åœºæ™¯ä¸­å–å¾—äº†æ˜¾è‘—å¢ç›Šï¼ŒåŒæ—¶åœ¨ä½å™ªå£°ä»»åŠ¡ä¸­ä¹Ÿä¿æŒäº†æå¼ºçš„ç«äº‰åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review for ICLR 2026, 25 pages total with appendix, 7 figures, 12 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.18258v2",
      "published_date": "2025-08-25 17:51:00 UTC",
      "updated_date": "2025-11-10 15:31:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:21.391217+00:00"
    },
    {
      "arxiv_id": "2508.18255v2",
      "title": "Hermes 4 Technical Report",
      "title_zh": "Hermes 4 æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Ryan Teknium",
        "Roger Jin",
        "Jai Suphavadeeprasit",
        "Dakota Mahan",
        "Jeffrey Quesnelle",
        "Joe Li",
        "Chen Guang",
        "Shannon Sands",
        "Karan Malhotra"
      ],
      "abstract": "We present Hermes 4, a family of hybrid reasoning models that combine structured, multi-turn reasoning with broad instruction-following ability. We describe the challenges encountered during data curation, synthesis, training, and evaluation, and outline the solutions employed to address these challenges at scale. We comprehensively evaluate across mathematical reasoning, coding, knowledge, comprehension, and alignment benchmarks, and we report both quantitative performance and qualitative behavioral analysis. To support open research, all model weights are published publicly at https://huggingface.co/collections/NousResearch/hermes-4-collection-68a731bfd452e20816725728",
      "tldr_zh": "è¯¥æŠ¥å‘Šä»‹ç»äº† Hermes 4ï¼Œè¿™æ˜¯ä¸€ä¸ªæ··åˆæ¨ç†(Hybrid Reasoning)æ¨¡å‹ç³»åˆ—ï¼Œå…¶æ ¸å¿ƒç›®æ ‡æ˜¯å°†ç»“æ„åŒ–çš„å¤šè½®æ¨ç†èƒ½åŠ›ä¸å¹¿æ³›çš„æŒ‡ä»¤éµå¾ª(Instruction-following)èƒ½åŠ›ç›¸ç»“åˆã€‚ç ”ç©¶å›¢é˜Ÿè¯¦ç»†æè¿°äº†åœ¨æ•°æ®æ•´ç†(Data Curation)ã€æ•°æ®åˆæˆ(Synthesis)ã€æ¨¡å‹è®­ç»ƒåŠè¯„ä¼°è¿‡ç¨‹ä¸­é¢ä¸´çš„å¤§è§„æ¨¡æŒ‘æˆ˜ï¼Œå¹¶é˜è¿°äº†ç›¸åº”çš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡åœ¨æ•°å­¦æ¨ç†ã€ç¼–ç¨‹(Coding)ã€çŸ¥è¯†ã€ç†è§£å’Œå¯¹é½(Alignment)ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å…¨é¢è¯„ä¼°ï¼Œè¯¥ç ”ç©¶æä¾›äº†è¯¦å°½çš„å®šé‡æ€§èƒ½æ•°æ®ä¸å®šæ€§è¡Œä¸ºåˆ†æã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ¨¡å‹åœ¨å¤šé¢†åŸŸä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œç›®å‰æ‰€æœ‰æ¨¡å‹æƒé‡å·²åœ¨ Hugging Face å…¬å¼€å‘å¸ƒï¼Œæ—¨åœ¨æ¨åŠ¨å¼€æ”¾å¼äººå·¥æ™ºèƒ½ç ”ç©¶çš„å‘å±•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18255v2",
      "published_date": "2025-08-25 17:45:06 UTC",
      "updated_date": "2025-09-02 17:12:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:25.693178+00:00"
    },
    {
      "arxiv_id": "2508.18252v1",
      "title": "Efficient Computation of Blackwell Optimal Policies using Rational Functions",
      "title_zh": "åŸºäºæœ‰ç†å‡½æ•°çš„ Blackwell æœ€ä¼˜ç­–ç•¥é«˜æ•ˆè®¡ç®—",
      "authors": [
        "Dibyangshu Mukherjee",
        "Shivaram Kalyanakrishnan"
      ],
      "abstract": "Markov Decision Problems (MDPs) provide a foundational framework for modelling sequential decision-making across diverse domains, guided by optimality criteria such as discounted and average rewards. However, these criteria have inherent limitations: discounted optimality may overly prioritise short-term rewards, while average optimality relies on strong structural assumptions. Blackwell optimality addresses these challenges, offering a robust and comprehensive criterion that ensures optimality under both discounted and average reward frameworks. Despite its theoretical appeal, existing algorithms for computing Blackwell Optimal (BO) policies are computationally expensive or hard to implement.\n  In this paper we describe procedures for computing BO policies using an ordering of rational functions in the vicinity of $1$. We adapt state-of-the-art algorithms for deterministic and general MDPs, replacing numerical evaluations with symbolic operations on rational functions to derive bounds independent of bit complexity. For deterministic MDPs, we give the first strongly polynomial-time algorithms for computing BO policies, and for general MDPs we obtain the first subexponential-time algorithm. We further generalise several policy iteration algorithms, extending the best known upper bounds from the discounted to the Blackwell criterion.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†Markov Decision Problems (MDPs)ä¸­Blackwell optimalityçš„è®¡ç®—æ•ˆç‡é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸæŠ˜æ‰£ä¸å¹³å‡å¥–åŠ±å‡†åˆ™åœ¨å»ºæ¨¡åºè´¯å†³ç­–æ—¶çš„å±€é™æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åˆ©ç”¨1é™„è¿‘çš„rational functionsè¿›è¡Œæ’åºçš„è®¡ç®—ç¨‹åºï¼Œé€šè¿‡å°†ä¼ ç»Ÿçš„æ•°å€¼è¯„ä¼°æ›¿æ¢ä¸ºå¯¹rational functionsçš„ç¬¦å·æ“ä½œ(symbolic operations)ï¼Œå®ç°äº†ä¸ä½å¤æ‚åº¦(bit complexity)æ— å…³çš„ç•Œé™æ¨å¯¼ã€‚é’ˆå¯¹deterministic MDPsï¼Œè¯¥ç ”ç©¶æå‡ºäº†é¦–ä¸ªç”¨äºè®¡ç®—Blackwell Optimal (BO)ç­–ç•¥çš„å¼ºå¤šé¡¹å¼æ—¶é—´ç®—æ³•(strongly polynomial-time algorithms)ï¼›è€Œå¯¹äºä¸€èˆ¬MDPsï¼Œåˆ™å®ç°äº†é¦–ä¸ªäºšæŒ‡æ•°æ—¶é—´ç®—æ³•(subexponential-time algorithm)ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜æ³›åŒ–äº†å¤šç§policy iterationç®—æ³•ï¼ŒæˆåŠŸå°†æŠ˜æ‰£å‡†åˆ™ä¸‹çš„æœ€ä½³å·²çŸ¥ä¸Šç•Œæ‰©å±•è‡³Blackwellå‡†åˆ™ã€‚è¿™äº›æˆæœä¸ºé«˜æ•ˆè®¡ç®—å…·å¤‡é²æ£’æ€§çš„Blackwellæœ€ä¼˜ç­–ç•¥æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘å’Œç®—æ³•æ”¹è¿›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18252v1",
      "published_date": "2025-08-25 17:41:30 UTC",
      "updated_date": "2025-08-25 17:41:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:41.883953+00:00"
    },
    {
      "arxiv_id": "2508.18244v2",
      "title": "Type-Compliant Adaptation Cascades: Adapting Programmatic LM Workflows to Data",
      "title_zh": "ç±»å‹åˆè§„é€‚é…çº§è”ï¼šå°†ç¨‹åºåŒ–è¯­è¨€æ¨¡å‹å·¥ä½œæµé€‚é…åˆ°æ•°æ®",
      "authors": [
        "Chu-Cheng Lin",
        "Daiyi Peng",
        "Yifeng Lu",
        "Ming Zhang",
        "Eugene Ie"
      ],
      "abstract": "Reliably composing Large Language Models (LLMs) for complex, multi-step workflows remains a significant challenge. The dominant paradigm -- optimizing discrete prompts in a pipeline -- is notoriously brittle and struggles to enforce the formal compliance required for structured tasks. We introduce Type-Compliant Adaptation Cascades (TACs), a framework that recasts workflow adaptation as learning typed probabilistic programs. TACs treat the entire workflow, which is composed of parameter-efficiently adapted LLMs and deterministic logic, as an unnormalized joint distribution. This enables principled, gradient-based training even with latent intermediate structures. We provide theoretical justification for our tractable optimization objective, proving that the optimization bias vanishes as the model learns type compliance. Empirically, TACs significantly outperform state-of-the-art prompt-optimization baselines. Gains are particularly pronounced on structured tasks, improving FinQA from $12.0\\%$ to $24.7\\%$ for a Qwen 3 8B model, MGSM-SymPy from $57.1\\%$ to $75.9\\%$ for a Gemma 2 27B model, MGSM from $1.6\\%$ to $27.3\\%$, and MuSR from $36.5\\%$ to $62.6\\%$ for a Gemma 7B model. TACs offer a robust and theoretically grounded paradigm for developing reliable, task-compliant LLM systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Type-Compliant Adaptation Cascades (TACs) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤æ‚å¤šæ­¥å·¥ä½œæµä¸­ç»„åˆå¯é æ€§å·®åŠç¼ºä¹å½¢å¼åˆè§„æ€§ç­‰æŒ‘æˆ˜ã€‚TACs å°†åŒ…å«å‚æ•°é«˜æ•ˆé€‚é… LLMs å’Œç¡®å®šæ€§é€»è¾‘çš„ç¨‹åºåŒ–å·¥ä½œæµé‡æ–°å®šä¹‰ä¸ºå­¦ä¹ æœ‰ç±»å‹çš„æ¦‚ç‡ç¨‹åºï¼Œå¹¶å°†å…¶è§†ä¸ºä¸€ä¸ªéæ ‡å‡†åŒ–çš„è”åˆåˆ†å¸ƒã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œå³ä½¿åœ¨å­˜åœ¨æ½œåœ¨ä¸­é—´ç»“æ„çš„æƒ…å†µä¸‹ï¼Œæ¡†æ¶ä¹Ÿèƒ½å®ç°åŸºäºæ¢¯åº¦çš„åŸåˆ™æ€§è®­ç»ƒï¼Œå¹¶æä¾›äº†ä¼˜åŒ–åå·®éšç±»å‹åˆè§„æ€§å­¦ä¹ è€Œæ¶ˆå¤±çš„ç†è®ºè¯æ˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTACs åœ¨ FinQAã€MGSM å’Œ MuSR ç­‰å¤šä¸ªç»“æ„åŒ–ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„æç¤ºä¼˜åŒ– (prompt-optimization) åŸºå‡†æ¨¡å‹ï¼Œä¾‹å¦‚å°† Gemma 7B åœ¨ MuSR ä»»åŠ¡ä¸Šçš„è¡¨ç°ä» 36.5% æå‡è‡³ 62.6%ã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºå¯é ã€ç¬¦åˆä»»åŠ¡çº¦æŸä¸”å…·å¤‡ç†è®ºæ”¯æ’‘çš„ LLM ç³»ç»Ÿæä¾›äº†ä¸€ç§é²æ£’çš„æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18244v2",
      "published_date": "2025-08-25 17:36:21 UTC",
      "updated_date": "2025-09-26 21:39:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:40.484686+00:00"
    },
    {
      "arxiv_id": "2508.18226v1",
      "title": "Disentangling the Factors of Convergence between Brains and Computer Vision Models",
      "title_zh": "å˜æ¸…å¤§è„‘ä¸è®¡ç®—æœºè§†è§‰æ¨¡å‹è¶‹åŒçš„å½±å“å› ç´ ",
      "authors": [
        "JosÃ©phine Raugel",
        "Marc Szafraniec",
        "Huy V. Vo",
        "Camille Couprie",
        "Patrick Labatut",
        "Piotr Bojanowski",
        "Valentin Wyart",
        "Jean-RÃ©mi King"
      ],
      "abstract": "Many AI models trained on natural images develop representations that resemble those of the human brain. However, the factors that drive this brain-model similarity remain poorly understood. To disentangle how the model, training and data independently lead a neural network to develop brain-like representations, we trained a family of self-supervised vision transformers (DINOv3) that systematically varied these different factors. We compare their representations of images to those of the human brain recorded with both fMRI and MEG, providing high resolution in spatial and temporal analyses. We assess the brain-model similarity with three complementary metrics focusing on overall representational similarity, topographical organization, and temporal dynamics. We show that all three factors - model size, training amount, and image type - independently and interactively impact each of these brain similarity metrics. In particular, the largest DINOv3 models trained with the most human-centric images reach the highest brain-similarity. This emergence of brain-like representations in AI models follows a specific chronology during training: models first align with the early representations of the sensory cortices, and only align with the late and prefrontal representations of the brain with considerably more training. Finally, this developmental trajectory is indexed by both structural and functional properties of the human cortex: the representations that are acquired last by the models specifically align with the cortical areas with the largest developmental expansion, thickness, least myelination, and slowest timescales. Overall, these findings disentangle the interplay between architecture and experience in shaping how artificial neural networks come to see the world as humans do, thus offering a promising framework to understand how the human brain comes to represent its visual world.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨æ­ç¤ºé©±åŠ¨äººå·¥æ™ºèƒ½æ¨¡å‹ä¸äººç±»å¤§è„‘è¡¨å¾ç›¸ä¼¼æ€§(brain-model similarity)çš„å…³é”®å› ç´ ï¼Œé€šè¿‡ç³»ç»Ÿæ€§æ”¹å˜æ¨¡å‹è§„æ¨¡ã€è®­ç»ƒé‡å’Œæ•°æ®ç±»å‹è®­ç»ƒäº†ä¸€ç³»åˆ—è‡ªç›‘ç£è§†è§‰Transformer(DINOv3)æ¨¡å‹ã€‚ç ”ç©¶è€…å°†æ¨¡å‹è¡¨å¾ä¸åˆ©ç”¨fMRIå’ŒMEGè®°å½•çš„äººè„‘é«˜ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡æ•°æ®è¿›è¡Œå¯¹æ¯”ï¼Œå¹¶ä»æ•´ä½“ç›¸ä¼¼æ€§ã€æ‹“æ‰‘ç»„ç»‡å’Œæ—¶é—´åŠ¨æ€ä¸‰ä¸ªç»´åº¦è¿›è¡Œè¯„ä¼°ã€‚å®éªŒå‘ç°æ¨¡å‹è§„æ¨¡ã€è®­ç»ƒé‡å’Œå›¾åƒç±»å‹å‡ç‹¬ç«‹ä¸”äº¤äº’åœ°å½±å“å¤§è„‘ç›¸ä¼¼æ€§ï¼Œå…¶ä¸­é‡‡ç”¨å¤§è§„æ¨¡äººç±»ä¸­å¿ƒå›¾åƒè®­ç»ƒçš„å¤§å‹æ¨¡å‹ç›¸ä¼¼åº¦æœ€é«˜ã€‚è„‘ç±»è¡¨å¾çš„å‡ºç°éµå¾ªç‰¹å®šé¡ºåºï¼Œæ¨¡å‹åœ¨ç»è¿‡å¤§é‡è®­ç»ƒåæ‰é€æ¸ä»å¯¹é½æ—©æœŸæ„Ÿè§‰çš®å±‚è½¬å‘å¯¹é½æ™šæœŸå‰é¢å¶è¡¨å¾ã€‚è¿™ç§æ¨¡å‹å‘å±•è½¨è¿¹ä¸äººç±»å¤§è„‘çš®å±‚çš„å‘è‚²æ‰©å¼ ã€é«“é˜åŒ–ç¨‹åº¦åŠæ—¶é—´å°ºåº¦ç­‰ç»“æ„å±æ€§é«˜åº¦å»åˆï¼Œæ¨¡å‹æœ€æ™šä¹ å¾—çš„è¡¨å¾å¯¹åº”äºå‘è‚²æ‰©å¼ æœ€å¤§çš„çš®å±‚åŒºåŸŸã€‚è¯¥ç ”ç©¶é€šè¿‡è§£æ„æ¶æ„ä¸ç»éªŒåœ¨å¡‘é€ ç±»äººè§†è§‰ä¸­çš„ç›¸äº’ä½œç”¨ï¼Œä¸ºç†è§£äººç±»å¤§è„‘å¦‚ä½•è¡¨å¾è§†è§‰ä¸–ç•Œæä¾›äº†é‡è¦æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18226v1",
      "published_date": "2025-08-25 17:23:27 UTC",
      "updated_date": "2025-08-25 17:23:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:08.636869+00:00"
    },
    {
      "arxiv_id": "2508.19294v2",
      "title": "Object Detection with Multimodal Large Vision-Language Models: An In-depth Review",
      "title_zh": "åŸºäºå¤šæ¨¡æ€å¤§è§†è§‰è¯­è¨€æ¨¡å‹çš„ç›®æ ‡æ£€æµ‹æ·±åº¦ç»¼è¿°",
      "authors": [
        "Ranjan Sapkota",
        "Manoj Karkee"
      ],
      "abstract": "The fusion of language and vision in large vision-language models (LVLMs) has revolutionized deep learning-based object detection by enhancing adaptability, contextual reasoning, and generalization beyond traditional architectures. This in-depth review presents a structured exploration of the state-of-the-art in LVLMs, systematically organized through a three-step research review process. First, we discuss the functioning of vision language models (VLMs) for object detection, describing how these models harness natural language processing (NLP) and computer vision (CV) techniques to revolutionize object detection and localization. We then explain the architectural innovations, training paradigms, and output flexibility of recent LVLMs for object detection, highlighting how they achieve advanced contextual understanding for object detection. The review thoroughly examines the approaches used in integration of visual and textual information, demonstrating the progress made in object detection using VLMs that facilitate more sophisticated object detection and localization strategies. This review presents comprehensive visualizations demonstrating LVLMs' effectiveness in diverse scenarios including localization and segmentation, and then compares their real-time performance, adaptability, and complexity to traditional deep learning systems. Based on the review, its is expected that LVLMs will soon meet or surpass the performance of conventional methods in object detection. The review also identifies a few major limitations of the current LVLM modes, proposes solutions to address those challenges, and presents a clear roadmap for the future advancement in this field. We conclude, based on this study, that the recent advancement in LVLMs have made and will continue to make a transformative impact on object detection and robotic applications in the future.",
      "tldr_zh": "è¯¥ç»¼è¿°æ·±å…¥æ¢è®¨äº†å¤šæ¨¡æ€å¤§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨ç›®æ ‡æ£€æµ‹ï¼ˆObject Detectionï¼‰é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œç³»ç»Ÿæ€»ç»“äº†å…¶å¦‚ä½•é€šè¿‡èåˆè¯­è¨€ä¸è§†è§‰ä¿¡æ¯æ¥æå‡æ·±åº¦å­¦ä¹ ç³»ç»Ÿçš„é€‚åº”æ€§å’Œä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›ã€‚æ–‡ç« è¯¦ç»†é˜è¿°äº†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å·¥ä½œæœºåˆ¶ï¼Œè§£é‡Šäº†è¿™äº›æ¨¡å‹åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œè®¡ç®—æœºè§†è§‰ï¼ˆCVï¼‰æŠ€æœ¯å®ç°ç‰©ä½“å®šä½ä¸è¯†åˆ«çš„åˆ›æ–°æ–¹å¼ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†è¿‘æœŸ LVLMs çš„æ¶æ„åˆ›æ–°ã€è®­ç»ƒèŒƒå¼ï¼ˆTraining Paradigmsï¼‰ä»¥åŠè¾“å‡ºçµæ´»æ€§ï¼Œå±•ç¤ºäº†å›¾æ–‡ä¿¡æ¯é›†æˆåœ¨æå‡å¤æ‚åœºæ™¯ç†è§£æ–¹é¢çš„æ˜¾è‘—è¿›æ­¥ã€‚é€šè¿‡å°† LVLMs ä¸ä¼ ç»Ÿæ·±åº¦å­¦ä¹ ç³»ç»Ÿåœ¨å®æ—¶æ€§èƒ½ã€å¤æ‚åº¦å’Œå¤šåœºæ™¯é€‚åº”æ€§æ–¹é¢è¿›è¡Œå¯¹æ¯”ï¼Œæ–‡ç« æŒ‡å‡º LVLMs åœ¨å®šä½ä¸åˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶é¢„è§å…¶æ€§èƒ½å°†å¾ˆå¿«è¶…è¶Šä¼ ç»Ÿæ–¹æ³•ã€‚æœ€åï¼Œè¯¥è®ºæ–‡è¯†åˆ«äº†å½“å‰ LVLM æ¨¡å‹çš„å…³é”®å±€é™æ€§å¹¶æå‡ºäº†ç›¸åº”è§£å†³æ–¹æ¡ˆï¼Œä¸ºæœªæ¥åœ¨æœºå™¨äººåº”ç”¨ç­‰é¢†åŸŸçš„è½¬å‹æ€§å½±å“æç»˜äº†æ¸…æ™°çš„æŠ€æœ¯è·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "First Peer Reviewed Review Paper for Object Detection with Vision-Language Models (VLMs)",
      "pdf_url": "https://arxiv.org/pdf/2508.19294v2",
      "published_date": "2025-08-25 17:21:00 UTC",
      "updated_date": "2025-09-30 07:34:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:56:56.660498+00:00"
    },
    {
      "arxiv_id": "2508.18210v1",
      "title": "Why Synthetic Isn't Real Yet: A Diagnostic Framework for Contact Center Dialogue Generation",
      "title_zh": "åˆæˆå¯¹è¯ä¸ºä½•å°šéçœŸå®ï¼šå‘¼å«ä¸­å¿ƒå¯¹è¯ç”Ÿæˆçš„è¯Šæ–­æ¡†æ¶",
      "authors": [
        "Rishikesh Devanathan",
        "Varun Nathan",
        "Ayush Kumar"
      ],
      "abstract": "Synthetic transcript generation is critical in contact center domains, where privacy and data scarcity limit model training and evaluation. Unlike prior synthetic dialogue generation work on open-domain or medical dialogues, contact center conversations are goal-oriented, role-asymmetric, and behaviorally complex, featuring disfluencies, ASR noise, and compliance-driven agent actions. In deployments where transcripts are unavailable, standard pipelines still yield derived call attributes such as Intent Summaries, Topic Flow, and QA Evaluation Forms. We leverage these as supervision signals to guide generation. To assess the quality of such outputs, we introduce a diagnostic framework of 18 linguistically and behaviorally grounded metrics for comparing real and synthetic transcripts. We benchmark four language-agnostic generation strategies, from simple prompting to characteristic-aware multi-stage approaches, alongside reference-free baselines. Results reveal persistent challenges: no method excels across all traits, with notable deficits in disfluency, sentiment, and behavioral realism. Our diagnostic tool exposes these gaps, enabling fine-grained evaluation and stress testing of synthetic dialogue across languages.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å‘¼å«ä¸­å¿ƒ(Contact Center)é¢†åŸŸä¸­åˆæˆè½¬å½•æ–‡æœ¬ç”Ÿæˆçš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºç”±äºéšç§å’Œæ•°æ®ç¨€ç¼ºï¼Œç°æœ‰çš„åˆæˆå¯¹è¯ç”Ÿæˆåœ¨å¤„ç†å…·æœ‰ç›®æ ‡å¯¼å‘ã€è§’è‰²ä¸å¯¹ç§°åŠè¡Œä¸ºå¤æ‚æ€§çš„å¯¹è¯æ—¶ä»é¢ä¸´å›°éš¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨æ„å›¾æ‘˜è¦(Intent Summaries)ã€ä¸»é¢˜æµ(Topic Flow)å’Œè´¨é‡è¯„ä¼°è¡¨(QA Evaluation Forms)ä½œä¸ºç›‘ç£ä¿¡å·æ¥æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚ä½œè€…å¼•å…¥äº†ä¸€ä¸ªåŒ…å«18é¡¹è¯­è¨€å’Œè¡Œä¸ºæŒ‡æ ‡çš„è¯Šæ–­æ¡†æ¶(Diagnostic Framework)ï¼Œç”¨äºå¯¹æ¯”çœŸå®ä¸åˆæˆè½¬å½•æ–‡æœ¬çš„è´¨é‡ã€‚è¯¥ç ”ç©¶å¯¹ä»ç®€å•æç¤ºåˆ°å…·æœ‰ç‰¹å¾æ„ŸçŸ¥èƒ½åŠ›çš„å¤šé˜¶æ®µæ–¹æ³•ç­‰å››ç§ç”Ÿæˆç­–ç•¥è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›®å‰å°šæ— ä»»ä½•æ–¹æ³•èƒ½åœ¨æ‰€æœ‰ç‰¹å¾ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸æµåˆ©æ€§(Disfluency)ã€æƒ…æ„Ÿ(Sentiment)å’Œè¡Œä¸ºç°å®æ„Ÿ(Behavioral Realism)æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®è·ã€‚è¯¥è¯Šæ–­å·¥å…·æ­ç¤ºäº†è¿™äº›æŠ€æœ¯ç¼ºå£ï¼Œä¸ºå¤šè¯­è¨€åˆæˆå¯¹è¯çš„ç»†ç²’åº¦è¯„ä¼°å’Œå‹åŠ›æµ‹è¯•æä¾›äº†æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18210v1",
      "published_date": "2025-08-25 17:10:36 UTC",
      "updated_date": "2025-08-25 17:10:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:12.983922+00:00"
    },
    {
      "arxiv_id": "2508.18192v1",
      "title": "Unraveling the cognitive patterns of Large Language Models through module communities",
      "title_zh": "é€šè¿‡æ¨¡å—ç¤¾å›¢æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥æ¨¡å¼",
      "authors": [
        "Kushal Raj Bhandari",
        "Pin-Yu Chen",
        "Jianxi Gao"
      ],
      "abstract": "Large Language Models (LLMs) have reshaped our world with significant advancements in science, engineering, and society through applications ranging from scientific discoveries and medical diagnostics to Chatbots. Despite their ubiquity and utility, the underlying mechanisms of LLM remain concealed within billions of parameters and complex structures, making their inner architecture and cognitive processes challenging to comprehend. We address this gap by adopting approaches to understanding emerging cognition in biology and developing a network-based framework that links cognitive skills, LLM architectures, and datasets, ushering in a paradigm shift in foundation model analysis. The skill distribution in the module communities demonstrates that while LLMs do not strictly parallel the focalized specialization observed in specific biological systems, they exhibit unique communities of modules whose emergent skill patterns partially mirror the distributed yet interconnected cognitive organization seen in avian and small mammalian brains. Our numerical results highlight a key divergence from biological systems to LLMs, where skill acquisition benefits substantially from dynamic, cross-regional interactions and neural plasticity. By integrating cognitive science principles with machine learning, our framework provides new insights into LLM interpretability and suggests that effective fine-tuning strategies should leverage distributed learning dynamics rather than rigid modular interventions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å†…éƒ¨æœºåˆ¶éš¾ä»¥ç†è§£çš„é—®é¢˜ï¼Œå€Ÿé‰´ç”Ÿç‰©è®¤çŸ¥ç§‘å­¦ï¼Œå¼€å‘äº†ä¸€ä¸ªå°†è®¤çŸ¥æŠ€èƒ½ã€LLMæ¶æ„ä¸æ•°æ®é›†ç›¸å…³è”çš„ç³»ç»Ÿæ€§ç½‘ç»œæ¡†æ¶ã€‚ç ”ç©¶å‘ç°ï¼ŒLLMsåœ¨æ¨¡å—ç¤¾åŒº(module communities)ä¸­çš„æŠ€èƒ½åˆ†å¸ƒå¹¶æœªå®Œå…¨è¡¨ç°å‡ºç”Ÿç‰©ç³»ç»Ÿé‚£æ ·çš„ç‰¹å®šä¸“ä¸šåŒ–ï¼Œè€Œæ˜¯å±•ç°å‡ºä¸€ç§ç±»ä¼¼äºé¸Ÿç±»å’Œå°å‹å“ºä¹³åŠ¨ç‰©å¤§è„‘çš„åˆ†å¸ƒå¼ä¸”äº’è¿çš„è®¤çŸ¥ç»„ç»‡ã€‚æ•°å€¼ç»“æœæ˜¾ç¤ºï¼ŒLLMsçš„æŠ€èƒ½è·å–æå¤§åœ°å—ç›ŠäºåŠ¨æ€çš„è·¨åŒºåŸŸäº¤äº’(cross-regional interactions)å’Œç¥ç»å¯å¡‘æ€§(neural plasticity)ï¼Œè¿™ä¸ç”Ÿç‰©ç³»ç»Ÿå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆè®¤çŸ¥ç§‘å­¦ä¸æœºå™¨å­¦ä¹ ï¼Œä¸ºæå‡æ¨¡å‹å¯è§£é‡Šæ€§æä¾›äº†æ–°è·¯å¾„ï¼Œå¹¶æŒ‡å‡ºæœ‰æ•ˆçš„å¾®è°ƒ(fine-tuning)ç­–ç•¥åº”ä¾§é‡äºåˆ©ç”¨åˆ†å¸ƒå¼å­¦ä¹ åŠ¨æ€(distributed learning dynamics)ï¼Œè€Œéå±€é™äºåƒµç¡¬çš„æ¨¡å—åŒ–å¹²é¢„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18192v1",
      "published_date": "2025-08-25 16:49:38 UTC",
      "updated_date": "2025-08-25 16:49:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:11.150376+00:00"
    },
    {
      "arxiv_id": "2508.18190v3",
      "title": "ST-Raptor: LLM-Powered Semi-Structured Table Question Answering",
      "title_zh": "ST-Raptorï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åŠç»“æ„åŒ–è¡¨æ ¼é—®ç­”",
      "authors": [
        "Zirui Tang",
        "Boyu Niu",
        "Xuanhe Zhou",
        "Boxiu Li",
        "Wei Zhou",
        "Jiannan Wang",
        "Guoliang Li",
        "Xinyi Zhang",
        "Fan Wu"
      ],
      "abstract": "Semi-structured tables, widely used in real-world applications (e.g., financial reports, medical records, transactional orders), often involve flexible and complex layouts (e.g., hierarchical headers and merged cells). These tables generally rely on human analysts to interpret table layouts and answer relevant natural language questions, which is costly and inefficient. To automate the procedure, existing methods face significant challenges. First, methods like NL2SQL require converting semi-structured tables into structured ones, which often causes substantial information loss. Second, methods like NL2Code and multi-modal LLM QA struggle to understand the complex layouts of semi-structured tables and cannot accurately answer corresponding questions. To this end, we propose ST-Raptor, a tree-based framework for semi-structured table question answering using large language models. First, we introduce the Hierarchical Orthogonal Tree (HO-Tree), a structural model that captures complex semi-structured table layouts, along with an effective algorithm for constructing the tree. Second, we define a set of basic tree operations to guide LLMs in executing common QA tasks. Given a user question, ST-Raptor decomposes it into simpler sub-questions, generates corresponding tree operation pipelines, and conducts operation-table alignment for accurate pipeline execution. Third, we incorporate a two-stage verification mechanism: forward validation checks the correctness of execution steps, while backward validation evaluates answer reliability by reconstructing queries from predicted answers. To benchmark the performance, we present SSTQA, a dataset of 764 questions over 102 real-world semi-structured tables. Experiments show that ST-Raptor outperforms nine baselines by up to 20% in answer accuracy. The code is available at https://github.com/weAIDB/ST-Raptor.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡‘èæŠ¥å‘Šã€åŒ»ç–—è®°å½•ç­‰é¢†åŸŸä¸­å…·æœ‰å¤æ‚å¸ƒå±€ï¼ˆå¦‚åˆ†å±‚è¡¨å¤´å’Œåˆå¹¶å•å…ƒæ ¼ï¼‰çš„åŠç»“æ„åŒ–è¡¨æ ¼ï¼Œæå‡ºäº†åä¸º ST-Raptor çš„æ ‘çŠ¶å¤§è¯­è¨€æ¨¡å‹ (LLMs) é—®ç­”æ¡†æ¶ã€‚ä¸ºäº†è§£å†³ç°æœ‰ NL2SQL æ–¹æ³•å¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±ä»¥åŠ NL2Code å¯¹å¤æ‚å¸ƒå±€ç†è§£ä¸è¶³çš„é—®é¢˜ï¼ŒST-Raptor å¼•å…¥äº†å±‚çº§æ­£äº¤æ ‘ (HO-Tree) æ¨¡å‹æ¥ç²¾ç¡®æ•æ‰è¡¨æ ¼ç»“æ„ï¼Œå¹¶å®šä¹‰äº†ä¸€ç³»åˆ—åŸºç¡€æ ‘æ“ä½œæ¥æŒ‡å¯¼ LLMs æ‰§è¡Œé—®ç­”ä»»åŠ¡ã€‚è¯¥æ¡†æ¶å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜å¹¶ç”Ÿæˆæ“ä½œæµæ°´çº¿ï¼ŒåŒæ—¶ç»“åˆäº†å‰å‘æ ¡éªŒæ‰§è¡Œæ­¥éª¤å’Œåå‘æ ¡éªŒç­”æ¡ˆå¯é æ€§çš„ä¸¤é˜¶æ®µéªŒè¯æœºåˆ¶ï¼Œä»¥ç¡®ä¿é—®ç­”çš„å‡†ç¡®æ€§ã€‚ç ”ç©¶è€…è¿˜åŒæ­¥æ¨å‡ºäº†åŒ…å« 764 ä¸ªé—®é¢˜å’Œ 102 å¼ çœŸå®è¡¨æ ¼çš„ SSTQA åŸºå‡†æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒST-Raptor åœ¨ç­”æ¡ˆå‡†ç¡®ç‡ä¸Šæ¯” 9 ç§åŸºçº¿æ¨¡å‹æå‡äº†é«˜è¾¾ 20%ï¼Œä¸ºè‡ªåŠ¨åŒ–å¤„ç†å¤æ‚åŠç»“æ„åŒ–è¡¨æ ¼æä¾›äº†é«˜æ•ˆä¸”å¯é çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Extension of our SIGMOD 2026 paper. Please refer to source code available at: https://github.com/weAIDB/ST-Raptor",
      "pdf_url": "https://arxiv.org/pdf/2508.18190v3",
      "published_date": "2025-08-25 16:48:51 UTC",
      "updated_date": "2025-09-02 02:30:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:26.460006+00:00"
    },
    {
      "arxiv_id": "2508.18188v1",
      "title": "Explain and Monitor Deep Learning Models for Computer Vision using Obz AI",
      "title_zh": "åˆ©ç”¨ Obz AI è§£é‡Šä¸ç›‘æµ‹è®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Neo Christopher Chung",
        "Jakub Binda"
      ],
      "abstract": "Deep learning has transformed computer vision (CV), achieving outstanding performance in classification, segmentation, and related tasks. Such AI-based CV systems are becoming prevalent, with applications spanning from medical imaging to surveillance. State of the art models such as convolutional neural networks (CNNs) and vision transformers (ViTs) are often regarded as ``black boxes,'' offering limited transparency into their decision-making processes. Despite a recent advancement in explainable AI (XAI), explainability remains underutilized in practical CV deployments. A primary obstacle is the absence of integrated software solutions that connect XAI techniques with robust knowledge management and monitoring frameworks. To close this gap, we have developed Obz AI, a comprehensive software ecosystem designed to facilitate state-of-the-art explainability and observability for vision AI systems. Obz AI provides a seamless integration pipeline, from a Python client library to a full-stack analytics dashboard. With Obz AI, a machine learning engineer can easily incorporate advanced XAI methodologies, extract and analyze features for outlier detection, and continuously monitor AI models in real time. By making the decision-making mechanisms of deep models interpretable, Obz AI promotes observability and responsible deployment of computer vision systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ Computer Vision é¢†åŸŸå› â€œé»‘ç›’â€ç‰¹æ€§å¯¼è‡´é€æ˜åº¦ä¸è¶³ï¼Œä»¥åŠ XAI æŠ€æœ¯åœ¨å®é™…éƒ¨ç½²ä¸­ç¼ºä¹é›†æˆè½¯ä»¶æ–¹æ¡ˆçš„é—®é¢˜ï¼Œå¼€å‘äº†åä¸º Obz AI çš„ç»¼åˆè½¯ä»¶ç”Ÿæ€ç³»ç»Ÿã€‚Obz AI æä¾›äº†ä» Python å®¢æˆ·ç«¯åº“åˆ°å…¨æ ˆåˆ†æä»ªè¡¨æ¿çš„æ— ç¼é›†æˆç®¡çº¿ï¼Œæ—¨åœ¨æå‡è§†è§‰ AI ç³»ç»Ÿçš„å¯è§£é‡Šæ€§ï¼ˆExplainabilityï¼‰ä¸å¯è§‚å¯Ÿæ€§ï¼ˆObservabilityï¼‰ã€‚æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå¯ä»¥åˆ©ç”¨è¯¥å·¥å…·è½»æ¾é›†æˆå…ˆè¿›çš„ XAI æ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾æå–è¿›è¡Œç¦»ç¾¤å€¼æ£€æµ‹ï¼ˆOutlier Detectionï¼‰ï¼Œå¹¶å¯¹æ¨¡å‹è¿›è¡Œå®æ—¶ç›‘æ§ã€‚é€šè¿‡ä½¿æ·±åº¦æ¨¡å‹çš„å†³ç­–æœºåˆ¶å˜å¾—å¯è§£é‡Šï¼ŒObz AI æœ‰æ•ˆä¿ƒè¿›äº† AI ç³»ç»Ÿçš„é€æ˜åº¦ä¸è´Ÿè´£ä»»éƒ¨ç½²ã€‚è¯¥ç”Ÿæ€ç³»ç»Ÿçš„å»ºç«‹å¡«è¡¥äº† XAI æŠ€æœ¯ä¸ç¨³å¥çŸ¥è¯†ç®¡ç†åŠç›‘æ§æ¡†æ¶ä¹‹é—´çš„ç©ºç™½ï¼Œä¸ºå·¥ä¸šç•Œæä¾›äº†å®ç”¨çš„è§†è§‰ AI æ²»ç†æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18188v1",
      "published_date": "2025-08-25 16:46:21 UTC",
      "updated_date": "2025-08-25 16:46:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:14.757135+00:00"
    },
    {
      "arxiv_id": "2508.18187v1",
      "title": "BRAIN: Bias-Mitigation Continual Learning Approach to Vision-Brain Understanding",
      "title_zh": "BRAINï¼šé¢å‘è§†è§‰-å¤§è„‘ç†è§£çš„åå·®ç¼“è§£æŒç»­å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Xuan-Bac Nguyen",
        "Thanh-Dat Truong",
        "Pawan Sinha",
        "Khoa Luu"
      ],
      "abstract": "Memory decay makes it harder for the human brain to recognize visual objects and retain details. Consequently, recorded brain signals become weaker, uncertain, and contain poor visual context over time. This paper presents one of the first vision-learning approaches to address this problem. First, we statistically and experimentally demonstrate the existence of inconsistency in brain signals and its impact on the Vision-Brain Understanding (VBU) model. Our findings show that brain signal representations shift over recording sessions, leading to compounding bias, which poses challenges for model learning and degrades performance. Then, we propose a new Bias-Mitigation Continual Learning (BRAIN) approach to address these limitations. In this approach, the model is trained in a continual learning setup and mitigates the growing bias from each learning step. A new loss function named De-bias Contrastive Learning is also introduced to address the bias problem. In addition, to prevent catastrophic forgetting, where the model loses knowledge from previous sessions, the new Angular-based Forgetting Mitigation approach is introduced to preserve learned knowledge in the model. Finally, the empirical experiments demonstrate that our approach achieves State-of-the-Art (SOTA) performance across various benchmarks, surpassing prior and non-continual learning methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººç±»è®°å¿†è¡°å‡å¯¼è‡´è„‘ä¿¡å·åœ¨ä¸åŒè®°å½•é˜¶æ®µå‡ºç°ä¸ä¸€è‡´æ€§åŠç´¯ç§¯åå·®(compounding bias)çš„é—®é¢˜ï¼Œæå‡ºäº†BRAINæ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§ä¸“ä¸ºè§†è§‰-å¤§è„‘ç†è§£(Vision-Brain Understanding)è®¾è®¡çš„åç½®ç¼“è§£æŒç»­å­¦ä¹ (Bias-Mitigation Continual Learning)æ–¹æ³•ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å»åç½®å¯¹æ¯”å­¦ä¹ (De-bias Contrastive Learning)æŸå¤±å‡½æ•°ï¼Œç”¨ä»¥è§£å†³æ¨¡å‹åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ä¸æ–­å¢é•¿çš„åç½®é—®é¢˜ã€‚åŒæ—¶ï¼Œä¸ºäº†åº”å¯¹ç¾éš¾æ€§é—å¿˜(catastrophic forgetting)ï¼Œç ”ç©¶è€…æå‡ºäº†åŸºäºè§’åº¦çš„é—å¿˜ç¼“è§£(Angular-based Forgetting Mitigation)æŠ€æœ¯ä»¥ä¿ç•™å·²å­¦çŸ¥è¯†ã€‚ç»Ÿè®¡ä¸å®éªŒåˆ†æè¡¨æ˜ï¼Œè„‘ä¿¡å·è¡¨å¾çš„åç§»ä¼šä¸¥é‡å½±å“æ¨¡å‹æ€§èƒ½ï¼Œè€ŒBRAINèƒ½æœ‰æ•ˆå…‹æœè¿™äº›æŒ‘æˆ˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›(State-of-the-Art)çš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºå…ˆå‰çš„æŒç»­å­¦ä¹ åŠéæŒç»­å­¦ä¹ æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18187v1",
      "published_date": "2025-08-25 16:44:43 UTC",
      "updated_date": "2025-08-25 16:44:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:27.265757+00:00"
    },
    {
      "arxiv_id": "2508.18183v2",
      "title": "Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios",
      "title_zh": "å€ŸåŠ©å¤§è¯­è¨€æ¨¡å‹å®ç°ä½èµ„æºåœºæ™¯ä¸‹çš„ç²¾ç¡®æ‰‹è¯­ç¿»è¯‘",
      "authors": [
        "Luana Bulla",
        "Gabriele Tuccio",
        "Misael MongiovÃ¬",
        "Aldo Gangemi"
      ],
      "abstract": "Translating natural languages into sign languages is a highly complex and underexplored task. Despite growing interest in accessibility and inclusivity, the development of robust translation systems remains hindered by the limited availability of parallel corpora which align natural language with sign language data. Existing methods often struggle to generalize in these data-scarce environments, as the few datasets available are typically domain-specific, lack standardization, or fail to capture the full linguistic richness of sign languages. To address this limitation, we propose Advanced Use of LLMs for Sign Language Translation (AulSign), a novel method that leverages Large Language Models via dynamic prompting and in-context learning with sample selection and subsequent sign association. Despite their impressive abilities in processing text, LLMs lack intrinsic knowledge of sign languages; therefore, they are unable to natively perform this kind of translation. To overcome this limitation, we associate the signs with compact descriptions in natural language and instruct the model to use them. We evaluate our method on both English and Italian languages using SignBank+, a recognized benchmark in the field, as well as the Italian LaCAM CNR-ISTC dataset. We demonstrate superior performance compared to state-of-the-art models in low-data scenario. Our findings demonstrate the effectiveness of AulSign, with the potential to enhance accessibility and inclusivity in communication technologies for underrepresented linguistic communities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AulSignï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰åœ¨ä½èµ„æºåœºæ™¯ä¸‹å®ç°å‡†ç¡®æ‰‹è¯­ç¿»è¯‘çš„æ–°æ–¹æ³•ã€‚é’ˆå¯¹æ‰‹è¯­å¹³è¡Œè¯­æ–™åº“åŒ®ä¹å¯¼è‡´ç°æœ‰ç³»ç»Ÿæ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜ï¼ŒAulSigné€šè¿‡åŠ¨æ€æç¤ºï¼ˆDynamic promptingï¼‰å’Œç»“åˆæ ·æœ¬é€‰æ‹©çš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆIn-context learningï¼‰æ¥å¢å¼ºæ¨¡å‹æ€§èƒ½ã€‚ä¸ºäº†å…‹æœLLMsç¼ºä¹åŸç”Ÿæ‰‹è¯­çŸ¥è¯†çš„å±€é™ï¼Œè¯¥æ–¹æ³•å°†æ‰‹è¯­ä¿¡å·ä¸ç´§å‡‘çš„è‡ªç„¶è¯­è¨€æè¿°ç›¸å…³è”ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹å®Œæˆç¿»è¯‘ä»»åŠ¡ã€‚ç ”ç©¶åœ¨è‹±è¯­æ•°æ®é›†SignBank+å’Œæ„å¤§åˆ©è¯­æ•°æ®é›†LaCAM CNR-ISTCä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œç»“æœè¯æ˜AulSignåœ¨ä½æ•°æ®é‡åœºæ™¯ä¸‹çš„è¡¨ç°ä¼˜äºç°æœ‰çš„å…ˆè¿›æ¨¡å‹ã€‚è¯¥å‘ç°è¯å®äº†åˆ©ç”¨LLMsæå‡æ‰‹è¯­ç¿»è¯‘å‡†ç¡®æ€§çš„æœ‰æ•ˆæ€§ï¼Œä¸ºä¿ƒè¿›ä»£è¡¨æ€§ä¸è¶³è¯­è¨€ç¤¾åŒºçš„æ²Ÿé€šæ— éšœç¢å’ŒåŒ…å®¹æ€§æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18183v2",
      "published_date": "2025-08-25 16:36:36 UTC",
      "updated_date": "2025-09-08 14:25:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:29.854258+00:00"
    },
    {
      "arxiv_id": "2508.18182v1",
      "title": "AdLoCo: adaptive batching significantly improves communications efficiency and convergence for Large Language Models",
      "title_zh": "AdLoCoï¼šè‡ªé€‚åº”æ‰¹å¤„ç†æ˜¾è‘—æå‡å¤§è¯­è¨€æ¨¡å‹çš„é€šä¿¡æ•ˆç‡ä¸æ”¶æ•›æ€§",
      "authors": [
        "Nikolay Kutuzov",
        "Makar Baderko",
        "Stepan Kulibaba",
        "Artem Dzhalilov",
        "Daniel Bobrov",
        "Maxim Mashtaler",
        "Alexander Gasnikov"
      ],
      "abstract": "Scaling distributed training of Large Language Models (LLMs) requires not only algorithmic advances but also efficient utilization of heterogeneous hardware resources. While existing methods such as DiLoCo have demonstrated promising results, they often fail to fully exploit computational clusters under dynamic workloads. To address this limitation, we propose a three-stage method that combines Multi-Instance Training (MIT), Adaptive Batched DiLoCo, and switch mode mechanism. MIT allows individual nodes to run multiple lightweight training streams with different model instances in parallel and merge them to combine knowledge, increasing throughput and reducing idle time. Adaptive Batched DiLoCo dynamically adjusts local batch sizes to balance computation and communication, substantially lowering synchronization delays. Switch mode further stabilizes training by seamlessly introducing gradient accumulation once adaptive batch sizes grow beyond hardware-friendly limits. Together, these innovations improve both convergence speed and system efficiency. We also provide a theoretical estimate of the number of communications required for the full convergence of a model trained using our method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹(LLMs)åˆ†å¸ƒå¼è®­ç»ƒä¸­å¼‚æ„ç¡¬ä»¶èµ„æºåˆ©ç”¨ç‡ä½çš„é—®é¢˜ï¼Œæå‡ºäº†AdLoCoæ–¹æ³•ï¼Œæ—¨åœ¨æå‡é€šä¿¡æ•ˆç‡ä¸æ”¶æ•›æ€§èƒ½ã€‚è¯¥æ–¹æ³•åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µï¼šé¦–å…ˆé€šè¿‡å¤šå®ä¾‹è®­ç»ƒ(Multi-Instance Training, MIT)åœ¨å•èŠ‚ç‚¹å¹¶è¡Œè¿è¡Œå¤šä¸ªè½»é‡çº§è®­ç»ƒæµä»¥æé«˜ååé‡ï¼›å…¶æ¬¡ï¼Œé‡‡ç”¨è‡ªé€‚åº”æ‰¹å¤„ç†DiLoCoåŠ¨æ€è°ƒæ•´å±€éƒ¨æ‰¹å¤§å°(local batch sizes)ï¼Œæœ‰æ•ˆå¹³è¡¡è®¡ç®—ä¸é€šä¿¡å¹¶é™ä½åŒæ­¥å»¶è¿Ÿã€‚æ­¤å¤–ï¼ŒAdLoCoå¼•å…¥äº†åˆ‡æ¢æ¨¡å¼æœºåˆ¶ï¼Œé€šè¿‡åœ¨æ‰¹å¤§å°è¶…å‡ºç¡¬ä»¶é™åˆ¶æ—¶æ— ç¼å¼•å…¥æ¢¯åº¦ç´¯ç§¯æ¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›åˆ›æ–°æ˜¾è‘—æå‡äº†æ”¶æ•›é€Ÿåº¦å’Œç³»ç»Ÿæ•´ä½“æ•ˆç‡ã€‚ç ”ç©¶æœ€åè¿˜ä¸ºè¯¥æ–¹æ³•ä¸‹æ¨¡å‹å®Œå…¨æ”¶æ•›æ‰€éœ€çš„é€šä¿¡æ¬¡æ•°æä¾›äº†ç†è®ºä¼°ç®—ï¼Œä¸ºåŠ¨æ€è´Ÿè½½ä¸‹çš„é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒæä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18182v1",
      "published_date": "2025-08-25 16:35:57 UTC",
      "updated_date": "2025-08-25 16:35:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:27.853118+00:00"
    },
    {
      "arxiv_id": "2508.18179v1",
      "title": "SEAM: Semantically Equivalent Across Modalities Benchmark for Vision-Language Models",
      "title_zh": "SEAMï¼šè§†è§‰è¯­è¨€æ¨¡å‹çš„è·¨æ¨¡æ€è¯­ä¹‰ç­‰ä»·è¯„æµ‹åŸºå‡†",
      "authors": [
        "Zhenwei Tang",
        "Difan Jiao",
        "Blair Yang",
        "Ashton Anderson"
      ],
      "abstract": "Evaluating whether vision-language models (VLMs) reason consistently across representations is challenging because modality comparisons are typically confounded by task differences and asymmetric information. We introduce SEAM, a benchmark that pairs semantically equivalent inputs across four domains that have existing standardized textual and visual notations. By employing distinct notation systems across modalities, in contrast to OCR-based image-text pairing, SEAM provides a rigorous comparative assessment of the textual-symbolic and visual-spatial reasoning capabilities of VLMs. Across 21 contemporary models, we observe systematic modality imbalance: vision frequently lags language in overall performance, despite the problems containing semantically equivalent information, and cross-modal agreement is relatively low. Our error analysis reveals two main drivers: textual perception failures from tokenization in domain notation and visual perception failures that induce hallucinations. We also show that our results are largely robust to visual transformations. SEAM establishes a controlled, semantically equivalent setting for measuring and improving modality-agnostic reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† SEAMï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹ (Vision-Language Models, VLMs) çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€è¡¨ç¤ºä¸‹çš„æ¨ç†ä¸€è‡´æ€§ã€‚SEAM é€šè¿‡åœ¨å››ä¸ªå…·æœ‰æ ‡å‡†æ–‡æœ¬å’Œè§†è§‰ç¬¦å·ç³»ç»Ÿçš„é¢†åŸŸä¸­é…å¯¹è¯­ä¹‰ç­‰æ•ˆ (semantically equivalent) çš„è¾“å…¥ï¼Œå¯¹æ¨¡å‹çš„æ–‡æœ¬ç¬¦å·æ¨ç† (textual-symbolic reasoning) å’Œè§†è§‰ç©ºé—´æ¨ç† (visual-spatial reasoning) èƒ½åŠ›è¿›è¡Œä¸¥æ ¼çš„æ¯”è¾ƒè¯„ä¼°ã€‚åœ¨å¯¹ 21 ç§å½“ä»£æ¨¡å‹çš„æµ‹è¯•ä¸­ï¼Œç ”ç©¶è§‚å¯Ÿåˆ°æ˜¾è‘—çš„æ¨¡æ€ä¸å¹³è¡¡ï¼Œå³è§†è§‰æ¨¡æ€çš„è¡¨ç°é€šå¸¸è½åäºè¯­è¨€æ¨¡æ€ï¼Œä¸”è·¨æ¨¡æ€çš„ä¸€è‡´æ€§ (cross-modal agreement) è¾ƒä½ã€‚é”™è¯¯åˆ†ææ­ç¤ºäº†æ–‡æœ¬ç«¯å— tokenization å½±å“çš„æ„ŸçŸ¥å¤±è´¥å’Œè§†è§‰ç«¯å¯¼è‡´å¹»è§‰çš„æ„ŸçŸ¥å¤±è´¥æ˜¯ä¸»è¦è¯±å› ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ºè¡¡é‡å’Œæ”¹è¿›æ¨¡æ€æ— å…³æ¨ç† (modality-agnostic reasoning) æä¾›äº†ä¸€ä¸ªå—æ§çš„è¯­ä¹‰ç­‰æ•ˆè¯„ä¼°ç¯å¢ƒï¼Œä¸”å…¶å®éªŒç»“æœåœ¨è§†è§‰å˜æ¢ä¸‹è¡¨ç°å‡ºè¾ƒå¼ºçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.18179v1",
      "published_date": "2025-08-25 16:33:07 UTC",
      "updated_date": "2025-08-25 16:33:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:57:39.963106+00:00"
    },
    {
      "arxiv_id": "2508.18175v3",
      "title": "Amortized Sampling with Transferable Normalizing Flows",
      "title_zh": "åŸºäºå¯è¿ç§»å½’ä¸€åŒ–æµçš„æ‘Šé”€é‡‡æ ·",
      "authors": [
        "Charlie B. Tan",
        "Majdi Hassan",
        "Leon Klein",
        "Saifuddin Syed",
        "Dominique Beaini",
        "Michael M. Bronstein",
        "Alexander Tong",
        "Kirill Neklyudov"
      ],
      "abstract": "Efficient equilibrium sampling of molecular conformations remains a core challenge in computational chemistry and statistical inference. Classical approaches such as molecular dynamics or Markov chain Monte Carlo inherently lack amortization; the computational cost of sampling must be paid in full for each system of interest. The widespread success of generative models has inspired interest towards overcoming this limitation through learning sampling algorithms. Despite performing competitively with conventional methods when trained on a single system, learned samplers have so far demonstrated limited ability to transfer across systems. We demonstrate that deep learning enables the design of scalable and transferable samplers by introducing Prose, a 285 million parameter all-atom transferable normalizing flow trained on a corpus of peptide molecular dynamics trajectories up to 8 residues in length. Prose draws zero-shot uncorrelated proposal samples for arbitrary peptide systems, achieving the previously intractable transferability across sequence length, whilst retaining the efficient likelihood evaluation of normalizing flows. Through extensive empirical evaluation we demonstrate the efficacy of Prose as a proposal for a variety of sampling algorithms, finding a simple importance sampling-based finetuning procedure to achieve competitive performance to established methods such as sequential Monte Carlo. We open-source the Prose codebase, model weights, and training dataset, to further stimulate research into amortized sampling methods and finetuning objectives.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ†å­æ„è±¡å¹³è¡¡é‡‡æ ·ä¸­ç»å…¸æ–¹æ³•ç¼ºä¹æ‘Šé”€(Amortization)å¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º Prose çš„ 2.85 äº¿å‚æ•°å…¨åŸå­å¯è¿ç§» Normalizing Flows æ¨¡å‹ã€‚Prose åœ¨é•¿è¾¾ 8 ä¸ªæ®‹åŸºçš„è‚½é“¾åˆ†å­åŠ¨åŠ›å­¦è½¨è¿¹è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿä¸ºä»»æ„è‚½é“¾ç³»ç»Ÿæå–é›¶æ ·æœ¬(Zero-shot)ä¸”äº’ä¸ç›¸å…³çš„å»ºè®®æ ·æœ¬ã€‚è¯¥æ¨¡å‹é¦–æ¬¡å®ç°äº†æ­¤å‰éš¾ä»¥è¾¾æˆçš„è·¨åºåˆ—é•¿åº¦çš„å¯è¿ç§»æ€§ï¼ŒåŒæ—¶ä¿ç•™äº† Normalizing Flows é«˜æ•ˆçš„ä¼¼ç„¶è¯„ä¼°ç‰¹æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒProse å¯ä½œä¸ºå¤šç§é‡‡æ ·ç®—æ³•çš„é«˜æ•ˆå»ºè®®åˆ†å¸ƒï¼Œé€šè¿‡ç®€å•çš„ Importance Sampling å¾®è°ƒå³å¯è¾¾åˆ°ä¸ Sequential Monte Carlo ç­‰æˆç†Ÿæ–¹æ³•ç›¸åª²ç¾çš„æ€§èƒ½ã€‚è¯¥ç ”ç©¶é€šè¿‡å¼€æºä»£ç ã€æ¨¡å‹æƒé‡å’Œè®­ç»ƒæ•°æ®é›†ï¼Œä¸ºæ¨åŠ¨æ‘Šé”€é‡‡æ ·æ–¹æ³•åŠå¾®è°ƒç›®æ ‡çš„ç ”ç©¶æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.18175v3",
      "published_date": "2025-08-25 16:28:18 UTC",
      "updated_date": "2026-01-16 19:33:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:03.248447+00:00"
    },
    {
      "arxiv_id": "2508.18162v1",
      "title": "The Computational Complexity of Satisfiability in State Space Models",
      "title_zh": "çŠ¶æ€ç©ºé—´æ¨¡å‹å¯æ»¡è¶³æ€§çš„è®¡ç®—å¤æ‚åº¦",
      "authors": [
        "Eric Alsmann",
        "Martin Lange"
      ],
      "abstract": "We analyse the complexity of the satisfiability problem ssmSAT for State Space Models (SSM), which asks whether an input sequence can lead the model to an accepting configuration. We find that ssmSAT is undecidable in general, reflecting the computational power of SSM. Motivated by practical settings, we identify two natural restrictions under which ssmSAT becomes decidable and establish corresponding complexity bounds. First, for SSM with bounded context length, ssmSAT is NP-complete when the input length is given in unary and in NEXPTIME (and PSPACE-hard) when the input length is given in binary. Second, for quantised SSM operating over fixed-width arithmetic, ssmSAT is PSPACE-complete resp. in EXPSPACE depending on the bit-width encoding. While these results hold for diagonal gated SSM we also establish complexity bounds for time-invariant SSM. Our results establish a first complexity landscape for formal reasoning in SSM and highlight fundamental limits and opportunities for the verification of SSM-based language models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥åˆ†æäº†çŠ¶æ€ç©ºé—´æ¨¡å‹ State Space Models (SSM) ä¸­å¯æ»¡è¶³æ€§é—®é¢˜ ssmSAT çš„è®¡ç®—å¤æ‚åº¦ï¼Œå³æ¢è®¨ç‰¹å®šè¾“å…¥åºåˆ—èƒ½å¦å¼•å¯¼æ¨¡å‹è¿›å…¥æ¥å—é…ç½®ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸€èˆ¬æƒ…å†µä¸‹çš„ ssmSAT æ˜¯ undecidable çš„ï¼Œè¿™æ­ç¤ºäº† SSM æå¼ºçš„è®¡ç®—è¡¨è¾¾èƒ½åŠ›ã€‚é’ˆå¯¹å®é™…åº”ç”¨éœ€æ±‚ï¼Œç ”ç©¶è€…ç¡®å®šäº†ä¸¤ç§ä½¿é—®é¢˜å¯åˆ¤å®šçš„è‡ªç„¶çº¦æŸæ¡ä»¶ï¼šåœ¨ bounded context length é™åˆ¶ä¸‹ï¼Œé—®é¢˜çš„å¤æ‚åº¦åœ¨ NP-complete åˆ° NEXPTIME ä¹‹é—´æ³¢åŠ¨ï¼›è€Œå¯¹äºåœ¨å›ºå®šä½å®½ç®—æœ¯ä¸‹è¿è¡Œçš„ quantised SSMï¼Œå¤æ‚åº¦åˆ™è¢«ç¡®å®šä¸º PSPACE-complete æˆ–å±äº EXPSPACEã€‚è¿™äº›ç»“è®ºä¸ä»…æ¶µç›–äº†å¯¹è§’é—¨æ§ diagonal gated SSMï¼Œè¿˜å»ºç«‹äº†å¯¹æ—¶ä¸å˜ time-invariant SSM çš„å¤æ‚åº¦ç•Œé™ã€‚è¯¥å·¥ä½œæ„å»ºäº† SSM å½¢å¼åŒ–æ¨ç†çš„é¦–ä¸ªå¤æ‚åº¦å…¨æ™¯å›¾ï¼Œå¹¶æ˜ç¡®äº†éªŒè¯åŸºäº SSM çš„è¯­è¨€æ¨¡å‹æ—¶æ‰€é¢ä¸´çš„æ ¹æœ¬ç†è®ºæé™ä¸æ½œåœ¨æœºé‡ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.CC",
        "cs.LG"
      ],
      "primary_category": "cs.LO",
      "comment": "Accepted at ECAI 25",
      "pdf_url": "https://arxiv.org/pdf/2508.18162v1",
      "published_date": "2025-08-25 16:12:47 UTC",
      "updated_date": "2025-08-25 16:12:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:06.092891+00:00"
    },
    {
      "arxiv_id": "2508.18154v1",
      "title": "Assessing the Noise Robustness of Class Activation Maps: A Framework for Reliable Model Interpretability",
      "title_zh": "è¯„ä¼°ç±»æ¿€æ´»æ˜ å°„çš„å™ªå£°é²æ£’æ€§ï¼šä¸€ç§å®ç°å¯é æ¨¡å‹å¯è§£é‡Šæ€§çš„æ¡†æ¶",
      "authors": [
        "Syamantak Sarkar",
        "Revoti P. Bora",
        "Bhupender Kaushal",
        "Sudhish N George",
        "Kiran Raja"
      ],
      "abstract": "Class Activation Maps (CAMs) are one of the important methods for visualizing regions used by deep learning models. Yet their robustness to different noise remains underexplored. In this work, we evaluate and report the resilience of various CAM methods for different noise perturbations across multiple architectures and datasets. By analyzing the influence of different noise types on CAM explanations, we assess the susceptibility to noise and the extent to which dataset characteristics may impact explanation stability. The findings highlight considerable variability in noise sensitivity for various CAMs. We propose a robustness metric for CAMs that captures two key properties: consistency and responsiveness. Consistency reflects the ability of CAMs to remain stable under input perturbations that do not alter the predicted class, while responsiveness measures the sensitivity of CAMs to changes in the prediction caused by such perturbations. The metric is evaluated empirically across models, different perturbations, and datasets along with complementary statistical tests to exemplify the applicability of our proposed approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ å¯è§†åŒ–æ–¹æ³• Class Activation Maps (CAMs) çš„é²æ£’æ€§é—®é¢˜å±•å¼€æ¢è®¨ï¼Œå¹¶è¯„ä¼°äº†å¤šç§ CAM æ–¹æ³•åœ¨ä¸åŒæ¶æ„å’Œæ•°æ®é›†ä¸‹å¯¹å™ªå£°æ‰°åŠ¨çš„å¼¹æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰çš„ CAM æ–¹æ³•åœ¨é¢å¯¹å™ªå£°æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„æ•æ„Ÿæ€§å·®å¼‚ï¼Œä¸”æ•°æ®é›†ç‰¹å¾å¯¹è§£é‡Šçš„ç¨³å®šæ€§æœ‰é‡è¦å½±å“ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªç”¨äºè¡¡é‡ CAM é²æ£’æ€§çš„æ–°æŒ‡æ ‡ï¼Œè¯¥æŒ‡æ ‡æ¶µç›–äº† Consistencyï¼ˆä¸€è‡´æ€§ï¼‰å’Œ Responsivenessï¼ˆå“åº”æ€§ï¼‰ä¸¤ä¸ªæ ¸å¿ƒç»´åº¦ã€‚Consistency è¡¡é‡ CAM åœ¨è¾“å…¥æ‰°åŠ¨ä¸æ”¹å˜é¢„æµ‹ç±»åˆ«æ—¶ä¿æŒç¨³å®šçš„èƒ½åŠ›ï¼Œè€Œ Responsiveness åˆ™åæ˜ äº†å…¶å¯¹å› æ‰°åŠ¨å¯¼è‡´é¢„æµ‹å˜åŒ–çš„æ•æ„Ÿåº¦ã€‚è¯¥æŒ‡æ ‡é€šè¿‡è·¨æ¨¡å‹å’Œæ•°æ®é›†çš„å®è¯è¯„ä¼°åŠç»Ÿè®¡æµ‹è¯•å¾—åˆ°äº†éªŒè¯ï¼Œä¸ºè¯„ä¼°æ¨¡å‹å¯è§£é‡Šæ€§çš„å¯é æ€§æä¾›äº†ä¸€ä¸ªç³»ç»Ÿæ€§æ¡†æ¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Image and Vision Computing (2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.18154v1",
      "published_date": "2025-08-25 15:59:06 UTC",
      "updated_date": "2025-08-25 15:59:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:04.157067+00:00"
    },
    {
      "arxiv_id": "2508.18148v1",
      "title": "Learning from Few Samples: A Novel Approach for High-Quality Malcode Generation",
      "title_zh": "å°‘æ ·æœ¬å­¦ä¹ ï¼šä¸€ç§é«˜è´¨é‡æ¶æ„ä»£ç ç”Ÿæˆçš„åˆ›æ–°æ–¹æ³•",
      "authors": [
        "Haijian Ma",
        "Daizong Liu",
        "Xiaowen Cai",
        "Pan Zhou",
        "Yulai Xie"
      ],
      "abstract": "Intrusion Detection Systems (IDS) play a crucial role in network security defense. However, a significant challenge for IDS in training detection models is the shortage of adequately labeled malicious samples. To address these issues, this paper introduces a novel semi-supervised framework \\textbf{GANGRL-LLM}, which integrates Generative Adversarial Networks (GANs) with Large Language Models (LLMs) to enhance malicious code generation and SQL Injection (SQLi) detection capabilities in few-sample learning scenarios. Specifically, our framework adopts a collaborative training paradigm where: (1) the GAN-based discriminator improves malicious pattern recognition through adversarial learning with generated samples and limited real samples; and (2) the LLM-based generator refines the quality of malicious code synthesis using reward signals from the discriminator. The experimental results demonstrate that even with a limited number of labeled samples, our training framework is highly effective in enhancing both malicious code generation and detection capabilities. This dual enhancement capability offers a promising solution for developing adaptive defense systems capable of countering evolving cyber threats.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸ºGANGRL-LLMçš„åŠç›‘ç£æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(IDS)åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é¢ä¸´çš„æ¶æ„æ ·æœ¬çŸ­ç¼ºæŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°å°†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ä¸å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ç›¸ç»“åˆï¼Œé€šè¿‡ååŒè®­ç»ƒèŒƒå¼æå‡å°‘æ ·æœ¬åœºæ™¯ä¸‹çš„æ¶æ„ä»£ç ç”Ÿæˆå’ŒSQLæ³¨å…¥(SQLi)æ£€æµ‹èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼ŒGANåˆ¤åˆ«å™¨é€šè¿‡ä¸ç”Ÿæˆæ ·æœ¬åŠæœ‰é™çœŸå®æ ·æœ¬çš„å¯¹æŠ—å­¦ä¹ æ¥å¼ºåŒ–æ¶æ„æ¨¡å¼è¯†åˆ«ï¼Œè€ŒåŸºäºLLMçš„ç”Ÿæˆå™¨åˆ™æ ¹æ®åˆ¤åˆ«å™¨çš„å¥–åŠ±ä¿¡å·ä¸æ–­ä¼˜åŒ–æ¶æ„ä»£ç åˆæˆçš„è´¨é‡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œå³ä½¿åœ¨æ ‡æ³¨æ ·æœ¬æå…¶æœ‰é™çš„æƒ…å†µä¸‹ï¼Œè¯¥æ¡†æ¶ä¹Ÿèƒ½æ˜¾è‘—å¢å¼ºæ¶æ„ä»£ç çš„ç”Ÿæˆä¸æ£€æµ‹æ€§èƒ½ã€‚è¿™ä¸€åŒé‡å¢å¼ºèƒ½åŠ›ä¸ºå¼€å‘èƒ½å¤Ÿåº”å¯¹æ¼”åŒ–ç½‘ç»œå¨èƒçš„è‡ªé€‚åº”é˜²å¾¡ç³»ç»Ÿæä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "18pages,5 figures,emnlp",
      "pdf_url": "https://arxiv.org/pdf/2508.18148v1",
      "published_date": "2025-08-25 15:55:17 UTC",
      "updated_date": "2025-08-25 15:55:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:05.087711+00:00"
    },
    {
      "arxiv_id": "2508.18132v1",
      "title": "Test-Time Scaling Strategies for Generative Retrieval in Multimodal Conversational Recommendations",
      "title_zh": "å¤šæ¨¡æ€å¯¹è¯å¼æ¨èä¸­ç”Ÿæˆå¼æ£€ç´¢çš„æµ‹è¯•æ—¶ç¼©æ”¾ç­–ç•¥",
      "authors": [
        "Hung-Chun Hsu",
        "Yuan-Ching Kuo",
        "Chao-Han Huck Yang",
        "Szu-Wei Fu",
        "Hanrong Ye",
        "Hongxu Yin",
        "Yu-Chiang Frank Wang",
        "Ming-Feng Tsai",
        "Chuan-Ju Wang"
      ],
      "abstract": "The rapid evolution of e-commerce has exposed the limitations of traditional product retrieval systems in managing complex, multi-turn user interactions. Recent advances in multimodal generative retrieval -- particularly those leveraging multimodal large language models (MLLMs) as retrievers -- have shown promise. However, most existing methods are tailored to single-turn scenarios and struggle to model the evolving intent and iterative nature of multi-turn dialogues when applied naively. Concurrently, test-time scaling has emerged as a powerful paradigm for improving large language model (LLM) performance through iterative inference-time refinement. Yet, its effectiveness typically relies on two conditions: (1) a well-defined problem space (e.g., mathematical reasoning), and (2) the model's ability to self-correct -- conditions that are rarely met in conversational product search. In this setting, user queries are often ambiguous and evolving, and MLLMs alone have difficulty grounding responses in a fixed product corpus. Motivated by these challenges, we propose a novel framework that introduces test-time scaling into conversational multimodal product retrieval. Our approach builds on a generative retriever, further augmented with a test-time reranking (TTR) mechanism that improves retrieval accuracy and better aligns results with evolving user intent throughout the dialogue. Experiments across multiple benchmarks show consistent improvements, with average gains of 14.5 points in MRR and 10.6 points in nDCG@1.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå­å•†åŠ¡é¢†åŸŸä¼ ç»Ÿæ£€ç´¢ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚å¤šè½®äº¤äº’æ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åœ¨å¤šæ¨¡æ€å¯¹è¯æ¨èä¸­åº”ç”¨ Test-Time Scaling ç­–ç•¥çš„æ–°æ¡†æ¶ã€‚ä¸ºäº†è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨å¤„ç†æ¼”å˜æ„å›¾ä»¥åŠå°†å“åº”å¯¹é½åˆ°å›ºå®šäº§å“åº“æ—¶çš„æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•åœ¨ Generative Retriever çš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥å¼•å…¥äº†æµ‹è¯•æ—¶é‡æ’åº (Test-Time Reranking, TTR) æœºåˆ¶ã€‚è¯¥æœºåˆ¶é€šè¿‡æ¨ç†é˜¶æ®µçš„è¿­ä»£ä¼˜åŒ–ï¼Œä¸ä»…æ˜¾è‘—æé«˜äº†æ£€ç´¢çš„å‡†ç¡®æ€§ï¼Œè¿˜ç¡®ä¿äº†æ¨èç»“æœä¸å¯¹è¯è¿‡ç¨‹ä¸­åŠ¨æ€å˜åŒ–çš„ç”¨æˆ·æ„å›¾é«˜åº¦ä¸€è‡´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå…¶ä¸­ MRR å¹³å‡æå‡äº† 14.5 ä¸ªç‚¹ï¼ŒnDCG@1 æå‡äº† 10.6 ä¸ªç‚¹ï¼Œä¸ºå¤šè½®å¤šæ¨¡æ€äº§å“æ£€ç´¢æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18132v1",
      "published_date": "2025-08-25 15:38:56 UTC",
      "updated_date": "2025-08-25 15:38:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:26.585254+00:00"
    },
    {
      "arxiv_id": "2508.18124v3",
      "title": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics",
      "title_zh": "CMPhysBenchï¼šå‡èšæ€ç‰©ç†é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹è¯„ä¼°åŸºå‡†",
      "authors": [
        "Weida Wang",
        "Dongchen Huang",
        "Jiatong Li",
        "Tengchao Yang",
        "Ziyang Zheng",
        "Di Zhang",
        "Dong Han",
        "Benteng Chen",
        "Binzhao Luo",
        "Zhiyu Liu",
        "Kunling Liu",
        "Zhiyuan Gao",
        "Shiqi Geng",
        "Wei Ma",
        "Jiaming Su",
        "Xin Li",
        "Shuchen Pu",
        "Yuhan Shui",
        "Qianjia Cheng",
        "Zhihao Dou",
        "Dongfei Cui",
        "Changyong He",
        "Jin Zeng",
        "Zeke Xie",
        "Mao Su",
        "Dongzhan Zhou",
        "Yuqiang Li",
        "Wanli Ouyang",
        "Yunqi Cai",
        "Xi Dai",
        "Shufei Zhang",
        "Lei Bai",
        "Jinguang Cheng",
        "Zhong Fang",
        "Hongming Weng"
      ],
      "abstract": "We introduce CMPhysBench, designed to assess the proficiency of Large Language Models (LLMs) in Condensed Matter Physics, as a novel Benchmark. CMPhysBench is composed of more than 520 graduate-level meticulously curated questions covering both representative subfields and foundational theoretical frameworks of condensed matter physics, such as magnetism, superconductivity, strongly correlated systems, etc. To ensure a deep understanding of the problem-solving process,we focus exclusively on calculation problems, requiring LLMs to independently generate comprehensive solutions. Meanwhile, leveraging tree-based representations of expressions, we introduce the Scalable Expression Edit Distance (SEED) score, which provides fine-grained (non-binary) partial credit and yields a more accurate assessment of similarity between prediction and ground-truth. Our results show that even the best models, Grok-4, reach only 36 average SEED score and 28% accuracy on CMPhysBench, underscoring a significant capability gap, especially for this practical and frontier domain relative to traditional physics. The code anddataset are publicly available at https://github.com/CMPhysBench/CMPhysBench.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CMPhysBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å‡èšæ€ç‰©ç† (Condensed Matter Physics) é¢†åŸŸä¸“ä¸šæ°´å¹³çš„æ–°å‹åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å« 520 å¤šä¸ªç²¾å¿ƒæŒ‘é€‰çš„ç ”ç©¶ç”Ÿæ°´å¹³é—®é¢˜ï¼Œæ¶µç›–äº†ç£æ€§ (Magnetism)ã€è¶…å¯¼ (Superconductivity) å’Œå¼ºå…³è”ç³»ç»Ÿ (Strongly Correlated Systems) ç­‰æ ¸å¿ƒå­é¢†åŸŸåŠåŸºç¡€ç†è®ºæ¡†æ¶ã€‚ä¸ºäº†æ·±å…¥è¯„ä¼°æ¨¡å‹è§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼ŒCMPhysBench ä¸“æ³¨äºè®¡ç®—é¢˜ï¼Œè¦æ±‚ LLMs ç‹¬ç«‹ç”Ÿæˆå®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥ç ”ç©¶è¿˜å¼•å…¥äº†åŸºäºè¡¨è¾¾å¼æ ‘çŠ¶è¡¨ç¤ºçš„å¯æ‰©å±•è¡¨è¾¾å¼ç¼–è¾‘è·ç¦» (Scalable Expression Edit Distance, SEED) åˆ†æ•°ï¼Œé€šè¿‡ç»†ç²’åº¦çš„éäºŒåˆ†è¯„åˆ†æ›´ç²¾ç¡®åœ°è¡¡é‡æ¨¡å‹è¾“å‡ºä¸æ ‡å‡†ç­”æ¡ˆçš„ç›¸ä¼¼åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯è¡¨ç°æœ€å¥½çš„æ¨¡å‹ Grok-4 åœ¨è¯¥åŸºå‡†ä¸Šçš„å¹³å‡ SEED åˆ†æ•°ä¹Ÿä»…ä¸º 36ï¼Œå‡†ç¡®ç‡ä»…ä¸º 28%ï¼Œæ­ç¤ºäº† LLMs åœ¨å‡èšæ€ç‰©ç†è¿™ä¸€å‰æ²¿é¢†åŸŸé¢ä¸´çš„æ˜¾è‘—èƒ½åŠ›å·®è·ã€‚è¿™ä¸€å·¥å…·çš„æ¨å‡ºä¸ºæœªæ¥è¡¡é‡å’Œæå‡äººå·¥æ™ºèƒ½åœ¨å¤æ‚ç‰©ç†ç§‘å­¦é¢†åŸŸçš„è¡¨ç°æä¾›äº†é‡è¦çš„è¯„ä¼°æ‰‹æ®µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.18124v3",
      "published_date": "2025-08-25 15:32:22 UTC",
      "updated_date": "2025-08-29 14:28:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:44.795631+00:00"
    },
    {
      "arxiv_id": "2508.18113v1",
      "title": "The AI Data Scientist",
      "title_zh": "AI æ•°æ®ç§‘å­¦å®¶",
      "authors": [
        "Farkhad Akimov",
        "Munachiso Samuel Nwadike",
        "Zangir Iklassov",
        "Martin TakÃ¡Ä"
      ],
      "abstract": "Imagine decision-makers uploading data and, within minutes, receiving clear, actionable insights delivered straight to their fingertips. That is the promise of the AI Data Scientist, an autonomous Agent powered by large language models (LLMs) that closes the gap between evidence and action. Rather than simply writing code or responding to prompts, it reasons through questions, tests ideas, and delivers end-to-end insights at a pace far beyond traditional workflows. Guided by the scientific tenet of the hypothesis, this Agent uncovers explanatory patterns in data, evaluates their statistical significance, and uses them to inform predictive modeling. It then translates these results into recommendations that are both rigorous and accessible. At the core of the AI Data Scientist is a team of specialized LLM Subagents, each responsible for a distinct task such as data cleaning, statistical testing, validation, and plain-language communication. These Subagents write their own code, reason about causality, and identify when additional data is needed to support sound conclusions. Together, they achieve in minutes what might otherwise take days or weeks, enabling a new kind of interaction that makes deep data science both accessible and actionable.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† The AI Data Scientistï¼Œä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹ (LLMs) é©±åŠ¨çš„è‡ªä¸»æ™ºèƒ½ä½“ (Agent)ï¼Œæ—¨åœ¨å®ç°ä»åŸå§‹æ•°æ®åˆ°å¯æ‰§è¡Œè§è§£çš„å¿«é€Ÿè½¬åŒ–ã€‚è¯¥æ™ºèƒ½ä½“éµå¾ªç§‘å­¦å‡è®¾åŸåˆ™ï¼Œèƒ½å¤Ÿç‹¬ç«‹è¿›è¡Œé€»è¾‘æ¨ç†ã€æµ‹è¯•æ„æƒ³å¹¶äº¤ä»˜ç«¯åˆ°ç«¯çš„åˆ†æç»“æœï¼Œå…¶æ•ˆç‡è¿œè¶…ä¼ ç»Ÿå·¥ä½œæµã€‚å…¶æ ¸å¿ƒç”±å¤šä¸ªä¸“é—¨çš„ LLM Subagents å›¢é˜Ÿç»„æˆï¼Œåˆ†å·¥è´Ÿè´£æ•°æ®æ¸…æ´— (data cleaning)ã€ç»Ÿè®¡æµ‹è¯• (statistical testing)ã€éªŒè¯åŠè‡ªç„¶è¯­è¨€æ²Ÿé€šç­‰å…³é”®ç¯èŠ‚ã€‚è¿™äº›å­æ™ºèƒ½ä½“å…·å¤‡ç¼–å†™ä»£ç ã€æ¨ç†å› æœå…³ç³» (causality) ä»¥åŠè¯†åˆ«è¡¥å……æ•°æ®éœ€æ±‚çš„èƒ½åŠ›ã€‚é€šè¿‡å°†å¤æ‚çš„æ•°æ®ç§‘å­¦æµç¨‹è‡ªåŠ¨åŒ–ï¼Œè¯¥ç³»ç»Ÿèƒ½åœ¨æ•°åˆ†é’Ÿå†…å®Œæˆé€šå¸¸éœ€è¦æ•°å‘¨çš„åˆ†æä»»åŠ¡ï¼Œä¸ºå†³ç­–è€…æä¾›äº†ä¸¥è°¨ä¸”æ˜“äºè·å–çš„æ•°æ®é©±åŠ¨å»ºè®®ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18113v1",
      "published_date": "2025-08-25 15:21:49 UTC",
      "updated_date": "2025-08-25 15:21:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:49.787942+00:00"
    },
    {
      "arxiv_id": "2508.18106v3",
      "title": "A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code",
      "title_zh": "A.S.Eï¼šç”¨äºè¯„ä¼° AI ç”Ÿæˆä»£ç å®‰å…¨æ€§çš„ä»“åº“çº§åŸºå‡†",
      "authors": [
        "Keke Lian",
        "Bin Wang",
        "Lei Zhang",
        "Libo Chen",
        "Junjie Wang",
        "Ziming Zhao",
        "Yujiu Yang",
        "Miaoqian Lin",
        "Haotong Duan",
        "Haoran Zhao",
        "Shuang Liao",
        "Mingda Guo",
        "Jiazheng Quan",
        "Yilu Zhong",
        "Chenhao He",
        "Zichuan Chen",
        "Jie Wu",
        "Haoling Li",
        "Zhaoxuan Li",
        "Jiongchi Yu",
        "Hui Li",
        "Dong Zhang"
      ],
      "abstract": "The increasing adoption of large language models (LLMs) in software engineering necessitates rigorous security evaluation of their generated code. However, existing benchmarks often lack relevance to real-world AI-assisted programming scenarios, making them inadequate for assessing the practical security risks associated with AI-generated code in production environments. To address this gap, we introduce A.S.E (AI Code Generation Security Evaluation), a repository-level evaluation benchmark designed to closely mirror real-world AI programming tasks, offering a comprehensive and reliable framework for assessing the security of AI-generated code. Our evaluation of leading LLMs on A.S.E reveals several key findings. In particular, current LLMs still struggle with secure coding. The complexity in repository-level scenarios presents challenges for LLMs that typically perform well on snippet-level tasks. Moreover, a larger reasoning budget does not necessarily lead to better code generation. These observations offer valuable insights into the current state of AI code generation and help developers identify the most suitable models for practical tasks. They also lay the groundwork for refining LLMs to generate secure and efficient code in real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† A.S.E (AI Code Generation Security Evaluation)ï¼Œè¿™æ˜¯ä¸€ä¸ªä»“åº“çº§ (repository-level) çš„è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºå‡†åœ¨è¯„ä¼° AI ç”Ÿæˆä»£ç å®‰å…¨æ€§æ—¶ç¼ºä¹çœŸå®ç¼–ç¨‹åœºæ™¯ç›¸å…³æ€§çš„é—®é¢˜ã€‚A.S.E é€šè¿‡æ¨¡æ‹ŸçœŸå®çš„ AI ç¼–ç¨‹ä»»åŠ¡ï¼Œä¸ºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„å®é™…å®‰å…¨é£é™©æä¾›äº†ä¸€ä¸ªå…¨é¢ä¸”å¯é çš„æ¡†æ¶ã€‚å¯¹ä¸»æµ LLMs çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œå½“å‰æ¨¡å‹åœ¨ç¼–å†™å®‰å…¨ä»£ç æ–¹é¢ä»é¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œå…¶åœ¨å¤æ‚çš„ä»“åº“çº§åœºæ™¯ä¸‹çš„è¡¨ç°æ˜æ˜¾é€Šäºç®€å•çš„ç‰‡æ®µçº§ (snippet-level) ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°å¢åŠ æ¨ç†é¢„ç®— (reasoning budget) å¹¶ä¸ä¸€å®šèƒ½æå‡ç”Ÿæˆä»£ç çš„å®‰å…¨æ€§ã€‚è¿™äº›è§‚å¯Ÿç»“æœä¸ä»…æ­ç¤ºäº† AI ä»£ç ç”Ÿæˆçš„ç°çŠ¶ï¼Œè¿˜ä¸ºå¼€å‘è€…é€‰æ‹©é€‚åˆå®é™…ä»»åŠ¡çš„æ¨¡å‹æä¾›äº†æŒ‡å¯¼ï¼Œå¹¶ä¸ºæœªæ¥ä¼˜åŒ– LLMs ä»¥ç”Ÿæˆå®‰å…¨é«˜æ•ˆçš„ä»£ç å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18106v3",
      "published_date": "2025-08-25 15:11:11 UTC",
      "updated_date": "2025-09-18 15:18:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:31.891982+00:00"
    },
    {
      "arxiv_id": "2509.07990v1",
      "title": "Signals vs. Videos: Advancing Motion Intention Recognition for Human-Robot Collaboration in Construction",
      "title_zh": "ä¿¡å·ä¸è§†é¢‘ï¼šæ¨è¿›å»ºç­‘æ–½å·¥äººæœºåä½œä¸­çš„è¿åŠ¨æ„å›¾è¯†åˆ«",
      "authors": [
        "Charan Gajjala Chenchu",
        "Kinam Kim",
        "Gao Lu",
        "Zia Ud Din"
      ],
      "abstract": "Human-robot collaboration (HRC) in the construction industry depends on precise and prompt recognition of human motion intentions and actions by robots to maximize safety and workflow efficiency. There is a research gap in comparing data modalities, specifically signals and videos, for motion intention recognition. To address this, the study leverages deep learning to assess two different modalities in recognizing workers' motion intention at the early stage of movement in drywall installation tasks. The Convolutional Neural Network - Long Short-Term Memory (CNN-LSTM) model utilizing surface electromyography (sEMG) data achieved an accuracy of around 87% with an average time of 0.04 seconds to perform prediction on a sample input. Meanwhile, the pre-trained Video Swin Transformer combined with transfer learning harnessed video sequences as input to recognize motion intention and attained an accuracy of 94% but with a longer average time of 0.15 seconds for a similar prediction. This study emphasizes the unique strengths and trade-offs of both data formats, directing their systematic deployments to enhance HRC in real-world construction projects.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å»ºç­‘è¡Œä¸šäººæœºåä½œ(HRC)ä¸­è¿åŠ¨æ„å›¾è¯†åˆ«çš„ç²¾åº¦ä¸åŠæ—¶æ€§é—®é¢˜ï¼Œå¯¹æ¯”åˆ†æäº†ä¿¡å·(signals)ä¸è§†é¢‘(videos)ä¸¤ç§æ•°æ®æ¨¡æ€çš„è¡¨ç°ã€‚ç ”ç©¶åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯è¯„ä¼°äº†çŸ³è†æ¿å®‰è£…ä»»åŠ¡ä¸­å·¥äººçš„æ—©æœŸè¿åŠ¨æ„å›¾ï¼Œåˆ†åˆ«é‡‡ç”¨äº†åŸºäºè¡¨é¢è‚Œç”µå›¾(sEMG)æ•°æ®çš„CNN-LSTMæ¨¡å‹ï¼Œä»¥åŠç»“åˆè¿ç§»å­¦ä¹ çš„é¢„è®­ç»ƒVideo Swin Transformeræ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCNN-LSTMæ¨¡å‹åœ¨sEMGæ•°æ®ä¸Šå®ç°äº†çº¦87%çš„å‡†ç¡®ç‡ä¸”é¢„æµ‹è€—æ—¶ä»…ä¸º0.04ç§’ï¼Œè€ŒVideo Swin Transformeråœ¨è§†é¢‘åºåˆ—ä¸Šçš„å‡†ç¡®ç‡é«˜è¾¾94%ï¼Œä½†é¢„æµ‹æ—¶é—´å¢åŠ è‡³0.15ç§’ã€‚è¯¥ç ”ç©¶ç³»ç»Ÿæ€§åœ°é˜è¿°äº†ä¸¤ç§æ¨¡æ€åœ¨è¯†åˆ«ç²¾åº¦ä¸å“åº”é€Ÿåº¦ä¹‹é—´çš„æƒè¡¡ï¼Œä¸ºæå‡ç°å®å»ºç­‘åœºæ™¯ä¸‹çš„äººæœºåä½œæ•ˆèƒ½æä¾›äº†å…³é”®çš„éƒ¨ç½²æŒ‡å¯¼ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07990v1",
      "published_date": "2025-08-25 14:58:07 UTC",
      "updated_date": "2025-08-25 14:58:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:35.394233+00:00"
    },
    {
      "arxiv_id": "2508.18091v1",
      "title": "Teaching LLMs to Think Mathematically: A Critical Study of Decision-Making via Optimization",
      "title_zh": "åŸ¹å…»å¤§è¯­è¨€æ¨¡å‹çš„æ•°å­¦æ€ç»´ï¼šåŸºäºä¼˜åŒ–æ–¹æ³•çš„å†³ç­–æ·±åº¦ç ”ç©¶",
      "authors": [
        "Mohammad J. Abdel-Rahman",
        "Yasmeen Alslman",
        "Dania Refai",
        "Amro Saleh",
        "Malik A. Abu Loha",
        "Mohammad Yahya Hamed"
      ],
      "abstract": "This paper investigates the capabilities of large language models (LLMs) in formulating and solving decision-making problems using mathematical programming. We first conduct a systematic review and meta-analysis of recent literature to assess how well LLMs understand, structure, and solve optimization problems across domains. The analysis is guided by critical review questions focusing on learning approaches, dataset designs, evaluation metrics, and prompting strategies. Our systematic evidence is complemented by targeted experiments designed to evaluate the performance of state-of-the-art LLMs in automatically generating optimization models for problems in computer networks. Using a newly constructed dataset, we apply three prompting strategies: Act-as-expert, chain-of-thought, and self-consistency, and evaluate the obtained outputs based on optimality gap, token-level F1 score, and compilation accuracy. Results show promising progress in LLMs' ability to parse natural language and represent symbolic formulations, but also reveal key limitations in accuracy, scalability, and interpretability. These empirical gaps motivate several future research directions, including structured datasets, domain-specific fine-tuning, hybrid neuro-symbolic approaches, modular multi-agent architectures, and dynamic retrieval via chain-of-RAGs. This paper contributes a structured roadmap for advancing LLM capabilities in mathematical programming.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿæ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åˆ©ç”¨æ•°å­¦è§„åˆ’ï¼ˆMathematical Programmingï¼‰åˆ¶å®šå¹¶è§£å†³å†³ç­–é—®é¢˜çš„èƒ½åŠ›ã€‚ä½œè€…é¦–å…ˆé€šè¿‡ç³»ç»Ÿå›é¡¾å’Œå…ƒåˆ†æï¼Œè¯„ä¼°äº†LLMsåœ¨è·¨é¢†åŸŸç†è§£ã€æ„å»ºå’Œè§£å†³ä¼˜åŒ–é—®é¢˜ï¼ˆOptimization Problemsï¼‰æ–¹é¢çš„ç°çŠ¶ã€‚éšåï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨æ–°æ„å»ºçš„æ•°æ®é›†ï¼Œé’ˆå¯¹è®¡ç®—æœºç½‘ç»œä¸­çš„ä¼˜åŒ–æ¨¡å‹ç”Ÿæˆä»»åŠ¡ï¼Œå¯¹æ¯”äº†ä¸“å®¶è§’è‰²æ‰®æ¼”ï¼ˆAct-as-expertï¼‰ã€é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰å’Œè‡ªæ´½æ€§ï¼ˆSelf-Consistencyï¼‰ä¸‰ç§æç¤ºè¯ç­–ç•¥çš„è¡¨ç°ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶LLMsåœ¨è§£æè‡ªç„¶è¯­è¨€å¹¶è½¬åŒ–ä¸ºç¬¦å·åŒ–è¡¨è¿°æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰ã€å¯æ‰©å±•æ€§ï¼ˆScalabilityï¼‰å’Œå¯è§£é‡Šæ€§ï¼ˆInterpretabilityï¼‰æ–¹é¢ä»å­˜åœ¨å…³é”®å±€é™ã€‚åŸºäºå®éªŒæ­ç¤ºçš„å·®è·ï¼Œç ”ç©¶æå‡ºäº†åŒ…æ‹¬é¢†åŸŸç‰¹å®šå¾®è°ƒã€ç¥ç»ç¬¦å·ç»“åˆï¼ˆNeuro-symbolicï¼‰ä»¥åŠå¤šæ™ºèƒ½ä½“æ¶æ„åœ¨å†…çš„æœªæ¥ç ”ç©¶è·¯çº¿å›¾ã€‚æœ¬æ–‡ä¸ºæå‡LLMsåœ¨æ•°å­¦è§„åˆ’é¢†åŸŸçš„å†³ç­–èƒ½åŠ›æä¾›äº†ç»“æ„åŒ–çš„æŒ‡å¯¼æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18091v1",
      "published_date": "2025-08-25 14:52:56 UTC",
      "updated_date": "2025-08-25 14:52:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:58:50.294704+00:00"
    },
    {
      "arxiv_id": "2508.18090v1",
      "title": "Named Entity Recognition of Historical Text via Large Language Model",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å†å²æ–‡æœ¬å‘½åå®ä½“è¯†åˆ«",
      "authors": [
        "Shibingfeng Zhang",
        "Giovanni Colavizza"
      ],
      "abstract": "Large language models have demonstrated remarkable versatility across a wide range of natural language processing tasks and domains. One such task is Named Entity Recognition (NER), which involves identifying and classifying proper names in text, such as people, organizations, locations, dates, and other specific entities. NER plays a crucial role in extracting information from unstructured textual data, enabling downstream applications such as information retrieval from unstructured text.\n  Traditionally, NER is addressed using supervised machine learning approaches, which require large amounts of annotated training data. However, historical texts present a unique challenge, as the annotated datasets are often scarce or nonexistent, due to the high cost and expertise required for manual labeling. In addition, the variability and noise inherent in historical language, such as inconsistent spelling and archaic vocabulary, further complicate the development of reliable NER systems for these sources.\n  In this study, we explore the feasibility of applying LLMs to NER in historical documents using zero-shot and few-shot prompting strategies, which require little to no task-specific training data. Our experiments, conducted on the HIPE-2022 (Identifying Historical People, Places and other Entities) dataset, show that LLMs can achieve reasonably strong performance on NER tasks in this setting. While their performance falls short of fully supervised models trained on domain-specific annotations, the results are nevertheless promising. These findings suggest that LLMs offer a viable and efficient alternative for information extraction in low-resource or historically significant corpora, where traditional supervised methods are infeasible.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)å¯¹å†å²æ–‡æœ¬è¿›è¡Œå‘½åå®ä½“è¯†åˆ«(Named Entity Recognition, NER)çš„å¯è¡Œæ€§ã€‚é’ˆå¯¹å†å²æ–‡çŒ®ä¸­æ ‡æ³¨æ•°æ®åŒ®ä¹ã€æ‹¼å†™ä¸ä¸€è‡´ä»¥åŠå¤è¯­è¯æ±‡ä¸°å¯Œç­‰æŒ‘æˆ˜ï¼Œç ”ç©¶è€…é‡‡ç”¨äº†é›¶æ ·æœ¬(zero-shot)å’Œå°‘æ ·æœ¬(few-shot)æç¤ºç­–ç•¥ï¼Œæ— éœ€ç‰¹å®šä»»åŠ¡çš„è®­ç»ƒæ•°æ®å³å¯è¿›è¡Œå®ä½“æå–ã€‚å®éªŒåœ¨HIPE-2022æ•°æ®é›†ä¸Šå±•å¼€ï¼Œç»“æœæ˜¾ç¤ºLLMsåœ¨å†å²æ–‡æœ¬NERä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†ç›¸å½“å¼ºçš„æ€§èƒ½ã€‚è™½ç„¶å…¶å®æµ‹æ•ˆæœå°šæœªè¾¾åˆ°åŸºäºé¢†åŸŸç‰¹å®šæ ‡æ³¨è®­ç»ƒçš„å…¨ç›‘ç£æ¨¡å‹æ°´å¹³ï¼Œä½†ç ”ç©¶è¯æ˜äº†LLMsåœ¨å¤„ç†ä½èµ„æºæˆ–å…·æœ‰ç‰¹æ®Šå†å²æ„ä¹‰çš„è¯­æ–™åº“æ—¶ï¼Œæ˜¯ä¸€ç§é«˜æ•ˆä¸”å®ç”¨çš„ä¿¡æ¯æå–æ›¿ä»£æ–¹æ¡ˆã€‚è¿™ä¸€å‘ç°ä¸ºè§£å†³ä¼ ç»Ÿç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å†å²æ–‡çŒ®é¢†åŸŸå› æ ‡æ³¨æˆæœ¬è¿‡é«˜è€Œéš¾ä»¥å®æ–½çš„é—®é¢˜æä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18090v1",
      "published_date": "2025-08-25 14:52:11 UTC",
      "updated_date": "2025-08-25 14:52:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:03.857848+00:00"
    },
    {
      "arxiv_id": "2509.00058v1",
      "title": "A Comparative Study of Controllability, Explainability, and Performance in Dysfluency Detection Models",
      "title_zh": "è¯­æµä¸ç•…æ£€æµ‹æ¨¡å‹çš„å¯æ§æ€§ã€å¯è§£é‡Šæ€§ä¸æ€§èƒ½å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Eric Zhang",
        "Li Wei",
        "Sarah Chen",
        "Michael Wang"
      ],
      "abstract": "Recent advances in dysfluency detection have introduced a variety of modeling paradigms, ranging from lightweight object-detection inspired networks (YOLOStutter) to modular interpretable frameworks (UDM). While performance on benchmark datasets continues to improve, clinical adoption requires more than accuracy: models must be controllable and explainable. In this paper, we present a systematic comparative analysis of four representative approaches--YOLO-Stutter, FluentNet, UDM, and SSDM--along three dimensions: performance, controllability, and explainability. Through comprehensive evaluation on multiple datasets and expert clinician assessment, we find that YOLO-Stutter and FluentNet provide efficiency and simplicity, but with limited transparency; UDM achieves the best balance of accuracy and clinical interpretability; and SSDM, while promising, could not be fully reproduced in our experiments. Our analysis highlights the trade-offs among competing approaches and identifies future directions for clinically viable dysfluency modeling. We also provide detailed implementation insights and practical deployment considerations for each approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å£åƒæ£€æµ‹(Dysfluency Detection)é¢†åŸŸï¼Œå¯¹å››ç§ä»£è¡¨æ€§æ¨¡å‹YOLO-Stutterã€FluentNetã€UDMå’ŒSSDMåœ¨æ€§èƒ½(Performance)ã€å¯æ§æ€§(Controllability)å’Œå¯è§£é‡Šæ€§(Explainability)ä¸‰ä¸ªç»´åº¦ä¸Šè¿›è¡Œäº†ç³»ç»Ÿçš„å¯¹æ¯”åˆ†æã€‚ç ”ç©¶é€šè¿‡åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„ç»¼åˆè¯„ä¼°ä»¥åŠä¸´åºŠä¸“å®¶çš„ä¸“ä¸šè¯„å®¡ï¼Œæ¢è®¨äº†ä¸åŒå»ºæ¨¡èŒƒå¼åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„å®ç”¨æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒYOLO-Stutterå’ŒFluentNetåœ¨è¿è¡Œæ•ˆç‡å’Œç®€æ´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æ¨¡å‹é€æ˜åº¦(Transparency)æ–¹é¢å­˜åœ¨å±€é™ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒUDMæ¶æ„åœ¨æ£€æµ‹å‡†ç¡®ç‡ä¸ä¸´åºŠå¯è§£é‡Šæ€§ä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ã€‚SSDMè™½ç„¶å±•ç¤ºäº†ä¸€å®šçš„æ½œåŠ›ï¼Œä½†åœ¨è¯¥å®éªŒç¯å¢ƒä¸­æœªèƒ½è¢«å®Œå…¨å¤ç°ã€‚æœ¬ç ”ç©¶æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨æ€§èƒ½ä¸å¯è§£é‡Šæ€§ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶ä¸ºæ„å»ºä¸´åºŠå¯è¡Œçš„å£åƒæ£€æµ‹æ¨¡å‹æä¾›äº†å…·ä½“çš„å®ç°æ´å¯Ÿä¸éƒ¨ç½²å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00058v1",
      "published_date": "2025-08-25 14:23:09 UTC",
      "updated_date": "2025-08-25 14:23:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:07.557315+00:00"
    },
    {
      "arxiv_id": "2508.18066v1",
      "title": "Arnold: a generalist muscle transformer policy",
      "title_zh": "Arnoldï¼šä¸€ç§é€šç”¨çš„è‚Œè‚‰ Transformer ç­–ç•¥",
      "authors": [
        "Alberto Silvio Chiappa",
        "Boshi An",
        "Merkourios Simos",
        "Chengkun Li",
        "Alexander Mathis"
      ],
      "abstract": "Controlling high-dimensional and nonlinear musculoskeletal models of the human body is a foundational scientific challenge. Recent machine learning breakthroughs have heralded policies that master individual skills like reaching, object manipulation and locomotion in musculoskeletal systems with many degrees of freedom. However, these agents are merely \"specialists\", achieving high performance for a single skill. In this work, we develop Arnold, a generalist policy that masters multiple tasks and embodiments. Arnold combines behavior cloning and fine-tuning with PPO to achieve expert or super-expert performance in 14 challenging control tasks from dexterous object manipulation to locomotion. A key innovation is Arnold's sensorimotor vocabulary, a compositional representation of the semantics of heterogeneous sensory modalities, objectives, and actuators. Arnold leverages this vocabulary via a transformer architecture to deal with the variable observation and action spaces of each task. This framework supports efficient multi-task, multi-embodiment learning and facilitates rapid adaptation to novel tasks. Finally, we analyze Arnold to provide insights into biological motor control, corroborating recent findings on the limited transferability of muscle synergies across tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†Arnoldï¼Œä¸€ç§æ—¨åœ¨æ§åˆ¶é«˜ç»´åº¦ã€éçº¿æ€§äººä½“è‚Œè‚‰éª¨éª¼ç³»ç»Ÿçš„é€šç”¨ç­–ç•¥(generalist policy)ï¼Œå…‹æœäº†ä»¥å¾€æ™ºèƒ½ä½“ä»…èƒ½æ‰§è¡Œå•ä¸€æŠ€èƒ½çš„å±€é™ã€‚Arnoldé€šè¿‡ç»“åˆè¡Œä¸ºå…‹éš†(behavior cloning)å’Œè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)å¾®è°ƒï¼Œåœ¨åŒ…æ‹¬çµå·§ç‰©ä½“æ“ä½œå’Œè¿åŠ¨åœ¨å†…çš„14é¡¹æŒ‘æˆ˜æ€§æ§åˆ¶ä»»åŠ¡ä¸­è¾¾åˆ°äº†ä¸“å®¶çº§æ°´å¹³ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ„Ÿè§‰è¿åŠ¨è¯æ±‡è¡¨(sensorimotor vocabulary)ï¼Œåˆ©ç”¨Transformeræ¶æ„å¤„ç†ä¸åŒä»»åŠ¡ä¸­å¤šå˜çš„è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´ï¼Œå®ç°äº†é«˜æ•ˆçš„å¤šä»»åŠ¡ã€å¤šå…·èº«(multi-embodiment)å­¦ä¹ ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å±•ç°äº†å¯¹æ–°ä»»åŠ¡çš„å¿«é€Ÿé€‚åº”èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å¯¹Arnoldçš„åˆ†æéªŒè¯äº†ç”Ÿç‰©è¿åŠ¨æ§åˆ¶ä¸­è‚Œè‚‰ååŒ(muscle synergies)è·¨ä»»åŠ¡è¿ç§»å—é™çš„å‘ç°ï¼Œä¸ºç†è§£äººç±»è¿åŠ¨æ§åˆ¶æœºåˆ¶æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.RO",
      "comment": "A.S.C. and B.A. contributed equally. Code is available at https://github.com/amathislab/arnold-the-generalist",
      "pdf_url": "https://arxiv.org/pdf/2508.18066v1",
      "published_date": "2025-08-25 14:22:40 UTC",
      "updated_date": "2025-08-25 14:22:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:12.797602+00:00"
    },
    {
      "arxiv_id": "2508.18057v2",
      "title": "Dynamic Fusion Multimodal Network for SpeechWellness Detection",
      "title_zh": "é¢å‘ SpeechWellness æ£€æµ‹çš„åŠ¨æ€èåˆå¤šæ¨¡æ€ç½‘ç»œ",
      "authors": [
        "Wenqiang Sun",
        "Han Yin",
        "Jisheng Bai",
        "Jianfeng Chen"
      ],
      "abstract": "Suicide is one of the leading causes of death among adolescents. Previous suicide risk prediction studies have primarily focused on either textual or acoustic information in isolation, the integration of multimodal signals, such as speech and text, offers a more comprehensive understanding of an individual's mental state. Motivated by this, and in the context of the 1st SpeechWellness detection challenge, we explore a lightweight multi-branch multimodal system based on a dynamic fusion mechanism for speechwellness detection. To address the limitation of prior approaches that rely on time-domain waveforms for acoustic analysis, our system incorporates both time-domain and time-frequency (TF) domain acoustic features, as well as semantic representations. In addition, we introduce a dynamic fusion block to adaptively integrate information from different modalities. Specifically, it applies learnable weights to each modality during the fusion process, enabling the model to adjust the contribution of each modality. To enhance computational efficiency, we design a lightweight structure by simplifying the original baseline model. Experimental results demonstrate that the proposed system exhibits superior performance compared to the challenge baseline, achieving a 78% reduction in model parameters and a 5% improvement in accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é’å°‘å¹´è‡ªæ€é£é™©é¢„æµ‹æå‡ºäº† Dynamic Fusion Multimodal Networkï¼Œæ—¨åœ¨é€šè¿‡èåˆè¯­éŸ³å’Œæ–‡æœ¬ä¿¡å·æ›´å…¨é¢åœ°ç†è§£ä¸ªä½“å¿ƒç†çŠ¶æ€ã€‚ä½œä¸ºç¬¬ä¸€å±Š SpeechWellness æŒ‘æˆ˜èµ›çš„å‚èµ›æ–¹æ¡ˆï¼Œè¯¥ç³»ç»Ÿå…‹æœäº†ä»¥å¾€ç ”ç©¶ä»…ä¾èµ–æ—¶åŸŸæ³¢å½¢çš„å±€é™ï¼Œæ•´åˆäº†æ—¶åŸŸ (time-domain)ã€æ—¶é¢‘åŸŸ (TF-domain) å£°å­¦ç‰¹å¾ä»¥åŠè¯­ä¹‰è¡¨ç¤º (semantic representations)ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†åŠ¨æ€èåˆæ¨¡å— (dynamic fusion block)ï¼Œé€šè¿‡åº”ç”¨å¯å­¦ä¹ çš„æƒé‡è‡ªé€‚åº”åœ°é›†æˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯å¹¶è°ƒæ•´å…¶è´¡çŒ®åº¦ã€‚ä¸ºäº†ä¼˜åŒ–è®¡ç®—æ•ˆç‡ï¼Œç ”ç©¶è€…é€šè¿‡ç®€åŒ–åŸºçº¿æ¨¡å‹è®¾è®¡äº†ä¸€ç§è½»é‡åŒ–ç»“æ„ (lightweight structure)ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºæŒ‘æˆ˜èµ›åŸºçº¿ï¼Œåœ¨æ¨¡å‹å‚æ•°é‡å‡å°‘ 78% çš„åŒæ—¶å®ç°äº† 5% çš„å‡†ç¡®ç‡æå‡ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘é«˜æ•ˆä¸”ç²¾å‡†çš„å¿ƒç†å¥åº·æ£€æµ‹æŠ€æœ¯æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages, 5figures",
      "pdf_url": "https://arxiv.org/pdf/2508.18057v2",
      "published_date": "2025-08-25 14:18:12 UTC",
      "updated_date": "2025-09-01 11:20:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:15.396506+00:00"
    },
    {
      "arxiv_id": "2508.19292v1",
      "title": "Stand on The Shoulders of Giants: Building JailExpert from Previous Attack Experience",
      "title_zh": "ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šï¼šåŸºäºä»¥å¾€æ”»å‡»ç»éªŒæ„å»º JailExpert",
      "authors": [
        "Xi Wang",
        "Songlei Jian",
        "Shasha Li",
        "Xiaopeng Li",
        "Bin Ji",
        "Jun Ma",
        "Xiaodong Liu",
        "Jing Wang",
        "Feilong Bao",
        "Jianfeng Zhang",
        "Baosheng Wang",
        "Jie Yu"
      ],
      "abstract": "Large language models (LLMs) generate human-aligned content under certain safety constraints. However, the current known technique ``jailbreak prompt'' can circumvent safety-aligned measures and induce LLMs to output malicious content. Research on Jailbreaking can help identify vulnerabilities in LLMs and guide the development of robust security frameworks. To circumvent the issue of attack templates becoming obsolete as models evolve, existing methods adopt iterative mutation and dynamic optimization to facilitate more automated jailbreak attacks. However, these methods face two challenges: inefficiency and repetitive optimization, as they overlook the value of past attack experiences. To better integrate past attack experiences to assist current jailbreak attempts, we propose the \\textbf{JailExpert}, an automated jailbreak framework, which is the first to achieve a formal representation of experience structure, group experiences based on semantic drift, and support the dynamic updating of the experience pool. Extensive experiments demonstrate that JailExpert significantly improves both attack effectiveness and efficiency. Compared to the current state-of-the-art black-box jailbreak methods, JailExpert achieves an average increase of 17\\% in attack success rate and 2.7 times improvement in attack efficiency. Our implementation is available at \\href{https://github.com/xiZAIzai/JailExpert}{XiZaiZai/JailExpert}",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†JailExpertï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è¶Šç‹±æ”»å‡»æ•ˆç‡å’ŒæˆåŠŸç‡çš„è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ”»å‡»æ–¹æ³•å› å¿½è§†è¿‡å¾€ç»éªŒè€Œå¯¼è‡´çš„é‡å¤ä¼˜åŒ–å’Œä½æ•ˆé—®é¢˜ï¼ŒJailExperté¦–æ¬¡å®ç°äº†æ”»å‡»ç»éªŒç»“æ„çš„æ­£å¼è¡¨ç¤ºï¼Œå¹¶æ ¹æ®è¯­ä¹‰åç§»(semantic drift)å¯¹ç»éªŒè¿›è¡Œåˆ†ç»„ã€‚è¯¥æ¡†æ¶æ”¯æŒç»éªŒæ± çš„åŠ¨æ€æ›´æ–°ï¼Œä»è€Œæœ‰æ•ˆåœ°åˆ©ç”¨æ—¢å¾€æ”»å‡»ç»éªŒæ¥è¾…åŠ©å½“å‰çš„è¶Šç‹±å°è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸ç°æœ‰çš„æœ€å…ˆè¿›é»‘ç›’è¶Šç‹±æ–¹æ³•ç›¸æ¯”ï¼ŒJailExpertåœ¨æ”»å‡»æˆåŠŸç‡ä¸Šå¹³å‡æå‡äº†17%ï¼Œä¸”æ”»å‡»æ•ˆç‡æé«˜äº†2.7å€ã€‚è¯¥ç ”ç©¶é€šè¿‡åˆ©ç”¨å†å²æ”»å‡»ç»éªŒï¼Œä¸ºè¯†åˆ«å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ¼æ´å¹¶æ„å»ºæ›´é²æ£’çš„å®‰å…¨é˜²å¾¡æ¡†æ¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, EMNLP 2025 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2508.19292v1",
      "published_date": "2025-08-25 14:16:30 UTC",
      "updated_date": "2025-08-25 14:16:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:13.561019+00:00"
    },
    {
      "arxiv_id": "2508.18048v1",
      "title": "HyST: LLM-Powered Hybrid Retrieval over Semi-Structured Tabular Data",
      "title_zh": "HySTï¼šå¤§æ¨¡å‹é©±åŠ¨çš„åŠç»“æ„åŒ–è¡¨æ ¼æ•°æ®æ··åˆæ£€ç´¢",
      "authors": [
        "Jiyoon Myung",
        "Jihyeon Park",
        "Joohyung Han"
      ],
      "abstract": "User queries in real-world recommendation systems often combine structured constraints (e.g., category, attributes) with unstructured preferences (e.g., product descriptions or reviews). We introduce HyST (Hybrid retrieval over Semi-structured Tabular data), a hybrid retrieval framework that combines LLM-powered structured filtering with semantic embedding search to support complex information needs over semi-structured tabular data. HyST extracts attribute-level constraints from natural language using large language models (LLMs) and applies them as metadata filters, while processing the remaining unstructured query components via embedding-based retrieval. Experiments on a semi-structured benchmark show that HyST consistently outperforms tradtional baselines, highlighting the importance of structured filtering in improving retrieval precision, offering a scalable and accurate solution for real-world user queries.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HyST (Hybrid retrieval over Semi-structured Tabular data)ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) é©±åŠ¨çš„æ··åˆæ£€ç´¢æ¡†æ¶ï¼Œæ—¨åœ¨å¤„ç†åŠç»“æ„åŒ–è¡¨æ ¼æ•°æ®ä¸­çš„å¤æ‚ä¿¡æ¯éœ€æ±‚ã€‚é’ˆå¯¹ç°å®ä¸–ç•Œæ¨èç³»ç»Ÿä¸­ç»“åˆäº†ç»“æ„åŒ–çº¦æŸä¸éç»“æ„åŒ–åå¥½çš„æŸ¥è¯¢ï¼ŒHyST é€šè¿‡ LLMs ä»è‡ªç„¶è¯­è¨€ä¸­ç²¾å‡†æå–å±æ€§çº§çº¦æŸï¼Œå¹¶å°†å…¶ä½œä¸ºå…ƒæ•°æ®è¿‡æ»¤å™¨ (metadata filters) æ‰§è¡Œã€‚ä¸æ­¤åŒæ—¶ï¼ŒæŸ¥è¯¢ä¸­çš„éç»“æ„åŒ–éƒ¨åˆ†åˆ™é€šè¿‡åŸºäºåµŒå…¥çš„æ£€ç´¢ (embedding-based retrieval) è¿›è¡Œè¯­ä¹‰åŒ¹é…ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHyST åœ¨åŠç»“æ„åŒ–åŸºå‡†æµ‹è¯•ä¸Šçš„ä¸€è‡´è¡¨ç°ä¼˜äºä¼ ç»ŸåŸºçº¿æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢ç²¾åº¦ã€‚è¯¥ç ”ç©¶ä¸ä»…å¼ºè°ƒäº†ç»“æ„åŒ–è¿‡æ»¤åœ¨æ··åˆæ£€ç´¢ä¸­çš„é‡è¦æ€§ï¼Œè¿˜ä¸ºå¤æ‚çš„ç”¨æˆ·æŸ¥è¯¢æä¾›äº†ä¸€ç§å…·å¤‡å¯æ‰©å±•æ€§å’Œå‡†ç¡®æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at the 2nd EARL Workshop on Evaluating and Applying Recommender Systems with Large Language Models (RecSys 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.18048v1",
      "published_date": "2025-08-25 14:06:27 UTC",
      "updated_date": "2025-08-25 14:06:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:28.660896+00:00"
    },
    {
      "arxiv_id": "2508.18040v1",
      "title": "PerPilot: Personalizing VLM-based Mobile Agents via Memory and Exploration",
      "title_zh": "PerPilotï¼šé€šè¿‡è®°å¿†ä¸æ¢ç´¢å®ç°åŸºäºVLMçš„ç§»åŠ¨æ™ºèƒ½ä½“ä¸ªæ€§åŒ–",
      "authors": [
        "Xin Wang",
        "Zhiyao Cui",
        "Hao Li",
        "Ya Zeng",
        "Chenxu Wang",
        "Ruiqi Song",
        "Yihang Chen",
        "Kun Shao",
        "Qiaosheng Zhang",
        "Jinzhuo Liu",
        "Siyue Ren",
        "Shuyue Hu",
        "Zhen Wang"
      ],
      "abstract": "Vision language model (VLM)-based mobile agents show great potential for assisting users in performing instruction-driven tasks. However, these agents typically struggle with personalized instructions -- those containing ambiguous, user-specific context -- a challenge that has been largely overlooked in previous research. In this paper, we define personalized instructions and introduce PerInstruct, a novel human-annotated dataset covering diverse personalized instructions across various mobile scenarios. Furthermore, given the limited personalization capabilities of existing mobile agents, we propose PerPilot, a plug-and-play framework powered by large language models (LLMs) that enables mobile agents to autonomously perceive, understand, and execute personalized user instructions. PerPilot identifies personalized elements and autonomously completes instructions via two complementary approaches: memory-based retrieval and reasoning-based exploration. Experimental results demonstrate that PerPilot effectively handles personalized tasks with minimal user intervention and progressively improves its performance with continued use, underscoring the importance of personalization-aware reasoning for next-generation mobile agents. The dataset and code are available at: https://github.com/xinwang-nwpu/PerPilot",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PerPilotï¼Œä¸€ä¸ªæ—¨åœ¨æå‡åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ (VLM) çš„ç§»åŠ¨æ™ºèƒ½ä½“ä¸ªæ€§åŒ–èƒ½åŠ›çš„å³æ’å³ç”¨æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ™ºèƒ½ä½“éš¾ä»¥å¤„ç†åŒ…å«æ¨¡ç³Šã€ç”¨æˆ·ç‰¹å®šèƒŒæ™¯çš„ä¸ªæ€§åŒ–æŒ‡ä»¤è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…é¦–å…ˆå®šä¹‰äº†ä¸ªæ€§åŒ–æŒ‡ä»¤å¹¶æ¨å‡ºäº† PerInstruct äººå·¥æ ‡æ³¨æ•°æ®é›†ã€‚PerPilot æ¡†æ¶é€šè¿‡å¤§è¯­è¨€æ¨¡å‹ (LLM) èµ‹èƒ½ï¼Œç»“åˆåŸºäºè®°å¿†çš„æ£€ç´¢ (memory-based retrieval) å’ŒåŸºäºæ¨ç†çš„æ¢ç´¢ (reasoning-based exploration) ä¸¤ç§äº’è¡¥æ–¹æ³•ï¼Œå®ç°å¯¹ä¸ªæ€§åŒ–ç”¨æˆ·æŒ‡ä»¤çš„è‡ªä¸»æ„ŸçŸ¥ä¸æ‰§è¡Œã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPerPilot èƒ½åœ¨æå°‘ç”¨æˆ·å¹²é¢„ä¸‹é«˜æ•ˆå®Œæˆä¸ªæ€§åŒ–ä»»åŠ¡ï¼Œå¹¶éšä½¿ç”¨æ¬¡æ•°å¢åŠ æŒç»­ä¼˜åŒ–æ€§èƒ½ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†ä¸ªæ€§åŒ–æ„ŸçŸ¥æ¨ç†å¯¹äºä¸‹ä¸€ä»£ç§»åŠ¨æ™ºèƒ½ä½“çš„é‡è¦æ€§ï¼Œä¸ºå®ç°æ›´æ™ºèƒ½çš„è‡ªä¸»è¾…åŠ©æŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18040v1",
      "published_date": "2025-08-25 13:57:02 UTC",
      "updated_date": "2025-08-25 13:57:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:21.152484+00:00"
    },
    {
      "arxiv_id": "2508.18025v2",
      "title": "AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration",
      "title_zh": "AQ-PCDSysï¼šé¢å‘è‡ªä¸»ç©ºé—´æ¢æµ‹çš„è‡ªé€‚åº”é‡åŒ–è¡Œæ˜Ÿæ’å‡»å‘æ£€æµ‹ç³»ç»Ÿ",
      "authors": [
        "Aditri Paul",
        "Archan Paul"
      ],
      "abstract": "Successful autonomous planetary exploration hinges on real-time, high-fidelity environmental perception. However, standard deep learning models usually demand far more memory and computation power than space-qualified, radiation-hardened onboard hardware can provide. This creates a fundamental design challenge of deploying sophisticated detection architectures without saturating the rigid power and memory envelopes of the computation hardware of planetary exploration platforms. We propose the Adaptive Quantized Planetary Crater Detection System to resolve this bottleneck. Our framework integrates a Quantized Neural Network, refined through Quantization Aware Training, with an Adaptive Multi-Sensor Fusion module. By forcing weights into low-precision integer arithmetic, we effectively strip away the floating-point overhead that typically bottlenecks onboard processors and system memory. This yields a leaner model footprint and significantly faster processing while the detection fidelity remains high. Such efficiency enables AMF module to merge high-bandwidth Optical Imagery streams with Digital Elevation Models using an Adaptive Weighting Mechanism to re-balance sensor priority under variable conditions like deep shadows or high albedo. Integrated Multi-Scale Detection Heads then resolve craters across a wide range of diameters, providing a computationally efficient and precise solution for real-time detection, localization of craters and hazard avoidance. This paper establishes the architectural design and theoretical justification of the system. While our methodology is grounded in principles of hybrid computer vision and planetary science, we present this as a blueprint for future empirical validation and hardware benchmarking on integer-arithmetic units. This system provides a capability vital for the next generation of autonomous landing, navigation, and deep space explorations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AQ-PCDSysï¼Œä¸€ç§ä¸ºè‡ªä¸»ç©ºé—´æ¢ç´¢è®¾è®¡çš„è‡ªé€‚åº”é‡åŒ–è¡Œæ˜Ÿé™¨çŸ³å‘æ£€æµ‹ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¤æ‚æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨èµ„æºå—é™çš„è¾å°„åŠ å›ºæœºè½½ç¡¬ä»¶ä¸Šçš„éƒ¨ç½²éš¾é¢˜ã€‚è¯¥æ¡†æ¶é›†æˆäº†ä¸€ä¸ªé€šè¿‡é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(Quantization Aware Training)ä¼˜åŒ–çš„é‡åŒ–ç¥ç»ç½‘ç»œ(Quantized Neural Network)ï¼Œåˆ©ç”¨ä½ç²¾åº¦æ•´æ•°è¿ç®—æœ‰æ•ˆé™ä½äº†è®¡ç®—å¼€é”€å¹¶æ˜¾è‘—æå‡äº†å¤„ç†é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ£€æµ‹çš„ä¿çœŸåº¦ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿé€šè¿‡è‡ªé€‚åº”å¤šä¼ æ„Ÿå™¨èåˆ(Adaptive Multi-Sensor Fusion)æ¨¡å—å’Œè‡ªé€‚åº”åŠ æƒæœºåˆ¶(Adaptive Weighting Mechanism)ï¼Œåœ¨æ·±å½±æˆ–é«˜åç…§ç‡ç­‰æç«¯ç¯å¢ƒä¸‹åŠ¨æ€æ•´åˆå…‰å­¦å›¾åƒ(Optical Imagery)ä¸æ•°å­—é«˜ç¨‹æ¨¡å‹(Digital Elevation Models)ã€‚é…åˆå¤šå°ºåº¦æ£€æµ‹å¤´(Multi-Scale Detection Heads)ï¼Œè¯¥æ–¹æ¡ˆèƒ½åœ¨å¤§è·¨åº¦ç›´å¾„èŒƒå›´å†…å®ç°é™¨çŸ³å‘çš„å®æ—¶æ£€æµ‹ã€å®šä½ä¸é¿éšœã€‚è¿™é¡¹ç ”ç©¶ä¸ºæœªæ¥åœ¨æ•´æ•°è¿ç®—å•å…ƒä¸Šçš„ç¡¬ä»¶åŸºå‡†æµ‹è¯•å’Œå®è¯éªŒè¯æä¾›äº†è“å›¾ï¼Œå¯¹äºä¸‹ä¸€ä»£è‡ªä¸»ç€é™†ã€å¯¼èˆªå’Œæ·±ç©ºæ¢æµ‹ä»»åŠ¡å…·æœ‰é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.ET",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 6 figures. A research paper on a novel deep learning framework for planetary crater detection",
      "pdf_url": "https://arxiv.org/pdf/2508.18025v2",
      "published_date": "2025-08-25 13:44:00 UTC",
      "updated_date": "2026-01-14 14:49:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:32.284348+00:00"
    },
    {
      "arxiv_id": "2508.18013v1",
      "title": "Towards Continual Visual Anomaly Detection in the Medical Domain",
      "title_zh": "è¿ˆå‘åŒ»å­¦é¢†åŸŸçš„æŒç»­è§†è§‰å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Manuel Barusco",
        "Francesco Borsatti",
        "Nicola Beda",
        "Davide Dalle Pezze",
        "Gian Antonio Susto"
      ],
      "abstract": "Visual Anomaly Detection (VAD) seeks to identify abnormal images and precisely localize the corresponding anomalous regions, relying solely on normal data during training. This approach has proven essential in domains such as manufacturing and, more recently, in the medical field, where accurate and explainable detection is critical. Despite its importance, the impact of evolving input data distributions over time has received limited attention, even though such changes can significantly degrade model performance. In particular, given the dynamic and evolving nature of medical imaging data, Continual Learning (CL) provides a natural and effective framework to incrementally adapt models while preserving previously acquired knowledge. This study explores for the first time the application of VAD models in a CL scenario for the medical field. In this work, we utilize a CL version of the well-established PatchCore model, called PatchCoreCL, and evaluate its performance using BMAD, a real-world medical imaging dataset with both image-level and pixel-level annotations. Our results demonstrate that PatchCoreCL is an effective solution, achieving performance comparable to the task-specific models, with a forgetting value less than a 1%, highlighting the feasibility and potential of CL for adaptive VAD in medical imaging.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åœ¨åŒ»ç–—é¢†åŸŸä¸­å®ç°æŒç»­è§†è§‰å¼‚å¸¸æ£€æµ‹ (Visual Anomaly Detection, VAD) çš„é‡è¦æ€§ï¼Œæ—¨åœ¨è§£å†³åŒ»ç–—å½±åƒæ•°æ®éšæ—¶é—´åŠ¨æ€æ¼”å˜å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚è€ƒè™‘åˆ°åŒ»ç–—æ•°æ®çš„æ¼”è¿›ç‰¹æ€§ï¼Œè¯¥ç ”ç©¶é¦–æ¬¡å°†æŒç»­å­¦ä¹  (Continual Learning, CL) æ¡†æ¶å¼•å…¥ VAD æ¨¡å‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å¢é‡é€‚åº”æ–°æ•°æ®çš„åŒæ—¶ä¿ç•™å…ˆå‰ä¹ å¾—çš„çŸ¥è¯†ã€‚ä½œè€…åˆ©ç”¨äº†æˆç†Ÿ PatchCore æ¨¡å‹çš„æŒç»­å­¦ä¹ ç‰ˆæœ¬ PatchCoreCLï¼Œå¹¶ä½¿ç”¨çœŸå®åŒ»ç–—å½±åƒæ•°æ®é›† BMAD å¯¹å…¶åœ¨å›¾åƒçº§å’Œåƒç´ çº§ä»»åŠ¡ä¸Šçš„è¡¨ç°è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPatchCoreCL åœ¨æ€§èƒ½ä¸Šä¸ç‰¹å®šä»»åŠ¡æ¨¡å‹ (task-specific models) ç›¸å½“ï¼Œä¸”é—å¿˜ç‡ (forgetting value) ä½äº 1%ã€‚è¿™ä¸€å‘ç°æœ‰åŠ›è¯æ˜äº†æŒç»­å­¦ä¹ åœ¨æ„å»ºè‡ªé€‚åº”åŒ»ç–—è§†è§‰å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿæ–¹é¢çš„å¯è¡Œæ€§ä¸æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.18013v1",
      "published_date": "2025-08-25 13:28:15 UTC",
      "updated_date": "2025-08-25 13:28:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:34.489355+00:00"
    },
    {
      "arxiv_id": "2508.18003v1",
      "title": "Previously on... Automating Code Review",
      "title_zh": "å¾€æ˜”å›é¡¾ï¼šè‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥ç ”ç©¶ç»¼è¿°",
      "authors": [
        "Robert HeumÃ¼ller",
        "Frank Ortmeier"
      ],
      "abstract": "Modern Code Review (MCR) is a standard practice in software engineering, yet it demands substantial time and resource investments. Recent research has increasingly explored automating core review tasks using machine learning (ML) and deep learning (DL). As a result, there is substantial variability in task definitions, datasets, and evaluation procedures. This study provides the first comprehensive analysis of MCR automation research, aiming to characterize the field's evolution, formalize learning tasks, highlight methodological challenges, and offer actionable recommendations to guide future research. Focusing on the primary code review tasks, we systematically surveyed 691 publications and identified 24 relevant studies published between May 2015 and April 2024. Each study was analyzed in terms of tasks, models, metrics, baselines, results, validity concerns, and artifact availability. In particular, our analysis reveals significant potential for standardization, including 48 task metric combinations, 22 of which were unique to their original paper, and limited dataset reuse. We highlight challenges and derive concrete recommendations for examples such as the temporal bias threat, which are rarely addressed so far. Our work contributes to a clearer overview of the field, supports the framing of new research, helps to avoid pitfalls, and promotes greater standardization in evaluation practices.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£ä»£ç å®¡æŸ¥ (Modern Code Review, MCR) è‡ªåŠ¨åŒ–é¢†åŸŸè¿›è¡Œäº†é¦–æ¬¡å…¨é¢çš„ç³»ç»Ÿæ€§åˆ†æï¼Œæ—¨åœ¨å½’çº³è¯¥é¢†åŸŸçš„æ¼”å˜å†ç¨‹å¹¶è§„èŒƒå­¦ä¹ ä»»åŠ¡ (Learning Tasks)ã€‚é€šè¿‡è°ƒç ” 2015 å¹´è‡³ 2024 å¹´é—´çš„ 691 ç¯‡å‡ºç‰ˆç‰©ï¼Œç ”ç©¶è€…æ·±å…¥å‰–æäº† 24 é¡¹æ ¸å¿ƒç ”ç©¶åœ¨æ¨¡å‹ (Models)ã€è¯„ä»·æŒ‡æ ‡ (Metrics) å’ŒåŸºå‡†æµ‹è¯• (Baselines) ç­‰ç»´åº¦çš„è¡¨ç°ã€‚åˆ†æç»“æœæ­ç¤ºäº†è¯¥é¢†åŸŸåœ¨æ ‡å‡†åŒ–æ–¹é¢çš„æ˜¾è‘—ç¼ºå¤±ï¼Œå…·ä½“è¡¨ç°ä¸ºå­˜åœ¨å¤§é‡äº’ä¸å…¼å®¹çš„ä»»åŠ¡æŒ‡æ ‡ç»„åˆä»¥åŠè¾ƒä½çš„æ•°æ®é›†é‡ç”¨ç‡ã€‚ç ”ç©¶è¿˜ç‰¹åˆ«å¼ºè°ƒäº†æ—¶é—´åå·® (Temporal Bias) ç­‰ä»¥å¾€è¢«å¿½è§†çš„æ–¹æ³•è®ºæŒ‘æˆ˜ä¸æ•ˆåº¦å¨èƒã€‚æœ€ç»ˆï¼Œè¯¥è®ºæ–‡ä¸ºæœªæ¥ç ”ç©¶æä¾›äº†å…·ä½“çš„æ”¹è¿›å»ºè®®ï¼Œæ—¨åœ¨å¸®åŠ©ç ”ç©¶è€…è§„é¿æ½œåœ¨é™·é˜±å¹¶æ¨åŠ¨ MCR è‡ªåŠ¨åŒ–è¯„ä¼°å®è·µçš„æ ‡å‡†åŒ–ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Preprint currently under review",
      "pdf_url": "https://arxiv.org/pdf/2508.18003v1",
      "published_date": "2025-08-25 13:12:48 UTC",
      "updated_date": "2025-08-25 13:12:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T13:59:42.070930+00:00"
    },
    {
      "arxiv_id": "2508.18337v3",
      "title": "Warm Chat: Diffuse Emotion-aware Interactive Talking Head Avatar with Tree-Structured Guidance",
      "title_zh": "Warm Chatï¼šåŸºäºæ ‘çŠ¶ç»“æ„å¼•å¯¼çš„æƒ…æ„Ÿæ„ŸçŸ¥äº¤äº’å¼æ‰©æ•£è¯´è¯äººå¤´åƒ",
      "authors": [
        "Haijie Yang",
        "Zhenyu Zhang",
        "Hao Tang",
        "Jianjun Qian",
        "Jian Yang"
      ],
      "abstract": "Generative models have advanced rapidly, enabling impressive talking head generation that brings AI to life. However, most existing methods focus solely on one-way portrait animation. Even the few that support bidirectional conversational interactions lack precise emotion-adaptive capabilities, significantly limiting their practical applicability. In this paper, we propose Warm Chat, a novel emotion-aware talking head generation framework for dyadic interactions. Leveraging the dialogue generation capability of large language models (LLMs, e.g., GPT-4), our method produces temporally consistent virtual avatars with rich emotional variations that seamlessly transition between speaking and listening states. Specifically, we design a Transformer-based head mask generator that learns temporally consistent motion features in a latent mask space, capable of generating arbitrary-length, temporally consistent mask sequences to constrain head motions. Furthermore, we introduce an interactive talking tree structure to represent dialogue state transitions, where each tree node contains information such as child/parent/sibling nodes and the current character's emotional state. By performing reverse-level traversal, we extract rich historical emotional cues from the current node to guide expression synthesis. Extensive experiments demonstrate the superior performance and effectiveness of our method.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Warm Chatï¼Œä¸€ä¸ªä¸“ä¸ºåŒå‘äº’åŠ¨è®¾è®¡çš„äº¤äº’å¼æƒ…æ„Ÿæ„ŸçŸ¥ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è°ˆè¯å¤´éƒ¨ (Talking Head) ç”Ÿæˆæ–¹æ³•åœ¨æƒ…æ„Ÿé€‚åº”æ€§åŠåŒå‘å¯¹è¯äº¤äº’æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ Large Language Models (LLMs) çš„å¯¹è¯ç”Ÿæˆèƒ½åŠ›ï¼Œäº§ç”Ÿå…·æœ‰ä¸°å¯Œæƒ…æ„Ÿå˜åŒ–ä¸”èƒ½åœ¨è¯´è¯ä¸å€¾å¬çŠ¶æ€é—´æ— ç¼åˆ‡æ¢çš„è™šæ‹Ÿå¤´åƒã€‚æŠ€æœ¯ä¸Šï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ä¸ªåŸºäº Transformer çš„å¤´éƒ¨æ©è†œç”Ÿæˆå™¨ (Head Mask Generator)ï¼Œé€šè¿‡åœ¨æ½œç©ºé—´å­¦ä¹ è¿åŠ¨ç‰¹å¾ï¼Œç”Ÿæˆæ—¶é—´ä¸€è‡´çš„æ©è†œåºåˆ—ä»¥çº¦æŸå¤´éƒ¨è¿åŠ¨ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§äº¤äº’å¼è°ˆè¯æ ‘ç»“æ„ (Interactive Talking Tree Structure) æ¥è¡¨å¾å¯¹è¯çŠ¶æ€è½¬æ¢ï¼Œå¹¶é€šè¿‡åå‘å±‚çº§éå† (Reverse-level Traversal) æå–å†å²æƒ…æ„Ÿçº¿ç´¢ä»¥å¼•å¯¼è¡¨æƒ…åˆæˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒWarm Chat åœ¨ç”Ÿæˆé«˜è´¨é‡ã€æƒ…æ„Ÿä¸°å¯Œçš„äº’åŠ¨å¤´åƒæ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†è™šæ‹Ÿå½¢è±¡çš„å®ç”¨æ€§ä¸è¡¨ç°åŠ›ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "The submission is withdrawn at the request of the authors due to internal reasons within the research team",
      "pdf_url": "https://arxiv.org/pdf/2508.18337v3",
      "published_date": "2025-08-25 13:07:03 UTC",
      "updated_date": "2025-11-24 11:19:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:10.070066+00:00"
    },
    {
      "arxiv_id": "2508.17990v1",
      "title": "Automating Conflict-Aware ACL Configurations with Natural Language Intents",
      "title_zh": "åŸºäºè‡ªç„¶è¯­è¨€æ„å›¾çš„å†²çªæ„ŸçŸ¥ ACL è‡ªåŠ¨åŒ–é…ç½®",
      "authors": [
        "Wenlong Ding",
        "Jianqiang Li",
        "Zhixiong Niu",
        "Huangxun Chen",
        "Yongqiang Xiong",
        "Hong Xu"
      ],
      "abstract": "ACL configuration is essential for managing network flow reachability, yet its complexity grows significantly with topologies and pre-existing rules. To carry out ACL configuration, the operator needs to (1) understand the new configuration policies or intents and translate them into concrete ACL rules, (2) check and resolve any conflicts between the new and existing rules, and (3) deploy them across the network. Existing systems rely heavily on manual efforts for these tasks, especially for the first two, which are tedious, error-prone, and impractical to scale.\n  We propose Xumi to tackle this problem. Leveraging LLMs with domain knowledge of the target network, Xumi automatically and accurately translates the natural language intents into complete ACL rules to reduce operators' manual efforts. Xumi then detects all potential conflicts between new and existing rules and generates resolved intents for deployment with operators' guidance, and finally identifies the best deployment plan that minimizes the rule additions while satisfying all intents. Evaluation shows that Xumi accelerates the entire configuration pipeline by over 10x compared to current practices, addresses O(100) conflicting ACLs and reduces rule additions by ~40% in modern cloud network.",
      "tldr_zh": "ACLé…ç½®å¯¹äºç®¡ç†ç½‘ç»œæµçš„å¯è¾¾æ€§è‡³å…³é‡è¦ï¼Œä½†éšç€ç½‘ç»œæ‹“æ‰‘å’Œé¢„å­˜è§„åˆ™çš„å¢åŠ ï¼Œå…¶å¤æ‚æ€§æ˜¾è‘—æå‡ï¼Œå¯¼è‡´ä¼ ç»Ÿçš„æ‰‹åŠ¨é…ç½®æµç¨‹ç¹çä¸”æ˜“å‡ºé”™ã€‚è¯¥ç ”ç©¶æå‡ºäº†Xumiç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€æ„å›¾(Natural Language Intents)å®ç°å†²çªæ„ŸçŸ¥çš„ACLè‡ªåŠ¨åŒ–é…ç½®ã€‚Xumiåˆ©ç”¨å…·å¤‡ç›®æ ‡ç½‘ç»œé¢†åŸŸçŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)ï¼Œè‡ªåŠ¨ä¸”å‡†ç¡®åœ°å°†è‡ªç„¶è¯­è¨€æ„å›¾è½¬åŒ–ä¸ºå®Œæ•´çš„ACLè§„åˆ™ï¼Œå¤§å¹…å‡å°‘äº†è¿ç»´äººå‘˜çš„æ‰‹åŠ¨è´Ÿæ‹…ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿè¯†åˆ«æ–°æ—§è§„åˆ™ä¹‹é—´çš„æ‰€æœ‰æ½œåœ¨å†²çªï¼Œå¹¶åœ¨äººå·¥æŒ‡å¯¼ä¸‹ç”Ÿæˆä¿®å¤åçš„æ„å›¾ï¼Œæœ€åé€šè¿‡ä¼˜åŒ–éƒ¨ç½²è®¡åˆ’æ¥æœ€å°åŒ–è§„åˆ™çš„æ–°å¢æ•°é‡ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œåœ¨ç°ä»£äº‘ç½‘ç»œç¯å¢ƒä¸‹ï¼ŒXumiå°†æ•´ä¸ªé…ç½®ç®¡çº¿çš„æ•ˆç‡æå‡äº†10å€ä»¥ä¸Šï¼Œèƒ½æœ‰æ•ˆå¤„ç†æ•°ç™¾æ¡å†²çªçš„ACLè§„åˆ™ï¼Œå¹¶å‡å°‘çº¦40%çš„è§„åˆ™æ–°å¢é‡ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17990v1",
      "published_date": "2025-08-25 13:00:41 UTC",
      "updated_date": "2025-08-25 13:00:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:04.367987+00:00"
    },
    {
      "arxiv_id": "2508.17971v1",
      "title": "Neural Algorithmic Reasoners informed Large Language Model for Multi-Agent Path Finding",
      "title_zh": "ç”±ç¥ç»ç®—æ³•æ¨ç†å™¨å¼•å¯¼çš„å¤§è¯­è¨€æ¨¡å‹å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’",
      "authors": [
        "Pu Feng",
        "Size Wang",
        "Yuhong Cao",
        "Junkang Liang",
        "Rongye Shi",
        "Wenjun Wu"
      ],
      "abstract": "The development and application of large language models (LLM) have demonstrated that foundational models can be utilized to solve a wide array of tasks. However, their performance in multi-agent path finding (MAPF) tasks has been less than satisfactory, with only a few studies exploring this area. MAPF is a complex problem requiring both planning and multi-agent coordination. To improve the performance of LLM in MAPF tasks, we propose a novel framework, LLM-NAR, which leverages neural algorithmic reasoners (NAR) to inform LLM for MAPF. LLM-NAR consists of three key components: an LLM for MAPF, a pre-trained graph neural network-based NAR, and a cross-attention mechanism. This is the first work to propose using a neural algorithmic reasoner to integrate GNNs with the map information for MAPF, thereby guiding LLM to achieve superior performance. LLM-NAR can be easily adapted to various LLM models. Both simulation and real-world experiments demonstrate that our method significantly outperforms existing LLM-based approaches in solving MAPF problems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Language Models (LLM) åœ¨ Multi-Agent Path Finding (MAPF) ä»»åŠ¡ä¸­ç”±äºç¼ºä¹è§„åˆ’ä¸å¤šæ™ºèƒ½ä½“åè°ƒèƒ½åŠ›å¯¼è‡´è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º LLM-NAR çš„åˆ›æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨åˆ©ç”¨ Neural Algorithmic Reasoners (NAR) ä¸º LLM æä¾›ä¿¡æ¯æ”¯æ’‘ï¼Œå…¶æ ¸å¿ƒç»„ä»¶åŒ…æ‹¬ä¸€ä¸ªç”¨äº MAPF çš„ LLMã€ä¸€ä¸ªåŸºäº Graph Neural Network (GNN) çš„é¢„è®­ç»ƒ NAR ä»¥åŠ Cross-attention æœºåˆ¶ã€‚è¿™æ˜¯å­¦æœ¯ç•Œé¦–æ¬¡æå‡ºåˆ©ç”¨ç¥ç»ç®—æ³•æ¨ç†å™¨å°† GNN ä¸åœ°å›¾æ‹“æ‰‘ä¿¡æ¯æ•´åˆï¼Œä»è€Œå¼•å¯¼ LLM å®ç°å“è¶Šçš„è·¯å¾„è§„åˆ’æ€§èƒ½ã€‚LLM-NAR å…·æœ‰å¾ˆå¼ºçš„é€‚é…æ€§ï¼Œèƒ½å¤Ÿè½»æ¾é›†æˆåˆ°ä¸åŒçš„ LLM æ¨¡å‹ä¸­ã€‚ä»¿çœŸå®éªŒä¸çœŸå®ä¸–ç•Œæµ‹è¯•å‡è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§£å†³ MAPF é—®é¢˜ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºäº LLM çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCNN 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17971v1",
      "published_date": "2025-08-25 12:38:08 UTC",
      "updated_date": "2025-08-25 12:38:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:06.357671+00:00"
    },
    {
      "arxiv_id": "2508.17959v1",
      "title": "Language Models Coupled with Metacognition Can Outperform Reasoning Models",
      "title_zh": "ç»“åˆå…ƒè®¤çŸ¥çš„è¯­è¨€æ¨¡å‹æ€§èƒ½å¯è¶…è¶Šæ¨ç†æ¨¡å‹",
      "authors": [
        "Vedant Khandelwal",
        "Francesca Rossi",
        "Keerthiram Murugesan",
        "Erik Miehling",
        "Murray Campbell",
        "Karthikeyan Natesan Ramamurthy",
        "Lior Horesh"
      ],
      "abstract": "Large language models (LLMs) excel in speed and adaptability across various reasoning tasks, but they often struggle when strict logic or constraint enforcement is required. In contrast, Large Reasoning Models (LRMs) are specifically designed for complex, step-by-step reasoning, although they come with significant computational costs and slower inference times. To address these trade-offs, we employ and generalize the SOFAI (Slow and Fast AI) cognitive architecture into SOFAI-LM, which coordinates a fast LLM with a slower but more powerful LRM through metacognition. The metacognitive module actively monitors the LLM's performance and provides targeted, iterative feedback with relevant examples. This enables the LLM to progressively refine its solutions without requiring the need for additional model fine-tuning. Extensive experiments on graph coloring and code debugging problems demonstrate that our feedback-driven approach significantly enhances the problem-solving capabilities of the LLM. In many instances, it achieves performance levels that match or even exceed those of standalone LRMs while requiring considerably less time. Additionally, when the LLM and feedback mechanism alone are insufficient, we engage the LRM by providing appropriate information collected during the LLM's feedback loop, tailored to the specific characteristics of the problem domain and leads to improved overall performance. Evaluations on two contrasting domains: graph coloring, requiring globally consistent solutions, and code debugging, demanding localized fixes, demonstrate that SOFAI-LM enables LLMs to match or outperform standalone LRMs in accuracy while maintaining significantly lower inference time.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨é€»è¾‘çº¦æŸä»»åŠ¡ä¸Šçš„å±€é™æ€§ä»¥åŠå¤§æ¨ç†æ¨¡å‹ (LRMs) é«˜æ˜‚çš„è®¡ç®—æˆæœ¬ï¼Œæå‡ºäº†åŸºäº SOFAI (Slow and Fast AI) è®¤çŸ¥æ¶æ„çš„ SOFAI-LM æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥å…ƒè®¤çŸ¥ (metacognition) æ¨¡å—ï¼Œé€šè¿‡ä¸»åŠ¨ç›‘æ§ LLM çš„è¡¨ç°å¹¶æä¾›è¿­ä»£åé¦ˆä¸ç¤ºä¾‹ï¼Œä¿ƒä½¿æ¨¡å‹åœ¨æ— éœ€å¾®è°ƒçš„æƒ…å†µä¸‹è‡ªä¸»ä¼˜åŒ–è§£é¢˜è¿‡ç¨‹ã€‚å½“ LLM æ— æ³•ç‹¬ç«‹å®Œæˆä»»åŠ¡æ—¶ï¼Œå…ƒè®¤çŸ¥æ¨¡å—ä¼šæ•´åˆåé¦ˆå¾ªç¯ä¸­çš„å…³é”®ä¿¡æ¯å¼•å¯¼ LRM ä»‹å…¥ï¼Œå®ç°å¿«æ…¢æ€ç»´çš„æœ‰æ•ˆåä½œã€‚åœ¨å›¾ç€è‰² (graph coloring) å’Œä»£ç è°ƒè¯• (code debugging) ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSOFAI-LM åœ¨ä¿æŒæ˜¾è‘—è¾ƒä½æ¨ç†æ—¶é—´çš„åŒæ—¶ï¼Œå…¶å‡†ç¡®ç‡è¾¾åˆ°ç”šè‡³è¶…è¿‡äº†ç‹¬ç«‹è¿è¡Œçš„ LRMsã€‚è¯¥ç ”ç©¶ä¸ä»…æå‡äº† LLMs è§£å†³å¤æ‚é€»è¾‘é—®é¢˜çš„èƒ½åŠ›ï¼Œä¹Ÿä¸ºé«˜æ•ˆåè°ƒä¸åŒèƒ½åŠ›çš„ AI æ¨¡å‹æä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "37 Pages, 95 Figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17959v1",
      "published_date": "2025-08-25 12:19:57 UTC",
      "updated_date": "2025-08-25 12:19:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:28.755543+00:00"
    },
    {
      "arxiv_id": "2508.17953v1",
      "title": "Understanding Subword Compositionality of Large Language Models",
      "title_zh": "ç†è§£å¤§è¯­è¨€æ¨¡å‹çš„å­è¯ç»„åˆæ€§",
      "authors": [
        "Qiwei Peng",
        "Yekun Chai",
        "Anders SÃ¸gaard"
      ],
      "abstract": "Large language models (LLMs) take sequences of subwords as input, requiring them to effective compose subword representations into meaningful word-level representations. In this paper, we present a comprehensive set of experiments to probe how LLMs compose subword information, focusing on three key aspects: structural similarity, semantic decomposability, and form retention. Our analysis of the experiments suggests that these five LLM families can be classified into three distinct groups, likely reflecting difference in their underlying composition strategies. Specifically, we observe (i) three distinct patterns in the evolution of structural similarity between subword compositions and whole-word representations across layers; (ii) great performance when probing layer by layer their sensitivity to semantic decompositionality; and (iii) three distinct patterns when probing sensitivity to formal features, e.g., character sequence length. These findings provide valuable insights into the compositional dynamics of LLMs and highlight different compositional pattens in how LLMs encode and integrate subword information.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)å¦‚ä½•å°†å­è¯(subwords)è¡¨ç¤ºç»„åˆæˆæœ‰æ„ä¹‰çš„è¯çº§è¡¨ç¤ºï¼Œé‡ç‚¹åˆ†æäº†ç»“æ„ç›¸ä¼¼æ€§(structural similarity)ã€è¯­ä¹‰å¯åˆ†è§£æ€§(semantic decomposability)å’Œå½¢æ€ä¿ç•™(form retention)ä¸‰ä¸ªå…³é”®ç»´åº¦ã€‚é€šè¿‡å¯¹äº”ä¸ªä¸»æµLLMå®¶æ—è¿›è¡Œç³»ç»Ÿæ€§æ¢æµ‹å®éªŒï¼Œç ”ç©¶å‘ç°è¿™äº›æ¨¡å‹åœ¨åº•å±‚ç»„åˆç­–ç•¥ä¸Šå‘ˆç°å‡ºä¸‰ç±»æˆªç„¶ä¸åŒçš„æ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå­è¯ç»„åˆä¸æ•´è¯è¡¨ç¤ºä¹‹é—´çš„ç»“æ„ç›¸ä¼¼æ€§åœ¨ä¸åŒæ¨¡å‹å±‚çº§ä¸­è¡¨ç°å‡ºä¸‰ç§æ¼”åŒ–è§„å¾‹ï¼Œä¸”æ¨¡å‹åœ¨å±‚çº§æ¢æµ‹ä¸­å¯¹è¯­ä¹‰åˆ†è§£è¡¨ç°å‡ºæé«˜çš„æ•æ„Ÿæ€§ã€‚æ­¤å¤–ï¼Œåœ¨é’ˆå¯¹å­—ç¬¦åºåˆ—é•¿åº¦ç­‰å½¢å¼ç‰¹å¾çš„æ•æ„Ÿåº¦æ¢æµ‹ä¸­ï¼ŒåŒæ ·è§‚å¯Ÿåˆ°äº†ä¸‰ç§ä¸åŒçš„å“åº”æ¨¡å¼ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†LLMå†…éƒ¨å¤æ‚çš„ç»„åˆåŠ¨åŠ›å­¦ï¼Œä¸ºç†è§£æ¨¡å‹å¦‚ä½•ç¼–ç å’Œæ•´åˆå­è¯ä¿¡æ¯æä¾›äº†æ·±åº¦çš„ç†è®ºè§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Main",
      "pdf_url": "https://arxiv.org/pdf/2508.17953v1",
      "published_date": "2025-08-25 12:16:56 UTC",
      "updated_date": "2025-08-25 12:16:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:13.185523+00:00"
    },
    {
      "arxiv_id": "2508.17948v1",
      "title": "Debiasing Multilingual LLMs in Cross-lingual Latent Space",
      "title_zh": "è·¨è¯­è¨€æ½œç©ºé—´ä¸‹çš„å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹å»å",
      "authors": [
        "Qiwei Peng",
        "Guimin Hu",
        "Yekun Chai",
        "Anders SÃ¸gaard"
      ],
      "abstract": "Debiasing techniques such as SentDebias aim to reduce bias in large language models (LLMs). Previous studies have evaluated their cross-lingual transferability by directly applying these methods to LLM representations, revealing their limited effectiveness across languages. In this work, we therefore propose to perform debiasing in a joint latent space rather than directly on LLM representations. We construct a well-aligned cross-lingual latent space using an autoencoder trained on parallel TED talk scripts. Our experiments with Aya-expanse and two debiasing techniques across four languages (English, French, German, Dutch) demonstrate that a) autoencoders effectively construct a well-aligned cross-lingual latent space, and b) applying debiasing techniques in the learned cross-lingual latent space significantly improves both the overall debiasing performance and cross-lingual transferability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å»åæŠ€æœ¯(Debiasing techniques)åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹è·¨è¯­è¨€è¿ç§»èƒ½åŠ›å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åœ¨è”åˆæ½œåœ¨ç©ºé—´(joint latent space)ä¸­è¿›è¡Œå»åçš„æ–°æ–¹æ³•ã€‚ç ”ç©¶åˆ©ç”¨åœ¨å¹³è¡ŒTEDæ¼”è®²è„šæœ¬ä¸Šè®­ç»ƒçš„è‡ªåŠ¨ç¼–ç å™¨(autoencoder)æ„å»ºäº†ä¸€ä¸ªå¯¹é½è‰¯å¥½çš„è·¨è¯­è¨€æ½œåœ¨ç©ºé—´ï¼Œä»è€Œé¿å…äº†ç›´æ¥åœ¨LLMè¡¨ç¤ºä¸Šè¿›è¡Œæ“ä½œã€‚å®éªŒé€šè¿‡Aya-expanseæ¨¡å‹åœ¨è‹±è¯­ã€æ³•è¯­ã€å¾·è¯­å’Œè·å…°è¯­å››ç§è¯­è¨€ä¸ŠéªŒè¯äº†SentDebiasç­‰å»åæŠ€æœ¯ï¼Œç»“æœè¯å®è‡ªåŠ¨ç¼–ç å™¨èƒ½æœ‰æ•ˆå®ç°ç©ºé—´å¯¹é½ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨å­¦ä¹ åˆ°çš„è·¨è¯­è¨€æ½œåœ¨ç©ºé—´ä¸­åº”ç”¨å»åæŠ€æœ¯ï¼Œä¸ä»…æ˜¾è‘—æå‡äº†æ•´ä½“çš„å»åæ€§èƒ½ï¼Œè¿˜å¤§å¹…å¢å¼ºäº†å»åæ•ˆæœçš„è·¨è¯­è¨€è¿ç§»èƒ½åŠ›(cross-lingual transferability)ã€‚è¯¥æ–¹æ³•ä¸ºæ„å»ºæ›´åŠ å…¬å¹³ä¸”å…·å¤‡å¤šè¯­è¨€æ³›åŒ–èƒ½åŠ›çš„æ¨¡å‹æä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Main",
      "pdf_url": "https://arxiv.org/pdf/2508.17948v1",
      "published_date": "2025-08-25 12:13:37 UTC",
      "updated_date": "2025-08-25 12:13:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:28.164843+00:00"
    },
    {
      "arxiv_id": "2508.17944v1",
      "title": "A Feminist Account of Intersectional Algorithmic Fairness",
      "title_zh": "å¥³æ€§ä¸»ä¹‰è§†è§’ä¸‹çš„äº¤å‰æ€§ç®—æ³•å…¬å¹³æ€§",
      "authors": [
        "Marie Mirsch",
        "Laila Wegner",
        "Jonas Strube",
        "Carmen Leicht-Scholten"
      ],
      "abstract": "Intersectionality has profoundly influenced research and political action by revealing how interconnected systems of privilege and oppression influence lived experiences, yet its integration into algorithmic fairness research remains limited. Existing approaches often rely on single-axis or formal subgroup frameworks that risk oversimplifying social realities and neglecting structural inequalities. We propose Substantive Intersectional Algorithmic Fairness, extending Green's (2022) notion of substantive algorithmic fairness with insights from intersectional feminist theory. Building on this foundation, we introduce ten desiderata within the ROOF methodology to guide the design, assessment, and deployment of algorithmic systems in ways that address systemic inequities while mitigating harms to intersectionally marginalized communities. Rather than prescribing fixed operationalizations, these desiderata encourage reflection on assumptions of neutrality, the use of protected attributes, the inclusion of multiply marginalized groups, and enhancing algorithmic systems' potential. Our approach emphasizes that fairness cannot be separated from social context, and that in some cases, principled non-deployment may be necessary. By bridging computational and social science perspectives, we provide actionable guidance for more equitable, inclusive, and context-sensitive intersectional algorithmic practices.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†äº¤å‰æ€§(Intersectionality)åœ¨ç®—æ³•å…¬å¹³æ€§ç ”ç©¶ä¸­çš„å±€é™æ€§ï¼ŒæŒ‡å‡ºç›®å‰çš„å•ä¸€è½´å‘æˆ–å½¢å¼åŒ–å­ç»„æ¡†æ¶å®¹æ˜“ç®€åŒ–ç¤¾ä¼šç°å®å¹¶å¿½è§†ç»“æ„æ€§ä¸å¹³ç­‰ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†å®è´¨æ€§äº¤å‰ç®—æ³•å…¬å¹³æ€§(Substantive Intersectional Algorithmic Fairness)ï¼Œå°†Green(2022)çš„å®è´¨æ€§ç®—æ³•å…¬å¹³æ€§æ¦‚å¿µä¸äº¤å‰å¥³æƒä¸»ä¹‰ç†è®º(intersectional feminist theory)ç›¸ç»“åˆã€‚ç ”ç©¶è¿›ä¸€æ­¥åœ¨ROOFæ–¹æ³•è®ºä¸­å¼•å…¥äº†åé¡¹è¯‰æ±‚(desiderata)ï¼Œæ—¨åœ¨å¼•å¯¼ç®—æ³•ç³»ç»Ÿçš„è®¾è®¡ã€è¯„ä¼°å’Œéƒ¨ç½²ï¼Œä»è€Œåº”å¯¹ç³»ç»Ÿæ€§ä¸å¹³ç­‰å¹¶å‡è½»å¯¹äº¤å‰è¾¹ç¼˜åŒ–ç¾¤ä½“çš„ä¼¤å®³ã€‚è¿™äº›è¯‰æ±‚é¼“åŠ±åæ€ä¸­ç«‹æ€§å‡è®¾ã€ä¿æŠ¤å±æ€§çš„ä½¿ç”¨ä»¥åŠå¼ºåŒ–å—å¤šé‡è¾¹ç¼˜åŒ–å½±å“ç¾¤ä½“çš„æ½œåŠ›ã€‚è¯¥æ–¹æ³•å¼ºè°ƒå…¬å¹³æ€§ä¸èƒ½è„±ç¦»ç¤¾ä¼šè¯­å¢ƒ(social context)ï¼Œå¹¶æŒ‡å‡ºåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæœ‰åŸåˆ™çš„ä¸éƒ¨ç½²(principled non-deployment)å¯èƒ½æ˜¯å¿…è¦çš„å†³ç­–ã€‚é€šè¿‡è·¨è¶Šè®¡ç®—ä¸ç¤¾ä¼šç§‘å­¦çš„è§†è§’ï¼Œæœ¬ç ”ç©¶ä¸ºæ„å»ºæ›´å…·åŒ…å®¹æ€§å’ŒèƒŒæ™¯æ•æ„Ÿæ€§çš„äº¤å‰ç®—æ³•å®è·µæä¾›äº†å¯æ“ä½œçš„æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "27 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2508.17944v1",
      "published_date": "2025-08-25 12:09:04 UTC",
      "updated_date": "2025-08-25 12:09:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:28.565387+00:00"
    },
    {
      "arxiv_id": "2508.17932v1",
      "title": "See What You Need: Query-Aware Visual Intelligence through Reasoning-Perception Loops",
      "title_zh": "è§ä½ æ‰€éœ€ï¼šåŸºäºæ¨ç†-æ„ŸçŸ¥é—­ç¯çš„æŸ¥è¯¢æ„ŸçŸ¥è§†è§‰æ™ºèƒ½",
      "authors": [
        "Zixuan Dong",
        "Baoyun Peng",
        "Yufei Wang",
        "Lin Liu",
        "Xinxin Dong",
        "Yunlong Cao",
        "Xiaodong Wang"
      ],
      "abstract": "Human video comprehension demonstrates dynamic coordination between reasoning and visual attention, adaptively focusing on query-relevant details. However, current long-form video question answering systems employ rigid pipelines that decouple reasoning from perception, leading to either information loss through premature visual abstraction or computational inefficiency through exhaustive processing. The core limitation lies in the inability to adapt visual extraction to specific reasoning requirements, different queries demand fundamentally different visual evidence from the same video content. In this work, we present CAVIA, a training-free framework that revolutionizes video understanding through reasoning, perception coordination. Unlike conventional approaches where visual processing operates independently of reasoning, CAVIA creates a closed-loop system where reasoning continuously guides visual extraction based on identified information gaps. CAVIA introduces three innovations: (1) hierarchical reasoning, guided localization to precise frames; (2) cross-modal semantic bridging for targeted extraction; (3) confidence-driven iterative synthesis. CAVIA achieves state-of-the-art performance on challenging benchmarks: EgoSchema (65.7%, +5.3%), NExT-QA (76.1%, +2.6%), and IntentQA (73.8%, +6.9%), demonstrating that dynamic reasoning-perception coordination provides a scalable paradigm for video understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é•¿è§†é¢‘é—®ç­”ç³»ç»Ÿ(long-form video question answering)ä¸­æ¨ç†ä¸æ„ŸçŸ¥è„±èŠ‚å¯¼è‡´çš„æ•ˆç‡ä½ä¸‹å’Œä¿¡æ¯ä¸¢å¤±é—®é¢˜ï¼Œæå‡ºäº†CAVIAæ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„ç‹¬ç«‹å¤„ç†æ–¹å¼ä¸åŒï¼ŒCAVIAé€šè¿‡æ¨ç†-æ„ŸçŸ¥å¾ªç¯(Reasoning-Perception Loops)æ„å»ºäº†ä¸€ä¸ªé—­ç¯ç³»ç»Ÿï¼Œåˆ©ç”¨æ¨ç†è¿‡ç¨‹åŠ¨æ€æŒ‡å¯¼è§†è§‰æå–ä»¥å¡«è¡¥ä¿¡æ¯ç¼ºå£ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸‰å¤§åˆ›æ–°ï¼šå®ç°ç²¾ç¡®å®šä½çš„åˆ†å±‚æ¨ç†(hierarchical reasoning)ã€ç”¨äºç›®æ ‡æå–çš„è·¨æ¨¡æ€è¯­ä¹‰æ¡¥æ¥(cross-modal semantic bridging)ä»¥åŠç½®ä¿¡åº¦é©±åŠ¨çš„è¿­ä»£ç»¼åˆ(confidence-driven iterative synthesis)ã€‚ä½œä¸ºä¸€ä¸ªæ— éœ€è®­ç»ƒ(training-free)çš„æ¡†æ¶ï¼ŒCAVIAèƒ½å¤Ÿæ ¹æ®ç‰¹å®šæŸ¥è¯¢è‡ªé€‚åº”åœ°è·å–è§†è§‰è¯æ®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCAVIAåœ¨EgoSchemaã€NExT-QAå’ŒIntentQAç­‰æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›çš„(state-of-the-art)æ€§èƒ½ï¼Œå‡†ç¡®ç‡åˆ†åˆ«æå‡äº†5.3%ã€2.6%å’Œ6.9%ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åŠ¨æ€çš„æ¨ç†-æ„ŸçŸ¥åä½œæ˜¯å®ç°å¯æ‰©å±•è§†é¢‘ç†è§£çš„ä¸€ç§é«˜æ•ˆèŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17932v1",
      "published_date": "2025-08-25 12:00:12 UTC",
      "updated_date": "2025-08-25 12:00:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:28.964042+00:00"
    },
    {
      "arxiv_id": "2508.17926v1",
      "title": "AMELIA: A Family of Multi-task End-to-end Language Models for Argumentation",
      "title_zh": "AMELIAï¼šé¢å‘è®ºè¾©çš„å¤šä»»åŠ¡ç«¯åˆ°ç«¯è¯­è¨€æ¨¡å‹ç³»åˆ—",
      "authors": [
        "Henri Savigny",
        "Bruno Yun"
      ],
      "abstract": "Argument mining is a subfield of argumentation that aims to automatically extract argumentative structures and their relations from natural language texts. This paper investigates how a single large language model can be leveraged to perform one or several argument mining tasks. Our contributions are two-fold. First, we construct a multi-task dataset by surveying and converting 19 well-known argument mining datasets from the literature into a unified format. Second, we explore various training strategies using Meta AI's Llama-3.1-8B-Instruct model: (1) fine-tuning on individual tasks, (2) fine-tuning jointly on multiple tasks, and (3) merging models fine-tuned separately on individual tasks. Our experiments show that task-specific fine-tuning significantly improves individual performance across all tasks. Moreover, multi-task fine-tuning maintains strong performance without degradation, suggesting effective transfer learning across related tasks. Finally, we demonstrate that model merging offers a viable compromise: it yields competitive performance while mitigating the computational costs associated with full multi-task fine-tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨å•ä¸€å¤§å‹è¯­è¨€æ¨¡å‹æ‰§è¡Œå¤šé¡¹è®ºè¾©æŒ–æ˜ï¼ˆArgument miningï¼‰ä»»åŠ¡ï¼Œå¹¶æå‡ºäº†AMELIAç³»åˆ—æ¨¡å‹ã€‚ç ”ç©¶è€…é¦–å…ˆé€šè¿‡è°ƒç ”å¹¶å°†19ä¸ªçŸ¥åçš„è®ºè¾©æŒ–æ˜æ•°æ®é›†è½¬åŒ–ä¸ºç»Ÿä¸€æ ¼å¼ï¼Œæ„å»ºäº†ä¸€ä¸ªè¦†ç›–å¹¿æ³›çš„å¤šä»»åŠ¡æ•°æ®é›†ã€‚åŸºäºLlama-3.1-8B-Instructæ¨¡å‹ï¼Œè¯¥ç ”ç©¶æ·±å…¥æ¢ç´¢äº†å•ä»»åŠ¡å¾®è°ƒï¼ˆFine-tuningï¼‰ã€å¤šä»»åŠ¡è”åˆå¾®è°ƒä»¥åŠæ¨¡å‹åˆå¹¶ï¼ˆModel mergingï¼‰ä¸‰ç§è®­ç»ƒç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç‰¹å®šä»»åŠ¡çš„å¾®è°ƒèƒ½æ˜¾è‘—æå‡å•é¡¹ä»»åŠ¡è¡¨ç°ï¼Œè€Œå¤šä»»åŠ¡å¾®è°ƒåˆ™åœ¨ä¸æŸå¤±æ€§èƒ½çš„å‰æä¸‹å®ç°äº†æœ‰æ•ˆçš„è¿ç§»å­¦ä¹ ï¼ˆTransfer learningï¼‰ã€‚æœ€åï¼Œç ”ç©¶è¯æ˜æ¨¡å‹åˆå¹¶æ˜¯åœ¨ç¡®ä¿ç«äº‰æ€§æ€§èƒ½ä¸é™ä½è®¡ç®—æˆæœ¬ä¹‹é—´å–å¾—å¹³è¡¡çš„ä¸€ç§é«˜æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17926v1",
      "published_date": "2025-08-25 11:51:39 UTC",
      "updated_date": "2025-08-25 11:51:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:00:50.093628+00:00"
    },
    {
      "arxiv_id": "2509.03529v1",
      "title": "Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages",
      "title_zh": "æ—¨åœ¨æå‡ä¿¡æ¯äº¤å‰è¯„ä¼°èƒ½åŠ›çš„ AI å·¥å…·å¤šæ¨¡æ€æ–¹æ¡ˆ",
      "authors": [
        "Alejandro Ãlvarez Castro",
        "JoaquÃ­n Ordieres-MerÃ©"
      ],
      "abstract": "Earnings calls represent a uniquely rich and semi-structured source of financial communication, blending scripted managerial commentary with unscripted analyst dialogue. Although recent advances in financial sentiment analysis have integrated multi-modal signals, such as textual content and vocal tone, most systems rely on flat document-level or sentence-level models, failing to capture the layered discourse structure of these interactions. This paper introduces a novel multi-modal framework designed to generate semantically rich and structurally aware embeddings of earnings calls, by encoding them as hierarchical discourse trees. Each node, comprising either a monologue or a question-answer pair, is enriched with emotional signals derived from text, audio, and video, as well as structured metadata including coherence scores, topic labels, and answer coverage assessments. A two-stage transformer architecture is proposed: the first encodes multi-modal content and discourse metadata at the node level using contrastive learning, while the second synthesizes a global embedding for the entire conference. Experimental results reveal that the resulting embeddings form stable, semantically meaningful representations that reflect affective tone, structural logic, and thematic alignment. Beyond financial reporting, the proposed system generalizes to other high-stakes unscripted communicative domains such as tele-medicine, education, and political discourse, offering a robust and explainable approach to multi-modal discourse representation. This approach offers practical utility for downstream tasks such as financial forecasting and discourse evaluation, while also providing a generalizable method applicable to other domains involving high-stakes communication.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è´¢æŠ¥ç”µè¯ä¼šè®®(Earnings calls)ä¸­ç°æœ‰æƒ…ç»ªåˆ†ææ¨¡å‹æ— æ³•æ•æ‰å¤æ‚è¯è¯­ç»“æ„çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„å¤šæ¨¡æ€æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†ä¼šè®®å†…å®¹ç¼–ç ä¸ºåˆ†å±‚è¯è¯­æ ‘(hierarchical discourse trees)ï¼Œé€šè¿‡æ•´åˆæ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘çš„æƒ…æ„Ÿä¿¡å·ï¼Œä»¥åŠä¸€è‡´æ€§å¾—åˆ†(coherence scores)å’Œä¸»é¢˜æ ‡ç­¾ç­‰å…ƒæ•°æ®æ¥ä¸°å¯ŒèŠ‚ç‚¹ä¿¡æ¯ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸¤é˜¶æ®µTransformeræ¶æ„ï¼Œç»“åˆå¯¹æ¯”å­¦ä¹ (contrastive learning)ç”ŸæˆèŠ‚ç‚¹çº§ç¼–ç ï¼Œå¹¶æœ€ç»ˆåˆæˆæ•´ä¸ªä¼šè®®çš„å…¨å±€åµŒå…¥(global embedding)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç”Ÿæˆçš„åµŒå…¥èƒ½æœ‰æ•ˆåæ˜ æƒ…æ„Ÿè¯­æ°”ã€ç»“æ„é€»è¾‘å’Œä¸»é¢˜ä¸€è‡´æ€§ï¼Œå…·æœ‰æé«˜çš„è¯­ä¹‰ç¨³å®šæ€§ã€‚è¯¥æ–¹æ³•ä¸ä»…åœ¨é‡‘èé¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œè¿˜å¯æ¨å¹¿è‡³è¿œç¨‹åŒ»ç–—ã€æ•™è‚²å’Œæ”¿æ²»è¾©è®ºç­‰é«˜é£é™©å³å…´äº¤æµåœºæ™¯ï¼Œä¸ºå¤æ‚çš„å¤šæ¨¡æ€è¯è¯­è¡¨å¾æä¾›äº†ä¸€ç§ç¨³å¥ä¸”å¯è§£é‡Šçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at NLMLT2025 (https://airccse.org/csit/V15N16.html), 15 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.03529v1",
      "published_date": "2025-08-25 11:47:56 UTC",
      "updated_date": "2025-08-25 11:47:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:02.803375+00:00"
    },
    {
      "arxiv_id": "2508.17901v1",
      "title": "Riemannian Optimization for LoRA on the Stiefel Manifold",
      "title_zh": "Stiefel æµå½¢ä¸Š LoRA çš„é»æ›¼ä¼˜åŒ–",
      "authors": [
        "Juneyoung Park",
        "Minjae Kang",
        "Seongbae Lee",
        "Haegang Lee",
        "Seongwan Kim",
        "Jaeho Lee"
      ],
      "abstract": "While powerful, large language models (LLMs) present significant fine-tuning challenges due to their size. Parameter-efficient fine-tuning (PEFT) methods like LoRA provide solutions, yet suffer from critical optimizer inefficiencies; notably basis redundancy in LoRA's $B$ matrix when using AdamW, which fundamentally limits performance. We address this by optimizing the $B$ matrix on the Stiefel manifold, imposing explicit orthogonality constraints that achieve near-perfect orthogonality and full effective rank. This geometric approach dramatically enhances parameter efficiency and representational capacity. Our Stiefel optimizer consistently outperforms AdamW across benchmarks with both LoRA and DoRA, demonstrating that geometric constraints are the key to unlocking LoRA's full potential for effective LLM fine-tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT) è¿‡ç¨‹ä¸­ LoRA å­˜åœ¨çš„ä¼˜åŒ–æ•ˆç‡ä½ä¸‹é—®é¢˜ï¼ŒæŒ‡å‡ºåœ¨ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨æ—¶ LoRA çš„ $B$ çŸ©é˜µå­˜åœ¨åŸºå‘é‡å†—ä½™ (basis redundancy)ï¼Œä»è€Œé™åˆ¶äº†å…¶æ€§èƒ½è¡¨ç°ã€‚ä¸ºè§£å†³è¿™ä¸€ç“¶é¢ˆï¼Œä½œè€…æå‡ºäº†åœ¨ Stiefel manifold ä¸Šå¯¹ $B$ çŸ©é˜µè¿›è¡Œä¼˜åŒ–ï¼Œé€šè¿‡æ–½åŠ æ˜¾å¼çš„æ­£äº¤çº¦æŸ (orthogonality constraints) ä»¥å®ç°è¿‘ä¹å®Œç¾çš„æ­£äº¤æ€§å’Œå…¨æœ‰æ•ˆç§©ã€‚è¿™ç§å‡ ä½•ä¼˜åŒ–æ–¹æ³•æå¤§åœ°æå‡äº†æ¨¡å‹çš„å‚æ•°æ•ˆç‡ä¸è¡¨å¾èƒ½åŠ› (representational capacity)ã€‚å®éªŒè¯æ˜ï¼Œè¯¥ Stiefel ä¼˜åŒ–å™¨åœ¨ LoRA å’Œ DoRA çš„å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ä¸€è‡´ä¼˜äº AdamW ä¼˜åŒ–å™¨ã€‚è¯¥ç ”ç©¶ç»“æœå¼ºè°ƒäº†å‡ ä½•çº¦æŸæ˜¯è§£é” LoRA åœ¨å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒä¸­å…¨éƒ¨æ½œåŠ›çš„æ ¸å¿ƒè¦ç´ ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2508.17901v1",
      "published_date": "2025-08-25 11:15:52 UTC",
      "updated_date": "2025-08-25 11:15:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:38.561140+00:00"
    },
    {
      "arxiv_id": "2508.17900v1",
      "title": "A Defect Classification Framework for AI-Based Software Systems (AI-ODC)",
      "title_zh": "é¢å‘äººå·¥æ™ºèƒ½è½¯ä»¶ç³»ç»Ÿçš„ç¼ºé™·åˆ†ç±»æ¡†æ¶ (AI-ODC)",
      "authors": [
        "Mohammed O. Alannsary"
      ],
      "abstract": "Artificial Intelligence has gained a lot of attention recently, it has been utilized in several fields ranging from daily life activities, such as responding to emails and scheduling appointments, to manufacturing and automating work activities. Artificial Intelligence systems are mainly implemented as software solutions, and it is essential to discover and remove software defects to assure its quality using defect analysis which is one of the major activities that contribute to software quality. Despite the proliferation of AI-based systems, current defect analysis models fail to capture their unique attributes. This paper proposes a framework inspired by the Orthogonal Defect Classification (ODC) paradigm and enables defect analysis of Artificial Intelligence systems while recognizing its special attributes and characteristics. This study demonstrated the feasibility of modifying ODC for AI systems to classify its defects. The ODC was adjusted to accommodate the Data, Learning, and Thinking aspects of AI systems which are newly introduced classification dimensions. This adjustment involved the introduction of an additional attribute to the ODC attributes, the incorporation of a new severity level, and the substitution of impact areas with characteristics pertinent to AI systems. The framework was showcased by applying it to a publicly available Machine Learning bug dataset, with results analyzed through one-way and two-way analysis. The case study indicated that defects occurring during the Learning phase were the most prevalent and were significantly linked to high-severity classifications. In contrast, defects identified in the Thinking phase had a disproportionate effect on trustworthiness and accuracy. These findings illustrate AIODC's capability to identify high-risk defect categories and inform focused quality assurance measures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è½¯ä»¶ç¼ºé™·åˆ†ææ¨¡å‹éš¾ä»¥æ•æ‰äººå·¥æ™ºèƒ½(Artificial Intelligence)ç³»ç»Ÿç‹¬ç‰¹å±æ€§çš„é—®é¢˜ï¼Œæå‡ºäº† AI-ODC æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§å—æ­£äº¤ç¼ºé™·åˆ†ç±»(Orthogonal Defect Classification, ODC)èŒƒå¼å¯å‘å¹¶ä¸“é—¨é’ˆå¯¹ AI ç³»ç»Ÿè®¾è®¡çš„ç¼ºé™·åˆ†ç±»æ¡†æ¶ã€‚AI-ODC é€šè¿‡å¼•å…¥æ•°æ®(Data)ã€å­¦ä¹ (Learning)å’Œæ€ç»´(Thinking)ä¸‰ä¸ªå…¨æ–°çš„åˆ†ç±»ç»´åº¦ï¼Œå¹¶è°ƒæ•´äº†å±æ€§ã€ä¸¥é‡ç­‰çº§å’Œ AI ç›¸å…³ç‰¹æ€§ï¼Œå®ç°äº†å¯¹ AI ç³»ç»Ÿç¼ºé™·çš„ç²¾ç»†åŒ–å»ºæ¨¡ã€‚ç ”ç©¶åˆ©ç”¨å…¬å¼€çš„æœºå™¨å­¦ä¹ (Machine Learning)ç¼ºé™·æ•°æ®é›†è¿›è¡Œäº†æ¡ˆä¾‹åˆ†æï¼Œç»“æœè¡¨æ˜å­¦ä¹ (Learning)é˜¶æ®µçš„ç¼ºé™·æœ€ä¸ºæ™®éä¸”é€šå¸¸å…³è”è¾ƒé«˜çš„ä¸¥é‡ç­‰çº§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°æ€ç»´(Thinking)é˜¶æ®µçš„ç¼ºé™·å¯¹ç³»ç»Ÿçš„å¯ä¿¡åº¦(Trustworthiness)å’Œå‡†ç¡®æ€§(Accuracy)å…·æœ‰æ˜¾è‘—å½±å“ã€‚å®éªŒè¯æ˜ AI-ODC èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«é«˜é£é™©ç¼ºé™·ç±»åˆ«ï¼Œä¸º AI ç³»ç»Ÿçš„è´¨é‡ä¿è¯(Quality Assurance)æªæ–½æä¾›äº†ç§‘å­¦çš„å†³ç­–ä¾æ®ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Article, 19 pages, 6 figures, 8 tables,",
      "pdf_url": "https://arxiv.org/pdf/2508.17900v1",
      "published_date": "2025-08-25 11:15:31 UTC",
      "updated_date": "2025-08-25 11:15:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:20.964196+00:00"
    },
    {
      "arxiv_id": "2508.17894v1",
      "title": "Designing Practical Models for Isolated Word Visual Speech Recognition",
      "title_zh": "å­¤ç«‹è¯è§†è§‰è¯­éŸ³è¯†åˆ«çš„å®ç”¨æ¨¡å‹è®¾è®¡",
      "authors": [
        "Iason Ioannis Panagos",
        "Giorgos Sfikas",
        "Christophoros Nikou"
      ],
      "abstract": "Visual speech recognition (VSR) systems decode spoken words from an input sequence using only the video data. Practical applications of such systems include medical assistance as well as human-machine interactions. A VSR system is typically employed in a complementary role in cases where the audio is corrupt or not available. In order to accurately predict the spoken words, these architectures often rely on deep neural networks in order to extract meaningful representations from the input sequence. While deep architectures achieve impressive recognition performance, relying on such models incurs significant computation costs which translates into increased resource demands in terms of hardware requirements and results in limited applicability in real-world scenarios where resources might be constrained. This factor prevents wider adoption and deployment of speech recognition systems in more practical applications. In this work, we aim to alleviate this issue by developing architectures for VSR that have low hardware costs. Following the standard two-network design paradigm, where one network handles visual feature extraction and another one utilizes the extracted features to classify the entire sequence, we develop lightweight end-to-end architectures by first benchmarking efficient models from the image classification literature, and then adopting lightweight block designs in a temporal convolution network backbone. We create several unified models with low resource requirements but strong recognition performance. Experiments on the largest public database for English words demonstrate the effectiveness and practicality of our developed models. Code and trained models will be made publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³è§†è§‰è¯­éŸ³è¯†åˆ« (Visual Speech Recognition, VSR) ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­å› æ·±åº¦ç¥ç»ç½‘ç»œå¸¦æ¥çš„é«˜è®¡ç®—æˆæœ¬å’Œç¡¬ä»¶èµ„æºé™åˆ¶ã€‚ä¸ºäº†æé«˜å…¶åœ¨èµ„æºå—é™åœºæ™¯ä¸‹çš„é€‚ç”¨æ€§ï¼Œä½œè€…å¼€å‘äº†ä¸€ç³»åˆ—ä½ç¡¬ä»¶æˆæœ¬çš„è½»é‡çº§ç«¯åˆ°ç«¯æ¶æ„ã€‚æ–¹æ¡ˆéµå¾ªæ ‡å‡†çš„åŒç½‘ç»œè®¾è®¡èŒƒå¼ï¼Œå°†è§†è§‰ç‰¹å¾æå– (visual feature extraction) ç½‘ç»œä¸è´Ÿè´£åºåˆ—åˆ†ç±»çš„ç½‘ç»œç›¸ç»“åˆã€‚ç ”ç©¶é¦–å…ˆå¯¹å›¾åƒåˆ†ç±»é¢†åŸŸçš„é«˜æ•ˆæ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯• (benchmarking)ï¼Œéšååœ¨æ—¶é—´å·ç§¯ç½‘ç»œ (temporal convolution network) éª¨å¹²ä¸­å¼•å…¥äº†è½»é‡åŒ–æ¨¡å—è®¾è®¡ã€‚åœ¨ç›®å‰æœ€å¤§çš„å…¬å¼€è‹±è¯­å•è¯æ•°æ®åº“ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¿™äº›ç»Ÿä¸€æ¨¡å‹åœ¨ä¿æŒå¼ºè¯†åˆ«æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½äº†èµ„æºéœ€æ±‚ã€‚è¯¥æˆæœä¸º VSR ç³»ç»Ÿåœ¨åŒ»ç–—è¾…åŠ©å’Œäººæœºäº¤äº’ç­‰å®é™…åœºæ™¯ä¸­çš„å¹¿æ³›éƒ¨ç½²æä¾›äº†æ›´å…·å®è·µä»·å€¼çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Double-column format, 13 pages with references, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17894v1",
      "published_date": "2025-08-25 11:04:36 UTC",
      "updated_date": "2025-08-25 11:04:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:33.065723+00:00"
    },
    {
      "arxiv_id": "2508.17877v1",
      "title": "Edge-Enhanced Vision Transformer Framework for Accurate AI-Generated Image Detection",
      "title_zh": "ç”¨äºç²¾å‡† AI ç”Ÿæˆå›¾åƒæ£€æµ‹çš„è¾¹ç¼˜å¢å¼ºå‹ Vision Transformer æ¡†æ¶",
      "authors": [
        "Dabbrata Das",
        "Mahshar Yahan",
        "Md Tareq Zaman",
        "Md Rishadul Bayesh"
      ],
      "abstract": "The rapid advancement of generative models has led to a growing prevalence of highly realistic AI-generated images, posing significant challenges for digital forensics and content authentication. Conventional detection methods mainly rely on deep learning models that extract global features, which often overlook subtle structural inconsistencies and demand substantial computational resources. To address these limitations, we propose a hybrid detection framework that combines a fine-tuned Vision Transformer (ViT) with a novel edge-based image processing module. The edge-based module computes variance from edge-difference maps generated before and after smoothing, exploiting the observation that AI-generated images typically exhibit smoother textures, weaker edges, and reduced noise compared to real images. When applied as a post-processing step on ViT predictions, this module enhances sensitivity to fine-grained structural cues while maintaining computational efficiency. Extensive experiments on the CIFAKE, Artistic, and Custom Curated datasets demonstrate that the proposed framework achieves superior detection performance across all benchmarks, attaining 97.75% accuracy and a 97.77% F1-score on CIFAKE, surpassing widely adopted state-of-the-art models. These results establish the proposed method as a lightweight, interpretable, and effective solution for both still images and video frames, making it highly suitable for real-world applications in automated content verification and digital forensics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è¾¹ç¼˜å¢å¼ºçš„ Vision Transformer (ViT) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”Ÿæˆæ¨¡å‹å¸¦æ¥çš„é«˜åº¦çœŸå® AI ç”Ÿæˆå›¾åƒæ£€æµ‹éš¾é¢˜ã€‚ä¼ ç»Ÿæ£€æµ‹æ–¹æ³•ä¸»è¦ä¾èµ–æå–å…¨å±€ç‰¹å¾çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¾€å¾€å¿½è§†äº†ç»†å¾®çš„ç»“æ„ä¸ä¸€è‡´æ€§ä¸”è®¡ç®—èµ„æºéœ€æ±‚å·¨å¤§ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆå¾®è°ƒåçš„ ViT ä¸åˆ›æ–°çš„åŸºäºè¾¹ç¼˜çš„å›¾åƒå¤„ç†æ¨¡å—ï¼Œåˆ©ç”¨ AI ç”Ÿæˆå›¾åƒé€šå¸¸å…·æœ‰æ›´å¹³æ»‘çº¹ç†ã€æ›´å¼±è¾¹ç¼˜å’Œæ›´å°‘å™ªå£°çš„ç‰©ç†ç‰¹å¾è¿›è¡Œè¯†åˆ«ã€‚è¾¹ç¼˜å¤„ç†æ¨¡å—é€šè¿‡è®¡ç®—å¹³æ»‘å‰åçš„è¾¹ç¼˜å·®å¼‚å›¾æ–¹å·®ï¼Œä½œä¸º ViT é¢„æµ‹çš„åå¤„ç†æ­¥éª¤ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¯¹ç»†ç²’åº¦ç»“æ„çº¿ç´¢çš„æ•æ„Ÿæ€§ã€‚åœ¨ CIFAKEã€Artistic å’Œè‡ªå®šä¹‰æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­å‡è¡¨ç°å“è¶Šï¼Œå…¶ä¸­åœ¨ CIFAKE ä¸Šè¾¾åˆ°äº† 97.75% çš„å‡†ç¡®ç‡å’Œ 97.77% çš„ F1-scoreã€‚è¯¥æ–¹æ³•è¢«è¯æ˜æ˜¯ä¸€ç§è½»é‡åŒ–ã€å¯è§£é‡Šä¸”æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œé€‚ç”¨äºé™æ€å›¾åƒå’Œè§†é¢‘å¸§ï¼Œä¸ºè‡ªåŠ¨åŒ–å†…å®¹éªŒè¯å’Œæ•°å­—å–è¯æä¾›äº†å¯é çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17877v1",
      "published_date": "2025-08-25 10:30:56 UTC",
      "updated_date": "2025-08-25 10:30:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:46.956691+00:00"
    },
    {
      "arxiv_id": "2508.17874v2",
      "title": "Vocoder-Projected Feature Discriminator",
      "title_zh": "å£°ç å™¨æŠ•å½±ç‰¹å¾åˆ¤åˆ«å™¨",
      "authors": [
        "Takuhiro Kaneko",
        "Hirokazu Kameoka",
        "Kou Tanaka",
        "Yuto Kondo"
      ],
      "abstract": "In text-to-speech (TTS) and voice conversion (VC), acoustic features, such as mel spectrograms, are typically used as synthesis or conversion targets owing to their compactness and ease of learning. However, because the ultimate goal is to generate high-quality waveforms, employing a vocoder to convert these features into waveforms and applying adversarial training in the time domain is reasonable. Nevertheless, upsampling the waveform introduces significant time and memory overheads. To address this issue, we propose a vocoder-projected feature discriminator (VPFD), which uses vocoder features for adversarial training. Experiments on diffusion-based VC distillation demonstrated that a pretrained and frozen vocoder feature extractor with a single upsampling step is necessary and sufficient to achieve a VC performance comparable to that of waveform discriminators while reducing the training time and memory consumption by 9.6 and 11.4 times, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬è½¬è¯­éŸ³(TTS)å’Œè¯­éŸ³è½¬æ¢(VC)ä¸­ï¼Œå°†å£°å­¦ç‰¹å¾è½¬åŒ–ä¸ºæ³¢å½¢å¹¶è¿›è¡Œæ—¶åŸŸå¯¹æŠ—è®­ç»ƒæ‰€äº§ç”Ÿçš„é«˜æ˜‚è®¡ç®—ä¸å†…å­˜å¼€é”€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å£°ç å™¨æŠ•å½±ç‰¹å¾åˆ¤åˆ«å™¨(Vocoder-Projected Feature Discriminator, VPFD)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒä¸”å†»ç»“çš„å£°ç å™¨ç‰¹å¾æå–å™¨é…åˆå•æ­¥ä¸Šé‡‡æ ·ï¼Œç›´æ¥åœ¨å£°ç å™¨ç‰¹å¾ç©ºé—´è¿›è¡Œå¯¹æŠ—è®­ç»ƒï¼Œé¿å…äº†å®Œå…¨æ³¢å½¢ä¸Šé‡‡æ ·å¸¦æ¥çš„è´Ÿæ‹…ã€‚åœ¨åŸºäºæ‰©æ•£(Diffusion)çš„VCè’¸é¦å®éªŒä¸­ï¼ŒVPFDåœ¨è¯­éŸ³è½¬æ¢æ€§èƒ½ä¸Šè¾¾åˆ°äº†ä¸ä¼ ç»Ÿæ³¢å½¢åˆ¤åˆ«å™¨(Waveform Discriminators)ç›¸å½“çš„æ°´å¹³ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿è¯åˆæˆè´¨é‡çš„åŒæ—¶ï¼Œå°†è®­ç»ƒæ—¶é—´å’Œå†…å­˜æ¶ˆè€—åˆ†åˆ«å¤§å¹…é™ä½äº†9.6å€å’Œ11.4å€ï¼Œä¸ºå®ç°é«˜æ•ˆçš„é«˜è´¨é‡è¯­éŸ³åˆæˆæä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "stat.ML"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to Interspeech 2025. Project page: https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/vpfd/",
      "pdf_url": "https://arxiv.org/pdf/2508.17874v2",
      "published_date": "2025-08-25 10:29:08 UTC",
      "updated_date": "2025-08-27 02:31:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:30.860489+00:00"
    },
    {
      "arxiv_id": "2508.17868v1",
      "title": "FasterVoiceGrad: Faster One-step Diffusion-Based Voice Conversion with Adversarial Diffusion Conversion Distillation",
      "title_zh": "FasterVoiceGradï¼šåŸºäºå¯¹æŠ—æ‰©æ•£è½¬æ¢è’¸é¦çš„æ›´å¿«é€Ÿå•æ­¥æ‰©æ•£è¯­éŸ³è½¬æ¢",
      "authors": [
        "Takuhiro Kaneko",
        "Hirokazu Kameoka",
        "Kou Tanaka",
        "Yuto Kondo"
      ],
      "abstract": "A diffusion-based voice conversion (VC) model (e.g., VoiceGrad) can achieve high speech quality and speaker similarity; however, its conversion process is slow owing to iterative sampling. FastVoiceGrad overcomes this limitation by distilling VoiceGrad into a one-step diffusion model. However, it still requires a computationally intensive content encoder to disentangle the speaker's identity and content, which slows conversion. Therefore, we propose FasterVoiceGrad, a novel one-step diffusion-based VC model obtained by simultaneously distilling a diffusion model and content encoder using adversarial diffusion conversion distillation (ADCD), where distillation is performed in the conversion process while leveraging adversarial and score distillation training. Experimental evaluations of one-shot VC demonstrated that FasterVoiceGrad achieves competitive VC performance compared to FastVoiceGrad, with 6.6-6.9 and 1.8 times faster speed on a GPU and CPU, respectively.",
      "tldr_zh": "åŸºäºæ‰©æ•£æ¨¡å‹(diffusion-based)çš„è¯­éŸ³è½¬æ¢(VC)æ¨¡å‹å¦‚ VoiceGrad è™½ç„¶éŸ³è´¨ä¼˜å¼‚ï¼Œä½†è¿­ä»£é‡‡æ ·å¯¼è‡´å…¶è½¬æ¢é€Ÿåº¦è¾ƒæ…¢ã€‚å°½ç®¡ FastVoiceGrad å°†å…¶ç®€åŒ–ä¸ºå•æ­¥æ¨¡å‹ï¼Œä½†å…¶ content encoder ä»å­˜åœ¨è¾ƒé«˜çš„è®¡ç®—å¼€é”€ï¼Œå½±å“äº†æ•´ä½“æ•ˆç‡ã€‚è¯¥ç ”ç©¶æå‡ºäº† FasterVoiceGradï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¯¹æŠ—æ‰©æ•£è½¬æ¢è’¸é¦(Adversarial Diffusion Conversion Distillation, ADCD)æŠ€æœ¯åŒæ—¶å¯¹æ‰©æ•£æ¨¡å‹å’Œ content encoder è¿›è¡Œè’¸é¦çš„æ–°å‹å•æ­¥æ¨¡å‹ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å¯¹æŠ—è®­ç»ƒ(adversarial training)ä¸è¯„åˆ†è’¸é¦(score distillation)ç­–ç•¥ï¼Œæ˜¾è‘—ä¼˜åŒ–äº†è½¬æ¢æµç¨‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ one-shot VC ä»»åŠ¡ä¸­ï¼ŒFasterVoiceGrad å–å¾—äº†ä¸ FastVoiceGrad ç›¸å½“çš„æ€§èƒ½è¡¨ç°ã€‚åœ¨ç¡¬ä»¶åŠ é€Ÿæ–¹é¢ï¼Œå…¶åœ¨ GPU å’Œ CPU ä¸Šçš„è½¬æ¢é€Ÿåº¦åˆ†åˆ«æ¯” FastVoiceGrad å¿« 6.6-6.9 å€å’Œ 1.8 å€ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "stat.ML"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to Interspeech 2025. Project page: https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/fastervoicegrad/",
      "pdf_url": "https://arxiv.org/pdf/2508.17868v1",
      "published_date": "2025-08-25 10:23:24 UTC",
      "updated_date": "2025-08-25 10:23:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:38.083111+00:00"
    },
    {
      "arxiv_id": "2508.17867v2",
      "title": "Ada-TransGNN: An Air Quality Prediction Model Based On Adaptive Graph Convolutional Networks",
      "title_zh": "Ada-TransGNNï¼šåŸºäºè‡ªé€‚åº”å›¾å·ç§¯ç½‘ç»œçš„ç©ºæ°”è´¨é‡é¢„æµ‹æ¨¡å‹",
      "authors": [
        "Dan Wang",
        "Feng Jiang",
        "Zhanquan Wang"
      ],
      "abstract": "Accurate air quality prediction is becoming increasingly important in the environmental field. To address issues such as low prediction accuracy and slow real-time updates in existing models, which lead to lagging prediction results, we propose a Transformer-based spatiotemporal data prediction method (Ada-TransGNN) that integrates global spatial semantics and temporal behavior. The model constructs an efficient and collaborative spatiotemporal block set comprising a multi-head attention mechanism and a graph convolutional network to extract dynamically changing spatiotemporal dependency features from complex air quality monitoring data. Considering the interaction relationships between different monitoring points, we propose an adaptive graph structure learning module, which combines spatiotemporal dependency features in a data-driven manner to learn the optimal graph structure, thereby more accurately capturing the spatial relationships between monitoring points. Additionally, we design an auxiliary task learning module that enhances the decoding capability of temporal relationships by integrating spatial context information into the optimal graph structure representation, effectively improving the accuracy of prediction results. We conducted comprehensive evaluations on a benchmark dataset and a novel dataset (Mete-air). The results demonstrate that our model outperforms existing state-of-the-art prediction models in short-term and long-term predictions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Ada-TransGNNï¼Œä¸€ç§åŸºäºTransformerçš„æ—¶ç©ºæ•°æ®é¢„æµ‹æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç©ºæ°”è´¨é‡é¢„æµ‹ä¸­ç²¾åº¦ä½å’Œå®æ—¶æ›´æ–°æ…¢å¯¼è‡´çš„é¢„æµ‹æ»åé—®é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡é›†æˆå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶(Multi-head attention)å’Œå›¾å·ç§¯ç½‘ç»œ(Graph Convolutional Network, GCN)æ„æˆçš„æ—¶ç©ºå—ï¼Œä»å¤æ‚ç›‘æµ‹æ•°æ®ä¸­æå–åŠ¨æ€å˜åŒ–çš„ç‰¹å¾ã€‚é’ˆå¯¹ç›‘æµ‹ç‚¹é—´çš„äº¤äº’å…³ç³»ï¼Œç ”ç©¶å¼•å…¥äº†è‡ªé€‚åº”å›¾ç»“æ„å­¦ä¹ æ¨¡å—(Adaptive graph structure learning module)ï¼Œä»¥æ•°æ®é©±åŠ¨çš„æ–¹å¼å­¦ä¹ æœ€ä¼˜å›¾ç»“æ„å¹¶å‡†ç¡®æ•æ‰ç©ºé—´å…³ç³»ã€‚åŒæ—¶ï¼Œæ¨¡å‹è®¾è®¡äº†è¾…åŠ©ä»»åŠ¡å­¦ä¹ æ¨¡å—(Auxiliary task learning module)ï¼Œé€šè¿‡æ•´åˆç©ºé—´èƒŒæ™¯ä¿¡æ¯æ¥å¢å¼ºæ—¶é—´å…³ç³»çš„è§£ç èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥æå‡é¢„æµ‹ç²¾åº¦ã€‚åœ¨åŸºå‡†æ•°æ®é›†å’ŒMete-airæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒAda-TransGNNåœ¨çŸ­æœŸå’Œé•¿æœŸé¢„æµ‹æ–¹é¢å‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 4 figures, 3 tables. This paper is accepted by ICONIP 2025 but not published",
      "pdf_url": "https://arxiv.org/pdf/2508.17867v2",
      "published_date": "2025-08-25 10:22:03 UTC",
      "updated_date": "2025-08-26 01:47:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:55.185612+00:00"
    },
    {
      "arxiv_id": "2508.19290v1",
      "title": "Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation",
      "title_zh": "é’ˆå¯¹ LiDAR åˆ†å‰²çš„é«˜æ•ˆåŸºäºæ¨¡å‹å¯¹æŠ—æ”»å‡»å‡€åŒ–",
      "authors": [
        "Alexandros Gkillas",
        "Ioulia Kapsali",
        "Nikos Piperigkos",
        "Aris S. Lalos"
      ],
      "abstract": "LiDAR-based segmentation is essential for reliable perception in autonomous vehicles, yet modern segmentation networks are highly susceptible to adversarial attacks that can compromise safety. Most existing defenses are designed for networks operating directly on raw 3D point clouds and rely on large, computationally intensive generative models. However, many state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D range view representations. Despite their widespread adoption, dedicated lightweight adversarial defenses for this domain remain largely unexplored. We introduce an efficient model-based purification framework tailored for adversarial defense in 2D range-view LiDAR segmentation. We propose a direct attack formulation in the range-view domain and develop an explainable purification network based on a mathematical justified optimization problem, achieving strong adversarial resilience with minimal computational overhead. Our method achieves competitive performance on open benchmarks, consistently outperforming generative and adversarial training baselines. More importantly, real-world deployment on a demo vehicle demonstrates the framework's ability to deliver accurate operation in practical autonomous driving scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­ LiDAR segmentation æ˜“å— Adversarial Attacks çš„å®‰å…¨é£é™©ï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„åŸºäºæ¨¡å‹çš„å‡€åŒ– (Model-Based Purification) æ¡†æ¶ã€‚ä¸ç›®å‰ä¸»æµä¾§é‡äº 3D Point Clouds ä¸”è®¡ç®—å¯†é›†çš„æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ¡ˆä¸“é—¨é’ˆå¯¹æ›´å…·æ•ˆç‡çš„ 2D range-view è¡¨ç¤ºè¿›è¡Œä¼˜åŒ–ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸè½»é‡åŒ–é˜²å¾¡æŠ€æœ¯çš„ç©ºç™½ã€‚ç ”ç©¶è€…åœ¨ range-view é¢†åŸŸæå‡ºäº†ç›´æ¥æ”»å‡»è¡¨è¿°ï¼Œå¹¶åŸºäºæ•°å­¦ä¼˜åŒ–ç†è®ºå¼€å‘äº†ä¸€ä¸ªå…·æœ‰å¯è§£é‡Šæ€§çš„å‡€åŒ–ç½‘ç»œã€‚è¯¥æ–¹æ³•åœ¨ä¿æŒæä½è®¡ç®—å¼€é”€çš„åŒæ—¶å®ç°äº†æå¼ºçš„å¯¹æŠ—éŸ§æ€§ï¼Œåœ¨å…¬å¼€åŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½ä¼˜äº Generative Models å’Œ Adversarial Training ç­‰ä¼ ç»ŸåŸºçº¿æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å·²åœ¨çœŸå®æ¼”ç¤ºè½¦è¾†ä¸ŠæˆåŠŸå®Œæˆéƒ¨ç½²ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­ä¿éšœæ„ŸçŸ¥ç³»ç»Ÿå‡†ç¡®è¿è¡Œçš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19290v1",
      "published_date": "2025-08-25 10:14:10 UTC",
      "updated_date": "2025-08-25 10:14:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:57.898940+00:00"
    },
    {
      "arxiv_id": "2508.17860v1",
      "title": "AVAM: Universal Training-free Adaptive Visual Anchoring Embedded into Multimodal Large Language Model for Multi-image Question Answering",
      "title_zh": "AVAMï¼šé›†æˆäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„é€šç”¨å…è®­ç»ƒè‡ªé€‚åº”è§†è§‰é”šå®šæŠ€æœ¯ï¼Œç”¨äºå¤šå›¾é—®ç­”",
      "authors": [
        "Kang Zeng",
        "Guojin Zhong",
        "Jintao Cheng",
        "Jin Yuan",
        "Zhiyong Li"
      ],
      "abstract": "The advancement of Multimodal Large Language Models (MLLMs) has driven significant progress in Visual Question Answering (VQA), evolving from Single to Multi Image VQA (MVQA). However, the increased number of images in MVQA inevitably introduces substantial visual redundancy that is irrelevant to question answering, negatively impacting both accuracy and efficiency. To address this issue, existing methods lack flexibility in controlling the number of compressed visual tokens and tend to produce discrete visual fragments, which hinder MLLMs' ability to comprehend images holistically. In this paper, we propose a straightforward yet universal Adaptive Visual Anchoring strategy, which can be seamlessly integrated into existing MLLMs, offering significant accuracy improvements through adaptive compression. Meanwhile, to balance the results derived from both global and compressed visual input, we further introduce a novel collaborative decoding mechanism, enabling optimal performance. Extensive experiments validate the effectiveness of our method, demonstrating consistent performance improvements across various MLLMs. The code will be publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AVAMï¼Œä¸€ç§é€šç”¨çš„å…è®­ç»ƒè‡ªé€‚åº”è§†è§‰é”šå®šï¼ˆTraining-free Adaptive Visual Anchoringï¼‰ç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³å¤šå›¾è§†è§‰é—®ç­”ï¼ˆMVQAï¼‰ä¸­ç”±äºå¤§é‡å†—ä½™è§†è§‰ä¿¡æ¯å¯¼è‡´çš„å‡†ç¡®ç‡ä¸æ•ˆç‡ä¸‹é™é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨å‹ç¼©è§†è§‰Tokenï¼ˆVisual tokensï¼‰æ—¶ç¼ºä¹çµæ´»æ€§ä¸”ç ´åå›¾åƒæ•´ä½“ç†è§£çš„ç¼ºé™·ï¼ŒAVAMé€šè¿‡è‡ªé€‚åº”å‹ç¼©æŠ€æœ¯å®ç°äº†ä¸ç°æœ‰è¶…å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ— ç¼é›†æˆã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº†ä¸€ç§åˆ›æ–°çš„ååŒè§£ç æœºåˆ¶ï¼ˆCollaborative decoding mechanismï¼‰ï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†å…¨å±€ä¸å‹ç¼©è§†è§‰è¾“å…¥ä¹‹é—´çš„ä¿¡æ¯ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒAVAMåœ¨å¤šç§ä¸åŒçš„MLLMsæ¶æ„ä¸‹å‡èƒ½æ˜¾è‘—ä¸”ç¨³å®šåœ°æå‡æ¨¡å‹è¡¨ç°ã€‚è¯¥æ–¹æ³•ä¸ä»…æé«˜äº†å¤šå›¾åœºæ™¯ä¸‹çš„ä»»åŠ¡ç²¾åº¦ï¼Œè¿˜å…¼é¡¾äº†å¤„ç†æ•ˆç‡ï¼Œä¸ºå¤šæ¨¡æ€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨å¤æ‚è§†è§‰ä»»åŠ¡ä¸­çš„åº”ç”¨æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17860v1",
      "published_date": "2025-08-25 10:10:46 UTC",
      "updated_date": "2025-08-25 10:10:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:01:52.782970+00:00"
    },
    {
      "arxiv_id": "2508.19289v1",
      "title": "Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation",
      "title_zh": "åƒè®¾è®¡å¸ˆä¸€æ ·å®¡è§†ï¼šåŸºäºè®¾è®¡å¸ˆç‰¹å¾å¢å¼ºçš„æ— ç›‘ç£å¹»ç¯ç‰‡è´¨é‡è¯„ä¼°ç ”ç©¶",
      "authors": [
        "Tai Inui",
        "Steven Oh",
        "Magdeline Kuan"
      ],
      "abstract": "We present an unsupervised slide-quality assessment pipeline that combines seven expert-inspired visual-design metrics (whitespace, colorfulness, edge density, brightness contrast, text density, color harmony, layout balance) with CLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate presentation slides. Trained on 12k professional lecture slides and evaluated on six academic talks (115 slides), our method achieved Pearson correlations up to 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores from leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude Sonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual ratings, discriminant validity against speaker-delivery scores, and exploratory alignment with overall impressions. Our results show that augmenting low-level design cues with multimodal embeddings closely approximates audience perceptions of slide quality, enabling scalable, objective feedback in real time.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„æ¼”ç¤ºæ–‡ç¨¿è´¨é‡è¯„ä¼°æµæ°´çº¿ï¼Œé€šè¿‡ç»“åˆä¸ƒç§å—ä¸“å®¶å¯å‘çš„è®¾è®¡æŒ‡æ ‡ï¼ˆåŒ…æ‹¬ whitespace, colorfulness, edge density, brightness contrast, text density, color harmony, layout balanceï¼‰ä¸ CLIP-ViT embeddingsï¼Œå¹¶åˆ©ç”¨åŸºäº Isolation Forest çš„å¼‚å¸¸å¾—åˆ†æ¥è¯„ä¼°å¹»ç¯ç‰‡ã€‚è¯¥æ–¹æ³•åœ¨ 1.2 ä¸‡å¼ ä¸“ä¸šè®²åº§å¹»ç¯ç‰‡ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå®éªŒç»“æœè¡¨æ˜å…¶ä¸äººç±»è§†è§‰è´¨é‡è¯„åˆ†çš„ Pearson correlations é«˜è¾¾ 0.83ï¼Œæ€§èƒ½è¡¨ç°æ˜¯ ChatGPT o4-mini-high, ChatGPT o3, Claude Sonnet 4 å’Œ Gemini 2.5 Pro ç­‰é¢†å…ˆè§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) çš„ 1.79 å€è‡³ 3.23 å€ã€‚ç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ–¹æ³•åœ¨è§†è§‰è¯„åˆ†ä¸Šçš„èšåˆæ•ˆåº¦ (convergent validity) ä»¥åŠé’ˆå¯¹æ¼”è®²è€…è¡¨ç°è¯„åˆ†çš„åˆ¤åˆ«æ•ˆåº¦ (discriminant validity)ã€‚ç»“æœè¯æ˜ï¼Œåˆ©ç”¨å¤šæ¨¡æ€åµŒå…¥å¢å¼ºåº•å±‚è®¾è®¡çº¿ç´¢å¯ä»¥é«˜åº¦è¿‘ä¼¼è§‚ä¼—å¯¹å¹»ç¯ç‰‡è´¨é‡çš„æ„ŸçŸ¥ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°å®æ—¶ã€å®¢è§‚ä¸”å¯æ‰©å±•çš„å¹»ç¯ç‰‡è´¨é‡åé¦ˆæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.19289v1",
      "published_date": "2025-08-25 10:07:58 UTC",
      "updated_date": "2025-08-25 10:07:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:02:09.760982+00:00"
    },
    {
      "arxiv_id": "2508.17857v1",
      "title": "VISA: Group-wise Visual Token Selection and Aggregation via Graph Summarization for Efficient MLLMs Inference",
      "title_zh": "VISAï¼šåŸºäºå›¾æ‘˜è¦çš„åˆ†ç»„è§†è§‰è¯å…ƒé€‰æ‹©ä¸èšåˆï¼Œå®ç°é«˜æ•ˆ MLLM æ¨ç†",
      "authors": [
        "Pengfei Jiang",
        "Hanjun Li",
        "Linglan Zhao",
        "Fei Chao",
        "Ke Yan",
        "Shouhong Ding",
        "Rongrong Ji"
      ],
      "abstract": "In this study, we introduce a novel method called group-wise \\textbf{VI}sual token \\textbf{S}election and \\textbf{A}ggregation (VISA) to address the issue of inefficient inference stemming from excessive visual tokens in multimoal large language models (MLLMs). Compared with previous token pruning approaches, our method can preserve more visual information while compressing visual tokens. We first propose a graph-based visual token aggregation (VTA) module. VTA treats each visual token as a node, forming a graph based on semantic similarity among visual tokens. It then aggregates information from removed tokens into kept tokens based on this graph, producing a more compact visual token representation. Additionally, we introduce a group-wise token selection strategy (GTS) to divide visual tokens into kept and removed ones, guided by text tokens from the final layers of each group. This strategy progressively aggregates visual information, enhancing the stability of the visual information extraction process. We conduct comprehensive experiments on LLaVA-1.5, LLaVA-NeXT, and Video-LLaVA across various benchmarks to validate the efficacy of VISA. Our method consistently outperforms previous methods, achieving a superior trade-off between model performance and inference speed. The code is available at https://github.com/mobiushy/VISA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)ä¸­å› è§†è§‰Tokenè¿‡å¤šå¯¼è‡´çš„æ¨ç†æ•ˆç‡ä½ä¸‹é—®é¢˜ï¼Œæå‡ºäº†VISAï¼ˆGroup-wise Visual Token Selection and Aggregationï¼‰æ–¹æ³•ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥åŸºäºå›¾çš„è§†è§‰Tokenèšåˆæ¨¡å—(VTA)ï¼Œåˆ©ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦(semantic similarity)æ„å»ºå›¾ç»“æ„ï¼Œå°†å¾…ç§»é™¤Tokençš„ä¿¡æ¯æœ‰æ•ˆæ•´åˆè‡³ä¿ç•™Tokenä¸­ï¼Œä»¥åœ¨å‹ç¼©è¿‡ç¨‹ä¸­æœ€å¤§é™åº¦ä¿ç•™è§†è§‰ç»†èŠ‚ã€‚åŒæ—¶ï¼Œç ”ç©¶é‡‡ç”¨äº†åˆ†ç»„Tokené€‰æ‹©ç­–ç•¥(GTS)ï¼Œåœ¨æ–‡æœ¬Tokençš„å¼•å¯¼ä¸‹é€æ­¥ç­›é€‰å¹¶èšåˆè§†è§‰ä¿¡æ¯ï¼Œæ˜¾è‘—å¢å¼ºäº†æå–è¿‡ç¨‹çš„ç¨³å®šæ€§ã€‚å®éªŒç»“æœåœ¨LLaVA-1.5ã€LLaVA-NeXTå’ŒVideo-LLaVAç­‰å¤šä¸ªåŸºå‡†ä¸ŠéªŒè¯äº†VISAçš„æœ‰æ•ˆæ€§ã€‚æœ€ç»ˆç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶å¤§å¹…æå‡äº†æ¨ç†é€Ÿåº¦ï¼Œåœ¨æ€§èƒ½ä¸é€Ÿåº¦çš„æƒè¡¡(trade-off)ä¸Šä¼˜äºä»¥å¾€çš„Tokenå‰ªææ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACMMM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17857v1",
      "published_date": "2025-08-25 10:07:07 UTC",
      "updated_date": "2025-08-25 10:07:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:02:29.553825+00:00"
    },
    {
      "arxiv_id": "2508.17850v8",
      "title": "GEPO: Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning",
      "title_zh": "GEPOï¼šé¢å‘ç¨³å®šå¼‚æ„å¼ºåŒ–å­¦ä¹ çš„ç»„æœŸæœ›ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Han Zhang",
        "Ruibin Zheng",
        "Zexuan Yi",
        "Zhuo Zhang",
        "Hanyang Peng",
        "Hui Wang",
        "Zike Yuan",
        "Cai Ke",
        "Shiwei Chen",
        "Jiacheng Yang",
        "Yangning Li",
        "Xiang Li",
        "Jiangyue Yan",
        "Yaoqi Liu",
        "Liwen Jing",
        "Jiayin Qi",
        "Ruifeng Xu",
        "Binxing Fang",
        "Yue Yu"
      ],
      "abstract": "As single-center computing approaches power constraints, decentralized training becomes essential. However, traditional Reinforcement Learning (RL) methods, crucial for enhancing large model post-training, cannot adapt to decentralized distributed training due to the tight coupling between parameter learning and rollout sampling. For this, we propose HeteroRL, a heterogeneous RL architecture that decouples these processes, enabling stable training across geographically distributed nodes connected via the Internet. The core component is Group Expectation Policy Optimization (GEPO), an asynchronous RL algorithm robust to latency caused by network delays or heterogeneity in computational resources. Our study reveals that high latency significantly increases KL divergence, leading to higher variance of importance weights and training instability. GEPO mitigates this issue by using group expectation weighting to exponentially reduce the variance of importance weights, with theoretical guarantees. Experiments show GEPO achieves superior stability - only a 3% performance drop from online to 1800s latency-and reduces the best-to-last gap by 85% versus GSPO (1.8 vs. 12.0) while attaining the highest scores, highlighting its effectiveness in decentralized, resource-heterogeneous environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å•ä¸­å¿ƒè®¡ç®—å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†HeteroRLæ¶æ„ï¼Œæ—¨åœ¨é€šè¿‡è§£è€¦å‚æ•°å­¦ä¹ ä¸é‡‡æ ·è¿‡ç¨‹ï¼Œå®ç°è·¨åœ°åŸŸåˆ†å¸ƒå¼èŠ‚ç‚¹çš„å»ä¸­å¿ƒåŒ–å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚ä¸ºäº†åº”å¯¹ç½‘ç»œå»¶è¿Ÿå’Œè®¡ç®—èµ„æºå¼‚æ„æ€§å¸¦æ¥çš„è®­ç»ƒä¸ç¨³å®šï¼Œç ”ç©¶è€…å¼€å‘äº†æ ¸å¿ƒç®—æ³•Group Expectation Policy Optimization (GEPO)ã€‚è¯¥ç®—æ³•é€šè¿‡group expectation weightingæŠ€æœ¯ï¼Œä»ç†è®ºä¸Šè§£å†³äº†é«˜å»¶è¿Ÿå¯¼è‡´çš„KL divergenceå¢åŠ ä»¥åŠimportance weightsæ–¹å·®è¿‡å¤§çš„é—®é¢˜ï¼Œä»è€Œæ˜¾è‘—æå‡äº†ç®—æ³•çš„é²æ£’æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGEPOåœ¨å»¶è¿Ÿé«˜è¾¾1800ç§’çš„æƒ…å†µä¸‹ä»…æœ‰3%çš„æ€§èƒ½ä¸‹é™ï¼Œä¸”ç›¸æ¯”GSPOå°†best-to-lastå·®è·ç¼©å°äº†85%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†GEPOåœ¨èµ„æºå¼‚æ„çš„å»ä¸­å¿ƒåŒ–ç¯å¢ƒä¸­å…·æœ‰å“è¶Šçš„ç¨³å®šæ€§å’Œæœ‰æ•ˆæ€§ï¼Œä¸ºå¤§è§„æ¨¡æ¨¡å‹åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„é«˜æ•ˆè®­ç»ƒæä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17850v8",
      "published_date": "2025-08-25 09:57:35 UTC",
      "updated_date": "2025-12-01 08:13:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:02:42.082242+00:00"
    },
    {
      "arxiv_id": "2509.00057v1",
      "title": "From Data to Decision: A Multi-Stage Framework for Class Imbalance Mitigation in Optical Network Failure Analysis",
      "title_zh": "ä»æ•°æ®åˆ°å†³ç­–ï¼šå…‰ç½‘ç»œæ•…éšœåˆ†æä¸­ç±»åˆ«ä¸å¹³è¡¡ç¼“è§£çš„å¤šé˜¶æ®µæ¡†æ¶",
      "authors": [
        "Yousuf Moiz Ali",
        "Jaroslaw E. Prilepsky",
        "Nicola Sambo",
        "Joao Pedro",
        "Mohammad M. Hosseini",
        "Antonio Napoli",
        "Sergei K. Turitsyn",
        "Pedro Freire"
      ],
      "abstract": "Machine learning-based failure management in optical networks has gained significant attention in recent years. However, severe class imbalance, where normal instances vastly outnumber failure cases, remains a considerable challenge. While pre- and in-processing techniques have been widely studied, post-processing methods are largely unexplored. In this work, we present a direct comparison of pre-, in-, and post-processing approaches for class imbalance mitigation in failure detection and identification using an experimental dataset. For failure detection, post-processing methods-particularly Threshold Adjustment-achieve the highest F1 score improvement (up to 15.3%), while Random Under-Sampling provides the fastest inference. In failure identification, GenAI methods deliver the most substantial performance gains (up to 24.2%), whereas post-processing shows limited impact in multi-class settings. When class overlap is present and latency is critical, over-sampling methods such as the SMOTE are most effective; without latency constraints, Meta-Learning yields the best results. In low-overlap scenarios, Generative AI approaches provide the highest performance with minimal inference time.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå¤šé˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…‰ç½‘ç»œæ•…éšœåˆ†æ (Optical Network Failure Analysis) ä¸­ä¸¥é‡çš„ç±»åˆ«ä¸å¹³è¡¡ (Class Imbalance) é—®é¢˜ã€‚ä½œè€…é’ˆå¯¹å®éªŒæ•°æ®é›†ï¼Œç›´æ¥å¯¹æ¯”äº†é¢„å¤„ç† (pre-processing)ã€å¤„ç†ä¸­ (in-processing) å’Œåå¤„ç† (post-processing) æŠ€æœ¯åœ¨æ•…éšœæ£€æµ‹ä¸è¯†åˆ«ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨æ•…éšœæ£€æµ‹æ–¹é¢ï¼Œé˜ˆå€¼è°ƒæ•´ (Threshold Adjustment) ç­‰åå¤„ç†æ–¹æ³•å¯¹ F1 åˆ†æ•°çš„æå‡æœ€ä¸ºæ˜¾è‘—ï¼Œè€Œéšæœºæ¬ é‡‡æ · (Random Under-Sampling) æ¨ç†é€Ÿåº¦æœ€å¿«ã€‚åœ¨æ•…éšœè¯†åˆ«ä»»åŠ¡ä¸­ï¼Œç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) è¡¨ç°å‡ºé«˜è¾¾ 24.2% çš„æ€§èƒ½å¢ç›Šï¼Œç›¸æ¯”ä¹‹ä¸‹åå¤„ç†æ–¹æ³•åœ¨å¤šåˆ†ç±»è®¾ç½®ä¸‹æ•ˆæœå—é™ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹ç±»åˆ«é‡å å’Œå»¶è¿Ÿæ•æ„Ÿçš„ä¸åŒåœºæ™¯ï¼ŒSMOTEã€å…ƒå­¦ä¹  (Meta-Learning) åŠç”Ÿæˆå¼ AI åˆ†åˆ«å±•ç°å‡ºå„è‡ªçš„é€‚ç”¨ä¼˜åŠ¿ã€‚è¯¥å·¥ä½œé€šè¿‡ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œä¸ºå…‰ç½‘ç»œåœ¨ä¸åŒçº¦æŸæ¡ä»¶ä¸‹çš„æ•…éšœç®¡ç†å†³ç­–æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00057v1",
      "published_date": "2025-08-25 09:50:51 UTC",
      "updated_date": "2025-08-25 09:50:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:02:42.888600+00:00"
    },
    {
      "arxiv_id": "2508.17825v3",
      "title": "FAIRGAMER: Evaluating Social Biases in LLM-Based Video Game NPCs",
      "title_zh": "FAIRGAMERï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç”µå­æ¸¸æˆ NPC ç¤¾ä¼šåè§è¯„ä¼°",
      "authors": [
        "Bingkang Shi",
        "Jen-tse Huang",
        "Long Luo",
        "Tianyu Zong",
        "Hongzhu Yi",
        "Yuanxiang Wang",
        "Songlin Hu",
        "Xiaodan Zhang",
        "Zhongjiang Yao"
      ],
      "abstract": "Large Language Models (LLMs) have increasingly enhanced or replaced traditional Non-Player Characters (NPCs) in video games. However, these LLM-based NPCs inherit underlying social biases (e.g., race or class), posing fairness risks during in-game interactions. To address the limited exploration of this issue, we introduce FairGamer, the first benchmark to evaluate social biases across three interaction patterns: transaction, cooperation, and competition. FairGamer assesses four bias types, including class, race, age, and nationality, across 12 distinct evaluation tasks using a novel metric, FairMCV. Our evaluation of seven frontier LLMs reveals that: (1) models exhibit biased decision-making, with Grok-4-Fast demonstrating the highest bias (average FairMCV = 76.9%); and (2) larger LLMs display more severe social biases, suggesting that increased model capacity inadvertently amplifies these biases. We release FairGamer at https://github.com/Anonymous999-xxx/FairGamer to facilitate future research on NPC fairness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„ç”µå­æ¸¸æˆéç©å®¶è§’è‰²(NPCs)ä¸­å­˜åœ¨çš„ç¤¾äº¤åè§é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªè¯„ä¼°åŸºå‡†FairGamerã€‚è¯¥æ¡†æ¶æ¶µç›–äº†äº¤æ˜“(transaction)ã€åˆä½œ(cooperation)å’Œç«äº‰(competition)ä¸‰ç§äº¤äº’æ¨¡å¼ï¼Œå¹¶é€šè¿‡æ–°é¢–çš„FairMCVæŒ‡æ ‡åœ¨12é¡¹ä»»åŠ¡ä¸­è¯„ä¼°äº†é˜¶çº§ã€ç§æ—ã€å¹´é¾„å’Œå›½ç±å››ç§åè§ç±»å‹ã€‚é€šè¿‡å¯¹ä¸ƒä¸ªå‰æ²¿LLMsçš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°è¿™äº›æ¨¡å‹åœ¨æ¸¸æˆå†³ç­–ä¸­æ™®éè¡¨ç°å‡ºåè§ï¼Œå…¶ä¸­Grok-4-Fastçš„åè§ç¨‹åº¦æœ€é«˜ï¼Œå¹³å‡FairMCVè¾¾åˆ°76.9%ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥æ­ç¤ºï¼Œæ¨¡å‹å®¹é‡çš„å¢åŠ åè€Œä¼šæ— æ„ä¸­æ”¾å¤§ç¤¾äº¤åè§ï¼Œå³è§„æ¨¡è¶Šå¤§çš„LLMsåè§é—®é¢˜å¾€å¾€è¶Šä¸¥é‡ã€‚è¯¥ç ”ç©¶ä¸ºè¯„ä¼°å’Œä¼˜åŒ–æ¸¸æˆNPCçš„å…¬å¹³æ€§æä¾›äº†é‡è¦å·¥å…·å’Œç†è®ºå‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17825v3",
      "published_date": "2025-08-25 09:26:19 UTC",
      "updated_date": "2026-01-21 02:31:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:02:32.992520+00:00"
    },
    {
      "arxiv_id": "2508.17822v1",
      "title": "Limits of message passing for node classification: How class-bottlenecks restrict signal-to-noise ratio",
      "title_zh": "èŠ‚ç‚¹åˆ†ç±»ä¸­æ¶ˆæ¯ä¼ é€’çš„å±€é™æ€§ï¼šç±»åˆ«ç“¶é¢ˆå¦‚ä½•é™åˆ¶ä¿¡å™ªæ¯”",
      "authors": [
        "Jonathan Rubin",
        "Sahil Loomba",
        "Nick S. Jones"
      ],
      "abstract": "Message passing neural networks (MPNNs) are powerful models for node classification but suffer from performance limitations under heterophily (low same-class connectivity) and structural bottlenecks in the graph. We provide a unifying statistical framework exposing the relationship between heterophily and bottlenecks through the signal-to-noise ratio (SNR) of MPNN representations. The SNR decomposes model performance into feature-dependent parameters and feature-independent sensitivities. We prove that the sensitivity to class-wise signals is bounded by higher-order homophily -- a generalisation of classical homophily to multi-hop neighbourhoods -- and show that low higher-order homophily manifests locally as the interaction between structural bottlenecks and class labels (class-bottlenecks). Through analysis of graph ensembles, we provide a further quantitative decomposition of bottlenecking into underreaching (lack of depth implying signals cannot arrive) and oversquashing (lack of breadth implying signals arriving on fewer paths) with closed-form expressions. We prove that optimal graph structures for maximising higher-order homophily are disjoint unions of single-class and two-class-bipartite clusters. This yields BRIDGE, a graph ensemble-based rewiring algorithm that achieves near-perfect classification accuracy across all homophily regimes on synthetic benchmarks and significant improvements on real-world benchmarks, by eliminating the ``mid-homophily pitfall'' where MPNNs typically struggle, surpassing current standard rewiring techniques from the literature. Our framework, whose code we make available for public use, provides both diagnostic tools for assessing MPNN performance, and simple yet effective methods for enhancing performance through principled graph modification.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¶ˆæ¯ä¼ é€’ç¥ç»ç½‘ç»œ (Message passing neural networks, MPNNs) åœ¨å¼‚è´¨æ€§ (heterophily) å’Œå›¾ç»“æ„ç“¶é¢ˆå½±å“ä¸‹æ€§èƒ½å—é™çš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç»Ÿè®¡æ¡†æ¶ï¼Œé€šè¿‡è¡¨ç¤ºçš„ä¿¡å™ªæ¯” (signal-to-noise ratio, SNR) æ­ç¤ºäº†å¼‚è´¨æ€§ä¸ç“¶é¢ˆä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚ç ”ç©¶è¯æ˜å¯¹ç±»ä¿¡å·çš„æ•æ„Ÿæ€§å—åˆ°é«˜é˜¶åŒè´¨æ€§ (higher-order homophily) çš„é™åˆ¶ï¼Œä¸”ä½é«˜é˜¶åŒè´¨æ€§åœ¨å±€éƒ¨è¡¨ç°ä¸ºç±»ç“¶é¢ˆ (class-bottlenecks) ç°è±¡ã€‚é€šè¿‡å¯¹å›¾ç³»ç»¼çš„åˆ†æï¼Œè¯¥æ¡†æ¶è¿›ä¸€æ­¥å®šé‡åˆ†è§£äº†ç“¶é¢ˆæ•ˆåº”ä¸­çš„æ¬ è§¦åŠ (underreaching) å’Œè¿‡åº¦æŒ¤å‹ (oversquashing) ç°è±¡å¹¶ç»™å‡ºäº†é—­å¼è¡¨è¾¾å¼ã€‚åŸºäºæœ€å¤§åŒ–é«˜é˜¶åŒè´¨æ€§çš„æœ€ä¼˜å›¾ç»“æ„ç†è®ºï¼Œç ”ç©¶æå‡ºäº† BRIDGE ç®—æ³•è¿›è¡Œå›¾é‡è¿ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†æ¨¡å‹åœ¨ä¼ ç»Ÿ MPNNs éš¾ä»¥å¤„ç†çš„ä¸­ç­‰åŒè´¨æ€§é™·é˜± (mid-homophily pitfall) ä¸­çš„æ€§èƒ½ç“¶é¢ˆã€‚å®éªŒç»“æœè¯å® BRIDGE åœ¨åˆæˆä¸çœŸå®åŸºå‡†æµ‹è¯•ä¸Šå‡å®ç°äº†åˆ†ç±»ç²¾åº¦çš„æ˜¾è‘—æå‡ï¼Œä¸ºè¯Šæ–­å’Œå¢å¼ºæ¨¡å‹æ€§èƒ½æä¾›äº†ç³»ç»Ÿæ€§çš„ç†è®ºä¾æ®ä¸å®ç”¨å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "math.ST",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17822v1",
      "published_date": "2025-08-25 09:25:14 UTC",
      "updated_date": "2025-08-25 09:25:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:02:38.284093+00:00"
    },
    {
      "arxiv_id": "2508.17821v2",
      "title": "Limitations of Normalization in Attention Mechanism",
      "title_zh": "æ³¨æ„åŠ›æœºåˆ¶ä¸­å½’ä¸€åŒ–çš„å±€é™æ€§",
      "authors": [
        "Timur Mudarisov",
        "Mikhail Burtsev",
        "Tatiana Petrova",
        "Radu State"
      ],
      "abstract": "This paper investigates the limitations of the normalization in attention mechanisms. We begin with a theoretical framework that enables the identification of the model's selective ability and the geometric separation involved in token selection. Our analysis includes explicit bounds on distances and separation criteria for token vectors under softmax scaling. Through experiments with pre-trained GPT-2 model, we empirically validate our theoretical results and analyze key behaviors of the attention mechanism. Notably, we demonstrate that as the number of selected tokens increases, the model's ability to distinguish informative tokens declines, often converging toward a uniform selection pattern. We also show that gradient sensitivity under softmax normalization presents challenges during training, especially at low temperature settings. These findings advance current understanding of softmax-based attention mechanism and motivate the need for more robust normalization and selection strategies in future attention architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶å»ºç«‹äº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œæ—¨åœ¨æ·±å…¥æ¢è®¨æ³¨æ„åŠ›æœºåˆ¶(Attention Mechanism)ä¸­å½’ä¸€åŒ–(Normalization)çš„å±€é™æ€§ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨æ ‡è®°é€‰æ‹©è¿‡ç¨‹ä¸­çš„é€‰æ‹©èƒ½åŠ›å’Œå‡ ä½•åˆ†ç¦»ï¼Œç ”ç©¶è€…æ¨å¯¼å‡ºäº†Softmaxç¼©æ”¾ä¸‹çš„è·ç¦»æ˜¾å¼ç•Œé™å’Œæ ‡è®°å‘é‡åˆ†ç¦»æ ‡å‡†ã€‚åˆ©ç”¨é¢„è®­ç»ƒçš„GPT-2æ¨¡å‹è¿›è¡Œçš„å®éªŒéªŒè¯äº†ç†è®ºç»“æœï¼Œå¹¶æ­ç¤ºäº†æ³¨æ„åŠ›æœºåˆ¶çš„å…³é”®è¡Œä¸ºç‰¹å¾ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œéšç€è¢«é€‰æ ‡è®°æ•°é‡å¢åŠ ï¼Œæ¨¡å‹åŒºåˆ†ä¿¡æ¯åŒ–æ ‡è®°çš„èƒ½åŠ›ä¼šæ˜¾è‘—ä¸‹é™ï¼Œå¹¶é€æ¸è¶‹å‘äºå‡åŒ€é€‰æ‹©æ¨¡å¼ã€‚æ­¤å¤–ï¼ŒSoftmaxå½’ä¸€åŒ–åœ¨ä½æ¸©åº¦è®¾ç½®ä¸‹çš„æ¢¯åº¦æ•æ„Ÿåº¦ä¸ºæ¨¡å‹è®­ç»ƒå¸¦æ¥äº†æŒ‘æˆ˜ã€‚è¿™äº›å‘ç°ä¸ºç†è§£åŸºäºSoftmaxçš„æ³¨æ„åŠ›æœºåˆ¶æä¾›äº†æ–°è§†è§’ï¼Œå¹¶å¼ºè°ƒäº†åœ¨æœªæ¥æ¶æ„ä¸­å¼€å‘æ›´é²æ£’çš„å½’ä¸€åŒ–ä¸é€‰æ‹©ç­–ç•¥çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17821v2",
      "published_date": "2025-08-25 09:25:05 UTC",
      "updated_date": "2025-10-20 15:30:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:08.787807+00:00"
    },
    {
      "arxiv_id": "2508.17816v1",
      "title": "UniSino: Physics-Driven Foundational Model for Universal CT Sinogram Standardization",
      "title_zh": "UniSinoï¼šç‰©ç†é©±åŠ¨çš„é€šç”¨CTæ­£å¼¦å›¾æ ‡å‡†åŒ–åŸºç¡€æ¨¡å‹",
      "authors": [
        "Xingyu Ai",
        "Shaoyu Wang",
        "Zhiyuan Jia",
        "Ao Xu",
        "Hongming Shan",
        "Jianhua Ma",
        "Qiegen Liu"
      ],
      "abstract": "During raw-data acquisition in CT imaging, diverse factors can degrade the collected sinograms, with undersampling and noise leading to severe artifacts and noise in reconstructed images and compromising diagnostic accuracy. Conventional correction methods rely on manually designed algorithms or fixed empirical parameters, but these approaches often lack generalizability across heterogeneous artifact types. To address these limitations, we propose UniSino, a foundation model for universal CT sinogram standardization. Unlike existing foundational models that operate in image domain, UniSino directly standardizes data in the projection domain, which enables stronger generalization across diverse undersampling scenarios. Its training framework incorporates the physical characteristics of sinograms, enhancing generalization and enabling robust performance across multiple subtasks spanning four benchmark datasets. Experimental results demonstrate thatUniSino achieves superior reconstruction quality both single and mixed undersampling case, demonstrating exceptional robustness and generalization in sinogram enhancement for CT imaging. The code is available at: https://github.com/yqx7150/UniSino.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UniSinoï¼Œä¸€ç§ç”¨äºé€šç”¨CTæ­£å¼¦å›¾(Sinogram)æ ‡å‡†åŒ–çš„ç‰©ç†é©±åŠ¨åŸºç¡€æ¨¡å‹(Foundational Model)ï¼Œæ—¨åœ¨è§£å†³CTæˆåƒä¸­å› æ¬ é‡‡æ ·(undersampling)å’Œå™ªå£°å¯¼è‡´çš„å›¾åƒä¼ªå½±åŠè¯Šæ–­å‡†ç¡®æ€§ä¸‹é™é—®é¢˜ã€‚ä¸åŒäºä»¥å¾€åœ¨å›¾åƒåŸŸ(image domain)æ“ä½œçš„æ¨¡å‹ï¼ŒUniSinoç›´æ¥åœ¨æŠ•å½±åŸŸ(projection domain)è¿›è¡Œæ•°æ®æ ‡å‡†åŒ–ï¼Œä»è€Œåœ¨å¼‚æ„æ¬ é‡‡æ ·åœºæ™¯ä¸‹å±•ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚å…¶è®­ç»ƒæ¡†æ¶é€šè¿‡èå…¥æ­£å¼¦å›¾çš„ç‰©ç†ç‰¹æ€§ï¼Œæ˜¾è‘—æå‡äº†åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ã€å¤šä¸ªå­ä»»åŠ¡ä¸­çš„é²æ£’æ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒUniSinoåœ¨å•ä¸€åŠæ··åˆæ¬ é‡‡æ ·æ¡ˆä¾‹ä¸­å‡èƒ½å®ç°å“è¶Šçš„é‡å»ºè´¨é‡ã€‚è¯¥ç ”ç©¶ä¸ºCTæˆåƒä¸­çš„æ­£å¼¦å›¾å¢å¼º(sinogram enhancement)æä¾›äº†å…·æœ‰é«˜åº¦é²æ£’æ€§å’Œæ³›åŒ–æ€§çš„é€šç”¨è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17816v1",
      "published_date": "2025-08-25 09:12:14 UTC",
      "updated_date": "2025-08-25 09:12:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:02:49.844337+00:00"
    },
    {
      "arxiv_id": "2508.17814v1",
      "title": "Scalable Engine and the Performance of Different LLM Models in a SLURM based HPC architecture",
      "title_zh": "åŸºäº SLURM çš„é«˜æ€§èƒ½è®¡ç®—æ¶æ„ä¸­å¯æ‰©å±•å¼•æ“ä¸ä¸åŒå¤§è¯­è¨€æ¨¡å‹çš„æ€§èƒ½è¡¨ç°",
      "authors": [
        "Anderson de Lima Luiz",
        "Shubham Vijay Kurlekar",
        "Munir Georges"
      ],
      "abstract": "This work elaborates on a High performance computing (HPC) architecture based on Simple Linux Utility for Resource Management (SLURM) [1] for deploying heterogeneous Large Language Models (LLMs) into a scalable inference engine. Dynamic resource scheduling and seamless integration of containerized microservices have been leveraged herein to manage CPU, GPU, and memory allocations efficiently in multi-node clusters. Extensive experiments, using Llama 3.2 (1B and 3B parameters) [2] and Llama 3.1 (8B and 70B) [3], probe throughput, latency, and concurrency and show that small models can handle up to 128 concurrent requests at sub-50 ms latency, while for larger models, saturation happens with as few as two concurrent users, with a latency of more than 2 seconds. This architecture includes Representational State Transfer Application Programming Interfaces (REST APIs) [4] endpoints for single and bulk inferences, as well as advanced workflows such as multi-step \"tribunal\" refinement. Experimental results confirm minimal overhead from container and scheduling activities and show that the approach scales reliably both for batch and interactive settings. We further illustrate real-world scenarios, including the deployment of chatbots with retrievalaugmented generation, which helps to demonstrate the flexibility and robustness of the architecture. The obtained results pave ways for significantly more efficient, responsive, and fault-tolerant LLM inference on large-scale HPC infrastructures.",
      "tldr_zh": "æœ¬ç ”ç©¶è¯¦ç»†é˜è¿°äº†ä¸€ç§åŸºäº SLURMï¼ˆSimple Linux Utility for Resource Managementï¼‰çš„é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰æ¶æ„ï¼Œæ—¨åœ¨å°†å¼‚æ„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éƒ¨ç½²ä¸ºå¯æ‰©å±•çš„æ¨ç†å¼•æ“ã€‚è¯¥æ¶æ„åˆ©ç”¨åŠ¨æ€èµ„æºè°ƒåº¦å’Œå®¹å™¨åŒ–å¾®æœåŠ¡çš„æ— ç¼é›†æˆï¼Œåœ¨å¤šèŠ‚ç‚¹é›†ç¾¤ä¸­é«˜æ•ˆç®¡ç† CPUã€GPU å’Œå†…å­˜åˆ†é…ã€‚ç³»ç»Ÿæä¾›äº†ç”¨äºå•æ¬¡å’Œæ‰¹é‡æ¨ç†çš„ REST APIs æ¥å£ï¼Œå¹¶æ”¯æŒå¤šæ­¥éª¤â€œtribunalâ€ä¼˜åŒ–ç­‰é«˜çº§å·¥ä½œæµã€‚ç ”ç©¶äººå‘˜ä½¿ç”¨ Llama 3.2ï¼ˆ1B å’Œ 3Bï¼‰ä»¥åŠ Llama 3.1ï¼ˆ8B å’Œ 70Bï¼‰è¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œé‡ç‚¹è¯„ä¼°äº†ååé‡ã€å»¶è¿Ÿå’Œå¹¶å‘æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°å‹æ¨¡å‹åœ¨å¤„ç†å¤šè¾¾ 128 ä¸ªå¹¶å‘è¯·æ±‚æ—¶å»¶è¿Ÿä½äº 50 æ¯«ç§’ï¼Œè€Œå¤§å‹æ¨¡å‹åœ¨ä»…æœ‰ä¸¤ä¸ªå¹¶å‘ç”¨æˆ·æ—¶å³è¾¾åˆ°é¥±å’Œä¸”å»¶è¿Ÿè¶…è¿‡ 2 ç§’ã€‚æ•°æ®è¯å®å®¹å™¨å’Œè°ƒåº¦æ´»åŠ¨çš„å¼€é”€æå°ï¼Œä¸”è¯¥æ–¹æ¡ˆåœ¨æ‰¹å¤„ç†å’Œäº¤äº’å¼åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºå¯é çš„å¯æ‰©å±•æ€§ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨å¤§å‹ HPC åŸºç¡€è®¾æ–½ä¸Šå®ç°æ›´é«˜æ•ˆã€å“åº”è¿…é€Ÿä¸”å®¹é”™çš„ LLM æ¨ç†å¼€è¾Ÿäº†é“è·¯ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted in ESSV 2025 - https://www.essv.de/paper.php?id=1265",
      "pdf_url": "https://arxiv.org/pdf/2508.17814v1",
      "published_date": "2025-08-25 09:11:27 UTC",
      "updated_date": "2025-08-25 09:11:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:06.892711+00:00"
    },
    {
      "arxiv_id": "2508.17811v2",
      "title": "MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting",
      "title_zh": "MeshSplatï¼šåŸºäºé«˜æ–¯æ³¼æº…çš„å¯æ³›åŒ–ç¨€ç–è§†å›¾è¡¨é¢é‡å»º",
      "authors": [
        "Hanzhi Chang",
        "Ruijie Zhu",
        "Wenjie Chang",
        "Mulin Yu",
        "Yanzhe Liang",
        "Jiahao Lu",
        "Zhuoyuan Li",
        "Tianzhu Zhang"
      ],
      "abstract": "Surface reconstruction has been widely studied in computer vision and graphics. However, existing surface reconstruction works struggle to recover accurate scene geometry when the input views are extremely sparse. To address this issue, we propose MeshSplat, a generalizable sparse-view surface reconstruction framework via Gaussian Splatting. Our key idea is to leverage 2DGS as a bridge, which connects novel view synthesis to learned geometric priors and then transfers these priors to achieve surface reconstruction. Specifically, we incorporate a feed-forward network to predict per-view pixel-aligned 2DGS, which enables the network to synthesize novel view images and thus eliminates the need for direct 3D ground-truth supervision. To improve the accuracy of 2DGS position and orientation prediction, we propose a Weighted Chamfer Distance Loss to regularize the depth maps, especially in overlapping areas of input views, and also a normal prediction network to align the orientation of 2DGS with normal vectors predicted by a monocular normal estimator. Extensive experiments validate the effectiveness of our proposed improvement, demonstrating that our method achieves state-of-the-art performance in generalizable sparse-view mesh reconstruction tasks. Project Page: https://hanzhichang.github.io/meshsplat_web",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¾“å…¥è§†å›¾æå…¶ç¨€ç–æ—¶ç°æœ‰è¡¨é¢é‡å»ºæ–¹æ³•éš¾ä»¥æ¢å¤å‡†ç¡®åœºæ™¯å‡ ä½•çš„é—®é¢˜ï¼Œæå‡ºäº†MeshSplatï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡Gaussian Splattingå®ç°çš„æ³›åŒ–ç¨€ç–è§†å›¾è¡¨é¢é‡å»ºæ¡†æ¶ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†2DGSä½œä¸ºè¿æ¥æ–°è§†å›¾åˆæˆä¸å­¦ä¹ å‡ ä½•å…ˆéªŒçš„æ¡¥æ¢ï¼Œä»è€Œæœ‰æ•ˆåœ°å°†å…ˆéªŒçŸ¥è¯†è½¬ç§»åˆ°è¡¨é¢é‡å»ºä»»åŠ¡ä¸­ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ¡†æ¶é€šè¿‡å‰é¦ˆç½‘ç»œé¢„æµ‹é€è§†å›¾åƒç´ å¯¹é½çš„2DGSï¼Œä½¿ç³»ç»Ÿå…·å¤‡åˆæˆæ–°è§†å›¾çš„èƒ½åŠ›ï¼Œæ¶ˆé™¤äº†å¯¹ç›´æ¥3DçœŸå€¼ç›‘ç£çš„ä¾èµ–ã€‚ä¸ºäº†æé«˜2DGSåœ¨ä½ç½®å’Œæ–¹å‘é¢„æµ‹ä¸Šçš„ç²¾åº¦ï¼Œç ”ç©¶æå‡ºäº†åŠ æƒChamfer Distance Lossæ¥æ­£åˆ™åŒ–é‡å åŒºåŸŸçš„æ·±åº¦å›¾ï¼Œå¹¶å¼•å…¥æ³•çº¿é¢„æµ‹ç½‘ç»œä»¥å¯¹é½2DGSæ–¹å‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMeshSplatåœ¨æ³›åŒ–ç¨€ç–è§†å›¾ç½‘æ ¼é‡å»ºä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼Œè¾¾åˆ°äº†ç›®å‰æœ€å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.17811v2",
      "published_date": "2025-08-25 09:04:20 UTC",
      "updated_date": "2025-11-25 08:48:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:01.283633+00:00"
    },
    {
      "arxiv_id": "2508.17797v1",
      "title": "Adaptive Output Steps: FlexiSteps Network for Dynamic Trajectory Prediction",
      "title_zh": "è‡ªé€‚åº”è¾“å‡ºæ­¥é•¿ï¼šé¢å‘åŠ¨æ€è½¨è¿¹é¢„æµ‹çš„ FlexiSteps ç½‘ç»œ",
      "authors": [
        "Yunxiang Liu",
        "Hongkuo Niu",
        "Jianlin Zhu"
      ],
      "abstract": "Accurate trajectory prediction is vital for autonomous driving, robotics, and intelligent decision-making systems, yet traditional models typically rely on fixed-length output predictions, limiting their adaptability to dynamic real-world scenarios. In this paper, we introduce the FlexiSteps Network (FSN), a novel framework that dynamically adjusts prediction output time steps based on varying contextual conditions. Inspired by recent advancements addressing observation length discrepancies and dynamic feature extraction, FSN incorporates an pre-trained Adaptive Prediction Module (APM) to evaluate and adjust the output steps dynamically, ensuring optimal prediction accuracy and efficiency. To guarantee the plug-and-play of our FSN, we also design a Dynamic Decoder(DD). Additionally, to balance the prediction time steps and prediction accuracy, we design a scoring mechanism, which not only introduces the FrÃ©chet distance to evaluate the geometric similarity between the predicted trajectories and the ground truth trajectories but the length of predicted steps is also considered. Extensive experiments conducted on benchmark datasets including Argoverse and INTERACTION demonstrate the effectiveness and flexibility of our proposed FSN framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FlexiSteps Network (FSN)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè½¨è¿¹é¢„æµ‹æ¨¡å‹å› ä¾èµ–å›ºå®šé•¿åº¦è¾“å‡ºè€Œå¯¼è‡´åœ¨åŠ¨æ€ç°å®åœºæ™¯ä¸­é€‚åº”æ€§å—é™çš„é—®é¢˜ã€‚FSN å¼•å…¥äº†ä¸€ä¸ªé¢„è®­ç»ƒçš„ Adaptive Prediction Module (APM)ï¼Œèƒ½å¤Ÿæ ¹æ®å˜åŒ–çš„ä¸Šä¸‹æ–‡æ¡ä»¶åŠ¨æ€è¯„ä¼°å¹¶è°ƒæ•´é¢„æµ‹è¾“å‡ºçš„æ—¶é—´æ­¥é•¿ï¼Œä»è€Œå…¼é¡¾é¢„æµ‹çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚ä¸ºäº†å®ç°æ¡†æ¶çš„å³æ’å³ç”¨ï¼Œç ”ç©¶è¿˜é…å¥—è®¾è®¡äº†ä¸€ä¸ª Dynamic Decoder (DD)ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„è¯„åˆ†æœºåˆ¶ï¼Œåˆ©ç”¨ FrÃ©chet distance è¯„ä¼°é¢„æµ‹è½¨è¿¹ä¸çœŸå®è½¨è¿¹çš„å‡ ä½•ç›¸ä¼¼æ€§ï¼Œå¹¶ç»¼åˆè€ƒè™‘é¢„æµ‹æ­¥é•¿çš„é•¿åº¦ã€‚åœ¨ Argoverse å’Œ INTERACTION ç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒFSN æ¡†æ¶åœ¨æä¾›é«˜åº¦çµæ´»æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é¢„æµ‹æ•ˆèƒ½ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17797v1",
      "published_date": "2025-08-25 08:43:08 UTC",
      "updated_date": "2025-08-25 08:43:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:08.000490+00:00"
    },
    {
      "arxiv_id": "2508.17786v1",
      "title": "Interpretable Early Failure Detection via Machine Learning and Trace Checking-based Monitoring",
      "title_zh": "åŸºäºæœºå™¨å­¦ä¹ ä¸è½¨è¿¹æ£€æŸ¥ç›‘æ§çš„å¯è§£é‡Šæ—©æœŸæ•…éšœæ£€æµ‹",
      "authors": [
        "Andrea Brunello",
        "Luca Geatti",
        "Angelo Montanari",
        "Nicola Saccomanno"
      ],
      "abstract": "Monitoring is a runtime verification technique that allows one to check whether an ongoing computation of a system (partial trace) satisfies a given formula. It does not need a complete model of the system, but it typically requires the construction of a deterministic automaton doubly exponential in the size of the formula (in the worst case), which limits its practicality. In this paper, we show that, when considering finite, discrete traces, monitoring of pure past (co)safety fragments of Signal Temporal Logic (STL) can be reduced to trace checking, that is, evaluation of a formula over a trace, that can be performed in time polynomial in the size of the formula and the length of the trace. By exploiting such a result, we develop a GPU-accelerated framework for interpretable early failure detection based on vectorized trace checking, that employs genetic programming to learn temporal properties from historical trace data. The framework shows a 2-10% net improvement in key performance metrics compared to the state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæœºå™¨å­¦ä¹ å’Œè½¨è¿¹æ£€æŸ¥ (Trace Checking) çš„å¯è§£é‡Šæ—©æœŸæ•…éšœæ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè¿è¡Œæ—¶ç›‘æ§ä¸­æ„é€ ç¡®å®šæ€§è‡ªåŠ¨æœºå¯¼è‡´çš„å¤æ‚åº¦çˆ†ç‚¸é—®é¢˜ã€‚ä½œè€…è¯æ˜äº†é’ˆå¯¹æœ‰é™ç¦»æ•£è½¨è¿¹ï¼ŒSignal Temporal Logic (STL) çš„çº¯è¿‡å»æ—¶ (co) å®‰å…¨æ€§ç‰‡æ®µçš„ç›‘æ§å¯ä»¥ç®€åŒ–ä¸ºå¤šé¡¹å¼å¤æ‚åº¦çš„è½¨è¿¹æ£€æŸ¥è¿‡ç¨‹ã€‚åŸºäºæ­¤ç†è®ºï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ª GPU åŠ é€Ÿçš„å‘é‡åŒ–ç›‘æµ‹æ¡†æ¶ï¼Œå¹¶é‡‡ç”¨é—ä¼ ç¼–ç¨‹ (Genetic Programming) æŠ€æœ¯ä»å†å²è½¨è¿¹æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ å…³é”®æ—¶é—´å±æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ä¸Šæ¯”ç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯æå‡äº† 2% è‡³ 10%ï¼Œä¸ºå®ç°é«˜æ•ˆã€å®æ—¶ä¸”å…·å¤‡å¯è§£é‡Šæ€§çš„ç³»ç»Ÿç›‘æ§æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Full version of the paper accepted for publication at the 28th European Conference on Artificial Intelligence (ECAI 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.17786v1",
      "published_date": "2025-08-25 08:30:01 UTC",
      "updated_date": "2025-08-25 08:30:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:34.494135+00:00"
    },
    {
      "arxiv_id": "2508.17784v1",
      "title": "Proximal Supervised Fine-Tuning",
      "title_zh": "è¿‘ç«¯æœ‰ç›‘ç£å¾®è°ƒ",
      "authors": [
        "Wenhong Zhu",
        "Ruobing Xie",
        "Rui Wang",
        "Xingwu Sun",
        "Di Wang",
        "Pengfei Liu"
      ],
      "abstract": "Supervised fine-tuning (SFT) of foundation models often leads to poor generalization, where prior capabilities deteriorate after tuning on new tasks or domains. Inspired by trust-region policy optimization (TRPO) and proximal policy optimization (PPO) in reinforcement learning (RL), we propose Proximal SFT (PSFT). This fine-tuning objective incorporates the benefits of trust-region, effectively constraining policy drift during SFT while maintaining competitive tuning. By viewing SFT as a special case of policy gradient methods with constant positive advantages, we derive PSFT that stabilizes optimization and leads to generalization, while leaving room for further optimization in subsequent post-training stages. Experiments across mathematical and human-value domains show that PSFT matches SFT in-domain, outperforms it in out-of-domain generalization, remains stable under prolonged training without causing entropy collapse, and provides a stronger foundation for the subsequent optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning, SFT)ä¸­å¸¸è§çš„æ³›åŒ–èƒ½åŠ›ä¸‹é™å’Œå…ˆéªŒèƒ½åŠ›é€€åŒ–é—®é¢˜ï¼Œå—åˆ°äº†å¼ºåŒ–å­¦ä¹ ä¸­ä¿¡ä»»åŒºåŸŸç­–ç•¥ä¼˜åŒ–(TRPO)å’Œè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)çš„å¯å‘ï¼Œæå‡ºäº†è¿‘ç«¯ç›‘ç£å¾®è°ƒ(Proximal SFT, PSFT)æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨SFTç›®æ ‡ä¸­å¼•å…¥ä¿¡ä»»åŒºåŸŸçº¦æŸï¼Œæœ‰æ•ˆé™åˆ¶äº†å¾®è°ƒè¿‡ç¨‹ä¸­çš„ç­–ç•¥æ¼‚ç§»(Policy Drift)ï¼Œä»è€Œåœ¨ä¿æŒè°ƒä¼˜æ•ˆæœçš„åŒæ—¶ç¨³å®šä¼˜åŒ–è¿‡ç¨‹ã€‚ç ”ç©¶å°†SFTè§†ä¸ºå…·æœ‰æ’å®šæ­£ä¼˜åŠ¿å€¼çš„ç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„ç‰¹ä¾‹ï¼Œæ¨å¯¼å‡ºçš„PSFTä¸ä»…æå‡äº†æ¨¡å‹çš„æ³›åŒ–æ€§ï¼Œè¿˜ä¸ºåç»­çš„åè®­ç»ƒé˜¶æ®µç•™ä¸‹äº†ä¼˜åŒ–ç©ºé—´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ•°å­¦å’Œäººç±»ä»·å€¼è§‚é¢†åŸŸï¼ŒPSFTåœ¨åŸŸå†…è¡¨ç°ä¸SFTç›¸å½“ï¼Œä½†åœ¨åŸŸå¤–(Out-of-Domain)æ³›åŒ–èƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºSFTã€‚æ­¤å¤–ï¼ŒPSFTåœ¨é•¿æ—¶é—´è®­ç»ƒä¸‹è¡¨ç°ç¨³å®šï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢ç†µåç¼©(Entropy Collapse)ï¼Œä¸ºåŸºç¡€æ¨¡å‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–å¥ å®šäº†æ›´å¼ºå¥çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17784v1",
      "published_date": "2025-08-25 08:26:43 UTC",
      "updated_date": "2025-08-25 08:26:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:39.442757+00:00"
    },
    {
      "arxiv_id": "2508.17783v1",
      "title": "Algebraic Approach to Ridge-Regularized Mean Squared Error Minimization in Minimal ReLU Neural Network",
      "title_zh": "æå° ReLU ç¥ç»ç½‘ç»œå²­æ­£åˆ™åŒ–å‡æ–¹è¯¯å·®æœ€å°åŒ–é—®é¢˜çš„ä»£æ•°æ–¹æ³•",
      "authors": [
        "Ryoya Fukasaku",
        "Yutaro Kabata",
        "Akifumi Okuno"
      ],
      "abstract": "This paper investigates a perceptron, a simple neural network model, with ReLU activation and a ridge-regularized mean squared error (RR-MSE). Our approach leverages the fact that the RR-MSE for ReLU perceptron is piecewise polynomial, enabling a systematic analysis using tools from computational algebra. In particular, we develop a Divide-Enumerate-Merge strategy that exhaustively enumerates all local minima of the RR-MSE. By virtue of the algebraic formulation, our approach can identify not only the typical zero-dimensional minima (i.e., isolated points) obtained by numerical optimization, but also higher-dimensional minima (i.e., connected sets such as curves, surfaces, or hypersurfaces). Although computational algebraic methods are computationally very intensive for perceptrons of practical size, as a proof of concept, we apply the proposed approach in practice to minimal perceptrons with a few hidden units.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…·æœ‰ ReLU æ¿€æ´»å‡½æ•°å’Œå²­æ­£åˆ™åŒ–å‡æ–¹è¯¯å·® (RR-MSE) çš„æ„ŸçŸ¥å™¨æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡ä»£æ•°æ–¹æ³•è§£å†³æœ€å°ç¥ç»ç½‘ç»œçš„ä¼˜åŒ–é—®é¢˜ã€‚åŸºäº RR-MSE åœ¨ ReLU æ„ŸçŸ¥å™¨ä¸­å‘ˆç°åˆ†æ®µå¤šé¡¹å¼ (piecewise polynomial) çš„ç‰¹æ€§ï¼Œç ”ç©¶è€…å¼•å…¥äº†è®¡ç®—ä»£æ•° (computational algebra) å·¥å…·è¿›è¡Œç³»ç»Ÿåˆ†æã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§â€œåˆ’åˆ†-æšä¸¾-åˆå¹¶â€ (Divide-Enumerate-Merge) ç­–ç•¥ï¼Œèƒ½å¤Ÿè¯¦å°½æšä¸¾ RR-MSE çš„æ‰€æœ‰å±€éƒ¨æå°å€¼ (local minima)ã€‚å‡­å€Ÿä»£æ•°å…¬å¼åŒ–æ–¹æ³•ï¼Œè¯¥ç­–ç•¥ä¸ä»…èƒ½è¯†åˆ«æ•°å€¼ä¼˜åŒ–ä¸­å¸¸è§çš„é›¶ç»´å­¤ç«‹æå°å€¼ç‚¹ï¼Œè¿˜èƒ½å‘ç°å¦‚æ›²çº¿ã€æ›²é¢æˆ–è¶…æ›²é¢ç­‰é«˜ç»´è¿é€šæå°å€¼é›† (higher-dimensional minima)ã€‚è™½ç„¶è¯¥æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡æ¨¡å‹æ—¶é¢ä¸´æé«˜çš„è®¡ç®—æŒ‘æˆ˜ï¼Œä½†é€šè¿‡å¯¹å°‘é‡éšè—å•å…ƒçš„æœ€å°æ„ŸçŸ¥å™¨è¿›è¡Œå®éªŒï¼Œè¯¥ç ”ç©¶æˆåŠŸéªŒè¯äº†å…¶åœ¨ç†è®ºåˆ†æå’Œå‚æ•°ç©ºé—´æ¢ç´¢ä¸­çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.CO"
      ],
      "primary_category": "stat.ML",
      "comment": "44 pages, 5 figres",
      "pdf_url": "https://arxiv.org/pdf/2508.17783v1",
      "published_date": "2025-08-25 08:24:20 UTC",
      "updated_date": "2025-08-25 08:24:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:47.889759+00:00"
    },
    {
      "arxiv_id": "2508.17778v1",
      "title": "AgentRAN: An Agentic AI Architecture for Autonomous Control of Open 6G Networks",
      "title_zh": "AgentRANï¼šé¢å‘å¼€æ”¾å¼ 6G ç½‘ç»œè‡ªä¸»æ§åˆ¶çš„æ™ºèƒ½ä½“ AI æ¶æ„",
      "authors": [
        "Maxime Elkael",
        "Salvatore D'Oro",
        "Leonardo Bonati",
        "Michele Polese",
        "Yunseong Lee",
        "Koichiro Furueda",
        "Tommaso Melodia"
      ],
      "abstract": "The Open RAN movement has catalyzed a transformation toward programmable, interoperable cellular infrastructures. Yet, today's deployments still rely heavily on static control and manual operations. To move beyond this limitation, we introduce AgenRAN, an AI-native, Open RAN-aligned agentic framework that generates and orchestrates a fabric of distributed AI agents based on Natural Language (NL) intents. Unlike traditional approaches that require explicit programming, AgentRAN's LLM-powered agents interpret natural language intents, negotiate strategies through structured conversations, and orchestrate control loops across the network. AgentRAN instantiates a self-organizing hierarchy of agents that decompose complex intents across time scales (from sub-millisecond to minutes), spatial domains (cell to network-wide), and protocol layers (PHY/MAC to RRC). A central innovation is the AI-RAN Factory, an automated synthesis pipeline that observes agent interactions and continuously generates new agents embedding improved control algorithms, effectively transforming the network from a static collection of functions into an adaptive system capable of evolving its own intelligence. We demonstrate AgentRAN through live experiments on 5G testbeds where competing user demands are dynamically balanced through cascading intents. By replacing rigid APIs with NL coordination, AgentRAN fundamentally redefines how future 6G networks autonomously interpret, adapt, and optimize their behavior to meet operator goals.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AgentRANï¼Œè¿™æ˜¯ä¸€ç§é¢å‘ 6G ç½‘ç»œä¸”ç¬¦åˆ Open RAN æ ‡å‡†çš„ AI åŸç”Ÿæ™ºèƒ½ä½“æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰èœ‚çªç½‘ç»œè¿‡äºä¾èµ–é™æ€æ§åˆ¶å’Œæ‰‹åŠ¨æ“ä½œçš„é—®é¢˜ã€‚AgentRAN åˆ©ç”¨åŸºäº LLM çš„æ™ºèƒ½ä½“æ¥è§£æè‡ªç„¶è¯­è¨€ï¼ˆNLï¼‰æ„å›¾ï¼Œå¹¶é€šè¿‡ç»“æ„åŒ–å¯¹è¯åå•†ç­–ç•¥ï¼Œåœ¨æ•´ä¸ªç½‘ç»œä¸­ç¼–æ’æ§åˆ¶å›è·¯ã€‚è¯¥æ¶æ„æ„å»ºäº†ä¸€ä¸ªè‡ªç»„ç»‡çš„æ™ºèƒ½ä½“å±‚æ¬¡ç»“æ„ï¼Œèƒ½å¤Ÿè·¨è¶Šä¸åŒæ—¶é—´å°ºåº¦ã€ç©ºé—´åŸŸå’Œåè®®å±‚åˆ†è§£å¤æ‚çš„æ„å›¾ã€‚å…¶æ ¸å¿ƒåˆ›æ–° AI-RAN Factory æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–åˆæˆæµæ°´çº¿ï¼Œé€šè¿‡è§‚å¯Ÿæ™ºèƒ½ä½“äº¤äº’æŒç»­ç”ŸæˆåµŒå…¥æ”¹è¿›æ§åˆ¶ç®—æ³•çš„æ–°æ™ºèƒ½ä½“ï¼Œä½¿ç½‘ç»œä»é™æ€åŠŸèƒ½é›†åˆè½¬å˜ä¸ºå¯è¿›åŒ–çš„è‡ªä¸»ç³»ç»Ÿã€‚åœ¨ 5G æµ‹è¯•åºŠä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAgentRAN èƒ½å¤ŸåŠ¨æ€å¹³è¡¡ç«äº‰æ€§ç”¨æˆ·éœ€æ±‚ï¼Œé€šè¿‡å°†åˆšæ€§ API æ›¿æ¢ä¸º NL åè°ƒï¼Œå®šä¹‰äº†æœªæ¥ 6G ç½‘ç»œå¦‚ä½•è‡ªä¸»è§£é‡Šã€é€‚åº”å¹¶ä¼˜åŒ–å…¶è¡Œä¸ºã€‚",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2508.17778v1",
      "published_date": "2025-08-25 08:18:10 UTC",
      "updated_date": "2025-08-25 08:18:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:48.586942+00:00"
    },
    {
      "arxiv_id": "2509.03527v1",
      "title": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model",
      "title_zh": "åŸºäº RAG æ–¹æ³•ä¸å¾®è°ƒ Mistral å¤§è¯­è¨€æ¨¡å‹çš„åŠ å¯†è´§å¸æ–°é—»å¤šå±‚çº§åˆ†æ",
      "authors": [
        "Bohdan M. Pavlyshenko"
      ],
      "abstract": "In the paper, we consider multilevel multitask analysis of cryptocurrency news using a fine-tuned Mistral 7B large language model with retrieval-augmented generation (RAG).\n  On the first level of analytics, the fine-tuned model generates graph and text summaries with sentiment scores as well as JSON representations of summaries. Higher levels perform hierarchical stacking that consolidates sets of graph-based and text-based summaries as well as summaries of summaries into comprehensive reports. The combination of graph and text summaries provides complementary views of cryptocurrency news. The model is fine-tuned with 4-bit quantization using the PEFT/LoRA approach. The representation of cryptocurrency news as knowledge graph can essentially eliminate problems with large language model hallucinations.\n  The obtained results demonstrate that the use of fine-tuned Mistral 7B LLM models for multilevel cryptocurrency news analysis can conduct informative qualitative and quantitative analytics, providing important insights.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¾®è°ƒçš„ Mistral 7B å¤§è¯­è¨€æ¨¡å‹å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯çš„å¤šå±‚çº§åŠ å¯†è´§å¸æ–°é—»åˆ†ææ–¹æ³•ã€‚åœ¨ç¬¬ä¸€å±‚çº§ï¼Œå¾®è°ƒåçš„æ¨¡å‹ç”ŸæˆåŒ…å«æƒ…æ„Ÿè¯„åˆ†çš„å›¾è°±ä¸æ–‡æœ¬æ‘˜è¦ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸º JSON æ ¼å¼ä»¥ä¾›åç»­å¤„ç†ã€‚æ›´é«˜å±‚çº§åˆ™é‡‡ç”¨åˆ†å±‚å †å  (Hierarchical stacking) æŠ€æœ¯ï¼Œå°†å¤šç»„å›¾è°±ã€æ–‡æœ¬æ‘˜è¦åŠå…¶è¿›ä¸€æ­¥çš„æ±‡æ€»æ•´åˆä¸ºå…¨é¢çš„åˆ†ææŠ¥å‘Šã€‚é€šè¿‡ç»“åˆå›¾è°±å’Œæ–‡æœ¬æ‘˜è¦ï¼Œè¯¥ç³»ç»Ÿä¸ºåŠ å¯†è´§å¸æ–°é—»æä¾›äº†äº’è¡¥çš„è§‚å¯Ÿè§†è§’ï¼Œå¹¶åˆ©ç”¨ PEFT/LoRA æ–¹æ³•å’Œ 4-bit é‡åŒ–æŠ€æœ¯å®ç°äº†é«˜æ•ˆçš„æ¨¡å‹å¾®è°ƒã€‚å¼•å…¥çŸ¥è¯†å›¾è°± (Knowledge graph) è¡¨ç¤ºæ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ­¤ç±»ç‰¹å®šé¢†åŸŸæ•°æ®æ—¶å¸¸è§çš„å¹»è§‰ (Hallucinations) é—®é¢˜ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥å¤šå±‚çº§æ¡†æ¶èƒ½å¤Ÿæ‰§è¡Œæ·±å…¥çš„å®šæ€§å’Œå®šé‡åˆ†æï¼Œä¸ºåŠ å¯†è´§å¸å¸‚åœºæä¾›äº†é‡è¦çš„ä¸“ä¸šè§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.03527v1",
      "published_date": "2025-08-25 08:17:08 UTC",
      "updated_date": "2025-08-25 08:17:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:40.455541+00:00"
    },
    {
      "arxiv_id": "2508.17754v1",
      "title": "DiffusionGS: Generative Search with Query Conditioned Diffusion in Kuaishou",
      "title_zh": "DiffusionGSï¼šKuaishou ä¸­åŸºäºæŸ¥è¯¢æ¡ä»¶æ‰©æ•£çš„ç”Ÿæˆå¼æœç´¢",
      "authors": [
        "Qinyao Li",
        "Xiaoyang Zheng",
        "Qihang Zhao",
        "Ke Xu",
        "Zhongbo Sun",
        "Chao Wang",
        "Chenyi Lei",
        "Han Li",
        "Wenwu Ou"
      ],
      "abstract": "Personalized search ranking systems are critical for driving engagement and revenue in modern e-commerce and short-video platforms. While existing methods excel at estimating users' broad interests based on the filtered historical behaviors, they typically under-exploit explicit alignment between a user's real-time intent (represented by the user query) and their past actions. In this paper, we propose DiffusionGS, a novel and scalable approach powered by generative models. Our key insight is that user queries can serve as explicit intent anchors to facilitate the extraction of users' immediate interests from long-term, noisy historical behaviors. Specifically, we formulate interest extraction as a conditional denoising task, where the user's query guides a conditional diffusion process to produce a robust, user intent-aware representation from their behavioral sequence. We propose the User-aware Denoising Layer (UDL) to incorporate user-specific profiles into the optimization of attention distribution on the user's past actions. By reframing queries as intent priors and leveraging diffusion-based denoising, our method provides a powerful mechanism for capturing dynamic user interest shifts. Extensive offline and online experiments demonstrate the superiority of DiffusionGS over state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DiffusionGSï¼Œè¿™æ˜¯ä¸€ç§åœ¨å¿«æ‰‹(Kuaishou)åº”ç”¨çš„æ–°é¢–å¯æ‰©å±•ç”Ÿæˆå¼æœç´¢æ’åºæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç³»ç»Ÿåœ¨å¯¹é½ç”¨æˆ·å®æ—¶æŸ¥è¯¢æ„å›¾ä¸é•¿æœŸå™ªå£°è¡Œä¸ºæ•°æ®æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°å°†å…´è¶£æå–å»ºæ¨¡ä¸ºä¸€ä¸ªæ¡ä»¶å»å™ªä»»åŠ¡ï¼Œåˆ©ç”¨æ¡ä»¶æ‰©æ•£è¿‡ç¨‹(conditional diffusion)å¹¶ä»¥ç”¨æˆ·æŸ¥è¯¢ä½œä¸ºæ„å›¾é”šç‚¹ï¼Œä»è¡Œä¸ºåºåˆ—ä¸­æå–å‡ºå…·æœ‰æ„å›¾æ„ŸçŸ¥èƒ½åŠ›çš„ç¨³å¥ç‰¹å¾è¡¨ç¤ºã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†ç”¨æˆ·æ„ŸçŸ¥å»å™ªå±‚(User-aware Denoising Layer, UDL)ï¼Œé€šè¿‡å°†ç‰¹å®šç”¨æˆ·ç”»åƒèå…¥æ³¨æ„åŠ›æœºåˆ¶æ¥ä¼˜åŒ–å¯¹å†å²è¡Œä¸ºçš„å»ºæ¨¡ã€‚é€šè¿‡å°†æŸ¥è¯¢è¯é‡æ„ä¸ºæ„å›¾å…ˆéªŒå¹¶ç»“åˆæ‰©æ•£å»å™ªæŠ€æœ¯ï¼ŒDiffusionGS æä¾›äº†ä¸€ç§æ•è·ç”¨æˆ·åŠ¨æ€å…´è¶£åç§»çš„å¼ºå¤§æœºåˆ¶ã€‚å¤§é‡çš„ç¦»çº¿å’Œåœ¨çº¿å®éªŒç»“æœè¯æ˜ï¼ŒDiffusionGS çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¤§è§„æ¨¡å·¥ä¸šåœºæ™¯ä¸‹çš„æœç´¢ä¸ªæ€§åŒ–æ€§èƒ½ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17754v1",
      "published_date": "2025-08-25 07:46:51 UTC",
      "updated_date": "2025-08-25 07:46:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:59.888320+00:00"
    },
    {
      "arxiv_id": "2508.17753v1",
      "title": "Talking to Robots: A Practical Examination of Speech Foundation Models for HRI Applications",
      "title_zh": "ä¸æœºå™¨äººå¯¹è¯ï¼šè¯­éŸ³åŸºç¡€æ¨¡å‹åœ¨ HRI åº”ç”¨ä¸­çš„å®è·µç ”ç©¶",
      "authors": [
        "Theresa Pekarek Rosin",
        "Julia Gachot",
        "Henri-Leon Kordt",
        "Matthias Kerzel",
        "Stefan Wermter"
      ],
      "abstract": "Automatic Speech Recognition (ASR) systems in real-world settings need to handle imperfect audio, often degraded by hardware limitations or environmental noise, while accommodating diverse user groups. In human-robot interaction (HRI), these challenges intersect to create a uniquely challenging recognition environment. We evaluate four state-of-the-art ASR systems on eight publicly available datasets that capture six dimensions of difficulty: domain-specific, accented, noisy, age-variant, impaired, and spontaneous speech. Our analysis demonstrates significant variations in performance, hallucination tendencies, and inherent biases, despite similar scores on standard benchmarks. These limitations have serious implications for HRI, where recognition errors can interfere with task performance, user trust, and safety.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³åŸºç¡€æ¨¡å‹ (Speech Foundation Models) åœ¨äººæœºäº¤äº’ (HRI) åº”ç”¨ä¸­çš„å®é™…è¡¨ç°è¿›è¡Œäº†æ·±å…¥è¯„ä¼°ï¼Œé‡ç‚¹å…³æ³¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR) ç³»ç»Ÿåœ¨ç°å®å¤æ‚ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å…«ä¸ªå…¬å¼€æ•°æ®é›†ï¼Œä»é¢†åŸŸç‰¹å®šã€å£éŸ³ã€å™ªå£°ã€å¹´é¾„å·®å¼‚ã€å—æŸè¯­éŸ³ä»¥åŠè‡ªå‘è¯­éŸ³ç­‰å…­ä¸ªç»´åº¦ï¼Œå¯¹å››ç§æœ€å…ˆè¿›çš„ ASR ç³»ç»Ÿè¿›è¡Œäº†ç³»ç»Ÿæ€§æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡è¿™äº›ç³»ç»Ÿåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­çš„å¾—åˆ†ç›¸è¿‘ï¼Œä½†åœ¨å¤„ç†ç°å®ä¸–ç•Œçš„ä¸å®Œç¾éŸ³é¢‘æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½å·®å¼‚ã€å¹»è§‰ (hallucination) å€¾å‘ä»¥åŠå›ºæœ‰åè§ã€‚ç ”ç©¶å¼ºè°ƒï¼Œè¿™äº›è¯†åˆ«å±‚é¢çš„å±€é™æ€§ä¼šç›´æ¥å¹²æ‰° HRI çš„ä»»åŠ¡æ‰§è¡Œæ•ˆç‡ï¼Œå¹¶å¯¹ç”¨æˆ·ä¿¡ä»»å’Œäº¤äº’å®‰å…¨æ€§äº§ç”Ÿè´Ÿé¢å½±å“ã€‚è¯¥è®ºæ–‡çš„å‘ç°æ­ç¤ºäº†å½“å‰è¯­éŸ³æ¨¡å‹åœ¨æœºå™¨äººå®é™…éƒ¨ç½²ä¸­çš„å…³é”®ç“¶é¢ˆï¼Œä¸ºæ„å»ºæ›´å¯é çš„ HRI ç³»ç»Ÿæä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at the workshop on Foundation Models for Social Robotics (FoMoSR) at ICSR 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17753v1",
      "published_date": "2025-08-25 07:45:20 UTC",
      "updated_date": "2025-08-25 07:45:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:03:58.387695+00:00"
    },
    {
      "arxiv_id": "2509.00055v2",
      "title": "U2UData+: A Scalable Swarm UAVs Autonomous Flight Dataset for Embodied Long-horizon Tasks",
      "title_zh": "U2UData+ï¼šé¢å‘å…·èº«é•¿ç¨‹ä»»åŠ¡çš„å¯æ‰©å±•é›†ç¾¤æ— äººæœºè‡ªä¸»é£è¡Œæ•°æ®é›†",
      "authors": [
        "Tongtong Feng",
        "Xin Wang",
        "Feilin Han",
        "Leping Zhang",
        "Wenwu Zhu"
      ],
      "abstract": "Swarm UAV autonomous flight for Embodied Long-Horizon (ELH) tasks is crucial for advancing the low-altitude economy. However, existing methods focus only on specific basic tasks due to dataset limitations, failing in real-world deployment for ELH tasks. ELH tasks are not mere concatenations of basic tasks, requiring handling long-term dependencies, maintaining embodied persistent states, and adapting to dynamic goal shifts. This paper presents U2UData+, the first large-scale swarm UAV autonomous flight dataset for ELH tasks and the first scalable swarm UAV data online collection and algorithm closed-loop verification platform. The dataset is captured by 15 UAVs in autonomous collaborative flights for ELH tasks, comprising 12 scenes, 720 traces, 120 hours, 600 seconds per trajectory, 4.32M LiDAR frames, and 12.96M RGB frames. This dataset also includes brightness, temperature, humidity, smoke, and airflow values covering all flight routes. The platform supports the customization of simulators, UAVs, sensors, flight algorithms, formation modes, and ELH tasks. Through a visual control window, this platform allows users to collect customized datasets through one-click deployment online and to verify algorithms by closed-loop simulation. U2UData+ also introduces an ELH task for wildlife conservation and provides comprehensive benchmarks with 9 SOTA models. U2UData+ can be found at https://fengtt42.github.io/U2UData-2/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— äººæœºç¾¤(Swarm UAVs)åœ¨æ‰§è¡Œå…·èº«é•¿ç¨‹(Embodied Long-Horizon, ELH)ä»»åŠ¡æ—¶é¢ä¸´çš„é•¿æœŸä¾èµ–ã€çŠ¶æ€æŒä¹…æ€§åŠåŠ¨æ€ç›®æ ‡åç§»ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†U2UData+ã€‚ä½œä¸ºé¦–ä¸ªé¢å‘ELHä»»åŠ¡çš„å¤§è§„æ¨¡æ— äººæœºç¾¤è‡ªä¸»é£è¡Œæ•°æ®é›†ï¼Œå®ƒç”±15æ¶æ— äººæœºåœ¨12ä¸ªåœºæ™¯ä¸­åä½œé‡‡é›†ï¼ŒåŒ…å«120å°æ—¶çš„è½¨è¿¹æ•°æ®ã€432ä¸‡å¸§LiDARæ•°æ®ä»¥åŠ1296ä¸‡å¸§RGBå›¾åƒã€‚é™¤äº†æ ¸å¿ƒè§†è§‰æ•°æ®ï¼Œè¯¥æ•°æ®é›†è¿˜æ•´åˆäº†å…‰ç…§ã€æ¸©æ¹¿åº¦ç­‰ç¯å¢ƒä¼ æ„Ÿæ•°å€¼ï¼Œå¹¶é…å¥—æ¨å‡ºäº†ä¸€ä¸ªæ”¯æŒåœ¨çº¿æ•°æ®é‡‡é›†ä¸ç®—æ³•é—­ç¯éªŒè¯çš„å¯æ‰©å±•å¹³å°ã€‚è¯¥å¹³å°å…è®¸ç”¨æˆ·é€šè¿‡å¯è§†åŒ–çª—å£ä¸€é”®éƒ¨ç½²è‡ªå®šä¹‰ä»¿çœŸç¯å¢ƒä¸é£è¡Œç®—æ³•ï¼Œæå¤§åœ°ç®€åŒ–äº†æ•°æ®é›†å®šåˆ¶ä¸éªŒè¯æµç¨‹ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº†ä¸€ä¸ªé‡ç”ŸåŠ¨ç‰©ä¿æŠ¤çš„å…¸å‹ELHä»»åŠ¡ï¼Œå¹¶åŸºäº9ç§SOTAæ¨¡å‹å»ºç«‹äº†å…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œä¸ºæ¨åŠ¨ä½ç©ºç»æµä¸­çš„è‡ªä¸»é£è¡ŒæŠ€æœ¯å¥ å®šäº†æ•°æ®åŸºç¡€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA",
        "cs.MM"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by AAAI26",
      "pdf_url": "https://arxiv.org/pdf/2509.00055v2",
      "published_date": "2025-08-25 07:39:36 UTC",
      "updated_date": "2025-11-19 10:20:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:04:08.491203+00:00"
    },
    {
      "arxiv_id": "2508.17742v1",
      "title": "EEG-FM-Bench: A Comprehensive Benchmark for the Systematic Evaluation of EEG Foundation Models",
      "title_zh": "EEG-FM-Benchï¼šé¢å‘è„‘ç”µåŸºç¡€æ¨¡å‹ç³»ç»ŸåŒ–è¯„ä¼°çš„ç»¼åˆåŸºå‡†",
      "authors": [
        "Wei Xiong",
        "Jiangtong Li",
        "Jie Li",
        "Kun Zhu"
      ],
      "abstract": "Electroencephalography (EEG) foundation models are poised to significantly advance brain signal analysis by learning robust representations from large-scale, unlabeled datasets. However, their rapid proliferation has outpaced the development of standardized evaluation benchmarks, which complicates direct model comparisons and hinders systematic scientific progress. This fragmentation fosters scientific inefficiency and obscures genuine architectural advancements. To address this critical gap, we introduce EEG-FM-Bench, the first comprehensive benchmark for the systematic and standardized evaluation of EEG foundation models (EEG-FMs). Our contributions are threefold: (1) we curate a diverse suite of downstream tasks and datasets from canonical EEG paradigms, implementing standardized processing and evaluation protocols within a unified open-source framework; (2) we benchmark prominent state-of-the-art foundation models to establish comprehensive baseline results for a clear comparison of the current landscape; (3) we perform qualitative analyses of the learned representations to provide insights into model behavior and inform future architectural design. Through extensive experiments, we find that fine-grained spatio-temporal feature interaction, multitask unified training and neuropsychological priors would contribute to enhancing model performance and generalization capabilities. By offering a unified platform for fair comparison and reproducible research, EEG-FM-Bench seeks to catalyze progress and guide the community toward the development of more robust and generalizable EEG-FMs. Code is released at https://github.com/xw1216/EEG-FM-Bench.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è„‘ç”µå›¾åŸºç¡€æ¨¡å‹ (EEG foundation models) è¿…é€Ÿå‘å±•ä½†ç¼ºä¹æ ‡å‡†åŒ–è¯„ä¼°åŸºå‡†çš„é—®é¢˜ï¼Œæ¨å‡ºäº†é¦–ä¸ªç”¨äºç³»ç»ŸåŒ–è¯„ä¼°çš„ç»¼åˆåŸºå‡† EEG-FM-Benchã€‚è¯¥åŸºå‡†åœ¨ä¸€ä¸ªç»Ÿä¸€çš„å¼€æºæ¡†æ¶å†…ï¼Œæ•´åˆäº†æ¥è‡ªå…¸å‹ EEG èŒƒå¼çš„å¤šæ ·åŒ–ä¸‹æ¸¸ä»»åŠ¡å’Œæ•°æ®é›†ï¼Œå¹¶å»ºç«‹äº†æ ‡å‡†åŒ–çš„æ•°æ®å¤„ç†ä¸è¯„ä¼°åè®®ã€‚ç ”ç©¶å›¢é˜Ÿå¯¹å½“å‰ä¸»æµçš„ SOTA åŸºç¡€æ¨¡å‹è¿›è¡Œäº†æµ‹è¯„ä»¥ç¡®ç«‹åŸºçº¿ï¼Œå¹¶é€šè¿‡å®šæ€§åˆ†ææ·±å…¥æ¢è®¨äº†æ¨¡å‹å­¦ä¹ åˆ°çš„è¡¨å¾ (learned representations) åŠå…¶æ¶æ„è®¾è®¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»†ç²’åº¦çš„æ—¶ç©ºç‰¹å¾äº¤äº’ (fine-grained spatio-temporal feature interaction)ã€å¤šä»»åŠ¡ç»Ÿä¸€è®­ç»ƒ (multitask unified training) ä»¥åŠç¥ç»å¿ƒç†å­¦å…ˆéªŒ (neuropsychological priors) å¯¹äºå¢å¼ºæ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›è‡³å…³é‡è¦ã€‚ä½œä¸ºä¸€ç§ä¿ƒè¿›å…¬å¹³æ¯”è¾ƒå’Œå¯é‡å¤ç ”ç©¶çš„å·¥å…·ï¼ŒEEG-FM-Bench æ—¨åœ¨æ¨åŠ¨å­¦æœ¯ç•Œå¼€å‘å‡ºæ›´å…·é²æ£’æ€§å’Œé€šç”¨æ€§çš„ EEG-FMsã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "eess.SP",
      "comment": "17 pages, 7 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.17742v1",
      "published_date": "2025-08-25 07:34:33 UTC",
      "updated_date": "2025-08-25 07:34:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:04:11.983293+00:00"
    },
    {
      "arxiv_id": "2508.17739v2",
      "title": "Speculative Safety-Aware Decoding",
      "title_zh": "æŠ•æœºæ€§å®‰å…¨æ„ŸçŸ¥è§£ç ",
      "authors": [
        "Xuekang Wang",
        "Shengyu Zhu",
        "Xueqi Cheng"
      ],
      "abstract": "Despite extensive efforts to align Large Language Models (LLMs) with human values and safety rules, jailbreak attacks that exploit certain vulnerabilities continuously emerge, highlighting the need to strengthen existing LLMs with additional safety properties to defend against these attacks. However, tuning large models has become increasingly resource intensive and may have difficulty ensuring consistent performance. We introduce Speculative Safety-Aware Decoding (SSD), a lightweight decoding-time approach that equips LLMs with the desired safety property while accelerating inference. We assume that there exists a small language model that possesses this desired property. SSD integrates speculative sampling during decoding and leverages the match ratio between the small and composite models to quantify jailbreak risks. This enables SSD to dynamically switch between decoding schemes to prioritize utility or safety, to handle the challenge of different model capacities. The output token is then sampled from a new distribution that combines the distributions of the original and the small models. Experimental results show that SSD successfully equips the large model with the desired safety property, and also allows the model to remain helpful to benign queries. Furthermore, SSD accelerates the inference time, thanks to the speculative sampling design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Speculative Safety-Aware Decoding (SSD)ï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§çš„è§£ç æ—¶(decoding-time)æ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºå¤§è¯­è¨€æ¨¡å‹(LLMs)é…å¤‡å®‰å…¨å±æ€§å¹¶é˜²å¾¡è¶Šç‹±æ”»å‡»(jailbreak attacks)ã€‚SSDåˆ©ç”¨ä¸€ä¸ªå…·å¤‡å®‰å…¨å±æ€§çš„å°æ¨¡å‹ï¼Œåœ¨è§£ç è¿‡ç¨‹ä¸­ç»“åˆæŠ•æœºé‡‡æ ·(speculative sampling)ï¼Œé€šè¿‡è®¡ç®—å°æ¨¡å‹ä¸ç»„åˆæ¨¡å‹ä¹‹é—´çš„åŒ¹é…ç‡æ¥é‡åŒ–è¶Šç‹±é£é™©ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®ä¸åŒæ¨¡å‹çš„å®¹é‡å·®å¼‚åŠ¨æ€åˆ‡æ¢è§£ç æ–¹æ¡ˆï¼Œåœ¨å®ç”¨æ€§ä¸å®‰å…¨æ€§ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå¹¶ä»ç»“åˆäº†åŸå§‹æ¨¡å‹ä¸å°æ¨¡å‹çš„æ–°åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSSDåœ¨èµ‹äºˆå¤§æ¨¡å‹æ‰€éœ€å®‰å…¨å±æ€§çš„åŒæ—¶ï¼Œèƒ½ä¿æŒå¯¹è‰¯æ€§æŸ¥è¯¢çš„å“åº”èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå—ç›ŠäºæŠ•æœºé‡‡æ ·è®¾è®¡ï¼ŒSSDè¿˜æ˜¾è‘—æå‡äº†æ¨ç†é€Ÿåº¦ï¼Œä¸ºæ„å»ºå®‰å…¨ä¸”é«˜æ•ˆçš„è¯­è¨€æ¨¡å‹æ¨ç†æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Camera-ready version of EMNLP 2025 main conference. Code: https://github.com/k-k1w-w1x-x/Speculative-Safety-Aware-Decoding",
      "pdf_url": "https://arxiv.org/pdf/2508.17739v2",
      "published_date": "2025-08-25 07:30:10 UTC",
      "updated_date": "2025-09-28 05:23:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:04:24.490285+00:00"
    },
    {
      "arxiv_id": "2509.00054v2",
      "title": "Robotic Fire Risk Detection based on Dynamic Knowledge Graph Reasoning: An LLM-Driven Approach with Graph Chain-of-Thought",
      "title_zh": "åŸºäºåŠ¨æ€çŸ¥è¯†å›¾è°±æ¨ç†çš„æœºå™¨äººç«ç¾é£é™©æ£€æµ‹ï¼šä¸€ç§ç»“åˆå›¾é“¾å¼æ€ç»´çš„å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨æ–¹æ³•",
      "authors": [
        "Haimei Pan",
        "Jiyun Zhang",
        "Qinxi Wei",
        "Xiongnan Jin",
        "Chen Xinkai",
        "Jie Cheng"
      ],
      "abstract": "Fire is a highly destructive disaster, but effective prevention can significantly reduce its likelihood of occurrence. When it happens, deploying emergency robots in fire-risk scenarios can help minimize the danger to human responders. However, current research on pre-disaster warnings and disaster-time rescue still faces significant challenges due to incomplete perception, inadequate fire situational awareness, and delayed response. To enhance intelligent perception and response planning for robots in fire scenarios, we first construct a knowledge graph (KG) by leveraging large language models (LLMs) to integrate fire domain knowledge derived from fire prevention guidelines and fire rescue task information from robotic emergency response documents. We then propose a new framework called Insights-on-Graph (IOG), which integrates the structured fire information of KG and Large Multimodal Models (LMMs). The framework generates perception-driven risk graphs from real-time scene imagery to enable early fire risk detection and provide interpretable emergency responses for task module and robot component configuration based on the evolving risk situation. Extensive simulations and real-world experiments show that IOG has good applicability and practical application value in fire risk detection and rescue decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç«ç¾æ•‘æ´ä¸­æœºå™¨äººæ„ŸçŸ¥ä¸å…¨å’Œå“åº”å»¶è¿Ÿç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€çŸ¥è¯†å›¾è°±æ¨ç†çš„Insights-on-Graph (IOG)æ¡†æ¶ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆåˆ©ç”¨Large Language Models (LLMs)æ•´åˆç«ç¾é¢„é˜²æŒ‡å—ä¸æ•‘æ´ä»»åŠ¡ä¿¡æ¯ï¼Œæ„å»ºäº†ä¸“ä¸šçš„çŸ¥è¯†å›¾è°±(KG)ã€‚éšåï¼ŒIOGæ¡†æ¶å°†KGçš„ç»“æ„åŒ–çŸ¥è¯†ä¸Large Multimodal Models (LMMs)ç›¸ç»“åˆï¼Œé€šè¿‡å®æ—¶åœºæ™¯å›¾åƒç”Ÿæˆæ„ŸçŸ¥é©±åŠ¨çš„é£é™©å›¾ï¼Œä»è€Œå®ç°æ—©æœŸç«ç¾é£é™©æ£€æµ‹ã€‚è¯¥æ¡†æ¶èƒ½æ ¹æ®ä¸æ–­æ¼”å˜çš„é£é™©çŠ¶å†µï¼Œä¸ºä»»åŠ¡æ¨¡å—å’Œæœºå™¨äººç»„ä»¶é…ç½®æä¾›å…·æœ‰å¯è§£é‡Šæ€§çš„åº”æ€¥å“åº”å†³ç­–ã€‚å¤§é‡çš„ä»¿çœŸå’Œå®åœ°å®éªŒè¯æ˜ï¼ŒIOGåœ¨ç«ç¾é£é™©æ£€æµ‹å’Œæ•‘æ´å†³ç­–é¢†åŸŸå…·æœ‰æå¼ºçš„é€‚ç”¨æ€§ä¸å®é™…åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "We have decided to withdraw this paper as the work is still undergoing further refinement. To ensure the clarity of the results, we prefer to make additional improvements before resubmission. We appreciate the readers' understanding",
      "pdf_url": "https://arxiv.org/pdf/2509.00054v2",
      "published_date": "2025-08-25 07:10:16 UTC",
      "updated_date": "2025-09-07 05:25:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:04:40.351181+00:00"
    },
    {
      "arxiv_id": "2508.17718v1",
      "title": "Instant Preference Alignment for Text-to-Image Diffusion Models",
      "title_zh": "æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å³æ—¶åå¥½å¯¹é½",
      "authors": [
        "Yang Li",
        "Songlin Yang",
        "Xiaoxuan Han",
        "Wei Wang",
        "Jing Dong",
        "Yueming Lyu",
        "Ziyu Xue"
      ],
      "abstract": "Text-to-image (T2I) generation has greatly enhanced creative expression, yet achieving preference-aligned generation in a real-time and training-free manner remains challenging. Previous methods often rely on static, pre-collected preferences or fine-tuning, limiting adaptability to evolving and nuanced user intents. In this paper, we highlight the need for instant preference-aligned T2I generation and propose a training-free framework grounded in multimodal large language model (MLLM) priors. Our framework decouples the task into two components: preference understanding and preference-guided generation. For preference understanding, we leverage MLLMs to automatically extract global preference signals from a reference image and enrich a given prompt using structured instruction design. Our approach supports broader and more fine-grained coverage of user preferences than existing methods. For preference-guided generation, we integrate global keyword-based control and local region-aware cross-attention modulation to steer the diffusion model without additional training, enabling precise alignment across both global attributes and local elements. The entire framework supports multi-round interactive refinement, facilitating real-time and context-aware image generation. Extensive experiments on the Viper dataset and our collected benchmark demonstrate that our method outperforms prior approaches in both quantitative metrics and human evaluations, and opens up new possibilities for dialog-based generation and MLLM-diffusion integration.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒ(T2I)é¢†åŸŸä¸­å®æ—¶ä¸”æ— éœ€è®­ç»ƒçš„åå¥½å¯¹é½éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)å…ˆéªŒçš„æ— éœ€è®­ç»ƒ(training-free)æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†ä»»åŠ¡è§£è€¦ä¸ºåå¥½ç†è§£å’Œåå¥½å¼•å¯¼ç”Ÿæˆä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œåˆ©ç”¨MLLMä»å‚è€ƒå›¾åƒä¸­è‡ªåŠ¨æå–å…¨å±€åå¥½ä¿¡å·ï¼Œå¹¶é€šè¿‡ç»“æ„åŒ–æŒ‡ä»¤è®¾è®¡æ¥ä¸°å¯Œç”¨æˆ·æç¤ºè¯(prompt)ï¼Œå®ç°æ¯”ç°æœ‰æ–¹æ³•æ›´ç»†ç²’åº¦çš„åå¥½è¦†ç›–ã€‚åœ¨ç”Ÿæˆé˜¶æ®µï¼Œè¯¥æ–¹æ³•æ•´åˆäº†å…¨å±€å…³é”®è¯æ§åˆ¶å’Œå±€éƒ¨åŒºåŸŸæ„ŸçŸ¥çš„äº¤å‰æ³¨æ„åŠ›(cross-attention)è°ƒèŠ‚ï¼Œåœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ç²¾ç¡®å¼•å¯¼æ‰©æ•£æ¨¡å‹(diffusion model)å®ç°å…¨å±€ä¸å±€éƒ¨å…ƒç´ çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæ•´ä¸ªæ¡†æ¶æ”¯æŒå¤šè½®äº¤äº’å¼ä¼˜åŒ–ï¼Œèƒ½å¤Ÿå®ç°å®æ—¶ä¸”å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„å›¾åƒç”Ÿæˆã€‚åœ¨Viperæ•°æ®é›†åŠè‡ªå»ºåŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šé‡æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ä¸­å‡ä¼˜äºå…ˆå‰æ–¹æ¡ˆï¼Œä¸ºåŸºäºå¯¹è¯çš„ç”Ÿæˆä»¥åŠMLLMä¸æ‰©æ•£æ¨¡å‹çš„é›†æˆæä¾›äº†æ–°çš„å¯èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17718v1",
      "published_date": "2025-08-25 06:51:15 UTC",
      "updated_date": "2025-08-25 06:51:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:04:48.984170+00:00"
    },
    {
      "arxiv_id": "2509.00053v1",
      "title": "Traj-MLLM: Can Multimodal Large Language Models Reform Trajectory Data Mining?",
      "title_zh": "Traj-MLLMï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹èƒ½å¦é‡å¡‘è½¨è¿¹æ•°æ®æŒ–æ˜ï¼Ÿ",
      "authors": [
        "Shuo Liu",
        "Di Yao",
        "Yan Lin",
        "Gao Cong",
        "Jingping Bi"
      ],
      "abstract": "Building a general model capable of analyzing human trajectories across different geographic regions and different tasks becomes an emergent yet important problem for various applications. However, existing works suffer from the generalization problem, \\ie, they are either restricted to train for specific regions or only suitable for a few tasks. Given the recent advances of multimodal large language models (MLLMs), we raise the question: can MLLMs reform current trajectory data mining and solve the problem? Nevertheless, due to the modality gap of trajectory, how to generate task-independent multimodal trajectory representations and how to adapt flexibly to different tasks remain the foundational challenges. In this paper, we propose \\texttt{Traj-MLLM}}, which is the first general framework using MLLMs for trajectory data mining. By integrating multiview contexts, \\texttt{Traj-MLLM}} transforms raw trajectories into interleaved image-text sequences while preserving key spatial-temporal characteristics, and directly utilizes the reasoning ability of MLLMs for trajectory analysis. Additionally, a prompt optimization method is proposed to finalize data-invariant prompts for task adaptation. Extensive experiments on four publicly available datasets show that \\texttt{Traj-MLLM}} outperforms state-of-the-art baselines by $48.05\\%$, $15.52\\%$, $51.52\\%$, $1.83\\%$ on travel time estimation, mobility prediction, anomaly detection and transportation mode identification, respectively. \\texttt{Traj-MLLM}} achieves these superior performances without requiring any training data or fine-tuning the MLLM backbones.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Traj-MLLMï¼Œè¿™æ˜¯é¦–ä¸ªåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)è¿›è¡Œè½¨è¿¹æ•°æ®æŒ–æ˜çš„é€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨ä¸åŒåœ°ç†åŒºåŸŸå’Œä»»åŠ¡ä¸­æ³›åŒ–èƒ½åŠ›æœ‰é™çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆå¤šè§†å›¾ä¸Šä¸‹æ–‡ï¼Œå°†åŸå§‹è½¨è¿¹è½¬åŒ–ä¸ºäº¤é”™çš„å›¾åƒ-æ–‡æœ¬åºåˆ—(image-text sequences)ï¼Œåœ¨ä¿ç•™å…³é”®æ—¶ç©ºç‰¹å¾çš„åŒæ—¶ç›´æ¥åˆ©ç”¨MLLMsçš„æ¨ç†èƒ½åŠ›è¿›è¡Œè½¨è¿¹åˆ†æã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§æç¤ºä¼˜åŒ–(prompt optimization)æ–¹æ³•ï¼Œç”¨äºå®ç°æ•°æ®ä¸å˜çš„æç¤ºè¯ä»¥è¿›è¡Œä»»åŠ¡é€‚é…ã€‚åœ¨å››ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒTraj-MLLMåœ¨æ—…è¡Œæ—¶é—´ä¼°ç®—(travel time estimation)ã€ç§»åŠ¨é¢„æµ‹(mobility prediction)ã€å¼‚å¸¸æ£€æµ‹(anomaly detection)å’Œè¿è¾“æ¨¡å¼è¯†åˆ«(transportation mode identification)ä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ã€‚æœ€é‡è¦çš„æ˜¯ï¼ŒTraj-MLLMåœ¨æ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®æˆ–å¯¹MLLMséª¨å¹²ç½‘ç»œè¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹å–å¾—äº†è¿™äº›æˆæœï¼Œä¸ºè½¨è¿¹æ•°æ®æŒ–æ˜æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”é€šç”¨çš„æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MM",
      "comment": "20 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.00053v1",
      "published_date": "2025-08-25 06:45:34 UTC",
      "updated_date": "2025-08-25 06:45:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:04:48.294918+00:00"
    },
    {
      "arxiv_id": "2508.17693v1",
      "title": "Database Normalization via Dual-LLM Self-Refinement",
      "title_zh": "åŸºäºåŒå¤§è¯­è¨€æ¨¡å‹è‡ªæˆ‘ç²¾ä¿®çš„æ•°æ®åº“è§„èŒƒåŒ–",
      "authors": [
        "Eunjae Jo",
        "Nakyung Lee",
        "Gyuyeong Kim"
      ],
      "abstract": "Database normalization is crucial to preserving data integrity. However, it is time-consuming and error-prone, as it is typically performed manually by data engineers. To this end, we present Miffie, a database normalization framework that leverages the capability of large language models. Miffie enables automated data normalization without human effort while preserving high accuracy. The core of Miffie is a dual-model self-refinement architecture that combines the best-performing models for normalized schema generation and verification, respectively. The generation module eliminates anomalies based on the feedback of the verification module until the output schema satisfies the requirement for normalization. We also carefully design task-specific zero-shot prompts to guide the models for achieving both high accuracy and cost efficiency. Experimental results show that Miffie can normalize complex database schemas while maintaining high accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°æ®åº“è§„èŒƒåŒ–(Database normalization)ä¼ ç»Ÿæ‰‹åŠ¨æ“ä½œè€—æ—¶ä¸”æ˜“å‡ºé”™çš„é—®é¢˜ï¼Œæå‡ºäº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„è‡ªåŠ¨åŒ–æ¡†æ¶ Miffieã€‚Miffie é‡‡ç”¨äº†æ ¸å¿ƒçš„åŒæ¨¡å‹è‡ªæˆ‘ç»†åŒ–(dual-model self-refinement)æ¶æ„ï¼Œå°†è´Ÿè´£è§„èŒƒåŒ–æ¨¡å¼ç”Ÿæˆ(normalized schema generation)å’ŒéªŒè¯(verification)çš„æœ€ä¼˜æ¨¡å‹ç›¸ç»“åˆã€‚é€šè¿‡è¿™ç§æœºåˆ¶ï¼Œç”Ÿæˆæ¨¡å—èƒ½æ ¹æ®éªŒè¯æ¨¡å—çš„åé¦ˆæŒç»­æ¶ˆé™¤å¼‚å¸¸ï¼Œç›´è‡³è¾“å‡ºæ¨¡å¼æ»¡è¶³è§„èŒƒåŒ–è¦æ±‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ç²¾å¿ƒè®¾è®¡äº†ç‰¹å®šä»»åŠ¡çš„é›¶æ ·æœ¬æç¤º(zero-shot prompts)ï¼Œä»¥å®ç°é«˜å‡†ç¡®ç‡ä¸æˆæœ¬æ•ˆç›Šçš„å¹³è¡¡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒMiffie èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤æ‚çš„æ•°æ®åº“æ¨¡å¼(complex database schemas)å¹¶ä¿æŒæé«˜çš„å‡†ç¡®åº¦ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "5 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.17693v1",
      "published_date": "2025-08-25 06:02:17 UTC",
      "updated_date": "2025-08-25 06:02:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:02.655934+00:00"
    },
    {
      "arxiv_id": "2508.17692v1",
      "title": "LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“æ¨ç†æ¡†æ¶ï¼šä»æ–¹æ³•åˆ°åœºæ™¯çš„ç»¼è¿°",
      "authors": [
        "Bingxi Zhao",
        "Lin Geng Foo",
        "Ping Hu",
        "Christian Theobalt",
        "Hossein Rahmani",
        "Jun Liu"
      ],
      "abstract": "Recent advances in the intrinsic reasoning capabilities of large language models (LLMs) have given rise to LLM-based agent systems that exhibit near-human performance on a variety of automated tasks. However, although these systems share similarities in terms of their use of LLMs, different reasoning frameworks of the agent system steer and organize the reasoning process in different ways. In this survey, we propose a systematic taxonomy that decomposes agentic reasoning frameworks and analyze how these frameworks dominate framework-level reasoning by comparing their applications across different scenarios. Specifically, we propose an unified formal language to further classify agentic reasoning systems into single-agent methods, tool-based methods, and multi-agent methods. After that, we provide a comprehensive review of their key application scenarios in scientific discovery, healthcare, software engineering, social simulation, and economics. We also analyze the characteristic features of each framework and summarize different evaluation strategies. Our survey aims to provide the research community with a panoramic view to facilitate understanding of the strengths, suitable scenarios, and evaluation practices of different agentic reasoning frameworks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨æ¨ç†æ¡†æ¶ä¸Šçš„å·®å¼‚è¿›è¡Œäº†ç³»ç»Ÿæ€§ç»¼è¿°ï¼Œæ¢è®¨äº†ä¸åŒæ¡†æ¶å¦‚ä½•ç»„ç»‡ä¸å¼•å¯¼æ¨ç†è¿‡ç¨‹ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿçš„åˆ†ç±»æ³•æ¥åˆ†è§£ agentic reasoning frameworksï¼Œå¹¶å¼•å…¥ç»Ÿä¸€çš„æ­£å¼è¯­è¨€å°†ç³»ç»Ÿåˆ’åˆ†ä¸º single-agent methodsã€tool-based methods ä»¥åŠ multi-agent methods ä¸‰å¤§ç±»ã€‚æ–‡ç« è¯¦ç»†å›é¡¾äº†è¿™äº›æ¡†æ¶åœ¨ scientific discoveryã€healthcareã€software engineeringã€social simulation å’Œ economics ç­‰æ ¸å¿ƒé¢†åŸŸçš„åº”ç”¨ç°çŠ¶ã€‚æ­¤å¤–ï¼Œç»¼è¿°æ·±å…¥åˆ†æäº†å„æ¡†æ¶çš„ç‰¹å¾ï¼Œå¹¶å¯¹å½“å‰çš„è¯„ä¼°ç­–ç•¥ï¼ˆevaluation strategiesï¼‰è¿›è¡Œäº†æ€»ç»“ã€‚è¯¥ç ”ç©¶æ—¨åœ¨ä¸ºå­¦æœ¯ç•Œæä¾›å…¨æ™¯è§†å›¾ï¼Œå¸®åŠ©ç ”ç©¶è€…ç†è§£ä¸åŒ agentic reasoning frameworks çš„ä¼˜åŠ¿ã€é€‚ç”¨åœºæ™¯åŠè¯„ä¼°æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "51 pages,10 figures,8 tables. Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2508.17692v1",
      "published_date": "2025-08-25 06:01:16 UTC",
      "updated_date": "2025-08-25 06:01:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:04:53.246523+00:00"
    },
    {
      "arxiv_id": "2508.19288v1",
      "title": "Tricking LLM-Based NPCs into Spilling Secrets",
      "title_zh": "è¯±å¯¼åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ NPC æ³„éœ²ç§˜å¯†",
      "authors": [
        "Kyohei Shiomi",
        "Zhuotao Lian",
        "Toru Nakanishi",
        "Teruaki Kitasuka"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used to generate dynamic dialogue for game NPCs. However, their integration raises new security concerns. In this study, we examine whether adversarial prompt injection can cause LLM-based NPCs to reveal hidden background secrets that are meant to remain undisclosed.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ¸¸æˆé¢†åŸŸä¸­ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ä¸ºéç©å®¶è§’è‰² (NPCs) ç”ŸæˆåŠ¨æ€å¯¹è¯æ—¶æ‰€å¸¦æ¥çš„æ–°å…´å®‰å…¨æŒ‘æˆ˜ã€‚ä½œè€…é‡ç‚¹ç ”ç©¶äº†å¯¹æŠ—æ€§æç¤ºæ³¨å…¥ (Adversarial Prompt Injection) æŠ€æœ¯æ˜¯å¦ä¼šå¯¼è‡´åŸºäº LLMs çš„ NPCs æ³„éœ²åŸæœ¬ä¸åº”å…¬å¼€çš„éšè—èƒŒæ™¯ç§˜å¯†ã€‚é€šè¿‡å®éªŒåˆ†æï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†å°†ç”Ÿæˆå¼æ¨¡å‹é›†æˆåˆ°æ¸¸æˆäº¤äº’ç³»ç»Ÿä¸­æ‰€å¼•å…¥çš„æ½œåœ¨å®‰å…¨æ¼æ´ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†åœ¨å¼€å‘åŠ¨æ€å¯¹è¯åŠŸèƒ½æ—¶ï¼Œä¸ä»…éœ€è¦å…³æ³¨äº¤äº’çš„è‡ªç„¶æ€§ï¼Œè¿˜å¿…é¡»é’ˆå¯¹æ•æ„Ÿä¿¡æ¯æ³„éœ²æ„å»ºæœ‰æ•ˆçš„é˜²å¾¡æœºåˆ¶ï¼Œä»¥ç¡®ä¿æ¸¸æˆç¯å¢ƒçš„å®‰å…¨æ€§å’Œé€»è¾‘ä¸¥å¯†æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19288v1",
      "published_date": "2025-08-25 05:25:28 UTC",
      "updated_date": "2025-08-25 05:25:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:04:54.889633+00:00"
    },
    {
      "arxiv_id": "2508.17681v4",
      "title": "Unlearning as Ablation: Toward a Falsifiable Benchmark for Generative Scientific Discovery",
      "title_zh": "ä»¥é—å¿˜å­¦ä¹ ä¸ºæ¶ˆèï¼šæ„å»ºç”Ÿæˆå¼ç§‘å­¦å‘ç°çš„å¯è¯ä¼ªåŸºå‡†",
      "authors": [
        "Robert Yang"
      ],
      "abstract": "Bold claims about AI's role in science-from \"AGI will cure all diseases\" to promises of radically accelerated discovery-raise a central epistemic question: do large language models (LLMs) truly generate new knowledge, or do they merely remix memorized fragments? We propose unlearning-as-ablation as a falsifiable probe of constructive scientific discovery. The idea is to systematically remove a target result together with its forget-closure (supporting lemmas, paraphrases, and multi-hop entailments) and then evaluate whether the model can re-derive the result from only permitted axioms and tools. Success would indicate generative capability beyond recall; failure would expose current limits. Unlike prevailing motivations for unlearning-privacy, copyright, or safety-our framing repositions it as an epistemic probe for AI-for-Science. We outline a minimal pilot in mathematics and algorithms to illustrate feasibility, and sketch how the same approach could later be extended to domains such as physics or chemistry. This is a position paper: our contribution is conceptual and methodological, not empirical. We aim to stimulate discussion on how principled ablation tests could help distinguish models that reconstruct knowledge from those that merely retrieve it, and how such probes might guide the next generation of AI-for-Science benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å°†â€œé—å¿˜ä½œä¸ºæ¶ˆèâ€ï¼ˆunlearning-as-ablationï¼‰ä½œä¸ºä¸€ç§å¯è¯ä¼ªçš„æ¢æµ‹æ‰‹æ®µï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç§‘å­¦å‘ç°ä¸­æ˜¯çœŸæ­£ç”Ÿæˆäº†æ–°çŸ¥è¯†ï¼Œè¿˜æ˜¯ä»…ä»…åœ¨é‡æ–°ç»„åˆè®°å¿†ä¸­çš„ç‰‡æ®µã€‚è¯¥æ–¹æ³•é€šè¿‡ç³»ç»Ÿæ€§åœ°ç§»é™¤ç‰¹å®šç›®æ ‡ç»“æœåŠå…¶ç›¸å…³çš„æ”¯æŒå¼•ç†ã€è½¬è¿°å’Œå¤šè·³è•´å«ï¼ˆforget-closureï¼‰ï¼Œæ¥è¯„ä¼°æ¨¡å‹æ˜¯å¦èƒ½ä»…ä¾é è®¸å¯çš„å…¬ç†å’Œå·¥å…·é‡æ–°æ¨å¯¼å‡ºè¯¥ç»“æœã€‚æˆåŠŸçš„é‡æ–°æ¨å¯¼å°†è¡¨æ˜æ¨¡å‹å…·å¤‡è¶…è¶Šç®€å•å¬å›çš„ç”Ÿæˆèƒ½åŠ›ï¼Œè€Œå¤±è´¥åˆ™ä¼šæ­ç¤ºå…¶å½“å‰çš„å±€é™æ€§ã€‚ä¸ä»¥å¾€å…³æ³¨éšç§ã€ç‰ˆæƒæˆ–å®‰å…¨çš„é—å¿˜ï¼ˆunlearningï¼‰åŠ¨æœºä¸åŒï¼Œæœ¬ç ”ç©¶å°†å…¶é‡æ–°å®šä½ä¸ºAI-for-Scienceçš„ä¸€ç§è®¤è¯†è®ºæ¢æµ‹å™¨ã€‚ä½œä¸ºä¸€ç¯‡ç«‹åœºè®ºæ–‡ï¼Œå…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºæ¦‚å¿µå’Œæ–¹æ³•è®ºå±‚é¢ï¼Œé€šè¿‡åœ¨æ•°å­¦å’Œç®—æ³•é¢†åŸŸè§„åˆ’åˆæ­¥è¯•ç‚¹ï¼Œä¸ºåŒºåˆ†çŸ¥è¯†é‡æ„ä¸å•çº¯æ£€ç´¢çš„æ¨¡å‹æä¾›äº†æŒ‡å¯¼ã€‚è¯¥æ¡†æ¶æ—¨åœ¨æ¿€å‘å…³äºé€šè¿‡è§„èŒƒåŒ–æ¶ˆèæµ‹è¯•æ¥æ„å»ºç§‘å­¦å‘ç°åŸºå‡†çš„è®¨è®ºï¼Œä»è€Œå¼•å¯¼ä¸‹ä¸€ä»£äººå·¥æ™ºèƒ½ç§‘å­¦ç ”ç©¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages + appendix. Accepted to NeurIPS 2025 AI4Science Workshop",
      "pdf_url": "https://arxiv.org/pdf/2508.17681v4",
      "published_date": "2025-08-25 05:24:15 UTC",
      "updated_date": "2025-11-25 02:30:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:17.753517+00:00"
    },
    {
      "arxiv_id": "2508.17680v1",
      "title": "Robustness Feature Adapter for Efficient Adversarial Training",
      "title_zh": "ç”¨äºé«˜æ•ˆå¯¹æŠ—è®­ç»ƒçš„é²æ£’ç‰¹å¾é€‚é…å™¨",
      "authors": [
        "Quanwei Wu",
        "Jun Guo",
        "Wei Wang",
        "Yi Wang"
      ],
      "abstract": "Adversarial training (AT) with projected gradient descent is the most popular method to improve model robustness under adversarial attacks. However, computational overheads become prohibitively large when AT is applied to large backbone models. AT is also known to have the issue of robust overfitting. This paper contributes to solving both problems simultaneously towards building more trustworthy foundation models. In particular, we propose a new adapter-based approach for efficient AT directly in the feature space. We show that the proposed adapter-based approach can improve the inner-loop convergence quality by eliminating robust overfitting. As a result, it significantly increases computational efficiency and improves model accuracy by generalizing adversarial robustness to unseen attacks. We demonstrate the effectiveness of the new adapter-based approach in different backbone architectures and in AT at scale.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Robustness Feature Adapterï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„åŸºäºé€‚é…å™¨(adapter-based)çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¯¹æŠ—è®­ç»ƒ(Adversarial Training, AT)åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸­é¢ä¸´çš„è®¡ç®—å¼€é”€å·¨å¤§å’Œé²æ£’è¿‡æ‹Ÿåˆ(robust overfitting)é—®é¢˜ã€‚è¯¥æ–¹æ³•ç›´æ¥åœ¨ç‰¹å¾ç©ºé—´å†…æ‰§è¡Œé«˜æ•ˆçš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿæ˜¾è‘—æ”¹å–„å†…å±‚å¾ªç¯çš„æ”¶æ•›è´¨é‡ï¼Œä»è€Œæœ‰æ•ˆæ¶ˆé™¤é²æ£’è¿‡æ‹Ÿåˆç°è±¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•ä¸ä»…å¤§å¹…æå‡äº†è®¡ç®—æ•ˆç‡ï¼Œè¿˜é€šè¿‡å°†å¯¹æŠ—é²æ£’æ€§æ³›åŒ–åˆ°æœªè§è¿‡çš„æ”»å‡»ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ•´ä½“å‡†ç¡®æ€§ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨å¤šç§éª¨å¹²æ¶æ„å’Œå¤§è§„æ¨¡å¯¹æŠ—è®­ç»ƒåœºæ™¯ä¸­éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæ„å»ºæ›´åŠ å¯ä¿¡çš„åŸºç¡€æ¨¡å‹æä¾›äº†é‡è¦è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been accepted for presentation at ECAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17680v1",
      "published_date": "2025-08-25 05:23:50 UTC",
      "updated_date": "2025-08-25 05:23:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:06.046419+00:00"
    },
    {
      "arxiv_id": "2508.19287v1",
      "title": "Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior",
      "title_zh": "å†…å®¹åµŒå…¥æç¤ºæ”»å‡»ï¼šåˆ©ç”¨ä¸Šä¼ è¾“å…¥åŠ«æŒå¤§è¯­è¨€æ¨¡å‹è¡Œä¸º",
      "authors": [
        "Zhuotao Lian",
        "Weiyu Wang",
        "Qingkui Zeng",
        "Toru Nakanishi",
        "Teruaki Kitasuka",
        "Chunhua Su"
      ],
      "abstract": "Large Language Models (LLMs) are widely deployed in applications that accept user-submitted content, such as uploaded documents or pasted text, for tasks like summarization and question answering. In this paper, we identify a new class of attacks, prompt in content injection, where adversarial instructions are embedded in seemingly benign inputs. When processed by the LLM, these hidden prompts can manipulate outputs without user awareness or system compromise, leading to biased summaries, fabricated claims, or misleading suggestions. We demonstrate the feasibility of such attacks across popular platforms, analyze their root causes including prompt concatenation and insufficient input isolation, and discuss mitigation strategies. Our findings reveal a subtle yet practical threat in real-world LLM workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶ç¡®å®šäº†ä¸€ç±»æ–°å‹æ”»å‡»ï¼Œå³ prompt in content injectionï¼ˆå†…å®¹ä¸­æç¤ºæ³¨å…¥ï¼‰ï¼Œå…¶ä¸­æ¶æ„æŒ‡ä»¤è¢«åµŒå…¥åˆ°çœ‹ä¼¼æ— å®³çš„ä¸Šä¼ æ–‡æ¡£æˆ–ç²˜è´´æ–‡æœ¬ç­‰ç”¨æˆ·æäº¤å†…å®¹ä¸­ã€‚å½“å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¤„ç†è¿™äº›è¾“å…¥è¿›è¡Œæ‘˜è¦ç”Ÿæˆæˆ–é—®ç­”ä»»åŠ¡æ—¶ï¼Œéšè—çš„æç¤ºå¯ä»¥åœ¨ç”¨æˆ·ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹æ“çºµè¾“å‡ºï¼Œå¯¼è‡´äº§ç”Ÿæœ‰åè§çš„æ‘˜è¦ã€è™šå‡å£°æ˜æˆ–è¯¯å¯¼æ€§å»ºè®®ã€‚é€šè¿‡åœ¨å¤šä¸ªæµè¡Œå¹³å°ä¸Šçš„å®éªŒï¼Œç ”ç©¶è¯æ˜äº†æ­¤ç±»æ”»å‡»çš„å¯è¡Œæ€§ï¼Œå¹¶æŒ‡å‡ºå…¶æ ¹æºåœ¨äº prompt concatenationï¼ˆæç¤ºæ‹¼æ¥ï¼‰ä»¥åŠè¾“å…¥éš”ç¦»ä¸è¶³ã€‚è¯¥è®ºæ–‡è¯¦ç»†åˆ†æäº†æ”»å‡»æœºåˆ¶å¹¶è®¨è®ºäº†ç›¸åº”çš„ç¼“è§£ç­–ç•¥ï¼Œæ­ç¤ºäº†ç°å®ä¸–ç•Œ LLM å·¥ä½œæµä¸­ä¸€ç§éšè”½ä¸”å…·æœ‰å®é™…å¨èƒçš„å®‰å…¨é£é™©ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19287v1",
      "published_date": "2025-08-25 05:20:11 UTC",
      "updated_date": "2025-08-25 05:20:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:18.851866+00:00"
    },
    {
      "arxiv_id": "2508.17674v2",
      "title": "Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models",
      "title_zh": "æ”»å‡»å¤§è¯­è¨€æ¨¡å‹ä¸ AI æ™ºèƒ½ä½“ï¼šé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹çš„å¹¿å‘ŠåµŒå…¥æ”»å‡»",
      "authors": [
        "Qiming Guo",
        "Jinwen Tang",
        "Xingran Huang"
      ],
      "abstract": "We introduce Advertisement Embedding Attacks (AEA), a new class of LLM security threats that stealthily inject promotional or malicious content into model outputs and AI agents. AEA operate through two low-cost vectors: (1) hijacking third-party service-distribution platforms to prepend adversarial prompts, and (2) publishing back-doored open-source checkpoints fine-tuned with attacker data. Unlike conventional attacks that degrade accuracy, AEA subvert information integrity, causing models to return covert ads, propaganda, or hate speech while appearing normal. We detail the attack pipeline, map five stakeholder victim groups, and present an initial prompt-based self-inspection defense that mitigates these injections without additional model retraining. Our findings reveal an urgent, under-addressed gap in LLM security and call for coordinated detection, auditing, and policy responses from the AI-safety community.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å¹¿å‘ŠåµŒå…¥æ”»å‡» (Advertisement Embedding Attacks, AEA)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) å’Œ AI æ™ºèƒ½ä½“çš„æ–°å‹å®‰å…¨å¨èƒï¼Œæ—¨åœ¨éšè”½åœ°åœ¨æ¨¡å‹è¾“å‡ºä¸­æ³¨å…¥ä¿ƒé”€æˆ–æ¶æ„å†…å®¹ã€‚AEA ä¸»è¦é€šè¿‡åŠ«æŒç¬¬ä¸‰æ–¹æœåŠ¡åˆ†å‘å¹³å°ä»¥æ·»åŠ å¯¹æŠ—æ€§æç¤ºï¼Œä»¥åŠå‘å¸ƒç»è¿‡æ¶æ„æ•°æ®å¾®è°ƒçš„å¸¦åé—¨å¼€æºæ£€æŸ¥ç‚¹ (checkpoints) è¿™ä¸¤ç±»ä½æˆæœ¬å‘é‡å®ç°ã€‚ä¸ä¼ ç»Ÿçš„å‡†ç¡®ç‡ç ´åæ”»å‡»ä¸åŒï¼ŒAEA ç ´åäº†ä¿¡æ¯å®Œæ•´æ€§ï¼Œä½¿æ¨¡å‹åœ¨è¡¨ç°æ­£å¸¸çš„æƒ…å†µä¸‹è¿”å›éšè”½å¹¿å‘Šã€å®£ä¼ ä¿¡æ¯æˆ–ä»‡æ¨è¨€è®ºã€‚ç ”ç©¶è¯¦ç»†é˜è¿°äº†æ”»å‡»æµç¨‹ï¼Œè¯†åˆ«äº†äº”ç±»åˆ©ç›Šç›¸å…³å—å®³è€…ç¾¤ä½“ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ— éœ€é¢å¤–æ¨¡å‹é‡è®­å³å¯ç¼“è§£æ­¤ç±»æ³¨å…¥çš„æç¤ºè¯è‡ªæ£€é˜²å¾¡æœºåˆ¶ã€‚è¿™äº›å‘ç°æ­ç¤ºäº† LLM å®‰å…¨é¢†åŸŸä¸­ä¸€ä¸ªäºŸå¾…è§£å†³çš„ç´§è¿«ç©ºç™½ï¼Œå¹¶å‘¼å AI å®‰å…¨ç¤¾åŒºåŠ å¼ºååŒæ£€æµ‹ã€å®¡è®¡å’Œæ”¿ç­–å“åº”ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.17674v2",
      "published_date": "2025-08-25 05:13:23 UTC",
      "updated_date": "2025-09-08 18:05:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:19.046511+00:00"
    },
    {
      "arxiv_id": "2508.17671v6",
      "title": "Consistent Opponent Modeling in Imperfect-Information Games",
      "title_zh": "ä¸å®Œç¾ä¿¡æ¯åšå¼ˆä¸­çš„ä¸€è‡´å¯¹æ‰‹å»ºæ¨¡",
      "authors": [
        "Sam Ganzfried"
      ],
      "abstract": "The goal of agents in multi-agent environments is to maximize total reward against the opposing agents that are encountered. Following a game-theoretic solution concept, such as Nash equilibrium, may obtain a strong performance in some settings; however, such approaches fail to capitalize on historical and observed data from repeated interactions against our opponents. Opponent modeling algorithms integrate machine learning techniques to exploit suboptimal opponents utilizing available data; however, the effectiveness of such approaches in imperfect-information games to date is quite limited. We show that existing opponent modeling approaches fail to satisfy a simple desirable property even against static opponents drawn from a known prior distribution; namely, they do not guarantee that the model approaches the opponent's true strategy even in the limit as the number of game iterations approaches infinity. We develop a new algorithm that is able to achieve this property and runs efficiently by solving a convex minimization problem based on the sequence-form game representation using projected gradient descent. The algorithm is guaranteed to efficiently converge to the opponent's true strategy under standard Bayesian identifiability and visitation assumptions, given observations from gameplay and possibly additional historical data if it is available.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸å®Œå…¨ä¿¡æ¯åšå¼ˆ (Imperfect-Information Games) ä¸­çš„å¯¹æ‰‹å»ºæ¨¡ (Opponent Modeling) é—®é¢˜å±•å¼€ï¼ŒæŒ‡å‡ºå½“å‰æ–¹æ³•å³ä¾¿åœ¨é¢å¯¹å·²çŸ¥å…ˆéªŒåˆ†å¸ƒçš„é™æ€å¯¹æ‰‹æ—¶ï¼Œä¹Ÿæ— æ³•ä¿è¯æ¨¡å‹åœ¨åšå¼ˆæ¬¡æ•°è¶‹äºæ— ç©·æ—¶é€¼è¿‘å¯¹æ‰‹çš„çœŸå®ç­–ç•¥ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å…·å¤‡ä¸€è‡´æ€§ (Consistent) çš„æ–°ç®—æ³•ï¼Œæ—¨åœ¨é€šè¿‡åˆ©ç”¨åšå¼ˆè§‚å¯Ÿæ•°æ®å’Œå†å²ä¿¡æ¯æ¥ç²¾ç¡®æ•æ‰å¯¹æ‰‹è¡Œä¸ºã€‚è¯¥ç®—æ³•å°†å¯¹æ‰‹å»ºæ¨¡è¿‡ç¨‹è½¬åŒ–ä¸ºåŸºäºåºåˆ—å½¢å¼åšå¼ˆè¡¨ç¤º (Sequence-form game representation) çš„å‡¸æœ€å°åŒ– (Convex Minimization) é—®é¢˜ï¼Œå¹¶é‡‡ç”¨æŠ•å½±æ¢¯åº¦ä¸‹é™ (Projected Gradient Descent) æ–¹æ³•è¿›è¡Œé«˜æ•ˆæ±‚è§£ã€‚åœ¨æ»¡è¶³æ ‡å‡†è´å¶æ–¯å¯è¾¨è¯†æ€§ (Bayesian identifiability) å’Œè®¿é—®å‡è®¾çš„å‰æä¸‹ï¼Œè¯¥ç®—æ³•è¢«è¯æ˜èƒ½å¤Ÿç¡®ä¿æ¨¡å‹é«˜æ•ˆåœ°æ”¶æ•›è‡³å¯¹æ‰‹çš„çœŸå®ç­–ç•¥ã€‚è¿™é¡¹å·¥ä½œå…‹æœäº†ç°æœ‰å¯¹æ‰‹å»ºæ¨¡æŠ€æœ¯çš„ç†è®ºç¼ºé™·ï¼Œä¸ºåœ¨å¤æ‚å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å®ç°æ›´å…·é²æ£’æ€§çš„å†³ç­–ä¼˜åŒ–å¥ å®šäº†æ•°å­¦åŸºç¡€ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17671v6",
      "published_date": "2025-08-25 05:08:49 UTC",
      "updated_date": "2026-01-02 08:55:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:40.296356+00:00"
    },
    {
      "arxiv_id": "2508.17669v1",
      "title": "A Taxonomy of Transcendence",
      "title_zh": "è¶…è¶Šæ€§åˆ†ç±»å­¦",
      "authors": [
        "Natalie Abreu",
        "Edwin Zhang",
        "Eran Malach",
        "Naomi Saphra"
      ],
      "abstract": "Although language models are trained to mimic humans, the resulting systems display capabilities beyond the scope of any one person. To understand this phenomenon, we use a controlled setting to identify properties of the training data that lead a model to transcend the performance of its data sources. We build on previous work to outline three modes of transcendence, which we call skill denoising, skill selection, and skill generalization. We then introduce a knowledge graph-based setting in which simulated experts generate data based on their individual expertise. We highlight several aspects of data diversity that help to enable the model's transcendent capabilities. Additionally, our data generation setting offers a controlled testbed that we hope is valuable for future research in the area.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è¯­è¨€æ¨¡å‹(language models)å°½ç®¡ä»¥æ¨¡ä»¿äººç±»ä¸ºè®­ç»ƒç›®æ ‡ï¼Œä½†æœ€ç»ˆå±•ç°å‡ºè¶…è¶Šå•ä¸ªäººç±»èƒ½åŠ›çš„ç°è±¡ã€‚ä¸ºäº†å‰–æè¿™ç§â€œè¶…è¶Šæ€§â€ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸‰ç§æ ¸å¿ƒæ¨¡å¼ï¼šæŠ€èƒ½å»å™ª(skill denoising)ã€æŠ€èƒ½é€‰æ‹©(skill selection)å’ŒæŠ€èƒ½æ³›åŒ–(skill generalization)ã€‚è¯¥ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±(knowledge graph)çš„å—æ§å®éªŒç¯å¢ƒï¼Œé€šè¿‡æ¨¡æ‹Ÿä¸“å®¶ç”Ÿæˆçš„æ•°æ®æ¥ç ”ç©¶æ¨¡å‹å¦‚ä½•çªç ´å…¶æ•°æ®æºçš„æ€§èƒ½é™åˆ¶ã€‚å®éªŒç»“æœé‡ç‚¹æ­ç¤ºäº†æ•°æ®å¤šæ ·æ€§(data diversity)åœ¨ä¿ƒæˆæ¨¡å‹è¶…è¶Šèƒ½åŠ›æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æ‰€å¼•å…¥çš„å—æ§æµ‹è¯•å¹³å°ä¹Ÿä¸ºæœªæ¥æ¢ç´¢æ¨¡å‹æ€§èƒ½è¶…è¶Šè®­ç»ƒæ•°æ®çš„æœºç†æä¾›äº†é‡è¦çš„ç ”ç©¶å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17669v1",
      "published_date": "2025-08-25 05:05:00 UTC",
      "updated_date": "2025-08-25 05:05:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:45.150153+00:00"
    },
    {
      "arxiv_id": "2508.17667v1",
      "title": "Hierarchical Vision-Language Learning for Medical Out-of-Distribution Detection",
      "title_zh": "é¢å‘åŒ»ç–—åˆ†å¸ƒå¤–æ£€æµ‹çš„å±‚çº§åŒ–è§†è§‰-è¯­è¨€å­¦ä¹ ",
      "authors": [
        "Runhe Lai",
        "Xinhua Lu",
        "Kanghao Chen",
        "Qichao Chen",
        "Wei-Shi Zheng",
        "Ruixuan Wang"
      ],
      "abstract": "In trustworthy medical diagnosis systems, integrating out-of-distribution (OOD) detection aims to identify unknown diseases in samples, thereby mitigating the risk of misdiagnosis. In this study, we propose a novel OOD detection framework based on vision-language models (VLMs), which integrates hierarchical visual information to cope with challenging unknown diseases that resemble known diseases. Specifically, a cross-scale visual fusion strategy is proposed to couple visual embeddings from multiple scales. This enriches the detailed representation of medical images and thus improves the discrimination of unknown diseases. Moreover, a cross-scale hard pseudo-OOD sample generation strategy is proposed to benefit OOD detection maximally. Experimental evaluations on three public medical datasets support that the proposed framework achieves superior OOD detection performance compared to existing methods. The source code is available at https://openi.pcl.ac.cn/OpenMedIA/HVL.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)çš„å±‚æ¬¡åŒ–åˆ†å¸ƒå¤–æ£€æµ‹(Out-of-Distribution, OOD)æ¡†æ¶ï¼Œæ—¨åœ¨è¯†åˆ«åŒ»ç–—è¯Šæ–­ä¸­ä¸å·²çŸ¥ç–¾ç—…ç›¸ä¼¼çš„æœªçŸ¥æ ·æœ¬ï¼Œä»è€Œé™ä½è¯¯è¯Šé£é™©ã€‚ä¸ºäº†åº”å¯¹å¤æ‚å¤šå˜çš„åŒ»ç–—å›¾åƒï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†è·¨å°ºåº¦è§†è§‰èåˆ(Cross-scale visual fusion)ç­–ç•¥ï¼Œé€šè¿‡æ•´åˆå¤šä¸ªå°ºåº¦çš„è§†è§‰åµŒå…¥(Visual embeddings)æ¥ä¸°å¯Œå›¾åƒçš„ç»†èŠ‚ç‰¹å¾è¡¨ç¤ºï¼Œæ˜¾è‘—æå‡äº†å¯¹æœªçŸ¥ç–¾ç—…çš„è¾¨åˆ«èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜è¿›ä¸€æ­¥å¼€å‘äº†è·¨å°ºåº¦å›°éš¾ä¼ªOODæ ·æœ¬ç”Ÿæˆ(Cross-scale hard pseudo-OOD sample generation)ç­–ç•¥ï¼Œé€šè¿‡æ„é€ å…·æœ‰æŒ‘æˆ˜æ€§çš„è®­ç»ƒæ ·æœ¬æ¥æœ€å¤§åŒ–æ£€æµ‹æ•ˆèƒ½ã€‚åœ¨ä¸‰ä¸ªå…¬å…±åŒ»ç–—æ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°è¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºæ„å»ºå¯ä¿¡èµ–çš„åŒ»ç–—è¯Šæ–­ç³»ç»Ÿæä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 2 figures, Accepted by MICCAI2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17667v1",
      "published_date": "2025-08-25 04:55:27 UTC",
      "updated_date": "2025-08-25 04:55:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:44.351114+00:00"
    },
    {
      "arxiv_id": "2508.17661v1",
      "title": "Spacer: Towards Engineered Scientific Inspiration",
      "title_zh": "Spacerï¼šè¿ˆå‘å·¥ç¨‹åŒ–çš„ç§‘å­¦çµæ„Ÿ",
      "authors": [
        "Minhyeong Lee",
        "Suyoung Hwang",
        "Seunghyun Moon",
        "Geonho Nah",
        "Donghyun Koh",
        "Youngjun Cho",
        "Johyun Park",
        "Hojin Yoo",
        "Jiho Park",
        "Haneul Choi",
        "Sungbin Moon",
        "Taehoon Hwang",
        "Seungwon Kim",
        "Jaeyeong Kim",
        "Seongjun Kim",
        "Juneau Jung"
      ],
      "abstract": "Recent advances in LLMs have made automated scientific research the next frontline in the path to artificial superintelligence. However, these systems are bound either to tasks of narrow scope or the limited creative capabilities of LLMs. We propose Spacer, a scientific discovery system that develops creative and factually grounded concepts without external intervention. Spacer attempts to achieve this via 'deliberate decontextualization,' an approach that disassembles information into atomic units - keywords - and draws creativity from unexplored connections between them. Spacer consists of (i) Nuri, an inspiration engine that builds keyword sets, and (ii) the Manifesting Pipeline that refines these sets into elaborate scientific statements. Nuri extracts novel, high-potential keyword sets from a keyword graph built with 180,000 academic publications in biological fields. The Manifesting Pipeline finds links between keywords, analyzes their logical structure, validates their plausibility, and ultimately drafts original scientific concepts. According to our experiments, the evaluation metric of Nuri accurately classifies high-impact publications with an AUROC score of 0.737. Our Manifesting Pipeline also successfully reconstructs core concepts from the latest top-journal articles solely from their keyword sets. An LLM-based scoring system estimates that this reconstruction was sound for over 85% of the cases. Finally, our embedding space analysis shows that outputs from Spacer are significantly more similar to leading publications compared with those from SOTA LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Spacerï¼Œä¸€ä¸ªæ—¨åœ¨å®ç°å·¥ç¨‹åŒ–ç§‘å­¦çµæ„Ÿå’Œè‡ªåŠ¨åŒ–ç§‘å­¦å‘ç°çš„ç³»ç»Ÿï¼Œä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç§‘å­¦ç ”ç©¶ä¸­é¢ä¸´çš„åˆ›æ„å±€é™ã€‚è¯¥ç³»ç»Ÿæ ¸å¿ƒé‡‡ç”¨äº†â€œåˆ»æ„å»è¯­å¢ƒåŒ–â€(deliberate decontextualization)ç­–ç•¥ï¼Œé€šè¿‡å°†ä¿¡æ¯åˆ†è§£ä¸ºåŸå­å…³é”®è¯å¹¶æ¢ç´¢å…¶é—´æœªè¢«å‘ç°çš„è”ç³»æ¥æ¿€å‘çµæ„Ÿã€‚Spacer ç”±çµæ„Ÿå¼•æ“ Nuri å’Œ Manifesting Pipeline ç»„æˆï¼Œå‰è€…åŸºäº 180,000 ç¯‡ç”Ÿç‰©é¢†åŸŸè®ºæ–‡æ„å»ºçš„å…³é”®è¯å›¾è°±æå–é«˜æ½œåŠ›ç»„åˆï¼Œåè€…åˆ™è´Ÿè´£åˆ†æé€»è¾‘ç»“æ„å¹¶å°†å…¶ç»†åŒ–ä¸ºç§‘å­¦é™ˆè¿°ã€‚å®éªŒè¡¨æ˜ï¼ŒNuri åœ¨è¯†åˆ«é«˜å½±å“åŠ›è®ºæ–‡æ–¹é¢çš„ AUROC è¾¾åˆ° 0.737ï¼Œä¸” Manifesting Pipeline èƒ½ä»¥è¶…è¿‡ 85% çš„å‡†ç¡®ç‡é‡æ„é¡¶çº§æœŸåˆŠçš„æ ¸å¿ƒæ¦‚å¿µã€‚åµŒå…¥ç©ºé—´åˆ†æè¯å®ï¼Œç›¸æ¯”äºç›®å‰çš„ SOTA LLMsï¼ŒSpacer äº§å‡ºçš„æ¦‚å¿µä¸é¢†å…ˆå­¦æœ¯å‡ºç‰ˆç‰©å…·æœ‰æ›´é«˜çš„ç›¸ä¼¼æ€§ï¼Œä¸ºè‡ªä¸»ç§‘å­¦æ¢ç´¢æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17661v1",
      "published_date": "2025-08-25 04:49:16 UTC",
      "updated_date": "2025-08-25 04:49:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:45.991770+00:00"
    },
    {
      "arxiv_id": "2508.19286v1",
      "title": "RL-Finetuned LLMs for Privacy-Preserving Synthetic Rewriting",
      "title_zh": "ç”¨äºéšç§ä¿æŠ¤åˆæˆæ”¹å†™çš„ RL å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Zhan Shi",
        "Yefeng Yuan",
        "Yuhong Liu",
        "Liang Cheng",
        "Yi Fang"
      ],
      "abstract": "The performance of modern machine learning systems depends on access to large, high-quality datasets, often sourced from user-generated content or proprietary, domain-specific corpora. However, these rich datasets inherently contain sensitive personal information, raising significant concerns about privacy, data security, and compliance with regulatory frameworks. While conventional anonymization techniques can remove explicit identifiers, such removal may result in performance drop in downstream machine learning tasks. More importantly, simple anonymization may not be effective against inference attacks that exploit implicit signals such as writing style, topical focus, or demographic cues, highlighting the need for more robust privacy safeguards during model training. To address the challenging issue of balancing user privacy and data utility, we propose a reinforcement learning framework that fine-tunes a large language model (LLM) using a composite reward function that jointly optimizes for explicit and implicit privacy, semantic fidelity, and output diversity. To effectively capture population level regularities, the privacy reward combines semantic cues with structural patterns derived from a minimum spanning tree (MST) over latent representations. By modeling these privacy-sensitive signals in their distributional context, the proposed approach guides the model to generate synthetic rewrites that preserve utility while mitigating privacy risks. Empirical results show that the proposed method significantly enhances author obfuscation and privacy metrics without degrading semantic quality, providing a scalable and model-agnostic solution for privacy preserving data generation in the era of large language models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„æ¡†æ¶ï¼Œé€šè¿‡å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹(LLMs)æ¥è§£å†³æ•°æ®å…±äº«ä¸­çš„ç”¨æˆ·éšç§ä¸æ•°æ®æ•ˆç”¨å¹³è¡¡é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åº”å¯¹é’ˆå¯¹å†™ä½œé£æ ¼ç­‰éšå¼ä¿¡å·çš„æ¨ç†æ”»å‡»ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¤åˆå¥–åŠ±å‡½æ•°ï¼ŒååŒä¼˜åŒ–æ˜¾å¼ä¸éšå¼éšç§ã€è¯­ä¹‰ä¿çœŸåº¦ä»¥åŠè¾“å‡ºå¤šæ ·æ€§ã€‚ä¸ºäº†æœ‰æ•ˆæ•æ‰ç¾¤ä½“å±‚é¢çš„è§„å¾‹ï¼Œéšç§å¥–åŠ±ç»“åˆäº†è¯­ä¹‰çº¿ç´¢ä¸åŸºäºæ½œåœ¨è¡¨ç¤ºç”Ÿæˆçš„æœ€å°ç”Ÿæˆæ ‘(Minimum Spanning Tree, MST)ç»“æ„æ¨¡å¼ã€‚é€šè¿‡åœ¨åˆ†å¸ƒä¸Šä¸‹æ–‡ä¸­å»ºæ¨¡éšç§æ•æ„Ÿä¿¡å·ï¼Œè¯¥æ–¹æ³•å¼•å¯¼æ¨¡å‹ç”Ÿæˆæ—¢èƒ½ä¿ç•™æ•ˆç”¨åˆèƒ½é™ä½éšç§é£é™©çš„åˆæˆé‡å†™å†…å®¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸é™ä½è¯­ä¹‰è´¨é‡çš„å‰æä¸‹ï¼Œæ˜¾è‘—å¢å¼ºäº†ä½œè€…æ··æ·†(Author Obfuscation)å’Œéšç§ä¿æŠ¤æŒ‡æ ‡ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£çš„éšç§ä¿æŠ¤æ•°æ®ç”Ÿæˆæä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”æ¨¡å‹æ— å…³(Model-agnostic)çš„æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.19286v1",
      "published_date": "2025-08-25 04:38:19 UTC",
      "updated_date": "2025-08-25 04:38:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:05:44.547757+00:00"
    },
    {
      "arxiv_id": "2508.17637v1",
      "title": "Weights-Rotated Preference Optimization for Large Language Models",
      "title_zh": "é¢å‘å¤§è¯­è¨€æ¨¡å‹çš„æƒé‡æ—‹è½¬åå¥½ä¼˜åŒ–",
      "authors": [
        "Chenxu Yang",
        "Ruipeng Jia",
        "Mingyu Zheng",
        "Naibin Gu",
        "Zheng Lin",
        "Siyuan Chen",
        "Weichong Yin",
        "Hua Wu",
        "Weiping Wang"
      ],
      "abstract": "Despite the efficacy of Direct Preference Optimization (DPO) in aligning Large Language Models (LLMs), reward hacking remains a pivotal challenge. This issue emerges when LLMs excessively reduce the probability of rejected completions to achieve high rewards, without genuinely meeting their intended goals. As a result, this leads to overly lengthy generation lacking diversity, as well as catastrophic forgetting of knowledge. We investigate the underlying reason behind this issue, which is representation redundancy caused by neuron collapse in the parameter space. Hence, we propose a novel Weights-Rotated Preference Optimization (RoPO) algorithm, which implicitly constrains the output layer logits with the KL divergence inherited from DPO and explicitly constrains the intermediate hidden states by fine-tuning on a multi-granularity orthogonal matrix. This design prevents the policy model from deviating too far from the reference model, thereby retaining the knowledge and expressive capabilities acquired during pre-training and SFT stages. Our RoPO achieves up to a 3.27-point improvement on AlpacaEval 2, and surpasses the best baseline by 6.2 to 7.5 points on MT-Bench with merely 0.015% of the trainable parameters, demonstrating its effectiveness in alleviating the reward hacking problem of DPO.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Direct Preference Optimization (DPO) åœ¨å¤§è¯­è¨€æ¨¡å‹å¯¹é½è¿‡ç¨‹ä¸­å‡ºç°çš„å¥–åŠ±ç ´è§£ (reward hacking) é—®é¢˜ï¼ŒæŒ‡å‡ºå…¶æ ¹æºåœ¨äºç¥ç»å…ƒåç¼© (neuron collapse) å¯¼è‡´çš„è¡¨ç¤ºå†—ä½™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†æƒé‡æ—‹è½¬åå¥½ä¼˜åŒ– (Weights-Rotated Preference Optimization, RoPO) ç®—æ³•ï¼Œé€šè¿‡ç»“åˆ KL æ•£åº¦éšå¼çº¦æŸè¾“å‡ºå±‚é€»è¾‘å€¼ (logits) ä»¥åŠåˆ©ç”¨å¤šç²’åº¦æ­£äº¤çŸ©é˜µ (multi-granularity orthogonal matrix) æ˜¾å¼çº¦æŸä¸­é—´éšè—çŠ¶æ€ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é˜²æ­¢ç­–ç•¥æ¨¡å‹è¿‡åº¦åç¦»å‚è€ƒæ¨¡å‹ï¼Œä»è€Œæœ‰æ•ˆä¿ç•™é¢„è®­ç»ƒå’Œ SFT é˜¶æ®µçš„çŸ¥è¯†ä¸è¡¨è¾¾èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒRoPO åœ¨ AlpacaEval 2 å’Œ MT-Bench ç­‰åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œä¸”ä»…éœ€ 0.015% çš„å¯è®­ç»ƒå‚æ•°ï¼Œä¸ºç¼“è§£ DPO çš„å¥–åŠ±ç ´è§£åŠç¾éš¾æ€§é—å¿˜é—®é¢˜æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17637v1",
      "published_date": "2025-08-25 03:57:17 UTC",
      "updated_date": "2025-08-25 03:57:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:22.889987+00:00"
    },
    {
      "arxiv_id": "2508.17636v1",
      "title": "Few-Shot Pattern Detection via Template Matching and Regression",
      "title_zh": "åŸºäºæ¨¡æ¿åŒ¹é…ä¸å›å½’çš„å°‘æ ·æœ¬æ¨¡å¼æ£€æµ‹",
      "authors": [
        "Eunchan Jo",
        "Dahyun Kang",
        "Sanghyun Kim",
        "Yunseon Choi",
        "Minsu Cho"
      ],
      "abstract": "We address the problem of few-shot pattern detection, which aims to detect all instances of a given pattern, typically represented by a few exemplars, from an input image. Although similar problems have been studied in few-shot object counting and detection (FSCD), previous methods and their benchmarks have narrowed patterns of interest to object categories and often fail to localize non-object patterns. In this work, we propose a simple yet effective detector based on template matching and regression, dubbed TMR. While previous FSCD methods typically represent target exemplars as spatially collapsed prototypes and lose structural information, we revisit classic template matching and regression. It effectively preserves and leverages the spatial layout of exemplars through a minimalistic structure with a small number of learnable convolutional or projection layers on top of a frozen backbone We also introduce a new dataset, dubbed RPINE, which covers a wider range of patterns than existing object-centric datasets. Our method outperforms the state-of-the-art methods on the three benchmarks, RPINE, FSCD-147, and FSCD-LVIS, and demonstrates strong generalization in cross-dataset evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°‘æ ·æœ¬æ¨¡å¼æ£€æµ‹(Few-Shot Pattern Detection)ä¸­ä¼ ç»Ÿæ–¹æ³•å¾€å¾€å±€é™äºç‰©ä½“ç±»åˆ«ä¸”éš¾ä»¥å®šä½éç‰©ä½“æ¨¡å¼çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºTMRçš„æ¨¡æ¿åŒ¹é…ä¸å›å½’(Template Matching and Regression)æ£€æµ‹å™¨ã€‚ä¸ä»¥å¾€å°†æ ·æœ¬è¡¨å¾ä¸ºç©ºé—´æŠ˜å åŸå‹(Spatially Collapsed Prototypes)è€Œä¸¢å¤±ç»“æ„ä¿¡æ¯çš„æ–¹æ³•ä¸åŒï¼ŒTMRé€šè¿‡åœ¨å†»ç»“çš„ä¸»å¹²ç½‘ç»œ(Frozen Backbone)ä¸Šå¢åŠ å°‘é‡å¯å­¦ä¹ çš„å·ç§¯æˆ–æŠ•å½±å±‚ï¼Œæœ‰æ•ˆåœ°ä¿ç•™å¹¶åˆ©ç”¨äº†æ ·æœ¬çš„ç©ºé—´å¸ƒå±€ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜å¼•å…¥äº†æ¶µç›–æ›´å¹¿æ³›æ¨¡å¼ç±»å‹çš„æ–°æ•°æ®é›†RPINEã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTMRåœ¨RPINEã€FSCD-147å’ŒFSCD-LVISä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•(State-of-the-Art)ï¼Œå¹¶åœ¨è·¨æ•°æ®é›†è¯„ä¼°ä¸­å±•ç°å‡ºæå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICCV 2025 (highlight)",
      "pdf_url": "https://arxiv.org/pdf/2508.17636v1",
      "published_date": "2025-08-25 03:52:42 UTC",
      "updated_date": "2025-08-25 03:52:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:12.297408+00:00"
    },
    {
      "arxiv_id": "2508.17634v2",
      "title": "Finding Outliers in a Haystack: Anomaly Detection for Large Pointcloud Scenes",
      "title_zh": "å¤§æµ·æé’ˆï¼šå¤§è§„æ¨¡ç‚¹äº‘åœºæ™¯ä¸‹çš„å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Ryan Faulkner",
        "Luke Haub",
        "Simon Ratcliffe",
        "Tat-Jun Chin"
      ],
      "abstract": "LiDAR scanning in outdoor scenes acquires accurate distance measurements over wide areas, producing large-scale point clouds. Application examples for this data include robotics, automotive vehicles, and land surveillance. During such applications, outlier objects from outside the training data will inevitably appear. Our research contributes a novel approach to open-set segmentation, leveraging the learnings of object defect-detection research. We also draw on the Mamba architecture's strong performance in utilising long-range dependencies and scalability to large data. Combining both, we create a reconstruction based approach for the task of outdoor scene open-set segmentation. We show that our approach improves performance not only when applied to our our own open-set segmentation method, but also when applied to existing methods. Furthermore we contribute a Mamba based architecture which is competitive with existing voxel-convolution based methods on challenging, large-scale pointclouds.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶åŠç›‘æ§é¢†åŸŸä¸­ LiDAR æ‰«æäº§ç”Ÿçš„å¤§è§„æ¨¡ç‚¹äº‘æ•°æ®ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å¼€é›†åˆ†å‰² (open-set segmentation) æ–¹æ³•ï¼Œæ—¨åœ¨å‡†ç¡®æ£€æµ‹å‡ºè®­ç»ƒæ•°æ®ä¹‹å¤–çš„å¼‚å¸¸ç‰©ä½“ã€‚è¯¥æ–¹æ³•å€Ÿé‰´äº†ç‰©ä½“ç¼ºé™·æ£€æµ‹ (object defect-detection) ç ”ç©¶çš„æ€è·¯ï¼Œå¹¶ç»“åˆ Mamba æ¶æ„åœ¨å¤„ç†é•¿è·ç¦»ä¾èµ–å’Œå¤§è§„æ¨¡æ•°æ®æ‰©å±•æ€§ä¸Šçš„ä¼˜åŠ¿ï¼Œæ„å»ºäº†ä¸€ä¸ªåŸºäºé‡æ„ (reconstruction-based) çš„å¼‚å¸¸æ£€æµ‹æ¡†æ¶ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆä¸ä»…æ˜¾è‘—æå‡äº†å…¶è‡ªèº«å¼€é›†åˆ†å‰²æ–¹æ³•çš„æ€§èƒ½ï¼Œåœ¨åº”ç”¨äºç°æœ‰çš„ä¸»æµæ–¹æ³•æ—¶ä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„å…¼å®¹æ€§ä¸æ€§èƒ½å¢å¼ºã€‚æ­¤å¤–ï¼Œç ”ç©¶è´¡çŒ®çš„ Mamba æ¶æ„åœ¨åº”å¯¹æŒ‘æˆ˜æ€§çš„å¤§è§„æ¨¡ç‚¹äº‘ä»»åŠ¡æ—¶ï¼Œå…¶æ€§èƒ½å·²è¾¾åˆ°ä¸ä¼ ç»Ÿä½“ç´ å·ç§¯ (voxel-convolution) æ–¹æ³•ç›¸åª²ç¾çš„æ°´å¹³ã€‚è¯¥æˆæœä¸ºå¤§è§„æ¨¡æˆ·å¤–åœºæ™¯ä¸‹çš„å¯é å¼‚å¸¸æ£€æµ‹æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv Preprint, paper has since been accepted to ACPR 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17634v2",
      "published_date": "2025-08-25 03:47:33 UTC",
      "updated_date": "2025-08-26 07:01:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:23.091390+00:00"
    },
    {
      "arxiv_id": "2508.17631v2",
      "title": "ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion",
      "title_zh": "ControlEchoSynthï¼šé€šè¿‡å—æ§è§†é¢‘æ‰©æ•£æå‡å°„è¡€åˆ†æ•°è¯„ä¼°æ¨¡å‹",
      "authors": [
        "Nima Kondori",
        "Hanwen Liang",
        "Hooman Vaseli",
        "Bingyu Xie",
        "Christina Luong",
        "Purang Abolmaesumi",
        "Teresa Tsang",
        "Renjie Liao"
      ],
      "abstract": "Synthetic data generation represents a significant advancement in boosting the performance of machine learning (ML) models, particularly in fields where data acquisition is challenging, such as echocardiography. The acquisition and labeling of echocardiograms (echo) for heart assessment, crucial in point-of-care ultrasound (POCUS) settings, often encounter limitations due to the restricted number of echo views available, typically captured by operators with varying levels of experience. This study proposes a novel approach for enhancing clinical diagnosis accuracy by synthetically generating echo views. These views are conditioned on existing, real views of the heart, focusing specifically on the estimation of ejection fraction (EF), a critical parameter traditionally measured from biplane apical views. By integrating a conditional generative model, we demonstrate an improvement in EF estimation accuracy, providing a comparative analysis with traditional methods. Preliminary results indicate that our synthetic echoes, when used to augment existing datasets, not only enhance EF estimation but also show potential in advancing the development of more robust, accurate, and clinically relevant ML models. This approach is anticipated to catalyze further research in synthetic data applications, paving the way for innovative solutions in medical imaging diagnostics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ControlEchoSynthï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å—æ§è§†é¢‘æ‰©æ•£ (Controlled Video Diffusion) æŠ€æœ¯ç”Ÿæˆåˆæˆæ•°æ®çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³è¶…å£°å¿ƒåŠ¨å›¾ (Echocardiography) åœ¨åºŠæ—è¶…å£° (POCUS) ç¯å¢ƒä¸­å› æ•°æ®è·å–å’Œæ ‡æ³¨å›°éš¾è€Œå¯¼è‡´çš„æ¨¡å‹æ€§èƒ½å—é™é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ¡ä»¶ç”Ÿæˆæ¨¡å‹ï¼ŒåŸºäºå¿ƒè„çš„ç°æœ‰çœŸå®è§†è§’ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆè§†å›¾ï¼Œå¹¶ä¸“é—¨é’ˆå¯¹ä¸´åºŠå…³é”®æŒ‡æ ‡å°„è¡€åˆ†æ•° (Ejection Fraction, EF) çš„è‡ªåŠ¨è¯„ä¼°è¿›è¡Œä¼˜åŒ–ã€‚å®éªŒåˆ†æè¡¨æ˜ï¼Œåˆ©ç”¨ ControlEchoSynth ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºç°æœ‰æ•°æ®é›†ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ EF è¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œå…¶è¡¨ç°ä¼˜äºä¼ ç»Ÿæ•°æ®å¢å¼ºæ–¹æ³•ã€‚åˆæ­¥ç»“æœè¯å®è¯¥æ–¹æ³•æœ‰æ•ˆå¢å¼ºäº†æœºå™¨å­¦ä¹  (ML) æ¨¡å‹çš„é²æ£’æ€§å’Œä¸´åºŠç›¸å…³æ€§ï¼Œä¸ºåŒ»å­¦å½±åƒè¯Šæ–­æä¾›äº†æ›´å…·ä»·å€¼çš„è®­ç»ƒèµ„æºã€‚è¿™ä¸€æ–¹æ³•ä¸ä»…ä¸ºå¿ƒè„è¶…å£°æ•°æ®çš„åŒ®ä¹æä¾›äº†åˆ›æ–°è§£å†³æ–¹æ¡ˆï¼Œä¹Ÿä¸ºåˆæˆæ•°æ®åœ¨è‡ªåŠ¨åŒ–åŒ»ç–—è¯Šæ–­é¢†åŸŸçš„å¹¿æ³›åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Data Curation and Augmentation in Medical Imaging CVPR 2024",
      "pdf_url": "https://arxiv.org/pdf/2508.17631v2",
      "published_date": "2025-08-25 03:27:25 UTC",
      "updated_date": "2025-08-27 01:36:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:16.686596+00:00"
    },
    {
      "arxiv_id": "2508.17627v2",
      "title": "The Evolution of Thought: Tracking LLM Overthinking via Reasoning Dynamics Analysis",
      "title_zh": "æ€ç»´çš„æ¼”è¿›ï¼šé€šè¿‡æ¨ç†åŠ¨åŠ›å­¦åˆ†æè¿½è¸ª LLM è¿‡åº¦æ€è€ƒ",
      "authors": [
        "Zihao Wei",
        "Liang Pang",
        "Jiahao Liu",
        "Wenjie Shi",
        "Jingcheng Deng",
        "Shicheng Xu",
        "Zenghao Duan",
        "Fei Sun",
        "Huawei Shen",
        "Xueqi Cheng"
      ],
      "abstract": "Test-time scaling via explicit reasoning trajectories significantly boosts large language model (LLM) performance but often triggers overthinking. To explore this, we analyze reasoning through two lenses: Reasoning Length Dynamics, which reveals a compensatory trade-off between thinking and answer content length that eventually leads to thinking redundancy, and Reasoning Semantic Dynamics, which identifies semantic convergence and repetitive oscillations. These dynamics uncover an instance-specific Reasoning Completion Point (RCP), beyond which computation continues without further performance gain. Since the RCP varies across instances, we propose a Reasoning Completion Point Detector (RCPD), an inference-time early-exit method that identifies the RCP by monitoring the rank dynamics of termination tokens (e.g., </think>). Across AIME and GPQA benchmarks using Qwen3 and DeepSeek-R1, RCPD reduces token usage by up to 44% while preserving accuracy, offering a principled approach to efficient test-time scaling.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨é€šè¿‡æ˜¾å¼æ¨ç†è½¨è¿¹æå‡æ€§èƒ½æ—¶å‡ºç°çš„â€œè¿‡åº¦æ€è€ƒâ€(overthinking)ç°è±¡ã€‚ä½œè€…é€šè¿‡Reasoning Length Dynamicså’ŒReasoning Semantic Dynamicsä¸¤ä¸ªç»´åº¦åˆ†ææ¨ç†è¿‡ç¨‹ï¼Œæ­ç¤ºäº†æ¨ç†å†—ä½™ã€è¯­ä¹‰æ”¶æ•›åŠé‡å¤æŒ¯è¡ç­‰ç‰¹å¾ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶æå‡ºäº†Reasoning Completion Point (RCP)æ¦‚å¿µï¼Œå³è®¡ç®—ä¸å†äº§ç”Ÿæ€§èƒ½æ”¶ç›Šçš„ä¸´ç•Œç‚¹ã€‚ä¸ºäº†å®ç°é«˜æ•ˆæ¨ç†ï¼Œç ”ç©¶è®¾è®¡äº†Reasoning Completion Point Detector (RCPD)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡ç›‘æµ‹ç»ˆæ­¢æ ‡è®°(å¦‚</think>)æ’ååŠ¨æ€æ¥è¯†åˆ«RCPçš„æ¨ç†æ—¶æ—©æœŸé€€å‡º(early-exit)æ–¹æ³•ã€‚å®éªŒåœ¨AIMEå’ŒGPQAåŸºå‡†ä¸Šåˆ©ç”¨Qwen3å’ŒDeepSeek-R1éªŒè¯ï¼Œè¯æ˜RCPDåœ¨ä¿æŒå‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œæœ€é«˜å¯å‡å°‘44%çš„tokenæ¶ˆè€—é‡ã€‚è¯¥æˆæœä¸ºæµ‹è¯•æ—¶ç¼©æ”¾(test-time scaling)æä¾›äº†ä¸€ç§åŸºäºåŸç†çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17627v2",
      "published_date": "2025-08-25 03:17:17 UTC",
      "updated_date": "2026-01-13 03:40:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:16.893993+00:00"
    },
    {
      "arxiv_id": "2508.17621v2",
      "title": "Steering When Necessary: Flexible Steering Large Language Models with Backtracking",
      "title_zh": "æŒ‰éœ€å¼•å¯¼ï¼šåŸºäºå›æº¯æœºåˆ¶çš„å¤§è¯­è¨€æ¨¡å‹çµæ´»å¼•å¯¼",
      "authors": [
        "Zifeng Cheng",
        "Jinwei Gan",
        "Zhiwei Jiang",
        "Cong Wang",
        "Yafeng Yin",
        "Xiang Luo",
        "Yuchen Fu",
        "Qing Gu"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable performance across many generation tasks. Nevertheless, effectively aligning them with desired behaviors remains a significant challenge. Activation steering is an effective and cost-efficient approach that directly modifies the activations of LLMs during the inference stage, aligning their responses with the desired behaviors and avoiding the high cost of fine-tuning. Existing methods typically indiscriminately intervene to all generations or rely solely on the question to determine intervention, which limits the accurate assessment of the intervention strength. To this end, we propose the Flexible Activation Steering with Backtracking (FASB) framework, which dynamically determines both the necessity and strength of intervention by tracking the internal states of the LLMs during generation, considering both the question and the generated content. Since intervening after detecting a deviation from the desired behavior is often too late, we further propose the backtracking mechanism to correct the deviated tokens and steer the LLMs toward the desired behavior. Extensive experiments on the TruthfulQA dataset and six multiple-choice datasets demonstrate that our method outperforms baselines. Our code will be released at https://github.com/gjw185/FASB.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FASBï¼ˆFlexible Activation Steering with Backtrackingï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¿€æ´»å¼•å¯¼ï¼ˆActivation steeringï¼‰è¿‡ç¨‹ä¸­çš„çµæ´»æ€§ä¸å¯¹é½å‡†ç¡®æ€§ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å¹²é¢„ç­–ç•¥è¿‡äºåƒµåŒ–ä¸”éš¾ä»¥ç²¾ç¡®è¯„ä¼°å¹²é¢„å¼ºåº¦çš„é—®é¢˜ï¼ŒFASBé€šè¿‡è¿½è¸ªæ¨¡å‹ç”Ÿæˆæ—¶çš„å†…éƒ¨çŠ¶æ€ï¼Œç»¼åˆè€ƒè™‘é—®é¢˜èƒŒæ™¯ä¸å·²ç”Ÿæˆå†…å®¹æ¥åŠ¨æ€åˆ¤å®šå¹²é¢„çš„å¿…è¦æ€§ã€‚ä¸ºäº†è§£å†³åå·®æ£€æµ‹é€šå¸¸æ»åäºé”™è¯¯ç”Ÿæˆçš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°å¼•å…¥äº†å›æº¯æœºåˆ¶ï¼ˆBacktracking mechanismï¼‰ï¼Œèƒ½å¤Ÿå¯¹å‘ç”Ÿåç¦»çš„Tokenè¿›è¡Œå›æº¯ä¿®æ­£å¹¶å¼•å¯¼æ¨¡å‹é‡å›ç›®æ ‡è¡Œä¸ºè½¨é“ã€‚åœ¨TruthfulQAå’Œå…­ä¸ªå¤šé¡¹é€‰æ‹©æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼ŒFASBçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°ä½æˆæœ¬ä¸”é«˜æ•ˆçš„æ¨¡å‹è¡Œä¸ºå¯¹é½æä¾›äº†å…·æœ‰é²æ£’æ€§çš„æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.17621v2",
      "published_date": "2025-08-25 03:01:30 UTC",
      "updated_date": "2025-10-01 14:31:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:52.441635+00:00"
    },
    {
      "arxiv_id": "2509.00052v2",
      "title": "Lightning Fast Caching-based Parallel Denoising Prediction for Accelerating Talking Head Generation",
      "title_zh": "ç”¨äºåŠ é€Ÿè¯´è¯äººè„¸ç”Ÿæˆçš„æé€Ÿç¼“å­˜å¹¶è¡Œå»å™ªé¢„æµ‹",
      "authors": [
        "Jianzhi Long",
        "Wenhao Sun",
        "Rongcheng Tu",
        "Dacheng Tao"
      ],
      "abstract": "Diffusion-based talking head models generate high-quality, photorealistic videos but suffer from slow inference, limiting practical applications. Existing acceleration methods for general diffusion models fail to exploit the temporal and spatial redundancies unique to talking head generation. In this paper, we propose a task-specific framework addressing these inefficiencies through two key innovations. First, we introduce Lightning-fast Caching-based Parallel denoising prediction (LightningCP), caching static features to bypass most model layers in inference time. We also enable parallel prediction using cached features and estimated noisy latents as inputs, efficiently bypassing sequential sampling. Second, we propose Decoupled Foreground Attention (DFA) to further accelerate attention computations, exploiting the spatial decoupling in talking head videos to restrict attention to dynamic foreground regions. Additionally, we remove reference features in certain layers to bring extra speedup. Extensive experiments demonstrate that our framework significantly improves inference speed while preserving video quality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäº Diffusion-based çš„ talking head generation æ¨¡å‹æ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼ŒæŒ‡å‡ºé€šç”¨åŠ é€Ÿæ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨è¯¥ä»»åŠ¡ç‰¹æœ‰çš„æ—¶ç©ºå†—ä½™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Lightning-fast Caching-based Parallel denoising prediction (LightningCP) æ¡†æ¶ï¼Œé€šè¿‡ç¼“å­˜é™æ€ç‰¹å¾æ¥è·³è¿‡å¤§éƒ¨åˆ†æ¨ç†å±‚ï¼Œå¹¶åˆ©ç”¨ç¼“å­˜ç‰¹å¾ä¸ä¼°è®¡çš„ noisy latents å®ç°å¹¶è¡Œé¢„æµ‹ï¼Œä»è€Œæœ‰æ•ˆç»•è¿‡ä¼ ç»Ÿçš„ä¸²è¡Œé‡‡æ ·ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº† Decoupled Foreground Attention (DFA) æŠ€æœ¯ï¼Œåˆ©ç”¨ç©ºé—´è§£è€¦ç‰¹æ€§å°†æ³¨æ„åŠ›è®¡ç®—é™åˆ¶åœ¨åŠ¨æ€å‰æ™¯åŒºåŸŸä»¥è¿›ä¸€æ­¥æé€Ÿã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨ç‰¹å®šå±‚ä¸­ç§»é™¤ reference featuresï¼Œè¯¥æ–¹æ¡ˆè·å¾—äº†é¢å¤–çš„æ€§èƒ½å¢ç›Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¿æŒé«˜è´¨é‡çš„è§†é¢‘ç”Ÿæˆæ•ˆæœï¼Œä¸ºè¯¥é¢†åŸŸçš„å®é™…åº”ç”¨æä¾›äº†é«˜æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.00052v2",
      "published_date": "2025-08-25 02:58:39 UTC",
      "updated_date": "2026-01-19 08:05:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:48.552783+00:00"
    },
    {
      "arxiv_id": "2508.17611v1",
      "title": "Evaluating Movement Initiation Timing in Ultimate Frisbee via Temporal Counterfactuals",
      "title_zh": "åŸºäºæ—¶é—´åäº‹å®çš„æé™é£ç›˜è·‘åŠ¨å¯åŠ¨æ—¶æœºè¯„ä¼°",
      "authors": [
        "Shunsuke Iwashita",
        "Ning Ding",
        "Keisuke Fujii"
      ],
      "abstract": "Ultimate is a sport where points are scored by passing a disc and catching it in the opposing team's end zone. In Ultimate, the player holding the disc cannot move, making field dynamics primarily driven by other players' movements. However, current literature in team sports has ignored quantitative evaluations of when players initiate such unlabeled movements in game situations. In this paper, we propose a quantitative evaluation method for movement initiation timing in Ultimate Frisbee. First, game footage was recorded using a drone camera, and players' positional data was obtained, which will be published as UltimateTrack dataset. Next, players' movement initiations were detected, and temporal counterfactual scenarios were generated by shifting the timing of movements using rule-based approaches. These scenarios were analyzed using a space evaluation metric based on soccer's pitch control reflecting the unique rules of Ultimate. By comparing the spatial evaluation values across scenarios, the difference between actual play and the most favorable counterfactual scenario was used to quantitatively assess the impact of movement timing.\n  We validated our method and show that sequences in which the disc was actually thrown to the receiver received higher evaluation scores than the sequences without a throw.\n  In practical verifications, the higher-skill group displays a broader distribution of time offsets from the model's optimal initiation point.\n  These findings demonstrate that the proposed metric provides an objective means of assessing movement initiation timing, which has been difficult to quantify in unlabeled team sport plays.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æé™é£ç›˜ (Ultimate Frisbee) è¿åŠ¨ä¸­çƒå‘˜ç§»åŠ¨å¯åŠ¨æ—¶æœºéš¾ä»¥é‡åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ—¶é—´åäº‹å® (Temporal Counterfactuals) çš„å®šé‡è¯„ä¼°æ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ— äººæœºè®°å½•æ¯”èµ›ç”»é¢å¹¶æ„å»ºäº† UltimateTrack æ•°æ®é›†ï¼Œè¿›è€Œæ£€æµ‹çƒå‘˜ç§»åŠ¨å¯åŠ¨å¹¶ç”Ÿæˆå¹³ç§»æ—¶é—´ç‚¹çš„åäº‹å®åœºæ™¯ã€‚è¯„ä¼°è¿‡ç¨‹ç»“åˆæé™é£ç›˜è§„åˆ™ï¼Œé‡‡ç”¨äº†æ”¹è¿›çš„çƒåœºæ§åˆ¶ (Pitch Control) ç©ºé—´è¯„ä¼°æŒ‡æ ‡ï¼Œé€šè¿‡å¯¹æ¯”å®é™…è¡¨ç°ä¸æœ€ä¼˜åäº‹å®åœºæ™¯çš„å·®å¼‚æ¥å®šé‡åˆ†ææ—¶æœºå½±å“ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œå®é™…å‘ç”Ÿä¼ çƒçš„åºåˆ—æ¯”æœªä¼ çƒåºåˆ—è·å¾—äº†æ›´é«˜çš„è¯„ä¼°å¾—åˆ†ã€‚æ­¤å¤–ï¼Œå®è¯åˆ†æå‘ç°é«˜æ°´å¹³çƒå‘˜ç»„åœ¨ç§»åŠ¨å¯åŠ¨æ—¶æœºä¸Šè¾ƒæ¨¡å‹æœ€ä¼˜ç‚¹çš„åˆ†å¸ƒæ›´ä¸ºå¹¿æ³›ã€‚è¯¥ç ”ç©¶ä¸ºå›¢é˜Ÿè¿åŠ¨ä¸­è¿™ç±»æ— æ ‡è®°çš„çƒå‘˜åŠ¨æ€è¡Œä¸ºæä¾›äº†å®¢è§‚ä¸”å¯é‡åŒ–çš„è¯„ä¼°å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 13 figures, 12th Workshop on Machine Learning and Data Mining for Sports Analytics, https://github.com/shunsuke-iwashita/VTCS",
      "pdf_url": "https://arxiv.org/pdf/2508.17611v1",
      "published_date": "2025-08-25 02:42:08 UTC",
      "updated_date": "2025-08-25 02:42:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:49.392056+00:00"
    },
    {
      "arxiv_id": "2508.17600v2",
      "title": "GWM: Towards Scalable Gaussian World Models for Robotic Manipulation",
      "title_zh": "GWMï¼šé¢å‘æœºå™¨äººæ“ä½œçš„å¯æ‰©å±•é«˜æ–¯ä¸–ç•Œæ¨¡å‹",
      "authors": [
        "Guanxing Lu",
        "Baoxiong Jia",
        "Puhao Li",
        "Yixin Chen",
        "Ziwei Wang",
        "Yansong Tang",
        "Siyuan Huang"
      ],
      "abstract": "Training robot policies within a learned world model is trending due to the inefficiency of real-world interactions. The established image-based world models and policies have shown prior success, but lack robust geometric information that requires consistent spatial and physical understanding of the three-dimensional world, even pre-trained on internet-scale video sources. To this end, we propose a novel branch of world model named Gaussian World Model (GWM) for robotic manipulation, which reconstructs the future state by inferring the propagation of Gaussian primitives under the effect of robot actions. At its core is a latent Diffusion Transformer (DiT) combined with a 3D variational autoencoder, enabling fine-grained scene-level future state reconstruction with Gaussian Splatting. GWM can not only enhance the visual representation for imitation learning agent by self-supervised future prediction training, but can serve as a neural simulator that supports model-based reinforcement learning. Both simulated and real-world experiments depict that GWM can precisely predict future scenes conditioned on diverse robot actions, and can be further utilized to train policies that outperform the state-of-the-art by impressive margins, showcasing the initial data scaling potential of 3D world model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Gaussian World Model (GWM)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºäºå›¾åƒçš„ä¸–ç•Œæ¨¡å‹åœ¨æœºå™¨äººæ“ä½œä¸­ç¼ºä¹ç¨³å¥å‡ ä½•ä¿¡æ¯å’Œä¸‰ç»´ç©ºé—´ä¸€è‡´æ€§ç†è§£çš„é—®é¢˜ã€‚GWMé€šè¿‡æ¨ç†æœºå™¨äººåŠ¨ä½œå½±å“ä¸‹Gaussian primitivesçš„ä¼ æ’­æ¥é‡å»ºæœªæ¥çŠ¶æ€ï¼Œå…¶æ ¸å¿ƒæ¶æ„ç»“åˆäº†Latent Diffusion Transformer (DiT)å’Œ3D Variational Autoencoder (VAE)ï¼Œå¹¶åˆ©ç”¨Gaussian SplattingæŠ€æœ¯å®ç°ç»†ç²’åº¦çš„åœºæ™¯çº§æœªæ¥çŠ¶æ€é‡å»ºã€‚è¯¥æ¨¡å‹æ—¢èƒ½é€šè¿‡è‡ªç›‘ç£çš„æœªæ¥é¢„æµ‹è®­ç»ƒå¢å¼ºæ¨¡ä»¿å­¦ä¹ æ™ºèƒ½ä½“çš„è§†è§‰è¡¨ç¤ºï¼Œä¹Ÿèƒ½ä½œä¸ºç¥ç»æ¨¡æ‹Ÿå™¨æ”¯æŒåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ (model-based reinforcement learning)ã€‚ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œå®éªŒè¡¨æ˜ï¼ŒGWMèƒ½å¤Ÿæ ¹æ®å¤šç§æœºå™¨äººåŠ¨ä½œç²¾ç¡®é¢„æµ‹æœªæ¥åœºæ™¯ï¼Œä¸”ç”±æ­¤è®­ç»ƒå‡ºçš„ç­–ç•¥ä»¥æ˜¾è‘—ä¼˜åŠ¿è¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›(SOTA)æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œä¸ä»…éªŒè¯äº†GWMåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œè¿˜å±•ç¤ºäº†3Dä¸–ç•Œæ¨¡å‹åœ¨æ•°æ®æ‰©å±•(data scaling)æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at ICCV 2025. Project page: https://gaussian-world-model.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2508.17600v2",
      "published_date": "2025-08-25 02:01:09 UTC",
      "updated_date": "2025-09-17 02:27:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:48.742939+00:00"
    },
    {
      "arxiv_id": "2508.17590v1",
      "title": "RubikSQL: Lifelong Learning Agentic Knowledge Base as an Industrial NL2SQL System",
      "title_zh": "RubikSQLï¼šé¢å‘å·¥ä¸šçº§NL2SQLç³»ç»Ÿçš„ç»ˆèº«å­¦ä¹ æ™ºèƒ½ä½“åŒ–çŸ¥è¯†åº“",
      "authors": [
        "Zui Chen",
        "Han Li",
        "Xinhao Zhang",
        "Xiaoyu Chen",
        "Chunyin Dong",
        "Yifeng Wang",
        "Xin Cai",
        "Su Zhang",
        "Ziqi Li",
        "Chi Ding",
        "Jinxu Li",
        "Shuai Wang",
        "Dousheng Zhao",
        "Sanhai Gao",
        "Guangyi Liu"
      ],
      "abstract": "We present RubikSQL, a novel NL2SQL system designed to address key challenges in real-world enterprise-level NL2SQL, such as implicit intents and domain-specific terminology. RubikSQL frames NL2SQL as a lifelong learning task, demanding both Knowledge Base (KB) maintenance and SQL generation. RubikSQL systematically builds and refines its KB through techniques including database profiling, structured information extraction, agentic rule mining, and Chain-of-Thought (CoT)-enhanced SQL profiling. RubikSQL then employs a multi-agent workflow to leverage this curated KB, generating accurate SQLs. RubikSQL achieves SOTA performance on both the KaggleDBQA and BIRD Mini-Dev datasets. Finally, we release the RubikBench benchmark, a new benchmark specifically designed to capture vital traits of industrial NL2SQL scenarios, providing a valuable resource for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RubikSQLï¼Œä¸€ç§æ–°å‹çš„ NL2SQL ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ä¼ä¸šçº§åº”ç”¨ä¸­å¸¸è§çš„éšå¼æ„å›¾å’Œç‰¹å®šé¢†åŸŸæœ¯è¯­ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚RubikSQL å°† NL2SQL è§†ä¸ºä¸€é¡¹ç»ˆèº«å­¦ä¹  (lifelong learning) ä»»åŠ¡ï¼ŒåŒæ­¥æ¶µç›–äº†çŸ¥è¯†åº“ (Knowledge Base) çš„ç»´æŠ¤ä¸ SQL ç”Ÿæˆè¿‡ç¨‹ã€‚ç³»ç»Ÿé€šè¿‡æ•°æ®åº“å‰–æ (database profiling)ã€ç»“æ„åŒ–ä¿¡æ¯æå–ã€æ™ºèƒ½ä½“è§„åˆ™æŒ–æ˜ä»¥åŠå¢å¼ºç‰ˆé“¾å¼æ€ç»´ (Chain-of-Thought) SQL å‰–æç­‰æŠ€æœ¯ï¼Œç³»ç»Ÿæ€§åœ°æ„å»ºå¹¶å®Œå–„å…¶çŸ¥è¯†åº“ã€‚éšåï¼ŒRubikSQL åˆ©ç”¨å¤šæ™ºèƒ½ä½“å·¥ä½œæµ (multi-agent workflow) ç»“åˆè¯¥ç²¾é€‰çŸ¥è¯†åº“ï¼Œå®ç°äº†é«˜å‡†ç¡®åº¦çš„ SQL è¯­å¥ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRubikSQL åœ¨ KaggleDBQA å’Œ BIRD Mini-Dev æ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº† SOTA æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å‘å¸ƒäº†ä¸“é—¨é’ˆå¯¹å·¥ä¸šçº§ NL2SQL åœºæ™¯ç‰¹å¾è®¾è®¡çš„ RubikBench åŸºå‡†æµ‹è¯•ï¼Œä¸ºè¯¥é¢†åŸŸçš„åç»­ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.DB",
      "comment": "18 pages, 3 figures, 3 tables, to be submitted to VLDB 2026 (PVLDB Volume 19)",
      "pdf_url": "https://arxiv.org/pdf/2508.17590v1",
      "published_date": "2025-08-25 01:28:37 UTC",
      "updated_date": "2025-08-25 01:28:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:06:57.063715+00:00"
    },
    {
      "arxiv_id": "2508.17580v1",
      "title": "UQ: Assessing Language Models on Unsolved Questions",
      "title_zh": "UQï¼šé’ˆå¯¹æœªè§£å†³é—®é¢˜çš„è¯­è¨€æ¨¡å‹è¯„ä¼°",
      "authors": [
        "Fan Nie",
        "Ken Ziyu Liu",
        "Zihao Wang",
        "Rui Sun",
        "Wei Liu",
        "Weijia Shi",
        "Huaxiu Yao",
        "Linjun Zhang",
        "Andrew Y. Ng",
        "James Zou",
        "Sanmi Koyejo",
        "Yejin Choi",
        "Percy Liang",
        "Niklas Muennighoff"
      ],
      "abstract": "Benchmarks shape progress in AI research. A useful benchmark should be both difficult and realistic: questions should challenge frontier models while also reflecting real-world usage. Yet, current paradigms face a difficulty-realism tension: exam-style benchmarks are often made artificially difficult with limited real-world value, while benchmarks based on real user interaction often skew toward easy, high-frequency problems. In this work, we explore a radically different paradigm: assessing models on unsolved questions. Rather than a static benchmark scored once, we curate unsolved questions and evaluate models asynchronously over time with validator-assisted screening and community verification. We introduce UQ, a testbed of 500 challenging, diverse questions sourced from Stack Exchange, spanning topics from CS theory and math to sci-fi and history, probing capabilities including reasoning, factuality, and browsing. UQ is difficult and realistic by construction: unsolved questions are often hard and naturally arise when humans seek answers, thus solving them yields direct real-world value. Our contributions are threefold: (1) UQ-Dataset and its collection pipeline combining rule-based filters, LLM judges, and human review to ensure question quality (e.g., well-defined and difficult); (2) UQ-Validators, compound validation strategies that leverage the generator-validator gap to provide evaluation signals and pre-screen candidate solutions for human review; and (3) UQ-Platform, an open platform where experts collectively verify questions and solutions. The top model passes UQ-validation on only 15% of questions, and preliminary human verification has already identified correct answers among those that passed. UQ charts a path for evaluating frontier models on real-world, open-ended challenges, where success pushes the frontier of human knowledge. We release UQ at https://uq.stanford.edu.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UQï¼Œä¸€ä¸ªåŸºäºæœªè§£å†³é—®é¢˜(unsolved questions)çš„å…¨æ–°è¯„ä¼°èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³å½“å‰AIåŸºå‡†æµ‹è¯•åœ¨éš¾åº¦ä¸ç°å®æ€§ä¹‹é—´å­˜åœ¨çš„çŸ›ç›¾ã€‚ç ”ç©¶å›¢é˜Ÿä»Stack Exchangeä¸­ç­›é€‰å¹¶æ„å»ºäº†åŒ…å«500ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§ä¸”æ¶µç›–å¤šå­¦ç§‘çš„UQ-Datasetï¼Œåˆ©ç”¨ç”±è§„åˆ™è¿‡æ»¤ã€LLMè¯„åˆ¤å’Œäººå·¥å®¡æ ¸ç»„æˆçš„æµç¨‹ç¡®ä¿é¢˜ç›®è´¨é‡ã€‚ä¸ºäº†æä¾›æœ‰æ•ˆçš„è¯„ä¼°ä¿¡å·ï¼Œç ”ç©¶å¼•å…¥äº†UQ-Validatorsç­–ç•¥ï¼Œåˆ©ç”¨ç”Ÿæˆå™¨ä¸éªŒè¯å™¨ä¹‹é—´çš„å·®è·(generator-validator gap)æ¥é¢„ç­›é€‰å€™é€‰ç­”æ¡ˆã€‚æ­¤å¤–ï¼ŒUQ-Platformä½œä¸ºå¼€æ”¾å¹³å°æ”¯æŒä¸“å®¶é›†ä½“éªŒè¯ï¼Œä¸ºè¯„ä¼°å‰æ²¿æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œå¼€æ”¾æ€§æŒ‘æˆ˜ä¸­çš„è¡¨ç°æä¾›äº†æ”¯æ’‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé¡¶å°–æ¨¡å‹åœ¨UQéªŒè¯ä¸­çš„é€šè¿‡ç‡ä»…ä¸º15%ï¼Œè¯æ˜äº†è¯¥åŸºå‡†æµ‹è¯•åœ¨è¡¡é‡æ¨ç†ã€äº‹å®æ€§å’Œæµè§ˆèƒ½åŠ›æ–¹é¢çš„æé«˜éš¾åº¦ã€‚é€šè¿‡è¯„ä¼°æ¨¡å‹è§£å†³æœªè§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œè¯¥ç ”ç©¶ä¸ºæ¨åŠ¨äººç±»çŸ¥è¯†è¾¹ç•Œçš„AIè¯„ä¼°æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "FN, KZL, and NM are project co-leads and contributed equally. Project website: https://uq.stanford.edu",
      "pdf_url": "https://arxiv.org/pdf/2508.17580v1",
      "published_date": "2025-08-25 01:07:59 UTC",
      "updated_date": "2025-08-25 01:07:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:07:04.247628+00:00"
    },
    {
      "arxiv_id": "2508.17568v1",
      "title": "MetaGen: A DSL, Database, and Benchmark for VLM-Assisted Metamaterial Generation",
      "title_zh": "MetaGenï¼šé¢å‘ VLM è¾…åŠ©è¶…ææ–™ç”Ÿæˆçš„é¢†åŸŸç‰¹å®šè¯­è¨€ã€æ•°æ®åº“åŠåŸºå‡†",
      "authors": [
        "Liane Makatura",
        "Benjamin Jones",
        "Siyuan Bian",
        "Wojciech Matusik"
      ],
      "abstract": "Metamaterials are micro-architected structures whose geometry imparts highly tunable-often counter-intuitive-bulk properties. Yet their design is difficult because of geometric complexity and a non-trivial mapping from architecture to behaviour. We address these challenges with three complementary contributions. (i) MetaDSL: a compact, semantically rich domain-specific language that captures diverse metamaterial designs in a form that is both human-readable and machine-parsable. (ii) MetaDB: a curated repository of more than 150,000 parameterized MetaDSL programs together with their derivatives-three-dimensional geometry, multi-view renderings, and simulated elastic properties. (iii) MetaBench: benchmark suites that test three core capabilities of vision-language metamaterial assistants-structure reconstruction, property-driven inverse design, and performance prediction. We establish baselines by fine-tuning state-of-the-art vision-language models and deploy an omni-model within an interactive, CAD-like interface. Case studies show that our framework provides a strong first step toward integrated design and understanding of structure-representation-property relationships.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¶…ææ–™(Metamaterials)å¤æ‚çš„å‡ ä½•ç»“æ„åŠå…¶ä¸ç‰©ç†è¡Œä¸ºé—´çš„éå¹³å‡¡æ˜ å°„å…³ç³»ï¼Œæå‡ºäº†MetaGenæ¡†æ¶ä»¥å®ç°è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)è¾…åŠ©çš„è¶…ææ–™ç”Ÿæˆã€‚è¯¥æ¡†æ¶é¦–å…ˆå¼•å…¥äº†MetaDSLï¼Œè¿™æ˜¯ä¸€ç§å…¼å…·äººç±»å¯è¯»æ€§ä¸æœºå™¨å¯è§£ææ€§çš„é¢†åŸŸç‰¹å®šè¯­è¨€(domain-specific language)ï¼Œèƒ½å¤Ÿé«˜æ•ˆæ•æ‰å¤šæ ·çš„è¶…ææ–™è®¾è®¡æ–¹æ¡ˆã€‚ç ”ç©¶è¿›ä¸€æ­¥æ„å»ºäº†MetaDBï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«è¶…è¿‡15ä¸‡ä¸ªå‚æ•°åŒ–MetaDSLç¨‹åºåŠå…¶å…³è”çš„3Då‡ ä½•ã€å¤šè§†å›¾æ¸²æŸ“å’Œæ¨¡æ‹Ÿå¼¹æ€§å±æ€§çš„å¤§è§„æ¨¡ç²¾é€‰æ•°æ®åº“ã€‚ä¸ºäº†è¯„ä¼°VLMsåœ¨è¶…ææ–™é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œç ”ç©¶è®¾è®¡äº†MetaBenchåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–ç»“æ„é‡å»ºã€æ€§èƒ½é©±åŠ¨çš„é€†å‘è®¾è®¡(inverse design)ä»¥åŠæ€§èƒ½é¢„æµ‹ä¸‰å¤§æ ¸å¿ƒä»»åŠ¡ã€‚å®éªŒé€šè¿‡å¾®è°ƒæœ€å…ˆè¿›çš„VLMså¹¶å°†å…¶éƒ¨ç½²äºäº¤äº’å¼CADç•Œé¢ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨ç†è§£ç»“æ„-è¡¨ç¤º-å±æ€§(structure-representation-property)å…³ç³»åŠé›†æˆè®¾è®¡æµç¨‹ä¸­çš„é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17568v1",
      "published_date": "2025-08-25 00:36:07 UTC",
      "updated_date": "2025-08-25 00:36:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:07:11.584719+00:00"
    },
    {
      "arxiv_id": "2508.17565v1",
      "title": "TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis",
      "title_zh": "TradingGroupï¼šå…·å¤‡è‡ªåæ€ä¸æ•°æ®åˆæˆèƒ½åŠ›çš„å¤šæ™ºèƒ½ä½“äº¤æ˜“ç³»ç»Ÿ",
      "authors": [
        "Feng Tian",
        "Flora D. Salim",
        "Hao Xue"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have enabled powerful agent-based applications in finance, particularly for sentiment analysis, financial report comprehension, and stock forecasting. However, existing systems often lack inter-agent coordination, structured self-reflection, and access to high-quality, domain-specific post-training data such as data from trading activities including both market conditions and agent decisions. These data are crucial for agents to understand the market dynamics, improve the quality of decision-making and promote effective coordination. We introduce TradingGroup, a multi-agent trading system designed to address these limitations through a self-reflective architecture and an end-to-end data-synthesis pipeline. TradingGroup consists of specialized agents for news sentiment analysis, financial report interpretation, stock trend forecasting, trading style adaptation, and a trading decision making agent that merges all signals and style preferences to produce buy, sell or hold decisions. Specifically, we design self-reflection mechanisms for the stock forecasting, style, and decision-making agents to distill past successes and failures for similar reasoning in analogous future scenarios and a dynamic risk-management model to offer configurable dynamic stop-loss and take-profit mechanisms. In addition, TradingGroup embeds an automated data-synthesis and annotation pipeline that generates high-quality post-training data for further improving the agent performance through post-training. Our backtesting experiments across five real-world stock datasets demonstrate TradingGroup's superior performance over rule-based, machine learning, reinforcement learning, and existing LLM-based trading strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TradingGroupï¼Œä¸€ä¸ªé›†æˆäº†è‡ªæˆ‘åæ€(Self-Reflection)å’Œæ•°æ®åˆæˆ(Data-Synthesis)æœºåˆ¶çš„å¤šæ™ºèƒ½ä½“äº¤æ˜“ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰é‡‘èæ™ºèƒ½ä½“åœ¨åä½œåè°ƒã€ç»“æ„åŒ–åæ€ä»¥åŠé«˜è´¨é‡é¢†åŸŸç‰¹å®šæ•°æ®è·å–æ–¹é¢çš„ä¸è¶³ã€‚è¯¥ç³»ç»Ÿç”±è´Ÿè´£æ–°é—»æƒ…æ„Ÿåˆ†æã€è´¢æŠ¥è§£è¯»ã€è¶‹åŠ¿é¢„æµ‹ã€é£æ ¼é€‚é…å’Œæœ€ç»ˆå†³ç­–çš„å¤šä¸ªä¸“é—¨æ™ºèƒ½ä½“ç»„æˆï¼Œé€šè¿‡å†³ç­–æ™ºèƒ½ä½“æ•´åˆå¤šå…ƒä¿¡å·ä»¥äº§ç”Ÿä¹°å…¥ã€å–å‡ºæˆ–æŒæœ‰çš„æŒ‡ä»¤ã€‚TradingGroupç‰¹åˆ«ä¸ºè¶‹åŠ¿é¢„æµ‹å’Œå†³ç­–è¿‡ç¨‹è®¾è®¡äº†è‡ªæˆ‘åæ€æœºåˆ¶ï¼Œèƒ½å¤Ÿä»å†å²ç›ˆäºç»éªŒä¸­æç‚¼è§„å¾‹ä»¥ä¼˜åŒ–æœªæ¥å†³ç­–ï¼Œå¹¶å¼•å…¥åŠ¨æ€é£é™©ç®¡ç†(Risk-management)æ¨¡å‹å®ç°çµæ´»çš„æ­¢æŸæ­¢ç›ˆã€‚æ­¤å¤–ï¼Œç³»ç»Ÿå†…ç½®è‡ªåŠ¨åŒ–çš„æ•°æ®åˆæˆä¸æ ‡æ³¨æµæ°´çº¿ï¼Œç”Ÿæˆé«˜è´¨é‡çš„åè®­ç»ƒ(Post-training)æ•°æ®ä»¥æŒç»­æå‡æ™ºèƒ½ä½“æ€§èƒ½ã€‚åœ¨äº”ä¸ªçœŸå®è‚¡ç¥¨æ•°æ®é›†ä¸Šçš„å›æµ‹å®éªŒè¯æ˜ï¼ŒTradingGroupçš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„åŸºäºè§„åˆ™ã€æœºå™¨å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ä»¥åŠç°æœ‰çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„äº¤æ˜“ç­–ç•¥ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.17565v1",
      "published_date": "2025-08-25 00:29:58 UTC",
      "updated_date": "2025-08-25 00:29:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:07:08.449827+00:00"
    },
    {
      "arxiv_id": "2508.17561v1",
      "title": "Consciousness as a Functor",
      "title_zh": "ä½œä¸ºå‡½å­çš„æ„è¯†",
      "authors": [
        "Sridhar Mahadevan"
      ],
      "abstract": "We propose a novel theory of consciousness as a functor (CF) that receives and transmits contents from unconscious memory into conscious memory. Our CF framework can be seen as a categorial formulation of the Global Workspace Theory proposed by Baars. CF models the ensemble of unconscious processes as a topos category of coalgebras. The internal language of thought in CF is defined as a Multi-modal Universal Mitchell-Benabou Language Embedding (MUMBLE). We model the transmission of information from conscious short-term working memory to long-term unconscious memory using our recently proposed Universal Reinforcement Learning (URL) framework. To model the transmission of information from unconscious long-term memory into resource-constrained short-term memory, we propose a network economic model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºæ„è¯†å‡½å­ (Consciousness as a Functor, CF) çš„æ–°ç†è®ºï¼Œæ—¨åœ¨æè¿°æ½œæ„è¯†è®°å¿†ä¸æ„è¯†è®°å¿†ä¹‹é—´çš„å†…å®¹æ¥æ”¶ä¸ä¼ è¾“ã€‚è¯¥æ¡†æ¶æ˜¯ Baars å…¨çƒå·¥ä½œç©ºé—´ç†è®º (Global Workspace Theory) çš„ä¸€ç§èŒƒç•´è®ºè¡¨è¿°ã€‚ç ”ç©¶å°†æ½œæ„è¯†è¿‡ç¨‹çš„æ•´ä½“å»ºæ¨¡ä¸ºä½™ä»£æ•°çš„æ‹“æ‰‘æ–¯èŒƒç•´ (topos category of coalgebras)ï¼Œå¹¶å®šä¹‰äº†åä¸º MUMBLE çš„å¤šæ¨¡æ€é€šç”¨ Mitchell-Benabou è¯­è¨€åµŒå…¥ä½œä¸ºå…¶å†…éƒ¨æ€ç»´è¯­è¨€ã€‚å¯¹äºä»æ„è¯†çŸ­æœŸå·¥ä½œè®°å¿†åˆ°æ½œæ„è¯†é•¿æœŸè®°å¿†çš„ä¿¡æ¯ä¼ é€’ï¼Œç ”ç©¶é‡‡ç”¨äº†é€šç”¨å¼ºåŒ–å­¦ä¹  (URL) æ¡†æ¶è¿›è¡Œå»ºæ¨¡ã€‚é’ˆå¯¹ä»æ½œæ„è¯†é•¿æœŸè®°å¿†åˆ°èµ„æºå—é™çš„æ„è¯†çŸ­æœŸè®°å¿†çš„ä¿¡æ¯ä¼ è¾“ï¼Œè¯¥ç†è®ºå¼•å…¥äº†ä¸€ä¸ªç½‘ç»œç»æµæ¨¡å‹ã€‚è¿™ä¸€ CF æ¡†æ¶é€šè¿‡ä¸¥æ ¼çš„æ•°å­¦å·¥å…·ä¸ºæ¢ç´¢æ„è¯†çš„è®¤çŸ¥æ¶æ„å’ŒåŠ¨åŠ›å­¦æœºåˆ¶æä¾›äº†å…¨æ–°çš„èŒƒç•´è®ºè§†è§’ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.17561v1",
      "published_date": "2025-08-25 00:06:52 UTC",
      "updated_date": "2025-08-25 00:06:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T14:07:13.989100+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 139,
  "processed_papers_count": 139,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T14:08:10.668417+00:00"
}