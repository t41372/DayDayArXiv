[
  {
    "arxiv_id": "2410.17257v2",
    "title": "Code-Driven Law NO, Normware SI!",
    "authors": [
      "Giovanni Sileno"
    ],
    "abstract": "With the digitalization of society, the interest, the debates and the\nresearch efforts concerning \"code\", \"law\", \"artificial intelligence\", and their\nvarious relationships, have been widely increasing. Yet, most arguments\nprimarily focus on contemporary computational methods and artifacts\n(inferential models constructed via machine-learning methods, rule-based\nsystems, smart contracts), rather than attempting to identify more fundamental\nmechanisms. Aiming to go beyond this conceptual limitation, this paper\nintroduces and elaborates on \"normware\" as an explicit additional stance --\ncomplementary to software and hardware -- for the interpretation and the design\nof artificial devices. By means of a few examples, I will argue that a\nnormware-centred perspective provides a more adequate abstraction to study and\ndesign interactions between computational systems and human institutions, and\nmay help with the design and development of technical interventions within\nwider socio-technical views.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CY",
    "comment": "First version of the paper presented at CRCL 2022",
    "pdf_url": "http://arxiv.org/pdf/2410.17257v2",
    "published_date": "2024-10-05 22:37:45 UTC",
    "updated_date": "2025-01-20 19:40:29 UTC"
  },
  {
    "arxiv_id": "2410.04289v1",
    "title": "Self-Supervised Anomaly Detection in the Wild: Favor Joint Embeddings Methods",
    "authors": [
      "Daniel Otero",
      "Rafael Mateus",
      "Randall Balestriero"
    ],
    "abstract": "Accurate anomaly detection is critical in vision-based infrastructure\ninspection, where it helps prevent costly failures and enhances safety.\nSelf-Supervised Learning (SSL) offers a promising approach by learning robust\nrepresentations from unlabeled data. However, its application in anomaly\ndetection remains underexplored. This paper addresses this gap by providing a\ncomprehensive evaluation of SSL methods for real-world anomaly detection,\nfocusing on sewer infrastructure. Using the Sewer-ML dataset, we evaluate\nlightweight models such as ViT-Tiny and ResNet-18 across SSL frameworks,\nincluding BYOL, Barlow Twins, SimCLR, DINO, and MAE, under varying class\nimbalance levels. Through 250 experiments, we rigorously assess the performance\nof these SSL methods to ensure a robust and comprehensive evaluation. Our\nfindings highlight the superiority of joint-embedding methods like SimCLR and\nBarlow Twins over reconstruction-based approaches such as MAE, which struggle\nto maintain performance under class imbalance. Furthermore, we find that the\nSSL model choice is more critical than the backbone architecture. Additionally,\nwe emphasize the need for better label-free assessments of SSL representations,\nas current methods like RankMe fail to adequately evaluate representation\nquality, making cross-validation without labels infeasible. Despite the\nremaining performance gap between SSL and supervised models, these findings\nhighlight the potential of SSL to enhance anomaly detection, paving the way for\nfurther research in this underexplored area of SSL applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04289v1",
    "published_date": "2024-10-05 21:27:47 UTC",
    "updated_date": "2024-10-05 21:27:47 UTC"
  },
  {
    "arxiv_id": "2410.05328v1",
    "title": "Reward Learning From Preference With Ties",
    "authors": [
      "Jinsong Liu",
      "Dongdong Ge",
      "Ruihao Zhu"
    ],
    "abstract": "Reward learning plays a pivotal role in Reinforcement Learning from Human\nFeedback (RLHF), ensuring the alignment of language models. The Bradley-Terry\n(BT) model stands as the prevalent choice for capturing human preferences from\ndatasets containing pairs of chosen and rejected responses. In preference\nmodeling, the focus is not on absolute values but rather on the reward\ndifference between chosen and rejected responses, referred to as preference\nstrength. Thus, precise evaluation of preference strength holds paramount\nimportance in preference modeling. However, an easily overlooked factor\nsignificantly affecting preference strength measurement is that human attitudes\ntowards two responses may not solely indicate a preference for one over the\nother and ties are also a common occurrence. To address this, we propose the\nadoption of the generalized Bradley-Terry model -- the Bradley-Terry model with\nties (BTT) -- to accommodate tied preferences, thus leveraging additional\ninformation. We prove that even with the access to the true distributions of\nprompt and response, disregarding ties can lead to a notable bias in preference\nstrength measurement. Comprehensive experiments further validate the advantages\nof incorporating ties in preference modeling. Notably, fine-tuning with BTT\nsignificantly outperforms fine-tuning with BT on synthetic preference datasets\nwith ties, labeled by state-of-the-art open-source LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05328v1",
    "published_date": "2024-10-05 21:02:57 UTC",
    "updated_date": "2024-10-05 21:02:57 UTC"
  },
  {
    "arxiv_id": "2410.04277v1",
    "title": "Mechanistic Behavior Editing of Language Models",
    "authors": [
      "Joykirat Singh",
      "Subhabrata Dutta",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Large Language Models trained on web-scale text acquire language generation\nabilities that can solve a wide range of tasks, particularly when task\nknowledge is refined into the generative prior using in-context examples.\nHowever, spurious features learned from noisy data hinder their\ngeneralizability. Supervised finetuning can introduce task specificity, but\nintroduce data inefficiency. Prior studies indicate that (i) noisy neural\ncircuitries coexist with generalizable ones within LLMs, and (ii) finetuning\ntypically enhances (or suppresses) existing abilities without introducing newer\nones. Building upon these, we propose TaRot, a novel method for task\nadaptation. TaRot intervenes in the neural circuitries using learnable rotation\nmatrices that are optimized using Bayesian Optimization, on labelled samples in\nthe order of standard few-shot prompting examples. Experiments on multiple\nclassification and generation tasks using LLMs of varying sizes reveal the\nefficacy of TaRot, improving upon both zero- as well as few-shot performance,\nwith average improvements (across models and tasks) of 23.81% and 11.15%,\nrespectively. The source code is available at\nhttps://github.com/joykirat18/TaRot",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04277v1",
    "published_date": "2024-10-05 19:58:08 UTC",
    "updated_date": "2024-10-05 19:58:08 UTC"
  },
  {
    "arxiv_id": "2410.04266v1",
    "title": "Constructing Cloze Questions Generatively",
    "authors": [
      "Yicheng Sun",
      "Jie Wang"
    ],
    "abstract": "We present a generative method called CQG for constructing cloze questions\nfrom a given article using neural networks and WordNet, with an emphasis on\ngenerating multigram distractors. Built on sense disambiguation, text-to-text\ntransformation, WordNet's synset taxonomies and lexical labels, CQG selects an\nanswer key for a given sentence, segments it into a sequence of instances,\ngenerates instance-level distractor candidates (IDCs) using a transformer and\nsibling synsets.It then removes inappropriate IDCs, ranks the remaining IDCs\nbased on contextual embedding similarities, as well as synset and lexical\nrelatedness, forms distractor candidates by combinatorially replacing instances\nwith the corresponding top-ranked IDCs, and checks if they are legitimate\nphrases. Finally, it selects top-ranked distractor candidates based on\ncontextual semantic similarities to the answer key. Experiments show that this\nmethod significantly outperforms SOTA results. Human judges also confirm the\nhigh qualities of the generated distractors.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures,5 tables, 2023 International Joint Conference on\n  Neural Networks (IJCNN)",
    "pdf_url": "http://arxiv.org/pdf/2410.04266v1",
    "published_date": "2024-10-05 18:55:38 UTC",
    "updated_date": "2024-10-05 18:55:38 UTC"
  },
  {
    "arxiv_id": "2410.04260v2",
    "title": "Pareto Control Barrier Function for Inner Safe Set Maximization Under Input Constraints",
    "authors": [
      "Xiaoyang Cao",
      "Zhe Fu",
      "Alexandre M. Bayen"
    ],
    "abstract": "This article introduces the Pareto Control Barrier Function (PCBF) algorithm\nto maximize the inner safe set of dynamical systems under input constraints.\nTraditional Control Barrier Functions (CBFs) ensure safety by maintaining\nsystem trajectories within a safe set but often fail to account for realistic\ninput constraints. To address this problem, we leverage the Pareto multi-task\nlearning framework to balance competing objectives of safety and safe set\nvolume. The PCBF algorithm is applicable to high-dimensional systems and is\ncomputationally efficient. We validate its effectiveness through comparison\nwith Hamilton-Jacobi reachability for an inverted pendulum and through\nsimulations on a 12-dimensional quadrotor system. Results show that the PCBF\nconsistently outperforms existing methods, yielding larger safe sets and\nensuring safety under input constraints.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "math.OC",
    "comment": "Accepted for presentation at American Control Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.04260v2",
    "published_date": "2024-10-05 18:45:19 UTC",
    "updated_date": "2025-03-20 17:05:28 UTC"
  },
  {
    "arxiv_id": "2410.04256v1",
    "title": "Implicit to Explicit Entropy Regularization: Benchmarking ViT Fine-tuning under Noisy Labels",
    "authors": [
      "Maria Marrium",
      "Arif Mahmood",
      "Mohammed Bennamoun"
    ],
    "abstract": "Automatic annotation of large-scale datasets can introduce noisy training\ndata labels, which adversely affect the learning process of deep neural\nnetworks (DNNs). Consequently, Noisy Labels Learning (NLL) has become a\ncritical research field for Convolutional Neural Networks (CNNs), though it\nremains less explored for Vision Transformers (ViTs). In this study, we\nevaluate the vulnerability of ViT fine-tuning to noisy labels and compare its\nrobustness with CNNs. We also investigate whether NLL methods developed for\nCNNs are equally effective for ViTs. Using linear probing and MLP-K\nfine-tuning, we benchmark two ViT backbones (ViT-B/16 and ViT-L/16) using three\ncommonly used classification losses: Cross Entropy (CE), Focal Loss (FL), and\nMean Absolute Error (MAE), alongside six robust NLL methods: GCE, SCE, NLNL,\nAPL, NCE+AGCE, and ANL-CE. The evaluation is conducted across six datasets\nincluding MNIST, CIFAR-10/100, WebVision, Clothing1M, and Food-101N.\nFurthermore, we explore whether implicit prediction entropy minimization\ncontributes to ViT robustness against noisy labels, noting a general trend of\nprediction entropy reduction across most NLL methods. Building on this\nobservation, we examine whether explicit entropy minimization could enhance ViT\nresilience to noisy labels. Our findings indicate that incorporating entropy\nregularization enhances the performance of established loss functions such as\nCE and FL, as well as the robustness of the six studied NLL methods across both\nViT backbones.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04256v1",
    "published_date": "2024-10-05 18:24:38 UTC",
    "updated_date": "2024-10-05 18:24:38 UTC"
  },
  {
    "arxiv_id": "2410.04254v1",
    "title": "Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia",
    "authors": [
      "Tomás Feith",
      "Akhil Arora",
      "Martin Gerlach",
      "Debjit Paul",
      "Robert West"
    ],
    "abstract": "Links are a fundamental part of information networks, turning isolated pieces\nof knowledge into a network of information that is much richer than the sum of\nits parts. However, adding a new link to the network is not trivial: it\nrequires not only the identification of a suitable pair of source and target\nentities but also the understanding of the content of the source to locate a\nsuitable position for the link in the text. The latter problem has not been\naddressed effectively, particularly in the absence of text spans in the source\nthat could serve as anchors to insert a link to the target entity. To bridge\nthis gap, we introduce and operationalize the task of entity insertion in\ninformation networks. Focusing on the case of Wikipedia, we empirically show\nthat this problem is, both, relevant and challenging for editors. We compile a\nbenchmark dataset in 105 languages and develop a framework for entity insertion\ncalled LocEI (Localized Entity Insertion) and its multilingual variant XLocEI.\nWe show that XLocEI outperforms all baseline models (including state-of-the-art\nprompt-based ranking with LLMs such as GPT-4) and that it can be applied in a\nzero-shot manner on languages not seen during training with minimal performance\ndrop. These findings are important for applying entity insertion models in\npractice, e.g., to support editors in adding links across the more than 300\nlanguage versions of Wikipedia.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024; 24 pages; 62 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.04254v1",
    "published_date": "2024-10-05 18:22:15 UTC",
    "updated_date": "2024-10-05 18:22:15 UTC"
  },
  {
    "arxiv_id": "2410.04253v2",
    "title": "Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills",
    "authors": [
      "Zana Buçinca",
      "Siddharth Swaroop",
      "Amanda E. Paluch",
      "Finale Doshi-Velez",
      "Krzysztof Z. Gajos"
    ],
    "abstract": "People's decision-making abilities often fail to improve or may even erode\nwhen they rely on AI for decision-support, even when the AI provides\ninformative explanations. We argue this is partly because people intuitively\nseek contrastive explanations, which clarify the difference between the AI's\ndecision and their own reasoning, while most AI systems offer \"unilateral\"\nexplanations that justify the AI's decision but do not account for users'\nthinking. To align human-AI knowledge on decision tasks, we introduce a\nframework for generating human-centered contrastive explanations that explain\nthe difference between AI's choice and a predicted, likely human choice about\nthe same task. Results from a large-scale experiment (N = 628) demonstrate that\ncontrastive explanations significantly enhance users' independent\ndecision-making skills compared to unilateral explanations, without sacrificing\ndecision accuracy. Amid rising deskilling concerns, our research demonstrates\nthat incorporating human reasoning into AI design can foster human skill\ndevelopment.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04253v2",
    "published_date": "2024-10-05 18:21:04 UTC",
    "updated_date": "2025-03-19 00:44:00 UTC"
  },
  {
    "arxiv_id": "2410.04251v1",
    "title": "Enhancing Future Link Prediction in Quantum Computing Semantic Networks through LLM-Initiated Node Features",
    "authors": [
      "Gilchan Park",
      "Paul Baity",
      "Byung-Jun Yoon",
      "Adolfy Hoisie"
    ],
    "abstract": "Quantum computing is rapidly evolving in both physics and computer science,\noffering the potential to solve complex problems and accelerate computational\nprocesses. The development of quantum chips necessitates understanding the\ncorrelations among diverse experimental conditions. Semantic networks built on\nscientific literature, representing meaningful relationships between concepts,\nhave been used across various domains to identify knowledge gaps and novel\nconcept combinations. Neural network-based approaches have shown promise in\nlink prediction within these networks. This study proposes initializing node\nfeatures using LLMs to enhance node representations for link prediction tasks\nin graph neural networks. LLMs can provide rich descriptions, reducing the need\nfor manual feature creation and lowering costs. Our method, evaluated using\nvarious link prediction models on a quantum computing semantic network,\ndemonstrated efficacy compared to traditional node embedding techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04251v1",
    "published_date": "2024-10-05 18:16:07 UTC",
    "updated_date": "2024-10-05 18:16:07 UTC"
  },
  {
    "arxiv_id": "2410.21279v1",
    "title": "Comparative Global AI Regulation: Policy Perspectives from the EU, China, and the US",
    "authors": [
      "Jon Chun",
      "Christian Schroeder de Witt",
      "Katherine Elkins"
    ],
    "abstract": "As a powerful and rapidly advancing dual-use technology, AI offers both\nimmense benefits and worrisome risks. In response, governing bodies around the\nworld are developing a range of regulatory AI laws and policies. This paper\ncompares three distinct approaches taken by the EU, China and the US. Within\nthe US, we explore AI regulation at both the federal and state level, with a\nfocus on California's pending Senate Bill 1047. Each regulatory system reflects\ndistinct cultural, political and economic perspectives. Each also highlights\ndiffering regional perspectives on regulatory risk-benefit tradeoffs, with\ndivergent judgments on the balance between safety versus innovation and\ncooperation versus competition. Finally, differences between regulatory\nframeworks reflect contrastive stances in regards to trust in centralized\nauthority versus trust in a more decentralized free market of self-interested\nstakeholders. Taken together, these varied approaches to AI innovation and\nregulation influence each other, the broader international community, and the\nfuture of AI regulation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "91B32, 68T01 91B32, 68T99, 91F10, 91F50",
      "K.5.1; K.4.1; K.5.2"
    ],
    "primary_category": "cs.CY",
    "comment": "36 pages, 11 figures and tables",
    "pdf_url": "http://arxiv.org/pdf/2410.21279v1",
    "published_date": "2024-10-05 18:08:48 UTC",
    "updated_date": "2024-10-05 18:08:48 UTC"
  },
  {
    "arxiv_id": "2410.04245v1",
    "title": "Towards Propositional KLM-Style Defeasible Standpoint Logics",
    "authors": [
      "Nicholas Leisegang",
      "Thomas Meyer",
      "Sebastian Rudolph"
    ],
    "abstract": "The KLM approach to defeasible reasoning introduces a weakened form of\nimplication into classical logic. This allows one to incorporate exceptions to\ngeneral rules into a logical system, and for old conclusions to be withdrawn\nupon learning new contradictory information. Standpoint logics are a group of\nlogics, introduced to the field of Knowledge Representation in the last 5\nyears, which allow for multiple viewpoints to be integrated into the same\nontology, even when certain viewpoints may hold contradicting beliefs. In this\npaper, we aim to integrate standpoints into KLM propositional logic in a\nrestricted setting. We introduce the logical system of Defeasible Restricted\nStandpoint Logic (DRSL) and define its syntax and semantics. Specifically, we\nintegrate ranked interpretations and standpoint structures, which provide the\nsemantics for propositional KLM and propositional standpoint logic\nrespectively, in order to introduce ranked standpoint structures for DRSL.\nMoreover, we extend the non-monotonic entailment relation of rational closure\nfrom the propositional KLM case to the DRSL case. The main contribution of this\npaper is to characterize rational closure for DRSL both algorithmically and\nsemantically, showing that rational closure can be characterized through a\nsingle representative ranked standpoint structure. Finally, we conclude that\nthe semantic and algorithmic characterizations of rational closure are\nequivalent, and that entailment-checking for DRSL under rational closure is in\nthe same complexity class as entailment-checking for propositional KLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04245v1",
    "published_date": "2024-10-05 18:07:03 UTC",
    "updated_date": "2024-10-05 18:07:03 UTC"
  },
  {
    "arxiv_id": "2410.04236v1",
    "title": "Overview of Factify5WQA: Fact Verification through 5W Question-Answering",
    "authors": [
      "Suryavardan Suresh",
      "Anku Rani",
      "Parth Patwa",
      "Aishwarya Reganti",
      "Vinija Jain",
      "Aman Chadha",
      "Amitava Das",
      "Amit Sheth",
      "Asif Ekbal"
    ],
    "abstract": "Researchers have found that fake news spreads much times faster than real\nnews. This is a major problem, especially in today's world where social media\nis the key source of news for many among the younger population. Fact\nverification, thus, becomes an important task and many media sites contribute\nto the cause. Manual fact verification is a tedious task, given the volume of\nfake news online. The Factify5WQA shared task aims to increase research towards\nautomated fake news detection by providing a dataset with an aspect-based\nquestion answering based fact verification method. Each claim and its\nsupporting document is associated with 5W questions that help compare the two\ninformation sources. The objective performance measure in the task is done by\ncomparing answers using BLEU score to measure the accuracy of the answers,\nfollowed by an accuracy measure of the classification. The task had submissions\nusing custom training setup and pre-trained language-models among others. The\nbest performing team posted an accuracy of 69.56%, which is a near 35%\nimprovement over the baseline.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at defactify3@aaai2024",
    "pdf_url": "http://arxiv.org/pdf/2410.04236v1",
    "published_date": "2024-10-05 17:28:18 UTC",
    "updated_date": "2024-10-05 17:28:18 UTC"
  },
  {
    "arxiv_id": "2410.04234v2",
    "title": "Functional Homotopy: Smoothing Discrete Optimization via Continuous Parameters for LLM Jailbreak Attacks",
    "authors": [
      "Zi Wang",
      "Divyam Anshumaan",
      "Ashish Hooda",
      "Yudong Chen",
      "Somesh Jha"
    ],
    "abstract": "Optimization methods are widely employed in deep learning to identify and\nmitigate undesired model responses. While gradient-based techniques have proven\neffective for image models, their application to language models is hindered by\nthe discrete nature of the input space. This study introduces a novel\noptimization approach, termed the \\emph{functional homotopy} method, which\nleverages the functional duality between model training and input generation.\nBy constructing a series of easy-to-hard optimization problems, we iteratively\nsolve these problems using principles derived from established homotopy\nmethods. We apply this approach to jailbreak attack synthesis for large\nlanguage models (LLMs), achieving a $20\\%-30\\%$ improvement in success rate\nover existing methods in circumventing established safe open-source models such\nas Llama-2 and Llama-3.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.04234v2",
    "published_date": "2024-10-05 17:22:39 UTC",
    "updated_date": "2025-02-16 02:16:15 UTC"
  },
  {
    "arxiv_id": "2410.13883v1",
    "title": "Transformers Utilization in Chart Understanding: A Review of Recent Advances & Future Trends",
    "authors": [
      "Mirna Al-Shetairy",
      "Hanan Hindy",
      "Dina Khattab",
      "Mostafa M. Aref"
    ],
    "abstract": "In recent years, interest in vision-language tasks has grown, especially\nthose involving chart interactions. These tasks are inherently multimodal,\nrequiring models to process chart images, accompanying text, underlying data\ntables, and often user queries. Traditionally, Chart Understanding (CU) relied\non heuristics and rule-based systems. However, recent advancements that have\nintegrated transformer architectures significantly improved performance. This\npaper reviews prominent research in CU, focusing on State-of-The-Art (SoTA)\nframeworks that employ transformers within End-to-End (E2E) solutions. Relevant\nbenchmarking datasets and evaluation techniques are analyzed. Additionally,\nthis article identifies key challenges and outlines promising future directions\nfor advancing CU solutions. Following the PRISMA guidelines, a comprehensive\nliterature search is conducted across Google Scholar, focusing on publications\nfrom Jan'20 to Jun'24. After rigorous screening and quality assessment, 32\nstudies are selected for in-depth analysis. The CU tasks are categorized into a\nthree-layered paradigm based on the cognitive task required. Recent\nadvancements in the frameworks addressing various CU tasks are also reviewed.\nFrameworks are categorized into single-task or multi-task based on the number\nof tasks solvable by the E2E solution. Within multi-task frameworks,\npre-trained and prompt-engineering-based techniques are explored. This review\noverviews leading architectures, datasets, and pre-training tasks. Despite\nsignificant progress, challenges remain in OCR dependency, handling\nlow-resolution images, and enhancing visual reasoning. Future directions\ninclude addressing these challenges, developing robust benchmarks, and\noptimizing model efficiency. Additionally, integrating explainable AI\ntechniques and exploring the balance between real and synthetic data are\ncrucial for advancing CU research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13883v1",
    "published_date": "2024-10-05 16:26:44 UTC",
    "updated_date": "2024-10-05 16:26:44 UTC"
  },
  {
    "arxiv_id": "2410.04217v2",
    "title": "Improving Portfolio Optimization Results with Bandit Networks",
    "authors": [
      "Gustavo de Freitas Fonseca",
      "Lucas Coelho e Silva",
      "Paulo André Lima de Castro"
    ],
    "abstract": "In Reinforcement Learning (RL), multi-armed Bandit (MAB) problems have found\napplications across diverse domains such as recommender systems, healthcare,\nand finance. Traditional MAB algorithms typically assume stationary reward\ndistributions, which limits their effectiveness in real-world scenarios\ncharacterized by non-stationary dynamics. This paper addresses this limitation\nby introducing and evaluating novel Bandit algorithms designed for\nnon-stationary environments. First, we present the Adaptive Discounted Thompson\nSampling (ADTS) algorithm, which enhances adaptability through relaxed\ndiscounting and sliding window mechanisms to better respond to changes in\nreward distributions. We then extend this approach to the Portfolio\nOptimization problem by introducing the Combinatorial Adaptive Discounted\nThompson Sampling (CADTS) algorithm, which addresses computational challenges\nwithin Combinatorial Bandits and improves dynamic asset allocation.\nAdditionally, we propose a novel architecture called Bandit Networks, which\nintegrates the outputs of ADTS and CADTS, thereby mitigating computational\nlimitations in stock selection. Through extensive experiments using real\nfinancial market data, we demonstrate the potential of these algorithms and\narchitectures in adapting to dynamic environments and optimizing\ndecision-making processes. For instance, the proposed bandit network instances\npresent superior performance when compared to classic portfolio optimization\napproaches, such as capital asset pricing model, equal weights, risk parity,\nand Markovitz, with the best network presenting an out-of-sample Sharpe Ratio\n20% higher than the best performing classical model.",
    "categories": [
      "cs.AI",
      "q-fin.PM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04217v2",
    "published_date": "2024-10-05 16:17:31 UTC",
    "updated_date": "2024-10-08 07:48:03 UTC"
  },
  {
    "arxiv_id": "2410.04211v1",
    "title": "Correlation-Aware Select and Merge Attention for Efficient Fine-Tuning and Context Length Extension",
    "authors": [
      "Ning Wang",
      "Zekun Li",
      "Tongxin Bai",
      "Guoqi Li"
    ],
    "abstract": "Modeling long sequences is crucial for various large-scale models; however,\nextending existing architectures to handle longer sequences presents\nsignificant technical and resource challenges. In this paper, we propose an\nefficient and flexible attention architecture that enables the extension of\ncontext lengths in large language models with reduced computational resources\nand fine-tuning time compared to other excellent methods. Specifically, we\nintroduce correlation-aware selection and merging mechanisms to facilitate\nefficient sparse attention. In addition, we also propose a novel data\naugmentation technique involving positional encodings to enhance generalization\nto unseen positions. The results are as follows: First, using a single A100, we\nachieve fine-tuning on Llama2-7B with a sequence length of 32K, which is more\nefficient than other methods that rely on subsets for regression. Second, we\npresent a comprehensive method for extending context lengths across the\npre-training, fine-tuning, and inference phases. During pre-training, our\nattention mechanism partially breaks translation invariance during token\nselection, so we apply positional encodings only to the selected tokens. This\napproach achieves relatively high performance and significant extrapolation\ncapabilities. For fine-tuning, we introduce Cyclic, Randomly Truncated, and\nDynamically Growing NTK Positional Embedding (CRD NTK). This design allows\nfine-tuning with a sequence length of only 16K, enabling models such as\nLlama2-7B and Mistral-7B to perform inference with context lengths of up to 1M\nor even arbitrary lengths. Our method achieves 100\\% accuracy on the passkey\ntask with a context length of 4M and maintains stable perplexity at a 1M\ncontext length. This represents at least a 64-fold reduction in resource\nrequirements compared to traditional full-attention mechanisms, while still\nachieving competitive performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.04211v1",
    "published_date": "2024-10-05 15:59:32 UTC",
    "updated_date": "2024-10-05 15:59:32 UTC"
  },
  {
    "arxiv_id": "2410.04203v2",
    "title": "RainbowPO: A Unified Framework for Combining Improvements in Preference Optimization",
    "authors": [
      "Hanyang Zhao",
      "Genta Indra Winata",
      "Anirban Das",
      "Shi-Xiong Zhang",
      "David D. Yao",
      "Wenpin Tang",
      "Sambit Sahu"
    ],
    "abstract": "Recently, numerous preference optimization algorithms have been introduced as\nextensions to the Direct Preference Optimization (DPO) family. While these\nmethods have successfully aligned models with human preferences, there is a\nlack of understanding regarding the contributions of their additional\ncomponents. Moreover, fair and consistent comparisons are scarce, making it\ndifficult to discern which components genuinely enhance downstream performance.\nIn this work, we propose RainbowPO, a unified framework that demystifies the\neffectiveness of existing DPO methods by categorizing their key components into\nseven broad directions. We integrate these components into a single cohesive\nobjective, enhancing the performance of each individual element. Through\nextensive experiments, we demonstrate that RainbowPO outperforms existing DPO\nvariants. Additionally, we provide insights to guide researchers in developing\nnew DPO methods and assist practitioners in their implementations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04203v2",
    "published_date": "2024-10-05 15:44:46 UTC",
    "updated_date": "2025-03-01 00:02:01 UTC"
  },
  {
    "arxiv_id": "2410.04199v3",
    "title": "LongGenBench: Long-context Generation Benchmark",
    "authors": [
      "Xiang Liu",
      "Peijie Dong",
      "Xuming Hu",
      "Xiaowen Chu"
    ],
    "abstract": "Current long-context benchmarks primarily focus on retrieval-based tests,\nrequiring Large Language Models (LLMs) to locate specific information within\nextensive input contexts, such as the needle-in-a-haystack (NIAH) benchmark.\nLong-context generation refers to the ability of a language model to generate\ncoherent and contextually accurate text that spans across lengthy passages or\ndocuments. While recent studies show strong performance on NIAH and other\nretrieval-based long-context benchmarks, there is a significant lack of\nbenchmarks for evaluating long-context generation capabilities. To bridge this\ngap and offer a comprehensive assessment, we introduce a synthetic benchmark,\nLongGenBench, which allows for flexible configurations of customized generation\ncontext lengths. LongGenBench advances beyond traditional benchmarks by\nredesigning the format of questions and necessitating that LLMs respond with a\nsingle, cohesive long-context answer. Upon extensive evaluation using\nLongGenBench, we observe that: (1) both API accessed and open source models\nexhibit performance degradation in long-context generation scenarios, ranging\nfrom 1.2% to 47.1%; (2) different series of LLMs exhibit varying trends of\nperformance degradation, with the Gemini-1.5-Flash model showing the least\ndegradation among API accessed models, and the Qwen2 series exhibiting the\nleast degradation in LongGenBench among open source models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 https://github.com/Dominic789654/LongGenBench",
    "pdf_url": "http://arxiv.org/pdf/2410.04199v3",
    "published_date": "2024-10-05 15:33:25 UTC",
    "updated_date": "2024-10-24 14:43:22 UTC"
  },
  {
    "arxiv_id": "2410.04191v1",
    "title": "Accelerating Diffusion Models with One-to-Many Knowledge Distillation",
    "authors": [
      "Linfeng Zhang",
      "Kaisheng Ma"
    ],
    "abstract": "Significant advancements in image generation have been made with diffusion\nmodels. Nevertheless, when contrasted with previous generative models,\ndiffusion models face substantial computational overhead, leading to failure in\nreal-time generation. Recent approaches have aimed to accelerate diffusion\nmodels by reducing the number of sampling steps through improved sampling\ntechniques or step distillation. However, the methods to diminish the\ncomputational cost for each timestep remain a relatively unexplored area.\nObserving the fact that diffusion models exhibit varying input distributions\nand feature distributions at different timesteps, we introduce one-to-many\nknowledge distillation (O2MKD), which distills a single teacher diffusion model\ninto multiple student diffusion models, where each student diffusion model is\ntrained to learn the teacher's knowledge for a subset of continuous timesteps.\nExperiments on CIFAR10, LSUN Church, CelebA-HQ with DDPM and COCO30K with\nStable Diffusion show that O2MKD can be applied to previous knowledge\ndistillation and fast sampling methods to achieve significant acceleration.\nCodes will be released in Github.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04191v1",
    "published_date": "2024-10-05 15:10:04 UTC",
    "updated_date": "2024-10-05 15:10:04 UTC"
  },
  {
    "arxiv_id": "2410.04184v1",
    "title": "Non-monotonic Extensions to Formal Concept Analysis via Object Preferences",
    "authors": [
      "Lucas Carr",
      "Nicholas Leisegang",
      "Thomas Meyer",
      "Sebastian Rudolph"
    ],
    "abstract": "Formal Concept Analysis (FCA) is an approach to creating a conceptual\nhierarchy in which a \\textit{concept lattice} is generated from a\n\\textit{formal context}. That is, a triple consisting of a set of objects, $G$,\na set of attributes, $M$, and an incidence relation $I$ on $G \\times M$. A\n\\textit{concept} is then modelled as a pair consisting of a set of objects (the\n\\textit{extent}), and a set of shared attributes (the \\textit{intent}).\nImplications in FCA describe how one set of attributes follows from another.\nThe semantics of these implications closely resemble that of logical\nconsequence in classical logic. In that sense, it describes a monotonic\nconditional. The contributions of this paper are two-fold. First, we introduce\na non-monotonic conditional between sets of attributes, which assumes a\npreference over the set of objects. We show that this conditional gives rise to\na consequence relation that is consistent with the postulates for\nnon-monotonicty proposed by Kraus, Lehmann, and Magidor (commonly referred to\nas the KLM postulates). We argue that our contribution establishes a strong\ncharacterisation of non-monotonicity in FCA. Typical concepts represent\nconcepts where the intent aligns with expectations from the extent, allowing\nfor an exception-tolerant view of concepts. To this end, we show that the set\nof all typical concepts is a meet semi-lattice of the original concept lattice.\nThis notion of typical concepts is a further introduction of KLM-style\ntypicality into FCA, and is foundational towards developing an algebraic\nstructure representing a concept lattice of prototypical concepts.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04184v1",
    "published_date": "2024-10-05 15:01:00 UTC",
    "updated_date": "2024-10-05 15:01:00 UTC"
  },
  {
    "arxiv_id": "2410.16285v1",
    "title": "Assessing the Performance of Human-Capable LLMs -- Are LLMs Coming for Your Job?",
    "authors": [
      "John Mavi",
      "Nathan Summers",
      "Sergio Coronado"
    ],
    "abstract": "The current paper presents the development and validation of SelfScore, a\nnovel benchmark designed to assess the performance of automated Large Language\nModel (LLM) agents on help desk and professional consultation tasks. Given the\nincreasing integration of AI in industries, particularly within customer\nservice, SelfScore fills a crucial gap by enabling the comparison of automated\nagents and human workers. The benchmark evaluates agents on problem complexity\nand response helpfulness, ensuring transparency and simplicity in its scoring\nsystem. The study also develops automated LLM agents to assess SelfScore and\nexplores the benefits of Retrieval-Augmented Generation (RAG) for\ndomain-specific tasks, demonstrating that automated LLM agents incorporating\nRAG outperform those without. All automated LLM agents were observed to perform\nbetter than the human control group. Given these results, the study raises\nconcerns about the potential displacement of human workers, especially in areas\nwhere AI technologies excel. Ultimately, SelfScore provides a foundational tool\nfor understanding the impact of AI in help desk environments while advocating\nfor ethical considerations in the ongoing transition towards automation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16285v1",
    "published_date": "2024-10-05 14:37:35 UTC",
    "updated_date": "2024-10-05 14:37:35 UTC"
  },
  {
    "arxiv_id": "2410.04171v2",
    "title": "IV-Mixed Sampler: Leveraging Image Diffusion Models for Enhanced Video Synthesis",
    "authors": [
      "Shitong Shao",
      "Zikai Zhou",
      "Lichen Bai",
      "Haoyi Xiong",
      "Zeke Xie"
    ],
    "abstract": "The multi-step sampling mechanism, a key feature of visual diffusion models,\nhas significant potential to replicate the success of OpenAI's Strawberry in\nenhancing performance by increasing the inference computational cost.\nSufficient prior studies have demonstrated that correctly scaling up\ncomputation in the sampling process can successfully lead to improved\ngeneration quality, enhanced image editing, and compositional generalization.\nWhile there have been rapid advancements in developing inference-heavy\nalgorithms for improved image generation, relatively little work has explored\ninference scaling laws in video diffusion models (VDMs). Furthermore, existing\nresearch shows only minimal performance gains that are perceptible to the naked\neye. To address this, we design a novel training-free algorithm IV-Mixed\nSampler that leverages the strengths of image diffusion models (IDMs) to assist\nVDMs surpass their current capabilities. The core of IV-Mixed Sampler is to use\nIDMs to significantly enhance the quality of each video frame and VDMs ensure\nthe temporal coherence of the video during the sampling process. Our\nexperiments have demonstrated that IV-Mixed Sampler achieves state-of-the-art\nperformance on 4 benchmarks including UCF-101-FVD, MSR-VTT-FVD,\nChronomagic-Bench-150, and Chronomagic-Bench-1649. For example, the open-source\nAnimatediff with IV-Mixed Sampler reduces the UMT-FVD score from 275.2 to\n228.6, closing to 223.1 from the closed-source Pika-2.0.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04171v2",
    "published_date": "2024-10-05 14:33:28 UTC",
    "updated_date": "2024-10-08 03:24:10 UTC"
  },
  {
    "arxiv_id": "2410.04154v2",
    "title": "Applying Quantum Autoencoders for Time Series Anomaly Detection",
    "authors": [
      "Robin Frehner",
      "Kurt Stockinger"
    ],
    "abstract": "Anomaly detection is an important problem with applications in various\ndomains such as fraud detection, pattern recognition or medical diagnosis.\nSeveral algorithms have been introduced using classical computing approaches.\nHowever, using quantum computing for solving anomaly detection problems in time\nseries data is a widely unexplored research field.\n  This paper explores the application of quantum autoencoders to time series\nanomaly detection. We investigate two primary techniques for classifying\nanomalies: (1) Analyzing the reconstruction error generated by the quantum\nautoencoder and (2) latent representation analysis. Our simulated experimental\nresults, conducted across various ansaetze, demonstrate that quantum\nautoencoders consistently outperform classical deep learning-based autoencoders\nacross multiple datasets. Specifically, quantum autoencoders achieve superior\nanomaly detection performance while utilizing 60-230 times fewer parameters and\nrequiring five times fewer training iterations. In addition, we implement our\nquantum encoder on real quantum hardware. Our experimental results demonstrate\nthat quantum autoencoders achieve anomaly detection performance on par with\ntheir simulated counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.04154v2",
    "published_date": "2024-10-05 13:29:25 UTC",
    "updated_date": "2024-10-09 13:56:28 UTC"
  },
  {
    "arxiv_id": "2410.04153v1",
    "title": "Neuro-Symbolic Entity Alignment via Variational Inference",
    "authors": [
      "Shengyuan Chen",
      "Qinggang Zhang",
      "Junnan Dong",
      "Wen Hua",
      "Jiannong Cao",
      "Xiao Huang"
    ],
    "abstract": "Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying\nequivalent entity pairs. Existing methods can be categorized into symbolic and\nneural models. Symbolic models, while precise, struggle with substructure\nheterogeneity and sparsity, whereas neural models, although effective,\ngenerally lack interpretability and cannot handle uncertainty. We propose\nNeuSymEA, a probabilistic neuro-symbolic framework that combines the strengths\nof both methods. NeuSymEA models the joint probability of all possible pairs'\ntruth scores in a Markov random field, regulated by a set of rules, and\noptimizes it with the variational EM algorithm. In the E-step, a neural model\nparameterizes the truth score distributions and infers missing alignments. In\nthe M-step, the rule weights are updated based on the observed and inferred\nalignments. To facilitate interpretability, we further design a\npath-ranking-based explainer upon this framework that generates supporting\nrules for the inferred alignments. Experiments on benchmarks demonstrate that\nNeuSymEA not only significantly outperforms baselines in terms of effectiveness\nand robustness, but also provides interpretable results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04153v1",
    "published_date": "2024-10-05 13:29:22 UTC",
    "updated_date": "2024-10-05 13:29:22 UTC"
  },
  {
    "arxiv_id": "2410.04152v1",
    "title": "DAMMI:Daily Activities in a Psychologically Annotated Multi-Modal IoT dataset",
    "authors": [
      "Mohsen Falah Rad",
      "Kamrad Khoshhal Roudposhti",
      "Mohammad Hassan Khoobkar",
      "Mohsen Shirali",
      "Zahra Ahmadi",
      "Carlos Fernandez-Llatas"
    ],
    "abstract": "The growth in the elderly population and the shift in the age pyramid have\nincreased the demand for healthcare and well-being services. To address this\nconcern, alongside the rising cost of medical care, the concept of ageing at\nhome has emerged, driven by recent advances in medical and technological\nsolutions. Experts in computer science, communication technology, and\nhealthcare have collaborated to develop affordable health solutions by\nemploying sensors in living environments, wearable devices, and smartphones, in\nassociation with advanced data mining and intelligent systems with learning\ncapabilities, to monitor, analyze, and predict the health status of elderly\nindividuals. However, implementing intelligent healthcare systems and\ndeveloping analytical techniques requires testing and evaluating algorithms on\nreal-world data. Despite the need, there is a shortage of publicly available\ndatasets that meet these requirements. To address this gap, we present the\nDAMMI dataset in this work, designed to support researchers in the field. The\ndataset includes daily activity data of an elderly individual collected via\nhome-installed sensors, smartphone data, and a wristband over 146 days. It also\ncontains daily psychological reports provided by a team of psychologists.\nFurthermore, the data collection spans significant events such as the COVID-19\npandemic, New Year's holidays, and the religious month of Ramadan, offering\nadditional opportunities for analysis. In this paper, we outline detailed\ninformation about the data collection system, the types of data recorded, and\npre-processed event logs. This dataset is intended to assist professionals in\nIoT and data mining in evaluating and implementing their research ideas.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.04152v1",
    "published_date": "2024-10-05 13:26:54 UTC",
    "updated_date": "2024-10-05 13:26:54 UTC"
  },
  {
    "arxiv_id": "2410.05323v1",
    "title": "From Incomplete Coarse-Grained to Complete Fine-Grained: A Two-Stage Framework for Spatiotemporal Data Reconstruction",
    "authors": [
      "Ziyu Sun",
      "Haoyang Su",
      "En Wang",
      "Funing Yang",
      "Yongjian Yang",
      "Wenbin Liu"
    ],
    "abstract": "With the rapid development of various sensing devices, spatiotemporal data is\nbecoming increasingly important nowadays. However, due to sensing costs and\nprivacy concerns, the collected data is often incomplete and coarse-grained,\nlimiting its application to specific tasks. To address this, we propose a new\ntask called spatiotemporal data reconstruction, which aims to infer complete\nand fine-grained data from sparse and coarse-grained observations. To achieve\nthis, we introduce a two-stage data inference framework, DiffRecon, grounded in\nthe Denoising Diffusion Probabilistic Model (DDPM). In the first stage, we\npresent Diffusion-C, a diffusion model augmented by ST-PointFormer, a powerful\nencoder designed to leverage the spatial correlations between sparse data\npoints. Following this, the second stage introduces Diffusion-F, which\nincorporates the proposed T-PatternNet to capture the temporal pattern within\nsequential data. Together, these two stages form an end-to-end framework\ncapable of inferring complete, fine-grained data from incomplete and\ncoarse-grained observations. We conducted experiments on multiple real-world\ndatasets to demonstrate the superiority of our method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.05323v1",
    "published_date": "2024-10-05 13:16:53 UTC",
    "updated_date": "2024-10-05 13:16:53 UTC"
  },
  {
    "arxiv_id": "2410.04148v1",
    "title": "Reasoning with Natural Language Explanations",
    "authors": [
      "Marco Valentino",
      "André Freitas"
    ],
    "abstract": "Explanation constitutes an archetypal feature of human rationality,\nunderpinning learning and generalisation, and representing one of the media\nsupporting scientific discovery and communication. Due to the importance of\nexplanations in human reasoning, an increasing amount of research in Natural\nLanguage Inference (NLI) has started reconsidering the role that explanations\nplay in learning and inference, attempting to build explanation-based NLI\nmodels that can effectively encode and use natural language explanations on\ndownstream tasks. Research in explanation-based NLI, however, presents specific\nchallenges and opportunities, as explanatory reasoning reflects aspects of both\nmaterial and formal inference, making it a particularly rich setting to model\nand deliver complex reasoning. In this tutorial, we provide a comprehensive\nintroduction to the field of explanation-based NLI, grounding this discussion\non the epistemological-linguistic foundations of explanations, systematically\ndescribing the main architectural trends and evaluation methodologies that can\nbe used to build systems capable of explanatory reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Tutorial to be presented at EMNLP 2024. Website:\n  https://sites.google.com/view/reasoning-with-explanations",
    "pdf_url": "http://arxiv.org/pdf/2410.04148v1",
    "published_date": "2024-10-05 13:15:24 UTC",
    "updated_date": "2024-10-05 13:15:24 UTC"
  },
  {
    "arxiv_id": "2410.04139v2",
    "title": "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression",
    "authors": [
      "Eunseong Choi",
      "Sunkyung Lee",
      "Minjin Choi",
      "June Park",
      "Jongwuk Lee"
    ],
    "abstract": "Large language models (LLMs) have achieved significant performance gains\nusing advanced prompting techniques over various tasks. However, the increasing\nlength of prompts leads to high computational costs and often obscures crucial\ninformation. Prompt compression has been proposed to alleviate these issues,\nbut it faces challenges in (i) capturing the global context and (ii) training\nthe compressor effectively. To tackle these challenges, we introduce a novel\nprompt compression method, namely Reading To Compressing (R2C), utilizing the\nFusion-in-Decoder (FiD) architecture to identify the important information in\nthe prompt. Specifically, the cross-attention scores of the FiD are used to\ndiscern essential chunks and sentences from the prompt. R2C effectively\ncaptures the global context without compromising semantic consistency while\ndetouring the necessity of pseudo-labels for training the compressor. Empirical\nresults show that R2C retains key contexts, enhancing the LLM performance by 6%\nin out-of-domain evaluations while reducing the prompt length by 80%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of the Association for Computational Linguistics: EMNLP\n  2024; 21 pages; 10 figures and 7 tables. Code available at\n  https://github.com/eunseongc/R2C",
    "pdf_url": "http://arxiv.org/pdf/2410.04139v2",
    "published_date": "2024-10-05 12:27:47 UTC",
    "updated_date": "2024-12-31 07:04:56 UTC"
  },
  {
    "arxiv_id": "2410.04135v1",
    "title": "IceCloudNet: 3D reconstruction of cloud ice from Meteosat SEVIRI",
    "authors": [
      "Kai Jeggle",
      "Mikolaj Czerkawski",
      "Federico Serva",
      "Bertrand Le Saux",
      "David Neubauer",
      "Ulrike Lohmann"
    ],
    "abstract": "IceCloudNet is a novel method based on machine learning able to predict\nhigh-quality vertically resolved cloud ice water contents (IWC) and ice crystal\nnumber concentrations (N$_\\textrm{ice}$). The predictions come at the\nspatio-temporal coverage and resolution of geostationary satellite observations\n(SEVIRI) and the vertical resolution of active satellite retrievals (DARDAR).\nIceCloudNet consists of a ConvNeXt-based U-Net and a 3D PatchGAN discriminator\nmodel and is trained by predicting DARDAR profiles from co-located SEVIRI\nimages. Despite the sparse availability of DARDAR data due to its narrow\noverpass, IceCloudNet is able to predict cloud occurrence, spatial structure,\nand microphysical properties with high precision. The model has been applied to\nten years of SEVIRI data, producing a dataset of vertically resolved IWC and\nN$_\\textrm{ice}$ of clouds containing ice with a 3 kmx3 kmx240 mx15 minute\nresolution in a spatial domain of 30{\\deg}W to 30{\\deg}E and 30{\\deg}S to\n30{\\deg}N. The produced dataset increases the availability of vertical cloud\nprofiles, for the period when DARDAR is available, by more than six orders of\nmagnitude and moreover, IceCloudNet is able to produce vertical cloud profiles\nbeyond the lifetime of the recently ended satellite missions underlying DARDAR.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.CV",
      "J.2"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "his paper was submitted to Artificial Intelligence for the Earth\n  Systems",
    "pdf_url": "http://arxiv.org/pdf/2410.04135v1",
    "published_date": "2024-10-05 12:15:38 UTC",
    "updated_date": "2024-10-05 12:15:38 UTC"
  },
  {
    "arxiv_id": "2410.04133v3",
    "title": "An Electrocardiogram Foundation Model Built on over 10 Million Recordings with External Evaluation across Multiple Domains",
    "authors": [
      "Jun Li",
      "Aaron Aguirre",
      "Junior Moura",
      "Che Liu",
      "Lanhai Zhong",
      "Chenxi Sun",
      "Gari Clifford",
      "Brandon Westover",
      "Shenda Hong"
    ],
    "abstract": "Artificial intelligence (AI) has demonstrated significant potential in ECG\nanalysis and cardiovascular disease assessment. Recently, foundation models\nhave played a remarkable role in advancing medical AI. The development of an\nECG foundation model holds the promise of elevating AI-ECG research to new\nheights. However, building such a model faces several challenges, including\ninsufficient database sample sizes and inadequate generalization across\nmultiple domains. Additionally, there is a notable performance gap between\nsingle-lead and multi-lead ECG analyses. We introduced an ECG Foundation Model\n(ECGFounder), a general-purpose model that leverages real-world ECG annotations\nfrom cardiology experts to broaden the diagnostic capabilities of ECG analysis.\nECGFounder was trained on over 10 million ECGs with 150 label categories from\nthe Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease\ndiagnosis through ECG analysis. The model is designed to be both an effective\nout-of-the-box solution, and a to be fine-tunable for downstream tasks,\nmaximizing usability. Importantly, we extended its application to lower rank\nECGs, and arbitrary single-lead ECGs in particular. ECGFounder is applicable to\nsupporting various downstream tasks in mobile monitoring scenarios.\nExperimental results demonstrate that ECGFounder achieves expert-level\nperformance on internal validation sets, with AUROC exceeding 0.95 for eighty\ndiagnoses. It also shows strong classification performance and generalization\nacross various diagnoses on external validation sets. When fine-tuned,\nECGFounder outperforms baseline models in demographic analysis, clinical event\ndetection, and cross-modality cardiac rhythm diagnosis. The trained model and\ndata will be publicly released upon publication through the bdsp.io. Our code\nis available at https://github.com/PKUDigitalHealth/ECGFounder",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Code: https://github.com/PKUDigitalHealth/ECGFounder",
    "pdf_url": "http://arxiv.org/pdf/2410.04133v3",
    "published_date": "2024-10-05 12:12:02 UTC",
    "updated_date": "2025-04-03 08:42:11 UTC"
  },
  {
    "arxiv_id": "2410.04118v2",
    "title": "Riemann Sum Optimization for Accurate Integrated Gradients Computation",
    "authors": [
      "Swadesh Swain",
      "Shree Singhi"
    ],
    "abstract": "Integrated Gradients (IG) is a widely used algorithm for attributing the\noutputs of a deep neural network to its input features. Due to the absence of\nclosed-form integrals for deep learning models, inaccurate Riemann Sum\napproximations are used to calculate IG. This often introduces undesirable\nerrors in the form of high levels of noise, leading to false insights in the\nmodel's decision-making process. We introduce a framework, RiemannOpt, that\nminimizes these errors by optimizing the sample point selection for the Riemann\nSum. Our algorithm is highly versatile and applicable to IG as well as its\nderivatives like Blur IG and Guided IG. RiemannOpt achieves up to 20%\nimprovement in Insertion Scores. Additionally, it enables its users to curtail\ncomputational costs by up to four folds, thereby making it highly functional\nfor constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Interpretable AI: Past, Present and Future Workshop at\n  NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.04118v2",
    "published_date": "2024-10-05 10:57:13 UTC",
    "updated_date": "2025-01-05 15:30:35 UTC"
  },
  {
    "arxiv_id": "2410.04114v1",
    "title": "Transport-Embedded Neural Architecture: Redefining the Landscape of physics aware neural models in fluid mechanics",
    "authors": [
      "Amirmahdi Jafari"
    ],
    "abstract": "This work introduces a new neural model which follows the transport equation\nby design. A physical problem, the Taylor-Green vortex, defined on a\nbi-periodic domain, is used as a benchmark to evaluate the performance of both\nthe standard physics-informed neural network and our model (transport-embedded\nneural network). Results exhibit that while the standard physics-informed\nneural network fails to predict the solution accurately and merely returns the\ninitial condition for the entire time span, our model successfully captures the\ntemporal changes in the physics, particularly for high Reynolds numbers of the\nflow. Additionally, the ability of our model to prevent false minima can pave\nthe way for addressing multiphysics problems, which are more prone to false\nminima, and help them accurately predict complex physics.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04114v1",
    "published_date": "2024-10-05 10:32:51 UTC",
    "updated_date": "2024-10-05 10:32:51 UTC"
  },
  {
    "arxiv_id": "2410.04108v2",
    "title": "Towards Scalable General Utility Reinforcement Learning: Occupancy Approximation, Sample Complexity and Global Optimality",
    "authors": [
      "Anas Barakat",
      "Souradip Chakraborty",
      "Peihong Yu",
      "Pratap Tokekar",
      "Amrit Singh Bedi"
    ],
    "abstract": "Reinforcement learning with general utilities has recently gained attention\nthanks to its ability to unify several problems, including imitation learning,\npure exploration, and safe reinforcement learning. However, prior work for\nsolving this general problem in a unified way has only focused on the tabular\nsetting. This is restrictive when considering larger state-action spaces\nbecause of the need to estimate occupancy measures during policy optimization.\nIn this work, we address this issue and propose to approximate occupancy\nmeasures within a function approximation class using maximum likelihood\nestimation (MLE). We propose a simple policy gradient algorithm where an actor\nupdates the policy parameters to maximize the general utility objective whereas\na critic approximates the occupancy measure using MLE. We provide a statistical\ncomplexity analysis showing that our occupancy measure estimation error only\nscales with the dimension of our function approximation class rather than the\nsize of the state action space. Under suitable assumptions, we establish first\norder stationarity and global optimality performance bounds for the proposed\nalgorithm for nonconcave and concave general utilities respectively. We\ncomplement our methodological and theoretical findings with promising empirical\nresults showing the scalability potential of our approach compared to existing\ntabular count-based approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "revised version",
    "pdf_url": "http://arxiv.org/pdf/2410.04108v2",
    "published_date": "2024-10-05 10:24:07 UTC",
    "updated_date": "2025-02-26 21:19:07 UTC"
  },
  {
    "arxiv_id": "2410.04098v1",
    "title": "The OCON model: an old but green solution for distributable supervised classification for acoustic monitoring in smart cities",
    "authors": [
      "Stefano Giacomelli",
      "Marco Giordano",
      "Claudia Rinaldi"
    ],
    "abstract": "This paper explores a structured application of the One-Class approach and\nthe One-Class-One-Network model for supervised classification tasks, focusing\non vowel phonemes classification and speakers recognition for the Automatic\nSpeech Recognition (ASR) domain. For our case-study, the ASR model runs on a\nproprietary sensing and lightning system, exploited to monitor acoustic and air\npollution on urban streets. We formalize combinations of pseudo-Neural\nArchitecture Search and Hyper-Parameters Tuning experiments, using an informed\ngrid-search methodology, to achieve classification accuracy comparable to\nnowadays most complex architectures, delving into the speaker recognition and\nenergy efficiency aspects. Despite its simplicity, our model proposal has a\nvery good chance to generalize the language and speaker genders context for\nwidespread applicability in computational constrained contexts, proved by\nrelevant statistical and performance metrics. Our experiments code is openly\naccessible on our GitHub.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "68T05, 68T07, 68T10, 68T30, 68T50",
      "C.2.4; C.2.5; C.2.6; C.3; B.8.2; C.4; D.2.8; D.2.13; H.3.1; I.2.4;\n  I.2.6; I.2.7; I.2.8; I.2.11; I.5.1; I.5.4; I.5.5; J.5; J.7; K.4.0"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at \"IEEE 5th International Symposium on the Internet of\n  Sounds, 30 Sep / 2 Oct 2024, Erlangen, Germany\"",
    "pdf_url": "http://arxiv.org/pdf/2410.04098v1",
    "published_date": "2024-10-05 09:47:54 UTC",
    "updated_date": "2024-10-05 09:47:54 UTC"
  },
  {
    "arxiv_id": "2410.04096v1",
    "title": "Sinc Kolmogorov-Arnold Network and Its Applications on Physics-informed Neural Networks",
    "authors": [
      "Tianchi Yu",
      "Jingwei Qiu",
      "Jiang Yang",
      "Ivan Oseledets"
    ],
    "abstract": "In this paper, we propose to use Sinc interpolation in the context of\nKolmogorov-Arnold Networks, neural networks with learnable activation\nfunctions, which recently gained attention as alternatives to multilayer\nperceptron. Many different function representations have already been tried,\nbut we show that Sinc interpolation proposes a viable alternative, since it is\nknown in numerical analysis to represent well both smooth functions and\nfunctions with singularities. This is important not only for function\napproximation but also for the solutions of partial differential equations with\nphysics-informed neural networks. Through a series of experiments, we show that\nSincKANs provide better results in almost all of the examples we have\nconsidered.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "cs.NE",
      "math.NA",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04096v1",
    "published_date": "2024-10-05 09:33:39 UTC",
    "updated_date": "2024-10-05 09:33:39 UTC"
  },
  {
    "arxiv_id": "2410.05320v1",
    "title": "The OCON model: an old but gold solution for distributable supervised classification",
    "authors": [
      "Stefano Giacomelli",
      "Marco Giordano",
      "Claudia Rinaldi"
    ],
    "abstract": "This paper introduces to a structured application of the One-Class approach\nand the One-Class-One-Network model for supervised classification tasks,\nspecifically addressing a vowel phonemes classification case study within the\nAutomatic Speech Recognition research field. Through pseudo-Neural Architecture\nSearch and Hyper-Parameters Tuning experiments conducted with an informed\ngrid-search methodology, we achieve classification accuracy comparable to\nnowadays complex architectures (90.0 - 93.7%). Despite its simplicity, our\nmodel prioritizes generalization of language context and distributed\napplicability, supported by relevant statistical and performance metrics. The\nexperiments code is openly available at our GitHub.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.LG",
      "cs.SD",
      "68T07, 68T09, 68T10, 68T50, 91F20",
      "I.2.7; I.2.11; I.5.1; I.5.2; I.5.5; J.5; E.4; D.2.7; D.2.13"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at \"2024 29th IEEE Symposium on Computers and Communications\n  (ISCC): workshop on Next-Generation Multimedia Services at the Edge:\n  Leveraging 5G and Beyond (NGMSE2024)\". arXiv admin note: text overlap with\n  arXiv:2410.04098",
    "pdf_url": "http://arxiv.org/pdf/2410.05320v1",
    "published_date": "2024-10-05 09:15:01 UTC",
    "updated_date": "2024-10-05 09:15:01 UTC"
  },
  {
    "arxiv_id": "2410.04087v1",
    "title": "GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization",
    "authors": [
      "Yangfan Ye",
      "Xiachong Feng",
      "Xiaocheng Feng",
      "Weitao Ma",
      "Libo Qin",
      "Dongliang Xu",
      "Qing Yang",
      "Hongtao Liu",
      "Bing Qin"
    ],
    "abstract": "News summarization in today's global scene can be daunting with its flood of\nmultilingual content and varied viewpoints from different sources. However,\ncurrent studies often neglect such real-world scenarios as they tend to focus\nsolely on either single-language or single-document tasks. To bridge this gap,\nwe aim to unify Multi-lingual, Cross-lingual and Multi-document Summarization\ninto a novel task, i.e., MCMS, which encapsulates the real-world requirements\nall-in-one. Nevertheless, the lack of a benchmark inhibits researchers from\nadequately studying this invaluable problem. To tackle this, we have\nmeticulously constructed the GLOBESUMM dataset by first collecting a wealth of\nmultilingual news reports and restructuring them into event-centric format.\nAdditionally, we introduce the method of protocol-guided prompting for\nhigh-quality and cost-effective reference annotation. In MCMS, we also\nhighlight the challenge of conflicts between news reports, in addition to the\nissues of redundancies and omissions, further enhancing the complexity of\nGLOBESUMM. Through extensive experimental analysis, we validate the quality of\nour dataset and elucidate the inherent challenges of the task. We firmly\nbelieve that GLOBESUMM, given its challenging nature, will greatly contribute\nto the multilingual communities and the evaluation of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 main conference, long paper",
    "pdf_url": "http://arxiv.org/pdf/2410.04087v1",
    "published_date": "2024-10-05 08:56:44 UTC",
    "updated_date": "2024-10-05 08:56:44 UTC"
  },
  {
    "arxiv_id": "2410.04084v1",
    "title": "Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to Overcome Medical Image Long-Tailed Class Imbalance",
    "authors": [
      "Pankhi Kashyap",
      "Pavni Tandon",
      "Sunny Gupta",
      "Abhishek Tiwari",
      "Ritwik Kulkarni",
      "Kshitij Sharad Jadhav"
    ],
    "abstract": "Long-tailed problems in healthcare emerge from data imbalance due to\nvariability in the prevalence and representation of different medical\nconditions, warranting the requirement of precise and dependable classification\nmethods. Traditional loss functions such as cross-entropy and binary\ncross-entropy are often inadequate due to their inability to address the\nimbalances between the classes with high representation and the classes with\nlow representation found in medical image datasets. We introduce a novel\npolynomial loss function based on Pade approximation, designed specifically to\novercome the challenges associated with long-tailed classification. This\napproach incorporates asymmetric sampling techniques to better classify\nunder-represented classes. We conducted extensive evaluations on three publicly\navailable medical datasets and a proprietary medical dataset. Our\nimplementation of the proposed loss function is open-sourced in the public\nrepository:https://github.com/ipankhi/ALPA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10; I.4.0; I.4.1; I.4.2; I.4.6; I.4.7; I.4.8; I.4.9; I.4.10;\n  I.2.10; I.5.1; I.5.2; I.5.4; J.2; I.2.6; I.2.11; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 1 figures. Accepted in The 35th British Machine Vision\n  Conference (BMVC24)",
    "pdf_url": "http://arxiv.org/pdf/2410.04084v1",
    "published_date": "2024-10-05 08:49:33 UTC",
    "updated_date": "2024-10-05 08:49:33 UTC"
  },
  {
    "arxiv_id": "2410.04081v3",
    "title": "Epsilon-VAE: Denoising as Visual Decoding",
    "authors": [
      "Long Zhao",
      "Sanghyun Woo",
      "Ziyu Wan",
      "Yandong Li",
      "Han Zhang",
      "Boqing Gong",
      "Hartwig Adam",
      "Xuhui Jia",
      "Ting Liu"
    ],
    "abstract": "In generative modeling, tokenization simplifies complex data into compact,\nstructured representations, creating a more efficient, learnable space. For\nhigh-dimensional visual data, it reduces redundancy and emphasizes key features\nfor high-quality generation. Current visual tokenization methods rely on a\ntraditional autoencoder framework, where the encoder compresses data into\nlatent representations, and the decoder reconstructs the original input. In\nthis work, we offer a new perspective by proposing denoising as decoding,\nshifting from single-step reconstruction to iterative refinement. Specifically,\nwe replace the decoder with a diffusion process that iteratively refines noise\nto recover the original image, guided by the latents provided by the encoder.\nWe evaluate our approach by assessing both reconstruction (rFID) and generation\nquality (FID), comparing it to state-of-the-art autoencoding approaches. By\nadopting iterative reconstruction through diffusion, our autoencoder, namely\n$\\epsilon$-VAE, achieves high reconstruction quality, which in turn enhances\ndownstream generation quality by 22% and provides 2.3$\\times$ inference\nspeedup. We hope this work offers new insights into integrating iterative\ngeneration and autoencoding for improved compression and generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint. v2: added comparisons to SD-VAE and more visual results",
    "pdf_url": "http://arxiv.org/pdf/2410.04081v3",
    "published_date": "2024-10-05 08:27:53 UTC",
    "updated_date": "2025-02-24 22:54:41 UTC"
  },
  {
    "arxiv_id": "2410.04074v1",
    "title": "On Eliciting Syntax from Language Models via Hashing",
    "authors": [
      "Yiran Wang",
      "Masao Utiyama"
    ],
    "abstract": "Unsupervised parsing, also known as grammar induction, aims to infer\nsyntactic structure from raw text. Recently, binary representation has\nexhibited remarkable information-preserving capabilities at both lexicon and\nsyntax levels. In this paper, we explore the possibility of leveraging this\ncapability to deduce parsing trees from raw text, relying solely on the\nimplicitly induced grammars within models. To achieve this, we upgrade the\nbit-level CKY from zero-order to first-order to encode the lexicon and syntax\nin a unified binary representation space, switch training from supervised to\nunsupervised under the contrastive hashing framework, and introduce a novel\nloss function to impose stronger yet balanced alignment signals. Our model\nshows competitive performance on various datasets, therefore, we claim that our\nmethod is effective and efficient enough to acquire high-quality parsing trees\nfrom pre-trained language models at a low cost.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP-2024",
    "pdf_url": "http://arxiv.org/pdf/2410.04074v1",
    "published_date": "2024-10-05 08:06:19 UTC",
    "updated_date": "2024-10-05 08:06:19 UTC"
  },
  {
    "arxiv_id": "2410.04072v2",
    "title": "MROSS: Multi-Round Region-based Optimization for Scene Sketching",
    "authors": [
      "Yiqi Liang",
      "Ying Liu",
      "Dandan Long",
      "Ruihui Li"
    ],
    "abstract": "Scene sketching is to convert a scene into a simplified, abstract\nrepresentation that captures the essential elements and composition of the\noriginal scene. It requires a semantic understanding of the scene and\nconsideration of different regions within the scene. Since scenes often contain\ndiverse visual information across various regions, such as foreground objects,\nbackground elements, and spatial divisions, dealing with these different\nregions poses unique difficulties. In this paper, we define a sketch as some\nsets of B\\'ezier curves because of their smooth and versatile characteristics.\nWe optimize different regions of input scene in multiple rounds. In each\noptimization round, the strokes sampled from the next region can seamlessly be\nintegrated into the sketch generated in the previous optimization round. We\npropose an additional stroke initialization method to ensure the integrity of\nthe scene and the convergence of optimization. A novel CLIP-based Semantic Loss\nand a VGG-based Feature Loss are utilized to guide our multi-round\noptimization. Extensive experimental results on the quality and quantity of the\ngenerated sketches confirm the effectiveness of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.04072v2",
    "published_date": "2024-10-05 08:04:26 UTC",
    "updated_date": "2025-04-15 11:44:00 UTC"
  },
  {
    "arxiv_id": "2410.04070v7",
    "title": "PAD: Personalized Alignment of LLMs at Decoding-Time",
    "authors": [
      "Ruizhe Chen",
      "Xiaotian Zhang",
      "Meng Luo",
      "Wenhao Chai",
      "Zuozhu Liu"
    ],
    "abstract": "Aligning with personalized preferences, which vary significantly across\ncultural, educational, and political differences, poses a significant challenge\ndue to the computational costs and data demands of traditional alignment\nmethods. In response, this paper presents Personalized Alignment at\nDecoding-time (PAD), a novel framework designed to align LLM outputs with\ndiverse personalized preferences during the inference phase, eliminating the\nneed for additional training. By introducing a unique personalized reward\nmodeling strategy, this framework decouples the text generation process from\npersonalized preferences, facilitating the generation of generalizable\ntoken-level personalized rewards. The PAD algorithm leverages these rewards to\nguide the decoding process, dynamically tailoring the base model's predictions\nto personalized preferences. Extensive experimental results demonstrate that\nPAD not only outperforms existing training-based alignment methods in terms of\naligning with diverse preferences but also shows significant generalizability\nto preferences unseen during training and scalability across different base\nmodels. This work advances the capability of LLMs to meet user needs in\nreal-time applications, presenting a substantial step forward in personalized\nLLM alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.04070v7",
    "published_date": "2024-10-05 08:00:55 UTC",
    "updated_date": "2025-03-13 13:37:57 UTC"
  },
  {
    "arxiv_id": "2410.04068v1",
    "title": "ECon: On the Detection and Resolution of Evidence Conflicts",
    "authors": [
      "Cheng Jiayang",
      "Chunkit Chan",
      "Qianqian Zhuang",
      "Lin Qiu",
      "Tianhang Zhang",
      "Tengxiao Liu",
      "Yangqiu Song",
      "Yue Zhang",
      "Pengfei Liu",
      "Zheng Zhang"
    ],
    "abstract": "The rise of large language models (LLMs) has significantly influenced the\nquality of information in decision-making systems, leading to the prevalence of\nAI-generated content and challenges in detecting misinformation and managing\nconflicting information, or \"inter-evidence conflicts.\" This study introduces a\nmethod for generating diverse, validated evidence conflicts to simulate\nreal-world misinformation scenarios. We evaluate conflict detection methods,\nincluding Natural Language Inference (NLI) models, factual consistency (FC)\nmodels, and LLMs, on these conflicts (RQ1) and analyze LLMs' conflict\nresolution behaviors (RQ2). Our key findings include: (1) NLI and LLM models\nexhibit high precision in detecting answer conflicts, though weaker models\nsuffer from low recall; (2) FC models struggle with lexically similar answer\nconflicts, while NLI and LLM models handle these better; and (3) stronger\nmodels like GPT-4 show robust performance, especially with nuanced conflicts.\nFor conflict resolution, LLMs often favor one piece of conflicting evidence\nwithout justification and rely on internal knowledge if they have prior\nbeliefs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2410.04068v1",
    "published_date": "2024-10-05 07:41:17 UTC",
    "updated_date": "2024-10-05 07:41:17 UTC"
  },
  {
    "arxiv_id": "2410.04064v2",
    "title": "Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback",
    "authors": [
      "Fatemeh Pesaran Zadeh",
      "Juyeon Kim",
      "Jin-Hwa Kim",
      "Gunhee Kim"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong capabilities across\nvarious language tasks, notably through instruction-tuning methods. However,\nLLMs face challenges in visualizing complex, real-world data through charts and\nplots. Firstly, existing datasets rarely cover a full range of chart types,\nsuch as 3D, volumetric, and gridded charts. Secondly, supervised fine-tuning\nmethods do not fully leverage the intricate relationships within rich datasets,\nincluding text, code, and figures. To address these challenges, we propose a\nhierarchical pipeline and a new dataset for chart generation. Our dataset,\nText2Chart31, includes 31 unique plot types referring to the Matplotlib\nlibrary, with 11.1K tuples of descriptions, code, data tables, and plots.\nMoreover, we introduce a reinforcement learning-based instruction tuning\ntechnique for chart generation tasks without requiring human feedback. Our\nexperiments show that this approach significantly enhances the model\nperformance, enabling smaller models to outperform larger open-source models\nand be comparable to state-of-the-art proprietary models in data visualization\ntasks. We make the code and dataset available at\nhttps://github.com/fatemehpesaran310/Text2Chart31.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP 2024 Main Oral. Code and dataset are released at\n  https://github.com/fatemehpesaran310/Text2Chart31",
    "pdf_url": "http://arxiv.org/pdf/2410.04064v2",
    "published_date": "2024-10-05 07:25:56 UTC",
    "updated_date": "2025-02-17 13:04:24 UTC"
  },
  {
    "arxiv_id": "2410.04061v3",
    "title": "Enhancing Graph Self-Supervised Learning with Graph Interplay",
    "authors": [
      "Xinjian Zhao",
      "Wei Pang",
      "Xiangru Jian",
      "Yaoyao Xu",
      "Chaolong Ying",
      "Tianshu Yu"
    ],
    "abstract": "Graph self-supervised learning (GSSL) has emerged as a compelling framework\nfor extracting informative representations from graph-structured data without\nextensive reliance on labeled inputs. In this study, we introduce Graph\nInterplay (GIP), an innovative and versatile approach that significantly\nenhances the performance equipped with various existing GSSL methods. To this\nend, GIP advocates direct graph-level communications by introducing random\ninter-graph edges within standard batches. Against GIP's simplicity, we further\ntheoretically show that \\textsc{GIP} essentially performs a principled manifold\nseparation via combining inter-graph message passing and GSSL, bringing about\nmore structured embedding manifolds and thus benefits a series of downstream\ntasks. Our empirical study demonstrates that GIP surpasses the performance of\nprevailing GSSL methods across multiple benchmarks by significant margins,\nhighlighting its potential as a breakthrough approach. Besides, GIP can be\nreadily integrated into a series of GSSL methods and consistently offers\nadditional performance gain. This advancement not only amplifies the capability\nof GSSL but also potentially sets the stage for a novel graph learning paradigm\nin a broader sense.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Due to potential implicit data leakage in our experimental setup,\n  where the pretraining dataset was ordered by default labels, we withdraw this\n  manuscript for further self-examination and rigorous validation",
    "pdf_url": "http://arxiv.org/pdf/2410.04061v3",
    "published_date": "2024-10-05 07:05:21 UTC",
    "updated_date": "2025-01-16 01:18:40 UTC"
  },
  {
    "arxiv_id": "2410.04060v3",
    "title": "LoRTA: Low Rank Tensor Adaptation of Large Language Models",
    "authors": [
      "Ignacio Hounie",
      "Charilaos Kanatsoulis",
      "Arnuv Tandon",
      "Alejandro Ribeiro"
    ],
    "abstract": "Low Rank Adaptation (LoRA) is a popular Parameter Efficient Fine Tuning\n(PEFT) method that effectively adapts large pre-trained models for downstream\ntasks. LoRA parameterizes model updates using low-rank matrices at each layer,\nsignificantly reducing the number of trainable parameters and, consequently,\nresource requirements during fine-tuning. However, the lower bound on the\nnumber of trainable parameters remains high due to the use of the low-rank\nmatrix model. Recent works have addressed this limitation by proposing low rank\ntensor parameterizations for model updates. However, they only exploit\nredundancy across layers, or tensorize individual matrices using ad-hoc schemes\nthat introduce additional hyperparameters. In this work, we propose a\nhigher-order Candecomp/Parafac (CP) decomposition, enabling a more compact and\nflexible representation compared to existing matrix and tensor based PEFT\nmethods. Our experiments on Natural Language Understanding, Instruction Tuning,\nPreference Optimization and Protein Folding benchmarks demonstrate that our\nmethod can achieve a reduction in the number of parameters while maintaining\ncomparable performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04060v3",
    "published_date": "2024-10-05 06:59:50 UTC",
    "updated_date": "2025-02-02 17:56:53 UTC"
  },
  {
    "arxiv_id": "2410.04054v2",
    "title": "Large Language Models can Achieve Social Balance",
    "authors": [
      "Pedro Cisneros-Velarde"
    ],
    "abstract": "Social balance is a well-established concept in sociology which dictates how\nindividual interactions can lead a population to become one faction of positive\ninteractions or be divided in two or more antagonistic factions. In this paper,\nwe consider a group of large language models (LLMs) and study how, after\ncontinuous interactions, they can achieve social balance. Across three\ndifferent LLM models, we find that achieving social balance depends on (i) the\ntype of interaction; (ii) whether agents consider homophily or influence from\ntheir peers; and (iii) the population size. We characterize how each model\nachieves social balance with different frequency, diversity of positive or\nnegative interactions, and interaction stability across conditions (i) to\n(iii). We show that models achieve different notions of social balance and\njustify their social dynamics differently. Remarkably, the largest model is not\nnecessarily more likely to achieve social balance with more frequency,\nstability, and diversity than the smaller ones.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA",
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04054v2",
    "published_date": "2024-10-05 06:23:28 UTC",
    "updated_date": "2025-03-15 01:10:55 UTC"
  },
  {
    "arxiv_id": "2410.04047v3",
    "title": "Multi-Step Time Series Inference Agent for Reasoning and Automated Task Execution",
    "authors": [
      "Wen Ye",
      "Yizhou Zhang",
      "Wei Yang",
      "Defu Cao",
      "Lumingyuan Tang",
      "Jie Cai",
      "Yan Liu"
    ],
    "abstract": "Time series analysis is crucial in real-world applications, yet traditional\nmethods focus on isolated tasks only, and recent studies on time series\nreasoning remain limited to simple, single-step inference constrained to\nnatural language answer. In this work, we propose a practical novel task:\nmulti-step time series inference that demands both compositional reasoning and\ncomputation precision of time series analysis. To address such challenge, we\npropose a simple but effective program-aided inference agent that leverages\nLLMs' reasoning ability to decompose complex tasks into structured execution\npipelines. By integrating in-context learning, self-correction, and\nprogram-aided execution, our proposed approach ensures accurate and\ninterpretable results. To benchmark performance, we introduce a new dataset and\na unified evaluation framework with task-specific success criteria. Experiments\nshow that our approach outperforms standalone general purpose LLMs in both\nbasic time series concept understanding as well as multi-step time series\ninference task, highlighting the importance of hybrid approaches that combine\nreasoning with computational precision.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04047v3",
    "published_date": "2024-10-05 06:04:19 UTC",
    "updated_date": "2025-02-12 00:23:36 UTC"
  },
  {
    "arxiv_id": "2410.05318v1",
    "title": "Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification",
    "authors": [
      "Zhenwen Liang",
      "Ye Liu",
      "Tong Niu",
      "Xiangliang Zhang",
      "Yingbo Zhou",
      "Semih Yavuz"
    ],
    "abstract": "Despite significant advancements in the general capability of large language\nmodels (LLMs), they continue to struggle with consistent and accurate\nreasoning, especially in complex tasks such as mathematical and code reasoning.\nOne key limitation is that LLMs are trained primarily on correct solutions,\nreducing their ability to detect and learn from errors, which hampers their\nability to reliably verify and rank outputs. To address this, we scale up the\ninference-time computation by generating multiple reasoning paths and employing\nverifiers to assess and rank the generated outputs by correctness. To\nfacilitate this, we introduce a comprehensive dataset consisting of correct and\nincorrect solutions for math and code tasks, generated by multiple LLMs. This\ndiverse set of solutions enables verifiers to more effectively distinguish and\nrank correct answers from erroneous outputs. The training methods for building\nverifiers were selected based on an extensive comparison of existing\napproaches. Moreover, to leverage the unique strengths of different reasoning\nstrategies, we propose a novel collaborative method integrating\nChain-of-Thought (CoT) and Program-of-Thought (PoT) solutions for verification.\nCoT provides a clear, step-by-step reasoning process that enhances\ninterpretability, while PoT, being executable, offers a precise and\nerror-sensitive validation mechanism. By taking both of their strengths, our\napproach significantly improves the accuracy and reliability of reasoning\nverification. Our verifiers, Math-Rev and Code-Rev, demonstrate substantial\nperformance gains to existing LLMs, achieving state-of-the-art results on\nbenchmarks such as GSM8k and MATH and even outperforming GPT-4o with\nQwen-72B-Instruct as the reasoner.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05318v1",
    "published_date": "2024-10-05 05:21:48 UTC",
    "updated_date": "2024-10-05 05:21:48 UTC"
  },
  {
    "arxiv_id": "2410.04039v3",
    "title": "BlockFound: Customized blockchain foundation model for anomaly detection",
    "authors": [
      "Jiahao Yu",
      "Xian Wu",
      "Hao Liu",
      "Wenbo Guo",
      "Xinyu Xing"
    ],
    "abstract": "We propose BlockFound, a customized foundation model for anomaly blockchain\ntransaction detection. Unlike existing methods that rely on rule-based systems\nor directly apply off-the-shelf large language models, BlockFound introduces a\nseries of customized designs to model the unique data structure of blockchain\ntransactions. First, a blockchain transaction is multi-modal, containing\nblockchain-specific tokens, texts, and numbers. We design a modularized\ntokenizer to handle these multi-modal inputs, balancing the information across\ndifferent modalities. Second, we design a customized mask language learning\nmechanism for pretraining with RoPE embedding and FlashAttention for handling\nlonger sequences. After training the foundation model, we further design a\nnovel detection method for anomaly detection. Extensive evaluations on Ethereum\nand Solana transactions demonstrate BlockFound's exceptional capability in\nanomaly detection while maintaining a low false positive rate. Remarkably,\nBlockFound is the only method that successfully detects anomalous transactions\non Solana with high accuracy, whereas all other approaches achieved very low or\nzero detection recall scores. This work not only provides new foundation models\nfor blockchain but also sets a new benchmark for applying LLMs in blockchain\ndata.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04039v3",
    "published_date": "2024-10-05 05:11:34 UTC",
    "updated_date": "2024-10-18 04:05:06 UTC"
  },
  {
    "arxiv_id": "2410.04038v2",
    "title": "Gamified crowd-sourcing of high-quality data for visual fine-tuning",
    "authors": [
      "Shashank Yadav",
      "Rohan Tomar",
      "Garvit Jain",
      "Chirag Ahooja",
      "Shubham Chaudhary",
      "Charles Elkan"
    ],
    "abstract": "This paper introduces Gamified Adversarial Prompting (GAP), a framework that\ncrowd-sources high-quality data for visual instruction tuning of large\nmultimodal models. GAP transforms the data collection process into an engaging\ngame, incentivizing players to provide fine-grained, challenging questions and\nanswers that target gaps in the model's knowledge. Our contributions include\n(1) an approach to capture question-answer pairs from humans that directly\naddress weaknesses in a model's knowledge, (2) a method for evaluating and\nrewarding players that successfully incentivizes them to provide high-quality\nsubmissions, and (3) a scalable, gamified platform that succeeds in collecting\nthis data from over 50,000 participants in just a few weeks. Our implementation\nof GAP has significantly improved the accuracy of a small multimodal model,\nnamely MiniCPM-Llama3-V-2.5-8B, increasing its GPT score from 0.147 to 0.477 on\nour dataset, approaching the benchmark set by the much larger GPT-4V. Moreover,\nwe demonstrate that the data generated using MiniCPM-Llama3-V-2.5-8B also\nenhances its performance across other benchmarks, and exhibits cross-model\nbenefits. Specifically, the same data improves the performance of QWEN2-VL-2B\nand QWEN2-VL-7B on the same multiple benchmarks.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04038v2",
    "published_date": "2024-10-05 05:10:29 UTC",
    "updated_date": "2024-10-08 02:37:41 UTC"
  },
  {
    "arxiv_id": "2410.04029v1",
    "title": "SyllableLM: Learning Coarse Semantic Units for Speech Language Models",
    "authors": [
      "Alan Baade",
      "Puyuan Peng",
      "David Harwath"
    ],
    "abstract": "Language models require tokenized inputs. However, tokenization strategies\nfor continuous data like audio and vision are often based on simple heuristics\nsuch as fixed sized convolutions or discrete clustering, which do not\nnecessarily align with the semantic structure of the data. For speech in\nparticular, the high resolution of waveforms (16,000 samples/second or more)\npresents a significant challenge as speech-based language models have had to\nuse several times more tokens per word than text-based language models. In this\nwork, we introduce a controllable self-supervised technique to merge speech\nrepresentations into coarser syllable-like units while still preserving\nsemantic information. We do this by 1) extracting noisy boundaries through\nanalyzing correlations in pretrained encoder losses and 2) iteratively\nimproving model representations with a novel distillation technique. Our method\nproduces controllable-rate semantic units at as low as 5Hz and 60bps and\nachieves SotA in syllabic segmentation and clustering. Using these coarse\ntokens, we successfully train SyllableLM, a Speech Language Model (SpeechLM)\nthat matches or outperforms current SotA SpeechLMs on a range of spoken\nlanguage modeling tasks. SyllableLM also achieves significant improvements in\nefficiency with a 30x reduction in training compute and a 4x wall-clock\ninference speedup.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.04029v1",
    "published_date": "2024-10-05 04:29:55 UTC",
    "updated_date": "2024-10-05 04:29:55 UTC"
  },
  {
    "arxiv_id": "2410.04025v1",
    "title": "IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback",
    "authors": [
      "Kevin Pu",
      "K. J. Kevin Feng",
      "Tovi Grossman",
      "Tom Hope",
      "Bhavana Dalvi Mishra",
      "Matt Latzke",
      "Jonathan Bragg",
      "Joseph Chee Chang",
      "Pao Siangliulue"
    ],
    "abstract": "Research ideation involves broad exploring and deep refining ideas. Both\nrequire deep engagement with literature. Existing tools focus primarily on idea\nbroad generation, yet offer little support for iterative specification,\nrefinement, and evaluation needed to further develop initial ideas. To bridge\nthis gap, we introduce IdeaSynth, a research idea development system that uses\nLLMs to provide literature-grounded feedback for articulating research\nproblems, solutions, evaluations, and contributions. IdeaSynth represents these\nidea facets as nodes on a canvas, and allow researchers to iteratively refine\nthem by creating and exploring variations and composing them. Our lab study\n(N=20) showed that participants, while using IdeaSynth, explored more\nalternative ideas and expanded initial ideas with more details compared to a\nstrong LLM-based baseline. Our deployment study (N=7) demonstrated that\nparticipants effectively used IdeaSynth for real-world research projects at\nvarious ideation stages from developing initial ideas to revising framings of\nmature manuscripts, highlighting the possibilities to adopt IdeaSynth in\nresearcher's workflows.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04025v1",
    "published_date": "2024-10-05 04:06:07 UTC",
    "updated_date": "2024-10-05 04:06:07 UTC"
  },
  {
    "arxiv_id": "2410.04022v2",
    "title": "Efficient Large-Scale Urban Parking Prediction: Graph Coarsening Based on Real-Time Parking Service Capability",
    "authors": [
      "Yixuan Wang",
      "Zhenwu Chen",
      "Kangshuai Zhang",
      "Yunduan Cui",
      "Yang Yang",
      "Lei Peng"
    ],
    "abstract": "With the sharp increase in the number of vehicles, the issue of parking\ndifficulties has emerged as an urgent challenge that many cities need to\naddress promptly. In the task of predicting large-scale urban parking data,\nexisting research often lacks effective deep learning models and strategies. To\ntackle this challenge, this paper proposes an innovative framework for\npredicting large-scale urban parking graphs leveraging real-time service\ncapabilities, aimed at improving the accuracy and efficiency of parking\npredictions. Specifically, we introduce a graph attention mechanism that\nassesses the real-time service capabilities of parking lots to construct a\ndynamic parking graph that accurately reflects real preferences in parking\nbehavior. To effectively handle large-scale parking data, this study combines\ngraph coarsening techniques with temporal convolutional autoencoders to achieve\nunified dimension reduction of the complex urban parking graph structure and\nfeatures. Subsequently, we use a spatio-temporal graph convolutional model to\nmake predictions based on the coarsened graph, and a pre-trained\nautoencoder-decoder module restores the predicted results to their original\ndata dimensions, completing the task. Our methodology has been rigorously\ntested on a real dataset from parking lots in Shenzhen. The experimental\nresults indicate that compared to traditional parking prediction models, our\nframework achieves improvements of 46.8\\% and 30.5\\% in accuracy and\nefficiency, respectively. Remarkably, with the expansion of the graph's scale,\nour framework's advantages become even more apparent, showcasing its\nsubstantial potential for solving complex urban parking dilemmas in practical\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04022v2",
    "published_date": "2024-10-05 03:54:25 UTC",
    "updated_date": "2025-01-20 03:44:43 UTC"
  },
  {
    "arxiv_id": "2410.05317v4",
    "title": "Accelerating Diffusion Transformers with Token-wise Feature Caching",
    "authors": [
      "Chang Zou",
      "Xuyang Liu",
      "Ting Liu",
      "Siteng Huang",
      "Linfeng Zhang"
    ],
    "abstract": "Diffusion transformers have shown significant effectiveness in both image and\nvideo synthesis at the expense of huge computation costs. To address this\nproblem, feature caching methods have been introduced to accelerate diffusion\ntransformers by caching the features in previous timesteps and reusing them in\nthe following timesteps. However, previous caching methods ignore that\ndifferent tokens exhibit different sensitivities to feature caching, and\nfeature caching on some tokens may lead to 10$\\times$ more destruction to the\noverall generation quality compared with other tokens. In this paper, we\nintroduce token-wise feature caching, allowing us to adaptively select the most\nsuitable tokens for caching, and further enable us to apply different caching\nratios to neural layers in different types and depths. Extensive experiments on\nPixArt-$\\alpha$, OpenSora, and DiT demonstrate our effectiveness in both image\nand video generation with no requirements for training. For instance,\n2.36$\\times$ and 1.93$\\times$ acceleration are achieved on OpenSora and\nPixArt-$\\alpha$ with almost no drop in generation quality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ToCa is honored to be accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.05317v4",
    "published_date": "2024-10-05 03:47:06 UTC",
    "updated_date": "2025-02-19 10:39:58 UTC"
  },
  {
    "arxiv_id": "2410.05315v2",
    "title": "PalmBench: A Comprehensive Benchmark of Compressed Large Language Models on Mobile Platforms",
    "authors": [
      "Yilong Li",
      "Jingyu Liu",
      "Hao Zhang",
      "M Badri Narayanan",
      "Utkarsh Sharma",
      "Shuai Zhang",
      "Pan Hu",
      "Yijing Zeng",
      "Jayaram Raghuram",
      "Suman Banerjee"
    ],
    "abstract": "Deploying large language models (LLMs) locally on mobile devices is\nadvantageous in scenarios where transmitting data to remote cloud servers is\neither undesirable due to privacy concerns or impractical due to network\nconnection. Recent advancements (MLC, 2023a; Gerganov, 2023) have facilitated\nthe local deployment of LLMs. However, local deployment also presents\nchallenges, particularly in balancing quality (generative performance),\nlatency, and throughput within the hardware constraints of mobile devices. In\nthis paper, we introduce our lightweight, all-in-one automated benchmarking\nframework that allows users to evaluate LLMs on mobile devices. We provide a\ncomprehensive benchmark of various popular LLMs with different quantization\nconfigurations (both weights and activations) across multiple mobile platforms\nwith varying hardware capabilities. Unlike traditional benchmarks that assess\nfull-scale models on high-end GPU clusters, we focus on evaluating resource\nefficiency (memory and power consumption) and harmful output for compressed\nmodels on mobile devices. Our key observations include i) differences in energy\nefficiency and throughput across mobile platforms; ii) the impact of\nquantization on memory usage, GPU execution time, and power consumption; and\niii) accuracy and performance degradation of quantized models compared to their\nnon-quantized counterparts; and iv) the frequency of hallucinations and toxic\ncontent generated by compressed LLMs on mobile devices.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.05315v2",
    "published_date": "2024-10-05 03:37:07 UTC",
    "updated_date": "2025-01-09 00:11:59 UTC"
  },
  {
    "arxiv_id": "2410.04012v2",
    "title": "JAM: A Comprehensive Model for Age Estimation, Verification, and Comparability",
    "authors": [
      "François David",
      "Alexey A. Novikov",
      "Ruslan Parkhomenko",
      "Artem Voronin",
      "Alix Melchy"
    ],
    "abstract": "This paper introduces a comprehensive model for age estimation, verification,\nand comparability, offering a comprehensive solution for a wide range of\napplications. It employs advanced learning techniques to understand age\ndistribution and uses confidence scores to create probabilistic age ranges,\nenhancing its ability to handle ambiguous cases. The model has been tested on\nboth proprietary and public datasets and compared against one of the\ntop-performing models in the field. Additionally, it has recently been\nevaluated by NIST as part of the FATE challenge, achieving top places in many\ncategories.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04012v2",
    "published_date": "2024-10-05 03:02:47 UTC",
    "updated_date": "2025-01-27 19:02:05 UTC"
  },
  {
    "arxiv_id": "2410.04010v1",
    "title": "Hyperbolic Fine-tuning for Large Language Models",
    "authors": [
      "Menglin Yang",
      "Aosong Feng",
      "Bo Xiong",
      "Jihong Liu",
      "Irwin King",
      "Rex Ying"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance on\nvarious tasks. However, it remains an open question whether the default\nEuclidean space is the most suitable choice for embedding tokens in LLMs. In\nthis study, we first investigate the non-Euclidean characteristics of LLMs. Our\nfindings reveal that token frequency follows a power-law distribution, with\nhigh-frequency tokens clustering near the origin and low-frequency tokens\npositioned farther away. Additionally, token embeddings exhibit a high degree\nof hyperbolicity, indicating a latent tree-like structure in the embedding\nspace. Building on the observation, we propose to efficiently fine-tune LLMs in\nhyperbolic space to better exploit the underlying complex structures. However,\nwe found that this fine-tuning in hyperbolic space cannot be achieved with\nnaive application of exponential and logarithmic maps, when the embedding and\nweight matrices both reside in Euclidean space. To address this technique\nissue, we introduce a new method called hyperbolic low-rank efficient\nfine-tuning, HypLoRA, that performs low-rank adaptation directly on the\nhyperbolic manifold, avoiding the cancellation effect caused by the exponential\nand logarithmic maps, thus preserving the hyperbolic modeling capabilities.\nThrough extensive experiments, we demonstrate that HypLoRA significantly\nenhances the performance of LLMs on reasoning tasks, particularly for complex\nreasoning problems. In particular, HypLoRA improves the performance in the\ncomplex AQuA dataset by up to 13.0%, showcasing its effectiveness in handling\ncomplex reasoning challenges",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "The preliminary work was accepted for the ICML 2024 LLM Cognition\n  Workshop, and this version includes new investigations, analyses,\n  experiments, and results",
    "pdf_url": "http://arxiv.org/pdf/2410.04010v1",
    "published_date": "2024-10-05 02:58:25 UTC",
    "updated_date": "2024-10-05 02:58:25 UTC"
  },
  {
    "arxiv_id": "2410.04002v1",
    "title": "Take It Easy: Label-Adaptive Self-Rationalization for Fact Verification and Explanation Generation",
    "authors": [
      "Jing Yang",
      "Anderson Rocha"
    ],
    "abstract": "Computational methods to aid journalists in the task often require adapting a\nmodel to specific domains and generating explanations. However, most automated\nfact-checking methods rely on three-class datasets, which do not accurately\nreflect real-world misinformation. Moreover, fact-checking explanations are\noften generated based on text summarization of evidence, failing to address the\nrelationship between the claim and the evidence. To address these issues, we\nextend the self-rationalization method--typically used in natural language\ninference (NLI) tasks--to fact verification. We propose a label-adaptive\nlearning approach: first, we fine-tune a model to learn veracity prediction\nwith annotated labels (step-1 model). Then, we fine-tune the step-1 model again\nto learn self-rationalization, using the same data and additional annotated\nexplanations. Our results show that our label-adaptive approach improves\nveracity prediction by more than ten percentage points (Macro F1) on both the\nPubHealth and AVeriTec datasets, outperforming the GPT-4 model. Furthermore, to\naddress the high cost of explanation annotation, we generated 64 synthetic\nexplanations from three large language models: GPT-4-turbo, GPT-3.5-turbo, and\nLlama-3-8B and few-shot fine-tune our step-1 model. The few-shot synthetic\nexplanation fine-tuned model performed comparably to the fully fine-tuned\nself-rationalization model, demonstrating the potential of low-budget learning\nwith synthetic data. Our label-adaptive self-rationalization approach presents\na promising direction for future research on real-world explainable\nfact-checking with different labeling schemes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper accepted in the 16th IEEE INTERNATIONAL WORKSHOP ON INFORMATION\n  FORENSICS AND SECURITY (WIFS) 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.04002v1",
    "published_date": "2024-10-05 02:19:49 UTC",
    "updated_date": "2024-10-05 02:19:49 UTC"
  },
  {
    "arxiv_id": "2410.04001v1",
    "title": "FastLRNR and Sparse Physics Informed Backpropagation",
    "authors": [
      "Woojin Cho",
      "Kookjin Lee",
      "Noseong Park",
      "Donsub Rim",
      "Gerrit Welper"
    ],
    "abstract": "We introduce Sparse Physics Informed Backpropagation (SPInProp), a new class\nof methods for accelerating backpropagation for a specialized neural network\narchitecture called Low Rank Neural Representation (LRNR). The approach\nexploits the low rank structure within LRNR and constructs a reduced neural\nnetwork approximation that is much smaller in size. We call the smaller network\nFastLRNR. We show that backpropagation of FastLRNR can be substituted for that\nof LRNR, enabling a significant reduction in complexity. We apply SPInProp to a\nphysics informed neural networks framework and demonstrate how the solution of\nparametrized partial differential equations is accelerated.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07, 65D25, 65M22"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.04001v1",
    "published_date": "2024-10-05 02:19:28 UTC",
    "updated_date": "2024-10-05 02:19:28 UTC"
  },
  {
    "arxiv_id": "2410.09081v1",
    "title": "Semantic Environment Atlas for Object-Goal Navigation",
    "authors": [
      "Nuri Kim",
      "Jeongho Park",
      "Mineui Hong",
      "Songhwai Oh"
    ],
    "abstract": "In this paper, we introduce the Semantic Environment Atlas (SEA), a novel\nmapping approach designed to enhance visual navigation capabilities of embodied\nagents. The SEA utilizes semantic graph maps that intricately delineate the\nrelationships between places and objects, thereby enriching the navigational\ncontext. These maps are constructed from image observations and capture visual\nlandmarks as sparsely encoded nodes within the environment. The SEA integrates\nmultiple semantic maps from various environments, retaining a memory of\nplace-object relationships, which proves invaluable for tasks such as visual\nlocalization and navigation. We developed navigation frameworks that\neffectively leverage the SEA, and we evaluated these frameworks through visual\nlocalization and object-goal navigation tasks. Our SEA-based localization\nframework significantly outperforms existing methods, accurately identifying\nlocations from single query images. Experimental results in Habitat scenarios\nshow that our method not only achieves a success rate of 39.0%, an improvement\nof 12.4% over the current state-of-the-art, but also maintains robustness under\nnoisy odometry and actuation conditions, all while keeping computational costs\nlow.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.09081v1",
    "published_date": "2024-10-05 00:37:15 UTC",
    "updated_date": "2024-10-05 00:37:15 UTC"
  },
  {
    "arxiv_id": "2410.16283v2",
    "title": "Understanding the Effect of Algorithm Transparency of Model Explanations in Text-to-SQL Semantic Parsing",
    "authors": [
      "Daking Rai",
      "Rydia R. Weiland",
      "Kayla Margaret Gabriella Herrera",
      "Tyler H. Shaw",
      "Ziyu Yao"
    ],
    "abstract": "Explaining the decisions of AI has become vital for fostering appropriate\nuser trust in these systems. This paper investigates explanations for a\nstructured prediction task called ``text-to-SQL Semantic Parsing'', which\ntranslates a natural language question into a structured query language (SQL)\nprogram. In this task setting, we designed three levels of model explanation,\neach exposing a different amount of the model's decision-making details (called\n``algorithm transparency''), and investigated how different model explanations\ncould potentially yield different impacts on the user experience. Our study\nwith $\\sim$100 participants shows that (1) the low-/high-transparency\nexplanations often lead to less/more user reliance on the model decisions,\nwhereas the medium-transparency explanations strike a good balance. We also\nshow that (2) only the medium-transparency participant group was able to engage\nfurther in the interaction and exhibit increasing performance over time, and\nthat (3) they showed the least changes in trust before and after the study.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "I.3.6"
    ],
    "primary_category": "cs.IR",
    "comment": "15 pages, 18 figure, Preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.16283v2",
    "published_date": "2024-10-05 00:13:33 UTC",
    "updated_date": "2024-11-24 14:36:20 UTC"
  }
]