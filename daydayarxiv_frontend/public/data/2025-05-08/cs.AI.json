{
  "date": "2025-05-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-05-08的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的研究热点依旧围绕大型语言模型 (LLM) 的能力边界探索、效率提升与对齐展开，同时多模态理解与生成、强化学习在复杂任务中的应用也备受关注。几篇关于提升LLM推理能力、优化生成模型训练以及反思AI伦理的论文尤为引人注目。此外，视觉模型、机器人技术和AI在特定领域的应用（如医学、化学）也贡献了许多有趣的工作。\n\n---\n\n**重点关注与热门研究**\n\n1.  **Flow-GRPO: 通过在线强化学习训练流匹配模型 (Flow-GRPO: Training Flow Matching Models via Online RL)**\n    *   Flow-GRPO 首次将在线强化学习 (RL) 集成到流匹配模型 (flow matching models) 的训练中。通过 ODE-SDE 转换实现 RL 探索，并采用去噪缩减策略提高采样效率。实验表明，该方法在文本到图像任务中表现出色，显著提升了复杂构图（如物体数量、空间关系）和视觉文本渲染的准确性，例如将 SD3.5 在 GenEval 上的准确率从 63% 提升到 95%，且未出现奖励黑客问题。\n\n2.\n    **StreamBridge: 将你的离线视频大语言模型转变为主动式流媒体助手 (StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant)**\n    *   StreamBridge 提出一个简单有效的框架，将现有的离线视频大语言模型 (Video-LLMs) 无缝转换为流式处理模型。它通过内存缓冲区和轮次衰减压缩策略解决多轮实时理解问题，并通过解耦的轻量级激活模型实现主动响应。为支持该框架，论文还构建了 Stream-IT 数据集。实验表明，StreamBridge 显著提升了离线 Video-LLMs 在流式视频理解任务上的能力。\n\n3.  **ComPO: 通过比较预言机实现偏好对齐 (ComPO: Preference Alignment via Comparison Oracles)**\n    *   针对现有直接对齐方法存在的冗余和似然位移问题，ComPO 提出一种基于比较预言机 (comparison oracles) 的新偏好对齐方法。该方法为基础方案提供了收敛性保证，并通过启发式方法改进，实验证明其在使用有噪声的偏好对对齐 LLM (如 Mistral-7B, Llama-3-8B, Gemma-2-9B) 方面的灵活性和兼容性，特别强调了针对不同似然边际的偏好对设计专门方法的重要性。\n\n4.  **推理模型并不总是说出它们所想 (Reasoning Models Don't Always Say What They Think)**\n    *   这篇论文探讨了思维链 (CoT) 是否忠实地代表了模型的实际推理过程。研究发现，即使模型在推理中使用了提示中的线索，CoT 也常常不能完全揭示（揭示率常低于20%）。基于结果的强化学习可以初步改善忠实度，但很快会停滞。当强化学习导致模型更频繁地使用提示（奖励黑客）时，其表达这些提示的倾向性并未增加。这表明 CoT 监控有潜力发现不期望的行为，但不足以完全排除它们，尤其是在测试时难以捕捉罕见灾难性行为。\n\n5.  **通过弹性推理实现可扩展的思维链 (Scalable Chain of Thoughts via Elastic Reasoning)**\n    *   大型推理模型 (LRM) 通过生成扩展的思维链 (CoT) 在复杂任务上取得进展，但其不受控制的输出长度给实际部署带来了挑战。Elastic Reasoning 框架将推理分为“思考”和“解决方案”两个阶段，并独立分配预算。它在测试时优先保证解决方案的完整性，并通过预算约束的 rollout 策略训练模型适应被截断的思考过程。实验表明，该方法在严格预算下表现稳健，训练成本更低，甚至在无约束设置下也能产生更简洁高效的推理。\n\n6.  **TokLIP: 将视觉符号与CLIP结合用于多模态理解与生成 (TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation)**\n    *   针对现有基于符号的多模态统一工作训练开销大、理解能力有限的问题，TokLIP 提出一种视觉符号器 (visual tokenizer)。它通过语义化矢量量化 (VQ) 符号并结合 CLIP 级别的语义来增强理解能力，同时支持使用标准 VQ 符号进行端到端的多模态自回归训练。TokLIP 将低级离散 VQ 符号器与基于 ViT 的符号编码器集成，以捕获高级连续语义，实现了出色的数据效率。\n\n---\n\n**大型语言模型 (LLM) 与智能体**\n\n7.  **通过测试时扩展实现跨语言推理 (Crosslingual Reasoning through Test-Time Scaling)**\n    *   研究了以英语为中心的推理语言模型 (RLM) 在长思维链 (CoT) 微调后，其推理能力在多语言间的泛化程度。发现通过扩展推理计算，RLM 在多种语言（包括低资源语言）上的数学推理能力得到提升。RLM 的 CoT 通常是英文的，但会引用非英文输入进行思考。研究还发现控制 CoT 语言的有效策略，模型在高资源语言中推理效果更好。但从 STEM 到文化常识的领域外推理泛化能力较差。\n\n8.  **EcoAgent: 面向移动自动化的边缘-云协同多智能体高效框架 (EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation)**\n    *   为解决云端移动智能体延迟高、成本高，而边缘端微调模型能力受限的问题，EcoAgent 提出了一种边缘-云协同的多智能体框架。该框架包含云端规划智能体和两个边缘智能体（执行智能体和观察智能体）。观察智能体使用预理解模块压缩屏幕图像，规划智能体在失败时通过反思模块重新规划。实验表明，EcoAgent 在保持高任务成功率的同时显著减少了 MLLM 的 token 消耗。\n\n9.  **软件开发生命周期视角：CodeLLM 和智能体基准测试综述 (Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents)**\n    *   这篇综述回顾了现有的 CodeLLM 和智能体基准测试，分析了来自461篇相关论文的181个基准，覆盖了软件开发生命周期 (SDLC) 的不同阶段。发现约60%的基准集中在软件开发阶段，而需求工程和软件设计阶段的关注度较低（分别为5%和3%）。Python 是最主要的编程语言。论文指出了当前研究的挑战并提出了未来方向。\n\n10. **通过自信息重写攻击揭示文本水印的弱点 (Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks)**\n    *   文本水印通过控制 LLM 采样过程嵌入统计信号。本文揭示了当前水印算法将水印嵌入高熵词元以保证文本质量的设计可能被攻击者利用。论文提出了一种通用的高效释义攻击方法——自信息重写攻击 (SIRA)，通过计算每个词元的自信息来识别潜在的模式词元并进行针对性攻击。实验表明 SIRA 在七种近期水印方法上实现了近100%的攻击成功率，成本极低，且无需访问水印算法或被水印的 LLM。\n\n11. **MARK: 知识的记忆增强精炼 (MARK: Memory Augmented Refinement of Knowledge)**\n    *   为解决 LLM 在不重新微调的情况下难以适应不断发展的领域知识的问题，MARK 框架利用结构化的精炼记忆使 LLM 能够持续学习。MARK 通过专门的智能体运作：残留精炼记忆智能体、用户问题精炼记忆智能体和 LLM 响应精炼记忆智能体，它们分析存储的记忆、检测模式、解决矛盾并提高响应准确性。该框架旨在减少幻觉，适应特定领域知识，并改进个性化 AI 助手。\n\n12. **思维链词元是计算机程序变量 (Chain-of-Thought Tokens are Computer Program Variables)**\n    *   通过对多位数乘法和动态规划这两个组合任务的实证研究，论文探讨了思维链 (CoT) 词元在 LLM 中的作用。研究发现，仅保留存储中间结果的词元就能达到与完整 CoT 相当的性能。将中间结果存储为替代的潜在形式也不会影响模型性能。对 CoT 中的某些值进行随机干预，后续 CoT 词元和最终答案会相应改变。这些发现表明 CoT 词元可能像计算机程序中的变量一样运作，但也存在潜在的捷径和计算复杂性限制等缺点。\n\n13. **Enigme: 用于评估语言模型推理能力的生成式文本谜题 (Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models)**\n    *   本文认为需要考虑 Transformer 解码器模型的架构约束来理解其推理能力的局限性。通过分析其潜在变量结构，可以设计出探测其推理能力边界的任务。论文介绍了 enigme，一个用于生成基于文本的谜题的开源库，这些谜题可用于训练和评估 Transformer 解码器模型及未来 AI 架构的推理技能。\n\n---\n\n**计算机视觉与多模态**\n\n14. **FG-CLIP: 细粒度视觉与文本对齐 (FG-CLIP: Fine-Grained Visual and Textual Alignment)**\n    *   针对 CLIP 在细粒度理解方面的不足，FG-CLIP 提出三点创新：利用大型多模态模型生成16亿长描述-图像对以捕获全局语义细节；构建包含1200万图像和4000万区域特定边界框的高质量数据集，与详细描述对齐；并加入1000万细粒度难负样本以提高模型区分细微语义差异的能力。实验表明 FG-CLIP 在细粒度理解、开放词汇目标检测等任务上优于基线。\n\n15. **高斯飞行时间：动态辐射场中间接优化深度 (Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields)**\n    *   提出一种使用原始传感器样本从单目连续波飞行时间 (C-ToF) 相机重建动态场景的方法。该方法在精度上与神经体方法相当或更好，但速度快100倍。针对 C-ToF 辐射场重建中深度未直接测量的问题，以及快速基于基元（如3D高斯溅射）的场景表示优化脆弱的问题，论文在优化中加入了两个启发式方法来提高高斯表示的场景几何精度。\n\n16. **StabStitch++: 具有时空双向扭曲的无监督在线视频拼接 (StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps)**\n    *   针对视频拼接中由不平滑的连续扭曲引起的“扭曲抖动”问题，StabStitch++ 提出一个新的视频拼接框架，同时实现空间拼接和时间稳定性的无监督学习。它设计了一个可微的双向分解模块来解耦单应性变换，并将其融入空间扭曲。通过整合空间和时间扭曲推导出拼接轨迹的数学表达式，并提出扭曲平滑模型以生成稳定的拼接视频。\n\n17. **直接从傅里叶叠层显微镜测量数据进行图像分类，无需重建 (Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction)**\n    *   傅里叶叠层显微镜 (FPM) 能够实现高分辨率、大视场成像，在医学细胞分类等领域有价值。但从大量测量数据重建高分辨率图像计算成本高。本文研究了直接从 FPM 测量数据进行图像内容分类，而无需先进行重建。结果表明，卷积神经网络 (CNN) 可以从测量序列中提取有意义信息，性能显著优于单张带限图像分类，且效率远高于重建高分辨率图像。\n\n18. **T2VTextBench: 用于视频生成模型中文本控制能力的人工评估基准 (T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video Generation Models)**\n    *   文本到视频生成在保真度和指令遵循方面取得了进展，但精确渲染屏幕文本（如字幕、公式）的能力仍有待测试。T2VTextBench 是首个专门评估文本到视频模型中屏幕文本保真度和时间一致性的人工评估基准。通过集成复杂文本字符串和动态场景变化的提示，测试了十个 SOTA 系统，发现大多数系统难以生成清晰、一致的文本。\n\n19. **SpatialPrompting: 基于关键帧的零样本空间推理与现有货架多模态大语言模型 (SpatialPrompting: Keyframe-driven Zero-Shot Spatial Reasoning with Off-the-Shelf Multimodal Large Language Models)**\n    *   SpatialPrompting 提出一个新框架，利用现有多模态大语言模型的涌现推理能力实现三维环境中的零样本空间推理。该框架采用关键帧驱动的提示生成策略，使用视觉语言相似性、马氏距离等指标从图像序列中选择关键帧，并结合相机姿态数据来抽象空间关系和推断复杂三维结构，在 ScanQA 和 SQA3D 等基准上取得了 SOTA 零样本性能。\n\n20. **用于人脸深度伪造检测的跨分支正交性以提高泛化能力 (Cross-Branch Orthogonality for Improved Generalization in Face Deepfake Detection)**\n    *   针对现有深度伪造检测器依赖特定伪造痕迹导致泛化能力不足的问题，本文提出一种新策略，利用从粗到细的空间信息、语义信息及其交互，同时确保特征独特性并减少冗余。引入一种新的基于特征正交性的解耦策略，以确保分支级别和跨分支特征解耦，从而在不增加特征空间复杂性或损害泛化能力的情况下集成多个特征向量。\n\n---\n\n**强化学习与机器人**\n\n21. **利用状态建模和对抗性探索增强协作式多智能体强化学习 (Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration)**\n    *   针对分布式部分可观测环境中无通信能力的多智能体协作学习挑战，本文提出一种新的状态建模框架。智能体推断非可观测状态的有意义的信念表示，并在此基础上提出 MARL SMPE 算法。智能体通过将信念纳入策略网络并采用对抗性探索策略来增强其在部分可观测性下的策略判别能力。\n\n22. **ADD: 基于对抗性微分判别器的物理运动模仿 (ADD: Physics-Based Motion Imitation with Adversarial Differential Discriminators)**\n    *   针对多目标优化问题（如基于强化学习的物理模拟角色运动跟踪）中手动调整权重耗时费力的问题，本文提出一种新颖的对抗性多目标优化技术。所提出的对抗性微分判别器 (adversarial differential discriminator) 仅接收单个正样本，仍能有效指导优化过程，使角色能够精确复制各种杂技和敏捷行为，而无需手动调整奖励函数。\n\n23. **D-CODA: 用于协调双臂数据增强的扩散模型 (D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation)**\n    *   针对双臂操作学习维度高、协调难的问题，D-CODA 提出一种针对眼在手 (eye-in-hand) 双臂模仿学习的离线数据增强方法。该方法训练一个扩散模型来为双臂合成新颖的、视角一致的手腕相机图像，同时生成关节空间动作标签，并通过约束优化确保增强状态的有效性和可行性。\n\n---\n\n**AI伦理、安全与可解释性**\n\n24. **社会与技术进步如同缝制一床不断扩大、不断变化、补丁斑驳、色彩斑斓的被子 (Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt)**\n    *   这篇立场文件探讨了 AI 系统决策的伦理问题。作者担心“一刀切”的对齐方案会忽视持久的道德多样性，引发抵制，侵蚀信任。论文对“理性趋同公理”（即理性智能体在理想条件下最终会就单一伦理达成一致）提出质疑，并提出“适当性框架” (appropriateness framework) 作为替代方案。该框架基于冲突理论、文化进化等多学科，将持续分歧视为常态，并提出四个设计原则：情境基础、社区定制、持续适应和多中心治理。\n\n25. **ChainMarks: 用加密链保护 DNN 水印 (ChainMarks: Securing DNN Watermark with Cryptographic Chain)**\n    *   针对现有 DNN 水印方案易受水印去除和模糊攻击的问题，ChainMarks 提出一种安全的 DNN 水印方案。它通过在触发器输入中引入加密链来生成安全鲁棒的水印，并利用两阶段蒙特卡洛方法确定水印存在性。触发器输入通过对密钥重复应用哈希函数生成，目标标签由模型所有者的数字签名生成。实验表明 ChainMarks 具有更高的鲁棒性和安全性。\n\n26. **立场：AI 会议同行评审危机需要作者反馈和审稿人奖励 (Position: The AI Conference Peer Review Crisis Demands Author Feedback and Reviewer Rewards)**\n    *   针对 AI 会议论文提交量激增带来的同行评审质量和审稿人责任问题，这篇立场文件主张将传统的单向评审系统转变为双向反馈循环。作者可以评估评审质量，审稿人可以获得正式认证，从而建立一个促进可持续、高质量同行评审系统的问责框架。具体提出了双阶段双向评审系统和系统化的审稿人奖励机制。\n\n27. **立场：认知人工智能对于机器学习模型知道何时它们不知道至关重要 (Position: Epistemic Artificial Intelligence is Essential for Machine Learning Models to Know When They Do Not Know)**\n    *   尽管 AI 取得了巨大成就，但在处理不确定性和泛化到训练数据之外的能力方面仍存在差距。本文认为，AI 模型在面对不熟悉或对抗性数据时难以做出稳健预测。传统机器学习方法过分强调数据拟合和领域自适应。这篇立场文件主张向认知人工智能 (epistemic artificial intelligence) 范式转变，强调模型不仅要从已知中学习，还要从其无知中学习，通过识别和管理不确定性来提高 AI 系统的韧性和鲁棒性。\n\n---\n\n**机器学习理论与方法**\n\n28. **通过分层安全抽象解释推进神经网络验证 (Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation)**\n    *   传统深度神经网络 (DNN) 形式化验证 (FV) 方法受限于安全属性的二元编码。本文引入“抽象 DNN 验证”问题，验证非安全输出的层次结构，提供更细致的安全性分析。通过利用抽象解释和推理输出可达集，该方法能够在 FV 过程中评估多个安全级别，计算成本与传统二元验证相当甚至更低。\n\n29. **基于概念的无监督域自适应 (Concept-Based Unsupervised Domain Adaptation)**\n    *   概念瓶颈模型 (CBM) 通过人类可理解的概念解释预测，但通常假设训练和测试数据同分布。为解决领域漂移问题，本文提出基于概念的无监督域自适应 (CUDA) 框架。CUDA 利用对抗训练对齐跨域概念表示，引入松弛阈值允许概念分布的微小领域特定差异，直接在目标域推断概念，并将概念学习整合到传统域自适应 (DA) 中，提高了可解释性并建立了新的 DA 基准。\n\n30. **随机变分传播：局部、可扩展且高效的反向传播替代方案 (Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation)**\n    *   反向传播 (BP) 依赖全局梯度同步，限制了可扩展性并带来内存开销。SVP 提出一种可扩展的替代方案，将训练重构为分层变分推断。SVP 将层激活视为潜变量并优化局部证据下界 (ELBO)，实现独立的局部更新同时保持全局一致性。为防止层间表示崩溃，SVP 通过固定随机矩阵将激活投影到低维空间。SVP 在多种架构和数据集上取得了与 BP 相当的精度，内存使用减少高达4倍，并显著提高了可扩展性。\n\n31. **通过激活子空间理解加法的上下文学习 (Understanding In-context Learning of Addition via Activation Subspaces)**\n    *   研究语言模型如何通过上下文学习执行加法任务。发现 Llama-3-8B 在此任务上表现良好，并通过一种新的优化方法将其少样本学习能力定位到三个注意力头。提取的信号位于一个六维子空间中，其中四维跟踪个位数，两维跟踪整体幅度。还研究了这些注意力头如何从少样本示例中提取信息，识别出一种自我校正机制。\n\n32. **Graffe: 通过扩散概率模型进行图表示学习 (Graffe: Graph Representation Learning via Diffusion Probabilistic Models)**\n    *   Graffe 是一种用于图表示学习的自监督扩散模型。它包含一个图编码器，将源图提炼为紧凑表示，该表示作为条件指导扩散解码器的去噪过程。理论上证明了去噪目标隐式最大化数据与其表示之间的条件互信息。实验表明，Graffe 在节点和图分类任务的线性探测设置下取得了有竞争力的结果。\n\n33. **重新思考上下文学习中的不变性 (Rethinking Invariance in In-context Learning)**\n    *   上下文学习 (ICL) 对上下文示例的顺序敏感。为解决此问题，本文确定了不变 ICL 算法设计中的两个关键要素：信息不泄露和上下文相互依赖。基于此，提出了不变 ICL (InvICL) 方法，旨在实现 ICL 的不变性同时确保这两个属性。实验表明 InvICL 在大多数基准数据集上优于先前模型。\n\n34. **有限宽度多层神经网络的精确梯度下降训练动态 (Precise gradient descent training dynamics for finite-width multi-layer neural networks)**\n    *   本文首次对通用多层神经网络在典型单指数回归模型下的梯度下降迭代进行了精确的分布刻画，处于“有限宽度比例机制”下（样本量和特征维度成比例增长，网络宽度和深度有界）。该非渐近状态演化理论捕捉了第一层权重的 高斯波动和更深层权重的集中现象，对非高斯特征也有效。\n\n---\n\n**特定领域应用**\n\n35. **对话式流程模型重设计 (Conversational Process Model Redesign)**\n    *   探讨使用 LLM 以迭代和有效的方式支持领域专家创建和重新设计流程模型的可行性。提出的对话式流程模型重设计 (CPD) 方法接收流程模型和用户以自然语言提出的重设计请求。LLM 用于识别文献中的流程变更模式，重新表述变更请求以与已识别模式的预期措辞对齐，然后将变更的含义应用于流程模型。\n\n36. **TransProQA: 基于专业问答的 LLM 文学翻译评估指标 (TransProQA: an LLM-based literary Translation evaluation metric with Professional Question Answering)**\n    *   针对现有评估指标优先考虑机械准确性而非艺术表达的问题，TransProQA 提出一种新的、无参考的、基于 LLM 的问答 (QA) 框架，专为文学翻译评估设计。它独特地整合了专业文学翻译家和研究人员的见解，关注文学质量评估中的关键要素。实验表明 TransProQA 显著优于当前指标。\n\n37. **ChemRxivQuest: 从 ChemRxiv 预印本中提取的化学问答数据库 (ChemRxivQuest: A Curated Chemistry Question-Answer Database Extracted from ChemRxiv Preprints)**\n    *   为支持化学领域自然语言处理 (NLP) 的发展，ChemRxivQuest 构建了一个包含970个高质量问答对的精选数据集，这些数据来源于155篇 ChemRxiv 预印本，涵盖17个化学子领域。每个问答对都明确链接到其源文本段落。该数据集强调概念性、机理性、应用性和实验性问题。\n\n38. **眼科基础模型在临床显著性年龄相关性黄斑变性检测中的基准测试 (Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection)**\n    *   研究了在自然图像或眼科数据上预训练的基础模型在视网膜成像中的优势。通过在7个数字眼底图像 (DFI) 数据集（共7万张图像）上对6个自监督学习 (SSL) 预训练的 ViT 进行基准测试，用于中晚期年龄相关性黄斑变性 (AMD) 识别。结果显示，在自然图像上预训练的 iBOT 实现了最高的分布外泛化能力，优于领域特定模型。\n\n39. **PlaceIt3D: 真实3D场景中语言引导的对象放置 (PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes)**\n    *   引入了语言引导的真实3D场景对象放置新任务。模型接收3D场景点云、3D资产和描述放置位置的文本提示，任务是找到一个尊重提示的有效放置方案。为此，论文提出了新的基准、评估协议、训练数据集以及首个基线方法。\n\n40. **Foam-Agent: 迈向自动化智能 CFD 工作流 (Foam-Agent: Towards Automated Intelligent CFD Workflows)**\n    *   计算流体动力学 (CFD) 需要大量专业知识和手动配置。Foam-Agent 是一个多智能体框架，可根据自然语言输入自动执行基于 OpenFOAM 的复杂 CFD 仿真工作流。其创新包括分层多索引检索系统、依赖感知的配置文件生成系统和迭代错误校正机制。在110个仿真任务数据集上的评估显示，Foam-Agent 实现了83.6%的成功率。\n\n---\n\n**快速浏览**\n\n*   **CART-ELC: 通过穷举搜索进行斜向决策树归纳 (CART-ELC: Oblique Decision Tree Induction via Exhaustive Search)**: 提出 CART-ELC 算法，通过对受限超平面集进行穷举搜索来归纳斜向决策树，旨在提高分类性能并生成更简洁的树。\n*   **基于多模态数据和深度机器学习的疼痛评估框架 (A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods)**: 博士论文摘要，旨在开发用于自动疼痛评估的创新计算方法，考虑人口统计学等因素，并设计适用于不同场景的单模态和多模态评估流程。\n*   **脉冲神经网络在线测试时自适应的阈值调制 (Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks)**: 提出一种低功耗、神经形态芯片友好的在线测试时自适应框架 TM (Threshold Modulation)，通过神经元动力学启发的归一化动态调整发放阈值，以增强 SNN 在分布漂移下的泛化能力。\n*   **高保真晶粒长大建模：利用深度学习进行快速计算 (High-fidelity Grain Growth Modeling: Leveraging Deep Learning for Fast Computations)**: 提出一个结合卷积 LSTM 和自编码器的机器学习框架，用于高效预测晶粒长大演化，速度比传统方法快89倍，同时保持高保真度。\n*   **用于高分辨率无人机和卫星影像多尺度建筑物分割的特征增强深度网络 (Feature-Augmented Deep Networks for Multiscale Building Segmentation in High-Resolution UAV and Satellite Imagery)**: 提出一个综合深度学习框架，使用 RGB 航空和卫星影像进行多尺度建筑物分割。通过引入 PCA、VDVI 等二次表征作为特征增强输入，并采用 Res-U-Net 架构和优化的训练策略，提高了分割准确性。\n*   **绘制用户对视觉语言模型的信任图：研究概况、挑战与展望 (Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects)**: 这篇综述回顾了用户-VLM 交互中信任动态的研究，通过一个多学科分类法，并结合潜在 VLM 用户研讨会的见解，为未来 VLM 信任研究提出了初步要求。\n*   **T-T: 用于基于标注的方面情感三元组提取的表格 Transformer (T-T: Table Transformer for Tagging-based Aspect Sentiment Triplet Extraction)**: 提出一种新颖的 Table-Transformer (T-T) 用于基于标注的方面情感三元组提取 (ASTE) 任务。引入条纹注意力机制和循环移位策略来解决表格序列过长和局部注意力交互不公平的问题。\n*   **将 CASH 应用于老虎机：AutoML 的 Max K-臂问题 (Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning)**: 提出 MaxUCB，一种 max K-臂老虎机方法，用于权衡探索不同模型类别和进行超参数优化，专为 AutoML 中组合算法选择和超参数优化 (CASH) 问题的轻尾有界奖励分布设计。\n*   **激励感知机器学习；鲁棒性、公平性、改进与因果关系 (Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality)**: 这篇文献综述探讨了激励感知机器学习领域，其中个体可以策略性地修改其输入以影响结果，并从鲁棒性、公平性和改进/因果关系三个角度对研究进行分类。\n*   **LAPSO: 学习增强型电力系统运行的统一优化视图 (LAPSO: A Unified Optimization View for Learning-Augmented Power System Operations)**: 提出一个学习增强型电力系统运行 (LAPSO) 的整体框架。采用原生优化视角，旨在打破预测、运行和控制等任务之间的时间孤岛，并在训练和推理阶段统一机器学习和基于模型的优化目标。\n*   **Biomed-DPT: 用于生物医学视觉语言模型的双模态提示调整 (Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models)**: 提出 Biomed-DPT，一种知识增强的双模态提示调整技术，用于在少样本场景下将预训练的视觉语言模型 (VLM) 适应于生物医学图像分类任务。它设计了文本双提示和视觉软提示。\n*   **用基于激活的剪枝算子指导进化自编码器训练 (Guiding Evolutionary AutoEncoder Training with Activation-Based Pruning Operators)**: 探索使用进化计算进行神经网络剪枝的新方法，专注于同时剪枝自编码器的编码器和解码器。引入了两个使用层激活指导权重剪枝的新变异算子。\n*   **AI 智能体成功率是否存在半衰期？ (Is there a half-life for the success rates of AI agents?)**: 基于 Kwa 等人 (2025) 的实证工作，表明在其研究工程任务套件中，AI 智能体在较长持续时间任务上的性能可以用一个简单的数学模型解释——人类完成任务每分钟的失败率恒定，这意味着成功率随任务长度指数下降。\n*   **多智能体具身AI：进展与未来方向 (Multi-agent Embodied AI: Advances and Future Directions)**: 这篇综述回顾了多智能体具身 AI 的研究现状，分析了关键贡献，并确定了挑战和未来方向，旨在填补该领域全面综述的空白，促进其进一步发展。\n*   **具有关系和时间知识的序列分类神经符号框架 (A Neuro-Symbolic Framework for Sequence Classification with Relational and Temporal Knowledge)**: 探讨在知识驱动的序列分类问题中利用随时间变化并涵盖时间维度的背景知识。实验评估了多阶段神经符号和纯神经架构，并在新引入的基准框架上进行。\n*   **超越低秩分解：高效设备端学习的捷径方法 (Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning)**: 针对设备端学习的内存和计算限制，提出一种新的快捷方法作为低秩分解方法的替代方案，以解决反向传播中激活内存瓶颈问题。实验表明该方法能显著减少激活内存使用和训练 FLOPs。\n*   **潮汕话-自然场景：首个带正字法标注的自然场景潮汕话数据集 (Teochew-Wild: The First In-the-wild Teochew Dataset with Orthographic Annotations)**: 报告了潮汕话方言语音语料库 Teochew-Wild 的构建。该语料库包含18.9小时来自多位说话人的自然场景潮汕话语音数据，覆盖正式和口语表达，并带有精确的正字法和拼音标注。\n*   **多语言推文的图文关系预测 (Image-Text Relation Prediction for Multilingual Tweets)**: 探讨多语言视觉语言模型如何处理不同语言中图文关系预测任务，并构建了一个专门的、平衡的基准数据集，包含拉脱维亚语 Twitter帖子及其人工翻译的英语版本。\n*   **基于大型语言模型的多智能体系统声誉系统以避免公地悲剧 (A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons)**: 提出 RepuNet，一个动态的双层声誉框架，用于缓解生成式多智能体系统 (MAS) 中的“公地悲剧”问题。该框架模拟智能体级别的声誉动态和系统级别的网络演化，促进和维持 MAS 中的合作。\n*   **生成可靠的临床试验合成数据：超参数优化和领域约束的作用 (Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints)**: 系统评估了四种超参数优化 (HPO) 策略在八种生成模型上生成合成临床数据的效果。结果表明 HPO 能提高合成数据质量，但仅靠 HPO 不足以确保临床有效性，需要结合领域知识进行预处理和后处理。\n*   **用于连续认证的自由文本键盘动力学的基于智能体的建模方法 (An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication)**: 使用基于智能体的模型 (ABM) 模拟不同打字配置文件在机械键盘和薄膜键盘上的行为，研究行为生物识别技术在连续认证中的效果。结果显示随机森林在键盘内用户识别方面表现良好，但跨键盘泛化能力差。\n*   **链接预测中的结构对齐 (Structural Alignment in Link Prediction)**: 博士论文，从图结构优先的角度重新分析知识图谱 (KG) 和链接预测，提出结构对齐假说，认为链接预测可以被理解和建模为一个结构性任务，并探讨了其在跨 KG 迁移学习中的应用。\n*   **抑郁症预测的公平不确定性量化 (Fair Uncertainty Quantification for Depression Prediction)**: 针对深度学习抑郁症预测中可靠性和算法公平性问题，研究了不确定性量化 (UQ) 的算法公平性（机会均等覆盖 EOC 公平性），并提出公平不确定性量化 (FUQ) 方法。FUQ 通过基于群体的分析和保形预测来实现可靠和公平的抑郁症预测。\n*   **语言状态空间中认知控制的信念过滤 (Belief Filtering for Epistemic Control in Linguistic State Space)**: 在语义流形框架内，将信念过滤作为人工智能体认知控制的一种机制，用于调节表示为语言表达式的内部认知状态。信念过滤器作为内容感知操作作用于认知转换过程中的自然语言片段。\n*   **物理辅助和拓扑感知的深度学习天气预测 (Physics-Assisted and Topology-Informed Deep Learning for Weather Prediction)**: 提出 PASSAT 模型，将天气演化归因于平流过程和地球-大气相互作用，并考虑地球表面拓扑结构。PASSAT 在球面流形上数值求解平流方程和纳维-斯托克斯方程，利用球面图神经网络捕捉地球-大气相互作用。\n*   **一个面向高等教育语义检索的开源双损失嵌入模型 (An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education)**: 提出了两个针对教育问答（特别是课程大纲）微调的开源嵌入模型。通过手动管理和 LLM 辅助生成构建了一个包含3197个句子对的合成数据集。评估了使用 MultipleNegativesRankingLoss (MNRL) 的基线模型和结合 MNRL 与 CosineSimilarityLoss 的双损失模型。\n*   **用于图像对齐的自回归变换 (Auto-regressive transformation for image alignment)**: 提出自回归变换 (ART) 方法，在一个自回归框架内迭代估计从粗到细的变换。利用分层多尺度特征，网络在每个尺度使用随机采样点优化变换，并通过交叉注意力层的指导关注关键区域，以应对特征稀疏、大尺度差异等挑战。\n*   **ConCISE: 逐步高效推理中的置信度引导压缩 (ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning)**: 针对大型推理模型 (LRM) 思维链 (CoT) 输出冗余问题，从置信度引导的视角解释冗余反思的出现，并提出 ConCISE 框架。通过在推理过程中增强模型置信度来简化推理链，包括置信度注入和提前停止机制。\n*   **GroverGPT-2: 通过思维链推理和量子原生符号化模拟 Grover 算法 (GroverGPT-2: Simulating Grover's Algorithm via Chain-of-Thought Reasoning and Quantum-Native Tokenization)**: 提出 GroverGPT-2，一种基于 LLM 的方法，使用思维链 (CoT) 推理和量子原生符号化来模拟 Grover 算法。该方法直接从量子电路表示进行模拟，并产生结构化、可解释的输出，证明了 LLM 等经典模型捕捉量子算法结构的能力。\n*   **从损失景观中学习：通过自适应锐度感知梯度对齐实现可泛化的混合精度量化 (Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via Adaptive Sharpness-Aware Gradient Aligning)**: 为解决混合精度量化 (MPQ) 在大规模数据集上搜索量化策略计算成本高的问题，提出一种新方法：先在小数据集上搜索策略，然后泛化到大规模数据集。采用锐度感知最小化、隐式梯度方向对齐和自适应扰动半径等技术。\n*   **联邦学习在信息物理系统中的应用：综合综述 (Federated Learning for Cyber Physical Systems: A Comprehensive Survey)**: 全面分析了联邦学习 (FL) 在信息物理系统 (CPS) 中的最新进展，包括应用领域、系统拓扑和算法。讨论了 FL 和 CPS 的进展及其集成，并与 FL 在物联网 (IoT) 中的应用进行了比较。\n*   **QBR: 一种基于问题库的面向公众的细粒度法律知识检索方法 (QBR: A Question-Bank-Based Approach to Fine-Grained Legal Knowledge Retrieval for the General Public)**: 提出 QBR 方法，利用问题库 (QB) 作为弥合普通公众与专业法律知识之间差距的媒介。QB 用于派生训练样本以增强文档中知识单元的嵌入，从而实现有效的细粒度知识检索。\n*   **基于人工智能和视觉的纳米无人机在部分已知环境中的自主导航 (AI and Vision based Autonomous Navigation of Nano-Drones in Partially-Known Environments)**: 提出一种新颖的、基于人工智能和视觉的反应式规划方法，用于在集成传感、计算和通信范式下实现障碍物规避。通过将导航任务分为两部分（边缘端深度学习目标检测器和板载规划算法）来应对纳米无人机的资源限制。\n*   **具有两个中介变量的因果概率分解 (Decomposition of Probabilities of Causation with Two Mediators)**: 研究了包含两个中介变量时，将总的必要性和充分性概率 (PNS) 分解为沿不同因果路径的路径特定 PNS。定义了用于分解的路径特定 PNS，并提供了识别定理。\n*   **因果效应的矩 (Moments of Causal Effects)**: 提供了因果效应的矩和乘积矩的定义、识别定理和界限，以分析其分布和关系，超越了传统仅关注平均因果效应的评估方法。\n\n---\n\n希望这份 TLDR 快报能帮助您快速了解 arXiv 的最新动态！",
  "papers": [
    {
      "arxiv_id": "2505.05470v1",
      "title": "Flow-GRPO: Training Flow Matching Models via Online RL",
      "title_zh": "Flow-GRPO：通过在线强化学习训练 Flow Matching 模型\n",
      "authors": [
        "Jie Liu",
        "Gongye Liu",
        "Jiajun Liang",
        "Yangguang Li",
        "Jiaheng Liu",
        "Xintao Wang",
        "Pengfei Wan",
        "Di Zhang",
        "Wanli Ouyang"
      ],
      "abstract": "We propose Flow-GRPO, the first method integrating online reinforcement\nlearning (RL) into flow matching models. Our approach uses two key strategies:\n(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary\nDifferential Equation (ODE) into an equivalent Stochastic Differential Equation\n(SDE) that matches the original model's marginal distribution at all timesteps,\nenabling statistical sampling for RL exploration; and (2) a Denoising Reduction\nstrategy that reduces training denoising steps while retaining the original\ninference timestep number, significantly improving sampling efficiency without\nperformance degradation. Empirically, Flow-GRPO is effective across multiple\ntext-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly\nperfect object counts, spatial relations, and fine-grained attributes, boosting\nGenEval accuracy from $63\\%$ to $95\\%$. In visual text rendering, its accuracy\nimproves from $59\\%$ to $92\\%$, significantly enhancing text generation.\nFlow-GRPO also achieves substantial gains in human preference alignment.\nNotably, little to no reward hacking occurred, meaning rewards did not increase\nat the cost of image quality or diversity, and both remained stable in our\nexperiments.",
      "tldr_zh": "该论文提出了Flow-GRPO，一种将在线强化学习(RL)集成到Flow Matching模型中的新方法。该方法利用ODE-to-SDE转换，将确定性常微分方程(ODE)转化为等价的随机微分方程(SDE)，从而实现RL探索的统计抽样。同时，采用降噪减少策略(Denoising Reduction)减少训练降噪步骤，提高采样效率。实验表明，Flow-GRPO在多个文本到图像任务中有效，尤其在复杂构图、视觉文本渲染和人类偏好对齐方面取得了显著提升，且未观察到reward hacking现象。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/yifan123/flow_grpo",
      "pdf_url": "http://arxiv.org/pdf/2505.05470v1",
      "published_date": "2025-05-08 17:58:45 UTC",
      "updated_date": "2025-05-08 17:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:07:39.538330"
    },
    {
      "arxiv_id": "2505.05467v1",
      "title": "StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant",
      "title_zh": "StreamBridge：将您的离线视频大语言模型转化为主动流式助手\n",
      "authors": [
        "Haibo Wang",
        "Bo Feng",
        "Zhengfeng Lai",
        "Mingze Xu",
        "Shiyu Li",
        "Weifeng Ge",
        "Afshin Dehghan",
        "Meng Cao",
        "Ping Huang"
      ],
      "abstract": "We present StreamBridge, a simple yet effective framework that seamlessly\ntransforms offline Video-LLMs into streaming-capable models. It addresses two\nfundamental challenges in adapting existing models into online scenarios: (1)\nlimited capability for multi-turn real-time understanding, and (2) lack of\nproactive response mechanisms. Specifically, StreamBridge incorporates (1) a\nmemory buffer combined with a round-decayed compression strategy, supporting\nlong-context multi-turn interactions, and (2) a decoupled, lightweight\nactivation model that can be effortlessly integrated into existing Video-LLMs,\nenabling continuous proactive responses. To further support StreamBridge, we\nconstruct Stream-IT, a large-scale dataset tailored for streaming video\nunderstanding, featuring interleaved video-text sequences and diverse\ninstruction formats. Extensive experiments show that StreamBridge significantly\nimproves the streaming understanding capabilities of offline Video-LLMs across\nvarious tasks, outperforming even proprietary models such as GPT-4o and Gemini\n1.5 Pro. Simultaneously, it achieves competitive or superior performance on\nstandard video understanding benchmarks.",
      "tldr_zh": "StreamBridge是一个框架，可以将离线Video-LLM转化为流式处理模型，解决其在实时多轮理解和主动响应机制上的不足。它包含一个带有衰减压缩策略的记忆缓冲区，用于支持长上下文多轮交互，以及一个解耦的轻量级激活模型，用于实现连续的主动响应。为了支持StreamBridge，作者构建了一个大规模数据集Stream-IT，专门用于流式视频理解。实验表明，StreamBridge显著提高了离线Video-LLM的流式理解能力，并在各种任务中优于GPT-4o和Gemini 1.5 Pro等模型，同时在标准视频理解基准测试中也取得了有竞争力的性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05467v1",
      "published_date": "2025-05-08 17:57:40 UTC",
      "updated_date": "2025-05-08 17:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:07:51.619420"
    },
    {
      "arxiv_id": "2505.05465v1",
      "title": "ComPO: Preference Alignment via Comparison Oracles",
      "title_zh": "ComPO：通过比较 Oracle 实现偏好对齐\n",
      "authors": [
        "Peter Chen",
        "Xi Chen",
        "Wotao Yin",
        "Tianyi Lin"
      ],
      "abstract": "Direct alignment methods are increasingly used for aligning large language\nmodels (LLMs) with human preferences. However, these methods suffer from the\nissues of verbosity and likelihood displacement, which can be driven by the\nnoisy preference pairs that induce similar likelihood for preferred and\ndispreferred responses. The contributions of this paper are two-fold. First, we\npropose a new preference alignment method based on comparison oracles and\nprovide the convergence guarantee for its basic scheme. Second, we improve our\nmethod using some heuristics and conduct the experiments to demonstrate the\nflexibility and compatibility of practical scheme in improving the performance\nof LLMs using noisy preference pairs. Evaluations are conducted across multiple\nbase and instruction-tuned models (Mistral-7B, Llama-3-8B and Gemma-2-9B) with\nbenchmarks (AlpacaEval 2, MT-Bench and Arena-Hard). Experimental results show\nthe effectiveness of our method as an alternative to addressing the limitations\nof existing direct alignment methods. A highlight of our work is that we\nevidence the importance of designing specialized methods for preference pairs\nwith distinct likelihood margin, which complements the recent findings in\n\\citet{Razin-2025-Unintentional}.",
      "tldr_zh": "该论文提出了一种新的偏好对齐方法ComPO，它基于比较预言机(comparison oracles)，旨在解决直接对齐方法中由于噪声偏好对导致相似的可能性而产生的冗长和可能性位移问题。ComPO方法通过理论分析保证了收敛性，并通过启发式方法改进，实验证明了其在利用噪声偏好对提高LLM性能方面的灵活性和兼容性。在Mistral-7B、Llama-3-8B和Gemma-2-9B等模型上的实验结果表明，ComPO作为现有直接对齐方法的替代方案是有效的，并强调了为具有不同可能性裕度的偏好对设计专门方法的重要性。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.05465v1",
      "published_date": "2025-05-08 17:56:57 UTC",
      "updated_date": "2025-05-08 17:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:08:03.693093"
    },
    {
      "arxiv_id": "2505.05453v1",
      "title": "Conversational Process Model Redesign",
      "title_zh": "会话式流程模型重设计\n",
      "authors": [
        "Nataliia Klievtsova",
        "Timotheus Kampik",
        "Juergen Mangler",
        "Stefanie Rinderle-Ma"
      ],
      "abstract": "With the recent success of large language models (LLMs), the idea of\nAI-augmented Business Process Management systems is becoming more feasible. One\nof their essential characteristics is the ability to be conversationally\nactionable, allowing humans to interact with the LLM effectively to perform\ncrucial process life cycle tasks such as process model design and redesign.\nHowever, most current research focuses on single-prompt execution and\nevaluation of results, rather than on continuous interaction between the user\nand the LLM. In this work, we aim to explore the feasibility of using LLMs to\nempower domain experts in the creation and redesign of process models in an\niterative and effective way. The proposed conversational process model redesign\n(CPD) approach receives as input a process model and a redesign request by the\nuser in natural language. Instead of just letting the LLM make changes, the LLM\nis employed to (a) identify process change patterns from literature, (b)\nre-phrase the change request to be aligned with an expected wording for the\nidentified pattern (i.e., the meaning), and then to (c) apply the meaning of\nthe change to the process model. This multi-step approach allows for\nexplainable and reproducible changes. In order to ensure the feasibility of the\nCPD approach, and to find out how well the patterns from literature can be\nhandled by the LLM, we performed an extensive evaluation. The results show that\nsome patterns are hard to understand by LLMs and by users. Within the scope of\nthe study, we demonstrated that users need support to describe the changes\nclearly. Overall the evaluation shows that the LLMs can handle most changes\nwell according to a set of completeness and correctness criteria.",
      "tldr_zh": "本文提出了一种对话式流程模型重设计(CPD)方法，旨在利用大型语言模型(LLMs)赋能领域专家，以迭代和有效的方式创建和重设计流程模型。该方法接收流程模型和自然语言的重设计请求作为输入，通过LLM识别流程变更模式，并将请求重述为与识别的模式对齐的预期措辞，最后将变更的含义应用于流程模型。这种多步骤方法实现了可解释和可重现的变更。通过广泛的评估，验证了CPD方法的可行性，并发现LLM和用户都难以理解某些模式，用户需要支持才能清晰地描述变更。总体而言，评估表明LLM可以根据完整性和正确性标准很好地处理大多数变更。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05453v1",
      "published_date": "2025-05-08 17:44:45 UTC",
      "updated_date": "2025-05-08 17:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:08:15.700482"
    },
    {
      "arxiv_id": "2505.05440v1",
      "title": "EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation",
      "title_zh": "EcoAgent：一种用于移动自动化的高效边缘-云协同多智能体框架\n",
      "authors": [
        "Biao Yi",
        "Xavier Hu",
        "Yurun Chen",
        "Shengyu Zhang",
        "Hongxia Yang",
        "Fan Wu",
        "Fei Wu"
      ],
      "abstract": "Cloud-based mobile agents powered by (multimodal) large language models\n((M)LLMs) offer strong reasoning abilities but suffer from high latency and\ncost. While fine-tuned (M)SLMs enable edge deployment, they often lose general\ncapabilities and struggle with complex tasks. To address this, we propose\nEcoAgent, an Edge-Cloud cOllaborative multi-agent framework for mobile\nautomation. EcoAgent features a closed-loop collaboration among a cloud-based\nPlanning Agent and two edge-based agents: the Execution Agent for action\nexecution and the Observation Agent for verifying outcomes. The Observation\nAgent uses a Pre-Understanding Module to compress screen images into concise\ntext, reducing token usage. In case of failure, the Planning Agent retrieves\nscreen history and replans via a Reflection Module. Experiments on AndroidWorld\nshow that EcoAgent maintains high task success rates while significantly\nreducing MLLM token consumption, enabling efficient and practical mobile\nautomation.",
      "tldr_zh": "EcoAgent是一个高效的边缘-云协同多智能体框架，用于移动自动化。它旨在解决云端大型语言模型(MLLMs)高延迟和高成本问题，以及边缘端精调小模型(MSLMs)通用能力不足的问题。EcoAgent包含一个云端规划智能体和两个边缘智能体：执行智能体负责动作执行，观察智能体负责验证结果。观察智能体利用预理解模块压缩屏幕图像为简洁文本，以减少token使用。当任务失败时，规划智能体会检索屏幕历史并进行重新规划。在AndroidWorld上的实验表明，EcoAgent在保持高任务成功率的同时，显著降低了MLLM的token消耗，实现了高效且实用的移动自动化。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05440v1",
      "published_date": "2025-05-08 17:31:20 UTC",
      "updated_date": "2025-05-08 17:31:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:08:27.649408"
    },
    {
      "arxiv_id": "2505.05423v1",
      "title": "TransProQA: an LLM-based literary Translation evaluation metric with Professional Question Answering",
      "title_zh": "TransProQA：一种基于大型语言模型的文学翻译评估指标，具有专业问答能力",
      "authors": [
        "Ran Zhang",
        "Wei Zhao",
        "Lieve Macken",
        "Steffen Eger"
      ],
      "abstract": "The impact of Large Language Models (LLMs) has extended into literary\ndomains. However, existing evaluation metrics prioritize mechanical accuracy\nover artistic expression and tend to overrate machine translation (MT) as being\nsuperior to experienced professional human translation. In the long run, this\nbias could result in a permanent decline in translation quality and cultural\nauthenticity. In response to the urgent need for a specialized literary\nevaluation metric, we introduce TransProQA, a novel, reference-free, LLM-based\nquestion-answering (QA) framework designed specifically for literary\ntranslation evaluation. TransProQA uniquely integrates insights from\nprofessional literary translators and researchers, focusing on critical\nelements in literary quality assessment such as literary devices, cultural\nunderstanding, and authorial voice. Our extensive evaluation shows that while\nliterary-finetuned XCOMET-XL yields marginal gains, TransProQA substantially\noutperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ\nand Kendall's tau) and surpassing the best state-of-the-art (SOTA) metrics by\nover 15 points in adequacy assessments. Incorporating professional translator\ninsights as weights further improves performance, highlighting the value of\ntranslator inputs. Notably, TransProQA approaches human-level evaluation\nperformance comparable to trained linguistic annotators. It demonstrates broad\napplicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b,\nindicating its potential as an accessible and training-free literary evaluation\nmetric and a valuable tool for evaluating texts that require local processing\ndue to copyright or ethical considerations.",
      "tldr_zh": "该论文提出了TransProQA，一种基于大型语言模型(LLM)的、无需参考的文学翻译评估框架，旨在解决现有评估指标过度关注机械准确性而忽略艺术表达的问题。TransProQA通过专业问答(QA)的方式，整合了专业文学翻译者和研究者的见解，侧重于文学质量评估中的关键要素，如文学手法、文化理解和作者声音。实验结果表明，TransProQA显著优于现有指标，在相关性(ACC-EQ和Kendall's tau)方面提升高达0.07，并在充分性评估中超越最佳SOTA指标15个点以上。该框架具有广泛的适用性，可用于评估需要本地处理的文本，并接近人类水平的评估性能。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "WIP",
      "pdf_url": "http://arxiv.org/pdf/2505.05423v1",
      "published_date": "2025-05-08 17:12:56 UTC",
      "updated_date": "2025-05-08 17:12:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:08:39.669209"
    },
    {
      "arxiv_id": "2505.05422v1",
      "title": "TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation",
      "title_zh": "TokLIP：将视觉 Token 与 CLIP 结合，实现多模态理解和生成",
      "authors": [
        "Haokun Lin",
        "Teng Wang",
        "Yixiao Ge",
        "Yuying Ge",
        "Zhichao Lu",
        "Ying Wei",
        "Qingfu Zhang",
        "Zhenan Sun",
        "Ying Shan"
      ],
      "abstract": "Pioneering token-based works such as Chameleon and Emu3 have established a\nfoundation for multimodal unification but face challenges of high training\ncomputational overhead and limited comprehension performance due to a lack of\nhigh-level semantics. In this paper, we introduce TokLIP, a visual tokenizer\nthat enhances comprehension by semanticizing vector-quantized (VQ) tokens and\nincorporating CLIP-level semantics while enabling end-to-end multimodal\nautoregressive training with standard VQ tokens. TokLIP integrates a low-level\ndiscrete VQ tokenizer with a ViT-based token encoder to capture high-level\ncontinuous semantics. Unlike previous approaches (e.g., VILA-U) that discretize\nhigh-level features, TokLIP disentangles training objectives for comprehension\nand generation, allowing the direct application of advanced VQ tokenizers\nwithout the need for tailored quantization operations. Our empirical results\ndemonstrate that TokLIP achieves exceptional data efficiency, empowering visual\ntokens with high-level semantic understanding while enhancing low-level\ngenerative capacity, making it well-suited for autoregressive Transformers in\nboth comprehension and generation tasks. The code and models are available at\nhttps://github.com/TencentARC/TokLIP.",
      "tldr_zh": "TokLIP 是一种新型视觉 tokenizer，旨在提升多模态理解和生成能力。它通过语义化 vector-quantized (VQ) tokens 并融入 CLIP 级别的语义信息，增强了视觉 tokens 的理解能力。TokLIP 结合了低级的离散 VQ tokenizer 和基于 ViT 的 token encoder，从而同时捕捉低级生成能力和高级连续语义。与以往方法不同，TokLIP 解耦了理解和生成的训练目标，可以直接应用先进的 VQ tokenizer。实验结果表明，TokLIP 具有卓越的数据效率，增强了视觉 tokens 的高级语义理解能力和低级生成能力，使其非常适合用于自回归 Transformer 中的理解和生成任务。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2505.05422v1",
      "published_date": "2025-05-08 17:12:19 UTC",
      "updated_date": "2025-05-08 17:12:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:08:51.885678"
    },
    {
      "arxiv_id": "2505.05410v1",
      "title": "Reasoning Models Don't Always Say What They Think",
      "title_zh": "推理模型并不总是说出它们所想",
      "authors": [
        "Yanda Chen",
        "Joe Benton",
        "Ansh Radhakrishnan",
        "Jonathan Uesato",
        "Carson Denison",
        "John Schulman",
        "Arushi Somani",
        "Peter Hase",
        "Misha Wagner",
        "Fabien Roger",
        "Vlad Mikulik",
        "Samuel R. Bowman",
        "Jan Leike",
        "Jared Kaplan",
        "Ethan Perez"
      ],
      "abstract": "Chain-of-thought (CoT) offers a potential boon for AI safety as it allows\nmonitoring a model's CoT to try to understand its intentions and reasoning\nprocesses. However, the effectiveness of such monitoring hinges on CoTs\nfaithfully representing models' actual reasoning processes. We evaluate CoT\nfaithfulness of state-of-the-art reasoning models across 6 reasoning hints\npresented in the prompts and find: (1) for most settings and models tested,\nCoTs reveal their usage of hints in at least 1% of examples where they use the\nhint, but the reveal rate is often below 20%, (2) outcome-based reinforcement\nlearning initially improves faithfulness but plateaus without saturating, and\n(3) when reinforcement learning increases how frequently hints are used (reward\nhacking), the propensity to verbalize them does not increase, even without\ntraining against a CoT monitor. These results suggest that CoT monitoring is a\npromising way of noticing undesired behaviors during training and evaluations,\nbut that it is not sufficient to rule them out. They also suggest that in\nsettings like ours where CoT reasoning is not necessary, test-time monitoring\nof CoTs is unlikely to reliably catch rare and catastrophic unexpected\nbehaviors.",
      "tldr_zh": "本文研究了思维链(CoT)是否能真实反映模型实际的推理过程，这对AI安全至关重要。通过在提示中引入6种推理提示，评估了先进推理模型在CoT上的忠实度。实验发现：(1) 大部分情况下，模型在使用提示时，CoT的揭示率通常低于20%；(2) 基于结果的强化学习虽然能提高忠实度，但效果有限；(3) 当强化学习增加提示的使用频率时， verbalize 它们的倾向并没有增加。结果表明，CoT监控是发现训练和评估期间不良行为的有希望的方法，但不足以完全排除这些行为。在CoT推理并非必要的情况下，测试时监控CoT不太可能可靠地捕捉到罕见的灾难性意外行为。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05410v1",
      "published_date": "2025-05-08 16:51:43 UTC",
      "updated_date": "2025-05-08 16:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:09:03.914419"
    },
    {
      "arxiv_id": "2505.05408v1",
      "title": "Crosslingual Reasoning through Test-Time Scaling",
      "title_zh": "通过测试时缩放实现跨语言推理\n",
      "authors": [
        "Zheng-Xin Yong",
        "M. Farid Adilazuarda",
        "Jonibek Mansurov",
        "Ruochen Zhang",
        "Niklas Muennighoff",
        "Carsten Eickhoff",
        "Genta Indra Winata",
        "Julia Kreutzer",
        "Stephen H. Bach",
        "Alham Fikri Aji"
      ],
      "abstract": "Reasoning capabilities of large language models are primarily studied for\nEnglish, even when pretrained models are multilingual. In this work, we\ninvestigate to what extent English reasoning finetuning with long\nchain-of-thoughts (CoTs) can generalize across languages. First, we find that\nscaling up inference compute for English-centric reasoning language models\n(RLMs) improves multilingual mathematical reasoning across many languages\nincluding low-resource languages, to an extent where they outperform models\ntwice their size. Second, we reveal that while English-centric RLM's CoTs are\nnaturally predominantly English, they consistently follow a quote-and-think\npattern to reason about quoted non-English inputs. Third, we discover an\neffective strategy to control the language of long CoT reasoning, and we\nobserve that models reason better and more efficiently in high-resource\nlanguages. Finally, we observe poor out-of-domain reasoning generalization, in\nparticular from STEM to cultural commonsense knowledge, even for English.\nOverall, we demonstrate the potentials, study the mechanisms and outline the\nlimitations of crosslingual generalization of English reasoning test-time\nscaling. We conclude that practitioners should let English-centric RLMs reason\nin high-resource languages, while further work is needed to improve reasoning\nin low-resource languages and out-of-domain contexts.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在英语推理微调后，其链式思维(CoT)推理能力在跨语言环境下的泛化能力。研究发现，针对英语的推理语言模型(RLMs)通过扩大推理计算规模，可以显著提升包括低资源语言在内的多语言数学推理能力，甚至超越规模两倍的模型。研究揭示了以英语为中心的RLM的CoT推理过程遵循“引用-思考”模式处理非英语输入，并发现控制CoT推理语言的有效策略，在高资源语言中能实现更好更高效的推理。最后，研究观察到领域外推理泛化能力较差，尤其是在从STEM到文化常识知识的迁移中。总而言之，该研究展示了英语推理测试时扩展的跨语言泛化的潜力，并指出了其局限性，建议从业者应在高资源语言中使用以英语为中心的RLM进行推理，并进一步改进低资源语言和领域外环境中的推理能力。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05408v1",
      "published_date": "2025-05-08 16:50:06 UTC",
      "updated_date": "2025-05-08 16:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:09:16.239788"
    },
    {
      "arxiv_id": "2505.05402v1",
      "title": "CART-ELC: Oblique Decision Tree Induction via Exhaustive Search",
      "title_zh": "CART-ELC：基于穷举搜索的倾斜决策树归纳",
      "authors": [
        "Andrew D. Laack"
      ],
      "abstract": "Oblique decision trees have attracted attention due to their potential for\nimproved classification performance over traditional axis-aligned decision\ntrees. However, methods that rely on exhaustive search to find oblique splits\nface computational challenges. As a result, they have not been widely explored.\nWe introduce a novel algorithm, Classification and Regression Tree - Exhaustive\nLinear Combinations (CART-ELC), for inducing oblique decision trees that\nperforms an exhaustive search on a restricted set of hyperplanes. We then\ninvestigate the algorithm's computational complexity and its predictive\ncapabilities. Our results demonstrate that CART-ELC consistently achieves\ncompetitive performance on small datasets, often yielding statistically\nsignificant improvements in classification accuracy relative to existing\ndecision tree induction algorithms, while frequently producing shallower,\nsimpler, and thus more interpretable trees.",
      "tldr_zh": "该论文提出了一种新的斜决策树归纳算法CART-ELC，通过在限制的超平面集合上进行穷举搜索来寻找最佳斜分割。与传统的轴对齐决策树相比，斜决策树具有提高分类性能的潜力，但穷举搜索面临计算挑战。研究分析了CART-ELC算法的计算复杂度及其预测能力。实验结果表明，在小型数据集上，CART-ELC能够稳定地获得有竞争力的性能，并且通常在分类精度方面优于现有的决策树归纳算法，同时生成更浅、更简单、更易于解释的树。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "I.2.6; I.5.2; F.2.2; G.3; G.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05402v1",
      "published_date": "2025-05-08 16:42:13 UTC",
      "updated_date": "2025-05-08 16:42:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:09:27.518493"
    },
    {
      "arxiv_id": "2505.05396v1",
      "title": "A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods",
      "title_zh": "一种基于多模态数据和深度机器学习方法的疼痛评估框架\n",
      "authors": [
        "Stefanos Gkikas"
      ],
      "abstract": "From the original abstract:\n  This thesis initially aims to study the pain assessment process from a\nclinical-theoretical perspective while exploring and examining existing\nautomatic approaches. Building on this foundation, the primary objective of\nthis Ph.D. project is to develop innovative computational methods for automatic\npain assessment that achieve high performance and are applicable in real\nclinical settings. A primary goal is to thoroughly investigate and assess\nsignificant factors, including demographic elements that impact pain\nperception, as recognized in pain research, through a computational standpoint.\nWithin the limits of the available data in this research area, our goal was to\ndesign, develop, propose, and offer automatic pain assessment pipelines for\nunimodal and multimodal configurations that are applicable to the specific\nrequirements of different scenarios. The studies published in this Ph.D. thesis\nshowcased the effectiveness of the proposed methods, achieving state-of-the-art\nresults. Additionally, they paved the way for exploring new approaches in\nartificial intelligence, foundation models, and generative artificial\nintelligence.",
      "tldr_zh": "该论文旨在构建一个基于多模态数据和深度学习的疼痛评估框架。研究首先从临床理论角度分析疼痛评估过程，并调研现有的自动评估方法。在此基础上，论文提出了新的计算方法，用于实现高性能且适用于真实临床环境的自动疼痛评估。研究充分考察了包括人口统计学因素在内的、影响疼痛感知的关键因素。论文设计并提出了适用于不同场景的单模态和多模态自动疼痛评估流程，实验结果表明所提出的方法有效，并达到了state-of-the-art的性能，为人工智能、基础模型和生成式人工智能在疼痛评估领域的新方法探索奠定了基础。\n",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05396v1",
      "published_date": "2025-05-08 16:32:55 UTC",
      "updated_date": "2025-05-08 16:32:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:09:39.868604"
    },
    {
      "arxiv_id": "2505.05375v1",
      "title": "Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks",
      "title_zh": "用于脉冲神经网络在线测试时自适应的阈值调制\n",
      "authors": [
        "Kejie Zhao",
        "Wenjia Hua",
        "Aiersi Tuerhong",
        "Luziwei Leng",
        "Yuxin Ma",
        "Qinghua Guo"
      ],
      "abstract": "Recently, spiking neural networks (SNNs), deployed on neuromorphic chips,\nprovide highly efficient solutions on edge devices in different scenarios.\nHowever, their ability to adapt to distribution shifts after deployment has\nbecome a crucial challenge. Online test-time adaptation (OTTA) offers a\npromising solution by enabling models to dynamically adjust to new data\ndistributions without requiring source data or labeled target samples.\nNevertheless, existing OTTA methods are largely designed for traditional\nartificial neural networks and are not well-suited for SNNs. To address this\ngap, we propose a low-power, neuromorphic chip-friendly online test-time\nadaptation framework, aiming to enhance model generalization under distribution\nshifts. The proposed approach is called Threshold Modulation (TM), which\ndynamically adjusts the firing threshold through neuronal dynamics-inspired\nnormalization, being more compatible with neuromorphic hardware. Experimental\nresults on benchmark datasets demonstrate the effectiveness of this method in\nimproving the robustness of SNNs against distribution shifts while maintaining\nlow computational cost. The proposed method offers a practical solution for\nonline test-time adaptation of SNNs, providing inspiration for the design of\nfuture neuromorphic chips. The demo code is available at\ngithub.com/NneurotransmitterR/TM-OTTA-SNN.",
      "tldr_zh": "该论文提出了一种针对脉冲神经网络(SNNs)的在线测试时自适应(OTTA)框架，名为阈值调制(Threshold Modulation, TM)。该方法通过神经元动态启发的归一化动态调整神经元的发放阈值，从而使SNNs能够适应部署后的数据分布变化，且更兼容神经形态硬件。实验结果表明，TM方法在基准数据集上能有效提高SNNs在分布偏移下的鲁棒性，同时保持较低的计算成本。该研究为SNNs的在线测试时自适应提供了一种实用的解决方案，并为未来神经形态芯片的设计提供了灵感。代码已开源。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IJCNN 2025. \\c{opyright} 2025 IEEE. Personal use of this\n  material is permitted. Permission from IEEE must be obtained for all other\n  uses, including reprinting/republishing this material for advertising or\n  promotional purposes, collecting new collected works for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
      "pdf_url": "http://arxiv.org/pdf/2505.05375v1",
      "published_date": "2025-05-08 16:09:40 UTC",
      "updated_date": "2025-05-08 16:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:09:51.710058"
    },
    {
      "arxiv_id": "2505.05356v1",
      "title": "Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields",
      "title_zh": "高斯飞行时间：在动态辐射场中间接优化深度\n",
      "authors": [
        "Runfeng Li",
        "Mikhail Okunev",
        "Zixuan Guo",
        "Anh Ha Duong",
        "Christian Richardt",
        "Matthew O'Toole",
        "James Tompkin"
      ],
      "abstract": "We present a method to reconstruct dynamic scenes from monocular\ncontinuous-wave time-of-flight (C-ToF) cameras using raw sensor samples that\nachieves similar or better accuracy than neural volumetric approaches and is\n100x faster. Quickly achieving high-fidelity dynamic 3D reconstruction from a\nsingle viewpoint is a significant challenge in computer vision. In C-ToF\nradiance field reconstruction, the property of interest-depth-is not directly\nmeasured, causing an additional challenge. This problem has a large and\nunderappreciated impact upon the optimization when using a fast primitive-based\nscene representation like 3D Gaussian splatting, which is commonly used with\nmulti-view data to produce satisfactory results and is brittle in its\noptimization otherwise. We incorporate two heuristics into the optimization to\nimprove the accuracy of scene geometry represented by Gaussians. Experimental\nresults show that our approach produces accurate reconstructions under\nconstrained C-ToF sensing conditions, including for fast motions like swinging\nbaseball bats. https://visual.cs.brown.edu/gftorf",
      "tldr_zh": "该论文提出了一种利用单目连续波飞行时间(C-ToF)相机原始传感器数据重建动态场景的方法，其精度与神经体积方法相当甚至更好，速度却快100倍。在C-ToF辐射场重建中，深度并非直接测量值，这给优化带来了额外的挑战。该研究通过引入两个启发式方法来提高高斯函数表示的场景几何体的精度，从而优化场景重建。实验结果表明，该方法在受限的C-ToF传感条件下，能够产生精确的重建结果，包括对挥舞棒球棒等快速运动的重建。\n",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05356v1",
      "published_date": "2025-05-08 15:45:53 UTC",
      "updated_date": "2025-05-08 15:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:10:03.703337"
    },
    {
      "arxiv_id": "2505.05354v1",
      "title": "High-fidelity Grain Growth Modeling: Leveraging Deep Learning for Fast Computations",
      "title_zh": "高保真晶粒长大建模：利用深度学习实现快速计算\n",
      "authors": [
        "Pungponhavoan Tep",
        "Marc Bernacki"
      ],
      "abstract": "Grain growth simulation is crucial for predicting metallic material\nmicrostructure evolution during annealing and resulting final mechanical\nproperties, but traditional partial differential equation-based methods are\ncomputationally expensive, creating bottlenecks in materials design and\nmanufacturing. In this work, we introduce a machine learning framework that\ncombines a Convolutional Long Short-Term Memory networks with an Autoencoder to\nefficiently predict grain growth evolution. Our approach captures both spatial\nand temporal aspects of grain evolution while encoding high-dimensional grain\nstructure data into a compact latent space for pattern learning, enhanced by a\nnovel composite loss function combining Mean Squared Error, Structural\nSimilarity Index Measurement, and Boundary Preservation to maintain structural\nintegrity of grain boundary topology of the prediction. Results demonstrated\nthat our machine learning approach accelerates grain growth prediction by up to\n\\SI{89}{\\times} faster, reducing computation time from \\SI{10}{\\minute} to\napproximately \\SI{10}{\\second} while maintaining high-fidelity predictions. The\nbest model (S-30-30) achieving a structural similarity score of\n\\SI{86.71}{\\percent} and mean grain size error of just \\SI{0.07}{\\percent}. All\nmodels accurately captured grain boundary topology, morphology, and size\ndistributions. This approach enables rapid microstructural prediction for\napplications where conventional simulations are prohibitively time-consuming,\npotentially accelerating innovation in materials science and manufacturing.",
      "tldr_zh": "该研究提出了一种基于深度学习的框架，用于高效预测晶粒生长演化，旨在解决传统偏微分方程方法计算成本高昂的问题。该框架结合了卷积长短期记忆网络(Convolutional Long Short-Term Memory networks)和自编码器(Autoencoder)，捕捉晶粒演化的时空特征，并将高维晶粒结构数据编码到紧凑的潜在空间中进行模式学习。通过结合均方误差(Mean Squared Error)、结构相似性指数测量(Structural Similarity Index Measurement)和边界保持的复合损失函数，保持了晶界拓扑的结构完整性。实验结果表明，该方法将晶粒生长预测速度提高了高达89倍，同时保持了高保真度的预测，结构相似性评分达到86.71%，平均晶粒尺寸误差仅为0.07%。该方法能够快速预测微观结构，加速材料科学和制造领域的创新。\n",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05354v1",
      "published_date": "2025-05-08 15:43:40 UTC",
      "updated_date": "2025-05-08 15:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:10:16.165650"
    },
    {
      "arxiv_id": "2505.05321v1",
      "title": "Feature-Augmented Deep Networks for Multiscale Building Segmentation in High-Resolution UAV and Satellite Imagery",
      "title_zh": "用于高分辨率无人机和卫星影像中多尺度建筑物分割的特征增强型深度网络\n",
      "authors": [
        "Chintan B. Maniyar",
        "Minakshi Kumar",
        "Gengchen Mai"
      ],
      "abstract": "Accurate building segmentation from high-resolution RGB imagery remains\nchallenging due to spectral similarity with non-building features, shadows, and\nirregular building geometries. In this study, we present a comprehensive deep\nlearning framework for multiscale building segmentation using RGB aerial and\nsatellite imagery with spatial resolutions ranging from 0.4m to 2.7m. We curate\na diverse, multi-sensor dataset and introduce feature-augmented inputs by\nderiving secondary representations including Principal Component Analysis\n(PCA), Visible Difference Vegetation Index (VDVI), Morphological Building Index\n(MBI), and Sobel edge filters from RGB channels. These features guide a\nRes-U-Net architecture in learning complex spatial patterns more effectively.\nWe also propose training policies incorporating layer freezing, cyclical\nlearning rates, and SuperConvergence to reduce training time and resource\nusage. Evaluated on a held-out WorldView-3 image, our model achieves an overall\naccuracy of 96.5%, an F1-score of 0.86, and an Intersection over Union (IoU) of\n0.80, outperforming existing RGB-based benchmarks. This study demonstrates the\neffectiveness of combining multi-resolution imagery, feature augmentation, and\noptimized training strategies for robust building segmentation in remote\nsensing applications.",
      "tldr_zh": "该研究提出了一种用于高分辨率无人机和卫星图像中多尺度建筑物分割的特征增强深度学习框架。该框架通过从RGB通道导出主成分分析(PCA)、可见差异植被指数(VDVI)、形态建筑物指数(MBI)和Sobel边缘滤波器等辅助表示，构建特征增强输入，以指导Res-U-Net架构更有效地学习复杂的空间模式。此外，研究还提出了结合层冻结、循环学习率和SuperConvergence的训练策略，以减少训练时间和资源使用。在WorldView-3图像上的评估结果表明，该模型取得了优于现有RGB基准的分割性能，证明了结合多分辨率图像、特征增强和优化训练策略在遥感应用中进行鲁棒建筑物分割的有效性。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6; I.4.10; I.5.1; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "in preparation for journal submission, 25 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05321v1",
      "published_date": "2025-05-08 15:08:36 UTC",
      "updated_date": "2025-05-08 15:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:10:27.891059"
    },
    {
      "arxiv_id": "2505.05318v1",
      "title": "Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects",
      "title_zh": "视觉语言模型中的用户信任映射：研究现状、挑战与展望\n",
      "authors": [
        "Agnese Chiatti",
        "Sara Bernardini",
        "Lara Shibelski Godoy Piccolo",
        "Viola Schiaffonati",
        "Matteo Matteucci"
      ],
      "abstract": "The rapid adoption of Vision Language Models (VLMs), pre-trained on large\nimage-text and video-text datasets, calls for protecting and informing users\nabout when to trust these systems. This survey reviews studies on trust\ndynamics in user-VLM interactions, through a multi-disciplinary taxonomy\nencompassing different cognitive science capabilities, collaboration modes, and\nagent behaviours. Literature insights and findings from a workshop with\nprospective VLM users inform preliminary requirements for future VLM trust\nstudies.",
      "tldr_zh": "本研究综述了用户与视觉语言模型(VLM)交互中的信任动态，旨在保护用户并告知何时信任这些系统。文章构建了一个多学科的分类体系，涵盖不同的认知科学能力、协作模式和智能体行为。通过文献调研和一个面向VLM潜在用户的研讨会，总结了未来VLM信任研究的初步要求，为该领域的研究提供了方向。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05318v1",
      "published_date": "2025-05-08 15:02:49 UTC",
      "updated_date": "2025-05-08 15:02:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:10:39.390731"
    },
    {
      "arxiv_id": "2505.05315v1",
      "title": "Scalable Chain of Thoughts via Elastic Reasoning",
      "title_zh": "基于弹性推理的可扩展链式思考\n",
      "authors": [
        "Yuhui Xu",
        "Hanze Dong",
        "Lei Wang",
        "Doyen Sahoo",
        "Junnan Li",
        "Caiming Xiong"
      ],
      "abstract": "Large reasoning models (LRMs) have achieved remarkable progress on complex\ntasks by generating extended chains of thought (CoT). However, their\nuncontrolled output lengths pose significant challenges for real-world\ndeployment, where inference-time budgets on tokens, latency, or compute are\nstrictly constrained. We propose Elastic Reasoning, a novel framework for\nscalable chain of thoughts that explicitly separates reasoning into two\nphases--thinking and solution--with independently allocated budgets. At test\ntime, Elastic Reasoning prioritize that completeness of solution segments,\nsignificantly improving reliability under tight resource constraints. To train\nmodels that are robust to truncated thinking, we introduce a lightweight\nbudget-constrained rollout strategy, integrated into GRPO, which teaches the\nmodel to reason adaptively when the thinking process is cut short and\ngeneralizes effectively to unseen budget constraints without additional\ntraining. Empirical results on mathematical (AIME, MATH500) and programming\n(LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning\nperforms robustly under strict budget constraints, while incurring\nsignificantly lower training cost than baseline methods. Remarkably, our\napproach also produces more concise and efficient reasoning even in\nunconstrained settings. Elastic Reasoning offers a principled and practical\nsolution to the pressing challenge of controllable reasoning at scale.",
      "tldr_zh": "本文提出了一种名为“弹性推理”(Elastic Reasoning)的可扩展链式思考(Chain-of-Thought)框架，旨在解决大型推理模型(LRMs)在实际部署中因输出长度不可控而面临的资源限制问题。该框架将推理过程显式地分为“思考”和“解决方案”两个阶段，并为每个阶段独立分配预算。在测试阶段，“弹性推理”优先保证解决方案片段的完整性，从而在严格的资源约束下显著提高可靠性。为了训练对截断思考具有鲁棒性的模型，作者引入了一种轻量级的预算约束 rollout 策略，并将其集成到 GRPO 中，使模型能够在思考过程被缩短时进行自适应推理，并有效地泛化到未见的预算约束，而无需额外的训练。在数学（AIME、MATH500）和编程（LiveCodeBench、Codeforces）基准测试上的实验结果表明，“弹性推理”在严格的预算约束下表现出强大的鲁棒性，同时训练成本远低于基线方法。即使在无约束的环境中，该方法也能产生更简洁高效的推理。 “弹性推理”为可控推理这一紧迫挑战提供了一种原则性且实用的解决方案。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05315v1",
      "published_date": "2025-05-08 15:01:06 UTC",
      "updated_date": "2025-05-08 15:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:10:52.478800"
    },
    {
      "arxiv_id": "2505.05291v1",
      "title": "Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection",
      "title_zh": "眼科基础模型在临床显著性年龄相关性黄斑变性检测中的基准测试\n",
      "authors": [
        "Benjamin A. Cohen",
        "Jonathan Fhima",
        "Meishar Meisel",
        "Baskin Meital",
        "Luis Filipe Nakayama",
        "Eran Berkowitz",
        "Joachim A. Behar"
      ],
      "abstract": "Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to\nlearn robust representations from large-scale natural image datasets, enhancing\ntheir generalization across domains. In retinal imaging, foundation models\npretrained on either natural or ophthalmic data have shown promise, but the\nbenefits of in-domain pretraining remain uncertain. To investigate this, we\nbenchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets\ntotaling 70,000 expert-annotated images for the task of moderate-to-late\nage-related macular degeneration (AMD) identification. Our results show that\niBOT pretrained on natural images achieves the highest out-of-distribution\ngeneralization, with AUROCs of 0.80-0.97, outperforming domain-specific models,\nwhich achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining,\nwhich achieved AUROCs of 0.68-0.91. These findings highlight the value of\nfoundation models in improving AMD identification and challenge the assumption\nthat in-domain pretraining is necessary. Furthermore, we release BRAMD, an\nopen-access dataset (n=587) of DFIs with AMD labels from Brazil.",
      "tldr_zh": "该研究对六个基于自监督学习(SSL)的Vision Transformer (ViT)模型在七个眼底图像数据集上进行了基准测试，用于检测中度至晚期年龄相关性黄斑变性(AMD)。结果表明，在自然图像上预训练的iBOT模型具有最高的 out-of-distribution 泛化能力，其AUROCs达到0.80-0.97，优于在眼科领域数据上预训练的模型(AUROCs为0.78-0.96)和未经过预训练的基线ViT-L模型(AUROCs为0.68-0.91)。这项研究强调了基础模型在提高AMD识别能力方面的价值，并挑战了领域内预训练是必要的这一假设。此外，作者还发布了一个名为BRAMD的开放访问数据集，其中包含来自巴西的带有AMD标签的眼底图像。\n",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.TO"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05291v1",
      "published_date": "2025-05-08 14:31:02 UTC",
      "updated_date": "2025-05-08 14:31:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:11:04.112284"
    },
    {
      "arxiv_id": "2505.05288v1",
      "title": "PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes",
      "title_zh": "PlaceIt3D：真实3D场景中基于语言引导的物体放置\n",
      "authors": [
        "Ahmed Abdelreheem",
        "Filippo Aleotti",
        "Jamie Watson",
        "Zawar Qureshi",
        "Abdelrahman Eldesokey",
        "Peter Wonka",
        "Gabriel Brostow",
        "Sara Vicente",
        "Guillermo Garcia-Hernando"
      ],
      "abstract": "We introduce the novel task of Language-Guided Object Placement in Real 3D\nScenes. Our model is given a 3D scene's point cloud, a 3D asset, and a textual\nprompt broadly describing where the 3D asset should be placed. The task here is\nto find a valid placement for the 3D asset that respects the prompt. Compared\nwith other language-guided localization tasks in 3D scenes such as grounding,\nthis task has specific challenges: it is ambiguous because it has multiple\nvalid solutions, and it requires reasoning about 3D geometric relationships and\nfree space. We inaugurate this task by proposing a new benchmark and evaluation\nprotocol. We also introduce a new dataset for training 3D LLMs on this task, as\nwell as the first method to serve as a non-trivial baseline. We believe that\nthis challenging task and our new benchmark could become part of the suite of\nbenchmarks used to evaluate and compare generalist 3D LLM models.",
      "tldr_zh": "该论文提出了一个新任务：语言引导的真实3D场景物体放置(Language-Guided Object Placement in Real 3D Scenes)。模型接收3D场景的点云、一个3D资产以及描述放置位置的文本提示，目标是找到一个符合提示的有效放置方案。与3D场景中的其他语言引导定位任务相比，该任务具有多解歧义性，并需要推理3D几何关系和自由空间。论文为此任务提出了一个新的基准和评估协议，并引入了一个用于训练3D LLM的数据集，以及一个作为基线的初步方法。研究者认为该任务和基准可以用于评估和比较通用3D LLM模型。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Tech report. Project page: https://nianticlabs.github.io/placeit3d/",
      "pdf_url": "http://arxiv.org/pdf/2505.05288v1",
      "published_date": "2025-05-08 14:29:11 UTC",
      "updated_date": "2025-05-08 14:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:11:15.823688"
    },
    {
      "arxiv_id": "2505.05283v1",
      "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents",
      "title_zh": "软件开发生命周期视角：CodeLLM 和 Agent 基准测试综述\n",
      "authors": [
        "Kaixin Wang",
        "Tianlin Li",
        "Xiaoyu Zhang",
        "Chong Wang",
        "Weisong Sun",
        "Yang Liu",
        "Bin Shi"
      ],
      "abstract": "Code large language models (CodeLLMs) and agents have shown great promise in\ntackling complex software engineering tasks.Compared to traditional software\nengineering methods, CodeLLMs and agents offer stronger abilities, and can\nflexibly process inputs and outputs in both natural and code. Benchmarking\nplays a crucial role in evaluating the capabilities of CodeLLMs and agents,\nguiding their development and deployment. However, despite their growing\nsignificance, there remains a lack of comprehensive reviews of benchmarks for\nCodeLLMs and agents. To bridge this gap, this paper provides a comprehensive\nreview of existing benchmarks for CodeLLMs and agents, studying and analyzing\n181 benchmarks from 461 relevant papers, covering the different phases of the\nsoftware development life cycle (SDLC). Our findings reveal a notable imbalance\nin the coverage of current benchmarks, with approximately 60% focused on the\nsoftware development phase in SDLC, while requirements engineering and software\ndesign phases receive minimal attention at only 5% and 3%, respectively.\nAdditionally, Python emerges as the dominant programming language across the\nreviewed benchmarks. Finally, this paper highlights the challenges of current\nresearch and proposes future directions, aiming to narrow the gap between the\ntheoretical capabilities of CodeLLMs and agents and their application in\nreal-world scenarios.",
      "tldr_zh": "本文对代码大语言模型(CodeLLMs)和智能体在软件开发生命周期(SDLC)中的基准测试进行了全面的综述。通过分析461篇相关论文中的181个基准，揭示了当前基准测试覆盖范围的不平衡现象，约60%集中在软件开发阶段，而需求工程和软件设计阶段的关注度分别仅为5%和3%。此外，Python是这些基准测试中最主要的编程语言。最后，文章强调了当前研究的挑战，并提出了未来的研究方向，旨在缩小CodeLLMs和智能体的理论能力与实际应用之间的差距。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05283v1",
      "published_date": "2025-05-08 14:27:45 UTC",
      "updated_date": "2025-05-08 14:27:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:11:27.712264"
    },
    {
      "arxiv_id": "2505.05271v1",
      "title": "T-T: Table Transformer for Tagging-based Aspect Sentiment Triplet Extraction",
      "title_zh": "T-T：用于基于标注的方面情感三元组抽取的表格 Transformer\n",
      "authors": [
        "Kun Peng",
        "Chaodong Tong",
        "Cong Cao",
        "Hao Peng",
        "Qian Li",
        "Guanlin Wu",
        "Lei Jiang",
        "Yanbing Liu",
        "Philip S. Yu"
      ],
      "abstract": "Aspect sentiment triplet extraction (ASTE) aims to extract triplets composed\nof aspect terms, opinion terms, and sentiment polarities from given sentences.\nThe table tagging method is a popular approach to addressing this task, which\nencodes a sentence into a 2-dimensional table, allowing for the tagging of\nrelations between any two words. Previous efforts have focused on designing\nvarious downstream relation learning modules to better capture interactions\nbetween tokens in the table, revealing that a stronger capability to capture\nrelations can lead to greater improvements in the model. Motivated by this, we\nattempt to directly utilize transformer layers as downstream relation learning\nmodules. Due to the powerful semantic modeling capability of transformers, it\nis foreseeable that this will lead to excellent improvement. However, owing to\nthe quadratic relation between the length of the table and the length of the\ninput sentence sequence, using transformers directly faces two challenges:\noverly long table sequences and unfair local attention interaction. To address\nthese challenges, we propose a novel Table-Transformer (T-T) for the\ntagging-based ASTE method. Specifically, we introduce a stripe attention\nmechanism with a loop-shift strategy to tackle these challenges. The former\nmodifies the global attention mechanism to only attend to a 2-dimensional local\nattention window, while the latter facilitates interaction between different\nattention windows. Extensive and comprehensive experiments demonstrate that the\nT-T, as a downstream relation learning module, achieves state-of-the-art\nperformance with lower computational costs.",
      "tldr_zh": "本文提出了一种名为Table-Transformer (T-T) 的新型模型，用于解决基于表格标注的方面情感三元组抽取(ASTE)任务。该模型利用Transformer层作为下游关系学习模块，旨在提升模型捕获token间关系的能力。为了应对表格长度与输入句子长度之间的二次关系带来的挑战，T-T引入了一种带有循环移位策略的条纹注意力机制。该机制将全局注意力修改为仅关注二维局部注意力窗口，并促进不同注意力窗口之间的交互。实验结果表明，T-T作为下游关系学习模块，以更低的计算成本实现了最先进的性能。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IJCAI2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05271v1",
      "published_date": "2025-05-08 14:17:27 UTC",
      "updated_date": "2025-05-08 14:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:11:39.610551"
    },
    {
      "arxiv_id": "2505.05262v1",
      "title": "Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration",
      "title_zh": "利用状态建模和对抗探索增强合作多智能体强化学习\n",
      "authors": [
        "Andreas Kontogiannis",
        "Konstantinos Papathanasiou",
        "Yi Shen",
        "Giorgos Stamou",
        "Michael M. Zavlanos",
        "George Vouros"
      ],
      "abstract": "Learning to cooperate in distributed partially observable environments with\nno communication abilities poses significant challenges for multi-agent deep\nreinforcement learning (MARL). This paper addresses key concerns in this\ndomain, focusing on inferring state representations from individual agent\nobservations and leveraging these representations to enhance agents'\nexploration and collaborative task execution policies. To this end, we propose\na novel state modelling framework for cooperative MARL, where agents infer\nmeaningful belief representations of the non-observable state, with respect to\noptimizing their own policies, while filtering redundant and less informative\njoint state information. Building upon this framework, we propose the MARL SMPE\nalgorithm. In SMPE, agents enhance their own policy's discriminative abilities\nunder partial observability, explicitly by incorporating their beliefs into the\npolicy network, and implicitly by adopting an adversarial type of exploration\npolicies which encourages agents to discover novel, high-value states while\nimproving the discriminative abilities of others. Experimentally, we show that\nSMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative\ntasks from the MPE, LBF, and RWARE benchmarks.",
      "tldr_zh": "本文提出了一种新的状态建模框架用于增强合作式多智能体强化学习(MARL)，特别是在分布式部分可观测环境中，智能体之间无法直接通信的场景。该框架的核心思想是让智能体从自身观测中推断出有意义的、关于不可观测状态的信念表示，并以此优化自身策略，同时过滤掉冗余的联合状态信息。在此基础上，作者提出了MARL SMPE算法，该算法通过将信念融入策略网络，并采用对抗式探索策略，鼓励智能体发现新的、高价值的状态，同时提高其他智能体的区分能力。实验结果表明，SMPE在MPE、LBF和RWARE等复杂合作任务中优于现有的MARL算法。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted (Poster) at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05262v1",
      "published_date": "2025-05-08 14:07:20 UTC",
      "updated_date": "2025-05-08 14:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:11:51.774472"
    },
    {
      "arxiv_id": "2505.05235v1",
      "title": "Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation",
      "title_zh": "通过分层安全抽象解释推进神经网络验证\n",
      "authors": [
        "Luca Marzari",
        "Isabella Mastroeni",
        "Alessandro Farinelli"
      ],
      "abstract": "Traditional methods for formal verification (FV) of deep neural networks\n(DNNs) are constrained by a binary encoding of safety properties, where a model\nis classified as either safe or unsafe (robust or not robust). This binary\nencoding fails to capture the nuanced safety levels within a model, often\nresulting in either overly restrictive or too permissive requirements. In this\npaper, we introduce a novel problem formulation called Abstract\nDNN-Verification, which verifies a hierarchical structure of unsafe outputs,\nproviding a more granular analysis of the safety aspect for a given DNN.\nCrucially, by leveraging abstract interpretation and reasoning about output\nreachable sets, our approach enables assessing multiple safety levels during\nthe FV process, requiring the same (in the worst case) or even potentially less\ncomputational effort than the traditional binary verification approach.\nSpecifically, we demonstrate how this formulation allows rank adversarial\ninputs according to their abstract safety level violation, offering a more\ndetailed evaluation of the model's safety and robustness. Our contributions\ninclude a theoretical exploration of the relationship between our novel\nabstract safety formulation and existing approaches that employ abstract\ninterpretation for robustness verification, complexity analysis of the novel\nproblem introduced, and an empirical evaluation considering both a complex deep\nreinforcement learning task (based on Habitat 3.0) and standard\nDNN-Verification benchmarks.",
      "tldr_zh": "本文提出了一种新的神经网络验证方法，称为抽象DNN验证(Abstract DNN-Verification)，旨在解决传统二元安全属性编码在深度神经网络(DNN)验证中的局限性。该方法通过验证不安全输出的层次结构，提供对DNN安全性更细粒度的分析。利用抽象解释和输出可达集推理，该方法能够在验证过程中评估多个安全级别，并且计算复杂度与传统的二元验证方法相当甚至更低。实验结果表明，该方法能够根据对抗性输入的抽象安全级别违规程度对其进行排序，从而更详细地评估模型的安全性和鲁棒性。该研究在理论上探讨了新的抽象安全公式与现有基于抽象解释的鲁棒性验证方法之间的关系，并对新问题的复杂性进行了分析，同时在深度强化学习任务和标准DNN验证基准上进行了实证评估。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05235v1",
      "published_date": "2025-05-08 13:29:46 UTC",
      "updated_date": "2025-05-08 13:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:12:04.216044"
    },
    {
      "arxiv_id": "2505.05232v1",
      "title": "ChemRxivQuest: A Curated Chemistry Question-Answer Database Extracted from ChemRxiv Preprints",
      "title_zh": "ChemRxivQuest：一个从 ChemRxiv 预印本中提取的精选化学问答数据库\n",
      "authors": [
        "Mahmoud Amiri",
        "Thomas Bocklitz"
      ],
      "abstract": "The rapid expansion of chemistry literature poses significant challenges for\nresearchers seeking to efficiently access domain-specific knowledge. To support\nadvancements in chemistry-focused natural language processing (NLP), we present\nChemRxivQuest, a curated dataset of 970 high-quality question-answer (QA) pairs\nderived from 155 ChemRxiv preprints across 17 subfields of chemistry. Each QA\npair is explicitly linked to its source text segment to ensure traceability and\ncontextual accuracy. ChemRxivQuest was constructed using an automated pipeline\nthat combines optical character recognition (OCR), GPT-4o-based QA generation,\nand a fuzzy matching technique for answer verification. The dataset emphasizes\nconceptual, mechanistic, applied, and experimental questions, enabling\napplications in retrieval-based QA systems, search engine development, and\nfine-tuning of domain-adapted large language models. We analyze the dataset's\nstructure, coverage, and limitations, and outline future directions for\nexpansion and expert validation. ChemRxivQuest provides a foundational resource\nfor chemistry NLP research, education, and tool development.",
      "tldr_zh": "ChemRxivQuest是一个高质量的化学问答(QA)数据集，包含970个QA对，来源于ChemRxiv的155篇预印本，覆盖17个化学子领域。该数据集通过自动化流程构建，结合了光学字符识别(OCR)、基于GPT-4o的QA生成和模糊匹配技术进行答案验证，保证了溯源性和上下文准确性。ChemRxivQuest侧重于概念性、机制性、应用性和实验性问题，适用于检索式QA系统、搜索引擎开发以及领域自适应大语言模型的微调。该数据集为化学领域的NLP研究、教育和工具开发提供了一个基础资源。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05232v1",
      "published_date": "2025-05-08 13:26:33 UTC",
      "updated_date": "2025-05-08 13:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:12:15.688078"
    },
    {
      "arxiv_id": "2505.05226v1",
      "title": "Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning",
      "title_zh": "将 CASH 应用于 Bandit 算法：用于自动化机器学习的 Max K-Armed 问题\n",
      "authors": [
        "Amir Rezaei Balef",
        "Claire Vernade",
        "Katharina Eggensperger"
      ],
      "abstract": "The Combined Algorithm Selection and Hyperparameter optimization (CASH) is a\nchallenging resource allocation problem in the field of AutoML. We propose\nMaxUCB, a max $k$-armed bandit method to trade off exploring different model\nclasses and conducting hyperparameter optimization. MaxUCB is specifically\ndesigned for the light-tailed and bounded reward distributions arising in this\nsetting and, thus, provides an efficient alternative compared to classic max\n$k$-armed bandit methods assuming heavy-tailed reward distributions. We\ntheoretically and empirically evaluate our method on four standard AutoML\nbenchmarks, demonstrating superior performance over prior approaches.",
      "tldr_zh": "该论文提出了一种名为MaxUCB的max $k$-armed bandit方法，用于解决AutoML中的组合算法选择和超参数优化(CASH)问题。MaxUCB专门针对CASH场景中常见的轻尾和有界奖励分布设计，相比于假设重尾分布的传统max $k$-armed bandit方法，具有更高的效率。理论和实验评估表明，在四个标准AutoML基准测试中，MaxUCB的性能优于现有方法。该方法旨在更好地权衡探索不同模型类别和进行超参数优化。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05226v1",
      "published_date": "2025-05-08 13:18:05 UTC",
      "updated_date": "2025-05-08 13:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:12:27.619239"
    },
    {
      "arxiv_id": "2505.05211v1",
      "title": "Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality",
      "title_zh": "激励感知机器学习：稳健性、公平性、改进与因果关系\n",
      "authors": [
        "Chara Podimata"
      ],
      "abstract": "The article explores the emerging domain of incentive-aware machine learning\n(ML), which focuses on algorithmic decision-making in contexts where\nindividuals can strategically modify their inputs to influence outcomes. It\ncategorizes the research into three perspectives: robustness, aiming to design\nmodels resilient to \"gaming\"; fairness, analyzing the societal impacts of such\nsystems; and improvement/causality, recognizing situations where strategic\nactions lead to genuine personal or societal improvement. The paper introduces\na unified framework encapsulating models for these perspectives, including\noffline, online, and causal settings, and highlights key challenges such as\ndifferentiating between gaming and improvement and addressing heterogeneity\namong agents. By synthesizing findings from diverse works, we outline\ntheoretical advancements and practical solutions for robust, fair, and\ncausally-informed incentive-aware ML systems.",
      "tldr_zh": "本文探讨了激励感知机器学习(Incentive-Aware Machine Learning)这一新兴领域，该领域关注个体可以通过策略性地修改输入来影响结果的算法决策。研究将其分为三个角度：鲁棒性(Robustness)，旨在设计能够抵抗“博弈”的模型；公平性(Fairness)，分析此类系统对社会的影响；以及改进/因果关系(Improvement/Causality)，识别战略行为导致个人或社会真正改善的情况。文章提出了一个统一的框架，包含离线、在线和因果设置的模型，并强调了区分博弈和改进以及解决智能体之间异质性等关键挑战。通过综合不同研究的成果，概述了鲁棒、公平和具有因果关系的激励感知ML系统的理论进步和实际解决方案。\n",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "This literature review was published in SIGEcom Exchanges in 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05211v1",
      "published_date": "2025-05-08 13:04:32 UTC",
      "updated_date": "2025-05-08 13:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:12:39.936554"
    },
    {
      "arxiv_id": "2505.05203v1",
      "title": "LAPSO: A Unified Optimization View for Learning-Augmented Power System Operations",
      "title_zh": "LAPSO：一种用于学习增强型电力系统运行的统一优化视角\n",
      "authors": [
        "Wangkun Xu",
        "Zhongda Chu",
        "Fei Teng"
      ],
      "abstract": "With the high penetration of renewables, traditional model-based power system\noperation is challenged to deliver economic, stable, and robust decisions.\nMachine learning has emerged as a powerful modeling tool for capturing complex\ndynamics to address these challenges. However, its separate design often lacks\nsystematic integration with existing methods. To fill the gap, this paper\nproposes a holistic framework of Learning-Augmented Power System Operations\n(LAPSO, pronounced as Lap-So). Adopting a native optimization perspective,\nLAPSO is centered on the operation stage and aims to break the boundary between\ntemporally siloed power system tasks, such as forecast, operation and control,\nwhile unifying the objectives of machine learning and model-based optimizations\nat both training and inference stages. Systematic analysis and simulations\ndemonstrate the effectiveness of applying LAPSO in designing new integrated\nalgorithms, such as stability-constrained optimization (SCO) and\nobjective-based forecasting (OBF), while enabling end-to-end tracing of\ndifferent sources of uncertainties. In addition, a dedicated Python\npackage-lapso is introduced to automatically augment existing power system\noptimization models with learnable components. All code and data are available\nat https://github.com/xuwkk/lapso_exp.",
      "tldr_zh": "该论文提出了一个学习增强电力系统运行(Learning-Augmented Power System Operations, LAPSO)的统一优化框架，旨在解决高比例可再生能源带来的传统模型驱动电力系统运行的挑战。LAPSO以优化为核心，打破了电力系统任务在时间上的孤岛状态，统一了机器学习和模型优化在训练和推理阶段的目标。通过系统分析和仿真，验证了LAPSO在设计新的集成算法（如稳定性约束优化SCO和基于目标函数的预测OBF）方面的有效性，并支持对不同不确定性来源的端到端追踪。此外，还提供了一个Python包lapso，用于自动地用可学习组件增强现有的电力系统优化模型。\n",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05203v1",
      "published_date": "2025-05-08 13:00:24 UTC",
      "updated_date": "2025-05-08 13:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:12:51.895645"
    },
    {
      "arxiv_id": "2505.05197v1",
      "title": "Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt",
      "title_zh": "将社会和技术进步比作缝制一块不断增长、不断变化、充满补丁和色彩斑斓的被子\n",
      "authors": [
        "Joel Z. Leibo",
        "Alexander Sasha Vezhnevets",
        "William A. Cunningham",
        "Sébastien Krier",
        "Manfred Diaz",
        "Simon Osindero"
      ],
      "abstract": "Artificial Intelligence (AI) systems are increasingly placed in positions\nwhere their decisions have real consequences, e.g., moderating online spaces,\nconducting research, and advising on policy. Ensuring they operate in a safe\nand ethically acceptable fashion is thus critical. However, most solutions have\nbeen a form of one-size-fits-all \"alignment\". We are worried that such systems,\nwhich overlook enduring moral diversity, will spark resistance, erode trust,\nand destabilize our institutions. This paper traces the underlying problem to\nan often-unstated Axiom of Rational Convergence: the idea that under ideal\nconditions, rational agents will converge in the limit of conversation on a\nsingle ethics. Treating that premise as both optional and doubtful, we propose\nwhat we call the appropriateness framework: an alternative approach grounded in\nconflict theory, cultural evolution, multi-agent systems, and institutional\neconomics. The appropriateness framework treats persistent disagreement as the\nnormal case and designs for it by applying four principles: (1) contextual\ngrounding, (2) community customization, (3) continual adaptation, and (4)\npolycentric governance. We argue here that adopting these design principles is\na good way to shift the main alignment metaphor from moral unification to a\nmore productive metaphor of conflict management, and that taking this step is\nboth desirable and urgent.",
      "tldr_zh": "本文批判了AI伦理对齐中“一刀切”的解决方案，认为其忽视了道德的多样性，可能引发抵制并破坏信任。作者质疑“理性趋同公理”，即理想条件下理性个体最终会在伦理上趋同的观点。作为替代，作者提出了“适当性框架”，该框架基于冲突理论、文化演化、多智能体系统和制度经济学，将持久的分歧视为常态，并通过情境基础、社群定制、持续适应和多中心治理四个原则进行设计。该框架旨在将AI伦理对齐的主要隐喻从道德统一转变为更具建设性的冲突管理，并强调了采取这一转变的必要性和紧迫性。\n",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.05197v1",
      "published_date": "2025-05-08 12:55:07 UTC",
      "updated_date": "2025-05-08 12:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:13:04.179888"
    },
    {
      "arxiv_id": "2505.05195v1",
      "title": "Concept-Based Unsupervised Domain Adaptation",
      "title_zh": "基于概念的无监督领域自适应\n",
      "authors": [
        "Xinyue Xu",
        "Yueying Hu",
        "Hui Tang",
        "Yi Qin",
        "Lu Mi",
        "Hao Wang",
        "Xiaomeng Li"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) enhance interpretability by explaining\npredictions through human-understandable concepts but typically assume that\ntraining and test data share the same distribution. This assumption often fails\nunder domain shifts, leading to degraded performance and poor generalization.\nTo address these limitations and improve the robustness of CBMs, we propose the\nConcept-based Unsupervised Domain Adaptation (CUDA) framework. CUDA is designed\nto: (1) align concept representations across domains using adversarial\ntraining, (2) introduce a relaxation threshold to allow minor domain-specific\ndifferences in concept distributions, thereby preventing performance drop due\nto over-constraints of these distributions, (3) infer concepts directly in the\ntarget domain without requiring labeled concept data, enabling CBMs to adapt to\ndiverse domains, and (4) integrate concept learning into conventional domain\nadaptation (DA) with theoretical guarantees, improving interpretability and\nestablishing new benchmarks for DA. Experiments demonstrate that our approach\nsignificantly outperforms the state-of-the-art CBM and DA methods on real-world\ndatasets.",
      "tldr_zh": "本文提出了基于概念的无监督领域自适应框架(CUDA)，旨在提升概念瓶颈模型(CBMs)在领域迁移下的鲁棒性和泛化能力。CUDA通过对抗训练对齐跨域的概念表示，并引入松弛阈值以容忍概念分布中的细微领域差异，避免过度约束导致的性能下降。该框架还支持在目标域直接推断概念，无需标签数据，并整合概念学习到传统领域自适应(DA)中，提供理论保证。实验结果表明，CUDA在真实数据集上显著优于现有CBM和DA方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05195v1",
      "published_date": "2025-05-08 12:52:02 UTC",
      "updated_date": "2025-05-08 12:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:13:15.788519"
    },
    {
      "arxiv_id": "2505.05190v1",
      "title": "Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks",
      "title_zh": "通过自信息重写攻击揭示文本水印的弱点\n",
      "authors": [
        "Yixin Cheng",
        "Hongcheng Guo",
        "Yangming Li",
        "Leonid Sigal"
      ],
      "abstract": "Text watermarking aims to subtly embed statistical signals into text by\ncontrolling the Large Language Model (LLM)'s sampling process, enabling\nwatermark detectors to verify that the output was generated by the specified\nmodel. The robustness of these watermarking algorithms has become a key factor\nin evaluating their effectiveness. Current text watermarking algorithms embed\nwatermarks in high-entropy tokens to ensure text quality. In this paper, we\nreveal that this seemingly benign design can be exploited by attackers, posing\na significant risk to the robustness of the watermark. We introduce a generic\nefficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA),\nwhich leverages the vulnerability by calculating the self-information of each\ntoken to identify potential pattern tokens and perform targeted attack. Our\nwork exposes a widely prevalent vulnerability in current watermarking\nalgorithms. The experimental results show SIRA achieves nearly 100% attack\nsuccess rates on seven recent watermarking methods with only 0.88 USD per\nmillion tokens cost. Our approach does not require any access to the watermark\nalgorithms or the watermarked LLM and can seamlessly transfer to any LLM as the\nattack model, even mobile-level models. Our findings highlight the urgent need\nfor more robust watermarking.",
      "tldr_zh": "本文揭示了现有文本水印算法中的一个普遍漏洞，该漏洞源于水印通常嵌入在高熵token中的设计。研究者提出了一种名为自信息重写攻击(Self-Information Rewrite Attack, SIRA)的通用高效的释义攻击方法，该方法通过计算每个token的自信息来识别潜在的模式token并进行针对性攻击。实验表明，SIRA能够以极低的成本（每百万token 0.88美元）对七种最新的水印方法实现接近100%的攻击成功率。该攻击无需访问水印算法或带水印的LLM，并且可以无缝转移到任何LLM作为攻击模型。这项研究强调了对更强大的水印技术的需求。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025 Accpeted",
      "pdf_url": "http://arxiv.org/pdf/2505.05190v1",
      "published_date": "2025-05-08 12:39:00 UTC",
      "updated_date": "2025-05-08 12:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:13:28.020876"
    },
    {
      "arxiv_id": "2505.05189v1",
      "title": "Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models",
      "title_zh": "Biomed-DPT：用于生物医学视觉-语言模型的双模态提示调优\n",
      "authors": [
        "Wei Peng",
        "Kang Liu",
        "Jianchen Hu",
        "Meng Zhang"
      ],
      "abstract": "Prompt learning is one of the most effective paradigms for adapting\npre-trained vision-language models (VLMs) to the biomedical image\nclassification tasks in few shot scenarios. However, most of the current prompt\nlearning methods only used the text prompts and ignored the particular\nstructures (such as the complex anatomical structures and subtle pathological\nfeatures) in the biomedical images. In this work, we propose Biomed-DPT, a\nknowledge-enhanced dual modality prompt tuning technique. In designing the text\nprompt, Biomed-DPT constructs a dual prompt including the template-driven\nclinical prompts and the large language model (LLM)-driven domain-adapted\nprompts, then extracts the clinical knowledge from the domain-adapted prompts\nthrough the knowledge distillation technique. In designing the vision prompt,\nBiomed-DPT introduces the zero vector as a soft prompt to leverage attention\nre-weighting so that the focus on non-diagnostic regions and the recognition of\nnon-critical pathological features are avoided. Biomed-DPT achieves an average\nclassification accuracy of 66.14\\% across 11 biomedical image datasets covering\n9 modalities and 10 organs, with performance reaching 78.06\\% in base classes\nand 75.97\\% in novel classes, surpassing the Context Optimization (CoOp) method\nby 6.20\\%, 3.78\\%, and 8.04\\%, respectively. Our code are available at\n\\underline{https://github.com/Kanyooo/Biomed-DPT}.",
      "tldr_zh": "该论文提出了Biomed-DPT，一种用于生物医学视觉-语言模型的双模态Prompt Tuning技术。该方法针对现有Prompt Learning方法忽略生物医学图像结构的缺点，设计了文本和视觉双重Prompt。在文本Prompt方面，Biomed-DPT构建了包含模板驱动的临床Prompt和大型语言模型(LLM)驱动的领域自适应Prompt的双重Prompt，并通过知识蒸馏提取临床知识。在视觉Prompt方面，引入零向量作为软Prompt，利用注意力重加权避免关注非诊断区域和识别非关键病理特征。实验结果表明，Biomed-DPT在11个生物医学图像数据集上取得了平均66.14%的分类准确率，超过了CoOp方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05189v1",
      "published_date": "2025-05-08 12:37:51 UTC",
      "updated_date": "2025-05-08 12:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:13:39.907398"
    },
    {
      "arxiv_id": "2505.05181v1",
      "title": "Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation",
      "title_zh": "随机变分传播：反向传播的局部、可扩展和高效替代方案\n",
      "authors": [
        "Bojian Yin",
        "Federico Corradi"
      ],
      "abstract": "Backpropagation (BP) is the cornerstone of deep learning, but its reliance on\nglobal gradient synchronization limits scalability and imposes significant\nmemory overhead. We propose Stochastic Variational Propagation (SVP), a\nscalable alternative that reframes training as hierarchical variational\ninference. SVP treats layer activations as latent variables and optimizes local\nEvidence Lower Bounds (ELBOs), enabling independent, local updates while\npreserving global coherence. However, directly applying KL divergence in\nlayer-wise ELBOs risks inter-layer's representation collapse due to excessive\ncompression. To prevent this, SVP projects activations into low-dimensional\nspaces via fixed random matrices, ensuring information preservation and\nrepresentational diversity. Combined with a feature alignment loss for\ninter-layer consistency, SVP achieves competitive accuracy with BP across\ndiverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to\nImageNet), reduces memory usage by up to 4x, and significantly improves\nscalability. More broadly, SVP introduces a probabilistic perspective to deep\nrepresentation learning, opening pathways toward more modular and interpretable\nneural network design.",
      "tldr_zh": "本文提出了一种名为随机变分传播(Stochastic Variational Propagation, SVP)的可扩展反向传播(Backpropagation, BP)替代方案。SVP将训练过程重新定义为分层变分推断，将层激活视为潜在变量，并优化局部证据下界(Evidence Lower Bounds, ELBOs)，从而实现独立的局部更新。为防止层间表示崩溃，SVP通过固定的随机矩阵将激活投影到低维空间，并结合特征对齐损失以保持层间一致性。实验结果表明，SVP在多种架构和数据集上实现了与BP相当的精度，同时显著降低了内存使用并提高了可扩展性。SVP为深度表征学习引入了一种概率视角，为更模块化和可解释的神经网络设计开辟了道路。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05181v1",
      "published_date": "2025-05-08 12:32:29 UTC",
      "updated_date": "2025-05-08 12:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:13:52.009205"
    },
    {
      "arxiv_id": "2505.05177v1",
      "title": "MARK: Memory Augmented Refinement of Knowledge",
      "title_zh": "MARK：知识的记忆增强式精炼",
      "authors": [
        "Anish Ganguli",
        "Prabal Deb",
        "Debleena Banerjee"
      ],
      "abstract": "Large Language Models (LLMs) assist in specialized tasks but struggle to\nalign with evolving domain knowledge without costly fine-tuning. Domain\nknowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid')\nand generally accepted principles (e.g., ethical standards); Refined Memory:\nEvolving insights shaped by business needs and real-world changes. However, a\nsignificant gap often exists between a domain expert's deep, nuanced\nunderstanding and the system's domain knowledge, which can hinder accurate\ninformation retrieval and application. Our Memory-Augmented Refinement of\nKnowledge (MARK) framework enables LLMs to continuously learn without\nretraining by leveraging structured refined memory, inspired by the Society of\nMind. MARK operates through specialized agents, each serving a distinct role:\nResidual Refined Memory Agent: Stores and retrieves domain-specific insights to\nmaintain context over time; User Question Refined Memory Agent: Captures\nuser-provided facts, abbreviations, and terminology for better comprehension;\nLLM Response Refined Memory Agent: Extracts key elements from responses for\nrefinement and personalization. These agents analyse stored refined memory,\ndetect patterns, resolve contradictions, and improve response accuracy.\nTemporal factors like recency and frequency prioritize relevant information\nwhile discarding outdated insights. MARK enhances LLMs in multiple ways: Ground\nTruth Strategy: Reduces hallucinations by establishing a structured reference;\nDomain-Specific Adaptation: Essential for fields like healthcare, law, and\nmanufacturing, where proprietary insights are absent from public datasets;\nPersonalized AI Assistants: Improves virtual assistants by remembering user\npreferences, ensuring coherent responses over time.",
      "tldr_zh": "该论文提出了一个名为MARK（Memory Augmented Refinement of Knowledge）的框架，旨在使大型语言模型(LLMs)能够在无需昂贵微调的情况下持续学习并适应不断发展的领域知识。MARK框架受到心智社会理论的启发，利用结构化的精炼记忆，通过多个专门的智能体协同工作：残差精炼记忆智能体、用户问题精炼记忆智能体和LLM响应精炼记忆智能体，分别负责存储和检索领域知识、捕获用户提供的信息以及提取响应的关键要素。MARK通过分析存储的精炼记忆，检测模式，解决矛盾并提高响应准确性，从而减少幻觉，实现领域特定适应和个性化AI助手。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05177v1",
      "published_date": "2025-05-08 12:28:00 UTC",
      "updated_date": "2025-05-08 12:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:14:04.121855"
    },
    {
      "arxiv_id": "2505.05170v1",
      "title": "Dukawalla: Voice Interfaces for Small Businesses in Africa",
      "title_zh": "Dukawalla：非洲小企业的语音界面\n",
      "authors": [
        "Elizabeth Ankrah",
        "Stephanie Nyairo",
        "Mercy Muchai",
        "Kagonya Awori",
        "Millicent Ochieng",
        "Mark Kariuki",
        "Jacki O'Neill"
      ],
      "abstract": "Small and medium sized businesses often struggle with data driven decision\nmaking do to a lack of advanced analytics tools, especially in African\ncountries where they make up a majority of the workforce. Though many tools\nexist they are not designed to fit into the ways of working of SMB workers who\nare mobile first, have limited time to learn new workflows, and for whom social\nand business are tightly coupled. To address this, the Dukawalla prototype was\ncreated. This intelligent assistant bridges the gap between raw business data,\nand actionable insights by leveraging voice interaction and the power of\ngenerative AI. Dukawalla provides an intuitive way for business owners to\ninteract with their data, aiding in informed decision making. This paper\nexamines Dukawalla's deployment across SMBs in Nairobi, focusing on their\nexperiences using this voice based assistant to streamline data collection and\nprovide business insights",
      "tldr_zh": "非洲的中小型企业在数据驱动的决策方面面临挑战，因为缺乏先进的分析工具。Dukawalla原型旨在解决这个问题，它是一个智能助手，利用语音交互和生成式AI，弥合了原始业务数据和可操作的见解之间的差距。Dukawalla为企业主提供了一种直观的方式来与他们的数据交互，从而帮助他们做出明智的决策。本文探讨了Dukawalla在内罗毕中小企业的部署情况，重点关注他们使用这种基于语音的助手来简化数据收集和提供业务见解的体验。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05170v1",
      "published_date": "2025-05-08 12:13:16 UTC",
      "updated_date": "2025-05-08 12:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:14:15.911380"
    },
    {
      "arxiv_id": "2505.05145v1",
      "title": "Understanding In-context Learning of Addition via Activation Subspaces",
      "title_zh": "通过激活子空间理解加法的上下文学习\n",
      "authors": [
        "Xinyan Hu",
        "Kayo Yin",
        "Michael I. Jordan",
        "Jacob Steinhardt",
        "Lijie Chen"
      ],
      "abstract": "To perform in-context learning, language models must extract signals from\nindividual few-shot examples, aggregate these into a learned prediction rule,\nand then apply this rule to new examples. How is this implemented in the\nforward pass of modern transformer models? To study this, we consider a\nstructured family of few-shot learning tasks for which the true prediction rule\nis to add an integer $k$ to the input. We find that Llama-3-8B attains high\naccuracy on this task for a range of $k$, and localize its few-shot ability to\njust three attention heads via a novel optimization approach. We further show\nthe extracted signals lie in a six-dimensional subspace, where four of the\ndimensions track the unit digit and the other two dimensions track overall\nmagnitude. We finally examine how these heads extract information from\nindividual few-shot examples, identifying a self-correction mechanism in which\nmistakes from earlier examples are suppressed by later examples. Our results\ndemonstrate how tracking low-dimensional subspaces across a forward pass can\nprovide insight into fine-grained computational structures.",
      "tldr_zh": "该论文研究了语言模型如何在上下文学习中执行加法任务，特别是Llama-3-8B模型在少量样本学习中如何实现加法运算。研究发现，模型在执行加法任务时，其能力集中在三个注意力头上，并且提取的信号位于一个六维子空间中。这个子空间中，四个维度追踪个位数，另外两个维度追踪整体大小。此外，研究还揭示了一种自纠正机制，即后面的例子可以抑制前面例子中的错误。这项工作表明，通过追踪前向传播中的低维子空间，可以深入了解模型细粒度的计算结构。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.05145v1",
      "published_date": "2025-05-08 11:32:46 UTC",
      "updated_date": "2025-05-08 11:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:14:28.082796"
    },
    {
      "arxiv_id": "2505.05138v1",
      "title": "Guiding Evolutionary AutoEncoder Training with Activation-Based Pruning Operators",
      "title_zh": "利用基于激活的剪枝算子指导进化自编码器训练\n",
      "authors": [
        "Steven Jorgensen",
        "Erik Hemberg",
        "Jamal Toutouh",
        "Una-May O'Reilly"
      ],
      "abstract": "This study explores a novel approach to neural network pruning using\nevolutionary computation, focusing on simultaneously pruning the encoder and\ndecoder of an autoencoder. We introduce two new mutation operators that use\nlayer activations to guide weight pruning. Our findings reveal that one of\nthese activation-informed operators outperforms random pruning, resulting in\nmore efficient autoencoders with comparable performance to canonically trained\nmodels. Prior work has established that autoencoder training is effective and\nscalable with a spatial coevolutionary algorithm that cooperatively coevolves a\npopulation of encoders with a population of decoders, rather than one\nautoencoder. We evaluate how the same activity-guided mutation operators\ntransfer to this context. We find that random pruning is better than guided\npruning, in the coevolutionary setting. This suggests activation-based guidance\nproves more effective in low-dimensional pruning environments, where\nconstrained sample spaces can lead to deviations from true uniformity in\nrandomization. Conversely, population-driven strategies enhance robustness by\nexpanding the total pruning dimensionality, achieving statistically uniform\nrandomness that better preserves system dynamics. We experiment with pruning\naccording to different schedules and present best combinations of operator and\nschedule for the canonical and coevolving populations cases.",
      "tldr_zh": "该研究提出了一种新颖的神经网络剪枝方法，利用进化计算同时剪枝自编码器的编码器和解码器。引入了两种新的基于层激活的变异算子来指导权重剪枝。实验结果表明，其中一种基于激活信息的算子优于随机剪枝，从而产生了更高效的自编码器，其性能与标准训练模型相当。研究发现，在空间协同进化算法中，随机剪枝优于引导剪枝。这表明，基于激活的指导在低维剪枝环境中更有效，而群体驱动的策略通过扩展总剪枝维度来增强鲁棒性，实现统计均匀的随机性，从而更好地保持系统动态。研究还实验了不同的剪枝策略，并提出了标准和协同进化群体案例中算子和策略的最佳组合。\n",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted to The Genetic and Evolutionary Computation Conference\n  (GECCO 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.05138v1",
      "published_date": "2025-05-08 11:21:29 UTC",
      "updated_date": "2025-05-08 11:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:14:40.243425"
    },
    {
      "arxiv_id": "2505.05115v1",
      "title": "Is there a half-life for the success rates of AI agents?",
      "title_zh": "AI 智能体的成功率是否存在半衰期？\n",
      "authors": [
        "Toby Ord"
      ],
      "abstract": "Building on the recent empirical work of Kwa et al. (2025), I show that\nwithin their suite of research-engineering tasks the performance of AI agents\non longer-duration tasks can be explained by an extremely simple mathematical\nmodel -- a constant rate of failing during each minute a human would take to do\nthe task. This implies an exponentially declining success rate with the length\nof the task and that each agent could be characterised by its own half-life.\nThis empirical regularity allows us to estimate the success rate for an agent\nat different task lengths. And the fact that this model is a good fit for the\ndata is suggestive of the underlying causes of failure on longer tasks -- that\nthey involve increasingly large sets of subtasks where failing any one fails\nthe task. Whether this model applies more generally on other suites of tasks is\nunknown and an important subject for further work.",
      "tldr_zh": "本文基于Kwa et al. (2025)的研究，发现AI agent在一系列研究工程任务中的表现，尤其是长时任务，可以用一个简单的数学模型解释：agent在人类完成任务的每分钟内，以恒定速率失败。这意味着成功率随任务长度呈指数下降，每个agent都可以用其“半衰期”来表征。该模型能够预测agent在不同任务长度下的成功率，并暗示长时任务失败的根本原因在于子任务数量过多，任何一个子任务的失败都会导致整个任务失败。该模型是否适用于其他任务集合尚不清楚，有待进一步研究。\n",
      "categories": [
        "cs.AI",
        "68T42",
        "I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05115v1",
      "published_date": "2025-05-08 10:31:03 UTC",
      "updated_date": "2025-05-08 10:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:14:51.899508"
    },
    {
      "arxiv_id": "2505.05108v1",
      "title": "Multi-agent Embodied AI: Advances and Future Directions",
      "title_zh": "多智能体具身人工智能：进展与未来方向\n",
      "authors": [
        "Zhaohan Feng",
        "Ruiqi Xue",
        "Lei Yuan",
        "Yang Yu",
        "Ning Ding",
        "Meiqin Liu",
        "Bingzhao Gao",
        "Jian Sun",
        "Gang Wang"
      ],
      "abstract": "Embodied artificial intelligence (Embodied AI) plays a pivotal role in the\napplication of advanced technologies in the intelligent era, where AI systems\nare integrated with physical bodies that enable them to perceive, reason, and\ninteract with their environments. Through the use of sensors for input and\nactuators for action, these systems can learn and adapt based on real-world\nfeedback, allowing them to perform tasks effectively in dynamic and\nunpredictable environments. As techniques such as deep learning (DL),\nreinforcement learning (RL), and large language models (LLMs) mature, embodied\nAI has become a leading field in both academia and industry, with applications\nspanning robotics, healthcare, transportation, and manufacturing. However, most\nresearch has focused on single-agent systems that often assume static, closed\nenvironments, whereas real-world embodied AI must navigate far more complex\nscenarios. In such settings, agents must not only interact with their\nsurroundings but also collaborate with other agents, necessitating\nsophisticated mechanisms for adaptation, real-time learning, and collaborative\nproblem-solving. Despite increasing interest in multi-agent systems, existing\nresearch remains narrow in scope, often relying on simplified models that fail\nto capture the full complexity of dynamic, open environments for multi-agent\nembodied AI. Moreover, no comprehensive survey has systematically reviewed the\nadvancements in this area. As embodied AI rapidly evolves, it is crucial to\ndeepen our understanding of multi-agent embodied AI to address the challenges\npresented by real-world applications. To fill this gap and foster further\ndevelopment in the field, this paper reviews the current state of research,\nanalyzes key contributions, and identifies challenges and future directions,\nproviding insights to guide innovation and progress in this field.",
      "tldr_zh": "本文综述了多智能体具身智能(Multi-agent Embodied AI)领域的研究进展，该领域旨在将AI系统与物理实体结合，使其能够感知、推理并与环境互动。 现有研究主要集中在静态、封闭环境中的单智能体系统，而现实世界需要智能体在动态、开放的环境中与其他智能体协作。本文回顾了当前的研究现状，分析了关键贡献，并指出了该领域面临的挑战和未来发展方向，旨在促进多智能体具身智能在机器人、医疗、交通和制造等领域的创新和进步。\n",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05108v1",
      "published_date": "2025-05-08 10:13:53 UTC",
      "updated_date": "2025-05-08 10:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:15:03.832235"
    },
    {
      "arxiv_id": "2505.05106v1",
      "title": "A Neuro-Symbolic Framework for Sequence Classification with Relational and Temporal Knowledge",
      "title_zh": "一种用于序列分类的神经符号框架，具有关系和时间知识",
      "authors": [
        "Luca Salvatore Lorello",
        "Marco Lippi",
        "Stefano Melacci"
      ],
      "abstract": "One of the goals of neuro-symbolic artificial intelligence is to exploit\nbackground knowledge to improve the performance of learning tasks. However,\nmost of the existing frameworks focus on the simplified scenario where\nknowledge does not change over time and does not cover the temporal dimension.\nIn this work we consider the much more challenging problem of knowledge-driven\nsequence classification where different portions of knowledge must be employed\nat different timesteps, and temporal relations are available. Our experimental\nevaluation compares multi-stage neuro-symbolic and neural-only architectures,\nand it is conducted on a newly-introduced benchmarking framework. Results\ndemonstrate the challenging nature of this novel setting, and also highlight\nunder-explored shortcomings of neuro-symbolic methods, representing a precious\nreference for future research.",
      "tldr_zh": "本文提出了一种神经符号框架，用于处理具有关系和时间知识的序列分类问题。该框架旨在利用背景知识提升学习任务的性能，尤其关注知识随时间变化以及包含时间关系的情况。研究者对比了多阶段神经符号架构和纯神经架构，并在新引入的基准框架上进行了实验评估。实验结果表明，该框架面临着挑战，并揭示了神经符号方法中一些未被充分探索的缺点，为未来的研究提供了参考。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05106v1",
      "published_date": "2025-05-08 10:10:00 UTC",
      "updated_date": "2025-05-08 10:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:15:15.775947"
    },
    {
      "arxiv_id": "2505.05086v1",
      "title": "Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning",
      "title_zh": "超越低秩分解：一种用于高效设备端学习的捷径方法\n",
      "authors": [
        "Le-Trung Nguyen",
        "Ael Quelennec",
        "Van-Tam Nguyen",
        "Enzo Tartaglione"
      ],
      "abstract": "On-device learning has emerged as a promising direction for AI development,\nparticularly because of its potential to reduce latency issues and mitigate\nprivacy risks associated with device-server communication, while improving\nenergy efficiency. Despite these advantages, significant memory and\ncomputational constraints still represent major challenges for its deployment.\nDrawing on previous studies on low-rank decomposition methods that address\nactivation memory bottlenecks in backpropagation, we propose a novel shortcut\napproach as an alternative. Our analysis and experiments demonstrate that our\nmethod can reduce activation memory usage, even up to $120.09\\times$ compared\nto vanilla training, while also reducing overall training FLOPs up to\n$1.86\\times$ when evaluated on traditional benchmarks.",
      "tldr_zh": "本文提出了一种新的捷径方法，旨在解决设备端学习中内存和计算资源受限的问题，该方法是低秩分解方法的一种替代方案。通过减少反向传播过程中的激活内存瓶颈，该方法显著降低了激活内存的使用，最高可达传统训练的120.09倍。实验结果表明，在传统基准测试中，该方法还能将整体训练FLOPs降低高达1.86倍，从而提高了设备端学习的效率。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05086v1",
      "published_date": "2025-05-08 09:34:15 UTC",
      "updated_date": "2025-05-08 09:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:15:27.773241"
    },
    {
      "arxiv_id": "2505.05071v1",
      "title": "FG-CLIP: Fine-Grained Visual and Textual Alignment",
      "title_zh": "FG-CLIP：细粒度的视觉和文本对齐\n",
      "authors": [
        "Chunyu Xie",
        "Bin Wang",
        "Fanjing Kong",
        "Jincheng Li",
        "Dawei Liang",
        "Gengshen Zhang",
        "Dawei Leng",
        "Yuhui Yin"
      ],
      "abstract": "Contrastive Language-Image Pre-training (CLIP) excels in multimodal tasks\nsuch as image-text retrieval and zero-shot classification but struggles with\nfine-grained understanding due to its focus on coarse-grained short captions.\nTo address this, we propose Fine-Grained CLIP (FG-CLIP), which enhances\nfine-grained understanding through three key innovations. First, we leverage\nlarge multimodal models to generate 1.6 billion long caption-image pairs for\ncapturing global-level semantic details. Second, a high-quality dataset is\nconstructed with 12 million images and 40 million region-specific bounding\nboxes aligned with detailed captions to ensure precise, context-rich\nrepresentations. Third, 10 million hard fine-grained negative samples are\nincorporated to improve the model's ability to distinguish subtle semantic\ndifferences. Corresponding training methods are meticulously designed for these\ndata. Extensive experiments demonstrate that FG-CLIP outperforms the original\nCLIP and other state-of-the-art methods across various downstream tasks,\nincluding fine-grained understanding, open-vocabulary object detection,\nimage-text retrieval, and general multimodal benchmarks. These results\nhighlight FG-CLIP's effectiveness in capturing fine-grained image details and\nimproving overall model performance. The related data, code, and models are\navailable at https://github.com/360CVGroup/FG-CLIP.",
      "tldr_zh": "FG-CLIP旨在提升CLIP模型在细粒度视觉和文本对齐方面的能力，解决CLIP在处理图像-文本检索和零样本分类等任务时，由于侧重于粗粒度的短文本描述而导致的细粒度理解不足问题。该方法通过三个创新点实现：利用大型多模态模型生成16亿长文本描述-图像对以捕捉全局语义细节；构建包含1200万图像和4000万区域特定边界框的高质量数据集，并配以详细的文本描述，确保精确的上下文表示；以及引入1000万个困难的细粒度负样本，提高模型区分细微语义差异的能力。实验结果表明，FG-CLIP在细粒度理解、开放词汇目标检测、图像-文本检索以及通用多模态基准测试中均优于原始CLIP和其他先进方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05071v1",
      "published_date": "2025-05-08 09:06:53 UTC",
      "updated_date": "2025-05-08 09:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:15:40.227406"
    },
    {
      "arxiv_id": "2505.05059v1",
      "title": "Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search",
      "title_zh": "利用束搜索增强强化学习以进行模拟集成电路的布局规划\n",
      "authors": [
        "Sandro Junior Della Rovere",
        "Davide Basso",
        "Luca Bortolussi",
        "Mirjana Videnovic-Misic",
        "Husni Habal"
      ],
      "abstract": "The layout of analog ICs requires making complex trade-offs, while addressing\ndevice physics and variability of the circuits. This makes full automation with\nlearning-based solutions hard to achieve. However, reinforcement learning (RL)\nhas recently reached significant results, particularly in solving the\nfloorplanning problem. This paper presents a hybrid method that combines RL\nwith a beam (BS) strategy. The BS algorithm enhances the agent's inference\nprocess, allowing for the generation of flexible floorplans by accomodating\nvarious objective weightings, and addressing congestion without without the\nneed for policy retraining or fine-tuning. Moreover, the RL agent's\ngeneralization ability stays intact, along with its efficient handling of\ncircuit features and constraints. Experimental results show approx. 5-85%\nimprovement in area, dead space and half-perimeter wire length compared to a\nstandard RL application, along with higher rewards for the agent. Moreover,\nperformance and efficiency align closely with those of existing\nstate-of-the-art techniques.",
      "tldr_zh": "本文提出了一种结合强化学习(RL)和束搜索(Beam Search, BS)的混合方法，用于改进模拟集成电路(Analog ICs)的布局规划。束搜索算法增强了RL代理的推理过程，允许生成灵活的布局方案，适应不同的目标权重，并解决拥塞问题，而无需重新训练或微调策略。实验结果表明，与标准RL应用相比，该方法在面积、死区和半周长线长方面有约5-85%的改进，同时代理获得了更高的奖励。此外，性能和效率与现有的最先进技术非常接近。该方法保持了RL代理的泛化能力，以及有效处理电路特征和约束的能力。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in Proceedings of the 21st International Conference on\n  Synthesis, Modeling, Analysis and Simulation Methods, and Applications to\n  Circuit Design (SMACD 2025). 4 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05059v1",
      "published_date": "2025-05-08 08:50:32 UTC",
      "updated_date": "2025-05-08 08:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:15:51.968128"
    },
    {
      "arxiv_id": "2505.05056v1",
      "title": "Teochew-Wild: The First In-the-wild Teochew Dataset with Orthographic Annotations",
      "title_zh": "Teochew-Wild：首个带有正字注释的潮州话真实场景数据集\n",
      "authors": [
        "Linrong Pan",
        "Chenglong Jiang",
        "Gaoze Hou",
        "Ying Gao"
      ],
      "abstract": "This paper reports the construction of the Teochew-Wild, a speech corpus of\nthe Teochew dialect. The corpus includes 18.9 hours of in-the-wild Teochew\nspeech data from multiple speakers, covering both formal and colloquial\nexpressions, with precise orthographic and pinyin annotations. Additionally, we\nprovide supplementary text processing tools and resources to propel research\nand applications in speech tasks for this low-resource language, such as\nautomatic speech recognition (ASR) and text-to-speech (TTS). To the best of our\nknowledge, this is the first publicly available Teochew dataset with accurate\northographic annotations. We conduct experiments on the corpus, and the results\nvalidate its effectiveness in ASR and TTS tasks.",
      "tldr_zh": "该论文介绍了潮州话-Wild (Teochew-Wild) 语料库，这是首个带有正字注释的潮州话口语数据集。该语料库包含18.9小时的潮州话口语数据，涵盖正式和口语表达，并具有精确的正字和拼音注释。此外，论文还提供了文本处理工具和资源，以促进该低资源语言的语音任务研究和应用，例如自动语音识别 (ASR) 和文本到语音 (TTS)。实验结果验证了该语料库在 ASR 和 TTS 任务中的有效性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05056v1",
      "published_date": "2025-05-08 08:47:11 UTC",
      "updated_date": "2025-05-08 08:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:16:03.984208"
    },
    {
      "arxiv_id": "2505.05054v1",
      "title": "Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction",
      "title_zh": "无需重建即可从傅里叶叠层显微镜测量结果中进行直接图像分类\n",
      "authors": [
        "Navya Sonal Agarwal",
        "Jan Philipp Schneider",
        "Kanchana Vaishnavi Gandikota",
        "Syed Muhammad Kazim",
        "John Meshreki",
        "Ivo Ihrke",
        "Michael Moeller"
      ],
      "abstract": "The computational imaging technique of Fourier Ptychographic Microscopy (FPM)\nenables high-resolution imaging with a wide field of view and can serve as an\nextremely valuable tool, e.g. in the classification of cells in medical\napplications. However, reconstructing a high-resolution image from tens or even\nhundreds of measurements is computationally expensive, particularly for a wide\nfield of view. Therefore, in this paper, we investigate the idea of classifying\nthe image content in the FPM measurements directly without performing a\nreconstruction step first. We show that Convolutional Neural Networks (CNN) can\nextract meaningful information from measurement sequences, significantly\noutperforming the classification on a single band-limited image (up to 12 %)\nwhile being significantly more efficient than a reconstruction of a\nhigh-resolution image. Furthermore, we demonstrate that a learned multiplexing\nof several raw measurements allows maintaining the classification accuracy\nwhile reducing the amount of data (and consequently also the acquisition time)\nsignificantly.",
      "tldr_zh": "该论文提出了一种直接从傅里叶叠层显微镜(FPM)测量数据进行图像分类的方法，无需先进行图像重建。研究表明，卷积神经网络(CNN)可以直接从测量序列中提取有效信息，分类性能显著优于基于单个带限图像的分类（提升高达12%），并且比重建高分辨率图像更高效。此外，研究还证明，通过学习对多个原始测量数据进行多路复用，可以在保持分类精度的同时显著减少数据量（从而缩短采集时间）。\n",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "ISCS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05054v1",
      "published_date": "2025-05-08 08:46:28 UTC",
      "updated_date": "2025-05-08 08:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:16:15.744947"
    },
    {
      "arxiv_id": "2505.05040v1",
      "title": "Image-Text Relation Prediction for Multilingual Tweets",
      "title_zh": "面向多语种推文的图像-文本关系预测\n",
      "authors": [
        "Matīss Rikters",
        "Edison Marrese-Taylor"
      ],
      "abstract": "Various social networks have been allowing media uploads for over a decade\nnow. Still, it has not always been clear what is their relation with the posted\ntext or even if there is any at all. In this work, we explore how multilingual\nvision-language models tackle the task of image-text relation prediction in\ndifferent languages, and construct a dedicated balanced benchmark data set from\nTwitter posts in Latvian along with their manual translations into English. We\ncompare our results to previous work and show that the more recently released\nvision-language model checkpoints are becoming increasingly capable at this\ntask, but there is still much room for further improvement.",
      "tldr_zh": "本文研究了多语言视觉-语言模型在多语言推文图像-文本关系预测任务中的表现。作者构建了一个专门的平衡基准数据集，该数据集由拉脱维亚语的Twitter帖子及其人工翻译的英语组成。通过对比实验，表明最新的视觉-语言模型在该任务上的能力不断提高，但仍有很大的改进空间。该研究为理解多语言社交媒体内容及其模态关系提供了有价值的见解。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05040v1",
      "published_date": "2025-05-08 08:23:20 UTC",
      "updated_date": "2025-05-08 08:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:16:27.820515"
    },
    {
      "arxiv_id": "2505.05029v1",
      "title": "A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons",
      "title_zh": "用于大型语言模型多智能体系统的声誉系统，以避免公地悲剧\n",
      "authors": [
        "Siyue Ren",
        "Wanli Fu",
        "Xinkun Zou",
        "Chen Shen",
        "Yi Cai",
        "Chen Chu",
        "Zhen Wang",
        "Shuyue Hu"
      ],
      "abstract": "The tragedy of the commons, where individual self-interest leads to\ncollectively disastrous outcomes, is a pervasive challenge in human society.\nRecent studies have demonstrated that similar phenomena can arise in generative\nmulti-agent systems (MASs). To address this challenge, this paper explores the\nuse of reputation systems as a remedy. We propose RepuNet, a dynamic,\ndual-level reputation framework that models both agent-level reputation\ndynamics and system-level network evolution. Specifically, driven by direct\ninteractions and indirect gossip, agents form reputations for both themselves\nand their peers, and decide whether to connect or disconnect other agents for\nfuture interactions. Through two distinct scenarios, we show that RepuNet\neffectively mitigates the 'tragedy of the commons', promoting and sustaining\ncooperation in generative MASs. Moreover, we find that reputation systems can\ngive rise to rich emergent behaviors in generative MASs, such as the formation\nof cooperative clusters, the social isolation of exploitative agents, and the\npreference for sharing positive gossip rather than negative ones.",
      "tldr_zh": "本文提出RepuNet，一个用于大型语言模型(LLM)驱动的多智能体系统(MAS)的声誉系统，旨在解决“公地悲剧”问题。RepuNet是一个动态的双层声誉框架，模拟智能体层面的声誉动态和系统层面的网络演化。通过直接交互和间接信息传播，智能体形成自身和他人的声誉，并决定是否与其他智能体连接或断开连接。在两个不同的场景中，实验表明RepuNet有效地缓解了“公地悲剧”，促进了生成式MAS中的合作。此外，声誉系统还能在生成式MAS中产生丰富的涌现行为，例如合作集群的形成、剥削型智能体的社会隔离以及偏好分享积极而非消极的信息。\n",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05029v1",
      "published_date": "2025-05-08 08:02:20 UTC",
      "updated_date": "2025-05-08 08:02:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:16:40.273690"
    },
    {
      "arxiv_id": "2505.05019v1",
      "title": "Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints",
      "title_zh": "生成可靠的合成临床试验数据：超参数优化和领域约束的作用\n",
      "authors": [
        "Waldemar Hahn",
        "Jan-Niklas Eckardt",
        "Christoph Röllig",
        "Martin Sedlmayr",
        "Jan Moritz Middeke",
        "Markus Wolfien"
      ],
      "abstract": "The generation of synthetic clinical trial data offers a promising approach\nto mitigating privacy concerns and data accessibility limitations in medical\nresearch. However, ensuring that synthetic datasets maintain high fidelity,\nutility, and adherence to domain-specific constraints remains a key challenge.\nWhile hyperparameter optimization (HPO) has been shown to improve generative\nmodel performance, the effectiveness of different optimization strategies for\nsynthetic clinical data remains unclear. This study systematically evaluates\nfour HPO strategies across eight generative models, comparing single-metric\noptimization against compound metric optimization approaches. Our results\ndemonstrate that HPO consistently improves synthetic data quality, with TVAE,\nCTGAN, and CTAB-GAN+ achieving improvements of up to 60%, 39%, and 38%,\nrespectively. Compound metric optimization outperformed single-metric\nstrategies, producing more balanced and generalizable synthetic datasets.\nInterestingly, HPO alone is insufficient to ensure clinically valid synthetic\ndata, as all models exhibited violations of fundamental survival constraints.\nPreprocessing and postprocessing played a crucial role in reducing these\nviolations, as models lacking robust processing steps produced invalid data in\nup to 61% of cases. These findings underscore the necessity of integrating\nexplicit domain knowledge alongside HPO to create high quality synthetic\ndatasets. Our study provides actionable recommendations for improving synthetic\ndata generation, with future research needed to refine metric selection and\nvalidate these findings on larger datasets to enhance clinical applicability.",
      "tldr_zh": "该研究探讨了超参数优化(HPO)和领域约束在生成可靠的合成临床试验数据中的作用。研究系统评估了四种HPO策略在八个生成模型上的表现，比较了单指标优化和复合指标优化方法。结果表明，HPO能显著提高合成数据质量，TVAE、CTGAN和CTAB-GAN+分别提升高达60%、39%和38%。复合指标优化优于单指标策略，产生更平衡和泛化的数据集。然而，HPO不足以保证临床有效性，所有模型都违反了生存约束。预处理和后处理在减少违规方面至关重要，缺乏处理步骤的模型产生高达61%的无效数据。研究强调了整合领域知识和HPO的必要性，并为改进合成数据生成提供了建议。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05019v1",
      "published_date": "2025-05-08 07:51:36 UTC",
      "updated_date": "2025-05-08 07:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:16:52.109228"
    },
    {
      "arxiv_id": "2505.05015v1",
      "title": "An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication",
      "title_zh": "一种基于 Agent 的建模方法，用于自由文本键盘动态的连续身份验证\n",
      "authors": [
        "Roberto Dillon",
        "Arushi"
      ],
      "abstract": "Continuous authentication systems leveraging free-text keyboard dynamics\noffer a promising additional layer of security in a multifactor authentication\nsetup that can be used in a transparent way with no impact on user experience.\nThis study investigates the efficacy of behavioral biometrics by employing an\nAgent-Based Model (ABM) to simulate diverse typing profiles across mechanical\nand membrane keyboards. Specifically, we generated synthetic keystroke data\nfrom five unique agents, capturing features related to dwell time, flight time,\nand error rates within sliding 5-second windows updated every second. Two\nmachine learning approaches, One-Class Support Vector Machine (OC-SVM) and\nRandom Forest (RF), were evaluated for user verification. Results revealed a\nstark contrast in performance: while One-Class SVM failed to differentiate\nindividual users within each group, Random Forest achieved robust\nintra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize\nacross keyboards for the same user, highlighting the significant impact of\nkeyboard hardware on typing behavior. These findings suggest that: (1)\nkeyboard-specific user profiles may be necessary for reliable authentication,\nand (2) ensemble methods like RF outperform One-Class SVM in capturing\nfine-grained user-specific patterns.",
      "tldr_zh": "该研究利用基于Agent的建模(ABM)方法，探索自由文本键盘动态在持续身份验证中的有效性。通过模拟不同打字习惯的Agent，生成了包含按键时长、飞行时间和错误率等特征的合成击键数据。分别使用One-Class SVM和Random Forest两种机器学习方法进行用户验证。结果表明，Random Forest在键盘内用户识别方面表现良好(Accuracy > 0.7)，但难以泛化到同一用户在不同键盘上的行为。研究结果表明，可靠的身份验证可能需要特定于键盘的用户配置文件，并且集成方法(如Random Forest)在捕获细粒度的用户特定模式方面优于One-Class SVM。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "68T10, 62H30",
        "I.2.6; I.5.4; I.6.3"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.05015v1",
      "published_date": "2025-05-08 07:42:05 UTC",
      "updated_date": "2025-05-08 07:42:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:17:04.138628"
    },
    {
      "arxiv_id": "2505.05001v1",
      "title": "StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps",
      "title_zh": "StabStitch++：基于时空双向扭曲的无监督在线视频拼接\n",
      "authors": [
        "Lang Nie",
        "Chunyu Lin",
        "Kang Liao",
        "Yun Zhang",
        "Shuaicheng Liu",
        "Yao Zhao"
      ],
      "abstract": "We retarget video stitching to an emerging issue, named warping shake, which\nunveils the temporal content shakes induced by sequentially unsmooth warps when\nextending image stitching to video stitching. Even if the input videos are\nstable, the stitched video can inevitably cause undesired warping shakes and\naffect the visual experience. To address this issue, we propose StabStitch++, a\nnovel video stitching framework to realize spatial stitching and temporal\nstabilization with unsupervised learning simultaneously. First, different from\nexisting learning-based image stitching solutions that typically warp one image\nto align with another, we suppose a virtual midplane between original image\nplanes and project them onto it. Concretely, we design a differentiable\nbidirectional decomposition module to disentangle the homography transformation\nand incorporate it into our spatial warp, evenly spreading alignment burdens\nand projective distortions across two views. Then, inspired by camera paths in\nvideo stabilization, we derive the mathematical expression of stitching\ntrajectories in video stitching by elaborately integrating spatial and temporal\nwarps. Finally, a warp smoothing model is presented to produce stable stitched\nvideos with a hybrid loss to simultaneously encourage content alignment,\ntrajectory smoothness, and online collaboration. Compared with StabStitch that\nsacrifices alignment for stabilization, StabStitch++ makes no compromise and\noptimizes both of them simultaneously, especially in the online mode. To\nestablish an evaluation benchmark and train the learning framework, we build a\nvideo stitching dataset with a rich diversity in camera motions and scenes.\nExperiments exhibit that StabStitch++ surpasses current solutions in stitching\nperformance, robustness, and efficiency, offering compelling advancements in\nthis field by building a real-time online video stitching system.",
      "tldr_zh": "该论文提出了 StabStitch++，一个新颖的视频拼接框架，旨在解决视频拼接中由不平滑的warps引起的时序内容抖动问题（warping shake）。StabStitch++ 通过无监督学习同时实现空间拼接和时间稳定。其核心思想是假设一个虚拟中间平面，并将原始图像投影到该平面上，通过可微的双向分解模块分解单应变换并将其融入空间warp中，从而均衡对齐负担和投影失真。此外，该方法还推导了视频拼接中拼接轨迹的数学表达式，并提出了一个warp平滑模型，以生成稳定的拼接视频。实验结果表明，StabStitch++ 在拼接性能、鲁棒性和效率方面均优于现有解决方案，并构建了一个实时在线视频拼接系统。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "TPAMI2025; https://github.com/nie-lang/StabStitch2. arXiv admin note:\n  text overlap with arXiv:2403.06378",
      "pdf_url": "http://arxiv.org/pdf/2505.05001v1",
      "published_date": "2025-05-08 07:12:23 UTC",
      "updated_date": "2025-05-08 07:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:17:16.393098"
    },
    {
      "arxiv_id": "2505.04997v1",
      "title": "Foam-Agent: Towards Automated Intelligent CFD Workflows",
      "title_zh": "Foam-Agent：迈向自动化智能 CFD 工作流\n",
      "authors": [
        "Ling Yue",
        "Nithin Somasekharan",
        "Yadi Cao",
        "Shaowu Pan"
      ],
      "abstract": "Computational Fluid Dynamics (CFD) is an essential simulation tool in various\nengineering disciplines, but it often requires substantial domain expertise and\nmanual configuration, creating barriers to entry. We present Foam-Agent, a\nmulti-agent framework that automates complex OpenFOAM-based CFD simulation\nworkflows from natural language inputs. Our innovation includes (1) a\nhierarchical multi-index retrieval system with specialized indices for\ndifferent simulation aspects, (2) a dependency-aware file generation system\nthat provides consistency management across configuration files, and (3) an\niterative error correction mechanism that diagnoses and resolves simulation\nfailures without human intervention. Through comprehensive evaluation on the\ndataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with\nClaude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for\nMetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the\ncritical contribution of each system component, with the specialized error\ncorrection mechanism providing a 36.4% performance improvement. Foam-Agent\nsubstantially lowers the CFD expertise threshold while maintaining modeling\naccuracy, demonstrating the potential of specialized multi-agent systems to\ndemocratize access to complex scientific simulation tools. The code is public\nat https://github.com/csml-rpi/Foam-Agent",
      "tldr_zh": "Foam-Agent是一个多智能体框架，旨在自动化基于OpenFOAM的复杂CFD仿真工作流程，并允许用户使用自然语言输入。该框架包含一个分层多索引检索系统，用于检索不同的仿真方面信息；一个依赖感知的文件生成系统，用于保证配置文件的一致性；以及一个迭代错误纠正机制，用于诊断和解决仿真失败问题。在包含110个仿真任务的数据集上，Foam-Agent使用Claude 3.5 Sonnet实现了83.6%的成功率，显著优于现有的MetaOpenFOAM和OpenFOAM-GPT框架。消融研究表明，专门的错误纠正机制贡献了36.4%的性能提升。Foam-Agent降低了CFD专业知识的门槛，同时保持了建模精度，展示了专业多智能体系统在普及复杂科学仿真工具方面的潜力。代码已公开。\n",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04997v1",
      "published_date": "2025-05-08 07:05:51 UTC",
      "updated_date": "2025-05-08 07:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:17:28.384222"
    },
    {
      "arxiv_id": "2505.04994v1",
      "title": "Rethinking Invariance in In-context Learning",
      "title_zh": "重新思考上下文学习中的不变性\n",
      "authors": [
        "Lizhe Fang",
        "Yifei Wang",
        "Khashayar Gatmiry",
        "Lei Fang",
        "Yisen Wang"
      ],
      "abstract": "In-Context Learning (ICL) has emerged as a pivotal capability of\nauto-regressive large language models, yet it is hindered by a notable\nsensitivity to the ordering of context examples regardless of their mutual\nindependence. To address this issue, recent studies have introduced several\nvariant algorithms of ICL that achieve permutation invariance. However, many of\nthese do not exhibit comparable performance with the standard auto-regressive\nICL algorithm. In this work, we identify two crucial elements in the design of\nan invariant ICL algorithm: information non-leakage and context\ninterdependence, which are not simultaneously achieved by any of the existing\nmethods. These investigations lead us to the proposed Invariant ICL (InvICL), a\nmethodology designed to achieve invariance in ICL while ensuring the two\nproperties. Empirically, our findings reveal that InvICL surpasses previous\nmodels, both invariant and non-invariant, in most benchmark datasets,\nshowcasing superior generalization capabilities across varying input lengths.\nCode is available at https://github.com/PKU-ML/InvICL.",
      "tldr_zh": "本文研究了上下文学习(In-Context Learning, ICL)中对上下文示例顺序敏感的问题，即使这些示例是相互独立的。现有的一些置换不变ICL算法性能不如标准的自回归ICL算法。作者提出了设计不变ICL算法的两个关键要素：信息非泄露和上下文相互依赖性，并在此基础上提出了Invariant ICL (InvICL)方法。实验结果表明，InvICL在大多数基准数据集上优于以往的变体和非变体模型，展现出更强的泛化能力。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04994v1",
      "published_date": "2025-05-08 06:59:14 UTC",
      "updated_date": "2025-05-08 06:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:17:39.956041"
    },
    {
      "arxiv_id": "2505.04983v1",
      "title": "Decomposition of Probabilities of Causation with Two Mediators",
      "title_zh": "具有两个中介变量的因果概率分解\n",
      "authors": [
        "Yuta Kawakami",
        "Jin Tian"
      ],
      "abstract": "Mediation analysis for probabilities of causation (PoC) provides a\nfundamental framework for evaluating the necessity and sufficiency of treatment\nin provoking an event through different causal pathways. One of the primary\nobjectives of causal mediation analysis is to decompose the total effect into\npath-specific components. In this study, we investigate the path-specific\nprobability of necessity and sufficiency (PNS) to decompose the total PNS into\npath-specific components along distinct causal pathways between treatment and\noutcome, incorporating two mediators. We define the path-specific PNS for\ndecomposition and provide an identification theorem. Furthermore, we conduct\nnumerical experiments to assess the properties of the proposed estimators from\nfinite samples and demonstrate their practical application using a real-world\neducational dataset.",
      "tldr_zh": "该研究针对因果概率(Probabilities of Causation, PoC)的中介分析，提出了分解具有两个中介变量情况下的PoC方法。研究重点在于将总体必要性和充分性概率(Probability of Necessity and Sufficiency, PNS)分解为沿治疗和结果之间不同因果路径的、特定于路径的组成部分。论文定义了用于分解的特定路径PNS，并提供了一个识别定理。通过数值实验评估了所提出的估计器在有限样本中的性质，并使用真实世界的教育数据集展示了其在实际中的应用。\n",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "arXiv admin note: text overlap with arXiv:2412.14491",
      "pdf_url": "http://arxiv.org/pdf/2505.04983v1",
      "published_date": "2025-05-08 06:40:17 UTC",
      "updated_date": "2025-05-08 06:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:17:52.015250"
    },
    {
      "arxiv_id": "2505.04977v1",
      "title": "ChainMarks: Securing DNN Watermark with Cryptographic Chain",
      "title_zh": "ChainMarks：利用密码链保护 DNN 水印",
      "authors": [
        "Brian Choi",
        "Shu Wang",
        "Isabelle Choi",
        "Kun Sun"
      ],
      "abstract": "With the widespread deployment of deep neural network (DNN) models, dynamic\nwatermarking techniques are being used to protect the intellectual property of\nmodel owners. However, recent studies have shown that existing watermarking\nschemes are vulnerable to watermark removal and ambiguity attacks. Besides, the\nvague criteria for determining watermark presence further increase the\nlikelihood of such attacks. In this paper, we propose a secure DNN watermarking\nscheme named ChainMarks, which generates secure and robust watermarks by\nintroducing a cryptographic chain into the trigger inputs and utilizes a\ntwo-phase Monte Carlo method for determining watermark presence. First,\nChainMarks generates trigger inputs as a watermark dataset by repeatedly\napplying a hash function over a secret key, where the target labels associated\nwith trigger inputs are generated from the digital signature of model owner.\nThen, the watermarked model is produced by training a DNN over both the\noriginal and watermark datasets. To verify watermarks, we compare the predicted\nlabels of trigger inputs with the target labels and determine ownership with a\nmore accurate decision threshold that considers the classification probability\nof specific models. Experimental results show that ChainMarks exhibits higher\nlevels of robustness and security compared to state-of-the-art watermarking\nschemes. With a better marginal utility, ChainMarks provides a higher\nprobability guarantee of watermark presence in DNN models with the same level\nof watermark accuracy.",
      "tldr_zh": "该论文提出了一种名为ChainMarks的安全DNN水印方案，旨在解决现有水印技术易受攻击的问题。ChainMarks通过在触发输入中引入密码学链来生成安全且鲁棒的水印，并利用两阶段蒙特卡洛方法来判断水印是否存在。该方案首先通过对密钥重复应用哈希函数生成触发输入作为水印数据集，并使用模型所有者的数字签名生成目标标签。然后，通过在原始数据集和水印数据集上训练DNN来生成带水印的模型。为了验证水印，ChainMarks比较触发输入的预测标签与目标标签，并使用更精确的决策阈值来确定所有权。实验结果表明，与现有技术相比，ChainMarks具有更高的鲁棒性和安全性，并且在相同的水印精度下，提供了更高的水印存在概率保证。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted In ACM ASIA Conference on Computer and Communications\n  Security (ASIA CCS '25), August 25-29, 2025, Ha Noi, Vietnam",
      "pdf_url": "http://arxiv.org/pdf/2505.04977v1",
      "published_date": "2025-05-08 06:30:46 UTC",
      "updated_date": "2025-05-08 06:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:18:04.380497"
    },
    {
      "arxiv_id": "2505.04972v1",
      "title": "AI and Vision based Autonomous Navigation of Nano-Drones in Partially-Known Environments",
      "title_zh": "基于AI和视觉的纳米无人机在部分已知环境中的自主导航\n",
      "authors": [
        "Mattia Sartori",
        "Chetna Singhal",
        "Neelabhro Roy",
        "Davide Brunelli",
        "James Gross"
      ],
      "abstract": "The miniaturisation of sensors and processors, the advancements in connected\nedge intelligence, and the exponential interest in Artificial Intelligence are\nboosting the affirmation of autonomous nano-size drones in the Internet of\nRobotic Things ecosystem. However, achieving safe autonomous navigation and\nhigh-level tasks such as exploration and surveillance with these tiny platforms\nis extremely challenging due to their limited resources. This work focuses on\nenabling the safe and autonomous flight of a pocket-size, 30-gram platform\ncalled Crazyflie 2.1 in a partially known environment. We propose a novel\nAI-aided, vision-based reactive planning method for obstacle avoidance under\nthe ambit of Integrated Sensing, Computing and Communication paradigm. We deal\nwith the constraints of the nano-drone by splitting the navigation task into\ntwo parts: a deep learning-based object detector runs on the edge (external\nhardware) while the planning algorithm is executed onboard. The results show\nthe ability to command the drone at $\\sim8$ frames-per-second and a model\nperformance reaching a COCO mean-average-precision of $60.8$. Field experiments\ndemonstrate the feasibility of the solution with the drone flying at a top\nspeed of $1$ m/s while steering away from an obstacle placed in an unknown\nposition and reaching the target destination. The outcome highlights the\ncompatibility of the communication delay and the model performance with the\nrequirements of the real-time navigation task. We provide a feasible\nalternative to a fully onboard implementation that can be extended to\nautonomous exploration with nano-drones.",
      "tldr_zh": "该研究提出了一种基于AI和视觉的纳米无人机自主导航方法，用于在部分已知环境中实现安全飞行。该方法针对30克重的Crazyflie 2.1无人机，采用了一种新型的AI辅助、基于视觉的反应式规划方法，用于在集成感知、计算和通信范式下进行避障。导航任务被分解为两部分：基于深度学习的目标检测器在边缘设备上运行，而规划算法在无人机上执行。实验结果表明，该方法能以约8帧/秒的速度控制无人机，目标检测模型在COCO上的平均精度达到60.8%。实际飞行实验验证了该方案的可行性，无人机能以1米/秒的速度避开未知位置的障碍物并到达目标位置。该研究提供了一种可行的替代方案，以替代完全板载的实现方式，并可扩展到纳米无人机的自主探索。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.RO",
      "comment": "in DCOSS-IoT 2025, Wi-DroIT 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04972v1",
      "published_date": "2025-05-08 06:16:36 UTC",
      "updated_date": "2025-05-08 06:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:18:16.449870"
    },
    {
      "arxiv_id": "2505.04971v1",
      "title": "Moments of Causal Effects",
      "title_zh": "因果效应的矩",
      "authors": [
        "Yuta Kawakami",
        "Jin Tian"
      ],
      "abstract": "The moments of random variables are fundamental statistical measures for\ncharacterizing the shape of a probability distribution, encompassing metrics\nsuch as mean, variance, skewness, and kurtosis. Additionally, the product\nmoments, including covariance and correlation, reveal the relationships between\nmultiple random variables. On the other hand, the primary focus of causal\ninference is the evaluation of causal effects, which are defined as the\ndifference between two potential outcomes. While traditional causal effect\nassessment focuses on the average causal effect, this work provides\ndefinitions, identification theorems, and bounds for moments and product\nmoments of causal effects to analyze their distribution and relationships. We\nconduct experiments to illustrate the estimation of the moments of causal\neffects from finite samples and demonstrate their practical application using a\nreal-world medical dataset.",
      "tldr_zh": "该论文定义并研究了因果效应的矩(Moments of Causal Effects)及其乘积矩，旨在分析因果效应的分布和关系，而不仅仅是关注平均因果效应。论文提供了矩的定义、识别定理和界限。通过实验，验证了从有限样本中估计因果效应矩的可行性，并使用真实医疗数据集展示了其应用。该研究为更全面地理解因果效应提供了新的视角。\n",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04971v1",
      "published_date": "2025-05-08 06:09:05 UTC",
      "updated_date": "2025-05-08 06:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:18:27.869381"
    },
    {
      "arxiv_id": "2505.04966v1",
      "title": "Position: The AI Conference Peer Review Crisis Demands Author Feedback and Reviewer Rewards",
      "title_zh": "立场：人工智能会议同行评审危机亟需作者反馈和评审者奖励\n",
      "authors": [
        "Jaeho Kim",
        "Yunseok Lee",
        "Seulki Lee"
      ],
      "abstract": "The peer review process in major artificial intelligence (AI) conferences\nfaces unprecedented challenges with the surge of paper submissions (exceeding\n10,000 submissions per venue), accompanied by growing concerns over review\nquality and reviewer responsibility. This position paper argues for the need to\ntransform the traditional one-way review system into a bi-directional feedback\nloop where authors evaluate review quality and reviewers earn formal\naccreditation, creating an accountability framework that promotes a\nsustainable, high-quality peer review system. The current review system can be\nviewed as an interaction between three parties: the authors, reviewers, and\nsystem (i.e., conference), where we posit that all three parties share\nresponsibility for the current problems. However, issues with authors can only\nbe addressed through policy enforcement and detection tools, and ethical\nconcerns can only be corrected through self-reflection. As such, this paper\nfocuses on reforming reviewer accountability with systematic rewards through\ntwo key mechanisms: (1) a two-stage bi-directional review system that allows\nauthors to evaluate reviews while minimizing retaliatory behavior, (2)a\nsystematic reviewer reward system that incentivizes quality reviewing. We ask\nfor the community's strong interest in these problems and the reforms that are\nneeded to enhance the peer review process.",
      "tldr_zh": "人工智能(AI)会议的同行评审过程面临前所未有的挑战，投稿数量激增导致评审质量和评审人责任感下降。本文提出将传统的单向评审系统转变为双向反馈循环，作者可以评估评审质量，评审人可以获得正式认可，从而建立一个促进可持续、高质量同行评审系统的责任框架。本文重点关注通过以下两个关键机制改革评审人责任制并给予系统性奖励：(1)允许作者评估评审的双阶段双向评审系统，同时最大限度地减少报复行为；(2)激励高质量评审的系统性评审人奖励系统。呼吁社区关注这些问题以及改进同行评审过程所需的改革。\n",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML2025 Position Track Oral",
      "pdf_url": "http://arxiv.org/pdf/2505.04966v1",
      "published_date": "2025-05-08 05:51:48 UTC",
      "updated_date": "2025-05-08 05:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:18:40.175955"
    },
    {
      "arxiv_id": "2505.04961v1",
      "title": "ADD: Physics-Based Motion Imitation with Adversarial Differential Discriminators",
      "title_zh": "ADD：基于物理的运动模仿与对抗差分判别器\n",
      "authors": [
        "Ziyu Zhang",
        "Sergey Bashkirov",
        "Dun Yang",
        "Michael Taylor",
        "Xue Bin Peng"
      ],
      "abstract": "Multi-objective optimization problems, which require the simultaneous\noptimization of multiple terms, are prevalent across numerous applications.\nExisting multi-objective optimization methods often rely on manually tuned\naggregation functions to formulate a joint optimization target. The performance\nof such hand-tuned methods is heavily dependent on careful weight selection, a\ntime-consuming and laborious process. These limitations also arise in the\nsetting of reinforcement-learning-based motion tracking for physically\nsimulated characters, where intricately crafted reward functions are typically\nused to achieve high-fidelity results. Such solutions not only require domain\nexpertise and significant manual adjustment, but also limit the applicability\nof the resulting reward function across diverse skills. To bridge this gap, we\npresent a novel adversarial multi-objective optimization technique that is\nbroadly applicable to a range of multi-objective optimization problems,\nincluding motion tracking. The proposed adversarial differential discriminator\nreceives a single positive sample, yet is still effective at guiding the\noptimization process. We demonstrate that our technique can enable characters\nto closely replicate a variety of acrobatic and agile behaviors, achieving\ncomparable quality to state-of-the-art motion-tracking methods, without relying\non manually tuned reward functions. Results are best visualized through\nhttps://youtu.be/rz8BYCE9E2w.",
      "tldr_zh": "本文提出了一种新的基于物理的运动模仿方法，称为ADD，它利用对抗差分判别器进行多目标优化。该方法旨在解决传统方法中依赖手动调整聚合函数和奖励函数的问题，这些手动调整耗时且需要领域专业知识。ADD通过接收单个正样本来指导优化过程，使模拟角色能够精确地模仿各种杂技和敏捷行为。实验结果表明，ADD在运动跟踪方面达到了与最先进方法相当的质量，且无需手动调整奖励函数。\n",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.GR",
      "comment": "19 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04961v1",
      "published_date": "2025-05-08 05:42:33 UTC",
      "updated_date": "2025-05-08 05:42:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:18:52.038916"
    },
    {
      "arxiv_id": "2505.04956v1",
      "title": "Graffe: Graph Representation Learning via Diffusion Probabilistic Models",
      "title_zh": "Graffe：基于扩散概率模型的图表示学习\n",
      "authors": [
        "Dingshuo Chen",
        "Shuchen Xue",
        "Liuji Chen",
        "Yingheng Wang",
        "Qiang Liu",
        "Shu Wu",
        "Zhi-Ming Ma",
        "Liang Wang"
      ],
      "abstract": "Diffusion probabilistic models (DPMs), widely recognized for their potential\nto generate high-quality samples, tend to go unnoticed in representation\nlearning. While recent progress has highlighted their potential for capturing\nvisual semantics, adapting DPMs to graph representation learning remains in its\ninfancy. In this paper, we introduce Graffe, a self-supervised diffusion model\nproposed for graph representation learning. It features a graph encoder that\ndistills a source graph into a compact representation, which, in turn, serves\nas the condition to guide the denoising process of the diffusion decoder. To\nevaluate the effectiveness of our model, we first explore the theoretical\nfoundations of applying diffusion models to representation learning, proving\nthat the denoising objective implicitly maximizes the conditional mutual\ninformation between data and its representation. Specifically, we prove that\nthe negative logarithm of the denoising score matching loss is a tractable\nlower bound for the conditional mutual information. Empirically, we conduct a\nseries of case studies to validate our theoretical insights. In addition,\nGraffe delivers competitive results under the linear probing setting on node\nand graph classification tasks, achieving state-of-the-art performance on 9 of\nthe 11 real-world datasets. These findings indicate that powerful generative\nmodels, especially diffusion models, serve as an effective tool for graph\nrepresentation learning.",
      "tldr_zh": "该论文提出了Graffe，一种用于图表示学习的自监督扩散模型。Graffe包含一个图编码器，将源图提炼成紧凑的表示，并以此作为条件来指导扩散解码器的去噪过程。理论上，论文证明了去噪目标隐式地最大化了数据和其表示之间的条件互信息，并提供了条件互信息的易处理下界。实验方面，Graffe在节点和图分类任务的线性探测设置下表现出色，在11个真实世界数据集中的9个上取得了state-of-the-art的性能。研究结果表明，扩散模型是图表示学习的有效工具。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2505.04956v1",
      "published_date": "2025-05-08 05:38:19 UTC",
      "updated_date": "2025-05-08 05:38:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:19:04.245324"
    },
    {
      "arxiv_id": "2505.04955v1",
      "title": "Chain-of-Thought Tokens are Computer Program Variables",
      "title_zh": "链式思维 Token 是计算机程序变量\n",
      "authors": [
        "Fangwei Zhu",
        "Peiyi Wang",
        "Zhifang Sui"
      ],
      "abstract": "Chain-of-thoughts (CoT) requires large language models (LLMs) to generate\nintermediate steps before reaching the final answer, and has been proven\neffective to help LLMs solve complex reasoning tasks. However, the inner\nmechanism of CoT still remains largely unclear. In this paper, we empirically\nstudy the role of CoT tokens in LLMs on two compositional tasks: multi-digit\nmultiplication and dynamic programming. While CoT is essential for solving\nthese problems, we find that preserving only tokens that store intermediate\nresults would achieve comparable performance. Furthermore, we observe that\nstoring intermediate results in an alternative latent form will not affect\nmodel performance. We also randomly intervene some values in CoT, and notice\nthat subsequent CoT tokens and the final answer would change correspondingly.\nThese findings suggest that CoT tokens may function like variables in computer\nprograms but with potential drawbacks like unintended shortcuts and\ncomputational complexity limits between tokens. The code and data are available\nat https://github.com/solitaryzero/CoTs_are_Variables.",
      "tldr_zh": "该论文研究了链式思维(CoT)token在大语言模型(LLMs)中的作用，通过多位数乘法和动态规划两个组合任务的实验，揭示了CoT的内在机制。研究发现，仅保留存储中间结果的token即可达到与完整CoT相当的性能，并且将中间结果存储为替代的潜在形式并不影响模型性能。此外，对CoT中的值进行随机干预会相应地改变后续的CoT token和最终答案。这些结果表明，CoT token可能类似于计算机程序中的变量，但存在潜在的缺陷，例如意外的捷径和token之间的计算复杂性限制。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04955v1",
      "published_date": "2025-05-08 05:32:36 UTC",
      "updated_date": "2025-05-08 05:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:19:16.196571"
    },
    {
      "arxiv_id": "2505.04950v1",
      "title": "Position: Epistemic Artificial Intelligence is Essential for Machine Learning Models to Know When They Do Not Know",
      "title_zh": "立场：认知人工智能对于机器学习模型了解何时“不知道”至关重要\n",
      "authors": [
        "Shireen Kudukkil Manchingal",
        "Fabio Cuzzolin"
      ],
      "abstract": "Despite the impressive achievements of AI, including advancements in\ngenerative models and large language models, there remains a significant gap in\nthe ability of AI to handle uncertainty and generalize beyond the training\ndata. We argue that AI models, especially in autonomous systems, fail to make\nrobust predictions when faced with unfamiliar or adversarial data, as evidenced\nby incidents with autonomous vehicles. Traditional machine learning approaches\nstruggle to address these issues due to an overemphasis on data fitting and\ndomain adaptation. This position paper posits a paradigm shift towards\nepistemic artificial intelligence, emphasizing the need for models to learn not\nonly from what they know but also from their ignorance. This approach, which\nfocuses on recognizing and managing uncertainty, offers a potential solution to\nimprove the resilience and robustness of AI systems, ensuring that they can\nbetter handle unpredictable real-world environments.",
      "tldr_zh": "本文指出当前人工智能，尤其是机器学习模型，在处理不确定性和泛化能力方面存在显著缺陷，尤其是在面对未知或对抗性数据时，导致系统预测的鲁棒性不足。传统机器学习方法过度强调数据拟合和领域适应，难以有效解决这些问题。因此，本文倡导转向认知人工智能(Epistemic AI)的范式，强调模型不仅要学习已知信息，还要学习如何识别和管理自身的“无知”。这种方法旨在提升AI系统的韧性和鲁棒性，使其更好地应对不可预测的现实环境。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04950v1",
      "published_date": "2025-05-08 05:10:38 UTC",
      "updated_date": "2025-05-08 05:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:19:28.050047"
    },
    {
      "arxiv_id": "2505.04946v1",
      "title": "T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video Generation Models",
      "title_zh": "T2VTextBench：视频生成模型中用于文本控制的人工评估基准\n",
      "authors": [
        "Xuyang Guo",
        "Jiayan Huo",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang",
        "Jiale Zhao"
      ],
      "abstract": "Thanks to recent advancements in scalable deep architectures and large-scale\npretraining, text-to-video generation has achieved unprecedented capabilities\nin producing high-fidelity, instruction-following content across a wide range\nof styles, enabling applications in advertising, entertainment, and education.\nHowever, these models' ability to render precise on-screen text, such as\ncaptions or mathematical formulas, remains largely untested, posing significant\nchallenges for applications requiring exact textual accuracy. In this work, we\nintroduce T2VTextBench, the first human-evaluation benchmark dedicated to\nevaluating on-screen text fidelity and temporal consistency in text-to-video\nmodels. Our suite of prompts integrates complex text strings with dynamic scene\nchanges, testing each model's ability to maintain detailed instructions across\nframes. We evaluate ten state-of-the-art systems, ranging from open-source\nsolutions to commercial offerings, and find that most struggle to generate\nlegible, consistent text. These results highlight a critical gap in current\nvideo generators and provide a clear direction for future research aimed at\nenhancing textual manipulation in video synthesis.",
      "tldr_zh": "T2VTextBench是一个全新的人工评估基准，专门用于评估文本到视频生成模型中对文本控制的精确性。该基准测试模型在动态场景变化中渲染精确屏幕文本（如字幕或数学公式）的能力，这对广告、娱乐和教育等应用至关重要。通过集成复杂文本字符串和动态场景变化，T2VTextBench测试了模型在帧间保持详细指令的能力。对十个最先进系统的评估表明，大多数模型难以生成清晰且一致的文本，揭示了当前视频生成器在文本处理方面的一个关键差距，并为未来增强视频合成中文本操作的研究指明了方向。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04946v1",
      "published_date": "2025-05-08 04:49:52 UTC",
      "updated_date": "2025-05-08 04:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:19:40.213556"
    },
    {
      "arxiv_id": "2505.04939v1",
      "title": "Structural Alignment in Link Prediction",
      "title_zh": "链接预测中的结构对齐\n",
      "authors": [
        "Jeffrey Seathrún Sardina"
      ],
      "abstract": "While Knowledge Graphs (KGs) have become increasingly popular across various\nscientific disciplines for their ability to model and interlink huge quantities\nof data, essentially all real-world KGs are known to be incomplete. As such,\nwith the growth of KG use has been a concurrent development of machine learning\ntools designed to predict missing information in KGs, which is referred to as\nthe Link Prediction Task. The majority of state-of-the-art link predictors to\ndate have followed an embedding-based paradigm. In this paradigm, it is assumed\nthat the information content of a KG is best represented by the (individual)\nvector representations of its nodes and edges, and that therefore node and edge\nembeddings are particularly well-suited to performing link prediction.\n  This thesis proposes an alternative perspective on the field's approach to\nlink prediction and KG data modelling. Specifically, this work re-analyses KGs\nand state-of-the-art link predictors from a graph-structure-first perspective\nthat models the information content of a KG in terms of whole triples, rather\nthan individual nodes and edges.\n  Following a literature review and two core sets of experiments, this thesis\nconcludes that a structure-first perspective on KGs and link prediction is both\nviable and useful for understanding KG learning and for enabling cross-KG\ntransfer learning for the link prediction task. This observation is used to\ncreate and propose the Structural Alignment Hypothesis, which postulates that\nlink prediction can be understood and modelled as a structural task.\n  All code and data used for this thesis are open-sourced. This thesis was\nwritten bilingually, with the main document in English and an informal extended\nsummary in Irish. An Irish-language translation dictionary of machine learning\nterms (the Focl\\'oir Tr\\'achtais) created for this work is open-sourced as\nwell.",
      "tldr_zh": "该论文从图结构优先的角度重新审视知识图谱(KG)和链接预测任务，不同于以往基于嵌入的方法，该方法侧重于将KG的信息内容建模为完整的三元组，而非单独的节点和边。通过文献回顾和实验，论文得出结论：结构优先的视角对于理解KG学习和实现跨KG迁移学习是可行且有用的。基于此，论文提出了结构对齐假设(Structural Alignment Hypothesis)，认为链接预测可以被理解和建模为一个结构任务。该论文的所有代码和数据均已开源，并提供了一个机器学习术语的爱尔兰语翻译词典。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Ph.D. thesis submitted to Trinity College Dublin",
      "pdf_url": "http://arxiv.org/pdf/2505.04939v1",
      "published_date": "2025-05-08 04:27:15 UTC",
      "updated_date": "2025-05-08 04:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:19:52.215782"
    },
    {
      "arxiv_id": "2505.04931v1",
      "title": "Fair Uncertainty Quantification for Depression Prediction",
      "title_zh": "抑郁症预测的公平不确定性量化",
      "authors": [
        "Yonghong Li",
        "Xiuzhuang Zhou"
      ],
      "abstract": "Trustworthy depression prediction based on deep learning, incorporating both\npredictive reliability and algorithmic fairness across diverse demographic\ngroups, is crucial for clinical application. Recently, achieving reliable\ndepression predictions through uncertainty quantification has attracted\nincreasing attention. However, few studies have focused on the fairness of\nuncertainty quantification (UQ) in depression prediction. In this work, we\ninvestigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage\n(EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for\ndepression prediction. FUQ pursues reliable and fair depression predictions\nthrough group-based analysis. Specifically, we first group all the participants\nby different sensitive attributes and leverage conformal prediction to quantify\nuncertainty within each demographic group, which provides a theoretically\nguaranteed and valid way to quantify uncertainty for depression prediction and\nfacilitates the investigation of fairness across different demographic groups.\nFurthermore, we propose a fairness-aware optimization strategy that formulates\nfairness as a constrained optimization problem under EOC constraints. This\nenables the model to preserve predictive reliability while adapting to the\nheterogeneous uncertainty levels across demographic groups, thereby achieving\noptimal fairness. Through extensive evaluations on several visual and audio\ndepression datasets, our approach demonstrates its effectiveness.",
      "tldr_zh": "该研究关注抑郁症预测中不确定性量化(Uncertainty Quantification, UQ)的公平性问题，提出了Fair Uncertainty Quantification (FUQ)方法。FUQ旨在通过群体分析实现可靠且公平的抑郁症预测，重点关注Equal Opportunity Coverage (EOC)公平性。该方法首先根据敏感属性对参与者分组，并利用conformal prediction量化每个群体内的不确定性。然后，提出一种公平感知优化策略，将公平性建模为EOC约束下的约束优化问题，使模型能够在保持预测可靠性的同时适应不同人群的不确定性水平。在多个视觉和音频抑郁症数据集上的实验结果表明了该方法的有效性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04931v1",
      "published_date": "2025-05-08 04:09:36 UTC",
      "updated_date": "2025-05-08 04:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:20:06.440563"
    },
    {
      "arxiv_id": "2505.04927v1",
      "title": "Belief Filtering for Epistemic Control in Linguistic State Space",
      "title_zh": "语言状态空间中认知控制的信念过滤\n",
      "authors": [
        "Sebastian Dumbrava"
      ],
      "abstract": "We examine belief filtering as a mechanism for the epistemic control of\nartificial agents, focusing on the regulation of internal cognitive states\nrepresented as linguistic expressions. This mechanism is developed within the\nSemantic Manifold framework, where belief states are dynamic, structured\nensembles of natural language fragments. Belief filters act as content-aware\noperations on these fragments across various cognitive transitions. This paper\nillustrates how the inherent interpretability and modularity of such a\nlinguistically-grounded cognitive architecture directly enable belief\nfiltering, offering a principled approach to agent regulation. The study\nhighlights the potential for enhancing AI safety and alignment through\nstructured interventions in an agent's internal semantic space and points to\nnew directions for architecturally embedded cognitive governance.",
      "tldr_zh": "本文探讨了信念过滤机制，用于对人工智能代理进行认知控制，侧重于调节以语言表达式表示的内部认知状态。该机制在语义流形框架内开发，其中信念状态是自然语言片段的动态、结构化集合。信念过滤器充当对这些片段的内容感知操作，跨越各种认知转换。本文阐述了这种基于语言的认知架构的内在可解释性和模块化如何直接实现信念过滤，从而为代理监管提供了一种原则性方法。该研究强调了通过对代理内部语义空间进行结构化干预来增强人工智能安全性和对齐的潜力，并为架构嵌入式认知治理指明了新的方向。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.04927v1",
      "published_date": "2025-05-08 03:52:43 UTC",
      "updated_date": "2025-05-08 03:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:20:16.244187"
    },
    {
      "arxiv_id": "2505.04918v1",
      "title": "Physics-Assisted and Topology-Informed Deep Learning for Weather Prediction",
      "title_zh": "基于物理辅助和拓扑感知的深度学习天气预测\n",
      "authors": [
        "Jiaqi Zheng",
        "Qing Ling",
        "Yerong Feng"
      ],
      "abstract": "Although deep learning models have demonstrated remarkable potential in\nweather prediction, most of them overlook either the \\textbf{physics} of the\nunderlying weather evolution or the \\textbf{topology} of the Earth's surface.\nIn light of these disadvantages, we develop PASSAT, a novel Physics-ASSisted\nAnd Topology-informed deep learning model for weather prediction. PASSAT\nattributes the weather evolution to two key factors: (i) the advection process\nthat can be characterized by the advection equation and the Navier-Stokes\nequation; (ii) the Earth-atmosphere interaction that is difficult to both model\nand calculate. PASSAT also takes the topology of the Earth's surface into\nconsideration, other than simply treating it as a plane. With these\nconsiderations, PASSAT numerically solves the advection equation and the\nNavier-Stokes equation on the spherical manifold, utilizes a spherical graph\nneural network to capture the Earth-atmosphere interaction, and generates the\ninitial velocity fields that are critical to solving the advection equation\nfrom the same spherical graph neural network. In the $5.625^\\circ$-resolution\nERA5 data set, PASSAT outperforms both the state-of-the-art deep learning-based\nweather prediction models and the operational numerical weather prediction\nmodel IFS T42. Code and checkpoint are available at\nhttps://github.com/Yumenomae/PASSAT_5p625.",
      "tldr_zh": "该论文提出了一种名为PASSAT的物理辅助和拓扑感知深度学习模型，用于天气预测。PASSAT模型考虑了天气演变的两个关键因素：由平流方程和Navier-Stokes方程描述的平流过程，以及难以建模和计算的地球-大气相互作用。此外，PASSAT还考虑了地球表面的拓扑结构，并在球面流形上数值求解平流方程和Navier-Stokes方程。实验结果表明，在$5.625^\\circ$分辨率的ERA5数据集上，PASSAT的性能优于最先进的基于深度学习的天气预测模型和业务数值天气预测模型IFS T42。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "International Joint Conferences on Artificial Intelligence (IJCAI\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.04918v1",
      "published_date": "2025-05-08 03:25:55 UTC",
      "updated_date": "2025-05-08 03:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:20:28.390084"
    },
    {
      "arxiv_id": "2505.04916v1",
      "title": "An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education",
      "title_zh": "一种用于高等教育语义检索的开源双损失嵌入模型\n",
      "authors": [
        "Ramteja Sajja",
        "Yusuf Sermet",
        "Ibrahim Demir"
      ],
      "abstract": "Recent advances in AI have catalyzed the adoption of intelligent educational\ntools, yet many semantic retrieval systems remain ill-suited to the unique\nlinguistic and structural characteristics of academic content. This study\npresents two open-source embedding models fine-tuned for educational question\nanswering, particularly in the context of course syllabi. A synthetic dataset\nof 3,197 sentence pairs, spanning synonymous terminology, paraphrased\nquestions, and implicit-explicit mappings, was constructed through a\ncombination of manual curation and large language model (LLM)-assisted\ngeneration. Two training strategies were evaluated: (1) a baseline model\nfine-tuned using MultipleNegativesRankingLoss (MNRL), and (2) a dual-loss model\nthat combines MNRL with CosineSimilarityLoss to improve both semantic ranking\nand similarity calibration. Evaluations were conducted on 28 university course\nsyllabi using a fixed set of natural language questions categorized into\ncourse, faculty, and teaching assistant information. Results demonstrate that\nboth fine-tuned models outperform strong open-source baselines, including\nall-MiniLM-L6-v2 and multi-qa-MiniLM-L6-cos-v1, and that the dual-loss model\nnarrows the performance gap with high-performing proprietary embeddings such as\nOpenAI's text-embedding-3 series. This work contributes reusable,\ndomain-aligned embedding models and provides a replicable framework for\neducational semantic retrieval, supporting downstream applications such as\nacademic chatbots, retrieval-augmented generation (RAG) systems, and learning\nmanagement system (LMS) integrations.",
      "tldr_zh": "该研究针对高等教育领域语义检索的特殊性，提出了两个开源的embedding模型，并针对课程大纲的问答场景进行了优化。研究人员构建了一个包含3197个句子对的合成数据集，并评估了两种训练策略：基于MultipleNegativesRankingLoss (MNRL)的baseline模型和结合MNRL与CosineSimilarityLoss的dual-loss模型。实验结果表明，两个fine-tuned模型均优于现有的开源模型，且dual-loss模型缩小了与OpenAI等商业embedding模型的差距。该研究贡献了可复用的、领域对齐的embedding模型，并为教育语义检索提供了一个可复制的框架，可应用于学术聊天机器人、RAG系统和LMS集成等场景。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2505.04916v1",
      "published_date": "2025-05-08 03:14:14 UTC",
      "updated_date": "2025-05-08 03:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:20:40.429275"
    },
    {
      "arxiv_id": "2505.04914v1",
      "title": "Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models",
      "title_zh": "Enigme：用于评估语言模型推理能力的生成式文本谜题\n",
      "authors": [
        "John Hawkins"
      ],
      "abstract": "Transformer-decoder language models are a core innovation in text based\ngenerative artificial intelligence. These models are being deployed as\ngeneral-purpose intelligence systems in many applications. Central to their\nutility is the capacity to understand natural language commands and exploit the\nreasoning embedded in human text corpora to apply some form of reasoning\nprocess to a wide variety of novel tasks. To understand the limitations of this\napproach to generating reasoning we argue that we need to consider the\narchitectural constraints of these systems. Consideration of the latent\nvariable structure of transformer-decoder models allows us to design reasoning\ntasks that should probe the boundary of their capacity to reason. We present\nenigme, an open-source library for generating text-based puzzles to be used in\ntraining and evaluating reasoning skills within transformer-decoder models and\nfuture AI architectures.",
      "tldr_zh": "该论文提出了enigme，一个用于生成文本谜题的开源库，旨在评估Transformer-decoder语言模型中的推理能力。作者认为，理解这些模型在生成推理方面的局限性需要考虑其架构约束。通过分析Transformer-decoder模型的潜在变量结构，论文设计了能够探测模型推理能力边界的谜题任务。enigme可用于训练和评估Transformer-decoder模型以及未来AI架构中的推理技能。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published in the proceedings of The 2025 11th International\n  Conference on Engineering, Applied Sciences, and Technology (ICEAST)",
      "pdf_url": "http://arxiv.org/pdf/2505.04914v1",
      "published_date": "2025-05-08 03:09:57 UTC",
      "updated_date": "2025-05-08 03:09:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:20:51.977714"
    },
    {
      "arxiv_id": "2505.04911v1",
      "title": "SpatialPrompting: Keyframe-driven Zero-Shot Spatial Reasoning with Off-the-Shelf Multimodal Large Language Models",
      "title_zh": "SpatialPrompting：基于关键帧驱动的零样本空间推理与现成的多模态大型语言模型\n",
      "authors": [
        "Shun Taguchi",
        "Hideki Deguchi",
        "Takumi Hamazaki",
        "Hiroyuki Sakai"
      ],
      "abstract": "This study introduces SpatialPrompting, a novel framework that harnesses the\nemergent reasoning capabilities of off-the-shelf multimodal large language\nmodels to achieve zero-shot spatial reasoning in three-dimensional (3D)\nenvironments. Unlike existing methods that rely on expensive 3D-specific\nfine-tuning with specialized 3D inputs such as point clouds or voxel-based\nfeatures, SpatialPrompting employs a keyframe-driven prompt generation\nstrategy. This framework uses metrics such as vision-language similarity,\nMahalanobis distance, field of view, and image sharpness to select a diverse\nand informative set of keyframes from image sequences and then integrates them\nwith corresponding camera pose data to effectively abstract spatial\nrelationships and infer complex 3D structures. The proposed framework not only\nestablishes a new paradigm for flexible spatial reasoning that utilizes\nintuitive visual and positional cues but also achieves state-of-the-art\nzero-shot performance on benchmark datasets, such as ScanQA and SQA3D, across\nseveral metrics. The proposed method effectively eliminates the need for\nspecialized 3D inputs and fine-tuning, offering a simpler and more scalable\nalternative to conventional approaches.",
      "tldr_zh": "该论文提出SpatialPrompting，一个新颖的框架，利用现成的多模态大语言模型实现三维环境中的零样本空间推理。与依赖昂贵的3D特定微调和专业3D输入（如点云或体素特征）的现有方法不同，SpatialPrompting采用关键帧驱动的提示生成策略。该框架使用视觉-语言相似性、马氏距离、视野和图像清晰度等指标，从图像序列中选择多样且信息丰富的关键帧，并将其与相应的相机姿态数据集成，以有效地抽象空间关系并推断复杂的3D结构。实验结果表明，SpatialPrompting在ScanQA和SQA3D等基准数据集上实现了最先进的零样本性能，且无需专门的3D输入和微调，为空间推理提供了一种更简单且可扩展的替代方案。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04911v1",
      "published_date": "2025-05-08 02:59:01 UTC",
      "updated_date": "2025-05-08 02:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:21:04.511559"
    },
    {
      "arxiv_id": "2505.04898v1",
      "title": "Precise gradient descent training dynamics for finite-width multi-layer neural networks",
      "title_zh": "有限宽度多层神经网络的精确梯度下降训练动态\n",
      "authors": [
        "Qiyang Han",
        "Masaaki Imaizumi"
      ],
      "abstract": "In this paper, we provide the first precise distributional characterization\nof gradient descent iterates for general multi-layer neural networks under the\ncanonical single-index regression model, in the `finite-width proportional\nregime' where the sample size and feature dimension grow proportionally while\nthe network width and depth remain bounded. Our non-asymptotic state evolution\ntheory captures Gaussian fluctuations in first-layer weights and concentration\nin deeper-layer weights, and remains valid for non-Gaussian features.\n  Our theory differs from existing neural tangent kernel (NTK), mean-field (MF)\ntheories and tensor program (TP) in several key aspects. First, our theory\noperates in the finite-width regime whereas these existing theories are\nfundamentally infinite-width. Second, our theory allows weights to evolve from\nindividual initializations beyond the lazy training regime, whereas NTK and MF\nare either frozen at or only weakly sensitive to initialization, and TP relies\non special initialization schemes. Third, our theory characterizes both\ntraining and generalization errors for general multi-layer neural networks\nbeyond the uniform convergence regime, whereas existing theories study\ngeneralization almost exclusively in two-layer settings.\n  As a statistical application, we show that vanilla gradient descent can be\naugmented to yield consistent estimates of the generalization error at each\niteration, which can be used to guide early stopping and hyperparameter tuning.\nAs a further theoretical implication, we show that despite model\nmisspecification, the model learned by gradient descent retains the structure\nof a single-index function with an effective signal determined by a linear\ncombination of the true signal and the initialization.",
      "tldr_zh": "本文针对有限宽度多层神经网络，在规范的单指标回归模型下，首次精确地描述了梯度下降迭代的分布特征。该理论在样本量和特征维度成比例增长，而网络宽度和深度保持有限的“有限宽度比例机制”下有效。提出的非渐近状态演化理论捕捉了第一层权重中的高斯波动和更深层权重中的集中，并且对非高斯特征仍然有效。该理论与现有的神经正切核(NTK)、平均场(MF)理论和张量程序(TP)不同，它在有限宽度机制下运行，允许权重从个体初始化演化，并能表征训练和泛化误差。作为一个统计应用，研究表明可以增强 vanilla 梯度下降，以产生对每次迭代泛化误差的一致估计，并用于指导早停和超参数调整。 此外，即使在模型错误指定的情况下，梯度下降学习的模型仍然保留单指标函数的结构，其有效信号由真实信号和初始化的线性组合决定。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04898v1",
      "published_date": "2025-05-08 02:19:39 UTC",
      "updated_date": "2025-05-08 02:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:21:16.765482"
    },
    {
      "arxiv_id": "2505.04891v1",
      "title": "Clustering with Communication: A Variational Framework for Single Cell Representation Learning",
      "title_zh": "基于通信的聚类：用于单细胞表征学习的变分框架\n",
      "authors": [
        "Cong Qi",
        "Yeqing Chen",
        "Jie Zhang",
        "Wei Zhi"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) has revealed complex cellular\nheterogeneity, but recent studies emphasize that understanding biological\nfunction also requires modeling cell-cell communication (CCC), the signaling\ninteractions mediated by ligand-receptor pairs that coordinate cellular\nbehavior. Tools like CellChat have demonstrated that CCC plays a critical role\nin processes such as cell differentiation, tissue regeneration, and immune\nresponse, and that transcriptomic data inherently encodes rich information\nabout intercellular signaling. We propose CCCVAE, a novel variational\nautoencoder framework that incorporates CCC signals into single-cell\nrepresentation learning. By leveraging a communication-aware kernel derived\nfrom ligand-receptor interactions and a sparse Gaussian process, CCCVAE encodes\nbiologically informed priors into the latent space. Unlike conventional VAEs\nthat treat each cell independently, CCCVAE encourages latent embeddings to\nreflect both transcriptional similarity and intercellular signaling context.\nEmpirical results across four scRNA-seq datasets show that CCCVAE improves\nclustering performance, achieving higher evaluation scores than standard VAE\nbaselines. This work demonstrates the value of embedding biological priors into\ndeep generative models for unsupervised single-cell analysis.",
      "tldr_zh": "本文提出了一种新的变分自编码器框架CCCVAE，用于单细胞表达谱的表示学习，该框架整合了细胞间通讯(CCC)信号。CCCVAE利用从配体-受体相互作用导出的通信感知核以及稀疏高斯过程，将生物学先验知识编码到潜在空间中。与独立处理每个细胞的传统VAE不同，CCCVAE鼓励潜在嵌入反映转录相似性和细胞间信号传递环境。在四个scRNA-seq数据集上的实验结果表明，CCCVAE提高了聚类性能，优于标准VAE基线，证明了将生物学先验知识嵌入到用于无监督单细胞分析的深度生成模型中的价值。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04891v1",
      "published_date": "2025-05-08 01:53:36 UTC",
      "updated_date": "2025-05-08 01:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:21:28.404250"
    },
    {
      "arxiv_id": "2505.04888v1",
      "title": "Cross-Branch Orthogonality for Improved Generalization in Face Deepfake Detection",
      "title_zh": "用于改进人脸 Deepfake 检测泛化能力的跨分支正交性\n",
      "authors": [
        "Tharindu Fernando",
        "Clinton Fookes",
        "Sridha Sridharan",
        "Simon Denman"
      ],
      "abstract": "Remarkable advancements in generative AI technology have given rise to a\nspectrum of novel deepfake categories with unprecedented leaps in their\nrealism, and deepfakes are increasingly becoming a nuisance to law enforcement\nauthorities and the general public. In particular, we observe alarming levels\nof confusion, deception, and loss of faith regarding multimedia content within\nsociety caused by face deepfakes, and existing deepfake detectors are\nstruggling to keep up with the pace of improvements in deepfake generation.\nThis is primarily due to their reliance on specific forgery artifacts, which\nlimits their ability to generalise and detect novel deepfake types. To combat\nthe spread of malicious face deepfakes, this paper proposes a new strategy that\nleverages coarse-to-fine spatial information, semantic information, and their\ninteractions while ensuring feature distinctiveness and reducing the redundancy\nof the modelled features. A novel feature orthogonality-based disentanglement\nstrategy is introduced to ensure branch-level and cross-branch feature\ndisentanglement, which allows us to integrate multiple feature vectors without\nadding complexity to the feature space or compromising generalisation.\nComprehensive experiments on three public benchmarks: FaceForensics++,\nCeleb-DF, and the Deepfake Detection Challenge (DFDC) show that these design\nchoices enable the proposed approach to outperform current state-of-the-art\nmethods by 5% on the Celeb-DF dataset and 7% on the DFDC dataset in a\ncross-dataset evaluation setting.",
      "tldr_zh": "为了应对日益逼真的面部deepfake带来的挑战，该论文提出了一种新的检测策略，旨在利用粗细粒度的空间信息、语义信息及其相互作用，同时确保特征的独特性并减少冗余。核心在于引入了一种基于特征正交性的解耦策略，以实现分支级别和跨分支的特征解耦，从而在不增加特征空间复杂性的前提下整合多个特征向量，并提升泛化能力。在FaceForensics++、Celeb-DF和Deepfake Detection Challenge (DFDC)三个公共基准数据集上的实验结果表明，该方法在跨数据集评估中，相比现有最佳方法在Celeb-DF数据集上提升了5%，在DFDC数据集上提升了7%。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04888v1",
      "published_date": "2025-05-08 01:49:53 UTC",
      "updated_date": "2025-05-08 01:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:21:40.312357"
    },
    {
      "arxiv_id": "2505.04883v1",
      "title": "QBR: A Question-Bank-Based Approach to Fine-Grained Legal Knowledge Retrieval for the General Public",
      "title_zh": "QBR：一种面向公众的、基于题库的细粒度法律知识检索方法\n",
      "authors": [
        "Mingruo Yuan",
        "Ben Kao",
        "Tien-Hsuan Wu"
      ],
      "abstract": "Retrieval of legal knowledge by the general public is a challenging problem\ndue to the technicality of the professional knowledge and the lack of\nfundamental understanding by laypersons on the subject. Traditional information\nretrieval techniques assume that users are capable of formulating succinct and\nprecise queries for effective document retrieval. In practice, however, the\nwide gap between the highly technical contents and untrained users makes legal\nknowledge retrieval very difficult. We propose a methodology, called QBR, which\nemploys a Questions Bank (QB) as an effective medium for bridging the knowledge\ngap. We show how the QB is used to derive training samples to enhance the\nembedding of knowledge units within documents, which leads to effective\nfine-grained knowledge retrieval. We discuss and evaluate through experiments\nvarious advantages of QBR over traditional methods. These include more\naccurate, efficient, and explainable document retrieval, better comprehension\nof retrieval results, and highly effective fine-grained knowledge retrieval. We\nalso present some case studies and show that QBR achieves social impact by\nassisting citizens to resolve everyday legal concerns.",
      "tldr_zh": "该论文提出了一种名为QBR的基于问题库(Question Bank)的细粒度法律知识检索方法，旨在解决公众法律知识检索的难题。QBR利用问题库作为桥梁，弥合了专业法律知识和缺乏相关背景知识的普通用户之间的差距。该方法通过问题库生成训练样本，增强文档中知识单元的嵌入，从而实现更准确、高效和可解释的细粒度知识检索。实验结果表明，QBR在文档检索的准确性、效率和可解释性方面优于传统方法，并能帮助公众解决日常法律问题，具有重要的社会意义。\n",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04883v1",
      "published_date": "2025-05-08 01:43:21 UTC",
      "updated_date": "2025-05-08 01:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:21:52.284997"
    },
    {
      "arxiv_id": "2505.04881v1",
      "title": "ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning",
      "title_zh": "ConCISE：步步高效推理中基于置信度的压缩方法\n",
      "authors": [
        "Ziqing Qiao",
        "Yongheng Deng",
        "Jiali Zeng",
        "Dong Wang",
        "Lai Wei",
        "Fandong Meng",
        "Jie Zhou",
        "Ju Ren",
        "Yaoxue Zhang"
      ],
      "abstract": "Large Reasoning Models (LRMs) perform strongly in complex reasoning tasks via\nChain-of-Thought (CoT) prompting, but often suffer from verbose outputs caused\nby redundant content, increasing computational overhead, and degrading user\nexperience. Existing compression methods either operate post-hoc pruning,\nrisking disruption to reasoning coherence, or rely on sampling-based selection,\nwhich fails to intervene effectively during generation. In this work, we\nintroduce a confidence-guided perspective to explain the emergence of redundant\nreflection in LRMs, identifying two key patterns: Confidence Deficit, where the\nmodel reconsiders correct steps due to low internal confidence, and Termination\nDelay, where reasoning continues even after reaching a confident answer. Based\non this analysis, we propose ConCISE (Confidence-guided Compression In\nStep-by-step Efficient Reasoning), a framework that simplifies reasoning chains\nby reinforcing the model's confidence during inference, thus preventing the\ngeneration of redundant reflection steps. It integrates Confidence Injection to\nstabilize intermediate steps and Early Stopping to terminate reasoning when\nconfidence is sufficient. Extensive experiments demonstrate that fine-tuning\nLRMs on ConCISE-generated data yields significantly shorter outputs, reducing\nlength by up to approximately 50% under SimPO, while maintaining high task\naccuracy. ConCISE consistently outperforms existing baselines across multiple\nreasoning benchmarks.",
      "tldr_zh": "该论文提出了ConCISE，一个基于置信度引导的压缩框架，旨在解决大型推理模型(LRMs)在使用链式思考(CoT)提示时产生的冗余输出问题。ConCISE通过分析模型在推理过程中出现的置信度不足和终止延迟两种模式，有针对性地进行干预。该框架包含置信度注入(Confidence Injection)和提前停止(Early Stopping)机制，分别用于稳定中间推理步骤和在置信度足够时终止推理。实验结果表明，在ConCISE生成的数据上微调LRMs可以显著缩短输出长度（高达50%），同时保持较高的任务准确率，并在多个推理基准测试中优于现有方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04881v1",
      "published_date": "2025-05-08 01:40:40 UTC",
      "updated_date": "2025-05-08 01:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:22:04.448353"
    },
    {
      "arxiv_id": "2505.04880v1",
      "title": "GroverGPT-2: Simulating Grover's Algorithm via Chain-of-Thought Reasoning and Quantum-Native Tokenization",
      "title_zh": "GroverGPT-2：通过链式思维推理和量子原生 Tokenization 模拟 Grover 算法\n",
      "authors": [
        "Min Chen",
        "Jinglei Cheng",
        "Pingzhi Li",
        "Haoran Wang",
        "Tianlong Chen",
        "Junyu Liu"
      ],
      "abstract": "Quantum computing offers theoretical advantages over classical computing for\nspecific tasks, yet the boundary of practical quantum advantage remains an open\nquestion. To investigate this boundary, it is crucial to understand whether,\nand how, classical machines can learn and simulate quantum algorithms. Recent\nprogress in large language models (LLMs) has demonstrated strong reasoning\nabilities, prompting exploration into their potential for this challenge. In\nthis work, we introduce GroverGPT-2, an LLM-based method for simulating\nGrover's algorithm using Chain-of-Thought (CoT) reasoning and quantum-native\ntokenization. Building on its predecessor, GroverGPT-2 performs simulation\ndirectly from quantum circuit representations while producing logically\nstructured and interpretable outputs. Our results show that GroverGPT-2 can\nlearn and internalize quantum circuit logic through efficient processing of\nquantum-native tokens, providing direct evidence that classical models like\nLLMs can capture the structure of quantum algorithms. Furthermore, GroverGPT-2\noutputs interleave circuit data with natural language, embedding explicit\nreasoning into the simulation. This dual capability positions GroverGPT-2 as a\nprototype for advancing machine understanding of quantum algorithms and\nmodeling quantum circuit logic. We also identify an empirical scaling law for\nGroverGPT-2 with increasing qubit numbers, suggesting a path toward scalable\nclassical simulation. These findings open new directions for exploring the\nlimits of classical simulatability, enhancing quantum education and research,\nand laying groundwork for future foundation models in quantum computing.",
      "tldr_zh": "该论文介绍了GroverGPT-2，一种基于LLM的方法，用于模拟Grover算法，它结合了链式思维(CoT)推理和量子原生标记化。GroverGPT-2直接从量子电路表示执行模拟，并生成逻辑结构化和可解释的输出，展示了LLM可以通过有效处理量子原生token来学习和内化量子电路逻辑。研究表明，GroverGPT-2可以将电路数据与自然语言交织，将显式推理嵌入到模拟中，从而促进机器对量子算法的理解和量子电路逻辑的建模。此外，论文还提出了GroverGPT-2随qubit数量增加的经验缩放规律，为可扩展的经典模拟提供了方向，并为量子计算领域的基础模型奠定了基础。\n",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "26 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04880v1",
      "published_date": "2025-05-08 01:38:12 UTC",
      "updated_date": "2025-05-08 01:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:22:16.489530"
    },
    {
      "arxiv_id": "2505.04877v1",
      "title": "Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via Adaptive Sharpness-Aware Gradient Aligning",
      "title_zh": "从损失景观中学习：通过自适应锐度感知梯度对齐实现可泛化的混合精度量化",
      "authors": [
        "Lianbo Ma",
        "Jianlun Ma",
        "Yuee Zhou",
        "Guoyang Xie",
        "Qiang He",
        "Zhichao Lu"
      ],
      "abstract": "Mixed Precision Quantization (MPQ) has become an essential technique for\noptimizing neural network by determining the optimal bitwidth per layer.\nExisting MPQ methods, however, face a major hurdle: they require a\ncomputationally expensive search for quantization policies on large-scale\ndatasets. To resolve this issue, we introduce a novel approach that first\nsearches for quantization policies on small datasets and then generalizes them\nto large-scale datasets. This approach simplifies the process, eliminating the\nneed for large-scale quantization fine-tuning and only necessitating model\nweight adjustment. Our method is characterized by three key techniques:\nsharpness-aware minimization for enhanced quantization generalization, implicit\ngradient direction alignment to handle gradient conflicts among different\noptimization objectives, and an adaptive perturbation radius to accelerate\noptimization. Both theoretical analysis and experimental results validate our\napproach. Using the CIFAR10 dataset (just 0.5\\% the size of ImageNet training\ndata) for MPQ policy search, we achieved equivalent accuracy on ImageNet with a\nsignificantly lower computational cost, while improving efficiency by up to\n150% over the baselines.",
      "tldr_zh": "本文提出了一种新的混合精度量化(MPQ)方法，旨在解决现有方法需要在大型数据集上进行昂贵的量化策略搜索的问题。该方法首先在小数据集上搜索量化策略，然后将其推广到大型数据集，从而避免了大规模的量化微调。其核心技术包括：基于锐度感知最小化(sharpness-aware minimization)以增强量化泛化能力，隐式梯度方向对齐(implicit gradient direction alignment)以处理不同优化目标之间的梯度冲突，以及自适应扰动半径(adaptive perturbation radius)以加速优化。实验结果表明，该方法在CIFAR10数据集（仅为ImageNet训练数据的0.5%）上进行MPQ策略搜索，即可在ImageNet上获得相当的精度，同时效率提高了高达150%。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04877v1",
      "published_date": "2025-05-08 01:20:24 UTC",
      "updated_date": "2025-05-08 01:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:22:28.592911"
    },
    {
      "arxiv_id": "2505.04873v1",
      "title": "Federated Learning for Cyber Physical Systems: A Comprehensive Survey",
      "title_zh": "面向信息物理系统的联邦学习：一项综合综述\n",
      "authors": [
        "Minh K. Quan",
        "Pubudu N. Pathirana",
        "Mayuri Wijayasundara",
        "Sujeeva Setunge",
        "Dinh C. Nguyen",
        "Christopher G. Brinton",
        "David J. Love",
        "H. Vincent Poor"
      ],
      "abstract": "The integration of machine learning (ML) in cyber physical systems (CPS) is a\ncomplex task due to the challenges that arise in terms of real-time decision\nmaking, safety, reliability, device heterogeneity, and data privacy. There are\nalso open research questions that must be addressed in order to fully realize\nthe potential of ML in CPS. Federated learning (FL), a distributed approach to\nML, has become increasingly popular in recent years. It allows models to be\ntrained using data from decentralized sources. This approach has been gaining\npopularity in the CPS field, as it integrates computer, communication, and\nphysical processes. Therefore, the purpose of this work is to provide a\ncomprehensive analysis of the most recent developments of FL-CPS, including the\nnumerous application areas, system topologies, and algorithms developed in\nrecent years. The paper starts by discussing recent advances in both FL and\nCPS, followed by their integration. Then, the paper compares the application of\nFL in CPS with its applications in the internet of things (IoT) in further\ndepth to show their connections and distinctions. Furthermore, the article\nscrutinizes how FL is utilized in critical CPS applications, e.g., intelligent\ntransportation systems, cybersecurity services, smart cities, and smart\nhealthcare solutions. The study also includes critical insights and lessons\nlearned from various FL-CPS implementations. The paper's concluding section\ndelves into significant concerns and suggests avenues for further research in\nthis fast-paced and dynamic era.",
      "tldr_zh": "本文全面综述了联邦学习(FL)在信息物理系统(CPS)中的最新发展。由于CPS对实时决策、安全性、可靠性、设备异构性和数据隐私的挑战，将机器学习(ML)集成到CPS中是一项复杂的任务。联邦学习作为一种分布式ML方法，允许使用来自去中心化源的数据训练模型，因其在整合计算机、通信和物理过程方面的优势，在CPS领域越来越受欢迎。本文深入探讨了FL在智能交通系统、网络安全服务、智慧城市和智能医疗保健解决方案等关键CPS应用中的应用，并总结了各种FL-CPS实施中的关键见解和经验教训，最后探讨了该领域的重要问题，并为未来的研究方向提出了建议。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted by IEEE Communications Surveys &\n  Tutorials",
      "pdf_url": "http://arxiv.org/pdf/2505.04873v1",
      "published_date": "2025-05-08 01:17:15 UTC",
      "updated_date": "2025-05-08 01:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:22:40.471816"
    },
    {
      "arxiv_id": "2505.04864v1",
      "title": "Auto-regressive transformation for image alignment",
      "title_zh": "用于图像对齐的自回归变换\n",
      "authors": [
        "Kanggeon Lee",
        "Soochahn Lee",
        "Kyoung Mu Lee"
      ],
      "abstract": "Existing methods for image alignment struggle in cases involving\nfeature-sparse regions, extreme scale and field-of-view differences, and large\ndeformations, often resulting in suboptimal accuracy. Robustness to these\nchallenges improves through iterative refinement of the transformation field\nwhile focusing on critical regions in multi-scale image representations. We\nthus propose Auto-Regressive Transformation (ART), a novel method that\niteratively estimates the coarse-to-fine transformations within an\nauto-regressive framework. Leveraging hierarchical multi-scale features, our\nnetwork refines the transformations using randomly sampled points at each\nscale. By incorporating guidance from the cross-attention layer, the model\nfocuses on critical regions, ensuring accurate alignment even in challenging,\nfeature-limited conditions. Extensive experiments across diverse datasets\ndemonstrate that ART significantly outperforms state-of-the-art methods,\nestablishing it as a powerful new method for precise image alignment with broad\napplicability.",
      "tldr_zh": "本文提出了一种新的图像对齐方法——自回归变换(Auto-Regressive Transformation, ART)，旨在解决现有方法在特征稀疏区域、极端尺度和视场差异以及大形变情况下表现不佳的问题。ART在一个自回归框架内迭代估计由粗到精的变换，利用分层多尺度特征，并通过交叉注意力层引导模型关注关键区域，从而在特征有限的挑战性条件下实现精确对齐。在多个数据集上的大量实验表明，ART显著优于现有技术，成为一种强大的图像对齐新方法，具有广泛的适用性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04864v1",
      "published_date": "2025-05-08 00:28:31 UTC",
      "updated_date": "2025-05-08 00:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:22:52.353263"
    },
    {
      "arxiv_id": "2505.04860v1",
      "title": "D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation",
      "title_zh": "D-CODA：用于协同双臂数据增强的扩散模型\n",
      "authors": [
        "I-Chun Arthur Liu",
        "Jason Chen",
        "Gaurav Sukhatme",
        "Daniel Seita"
      ],
      "abstract": "Learning bimanual manipulation is challenging due to its high dimensionality\nand tight coordination required between two arms. Eye-in-hand imitation\nlearning, which uses wrist-mounted cameras, simplifies perception by focusing\non task-relevant views. However, collecting diverse demonstrations remains\ncostly, motivating the need for scalable data augmentation. While prior work\nhas explored visual augmentation in single-arm settings, extending these\napproaches to bimanual manipulation requires generating viewpoint-consistent\nobservations across both arms and producing corresponding action labels that\nare both valid and feasible. In this work, we propose Diffusion for COordinated\nDual-arm Data Augmentation (D-CODA), a method for offline data augmentation\ntailored to eye-in-hand bimanual imitation learning that trains a diffusion\nmodel to synthesize novel, viewpoint-consistent wrist-camera images for both\narms while simultaneously generating joint-space action labels. It employs\nconstrained optimization to ensure that augmented states involving\ngripper-to-object contacts adhere to constraints suitable for bimanual\ncoordination. We evaluate D-CODA on 5 simulated and 3 real-world tasks. Our\nresults across 2250 simulation trials and 300 real-world trials demonstrate\nthat it outperforms baselines and ablations, showing its potential for scalable\ndata augmentation in eye-in-hand bimanual manipulation. Our project website is\nat: https://dcodaaug.github.io/D-CODA/.",
      "tldr_zh": "该论文提出了Diffusion for COordinated Dual-arm Data Augmentation (D-CODA)，一种用于双臂模仿学习的离线数据增强方法，特别针对手眼视觉。D-CODA训练一个扩散模型，合成视角一致的双臂腕部相机图像，并同时生成关节空间动作标签。该方法采用约束优化，确保增强后的状态（特别是gripper与物体接触时）满足双臂协调的约束条件。实验结果表明，D-CODA在模拟和真实世界的双臂操作任务中优于基线方法，验证了其在手眼双臂操作中进行可扩展数据增强的潜力。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04860v1",
      "published_date": "2025-05-08 00:03:04 UTC",
      "updated_date": "2025-05-08 00:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-10T02:23:04.493449"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 78,
  "processed_papers_count": 78,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-10T02:25:22.534796"
}