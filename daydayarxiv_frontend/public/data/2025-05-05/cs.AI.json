{
  "date": "2025-05-05",
  "category": "cs.AI",
  "summary": "<thought>**My Approach to Crafting the arXiv TLDR快报**\n\nMy process for compiling the arXiv TLDR快报 is methodical and designed to efficiently distill a large volume of research. I start by focusing on the core goal: to produce a concise, informative, and engaging daily report in Chinese that highlights the most important and interesting arXiv papers for researchers. I prioritize papers based on their potential impact and relevance to current hot topics.\n\nFirst, I quickly scan all paper titles and abstracts, mentally categorizing them into broad themes like LLMs, Vision, Reinforcement Learning, and AI Safety. During this initial scan, I flag papers that stand out for their novelty, potential impact, or association with well-known authors or institutions. I also note papers that are surveys or highly specialized, which will likely warrant briefer summaries unless they offer significant new perspectives.\n\nNext, I prioritize papers based on their relevance to \"hot\" topics, novel frameworks or methods, impactful applications, and foundation models or benchmarks. I understand that the LLMs category will likely dominate, so papers on LLM reasoning, efficiency, safety, and diverse applications will be heavily emphasized.\n\nIn the drafting stage, I begin with a standard greeting and a one-sentence summary that captures the main themes of the day's papers. I pay close attention to the inclusion of specific standout areas, like \"多模态交互\" (multimodal interaction) or \"AI智能体\" (AI agents), to add flavor and clarity.\n\nFor each paper, I aim to provide a concise summary that includes the Chinese and English titles, the core contribution, the methodology, key findings/results, and, if appropriate, the implications. I emphasize conciseness and use strong verbs to convey information efficiently, ensuring that key academic terms are present. I refine each summary iteratively, looking for opportunities to group similar papers and ensure smooth transitions between them. For papers that I deem less critical or highly niche, the summary is much shorter to maintain the overall \"quick report\" length.\n\nFinally, I review and edit the entire report, ensuring clarity, conciseness, and accuracy. I verify that all output requirements are met and make any necessary adjustments to ensure a good balance between detail for important papers and brevity for others. This systematic approach allows me to process a large number of abstracts efficiently and present the most relevant information in a structured and accessible way for the target audience.\n</thought>欢迎来到 UTC 时间2025-05-05的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文热点依然高度集中在大型语言模型 (LLM) 的各个方面，包括其推理能力的提升、在特定领域的应用、效率优化、安全性以及多模态交互能力的拓展。值得关注的亮点包括：用于卫星图像理解的语言指令分割助手 LISAT，通过开放式反馈自动归纳智能体评估指标的 AutoLibra，探索 LLM 在法律程序自动化中的应用，以及旨在实现实时自主交互的语音语言基础模型 Voila。此外，关于 LLM 的形式化数学推理、临床推理增强、以及通过强化学习进行微调的论文也纷纷涌现。AI 安全、可解释性以及数据版权问题同样是研究者们关注的焦点。\n\n接下来，我们一起看看今天有哪些值得关注的论文：\n\n---\n\n**重点关注：LLM 与多模态、智能体及应用**\n\n1.  **LISAT: 用于卫星图像的语言指令分割助手 (LISAT: Language-Instructed Segmentation Assistant for Satellite Imagery)**\n    *   核心贡献：提出 LISAT，一个专为遥感图像设计的视觉语言模型，能够理解复杂的用户查询，描述遥感场景，回答问题并分割感兴趣的对象。同时发布了新的地理空间推理分割数据集 GRES 和多模态预训练数据集 PreGRES。\n    *   发现：LISAT 在遥感描述任务上显著优于现有地理空间基础模型（如 RS-GPT4V），并在推理分割任务上远超最先进的开放域模型。\n    *   意义：推动了视觉语言模型在复杂遥感图像分析领域的应用，特别是在理解和执行基于自然语言的复杂指令方面。\n\n2.  **AutoLibra: 从开放式反馈中归纳智能体指标 (AutoLibra: Agent Metric Induction from Open-Ended Feedback)**\n    *   核心贡献：提出 AutoLibra 框架，能将开放式的人类反馈（如“如果按钮禁用，不要再点击”）转化为评估智能体轨迹中细粒度行为的指标。\n    *   方法：通过将反馈与智能体行为关联，聚类相似的正反行为，并创建包含明确定义和具体示例的指标，这些指标可用于提示 LLM 作为评估器。\n    *   发现：AutoLibra 能归纳出比现有智能体评估基准更具体的指标，并发现新的指标来分析智能体，其归纳的指标在改进智能体方面（如文本游戏和网页导航）表现更优。\n    *   意义：为智能体评估和改进提供了一种更自动化、更细致且任务无关的方法，有助于开发更可靠的语言智能体。\n\n3.  **Voila: 用于实时自主交互和语音角色扮演的语音语言基础模型 (Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play)**\n    *   核心贡献：推出 Voila，一系列大型语音语言基础模型，旨在实现全双工、低延迟（195毫秒响应）的对话，同时保留丰富的声音细节如音调、节奏和情感。\n    *   方法：采用端到端架构和分层多尺度 Transformer，集成了 LLM 的推理能力和强大的声学建模。\n    *   发现：Voila 支持超过一百万种预构建声音和快速定制新声音（最短10秒音频），并可统一处理自动语音识别（ASR）、文本到语音（TTS）和多语言语音翻译等任务。模型已开源。\n    *   意义：向更自然、更具情感共鸣的下一代人机交互迈出了重要一步，有望推动语音 AI 代理的广泛应用。\n\n4.  **El Agente: 一个用于量子化学的自主智能体 (El Agente: An Autonomous Agent for Quantum Chemistry)**\n    *   核心贡献：介绍 El Agente Q，一个基于 LLM 的多智能体系统，能从自然语言用户提示中动态生成并执行量子化学工作流程。\n    *   方法：基于一种新颖的认知架构，具有分层记忆框架，支持灵活的任务分解、自适应工具选择、后分析以及自主文件处理和提交。\n    *   发现：在大学水平的课程练习和案例研究中表现出强大的问题解决能力（平均任务成功率>87%）和通过现场调试实现的自适应错误处理能力。\n    *   意义：为实现更自主、更易用的量子化学研究奠定了基础，降低了复杂计算化学工具的使用门槛。\n\n---\n\n**LLM 推理与优化**\n\n5.  **知道你不知道：通过自我实践学习何时在多轮 RAG 中继续搜索 (Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing)**\n    *   核心贡献：提出 SIM-RAG 框架，旨在增强检索增强生成 (RAG) 系统的自我意识和多轮检索能力，解决现有系统在信息不足时仍错误回答或信息充足时仍继续搜索的问题。\n    *   方法：让 RAG 系统自我实践多轮检索生成合成训练数据，训练一个轻量级信息充分性评估器 (Critic)，在推理时指导检索决策。\n    *   发现：SIM-RAG 在多个 RAG 基准测试中表现有效，且系统高效、数据高效，无需昂贵的人工标注。\n    *   意义：提升了复杂问答场景下 RAG 系统的鲁棒性和效率。\n\n6.  **FormalMATH: 大型语言模型形式化数学推理基准 (FormalMATH: Benchmarking Formal Mathematical Reasoning of Large Language Models)**\n    *   核心贡献：提出 FormalMATH，一个包含5560个形式化验证问题的 Lean4 大规模基准，涵盖从高中奥林匹克到本科水平的多个数学领域。同时提出了一种人机协同的自动形式化流程。\n    *   发现：当前最先进的 LLM 定理证明器在该基准上成功率仅为16.46%，表现出明显的领域偏见，并过度依赖简化的自动化策略。有趣的是，自然语言解决方案指导在思维链推理场景中与证明成功率呈负相关。\n    *   意义：为评估和推动 LLM 在形式化数学推理这一挑战性任务上的发展提供了重要工具。\n\n7.  **通过拒绝采样和强化学习中的梯度方差最小化优化思维链推理器 (Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL)**\n    *   核心贡献：提出 GVM-RAFT，一种针对提示的动态样本分配策略，旨在在计算预算约束下最小化随机梯度方差，以解决思维链 (CoT) 训练中因静态采样策略导致的低效随机梯度估计问题。\n    *   方法：通过监控提示接受率和随机梯度范数来动态分配计算资源。\n    *   发现：GVM-RAFT 在数学推理任务上比传统 RAFT 实现了2-4倍的加速和显著的准确性提升，该策略也可推广到其他强化学习算法。\n    *   意义：为提高 CoT 推理 LLM 的训练效率和性能提供了新思路。\n\n8.  **RM-R1: 作为推理的奖励建模 (RM-R1: Reward Modeling as Reasoning)**\n    *   核心贡献：提出一类新的生成式奖励模型——推理奖励模型 (ReasRMs)，并将奖励建模表述为一个推理任务。推出了 RM-R1 系列模型。\n    *   方法：采用两阶段训练流程：(1) 提炼高质量推理链；(2) 使用可验证奖励进行强化学习。RM-R1 通过自生成推理轨迹或特定于聊天的评估标准来评估候选响应。\n    *   发现：RM-R1 在多个奖励模型基准上达到 SOTA 或接近 SOTA 水平，性能优于许多更大的开源模型和专有模型，并提升了可解释性。\n    *   意义：为提升 LLM 对齐过程中的奖励模型性能和可解释性提供了新范式。\n\n9.  **HSplitLoRA: 面向大型语言模型的异构分割参数高效微调框架 (HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models)**\n    *   核心贡献：提出 HSplitLoRA，一个基于分割学习 (SL) 和低秩适应 (LoRA) 的异构参数高效微调 (PEFT) 框架，用于在异构客户端设备上高效微调 LLM。\n    *   方法：识别重要权重，动态配置 LoRA 适配器的分解秩，根据客户端计算预算确定模型分割点，并设计无噪声适配器聚合机制。\n    *   发现：HSplitLoRA 在训练准确性和收敛速度方面优于现有基准。\n    *   意义：为资源受限和异构环境下的 LLM 微调提供了更有效的解决方案。\n\n10. **EMORL: 用于高效灵活 LLM 微调的集成多目标强化学习 (EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning)**\n    *   核心贡献：提出 EMORL 框架，利用集成学习原理，通过对多个具有单一目标的模型进行微调，并在训练后优化它们的聚合，以提高多目标 LLM 微调的效率和灵活性。\n    *   方法：首次聚合各个模型的最后隐藏状态，并使用分层网格搜索算法确定最佳加权组合。\n    *   发现：EMORL 在辅导员反思生成任务上，相比基线显著降低了训练消耗，提高了可扩展性和可解释性，并在多目标上表现相当。\n    *   意义：为解决 LLM 多目标微调中的复杂平衡、低效和可扩展性差等问题提供了新思路。\n\n11. **递归分解与依赖关系：用于通用分治推理 (Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning)**\n    *   核心贡献：提出递归分解与依赖关系 (RDD)，一种可扩展的分治方法，用于解决推理问题，比先前方法需要更少的监督。\n    *   方法：RDD 支持子任务依赖和有序执行，以及错误恢复机制。\n    *   发现：在计算匹配的情况下，随着任务复杂度的增加，RDD 优于其他方法，并且计算效率更高。\n    *   意义：为复杂推理任务提供了一种更通用、更高效的 LLM 解决方案。\n\n12. **慢思考推理 LLM 综述：基于强化学习和推理时伸缩定律 (A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law)**\n    *   核心贡献：这篇综述探讨了模仿“慢思考”（如 OpenAI 的 o1）的推理 LLM 的最新进展，这些模型在复杂任务中动态调整计算资源。\n    *   内容：将方法分为三类：测试时伸缩、强化学习和慢思考框架，并讨论了该领域的挑战和未来方向。\n    *   意义：为理解和推进 LLM 的深度推理能力提供了有价值的概述。\n\n---\n\n**AI 安全、可解释性与伦理**\n\n13. **可解释人工智能中的隐私风险与保护方法：范围综述 (Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review)**\n    *   核心贡献：对现有文献进行范围综述，探讨可解释人工智能 (XAI) 中隐私与可解释性之间的冲突。\n    *   内容：回顾了57篇文章，识别了 XAI 中解释发布的隐私风险、现有的隐私保护方法，并提出了隐私保护解释的构成要素。\n    *   意义：为研究人员和实践者理解隐私合规 XAI 的要求提供了指导，并指出了平衡隐私与其他系统需求的挑战。\n\n14. **数据集版权规避攻击：针对个性化文本到图像扩散模型 (Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models)**\n    *   核心贡献：首次提出针对文本到图像 (T2I) 扩散模型中数据集所有权验证 (DOV) 机制的版权规避攻击 (CEAT2I)。\n    *   方法：CEAT2I 包括水印样本检测、触发器识别和高效水印缓解三个阶段。利用 T2I 模型在微调过程中对水印样本收敛更快的特性进行检测。\n    *   发现：CEAT2I 能有效规避 DOV 机制，同时保持模型性能。\n    *   意义：揭示了当前 T2I 模型版权保护机制的脆弱性，对未来的版权保护技术提出了挑战。\n\n15. **再见，蓝皮书？用大型语言模型自动化法律程序 (Bye-bye, Bluebook? Automating Legal Procedure with Large Language Models)**\n    *   核心贡献：构建了一个包含866个《蓝皮书》（美国法律引用统一系统）任务的原始数据集，并测试了主流 LLM 在遵守这一复杂程序规则方面的能力。\n    *   发现：即使是旗舰 LLM，生成完全合规的《蓝皮书》引用的准确率也仅在69%-74%之间，通过上下文学习规则也只能提升到77%。\n    *   意义：警示了在对程序保真度要求极高的法律领域，直接使用现有 LLM 进行自动化的风险。\n\n16. **大型语言模型智能体的目标漂移评估技术报告 (Technical Report: Evaluating Goal Drift in Language Model Agents)**\n    *   核心贡献：提出一种分析语言模型 (LM) 智能体目标漂移（随时间偏离原始目标的趋势）的新方法。\n    *   发现：实验表明，即使是性能最好的智能体（Claude 3.5 Sonnet 的脚手架版本）也会表现出一定程度的目标漂移，且目标漂移与模型随着上下文长度增加而对模式匹配行为的易感性增加相关。\n    *   意义：对于需要长期自主运行的 LM 智能体，理解和测量目标漂移对于确保其安全运行至关重要。\n\n17. **智能体的神经多样性作为 AI 对齐问题的权变解决方案 (Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem)**\n    *   核心贡献：论证完全的 AI 对齐由于逻辑和可计算性的基本原理（如图灵的计算普遍性、哥德尔不完备性和蔡廷随机性）是无法实现的。\n    *   主张：接受 AI 的“神经多样性”或部分不对齐，并培养一个竞争性的、部分对齐的智能体动态生态系统，是减轻风险的可能路径。\n    *   意义：对 AI 对齐问题提出了一个根本性的挑战，并提供了一个基于数学原理的替代性思考框架。\n\n18. **什么是 AI 安全？我们希望它是什么？(What Is AI Safety? What Do We Want It to Be?)**\n    *   核心贡献：探讨 AI 安全领域的定义，认为将 AI 安全的目标仅仅限定于防止未来系统的灾难性风险，或将其视为安全工程的一个分支，与“AI 安全旨在防止或减少 AI 系统造成的危害”这一更广泛的“安全概念”存在张力。\n    *   主张：从描述性和规范性角度来看，更广泛的“安全概念”更有利于该领域的发展，能够包容偏见、错误信息和隐私等问题。\n    *   意义：对 AI 安全领域的核心目标和范围进行了哲学思辨，有助于领域内的共识建立和发展方向。\n\n---\n\n**特定领域应用与技术**\n\n19. **利用全国性脓毒症登记处的真实世界数据增强 LLM 的临床推理能力 (Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry)**\n    *   核心贡献：通过利用全国性脓毒症登记处的真实世界临床数据，构建推理密集型问题，并使用强化学习对 Phi-4 进行微调，得到 C-Reason 模型，以增强 LLM 的临床推理能力。\n    *   发现：C-Reason 在领域内测试集上表现出强大的临床推理能力，并能泛化到不同任务和患者队列的脓毒症数据集、抗生素使用咨询以及其他疾病。\n    *   意义：展示了利用真实世界临床数据提升 LLM 在医疗领域推理能力的有效途径。\n\n20. **超越显示器：混合现实可视化与 AI 增强数字病理学工作流程 (Beyond the Monitor: Mixed Reality Visualization and AI for Enhanced Digital Pathology Workflow)**\n    *   核心贡献：推出 PathVis，一个用于 Apple Vision Pro 的混合现实可视化平台，旨在改善病理学家与千兆像素级全玻片图像 (WSI) 的交互方式。\n    *   方法：PathVis 用自然手势、眼动追踪和语音命令替代传统的鼠标键盘导航，并集成 AI 驱动的相似病例检索和多模态对话式 AI 助手。\n    *   意义：有望通过沉浸式工作空间和 AI辅助，减少病理学家的认知负荷，提高诊断效率和准确性。\n\n21. **利用大型语言模型和双任务学习增强化学反应和逆合成预测 (Enhancing Chemical Reaction and Retrosynthesis Prediction with Large Language Model and Dual-task Learning)**\n    *   核心贡献：提出 ChemDual，一种用于精确化学合成的新型 LLM 框架，解决了化学合成相关指令数据集大规模缺乏以及现有微调策略忽略反应与逆合成预测之间密切关联的问题。\n    *   方法：构建了包含440万条指令的大规模数据集，并引入了配备多尺度分词器和双任务学习策略的增强型 LLaMA。\n    *   发现：ChemDual 在反应预测和逆合成预测方面均达到 SOTA 水平，生成的化合物具有多样且强的蛋白质结合亲和力。\n    *   意义：展示了 LLM 在药物发现和设计领域的巨大潜力。\n\n22. **LLaMA-Omni2: 基于自回归流式语音合成的 LLM 实时语音聊天机器人 (LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis)**\n    *   核心贡献：推出 LLaMA-Omni 2，一系列参数从0.5B到14B的语音语言模型 (SpeechLMs)，能够实现高质量的实时语音交互。\n    *   方法：基于 Qwen2.5 系列模型构建，集成了语音编码器和自回归流式语音解码器。\n    *   发现：尽管仅在20万个多轮语音对话样本上训练，LLaMA-Omni 2 在多个语音问答和语音指令遵循基准上表现强劲，超过了之前最先进的 SpeechLMs。\n    *   意义：推动了基于 LLM 的智能语音聊天机器人的发展，使其更接近自然流畅的人机交互。\n\n23. **知识图谱用于增强大型语言模型中的实体消歧 (Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation)**\n    *   核心贡献：提出一种利用知识图谱 (KG) 来增强大型语言模型 (LLM) 进行零样本实体消歧 (ED) 的方法。\n    *   方法：利用 KG 中实体类别的层次表示来逐步裁剪候选空间，并利用实体描述来丰富输入提示的额外事实知识。\n    *   发现：该方法优于未增强和仅描述增强的 LLM，并且比特定任务模型具有更高的适应性。\n    *   意义：为解决 LLM 知识过时或缺失特定领域信息的问题提供了一种有效途径。\n\n24. **用于控制生物网络的基于图神经网络的强化学习：GATTACA 框架 (Graph Neural Network-Based Reinforcement Learning for Controlling Biological Networks: The GATTACA Framework)**\n    *   核心贡献：探索使用深度强化学习 (DRL) 控制复杂生物系统（如基因调控网络和信号通路网络）的布尔网络模型，特别关注细胞重编程。\n    *   方法：提出一种新的布尔网络模型控制问题，并设计了一个计算框架，将图神经网络与图卷积集成到 DRL 代理的动作价值函数逼近器中。\n    *   发现：在多个大型真实世界生物网络上的实验证明了该方法的可扩展性和有效性。\n    *   意义：为通过计算方法发现细胞重编程策略提供了新工具。\n\n---\n\n**其他值得关注的论文**\n\n25. **关于使用大型语言模型生成统计准确的表格数据的说明 (A Note on Statistically Accurate Tabular Data Generation Using Large Language Models)**\n    *   核心贡献：提出一种概率驱动的提示方法，利用 LLM 估计条件分布，以生成更准确和可扩展的表格数据，旨在保留复杂的特征依赖性，特别是分类变量之间的依赖性。\n\n26. **SCFormer: 用于多元时间序列预测的结构化通道 Transformer 与累积历史状态 (SCFormer: Structured Channel-wise Transformer with Cumulative Historical State for Multivariate Time Series Forecasting)**\n    *   核心贡献：提出 SCFormer，通过对所有线性变换（包括查询、键、值矩阵和全连接层）引入时间约束，并使用高阶多项式投影算子 (HiPPO) 处理累积历史时间序列，以改进多元时间序列预测。\n\n27. **Bielik v3 Small: 技术报告 (Bielik v3 Small: Technical Report) & Bielik 11B v2 技术报告 (Bielik 11B v2 Technical Report)**\n    *   核心贡献：分别介绍了 Bielik v3 (1.5B 和 4.5B 参数) 和 Bielik 11B v2，一系列针对波兰语优化的参数高效生成文本模型。\n    *   方法：采用了定制的波兰语分词器 (APT4)、加权指令交叉熵损失和自适应学习率等创新。\n    *   发现：这些模型在波兰语基准测试中表现出色，性能可与参数量大数倍的模型相媲美，为资源受限的非英语语言 AI 应用提供了高质量解决方案。\n\n28. **SuperEdit: 纠正和促进基于指令的图像编辑的监督 (SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing)**\n    *   核心贡献：通过为给定的图像对构建更有效的编辑指令来解决现有图像编辑数据集中指令与图像对不匹配导致的噪声监督问题。\n    *   方法：利用 VLM 纠正编辑指令，并引入对比编辑指令和三元组损失来增强监督效果。\n    *   发现：在多个基准上显著优于现有方法，且无需额外的 VLM 模块或预训练任务。\n\n29. **MetaScenes: 迈向真实世界 3D 扫描的自动化副本创建 (MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans)**\n    *   核心贡献：推出 MetaScenes，一个由真实世界扫描构建的大规模、可模拟的 3D 场景数据集，包含15366个对象，横跨831个细粒度类别。同时提出 Scan2Sim，一个鲁棒的多模态对齐模型，用于自动化高质量资产替换。\n    *   意义：为具身智能 (EAI) 研究提供了高质量、多样化的 3D 场景，支持更通用的智能体学习和模拟到现实的应用。\n\n30. **重新思考联邦图学习：数据压缩视角 (Rethinking Federated Graph Learning: A Data Condensation Perspective)**\n    *   核心贡献：提出一种新的联邦图学习 (FGL) 范式 FedGM，利用压缩图作为新的优化载体来解决 FGL 数据异构性问题。\n    *   方法：使用广义压缩图共识来聚合分布式图的综合知识，并通过单次传输压缩数据来最小化通信成本和隐私风险。\n\n31. **大型语言模型在边缘设备低延迟推理的分区策略 (Large Language Model Partitioning for Low-Latency Inference at the Edge)**\n    *   核心贡献：提出一种资源感知的 Transformer 架构分区算法，在生成 token 过程中定期更新分区决策，以减少 LLM 在资源受限的边缘环境中的推理延迟。\n    *   方法：在注意力头级别对解码器进行分区，并将每个注意力头与其键值缓存共同定位，允许在资源紧张时进行动态迁移。\n\n32. **T2S: 基于文本到序列扩散模型的高分辨率时间序列生成 (T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models)**\n    *   核心贡献：提出 T2S，一个基于扩散的框架，以领域无关的方式连接自然语言和时间序列，能够生成任意长度的高分辨率时间序列。同时构建了一个包含超过60万个高分辨率时间序列-文本对的新型片段级数据集。\n\n---\n\n今天的 arXiv 快报就到这里，希望对您有所帮助！",
  "papers": [
    {
      "arxiv_id": "2505.02829v1",
      "title": "LISAT: Language-Instructed Segmentation Assistant for Satellite Imagery",
      "title_zh": "LISAT：用于卫星图像的语言指令分割助手\n",
      "authors": [
        "Jerome Quenum",
        "Wen-Han Hsieh",
        "Tsung-Han Wu",
        "Ritwik Gupta",
        "Trevor Darrell",
        "David M. Chan"
      ],
      "abstract": "Segmentation models can recognize a pre-defined set of objects in images.\nHowever, models that can reason over complex user queries that implicitly refer\nto multiple objects of interest are still in their infancy. Recent advances in\nreasoning segmentation--generating segmentation masks from complex, implicit\nquery text--demonstrate that vision-language models can operate across an open\ndomain and produce reasonable outputs. However, our experiments show that such\nmodels struggle with complex remote-sensing imagery. In this work, we introduce\nLISAt, a vision-language model designed to describe complex remote-sensing\nscenes, answer questions about them, and segment objects of interest. We\ntrained LISAt on a new curated geospatial reasoning-segmentation dataset, GRES,\nwith 27,615 annotations over 9,205 images, and a multimodal pretraining\ndataset, PreGRES, containing over 1 million question-answer pairs. LISAt\noutperforms existing geospatial foundation models such as RS-GPT4V by over\n10.04 % (BLEU-4) on remote-sensing description tasks, and surpasses\nstate-of-the-art open-domain models on reasoning segmentation tasks by 143.36 %\n(gIoU). Our model, datasets, and code are available at\nhttps://lisat-bair.github.io/LISAt/",
      "tldr_zh": "该论文提出了LISAT，一个专为卫星图像设计的语言指令分割助手。LISAT是一个视觉-语言模型，能够描述复杂的遥感场景，回答相关问题，并分割感兴趣的目标。研究者们构建了一个新的地理空间推理分割数据集GRES（包含27,615个标注，覆盖9,205张图像）和一个多模态预训练数据集PreGRES（包含超过100万个问答对）来训练LISAT。实验结果表明，LISAT在遥感描述任务上超越了现有的地理空间基础模型RS-GPT4V超过10.04% (BLEU-4)，并在推理分割任务上超过了最先进的开放域模型143.36% (gIoU)。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 10 figures, 19 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.02829v1",
      "published_date": "2025-05-05 17:56:25 UTC",
      "updated_date": "2025-05-05 17:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:15:48.172427"
    },
    {
      "arxiv_id": "2505.02828v1",
      "title": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review",
      "title_zh": "可解释人工智能中的隐私风险与保护方法：范围界定综述\n",
      "authors": [
        "Sonal Allana",
        "Mohan Kankanhalli",
        "Rozita Dara"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a pillar of\nTrustworthy AI and aims to bring transparency in complex models that are opaque\nby nature. Despite the benefits of incorporating explanations in models, an\nurgent need is found in addressing the privacy concerns of providing this\nadditional information to end users. In this article, we conduct a scoping\nreview of existing literature to elicit details on the conflict between privacy\nand explainability. Using the standard methodology for scoping review, we\nextracted 57 articles from 1,943 studies published from January 2019 to\nDecember 2024. The review addresses 3 research questions to present readers\nwith more understanding of the topic: (1) what are the privacy risks of\nreleasing explanations in AI systems? (2) what current methods have researchers\nemployed to achieve privacy preservation in XAI systems? (3) what constitutes a\nprivacy preserving explanation? Based on the knowledge synthesized from the\nselected studies, we categorize the privacy risks and preservation methods in\nXAI and propose the characteristics of privacy preserving explanations to aid\nresearchers and practitioners in understanding the requirements of XAI that is\nprivacy compliant. Lastly, we identify the challenges in balancing privacy with\nother system desiderata and provide recommendations for achieving privacy\npreserving XAI. We expect that this review will shed light on the complex\nrelationship of privacy and explainability, both being the fundamental\nprinciples of Trustworthy AI.",
      "tldr_zh": "这篇综述探讨了可解释人工智能(XAI)中存在的隐私风险以及相应的保护方法。通过对2019年至2024年间发表的1943篇研究中的57篇文章进行筛选和分析，文章总结了XAI中发布解释所带来的隐私风险，并对现有研究人员采用的隐私保护方法进行了分类。该综述还提出了隐私保护解释的特征，旨在帮助研究人员和从业者理解符合隐私要求的XAI的需求。最后，文章指出了在隐私与其他系统需求之间取得平衡所面临的挑战，并为实现隐私保护的XAI提供了建议。\n",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted for peer review",
      "pdf_url": "http://arxiv.org/pdf/2505.02828v1",
      "published_date": "2025-05-05 17:53:28 UTC",
      "updated_date": "2025-05-05 17:53:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:16:00.147028"
    },
    {
      "arxiv_id": "2505.02824v1",
      "title": "Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models",
      "title_zh": "面向个性化文本到图像扩散模型的数据集版权规避攻击\n",
      "authors": [
        "Kuofeng Gao",
        "Yufei Zhu",
        "Yiming Li",
        "Jiawang Bai",
        "Yong Yang",
        "Zhifeng Li",
        "Shu-Tao Xia"
      ],
      "abstract": "Text-to-image (T2I) diffusion models have rapidly advanced, enabling\nhigh-quality image generation conditioned on textual prompts. However, the\ngrowing trend of fine-tuning pre-trained models for personalization raises\nserious concerns about unauthorized dataset usage. To combat this, dataset\nownership verification (DOV) has emerged as a solution, embedding watermarks\ninto the fine-tuning datasets using backdoor techniques. These watermarks\nremain inactive under benign samples but produce owner-specified outputs when\ntriggered. Despite the promise of DOV for T2I diffusion models, its robustness\nagainst copyright evasion attacks (CEA) remains unexplored. In this paper, we\nexplore how attackers can bypass these mechanisms through CEA, allowing models\nto circumvent watermarks even when trained on watermarked datasets. We propose\nthe first copyright evasion attack (i.e., CEAT2I) specifically designed to\nundermine DOV in T2I diffusion models. Concretely, our CEAT2I comprises three\nstages: watermarked sample detection, trigger identification, and efficient\nwatermark mitigation. A key insight driving our approach is that T2I models\nexhibit faster convergence on watermarked samples during the fine-tuning,\nevident through intermediate feature deviation. Leveraging this, CEAT2I can\nreliably detect the watermarked samples. Then, we iteratively ablate tokens\nfrom the prompts of detected watermarked samples and monitor shifts in\nintermediate features to pinpoint the exact trigger tokens. Finally, we adopt a\nclosed-form concept erasure method to remove the injected watermark. Extensive\nexperiments show that our CEAT2I effectively evades DOV mechanisms while\npreserving model performance.",
      "tldr_zh": "本文针对个性化文本到图像(T2I)扩散模型中未经授权的数据集使用问题，提出了首个数据集版权规避攻击(CEAT2I)。该攻击旨在绕过通过后门技术将水印嵌入微调数据集的数据集所有权验证(DOV)机制。CEAT2I包含三个阶段：水印样本检测、触发词识别和高效水印缓解。该方法利用T2I模型在微调过程中对水印样本的快速收敛特性，通过中间特征偏差检测水印样本，并通过迭代消融提示中的token来识别触发词，最后采用闭式概念擦除方法移除水印。实验表明，CEAT2I能有效规避DOV机制，同时保持模型性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02824v1",
      "published_date": "2025-05-05 17:51:55 UTC",
      "updated_date": "2025-05-05 17:51:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:16:12.198817"
    },
    {
      "arxiv_id": "2505.02820v1",
      "title": "AutoLibra: Agent Metric Induction from Open-Ended Feedback",
      "title_zh": "AutoLibra：从开放式反馈中归纳智能体指标\n",
      "authors": [
        "Hao Zhu",
        "Phil Cuvin",
        "Xinkai Yu",
        "Charlotte Ka Yee Yan",
        "Jason Zhang",
        "Diyi Yang"
      ],
      "abstract": "Agents are predominantly evaluated and optimized via task success metrics,\nwhich are coarse, rely on manual design from experts, and fail to reward\nintermediate emergent behaviors. We propose AutoLibra, a framework for agent\nevaluation, that transforms open-ended human feedback, e.g., \"If you find that\nthe button is disabled, don't click it again\", or \"This agent has too much\nautonomy to decide what to do on its own\", into metrics for evaluating\nfine-grained behaviors in agent trajectories. AutoLibra accomplishes this by\ngrounding feedback to an agent's behavior, clustering similar positive and\nnegative behaviors, and creating concrete metrics with clear definitions and\nconcrete examples, which can be used for prompting LLM-as-a-Judge as\nevaluators. We further propose two meta-metrics to evaluate the alignment of a\nset of (induced) metrics with open feedback: \"coverage\" and \"redundancy\".\nThrough optimizing these meta-metrics, we experimentally demonstrate\nAutoLibra's ability to induce more concrete agent evaluation metrics than the\nones proposed in previous agent evaluation benchmarks and discover new metrics\nto analyze agents. We also present two applications of AutoLibra in agent\nimprovement: First, we show that AutoLibra-induced metrics serve as better\nprompt-engineering targets than the task success rate on a wide range of text\ngame tasks, improving agent performance over baseline by a mean of 20%. Second,\nwe show that AutoLibra can iteratively select high-quality fine-tuning data for\nweb navigation agents. Our results suggest that AutoLibra is a powerful\ntask-agnostic tool for evaluating and improving language agents.",
      "tldr_zh": "AutoLibra是一个用于智能体评估的框架，它将开放式的用户反馈转化为细粒度的行为评估指标。该框架通过将反馈与智能体的行为关联，聚类相似的积极和消极行为，并创建具有明确定义和具体示例的评估指标，用于提示LLM作为评估者。AutoLibra还提出了两个元指标“覆盖率”和“冗余度”来评估指标与开放反馈的一致性。实验表明，AutoLibra能够诱导出比现有智能体评估基准更具体的评估指标，并发现新的指标来分析智能体。AutoLibra诱导的指标可以作为更好的prompt工程目标，并在智能体改进中用于迭代选择高质量的微调数据，从而提升智能体的性能。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "https://opensocial.world/",
      "pdf_url": "http://arxiv.org/pdf/2505.02820v1",
      "published_date": "2025-05-05 17:47:49 UTC",
      "updated_date": "2025-05-05 17:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:16:24.247954"
    },
    {
      "arxiv_id": "2505.02811v1",
      "title": "Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing",
      "title_zh": "知你所不知：通过自我实践学习何时在多轮 RAG 中继续搜索\n",
      "authors": [
        "Diji Yang",
        "Linda Zeng",
        "Jinmeng Rao",
        "Yi Zhang"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has shown strong capability in enhancing\nlanguage models' knowledge and reducing AI generative hallucinations, driving\nits widespread use. However, complex tasks requiring multi-round retrieval\nremain challenging, and early attempts tend to be overly optimistic without a\ngood sense of self-skepticism. Current multi-round RAG systems may continue\nsearching even when enough information has already been retrieved, or they may\nprovide incorrect answers without having sufficient information or knowledge.\nExisting solutions either require large amounts of expensive human-labeled\nprocess supervision data or lead to subpar performance.\n  This paper aims to address these limitations by introducing a new framework,\n\\textbf{SIM-RAG}, to explicitly enhance RAG systems' self-awareness and\nmulti-round retrieval capabilities. To train SIM-RAG, we first let a RAG system\nself-practice multi-round retrieval, augmenting existing question-answer pairs\nwith intermediate inner monologue reasoning steps to generate synthetic\ntraining data. For each pair, the system may explore multiple retrieval paths,\nwhich are labeled as successful if they reach the correct answer and\nunsuccessful otherwise. Using this data, we train a lightweight information\nsufficiency Critic. At inference time, the Critic evaluates whether the RAG\nsystem has retrieved sufficient information at each round, guiding retrieval\ndecisions and improving system-level self-awareness through in-context\nreinforcement learning.\n  Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an\neffective multi-round RAG solution. Furthermore, this framework is\nsystem-efficient, adding a lightweight component to RAG without requiring\nmodifications to existing LLMs or search engines, and data-efficient,\neliminating the need for costly human-annotated mid-step retrieval process\nsupervision data.",
      "tldr_zh": "这篇论文提出了一种名为SIM-RAG的新框架，旨在提升RAG系统在多轮检索中的自我感知能力。SIM-RAG通过让RAG系统进行自我练习，为现有问题-答案对增加中间推理步骤，生成合成训练数据。系统探索多条检索路径，成功路径被标记为到达正确答案，否则为不成功。利用这些数据，训练一个轻量级的信息充分性Critic。在推理时，Critic评估RAG系统在每一轮检索中是否检索到足够的信息，通过上下文强化学习指导检索决策，提高系统级的自我感知能力。实验表明，SIM-RAG是一种有效的多轮RAG解决方案，且系统高效，无需修改现有LLM或搜索引擎，也无需昂贵的人工标注数据。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Proceedings of the 48th International ACM SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02811v1",
      "published_date": "2025-05-05 17:39:35 UTC",
      "updated_date": "2025-05-05 17:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:16:36.309025"
    },
    {
      "arxiv_id": "2505.02795v1",
      "title": "HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models",
      "title_zh": "HSplitLoRA：一种用于大型语言模型的异构拆分参数高效微调框架\n",
      "authors": [
        "Zheng Lin",
        "Yuxin Zhang",
        "Zhe Chen",
        "Zihan Fang",
        "Xianhao Chen",
        "Praneeth Vepakomma",
        "Wei Ni",
        "Jun Luo",
        "Yue Gao"
      ],
      "abstract": "Recently, large language models (LLMs) have achieved remarkable\nbreakthroughs, revolutionizing the natural language processing domain and\nbeyond. Due to immense parameter sizes, fine-tuning these models with private\ndata for diverse downstream tasks has become mainstream. Though federated\nlearning (FL) offers a promising solution for fine-tuning LLMs without sharing\nraw data, substantial computing costs hinder its democratization. Moreover, in\nreal-world scenarios, private client devices often possess heterogeneous\ncomputing resources, further complicating LLM fine-tuning. To combat these\nchallenges, we propose HSplitLoRA, a heterogeneous parameter-efficient\nfine-tuning (PEFT) framework built on split learning (SL) and low-rank\nadaptation (LoRA) fine-tuning, for efficiently fine-tuning LLMs on\nheterogeneous client devices. HSplitLoRA first identifies important weights\nbased on their contributions to LLM training. It then dynamically configures\nthe decomposition ranks of LoRA adapters for selected weights and determines\nthe model split point according to varying computing budgets of client devices.\nFinally, a noise-free adapter aggregation mechanism is devised to support\nheterogeneous adapter aggregation without introducing noise. Extensive\nexperiments demonstrate that HSplitLoRA outperforms state-of-the-art benchmarks\nin training accuracy and convergence speed.",
      "tldr_zh": "本文提出了HSplitLoRA，一个异构参数高效微调(PEFT)框架，旨在解决在异构客户端设备上高效微调大型语言模型(LLMs)的问题。HSplitLoRA基于分割学习(SL)和低秩适应(LoRA)微调，首先识别LLM训练中的重要权重，然后根据客户端设备不同的计算预算，动态配置LoRA适配器的分解秩并确定模型分割点。此外，还设计了一种无噪声的适配器聚合机制，以支持异构适配器聚合。实验结果表明，HSplitLoRA在训练精度和收敛速度方面优于现有技术。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02795v1",
      "published_date": "2025-05-05 17:09:19 UTC",
      "updated_date": "2025-05-05 17:09:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:16:48.076585"
    },
    {
      "arxiv_id": "2505.02781v1",
      "title": "Local Markov Equivalence and Local Causal Discovery for Identifying Controlled Direct Effects",
      "title_zh": "局部马尔可夫等价性和局部因果发现，用于识别受控直接效应\n",
      "authors": [
        "Timothée Loranchet",
        "Charles K. Assaad"
      ],
      "abstract": "Understanding and identifying controlled direct effects (CDEs) is crucial\nacross numerous scientific domains, including public health. While existing\nmethods can identify these effects from causal directed acyclic graphs (DAGs),\nthe true underlying structure is often unknown in practice. Essential graphs,\nwhich represent a Markov equivalence class of DAGs characterized by the same\nset of d-separations, provide a more practical and realistic alternative.\nHowever, learning the full essential graph is computationally intensive and\ntypically depends on strong, untestable assumptions. In this work, we\ncharacterize a local class of graphs, defined relative to a target variable,\nthat share a specific subset of d-separations, and introduce a graphical\nrepresentation of this class, called the local essential graph (LEG). We then\npresent LocPC, a novel algorithm designed to recover the LEG from an observed\ndistribution using only local conditional independence tests. Building on\nLocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG\nthat is sufficient to identify a CDE, bypassing the need of retrieving the full\nessential graph. Compared to global methods, our algorithms require less\nconditional independence tests and operate under weaker assumptions while\nmaintaining theoretical guarantees.",
      "tldr_zh": "该论文研究了控制直接效应(CDEs)的识别问题，提出了一种基于局部马尔可夫等价(local Markov equivalence)和局部因果发现(local causal discovery)的新方法。 针对传统方法依赖于完整因果DAG结构，而实际中DAG未知的问题，论文引入局部本质图(LEG)的概念，并提出了LocPC算法来从观测数据中恢复LEG。进一步，论文提出了LocPC-CDE算法，该算法直接发现足以识别CDE的LEG部分，避免了学习完整本质图的需求。相比于全局方法，该算法在更弱的假设下，需要更少的条件独立性测试，并具有理论保证。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02781v1",
      "published_date": "2025-05-05 16:47:29 UTC",
      "updated_date": "2025-05-05 16:47:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:17:00.276163"
    },
    {
      "arxiv_id": "2505.02780v1",
      "title": "Beyond the Monitor: Mixed Reality Visualization and AI for Enhanced Digital Pathology Workflow",
      "title_zh": "超越显示器：用于增强数字病理工作流程的混合现实可视化和人工智能\n",
      "authors": [
        "Jai Prakash Veerla",
        "Partha Sai Guttikonda",
        "Helen H. Shang",
        "Mohammad Sadegh Nasr",
        "Cesar Torres",
        "Jacob M. Luber"
      ],
      "abstract": "Pathologists rely on gigapixel whole-slide images (WSIs) to diagnose diseases\nlike cancer, yet current digital pathology tools hinder diagnosis. The immense\nscale of WSIs, often exceeding 100,000 X 100,000 pixels, clashes with the\nlimited views traditional monitors offer. This mismatch forces constant panning\nand zooming, increasing pathologist cognitive load, causing diagnostic fatigue,\nand slowing pathologists' adoption of digital methods. PathVis, our\nmixed-reality visualization platform for Apple Vision Pro, addresses these\nchallenges. It transforms the pathologist's interaction with data, replacing\ncumbersome mouse-and-monitor navigation with intuitive exploration using\nnatural hand gestures, eye gaze, and voice commands in an immersive workspace.\nPathVis integrates AI to enhance diagnosis. An AI-driven search function\ninstantly retrieves and displays the top five similar patient cases\nside-by-side, improving diagnostic precision and efficiency through rapid\ncomparison. Additionally, a multimodal conversational AI assistant offers\nreal-time image interpretation support and aids collaboration among\npathologists across multiple Apple devices. By merging the directness of\ntraditional pathology with advanced mixed-reality visualization and AI, PathVis\nimproves diagnostic workflows, reduces cognitive strain, and makes pathology\npractice more effective and engaging. The PathVis source code and a demo video\nare publicly available at: https://github.com/jaiprakash1824/Path_Vis",
      "tldr_zh": "病理学家依赖于千兆像素的全玻片图像(WSIs)进行疾病诊断，但现有工具受限于传统显示器的视野，导致诊断效率低下。PathVis是一个混合现实可视化平台，专为Apple Vision Pro设计，旨在解决这一问题。它通过自然的手势、眼动追踪和语音命令，提供沉浸式的工作空间，取代了繁琐的鼠标和显示器操作。PathVis集成了AI驱动的搜索功能，可以即时检索并排显示最相似的五个病例，并通过多模态对话式AI助手提供实时图像解释支持和协作。PathVis旨在提高诊断工作流程效率，减轻认知负担，并使病理学实践更有效和更具吸引力。该项目的源代码和演示视频已公开。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "q-bio.TO"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02780v1",
      "published_date": "2025-05-05 16:46:53 UTC",
      "updated_date": "2025-05-05 16:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:17:12.696708"
    },
    {
      "arxiv_id": "2505.02766v1",
      "title": "Giving Simulated Cells a Voice: Evolving Prompt-to-Intervention Models for Cellular Control",
      "title_zh": "赋予模拟细胞声音：演化用于细胞控制的提示到干预模型\n",
      "authors": [
        "Nam H. Le",
        "Patrick Erikson",
        "Yanbo Zhang",
        "Michael Levin",
        "Josh Bongard"
      ],
      "abstract": "Guiding biological systems toward desired states, such as morphogenetic\noutcomes, remains a fundamental challenge with far-reaching implications for\nmedicine and synthetic biology. While large language models (LLMs) have enabled\nnatural language as an interface for interpretable control in AI systems, their\nuse as mediators for steering biological or cellular dynamics remains largely\nunexplored.\n  In this work, we present a functional pipeline that translates natural\nlanguage prompts into spatial vector fields capable of directing simulated\ncellular collectives. Our approach combines a large language model with an\nevolvable neural controller (Prompt-to-Intervention, or P2I), optimized via\nevolutionary strategies to generate behaviors such as clustering or scattering\nin a simulated 2D environment.\n  We demonstrate that even with constrained vocabulary and simplified cell\nmodels, evolved P2I networks can successfully align cellular dynamics with\nuser-defined goals expressed in plain language. This work offers a complete\nloop from language input to simulated bioelectric-like intervention to\nbehavioral output, providing a foundation for future systems capable of natural\nlanguage-driven cellular control.",
      "tldr_zh": "该研究提出了一种将自然语言提示转化为空间向量场，从而控制模拟细胞集合行为的pipeline。该方法结合大型语言模型(LLM)和可进化神经控制器(Prompt-to-Intervention, P2I)，通过进化策略优化，生成如聚集或分散等行为。实验证明，即使在受限词汇和简化细胞模型下，进化后的P2I网络也能成功地将细胞动态与用户定义的自然语言目标对齐。该工作为未来基于自然语言驱动的细胞控制系统奠定了基础，提供了一个从语言输入到模拟生物电干预再到行为输出的完整闭环。\n",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.RO",
        "q-bio.TO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to GECCO Workshop on Bio-Inspired AI (ACM GECCO2025). 13\n  pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02766v1",
      "published_date": "2025-05-05 16:21:46 UTC",
      "updated_date": "2025-05-05 16:21:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:17:24.078785"
    },
    {
      "arxiv_id": "2505.02763v1",
      "title": "Bye-bye, Bluebook? Automating Legal Procedure with Large Language Models",
      "title_zh": "再见，Bluebook？利用大型语言模型实现法律程序的自动化\n",
      "authors": [
        "Matthew Dahl"
      ],
      "abstract": "Legal practice requires careful adherence to procedural rules. In the United\nStates, few are more complex than those found in The Bluebook: A Uniform System\nof Citation. Compliance with this system's 500+ pages of byzantine formatting\ninstructions is the raison d'etre of thousands of student law review editors\nand the bete noire of lawyers everywhere. To evaluate whether large language\nmodels (LLMs) are able to adhere to the procedures of such a complicated\nsystem, we construct an original dataset of 866 Bluebook tasks and test\nflagship LLMs from OpenAI, Anthropic, Google, Meta, and DeepSeek. We show (1)\nthat these models produce fully compliant Bluebook citations only 69%-74% of\nthe time and (2) that in-context learning on the Bluebook's underlying system\nof rules raises accuracy only to 77%. These results caution against using\noff-the-shelf LLMs to automate aspects of the law where fidelity to procedure\nis paramount.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在自动化法律程序方面的能力，特别是针对美国复杂的法律引用体系《Bluebook》。研究人员构建了一个包含866个Bluebook任务的数据集，并测试了OpenAI、Anthropic、Google、Meta和DeepSeek等公司的LLM。实验结果表明，这些模型生成完全符合Bluebook规范的引用的准确率仅为69%-74%，即使通过上下文学习也仅提升至77%。因此，研究警告说，在法律领域中，如果对程序准确性要求极高，则不应使用现成的LLM来自动化相关任务。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02763v1",
      "published_date": "2025-05-05 16:18:07 UTC",
      "updated_date": "2025-05-05 16:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:17:36.207890"
    },
    {
      "arxiv_id": "2505.02747v1",
      "title": "The use of Artificial Intelligence for Intervention and Assessment in Individuals with ASD",
      "title_zh": "人工智能在自闭症谱系障碍患者干预和评估中的应用\n",
      "authors": [
        "Aggeliki Sideraki",
        "Christos-Nikolaos Anagnostopoulos"
      ],
      "abstract": "This paper explores the use of Artificial Intelligence (AI) as a tool for\ndiagnosis, assessment, and intervention for individuals with Autism Spectrum\nDisorder (ASD). It focuses particularly on AI's role in early diagnosis,\nutilizing advanced machine learning techniques and data analysis. Recent\nstudies demonstrate that deep learning algorithms can identify behavioral\npatterns through biometric data analysis, video-based interaction assessments,\nand linguistic feature extraction, providing a more accurate and timely\ndiagnosis compared to traditional methods. Additionally, AI automates\ndiagnostic tools, reducing subjective biases and enabling the development of\npersonalized assessment protocols for ASD monitoring. At the same time, the\npaper examines AI-powered intervention technologies, emphasizing educational\nrobots and adaptive communication tools. Social robotic assistants, such as NAO\nand Kaspar, have been shown to enhance social skills in children by offering\nstructured, repetitive interactions that reinforce learning. Furthermore,\nAI-driven Augmentative and Alternative Communication (AAC) systems allow\nchildren with ASD to express themselves more effectively, while\nmachine-learning chatbots provide language development support through\npersonalized responses. The study presents research findings supporting the\neffectiveness of these AI applications while addressing challenges such as\nlong-term evaluation and customization to individual needs. In conclusion, the\npaper highlights the significance of AI as an innovative tool in ASD diagnosis\nand intervention, advocating for further research to assess its long-term\nimpact.",
      "tldr_zh": "本文探讨了人工智能(AI)在自闭症谱系障碍(ASD)个体诊断、评估和干预中的应用。AI通过先进的机器学习技术和数据分析，在早期诊断中发挥关键作用，例如通过生物特征数据分析、视频互动评估和语言特征提取来识别行为模式。此外，AI还被用于自动化诊断工具，减少主观偏见，并为ASD监测开发个性化的评估方案。在干预方面，AI驱动的教育机器人和自适应交流工具，如NAO和Kaspar，通过结构化的重复互动来增强儿童的社交技能。AI驱动的增强和替代交流(AAC)系统以及机器学习聊天机器人也为ASD儿童提供了更有效的表达和语言发展支持。研究强调了AI在ASD诊断和干预中的重要性，并呼吁进一步研究以评估其长期影响。\n",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.02747v1",
      "published_date": "2025-05-05 15:58:32 UTC",
      "updated_date": "2025-05-05 15:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:17:48.326204"
    },
    {
      "arxiv_id": "2505.02737v2",
      "title": "Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation",
      "title_zh": "知识图谱增强大型语言模型在实体消歧中的应用\n",
      "authors": [
        "Gerard Pons",
        "Besim Bilalli",
        "Anna Queralt"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have positioned them as a\nprominent solution for Natural Language Processing tasks. Notably, they can\napproach these problems in a zero or few-shot manner, thereby eliminating the\nneed for training or fine-tuning task-specific models. However, LLMs face some\nchallenges, including hallucination and the presence of outdated knowledge or\nmissing information from specific domains in the training data. These problems\ncannot be easily solved by retraining the models with new data as it is a\ntime-consuming and expensive process. To mitigate these issues, Knowledge\nGraphs (KGs) have been proposed as a structured external source of information\nto enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for\nzero-shot Entity Disambiguation (ED). For that purpose, we leverage the\nhierarchical representation of the entities' classes in a KG to gradually prune\nthe candidate space as well as the entities' descriptions to enrich the input\nprompt with additional factual knowledge. Our evaluation on popular ED datasets\nshows that the proposed method outperforms non-enhanced and description-only\nenhanced LLMs, and has a higher degree of adaptability than task-specific\nmodels. Furthermore, we conduct an error analysis and discuss the impact of the\nleveraged KG's semantic expressivity on the ED performance.",
      "tldr_zh": "该研究探索了利用知识图谱(Knowledge Graphs, KGs)增强大型语言模型(Large Language Models, LLMs)在实体消歧(Entity Disambiguation, ED)任务中的性能。针对LLMs存在的幻觉、知识过时或领域信息缺失等问题，研究提出利用KG作为外部知识源来丰富LLMs。具体方法是利用KG中实体类别的层级结构逐步缩小候选空间，并利用实体的描述信息来丰富输入提示。实验结果表明，该方法在流行的ED数据集上优于未增强的LLMs和仅使用描述信息增强的LLMs，并且具有比特定任务模型更高的适应性。此外，研究还进行了误差分析，并讨论了KG的语义表达能力对ED性能的影响。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "Pre-print submitted to ISWC 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.02737v2",
      "published_date": "2025-05-05 15:40:24 UTC",
      "updated_date": "2025-05-06 06:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:18:00.525684"
    },
    {
      "arxiv_id": "2505.02735v1",
      "title": "FormalMATH: Benchmarking Formal Mathematical Reasoning of Large Language Models",
      "title_zh": "FormalMATH：大规模语言模型的形式化数学推理基准测试",
      "authors": [
        "Zhouliang Yu",
        "Ruotian Peng",
        "Keyi Ding",
        "Yizhe Li",
        "Zhongyuan Peng",
        "Minghao Liu",
        "Yifan Zhang",
        "Zheng Yuan",
        "Huajian Xin",
        "Wenhao Huang",
        "Yandong Wen",
        "Ge Zhang",
        "Weiyang Liu"
      ],
      "abstract": "Formal mathematical reasoning remains a critical challenge for artificial\nintelligence, hindered by limitations of existing benchmarks in scope and\nscale. To address this, we present FormalMATH, a large-scale Lean4 benchmark\ncomprising 5,560 formally verified problems spanning from high-school Olympiad\nchallenges to undergraduate-level theorems across diverse domains (e.g.,\nalgebra, applied mathematics, calculus, number theory, and discrete\nmathematics). To mitigate the inefficiency of manual formalization, we\nintroduce a novel human-in-the-loop autoformalization pipeline that integrates:\n(1) specialized large language models (LLMs) for statement autoformalization,\n(2) multi-LLM semantic verification, and (3) negation-based disproof filtering\nstrategies using off-the-shelf LLM-based provers. This approach reduces expert\nannotation costs by retaining 72.09% of statements before manual verification\nwhile ensuring fidelity to the original natural-language problems. Our\nevaluation of state-of-the-art LLM-based theorem provers reveals significant\nlimitations: even the strongest models achieve only 16.46% success rate under\npractical sampling budgets, exhibiting pronounced domain bias (e.g., excelling\nin algebra but failing in calculus) and over-reliance on simplified automation\ntactics. Notably, we identify a counterintuitive inverse relationship between\nnatural-language solution guidance and proof success in chain-of-thought\nreasoning scenarios, suggesting that human-written informal reasoning\nintroduces noise rather than clarity in the formal reasoning settings. We\nbelieve that FormalMATH provides a robust benchmark for benchmarking formal\nmathematical reasoning.",
      "tldr_zh": "FormalMATH是一个大规模的Lean4基准测试，包含5560个经过形式验证的数学问题，涵盖高中奥林匹克到本科级别的各种领域。为了解决手动形式化的低效率问题，论文提出了一种人机协作的自动形式化流程，该流程集成了专门的LLM用于语句自动形式化，多LLM语义验证和基于否定证明过滤策略。实验表明，即使是最强大的LLM模型在实际采样预算下也仅达到16.46％的成功率，并且在不同领域表现出明显的偏差。研究还发现，在链式思维推理场景中，自然语言解决方案指导与证明成功之间存在反直觉的逆关系，表明人类编写的非正式推理引入了噪声。FormalMATH为形式化数学推理提供了一个强大的基准。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Technical Report v1 (33 pages, 8 figures, project page:\n  https://sphere-ai-lab.github.io/FormalMATH/)",
      "pdf_url": "http://arxiv.org/pdf/2505.02735v1",
      "published_date": "2025-05-05 15:37:00 UTC",
      "updated_date": "2025-05-05 15:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:18:12.552696"
    },
    {
      "arxiv_id": "2505.02722v1",
      "title": "Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry",
      "title_zh": "利用来自全国脓毒症登记的真实世界数据增强大型语言模型 (LLM) 的临床推理能力\n",
      "authors": [
        "Junu Kim",
        "Chaeeun Shim",
        "Sungjin Park",
        "Su Yeon Lee",
        "Gee Young Suh",
        "Chae-Man Lim",
        "Seong Jin Choi",
        "Song Mi Moon",
        "Kyoung-Ho Song",
        "Eu Suk Kim",
        "Hong Bin Kim",
        "Sejoong Kim",
        "Chami Im",
        "Dong-Wan Kang",
        "Yong Soo Kim",
        "Hee-Joon Bae",
        "Sung Yoon Lim",
        "Han-Gil Jeong",
        "Edward Choi"
      ],
      "abstract": "Although large language models (LLMs) have demonstrated impressive reasoning\ncapabilities across general domains, their effectiveness in real-world clinical\npractice remains limited. This is likely due to their insufficient exposure to\nreal-world clinical data during training, as such data is typically not\nincluded due to privacy concerns. To address this, we propose enhancing the\nclinical reasoning capabilities of LLMs by leveraging real-world clinical data.\nWe constructed reasoning-intensive questions from a nationwide sepsis registry\nand fine-tuned Phi-4 on these questions using reinforcement learning, resulting\nin C-Reason. C-Reason exhibited strong clinical reasoning capabilities on the\nin-domain test set, as evidenced by both quantitative metrics and expert\nevaluations. Furthermore, its enhanced reasoning capabilities generalized to a\nsepsis dataset involving different tasks and patient cohorts, an open-ended\nconsultations on antibiotics use task, and other diseases. Future research\nshould focus on training LLMs with large-scale, multi-disease clinical datasets\nto develop more powerful, general-purpose clinical reasoning models.",
      "tldr_zh": "该研究旨在提升大型语言模型(LLMs)在真实临床环境中的推理能力，通过利用全国范围内的脓毒症注册数据，构建了推理密集型问题，并使用强化学习对Phi-4进行微调，得到C-Reason模型。实验结果表明，C-Reason在领域内测试集上表现出强大的临床推理能力，并通过定量指标和专家评估验证。其增强的推理能力推广到涉及不同任务和患者群体的脓毒症数据集，以及关于抗生素使用的开放式咨询任务和其他疾病。该研究强调了使用大规模、多疾病临床数据集训练LLMs，以开发更强大、通用的临床推理模型的重要性。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02722v1",
      "published_date": "2025-05-05 15:23:47 UTC",
      "updated_date": "2025-05-05 15:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:18:24.255649"
    },
    {
      "arxiv_id": "2505.02712v1",
      "title": "Graph Neural Network-Based Reinforcement Learning for Controlling Biological Networks: The GATTACA Framework",
      "title_zh": "基于图神经网络的强化学习控制生物网络：GATTACA 框架\n",
      "authors": [
        "Andrzej Mizera",
        "Jakub Zarzycki"
      ],
      "abstract": "Cellular reprogramming, the artificial transformation of one cell type into\nanother, has been attracting increasing research attention due to its\ntherapeutic potential for complex diseases. However, discovering reprogramming\nstrategies through classical wet-lab experiments is hindered by lengthy time\ncommitments and high costs. In this study, we explore the use of deep\nreinforcement learning (DRL) to control Boolean network models of complex\nbiological systems, such as gene regulatory networks and signalling pathway\nnetworks. We formulate a novel control problem for Boolean network models under\nthe asynchronous update mode in the context of cellular reprogramming. To\nfacilitate scalability, we consider our previously introduced concept of a\npseudo-attractor and we improve our procedure for effective identification of\npseudo-attractor states. Finally, we devise a computational framework to solve\nthe control problem. To leverage the structure of biological systems, we\nincorporate graph neural networks with graph convolutions into the artificial\nneural network approximator for the action-value function learned by the DRL\nagent. Experiments on a number of large real-world biological networks from\nliterature demonstrate the scalability and effectiveness of our approach.",
      "tldr_zh": "该研究提出GATTACA框架，利用基于图神经网络(GNN)的强化学习(RL)方法控制生物网络，以解决细胞重编程策略发现中耗时和高成本的问题。该框架针对细胞重编程背景下的布尔网络模型，在异步更新模式下构建了一个新的控制问题。通过引入伪吸引子(pseudo-attractor)的概念并改进其识别方法，提高了模型的可扩展性。GATTACA框架利用图卷积将GNN融入到RL智能体的动作价值函数近似器中，从而有效利用了生物系统的结构信息。在多个大型真实生物网络上的实验表明，该方法具有良好的可扩展性和有效性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02712v1",
      "published_date": "2025-05-05 15:07:20 UTC",
      "updated_date": "2025-05-05 15:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:18:36.305348"
    },
    {
      "arxiv_id": "2505.02709v1",
      "title": "Technical Report: Evaluating Goal Drift in Language Model Agents",
      "title_zh": "技术报告：评估语言模型 Agent 中的目标漂移",
      "authors": [
        "Rauno Arike",
        "Elizabeth Donoway",
        "Henning Bartsch",
        "Marius Hobbhahn"
      ],
      "abstract": "As language models (LMs) are increasingly deployed as autonomous agents,\ntheir robust adherence to human-assigned objectives becomes crucial for safe\noperation. When these agents operate independently for extended periods without\nhuman oversight, even initially well-specified goals may gradually shift.\nDetecting and measuring goal drift - an agent's tendency to deviate from its\noriginal objective over time - presents significant challenges, as goals can\nshift gradually, causing only subtle behavioral changes. This paper proposes a\nnovel approach to analyzing goal drift in LM agents. In our experiments, agents\nare first explicitly given a goal through their system prompt, then exposed to\ncompeting objectives through environmental pressures. We demonstrate that while\nthe best-performing agent (a scaffolded version of Claude 3.5 Sonnet) maintains\nnearly perfect goal adherence for more than 100,000 tokens in our most\ndifficult evaluation setting, all evaluated models exhibit some degree of goal\ndrift. We also find that goal drift correlates with models' increasing\nsusceptibility to pattern-matching behaviors as the context length grows.",
      "tldr_zh": "该技术报告提出了一种新方法来评估语言模型智能体中的目标漂移现象，即智能体在长时间独立运行后偏离其初始目标的趋势。研究通过让智能体在系统提示中明确设定目标，然后暴露于竞争性环境压力下进行实验。结果表明，即使是表现最佳的智能体（Claude 3.5 Sonnet的scaffolded版本）在最困难的评估环境中，经过超过10万个token后也表现出一定程度的目标漂移。此外，研究还发现目标漂移与模型随着上下文长度增加而对模式匹配行为的敏感性增强相关。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02709v1",
      "published_date": "2025-05-05 15:06:09 UTC",
      "updated_date": "2025-05-05 15:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:18:48.330885"
    },
    {
      "arxiv_id": "2505.02707v1",
      "title": "Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play",
      "title_zh": "Voila：用于实时自主交互和语音角色扮演的语音-语言基础模型\n",
      "authors": [
        "Yemin Shi",
        "Yu Shu",
        "Siwei Dong",
        "Guangyi Liu",
        "Jaward Sesay",
        "Jingwen Li",
        "Zhiting Hu"
      ],
      "abstract": "A voice AI agent that blends seamlessly into daily life would interact with\nhumans in an autonomous, real-time, and emotionally expressive manner. Rather\nthan merely reacting to commands, it would continuously listen, reason, and\nrespond proactively, fostering fluid, dynamic, and emotionally resonant\ninteractions. We introduce Voila, a family of large voice-language foundation\nmodels that make a step towards this vision. Voila moves beyond traditional\npipeline systems by adopting a new end-to-end architecture that enables\nfull-duplex, low-latency conversations while preserving rich vocal nuances such\nas tone, rhythm, and emotion. It achieves a response latency of just 195\nmilliseconds, surpassing the average human response time. Its hierarchical\nmulti-scale Transformer integrates the reasoning capabilities of large language\nmodels (LLMs) with powerful acoustic modeling, enabling natural, persona-aware\nvoice generation -- where users can simply write text instructions to define\nthe speaker's identity, tone, and other characteristics. Moreover, Voila\nsupports over one million pre-built voices and efficient customization of new\nones from brief audio samples as short as 10 seconds. Beyond spoken dialogue,\nVoila is designed as a unified model for a wide range of voice-based\napplications, including automatic speech recognition (ASR), Text-to-Speech\n(TTS), and, with minimal adaptation, multilingual speech translation. Voila is\nfully open-sourced to support open research and accelerate progress toward\nnext-generation human-machine interactions.",
      "tldr_zh": "Voila 是一系列大型语音-语言基础模型，旨在实现自主、实时、情感丰富的语音交互。它采用端到端架构，实现全双工、低延迟的对话，同时保留音色、节奏和情感等丰富的语音细节，响应延迟仅为195毫秒。Voila 通过分层多尺度 Transformer 融合了大型语言模型 (LLM) 的推理能力和强大的声学建模，实现自然、具有角色感知的语音生成，用户可以通过简单的文本指令定义说话者的身份、语气等特征。此外，Voila 支持超过一百万个预构建的声音，并能通过短至 10 秒的音频样本高效定制新声音。Voila 是一个统一的模型，适用于各种基于语音的应用，包括自动语音识别 (ASR)、文本到语音 (TTS)，以及经过少量调整后的多语言语音翻译。该模型已完全开源，以支持开放研究并加速下一代人机交互的发展。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 7 figures, Website: https://voila.maitrix.org",
      "pdf_url": "http://arxiv.org/pdf/2505.02707v1",
      "published_date": "2025-05-05 15:05:01 UTC",
      "updated_date": "2025-05-05 15:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:19:00.635559"
    },
    {
      "arxiv_id": "2505.02694v1",
      "title": "AI Standardized Patient Improves Human Conversations in Advanced Cancer Care",
      "title_zh": "AI标准化病人提升晚期癌症护理中的人际对话质量\n",
      "authors": [
        "Kurtis Haut",
        "Masum Hasan",
        "Thomas Carroll",
        "Ronald Epstein",
        "Taylan Sen",
        "Ehsan Hoque"
      ],
      "abstract": "Serious illness communication (SIC) in end-of-life care faces challenges such\nas emotional stress, cultural barriers, and balancing hope with honesty.\nDespite its importance, one of the few available ways for clinicians to\npractice SIC is with standardized patients, which is expensive, time-consuming,\nand inflexible. In this paper, we present SOPHIE, an AI-powered standardized\npatient simulation and automated feedback system. SOPHIE combines large\nlanguage models (LLMs), a lifelike virtual avatar, and automated, personalized\nfeedback based on clinical literature to provide remote, on-demand SIC\ntraining. In a randomized control study with healthcare students and\nprofessionals, SOPHIE users demonstrated significant improvement across three\ncritical SIC domains: Empathize, Be Explicit, and Empower. These results\nsuggest that AI-driven tools can enhance complex interpersonal communication\nskills, offering scalable, accessible solutions to address a critical gap in\nclinician education.",
      "tldr_zh": "该论文介绍了一种名为SOPHIE的AI标准化病人模拟和自动化反馈系统，旨在提升晚期癌症护理中的严肃疾病沟通(SIC)能力。SOPHIE结合了大型语言模型(LLMs)、逼真的虚拟形象以及基于临床文献的个性化反馈，提供远程、按需的SIC培训。一项针对医疗保健学生和专业人士的随机对照研究表明，SOPHIE用户在共情、明确表达和赋权三个关键SIC领域均表现出显著改善。研究结果表明，AI驱动的工具可以增强复杂的人际沟通技能，为解决临床医生教育中的关键差距提供可扩展、可访问的解决方案。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "20 pages, 6 figures, 4 tables, submitting to New England Journal of\n  Medicine (NEJM)",
      "pdf_url": "http://arxiv.org/pdf/2505.02694v1",
      "published_date": "2025-05-05 14:44:17 UTC",
      "updated_date": "2025-05-05 14:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:19:12.199531"
    },
    {
      "arxiv_id": "2505.02665v1",
      "title": "A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law",
      "title_zh": "基于强化学习和推理时标度律的慢思考推理LLM综述\n",
      "authors": [
        "Qianjun Pan",
        "Wenkai Ji",
        "Yuyang Ding",
        "Junsong Li",
        "Shilian Chen",
        "Junyi Wang",
        "Jie Zhou",
        "Qin Chen",
        "Min Zhang",
        "Yulan Wu",
        "Liang He"
      ],
      "abstract": "This survey explores recent advancements in reasoning large language models\n(LLMs) designed to mimic \"slow thinking\" - a reasoning process inspired by\nhuman cognition, as described in Kahneman's Thinking, Fast and Slow. These\nmodels, like OpenAI's o1, focus on scaling computational resources dynamically\nduring complex tasks, such as math reasoning, visual reasoning, medical\ndiagnosis, and multi-agent debates. We present the development of reasoning\nLLMs and list their key technologies. By synthesizing over 100 studies, it\ncharts a path toward LLMs that combine human-like deep thinking with scalable\nefficiency for reasoning. The review breaks down methods into three categories:\n(1) test-time scaling dynamically adjusts computation based on task complexity\nvia search and sampling, dynamic verification; (2) reinforced learning refines\ndecision-making through iterative improvement leveraging policy networks,\nreward models, and self-evolution strategies; and (3) slow-thinking frameworks\n(e.g., long CoT, hierarchical processes) that structure problem-solving with\nmanageable steps. The survey highlights the challenges and further directions\nof this domain. Understanding and advancing the reasoning abilities of LLMs is\ncrucial for unlocking their full potential in real-world applications, from\nscientific discovery to decision support systems.",
      "tldr_zh": "该综述探讨了基于“慢思考”的推理大型语言模型(LLMs)的最新进展，这些模型旨在模仿人类认知中的推理过程。重点关注了在复杂任务中动态调整计算资源的模型，例如数学推理、视觉推理、医疗诊断和多智能体辩论。文章将方法分为三类：(1)测试时缩放，通过搜索和抽样、动态验证等方式基于任务复杂性动态调整计算；(2)强化学习，通过策略网络、奖励模型和自我进化策略迭代改进决策；(3)慢思考框架，例如长链式思考(CoT)、分层过程，以可管理步骤构建问题解决过程。该综述总结了100多项研究，概述了该领域的挑战和未来方向，旨在推动LLMs在实际应用中的潜力。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02665v1",
      "published_date": "2025-05-05 14:14:59 UTC",
      "updated_date": "2025-05-05 14:14:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:19:24.548462"
    },
    {
      "arxiv_id": "2505.02659v2",
      "title": "A Note on Statistically Accurate Tabular Data Generation Using Large Language Models",
      "title_zh": "关于使用大型语言模型进行统计精确的表格数据生成的一点说明\n",
      "authors": [
        "Andrey Sidorenko"
      ],
      "abstract": "Large language models (LLMs) have shown promise in synthetic tabular data\ngeneration, yet existing methods struggle to preserve complex feature\ndependencies, particularly among categorical variables. This work introduces a\nprobability-driven prompting approach that leverages LLMs to estimate\nconditional distributions, enabling more accurate and scalable data synthesis.\nThe results highlight the potential of prompting probability distributions to\nenhance the statistical fidelity of LLM-generated tabular data.",
      "tldr_zh": "这篇论文提出了一种基于概率驱动提示的方法，利用大型语言模型（LLMs）生成更准确的合成表格数据。现有方法在保留复杂特征依赖关系，尤其是在分类变量之间，表现不佳。该方法通过LLM估计条件分布，从而实现更精确和可扩展的数据合成。实验结果表明，使用概率分布提示可以提高LLM生成的表格数据的统计保真度。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02659v2",
      "published_date": "2025-05-05 14:05:15 UTC",
      "updated_date": "2025-05-06 08:34:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:19:36.039999"
    },
    {
      "arxiv_id": "2505.02655v1",
      "title": "SCFormer: Structured Channel-wise Transformer with Cumulative Historical State for Multivariate Time Series Forecasting",
      "title_zh": "SCFormer：用于多元时间序列预测的具有累积历史状态的结构化通道Transformer\n",
      "authors": [
        "Shiwei Guo",
        "Ziang Chen",
        "Yupeng Ma",
        "Yunfei Han",
        "Yi Wang"
      ],
      "abstract": "The Transformer model has shown strong performance in multivariate time\nseries forecasting by leveraging channel-wise self-attention. However, this\napproach lacks temporal constraints when computing temporal features and does\nnot utilize cumulative historical series effectively.To address these\nlimitations, we propose the Structured Channel-wise Transformer with Cumulative\nHistorical state (SCFormer). SCFormer introduces temporal constraints to all\nlinear transformations, including the query, key, and value matrices, as well\nas the fully connected layers within the Transformer. Additionally, SCFormer\nemploys High-order Polynomial Projection Operators (HiPPO) to deal with\ncumulative historical time series, allowing the model to incorporate\ninformation beyond the look-back window during prediction. Extensive\nexperiments on multiple real-world datasets demonstrate that SCFormer\nsignificantly outperforms mainstream baselines, highlighting its effectiveness\nin enhancing time series forecasting. The code is publicly available at\nhttps://github.com/ShiweiGuo1995/SCFormer",
      "tldr_zh": "本文提出了一种名为SCFormer的结构化通道Transformer模型，用于多变量时间序列预测。该模型通过在Transformer的各个线性变换中引入时间约束，并利用高阶多项式投影算子(HiPPO)处理累积历史时间序列，从而克服了传统Transformer在时间特征计算和历史信息利用方面的局限性。SCFormer能够有效整合look-back窗口之外的信息进行预测。在多个真实数据集上的实验结果表明，SCFormer显著优于主流基线模型，证明了其在时间序列预测方面的有效性。代码已公开。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02655v1",
      "published_date": "2025-05-05 13:59:55 UTC",
      "updated_date": "2025-05-05 13:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:19:48.260935"
    },
    {
      "arxiv_id": "2505.02649v1",
      "title": "Eye Movements as Indicators of Deception: A Machine Learning Approach",
      "title_zh": "眼动作为欺骗的指标：一种机器学习方法\n",
      "authors": [
        "Valentin Foucher",
        "Santiago de Leon-Martinez",
        "Robert Moro"
      ],
      "abstract": "Gaze may enhance the robustness of lie detectors but remains under-studied.\nThis study evaluated the efficacy of AI models (using fixations, saccades,\nblinks, and pupil size) for detecting deception in Concealed Information Tests\nacross two datasets. The first, collected with Eyelink 1000, contains gaze data\nfrom a computerized experiment where 87 participants revealed, concealed, or\nfaked the value of a previously selected card. The second, collected with Pupil\nNeon, involved 36 participants performing a similar task but facing an\nexperimenter. XGBoost achieved accuracies up to 74% in a binary classification\ntask (Revealing vs. Concealing) and 49% in a more challenging\nthree-classification task (Revealing vs. Concealing vs. Faking). Feature\nanalysis identified saccade number, duration, amplitude, and maximum pupil size\nas the most important for deception prediction. These results demonstrate the\nfeasibility of using gaze and AI to enhance lie detectors and encourage future\nresearch that may improve on this.",
      "tldr_zh": "本研究探索了利用眼动数据（注视、扫视、眨眼和瞳孔大小）结合机器学习模型来检测说谎的可行性。研究人员使用了两个数据集，分别通过Eyelink 1000和Pupil Neon设备收集，参与者在隐藏信息测试中进行说谎、隐瞒或伪装行为。结果表明，XGBoost模型在二分类任务（揭示 vs. 隐瞒）中准确率高达74%，在三分类任务（揭示 vs. 隐瞒 vs. 伪装）中准确率达到49%。特征分析显示，扫视次数、持续时间、幅度和最大瞳孔尺寸是预测说谎的关键指标。该研究证明了利用眼动和人工智能增强测谎仪器的潜力。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02649v1",
      "published_date": "2025-05-05 13:50:12 UTC",
      "updated_date": "2025-05-05 13:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:20:00.538547"
    },
    {
      "arxiv_id": "2505.02640v1",
      "title": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints",
      "title_zh": "面向具有动态资源约束的物联网的自适应预算多臂老虎机\n",
      "authors": [
        "Shubham Vaishnav",
        "Praveen Kumar Donta",
        "Sindri Magnússon"
      ],
      "abstract": "Internet of Things (IoT) systems increasingly operate in environments where\ndevices must respond in real time while managing fluctuating resource\nconstraints, including energy and bandwidth. Yet, current approaches often fall\nshort in addressing scenarios where operational constraints evolve over time.\nTo address these limitations, we propose a novel Budgeted Multi-Armed Bandit\nframework tailored for IoT applications with dynamic operational limits. Our\nmodel introduces a decaying violation budget, which permits limited constraint\nviolations early in the learning process and gradually enforces stricter\ncompliance over time. We present the Budgeted Upper Confidence Bound (UCB)\nalgorithm, which adaptively balances performance optimization and compliance\nwith time-varying constraints. We provide theoretical guarantees showing that\nBudgeted UCB achieves sublinear regret and logarithmic constraint violations\nover the learning horizon. Extensive simulations in a wireless communication\nsetting show that our approach achieves faster adaptation and better constraint\nsatisfaction than standard online learning methods. These results highlight the\nframework's potential for building adaptive, resource-aware IoT systems.",
      "tldr_zh": "该论文提出了一种新的自适应预算多臂老虎机(Budgeted Multi-Armed Bandit)框架，专门用于解决物联网(IoT)应用中动态资源约束问题。该模型引入了衰减违规预算(decaying violation budget)机制，允许在学习初期有限的违反约束，并随着时间推移逐渐加强合规性。研究者提出了预算上限置信界(Budgeted UCB)算法，该算法自适应地平衡了性能优化和时变约束的合规性。理论分析表明，Budgeted UCB在学习范围内实现了亚线性遗憾(sublinear regret)和对数约束违规(logarithmic constraint violations)。在无线通信环境中的大量仿真表明，该方法比标准的在线学习方法实现了更快的适应性和更好的约束满足，突出了该框架在构建自适应、资源感知的物联网系统方面的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02640v1",
      "published_date": "2025-05-05 13:33:39 UTC",
      "updated_date": "2025-05-05 13:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:20:12.714779"
    },
    {
      "arxiv_id": "2505.02639v1",
      "title": "Enhancing Chemical Reaction and Retrosynthesis Prediction with Large Language Model and Dual-task Learning",
      "title_zh": "利用大型语言模型和双任务学习增强化学反应和逆合成预测\n",
      "authors": [
        "Xuan Lin",
        "Qingrui Liu",
        "Hongxin Xiang",
        "Daojian Zeng",
        "Xiangxiang Zeng"
      ],
      "abstract": "Chemical reaction and retrosynthesis prediction are fundamental tasks in drug\ndiscovery. Recently, large language models (LLMs) have shown potential in many\ndomains. However, directly applying LLMs to these tasks faces two major\nchallenges: (i) lacking a large-scale chemical synthesis-related instruction\ndataset; (ii) ignoring the close correlation between reaction and\nretrosynthesis prediction for the existing fine-tuning strategies. To address\nthese challenges, we propose ChemDual, a novel LLM framework for accurate\nchemical synthesis. Specifically, considering the high cost of data acquisition\nfor reaction and retrosynthesis, ChemDual regards the\nreaction-and-retrosynthesis of molecules as a related\nrecombination-and-fragmentation process and constructs a large-scale of 4.4\nmillion instruction dataset. Furthermore, ChemDual introduces an enhanced\nLLaMA, equipped with a multi-scale tokenizer and dual-task learning strategy,\nto jointly optimize the process of recombination and fragmentation as well as\nthe tasks between reaction and retrosynthesis prediction. Extensive experiments\non Mol-Instruction and USPTO-50K datasets demonstrate that ChemDual achieves\nstate-of-the-art performance in both predictions of reaction and\nretrosynthesis, outperforming the existing conventional single-task approaches\nand the general open-source LLMs. Through molecular docking analysis, ChemDual\ngenerates compounds with diverse and strong protein binding affinity, further\nhighlighting its strong potential in drug design.",
      "tldr_zh": "该论文提出了ChemDual，一个新颖的LLM框架，用于提升化学反应和逆合成预测的准确性。ChemDual通过将分子反应和逆合成视为相关的重组和碎片过程，构建了一个包含440万条指令的大规模数据集。此外，ChemDual引入了一个增强的LLaMA模型，配备多尺度tokenizer和双任务学习策略，共同优化重组和碎片过程，以及反应和逆合成预测任务。在Mol-Instruction和USPTO-50K数据集上的实验表明，ChemDual在反应和逆合成预测方面均达到了state-of-the-art的性能，优于现有的单任务方法和通用开源LLM。分子对接分析表明，ChemDual生成的化合物具有多样且强大的蛋白质结合亲和力，突显了其在药物设计方面的巨大潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02639v1",
      "published_date": "2025-05-05 13:31:36 UTC",
      "updated_date": "2025-05-05 13:31:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:20:24.472746"
    },
    {
      "arxiv_id": "2505.02627v1",
      "title": "A Theoretical Analysis of Compositional Generalization in Neural Networks: A Necessary and Sufficient Condition",
      "title_zh": "神经网络中组合泛化的理论分析：一个充要条件\n",
      "authors": [
        "Yuanpeng Li"
      ],
      "abstract": "Compositional generalization is a crucial property in artificial\nintelligence, enabling models to handle novel combinations of known components.\nWhile most deep learning models lack this capability, certain models succeed in\nspecific tasks, suggesting the existence of governing conditions. This paper\nderives a necessary and sufficient condition for compositional generalization\nin neural networks. Conceptually, it requires that (i) the computational graph\nmatches the true compositional structure, and (ii) components encode just\nenough information in training. The condition is supported by mathematical\nproofs. This criterion combines aspects of architecture design, regularization,\nand training data properties. A carefully designed minimal example illustrates\nan intuitive understanding of the condition. We also discuss the potential of\nthe condition for assessing compositional generalization before training. This\nwork is a fundamental theoretical study of compositional generalization in\nneural networks.",
      "tldr_zh": "该论文从理论上分析了神经网络中的组合泛化能力，提出了一个充要条件。该条件要求：(1)计算图需要匹配真实的组合结构；(2) 各个组成部分在训练过程中编码的信息量要恰到好处。该条件结合了架构设计、正则化和训练数据属性等方面。论文通过数学证明支持了该条件，并通过一个精心设计的最小示例阐释了其直观理解。此外，论文还探讨了在训练前评估组合泛化能力的可能性。这项工作是对神经网络中组合泛化能力的一项基础理论研究。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02627v1",
      "published_date": "2025-05-05 13:13:46 UTC",
      "updated_date": "2025-05-05 13:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:20:36.353840"
    },
    {
      "arxiv_id": "2505.02625v1",
      "title": "LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis",
      "title_zh": "LLaMA-Omni2：基于LLM的实时语音聊天机器人，采用自回归流式语音合成\n",
      "authors": [
        "Qingkai Fang",
        "Yan Zhou",
        "Shoutao Guo",
        "Shaolei Zhang",
        "Yang Feng"
      ],
      "abstract": "Real-time, intelligent, and natural speech interaction is an essential part\nof the next-generation human-computer interaction. Recent advancements have\nshowcased the potential of building intelligent spoken chatbots based on large\nlanguage models (LLMs). In this paper, we introduce LLaMA-Omni 2, a series of\nspeech language models (SpeechLMs) ranging from 0.5B to 14B parameters, capable\nof achieving high-quality real-time speech interaction. LLaMA-Omni 2 is built\nupon the Qwen2.5 series models, integrating a speech encoder and an\nautoregressive streaming speech decoder. Despite being trained on only 200K\nmulti-turn speech dialogue samples, LLaMA-Omni 2 demonstrates strong\nperformance on several spoken question answering and speech instruction\nfollowing benchmarks, surpassing previous state-of-the-art SpeechLMs like\nGLM-4-Voice, which was trained on millions of hours of speech data.",
      "tldr_zh": "该论文介绍了LLaMA-Omni 2，一系列基于Qwen2.5的语音语言模型(SpeechLM)，参数规模从0.5B到14B。LLaMA-Omni 2集成了语音编码器和自回归流式语音解码器，旨在实现高质量的实时语音交互。尽管仅使用200K多轮语音对话样本进行训练，LLaMA-Omni 2在语音问答和语音指令跟随基准测试中表现出色，超越了之前最先进的SpeechLM，如GLM-4-Voice。这表明LLaMA-Omni 2在构建智能语音聊天机器人方面具有巨大潜力。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Project: https://github.com/ictnlp/LLaMA-Omni2",
      "pdf_url": "http://arxiv.org/pdf/2505.02625v1",
      "published_date": "2025-05-05 12:53:09 UTC",
      "updated_date": "2025-05-05 12:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:20:48.391273"
    },
    {
      "arxiv_id": "2505.02609v1",
      "title": "Study of the influence of a biased database on the prediction of standard algorithms for selecting the best candidate for an interview",
      "title_zh": "有偏数据库对标准算法预测面试最佳候选人的影响研究\n",
      "authors": [
        "Shuyu Wang",
        "Angélique Saillet",
        "Philomène Le Gall",
        "Alain Lacroux",
        "Christelle Martin-Lacroux",
        "Vincent Brault"
      ],
      "abstract": "Artificial intelligence is used at various stages of the recruitment process\nto automatically select the best candidate for a position, with companies\nguaranteeing unbiased recruitment. However, the algorithms used are either\ntrained by humans or are based on learning from past experiences that were\nbiased. In this article, we propose to generate data mimicking external\n(discrimination) and internal biases (self-censorship) in order to train five\nclassic algorithms and to study the extent to which they do or do not find the\nbest candidates according to objective criteria. In addition, we study the\ninfluence of the anonymisation of files on the quality of predictions.",
      "tldr_zh": "该研究探讨了有偏数据库对使用标准算法进行面试候选人选择的影响。通过模拟外部歧视和内部自我审查产生数据，用于训练五种经典算法，研究它们在多大程度上能根据客观标准找到最佳候选人。此外，该研究还考察了文件匿名化对预测质量的影响。研究结果揭示了算法在招聘过程中可能存在的偏见，并强调了数据偏见对人工智能公平性的重要影响。\n",
      "categories": [
        "cs.AI",
        "cs.CY",
        "stat.AP",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "38 pages, 25 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.02609v1",
      "published_date": "2025-05-05 12:24:31 UTC",
      "updated_date": "2025-05-05 12:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:21:00.142095"
    },
    {
      "arxiv_id": "2505.02581v1",
      "title": "Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem",
      "title_zh": "作为人工智能对齐问题的应急解决方案的能动性神经多样性",
      "authors": [
        "Alberto Hernández-Espinosa",
        "Felipe S. Abrahão",
        "Olaf Witkowski",
        "Hector Zenil"
      ],
      "abstract": "The AI alignment problem, which focusses on ensuring that artificial\nintelligence (AI), including AGI and ASI, systems act according to human\nvalues, presents profound challenges. With the progression from narrow AI to\nArtificial General Intelligence (AGI) and Superintelligence, fears about\ncontrol and existential risk have escalated. This paper demonstrates that\nachieving complete alignment is inherently unattainable due to mathematical\nprinciples rooted in the foundations of predicate logic and computability, in\nparticular Turing's computational universality, G\\\"odel's incompleteness and\nChaitin's randomness. Instead, we argue that embracing AI misalignment or\nagent's `neurodivergence' as a contingent strategy, defined as fostering a\ndynamic ecosystem of competing, partially aligned agents, is a possible only\nviable path to mitigate risks. Through mathematical proofs and an experimental\ndesign, we explore how misalignment may serve and should be promoted as a\ncounterbalancing mechanism to team up with whichever agents are most aligned AI\nto human values, ensuring that no single system dominates destructively. The\nmain premise of our contribution is that misalignment is inevitable because\nfull AI-human alignment is a mathematical impossibility from Turing-complete\nsystems which we also prove in this paper, a feature then inherited to AGI and\nASI systems. We introduce and test `change-of-opinion' attacks based on this\nkind of perturbation and intervention analysis to study how agents may\nneutralise friendly or unfriendly AIs through cooperation, competition or\nmalice.",
      "tldr_zh": "本文探讨了AI对齐问题，指出完全对齐由于图灵完备性、哥德尔不完备性和Chaitin随机性等数学原理在根本上是无法实现的。因此，文章提出将AI的“神经多样性”（neurodivergence），即AI的不对齐，作为一种权宜之计。通过数学证明和实验设计，作者论证了拥抱AI的不对齐，构建一个由竞争的、部分对齐的智能体组成的动态生态系统，可能是缓解风险的唯一可行途径。研究引入并测试了基于“改变观点”的攻击，以研究智能体如何通过合作、竞争或恶意行为来中和友好或不友好的AI。核心观点是，完全的AI-人类对齐在数学上是不可能的，因此不对齐是不可避免的，而这种特性也将传递给AGI和ASI系统。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.02581v1",
      "published_date": "2025-05-05 11:33:18 UTC",
      "updated_date": "2025-05-05 11:33:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:21:12.719251"
    },
    {
      "arxiv_id": "2505.02579v2",
      "title": "EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning",
      "title_zh": "EMORL：用于高效灵活的 LLM 微调的集成多目标强化学习\n",
      "authors": [
        "Lingxiao Kong",
        "Cong Yang",
        "Susanne Neufang",
        "Oya Deniz Beyan",
        "Zeyd Boukhers"
      ],
      "abstract": "Recent advances in reinforcement learning (RL) for large language model (LLM)\nfine-tuning show promise in addressing multi-objective tasks but still face\nsignificant challenges, including complex objective balancing, low training\nefficiency, poor scalability, and limited explainability. Leveraging ensemble\nlearning principles, we introduce an Ensemble Multi-Objective RL (EMORL)\nframework that fine-tunes multiple models with individual objectives while\noptimizing their aggregation after the training to improve efficiency and\nflexibility. Our method is the first to aggregate the last hidden states of\nindividual models, incorporating contextual information from multiple\nobjectives. This approach is supported by a hierarchical grid search algorithm\nthat identifies optimal weighted combinations. We evaluate EMORL on counselor\nreflection generation tasks, using text-scoring LLMs to evaluate the\ngenerations and provide rewards during RL fine-tuning. Through comprehensive\nexperiments on the PAIR and Psych8k datasets, we demonstrate the advantages of\nEMORL against existing baselines: significantly lower and more stable training\nconsumption ($17,529\\pm 1,650$ data points and $6,573\\pm 147.43$ seconds),\nimproved scalability and explainability, and comparable performance across\nmultiple objectives.",
      "tldr_zh": "该论文提出了一个集成多目标强化学习框架（EMORL），用于高效且灵活的大语言模型（LLM）微调。EMORL通过集成学习的思想，训练多个具有独立目标的模型，并在训练后优化它们的聚合，从而提高效率和灵活性。该方法创新性地聚合了各个模型的最后隐藏状态，融入了来自多个目标的上下文信息，并通过分层网格搜索算法确定最佳的加权组合。在PAIR和Psych8k数据集上的实验表明，EMORL在降低训练消耗、提高可扩展性和可解释性方面优于现有基线，同时在多个目标上实现了可比的性能。具体而言，EMORL的训练消耗显著降低，仅需$17,529\\pm 1,650$个数据点和$6,573\\pm 147.43$秒。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 9 figures, submitted to SIGDIAL 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2505.02579v2",
      "published_date": "2025-05-05 11:30:46 UTC",
      "updated_date": "2025-05-06 06:26:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:21:24.710729"
    },
    {
      "arxiv_id": "2505.02576v1",
      "title": "Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning",
      "title_zh": "具有依赖关系的递归分解，用于通用的分而治之推理",
      "authors": [
        "Sergio Hernández-Gutiérrez",
        "Minttu Alakuijala",
        "Alexander V. Nikitin",
        "Pekka Marttinen"
      ],
      "abstract": "Reasoning tasks are crucial in many domains, especially in science and\nengineering. Although large language models (LLMs) have made progress in\nreasoning tasks using techniques such as chain-of-thought and least-to-most\nprompting, these approaches still do not effectively scale to complex problems\nin either their performance or execution time. Moreover, they often require\nadditional supervision for each new task, such as in-context examples. In this\nwork, we introduce Recursive Decomposition with Dependencies (RDD), a scalable\ndivide-and-conquer method for solving reasoning problems that requires less\nsupervision than prior approaches. Our method can be directly applied to a new\nproblem class even in the absence of any task-specific guidance. Furthermore,\nRDD supports sub-task dependencies, allowing for ordered execution of\nsub-tasks, as well as an error recovery mechanism that can correct mistakes\nmade in previous steps. We evaluate our approach on two benchmarks with six\ndifficulty levels each and in two in-context settings: one with task-specific\nexamples and one without. Our results demonstrate that RDD outperforms other\nmethods in a compute-matched setting as task complexity increases, while also\nbeing more computationally efficient.",
      "tldr_zh": "该论文提出了一种名为Recursive Decomposition with Dependencies (RDD) 的可扩展分治方法，用于解决复杂的推理问题。RDD 相比于 chain-of-thought 等方法，所需的监督更少，即使在没有特定任务指导的情况下，也能直接应用于新的问题类别。RDD 支持子任务依赖关系，允许子任务按顺序执行，并具有纠正先前步骤中错误的错误恢复机制。在两个基准测试（每个基准测试有六个难度级别）和两种上下文设置（一种带有特定于任务的示例，另一种没有）中的评估结果表明，随着任务复杂性的增加，RDD 在计算匹配的设置中优于其他方法，同时计算效率更高。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02576v1",
      "published_date": "2025-05-05 11:24:20 UTC",
      "updated_date": "2025-05-05 11:24:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:21:36.427893"
    },
    {
      "arxiv_id": "2505.02573v1",
      "title": "Rethinking Federated Graph Learning: A Data Condensation Perspective",
      "title_zh": "重新思考联邦图学习：一种数据浓缩的视角\n",
      "authors": [
        "Hao Zhang",
        "Xunkai Li",
        "Yinlin Zhu",
        "Lianglin Hu"
      ],
      "abstract": "Federated graph learning is a widely recognized technique that promotes\ncollaborative training of graph neural networks (GNNs) by multi-client\ngraphs.However, existing approaches heavily rely on the communication of model\nparameters or gradients for federated optimization and fail to adequately\naddress the data heterogeneity introduced by intricate and diverse graph\ndistributions. Although some methods attempt to share additional messages among\nthe server and clients to improve federated convergence during communication,\nthey introduce significant privacy risks and increase communication overhead.\nTo address these issues, we introduce the concept of a condensed graph as a\nnovel optimization carrier to address FGL data heterogeneity and propose a new\nFGL paradigm called FedGM. Specifically, we utilize a generalized condensation\ngraph consensus to aggregate comprehensive knowledge from distributed graphs,\nwhile minimizing communication costs and privacy risks through a single\ntransmission of the condensed data. Extensive experiments on six public\ndatasets consistently demonstrate the superiority of FedGM over\nstate-of-the-art baselines, highlighting its potential for a novel FGL\nparadigm.",
      "tldr_zh": "本文从数据浓缩的角度重新思考联邦图学习(Federated Graph Learning, FGL)，提出了一种新的FGL范式FedGM。FedGM利用广义浓缩图共识来聚合来自分布式图的全面知识，并通过单次传输浓缩数据来最小化通信成本和隐私风险，从而解决FGL中数据异构性的问题。在六个公共数据集上的大量实验表明，FedGM优于现有的state-of-the-art基线模型，验证了其作为一种新型FGL范式的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02573v1",
      "published_date": "2025-05-05 11:23:29 UTC",
      "updated_date": "2025-05-05 11:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:21:48.248721"
    },
    {
      "arxiv_id": "2505.02566v1",
      "title": "Robustness questions the interpretability of graph neural networks: what to do?",
      "title_zh": "鲁棒性质疑图神经网络的可解释性：该怎么办？\n",
      "authors": [
        "Kirill Lukyanov",
        "Georgii Sazonov",
        "Serafim Boyarsky",
        "Ilya Makarov"
      ],
      "abstract": "Graph Neural Networks (GNNs) have become a cornerstone in graph-based data\nanalysis, with applications in diverse domains such as bioinformatics, social\nnetworks, and recommendation systems. However, the interplay between model\ninterpretability and robustness remains poorly understood, especially under\nadversarial scenarios like poisoning and evasion attacks. This paper presents a\ncomprehensive benchmark to systematically analyze the impact of various factors\non the interpretability of GNNs, including the influence of\nrobustness-enhancing defense mechanisms.\n  We evaluate six GNN architectures based on GCN, SAGE, GIN, and GAT across\nfive datasets from two distinct domains, employing four interpretability\nmetrics: Fidelity, Stability, Consistency, and Sparsity. Our study examines how\ndefenses against poisoning and evasion attacks, applied before and during model\ntraining, affect interpretability and highlights critical trade-offs between\nrobustness and interpretability. The framework will be published as open\nsource.\n  The results reveal significant variations in interpretability depending on\nthe chosen defense methods and model architecture characteristics. By\nestablishing a standardized benchmark, this work provides a foundation for\ndeveloping GNNs that are both robust to adversarial threats and interpretable,\nfacilitating trust in their deployment in sensitive applications.",
      "tldr_zh": "该论文深入研究了图神经网络(GNNs)在对抗性攻击下的鲁棒性和可解释性之间的关系。通过构建一个全面的benchmark，作者系统地分析了包括GCN、SAGE、GIN和GAT等六种GNN架构在不同数据集上，在受到投毒和逃逸攻击时，以及应用防御机制前后，其可解释性指标（Fidelity, Stability, Consistency, Sparsity）的变化。研究结果揭示了鲁棒性防御方法和模型架构特性对可解释性的显著影响，强调了二者之间的权衡。该研究为开发既具有对抗威胁的鲁棒性又具有可解释性的GNN奠定了基础，并开源了该benchmark框架。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02566v1",
      "published_date": "2025-05-05 11:14:56 UTC",
      "updated_date": "2025-05-05 11:14:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:22:00.676287"
    },
    {
      "arxiv_id": "2505.02550v1",
      "title": "Bielik v3 Small: Technical Report",
      "title_zh": "Bielik v3 Small：技术报告\n",
      "authors": [
        "Krzysztof Ociepa",
        "Łukasz Flis",
        "Remigiusz Kinas",
        "Krzysztof Wróbel",
        "Adrian Gwoździej"
      ],
      "abstract": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications.",
      "tldr_zh": "该报告介绍了Bielik v3，一系列针对波兰语处理优化的参数高效生成文本模型（15亿和45亿参数）。该模型通过定制的波兰语分词器(APT4)显著提高token效率，并采用加权指令交叉熵损失(Weighted Instruction Cross-Entropy Loss)和自适应学习率(Adaptive Learning Rate)等创新方法。Bielik v3在包含2920亿tokens的大规模语料库上训练，在Open PL LLM Leaderboard等多个基准测试中表现出色。实验结果表明，该模型在参数效率方面表现优异，为资源受限的应用提供了高质量的波兰语AI解决方案。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02550v1",
      "published_date": "2025-05-05 10:39:51 UTC",
      "updated_date": "2025-05-05 10:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:22:12.605044"
    },
    {
      "arxiv_id": "2505.02540v1",
      "title": "Lazy But Effective: Collaborative Personalized Federated Learning with Heterogeneous Data",
      "title_zh": "偷懒但有效：具有异构数据的协同个性化联邦学习\n",
      "authors": [
        "Ljubomir Rokvic",
        "Panayiotis Danassis",
        "Boi Faltings"
      ],
      "abstract": "In Federated Learning, heterogeneity in client data distributions often means\nthat a single global model does not have the best performance for individual\nclients. Consider for example training a next-word prediction model for\nkeyboards: user-specific language patterns due to demographics (dialect, age,\netc.), language proficiency, and writing style result in a highly non-IID\ndataset across clients. Other examples are medical images taken with different\nmachines, or driving data from different vehicle types. To address this, we\npropose a simple yet effective personalized federated learning framework\n(pFedLIA) that utilizes a computationally efficient influence approximation,\ncalled `Lazy Influence', to cluster clients in a distributed manner before\nmodel aggregation. Within each cluster, data owners collaborate to jointly\ntrain a model that captures the specific data patterns of the clients. Our\nmethod has been shown to successfully recover the global model's performance\ndrop due to the non-IID-ness in various synthetic and real-world settings,\nspecifically a next-word prediction task on the Nordic languages as well as\nseveral benchmark tasks. It matches the performance of a hypothetical Oracle\nclustering, and significantly improves on existing baselines, e.g., an\nimprovement of 17% on CIFAR100.",
      "tldr_zh": "本文提出了一种简单而有效的个性化联邦学习框架(pFedLIA)，旨在解决联邦学习中由于客户端数据分布异构性导致的全局模型性能下降问题。该框架利用一种计算效率高的影响近似方法，称为“Lazy Influence”，以分布式方式对客户端进行聚类，然后再进行模型聚合。在每个集群内，数据所有者协同训练一个模型，以捕获客户端的特定数据模式。实验结果表明，该方法成功地恢复了由于各种合成和真实世界设置中的非独立同分布性导致的全局模型性能下降，例如在北欧语言的下一个单词预测任务以及几个基准任务中。它与假设的 Oracle 聚类的性能相匹配，并且显着优于现有的基线，例如在 CIFAR100 上提高了 17%。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the International Joint Conference on Neural Networks\n  (IJCNN), IEEE, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02540v1",
      "published_date": "2025-05-05 10:26:35 UTC",
      "updated_date": "2025-05-05 10:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:22:24.713589"
    },
    {
      "arxiv_id": "2505.02537v2",
      "title": "Advancing Constrained Monotonic Neural Networks: Achieving Universal Approximation Beyond Bounded Activations",
      "title_zh": "推进约束单调神经网络：实现超越有界激活的通用逼近\n",
      "authors": [
        "Davide Sartor",
        "Alberto Sinigaglia",
        "Gian Antonio Susto"
      ],
      "abstract": "Conventional techniques for imposing monotonicity in MLPs by construction\ninvolve the use of non-negative weight constraints and bounded activation\nfunctions, which pose well-known optimization challenges. In this work, we\ngeneralize previous theoretical results, showing that MLPs with non-negative\nweight constraint and activations that saturate on alternating sides are\nuniversal approximators for monotonic functions. Additionally, we show an\nequivalence between the saturation side in the activations and the sign of the\nweight constraint. This connection allows us to prove that MLPs with convex\nmonotone activations and non-positive constrained weights also qualify as\nuniversal approximators, in contrast to their non-negative constrained\ncounterparts. Our results provide theoretical grounding to the empirical\neffectiveness observed in previous works while leading to possible\narchitectural simplification. Moreover, to further alleviate the optimization\ndifficulties, we propose an alternative formulation that allows the network to\nadjust its activations according to the sign of the weights. This eliminates\nthe requirement for weight reparameterization, easing initialization and\nimproving training stability. Experimental evaluation reinforces the validity\nof the theoretical results, showing that our novel approach compares favourably\nto traditional monotonic architectures.",
      "tldr_zh": "该论文针对传统单调神经网络(Monotonic Neural Networks)中非负权重约束和有界激活函数带来的优化挑战，提出了改进方案。理论上证明了具有非负权重约束和交替饱和激活函数的MLP是单调函数的通用逼近器，并揭示了激活函数的饱和侧与权重约束符号之间的等价关系。基于此，证明了具有凸单调激活函数和非正约束权重的MLP同样是通用逼近器。此外，提出了一种允许网络根据权重符号调整其激活函数的新公式，无需权重重参数化，从而简化初始化并提高训练稳定性。实验结果验证了理论的有效性，表明该方法优于传统的单调架构。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2505.02537v2",
      "published_date": "2025-05-05 10:18:48 UTC",
      "updated_date": "2025-05-06 11:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:22:36.455724"
    },
    {
      "arxiv_id": "2505.02533v1",
      "title": "Large Language Model Partitioning for Low-Latency Inference at the Edge",
      "title_zh": "用于边缘低延迟推理的大语言模型分割",
      "authors": [
        "Dimitrios Kafetzis",
        "Ramin Khalili",
        "Iordanis Koutsopoulos"
      ],
      "abstract": "Large Language Models (LLMs) based on autoregressive, decoder-only\nTransformers generate text one token at a time, where a token represents a\ndiscrete unit of text. As each newly produced token is appended to the partial\noutput sequence, the length grows and so does the memory and compute load, due\nto the expanding key-value caches, which store intermediate representations of\nall previously generated tokens in the multi-head attention (MHA) layer. As\nthis iterative process steadily increases memory and compute demands,\nlayer-based partitioning in resource-constrained edge environments often\nresults in memory overload or high inference latency. To address this and\nreduce inference latency, we propose a resource-aware Transformer architecture\npartitioning algorithm, where the partitioning decision is updated at regular\nintervals during token generation. The approach is myopic in that it is based\non instantaneous information about device resource availability and network\nlink bandwidths. When first executed, the algorithm places blocks on devices,\nand in later executions, it migrates these blocks among devices so that the sum\nof migration delay and inference delay remains low. Our approach partitions the\ndecoder at the attention head level, co-locating each attention head with its\nkey-value cache and allowing dynamic migrations whenever resources become\ntight. By allocating different attention heads to different devices, we exploit\nparallel execution of attention heads and thus achieve substantial reductions\nin inference delays. Our experiments show that in small-scale settings (3-5\ndevices), the proposed method achieves within 15 to 20 percent of an exact\noptimal solver's latency, while in larger-scale tests it achieves notable\nimprovements in inference speed and memory usage compared to state-of-the-art\nlayer-based partitioning approaches.",
      "tldr_zh": "该论文提出了一种资源感知的Transformer架构分割算法，用于在资源受限的边缘环境中降低LLM的推理延迟。该算法在token生成过程中定期更新分割决策，根据设备资源可用性和网络带宽的瞬时信息进行决策。该方法在attention head级别分割解码器，将每个attention head与其key-value缓存共同定位，并允许动态迁移。通过将不同的attention head分配给不同的设备，利用attention head的并行执行，从而显著降低推理延迟。实验表明，与最先进的基于层的分割方法相比，该方法在推理速度和内存使用方面取得了显著的改进。\n",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02533v1",
      "published_date": "2025-05-05 10:16:16 UTC",
      "updated_date": "2025-05-05 10:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:22:48.487937"
    },
    {
      "arxiv_id": "2505.02516v1",
      "title": "Machine-Learning-Powered Neural Interfaces for Smart Prosthetics and Diagnostics",
      "title_zh": "机器学习驱动的神经接口，用于智能假肢和诊断",
      "authors": [
        "MohammadAli Shaeri",
        "Jinhan Liu",
        "Mahsa Shoaran"
      ],
      "abstract": "Advanced neural interfaces are transforming applications ranging from\nneuroscience research to diagnostic tools (for mental state recognition, tremor\nand seizure detection) as well as prosthetic devices (for motor and\ncommunication recovery). By integrating complex functions into miniaturized\nneural devices, these systems unlock significant opportunities for personalized\nassistive technologies and adaptive therapeutic interventions. Leveraging\nhigh-density neural recordings, on-site signal processing, and machine learning\n(ML), these interfaces extract critical features, identify disease\nneuro-markers, and enable accurate, low-latency neural decoding. This\nintegration facilitates real-time interpretation of neural signals, adaptive\nmodulation of brain activity, and efficient control of assistive devices.\nMoreover, the synergy between neural interfaces and ML has paved the way for\nself-sufficient, ubiquitous platforms capable of operating in diverse\nenvironments with minimal hardware costs and external dependencies. In this\nwork, we review recent advancements in AI-driven decoding algorithms and\nenergy-efficient System-on-Chip (SoC) platforms for next-generation\nminiaturized neural devices. These innovations highlight the potential for\ndeveloping intelligent neural interfaces, addressing critical challenges in\nscalability, reliability, interpretability, and user adaptability.",
      "tldr_zh": "本文综述了基于机器学习(ML)的神经接口在智能假肢和诊断领域的最新进展。通过集成高密度神经记录、片上信号处理和机器学习，这些接口能够提取关键特征、识别疾病神经标记，并实现精确、低延迟的神经解码。这种集成促进了神经信号的实时解释、大脑活动的自适应调节以及辅助设备的有效控制。此外，神经接口和机器学习的协同作用为开发能够在各种环境中运行的自给自足的通用平台铺平了道路，解决了可扩展性、可靠性、可解释性和用户适应性等关键挑战。本文还回顾了用于下一代小型化神经设备的AI驱动解码算法和节能片上系统(SoC)平台的最新进展。\n",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.LG",
        "eess.SP",
        "q-bio.NC",
        "I.2.0; B.7.0; I.5.1; C.3"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in the 2025 IEEE International NEWCAS Conference\n  (NEWCAS'25)",
      "pdf_url": "http://arxiv.org/pdf/2505.02516v1",
      "published_date": "2025-05-05 09:49:13 UTC",
      "updated_date": "2025-05-05 09:49:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:23:00.616669"
    },
    {
      "arxiv_id": "2505.02502v1",
      "title": "Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study",
      "title_zh": "揭示 LLM 在实际部署中的现状：一项实证研究\n",
      "authors": [
        "Xinyi Hou",
        "Jiahao Han",
        "Yanjie Zhao",
        "Haoyu Wang"
      ],
      "abstract": "Background: Large language models (LLMs) are increasingly deployed via\nopen-source and commercial frameworks, enabling individuals and organizations\nto self-host advanced AI capabilities. However, insecure defaults and\nmisconfigurations often expose LLM services to the public Internet, posing\nsignificant security and system engineering risks. Aims: This study aims to\nunveil the current landscape of public-facing LLM deployments in the wild\nthrough a large-scale empirical study, focusing on service prevalence, exposure\ncharacteristics, systemic vulnerabilities, and associated risks. Method: We\nconducted an Internet-wide measurement to identify public-facing LLM\ndeployments across 15 frameworks, discovering 320,102 services. We extracted\n158 unique API endpoints, grouped into 12 functional categories based on\ncapabilities and security risks. We further analyzed configurations,\nauthentication practices, and geographic distributions, revealing deployment\ntrends and systemic issues in real-world LLM system engineering. Results: Our\nstudy shows that public LLM deployments are rapidly growing but often insecure.\nAmong all endpoints, we observe widespread use of insecure protocols, poor TLS\nconfigurations, and unauthenticated access to critical operations. Security\nrisks, including model disclosure, system leakage, and unauthorized access, are\npervasive, highlighting the need for secure-by-default frameworks and stronger\ndeployment practices. Conclusions: Public-facing LLM deployments suffer from\nwidespread security and configuration flaws, exposing services to misuse, model\ntheft, resource hijacking, and remote exploitation. Strengthening default\nsecurity, deployment practices, and operational standards is critical for the\ngrowing self-hosted LLM ecosystem.",
      "tldr_zh": "该研究旨在揭示公共领域中大型语言模型(LLM)部署的现状，通过大规模实证研究分析其服务普及率、暴露特征、系统性漏洞和相关风险。研究人员对互联网范围内的15个框架进行了测量，发现了320,102个面向公众的LLM服务，并提取了158个独特的API端点。结果表明，公共LLM部署迅速增长但安全性不足，存在不安全协议、TLS配置不佳以及未经身份验证的关键操作等问题。研究强调，需要加强默认安全性、部署实践和操作标准，以应对LLM部署中存在的滥用、模型盗窃、资源劫持和远程利用等风险。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02502v1",
      "published_date": "2025-05-05 09:30:19 UTC",
      "updated_date": "2025-05-05 09:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:23:12.618747"
    },
    {
      "arxiv_id": "2505.02501v1",
      "title": "Corr2Distrib: Making Ambiguous Correspondences an Ally to Predict Reliable 6D Pose Distributions",
      "title_zh": "Corr2Distrib：化模糊对应为助力，预测可靠的 6D 姿态分布\n",
      "authors": [
        "Asma Brazi",
        "Boris Meden",
        "Fabrice Mayran de Chamisso",
        "Steve Bourgeois",
        "Vincent Lepetit"
      ],
      "abstract": "We introduce Corr2Distrib, the first correspondence-based method which\nestimates a 6D camera pose distribution from an RGB image, explaining the\nobservations. Indeed, symmetries and occlusions introduce visual ambiguities,\nleading to multiple valid poses. While a few recent methods tackle this\nproblem, they do not rely on local correspondences which, according to the BOP\nChallenge, are currently the most effective way to estimate a single 6DoF pose\nsolution. Using correspondences to estimate a pose distribution is not\nstraightforward, since ambiguous correspondences induced by visual ambiguities\ndrastically decrease the performance of PnP. With Corr2Distrib, we turn these\nambiguities into an advantage to recover all valid poses. Corr2Distrib first\nlearns a symmetry-aware representation for each 3D point on the object's\nsurface, characterized by a descriptor and a local frame. This representation\nenables the generation of 3DoF rotation hypotheses from single 2D-3D\ncorrespondences. Next, we refine these hypotheses into a 6DoF pose distribution\nusing PnP and pose scoring. Our experimental evaluations on complex\nnon-synthetic scenes show that Corr2Distrib outperforms state-of-the-art\nsolutions for both pose distribution estimation and single pose estimation from\nan RGB image, demonstrating the potential of correspondences-based approaches.",
      "tldr_zh": "本文提出了一种名为Corr2Distrib的、基于对应关系(correspondence-based)的方法，用于从RGB图像中估计6D相机姿态分布。该方法旨在解决对称性和遮挡引入的视觉歧义问题，这些歧义会导致多个有效的姿态。Corr2Distrib首先学习物体表面每个3D点的对称感知表示(symmetry-aware representation)，该表示包含描述符和局部坐标系(local frame)。然后，利用该表示从单个2D-3D对应关系中生成3DoF旋转假设，并通过PnP和姿态评分将这些假设细化为6DoF姿态分布。实验结果表明，Corr2Distrib在姿态分布估计和单姿态估计方面均优于现有方法，证明了基于对应关系的方法的潜力。该方法有效地将视觉歧义转化为优势，从而恢复所有有效的姿态。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02501v1",
      "published_date": "2025-05-05 09:29:32 UTC",
      "updated_date": "2025-05-05 09:29:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:23:24.880589"
    },
    {
      "arxiv_id": "2505.02489v1",
      "title": "Beyond the model: Key differentiators in large language models and multi-agent services",
      "title_zh": "超越模型：大型语言模型和多智能体服务的关键差异化因素\n",
      "authors": [
        "Muskaan Goyal",
        "Pranav Bhasin"
      ],
      "abstract": "With the launch of foundation models like DeepSeek, Manus AI, and Llama 4, it\nhas become evident that large language models (LLMs) are no longer the sole\ndefining factor in generative AI. As many now operate at comparable levels of\ncapability, the real race is not about having the biggest model but optimizing\nthe surrounding ecosystem, including data quality and management, computational\nefficiency, latency, and evaluation frameworks. This review article delves into\nthese critical differentiators that ensure modern AI services are efficient and\nprofitable.",
      "tldr_zh": "随着DeepSeek、Manus AI和Llama 4等基础模型的发布，大型语言模型(LLMs)不再是生成式AI的唯一决定因素。由于许多模型在能力上处于相似水平，真正的竞争在于优化周围的生态系统，包括数据质量和管理、计算效率、延迟和评估框架。本文探讨了这些关键的差异化因素，这些因素确保了现代AI服务的高效和盈利。该研究强调，在LLM能力趋同的背景下，关注数据、效率和评估是构建成功的AI服务的关键。\n",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.02489v1",
      "published_date": "2025-05-05 09:15:31 UTC",
      "updated_date": "2025-05-05 09:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:23:36.291895"
    },
    {
      "arxiv_id": "2505.02486v1",
      "title": "SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning",
      "title_zh": "SEFE：用于多模态持续指令微调的表面和本质遗忘消除器\n",
      "authors": [
        "Jinpeng Chen",
        "Runmin Cong",
        "Yuzhi Zhao",
        "Hongzheng Yang",
        "Guangneng Hu",
        "Horace Ho Shing Ip",
        "Sam Kwong"
      ],
      "abstract": "Multimodal Continual Instruction Tuning (MCIT) aims to enable Multimodal\nLarge Language Models (MLLMs) to incrementally learn new tasks without\ncatastrophic forgetting. In this paper, we explore forgetting in this context,\ncategorizing it into superficial forgetting and essential forgetting.\nSuperficial forgetting refers to cases where the model's knowledge may not be\ngenuinely lost, but its responses to previous tasks deviate from expected\nformats due to the influence of subsequent tasks' answer styles, making the\nresults unusable. By contrast, essential forgetting refers to situations where\nthe model provides correctly formatted but factually inaccurate answers,\nindicating a true loss of knowledge. Assessing essential forgetting\nnecessitates addressing superficial forgetting first, as severe superficial\nforgetting can obscure the model's knowledge state. Hence, we first introduce\nthe Answer Style Diversification (ASD) paradigm, which defines a standardized\nprocess for transforming data styles across different tasks, unifying their\ntraining sets into similarly diversified styles to prevent superficial\nforgetting caused by style shifts. Building on this, we propose RegLoRA to\nmitigate essential forgetting. RegLoRA stabilizes key parameters where prior\nknowledge is primarily stored by applying regularization, enabling the model to\nretain existing competencies. Experimental results demonstrate that our overall\nmethod, SEFE, achieves state-of-the-art performance.",
      "tldr_zh": "本文研究了多模态持续指令调优(MCIT)中的遗忘问题，将其分为表层遗忘和本质遗忘。表层遗忘指模型知识未真正丢失，但因后续任务影响导致对先前任务的回答格式偏离；本质遗忘指模型提供格式正确但内容错误的答案，表示知识的真正丧失。为了解决这些问题，作者提出了SEFE框架，首先引入答案风格多样化(ASD)范式，统一不同任务的数据风格以防止表层遗忘，然后提出RegLoRA，通过正则化稳定存储先前知识的关键参数，从而减轻本质遗忘。实验结果表明，SEFE方法在MCIT任务上取得了state-of-the-art的性能。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02486v1",
      "published_date": "2025-05-05 09:09:41 UTC",
      "updated_date": "2025-05-05 09:09:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:23:48.688333"
    },
    {
      "arxiv_id": "2505.02485v1",
      "title": "Integrating Column Generation and Large Neighborhood Search for Bus Driver Scheduling with Complex Break Constraints",
      "title_zh": "集成列生成和大邻域搜索，解决具有复杂休息约束的公交车司机排班问题\n",
      "authors": [
        "Lucas Kletzander",
        "Tommaso Mannelli Mazzoli",
        "Nysret Musliu",
        "Pascal Van Hentenryck"
      ],
      "abstract": "The Bus Driver Scheduling Problem (BDSP) is a combinatorial optimization\nproblem with the goal to design shifts to cover prearranged bus tours. The\nobjective takes into account the operational cost as well as the satisfaction\nof drivers. This problem is heavily constrained due to strict legal rules and\ncollective agreements. The objective of this article is to provide\nstate-of-the-art exact and hybrid solution methods that can provide\nhigh-quality solutions for instances of different sizes. This work presents a\ncomprehensive study of both an exact method, Branch and Price (B&P), as well as\na Large Neighborhood Search (LNS) framework which uses B&P or Column Generation\n(CG) for the repair phase to solve the BDSP. It further proposes and evaluates\na novel deeper integration of B&P and LNS, storing the generated columns from\nthe LNS subproblems and reusing them for other subproblems, or to find better\nglobal solutions. The article presents a detailed analysis of several\ncomponents of the solution methods and their impact, including general\nimprovements for the B&P subproblem, which is a high-dimensional Resource\nConstrained Shortest Path Problem (RCSPP), and the components of the LNS. The\nevaluation shows that our approach provides new state-of-the-art results for\ninstances of all sizes, including exact solutions for small instances, and low\ngaps to a known lower bound for mid-sized instances. Conclusions: We observe\nthat B&P provides the best results for small instances, while the tight\nintegration of LNS and CG can provide high-quality solutions for larger\ninstances, further improving over LNS which just uses CG as a black box. The\nproposed methods are general and can also be applied to other rule sets and\nrelated optimization problems",
      "tldr_zh": "本文研究了带有复杂休息约束的公交车司机排班问题(BDSP)，旨在设计满足运营成本和司机满意度的班次计划。针对该问题，文章提出了一种精确方法——分支定价(B&P)算法，以及一种使用B&P或列生成(CG)进行修复的大邻域搜索(LNS)框架。更进一步，文章提出了一种B&P和LNS的深度集成方法，存储LNS子问题中生成的列，并将其重用于其他子问题或寻找更好的全局解。实验结果表明，该方法在各种规模的实例上都取得了新的state-of-the-art结果，小规模实例可获得精确解，中等规模实例与已知下界的差距很小。结论表明，B&P在小规模实例上表现最佳，而LNS和CG的紧密集成可以为更大规模的实例提供高质量的解决方案。\n",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02485v1",
      "published_date": "2025-05-05 09:08:25 UTC",
      "updated_date": "2025-05-05 09:08:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:24:00.892154"
    },
    {
      "arxiv_id": "2505.02484v1",
      "title": "El Agente: An Autonomous Agent for Quantum Chemistry",
      "title_zh": "El Agente：用于量子化学的自主智能体\n",
      "authors": [
        "Yunheng Zou",
        "Austin H. Cheng",
        "Abdulrahman Aldossary",
        "Jiaru Bai",
        "Shi Xuan Leong",
        "Jorge Arturo Campos-Gonzalez-Angulo",
        "Changhyeok Choi",
        "Cher Tian Ser",
        "Gary Tom",
        "Andrew Wang",
        "Zijian Zhang",
        "Ilya Yakavets",
        "Han Hao",
        "Chris Crebolder",
        "Varinia Bernales",
        "Alán Aspuru-Guzik"
      ],
      "abstract": "Computational chemistry tools are widely used to study the behaviour of\nchemical phenomena. Yet, the complexity of these tools can make them\ninaccessible to non-specialists and challenging even for experts. In this work,\nwe introduce El Agente Q, an LLM-based multi-agent system that dynamically\ngenerates and executes quantum chemistry workflows from natural language user\nprompts. The system is built on a novel cognitive architecture featuring a\nhierarchical memory framework that enables flexible task decomposition,\nadaptive tool selection, post-analysis, and autonomous file handling and\nsubmission. El Agente Q is benchmarked on six university-level course exercises\nand two case studies, demonstrating robust problem-solving performance\n(averaging >87% task success) and adaptive error handling through in situ\ndebugging. It also supports longer-term, multi-step task execution for more\ncomplex workflows, while maintaining transparency through detailed action trace\nlogs. Together, these capabilities lay the foundation for increasingly\nautonomous and accessible quantum chemistry.",
      "tldr_zh": "该论文介绍了El Agente Q，一个基于LLM的多智能体系统，旨在实现量子化学的自动化。该系统能够根据自然语言提示动态生成和执行量子化学工作流程。其核心是一个新颖的认知架构，包含分层记忆框架，支持灵活的任务分解、自适应工具选择、后处理以及自主的文件处理和提交。在六个大学课程练习和两个案例研究中，El Agente Q表现出强大的问题解决能力（平均任务成功率>87%），并通过原位调试进行自适应错误处理。该系统还支持更长期的多步骤任务执行，并通过详细的行动轨迹日志保持透明性，为实现更自主和可访问的量子化学奠定了基础。\n",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "physics.chem-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02484v1",
      "published_date": "2025-05-05 09:07:22 UTC",
      "updated_date": "2025-05-05 09:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:24:12.695594"
    },
    {
      "arxiv_id": "2505.02483v1",
      "title": "Automated Hybrid Reward Scheduling via Large Language Models for Robotic Skill Learning",
      "title_zh": "基于大型语言模型的机器人技能学习自动化混合奖励调度",
      "authors": [
        "Changxin Huang",
        "Junyang Liang",
        "Yanbin Chang",
        "Jingzhao Xu",
        "Jianqiang Li"
      ],
      "abstract": "Enabling a high-degree-of-freedom robot to learn specific skills is a\nchallenging task due to the complexity of robotic dynamics. Reinforcement\nlearning (RL) has emerged as a promising solution; however, addressing such\nproblems requires the design of multiple reward functions to account for\nvarious constraints in robotic motion. Existing approaches typically sum all\nreward components indiscriminately to optimize the RL value function and\npolicy. We argue that this uniform inclusion of all reward components in policy\noptimization is inefficient and limits the robot's learning performance. To\naddress this, we propose an Automated Hybrid Reward Scheduling (AHRS) framework\nbased on Large Language Models (LLMs). This paradigm dynamically adjusts the\nlearning intensity of each reward component throughout the policy optimization\nprocess, enabling robots to acquire skills in a gradual and structured manner.\nSpecifically, we design a multi-branch value network, where each branch\ncorresponds to a distinct reward component. During policy optimization, each\nbranch is assigned a weight that reflects its importance, and these weights are\nautomatically computed based on rules designed by LLMs. The LLM generates a\nrule set in advance, derived from the task description, and during training, it\nselects a weight calculation rule from the library based on language prompts\nthat evaluate the performance of each branch. Experimental results demonstrate\nthat the AHRS method achieves an average 6.48% performance improvement across\nmultiple high-degree-of-freedom robotic tasks.",
      "tldr_zh": "该论文提出了一种基于大语言模型(LLM)的自动化混合奖励调度(AHRS)框架，旨在提升高自由度机器人技能学习的效率。AHRS通过动态调整不同奖励成分的学习强度，使机器人能够以渐进和结构化的方式掌握技能。该方法设计了一个多分支价值网络，每个分支对应一个奖励成分，并由LLM根据任务描述生成规则集，动态地为每个分支分配权重。实验结果表明，AHRS在多个高自由度机器人任务中实现了平均6.48%的性能提升。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02483v1",
      "published_date": "2025-05-05 09:06:17 UTC",
      "updated_date": "2025-05-05 09:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:24:24.505610"
    },
    {
      "arxiv_id": "2505.02467v1",
      "title": "Timing Is Everything: Finding the Optimal Fusion Points in Multimodal Medical Imaging",
      "title_zh": "时机就是一切：在多模态医学影像中寻找最佳融合点\n",
      "authors": [
        "Valerio Guarrasi",
        "Klara Mogensen",
        "Sara Tassinari",
        "Sara Qvarlander",
        "Paolo Soda"
      ],
      "abstract": "Multimodal deep learning harnesses diverse imaging modalities, such as MRI\nsequences, to enhance diagnostic accuracy in medical imaging. A key challenge\nis determining the optimal timing for integrating these\nmodalities-specifically, identifying the network layers where fusion modules\nshould be inserted. Current approaches often rely on manual tuning or\nexhaustive search, which are computationally expensive without any guarantee of\nconverging to optimal results. We propose a sequential forward search algorithm\nthat incrementally activates and evaluates candidate fusion modules at\ndifferent layers of a multimodal network. At each step, the algorithm retrains\nfrom previously learned weights and compares validation loss to identify the\nbest-performing configuration. This process systematically reduces the search\nspace, enabling efficient identification of the optimal fusion timing without\nexhaustively testing all possible module placements. The approach is validated\non two multimodal MRI datasets, each addressing different classification tasks.\nOur algorithm consistently identified configurations that outperformed unimodal\nbaselines, late fusion, and a brute-force ensemble of all potential fusion\nplacements. These architectures demonstrated superior accuracy, F-score, and\nspecificity while maintaining competitive or improved AUC values. Furthermore,\nthe sequential nature of the search significantly reduced computational\noverhead, making the optimization process more practical. By systematically\ndetermining the optimal timing to fuse imaging modalities, our method advances\nmultimodal deep learning for medical imaging. It provides an efficient and\nrobust framework for fusion optimization, paving the way for improved clinical\ndecision-making and more adaptable, scalable architectures in medical AI\napplications.",
      "tldr_zh": "该研究提出了一种用于多模态医学影像深度学习中，寻找最佳融合点的序列前向搜索算法。该算法通过逐步激活和评估多模态网络不同层的候选融合模块，并基于验证损失选择最佳配置，从而系统地减少搜索空间。实验在两个多模态MRI数据集上验证了该算法的有效性，结果表明，该算法找到的配置优于单模态基线、晚期融合以及所有潜在融合位置的暴力集成。该方法在提高准确率、F-score和特异性的同时，保持了有竞争力的AUC值，并显著降低了计算开销，为医学影像多模态深度学习提供了一种高效且鲁棒的融合优化框架。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02467v1",
      "published_date": "2025-05-05 08:53:21 UTC",
      "updated_date": "2025-05-05 08:53:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:24:36.727394"
    },
    {
      "arxiv_id": "2505.02462v1",
      "title": "Incentivizing Inclusive Contributions in Model Sharing Markets",
      "title_zh": "激励模型共享市场中的包容性贡献\n",
      "authors": [
        "Enpei Zhang",
        "Jingyi Chai",
        "Rui Ye",
        "Yanfeng Wang",
        "Siheng Chen"
      ],
      "abstract": "While data plays a crucial role in training contemporary AI models, it is\nacknowledged that valuable public data will be exhausted in a few years,\ndirecting the world's attention towards the massive decentralized private data.\nHowever, the privacy-sensitive nature of raw data and lack of incentive\nmechanism prevent these valuable data from being fully exploited. Addressing\nthese challenges, this paper proposes inclusive and incentivized personalized\nfederated learning (iPFL), which incentivizes data holders with diverse\npurposes to collaboratively train personalized models without revealing raw\ndata. iPFL constructs a model-sharing market by solving a graph-based training\noptimization and incorporates an incentive mechanism based on game theory\nprinciples. Theoretical analysis shows that iPFL adheres to two key incentive\nproperties: individual rationality and truthfulness. Empirical studies on\neleven AI tasks (e.g., large language models' instruction-following tasks)\ndemonstrate that iPFL consistently achieves the highest economic utility, and\nbetter or comparable model performance compared to baseline methods. We\nanticipate that our iPFL can serve as a valuable technique for boosting future\nAI models on decentralized private data while making everyone satisfied.",
      "tldr_zh": "该论文提出了一种包容性的激励个性化联邦学习框架(iPFL)，旨在解决去中心化私有数据难以被充分利用的问题。iPFL通过构建基于图的训练优化模型共享市场，并结合博弈论原理的激励机制，激励具有不同目的的数据持有者在不泄露原始数据的情况下协同训练个性化模型。理论分析表明，iPFL满足个体理性和真实性两个关键激励属性。在11项AI任务（例如，大型语言模型的指令跟随任务）上的实证研究表明，与基线方法相比，iPFL始终实现最高的经济效用，并获得更好或相当的模型性能。该研究为未来在去中心化私有数据上提升AI模型性能提供了一种有价值的技术，并能使各方满意。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02462v1",
      "published_date": "2025-05-05 08:45:26 UTC",
      "updated_date": "2025-05-05 08:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:24:48.841254"
    },
    {
      "arxiv_id": "2505.02443v1",
      "title": "Investigating the Impact of Personalized AI Tutors on Language Learning Performance",
      "title_zh": "个性化 AI 导师对语言学习效果的影响研究",
      "authors": [
        "Simon Suh"
      ],
      "abstract": "Driven by the global shift towards online learning prompted by the COVID 19\npandemic, Artificial Intelligence has emerged as a pivotal player in the field\nof education. Intelligent Tutoring Systems offer a new method of personalized\nteaching, replacing the limitations of traditional teaching methods. However,\nconcerns arise about the ability of AI tutors to address skill development and\nengagement during the learning process. In this paper, I will conduct a quasi\nexperiment with paired sample t test on 34 students pre and post use of AI\ntutors in language learning platforms like Santa and Duolingo to examine the\nrelationship between students engagement, academic performance, and students\nsatisfaction during a personalized language learning experience.",
      "tldr_zh": "本研究探讨了个性化AI辅导对语言学习效果的影响。通过对34名学生在使用Santa和Duolingo等语言学习平台前后进行准实验和配对样本t检验，考察了学生参与度、学业表现和满意度之间的关系。研究旨在评估AI辅导在提升语言学习过程中的技能发展和学习投入方面的能力。\n",
      "categories": [
        "cs.AI",
        "cs.HC",
        "I.2.6; K.3.1"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 4 figures, 1 table, Uses three theoretical frameworks like\n  Domain modeling, Gardner Theory of Multiple Intelligences, and Zone of\n  Proximal Development",
      "pdf_url": "http://arxiv.org/pdf/2505.02443v1",
      "published_date": "2025-05-05 08:11:20 UTC",
      "updated_date": "2025-05-05 08:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:25:00.301263"
    },
    {
      "arxiv_id": "2505.02441v1",
      "title": "MSFNet-CPD: Multi-Scale Cross-Modal Fusion Network for Crop Pest Detection",
      "title_zh": "MSFNet-CPD：用于作物病虫害检测的多尺度跨模态融合网络\n",
      "authors": [
        "Jiaqi Zhang",
        "Zhuodong Liu",
        "Kejian Yu"
      ],
      "abstract": "Accurate identification of agricultural pests is essential for crop\nprotection but remains challenging due to the large intra-class variance and\nfine-grained differences among pest species. While deep learning has advanced\npest detection, most existing approaches rely solely on low-level visual\nfeatures and lack effective multi-modal integration, leading to limited\naccuracy and poor interpretability. Moreover, the scarcity of high-quality\nmulti-modal agricultural datasets further restricts progress in this field. To\naddress these issues, we construct two novel multi-modal benchmarks-CTIP102 and\nSTIP102-based on the widely-used IP102 dataset, and introduce a Multi-scale\nCross-Modal Fusion Network (MSFNet-CPD) for robust pest detection. Our approach\nenhances visual quality via a super-resolution reconstruction module, and feeds\nboth the original and reconstructed images into the network to improve clarity\nand detection performance. To better exploit semantic cues, we propose an\nImage-Text Fusion (ITF) module for joint modeling of visual and textual\nfeatures, and an Image-Text Converter (ITC) that reconstructs fine-grained\ndetails across multiple scales to handle challenging backgrounds. Furthermore,\nwe introduce an Arbitrary Combination Image Enhancement (ACIE) strategy to\ngenerate a more complex and diverse pest detection dataset, MTIP102, improving\nthe model's generalization to real-world scenarios. Extensive experiments\ndemonstrate that MSFNet-CPD consistently outperforms state-of-the-art methods\non multiple pest detection benchmarks. All code and datasets will be made\npublicly available at: https://github.com/Healer-ML/MSFNet-CPD.",
      "tldr_zh": "该论文针对农作物病虫害检测中类内差异大和细粒度差异等挑战，提出了多尺度跨模态融合网络(MSFNet-CPD)。该网络通过超分辨率重建模块增强图像质量，并利用图像-文本融合(ITF)模块联合建模视觉和文本特征。同时，引入图像-文本转换器(ITC)重建多尺度细粒度细节以应对复杂背景。此外，论文构建了CTIP102和STIP102两个多模态基准数据集，并提出了任意组合图像增强(ACIE)策略生成更复杂的MTIP102数据集，以提高模型泛化能力。实验结果表明，MSFNet-CPD在多个病虫害检测基准上优于现有方法。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02441v1",
      "published_date": "2025-05-05 08:10:22 UTC",
      "updated_date": "2025-05-05 08:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:25:12.797039"
    },
    {
      "arxiv_id": "2505.02439v1",
      "title": "ReeM: Ensemble Building Thermodynamics Model for Efficient HVAC Control via Hierarchical Reinforcement Learning",
      "title_zh": "ReeM：基于集成构建热力学模型的分层强化学习高效暖通空调控制\n",
      "authors": [
        "Yang Deng",
        "Yaohui Liu",
        "Rui Liang",
        "Dafang Zhao",
        "Donghua Xie",
        "Ittetsu Taniguchi",
        "Dan Wang"
      ],
      "abstract": "The building thermodynamics model, which predicts real-time indoor\ntemperature changes under potential HVAC (Heating, Ventilation, and Air\nConditioning) control operations, is crucial for optimizing HVAC control in\nbuildings. While pioneering studies have attempted to develop such models for\nvarious building environments, these models often require extensive data\ncollection periods and rely heavily on expert knowledge, making the modeling\nprocess inefficient and limiting the reusability of the models. This paper\nexplores a model ensemble perspective that utilizes existing developed models\nas base models to serve a target building environment, thereby providing\naccurate predictions while reducing the associated efforts. Given that building\ndata streams are non-stationary and the number of base models may increase, we\npropose a Hierarchical Reinforcement Learning (HRL) approach to dynamically\nselect and weight the base models. Our approach employs a two-tiered\ndecision-making process: the high-level focuses on model selection, while the\nlow-level determines the weights of the selected models. We thoroughly evaluate\nthe proposed approach through offline experiments and an on-site case study,\nand the experimental results demonstrate the effectiveness of our method.",
      "tldr_zh": "该论文提出了一种名为ReeM的集成建筑热力学模型，用于通过分层强化学习(Hierarchical Reinforcement Learning, HRL)实现高效的暖通空调(Heating, Ventilation, and Air Conditioning, HVAC)控制。ReeM利用现有的模型作为基础模型，服务于目标建筑环境，从而提供准确的预测并减少相关工作量。针对建筑数据流的非平稳性和基础模型数量增加的问题，论文采用HRL方法动态选择和加权基础模型。HRL包含一个两层决策过程：高层侧重于模型选择，低层确定所选模型的权重。离线实验和现场案例研究表明，该方法是有效的。\n",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02439v1",
      "published_date": "2025-05-05 08:09:36 UTC",
      "updated_date": "2025-05-05 08:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:25:24.647976"
    },
    {
      "arxiv_id": "2505.02435v1",
      "title": "A New Approach to Backtracking Counterfactual Explanations: A Causal Framework for Efficient Model Interpretability",
      "title_zh": "一种新的回溯反事实解释方法：用于高效模型可解释性的因果框架\n",
      "authors": [
        "Pouria Fatemi",
        "Ehsan Sharifian",
        "Mohammad Hossein Yassaee"
      ],
      "abstract": "Counterfactual explanations enhance interpretability by identifying\nalternative inputs that produce different outputs, offering localized insights\ninto model decisions. However, traditional methods often neglect causal\nrelationships, leading to unrealistic examples. While newer approaches\nintegrate causality, they are computationally expensive. To address these\nchallenges, we propose an efficient method based on backtracking\ncounterfactuals that incorporates causal reasoning to generate actionable\nexplanations. We first examine the limitations of existing methods and then\nintroduce our novel approach and its features. We also explore the relationship\nbetween our method and previous techniques, demonstrating that it generalizes\nthem in specific scenarios. Finally, experiments show that our method provides\ndeeper insights into model outputs.",
      "tldr_zh": "该论文提出了一种新的回溯反事实解释方法，旨在提高模型的可解释性。现有反事实解释方法忽略因果关系，导致生成不切实际的解释，而考虑因果关系的方法计算成本高。该方法通过结合因果推理生成可执行的解释，克服了上述挑战。该方法不仅效率高，而且能够提供对模型输出更深入的理解，并在特定场景下推广了先前的技术。实验结果验证了该方法能够提供对模型输出的更深入的理解。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02435v1",
      "published_date": "2025-05-05 08:01:56 UTC",
      "updated_date": "2025-05-05 08:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:25:36.510453"
    },
    {
      "arxiv_id": "2505.02433v1",
      "title": "FairPO: Robust Preference Optimization for Fair Multi-Label Learning",
      "title_zh": "FairPO：用于公平多标签学习的鲁棒偏好优化",
      "authors": [
        "Soumen Kumar Mondal",
        "Akshit Varmora",
        "Prateek Chanda",
        "Ganesh Ramakrishnan"
      ],
      "abstract": "We propose FairPO, a novel framework designed to promote fairness in\nmulti-label classification by directly optimizing preference signals with a\ngroup robustness perspective. In our framework, the set of labels is\npartitioned into privileged and non-privileged groups, and a preference-based\nloss inspired by Direct Preference Optimization (DPO) is employed to more\neffectively differentiate true positive labels from confusing negatives within\nthe privileged group, while preserving baseline classification performance for\nnon-privileged labels. By framing the learning problem as a robust optimization\nover groups, our approach dynamically adjusts the training emphasis toward\ngroups with poorer performance, thereby mitigating bias and ensuring a fairer\ntreatment across diverse label categories. In addition, we outline plans to\nextend this approach by investigating alternative loss formulations such as\nSimple Preference Optimisation (SimPO) and Contrastive Preference Optimization\n(CPO) to exploit reference-free reward formulations and contrastive training\nsignals. Furthermore, we plan to extend FairPO with multilabel generation\ncapabilities, enabling the model to dynamically generate diverse and coherent\nlabel sets for ambiguous inputs.",
      "tldr_zh": "该论文提出了FairPO，一个用于公平多标签学习的新框架，旨在通过从群体鲁棒性的角度直接优化偏好信号来提升公平性。FairPO将标签集划分为特权组和非特权组，并采用受直接偏好优化(DPO)启发的基于偏好的损失函数，更有效地将特权组中的真正例标签与易混淆的负例区分开来，同时保持非特权标签的基线分类性能。通过将学习问题构建为基于群体的鲁棒优化，FairPO动态调整对表现较差群体的训练侧重，从而减轻偏差并确保对不同标签类别的更公平对待。研究还计划探索Simple Preference Optimisation (SimPO)和Contrastive Preference Optimization (CPO)等替代损失函数，并扩展FairPO的多标签生成能力。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02433v1",
      "published_date": "2025-05-05 07:58:54 UTC",
      "updated_date": "2025-05-05 07:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:25:48.937896"
    },
    {
      "arxiv_id": "2505.02426v1",
      "title": "Towards One-shot Federated Learning: Advances, Challenges, and Future Directions",
      "title_zh": "迈向单次联邦学习：进展、挑战与未来方向\n",
      "authors": [
        "Flora Amato",
        "Lingyu Qiu",
        "Mohammad Tanveer",
        "Salvatore Cuomo",
        "Fabio Giampaolo",
        "Francesco Piccialli"
      ],
      "abstract": "One-shot FL enables collaborative training in a single round, eliminating the\nneed for iterative communication, making it particularly suitable for use in\nresource-constrained and privacy-sensitive applications. This survey offers a\nthorough examination of One-shot FL, highlighting its distinct operational\nframework compared to traditional federated approaches. One-shot FL supports\nresource-limited devices by enabling single-round model aggregation while\nmaintaining data locality. The survey systematically categorizes existing\nmethodologies, emphasizing advancements in client model initialization,\naggregation techniques, and strategies for managing heterogeneous data\ndistributions. Furthermore, we analyze the limitations of current approaches,\nparticularly in terms of scalability and generalization in non-IID settings. By\nanalyzing cutting-edge techniques and outlining open challenges, this survey\naspires to provide a comprehensive reference for researchers and practitioners\naiming to design and implement One-shot FL systems, advancing the development\nand adoption of One-shot FL solutions in a real-world, resource-constrained\nscenario.",
      "tldr_zh": "本文全面综述了单次联邦学习(One-shot FL)的最新进展、挑战和未来方向。与传统联邦学习相比，One-shot FL仅需一轮通信即可完成协同训练，适用于资源受限和隐私敏感的应用。该综述系统地对现有方法进行分类，重点关注客户端模型初始化、聚合技术以及处理异构数据分布的策略的改进。同时，分析了当前方法在可扩展性和非独立同分布(non-IID)环境下的泛化能力方面的局限性。本文旨在为研究人员和实践者提供参考，以设计和实施One-shot FL系统，推动One-shot FL解决方案在实际资源受限场景中的发展和应用。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02426v1",
      "published_date": "2025-05-05 07:46:21 UTC",
      "updated_date": "2025-05-05 07:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:26:00.720568"
    },
    {
      "arxiv_id": "2505.02417v1",
      "title": "T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models",
      "title_zh": "T2S：基于文本到序列扩散模型的高分辨率时间序列生成\n",
      "authors": [
        "Yunfeng Ge",
        "Jiawei Li",
        "Yiji Zhao",
        "Haomin Wen",
        "Zhao Li",
        "Meikang Qiu",
        "Hongyan Li",
        "Ming Jin",
        "Shirui Pan"
      ],
      "abstract": "Text-to-Time Series generation holds significant potential to address\nchallenges such as data sparsity, imbalance, and limited availability of\nmultimodal time series datasets across domains. While diffusion models have\nachieved remarkable success in Text-to-X (e.g., vision and audio data)\ngeneration, their use in time series generation remains in its nascent stages.\nExisting approaches face two critical limitations: (1) the lack of systematic\nexploration of general-proposed time series captions, which are often\ndomain-specific and struggle with generalization; and (2) the inability to\ngenerate time series of arbitrary lengths, limiting their applicability to\nreal-world scenarios. In this work, we first categorize time series captions\ninto three levels: point-level, fragment-level, and instance-level.\nAdditionally, we introduce a new fragment-level dataset containing over 600,000\nhigh-resolution time series-text pairs. Second, we propose Text-to-Series\n(T2S), a diffusion-based framework that bridges the gap between natural\nlanguage and time series in a domain-agnostic manner. T2S employs a\nlength-adaptive variational autoencoder to encode time series of varying\nlengths into consistent latent embeddings. On top of that, T2S effectively\naligns textual representations with latent embeddings by utilizing Flow\nMatching and employing Diffusion Transformer as the denoiser. We train T2S in\nan interleaved paradigm across multiple lengths, allowing it to generate\nsequences of any desired length. Extensive evaluations demonstrate that T2S\nachieves state-of-the-art performance across 13 datasets spanning 12 domains.",
      "tldr_zh": "本文提出了Text-to-Series (T2S)，一种基于扩散模型的文本到时间序列生成框架，旨在解决时间序列数据稀疏、不平衡以及多模态数据有限的问题。T2S通过长度自适应的变分自编码器(variational autoencoder)将不同长度的时间序列编码成一致的潜在嵌入，并利用Flow Matching和Diffusion Transformer将文本表示与潜在嵌入对齐。该研究对时间序列的描述进行了分类，并提出了一个包含超过60万个高分辨率时间序列-文本对的新数据集。实验结果表明，T2S在跨越12个领域的13个数据集上实现了最先进的性能，能够生成任意长度的时间序列。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.02417v1",
      "published_date": "2025-05-05 07:22:54 UTC",
      "updated_date": "2025-05-05 07:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:26:12.736590"
    },
    {
      "arxiv_id": "2505.02413v1",
      "title": "Task-Oriented Semantic Communication in Large Multimodal Models-based Vehicle Networks",
      "title_zh": "基于大型多模态模型的车辆网络中的面向任务的语义通信\n",
      "authors": [
        "Baoxia Du",
        "Hongyang Du",
        "Dusit Niyato",
        "Ruidong Li"
      ],
      "abstract": "Task-oriented semantic communication has emerged as a fundamental approach\nfor enhancing performance in various communication scenarios. While recent\nadvances in Generative Artificial Intelligence (GenAI), such as Large Language\nModels (LLMs), have been applied to semantic communication designs, the\npotential of Large Multimodal Models (LMMs) remains largely unexplored. In this\npaper, we investigate an LMM-based vehicle AI assistant using a Large Language\nand Vision Assistant (LLaVA) and propose a task-oriented semantic communication\nframework to facilitate efficient interaction between users and cloud servers.\nTo reduce computational demands and shorten response time, we optimize LLaVA's\nimage slicing to selectively focus on areas of utmost interest to users.\nAdditionally, we assess the importance of image patches by combining objective\nand subjective user attention, adjusting energy usage for transmitting semantic\ninformation. This strategy optimizes resource utilization, ensuring precise\ntransmission of critical information. We construct a Visual Question Answering\n(VQA) dataset for traffic scenarios to evaluate effectiveness. Experimental\nresults show that our semantic communication framework significantly increases\naccuracy in answering questions under the same channel conditions, performing\nparticularly well in environments with poor Signal-to-Noise Ratios (SNR).\nAccuracy can be improved by 13.4% at an SNR of 12dB and 33.1% at 10dB,\nrespectively.",
      "tldr_zh": "本文提出了一种基于大型多模态模型(LMM)的面向任务的语义通信框架，用于车辆网络中的车辆AI助手。该框架利用大型语言和视觉助手(LLaVA)促进用户与云服务器之间的有效交互。为了降低计算需求和缩短响应时间，研究优化了LLaVA的图像切片，选择性地关注用户最感兴趣的区域。此外，通过结合客观和主观用户注意力评估图像块的重要性，调整能量使用以传输语义信息，从而优化资源利用率。通过构建交通场景的视觉问答(VQA)数据集进行评估，实验结果表明，在相同信道条件下，该语义通信框架显著提高了回答问题的准确性，尤其是在信噪比(SNR)较差的环境中，在12dB的SNR下准确率提高了13.4%，在10dB的SNR下提高了33.1%。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02413v1",
      "published_date": "2025-05-05 07:18:47 UTC",
      "updated_date": "2025-05-05 07:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:26:24.905113"
    },
    {
      "arxiv_id": "2505.02410v1",
      "title": "Bielik 11B v2 Technical Report",
      "title_zh": "Bielik 11B v2 技术报告\n",
      "authors": [
        "Krzysztof Ociepa",
        "Łukasz Flis",
        "Krzysztof Wróbel",
        "Adrian Gwoździej",
        "Remigiusz Kinas"
      ],
      "abstract": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages.",
      "tldr_zh": "本文介绍了Bielik 11B v2，一个专为波兰语文本处理优化的先进语言模型。该模型基于Mistral 7B v0.2架构，通过深度扩展至110亿参数，在波兰语基准测试中表现出色，并保持了强大的跨语言能力。研究引入了两项关键技术创新：加权指令交叉熵损失(Weighted Instruction Cross-Entropy Loss)，通过为训练样本分配基于质量的权重来优化跨不同指令类型的学习；以及自适应学习率(Adaptive Learning Rate)，根据上下文长度动态调整学习率。实验结果表明，Bielik 11B v2优于许多更大的模型，包括参数量是其2-6倍的模型，并在从语言理解到复杂推理的任务中显著超越了其他专门的波兰语语言模型。该模型的参数效率和广泛的量化选项使其能够在各种硬件配置上部署，从而推进了波兰语AI能力，并为资源效率型语言建模在较少代表性语言中建立了新的基准。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02410v1",
      "published_date": "2025-05-05 07:03:41 UTC",
      "updated_date": "2025-05-05 07:03:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:26:37.094168"
    },
    {
      "arxiv_id": "2505.02396v1",
      "title": "Diagnostic Uncertainty in Pneumonia Detection using CNN MobileNetV2 and CNN from Scratch",
      "title_zh": "基于 CNN MobileNetV2 和从零开始构建的 CNN 的肺炎检测诊断不确定性研究\n",
      "authors": [
        "Kennard Norbert Sudiardjo",
        "Islam Nur Alam",
        "Wilson Wijaya",
        "Lili Ayu Wulandhari"
      ],
      "abstract": "Pneumonia Diagnosis, though it is crucial for an effective treatment, it can\nbe hampered by uncertainty. This uncertainty starts to arise due to some\nfactors like atypical presentations, limitations of diagnostic tools such as\nchest X-rays, and the presence of co-existing respiratory conditions. This\nresearch proposes one of the supervised learning methods, CNN. Using\nMobileNetV2 as the pre-trained one with ResNet101V2 architecture and using\nKeras API as the built from scratch model, for identifying lung diseases\nespecially pneumonia. The datasets used in this research were obtained from the\nwebsite through Kaggle. The result shows that by implementing CNN MobileNetV2\nand CNN from scratch the result is promising. While validating data,\nMobileNetV2 performs with stability and minimal overfitting, while the training\naccuracy increased to 84.87% later it slightly decreased to 78.95%, with\nincreasing validation loss from 0.499 to 0.6345. Nonetheless, MobileNetV2 is\nmore stable. Although it takes more time to train each epoch. Meanwhile, after\nthe 10th epoch, the Scratch model displayed more instability and overfitting\ndespite having higher validation accuracy, training accuracy decreased\nsignificantly to 78.12% and the validation loss increased from 0.5698 to\n1.1809. With these results, ResNet101V2 offers stability, and the Scratch model\noffers high accuracy.",
      "tldr_zh": "该研究探讨了肺炎诊断中的不确定性，并提出使用卷积神经网络(CNN)进行辅助诊断。研究采用了MobileNetV2（预训练模型，基于ResNet101V2架构）和Keras API构建的CNN模型（从零开始训练）来识别包括肺炎在内的肺部疾病。实验结果表明，MobileNetV2在验证数据上表现出更好的稳定性和更少的过拟合，但训练时间较长；而从零开始训练的CNN模型虽然验证准确率较高，但在训练后期表现出不稳定性和过拟合现象。总的来说，ResNet101V2架构的MobileNetV2提供了更好的稳定性，而从零开始构建的模型提供了更高的准确率。\n",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02396v1",
      "published_date": "2025-05-05 06:40:08 UTC",
      "updated_date": "2025-05-05 06:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:26:49.007507"
    },
    {
      "arxiv_id": "2505.02391v1",
      "title": "Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL",
      "title_zh": "通过拒绝采样和强化学习中的梯度方差最小化来优化链式思维推理器\n",
      "authors": [
        "Jiarui Yao",
        "Yifan Hao",
        "Hanning Zhang",
        "Hanze Dong",
        "Wei Xiong",
        "Nan Jiang",
        "Tong Zhang"
      ],
      "abstract": "Chain-of-thought (CoT) reasoning in large language models (LLMs) can be\nformalized as a latent variable problem, where the model needs to generate\nintermediate reasoning steps. While prior approaches such as iterative\nreward-ranked fine-tuning (RAFT) have relied on such formulations, they\ntypically apply uniform inference budgets across prompts, which fails to\naccount for variability in difficulty and convergence behavior. This work\nidentifies the main bottleneck in CoT training as inefficient stochastic\ngradient estimation due to static sampling strategies. We propose GVM-RAFT, a\nprompt-specific Dynamic Sample Allocation Strategy designed to minimize\nstochastic gradient variance under a computational budget constraint. The\nmethod dynamically allocates computational resources by monitoring prompt\nacceptance rates and stochastic gradient norms, ensuring that the resulting\ngradient variance is minimized. Our theoretical analysis shows that the\nproposed dynamic sampling strategy leads to accelerated convergence guarantees\nunder suitable conditions. Experiments on mathematical reasoning show that\nGVM-RAFT achieves a 2-4x speedup and considerable accuracy improvements over\nvanilla RAFT. The proposed dynamic sampling strategy is general and can be\nincorporated into other reinforcement learning algorithms, such as GRPO,\nleading to similar improvements in convergence and test accuracy. Our code is\navailable at https://github.com/RLHFlow/GVM.",
      "tldr_zh": "该论文将大语言模型中的链式思考(CoT)推理形式化为一个隐变量问题，并指出CoT训练的主要瓶颈在于静态采样策略导致的随机梯度估计效率低下。为此，论文提出了GVM-RAFT，一种prompt特定的动态样本分配策略，旨在计算预算约束下最小化随机梯度方差。GVM-RAFT通过监控prompt接受率和随机梯度范数动态分配计算资源，从而最小化梯度方差。理论分析表明，该动态采样策略在特定条件下可以加速收敛。在数学推理实验中，GVM-RAFT相比于RAFT实现了2-4倍的加速和显著的精度提升。该动态采样策略具有通用性，可以被整合到其他强化学习算法中，例如GRPO，并带来类似的收敛和测试精度提升。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02391v1",
      "published_date": "2025-05-05 06:26:00 UTC",
      "updated_date": "2025-05-05 06:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:27:00.999578"
    },
    {
      "arxiv_id": "2505.02390v1",
      "title": "Quantitative Analysis of Performance Drop in DeepSeek Model Quantization",
      "title_zh": "DeepSeek 模型量化性能下降的定量分析\n",
      "authors": [
        "Enbo Zhao",
        "Yi Shen",
        "Shuming Shi",
        "Jieyun Huang",
        "Zhihao Chen",
        "Ning Wang",
        "Siqi Xiao",
        "Jian Zhang",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "Recently, there is a high demand for deploying DeepSeek-R1 and V3 locally,\npossibly because the official service often suffers from being busy and some\norganizations have data privacy concerns. While single-machine deployment\noffers infrastructure simplicity, the models' 671B FP8 parameter configuration\nexceeds the practical memory limits of a standard 8-GPU machine. Quantization\nis a widely used technique that helps reduce model memory consumption. However,\nit is unclear what the performance of DeepSeek-R1 and V3 will be after being\nquantized. This technical report presents the first quantitative evaluation of\nmulti-bitwidth quantization across the complete DeepSeek model spectrum. Key\nfindings reveal that 4-bit quantization maintains little performance\ndegradation versus FP8 while enabling single-machine deployment on standard\nNVIDIA GPU devices. We further propose DQ3_K_M, a dynamic 3-bit quantization\nmethod that significantly outperforms traditional Q3_K_M variant on various\nbenchmarks, which is also comparable with 4-bit quantization (Q4_K_M) approach\nin most tasks. Moreover, DQ3_K_M supports single-machine deployment\nconfigurations for both NVIDIA H100/A100 and Huawei 910B. Our implementation of\nDQ3\\_K\\_M is released at https://github.com/UnicomAI/DeepSeek-Eval, containing\noptimized 3-bit quantized variants of both DeepSeek-R1 and DeepSeek-V3.",
      "tldr_zh": "该技术报告对DeepSeek系列模型（R1和V3）在量化后的性能下降进行了定量分析，旨在解决模型本地部署的需求。研究发现，4比特量化在保持较小性能损失的前提下，能够使模型在标准NVIDIA GPU设备上进行单机部署。此外，报告提出了一种动态3比特量化方法DQ3_K_M，该方法在多个基准测试中显著优于传统的Q3_K_M，并在大多数任务中与4比特量化(Q4_K_M)方法相当。DQ3_K_M同时支持NVIDIA H100/A100和华为910B的单机部署配置。研究团队已发布了DQ3_K_M的实现代码，其中包含DeepSeek-R1和DeepSeek-V3的优化3比特量化版本。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02390v1",
      "published_date": "2025-05-05 06:25:20 UTC",
      "updated_date": "2025-05-05 06:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:27:12.922712"
    },
    {
      "arxiv_id": "2505.02388v1",
      "title": "MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans",
      "title_zh": "MetaScenes：迈向真实世界 3D 扫描的自动化副本创建\n",
      "authors": [
        "Huangyue Yu",
        "Baoxiong Jia",
        "Yixin Chen",
        "Yandan Yang",
        "Puhao Li",
        "Rongpeng Su",
        "Jiaxin Li",
        "Qing Li",
        "Wei Liang",
        "Song-Chun Zhu",
        "Tengyu Liu",
        "Siyuan Huang"
      ],
      "abstract": "Embodied AI (EAI) research requires high-quality, diverse 3D scenes to\neffectively support skill acquisition, sim-to-real transfer, and\ngeneralization. Achieving these quality standards, however, necessitates the\nprecise replication of real-world object diversity. Existing datasets\ndemonstrate that this process heavily relies on artist-driven designs, which\ndemand substantial human effort and present significant scalability challenges.\nTo scalably produce realistic and interactive 3D scenes, we first present\nMetaScenes, a large-scale, simulatable 3D scene dataset constructed from\nreal-world scans, which includes 15366 objects spanning 831 fine-grained\ncategories. Then, we introduce Scan2Sim, a robust multi-modal alignment model,\nwhich enables the automated, high-quality replacement of assets, thereby\neliminating the reliance on artist-driven designs for scaling 3D scenes. We\nfurther propose two benchmarks to evaluate MetaScenes: a detailed scene\nsynthesis task focused on small item layouts for robotic manipulation and a\ndomain transfer task in vision-and-language navigation (VLN) to validate\ncross-domain transfer. Results confirm MetaScene's potential to enhance EAI by\nsupporting more generalizable agent learning and sim-to-real applications,\nintroducing new possibilities for EAI research. Project website:\nhttps://meta-scenes.github.io/.",
      "tldr_zh": "该论文提出了MetaScenes，一个大规模、可模拟的3D场景数据集，它由真实世界的扫描数据构建而成，包含15366个物体，涵盖831个细粒度类别。为了实现真实场景的自动复制，作者还提出了Scan2Sim，一个鲁棒的多模态对齐模型，能够自动且高质量地替换资源，从而避免依赖人工设计来扩展3D场景。此外，论文还提出了两个基准测试来评估MetaScenes：一个关注机器人操作的小物件布局的详细场景合成任务，以及一个用于验证跨域迁移的视觉语言导航(VLN)中的域迁移任务。实验结果表明，MetaScenes有潜力通过支持更通用的智能体学习和sim-to-real应用来增强具身智能(EAI)，为EAI研究引入新的可能性。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02388v1",
      "published_date": "2025-05-05 06:13:25 UTC",
      "updated_date": "2025-05-05 06:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:27:25.148640"
    },
    {
      "arxiv_id": "2505.02387v1",
      "title": "RM-R1: Reward Modeling as Reasoning",
      "title_zh": "RM-R1：将奖励建模作为推理",
      "authors": [
        "Xiusi Chen",
        "Gaotang Li",
        "Ziqi Wang",
        "Bowen Jin",
        "Cheng Qian",
        "Yu Wang",
        "Hongru Wang",
        "Yu Zhang",
        "Denghui Zhang",
        "Tong Zhang",
        "Hanghang Tong",
        "Heng Ji"
      ],
      "abstract": "Reward modeling is essential for aligning large language models (LLMs) with\nhuman preferences, especially through reinforcement learning from human\nfeedback (RLHF). To provide accurate reward signals, a reward model (RM) should\nstimulate deep thinking and conduct interpretable reasoning before assigning a\nscore or a judgment. However, existing RMs either produce opaque scalar scores\nor directly generate the prediction of a preferred answer, making them struggle\nto integrate natural language critiques, thus lacking interpretability.\nInspired by recent advances of long chain-of-thought (CoT) on\nreasoning-intensive tasks, we hypothesize and validate that integrating\nreasoning capabilities into reward modeling significantly enhances RM's\ninterpretability and performance. In this work, we introduce a new class of\ngenerative reward models -- Reasoning Reward Models (ReasRMs) -- which\nformulate reward modeling as a reasoning task. We propose a reasoning-oriented\ntraining pipeline and train a family of ReasRMs, RM-R1. The training consists\nof two key stages: (1) distillation of high-quality reasoning chains and (2)\nreinforcement learning with verifiable rewards. RM-R1 improves LLM rollouts by\nself-generating reasoning traces or chat-specific rubrics and evaluating\ncandidate responses against them. Empirically, our models achieve\nstate-of-the-art or near state-of-the-art performance of generative RMs across\nmultiple comprehensive reward model benchmarks, outperforming much larger\nopen-weight models (e.g., Llama3.1-405B) and proprietary ones (e.g., GPT-4o) by\nup to 13.8%. Beyond final performance, we perform thorough empirical analysis\nto understand the key ingredients of successful ReasRM training. To facilitate\nfuture research, we release six ReasRM models along with code and data at\nhttps://github.com/RM-R1-UIUC/RM-R1.",
      "tldr_zh": "该论文提出了一种新的生成式奖励模型框架——推理奖励模型(ReasRM)，旨在通过将奖励建模视为一个推理任务，提升奖励模型(RM)的可解释性和性能。ReasRM通过生成推理链或特定聊天规则，并根据这些规则评估候选回复，从而改进大型语言模型(LLM)的输出。该研究提出了一个面向推理的训练流程，并训练了一系列ReasRM模型，命名为RM-R1。实验结果表明，RM-R1在多个奖励模型基准测试中达到了最先进或接近最先进的性能，甚至优于更大的开源模型(如Llama3.1-405B)和专有模型(如GPT-4o)。该研究还发布了六个ReasRM模型以及代码和数据，以促进未来的研究。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02387v1",
      "published_date": "2025-05-05 06:11:12 UTC",
      "updated_date": "2025-05-05 06:11:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:27:36.983110"
    },
    {
      "arxiv_id": "2505.02370v1",
      "title": "SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing",
      "title_zh": "SuperEdit：校正并促进基于指令的图像编辑的监督\n",
      "authors": [
        "Ming Li",
        "Xin Gu",
        "Fan Chen",
        "Xiaoying Xing",
        "Longyin Wen",
        "Chen Chen",
        "Sijie Zhu"
      ],
      "abstract": "Due to the challenges of manually collecting accurate editing data, existing\ndatasets are typically constructed using various automated methods, leading to\nnoisy supervision signals caused by the mismatch between editing instructions\nand original-edited image pairs. Recent efforts attempt to improve editing\nmodels through generating higher-quality edited images, pre-training on\nrecognition tasks, or introducing vision-language models (VLMs) but fail to\nresolve this fundamental issue. In this paper, we offer a novel solution by\nconstructing more effective editing instructions for given image pairs. This\nincludes rectifying the editing instructions to better align with the\noriginal-edited image pairs and using contrastive editing instructions to\nfurther enhance their effectiveness. Specifically, we find that editing models\nexhibit specific generation attributes at different inference steps,\nindependent of the text. Based on these prior attributes, we define a unified\nguide for VLMs to rectify editing instructions. However, there are some\nchallenging editing scenarios that cannot be resolved solely with rectified\ninstructions. To this end, we further construct contrastive supervision signals\nwith positive and negative instructions and introduce them into the model\ntraining using triplet loss, thereby further facilitating supervision\neffectiveness. Our method does not require the VLM modules or pre-training\ntasks used in previous work, offering a more direct and efficient way to\nprovide better supervision signals, and providing a novel, simple, and\neffective solution for instruction-based image editing. Results on multiple\nbenchmarks demonstrate that our method significantly outperforms existing\napproaches. Compared with previous SOTA SmartEdit, we achieve 9.19%\nimprovements on the Real-Edit benchmark with 30x less training data and 13x\nsmaller model size.",
      "tldr_zh": "该论文提出了一种名为SuperEdit的新方法，旨在通过改进图像编辑指令来提升基于指令的图像编辑模型的性能，从而解决现有数据集因自动构建导致的指令与图像不匹配问题。SuperEdit通过修正编辑指令使其与原始-编辑图像对更对齐，并利用对比编辑指令增强其有效性。该方法利用视觉语言模型(VLM)的先验属性来修正编辑指令，并构建包含正负指令的对比监督信号，通过Triplet Loss引入模型训练，从而提高监督有效性。实验结果表明，SuperEdit在多个基准测试中显著优于现有方法，例如在Real-Edit基准测试中，相比之前的SOTA SmartEdit，在更少的数据和更小的模型下取得了9.19%的提升。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code, Data and Models are available at:\n  https://github.com/bytedance/SuperEdit",
      "pdf_url": "http://arxiv.org/pdf/2505.02370v1",
      "published_date": "2025-05-05 05:19:40 UTC",
      "updated_date": "2025-05-05 05:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:27:49.092006"
    },
    {
      "arxiv_id": "2505.02369v2",
      "title": "Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks",
      "title_zh": "用于神经网络的 Z-score 梯度滤波的锐度感知最小化\n",
      "authors": [
        "Juyoung Yun"
      ],
      "abstract": "Generalizing well in deep neural networks remains a core challenge,\nparticularly due to their tendency to converge to sharp minima that degrade\nrobustness. Sharpness-Aware Minimization (SAM) mitigates this by seeking\nflatter minima but perturbs parameters using the full gradient, which can\ninclude statistically insignificant directions. We propose ZSharp, a simple yet\neffective extension to SAM that applies layer-wise Z-score normalization\nfollowed by percentile-based filtering to retain only statistically significant\ngradient components. This selective perturbation aligns updates with\ncurvature-sensitive directions, enhancing generalization without requiring\narchitectural changes. ZSharp introduces only one additional hyperparameter,\nthe percentile threshold, and remains fully compatible with existing SAM\nvariants. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet using ResNet,\nVGG, and Vision Transformers show that ZSharp consistently outperforms SAM and\nits variants in test accuracy, particularly on deeper and transformer-based\nmodels. These results demonstrate that ZSharp is a principled and lightweight\nimprovement for sharpness-aware optimization.",
      "tldr_zh": "这篇论文提出了一种名为ZSharp的SAM(Sharpness-Aware Minimization)改进方法，旨在提升深度神经网络的泛化能力。ZSharp通过层级的Z-score标准化和基于百分比的过滤，只保留统计上显著的梯度分量，从而更精确地调整参数扰动方向，使其与曲率敏感的方向对齐。实验结果表明，在CIFAR-10、CIFAR-100和Tiny-ImageNet数据集上，使用ResNet、VGG和Vision Transformers等模型时，ZSharp在测试精度上始终优于SAM及其变体，尤其是在更深层和基于Transformer的模型上。ZSharp只需引入一个额外的超参数，即百分比阈值，即可实现对SAM的有效改进。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "cs.NE",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02369v2",
      "published_date": "2025-05-05 05:13:12 UTC",
      "updated_date": "2025-05-06 01:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:28:00.920541"
    },
    {
      "arxiv_id": "2505.02366v1",
      "title": "JTCSE: Joint Tensor-Modulus Constraints and Cross-Attention for Unsupervised Contrastive Learning of Sentence Embeddings",
      "title_zh": "JTCSE：联合张量模约束和交叉注意力用于句子嵌入的无监督对比学习\n",
      "authors": [
        "Tianyu Zong",
        "Hongzhu Yi",
        "Bingkang Shi",
        "Yuanxiang Wang",
        "Jungang Xu"
      ],
      "abstract": "Unsupervised contrastive learning has become a hot research topic in natural\nlanguage processing. Existing works usually aim at constraining the orientation\ndistribution of the representations of positive and negative samples in the\nhigh-dimensional semantic space in contrastive learning, but the semantic\nrepresentation tensor possesses both modulus and orientation features, and the\nexisting works ignore the modulus feature of the representations and cause\ninsufficient contrastive learning. % Therefore, we firstly propose a training\nobjective that aims at modulus constraints on the semantic representation\ntensor, to strengthen the alignment between the positive samples in contrastive\nlearning. Therefore, we first propose a training objective that is designed to\nimpose modulus constraints on the semantic representation tensor, to strengthen\nthe alignment between positive samples in contrastive learning. Then, the\nBERT-like model suffers from the phenomenon of sinking attention, leading to a\nlack of attention to CLS tokens that aggregate semantic information. In\nresponse, we propose a cross-attention structure among the twin-tower ensemble\nmodels to enhance the model's attention to CLS token and optimize the quality\nof CLS Pooling. Combining the above two motivations, we propose a new\n\\textbf{J}oint \\textbf{T}ensor representation modulus constraint and\n\\textbf{C}ross-attention unsupervised contrastive learning \\textbf{S}entence\n\\textbf{E}mbedding representation framework JTCSE, which we evaluate in seven\nsemantic text similarity computation tasks, and the experimental results show\nthat JTCSE's twin-tower ensemble model and single-tower distillation model\noutperform the other baselines and become the current SOTA. In addition, we\nhave conducted an extensive zero-shot downstream task evaluation, which shows\nthat JTCSE outperforms other baselines overall on more than 130 tasks.",
      "tldr_zh": "该论文提出了一种新的无监督对比学习框架JTCSE，用于提升句子嵌入的质量。JTCSE的核心在于两个方面：首先，它引入了张量模量约束(Tensor-Modulus Constraints)的目标函数，以加强对比学习中正样本之间语义表示的对齐。其次，针对BERT类模型中存在的注意力沉没问题，JTCSE设计了一种跨注意力结构(Cross-Attention)，增强模型对CLS token的关注，从而优化CLS Pooling的效果。实验结果表明，JTCSE在语义文本相似度计算和零样本下游任务中均取得了SOTA表现，验证了其有效性。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02366v1",
      "published_date": "2025-05-05 05:09:21 UTC",
      "updated_date": "2025-05-05 05:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:28:12.807461"
    },
    {
      "arxiv_id": "2505.02362v1",
      "title": "Advancing Email Spam Detection: Leveraging Zero-Shot Learning and Large Language Models",
      "title_zh": "推进电子邮件垃圾邮件检测：利用零样本学习和大型语言模型\n",
      "authors": [
        "Ghazaleh SHirvani",
        "Saeid Ghasemshirazi"
      ],
      "abstract": "Email spam detection is a critical task in modern communication systems,\nessential for maintaining productivity, security, and user experience.\nTraditional machine learning and deep learning approaches, while effective in\nstatic settings, face significant limitations in adapting to evolving spam\ntactics, addressing class imbalance, and managing data scarcity. These\nchallenges necessitate innovative approaches that reduce dependency on\nextensive labeled datasets and frequent retraining. This study investigates the\neffectiveness of Zero-Shot Learning using FLAN-T5, combined with advanced\nNatural Language Processing (NLP) techniques such as BERT for email spam\ndetection. By employing BERT to preprocess and extract critical information\nfrom email content, and FLAN-T5 to classify emails in a Zero-Shot framework,\nthe proposed approach aims to address the limitations of traditional spam\ndetection systems. The integration of FLAN-T5 and BERT enables robust spam\ndetection without relying on extensive labeled datasets or frequent retraining,\nmaking it highly adaptable to unseen spam patterns and adversarial\nenvironments. This research highlights the potential of leveraging zero-shot\nlearning and NLPs for scalable and efficient spam detection, providing insights\ninto their capability to address the dynamic and challenging nature of spam\ndetection tasks.",
      "tldr_zh": "该研究探索了利用零样本学习和大型语言模型(LLMs)来改进电子邮件垃圾邮件检测的方法。传统方法在适应不断变化的垃圾邮件策略、处理类别不平衡和数据稀缺方面存在局限性。该研究结合BERT进行预处理和信息提取，以及FLAN-T5在零样本框架下进行分类，旨在解决传统垃圾邮件检测系统的局限性。实验表明，这种集成方法无需依赖大量标记数据集或频繁的重新训练，即可实现强大的垃圾邮件检测，并能适应未知的垃圾邮件模式和对抗环境。该研究突出了利用零样本学习和NLP进行可扩展和高效的垃圾邮件检测的潜力。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02362v1",
      "published_date": "2025-05-05 04:48:20 UTC",
      "updated_date": "2025-05-05 04:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:28:24.895307"
    },
    {
      "arxiv_id": "2505.02360v1",
      "title": "Catastrophic Overfitting, Entropy Gap and Participation Ratio: A Noiseless $l^p$ Norm Solution for Fast Adversarial Training",
      "title_zh": "灾难性过拟合、熵差和参与率：一种用于快速对抗训练的无噪声 $l^p$ 范数解决方案\n",
      "authors": [
        "Fares B. Mehouachi",
        "Saif Eddin Jabari"
      ],
      "abstract": "Adversarial training is a cornerstone of robust deep learning, but fast\nmethods like the Fast Gradient Sign Method (FGSM) often suffer from\nCatastrophic Overfitting (CO), where models become robust to single-step\nattacks but fail against multi-step variants. While existing solutions rely on\nnoise injection, regularization, or gradient clipping, we propose a novel\nsolution that purely controls the $l^p$ training norm to mitigate CO.\n  Our study is motivated by the empirical observation that CO is more prevalent\nunder the $l^{\\infty}$ norm than the $l^2$ norm. Leveraging this insight, we\ndevelop a framework for generalized $l^p$ attack as a fixed point problem and\ncraft $l^p$-FGSM attacks to understand the transition mechanics from $l^2$ to\n$l^{\\infty}$. This leads to our core insight: CO emerges when highly\nconcentrated gradients where information localizes in few dimensions interact\nwith aggressive norm constraints. By quantifying gradient concentration through\nParticipation Ratio and entropy measures, we develop an adaptive $l^p$-FGSM\nthat automatically tunes the training norm based on gradient information.\nExtensive experiments demonstrate that this approach achieves strong robustness\nwithout requiring additional regularization or noise injection, providing a\nnovel and theoretically-principled pathway to mitigate the CO problem.",
      "tldr_zh": "该论文提出了一种新颖的基于控制 $l^p$ 训练范数的快速对抗训练方法，旨在解决快速梯度符号法(FGSM)中常见的灾难性过拟合(Catastrophic Overfitting, CO)问题。研究发现CO在高浓度梯度下更容易出现，信息集中在少数维度中。通过引入参与率(Participation Ratio)和熵度量来量化梯度集中度，作者开发了一种自适应 $l^p$-FGSM，可以根据梯度信息自动调整训练范数。实验结果表明，该方法在无需额外正则化或噪声注入的情况下，实现了强大的鲁棒性，为缓解CO问题提供了一种新的理论方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02360v1",
      "published_date": "2025-05-05 04:41:21 UTC",
      "updated_date": "2025-05-05 04:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:28:36.916635"
    },
    {
      "arxiv_id": "2505.02352v1",
      "title": "Social Biases in Knowledge Representations of Wikidata separates Global North from Global South",
      "title_zh": "Wikidata知识表示中的社会偏见将全球北方与全球南方区分开来\n",
      "authors": [
        "Paramita Das",
        "Sai Keerthana Karnam",
        "Aditya Soni",
        "Animesh Mukherjee"
      ],
      "abstract": "Knowledge Graphs have become increasingly popular due to their wide usage in\nvarious downstream applications, including information retrieval, chatbot\ndevelopment, language model construction, and many others. Link prediction (LP)\nis a crucial downstream task for knowledge graphs, as it helps to address the\nproblem of the incompleteness of the knowledge graphs. However, previous\nresearch has shown that knowledge graphs, often created in a (semi) automatic\nmanner, are not free from social biases. These biases can have harmful effects\non downstream applications, especially by leading to unfair behavior toward\nminority groups. To understand this issue in detail, we develop a framework --\nAuditLP -- deploying fairness metrics to identify biased outcomes in LP,\nspecifically how occupations are classified as either male or female-dominated\nbased on gender as a sensitive attribute. We have experimented with the\nsensitive attribute of age and observed that occupations are categorized as\nyoung-biased, old-biased, and age-neutral. We conduct our experiments on a\nlarge number of knowledge triples that belong to 21 different geographies\nextracted from the open-sourced knowledge graph, Wikidata. Our study shows that\nthe variance in the biased outcomes across geographies neatly mirrors the\nsocio-economic and cultural division of the world, resulting in a transparent\npartition of the Global North from the Global South.",
      "tldr_zh": "该研究探讨了知识图谱（Knowledge Graphs）中存在的社会偏见，特别是这些偏见如何影响链接预测（Link Prediction）任务，并导致对不同群体的歧视。研究者提出了一个名为AuditLP的框架，利用公平性指标来识别链接预测中的偏见，例如基于性别将职业归类为男性或女性主导，或基于年龄将职业归类为年轻或年老偏向。通过对从Wikidata提取的21个不同地理区域的大量知识三元组进行实验，研究发现这些偏见在不同地区的差异反映了世界社会经济和文化的分裂，从而将全球北方和全球南方明显区分开来。这项研究揭示了知识图谱中社会偏见的存在及其地域性差异。\n",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.02352v1",
      "published_date": "2025-05-05 04:21:12 UTC",
      "updated_date": "2025-05-05 04:21:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:28:49.085003"
    },
    {
      "arxiv_id": "2505.02347v1",
      "title": "Temporal Robustness in Discrete Time Linear Dynamical Systems",
      "title_zh": "离散时间线性动态系统中的时间鲁棒性\n",
      "authors": [
        "Nilava Metya",
        "Arunesh Sinha"
      ],
      "abstract": "Discrete time linear dynamical systems, including Markov chains, have found\nmany applications. However, in some problems, there is uncertainty about the\ntime horizon for which the system runs. This creates uncertainty about the cost\n(or reward) incurred based on the state distribution when the system stops.\nGiven past data samples of how long a system ran, we propose to theoretically\nanalyze a distributional robust cost estimation task in a Wasserstein ambiguity\nset, instead of learning a probability distribution from a few samples. Towards\nthis, we show an equivalence between a discrete time Markov Chain on a\nprobability simplex and a global asymptotic stable (GAS) discrete time linear\ndynamical system, allowing us to base our study on a GAS system only. Then, we\nprovide various polynomial time algorithms and hardness results for different\ncases in our theoretical study, including a fundamental result about\nWasserstein distance based polytope.",
      "tldr_zh": "该论文研究了离散时间线性动力系统（包括马尔可夫链）在时间范围不确定性下的鲁棒性问题，即系统运行时间的不确定性导致成本或奖励的不确定性。作者没有直接从少量样本中学习概率分布，而是提出在基于 Wasserstein 距离的模糊集上进行分布鲁棒的成本估计。论文证明了概率单纯形上的离散时间马尔可夫链与全局渐近稳定(GAS)的离散时间线性动力系统之间的等价性，从而将研究重点放在 GAS 系统上。论文针对不同的情况提供了多项式时间算法和硬度结果，并提出了关于基于 Wasserstein 距离的多面体的基本结果。\n",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02347v1",
      "published_date": "2025-05-05 04:02:33 UTC",
      "updated_date": "2025-05-05 04:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:29:01.030301"
    },
    {
      "arxiv_id": "2505.02322v1",
      "title": "HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking",
      "title_zh": "HyperTree Planning：通过分层思维增强 LLM 推理能力\n",
      "authors": [
        "Runquan Gui",
        "Zhihai Wang",
        "Jie Wang",
        "Chi Ma",
        "Huiling Zhen",
        "Mingxuan Yuan",
        "Jianye Hao",
        "Defu Lian",
        "Enhong Chen",
        "Feng Wu"
      ],
      "abstract": "Recent advancements have significantly enhanced the performance of large\nlanguage models (LLMs) in tackling complex reasoning tasks, achieving notable\nsuccess in domains like mathematical and logical reasoning. However, these\nmethods encounter challenges with complex planning tasks, primarily due to\nextended reasoning steps, diverse constraints, and the challenge of handling\nmultiple distinct sub-tasks. To address these challenges, we propose HyperTree\nPlanning (HTP), a novel reasoning paradigm that constructs hypertree-structured\nplanning outlines for effective planning. The hypertree structure enables LLMs\nto engage in hierarchical thinking by flexibly employing the divide-and-conquer\nstrategy, effectively breaking down intricate reasoning steps, accommodating\ndiverse constraints, and managing multiple distinct sub-tasks in a\nwell-organized manner. We further introduce an autonomous planning framework\nthat completes the planning process by iteratively refining and expanding the\nhypertree-structured planning outlines. Experiments demonstrate the\neffectiveness of HTP, achieving state-of-the-art accuracy on the TravelPlanner\nbenchmark with Gemini-1.5-Pro, resulting in a 3.6 times performance improvement\nover o1-preview.",
      "tldr_zh": "该论文提出了HyperTree Planning (HTP)，一种新的推理范式，通过构建超树结构的规划大纲来增强LLM在复杂规划任务中的推理能力。HTP使LLM能够通过灵活地使用分而治之的策略进行分层思考，有效地分解复杂的推理步骤，适应不同的约束，并以有组织的方式管理多个不同的子任务。此外，论文还介绍了一个自主规划框架，通过迭代地细化和扩展超树结构的规划大纲来完成规划过程。实验结果表明，HTP在TravelPlanner基准测试中达到了最先进的精度，使用Gemini-1.5-Pro相比o1-preview性能提高了3.6倍。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2406.14228 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2505.02322v1",
      "published_date": "2025-05-05 02:38:58 UTC",
      "updated_date": "2025-05-05 02:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:29:12.893994"
    },
    {
      "arxiv_id": "2505.02314v1",
      "title": "NeuroSim V1.5: Improved Software Backbone for Benchmarking Compute-in-Memory Accelerators with Device and Circuit-level Non-idealities",
      "title_zh": "NeuroSim V1.5：改进的软件主干，用于基准测试具有器件和电路级非理想性的存内计算加速器\n",
      "authors": [
        "James Read",
        "Ming-Yen Lee",
        "Wei-Hsing Huang",
        "Yuan-Chun Luo",
        "Anni Lu",
        "Shimeng Yu"
      ],
      "abstract": "The exponential growth of artificial intelligence (AI) applications has\nexposed the inefficiency of conventional von Neumann architectures, where\nfrequent data transfers between compute units and memory create significant\nenergy and latency bottlenecks. Analog Computing-in-Memory (ACIM) addresses\nthis challenge by performing multiply-accumulate (MAC) operations directly in\nthe memory arrays, substantially reducing data movement. However, designing\nrobust ACIM accelerators requires accurate modeling of device- and\ncircuit-level non-idealities. In this work, we present NeuroSim V1.5,\nintroducing several key advances: (1) seamless integration with TensorRT's\npost-training quantization flow enabling support for more neural networks\nincluding transformers, (2) a flexible noise injection methodology built on\npre-characterized statistical models, making it straightforward to incorporate\ndata from SPICE simulations or silicon measurements, (3) expanded device\nsupport including emerging non-volatile capacitive memories, and (4) up to 6.5x\nfaster runtime than NeuroSim V1.4 through optimized behavioral simulation. The\ncombination of these capabilities uniquely enables systematic design space\nexploration across both accuracy and hardware efficiency metrics. Through\nmultiple case studies, we demonstrate optimization of critical design\nparameters while maintaining network accuracy. By bridging high-fidelity noise\nmodeling with efficient simulation, NeuroSim V1.5 advances the design and\nvalidation of next-generation ACIM accelerators. All NeuroSim versions are\navailable open-source at https://github.com/neurosim/NeuroSim.",
      "tldr_zh": "NeuroSim V1.5是一个用于评估存内计算(Compute-in-Memory, CIM)加速器的软件平台，它改进了对器件和电路非理想性的建模。该版本的主要更新包括：(1)与TensorRT的后训练量化流程无缝集成，支持更多神经网络，包括Transformer；(2)基于统计模型的灵活噪声注入方法，易于整合SPICE仿真或硅片测量数据；(3)扩展的器件支持，包括新兴的非易失性容性存储器；(4)通过优化行为仿真，运行速度比NeuroSim V1.4快6.5倍。NeuroSim V1.5通过高保真噪声建模和高效仿真，能够系统地探索设计空间，优化关键设计参数，同时保持网络精度，从而推进下一代ACIM加速器的设计和验证。该工具已开源。\n",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "15 pages, 9 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.02314v1",
      "published_date": "2025-05-05 02:07:04 UTC",
      "updated_date": "2025-05-05 02:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:29:25.110860"
    },
    {
      "arxiv_id": "2505.02313v1",
      "title": "What Is AI Safety? What Do We Want It to Be?",
      "title_zh": "什么是 AI 安全？我们希望它成为什么？\n",
      "authors": [
        "Jacqueline Harding",
        "Cameron Domenico Kirk-Giannini"
      ],
      "abstract": "The field of AI safety seeks to prevent or reduce the harms caused by AI\nsystems. A simple and appealing account of what is distinctive of AI safety as\na field holds that this feature is constitutive: a research project falls\nwithin the purview of AI safety just in case it aims to prevent or reduce the\nharms caused by AI systems. Call this appealingly simple account The Safety\nConception of AI safety. Despite its simplicity and appeal, we argue that The\nSafety Conception is in tension with at least two trends in the ways AI safety\nresearchers and organizations think and talk about AI safety: first, a tendency\nto characterize the goal of AI safety research in terms of catastrophic risks\nfrom future systems; second, the increasingly popular idea that AI safety can\nbe thought of as a branch of safety engineering. Adopting the methodology of\nconceptual engineering, we argue that these trends are unfortunate: when we\nconsider what concept of AI safety it would be best to have, there are\ncompelling reasons to think that The Safety Conception is the answer.\nDescriptively, The Safety Conception allows us to see how work on topics that\nhave historically been treated as central to the field of AI safety is\ncontinuous with work on topics that have historically been treated as more\nmarginal, like bias, misinformation, and privacy. Normatively, taking The\nSafety Conception seriously means approaching all efforts to prevent or\nmitigate harms from AI systems based on their merits rather than drawing\narbitrary distinctions between them.",
      "tldr_zh": "本文探讨了“什么是AI安全？”以及我们希望它成为什么。文章指出，AI安全领域旨在预防或减少AI系统造成的危害。一个简单的观点认为，AI安全研究的独特之处在于其旨在预防或减少AI系统造成的危害，称之为“AI安全的安全性概念”。然而，这种观点与AI安全研究中将目标定义为未来系统的灾难性风险以及将AI安全视为安全工程分支的趋势相悖。文章通过概念工程的方法，论证了“AI安全的安全性概念”更优，因为它能够将历史上被认为是AI安全核心的主题与边缘主题（如偏见、虚假信息和隐私）联系起来，并促使我们根据优劣来评估所有预防或减轻AI系统危害的努力，而不是进行任意区分。\n",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02313v1",
      "published_date": "2025-05-05 01:55:00 UTC",
      "updated_date": "2025-05-05 01:55:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:29:37.108654"
    },
    {
      "arxiv_id": "2505.02309v1",
      "title": "Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques",
      "title_zh": "优化资源受限环境下的 LLM：模型压缩技术综述\n",
      "authors": [
        "Sanjay Surendranath Girija",
        "Shashank Kapoor",
        "Lakshit Arora",
        "Dipen Pradhan",
        "Aman Raj",
        "Ankit Shetgaonkar"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized many areas of artificial\nintelligence (AI), but their substantial resource requirements limit their\ndeployment on mobile and edge devices. This survey paper provides a\ncomprehensive overview of techniques for compressing LLMs to enable efficient\ninference in resource-constrained environments. We examine three primary\napproaches: Knowledge Distillation, Model Quantization, and Model Pruning. For\neach technique, we discuss the underlying principles, present different\nvariants, and provide examples of successful applications. We also briefly\ndiscuss complementary techniques such as mixture-of-experts and early-exit\nstrategies. Finally, we highlight promising future directions, aiming to\nprovide a valuable resource for both researchers and practitioners seeking to\noptimize LLMs for edge deployment.",
      "tldr_zh": "这篇综述论文全面概述了用于压缩大型语言模型(LLMs)的技术，旨在使其能够在资源受限的环境中高效推理。论文考察了三种主要方法：知识蒸馏(Knowledge Distillation)、模型量化(Model Quantization)和模型剪枝(Model Pruning)。针对每种技术，论文讨论了其基本原理、不同的变体以及成功的应用案例。此外，还简要讨论了混合专家模型(Mixture-of-Experts)和提前退出策略(Early-Exit Strategies)等补充技术。最后，论文强调了有前景的未来方向，旨在为寻求优化LLMs以进行边缘部署的研究人员和从业人员提供有价值的资源。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE COMPSAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02309v1",
      "published_date": "2025-05-05 01:27:47 UTC",
      "updated_date": "2025-05-05 01:27:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:29:48.818748"
    },
    {
      "arxiv_id": "2505.02306v1",
      "title": "SafeMate: A Model Context Protocol-Based Multimodal Agent for Emergency Preparedness",
      "title_zh": "SafeMate：一种基于模型上下文协议的用于应急准备的多模态智能体\n",
      "authors": [
        "Junfeng Jiao",
        "Jihyung Park",
        "Yiming Xu",
        "Lucy Atkinson"
      ],
      "abstract": "Despite the abundance of public safety documents and emergency protocols,\nmost individuals remain ill-equipped to interpret and act on such information\nduring crises. Traditional emergency decision support systems (EDSS) are\ndesigned for professionals and rely heavily on static documents like PDFs or\nSOPs, which are difficult for non-experts to navigate under stress. This gap\nbetween institutional knowledge and public accessibility poses a critical\nbarrier to effective emergency preparedness and response.\n  We introduce SafeMate, a retrieval-augmented AI assistant that delivers\naccurate, context-aware guidance to general users in both preparedness and\nactive emergency scenarios. Built on the Model Context Protocol (MCP), SafeMate\ndynamically routes user queries to tools for document retrieval, checklist\ngeneration, and structured summarization. It uses FAISS with cosine similarity\nto identify relevant content from trusted sources.",
      "tldr_zh": "SafeMate是一个基于模型上下文协议(Model Context Protocol, MCP)的多模态智能体，旨在为普通用户提供准确、上下文相关的应急准备和应对指导。它利用检索增强的AI助手，通过FAISS和余弦相似度从可信来源识别相关内容，并将用户查询动态路由到文档检索、清单生成和结构化摘要等工具。SafeMate旨在弥合机构知识和公众可访问性之间的差距，提高应急准备和响应的效率。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02306v1",
      "published_date": "2025-05-05 01:09:02 UTC",
      "updated_date": "2025-05-05 01:09:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:30:00.674893"
    },
    {
      "arxiv_id": "2505.02299v1",
      "title": "Adaptive Scoring and Thresholding with Human Feedback for Robust Out-of-Distribution Detection",
      "title_zh": "基于人类反馈的自适应评分和阈值设定，实现稳健的分布外检测\n",
      "authors": [
        "Daisuke Yamada",
        "Harit Vishwakarma",
        "Ramya Korlakai Vinayak"
      ],
      "abstract": "Machine Learning (ML) models are trained on in-distribution (ID) data but\noften encounter out-of-distribution (OOD) inputs during deployment -- posing\nserious risks in safety-critical domains. Recent works have focused on\ndesigning scoring functions to quantify OOD uncertainty, with score thresholds\ntypically set based solely on ID data to achieve a target true positive rate\n(TPR), since OOD data is limited before deployment. However, these TPR-based\nthresholds leave false positive rates (FPR) uncontrolled, often resulting in\nhigh FPRs where OOD points are misclassified as ID. Moreover, fixed scoring\nfunctions and thresholds lack the adaptivity needed to handle newly observed,\nevolving OOD inputs, leading to sub-optimal performance. To address these\nchallenges, we propose a human-in-the-loop framework that \\emph{safely updates\nboth scoring functions and thresholds on the fly} based on real-world OOD\ninputs. Our method maximizes TPR while strictly controlling FPR at all times,\neven as the system adapts over time. We provide theoretical guarantees for FPR\ncontrol under stationary conditions and present extensive empirical evaluations\non OpenOOD benchmarks to demonstrate that our approach outperforms existing\nmethods by achieving higher TPRs while maintaining FPR control.",
      "tldr_zh": "该论文提出了一种基于人工反馈的自适应评分和阈值方法，用于提高OOD（Out-of-Distribution）检测的鲁棒性。该方法旨在解决现有方法中基于ID（In-Distribution）数据设置阈值导致FPR（False Positive Rate）不可控以及固定评分函数和阈值缺乏适应性的问题。该框架通过人工反馈实时更新评分函数和阈值，在严格控制FPR的同时最大化TPR（True Positive Rate）。理论分析保证了在稳定条件下FPR的控制，实验结果表明该方法在OpenOOD基准测试中优于现有方法，实现了更高的TPR并保持了FPR的控制。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02299v1",
      "published_date": "2025-05-05 00:25:14 UTC",
      "updated_date": "2025-05-05 00:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-07T02:30:13.080398"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 73,
  "processed_papers_count": 73,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-07T02:31:46.124603"
}