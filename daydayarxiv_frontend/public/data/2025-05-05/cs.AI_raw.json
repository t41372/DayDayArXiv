[
  {
    "arxiv_id": "2505.02829v1",
    "title": "LISAT: Language-Instructed Segmentation Assistant for Satellite Imagery",
    "authors": [
      "Jerome Quenum",
      "Wen-Han Hsieh",
      "Tsung-Han Wu",
      "Ritwik Gupta",
      "Trevor Darrell",
      "David M. Chan"
    ],
    "abstract": "Segmentation models can recognize a pre-defined set of objects in images.\nHowever, models that can reason over complex user queries that implicitly refer\nto multiple objects of interest are still in their infancy. Recent advances in\nreasoning segmentation--generating segmentation masks from complex, implicit\nquery text--demonstrate that vision-language models can operate across an open\ndomain and produce reasonable outputs. However, our experiments show that such\nmodels struggle with complex remote-sensing imagery. In this work, we introduce\nLISAt, a vision-language model designed to describe complex remote-sensing\nscenes, answer questions about them, and segment objects of interest. We\ntrained LISAt on a new curated geospatial reasoning-segmentation dataset, GRES,\nwith 27,615 annotations over 9,205 images, and a multimodal pretraining\ndataset, PreGRES, containing over 1 million question-answer pairs. LISAt\noutperforms existing geospatial foundation models such as RS-GPT4V by over\n10.04 % (BLEU-4) on remote-sensing description tasks, and surpasses\nstate-of-the-art open-domain models on reasoning segmentation tasks by 143.36 %\n(gIoU). Our model, datasets, and code are available at\nhttps://lisat-bair.github.io/LISAt/",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 10 figures, 19 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.02829v1",
    "published_date": "2025-05-05 17:56:25 UTC",
    "updated_date": "2025-05-05 17:56:25 UTC"
  },
  {
    "arxiv_id": "2505.02828v1",
    "title": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review",
    "authors": [
      "Sonal Allana",
      "Mohan Kankanhalli",
      "Rozita Dara"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a pillar of\nTrustworthy AI and aims to bring transparency in complex models that are opaque\nby nature. Despite the benefits of incorporating explanations in models, an\nurgent need is found in addressing the privacy concerns of providing this\nadditional information to end users. In this article, we conduct a scoping\nreview of existing literature to elicit details on the conflict between privacy\nand explainability. Using the standard methodology for scoping review, we\nextracted 57 articles from 1,943 studies published from January 2019 to\nDecember 2024. The review addresses 3 research questions to present readers\nwith more understanding of the topic: (1) what are the privacy risks of\nreleasing explanations in AI systems? (2) what current methods have researchers\nemployed to achieve privacy preservation in XAI systems? (3) what constitutes a\nprivacy preserving explanation? Based on the knowledge synthesized from the\nselected studies, we categorize the privacy risks and preservation methods in\nXAI and propose the characteristics of privacy preserving explanations to aid\nresearchers and practitioners in understanding the requirements of XAI that is\nprivacy compliant. Lastly, we identify the challenges in balancing privacy with\nother system desiderata and provide recommendations for achieving privacy\npreserving XAI. We expect that this review will shed light on the complex\nrelationship of privacy and explainability, both being the fundamental\nprinciples of Trustworthy AI.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted for peer review",
    "pdf_url": "http://arxiv.org/pdf/2505.02828v1",
    "published_date": "2025-05-05 17:53:28 UTC",
    "updated_date": "2025-05-05 17:53:28 UTC"
  },
  {
    "arxiv_id": "2505.02824v1",
    "title": "Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models",
    "authors": [
      "Kuofeng Gao",
      "Yufei Zhu",
      "Yiming Li",
      "Jiawang Bai",
      "Yong Yang",
      "Zhifeng Li",
      "Shu-Tao Xia"
    ],
    "abstract": "Text-to-image (T2I) diffusion models have rapidly advanced, enabling\nhigh-quality image generation conditioned on textual prompts. However, the\ngrowing trend of fine-tuning pre-trained models for personalization raises\nserious concerns about unauthorized dataset usage. To combat this, dataset\nownership verification (DOV) has emerged as a solution, embedding watermarks\ninto the fine-tuning datasets using backdoor techniques. These watermarks\nremain inactive under benign samples but produce owner-specified outputs when\ntriggered. Despite the promise of DOV for T2I diffusion models, its robustness\nagainst copyright evasion attacks (CEA) remains unexplored. In this paper, we\nexplore how attackers can bypass these mechanisms through CEA, allowing models\nto circumvent watermarks even when trained on watermarked datasets. We propose\nthe first copyright evasion attack (i.e., CEAT2I) specifically designed to\nundermine DOV in T2I diffusion models. Concretely, our CEAT2I comprises three\nstages: watermarked sample detection, trigger identification, and efficient\nwatermark mitigation. A key insight driving our approach is that T2I models\nexhibit faster convergence on watermarked samples during the fine-tuning,\nevident through intermediate feature deviation. Leveraging this, CEAT2I can\nreliably detect the watermarked samples. Then, we iteratively ablate tokens\nfrom the prompts of detected watermarked samples and monitor shifts in\nintermediate features to pinpoint the exact trigger tokens. Finally, we adopt a\nclosed-form concept erasure method to remove the injected watermark. Extensive\nexperiments show that our CEAT2I effectively evades DOV mechanisms while\npreserving model performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02824v1",
    "published_date": "2025-05-05 17:51:55 UTC",
    "updated_date": "2025-05-05 17:51:55 UTC"
  },
  {
    "arxiv_id": "2505.02820v1",
    "title": "AutoLibra: Agent Metric Induction from Open-Ended Feedback",
    "authors": [
      "Hao Zhu",
      "Phil Cuvin",
      "Xinkai Yu",
      "Charlotte Ka Yee Yan",
      "Jason Zhang",
      "Diyi Yang"
    ],
    "abstract": "Agents are predominantly evaluated and optimized via task success metrics,\nwhich are coarse, rely on manual design from experts, and fail to reward\nintermediate emergent behaviors. We propose AutoLibra, a framework for agent\nevaluation, that transforms open-ended human feedback, e.g., \"If you find that\nthe button is disabled, don't click it again\", or \"This agent has too much\nautonomy to decide what to do on its own\", into metrics for evaluating\nfine-grained behaviors in agent trajectories. AutoLibra accomplishes this by\ngrounding feedback to an agent's behavior, clustering similar positive and\nnegative behaviors, and creating concrete metrics with clear definitions and\nconcrete examples, which can be used for prompting LLM-as-a-Judge as\nevaluators. We further propose two meta-metrics to evaluate the alignment of a\nset of (induced) metrics with open feedback: \"coverage\" and \"redundancy\".\nThrough optimizing these meta-metrics, we experimentally demonstrate\nAutoLibra's ability to induce more concrete agent evaluation metrics than the\nones proposed in previous agent evaluation benchmarks and discover new metrics\nto analyze agents. We also present two applications of AutoLibra in agent\nimprovement: First, we show that AutoLibra-induced metrics serve as better\nprompt-engineering targets than the task success rate on a wide range of text\ngame tasks, improving agent performance over baseline by a mean of 20%. Second,\nwe show that AutoLibra can iteratively select high-quality fine-tuning data for\nweb navigation agents. Our results suggest that AutoLibra is a powerful\ntask-agnostic tool for evaluating and improving language agents.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "https://opensocial.world/",
    "pdf_url": "http://arxiv.org/pdf/2505.02820v1",
    "published_date": "2025-05-05 17:47:49 UTC",
    "updated_date": "2025-05-05 17:47:49 UTC"
  },
  {
    "arxiv_id": "2505.02811v1",
    "title": "Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing",
    "authors": [
      "Diji Yang",
      "Linda Zeng",
      "Jinmeng Rao",
      "Yi Zhang"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has shown strong capability in enhancing\nlanguage models' knowledge and reducing AI generative hallucinations, driving\nits widespread use. However, complex tasks requiring multi-round retrieval\nremain challenging, and early attempts tend to be overly optimistic without a\ngood sense of self-skepticism. Current multi-round RAG systems may continue\nsearching even when enough information has already been retrieved, or they may\nprovide incorrect answers without having sufficient information or knowledge.\nExisting solutions either require large amounts of expensive human-labeled\nprocess supervision data or lead to subpar performance.\n  This paper aims to address these limitations by introducing a new framework,\n\\textbf{SIM-RAG}, to explicitly enhance RAG systems' self-awareness and\nmulti-round retrieval capabilities. To train SIM-RAG, we first let a RAG system\nself-practice multi-round retrieval, augmenting existing question-answer pairs\nwith intermediate inner monologue reasoning steps to generate synthetic\ntraining data. For each pair, the system may explore multiple retrieval paths,\nwhich are labeled as successful if they reach the correct answer and\nunsuccessful otherwise. Using this data, we train a lightweight information\nsufficiency Critic. At inference time, the Critic evaluates whether the RAG\nsystem has retrieved sufficient information at each round, guiding retrieval\ndecisions and improving system-level self-awareness through in-context\nreinforcement learning.\n  Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an\neffective multi-round RAG solution. Furthermore, this framework is\nsystem-efficient, adding a lightweight component to RAG without requiring\nmodifications to existing LLMs or search engines, and data-efficient,\neliminating the need for costly human-annotated mid-step retrieval process\nsupervision data.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Proceedings of the 48th International ACM SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02811v1",
    "published_date": "2025-05-05 17:39:35 UTC",
    "updated_date": "2025-05-05 17:39:35 UTC"
  },
  {
    "arxiv_id": "2505.02795v1",
    "title": "HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models",
    "authors": [
      "Zheng Lin",
      "Yuxin Zhang",
      "Zhe Chen",
      "Zihan Fang",
      "Xianhao Chen",
      "Praneeth Vepakomma",
      "Wei Ni",
      "Jun Luo",
      "Yue Gao"
    ],
    "abstract": "Recently, large language models (LLMs) have achieved remarkable\nbreakthroughs, revolutionizing the natural language processing domain and\nbeyond. Due to immense parameter sizes, fine-tuning these models with private\ndata for diverse downstream tasks has become mainstream. Though federated\nlearning (FL) offers a promising solution for fine-tuning LLMs without sharing\nraw data, substantial computing costs hinder its democratization. Moreover, in\nreal-world scenarios, private client devices often possess heterogeneous\ncomputing resources, further complicating LLM fine-tuning. To combat these\nchallenges, we propose HSplitLoRA, a heterogeneous parameter-efficient\nfine-tuning (PEFT) framework built on split learning (SL) and low-rank\nadaptation (LoRA) fine-tuning, for efficiently fine-tuning LLMs on\nheterogeneous client devices. HSplitLoRA first identifies important weights\nbased on their contributions to LLM training. It then dynamically configures\nthe decomposition ranks of LoRA adapters for selected weights and determines\nthe model split point according to varying computing budgets of client devices.\nFinally, a noise-free adapter aggregation mechanism is devised to support\nheterogeneous adapter aggregation without introducing noise. Extensive\nexperiments demonstrate that HSplitLoRA outperforms state-of-the-art benchmarks\nin training accuracy and convergence speed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02795v1",
    "published_date": "2025-05-05 17:09:19 UTC",
    "updated_date": "2025-05-05 17:09:19 UTC"
  },
  {
    "arxiv_id": "2505.02781v1",
    "title": "Local Markov Equivalence and Local Causal Discovery for Identifying Controlled Direct Effects",
    "authors": [
      "Timothée Loranchet",
      "Charles K. Assaad"
    ],
    "abstract": "Understanding and identifying controlled direct effects (CDEs) is crucial\nacross numerous scientific domains, including public health. While existing\nmethods can identify these effects from causal directed acyclic graphs (DAGs),\nthe true underlying structure is often unknown in practice. Essential graphs,\nwhich represent a Markov equivalence class of DAGs characterized by the same\nset of d-separations, provide a more practical and realistic alternative.\nHowever, learning the full essential graph is computationally intensive and\ntypically depends on strong, untestable assumptions. In this work, we\ncharacterize a local class of graphs, defined relative to a target variable,\nthat share a specific subset of d-separations, and introduce a graphical\nrepresentation of this class, called the local essential graph (LEG). We then\npresent LocPC, a novel algorithm designed to recover the LEG from an observed\ndistribution using only local conditional independence tests. Building on\nLocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG\nthat is sufficient to identify a CDE, bypassing the need of retrieving the full\nessential graph. Compared to global methods, our algorithms require less\nconditional independence tests and operate under weaker assumptions while\nmaintaining theoretical guarantees.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02781v1",
    "published_date": "2025-05-05 16:47:29 UTC",
    "updated_date": "2025-05-05 16:47:29 UTC"
  },
  {
    "arxiv_id": "2505.02780v1",
    "title": "Beyond the Monitor: Mixed Reality Visualization and AI for Enhanced Digital Pathology Workflow",
    "authors": [
      "Jai Prakash Veerla",
      "Partha Sai Guttikonda",
      "Helen H. Shang",
      "Mohammad Sadegh Nasr",
      "Cesar Torres",
      "Jacob M. Luber"
    ],
    "abstract": "Pathologists rely on gigapixel whole-slide images (WSIs) to diagnose diseases\nlike cancer, yet current digital pathology tools hinder diagnosis. The immense\nscale of WSIs, often exceeding 100,000 X 100,000 pixels, clashes with the\nlimited views traditional monitors offer. This mismatch forces constant panning\nand zooming, increasing pathologist cognitive load, causing diagnostic fatigue,\nand slowing pathologists' adoption of digital methods. PathVis, our\nmixed-reality visualization platform for Apple Vision Pro, addresses these\nchallenges. It transforms the pathologist's interaction with data, replacing\ncumbersome mouse-and-monitor navigation with intuitive exploration using\nnatural hand gestures, eye gaze, and voice commands in an immersive workspace.\nPathVis integrates AI to enhance diagnosis. An AI-driven search function\ninstantly retrieves and displays the top five similar patient cases\nside-by-side, improving diagnostic precision and efficiency through rapid\ncomparison. Additionally, a multimodal conversational AI assistant offers\nreal-time image interpretation support and aids collaboration among\npathologists across multiple Apple devices. By merging the directness of\ntraditional pathology with advanced mixed-reality visualization and AI, PathVis\nimproves diagnostic workflows, reduces cognitive strain, and makes pathology\npractice more effective and engaging. The PathVis source code and a demo video\nare publicly available at: https://github.com/jaiprakash1824/Path_Vis",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "q-bio.TO"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02780v1",
    "published_date": "2025-05-05 16:46:53 UTC",
    "updated_date": "2025-05-05 16:46:53 UTC"
  },
  {
    "arxiv_id": "2505.02766v1",
    "title": "Giving Simulated Cells a Voice: Evolving Prompt-to-Intervention Models for Cellular Control",
    "authors": [
      "Nam H. Le",
      "Patrick Erikson",
      "Yanbo Zhang",
      "Michael Levin",
      "Josh Bongard"
    ],
    "abstract": "Guiding biological systems toward desired states, such as morphogenetic\noutcomes, remains a fundamental challenge with far-reaching implications for\nmedicine and synthetic biology. While large language models (LLMs) have enabled\nnatural language as an interface for interpretable control in AI systems, their\nuse as mediators for steering biological or cellular dynamics remains largely\nunexplored.\n  In this work, we present a functional pipeline that translates natural\nlanguage prompts into spatial vector fields capable of directing simulated\ncellular collectives. Our approach combines a large language model with an\nevolvable neural controller (Prompt-to-Intervention, or P2I), optimized via\nevolutionary strategies to generate behaviors such as clustering or scattering\nin a simulated 2D environment.\n  We demonstrate that even with constrained vocabulary and simplified cell\nmodels, evolved P2I networks can successfully align cellular dynamics with\nuser-defined goals expressed in plain language. This work offers a complete\nloop from language input to simulated bioelectric-like intervention to\nbehavioral output, providing a foundation for future systems capable of natural\nlanguage-driven cellular control.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.RO",
      "q-bio.TO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to GECCO Workshop on Bio-Inspired AI (ACM GECCO2025). 13\n  pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02766v1",
    "published_date": "2025-05-05 16:21:46 UTC",
    "updated_date": "2025-05-05 16:21:46 UTC"
  },
  {
    "arxiv_id": "2505.02763v1",
    "title": "Bye-bye, Bluebook? Automating Legal Procedure with Large Language Models",
    "authors": [
      "Matthew Dahl"
    ],
    "abstract": "Legal practice requires careful adherence to procedural rules. In the United\nStates, few are more complex than those found in The Bluebook: A Uniform System\nof Citation. Compliance with this system's 500+ pages of byzantine formatting\ninstructions is the raison d'etre of thousands of student law review editors\nand the bete noire of lawyers everywhere. To evaluate whether large language\nmodels (LLMs) are able to adhere to the procedures of such a complicated\nsystem, we construct an original dataset of 866 Bluebook tasks and test\nflagship LLMs from OpenAI, Anthropic, Google, Meta, and DeepSeek. We show (1)\nthat these models produce fully compliant Bluebook citations only 69%-74% of\nthe time and (2) that in-context learning on the Bluebook's underlying system\nof rules raises accuracy only to 77%. These results caution against using\noff-the-shelf LLMs to automate aspects of the law where fidelity to procedure\nis paramount.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02763v1",
    "published_date": "2025-05-05 16:18:07 UTC",
    "updated_date": "2025-05-05 16:18:07 UTC"
  },
  {
    "arxiv_id": "2505.02747v1",
    "title": "The use of Artificial Intelligence for Intervention and Assessment in Individuals with ASD",
    "authors": [
      "Aggeliki Sideraki",
      "Christos-Nikolaos Anagnostopoulos"
    ],
    "abstract": "This paper explores the use of Artificial Intelligence (AI) as a tool for\ndiagnosis, assessment, and intervention for individuals with Autism Spectrum\nDisorder (ASD). It focuses particularly on AI's role in early diagnosis,\nutilizing advanced machine learning techniques and data analysis. Recent\nstudies demonstrate that deep learning algorithms can identify behavioral\npatterns through biometric data analysis, video-based interaction assessments,\nand linguistic feature extraction, providing a more accurate and timely\ndiagnosis compared to traditional methods. Additionally, AI automates\ndiagnostic tools, reducing subjective biases and enabling the development of\npersonalized assessment protocols for ASD monitoring. At the same time, the\npaper examines AI-powered intervention technologies, emphasizing educational\nrobots and adaptive communication tools. Social robotic assistants, such as NAO\nand Kaspar, have been shown to enhance social skills in children by offering\nstructured, repetitive interactions that reinforce learning. Furthermore,\nAI-driven Augmentative and Alternative Communication (AAC) systems allow\nchildren with ASD to express themselves more effectively, while\nmachine-learning chatbots provide language development support through\npersonalized responses. The study presents research findings supporting the\neffectiveness of these AI applications while addressing challenges such as\nlong-term evaluation and customization to individual needs. In conclusion, the\npaper highlights the significance of AI as an innovative tool in ASD diagnosis\nand intervention, advocating for further research to assess its long-term\nimpact.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02747v1",
    "published_date": "2025-05-05 15:58:32 UTC",
    "updated_date": "2025-05-05 15:58:32 UTC"
  },
  {
    "arxiv_id": "2505.02737v2",
    "title": "Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation",
    "authors": [
      "Gerard Pons",
      "Besim Bilalli",
      "Anna Queralt"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have positioned them as a\nprominent solution for Natural Language Processing tasks. Notably, they can\napproach these problems in a zero or few-shot manner, thereby eliminating the\nneed for training or fine-tuning task-specific models. However, LLMs face some\nchallenges, including hallucination and the presence of outdated knowledge or\nmissing information from specific domains in the training data. These problems\ncannot be easily solved by retraining the models with new data as it is a\ntime-consuming and expensive process. To mitigate these issues, Knowledge\nGraphs (KGs) have been proposed as a structured external source of information\nto enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for\nzero-shot Entity Disambiguation (ED). For that purpose, we leverage the\nhierarchical representation of the entities' classes in a KG to gradually prune\nthe candidate space as well as the entities' descriptions to enrich the input\nprompt with additional factual knowledge. Our evaluation on popular ED datasets\nshows that the proposed method outperforms non-enhanced and description-only\nenhanced LLMs, and has a higher degree of adaptability than task-specific\nmodels. Furthermore, we conduct an error analysis and discuss the impact of the\nleveraged KG's semantic expressivity on the ED performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Pre-print submitted to ISWC 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.02737v2",
    "published_date": "2025-05-05 15:40:24 UTC",
    "updated_date": "2025-05-06 06:44:35 UTC"
  },
  {
    "arxiv_id": "2505.02735v1",
    "title": "FormalMATH: Benchmarking Formal Mathematical Reasoning of Large Language Models",
    "authors": [
      "Zhouliang Yu",
      "Ruotian Peng",
      "Keyi Ding",
      "Yizhe Li",
      "Zhongyuan Peng",
      "Minghao Liu",
      "Yifan Zhang",
      "Zheng Yuan",
      "Huajian Xin",
      "Wenhao Huang",
      "Yandong Wen",
      "Ge Zhang",
      "Weiyang Liu"
    ],
    "abstract": "Formal mathematical reasoning remains a critical challenge for artificial\nintelligence, hindered by limitations of existing benchmarks in scope and\nscale. To address this, we present FormalMATH, a large-scale Lean4 benchmark\ncomprising 5,560 formally verified problems spanning from high-school Olympiad\nchallenges to undergraduate-level theorems across diverse domains (e.g.,\nalgebra, applied mathematics, calculus, number theory, and discrete\nmathematics). To mitigate the inefficiency of manual formalization, we\nintroduce a novel human-in-the-loop autoformalization pipeline that integrates:\n(1) specialized large language models (LLMs) for statement autoformalization,\n(2) multi-LLM semantic verification, and (3) negation-based disproof filtering\nstrategies using off-the-shelf LLM-based provers. This approach reduces expert\nannotation costs by retaining 72.09% of statements before manual verification\nwhile ensuring fidelity to the original natural-language problems. Our\nevaluation of state-of-the-art LLM-based theorem provers reveals significant\nlimitations: even the strongest models achieve only 16.46% success rate under\npractical sampling budgets, exhibiting pronounced domain bias (e.g., excelling\nin algebra but failing in calculus) and over-reliance on simplified automation\ntactics. Notably, we identify a counterintuitive inverse relationship between\nnatural-language solution guidance and proof success in chain-of-thought\nreasoning scenarios, suggesting that human-written informal reasoning\nintroduces noise rather than clarity in the formal reasoning settings. We\nbelieve that FormalMATH provides a robust benchmark for benchmarking formal\nmathematical reasoning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Technical Report v1 (33 pages, 8 figures, project page:\n  https://sphere-ai-lab.github.io/FormalMATH/)",
    "pdf_url": "http://arxiv.org/pdf/2505.02735v1",
    "published_date": "2025-05-05 15:37:00 UTC",
    "updated_date": "2025-05-05 15:37:00 UTC"
  },
  {
    "arxiv_id": "2505.02722v1",
    "title": "Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry",
    "authors": [
      "Junu Kim",
      "Chaeeun Shim",
      "Sungjin Park",
      "Su Yeon Lee",
      "Gee Young Suh",
      "Chae-Man Lim",
      "Seong Jin Choi",
      "Song Mi Moon",
      "Kyoung-Ho Song",
      "Eu Suk Kim",
      "Hong Bin Kim",
      "Sejoong Kim",
      "Chami Im",
      "Dong-Wan Kang",
      "Yong Soo Kim",
      "Hee-Joon Bae",
      "Sung Yoon Lim",
      "Han-Gil Jeong",
      "Edward Choi"
    ],
    "abstract": "Although large language models (LLMs) have demonstrated impressive reasoning\ncapabilities across general domains, their effectiveness in real-world clinical\npractice remains limited. This is likely due to their insufficient exposure to\nreal-world clinical data during training, as such data is typically not\nincluded due to privacy concerns. To address this, we propose enhancing the\nclinical reasoning capabilities of LLMs by leveraging real-world clinical data.\nWe constructed reasoning-intensive questions from a nationwide sepsis registry\nand fine-tuned Phi-4 on these questions using reinforcement learning, resulting\nin C-Reason. C-Reason exhibited strong clinical reasoning capabilities on the\nin-domain test set, as evidenced by both quantitative metrics and expert\nevaluations. Furthermore, its enhanced reasoning capabilities generalized to a\nsepsis dataset involving different tasks and patient cohorts, an open-ended\nconsultations on antibiotics use task, and other diseases. Future research\nshould focus on training LLMs with large-scale, multi-disease clinical datasets\nto develop more powerful, general-purpose clinical reasoning models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02722v1",
    "published_date": "2025-05-05 15:23:47 UTC",
    "updated_date": "2025-05-05 15:23:47 UTC"
  },
  {
    "arxiv_id": "2505.02712v1",
    "title": "Graph Neural Network-Based Reinforcement Learning for Controlling Biological Networks: The GATTACA Framework",
    "authors": [
      "Andrzej Mizera",
      "Jakub Zarzycki"
    ],
    "abstract": "Cellular reprogramming, the artificial transformation of one cell type into\nanother, has been attracting increasing research attention due to its\ntherapeutic potential for complex diseases. However, discovering reprogramming\nstrategies through classical wet-lab experiments is hindered by lengthy time\ncommitments and high costs. In this study, we explore the use of deep\nreinforcement learning (DRL) to control Boolean network models of complex\nbiological systems, such as gene regulatory networks and signalling pathway\nnetworks. We formulate a novel control problem for Boolean network models under\nthe asynchronous update mode in the context of cellular reprogramming. To\nfacilitate scalability, we consider our previously introduced concept of a\npseudo-attractor and we improve our procedure for effective identification of\npseudo-attractor states. Finally, we devise a computational framework to solve\nthe control problem. To leverage the structure of biological systems, we\nincorporate graph neural networks with graph convolutions into the artificial\nneural network approximator for the action-value function learned by the DRL\nagent. Experiments on a number of large real-world biological networks from\nliterature demonstrate the scalability and effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.MN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02712v1",
    "published_date": "2025-05-05 15:07:20 UTC",
    "updated_date": "2025-05-05 15:07:20 UTC"
  },
  {
    "arxiv_id": "2505.02709v1",
    "title": "Technical Report: Evaluating Goal Drift in Language Model Agents",
    "authors": [
      "Rauno Arike",
      "Elizabeth Donoway",
      "Henning Bartsch",
      "Marius Hobbhahn"
    ],
    "abstract": "As language models (LMs) are increasingly deployed as autonomous agents,\ntheir robust adherence to human-assigned objectives becomes crucial for safe\noperation. When these agents operate independently for extended periods without\nhuman oversight, even initially well-specified goals may gradually shift.\nDetecting and measuring goal drift - an agent's tendency to deviate from its\noriginal objective over time - presents significant challenges, as goals can\nshift gradually, causing only subtle behavioral changes. This paper proposes a\nnovel approach to analyzing goal drift in LM agents. In our experiments, agents\nare first explicitly given a goal through their system prompt, then exposed to\ncompeting objectives through environmental pressures. We demonstrate that while\nthe best-performing agent (a scaffolded version of Claude 3.5 Sonnet) maintains\nnearly perfect goal adherence for more than 100,000 tokens in our most\ndifficult evaluation setting, all evaluated models exhibit some degree of goal\ndrift. We also find that goal drift correlates with models' increasing\nsusceptibility to pattern-matching behaviors as the context length grows.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02709v1",
    "published_date": "2025-05-05 15:06:09 UTC",
    "updated_date": "2025-05-05 15:06:09 UTC"
  },
  {
    "arxiv_id": "2505.02707v1",
    "title": "Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play",
    "authors": [
      "Yemin Shi",
      "Yu Shu",
      "Siwei Dong",
      "Guangyi Liu",
      "Jaward Sesay",
      "Jingwen Li",
      "Zhiting Hu"
    ],
    "abstract": "A voice AI agent that blends seamlessly into daily life would interact with\nhumans in an autonomous, real-time, and emotionally expressive manner. Rather\nthan merely reacting to commands, it would continuously listen, reason, and\nrespond proactively, fostering fluid, dynamic, and emotionally resonant\ninteractions. We introduce Voila, a family of large voice-language foundation\nmodels that make a step towards this vision. Voila moves beyond traditional\npipeline systems by adopting a new end-to-end architecture that enables\nfull-duplex, low-latency conversations while preserving rich vocal nuances such\nas tone, rhythm, and emotion. It achieves a response latency of just 195\nmilliseconds, surpassing the average human response time. Its hierarchical\nmulti-scale Transformer integrates the reasoning capabilities of large language\nmodels (LLMs) with powerful acoustic modeling, enabling natural, persona-aware\nvoice generation -- where users can simply write text instructions to define\nthe speaker's identity, tone, and other characteristics. Moreover, Voila\nsupports over one million pre-built voices and efficient customization of new\nones from brief audio samples as short as 10 seconds. Beyond spoken dialogue,\nVoila is designed as a unified model for a wide range of voice-based\napplications, including automatic speech recognition (ASR), Text-to-Speech\n(TTS), and, with minimal adaptation, multilingual speech translation. Voila is\nfully open-sourced to support open research and accelerate progress toward\nnext-generation human-machine interactions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 7 figures, Website: https://voila.maitrix.org",
    "pdf_url": "http://arxiv.org/pdf/2505.02707v1",
    "published_date": "2025-05-05 15:05:01 UTC",
    "updated_date": "2025-05-05 15:05:01 UTC"
  },
  {
    "arxiv_id": "2505.02694v1",
    "title": "AI Standardized Patient Improves Human Conversations in Advanced Cancer Care",
    "authors": [
      "Kurtis Haut",
      "Masum Hasan",
      "Thomas Carroll",
      "Ronald Epstein",
      "Taylan Sen",
      "Ehsan Hoque"
    ],
    "abstract": "Serious illness communication (SIC) in end-of-life care faces challenges such\nas emotional stress, cultural barriers, and balancing hope with honesty.\nDespite its importance, one of the few available ways for clinicians to\npractice SIC is with standardized patients, which is expensive, time-consuming,\nand inflexible. In this paper, we present SOPHIE, an AI-powered standardized\npatient simulation and automated feedback system. SOPHIE combines large\nlanguage models (LLMs), a lifelike virtual avatar, and automated, personalized\nfeedback based on clinical literature to provide remote, on-demand SIC\ntraining. In a randomized control study with healthcare students and\nprofessionals, SOPHIE users demonstrated significant improvement across three\ncritical SIC domains: Empathize, Be Explicit, and Empower. These results\nsuggest that AI-driven tools can enhance complex interpersonal communication\nskills, offering scalable, accessible solutions to address a critical gap in\nclinician education.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "20 pages, 6 figures, 4 tables, submitting to New England Journal of\n  Medicine (NEJM)",
    "pdf_url": "http://arxiv.org/pdf/2505.02694v1",
    "published_date": "2025-05-05 14:44:17 UTC",
    "updated_date": "2025-05-05 14:44:17 UTC"
  },
  {
    "arxiv_id": "2505.02665v1",
    "title": "A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law",
    "authors": [
      "Qianjun Pan",
      "Wenkai Ji",
      "Yuyang Ding",
      "Junsong Li",
      "Shilian Chen",
      "Junyi Wang",
      "Jie Zhou",
      "Qin Chen",
      "Min Zhang",
      "Yulan Wu",
      "Liang He"
    ],
    "abstract": "This survey explores recent advancements in reasoning large language models\n(LLMs) designed to mimic \"slow thinking\" - a reasoning process inspired by\nhuman cognition, as described in Kahneman's Thinking, Fast and Slow. These\nmodels, like OpenAI's o1, focus on scaling computational resources dynamically\nduring complex tasks, such as math reasoning, visual reasoning, medical\ndiagnosis, and multi-agent debates. We present the development of reasoning\nLLMs and list their key technologies. By synthesizing over 100 studies, it\ncharts a path toward LLMs that combine human-like deep thinking with scalable\nefficiency for reasoning. The review breaks down methods into three categories:\n(1) test-time scaling dynamically adjusts computation based on task complexity\nvia search and sampling, dynamic verification; (2) reinforced learning refines\ndecision-making through iterative improvement leveraging policy networks,\nreward models, and self-evolution strategies; and (3) slow-thinking frameworks\n(e.g., long CoT, hierarchical processes) that structure problem-solving with\nmanageable steps. The survey highlights the challenges and further directions\nof this domain. Understanding and advancing the reasoning abilities of LLMs is\ncrucial for unlocking their full potential in real-world applications, from\nscientific discovery to decision support systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02665v1",
    "published_date": "2025-05-05 14:14:59 UTC",
    "updated_date": "2025-05-05 14:14:59 UTC"
  },
  {
    "arxiv_id": "2505.02659v2",
    "title": "A Note on Statistically Accurate Tabular Data Generation Using Large Language Models",
    "authors": [
      "Andrey Sidorenko"
    ],
    "abstract": "Large language models (LLMs) have shown promise in synthetic tabular data\ngeneration, yet existing methods struggle to preserve complex feature\ndependencies, particularly among categorical variables. This work introduces a\nprobability-driven prompting approach that leverages LLMs to estimate\nconditional distributions, enabling more accurate and scalable data synthesis.\nThe results highlight the potential of prompting probability distributions to\nenhance the statistical fidelity of LLM-generated tabular data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02659v2",
    "published_date": "2025-05-05 14:05:15 UTC",
    "updated_date": "2025-05-06 08:34:46 UTC"
  },
  {
    "arxiv_id": "2505.02655v1",
    "title": "SCFormer: Structured Channel-wise Transformer with Cumulative Historical State for Multivariate Time Series Forecasting",
    "authors": [
      "Shiwei Guo",
      "Ziang Chen",
      "Yupeng Ma",
      "Yunfei Han",
      "Yi Wang"
    ],
    "abstract": "The Transformer model has shown strong performance in multivariate time\nseries forecasting by leveraging channel-wise self-attention. However, this\napproach lacks temporal constraints when computing temporal features and does\nnot utilize cumulative historical series effectively.To address these\nlimitations, we propose the Structured Channel-wise Transformer with Cumulative\nHistorical state (SCFormer). SCFormer introduces temporal constraints to all\nlinear transformations, including the query, key, and value matrices, as well\nas the fully connected layers within the Transformer. Additionally, SCFormer\nemploys High-order Polynomial Projection Operators (HiPPO) to deal with\ncumulative historical time series, allowing the model to incorporate\ninformation beyond the look-back window during prediction. Extensive\nexperiments on multiple real-world datasets demonstrate that SCFormer\nsignificantly outperforms mainstream baselines, highlighting its effectiveness\nin enhancing time series forecasting. The code is publicly available at\nhttps://github.com/ShiweiGuo1995/SCFormer",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02655v1",
    "published_date": "2025-05-05 13:59:55 UTC",
    "updated_date": "2025-05-05 13:59:55 UTC"
  },
  {
    "arxiv_id": "2505.02649v1",
    "title": "Eye Movements as Indicators of Deception: A Machine Learning Approach",
    "authors": [
      "Valentin Foucher",
      "Santiago de Leon-Martinez",
      "Robert Moro"
    ],
    "abstract": "Gaze may enhance the robustness of lie detectors but remains under-studied.\nThis study evaluated the efficacy of AI models (using fixations, saccades,\nblinks, and pupil size) for detecting deception in Concealed Information Tests\nacross two datasets. The first, collected with Eyelink 1000, contains gaze data\nfrom a computerized experiment where 87 participants revealed, concealed, or\nfaked the value of a previously selected card. The second, collected with Pupil\nNeon, involved 36 participants performing a similar task but facing an\nexperimenter. XGBoost achieved accuracies up to 74% in a binary classification\ntask (Revealing vs. Concealing) and 49% in a more challenging\nthree-classification task (Revealing vs. Concealing vs. Faking). Feature\nanalysis identified saccade number, duration, amplitude, and maximum pupil size\nas the most important for deception prediction. These results demonstrate the\nfeasibility of using gaze and AI to enhance lie detectors and encourage future\nresearch that may improve on this.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02649v1",
    "published_date": "2025-05-05 13:50:12 UTC",
    "updated_date": "2025-05-05 13:50:12 UTC"
  },
  {
    "arxiv_id": "2505.02640v1",
    "title": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints",
    "authors": [
      "Shubham Vaishnav",
      "Praveen Kumar Donta",
      "Sindri Magnússon"
    ],
    "abstract": "Internet of Things (IoT) systems increasingly operate in environments where\ndevices must respond in real time while managing fluctuating resource\nconstraints, including energy and bandwidth. Yet, current approaches often fall\nshort in addressing scenarios where operational constraints evolve over time.\nTo address these limitations, we propose a novel Budgeted Multi-Armed Bandit\nframework tailored for IoT applications with dynamic operational limits. Our\nmodel introduces a decaying violation budget, which permits limited constraint\nviolations early in the learning process and gradually enforces stricter\ncompliance over time. We present the Budgeted Upper Confidence Bound (UCB)\nalgorithm, which adaptively balances performance optimization and compliance\nwith time-varying constraints. We provide theoretical guarantees showing that\nBudgeted UCB achieves sublinear regret and logarithmic constraint violations\nover the learning horizon. Extensive simulations in a wireless communication\nsetting show that our approach achieves faster adaptation and better constraint\nsatisfaction than standard online learning methods. These results highlight the\nframework's potential for building adaptive, resource-aware IoT systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02640v1",
    "published_date": "2025-05-05 13:33:39 UTC",
    "updated_date": "2025-05-05 13:33:39 UTC"
  },
  {
    "arxiv_id": "2505.02639v1",
    "title": "Enhancing Chemical Reaction and Retrosynthesis Prediction with Large Language Model and Dual-task Learning",
    "authors": [
      "Xuan Lin",
      "Qingrui Liu",
      "Hongxin Xiang",
      "Daojian Zeng",
      "Xiangxiang Zeng"
    ],
    "abstract": "Chemical reaction and retrosynthesis prediction are fundamental tasks in drug\ndiscovery. Recently, large language models (LLMs) have shown potential in many\ndomains. However, directly applying LLMs to these tasks faces two major\nchallenges: (i) lacking a large-scale chemical synthesis-related instruction\ndataset; (ii) ignoring the close correlation between reaction and\nretrosynthesis prediction for the existing fine-tuning strategies. To address\nthese challenges, we propose ChemDual, a novel LLM framework for accurate\nchemical synthesis. Specifically, considering the high cost of data acquisition\nfor reaction and retrosynthesis, ChemDual regards the\nreaction-and-retrosynthesis of molecules as a related\nrecombination-and-fragmentation process and constructs a large-scale of 4.4\nmillion instruction dataset. Furthermore, ChemDual introduces an enhanced\nLLaMA, equipped with a multi-scale tokenizer and dual-task learning strategy,\nto jointly optimize the process of recombination and fragmentation as well as\nthe tasks between reaction and retrosynthesis prediction. Extensive experiments\non Mol-Instruction and USPTO-50K datasets demonstrate that ChemDual achieves\nstate-of-the-art performance in both predictions of reaction and\nretrosynthesis, outperforming the existing conventional single-task approaches\nand the general open-source LLMs. Through molecular docking analysis, ChemDual\ngenerates compounds with diverse and strong protein binding affinity, further\nhighlighting its strong potential in drug design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication at IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02639v1",
    "published_date": "2025-05-05 13:31:36 UTC",
    "updated_date": "2025-05-05 13:31:36 UTC"
  },
  {
    "arxiv_id": "2505.02627v1",
    "title": "A Theoretical Analysis of Compositional Generalization in Neural Networks: A Necessary and Sufficient Condition",
    "authors": [
      "Yuanpeng Li"
    ],
    "abstract": "Compositional generalization is a crucial property in artificial\nintelligence, enabling models to handle novel combinations of known components.\nWhile most deep learning models lack this capability, certain models succeed in\nspecific tasks, suggesting the existence of governing conditions. This paper\nderives a necessary and sufficient condition for compositional generalization\nin neural networks. Conceptually, it requires that (i) the computational graph\nmatches the true compositional structure, and (ii) components encode just\nenough information in training. The condition is supported by mathematical\nproofs. This criterion combines aspects of architecture design, regularization,\nand training data properties. A carefully designed minimal example illustrates\nan intuitive understanding of the condition. We also discuss the potential of\nthe condition for assessing compositional generalization before training. This\nwork is a fundamental theoretical study of compositional generalization in\nneural networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02627v1",
    "published_date": "2025-05-05 13:13:46 UTC",
    "updated_date": "2025-05-05 13:13:46 UTC"
  },
  {
    "arxiv_id": "2505.02625v1",
    "title": "LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis",
    "authors": [
      "Qingkai Fang",
      "Yan Zhou",
      "Shoutao Guo",
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "abstract": "Real-time, intelligent, and natural speech interaction is an essential part\nof the next-generation human-computer interaction. Recent advancements have\nshowcased the potential of building intelligent spoken chatbots based on large\nlanguage models (LLMs). In this paper, we introduce LLaMA-Omni 2, a series of\nspeech language models (SpeechLMs) ranging from 0.5B to 14B parameters, capable\nof achieving high-quality real-time speech interaction. LLaMA-Omni 2 is built\nupon the Qwen2.5 series models, integrating a speech encoder and an\nautoregressive streaming speech decoder. Despite being trained on only 200K\nmulti-turn speech dialogue samples, LLaMA-Omni 2 demonstrates strong\nperformance on several spoken question answering and speech instruction\nfollowing benchmarks, surpassing previous state-of-the-art SpeechLMs like\nGLM-4-Voice, which was trained on millions of hours of speech data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint. Project: https://github.com/ictnlp/LLaMA-Omni2",
    "pdf_url": "http://arxiv.org/pdf/2505.02625v1",
    "published_date": "2025-05-05 12:53:09 UTC",
    "updated_date": "2025-05-05 12:53:09 UTC"
  },
  {
    "arxiv_id": "2505.02609v1",
    "title": "Study of the influence of a biased database on the prediction of standard algorithms for selecting the best candidate for an interview",
    "authors": [
      "Shuyu Wang",
      "Angélique Saillet",
      "Philomène Le Gall",
      "Alain Lacroux",
      "Christelle Martin-Lacroux",
      "Vincent Brault"
    ],
    "abstract": "Artificial intelligence is used at various stages of the recruitment process\nto automatically select the best candidate for a position, with companies\nguaranteeing unbiased recruitment. However, the algorithms used are either\ntrained by humans or are based on learning from past experiences that were\nbiased. In this article, we propose to generate data mimicking external\n(discrimination) and internal biases (self-censorship) in order to train five\nclassic algorithms and to study the extent to which they do or do not find the\nbest candidates according to objective criteria. In addition, we study the\ninfluence of the anonymisation of files on the quality of predictions.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "38 pages, 25 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.02609v1",
    "published_date": "2025-05-05 12:24:31 UTC",
    "updated_date": "2025-05-05 12:24:31 UTC"
  },
  {
    "arxiv_id": "2505.02581v1",
    "title": "Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem",
    "authors": [
      "Alberto Hernández-Espinosa",
      "Felipe S. Abrahão",
      "Olaf Witkowski",
      "Hector Zenil"
    ],
    "abstract": "The AI alignment problem, which focusses on ensuring that artificial\nintelligence (AI), including AGI and ASI, systems act according to human\nvalues, presents profound challenges. With the progression from narrow AI to\nArtificial General Intelligence (AGI) and Superintelligence, fears about\ncontrol and existential risk have escalated. This paper demonstrates that\nachieving complete alignment is inherently unattainable due to mathematical\nprinciples rooted in the foundations of predicate logic and computability, in\nparticular Turing's computational universality, G\\\"odel's incompleteness and\nChaitin's randomness. Instead, we argue that embracing AI misalignment or\nagent's `neurodivergence' as a contingent strategy, defined as fostering a\ndynamic ecosystem of competing, partially aligned agents, is a possible only\nviable path to mitigate risks. Through mathematical proofs and an experimental\ndesign, we explore how misalignment may serve and should be promoted as a\ncounterbalancing mechanism to team up with whichever agents are most aligned AI\nto human values, ensuring that no single system dominates destructively. The\nmain premise of our contribution is that misalignment is inevitable because\nfull AI-human alignment is a mathematical impossibility from Turing-complete\nsystems which we also prove in this paper, a feature then inherited to AGI and\nASI systems. We introduce and test `change-of-opinion' attacks based on this\nkind of perturbation and intervention analysis to study how agents may\nneutralise friendly or unfriendly AIs through cooperation, competition or\nmalice.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02581v1",
    "published_date": "2025-05-05 11:33:18 UTC",
    "updated_date": "2025-05-05 11:33:18 UTC"
  },
  {
    "arxiv_id": "2505.02579v2",
    "title": "EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning",
    "authors": [
      "Lingxiao Kong",
      "Cong Yang",
      "Susanne Neufang",
      "Oya Deniz Beyan",
      "Zeyd Boukhers"
    ],
    "abstract": "Recent advances in reinforcement learning (RL) for large language model (LLM)\nfine-tuning show promise in addressing multi-objective tasks but still face\nsignificant challenges, including complex objective balancing, low training\nefficiency, poor scalability, and limited explainability. Leveraging ensemble\nlearning principles, we introduce an Ensemble Multi-Objective RL (EMORL)\nframework that fine-tunes multiple models with individual objectives while\noptimizing their aggregation after the training to improve efficiency and\nflexibility. Our method is the first to aggregate the last hidden states of\nindividual models, incorporating contextual information from multiple\nobjectives. This approach is supported by a hierarchical grid search algorithm\nthat identifies optimal weighted combinations. We evaluate EMORL on counselor\nreflection generation tasks, using text-scoring LLMs to evaluate the\ngenerations and provide rewards during RL fine-tuning. Through comprehensive\nexperiments on the PAIR and Psych8k datasets, we demonstrate the advantages of\nEMORL against existing baselines: significantly lower and more stable training\nconsumption ($17,529\\pm 1,650$ data points and $6,573\\pm 147.43$ seconds),\nimproved scalability and explainability, and comparable performance across\nmultiple objectives.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 9 figures, submitted to SIGDIAL 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2505.02579v2",
    "published_date": "2025-05-05 11:30:46 UTC",
    "updated_date": "2025-05-06 06:26:11 UTC"
  },
  {
    "arxiv_id": "2505.02576v1",
    "title": "Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning",
    "authors": [
      "Sergio Hernández-Gutiérrez",
      "Minttu Alakuijala",
      "Alexander V. Nikitin",
      "Pekka Marttinen"
    ],
    "abstract": "Reasoning tasks are crucial in many domains, especially in science and\nengineering. Although large language models (LLMs) have made progress in\nreasoning tasks using techniques such as chain-of-thought and least-to-most\nprompting, these approaches still do not effectively scale to complex problems\nin either their performance or execution time. Moreover, they often require\nadditional supervision for each new task, such as in-context examples. In this\nwork, we introduce Recursive Decomposition with Dependencies (RDD), a scalable\ndivide-and-conquer method for solving reasoning problems that requires less\nsupervision than prior approaches. Our method can be directly applied to a new\nproblem class even in the absence of any task-specific guidance. Furthermore,\nRDD supports sub-task dependencies, allowing for ordered execution of\nsub-tasks, as well as an error recovery mechanism that can correct mistakes\nmade in previous steps. We evaluate our approach on two benchmarks with six\ndifficulty levels each and in two in-context settings: one with task-specific\nexamples and one without. Our results demonstrate that RDD outperforms other\nmethods in a compute-matched setting as task complexity increases, while also\nbeing more computationally efficient.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02576v1",
    "published_date": "2025-05-05 11:24:20 UTC",
    "updated_date": "2025-05-05 11:24:20 UTC"
  },
  {
    "arxiv_id": "2505.02573v1",
    "title": "Rethinking Federated Graph Learning: A Data Condensation Perspective",
    "authors": [
      "Hao Zhang",
      "Xunkai Li",
      "Yinlin Zhu",
      "Lianglin Hu"
    ],
    "abstract": "Federated graph learning is a widely recognized technique that promotes\ncollaborative training of graph neural networks (GNNs) by multi-client\ngraphs.However, existing approaches heavily rely on the communication of model\nparameters or gradients for federated optimization and fail to adequately\naddress the data heterogeneity introduced by intricate and diverse graph\ndistributions. Although some methods attempt to share additional messages among\nthe server and clients to improve federated convergence during communication,\nthey introduce significant privacy risks and increase communication overhead.\nTo address these issues, we introduce the concept of a condensed graph as a\nnovel optimization carrier to address FGL data heterogeneity and propose a new\nFGL paradigm called FedGM. Specifically, we utilize a generalized condensation\ngraph consensus to aggregate comprehensive knowledge from distributed graphs,\nwhile minimizing communication costs and privacy risks through a single\ntransmission of the condensed data. Extensive experiments on six public\ndatasets consistently demonstrate the superiority of FedGM over\nstate-of-the-art baselines, highlighting its potential for a novel FGL\nparadigm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02573v1",
    "published_date": "2025-05-05 11:23:29 UTC",
    "updated_date": "2025-05-05 11:23:29 UTC"
  },
  {
    "arxiv_id": "2505.02566v1",
    "title": "Robustness questions the interpretability of graph neural networks: what to do?",
    "authors": [
      "Kirill Lukyanov",
      "Georgii Sazonov",
      "Serafim Boyarsky",
      "Ilya Makarov"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become a cornerstone in graph-based data\nanalysis, with applications in diverse domains such as bioinformatics, social\nnetworks, and recommendation systems. However, the interplay between model\ninterpretability and robustness remains poorly understood, especially under\nadversarial scenarios like poisoning and evasion attacks. This paper presents a\ncomprehensive benchmark to systematically analyze the impact of various factors\non the interpretability of GNNs, including the influence of\nrobustness-enhancing defense mechanisms.\n  We evaluate six GNN architectures based on GCN, SAGE, GIN, and GAT across\nfive datasets from two distinct domains, employing four interpretability\nmetrics: Fidelity, Stability, Consistency, and Sparsity. Our study examines how\ndefenses against poisoning and evasion attacks, applied before and during model\ntraining, affect interpretability and highlights critical trade-offs between\nrobustness and interpretability. The framework will be published as open\nsource.\n  The results reveal significant variations in interpretability depending on\nthe chosen defense methods and model architecture characteristics. By\nestablishing a standardized benchmark, this work provides a foundation for\ndeveloping GNNs that are both robust to adversarial threats and interpretable,\nfacilitating trust in their deployment in sensitive applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02566v1",
    "published_date": "2025-05-05 11:14:56 UTC",
    "updated_date": "2025-05-05 11:14:56 UTC"
  },
  {
    "arxiv_id": "2505.02550v1",
    "title": "Bielik v3 Small: Technical Report",
    "authors": [
      "Krzysztof Ociepa",
      "Łukasz Flis",
      "Remigiusz Kinas",
      "Krzysztof Wróbel",
      "Adrian Gwoździej"
    ],
    "abstract": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02550v1",
    "published_date": "2025-05-05 10:39:51 UTC",
    "updated_date": "2025-05-05 10:39:51 UTC"
  },
  {
    "arxiv_id": "2505.02540v1",
    "title": "Lazy But Effective: Collaborative Personalized Federated Learning with Heterogeneous Data",
    "authors": [
      "Ljubomir Rokvic",
      "Panayiotis Danassis",
      "Boi Faltings"
    ],
    "abstract": "In Federated Learning, heterogeneity in client data distributions often means\nthat a single global model does not have the best performance for individual\nclients. Consider for example training a next-word prediction model for\nkeyboards: user-specific language patterns due to demographics (dialect, age,\netc.), language proficiency, and writing style result in a highly non-IID\ndataset across clients. Other examples are medical images taken with different\nmachines, or driving data from different vehicle types. To address this, we\npropose a simple yet effective personalized federated learning framework\n(pFedLIA) that utilizes a computationally efficient influence approximation,\ncalled `Lazy Influence', to cluster clients in a distributed manner before\nmodel aggregation. Within each cluster, data owners collaborate to jointly\ntrain a model that captures the specific data patterns of the clients. Our\nmethod has been shown to successfully recover the global model's performance\ndrop due to the non-IID-ness in various synthetic and real-world settings,\nspecifically a next-word prediction task on the Nordic languages as well as\nseveral benchmark tasks. It matches the performance of a hypothetical Oracle\nclustering, and significantly improves on existing baselines, e.g., an\nimprovement of 17% on CIFAR100.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the International Joint Conference on Neural Networks\n  (IJCNN), IEEE, 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02540v1",
    "published_date": "2025-05-05 10:26:35 UTC",
    "updated_date": "2025-05-05 10:26:35 UTC"
  },
  {
    "arxiv_id": "2505.02537v2",
    "title": "Advancing Constrained Monotonic Neural Networks: Achieving Universal Approximation Beyond Bounded Activations",
    "authors": [
      "Davide Sartor",
      "Alberto Sinigaglia",
      "Gian Antonio Susto"
    ],
    "abstract": "Conventional techniques for imposing monotonicity in MLPs by construction\ninvolve the use of non-negative weight constraints and bounded activation\nfunctions, which pose well-known optimization challenges. In this work, we\ngeneralize previous theoretical results, showing that MLPs with non-negative\nweight constraint and activations that saturate on alternating sides are\nuniversal approximators for monotonic functions. Additionally, we show an\nequivalence between the saturation side in the activations and the sign of the\nweight constraint. This connection allows us to prove that MLPs with convex\nmonotone activations and non-positive constrained weights also qualify as\nuniversal approximators, in contrast to their non-negative constrained\ncounterparts. Our results provide theoretical grounding to the empirical\neffectiveness observed in previous works while leading to possible\narchitectural simplification. Moreover, to further alleviate the optimization\ndifficulties, we propose an alternative formulation that allows the network to\nadjust its activations according to the sign of the weights. This eliminates\nthe requirement for weight reparameterization, easing initialization and\nimproving training stability. Experimental evaluation reinforces the validity\nof the theoretical results, showing that our novel approach compares favourably\nto traditional monotonic architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2505.02537v2",
    "published_date": "2025-05-05 10:18:48 UTC",
    "updated_date": "2025-05-06 11:45:55 UTC"
  },
  {
    "arxiv_id": "2505.02533v1",
    "title": "Large Language Model Partitioning for Low-Latency Inference at the Edge",
    "authors": [
      "Dimitrios Kafetzis",
      "Ramin Khalili",
      "Iordanis Koutsopoulos"
    ],
    "abstract": "Large Language Models (LLMs) based on autoregressive, decoder-only\nTransformers generate text one token at a time, where a token represents a\ndiscrete unit of text. As each newly produced token is appended to the partial\noutput sequence, the length grows and so does the memory and compute load, due\nto the expanding key-value caches, which store intermediate representations of\nall previously generated tokens in the multi-head attention (MHA) layer. As\nthis iterative process steadily increases memory and compute demands,\nlayer-based partitioning in resource-constrained edge environments often\nresults in memory overload or high inference latency. To address this and\nreduce inference latency, we propose a resource-aware Transformer architecture\npartitioning algorithm, where the partitioning decision is updated at regular\nintervals during token generation. The approach is myopic in that it is based\non instantaneous information about device resource availability and network\nlink bandwidths. When first executed, the algorithm places blocks on devices,\nand in later executions, it migrates these blocks among devices so that the sum\nof migration delay and inference delay remains low. Our approach partitions the\ndecoder at the attention head level, co-locating each attention head with its\nkey-value cache and allowing dynamic migrations whenever resources become\ntight. By allocating different attention heads to different devices, we exploit\nparallel execution of attention heads and thus achieve substantial reductions\nin inference delays. Our experiments show that in small-scale settings (3-5\ndevices), the proposed method achieves within 15 to 20 percent of an exact\noptimal solver's latency, while in larger-scale tests it achieves notable\nimprovements in inference speed and memory usage compared to state-of-the-art\nlayer-based partitioning approaches.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02533v1",
    "published_date": "2025-05-05 10:16:16 UTC",
    "updated_date": "2025-05-05 10:16:16 UTC"
  },
  {
    "arxiv_id": "2505.02516v1",
    "title": "Machine-Learning-Powered Neural Interfaces for Smart Prosthetics and Diagnostics",
    "authors": [
      "MohammadAli Shaeri",
      "Jinhan Liu",
      "Mahsa Shoaran"
    ],
    "abstract": "Advanced neural interfaces are transforming applications ranging from\nneuroscience research to diagnostic tools (for mental state recognition, tremor\nand seizure detection) as well as prosthetic devices (for motor and\ncommunication recovery). By integrating complex functions into miniaturized\nneural devices, these systems unlock significant opportunities for personalized\nassistive technologies and adaptive therapeutic interventions. Leveraging\nhigh-density neural recordings, on-site signal processing, and machine learning\n(ML), these interfaces extract critical features, identify disease\nneuro-markers, and enable accurate, low-latency neural decoding. This\nintegration facilitates real-time interpretation of neural signals, adaptive\nmodulation of brain activity, and efficient control of assistive devices.\nMoreover, the synergy between neural interfaces and ML has paved the way for\nself-sufficient, ubiquitous platforms capable of operating in diverse\nenvironments with minimal hardware costs and external dependencies. In this\nwork, we review recent advancements in AI-driven decoding algorithms and\nenergy-efficient System-on-Chip (SoC) platforms for next-generation\nminiaturized neural devices. These innovations highlight the potential for\ndeveloping intelligent neural interfaces, addressing critical challenges in\nscalability, reliability, interpretability, and user adaptability.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.LG",
      "eess.SP",
      "q-bio.NC",
      "I.2.0; B.7.0; I.5.1; C.3"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in the 2025 IEEE International NEWCAS Conference\n  (NEWCAS'25)",
    "pdf_url": "http://arxiv.org/pdf/2505.02516v1",
    "published_date": "2025-05-05 09:49:13 UTC",
    "updated_date": "2025-05-05 09:49:13 UTC"
  },
  {
    "arxiv_id": "2505.02502v1",
    "title": "Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study",
    "authors": [
      "Xinyi Hou",
      "Jiahao Han",
      "Yanjie Zhao",
      "Haoyu Wang"
    ],
    "abstract": "Background: Large language models (LLMs) are increasingly deployed via\nopen-source and commercial frameworks, enabling individuals and organizations\nto self-host advanced AI capabilities. However, insecure defaults and\nmisconfigurations often expose LLM services to the public Internet, posing\nsignificant security and system engineering risks. Aims: This study aims to\nunveil the current landscape of public-facing LLM deployments in the wild\nthrough a large-scale empirical study, focusing on service prevalence, exposure\ncharacteristics, systemic vulnerabilities, and associated risks. Method: We\nconducted an Internet-wide measurement to identify public-facing LLM\ndeployments across 15 frameworks, discovering 320,102 services. We extracted\n158 unique API endpoints, grouped into 12 functional categories based on\ncapabilities and security risks. We further analyzed configurations,\nauthentication practices, and geographic distributions, revealing deployment\ntrends and systemic issues in real-world LLM system engineering. Results: Our\nstudy shows that public LLM deployments are rapidly growing but often insecure.\nAmong all endpoints, we observe widespread use of insecure protocols, poor TLS\nconfigurations, and unauthenticated access to critical operations. Security\nrisks, including model disclosure, system leakage, and unauthorized access, are\npervasive, highlighting the need for secure-by-default frameworks and stronger\ndeployment practices. Conclusions: Public-facing LLM deployments suffer from\nwidespread security and configuration flaws, exposing services to misuse, model\ntheft, resource hijacking, and remote exploitation. Strengthening default\nsecurity, deployment practices, and operational standards is critical for the\ngrowing self-hosted LLM ecosystem.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02502v1",
    "published_date": "2025-05-05 09:30:19 UTC",
    "updated_date": "2025-05-05 09:30:19 UTC"
  },
  {
    "arxiv_id": "2505.02501v1",
    "title": "Corr2Distrib: Making Ambiguous Correspondences an Ally to Predict Reliable 6D Pose Distributions",
    "authors": [
      "Asma Brazi",
      "Boris Meden",
      "Fabrice Mayran de Chamisso",
      "Steve Bourgeois",
      "Vincent Lepetit"
    ],
    "abstract": "We introduce Corr2Distrib, the first correspondence-based method which\nestimates a 6D camera pose distribution from an RGB image, explaining the\nobservations. Indeed, symmetries and occlusions introduce visual ambiguities,\nleading to multiple valid poses. While a few recent methods tackle this\nproblem, they do not rely on local correspondences which, according to the BOP\nChallenge, are currently the most effective way to estimate a single 6DoF pose\nsolution. Using correspondences to estimate a pose distribution is not\nstraightforward, since ambiguous correspondences induced by visual ambiguities\ndrastically decrease the performance of PnP. With Corr2Distrib, we turn these\nambiguities into an advantage to recover all valid poses. Corr2Distrib first\nlearns a symmetry-aware representation for each 3D point on the object's\nsurface, characterized by a descriptor and a local frame. This representation\nenables the generation of 3DoF rotation hypotheses from single 2D-3D\ncorrespondences. Next, we refine these hypotheses into a 6DoF pose distribution\nusing PnP and pose scoring. Our experimental evaluations on complex\nnon-synthetic scenes show that Corr2Distrib outperforms state-of-the-art\nsolutions for both pose distribution estimation and single pose estimation from\nan RGB image, demonstrating the potential of correspondences-based approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02501v1",
    "published_date": "2025-05-05 09:29:32 UTC",
    "updated_date": "2025-05-05 09:29:32 UTC"
  },
  {
    "arxiv_id": "2505.02489v1",
    "title": "Beyond the model: Key differentiators in large language models and multi-agent services",
    "authors": [
      "Muskaan Goyal",
      "Pranav Bhasin"
    ],
    "abstract": "With the launch of foundation models like DeepSeek, Manus AI, and Llama 4, it\nhas become evident that large language models (LLMs) are no longer the sole\ndefining factor in generative AI. As many now operate at comparable levels of\ncapability, the real race is not about having the biggest model but optimizing\nthe surrounding ecosystem, including data quality and management, computational\nefficiency, latency, and evaluation frameworks. This review article delves into\nthese critical differentiators that ensure modern AI services are efficient and\nprofitable.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02489v1",
    "published_date": "2025-05-05 09:15:31 UTC",
    "updated_date": "2025-05-05 09:15:31 UTC"
  },
  {
    "arxiv_id": "2505.02486v1",
    "title": "SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning",
    "authors": [
      "Jinpeng Chen",
      "Runmin Cong",
      "Yuzhi Zhao",
      "Hongzheng Yang",
      "Guangneng Hu",
      "Horace Ho Shing Ip",
      "Sam Kwong"
    ],
    "abstract": "Multimodal Continual Instruction Tuning (MCIT) aims to enable Multimodal\nLarge Language Models (MLLMs) to incrementally learn new tasks without\ncatastrophic forgetting. In this paper, we explore forgetting in this context,\ncategorizing it into superficial forgetting and essential forgetting.\nSuperficial forgetting refers to cases where the model's knowledge may not be\ngenuinely lost, but its responses to previous tasks deviate from expected\nformats due to the influence of subsequent tasks' answer styles, making the\nresults unusable. By contrast, essential forgetting refers to situations where\nthe model provides correctly formatted but factually inaccurate answers,\nindicating a true loss of knowledge. Assessing essential forgetting\nnecessitates addressing superficial forgetting first, as severe superficial\nforgetting can obscure the model's knowledge state. Hence, we first introduce\nthe Answer Style Diversification (ASD) paradigm, which defines a standardized\nprocess for transforming data styles across different tasks, unifying their\ntraining sets into similarly diversified styles to prevent superficial\nforgetting caused by style shifts. Building on this, we propose RegLoRA to\nmitigate essential forgetting. RegLoRA stabilizes key parameters where prior\nknowledge is primarily stored by applying regularization, enabling the model to\nretain existing competencies. Experimental results demonstrate that our overall\nmethod, SEFE, achieves state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02486v1",
    "published_date": "2025-05-05 09:09:41 UTC",
    "updated_date": "2025-05-05 09:09:41 UTC"
  },
  {
    "arxiv_id": "2505.02485v1",
    "title": "Integrating Column Generation and Large Neighborhood Search for Bus Driver Scheduling with Complex Break Constraints",
    "authors": [
      "Lucas Kletzander",
      "Tommaso Mannelli Mazzoli",
      "Nysret Musliu",
      "Pascal Van Hentenryck"
    ],
    "abstract": "The Bus Driver Scheduling Problem (BDSP) is a combinatorial optimization\nproblem with the goal to design shifts to cover prearranged bus tours. The\nobjective takes into account the operational cost as well as the satisfaction\nof drivers. This problem is heavily constrained due to strict legal rules and\ncollective agreements. The objective of this article is to provide\nstate-of-the-art exact and hybrid solution methods that can provide\nhigh-quality solutions for instances of different sizes. This work presents a\ncomprehensive study of both an exact method, Branch and Price (B&P), as well as\na Large Neighborhood Search (LNS) framework which uses B&P or Column Generation\n(CG) for the repair phase to solve the BDSP. It further proposes and evaluates\na novel deeper integration of B&P and LNS, storing the generated columns from\nthe LNS subproblems and reusing them for other subproblems, or to find better\nglobal solutions. The article presents a detailed analysis of several\ncomponents of the solution methods and their impact, including general\nimprovements for the B&P subproblem, which is a high-dimensional Resource\nConstrained Shortest Path Problem (RCSPP), and the components of the LNS. The\nevaluation shows that our approach provides new state-of-the-art results for\ninstances of all sizes, including exact solutions for small instances, and low\ngaps to a known lower bound for mid-sized instances. Conclusions: We observe\nthat B&P provides the best results for small instances, while the tight\nintegration of LNS and CG can provide high-quality solutions for larger\ninstances, further improving over LNS which just uses CG as a black box. The\nproposed methods are general and can also be applied to other rule sets and\nrelated optimization problems",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02485v1",
    "published_date": "2025-05-05 09:08:25 UTC",
    "updated_date": "2025-05-05 09:08:25 UTC"
  },
  {
    "arxiv_id": "2505.02484v1",
    "title": "El Agente: An Autonomous Agent for Quantum Chemistry",
    "authors": [
      "Yunheng Zou",
      "Austin H. Cheng",
      "Abdulrahman Aldossary",
      "Jiaru Bai",
      "Shi Xuan Leong",
      "Jorge Arturo Campos-Gonzalez-Angulo",
      "Changhyeok Choi",
      "Cher Tian Ser",
      "Gary Tom",
      "Andrew Wang",
      "Zijian Zhang",
      "Ilya Yakavets",
      "Han Hao",
      "Chris Crebolder",
      "Varinia Bernales",
      "Alán Aspuru-Guzik"
    ],
    "abstract": "Computational chemistry tools are widely used to study the behaviour of\nchemical phenomena. Yet, the complexity of these tools can make them\ninaccessible to non-specialists and challenging even for experts. In this work,\nwe introduce El Agente Q, an LLM-based multi-agent system that dynamically\ngenerates and executes quantum chemistry workflows from natural language user\nprompts. The system is built on a novel cognitive architecture featuring a\nhierarchical memory framework that enables flexible task decomposition,\nadaptive tool selection, post-analysis, and autonomous file handling and\nsubmission. El Agente Q is benchmarked on six university-level course exercises\nand two case studies, demonstrating robust problem-solving performance\n(averaging >87% task success) and adaptive error handling through in situ\ndebugging. It also supports longer-term, multi-step task execution for more\ncomplex workflows, while maintaining transparency through detailed action trace\nlogs. Together, these capabilities lay the foundation for increasingly\nautonomous and accessible quantum chemistry.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "physics.chem-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02484v1",
    "published_date": "2025-05-05 09:07:22 UTC",
    "updated_date": "2025-05-05 09:07:22 UTC"
  },
  {
    "arxiv_id": "2505.02483v1",
    "title": "Automated Hybrid Reward Scheduling via Large Language Models for Robotic Skill Learning",
    "authors": [
      "Changxin Huang",
      "Junyang Liang",
      "Yanbin Chang",
      "Jingzhao Xu",
      "Jianqiang Li"
    ],
    "abstract": "Enabling a high-degree-of-freedom robot to learn specific skills is a\nchallenging task due to the complexity of robotic dynamics. Reinforcement\nlearning (RL) has emerged as a promising solution; however, addressing such\nproblems requires the design of multiple reward functions to account for\nvarious constraints in robotic motion. Existing approaches typically sum all\nreward components indiscriminately to optimize the RL value function and\npolicy. We argue that this uniform inclusion of all reward components in policy\noptimization is inefficient and limits the robot's learning performance. To\naddress this, we propose an Automated Hybrid Reward Scheduling (AHRS) framework\nbased on Large Language Models (LLMs). This paradigm dynamically adjusts the\nlearning intensity of each reward component throughout the policy optimization\nprocess, enabling robots to acquire skills in a gradual and structured manner.\nSpecifically, we design a multi-branch value network, where each branch\ncorresponds to a distinct reward component. During policy optimization, each\nbranch is assigned a weight that reflects its importance, and these weights are\nautomatically computed based on rules designed by LLMs. The LLM generates a\nrule set in advance, derived from the task description, and during training, it\nselects a weight calculation rule from the library based on language prompts\nthat evaluate the performance of each branch. Experimental results demonstrate\nthat the AHRS method achieves an average 6.48% performance improvement across\nmultiple high-degree-of-freedom robotic tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02483v1",
    "published_date": "2025-05-05 09:06:17 UTC",
    "updated_date": "2025-05-05 09:06:17 UTC"
  },
  {
    "arxiv_id": "2505.02467v1",
    "title": "Timing Is Everything: Finding the Optimal Fusion Points in Multimodal Medical Imaging",
    "authors": [
      "Valerio Guarrasi",
      "Klara Mogensen",
      "Sara Tassinari",
      "Sara Qvarlander",
      "Paolo Soda"
    ],
    "abstract": "Multimodal deep learning harnesses diverse imaging modalities, such as MRI\nsequences, to enhance diagnostic accuracy in medical imaging. A key challenge\nis determining the optimal timing for integrating these\nmodalities-specifically, identifying the network layers where fusion modules\nshould be inserted. Current approaches often rely on manual tuning or\nexhaustive search, which are computationally expensive without any guarantee of\nconverging to optimal results. We propose a sequential forward search algorithm\nthat incrementally activates and evaluates candidate fusion modules at\ndifferent layers of a multimodal network. At each step, the algorithm retrains\nfrom previously learned weights and compares validation loss to identify the\nbest-performing configuration. This process systematically reduces the search\nspace, enabling efficient identification of the optimal fusion timing without\nexhaustively testing all possible module placements. The approach is validated\non two multimodal MRI datasets, each addressing different classification tasks.\nOur algorithm consistently identified configurations that outperformed unimodal\nbaselines, late fusion, and a brute-force ensemble of all potential fusion\nplacements. These architectures demonstrated superior accuracy, F-score, and\nspecificity while maintaining competitive or improved AUC values. Furthermore,\nthe sequential nature of the search significantly reduced computational\noverhead, making the optimization process more practical. By systematically\ndetermining the optimal timing to fuse imaging modalities, our method advances\nmultimodal deep learning for medical imaging. It provides an efficient and\nrobust framework for fusion optimization, paving the way for improved clinical\ndecision-making and more adaptable, scalable architectures in medical AI\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02467v1",
    "published_date": "2025-05-05 08:53:21 UTC",
    "updated_date": "2025-05-05 08:53:21 UTC"
  },
  {
    "arxiv_id": "2505.02462v1",
    "title": "Incentivizing Inclusive Contributions in Model Sharing Markets",
    "authors": [
      "Enpei Zhang",
      "Jingyi Chai",
      "Rui Ye",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "abstract": "While data plays a crucial role in training contemporary AI models, it is\nacknowledged that valuable public data will be exhausted in a few years,\ndirecting the world's attention towards the massive decentralized private data.\nHowever, the privacy-sensitive nature of raw data and lack of incentive\nmechanism prevent these valuable data from being fully exploited. Addressing\nthese challenges, this paper proposes inclusive and incentivized personalized\nfederated learning (iPFL), which incentivizes data holders with diverse\npurposes to collaboratively train personalized models without revealing raw\ndata. iPFL constructs a model-sharing market by solving a graph-based training\noptimization and incorporates an incentive mechanism based on game theory\nprinciples. Theoretical analysis shows that iPFL adheres to two key incentive\nproperties: individual rationality and truthfulness. Empirical studies on\neleven AI tasks (e.g., large language models' instruction-following tasks)\ndemonstrate that iPFL consistently achieves the highest economic utility, and\nbetter or comparable model performance compared to baseline methods. We\nanticipate that our iPFL can serve as a valuable technique for boosting future\nAI models on decentralized private data while making everyone satisfied.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02462v1",
    "published_date": "2025-05-05 08:45:26 UTC",
    "updated_date": "2025-05-05 08:45:26 UTC"
  },
  {
    "arxiv_id": "2505.02443v1",
    "title": "Investigating the Impact of Personalized AI Tutors on Language Learning Performance",
    "authors": [
      "Simon Suh"
    ],
    "abstract": "Driven by the global shift towards online learning prompted by the COVID 19\npandemic, Artificial Intelligence has emerged as a pivotal player in the field\nof education. Intelligent Tutoring Systems offer a new method of personalized\nteaching, replacing the limitations of traditional teaching methods. However,\nconcerns arise about the ability of AI tutors to address skill development and\nengagement during the learning process. In this paper, I will conduct a quasi\nexperiment with paired sample t test on 34 students pre and post use of AI\ntutors in language learning platforms like Santa and Duolingo to examine the\nrelationship between students engagement, academic performance, and students\nsatisfaction during a personalized language learning experience.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2.6; K.3.1"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 4 figures, 1 table, Uses three theoretical frameworks like\n  Domain modeling, Gardner Theory of Multiple Intelligences, and Zone of\n  Proximal Development",
    "pdf_url": "http://arxiv.org/pdf/2505.02443v1",
    "published_date": "2025-05-05 08:11:20 UTC",
    "updated_date": "2025-05-05 08:11:20 UTC"
  },
  {
    "arxiv_id": "2505.02441v1",
    "title": "MSFNet-CPD: Multi-Scale Cross-Modal Fusion Network for Crop Pest Detection",
    "authors": [
      "Jiaqi Zhang",
      "Zhuodong Liu",
      "Kejian Yu"
    ],
    "abstract": "Accurate identification of agricultural pests is essential for crop\nprotection but remains challenging due to the large intra-class variance and\nfine-grained differences among pest species. While deep learning has advanced\npest detection, most existing approaches rely solely on low-level visual\nfeatures and lack effective multi-modal integration, leading to limited\naccuracy and poor interpretability. Moreover, the scarcity of high-quality\nmulti-modal agricultural datasets further restricts progress in this field. To\naddress these issues, we construct two novel multi-modal benchmarks-CTIP102 and\nSTIP102-based on the widely-used IP102 dataset, and introduce a Multi-scale\nCross-Modal Fusion Network (MSFNet-CPD) for robust pest detection. Our approach\nenhances visual quality via a super-resolution reconstruction module, and feeds\nboth the original and reconstructed images into the network to improve clarity\nand detection performance. To better exploit semantic cues, we propose an\nImage-Text Fusion (ITF) module for joint modeling of visual and textual\nfeatures, and an Image-Text Converter (ITC) that reconstructs fine-grained\ndetails across multiple scales to handle challenging backgrounds. Furthermore,\nwe introduce an Arbitrary Combination Image Enhancement (ACIE) strategy to\ngenerate a more complex and diverse pest detection dataset, MTIP102, improving\nthe model's generalization to real-world scenarios. Extensive experiments\ndemonstrate that MSFNet-CPD consistently outperforms state-of-the-art methods\non multiple pest detection benchmarks. All code and datasets will be made\npublicly available at: https://github.com/Healer-ML/MSFNet-CPD.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02441v1",
    "published_date": "2025-05-05 08:10:22 UTC",
    "updated_date": "2025-05-05 08:10:22 UTC"
  },
  {
    "arxiv_id": "2505.02439v1",
    "title": "ReeM: Ensemble Building Thermodynamics Model for Efficient HVAC Control via Hierarchical Reinforcement Learning",
    "authors": [
      "Yang Deng",
      "Yaohui Liu",
      "Rui Liang",
      "Dafang Zhao",
      "Donghua Xie",
      "Ittetsu Taniguchi",
      "Dan Wang"
    ],
    "abstract": "The building thermodynamics model, which predicts real-time indoor\ntemperature changes under potential HVAC (Heating, Ventilation, and Air\nConditioning) control operations, is crucial for optimizing HVAC control in\nbuildings. While pioneering studies have attempted to develop such models for\nvarious building environments, these models often require extensive data\ncollection periods and rely heavily on expert knowledge, making the modeling\nprocess inefficient and limiting the reusability of the models. This paper\nexplores a model ensemble perspective that utilizes existing developed models\nas base models to serve a target building environment, thereby providing\naccurate predictions while reducing the associated efforts. Given that building\ndata streams are non-stationary and the number of base models may increase, we\npropose a Hierarchical Reinforcement Learning (HRL) approach to dynamically\nselect and weight the base models. Our approach employs a two-tiered\ndecision-making process: the high-level focuses on model selection, while the\nlow-level determines the weights of the selected models. We thoroughly evaluate\nthe proposed approach through offline experiments and an on-site case study,\nand the experimental results demonstrate the effectiveness of our method.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02439v1",
    "published_date": "2025-05-05 08:09:36 UTC",
    "updated_date": "2025-05-05 08:09:36 UTC"
  },
  {
    "arxiv_id": "2505.02435v1",
    "title": "A New Approach to Backtracking Counterfactual Explanations: A Causal Framework for Efficient Model Interpretability",
    "authors": [
      "Pouria Fatemi",
      "Ehsan Sharifian",
      "Mohammad Hossein Yassaee"
    ],
    "abstract": "Counterfactual explanations enhance interpretability by identifying\nalternative inputs that produce different outputs, offering localized insights\ninto model decisions. However, traditional methods often neglect causal\nrelationships, leading to unrealistic examples. While newer approaches\nintegrate causality, they are computationally expensive. To address these\nchallenges, we propose an efficient method based on backtracking\ncounterfactuals that incorporates causal reasoning to generate actionable\nexplanations. We first examine the limitations of existing methods and then\nintroduce our novel approach and its features. We also explore the relationship\nbetween our method and previous techniques, demonstrating that it generalizes\nthem in specific scenarios. Finally, experiments show that our method provides\ndeeper insights into model outputs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02435v1",
    "published_date": "2025-05-05 08:01:56 UTC",
    "updated_date": "2025-05-05 08:01:56 UTC"
  },
  {
    "arxiv_id": "2505.02433v1",
    "title": "FairPO: Robust Preference Optimization for Fair Multi-Label Learning",
    "authors": [
      "Soumen Kumar Mondal",
      "Akshit Varmora",
      "Prateek Chanda",
      "Ganesh Ramakrishnan"
    ],
    "abstract": "We propose FairPO, a novel framework designed to promote fairness in\nmulti-label classification by directly optimizing preference signals with a\ngroup robustness perspective. In our framework, the set of labels is\npartitioned into privileged and non-privileged groups, and a preference-based\nloss inspired by Direct Preference Optimization (DPO) is employed to more\neffectively differentiate true positive labels from confusing negatives within\nthe privileged group, while preserving baseline classification performance for\nnon-privileged labels. By framing the learning problem as a robust optimization\nover groups, our approach dynamically adjusts the training emphasis toward\ngroups with poorer performance, thereby mitigating bias and ensuring a fairer\ntreatment across diverse label categories. In addition, we outline plans to\nextend this approach by investigating alternative loss formulations such as\nSimple Preference Optimisation (SimPO) and Contrastive Preference Optimization\n(CPO) to exploit reference-free reward formulations and contrastive training\nsignals. Furthermore, we plan to extend FairPO with multilabel generation\ncapabilities, enabling the model to dynamically generate diverse and coherent\nlabel sets for ambiguous inputs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02433v1",
    "published_date": "2025-05-05 07:58:54 UTC",
    "updated_date": "2025-05-05 07:58:54 UTC"
  },
  {
    "arxiv_id": "2505.02426v1",
    "title": "Towards One-shot Federated Learning: Advances, Challenges, and Future Directions",
    "authors": [
      "Flora Amato",
      "Lingyu Qiu",
      "Mohammad Tanveer",
      "Salvatore Cuomo",
      "Fabio Giampaolo",
      "Francesco Piccialli"
    ],
    "abstract": "One-shot FL enables collaborative training in a single round, eliminating the\nneed for iterative communication, making it particularly suitable for use in\nresource-constrained and privacy-sensitive applications. This survey offers a\nthorough examination of One-shot FL, highlighting its distinct operational\nframework compared to traditional federated approaches. One-shot FL supports\nresource-limited devices by enabling single-round model aggregation while\nmaintaining data locality. The survey systematically categorizes existing\nmethodologies, emphasizing advancements in client model initialization,\naggregation techniques, and strategies for managing heterogeneous data\ndistributions. Furthermore, we analyze the limitations of current approaches,\nparticularly in terms of scalability and generalization in non-IID settings. By\nanalyzing cutting-edge techniques and outlining open challenges, this survey\naspires to provide a comprehensive reference for researchers and practitioners\naiming to design and implement One-shot FL systems, advancing the development\nand adoption of One-shot FL solutions in a real-world, resource-constrained\nscenario.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02426v1",
    "published_date": "2025-05-05 07:46:21 UTC",
    "updated_date": "2025-05-05 07:46:21 UTC"
  },
  {
    "arxiv_id": "2505.02417v1",
    "title": "T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models",
    "authors": [
      "Yunfeng Ge",
      "Jiawei Li",
      "Yiji Zhao",
      "Haomin Wen",
      "Zhao Li",
      "Meikang Qiu",
      "Hongyan Li",
      "Ming Jin",
      "Shirui Pan"
    ],
    "abstract": "Text-to-Time Series generation holds significant potential to address\nchallenges such as data sparsity, imbalance, and limited availability of\nmultimodal time series datasets across domains. While diffusion models have\nachieved remarkable success in Text-to-X (e.g., vision and audio data)\ngeneration, their use in time series generation remains in its nascent stages.\nExisting approaches face two critical limitations: (1) the lack of systematic\nexploration of general-proposed time series captions, which are often\ndomain-specific and struggle with generalization; and (2) the inability to\ngenerate time series of arbitrary lengths, limiting their applicability to\nreal-world scenarios. In this work, we first categorize time series captions\ninto three levels: point-level, fragment-level, and instance-level.\nAdditionally, we introduce a new fragment-level dataset containing over 600,000\nhigh-resolution time series-text pairs. Second, we propose Text-to-Series\n(T2S), a diffusion-based framework that bridges the gap between natural\nlanguage and time series in a domain-agnostic manner. T2S employs a\nlength-adaptive variational autoencoder to encode time series of varying\nlengths into consistent latent embeddings. On top of that, T2S effectively\naligns textual representations with latent embeddings by utilizing Flow\nMatching and employing Diffusion Transformer as the denoiser. We train T2S in\nan interleaved paradigm across multiple lengths, allowing it to generate\nsequences of any desired length. Extensive evaluations demonstrate that T2S\nachieves state-of-the-art performance across 13 datasets spanning 12 domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.02417v1",
    "published_date": "2025-05-05 07:22:54 UTC",
    "updated_date": "2025-05-05 07:22:54 UTC"
  },
  {
    "arxiv_id": "2505.02413v1",
    "title": "Task-Oriented Semantic Communication in Large Multimodal Models-based Vehicle Networks",
    "authors": [
      "Baoxia Du",
      "Hongyang Du",
      "Dusit Niyato",
      "Ruidong Li"
    ],
    "abstract": "Task-oriented semantic communication has emerged as a fundamental approach\nfor enhancing performance in various communication scenarios. While recent\nadvances in Generative Artificial Intelligence (GenAI), such as Large Language\nModels (LLMs), have been applied to semantic communication designs, the\npotential of Large Multimodal Models (LMMs) remains largely unexplored. In this\npaper, we investigate an LMM-based vehicle AI assistant using a Large Language\nand Vision Assistant (LLaVA) and propose a task-oriented semantic communication\nframework to facilitate efficient interaction between users and cloud servers.\nTo reduce computational demands and shorten response time, we optimize LLaVA's\nimage slicing to selectively focus on areas of utmost interest to users.\nAdditionally, we assess the importance of image patches by combining objective\nand subjective user attention, adjusting energy usage for transmitting semantic\ninformation. This strategy optimizes resource utilization, ensuring precise\ntransmission of critical information. We construct a Visual Question Answering\n(VQA) dataset for traffic scenarios to evaluate effectiveness. Experimental\nresults show that our semantic communication framework significantly increases\naccuracy in answering questions under the same channel conditions, performing\nparticularly well in environments with poor Signal-to-Noise Ratios (SNR).\nAccuracy can be improved by 13.4% at an SNR of 12dB and 33.1% at 10dB,\nrespectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02413v1",
    "published_date": "2025-05-05 07:18:47 UTC",
    "updated_date": "2025-05-05 07:18:47 UTC"
  },
  {
    "arxiv_id": "2505.02410v1",
    "title": "Bielik 11B v2 Technical Report",
    "authors": [
      "Krzysztof Ociepa",
      "Łukasz Flis",
      "Krzysztof Wróbel",
      "Adrian Gwoździej",
      "Remigiusz Kinas"
    ],
    "abstract": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02410v1",
    "published_date": "2025-05-05 07:03:41 UTC",
    "updated_date": "2025-05-05 07:03:41 UTC"
  },
  {
    "arxiv_id": "2505.02396v1",
    "title": "Diagnostic Uncertainty in Pneumonia Detection using CNN MobileNetV2 and CNN from Scratch",
    "authors": [
      "Kennard Norbert Sudiardjo",
      "Islam Nur Alam",
      "Wilson Wijaya",
      "Lili Ayu Wulandhari"
    ],
    "abstract": "Pneumonia Diagnosis, though it is crucial for an effective treatment, it can\nbe hampered by uncertainty. This uncertainty starts to arise due to some\nfactors like atypical presentations, limitations of diagnostic tools such as\nchest X-rays, and the presence of co-existing respiratory conditions. This\nresearch proposes one of the supervised learning methods, CNN. Using\nMobileNetV2 as the pre-trained one with ResNet101V2 architecture and using\nKeras API as the built from scratch model, for identifying lung diseases\nespecially pneumonia. The datasets used in this research were obtained from the\nwebsite through Kaggle. The result shows that by implementing CNN MobileNetV2\nand CNN from scratch the result is promising. While validating data,\nMobileNetV2 performs with stability and minimal overfitting, while the training\naccuracy increased to 84.87% later it slightly decreased to 78.95%, with\nincreasing validation loss from 0.499 to 0.6345. Nonetheless, MobileNetV2 is\nmore stable. Although it takes more time to train each epoch. Meanwhile, after\nthe 10th epoch, the Scratch model displayed more instability and overfitting\ndespite having higher validation accuracy, training accuracy decreased\nsignificantly to 78.12% and the validation loss increased from 0.5698 to\n1.1809. With these results, ResNet101V2 offers stability, and the Scratch model\noffers high accuracy.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02396v1",
    "published_date": "2025-05-05 06:40:08 UTC",
    "updated_date": "2025-05-05 06:40:08 UTC"
  },
  {
    "arxiv_id": "2505.02391v1",
    "title": "Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL",
    "authors": [
      "Jiarui Yao",
      "Yifan Hao",
      "Hanning Zhang",
      "Hanze Dong",
      "Wei Xiong",
      "Nan Jiang",
      "Tong Zhang"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning in large language models (LLMs) can be\nformalized as a latent variable problem, where the model needs to generate\nintermediate reasoning steps. While prior approaches such as iterative\nreward-ranked fine-tuning (RAFT) have relied on such formulations, they\ntypically apply uniform inference budgets across prompts, which fails to\naccount for variability in difficulty and convergence behavior. This work\nidentifies the main bottleneck in CoT training as inefficient stochastic\ngradient estimation due to static sampling strategies. We propose GVM-RAFT, a\nprompt-specific Dynamic Sample Allocation Strategy designed to minimize\nstochastic gradient variance under a computational budget constraint. The\nmethod dynamically allocates computational resources by monitoring prompt\nacceptance rates and stochastic gradient norms, ensuring that the resulting\ngradient variance is minimized. Our theoretical analysis shows that the\nproposed dynamic sampling strategy leads to accelerated convergence guarantees\nunder suitable conditions. Experiments on mathematical reasoning show that\nGVM-RAFT achieves a 2-4x speedup and considerable accuracy improvements over\nvanilla RAFT. The proposed dynamic sampling strategy is general and can be\nincorporated into other reinforcement learning algorithms, such as GRPO,\nleading to similar improvements in convergence and test accuracy. Our code is\navailable at https://github.com/RLHFlow/GVM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02391v1",
    "published_date": "2025-05-05 06:26:00 UTC",
    "updated_date": "2025-05-05 06:26:00 UTC"
  },
  {
    "arxiv_id": "2505.02390v1",
    "title": "Quantitative Analysis of Performance Drop in DeepSeek Model Quantization",
    "authors": [
      "Enbo Zhao",
      "Yi Shen",
      "Shuming Shi",
      "Jieyun Huang",
      "Zhihao Chen",
      "Ning Wang",
      "Siqi Xiao",
      "Jian Zhang",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "abstract": "Recently, there is a high demand for deploying DeepSeek-R1 and V3 locally,\npossibly because the official service often suffers from being busy and some\norganizations have data privacy concerns. While single-machine deployment\noffers infrastructure simplicity, the models' 671B FP8 parameter configuration\nexceeds the practical memory limits of a standard 8-GPU machine. Quantization\nis a widely used technique that helps reduce model memory consumption. However,\nit is unclear what the performance of DeepSeek-R1 and V3 will be after being\nquantized. This technical report presents the first quantitative evaluation of\nmulti-bitwidth quantization across the complete DeepSeek model spectrum. Key\nfindings reveal that 4-bit quantization maintains little performance\ndegradation versus FP8 while enabling single-machine deployment on standard\nNVIDIA GPU devices. We further propose DQ3_K_M, a dynamic 3-bit quantization\nmethod that significantly outperforms traditional Q3_K_M variant on various\nbenchmarks, which is also comparable with 4-bit quantization (Q4_K_M) approach\nin most tasks. Moreover, DQ3_K_M supports single-machine deployment\nconfigurations for both NVIDIA H100/A100 and Huawei 910B. Our implementation of\nDQ3\\_K\\_M is released at https://github.com/UnicomAI/DeepSeek-Eval, containing\noptimized 3-bit quantized variants of both DeepSeek-R1 and DeepSeek-V3.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02390v1",
    "published_date": "2025-05-05 06:25:20 UTC",
    "updated_date": "2025-05-05 06:25:20 UTC"
  },
  {
    "arxiv_id": "2505.02388v1",
    "title": "MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans",
    "authors": [
      "Huangyue Yu",
      "Baoxiong Jia",
      "Yixin Chen",
      "Yandan Yang",
      "Puhao Li",
      "Rongpeng Su",
      "Jiaxin Li",
      "Qing Li",
      "Wei Liang",
      "Song-Chun Zhu",
      "Tengyu Liu",
      "Siyuan Huang"
    ],
    "abstract": "Embodied AI (EAI) research requires high-quality, diverse 3D scenes to\neffectively support skill acquisition, sim-to-real transfer, and\ngeneralization. Achieving these quality standards, however, necessitates the\nprecise replication of real-world object diversity. Existing datasets\ndemonstrate that this process heavily relies on artist-driven designs, which\ndemand substantial human effort and present significant scalability challenges.\nTo scalably produce realistic and interactive 3D scenes, we first present\nMetaScenes, a large-scale, simulatable 3D scene dataset constructed from\nreal-world scans, which includes 15366 objects spanning 831 fine-grained\ncategories. Then, we introduce Scan2Sim, a robust multi-modal alignment model,\nwhich enables the automated, high-quality replacement of assets, thereby\neliminating the reliance on artist-driven designs for scaling 3D scenes. We\nfurther propose two benchmarks to evaluate MetaScenes: a detailed scene\nsynthesis task focused on small item layouts for robotic manipulation and a\ndomain transfer task in vision-and-language navigation (VLN) to validate\ncross-domain transfer. Results confirm MetaScene's potential to enhance EAI by\nsupporting more generalizable agent learning and sim-to-real applications,\nintroducing new possibilities for EAI research. Project website:\nhttps://meta-scenes.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02388v1",
    "published_date": "2025-05-05 06:13:25 UTC",
    "updated_date": "2025-05-05 06:13:25 UTC"
  },
  {
    "arxiv_id": "2505.02387v1",
    "title": "RM-R1: Reward Modeling as Reasoning",
    "authors": [
      "Xiusi Chen",
      "Gaotang Li",
      "Ziqi Wang",
      "Bowen Jin",
      "Cheng Qian",
      "Yu Wang",
      "Hongru Wang",
      "Yu Zhang",
      "Denghui Zhang",
      "Tong Zhang",
      "Hanghang Tong",
      "Heng Ji"
    ],
    "abstract": "Reward modeling is essential for aligning large language models (LLMs) with\nhuman preferences, especially through reinforcement learning from human\nfeedback (RLHF). To provide accurate reward signals, a reward model (RM) should\nstimulate deep thinking and conduct interpretable reasoning before assigning a\nscore or a judgment. However, existing RMs either produce opaque scalar scores\nor directly generate the prediction of a preferred answer, making them struggle\nto integrate natural language critiques, thus lacking interpretability.\nInspired by recent advances of long chain-of-thought (CoT) on\nreasoning-intensive tasks, we hypothesize and validate that integrating\nreasoning capabilities into reward modeling significantly enhances RM's\ninterpretability and performance. In this work, we introduce a new class of\ngenerative reward models -- Reasoning Reward Models (ReasRMs) -- which\nformulate reward modeling as a reasoning task. We propose a reasoning-oriented\ntraining pipeline and train a family of ReasRMs, RM-R1. The training consists\nof two key stages: (1) distillation of high-quality reasoning chains and (2)\nreinforcement learning with verifiable rewards. RM-R1 improves LLM rollouts by\nself-generating reasoning traces or chat-specific rubrics and evaluating\ncandidate responses against them. Empirically, our models achieve\nstate-of-the-art or near state-of-the-art performance of generative RMs across\nmultiple comprehensive reward model benchmarks, outperforming much larger\nopen-weight models (e.g., Llama3.1-405B) and proprietary ones (e.g., GPT-4o) by\nup to 13.8%. Beyond final performance, we perform thorough empirical analysis\nto understand the key ingredients of successful ReasRM training. To facilitate\nfuture research, we release six ReasRM models along with code and data at\nhttps://github.com/RM-R1-UIUC/RM-R1.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02387v1",
    "published_date": "2025-05-05 06:11:12 UTC",
    "updated_date": "2025-05-05 06:11:12 UTC"
  },
  {
    "arxiv_id": "2505.02370v1",
    "title": "SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing",
    "authors": [
      "Ming Li",
      "Xin Gu",
      "Fan Chen",
      "Xiaoying Xing",
      "Longyin Wen",
      "Chen Chen",
      "Sijie Zhu"
    ],
    "abstract": "Due to the challenges of manually collecting accurate editing data, existing\ndatasets are typically constructed using various automated methods, leading to\nnoisy supervision signals caused by the mismatch between editing instructions\nand original-edited image pairs. Recent efforts attempt to improve editing\nmodels through generating higher-quality edited images, pre-training on\nrecognition tasks, or introducing vision-language models (VLMs) but fail to\nresolve this fundamental issue. In this paper, we offer a novel solution by\nconstructing more effective editing instructions for given image pairs. This\nincludes rectifying the editing instructions to better align with the\noriginal-edited image pairs and using contrastive editing instructions to\nfurther enhance their effectiveness. Specifically, we find that editing models\nexhibit specific generation attributes at different inference steps,\nindependent of the text. Based on these prior attributes, we define a unified\nguide for VLMs to rectify editing instructions. However, there are some\nchallenging editing scenarios that cannot be resolved solely with rectified\ninstructions. To this end, we further construct contrastive supervision signals\nwith positive and negative instructions and introduce them into the model\ntraining using triplet loss, thereby further facilitating supervision\neffectiveness. Our method does not require the VLM modules or pre-training\ntasks used in previous work, offering a more direct and efficient way to\nprovide better supervision signals, and providing a novel, simple, and\neffective solution for instruction-based image editing. Results on multiple\nbenchmarks demonstrate that our method significantly outperforms existing\napproaches. Compared with previous SOTA SmartEdit, we achieve 9.19%\nimprovements on the Real-Edit benchmark with 30x less training data and 13x\nsmaller model size.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code, Data and Models are available at:\n  https://github.com/bytedance/SuperEdit",
    "pdf_url": "http://arxiv.org/pdf/2505.02370v1",
    "published_date": "2025-05-05 05:19:40 UTC",
    "updated_date": "2025-05-05 05:19:40 UTC"
  },
  {
    "arxiv_id": "2505.02369v2",
    "title": "Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks",
    "authors": [
      "Juyoung Yun"
    ],
    "abstract": "Generalizing well in deep neural networks remains a core challenge,\nparticularly due to their tendency to converge to sharp minima that degrade\nrobustness. Sharpness-Aware Minimization (SAM) mitigates this by seeking\nflatter minima but perturbs parameters using the full gradient, which can\ninclude statistically insignificant directions. We propose ZSharp, a simple yet\neffective extension to SAM that applies layer-wise Z-score normalization\nfollowed by percentile-based filtering to retain only statistically significant\ngradient components. This selective perturbation aligns updates with\ncurvature-sensitive directions, enhancing generalization without requiring\narchitectural changes. ZSharp introduces only one additional hyperparameter,\nthe percentile threshold, and remains fully compatible with existing SAM\nvariants. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet using ResNet,\nVGG, and Vision Transformers show that ZSharp consistently outperforms SAM and\nits variants in test accuracy, particularly on deeper and transformer-based\nmodels. These results demonstrate that ZSharp is a principled and lightweight\nimprovement for sharpness-aware optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "cs.NE",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02369v2",
    "published_date": "2025-05-05 05:13:12 UTC",
    "updated_date": "2025-05-06 01:56:40 UTC"
  },
  {
    "arxiv_id": "2505.02366v1",
    "title": "JTCSE: Joint Tensor-Modulus Constraints and Cross-Attention for Unsupervised Contrastive Learning of Sentence Embeddings",
    "authors": [
      "Tianyu Zong",
      "Hongzhu Yi",
      "Bingkang Shi",
      "Yuanxiang Wang",
      "Jungang Xu"
    ],
    "abstract": "Unsupervised contrastive learning has become a hot research topic in natural\nlanguage processing. Existing works usually aim at constraining the orientation\ndistribution of the representations of positive and negative samples in the\nhigh-dimensional semantic space in contrastive learning, but the semantic\nrepresentation tensor possesses both modulus and orientation features, and the\nexisting works ignore the modulus feature of the representations and cause\ninsufficient contrastive learning. % Therefore, we firstly propose a training\nobjective that aims at modulus constraints on the semantic representation\ntensor, to strengthen the alignment between the positive samples in contrastive\nlearning. Therefore, we first propose a training objective that is designed to\nimpose modulus constraints on the semantic representation tensor, to strengthen\nthe alignment between positive samples in contrastive learning. Then, the\nBERT-like model suffers from the phenomenon of sinking attention, leading to a\nlack of attention to CLS tokens that aggregate semantic information. In\nresponse, we propose a cross-attention structure among the twin-tower ensemble\nmodels to enhance the model's attention to CLS token and optimize the quality\nof CLS Pooling. Combining the above two motivations, we propose a new\n\\textbf{J}oint \\textbf{T}ensor representation modulus constraint and\n\\textbf{C}ross-attention unsupervised contrastive learning \\textbf{S}entence\n\\textbf{E}mbedding representation framework JTCSE, which we evaluate in seven\nsemantic text similarity computation tasks, and the experimental results show\nthat JTCSE's twin-tower ensemble model and single-tower distillation model\noutperform the other baselines and become the current SOTA. In addition, we\nhave conducted an extensive zero-shot downstream task evaluation, which shows\nthat JTCSE outperforms other baselines overall on more than 130 tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02366v1",
    "published_date": "2025-05-05 05:09:21 UTC",
    "updated_date": "2025-05-05 05:09:21 UTC"
  },
  {
    "arxiv_id": "2505.02362v1",
    "title": "Advancing Email Spam Detection: Leveraging Zero-Shot Learning and Large Language Models",
    "authors": [
      "Ghazaleh SHirvani",
      "Saeid Ghasemshirazi"
    ],
    "abstract": "Email spam detection is a critical task in modern communication systems,\nessential for maintaining productivity, security, and user experience.\nTraditional machine learning and deep learning approaches, while effective in\nstatic settings, face significant limitations in adapting to evolving spam\ntactics, addressing class imbalance, and managing data scarcity. These\nchallenges necessitate innovative approaches that reduce dependency on\nextensive labeled datasets and frequent retraining. This study investigates the\neffectiveness of Zero-Shot Learning using FLAN-T5, combined with advanced\nNatural Language Processing (NLP) techniques such as BERT for email spam\ndetection. By employing BERT to preprocess and extract critical information\nfrom email content, and FLAN-T5 to classify emails in a Zero-Shot framework,\nthe proposed approach aims to address the limitations of traditional spam\ndetection systems. The integration of FLAN-T5 and BERT enables robust spam\ndetection without relying on extensive labeled datasets or frequent retraining,\nmaking it highly adaptable to unseen spam patterns and adversarial\nenvironments. This research highlights the potential of leveraging zero-shot\nlearning and NLPs for scalable and efficient spam detection, providing insights\ninto their capability to address the dynamic and challenging nature of spam\ndetection tasks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02362v1",
    "published_date": "2025-05-05 04:48:20 UTC",
    "updated_date": "2025-05-05 04:48:20 UTC"
  },
  {
    "arxiv_id": "2505.02360v1",
    "title": "Catastrophic Overfitting, Entropy Gap and Participation Ratio: A Noiseless $l^p$ Norm Solution for Fast Adversarial Training",
    "authors": [
      "Fares B. Mehouachi",
      "Saif Eddin Jabari"
    ],
    "abstract": "Adversarial training is a cornerstone of robust deep learning, but fast\nmethods like the Fast Gradient Sign Method (FGSM) often suffer from\nCatastrophic Overfitting (CO), where models become robust to single-step\nattacks but fail against multi-step variants. While existing solutions rely on\nnoise injection, regularization, or gradient clipping, we propose a novel\nsolution that purely controls the $l^p$ training norm to mitigate CO.\n  Our study is motivated by the empirical observation that CO is more prevalent\nunder the $l^{\\infty}$ norm than the $l^2$ norm. Leveraging this insight, we\ndevelop a framework for generalized $l^p$ attack as a fixed point problem and\ncraft $l^p$-FGSM attacks to understand the transition mechanics from $l^2$ to\n$l^{\\infty}$. This leads to our core insight: CO emerges when highly\nconcentrated gradients where information localizes in few dimensions interact\nwith aggressive norm constraints. By quantifying gradient concentration through\nParticipation Ratio and entropy measures, we develop an adaptive $l^p$-FGSM\nthat automatically tunes the training norm based on gradient information.\nExtensive experiments demonstrate that this approach achieves strong robustness\nwithout requiring additional regularization or noise injection, providing a\nnovel and theoretically-principled pathway to mitigate the CO problem.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02360v1",
    "published_date": "2025-05-05 04:41:21 UTC",
    "updated_date": "2025-05-05 04:41:21 UTC"
  },
  {
    "arxiv_id": "2505.02352v1",
    "title": "Social Biases in Knowledge Representations of Wikidata separates Global North from Global South",
    "authors": [
      "Paramita Das",
      "Sai Keerthana Karnam",
      "Aditya Soni",
      "Animesh Mukherjee"
    ],
    "abstract": "Knowledge Graphs have become increasingly popular due to their wide usage in\nvarious downstream applications, including information retrieval, chatbot\ndevelopment, language model construction, and many others. Link prediction (LP)\nis a crucial downstream task for knowledge graphs, as it helps to address the\nproblem of the incompleteness of the knowledge graphs. However, previous\nresearch has shown that knowledge graphs, often created in a (semi) automatic\nmanner, are not free from social biases. These biases can have harmful effects\non downstream applications, especially by leading to unfair behavior toward\nminority groups. To understand this issue in detail, we develop a framework --\nAuditLP -- deploying fairness metrics to identify biased outcomes in LP,\nspecifically how occupations are classified as either male or female-dominated\nbased on gender as a sensitive attribute. We have experimented with the\nsensitive attribute of age and observed that occupations are categorized as\nyoung-biased, old-biased, and age-neutral. We conduct our experiments on a\nlarge number of knowledge triples that belong to 21 different geographies\nextracted from the open-sourced knowledge graph, Wikidata. Our study shows that\nthe variance in the biased outcomes across geographies neatly mirrors the\nsocio-economic and cultural division of the world, resulting in a transparent\npartition of the Global North from the Global South.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02352v1",
    "published_date": "2025-05-05 04:21:12 UTC",
    "updated_date": "2025-05-05 04:21:12 UTC"
  },
  {
    "arxiv_id": "2505.02347v1",
    "title": "Temporal Robustness in Discrete Time Linear Dynamical Systems",
    "authors": [
      "Nilava Metya",
      "Arunesh Sinha"
    ],
    "abstract": "Discrete time linear dynamical systems, including Markov chains, have found\nmany applications. However, in some problems, there is uncertainty about the\ntime horizon for which the system runs. This creates uncertainty about the cost\n(or reward) incurred based on the state distribution when the system stops.\nGiven past data samples of how long a system ran, we propose to theoretically\nanalyze a distributional robust cost estimation task in a Wasserstein ambiguity\nset, instead of learning a probability distribution from a few samples. Towards\nthis, we show an equivalence between a discrete time Markov Chain on a\nprobability simplex and a global asymptotic stable (GAS) discrete time linear\ndynamical system, allowing us to base our study on a GAS system only. Then, we\nprovide various polynomial time algorithms and hardness results for different\ncases in our theoretical study, including a fundamental result about\nWasserstein distance based polytope.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02347v1",
    "published_date": "2025-05-05 04:02:33 UTC",
    "updated_date": "2025-05-05 04:02:33 UTC"
  },
  {
    "arxiv_id": "2505.02322v1",
    "title": "HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking",
    "authors": [
      "Runquan Gui",
      "Zhihai Wang",
      "Jie Wang",
      "Chi Ma",
      "Huiling Zhen",
      "Mingxuan Yuan",
      "Jianye Hao",
      "Defu Lian",
      "Enhong Chen",
      "Feng Wu"
    ],
    "abstract": "Recent advancements have significantly enhanced the performance of large\nlanguage models (LLMs) in tackling complex reasoning tasks, achieving notable\nsuccess in domains like mathematical and logical reasoning. However, these\nmethods encounter challenges with complex planning tasks, primarily due to\nextended reasoning steps, diverse constraints, and the challenge of handling\nmultiple distinct sub-tasks. To address these challenges, we propose HyperTree\nPlanning (HTP), a novel reasoning paradigm that constructs hypertree-structured\nplanning outlines for effective planning. The hypertree structure enables LLMs\nto engage in hierarchical thinking by flexibly employing the divide-and-conquer\nstrategy, effectively breaking down intricate reasoning steps, accommodating\ndiverse constraints, and managing multiple distinct sub-tasks in a\nwell-organized manner. We further introduce an autonomous planning framework\nthat completes the planning process by iteratively refining and expanding the\nhypertree-structured planning outlines. Experiments demonstrate the\neffectiveness of HTP, achieving state-of-the-art accuracy on the TravelPlanner\nbenchmark with Gemini-1.5-Pro, resulting in a 3.6 times performance improvement\nover o1-preview.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2406.14228 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2505.02322v1",
    "published_date": "2025-05-05 02:38:58 UTC",
    "updated_date": "2025-05-05 02:38:58 UTC"
  },
  {
    "arxiv_id": "2505.02314v1",
    "title": "NeuroSim V1.5: Improved Software Backbone for Benchmarking Compute-in-Memory Accelerators with Device and Circuit-level Non-idealities",
    "authors": [
      "James Read",
      "Ming-Yen Lee",
      "Wei-Hsing Huang",
      "Yuan-Chun Luo",
      "Anni Lu",
      "Shimeng Yu"
    ],
    "abstract": "The exponential growth of artificial intelligence (AI) applications has\nexposed the inefficiency of conventional von Neumann architectures, where\nfrequent data transfers between compute units and memory create significant\nenergy and latency bottlenecks. Analog Computing-in-Memory (ACIM) addresses\nthis challenge by performing multiply-accumulate (MAC) operations directly in\nthe memory arrays, substantially reducing data movement. However, designing\nrobust ACIM accelerators requires accurate modeling of device- and\ncircuit-level non-idealities. In this work, we present NeuroSim V1.5,\nintroducing several key advances: (1) seamless integration with TensorRT's\npost-training quantization flow enabling support for more neural networks\nincluding transformers, (2) a flexible noise injection methodology built on\npre-characterized statistical models, making it straightforward to incorporate\ndata from SPICE simulations or silicon measurements, (3) expanded device\nsupport including emerging non-volatile capacitive memories, and (4) up to 6.5x\nfaster runtime than NeuroSim V1.4 through optimized behavioral simulation. The\ncombination of these capabilities uniquely enables systematic design space\nexploration across both accuracy and hardware efficiency metrics. Through\nmultiple case studies, we demonstrate optimization of critical design\nparameters while maintaining network accuracy. By bridging high-fidelity noise\nmodeling with efficient simulation, NeuroSim V1.5 advances the design and\nvalidation of next-generation ACIM accelerators. All NeuroSim versions are\navailable open-source at https://github.com/neurosim/NeuroSim.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "15 pages, 9 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.02314v1",
    "published_date": "2025-05-05 02:07:04 UTC",
    "updated_date": "2025-05-05 02:07:04 UTC"
  },
  {
    "arxiv_id": "2505.02313v1",
    "title": "What Is AI Safety? What Do We Want It to Be?",
    "authors": [
      "Jacqueline Harding",
      "Cameron Domenico Kirk-Giannini"
    ],
    "abstract": "The field of AI safety seeks to prevent or reduce the harms caused by AI\nsystems. A simple and appealing account of what is distinctive of AI safety as\na field holds that this feature is constitutive: a research project falls\nwithin the purview of AI safety just in case it aims to prevent or reduce the\nharms caused by AI systems. Call this appealingly simple account The Safety\nConception of AI safety. Despite its simplicity and appeal, we argue that The\nSafety Conception is in tension with at least two trends in the ways AI safety\nresearchers and organizations think and talk about AI safety: first, a tendency\nto characterize the goal of AI safety research in terms of catastrophic risks\nfrom future systems; second, the increasingly popular idea that AI safety can\nbe thought of as a branch of safety engineering. Adopting the methodology of\nconceptual engineering, we argue that these trends are unfortunate: when we\nconsider what concept of AI safety it would be best to have, there are\ncompelling reasons to think that The Safety Conception is the answer.\nDescriptively, The Safety Conception allows us to see how work on topics that\nhave historically been treated as central to the field of AI safety is\ncontinuous with work on topics that have historically been treated as more\nmarginal, like bias, misinformation, and privacy. Normatively, taking The\nSafety Conception seriously means approaching all efforts to prevent or\nmitigate harms from AI systems based on their merits rather than drawing\narbitrary distinctions between them.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02313v1",
    "published_date": "2025-05-05 01:55:00 UTC",
    "updated_date": "2025-05-05 01:55:00 UTC"
  },
  {
    "arxiv_id": "2505.02309v1",
    "title": "Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques",
    "authors": [
      "Sanjay Surendranath Girija",
      "Shashank Kapoor",
      "Lakshit Arora",
      "Dipen Pradhan",
      "Aman Raj",
      "Ankit Shetgaonkar"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized many areas of artificial\nintelligence (AI), but their substantial resource requirements limit their\ndeployment on mobile and edge devices. This survey paper provides a\ncomprehensive overview of techniques for compressing LLMs to enable efficient\ninference in resource-constrained environments. We examine three primary\napproaches: Knowledge Distillation, Model Quantization, and Model Pruning. For\neach technique, we discuss the underlying principles, present different\nvariants, and provide examples of successful applications. We also briefly\ndiscuss complementary techniques such as mixture-of-experts and early-exit\nstrategies. Finally, we highlight promising future directions, aiming to\nprovide a valuable resource for both researchers and practitioners seeking to\noptimize LLMs for edge deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE COMPSAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02309v1",
    "published_date": "2025-05-05 01:27:47 UTC",
    "updated_date": "2025-05-05 01:27:47 UTC"
  },
  {
    "arxiv_id": "2505.02306v1",
    "title": "SafeMate: A Model Context Protocol-Based Multimodal Agent for Emergency Preparedness",
    "authors": [
      "Junfeng Jiao",
      "Jihyung Park",
      "Yiming Xu",
      "Lucy Atkinson"
    ],
    "abstract": "Despite the abundance of public safety documents and emergency protocols,\nmost individuals remain ill-equipped to interpret and act on such information\nduring crises. Traditional emergency decision support systems (EDSS) are\ndesigned for professionals and rely heavily on static documents like PDFs or\nSOPs, which are difficult for non-experts to navigate under stress. This gap\nbetween institutional knowledge and public accessibility poses a critical\nbarrier to effective emergency preparedness and response.\n  We introduce SafeMate, a retrieval-augmented AI assistant that delivers\naccurate, context-aware guidance to general users in both preparedness and\nactive emergency scenarios. Built on the Model Context Protocol (MCP), SafeMate\ndynamically routes user queries to tools for document retrieval, checklist\ngeneration, and structured summarization. It uses FAISS with cosine similarity\nto identify relevant content from trusted sources.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02306v1",
    "published_date": "2025-05-05 01:09:02 UTC",
    "updated_date": "2025-05-05 01:09:02 UTC"
  },
  {
    "arxiv_id": "2505.02299v1",
    "title": "Adaptive Scoring and Thresholding with Human Feedback for Robust Out-of-Distribution Detection",
    "authors": [
      "Daisuke Yamada",
      "Harit Vishwakarma",
      "Ramya Korlakai Vinayak"
    ],
    "abstract": "Machine Learning (ML) models are trained on in-distribution (ID) data but\noften encounter out-of-distribution (OOD) inputs during deployment -- posing\nserious risks in safety-critical domains. Recent works have focused on\ndesigning scoring functions to quantify OOD uncertainty, with score thresholds\ntypically set based solely on ID data to achieve a target true positive rate\n(TPR), since OOD data is limited before deployment. However, these TPR-based\nthresholds leave false positive rates (FPR) uncontrolled, often resulting in\nhigh FPRs where OOD points are misclassified as ID. Moreover, fixed scoring\nfunctions and thresholds lack the adaptivity needed to handle newly observed,\nevolving OOD inputs, leading to sub-optimal performance. To address these\nchallenges, we propose a human-in-the-loop framework that \\emph{safely updates\nboth scoring functions and thresholds on the fly} based on real-world OOD\ninputs. Our method maximizes TPR while strictly controlling FPR at all times,\neven as the system adapts over time. We provide theoretical guarantees for FPR\ncontrol under stationary conditions and present extensive empirical evaluations\non OpenOOD benchmarks to demonstrate that our approach outperforms existing\nmethods by achieving higher TPRs while maintaining FPR control.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02299v1",
    "published_date": "2025-05-05 00:25:14 UTC",
    "updated_date": "2025-05-05 00:25:14 UTC"
  }
]