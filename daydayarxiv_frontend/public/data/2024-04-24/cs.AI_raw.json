[
  {
    "arxiv_id": "2404.16251v3",
    "title": "Prompt Leakage effect and defense strategies for multi-turn LLM interactions",
    "authors": [
      "Divyansh Agarwal",
      "Alexander R. Fabbri",
      "Ben Risher",
      "Philippe Laban",
      "Shafiq Joty",
      "Chien-Sheng Wu"
    ],
    "abstract": "Prompt leakage poses a compelling security and privacy threat in LLM\napplications. Leakage of system prompts may compromise intellectual property,\nand act as adversarial reconnaissance for an attacker. A systematic evaluation\nof prompt leakage threats and mitigation strategies is lacking, especially for\nmulti-turn LLM interactions. In this paper, we systematically investigate LLM\nvulnerabilities against prompt leakage for 10 closed- and open-source LLMs,\nacross four domains. We design a unique threat model which leverages the LLM\nsycophancy effect and elevates the average attack success rate (ASR) from 17.7%\nto 86.2% in a multi-turn setting. Our standardized setup further allows\ndissecting leakage of specific prompt contents such as task instructions and\nknowledge documents. We measure the mitigation effect of 7 black-box defense\nstrategies, along with finetuning an open-source model to defend against\nleakage attempts. We present different combination of defenses against our\nthreat model, including a cost analysis. Our study highlights key takeaways for\nbuilding secure LLM applications and provides directions for research in\nmulti-turn LLM interactions",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16251v3",
    "published_date": "2024-04-24 23:39:58 UTC",
    "updated_date": "2024-07-29 17:16:19 UTC"
  },
  {
    "arxiv_id": "2404.16248v1",
    "title": "URL: Universal Referential Knowledge Linking via Task-instructed Representation Compression",
    "authors": [
      "Zhuoqun Li",
      "Hongyu Lin",
      "Tianshu Wang",
      "Boxi Cao",
      "Yaojie Lu",
      "Weixiang Zhou",
      "Hao Wang",
      "Zhenyu Zeng",
      "Le Sun",
      "Xianpei Han"
    ],
    "abstract": "Linking a claim to grounded references is a critical ability to fulfill human\ndemands for authentic and reliable information. Current studies are limited to\nspecific tasks like information retrieval or semantic matching, where the\nclaim-reference relationships are unique and fixed, while the referential\nknowledge linking (RKL) in real-world can be much more diverse and complex. In\nthis paper, we propose universal referential knowledge linking (URL), which\naims to resolve diversified referential knowledge linking tasks by one unified\nmodel. To this end, we propose a LLM-driven task-instructed representation\ncompression, as well as a multi-view learning approach, in order to effectively\nadapt the instruction following and semantic understanding abilities of LLMs to\nreferential knowledge linking. Furthermore, we also construct a new benchmark\nto evaluate ability of models on referential knowledge linking tasks across\ndifferent scenarios. Experiments demonstrate that universal RKL is challenging\nfor existing approaches, while the proposed framework can effectively resolve\nthe task across various scenarios, and therefore outperforms previous\napproaches by a large margin.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16248v1",
    "published_date": "2024-04-24 23:37:15 UTC",
    "updated_date": "2024-04-24 23:37:15 UTC"
  },
  {
    "arxiv_id": "2404.16893v1",
    "title": "Automatic AI controller that can drive with confidence: steering vehicle with uncertainty knowledge",
    "authors": [
      "Neha Kumari",
      "Sumit Kumar. Sneha Priya",
      "Ayush Kumar",
      "Akash Fogla"
    ],
    "abstract": "In safety-critical systems that interface with the real world, the role of\nuncertainty in decision-making is pivotal, particularly in the context of\nmachine learning models. For the secure functioning of Cyber-Physical Systems\n(CPS), it is imperative to manage such uncertainty adeptly. In this research,\nwe focus on the development of a vehicle's lateral control system using a\nmachine learning framework. Specifically, we employ a Bayesian Neural Network\n(BNN), a probabilistic learning model, to address uncertainty quantification.\nThis capability allows us to gauge the level of confidence or uncertainty in\nthe model's predictions. The BNN based controller is trained using simulated\ndata gathered from the vehicle traversing a single track and subsequently\ntested on various other tracks. We want to share two significant results:\nfirstly, the trained model demonstrates the ability to adapt and effectively\ncontrol the vehicle on multiple similar tracks. Secondly, the quantification of\nprediction confidence integrated into the controller serves as an early-warning\nsystem, signaling when the algorithm lacks confidence in its predictions and is\ntherefore susceptible to failure. By establishing a confidence threshold, we\ncan trigger manual intervention, ensuring that control is relinquished from the\nalgorithm when it operates outside of safe parameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2303.08187",
    "pdf_url": "http://arxiv.org/pdf/2404.16893v1",
    "published_date": "2024-04-24 23:22:37 UTC",
    "updated_date": "2024-04-24 23:22:37 UTC"
  },
  {
    "arxiv_id": "2404.17605v1",
    "title": "Autonomous LLM-driven research from data to human-verifiable research papers",
    "authors": [
      "Tal Ifargan",
      "Lukas Hafner",
      "Maor Kern",
      "Ori Alcalay",
      "Roy Kishony"
    ],
    "abstract": "As AI promises to accelerate scientific discovery, it remains unclear whether\nfully AI-driven research is possible and whether it can adhere to key\nscientific values, such as transparency, traceability and verifiability.\nMimicking human scientific practices, we built data-to-paper, an automation\nplatform that guides interacting LLM agents through a complete stepwise\nresearch process, while programmatically back-tracing information flow and\nallowing human oversight and interactions. In autopilot mode, provided with\nannotated data alone, data-to-paper raised hypotheses, designed research plans,\nwrote and debugged analysis codes, generated and interpreted results, and\ncreated complete and information-traceable research papers. Even though\nresearch novelty was relatively limited, the process demonstrated autonomous\ngeneration of de novo quantitative insights from data. For simple research\ngoals, a fully-autonomous cycle can create manuscripts which recapitulate\npeer-reviewed publications without major errors in about 80-90%, yet as goal\ncomplexity increases, human co-piloting becomes critical for assuring accuracy.\nBeyond the process itself, created manuscripts too are inherently verifiable,\nas information-tracing allows to programmatically chain results, methods and\ndata. Our work thereby demonstrates a potential for AI-driven acceleration of\nscientific discovery while enhancing, rather than jeopardizing, traceability,\ntransparency and verifiability.",
    "categories": [
      "q-bio.OT",
      "cs.AI"
    ],
    "primary_category": "q-bio.OT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.17605v1",
    "published_date": "2024-04-24 23:15:49 UTC",
    "updated_date": "2024-04-24 23:15:49 UTC"
  },
  {
    "arxiv_id": "2404.16233v2",
    "title": "AutoGluon-Multimodal (AutoMM): Supercharging Multimodal AutoML with Foundation Models",
    "authors": [
      "Zhiqiang Tang",
      "Haoyang Fang",
      "Su Zhou",
      "Taojiannan Yang",
      "Zihan Zhong",
      "Tony Hu",
      "Katrin Kirchhoff",
      "George Karypis"
    ],
    "abstract": "AutoGluon-Multimodal (AutoMM) is introduced as an open-source AutoML library\ndesigned specifically for multimodal learning. Distinguished by its exceptional\nease of use, AutoMM enables fine-tuning of foundation models with just three\nlines of code. Supporting various modalities including image, text, and tabular\ndata, both independently and in combination, the library offers a comprehensive\nsuite of functionalities spanning classification, regression, object detection,\nsemantic matching, and image segmentation. Experiments across diverse datasets\nand tasks showcases AutoMM's superior performance in basic classification and\nregression tasks compared to existing AutoML tools, while also demonstrating\ncompetitive results in advanced tasks, aligning with specialized toolboxes\ndesigned for such purposes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AutoML 2024 Conference",
    "pdf_url": "http://arxiv.org/pdf/2404.16233v2",
    "published_date": "2024-04-24 22:28:12 UTC",
    "updated_date": "2024-04-30 21:09:27 UTC"
  },
  {
    "arxiv_id": "2404.16218v1",
    "title": "Efficient NAS with FaDE on Hierarchical Spaces",
    "authors": [
      "Simon Neumeyer",
      "Julian Stier",
      "Michael Granitzer"
    ],
    "abstract": "Neural architecture search (NAS) is a challenging problem. Hierarchical\nsearch spaces allow for cheap evaluations of neural network sub modules to\nserve as surrogate for architecture evaluations. Yet, sometimes the hierarchy\nis too restrictive or the surrogate fails to generalize. We present FaDE which\nuses differentiable architecture search to obtain relative performance\npredictions on finite regions of a hierarchical NAS space. The relative nature\nof these ranks calls for a memory-less, batch-wise outer search algorithm for\nwhich we use an evolutionary algorithm with pseudo-gradient descent. FaDE is\nespecially suited on deep hierarchical, respectively multi-cell search spaces,\nwhich it can explore by linear instead of exponential cost and therefore\neliminates the need for a proxy search space.\n  Our experiments show that firstly, FaDE-ranks on finite regions of the search\nspace correlate with corresponding architecture performances and secondly, the\nranks can empower a pseudo-gradient evolutionary search on the complete neural\narchitecture search space.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "I.2.6"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16218v1",
    "published_date": "2024-04-24 21:33:17 UTC",
    "updated_date": "2024-04-24 21:33:17 UTC"
  },
  {
    "arxiv_id": "2404.16208v1",
    "title": "GPU-RANC: A CUDA Accelerated Simulation Framework for Neuromorphic Architectures",
    "authors": [
      "Sahil Hassan",
      "Michael Inouye",
      "Miguel C. Gonzalez",
      "Ilkin Aliyev",
      "Joshua Mack",
      "Maisha Hafiz",
      "Ali Akoglu"
    ],
    "abstract": "Open-source simulation tools play a crucial role for neuromorphic application\nengineers and hardware architects to investigate performance bottlenecks and\nexplore design optimizations before committing to silicon. Reconfigurable\nArchitecture for Neuromorphic Computing (RANC) is one such tool that offers\nability to execute pre-trained Spiking Neural Network (SNN) models within a\nunified ecosystem through both software-based simulation and FPGA-based\nemulation. RANC has been utilized by the community with its flexible and highly\nparameterized design to study implementation bottlenecks, tune architectural\nparameters or modify neuron behavior based on application insights and study\nthe trade space on hardware performance and network accuracy. In designing\narchitectures for use in neuromorphic computing, there are an incredibly large\nnumber of configuration parameters such as number and precision of weights per\nneuron, neuron and axon counts per core, network topology, and neuron behavior.\nTo accelerate such studies and provide users with a streamlined productive\ndesign space exploration, in this paper we introduce the GPU-based\nimplementation of RANC. We summarize our parallelization approach and quantify\nthe speedup gains achieved with GPU-based tick-accurate simulations across\nvarious use cases. We demonstrate up to 780 times speedup compared to serial\nversion of the RANC simulator based on a 512 neuromorphic core MNIST inference\napplication. We believe that the RANC ecosystem now provides a much more\nfeasible avenue in the research of exploring different optimizations for\naccelerating SNNs and performing richer studies by enabling rapid convergence\nto optimized neuromorphic architectures.",
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "primary_category": "cs.ET",
    "comment": "Accepted for publication in Neuro-Inspired Computational Elements\n  (NICE) Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.16208v1",
    "published_date": "2024-04-24 21:08:21 UTC",
    "updated_date": "2024-04-24 21:08:21 UTC"
  },
  {
    "arxiv_id": "2404.16206v1",
    "title": "Knowledge Graph Completion using Structural and Textual Embeddings",
    "authors": [
      "Sakher Khalil Alqaaidi",
      "Krzysztof Kochut"
    ],
    "abstract": "Knowledge Graphs (KGs) are widely employed in artificial intelligence\napplications, such as question-answering and recommendation systems. However,\nKGs are frequently found to be incomplete. While much of the existing\nliterature focuses on predicting missing nodes for given incomplete KG triples,\nthere remains an opportunity to complete KGs by exploring relations between\nexisting nodes, a task known as relation prediction. In this study, we propose\na relations prediction model that harnesses both textual and structural\ninformation within KGs. Our approach integrates walks-based embeddings with\nlanguage model embeddings to effectively represent nodes. We demonstrate that\nour model achieves competitive results in the relation prediction task when\nevaluated on a widely used dataset.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16206v1",
    "published_date": "2024-04-24 21:04:14 UTC",
    "updated_date": "2024-04-24 21:04:14 UTC"
  },
  {
    "arxiv_id": "2407.09480v1",
    "title": "Using Artificial Intelligence to Unlock Crowdfunding Success for Small Businesses",
    "authors": [
      "Teng Ye",
      "Jingnan Zheng",
      "Junhui Jin",
      "Jingyi Qiu",
      "Wei Ai",
      "Qiaozhu Mei"
    ],
    "abstract": "While small businesses are increasingly turning to online crowdfunding\nplatforms for essential funding, over 40% of these campaigns may fail to raise\nany money, especially those from low socio-economic areas. We utilize the\nlatest advancements in AI technology to identify crucial factors that influence\nthe success of crowdfunding campaigns and to improve their fundraising outcomes\nby strategically optimizing these factors. Our best-performing machine learning\nmodel accurately predicts the fundraising outcomes of 81.0% of campaigns,\nprimarily based on their textual descriptions. Interpreting the machine\nlearning model allows us to provide actionable suggestions on improving the\ntextual description before launching a campaign. We demonstrate that by\naugmenting just three aspects of the narrative using a large language model, a\ncampaign becomes more preferable to 83% human evaluators, and its likelihood of\nsecuring financial support increases by 11.9%. Our research uncovers the\neffective strategies for crafting descriptions for small business fundraising\ncampaigns and opens up a new realm in integrating large language models into\ncrowdfunding methodologies.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CL",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09480v1",
    "published_date": "2024-04-24 20:53:10 UTC",
    "updated_date": "2024-04-24 20:53:10 UTC"
  },
  {
    "arxiv_id": "2404.16196v3",
    "title": "ApisTox: a new benchmark dataset for the classification of small molecules toxicity on honey bees",
    "authors": [
      "Jakub Adamczyk",
      "Jakub Poziemski",
      "Pawel Siedlecki"
    ],
    "abstract": "The global decline in bee populations poses significant risks to agriculture,\nbiodiversity, and environmental stability. To bridge the gap in existing data,\nwe introduce ApisTox, a comprehensive dataset focusing on the toxicity of\npesticides to honey bees (Apis mellifera). This dataset combines and leverages\ndata from existing sources such as ECOTOX and PPDB, providing an extensive,\nconsistent, and curated collection that surpasses the previous datasets.\nApisTox incorporates a wide array of data, including toxicity levels for\nchemicals, details such as time of their publication in literature, and\nidentifiers linking them to external chemical databases. This dataset may serve\nas an important tool for environmental and agricultural research, but also can\nsupport the development of policies and practices aimed at minimizing harm to\nbee populations. Finally, ApisTox offers a unique resource for benchmarking\nmolecular property prediction methods on agrochemical compounds, facilitating\nadvancements in both environmental science and cheminformatics. This makes it a\nvaluable tool for both academic research and practical applications in bee\nconservation.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "q-bio.BM",
      "92-04",
      "J.3"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16196v3",
    "published_date": "2024-04-24 20:35:17 UTC",
    "updated_date": "2024-11-29 13:04:35 UTC"
  },
  {
    "arxiv_id": "2404.16193v2",
    "title": "Improving Multi-label Recognition using Class Co-Occurrence Probabilities",
    "authors": [
      "Samyak Rawlekar",
      "Shubhang Bhatnagar",
      "Vishnuvardhan Pogunulu Srinivasulu",
      "Narendra Ahuja"
    ],
    "abstract": "Multi-label Recognition (MLR) involves the identification of multiple objects\nwithin an image. To address the additional complexity of this problem, recent\nworks have leveraged information from vision-language models (VLMs) trained on\nlarge text-images datasets for the task. These methods learn an independent\nclassifier for each object (class), overlooking correlations in their\noccurrences. Such co-occurrences can be captured from the training data as\nconditional probabilities between a pair of classes. We propose a framework to\nextend the independent classifiers by incorporating the co-occurrence\ninformation for object pairs to improve the performance of independent\nclassifiers. We use a Graph Convolutional Network (GCN) to enforce the\nconditional probabilities between classes, by refining the initial estimates\nderived from image and text sources obtained using VLMs. We validate our method\non four MLR datasets, where our approach outperforms all state-of-the-art\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICPR 2024, CVPR workshops 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.16193v2",
    "published_date": "2024-04-24 20:33:25 UTC",
    "updated_date": "2024-09-19 21:19:05 UTC"
  },
  {
    "arxiv_id": "2404.16188v1",
    "title": "Pearls from Pebbles: Improved Confidence Functions for Auto-labeling",
    "authors": [
      "Harit Vishwakarma",
      "Reid",
      "Chen",
      "Sui Jiet Tay",
      "Satya Sai Srinath Namburi",
      "Frederic Sala",
      "Ramya Korlakai Vinayak"
    ],
    "abstract": "Auto-labeling is an important family of techniques that produce labeled\ntraining sets with minimum manual labeling. A prominent variant,\nthreshold-based auto-labeling (TBAL), works by finding a threshold on a model's\nconfidence scores above which it can accurately label unlabeled data points.\nHowever, many models are known to produce overconfident scores, leading to poor\nTBAL performance. While a natural idea is to apply off-the-shelf calibration\nmethods to alleviate the overconfidence issue, such methods still fall short.\nRather than experimenting with ad-hoc choices of confidence functions, we\npropose a framework for studying the \\emph{optimal} TBAL confidence function.\nWe develop a tractable version of the framework to obtain \\texttt{Colander}\n(Confidence functions for Efficient and Reliable Auto-labeling), a new post-hoc\nmethod specifically designed to maximize performance in TBAL systems. We\nperform an extensive empirical evaluation of our method \\texttt{Colander} and\ncompare it against methods designed for calibration. \\texttt{Colander} achieves\nup to 60\\% improvements on coverage over the baselines while maintaining\nauto-labeling error below $5\\%$ and using the same amount of labeled data as\nthe baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16188v1",
    "published_date": "2024-04-24 20:22:48 UTC",
    "updated_date": "2024-04-24 20:22:48 UTC"
  },
  {
    "arxiv_id": "2404.16183v1",
    "title": "ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment",
    "authors": [
      "Sarala Naidu",
      "Ning Xiong"
    ],
    "abstract": "Anomaly detection in industrial systems is crucial for preventing equipment\nfailures, ensuring risk identification, and maintaining overall system\nefficiency. Traditional monitoring methods often rely on fixed thresholds and\nempirical rules, which may not be sensitive enough to detect subtle changes in\nsystem health and predict impending failures. To address this limitation, this\npaper proposes, a novel Attention-based convolutional autoencoder (ABCD) for\nrisk detection and map the risk value derive to the maintenance planning. ABCD\nlearns the normal behavior of conductivity from historical data of a real-world\nindustrial cooling system and reconstructs the input data, identifying\nanomalies that deviate from the expected patterns. The framework also employs\ncalibration techniques to ensure the reliability of its predictions. Evaluation\nresults demonstrate that with the attention mechanism in ABCD a 57.4% increase\nin performance and a reduction of false alarms by 9.37% is seen compared to\nwithout attention. The approach can effectively detect risks, the risk priority\nrank mapped to maintenance, providing valuable insights for cooling system\ndesigners and service personnel. Calibration error of 0.03% indicates that the\nmodel is well-calibrated and enhances model's trustworthiness, enabling\ninformed decisions about maintenance strategies",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16183v1",
    "published_date": "2024-04-24 20:15:57 UTC",
    "updated_date": "2024-04-24 20:15:57 UTC"
  },
  {
    "arxiv_id": "2404.16177v1",
    "title": "Advancing Recommender Systems by mitigating Shilling attacks",
    "authors": [
      "Aditya Chichani",
      "Juzer Golwala",
      "Tejas Gundecha",
      "Kiran Gawande"
    ],
    "abstract": "Considering the premise that the number of products offered grow in an\nexponential fashion and the amount of data that a user can assimilate before\nmaking a decision is relatively small, recommender systems help in categorizing\ncontent according to user preferences. Collaborative filtering is a widely used\nmethod for computing recommendations due to its good performance. But, this\nmethod makes the system vulnerable to attacks which try to bias the\nrecommendations. These attacks, known as 'shilling attacks' are performed to\npush an item or nuke an item in the system. This paper proposes an algorithm to\ndetect such shilling profiles in the system accurately and also study the\neffects of such profiles on the recommendations.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Published in IEEE, Proceedings of 2018 9th International Conference\n  on Computing, Communication and Networking Technologies (ICCCNT)",
    "pdf_url": "http://arxiv.org/pdf/2404.16177v1",
    "published_date": "2024-04-24 20:05:39 UTC",
    "updated_date": "2024-04-24 20:05:39 UTC"
  },
  {
    "arxiv_id": "2404.16168v3",
    "title": "The Over-Certainty Phenomenon in Modern UDA Algorithms",
    "authors": [
      "Fin Amin",
      "Jung-Eun Kim"
    ],
    "abstract": "When neural networks are confronted with unfamiliar data that deviate from\ntheir training set, this signifies a domain shift. While these networks output\npredictions on their inputs, they typically fail to account for their level of\nfamiliarity with these novel observations. While prevailing works navigate\nunsupervised domain adaptation with the goal of curtailing model entropy, they\nunintentionally birth models that grapple with sub-optimal calibration - a\ndilemma we term the over-certainty phenomenon. In this paper, we uncover a\nconcerning trend in unsupervised domain adaptation and propose a solution that\nnot only maintains accuracy but also addresses calibration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16168v3",
    "published_date": "2024-04-24 19:55:50 UTC",
    "updated_date": "2024-08-25 23:06:51 UTC"
  },
  {
    "arxiv_id": "2404.16164v1",
    "title": "Towards a Holistic Evaluation of LLMs on Factual Knowledge Recall",
    "authors": [
      "Jiaqing Yuan",
      "Lin Pan",
      "Chung-Wei Hang",
      "Jiang Guo",
      "Jiarong Jiang",
      "Bonan Min",
      "Patrick Ng",
      "Zhiguo Wang"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance on a variety\nof NLP tasks, and are being rapidly adopted in a wide range of use cases. It is\ntherefore of vital importance to holistically evaluate the factuality of their\ngenerated outputs, as hallucinations remain a challenging issue.\n  In this work, we focus on assessing LLMs' ability to recall factual knowledge\nlearned from pretraining, and the factors that affect this ability. To that\nend, we construct FACT-BENCH, a representative benchmark covering 20 domains,\n134 property types, 3 answer types, and different knowledge popularity levels.\nWe benchmark 31 models from 10 model families and provide a holistic assessment\nof their strengths and weaknesses. We observe that instruction-tuning hurts\nknowledge recall, as pretraining-only models consistently outperform their\ninstruction-tuned counterparts, and positive effects of model scaling, as\nlarger models outperform smaller ones for all model families. However, the best\nperformance from GPT-4 still represents a large gap with the upper-bound. We\nadditionally study the role of in-context exemplars using counterfactual\ndemonstrations, which lead to significant degradation of factual knowledge\nrecall for large models. By further decoupling model known and unknown\nknowledge, we find the degradation is attributed to exemplars that contradict a\nmodel's known knowledge, as well as the number of such exemplars. Lastly, we\nfine-tune LLaMA-7B in different settings of known and unknown knowledge. In\nparticular, fine-tuning on a model's known knowledge is beneficial, and\nconsistently outperforms fine-tuning on unknown and mixed knowledge. We will\nmake our benchmark publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16164v1",
    "published_date": "2024-04-24 19:40:01 UTC",
    "updated_date": "2024-04-24 19:40:01 UTC"
  },
  {
    "arxiv_id": "2404.16162v1",
    "title": "Scaling Lifelong Multi-Agent Path Finding to More Realistic Settings: Research Challenges and Opportunities",
    "authors": [
      "He Jiang",
      "Yulun Zhang",
      "Rishi Veerapaneni",
      "Jiaoyang Li"
    ],
    "abstract": "Multi-Agent Path Finding (MAPF) is the problem of moving multiple agents from\nstarts to goals without collisions. Lifelong MAPF (LMAPF) extends MAPF by\ncontinuously assigning new goals to agents. We present our winning approach to\nthe 2023 League of Robot Runners LMAPF competition, which leads us to several\ninteresting research challenges and future directions. In this paper, we\noutline three main research challenges. The first challenge is to search for\nhigh-quality LMAPF solutions within a limited planning time (e.g., 1s per step)\nfor a large number of agents (e.g., 10,000) or extremely high agent density\n(e.g., 97.7%). We present future directions such as developing more competitive\nrule-based and anytime MAPF algorithms and parallelizing state-of-the-art MAPF\nalgorithms. The second challenge is to alleviate congestion and the effect of\nmyopic behaviors in LMAPF algorithms. We present future directions, such as\ndeveloping moving guidance and traffic rules to reduce congestion,\nincorporating future prediction and real-time search, and determining the\noptimal agent number. The third challenge is to bridge the gaps between the\nLMAPF models used in the literature and real-world applications. We present\nfuture directions, such as dealing with more realistic kinodynamic models,\nexecution uncertainty, and evolving systems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted to Symposium on Combinatorial Search (SoCS), 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.16162v1",
    "published_date": "2024-04-24 19:37:18 UTC",
    "updated_date": "2024-04-24 19:37:18 UTC"
  },
  {
    "arxiv_id": "2404.16160v2",
    "title": "Domain-Specific Improvement on Psychotherapy Chatbot Using Assistant",
    "authors": [
      "Cheng Kang",
      "Daniel Novak",
      "Katerina Urbanova",
      "Yuqing Cheng",
      "Yong Hu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive generalization\ncapabilities on specific tasks with human-written instruction data. However,\nthe limited quantity, diversity, and professional expertise of such instruction\ndata raise concerns about the performance of LLMs in psychotherapy tasks when\nprovided with domain-specific instructions. To address this, we firstly propose\nDomain-Specific Assistant Instructions based on AlexanderStreet therapy, and\nsecondly, we use an adaption fine-tuning method and retrieval augmented\ngeneration method to improve pre-trained LLMs. Through quantitative evaluation\nof linguistic quality using automatic and human evaluation, we observe that\npre-trained LLMs on Psychotherapy Assistant Instructions outperform\nstate-of-the-art LLMs response baselines. Our Assistant-Instruction approach\noffers a half-annotation method to align pre-trained LLMs with instructions and\nprovide pre-trained LLMs with more psychotherapy knowledge.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICASSP 2024 EIHRC Workshop",
    "pdf_url": "http://arxiv.org/pdf/2404.16160v2",
    "published_date": "2024-04-24 19:30:18 UTC",
    "updated_date": "2024-09-02 16:33:29 UTC"
  },
  {
    "arxiv_id": "2404.16159v2",
    "title": "AFU: Actor-Free critic Updates in off-policy RL for continuous control",
    "authors": [
      "Nicolas Perrin-Gilbert"
    ],
    "abstract": "This paper presents AFU, an off-policy deep RL algorithm addressing in a new\nway the challenging \"max-Q problem\" in Q-learning for continuous action spaces,\nwith a solution based on regression and conditional gradient scaling. AFU has\nan actor but its critic updates are entirely independent from it. As a\nconsequence, the actor can be chosen freely. In the initial version, AFU-alpha,\nwe employ the same stochastic actor as in Soft Actor-Critic (SAC), but we then\nstudy a simple failure mode of SAC and show how AFU can be modified to make\nactor updates less likely to become trapped in local optima, resulting in a\nsecond version of the algorithm, AFU-beta. Experimental results demonstrate the\nsample efficiency of both versions of AFU, marking it as the first model-free\noff-policy algorithm competitive with state-of-the-art actor-critic methods\nwhile departing from the actor-critic perspective.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.16159v2",
    "published_date": "2024-04-24 19:30:03 UTC",
    "updated_date": "2024-10-25 11:32:56 UTC"
  },
  {
    "arxiv_id": "2404.16891v1",
    "title": "Attacks on Third-Party APIs of Large Language Models",
    "authors": [
      "Wanru Zhao",
      "Vidit Khazanchi",
      "Haodi Xing",
      "Xuanli He",
      "Qiongkai Xu",
      "Nicholas Donald Lane"
    ],
    "abstract": "Large language model (LLM) services have recently begun offering a plugin\necosystem to interact with third-party API services. This innovation enhances\nthe capabilities of LLMs, but it also introduces risks, as these plugins\ndeveloped by various third parties cannot be easily trusted. This paper\nproposes a new attacking framework to examine security and safety\nvulnerabilities within LLM platforms that incorporate third-party services.\nApplying our framework specifically to widely used LLMs, we identify real-world\nmalicious attacks across various domains on third-party APIs that can\nimperceptibly modify LLM outputs. The paper discusses the unique challenges\nposed by third-party API integration and offers strategic possibilities to\nimprove the security and safety of LLM ecosystems moving forward. Our code is\nreleased at https://github.com/vk0812/Third-Party-Attacks-on-LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "ICLR 2024 Workshop on Secure and Trustworthy Large Language Models",
    "pdf_url": "http://arxiv.org/pdf/2404.16891v1",
    "published_date": "2024-04-24 19:27:02 UTC",
    "updated_date": "2024-04-24 19:27:02 UTC"
  },
  {
    "arxiv_id": "2404.16130v2",
    "title": "From Local to Global: A Graph RAG Approach to Query-Focused Summarization",
    "authors": [
      "Darren Edge",
      "Ha Trinh",
      "Newman Cheng",
      "Joshua Bradley",
      "Alex Chao",
      "Apurva Mody",
      "Steven Truitt",
      "Dasha Metropolitansky",
      "Robert Osazuwa Ness",
      "Jonathan Larson"
    ],
    "abstract": "The use of retrieval-augmented generation (RAG) to retrieve relevant\ninformation from an external knowledge source enables large language models\n(LLMs) to answer questions over private and/or previously unseen document\ncollections. However, RAG fails on global questions directed at an entire text\ncorpus, such as \"What are the main themes in the dataset?\", since this is\ninherently a query-focused summarization (QFS) task, rather than an explicit\nretrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of\ntext indexed by typical RAG systems. To combine the strengths of these\ncontrasting methods, we propose GraphRAG, a graph-based approach to question\nanswering over private text corpora that scales with both the generality of\nuser questions and the quantity of source text. Our approach uses an LLM to\nbuild a graph index in two stages: first, to derive an entity knowledge graph\nfrom the source documents, then to pregenerate community summaries for all\ngroups of closely related entities. Given a question, each community summary is\nused to generate a partial response, before all partial responses are again\nsummarized in a final response to the user. For a class of global sensemaking\nquestions over datasets in the 1 million token range, we show that GraphRAG\nleads to substantial improvements over a conventional RAG baseline for both the\ncomprehensiveness and diversity of generated answers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "H.3.3; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16130v2",
    "published_date": "2024-04-24 18:38:11 UTC",
    "updated_date": "2025-02-19 10:49:41 UTC"
  },
  {
    "arxiv_id": "2404.16123v1",
    "title": "FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication",
    "authors": [
      "Eric Slyman",
      "Stefan Lee",
      "Scott Cohen",
      "Kushal Kafle"
    ],
    "abstract": "Recent dataset deduplication techniques have demonstrated that content-aware\ndataset pruning can dramatically reduce the cost of training Vision-Language\nPretrained (VLP) models without significant performance losses compared to\ntraining on the original dataset. These results have been based on pruning\ncommonly used image-caption datasets collected from the web -- datasets that\nare known to harbor harmful social biases that may then be codified in trained\nmodels. In this work, we evaluate how deduplication affects the prevalence of\nthese biases in the resulting trained models and introduce an easy-to-implement\nmodification to the recent SemDeDup algorithm that can reduce the negative\neffects that we observe. When examining CLIP-style models trained on\ndeduplicated variants of LAION-400M, we find our proposed FairDeDup algorithm\nconsistently leads to improved fairness metrics over SemDeDup on the FairFace\nand FACET datasets while maintaining zero-shot performance on CLIP benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "I.4.10; I.2.7; E.0"
    ],
    "primary_category": "cs.CV",
    "comment": "Conference paper at CVPR 2024. 6 pages, 8 figures. Project Page:\n  https://ericslyman.com/fairdedup/",
    "pdf_url": "http://arxiv.org/pdf/2404.16123v1",
    "published_date": "2024-04-24 18:28:17 UTC",
    "updated_date": "2024-04-24 18:28:17 UTC"
  },
  {
    "arxiv_id": "2405.05136v1",
    "title": "Integrating LSTM and BERT for Long-Sequence Data Analysis in Intelligent Tutoring Systems",
    "authors": [
      "Zhaoxing Li",
      "Jujie Yang",
      "Jindi Wang",
      "Lei Shi",
      "Sebastian Stein"
    ],
    "abstract": "The field of Knowledge Tracing aims to understand how students learn and\nmaster knowledge over time by analyzing their historical behaviour data. To\nachieve this goal, many researchers have proposed Knowledge Tracing models that\nuse data from Intelligent Tutoring Systems to predict students' subsequent\nactions. However, with the development of Intelligent Tutoring Systems,\nlarge-scale datasets containing long-sequence data began to emerge. Recent deep\nlearning based Knowledge Tracing models face obstacles such as low efficiency,\nlow accuracy, and low interpretability when dealing with large-scale datasets\ncontaining long-sequence data. To address these issues and promote the\nsustainable development of Intelligent Tutoring Systems, we propose a LSTM\nBERT-based Knowledge Tracing model for long sequence data processing, namely\nLBKT, which uses a BERT-based architecture with a Rasch model-based embeddings\nblock to deal with different difficulty levels information and an LSTM block to\nprocess the sequential characteristic in students' actions. LBKT achieves the\nbest performance on most benchmark datasets on the metrics of ACC and AUC.\nAdditionally, an ablation study is conducted to analyse the impact of each\ncomponent of LBKT's overall performance. Moreover, we used t-SNE as the\nvisualisation tool to demonstrate the model's embedding strategy. The results\nindicate that LBKT is faster, more interpretable, and has a lower memory cost\nthan the traditional deep learning based Knowledge Tracing methods.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05136v1",
    "published_date": "2024-04-24 18:19:44 UTC",
    "updated_date": "2024-04-24 18:19:44 UTC"
  },
  {
    "arxiv_id": "2404.16116v2",
    "title": "Classifying Human-Generated and AI-Generated Election Claims in Social Media",
    "authors": [
      "Alphaeus Dmonte",
      "Marcos Zampieri",
      "Kevin Lybarger",
      "Massimiliano Albanese",
      "Genya Coulter"
    ],
    "abstract": "Politics is one of the most prevalent topics discussed on social media\nplatforms, particularly during major election cycles, where users engage in\nconversations about candidates and electoral processes. Malicious actors may\nuse this opportunity to disseminate misinformation to undermine trust in the\nelectoral process. The emergence of Large Language Models (LLMs) exacerbates\nthis issue by enabling malicious actors to generate misinformation at an\nunprecedented scale. Artificial intelligence (AI)-generated content is often\nindistinguishable from authentic user content, raising concerns about the\nintegrity of information on social networks. In this paper, we present a novel\ntaxonomy for characterizing election-related claims. This taxonomy provides an\ninstrument for analyzing election-related claims, with granular categories\nrelated to jurisdiction, equipment, processes, and the nature of claims. We\nintroduce ElectAI, a novel benchmark dataset that consists of 9,900 tweets,\neach labeled as human- or AI-generated. For AI-generated tweets, the specific\nLLM variant that produced them is specified. We annotated a subset of 1,550\ntweets using the proposed taxonomy to capture the characteristics of\nelection-related claims. We explored the capabilities of LLMs in extracting the\ntaxonomy attributes and trained various machine learning models using ElectAI\nto distinguish between human- and AI-generated posts and identify the specific\nLLM variant.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16116v2",
    "published_date": "2024-04-24 18:13:29 UTC",
    "updated_date": "2024-04-26 01:51:51 UTC"
  },
  {
    "arxiv_id": "2404.16115v1",
    "title": "Online Personalizing White-box LLMs Generation with Neural Bandits",
    "authors": [
      "Zekai Chen",
      "Weeden Daniel",
      "Po-yu Chen",
      "Francois Buet-Golfouse"
    ],
    "abstract": "The advent of personalized content generation by LLMs presents a novel\nchallenge: how to efficiently adapt text to meet individual preferences without\nthe unsustainable demand of creating a unique model for each user. This study\nintroduces an innovative online method that employs neural bandit algorithms to\ndynamically optimize soft instruction embeddings based on user feedback,\nenhancing the personalization of open-ended text generation by white-box LLMs.\nThrough rigorous experimentation on various tasks, we demonstrate significant\nperformance improvements over baseline strategies. NeuralTS, in particular,\nleads to substantial enhancements in personalized news headline generation,\nachieving up to a 62.9% improvement in terms of best ROUGE scores and up to\n2.76% increase in LLM-agent evaluation against the baseline.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.16115v1",
    "published_date": "2024-04-24 18:13:12 UTC",
    "updated_date": "2024-04-24 18:13:12 UTC"
  },
  {
    "arxiv_id": "2404.16112v1",
    "title": "Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges",
    "authors": [
      "Badri Narayana Patro",
      "Vijay Srinivas Agneeswaran"
    ],
    "abstract": "Sequence modeling is a crucial area across various domains, including Natural\nLanguage Processing (NLP), speech recognition, time series forecasting, music\ngeneration, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short\nTerm Memory Networks (LSTMs) have historically dominated sequence modeling\ntasks like Machine Translation, Named Entity Recognition (NER), etc. However,\nthe advancement of transformers has led to a shift in this paradigm, given\ntheir superior performance. Yet, transformers suffer from $O(N^2)$ attention\ncomplexity and challenges in handling inductive bias. Several variations have\nbeen proposed to address these issues which use spectral networks or\nconvolutions and have performed well on a range of tasks. However, they still\nhave difficulty in dealing with long sequences. State Space Models(SSMs) have\nemerged as promising alternatives for sequence modeling paradigms in this\ncontext, especially with the advent of S4 and its variants, such as S4nd,\nHippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear\nRecurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the\nfoundational SSMs based on three paradigms namely, Gating architectures,\nStructural architectures, and Recurrent architectures. This survey also\nhighlights diverse applications of SSMs across domains such as vision, video,\naudio, speech, language (especially long sequence modeling), medical (including\ngenomics), chemical (like drug design), recommendation systems, and time series\nanalysis, including tabular data. Moreover, we consolidate the performance of\nSSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile,\nImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast,\nCOIN, LVU, and various time series datasets. The project page for Mamba-360\nwork is available on this webpage.\\url{https://github.com/badripatro/mamba360}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16112v1",
    "published_date": "2024-04-24 18:10:31 UTC",
    "updated_date": "2024-04-24 18:10:31 UTC"
  },
  {
    "arxiv_id": "2404.16035v1",
    "title": "MaGGIe: Masked Guided Gradual Human Instance Matting",
    "authors": [
      "Chuong Huynh",
      "Seoung Wug Oh",
      "Abhinav Shrivastava",
      "Joon-Young Lee"
    ],
    "abstract": "Human matting is a foundation task in image and video processing, where human\nforeground pixels are extracted from the input. Prior works either improve the\naccuracy by additional guidance or improve the temporal consistency of a single\ninstance across frames. We propose a new framework MaGGIe, Masked Guided\nGradual Human Instance Matting, which predicts alpha mattes progressively for\neach human instances while maintaining the computational cost, precision, and\nconsistency. Our method leverages modern architectures, including transformer\nattention and sparse convolution, to output all instance mattes simultaneously\nwithout exploding memory and latency. Although keeping constant inference costs\nin the multiple-instance scenario, our framework achieves robust and versatile\nperformance on our proposed synthesized benchmarks. With the higher quality\nimage and video matting benchmarks, the novel multi-instance synthesis approach\nfrom publicly available sources is introduced to increase the generalization of\nmodels in real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024. Project link: https://maggie-matt.github.io",
    "pdf_url": "http://arxiv.org/pdf/2404.16035v1",
    "published_date": "2024-04-24 17:59:53 UTC",
    "updated_date": "2024-04-24 17:59:53 UTC"
  },
  {
    "arxiv_id": "2404.16030v1",
    "title": "MoDE: CLIP Data Experts via Clustering",
    "authors": [
      "Jiawei Ma",
      "Po-Yao Huang",
      "Saining Xie",
      "Shang-Wen Li",
      "Luke Zettlemoyer",
      "Shih-Fu Chang",
      "Wen-Tau Yih",
      "Hu Xu"
    ],
    "abstract": "The success of contrastive language-image pretraining (CLIP) relies on the\nsupervision from the pairing between images and captions, which tends to be\nnoisy in web-crawled data. We present Mixture of Data Experts (MoDE) and learn\na system of CLIP data experts via clustering. Each data expert is trained on\none data cluster, being less sensitive to false negative noises in other\nclusters. At inference time, we ensemble their outputs by applying weights\ndetermined through the correlation between task metadata and cluster\nconditions. To estimate the correlation precisely, the samples in one cluster\nshould be semantically similar, but the number of data experts should still be\nreasonable for training and inference. As such, we consider the ontology in\nhuman language and propose to use fine-grained cluster centers to represent\neach data expert at a coarse-grained level. Experimental studies show that four\nCLIP data experts on ViT-B/16 outperform the ViT-L/14 by OpenAI CLIP and\nOpenCLIP on zero-shot image classification but with less ($<$35\\%) training\ncost. Meanwhile, MoDE can train all data expert asynchronously and can flexibly\ninclude new data experts. The code is available at\nhttps://github.com/facebookresearch/MetaCLIP/tree/main/mode.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE CVPR 2024 Camera Ready. Code Link:\n  https://github.com/facebookresearch/MetaCLIP/tree/main/mode",
    "pdf_url": "http://arxiv.org/pdf/2404.16030v1",
    "published_date": "2024-04-24 17:59:24 UTC",
    "updated_date": "2024-04-24 17:59:24 UTC"
  },
  {
    "arxiv_id": "2404.16017v3",
    "title": "RetinaRegNet: A Zero-Shot Approach for Retinal Image Registration",
    "authors": [
      "Vishal Balaji Sivaraman",
      "Muhammad Imran",
      "Qingyue Wei",
      "Preethika Muralidharan",
      "Michelle R. Tamplin",
      "Isabella M . Grumbach",
      "Randy H. Kardon",
      "Jui-Kai Wang",
      "Yuyin Zhou",
      "Wei Shao"
    ],
    "abstract": "We introduce RetinaRegNet, a zero-shot image registration model designed to\nregister retinal images with minimal overlap, large deformations, and varying\nimage quality. RetinaRegNet addresses these challenges and achieves robust and\naccurate registration through the following steps. First, we extract features\nfrom the moving and fixed images using latent diffusion models. We then sample\nfeature points from the fixed image using a combination of the SIFT algorithm\nand random point sampling. For each sampled point, we identify its\ncorresponding point in the moving image using a 2D correlation map, which\ncomputes the cosine similarity between the diffusion feature vectors of the\npoint in the fixed image and all pixels in the moving image. Second, we\neliminate most incorrectly detected point correspondences (outliers) by\nenforcing an inverse consistency constraint, ensuring that correspondences are\nconsistent in both forward and backward directions. We further remove outliers\nwith large distances between corresponding points using a global transformation\nbased outlier detector. Finally, we implement a two-stage registration\nframework to handle large deformations. The first stage estimates a homography\ntransformation to achieve global alignment between the images, while the second\nstage uses a third-order polynomial transformation to estimate local\ndeformations. We evaluated RetinaRegNet on three retinal image registration\ndatasets: color fundus images, fluorescein angiography images, and laser\nspeckle flowgraphy images. Our model consistently outperformed state-of-the-art\nmethods across all datasets. The accurate registration achieved by RetinaRegNet\nenables the tracking of eye disease progression, enhances surgical planning,\nand facilitates the evaluation of treatment efficacy. Our code is publicly\navailable at: https://github.com/mirthAI/RetinaRegNet.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16017v3",
    "published_date": "2024-04-24 17:50:37 UTC",
    "updated_date": "2024-09-11 00:25:37 UTC"
  },
  {
    "arxiv_id": "2404.16015v2",
    "title": "Neural Operators Learn the Local Physics of Magnetohydrodynamics",
    "authors": [
      "Taeyoung Kim",
      "Youngsoo Ha",
      "Myungjoo Kang"
    ],
    "abstract": "Magnetohydrodynamics (MHD) plays a pivotal role in describing the dynamics of\nplasma and conductive fluids, essential for understanding phenomena such as the\nstructure and evolution of stars and galaxies, and in nuclear fusion for plasma\nmotion through ideal MHD equations. Solving these hyperbolic PDEs requires\nsophisticated numerical methods, presenting computational challenges due to\ncomplex structures and high costs. Recent advances introduce neural operators\nlike the Fourier Neural Operator (FNO) as surrogate models for traditional\nnumerical analyses. This study explores a modified Flux Fourier neural operator\nmodel to approximate the numerical flux of ideal MHD, offering a novel approach\nthat outperforms existing neural operator models by enabling continuous\ninference, generalization outside sampled distributions, and faster computation\ncompared to classical numerical schemes.",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "48 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.16015v2",
    "published_date": "2024-04-24 17:48:38 UTC",
    "updated_date": "2024-10-10 14:19:57 UTC"
  },
  {
    "arxiv_id": "2404.16014v2",
    "title": "Improving Dictionary Learning with Gated Sparse Autoencoders",
    "authors": [
      "Senthooran Rajamanoharan",
      "Arthur Conmy",
      "Lewis Smith",
      "Tom Lieberum",
      "Vikrant Varma",
      "Jnos Kramr",
      "Rohin Shah",
      "Neel Nanda"
    ],
    "abstract": "Recent work has found that sparse autoencoders (SAEs) are an effective\ntechnique for unsupervised discovery of interpretable features in language\nmodels' (LMs) activations, by finding sparse, linear reconstructions of LM\nactivations. We introduce the Gated Sparse Autoencoder (Gated SAE), which\nachieves a Pareto improvement over training with prevailing methods. In SAEs,\nthe L1 penalty used to encourage sparsity introduces many undesirable biases,\nsuch as shrinkage -- systematic underestimation of feature activations. The key\ninsight of Gated SAEs is to separate the functionality of (a) determining which\ndirections to use and (b) estimating the magnitudes of those directions: this\nenables us to apply the L1 penalty only to the former, limiting the scope of\nundesirable side effects. Through training SAEs on LMs of up to 7B parameters\nwe find that, in typical hyper-parameter ranges, Gated SAEs solve shrinkage,\nare similarly interpretable, and require half as many firing features to\nachieve comparable reconstruction fidelity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 main text pages, 22 appendix pages",
    "pdf_url": "http://arxiv.org/pdf/2404.16014v2",
    "published_date": "2024-04-24 17:47:22 UTC",
    "updated_date": "2024-04-30 17:54:04 UTC"
  },
  {
    "arxiv_id": "2404.15961v1",
    "title": "Soil analysis with machine-learning-based processing of stepped-frequency GPR field measurements: Preliminary study",
    "authors": [
      "Chunlei Xu",
      "Michael Pregesbauer",
      "Naga Sravani Chilukuri",
      "Daniel Windhager",
      "Mahsa Yousefi",
      "Pedro Julian",
      "Lothar Ratschbacher"
    ],
    "abstract": "Ground Penetrating Radar (GPR) has been widely studied as a tool for\nextracting soil parameters relevant to agriculture and horticulture. When\ncombined with Machine-Learning-based (ML) methods, high-resolution Stepped\nFrequency Countinuous Wave Radar (SFCW) measurements hold the promise to give\ncost effective access to depth resolved soil parameters, including at\nroot-level depth. In a first step in this direction, we perform an extensive\nfield survey with a tractor mounted SFCW GPR instrument. Using ML data\nprocessing we test the GPR instrument's capabilities to predict the apparent\nelectrical conductivity (ECaR) as measured by a simultaneously recording\nElectromagnetic Induction (EMI) instrument. The large-scale field measurement\ncampaign with 3472 co-registered and geo-located GPR and EMI data samples\ndistributed over ~6600 square meters was performed on a golf course. The\nselected terrain benefits from a high surface homogeneity, but also features\nthe challenge of only small, and hence hard to discern, variations in the\nmeasured soil parameter. Based on the quantitative results we suggest the use\nof nugget-to-sill ratio as a performance metric for the evaluation of\nend-to-end ML performance in the agricultural setting and discuss the limiting\nfactors in the multi-sensor regression setting. The code is released as open\nsource and available at\nhttps://opensource.silicon-austria.com/xuc/soil-analysis-machine-learning-stepped-frequency-gpr.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15961v1",
    "published_date": "2024-04-24 16:30:12 UTC",
    "updated_date": "2024-04-24 16:30:12 UTC"
  },
  {
    "arxiv_id": "2404.15949v2",
    "title": "CORM: Cache Optimization with Recent Message for Large Language Model Inference",
    "authors": [
      "Jincheng Dai",
      "Zhuowei Huang",
      "Haiyun Jiang",
      "Chen Chen",
      "Deng Cai",
      "Wei Bi",
      "Shuming Shi"
    ],
    "abstract": "Large Language Models (LLMs), despite their remarkable performance across a\nwide range of tasks, necessitate substantial GPU memory and consume significant\ncomputational resources. Beyond the memory taken up by model weights, the\nmemory used by the KV cache rises linearly with sequence length, becoming a\nprimary bottleneck for inference. In this paper, we introduce an innovative\nmethod for optimizing the KV cache, which considerably minimizes its memory\nfootprint. Upon thorough investigation, we discover that in most Transformer\nmodels, (i) there is a striking similarity between adjacent tokens' query\nvectors, and (ii) the attention calculation of the current query can rely\nexclusively on the attention information of a small fraction of preceding\nqueries. Based on these observations, we present CORM, a KV cache eviction\npolicy that dynamically retains essential key-value pairs for inference without\nthe need for model fine-tuning. Our validation shows that CORM reduces the\ninference memory usage of KV cache by up to 70\\% with negligible performance\ndegradation across six tasks in LongBench. Furthermore, we demonstrate that\nCORM is compatible with GQA for further compression rate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15949v2",
    "published_date": "2024-04-24 16:11:54 UTC",
    "updated_date": "2024-06-21 11:44:17 UTC"
  },
  {
    "arxiv_id": "2404.15946v1",
    "title": "Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography",
    "authors": [
      "Xuxin Chen",
      "Yuheng Li",
      "Mingzhe Hu",
      "Ella Salari",
      "Xiaoqian Chen",
      "Richard L. J. Qiu",
      "Bin Zheng",
      "Xiaofeng Yang"
    ],
    "abstract": "Although fusion of information from multiple views of mammograms plays an\nimportant role to increase accuracy of breast cancer detection, developing\nmulti-view mammograms-based computer-aided diagnosis (CAD) schemes still faces\nchallenges and no such CAD schemes have been used in clinical practice. To\novercome the challenges, we investigate a new approach based on Contrastive\nLanguage-Image Pre-training (CLIP), which has sparked interest across various\nmedical imaging tasks. By solving the challenges in (1) effectively adapting\nthe single-view CLIP for multi-view feature fusion and (2) efficiently\nfine-tuning this parameter-dense model with limited samples and computational\nresources, we introduce Mammo-CLIP, the first multi-modal framework to process\nmulti-view mammograms and corresponding simple texts. Mammo-CLIP uses an early\nfeature fusion strategy to learn multi-view relationships in four mammograms\nacquired from the CC and MLO views of the left and right breasts. To enhance\nlearning efficiency, plug-and-play adapters are added into CLIP image and text\nencoders for fine-tuning parameters and limiting updates to about 1% of the\nparameters. For framework evaluation, we assembled two datasets\nretrospectively. The first dataset, comprising 470 malignant and 479 benign\ncases, was used for few-shot fine-tuning and internal evaluation of the\nproposed Mammo-CLIP via 5-fold cross-validation. The second dataset, including\n60 malignant and 294 benign cases, was used to test generalizability of\nMammo-CLIP. Study results show that Mammo-CLIP outperforms the state-of-art\ncross-view transformer in AUC (0.841 vs. 0.817, 0.837 vs. 0.807) on both\ndatasets. It also surpasses previous two CLIP-based methods by 20.3% and 14.3%.\nThis study highlights the potential of applying the finetuned vision-language\nmodels for developing next-generation, image-text-based CAD schemes of breast\ncancer.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15946v1",
    "published_date": "2024-04-24 16:07:31 UTC",
    "updated_date": "2024-04-24 16:07:31 UTC"
  },
  {
    "arxiv_id": "2404.15943v3",
    "title": "Decentralized Personalized Federated Learning based on a Conditional Sparse-to-Sparser Scheme",
    "authors": [
      "Qianyu Long",
      "Qiyuan Wang",
      "Christos Anagnostopoulos",
      "Daning Bi"
    ],
    "abstract": "Decentralized Federated Learning (DFL) has become popular due to its\nrobustness and avoidance of centralized coordination. In this paradigm, clients\nactively engage in training by exchanging models with their networked\nneighbors. However, DFL introduces increased costs in terms of training and\ncommunication. Existing methods focus on minimizing communication often\noverlooking training efficiency and data heterogeneity. To address this gap, we\npropose a novel \\textit{sparse-to-sparser} training scheme: DA-DPFL. DA-DPFL\ninitializes with a subset of model parameters, which progressively reduces\nduring training via \\textit{dynamic aggregation} and leads to substantial\nenergy savings while retaining adequate information during critical learning\nperiods.\n  Our experiments showcase that DA-DPFL substantially outperforms DFL baselines\nin test accuracy, while achieving up to $5$ times reduction in energy costs. We\nprovide a theoretical analysis of DA-DPFL's convergence by solidifying its\napplicability in decentralized and personalized learning. The code is available\nat:https://github.com/EricLoong/da-dpfl",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 9 figures, 3 pages theory",
    "pdf_url": "http://arxiv.org/pdf/2404.15943v3",
    "published_date": "2024-04-24 16:03:34 UTC",
    "updated_date": "2024-07-22 21:58:05 UTC"
  },
  {
    "arxiv_id": "2404.15923v1",
    "title": "KGValidator: A Framework for Automatic Validation of Knowledge Graph Construction",
    "authors": [
      "Jack Boylan",
      "Shashank Mangla",
      "Dominic Thorn",
      "Demian Gholipour Ghalandari",
      "Parsa Ghaffari",
      "Chris Hokamp"
    ],
    "abstract": "This study explores the use of Large Language Models (LLMs) for automatic\nevaluation of knowledge graph (KG) completion models. Historically, validating\ninformation in KGs has been a challenging task, requiring large-scale human\nannotation at prohibitive cost. With the emergence of general-purpose\ngenerative AI and LLMs, it is now plausible that human-in-the-loop validation\ncould be replaced by a generative agent. We introduce a framework for\nconsistency and validation when using generative models to validate knowledge\ngraphs. Our framework is based upon recent open-source developments for\nstructural and semantic validation of LLM outputs, and upon flexible approaches\nto fact checking and verification, supported by the capacity to reference\nexternal knowledge sources of any kind. The design is easy to adapt and extend,\nand can be used to verify any kind of graph-structured data through a\ncombination of model-intrinsic knowledge, user-supplied context, and agents\ncapable of external knowledge retrieval.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Text2KG 2024, ESWC 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15923v1",
    "published_date": "2024-04-24 15:27:25 UTC",
    "updated_date": "2024-04-24 15:27:25 UTC"
  },
  {
    "arxiv_id": "2404.15903v1",
    "title": "Drawing the Line: Deep Segmentation for Extracting Art from Ancient Etruscan Mirrors",
    "authors": [
      "Rafael Sterzinger",
      "Simon Brenner",
      "Robert Sablatnig"
    ],
    "abstract": "Etruscan mirrors constitute a significant category within Etruscan art and,\ntherefore, undergo systematic examinations to obtain insights into ancient\ntimes. A crucial aspect of their analysis involves the labor-intensive task of\nmanually tracing engravings from the backside. Additionally, this task is\ninherently challenging due to the damage these mirrors have sustained,\nintroducing subjectivity into the process. We address these challenges by\nautomating the process through photometric-stereo scanning in conjunction with\ndeep segmentation networks which, however, requires effective usage of the\nlimited data at hand. We accomplish this by incorporating predictions on a\nper-patch level, and various data augmentations, as well as exploring\nself-supervised learning. Compared to our baseline, we improve predictive\nperformance w.r.t. the pseudo-F-Measure by around 16%. When assessing\nperformance on complete mirrors against a human baseline, our approach yields\nquantitative similar performance to a human annotator and significantly\noutperforms existing binarization methods. With our proposed methodology, we\nstreamline the annotation process, enhance its objectivity, and reduce overall\nworkload, offering a valuable contribution to the examination of these\nhistorical artifacts and other non-traditional documents.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, accepted at ICDAR2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15903v1",
    "published_date": "2024-04-24 14:57:37 UTC",
    "updated_date": "2024-04-24 14:57:37 UTC"
  },
  {
    "arxiv_id": "2404.15899v3",
    "title": "ST-MambaSync: The Complement of Mamba and Transformers for Spatial-Temporal in Traffic Flow Prediction",
    "authors": [
      "Zhiqi Shao",
      "Xusheng Yao",
      "Ze Wang",
      "Junbin Gao"
    ],
    "abstract": "Accurate traffic flow prediction is crucial for optimizing traffic\nmanagement, enhancing road safety, and reducing environmental impacts. Existing\nmodels face challenges with long sequence data, requiring substantial memory\nand computational resources, and often suffer from slow inference times due to\nthe lack of a unified summary state. This paper introduces ST-MambaSync, an\ninnovative traffic flow prediction model that combines transformer technology\nwith the ST-Mamba block, representing a significant advancement in the field.\nWe are the pioneers in employing the Mamba mechanism which is an attention\nmechanism integrated with ResNet within a transformer framework, which\nsignificantly enhances the model's explainability and performance. ST-MambaSync\neffectively addresses key challenges such as data length and computational\nefficiency, setting new benchmarks for accuracy and processing speed through\ncomprehensive comparative analysis. This development has significant\nimplications for urban planning and real-time traffic management, establishing\na new standard in traffic flow prediction technology.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "53A45",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages. arXiv admin note: substantial text overlap with\n  arXiv:2404.13257",
    "pdf_url": "http://arxiv.org/pdf/2404.15899v3",
    "published_date": "2024-04-24 14:41:41 UTC",
    "updated_date": "2024-05-09 06:48:37 UTC"
  },
  {
    "arxiv_id": "2404.15894v1",
    "title": "Assessing The Potential Of Mid-Sized Language Models For Clinical QA",
    "authors": [
      "Elliot Bolton",
      "Betty Xiong",
      "Vijaytha Muralidharan",
      "Joel Schamroth",
      "Vivek Muralidharan",
      "Christopher D. Manning",
      "Roxana Daneshjou"
    ],
    "abstract": "Large language models, such as GPT-4 and Med-PaLM, have shown impressive\nperformance on clinical tasks; however, they require access to compute, are\nclosed-source, and cannot be deployed on device. Mid-size models such as\nBioGPT-large, BioMedLM, LLaMA 2, and Mistral 7B avoid these drawbacks, but\ntheir capacity for clinical tasks has been understudied. To help assess their\npotential for clinical use and help researchers decide which model they should\nuse, we compare their performance on two clinical question-answering (QA)\ntasks: MedQA and consumer query answering. We find that Mistral 7B is the best\nperforming model, winning on all benchmarks and outperforming models trained\nspecifically for the biomedical domain. While Mistral 7B's MedQA score of 63.0%\napproaches the original Med-PaLM, and it often can produce plausible responses\nto consumer health queries, room for improvement still exists. This study\nprovides the first head-to-head assessment of open source mid-sized models on\nclinical tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.15894v1",
    "published_date": "2024-04-24 14:32:34 UTC",
    "updated_date": "2024-04-24 14:32:34 UTC"
  },
  {
    "arxiv_id": "2407.05210v1",
    "title": "Leveraging AI for Climate Resilience in Africa: Challenges, Opportunities, and the Need for Collaboration",
    "authors": [
      "Rendani Mbuvha",
      "Yassine Yaakoubi",
      "John Bagiliko",
      "Santiago Hincapie Potes",
      "Amal Nammouchi",
      "Sabrina Amrouche"
    ],
    "abstract": "As climate change issues become more pressing, their impact in Africa calls\nfor urgent, innovative solutions tailored to the continent's unique challenges.\nWhile Artificial Intelligence (AI) emerges as a critical and valuable tool for\nclimate change adaptation and mitigation, its effectiveness and potential are\ncontingent upon overcoming significant challenges such as data scarcity,\ninfrastructure gaps, and limited local AI development. This position paper\nexplores the role of AI in climate change adaptation and mitigation in Africa.\nIt advocates for a collaborative approach to build capacity, develop\nopen-source data repositories, and create context-aware, robust AI-driven\nclimate solutions that are culturally and contextually relevant.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05210v1",
    "published_date": "2024-04-24 14:05:22 UTC",
    "updated_date": "2024-04-24 14:05:22 UTC"
  },
  {
    "arxiv_id": "2404.15882v2",
    "title": "Unexplored Faces of Robustness and Out-of-Distribution: Covariate Shifts in Environment and Sensor Domains",
    "authors": [
      "Eunsu Baek",
      "Keondo Park",
      "Jiyoon Kim",
      "Hyung-Sin Kim"
    ],
    "abstract": "Computer vision applications predict on digital images acquired by a camera\nfrom physical scenes through light. However, conventional robustness benchmarks\nrely on perturbations in digitized images, diverging from distribution shifts\noccurring in the image acquisition process. To bridge this gap, we introduce a\nnew distribution shift dataset, ImageNet-ES, comprising variations in\nenvironmental and camera sensor factors by directly capturing 202k images with\na real camera in a controllable testbed. With the new dataset, we evaluate\nout-of-distribution (OOD) detection and model robustness. We find that existing\nOOD detection methods do not cope with the covariate shifts in ImageNet-ES,\nimplying that the definition and detection of OOD should be revisited to\nembrace real-world distribution shifts. We also observe that the model becomes\nmore robust in both ImageNet-C and -ES by learning environment and sensor\nvariations in addition to existing digital augmentations. Lastly, our results\nsuggest that effective shift mitigation via camera sensor control can\nsignificantly improve performance without increasing model size. With these\nfindings, our benchmark may aid future research on robustness, OOD, and camera\nsensor control for computer vision. Our code and dataset are available at\nhttps://github.com/Edw2n/ImageNet-ES.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a conference paper at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15882v2",
    "published_date": "2024-04-24 13:59:19 UTC",
    "updated_date": "2024-04-25 05:38:52 UTC"
  },
  {
    "arxiv_id": "2404.15881v1",
    "title": "Steal Now and Attack Later: Evaluating Robustness of Object Detection against Black-box Adversarial Attacks",
    "authors": [
      "Erh-Chung Chen",
      "Pin-Yu Chen",
      "I-Hsin Chung",
      "Che-Rung Lee"
    ],
    "abstract": "Latency attacks against object detection represent a variant of adversarial\nattacks that aim to inflate the inference time by generating additional ghost\nobjects in a target image. However, generating ghost objects in the black-box\nscenario remains a challenge since information about these unqualified objects\nremains opaque. In this study, we demonstrate the feasibility of generating\nghost objects in adversarial examples by extending the concept of \"steal now,\ndecrypt later\" attacks. These adversarial examples, once produced, can be\nemployed to exploit potential vulnerabilities in the AI service, giving rise to\nsignificant security concerns. The experimental results demonstrate that the\nproposed attack achieves successful attacks across various commonly used models\nand Google Vision API without any prior knowledge about the target model.\nAdditionally, the average cost of each attack is less than \\$ 1 dollars, posing\na significant threat to AI security.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15881v1",
    "published_date": "2024-04-24 13:51:56 UTC",
    "updated_date": "2024-04-24 13:51:56 UTC"
  },
  {
    "arxiv_id": "2404.15869v1",
    "title": "Semantic Routing for Enhanced Performance of LLM-Assisted Intent-Based 5G Core Network Management and Orchestration",
    "authors": [
      "Dimitrios Michael Manias",
      "Ali Chouman",
      "Abdallah Shami"
    ],
    "abstract": "Large language models (LLMs) are rapidly emerging in Artificial Intelligence\n(AI) applications, especially in the fields of natural language processing and\ngenerative AI. Not limited to text generation applications, these models\ninherently possess the opportunity to leverage prompt engineering, where the\ninputs of such models can be appropriately structured to articulate a model's\npurpose explicitly. A prominent example of this is intent-based networking, an\nemerging approach for automating and maintaining network operations and\nmanagement. This paper presents semantic routing to achieve enhanced\nperformance in LLM-assisted intent-based management and orchestration of 5G\ncore networks. This work establishes an end-to-end intent extraction framework\nand presents a diverse dataset of sample user intents accompanied by a thorough\nanalysis of the effects of encoders and quantization on overall system\nperformance. The results show that using a semantic router improves the\naccuracy and efficiency of the LLM deployment compared to stand-alone LLMs with\nprompting architectures.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Submitted to IEEE GlobeCom 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15869v1",
    "published_date": "2024-04-24 13:34:20 UTC",
    "updated_date": "2024-04-24 13:34:20 UTC"
  },
  {
    "arxiv_id": "2404.16080v1",
    "title": "Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy",
    "authors": [
      "Hong-Jun Yoon",
      "Chris Keum",
      "Alexander Witkowski",
      "Joanna Ludzik",
      "Tracy Petrie",
      "Heidi A. Hanson",
      "Sancy A. Leachman"
    ],
    "abstract": "Reflectance Confocal Microscopy (RCM) is a non-invasive imaging technique\nused in biomedical research and clinical dermatology. It provides virtual\nhigh-resolution images of the skin and superficial tissues, reducing the need\nfor physical biopsies. RCM employs a laser light source to illuminate the\ntissue, capturing the reflected light to generate detailed images of\nmicroscopic structures at various depths. Recent studies explored AI and\nmachine learning, particularly CNNs, for analyzing RCM images. Our study\nproposes a segmentation strategy based on textural features to identify\nclinically significant regions, empowering dermatologists in effective image\ninterpretation and boosting diagnostic confidence. This approach promises to\nadvance dermatological diagnosis and treatment.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16080v1",
    "published_date": "2024-04-24 13:23:03 UTC",
    "updated_date": "2024-04-24 13:23:03 UTC"
  },
  {
    "arxiv_id": "2404.15852v1",
    "title": "QOPTLib: a Quantum Computing Oriented Benchmark for Combinatorial Optimization Problems",
    "authors": [
      "Eneko Osaba",
      "Esther Villar-Rodriguez"
    ],
    "abstract": "In this paper, we propose a quantum computing oriented benchmark for\ncombinatorial optimization. This benchmark, coined as QOPTLib, is composed of\n40 instances equally distributed over four well-known problems: Traveling\nSalesman Problem, Vehicle Routing Problem, one-dimensional Bin Packing Problem\nand the Maximum Cut Problem. The sizes of the instances in QOPTLib not only\ncorrespond to computationally addressable sizes, but also to the maximum length\napproachable with non-zero likelihood of getting a good result. In this regard,\nit is important to highlight that hybrid approaches are also taken into\nconsideration. Thus, this benchmark constitutes the first effort to provide\nusers a general-purpose dataset. Also in this paper, we introduce a first full\nsolving of QOPTLib using two solvers based on quantum annealing. Our main\nintention with this is to establish a preliminary baseline, hoping to inspire\nother researchers to beat these outcomes with newly proposed quantum-based\nalgorithms.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "quant-ph",
    "comment": "15 pages, 3 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2404.15852v1",
    "published_date": "2024-04-24 13:02:33 UTC",
    "updated_date": "2024-04-24 13:02:33 UTC"
  },
  {
    "arxiv_id": "2404.16078v2",
    "title": "Learning World Models With Hierarchical Temporal Abstractions: A Probabilistic Perspective",
    "authors": [
      "Vaisakh Shaj"
    ],
    "abstract": "Machines that can replicate human intelligence with type 2 reasoning\ncapabilities should be able to reason at multiple levels of spatio-temporal\nabstractions and scales using internal world models. Devising formalisms to\ndevelop such internal world models, which accurately reflect the causal\nhierarchies inherent in the dynamics of the real world, is a critical research\nchallenge in the domains of artificial intelligence and machine learning. This\nthesis identifies several limitations with the prevalent use of state space\nmodels (SSMs) as internal world models and propose two new probabilistic\nformalisms namely Hidden-Parameter SSMs and Multi-Time Scale SSMs to address\nthese drawbacks. The structure of graphical models in both formalisms\nfacilitates scalable exact probabilistic inference using belief propagation, as\nwell as end-to-end learning via backpropagation through time. This approach\npermits the development of scalable, adaptive hierarchical world models capable\nof representing nonstationary dynamics across multiple temporal abstractions\nand scales. Moreover, these probabilistic formalisms integrate the concept of\nuncertainty in world states, thus improving the system's capacity to emulate\nthe stochastic nature of the real world and quantify the confidence in its\npredictions. The thesis also discuss how these formalisms are in line with\nrelated neuroscience literature on Bayesian brain hypothesis and predicitive\nprocessing. Our experiments on various real and simulated robots demonstrate\nthat our formalisms can match and in many cases exceed the performance of\ncontemporary transformer variants in making long-range future predictions. We\nconclude the thesis by reflecting on the limitations of our current models and\nsuggesting directions for future research.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Doctoral Dissertation Preprint, Department of Computer Science,\n  Karlsruhe Institute Of Technology, 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.16078v2",
    "published_date": "2024-04-24 12:41:04 UTC",
    "updated_date": "2024-04-26 09:54:28 UTC"
  },
  {
    "arxiv_id": "2404.15840v3",
    "title": "Constructive Interpolation and Concept-Based Beth Definability for Description Logics via Sequents",
    "authors": [
      "Tim S. Lyon",
      "Jonas Karge"
    ],
    "abstract": "We introduce a constructive method applicable to a large number of\ndescription logics (DLs) for establishing the concept-based Beth definability\nproperty (CBP) based on sequent systems. Using the highly expressive DL RIQ as\na case study, we introduce novel sequent calculi for RIQ-ontologies and show\nhow certain interpolants can be computed from sequent calculus proofs, which\npermit the extraction of explicit definitions of implicitly definable concepts.\nTo the best of our knowledge, this is the first sequent-based approach to\ncomputing interpolants and definitions within the context of DLs, as well as\nthe first proof that RIQ enjoys the CBP. Moreover, due to the modularity of our\nsequent systems, our results hold for restrictions of RIQ, and are applicable\nto other DLs by suitable modifications.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.DB",
      "math.LO"
    ],
    "primary_category": "cs.LO",
    "comment": "Accepted to IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15840v3",
    "published_date": "2024-04-24 12:28:27 UTC",
    "updated_date": "2024-10-18 11:22:32 UTC"
  },
  {
    "arxiv_id": "2404.15823v1",
    "title": "A Configurable and Efficient Memory Hierarchy for Neural Network Hardware Accelerator",
    "authors": [
      "Oliver Bause",
      "Paul Palomero Bernardo",
      "Oliver Bringmann"
    ],
    "abstract": "As machine learning applications continue to evolve, the demand for efficient\nhardware accelerators, specifically tailored for deep neural networks (DNNs),\nbecomes increasingly vital. In this paper, we propose a configurable memory\nhierarchy framework tailored for per layer adaptive memory access patterns of\nDNNs. The hierarchy requests data on-demand from the off-chip memory to provide\nit to the accelerator's compute units. The objective is to strike an optimized\nbalance between minimizing the required memory capacity and maintaining high\naccelerator performance. The framework is characterized by its configurability,\nallowing the creation of a tailored memory hierarchy with up to five levels.\nFurthermore, the framework incorporates an optional shift register as final\nlevel to increase the flexibility of the memory management process. A\ncomprehensive loop-nest analysis of DNN layers shows that the framework can\nefficiently execute the access patterns of most loop unrolls. Synthesis results\nand a case study of the DNN accelerator UltraTrail indicate a possible\nreduction in chip area of up to 62.2% as smaller memory modules can be used. At\nthe same time, the performance loss can be minimized to 2.4%.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "accepted at MBMV 2024 - 27. Workshop \"Methoden und\n  Beschreibungssprachen zur Modellierung und Verifikation von Schaltungen und\n  Systemen\"",
    "pdf_url": "http://arxiv.org/pdf/2404.15823v1",
    "published_date": "2024-04-24 11:57:37 UTC",
    "updated_date": "2024-04-24 11:57:37 UTC"
  },
  {
    "arxiv_id": "2404.15822v1",
    "title": "Recursive Backwards Q-Learning in Deterministic Environments",
    "authors": [
      "Jan Diekhoff",
      "Jrn Fischer"
    ],
    "abstract": "Reinforcement learning is a popular method of finding optimal solutions to\ncomplex problems. Algorithms like Q-learning excel at learning to solve\nstochastic problems without a model of their environment. However, they take\nlonger to solve deterministic problems than is necessary. Q-learning can be\nimproved to better solve deterministic problems by introducing such a\nmodel-based approach. This paper introduces the recursive backwards Q-learning\n(RBQL) agent, which explores and builds a model of the environment. After\nreaching a terminal state, it recursively propagates its value backwards\nthrough this model. This lets each state be evaluated to its optimal value\nwithout a lengthy learning process. In the example of finding the shortest path\nthrough a maze, this agent greatly outperforms a regular Q-learning agent.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15822v1",
    "published_date": "2024-04-24 11:54:53 UTC",
    "updated_date": "2024-04-24 11:54:53 UTC"
  },
  {
    "arxiv_id": "2404.15814v1",
    "title": "Fast Ensembling with Diffusion Schrdinger Bridge",
    "authors": [
      "Hyunsu Kim",
      "Jongmin Yoon",
      "Juho Lee"
    ],
    "abstract": "Deep Ensemble (DE) approach is a straightforward technique used to enhance\nthe performance of deep neural networks by training them from different initial\npoints, converging towards various local optima. However, a limitation of this\nmethodology lies in its high computational overhead for inference, arising from\nthe necessity to store numerous learned parameters and execute individual\nforward passes for each parameter during the inference stage. We propose a\nnovel approach called Diffusion Bridge Network (DBN) to address this challenge.\nBased on the theory of the Schr\\\"odinger bridge, this method directly learns to\nsimulate an Stochastic Differential Equation (SDE) that connects the output\ndistribution of a single ensemble member to the output distribution of the\nensembled model, allowing us to obtain ensemble prediction without having to\ninvoke forward pass through all the ensemble models. By substituting the heavy\nensembles with this lightweight neural network constructing DBN, we achieved\ninference with reduced computational cost while maintaining accuracy and\nuncertainty scores on benchmark datasets such as CIFAR-10, CIFAR-100, and\nTinyImageNet. Our implementation is available at\nhttps://github.com/kim-hyunsu/dbn.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15814v1",
    "published_date": "2024-04-24 11:35:02 UTC",
    "updated_date": "2024-04-24 11:35:02 UTC"
  },
  {
    "arxiv_id": "2405.12990v1",
    "title": "BERT vs GPT for financial engineering",
    "authors": [
      "Edward Sharkey",
      "Philip Treleaven"
    ],
    "abstract": "The paper benchmarks several Transformer models [4], to show how these models\ncan judge sentiment from a news event. This signal can then be used for\ndownstream modelling and signal identification for commodity trading. We find\nthat fine-tuned BERT models outperform fine-tuned or vanilla GPT models on this\ntask. Transformer models have revolutionized the field of natural language\nprocessing (NLP) in recent years, achieving state-of-the-art results on various\ntasks such as machine translation, text summarization, question answering, and\nnatural language generation. Among the most prominent transformer models are\nBidirectional Encoder Representations from Transformers (BERT) and Generative\nPre-trained Transformer (GPT), which differ in their architectures and\nobjectives.\n  A CopBERT model training data and process overview is provided. The CopBERT\nmodel outperforms similar domain specific BERT trained models such as FinBERT.\nThe below confusion matrices show the performance on CopBERT & CopGPT\nrespectively. We see a ~10 percent increase in f1_score when compare CopBERT vs\nGPT4 and 16 percent increase vs CopGPT. Whilst GPT4 is dominant It highlights\nthe importance of considering alternatives to GPT models for financial\nengineering tasks, given risks of hallucinations, and challenges with\ninterpretability. We unsurprisingly see the larger LLMs outperform the BERT\nmodels, with predictive power. In summary BERT is partially the new XGboost,\nwhat it lacks in predictive power it provides with higher levels of\ninterpretability. Concluding that BERT models might not be the next XGboost\n[2], but represent an interesting alternative for financial engineering tasks,\nthat require a blend of interpretability and accuracy.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12990v1",
    "published_date": "2024-04-24 11:30:04 UTC",
    "updated_date": "2024-04-24 11:30:04 UTC"
  },
  {
    "arxiv_id": "2404.15804v1",
    "title": "GeckOpt: LLM System Efficiency via Intent-Based Tool Selection",
    "authors": [
      "Michael Fore",
      "Simranjit Singh",
      "Dimitrios Stamoulis"
    ],
    "abstract": "In this preliminary study, we investigate a GPT-driven intent-based reasoning\napproach to streamline tool selection for large language models (LLMs) aimed at\nsystem efficiency. By identifying the intent behind user prompts at runtime, we\nnarrow down the API toolset required for task execution, reducing token\nconsumption by up to 24.6\\%. Early results on a real-world, massively parallel\nCopilot platform with over 100 GPT-4-Turbo nodes show cost reductions and\npotential towards improving LLM-based system efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "GLSVLSI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15804v1",
    "published_date": "2024-04-24 11:03:15 UTC",
    "updated_date": "2024-04-24 11:03:15 UTC"
  },
  {
    "arxiv_id": "2404.15802v1",
    "title": "Raformer: Redundancy-Aware Transformer for Video Wire Inpainting",
    "authors": [
      "Zhong Ji",
      "Yimu Su",
      "Yan Zhang",
      "Jiacheng Hou",
      "Yanwei Pang",
      "Jungong Han"
    ],
    "abstract": "Video Wire Inpainting (VWI) is a prominent application in video inpainting,\naimed at flawlessly removing wires in films or TV series, offering significant\ntime and labor savings compared to manual frame-by-frame removal. However, wire\nremoval poses greater challenges due to the wires being longer and slimmer than\nobjects typically targeted in general video inpainting tasks, and often\nintersecting with people and background objects irregularly, which adds\ncomplexity to the inpainting process. Recognizing the limitations posed by\nexisting video wire datasets, which are characterized by their small size, poor\nquality, and limited variety of scenes, we introduce a new VWI dataset with a\nnovel mask generation strategy, namely Wire Removal Video Dataset 2 (WRV2) and\nPseudo Wire-Shaped (PWS) Masks. WRV2 dataset comprises over 4,000 videos with\nan average length of 80 frames, designed to facilitate the development and\nefficacy of inpainting models. Building upon this, our research proposes the\nRedundancy-Aware Transformer (Raformer) method that addresses the unique\nchallenges of wire removal in video inpainting. Unlike conventional approaches\nthat indiscriminately process all frame patches, Raformer employs a novel\nstrategy to selectively bypass redundant parts, such as static background\nsegments devoid of valuable information for inpainting. At the core of Raformer\nis the Redundancy-Aware Attention (RAA) module, which isolates and accentuates\nessential content through a coarse-grained, window-based attention mechanism.\nThis is complemented by a Soft Feature Alignment (SFA) module, which refines\nthese features and achieves end-to-end feature alignment. Extensive experiments\non both the traditional video inpainting datasets and our proposed WRV2 dataset\ndemonstrate that Raformer outperforms other state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15802v1",
    "published_date": "2024-04-24 11:02:13 UTC",
    "updated_date": "2024-04-24 11:02:13 UTC"
  },
  {
    "arxiv_id": "2404.15794v2",
    "title": "Large Language Models as In-context AI Generators for Quality-Diversity",
    "authors": [
      "Bryan Lim",
      "Manon Flageat",
      "Antoine Cully"
    ],
    "abstract": "Quality-Diversity (QD) approaches are a promising direction to develop\nopen-ended processes as they can discover archives of high-quality solutions\nacross diverse niches. While already successful in many applications, QD\napproaches usually rely on combining only one or two solutions to generate new\ncandidate solutions. As observed in open-ended processes such as technological\nevolution, wisely combining large diversity of these solutions could lead to\nmore innovative solutions and potentially boost the productivity of QD search.\nIn this work, we propose to exploit the pattern-matching capabilities of\ngenerative models to enable such efficient solution combinations. We introduce\nIn-context QD, a framework of techniques that aim to elicit the in-context\ncapabilities of pre-trained Large Language Models (LLMs) to generate\ninteresting solutions using few-shot and many-shot prompting with\nquality-diverse examples from the QD archive as context. Applied to a series of\ncommon QD domains, In-context QD displays promising results compared to both QD\nbaselines and similar strategies developed for single-objective optimization.\nAdditionally, this result holds across multiple values of parameter sizes and\narchive population sizes, as well as across domains with distinct\ncharacteristics from BBO functions to policy search. Finally, we perform an\nextensive ablation that highlights the key prompt design considerations that\nencourage the generation of promising solutions for QD.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15794v2",
    "published_date": "2024-04-24 10:35:36 UTC",
    "updated_date": "2024-06-05 07:40:08 UTC"
  },
  {
    "arxiv_id": "2404.15781v1",
    "title": "Real-Time Compressed Sensing for Joint Hyperspectral Image Transmission and Restoration for CubeSat",
    "authors": [
      "Chih-Chung Hsu",
      "Chih-Yu Jian",
      "Eng-Shen Tu",
      "Chia-Ming Lee",
      "Guan-Lin Chen"
    ],
    "abstract": "This paper addresses the challenges associated with hyperspectral image (HSI)\nreconstruction from miniaturized satellites, which often suffer from stripe\neffects and are computationally resource-limited. We propose a Real-Time\nCompressed Sensing (RTCS) network designed to be lightweight and require only\nrelatively few training samples for efficient and robust HSI reconstruction in\nthe presence of the stripe effect and under noisy transmission conditions. The\nRTCS network features a simplified architecture that reduces the required\ntraining samples and allows for easy implementation on integer-8-based\nencoders, facilitating rapid compressed sensing for stripe-like HSI, which\nexactly matches the moderate design of miniaturized satellites on push broom\nscanning mechanism. This contrasts optimization-based models that demand\nhigh-precision floating-point operations, making them difficult to deploy on\nedge devices. Our encoder employs an integer-8-compatible linear projection for\nstripe-like HSI data transmission, ensuring real-time compressed sensing.\nFurthermore, based on the novel two-streamed architecture, an efficient HSI\nrestoration decoder is proposed for the receiver side, allowing for edge-device\nreconstruction without needing a sophisticated central server. This is\nparticularly crucial as an increasing number of miniaturized satellites\nnecessitates significant computing resources on the ground station. Extensive\nexperiments validate the superior performance of our approach, offering new and\nvital capabilities for existing miniaturized satellite systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by TGRS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15781v1",
    "published_date": "2024-04-24 10:03:37 UTC",
    "updated_date": "2024-04-24 10:03:37 UTC"
  },
  {
    "arxiv_id": "2404.15774v1",
    "title": "Toward Physics-Aware Deep Learning Architectures for LiDAR Intensity Simulation",
    "authors": [
      "Vivek Anand",
      "Bharat Lohani",
      "Gaurav Pandey",
      "Rakesh Mishra"
    ],
    "abstract": "Autonomous vehicles (AVs) heavily rely on LiDAR perception for environment\nunderstanding and navigation. LiDAR intensity provides valuable information\nabout the reflected laser signals and plays a crucial role in enhancing the\nperception capabilities of AVs. However, accurately simulating LiDAR intensity\nremains a challenge due to the unavailability of material properties of the\nobjects in the environment, and complex interactions between the laser beam and\nthe environment. The proposed method aims to improve the accuracy of intensity\nsimulation by incorporating physics-based modalities within the deep learning\nframework. One of the key entities that captures the interaction between the\nlaser beam and the objects is the angle of incidence. In this work we\ndemonstrate that the addition of the LiDAR incidence angle as a separate input\nto the deep neural networks significantly enhances the results. We present a\ncomparative study between two prominent deep learning architectures: U-NET a\nConvolutional Neural Network (CNN), and Pix2Pix a Generative Adversarial\nNetwork (GAN). We implemented these two architectures for the intensity\nprediction task and used SemanticKITTI and VoxelScape datasets for experiments.\nThe comparative analysis reveals that both architectures benefit from the\nincidence angle as an additional input. Moreover, the Pix2Pix architecture\noutperforms U-NET, especially when the incidence angle is incorporated.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.15774v1",
    "published_date": "2024-04-24 09:52:36 UTC",
    "updated_date": "2024-04-24 09:52:36 UTC"
  },
  {
    "arxiv_id": "2404.15766v2",
    "title": "Unifying Bayesian Flow Networks and Diffusion Models through Stochastic Differential Equations",
    "authors": [
      "Kaiwen Xue",
      "Yuhao Zhou",
      "Shen Nie",
      "Xu Min",
      "Xiaolu Zhang",
      "Jun Zhou",
      "Chongxuan Li"
    ],
    "abstract": "Bayesian flow networks (BFNs) iteratively refine the parameters, instead of\nthe samples in diffusion models (DMs), of distributions at various noise levels\nthrough Bayesian inference. Owing to its differentiable nature, BFNs are\npromising in modeling both continuous and discrete data, while simultaneously\nmaintaining fast sampling capabilities. This paper aims to understand and\nenhance BFNs by connecting them with DMs through stochastic differential\nequations (SDEs). We identify the linear SDEs corresponding to the\nnoise-addition processes in BFNs, demonstrate that BFN's regression losses are\naligned with denoise score matching, and validate the sampler in BFN as a\nfirst-order solver for the respective reverse-time SDE. Based on these findings\nand existing recipes of fast sampling in DMs, we propose specialized solvers\nfor BFNs that markedly surpass the original BFN sampler in terms of sample\nquality with a limited number of function evaluations (e.g., 10) on both image\nand text datasets. Notably, our best sampler achieves an increase in speed of\n5~20 times for free. Our code is available at\nhttps://github.com/ML-GSAI/BFN-Solver.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15766v2",
    "published_date": "2024-04-24 09:39:06 UTC",
    "updated_date": "2024-06-02 13:55:21 UTC"
  },
  {
    "arxiv_id": "2404.15760v1",
    "title": "Debiasing Machine Unlearning with Counterfactual Examples",
    "authors": [
      "Ziheng Chen",
      "Jia Wang",
      "Jun Zhuang",
      "Abbavaram Gowtham Reddy",
      "Fabrizio Silvestri",
      "Jin Huang",
      "Kaushiki Nag",
      "Kun Kuang",
      "Xin Ning",
      "Gabriele Tolomei"
    ],
    "abstract": "The right to be forgotten (RTBF) seeks to safeguard individuals from the\nenduring effects of their historical actions by implementing machine-learning\ntechniques. These techniques facilitate the deletion of previously acquired\nknowledge without requiring extensive model retraining. However, they often\noverlook a critical issue: unlearning processes bias. This bias emerges from\ntwo main sources: (1) data-level bias, characterized by uneven data removal,\nand (2) algorithm-level bias, which leads to the contamination of the remaining\ndataset, thereby degrading model accuracy. In this work, we analyze the causal\nfactors behind the unlearning process and mitigate biases at both data and\nalgorithmic levels. Typically, we introduce an intervention-based approach,\nwhere knowledge to forget is erased with a debiased dataset. Besides, we guide\nthe forgetting procedure by leveraging counterfactual examples, as they\nmaintain semantic data consistency without hurting performance on the remaining\ndataset. Experimental results demonstrate that our method outperforms existing\nmachine unlearning baselines on evaluation metrics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15760v1",
    "published_date": "2024-04-24 09:33:10 UTC",
    "updated_date": "2024-04-24 09:33:10 UTC"
  },
  {
    "arxiv_id": "2404.15758v1",
    "title": "Let's Think Dot by Dot: Hidden Computation in Transformer Language Models",
    "authors": [
      "Jacob Pfau",
      "William Merrill",
      "Samuel R. Bowman"
    ],
    "abstract": "Chain-of-thought responses from language models improve performance across\nmost benchmarks. However, it remains unclear to what extent these performance\ngains can be attributed to human-like task decomposition or simply the greater\ncomputation that additional tokens allow. We show that transformers can use\nmeaningless filler tokens (e.g., '......') in place of a chain of thought to\nsolve two hard algorithmic tasks they could not solve when responding without\nintermediate tokens. However, we find empirically that learning to use filler\ntokens is difficult and requires specific, dense supervision to converge. We\nalso provide a theoretical characterization of the class of problems where\nfiller tokens are useful in terms of the quantifier depth of a first-order\nformula. For problems satisfying this characterization, chain-of-thought tokens\nneed not provide information about the intermediate computational steps\ninvolved in multi-token computations. In summary, our results show that\nadditional tokens can provide computational benefits independent of token\nchoice. The fact that intermediate tokens can act as filler tokens raises\nconcerns about large language models engaging in unauditable, hidden\ncomputations that are increasingly detached from the observed chain-of-thought\ntokens.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.15758v1",
    "published_date": "2024-04-24 09:30:00 UTC",
    "updated_date": "2024-04-24 09:30:00 UTC"
  },
  {
    "arxiv_id": "2405.00055v2",
    "title": "A Hybrid Probabilistic Battery Health Management Approach for Robust Inspection Drone Operations",
    "authors": [
      "Jokin Alcibar",
      "Jose I. Aizpurua",
      "Ekhi Zugastia",
      "Oier Penagarikano"
    ],
    "abstract": "Health monitoring of remote critical infrastructure is a complex and\nexpensive activity due to the limited infrastructure accessibility. Inspection\ndrones are ubiquitous assets that enhance the reliability of critical\ninfrastructures through improved accessibility. However, due to the harsh\noperation environment, it is crucial to monitor their health to ensure\nsuccessful inspection operations. The battery is a key component that\ndetermines the overall reliability of the inspection drones and, with an\nappropriate health management approach, contributes to reliable and robust\ninspections. In this context, this paper presents a novel hybrid probabilistic\napproach for battery end-of-discharge (EOD) voltage prediction of Li-Po\nbatteries. The hybridization is achieved in an error-correction configuration,\nwhich combines physics-based discharge and probabilistic error-correction\nmodels to quantify the aleatoric and epistemic uncertainty. The performance of\nthe hybrid probabilistic methodology was empirically evaluated on a dataset\ncomprising EOD voltage under varying load conditions. The dataset was obtained\nfrom real inspection drones operated on different flights, focused on offshore\nwind turbine inspections. The proposed approach has been tested with different\nprobabilistic methods and demonstrates 14.8% improved performance in\nprobabilistic accuracy compared to the best probabilistic method. In addition,\naleatoric and epistemic uncertainties provide robust estimations to enhance the\ndiagnosis of battery health-states.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00055v2",
    "published_date": "2024-04-24 09:22:18 UTC",
    "updated_date": "2024-12-20 12:27:01 UTC"
  },
  {
    "arxiv_id": "2404.15751v1",
    "title": "Guided-SPSA: Simultaneous Perturbation Stochastic Approximation assisted by the Parameter Shift Rule",
    "authors": [
      "Maniraman Periyasamy",
      "Axel Plinge",
      "Christopher Mutschler",
      "Daniel D. Scherer",
      "Wolfgang Mauerer"
    ],
    "abstract": "The study of variational quantum algorithms (VQCs) has received significant\nattention from the quantum computing community in recent years. These hybrid\nalgorithms, utilizing both classical and quantum components, are well-suited\nfor noisy intermediate-scale quantum devices. Though estimating exact gradients\nusing the parameter-shift rule to optimize the VQCs is realizable in NISQ\ndevices, they do not scale well for larger problem sizes. The computational\ncomplexity, in terms of the number of circuit evaluations required for gradient\nestimation by the parameter-shift rule, scales linearly with the number of\nparameters in VQCs. On the other hand, techniques that approximate the\ngradients of the VQCs, such as the simultaneous perturbation stochastic\napproximation (SPSA), do not scale with the number of parameters but struggle\nwith instability and often attain suboptimal solutions. In this work, we\nintroduce a novel gradient estimation approach called Guided-SPSA, which\nmeaningfully combines the parameter-shift rule and SPSA-based gradient\napproximation. The Guided-SPSA results in a 15% to 25% reduction in the number\nof circuit evaluations required during training for a similar or better\noptimality of the solution found compared to the parameter-shift rule. The\nGuided-SPSA outperforms standard SPSA in all scenarios and outperforms the\nparameter-shift rule in scenarios such as suboptimal initialization of the\nparameters. We demonstrate numerically the performance of Guided-SPSA on\ndifferent paradigms of quantum machine learning, such as regression,\nclassification, and reinforcement learning.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2404.15751v1",
    "published_date": "2024-04-24 09:13:39 UTC",
    "updated_date": "2024-04-24 09:13:39 UTC"
  },
  {
    "arxiv_id": "2404.16890v1",
    "title": "NEPENTHE: Entropy-Based Pruning as a Neural Network Depth's Reducer",
    "authors": [
      "Zhu Liao",
      "Victor Qutu",
      "Van-Tam Nguyen",
      "Enzo Tartaglione"
    ],
    "abstract": "While deep neural networks are highly effective at solving complex tasks,\ntheir computational demands can hinder their usefulness in real-time\napplications and with limited-resources systems. Besides, for many tasks it is\nknown that these models are over-parametrized: neoteric works have broadly\nfocused on reducing the width of these networks, rather than their depth. In\nthis paper, we aim to reduce the depth of over-parametrized deep neural\nnetworks: we propose an eNtropy-basEd Pruning as a nEural Network depTH's\nrEducer (NEPENTHE) to alleviate deep neural networks' computational burden.\nBased on our theoretical finding, NEPENTHE focuses on un-structurally pruning\nconnections in layers with low entropy to remove them entirely. We validate our\napproach on popular architectures such as MobileNet and Swin-T, showing that\nwhen encountering an over-parametrization regime, it can effectively linearize\nsome layers (hence reducing the model's depth) with little to no performance\nloss. The code will be publicly available upon acceptance of the article.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16890v1",
    "published_date": "2024-04-24 09:12:04 UTC",
    "updated_date": "2024-04-24 09:12:04 UTC"
  },
  {
    "arxiv_id": "2404.15744v2",
    "title": "A General Black-box Adversarial Attack on Graph-based Fake News Detectors",
    "authors": [
      "Peican Zhu",
      "Zechen Pan",
      "Yang Liu",
      "Jiwei Tian",
      "Keke Tang",
      "Zhen Wang"
    ],
    "abstract": "Graph Neural Network (GNN)-based fake news detectors apply various methods to\nconstruct graphs, aiming to learn distinctive news embeddings for\nclassification. Since the construction details are unknown for attackers in a\nblack-box scenario, it is unrealistic to conduct the classical adversarial\nattacks that require a specific adjacency matrix. In this paper, we propose the\nfirst general black-box adversarial attack framework, i.e., General Attack via\nFake Social Interaction (GAFSI), against detectors based on different graph\nstructures. Specifically, as sharing is an important social interaction for\nGNN-based fake news detectors to construct the graph, we simulate sharing\nbehaviors to fool the detectors. Firstly, we propose a fraudster selection\nmodule to select engaged users leveraging local and global information. In\naddition, a post injection module guides the selected users to create shared\nrelations by sending posts. The sharing records will be added to the social\ncontext, leading to a general attack against different detectors. Experimental\nresults on empirical datasets demonstrate the effectiveness of GAFSI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15744v2",
    "published_date": "2024-04-24 09:04:05 UTC",
    "updated_date": "2024-04-26 01:52:38 UTC"
  },
  {
    "arxiv_id": "2404.15736v2",
    "title": "What Makes Multimodal In-Context Learning Work?",
    "authors": [
      "Folco Bertini Baldassini",
      "Mustafa Shukor",
      "Matthieu Cord",
      "Laure Soulier",
      "Benjamin Piwowarski"
    ],
    "abstract": "Large Language Models have demonstrated remarkable performance across various\ntasks, exhibiting the capacity to swiftly acquire new skills, such as through\nIn-Context Learning (ICL) with minimal demonstration examples. In this work, we\npresent a comprehensive framework for investigating Multimodal ICL (M-ICL) in\nthe context of Large Multimodal Models. We consider the best open-source\nmultimodal models (e.g., IDEFICS, OpenFlamingo) and a wide range of multimodal\ntasks. Our study unveils several noteworthy findings: (1) M-ICL primarily\nrelies on text-driven mechanisms, showing little to no influence from the image\nmodality. (2) When used with advanced-ICL strategy (like RICES), M-ICL is not\nbetter than a simple strategy based on majority voting over context examples.\nMoreover, we identify several biases and limitations of M-ICL that warrant\nconsideration prior to deployment. Code available at\nhttps://gitlab.com/folbaeni/multimodal-icl",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 16 figures. Accepted to CVPR 2024 Workshop on Prompting in\n  Vision. Project page: https://folbaeni.gitlab.io/multimodal-icl",
    "pdf_url": "http://arxiv.org/pdf/2404.15736v2",
    "published_date": "2024-04-24 08:50:45 UTC",
    "updated_date": "2024-04-25 06:04:16 UTC"
  },
  {
    "arxiv_id": "2404.15721v2",
    "title": "SPARO: Selective Attention for Robust and Compositional Transformer Encodings for Vision",
    "authors": [
      "Ankit Vani",
      "Bac Nguyen",
      "Samuel Lavoie",
      "Ranjay Krishna",
      "Aaron Courville"
    ],
    "abstract": "Selective attention helps us focus on task-relevant aspects in the constant\nflood of our sensory input. This constraint in our perception allows us to\nrobustly generalize under distractions and to new compositions of perceivable\nconcepts. Transformers employ a similar notion of attention in their\narchitecture, but representation learning models with transformer backbones\nlike CLIP and DINO often fail to demonstrate robustness and compositionality.\nWe highlight a missing architectural prior: unlike human perception,\ntransformer encodings do not separately attend over individual concepts. In\nresponse, we propose SPARO, a read-out mechanism that partitions encodings into\nseparately-attended slots, each produced by a single attention head. Using\nSPARO with CLIP imparts an inductive bias that the vision and text modalities\nare different views of a shared compositional world with the same corresponding\nconcepts. Using SPARO, we demonstrate improvements on downstream recognition,\nrobustness, retrieval, and compositionality benchmarks with CLIP (up to +14%\nfor ImageNet, +4% for SugarCrepe), and on nearest neighbors and linear probe\nfor ImageNet with DINO (+3% each). We also showcase a powerful ability to\nintervene and select individual SPARO concepts to further improve downstream\ntask performance (up from +4% to +9% for SugarCrepe) and use this ability to\nstudy the robustness of SPARO's representation structure. Finally, we provide\ninsights through ablation experiments and visualization of learned concepts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Conference paper at ECCV 2024. 11 pages main, 23 pages total\n  including references and appendix",
    "pdf_url": "http://arxiv.org/pdf/2404.15721v2",
    "published_date": "2024-04-24 08:15:36 UTC",
    "updated_date": "2024-09-14 05:05:01 UTC"
  },
  {
    "arxiv_id": "2404.15719v2",
    "title": "HDBN: A Novel Hybrid Dual-branch Network for Robust Skeleton-based Action Recognition",
    "authors": [
      "Jinfu Liu",
      "Baiqiao Yin",
      "Jiaying Lin",
      "Jiajun Wen",
      "Yue Li",
      "Mengyuan Liu"
    ],
    "abstract": "Skeleton-based action recognition has gained considerable traction thanks to\nits utilization of succinct and robust skeletal representations. Nonetheless,\ncurrent methodologies often lean towards utilizing a solitary backbone to model\nskeleton modality, which can be limited by inherent flaws in the network\nbackbone. To address this and fully leverage the complementary characteristics\nof various network architectures, we propose a novel Hybrid Dual-Branch Network\n(HDBN) for robust skeleton-based action recognition, which benefits from the\ngraph convolutional network's proficiency in handling graph-structured data and\nthe powerful modeling capabilities of Transformers for global information. In\ndetail, our proposed HDBN is divided into two trunk branches: MixGCN and\nMixFormer. The two branches utilize GCNs and Transformers to model both 2D and\n3D skeletal modalities respectively. Our proposed HDBN emerged as one of the\ntop solutions in the Multi-Modal Video Reasoning and Analyzing Competition\n(MMVRAC) of 2024 ICME Grand Challenge, achieving accuracies of 47.95% and\n75.36% on two benchmarks of the UAV-Human dataset by outperforming most\nexisting methods. Our code will be publicly available at:\nhttps://github.com/liujf69/ICMEW2024-Track10.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15719v2",
    "published_date": "2024-04-24 08:11:50 UTC",
    "updated_date": "2024-04-25 08:27:34 UTC"
  },
  {
    "arxiv_id": "2404.15714v1",
    "title": "Ada-DF: An Adaptive Label Distribution Fusion Network For Facial Expression Recognition",
    "authors": [
      "Shu Liu",
      "Yan Xu",
      "Tongming Wan",
      "Xiaoyan Kui"
    ],
    "abstract": "Facial expression recognition (FER) plays a significant role in our daily\nlife. However, annotation ambiguity in the datasets could greatly hinder the\nperformance. In this paper, we address FER task via label distribution learning\nparadigm, and develop a dual-branch Adaptive Distribution Fusion (Ada-DF)\nframework. One auxiliary branch is constructed to obtain the label\ndistributions of samples. The class distributions of emotions are then computed\nthrough the label distributions of each emotion. Finally, those two\ndistributions are adaptively fused according to the attention weights to train\nthe target branch. Extensive experiments are conducted on three real-world\ndatasets, RAF-DB, AffectNet and SFEW, where our Ada-DF shows advantages over\nthe state-of-the-art works.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15714v1",
    "published_date": "2024-04-24 08:07:16 UTC",
    "updated_date": "2024-04-24 08:07:16 UTC"
  },
  {
    "arxiv_id": "2404.15704v1",
    "title": "Efficient Multi-Model Fusion with Adversarial Complementary Representation Learning",
    "authors": [
      "Zuheng Kang",
      "Yayun He",
      "Jianzong Wang",
      "Junqing Peng",
      "Jing Xiao"
    ],
    "abstract": "Single-model systems often suffer from deficiencies in tasks such as speaker\nverification (SV) and image classification, relying heavily on partial prior\nknowledge during decision-making, resulting in suboptimal performance. Although\nmulti-model fusion (MMF) can mitigate some of these issues, redundancy in\nlearned representations may limits improvements. To this end, we propose an\nadversarial complementary representation learning (ACoRL) framework that\nenables newly trained models to avoid previously acquired knowledge, allowing\neach individual component model to learn maximally distinct, complementary\nrepresentations. We make three detailed explanations of why this works and\nexperimental results demonstrate that our method more efficiently improves\nperformance compared to traditional MMF. Furthermore, attribution analysis\nvalidates the model trained under ACoRL acquires more complementary knowledge,\nhighlighting the efficacy of our approach in enhancing efficiency and\nrobustness across tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 2024 International Joint Conference on Neural\n  Networks (IJCNN 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.15704v1",
    "published_date": "2024-04-24 07:47:55 UTC",
    "updated_date": "2024-04-24 07:47:55 UTC"
  },
  {
    "arxiv_id": "2404.15697v1",
    "title": "DeepFeatureX Net: Deep Features eXtractors based Network for discriminating synthetic from real images",
    "authors": [
      "Orazio Pontorno",
      "Luca Guarnera",
      "Sebastiano Battiato"
    ],
    "abstract": "Deepfakes, synthetic images generated by deep learning algorithms, represent\none of the biggest challenges in the field of Digital Forensics. The scientific\ncommunity is working to develop approaches that can discriminate the origin of\ndigital images (real or AI-generated). However, these methodologies face the\nchallenge of generalization, that is, the ability to discern the nature of an\nimage even if it is generated by an architecture not seen during training. This\nusually leads to a drop in performance. In this context, we propose a novel\napproach based on three blocks called Base Models, each of which is responsible\nfor extracting the discriminative features of a specific image class (Diffusion\nModel-generated, GAN-generated, or real) as it is trained by exploiting\ndeliberately unbalanced datasets. The features extracted from each block are\nthen concatenated and processed to discriminate the origin of the input image.\nExperimental results showed that this approach not only demonstrates good\nrobust capabilities to JPEG compression but also outperforms state-of-the-art\nmethods in several generalization tests. Code, models and dataset are available\nat https://github.com/opontorno/block-based_deepfake-detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15697v1",
    "published_date": "2024-04-24 07:25:36 UTC",
    "updated_date": "2024-04-24 07:25:36 UTC"
  },
  {
    "arxiv_id": "2404.15687v2",
    "title": "Graph Neural Networks for Vulnerability Detection: A Counterfactual Explanation",
    "authors": [
      "Zhaoyang Chu",
      "Yao Wan",
      "Qian Li",
      "Yang Wu",
      "Hongyu Zhang",
      "Yulei Sui",
      "Guandong Xu",
      "Hai Jin"
    ],
    "abstract": "Vulnerability detection is crucial for ensuring the security and reliability\nof software systems. Recently, Graph Neural Networks (GNNs) have emerged as a\nprominent code embedding approach for vulnerability detection, owing to their\nability to capture the underlying semantic structure of source code. However,\nGNNs face significant challenges in explainability due to their inherently\nblack-box nature. To this end, several factual reasoning-based explainers have\nbeen proposed. These explainers provide explanations for the predictions made\nby GNNs by analyzing the key features that contribute to the outcomes. We argue\nthat these factual reasoning-based explanations cannot answer critical what-if\nquestions: What would happen to the GNN's decision if we were to alter the code\ngraph into alternative structures? Inspired by advancements of counterfactual\nreasoning in artificial intelligence, we propose CFExplainer, a novel\ncounterfactual explainer for GNN-based vulnerability detection. Unlike factual\nreasoning-based explainers, CFExplainer seeks the minimal perturbation to the\ninput code graph that leads to a change in the prediction, thereby addressing\nthe what-if questions for vulnerability detection. We term this perturbation a\ncounterfactual explanation, which can pinpoint the root causes of the detected\nvulnerability and furnish valuable insights for developers to undertake\nappropriate actions for fixing the vulnerability. Extensive experiments on four\nGNN-based vulnerability detection models demonstrate the effectiveness of\nCFExplainer over existing state-of-the-art factual reasoning-based explainers.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper was accepted in the proceedings of the 33rd ACM SIGSOFT\n  International Symposium on Software Testing and Analysis (ISSTA 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.15687v2",
    "published_date": "2024-04-24 06:52:53 UTC",
    "updated_date": "2024-07-15 14:05:49 UTC"
  },
  {
    "arxiv_id": "2404.15681v2",
    "title": "Automated Creation of Source Code Variants of a Cryptographic Hash Function Implementation Using Generative Pre-Trained Transformer Models",
    "authors": [
      "Elijah Pelofske",
      "Vincent Urias",
      "Lorie M. Liebrock"
    ],
    "abstract": "Generative pre-trained transformers (GPT's) are a type of large language\nmachine learning model that are unusually adept at producing novel, and\ncoherent, natural language. In this study the ability of GPT models to generate\nnovel and correct versions, and notably very insecure versions, of\nimplementations of the cryptographic hash function SHA-1 is examined. The GPT\nmodels Llama-2-70b-chat-h, Mistral-7B-Instruct-v0.1, and zephyr-7b-alpha are\nused. The GPT models are prompted to re-write each function using a modified\nversion of the localGPT framework and langchain to provide word embedding\ncontext of the full source code and header files to the model, resulting in\nover 150,000 function re-write GPT output text blocks, approximately 50,000 of\nwhich were able to be parsed as C code and subsequently compiled. The generated\ncode is analyzed for being compilable, correctness of the algorithm, memory\nleaks, compiler optimization stability, and character distance to the reference\nimplementation. Remarkably, several generated function variants have a high\nimplementation security risk of being correct for some test vectors, but\nincorrect for other test vectors. Additionally, many function implementations\nwere not correct to the reference algorithm of SHA-1, but produced hashes that\nhave some of the basic characteristics of hash functions. Many of the function\nre-writes contained serious flaws such as memory leaks, integer overflows, out\nof bounds accesses, use of uninitialised values, and compiler optimization\ninstability. Compiler optimization settings and SHA-256 hash checksums of the\ncompiled binaries are used to cluster implementations that are equivalent but\nmay not have identical syntax - using this clustering over 100,000 novel and\ncorrect versions of the SHA-1 codebase were generated where each component C\nfunction of the reference implementation is different from the original code.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15681v2",
    "published_date": "2024-04-24 06:29:55 UTC",
    "updated_date": "2024-07-10 03:32:36 UTC"
  },
  {
    "arxiv_id": "2404.15678v4",
    "title": "Retrieval and Distill: A Temporal Data Shift-Free Paradigm for Online Recommendation System",
    "authors": [
      "Lei Zheng",
      "Ning Li",
      "Weinan Zhang",
      "Yong Yu"
    ],
    "abstract": "Current recommendation systems are significantly affected by a serious issue\nof temporal data shift, which is the inconsistency between the distribution of\nhistorical data and that of online data. Most existing models focus on\nutilizing updated data, overlooking the transferable, temporal data shift-free\ninformation that can be learned from shifting data. We propose the Temporal\nInvariance of Association theorem, which suggests that given a fixed search\nspace, the relationship between the data and the data in the search space keeps\ninvariant over time. Leveraging this principle, we designed a retrieval-based\nrecommendation system framework that can train a data shift-free relevance\nnetwork using shifting data, significantly enhancing the predictive performance\nof the original model in the recommendation system. However, retrieval-based\nrecommendation models face substantial inference time costs when deployed\nonline. To address this, we further designed a distill framework that can\ndistill information from the relevance network into a parameterized module\nusing shifting data. The distilled model can be deployed online alongside the\noriginal model, with only a minimal increase in inference time. Extensive\nexperiments on multiple real datasets demonstrate that our framework\nsignificantly improves the performance of the original model by utilizing\nshifting data.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15678v4",
    "published_date": "2024-04-24 06:16:09 UTC",
    "updated_date": "2024-06-13 07:53:06 UTC"
  },
  {
    "arxiv_id": "2404.15676v3",
    "title": "Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs",
    "authors": [
      "Yu Xia",
      "Rui Wang",
      "Xu Liu",
      "Mingyan Li",
      "Tong Yu",
      "Xiang Chen",
      "Julian McAuley",
      "Shuai Li"
    ],
    "abstract": "Chain-of-Thought (CoT) has been a widely adopted prompting method, eliciting\nimpressive reasoning abilities of Large Language Models (LLMs). Inspired by the\nsequential thought structure of CoT, a number of Chain-of-X (CoX) methods have\nbeen developed to address various challenges across diverse domains and tasks\ninvolving LLMs. In this paper, we provide a comprehensive survey of Chain-of-X\nmethods for LLMs in different contexts. Specifically, we categorize them by\ntaxonomies of nodes, i.e., the X in CoX, and application tasks. We also discuss\nthe findings and implications of existing CoX methods, as well as potential\nfuture directions. Our survey aims to serve as a detailed and up-to-date\nresource for researchers seeking to apply the idea of CoT to broader scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.15676v3",
    "published_date": "2024-04-24 06:12:00 UTC",
    "updated_date": "2025-02-05 22:01:59 UTC"
  },
  {
    "arxiv_id": "2404.15667v4",
    "title": "The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews",
    "authors": [
      "Aleksi Huotala",
      "Miikka Kuutila",
      "Paul Ralph",
      "Mika Mntyl"
    ],
    "abstract": "Systematic review (SR) is a popular research method in software engineering\n(SE). However, conducting an SR takes an average of 67 weeks. Thus, automating\nany step of the SR process could reduce the effort associated with SRs. Our\nobjective is to investigate if Large Language Models (LLMs) can accelerate\ntitle-abstract screening by simplifying abstracts for human screeners, and\nautomating title-abstract screening. We performed an experiment where humans\nscreened titles and abstracts for 20 papers with both original and simplified\nabstracts from a prior SR. The experiment with human screeners was reproduced\nwith GPT-3.5 and GPT-4 LLMs to perform the same screening tasks. We also\nstudied if different prompting techniques (Zero-shot (ZS), One-shot (OS),\nFew-shot (FS), and Few-shot with Chain-of-Thought (FS-CoT)) improve the\nscreening performance of LLMs. Lastly, we studied if redesigning the prompt\nused in the LLM reproduction of screening leads to improved performance. Text\nsimplification did not increase the screeners' screening performance, but\nreduced the time used in screening. Screeners' scientific literacy skills and\nresearcher status predict screening performance. Some LLM and prompt\ncombinations perform as well as human screeners in the screening tasks. Our\nresults indicate that the GPT-4 LLM is better than its predecessor, GPT-3.5.\nAdditionally, Few-shot and One-shot prompting outperforms Zero-shot prompting.\nUsing LLMs for text simplification in the screening process does not\nsignificantly improve human performance. Using LLMs to automate title-abstract\nscreening seems promising, but current LLMs are not significantly more accurate\nthan human screeners. To recommend the use of LLMs in the screening process of\nSRs, more research is needed. We recommend future SR studies publish\nreplication packages with screening data to enable more conclusive\nexperimenting with LLM screening.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the International Conference on Evaluation and Assessment\n  in Software Engineering (EASE), 2024 edition",
    "pdf_url": "http://arxiv.org/pdf/2404.15667v4",
    "published_date": "2024-04-24 05:53:20 UTC",
    "updated_date": "2024-05-08 11:28:50 UTC"
  },
  {
    "arxiv_id": "2404.15657v1",
    "title": "FedSI: Federated Subnetwork Inference for Efficient Uncertainty Quantification",
    "authors": [
      "Hui Chen",
      "Hengyu Liu",
      "Zhangkai Wu",
      "Xuhui Fan",
      "Longbing Cao"
    ],
    "abstract": "While deep neural networks (DNNs) based personalized federated learning (PFL)\nis demanding for addressing data heterogeneity and shows promising performance,\nexisting methods for federated learning (FL) suffer from efficient systematic\nuncertainty quantification. The Bayesian DNNs-based PFL is usually questioned\nof either over-simplified model structures or high computational and memory\ncosts. In this paper, we introduce FedSI, a novel Bayesian DNNs-based\nsubnetwork inference PFL framework. FedSI is simple and scalable by leveraging\nBayesian methods to incorporate systematic uncertainties effectively. It\nimplements a client-specific subnetwork inference mechanism, selects network\nparameters with large variance to be inferred through posterior distributions,\nand fixes the rest as deterministic ones. FedSI achieves fast and scalable\ninference while preserving the systematic uncertainties to the fullest extent.\nExtensive experiments on three different benchmark datasets demonstrate that\nFedSI outperforms existing Bayesian and non-Bayesian FL baselines in\nheterogeneous FL scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15657v1",
    "published_date": "2024-04-24 05:24:08 UTC",
    "updated_date": "2024-04-24 05:24:08 UTC"
  },
  {
    "arxiv_id": "2404.15653v1",
    "title": "CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data",
    "authors": [
      "Sachin Mehta",
      "Maxwell Horton",
      "Fartash Faghri",
      "Mohammad Hossein Sekhavat",
      "Mahyar Najibi",
      "Mehrdad Farajtabar",
      "Oncel Tuzel",
      "Mohammad Rastegari"
    ],
    "abstract": "Contrastive learning has emerged as a transformative method for learning\neffective visual representations through the alignment of image and text\nembeddings. However, pairwise similarity computation in contrastive loss\nbetween image and text pairs poses computational challenges. This paper\npresents a novel weakly supervised pre-training of vision models on web-scale\nimage-text data. The proposed method reframes pre-training on image-text data\nas a classification task. Consequently, it eliminates the need for pairwise\nsimilarity computations in contrastive loss, achieving a remarkable $2.7\\times$\nacceleration in training speed compared to contrastive learning on web-scale\ndata. Through extensive experiments spanning diverse vision tasks, including\ndetection and segmentation, we demonstrate that the proposed method maintains\nhigh representation quality. Our source code along with pre-trained model\nweights and training recipes is available at\n\\url{https://github.com/apple/corenet}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15653v1",
    "published_date": "2024-04-24 05:13:28 UTC",
    "updated_date": "2024-04-24 05:13:28 UTC"
  },
  {
    "arxiv_id": "2404.15648v2",
    "title": "Cross-Embodied Affordance Transfer through Learning Affordance Equivalences",
    "authors": [
      "Hakan Aktas",
      "Yukie Nagai",
      "Minoru Asada",
      "Matteo Saveriano",
      "Erhan Oztop",
      "Emre Ugur"
    ],
    "abstract": "Affordances represent the inherent effect and action possibilities that\nobjects offer to the agents within a given context. From a theoretical\nviewpoint, affordances bridge the gap between effect and action, providing a\nfunctional understanding of the connections between the actions of an agent and\nits environment in terms of the effects it can cause. In this study, we propose\na deep neural network model that unifies objects, actions, and effects into a\nsingle latent vector in a common latent space that we call the affordance\nspace. Using the affordance space, our system can generate effect trajectories\nwhen action and object are given and can generate action trajectories when\neffect trajectories and objects are given. Our model does not learn the\nbehavior of individual objects acted upon by a single agent. Still, rather, it\nforms a `shared affordance representation' spanning multiple agents and\nobjects, which we call Affordance Equivalence. Affordance Equivalence\nfacilitates not only action generalization over objects but also Cross\nEmbodiment transfer linking actions of different robots. In addition to the\nsimulation experiments that demonstrate the proposed model's range of\ncapabilities, we also showcase that our model can be used for direct imitation\nin real-world settings.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 9 figures, Submitted to IEEE Transactions on Cognitive and\n  Developmental Systems",
    "pdf_url": "http://arxiv.org/pdf/2404.15648v2",
    "published_date": "2024-04-24 05:07:36 UTC",
    "updated_date": "2024-10-10 01:18:06 UTC"
  },
  {
    "arxiv_id": "2404.16076v1",
    "title": "Semantic Evolvement Enhanced Graph Autoencoder for Rumor Detection",
    "authors": [
      "Xiang Tao",
      "Liang Wang",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "abstract": "Due to the rapid spread of rumors on social media, rumor detection has become\nan extremely important challenge. Recently, numerous rumor detection models\nwhich utilize textual information and the propagation structure of events have\nbeen proposed. However, these methods overlook the importance of semantic\nevolvement information of event in propagation process, which is often\nchallenging to be truly learned in supervised training paradigms and\ntraditional rumor detection methods. To address this issue, we propose a novel\nsemantic evolvement enhanced Graph Autoencoder for Rumor Detection (GARD) model\nin this paper. The model learns semantic evolvement information of events by\ncapturing local semantic changes and global semantic evolvement information\nthrough specific graph autoencoder and reconstruction strategies. By combining\nsemantic evolvement information and propagation structure information, the\nmodel achieves a comprehensive understanding of event propagation and perform\naccurate and robust detection, while also detecting rumors earlier by capturing\nsemantic evolvement information in the early stages. Moreover, in order to\nenhance the model's ability to learn the distinct patterns of rumors and\nnon-rumors, we introduce a uniformity regularizer to further improve the\nmodel's performance. Experimental results on three public benchmark datasets\nconfirm the superiority of our GARD method over the state-of-the-art approaches\nin both overall performance and early rumor detection.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16076v1",
    "published_date": "2024-04-24 05:05:58 UTC",
    "updated_date": "2024-04-24 05:05:58 UTC"
  },
  {
    "arxiv_id": "2404.15638v1",
    "title": "PriorNet: A Novel Lightweight Network with Multidimensional Interactive Attention for Efficient Image Dehazing",
    "authors": [
      "Yutong Chen",
      "Zhang Wen",
      "Chao Wang",
      "Lei Gong",
      "Zhongchao Yi"
    ],
    "abstract": "Hazy images degrade visual quality, and dehazing is a crucial prerequisite\nfor subsequent processing tasks. Most current dehazing methods rely on neural\nnetworks and face challenges such as high computational parameter pressure and\nweak generalization capabilities. This paper introduces PriorNet--a novel,\nlightweight, and highly applicable dehazing network designed to significantly\nimprove the clarity and visual quality of hazy images while avoiding excessive\ndetail extraction issues. The core of PriorNet is the original\nMulti-Dimensional Interactive Attention (MIA) mechanism, which effectively\ncaptures a wide range of haze characteristics, substantially reducing the\ncomputational load and generalization difficulties associated with complex\nsystems. By utilizing a uniform convolutional kernel size and incorporating\nskip connections, we have streamlined the feature extraction process.\nSimplifying the number of layers and architecture not only enhances dehazing\nefficiency but also facilitates easier deployment on edge devices. Extensive\ntesting across multiple datasets has demonstrated PriorNet's exceptional\nperformance in dehazing and clarity restoration, maintaining image detail and\ncolor fidelity in single-image dehazing tasks. Notably, with a model size of\njust 18Kb, PriorNet showcases superior dehazing generalization capabilities\ncompared to other methods. Our research makes a significant contribution to\nadvancing image dehazing technology, providing new perspectives and tools for\nthe field and related domains, particularly emphasizing the importance of\nimproving universality and deployability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.15638v1",
    "published_date": "2024-04-24 04:20:22 UTC",
    "updated_date": "2024-04-24 04:20:22 UTC"
  },
  {
    "arxiv_id": "2404.15633v3",
    "title": "Artificial Intelligence for Multi-Unit Auction design",
    "authors": [
      "Peyman Khezr",
      "Kendall Taylor"
    ],
    "abstract": "Understanding bidding behavior in multi-unit auctions remains an ongoing\nchallenge for researchers. Despite their widespread use, theoretical insights\ninto the bidding behavior, revenue ranking, and efficiency of commonly used\nmulti-unit auctions are limited. This paper utilizes artificial intelligence,\nspecifically reinforcement learning, as a model free learning approach to\nsimulate bidding in three prominent multi-unit auctions employed in practice.\nWe introduce six algorithms that are suitable for learning and bidding in\nmulti-unit auctions and compare them using an illustrative example. This paper\nunderscores the significance of using artificial intelligence in auction\ndesign, particularly in enhancing the design of multi-unit auctions.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15633v3",
    "published_date": "2024-04-24 03:51:26 UTC",
    "updated_date": "2024-08-08 02:11:02 UTC"
  },
  {
    "arxiv_id": "2404.15617v2",
    "title": "DPO: Differential reinforcement learning with application to optimal configuration search",
    "authors": [
      "Chandrajit Bajaj",
      "Minh Nguyen"
    ],
    "abstract": "Reinforcement learning (RL) with continuous state and action spaces remains\none of the most challenging problems within the field. Most current learning\nmethods focus on integral identities such as value functions to derive an\noptimal strategy for the learning agent. In this paper, we instead study the\ndual form of the original RL formulation to propose the first differential RL\nframework that can handle settings with limited training samples and\nshort-length episodes. Our approach introduces Differential Policy Optimization\n(DPO), a pointwise and stage-wise iteration method that optimizes policies\nencoded by local-movement operators. We prove a pointwise convergence estimate\nfor DPO and provide a regret bound comparable with the best current theoretical\nderivation. Such pointwise estimate ensures that the learned policy matches the\noptimal path uniformly across different steps. We then apply DPO to a class of\npractical RL problems with continuous state and action spaces, and which search\nfor optimal configurations with Lagrangian rewards. DPO is easy to implement,\nscalable, and shows competitive results on benchmarking experiments against\nseveral popular RL methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15617v2",
    "published_date": "2024-04-24 03:11:12 UTC",
    "updated_date": "2024-08-13 03:47:38 UTC"
  },
  {
    "arxiv_id": "2404.15616v1",
    "title": "A Bi-directional Quantum Search Algorithm",
    "authors": [
      "Debanjan Konar",
      "Zain Hafeez",
      "Vaneet Aggarwal"
    ],
    "abstract": "Grover's search algorithms, including various partial Grover searches,\nexperience scaling problems as the number of iterations rises with increased\nqubits, making implementation more computationally expensive. This paper\ncombines Partial Grover's search algorithm and Bi-directional Search to create\na fast Grover's quantum search algorithm, referred to as Bi-Directional Grover\nSearch (BDGS). We incorporated a bi-directional search tactic with a partial\nGrover search, starting from an initial state and a single marked state in\nparallel. We have shown in this article that our novel approach requires\n$\\frac{\\pi}{4\\sqrt{2}}\\sqrt{N}(1-\\sqrt{\\frac{1}{b^{r/2k}}})$ iterations over\nregular Grover Search and Partial Grover Search (PGS), which takes\n$\\frac{\\pi}{4}\\sqrt{N}\\sqrt{1-\\frac{1}{b}}$ (here, $N=2^r$ elements, $b$ is the\nbranching factor of partial search, and $k= \\lceil\\log_2b \\rceil$). The\nproposed BDGS algorithm is benchmarked against the state-of-the-art Depth-First\nGrover's Search (DFGS) and generic Grover's Search (GS) implementations for $2$\nto $20$ qubits and provides promising results. The Qiskit Python implementation\nof the proposed BDGS algorithm is available on Github\n(https://github.com/hafeezzwiz21/DFGS-BDGS).",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.15616v1",
    "published_date": "2024-04-24 03:11:10 UTC",
    "updated_date": "2024-04-24 03:11:10 UTC"
  },
  {
    "arxiv_id": "2404.15604v1",
    "title": "Hybrid LLM/Rule-based Approaches to Business Insights Generation from Structured Data",
    "authors": [
      "Aliaksei Vertsel",
      "Mikhail Rumiantsau"
    ],
    "abstract": "In the field of business data analysis, the ability to extract actionable\ninsights from vast and varied datasets is essential for informed\ndecision-making and maintaining a competitive edge. Traditional rule-based\nsystems, while reliable, often fall short when faced with the complexity and\ndynamism of modern business data. Conversely, Artificial Intelligence (AI)\nmodels, particularly Large Language Models (LLMs), offer significant potential\nin pattern recognition and predictive analytics but can lack the precision\nnecessary for specific business applications. This paper explores the efficacy\nof hybrid approaches that integrate the robustness of rule-based systems with\nthe adaptive power of LLMs in generating actionable business insights.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15604v1",
    "published_date": "2024-04-24 02:42:24 UTC",
    "updated_date": "2024-04-24 02:42:24 UTC"
  },
  {
    "arxiv_id": "2404.15601v1",
    "title": "Deepfakes and Higher Education: A Research Agenda and Scoping Review of Synthetic Media",
    "authors": [
      "Jasper Roe",
      "Mike Perkins"
    ],
    "abstract": "The availability of software which can produce convincing yet synthetic media\nposes both threats and benefits to tertiary education globally. While other\nforms of synthetic media exist, this study focuses on deepfakes, which are\nadvanced Generative AI (GenAI) fakes of real people. This conceptual paper\nassesses the current literature on deepfakes across multiple disciplines by\nconducting an initial scoping review of 182 peer-reviewed publications.\n  The review reveals three major trends: detection methods, malicious\napplications, and potential benefits, although no specific studies on deepfakes\nin the tertiary educational context were found. Following a discussion of these\ntrends, this study applies the findings to postulate the major risks and\npotential mitigation strategies of deepfake technologies in higher education,\nas well as potential beneficial uses to aid the teaching and learning of both\ndeepfakes and synthetic media. This culminates in the proposal of a research\nagenda to build a comprehensive, cross-cultural approach to investigate\ndeepfakes in higher education.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15601v1",
    "published_date": "2024-04-24 02:40:58 UTC",
    "updated_date": "2024-04-24 02:40:58 UTC"
  },
  {
    "arxiv_id": "2404.15599v2",
    "title": "Human-in-the-loop Learning for Dynamic Congestion Games",
    "authors": [
      "Hongbo Li",
      "Lingjie Duan"
    ],
    "abstract": "Today mobile users learn and share their traffic observations via\ncrowdsourcing platforms (e.g., Waze). Yet such platforms simply cater to\nselfish users' myopic interests to recommend the shortest path, and do not\nencourage enough users to travel and learn other paths for future others. Prior\nstudies focus on one-shot congestion games without considering users'\ninformation learning, while our work studies how users learn and alter traffic\nconditions on stochastic paths in a human-in-the-loop manner. Our analysis\nshows that the myopic routing policy leads to severe under-exploration of\nstochastic paths. This results in a price of anarchy (PoA) greater than $2$, as\ncompared to the socially optimal policy in minimizing the long-term social\ncost. Besides, the myopic policy fails to ensure the correct learning\nconvergence about users' traffic hazard beliefs. To address this, we focus on\ninformational (non-monetary) mechanisms as they are easier to implement than\npricing. We first show that existing information-hiding mechanisms and\ndeterministic path-recommendation mechanisms in Bayesian persuasion literature\ndo not work with even (\\text{PoA}=\\infty). Accordingly, we propose a new\ncombined hiding and probabilistic recommendation (CHAR) mechanism to hide all\ninformation from a selected user group and provide state-dependent\nprobabilistic recommendations to the other user group. Our CHAR successfully\nensures PoA less than (\\frac{5}{4}), which cannot be further reduced by any\nother informational (non-monetary) mechanism. Besides the parallel network, we\nfurther extend our analysis and CHAR to more general linear path graphs with\nmultiple intermediate nodes, and we prove that the PoA results remain\nunchanged. Additionally, we carry out experiments with real-world datasets to\nfurther extend our routing graphs and verify the close-to-optimal performance\nof our CHAR.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "This paper has been published IEEE Transactions on Mobile Computing\n  (2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.15599v2",
    "published_date": "2024-04-24 02:23:12 UTC",
    "updated_date": "2024-11-16 01:45:44 UTC"
  },
  {
    "arxiv_id": "2404.15597v1",
    "title": "GRSN: Gated Recurrent Spiking Neurons for POMDPs and MARL",
    "authors": [
      "Lang Qin",
      "Ziming Wang",
      "Runhao Jiang",
      "Rui Yan",
      "Huajin Tang"
    ],
    "abstract": "Spiking neural networks (SNNs) are widely applied in various fields due to\ntheir energy-efficient and fast-inference capabilities. Applying SNNs to\nreinforcement learning (RL) can significantly reduce the computational resource\nrequirements for agents and improve the algorithm's performance under\nresource-constrained conditions. However, in current spiking reinforcement\nlearning (SRL) algorithms, the simulation results of multiple time steps can\nonly correspond to a single-step decision in RL. This is quite different from\nthe real temporal dynamics in the brain and also fails to fully exploit the\ncapacity of SNNs to process temporal data. In order to address this temporal\nmismatch issue and further take advantage of the inherent temporal dynamics of\nspiking neurons, we propose a novel temporal alignment paradigm (TAP) that\nleverages the single-step update of spiking neurons to accumulate historical\nstate information in RL and introduces gated units to enhance the memory\ncapacity of spiking neurons. Experimental results show that our method can\nsolve partially observable Markov decision processes (POMDPs) and multi-agent\ncooperation problems with similar performance as recurrent neural networks\n(RNNs) but with about 50% power consumption.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15597v1",
    "published_date": "2024-04-24 02:20:50 UTC",
    "updated_date": "2024-04-24 02:20:50 UTC"
  },
  {
    "arxiv_id": "2404.15592v2",
    "title": "ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction",
    "authors": [
      "Henry Peng Zou",
      "Vinay Samuel",
      "Yue Zhou",
      "Weizhi Zhang",
      "Liancheng Fang",
      "Zihe Song",
      "Philip S. Yu",
      "Cornelia Caragea"
    ],
    "abstract": "Existing datasets for attribute value extraction (AVE) predominantly focus on\nexplicit attribute values while neglecting the implicit ones, lack product\nimages, are often not publicly available, and lack an in-depth human inspection\nacross diverse domains. To address these limitations, we present ImplicitAVE,\nthe first, publicly available multimodal dataset for implicit attribute value\nextraction. ImplicitAVE, sourced from the MAVE dataset, is carefully curated\nand expanded to include implicit AVE and multimodality, resulting in a refined\ndataset of 68k training and 1.6k testing data across five domains. We also\nexplore the application of multimodal large language models (MLLMs) to implicit\nAVE, establishing a comprehensive benchmark for MLLMs on the ImplicitAVE\ndataset. Six recent MLLMs with eleven variants are evaluated across diverse\nsettings, revealing that implicit value extraction remains a challenging task\nfor MLLMs. The contributions of this work include the development and release\nof ImplicitAVE, and the exploration and benchmarking of various MLLMs for\nimplicit AVE, providing valuable insights and potential future research\ndirections. Dataset and code are available at\nhttps://github.com/HenryPengZou/ImplicitAVE",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACL 2024 (Findings) - Scores: Soundness - 4/4/4, Dataset\n  - 4/4/4, Overall Assessment - 4/3.5/3.5, Meta - 4",
    "pdf_url": "http://arxiv.org/pdf/2404.15592v2",
    "published_date": "2024-04-24 01:54:40 UTC",
    "updated_date": "2024-07-19 19:36:18 UTC"
  },
  {
    "arxiv_id": "2404.15583v3",
    "title": "Multi-Agent Reinforcement Learning for Energy Networks: Computational Challenges, Progress and Open Problems",
    "authors": [
      "Sarah Keren",
      "Chaimaa Essayeh",
      "Stefano V. Albrecht",
      "Thomas Morstyn"
    ],
    "abstract": "The rapidly changing architecture and functionality of electrical networks\nand the increasing penetration of renewable and distributed energy resources\nhave resulted in various technological and managerial challenges. These have\nrendered traditional centralized energy-market paradigms insufficient due to\ntheir inability to support the dynamic and evolving nature of the network. This\nsurvey explores how multi-agent reinforcement learning (MARL) can support the\ndecentralization and decarbonization of energy networks and mitigate the\nassociated challenges. This is achieved by specifying key computational\nchallenges in managing energy networks, reviewing recent research progress on\naddressing them, and highlighting open challenges that may be addressed using\nMARL.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15583v3",
    "published_date": "2024-04-24 01:35:27 UTC",
    "updated_date": "2024-05-25 05:10:30 UTC"
  },
  {
    "arxiv_id": "2406.02562v1",
    "title": "Gated Low-rank Adaptation for personalized Code-Switching Automatic Speech Recognition on the low-spec devices",
    "authors": [
      "Gwantae Kim",
      "Bokyeung Lee",
      "Donghyeon Kim",
      "Hanseok Ko"
    ],
    "abstract": "In recent times, there has been a growing interest in utilizing personalized\nlarge models on low-spec devices, such as mobile and CPU-only devices. However,\nutilizing a personalized large model in the on-device is inefficient, and\nsometimes limited due to computational cost. To tackle the problem, this paper\npresents the weights separation method to minimize on-device model weights\nusing parameter-efficient fine-tuning methods. Moreover, some people speak\nmultiple languages in an utterance, as known as code-switching, the\npersonalized ASR model is necessary to address such cases. However, current\nmultilingual speech recognition models are limited to recognizing a single\nlanguage within each utterance. To tackle this problem, we propose\ncode-switching speech recognition models that incorporate fine-tuned\nmonolingual and multilingual speech recognition models. Additionally, we\nintroduce a gated low-rank adaptation(GLoRA) for parameter-efficient\nfine-tuning with minimal performance degradation. Our experiments, conducted on\nKorean-English code-switching datasets, demonstrate that fine-tuning speech\nrecognition models for code-switching surpasses the performance of traditional\ncode-switching speech recognition models trained from scratch. Furthermore,\nGLoRA enhances parameter-efficient fine-tuning performance compared to\nconventional LoRA.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "Table 2 is revised",
    "pdf_url": "http://arxiv.org/pdf/2406.02562v1",
    "published_date": "2024-04-24 01:31:39 UTC",
    "updated_date": "2024-04-24 01:31:39 UTC"
  },
  {
    "arxiv_id": "2404.16887v1",
    "title": "Anomaly Detection for Incident Response at Scale",
    "authors": [
      "Hanzhang Wang",
      "Gowtham Kumar Tangirala",
      "Gilkara Pranav Naidu",
      "Charles Mayville",
      "Arighna Roy",
      "Joanne Sun",
      "Ramesh Babu Mandava"
    ],
    "abstract": "We present a machine learning-based anomaly detection product, AI Detect and\nRespond (AIDR), that monitors Walmart's business and system health in\nreal-time. During the validation over 3 months, the product served predictions\nfrom over 3000 models to more than 25 application, platform, and operation\nteams, covering 63\\% of major incidents and reducing the mean-time-to-detect\n(MTTD) by more than 7 minutes. Unlike previous anomaly detection methods, our\nsolution leverages statistical, ML and deep learning models while continuing to\nincorporate rule-based static thresholds to incorporate domain-specific\nknowledge. Both univariate and multivariate ML models are deployed and\nmaintained through distributed services for scalability and high availability.\nAIDR has a feedback loop that assesses model quality with a combination of\ndrift detection algorithms and customer feedback. It also offers\nself-onboarding capabilities and customizability. AIDR has achieved success\nwith various internal teams with lower time to detection and fewer false\npositives than previous methods. As we move forward, we aim to expand incident\ncoverage and prevention, reduce noise, and integrate further with root cause\nrecommendation (RCR) to enable an end-to-end AIDR experience.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ASPLOS 2024 AIOps workshop",
    "pdf_url": "http://arxiv.org/pdf/2404.16887v1",
    "published_date": "2024-04-24 00:46:19 UTC",
    "updated_date": "2024-04-24 00:46:19 UTC"
  },
  {
    "arxiv_id": "2404.16886v1",
    "title": "Review of Data-centric Time Series Analysis from Sample, Feature, and Period",
    "authors": [
      "Chenxi Sun",
      "Hongyan Li",
      "Yaliang Li",
      "Shenda Hong"
    ],
    "abstract": "Data is essential to performing time series analysis utilizing machine\nlearning approaches, whether for classic models or today's large language\nmodels. A good time-series dataset is advantageous for the model's accuracy,\nrobustness, and convergence, as well as task outcomes and costs. The emergence\nof data-centric AI represents a shift in the landscape from model refinement to\nprioritizing data quality. Even though time-series data processing methods\nfrequently come up in a wide range of research fields, it hasn't been well\ninvestigated as a specific topic. To fill the gap, in this paper, we\nsystematically review different data-centric methods in time series analysis,\ncovering a wide range of research topics. Based on the time-series data\ncharacteristics at sample, feature, and period, we propose a taxonomy for the\nreviewed data selection methods. In addition to discussing and summarizing\ntheir characteristics, benefits, and drawbacks targeting time-series data, we\nalso introduce the challenges and opportunities by proposing recommendations,\nopen problems, and possible research topics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2404.16886v1",
    "published_date": "2024-04-24 00:34:44 UTC",
    "updated_date": "2024-04-24 00:34:44 UTC"
  }
]