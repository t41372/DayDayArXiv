{
  "date": "2024-04-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-24 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、效率优化、多模态学习以及在科研和实际应用中的创新，强调了大型语言模型 (LLM) 的鲁棒性、知识提取和多代理强化学习等方面。其中，令人印象深刻的包括 LLM 在科研自动化的潜力（如 Autonomous LLM-driven research）和 AI 安全防御策略（如 Prompt Leakage effect），这些论文涉及知名学者和热门话题，展示了 AI 在复杂任务中的扩展应用。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些重要、话题度高或有创新贡献的文章，并将相关主题归类快速概述。其他次要论文（如一些算法优化或特定领域实验）将简略掠过，以控制篇幅。\n\n### AI 安全与 LLM 优化\n- **Prompt Leakage effect and defense strategies (提示泄露效应及其防御策略)**  \n  这篇论文探讨了 LLM 在多轮交互中的提示泄露风险，提出了一种威胁模型和防御策略。通过利用 LLM 的 sycophancy 效应，提升攻击成功率至 86.2%，并测试了 10 个模型的缓解效果。主要贡献是提供系统化的安全框架，帮助构建更安全的 LLM 应用，强调隐私保护在实际部署中的重要性。\n\n- **Attacks on Third-Party APIs of Large Language Models (针对大型语言模型第三方 API 的攻击)**  \n  作者包括 Nicholas Donald Lane 等，研究了 LLM 插件生态中的安全漏洞。论文提出一种攻击框架，展示了如何通过第三方 API 修改 LLM 输出。关键发现是，这些攻击在黑盒场景下有效，揭示了 LLM 生态的安全挑战，并为未来防御策略提供了方向。\n\n- **URL: Universal Referential Knowledge Linking via Task-instructed Representation Compression (通过任务指导表示压缩的通用引用知识链接)**  \n  这篇论文开发了 LLM 驱动的通用知识链接框架，支持多种引用任务。核心方法是多视图学习和表示压缩，提升了 LLM 在语义匹配中的性能。主要发现是，该框架在各种场景下大幅超越现有方法，适用于复杂知识图谱构建。\n\n### LLM 在科研和多模态应用\n- **Autonomous LLM-driven research from data to human-verifiable research papers (从数据到可验证论文的自主 LLM 驱动研究)**  \n  作者包括 Roy Kishony 等知名学者，提出一个平台让 LLM 代理自主完成研究过程，包括假设生成和论文撰写。论文的关键贡献是实现 80-90% 的自动化准确率，同时保持透明性和可验证性，展示了 LLM 在科研加速中的潜力。\n\n- **AutoGluon-Multimodal (AutoMM): Supercharging Multimodal AutoML with Foundation Models (使用基础模型增强多模态自动机器学习的 AutoGluon-Multimodal)**  \n  这篇论文介绍了开源库 AutoMM，支持图像、文本和表格数据的多模态任务。核心是三行代码即可微调基础模型，实现分类和检测等任务。主要发现是，在各种数据集上，它超越了现有 AutoML 工具，适用于高效的多模态应用。\n\n- **From Local to Global: A Graph RAG Approach to Query-Focused Summarization (从局部到全局：基于图 RAG 的查询焦点摘要方法)**  \n  论文提出 GraphRAG 框架，使用 LLM 构建实体图和社区摘要，实现对大型文本语料的全局查询摘要。关键贡献是处理海量数据时保持高效和准确，显著提升了摘要任务的全面性和多样性。\n\n### 计算机视觉和鲁棒性\n- **FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication (在语义数据集去重中检测和缓解视觉-语言公平性差异的 FairDeDup)**  \n  这篇论文（作者包括 Scott Cohen）解决了多模态数据集去重中的公平问题。核心方法是修改 SemDeDup 算法，减少偏见影响。主要发现是，它在 CLIP 模型上保持性能的同时，提高了公平指标，适用于 AI 公平性研究。\n\n- **Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography (利用 CLIP 的多视图乳腺癌诊断的 Mammo-CLIP)**  \n  论文使用 CLIP 框架处理多视图乳腺 X 光图像，提高乳腺癌检测准确率。关键贡献是细化模型以适应医疗数据，实验显示在基准数据集上 AUC 提升 2%，为 AI 在医疗诊断中的应用提供了新路径。\n\n### 其他快速概述\n其他论文涉及强化学习、量子计算和特定领域优化，如：\n- **GPU-RANC: A CUDA Accelerated Simulation Framework for Neuromorphic Architectures (CUDA 加速的神经形态架构模拟框架 GPU-RANC)**：提出高效模拟框架，提升 SNN 模拟速度达 780 倍，适用于硬件优化。\n- **Knowledge Graph Completion using Structural and Textual Embeddings (使用结构和文本嵌入的知识图谱补全)**：整合文本和结构信息改进知识图谱预测，表现与基准数据集竞争。\n- **Using Artificial Intelligence to Unlock Crowdfunding Success for Small Businesses (使用 AI 解锁小企业众筹成功)**：利用 LLM 优化众筹描述，提升成功率 11.9%，聚焦实际商业应用。\n\n总体而言，今天的论文突出了 AI 在安全和应用扩展中的进展，但也暴露了挑战如泛化性和效率。感兴趣的读者可关注 LLM 相关主题，以探索更多创新机会。明天见！",
  "papers": [
    {
      "arxiv_id": "2404.16251v3",
      "title": "Prompt Leakage effect and defense strategies for multi-turn LLM interactions",
      "title_zh": "提示泄露效应以及针对多轮 LLM 交互的防御策略",
      "authors": [
        "Divyansh Agarwal",
        "Alexander R. Fabbri",
        "Ben Risher",
        "Philippe Laban",
        "Shafiq Joty",
        "Chien-Sheng Wu"
      ],
      "abstract": "Prompt leakage poses a compelling security and privacy threat in LLM\napplications. Leakage of system prompts may compromise intellectual property,\nand act as adversarial reconnaissance for an attacker. A systematic evaluation\nof prompt leakage threats and mitigation strategies is lacking, especially for\nmulti-turn LLM interactions. In this paper, we systematically investigate LLM\nvulnerabilities against prompt leakage for 10 closed- and open-source LLMs,\nacross four domains. We design a unique threat model which leverages the LLM\nsycophancy effect and elevates the average attack success rate (ASR) from 17.7%\nto 86.2% in a multi-turn setting. Our standardized setup further allows\ndissecting leakage of specific prompt contents such as task instructions and\nknowledge documents. We measure the mitigation effect of 7 black-box defense\nstrategies, along with finetuning an open-source model to defend against\nleakage attempts. We present different combination of defenses against our\nthreat model, including a cost analysis. Our study highlights key takeaways for\nbuilding secure LLM applications and provides directions for research in\nmulti-turn LLM interactions",
      "tldr_zh": "本研究探讨了提示泄露（Prompt leakage）在多轮 LLM 交互中的安全和隐私威胁，可能导致知识产权泄露或攻击者侦察。作者设计了一个独特的威胁模型，利用 LLM 的 sycophancy effect，将平均攻击成功率（ASR）从 17.7% 提高到 86.2%，并系统评估了 10 个闭源和开源 LLM 在四个领域的漏洞，包括任务指令和知识文档的特定泄露。实验测试了 7 种黑盒防御策略以及对开源模型的微调，提供多种防御组合的成本分析。研究总结了构建安全 LLM 应用的要点，并为多轮 LLM 交互的研究指明方向。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16251v3",
      "published_date": "2024-04-24 23:39:58 UTC",
      "updated_date": "2024-07-29 17:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:08:32.426922"
    },
    {
      "arxiv_id": "2404.16248v1",
      "title": "URL: Universal Referential Knowledge Linking via Task-instructed Representation Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoqun Li",
        "Hongyu Lin",
        "Tianshu Wang",
        "Boxi Cao",
        "Yaojie Lu",
        "Weixiang Zhou",
        "Hao Wang",
        "Zhenyu Zeng",
        "Le Sun",
        "Xianpei Han"
      ],
      "abstract": "Linking a claim to grounded references is a critical ability to fulfill human\ndemands for authentic and reliable information. Current studies are limited to\nspecific tasks like information retrieval or semantic matching, where the\nclaim-reference relationships are unique and fixed, while the referential\nknowledge linking (RKL) in real-world can be much more diverse and complex. In\nthis paper, we propose universal referential knowledge linking (URL), which\naims to resolve diversified referential knowledge linking tasks by one unified\nmodel. To this end, we propose a LLM-driven task-instructed representation\ncompression, as well as a multi-view learning approach, in order to effectively\nadapt the instruction following and semantic understanding abilities of LLMs to\nreferential knowledge linking. Furthermore, we also construct a new benchmark\nto evaluate ability of models on referential knowledge linking tasks across\ndifferent scenarios. Experiments demonstrate that universal RKL is challenging\nfor existing approaches, while the proposed framework can effectively resolve\nthe task across various scenarios, and therefore outperforms previous\napproaches by a large margin.",
      "tldr_zh": "该论文提出了一种通用参照知识链接（URL）方法，旨在通过一个统一的模型处理多样化的参照知识链接（RKL）任务，以应对现实世界中复杂的关系需求。核心方法包括LLM-driven task-instructed representation compression和multi-view learning approach，这些技术利用大型语言模型（LLMs）的指令遵循和语义理解能力，实现任务适应和表示压缩。论文还构建了一个新基准，用于评估模型在不同场景下的RKL性能。实验结果表明，该框架在各种场景中大幅超越现有方法，证明了其有效性和普适性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16248v1",
      "published_date": "2024-04-24 23:37:15 UTC",
      "updated_date": "2024-04-24 23:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:08:43.957961"
    },
    {
      "arxiv_id": "2404.16893v1",
      "title": "Automatic AI controller that can drive with confidence: steering vehicle with uncertainty knowledge",
      "title_zh": "能够自信驾驶的",
      "authors": [
        "Neha Kumari",
        "Sumit Kumar. Sneha Priya",
        "Ayush Kumar",
        "Akash Fogla"
      ],
      "abstract": "In safety-critical systems that interface with the real world, the role of\nuncertainty in decision-making is pivotal, particularly in the context of\nmachine learning models. For the secure functioning of Cyber-Physical Systems\n(CPS), it is imperative to manage such uncertainty adeptly. In this research,\nwe focus on the development of a vehicle's lateral control system using a\nmachine learning framework. Specifically, we employ a Bayesian Neural Network\n(BNN), a probabilistic learning model, to address uncertainty quantification.\nThis capability allows us to gauge the level of confidence or uncertainty in\nthe model's predictions. The BNN based controller is trained using simulated\ndata gathered from the vehicle traversing a single track and subsequently\ntested on various other tracks. We want to share two significant results:\nfirstly, the trained model demonstrates the ability to adapt and effectively\ncontrol the vehicle on multiple similar tracks. Secondly, the quantification of\nprediction confidence integrated into the controller serves as an early-warning\nsystem, signaling when the algorithm lacks confidence in its predictions and is\ntherefore susceptible to failure. By establishing a confidence threshold, we\ncan trigger manual intervention, ensuring that control is relinquished from the\nalgorithm when it operates outside of safe parameters.",
      "tldr_zh": "该研究开发了一种自动AI控制器，用于车辆横向控制系统，通过Bayesian Neural Network (BNN)量化预测不确定性，以提升Cyber-Physical Systems (CPS)的安全决策。BNN模型基于模拟数据训练，并在多个类似轨道上进行测试，展示了良好的适应性和控制效果。主要发现包括：模型能有效管理车辆在不同轨道的行驶，同时通过置信度量化作为早期警告系统，当预测不确定性超过设定阈值时，触发手动干预，确保系统在安全参数外及时切换控制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2303.08187",
      "pdf_url": "http://arxiv.org/pdf/2404.16893v1",
      "published_date": "2024-04-24 23:22:37 UTC",
      "updated_date": "2024-04-24 23:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:08:54.803861"
    },
    {
      "arxiv_id": "2404.17605v1",
      "title": "Autonomous LLM-driven research from data to human-verifiable research papers",
      "title_zh": "翻译失败",
      "authors": [
        "Tal Ifargan",
        "Lukas Hafner",
        "Maor Kern",
        "Ori Alcalay",
        "Roy Kishony"
      ],
      "abstract": "As AI promises to accelerate scientific discovery, it remains unclear whether\nfully AI-driven research is possible and whether it can adhere to key\nscientific values, such as transparency, traceability and verifiability.\nMimicking human scientific practices, we built data-to-paper, an automation\nplatform that guides interacting LLM agents through a complete stepwise\nresearch process, while programmatically back-tracing information flow and\nallowing human oversight and interactions. In autopilot mode, provided with\nannotated data alone, data-to-paper raised hypotheses, designed research plans,\nwrote and debugged analysis codes, generated and interpreted results, and\ncreated complete and information-traceable research papers. Even though\nresearch novelty was relatively limited, the process demonstrated autonomous\ngeneration of de novo quantitative insights from data. For simple research\ngoals, a fully-autonomous cycle can create manuscripts which recapitulate\npeer-reviewed publications without major errors in about 80-90%, yet as goal\ncomplexity increases, human co-piloting becomes critical for assuring accuracy.\nBeyond the process itself, created manuscripts too are inherently verifiable,\nas information-tracing allows to programmatically chain results, methods and\ndata. Our work thereby demonstrates a potential for AI-driven acceleration of\nscientific discovery while enhancing, rather than jeopardizing, traceability,\ntransparency and verifiability.",
      "tldr_zh": "本研究开发了 data-to-paper 平台，使用互动的 LLM 代理模拟人类科学实践，从标注数据出发，自主完成假设生成、研究计划设计、代码编写、结果分析和完整论文创作，同时通过程序化信息追踪确保透明性和可验证性。实验显示，在自动模式下，该平台能从数据中产生新的定量洞见，并生成80-90%准确的论文，成功复现简单目标的同行评议出版物，但复杂目标需人类协作以保证准确性。该平台不仅展示了 AI 驱动科学发现的潜力，还通过信息追溯机制增强了研究的追溯性、透明性和可验证性。",
      "categories": [
        "q-bio.OT",
        "cs.AI"
      ],
      "primary_category": "q-bio.OT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.17605v1",
      "published_date": "2024-04-24 23:15:49 UTC",
      "updated_date": "2024-04-24 23:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:09:07.995028"
    },
    {
      "arxiv_id": "2404.16233v2",
      "title": "AutoGluon-Multimodal (AutoMM): Supercharging Multimodal AutoML with Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiang Tang",
        "Haoyang Fang",
        "Su Zhou",
        "Taojiannan Yang",
        "Zihan Zhong",
        "Tony Hu",
        "Katrin Kirchhoff",
        "George Karypis"
      ],
      "abstract": "AutoGluon-Multimodal (AutoMM) is introduced as an open-source AutoML library\ndesigned specifically for multimodal learning. Distinguished by its exceptional\nease of use, AutoMM enables fine-tuning of foundation models with just three\nlines of code. Supporting various modalities including image, text, and tabular\ndata, both independently and in combination, the library offers a comprehensive\nsuite of functionalities spanning classification, regression, object detection,\nsemantic matching, and image segmentation. Experiments across diverse datasets\nand tasks showcases AutoMM's superior performance in basic classification and\nregression tasks compared to existing AutoML tools, while also demonstrating\ncompetitive results in advanced tasks, aligning with specialized toolboxes\ndesigned for such purposes.",
      "tldr_zh": "该论文介绍了 AutoGluon-Multimodal (AutoMM)，一个开源的 AutoML 库，旨在通过 foundation models 提升多模态学习效率。AutoMM 极易上手，仅需三行代码即可微调模型，支持图像、文本和表格数据，并处理多种任务，如分类、回归、对象检测、语义匹配和图像分割。实验结果显示，AutoMM 在基本分类和回归任务上优于现有 AutoML 工具，在高级任务上也表现出与专业工具相当的竞争力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AutoML 2024 Conference",
      "pdf_url": "http://arxiv.org/pdf/2404.16233v2",
      "published_date": "2024-04-24 22:28:12 UTC",
      "updated_date": "2024-04-30 21:09:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:09:20.059916"
    },
    {
      "arxiv_id": "2404.16218v1",
      "title": "Efficient NAS with FaDE on Hierarchical Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Neumeyer",
        "Julian Stier",
        "Michael Granitzer"
      ],
      "abstract": "Neural architecture search (NAS) is a challenging problem. Hierarchical\nsearch spaces allow for cheap evaluations of neural network sub modules to\nserve as surrogate for architecture evaluations. Yet, sometimes the hierarchy\nis too restrictive or the surrogate fails to generalize. We present FaDE which\nuses differentiable architecture search to obtain relative performance\npredictions on finite regions of a hierarchical NAS space. The relative nature\nof these ranks calls for a memory-less, batch-wise outer search algorithm for\nwhich we use an evolutionary algorithm with pseudo-gradient descent. FaDE is\nespecially suited on deep hierarchical, respectively multi-cell search spaces,\nwhich it can explore by linear instead of exponential cost and therefore\neliminates the need for a proxy search space.\n  Our experiments show that firstly, FaDE-ranks on finite regions of the search\nspace correlate with corresponding architecture performances and secondly, the\nranks can empower a pseudo-gradient evolutionary search on the complete neural\narchitecture search space.",
      "tldr_zh": "该研究针对神经架构搜索 (NAS) 的挑战，提出了一种名为 FaDE 的方法，利用可微架构搜索在层次化搜索空间的有限区域获取相对性能预测，从而提升搜索效率。FaDE 结合进化算法和伪梯度下降作为无记忆的批量外层搜索算法，适用于深度层次化或多单元搜索空间，能以线性成本探索空间而非指数级开销。实验结果显示，FaDE 的性能排名与实际架构性能高度相关，并成功增强了在完整 NAS 空间上的伪梯度进化搜索。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16218v1",
      "published_date": "2024-04-24 21:33:17 UTC",
      "updated_date": "2024-04-24 21:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:09:30.629930"
    },
    {
      "arxiv_id": "2404.16208v1",
      "title": "GPU-RANC: A CUDA Accelerated Simulation Framework for Neuromorphic Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Hassan",
        "Michael Inouye",
        "Miguel C. Gonzalez",
        "Ilkin Aliyev",
        "Joshua Mack",
        "Maisha Hafiz",
        "Ali Akoglu"
      ],
      "abstract": "Open-source simulation tools play a crucial role for neuromorphic application\nengineers and hardware architects to investigate performance bottlenecks and\nexplore design optimizations before committing to silicon. Reconfigurable\nArchitecture for Neuromorphic Computing (RANC) is one such tool that offers\nability to execute pre-trained Spiking Neural Network (SNN) models within a\nunified ecosystem through both software-based simulation and FPGA-based\nemulation. RANC has been utilized by the community with its flexible and highly\nparameterized design to study implementation bottlenecks, tune architectural\nparameters or modify neuron behavior based on application insights and study\nthe trade space on hardware performance and network accuracy. In designing\narchitectures for use in neuromorphic computing, there are an incredibly large\nnumber of configuration parameters such as number and precision of weights per\nneuron, neuron and axon counts per core, network topology, and neuron behavior.\nTo accelerate such studies and provide users with a streamlined productive\ndesign space exploration, in this paper we introduce the GPU-based\nimplementation of RANC. We summarize our parallelization approach and quantify\nthe speedup gains achieved with GPU-based tick-accurate simulations across\nvarious use cases. We demonstrate up to 780 times speedup compared to serial\nversion of the RANC simulator based on a 512 neuromorphic core MNIST inference\napplication. We believe that the RANC ecosystem now provides a much more\nfeasible avenue in the research of exploring different optimizations for\naccelerating SNNs and performing richer studies by enabling rapid convergence\nto optimized neuromorphic architectures.",
      "tldr_zh": "该论文介绍了 GPU-RANC，一种基于 CUDA 加速的模拟框架，用于神经形态架构（Neuromorphic Architectures）的性能瓶颈分析和设计优化。框架扩展了原有 Reconfigurable Architecture for Neuromorphic Computing (RANC) 系统，通过并行化方法实现对 Spiking Neural Network (SNN) 模型的 tick-accurate 模拟，支持软件和 FPGA 仿真。实验结果显示，在 512 个神经形态核心的 MNIST 推理应用中，GPU 版本比串行版本速度提升高达 780 倍，从而为加速 SNN 优化和快速探索硬件参数提供了高效工具。",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "Accepted for publication in Neuro-Inspired Computational Elements\n  (NICE) Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.16208v1",
      "published_date": "2024-04-24 21:08:21 UTC",
      "updated_date": "2024-04-24 21:08:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:09:45.000738"
    },
    {
      "arxiv_id": "2404.16206v1",
      "title": "Knowledge Graph Completion using Structural and Textual Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Sakher Khalil Alqaaidi",
        "Krzysztof Kochut"
      ],
      "abstract": "Knowledge Graphs (KGs) are widely employed in artificial intelligence\napplications, such as question-answering and recommendation systems. However,\nKGs are frequently found to be incomplete. While much of the existing\nliterature focuses on predicting missing nodes for given incomplete KG triples,\nthere remains an opportunity to complete KGs by exploring relations between\nexisting nodes, a task known as relation prediction. In this study, we propose\na relations prediction model that harnesses both textual and structural\ninformation within KGs. Our approach integrates walks-based embeddings with\nlanguage model embeddings to effectively represent nodes. We demonstrate that\nour model achieves competitive results in the relation prediction task when\nevaluated on a widely used dataset.",
      "tldr_zh": "知识图谱（Knowledge Graphs）常不完整，现有多研究聚焦于预测缺失节点，但本文提出一种关系预测模型，专注于探索现有节点间的关系。模型通过整合基于walks的结构嵌入（walks-based embeddings）和语言模型嵌入（language model embeddings）来有效表示节点，从而提升关系预测的准确性。在广泛使用的标准数据集上，该模型取得了竞争性的结果，展示了其在知识图谱完成任务中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16206v1",
      "published_date": "2024-04-24 21:04:14 UTC",
      "updated_date": "2024-04-24 21:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:09:54.834821"
    },
    {
      "arxiv_id": "2407.09480v1",
      "title": "Using Artificial Intelligence to Unlock Crowdfunding Success for Small Businesses",
      "title_zh": "翻译失败",
      "authors": [
        "Teng Ye",
        "Jingnan Zheng",
        "Junhui Jin",
        "Jingyi Qiu",
        "Wei Ai",
        "Qiaozhu Mei"
      ],
      "abstract": "While small businesses are increasingly turning to online crowdfunding\nplatforms for essential funding, over 40% of these campaigns may fail to raise\nany money, especially those from low socio-economic areas. We utilize the\nlatest advancements in AI technology to identify crucial factors that influence\nthe success of crowdfunding campaigns and to improve their fundraising outcomes\nby strategically optimizing these factors. Our best-performing machine learning\nmodel accurately predicts the fundraising outcomes of 81.0% of campaigns,\nprimarily based on their textual descriptions. Interpreting the machine\nlearning model allows us to provide actionable suggestions on improving the\ntextual description before launching a campaign. We demonstrate that by\naugmenting just three aspects of the narrative using a large language model, a\ncampaign becomes more preferable to 83% human evaluators, and its likelihood of\nsecuring financial support increases by 11.9%. Our research uncovers the\neffective strategies for crafting descriptions for small business fundraising\ncampaigns and opens up a new realm in integrating large language models into\ncrowdfunding methodologies.",
      "tldr_zh": "本研究针对小型企业众筹活动的高失败率（尤其是低社经地区，超过40%失败），利用AI技术识别关键影响因素并优化活动文本描述。研究的最佳机器学习模型基于文本分析，准确预测81.0%的筹资结果，并提供行动建议来改进描述。使用large language model增强叙述的三个方面后，活动对83%人类评估者更具吸引力，并将成功率提高11.9%。这项工作揭示了有效的众筹策略，并开辟了将large language model整合到众筹方法中的新领域。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CL",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09480v1",
      "published_date": "2024-04-24 20:53:10 UTC",
      "updated_date": "2024-04-24 20:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:10:08.284689"
    },
    {
      "arxiv_id": "2404.16196v3",
      "title": "ApisTox: a new benchmark dataset for the classification of small molecules toxicity on honey bees",
      "title_zh": "ApisTox：一个新的基准数据集，用于小分子对蜜蜂毒性的分类",
      "authors": [
        "Jakub Adamczyk",
        "Jakub Poziemski",
        "Pawel Siedlecki"
      ],
      "abstract": "The global decline in bee populations poses significant risks to agriculture,\nbiodiversity, and environmental stability. To bridge the gap in existing data,\nwe introduce ApisTox, a comprehensive dataset focusing on the toxicity of\npesticides to honey bees (Apis mellifera). This dataset combines and leverages\ndata from existing sources such as ECOTOX and PPDB, providing an extensive,\nconsistent, and curated collection that surpasses the previous datasets.\nApisTox incorporates a wide array of data, including toxicity levels for\nchemicals, details such as time of their publication in literature, and\nidentifiers linking them to external chemical databases. This dataset may serve\nas an important tool for environmental and agricultural research, but also can\nsupport the development of policies and practices aimed at minimizing harm to\nbee populations. Finally, ApisTox offers a unique resource for benchmarking\nmolecular property prediction methods on agrochemical compounds, facilitating\nadvancements in both environmental science and cheminformatics. This makes it a\nvaluable tool for both academic research and practical applications in bee\nconservation.",
      "tldr_zh": "本研究引入了ApisTox，这是一个新的基准数据集，用于分类小分子对蜜蜂（Apis mellifera）的毒性，旨在解决全球蜜蜂种群下降对农业和环境的影响。ApisTox整合了ECOTOX和PPDB等现有数据来源，提供了一个更全面、一致的集合，包括化学毒性水平、文献出版时间以及外部化学数据库的标识符。该数据集可支持环境和农业研究、政策制定以减少对蜜蜂的伤害，并作为基准测试molecular property prediction方法的工具，推动环境科学和化学信息学领域的进步。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.BM",
        "92-04",
        "J.3"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16196v3",
      "published_date": "2024-04-24 20:35:17 UTC",
      "updated_date": "2024-11-29 13:04:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:10:20.019673"
    },
    {
      "arxiv_id": "2404.16193v2",
      "title": "Improving Multi-label Recognition using Class Co-Occurrence Probabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Samyak Rawlekar",
        "Shubhang Bhatnagar",
        "Vishnuvardhan Pogunulu Srinivasulu",
        "Narendra Ahuja"
      ],
      "abstract": "Multi-label Recognition (MLR) involves the identification of multiple objects\nwithin an image. To address the additional complexity of this problem, recent\nworks have leveraged information from vision-language models (VLMs) trained on\nlarge text-images datasets for the task. These methods learn an independent\nclassifier for each object (class), overlooking correlations in their\noccurrences. Such co-occurrences can be captured from the training data as\nconditional probabilities between a pair of classes. We propose a framework to\nextend the independent classifiers by incorporating the co-occurrence\ninformation for object pairs to improve the performance of independent\nclassifiers. We use a Graph Convolutional Network (GCN) to enforce the\nconditional probabilities between classes, by refining the initial estimates\nderived from image and text sources obtained using VLMs. We validate our method\non four MLR datasets, where our approach outperforms all state-of-the-art\nmethods.",
      "tldr_zh": "本文提出了一种改进多标签识别（Multi-label Recognition, MLR）的方法，通过利用类别共现概率来提升独立分类器的性能。作者的框架整合了从视觉语言模型（VLMs）获取的图像和文本信息，并使用 Graph Convolutional Network (GCN) 来强制执行类之间的条件概率，从而炼化初始估计。实验在四个 MLR 数据集上验证，该方法超越了所有最先进的技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICPR 2024, CVPR workshops 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.16193v2",
      "published_date": "2024-04-24 20:33:25 UTC",
      "updated_date": "2024-09-19 21:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:10:32.836276"
    },
    {
      "arxiv_id": "2404.16188v1",
      "title": "Pearls from Pebbles: Improved Confidence Functions for Auto-labeling",
      "title_zh": "翻译失败",
      "authors": [
        "Harit Vishwakarma",
        "Reid",
        "Chen",
        "Sui Jiet Tay",
        "Satya Sai Srinath Namburi",
        "Frederic Sala",
        "Ramya Korlakai Vinayak"
      ],
      "abstract": "Auto-labeling is an important family of techniques that produce labeled\ntraining sets with minimum manual labeling. A prominent variant,\nthreshold-based auto-labeling (TBAL), works by finding a threshold on a model's\nconfidence scores above which it can accurately label unlabeled data points.\nHowever, many models are known to produce overconfident scores, leading to poor\nTBAL performance. While a natural idea is to apply off-the-shelf calibration\nmethods to alleviate the overconfidence issue, such methods still fall short.\nRather than experimenting with ad-hoc choices of confidence functions, we\npropose a framework for studying the \\emph{optimal} TBAL confidence function.\nWe develop a tractable version of the framework to obtain \\texttt{Colander}\n(Confidence functions for Efficient and Reliable Auto-labeling), a new post-hoc\nmethod specifically designed to maximize performance in TBAL systems. We\nperform an extensive empirical evaluation of our method \\texttt{Colander} and\ncompare it against methods designed for calibration. \\texttt{Colander} achieves\nup to 60\\% improvements on coverage over the baselines while maintaining\nauto-labeling error below $5\\%$ and using the same amount of labeled data as\nthe baselines.",
      "tldr_zh": "这篇论文针对自动标注(Auto-labeling)技术中的过度自信问题，提出一个框架来研究最优阈值基于自动标注(TBAL)置信度函数，以改善模型的标注准确性。作者开发了Colander，一种专门设计的后处理方法，能够最大化TBAL系统的性能，同时使用与基线相同的标注数据量。实验结果显示，Colander将覆盖率提高了高达60%，并将自动标注错误率控制在5%以下。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16188v1",
      "published_date": "2024-04-24 20:22:48 UTC",
      "updated_date": "2024-04-24 20:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:10:44.773918"
    },
    {
      "arxiv_id": "2404.16183v1",
      "title": "ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment",
      "title_zh": "ABCD：信任增强的基于注意力的卷积自编码器用于风险评估",
      "authors": [
        "Sarala Naidu",
        "Ning Xiong"
      ],
      "abstract": "Anomaly detection in industrial systems is crucial for preventing equipment\nfailures, ensuring risk identification, and maintaining overall system\nefficiency. Traditional monitoring methods often rely on fixed thresholds and\nempirical rules, which may not be sensitive enough to detect subtle changes in\nsystem health and predict impending failures. To address this limitation, this\npaper proposes, a novel Attention-based convolutional autoencoder (ABCD) for\nrisk detection and map the risk value derive to the maintenance planning. ABCD\nlearns the normal behavior of conductivity from historical data of a real-world\nindustrial cooling system and reconstructs the input data, identifying\nanomalies that deviate from the expected patterns. The framework also employs\ncalibration techniques to ensure the reliability of its predictions. Evaluation\nresults demonstrate that with the attention mechanism in ABCD a 57.4% increase\nin performance and a reduction of false alarms by 9.37% is seen compared to\nwithout attention. The approach can effectively detect risks, the risk priority\nrank mapped to maintenance, providing valuable insights for cooling system\ndesigners and service personnel. Calibration error of 0.03% indicates that the\nmodel is well-calibrated and enhances model's trustworthiness, enabling\ninformed decisions about maintenance strategies",
      "tldr_zh": "这篇论文提出了一种名为 ABCD 的注意力机制增强卷积自编码器（Attention-based convolutional autoencoder），旨在提升工业系统的风险评估能力，解决传统阈值方法对微妙异常检测的不足。ABCD 通过从真实工业冷却系统的历史数据中学习正常行为，进行数据重构并识别异常，同时整合校准技术以确保预测的可靠性和可信度。实验结果显示，加入注意力机制后，模型性能提升57.4%，假警报减少9.37%，校准误差仅为0.03%。该框架还能将风险优先级映射到维护规划，为冷却系统设计师和服务人员提供决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16183v1",
      "published_date": "2024-04-24 20:15:57 UTC",
      "updated_date": "2024-04-24 20:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:10:58.272505"
    },
    {
      "arxiv_id": "2404.16177v1",
      "title": "Advancing Recommender Systems by mitigating Shilling attacks",
      "title_zh": "通过缓解 Shilling attacks 推进推荐系统",
      "authors": [
        "Aditya Chichani",
        "Juzer Golwala",
        "Tejas Gundecha",
        "Kiran Gawande"
      ],
      "abstract": "Considering the premise that the number of products offered grow in an\nexponential fashion and the amount of data that a user can assimilate before\nmaking a decision is relatively small, recommender systems help in categorizing\ncontent according to user preferences. Collaborative filtering is a widely used\nmethod for computing recommendations due to its good performance. But, this\nmethod makes the system vulnerable to attacks which try to bias the\nrecommendations. These attacks, known as 'shilling attacks' are performed to\npush an item or nuke an item in the system. This paper proposes an algorithm to\ndetect such shilling profiles in the system accurately and also study the\neffects of such profiles on the recommendations.",
      "tldr_zh": "推荐系统通过协作过滤(collaborative filtering)帮助用户从海量产品中筛选偏好内容，但这种方法容易受到shilling attacks的攻击，这些攻击旨在操纵推荐以推动或破坏特定物品。论文提出了一种算法，用于准确检测这些shilling profiles。研究还分析了这些攻击对推荐结果的影响，从而提升系统的鲁棒性和可靠性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Published in IEEE, Proceedings of 2018 9th International Conference\n  on Computing, Communication and Networking Technologies (ICCCNT)",
      "pdf_url": "http://arxiv.org/pdf/2404.16177v1",
      "published_date": "2024-04-24 20:05:39 UTC",
      "updated_date": "2024-04-24 20:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:11:08.762284"
    },
    {
      "arxiv_id": "2404.16168v3",
      "title": "The Over-Certainty Phenomenon in Modern UDA Algorithms",
      "title_zh": "现代 UDA 算法中的过度确定性现象",
      "authors": [
        "Fin Amin",
        "Jung-Eun Kim"
      ],
      "abstract": "When neural networks are confronted with unfamiliar data that deviate from\ntheir training set, this signifies a domain shift. While these networks output\npredictions on their inputs, they typically fail to account for their level of\nfamiliarity with these novel observations. While prevailing works navigate\nunsupervised domain adaptation with the goal of curtailing model entropy, they\nunintentionally birth models that grapple with sub-optimal calibration - a\ndilemma we term the over-certainty phenomenon. In this paper, we uncover a\nconcerning trend in unsupervised domain adaptation and propose a solution that\nnot only maintains accuracy but also addresses calibration.",
      "tldr_zh": "该研究揭示了现代无监督域适应（unsupervised domain adaptation, UDA）算法中存在的过度确定性现象（over-certainty phenomenon），即神经网络在面对域移位（domain shift）时，虽然输出预测但无法正确评估对新数据的熟悉程度，导致模型校准不佳。现有UDA方法在降低模型熵（model entropy）的同时， unintentionally 产生了这种 suboptimal 校准问题。论文提出了一种解决方案，不仅维持了模型的准确性，还有效改善了校准性能，为UDA算法的可靠性提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16168v3",
      "published_date": "2024-04-24 19:55:50 UTC",
      "updated_date": "2024-08-25 23:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:11:20.167632"
    },
    {
      "arxiv_id": "2404.16164v1",
      "title": "Towards a Holistic Evaluation of LLMs on Factual Knowledge Recall",
      "title_zh": "迈向大型语言模型事实知识召回的整体评估",
      "authors": [
        "Jiaqing Yuan",
        "Lin Pan",
        "Chung-Wei Hang",
        "Jiang Guo",
        "Jiarong Jiang",
        "Bonan Min",
        "Patrick Ng",
        "Zhiguo Wang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance on a variety\nof NLP tasks, and are being rapidly adopted in a wide range of use cases. It is\ntherefore of vital importance to holistically evaluate the factuality of their\ngenerated outputs, as hallucinations remain a challenging issue.\n  In this work, we focus on assessing LLMs' ability to recall factual knowledge\nlearned from pretraining, and the factors that affect this ability. To that\nend, we construct FACT-BENCH, a representative benchmark covering 20 domains,\n134 property types, 3 answer types, and different knowledge popularity levels.\nWe benchmark 31 models from 10 model families and provide a holistic assessment\nof their strengths and weaknesses. We observe that instruction-tuning hurts\nknowledge recall, as pretraining-only models consistently outperform their\ninstruction-tuned counterparts, and positive effects of model scaling, as\nlarger models outperform smaller ones for all model families. However, the best\nperformance from GPT-4 still represents a large gap with the upper-bound. We\nadditionally study the role of in-context exemplars using counterfactual\ndemonstrations, which lead to significant degradation of factual knowledge\nrecall for large models. By further decoupling model known and unknown\nknowledge, we find the degradation is attributed to exemplars that contradict a\nmodel's known knowledge, as well as the number of such exemplars. Lastly, we\nfine-tune LLaMA-7B in different settings of known and unknown knowledge. In\nparticular, fine-tuning on a model's known knowledge is beneficial, and\nconsistently outperforms fine-tuning on unknown and mixed knowledge. We will\nmake our benchmark publicly available.",
      "tldr_zh": "本研究评估大型语言模型 (LLMs) 在事实知识回忆方面的整体性能，构建了 FACT-BENCH 基准，该基准覆盖 20 个领域、134 个属性类型、3 个答案类型以及不同知识流行度水平。测试了 31 个模型来自 10 个模型家族，结果显示预训练模型优于指令微调模型，而模型规模越大（如 GPT-4），表现越好，但仍与理想上界存在较大差距。进一步分析发现，使用反事实上下文示例会显著降低大模型的知识回忆能力，尤其是当示例与模型已知知识矛盾时；此外，针对 LLaMA-7B 的微调实验表明，在已知知识上微调最有效。该基准将公开可用，以促进未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16164v1",
      "published_date": "2024-04-24 19:40:01 UTC",
      "updated_date": "2024-04-24 19:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:11:33.777141"
    },
    {
      "arxiv_id": "2404.16162v1",
      "title": "Scaling Lifelong Multi-Agent Path Finding to More Realistic Settings: Research Challenges and Opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "He Jiang",
        "Yulun Zhang",
        "Rishi Veerapaneni",
        "Jiaoyang Li"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) is the problem of moving multiple agents from\nstarts to goals without collisions. Lifelong MAPF (LMAPF) extends MAPF by\ncontinuously assigning new goals to agents. We present our winning approach to\nthe 2023 League of Robot Runners LMAPF competition, which leads us to several\ninteresting research challenges and future directions. In this paper, we\noutline three main research challenges. The first challenge is to search for\nhigh-quality LMAPF solutions within a limited planning time (e.g., 1s per step)\nfor a large number of agents (e.g., 10,000) or extremely high agent density\n(e.g., 97.7%). We present future directions such as developing more competitive\nrule-based and anytime MAPF algorithms and parallelizing state-of-the-art MAPF\nalgorithms. The second challenge is to alleviate congestion and the effect of\nmyopic behaviors in LMAPF algorithms. We present future directions, such as\ndeveloping moving guidance and traffic rules to reduce congestion,\nincorporating future prediction and real-time search, and determining the\noptimal agent number. The third challenge is to bridge the gaps between the\nLMAPF models used in the literature and real-world applications. We present\nfuture directions, such as dealing with more realistic kinodynamic models,\nexecution uncertainty, and evolving systems.",
      "tldr_zh": "本论文探讨了 Multi-Agent Path Finding (MAPF) 的扩展形式 Lifelong MAPF (LMAPF)，旨在通过作者在2023年 League of Robot Runners 比赛中的获胜方法，识别扩展到更现实场景的挑战和机会。论文提出了三个主要研究挑战：一是为大量代理（如10,000个）或高密度环境（如97.7%）在有限规划时间内（如1秒每步）寻找高质量解决方案；二是缓解 LMAPF 算法中的拥堵和短视行为；三是弥合文献模型与实际应用的差距，如处理更真实的动力学模型和执行不确定性。未来方向包括开发竞争性算法、引入移动指导和实时预测机制，以及优化代理数量和系统演化，以推动 LMAPF 在现实世界的应用。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted to Symposium on Combinatorial Search (SoCS), 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.16162v1",
      "published_date": "2024-04-24 19:37:18 UTC",
      "updated_date": "2024-04-24 19:37:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:11:48.542946"
    },
    {
      "arxiv_id": "2404.16160v2",
      "title": "Domain-Specific Improvement on Psychotherapy Chatbot Using Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Kang",
        "Daniel Novak",
        "Katerina Urbanova",
        "Yuqing Cheng",
        "Yong Hu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive generalization\ncapabilities on specific tasks with human-written instruction data. However,\nthe limited quantity, diversity, and professional expertise of such instruction\ndata raise concerns about the performance of LLMs in psychotherapy tasks when\nprovided with domain-specific instructions. To address this, we firstly propose\nDomain-Specific Assistant Instructions based on AlexanderStreet therapy, and\nsecondly, we use an adaption fine-tuning method and retrieval augmented\ngeneration method to improve pre-trained LLMs. Through quantitative evaluation\nof linguistic quality using automatic and human evaluation, we observe that\npre-trained LLMs on Psychotherapy Assistant Instructions outperform\nstate-of-the-art LLMs response baselines. Our Assistant-Instruction approach\noffers a half-annotation method to align pre-trained LLMs with instructions and\nprovide pre-trained LLMs with more psychotherapy knowledge.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在心理治疗任务中的性能问题，提出了基于AlexanderStreet治疗的Domain-Specific Assistant Instructions，以解决指令数据有限性和专业性不足的挑战。研究采用adaption fine-tuning和retrieval augmented generation方法，对预训练LLMs进行改进，从而提升其在心理治疗聊天机器人中的响应质量。实验结果显示，通过自动和人工评估，改进后的LLMs在语言质量上优于现有基线，并提供了一种半注释(half-annotation)方法，帮助LLMs更好地与领域指令对齐并扩展专业知识。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICASSP 2024 EIHRC Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.16160v2",
      "published_date": "2024-04-24 19:30:18 UTC",
      "updated_date": "2024-09-02 16:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:11:57.529846"
    },
    {
      "arxiv_id": "2404.16159v2",
      "title": "AFU: Actor-Free critic Updates in off-policy RL for continuous control",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Perrin-Gilbert"
      ],
      "abstract": "This paper presents AFU, an off-policy deep RL algorithm addressing in a new\nway the challenging \"max-Q problem\" in Q-learning for continuous action spaces,\nwith a solution based on regression and conditional gradient scaling. AFU has\nan actor but its critic updates are entirely independent from it. As a\nconsequence, the actor can be chosen freely. In the initial version, AFU-alpha,\nwe employ the same stochastic actor as in Soft Actor-Critic (SAC), but we then\nstudy a simple failure mode of SAC and show how AFU can be modified to make\nactor updates less likely to become trapped in local optima, resulting in a\nsecond version of the algorithm, AFU-beta. Experimental results demonstrate the\nsample efficiency of both versions of AFU, marking it as the first model-free\noff-policy algorithm competitive with state-of-the-art actor-critic methods\nwhile departing from the actor-critic perspective.",
      "tldr_zh": "这篇论文提出了 AFU，一种 off-policy 深度强化学习算法，用于解决连续动作空间中 Q-learning 的 \"max-Q problem\"，其方法基于回归和条件梯度缩放。AFU 的 critic 更新独立于 actor，允许自由选择 actor；在初始版本 AFU-alpha 中，使用与 Soft Actor-Critic (SAC) 相同的随机 actor，并通过修改避免了 SAC 的局部最优陷阱，发展出改进版本 AFU-beta。实验结果显示，AFU 算法在样本效率上表现出色，是首个能与最先进 actor-critic 方法竞争的模型无关 off-policy 算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.16159v2",
      "published_date": "2024-04-24 19:30:03 UTC",
      "updated_date": "2024-10-25 11:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:12:09.215773"
    },
    {
      "arxiv_id": "2404.16891v1",
      "title": "Attacks on Third-Party APIs of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wanru Zhao",
        "Vidit Khazanchi",
        "Haodi Xing",
        "Xuanli He",
        "Qiongkai Xu",
        "Nicholas Donald Lane"
      ],
      "abstract": "Large language model (LLM) services have recently begun offering a plugin\necosystem to interact with third-party API services. This innovation enhances\nthe capabilities of LLMs, but it also introduces risks, as these plugins\ndeveloped by various third parties cannot be easily trusted. This paper\nproposes a new attacking framework to examine security and safety\nvulnerabilities within LLM platforms that incorporate third-party services.\nApplying our framework specifically to widely used LLMs, we identify real-world\nmalicious attacks across various domains on third-party APIs that can\nimperceptibly modify LLM outputs. The paper discusses the unique challenges\nposed by third-party API integration and offers strategic possibilities to\nimprove the security and safety of LLM ecosystems moving forward. Our code is\nreleased at https://github.com/vk0812/Third-Party-Attacks-on-LLMs.",
      "tldr_zh": "本论文探讨了大型语言模型 (LLM) 的插件生态系统如何通过整合第三方 API 增强功能，但同时引入了安全风险。研究提出一个新的攻击框架，用于评估 LLM 平台中第三方服务的漏洞，并在实际 LLM 上识别出各种领域的恶意攻击，这些攻击能不明显地修改模型输出。论文分析了第三方 API 整合的独特挑战，并提供策略建议来提升 LLM 生态系统的安全性和可靠性，同时开源了相关代码。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "ICLR 2024 Workshop on Secure and Trustworthy Large Language Models",
      "pdf_url": "http://arxiv.org/pdf/2404.16891v1",
      "published_date": "2024-04-24 19:27:02 UTC",
      "updated_date": "2024-04-24 19:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:12:20.470749"
    },
    {
      "arxiv_id": "2404.16130v2",
      "title": "From Local to Global: A Graph RAG Approach to Query-Focused Summarization",
      "title_zh": "从局部到全局：Graph RAG",
      "authors": [
        "Darren Edge",
        "Ha Trinh",
        "Newman Cheng",
        "Joshua Bradley",
        "Alex Chao",
        "Apurva Mody",
        "Steven Truitt",
        "Dasha Metropolitansky",
        "Robert Osazuwa Ness",
        "Jonathan Larson"
      ],
      "abstract": "The use of retrieval-augmented generation (RAG) to retrieve relevant\ninformation from an external knowledge source enables large language models\n(LLMs) to answer questions over private and/or previously unseen document\ncollections. However, RAG fails on global questions directed at an entire text\ncorpus, such as \"What are the main themes in the dataset?\", since this is\ninherently a query-focused summarization (QFS) task, rather than an explicit\nretrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of\ntext indexed by typical RAG systems. To combine the strengths of these\ncontrasting methods, we propose GraphRAG, a graph-based approach to question\nanswering over private text corpora that scales with both the generality of\nuser questions and the quantity of source text. Our approach uses an LLM to\nbuild a graph index in two stages: first, to derive an entity knowledge graph\nfrom the source documents, then to pregenerate community summaries for all\ngroups of closely related entities. Given a question, each community summary is\nused to generate a partial response, before all partial responses are again\nsummarized in a final response to the user. For a class of global sensemaking\nquestions over datasets in the 1 million token range, we show that GraphRAG\nleads to substantial improvements over a conventional RAG baseline for both the\ncomprehensiveness and diversity of generated answers.",
      "tldr_zh": "这篇论文提出 GraphRAG，一种基于图的 RAG 方法，用于处理查询焦点摘要(QFS)任务，解决传统 RAG 在应对全局问题（如数据集主题分析）时的局限性。GraphRAG 通过 LLM 先构建实体知识图，然后为相关实体群生成社区摘要，再汇总部分响应形成最终答案，从而兼顾大规模文本处理和查询泛化。实验显示，在百万级令牌数据集上，GraphRAG 相较于传统 RAG 基线，显著提升了回答的全面性和多样性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "H.3.3; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16130v2",
      "published_date": "2024-04-24 18:38:11 UTC",
      "updated_date": "2025-02-19 10:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:12:35.730963"
    },
    {
      "arxiv_id": "2404.16123v1",
      "title": "FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Slyman",
        "Stefan Lee",
        "Scott Cohen",
        "Kushal Kafle"
      ],
      "abstract": "Recent dataset deduplication techniques have demonstrated that content-aware\ndataset pruning can dramatically reduce the cost of training Vision-Language\nPretrained (VLP) models without significant performance losses compared to\ntraining on the original dataset. These results have been based on pruning\ncommonly used image-caption datasets collected from the web -- datasets that\nare known to harbor harmful social biases that may then be codified in trained\nmodels. In this work, we evaluate how deduplication affects the prevalence of\nthese biases in the resulting trained models and introduce an easy-to-implement\nmodification to the recent SemDeDup algorithm that can reduce the negative\neffects that we observe. When examining CLIP-style models trained on\ndeduplicated variants of LAION-400M, we find our proposed FairDeDup algorithm\nconsistently leads to improved fairness metrics over SemDeDup on the FairFace\nand FACET datasets while maintaining zero-shot performance on CLIP benchmarks.",
      "tldr_zh": "这项研究评估了语义数据集去重技术对视觉语言预训练 (VLP) 模型公平性的影响，发现传统方法如 SemDeDup 可能放大有害社会偏见。作者提出了 FairDeDup 算法，这是一种易于实现的修改版本，旨在通过优化去重过程来减轻这些偏见。实验结果显示，在 LAION-400M 数据集的去重变体上训练的 CLIP 风格模型中，FairDeDup 显著提高了模型在 FairFace 和 FACET 数据集上的公平性指标，同时保持了 CLIP 基准的零样本性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "I.4.10; I.2.7; E.0"
      ],
      "primary_category": "cs.CV",
      "comment": "Conference paper at CVPR 2024. 6 pages, 8 figures. Project Page:\n  https://ericslyman.com/fairdedup/",
      "pdf_url": "http://arxiv.org/pdf/2404.16123v1",
      "published_date": "2024-04-24 18:28:17 UTC",
      "updated_date": "2024-04-24 18:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:12:47.264741"
    },
    {
      "arxiv_id": "2405.05136v1",
      "title": "Integrating LSTM and BERT for Long-Sequence Data Analysis in Intelligent Tutoring Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoxing Li",
        "Jujie Yang",
        "Jindi Wang",
        "Lei Shi",
        "Sebastian Stein"
      ],
      "abstract": "The field of Knowledge Tracing aims to understand how students learn and\nmaster knowledge over time by analyzing their historical behaviour data. To\nachieve this goal, many researchers have proposed Knowledge Tracing models that\nuse data from Intelligent Tutoring Systems to predict students' subsequent\nactions. However, with the development of Intelligent Tutoring Systems,\nlarge-scale datasets containing long-sequence data began to emerge. Recent deep\nlearning based Knowledge Tracing models face obstacles such as low efficiency,\nlow accuracy, and low interpretability when dealing with large-scale datasets\ncontaining long-sequence data. To address these issues and promote the\nsustainable development of Intelligent Tutoring Systems, we propose a LSTM\nBERT-based Knowledge Tracing model for long sequence data processing, namely\nLBKT, which uses a BERT-based architecture with a Rasch model-based embeddings\nblock to deal with different difficulty levels information and an LSTM block to\nprocess the sequential characteristic in students' actions. LBKT achieves the\nbest performance on most benchmark datasets on the metrics of ACC and AUC.\nAdditionally, an ablation study is conducted to analyse the impact of each\ncomponent of LBKT's overall performance. Moreover, we used t-SNE as the\nvisualisation tool to demonstrate the model's embedding strategy. The results\nindicate that LBKT is faster, more interpretable, and has a lower memory cost\nthan the traditional deep learning based Knowledge Tracing methods.",
      "tldr_zh": "本文针对知识追踪(Knowledge Tracing)模型在处理大规模长序列数据时存在的效率低、准确率低和可解释性差等问题，提出了一种整合 LSTM 和 BERT 的新模型 LBKT。LBKT 采用 BERT-based 架构结合 Rasch model-based embeddings 块来处理不同难度水平的信息，并使用 LSTM 块处理学生的顺序行为特性。在基准数据集上，LBKT 取得了最佳的 ACC 和 AUC 指标，比传统深度学习方法更快、更可解释且内存消耗更低。通过 ablation study 和 t-SNE 可视化，进一步分析了各组件对整体性能的影响。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.05136v1",
      "published_date": "2024-04-24 18:19:44 UTC",
      "updated_date": "2024-04-24 18:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:12:58.934575"
    },
    {
      "arxiv_id": "2404.16116v2",
      "title": "Classifying Human-Generated and AI-Generated Election Claims in Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Alphaeus Dmonte",
        "Marcos Zampieri",
        "Kevin Lybarger",
        "Massimiliano Albanese",
        "Genya Coulter"
      ],
      "abstract": "Politics is one of the most prevalent topics discussed on social media\nplatforms, particularly during major election cycles, where users engage in\nconversations about candidates and electoral processes. Malicious actors may\nuse this opportunity to disseminate misinformation to undermine trust in the\nelectoral process. The emergence of Large Language Models (LLMs) exacerbates\nthis issue by enabling malicious actors to generate misinformation at an\nunprecedented scale. Artificial intelligence (AI)-generated content is often\nindistinguishable from authentic user content, raising concerns about the\nintegrity of information on social networks. In this paper, we present a novel\ntaxonomy for characterizing election-related claims. This taxonomy provides an\ninstrument for analyzing election-related claims, with granular categories\nrelated to jurisdiction, equipment, processes, and the nature of claims. We\nintroduce ElectAI, a novel benchmark dataset that consists of 9,900 tweets,\neach labeled as human- or AI-generated. For AI-generated tweets, the specific\nLLM variant that produced them is specified. We annotated a subset of 1,550\ntweets using the proposed taxonomy to capture the characteristics of\nelection-related claims. We explored the capabilities of LLMs in extracting the\ntaxonomy attributes and trained various machine learning models using ElectAI\nto distinguish between human- and AI-generated posts and identify the specific\nLLM variant.",
      "tldr_zh": "这篇论文针对社交媒体上选举相关声明的误信息问题，提出一个新的分类体系（taxonomy），用于分析涉及管辖区、设备、过程和声明性质的细粒度类别。研究者引入了ElectAI数据集，包含9,900条推文，其中标注了人类生成或AI生成（并指定LLM变体），并对1,550条推文进行了taxonomy注解。实验中，他们探索了Large Language Models (LLMs)在提取taxonomy属性的能力，并训练各种机器学习模型，以区分人类和AI生成的内容并识别具体LLM变体，从而提升选举信息完整性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16116v2",
      "published_date": "2024-04-24 18:13:29 UTC",
      "updated_date": "2024-04-26 01:51:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:13:10.018091"
    },
    {
      "arxiv_id": "2404.16115v1",
      "title": "Online Personalizing White-box LLMs Generation with Neural Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Zekai Chen",
        "Weeden Daniel",
        "Po-yu Chen",
        "Francois Buet-Golfouse"
      ],
      "abstract": "The advent of personalized content generation by LLMs presents a novel\nchallenge: how to efficiently adapt text to meet individual preferences without\nthe unsustainable demand of creating a unique model for each user. This study\nintroduces an innovative online method that employs neural bandit algorithms to\ndynamically optimize soft instruction embeddings based on user feedback,\nenhancing the personalization of open-ended text generation by white-box LLMs.\nThrough rigorous experimentation on various tasks, we demonstrate significant\nperformance improvements over baseline strategies. NeuralTS, in particular,\nleads to substantial enhancements in personalized news headline generation,\nachieving up to a 62.9% improvement in terms of best ROUGE scores and up to\n2.76% increase in LLM-agent evaluation against the baseline.",
      "tldr_zh": "本研究提出了一种在线方法，使用neural bandits算法动态优化soft instruction embeddings，以基于用户反馈个性化white-box LLMs的文本生成，从而避免为每个用户创建独特模型的资源浪费。该方法通过实时适应用户偏好，显著提升了开放式文本生成的性能。在实验中，NeuralTS在个性化新闻标题生成任务上，ROUGE scores提高了62.9%，并在LLM-agent评估中提升了2.76%。这为高效的个性化内容生成提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.16115v1",
      "published_date": "2024-04-24 18:13:12 UTC",
      "updated_date": "2024-04-24 18:13:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:13:21.298303"
    },
    {
      "arxiv_id": "2404.16112v1",
      "title": "Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Badri Narayana Patro",
        "Vijay Srinivas Agneeswaran"
      ],
      "abstract": "Sequence modeling is a crucial area across various domains, including Natural\nLanguage Processing (NLP), speech recognition, time series forecasting, music\ngeneration, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short\nTerm Memory Networks (LSTMs) have historically dominated sequence modeling\ntasks like Machine Translation, Named Entity Recognition (NER), etc. However,\nthe advancement of transformers has led to a shift in this paradigm, given\ntheir superior performance. Yet, transformers suffer from $O(N^2)$ attention\ncomplexity and challenges in handling inductive bias. Several variations have\nbeen proposed to address these issues which use spectral networks or\nconvolutions and have performed well on a range of tasks. However, they still\nhave difficulty in dealing with long sequences. State Space Models(SSMs) have\nemerged as promising alternatives for sequence modeling paradigms in this\ncontext, especially with the advent of S4 and its variants, such as S4nd,\nHippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear\nRecurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the\nfoundational SSMs based on three paradigms namely, Gating architectures,\nStructural architectures, and Recurrent architectures. This survey also\nhighlights diverse applications of SSMs across domains such as vision, video,\naudio, speech, language (especially long sequence modeling), medical (including\ngenomics), chemical (like drug design), recommendation systems, and time series\nanalysis, including tabular data. Moreover, we consolidate the performance of\nSSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile,\nImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast,\nCOIN, LVU, and various time series datasets. The project page for Mamba-360\nwork is available on this webpage.\\url{https://github.com/badripatro/mamba360}.",
      "tldr_zh": "这篇调查论文探讨了 State Space Models (SSMs) 作为 Transformer 替代方案在长序列建模中的潜力，回顾了从 RNN 和 LSTM 到 SSMs 的演变，并指出了 Transformer 的问题，如 O(N^2) 注意力复杂度。论文将 SSMs 分类为 Gating architectures、Structural architectures 和 Recurrent architectures，包括变体如 S4、Mamba 等，并总结了其在 NLP、视觉、音频、医疗（如基因组学）、推荐系统和时间序列分析等领域的广泛应用。实验结果显示，SSMs 在基准数据集如 Long Range Arena (LRA)、WikiText 和 ImageNet 上表现出色，但仍面临处理长序列的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16112v1",
      "published_date": "2024-04-24 18:10:31 UTC",
      "updated_date": "2024-04-24 18:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:13:35.465016"
    },
    {
      "arxiv_id": "2404.16035v1",
      "title": "MaGGIe: Masked Guided Gradual Human Instance Matting",
      "title_zh": "翻译失败",
      "authors": [
        "Chuong Huynh",
        "Seoung Wug Oh",
        "Abhinav Shrivastava",
        "Joon-Young Lee"
      ],
      "abstract": "Human matting is a foundation task in image and video processing, where human\nforeground pixels are extracted from the input. Prior works either improve the\naccuracy by additional guidance or improve the temporal consistency of a single\ninstance across frames. We propose a new framework MaGGIe, Masked Guided\nGradual Human Instance Matting, which predicts alpha mattes progressively for\neach human instances while maintaining the computational cost, precision, and\nconsistency. Our method leverages modern architectures, including transformer\nattention and sparse convolution, to output all instance mattes simultaneously\nwithout exploding memory and latency. Although keeping constant inference costs\nin the multiple-instance scenario, our framework achieves robust and versatile\nperformance on our proposed synthesized benchmarks. With the higher quality\nimage and video matting benchmarks, the novel multi-instance synthesis approach\nfrom publicly available sources is introduced to increase the generalization of\nmodels in real-world scenarios.",
      "tldr_zh": "本文提出 MaGGIe 框架（Masked Guided Gradual Human Instance Matting），一种用于图像和视频处理的渐进式人类实例抠图方法，能够逐步预测每个实例的 alpha mattes，同时保持计算成本、精度和时序一致性。MaGGIe 利用 transformer attention 和 sparse convolution 等现代架构，同时输出多个实例的 matte，而不增加内存或延迟，从而在多实例场景中实现高效处理。在提出的合成基准上，该框架表现出色，并通过新颖的多实例合成方法提升了模型在真实世界场景中的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024. Project link: https://maggie-matt.github.io",
      "pdf_url": "http://arxiv.org/pdf/2404.16035v1",
      "published_date": "2024-04-24 17:59:53 UTC",
      "updated_date": "2024-04-24 17:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:13:45.829445"
    },
    {
      "arxiv_id": "2404.16030v1",
      "title": "MoDE: CLIP Data Experts via Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Ma",
        "Po-Yao Huang",
        "Saining Xie",
        "Shang-Wen Li",
        "Luke Zettlemoyer",
        "Shih-Fu Chang",
        "Wen-Tau Yih",
        "Hu Xu"
      ],
      "abstract": "The success of contrastive language-image pretraining (CLIP) relies on the\nsupervision from the pairing between images and captions, which tends to be\nnoisy in web-crawled data. We present Mixture of Data Experts (MoDE) and learn\na system of CLIP data experts via clustering. Each data expert is trained on\none data cluster, being less sensitive to false negative noises in other\nclusters. At inference time, we ensemble their outputs by applying weights\ndetermined through the correlation between task metadata and cluster\nconditions. To estimate the correlation precisely, the samples in one cluster\nshould be semantically similar, but the number of data experts should still be\nreasonable for training and inference. As such, we consider the ontology in\nhuman language and propose to use fine-grained cluster centers to represent\neach data expert at a coarse-grained level. Experimental studies show that four\nCLIP data experts on ViT-B/16 outperform the ViT-L/14 by OpenAI CLIP and\nOpenCLIP on zero-shot image classification but with less ($<$35\\%) training\ncost. Meanwhile, MoDE can train all data expert asynchronously and can flexibly\ninclude new data experts. The code is available at\nhttps://github.com/facebookresearch/MetaCLIP/tree/main/mode.",
      "tldr_zh": "该论文提出了 MoDE（Mixture of Data Experts），一种通过聚类方法学习 CLIP 数据专家的框架，以缓解网页爬取数据中图像和标题配对噪音的问题。每个数据专家在特定数据集群上训练，从而减少对其他集群的假负噪音敏感，并在推理时通过任务元数据与集群条件的相关性加权集成输出。作者使用细粒度集群中心在粗粒度级别表示专家，以平衡语义相似性和专家数量。实验结果显示，四个 CLIP 数据专家的 ViT-B/16 在 zero-shot image classification 上超过了 OpenAI CLIP 的 ViT-L/14，同时训练成本不到 35%，并支持异步训练和灵活添加新专家。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE CVPR 2024 Camera Ready. Code Link:\n  https://github.com/facebookresearch/MetaCLIP/tree/main/mode",
      "pdf_url": "http://arxiv.org/pdf/2404.16030v1",
      "published_date": "2024-04-24 17:59:24 UTC",
      "updated_date": "2024-04-24 17:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:13:58.482569"
    },
    {
      "arxiv_id": "2404.16017v3",
      "title": "RetinaRegNet: A Zero-Shot Approach for Retinal Image Registration",
      "title_zh": "翻译失败",
      "authors": [
        "Vishal Balaji Sivaraman",
        "Muhammad Imran",
        "Qingyue Wei",
        "Preethika Muralidharan",
        "Michelle R. Tamplin",
        "Isabella M . Grumbach",
        "Randy H. Kardon",
        "Jui-Kai Wang",
        "Yuyin Zhou",
        "Wei Shao"
      ],
      "abstract": "We introduce RetinaRegNet, a zero-shot image registration model designed to\nregister retinal images with minimal overlap, large deformations, and varying\nimage quality. RetinaRegNet addresses these challenges and achieves robust and\naccurate registration through the following steps. First, we extract features\nfrom the moving and fixed images using latent diffusion models. We then sample\nfeature points from the fixed image using a combination of the SIFT algorithm\nand random point sampling. For each sampled point, we identify its\ncorresponding point in the moving image using a 2D correlation map, which\ncomputes the cosine similarity between the diffusion feature vectors of the\npoint in the fixed image and all pixels in the moving image. Second, we\neliminate most incorrectly detected point correspondences (outliers) by\nenforcing an inverse consistency constraint, ensuring that correspondences are\nconsistent in both forward and backward directions. We further remove outliers\nwith large distances between corresponding points using a global transformation\nbased outlier detector. Finally, we implement a two-stage registration\nframework to handle large deformations. The first stage estimates a homography\ntransformation to achieve global alignment between the images, while the second\nstage uses a third-order polynomial transformation to estimate local\ndeformations. We evaluated RetinaRegNet on three retinal image registration\ndatasets: color fundus images, fluorescein angiography images, and laser\nspeckle flowgraphy images. Our model consistently outperformed state-of-the-art\nmethods across all datasets. The accurate registration achieved by RetinaRegNet\nenables the tracking of eye disease progression, enhances surgical planning,\nand facilitates the evaluation of treatment efficacy. Our code is publicly\navailable at: https://github.com/mirthAI/RetinaRegNet.",
      "tldr_zh": "本文提出 RetinaRegNet，一种零样本（zero-shot）方法，用于视网膜图像配准，针对最小重叠、大变形和图像质量变化等挑战。方法包括使用潜在扩散模型提取特征、结合 SIFT 算法和随机采样点匹配对应点、通过逆一致性约束和全局变换检测器去除异常点，以及两阶段框架（homography transformation 全局对齐和三阶多项式变换局部变形）。在色素基金us图像、荧光血管造影图像和激光散斑流速图像数据集上，RetinaRegNet 优于现有方法，实现了更准确的配准。该模型的应用可提升眼病进展跟踪、手术规划和治疗效果评估，代码已在 GitHub 公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16017v3",
      "published_date": "2024-04-24 17:50:37 UTC",
      "updated_date": "2024-09-11 00:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:14:12.440730"
    },
    {
      "arxiv_id": "2404.16015v2",
      "title": "Neural Operators Learn the Local Physics of Magnetohydrodynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Taeyoung Kim",
        "Youngsoo Ha",
        "Myungjoo Kang"
      ],
      "abstract": "Magnetohydrodynamics (MHD) plays a pivotal role in describing the dynamics of\nplasma and conductive fluids, essential for understanding phenomena such as the\nstructure and evolution of stars and galaxies, and in nuclear fusion for plasma\nmotion through ideal MHD equations. Solving these hyperbolic PDEs requires\nsophisticated numerical methods, presenting computational challenges due to\ncomplex structures and high costs. Recent advances introduce neural operators\nlike the Fourier Neural Operator (FNO) as surrogate models for traditional\nnumerical analyses. This study explores a modified Flux Fourier neural operator\nmodel to approximate the numerical flux of ideal MHD, offering a novel approach\nthat outperforms existing neural operator models by enabling continuous\ninference, generalization outside sampled distributions, and faster computation\ncompared to classical numerical schemes.",
      "tldr_zh": "本研究探讨了神经算子在磁流体力学(Magnetohydrodynamics, MHD)中的应用，针对MHD的超声速偏微分方程(hyperbolic PDEs)带来的计算挑战，提出一个修改后的Flux Fourier neural operator模型，作为传统数值分析的替代方案。该模型基于Fourier Neural Operator(FNO)，能够精确近似理想MHD的数值通量，支持连续推理、在采样分布外的泛化，并显著加快计算速度。实验结果表明，该方法优于现有神经算子模型，为理解恒星、星系演化及核聚变等现象提供了更高效的模拟工具。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "48 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.16015v2",
      "published_date": "2024-04-24 17:48:38 UTC",
      "updated_date": "2024-10-10 14:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:14:23.427910"
    },
    {
      "arxiv_id": "2404.16014v2",
      "title": "Improving Dictionary Learning with Gated Sparse Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Senthooran Rajamanoharan",
        "Arthur Conmy",
        "Lewis Smith",
        "Tom Lieberum",
        "Vikrant Varma",
        "János Kramár",
        "Rohin Shah",
        "Neel Nanda"
      ],
      "abstract": "Recent work has found that sparse autoencoders (SAEs) are an effective\ntechnique for unsupervised discovery of interpretable features in language\nmodels' (LMs) activations, by finding sparse, linear reconstructions of LM\nactivations. We introduce the Gated Sparse Autoencoder (Gated SAE), which\nachieves a Pareto improvement over training with prevailing methods. In SAEs,\nthe L1 penalty used to encourage sparsity introduces many undesirable biases,\nsuch as shrinkage -- systematic underestimation of feature activations. The key\ninsight of Gated SAEs is to separate the functionality of (a) determining which\ndirections to use and (b) estimating the magnitudes of those directions: this\nenables us to apply the L1 penalty only to the former, limiting the scope of\nundesirable side effects. Through training SAEs on LMs of up to 7B parameters\nwe find that, in typical hyper-parameter ranges, Gated SAEs solve shrinkage,\nare similarly interpretable, and require half as many firing features to\nachieve comparable reconstruction fidelity.",
      "tldr_zh": "本研究引入了 Gated Sparse Autoencoders (Gated SAE)，以改进传统 Sparse Autoencoders (SAEs) 在语言模型 (LMs) 激活中的字典学习，通过分离方向选择和幅度估计的功能，仅对前者施加 L1 penalty，从而减少收缩（shrinkage）等偏差。Gated SAE 的关键创新在于避免了 L1 penalty 的负面影响，同时保持特征的可解释性。在高达 7B 参数的 LMs 上实验表明，Gated SAE 需要仅一半的激活特征即可实现相似的重建保真度，并显著提升了整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 main text pages, 22 appendix pages",
      "pdf_url": "http://arxiv.org/pdf/2404.16014v2",
      "published_date": "2024-04-24 17:47:22 UTC",
      "updated_date": "2024-04-30 17:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:14:36.838006"
    },
    {
      "arxiv_id": "2404.15961v1",
      "title": "Soil analysis with machine-learning-based processing of stepped-frequency GPR field measurements: Preliminary study",
      "title_zh": "翻译失败",
      "authors": [
        "Chunlei Xu",
        "Michael Pregesbauer",
        "Naga Sravani Chilukuri",
        "Daniel Windhager",
        "Mahsa Yousefi",
        "Pedro Julian",
        "Lothar Ratschbacher"
      ],
      "abstract": "Ground Penetrating Radar (GPR) has been widely studied as a tool for\nextracting soil parameters relevant to agriculture and horticulture. When\ncombined with Machine-Learning-based (ML) methods, high-resolution Stepped\nFrequency Countinuous Wave Radar (SFCW) measurements hold the promise to give\ncost effective access to depth resolved soil parameters, including at\nroot-level depth. In a first step in this direction, we perform an extensive\nfield survey with a tractor mounted SFCW GPR instrument. Using ML data\nprocessing we test the GPR instrument's capabilities to predict the apparent\nelectrical conductivity (ECaR) as measured by a simultaneously recording\nElectromagnetic Induction (EMI) instrument. The large-scale field measurement\ncampaign with 3472 co-registered and geo-located GPR and EMI data samples\ndistributed over ~6600 square meters was performed on a golf course. The\nselected terrain benefits from a high surface homogeneity, but also features\nthe challenge of only small, and hence hard to discern, variations in the\nmeasured soil parameter. Based on the quantitative results we suggest the use\nof nugget-to-sill ratio as a performance metric for the evaluation of\nend-to-end ML performance in the agricultural setting and discuss the limiting\nfactors in the multi-sensor regression setting. The code is released as open\nsource and available at\nhttps://opensource.silicon-austria.com/xuc/soil-analysis-machine-learning-stepped-frequency-gpr.",
      "tldr_zh": "本研究探讨了使用 Ground Penetrating Radar (GPR) 结合 Machine-Learning-based (ML) 方法处理 Stepped Frequency Continuous Wave Radar (SFCW) 实地测量数据，以提取农业和园艺相关的土壤参数。研究团队在高尔夫球场上进行大规模实地调查，使用拖拉机安装的 SFCW GPR 仪器与 Electromagnetic Induction (EMI) 仪器同步收集3472个配准数据样本，测试 GPR 预测 apparent electrical conductivity (ECaR) 的能力。结果显示，该方法在多传感器回归场景中表现出色，并建议采用 nugget-to-sill ratio 作为评估指标，同时开源了相关代码以促进进一步应用。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15961v1",
      "published_date": "2024-04-24 16:30:12 UTC",
      "updated_date": "2024-04-24 16:30:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:14:49.285948"
    },
    {
      "arxiv_id": "2404.15949v2",
      "title": "CORM: Cache Optimization with Recent Message for Large Language Model Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Jincheng Dai",
        "Zhuowei Huang",
        "Haiyun Jiang",
        "Chen Chen",
        "Deng Cai",
        "Wei Bi",
        "Shuming Shi"
      ],
      "abstract": "Large Language Models (LLMs), despite their remarkable performance across a\nwide range of tasks, necessitate substantial GPU memory and consume significant\ncomputational resources. Beyond the memory taken up by model weights, the\nmemory used by the KV cache rises linearly with sequence length, becoming a\nprimary bottleneck for inference. In this paper, we introduce an innovative\nmethod for optimizing the KV cache, which considerably minimizes its memory\nfootprint. Upon thorough investigation, we discover that in most Transformer\nmodels, (i) there is a striking similarity between adjacent tokens' query\nvectors, and (ii) the attention calculation of the current query can rely\nexclusively on the attention information of a small fraction of preceding\nqueries. Based on these observations, we present CORM, a KV cache eviction\npolicy that dynamically retains essential key-value pairs for inference without\nthe need for model fine-tuning. Our validation shows that CORM reduces the\ninference memory usage of KV cache by up to 70\\% with negligible performance\ndegradation across six tasks in LongBench. Furthermore, we demonstrate that\nCORM is compatible with GQA for further compression rate.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的推理过程，提出了一种CORM缓存优化策略，以缓解KV cache随序列长度线性增长的内存瓶颈问题。CORM基于对Transformer模型的观察——相邻token的query向量高度相似，且当前query的注意力计算只需依赖少量前置query——动态保留关键的key-value对，而无需模型微调。实验结果显示，CORM可在LongBench的六种任务中将KV cache的推理内存使用减少高达70%，性能几乎不受影响，并与GQA技术兼容，实现进一步压缩。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15949v2",
      "published_date": "2024-04-24 16:11:54 UTC",
      "updated_date": "2024-06-21 11:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:15:01.305806"
    },
    {
      "arxiv_id": "2404.15946v1",
      "title": "Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography",
      "title_zh": "翻译失败",
      "authors": [
        "Xuxin Chen",
        "Yuheng Li",
        "Mingzhe Hu",
        "Ella Salari",
        "Xiaoqian Chen",
        "Richard L. J. Qiu",
        "Bin Zheng",
        "Xiaofeng Yang"
      ],
      "abstract": "Although fusion of information from multiple views of mammograms plays an\nimportant role to increase accuracy of breast cancer detection, developing\nmulti-view mammograms-based computer-aided diagnosis (CAD) schemes still faces\nchallenges and no such CAD schemes have been used in clinical practice. To\novercome the challenges, we investigate a new approach based on Contrastive\nLanguage-Image Pre-training (CLIP), which has sparked interest across various\nmedical imaging tasks. By solving the challenges in (1) effectively adapting\nthe single-view CLIP for multi-view feature fusion and (2) efficiently\nfine-tuning this parameter-dense model with limited samples and computational\nresources, we introduce Mammo-CLIP, the first multi-modal framework to process\nmulti-view mammograms and corresponding simple texts. Mammo-CLIP uses an early\nfeature fusion strategy to learn multi-view relationships in four mammograms\nacquired from the CC and MLO views of the left and right breasts. To enhance\nlearning efficiency, plug-and-play adapters are added into CLIP image and text\nencoders for fine-tuning parameters and limiting updates to about 1% of the\nparameters. For framework evaluation, we assembled two datasets\nretrospectively. The first dataset, comprising 470 malignant and 479 benign\ncases, was used for few-shot fine-tuning and internal evaluation of the\nproposed Mammo-CLIP via 5-fold cross-validation. The second dataset, including\n60 malignant and 294 benign cases, was used to test generalizability of\nMammo-CLIP. Study results show that Mammo-CLIP outperforms the state-of-art\ncross-view transformer in AUC (0.841 vs. 0.817, 0.837 vs. 0.807) on both\ndatasets. It also surpasses previous two CLIP-based methods by 20.3% and 14.3%.\nThis study highlights the potential of applying the finetuned vision-language\nmodels for developing next-generation, image-text-based CAD schemes of breast\ncancer.",
      "tldr_zh": "本研究提出Mammo-CLIP框架，利用Contrastive Language-Image Pre-training (CLIP)模型来提升多视图乳腺X光照片的乳腺癌诊断准确性，解决单视图CLIP在多视图特征融合和资源有限条件下微调的挑战。Mammo-CLIP采用早期特征融合策略处理左右乳房CC和MLO视图的四张图像，并通过添加即插即用适配器，仅微调约1%的参数，以高效学习多模态图像-文本关系。实验结果显示，该框架在两个数据集上的AUC值（分别为0.841和0.837）均优于最先进的跨视图transformer和现有CLIP-based方法，提高了20.3%和14.3%，为开发基于图像-文本的下一代计算机辅助诊断（CAD）方案提供了潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15946v1",
      "published_date": "2024-04-24 16:07:31 UTC",
      "updated_date": "2024-04-24 16:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:15:15.413929"
    },
    {
      "arxiv_id": "2404.15943v3",
      "title": "Decentralized Personalized Federated Learning based on a Conditional Sparse-to-Sparser Scheme",
      "title_zh": "翻译失败",
      "authors": [
        "Qianyu Long",
        "Qiyuan Wang",
        "Christos Anagnostopoulos",
        "Daning Bi"
      ],
      "abstract": "Decentralized Federated Learning (DFL) has become popular due to its\nrobustness and avoidance of centralized coordination. In this paradigm, clients\nactively engage in training by exchanging models with their networked\nneighbors. However, DFL introduces increased costs in terms of training and\ncommunication. Existing methods focus on minimizing communication often\noverlooking training efficiency and data heterogeneity. To address this gap, we\npropose a novel \\textit{sparse-to-sparser} training scheme: DA-DPFL. DA-DPFL\ninitializes with a subset of model parameters, which progressively reduces\nduring training via \\textit{dynamic aggregation} and leads to substantial\nenergy savings while retaining adequate information during critical learning\nperiods.\n  Our experiments showcase that DA-DPFL substantially outperforms DFL baselines\nin test accuracy, while achieving up to $5$ times reduction in energy costs. We\nprovide a theoretical analysis of DA-DPFL's convergence by solidifying its\napplicability in decentralized and personalized learning. The code is available\nat:https://github.com/EricLoong/da-dpfl",
      "tldr_zh": "本研究针对 Decentralized Federated Learning (DFL) 的训练和通信成本问题，提出了一种新的 personalized 学习方法 DA-DPFL，该方法基于 conditional sparse-to-sparser 方案，通过动态聚合逐步减少模型参数，从而显著节省能量并适应数据异质性。DA-DPFL 在实验中表现出色，比 DFL 基线模型提高了测试准确率，并实现了高达 5 倍的能量消耗减少。该方法还提供了收敛性的理论分析，并开源了代码，支持其在分布式学习中的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 9 figures, 3 pages theory",
      "pdf_url": "http://arxiv.org/pdf/2404.15943v3",
      "published_date": "2024-04-24 16:03:34 UTC",
      "updated_date": "2024-07-22 21:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:15:24.715716"
    },
    {
      "arxiv_id": "2404.15923v1",
      "title": "KGValidator: A Framework for Automatic Validation of Knowledge Graph Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Jack Boylan",
        "Shashank Mangla",
        "Dominic Thorn",
        "Demian Gholipour Ghalandari",
        "Parsa Ghaffari",
        "Chris Hokamp"
      ],
      "abstract": "This study explores the use of Large Language Models (LLMs) for automatic\nevaluation of knowledge graph (KG) completion models. Historically, validating\ninformation in KGs has been a challenging task, requiring large-scale human\nannotation at prohibitive cost. With the emergence of general-purpose\ngenerative AI and LLMs, it is now plausible that human-in-the-loop validation\ncould be replaced by a generative agent. We introduce a framework for\nconsistency and validation when using generative models to validate knowledge\ngraphs. Our framework is based upon recent open-source developments for\nstructural and semantic validation of LLM outputs, and upon flexible approaches\nto fact checking and verification, supported by the capacity to reference\nexternal knowledge sources of any kind. The design is easy to adapt and extend,\nand can be used to verify any kind of graph-structured data through a\ncombination of model-intrinsic knowledge, user-supplied context, and agents\ncapable of external knowledge retrieval.",
      "tldr_zh": "本研究探讨了使用 Large Language Models (LLMs) 自动评估 Knowledge Graph (KG) 完成模型，以解决传统验证过程依赖大规模人工标注的成本高问题。研究引入了 KGValidator 框架，该框架基于开源工具，结合结构和语义验证、事实检查以及外部知识检索代理，实现对 KG 的一致性和准确性验证。框架设计灵活，可适应任何图结构数据，通过模型内在知识、用户提供的上下文和外部来源，提升验证效率和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Text2KG 2024, ESWC 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15923v1",
      "published_date": "2024-04-24 15:27:25 UTC",
      "updated_date": "2024-04-24 15:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:15:36.121919"
    },
    {
      "arxiv_id": "2404.15903v1",
      "title": "Drawing the Line: Deep Segmentation for Extracting Art from Ancient Etruscan Mirrors",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Sterzinger",
        "Simon Brenner",
        "Robert Sablatnig"
      ],
      "abstract": "Etruscan mirrors constitute a significant category within Etruscan art and,\ntherefore, undergo systematic examinations to obtain insights into ancient\ntimes. A crucial aspect of their analysis involves the labor-intensive task of\nmanually tracing engravings from the backside. Additionally, this task is\ninherently challenging due to the damage these mirrors have sustained,\nintroducing subjectivity into the process. We address these challenges by\nautomating the process through photometric-stereo scanning in conjunction with\ndeep segmentation networks which, however, requires effective usage of the\nlimited data at hand. We accomplish this by incorporating predictions on a\nper-patch level, and various data augmentations, as well as exploring\nself-supervised learning. Compared to our baseline, we improve predictive\nperformance w.r.t. the pseudo-F-Measure by around 16%. When assessing\nperformance on complete mirrors against a human baseline, our approach yields\nquantitative similar performance to a human annotator and significantly\noutperforms existing binarization methods. With our proposed methodology, we\nstreamline the annotation process, enhance its objectivity, and reduce overall\nworkload, offering a valuable contribution to the examination of these\nhistorical artifacts and other non-traditional documents.",
      "tldr_zh": "本研究针对古埃特鲁斯坎镜子艺术的提取问题，提出了一种自动化方法，使用 photometric-stereo scanning 结合 deep segmentation networks 来取代手动追踪刻画的过程，从而解决镜子受损导致的主观性和劳动密集型挑战。该方法通过 per-patch 级预测、数据增强和 self-supervised learning 等技术，充分利用有限的数据来提升模型性能。与基线相比，pseudo-F-Measure 指标提高了约16%，并在完整镜子测试中达到了与人类标注者相当的水平，显著优于现有二值化方法。该创新方法简化了标注流程，提高了客观性和效率，为历史文物和其他非传统文档的分析提供了宝贵工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, accepted at ICDAR2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15903v1",
      "published_date": "2024-04-24 14:57:37 UTC",
      "updated_date": "2024-04-24 14:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:15:48.465883"
    },
    {
      "arxiv_id": "2404.15899v3",
      "title": "ST-MambaSync: The Complement of Mamba and Transformers for Spatial-Temporal in Traffic Flow Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqi Shao",
        "Xusheng Yao",
        "Ze Wang",
        "Junbin Gao"
      ],
      "abstract": "Accurate traffic flow prediction is crucial for optimizing traffic\nmanagement, enhancing road safety, and reducing environmental impacts. Existing\nmodels face challenges with long sequence data, requiring substantial memory\nand computational resources, and often suffer from slow inference times due to\nthe lack of a unified summary state. This paper introduces ST-MambaSync, an\ninnovative traffic flow prediction model that combines transformer technology\nwith the ST-Mamba block, representing a significant advancement in the field.\nWe are the pioneers in employing the Mamba mechanism which is an attention\nmechanism integrated with ResNet within a transformer framework, which\nsignificantly enhances the model's explainability and performance. ST-MambaSync\neffectively addresses key challenges such as data length and computational\nefficiency, setting new benchmarks for accuracy and processing speed through\ncomprehensive comparative analysis. This development has significant\nimplications for urban planning and real-time traffic management, establishing\na new standard in traffic flow prediction technology.",
      "tldr_zh": "本研究针对交通流量预测中的长序列数据挑战（如高内存需求和慢速推理），提出了一种创新模型ST-MambaSync，将Transformer技术与ST-Mamba块相结合。ST-MambaSync首次引入Mamba机制（一种整合ResNet的注意力机制）于Transformer框架中，显著提升了模型的可解释性和性能。该模型有效解决了数据长度和计算效率问题，通过全面比较分析，在准确性和处理速度上设定了新基准，对城市规划和实时交通管理具有重要影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "53A45",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages. arXiv admin note: substantial text overlap with\n  arXiv:2404.13257",
      "pdf_url": "http://arxiv.org/pdf/2404.15899v3",
      "published_date": "2024-04-24 14:41:41 UTC",
      "updated_date": "2024-05-09 06:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:16:00.441792"
    },
    {
      "arxiv_id": "2404.15894v1",
      "title": "Assessing The Potential Of Mid-Sized Language Models For Clinical QA",
      "title_zh": "翻译失败",
      "authors": [
        "Elliot Bolton",
        "Betty Xiong",
        "Vijaytha Muralidharan",
        "Joel Schamroth",
        "Vivek Muralidharan",
        "Christopher D. Manning",
        "Roxana Daneshjou"
      ],
      "abstract": "Large language models, such as GPT-4 and Med-PaLM, have shown impressive\nperformance on clinical tasks; however, they require access to compute, are\nclosed-source, and cannot be deployed on device. Mid-size models such as\nBioGPT-large, BioMedLM, LLaMA 2, and Mistral 7B avoid these drawbacks, but\ntheir capacity for clinical tasks has been understudied. To help assess their\npotential for clinical use and help researchers decide which model they should\nuse, we compare their performance on two clinical question-answering (QA)\ntasks: MedQA and consumer query answering. We find that Mistral 7B is the best\nperforming model, winning on all benchmarks and outperforming models trained\nspecifically for the biomedical domain. While Mistral 7B's MedQA score of 63.0%\napproaches the original Med-PaLM, and it often can produce plausible responses\nto consumer health queries, room for improvement still exists. This study\nprovides the first head-to-head assessment of open source mid-sized models on\nclinical tasks.",
      "tldr_zh": "本研究评估了中等规模语言模型（如BioGPT-large、BioMedLM、LLaMA 2和Mistral 7B）在临床问答(QA)任务上的潜力，这些模型避免了大型模型如GPT-4和Med-PaLM的计算需求、闭源和部署限制。研究者比较了这些模型在MedQA和消费者查询回答两个任务上的表现。结果显示，Mistral 7B表现最佳，在所有基准测试中胜出，其MedQA分数达63.0%，甚至超过了专门针对生物医学领域训练的模型，但仍存在改进空间。该研究首次提供了开源中等规模模型在临床任务上的直接评估，为研究者选择合适模型提供了参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.15894v1",
      "published_date": "2024-04-24 14:32:34 UTC",
      "updated_date": "2024-04-24 14:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:16:14.274174"
    },
    {
      "arxiv_id": "2407.05210v1",
      "title": "Leveraging AI for Climate Resilience in Africa: Challenges, Opportunities, and the Need for Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Rendani Mbuvha",
        "Yassine Yaakoubi",
        "John Bagiliko",
        "Santiago Hincapie Potes",
        "Amal Nammouchi",
        "Sabrina Amrouche"
      ],
      "abstract": "As climate change issues become more pressing, their impact in Africa calls\nfor urgent, innovative solutions tailored to the continent's unique challenges.\nWhile Artificial Intelligence (AI) emerges as a critical and valuable tool for\nclimate change adaptation and mitigation, its effectiveness and potential are\ncontingent upon overcoming significant challenges such as data scarcity,\ninfrastructure gaps, and limited local AI development. This position paper\nexplores the role of AI in climate change adaptation and mitigation in Africa.\nIt advocates for a collaborative approach to build capacity, develop\nopen-source data repositories, and create context-aware, robust AI-driven\nclimate solutions that are culturally and contextually relevant.",
      "tldr_zh": "本论文探讨了 AI 在非洲气候变化适应和缓解中的作用，强调 AI 作为关键工具的潜力，但面临数据 scarcity、infrastructure gaps 和本地 AI 开发有限等挑战。该文分析了这些挑战与机遇，并主张通过合作方式构建能力、开发 open-source 数据仓库，以及创建文化和上下文相关的 AI-driven 解决方案，以推动非洲的气候 resilience。总的来说，这为加强 AI 在气候领域的应用提供了战略性指导。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05210v1",
      "published_date": "2024-04-24 14:05:22 UTC",
      "updated_date": "2024-04-24 14:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:16:24.325828"
    },
    {
      "arxiv_id": "2404.15882v2",
      "title": "Unexplored Faces of Robustness and Out-of-Distribution: Covariate Shifts in Environment and Sensor Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Eunsu Baek",
        "Keondo Park",
        "Jiyoon Kim",
        "Hyung-Sin Kim"
      ],
      "abstract": "Computer vision applications predict on digital images acquired by a camera\nfrom physical scenes through light. However, conventional robustness benchmarks\nrely on perturbations in digitized images, diverging from distribution shifts\noccurring in the image acquisition process. To bridge this gap, we introduce a\nnew distribution shift dataset, ImageNet-ES, comprising variations in\nenvironmental and camera sensor factors by directly capturing 202k images with\na real camera in a controllable testbed. With the new dataset, we evaluate\nout-of-distribution (OOD) detection and model robustness. We find that existing\nOOD detection methods do not cope with the covariate shifts in ImageNet-ES,\nimplying that the definition and detection of OOD should be revisited to\nembrace real-world distribution shifts. We also observe that the model becomes\nmore robust in both ImageNet-C and -ES by learning environment and sensor\nvariations in addition to existing digital augmentations. Lastly, our results\nsuggest that effective shift mitigation via camera sensor control can\nsignificantly improve performance without increasing model size. With these\nfindings, our benchmark may aid future research on robustness, OOD, and camera\nsensor control for computer vision. Our code and dataset are available at\nhttps://github.com/Edw2n/ImageNet-ES.",
      "tldr_zh": "本研究探讨了计算机视觉模型在环境和传感器领域中的协变量偏移（covariate shifts），强调现有鲁棒性基准测试仅关注数字图像扰动，而忽略了图像获取过程中的真实分布偏移。研究者引入了ImageNet-ES数据集，通过在可控测试环境中用真实相机捕获20.2万张图像，模拟环境和传感器因素的变化，以评估out-of-distribution (OOD)检测和模型鲁棒性。结果显示，现有的OOD检测方法无法有效应对ImageNet-ES中的偏移，建议重新定义OOD以适应真实世界场景；此外，通过学习这些变化，模型在ImageNet-C和ImageNet-ES上的鲁棒性得到提升，且通过相机传感器控制可显著改善性能，而无需增加模型大小。该基准数据集有望推动未来关于鲁棒性、OOD检测和传感器控制的研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published as a conference paper at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15882v2",
      "published_date": "2024-04-24 13:59:19 UTC",
      "updated_date": "2024-04-25 05:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:16:38.312967"
    },
    {
      "arxiv_id": "2404.15881v1",
      "title": "Steal Now and Attack Later: Evaluating Robustness of Object Detection against Black-box Adversarial Attacks",
      "title_zh": "Steal Now and Attack Later：评估物体检测针对黑盒对抗攻击的鲁棒性",
      "authors": [
        "Erh-Chung Chen",
        "Pin-Yu Chen",
        "I-Hsin Chung",
        "Che-Rung Lee"
      ],
      "abstract": "Latency attacks against object detection represent a variant of adversarial\nattacks that aim to inflate the inference time by generating additional ghost\nobjects in a target image. However, generating ghost objects in the black-box\nscenario remains a challenge since information about these unqualified objects\nremains opaque. In this study, we demonstrate the feasibility of generating\nghost objects in adversarial examples by extending the concept of \"steal now,\ndecrypt later\" attacks. These adversarial examples, once produced, can be\nemployed to exploit potential vulnerabilities in the AI service, giving rise to\nsignificant security concerns. The experimental results demonstrate that the\nproposed attack achieves successful attacks across various commonly used models\nand Google Vision API without any prior knowledge about the target model.\nAdditionally, the average cost of each attack is less than \\$ 1 dollars, posing\na significant threat to AI security.",
      "tldr_zh": "本研究评估了对象检测模型对黑箱对抗攻击的鲁棒性，特别关注延迟攻击（latency attacks），这些攻击通过生成额外的ghost objects来增加推理时间。论文扩展了“steal now, decrypt later”攻击概念，展示了在黑箱场景下生成这些不合格对象的可行性，从而创建adversarial examples来利用AI服务的潜在漏洞。实验结果表明，该攻击方法在多种常用模型和Google Vision API上成功执行，且平均成本不到1美元，强调了对AI安全的重大威胁。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15881v1",
      "published_date": "2024-04-24 13:51:56 UTC",
      "updated_date": "2024-04-24 13:51:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:16:47.428284"
    },
    {
      "arxiv_id": "2404.15869v1",
      "title": "Semantic Routing for Enhanced Performance of LLM-Assisted Intent-Based 5G Core Network Management and Orchestration",
      "title_zh": "语义路由用于提升LLM辅助的基于意图的5G核心网络管理和编排性能",
      "authors": [
        "Dimitrios Michael Manias",
        "Ali Chouman",
        "Abdallah Shami"
      ],
      "abstract": "Large language models (LLMs) are rapidly emerging in Artificial Intelligence\n(AI) applications, especially in the fields of natural language processing and\ngenerative AI. Not limited to text generation applications, these models\ninherently possess the opportunity to leverage prompt engineering, where the\ninputs of such models can be appropriately structured to articulate a model's\npurpose explicitly. A prominent example of this is intent-based networking, an\nemerging approach for automating and maintaining network operations and\nmanagement. This paper presents semantic routing to achieve enhanced\nperformance in LLM-assisted intent-based management and orchestration of 5G\ncore networks. This work establishes an end-to-end intent extraction framework\nand presents a diverse dataset of sample user intents accompanied by a thorough\nanalysis of the effects of encoders and quantization on overall system\nperformance. The results show that using a semantic router improves the\naccuracy and efficiency of the LLM deployment compared to stand-alone LLMs with\nprompting architectures.",
      "tldr_zh": "本研究提出了一种语义路由（semantic routing）方法，以提升大型语言模型（LLMs）在基于意图的5G核心网络管理和编排中的性能。通过建立端到端意图提取框架和提供多样化用户意图数据集，该方法结合了提示工程、编码器和量化分析，优化了LLMs的部署。实验结果显示，与独立LLMs和提示架构相比，语义路由显著提高了系统的准确性和效率，为自动化网络操作提供了更可靠的解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Submitted to IEEE GlobeCom 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15869v1",
      "published_date": "2024-04-24 13:34:20 UTC",
      "updated_date": "2024-04-24 13:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:17:01.225968"
    },
    {
      "arxiv_id": "2404.16080v1",
      "title": "Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Hong-Jun Yoon",
        "Chris Keum",
        "Alexander Witkowski",
        "Joanna Ludzik",
        "Tracy Petrie",
        "Heidi A. Hanson",
        "Sancy A. Leachman"
      ],
      "abstract": "Reflectance Confocal Microscopy (RCM) is a non-invasive imaging technique\nused in biomedical research and clinical dermatology. It provides virtual\nhigh-resolution images of the skin and superficial tissues, reducing the need\nfor physical biopsies. RCM employs a laser light source to illuminate the\ntissue, capturing the reflected light to generate detailed images of\nmicroscopic structures at various depths. Recent studies explored AI and\nmachine learning, particularly CNNs, for analyzing RCM images. Our study\nproposes a segmentation strategy based on textural features to identify\nclinically significant regions, empowering dermatologists in effective image\ninterpretation and boosting diagnostic confidence. This approach promises to\nadvance dermatological diagnosis and treatment.",
      "tldr_zh": "本研究聚焦于Reflectance Confocal Microscopy (RCM)，一种非侵入性成像技术，用于皮肤和浅层组织的虚拟高分辨率图像生成，从而减少物理活检的需求。研究提出了一种基于纹理特征的分割策略，结合AI和机器学习（如CNNs），以识别RCM图像中的临床重要区域，帮助皮肤科医生更有效地解释图像。结果显示，该方法显著提升了诊断信心，并有望推进皮肤病学的诊断和治疗整体水平。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16080v1",
      "published_date": "2024-04-24 13:23:03 UTC",
      "updated_date": "2024-04-24 13:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:17:13.004002"
    },
    {
      "arxiv_id": "2404.15852v1",
      "title": "QOPTLib: a Quantum Computing Oriented Benchmark for Combinatorial Optimization Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Eneko Osaba",
        "Esther Villar-Rodriguez"
      ],
      "abstract": "In this paper, we propose a quantum computing oriented benchmark for\ncombinatorial optimization. This benchmark, coined as QOPTLib, is composed of\n40 instances equally distributed over four well-known problems: Traveling\nSalesman Problem, Vehicle Routing Problem, one-dimensional Bin Packing Problem\nand the Maximum Cut Problem. The sizes of the instances in QOPTLib not only\ncorrespond to computationally addressable sizes, but also to the maximum length\napproachable with non-zero likelihood of getting a good result. In this regard,\nit is important to highlight that hybrid approaches are also taken into\nconsideration. Thus, this benchmark constitutes the first effort to provide\nusers a general-purpose dataset. Also in this paper, we introduce a first full\nsolving of QOPTLib using two solvers based on quantum annealing. Our main\nintention with this is to establish a preliminary baseline, hoping to inspire\nother researchers to beat these outcomes with newly proposed quantum-based\nalgorithms.",
      "tldr_zh": "本研究提出 QOPTLib，这是一个针对组合优化问题的量子计算导向基准库，旨在为研究者提供通用数据集。QOPTLib 包含 40 个实例，平均分布在四个经典问题上：Traveling Salesman Problem、Vehicle Routing Problem、one-dimensional Bin Packing Problem 和 Maximum Cut Problem，这些实例的大小既适合计算处理，又考虑了量子计算的实际限制，包括混合方法。论文使用两个基于 Quantum Annealing 的求解器首次完全解决了 QOPTLib，建立初步基准性能。总体而言，此工作为量子算法的开发提供了参考，并鼓励后续研究超越现有成果。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "quant-ph",
      "comment": "15 pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2404.15852v1",
      "published_date": "2024-04-24 13:02:33 UTC",
      "updated_date": "2024-04-24 13:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:17:24.825138"
    },
    {
      "arxiv_id": "2404.16078v2",
      "title": "Learning World Models With Hierarchical Temporal Abstractions: A Probabilistic Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Vaisakh Shaj"
      ],
      "abstract": "Machines that can replicate human intelligence with type 2 reasoning\ncapabilities should be able to reason at multiple levels of spatio-temporal\nabstractions and scales using internal world models. Devising formalisms to\ndevelop such internal world models, which accurately reflect the causal\nhierarchies inherent in the dynamics of the real world, is a critical research\nchallenge in the domains of artificial intelligence and machine learning. This\nthesis identifies several limitations with the prevalent use of state space\nmodels (SSMs) as internal world models and propose two new probabilistic\nformalisms namely Hidden-Parameter SSMs and Multi-Time Scale SSMs to address\nthese drawbacks. The structure of graphical models in both formalisms\nfacilitates scalable exact probabilistic inference using belief propagation, as\nwell as end-to-end learning via backpropagation through time. This approach\npermits the development of scalable, adaptive hierarchical world models capable\nof representing nonstationary dynamics across multiple temporal abstractions\nand scales. Moreover, these probabilistic formalisms integrate the concept of\nuncertainty in world states, thus improving the system's capacity to emulate\nthe stochastic nature of the real world and quantify the confidence in its\npredictions. The thesis also discuss how these formalisms are in line with\nrelated neuroscience literature on Bayesian brain hypothesis and predicitive\nprocessing. Our experiments on various real and simulated robots demonstrate\nthat our formalisms can match and in many cases exceed the performance of\ncontemporary transformer variants in making long-range future predictions. We\nconclude the thesis by reflecting on the limitations of our current models and\nsuggesting directions for future research.",
      "tldr_zh": "这篇论文从概率视角探讨了构建内部世界模型，以实现机器的多层次时空抽象推理，针对传统状态空间模型(SSMs)的局限性，提出了Hidden-Parameter SSMs和Multi-Time Scale SSMs两种新形式主义。这些形式主义利用图形模型支持可扩展的精确概率推理、端到端学习，并整合不确定性来处理非平稳动态和多时间尺度。实验在真实和模拟机器人上表明，这些模型在长期预测任务中往往优于当代Transformer变体。论文还讨论了这些方法与神经科学文献（如Bayesian brain hypothesis和predictive processing）的关联，并提出了未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Doctoral Dissertation Preprint, Department of Computer Science,\n  Karlsruhe Institute Of Technology, 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.16078v2",
      "published_date": "2024-04-24 12:41:04 UTC",
      "updated_date": "2024-04-26 09:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:17:38.127894"
    },
    {
      "arxiv_id": "2404.15840v3",
      "title": "Constructive Interpolation and Concept-Based Beth Definability for Description Logics via Sequents",
      "title_zh": "翻译失败",
      "authors": [
        "Tim S. Lyon",
        "Jonas Karge"
      ],
      "abstract": "We introduce a constructive method applicable to a large number of\ndescription logics (DLs) for establishing the concept-based Beth definability\nproperty (CBP) based on sequent systems. Using the highly expressive DL RIQ as\na case study, we introduce novel sequent calculi for RIQ-ontologies and show\nhow certain interpolants can be computed from sequent calculus proofs, which\npermit the extraction of explicit definitions of implicitly definable concepts.\nTo the best of our knowledge, this is the first sequent-based approach to\ncomputing interpolants and definitions within the context of DLs, as well as\nthe first proof that RIQ enjoys the CBP. Moreover, due to the modularity of our\nsequent systems, our results hold for restrictions of RIQ, and are applicable\nto other DLs by suitable modifications.",
      "tldr_zh": "该研究引入了一种基于 sequent 系统的构造性方法，适用于多种 Description Logics (DLs)，以建立 Concept-Based Beth Definability (CBP) 属性。该方法通过开发新型 sequent calculi 来处理 DLs 中的 RIQ 本体，并从 sequent calculus proofs 中计算 interpolants，从而提取隐式可定义概念的显式定义。这是首个基于 sequent 的方法，用于 DLs 上下文中计算 interpolants 和定义，并首次证明 RIQ 具有 CBP。此外，该方法的模块性使其适用于 RIQ 的限制版本，并可通过修改扩展到其他 DLs。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.DB",
        "math.LO"
      ],
      "primary_category": "cs.LO",
      "comment": "Accepted to IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15840v3",
      "published_date": "2024-04-24 12:28:27 UTC",
      "updated_date": "2024-10-18 11:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:17:49.169024"
    },
    {
      "arxiv_id": "2404.15823v1",
      "title": "A Configurable and Efficient Memory Hierarchy for Neural Network Hardware Accelerator",
      "title_zh": "一种可配置",
      "authors": [
        "Oliver Bause",
        "Paul Palomero Bernardo",
        "Oliver Bringmann"
      ],
      "abstract": "As machine learning applications continue to evolve, the demand for efficient\nhardware accelerators, specifically tailored for deep neural networks (DNNs),\nbecomes increasingly vital. In this paper, we propose a configurable memory\nhierarchy framework tailored for per layer adaptive memory access patterns of\nDNNs. The hierarchy requests data on-demand from the off-chip memory to provide\nit to the accelerator's compute units. The objective is to strike an optimized\nbalance between minimizing the required memory capacity and maintaining high\naccelerator performance. The framework is characterized by its configurability,\nallowing the creation of a tailored memory hierarchy with up to five levels.\nFurthermore, the framework incorporates an optional shift register as final\nlevel to increase the flexibility of the memory management process. A\ncomprehensive loop-nest analysis of DNN layers shows that the framework can\nefficiently execute the access patterns of most loop unrolls. Synthesis results\nand a case study of the DNN accelerator UltraTrail indicate a possible\nreduction in chip area of up to 62.2% as smaller memory modules can be used. At\nthe same time, the performance loss can be minimized to 2.4%.",
      "tldr_zh": "本论文提出了一种可配置且高效的内存层次框架，针对深度神经网络 (DNNs) 的每层自适应内存访问模式，旨在在最小化内存容量和保持高加速器性能之间实现平衡。该框架通过从 off-chip 内存按需请求数据，支持多达五级内存层次，并可选集成 shift register，以提升内存管理灵活性。对 DNN 层的循环嵌套分析表明，该框架能高效处理大多数访问模式；综合结果显示，与 DNN 加速器 UltraTrail 相比，可减少芯片面积高达 62.2%，同时性能损失仅为 2.4%。这为神经网络硬件加速器设计提供了更优化的解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "accepted at MBMV 2024 - 27. Workshop \"Methoden und\n  Beschreibungssprachen zur Modellierung und Verifikation von Schaltungen und\n  Systemen\"",
      "pdf_url": "http://arxiv.org/pdf/2404.15823v1",
      "published_date": "2024-04-24 11:57:37 UTC",
      "updated_date": "2024-04-24 11:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:18:01.367015"
    },
    {
      "arxiv_id": "2404.15822v1",
      "title": "Recursive Backwards Q-Learning in Deterministic Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Diekhoff",
        "Jörn Fischer"
      ],
      "abstract": "Reinforcement learning is a popular method of finding optimal solutions to\ncomplex problems. Algorithms like Q-learning excel at learning to solve\nstochastic problems without a model of their environment. However, they take\nlonger to solve deterministic problems than is necessary. Q-learning can be\nimproved to better solve deterministic problems by introducing such a\nmodel-based approach. This paper introduces the recursive backwards Q-learning\n(RBQL) agent, which explores and builds a model of the environment. After\nreaching a terminal state, it recursively propagates its value backwards\nthrough this model. This lets each state be evaluated to its optimal value\nwithout a lengthy learning process. In the example of finding the shortest path\nthrough a maze, this agent greatly outperforms a regular Q-learning agent.",
      "tldr_zh": "本文提出了一种名为 Recursive Backwards Q-Learning (RBQL) 的算法，用于在确定性环境中提升强化学习效率。RBQL 代理通过构建环境模型，并在到达终端状态后递归向后传播值，来快速评估每个状态的最优值，从而避免了传统 Q-learning 的冗长学习过程。在迷宫寻路等示例中，RBQL 显著优于标准 Q-learning 代理，提供更快的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15822v1",
      "published_date": "2024-04-24 11:54:53 UTC",
      "updated_date": "2024-04-24 11:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:18:13.271710"
    },
    {
      "arxiv_id": "2404.15814v1",
      "title": "Fast Ensembling with Diffusion Schrödinger Bridge",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunsu Kim",
        "Jongmin Yoon",
        "Juho Lee"
      ],
      "abstract": "Deep Ensemble (DE) approach is a straightforward technique used to enhance\nthe performance of deep neural networks by training them from different initial\npoints, converging towards various local optima. However, a limitation of this\nmethodology lies in its high computational overhead for inference, arising from\nthe necessity to store numerous learned parameters and execute individual\nforward passes for each parameter during the inference stage. We propose a\nnovel approach called Diffusion Bridge Network (DBN) to address this challenge.\nBased on the theory of the Schr\\\"odinger bridge, this method directly learns to\nsimulate an Stochastic Differential Equation (SDE) that connects the output\ndistribution of a single ensemble member to the output distribution of the\nensembled model, allowing us to obtain ensemble prediction without having to\ninvoke forward pass through all the ensemble models. By substituting the heavy\nensembles with this lightweight neural network constructing DBN, we achieved\ninference with reduced computational cost while maintaining accuracy and\nuncertainty scores on benchmark datasets such as CIFAR-10, CIFAR-100, and\nTinyImageNet. Our implementation is available at\nhttps://github.com/kim-hyunsu/dbn.",
      "tldr_zh": "该研究针对 Deep Ensemble (DE) 方法在提升神经网络性能的同时存在的计算开销问题（如存储多个参数和多次前向传递），提出了一种新颖的 Diffusion Bridge Network (DBN) 框架。DBN 基于 Schrödinger bridge 理论，直接学习模拟一个 Stochastic Differential Equation (SDE)，将单个集成成员的输出分布连接到整体集成模型的输出分布，从而无需调用所有模型即可获得集成预测。实验结果显示，该方法在 CIFAR-10、CIFAR-100 和 TinyImageNet 数据集上实现了计算成本的显著降低，同时保持了准确性和不确定性分数。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15814v1",
      "published_date": "2024-04-24 11:35:02 UTC",
      "updated_date": "2024-04-24 11:35:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:18:25.270755"
    },
    {
      "arxiv_id": "2405.12990v1",
      "title": "BERT vs GPT for financial engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Sharkey",
        "Philip Treleaven"
      ],
      "abstract": "The paper benchmarks several Transformer models [4], to show how these models\ncan judge sentiment from a news event. This signal can then be used for\ndownstream modelling and signal identification for commodity trading. We find\nthat fine-tuned BERT models outperform fine-tuned or vanilla GPT models on this\ntask. Transformer models have revolutionized the field of natural language\nprocessing (NLP) in recent years, achieving state-of-the-art results on various\ntasks such as machine translation, text summarization, question answering, and\nnatural language generation. Among the most prominent transformer models are\nBidirectional Encoder Representations from Transformers (BERT) and Generative\nPre-trained Transformer (GPT), which differ in their architectures and\nobjectives.\n  A CopBERT model training data and process overview is provided. The CopBERT\nmodel outperforms similar domain specific BERT trained models such as FinBERT.\nThe below confusion matrices show the performance on CopBERT & CopGPT\nrespectively. We see a ~10 percent increase in f1_score when compare CopBERT vs\nGPT4 and 16 percent increase vs CopGPT. Whilst GPT4 is dominant It highlights\nthe importance of considering alternatives to GPT models for financial\nengineering tasks, given risks of hallucinations, and challenges with\ninterpretability. We unsurprisingly see the larger LLMs outperform the BERT\nmodels, with predictive power. In summary BERT is partially the new XGboost,\nwhat it lacks in predictive power it provides with higher levels of\ninterpretability. Concluding that BERT models might not be the next XGboost\n[2], but represent an interesting alternative for financial engineering tasks,\nthat require a blend of interpretability and accuracy.",
      "tldr_zh": "该论文比较了BERT和GPT模型在金融工程中的性能，特别是用于从新闻事件中判断情感并应用于商品交易建模。研究发现，微调后的BERT模型（如CopBERT）在该任务上优于微调或原版GPT模型，并在F1分数上比GPT4高约10%以及比CopGPT高16%。CopBERT模型通过特定训练数据和过程超越了类似FinBERT等领域特定BERT模型，强调了BERT在可解释性方面的优势，尽管大型LLMs如GPT4在预测能力上更强；总体结论是，BERT提供了一个平衡准确性和解释性的替代方案，适合金融任务的风险管理。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12990v1",
      "published_date": "2024-04-24 11:30:04 UTC",
      "updated_date": "2024-04-24 11:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:18:39.461006"
    },
    {
      "arxiv_id": "2404.15804v1",
      "title": "GeckOpt: LLM System Efficiency via Intent-Based Tool Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Fore",
        "Simranjit Singh",
        "Dimitrios Stamoulis"
      ],
      "abstract": "In this preliminary study, we investigate a GPT-driven intent-based reasoning\napproach to streamline tool selection for large language models (LLMs) aimed at\nsystem efficiency. By identifying the intent behind user prompts at runtime, we\nnarrow down the API toolset required for task execution, reducing token\nconsumption by up to 24.6\\%. Early results on a real-world, massively parallel\nCopilot platform with over 100 GPT-4-Turbo nodes show cost reductions and\npotential towards improving LLM-based system efficiency.",
      "tldr_zh": "该研究提出GeckOpt，一种基于GPT的意图识别推理方法，用于优化LLM系统效率。通过在运行时识别用户提示的意图，系统能缩小所需的API工具集，从而减少token消耗高达24.6%。在包含超过100个GPT-4-Turbo节点的真实Copilot平台上，实验结果显示了显著的成本降低，并为提升LLM系统效率提供了潜在改进方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "GLSVLSI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15804v1",
      "published_date": "2024-04-24 11:03:15 UTC",
      "updated_date": "2024-04-24 11:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:18:49.351041"
    },
    {
      "arxiv_id": "2404.15802v1",
      "title": "Raformer: Redundancy-Aware Transformer for Video Wire Inpainting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhong Ji",
        "Yimu Su",
        "Yan Zhang",
        "Jiacheng Hou",
        "Yanwei Pang",
        "Jungong Han"
      ],
      "abstract": "Video Wire Inpainting (VWI) is a prominent application in video inpainting,\naimed at flawlessly removing wires in films or TV series, offering significant\ntime and labor savings compared to manual frame-by-frame removal. However, wire\nremoval poses greater challenges due to the wires being longer and slimmer than\nobjects typically targeted in general video inpainting tasks, and often\nintersecting with people and background objects irregularly, which adds\ncomplexity to the inpainting process. Recognizing the limitations posed by\nexisting video wire datasets, which are characterized by their small size, poor\nquality, and limited variety of scenes, we introduce a new VWI dataset with a\nnovel mask generation strategy, namely Wire Removal Video Dataset 2 (WRV2) and\nPseudo Wire-Shaped (PWS) Masks. WRV2 dataset comprises over 4,000 videos with\nan average length of 80 frames, designed to facilitate the development and\nefficacy of inpainting models. Building upon this, our research proposes the\nRedundancy-Aware Transformer (Raformer) method that addresses the unique\nchallenges of wire removal in video inpainting. Unlike conventional approaches\nthat indiscriminately process all frame patches, Raformer employs a novel\nstrategy to selectively bypass redundant parts, such as static background\nsegments devoid of valuable information for inpainting. At the core of Raformer\nis the Redundancy-Aware Attention (RAA) module, which isolates and accentuates\nessential content through a coarse-grained, window-based attention mechanism.\nThis is complemented by a Soft Feature Alignment (SFA) module, which refines\nthese features and achieves end-to-end feature alignment. Extensive experiments\non both the traditional video inpainting datasets and our proposed WRV2 dataset\ndemonstrate that Raformer outperforms other state-of-the-art methods.",
      "tldr_zh": "该研究针对 Video Wire Inpainting (VWI) 的挑战，提出了一种 Redundancy-Aware Transformer (Raformer) 方法，用于高效去除视频中的电线，同时避免处理冗余部分如静态背景。论文引入了新的数据集 WRV2 和 Pseudo Wire-Shaped (PWS) Masks，包含超过4000个平均80帧的视频，以解决现有数据集规模小和场景多样性不足的问题。Raformer 的核心组件包括 Redundancy-Aware Attention (RAA) 模块的粗粒度窗口注意机制和 Soft Feature Alignment (SFA) 模块的端到端特征对齐，在传统视频修复数据集和 WRV2 上，Raformer 表现优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15802v1",
      "published_date": "2024-04-24 11:02:13 UTC",
      "updated_date": "2024-04-24 11:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:19:02.104708"
    },
    {
      "arxiv_id": "2404.15794v2",
      "title": "Large Language Models as In-context AI Generators for Quality-Diversity",
      "title_zh": "翻译失败",
      "authors": [
        "Bryan Lim",
        "Manon Flageat",
        "Antoine Cully"
      ],
      "abstract": "Quality-Diversity (QD) approaches are a promising direction to develop\nopen-ended processes as they can discover archives of high-quality solutions\nacross diverse niches. While already successful in many applications, QD\napproaches usually rely on combining only one or two solutions to generate new\ncandidate solutions. As observed in open-ended processes such as technological\nevolution, wisely combining large diversity of these solutions could lead to\nmore innovative solutions and potentially boost the productivity of QD search.\nIn this work, we propose to exploit the pattern-matching capabilities of\ngenerative models to enable such efficient solution combinations. We introduce\nIn-context QD, a framework of techniques that aim to elicit the in-context\ncapabilities of pre-trained Large Language Models (LLMs) to generate\ninteresting solutions using few-shot and many-shot prompting with\nquality-diverse examples from the QD archive as context. Applied to a series of\ncommon QD domains, In-context QD displays promising results compared to both QD\nbaselines and similar strategies developed for single-objective optimization.\nAdditionally, this result holds across multiple values of parameter sizes and\narchive population sizes, as well as across domains with distinct\ncharacteristics from BBO functions to policy search. Finally, we perform an\nextensive ablation that highlights the key prompt design considerations that\nencourage the generation of promising solutions for QD.",
      "tldr_zh": "本研究提出 In-context QD 框架，利用预训练 Large Language Models (LLMs) 的 in-context 学习能力，通过 few-shot 和 many-shot prompting，以 Quality-Diversity (QD) 档案中的高质量多样示例作为上下文，生成创新的候选解决方案，从而超越传统 QD 方法仅结合一两个解决方案的局限。实验结果显示，在多个 QD 领域（如 BBO 函数和策略搜索）中，In-context QD 相较于 QD 基线和单目标优化策略表现出色，且在不同参数大小、档案规模和领域特性下保持稳健性能。该框架还通过广泛的消融实验突出了提示设计的关键因素，有望提升 QD 搜索的生产力和创新性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15794v2",
      "published_date": "2024-04-24 10:35:36 UTC",
      "updated_date": "2024-06-05 07:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:19:14.633010"
    },
    {
      "arxiv_id": "2404.15781v1",
      "title": "Real-Time Compressed Sensing for Joint Hyperspectral Image Transmission and Restoration for CubeSat",
      "title_zh": "CubeSat 的实时压缩感知用于联合超光谱图像传输和恢复",
      "authors": [
        "Chih-Chung Hsu",
        "Chih-Yu Jian",
        "Eng-Shen Tu",
        "Chia-Ming Lee",
        "Guan-Lin Chen"
      ],
      "abstract": "This paper addresses the challenges associated with hyperspectral image (HSI)\nreconstruction from miniaturized satellites, which often suffer from stripe\neffects and are computationally resource-limited. We propose a Real-Time\nCompressed Sensing (RTCS) network designed to be lightweight and require only\nrelatively few training samples for efficient and robust HSI reconstruction in\nthe presence of the stripe effect and under noisy transmission conditions. The\nRTCS network features a simplified architecture that reduces the required\ntraining samples and allows for easy implementation on integer-8-based\nencoders, facilitating rapid compressed sensing for stripe-like HSI, which\nexactly matches the moderate design of miniaturized satellites on push broom\nscanning mechanism. This contrasts optimization-based models that demand\nhigh-precision floating-point operations, making them difficult to deploy on\nedge devices. Our encoder employs an integer-8-compatible linear projection for\nstripe-like HSI data transmission, ensuring real-time compressed sensing.\nFurthermore, based on the novel two-streamed architecture, an efficient HSI\nrestoration decoder is proposed for the receiver side, allowing for edge-device\nreconstruction without needing a sophisticated central server. This is\nparticularly crucial as an increasing number of miniaturized satellites\nnecessitates significant computing resources on the ground station. Extensive\nexperiments validate the superior performance of our approach, offering new and\nvital capabilities for existing miniaturized satellite systems.",
      "tldr_zh": "本文针对CubeSat微型卫星的高光谱图像(HSI)重建问题，提出Real-Time Compressed Sensing (RTCS)网络，以解决条纹效应和计算资源限制。该网络采用轻量级架构和整数-8兼容编码器，实现实时压缩感知和HSI数据传输，同时基于新型两流架构的解码器，在接收端边缘设备上进行高效重建，而无需复杂的中央服务器。相比传统优化模型，RTCS显著减少了训练样本需求和浮点运算依赖，使其更适合部署在资源有限的环境中。实验结果显示，该方法在HSI重建性能上优于基线模型，为微型卫星系统提供了新的实时传输和恢复能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TGRS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15781v1",
      "published_date": "2024-04-24 10:03:37 UTC",
      "updated_date": "2024-04-24 10:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:19:29.083906"
    },
    {
      "arxiv_id": "2404.15774v1",
      "title": "Toward Physics-Aware Deep Learning Architectures for LiDAR Intensity Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Vivek Anand",
        "Bharat Lohani",
        "Gaurav Pandey",
        "Rakesh Mishra"
      ],
      "abstract": "Autonomous vehicles (AVs) heavily rely on LiDAR perception for environment\nunderstanding and navigation. LiDAR intensity provides valuable information\nabout the reflected laser signals and plays a crucial role in enhancing the\nperception capabilities of AVs. However, accurately simulating LiDAR intensity\nremains a challenge due to the unavailability of material properties of the\nobjects in the environment, and complex interactions between the laser beam and\nthe environment. The proposed method aims to improve the accuracy of intensity\nsimulation by incorporating physics-based modalities within the deep learning\nframework. One of the key entities that captures the interaction between the\nlaser beam and the objects is the angle of incidence. In this work we\ndemonstrate that the addition of the LiDAR incidence angle as a separate input\nto the deep neural networks significantly enhances the results. We present a\ncomparative study between two prominent deep learning architectures: U-NET a\nConvolutional Neural Network (CNN), and Pix2Pix a Generative Adversarial\nNetwork (GAN). We implemented these two architectures for the intensity\nprediction task and used SemanticKITTI and VoxelScape datasets for experiments.\nThe comparative analysis reveals that both architectures benefit from the\nincidence angle as an additional input. Moreover, the Pix2Pix architecture\noutperforms U-NET, especially when the incidence angle is incorporated.",
      "tldr_zh": "该研究针对自动驾驶车辆（AVs）中 LiDAR 强度模拟的挑战，提出了一种整合物理感知的深度学习框架，以解决物体材料属性缺失和激光束环境交互的复杂性问题。具体而言，通过将入射角（angle of incidence）作为深度神经网络的额外输入，显著提升了模拟精度。实验比较了 U-NET（CNN）和 Pix2Pix（GAN）两种架构，使用 SemanticKITTI 和 VoxelScape 数据集，结果显示 Pix2Pix 在加入入射角后表现出色，整体性能优于 U-NET。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.15774v1",
      "published_date": "2024-04-24 09:52:36 UTC",
      "updated_date": "2024-04-24 09:52:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:19:39.023991"
    },
    {
      "arxiv_id": "2404.15766v2",
      "title": "Unifying Bayesian Flow Networks and Diffusion Models through Stochastic Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiwen Xue",
        "Yuhao Zhou",
        "Shen Nie",
        "Xu Min",
        "Xiaolu Zhang",
        "Jun Zhou",
        "Chongxuan Li"
      ],
      "abstract": "Bayesian flow networks (BFNs) iteratively refine the parameters, instead of\nthe samples in diffusion models (DMs), of distributions at various noise levels\nthrough Bayesian inference. Owing to its differentiable nature, BFNs are\npromising in modeling both continuous and discrete data, while simultaneously\nmaintaining fast sampling capabilities. This paper aims to understand and\nenhance BFNs by connecting them with DMs through stochastic differential\nequations (SDEs). We identify the linear SDEs corresponding to the\nnoise-addition processes in BFNs, demonstrate that BFN's regression losses are\naligned with denoise score matching, and validate the sampler in BFN as a\nfirst-order solver for the respective reverse-time SDE. Based on these findings\nand existing recipes of fast sampling in DMs, we propose specialized solvers\nfor BFNs that markedly surpass the original BFN sampler in terms of sample\nquality with a limited number of function evaluations (e.g., 10) on both image\nand text datasets. Notably, our best sampler achieves an increase in speed of\n5~20 times for free. Our code is available at\nhttps://github.com/ML-GSAI/BFN-Solver.",
      "tldr_zh": "本论文通过随机微分方程 (SDEs) 将 Bayesian flow networks (BFNs) 和 diffusion models (DMs) 统一起来，识别了 BFNs 中噪声添加过程对应的线性 SDEs，并证明了 BFN 的回归损失与去噪分数匹配一致。研究者验证了 BFN 的采样器作为相应逆时间 SDE 的一阶求解器，并基于 DMs 的快速采样方法提出改进的专用求解器。这些求解器在图像和文本数据集上显著提升了采样质量，并在有限的函数评估次数（如10次）下实现了5-20倍的速度提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15766v2",
      "published_date": "2024-04-24 09:39:06 UTC",
      "updated_date": "2024-06-02 13:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:19:51.656978"
    },
    {
      "arxiv_id": "2404.15760v1",
      "title": "Debiasing Machine Unlearning with Counterfactual Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Ziheng Chen",
        "Jia Wang",
        "Jun Zhuang",
        "Abbavaram Gowtham Reddy",
        "Fabrizio Silvestri",
        "Jin Huang",
        "Kaushiki Nag",
        "Kun Kuang",
        "Xin Ning",
        "Gabriele Tolomei"
      ],
      "abstract": "The right to be forgotten (RTBF) seeks to safeguard individuals from the\nenduring effects of their historical actions by implementing machine-learning\ntechniques. These techniques facilitate the deletion of previously acquired\nknowledge without requiring extensive model retraining. However, they often\noverlook a critical issue: unlearning processes bias. This bias emerges from\ntwo main sources: (1) data-level bias, characterized by uneven data removal,\nand (2) algorithm-level bias, which leads to the contamination of the remaining\ndataset, thereby degrading model accuracy. In this work, we analyze the causal\nfactors behind the unlearning process and mitigate biases at both data and\nalgorithmic levels. Typically, we introduce an intervention-based approach,\nwhere knowledge to forget is erased with a debiased dataset. Besides, we guide\nthe forgetting procedure by leveraging counterfactual examples, as they\nmaintain semantic data consistency without hurting performance on the remaining\ndataset. Experimental results demonstrate that our method outperforms existing\nmachine unlearning baselines on evaluation metrics.",
      "tldr_zh": "该论文探讨了机器遗忘（machine unlearning）过程中的偏置问题，包括数据级偏置（如不均匀数据删除）和算法级偏置（如污染剩余数据集导致模型准确性下降），并分析了其因果因素。研究提出一种基于干预的方法，使用去偏置数据集擦除需要遗忘的知识，同时通过反事实例子（counterfactual examples）指导遗忘过程，以保持语义一致性而不损害剩余数据集的性能。实验结果表明，该方法在评估指标上优于现有机器遗忘基线，为实现更可靠的“被遗忘权”（RTBF）提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15760v1",
      "published_date": "2024-04-24 09:33:10 UTC",
      "updated_date": "2024-04-24 09:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:20:02.176005"
    },
    {
      "arxiv_id": "2404.15758v1",
      "title": "Let's Think Dot by Dot: Hidden Computation in Transformer Language Models",
      "title_zh": "逐点思考：Transformer 语言模型中的隐藏计算",
      "authors": [
        "Jacob Pfau",
        "William Merrill",
        "Samuel R. Bowman"
      ],
      "abstract": "Chain-of-thought responses from language models improve performance across\nmost benchmarks. However, it remains unclear to what extent these performance\ngains can be attributed to human-like task decomposition or simply the greater\ncomputation that additional tokens allow. We show that transformers can use\nmeaningless filler tokens (e.g., '......') in place of a chain of thought to\nsolve two hard algorithmic tasks they could not solve when responding without\nintermediate tokens. However, we find empirically that learning to use filler\ntokens is difficult and requires specific, dense supervision to converge. We\nalso provide a theoretical characterization of the class of problems where\nfiller tokens are useful in terms of the quantifier depth of a first-order\nformula. For problems satisfying this characterization, chain-of-thought tokens\nneed not provide information about the intermediate computational steps\ninvolved in multi-token computations. In summary, our results show that\nadditional tokens can provide computational benefits independent of token\nchoice. The fact that intermediate tokens can act as filler tokens raises\nconcerns about large language models engaging in unauditable, hidden\ncomputations that are increasingly detached from the observed chain-of-thought\ntokens.",
      "tldr_zh": "本研究探究了Transformer语言模型中Chain-of-Thought（CoT）响应的性能提升是否源于任务分解或额外token的计算优势。实验发现，模型可以使用无意义的filler tokens（如“......”）来解决原本无法处理的算法任务，但这需要特定的密集监督才能实现。理论上，研究通过一阶逻辑量化器深度表征了此类问题的特性，表明额外token可提供独立计算益处，而非必须提供中间步骤信息；这也引发了对语言模型进行不可审计的隐藏计算的担忧。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.15758v1",
      "published_date": "2024-04-24 09:30:00 UTC",
      "updated_date": "2024-04-24 09:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:20:14.030607"
    },
    {
      "arxiv_id": "2405.00055v2",
      "title": "A Hybrid Probabilistic Battery Health Management Approach for Robust Inspection Drone Operations",
      "title_zh": "一种混合概率电池",
      "authors": [
        "Jokin Alcibar",
        "Jose I. Aizpurua",
        "Ekhi Zugastia",
        "Oier Penagarikano"
      ],
      "abstract": "Health monitoring of remote critical infrastructure is a complex and\nexpensive activity due to the limited infrastructure accessibility. Inspection\ndrones are ubiquitous assets that enhance the reliability of critical\ninfrastructures through improved accessibility. However, due to the harsh\noperation environment, it is crucial to monitor their health to ensure\nsuccessful inspection operations. The battery is a key component that\ndetermines the overall reliability of the inspection drones and, with an\nappropriate health management approach, contributes to reliable and robust\ninspections. In this context, this paper presents a novel hybrid probabilistic\napproach for battery end-of-discharge (EOD) voltage prediction of Li-Po\nbatteries. The hybridization is achieved in an error-correction configuration,\nwhich combines physics-based discharge and probabilistic error-correction\nmodels to quantify the aleatoric and epistemic uncertainty. The performance of\nthe hybrid probabilistic methodology was empirically evaluated on a dataset\ncomprising EOD voltage under varying load conditions. The dataset was obtained\nfrom real inspection drones operated on different flights, focused on offshore\nwind turbine inspections. The proposed approach has been tested with different\nprobabilistic methods and demonstrates 14.8% improved performance in\nprobabilistic accuracy compared to the best probabilistic method. In addition,\naleatoric and epistemic uncertainties provide robust estimations to enhance the\ndiagnosis of battery health-states.",
      "tldr_zh": "该论文提出了一种混合概率方法，用于管理检查无人机的电池健康，以提升其在恶劣环境下的可靠性和鲁棒性。方法通过错误修正配置结合基于物理的放电模型和概率错误修正模型，量化 aleatoric 和 epistemic uncertainty，从而准确预测 Li-Po batteries 的端电压 (EOD voltage)。实验基于真实数据集（来自海上风力涡轮机检查飞行），显示该方法比最佳概率方法提高了14.8%的 probabilistic accuracy，并提供稳健的估计以增强电池健康状态诊断。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00055v2",
      "published_date": "2024-04-24 09:22:18 UTC",
      "updated_date": "2024-12-20 12:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:20:25.614730"
    },
    {
      "arxiv_id": "2404.15751v1",
      "title": "Guided-SPSA: Simultaneous Perturbation Stochastic Approximation assisted by the Parameter Shift Rule",
      "title_zh": "Guided-SPSA：参数移位规则辅助下的同时扰动随机逼近",
      "authors": [
        "Maniraman Periyasamy",
        "Axel Plinge",
        "Christopher Mutschler",
        "Daniel D. Scherer",
        "Wolfgang Mauerer"
      ],
      "abstract": "The study of variational quantum algorithms (VQCs) has received significant\nattention from the quantum computing community in recent years. These hybrid\nalgorithms, utilizing both classical and quantum components, are well-suited\nfor noisy intermediate-scale quantum devices. Though estimating exact gradients\nusing the parameter-shift rule to optimize the VQCs is realizable in NISQ\ndevices, they do not scale well for larger problem sizes. The computational\ncomplexity, in terms of the number of circuit evaluations required for gradient\nestimation by the parameter-shift rule, scales linearly with the number of\nparameters in VQCs. On the other hand, techniques that approximate the\ngradients of the VQCs, such as the simultaneous perturbation stochastic\napproximation (SPSA), do not scale with the number of parameters but struggle\nwith instability and often attain suboptimal solutions. In this work, we\nintroduce a novel gradient estimation approach called Guided-SPSA, which\nmeaningfully combines the parameter-shift rule and SPSA-based gradient\napproximation. The Guided-SPSA results in a 15% to 25% reduction in the number\nof circuit evaluations required during training for a similar or better\noptimality of the solution found compared to the parameter-shift rule. The\nGuided-SPSA outperforms standard SPSA in all scenarios and outperforms the\nparameter-shift rule in scenarios such as suboptimal initialization of the\nparameters. We demonstrate numerically the performance of Guided-SPSA on\ndifferent paradigms of quantum machine learning, such as regression,\nclassification, and reinforcement learning.",
      "tldr_zh": "本研究针对变分量子算法 (VQCs) 的梯度估计问题，提出了一种新方法 Guided-SPSA，将参数转移规则 (parameter-shift rule) 与同时扰动随机逼近 (SPSA) 相结合，以减少计算复杂性和提高稳定性。Guided-SPSA 在训练过程中降低了 15% 到 25% 的电路评估次数，同时实现了与参数转移规则相当或更好的优化结果，尤其在参数初始化不佳时表现出色。实验结果显示，该方法在量子机器学习的不同范式中，如回归、分类和强化学习，均优于标准 SPSA，并为大规模量子优化提供了更高效的解决方案。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2404.15751v1",
      "published_date": "2024-04-24 09:13:39 UTC",
      "updated_date": "2024-04-24 09:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:20:38.501184"
    },
    {
      "arxiv_id": "2404.16890v1",
      "title": "NEPENTHE: Entropy-Based Pruning as a Neural Network Depth's Reducer",
      "title_zh": "翻译失败",
      "authors": [
        "Zhu Liao",
        "Victor Quétu",
        "Van-Tam Nguyen",
        "Enzo Tartaglione"
      ],
      "abstract": "While deep neural networks are highly effective at solving complex tasks,\ntheir computational demands can hinder their usefulness in real-time\napplications and with limited-resources systems. Besides, for many tasks it is\nknown that these models are over-parametrized: neoteric works have broadly\nfocused on reducing the width of these networks, rather than their depth. In\nthis paper, we aim to reduce the depth of over-parametrized deep neural\nnetworks: we propose an eNtropy-basEd Pruning as a nEural Network depTH's\nrEducer (NEPENTHE) to alleviate deep neural networks' computational burden.\nBased on our theoretical finding, NEPENTHE focuses on un-structurally pruning\nconnections in layers with low entropy to remove them entirely. We validate our\napproach on popular architectures such as MobileNet and Swin-T, showing that\nwhen encountering an over-parametrization regime, it can effectively linearize\nsome layers (hence reducing the model's depth) with little to no performance\nloss. The code will be publicly available upon acceptance of the article.",
      "tldr_zh": "本研究针对深度神经网络（deep neural networks）的计算开销问题，提出了一种基于熵的剪枝方法NEPENTHE，以减少网络深度而非宽度。NEPENTHE通过理论分析，聚焦于低熵层的无结构剪枝（un-structurally pruning），从而移除某些层并线性化模型。实验在MobileNet和Swin-T等架构上验证了其有效性，在过度参数化（over-parametrized）场景下，能显著降低深度，几乎不损失性能，为资源受限的实时应用提供高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16890v1",
      "published_date": "2024-04-24 09:12:04 UTC",
      "updated_date": "2024-04-24 09:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:20:50.171748"
    },
    {
      "arxiv_id": "2404.15744v2",
      "title": "A General Black-box Adversarial Attack on Graph-based Fake News Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Peican Zhu",
        "Zechen Pan",
        "Yang Liu",
        "Jiwei Tian",
        "Keke Tang",
        "Zhen Wang"
      ],
      "abstract": "Graph Neural Network (GNN)-based fake news detectors apply various methods to\nconstruct graphs, aiming to learn distinctive news embeddings for\nclassification. Since the construction details are unknown for attackers in a\nblack-box scenario, it is unrealistic to conduct the classical adversarial\nattacks that require a specific adjacency matrix. In this paper, we propose the\nfirst general black-box adversarial attack framework, i.e., General Attack via\nFake Social Interaction (GAFSI), against detectors based on different graph\nstructures. Specifically, as sharing is an important social interaction for\nGNN-based fake news detectors to construct the graph, we simulate sharing\nbehaviors to fool the detectors. Firstly, we propose a fraudster selection\nmodule to select engaged users leveraging local and global information. In\naddition, a post injection module guides the selected users to create shared\nrelations by sending posts. The sharing records will be added to the social\ncontext, leading to a general attack against different detectors. Experimental\nresults on empirical datasets demonstrate the effectiveness of GAFSI.",
      "tldr_zh": "该论文提出了一种通用黑箱对抗攻击框架 GAFSI，用于攻击基于 Graph Neural Network (GNN) 的假新闻检测器。该框架通过模拟分享行为（sharing behaviors）来欺骗检测器，包括 fraudster selection module 来选择参与用户，以及 post injection module 来引导用户创建虚假共享关系，从而在不同图结构下实现攻击。实验结果在实证数据集上证明了 GAFSI 的有效性，为评估和提升假新闻检测器的鲁棒性提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15744v2",
      "published_date": "2024-04-24 09:04:05 UTC",
      "updated_date": "2024-04-26 01:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:21:02.293721"
    },
    {
      "arxiv_id": "2404.15736v2",
      "title": "What Makes Multimodal In-Context Learning Work?",
      "title_zh": "翻译失败",
      "authors": [
        "Folco Bertini Baldassini",
        "Mustafa Shukor",
        "Matthieu Cord",
        "Laure Soulier",
        "Benjamin Piwowarski"
      ],
      "abstract": "Large Language Models have demonstrated remarkable performance across various\ntasks, exhibiting the capacity to swiftly acquire new skills, such as through\nIn-Context Learning (ICL) with minimal demonstration examples. In this work, we\npresent a comprehensive framework for investigating Multimodal ICL (M-ICL) in\nthe context of Large Multimodal Models. We consider the best open-source\nmultimodal models (e.g., IDEFICS, OpenFlamingo) and a wide range of multimodal\ntasks. Our study unveils several noteworthy findings: (1) M-ICL primarily\nrelies on text-driven mechanisms, showing little to no influence from the image\nmodality. (2) When used with advanced-ICL strategy (like RICES), M-ICL is not\nbetter than a simple strategy based on majority voting over context examples.\nMoreover, we identify several biases and limitations of M-ICL that warrant\nconsideration prior to deployment. Code available at\nhttps://gitlab.com/folbaeni/multimodal-icl",
      "tldr_zh": "该研究提出一个全面框架，调查 Multimodal In-Context Learning (M-ICL) 在 Large Multimodal Models 中的工作机制，使用开源模型如 IDEFICS 和 OpenFlamingo 进行多模态任务实验。结果发现，M-ICL 主要依赖文本驱动机制，图像模态的影响几乎可以忽略不计。相比高级 ICL 策略如 RICES，M-ICL 的性能并不优于简单的多数投票策略。此外，研究还指出了 M-ICL 的偏见和限制，强调在实际部署前需加以考虑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 16 figures. Accepted to CVPR 2024 Workshop on Prompting in\n  Vision. Project page: https://folbaeni.gitlab.io/multimodal-icl",
      "pdf_url": "http://arxiv.org/pdf/2404.15736v2",
      "published_date": "2024-04-24 08:50:45 UTC",
      "updated_date": "2024-04-25 06:04:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:21:16.292829"
    },
    {
      "arxiv_id": "2404.15721v2",
      "title": "SPARO: Selective Attention for Robust and Compositional Transformer Encodings for Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Ankit Vani",
        "Bac Nguyen",
        "Samuel Lavoie",
        "Ranjay Krishna",
        "Aaron Courville"
      ],
      "abstract": "Selective attention helps us focus on task-relevant aspects in the constant\nflood of our sensory input. This constraint in our perception allows us to\nrobustly generalize under distractions and to new compositions of perceivable\nconcepts. Transformers employ a similar notion of attention in their\narchitecture, but representation learning models with transformer backbones\nlike CLIP and DINO often fail to demonstrate robustness and compositionality.\nWe highlight a missing architectural prior: unlike human perception,\ntransformer encodings do not separately attend over individual concepts. In\nresponse, we propose SPARO, a read-out mechanism that partitions encodings into\nseparately-attended slots, each produced by a single attention head. Using\nSPARO with CLIP imparts an inductive bias that the vision and text modalities\nare different views of a shared compositional world with the same corresponding\nconcepts. Using SPARO, we demonstrate improvements on downstream recognition,\nrobustness, retrieval, and compositionality benchmarks with CLIP (up to +14%\nfor ImageNet, +4% for SugarCrepe), and on nearest neighbors and linear probe\nfor ImageNet with DINO (+3% each). We also showcase a powerful ability to\nintervene and select individual SPARO concepts to further improve downstream\ntask performance (up from +4% to +9% for SugarCrepe) and use this ability to\nstudy the robustness of SPARO's representation structure. Finally, we provide\ninsights through ablation experiments and visualization of learned concepts.",
      "tldr_zh": "这篇论文指出，Transformer模型如CLIP和DINO在视觉任务中缺乏鲁棒性和组合性，主要因为其编码机制未单独关注个体概念。作者提出SPARO机制，一种读取机制将编码分区成单独的注意力槽位，每个由单一注意力头生成，从而为视觉和文本模态引入归纳偏差，使其视为共享组合世界的不同视图。实验结果显示，SPARO显著提升了下游任务性能，包括ImageNet识别准确率提高14%、SugarCrepe鲁棒性提升4%，以及DINO的最近邻和线性探针各提高3%。此外，SPARO允许干预和选择特定概念，进一步优化任务表现（如SugarCrepe从+4%提升至+9%），并通过消融实验和可视化分析揭示了表示结构的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Conference paper at ECCV 2024. 11 pages main, 23 pages total\n  including references and appendix",
      "pdf_url": "http://arxiv.org/pdf/2404.15721v2",
      "published_date": "2024-04-24 08:15:36 UTC",
      "updated_date": "2024-09-14 05:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:21:27.566898"
    },
    {
      "arxiv_id": "2404.15719v2",
      "title": "HDBN: A Novel Hybrid Dual-branch Network for Robust Skeleton-based Action Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jinfu Liu",
        "Baiqiao Yin",
        "Jiaying Lin",
        "Jiajun Wen",
        "Yue Li",
        "Mengyuan Liu"
      ],
      "abstract": "Skeleton-based action recognition has gained considerable traction thanks to\nits utilization of succinct and robust skeletal representations. Nonetheless,\ncurrent methodologies often lean towards utilizing a solitary backbone to model\nskeleton modality, which can be limited by inherent flaws in the network\nbackbone. To address this and fully leverage the complementary characteristics\nof various network architectures, we propose a novel Hybrid Dual-Branch Network\n(HDBN) for robust skeleton-based action recognition, which benefits from the\ngraph convolutional network's proficiency in handling graph-structured data and\nthe powerful modeling capabilities of Transformers for global information. In\ndetail, our proposed HDBN is divided into two trunk branches: MixGCN and\nMixFormer. The two branches utilize GCNs and Transformers to model both 2D and\n3D skeletal modalities respectively. Our proposed HDBN emerged as one of the\ntop solutions in the Multi-Modal Video Reasoning and Analyzing Competition\n(MMVRAC) of 2024 ICME Grand Challenge, achieving accuracies of 47.95% and\n75.36% on two benchmarks of the UAV-Human dataset by outperforming most\nexisting methods. Our code will be publicly available at:\nhttps://github.com/liujf69/ICMEW2024-Track10.",
      "tldr_zh": "该研究针对基于骨骼的动作识别问题，提出了一种新型混合双分支网络 HDBN，以克服单一骨干网络的局限性。HDBN 包括 MixGCN 和 MixFormer 两个分支，分别利用 GCN 处理图结构数据和 Transformer 建模全局信息，从而对 2D 和 3D 骨骼模态进行互补建模。在 2024 ICME Grand Challenge 的 MMVRAC 比赛中，HDBN 在 UAV-Human 数据集上实现了 47.95% 和 75.36% 的准确率，优于大多数现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15719v2",
      "published_date": "2024-04-24 08:11:50 UTC",
      "updated_date": "2024-04-25 08:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:21:39.953253"
    },
    {
      "arxiv_id": "2404.15714v1",
      "title": "Ada-DF: An Adaptive Label Distribution Fusion Network For Facial Expression Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Shu Liu",
        "Yan Xu",
        "Tongming Wan",
        "Xiaoyan Kui"
      ],
      "abstract": "Facial expression recognition (FER) plays a significant role in our daily\nlife. However, annotation ambiguity in the datasets could greatly hinder the\nperformance. In this paper, we address FER task via label distribution learning\nparadigm, and develop a dual-branch Adaptive Distribution Fusion (Ada-DF)\nframework. One auxiliary branch is constructed to obtain the label\ndistributions of samples. The class distributions of emotions are then computed\nthrough the label distributions of each emotion. Finally, those two\ndistributions are adaptively fused according to the attention weights to train\nthe target branch. Extensive experiments are conducted on three real-world\ndatasets, RAF-DB, AffectNet and SFEW, where our Ada-DF shows advantages over\nthe state-of-the-art works.",
      "tldr_zh": "该论文针对面部表情识别 (FER) 中的标注模糊问题，提出了一种自适应标签分布融合网络 (Ada-DF)，基于标签分布学习范式构建双分支框架。辅助分支用于获取样本的标签分布，并计算每个情感的类分布，随后通过注意力权重自适应融合这些分布来训练目标分支。在 RAF-DB、AffectNet 和 SFEW 等真实数据集上的广泛实验显示，Ada-DF 优于现有最先进的方法，提高了 FER 的整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15714v1",
      "published_date": "2024-04-24 08:07:16 UTC",
      "updated_date": "2024-04-24 08:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:21:50.127043"
    },
    {
      "arxiv_id": "2404.15704v1",
      "title": "Efficient Multi-Model Fusion with Adversarial Complementary Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zuheng Kang",
        "Yayun He",
        "Jianzong Wang",
        "Junqing Peng",
        "Jing Xiao"
      ],
      "abstract": "Single-model systems often suffer from deficiencies in tasks such as speaker\nverification (SV) and image classification, relying heavily on partial prior\nknowledge during decision-making, resulting in suboptimal performance. Although\nmulti-model fusion (MMF) can mitigate some of these issues, redundancy in\nlearned representations may limits improvements. To this end, we propose an\nadversarial complementary representation learning (ACoRL) framework that\nenables newly trained models to avoid previously acquired knowledge, allowing\neach individual component model to learn maximally distinct, complementary\nrepresentations. We make three detailed explanations of why this works and\nexperimental results demonstrate that our method more efficiently improves\nperformance compared to traditional MMF. Furthermore, attribution analysis\nvalidates the model trained under ACoRL acquires more complementary knowledge,\nhighlighting the efficacy of our approach in enhancing efficiency and\nrobustness across tasks.",
      "tldr_zh": "该研究针对单模型系统在说话者验证(SV)和图像分类等任务中的性能不足问题，提出了一种对抗性互补表示学习(Adversarial Complementary Representation Learning, ACoRL)框架，以避免多模型融合(Multi-Model Fusion, MMF)中的表示冗余。ACoRL 通过对抗性训练让新模型避开先前知识，从而使每个组件模型学习最大程度不同的互补表示，并详细解释了其有效性。实验结果表明，该方法比传统 MMF 更高效地提升性能，且归因分析(attribution analysis)验证了模型获得了更多互补知识，提高了整体效率和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 2024 International Joint Conference on Neural\n  Networks (IJCNN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.15704v1",
      "published_date": "2024-04-24 07:47:55 UTC",
      "updated_date": "2024-04-24 07:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:22:03.422224"
    },
    {
      "arxiv_id": "2404.15697v1",
      "title": "DeepFeatureX Net: Deep Features eXtractors based Network for discriminating synthetic from real images",
      "title_zh": "翻译失败",
      "authors": [
        "Orazio Pontorno",
        "Luca Guarnera",
        "Sebastiano Battiato"
      ],
      "abstract": "Deepfakes, synthetic images generated by deep learning algorithms, represent\none of the biggest challenges in the field of Digital Forensics. The scientific\ncommunity is working to develop approaches that can discriminate the origin of\ndigital images (real or AI-generated). However, these methodologies face the\nchallenge of generalization, that is, the ability to discern the nature of an\nimage even if it is generated by an architecture not seen during training. This\nusually leads to a drop in performance. In this context, we propose a novel\napproach based on three blocks called Base Models, each of which is responsible\nfor extracting the discriminative features of a specific image class (Diffusion\nModel-generated, GAN-generated, or real) as it is trained by exploiting\ndeliberately unbalanced datasets. The features extracted from each block are\nthen concatenated and processed to discriminate the origin of the input image.\nExperimental results showed that this approach not only demonstrates good\nrobust capabilities to JPEG compression but also outperforms state-of-the-art\nmethods in several generalization tests. Code, models and dataset are available\nat https://github.com/opontorno/block-based_deepfake-detection.",
      "tldr_zh": "本文提出DeepFeatureX Net，一种基于深度特征提取器的网络，用于区分真实图像和AI生成的合成图像（Deepfakes），以解决现有方法在泛化能力上的不足。该网络由三个Base Models组成，每个模型针对特定图像类别（如Diffusion Model-generated、GAN-generated或真实图像）提取判别特征，并利用不平衡数据集进行训练，提取的特征随后被连接并处理以判断图像来源。实验结果表明，该方法对JPEG compression具有良好鲁棒性，并在多个泛化测试中优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15697v1",
      "published_date": "2024-04-24 07:25:36 UTC",
      "updated_date": "2024-04-24 07:25:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:22:14.627309"
    },
    {
      "arxiv_id": "2404.15687v2",
      "title": "Graph Neural Networks for Vulnerability Detection: A Counterfactual Explanation",
      "title_zh": "图神经网络用于漏洞检测：反事实解释",
      "authors": [
        "Zhaoyang Chu",
        "Yao Wan",
        "Qian Li",
        "Yang Wu",
        "Hongyu Zhang",
        "Yulei Sui",
        "Guandong Xu",
        "Hai Jin"
      ],
      "abstract": "Vulnerability detection is crucial for ensuring the security and reliability\nof software systems. Recently, Graph Neural Networks (GNNs) have emerged as a\nprominent code embedding approach for vulnerability detection, owing to their\nability to capture the underlying semantic structure of source code. However,\nGNNs face significant challenges in explainability due to their inherently\nblack-box nature. To this end, several factual reasoning-based explainers have\nbeen proposed. These explainers provide explanations for the predictions made\nby GNNs by analyzing the key features that contribute to the outcomes. We argue\nthat these factual reasoning-based explanations cannot answer critical what-if\nquestions: What would happen to the GNN's decision if we were to alter the code\ngraph into alternative structures? Inspired by advancements of counterfactual\nreasoning in artificial intelligence, we propose CFExplainer, a novel\ncounterfactual explainer for GNN-based vulnerability detection. Unlike factual\nreasoning-based explainers, CFExplainer seeks the minimal perturbation to the\ninput code graph that leads to a change in the prediction, thereby addressing\nthe what-if questions for vulnerability detection. We term this perturbation a\ncounterfactual explanation, which can pinpoint the root causes of the detected\nvulnerability and furnish valuable insights for developers to undertake\nappropriate actions for fixing the vulnerability. Extensive experiments on four\nGNN-based vulnerability detection models demonstrate the effectiveness of\nCFExplainer over existing state-of-the-art factual reasoning-based explainers.",
      "tldr_zh": "该论文探讨了Graph Neural Networks (GNNs) 在软件漏洞检测中的应用及其黑箱解释性问题，现有事实推理-based explainers 无法回答“如果改变代码图，GNNs 决策会如何变化”的关键假设问题。作者提出 CFExplainer，一种基于反事实推理的创新解释器，通过对输入代码图进行最小扰动来生成反事实解释，从而识别漏洞根因并为开发者提供修复指导。实验结果显示，CFExplainer 在四个 GNN-based 漏洞检测模型上优于现有状态-of-the-art 解释器，证明了其有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "This paper was accepted in the proceedings of the 33rd ACM SIGSOFT\n  International Symposium on Software Testing and Analysis (ISSTA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.15687v2",
      "published_date": "2024-04-24 06:52:53 UTC",
      "updated_date": "2024-07-15 14:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:22:26.819971"
    },
    {
      "arxiv_id": "2404.15681v2",
      "title": "Automated Creation of Source Code Variants of a Cryptographic Hash Function Implementation Using Generative Pre-Trained Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Elijah Pelofske",
        "Vincent Urias",
        "Lorie M. Liebrock"
      ],
      "abstract": "Generative pre-trained transformers (GPT's) are a type of large language\nmachine learning model that are unusually adept at producing novel, and\ncoherent, natural language. In this study the ability of GPT models to generate\nnovel and correct versions, and notably very insecure versions, of\nimplementations of the cryptographic hash function SHA-1 is examined. The GPT\nmodels Llama-2-70b-chat-h, Mistral-7B-Instruct-v0.1, and zephyr-7b-alpha are\nused. The GPT models are prompted to re-write each function using a modified\nversion of the localGPT framework and langchain to provide word embedding\ncontext of the full source code and header files to the model, resulting in\nover 150,000 function re-write GPT output text blocks, approximately 50,000 of\nwhich were able to be parsed as C code and subsequently compiled. The generated\ncode is analyzed for being compilable, correctness of the algorithm, memory\nleaks, compiler optimization stability, and character distance to the reference\nimplementation. Remarkably, several generated function variants have a high\nimplementation security risk of being correct for some test vectors, but\nincorrect for other test vectors. Additionally, many function implementations\nwere not correct to the reference algorithm of SHA-1, but produced hashes that\nhave some of the basic characteristics of hash functions. Many of the function\nre-writes contained serious flaws such as memory leaks, integer overflows, out\nof bounds accesses, use of uninitialised values, and compiler optimization\ninstability. Compiler optimization settings and SHA-256 hash checksums of the\ncompiled binaries are used to cluster implementations that are equivalent but\nmay not have identical syntax - using this clustering over 100,000 novel and\ncorrect versions of the SHA-1 codebase were generated where each component C\nfunction of the reference implementation is different from the original code.",
      "tldr_zh": "该研究利用 Generative Pre-Trained Transformer (GPT) 模型（如 Llama-2-70b-chat-h、Mistral-7B-Instruct-v0.1 和 zephyr-7b-alpha）自动生成 SHA-1 加密哈希函数代码变体，通过修改 localGPT 框架和 langchain 提供上下文，成功生成了超过 15 万个函数重写输出，其中约 5 万个可编译为 C 代码。分析显示，这些变体中许多存在严重安全风险，包括部分测试向量正确但其他错误、内存泄漏、整数溢出和编译器优化不稳定性。最终，通过聚类方法，研究者生成了超过 10 万个新颖且正确的 SHA-1 代码变体，这为评估 AI 生成代码的安全性和可靠性提供了重要洞见。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15681v2",
      "published_date": "2024-04-24 06:29:55 UTC",
      "updated_date": "2024-07-10 03:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:22:41.068266"
    },
    {
      "arxiv_id": "2404.15678v4",
      "title": "Retrieval and Distill: A Temporal Data Shift-Free Paradigm for Online Recommendation System",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Zheng",
        "Ning Li",
        "Weinan Zhang",
        "Yong Yu"
      ],
      "abstract": "Current recommendation systems are significantly affected by a serious issue\nof temporal data shift, which is the inconsistency between the distribution of\nhistorical data and that of online data. Most existing models focus on\nutilizing updated data, overlooking the transferable, temporal data shift-free\ninformation that can be learned from shifting data. We propose the Temporal\nInvariance of Association theorem, which suggests that given a fixed search\nspace, the relationship between the data and the data in the search space keeps\ninvariant over time. Leveraging this principle, we designed a retrieval-based\nrecommendation system framework that can train a data shift-free relevance\nnetwork using shifting data, significantly enhancing the predictive performance\nof the original model in the recommendation system. However, retrieval-based\nrecommendation models face substantial inference time costs when deployed\nonline. To address this, we further designed a distill framework that can\ndistill information from the relevance network into a parameterized module\nusing shifting data. The distilled model can be deployed online alongside the\noriginal model, with only a minimal increase in inference time. Extensive\nexperiments on multiple real datasets demonstrate that our framework\nsignificantly improves the performance of the original model by utilizing\nshifting data.",
      "tldr_zh": "该论文针对推荐系统中的 temporal data shift 问题提出了一种免受时间数据偏移影响的范式。作者引入 Temporal Invariance of Association theorem，该定理指出在固定搜索空间下，数据间关系随时间保持不变，并据此设计了一个 retrieval-based 框架，使用 shifting data 训练数据 shift-free 的相关性网络，从而提升原模型的预测性能。为解决检索模型在线部署的推理时间成本问题，他们进一步开发了 distill framework，将相关性网络的信息蒸馏到参数化模块中，仅需最小增加推理时间。在多个真实数据集上的实验证明，该框架显著提高了原模型的性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15678v4",
      "published_date": "2024-04-24 06:16:09 UTC",
      "updated_date": "2024-06-13 07:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:22:52.652750"
    },
    {
      "arxiv_id": "2404.15676v3",
      "title": "Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Xia",
        "Rui Wang",
        "Xu Liu",
        "Mingyan Li",
        "Tong Yu",
        "Xiang Chen",
        "Julian McAuley",
        "Shuai Li"
      ],
      "abstract": "Chain-of-Thought (CoT) has been a widely adopted prompting method, eliciting\nimpressive reasoning abilities of Large Language Models (LLMs). Inspired by the\nsequential thought structure of CoT, a number of Chain-of-X (CoX) methods have\nbeen developed to address various challenges across diverse domains and tasks\ninvolving LLMs. In this paper, we provide a comprehensive survey of Chain-of-X\nmethods for LLMs in different contexts. Specifically, we categorize them by\ntaxonomies of nodes, i.e., the X in CoX, and application tasks. We also discuss\nthe findings and implications of existing CoX methods, as well as potential\nfuture directions. Our survey aims to serve as a detailed and up-to-date\nresource for researchers seeking to apply the idea of CoT to broader scenarios.",
      "tldr_zh": "这篇论文调查了超越 Chain-of-Thought (CoT) 的 Chain-of-X (CoX) 范式，探讨了这些方法如何扩展 Large Language Models (LLMs) 的推理能力，以应对各种领域和任务的挑战。论文根据节点（即 X in CoX）和应用任务对 CoX 方法进行了系统分类，并分析了现有方法的发现、含义以及潜在未来方向。该调查为研究人员提供了一个详细的资源，帮助将 CoT 思想应用于更广泛的场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.15676v3",
      "published_date": "2024-04-24 06:12:00 UTC",
      "updated_date": "2025-02-05 22:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:23:03.256846"
    },
    {
      "arxiv_id": "2404.15667v4",
      "title": "The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews",
      "title_zh": "使用 LLMs 加速系统评论筛选过程的承诺与挑战",
      "authors": [
        "Aleksi Huotala",
        "Miikka Kuutila",
        "Paul Ralph",
        "Mika Mäntylä"
      ],
      "abstract": "Systematic review (SR) is a popular research method in software engineering\n(SE). However, conducting an SR takes an average of 67 weeks. Thus, automating\nany step of the SR process could reduce the effort associated with SRs. Our\nobjective is to investigate if Large Language Models (LLMs) can accelerate\ntitle-abstract screening by simplifying abstracts for human screeners, and\nautomating title-abstract screening. We performed an experiment where humans\nscreened titles and abstracts for 20 papers with both original and simplified\nabstracts from a prior SR. The experiment with human screeners was reproduced\nwith GPT-3.5 and GPT-4 LLMs to perform the same screening tasks. We also\nstudied if different prompting techniques (Zero-shot (ZS), One-shot (OS),\nFew-shot (FS), and Few-shot with Chain-of-Thought (FS-CoT)) improve the\nscreening performance of LLMs. Lastly, we studied if redesigning the prompt\nused in the LLM reproduction of screening leads to improved performance. Text\nsimplification did not increase the screeners' screening performance, but\nreduced the time used in screening. Screeners' scientific literacy skills and\nresearcher status predict screening performance. Some LLM and prompt\ncombinations perform as well as human screeners in the screening tasks. Our\nresults indicate that the GPT-4 LLM is better than its predecessor, GPT-3.5.\nAdditionally, Few-shot and One-shot prompting outperforms Zero-shot prompting.\nUsing LLMs for text simplification in the screening process does not\nsignificantly improve human performance. Using LLMs to automate title-abstract\nscreening seems promising, but current LLMs are not significantly more accurate\nthan human screeners. To recommend the use of LLMs in the screening process of\nSRs, more research is needed. We recommend future SR studies publish\nreplication packages with screening data to enable more conclusive\nexperimenting with LLM screening.",
      "tldr_zh": "本文研究了使用大型语言模型（LLMs）加速系统综述（SR）筛选过程的潜力与挑战，重点探讨LLMs简化摘要以辅助人类筛选，以及自动化标题-摘要筛选。研究通过实验比较了人类筛选者使用原摘要和简化摘要的表现，以及GPT-3.5和GPT-4在Zero-shot、One-shot、Few-shot和Few-shot with Chain-of-Thought提示下的筛选性能。结果显示，简化文本减少了筛选时间但未提升准确性，某些LLM组合可媲美人类，且Few-shot提示优于Zero-shot；然而，当前LLMs的准确性尚未显著超过人类，因此作者建议进行更多研究并发布筛选数据以推动该领域的进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the International Conference on Evaluation and Assessment\n  in Software Engineering (EASE), 2024 edition",
      "pdf_url": "http://arxiv.org/pdf/2404.15667v4",
      "published_date": "2024-04-24 05:53:20 UTC",
      "updated_date": "2024-05-08 11:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:23:17.277833"
    },
    {
      "arxiv_id": "2404.15657v1",
      "title": "FedSI: Federated Subnetwork Inference for Efficient Uncertainty Quantification",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Chen",
        "Hengyu Liu",
        "Zhangkai Wu",
        "Xuhui Fan",
        "Longbing Cao"
      ],
      "abstract": "While deep neural networks (DNNs) based personalized federated learning (PFL)\nis demanding for addressing data heterogeneity and shows promising performance,\nexisting methods for federated learning (FL) suffer from efficient systematic\nuncertainty quantification. The Bayesian DNNs-based PFL is usually questioned\nof either over-simplified model structures or high computational and memory\ncosts. In this paper, we introduce FedSI, a novel Bayesian DNNs-based\nsubnetwork inference PFL framework. FedSI is simple and scalable by leveraging\nBayesian methods to incorporate systematic uncertainties effectively. It\nimplements a client-specific subnetwork inference mechanism, selects network\nparameters with large variance to be inferred through posterior distributions,\nand fixes the rest as deterministic ones. FedSI achieves fast and scalable\ninference while preserving the systematic uncertainties to the fullest extent.\nExtensive experiments on three different benchmark datasets demonstrate that\nFedSI outperforms existing Bayesian and non-Bayesian FL baselines in\nheterogeneous FL scenarios.",
      "tldr_zh": "该论文提出FedSI，一种基于Bayesian DNNs的子网络推理框架，用于个性化联邦学习(PFL)，以高效量化系统不确定性，同时解决现有联邦学习(FL)方法在数据异质性场景下的局限性。FedSI通过客户端特定的子网络推理机制，选择方差较大的网络参数进行后验分布推理，而将其余参数固定为确定性，从而实现快速、可扩展的推理并最大程度保留不确定性。在三个基准数据集上的实验表明，FedSI在异质FL场景中优于现有Bayesian和非Bayesian基线方法，展示了其在处理数据异质性和不确定性量化方面的显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15657v1",
      "published_date": "2024-04-24 05:24:08 UTC",
      "updated_date": "2024-04-24 05:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:23:27.880185"
    },
    {
      "arxiv_id": "2404.15653v1",
      "title": "CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data",
      "title_zh": "翻译失败",
      "authors": [
        "Sachin Mehta",
        "Maxwell Horton",
        "Fartash Faghri",
        "Mohammad Hossein Sekhavat",
        "Mahyar Najibi",
        "Mehrdad Farajtabar",
        "Oncel Tuzel",
        "Mohammad Rastegari"
      ],
      "abstract": "Contrastive learning has emerged as a transformative method for learning\neffective visual representations through the alignment of image and text\nembeddings. However, pairwise similarity computation in contrastive loss\nbetween image and text pairs poses computational challenges. This paper\npresents a novel weakly supervised pre-training of vision models on web-scale\nimage-text data. The proposed method reframes pre-training on image-text data\nas a classification task. Consequently, it eliminates the need for pairwise\nsimilarity computations in contrastive loss, achieving a remarkable $2.7\\times$\nacceleration in training speed compared to contrastive learning on web-scale\ndata. Through extensive experiments spanning diverse vision tasks, including\ndetection and segmentation, we demonstrate that the proposed method maintains\nhigh representation quality. Our source code along with pre-trained model\nweights and training recipes is available at\n\\url{https://github.com/apple/corenet}.",
      "tldr_zh": "该论文提出了 CatLIP，一种新型弱监督预训练方法，用于在网络规模图像-文本数据上训练视觉模型。它将预训练重新定义为分类任务，从而避免了对比学习中成对相似性计算的计算开销，实现 2.7 倍的训练速度加速。实验结果显示，CatLIP 在检测、分割等多样视觉任务上保持了与 CLIP 相当的高表示质量，并提供了开源代码、预训练模型和训练方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15653v1",
      "published_date": "2024-04-24 05:13:28 UTC",
      "updated_date": "2024-04-24 05:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:23:39.516616"
    },
    {
      "arxiv_id": "2404.15648v2",
      "title": "Cross-Embodied Affordance Transfer through Learning Affordance Equivalences",
      "title_zh": "翻译失败",
      "authors": [
        "Hakan Aktas",
        "Yukie Nagai",
        "Minoru Asada",
        "Matteo Saveriano",
        "Erhan Oztop",
        "Emre Ugur"
      ],
      "abstract": "Affordances represent the inherent effect and action possibilities that\nobjects offer to the agents within a given context. From a theoretical\nviewpoint, affordances bridge the gap between effect and action, providing a\nfunctional understanding of the connections between the actions of an agent and\nits environment in terms of the effects it can cause. In this study, we propose\na deep neural network model that unifies objects, actions, and effects into a\nsingle latent vector in a common latent space that we call the affordance\nspace. Using the affordance space, our system can generate effect trajectories\nwhen action and object are given and can generate action trajectories when\neffect trajectories and objects are given. Our model does not learn the\nbehavior of individual objects acted upon by a single agent. Still, rather, it\nforms a `shared affordance representation' spanning multiple agents and\nobjects, which we call Affordance Equivalence. Affordance Equivalence\nfacilitates not only action generalization over objects but also Cross\nEmbodiment transfer linking actions of different robots. In addition to the\nsimulation experiments that demonstrate the proposed model's range of\ncapabilities, we also showcase that our model can be used for direct imitation\nin real-world settings.",
      "tldr_zh": "本研究提出了一种通过学习 Affordance Equivalences 的方法，实现 Cross-Embodied Affordance Transfer，从而桥接代理行动与环境效果的关联。模型使用一个深度神经网络，将对象、行动和效果统一到一个共同的 affordance space 中，能够根据给定行动和对象生成效果轨迹，或根据效果轨迹和对象生成行动轨迹。这种共享的 Affordance Equivalence 不仅支持行动在不同对象间的泛化，还实现了跨不同机器人的行动转移。实验结果显示，该模型在模拟环境中展示了广泛能力，并在真实世界中成功应用于直接模仿任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 9 figures, Submitted to IEEE Transactions on Cognitive and\n  Developmental Systems",
      "pdf_url": "http://arxiv.org/pdf/2404.15648v2",
      "published_date": "2024-04-24 05:07:36 UTC",
      "updated_date": "2024-10-10 01:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:23:54.256177"
    },
    {
      "arxiv_id": "2404.16076v1",
      "title": "Semantic Evolvement Enhanced Graph Autoencoder for Rumor Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Tao",
        "Liang Wang",
        "Qiang Liu",
        "Shu Wu",
        "Liang Wang"
      ],
      "abstract": "Due to the rapid spread of rumors on social media, rumor detection has become\nan extremely important challenge. Recently, numerous rumor detection models\nwhich utilize textual information and the propagation structure of events have\nbeen proposed. However, these methods overlook the importance of semantic\nevolvement information of event in propagation process, which is often\nchallenging to be truly learned in supervised training paradigms and\ntraditional rumor detection methods. To address this issue, we propose a novel\nsemantic evolvement enhanced Graph Autoencoder for Rumor Detection (GARD) model\nin this paper. The model learns semantic evolvement information of events by\ncapturing local semantic changes and global semantic evolvement information\nthrough specific graph autoencoder and reconstruction strategies. By combining\nsemantic evolvement information and propagation structure information, the\nmodel achieves a comprehensive understanding of event propagation and perform\naccurate and robust detection, while also detecting rumors earlier by capturing\nsemantic evolvement information in the early stages. Moreover, in order to\nenhance the model's ability to learn the distinct patterns of rumors and\nnon-rumors, we introduce a uniformity regularizer to further improve the\nmodel's performance. Experimental results on three public benchmark datasets\nconfirm the superiority of our GARD method over the state-of-the-art approaches\nin both overall performance and early rumor detection.",
      "tldr_zh": "本文提出了一种名为GARD的语义演变增强图自编码器(Graph Autoencoder)模型，用于社交媒体谣言检测，以解决现有方法忽略事件传播过程中语义演变信息的问题。GARD通过特定图自编码器捕获局部语义变化和全局语义演变信息，并结合传播结构信息，实现对事件传播的全面理解，从而提高检测的准确性和鲁棒性。模型还引入均匀性正则化器(uniformity regularizer)来强化学习谣言与非谣言的模式，并支持早期谣言检测。在三个公共基准数据集上的实验结果显示，GARD在整体性能和早期检测方面均优于最先进方法。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16076v1",
      "published_date": "2024-04-24 05:05:58 UTC",
      "updated_date": "2024-04-24 05:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:24:05.284303"
    },
    {
      "arxiv_id": "2404.15638v1",
      "title": "PriorNet: A Novel Lightweight Network with Multidimensional Interactive Attention for Efficient Image Dehazing",
      "title_zh": "PriorNet：一种新型轻量级网络，带有多维交互注意力，用于高效图像去雾",
      "authors": [
        "Yutong Chen",
        "Zhang Wen",
        "Chao Wang",
        "Lei Gong",
        "Zhongchao Yi"
      ],
      "abstract": "Hazy images degrade visual quality, and dehazing is a crucial prerequisite\nfor subsequent processing tasks. Most current dehazing methods rely on neural\nnetworks and face challenges such as high computational parameter pressure and\nweak generalization capabilities. This paper introduces PriorNet--a novel,\nlightweight, and highly applicable dehazing network designed to significantly\nimprove the clarity and visual quality of hazy images while avoiding excessive\ndetail extraction issues. The core of PriorNet is the original\nMulti-Dimensional Interactive Attention (MIA) mechanism, which effectively\ncaptures a wide range of haze characteristics, substantially reducing the\ncomputational load and generalization difficulties associated with complex\nsystems. By utilizing a uniform convolutional kernel size and incorporating\nskip connections, we have streamlined the feature extraction process.\nSimplifying the number of layers and architecture not only enhances dehazing\nefficiency but also facilitates easier deployment on edge devices. Extensive\ntesting across multiple datasets has demonstrated PriorNet's exceptional\nperformance in dehazing and clarity restoration, maintaining image detail and\ncolor fidelity in single-image dehazing tasks. Notably, with a model size of\njust 18Kb, PriorNet showcases superior dehazing generalization capabilities\ncompared to other methods. Our research makes a significant contribution to\nadvancing image dehazing technology, providing new perspectives and tools for\nthe field and related domains, particularly emphasizing the importance of\nimproving universality and deployability.",
      "tldr_zh": "本研究提出PriorNet，一种新型轻量级网络，结合Multi-Dimensional Interactive Attention (MIA)机制，用于高效图像去雾处理，以解决现有方法的高计算压力和弱泛化能力问题。PriorNet的核心是MIA机制，通过有效捕获雾霾特征、统一卷积核大小和跳跃连接，简化特征提取过程，并减少层数以便在边缘设备上轻松部署。在多个数据集上的广泛测试中，PriorNet以仅18Kb的模型大小，实现了卓越的去雾性能和图像细节、颜色保真度，比其他方法表现出更好的泛化能力。该工作为图像去雾技术提供了新工具，强调了提升通用性和可部署性的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.15638v1",
      "published_date": "2024-04-24 04:20:22 UTC",
      "updated_date": "2024-04-24 04:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:24:15.359857"
    },
    {
      "arxiv_id": "2404.15633v3",
      "title": "Artificial Intelligence for Multi-Unit Auction design",
      "title_zh": "翻译失败",
      "authors": [
        "Peyman Khezr",
        "Kendall Taylor"
      ],
      "abstract": "Understanding bidding behavior in multi-unit auctions remains an ongoing\nchallenge for researchers. Despite their widespread use, theoretical insights\ninto the bidding behavior, revenue ranking, and efficiency of commonly used\nmulti-unit auctions are limited. This paper utilizes artificial intelligence,\nspecifically reinforcement learning, as a model free learning approach to\nsimulate bidding in three prominent multi-unit auctions employed in practice.\nWe introduce six algorithms that are suitable for learning and bidding in\nmulti-unit auctions and compare them using an illustrative example. This paper\nunderscores the significance of using artificial intelligence in auction\ndesign, particularly in enhancing the design of multi-unit auctions.",
      "tldr_zh": "本研究探讨了多单位拍卖(multi-unit auctions)中竞标行为的理解问题，由于理论洞见有限，该领域面临挑战。作者采用人工智能，特别是强化学习(reinforcement learning)作为无模型学习方法，模拟三种常见多单位拍卖中的竞标行为，并引入六个适合学习的算法，通过示例进行比较。结果强调了人工智能在拍卖设计中的重要性，有助于提升多单位拍卖的收入排名和效率。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15633v3",
      "published_date": "2024-04-24 03:51:26 UTC",
      "updated_date": "2024-08-08 02:11:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:24:26.258569"
    },
    {
      "arxiv_id": "2404.15617v2",
      "title": "DPO: Differential reinforcement learning with application to optimal configuration search",
      "title_zh": "翻译失败",
      "authors": [
        "Chandrajit Bajaj",
        "Minh Nguyen"
      ],
      "abstract": "Reinforcement learning (RL) with continuous state and action spaces remains\none of the most challenging problems within the field. Most current learning\nmethods focus on integral identities such as value functions to derive an\noptimal strategy for the learning agent. In this paper, we instead study the\ndual form of the original RL formulation to propose the first differential RL\nframework that can handle settings with limited training samples and\nshort-length episodes. Our approach introduces Differential Policy Optimization\n(DPO), a pointwise and stage-wise iteration method that optimizes policies\nencoded by local-movement operators. We prove a pointwise convergence estimate\nfor DPO and provide a regret bound comparable with the best current theoretical\nderivation. Such pointwise estimate ensures that the learned policy matches the\noptimal path uniformly across different steps. We then apply DPO to a class of\npractical RL problems with continuous state and action spaces, and which search\nfor optimal configurations with Lagrangian rewards. DPO is easy to implement,\nscalable, and shows competitive results on benchmarking experiments against\nseveral popular RL methods.",
      "tldr_zh": "本研究提出了一种差分强化学习（Differential Reinforcement Learning）框架，针对连续状态和动作空间的强化学习（RL）问题，特别是在训练样本有限和短episode场景下优化策略。该框架引入了Differential Policy Optimization (DPO)，一种点式和阶段式迭代方法，使用局部移动操作符编码策略，并证明了DPO的点式收敛估计以及与现有最佳理论相当的regret bound，确保学习策略在不同步骤上均匀匹配最优路径。实验结果显示，DPO在搜索具有Lagrangian rewards的最优配置的实际RL问题中，易于实现、可扩展，且在基准测试中与流行RL方法竞争表现强劲。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15617v2",
      "published_date": "2024-04-24 03:11:12 UTC",
      "updated_date": "2024-08-13 03:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:24:39.806975"
    },
    {
      "arxiv_id": "2404.15616v1",
      "title": "A Bi-directional Quantum Search Algorithm",
      "title_zh": "一种双向量子搜索算法",
      "authors": [
        "Debanjan Konar",
        "Zain Hafeez",
        "Vaneet Aggarwal"
      ],
      "abstract": "Grover's search algorithms, including various partial Grover searches,\nexperience scaling problems as the number of iterations rises with increased\nqubits, making implementation more computationally expensive. This paper\ncombines Partial Grover's search algorithm and Bi-directional Search to create\na fast Grover's quantum search algorithm, referred to as Bi-Directional Grover\nSearch (BDGS). We incorporated a bi-directional search tactic with a partial\nGrover search, starting from an initial state and a single marked state in\nparallel. We have shown in this article that our novel approach requires\n$\\frac{\\pi}{4\\sqrt{2}}\\sqrt{N}(1-\\sqrt{\\frac{1}{b^{r/2k}}})$ iterations over\nregular Grover Search and Partial Grover Search (PGS), which takes\n$\\frac{\\pi}{4}\\sqrt{N}\\sqrt{1-\\frac{1}{b}}$ (here, $N=2^r$ elements, $b$ is the\nbranching factor of partial search, and $k= \\lceil\\log_2b \\rceil$). The\nproposed BDGS algorithm is benchmarked against the state-of-the-art Depth-First\nGrover's Search (DFGS) and generic Grover's Search (GS) implementations for $2$\nto $20$ qubits and provides promising results. The Qiskit Python implementation\nof the proposed BDGS algorithm is available on Github\n(https://github.com/hafeezzwiz21/DFGS-BDGS).",
      "tldr_zh": "这篇论文提出了一种新的量子搜索算法，名为 Bi-Directional Grover Search (BDGS)，它将 Partial Grover's search 与 Bi-directional Search 相结合，从初始状态和标记状态并行启动，以解决传统 Grover's Search 在 qubits 增加时迭代次数过多导致的计算开销问题。相比于 Grover's Search (GS) 和 Partial Grover Search (PGS)，BDGS 仅需 $\\frac{\\pi}{4\\sqrt{2}}\\sqrt{N}(1-\\sqrt{\\frac{1}{b^{r/2k}}})$ 迭代（其中 $N=2^r$ 为元素数，$b$ 为分支因子），显著减少了迭代需求。在 2 到 20 个 qubits 的基准测试中，BDGS 优于 Depth-First Grover's Search (DFGS) 和 GS，并提供了 Qiskit Python 实现（GitHub 链接）。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.15616v1",
      "published_date": "2024-04-24 03:11:10 UTC",
      "updated_date": "2024-04-24 03:11:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:24:54.171832"
    },
    {
      "arxiv_id": "2404.15604v1",
      "title": "Hybrid LLM/Rule-based Approaches to Business Insights Generation from Structured Data",
      "title_zh": "翻译失败",
      "authors": [
        "Aliaksei Vertsel",
        "Mikhail Rumiantsau"
      ],
      "abstract": "In the field of business data analysis, the ability to extract actionable\ninsights from vast and varied datasets is essential for informed\ndecision-making and maintaining a competitive edge. Traditional rule-based\nsystems, while reliable, often fall short when faced with the complexity and\ndynamism of modern business data. Conversely, Artificial Intelligence (AI)\nmodels, particularly Large Language Models (LLMs), offer significant potential\nin pattern recognition and predictive analytics but can lack the precision\nnecessary for specific business applications. This paper explores the efficacy\nof hybrid approaches that integrate the robustness of rule-based systems with\nthe adaptive power of LLMs in generating actionable business insights.",
      "tldr_zh": "本研究探讨了从结构化数据中生成商业洞见的挑战，传统 rule-based 系统虽可靠但难以处理现代数据的复杂性和动态性，而 LLM（Large Language Models）虽在模式识别和预测分析中潜力巨大，却往往缺乏所需的精确性。论文提出混合方法，将 rule-based 系统的稳健性与 LLM 的适应性相结合，以提升洞见生成的可操作性和准确性。这种方法有望为商业决策提供更有效的支持，帮助企业在竞争中保持优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15604v1",
      "published_date": "2024-04-24 02:42:24 UTC",
      "updated_date": "2024-04-24 02:42:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:25:02.904197"
    },
    {
      "arxiv_id": "2404.15601v1",
      "title": "Deepfakes and Higher Education: A Research Agenda and Scoping Review of Synthetic Media",
      "title_zh": "Deepfakes 与高等教育：合成媒体的研究议程和范围综述",
      "authors": [
        "Jasper Roe",
        "Mike Perkins"
      ],
      "abstract": "The availability of software which can produce convincing yet synthetic media\nposes both threats and benefits to tertiary education globally. While other\nforms of synthetic media exist, this study focuses on deepfakes, which are\nadvanced Generative AI (GenAI) fakes of real people. This conceptual paper\nassesses the current literature on deepfakes across multiple disciplines by\nconducting an initial scoping review of 182 peer-reviewed publications.\n  The review reveals three major trends: detection methods, malicious\napplications, and potential benefits, although no specific studies on deepfakes\nin the tertiary educational context were found. Following a discussion of these\ntrends, this study applies the findings to postulate the major risks and\npotential mitigation strategies of deepfake technologies in higher education,\nas well as potential beneficial uses to aid the teaching and learning of both\ndeepfakes and synthetic media. This culminates in the proposal of a research\nagenda to build a comprehensive, cross-cultural approach to investigate\ndeepfakes in higher education.",
      "tldr_zh": "这篇论文通过对182篇同行评审文献的范围审查（scoping review），评估了deepfakes（一种先进的Generative AI生成的人脸合成媒体）在多学科中的当前研究及其对高等教育的影响。审查揭示了三个主要趋势：检测方法、恶意应用和潜在益处，但未发现针对高等教育的特定研究。作者基于这些发现，讨论了deepfakes在高等教育中的主要风险（如学术诚信威胁）和缓解策略（如技术检测工具），以及潜在益处（如辅助教学）。最终，论文提出一个研究议程，旨在建立全面的跨文化方法来调查deepfakes在高等教育中的应用和发展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15601v1",
      "published_date": "2024-04-24 02:40:58 UTC",
      "updated_date": "2024-04-24 02:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:25:16.722370"
    },
    {
      "arxiv_id": "2404.15599v2",
      "title": "Human-in-the-loop Learning for Dynamic Congestion Games",
      "title_zh": "翻译失败",
      "authors": [
        "Hongbo Li",
        "Lingjie Duan"
      ],
      "abstract": "Today mobile users learn and share their traffic observations via\ncrowdsourcing platforms (e.g., Waze). Yet such platforms simply cater to\nselfish users' myopic interests to recommend the shortest path, and do not\nencourage enough users to travel and learn other paths for future others. Prior\nstudies focus on one-shot congestion games without considering users'\ninformation learning, while our work studies how users learn and alter traffic\nconditions on stochastic paths in a human-in-the-loop manner. Our analysis\nshows that the myopic routing policy leads to severe under-exploration of\nstochastic paths. This results in a price of anarchy (PoA) greater than $2$, as\ncompared to the socially optimal policy in minimizing the long-term social\ncost. Besides, the myopic policy fails to ensure the correct learning\nconvergence about users' traffic hazard beliefs. To address this, we focus on\ninformational (non-monetary) mechanisms as they are easier to implement than\npricing. We first show that existing information-hiding mechanisms and\ndeterministic path-recommendation mechanisms in Bayesian persuasion literature\ndo not work with even (\\text{PoA}=\\infty). Accordingly, we propose a new\ncombined hiding and probabilistic recommendation (CHAR) mechanism to hide all\ninformation from a selected user group and provide state-dependent\nprobabilistic recommendations to the other user group. Our CHAR successfully\nensures PoA less than (\\frac{5}{4}), which cannot be further reduced by any\nother informational (non-monetary) mechanism. Besides the parallel network, we\nfurther extend our analysis and CHAR to more general linear path graphs with\nmultiple intermediate nodes, and we prove that the PoA results remain\nunchanged. Additionally, we carry out experiments with real-world datasets to\nfurther extend our routing graphs and verify the close-to-optimal performance\nof our CHAR.",
      "tldr_zh": "本研究探讨了人类参与循环的人类-在-循环学习在动态拥堵游戏中的应用，指出现有交通平台（如Waze）仅推荐最短路径，导致对随机路径的低探索，造成Price of Anarchy (PoA)大于2，并阻碍交通危险信念的正确学习。作者提出了一种新的Combined Hiding and Probabilistic Recommendation (CHAR)机制，通过对部分用户隐藏信息并向另一部分提供状态相关的概率推荐，成功将PoA降低至小于5/4。实验结果在真实数据集上验证了CHAR机制的近似最优性能，并在更一般的线性路径图上证明了其鲁棒性。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "This paper has been published IEEE Transactions on Mobile Computing\n  (2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.15599v2",
      "published_date": "2024-04-24 02:23:12 UTC",
      "updated_date": "2024-11-16 01:45:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:25:27.867218"
    },
    {
      "arxiv_id": "2404.15597v1",
      "title": "GRSN: Gated Recurrent Spiking Neurons for POMDPs and MARL",
      "title_zh": "翻译失败",
      "authors": [
        "Lang Qin",
        "Ziming Wang",
        "Runhao Jiang",
        "Rui Yan",
        "Huajin Tang"
      ],
      "abstract": "Spiking neural networks (SNNs) are widely applied in various fields due to\ntheir energy-efficient and fast-inference capabilities. Applying SNNs to\nreinforcement learning (RL) can significantly reduce the computational resource\nrequirements for agents and improve the algorithm's performance under\nresource-constrained conditions. However, in current spiking reinforcement\nlearning (SRL) algorithms, the simulation results of multiple time steps can\nonly correspond to a single-step decision in RL. This is quite different from\nthe real temporal dynamics in the brain and also fails to fully exploit the\ncapacity of SNNs to process temporal data. In order to address this temporal\nmismatch issue and further take advantage of the inherent temporal dynamics of\nspiking neurons, we propose a novel temporal alignment paradigm (TAP) that\nleverages the single-step update of spiking neurons to accumulate historical\nstate information in RL and introduces gated units to enhance the memory\ncapacity of spiking neurons. Experimental results show that our method can\nsolve partially observable Markov decision processes (POMDPs) and multi-agent\ncooperation problems with similar performance as recurrent neural networks\n(RNNs) but with about 50% power consumption.",
      "tldr_zh": "本研究提出 GRSN（Gated Recurrent Spiking Neurons），一种基于脉冲神经网络（SNNs）的框架，用于解决强化学习（RL）中的时间不匹配问题。GRSN 引入 Temporal Alignment Paradigm (TAP)，通过利用 SNNs 的单步更新积累历史状态信息并添加门控单元（gated units），增强神经元的记忆容量，从而更好地处理时间动态数据。实验结果显示，该方法在部分可观测马尔可夫决策过程（POMDPs）和多智能体强化学习（MARL）任务上，性能与循环神经网络（RNNs）相当，但功耗降低约 50%。这为资源受限环境下的高效 RL 算法提供了新途径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15597v1",
      "published_date": "2024-04-24 02:20:50 UTC",
      "updated_date": "2024-04-24 02:20:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:25:40.141961"
    },
    {
      "arxiv_id": "2404.15592v2",
      "title": "ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Peng Zou",
        "Vinay Samuel",
        "Yue Zhou",
        "Weizhi Zhang",
        "Liancheng Fang",
        "Zihe Song",
        "Philip S. Yu",
        "Cornelia Caragea"
      ],
      "abstract": "Existing datasets for attribute value extraction (AVE) predominantly focus on\nexplicit attribute values while neglecting the implicit ones, lack product\nimages, are often not publicly available, and lack an in-depth human inspection\nacross diverse domains. To address these limitations, we present ImplicitAVE,\nthe first, publicly available multimodal dataset for implicit attribute value\nextraction. ImplicitAVE, sourced from the MAVE dataset, is carefully curated\nand expanded to include implicit AVE and multimodality, resulting in a refined\ndataset of 68k training and 1.6k testing data across five domains. We also\nexplore the application of multimodal large language models (MLLMs) to implicit\nAVE, establishing a comprehensive benchmark for MLLMs on the ImplicitAVE\ndataset. Six recent MLLMs with eleven variants are evaluated across diverse\nsettings, revealing that implicit value extraction remains a challenging task\nfor MLLMs. The contributions of this work include the development and release\nof ImplicitAVE, and the exploration and benchmarking of various MLLMs for\nimplicit AVE, providing valuable insights and potential future research\ndirections. Dataset and code are available at\nhttps://github.com/HenryPengZou/ImplicitAVE",
      "tldr_zh": "本研究介绍了ImplicitAVE，这是一个开源的多模态数据集，针对隐式属性值提取（AVE）问题，解决了现有数据集忽略隐式值、缺少图像以及缺乏跨领域检查的局限性。ImplicitAVE基于MAVE数据集进行扩展和精炼，共包含68k训练数据和1.6k测试数据，覆盖五个领域，并首次整合多模态元素。作者评估了六种多模态大型语言模型（MLLMs）及其十一种变体在ImplicitAVE上的性能，发现隐式值提取对MLLMs仍是一个挑战性任务。该工作提供了宝贵的基准测试见解，并通过开源代码（https://github.com/HenryPengZou/ImplicitAVE）支持未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACL 2024 (Findings) - Scores: Soundness - 4/4/4, Dataset\n  - 4/4/4, Overall Assessment - 4/3.5/3.5, Meta - 4",
      "pdf_url": "http://arxiv.org/pdf/2404.15592v2",
      "published_date": "2024-04-24 01:54:40 UTC",
      "updated_date": "2024-07-19 19:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:25:52.530956"
    },
    {
      "arxiv_id": "2404.15583v3",
      "title": "Multi-Agent Reinforcement Learning for Energy Networks: Computational Challenges, Progress and Open Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Keren",
        "Chaimaa Essayeh",
        "Stefano V. Albrecht",
        "Thomas Morstyn"
      ],
      "abstract": "The rapidly changing architecture and functionality of electrical networks\nand the increasing penetration of renewable and distributed energy resources\nhave resulted in various technological and managerial challenges. These have\nrendered traditional centralized energy-market paradigms insufficient due to\ntheir inability to support the dynamic and evolving nature of the network. This\nsurvey explores how multi-agent reinforcement learning (MARL) can support the\ndecentralization and decarbonization of energy networks and mitigate the\nassociated challenges. This is achieved by specifying key computational\nchallenges in managing energy networks, reviewing recent research progress on\naddressing them, and highlighting open challenges that may be addressed using\nMARL.",
      "tldr_zh": "这篇论文探讨了电力网络架构的快速演变和分布式可再生能源渗透所带来的技术和管理挑战，这些问题使得传统中心化能源市场模式难以适应动态环境。多智能体强化学习 (MARL) 被提出作为一种解决方案，以支持能源网络的去中心化和低碳化。该论文通过识别关键计算挑战、回顾最近的研究进展，并突出可使用 MARL 解决的开放问题，为未来能源管理提供了重要见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15583v3",
      "published_date": "2024-04-24 01:35:27 UTC",
      "updated_date": "2024-05-25 05:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:26:03.844066"
    },
    {
      "arxiv_id": "2406.02562v1",
      "title": "Gated Low-rank Adaptation for personalized Code-Switching Automatic Speech Recognition on the low-spec devices",
      "title_zh": "翻译失败",
      "authors": [
        "Gwantae Kim",
        "Bokyeung Lee",
        "Donghyeon Kim",
        "Hanseok Ko"
      ],
      "abstract": "In recent times, there has been a growing interest in utilizing personalized\nlarge models on low-spec devices, such as mobile and CPU-only devices. However,\nutilizing a personalized large model in the on-device is inefficient, and\nsometimes limited due to computational cost. To tackle the problem, this paper\npresents the weights separation method to minimize on-device model weights\nusing parameter-efficient fine-tuning methods. Moreover, some people speak\nmultiple languages in an utterance, as known as code-switching, the\npersonalized ASR model is necessary to address such cases. However, current\nmultilingual speech recognition models are limited to recognizing a single\nlanguage within each utterance. To tackle this problem, we propose\ncode-switching speech recognition models that incorporate fine-tuned\nmonolingual and multilingual speech recognition models. Additionally, we\nintroduce a gated low-rank adaptation(GLoRA) for parameter-efficient\nfine-tuning with minimal performance degradation. Our experiments, conducted on\nKorean-English code-switching datasets, demonstrate that fine-tuning speech\nrecognition models for code-switching surpasses the performance of traditional\ncode-switching speech recognition models trained from scratch. Furthermore,\nGLoRA enhances parameter-efficient fine-tuning performance compared to\nconventional LoRA.",
      "tldr_zh": "这篇论文针对低规格设备（如手机或仅CPU设备）上运行个性化代码-switching自动语音识别（ASR）模型的挑战，提出了一种权重分离方法，利用参数高效微调来最小化模型权重。论文引入了门控低秩适配（GLoRA）技术，通过结合微调后的单语和多语ASR模型，处理代码-switching场景中的多语言识别问题，同时减少性能损失。实验结果显示，在韩英代码-switching数据集上，该方法比从零训练的传统模型性能更优，且GLoRA相较于常规LoRA进一步提升了参数高效微调的效果。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "Table 2 is revised",
      "pdf_url": "http://arxiv.org/pdf/2406.02562v1",
      "published_date": "2024-04-24 01:31:39 UTC",
      "updated_date": "2024-04-24 01:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:26:17.474196"
    },
    {
      "arxiv_id": "2404.16887v1",
      "title": "Anomaly Detection for Incident Response at Scale",
      "title_zh": "大规模事件响应的异常检测",
      "authors": [
        "Hanzhang Wang",
        "Gowtham Kumar Tangirala",
        "Gilkara Pranav Naidu",
        "Charles Mayville",
        "Arighna Roy",
        "Joanne Sun",
        "Ramesh Babu Mandava"
      ],
      "abstract": "We present a machine learning-based anomaly detection product, AI Detect and\nRespond (AIDR), that monitors Walmart's business and system health in\nreal-time. During the validation over 3 months, the product served predictions\nfrom over 3000 models to more than 25 application, platform, and operation\nteams, covering 63\\% of major incidents and reducing the mean-time-to-detect\n(MTTD) by more than 7 minutes. Unlike previous anomaly detection methods, our\nsolution leverages statistical, ML and deep learning models while continuing to\nincorporate rule-based static thresholds to incorporate domain-specific\nknowledge. Both univariate and multivariate ML models are deployed and\nmaintained through distributed services for scalability and high availability.\nAIDR has a feedback loop that assesses model quality with a combination of\ndrift detection algorithms and customer feedback. It also offers\nself-onboarding capabilities and customizability. AIDR has achieved success\nwith various internal teams with lower time to detection and fewer false\npositives than previous methods. As we move forward, we aim to expand incident\ncoverage and prevention, reduce noise, and integrate further with root cause\nrecommendation (RCR) to enable an end-to-end AIDR experience.",
      "tldr_zh": "本研究介绍了 Walmart 的 AI Detect and Respond (AIDR) 系统，这是一个基于机器学习的异常检测产品，用于实时监控业务和系统健康。系统结合统计、ML 和深度学习模型，以及规则-based 阈值，支持 univariate 和 multivariate 模型，通过分布式服务实现可扩展性和高可用性，并通过反馈循环（如 drift detection 和客户反馈）来评估模型质量。在 3 个月验证中，AIDR 覆盖了 63% 的主要事件，将 mean-time-to-detect (MTTD) 减少超过 7 分钟，并显著降低了假阳性率；未来计划扩展事件覆盖、减少噪音，并与 root cause recommendation (RCR) 集成以实现端到端响应。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ASPLOS 2024 AIOps workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.16887v1",
      "published_date": "2024-04-24 00:46:19 UTC",
      "updated_date": "2024-04-24 00:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:26:30.449784"
    },
    {
      "arxiv_id": "2404.16886v1",
      "title": "Review of Data-centric Time Series Analysis from Sample, Feature, and Period",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxi Sun",
        "Hongyan Li",
        "Yaliang Li",
        "Shenda Hong"
      ],
      "abstract": "Data is essential to performing time series analysis utilizing machine\nlearning approaches, whether for classic models or today's large language\nmodels. A good time-series dataset is advantageous for the model's accuracy,\nrobustness, and convergence, as well as task outcomes and costs. The emergence\nof data-centric AI represents a shift in the landscape from model refinement to\nprioritizing data quality. Even though time-series data processing methods\nfrequently come up in a wide range of research fields, it hasn't been well\ninvestigated as a specific topic. To fill the gap, in this paper, we\nsystematically review different data-centric methods in time series analysis,\ncovering a wide range of research topics. Based on the time-series data\ncharacteristics at sample, feature, and period, we propose a taxonomy for the\nreviewed data selection methods. In addition to discussing and summarizing\ntheir characteristics, benefits, and drawbacks targeting time-series data, we\nalso introduce the challenges and opportunities by proposing recommendations,\nopen problems, and possible research topics.",
      "tldr_zh": "这篇论文系统回顾了数据中心AI在时间序列分析中的方法，强调高质量数据集对模型准确性、鲁棒性和任务效果的重要性。作者基于时间序列数据的样本、特征和周期特性，提出一个分类法来整理数据选择方法，并讨论了这些方法的优势、缺点以及针对时间序列数据的适用性。该研究还指出了当前挑战、机会，并推荐了开放问题和未来研究方向，以推动该领域的进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2404.16886v1",
      "published_date": "2024-04-24 00:34:44 UTC",
      "updated_date": "2024-04-24 00:34:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:26:43.822157"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 91,
  "processed_papers_count": 91,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T03:27:06.589516"
}