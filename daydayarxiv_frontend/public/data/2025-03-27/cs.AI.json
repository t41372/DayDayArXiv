{
  "date": "2025-03-27",
  "category": "cs.AI",
  "summary": "",
  "papers": [
    {
      "arxiv_id": "2503.21775v1",
      "title": "StyleMotif: Multi-Modal Motion Stylization using Style-Content Cross Fusion",
      "title_zh": "StyleMotif：使用风格-内容交叉融合的多模态运动风格化\n",
      "authors": [
        "Ziyu Guo",
        "Young Yoon Lee",
        "Joseph Liu",
        "Yizhak Ben-Shabat",
        "Victor Zordan",
        "Mubbasir Kapadia"
      ],
      "abstract": "We present StyleMotif, a novel Stylized Motion Latent Diffusion model,\ngenerating motion conditioned on both content and style from multiple\nmodalities. Unlike existing approaches that either focus on generating diverse\nmotion content or transferring style from sequences, StyleMotif seamlessly\nsynthesizes motion across a wide range of content while incorporating stylistic\ncues from multi-modal inputs, including motion, text, image, video, and audio.\nTo achieve this, we introduce a style-content cross fusion mechanism and align\na style encoder with a pre-trained multi-modal model, ensuring that the\ngenerated motion accurately captures the reference style while preserving\nrealism. Extensive experiments demonstrate that our framework surpasses\nexisting methods in stylized motion generation and exhibits emergent\ncapabilities for multi-modal motion stylization, enabling more nuanced motion\nsynthesis. Source code and pre-trained models will be released upon acceptance.\nProject Page: https://stylemotif.github.io",
      "tldr_zh": "StyleMotif 是一种新颖的风格化运动潜在扩散模型，它能够根据内容和风格生成运动，并且支持多种模态的输入。与现有方法不同，StyleMotif 无缝地综合了各种内容的运动，同时融入了来自运动、文本、图像、视频和音频等多模态输入的风格线索。为了实现这一目标，该论文引入了一种风格-内容交叉融合机制，并将风格编码器与预训练的多模态模型对齐，确保生成的运动准确地捕捉到参考风格，同时保持真实感。实验结果表明，StyleMotif 在风格化运动生成方面超越了现有方法，并展示了多模态运动风格化的新兴能力，从而能够进行更细致的运动合成。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://stylemotif.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.21775v1",
      "published_date": "2025-03-27 17:59:46 UTC",
      "updated_date": "2025-03-27 17:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:30:25.186850"
    },
    {
      "arxiv_id": "2503.21766v1",
      "title": "Stable-SCore: A Stable Registration-based Framework for 3D Shape Correspondence",
      "title_zh": "Stable-SCore：一种基于稳定配准的3D形状对应框架\n",
      "authors": [
        "Haolin Liu",
        "Xiaohang Zhan",
        "Zizheng Yan",
        "Zhongjin Luo",
        "Yuxin Wen",
        "Xiaoguang Han"
      ],
      "abstract": "Establishing character shape correspondence is a critical and fundamental\ntask in computer vision and graphics, with diverse applications including\nre-topology, attribute transfer, and shape interpolation. Current dominant\nfunctional map methods, while effective in controlled scenarios, struggle in\nreal situations with more complex challenges such as non-isometric shape\ndiscrepancies. In response, we revisit registration-for-correspondence methods\nand tap their potential for more stable shape correspondence estimation. To\novercome their common issues including unstable deformations and the necessity\nfor careful pre-alignment or high-quality initial 3D correspondences, we\nintroduce Stable-SCore: A Stable Registration-based Framework for 3D Shape\nCorrespondence. We first re-purpose a foundation model for 2D character\ncorrespondence that ensures reliable and stable 2D mappings. Crucially, we\npropose a novel Semantic Flow Guided Registration approach that leverages 2D\ncorrespondence to guide mesh deformations. Our framework significantly\nsurpasses existing methods in challenging scenarios, and brings possibilities\nfor a wide array of real applications, as demonstrated in our results.",
      "tldr_zh": "本文提出了一种基于稳定配准的3D形状对应框架Stable-SCore，旨在解决现有functional map方法在复杂场景下，如非等距形状差异等问题上的不足。该框架利用重新设计的2D角色对应基础模型，确保可靠稳定的2D映射。核心在于提出的语义流引导配准方法(Semantic Flow Guided Registration)，该方法利用2D对应关系来引导网格变形。实验结果表明，Stable-SCore在具有挑战性的场景中显著优于现有方法，并为广泛的实际应用带来了可能性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025. Homepage:\n  https://haolinliu97.github.io/Stable-Score/",
      "pdf_url": "http://arxiv.org/pdf/2503.21766v1",
      "published_date": "2025-03-27 17:59:02 UTC",
      "updated_date": "2025-03-27 17:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:30:37.145580"
    },
    {
      "arxiv_id": "2503.21761v1",
      "title": "Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single Video",
      "title_zh": "Uni4D：统一视觉基础模型，用于从单个视频进行 4D 建模\n",
      "authors": [
        "David Yifan Yao",
        "Albert J. Zhai",
        "Shenlong Wang"
      ],
      "abstract": "This paper presents a unified approach to understanding dynamic scenes from\ncasual videos. Large pretrained vision foundation models, such as\nvision-language, video depth prediction, motion tracking, and segmentation\nmodels, offer promising capabilities. However, training a single model for\ncomprehensive 4D understanding remains challenging. We introduce Uni4D, a\nmulti-stage optimization framework that harnesses multiple pretrained models to\nadvance dynamic 3D modeling, including static/dynamic reconstruction, camera\npose estimation, and dense 3D motion tracking. Our results show\nstate-of-the-art performance in dynamic 4D modeling with superior visual\nquality. Notably, Uni4D requires no retraining or fine-tuning, highlighting the\neffectiveness of repurposing visual foundation models for 4D understanding.",
      "tldr_zh": "本文提出了Uni4D，一个多阶段优化框架，旨在从单个视频中统一视觉基础模型，实现动态场景的4D建模。Uni4D利用预训练的视觉语言模型、视频深度预测模型、运动跟踪模型和分割模型等，无需重新训练或微调，即可实现静态/动态重建、相机姿态估计和稠密3D运动跟踪。实验结果表明，Uni4D在动态4D建模方面达到了state-of-the-art的性能，并具有卓越的视觉质量，展示了视觉基础模型在4D理解方面的有效性。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Project page (with code):\n  https://davidyao99.github.io/uni4d",
      "pdf_url": "http://arxiv.org/pdf/2503.21761v1",
      "published_date": "2025-03-27 17:57:32 UTC",
      "updated_date": "2025-03-27 17:57:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:30:49.197672"
    },
    {
      "arxiv_id": "2503.21757v1",
      "title": "Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck",
      "title_zh": "Fwd2Bot：基于双重前向瓶颈的 LVLM 视觉令牌压缩\n",
      "authors": [
        "Adrian Bulat",
        "Yassine Ouali",
        "Georgios Tzimiropoulos"
      ],
      "abstract": "In this work, we aim to compress the vision tokens of a Large Vision Language\nModel (LVLM) into a representation that is simultaneously suitable for (a)\ngenerative and (b) discriminative tasks, (c) is nearly lossless, and (d) is\nstorage-efficient. We propose a novel compression approach, called Fwd2Bot,\nthat uses the LVLM itself to compress the visual information in a task-agnostic\nmanner. At the core of Fwd2bot there exists a \"double-forward pass\" training\nstrategy, whereby, during the first forward pass, the LLM (of the LVLM) creates\na bottleneck by condensing the visual information into a small number of\nsummary tokens. Then, using the same LLM, the second forward pass processes the\nlanguage instruction(s) alongside the summary tokens, used as a direct\nreplacement for the image ones. The training signal is provided by two losses:\nan autoregressive one applied after the second pass that provides a direct\noptimization objective for compression, and a contrastive loss, applied after\nthe first pass, that further boosts the representation strength, especially for\ndiscriminative tasks. The training is further enhanced by stage-specific\nadapters. We accompany the proposed method by an in-depth ablation study.\nOverall, Fwd2Bot results in highly-informative compressed representations\nsuitable for both generative and discriminative tasks. For generative tasks, we\noffer a 2x higher compression rate without compromising the generative\ncapabilities, setting a new state-of-the-art result. For discriminative tasks,\nwe set a new state-of-the-art on image retrieval and compositionality.",
      "tldr_zh": "该论文提出了一种名为Fwd2Bot的新型视觉token压缩方法，旨在将大型视觉语言模型(LVLM)的视觉token压缩成一种适用于生成和判别任务、近乎无损且存储高效的表示。Fwd2Bot利用LVLM本身以任务无关的方式压缩视觉信息，其核心是“双重前向传递”训练策略：第一次前向传递，LLM将视觉信息压缩成少量summary tokens；第二次前向传递，LLM处理语言指令和summary tokens。通过自回归损失和对比损失进行训练，并使用stage-specific adapters进一步增强训练效果。实验表明，Fwd2Bot能够生成高度信息化的压缩表示，适用于生成和判别任务，在生成任务上实现了2倍更高的压缩率，并在图像检索和组合性方面取得了新的state-of-the-art。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21757v1",
      "published_date": "2025-03-27 17:57:07 UTC",
      "updated_date": "2025-03-27 17:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:31:01.461518"
    },
    {
      "arxiv_id": "2503.21747v1",
      "title": "CTRL-O: Language-Controllable Object-Centric Visual Representation Learning",
      "title_zh": "CTRL-O：语言可控的以对象为中心的视觉表征学习\n",
      "authors": [
        "Aniket Didolkar",
        "Andrii Zadaianchuk",
        "Rabiul Awal",
        "Maximilian Seitzer",
        "Efstratios Gavves",
        "Aishwarya Agrawal"
      ],
      "abstract": "Object-centric representation learning aims to decompose visual scenes into\nfixed-size vectors called \"slots\" or \"object files\", where each slot captures a\ndistinct object. Current state-of-the-art object-centric models have shown\nremarkable success in object discovery in diverse domains, including complex\nreal-world scenes. However, these models suffer from a key limitation: they\nlack controllability. Specifically, current object-centric models learn\nrepresentations based on their preconceived understanding of objects, without\nallowing user input to guide which objects are represented. Introducing\ncontrollability into object-centric models could unlock a range of useful\ncapabilities, such as the ability to extract instance-specific representations\nfrom a scene. In this work, we propose a novel approach for user-directed\ncontrol over slot representations by conditioning slots on language\ndescriptions. The proposed ConTRoLlable Object-centric representation learning\napproach, which we term CTRL-O, achieves targeted object-language binding in\ncomplex real-world scenes without requiring mask supervision. Next, we apply\nthese controllable slot representations on two downstream vision language\ntasks: text-to-image generation and visual question answering. The proposed\napproach enables instance-specific text-to-image generation and also achieves\nstrong performance on visual question answering.",
      "tldr_zh": "该论文提出了CTRL-O，一种语言可控的、以对象为中心的视觉表征学习方法。现有方法缺乏可控性，无法根据用户输入来指导对象表征。CTRL-O通过将语言描述作为条件来控制slot表征，从而实现目标对象与语言的绑定，无需mask监督。该方法在复杂的真实场景中实现了可控的slot表征，并成功应用于文本到图像生成和视觉问答两个下游任务，实现了特定实例的文本到图像生成，并在视觉问答任务上取得了良好的性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.21747v1",
      "published_date": "2025-03-27 17:53:50 UTC",
      "updated_date": "2025-03-27 17:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:31:13.264498"
    },
    {
      "arxiv_id": "2503.21735v1",
      "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics",
      "title_zh": "GateLens：一种用于汽车软件发布分析的、具有增强推理能力的大语言模型智能体\n",
      "authors": [
        "Arsham Gholamzadeh Khoee",
        "Shuai Wang",
        "Yinan Yu",
        "Robert Feldt",
        "Dhasarathy Parthasarathy"
      ],
      "abstract": "Ensuring the reliability and effectiveness of software release decisions is\ncritical, particularly in safety-critical domains like automotive systems.\nPrecise analysis of release validation data, often presented in tabular form,\nplays a pivotal role in this process. However, traditional methods that rely on\nmanual analysis of extensive test datasets and validation metrics are prone to\ndelays and high costs. Large Language Models (LLMs) offer a promising\nalternative but face challenges in analytical reasoning, contextual\nunderstanding, handling out-of-scope queries, and processing structured test\ndata consistently; limitations that hinder their direct application in\nsafety-critical scenarios. This paper introduces GateLens, an LLM-based tool\nfor analyzing tabular data in the automotive domain. GateLens translates\nnatural language queries into Relational Algebra (RA) expressions and then\ngenerates optimized Python code. It outperforms the baseline system on\nbenchmarking datasets, achieving higher F1 scores and handling complex and\nambiguous queries with greater robustness. Ablation studies confirm the\ncritical role of the RA module, with performance dropping sharply when omitted.\nIndustrial evaluations reveal that GateLens reduces analysis time by over 80%\nwhile maintaining high accuracy and reliability. As demonstrated by presented\nresults, GateLens achieved high performance without relying on few-shot\nexamples, showcasing strong generalization across various query types from\ndiverse company roles. Insights from deploying GateLens with a partner\nautomotive company offer practical guidance for integrating AI into critical\nworkflows such as release validation. Results show that by automating test\nresult analysis, GateLens enables faster, more informed, and dependable release\ndecisions, and can thus advance software scalability and reliability in\nautomotive systems.",
      "tldr_zh": "该论文提出了GateLens，一个基于LLM的工具，用于汽车软件发布分析中的表格数据分析。GateLens将自然语言查询转换为关系代数(RA)表达式，然后生成优化的Python代码。实验结果表明，GateLens在基准数据集上优于基线系统，实现了更高的F1分数，并且能够更稳健地处理复杂和模糊的查询。工业评估显示，GateLens将分析时间减少了80%以上，同时保持了高精度和可靠性。通过自动化测试结果分析，GateLens能够实现更快、更明智和更可靠的发布决策，从而提高汽车系统中软件的可扩展性和可靠性。RA模块在GateLens中起着关键作用，省略该模块会导致性能急剧下降。\n",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21735v1",
      "published_date": "2025-03-27 17:48:32 UTC",
      "updated_date": "2025-03-27 17:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:31:25.367868"
    },
    {
      "arxiv_id": "2503.21729v1",
      "title": "ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation",
      "title_zh": "ReaRAG：知识引导的推理通过迭代检索增强生成提高大型推理模型的真实性\n",
      "authors": [
        "Zhicheng Lee",
        "Shulin Cao",
        "Jinxin Liu",
        "Jiajie Zhang",
        "Weichuan Liu",
        "Xiaoyin Che",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely\nprimarily on parametric knowledge, limiting factual accuracy. While recent\nworks equip reinforcement learning (RL)-based LRMs with retrieval capabilities,\nthey suffer from overthinking and lack robustness in reasoning, reducing their\neffectiveness in question answering (QA) tasks. To address this, we propose\nReaRAG, a factuality-enhanced reasoning model that explores diverse queries\nwithout excessive iterations. Our solution includes a novel data construction\nframework with an upper bound on the reasoning chain length. Specifically, we\nfirst leverage an LRM to generate deliberate thinking, then select an action\nfrom a predefined action space (Search and Finish). For Search action, a query\nis executed against the RAG engine, where the result is returned as observation\nto guide reasoning steps later. This process iterates until a Finish action is\nchosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach\noutperforms existing baselines on multi-hop QA. Further analysis highlights its\nstrong reflective ability to recognize errors and refine its reasoning\ntrajectory. Our study enhances LRMs' factuality while effectively integrating\nrobust reasoning for Retrieval-Augmented Generation (RAG).",
      "tldr_zh": "该论文提出了ReaRAG，一种知识引导的推理模型，旨在提升大型推理模型(LRMs)的事实准确性。ReaRAG通过迭代检索增强生成(RAG)来探索多样化的查询，避免过度思考。该方法包含一个新颖的数据构建框架，限制了推理链的长度。具体来说，利用LRM生成有意的思考过程，并从预定义的动作空间（搜索和完成）中选择动作。对于搜索动作，查询在RAG引擎中执行，结果作为观察返回，以指导后续的推理步骤。实验表明，ReaRAG在多跳问答任务上优于现有基线，并展现出强大的反思能力，能够识别错误并改进推理轨迹，从而有效地整合了鲁棒的推理能力到RAG中。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21729v1",
      "published_date": "2025-03-27 17:44:18 UTC",
      "updated_date": "2025-03-27 17:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:31:37.399389"
    },
    {
      "arxiv_id": "2503.21720v1",
      "title": "Collab: Controlled Decoding using Mixture of Agents for LLM Alignment",
      "title_zh": "Collab：使用混合智能体进行可控解码，实现 LLM 对齐\n",
      "authors": [
        "Souradip Chakraborty",
        "Sujay Bhatt",
        "Udari Madhushani Sehwag",
        "Soumya Suvra Ghosal",
        "Jiahao Qiu",
        "Mengdi Wang",
        "Dinesh Manocha",
        "Furong Huang",
        "Alec Koppel",
        "Sumitra Ganesh"
      ],
      "abstract": "Alignment of Large Language models (LLMs) is crucial for safe and trustworthy\ndeployment in applications. Reinforcement learning from human feedback (RLHF)\nhas emerged as an effective technique to align LLMs to human preferences and\nbroader utilities, but it requires updating billions of model parameters, which\nis computationally expensive. Controlled Decoding, by contrast, provides a\nmechanism for aligning a model at inference time without retraining. However,\nsingle-agent decoding approaches often struggle to adapt to diverse tasks due\nto the complexity and variability inherent in these tasks. To strengthen the\ntest-time performance w.r.t the target task, we propose a mixture of\nagent-based decoding strategies leveraging the existing off-the-shelf aligned\nLLM policies. Treating each prior policy as an agent in the spirit of mixture\nof agent collaboration, we develop a decoding method that allows for\ninference-time alignment through a token-level selection strategy among\nmultiple agents. For each token, the most suitable LLM is dynamically chosen\nfrom a pool of models based on a long-term utility metric. This\npolicy-switching mechanism ensures optimal model selection at each step,\nenabling efficient collaboration and alignment among LLMs during decoding.\nTheoretical analysis of our proposed algorithm establishes optimal performance\nwith respect to the target task represented via a target reward for the given\noff-the-shelf models. We conduct comprehensive empirical evaluations with\nopen-source aligned models on diverse tasks and preferences, which demonstrates\nthe merits of this approach over single-agent decoding baselines. Notably,\nCollab surpasses the current SoTA decoding strategy, achieving an improvement\nof up to 1.56x in average reward and 71.89% in GPT-4 based win-tie rate.",
      "tldr_zh": "该论文提出了一种名为Collab的受控解码方法，利用混合智能体策略在推理时对LLM进行对齐，无需重新训练模型。Collab将现有的对齐LLM策略视为智能体，通过token级别的选择策略，动态地从模型池中选择最合适的LLM生成token。这种策略切换机制确保每一步都选择最优模型，从而实现LLM之间的有效协作和对齐。理论分析表明，该算法在给定现成模型的情况下，能够实现针对目标任务的最优性能。实验结果表明，Collab在多个任务和偏好上优于单智能体解码基线，在平均奖励方面提升高达1.56倍，在基于GPT-4的胜率方面提升高达71.89%，超越了当前的SoTA解码策略。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.21720v1",
      "published_date": "2025-03-27 17:34:25 UTC",
      "updated_date": "2025-03-27 17:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:31:49.448406"
    },
    {
      "arxiv_id": "2503.21718v1",
      "title": "Outlier dimensions favor frequent tokens in language model",
      "title_zh": "语言模型中的异常维度偏向于频繁出现的 tokens\n",
      "authors": [
        "Iuri Macocco",
        "Nora Graichen",
        "Gemma Boleda",
        "Marco Baroni"
      ],
      "abstract": "We study last-layer outlier dimensions, i.e.dimensions that display extreme\nactivations for the majority of inputs. We show that outlier dimensions arise\nin many different modern language models, and trace their function back to the\nheuristic of constantly predicting frequent words. We further show how a model\ncan block this heuristic when it is not contextually appropriate, by assigning\na counterbalancing weight mass to the remaining dimensions, and we investigate\nwhich model parameters boost outlier dimensions and when they arise during\ntraining. We conclude that outlier dimensions are a specialized mechanism\ndiscovered by many distinct models to implement a useful token prediction\nheuristic.",
      "tldr_zh": "该论文研究了语言模型最后一层中的“离群维度”(outlier dimensions)，即对大多数输入都显示出极端激活的维度。研究发现，许多现代语言模型中都存在离群维度，并且这些维度的功能可以追溯到持续预测高频词的启发式方法。模型可以通过将平衡权重分配给剩余维度来阻止这种启发式方法在不适合上下文时生效。研究还调查了哪些模型参数会增强离群维度，以及它们在训练过程中何时出现。结论是，离群维度是许多不同的模型发现的一种专门机制，用于实现有用的token预测启发式方法。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21718v1",
      "published_date": "2025-03-27 17:30:50 UTC",
      "updated_date": "2025-03-27 17:30:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:32:01.244260"
    },
    {
      "arxiv_id": "2503.21708v1",
      "title": "Elementwise Layer Normalization",
      "title_zh": "逐元素层归一化\n",
      "authors": [
        "Felix Stollenwerk"
      ],
      "abstract": "A recent paper proposed Dynamic Tanh (DyT) as a drop-in replacement for Layer\nNormalization. Although the method is empirically well-motivated and appealing\nfrom a practical point of view, it lacks a theoretical foundation. In this\nwork, we derive DyT mathematically and show that a well-defined approximation\nis needed to do so. By dropping said approximation, an alternative element-wise\ntransformation is obtained, which we call Elementwise Layer Normalization\n(ELN). We demonstrate that ELN resembles Layer Normalization more accurately\nthan DyT does.",
      "tldr_zh": "本文对Dynamic Tanh (DyT)进行了数学推导，发现其成立需要一个近似假设。通过去除该近似，作者提出了一种新的逐元素变换方法，称为Elementwise Layer Normalization (ELN)。实验表明，相比DyT，ELN更接近于传统的Layer Normalization。该研究为理解和改进Layer Normalization提供了一种新的视角。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21708v1",
      "published_date": "2025-03-27 17:20:44 UTC",
      "updated_date": "2025-03-27 17:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:32:13.040335"
    },
    {
      "arxiv_id": "2503.21699v1",
      "title": "MAVERIX: Multimodal Audio-Visual Evaluation Reasoning IndeX",
      "title_zh": "MAVERIX：多模态视听评估推理索引\n",
      "authors": [
        "Liuyue Xie",
        "George Z. Wei",
        "Avik Kuthiala",
        "Ce Zheng",
        "Ananya Bal",
        "Mosam Dabhi",
        "Liting Wen",
        "Taru Rustagi",
        "Ethan Lai",
        "Sushil Khyalia",
        "Rohan Choudhury",
        "Morteza Ziyadi",
        "Xu Zhang",
        "Hao Yang",
        "László A. Jeni"
      ],
      "abstract": "Frontier models have either been language-only or have primarily focused on\nvision and language modalities. Although recent advancements in models with\nvision and audio understanding capabilities have shown substantial progress,\nthe field lacks a standardized evaluation framework for thoroughly assessing\ntheir cross-modality perception performance. We introduce MAVERIX~(Multimodal\nAudio-Visual Evaluation Reasoning IndeX), a novel benchmark with 700 videos and\n2,556 questions explicitly designed to evaluate multimodal models through tasks\nthat necessitate close integration of video and audio information. MAVERIX\nuniquely provides models with audiovisual tasks, closely mimicking the\nmultimodal perceptual experiences available to humans during inference and\ndecision-making processes. To our knowledge, MAVERIX is the first benchmark\naimed explicitly at assessing comprehensive audiovisual integration.\nExperiments with state-of-the-art models, including Gemini 1.5 Pro and o1, show\nperformance approaching human levels (around 70% accuracy), while human experts\nreach near-ceiling performance (95.1%). With standardized evaluation protocols,\na rigorously annotated pipeline, and a public toolkit, MAVERIX establishes a\nchallenging testbed for advancing audiovisual multimodal intelligence.",
      "tldr_zh": "MAVERIX (Multimodal Audio-Visual Evaluation Reasoning IndeX) 是一个新型的基准测试，包含700个视频和2556个问题，旨在评估多模态模型在音视频理解方面的能力。该基准测试通过模拟人类在推理和决策过程中使用的音视频感知体验，提供了一系列需要紧密结合视频和音频信息的任务。实验结果表明，包括Gemini 1.5 Pro和o1在内的先进模型在该基准测试上的表现接近人类水平（约70%准确率），但仍远低于人类专家水平（95.1%）。MAVERIX通过标准化的评估协议、严格的标注流程和公开的工具包，为推进音视频多模态智能提供了一个具有挑战性的测试平台。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21699v1",
      "published_date": "2025-03-27 17:04:33 UTC",
      "updated_date": "2025-03-27 17:04:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:32:25.404037"
    },
    {
      "arxiv_id": "2503.21695v1",
      "title": "AMA-SAM: Adversarial Multi-Domain Alignment of Segment Anything Model for High-Fidelity Histology Nuclei Segmentation",
      "title_zh": "AMA-SAM：用于高保真组织学细胞核分割的 Segment Anything Model 对抗性多域对齐",
      "authors": [
        "Jiahe Qian",
        "Yaoyu Fang",
        "Jinkui Hao",
        "Bo Zhou"
      ],
      "abstract": "Accurate segmentation of cell nuclei in histopathology images is essential\nfor numerous biomedical research and clinical applications. However, existing\ncell nucleus segmentation methods only consider a single dataset (i.e., primary\ndomain), while neglecting to leverage supplementary data from diverse sources\n(i.e., auxiliary domains) to reduce overfitting and enhance the performance.\nAlthough incorporating multiple datasets could alleviate overfitting, it often\nexacerbates performance drops caused by domain shifts. In this work, we\nintroduce Adversarial Multi-domain Alignment of Segment Anything Model\n(AMA-SAM) that extends the Segment Anything Model (SAM) to overcome these\nobstacles through two key innovations. First, we propose a Conditional Gradient\nReversal Layer (CGRL), a multi-domain alignment module that harmonizes features\nfrom diverse domains to promote domain-invariant representation learning while\npreserving crucial discriminative features for the primary dataset. Second, we\naddress SAM's inherent low-resolution output by designing a High-Resolution\nDecoder (HR-Decoder), which directly produces fine-grained segmentation maps in\norder to capture intricate nuclei boundaries in high-resolution histology\nimages. To the best of our knowledge, this is the first attempt to adapt SAM\nfor multi-dataset learning with application to histology nuclei segmentation.\nWe validate our method on several publicly available datasets, demonstrating\nconsistent and significant improvements over state-of-the-art approaches.",
      "tldr_zh": "该论文提出了AMA-SAM，一种用于高保真组织学细胞核分割的对抗性多域对齐的Segment Anything Model。该方法旨在利用来自不同来源的辅助数据，克服现有细胞核分割方法仅考虑单一数据集的局限性，并解决多数据集带来的领域偏移问题。AMA-SAM包含两个关键创新：条件梯度反转层(CGRL)，用于协调来自不同域的特征，促进域不变表示学习；以及高分辨率解码器(HR-Decoder)，直接生成精细的分割图，以捕获高分辨率组织学图像中复杂的细胞核边界。实验结果表明，AMA-SAM在多个公开数据集上优于现有技术水平的方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 4 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21695v1",
      "published_date": "2025-03-27 16:59:39 UTC",
      "updated_date": "2025-03-27 16:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:32:37.405891"
    },
    {
      "arxiv_id": "2503.21694v1",
      "title": "Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data",
      "title_zh": "渐进式渲染蒸馏：使 Stable Diffusion 适应即时文本到网格生成，无需 3D 数据\n",
      "authors": [
        "Zhiyuan Ma",
        "Xinyue Liang",
        "Rongyuan Wu",
        "Xiangyu Zhu",
        "Zhen Lei",
        "Lei Zhang"
      ],
      "abstract": "It is highly desirable to obtain a model that can generate high-quality 3D\nmeshes from text prompts in just seconds. While recent attempts have adapted\npre-trained text-to-image diffusion models, such as Stable Diffusion (SD), into\ngenerators of 3D representations (e.g., Triplane), they often suffer from poor\nquality due to the lack of sufficient high-quality 3D training data. Aiming at\novercoming the data shortage, we propose a novel training scheme, termed as\nProgressive Rendering Distillation (PRD), eliminating the need for 3D\nground-truths by distilling multi-view diffusion models and adapting SD into a\nnative 3D generator. In each iteration of training, PRD uses the U-Net to\nprogressively denoise the latent from random noise for a few steps, and in each\nstep it decodes the denoised latent into 3D output. Multi-view diffusion\nmodels, including MVDream and RichDreamer, are used in joint with SD to distill\ntext-consistent textures and geometries into the 3D outputs through score\ndistillation. Since PRD supports training without 3D ground-truths, we can\neasily scale up the training data and improve generation quality for\nchallenging text prompts with creative concepts. Meanwhile, PRD can accelerate\nthe inference speed of the generation model in just a few steps. With PRD, we\ntrain a Triplane generator, namely TriplaneTurbo, which adds only $2.5\\%$\ntrainable parameters to adapt SD for Triplane generation. TriplaneTurbo\noutperforms previous text-to-3D generators in both efficiency and quality.\nSpecifically, it can produce high-quality 3D meshes in 1.2 seconds and\ngeneralize well for challenging text input. The code is available at\nhttps://github.com/theEricMa/TriplaneTurbo.",
      "tldr_zh": "该论文提出了一种名为渐进式渲染蒸馏 (Progressive Rendering Distillation, PRD) 的新型训练方案，旨在解决文本到3D网格生成中缺乏高质量3D训练数据的问题。PRD通过蒸馏多视角扩散模型，将Stable Diffusion (SD) 改编为原生3D生成器，无需3D ground-truth。该方法利用U-Net逐步去噪潜在变量，并解码为3D输出，同时结合MVDream和RichDreamer等模型，通过score distillation将文本一致的纹理和几何体提炼到3D输出中。PRD训练了一个名为TriplaneTurbo的Triplane生成器，仅增加少量可训练参数即可适配SD进行Triplane生成，在效率和质量上均优于以往的文本到3D生成器，能够在1.2秒内生成高质量3D网格，并能很好地泛化到具有挑战性的文本输入。\n",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted to CVPR 2025.\n  Code:https://github.com/theEricMa/TriplaneTurbo.\n  Demo:https://huggingface.co/spaces/ZhiyuanthePony/TriplaneTurbo",
      "pdf_url": "http://arxiv.org/pdf/2503.21694v1",
      "published_date": "2025-03-27 16:59:15 UTC",
      "updated_date": "2025-03-27 16:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:32:49.642038"
    },
    {
      "arxiv_id": "2503.21683v1",
      "title": "LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku with Self-Play and Reinforcement Learning",
      "title_zh": "LLM-Gomoku：一种基于大型语言模型的五子棋博弈系统，采用自博弈和强化学习策略",
      "authors": [
        "Hui Wang"
      ],
      "abstract": "In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced.",
      "tldr_zh": "该研究提出了一种基于大型语言模型(LLM)的五子棋AI系统，旨在模拟人类学习过程，提升LLM在策略规划和决策方面的能力。该系统通过让模型“读取棋盘”、“理解规则”、“选择策略”和“评估位置”来理解和应用五子棋的策略和逻辑。研究采用自博弈和强化学习来增强模型的能力。实验结果表明，该方法显著改善了棋子位置的选择，解决了生成非法位置的问题，并通过并行位置评估减少了处理时间，经过大量的自博弈训练，模型的五子棋能力得到了显著提升。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21683v1",
      "published_date": "2025-03-27 16:52:25 UTC",
      "updated_date": "2025-03-27 16:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:33:01.298097"
    },
    {
      "arxiv_id": "2503.21674v1",
      "title": "Intelligent IoT Attack Detection Design via ODLLM with Feature Ranking-based Knowledge Base",
      "title_zh": "基于特征排序知识库的 ODLLM 实现智能 IoT 攻击检测设计\n",
      "authors": [
        "Satvik Verma",
        "Qun Wang",
        "E. Wes Bethel"
      ],
      "abstract": "The widespread adoption of Internet of Things (IoT) devices has introduced\nsignificant cybersecurity challenges, particularly with the increasing\nfrequency and sophistication of Distributed Denial of Service (DDoS) attacks.\nTraditional machine learning (ML) techniques often fall short in detecting such\nattacks due to the complexity of blended and evolving patterns. To address\nthis, we propose a novel framework leveraging On-Device Large Language Models\n(ODLLMs) augmented with fine-tuning and knowledge base (KB) integration for\nintelligent IoT network attack detection. By implementing feature ranking\ntechniques and constructing both long and short KBs tailored to model\ncapacities, the proposed framework ensures efficient and accurate detection of\nDDoS attacks while overcoming computational and privacy limitations. Simulation\nresults demonstrate that the optimized framework achieves superior accuracy\nacross diverse attack types, especially when using compact models in edge\ncomputing environments. This work provides a scalable and secure solution for\nreal-time IoT security, advancing the applicability of edge intelligence in\ncybersecurity.",
      "tldr_zh": "该论文提出了一种新颖的物联网(IoT)攻击检测框架，该框架利用片上大语言模型(ODLLM)，通过微调和知识库(KB)集成来增强其能力。该框架采用特征排序技术构建长短知识库，以适应不同的模型容量，从而高效准确地检测DDoS攻击。实验结果表明，该优化框架在各种攻击类型上都实现了卓越的准确性，尤其是在边缘计算环境中使用紧凑模型时。该研究为实时物联网安全提供了一种可扩展且安全的解决方案，提升了边缘智能在网络安全中的应用。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21674v1",
      "published_date": "2025-03-27 16:41:57 UTC",
      "updated_date": "2025-03-27 16:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:33:13.226055"
    },
    {
      "arxiv_id": "2503.21670v1",
      "title": "COMI-LINGUA: Expert Annotated Large-Scale Dataset for Multitask NLP in Hindi-English Code-Mixing",
      "title_zh": "COMI-LINGUA：印地语-英语混合语中用于多任务 NLP 的专家标注的大规模数据集\n",
      "authors": [
        "Rajvee Sheth",
        "Himanshu Beniwal",
        "Mayank Singh"
      ],
      "abstract": "The rapid growth of digital communication has driven the widespread use of\ncode-mixing, particularly Hindi-English, in multilingual communities. Existing\ndatasets often focus on romanized text, have limited scope, or rely on\nsynthetic data, which fails to capture realworld language nuances. Human\nannotations are crucial for assessing the naturalness and acceptability of\ncode-mixed text. To address these challenges, We introduce COMI-LINGUA, the\nlargest manually annotated dataset for code-mixed text, comprising 100,970\ninstances evaluated by three expert annotators in both Devanagari and Roman\nscripts. The dataset supports five fundamental NLP tasks: Language\nIdentification, Matrix Language Identification, Part-of-Speech Tagging, Named\nEntity Recognition, and Translation. We evaluate LLMs on these tasks using\nCOMILINGUA, revealing limitations in current multilingual modeling strategies\nand emphasizing the need for improved code-mixed text processing capabilities.\nCOMI-LINGUA is publically availabe at:\nhttps://huggingface.co/datasets/LingoIITGN/COMI-LINGUA.",
      "tldr_zh": "COMI-LINGUA 是一个大规模人工标注的 Hindi-English 代码混合数据集，包含 100,970 个实例，由三位专家使用 Devanagari 和 Roman 脚本进行评估。该数据集支持五个关键的 NLP 任务：语言识别 (Language Identification)、矩阵语言识别 (Matrix Language Identification)、词性标注 (Part-of-Speech Tagging)、命名实体识别 (Named Entity Recognition) 和翻译。研究人员使用 COMI-LINGUA 评估了大型语言模型 (LLMs) 在这些任务上的表现，揭示了现有模型在处理代码混合文本方面的局限性，强调了改进代码混合文本处理能力的需求。COMI-LINGUA 数据集已公开发布。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21670v1",
      "published_date": "2025-03-27 16:36:39 UTC",
      "updated_date": "2025-03-27 16:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:33:25.296494"
    },
    {
      "arxiv_id": "2503.21668v1",
      "title": "Cognitive Science-Inspired Evaluation of Core Capabilities for Object Understanding in AI",
      "title_zh": "受认知科学启发的 AI 对象理解核心能力评估\n",
      "authors": [
        "Danaja Rutar",
        "Alva Markelius",
        "Konstantinos Voudouris",
        "José Hernández-Orallo",
        "Lucy Cheke"
      ],
      "abstract": "One of the core components of our world models is 'intuitive physics' - an\nunderstanding of objects, space, and causality. This capability enables us to\npredict events, plan action and navigate environments, all of which rely on a\ncomposite sense of objecthood. Despite its importance, there is no single,\nunified account of objecthood, though multiple theoretical frameworks provide\ninsights. In the first part of this paper, we present a comprehensive overview\nof the main theoretical frameworks in objecthood research - Gestalt psychology,\nenactive cognition, and developmental psychology - and identify the core\ncapabilities each framework attributes to object understanding, as well as what\nfunctional roles they play in shaping world models in biological agents. Given\nthe foundational role of objecthood in world modelling, understanding\nobjecthood is also essential in AI. In the second part of the paper, we\nevaluate how current AI paradigms approach and test objecthood capabilities\ncompared to those in cognitive science. We define an AI paradigm as a\ncombination of how objecthood is conceptualised, the methods used for studying\nobjecthood, the data utilised, and the evaluation techniques. We find that,\nwhilst benchmarks can detect that AI systems model isolated aspects of\nobjecthood, the benchmarks cannot detect when AI systems lack functional\nintegration across these capabilities, not solving the objecthood challenge\nfully. Finally, we explore novel evaluation approaches that align with the\nintegrated vision of objecthood outlined in this paper. These methods are\npromising candidates for advancing from isolated object capabilities toward\ngeneral-purpose AI with genuine object understanding in real-world contexts.",
      "tldr_zh": "该论文从认知科学角度出发，探讨了人工智能中物体理解的核心能力。首先，论文回顾了格式塔心理学、能动认知和发展心理学等主要理论框架，并识别了每个框架对物体理解所赋予的核心能力及其在塑造生物智能体世界模型中的作用。然后，论文评估了当前AI范式如何处理和测试物体理解能力，发现现有基准测试虽然可以检测AI系统对物体理解的孤立方面进行建模，但无法检测到AI系统在这些能力之间缺乏功能集成。最后，论文探讨了与本文概述的物体理解的综合愿景相一致的新型评估方法，这些方法有望推动从孤立的物体能力向具有真实物体理解的通用AI发展。\n",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21668v1",
      "published_date": "2025-03-27 16:35:02 UTC",
      "updated_date": "2025-03-27 16:35:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:33:37.421109"
    },
    {
      "arxiv_id": "2503.21657v1",
      "title": "Model Assembly Learning with Heterogeneous Layer Weight Merging",
      "title_zh": "基于异构层权重合并的模型组装学习\n",
      "authors": [
        "Yi-Kai Zhang",
        "Jin Wang",
        "Xu-Xiang Zhong",
        "De-Chuan Zhan",
        "Han-Jia Ye"
      ],
      "abstract": "Model merging acquires general capabilities without extra data or training by\ncombining multiple models' parameters. Previous approaches achieve linear mode\nconnectivity by aligning parameters into the same loss basin using permutation\ninvariance. In this paper, we introduce Model Assembly Learning (MAL), a novel\nparadigm for model merging that iteratively integrates parameters from diverse\nmodels in an open-ended model zoo to enhance the base model's capabilities.\nUnlike previous works that require identical architectures, MAL allows the\nmerging of heterogeneous architectures and selective parameters across layers.\nSpecifically, the base model can incorporate parameters from different layers\nof multiple pre-trained models. We systematically investigate the conditions\nand fundamental settings of heterogeneous parameter merging, addressing all\npossible mismatches in layer widths between the base and target models.\nFurthermore, we establish key laws and provide practical guidelines for\neffectively implementing MAL.",
      "tldr_zh": "本文提出了一种新的模型融合范式——模型组装学习(Model Assembly Learning, MAL)，旨在通过迭代整合来自不同模型的参数，提升基础模型的能力，而无需额外数据或训练。与以往需要相同架构的模型融合方法不同，MAL允许融合异构架构的模型，并选择性地合并跨层的参数。该方法系统地研究了异构参数融合的条件和基本设置，解决了基础模型和目标模型之间层宽度不匹配的问题。此外，本文还建立了关键法则，并为有效实施MAL提供了实用指南。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 Workshop on Neural Network Weights as a New Data Modality",
      "pdf_url": "http://arxiv.org/pdf/2503.21657v1",
      "published_date": "2025-03-27 16:21:53 UTC",
      "updated_date": "2025-03-27 16:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:33:49.012187"
    },
    {
      "arxiv_id": "2503.21646v1",
      "title": "Unlocking the Potential of Past Research: Using Generative AI to Reconstruct Healthcare Simulation Models",
      "title_zh": "释放过往研究的潜力：利用生成式人工智能重建医疗保健模拟模型\n",
      "authors": [
        "Thomas Monks",
        "Alison Harper",
        "Amy Heather"
      ],
      "abstract": "Discrete-event simulation (DES) is widely used in healthcare Operations\nResearch, but the models themselves are rarely shared. This limits their\npotential for reuse and long-term impact in the modelling and healthcare\ncommunities. This study explores the feasibility of using generative artificial\nintelligence (AI) to recreate published models using Free and Open Source\nSoftware (FOSS), based on the descriptions provided in an academic journal.\nUsing a structured methodology, we successfully generated, tested and\ninternally reproduced two DES models, including user interfaces. The reported\nresults were replicated for one model, but not the other, likely due to missing\ninformation on distributions. These models are substantially more complex than\nAI-generated DES models published to date. Given the challenges we faced in\nprompt engineering, code generation, and model testing, we conclude that our\niterative approach to model development, systematic comparison and testing, and\nthe expertise of our team were necessary to the success of our recreated\nsimulation models.",
      "tldr_zh": "该研究探索了利用生成式人工智能(AI)重建医疗保健离散事件仿真(DES)模型的可能性，旨在解决模型共享不足的问题。研究人员使用学术期刊中的描述，利用自由和开源软件(FOSS)成功生成、测试并内部复现了两个DES模型，包括用户界面。其中一个模型的结果被成功复现，而另一个模型则因缺少分布信息而未能复现。研究表明，通过迭代的模型开发方法、系统性的比较和测试，以及团队的专业知识，可以利用生成式AI重建复杂的医疗仿真模型。\n",
      "categories": [
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21646v1",
      "published_date": "2025-03-27 16:10:02 UTC",
      "updated_date": "2025-03-27 16:10:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:34:01.170705"
    },
    {
      "arxiv_id": "2503.21640v1",
      "title": "Towards Fully Automated Decision-Making Systems for Greenhouse Control: Challenges and Opportunities",
      "title_zh": "迈向温室控制全自动决策系统：挑战与机遇\n",
      "authors": [
        "Yongshuai Liu",
        "Taeyeong Choi",
        "Xin Liu"
      ],
      "abstract": "Machine learning has been successful in building control policies to drive a\ncomplex system to desired states in various applications (e.g. games, robotics,\netc.). To be specific, a number of parameters of policy can be automatically\noptimized from the observations of environment to be able to generate a\nsequence of decisions leading to the best performance. In this survey paper, we\nparticularly explore such policy-learning techniques for another unique,\npractical use-case scenario--farming, in which critical decisions (e.g., water\nsupply, heating, etc.) must be made in a timely manner to minimize risks (e.g.,\ndamage to plants) while maximizing the revenue (e.g., healthy crops) in the\nend. We first provide a broad overview of latest studies on it to identify not\nonly domain-specific challenges but opportunities with potential solutions,\nsome of which are suggested as promising directions for future research. Also,\nwe then introduce our successful approach to being ranked second among 46 teams\nat the ''3rd Autonomous Greenhouse Challenge'' to use this specific example to\ndiscuss the lessons learned about important considerations for design to create\nautonomous farm-management systems.",
      "tldr_zh": "该综述探讨了将机器学习策略学习技术应用于温室控制，以实现全自动决策系统的挑战与机遇。文章概述了最新的研究，识别了领域特定的挑战和潜在的解决方案，并为未来的研究方向提出了建议。此外，文章还介绍了作者团队在“第三届自主温室挑战赛”中获得第二名的成功案例，并以此为例讨论了设计自主农业管理系统的重要考虑因素。该研究旨在通过自动优化灌溉、加热等关键决策，在最大化收益的同时最小化风险。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21640v1",
      "published_date": "2025-03-27 16:06:59 UTC",
      "updated_date": "2025-03-27 16:06:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:34:13.241376"
    },
    {
      "arxiv_id": "2503.21634v1",
      "title": "When Astronomy Meets AI: Manazel For Crescent Visibility Prediction in Morocco",
      "title_zh": "当天文学遇上人工智能：用于摩洛哥新月可见性预测的 Manazel\n",
      "authors": [
        "Yassir Lairgi"
      ],
      "abstract": "The accurate determination of the beginning of each Hijri month is essential\nfor religious, cultural, and administrative purposes. Manazel (The code and\ndatasets are available at https://github.com/lairgiyassir/manazel) addresses\nthis challenge in Morocco by leveraging 13 years of crescent visibility data to\nrefine the ODEH criterion, a widely used standard for lunar crescent visibility\nprediction. The study integrates two key features, the Arc of Vision (ARCV) and\nthe total width of the crescent (W), to enhance the accuracy of lunar\nvisibility assessments. A machine learning approach utilizing the Logistic\nRegression algorithm is employed to classify crescent visibility conditions,\nachieving a predictive accuracy of 98.83%. This data-driven methodology offers\na robust and reliable framework for determining the start of the Hijri month,\ncomparing different data classification tools, and improving the consistency of\nlunar calendar calculations in Morocco. The findings demonstrate the\neffectiveness of machine learning in astronomical applications and highlight\nthe potential for further enhancements in the modeling of crescent visibility.",
      "tldr_zh": "该研究提出了Manazel，一个利用机器学习预测新月可见性的系统，旨在提高摩洛哥伊斯兰历的准确性。Manazel基于13年的新月可见性数据，结合Arc of Vision (ARCV)和新月总宽度(W)两个关键特征，改进了ODEH新月可见性标准。研究采用Logistic Regression算法进行新月可见性分类，达到了98.83%的预测准确率。Manazel为确定伊斯兰历的起始提供了可靠的框架，并展示了机器学习在天文应用中的有效性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21634v1",
      "published_date": "2025-03-27 15:56:55 UTC",
      "updated_date": "2025-03-27 15:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-28T17:34:25.311435"
    },
    {
      "arxiv_id": "2503.21620v1",
      "title": "UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning",
      "title_zh": "",
      "authors": [
        "Zhengxi Lu",
        "Yuxiang Chai",
        "Yaxuan Guo",
        "Xi Yin",
        "Liang Liu",
        "Hao Wang",
        "Guanjing Xiong",
        "Hongsheng Li"
      ],
      "abstract": "The recent DeepSeek-R1 has showcased the emergence of reasoning capabilities\nin LLMs through reinforcement learning (RL) with rule-based rewards. Building\non this idea, we are the first to explore how rule-based RL can enhance the\nreasoning capabilities of multimodal large language models (MLLMs) for graphic\nuser interface (GUI) action prediction tasks. To this end, we curate a small\nyet high-quality dataset of 136 challenging tasks, encompassing five common\naction types on mobile devices. We also introduce a unified rule-based action\nreward, enabling model optimization via policy-based algorithms such as Group\nRelative Policy Optimization (GRPO). Experimental results demonstrate that our\nproposed data-efficient model, UI-R1-3B, achieves substantial improvements on\nboth in-domain (ID) and out-of-domain (OOD) tasks. Specifically, on the ID\nbenchmark AndroidControl, the action type accuracy improves by 15%, while\ngrounding accuracy increases by 10.3%, compared with the base model (i.e.\nQwen2.5-VL-3B). On the OOD GUI grounding benchmark ScreenSpot-Pro, our model\nsurpasses the base model by 6.0% and achieves competitive performance with\nlarger models (e.g., OS-Atlas-7B), which are trained via supervised fine-tuning\n(SFT) on 76K data. These results underscore the potential of rule-based\nreinforcement learning to advance GUI understanding and control, paving the way\nfor future research in this domain.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21620v1",
      "published_date": "2025-03-27 15:39:30 UTC",
      "updated_date": "2025-03-27 15:39:30 UTC",
      "processing_status": "in_progress",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:34:13.245891"
    },
    {
      "arxiv_id": "2503.21615v1",
      "title": "A Measure Based Generalizable Approach to Understandability",
      "title_zh": "",
      "authors": [
        "Vikas Kushwaha",
        "Sruti Srinivasa Ragavan",
        "Subhajit Roy"
      ],
      "abstract": "Successful agent-human partnerships require that any agent generated\ninformation is understandable to the human, and that the human can easily steer\nthe agent towards a goal. Such effective communication requires the agent to\ndevelop a finer-level notion of what is understandable to the human.\nState-of-the-art agents, including LLMs, lack this detailed notion of\nunderstandability because they only capture average human sensibilities from\nthe training data, and therefore afford limited steerability (e.g., requiring\nnon-trivial prompt engineering).\n  In this paper, instead of only relying on data, we argue for developing\ngeneralizable, domain-agnostic measures of understandability that can be used\nas directives for these agents. Existing research on understandability measures\nis fragmented, we survey various such efforts across domains, and lay a\ncognitive-science-rooted groundwork for more coherent and domain-agnostic\nresearch investigations in future.",
      "tldr_zh": "",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.21615v1",
      "published_date": "2025-03-27 15:36:49 UTC",
      "updated_date": "2025-03-27 15:36:49 UTC",
      "processing_status": "in_progress",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:34:13.248308"
    },
    {
      "arxiv_id": "2503.21602v1",
      "title": "GenEdit: Compounding Operators and Continuous Improvement to Tackle Text-to-SQL in the Enterprise",
      "title_zh": "",
      "authors": [
        "Karime Maamari",
        "Connor Landy",
        "Amine Mhedhbi"
      ],
      "abstract": "Recent advancements in Text-to-SQL, driven by large language models, are\ndemocratizing data access. Despite these advancements, enterprise deployments\nremain challenging due to the need to capture business-specific knowledge,\nhandle complex queries, and meet expectations of continuous improvements. To\naddress these issues, we designed and implemented GenEdit: our Text-to-SQL\ngeneration system that improves with user feedback. GenEdit builds and\nmaintains a company-specific knowledge set, employs a pipeline of operators\ndecomposing SQL generation, and uses feedback to update its knowledge set to\nimprove future SQL generations.\n  We describe GenEdit's architecture made of two core modules: (i) decomposed\nSQL generation; and (ii) knowledge set edits based on user feedback. For\ngeneration, GenEdit leverages compounding operators to improve knowledge\nretrieval and to create a plan as chain-of-thought steps that guides\ngeneration. GenEdit first retrieves relevant examples in an initial retrieval\nstage where original SQL queries are decomposed into sub-statements, clauses or\nsub-queries. It then also retrieves instructions and schema elements. Using the\nretrieved contextual information, GenEdit then generates step-by-step plan in\nnatural language on how to produce the query. Finally, GenEdit uses the plan to\ngenerate SQL, minimizing the need for model reasoning, which enhances complex\nSQL generation. If necessary, GenEdit regenerates the query based on syntactic\nand semantic errors. The knowledge set edits are recommended through an\ninteractive copilot, allowing users to iterate on their feedback and to\nregenerate SQL queries as needed. Each generation uses staged edits which\nupdate the generation prompt. Once the feedback is submitted, it gets merged\nafter passing regression testing and obtaining an approval, improving future\ngenerations.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21602v1",
      "published_date": "2025-03-27 15:22:02 UTC",
      "updated_date": "2025-03-27 15:22:02 UTC",
      "processing_status": "in_progress",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:34:13.251745"
    },
    {
      "arxiv_id": "2503.21598v1",
      "title": "Prompt, Divide, and Conquer: Bypassing Large Language Model Safety Filters via Segmented and Distributed Prompt Processing",
      "title_zh": "",
      "authors": [
        "Johan Wahréus",
        "Ahmed Hussain",
        "Panos Papadimitratos"
      ],
      "abstract": "Large Language Models (LLMs) have transformed task automation and content\ngeneration across various domains while incorporating safety filters to prevent\nmisuse. We introduce a novel jailbreaking framework that employs distributed\nprompt processing combined with iterative refinements to bypass these safety\nmeasures, particularly in generating malicious code. Our architecture consists\nof four key modules: prompt segmentation, parallel processing, response\naggregation, and LLM-based jury evaluation. Tested on 500 malicious prompts\nacross 10 cybersecurity categories, the framework achieves a 73.2% Success Rate\n(SR) in generating malicious code. Notably, our comparative analysis reveals\nthat traditional single-LLM judge evaluation overestimates SRs (93.8%) compared\nto our LLM jury system (73.2%), with manual verification confirming that\nsingle-judge assessments often accept incomplete implementations. Moreover, we\ndemonstrate that our distributed architecture improves SRs by 12% over the\nnon-distributed approach in an ablation study, highlighting both the\neffectiveness of distributed prompt processing and the importance of robust\nevaluation methodologies in assessing jailbreak attempts.",
      "tldr_zh": "",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages; 26 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21598v1",
      "published_date": "2025-03-27 15:19:55 UTC",
      "updated_date": "2025-03-27 15:19:55 UTC",
      "processing_status": "in_progress",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:34:13.254998"
    },
    {
      "arxiv_id": "2503.21592v1",
      "title": "Critical Iterative Denoising: A Discrete Generative Model Applied to Graphs",
      "title_zh": "",
      "authors": [
        "Yoann Boget",
        "Alexandros Kalousis"
      ],
      "abstract": "Discrete Diffusion and Flow Matching models have significantly advanced\ngenerative modeling for discrete structures, including graphs. However, the\ntime dependencies in the noising process of these models lead to error\naccumulation and propagation during the backward process. This issue,\nparticularly pronounced in mask diffusion, is a known limitation in sequence\nmodeling and, as we demonstrate, also impacts discrete diffusion models for\ngraphs.\n  To address this problem, we propose a novel framework called Iterative\nDenoising, which simplifies discrete diffusion and circumvents the issue by\nassuming conditional independence across time. Additionally, we enhance our\nmodel by incorporating a Critic, which during generation selectively retains or\ncorrupts elements in an instance based on their likelihood under the data\ndistribution. Our empirical evaluations demonstrate that the proposed method\nsignificantly outperforms existing discrete diffusion baselines in graph\ngeneration tasks.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21592v1",
      "published_date": "2025-03-27 15:08:58 UTC",
      "updated_date": "2025-03-27 15:08:58 UTC",
      "processing_status": "in_progress",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:34:25.316859"
    },
    {
      "arxiv_id": "2503.21581v1",
      "title": "AlignDiff: Learning Physically-Grounded Camera Alignment via Diffusion",
      "title_zh": "",
      "authors": [
        "Liuyue Xie",
        "Jiancong Guo",
        "Ozan Cakmakci",
        "Andre Araujo",
        "Laszlo A. Jeni",
        "Zhiheng Jia"
      ],
      "abstract": "Accurate camera calibration is a fundamental task for 3D perception,\nespecially when dealing with real-world, in-the-wild environments where complex\noptical distortions are common. Existing methods often rely on pre-rectified\nimages or calibration patterns, which limits their applicability and\nflexibility. In this work, we introduce a novel framework that addresses these\nchallenges by jointly modeling camera intrinsic and extrinsic parameters using\na generic ray camera model. Unlike previous approaches, AlignDiff shifts focus\nfrom semantic to geometric features, enabling more accurate modeling of local\ndistortions. We propose AlignDiff, a diffusion model conditioned on geometric\npriors, enabling the simultaneous estimation of camera distortions and scene\ngeometry. To enhance distortion prediction, we incorporate edge-aware\nattention, focusing the model on geometric features around image edges, rather\nthan semantic content. Furthermore, to enhance generalizability to real-world\ncaptures, we incorporate a large database of ray-traced lenses containing over\nthree thousand samples. This database characterizes the distortion inherent in\na diverse variety of lens forms. Our experiments demonstrate that the proposed\nmethod significantly reduces the angular error of estimated ray bundles by ~8.2\ndegrees and overall calibration accuracy, outperforming existing approaches on\nchallenging, real-world datasets.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21581v1",
      "published_date": "2025-03-27 14:59:59 UTC",
      "updated_date": "2025-03-27 14:59:59 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898765"
    },
    {
      "arxiv_id": "2503.21571v1",
      "title": "Magnitude-Phase Dual-Path Speech Enhancement Network based on Self-Supervised Embedding and Perceptual Contrast Stretch Boosting",
      "title_zh": "",
      "authors": [
        "Alimjan Mattursun",
        "Liejun Wang",
        "Yinfeng Yu",
        "Chunyang Ma"
      ],
      "abstract": "Speech self-supervised learning (SSL) has made great progress in various\nspeech processing tasks, but there is still room for improvement in speech\nenhancement (SE). This paper presents BSP-MPNet, a dual-path framework that\ncombines self-supervised features with magnitude-phase information for SE. The\napproach starts by applying the perceptual contrast stretching (PCS) algorithm\nto enhance the magnitude-phase spectrum. A magnitude-phase 2D coarse (MP-2DC)\nencoder then extracts coarse features from the enhanced spectrum. Next, a\nfeature-separating self-supervised learning (FS-SSL) model generates\nself-supervised embeddings for the magnitude and phase components separately.\nThese embeddings are fused to create cross-domain feature representations.\nFinally, two parallel RNN-enhanced multi-attention (REMA) mask decoders refine\nthe features, apply them to the mask, and reconstruct the speech signal. We\nevaluate BSP-MPNet on the VoiceBank+DEMAND and WHAMR! datasets. Experimental\nresults show that BSP-MPNet outperforms existing methods under various noise\nconditions, providing new directions for self-supervised speech enhancement\nresearch. The implementation of the BSP-MPNet code is available\nonline\\footnote[2]{https://github.com/AlimMat/BSP-MPNet. \\label{s1}}",
      "tldr_zh": "",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Main paper (6 pages). Accepted for publication by ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.21571v1",
      "published_date": "2025-03-27 14:52:06 UTC",
      "updated_date": "2025-03-27 14:52:06 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898768"
    },
    {
      "arxiv_id": "2503.21558v1",
      "title": "A Local Perspective-based Model for Overlapping Community Detection",
      "title_zh": "",
      "authors": [
        "Gaofeng Zhou",
        "Rui-Feng Wang",
        "Kangning Cui"
      ],
      "abstract": "Community detection, which identifies densely connected node clusters with\nsparse between-group links, is vital for analyzing network structure and\nfunction in real-world systems. Most existing community detection methods based\non GCNs primarily focus on node-level information while overlooking\ncommunity-level features, leading to performance limitations on large-scale\nnetworks. To address this issue, we propose LQ-GCN, an overlapping community\ndetection model from a local community perspective. LQ-GCN employs a\nBernoulli-Poisson model to construct a community affiliation matrix and form an\nend-to-end detection framework. By adopting local modularity as the objective\nfunction, the model incorporates local community information to enhance the\nquality and accuracy of clustering results. Additionally, the conventional GCNs\narchitecture is optimized to improve the model capability in identifying\noverlapping communities in large-scale networks. Experimental results\ndemonstrate that LQ-GCN achieves up to a 33% improvement in Normalized Mutual\nInformation (NMI) and a 26.3% improvement in Recall compared to baseline models\nacross multiple real-world benchmark datasets.",
      "tldr_zh": "",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "10 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.21558v1",
      "published_date": "2025-03-27 14:43:42 UTC",
      "updated_date": "2025-03-27 14:43:42 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898772"
    },
    {
      "arxiv_id": "2503.21557v1",
      "title": "debug-gym: A Text-Based Environment for Interactive Debugging",
      "title_zh": "",
      "authors": [
        "Xingdi Yuan",
        "Morgane M Moss",
        "Charbel El Feghali",
        "Chinmay Singh",
        "Darya Moldavskaya",
        "Drew MacPhee",
        "Lucas Caccia",
        "Matheus Pereira",
        "Minseon Kim",
        "Alessandro Sordoni",
        "Marc-Alexandre Côté"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly relied upon for coding tasks,\nyet in most scenarios it is assumed that all relevant information can be either\naccessed in context or matches their training data. We posit that LLMs can\nbenefit from the ability to interactively explore a codebase to gather the\ninformation relevant to their task. To achieve this, we present a textual\nenvironment, namely debug-gym, for developing LLM-based agents in an\ninteractive coding setting. Our environment is lightweight and provides a\npreset of useful tools, such as a Python debugger (pdb), designed to facilitate\nan LLM-based agent's interactive debugging. Beyond coding and debugging tasks,\nthis approach can be generalized to other tasks that would benefit from\ninformation-seeking behavior by an LLM agent.",
      "tldr_zh": "",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21557v1",
      "published_date": "2025-03-27 14:43:28 UTC",
      "updated_date": "2025-03-27 14:43:28 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898776"
    },
    {
      "arxiv_id": "2503.21544v1",
      "title": "SWI: Speaking with Intent in Large Language Models",
      "title_zh": "",
      "authors": [
        "Yuwei Yin",
        "EunJeong Hwang",
        "Giuseppe Carenini"
      ],
      "abstract": "Intent, typically clearly formulated and planned, functions as a cognitive\nframework for reasoning and problem-solving. This paper introduces the concept\nof Speaking with Intent (SWI) in large language models (LLMs), where the\nexplicitly generated intent encapsulates the model's underlying intention and\nprovides high-level planning to guide subsequent analysis and communication. By\nemulating deliberate and purposeful thoughts in the human mind, SWI is\nhypothesized to enhance the reasoning capabilities and generation quality of\nLLMs. Extensive experiments on mathematical reasoning benchmarks consistently\ndemonstrate the superiority of Speaking with Intent over Baseline (i.e.,\ngeneration without explicit intent). Moreover, SWI outperforms answer-trigger\nprompting methods Chain-of-Thought and Plan-and-Solve and maintains competitive\nperformance with the strong method ARR (Analyzing, Retrieving, and Reasoning).\nAdditionally, the effectiveness and generalizability of SWI are solidified on\nreasoning-intensive question answering (QA) and text summarization benchmarks,\nwhere SWI brings consistent improvement to the Baseline generation. In text\nsummarization, SWI-generated summaries exhibit greater accuracy, conciseness,\nand factual correctness, with fewer hallucinations. Furthermore, human\nevaluations verify the coherence, effectiveness, and interpretability of the\nintent produced by SWI. This proof-of-concept study creates a novel avenue for\nenhancing LLMs' reasoning abilities with cognitive notions.",
      "tldr_zh": "",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages. Code: https://github.com/YuweiYin/SWI",
      "pdf_url": "http://arxiv.org/pdf/2503.21544v1",
      "published_date": "2025-03-27 14:34:28 UTC",
      "updated_date": "2025-03-27 14:34:28 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898779"
    },
    {
      "arxiv_id": "2503.21541v1",
      "title": "LOCATEdit: Graph Laplacian Optimized Cross Attention for Localized Text-Guided Image Editing",
      "title_zh": "",
      "authors": [
        "Achint Soni",
        "Meet Soni",
        "Sirisha Rambhatla"
      ],
      "abstract": "Text-guided image editing aims to modify specific regions of an image\naccording to natural language instructions while maintaining the general\nstructure and the background fidelity. Existing methods utilize masks derived\nfrom cross-attention maps generated from diffusion models to identify the\ntarget regions for modification. However, since cross-attention mechanisms\nfocus on semantic relevance, they struggle to maintain the image integrity. As\na result, these methods often lack spatial consistency, leading to editing\nartifacts and distortions. In this work, we address these limitations and\nintroduce LOCATEdit, which enhances cross-attention maps through a graph-based\napproach utilizing self-attention-derived patch relationships to maintain\nsmooth, coherent attention across image regions, ensuring that alterations are\nlimited to the designated items while retaining the surrounding structure.\n\\method consistently and substantially outperforms existing baselines on\nPIE-Bench, demonstrating its state-of-the-art performance and effectiveness on\nvarious editing tasks. Code can be found on\nhttps://github.com/LOCATEdit/LOCATEdit/",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21541v1",
      "published_date": "2025-03-27 14:32:17 UTC",
      "updated_date": "2025-03-27 14:32:17 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898783"
    },
    {
      "arxiv_id": "2503.21530v1",
      "title": "Low-Resource Transliteration for Roman-Urdu and Urdu Using Transformer-Based Models",
      "title_zh": "",
      "authors": [
        "Umer Butt",
        "Stalin Veranasi",
        "Günter Neumann"
      ],
      "abstract": "As the Information Retrieval (IR) field increasingly recognizes the\nimportance of inclusivity, addressing the needs of low-resource languages\nremains a significant challenge. Transliteration between Urdu and its Romanized\nform, Roman Urdu, remains underexplored despite the widespread use of both\nscripts in South Asia. Prior work using RNNs on the Roman-Urdu-Parl dataset\nshowed promising results but suffered from poor domain adaptability and limited\nevaluation. We propose a transformer-based approach using the m2m100\nmultilingual translation model, enhanced with masked language modeling (MLM)\npretraining and fine-tuning on both Roman-Urdu-Parl and the domain-diverse\nDakshina dataset. To address previous evaluation flaws, we introduce rigorous\ndataset splits and assess performance using BLEU, character-level BLEU, and\nCHRF. Our model achieves strong transliteration performance, with Char-BLEU\nscores of 96.37 for Urdu->Roman-Urdu and 97.44 for Roman-Urdu->Urdu. These\nresults outperform both RNN baselines and GPT-4o Mini and demonstrate the\neffectiveness of multilingual transfer learning for low-resource\ntransliteration tasks.",
      "tldr_zh": "",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21530v1",
      "published_date": "2025-03-27 14:18:50 UTC",
      "updated_date": "2025-03-27 14:18:50 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898787"
    },
    {
      "arxiv_id": "2503.21522v1",
      "title": "MONO2REST: Identifying and Exposing Microservices: a Reusable RESTification Approach",
      "title_zh": "",
      "authors": [
        "Matthéo Lecrivain",
        "Hanifa Barry",
        "Dalila Tamzalit",
        "Houari Sahraoui"
      ],
      "abstract": "The microservices architectural style has become the de facto standard for\nlarge-scale cloud applications, offering numerous benefits in scalability,\nmaintainability, and deployment flexibility. Many organizations are pursuing\nthe migration of legacy monolithic systems to a microservices architecture.\nHowever, this process is challenging, risky, time-intensive, and\nprone-to-failure while several organizations lack necessary financial\nresources, time, or expertise to set up this migration process. So, rather than\ntrying to migrate a legacy system where migration is risky or not feasible, we\nsuggest exposing it as a microservice application without without having to\nmigrate it. In this paper, we present a reusable, automated, two-phase approach\nthat combines evolutionary algorithms with machine learning techniques. In the\nfirst phase, we identify microservices at the method level using a\nmulti-objective genetic algorithm that considers both structural and semantic\ndependencies between methods. In the second phase, we generate REST APIs for\neach identified microservice using a classification algorithm to assign HTTP\nmethods and endpoints. We evaluated our approach with a case study on the\nSpring PetClinic application, which has both monolithic and microservices\nimplementations that serve as ground truth for comparison. Results demonstrate\nthat our approach successfully aligns identified microservices with those in\nthe reference microservices implementation, highlighting its effectiveness in\nservice identification and API generation.",
      "tldr_zh": "",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21522v1",
      "published_date": "2025-03-27 14:10:33 UTC",
      "updated_date": "2025-03-27 14:10:33 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898790"
    },
    {
      "arxiv_id": "2503.21514v1",
      "title": "Quantitative Evaluation of Quantum/Classical Neural Network Using a Game Solver Metric",
      "title_zh": "",
      "authors": [
        "Suzukaze Kamei",
        "Hideaki Kawaguchi",
        "Shin Nishio",
        "Tatakahiko Satoh"
      ],
      "abstract": "To evaluate the performance of quantum computing systems relative to\nclassical counterparts and explore the potential for quantum advantage, we\npropose a game-solving benchmark based on Elo ratings in the game of\ntic-tac-toe. We compare classical convolutional neural networks (CNNs), quantum\nconvolutional neural networks (QCNNs), and hybrid classical-quantum models by\nassessing their performance against a random-move agent in automated matches.\nAdditionally, we implement a QCNN integrated with quantum communication and\nevaluate its performance to quantify the overhead introduced by noisy quantum\nchannels. Our results show that the classical-quantum hybrid model achieves Elo\nratings comparable to those of classical CNNs, while the standalone QCNN\nunderperforms under current hardware constraints. The communication overhead\nwas found to be modest. These findings demonstrate the viability of using\ngame-based benchmarks for evaluating quantum computing systems and suggest that\nquantum communication can be incorporated with limited impact on performance,\nproviding a foundation for future hybrid quantum applications.",
      "tldr_zh": "",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "11 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21514v1",
      "published_date": "2025-03-27 14:05:16 UTC",
      "updated_date": "2025-03-27 14:05:16 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898794"
    },
    {
      "arxiv_id": "2503.21504v1",
      "title": "Keyword-Oriented Multimodal Modeling for Euphemism Identification",
      "title_zh": "",
      "authors": [
        "Yuxue Hu",
        "Junsong Li",
        "Meixuan Chen",
        "Dongyu Su",
        "Tongguan Wang",
        "Ying Sha"
      ],
      "abstract": "Euphemism identification deciphers the true meaning of euphemisms, such as\nlinking \"weed\" (euphemism) to \"marijuana\" (target keyword) in illicit texts,\naiding content moderation and combating underground markets. While existing\nmethods are primarily text-based, the rise of social media highlights the need\nfor multimodal analysis, incorporating text, images, and audio. However, the\nlack of multimodal datasets for euphemisms limits further research. To address\nthis, we regard euphemisms and their corresponding target keywords as keywords\nand first introduce a keyword-oriented multimodal corpus of euphemisms\n(KOM-Euph), involving three datasets (Drug, Weapon, and Sexuality), including\ntext, images, and speech. We further propose a keyword-oriented multimodal\neuphemism identification method (KOM-EI), which uses cross-modal feature\nalignment and dynamic fusion modules to explicitly utilize the visual and audio\nfeatures of the keywords for efficient euphemism identification. Extensive\nexperiments demonstrate that KOM-EI outperforms state-of-the-art models and\nlarge language models, and show the importance of our multimodal datasets.",
      "tldr_zh": "",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21504v1",
      "published_date": "2025-03-27 13:45:35 UTC",
      "updated_date": "2025-03-27 13:45:35 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898798"
    },
    {
      "arxiv_id": "2503.21495v1",
      "title": "Adaptive Resampling with Bootstrap for Noisy Multi-Objective Optimization Problems",
      "title_zh": "",
      "authors": [
        "Timo Budszuhn",
        "Mark Joachim Krallmann",
        "Daniel Horn"
      ],
      "abstract": "The challenge of noisy multi-objective optimization lies in the constant\ntrade-off between exploring new decision points and improving the precision of\nknown points through resampling. This decision should take into account both\nthe variability of the objective functions and the current estimate of a point\nin relation to the Pareto front. Since the amount and distribution of noise are\ngenerally unknown, it is desirable for a decision function to be highly\nadaptive to the properties of the optimization problem. This paper presents a\nresampling decision function that incorporates the stochastic nature of the\noptimization problem by using bootstrapping and the probability of dominance.\nThe distribution-free estimation of the probability of dominance is achieved\nusing bootstrap estimates of the means. To make the procedure applicable even\nwith very few observations, we transfer the distribution observed at other\ndecision points. The efficiency of this resampling approach is demonstrated by\napplying it in the NSGA-II algorithm with a sequential resampling procedure\nunder multiple noise variations.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "90C29",
        "G.1.6"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages. 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21495v1",
      "published_date": "2025-03-27 13:32:42 UTC",
      "updated_date": "2025-03-27 13:32:42 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898802"
    },
    {
      "arxiv_id": "2503.21474v1",
      "title": "The Procedural Content Generation Benchmark: An Open-source Testbed for Generative Challenges in Games",
      "title_zh": "",
      "authors": [
        "Ahmed Khalifa",
        "Roberto Gallotta",
        "Matthew Barthet",
        "Antonios Liapis",
        "Julian Togelius",
        "Georgios N. Yannakakis"
      ],
      "abstract": "This paper introduces the Procedural Content Generation Benchmark for\nevaluating generative algorithms on different game content creation tasks. The\nbenchmark comes with 12 game-related problems with multiple variants on each\nproblem. Problems vary from creating levels of different kinds to creating rule\nsets for simple arcade games. Each problem has its own content representation,\ncontrol parameters, and evaluation metrics for quality, diversity, and\ncontrollability. This benchmark is intended as a first step towards a\nstandardized way of comparing generative algorithms. We use the benchmark to\nscore three baseline algorithms: a random generator, an evolution strategy, and\na genetic algorithm. Results show that some problems are easier to solve than\nothers, as well as the impact the chosen objective has on quality, diversity,\nand controllability of the generated artifacts.",
      "tldr_zh": "",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 4 figures, 2 tables, published at FDG2025",
      "pdf_url": "http://arxiv.org/pdf/2503.21474v1",
      "published_date": "2025-03-27 13:05:40 UTC",
      "updated_date": "2025-03-27 13:05:40 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898806"
    },
    {
      "arxiv_id": "2503.21465v1",
      "title": "Retinal Fundus Multi-Disease Image Classification using Hybrid CNN-Transformer-Ensemble Architectures",
      "title_zh": "",
      "authors": [
        "Deependra Singh",
        "Saksham Agarwal",
        "Subhankar Mishra"
      ],
      "abstract": "Our research is motivated by the urgent global issue of a large population\naffected by retinal diseases, which are evenly distributed but underserved by\nspecialized medical expertise, particularly in non-urban areas. Our primary\nobjective is to bridge this healthcare gap by developing a comprehensive\ndiagnostic system capable of accurately predicting retinal diseases solely from\nfundus images. However, we faced significant challenges due to limited, diverse\ndatasets and imbalanced class distributions. To overcome these issues, we have\ndevised innovative strategies. Our research introduces novel approaches,\nutilizing hybrid models combining deeper Convolutional Neural Networks (CNNs),\nTransformer encoders, and ensemble architectures sequentially and in parallel\nto classify retinal fundus images into 20 disease labels. Our overarching goal\nis to assess these advanced models' potential in practical applications, with a\nstrong focus on enhancing retinal disease diagnosis accuracy across a broader\nspectrum of conditions. Importantly, our efforts have surpassed baseline model\nresults, with the C-Tran ensemble model emerging as the leader, achieving a\nremarkable model score of 0.9166, surpassing the baseline score of 0.9.\nAdditionally, experiments with the IEViT model showcased equally promising\noutcomes with improved computational efficiency. We've also demonstrated the\neffectiveness of dynamic patch extraction and the integration of domain\nknowledge in computer vision tasks. In summary, our research strives to\ncontribute significantly to retinal disease diagnosis, addressing the critical\nneed for accessible healthcare solutions in underserved regions while aiming\nfor comprehensive and accurate disease prediction.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T10, 68T45, 92C55",
        "I.2.10; I.5.4; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 3 figures, 7 tables. Conference paper presented at the\n  International Health Informatics Conference (IHIC 2023)",
      "pdf_url": "http://arxiv.org/pdf/2503.21465v1",
      "published_date": "2025-03-27 12:55:07 UTC",
      "updated_date": "2025-03-27 12:55:07 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898810"
    },
    {
      "arxiv_id": "2503.21464v1",
      "title": "Harnessing Chain-of-Thought Metadata for Task Routing and Adversarial Prompt Detection",
      "title_zh": "",
      "authors": [
        "Ryan Marinelli",
        "Josef Pichlmeier",
        "Tamas Bisztray"
      ],
      "abstract": "In this work, we propose a metric called Number of Thoughts (NofT) to\ndetermine the difficulty of tasks pre-prompting and support Large Language\nModels (LLMs) in production contexts. By setting thresholds based on the number\nof thoughts, this metric can discern the difficulty of prompts and support more\neffective prompt routing. A 2% decrease in latency is achieved when routing\nprompts from the MathInstruct dataset through quantized, distilled versions of\nDeepseek with 1.7 billion, 7 billion, and 14 billion parameters. Moreover, this\nmetric can be used to detect adversarial prompts used in prompt injection\nattacks with high efficacy. The Number of Thoughts can inform a classifier that\nachieves 95% accuracy in adversarial prompt detection. Our experiments ad\ndatasets used are available on our GitHub page:\nhttps://github.com/rymarinelli/Number_Of_Thoughts/tree/main.",
      "tldr_zh": "",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21464v1",
      "published_date": "2025-03-27 12:54:00 UTC",
      "updated_date": "2025-03-27 12:54:00 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898813"
    },
    {
      "arxiv_id": "2503.21463v1",
      "title": "Unveiling Latent Information in Transaction Hashes: Hypergraph Learning for Ethereum Ponzi Scheme Detection",
      "title_zh": "",
      "authors": [
        "Junhao Wu",
        "Yixin Yang",
        "Chengxiang Jin",
        "Silu Mu",
        "Xiaolei Qian",
        "Jiajun Zhou",
        "Shanqing Yu",
        "Qi Xuan"
      ],
      "abstract": "With the widespread adoption of Ethereum, financial frauds such as Ponzi\nschemes have become increasingly rampant in the blockchain ecosystem, posing\nsignificant threats to the security of account assets. Existing Ethereum fraud\ndetection methods typically model account transactions as graphs, but this\napproach primarily focuses on binary transactional relationships between\naccounts, failing to adequately capture the complex multi-party interaction\npatterns inherent in Ethereum. To address this, we propose a hypergraph\nmodeling method for the Ponzi scheme detection method in Ethereum, called\nHyperDet. Specifically, we treat transaction hashes as hyperedges that connect\nall the relevant accounts involved in a transaction. Additionally, we design a\ntwo-step hypergraph sampling strategy to significantly reduce computational\ncomplexity. Furthermore, we introduce a dual-channel detection module,\nincluding the hypergraph detection channel and the hyper-homo graph detection\nchannel, to be compatible with existing detection methods. Experimental results\nshow that, compared to traditional homogeneous graph-based methods, the\nhyper-homo graph detection channel achieves significant performance\nimprovements, demonstrating the superiority of hypergraph in Ponzi scheme\ndetection. This research offers innovations for modeling complex relationships\nin blockchain data.",
      "tldr_zh": "",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21463v1",
      "published_date": "2025-03-27 12:52:47 UTC",
      "updated_date": "2025-03-27 12:52:47 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898817"
    },
    {
      "arxiv_id": "2503.21435v1",
      "title": "Graph-to-Vision: Multi-graph Understanding and Reasoning using Vision-Language Models",
      "title_zh": "",
      "authors": [
        "Ruizhou Li",
        "Haiyun Jiang"
      ],
      "abstract": "Graph Neural Networks (GNNs), as the dominant paradigm for graph-structured\nlearning, have long faced dual challenges of exponentially escalating\ncomputational complexity and inadequate cross-scenario generalization\ncapability. With the rapid advancement of multimodal learning, Vision-Language\nModels (VLMs) have demonstrated exceptional cross-modal relational reasoning\ncapabilities and generalization capacities, thereby opening up novel pathways\nfor overcoming the inherent limitations of conventional graph learning\nparadigms. However, current research predominantly concentrates on\ninvestigating the single-graph reasoning capabilities of VLMs, which\nfundamentally fails to address the critical requirement for coordinated\nreasoning across multiple heterogeneous graph data in real-world application\nscenarios. To address these limitations, we propose the first multi-graph joint\nreasoning benchmark for VLMs. Our benchmark encompasses four graph categories:\nknowledge graphs, flowcharts, mind maps, and route maps,with each graph group\naccompanied by three progressively challenging instruction-response pairs.\nLeveraging this benchmark, we conducted comprehensive capability assessments of\nstate-of-the-art VLMs and performed fine-tuning on open-source models. This\nstudy not only addresses the underexplored evaluation gap in multi-graph\nreasoning for VLMs but also empirically validates their generalization\nsuperiority in graph-structured learning.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21435v1",
      "published_date": "2025-03-27 12:20:37 UTC",
      "updated_date": "2025-03-27 12:20:37 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898821"
    },
    {
      "arxiv_id": "2503.21419v1",
      "title": "Neuroplasticity in Artificial Intelligence -- An Overview and Inspirations on Drop In \\& Out Learning",
      "title_zh": "",
      "authors": [
        "Yupei Li",
        "Manuel Milling",
        "Björn W. Schuller"
      ],
      "abstract": "Artificial Intelligence (AI) has achieved new levels of performance and\nspread in public usage with the rise of deep neural networks (DNNs). Initially\ninspired by human neurons and their connections, NNs have become the foundation\nof AI models for many advanced architectures. However, some of the most\nintegral processes in the human brain, particularly neurogenesis and\nneuroplasticity in addition to the more spread neuroapoptosis have largely been\nignored in DNN architecture design. Instead, contemporary AI development\npredominantly focuses on constructing advanced frameworks, such as large\nlanguage models, which retain a static structure of neural connections during\ntraining and inference. In this light, we explore how neurogenesis,\nneuroapoptosis, and neuroplasticity can inspire future AI advances.\nSpecifically, we examine analogous activities in artificial NNs, introducing\nthe concepts of ``dropin'' for neurogenesis and revisiting ``dropout'' and\nstructural pruning for neuroapoptosis. We additionally suggest neuroplasticity\ncombining the two for future large NNs in ``life-long learning'' settings\nfollowing the biological inspiration. We conclude by advocating for greater\nresearch efforts in this interdisciplinary domain and identifying promising\ndirections for future exploration.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21419v1",
      "published_date": "2025-03-27 12:09:04 UTC",
      "updated_date": "2025-03-27 12:09:04 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898825"
    },
    {
      "arxiv_id": "2503.21412v1",
      "title": "Federated Intelligence: When Large AI Models Meet Federated Fine-Tuning and Collaborative Reasoning at the Network Edge",
      "title_zh": "",
      "authors": [
        "Wanli Ni",
        "Haofeng Sun",
        "Huiqing Ao",
        "Hui Tian"
      ],
      "abstract": "Large artificial intelligence (AI) models exhibit remarkable capabilities in\nvarious application scenarios, but deploying them at the network edge poses\nsignificant challenges due to issues such as data privacy, computational\nresources, and latency. In this paper, we explore federated fine-tuning and\ncollaborative reasoning techniques to facilitate the implementation of large AI\nmodels in resource-constrained wireless networks. Firstly, promising\napplications of large AI models within specific domains are discussed.\nSubsequently, federated fine-tuning methods are proposed to adapt large AI\nmodels to specific tasks or environments at the network edge, effectively\naddressing the challenges associated with communication overhead and enhancing\ncommunication efficiency. These methodologies follow clustered, hierarchical,\nand asynchronous paradigms to effectively tackle privacy issues and eliminate\ndata silos. Furthermore, to enhance operational efficiency and reduce latency,\nefficient frameworks for model collaborative reasoning are developed, which\ninclude decentralized horizontal collaboration, cloud-edge-end vertical\ncollaboration, and multi-access collaboration. Next, simulation results\ndemonstrate the effectiveness of our proposed methods in reducing the\nfine-tuning loss of large AI models across various downstream tasks. Finally,\nseveral open challenges and research opportunities are outlined.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21412v1",
      "published_date": "2025-03-27 11:56:36 UTC",
      "updated_date": "2025-03-27 11:56:36 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898829"
    },
    {
      "arxiv_id": "2503.21411v1",
      "title": "Exploring the Roles of Large Language Models in Reshaping Transportation Systems: A Survey, Framework, and Roadmap",
      "title_zh": "",
      "authors": [
        "Tong Nie",
        "Jian Sun",
        "Wei Ma"
      ],
      "abstract": "Modern transportation systems face pressing challenges due to increasing\ndemand, dynamic environments, and heterogeneous information integration. The\nrapid evolution of Large Language Models (LLMs) offers transformative potential\nto address these challenges. Extensive knowledge and high-level capabilities\nderived from pretraining evolve the default role of LLMs as text generators to\nbecome versatile, knowledge-driven task solvers for intelligent transportation\nsystems. This survey first presents LLM4TR, a novel conceptual framework that\nsystematically categorizes the roles of LLMs in transportation into four\nsynergetic dimensions: information processors, knowledge encoders, component\ngenerators, and decision facilitators. Through a unified taxonomy, we\nsystematically elucidate how LLMs bridge fragmented data pipelines, enhance\npredictive analytics, simulate human-like reasoning, and enable closed-loop\ninteractions across sensing, learning, modeling, and managing tasks in\ntransportation systems. For each role, our review spans diverse applications,\nfrom traffic prediction and autonomous driving to safety analytics and urban\nmobility optimization, highlighting how emergent capabilities of LLMs such as\nin-context learning and step-by-step reasoning can enhance the operation and\nmanagement of transportation systems. We further curate practical guidance,\nincluding available resources and computational guidelines, to support\nreal-world deployment. By identifying challenges in existing LLM-based\nsolutions, this survey charts a roadmap for advancing LLM-driven transportation\nresearch, positioning LLMs as central actors in the next generation of\ncyber-physical-social mobility ecosystems. Online resources can be found in the\nproject page: https://github.com/tongnie/awesome-llm4tr.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21411v1",
      "published_date": "2025-03-27 11:56:27 UTC",
      "updated_date": "2025-03-27 11:56:27 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898833"
    },
    {
      "arxiv_id": "2503.21406v1",
      "title": "Neuro-Symbolic Imitation Learning: Discovering Symbolic Abstractions for Skill Learning",
      "title_zh": "",
      "authors": [
        "Leon Keller",
        "Daniel Tanneberg",
        "Jan Peters"
      ],
      "abstract": "Imitation learning is a popular method for teaching robots new behaviors.\nHowever, most existing methods focus on teaching short, isolated skills rather\nthan long, multi-step tasks. To bridge this gap, imitation learning algorithms\nmust not only learn individual skills but also an abstract understanding of how\nto sequence these skills to perform extended tasks effectively. This paper\naddresses this challenge by proposing a neuro-symbolic imitation learning\nframework. Using task demonstrations, the system first learns a symbolic\nrepresentation that abstracts the low-level state-action space. The learned\nrepresentation decomposes a task into easier subtasks and allows the system to\nleverage symbolic planning to generate abstract plans. Subsequently, the system\nutilizes this task decomposition to learn a set of neural skills capable of\nrefining abstract plans into actionable robot commands. Experimental results in\nthree simulated robotic environments demonstrate that, compared to baselines,\nour neuro-symbolic approach increases data efficiency, improves generalization\ncapabilities, and facilitates interpretability.",
      "tldr_zh": "",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE International Conference on Robotics and Automation (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.21406v1",
      "published_date": "2025-03-27 11:50:29 UTC",
      "updated_date": "2025-03-27 11:50:29 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898837"
    },
    {
      "arxiv_id": "2503.21393v1",
      "title": "An evaluation of LLMs and Google Translate for translation of selected Indian languages via sentiment and semantic analyses",
      "title_zh": "",
      "authors": [
        "Rohitash Chandra",
        "Aryan Chaudhary",
        "Yeshwanth Rayavarapu"
      ],
      "abstract": "Large Language models (LLMs) have been prominent for language translation,\nincluding low-resource languages. There has been limited study about the\nassessment of the quality of translations generated by LLMs, including Gemini,\nGPT and Google Translate. In this study, we address this limitation by using\nsemantic and sentiment analysis of selected LLMs for Indian languages,\nincluding Sanskrit, Telugu and Hindi. We select prominent texts that have been\nwell translated by experts and use LLMs to generate their translations to\nEnglish, and then we provide a comparison with selected expert (human)\ntranslations. Our findings suggest that while LLMs have made significant\nprogress in translation accuracy, challenges remain in preserving sentiment and\nsemantic integrity, especially in figurative and philosophical contexts. The\nsentiment analysis revealed that GPT-4o and GPT-3.5 are better at preserving\nthe sentiments for the Bhagavad Gita (Sanskrit-English) translations when\ncompared to Google Translate. We observed a similar trend for the case of Tamas\n(Hindi-English) and Maha P (Telugu-English) translations. GPT-4o performs\nsimilarly to GPT-3.5 in the translation in terms of sentiments for the three\nlanguages. We found that LLMs are generally better at translation for capturing\nsentiments when compared to Google Translate.",
      "tldr_zh": "",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21393v1",
      "published_date": "2025-03-27 11:35:40 UTC",
      "updated_date": "2025-03-27 11:35:40 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898841"
    },
    {
      "arxiv_id": "2503.21392v1",
      "title": "HybridoNet-Adapt: A Domain-Adapted Framework for Accurate Lithium-Ion Battery RUL Prediction",
      "title_zh": "",
      "authors": [
        "Khoa Tran",
        "Bao Huynh",
        "Tri Le",
        "Lam Pham",
        "Vy-Rin Nguyen"
      ],
      "abstract": "Accurate prediction of the remaining useful life (RUL) in Lithium-ion battery\n(LIB) health management systems is crucial for ensuring reliability and safety.\nCurrent methods typically assume that training and testing data share the same\ndistribution, overlooking the benefits of incorporating diverse data sources to\nenhance model performance. To address this limitation, we introduce a\ndata-independent RUL prediction framework along with its domain adaptation (DA)\napproach, which leverages heterogeneous data sources for improved target\npredictions. Our approach integrates comprehensive data preprocessing,\nincluding feature extraction, denoising, and normalization, with a\ndata-independent prediction model that combines Long Short-Term Memory (LSTM),\nMultihead Attention, and a Neural Ordinary Differential Equation (NODE) block,\ntermed HybridoNet. The domain-adapted version, HybridoNet Adapt, is trained\nusing a novel technique inspired by the Domain-Adversarial Neural Network\n(DANN) framework, a regression ensemble method, and Maximum Mean Discrepancy\n(MMD) to learn domain-invariant features from labeled cycling data in the\nsource and target domains. Experimental results demonstrate that our approach\noutperforms state-of-the-art techniques, providing reliable RUL predictions for\nreal-world applications.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21392v1",
      "published_date": "2025-03-27 11:35:25 UTC",
      "updated_date": "2025-03-27 11:35:25 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898845"
    },
    {
      "arxiv_id": "2503.21356v1",
      "title": "Investigating the Duality of Interpretability and Explainability in Machine Learning",
      "title_zh": "",
      "authors": [
        "Moncef Garouani",
        "Josiane Mothe",
        "Ayah Barhrhouj",
        "Julien Aligon"
      ],
      "abstract": "The rapid evolution of machine learning (ML) has led to the widespread\nadoption of complex \"black box\" models, such as deep neural networks and\nensemble methods. These models exhibit exceptional predictive performance,\nmaking them invaluable for critical decision-making across diverse domains\nwithin society. However, their inherently opaque nature raises concerns about\ntransparency and interpretability, making them untrustworthy decision support\nsystems. To alleviate such a barrier to high-stakes adoption, research\ncommunity focus has been on developing methods to explain black box models as a\nmeans to address the challenges they pose. Efforts are focused on explaining\nthese models instead of developing ones that are inherently interpretable.\nDesigning inherently interpretable models from the outset, however, can pave\nthe path towards responsible and beneficial applications in the field of ML. In\nthis position paper, we clarify the chasm between explaining black boxes and\nadopting inherently interpretable models. We emphasize the imperative need for\nmodel interpretability and, following the purpose of attaining better (i.e.,\nmore effective or efficient w.r.t. predictive performance) and trustworthy\npredictors, provide an experimental evaluation of latest hybrid learning\nmethods that integrates symbolic knowledge into neural network predictors. We\ndemonstrate how interpretable hybrid models could potentially supplant black\nbox ones in different domains.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21356v1",
      "published_date": "2025-03-27 10:48:40 UTC",
      "updated_date": "2025-03-27 10:48:40 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898850"
    },
    {
      "arxiv_id": "2503.21352v1",
      "title": "Using large language models to produce literature reviews: Usages and systematic biases of microphysics parametrizations in 2699 publications",
      "title_zh": "",
      "authors": [
        "Tianhang Zhang",
        "Shengnan Fu",
        "David M. Schultz",
        "Zhonghua Zheng"
      ],
      "abstract": "Large language models afford opportunities for using computers for intensive\ntasks, realizing research opportunities that have not been considered before.\nOne such opportunity could be a systematic interrogation of the scientific\nliterature. Here, we show how a large language model can be used to construct a\nliterature review of 2699 publications associated with microphysics\nparametrizations in the Weather and Research Forecasting (WRF) model, with the\ngoal of learning how they were used and their systematic biases, when\nsimulating precipitation. The database was constructed of publications\nidentified from Web of Science and Scopus searches. The large language model\nGPT-4 Turbo was used to extract information about model configurations and\nperformance from the text of 2699 publications. Our results reveal the\nlandscape of how nine of the most popular microphysics parameterizations have\nbeen used around the world: Lin, Ferrier, WRF Single-Moment, Goddard Cumulus\nEnsemble, Morrison, Thompson, and WRF Double-Moment. More studies used\none-moment parameterizations before 2020 and two-moment parameterizations after\n2020. Seven out of nine parameterizations tended to overestimate precipitation.\nHowever, systematic biases of parameterizations differed in various regions.\nExcept simulations using the Lin, Ferrier, and Goddard parameterizations that\ntended to underestimate precipitation over almost all locations, the remaining\nsix parameterizations tended to overestimate, particularly over China,\nsoutheast Asia, western United States, and central Africa. This method could be\nused by other researchers to help understand how the increasingly massive body\nof scientific literature can be harnessed through the power of artificial\nintelligence to solve their research problems.",
      "tldr_zh": "",
      "categories": [
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21352v1",
      "published_date": "2025-03-27 10:42:19 UTC",
      "updated_date": "2025-03-27 10:42:19 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898854"
    },
    {
      "arxiv_id": "2503.21347v1",
      "title": "Residual Learning Inspired Crossover Operator and Strategy Enhancements for Evolutionary Multitasking",
      "title_zh": "",
      "authors": [
        "Ruilin Wang",
        "Xiang Feng",
        "Huiqun Yu",
        "Edmund M-K Lai"
      ],
      "abstract": "In evolutionary multitasking, strategies such as crossover operators and\nskill factor assignment are critical for effective knowledge transfer. Existing\nimprovements to crossover operators primarily focus on low-dimensional variable\ncombinations, such as arithmetic crossover or partially mapped crossover, which\nare insufficient for modeling complex high-dimensional interactions.Moreover,\nstatic or semi-dynamic crossover strategies fail to adapt to the dynamic\ndependencies among tasks. In addition, current Multifactorial Evolutionary\nAlgorithm frameworks often rely on fixed skill factor assignment strategies,\nlacking flexibility. To address these limitations, this paper proposes the\nMultifactorial Evolutionary Algorithm-Residual Learning (MFEA-RL) method based\non residual learning. The method employs a Very Deep Super-Resolution (VDSR)\nmodel to generate high-dimensional residual representations of individuals,\nenhancing the modeling of complex relationships within dimensions. A\nResNet-based mechanism dynamically assigns skill factors to improve task\nadaptability, while a random mapping mechanism efficiently performs crossover\noperations and mitigates the risk of negative transfer. Theoretical analysis\nand experimental results show that MFEA-RL outperforms state-of-the-art\nmultitasking algorithms. It excels in both convergence and adaptability on\nstandard evolutionary multitasking benchmarks, including CEC2017-MTSO and\nWCCI2020-MTSO. Additionally, its effectiveness is validated through a\nreal-world application scenario.",
      "tldr_zh": "",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21347v1",
      "published_date": "2025-03-27 10:27:17 UTC",
      "updated_date": "2025-03-27 10:27:17 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898858"
    },
    {
      "arxiv_id": "2503.21337v1",
      "title": "A 71.2-$μ$W Speech Recognition Accelerator with Recurrent Spiking Neural Network",
      "title_zh": "",
      "authors": [
        "Chih-Chyau Yang",
        "Tian-Sheuan Chang"
      ],
      "abstract": "This paper introduces a 71.2-$\\mu$W speech recognition accelerator designed\nfor edge devices' real-time applications, emphasizing an ultra low power\ndesign. Achieved through algorithm and hardware co-optimizations, we propose a\ncompact recurrent spiking neural network with two recurrent layers, one fully\nconnected layer, and a low time step (1 or 2). The 2.79-MB model undergoes\npruning and 4-bit fixed-point quantization, shrinking it by 96.42\\% to 0.1 MB.\nOn the hardware front, we take advantage of \\textit{mixed-level pruning},\n\\textit{zero-skipping} and \\textit{merged spike} techniques, reducing\ncomplexity by 90.49\\% to 13.86 MMAC/S. The \\textit{parallel time-step\nexecution} addresses inter-time-step data dependencies and enables weight\nbuffer power savings through weight sharing. Capitalizing on the sparse spike\nactivity, an input broadcasting scheme eliminates zero computations, further\nsaving power. Implemented on the TSMC 28-nm process, the design operates in\nreal time at 100 kHz, consuming 71.2 $\\mu$W, surpassing state-of-the-art\ndesigns. At 500 MHz, it has 28.41 TOPS/W and 1903.11 GOPS/mm$^2$ in energy and\narea efficiency, respectively.",
      "tldr_zh": "",
      "categories": [
        "cs.AR",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21337v1",
      "published_date": "2025-03-27 10:14:00 UTC",
      "updated_date": "2025-03-27 10:14:00 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898862"
    },
    {
      "arxiv_id": "2503.21335v1",
      "title": "A Low-Power Streaming Speech Enhancement Accelerator For Edge Devices",
      "title_zh": "",
      "authors": [
        "Ci-Hao Wu",
        "Tian-Sheuan Chang"
      ],
      "abstract": "Transformer-based speech enhancement models yield impressive results.\nHowever, their heterogeneous and complex structure restricts model compression\npotential, resulting in greater complexity and reduced hardware efficiency.\nAdditionally, these models are not tailored for streaming and low-power\napplications. Addressing these challenges, this paper proposes a low-power\nstreaming speech enhancement accelerator through model and hardware\noptimization. The proposed high performance model is optimized for hardware\nexecution with the co-design of model compression and target application, which\nreduces 93.9\\% of model size by the proposed domain-aware and streaming-aware\npruning techniques. The required latency is further reduced with batch\nnormalization-based transformers. Additionally, we employed softmax-free\nattention, complemented by an extra batch normalization, facilitating simpler\nhardware design. The tailored hardware accommodates these diverse computing\npatterns by breaking them down into element-wise multiplication and\naccumulation (MAC). This is achieved through a 1-D processing array, utilizing\nconfigurable SRAM addressing, thereby minimizing hardware complexities and\nsimplifying zero skipping. Using the TSMC 40nm CMOS process, the final\nimplementation requires merely 207.8K gates and 53.75KB SRAM. It consumes only\n8.08 mW for real-time inference at a 62.5MHz frequency.",
      "tldr_zh": "",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21335v1",
      "published_date": "2025-03-27 10:13:41 UTC",
      "updated_date": "2025-03-27 10:13:41 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898867"
    },
    {
      "arxiv_id": "2503.21332v1",
      "title": "ReFeed: Multi-dimensional Summarization Refinement with Reflective Reasoning on Feedback",
      "title_zh": "",
      "authors": [
        "Taewon Yun",
        "Jihwan Oh",
        "Hyangsuk Min",
        "Yuho Lee",
        "Jihwan Bang",
        "Jason Cai",
        "Hwanjun Song"
      ],
      "abstract": "Summarization refinement faces challenges when extending to multi-dimension.\nIn this paper, we introduce ReFeed, a powerful summarization refinement\npipeline that enhances multiple dimensions through reflective reasoning on\nfeedback. To achieve this, we release SumFeed-CoT, a large-scale Long-CoT-based\ndataset optimized for training a lightweight model with reflective reasoning.\nOur experiments reveal how the number of dimensions, feedback exposure, and\nreasoning policy influence refinement performance, highlighting reflective\nreasoning and simultaneously addressing multiple feedback is crucial to\nmitigate trade-off between dimensions. Furthermore, ReFeed is robust to noisy\nfeedback and feedback order. Lastly, our finding emphasizes that creating data\nwith a proper goal and guideline constitutes a fundamental pillar of effective\nreasoning. The dataset and model will be released.",
      "tldr_zh": "",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21332v1",
      "published_date": "2025-03-27 10:11:41 UTC",
      "updated_date": "2025-03-27 10:11:41 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898871"
    },
    {
      "arxiv_id": "2503.21322v1",
      "title": "HyperGraphRAG: Retrieval-Augmented Generation with Hypergraph-Structured Knowledge Representation",
      "title_zh": "",
      "authors": [
        "Haoran Luo",
        "Haihong E",
        "Guanting Chen",
        "Yandan Zheng",
        "Xiaobao Wu",
        "Yikai Guo",
        "Qika Lin",
        "Yu Feng",
        "Zemin Kuang",
        "Meina Song",
        "Yifan Zhu",
        "Luu Anh Tuan"
      ],
      "abstract": "While standard Retrieval-Augmented Generation (RAG) based on chunks, GraphRAG\nstructures knowledge as graphs to leverage the relations among entities.\nHowever, previous GraphRAG methods are limited by binary relations: one edge in\nthe graph only connects two entities, which cannot well model the n-ary\nrelations among more than two entities that widely exist in reality. To address\nthis limitation, we propose HyperGraphRAG, a novel hypergraph-based RAG method\nthat represents n-ary relational facts via hyperedges, modeling the complicated\nn-ary relations in the real world. To retrieve and generate over hypergraphs,\nwe introduce a complete pipeline with a hypergraph construction method, a\nhypergraph retrieval strategy, and a hypergraph-guided generation mechanism.\nExperiments across medicine, agriculture, computer science, and law demonstrate\nthat HyperGraphRAG outperforms standard RAG and GraphRAG in accuracy and\ngeneration quality.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.21322v1",
      "published_date": "2025-03-27 10:01:16 UTC",
      "updated_date": "2025-03-27 10:01:16 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898875"
    },
    {
      "arxiv_id": "2503.21309v1",
      "title": "FineCIR: Explicit Parsing of Fine-Grained Modification Semantics for Composed Image Retrieval",
      "title_zh": "",
      "authors": [
        "Zixu Li",
        "Zhiheng Fu",
        "Yupeng Hu",
        "Zhiwei Chen",
        "Haokun Wen",
        "Liqiang Nie"
      ],
      "abstract": "Composed Image Retrieval (CIR) facilitates image retrieval through a\nmultimodal query consisting of a reference image and modification text. The\nreference image defines the retrieval context, while the modification text\nspecifies desired alterations. However, existing CIR datasets predominantly\nemploy coarse-grained modification text (CoarseMT), which inadequately captures\nfine-grained retrieval intents. This limitation introduces two key challenges:\n(1) ignoring detailed differences leads to imprecise positive samples, and (2)\ngreater ambiguity arises when retrieving visually similar images. These issues\ndegrade retrieval accuracy, necessitating manual result filtering or repeated\nqueries. To address these limitations, we develop a robust fine-grained CIR\ndata annotation pipeline that minimizes imprecise positive samples and enhances\nCIR systems' ability to discern modification intents accurately. Using this\npipeline, we refine the FashionIQ and CIRR datasets to create two fine-grained\nCIR datasets: Fine-FashionIQ and Fine-CIRR. Furthermore, we introduce FineCIR,\nthe first CIR framework explicitly designed to parse the modification text.\nFineCIR effectively captures fine-grained modification semantics and aligns\nthem with ambiguous visual entities, enhancing retrieval precision. Extensive\nexperiments demonstrate that FineCIR consistently outperforms state-of-the-art\nCIR baselines on both fine-grained and traditional CIR benchmark datasets. Our\nFineCIR code and fine-grained CIR datasets are available at\nhttps://github.com/SDU-L/FineCIR.git.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21309v1",
      "published_date": "2025-03-27 09:34:21 UTC",
      "updated_date": "2025-03-27 09:34:21 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898880"
    },
    {
      "arxiv_id": "2503.21307v1",
      "title": "InternVL-X: Advancing and Accelerating InternVL Series with Efficient Visual Token Compression",
      "title_zh": "",
      "authors": [
        "Dongchen Lu",
        "Yuyao Sun",
        "Zilu Zhang",
        "Leping Huang",
        "Jianliang Zeng",
        "Mao Shu",
        "Huo Cao"
      ],
      "abstract": "Most multimodal large language models (MLLMs) treat visual tokens as \"a\nsequence of text\", integrating them with text tokens into a large language\nmodel (LLM). However, a great quantity of visual tokens significantly increases\nthe demand for computational resources and time. In this paper, we propose\nInternVL-X, which outperforms the InternVL model in both performance and\nefficiency by incorporating three visual token compression methods. First, we\npropose a novel vision-language projector, PVTC. This component integrates\nadjacent visual embeddings to form a local query and utilizes the transformed\nCLS token as a global query, then performs point-to-region cross-attention\nthrough these local and global queries to more effectively convert visual\nfeatures. Second, we present a layer-wise visual token compression module,\nLVTC, which compresses tokens in the LLM shallow layers and then expands them\nthrough upsampling and residual connections in the deeper layers. This\nsignificantly enhances the model computational efficiency. Futhermore, we\npropose an efficient high resolution slicing method, RVTC, which dynamically\nadjusts the number of visual tokens based on image area or length filtering.\nRVTC greatly enhances training efficiency with only a slight reduction in\nperformance. By utilizing 20% or fewer visual tokens, InternVL-X achieves\nstate-of-the-art performance on 7 public MLLM benchmarks, and improves the\naverage metric by 2.34% across 12 tasks.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21307v1",
      "published_date": "2025-03-27 09:31:35 UTC",
      "updated_date": "2025-03-27 09:31:35 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898884"
    },
    {
      "arxiv_id": "2503.21305v1",
      "title": "DeBackdoor: A Deductive Framework for Detecting Backdoor Attacks on Deep Models with Limited Data",
      "title_zh": "",
      "authors": [
        "Dorde Popovic",
        "Amin Sadeghi",
        "Ting Yu",
        "Sanjay Chawla",
        "Issa Khalil"
      ],
      "abstract": "Backdoor attacks are among the most effective, practical, and stealthy\nattacks in deep learning. In this paper, we consider a practical scenario where\na developer obtains a deep model from a third party and uses it as part of a\nsafety-critical system. The developer wants to inspect the model for potential\nbackdoors prior to system deployment. We find that most existing detection\ntechniques make assumptions that are not applicable to this scenario. In this\npaper, we present a novel framework for detecting backdoors under realistic\nrestrictions. We generate candidate triggers by deductively searching over the\nspace of possible triggers. We construct and optimize a smoothed version of\nAttack Success Rate as our search objective. Starting from a broad class of\ntemplate attacks and just using the forward pass of a deep model, we reverse\nengineer the backdoor attack. We conduct extensive evaluation on a wide range\nof attacks, models, and datasets, with our technique performing almost\nperfectly across these settings.",
      "tldr_zh": "",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21305v1",
      "published_date": "2025-03-27 09:31:10 UTC",
      "updated_date": "2025-03-27 09:31:10 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898889"
    },
    {
      "arxiv_id": "2503.21284v1",
      "title": "Multi-Scale Invertible Neural Network for Wide-Range Variable-Rate Learned Image Compression",
      "title_zh": "",
      "authors": [
        "Hanyue Tu",
        "Siqi Wu",
        "Li Li",
        "Wengang Zhou",
        "Houqiang Li"
      ],
      "abstract": "Autoencoder-based structures have dominated recent learned image compression\nmethods. However, the inherent information loss associated with autoencoders\nlimits their rate-distortion performance at high bit rates and restricts their\nflexibility of rate adaptation. In this paper, we present a variable-rate image\ncompression model based on invertible transform to overcome these limitations.\nSpecifically, we design a lightweight multi-scale invertible neural network,\nwhich bijectively maps the input image into multi-scale latent representations.\nTo improve the compression efficiency, a multi-scale spatial-channel context\nmodel with extended gain units is devised to estimate the entropy of the latent\nrepresentation from high to low levels. Experimental results demonstrate that\nthe proposed method achieves state-of-the-art performance compared to existing\nvariable-rate methods, and remains competitive with recent multi-model\napproaches. Notably, our method is the first learned image compression solution\nthat outperforms VVC across a very wide range of bit rates using a single\nmodel, especially at high bit rates.The source code is available at\n\\href{https://github.com/hytu99/MSINN-VRLIC}{https://github.com/hytu99/MSINN-VRLIC}.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IEEE Transactions on Multimedia 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.21284v1",
      "published_date": "2025-03-27 09:08:39 UTC",
      "updated_date": "2025-03-27 09:08:39 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898893"
    },
    {
      "arxiv_id": "2503.21272v1",
      "title": "Reinforced Model Merging",
      "title_zh": "",
      "authors": [
        "Jiaqi Han",
        "Jingwen Ye",
        "Shunyu Liu",
        "Haofei Zhang",
        "Jie Song",
        "Zunlei Feng",
        "Mingli Song"
      ],
      "abstract": "The success of large language models has garnered widespread attention for\nmodel merging techniques, especially training-free methods which combine model\ncapabilities within the parameter space. However, two challenges remain: (1)\nuniform treatment of all parameters leads to performance degradation; (2)\nsearch-based algorithms are often inefficient. In this paper, we present an\ninnovative framework termed Reinforced Model Merging (RMM), which encompasses\nan environment and agent tailored for merging tasks. These components interact\nto execute layer-wise merging actions, aiming to search the optimal merging\narchitecture. Notably, RMM operates without any gradient computations on the\noriginal models, rendering it feasible for edge devices. Furthermore, by\nutilizing data subsets during the evaluation process, we addressed the\nbottleneck in the reward feedback phase, thereby accelerating RMM by up to 100\ntimes. Extensive experiments demonstrate that RMM achieves state-of-the-art\nperformance across various vision and NLP datasets and effectively overcomes\nthe limitations of the existing baseline methods. Our code is available at\nhttps://github.com/WuDiHJQ/Reinforced-Model-Merging.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21272v1",
      "published_date": "2025-03-27 08:52:41 UTC",
      "updated_date": "2025-03-27 08:52:41 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898898"
    },
    {
      "arxiv_id": "2503.21258v1",
      "title": "Learn by Reasoning: Analogical Weight Generation for Few-Shot Class-Incremental Learning",
      "title_zh": "",
      "authors": [
        "Jizhou Han",
        "Chenhao Ding",
        "Yuhang He",
        "Songlin Dong",
        "Qiang Wang",
        "Xinyuan Gao",
        "Yihong Gong"
      ],
      "abstract": "Few-shot class-incremental Learning (FSCIL) enables models to learn new\nclasses from limited data while retaining performance on previously learned\nclasses. Traditional FSCIL methods often require fine-tuning parameters with\nlimited new class data and suffer from a separation between learning new\nclasses and utilizing old knowledge. Inspired by the analogical learning\nmechanisms of the human brain, we propose a novel analogical generative method.\nOur approach includes the Brain-Inspired Analogical Generator (BiAG), which\nderives new class weights from existing classes without parameter fine-tuning\nduring incremental stages. BiAG consists of three components: Weight\nSelf-Attention Module (WSA), Weight & Prototype Analogical Attention Module\n(WPAA), and Semantic Conversion Module (SCM). SCM uses Neural Collapse theory\nfor semantic conversion, WSA supplements new class weights, and WPAA computes\nanalogies to generate new class weights. Experiments on miniImageNet, CUB-200,\nand CIFAR-100 datasets demonstrate that our method achieves higher final and\naverage accuracy compared to SOTA methods.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21258v1",
      "published_date": "2025-03-27 08:31:46 UTC",
      "updated_date": "2025-03-27 08:31:46 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898902"
    },
    {
      "arxiv_id": "2503.21257v1",
      "title": "OminiAdapt: Learning Cross-Task Invariance for Robust and Environment-Aware Robotic Manipulation",
      "title_zh": "",
      "authors": [
        "Yongxu Wang",
        "Weiyun Yi",
        "Xinhao Kong",
        "Wanting Li"
      ],
      "abstract": "With the rapid development of embodied intelligence, leveraging large-scale\nhuman data for high-level imitation learning on humanoid robots has become a\nfocal point of interest in both academia and industry. However, applying\nhumanoid robots to precision operation domains remains challenging due to the\ncomplexities they face in perception and control processes, the long-standing\nphysical differences in morphology and actuation mechanisms between humanoid\nrobots and humans, and the lack of task-relevant features obtained from\negocentric vision. To address the issue of covariate shift in imitation\nlearning, this paper proposes an imitation learning algorithm tailored for\nhumanoid robots. By focusing on the primary task objectives, filtering out\nbackground information, and incorporating channel feature fusion with spatial\nattention mechanisms, the proposed algorithm suppresses environmental\ndisturbances and utilizes a dynamic weight update strategy to significantly\nimprove the success rate of humanoid robots in accomplishing target tasks.\nExperimental results demonstrate that the proposed method exhibits robustness\nand scalability across various typical task scenarios, providing new ideas and\napproaches for autonomous learning and control in humanoid robots. The project\nwill be open-sourced on GitHub.",
      "tldr_zh": "",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21257v1",
      "published_date": "2025-03-27 08:28:22 UTC",
      "updated_date": "2025-03-27 08:28:22 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898907"
    },
    {
      "arxiv_id": "2503.21254v1",
      "title": "Vision-to-Music Generation: A Survey",
      "title_zh": "",
      "authors": [
        "Zhaokai Wang",
        "Chenxi Bao",
        "Le Zhuo",
        "Jingrui Han",
        "Yang Yue",
        "Yihong Tang",
        "Victor Shea-Jay Huang",
        "Yue Liao"
      ],
      "abstract": "Vision-to-music Generation, including video-to-music and image-to-music\ntasks, is a significant branch of multimodal artificial intelligence\ndemonstrating vast application prospects in fields such as film scoring, short\nvideo creation, and dance music synthesis. However, compared to the rapid\ndevelopment of modalities like text and images, research in vision-to-music is\nstill in its preliminary stage due to its complex internal structure and the\ndifficulty of modeling dynamic relationships with video. Existing surveys focus\non general music generation without comprehensive discussion on\nvision-to-music. In this paper, we systematically review the research progress\nin the field of vision-to-music generation. We first analyze the technical\ncharacteristics and core challenges for three input types: general videos,\nhuman movement videos, and images, as well as two output types of symbolic\nmusic and audio music. We then summarize the existing methodologies on\nvision-to-music generation from the architecture perspective. A detailed review\nof common datasets and evaluation metrics is provided. Finally, we discuss\ncurrent challenges and promising directions for future research. We hope our\nsurvey can inspire further innovation in vision-to-music generation and the\nbroader field of multimodal generation in academic research and industrial\napplications. To follow latest works and foster further innovation in this\nfield, we are continuously maintaining a GitHub repository at\nhttps://github.com/wzk1015/Awesome-Vision-to-Music-Generation.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21254v1",
      "published_date": "2025-03-27 08:21:54 UTC",
      "updated_date": "2025-03-27 08:21:54 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898912"
    },
    {
      "arxiv_id": "2503.21251v1",
      "title": "Dual-Splitting Conformal Prediction for Multi-Step Time Series Forecasting",
      "title_zh": "",
      "authors": [
        "Qingdi Yu",
        "Zhiwei Cao",
        "Ruihang Wang",
        "Zhen Yang",
        "Lijun Deng",
        "Min Hu",
        "Yong Luo",
        "Xin Zhou"
      ],
      "abstract": "Time series forecasting is crucial for applications like resource scheduling\nand risk management, where multi-step predictions provide a comprehensive view\nof future trends. Uncertainty Quantification (UQ) is a mainstream approach for\naddressing forecasting uncertainties, with Conformal Prediction (CP) gaining\nattention due to its model-agnostic nature and statistical guarantees. However,\nmost variants of CP are designed for single-step predictions and face\nchallenges in multi-step scenarios, such as reliance on real-time data and\nlimited scalability. This highlights the need for CP methods specifically\ntailored to multi-step forecasting. We propose the Dual-Splitting Conformal\nPrediction (DSCP) method, a novel CP approach designed to capture inherent\ndependencies within time-series data for multi-step forecasting. Experimental\nresults on real-world datasets from four different domains demonstrate that the\nproposed DSCP significantly outperforms existing CP variants in terms of the\nWinkler Score, achieving a performance improvement of up to 23.59% compared to\nstate-of-the-art methods. Furthermore, we deployed the DSCP approach for\nrenewable energy generation and IT load forecasting in power management of a\nreal-world trajectory-based application, achieving an 11.25% reduction in\ncarbon emissions through predictive optimization of data center operations and\ncontrols.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T37",
        "I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 13 figures, 3 tables. Submitted to Applied Soft Computing.\n  With Editor This is the first public release of the work",
      "pdf_url": "http://arxiv.org/pdf/2503.21251v1",
      "published_date": "2025-03-27 08:17:18 UTC",
      "updated_date": "2025-03-27 08:17:18 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898916"
    },
    {
      "arxiv_id": "2503.21248v1",
      "title": "ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition",
      "title_zh": "",
      "authors": [
        "Yujie Liu",
        "Zonglin Yang",
        "Tong Xie",
        "Jinjie Ni",
        "Ben Gao",
        "Yuqiang Li",
        "Shixiang Tang",
        "Wanli Ouyang",
        "Erik Cambria",
        "Dongzhan Zhou"
      ],
      "abstract": "Large language models (LLMs) have demonstrated potential in assisting\nscientific research, yet their ability to discover high-quality research\nhypotheses remains unexamined due to the lack of a dedicated benchmark. To\naddress this gap, we introduce the first large-scale benchmark for evaluating\nLLMs with a near-sufficient set of sub-tasks of scientific discovery:\ninspiration retrieval, hypothesis composition, and hypothesis ranking. We\ndevelop an automated framework that extracts critical components - research\nquestions, background surveys, inspirations, and hypotheses - from scientific\npapers across 12 disciplines, with expert validation confirming its accuracy.\nTo prevent data contamination, we focus exclusively on papers published in\n2024, ensuring minimal overlap with LLM pretraining data. Our evaluation\nreveals that LLMs perform well in retrieving inspirations, an\nout-of-distribution task, suggesting their ability to surface novel knowledge\nassociations. This positions LLMs as \"research hypothesis mines\", capable of\nfacilitating automated scientific discovery by generating innovative hypotheses\nat scale with minimal human intervention.",
      "tldr_zh": "",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21248v1",
      "published_date": "2025-03-27 08:09:15 UTC",
      "updated_date": "2025-03-27 08:09:15 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898921"
    },
    {
      "arxiv_id": "2503.21244v1",
      "title": "Improving $(α, f)$-Byzantine Resilience in Federated Learning via layerwise aggregation and cosine distance",
      "title_zh": "",
      "authors": [
        "Mario García-Márquez",
        "Nuria Rodríguez-Barroso",
        "M. Victoria Luzón",
        "Francisco Herrera"
      ],
      "abstract": "The rapid development of artificial intelligence systems has amplified\nsocietal concerns regarding their usage, necessitating regulatory frameworks\nthat encompass data privacy. Federated Learning (FL) is posed as potential\nsolution to data privacy challenges in distributed machine learning by enabling\ncollaborative model training {without data sharing}. However, FL systems remain\nvulnerable to Byzantine attacks, where malicious nodes contribute corrupted\nmodel updates. While Byzantine Resilient operators have emerged as a widely\nadopted robust aggregation algorithm to mitigate these attacks, its efficacy\ndiminishes significantly in high-dimensional parameter spaces, sometimes\nleading to poor performing models. This paper introduces Layerwise Cosine\nAggregation, a novel aggregation scheme designed to enhance robustness of these\nrules in such high-dimensional settings while preserving computational\nefficiency. A theoretical analysis is presented, demonstrating the superior\nrobustness of the proposed Layerwise Cosine Aggregation compared to original\nrobust aggregation operators. Empirical evaluation across diverse image\nclassification datasets, under varying data distributions and Byzantine attack\nscenarios, consistently demonstrates the improved performance of Layerwise\nCosine Aggregation, achieving up to a 16% increase in model accuracy.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Knowledge-Based Systems",
      "pdf_url": "http://arxiv.org/pdf/2503.21244v1",
      "published_date": "2025-03-27 08:07:39 UTC",
      "updated_date": "2025-03-27 08:07:39 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898926"
    },
    {
      "arxiv_id": "2503.21241v1",
      "title": "Feature-Enhanced Machine Learning for All-Cause Mortality Prediction in Healthcare Data",
      "title_zh": "",
      "authors": [
        "HyeYoung Lee",
        "Pavel Tsoi"
      ],
      "abstract": "Accurate patient mortality prediction enables effective risk stratification,\nleading to personalized treatment plans and improved patient outcomes. However,\npredicting mortality in healthcare remains a significant challenge, with\nexisting studies often focusing on specific diseases or limited predictor sets.\nThis study evaluates machine learning models for all-cause in-hospital\nmortality prediction using the MIMIC-III database, employing a comprehensive\nfeature engineering approach. Guided by clinical expertise and literature, we\nextracted key features such as vital signs (e.g., heart rate, blood pressure),\nlaboratory results (e.g., creatinine, glucose), and demographic information.\nThe Random Forest model achieved the highest performance with an AUC of 0.94,\nsignificantly outperforming other machine learning and deep learning\napproaches. This demonstrates Random Forest's robustness in handling\nhigh-dimensional, noisy clinical data and its potential for developing\neffective clinical decision support tools. Our findings highlight the\nimportance of careful feature engineering for accurate mortality prediction. We\nconclude by discussing implications for clinical adoption and propose future\ndirections, including enhancing model robustness and tailoring prediction\nmodels for specific diseases.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21241v1",
      "published_date": "2025-03-27 08:04:42 UTC",
      "updated_date": "2025-03-27 08:04:42 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898931"
    },
    {
      "arxiv_id": "2503.21237v1",
      "title": "Bias-Aware Agent: Enhancing Fairness in AI-Driven Knowledge Retrieval",
      "title_zh": "",
      "authors": [
        "Karanbir Singh",
        "William Ngu"
      ],
      "abstract": "Advancements in retrieving accessible information have evolved faster in the\nlast few years compared to the decades since the internet's creation. Search\nengines, like Google, have been the number one way to find relevant data. They\nhave always relied on the user's abilities to find the best information in its\nbillions of links and sources at everybody's fingertips. The advent of large\nlanguage models (LLMs) has completely transformed the field of information\nretrieval. The LLMs excel not only at retrieving relevant knowledge but also at\nsummarizing it effectively, making information more accessible and consumable\nfor users. On top of it, the rise of AI Agents has introduced another aspect to\ninformation retrieval i.e. dynamic information retrieval which enables the\nintegration of real-time data such as weather forecasts, and financial data\nwith the knowledge base to curate context-aware knowledge. However, despite\nthese advancements the agents remain susceptible to issues of bias and\nfairness, challenges deeply rooted within the knowledge base and training of\nLLMs. This study introduces a novel approach to bias-aware knowledge retrieval\nby leveraging agentic framework and the innovative use of bias detectors as\ntools to identify and highlight inherent biases in the retrieved content. By\nempowering users with transparency and awareness, this approach aims to foster\nmore equitable information systems and promote the development of responsible\nAI.",
      "tldr_zh": "",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21237v1",
      "published_date": "2025-03-27 07:54:39 UTC",
      "updated_date": "2025-03-27 07:54:39 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898935"
    },
    {
      "arxiv_id": "2503.21232v1",
      "title": "Knowledge Graphs as World Models for Semantic Material-Aware Obstacle Handling in Autonomous Vehicles",
      "title_zh": "",
      "authors": [
        "Ayush Bheemaiah",
        "Seungyong Yang"
      ],
      "abstract": "The inability of autonomous vehicles (AVs) to infer the material properties\nof obstacles limits their decision-making capacity. While AVs rely on sensor\nsystems such as cameras, LiDAR, and radar to detect obstacles, this study\nsuggests combining sensors with a knowledge graph (KG)-based world model to\nimprove AVs' comprehension of physical material qualities. Beyond sensor data,\nAVs can infer qualities such as malleability, density, and elasticity using a\nsemantic KG that depicts the relationships between obstacles and their\nattributes. Using the CARLA autonomous driving simulator, we evaluated AV\nperformance with and without KG integration. The findings demonstrate that the\nKG-based method improves obstacle management, which allows AVs to use material\nqualities to make better decisions about when to change lanes or apply\nemergency braking. For example, the KG-integrated AV changed lanes for hard\nimpediments like traffic cones and successfully avoided collisions with\nflexible items such as plastic bags by passing over them. Compared to the\ncontrol system, the KG framework demonstrated improved responsiveness to\nobstacles by resolving conflicting sensor data, causing emergency stops for\n13.3% more cases. In addition, our method exhibits a 6.6% higher success rate\nin lane-changing maneuvers in experimental scenarios, particularly for larger,\nhigh-impact obstacles. While we focus particularly on autonomous driving, our\nwork demonstrates the potential of KG-based world models to improve\ndecision-making in embodied AI systems and scale to other domains, including\nrobotics, healthcare, and environmental simulation.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21232v1",
      "published_date": "2025-03-27 07:46:45 UTC",
      "updated_date": "2025-03-27 07:46:45 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898940"
    },
    {
      "arxiv_id": "2503.21219v1",
      "title": "GenFusion: Closing the Loop between Reconstruction and Generation via Videos",
      "title_zh": "",
      "authors": [
        "Sibo Wu",
        "Congrong Xu",
        "Binbin Huang",
        "Andreas Geiger",
        "Anpei Chen"
      ],
      "abstract": "Recently, 3D reconstruction and generation have demonstrated impressive novel\nview synthesis results, achieving high fidelity and efficiency. However, a\nnotable conditioning gap can be observed between these two fields, e.g.,\nscalable 3D scene reconstruction often requires densely captured views, whereas\n3D generation typically relies on a single or no input view, which\nsignificantly limits their applications. We found that the source of this\nphenomenon lies in the misalignment between 3D constraints and generative\npriors. To address this problem, we propose a reconstruction-driven video\ndiffusion model that learns to condition video frames on artifact-prone RGB-D\nrenderings. Moreover, we propose a cyclical fusion pipeline that iteratively\nadds restoration frames from the generative model to the training set, enabling\nprogressive expansion and addressing the viewpoint saturation limitations seen\nin previous reconstruction and generation pipelines. Our evaluation, including\nview synthesis from sparse view and masked input, validates the effectiveness\nof our approach.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21219v1",
      "published_date": "2025-03-27 07:16:24 UTC",
      "updated_date": "2025-03-27 07:16:24 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898945"
    },
    {
      "arxiv_id": "2503.21178v1",
      "title": "Integrating Large Language Models For Monte Carlo Simulation of Chemical Reaction Networks",
      "title_zh": "",
      "authors": [
        "Sadikshya Gyawali",
        "Ashwini Mandal",
        "Manish Dahal",
        "Manish Awale",
        "Sanjay Rijal",
        "Shital Adhikari",
        "Vaghawan Ojha"
      ],
      "abstract": "Chemical reaction network is an important method for modeling and exploring\ncomplex biological processes, bio-chemical interactions and the behavior of\ndifferent dynamics in system biology. But, formulating such reaction kinetics\ntakes considerable time. In this paper, we leverage the efficiency of modern\nlarge language models to automate the stochastic monte carlo simulation of\nchemical reaction networks and enable the simulation through the reaction\ndescription provided in the form of natural languages. We also integrate this\nprocess into widely used simulation tool Copasi to further give the edge and\nease to the modelers and researchers. In this work, we show the efficacy and\nlimitations of the modern large language models to parse and create reaction\nkinetics for modelling complex chemical reaction processes.",
      "tldr_zh": "",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted on MadeAI 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2503.21178v1",
      "published_date": "2025-03-27 06:01:50 UTC",
      "updated_date": "2025-03-27 06:01:50 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898949"
    },
    {
      "arxiv_id": "2503.21164v1",
      "title": "Adversarial Wear and Tear: Exploiting Natural Damage for Generating Physical-World Adversarial Examples",
      "title_zh": "",
      "authors": [
        "Samra Irshad",
        "Seungkyu Lee",
        "Nassir Navab",
        "Hong Joo Lee",
        "Seong Tae Kim"
      ],
      "abstract": "The presence of adversarial examples in the physical world poses significant\nchallenges to the deployment of Deep Neural Networks in safety-critical\napplications such as autonomous driving. Most existing methods for crafting\nphysical-world adversarial examples are ad-hoc, relying on temporary\nmodifications like shadows, laser beams, or stickers that are tailored to\nspecific scenarios. In this paper, we introduce a new class of physical-world\nadversarial examples, AdvWT, which draws inspiration from the naturally\noccurring phenomenon of `wear and tear', an inherent property of physical\nobjects. Unlike manually crafted perturbations, `wear and tear' emerges\norganically over time due to environmental degradation, as seen in the gradual\ndeterioration of outdoor signboards. To achieve this, AdvWT follows a two-step\napproach. First, a GAN-based, unsupervised image-to-image translation network\nis employed to model these naturally occurring damages, particularly in the\ncontext of outdoor signboards. The translation network encodes the\ncharacteristics of damaged signs into a latent `damage style code'. In the\nsecond step, we introduce adversarial perturbations into the style code,\nstrategically optimizing its transformation process. This manipulation subtly\nalters the damage style representation, guiding the network to generate\nadversarial images where the appearance of damages remains perceptually\nrealistic, while simultaneously ensuring their effectiveness in misleading\nneural networks. Through comprehensive experiments on two traffic sign\ndatasets, we show that AdvWT effectively misleads DNNs in both digital and\nphysical domains. AdvWT achieves an effective attack success rate, greater\nrobustness, and a more natural appearance compared to existing physical-world\nadversarial examples. Additionally, integrating AdvWT into training enhances a\nmodel's generalizability to real-world damaged signs.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21164v1",
      "published_date": "2025-03-27 05:19:41 UTC",
      "updated_date": "2025-03-27 05:19:41 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898954"
    },
    {
      "arxiv_id": "2503.21159v1",
      "title": "Multi-Objective Optimization for Privacy-Utility Balance in Differentially Private Federated Learning",
      "title_zh": "",
      "authors": [
        "Kanishka Ranaweera",
        "David Smith",
        "Pubudu N. Pathirana",
        "Ming Ding",
        "Thierry Rakotoarivelo",
        "Aruna Seneviratne"
      ],
      "abstract": "Federated learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, making it a promising approach\nfor privacy-preserving machine learning. However, ensuring differential privacy\n(DP) in FL presents challenges due to the trade-off between model utility and\nprivacy protection. Clipping gradients before aggregation is a common strategy\nto limit privacy loss, but selecting an optimal clipping norm is non-trivial,\nas excessively high values compromise privacy, while overly restrictive\nclipping degrades model performance. In this work, we propose an adaptive\nclipping mechanism that dynamically adjusts the clipping norm using a\nmulti-objective optimization framework. By integrating privacy and utility\nconsiderations into the optimization objective, our approach balances privacy\npreservation with model accuracy. We theoretically analyze the convergence\nproperties of our method and demonstrate its effectiveness through extensive\nexperiments on MNIST, Fashion-MNIST, and CIFAR-10 datasets. Our results show\nthat adaptive clipping consistently outperforms fixed-clipping baselines,\nachieving improved accuracy under the same privacy constraints. This work\nhighlights the potential of dynamic clipping strategies to enhance\nprivacy-utility trade-offs in differentially private federated learning.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21159v1",
      "published_date": "2025-03-27 04:57:05 UTC",
      "updated_date": "2025-03-27 04:57:05 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898959"
    },
    {
      "arxiv_id": "2503.21154v1",
      "title": "Federated Learning with Differential Privacy: An Utility-Enhanced Approach",
      "title_zh": "",
      "authors": [
        "Kanishka Ranaweera",
        "Dinh C. Nguyen",
        "Pubudu N. Pathirana",
        "David Smith",
        "Ming Ding",
        "Thierry Rakotoarivelo",
        "Aruna Seneviratne"
      ],
      "abstract": "Federated learning has emerged as an attractive approach to protect data\nprivacy by eliminating the need for sharing clients' data while reducing\ncommunication costs compared with centralized machine learning algorithms.\nHowever, recent studies have shown that federated learning alone does not\nguarantee privacy, as private data may still be inferred from the uploaded\nparameters to the central server. In order to successfully avoid data leakage,\nadopting differential privacy (DP) in the local optimization process or in the\nlocal update aggregation process has emerged as two feasible ways for achieving\nsample-level or user-level privacy guarantees respectively, in federated\nlearning models. However, compared to their non-private equivalents, these\napproaches suffer from a poor utility. To improve the privacy-utility\ntrade-off, we present a modification to these vanilla differentially private\nalgorithms based on a Haar wavelet transformation step and a novel noise\ninjection scheme that significantly lowers the asymptotic bound of the noise\nvariance. We also present a holistic convergence analysis of our proposed\nalgorithm, showing that our method yields better convergence performance than\nthe vanilla DP algorithms. Numerical experiments on real-world datasets\ndemonstrate that our method outperforms existing approaches in model utility\nwhile maintaining the same privacy guarantees.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21154v1",
      "published_date": "2025-03-27 04:48:29 UTC",
      "updated_date": "2025-03-27 04:48:29 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898964"
    },
    {
      "arxiv_id": "2503.21150v1",
      "title": "The Devil is in Low-Level Features for Cross-Domain Few-Shot Segmentation",
      "title_zh": "",
      "authors": [
        "Yuhan Liu",
        "Yixiong Zou",
        "Yuhua Li",
        "Ruixuan Li"
      ],
      "abstract": "Cross-Domain Few-Shot Segmentation (CDFSS) is proposed to transfer the\npixel-level segmentation capabilities learned from large-scale source-domain\ndatasets to downstream target-domain datasets, with only a few annotated images\nper class. In this paper, we focus on a well-observed but unresolved phenomenon\nin CDFSS: for target domains, particularly those distant from the source\ndomain, segmentation performance peaks at the very early epochs, and declines\nsharply as the source-domain training proceeds. We delve into this phenomenon\nfor an interpretation: low-level features are vulnerable to domain shifts,\nleading to sharper loss landscapes during the source-domain training, which is\nthe devil of CDFSS. Based on this phenomenon and interpretation, we further\npropose a method that includes two plug-and-play modules: one to flatten the\nloss landscapes for low-level features during source-domain training as a novel\nsharpness-aware minimization method, and the other to directly supplement\ntarget-domain information to the model during target-domain testing by\nlow-level-based calibration. Extensive experiments on four target datasets\nvalidate our rationale and demonstrate that our method surpasses the\nstate-of-the-art method in CDFSS signifcantly by 3.71% and 5.34% average MIoU\nin 1-shot and 5-shot scenarios, respectively.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.21150v1",
      "published_date": "2025-03-27 04:37:52 UTC",
      "updated_date": "2025-03-27 04:37:52 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898969"
    },
    {
      "arxiv_id": "2503.21138v1",
      "title": "A computational theory of evaluation for parameterisable subject",
      "title_zh": "",
      "authors": [
        "Hedong Yan"
      ],
      "abstract": "Evaluation is critical to advance decision making across domains, yet\nexisting methodologies often struggle to balance theoretical rigor and\npractical scalability. In order to reduce the cost of experimental evaluation,\nwe introduce a computational theory of evaluation for parameterisable subjects.\nWe prove upper bounds of generalized evaluation error and generalized causal\neffect error of evaluation metric on subject. We also prove efficiency, and\nconsistency to estimated causal effect of subject on metric by prediction. To\noptimize evaluation models, we propose a meta-learner to handle heterogeneous\nevaluation subjects space. Comparing with other computational approaches, our\n(conditional) evaluation model reduced 24.1%-99.0% evaluation errors across 12\nscenes, including individual medicine, scientific simulation, business\nactivities, and quantum trade. The evaluation time is reduced 3-7 order of\nmagnitude comparing with experiments or simulations.",
      "tldr_zh": "",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21138v1",
      "published_date": "2025-03-27 04:00:49 UTC",
      "updated_date": "2025-03-27 04:00:49 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898974"
    },
    {
      "arxiv_id": "2503.21109v1",
      "title": "Optimizing Multi-DNN Inference on Mobile Devices through Heterogeneous Processor Co-Execution",
      "title_zh": "",
      "authors": [
        "Yunquan Gao",
        "Zhiguo Zhang",
        "Praveen Kumar Donta",
        "Chinmaya Kumar Dehury",
        "Xiujun Wang",
        "Dusit Niyato",
        "Qiyang Zhang"
      ],
      "abstract": "Deep Neural Networks (DNNs) are increasingly deployed across diverse\nindustries, driving demand for mobile device support. However, existing mobile\ninference frameworks often rely on a single processor per model, limiting\nhardware utilization and causing suboptimal performance and energy efficiency.\nExpanding DNN accessibility on mobile platforms requires adaptive,\nresource-efficient solutions to meet rising computational needs without\ncompromising functionality. Parallel inference of multiple DNNs on\nheterogeneous processors remains challenging. Some works partition DNN\noperations into subgraphs for parallel execution across processors, but these\noften create excessive subgraphs based only on hardware compatibility,\nincreasing scheduling complexity and memory overhead.\n  To address this, we propose an Advanced Multi-DNN Model Scheduling (ADMS)\nstrategy for optimizing multi-DNN inference on mobile heterogeneous processors.\nADMS constructs an optimal subgraph partitioning strategy offline, balancing\nhardware operation support and scheduling granularity, and uses a\nprocessor-state-aware algorithm to dynamically adjust workloads based on\nreal-time conditions. This ensures efficient workload distribution and\nmaximizes processor utilization. Experiments show ADMS reduces multi-DNN\ninference latency by 4.04 times compared to vanilla frameworks.",
      "tldr_zh": "",
      "categories": [
        "cs.DC",
        "cs.AI",
        "68T07, 68W40",
        "I.2.6; C.1.4; D.4.8"
      ],
      "primary_category": "cs.DC",
      "comment": "14 pages, 12 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.21109v1",
      "published_date": "2025-03-27 03:03:09 UTC",
      "updated_date": "2025-03-27 03:03:09 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898979"
    },
    {
      "arxiv_id": "2503.21098v1",
      "title": "Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search",
      "title_zh": "",
      "authors": [
        "Yedan Shen",
        "Kaixin Wu",
        "Yuechen Ding",
        "Jingyuan Wen",
        "Hong Liu",
        "Mingjie Zhong",
        "Zhouhan Lin",
        "Jia Xu",
        "Linjian Mo"
      ],
      "abstract": "Generative retrieval (GR) has revolutionized document retrieval with the\nadvent of large language models (LLMs), and LLM-based GR is gradually being\nadopted by the industry. Despite its remarkable advantages and potential,\nLLM-based GR suffers from hallucination and generates documents that are\nirrelevant to the query in some instances, severely challenging its credibility\nin practical applications. We thereby propose an optimized GR framework\ndesigned to alleviate retrieval hallucination, which integrates knowledge\ndistillation reasoning in model training and incorporate decision agent to\nfurther improve retrieval precision. Specifically, we employ LLMs to assess and\nreason GR retrieved query-document (q-d) pairs, and then distill the reasoning\ndata as transferred knowledge to the GR model. Moreover, we utilize a decision\nagent as post-processing to extend the GR retrieved documents through retrieval\nmodel and select the most relevant ones from multi perspectives as the final\ngenerative retrieval result. Extensive offline experiments on real-world\ndatasets and online A/B tests on Fund Search and Insurance Search in Alipay\ndemonstrate our framework's superiority and effectiveness in improving search\nquality and conversion gains.",
      "tldr_zh": "",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.21098v1",
      "published_date": "2025-03-27 02:36:48 UTC",
      "updated_date": "2025-03-27 02:36:48 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898984"
    },
    {
      "arxiv_id": "2503.21095v1",
      "title": "Confidence Adjusted Surprise Measure for Active Resourceful Trials (CA-SMART): A Data-driven Active Learning Framework for Accelerating Material Discovery under Resource Constraints",
      "title_zh": "",
      "authors": [
        "Ahmed Shoyeb Raihan",
        "Zhichao Liu",
        "Tanveer Hossain Bhuiyan",
        "Imtiaz Ahmed"
      ],
      "abstract": "Accelerating the discovery and manufacturing of advanced materials with\nspecific properties is a critical yet formidable challenge due to vast search\nspace, high costs of experiments, and time-intensive nature of material\ncharacterization. In recent years, active learning, where a surrogate machine\nlearning (ML) model mimics the scientific discovery process of a human\nscientist, has emerged as a promising approach to address these challenges by\nguiding experimentation toward high-value outcomes with a limited budget. Among\nthe diverse active learning philosophies, the concept of surprise (capturing\nthe divergence between expected and observed outcomes) has demonstrated\nsignificant potential to drive experimental trials and refine predictive\nmodels. Scientific discovery often stems from surprise thereby making it a\nnatural driver to guide the search process. Despite its promise, prior studies\nleveraging surprise metrics such as Shannon and Bayesian surprise lack\nmechanisms to account for prior confidence, leading to excessive exploration of\nuncertain regions that may not yield useful information. To address this, we\npropose the Confidence-Adjusted Surprise Measure for Active Resourceful Trials\n(CA-SMART), a novel Bayesian active learning framework tailored for optimizing\ndata-driven experimentation. On a high level, CA-SMART incorporates\nConfidence-Adjusted Surprise (CAS) to dynamically balance exploration and\nexploitation by amplifying surprises in regions where the model is more certain\nwhile discounting them in highly uncertain areas. We evaluated CA-SMART on two\nbenchmark functions (Six-Hump Camelback and Griewank) and in predicting the\nfatigue strength of steel. The results demonstrate superior accuracy and\nefficiency compared to traditional surprise metrics, standard Bayesian\nOptimization (BO) acquisition functions and conventional ML methods.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21095v1",
      "published_date": "2025-03-27 02:21:42 UTC",
      "updated_date": "2025-03-27 02:21:42 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898989"
    },
    {
      "arxiv_id": "2503.21088v1",
      "title": "ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging",
      "title_zh": "",
      "authors": [
        "Haoming Xu",
        "Shuxun Wang",
        "Yanqiu Zhao",
        "Yi Zhong",
        "Ziyan Jiang",
        "Ningyuan Zhao",
        "Shumin Deng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "This paper presents the ZJUKLAB team's submission for SemEval-2025 Task 4:\nUnlearning Sensitive Content from Large Language Models. This task aims to\nselectively erase sensitive knowledge from large language models, avoiding both\nover-forgetting and under-forgetting issues. We propose an unlearning system\nthat leverages Model Merging (specifically TIES-Merging), combining two\nspecialized models into a more balanced unlearned model. Our system achieves\ncompetitive results, ranking second among 26 teams, with an online score of\n0.944 for Task Aggregate and 0.487 for overall Aggregate. In this paper, we\nalso conduct local experiments and perform a comprehensive analysis of the\nunlearning process, examining performance trajectories, loss dynamics, and\nweight perspectives, along with several supplementary experiments, to\nunderstand the effectiveness of our method. Furthermore, we analyze the\nshortcomings of our method and evaluation metrics, emphasizing that MIA scores\nand ROUGE-based metrics alone are insufficient to fully evaluate successful\nunlearning. Finally, we emphasize the need for more comprehensive evaluation\nmethodologies and rethinking of unlearning objectives in future research. Code\nis available at https://github.com/zjunlp/unlearn/tree/main/semeval25.",
      "tldr_zh": "",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.21088v1",
      "published_date": "2025-03-27 02:03:25 UTC",
      "updated_date": "2025-03-27 02:03:25 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.898995"
    },
    {
      "arxiv_id": "2503.21074v1",
      "title": "Rerouting Connection: Hybrid Computer Vision Analysis Reveals Visual Similarity Between Indus and Tibetan-Yi Corridor Writing Systems",
      "title_zh": "",
      "authors": [
        "Ooha Lakkadi Reddy"
      ],
      "abstract": "This thesis employs a hybrid CNN-Transformer architecture, in conjunction\nwith a detailed anthropological framework, to investigate potential historical\nconnections between the visual morphology of the Indus Valley script and\npictographic systems of the Tibetan-Yi Corridor. Through an ensemble\nmethodology of three target scripts across 15 independently trained models, we\ndemonstrate that Tibetan-Yi Corridor scripts exhibit approximately six-fold\nhigher visual similarity to the Indus script (61.7%-63.5%) than to the Bronze\nAge Proto-Cuneiform (10.2%-10.9%) or Proto-Elamite (7.6%-8.7%) systems.\nAdditionally and contrarily to our current understanding of the networks of the\nIndus Valley Civilization, the Indus script unexpectedly maps closer to\nTibetan-Yi Corridor scripts, with a mean cosine similarity of 0.629, than to\nthe aforementioned contemporaneous West Asian signaries, both of which recorded\nmean cosine similarities of 0.104 and 0.080 despite their close geographic\nproximity and evident trade relations. Across various dimensionality reduction\npractices and clustering methodologies, the Indus script consistently clusters\nclosest to Tibetan-Yi Corridor scripts. Our computational results align with\nqualitative observations of specific pictorial parallels in numeral systems,\ngender markers, and key iconographic elements; this is further supported by\narchaeological evidence of sustained contact networks along the ancient\nShu-Shendu road in tandem with the Indus Valley Civilization's decline,\nproviding a plausible transmission pathway. While alternative explanations\ncannot be ruled out, the specificity and consistency of observed similarities\nchallenge conventional narratives of isolated script development and suggest\nmore complex ancient cultural transmission networks between South and East Asia\nthan previously recognized.",
      "tldr_zh": "",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "106 pages total (main text: 42, 48 w/refs, 100 w/appendices). 21\n  figures, 4 tables in main; 106 figs, 8 tables total. Code and data at this\n  URL: https://github.com/oohalakkadi/ivc2tyc. Submitted as undergrad thesis at\n  Duke Kunshan University; accepted for presentation at the 2025 Computer\n  Applications and Quantitative Methods in Archaeology Conference, Athens",
      "pdf_url": "http://arxiv.org/pdf/2503.21074v1",
      "published_date": "2025-03-27 01:19:47 UTC",
      "updated_date": "2025-03-27 01:19:47 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.899000"
    },
    {
      "arxiv_id": "2503.21067v1",
      "title": "AskSport: Web Application for Sports Question-Answering",
      "title_zh": "",
      "authors": [
        "Enzo B Onofre",
        "Leonardo M P Moraes",
        "Cristina D Aguiar"
      ],
      "abstract": "This paper introduces AskSport, a question-answering web application about\nsports. It allows users to ask questions using natural language and retrieve\nthe three most relevant answers, including related information and documents.\nThe paper describes the characteristics and functionalities of the application,\nincluding use cases demonstrating its ability to return names and numerical\nvalues. AskSport and its implementation are available for public access on\nHuggingFace.",
      "tldr_zh": "",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.1; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "for accessing the application, see\n  https://huggingface.co/spaces/leomaurodesenv/qasports-website",
      "pdf_url": "http://arxiv.org/pdf/2503.21067v1",
      "published_date": "2025-03-27 00:57:27 UTC",
      "updated_date": "2025-03-27 00:57:27 UTC",
      "processing_status": "pending",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [],
      "last_update": "2025-03-28T17:21:13.899005"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 82,
  "processed_papers_count": 21,
  "failed_papers_count": 0,
  "summary_generated": false,
  "daily_data_saved": false,
  "last_update": "2025-03-28T17:34:25.316897"
}