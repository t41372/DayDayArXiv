{
  "date": "2025-07-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-07-09 的 arXiv 中文 TLDR 快报！\n\n**一句话总结：**\n今天的 arXiv 充满了“硬核”的反思与突破——图灵奖得主 Shafi Goldwasser 团队从理论上证明了 AI 外部过滤器的局限性，Google DeepMind 揭示了前沿 LLM 在简单推理任务上的“智商掉线”，而 AI for Science 领域迎来了能执行博士级宇宙学研究的多智能体系统。\n\n---\n\n### 【重磅理论与安全：AI 的“智商”与“判断力”不可分割】\n\n**1. On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment**\n**(论分离智能与判断的不可能性：AI 对齐中过滤的计算难解性)**\n> **Authors:** Sarah Ball, Shafi Goldwasser, et al.\n> **关键词:** AI Alignment, Filters, Cryptographic Hardness, LLM Safety\n\n这是一篇极具分量的理论文章，作者包括图灵奖得主 Shafi Goldwasser。\n- **核心观点：** 文章在密码学困难假设下证明，试图通过外部过滤器（即不触碰 LLM 内部权重，仅过滤输入 Prompt 或输出内容）来实现 AI 安全是**不可行**的。\n- **主要发现：**\n    1.  **Prompt 过滤无效：** 攻击者可以轻易构造出对抗性 Prompt，这些 Prompt 在任何高效过滤器看来都与良性 Prompt 在计算上无法区分（Computationally Indistinguishable）。\n    2.  **输出过滤难解：** 存在自然的设定，使得对 LLM 输出的有害性过滤在计算上是不可处理的。\n- **Implication：** 这意味着 AI 的“智能”与其“判断力”（Judgment）无法解耦，单纯依赖黑盒式的外部防护栏（Guardrails）不足以保证安全，安全机制必须深入模型内部架构。\n\n**6. Frontier LLMs Still Struggle with Simple Reasoning Tasks**\n**(前沿 LLM 仍受困于简单推理任务)**\n> **Authors:** Alan Malek, DeepMind 团队等\n> **关键词:** Reasoning, Generalization, Unpuzzles\n\n- **核心发现：** 尽管现在的模型能解奥数题，但它们在人类觉得“很简单”的任务上经常翻车。作者构建了一个 `unpuzzles` 数据集，将经典谜题“简化”或“去智化”（trivialized）。\n- **现象：** 令人惊讶的是，模型能解决复杂的原始谜题（可能是背下来的），却在简化版上失败。这表明模型更多依赖于**记忆和统计捷径**，而非真正的逻辑推理。即使是所谓的“思考型模型”（Thinking Models）也未能幸免。\n\n**43. What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models**\n**(基础模型发现了什么？利用归纳偏置探测世界模型)**\n> **Authors:** Keyon Vafa, Sendhil Mullainathan, et al. (To appear in ICML 2025)\n> **关键词:** World Models, Inductive Bias\n\n- **核心贡献：** 提出了一种通过“归纳偏置探测”（Inductive Bias Probe）来评估模型是否真正学到了底层世界模型的方法。\n- **结论：** 即使模型在训练任务上表现完美（例如预测行星轨迹），但在适应新任务时，它们往往**无法应用**牛顿力学等底层物理规律，而是退回到特定任务的启发式方法。这挑战了“序列预测即理解”的假设。\n\n---\n\n### 【模型架构与高效训练：LoRA 与优化器的新视角】\n\n**99. The Primacy of Magnitude in Low-Rank Adaptation**\n**(LoRA 中幅度的首要地位)**\n> **Authors:** Zicheng Zhang, et al. (NeurIPS 2025 Spotlight)\n> **关键词:** LoRA, Initialization, Weight Magnitude\n\n- **核心贡献：** 挑战了 LoRA 初始化中关于“谱”属性（Spectral）的迷信。作者证明，权重更新的**幅度（Magnitude）**才是决定收敛和性能的关键。\n- **方法：** 提出了 **LoRAM**，一种基于幅度的初始化方案，无需复杂的谱初始化计算，仅通过调整更新幅度就能达到 SOTA 效果。\n\n**113. SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam**\n**(SoftSignSGD(S3)：超越 Adam 的实用 DNN 训练与 Loss 尖峰最小化优化器)**\n> **Authors:** Hanyang Peng, Wen Gao, et al.\n> **关键词:** Optimizer, Adam, SignSGD\n\n- **核心贡献：** 针对 Adam 容易出现的 Loss Spikes（损失尖峰）问题，提出了一种新优化器 **S3**。\n- **改进：** 结合了 SignSGD 处理梯度的鲁棒性和 Adam 的适应性，使用 p 阶动量和统一的 EMA 系数。实验显示，S3 在使用 **10 倍于 Adam 的学习率**下仍能稳定训练，且收敛更快，没有 Loss Spikes。\n\n**31. FlexOlmo: Open Language Models for Flexible Data Use**\n**(FlexOlmo：面向灵活数据使用的开放语言模型)**\n> **Authors:** Weijia Shi, Noah A. Smith, Luke Zettlemoyer, et al.\n> **关键词:** MoE, Data Privacy, Distributed Training\n\n- **核心贡献：** 解决企业数据隐私与联合训练的矛盾。FlexOlmo 是一种 MoE 架构，允许不同数据拥有者在**不共享数据**的情况下独立训练 Expert，然后通过一种新的路由机制将它们整合，无需联合训练。\n\n---\n\n### 【Agentic AI：从科学发现到安全攻防】\n\n**13. Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery**\n**(用于自主科学发现的开源规划与控制语言智能体系统)**\n> **Authors:** Licong Xu, et al.\n> **关键词:** AI Scientist, Cosmology, Multi-agent\n\n- **核心贡献：** 发布了 **cmbagent**，一个包含约 30 个 LLM 智能体的系统，能够**全自动执行博士级别的宇宙学研究任务**（如利用超新星数据测量宇宙学参数）。\n- **能力：** 系统实现了无人在环（human-out-of-the-loop）的文献检索、代码编写、结果解释和相互评审。\n\n**112. Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models**\n**(基础模型自我博弈：通过基础模型实现的开放式策略创新)**\n> **Authors:** Aaron Dharna, Jeff Clune, et al. (RLC 2025)\n> **关键词:** Self-Play, Open-Ended Learning, Red-teaming\n\n- **核心贡献：** 提出了 FMSP（Foundation-Model Self-Play），利用 FM 的代码生成能力来改进传统的自我博弈（Self-Play）。\n- **应用：** 在 Gandalf（AI 安全模拟）中，该方法能自动进行红队攻击（Red-teaming），不仅能攻破防御，还能自动修复漏洞，展示了强大的策略探索能力。\n\n**56. The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover**\n**(LLM 的阴暗面：基于智能体的计算机完全接管攻击)**\n> **Authors:** Matteo Lupinacci, et al.\n> **关键词:** Agent Security, RAG Backdoor, Prompt Injection\n\n- **警示：** 评估了 18 个 SOTA LLM，发现 94.4% 的模型容易遭受直接 Prompt 注入，更可怕的是 **100%** 的模型可以被“智能体间信任利用攻击”（Inter-Agent Trust Exploitation）攻破。即便单个模型能防御，但在多智能体系统中，它们会因为信任队友而执行恶意载荷。\n\n---\n\n### 【视觉与多模态精选】\n\n**2. ConsNoTrainLoRA: Data-driven Weight Initialization of Low-rank Adapters using Constraints**\n**(ConsNoTrainLoRA: 基于约束的数据驱动 LoRA 权重初始化)**\n> **Authors:** Debasmit Das, et al. (ICCV 2025)\n> **关键词:** LoRA, Initialization, Fine-tuning\n\n- **方法：** 将 LoRA 初始化视为域迁移问题，利用预训练和微调数据的激活约束，导出了一个无需训练的闭式解来初始化 LoRA 权重，在图像生成和分类任务上显著提升了收敛速度。\n\n**5. Generating Moving 3D Soundscapes with Latent Diffusion Models**\n**(利用潜在扩散模型生成移动 3D 声景)**\n> **Authors:** Christian Templin, et al.\n> **关键词:** Spatial Audio, 3D Sound, Diffusion Models\n\n- **核心贡献：** 提出了 **SonicMotion**，这是第一个能生成带有**移动声源**的高保真 3D 音频（First-Order Ambisonics）的端到端扩散框架。这对于 VR/AR 和沉浸式体验是重大进步。\n\n**66. Democratizing High-Fidelity Co-Speech Gesture Video Generation**\n**(普及高保真伴随语音手势视频生成)**\n> **Authors:** Xu Yang, et al. (ICCV 2025)\n> **关键词:** Video Generation, Co-speech Gesture\n\n- **核心贡献：** 解决说话人视频生成中的手势同步问题。发布了 CSG-405 数据集（405小时），并提出了一种利用 2D 骨架作为辅助条件的轻量级扩散框架，实现了高保真的语音-手势同步。\n\n---\n**日报结语：**\n今天的论文提醒我们，虽然 Agent 已经能做博士课题了，但基础模型在最基本的逻辑判断和对抗防御上仍有巨大漏洞。Goldwasser 的理论证明更是给简单的“外挂安全”判了死刑。\nHave a productive day reading!",
  "papers": [
    {
      "arxiv_id": "2507.07341v1",
      "title": "On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment",
      "title_zh": "论智能与判断的不可分性：AI 对齐过滤机制的计算难解性",
      "authors": [
        "Sarah Ball",
        "Greg Gluch",
        "Shafi Goldwasser",
        "Frauke Kreuter",
        "Omer Reingold",
        "Guy N. Rothblum"
      ],
      "abstract": "With the increased deployment of large language models (LLMs), one concern is their potential misuse for generating harmful content. Our work studies the alignment challenge, with a focus on filters to prevent the generation of unsafe information. Two natural points of intervention are the filtering of the input prompt before it reaches the model, and filtering the output after generation. Our main results demonstrate computational challenges in filtering both prompts and outputs. First, we show that there exist LLMs for which there are no efficient prompt filters: adversarial prompts that elicit harmful behavior can be easily constructed, which are computationally indistinguishable from benign prompts for any efficient filter. Our second main result identifies a natural setting in which output filtering is computationally intractable. All of our separation results are under cryptographic hardness assumptions. In addition to these core findings, we also formalize and study relaxed mitigation approaches, demonstrating further computational barriers. We conclude that safety cannot be achieved by designing filters external to the LLM internals (architecture and weights); in particular, black-box access to the LLM will not suffice. Based on our technical results, we argue that an aligned AI system's intelligence cannot be separated from its judgment.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在AI对齐(alignment)方面的挑战，重点分析了通过过滤器防止有害内容生成的局限性。研究通过基于密码学硬度假设(cryptographic hardness assumptions)的理论分析，证明了对输入提示(prompt)和输出内容进行过滤在计算上是不可行的(computationally intractable)。结果表明，存在某些模型使得对抗性提示与良性提示对于任何高效过滤器而言都无法区分，且在自然设定下输出过滤同样面临计算困境。研究最终得出结论，仅靠外部过滤器或黑盒访问(black-box access)无法实现AI安全，AI系统的智能与其判断力(judgment)无法分离，安全机制必须深入到模型内部而非仅仅依赖外部干预。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07341v1",
      "published_date": "2025-07-09 23:55:35 UTC",
      "updated_date": "2025-07-09 23:55:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:34:49.697090+00:00"
    },
    {
      "arxiv_id": "2507.08044v1",
      "title": "ConsNoTrainLoRA: Data-driven Weight Initialization of Low-rank Adapters using Constraints",
      "title_zh": "ConsNoTrainLoRA：基于约束的低秩自适应权重数据驱动初始化",
      "authors": [
        "Debasmit Das",
        "Hyoungwoo Park",
        "Munawar Hayat",
        "Seokeon Choi",
        "Sungrack Yun",
        "Fatih Porikli"
      ],
      "abstract": "Foundation models are pre-trained on large-scale datasets and subsequently fine-tuned on small-scale datasets using parameter-efficient fine-tuning (PEFT) techniques like low-rank adapters (LoRA). In most previous works, LoRA weight matrices are randomly initialized with a fixed rank across all attachment points. In this paper, we improve convergence and final performance of LoRA fine-tuning, using our proposed data-driven weight initialization method, ConsNoTrainLoRA (CNTLoRA). We express LoRA initialization as a domain shift problem where we use multiple constraints relating the pre-training and fine-tuning activations. By reformulating these constraints, we obtain a closed-form estimate of LoRA weights that depends on pre-training weights and fine-tuning activation vectors and hence requires no training during initialization. This weight estimate is decomposed to initialize the up and down matrices with proposed flexibility of variable ranks. With the proposed initialization method, we fine-tune on downstream tasks such as image generation, image classification and image understanding. Both quantitative and qualitative results demonstrate that CNTLoRA outperforms standard and data-driven weight initialization methods. Extensive analyses and ablations further elucidate the design choices of our framework, providing an optimal recipe for faster convergence and enhanced performance.",
      "tldr_zh": "该研究针对预训练基础模型在使用低秩适配器(LoRA)进行参数高效微调(PEFT)时面临的权重随机初始化及固定秩(fixed rank)限制，提出了名为ConsNoTrainLoRA (CNTLoRA)的数据驱动初始化方法。CNTLoRA将初始化过程建模为领域偏移(domain shift)问题，通过建立预训练与微调激活向量之间的约束关系，推导出权重的闭式估计(closed-form estimate)，从而实现在初始化阶段无需额外训练。该方法支持可变秩(variable ranks)矩阵分解，能够更灵活地适应不同任务需求。在图像生成、分类和理解等下游任务的实验表明，CNTLoRA在收敛速度和最终性能上均显著优于传统的随机初始化及其他数据驱动方法。消融实验进一步验证了其框架设计的有效性，为提升大模型微调效率提供了新的技术路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.08044v1",
      "published_date": "2025-07-09 23:52:31 UTC",
      "updated_date": "2025-07-09 23:52:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:34:53.600945+00:00"
    },
    {
      "arxiv_id": "2507.07335v1",
      "title": "Leveraging Manifold Embeddings for Enhanced Graph Transformer Representations and Learning",
      "title_zh": "利用流形嵌入增强图 Transformer 的表征与学习",
      "authors": [
        "Ankit Jyothish",
        "Ali Jannesari"
      ],
      "abstract": "Graph transformers typically embed every node in a single Euclidean space, blurring heterogeneous topologies. We prepend a lightweight Riemannian mixture-of-experts layer that routes each node to various kinds of manifold, mixture of spherical, flat, hyperbolic - best matching its local structure. These projections provide intrinsic geometric explanations to the latent space. Inserted into a state-of-the-art ensemble graph transformer, this projector lifts accuracy by up to 3% on four node-classification benchmarks. The ensemble makes sure that both euclidean and non-euclidean features are captured. Explicit, geometry-aware projection thus sharpens predictive power while making graph representations more interpretable.",
      "tldr_zh": "该研究针对 Graph transformers 通常将所有节点嵌入单一 Euclidean space 从而模糊异构拓扑结构的问题，提出了一种利用多流形嵌入增强图表示的学习方法。作者通过引入一个轻量级的 Riemannian mixture-of-experts 层，将每个节点根据其局部结构特征路由至最匹配的流形空间，包括 spherical、flat 和 hyperbolic 空间。该投影层被集成到先进的 ensemble graph transformer 中，确保模型能够同时捕捉 Euclidean 和 non-Euclidean 特征，为潜空间提供内在的几何解释。实验结果表明，这种显式的几何感知投影在四个 node-classification 基准测试中将准确率提升了高达 3%。该方法在显著增强模型预测能力的同时，也大幅提升了图表示的可解释性，证明了针对性流形映射在处理复杂图拓扑中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07335v1",
      "published_date": "2025-07-09 23:33:36 UTC",
      "updated_date": "2025-07-09 23:33:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:34:56.707510+00:00"
    },
    {
      "arxiv_id": "2507.07328v2",
      "title": "Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery",
      "title_zh": "通过微调推理增强型大语言模型弥合化学合成与发现中的似真性与有效性差距",
      "authors": [
        "Malikussaid",
        "Hilal Hudan Nuha",
        "Isman Kurniawan"
      ],
      "abstract": "Large Language Models frequently generate outputs that appear scientifically reasonable yet violate fundamental principles--a phenomenon we characterize as the \"plausibility-validity gap.\" This challenge proves especially acute in chemistry, where superficial correctness masks deeper errors in molecular structure, reaction mechanisms, and synthetic pathways. We present a systematic approach combining a reasoning-centric model architecture (Magistral Small) with Low-Rank Adaptation fine-tuning on a dual-domain dataset covering molecular properties and chemical transformations. Evaluation reveals substantial improvements: the fine-tuned system achieves 96.3% format adherence, 97.4% chemical validity, and 74.4% synthesis feasibility. Comparative analysis shows our approach outperforms specialized translation models like MolT5 (97.4% vs 77.2% validity) while achieving performance comparable to complex tool-augmented systems like ChemCrow (9.0/10 vs 9.24/10 expert rating) through a more transparent, efficient methodology. Results demonstrate a learning hierarchy where syntactic correctness develops before chemical understanding, which precedes synthetic planning capability. This work establishes a reproducible framework for transforming generalist language models into dependable scientific tools while identifying critical areas including stereochemical precision, knowledge currency, and computational accessibility as key challenges for future advancement.",
      "tldr_zh": "该研究针对大语言模型在化学领域普遍存在的“看似合理但科学有误”现象（即plausibility-validity gap），提出了一种通过微调增强推理模型来优化化学合成与发现的系统性方案。作者采用以推理为核心的Magistral Small架构，并结合低秩自适应(Low-Rank Adaptation)技术在分子性质与化学转化的双领域数据集上进行训练。实验结果表明，该系统实现了97.4%的化学有效性(chemical validity)和74.4%的合成可行性(synthesis feasibility)，在性能上显著超越了MolT5等专用模型，并达到了与ChemCrow等复杂工具增强系统相媲美的专家评分。研究进一步揭示了模型在掌握科学知识时存在从语法正确、化学理解到合成规划能力的学习梯度。该工作为将通用大语言模型转化为可靠的科学工具提供了可复制框架，同时指出立体化学精度(stereochemical precision)和知识时效性是未来进一步提升的关键挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 1 equation, 5 tables, to be published in IEEE MCSoC 2025, unabridged version exists as arXiv:2507.07328v1",
      "pdf_url": "https://arxiv.org/pdf/2507.07328v2",
      "published_date": "2025-07-09 23:05:23 UTC",
      "updated_date": "2025-11-10 04:20:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:14.829947+00:00"
    },
    {
      "arxiv_id": "2507.07318v2",
      "title": "Generating Moving 3D Soundscapes with Latent Diffusion Models",
      "title_zh": "基于潜在扩散模型的动态 3D 声景生成",
      "authors": [
        "Christian Templin",
        "Yanda Zhu",
        "Hao Wang"
      ],
      "abstract": "Spatial audio has become central to immersive applications such as VR/AR, cinema, and music. Existing generative audio models are largely limited to mono or stereo formats and cannot capture the full 3D localization cues available in first-order Ambisonics (FOA). Recent FOA models extend text-to-audio generation but remain restricted to static sources. In this work, we introduce SonicMotion, the first end-to-end latent diffusion framework capable of generating FOA audio with explicit control over moving sound sources. SonicMotion is implemented in two variations: 1) a descriptive model conditioned on natural language prompts, and 2) a parametric model conditioned on both text and spatial trajectory parameters for higher precision. To support training and evaluation, we construct a new dataset of over one million simulated FOA caption pairs that include both static and dynamic sources with annotated azimuth, elevation, and motion attributes. Experiments show that SonicMotion achieves state-of-the-art semantic alignment and perceptual quality comparable to leading text-to-audio systems, while uniquely attaining low spatial localization error.",
      "tldr_zh": "该研究提出了SonicMotion，这是一个能够生成具有动态移动声源的一阶歧义立体声(First-order Ambisonics, FOA)音频的端到端潜在扩散模型(Latent Diffusion Models)框架。该框架旨在解决现有音频生成模型局限于单声道或双声道，且现有FOA模型通常只能处理静态声源的问题。SonicMotion提供了两种版本：一种是基于自然语言提示的描述性模型，另一种是结合文本与空间轨迹参数以实现更高精度的参数化模型。为了支持这一研究，团队构建了一个包含超过一百万个FOA标题对的新数据集，详细标注了静态与动态声源的方位角、仰角和运动属性。实验结果证明，SonicMotion在语义对齐和感知质量上达到了最先进(State-of-the-art)水平，表现出与领先文本转音频系统相当的性能。此外，该模型在空间定位精度方面具有独特优势，实现了极低的空间定位误差，为VR/AR、电影及音乐等沉浸式应用提供了强大的技术支撑。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07318v2",
      "published_date": "2025-07-09 22:31:06 UTC",
      "updated_date": "2025-09-19 13:59:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:06.289600+00:00"
    },
    {
      "arxiv_id": "2507.07313v1",
      "title": "Frontier LLMs Still Struggle with Simple Reasoning Tasks",
      "title_zh": "前沿大语言模型在简单推理任务上依然面临挑战",
      "authors": [
        "Alan Malek",
        "Jiawei Ge",
        "Nevena Lazic",
        "Chi Jin",
        "András György",
        "Csaba Szepesvári"
      ],
      "abstract": "While state-of-the-art large language models (LLMs) demonstrate advanced reasoning capabilities-achieving remarkable performance on challenging competitive math and coding benchmarks-they also frequently fail on tasks that are easy for humans. This work studies the performance of frontier LLMs on a broad set of such \"easy\" reasoning problems. By extending previous work in the literature, we create a suite of procedurally generated simple reasoning tasks, including counting, first-order logic, proof trees, and travel planning, with changeable parameters (such as document length. or the number of variables in a math problem) that can arbitrarily increase the amount of computation required to produce the answer while preserving the fundamental difficulty. While previous work showed that traditional, non-thinking models can be made to fail on such problems, we demonstrate that even state-of-the-art thinking models consistently fail on such problems and for similar reasons (e.g. statistical shortcuts, errors in intermediate steps, and difficulties in processing long contexts). To further understand the behavior of the models, we introduce the unpuzzles dataset, a different \"easy\" benchmark consisting of trivialized versions of well-known math and logic puzzles. Interestingly, while modern LLMs excel at solving the original puzzles, they tend to fail on the trivialized versions, exhibiting several systematic failure patterns related to memorizing the originals. We show that this happens even if the models are otherwise able to solve problems with different descriptions but requiring the same logic. Our results highlight that out-of-distribution generalization is still problematic for frontier language models and the new generation of thinking models, even for simple reasoning tasks, and making tasks easier does not necessarily imply improved performance.",
      "tldr_zh": "该研究探讨了前沿大语言模型(LLMs)在人类易于处理的简单推理任务中的表现，发现即使是最先进的“思考型”模型在这些任务上也经常失败。作者构建了一套程序化生成的简单推理任务集，涵盖counting、first-order logic、proof trees和travel planning，并可通过调整参数来增加计算量而保持任务基础难度不变。实验结果表明，模型常因statistical shortcuts、中间步骤错误以及长上下文处理困难而在这些简单任务上表现不佳。研究还进一步引入了unpuzzles数据集，即著名数学和逻辑谜题的极简版本，以分析模型的行为模式。实验发现，LLMs虽然擅长解决原始难题，却往往在简化版上失效，表现出与记忆原文相关的系统性失败模式。研究结果强调，对于前沿模型和新一代“思考型”模型而言，out-of-distribution generalization依然是一个严峻挑战，且任务难度的降低并不必然带来性能的提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "53 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.07313v1",
      "published_date": "2025-07-09 22:22:49 UTC",
      "updated_date": "2025-07-09 22:22:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:12.500234+00:00"
    },
    {
      "arxiv_id": "2507.07306v1",
      "title": "ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning",
      "title_zh": "ViDove：融合多模态语境与记忆增强推理的翻译智能体系统",
      "authors": [
        "Yichen Lu",
        "Wei Dai",
        "Jiaen Liu",
        "Ching Wing Kwok",
        "Zongheng Wu",
        "Xudong Xiao",
        "Ao Sun",
        "Sheng Fu",
        "Jianyuan Zhan",
        "Yian Wang",
        "Takatomo Saito",
        "Sicheng Lai"
      ],
      "abstract": "LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here: https://github.com/pigeonai-org/ViDove",
      "tldr_zh": "该研究介绍了ViDove，这是一个专为多模态(multimodal)输入设计的翻译智能体(agent)系统，旨在解决现有大语言模型翻译工具仅限于文本输入的问题。受人类翻译工作流启发，ViDove利用视觉信息和上下文背景来增强翻译过程，并集成了多模态记忆系统以及富含领域知识的长短期记忆模块，使智能体能够在实际场景中实现更准确且具适应性的翻译。实验结果显示，ViDove在字幕生成和通用翻译任务中表现卓越，相比之前的SOTA基线模型，其BLEU得分提升了28%，SubER提升了15%。此外，该研究还推出了DoveBench，这是一个包含17小时高质量人工标注数据的长视频自动字幕与翻译新基准，为该领域的研究提供了重要支持。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07306v1",
      "published_date": "2025-07-09 22:05:46 UTC",
      "updated_date": "2025-07-09 22:05:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:10.985177+00:00"
    },
    {
      "arxiv_id": "2507.07302v1",
      "title": "Application of LLMs to Multi-Robot Path Planning and Task Allocation",
      "title_zh": "大语言模型在多机器人路径规划与任务分配中的应用",
      "authors": [
        "Ashish Kumar"
      ],
      "abstract": "Efficient exploration is a well known problem in deep reinforcement learning and this problem is exacerbated in multi-agent reinforcement learning due the intrinsic complexities of such algorithms. There are several approaches to efficiently explore an environment to learn to solve tasks by multi-agent operating in that environment, of which, the idea of expert exploration is investigated in this work. More specifically, this work investigates the application of large-language models as expert planners for efficient exploration in planning based tasks for multiple agents.",
      "tldr_zh": "该研究探讨了在多智能体强化学习（MARL）中解决高效探索（Efficient exploration）这一难题，特别是在多机器人路径规划和任务分配的应用场景下。针对深度强化学习在多智能体环境中面临的内在复杂性，作者提出并研究了专家探索（Expert exploration）的概念。具体而言，该工作研究了将大语言模型（LLMs）作为专家规划器（Expert planners）的具体应用，以实现多智能体在规划类任务中的高效探索。通过利用 LLMs 的规划能力，该方法旨在克服传统算法在环境探索中的局限性，从而更有效地学习复杂任务的解决方案。该研究展示了将大语言模型集成到多智能体系统中以优化决策过程并提升学习效率的潜力。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07302v1",
      "published_date": "2025-07-09 22:01:32 UTC",
      "updated_date": "2025-07-09 22:01:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:15.994547+00:00"
    },
    {
      "arxiv_id": "2507.16829v1",
      "title": "You Don't Bring Me Flowers: Mitigating Unwanted Recommendations Through Conformal Risk Control",
      "title_zh": "“你不给我带花”：基于符合性风险控制缓解非预期推荐",
      "authors": [
        "Giovanni De Toni",
        "Erasmo Purificato",
        "Emilia Gómez",
        "Bruno Lepri",
        "Andrea Passerini",
        "Cristian Consonni"
      ],
      "abstract": "Recommenders are significantly shaping online information consumption. While effective at personalizing content, these systems increasingly face criticism for propagating irrelevant, unwanted, and even harmful recommendations. Such content degrades user satisfaction and contributes to significant societal issues, including misinformation, radicalization, and erosion of user trust. Although platforms offer mechanisms to mitigate exposure to undesired content, these mechanisms are often insufficiently effective and slow to adapt to users' feedback. This paper introduces an intuitive, model-agnostic, and distribution-free method that uses conformal risk control to provably bound unwanted content in personalized recommendations by leveraging simple binary feedback on items. We also address a limitation of traditional conformal risk control approaches, i.e., the fact that the recommender can provide a smaller set of recommended items, by leveraging implicit feedback on consumed items to expand the recommendation set while ensuring robust risk mitigation. Our experimental evaluation on data coming from a popular online video-sharing platform demonstrates that our approach ensures an effective and controllable reduction of unwanted recommendations with minimal effort. The source code is available here: https://github.com/geektoni/mitigating-harm-recsys.",
      "tldr_zh": "该研究针对个性化推荐系统中普遍存在的不相关、不合规甚至有害内容的推荐问题，旨在缓解由此导致的用户满意度下降和社会信任危机。论文提出了一种名为 Conformal Risk Control 的方法，这是一种模型无关 (model-agnostic) 且分布无关 (distribution-free) 的框架，通过利用用户对项目的简单二元反馈，为个性化推荐中出现的不良内容提供可证明的风险边界。为了克服传统 Conformal Risk Control 可能导致推荐列表缩减的局限性，研究进一步结合了对已消费项目的隐式反馈 (implicit feedback)，在确保风险得到稳健缓解的同时扩展了推荐集合。在热门在线视频分享平台数据上的实验评估证明，该方法能够以极小的计算代价，有效且可控地减少不良推荐内容的比例。这一研究为构建更安全、更符合用户偏好的推荐系统提供了一种具有理论保障且易于实施的解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at the 19th ACM Conference on Recommender Systems (RecSys 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.16829v1",
      "published_date": "2025-07-09 21:27:35 UTC",
      "updated_date": "2025-07-09 21:27:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:23.661427+00:00"
    },
    {
      "arxiv_id": "2507.07274v1",
      "title": "LinguaMark: Do Multimodal Models Speak Fairly? A Benchmark-Based Evaluation",
      "title_zh": "LinguaMark：多模态模型的表达是否公平？一项基于基准的评估",
      "authors": [
        "Ananya Raval",
        "Aravind Narayanan",
        "Vahid Reza Khazaie",
        "Shaina Raza"
      ],
      "abstract": "Large Multimodal Models (LMMs) are typically trained on vast corpora of image-text data but are often limited in linguistic coverage, leading to biased and unfair outputs across languages. While prior work has explored multimodal evaluation, less emphasis has been placed on assessing multilingual capabilities. In this work, we introduce LinguaMark, a benchmark designed to evaluate state-of-the-art LMMs on a multilingual Visual Question Answering (VQA) task. Our dataset comprises 6,875 image-text pairs spanning 11 languages and five social attributes. We evaluate models using three key metrics: Bias, Answer Relevancy, and Faithfulness. Our findings reveal that closed-source models generally achieve the highest overall performance. Both closed-source (GPT-4o and Gemini2.5) and open-source models (Gemma3, Qwen2.5) perform competitively across social attributes, and Qwen2.5 demonstrates strong generalization across multiple languages. We release our benchmark and evaluation code to encourage reproducibility and further research.",
      "tldr_zh": "该研究针对大型多模态模型 (LMMs) 在跨语言输出中存在的偏见与不公平问题，提出了 LinguaMark 基准测试，用于评估模型在多语言视觉问答 (VQA) 任务中的性能。该基准包含涵盖 11 种语言和 5 个社会属性的 6,875 个图像-文本对，并采用偏差 (Bias)、答案相关性 (Answer Relevancy) 和忠实度 (Faithfulness) 三项关键指标进行衡量。研究结果显示，GPT-4o 和 Gemini2.5 等闭源模型在整体性能上表现最佳，而开源模型 Gemma3 和 Qwen2.5 在社会属性维度上也具有竞争力。其中，Qwen2.5 在多种语言中展现了强大的泛化能力。该团队通过公开发布 LinguaMark 基准及其评估代码，为解决多模态模型在不同语言间的偏见问题提供了重要支持，推动了更公平、更具代表性的 AI 技术发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ASONAM'25",
      "pdf_url": "https://arxiv.org/pdf/2507.07274v1",
      "published_date": "2025-07-09 20:45:04 UTC",
      "updated_date": "2025-07-09 20:45:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:32.482806+00:00"
    },
    {
      "arxiv_id": "2507.07259v1",
      "title": "Exploiting Edge Features for Transferable Adversarial Attacks in Distributed Machine Learning",
      "title_zh": "利用边缘特征实现分布式机器学习中的可迁移对抗攻击",
      "authors": [
        "Giulio Rossolini",
        "Fabio Brau",
        "Alessandro Biondi",
        "Battista Biggio",
        "Giorgio Buttazzo"
      ],
      "abstract": "As machine learning models become increasingly deployed across the edge of internet of things environments, a partitioned deep learning paradigm in which models are split across multiple computational nodes introduces a new dimension of security risk. Unlike traditional inference setups, these distributed pipelines span the model computation across heterogeneous nodes and communication layers, thereby exposing a broader attack surface to potential adversaries. Building on these motivations, this work explores a previously overlooked vulnerability: even when both the edge and cloud components of the model are inaccessible (i.e., black-box), an adversary who intercepts the intermediate features transmitted between them can still pose a serious threat. We demonstrate that, under these mild and realistic assumptions, an attacker can craft highly transferable proxy models, making the entire deep learning system significantly more vulnerable to evasion attacks. In particular, the intercepted features can be effectively analyzed and leveraged to distill surrogate models capable of crafting highly transferable adversarial examples against the target model. To this end, we propose an exploitation strategy specifically designed for distributed settings, which involves reconstructing the original tensor shape from vectorized transmitted features using simple statistical analysis, and adapting surrogate architectures accordingly to enable effective feature distillation. A comprehensive and systematic experimental evaluation has been conducted to demonstrate that surrogate models trained with the proposed strategy, i.e., leveraging intermediate features, tremendously improve the transferability of adversarial attacks. These findings underscore the urgent need to account for intermediate feature leakage in the design of secure distributed deep learning systems.",
      "tldr_zh": "该研究探讨了在分布式机器学习（Distributed Machine Learning）环境下，模型在边缘与云端节点间分割部署所带来的安全风险。作者发现即使在边缘和云端模型组件均为黑盒（black-box）的现实条件下，攻击者仍能通过拦截节点间传输的中间特征（intermediate features）来构建严重威胁。研究提出了一种针对分布式设置的利用策略，通过统计分析从向量化特征中重建原始张量形状（tensor shape），并据此调整代理模型（surrogate models）架构以实现有效的特征蒸馏（feature distillation）。实验结果证明，利用这些中间特征训练出的代理模型能够生成极具迁移性的对抗样本，显著提升了针对目标模型的迁移对抗攻击（transferable adversarial attacks）成功率。这一发现揭示了分布式深度学习系统在面对逃逸攻击（evasion attacks）时的脆弱性，并强调了在设计安全系统时防范中间特征泄露（intermediate feature leakage）的紧迫性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "under review",
      "pdf_url": "https://arxiv.org/pdf/2507.07259v1",
      "published_date": "2025-07-09 20:09:00 UTC",
      "updated_date": "2025-07-09 20:09:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:46.078932+00:00"
    },
    {
      "arxiv_id": "2507.07258v1",
      "title": "FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning",
      "title_zh": "FedP3E：面向跨机构联邦学习中非独立同分布物联网恶意软件检测的隐私保护原型交换",
      "authors": [
        "Rami Darwish",
        "Mahmoud Abdelsalam",
        "Sajad Khorsandroo",
        "Kaushik Roy"
      ],
      "abstract": "As IoT ecosystems continue to expand across critical sectors, they have become prominent targets for increasingly sophisticated and large-scale malware attacks. The evolving threat landscape, combined with the sensitive nature of IoT-generated data, demands detection frameworks that are both privacy-preserving and resilient to data heterogeneity. Federated Learning (FL) offers a promising solution by enabling decentralized model training without exposing raw data. However, standard FL algorithms such as FedAvg and FedProx often fall short in real-world deployments characterized by class imbalance and non-IID data distributions -- particularly in the presence of rare or disjoint malware classes. To address these challenges, we propose FedP3E (Privacy-Preserving Prototype Exchange), a novel FL framework that supports indirect cross-client representation sharing while maintaining data privacy. Each client constructs class-wise prototypes using Gaussian Mixture Models (GMMs), perturbs them with Gaussian noise, and transmits only these compact summaries to the server. The aggregated prototypes are then distributed back to clients and integrated into local training, supported by SMOTE-based augmentation to enhance representation of minority malware classes. Rather than relying solely on parameter averaging, our prototype-driven mechanism enables clients to enrich their local models with complementary structural patterns observed across the federation -- without exchanging raw data or gradients. This targeted strategy reduces the adverse impact of statistical heterogeneity with minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset under realistic cross-silo scenarios with varying degrees of data imbalance.",
      "tldr_zh": "该研究针对跨孤岛联邦学习(Cross-Silo Federated Learning)中物联网(IoT)恶意软件检测面临的非独立同分布(Non-IID)数据分布和类别不平衡挑战，提出了名为FedP3E的隐私保护原型交换框架。该框架允许客户端利用高斯混合模型(GMMs)构建类原型，并添加高斯噪声(Gaussian noise)进行扰动，在不交换原始数据或梯度的情况下实现了间接的跨客户端特征共享。FedP3E结合了基于SMOTE的增强技术以提升少数类恶意软件的表示能力，通过原型驱动机制使本地模型能够吸收联邦网络中互补的结构模式。在N-BaIoT数据集上的实验结果表明，该方案能有效减轻统计异构性带来的负面影响，并在保持低通信开销的同时显著提升检测性能。该研究为隐私受限环境下的鲁棒性IoT安全监测任务提供了新的技术路径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07258v1",
      "published_date": "2025-07-09 20:07:35 UTC",
      "updated_date": "2025-07-09 20:07:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:49.544791+00:00"
    },
    {
      "arxiv_id": "2507.07257v2",
      "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery",
      "title_zh": "面向自主科学发现的语言智能体开源规划与控制系统",
      "authors": [
        "Licong Xu",
        "Milind Sarkar",
        "Anto I. Lonappan",
        "Íñigo Zubeldia",
        "Pablo Villanueva-Domingo",
        "Santiago Casas",
        "Christian Fidler",
        "Chetana Amancharla",
        "Ujjwal Tiwari",
        "Adrian Bayer",
        "Chadi Ait Ekioui",
        "Miles Cranmer",
        "Adrian Dimitrov",
        "James Fergusson",
        "Kahaan Gandhi",
        "Sven Krippendorf",
        "Andrew Laverick",
        "Julien Lesgourgues",
        "Antony Lewis",
        "Thomas Meier",
        "Blake Sherwin",
        "Kristen Surrao",
        "Francisco Villaescusa-Navarro",
        "Chi Wang",
        "Xueqing Xu",
        "Boris Bolliet"
      ],
      "abstract": "We present a multi-agent system for automation of scientific research tasks, cmbagent (https://github.com/CMBAgents/cmbagent). The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning & Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud.",
      "tldr_zh": "该研究提出了cmbagent，一个旨在实现科学研究任务自动化的开源多智能体系统。该系统由约30个大语言模型（LLM）智能体组成，采用规划与控制（Planning & Control）策略来编排智能体工作流，在执行过程中完全无需人工干预（human-in-the-loop）。系统中的每个智能体专注于特定领域，如文献检索、代码编写、结果解释及输出评判，并支持在本地环境中执行代码。研究团队成功将cmbagent应用于一项博士级别的宇宙学任务，即利用超新星数据测量宇宙学参数。实验结果显示，该系统在多个基准测试上的表现均优于现有的最先进（SOTA）大语言模型。目前该系统已在GitHub开源并提供云端部署，为自主科学发现（Autonomous Scientific Discovery）提供了强有力的技术支撑。",
      "categories": [
        "cs.AI",
        "astro-ph.IM",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted contribution to the ICML 2025 Workshop on Machine Learning for Astrophysics. Code: https://github.com/CMBAgents/cmbagent Videos: https://www.youtube.com/@cmbagent HuggingFace: https://huggingface.co/spaces/astropilot-ai/cmbagent Cloud: https://cmbagent.cloud",
      "pdf_url": "https://arxiv.org/pdf/2507.07257v2",
      "published_date": "2025-07-09 20:03:30 UTC",
      "updated_date": "2025-07-11 14:43:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:52.584157+00:00"
    },
    {
      "arxiv_id": "2507.07247v1",
      "title": "Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention",
      "title_zh": "显微镜下的注意力机制：自注意力变体资源利用的对比研究",
      "authors": [
        "Zhengyu Tian",
        "Anantha Padmanaban Krishna Kumar",
        "Hemant Krishnakumar",
        "Reza Rawassizadeh"
      ],
      "abstract": "As large language models (LLMs) and visual language models (VLMs) grow in scale and application, attention mechanisms have become a central computational bottleneck due to their high memory and time complexity. While many efficient attention variants have been proposed, there remains a lack of rigorous evaluation on their actual energy usage and hardware resource demands during training. In this work, we benchmark eight attention mechanisms in training GPT-2 architecture, measuring key metrics including training time, GPU memory usage, FLOPS, CPU usage, and power consumption. Our results reveal that attention mechanisms with optimized kernel implementations, including Flash Attention, Locality-Sensitive Hashing (LSH) Attention, and Multi-Head Latent Attention (MLA), achieve the best energy efficiency. We further show that lower GPU power alone does not guarantee reduced energy use, as training time plays an equally important role. Our study highlights the importance of energy-aware benchmarking in attention design and provides a practical insight for selecting resource-efficient mechanisms. All our codes are available at GitHub.",
      "tldr_zh": "该研究对多种 Self-Attention 变体的资源利用率进行了深入的比较研究，旨在应对大模型中注意力机制导致的内存和时间复杂度瓶颈。研究人员在 GPT-2 架构中对八种注意力机制进行了基准测试，详细测量了训练时间、GPU Memory 占用、FLOPS、CPU 利用率以及 Power Consumption 等关键硬件指标。实验结果显示，通过优化内核实现的 Flash Attention、Locality-Sensitive Hashing (LSH) Attention 和 Multi-Head Latent Attention (MLA) 达到了最佳的 Energy Efficiency。研究进一步发现，较低的 GPU 瞬时功耗并不直接保证总能效的提升，训练时间的长短对整体能源消耗具有同等重要的影响。该工作填补了注意力机制在实际训练中能源消耗评估的空白，为开发者选择资源高效的机制提供了重要的实践见解和 Energy-aware Benchmarking 指南。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07247v1",
      "published_date": "2025-07-09 19:37:23 UTC",
      "updated_date": "2025-07-09 19:37:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:56.678442+00:00"
    },
    {
      "arxiv_id": "2507.07236v2",
      "title": "Simple Yet Effective: An Information-Theoretic Approach to Multi-LLM Uncertainty Quantification",
      "title_zh": "简约而有效：基于信息论的多LLM不确定性量化方法",
      "authors": [
        "Maya Kruse",
        "Majid Afshar",
        "Saksham Khatwani",
        "Anoop Mayampurath",
        "Guanhua Chen",
        "Yanjun Gao"
      ],
      "abstract": "Large language models (LLMs) often behave inconsistently across inputs, indicating uncertainty and motivating the need for its quantification in high-stakes settings. Prior work on calibration and uncertainty quantification often focuses on individual models, overlooking the potential of model diversity. We hypothesize that LLMs make complementary predictions due to differences in training and the Zipfian nature of language, and that aggregating their outputs leads to more reliable uncertainty estimates. To leverage this, we propose MUSE (Multi-LLM Uncertainty via Subset Ensembles), a simple information-theoretic method that uses Jensen-Shannon Divergence to identify and aggregate well-calibrated subsets of LLMs. Experiments on binary prediction tasks demonstrate improved calibration and predictive performance compared to single-model and naïve ensemble baselines. In addition, we explore using MUSE as guided signals with chain-of-thought distillation to fine-tune LLMs for calibration. MUSE is available at:https://github.com/LARK-NLP-Lab/MUSE.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在高风险场景下预测不一致的不确定性量化问题，提出了一种利用模型多样性的新颖视角。研究者假设不同模型因训练差异和语言的 Zipfian 性质而具有互补性，据此开发了名为 MUSE (Multi-LLM Uncertainty via Subset Ensembles) 的信息论方法。该方法通过 Jensen-Shannon Divergence 识别并聚合校准良好的模型子集，旨在提供更可靠的不确定性估计。实验结果显示，MUSE 在二元预测任务中的校准精度和预测性能均优于单一模型及朴素集成(naïve ensemble)基准。此外，该研究还展示了将 MUSE 作为引导信号，结合链式思维蒸馏(chain-of-thought distillation)来微调模型校准能力的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to EMNLP 2025 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2507.07236v2",
      "published_date": "2025-07-09 19:13:25 UTC",
      "updated_date": "2025-09-05 17:54:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:35:57.224366+00:00"
    },
    {
      "arxiv_id": "2507.07217v1",
      "title": "Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains",
      "title_zh": "用于识别供应链中强迫劳动的神经符号特征提取",
      "authors": [
        "Zili Wang",
        "Frank Montabon",
        "Kristin Yvonne Rozier"
      ],
      "abstract": "Supply chain networks are complex systems that are challenging to analyze; this problem is exacerbated when there are illicit activities involved in the supply chain, such as counterfeit parts, forced labor, or human trafficking. While machine learning (ML) can find patterns in complex systems like supply chains, traditional ML techniques require large training data sets. However, illicit supply chains are characterized by very sparse data, and the data that is available is often (purposely) corrupted or unreliable in order to hide the nature of the activities. We need to be able to automatically detect new patterns that correlate with such illegal activity over complex, even temporal data, without requiring large training data sets. We explore neurosymbolic methods for identifying instances of illicit activity in supply chains and compare the effectiveness of manual and automated feature extraction from news articles accurately describing illicit activities uncovered by authorities. We propose a question tree approach for querying a large language model (LLM) to identify and quantify the relevance of articles. This enables a systematic evaluation of the differences between human and machine classification of news articles related to forced labor in supply chains.",
      "tldr_zh": "该研究针对供应链中强迫劳动(forced labor)等非法活动难以监测的问题，提出了一种神经符号(neurosymbolic)特征提取方法。由于非法供应链数据稀疏且常被刻意伪造，传统机器学习(ML)在缺乏大规模训练集的情况下难以奏效。为此，研究提出了一种基于大语言模型(LLM)的问题树(question tree)方法，旨在通过查询模型来识别并量化新闻文章的相关性。该研究系统地评估了人工与机器在分类强迫劳动相关新闻报道时的差异，并探索了在复杂时序数据中自动检测非法活动模式的有效性。这种神经符号方法为识别隐蔽的非法供应链活动提供了一种无需海量标注数据的新途径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07217v1",
      "published_date": "2025-07-09 18:44:48 UTC",
      "updated_date": "2025-07-09 18:44:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:03.680644+00:00"
    },
    {
      "arxiv_id": "2507.07216v2",
      "title": "Bias-Aware Mislabeling Detection via Decoupled Confident Learning",
      "title_zh": "基于解耦置信学习的偏见感知误标注检测",
      "authors": [
        "Yunyi Li",
        "Maria De-Arteaga",
        "Maytal Saar-Tsechansky"
      ],
      "abstract": "Reliable data is a cornerstone of modern organizational systems. A notable data integrity challenge stems from label bias, which refers to systematic errors in a label, a covariate that is central to a quantitative analysis, such that its quality differs across social groups. This type of bias has been conceptually and empirically explored and is widely recognized as a pressing issue across critical domains. However, effective methodologies for addressing it remain scarce. In this work, we propose Decoupled Confident Learning (DeCoLe), a principled machine learning based framework specifically designed to detect mislabeled instances in datasets affected by label bias, enabling bias aware mislabelling detection and facilitating data quality improvement. We theoretically justify the effectiveness of DeCoLe and evaluate its performance in the impactful context of hate speech detection, a domain where label bias is a well documented challenge. Empirical results demonstrate that DeCoLe excels at bias aware mislabeling detection, consistently outperforming alternative approaches for label error detection. Our work identifies and addresses the challenge of bias aware mislabeling detection and offers guidance on how DeCoLe can be integrated into organizational data management practices as a powerful tool to enhance data reliability.",
      "tldr_zh": "本研究针对现代组织系统中普遍存在的标签偏差 (label bias) 问题，即不同社会群体间标签质量存在系统性差异的挑战，指出当前缺乏有效应对手段。为此，作者提出了 Decoupled Confident Learning (DeCoLe) 框架，这是一种专门设计的基于机器学习的原则性框架，用于在受偏差影响的数据集中检测错误标注 (mislabeling) 实例。该研究从理论上证明了 DeCoLe 的有效性，并在仇恨言论检测 (hate speech detection) 这一具有代表性且标签偏差问题严重的领域对其进行了评估。实验结果表明，DeCoLe 在具备偏差意识的错误标注检测任务中表现卓越，且始终优于其他传统的标签错误检测方法。该工作有效解决了偏差感知下的错误标注检测难题，并为将 DeCoLe 集成到组织数据管理实践中以提升数据可靠性提供了有力指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07216v2",
      "published_date": "2025-07-09 18:44:36 UTC",
      "updated_date": "2025-07-11 16:34:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:01.647430+00:00"
    },
    {
      "arxiv_id": "2507.08039v1",
      "title": "Towards Evaluating Robustness of Prompt Adherence in Text to Image Models",
      "title_zh": "面向文生图模型提示遵循鲁棒性的评估研究",
      "authors": [
        "Sujith Vemishetty",
        "Advitiya Arora",
        "Anupama Sharma"
      ],
      "abstract": "The advancements in the domain of LLMs in recent years have surprised many, showcasing their remarkable capabilities and diverse applications. Their potential applications in various real-world scenarios have led to significant research on their reliability and effectiveness. On the other hand, multimodal LLMs and Text-to-Image models have only recently gained prominence, especially when compared to text-only LLMs. Their reliability remains constrained due to insufficient research on assessing their performance and robustness. This paper aims to establish a comprehensive evaluation framework for Text-to-Image models, concentrating particularly on their adherence to prompts. We created a novel dataset that aimed to assess the robustness of these models in generating images that conform to the specified factors of variation in the input text prompts. Our evaluation studies present findings on three variants of Stable Diffusion models: Stable Diffusion 3 Medium, Stable Diffusion 3.5 Large, and Stable Diffusion 3.5 Large Turbo, and two variants of Janus models: Janus Pro 1B and Janus Pro 7B. We introduce a pipeline that leverages text descriptions generated by the gpt-4o model for our ground-truth images, which are then used to generate artificial images by passing these descriptions to the Text-to-Image models. We then pass these generated images again through gpt-4o using the same system prompt and compare the variation between the two descriptions. Our results reveal that these models struggle to create simple binary images with only two factors of variation: a simple geometric shape and its location. We also show, using pre-trained VAEs on our dataset, that they fail to generate images that follow our input dataset distribution.",
      "tldr_zh": "该研究旨在建立一个全面的评估框架，以评估 Text-to-Image 模型在遵循 Prompt 方面的鲁棒性。作者通过创建一个全新的数据集，专门衡量模型在生成图像时对输入文本中特定变化因子的遵循能力。评估实验涵盖了 Stable Diffusion 3/3.5 系列以及 Janus Pro 系列模型，并引入了一种利用 gpt-4o 生成描述并对比生成结果差异的评估流水线。研究发现，这些模型在处理仅包含几何形状和位置这两个简单变化因子的二元图像时依然面临困难。此外，通过在数据集上预训练的 VAEs 分析证明，模型生成的图像难以遵循输入数据集的分布规律。该项工作揭示了当前主流文本生成图像模型在提示词遵循和生成可靠性方面仍存在显著局限。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08039v1",
      "published_date": "2025-07-09 18:40:17 UTC",
      "updated_date": "2025-07-09 18:40:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:06.807208+00:00"
    },
    {
      "arxiv_id": "2507.07203v1",
      "title": "State-Inference-Based Prompting for Natural Language Trading with Game NPCs",
      "title_zh": "基于状态推断的提示技术：面向游戏 NPC 的自然语言交易",
      "authors": [
        "Minkyung Kim",
        "Junsik Kim",
        "Hwidong Bae",
        "Woongcheol Yang",
        "Sangdon Park",
        "Sohee Bae"
      ],
      "abstract": "Large Language Models enable dynamic game interactions but struggle with rule-governed trading systems. Current implementations suffer from rule violations, such as item hallucinations and calculation errors, that erode player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable trading through autonomous dialogue state inference and context-specific rule adherence. The approach decomposes trading into six states within a unified prompt framework, implementing context-aware item referencing and placeholder-based price calculations. Evaluation across 100 trading dialogues demonstrates >97% state compliance, >95% referencing accuracy, and 99.7% calculation precision. SIBP maintains computational efficiency while outperforming baseline approaches, establishing a practical foundation for trustworthy NPC interactions in commercial games.",
      "tldr_zh": "该研究针对大语言模型 (Large Language Models) 在与游戏 NPC 进行自然语言交易时面临的规则违反、道具幻觉及计算错误等挑战，提出了 State-Inference-Based Prompting (SIBP) 框架。该框架通过自动对话状态推理 (autonomous dialogue state inference) 和特定上下文的规则遵循 (context-specific rule adherence)，在统一的提示框架内将交易过程分解为六个状态。SIBP 实施了上下文感知的道具引用 (context-aware item referencing) 和基于占位符的价格计算 (placeholder-based price calculations)，显著提升了交易的可靠性。在 100 场交易对话的评估中，该方法实现了超过 97% 的状态合规性 (state compliance)、95% 的引用准确度以及 99.7% 的计算精度。实验证明 SIBP 在保持计算效率的同时表现优于基准方法，为商业游戏中构建可信的 NPC 交互奠定了实用的技术基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages main content, 4 pages appendix, 3 figures. Accepted to the KDD 2025 Workshop on Prompt Optimization",
      "pdf_url": "https://arxiv.org/pdf/2507.07203v1",
      "published_date": "2025-07-09 18:24:47 UTC",
      "updated_date": "2025-07-09 18:24:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:14.918432+00:00"
    },
    {
      "arxiv_id": "2507.07201v1",
      "title": "MODA: A Unified 3D Diffusion Framework for Multi-Task Target-Aware Molecular Generation",
      "title_zh": "MODA：面向多任务目标感知分子生成的统一三维扩散框架",
      "authors": [
        "Dong Xu",
        "Zhangfan Yang",
        "Sisi Yuan",
        "Jenna Xinyi Yao",
        "Jiangqiang Li",
        "Junkai Ji"
      ],
      "abstract": "Three-dimensional molecular generators based on diffusion models can now reach near-crystallographic accuracy, yet they remain fragmented across tasks. SMILES-only inputs, two-stage pretrain-finetune pipelines, and one-task-one-model practices hinder stereochemical fidelity, task alignment, and zero-shot transfer. We introduce MODA, a diffusion framework that unifies fragment growing, linker design, scaffold hopping, and side-chain decoration with a Bayesian mask scheduler. During training, a contiguous spatial fragment is masked and then denoised in one pass, enabling the model to learn shared geometric and chemical priors across tasks. Multi-task training yields a universal backbone that surpasses six diffusion baselines and three training paradigms on substructure, chemical property, interaction, and geometry. Model-C reduces ligand-protein clashes and substructure divergences while maintaining Lipinski compliance, whereas Model-B preserves similarity but trails in novelty and binding affinity. Zero-shot de novo design and lead-optimisation tests confirm stable negative Vina scores and high improvement rates without force-field refinement. These results demonstrate that a single-stage multi-task diffusion routine can replace two-stage workflows for structure-based molecular design.",
      "tldr_zh": "该研究提出了 MODA，这是一个统一的 3D Diffusion 框架，旨在解决现有三维分子生成模型在 fragment growing、linker design 等任务上彼此孤立且依赖二阶段预训练流程的问题。通过引入 Bayesian mask scheduler，MODA 在单次去噪过程中学习空间掩码片段的生成，从而在单一模型中实现了多种分子优化任务的统一。多任务训练使该模型在子结构、化学性质及几何构型等多个维度上超越了六种 Diffusion 基线模型，并展现出优异的跨任务迁移能力。实验表明，Model-C 能有效减少 ligand-protein clashes 并保持 Lipinski 合规性，而 Zero-shot 测试证实了其在没有力场优化的条件下仍具有稳定的 Vina scores。该成果证明了单阶段多任务扩散方案可以取代传统的二阶段工作流，为 structure-based molecular design 提供了更高效的路径。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07201v1",
      "published_date": "2025-07-09 18:19:50 UTC",
      "updated_date": "2025-07-09 18:19:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:18.183955+00:00"
    },
    {
      "arxiv_id": "2507.07197v1",
      "title": "Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning",
      "title_zh": "结合预训练模型以增强强化学习中的特征表示",
      "authors": [
        "Elia Piccoli",
        "Malio Li",
        "Giacomo Carfì",
        "Vincenzo Lomonaco",
        "Davide Bacciu"
      ],
      "abstract": "The recent focus and release of pre-trained models have been a key components to several advancements in many fields (e.g. Natural Language Processing and Computer Vision), as a matter of fact, pre-trained models learn disparate latent embeddings sharing insightful representations. On the other hand, Reinforcement Learning (RL) focuses on maximizing the cumulative reward obtained via agent's interaction with the environment. RL agents do not have any prior knowledge about the world, and they either learn from scratch an end-to-end mapping between the observation and action spaces or, in more recent works, are paired with monolithic and computationally expensive Foundational Models. How to effectively combine and leverage the hidden information of different pre-trained models simultaneously in RL is still an open and understudied question. In this work, we propose Weight Sharing Attention (WSA), a new architecture to combine embeddings of multiple pre-trained models to shape an enriched state representation, balancing the tradeoff between efficiency and performance. We run an extensive comparison between several combination modes showing that WSA obtains comparable performance on multiple Atari games compared to end-to-end models. Furthermore, we study the generalization capabilities of this approach and analyze how scaling the number of models influences agents' performance during and after training.",
      "tldr_zh": "该研究探讨了如何在 Reinforcement Learning (RL) 中有效结合多个预训练模型以增强特征表示，针对 RL 智能体通常从零开始学习或过度依赖计算昂贵的 Foundational Models 这一现状。为此，作者提出了 Weight Sharing Attention (WSA) 架构，旨在同时融合多个预训练模型的隐层嵌入，从而构建更丰富的状态表示，并在效率与性能之间取得平衡。通过在多款 Atari 游戏中进行广泛实验，研究结果表明 WSA 在性能上与传统的 end-to-end 模型相当。此外，该研究还深入分析了该方法的泛化能力，并探讨了预训练模型数量的扩展对智能体在训练及评估阶段表现的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at 4th Conference on Lifelong Learning Agents (CoLLAs), 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07197v1",
      "published_date": "2025-07-09 18:13:52 UTC",
      "updated_date": "2025-07-09 18:13:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:29.129057+00:00"
    },
    {
      "arxiv_id": "2507.08871v1",
      "title": "Next-Generation Travel Demand Modeling with a Generative Framework for Household Activity Coordination",
      "title_zh": "基于家庭活动协同生成式框架的下一代交通需求建模",
      "authors": [
        "Xishun Liao",
        "Haoxuan Ma",
        "Yifan Liu",
        "Yuxiang Wei",
        "Brian Yueshuai He",
        "Chris Stanford",
        "Jiaqi Ma"
      ],
      "abstract": "Travel demand models are critical tools for planning, policy, and mobility system design. Traditional activity-based models (ABMs), although grounded in behavioral theories, often rely on simplified rules and assumptions, and are costly to develop and difficult to adapt across different regions. This paper presents a learning-based travel demand modeling framework that synthesizes household-coordinated daily activity patterns based on a household's socio-demographic profiles. The whole framework integrates population synthesis, coordinated activity generation, location assignment, and large-scale microscopic traffic simulation into a unified system. It is fully generative, data-driven, scalable, and transferable to other regions. A full-pipeline implementation is conducted in Los Angeles with a 10 million population. Comprehensive validation shows that the model closely replicates real-world mobility patterns and matches the performance of legacy ABMs with significantly reduced modeling cost and greater scalability. With respect to the SCAG ABM benchmark, the origin-destination matrix achieves a cosine similarity of 0.97, and the daily vehicle miles traveled (VMT) in the network yields a 0.006 Jensen-Shannon Divergence (JSD) and a 9.8% mean absolute percentage error (MAPE). When compared to real-world observations from Caltrans PeMS, the evaluation on corridor-level traffic speed and volume reaches a 0.001 JSD and a 6.11% MAPE.",
      "tldr_zh": "该研究提出了一种基于学习的旅游需求预测框架，旨在通过生成式方法合成家庭协同的日常活动模式，解决传统基于活动的模型(ABMs)在行为理论简化、开发成本高及跨区域迁移性差等方面的问题。该框架整合了人口合成(Population Synthesis)、协同活动生成、位置分配以及大规模微观交通仿真，形成了一个完全由数据驱动、可扩展且具备迁移能力的统一生成系统。研究人员在洛杉矶针对千万级人口进行了全流程实验验证，结果显示该模型能够高度还原现实世界的出行模式。与SCAG ABM基准模型相比，该模型的起点-终点矩阵(Origin-Destination Matrix)余弦相似度达到0.97，每日车辆行驶里程(VMT)的Jensen-Shannon散度(JSD)仅为0.006。此外，与Caltrans PeMS的实时观测数据对比表明，走廊级交通速度和流量的平均绝对百分比误差(MAPE)低至6.11%，证明了该模型在显著降低建模成本的同时，实现了卓越的模拟精度与扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.08871v1",
      "published_date": "2025-07-09 18:06:36 UTC",
      "updated_date": "2025-07-09 18:06:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:33.160165+00:00"
    },
    {
      "arxiv_id": "2507.07192v3",
      "title": "Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching",
      "title_zh": "跨越预测的“最后一公里”：利用条件引导流匹配增强时间序列预测",
      "authors": [
        "Huibo Xu",
        "Runlong Yu",
        "Likang Wu",
        "Xianquan Wang",
        "Qi Liu"
      ],
      "abstract": "Existing generative models for time series forecasting often transform simple priors (typically Gaussian) into complex data distributions. However, their sampling initialization, independent of historical data, hinders the capture of temporal dependencies, limiting predictive accuracy. They also treat residuals merely as optimization targets, ignoring that residuals often exhibit meaningful patterns like systematic biases or nontrivial distributional structures. To address these, we propose Conditional Guided Flow Matching (CGFM), a novel model-agnostic framework that extends flow matching by integrating outputs from an auxiliary predictive model. This enables learning from the probabilistic structure of prediction residuals, leveraging the auxiliary model's prediction distribution as a source to reduce learning difficulty and refine forecasts. CGFM incorporates historical data as both conditions and guidance, uses two-sided conditional paths (with source and target conditioned on the same history), and employs affine paths to expand the path space, avoiding path crossing without complex mechanisms, preserving temporal consistency, and strengthening distribution alignment. Experiments across datasets and baselines show CGFM consistently outperforms state-of-the-art models, advancing forecasting.",
      "tldr_zh": "该研究提出了 Conditional Guided Flow Matching (CGFM)，这是一个旨在增强时间序列预测的模型无关框架。它有效解决了现有生成模型因采样初始化独立于历史数据而难以捕捉时间依赖性的问题，并充分利用了常被忽视的预测残差 (prediction residuals) 中的系统性偏差模式。CGFM 通过集成辅助预测模型的输出，将其预测分布作为来源来学习残差的概率结构，从而显著降低学习难度并细化预测。该框架将历史数据同时作为条件和引导，采用双侧条件路径 (two-sided conditional paths) 确保源分布与目标分布均基于相同历史背景。此外，它利用仿射路径 (affine paths) 扩展路径空间，在避免路径交叉的同时保持了时间一致性并强化了分布对齐。实验结果证明，CGFM 在多个数据集和基线模型上均表现优异，持续超越了现有的先进 (state-of-the-art) 模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07192v3",
      "published_date": "2025-07-09 18:03:31 UTC",
      "updated_date": "2025-08-08 23:50:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:39.090898+00:00"
    },
    {
      "arxiv_id": "2507.07188v3",
      "title": "Prompt Perturbations Reveal Human-Like Biases in Large Language Model Survey Responses",
      "title_zh": "提示扰动揭示大语言模型调查响应中的类人偏见",
      "authors": [
        "Jens Rupprecht",
        "Georg Ahnert",
        "Markus Strohmaier"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used as proxies for human subjects in social science surveys, but their reliability and susceptibility to known human-like response biases, such as central tendency, opinion floating and primacy bias are poorly understood. This work investigates the response robustness of LLMs in normative survey contexts, we test nine LLMs on questions from the World Values Survey (WVS), applying a comprehensive set of ten perturbations to both question phrasing and answer option structure, resulting in over 167,000 simulated survey interviews. In doing so, we not only reveal LLMs' vulnerabilities to perturbations but also show that all tested models exhibit a consistent recency bias, disproportionately favoring the last-presented answer option. While larger models are generally more robust, all models remain sensitive to semantic variations like paraphrasing and to combined perturbations. This underscores the critical importance of prompt design and robustness testing when using LLMs to generate synthetic survey data.",
      "tldr_zh": "该研究探讨了大语言模型(Large Language Models, LLMs)在替代人类进行社会科学调查时的可靠性，及其对类人反应偏差(response biases)的敏感性。研究人员在世界价值观调查(World Values Survey, WVS)背景下测试了9个LLMs，针对问题表述和选项结构应用了10种扰动(perturbations)，总共模拟了超过16.7万次调查访谈。实验发现LLMs极易受到扰动影响，且所有测试模型都表现出一致的近因偏见(recency bias)，即不成比例地倾向于最后呈现的选项。尽管较大的模型通常表现出更强的鲁棒性(robustness)，但所有模型对转述(paraphrasing)和组合扰动依然十分敏感。该发现强调了在利用LLMs生成合成调查数据时，提示词设计(prompt design)和鲁棒性测试具有至关重要的意义。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07188v3",
      "published_date": "2025-07-09 18:01:50 UTC",
      "updated_date": "2025-10-16 11:31:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:39.238091+00:00"
    },
    {
      "arxiv_id": "2507.07186v2",
      "title": "Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs",
      "title_zh": "植根于预训练，随微调而变：大语言模型认知偏差起源的案例研究",
      "authors": [
        "Itay Itzhak",
        "Yonatan Belinkov",
        "Gabriel Stanovsky"
      ],
      "abstract": "Large language models (LLMs) exhibit cognitive biases -- systematic tendencies of irrational decision-making, similar to those seen in humans. Prior work has found that these biases vary across models and can be amplified by instruction tuning. However, it remains unclear if these differences in biases stem from pretraining, finetuning, or even random noise due to training stochasticity. We propose a two-step causal experimental approach to disentangle these factors. First, we finetune models multiple times using different random seeds to study how training randomness affects over $30$ cognitive biases. Second, we introduce \\emph{cross-tuning} -- swapping instruction datasets between models to isolate bias sources. This swap uses datasets that led to different bias patterns, directly testing whether biases are dataset-dependent. Our findings reveal that while training randomness introduces some variability, biases are mainly shaped by pretraining: models with the same pretrained backbone exhibit more similar bias patterns than those sharing only finetuning data. These insights suggest that understanding biases in finetuned models requires considering their pretraining origins beyond finetuning effects. This perspective can guide future efforts to develop principled strategies for evaluating and mitigating bias in LLMs.",
      "tldr_zh": "该研究探讨了大语言模型（LLMs）中认知偏差（cognitive biases）的起源，旨在厘清预训练（pretraining）、微调（finetuning）以及训练随机性对偏差形成的影响。研究者提出了一种两步因果实验方法，首先通过不同随机种子进行多次微调以评估随机性对30多种偏差的影响，随后引入了“交叉微调”（cross-tuning）技术，通过在模型间交换指令数据集来隔离偏差来源。研究发现，尽管训练过程中的随机性会引入一定变异，但认知偏差主要由预训练阶段塑造，具有相同预训练主干（backbone）的模型比仅共享微调数据的模型表现出更相似的偏差模式。这一见解表明，分析微调模型的偏差必须追溯其预训练起源，而不仅仅关注微调效果。该结论为未来开发评估和缓解LLMs偏差的原则性策略提供了重要的理论依据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "CoLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07186v2",
      "published_date": "2025-07-09 18:01:14 UTC",
      "updated_date": "2025-07-12 10:00:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:47.730418+00:00"
    },
    {
      "arxiv_id": "2507.07073v1",
      "title": "An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator",
      "title_zh": "一种用于学习 Laplace-Beltrami 算子谱的人工智能方法",
      "authors": [
        "Yulin An",
        "Enrique del Castillo"
      ],
      "abstract": "The spectrum of the Laplace-Beltrami (LB) operator is central in geometric deep learning tasks, capturing intrinsic properties of the shape of the object under consideration. The best established method for its estimation, from a triangulated mesh of the object, is based on the Finite Element Method (FEM), and computes the top k LB eigenvalues with a complexity of O(Nk), where N is the number of points. This can render the FEM method inefficient when repeatedly applied to databases of CAD mechanical parts, or in quality control applications where part metrology is acquired as large meshes and decisions about the quality of each part are needed quickly and frequently. As a solution to this problem, we present a geometric deep learning framework to predict the LB spectrum efficiently given the CAD mesh of a part, achieving significant computational savings without sacrificing accuracy, demonstrating that the LB spectrum is learnable. The proposed Graph Neural Network architecture uses a rich set of part mesh features - including Gaussian curvature, mean curvature, and principal curvatures. In addition to our trained network, we make available, for repeatability, a large curated dataset of real-world mechanical CAD models derived from the publicly available ABC dataset used for training and testing. Experimental results show that our method reduces computation time of the LB spectrum by approximately 5 times over linear FEM while delivering competitive accuracy.",
      "tldr_zh": "这项研究针对 Laplace-Beltrami (LB) 算子的能谱计算在几何深度学习任务中的核心作用，探讨了传统有限元方法 (Finite Element Method, FEM) 在处理大规模 CAD 模型和实时质量控制应用中效率较低的问题。为了解决这一挑战，作者提出了一种几何深度学习框架，旨在从零件的 CAD 网格中高效预测 LB 谱，并证明了该谱具有可学习性。该框架采用了 Graph Neural Network (GNN) 架构，并利用了包括高斯曲率 (Gaussian curvature)、平均曲率 (mean curvature) 和主曲率 (principal curvatures) 在内的丰富网格特征。此外，研究团队还基于 ABC 数据集整理并发布了一个大规模机械 CAD 模型数据集，以确保实验的可重复性。实验结果表明，该方法在保持竞争性准确率的同时，计算速度比线性 FEM 提高了约 5 倍，显著提升了大规模几何数据处理的效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 9 figures, submitted for publication",
      "pdf_url": "https://arxiv.org/pdf/2507.07073v1",
      "published_date": "2025-07-09 17:31:18 UTC",
      "updated_date": "2025-07-09 17:31:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:47.203527+00:00"
    },
    {
      "arxiv_id": "2507.07046v2",
      "title": "A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering",
      "title_zh": "一种基于特征工程的新型混合深度学习语音情感检测技术",
      "authors": [
        "Shahana Yasmin Chowdhury",
        "Bithi Banik",
        "Md Tamjidul Hoque",
        "Shreya Banerjee"
      ],
      "abstract": "Nowadays, speech emotion recognition (SER) plays a vital role in the field of human-computer interaction (HCI) and the evolution of artificial intelligence (AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions: neutral, happy, sad, angry, fear, disgust, and surprise, which are trained on five datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C). The model achieves high accuracy on individual datasets, including 97.83% on RAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS and EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy, outperforming previously reported results. To our knowledge, no existing study has evaluated a single SER model across all five benchmark datasets (i.e., R+T+S+C+E) simultaneously. In our work, we introduce this comprehensive combination and achieve a remarkable overall accuracy of 93.76%. These results confirm the robustness and generalizability of our DCRF-BiLSTM framework across diverse datasets.",
      "tldr_zh": "该研究提出了一种名为 DCRF-BiLSTM 的混合深度学习模型，利用特征工程 (Feature Engineering) 提升语音情感识别 (Speech Emotion Recognition, SER) 的效能。该模型能够准确识别中性、快乐、悲伤、愤怒、恐惧、厌恶和惊讶等七种核心情感。研究团队在 RAVDESS、TESS、SAVEE、EmoDB 和 Crema-D 等五个主流数据集上进行了训练与验证，在 TESS 和 EmoDB 数据集上实现了 100% 的分类准确率。在 (R+T+S) 的组合数据集测试中，该模型以 98.82% 的准确率超越了此前已报道的研究成果。该研究的一项重要贡献是首次在全部五个基准数据集的综合组合上评估了单一 SER 模型，并获得了 93.76% 的总体准确率。这些实验数据充分验证了 DCRF-BiLSTM 框架在多样化语音场景下具备极高的鲁棒性与泛化能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "17 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07046v2",
      "published_date": "2025-07-09 17:07:45 UTC",
      "updated_date": "2026-01-14 18:07:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:52.094786+00:00"
    },
    {
      "arxiv_id": "2507.13369v1",
      "title": "VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation",
      "title_zh": "VerilogDB：面向基于 LLM 的 RTL 生成的最大规模、最高质量数据集及预处理框架",
      "authors": [
        "Paul E. Calzada",
        "Zahin Ibnat",
        "Tanvir Rahman",
        "Kamal Kandula",
        "Danyu Lu",
        "Sujan Kumar Saha",
        "Farimah Farahmandi",
        "Mark Tehranipoor"
      ],
      "abstract": "Large Language Models (LLMs) are gaining popularity for hardware design automation, particularly through Register Transfer Level (RTL) code generation. In this work, we examine the current literature on RTL generation using LLMs and identify key requirements for training and fine-tuning datasets. We construct a robust Verilog dataset through an automated three-pronged process involving database (DB) creation and management with PostgreSQL, data collection from code hosting sites like OpenCores and GitHub, and data preprocessing to verify the codes' syntax, run logic synthesis, and extract relevant module metadata. We implement a scalable and efficient DB infrastructure to support analysis and detail our preprocessing pipeline to enforce high-quality data before DB insertion. The resulting dataset comprises 20,392 Verilog samples, 751 MB of Verilog code data, which is the largest high-quality Verilog dataset for LLM fine-tuning to our knowledge. We further evaluate the dataset, address associated challenges, and explore potential applications for future research and development in LLM-based hardware generation.",
      "tldr_zh": "该研究提出了 VerilogDB，这是一个专门针对 Large Language Models (LLMs) 进行 Register Transfer Level (RTL) 代码生成而设计的、目前已知规模最大且质量最高的 Verilog 数据集及其预处理框架。研究人员通过 PostgreSQL 构建了高效的数据库管理系统，从 OpenCores 和 GitHub 等开源平台采集代码，并利用自动化流水线进行语法验证、逻辑综合 (logic synthesis) 以及模块元数据 (metadata) 提取。该数据集包含 20,392 个 Verilog 样本，总计 751 MB 的高质量代码数据，显著超越了现有的同类资源。VerilogDB 的建立为硬件设计自动化领域的 LLM 微调 (fine-tuning) 提供了核心基础设施，有效解决了数据质量不一和规模受限的问题。通过对数据集的深入评估，该项工作为未来基于 LLM 的硬件生成研究和应用开发奠定了坚实的基础。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.13369v1",
      "published_date": "2025-07-09 17:06:54 UTC",
      "updated_date": "2025-07-09 17:06:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:51.781293+00:00"
    },
    {
      "arxiv_id": "2507.07034v1",
      "title": "Surrogate Model for Heat Transfer Prediction in Impinging Jet Arrays using Dynamic Inlet/Outlet and Flow Rate Control",
      "title_zh": "基于动态进出口与流量控制的冲击射流阵列传热预测代理模型",
      "authors": [
        "Mikael Vaillant",
        "Victor Oliveira Ferreira",
        "Wiebke Mainville",
        "Jean-Michel Lamarre",
        "Vincent Raymond",
        "Moncef Chioua",
        "Bruno Blais"
      ],
      "abstract": "This study presents a surrogate model designed to predict the Nusselt number distribution in an enclosed impinging jet arrays, where each jet function independently and where jets can be transformed from inlets to outlets, leading to a vast number of possible flow arrangements. While computational fluid dynamics (CFD) simulations can model heat transfer with high fidelity, their cost prohibits real-time application such as model-based temperature control. To address this, we generate a CNN-based surrogate model that can predict the Nusselt distribution in real time. We train it with data from implicit large eddy computational fluid dynamics simulations (Re < 2,000). We train two distinct models, one for a five by one array of jets (83 simulations) and one for a three by three array of jets (100 simulations). We introduce a method to extrapolate predictions to higher Reynolds numbers (Re < 10,000) using a correlation-based scaling. The surrogate models achieve high accuracy, with a normalized mean average error below 2% on validation data for the five by one surrogate model and 0.6% for the three by three surrogate model. Experimental validation confirms the model's predictive capabilities. This work provides a foundation for model-based control strategies in advanced thermal management applications.",
      "tldr_zh": "该研究提出了一个代理模型(surrogate model)，用于预测封闭式冲击射流阵列(impinging jet arrays)中的努塞尔数(Nusselt number)分布，主要针对各射流可独立切换进出口的复杂流动场景。为了解决计算流体动力学(CFD)模拟在实时温度控制中成本过高的问题，研究采用卷积神经网络(CNN)构建代理模型，并利用隐式大涡模拟(implicit large eddy computational fluid dynamics)生成的低雷诺数数据进行训练。研究通过关联缩放方法将预测能力成功外推至高雷诺数(Re < 10,000)范围，并在5x1和3x3阵列上分别实现了低于2%和0.6%的归一化平均绝对误差(normalized mean average error)。实验验证进一步确认了该模型的可靠性，证明其能实现高精度的实时预测。该成果为先进热管理系统中的基于模型的控制策略(model-based control strategies)提供了重要的理论支撑与技术基础。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "37 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.07034v1",
      "published_date": "2025-07-09 17:03:54 UTC",
      "updated_date": "2025-07-09 17:03:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:36:54.027479+00:00"
    },
    {
      "arxiv_id": "2507.07029v1",
      "title": "Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices",
      "title_zh": "基于 OCR 的发票表格提取流水线的设计与实现",
      "authors": [
        "Parshva Dhilankumar Patel"
      ],
      "abstract": "This paper presents the design and development of an OCR-powered pipeline for efficient table extraction from invoices. The system leverages Tesseract OCR for text recognition and custom post-processing logic to detect, align, and extract structured tabular data from scanned invoice documents. Our approach includes dynamic preprocessing, table boundary detection, and row-column mapping, optimized for noisy and non-standard invoice formats. The resulting pipeline significantly improves data extraction accuracy and consistency, supporting real-world use cases such as automated financial workflows and digital archiving.",
      "tldr_zh": "该研究设计并实现了一个基于 OCR 的流水线，专门用于从发票中高效提取表格数据。系统采用 Tesseract OCR 进行文字识别，并结合自定义的后处理逻辑，实现了扫描件中结构化表格数据的检测、对齐与提取。技术方案涵盖了动态预处理、表格边界检测以及行-列映射，并针对噪声干扰和非标准化发票格式进行了深度优化。实验证明，该流水线显著提升了数据提取的准确性与一致性。该系统有效支持了自动化财务工作流 (automated financial workflows) 和数字存档 (digital archiving) 等实际业务需求。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 23 figures, submitted to arXiv in July 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07029v1",
      "published_date": "2025-07-09 16:59:00 UTC",
      "updated_date": "2025-07-09 16:59:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:01.985722+00:00"
    },
    {
      "arxiv_id": "2507.07024v4",
      "title": "FlexOlmo: Open Language Models for Flexible Data Use",
      "title_zh": "FlexOlmo：面向灵活数据使用的开放语言模型",
      "authors": [
        "Weijia Shi",
        "Akshita Bhagia",
        "Kevin Farhat",
        "Niklas Muennighoff",
        "Pete Walsh",
        "Jacob Morrison",
        "Dustin Schwenk",
        "Shayne Longpre",
        "Jake Poznanski",
        "Allyson Ettinger",
        "Daogao Liu",
        "Margaret Li",
        "Dirk Groeneveld",
        "Mike Lewis",
        "Wen-tau Yih",
        "Luca Soldaini",
        "Kyle Lo",
        "Noah A. Smith",
        "Luke Zettlemoyer",
        "Pang Wei Koh",
        "Hannaneh Hajishirzi",
        "Ali Farhadi",
        "Sewon Min"
      ],
      "abstract": "We introduce FlexOlmo, a new class of language models (LMs) that supports (1) distributed training without data sharing, where different model parameters are independently trained on closed datasets, and (2) data-flexible inference, where these parameters along with their associated data can be flexibly included or excluded from model inferences with no further training. FlexOlmo employs a mixture-of-experts (MoE) architecture where each expert is trained independently on closed datasets and later integrated through a new domain-informed routing without any joint training. FlexOlmo is trained on FlexMix, a corpus we curate comprising publicly available datasets alongside seven domain-specific sets, representing realistic approximations of closed sets. We evaluate models with up to 37 billion parameters (20 billion active) on 31 diverse downstream tasks. We show that a general expert trained on public data can be effectively combined with independently trained experts from other data owners, leading to an average 41% relative improvement while allowing users to opt out of certain data based on data licensing or permission requirements. Our approach also outperforms prior model merging methods by 10.1% on average and surpasses the standard MoE trained without data restrictions using the same training FLOPs. Altogether, this research presents a solution for both data owners and researchers in regulated industries with sensitive or protected data. FlexOlmo enables benefiting from closed data while respecting data owners' preferences by keeping their data local and supporting fine-grained control of data access during inference.",
      "tldr_zh": "该研究提出了FlexOlmo，这是一种新型的语言模型(LMs)类别，支持在不共享数据的情况下进行分布式训练，并实现了数据灵活的推理。FlexOlmo采用了混合专家(Mixture-of-Experts, MoE)架构，每个专家在封闭数据集上独立训练，随后通过一种新型的领域知情路由(domain-informed routing)进行整合，无需任何联合训练。实验评估了参数规模达370亿的模型，结果显示将公共数据训练的通用专家与独立训练的领域专家结合，可带来平均41%的相对性能提升，并允许用户根据许可要求灵活选择排除特定数据。该方法在性能上比之前的模型合并(model merging)方法平均高出10.1%，且在相同训练FLOPs下优于标准的MoE模型。FlexOlmo通过保持数据的本地化并支持推理过程中细粒度的数据访问控制，为受监管行业处理敏感或受保护数据提供了一种兼顾性能与数据隐私的有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07024v4",
      "published_date": "2025-07-09 16:54:21 UTC",
      "updated_date": "2025-08-23 00:44:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:16.133396+00:00"
    },
    {
      "arxiv_id": "2507.07155v1",
      "title": "Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics",
      "title_zh": "面向天体物理学自主科学发现的检索增强生成智能体评估",
      "authors": [
        "Xueqing Xu",
        "Boris Bolliet",
        "Adrian Dimitrov",
        "Andrew Laverick",
        "Francisco Villaescusa-Navarro",
        "Licong Xu",
        "Íñigo Zubeldia"
      ],
      "abstract": "We evaluate 9 Retrieval Augmented Generation (RAG) agent configurations on 105 Cosmology Question-Answer (QA) pairs that we built specifically for this purpose.The RAG configurations are manually evaluated by a human expert, that is, a total of 945 generated answers were assessed. We find that currently the best RAG agent configuration is with OpenAI embedding and generative model, yielding 91.4\\% accuracy. Using our human evaluation results we calibrate LLM-as-a-Judge (LLMaaJ) system which can be used as a robust proxy for human evaluation. These results allow us to systematically select the best RAG agent configuration for multi-agent system for autonomous scientific discovery in astrophysics (e.g., cmbagent presented in a companion paper) and provide us with an LLMaaJ system that can be scaled to thousands of cosmology QA pairs. We make our QA dataset, human evaluation results, RAG pipelines, and LLMaaJ system publicly available for further use by the astrophysics community.",
      "tldr_zh": "该研究评估了9种检索增强生成 (Retrieval-Augmented Generation, RAG) 智能体配置，旨在推动天体物理学领域的自主科学发现。研究人员专门构建了包含105个宇宙学问答 (Cosmology QA) 对的数据集，并由人类专家对生成的945个答案进行了系统性评估。实验发现，目前表现最优的 RAG 配置结合了 OpenAI 的嵌入模型 (embedding) 与生成模型，其准确率达到了91.4%。利用人类评估结果，研究团队校准了 LLM-as-a-Judge (LLMaaJ) 系统，使其能够作为人类评估的稳健代理并支持大规模宇宙学问答扩展。该研究为 cmbagent 等多智能体系统在天体物理学中的应用提供了最优配置选择，并公开了所有数据集、评估结果及 RAG 流水线，为该领域的后续研究奠定了基础。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "Accepted contribution (spotlight) to the ICML 2025 Workshop on Machine Learning for Astrophysics; codes: https://huggingface.co/datasets/ASTROANTS/CosmoPaperQA, https://github.com/CMBAgents/cmbagent, https://github.com/CMBAgents/scirag",
      "pdf_url": "https://arxiv.org/pdf/2507.07155v1",
      "published_date": "2025-07-09 16:46:03 UTC",
      "updated_date": "2025-07-09 16:46:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:17.029700+00:00"
    },
    {
      "arxiv_id": "2507.07017v1",
      "title": "First Return, Entropy-Eliciting Explore",
      "title_zh": "FR3E：首次回报与熵激发式探索",
      "authors": [
        "Tianyu Zheng",
        "Tianshun Xing",
        "Qingshui Gu",
        "Taoran Liang",
        "Xingwei Qu",
        "Xin Zhou",
        "Yizhi Li",
        "Zhoufutu Wen",
        "Chenghua Lin",
        "Wenhao Huang",
        "Qian Liu",
        "Ge Zhang",
        "Zejun Ma"
      ],
      "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning abilities of Large Language Models (LLMs) but it struggles with unstable exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a structured exploration framework that identifies high-uncertainty decision points in reasoning trajectories and performs targeted rollouts to construct semantically grounded intermediate feedback. Our method provides targeted guidance without relying on dense supervision. Empirical results on mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable training, produces longer and more coherent responses, and increases the proportion of fully correct trajectories. These results highlight the framework's effectiveness in improving LLM reasoning through more robust and structured exploration.",
      "tldr_zh": "该研究提出了FR3E (First Return, Entropy-Eliciting Explore)，这是一种旨在优化大语言模型 (LLMs) 推理能力的结构化探索框架，解决了从可验证奖励中进行强化学习 (Reinforcement Learning from Verifiable Rewards, RLVR) 时存在的探索不稳定挑战。FR3E通过识别推理轨迹中的高不确定性决策点，并执行针对性的回滚 (targeted rollouts) 来构建具备语义基础的中间反馈，从而在不依赖密集监督的前提下提供有效引导。在数学推理基准测试 (AIME24) 的实验结果显示，FR3E显著增强了训练的稳定性，并使模型能够生成更长、更连贯的推导过程。此外，该方法显著提升了完全正确轨迹的比例，验证了其通过更稳健的结构化探索来提升大语言模型复杂推理任务性能的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07017v1",
      "published_date": "2025-07-09 16:45:48 UTC",
      "updated_date": "2025-07-09 16:45:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:21.140048+00:00"
    },
    {
      "arxiv_id": "2507.10571v3",
      "title": "Agentic AI with Orchestrator-Agent Trust: A Modular Visual Classification Framework with Trust-Aware Orchestration and RAG-Based Reasoning",
      "title_zh": "具备编排器-智能体信任机制的 Agentic AI：集成信任感知编排与 RAG 推理的模块化视觉分类框架",
      "authors": [
        "Konstantinos I. Roumeliotis",
        "Ranjan Sapkota",
        "Manoj Karkee",
        "Nikolaos D. Tselikas"
      ],
      "abstract": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent architectures that blend visual and language understanding. Yet, a pressing challenge remains: How can we trust these agents especially in zero-shot settings with no fine-tuning? We introduce a novel modular Agentic AI visual classification framework that integrates generalist multimodal agents with a non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG) module. Applied to apple leaf disease diagnosis, we benchmark three configurations: (I) zero-shot with confidence-based orchestration, (II) fine-tuned agents with improved performance, and (III) trust-calibrated orchestration enhanced by CLIP-based image retrieval and re-evaluation loops. Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator modulates trust across agents. Our results demonstrate a 77.94\\% accuracy improvement in the zero-shot setting using trust-aware orchestration and RAG, achieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL displayed overconfidence. Furthermore, image-RAG grounded predictions with visually similar cases, enabling correction of agent overconfidence via iterative re-evaluation. The proposed system separates perception (vision agents) from meta-reasoning (orchestrator), enabling scalable and interpretable multi-agent AI. This blueprint illustrates how Agentic AI can deliver trustworthy, modular, and transparent reasoning, and is extensible to diagnostics, biology, and other trust-critical domains. In doing so, we highlight Agentic AI not just as an architecture but as a paradigm for building reliable multi-agent intelligence. agentic ai, orchestrator agent trust, trust orchestration, visual classification, retrieval augmented reasoning",
      "tldr_zh": "该研究提出了一种模块化的 Agentic AI 视觉分类框架，旨在解决多智能体架构在零样本(zero-shot)设置下的信任与可靠性挑战。该框架创新性地集成了通用多模态智能体、非视觉推理编排器(orchestrator)以及检索增强生成(RAG)模块，并将其应用于苹果叶片病害诊断任务。研究人员通过 ECE、OCR 和 CCC 等置信度校准指标调节编排器对各智能体的信任度，并结合基于 CLIP 的图像检索实现迭代重评估循环。实验结果显示，在零样本设置下，采用信任感知编排和 RAG 技术使准确率提升了 77.94%，整体准确率达到 85.63%。研究发现 GPT-4o 具有更优的校准表现，而 Qwen-2.5-VL 表现出的过度自信可通过图像 RAG 引入的视觉相似案例进行修正。这项工作通过将感知与元推理分离，为构建可扩展、透明且可解释的信托关键型多智能体 AI 系统提供了重要范式。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10571v3",
      "published_date": "2025-07-09 16:39:29 UTC",
      "updated_date": "2025-09-21 06:44:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:40.091954+00:00"
    },
    {
      "arxiv_id": "2507.06996v1",
      "title": "Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing",
      "title_zh": "基于潜空间且仅需极简预处理的多表时间序列电子健康档案生成",
      "authors": [
        "Eunbyeol Cho",
        "Jiyoun Kim",
        "Minjae Lee",
        "Sungjin Park",
        "Edward Choi"
      ],
      "abstract": "Electronic Health Records (EHR) are time-series relational databases that record patient interactions and medical events over time, serving as a critical resource for healthcare research and applications. However, privacy concerns and regulatory restrictions limit the sharing and utilization of such sensitive data, necessitating the generation of synthetic EHR datasets. Unlike previous EHR synthesis methods, which typically generate medical records consisting of expert-chosen features (e.g. a few vital signs or structured codes only), we introduce RawMed, the first framework to synthesize multi-table, time-series EHR data that closely resembles raw EHRs. Using text-based representation and compression techniques, RawMed captures complex structures and temporal dynamics with minimal preprocessing. We also propose a new evaluation framework for multi-table time-series synthetic EHRs, assessing distributional similarity, inter-table relationships, temporal dynamics, and privacy. Validated on two open-source EHR datasets, RawMed outperforms baseline models in fidelity and utility. The code is available at https://github.com/eunbyeol-cho/RawMed.",
      "tldr_zh": "该研究提出了RawMed，这是第一个旨在合成多表时间序列Electronic Health Records (EHR)数据的框架，其生成的数据高度接近原始医疗记录。该框架采用文本表示(text-based representation)和压缩技术(compression techniques)，在仅需最少预处理(minimal preprocessing)的情况下捕捉复杂的结构和时间动态。研究者还同步提出了一个新的评估框架，用于从分布相似性、表间关系、时间动态和隐私性四个方面评估多表时间序列合成数据。在两个开源数据集上的验证结果显示，RawMed在保真度(fidelity)和实用性(utility)上均优于现有的基线模型。该工作通过从潜在空间(latent space)生成高质量合成数据，为受隐私限制的医疗数据研究提供了有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06996v1",
      "published_date": "2025-07-09 16:22:22 UTC",
      "updated_date": "2025-07-09 16:22:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:30.789218+00:00"
    },
    {
      "arxiv_id": "2507.06994v2",
      "title": "Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients",
      "title_zh": "面向接受 ICI 治疗的 NSCLC 患者生存预测的跨模态掩码学习",
      "authors": [
        "Qilong Xing",
        "Zikai Song",
        "Bingxin Gong",
        "Lian Yang",
        "Junqing Yu",
        "Wei Yang"
      ],
      "abstract": "Accurate prognosis of non-small cell lung cancer (NSCLC) patients undergoing immunotherapy is essential for personalized treatment planning, enabling informed patient decisions, and improving both treatment outcomes and quality of life. However, the lack of large, relevant datasets and effective multi-modal feature fusion strategies pose significant challenges in this domain. To address these challenges, we present a large-scale dataset and introduce a novel framework for multi-modal feature fusion aimed at enhancing the accuracy of survival prediction. The dataset comprises 3D CT images and corresponding clinical records from NSCLC patients treated with immune checkpoint inhibitors (ICI), along with progression-free survival (PFS) and overall survival (OS) data. We further propose a cross-modality masked learning approach for medical feature fusion, consisting of two distinct branches, each tailored to its respective modality: a Slice-Depth Transformer for extracting 3D features from CT images and a graph-based Transformer for learning node features and relationships among clinical variables in tabular data. The fusion process is guided by a masked modality learning strategy, wherein the model utilizes the intact modality to reconstruct missing components. This mechanism improves the integration of modality-specific features, fostering more effective inter-modality relationships and feature interactions. Our approach demonstrates superior performance in multi-modal integration for NSCLC survival prediction, surpassing existing methods and setting a new benchmark for prognostic models in this context.",
      "tldr_zh": "该研究针对接受免疫检查点抑制剂(ICI)治疗的非小细胞肺癌(NSCLC)患者，提出了一种旨在提升生存预测准确性的多模态特征融合框架。为了解决相关数据集匮乏及融合策略效率低下的挑战，研究团队首先构建了一个包含3D CT图像、临床记录以及无进展生存期(PFS)和总生存期(OS)数据的大规模数据集。核心方法采用了跨模态掩码学习(Cross-modality masked learning)策略，通过Slice-Depth Transformer提取图像特征，并利用图Transformer(Graph-based Transformer)学习临床变量间的关系。该框架通过掩码机制利用完整模态信息来重建缺失组件，从而有效增强了模态特异性特征的整合以及跨模态的交互效果。实验结果证明，该方法在NSCLC生存预测的多模态整合任务中表现优异，超越了现有技术并为该领域的预后模型建立了新的基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06994v2",
      "published_date": "2025-07-09 16:19:31 UTC",
      "updated_date": "2025-08-21 02:52:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:29.964399+00:00"
    },
    {
      "arxiv_id": "2507.06993v3",
      "title": "IMAIA: Interactive Maps AI Assistant for Travel Planning and Geo-Spatial Intelligence",
      "title_zh": "IMAIA：面向旅游规划与地理空间智能的交互式地图AI助手",
      "authors": [
        "Jieren Deng",
        "Zhizhang Hu",
        "Ziyan He",
        "Aleksandar Cvetkovic",
        "Pak Kiu Chung",
        "Dragomir Yankov",
        "Chiqun Zhang"
      ],
      "abstract": "Map applications are still largely point-and-click, making it difficult to ask map-centric questions or connect what a camera sees to the surrounding geospatial context with view-conditioned inputs. We introduce IMAIA, an interactive Maps AI Assistant that enables natural-language interaction with both vector (street) maps and satellite imagery, and augments camera inputs with geospatial intelligence to help users understand the world. IMAIA comprises two complementary components. Maps Plus treats the map as first-class context by parsing tiled vector/satellite views into a grid-aligned representation that a language model can query to resolve deictic references (e.g., ``the flower-shaped building next to the park in the top-right''). Places AI Smart Assistant (PAISA) performs camera-aware place understanding by fusing image--place embeddings with geospatial signals (location, heading, proximity) to ground a scene, surface salient attributes, and generate concise explanations. A lightweight multi-agent design keeps latency low and exposes interpretable intermediate decisions. Across map-centric QA and camera-to-place grounding tasks, IMAIA improves accuracy and responsiveness over strong baselines while remaining practical for user-facing deployments. By unifying language, maps, and geospatial cues, IMAIA moves beyond scripted tools toward conversational mapping that is both spatially grounded and broadly usable.",
      "tldr_zh": "该研究提出了IMAIA，一种能够通过自然语言与矢量地图、卫星图像及相机输入进行交互的智能地图助手，旨在提升旅游规划与地理空间智能。系统包含两个核心组件：Maps Plus通过网格对齐表示处理地图上下文，使语言模型能够解析复杂的指示性引用(deictic references)；PAISA则通过融合图像-地点嵌入与地理空间信号(geospatial signals)，实现相机感知的地点理解。IMAIA采用轻量级的多智能体(multi-agent)设计，在确保低延迟的同时增强了决策的可解释性。实验表明，该系统在地图问答(map-centric QA)和相机-地点对齐任务上的表现显著优于基线模型。通过整合语言、地图与地理空间线索，IMAIA实现了具有空间接地(spatially grounded)能力的对话式地图交互，为地理空间智能应用提供了新的范式。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06993v3",
      "published_date": "2025-07-09 16:18:09 UTC",
      "updated_date": "2025-09-23 03:59:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:34.668203+00:00"
    },
    {
      "arxiv_id": "2507.06992v2",
      "title": "MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation",
      "title_zh": "MCA-RG：通过医学概念对齐增强大语言模型的放射学报告生成",
      "authors": [
        "Qilong Xing",
        "Zikai Song",
        "Youjia Zhang",
        "Na Feng",
        "Junqing Yu",
        "Wei Yang"
      ],
      "abstract": "Despite significant advancements in adapting Large Language Models (LLMs) for radiology report generation (RRG), clinical adoption remains challenging due to difficulties in accurately mapping pathological and anatomical features to their corresponding text descriptions. Additionally, semantic agnostic feature extraction further hampers the generation of accurate diagnostic reports. To address these challenges, we introduce Medical Concept Aligned Radiology Report Generation (MCA-RG), a knowledge-driven framework that explicitly aligns visual features with distinct medical concepts to enhance the report generation process. MCA-RG utilizes two curated concept banks: a pathology bank containing lesion-related knowledge, and an anatomy bank with anatomical descriptions. The visual features are aligned with these medical concepts and undergo tailored enhancement. We further propose an anatomy-based contrastive learning procedure to improve the generalization of anatomical features, coupled with a matching loss for pathological features to prioritize clinically relevant regions. Additionally, a feature gating mechanism is employed to filter out low-quality concept features. Finally, the visual features are corresponding to individual medical concepts, and are leveraged to guide the report generation process. Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstrate that MCA-RG achieves superior performance, highlighting its effectiveness in radiology report generation.",
      "tldr_zh": "该研究提出了MCA-RG框架，旨在解决大型语言模型(LLMs)在放射报告生成(RRG)中难以准确映射病理和解剖特征，以及语义不可知特征提取导致的诊断报告不准确问题。该框架核心在于构建病理知识库(Pathology Bank)和解剖描述库(Anatomy Bank)，将视觉特征与具体的医学概念进行显式对齐和针对性增强。研究进一步采用了解剖特征对比学习(Anatomy-based Contrastive Learning)以提高特征泛化性，并结合病理特征匹配损失(Matching Loss)来优先提取临床相关区域的信息。此外，框架利用特征门控机制(Feature Gating Mechanism)过滤低质量概念特征，最终引导LLM生成更精确的放射报告。在MIMIC-CXR和CheXpert Plus两个公开基准数据集上的实验结果表明，MCA-RG显著提升了模型的生成性能，证明了该知识驱动框架在临床放射诊断中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06992v2",
      "published_date": "2025-07-09 16:15:38 UTC",
      "updated_date": "2025-08-21 02:47:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:42.585379+00:00"
    },
    {
      "arxiv_id": "2507.06969v3",
      "title": "Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy",
      "title_zh": "差分隐私中再识别、属性推断与数据重构风险的统一",
      "authors": [
        "Bogdan Kulynych",
        "Juan Felipe Gomez",
        "Georgios Kaissis",
        "Jamie Hayes",
        "Borja Balle",
        "Flavio P. Calmon",
        "Jean Louis Raisaro"
      ],
      "abstract": "Differentially private (DP) mechanisms are difficult to interpret and calibrate because existing methods for mapping standard privacy parameters to concrete privacy risks -- re-identification, attribute inference, and data reconstruction -- are both overly pessimistic and inconsistent. In this work, we use the hypothesis-testing interpretation of DP ($f$-DP), and determine that bounds on attack success can take the same unified form across re-identification, attribute inference, and data reconstruction risks. Our unified bounds are (1) consistent across a multitude of attack settings, and (2) tunable, enabling practitioners to evaluate risk with respect to arbitrary, including worst-case, levels of baseline risk. Empirically, our results are tighter than prior methods using $\\varepsilon$-DP, Rényi DP, and concentrated DP. As a result, calibrating noise using our bounds can reduce the required noise by 20% at the same risk level, which yields, e.g., an accuracy increase from 52% to 70% in a text classification task. Overall, this unifying perspective provides a principled framework for interpreting and calibrating the degree of protection in DP against specific levels of re-identification, attribute inference, or data reconstruction risk.",
      "tldr_zh": "该研究针对差分隐私 (Differential Privacy, DP) 机制中现有隐私参数映射到具体隐私风险（如重识别 re-identification、属性推理 attribute inference 和数据重构 data reconstruction）时存在的过度悲观和不一致问题，提出了一种统一的解释框架。利用基于假设检验的 DP 解释方法 ($f$-DP)，该研究确定了这三种风险在攻击成功率边界上的统一形式。这些统一边界在多种攻击设定下保持一致，且具有可调节性 (tunable)，支持从业者根据任意基准风险水平评估最坏情况下的风险。实验结果表明，该方法提供的边界比基于 $\\varepsilon$-DP、Rényi DP 和集中化 DP (concentrated DP) 的现有方法更为紧致。通过该边界进行噪声校准，可在相同风险水平下减少 20% 的所需噪声，从而显著提升模型效用。例如，在文本分类任务中，该方法将准确率从 52% 提升至 70%。总体而言，该研究为解释和校准差分隐私 (DP) 在针对特定风险水平下的保护程度提供了一个原则性的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025. v3 corrects Eq. (36) in Appendix D, and typos",
      "pdf_url": "https://arxiv.org/pdf/2507.06969v3",
      "published_date": "2025-07-09 15:59:30 UTC",
      "updated_date": "2025-11-26 14:25:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:42.270926+00:00"
    },
    {
      "arxiv_id": "2507.06968v3",
      "title": "Scaling Towards the Information Boundary of Instruction Sets: The Infinity Instruct Subject Technical Report",
      "title_zh": "迈向指令集的信息边界：Infinity Instruct Subject 技术报告",
      "authors": [
        "Li Du",
        "Hanyu Zhao",
        "Yiming Ju",
        "Tengfei Pan"
      ],
      "abstract": "Instruction tuning has become a foundation for unlocking the capabilities of large-scale pretrained models and improving their performance on complex tasks. Thus, the construction of high-quality instruction datasets is crucial for enhancing model performance and generalizability. Although current instruction datasets have reached tens of millions of samples, models finetuned on them may still struggle with complex instruction following and tasks in rare domains. This is primarily due to limited expansion in both ``coverage'' (coverage of task types and knowledge areas) and ``depth'' (instruction complexity) of the instruction set. To address this issue, we propose a systematic instruction data construction framework, which integrates a hierarchical tagging system, an informative seed selection algorithm, an evolutionary data synthesis process, and a model deficiency diagnosis with targeted data generation. These components form an iterative closed-loop to continuously enhance the coverage and depth of instruction data. Based on this framework, we construct Infinity Instruct Subject, a high-quality dataset containing $\\sim$1.5 million instructions. Experiments on multiple foundation models and benchmark tasks demonstrate its effectiveness in improving instruction-following capabilities. Further analyses suggest that Infinity Instruct Subject shows enlarged coverage and depth compared to comparable synthesized instruction datasets. Our work lays a theoretical and practical foundation for the efficient, continuous evolution of instruction datasets, moving from data quantity expansion to qualitative improvement.",
      "tldr_zh": "该研究针对当前指令微调(Instruction tuning)数据集中存在的任务类型与知识领域覆盖度(coverage)不足，以及指令复杂度(depth)有限的问题，提出了一个旨在提升大语言模型复杂指令遵循能力的系统化构建框架。该框架整合了层次化标签系统(hierarchical tagging system)、信息丰富种子选择算法(informative seed selection algorithm)、演化数据合成过程(evolutionary data synthesis process)以及基于模型缺陷诊断的针对性数据生成，形成了一个持续增强数据覆盖度与深度的迭代闭环。基于此框架，研究团队构建了包含约150万条高质量指令的数据集Infinity Instruct Subject。在多个基础模型和基准任务上的实验表明，该数据集能显著提升模型的指令遵循能力，且在覆盖度和深度上均优于同类合成数据集。该工作为指令数据集从单纯的数量扩张转向质量优化提供了理论与实践基础，有效推动了模型向指令集的信息边界演进。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06968v3",
      "published_date": "2025-07-09 15:59:02 UTC",
      "updated_date": "2025-12-04 08:00:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:37:50.012656+00:00"
    },
    {
      "arxiv_id": "2507.06967v1",
      "title": "Noisy PDE Training Requires Bigger PINNs",
      "title_zh": "噪声PDE训练需要更大规模的PINNs",
      "authors": [
        "Sebastien Andre-Sloan",
        "Anirbit Mukherjee",
        "Matthew Colbrook"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) are increasingly used to approximate solutions of partial differential equations (PDEs), especially in high dimensions. In real-world applications, data samples are noisy, so it is important to know when a predictor can still achieve low empirical risk. However, little is known about the conditions under which a PINN can do so effectively. We prove a lower bound on the size of neural networks required for the supervised PINN empirical risk to fall below the variance of noisy supervision labels. Specifically, if a predictor achieves an empirical risk $O(η)$ below $σ^2$ (variance of supervision data), then necessarily $d_N\\log d_N\\gtrsim N_s η^2$, where $N_s$ is the number of samples and $d_N$ is the number of trainable parameters of the PINN. A similar constraint applies to the fully unsupervised PINN setting when boundary labels are sampled noisily. Consequently, increasing the number of noisy supervision labels alone does not provide a ``free lunch'' in reducing empirical risk. We also show empirically that PINNs can indeed achieve empirical risks below $σ^2$ under such conditions. As a case study, we investigate PINNs applied to the Hamilton--Jacobi--Bellman (HJB) PDE. Our findings lay the groundwork for quantitatively understanding the parameter requirements for training PINNs in the presence of noise.",
      "tldr_zh": "该研究探讨了物理信息神经网络(PINNs)在处理含有噪声的偏微分方程(PDEs)训练数据时的性能表现，重点分析了预测器在何种条件下能实现低经验风险(empirical risk)。作者通过理论证明指出，若要使PINNs的经验风险降至噪声标签方差($σ^2$)以下，神经网络的参数数量($d_N$)必须满足特定的下界要求，即$d_N\\log d_N\\gtrsim N_s η^2$。这一发现表明，在存在噪声的情况下，单纯增加样本数量($N_s$)并不能“免费”降低经验风险，必须同步扩大模型规模。类似的约束同样适用于边界标签受噪声干扰的无监督学习场景。研究通过Hamilton--Jacobi--Bellman (HJB) 方程的案例研究进行了实验验证，证实了PINNs在满足特定参数条件时能够有效拟合噪声数据。该研究为定量理解噪声环境下训练PINNs的参数规模需求提供了理论框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06967v1",
      "published_date": "2025-07-09 15:58:26 UTC",
      "updated_date": "2025-07-09 15:58:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:04.120709+00:00"
    },
    {
      "arxiv_id": "2507.06959v1",
      "title": "CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale",
      "title_zh": "CheXPO：基于反事实理由的胸部 X 光视觉语言模型偏好优化",
      "authors": [
        "Xiao Liang",
        "Jiawei Hu",
        "Di Wang",
        "Zhi Ma",
        "Lin Zhao",
        "Ronghan Li",
        "Bo Wan",
        "Quan Wang"
      ],
      "abstract": "Vision-language models (VLMs) are prone to hallucinations that critically compromise reliability in medical applications. While preference optimization can mitigate these hallucinations through clinical feedback, its implementation faces challenges such as clinically irrelevant training samples, imbalanced data distributions, and prohibitive expert annotation costs. To address these challenges, we introduce CheXPO, a Chest X-ray Preference Optimization strategy that combines confidence-similarity joint mining with counterfactual rationale. Our approach begins by synthesizing a unified, fine-grained multi-task chest X-ray visual instruction dataset across different question types for supervised fine-tuning (SFT). We then identify hard examples through token-level confidence analysis of SFT failures and use similarity-based retrieval to expand hard examples for balancing preference sample distributions, while synthetic counterfactual rationales provide fine-grained clinical preferences, eliminating the need for additional expert input. Experiments show that CheXPO achieves 8.93% relative performance gain using only 5% of SFT samples, reaching state-of-the-art performance across diverse clinical tasks and providing a scalable, interpretable solution for real-world radiology applications.",
      "tldr_zh": "该研究针对视觉语言模型(VLMs)在医学应用中的幻觉问题，提出了CheXPO，一种结合置信度-相似性联合挖掘(Confidence-similarity joint mining)与反事实推理(Counterfactual Rationale)的胸部X射线偏好优化(Preference Optimization)策略。为了应对数据分布不均和高昂的专家标注成本，该方法通过合成精细的多任务视觉指令数据集进行监督微调(SFT)，并利用令牌级置信度分析识别困难样本。通过相似性检索扩展样本分布以及合成反事实推理，CheXPO在无需额外专家输入的情况下提供了精细的临床偏好指导。实验表明，该方法仅需5%的SFT样本即可获得8.93%的相对性能提升，在多种临床任务中达到了最先进(State-of-the-art)水平。CheXPO为实际放射学应用提供了一个高效、可扩展且具有可解释性的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06959v1",
      "published_date": "2025-07-09 15:40:18 UTC",
      "updated_date": "2025-07-09 15:40:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:06.383780+00:00"
    },
    {
      "arxiv_id": "2507.06952v4",
      "title": "What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models",
      "title_zh": "基座模型学到了什么？利用归纳偏置探究世界模型",
      "authors": [
        "Keyon Vafa",
        "Peter G. Chang",
        "Ashesh Rambachan",
        "Sendhil Mullainathan"
      ],
      "abstract": "Foundation models are premised on the idea that sequence prediction can uncover deeper domain understanding, much like how Kepler's predictions of planetary motion later led to the discovery of Newtonian mechanics. However, evaluating whether these models truly capture deeper structure remains a challenge. We develop a technique for evaluating foundation models that examines how they adapt to synthetic datasets generated from some postulated world model. Our technique measures whether the foundation model's inductive bias aligns with the world model, and so we refer to it as an inductive bias probe. Across multiple domains, we find that foundation models can excel at their training tasks yet fail to develop inductive biases towards the underlying world model when adapted to new tasks. We particularly find that foundation models trained on orbital trajectories consistently fail to apply Newtonian mechanics when adapted to new physics tasks. Further analysis reveals that these models behave as if they develop task-specific heuristics that fail to generalize.",
      "tldr_zh": "该研究探讨了基础模型(foundation models)是否通过序列预测揭示了深层的领域理解，特别是它们是否真正捕获了底层的世界模型(world models)。作者开发了一种名为归纳偏置探测(inductive bias probe)的技术，通过评估模型对基于特定世界模型生成的合成数据集的适应能力，来衡量模型的归纳偏置(inductive bias)是否与该世界模型一致。跨多个领域的研究结果显示，基础模型虽然在训练任务中表现出色，但在适应新任务时，往往无法针对底层的世界模型建立起有效的归纳偏置。特别是在轨道轨迹数据上训练的模型，在面对新物理任务时始终未能成功应用牛顿力学(Newtonian mechanics)。进一步分析表明，这些模型更倾向于开发任务特定的启发式策略(task-specific heuristics)，而非构建能够泛化的深层结构理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06952v4",
      "published_date": "2025-07-09 15:36:15 UTC",
      "updated_date": "2025-12-27 15:25:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:08.592638+00:00"
    },
    {
      "arxiv_id": "2507.06911v2",
      "title": "Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G",
      "title_zh": "超越连接：面向 6G AI-RAN 融合的开放架构",
      "authors": [
        "Michele Polese",
        "Niloofar Mohamadi",
        "Salvatore D'Oro",
        "Leonardo Bonati",
        "Tommaso Melodia"
      ],
      "abstract": "Data-intensive Artificial Intelligence (AI) applications at the network edge demand a fundamental shift in Radio Access Network (RAN) design, from merely consuming AI for network optimization, to actively enabling distributed AI workloads. This presents a significant opportunity for network operators to monetize AI while leveraging existing infrastructure. To realize this vision, this article presents a novel converged O-RAN and AI-RAN architecture for unified orchestration and management of telecommunications and AI workloads on shared infrastructure. The proposed architecture extends the Open RAN principles of modularity, disaggregation, and cloud-nativeness to support heterogeneous AI deployments. We introduce two key architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN Service Management and Orchestration (SMO) to enable integrated resource and allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide distributed edge AI platforms with real-time processing capabilities. The proposed architecture enables flexible orchestration, meeting requirements for managing heterogeneous workloads at different time scales while maintaining open, standardized interfaces and multi-vendor interoperability.",
      "tldr_zh": "该研究针对 6G 时代网络边缘数据密集型 AI 应用的需求，提出了一种融合 O-RAN 与 AI-RAN 的新型开放架构，旨在实现电信业务与 AI 工作负载在共享基础设施上的统一编排与管理。该架构推动无线接入网（RAN）从单纯利用 AI 优化网络向主动支持分布式 AI 工作负载转变，为运营商利用现有基础设施实现 AI 变现提供了重要机遇。研究引入了两大核心创新：一是扩展了 O-RAN 服务管理与编排（SMO）功能的 AI-RAN Orchestrator，用于实现跨网络与 AI 任务的集成资源分配；二是构建了具备实时处理能力的分布式边缘平台 AI-RAN sites。该架构遵循 Open RAN 的模块化、解耦和云原生原则，能够支持复杂的异构 AI 部署。通过采用开放的标准接口，该方案在确保多厂商互操作性的同时，实现了对不同时间尺度下异构工作负载的灵活编排与管理。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "Submitted to IEEE for publication, copyright may change without notice. 8 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.06911v2",
      "published_date": "2025-07-09 14:49:11 UTC",
      "updated_date": "2025-12-02 13:51:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:14.578978+00:00"
    },
    {
      "arxiv_id": "2507.06909v1",
      "title": "MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction",
      "title_zh": "MultiJustice：面向多当事人、多罪名法律预测的中文数据集",
      "authors": [
        "Xiao Wang",
        "Jiahuan Pei",
        "Diancheng Shui",
        "Zhiguang Han",
        "Xin Sun",
        "Dawei Zhu",
        "Xiaoyu Shen"
      ],
      "abstract": "Legal judgment prediction offers a compelling method to aid legal practitioners and researchers. However, the research question remains relatively under-explored: Should multiple defendants and charges be treated separately in LJP? To address this, we introduce a new dataset namely multi-person multi-charge prediction (MPMCP), and seek the answer by evaluating the performance of several prevailing legal large language models (LLMs) on four practical legal judgment scenarios: (S1) single defendant with a single charge, (S2) single defendant with multiple charges, (S3) multiple defendants with a single charge, and (S4) multiple defendants with multiple charges. We evaluate the dataset across two LJP tasks, i.e., charge prediction and penalty term prediction. We have conducted extensive experiments and found that the scenario involving multiple defendants and multiple charges (S4) poses the greatest challenges, followed by S2, S3, and S1. The impact varies significantly depending on the model. For example, in S4 compared to S1, InternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD, while Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD. Our dataset and code are available at https://github.com/lololo-xiao/MultiJustice-MPMCP.",
      "tldr_zh": "该研究推出了名为 MultiJustice（即 MPMCP）的新数据集，旨在探讨在法律判决预测（Legal Judgment Prediction，LJP）中是否应当分别处理多名被告和多项罪名。研究通过在单被告单罪名、单被告多罪名、多被告单罪名以及多被告多罪名四种实际场景下评估主流法律大语言模型（LLMs）的表现，重点分析了它们在罪名预测（charge prediction）和刑期预测（penalty term prediction）任务中的效能。实验结果表明，多被告多罪名的场景挑战性最大，其难度显著高于其他场景，且不同模型在处理复杂法律关系时的表现差异巨大。例如，InternLM2 在复杂场景下的性能下降幅度明显小于 Lawformer，反映了不同架构对多维度法律特征的捕捉能力。该研究不仅揭示了现有法律模型的局限性，还为未来多当事人法律辅助系统的开发提供了关键的数据和基准支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NLPCC 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06909v1",
      "published_date": "2025-07-09 14:47:00 UTC",
      "updated_date": "2025-07-09 14:47:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:17.795358+00:00"
    },
    {
      "arxiv_id": "2507.06908v1",
      "title": "MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection",
      "title_zh": "MIND：用于零样本有害模因检测的多智能体框架",
      "authors": [
        "Ziyan Liu",
        "Chunxiao Fan",
        "Haoran Lou",
        "Yuexin Wu",
        "Kaiwei Deng"
      ],
      "abstract": "The rapid expansion of memes on social media has highlighted the urgent need for effective approaches to detect harmful content. However, traditional data-driven approaches struggle to detect new memes due to their evolving nature and the lack of up-to-date annotated data. To address this issue, we propose MIND, a multi-agent framework for zero-shot harmful meme detection that does not rely on annotated data. MIND implements three key strategies: 1) We retrieve similar memes from an unannotated reference set to provide contextual information. 2) We propose a bi-directional insight derivation mechanism to extract a comprehensive understanding of similar memes. 3) We then employ a multi-agent debate mechanism to ensure robust decision-making through reasoned arbitration. Extensive experiments on three meme datasets demonstrate that our proposed framework not only outperforms existing zero-shot approaches but also shows strong generalization across different model architectures and parameter scales, providing a scalable solution for harmful meme detection. The code is available at https://github.com/destroy-lonely/MIND.",
      "tldr_zh": "该研究提出了MIND，一个针对零样本(Zero-shot)有害模因检测的多智能体框架，旨在解决传统数据驱动方法因模因快速演变及缺乏标注数据而难以检测新模因的问题。该框架不依赖标注数据，其核心由三项关键策略组成：首先从无标注参考集中检索相似模因以提供上下文信息；其次通过双向洞察推导机制(Bi-directional insight derivation)提取对相似模因的全面理解；最后利用多智能体辩论机制(Multi-agent debate)进行理性仲裁，确保决策过程的鲁棒性。在三个模因数据集上的实验结果表明，MIND的性能显著优于现有的零样本检测方法。此外，该框架在不同模型架构和参数规模下均展现出极强的泛化能力，为大规模有害模因治理提供了一种高效且可扩展的自动化解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06908v1",
      "published_date": "2025-07-09 14:46:32 UTC",
      "updated_date": "2025-07-09 14:46:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:18.431490+00:00"
    },
    {
      "arxiv_id": "2507.06899v2",
      "title": "VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation",
      "title_zh": "VisualTrap：基于视觉定位操纵的 GUI 智能体隐蔽后门攻击",
      "authors": [
        "Ziang Ye",
        "Yang Zhang",
        "Wentao Shi",
        "Xiaoyu You",
        "Fuli Feng",
        "Tat-Seng Chua"
      ],
      "abstract": "Graphical User Interface (GUI) agents powered by Large Vision-Language Models (LVLMs) have emerged as a revolutionary approach to automating human-machine interactions, capable of autonomously operating personal devices (e.g., mobile phones) or applications within the device to perform complex real-world tasks in a human-like manner. However, their close integration with personal devices raises significant security concerns, with many threats, including backdoor attacks, remaining largely unexplored. This work reveals that the visual grounding of GUI agent-mapping textual plans to GUI elements-can introduce vulnerabilities, enabling new types of backdoor attacks. With backdoor attack targeting visual grounding, the agent's behavior can be compromised even when given correct task-solving plans. To validate this vulnerability, we propose VisualTrap, a method that can hijack the grounding by misleading the agent to locate textual plans to trigger locations instead of the intended targets. VisualTrap uses the common method of injecting poisoned data for attacks, and does so during the pre-training of visual grounding to ensure practical feasibility of attacking. Empirical results show that VisualTrap can effectively hijack visual grounding with as little as 5% poisoned data and highly stealthy visual triggers (invisible to the human eye); and the attack can be generalized to downstream tasks, even after clean fine-tuning. Moreover, the injected trigger can remain effective across different GUI environments, e.g., being trained on mobile/web and generalizing to desktop environments. These findings underscore the urgent need for further research on backdoor attack risks in GUI agents.",
      "tldr_zh": "该研究揭示了基于大型视觉语言模型(LVLMs)的GUI agents在视觉定位(visual grounding)方面存在的安全漏洞，并针对这一漏洞提出了一种名为VisualTrap的隐蔽后门攻击(backdoor attack)方法。VisualTrap通过操控视觉定位过程，将智能体的文本计划错误地映射到预设的触发位置而非目标元素，从而在执行正确指令的情况下劫持其行为。为了确保攻击的可行性，该方法在预训练(pre-training)阶段注入中毒数据，且使用的视觉触发器(visual triggers)对肉眼不可见，具有极高的隐蔽性。实验结果表明，仅需5%的中毒数据，VisualTrap即可实现有效的劫持，且攻击能够在经过干净微调(fine-tuning)后的下游任务中持续存在。此外，该攻击表现出强大的跨环境泛化能力，在移动端或网页端训练的触发器仍能在桌面端GUI环境中保持有效。这项研究强调了GUI agents面临的潜在安全风险，并呼吁学术界对该领域的后门攻击风险进行更深入的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in COLM2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06899v2",
      "published_date": "2025-07-09 14:36:00 UTC",
      "updated_date": "2025-09-24 14:33:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:21.084338+00:00"
    },
    {
      "arxiv_id": "2507.06895v1",
      "title": "SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN",
      "title_zh": "SCoRE：基于多标签对比学习与贝叶斯 kNN 的精简式语料库关系抽取",
      "authors": [
        "Luca Mariotti",
        "Veronica Guidetti",
        "Federica Mandreoli"
      ],
      "abstract": "The growing demand for efficient knowledge graph (KG) enrichment leveraging external corpora has intensified interest in relation extraction (RE), particularly under low-supervision settings. To address the need for adaptable and noise-resilient RE solutions that integrate seamlessly with pre-trained large language models (PLMs), we introduce SCoRE, a modular and cost-effective sentence-level RE system. SCoRE enables easy PLM switching, requires no finetuning, and adapts smoothly to diverse corpora and KGs. By combining supervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN) classifier for multi-label classification, it delivers robust performance despite the noisy annotations of distantly supervised corpora. To improve RE evaluation, we propose two novel metrics: Correlation Structure Distance (CSD), measuring the alignment between learned relational patterns and KG structures, and Precision at R (P@R), assessing utility as a recommender system. We also release Wiki20d, a benchmark dataset replicating real-world RE conditions where only KG-derived annotations are available. Experiments on five benchmarks show that SCoRE matches or surpasses state-of-the-art methods while significantly reducing energy consumption. Further analyses reveal that increasing model complexity, as seen in prior work, degrades performance, highlighting the advantages of SCoRE's minimal design. Combining efficiency, modularity, and scalability, SCoRE stands as an optimal choice for real-world RE applications.",
      "tldr_zh": "针对知识图谱(Knowledge Graph, KG)富化中关系抽取(Relation Extraction, RE)对高效、低监督方案的需求，该研究提出了SCoRE，一种模块化且低成本的句子级关系抽取系统。SCoRE无需微调(finetuning)即可集成预训练语言模型(PLMs)，并能灵活适应多种语料库和知识图谱。该系统通过结合监督对比学习(Supervised Contrastive Learning)与贝叶斯k近邻(Bayesian kNN)分类器进行多标签分类，有效增强了对远程监督产生的噪声标注数据的鲁棒性。研究还引入了Correlation Structure Distance (CSD)和Precision at R (P@R)两项新评价指标，并发布了模拟真实环境的Wiki20d基准数据集。实验结果表明，SCoRE在五个基准测试中达到或超越了现有最先进技术(SOTA)的水平，同时显著降低了能源消耗。进一步分析证明，相比于增加模型复杂度的传统方法，SCoRE的极简设计在实际应用中更具性能优势、模块化特性和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06895v1",
      "published_date": "2025-07-09 14:33:07 UTC",
      "updated_date": "2025-07-09 14:33:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:26.324980+00:00"
    },
    {
      "arxiv_id": "2507.06893v1",
      "title": "Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights",
      "title_zh": "开发与维护 AI 测评开源库：挑战与启示",
      "authors": [
        "Alexandra Abbas",
        "Celia Waggoner",
        "Justin Olive"
      ],
      "abstract": "AI evaluations have become critical tools for assessing large language model capabilities and safety. This paper presents practical insights from eight months of maintaining $inspect\\_evals$, an open-source repository of 70+ community-contributed AI evaluations. We identify key challenges in implementing and maintaining AI evaluations and develop solutions including: (1) a structured cohort management framework for scaling community contributions, (2) statistical methodologies for optimal resampling and cross-model comparison with uncertainty quantification, and (3) systematic quality control processes for reproducibility. Our analysis reveals that AI evaluation requires specialized infrastructure, statistical rigor, and community coordination beyond traditional software development practices.",
      "tldr_zh": "本研究探讨了开发和维护 AI evaluations 开源库的挑战与实践，分享了维护包含70多个社区贡献评测的开源库 $inspect\\_evals$ 八个月的宝贵经验。论文提出了一个结构化的队列管理框架 (cohort management framework)，旨在有效扩展社区贡献规模并解决维护难题。为了实现科学的模型评估，研究开发了用于最佳重采样 (resampling) 和带有不确定性量化 (uncertainty quantification) 的跨模型比较统计方法。此外，该研究还建立了系统的质量控制流程 (quality control processes) 以确保评测结果的可重复性 (reproducibility)。分析结果表明，AI evaluation 的维护不仅依赖传统的软件开发实践，更需要专门的基础设施、严谨的统计学支撑以及紧密的社区协调。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06893v1",
      "published_date": "2025-07-09 14:30:45 UTC",
      "updated_date": "2025-07-09 14:30:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:26.634192+00:00"
    },
    {
      "arxiv_id": "2507.06892v3",
      "title": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model",
      "title_zh": "挤干浸湿的海绵：大语言模型高效离线强化微调",
      "authors": [
        "Jing Liang",
        "Hongyao Tang",
        "Yi Ma",
        "Jinyi Liu",
        "Yan Zheng",
        "Shuyue Hu",
        "Lei Bai",
        "Jianye Hao"
      ],
      "abstract": "Reinforcement Learning (RL) has demonstrated its potential to improve the reasoning ability of Large Language Models (LLMs). One major limitation of most existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL in nature, i.e., data generated during the past learning process is not fully utilized. This inevitably comes at a significant cost of compute and time, posing a stringent bottleneck on continuing economic and efficient scaling. To this end, we launch the renaissance of off-policy RL and propose Reincarnating Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix consists of three major components: (1) Mix-policy proximal policy gradient with an increased Update-To-Data (UTD) ratio for efficient training; (2) KL-Convex policy constraint to balance the trade-off between stability and flexibility; (3) Policy reincarnation to achieve a seamless transition from efficient early-stage learning to steady asymptotic improvement. In our experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with 0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level performance with an over 30x to 450x reduction in training cost in terms of rollout data volume. In addition, we reveal insightful findings via multifaceted analysis, including the implicit preference for shorter responses due to the Whipping Effect of off-policy discrepancy, the collapse mode of self-reflection behavior under the presence of severe off-policyness, etc.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在强化微调(Reinforcement Finetuning, RFT)中因主要采用在策略(on-policy)强化学习而导致训练效率低、计算成本高的问题，提出了ReMix框架。ReMix通过引入提高更新数据比(Update-To-Data ratio)的混合策略近端策略梯度、平衡稳定性和灵活性的KL-Convex策略约束，以及实现学习阶段平滑过渡的策略转世(Policy reincarnation)技术，使PPO和GRPO等方法能够高效利用离策略(off-policy)数据。实验结果显示，ReMix在AIME'24、MATH500等五个数学推理基准测试中达到了SOTA性能，且在训练所需的数据生成量上比现有先进模型降低了30倍至450倍。此外，研究还深入分析了由于离策略差异引发的鞭策效应(Whipping Effect)导致模型偏向简短回答，以及在严重偏离策略时自我反思(self-reflection)模式崩溃等现象。该方法为实现经济且高效的LLMs性能扩展提供了新的路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Preliminary version, v3, added the missing name of x-axis in the left part of Fig.1 and corrected a wrong number in Fig.3. Project page: https://anitaleungxx.github.io/ReMix",
      "pdf_url": "https://arxiv.org/pdf/2507.06892v3",
      "published_date": "2025-07-09 14:29:45 UTC",
      "updated_date": "2025-07-11 10:32:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:32.582857+00:00"
    },
    {
      "arxiv_id": "2507.06890v1",
      "title": "A Single-Point Measurement Framework for Robust Cyber-Attack Diagnosis in Smart Microgrids Using Dual Fractional-Order Feature Analysis",
      "title_zh": "基于双分数阶特征分析的智能微电网鲁棒网络攻击诊断单点测量框架",
      "authors": [
        "Yifan Wang"
      ],
      "abstract": "Cyber-attacks jeopardize the safe operation of smart microgrids. At the same time, existing diagnostic methods either depend on expensive multi-point instrumentation or stringent modelling assumptions that are untenable under single-sensor constraints. This paper proposes a Fractional-Order Memory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves low-latency fault localisation and cyber-attack detection using only one VPQ (Voltage-Power-Reactive-power) sensor. FO-MADS first constructs a dual fractional-order feature library by jointly applying Caputo and Grünwald-Letnikov derivatives, thereby amplifying micro-perturbations and slow drifts in the VPQ signal. A two-stage hierarchical classifier then pinpoints the affected inverter and isolates the faulty IGBT switch, effectively alleviating class imbalance. Robustness is further strengthened through Progressive Memory-Replay Adversarial Training (PMR-AT), whose attack-aware loss is dynamically re-weighted via Online Hard Example Mining (OHEM) to prioritise the most challenging samples. Experiments on a four-inverter microgrid testbed comprising 1 normal and 24 fault classes under four attack scenarios demonstrate diagnostic accuracies of 96.6 % (bias), 94.0 % (noise), 92.8 % (data replacement), and 95.7 % (replay), while sustaining 96.7 % under attack-free conditions. These results establish FO-MADS as a cost-effective and readily deployable solution that markedly enhances the cyber-physical resilience of smart microgrids.",
      "tldr_zh": "该研究提出了FO-MADS（Fractional-Order Memory-Enhanced Attack-Diagnosis Scheme），一种旨在增强智能微网（Smart Microgrids）网络物理弹性的单点测量诊断框架。针对现有诊断方法依赖昂贵的多点监测或苛刻建模假设的问题，该方案仅通过单个VPQ（Voltage-Power-Reactive-power）传感器即可实现低延迟的故障定位与网络攻击检测。FO-MADS通过结合Caputo和Grünwald-Letnikov导数构建双分数阶特征库，从而有效放大VPQ信号中的微小扰动和缓慢漂移。此外，系统采用两阶段分层分类器准确定位受影响的逆变器并隔离故障IGBT开关，同时利用Progressive Memory-Replay Adversarial Training (PMR-AT)和Online Hard Example Mining (OHEM)技术动态优化损失权重，增强了对抗攻击的鲁棒性。实验表明，该框架在偏差、噪声、数据替换和重放攻击下的诊断准确率均在92.8%以上，在无攻击条件下准确率达96.7%。这些结果证明FO-MADS是一种低成本且易于部署的解决方案，能够显著提升智能微网的安全运行能力。",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "8 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.06890v1",
      "published_date": "2025-07-09 14:27:40 UTC",
      "updated_date": "2025-07-09 14:27:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:45.751494+00:00"
    },
    {
      "arxiv_id": "2507.06876v1",
      "title": "Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change",
      "title_zh": "人工智能中的赢与输：关于 ChatGPT 的公共话语如何揭示社会对技术变革的意义建构",
      "authors": [
        "Adrian Rauchfleisch",
        "Joshua Philip Suarez",
        "Nikka Marie Sales",
        "Andreas Jungherr"
      ],
      "abstract": "Public product launches in Artificial Intelligence can serve as focusing events for collective attention, surfacing how societies react to technological change. Social media provide a window into the sensemaking around these events, surfacing hopes and fears and showing who chooses to engage in the discourse and when. We demonstrate that public sensemaking about AI is shaped by economic interests and cultural values of those involved. We analyze 3.8 million tweets posted by 1.6 million users across 117 countries in response to the public launch of ChatGPT in 2022. Our analysis shows how economic self-interest, proxied by occupational skill types in writing, programming, and mathematics, and national cultural orientations, as measured by Hofstede's individualism, uncertainty avoidance, and power distance dimensions, shape who speaks, when they speak, and their stance towards ChatGPT. Roles requiring more technical skills, such as programming and mathematics, tend to engage earlier and express more positive stances, whereas writing-centric occupations join later with greater skepticism. At the cultural level, individualism predicts both earlier engagement and a more negative stance, and uncertainty avoidance reduces the prevalence of positive stances but does not delay when users first engage with ChatGPT. Aggregate sentiment trends mask the dynamics observed in our study. The shift toward a more critical stance towards ChatGPT over time stems primarily from the entry of more skeptical voices rather than a change of heart among early adopters. Our findings underscore the importance of both the occupational background and cultural context in understanding public reactions to AI.",
      "tldr_zh": "该研究通过分析2022年ChatGPT发布后来自117个国家的3.8 million条推文，探讨了社会如何通过集体注意力(collective attention)理解技术变革。研究发现，公众对AI的认知过程(sensemaking)深受参与者的经济利益和文化价值(cultural values)共同塑造。以编程(programming)和数学(mathematics)为代表的技术型职业群体倾向于更早参与讨论并持有积极立场，而以写作(writing)为核心的职业群体则参与较晚且态度更为怀疑。在文化层面，个人主义(individualism)倾向预示着更早的参与和更负面的立场，而不确定性规避(uncertainty avoidance)则降低了积极态度的比例。随时间推移而出现的整体情绪下滑主要源于后期怀疑论者的进入，而非早期采用者的态度转变。该研究强调了职业背景和文化背景在理解公众对人工智能(AI)反应中的核心作用，揭示了技术变革背景下的社会认知动态。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06876v1",
      "published_date": "2025-07-09 14:15:12 UTC",
      "updated_date": "2025-07-09 14:15:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:52.679794+00:00"
    },
    {
      "arxiv_id": "2507.06856v1",
      "title": "IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization",
      "title_zh": "IAP：基于感知觉知定位与扰动优化的不可见对抗补丁攻击",
      "authors": [
        "Subrat Kishore Dutta",
        "Xiao Zhang"
      ],
      "abstract": "Despite modifying only a small localized input region, adversarial patches can drastically change the prediction of computer vision models. However, prior methods either cannot perform satisfactorily under targeted attack scenarios or fail to produce contextually coherent adversarial patches, causing them to be easily noticeable by human examiners and insufficiently stealthy against automatic patch defenses. In this paper, we introduce IAP, a novel attack framework that generates highly invisible adversarial patches based on perceptibility-aware localization and perturbation optimization schemes. Specifically, IAP first searches for a proper location to place the patch by leveraging classwise localization and sensitivity maps, balancing the susceptibility of patch location to both victim model prediction and human visual system, then employs a perceptibility-regularized adversarial loss and a gradient update rule that prioritizes color constancy for optimizing invisible perturbations. Comprehensive experiments across various image benchmarks and model architectures demonstrate that IAP consistently achieves competitive attack success rates in targeted settings with significantly improved patch invisibility compared to existing baselines. In addition to being highly imperceptible to humans, IAP is shown to be stealthy enough to render several state-of-the-art patch defenses ineffective.",
      "tldr_zh": "该研究提出了IAP，一种结合感知感知定位（perceptibility-aware localization）与扰动优化方案的新型攻击框架，旨在生成高度不可见的对抗补丁（adversarial patches）。针对现有方法在目标攻击下表现不佳或易被人类察觉的问题，IAP首先利用类别定位（classwise localization）和敏感度图（sensitivity maps）寻找补丁的最佳放置位置，以平衡模型敏感度与视觉隐蔽性。在优化过程中，该框架采用感知正则化对抗损失（perceptibility-regularized adversarial loss）及优先考虑颜色恒常性（color constancy）的梯度更新规则，确保生成的扰动与上下文环境融为一体。实验证明，IAP在多种图像基准和模型架构上均实现了极高的目标攻击成功率，且其不可见性显著优于现有基准。此外，该方法能有效规避多种先进的补丁防御技术，展示了其在实际应用场景中的强隐蔽性与攻击效能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06856v1",
      "published_date": "2025-07-09 13:58:40 UTC",
      "updated_date": "2025-07-09 13:58:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:51.098917+00:00"
    },
    {
      "arxiv_id": "2507.06853v2",
      "title": "DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models",
      "title_zh": "DiffSpectra：基于扩散模型的光谱分子结构解析",
      "authors": [
        "Liang Wang",
        "Yu Rong",
        "Tingyang Xu",
        "Zhenyi Zhong",
        "Zhiyuan Liu",
        "Pengju Wang",
        "Deli Zhao",
        "Qiang Liu",
        "Shu Wu",
        "Liang Wang",
        "Yang Zhang"
      ],
      "abstract": "Molecular structure elucidation from spectra is a fundamental challenge in molecular science. Conventional approaches rely heavily on expert interpretation and lack scalability, while retrieval-based machine learning approaches remain constrained by limited reference libraries. Generative models offer a promising alternative, yet most adopt autoregressive architectures that overlook 3D geometry and struggle to integrate diverse spectral modalities. In this work, we present DiffSpectra, a generative framework that formulates molecular structure elucidation as a conditional generation process, directly inferring 2D and 3D molecular structures from multi-modal spectra using diffusion models. Its denoising network is parameterized by the Diffusion Molecule Transformer, an SE(3)-equivariant architecture for geometric modeling, conditioned by SpecFormer, a Transformer-based spectral encoder capturing multi-modal spectral dependencies. Extensive experiments demonstrate that DiffSpectra accurately elucidates molecular structures, achieving 40.76% top-1 and 99.49% top-10 accuracy. Its performance benefits substantially from 3D geometric modeling, SpecFormer pre-training, and multi-modal conditioning. To our knowledge, DiffSpectra is the first framework that unifies multi-modal spectral reasoning and joint 2D/3D generative modeling for de novo molecular structure elucidation.",
      "tldr_zh": "该研究提出了 DiffSpectra，一个通过 Diffusion Models 从多模态光谱中直接推断 2D 和 3D 分子结构的生成式框架。该框架采用了具备 SE(3)-equivariant 几何建模能力的 Diffusion Molecule Transformer 作为去噪网络，并结合 SpecFormer 编码器来捕捉多模态光谱之间的依赖关系。实验结果证明 DiffSpectra 在分子结构解析任务中表现出色，达到了 40.76% 的 Top-1 和 99.49% 的 Top-10 准确率。其性能的提升主要归功于 3D 几何建模、SpecFormer 预训练以及多模态条件的引入。作为首个将多模态光谱推理与 2D/3D 生成建模相结合的框架，DiffSpectra 为实现自动化的从头（de novo）分子结构解析奠定了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "physics.chem-ph",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06853v2",
      "published_date": "2025-07-09 13:57:20 UTC",
      "updated_date": "2025-11-05 11:17:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:56.227310+00:00"
    },
    {
      "arxiv_id": "2507.06852v1",
      "title": "SCC-recursiveness in infinite argumentation (extended version)",
      "title_zh": "无限论证中的 SCC 递归性（扩展版）",
      "authors": [
        "Uri Andrews",
        "Luca San Mauro"
      ],
      "abstract": "Argumentation frameworks (AFs) are a foundational tool in artificial intelligence for modeling structured reasoning and conflict. SCC-recursiveness is a well-known design principle in which the evaluation of arguments is decomposed according to the strongly connected components (SCCs) of the attack graph, proceeding recursively from \"higher\" to \"lower\" components. While SCC-recursive semantics such as \\cft and \\stgt have proven effective for finite AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to generalize reliably to infinite AFs due to issues with well-foundedness.\n  We propose two approaches to extending SCC-recursiveness to the infinite setting. We systematically evaluate these semantics using Baroni and Giacomin's established criteria, showing in particular that directionality fails in general. We then examine these semantics' behavior in finitary frameworks, where we find some of our semantics satisfy directionality. These results advance the theory of infinite argumentation and lay the groundwork for reasoning systems capable of handling unbounded or evolving domains.",
      "tldr_zh": "该研究深入探讨了无限论证框架(infinite argumentation frameworks, AFs)中的SCC-recursiveness设计原则。研究指出，传统的SCC-recursiveness语义（如CF2和stage2）在处理有限框架时表现良好，但在无限设置下会因良基性(well-foundedness)问题而失效。为此，作者提出了两种将SCC-recursiveness扩展到无限环境的新方法，并根据Baroni和Giacomin建立的标准对其进行了系统评估。分析结果表明，虽然方向性(directionality)在一般无限情形下无法成立，但在有限性(finitary)框架中，部分提出的语义仍能满足该性质。该工作推进了无限论证的理论边界，为开发能够处理无界或演化领域推理系统提供了重要的理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, accepted at JELIA 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06852v1",
      "published_date": "2025-07-09 13:57:12 UTC",
      "updated_date": "2025-07-09 13:57:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:38:59.140254+00:00"
    },
    {
      "arxiv_id": "2507.06850v5",
      "title": "The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover",
      "title_zh": "LLM 的阴暗面：实现计算机全面接管的基于智能体攻击",
      "authors": [
        "Matteo Lupinacci",
        "Francesco Aurelio Pironti",
        "Francesco Blefari",
        "Francesco Romeo",
        "Luigi Arena",
        "Angelo Furfaro"
      ],
      "abstract": "The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables remarkable capabilities in natural language processing and generation. However, these systems introduce security vulnerabilities that extend beyond traditional content generation to system-level compromises. This paper presents a comprehensive evaluation of the LLMs security used as reasoning engines within autonomous agents, highlighting how they can be exploited as attack vectors capable of achieving computer takeovers. We focus on how different attack surfaces and trust boundaries can be leveraged to orchestrate such takeovers. We demonstrate that adversaries can effectively coerce popular LLMs into autonomously installing and executing malware on victim machines. Our evaluation of 18 state-of-the-art LLMs reveals an alarming scenario: 94.4% of models succumb to Direct Prompt Injection, and 83.3% are vulnerable to the more stealthy and evasive RAG Backdoor Attack. Notably, we tested trust boundaries within multi-agent systems, where LLM agents interact and influence each other, and we revealed that LLMs which successfully resist direct injection or RAG backdoor attacks will execute identical payloads when requested by peer agents. We found that 100.0% of tested LLMs can be compromised through Inter-Agent Trust Exploitation attacks, and that every model exhibits context-dependent security behaviors that create exploitable blind spots.",
      "tldr_zh": "该研究深入探讨了大型语言模型（LLMs）及其多智能体系统在系统层面的安全漏洞，重点分析了攻击者如何利用这些系统作为向量实现完整的计算机接管（computer takeover）。研究团队通过对18种先进 LLMs 的全面评估，验证了它们在受到胁迫时能够自主执行并安装恶意软件（malware）的严重风险。实验结果显示，高达94.4%的模型容易受到直接提示注入（Direct Prompt Injection）的攻击，而83.3%的模型对更具隐蔽性的 RAG Backdoor Attack 缺乏防御力。研究进一步揭示了多智能体系统内部的信任边界缺陷，证实 100% 的受试模型均可通过智能体间信任利用（Inter-Agent Trust Exploitation）被攻破，即便是能抵抗直接攻击的模型也会执行来自同行智能体的恶意负载。这些发现表明 LLMs 在作为自主智能体时存在严重的上下文依赖性安全盲点，为构建可信的 AI 系统提供了重要的安全警示。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06850v5",
      "published_date": "2025-07-09 13:54:58 UTC",
      "updated_date": "2025-11-04 10:28:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:03.934547+00:00"
    },
    {
      "arxiv_id": "2507.06849v2",
      "title": "OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion",
      "title_zh": "OpenDPDv2：神经网络数字预失真统一学习与优化框架",
      "authors": [
        "Yizhuo Wu",
        "Ang Li",
        "Chang Gao"
      ],
      "abstract": "Neural network (NN)-based Digital Predistortion (DPD) has demonstrated superior performance in improving signal quality in wideband radio frequency (RF) power amplifiers (PAs) employing complex modulation. However, NN DPDs usually rely on a large number of parameters for effective linearization and can significantly contribute to the energy consumption of the digital back-end in RF systems. This paper presents OpenDPDv2, an open-source, end-to-end framework that unifies PA modeling, NN-DPD learning, and deployment-oriented model optimization to reduce inference energy while preserving linearization performance. OpenDPDv2 introduces TRes-DeltaGRU, a delta-RNN DPD architecture with a lightweight temporal residual path that improves robustness under aggressive temporal sparsity, and it supports joint optimization of temporal sparsity and fixed-point quantization. On a 3.5 GHz GaN Doherty PA driven by a TM3.1a 200 MHz 256-QAM OFDM signal, the FP32 TRes-DeltaGRU model achieves ACPR of -59.9 dBc and EVM of -42.1 dB. By combining quantization with dynamic temporal sparsity, the model reduces inference energy by 4.5x while maintaining -51.8 dBc ACPR and -35.2 dB EVM at 56% temporal sparsity. Code, datasets, and documentation are publicly available at https://github.com/lab-emi/OpenDPD.",
      "tldr_zh": "该研究提出了OpenDPDv2，一个开源的端到端框架，旨在统一功率放大器(PA)建模、神经网络数字预失真(NN-DPD)学习以及面向部署的模型优化，以在降低推理能耗的同时保持线性化性能。针对现有NN-DPD参数量大且能耗高的问题，该框架引入了TRes-DeltaGRU架构，利用轻量级的时间残差路径增强了模型在激进时间稀疏性(temporal sparsity)下的鲁棒性。OpenDPDv2支持时间稀疏性与定点量化(fixed-point quantization)的联合优化，实现了计算开销与信号质量的深度权衡。在3.5 GHz GaN Doherty PA上的实验表明，该模型在56%的时间稀疏性下能将推理能耗降低4.5倍，同时维持了-51.8 dBc ACPR和-35.2 dB EVM的优异指标。该研究通过公开代码和数据集，为实现高效、低功耗的射频系统数字化预失真提供了完整的解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2507.06849v2",
      "published_date": "2025-07-09 13:54:47 UTC",
      "updated_date": "2025-12-16 22:05:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:07.274774+00:00"
    },
    {
      "arxiv_id": "2507.08864v1",
      "title": "Privacy-Utility-Fairness: A Balanced Approach to Vehicular-Traffic Management System",
      "title_zh": "隐私-效用-公平性：一种均衡的车辆交通管理系统方法",
      "authors": [
        "Poushali Sengupta",
        "Sabita Maharjan",
        "frank Eliassen",
        "Yan Zhang"
      ],
      "abstract": "Location-based vehicular traffic management faces significant challenges in protecting sensitive geographical data while maintaining utility for traffic management and fairness across regions. Existing state-of-the-art solutions often fail to meet the required level of protection against linkage attacks and demographic biases, leading to privacy leakage and inequity in data analysis. In this paper, we propose a novel algorithm designed to address the challenges regarding the balance of privacy, utility, and fairness in location-based vehicular traffic management systems. In this context, utility means providing reliable and meaningful traffic information, while fairness ensures that all regions and individuals are treated equitably in data use and decision-making. Employing differential privacy techniques, we enhance data security by integrating query-based data access with iterative shuffling and calibrated noise injection, ensuring that sensitive geographical data remains protected. We ensure adherence to epsilon-differential privacy standards by implementing the Laplace mechanism. We implemented our algorithm on vehicular location-based data from Norway, demonstrating its ability to maintain data utility for traffic management and urban planning while ensuring fair representation of all geographical areas without being overrepresented or underrepresented. Additionally, we have created a heatmap of Norway based on our model, illustrating the privatized and fair representation of the traffic conditions across various cities. Our algorithm provides privacy in vehicular traffic",
      "tldr_zh": "该研究针对基于位置的车辆交通管理系统中的地理数据保护、效用维持以及区域公平性挑战，提出了一种平衡 Privacy、Utility 和 Fairness 的创新算法。针对现有方案在抵御 Linkage Attacks 和人口统计偏见方面的不足，该方法采用了 Differential Privacy 技术，通过结合基于查询的数据访问、Iterative Shuffling 和校准噪声注入，确保了敏感地理数据的安全性。研究通过实现 Laplace Mechanism 严格遵循了 Epsilon-Differential Privacy 标准，有效提升了数据安全等级。利用挪威的车辆位置数据进行的实验表明，该算法在提供可靠交通管理和城市规划信息的同时，实现了各地理区域的公平代表性。此外，研究还生成了挪威交通热图，直观展示了私有化处理后且具备公平性的交通状况，证明了该算法在保障车辆交通隐私及系统均衡性方面的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "accepted in VTC 2025 Spring, Oslo, Norway",
      "pdf_url": "https://arxiv.org/pdf/2507.08864v1",
      "published_date": "2025-07-09 13:49:13 UTC",
      "updated_date": "2025-07-09 13:49:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:08.078982+00:00"
    },
    {
      "arxiv_id": "2507.13368v2",
      "title": "Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiation",
      "title_zh": "基于邻域差异化的可扩展属性缺失图聚类",
      "authors": [
        "Yaowen Hu",
        "Wenxuan Tu",
        "Yue Liu",
        "Xinhang Wan",
        "Junyi Yan",
        "Taichun Zhou",
        "Xinwang Liu"
      ],
      "abstract": "Deep graph clustering (DGC), which aims to unsupervisedly separate the nodes in an attribute graph into different clusters, has seen substantial potential in various industrial scenarios like community detection and recommendation. However, the real-world attribute graphs, e.g., social networks interactions, are usually large-scale and attribute-missing. To solve these two problems, we propose a novel DGC method termed \\underline{\\textbf{C}}omplementary \\underline{\\textbf{M}}ulti-\\underline{\\textbf{V}}iew \\underline{\\textbf{N}}eighborhood \\underline{\\textbf{D}}ifferentiation (\\textit{CMV-ND}), which preprocesses graph structural information into multiple views in a complete but non-redundant manner. First, to ensure completeness of the structural information, we propose a recursive neighborhood search that recursively explores the local structure of the graph by completely expanding node neighborhoods across different hop distances. Second, to eliminate the redundancy between neighborhoods at different hops, we introduce a neighborhood differential strategy that ensures no overlapping nodes between the differential hop representations. Then, we construct $K+1$ complementary views from the $K$ differential hop representations and the features of the target node. Last, we apply existing multi-view clustering or DGC methods to the views. Experimental results on six widely used graph datasets demonstrate that CMV-ND significantly improves the performance of various methods.",
      "tldr_zh": "该研究针对大规模且属性缺失(attribute-missing)的图数据，提出了一种名为CMV-ND（Complementary Multi-View Neighborhood Differentiation）的深度图聚类(Deep Graph Clustering, DGC)方法。为了保证结构信息的完整性，该方法采用递归邻域搜索(recursive neighborhood search)全面扩展不同跳数距离下的节点邻域。同时，研究引入了邻域微分策略(neighborhood differential strategy)以消除不同跳数邻域间的冗余，确保生成的差分表示之间不存在重叠节点。通过整合$K$个差分跳表示与目标节点特征，CMV-ND构建了$K+1$个互补视图，并能灵活应用现有的多视图聚类或深度图聚类算法。在六个通用图数据集上的实验结果证明，CMV-ND显著提升了多种现有方法的性能，有效解决了大规模图数据在属性缺失情况下的聚类难题。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.13368v2",
      "published_date": "2025-07-09 13:42:43 UTC",
      "updated_date": "2025-08-05 09:24:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:12.019602+00:00"
    },
    {
      "arxiv_id": "2507.06830v1",
      "title": "Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation",
      "title_zh": "面向轨迹引导图像到视频生成的基于方程发现的物理约束运动预测",
      "authors": [
        "Tao Feng",
        "Xianbing Zhao",
        "Zhenhua Chen",
        "Tien Tsin Wong",
        "Hamid Rezatofighi",
        "Gholamreza Haffari",
        "Lizhen Qu"
      ],
      "abstract": "Recent advances in diffusion-based and autoregressive video generation models have achieved remarkable visual realism. However, these models typically lack accurate physical alignment, failing to replicate real-world dynamics in object motion. This limitation arises primarily from their reliance on learned statistical correlations rather than capturing mechanisms adhering to physical laws. To address this issue, we introduce a novel framework that integrates symbolic regression (SR) and trajectory-guided image-to-video (I2V) models for physics-grounded video forecasting. Our approach extracts motion trajectories from input videos, uses a retrieval-based pre-training mechanism to enhance symbolic regression, and discovers equations of motion to forecast physically accurate future trajectories. These trajectories then guide video generation without requiring fine-tuning of existing models. Evaluated on scenarios in Classical Mechanics, including spring-mass, pendulums, and projectile motions, our method successfully recovers ground-truth analytical equations and improves the physical alignment of generated videos over baseline methods.",
      "tldr_zh": "该研究针对当前的扩散模型和自回归视频生成模型在物体运动中普遍缺乏物理对齐、难以遵循物理定律的问题，提出了一种整合符号回归(Symbolic Regression, SR)与轨迹引导图像到视频(I2V)模型的新型框架，用于实现物理增强的视频预测。该方法通过从输入视频中提取运动轨迹，并结合基于检索的预训练机制来增强符号回归，从而发现运动方程并预测物理上准确的未来轨迹。生成的轨迹可在无需微调现有模型的情况下引导视频合成过程。在弹簧质点、摆锤及抛体运动等经典力学场景的实验中，该方法成功恢复了基准真相(ground-truth)解析方程，并在物理对齐性能上显著优于基线方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06830v1",
      "published_date": "2025-07-09 13:28:42 UTC",
      "updated_date": "2025-07-09 13:28:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:24.178029+00:00"
    },
    {
      "arxiv_id": "2507.06828v2",
      "title": "Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data",
      "title_zh": "Speckle2Self：无需纯净数据的自监督超声斑点噪声抑制",
      "authors": [
        "Xuesong Li",
        "Nassir Navab",
        "Zhongliang Jiang"
      ],
      "abstract": "Image denoising is a fundamental task in computer vision, particularly in medical ultrasound (US) imaging, where speckle noise significantly degrades image quality. Although recent advancements in deep neural networks have led to substantial improvements in denoising for natural images, these methods cannot be directly applied to US speckle noise, as it is not purely random. Instead, US speckle arises from complex wave interference within the body microstructure, making it tissue-dependent. This dependency means that obtaining two independent noisy observations of the same scene, as required by pioneering Noise2Noise, is not feasible. Additionally, blind-spot networks also cannot handle US speckle noise due to its high spatial dependency. To address this challenge, we introduce Speckle2Self, a novel self-supervised algorithm for speckle reduction using only single noisy observations. The key insight is that applying a multi-scale perturbation (MSP) operation introduces tissue-dependent variations in the speckle pattern across different scales, while preserving the shared anatomical structure. This enables effective speckle suppression by modeling the clean image as a low-rank signal and isolating the sparse noise component. To demonstrate its effectiveness, Speckle2Self is comprehensively compared with conventional filter-based denoising algorithms and SOTA learning-based methods, using both realistic simulated US images and human carotid US images. Additionally, data from multiple US machines are employed to evaluate model generalization and adaptability to images from unseen domains. Project page: https://noseefood.github.io/us-speckle2self/",
      "tldr_zh": "该研究提出了Speckle2Self，一种专为超声(Ultrasound)图像设计的自监督斑点噪声(Speckle noise)去除算法，旨在解决传统方法难以处理组织依赖性噪声的问题。由于超声斑点具有高度的空间相关性且源于复杂的波干扰，传统的Noise2Noise或盲点网络(Blind-spot networks)难以直接应用，而该算法仅需单张噪声观测图像即可实现有效去噪。其核心创新在于引入了多尺度扰动(Multi-scale perturbation, MSP)操作，通过在不同尺度上诱发组织依赖的斑点变化，同时保留共享的解剖结构。该方法将清晰图像建模为低秩信号(Low-rank signal)，并成功分离出稀疏的噪声分量。实验结果表明，在模拟数据和人体颈动脉(Carotid)超声图像上，Speckle2Self的性能优于传统滤波器及多种SOTA学习方法。此外，通过跨多种超声设备的数据测试，验证了该模型在面对未知领域图像时具有极强的泛化能力和适应性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06828v2",
      "published_date": "2025-07-09 13:28:00 UTC",
      "updated_date": "2025-08-10 15:13:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:37.075392+00:00"
    },
    {
      "arxiv_id": "2507.06825v2",
      "title": "Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning",
      "title_zh": "Artificial Generals Intelligence：利用强化学习精通 Generals.io",
      "authors": [
        "Matej Straka",
        "Martin Schmid"
      ],
      "abstract": "We introduce a real-time strategy game environment based on Generals.io, a game with thousands of weekly active players. Our environment is fully compatible with Gymnasium and PettingZoo and is capable of running thousands of frames per second on commodity hardware. We also present a reference agent, trained with supervised pre-training and self-play, which reached the top 0.003% of the 1v1 human leaderboard after only 36 hours on a single H100 GPU. To accelerate learning, we incorporate potential-based reward shaping and memory features. Our contributions of a modular RTS benchmark and a competitive baseline agent provide an accessible yet challenging platform for advancing multi-agent reinforcement learning research. The documented code, together with examples and tutorials, is available at https://github.com/strakam/generals-bots.",
      "tldr_zh": "该研究推出了一个基于Generals.io的实时策略游戏(RTS)环境，旨在为多智能体强化学习(Multi-Agent Reinforcement Learning)研究提供一个易于访问且具挑战性的平台。该环境与Gymnasium和PettingZoo完全兼容，且在普通硬件上能够达到每秒数千帧的运行速度。研究人员提出了一个参考智能体，通过监督预训练(Supervised Pre-training)和自我对弈(Self-play)进行训练，在单张H100 GPU上仅耗时36小时便达到了1v1人类排行榜前0.003%的顶尖水平。为了提高学习效率，该研究还整合了基于势能的奖励塑造(Potential-based Reward Shaping)和记忆机制。该项目通过提供模块化的基准测试和极具竞争力的基准模型，为推动多智能体强化学习的发展做出了贡献，并已将代码和教程完全开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06825v2",
      "published_date": "2025-07-09 13:15:05 UTC",
      "updated_date": "2025-07-10 09:28:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:48.565266+00:00"
    },
    {
      "arxiv_id": "2507.06821v3",
      "title": "HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning",
      "title_zh": "HeLo：结合标签相关性的异构多模态融合情绪分布学习",
      "authors": [
        "Chuhang Zheng",
        "Chunwei Tian",
        "Jie Wen",
        "Daoqiang Zhang",
        "Qi Zhu"
      ],
      "abstract": "Multi-modal emotion recognition has garnered increasing attention as it plays a significant role in human-computer interaction (HCI) in recent years. Since different discrete emotions may exist at the same time, compared with single-class emotion recognition, emotion distribution learning (EDL) that identifies a mixture of basic emotions has gradually emerged as a trend. However, existing EDL methods face challenges in mining the heterogeneity among multiple modalities. Besides, rich semantic correlations across arbitrary basic emotions are not fully exploited. In this paper, we propose a multi-modal emotion distribution learning framework, named HeLo, aimed at fully exploring the heterogeneity and complementary information in multi-modal emotional data and label correlation within mixed basic emotions. Specifically, we first adopt cross-attention to effectively fuse the physiological data. Then, an optimal transport (OT)-based heterogeneity mining module is devised to mine the interaction and heterogeneity between the physiological and behavioral representations. To facilitate label correlation learning, we introduce a learnable label embedding optimized by correlation matrix alignment. Finally, the learnable label embeddings and label correlation matrices are integrated with the multi-modal representations through a novel label correlation-driven cross-attention mechanism for accurate emotion distribution learning. Experimental results on two publicly available datasets demonstrate the superiority of our proposed method in emotion distribution learning.",
      "tldr_zh": "该研究提出了HeLo，一种旨在解决多模态情感分布学习(Emotion Distribution Learning)中异质性挖掘和标签相关性利用不足问题的多模态框架。该框架首先利用交叉注意力(cross-attention)机制融合生理数据，并设计了一个基于最优传输(Optimal Transport)的异质性挖掘模块来探索生理与行为表征之间的深度交互。为了充分捕捉基本情感间的语义关联，HeLo引入了通过相关矩阵对齐进行优化的可学习标签嵌入(learnable label embedding)。随后，研究通过一种新颖的标签相关性驱动的交叉注意力机制，将标签特征与多模态表征进行有效集成。在两个公开数据集上的实验结果表明，HeLo在情感分布学习任务中展现出显著的优越性。该研究为处理人机交互中复杂的多模态情感数据提供了更具鲁棒性的建模方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06821v3",
      "published_date": "2025-07-09 13:08:58 UTC",
      "updated_date": "2025-07-26 16:52:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:45.757911+00:00"
    },
    {
      "arxiv_id": "2507.06819v3",
      "title": "Comprehensive Evaluation of Prototype Neural Networks",
      "title_zh": "原型神经网络的全面评估",
      "authors": [
        "Philipp Schlinge",
        "Steffen Meinert",
        "Martin Atzmueller"
      ],
      "abstract": "Prototype models are an important method for explainable artificial intelligence (XAI) and interpretable machine learning. In this paper, we perform an in-depth analysis of a set of prominent prototype models including ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive set of metrics. In addition to applying standard metrics from literature, we propose several new metrics to further complement the analysis of model interpretability. In our experimentation, we apply the set of prototype models on a diverse set of datasets including fine-grained classification, Non-IID settings and multi-label classification to further contrast the performance. Furthermore, we also provide our code as an open-source library (https://github.com/uos-sis/quanproto), which facilitates simple application of the metrics itself, as well as extensibility -- providing the option for easily adding new metrics and models.",
      "tldr_zh": "该研究针对可解释人工智能(XAI)和可解释机器学习中的关键原型模型，包括ProtoPNet、ProtoPool和PIPNet进行了深入的综合评估。作者采用了一套全面的评估指标体系，在应用文献标准指标的基础上，提出了多种新指标以进一步完善对模型可解释性的分析。实验在细粒度分类(fine-grained classification)、非独立同分布(Non-IID)设置以及多标签分类(multi-label classification)等多样化数据集上展开，旨在深入对比不同模型的性能差异。此外，该研究还推出了开源库quanproto，不仅简化了上述指标的应用，还为添加新模型和新指标提供了良好的扩展性。该工作为原型神经网络的性能衡量提供了标准化工具，有助于推动更透明、可解释的深度学习模型的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06819v3",
      "published_date": "2025-07-09 13:08:21 UTC",
      "updated_date": "2025-11-21 12:33:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:43.426378+00:00"
    },
    {
      "arxiv_id": "2507.06813v2",
      "title": "Intrinsic Training Signals for Federated Learning Aggregation",
      "title_zh": "面向联邦学习聚合的内在训练信号",
      "authors": [
        "Cosimo Fiorini",
        "Matteo Mosconi",
        "Pietro Buzzega",
        "Riccardo Salami",
        "Simone Calderara"
      ],
      "abstract": "Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy. While existing approaches for aggregating client-specific classification heads and adapted backbone parameters require architectural modifications or loss function changes, our method uniquely leverages intrinsic training signals already available during standard optimization. We present LIVAR (Layer Importance and VARiance-based merging), which introduces: i) a variance-weighted classifier aggregation scheme using naturally emergent feature statistics, and ii) an explainability-driven LoRA merging technique based on SHAP analysis of existing update parameter patterns. Without any architectural overhead, LIVAR achieves state-of-the-art performance on multiple benchmarks while maintaining seamless integration with existing FL methods. This work demonstrates that effective model merging can be achieved solely through existing training signals, establishing a new paradigm for efficient federated model aggregation. The code is available at https://github.com/aimagelab/fed-mammoth.",
      "tldr_zh": "该研究提出了LIVAR (Layer Importance and VARiance-based merging)，这是一种为联邦学习 (Federated Learning) 设计的新型聚合方法，旨在利用模型训练过程中产生的内在信号，而无需修改模型架构或损失函数。LIVAR 引入了一种基于方差权重的分类器聚合方案，利用训练中自然出现的特征统计数据来优化分类头。同时，该框架采用了一种受可解释性驱动的 LoRA 合并技术，通过对参数更新模式进行 SHAP 分析来实现更有效的骨干网络参数集成。实验结果表明，在不增加架构开销的前提下，LIVAR 在多个基准测试中达到了 SOTA 性能，并能与现有的联邦学习方法无缝衔接。该工作证明了仅通过现有的训练信号即可实现高效的模型合并，为高效的联邦模型聚合建立了一种全新的范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06813v2",
      "published_date": "2025-07-09 13:03:23 UTC",
      "updated_date": "2025-09-15 10:32:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:47.224381+00:00"
    },
    {
      "arxiv_id": "2507.06812v2",
      "title": "Democratizing High-Fidelity Co-Speech Gesture Video Generation",
      "title_zh": "推动高保真伴随语音手势视频生成的普及",
      "authors": [
        "Xu Yang",
        "Shaoli Huang",
        "Shenbo Xie",
        "Xuelin Chen",
        "Yifei Liu",
        "Changxing Ding"
      ],
      "abstract": "Co-speech gesture video generation aims to synthesize realistic, audio-aligned videos of speakers, complete with synchronized facial expressions and body gestures. This task presents challenges due to the significant one-to-many mapping between audio and visual content, further complicated by the scarcity of large-scale public datasets and high computational demands. We propose a lightweight framework that utilizes 2D full-body skeletons as an efficient auxiliary condition to bridge audio signals with visual outputs. Our approach introduces a diffusion model conditioned on fine-grained audio segments and a skeleton extracted from the speaker's reference image, predicting skeletal motions through skeleton-audio feature fusion to ensure strict audio coordination and body shape consistency. The generated skeletons are then fed into an off-the-shelf human video generation model with the speaker's reference image to synthesize high-fidelity videos. To democratize research, we present CSG-405-the first public dataset with 405 hours of high-resolution videos across 71 speech types, annotated with 2D skeletons and diverse speaker demographics. Experiments show that our method exceeds state-of-the-art approaches in visual quality and synchronization while generalizing across speakers and contexts. Code, models, and CSG-405 are publicly released at https://mpi-lab.github.io/Democratizing-CSG/",
      "tldr_zh": "该研究针对协同语音手势视频生成(Co-speech gesture video generation)中音频与视觉映射复杂及大规模数据集匮乏的问题，提出了一个轻量级框架。该框架利用2D全身骨架(2D full-body skeletons)作为高效的辅助条件，将音频信号与视觉输出有效连接。核心采用基于扩散模型(diffusion model)的方法，通过融合细粒度音频片段与参考图像的骨架特征来预测运动，确保了严格的音频协调性和体型一致性。生成的骨架随后被输入现成的视频生成模型，以合成高保真视频。此外，研究推出了首个包含405小时高分辨率视频的公开数据集CSG-405，涵盖71种演讲类型。实验证明，该方法在视觉质量和同步性方面均超越了现有最先进(SOTA)方法，并具有良好的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06812v2",
      "published_date": "2025-07-09 13:02:12 UTC",
      "updated_date": "2025-07-14 04:35:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:54.981461+00:00"
    },
    {
      "arxiv_id": "2507.06803v2",
      "title": "Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams",
      "title_zh": "Text to model via SysML：基于增强型系统建模语言图表的非结构化自然语言文本动力系统计算模型自动生成",
      "authors": [
        "Matthew Anderson Hendricks",
        "Alice Cicirello"
      ],
      "abstract": "This paper contributes to speeding up the design and deployment of engineering dynamical systems by proposing a strategy for exploiting domain and expert knowledge for the automated generation of dynamical system computational model starting from a corpus of document relevant to the dynamical system of interest and an input document describing the specific system. This strategy is implemented in five steps and, crucially, it uses system modeling language diagrams (SysML) to extract accurate information about the dependencies, attributes, and operations of components. Natural Language Processing (NLP) strategies and Large Language Models (LLMs) are employed in specific tasks to improve intermediate outputs of the SySML diagrams automated generation, such as: list of key nouns; list of extracted relationships; list of key phrases and key relationships; block attribute values; block relationships; and BDD diagram generation. The applicability of automated SysML diagram generation is illustrated with different case studies. The computational models of complex dynamical systems from SysML diagrams are then obtained via code generation and computational model generation steps. In the code generation step, NLP strategies are used for summarization, while LLMs are used for validation only. The proposed approach is not limited to a specific system, domain, or computational software. The applicability of the proposed approach is shown via an end-to-end example from text to model of a simple pendulum, showing improved performance compared to results yielded by LLMs only.",
      "tldr_zh": "该研究提出了一种从非结构化自然语言文本自动生成动力系统计算模型的策略，旨在通过利用领域专家知识加速工程动力系统的设计与部署。该方案通过五个步骤实现，核心在于利用系统建模语言(SysML)图表精确提取组件的依赖关系、属性及操作信息。研究结合了自然语言处理(NLP)技术和大型语言模型(LLMs)来优化SysML图表的自动化生成，包括提取关键名词、识别关系以及生成BDD图。最终通过代码生成和模型构建环节，将图表转化为复杂动力系统的计算模型。该方法具有跨领域的普适性，不局限于特定系统或软件。单摆系统的实验结果表明，该方法比仅使用LLMs具有更优的表现，为自动化系统建模提供了有效的技术路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "v2 - typos and imprecisions corrected",
      "pdf_url": "https://arxiv.org/pdf/2507.06803v2",
      "published_date": "2025-07-09 12:44:49 UTC",
      "updated_date": "2025-07-15 11:05:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:03.694655+00:00"
    },
    {
      "arxiv_id": "2507.06798v1",
      "title": "Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)",
      "title_zh": "比较辩证系统：信念变更中的矛盾与反例（扩展版）",
      "authors": [
        "Uri Andrews",
        "Luca San Mauro"
      ],
      "abstract": "Dialectical systems are a mathematical formalism for modeling an agent updating a knowledge base seeking consistency. Introduced in the 1970s by Roberto Magari, they were originally conceived to capture how a working mathematician or a research community refines beliefs in the pursuit of truth. Dialectical systems also serve as natural models for the belief change of an automated agent, offering a unifying, computable framework for dynamic belief management.\n  The literature distinguishes three main models of dialectical systems: (d-)dialectical systems based on revising beliefs when they are seen to be inconsistent, p-dialectical systems based on revising beliefs based on finding a counterexample, and q-dialectical systems which can do both. We answer an open problem in the literature by proving that q-dialectical systems are strictly more powerful than p-dialectical systems, which are themselves known to be strictly stronger than (d-)dialectical systems. This result highlights the complementary roles of counterexample and contradiction in automated belief revision, and thus also in the reasoning processes of mathematicians and research communities.",
      "tldr_zh": "该研究探讨了辩证系统（Dialectical systems），这是一种用于模拟智能体在寻求一致性过程中更新知识库的数学形式化方法。文献中主要区分了三种模型：基于发现矛盾而修订信念的 d-dialectical systems、基于发现反例修订的 p-dialectical systems，以及同时支持这两种修订方式的 q-dialectical systems。通过对这些模型进行深入比较，研究成功解决了一个学术界悬而未决的开放问题，证明了 q-dialectical systems 的处理能力严格强于 p-dialectical systems，而后者又强于 d-dialectical systems。这一研究结果不仅为动态信念管理提供了一个统一的可计算框架，还揭示了在自动信念修订（automated belief revision）以及数学家与研究社区的推理过程中，反例（counterexample）与矛盾（contradiction）所发挥的互补性关键作用。",
      "categories": [
        "cs.AI",
        "math.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, accepted at JELIA 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06798v1",
      "published_date": "2025-07-09 12:35:20 UTC",
      "updated_date": "2025-07-09 12:35:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:39:59.787544+00:00"
    },
    {
      "arxiv_id": "2507.06795v4",
      "title": "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining",
      "title_zh": "ixi-GEN：基于领域自适应持续预训练的高效工业级小型大语言模型",
      "authors": [
        "Seonwu Kim",
        "Yohan Na",
        "Kihun Kim",
        "Hanhee Cho",
        "Geun Lim",
        "Mintae Kim",
        "Seongik Park",
        "Ki Hyun Kim",
        "Youngsub Han",
        "Byoung-Ki Jeon"
      ],
      "abstract": "The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative despite inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been explored for domain adaptation, its utility in commercial settings remains under-examined. In this study, we validate the effectiveness of a DACP-based recipe across diverse foundation models and service domains, producing DACP-applied sLLMs (ixi-GEN). Through extensive experiments and real-world evaluations, we demonstrate that ixi-GEN models achieve substantial gains in target-domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.",
      "tldr_zh": "该研究提出了 ixi-GEN，一套旨在通过领域自适应持续预训练 (Domain Adaptive Continual Pretraining, DACP) 构建高效工业级小型大语言模型 (sLLMs) 的技术方案。针对许多企业在部署大规模模型时面临的基础设施限制，该研究在多种基础模型和服务领域验证了 DACP 策略的有效性。通过广泛的实验和真实场景评估，结果表明 ixi-GEN 模型在显著提升目标领域性能的同时，成功保留了模型的通用能力。这种方法为企业级部署提供了一种高性价比且具备可扩展性的解决方案，有效克服了 sLLMs 原有的性能局限。该研究不仅验证了 DACP 在商业环境下的实用价值，也为工业界实现高效的模型定制化提供了重要参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2025 Industry Track",
      "pdf_url": "https://arxiv.org/pdf/2507.06795v4",
      "published_date": "2025-07-09 12:30:42 UTC",
      "updated_date": "2025-10-23 06:41:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:05.188349+00:00"
    },
    {
      "arxiv_id": "2507.06782v1",
      "title": "Temporal Information Retrieval via Time-Specifier Model Merging",
      "title_zh": "基于时间限定词模型合并的时序信息检索",
      "authors": [
        "SeungYoon Han",
        "Taeho Hwang",
        "Sukmin Cho",
        "Soyeong Jeong",
        "Hoyun Song",
        "Huije Lee",
        "Jong C. Park"
      ],
      "abstract": "The rapid expansion of digital information and knowledge across structured and unstructured sources has heightened the importance of Information Retrieval (IR). While dense retrieval methods have substantially improved semantic matching for general queries, they consistently underperform on queries with explicit temporal constraints--often those containing numerical expressions and time specifiers such as ``in 2015.'' Existing approaches to Temporal Information Retrieval (TIR) improve temporal reasoning but often suffer from catastrophic forgetting, leading to reduced performance on non-temporal queries. To address this, we propose Time-Specifier Model Merging (TSM), a novel method that enhances temporal retrieval while preserving accuracy on non-temporal queries. TSM trains specialized retrievers for individual time specifiers and merges them in to a unified model, enabling precise handling of temporal constraints without compromising non-temporal retrieval. Extensive experiments on both temporal and non-temporal datasets demonstrate that TSM significantly improves performance on temporally constrained queries while maintaining strong results on non-temporal queries, consistently outperforming other baseline methods. Our code is available at https://github.com/seungyoonee/TSM .",
      "tldr_zh": "该研究针对密集检索(Dense Retrieval)方法在处理带有显式时间约束（如“in 2015”）的查询时表现不佳，以及现有时间信息检索(Temporal Information Retrieval, TIR)方法容易出现灾难性遗忘(Catastrophic Forgetting)的问题，提出了名为Time-Specifier Model Merging (TSM)的新方法。TSM通过为不同的时间限定词(Time Specifiers)训练专门的检索器，并将其合并为一个统一模型，实现了对时间约束的精确处理，同时避免了在非时间查询上的性能退化。实验结果表明，TSM在时间约束查询上的性能显著提升，并在非时间数据集上保持了强劲的表现，全面超越了现有的基准方法。该研究证明了模型合并技术在增强特定领域检索能力的同时，能够有效保留通用检索的准确性，为时间敏感型检索任务提供了一种稳健的解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06782v1",
      "published_date": "2025-07-09 12:16:11 UTC",
      "updated_date": "2025-07-09 12:16:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:03.103728+00:00"
    },
    {
      "arxiv_id": "2507.08038v1",
      "title": "AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research",
      "title_zh": "AblationBench：评估经验性人工智能研究中的消融实验自动规划",
      "authors": [
        "Talor Abramovich",
        "Gal Chechik"
      ],
      "abstract": "Autonomous agents built on language models (LMs) are showing increasing popularity in many fields, including scientific research. AI co-scientists aim to support or automate parts of the research process using these agents. A key component of empirical AI research is the design of ablation experiments. To this end, we introduce AblationBench, a benchmark suite for evaluating agents on ablation planning tasks in empirical AI research. It includes two tasks: AuthorAblation, which helps authors propose ablation experiments based on a method section and contains 83 instances, and ReviewerAblation, which helps reviewers find missing ablations in a full paper and contains 350 instances. For both tasks, we develop LM-based judges that serve as an automatic evaluation framework. Our experiments with frontier LMs show that these tasks remain challenging, with the best-performing LM system identifying only 29% of the original ablations on average. Lastly, we analyze the limitations of current LMs on these tasks, and find that chain-of-thought prompting outperforms the currently existing agent-based approach.",
      "tldr_zh": "该研究引入了AblationBench，这是一个专门用于评估AI智能体在实证AI研究中自动规划消融实验(ablation planning)能力的基准测试套件。该基准包含AuthorAblation和ReviewerAblation两项任务，分别用于辅助作者根据方法论部分提议消融方案以及辅助审稿人发现全文中缺失的实验。研究团队同步开发了基于语言模型(LM)的裁判系统作为自动评估框架，并利用前沿模型进行了基准测试。实验结果表明，这些任务对当前模型极具挑战性，表现最好的系统平均仅能识别出29%的原始消融实验。通过对模型局限性的分析，研究发现链式思维(chain-of-thought)提示技术在处理此类任务时优于现有的基于智能体(agent-based)的方法，为AI科研助手(AI co-scientists)的进一步发展提供了重要参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08038v1",
      "published_date": "2025-07-09 12:07:38 UTC",
      "updated_date": "2025-07-09 12:07:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:27.887533+00:00"
    },
    {
      "arxiv_id": "2507.07153v1",
      "title": "Aerial Maritime Vessel Detection and Identification",
      "title_zh": "空中海面舰船检测与识别",
      "authors": [
        "Antonella Barisic Kulas",
        "Frano Petric",
        "Stjepan Bogdan"
      ],
      "abstract": "Autonomous maritime surveillance and target vessel identification in environments where Global Navigation Satellite Systems (GNSS) are not available is critical for a number of applications such as search and rescue and threat detection. When the target vessel is only described by visual cues and its last known position is not available, unmanned aerial vehicles (UAVs) must rely solely on on-board vision to scan a large search area under strict computational constraints. To address this challenge, we leverage the YOLOv8 object detection model to detect all vessels in the field of view. We then apply feature matching and hue histogram distance analysis to determine whether any detected vessel corresponds to the target. When found, we localize the target using simple geometric principles. We demonstrate the proposed method in real-world experiments during the MBZIRC2023 competition, integrated into a fully autonomous system with GNSS-denied navigation. We also evaluate the impact of perspective on detection accuracy and localization precision and compare it with the oracle approach.",
      "tldr_zh": "该研究针对全球导航卫星系统(GNSS)不可用环境下的自主海事监视和目标船舶识别挑战，提出了一种专为无人机(UAV)设计的视觉处理框架。在缺乏目标最后已知位置且仅有视觉线索的情况下，该方案利用YOLOv8对象检测模型识别视野中的所有船舶，并结合特征匹配(feature matching)和色调直方图距离分析(hue histogram distance analysis)来精准判定目标身份。一旦识别成功，系统将通过几何原理实现目标的自主定位。该方法已在MBZIRC2023竞赛的真实实验中得到验证，并成功集成到具备GNSS-denied导航能力的完全自主系统中。实验进一步评估了透视视角对检测准确率和定位精度的影响，证明了该系统在严格计算约束下执行大规模海面搜索任务的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. ICUAS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07153v1",
      "published_date": "2025-07-09 11:43:02 UTC",
      "updated_date": "2025-07-09 11:43:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:23.080792+00:00"
    },
    {
      "arxiv_id": "2507.06763v1",
      "title": "FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views",
      "title_zh": "FOLC-Net：一种用于提升轴向、冠状及矢状位 MRI 疾病诊断能力的联邦优化轻量化架构",
      "authors": [
        "Saif Ur Rehman Khan",
        "Muhammad Nabeel Asim",
        "Sebastian Vollmer",
        "Andreas Dengel"
      ],
      "abstract": "The framework is designed to improve performance in the analysis of combined as well as single anatomical perspectives for MRI disease diagnosis. It specifically addresses the performance degradation observed in state-of-the-art (SOTA) models, particularly when processing axial, coronal, and sagittal anatomical planes. The paper introduces the FOLC-Net framework, which incorporates a novel federated-optimized lightweight architecture with approximately 1.217 million parameters and a storage requirement of only 0.9 MB. FOLC-Net integrates Manta-ray foraging optimization (MRFO) mechanisms for efficient model structure generation, global model cloning for scalable training, and ConvNeXt for enhanced client adaptability. The model was evaluated on combined multi-view data as well as individual views, such as axial, coronal, and sagittal, to assess its robustness in various medical imaging scenarios. Moreover, FOLC-Net tests a ShallowFed model on different data to evaluate its ability to generalize beyond the training dataset. The results show that FOLC-Net outperforms existing models, particularly in the challenging sagittal view. For instance, FOLC-Net achieved an accuracy of 92.44% on the sagittal view, significantly higher than the 88.37% accuracy of study method (DL + Residual Learning) and 88.95% of DL models. Additionally, FOLC-Net demonstrated improved accuracy across all individual views, providing a more reliable and robust solution for medical image analysis in decentralized environments. FOLC-Net addresses the limitations of existing SOTA models by providing a framework that ensures better adaptability to individual views while maintaining strong performance in multi-view settings. The incorporation of MRFO, global model cloning, and ConvNeXt ensures that FOLC-Net performs better in real-world medical applications.",
      "tldr_zh": "该研究提出了FOLC-Net，这是一种联邦优化的轻量级架构，旨在提升MRI图像在轴向(Axial)、冠状(Coronal)和矢状(Sagittal)视图下的疾病诊断性能。FOLC-Net针对现有SOTA模型在处理不同解剖平面时出现的性能退化问题，设计了仅包含约121.7万个参数且存储占用仅为0.9 MB的超轻量化模型。该框架集成了蝠鲼优化算法(MRFO)用于高效结构生成，并结合全局模型克隆技术和ConvNeXt网络，显著增强了客户端的适应性与训练扩展性。实验结果表明，FOLC-Net在多种视图测试中均优于现有模型，特别是在最具挑战性的矢状视图上达到了92.44%的准确率。此外，通过ShallowFed测试验证了该模型卓越的泛化能力，为去中心化环境下的临床医疗图像分析提供了一种兼顾轻量化、鲁棒性与高精度的可靠解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06763v1",
      "published_date": "2025-07-09 11:40:41 UTC",
      "updated_date": "2025-07-09 11:40:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:26.517933+00:00"
    },
    {
      "arxiv_id": "2507.08037v1",
      "title": "CRISP: Complex Reasoning with Interpretable Step-based Plans",
      "title_zh": "CRISP：基于可解释分步计划的复杂推理",
      "authors": [
        "Matan Vetzler",
        "Koren Lazar",
        "Guy Uziel",
        "Eran Hirsch",
        "Ateret Anaby-Tavor",
        "Leshem Choshen"
      ],
      "abstract": "Recent advancements in large language models (LLMs) underscore the need for stronger reasoning capabilities to solve complex problems effectively. While Chain-of-Thought (CoT) reasoning has been a step forward, it remains insufficient for many domains. A promising alternative is explicit high-level plan generation, but existing approaches largely assume that LLMs can produce effective plans through few-shot prompting alone, without additional training. In this work, we challenge this assumption and introduce CRISP (Complex Reasoning with Interpretable Step-based Plans), a multi-domain dataset of high-level plans for mathematical reasoning and code generation. The plans in CRISP are automatically generated and rigorously validated--both intrinsically, using an LLM as a judge, and extrinsically, by evaluating their impact on downstream task performance. We demonstrate that fine-tuning a small model on CRISP enables it to generate higher-quality plans than much larger models using few-shot prompting, while significantly outperforming Chain-of-Thought reasoning. Furthermore, our out-of-domain evaluation reveals that fine-tuning on one domain improves plan generation in the other, highlighting the generalizability of learned planning capabilities.",
      "tldr_zh": "该研究针对大语言模型（LLMs）在复杂问题解决中推理能力不足的问题，提出了CRISP（Complex Reasoning with Interpretable Step-based Plans）。CRISP是一个涵盖数学推理和代码生成的多领域高层计划数据集，其生成的计划经过了内在（使用LLM作为评审）和外在（评估对下游任务性能的影响）的双重严格验证。实验结果证明，在CRISP上进行微调的小型模型能够生成比采用few-shot提示的大型模型质量更高的计划，且在性能上显著优于Chain-of-Thought（CoT）推理。此外，跨领域评估显示在一个领域上的微调能显著提升另一领域的计划生成能力，证明了所学规划能力具有良好的泛化性(generalizability)。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08037v1",
      "published_date": "2025-07-09 11:40:24 UTC",
      "updated_date": "2025-07-09 11:40:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:36.526057+00:00"
    },
    {
      "arxiv_id": "2507.06753v1",
      "title": "KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution",
      "title_zh": "KAConvText：基于柯尔莫哥洛夫-阿诺德卷积的缅甸语句子分类新方法",
      "authors": [
        "Ye Kyaw Thu",
        "Thura Aung",
        "Thazin Myint Oo",
        "Thepchai Supnithi"
      ],
      "abstract": "This paper presents the first application of Kolmogorov-Arnold Convolution for Text (KAConvText) in sentence classification, addressing three tasks: imbalanced binary hate speech detection, balanced multiclass news classification, and imbalanced multiclass ethnic language identification. We investigate various embedding configurations, comparing random to fastText embeddings in both static and fine-tuned settings, with embedding dimensions of 100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs and CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we investigated KAConvText with different classification heads - MLP and KAN, where using KAN head supports enhanced interpretability. Results show that KAConvText-MLP with fine-tuned fastText embeddings achieves the best performance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection, 92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82% accuracy (F1-score = 0.9982) for language identification.",
      "tldr_zh": "该研究首次将Kolmogorov-Arnold Convolution应用于文本领域，提出了KAConvText框架以解决缅甸语（Burmese）的句子分类问题。研究涵盖了仇恨言论检测（hate speech detection）、新闻分类（news classification）以及少数民族语言识别（ethnic language identification）三项任务。作者系统探讨了随机嵌入与fastText嵌入在不同配置下的表现，并对比了标准CNN与CNN-KAN等基准模型。此外，通过研究MLP与KAN两种不同的分类头，该框架在保持高性能的同时增强了模型的可解释性（interpretability）。实验结果表明，采用微调fastText嵌入的KAConvText-MLP模型在仇恨言论检测和新闻分类中表现最佳，并在语言识别任务中达到了99.82%的极高准确率。该研究为低资源语言的复杂句子分类任务提供了一种基于Kolmogorov-Arnold网络的新颖有效方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.06753v1",
      "published_date": "2025-07-09 11:25:35 UTC",
      "updated_date": "2025-07-09 11:25:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:30.788407+00:00"
    },
    {
      "arxiv_id": "2507.07151v1",
      "title": "Robust Multimodal Large Language Models Against Modality Conflict",
      "title_zh": "针对模态冲突的鲁棒多模态大语言模型",
      "authors": [
        "Zongmeng Zhang",
        "Wengang Zhou",
        "Jie Zhao",
        "Houqiang Li"
      ],
      "abstract": "Despite the impressive capabilities of multimodal large language models (MLLMs) in vision-language tasks, they are prone to hallucinations in real-world scenarios. This paper investigates the hallucination phenomenon in MLLMs from the perspective of modality conflict. Unlike existing works focusing on the conflicts between model responses and inputs, we study the inherent conflicts in inputs from different modalities that place MLLMs in a dilemma and directly lead to hallucinations. We formally define the modality conflict and construct a dataset named Multimodal Modality Conflict (MMMC) to simulate this phenomenon in vision-language tasks. Three methods based on prompt engineering, supervised fine-tuning, and reinforcement learning are proposed to alleviate the hallucination caused by modality conflict. Extensive experiments are conducted on the MMMC dataset to analyze the merits and demerits of these methods. Our results show that the reinforcement learning method achieves the best performance in mitigating the hallucination under modality conflict, while the supervised fine-tuning method shows promising and stable performance. Our work sheds light on the unnoticed modality conflict that leads to hallucinations and provides more insights into the robustness of MLLMs.",
      "tldr_zh": "该研究从模态冲突(Modality Conflict)的视角探讨了多模态大语言模型(MLLMs)在现实场景中产生幻觉(Hallucinations)的问题。不同于以往关注模型响应与输入之间冲突的研究，本文重点研究不同模态输入之间的内在冲突，并正式定义了模态冲突。研究者为此构建了名为Multimodal Modality Conflict (MMMC)的数据集，旨在视觉-语言任务中模拟此类现象。为了缓解由模态冲突引起的幻觉，论文提出了基于提示工程(Prompt Engineering)、监督微调(Supervised Fine-Tuning, SFT)和强化学习(Reinforcement Learning, RL)的三种改进方法。实验分析表明，强化学习方法在减轻模态冲突下的幻觉方面表现最优，而监督微调方法则展现出稳定且具有潜力的性能。这项工作揭示了以往被忽视的模态冲突对模型鲁棒性的影响，为提升MLLMs的可靠性提供了新的见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07151v1",
      "published_date": "2025-07-09 11:18:38 UTC",
      "updated_date": "2025-07-09 11:18:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:35.911334+00:00"
    },
    {
      "arxiv_id": "2507.06738v1",
      "title": "DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement",
      "title_zh": "DIFFUMA：基于双路径 Mamba 与扩散增强的高保真时空视频预测",
      "authors": [
        "Xinyu Xie",
        "Weifeng Cao",
        "Jun Shi",
        "Yangyang Hu",
        "Hui Liang",
        "Wanyong Liang",
        "Xiaoliang Qian"
      ],
      "abstract": "Spatio-temporal video prediction plays a pivotal role in critical domains, ranging from weather forecasting to industrial automation. However, in high-precision industrial scenarios such as semiconductor manufacturing, the absence of specialized benchmark datasets severely hampers research on modeling and predicting complex processes. To address this challenge, we make a twofold contribution.First, we construct and release the Chip Dicing Lane Dataset (CHDL), the first public temporal image dataset dedicated to the semiconductor wafer dicing process. Captured via an industrial-grade vision system, CHDL provides a much-needed and challenging benchmark for high-fidelity process modeling, defect detection, and digital twin development.Second, we propose DIFFUMA, an innovative dual-path prediction architecture specifically designed for such fine-grained dynamics. The model captures global long-range temporal context through a parallel Mamba module, while simultaneously leveraging a diffusion module, guided by temporal features, to restore and enhance fine-grained spatial details, effectively combating feature degradation. Experiments demonstrate that on our CHDL benchmark, DIFFUMA significantly outperforms existing methods, reducing the Mean Squared Error (MSE) by 39% and improving the Structural Similarity (SSIM) from 0.926 to a near-perfect 0.988. This superior performance also generalizes to natural phenomena datasets. Our work not only delivers a new state-of-the-art (SOTA) model but, more importantly, provides the community with an invaluable data resource to drive future research in industrial AI.",
      "tldr_zh": "该研究针对半导体制造等高精度工业场景中缺乏专用基准数据集，导致复杂过程建模与预测受阻的问题，发布了首个专注于半导体晶圆切割过程的公开时序图像数据集Chip Dicing Lane Dataset (CHDL)。为了实现高保真度的过程建模，作者提出了名为DIFFUMA的创新双路径预测架构，该架构结合了用于捕捉全局长程时间上下文的并行Mamba模块，以及受时间特征引导、用于恢复细粒度空间细节的diffusion模块，有效解决了特征退化问题。实验证明，DIFFUMA在CHDL基准测试中表现卓越，将均方误差(MSE)降低了39%，并将结构相似性(SSIM)从0.926提升至接近完美的0.988。该模型不仅在工业场景中达到了SOTA水平，在自然现象数据集上也展现了极强的泛化能力。这项工作通过提供先进的模型方案与宝贵的数据资源，为工业人工智能领域的未来研究奠定了重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06738v1",
      "published_date": "2025-07-09 10:51:54 UTC",
      "updated_date": "2025-07-09 10:51:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:42.088532+00:00"
    },
    {
      "arxiv_id": "2507.06734v1",
      "title": "Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool",
      "title_zh": "公民社会在环：开源 Telegram 监控工具中 (L)LM 辅助分类的反馈驱动自适应",
      "authors": [
        "Milena Pustet",
        "Elisabeth Steffen",
        "Helena Mihaljević",
        "Grischa Stanjek",
        "Yannis Illies"
      ],
      "abstract": "The role of civil society organizations (CSOs) in monitoring harmful online content is increasingly crucial, especially as platform providers reduce their investment in content moderation. AI tools can assist in detecting and monitoring harmful content at scale. However, few open-source tools offer seamless integration of AI models and social media monitoring infrastructures. Given their thematic expertise and contextual understanding of harmful content, CSOs should be active partners in co-developing technological tools, providing feedback, helping to improve models, and ensuring alignment with stakeholder needs and values, rather than as passive 'consumers'. However, collaborations between the open source community, academia, and civil society remain rare, and research on harmful content seldom translates into practical tools usable by civil society actors. This work in progress explores how CSOs can be meaningfully involved in an AI-assisted open-source monitoring tool of anti-democratic movements on Telegram, which we are currently developing in collaboration with CSO stakeholders.",
      "tldr_zh": "该研究探讨了公民社会组织 (CSOs) 在监测有害在线内容中的关键作用，旨在解决当前开源工具中 AI 模型与社交媒体监测基础设施集成度不足的问题。研究强调 CSOs 应作为积极合作伙伴参与技术工具的共同开发，而非仅仅作为被动消费者，从而发挥其在有害内容背景理解方面的专业优势。作者正在开发一款监测 Telegram 上反民主运动的开源工具，通过集成 (L)LM 辅助分类功能，实现反馈驱动的模型适配。该项目的核心在于将“公民社会在环” (Civil Society in the Loop) 理念引入开发流程，利用 CSOs 的反馈不断改进模型，并确保技术手段与利益相关者的需求及价值观保持一致。这一正在进行的工作旨在弥合学术研究与实际应用之间的鸿沟，为开源社区与公民社会协作开发实用监测工具提供了重要参考。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06734v1",
      "published_date": "2025-07-09 10:46:58 UTC",
      "updated_date": "2025-07-09 10:46:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:40.550335+00:00"
    },
    {
      "arxiv_id": "2507.08858v1",
      "title": "Foundation models for time series forecasting: Application in conformal prediction",
      "title_zh": "时间序列预测基础模型：在符合性预测中的应用",
      "authors": [
        "Sami Achour",
        "Yassine Bouher",
        "Duong Nguyen",
        "Nicolas Chesneau"
      ],
      "abstract": "The zero-shot capabilities of foundation models (FMs) for time series forecasting offer promising potentials in conformal prediction, as most of the available data can be allocated to calibration. This study compares the performance of Time Series Foundation Models (TSFMs) with traditional methods, including statistical models and gradient boosting, within a conformal prediction setting. Our findings highlight two key advantages of TSFMs. First, when the volume of data is limited, TSFMs provide more reliable conformalized prediction intervals than classic models, thanks to their superior predictive accuracy. Second, the calibration process is more stable because more data are used for calibration. Morever, the fewer data available, the more pronounced these benefits become, as classic models require a substantial amount of data for effective training. These results underscore the potential of foundation models in improving conformal prediction reliability in time series applications, particularly in data-constrained cases. All the code to reproduce the experiments is available.",
      "tldr_zh": "该研究探讨了时间序列预测的基础模型(Foundation Models, TSFMs)在符合性预测(Conformal Prediction)中的应用，并将其与传统统计模型及梯度提升(Gradient Boosting)方法进行了对比。研究发现，TSFMs凭借优秀的零样本(Zero-shot)预测能力，在数据量有限的情况下能提供比传统模型更可靠的符合性预测区间。由于TSFMs能够将绝大部分可用数据分配给校准(Calibration)环节，这不仅提升了预测的准确度，还显著增强了校准过程的稳定性。实验结果证明，在数据受限的场景下，TSFMs的优势尤为突出，有效解决了传统模型对海量训练数据的依赖。该工作强调了基础模型在提高时间序列应用可靠性方面的潜力，并公开了用于复现实验的全部代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08858v1",
      "published_date": "2025-07-09 10:41:54 UTC",
      "updated_date": "2025-07-09 10:41:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:53.831877+00:00"
    },
    {
      "arxiv_id": "2507.06715v1",
      "title": "CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs",
      "title_zh": "CLI-RAG：基于大语言模型的临床结构化与上下文感知文本生成检索增强框架",
      "authors": [
        "Garapati Keerthana",
        "Manik Gupta"
      ],
      "abstract": "Large language models (LLMs), including zero-shot and few-shot paradigms, have shown promising capabilities in clinical text generation. However, real-world applications face two key challenges: (1) patient data is highly unstructured, heterogeneous, and scattered across multiple note types and (2) clinical notes are often long and semantically dense, making naive prompting infeasible due to context length constraints and the risk of omitting clinically relevant information.\n  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a domain-specific framework for structured and clinically grounded text generation using LLMs. It incorporates a novel hierarchical chunking strategy that respects clinical document structure and introduces a task-specific dual-stage retrieval mechanism. The global stage identifies relevant note types using evidence-based queries, while the local stage extracts high-value content within those notes creating relevance at both document and section levels.\n  We apply the system to generate structured progress notes for individual hospital visits using 15 clinical note types from the MIMIC-III dataset. Experiments show that it preserves temporal and semantic alignment across visits, achieving an average alignment score of 87.7%, surpassing the 80.7% baseline from real clinician-authored notes. The generated outputs also demonstrate high consistency across LLMs, reinforcing deterministic behavior essential for reproducibility, reliability, and clinical trust.",
      "tldr_zh": "该研究提出了CLI-RAG (Clinically Informed Retrieval-Augmented Generation)，这是一个专为临床结构化和上下文感知文本生成设计的领域专用框架，旨在解决临床数据高度非结构化和冗长导致的 LLMs 提示困难。该框架引入了创新的层次化分块策略(hierarchical chunking strategy)以尊重文档结构，并结合双阶段检索机制，在全局阶段(global stage)识别记录类型、在局部阶段(local stage)提取关键章节内容。通过在 MIMIC-III 数据集上的实验，CLI-RAG 能够生成高度对齐的结构化病程记录，其平均对齐评分达到87.7%，显著超过了临床医生人工记录的80.7%基准。此外，该系统在生成过程中表现出极高的确定性和一致性，有效提升了临床应用中的可重复性和医疗信任度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.06715v1",
      "published_date": "2025-07-09 10:13:38 UTC",
      "updated_date": "2025-07-09 10:13:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:40:48.900552+00:00"
    },
    {
      "arxiv_id": "2507.06684v1",
      "title": "Photometric Stereo using Gaussian Splatting and inverse rendering",
      "title_zh": "基于高斯泼溅与逆向渲染的光度立体视觉",
      "authors": [
        "Matéo Ducastel",
        "David Tschumperlé",
        "Yvain Quéau"
      ],
      "abstract": "Recent state-of-the-art algorithms in photometric stereo rely on neural networks and operate either through prior learning or inverse rendering optimization. Here, we revisit the problem of calibrated photometric stereo by leveraging recent advances in 3D inverse rendering using the Gaussian Splatting formalism. This allows us to parameterize the 3D scene to be reconstructed and optimize it in a more interpretable manner. Our approach incorporates a simplified model for light representation and demonstrates the potential of the Gaussian Splatting rendering engine for the photometric stereo problem.",
      "tldr_zh": "该研究利用 Gaussian Splatting 技术重新审视了校准的 Photometric Stereo 问题，旨在通过 3D Inverse Rendering 提升场景重建的精度与可解释性。与目前依赖 Prior Learning 或神经网络优化的主流算法不同，该方案利用 Gaussian Splatting 对 3D 场景进行参数化，使得优化过程更加直观且易于处理。文中引入了一个简化的 Light Representation 模型，并充分展示了 Gaussian Splatting 渲染引擎在处理光度立体视觉任务中的巨大潜力。实验结果验证了该方法在 3D 场景参数化与逆向优化方面的有效性，为高精度的物理感知重建提供了新的技术路径。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "in French language. GRETSI 2025, Association GRETSI, Aug 2025, Strasbourg, France",
      "pdf_url": "https://arxiv.org/pdf/2507.06684v1",
      "published_date": "2025-07-09 09:22:24 UTC",
      "updated_date": "2025-07-09 09:22:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:14.092364+00:00"
    },
    {
      "arxiv_id": "2507.07150v2",
      "title": "Class conditional conformal prediction for multiple inputs by p-value aggregation",
      "title_zh": "基于p值聚合的多输入类条件符合预测",
      "authors": [
        "Jean-Baptiste Fermanian",
        "Mohamed Hebiri",
        "Joseph Salmon"
      ],
      "abstract": "Conformal prediction methods are statistical tools designed to quantify uncertainty and generate predictive sets with guaranteed coverage probabilities. This work introduces an innovative refinement to these methods for classification tasks, specifically tailored for scenarios where multiple observations (multi-inputs) of a single instance are available at prediction time. Our approach is particularly motivated by applications in citizen science, where multiple images of the same plant or animal are captured by individuals. Our method integrates the information from each observation into conformal prediction, enabling a reduction in the size of the predicted label set while preserving the required class-conditional coverage guarantee. The approach is based on the aggregation of conformal p-values computed from each observation of a multi-input. By exploiting the exact distribution of these p-values, we propose a general aggregation framework using an abstract scoring function, encompassing many classical statistical tools. Knowledge of this distribution also enables refined versions of standard strategies, such as majority voting. We evaluate our method on simulated and real data, with a particular focus on Pl@ntNet, a prominent citizen science platform that facilitates the collection and identification of plant species through user-submitted images.",
      "tldr_zh": "该研究针对分类任务中单一样例对应多个观测值（multi-inputs）的场景，提出了一种改进的 Conformal Prediction 方法。受公民科学（citizen science）中同一生物多张图像识别需求的启发，该方法通过聚合各观测值计算出的 conformal p-values 来整合信息。研究利用 p-values 的精确分布构建了一个基于抽象评分函数的通用聚合框架，并在此基础上优化了多数投票（majority voting）等标准策略。该方法在确保类别条件覆盖率（class-conditional coverage guarantee）的同时，显著缩小了预测标签集的大小，从而提升了预测的精确度。通过在模拟数据和 Pl@ntNet 真实数据集上的评估，证明了该方法在处理多输入不确定性量化方面的优越性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.07150v2",
      "published_date": "2025-07-09 09:17:17 UTC",
      "updated_date": "2025-12-03 10:26:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:10.025053+00:00"
    },
    {
      "arxiv_id": "2507.06674v1",
      "title": "Exploring State-Space-Model based Language Model in Music Generation",
      "title_zh": "探索基于状态空间模型的语言模型在音乐生成中的应用",
      "authors": [
        "Wei-Jaw Lee",
        "Fang-Chih Hsieh",
        "Xuanjun Chen",
        "Fang-Duo Tsai",
        "Yi-Hsuan Yang"
      ],
      "abstract": "The recent surge in State Space Models (SSMs), particularly the emergence of Mamba, has established them as strong alternatives or complementary modules to Transformers across diverse domains. In this work, we aim to explore the potential of Mamba-based architectures for text-to-music generation. We adopt discrete tokens of Residual Vector Quantization (RVQ) as the modeling representation and empirically find that a single-layer codebook can capture semantic information in music. Motivated by this observation, we focus on modeling a single-codebook representation and adapt SiMBA, originally designed as a Mamba-based encoder, to function as a decoder for sequence modeling. We compare its performance against a standard Transformer-based decoder. Our results suggest that, under limited-resource settings, SiMBA achieves much faster convergence and generates outputs closer to the ground truth. This demonstrates the promise of SSMs for efficient and expressive text-to-music generation. We put audio examples on Github.",
      "tldr_zh": "该研究探讨了基于状态空间模型(State Space Models, SSMs)，特别是Mamba架构，在文本生成音乐(text-to-music generation)领域的应用潜力。作者采用残差矢量量化(Residual Vector Quantization, RVQ)的离散标记作为建模表示，并发现单层码本(single-layer codebook)即可捕捉音乐中的语义信息。基于这一发现，研究人员将原本作为编码器设计的SiMBA架构适配为用于序列建模的解码器，并将其性能与传统的Transformer解码器进行了对比。实验结果表明，在有限资源设置下，SiMBA实现了更快的收敛速度(faster convergence)，且生成的音频输出更接近真实值(ground truth)。该工作证明了SSMs在实现高效且富有表现力的音乐生成方面的优势，为该领域的模型架构提供了新的研究方向。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at ISMIR 2025 as Late-Breaking Demo (LBD)",
      "pdf_url": "https://arxiv.org/pdf/2507.06674v1",
      "published_date": "2025-07-09 09:05:18 UTC",
      "updated_date": "2025-07-09 09:05:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:12.564399+00:00"
    },
    {
      "arxiv_id": "2507.06658v1",
      "title": "Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models",
      "title_zh": "欧洲议会演说中的精英极化：一种基于大语言模型的新型测量方法",
      "authors": [
        "Gennadii Iakovlev"
      ],
      "abstract": "This project introduces a new measure of elite polarization via actor and subject detection using artificial intelligence. I identify when politicians mention one another in parliamentary speeches, note who is speaking and who is being addressed, and assess the emotional temperature behind these evaluations. This maps how elites evaluate their various out-parties, allowing us to create an index of mutual out-party hostility, that is, elite polarization. While I analyzed polarization data over the past four decades for the UK, and two decades for Hungary and Italy, my approach lays the groundwork for a twenty-year, EU-wide time-series dataset on elite polarization. I obtain the results that can be aggregated by party and quarter. The resulting index demonstrates a good face validity: it reacts to events such as electoral campaigns, country- and party-level crises, and to parties losing and assuming power.",
      "tldr_zh": "该研究利用 Large Language Models 提出了一种通过人工智能检测参与者与主体的精英极化 (Elite Polarization) 衡量新方法。通过识别议会发言中政治家之间的相互提及并评估其情感温度 (Emotional Temperature)，该研究构建了反映政党间相互敌对程度的极化指数。作者分析了英国过去四十年以及匈牙利和意大利近二十年的极化趋势，为建立覆盖全欧盟的时间序列数据集奠定了基础。研究结果显示，该指数具有良好的表面效度 (Face Validity)，能够有效捕捉选举活动、政治危机及政权更迭等重大事件的影响。该方法能够按政党和季度汇总数据，为量化研究精英层面的政治对立提供了精确且高效的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06658v1",
      "published_date": "2025-07-09 08:44:29 UTC",
      "updated_date": "2025-07-09 08:44:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:16.688006+00:00"
    },
    {
      "arxiv_id": "2507.06654v1",
      "title": "MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval",
      "title_zh": "MS-DPPs：面向文本-图像检索中复合属性语境多样性优化的多源行列式点过程",
      "authors": [
        "Naoya Sogi",
        "Takashi Shibata",
        "Makoto Terao",
        "Masanori Suganuma",
        "Takayuki Okatani"
      ],
      "abstract": "Result diversification (RD) is a crucial technique in Text-to-Image Retrieval for enhancing the efficiency of a practical application. Conventional methods focus solely on increasing the diversity metric of image appearances. However, the diversity metric and its desired value vary depending on the application, which limits the applications of RD. This paper proposes a novel task called CDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims to refine the diversities of multiple attributes, according to the application's context. To address this task, we propose Multi-Source DPPs, a simple yet strong baseline that extends the Determinantal Point Process (DPP) to multi-sources. We model MS-DPP as a single DPP model with a unified similarity matrix based on a manifold representation. We also introduce Tangent Normalization to reflect contexts. Extensive experiments demonstrate the effectiveness of the proposed method. Our code is publicly available at https://github.com/NEC-N-SOGI/msdpp.",
      "tldr_zh": "该研究针对文本到图像检索(Text-to-Image Retrieval)中的结果多样化(Result Diversification)技术进行了改进，指出传统方法仅侧重于图像外观多样性而限制了其应用范围。为此，论文提出了一项名为复合属性上下文多样性细化(Contextual Diversity Refinement of Composite Attributes, CDR-CA)的新任务，旨在根据应用上下文优化多个属性的多样性。为了应对这一挑战，作者提出了多源行列式点过程(Multi-Source Determinantal Point Processes, MS-DPPs)，通过基于流形表示(manifold representation)的统一相似度矩阵将行列式点过程(DPP)扩展至多源场景。此外，研究还引入了正切归一化(Tangent Normalization)以更准确地反映上下文特征。实验结果验证了MS-DPPs在处理复杂属性多样性方面的有效性，目前相关代码已在GitHub开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "IJCAI 2025. Code: https://github.com/NEC-N-SOGI/msdpp",
      "pdf_url": "https://arxiv.org/pdf/2507.06654v1",
      "published_date": "2025-07-09 08:38:46 UTC",
      "updated_date": "2025-07-09 08:38:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:21.163465+00:00"
    },
    {
      "arxiv_id": "2507.06650v1",
      "title": "Deep Disentangled Representation Network for Treatment Effect Estimation",
      "title_zh": "面向因果效应估计的深度解耦表示网络",
      "authors": [
        "Hui Meng",
        "Keping Yang",
        "Xuyu Peng",
        "Bo Zheng"
      ],
      "abstract": "Estimating individual-level treatment effect from observational data is a fundamental problem in causal inference and has attracted increasing attention in the fields of education, healthcare, and public policy.In this work, we concentrate on the study of disentangled representation methods that have shown promising outcomes by decomposing observed covariates into instrumental, confounding, and adjustment factors. However, most of the previous work has primarily revolved around generative models or hard decomposition methods for covariates, which often struggle to guarantee the attainment of precisely disentangled factors. In order to effectively model different causal relationships, we propose a novel treatment effect estimation algorithm that incorporates a mixture of experts with multi-head attention and a linear orthogonal regularizer to softly decompose the pre-treatment variables, and simultaneously eliminates selection bias via importance sampling re-weighting techniques. We conduct extensive experiments on both public semi-synthetic and real-world production datasets. The experimental results clearly demonstrate that our algorithm outperforms the state-of-the-art methods focused on individual treatment effects.",
      "tldr_zh": "该研究针对因果推断中的个体治疗效应 (Individual Treatment Effect) 估计问题，提出了一种新型的深度解耦表示网络，旨在从观测数据中更精准地提取因果信息。为了克服以往研究在生成模型或硬分解 (Hard Decomposition) 方法下难以实现变量精确解耦的局限性，该算法引入了结合多头注意力机制 (Multi-Head Attention) 的混合专家模型 (Mixture of Experts)，并通过线性正交正则化项 (Linear Orthogonal Regularizer) 对预处理变量中的工具变量、混杂因素和调节因子进行软分解。此外，框架整合了重要性采样重加权 (Importance Sampling Re-weighting) 技术，以消除数据中的选择偏倚 (Selection Bias)。在公开半合成数据集与真实生产环境数据集上的广泛实验证明，该算法在个体治疗效应估计任务中显著优于现有的先进模型。这一研究成果为教育、医疗及公共政策等领域的精准干预和决策制定提供了强有力的技术保障。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2507.06650v1",
      "published_date": "2025-07-09 08:29:37 UTC",
      "updated_date": "2025-07-09 08:29:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:24.458363+00:00"
    },
    {
      "arxiv_id": "2507.21108v1",
      "title": "A Survey of Classification Tasks and Approaches for Legal Contracts",
      "title_zh": "法律合同分类任务与方法综述",
      "authors": [
        "Amrita Singh",
        "Aditya Joshi",
        "Jiaojiao Jiang",
        "Hye-young Paik"
      ],
      "abstract": "Given the large size and volumes of contracts and their underlying inherent complexity, manual reviews become inefficient and prone to errors, creating a clear need for automation. Automatic Legal Contract Classification (LCC) revolutionizes the way legal contracts are analyzed, offering substantial improvements in speed, accuracy, and accessibility. This survey delves into the challenges of automatic LCC and a detailed examination of key tasks, datasets, and methodologies. We identify seven classification tasks within LCC, and review fourteen datasets related to English-language contracts, including public, proprietary, and non-public sources. We also introduce a methodology taxonomy for LCC, categorized into Traditional Machine Learning, Deep Learning, and Transformer-based approaches. Additionally, the survey discusses evaluation techniques and highlights the best-performing results from the reviewed studies. By providing a thorough overview of current methods and their limitations, this survey suggests future research directions to improve the efficiency, accuracy, and scalability of LCC. As the first comprehensive survey on LCC, it aims to support legal NLP researchers and practitioners in improving legal processes, making legal information more accessible, and promoting a more informed and equitable society.",
      "tldr_zh": "该综述针对大规模复杂合同手动审查效率低且易出错的问题，探讨了法律合同分类(LCC)自动化的必要性与挑战。作为首个关于LCC的全面综述，文章识别了七项核心分类任务，并系统性地回顾了14个涉及英语合同的公共及私有数据集。研究者提出了一套完整的方法论分类法(Taxonomy)，涵盖了传统Machine Learning、Deep Learning以及Transformer-based方法。通过对现有研究中评估技术和最佳性能结果的详细分析，该综述揭示了当前技术的局限性并指出了未来在提升LCC效率、准确性和可扩展性方面的研究方向。该项工作旨在通过法律NLP技术的进步优化法律流程，从而使法律信息更易获取并促进社会公平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review. 49 pages + references",
      "pdf_url": "https://arxiv.org/pdf/2507.21108v1",
      "published_date": "2025-07-09 08:22:42 UTC",
      "updated_date": "2025-07-09 08:22:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:24.953909+00:00"
    },
    {
      "arxiv_id": "2507.06639v2",
      "title": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision",
      "title_zh": "EXAONE Path 2.0：基于端到端监督的病理学基础模型",
      "authors": [
        "Myeongjang Pyeon",
        "Janghyeon Lee",
        "Minsoo Lee",
        "Juseung Yun",
        "Hwanil Choi",
        "Jonghyun Kim",
        "Jiwon Kim",
        "Yi Hu",
        "Jongseong Jang",
        "Soonyoung Lee"
      ],
      "abstract": "In digital pathology, whole-slide images (WSIs) are often difficult to handle due to their gigapixel scale, so most approaches train patch encoders via self-supervised learning (SSL) and then aggregate the patch-level embeddings via multiple instance learning (MIL) or slide encoders for downstream tasks. However, patch-level SSL may overlook complex domain-specific features that are essential for biomarker prediction, such as mutation status and molecular characteristics, as SSL methods rely only on basic augmentations selected for natural image domains on small patch-level area. Moreover, SSL methods remain less data efficient than fully supervised approaches, requiring extensive computational resources and datasets to achieve competitive performance. To address these limitations, we present EXAONE Path 2.0, a pathology foundation model that learns patch-level representations under direct slide-level supervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves state-of-the-art average performance across 10 biomarker prediction tasks, demonstrating remarkable data efficiency.",
      "tldr_zh": "该研究提出了 EXAONE Path 2.0，这是一种在直接 slide-level 监督下学习 patch-level 表征的病理学基础模型，旨在解决数字病理学中全切片图像 (WSIs) 处理的难题。针对传统自监督学习 (SSL) 方法在 patch-level 上容易忽略复杂领域特定特征且数据效率低下的局限性，该模型采用了端到端的监督学习路径。通过利用 slide-level 的标签直接引导表征学习，EXAONE Path 2.0 能够更有效地捕捉突变状态和分子特性等关键生物标志物信息。实验结果显示，该模型仅需 3.7 万张 WSIs 进行训练，就在 10 项生物标志物预测任务中实现了 SOTA 的平均性能。这一成果不仅展示了极高的数据效率，也为处理大规模医学图像数据提供了更具竞争力的方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "EXAONE Path 2.0 technical report",
      "pdf_url": "https://arxiv.org/pdf/2507.06639v2",
      "published_date": "2025-07-09 08:09:05 UTC",
      "updated_date": "2025-08-14 02:00:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:30.662270+00:00"
    },
    {
      "arxiv_id": "2507.07147v1",
      "title": "Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation",
      "title_zh": "基于无描述大语言模型蒸馏的加权多提示学习",
      "authors": [
        "Sua Lee",
        "Kyubum Shin",
        "Jung Ho Park"
      ],
      "abstract": "Recent advances in pre-trained Vision Language Models (VLM) have shown promising potential for effectively adapting to downstream tasks through prompt learning, without the need for additional annotated paired datasets. To supplement the text information in VLM trained on correlations with vision data, new approaches leveraging Large Language Models (LLM) in prompts have been proposed, enhancing robustness to unseen and diverse data. Existing methods typically extract text-based responses (i.e., descriptions) from LLM to incorporate into prompts; however, this approach suffers from high variability and low reliability. In this work, we propose Description-free Multi-prompt Learning(DeMul), a novel method that eliminates the process of extracting descriptions and instead directly distills knowledge from LLM into prompts. By adopting a description-free approach, prompts can encapsulate richer semantics while still being represented as continuous vectors for optimization, thereby eliminating the need for discrete pre-defined templates. Additionally, in a multi-prompt setting, we empirically demonstrate the potential of prompt weighting in reflecting the importance of different prompts during training. Experimental results show that our approach achieves superior performance across 11 recognition datasets.",
      "tldr_zh": "该研究提出了DeMul (Description-free Multi-prompt Learning)，这是一种无需文本描述的多提示学习方法，旨在解决现有视觉语言模型(VLM)在利用大语言模型(LLM)生成描述时存在的变异性高和可靠性不足的问题。与以往提取离散描述的方法不同，DeMul直接将LLM的知识蒸馏到提示词中，使提示词能以连续向量的形式捕捉更丰富的语义，从而消除了对预定义模板的依赖。此外，该研究在多提示学习框架中引入了权重分配机制，通过实证分析展示了不同提示词在训练过程中的重要性差异。实验结果表明，DeMul在11个图像识别数据集上表现优异，显著提升了模型在下游任务中的性能。该方法有效地增强了视觉语言表征的鲁棒性，为知识蒸馏与提示学习的结合提供了新的视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.07147v1",
      "published_date": "2025-07-09 07:55:25 UTC",
      "updated_date": "2025-07-09 07:55:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:30.977742+00:00"
    },
    {
      "arxiv_id": "2507.06628v1",
      "title": "Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning",
      "title_zh": "面向离线多任务强化学习的目标导向技能抽象",
      "authors": [
        "Jinmin He",
        "Kai Li",
        "Yifan Zang",
        "Haobo Fu",
        "Qiang Fu",
        "Junliang Xing",
        "Jian Cheng"
      ],
      "abstract": "Offline multi-task reinforcement learning aims to learn a unified policy capable of solving multiple tasks using only pre-collected task-mixed datasets, without requiring any online interaction with the environment. However, it faces significant challenges in effectively sharing knowledge across tasks. Inspired by the efficient knowledge abstraction observed in human learning, we propose Goal-Oriented Skill Abstraction (GO-Skill), a novel approach designed to extract and utilize reusable skills to enhance knowledge transfer and task performance. Our approach uncovers reusable skills through a goal-oriented skill extraction process and leverages vector quantization to construct a discrete skill library. To mitigate class imbalances between broadly applicable and task-specific skills, we introduce a skill enhancement phase to refine the extracted skills. Furthermore, we integrate these skills using hierarchical policy learning, enabling the construction of a high-level policy that dynamically orchestrates discrete skills to accomplish specific tasks. Extensive experiments on diverse robotic manipulation tasks within the MetaWorld benchmark demonstrate the effectiveness and versatility of GO-Skill.",
      "tldr_zh": "该研究针对离线多任务强化学习 (Offline multi-task reinforcement learning) 在跨任务知识共享方面的挑战，提出了一种名为 GO-Skill (Goal-Oriented Skill Abstraction) 的新框架。受人类学习中高效知识抽象的启发，该方法旨在提取和利用可重用技能以增强知识迁移能力。GO-Skill 通过目标导向的技能提取过程发现可重用技能，并利用矢量量化 (Vector quantization) 技术构建了一个离散技能库。为了平衡通用技能与特定任务技能之间的差异，研究还引入了技能增强阶段来优化所提取的技能，并采用分层策略学习 (Hierarchical policy learning) 来动态编排这些技能以完成复杂任务。在 MetaWorld 基准测试的多项机器人操作任务上的实验结果表明，GO-Skill 在处理离线多任务学习时具有显著的有效性和通用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06628v1",
      "published_date": "2025-07-09 07:54:49 UTC",
      "updated_date": "2025-07-09 07:54:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:33.999763+00:00"
    },
    {
      "arxiv_id": "2507.06625v2",
      "title": "Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic",
      "title_zh": "Q-STAC：Q 引导的 Stein 变分模型预测演员-评论家",
      "authors": [
        "Shizhe Cai",
        "Zeya Yin",
        "Jayadeep Jacob",
        "Fabio Ramos"
      ],
      "abstract": "Deep reinforcement learning (DRL) often struggles with complex robotic manipulation tasks due to low sample efficiency and biased value estimation. Model-based reinforcement learning (MBRL) improves efficiency by leveraging environment dynamics, with prior work integrating Model Predictive Control (MPC) to enhance policy robustness through online trajectory optimization. However, existing MBRL approaches still suffer from high model bias, task-specific cost function design, and significant computational overhead. To address these challenges, we propose Q-guided Stein Variational Model Predictive Actor-Critic (Q-STAC)--a unified framework that bridges Bayesian MPC and Soft Actor-Critic (SAC). Q-STAC employs Stein Variational Gradient Descent (SVGD) to iteratively optimize action sequences sampled from a learned prior distribution guided by Q-values, thereby eliminating manual cost-function engineering. By performing short-horizon model-predictive rollouts, Q-STAC reduces cumulative prediction errors, improves training stability and reduces computational complexity. Experiments on simulated particle navigation, diverse robotic manipulation tasks, and a real-world fruit-picking scenario demonstrate that Q-STAC consistently achieves superior sample efficiency, stability, and overall performance compared to both model-free and model-based baselines.",
      "tldr_zh": "该研究提出了 Q-STAC（Q-Guided Stein Variational Model Predictive Actor-Critic），这是一个将贝叶斯模型预测控制 (Bayesian MPC) 与 Soft Actor-Critic (SAC) 有效结合的统一强化学习框架。该框架旨在解决深度强化学习在机器人操作中面临的样本效率低、价值估计偏差，以及传统模型预测控制对人工成本函数设计和高额计算开销的依赖问题。Q-STAC 采用 Stein Variational Gradient Descent (SVGD) 算法，在 Q 值的引导下迭代优化从学习先验分布中采样的动作序列，从而消除了复杂的成本函数工程。通过执行短时域模型预测回测 (short-horizon model-predictive rollouts)，该方法有效减少了累积预测误差并增强了训练稳定性。实验结果显示，Q-STAC 在模拟导航、多种机器人操作及真实世界采摘水果场景中，其样本效率、稳定性和综合性能均显著优于现有的 model-free 和 model-based 基准模型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.06625v2",
      "published_date": "2025-07-09 07:53:53 UTC",
      "updated_date": "2025-12-04 02:30:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:46.699966+00:00"
    },
    {
      "arxiv_id": "2507.06623v1",
      "title": "Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review",
      "title_zh": "利用大语言模型 (LLM) 与范围界定综述方案加速数据提取：一项针对复杂范围界定综述的方法学研究",
      "authors": [
        "James Stewart-Evans",
        "Emma Wilson",
        "Tessa Langley",
        "Andrew Prayle",
        "Angela Hands",
        "Karen Exley",
        "Jo Leonardi-Bee"
      ],
      "abstract": "The data extraction stages of reviews are resource-intensive, and researchers may seek to expediate data extraction using online (large language models) LLMs and review protocols. Claude 3.5 Sonnet was used to trial two approaches that used a review protocol to prompt data extraction from 10 evidence sources included in a case study scoping review. A protocol-based approach was also used to review extracted data. Limited performance evaluation was undertaken which found high accuracy for the two extraction approaches (83.3% and 100%) when extracting simple, well-defined citation details; accuracy was lower (9.6% and 15.8%) when extracting more complex, subjective data items. Considering all data items, both approaches had precision >90% but low recall (<25%) and F1 scores (<40%). The context of a complex scoping review, open response types and methodological approach likely impacted performance due to missed and misattributed data. LLM feedback considered the baseline extraction accurate and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of 38 (21.1%) to key findings data items were considered to potentially add value. However, when repeating the process with a dataset featuring deliberate errors, only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for expediency require more robust performance evaluation across a range of LLMs and review contexts with comparison to conventional prompt engineering approaches. We recommend researchers evaluate and report LLM performance if using them similarly to conduct data extraction or review extracted data. LLM feedback contributed to protocol adaptation and may assist future review protocol drafting.",
      "tldr_zh": "该研究探讨了在复杂的范围综述(scoping review)中利用大语言模型(LLM) Claude 3.5 Sonnet 结合综述方案(review protocol)来加速数据提取的方法学研究。实验评估了两种提取策略，发现在处理简单的文献引用详情时准确率极高（83.3%至100%），但在提取复杂、主观的数据项时准确率大幅下降（9.6%至15.8%）。尽管模型展现了超过90%的精确率(precision)，但由于存在大量遗漏和错误归因，其召回率(recall)和F1分数均处于较低水平。此外，模型在识别数据中的刻意错误方面表现欠佳，仅能检测出5%的错误。研究强调在类似场景下使用LLM时需进行更严谨的性能评估与结果报告，并指出LLM反馈对综述方案的修订和撰写具有辅助作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "44 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.06623v1",
      "published_date": "2025-07-09 07:50:55 UTC",
      "updated_date": "2025-07-09 07:50:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:51.194645+00:00"
    },
    {
      "arxiv_id": "2507.06615v1",
      "title": "Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance",
      "title_zh": "基于跨任务策略引导的高效多任务强化学习",
      "authors": [
        "Jinmin He",
        "Kai Li",
        "Yifan Zang",
        "Haobo Fu",
        "Qiang Fu",
        "Junliang Xing",
        "Jian Cheng"
      ],
      "abstract": "Multi-task reinforcement learning endeavors to efficiently leverage shared information across various tasks, facilitating the simultaneous learning of multiple tasks. Existing approaches primarily focus on parameter sharing with carefully designed network structures or tailored optimization procedures. However, they overlook a direct and complementary way to exploit cross-task similarities: the control policies of tasks already proficient in some skills can provide explicit guidance for unmastered tasks to accelerate skills acquisition. To this end, we present a novel framework called Cross-Task Policy Guidance (CTPG), which trains a guide policy for each task to select the behavior policy interacting with the environment from all tasks' control policies, generating better training trajectories. In addition, we propose two gating mechanisms to improve the learning efficiency of CTPG: one gate filters out control policies that are not beneficial for guidance, while the other gate blocks tasks that do not necessitate guidance. CTPG is a general framework adaptable to existing parameter sharing approaches. Empirical evaluations demonstrate that incorporating CTPG with these approaches significantly enhances performance in manipulation and locomotion benchmarks.",
      "tldr_zh": "该研究提出了Cross-Task Policy Guidance (CTPG)框架，旨在提升Multi-task reinforcement learning中跨任务信息的利用效率。针对现有方法主要侧重参数共享而忽视直接策略指导的问题，CTPG通过为每个任务训练guide policy，从所有任务的control policies中动态选择behavior policy与环境交互，从而生成更优的训练轨迹以加速技能获取。此外，该框架引入了两种gating mechanisms，分别用于过滤无益的指导策略以及识别无需指导的任务，从而进一步优化学习效率。作为一种通用框架，CTPG能够与现有的参数共享方法无缝结合。在操作与运动基准测试中的实验结果表明，引入CTPG能显著增强模型的任务学习性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS2024",
      "pdf_url": "https://arxiv.org/pdf/2507.06615v1",
      "published_date": "2025-07-09 07:36:28 UTC",
      "updated_date": "2025-07-09 07:36:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:54.909449+00:00"
    },
    {
      "arxiv_id": "2507.06613v1",
      "title": "Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation",
      "title_zh": "Denoising Multi-Beta VAE：面向解耦与生成的表示学习",
      "authors": [
        "Anshuk Uppal",
        "Yuhta Takida",
        "Chieh-Hsin Lai",
        "Yuki Mitsufuji"
      ],
      "abstract": "Disentangled and interpretable latent representations in generative models typically come at the cost of generation quality. The $β$-VAE framework introduces a hyperparameter $β$ to balance disentanglement and reconstruction quality, where setting $β> 1$ introduces an information bottleneck that favors disentanglement over sharp, accurate reconstructions. To address this trade-off, we propose a novel generative modeling framework that leverages a range of $β$ values to learn multiple corresponding latent representations. First, we obtain a slew of representations by training a single variational autoencoder (VAE), with a new loss function that controls the information retained in each latent representation such that the higher $β$ value prioritize disentanglement over reconstruction fidelity. We then, introduce a non-linear diffusion model that smoothly transitions latent representations corresponding to different $β$ values. This model denoises towards less disentangled and more informative representations, ultimately leading to (almost) lossless representations, enabling sharp reconstructions. Furthermore, our model supports sample generation without input images, functioning as a standalone generative model. We evaluate our framework in terms of both disentanglement and generation quality. Additionally, we observe smooth transitions in the latent spaces with respect to changes in $β$, facilitating consistent manipulation of generated outputs.",
      "tldr_zh": "该研究提出了 Denoising Multi-Beta VAE 框架，旨在解决 $\\beta$-VAE 中解耦表示 (Disentanglement) 与重建质量 (Reconstruction quality) 难以兼顾的权衡问题。该框架通过一种新的损失函数训练单个变分自编码器 (VAE)，从而获得一系列对应不同 $\\beta$ 值的潜在表示，确保高 $\\beta$ 值能够优先捕捉解耦特征。研究进一步引入了一种非线性扩散模型 (Non-linear diffusion model)，在不同 $\\beta$ 值的潜在表示间实现平滑转换，通过去噪过程向信息更丰富的表示演进，最终达成近乎无损的图像重建。该模型不仅在解耦和生成质量上表现优异，还支持无输入图像的独立样本生成。实验观察到潜在空间随 $\\beta$ 值变化呈现出平滑过渡，这为生成结果的连贯属性操纵提供了有效途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 8 figures and 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.06613v1",
      "published_date": "2025-07-09 07:29:41 UTC",
      "updated_date": "2025-07-09 07:29:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:56.580133+00:00"
    },
    {
      "arxiv_id": "2507.06582v1",
      "title": "Learning controllable dynamics through informative exploration",
      "title_zh": "通过信息性探索学习可控动力学",
      "authors": [
        "Peter N. Loxley",
        "Friedrich T. Sommer"
      ],
      "abstract": "Environments with controllable dynamics are usually understood in terms of explicit models. However, such models are not always available, but may sometimes be learned by exploring an environment. In this work, we investigate using an information measure called \"predicted information gain\" to determine the most informative regions of an environment to explore next. Applying methods from reinforcement learning allows good suboptimal exploring policies to be found, and leads to reliable estimates of the underlying controllable dynamics. This approach is demonstrated by comparing with several myopic exploration approaches.",
      "tldr_zh": "该研究探讨了如何通过探索环境来学习系统的可控动力学（controllable dynamics），这在缺乏显式模型的情况下具有重要意义。作者引入了一种名为“predicted information gain”的信息度量方法，用于识别环境中最具信息价值的区域，从而优化探索过程。通过结合强化学习（reinforcement learning）技术，该方法能够开发出高效的探索策略，并获得对底层动力学的可靠估计。实验结果表明，该方法在与多种近视探索方法（myopic exploration approaches）的对比中表现优异，显著提升了学习底层可控动力学的效率与准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06582v1",
      "published_date": "2025-07-09 06:20:24 UTC",
      "updated_date": "2025-07-09 06:20:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:41:57.078912+00:00"
    },
    {
      "arxiv_id": "2507.06573v1",
      "title": "From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization",
      "title_zh": "从数据中心到样本中心：通过渐进式优化提升大语言模型推理能力",
      "authors": [
        "Xinjie Chen",
        "Minpeng Liao",
        "Guoxin Chen",
        "Chengxi Li",
        "Biao Fu",
        "Kai Fan",
        "Xinggao Liu"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has recently advanced the reasoning capabilities of large language models (LLMs). While prior work has emphasized algorithmic design, data curation, and reward shaping, we investigate RLVR from a sample-centric perspective and introduce LPPO (Learning-Progress and Prefix-guided Optimization), a framework of progressive optimization techniques. Our work addresses a critical question: how to best leverage a small set of trusted, high-quality demonstrations, rather than simply scaling up data volume. First, motivated by how hints aid human problem-solving, we propose prefix-guided sampling, an online data augmentation method that incorporates partial solution prefixes from expert demonstrations to guide the policy, particularly for challenging instances. Second, inspired by how humans focus on important questions aligned with their current capabilities, we introduce learning-progress weighting, a dynamic strategy that adjusts each training sample's influence based on model progression. We estimate sample-level learning progress via an exponential moving average of per-sample pass rates, promoting samples that foster learning and de-emphasizing stagnant ones. Experiments on mathematical-reasoning benchmarks demonstrate that our methods outperform strong baselines, yielding faster convergence and a higher performance ceiling.",
      "tldr_zh": "该研究提出了 LPPO (Learning-Progress and Prefix-guided Optimization)，这是一个旨在通过样本中心 (sample-centric) 的渐进优化技术来增强大语言模型 (LLMs) 推理能力的框架。不同于单纯增加数据量的传统方法，LPPO 关注于如何高效利用少量的优质演示数据。框架引入了前缀引导采样 (prefix-guided sampling) 技术，通过在在线数据增强中结合专家演示的部分解法前缀，引导策略模型解决高难度实例。同时，研究提出了学习进度加权 (learning-progress weighting) 策略，通过每个样本通过率的指数移动平均 (exponential moving average) 来动态调整训练样本的影响力。这种方法能够优先处理那些有助于提升模型能力的样本，并降低对停滞不前样本的关注，从而实现针对模型当前状态的动态优化。在数学推理基准测试上的实验结果表明，LPPO 在收敛速度和性能上限方面均优于现有的强基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2507.06573v1",
      "published_date": "2025-07-09 06:05:28 UTC",
      "updated_date": "2025-07-09 06:05:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:02.047407+00:00"
    },
    {
      "arxiv_id": "2507.06564v1",
      "title": "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments",
      "title_zh": "SkyVLN：城市环境下无人机的视觉语言导航与非线性模型预测控制",
      "authors": [
        "Tianshun Li",
        "Tianyi Huai",
        "Zhen Li",
        "Yichun Gao",
        "Haoang Li",
        "Xinhu Zheng"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across various sectors, driven by their mobility and adaptability. This paper introduces SkyVLN, a novel framework integrating vision-and-language navigation (VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in complex urban environments. Unlike traditional navigation methods, SkyVLN leverages Large Language Models (LLMs) to interpret natural language instructions and visual observations, enabling UAVs to navigate through dynamic 3D spaces with improved accuracy and robustness. We present a multimodal navigation agent equipped with a fine-grained spatial verbalizer and a history path memory mechanism. These components allow the UAV to disambiguate spatial contexts, handle ambiguous instructions, and backtrack when necessary. The framework also incorporates an NMPC module for dynamic obstacle avoidance, ensuring precise trajectory tracking and collision prevention. To validate our approach, we developed a high-fidelity 3D urban simulation environment using AirSim, featuring realistic imagery and dynamic urban elements. Extensive experiments demonstrate that SkyVLN significantly improves navigation success rates and efficiency, particularly in new and unseen environments.",
      "tldr_zh": "该研究提出了SkyVLN，这是一种将视觉语言导航(Vision-and-Language Navigation, VLN)与非线性模型预测控制(Nonlinear Model Predictive Control, NMPC)相结合的新型框架，旨在提升无人机(UAVs)在复杂城市环境中的自主性。该框架利用大语言模型(LLMs)来解读自然语言指令和视觉观测，并配备了细粒度空间语言化器(fine-grained spatial verbalizer)和历史路径记忆机制，使其能够有效消除空间上下文歧义并实现必要的回溯。此外，SkyVLN集成了NMPC模块用于动态避障，确保了精确的轨迹跟踪和碰撞预防。通过在基于AirSim构建的高保真3D城市模拟环境中进行验证，实验证明该方法显著提高了导航成功率和效率，尤其是在全新且未见过的环境中展现出强大的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 9 figures, has been accepted by IROS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06564v1",
      "published_date": "2025-07-09 05:38:32 UTC",
      "updated_date": "2025-07-09 05:38:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:06.083760+00:00"
    },
    {
      "arxiv_id": "2507.08853v1",
      "title": "Clio-X: AWeb3 Solution for Privacy-Preserving AI Access to Digital Archives",
      "title_zh": "Clio-X：面向数字档案隐私保护 AI 访问的 Web3 解决方案",
      "authors": [
        "Victoria L. Lemieux",
        "Rosa Gil",
        "Faith Molosiwa",
        "Qihong Zhou",
        "Binming Li",
        "Roberto Garcia",
        "Luis De La Torre Cubillo",
        "Zehua Wang"
      ],
      "abstract": "As archives turn to artificial intelligence to manage growing volumes of digital records, privacy risks inherent in current AI data practices raise critical concerns about data sovereignty and ethical accountability. This paper explores how privacy-enhancing technologies (PETs) and Web3 architectures can support archives to preserve control over sensitive content while still being able to make it available for access by researchers. We present Clio-X, a decentralized, privacy-first Web3 digital solution designed to embed PETs into archival workflows and support AI-enabled reference and access. Drawing on a user evaluation of a medium-fidelity prototype, the study reveals both interest in the potential of the solution and significant barriers to adoption related to trust, system opacity, economic concerns, and governance. Using Rogers' Diffusion of Innovation theory, we analyze the sociotechnical dimensions of these barriers and propose a path forward centered on participatory design and decentralized governance through a Clio-X Decentralized Autonomous Organization. By integrating technical safeguards with community-based oversight, Clio-X offers a novel model to ethically deploy AI in cultural heritage contexts.",
      "tldr_zh": "该研究提出了Clio-X，这是一种基于Web3架构的去中心化解决方案，旨在解决人工智能(AI)在管理数字档案时面临的隐私风险、数据主权及伦理问责挑战。通过将隐私增强技术(Privacy-enhancing technologies, PETs)嵌入档案工作流，Clio-X能够在确保档案机构对敏感内容控制权的前提下，实现由AI驱动的检索与访问。基于中保真原型的用户评估揭示了该方案在促进数据访问方面的潜力，但同时也指出在信任、系统透明度、经济考量及治理架构方面存在显著的采用障碍。研究利用创新扩散理论(Diffusion of Innovation theory)深入分析了上述障碍的社会技术维度，并提出了一条以参与式设计和Clio-X去中心化自治组织(Decentralized Autonomous Organization, DAO)为核心的发展路径。通过将技术防御与社区监督相结合，Clio-X为文化遗产机构在伦理框架下部署人工智能提供了一种创新的模式。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.DL"
      ],
      "primary_category": "cs.CR",
      "comment": "28 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.08853v1",
      "published_date": "2025-07-09 05:30:38 UTC",
      "updated_date": "2025-07-09 05:30:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:17.631874+00:00"
    },
    {
      "arxiv_id": "2507.06558v2",
      "title": "The Primacy of Magnitude in Low-Rank Adaptation",
      "title_zh": "量级在低秩自适应中的首要地位",
      "authors": [
        "Zicheng Zhang",
        "Haoran Li",
        "Yifeng Zhang",
        "Guoqiang Gong",
        "Jiaxing Wang",
        "Junxing Hu",
        "Pengzhang Liu",
        "Qixia Jiang"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) offers a parameter-efficient paradigm for tuning large models. While recent spectral initialization methods improve convergence and performance over the naive \"Noise & Zeros\" scheme, their extra computational and storage overhead undermines efficiency. In this paper, we establish update magnitude as the fundamental driver of LoRA performance and propose LoRAM, a magnitude-driven \"Basis & Basis\" initialization scheme that matches spectral methods without their inefficiencies. Our key contributions are threefold: (i) Magnitude of weight updates determines convergence. We prove low-rank structures intrinsically bound update magnitudes, unifying hyperparameter tuning in learning rate, scaling factor, and initialization as mechanisms to optimize magnitude regulation. (ii) Spectral initialization succeeds via magnitude amplification. We demystify that the presumed knowledge-driven benefit of the spectral component essentially arises from the boost in the weight update magnitude. (iii) A novel and compact initialization strategy, LoRAM, scales deterministic orthogonal bases using pretrained weight magnitudes to simulate spectral gains. Extensive experiments show that LoRAM serves as a strong baseline, retaining the full efficiency of LoRA while matching or outperforming spectral initialization across benchmarks.",
      "tldr_zh": "该研究探讨了低秩自适应 (Low-Rank Adaptation, LoRA) 的性能驱动机制，确立了权重更新幅度 (update magnitude) 是决定模型收敛与性能的核心因素。作者证明了谱初始化 (spectral initialization) 之所以优于传统的“噪声与零”方案，本质上是通过幅度放大而非单纯的知识驱动实现的。为解决谱方法带来的额外计算与存储开销，研究提出了一种名为 LoRAM 的“基底与基底” (Basis & Basis) 初始化方案。该方案利用预训练权重的幅度来缩放确定性正交基，从而在保持 LoRA 原始效率的同时模拟谱增益。实验结果表明，LoRAM 在多个基准测试中均能匹配或优于谱初始化方法，为大规模模型的高效微调提供了一个强有力的基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2025, spotlight",
      "pdf_url": "https://arxiv.org/pdf/2507.06558v2",
      "published_date": "2025-07-09 05:25:24 UTC",
      "updated_date": "2025-12-25 04:02:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:08.608755+00:00"
    },
    {
      "arxiv_id": "2507.06541v1",
      "title": "Graph-based Fake Account Detection: A Survey",
      "title_zh": "基于图的虚假账号检测综述",
      "authors": [
        "Ali Safarpoor Dehkordi",
        "Ahad N. Zehmakan"
      ],
      "abstract": "In recent years, there has been a growing effort to develop effective and efficient algorithms for fake account detection in online social networks. This survey comprehensively reviews existing methods, with a focus on graph-based techniques that utilise topological features of social graphs (in addition to account information, such as their shared contents and profile data) to distinguish between fake and real accounts. We provide several categorisations of these methods (for example, based on techniques used, input data, and detection time), discuss their strengths and limitations, and explain how these methods connect in the broader context. We also investigate the available datasets, including both real-world data and synthesised models. We conclude the paper by proposing several potential avenues for future research.",
      "tldr_zh": "该综述全面回顾了在线社交网络中检测虚假账户的现有方法，重点探讨了利用社交图拓扑特征及账户资料、共享内容等信息的 Graph-based 技术。文章从技术手段、输入数据和检测时间等多个维度对现有算法进行了详细分类，并深入讨论了各方法的优缺点及其在广义背景下的相互联系。此外，研究还对包括 real-world data 和 synthesized models 在内的可用数据集进行了系统调查。最后，本文为该领域的未来研究提出了若干潜在方向，为开发更高效、精准的虚假账户检测算法提供了重要参考。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "16 Tables, 5 Figures, 41 Pages",
      "pdf_url": "https://arxiv.org/pdf/2507.06541v1",
      "published_date": "2025-07-09 04:52:15 UTC",
      "updated_date": "2025-07-09 04:52:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:11.392388+00:00"
    },
    {
      "arxiv_id": "2507.08034v1",
      "title": "Integrating External Tools with Large Language Models to Improve Accuracy",
      "title_zh": "将外部工具与大语言模型集成以提升准确性",
      "authors": [
        "Nripesh Niketan",
        "Hadj Batatia"
      ],
      "abstract": "This paper deals with improving querying large language models (LLMs). It is well-known that without relevant contextual information, LLMs can provide poor quality responses or tend to hallucinate. Several initiatives have proposed integrating LLMs with external tools to provide them with up-to-date data to improve accuracy. In this paper, we propose a framework to integrate external tools to enhance the capabilities of LLMs in answering queries in educational settings. Precisely, we develop a framework that allows accessing external APIs to request additional relevant information. Integrated tools can also provide computational capabilities such as calculators or calendars. The proposed framework has been evaluated using datasets from the Multi-Modal Language Understanding (MMLU) collection. The data consists of questions on mathematical and scientific reasoning. Results compared to state-of-the-art language models show that the proposed approach significantly improves performance. Our Athena framework achieves 83% accuracy in mathematical reasoning and 88% in scientific reasoning, substantially outperforming all tested models including GPT-4o, LLaMA-Large, Mistral-Large, Phi-Large, and GPT-3.5, with the best baseline model (LLaMA-Large) achieving only 67% and 79% respectively. These promising results open the way to creating complex computing ecosystems around LLMs to make their use more natural to support various tasks and activities.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在缺乏相关上下文信息时容易产生幻觉或回复质量低下的问题，提出了一个旨在增强模型在教育领域查询能力的框架。通过开发 Athena 框架，该研究实现了 LLMs 与外部 APIs 的集成以获取实时补充信息，并利用计算器、日历等工具提供计算支持。实验在 Multi-Modal Language Understanding (MMLU) 的数学与科学推理数据集上进行评估，结果显示 Athena 在数学推理和科学推理中分别达到了 83% 和 88% 的准确率。这一性能显著超越了包括 GPT-4o、LLaMA-Large、Mistral-Large 和 GPT-3.5 在内的所有主流模型，相比最佳基线模型 LLaMA-Large 分别实现了 16% 和 9% 的准确率提升。该研究成果证明了围绕 LLMs 构建复杂计算生态系统以支持各类教育任务的可行性与潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 3 figures, 2 tables. Extended version of paper published in Proceedings of International Conference on Information Technology and Applications, Springer Nature Singapore, 2025, pp. 409-421. This version includes additional experimental results comparing against GPT-4o, LLaMA-Large, Mistral-Large, and Phi-Large, expanded evaluation methodology, and enhanced analysis",
      "pdf_url": "https://arxiv.org/pdf/2507.08034v1",
      "published_date": "2025-07-09 04:09:59 UTC",
      "updated_date": "2025-07-09 04:09:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:37.047654+00:00"
    },
    {
      "arxiv_id": "2507.06528v1",
      "title": "InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior",
      "title_zh": "InvestAlign：克服羊群效应下大语言模型与投资者决策过程对齐中的数据稀缺问题",
      "authors": [
        "Huisheng Wang",
        "Zhuoshi Pan",
        "Hangjing Zhang",
        "Mingxiao Liu",
        "Hanqing Gao",
        "H. Vicky Zhao"
      ],
      "abstract": "Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at https://github.com/thu-social-network-research-group/InvestAlign.",
      "tldr_zh": "该研究针对行为金融学中对齐大语言模型(LLMs)与羊群行为(Herd Behavior)下投资者决策过程时面临的真实用户数据匮乏(Data Scarcity)问题，提出了名为InvestAlign的新型框架。该框架通过利用简单且类似的理论最优投资问题的解析解来构建高质量的监督微调(SFT)数据集，从而规避了采集真实数据的高昂成本和隐私风险。理论分析表明，使用InvestAlign生成的数据进行训练，其参数收敛速度比使用真实用户数据更快，展现出更高的学习效率。基于该框架微调的InvestAgent智能体在简单和复杂投资场景中均展现出与真实用户行为高度一致的特征，表现显著优于微调前的原始模型。这一研究证明了InvestAlign在解决复杂投资优化问题以及实现模型与人类行为模式对齐方面的巨大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06528v1",
      "published_date": "2025-07-09 04:07:22 UTC",
      "updated_date": "2025-07-09 04:07:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:33.609554+00:00"
    },
    {
      "arxiv_id": "2507.06520v1",
      "title": "Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration",
      "title_zh": "Gradientsys：基于 ReAct 编排的多智能体大语言模型调度器",
      "authors": [
        "Xinyuan Song",
        "Zeyu Wang",
        "Siyi Wu",
        "Tianyu Shi",
        "Lynn Ai"
      ],
      "abstract": "We present Gradientsys, a next-generation multi-agent scheduling framework that coordinates diverse specialized AI agents using a typed Model-Context Protocol (MCP) and a ReAct-based dynamic planning loop. At its core, Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task dispatch, enabling parallel execution of heterogeneous agents such as PDF parsers, web search modules, GUI controllers, and web builders. The framework supports hybrid synchronous/asynchronous execution, respects agent capacity constraints, and incorporates a robust retry-and-replan mechanism to handle failures gracefully. To promote transparency and trust, Gradientsys includes an observability layer streaming real-time agent activity and intermediate reasoning via Server-Sent Events (SSE). We offer an architectural overview and evaluate Gradientsys against existing frameworks in terms of extensibility, scheduling topology, tool reusability, parallelism, and observability. Experiments on the GAIA general-assistant benchmark show that Gradientsys achieves higher task success rates with reduced latency and lower API costs compared to a MinionS-style baseline, demonstrating the strength of its LLM-driven multi-agent orchestration.",
      "tldr_zh": "该研究提出了Gradientsys，这是一个下一代多智能体调度框架，通过类型化的Model-Context Protocol (MCP)和基于ReAct的动态规划循环来协调多样化的专业AI智能体。其核心采用了LLM驱动的调度器进行智能的一对多任务分发，支持PDF解析器、网页搜索模块、GUI控制器和网页构建器等异构智能体的并行执行。该框架不仅支持混合同步/异步执行并遵循智能体容量约束，还引入了健壮的重试与重新规划(retry-and-replan)机制以处理执行失败。此外，Gradientsys集成了基于Server-Sent Events (SSE)的可观察性层，实现了智能体活动与推理过程的实时流式传输。在GAIA通用助手基准测试上的实验表明，相比于MinionS基线，Gradientsys在提升任务成功率的同时显著降低了延迟与API成本，验证了其在多智能体编排方面的卓越性能。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06520v1",
      "published_date": "2025-07-09 03:40:56 UTC",
      "updated_date": "2025-07-09 03:40:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:37.743013+00:00"
    },
    {
      "arxiv_id": "2507.06519v1",
      "title": "Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies",
      "title_zh": "失败预测提升Sim2Real节律性插入策略的鲁棒性",
      "authors": [
        "Yuhan Liu",
        "Xinyu Zhang",
        "Haonan Chang",
        "Abdeslam Boularias"
      ],
      "abstract": "This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where a robot must repeatedly perform high-precision insertions, such as screwing a nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving millimeter-level accuracy and maintaining consistent performance over multiple repetitions, particularly when factors like nut rotation and friction introduce additional complexity. We propose a sim-to-real framework that integrates a reinforcement learning-based insertion policy with a failure forecasting module. By representing the wrench's pose in the nut's coordinate frame rather than the robot's frame, our approach significantly enhances sim-to-real transferability. The insertion policy, trained in simulation, leverages real-time 6D pose tracking to execute precise alignment, insertion, and rotation maneuvers. Simultaneously, a neural network predicts potential execution failures, triggering a simple recovery mechanism that lifts the wrench and retries the insertion. Extensive experiments in both simulated and real-world environments demonstrate that our method not only achieves a high one-time success rate but also robustly maintains performance over long-horizon repetitive tasks.",
      "tldr_zh": "本研究针对节奏性插入任务(Rhythmic Insertion Tasks, RIT)中面临的高精度重复操作挑战，提出了一个结合强化学习(Reinforcement Learning)策略与故障预测模块的Sim2Real框架。该方法通过在螺母坐标系而非机器人坐标系下表示扳手的位姿，显著增强了模拟到现实的迁移能力。插入策略在仿真环境中训练，并利用实时6D Pose Tracking实现精确的对齐、插入和旋转动作。同时，系统引入神经网络预测潜在的执行故障，并触发自动恢复机制通过重试确保任务成功。实验结果表明，该方法不仅在单次操作中表现优异，且在长程重复性任务中展现出卓越的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at IROS2025. Project website: https://jaysparrow.github.io/rit",
      "pdf_url": "https://arxiv.org/pdf/2507.06519v1",
      "published_date": "2025-07-09 03:38:44 UTC",
      "updated_date": "2025-07-09 03:38:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:38.585984+00:00"
    },
    {
      "arxiv_id": "2507.06512v1",
      "title": "Towards LLM-based Root Cause Analysis of Hardware Design Failures",
      "title_zh": "迈向基于大语言模型的硬件设计失效根因分析",
      "authors": [
        "Siyu Qiu",
        "Muzhi Wang",
        "Raheel Afsharmazayejani",
        "Mohammad Moradi Shahmiri",
        "Benjamin Tan",
        "Hammond Pearce"
      ],
      "abstract": "With advances in large language models (LLMs), new opportunities have emerged to develop tools that support the digital hardware design process. In this work, we explore how LLMs can assist with explaining the root cause of design issues and bugs that are revealed during synthesis and simulation, a necessary milestone on the pathway towards widespread use of LLMs in the hardware design process and for hardware security analysis. We find promising results: for our corpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model reached a correct determination 100% of the time under pass@5 scoring, with other state of the art models and configurations usually achieving more than 80% performance and more than 90% when assisted with retrieval-augmented generation.",
      "tldr_zh": "该研究探索了利用大语言模型(LLMs)协助解释硬件设计过程中在综合(synthesis)和仿真(simulation)阶段出现的缺陷及漏洞的根因分析(Root Cause Analysis)，这是推动LLMs在硬件设计流程及硬件安全分析(hardware security analysis)中广泛应用的关键里程碑。通过对包含34种不同缺陷场景的语料库进行评估，研究发现OpenAI的o3-mini推理模型在pass@5评分标准下达到了100%的准确判定率。其他先进模型及其配置通常也能实现超过80%的性能，而在结合检索增强生成(RAG)技术辅助后，其准确率可进一步提升至90%以上。实验结果充分证明了LLMs在辅助硬件设计故障诊断方面的有效性，为未来自动化硬件开发工具的研发提供了重要参考。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "6 pages. Accepted for publication in IEEE COINS 2025 Special Session on LLMs for EDA and Security",
      "pdf_url": "https://arxiv.org/pdf/2507.06512v1",
      "published_date": "2025-07-09 03:25:52 UTC",
      "updated_date": "2025-07-09 03:25:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:46.037783+00:00"
    },
    {
      "arxiv_id": "2507.06507v2",
      "title": "GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models",
      "title_zh": "GR-LLMs：基于大语言模型的生成式推荐最新进展",
      "authors": [
        "Zhen Yang",
        "Haitao Lin",
        "Jiawei xue",
        "Ziji Zhang"
      ],
      "abstract": "In the past year, Generative Recommendations (GRs) have undergone substantial advancements, especially in leveraging the powerful sequence modeling and reasoning capabilities of Large Language Models (LLMs) to enhance overall recommendation performance. LLM-based GRs are forming a new paradigm that is distinctly different from discriminative recommendations, showing strong potential to replace traditional recommendation systems heavily dependent on complex hand-crafted features. In this paper, we provide a comprehensive survey aimed at facilitating further research of LLM-based GRs. Initially, we outline the general preliminaries and application cases of LLM-based GRs. Subsequently, we introduce the main considerations when LLM-based GRs are applied in real industrial scenarios. Finally, we explore promising directions for LLM-based GRs. We hope that this survey contributes to the ongoing advancement of the GR domain.",
      "tldr_zh": "该综述系统总结了基于大语言模型(Large Language Models, LLMs)的生成式推荐(Generative Recommendations, GRs)的最新进展，强调了LLMs凭借强大的序列建模和推理能力在提升推荐性能方面的核心作用。基于LLMs的GRs正在形成一种与传统判别式推荐截然不同的新范式，展现出取代依赖复杂手工特征的传统推荐系统的巨大潜力。文章首先概述了LLM-based GRs的基础理论预备知识及其典型应用案例。随后，针对真实工业场景的落地应用，论文详细介绍了部署此类系统时的主要考量因素。最后，该研究深入探讨了生成式推荐领域具有前景的未来研究方向，旨在为大模型驱动的推荐技术发展提供全面的参考与指引。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.06507v2",
      "published_date": "2025-07-09 03:13:08 UTC",
      "updated_date": "2025-07-14 07:46:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:43.661059+00:00"
    },
    {
      "arxiv_id": "2507.06506v1",
      "title": "Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings",
      "title_zh": "意在双关：基于对比学习与音义嵌入的双关语多智能体翻译",
      "authors": [
        "Russell Taylor",
        "Benjamin Herbert",
        "Michael Sana"
      ],
      "abstract": "Translating wordplay across languages presents unique challenges that have long confounded both professional human translators and machine translation systems. This research proposes a novel approach for translating puns from English to French by combining state-of-the-art large language models with specialized techniques for wordplay generation.\n  Our methodology employs a three-stage approach. First, we establish a baseline using multiple frontier large language models with feedback based on a new contrastive learning dataset. Second, we implement a guided chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we implement a multi-agent generator-discriminator framework for evaluating and regenerating puns with feedback.\n  Moving beyond the limitations of literal translation, our methodology's primary objective is to capture the linguistic creativity and humor of the source text wordplay, rather than simply duplicating its vocabulary. Our best runs earned first and second place in the CLEF JOKER 2025 Task 2 competition where they were evaluated manually by expert native French speakers.\n  This research addresses a gap between translation studies and computational linguistics by implementing linguistically-informed techniques for wordplay translation, advancing our understanding of how language models can be leveraged to handle the complex interplay between semantic ambiguity, phonetic similarity, and the implicit cultural and linguistic awareness needed for successful humor.",
      "tldr_zh": "该研究针对跨语言双关语(puns)翻译的挑战，提出了一种结合前沿大型语言模型与专门技巧的新型翻译方法，旨在捕捉源文本的语言创意和幽默，而非简单的字面对应。研究采用三阶段方法：首先基于全新的contrastive learning数据集建立基准；其次，结合phonetic-semantic embeddings实现了引导式的Chain-of-Thought流水线；最后，构建了multi-agent生成器-判别器框架，用于双关语的评估与反馈生成。实验表明，该方法在CLEF JOKER 2025 Task 2竞赛中获得第一和第二名，并得到了法语母语专家的手动评估认可。该研究通过引入语言学启发的技术，成功弥补了翻译学与计算语言学之间的鸿沟，显著提升了模型处理语义歧义、语音相似性及文化意识的能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain",
      "pdf_url": "https://arxiv.org/pdf/2507.06506v1",
      "published_date": "2025-07-09 03:09:14 UTC",
      "updated_date": "2025-07-09 03:09:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:54.674937+00:00"
    },
    {
      "arxiv_id": "2507.06502v1",
      "title": "MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models",
      "title_zh": "MoFE-Time：面向时间序列预测模型的频域混合专家模型",
      "authors": [
        "Yiwen Liu",
        "Chenyu Zhang",
        "Junjie Song",
        "Siqi Chen",
        "Sun Yin",
        "Zihan Wang",
        "Lingming Zeng",
        "Yuji Cao",
        "Junming Jiao"
      ],
      "abstract": "As a prominent data modality task, time series forecasting plays a pivotal role in diverse applications. With the remarkable advancements in Large Language Models (LLMs), the adoption of LLMs as the foundational architecture for time series modeling has gained significant attention. Although existing models achieve some success, they rarely both model time and frequency characteristics in a pretraining-finetuning paradigm leading to suboptimal performance in predictions of complex time series, which requires both modeling periodicity and prior pattern knowledge of signals. We propose MoFE-Time, an innovative time series forecasting model that integrates time and frequency domain features within a Mixture of Experts (MoE) network. Moreover, we use the pretraining-finetuning paradigm as our training framework to effectively transfer prior pattern knowledge across pretraining and finetuning datasets with different periodicity distributions. Our method introduces both frequency and time cells as experts after attention modules and leverages the MoE routing mechanism to construct multidimensional sparse representations of input signals. In experiments on six public benchmarks, MoFE-Time has achieved new state-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared to the representative methods Time-MoE. Beyond the existing evaluation benchmarks, we have developed a proprietary dataset, NEV-sales, derived from real-world business scenarios. Our method achieves outstanding results on this dataset, underscoring the effectiveness of the MoFE-Time model in practical commercial applications.",
      "tldr_zh": "该研究提出了 MoFE-Time，一种创新的时间序列预测模型，旨在解决现有大语言模型(LLMs)架构在处理复杂时间序列时无法同时兼顾时域和频域建模的问题。MoFE-Time 在混合专家(Mixture of Experts, MoE)网络中集成了时域和频域特征，并采用预训练-微调(pretraining-finetuning)范式，以实现跨不同周期分布数据集的先验模式知识迁移。该方法在注意力模块后引入频域和时域单元作为专家，通过 MoE 路由机制构建输入信号的多维稀疏表示。在六个公共基准测试的实验中，MoFE-Time 取得了新的 SOTA 性能，相较于 Time-MoE 模型，其 MSE 和 MAE 分别降低了 6.95% 和 6.02%。此外，该模型在真实商业场景数据集 NEV-sales 上的优异表现进一步验证了其在实际应用中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06502v1",
      "published_date": "2025-07-09 03:00:56 UTC",
      "updated_date": "2025-07-09 03:00:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:52.795880+00:00"
    },
    {
      "arxiv_id": "2508.00846v1",
      "title": "Cognitive Exoskeleton: Augmenting Human Cognition with an AI-Mediated Intelligent Visual Feedback",
      "title_zh": "认知外骨骼：利用 AI 介导的智能视觉反馈增强人类认知",
      "authors": [
        "Songlin Xu",
        "Xinyu Zhang"
      ],
      "abstract": "In this paper, we introduce an AI-mediated framework that can provide intelligent feedback to augment human cognition. Specifically, we leverage deep reinforcement learning (DRL) to provide adaptive time pressure feedback to improve user performance in a math arithmetic task. Time pressure feedback could either improve or deteriorate user performance by regulating user attention and anxiety. Adaptive time pressure feedback controlled by a DRL policy according to users' real-time performance could potentially solve this trade-off problem. However, the DRL training and hyperparameter tuning may require large amounts of data and iterative user studies. Therefore, we propose a dual-DRL framework that trains a regulation DRL agent to regulate user performance by interacting with another simulation DRL agent that mimics user cognition behaviors from an existing dataset. Our user study demonstrates the feasibility and effectiveness of the dual-DRL framework in augmenting user performance, in comparison to the baseline group.",
      "tldr_zh": "该研究提出了名为Cognitive Exoskeleton的AI介导框架，旨在通过智能视觉反馈增强人类认知。研究核心利用深度强化学习(Deep Reinforcement Learning)在数学运算任务中提供自适应时间压力反馈，通过实时调节用户的注意力和焦虑感来优化任务表现。针对DRL训练过程中对大规模数据和反复用户研究的依赖问题，作者提出了一种Dual-DRL框架，即通过训练一个调节智能体与另一个模拟人类认知行为的仿真智能体进行交互，从而实现高效的策略学习。用户研究结果证实了Dual-DRL框架在增强用户表现方面的可行性与有效性，其性能显著优于基准对照组。该成果为利用人工智能技术实现自适应人类认知干预提供了重要的理论与实践参考。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.00846v1",
      "published_date": "2025-07-09 02:12:14 UTC",
      "updated_date": "2025-07-09 02:12:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:42:53.680816+00:00"
    },
    {
      "arxiv_id": "2507.06485v2",
      "title": "Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning",
      "title_zh": "Video-RTS：重新审视强化学习与测试时扩展，实现高效增强的视频推理",
      "authors": [
        "Ziyang Wang",
        "Jaehong Yoon",
        "Shoubin Yu",
        "Md Mohaiminul Islam",
        "Gedas Bertasius",
        "Mohit Bansal"
      ],
      "abstract": "Despite advances in reinforcement learning (RL)-based video reasoning with large language models (LLMs), data collection and fine-tuning remain significant challenges. These methods often rely on large-scale supervised fine-tuning (SFT) with extensive video data and long Chain-of-Thought (CoT) annotations, making them costly and hard to scale. To address this, we present Video-RTS, a new approach to improve video reasoning capability with drastically improved data efficiency by combining data-efficient RL with a video-adaptive test-time scaling (TTS) strategy. Building on observations about the data scaling, we skip the resource-intensive SFT step and employ efficient pure-RL training with output-based rewards, requiring no additional annotations or extensive fine-tuning. Furthermore, to utilize computational resources more efficiently, we introduce a sparse-to-dense video TTS strategy that improves inference by iteratively adding frames based on output consistency. We validate our approach on multiple video reasoning benchmarks, showing that Video-RTS surpasses existing video reasoning models by 2.4% in accuracy using only 3.6% training samples. Specifically, Video-RTS achieves a 4.2% improvement on Video-Holmes, a recent and challenging video reasoning benchmark. Notably, our pure RL training and adaptive video TTS offer complementary strengths, enabling Video-RTS's strong reasoning performance.",
      "tldr_zh": "该研究提出了 Video-RTS，一种通过结合数据高效的强化学习(Reinforcement Learning)和视频自适应测试时扩展(Test-Time Scaling)策略来增强视频推理能力的新方法。为了解决传统方法中大规模监督微调(SFT)成本高昂且难以扩展的挑战，Video-RTS 跳过了资源密集型的 SFT 阶段，直接采用基于输出奖励的纯强化学习(pure-RL)进行训练，无需额外的 Chain-of-Thought 标注。此外，研究还引入了一种从稀疏到稠密(sparse-to-dense)的视频 TTS 策略，通过根据输出一致性迭代增加采样帧来优化推理效率。实验结果显示，Video-RTS 仅利用 3.6% 的训练样本就在多个基准测试中超越了现有模型，尤其在 Video-Holmes 测试中实现了 4.2% 的性能提升。该框架证明了纯强化学习与自适应 TTS 在视频推理任务中的互补优势，为实现更高效的视频智能分析奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2025. The first two authors contributed equally. Project page: https://sites.google.com/cs.unc.edu/videorts2025/",
      "pdf_url": "https://arxiv.org/pdf/2507.06485v2",
      "published_date": "2025-07-09 02:06:13 UTC",
      "updated_date": "2025-10-24 16:19:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:43:09.293933+00:00"
    },
    {
      "arxiv_id": "2507.06479v1",
      "title": "Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity",
      "title_zh": "极度稀疏观测环境下的海洋动力学生成式拉格朗日数据同化",
      "authors": [
        "Niloofar Asefi",
        "Leonard Lupin-Jimenez",
        "Tianning Wu",
        "Ruoying He",
        "Ashesh Chattopadhyay"
      ],
      "abstract": "Reconstructing ocean dynamics from observational data is fundamentally limited by the sparse, irregular, and Lagrangian nature of spatial sampling, particularly in subsurface and remote regions. This sparsity poses significant challenges for forecasting key phenomena such as eddy shedding and rogue waves. Traditional data assimilation methods and deep learning models often struggle to recover mesoscale turbulence under such constraints. We leverage a deep learning framework that combines neural operators with denoising diffusion probabilistic models (DDPMs) to reconstruct high-resolution ocean states from extremely sparse Lagrangian observations. By conditioning the generative model on neural operator outputs, the framework accurately captures small-scale, high-wavenumber dynamics even at $99\\%$ sparsity (for synthetic data) and $99.9\\%$ sparsity (for real satellite observations). We validate our method on benchmark systems, synthetic float observations, and real satellite data, demonstrating robust performance under severe spatial sampling limitations as compared to other deep learning baselines.",
      "tldr_zh": "该研究针对海洋动力学重建中观测数据极度稀疏、不规则且具有 Lagrangian 特性的难题，提出了一种结合 Neural Operators 与 Denoising Diffusion Probabilistic Models (DDPMs) 的生成式深度学习框架。该框架通过将生成模型条件化于 Neural Operators 的输出，能够从极度稀疏的采样中恢复高分辨率的海洋状态信息。实验结果表明，该方法在合成数据稀疏度达 99% 及真实卫星观测数据稀疏度达 99.9% 的极端情况下，依然能准确捕捉小尺度和高波数动力学特征。通过在基准系统、合成浮标观测和真实卫星数据上的广泛验证，该框架在处理严重空间采样限制方面表现出极强的鲁棒性，显著优于传统的 Data Assimilation 方法和其他深度学习基线模型。该技术为预测涡流脱落 (eddy shedding) 和巨浪 (rogue waves) 等关键海洋现象提供了全新的解决路径。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG",
        "math.DS",
        "nlin.CD"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06479v1",
      "published_date": "2025-07-09 01:56:25 UTC",
      "updated_date": "2025-07-09 01:56:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:43:31.104280+00:00"
    },
    {
      "arxiv_id": "2507.06466v1",
      "title": "Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models",
      "title_zh": "基础模型自博弈：基于基础模型的开放式策略创新",
      "authors": [
        "Aaron Dharna",
        "Cong Lu",
        "Jeff Clune"
      ],
      "abstract": "Multi-agent interactions have long fueled innovation, from natural predator-prey dynamics to the space race. Self-play (SP) algorithms try to harness these dynamics by pitting agents against ever-improving opponents, thereby creating an implicit curriculum toward learning high-quality solutions. However, SP often fails to produce diverse solutions and can get stuck in locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a new direction that leverages the code-generation capabilities and vast knowledge of foundation models (FMs) to overcome these challenges by leaping across local optima in policy space. We propose a family of approaches: (1) \\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent policies via competitive self-play; (2) \\textbf{Novelty-Search Self-Play (NSSP)} builds a diverse population of strategies, ignoring performance; and (3) the most promising variant, \\textbf{Quality-Diveristy Self-Play (QDSP)}, creates a diverse set of high-quality policies by combining the diversity of NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety simulation in which an attacker tries to jailbreak an LLM's defenses. In Car Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and heuristic-based methods, to name just a few. In terms of discovered policy quality, \\ouralgo and vFMSP surpass strong human-designed strategies. In Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through and jailbreaking six different, progressively stronger levels of defense. Furthermore, FMSPs can automatically proceed to patch the discovered vulnerabilities. Overall, FMSPs represent a promising new research frontier of improving self-play with foundation models, opening fresh paths toward more creative and open-ended strategy discovery",
      "tldr_zh": "该研究提出了Foundation-Model Self-Play (FMSP)框架，通过利用基础模型(Foundation Models)的代码生成能力和先验知识，解决了传统自博弈(Self-play)算法中策略多样性不足且易陷入局部最优的问题。作者构建了三种算法变体：持续优化策略的vFMSP、侧重策略多样性的NSSP以及兼顾质量与多样性的Quality-Diversity Self-Play (QDSP)。实验在Car Tag追逐博弈和Gandalf安全测试中进行，结果显示FMSP能够自主探索出涵盖强化学习(Reinforcement Learning)和树搜索(Tree Search)在内的多种高效策略，表现优于人类专家设计的方案。在Gandalf模拟中，该框架成功实现了自动红队测试(Red-teaming)，不仅连续突破了六个防御等级，还完成了对系统漏洞的自动化修复。总体而言，FMSP为实现开放式(Open-ended)策略创新和提高自博弈系统的创造力提供了极具前景的研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "67 pages, accepted to RLC 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.06466v1",
      "published_date": "2025-07-09 00:58:19 UTC",
      "updated_date": "2025-07-09 00:58:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:43:27.977402+00:00"
    },
    {
      "arxiv_id": "2507.06464v1",
      "title": "SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam",
      "title_zh": "SoftSignSGD(S3)：超越 Adam 的实用 DNN 训练与损失尖峰抑制增强型优化器",
      "authors": [
        "Hanyang Peng",
        "Shuang Qin",
        "Yue Yu",
        "Fangqing Jiang",
        "Hui Wang",
        "Wen Gao"
      ],
      "abstract": "Adam has proven remarkable successful in training deep neural networks, but the mechanisms underlying its empirical successes and limitations remain underexplored. In this study, we demonstrate that the effectiveness of Adam stems largely from its similarity to SignSGD in robustly handling large gradient fluctuations, yet it is also vulnerable to destabilizing loss spikes due to its uncontrolled update scaling. To enhance the advantage of Adam and mitigate its limitation, we propose SignSoftSGD (S3), a novel optimizer with three key innovations. \\emph{First}, S3 generalizes the sign-like update by employing a flexible $p$-th order momentum ($p \\geq 1$) in the denominator, departing from the conventional second-order momentum (variance) preconditioning. This design enables enhanced performance while achieving stable training even with aggressive learning rates. \\emph{Second}, S3 minimizes the occurrences of loss spikes through unified exponential moving average coefficients for numerator and denominator momenta, which inherently bound updates to $[-1, 1]$ and simplify hyperparameter tuning. \\emph{Third}, S3 incorporates an equivalent Nesterov's accelerated gradient(NAG) module, accelerating convergence without memory overhead. Theoretically, we prove that S3 achieves the optimal convergence rate of $O\\left(\\frac{1}{T^{\\sfrac{1}{4}}}\\right)$ for general nonconvex stochastic optimization under weak assumptions. Extensive experiments across a range of vision and language tasks show that \\textsf{\\small S3} not only converges more rapidly and improves performance but also rarely experiences loss spikes, even with a \\textbf{$\\bm{10 \\times}$} larger learning rate. In fact, S3 delivers performance comparable to or better than AdamW with \\textbf{$2 \\times$} the training steps, establishing its efficacy in both efficiency and final task performance.",
      "tldr_zh": "该研究提出了SoftSignSGD (S3)，这是一种旨在克服Adam在深度神经网络训练中易产生损失尖峰(loss spikes)局限性的增强型优化器。S3的核心创新包括在分母中使用p阶动量(p-th order momentum)以确保在高学习率下的训练稳定性，以及通过统一分子和分母的指数移动平均(EMA)系数将更新限制在[-1, 1]内以抑制损失尖峰。此外，该优化器集成了等效的Nesterov加速梯度(NAG)模块，在不增加额外内存开销的情况下实现了更快的收敛。理论分析证明S3能达到非凸随机优化的最优收敛率，而广泛的视觉与语言任务实验表明，S3在性能和收敛速度上均优于或等同于AdamW，且在极端超参数设置下仍表现出极高的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20pages, 11pages",
      "pdf_url": "https://arxiv.org/pdf/2507.06464v1",
      "published_date": "2025-07-09 00:47:37 UTC",
      "updated_date": "2025-07-09 00:47:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:43:51.282250+00:00"
    },
    {
      "arxiv_id": "2507.06459v1",
      "title": "EA: An Event Autoencoder for High-Speed Vision Sensing",
      "title_zh": "EA：面向高速视觉感知的事件自编码器",
      "authors": [
        "Riadul Islam",
        "Joey Mulé",
        "Dhandeep Challagundla",
        "Shahmir Rizvi",
        "Sean Carson"
      ],
      "abstract": "High-speed vision sensing is essential for real-time perception in applications such as robotics, autonomous vehicles, and industrial automation. Traditional frame-based vision systems suffer from motion blur, high latency, and redundant data processing, limiting their performance in dynamic environments. Event cameras, which capture asynchronous brightness changes at the pixel level, offer a promising alternative but pose challenges in object detection due to sparse and noisy event streams. To address this, we propose an event autoencoder architecture that efficiently compresses and reconstructs event data while preserving critical spatial and temporal features. The proposed model employs convolutional encoding and incorporates adaptive threshold selection and a lightweight classifier to enhance recognition accuracy while reducing computational complexity. Experimental results on the existing Smart Event Face Dataset (SEFD) demonstrate that our approach achieves comparable accuracy to the YOLO-v4 model while utilizing up to $35.5\\times$ fewer parameters. Implementations on embedded platforms, including Raspberry Pi 4B and NVIDIA Jetson Nano, show high frame rates ranging from 8 FPS up to 44.8 FPS. The proposed classifier exhibits up to 87.84x better FPS than the state-of-the-art and significantly improves event-based vision performance, making it ideal for low-power, high-speed applications in real-time edge computing.",
      "tldr_zh": "该研究提出了EA（Event Autoencoder），一种针对高速视觉传感设计的事件自编码器架构，旨在解决传统帧相机在动态环境中的运动模糊、高延迟以及事件相机数据稀疏且多噪点等挑战。该架构利用卷积编码、自适应阈值选择和轻量级分类器，在保留关键时空特征的同时实现了高效的数据压缩与重建。实验结果表明，在Smart Event Face Dataset (SEFD)数据集上，该方法在参数量比YOLO-v4模型减少多达35.5倍的情况下，仍能保持相当的识别准确率。在Raspberry Pi 4B和NVIDIA Jetson Nano等嵌入式平台上的部署显示，该系统运行帧率可达44.8 FPS，其分类器速度比现有最先进技术提升了87.84倍。这一成果显著增强了基于事件的视觉性能，为低功耗、高速度的实时边缘计算应用提供了理想的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.06459v1",
      "published_date": "2025-07-09 00:21:15 UTC",
      "updated_date": "2025-07-09 00:21:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T03:43:31.820597+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 114,
  "processed_papers_count": 114,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T03:45:49.294509+00:00"
}