{
  "date": "2024-04-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-20 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 41 篇论文，主要聚焦 AI 安全、机器学习优化、机器人学和量子计算等领域，其中令人印象深刻的是关于视觉语言模型的对抗鲁棒性提升（论文 12）和机器人表示学习（论文 3），以及 NeurIPS 2024 的图神经网络归一化方法（论文 24），这些文章展示了前沿创新和实际应用潜力。\n\n下面，我挑选了最具话题度和影响力的几篇论文进行详细讨论，将相关主题归类，其他较基础或会议论文则快速掠过，只列出标题和核心要点，以控制篇幅。\n\n### AI 安全与鲁棒性\n- **标题（中文）：增强视觉语言模型的对抗鲁棒性通过低秩自适应**  \n  **标题（英文）：Enhancing Adversarial Robustness of Vision-Language Models through Low-Rank Adaptation**  \n  这篇论文提出 AdvLoRA 方法，利用低秩自适应优化视觉语言模型（如 VLMs）的对抗鲁棒性，核心贡献是通过参数聚类和自适应更新减少计算开销，同时提升模型安全性。实验显示，该方法在保持性能的同时显著提高了对抗攻击抵抗力，对于 AI 安全领域有重要启发。\n\n- **标题（中文）：像素是障碍：扩散模型比我们想象的更具对抗鲁棒性**  \n  **标题（英文）：Pixel is a Barrier: Diffusion Models Are More Adversarially Robust Than We Think**  \n  作者发现扩散模型在像素空间（PDMs）比在潜在空间（LDMs）更抗对抗攻击，主要贡献是通过实验验证 PDMs 的鲁棒性，并提出使用 PDMs 作为净化器移除攻击模式，这为扩散模型的安全应用提供了新视角，挑战了现有保护方法的局限性。\n\n### 机器人学与视觉表示\n- **标题（中文）：从“什么”和“哪里”基础模型组合预训练的对象中心表示用于机器人学**  \n  **标题（英文）：Composing Pre-Trained Object-Centric Representations for Robotics From \"What\" and \"Where\" Foundation Models**  \n  这篇 ICRA 2024 论文引入 POCR 框架，通过结合预训练模型提取“什么”（对象描述）和“哪里”（位置信息），构建对象中心表示。核心发现是，该方法无需额外训练即可提升机器人任务性能，并在模拟和真实环境中表现出色，展示了视觉表示在机器人学习中的潜力。\n\n### 机器学习优化与创新模型\n- **标题（中文）：GRANOLA：自适应归一化为图神经网络**  \n  **标题（英文）：GRANOLA: Adaptive Normalization for Graph Neural Networks**  \n  来自 NeurIPS 2024 的论文，提出 GRANOLA 层，通过随机节点特征传播生成图的自适应归一化表示。关键贡献是理论证明其收敛性，并实验验证其在图基准上的优越性能，超越传统归一化方法，提供了一种高效的 GNN 优化策略。\n\n- **标题（中文）：音乐一致性模型**  \n  **标题（英文）：Music Consistency Models**  \n  这篇论文扩展一致性模型到音乐生成领域，提出 MusicCM 方法，通过一致性蒸馏和判别器训练实现高效音乐合成。核心发现是，仅需 4 步采样即可生成高质量音乐，支持实时应用，这为音频生成领域带来了创新。\n\n其他论文中，如量子学习的安全框架（论文 2）、联邦学习框架（论文 13 和 39）等有实际应用价值，但细节较常规，我仅快速概述：  \n- **论文 2（PristiQ）**：提出量子学习数据安全框架，使用加密子电路和优化算法，提升 QML 安全性。  \n- **论文 13（MultiConfederated Learning）**：设计去中心化联邦学习处理非独立数据，提高模型适应性。  \n- **论文 39（Personalized Wireless Federated Learning）**：探索无线联邦学习个性化训练，适用于大语言模型。  \n其余如会议论文（例如论文 5、8、19）或基础方法（论文 27、37）则跳过细节，仅供参考。\n\n总之，今天的 arXiv 快报突显了 AI 领域的创新与挑战，感兴趣的读者可关注上述关键论文进行深入阅读！如果有特定主题，欢迎随时反馈。",
  "papers": [
    {
      "arxiv_id": "2404.13476v1",
      "title": "A Framework for Feasible Counterfactual Exploration incorporating Causality, Sparsity and Density",
      "title_zh": "一种整合因果",
      "authors": [
        "Kleopatra Markou",
        "Dimitrios Tomaras",
        "Vana Kalogeraki",
        "Dimitrios Gunopulos"
      ],
      "abstract": "The imminent need to interpret the output of a Machine Learning model with\ncounterfactual (CF) explanations - via small perturbations to the input - has\nbeen notable in the research community. Although the variety of CF examples is\nimportant, the aspect of them being feasible at the same time, does not\nnecessarily apply in their entirety. This work uses different benchmark\ndatasets to examine through the preservation of the logical causal relations of\ntheir attributes, whether CF examples can be generated after a small amount of\nchanges to the original input, be feasible and actually useful to the end-user\nin a real-world case. To achieve this, we used a black box model as a\nclassifier, to distinguish the desired from the input class and a Variational\nAutoencoder (VAE) to generate feasible CF examples. As an extension, we also\nextracted two-dimensional manifolds (one for each dataset) that located the\nmajority of the feasible examples, a representation that adequately\ndistinguished them from infeasible ones. For our experimentation we used three\ncommonly used datasets and we managed to generate feasible and at the same time\nsparse, CF examples that satisfy all possible predefined causal constraints, by\nconfirming their importance with the attributes in a dataset.",
      "tldr_zh": "该论文提出了一种框架，用于生成可行的反事实（Counterfactual, CF）解释，旨在通过整合因果性（Causality）、稀疏性（Sparsity）和密度（Density），确保CF例子在保留属性逻辑因果关系的同时，仅需对原始输入进行少量变化。方法包括使用黑盒模型（Black box model）作为分类器和变分自动编码器（VAE）来创建可行的CF例子，并提取二维流形以区分可行与不可行实例。在实验中，使用三个常用基准数据集成功生成了满足预定义因果约束的稀疏CF例子，证明了该框架在真实世界应用中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.13476v1",
      "published_date": "2024-04-20 22:05:48 UTC",
      "updated_date": "2024-04-20 22:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:05:29.740594"
    },
    {
      "arxiv_id": "2404.13475v1",
      "title": "PristiQ: A Co-Design Framework for Preserving Data Security of Quantum Learning in the Cloud",
      "title_zh": "翻译失败",
      "authors": [
        "Zhepeng Wang",
        "Yi Sheng",
        "Nirajan Koirala",
        "Kanad Basu",
        "Taeho Jung",
        "Cheng-Chang Lu",
        "Weiwen Jiang"
      ],
      "abstract": "Benefiting from cloud computing, today's early-stage quantum computers can be\nremotely accessed via the cloud services, known as Quantum-as-a-Service (QaaS).\nHowever, it poses a high risk of data leakage in quantum machine learning\n(QML). To run a QML model with QaaS, users need to locally compile their\nquantum circuits including the subcircuit of data encoding first and then send\nthe compiled circuit to the QaaS provider for execution. If the QaaS provider\nis untrustworthy, the subcircuit to encode the raw data can be easily stolen.\nTherefore, we propose a co-design framework for preserving the data security of\nQML with the QaaS paradigm, namely PristiQ. By introducing an encryption\nsubcircuit with extra secure qubits associated with a user-defined security\nkey, the security of data can be greatly enhanced. And an automatic search\nalgorithm is proposed to optimize the model to maintain its performance on the\nencrypted quantum data. Experimental results on simulation and the actual IBM\nquantum computer both prove the ability of PristiQ to provide high security for\nthe quantum data while maintaining the model performance in QML.",
      "tldr_zh": "该论文提出PristiQ框架，用于保护量子机器学习(QML)在Quantum-as-a-Service (QaaS)云服务中的数据安全，以解决用户量子电路编译过程中数据泄露的风险。框架通过引入加密子电路和额外的secure qubits，以及用户定义的安全密钥，来增强数据编码的安全性。同时，论文设计了一个自动搜索算法来优化QML模型，确保在加密量子数据上维持性能。实验结果显示，在模拟环境和实际IBM量子计算机上，PristiQ实现了高数据安全性，同时保持了模型的准确性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CR",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13475v1",
      "published_date": "2024-04-20 22:03:32 UTC",
      "updated_date": "2024-04-20 22:03:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:05:41.551433"
    },
    {
      "arxiv_id": "2404.13474v1",
      "title": "Composing Pre-Trained Object-Centric Representations for Robotics From \"What\" and \"Where\" Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junyao Shi",
        "Jianing Qian",
        "Yecheng Jason Ma",
        "Dinesh Jayaraman"
      ],
      "abstract": "There have recently been large advances both in pre-training visual\nrepresentations for robotic control and segmenting unknown category objects in\ngeneral images. To leverage these for improved robot learning, we propose\n$\\textbf{POCR}$, a new framework for building pre-trained object-centric\nrepresentations for robotic control. Building on theories of \"what-where\"\nrepresentations in psychology and computer vision, we use segmentations from a\npre-trained model to stably locate across timesteps, various entities in the\nscene, capturing \"where\" information. To each such segmented entity, we apply\nother pre-trained models that build vector descriptions suitable for robotic\ncontrol tasks, thus capturing \"what\" the entity is. Thus, our pre-trained\nobject-centric representations for control are constructed by appropriately\ncombining the outputs of off-the-shelf pre-trained models, with no new\ntraining. On various simulated and real robotic tasks, we show that imitation\npolicies for robotic manipulators trained on POCR achieve better performance\nand systematic generalization than state of the art pre-trained representations\nfor robotics, as well as prior object-centric representations that are\ntypically trained from scratch.",
      "tldr_zh": "该论文提出了一种名为 POCR 的框架，用于构建预训练的对象中心表示（object-centric representations），以提升机器人控制性能。框架基于 \"what-where\" representations 理论，利用预训练模型的分割功能来捕捉场景中实体的位置信息（\"where\"），并结合其他预训练模型为每个实体生成适合机器人任务的向量描述（\"what\"），无需额外训练。在模拟和真实机器人任务中，基于 POCR 训练的模仿策略比现有预训练表示和从零训练的对象中心表示表现出更好的性能和系统化泛化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2024. Project website: https://sites.google.com/view/pocr",
      "pdf_url": "http://arxiv.org/pdf/2404.13474v1",
      "published_date": "2024-04-20 21:51:15 UTC",
      "updated_date": "2024-04-20 21:51:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:05:53.248748"
    },
    {
      "arxiv_id": "2404.13470v1",
      "title": "GWLZ: A Group-wise Learning-based Lossy Compression Framework for Scientific Data",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqi Jia",
        "Sian Jin",
        "Jinzhen Wang",
        "Wei Niu",
        "Dingwen Tao",
        "Miao Yin"
      ],
      "abstract": "The rapid expansion of computational capabilities and the ever-growing scale\nof modern HPC systems present formidable challenges in managing exascale\nscientific data. Faced with such vast datasets, traditional lossless\ncompression techniques prove insufficient in reducing data size to a manageable\nlevel while preserving all information intact. In response, researchers have\nturned to error-bounded lossy compression methods, which offer a balance\nbetween data size reduction and information retention. However, despite their\nutility, these compressors employing conventional techniques struggle with\nlimited reconstruction quality. To address this issue, we draw inspiration from\nrecent advancements in deep learning and propose GWLZ, a novel group-wise\nlearning-based lossy compression framework with multiple lightweight learnable\nenhancer models. Leveraging a group of neural networks, GWLZ significantly\nenhances the decompressed data reconstruction quality with negligible impact on\nthe compression efficiency. Experimental results on different fields from the\nNyx dataset demonstrate remarkable improvements by GWLZ, achieving up to 20%\nquality enhancements with negligible overhead as low as 0.0003x.",
      "tldr_zh": "该研究针对高性能计算(HPC)系统产生的海量科学数据管理挑战，提出GWLZ框架，这是一种基于组式学习(group-wise learning)的损失压缩方法，使用多个轻量级可学习增强器模型来提升数据重建质量。GWLZ通过一组神经网络显著改善解压缩数据的重建效果，同时保持压缩效率几乎不受影响。实验结果显示，在Nyx数据集的不同领域上，GWLZ实现了高达20%的质量提升，且额外开销低至0.0003x。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13470v1",
      "published_date": "2024-04-20 21:12:53 UTC",
      "updated_date": "2024-04-20 21:12:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:06:04.920134"
    },
    {
      "arxiv_id": "2404.13454v1",
      "title": "Revolutionizing System Reliability: The Role of AI in Predictive Maintenance Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Bidollahkhani",
        "Julian M. Kunkel"
      ],
      "abstract": "The landscape of maintenance in distributed systems is rapidly evolving with\nthe integration of Artificial Intelligence (AI). Also, as the complexity of\ncomputing continuum systems intensifies, the role of AI in predictive\nmaintenance (Pd.M.) becomes increasingly pivotal. This paper presents a\ncomprehensive survey of the current state of Pd.M. in the computing continuum,\nwith a focus on the combination of scalable AI technologies. Recognizing the\nlimitations of traditional maintenance practices in the face of increasingly\ncomplex and heterogenous computing continuum systems, the study explores how\nAI, especially machine learning and neural networks, is being used to enhance\nPd.M. strategies. The survey encompasses a thorough review of existing\nliterature, highlighting key advancements, methodologies, and case studies in\nthe field. It critically examines the role of AI in improving prediction\naccuracy for system failures and in optimizing maintenance schedules, thereby\ncontributing to reduced downtime and enhanced system longevity. By synthesizing\nfindings from the latest advancements in the field, the article provides\ninsights into the effectiveness and challenges of implementing AI-driven\npredictive maintenance. It underscores the evolution of maintenance practices\nin response to technological advancements and the growing complexity of\ncomputing continuum systems. The conclusions drawn from this survey are\ninstrumental for practitioners and researchers in understanding the current\nlandscape and future directions of Pd.M. in distributed systems. It emphasizes\nthe need for continued research and development in this area, pointing towards\na trend of more intelligent, efficient, and cost-effective maintenance\nsolutions in the era of AI.",
      "tldr_zh": "这篇论文通过全面调查探讨了人工智能（AI）在预测性维护（Pd.M.）策略中的作用，旨在应对分布式系统日益复杂的维护挑战。研究重点回顾了现有文献，突出机器学习和神经网络等AI技术如何提升系统故障预测准确性并优化维护时间表，从而减少停机时间并延长系统寿命。论文总结了关键进展和案例研究，并强调了AI驱动维护的潜在挑战和未来研究方向，为从业者和研究者提供宝贵见解，推动更智能、高效的维护解决方案。",
      "categories": [
        "cs.AI",
        "cs.PF",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted, published and presented for the IARIA CLOUDCOMP2024\n  Conference of Venice, Italy",
      "pdf_url": "http://arxiv.org/pdf/2404.13454v1",
      "published_date": "2024-04-20 19:31:05 UTC",
      "updated_date": "2024-04-20 19:31:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:06:16.863009"
    },
    {
      "arxiv_id": "2404.14451v1",
      "title": "Generative Subspace Adversarial Active Learning for Outlier Detection in Multiple Views of High-dimensional Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jose Cribeiro-Ramallo",
        "Vadim Arzamasov",
        "Federico Matteucci",
        "Denis Wambold",
        "Klemens Böhm"
      ],
      "abstract": "Outlier detection in high-dimensional tabular data is an important task in\ndata mining, essential for many downstream tasks and applications. Existing\nunsupervised outlier detection algorithms face one or more problems, including\ninlier assumption (IA), curse of dimensionality (CD), and multiple views (MV).\nTo address these issues, we introduce Generative Subspace Adversarial Active\nLearning (GSAAL), a novel approach that uses a Generative Adversarial Network\nwith multiple adversaries. These adversaries learn the marginal class\nprobability functions over different data subspaces, while a single generator\nin the full space models the entire distribution of the inlier class. GSAAL is\nspecifically designed to address the MV limitation while also handling the IA\nand CD, being the only method to do so. We provide a comprehensive mathematical\nformulation of MV, convergence guarantees for the discriminators, and\nscalability results for GSAAL. Our extensive experiments demonstrate the\neffectiveness and scalability of GSAAL, highlighting its superior performance\ncompared to other popular OD methods, especially in MV scenarios.",
      "tldr_zh": "这篇论文提出了 Generative Subspace Adversarial Active Learning (GSAAL)，一种新型方法，用于解决高维表格数据中异常检测（Outlier Detection）的 Inlier Assumption (IA)、 Curse of Dimensionality (CD) 和 Multiple Views (MV) 问题。GSAAL 基于 Generative Adversarial Network (GAN) 的多对手机制，学习不同数据子空间的边缘类概率函数，同时使用一个生成器在全空间建模正常类分布，是唯一同时处理这些挑战的算法。论文提供了全面的数学公式、收敛保证和可扩展性分析，实验结果显示 GSAAL 在多视图场景中比其他流行异常检测方法表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2404.14451v1",
      "published_date": "2024-04-20 19:22:05 UTC",
      "updated_date": "2024-04-20 19:22:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:06:29.903698"
    },
    {
      "arxiv_id": "2404.13449v1",
      "title": "SiNC+: Adaptive Camera-Based Vitals with Unsupervised Learning of Periodic Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy Speth",
        "Nathan Vance",
        "Patrick Flynn",
        "Adam Czajka"
      ],
      "abstract": "Subtle periodic signals, such as blood volume pulse and respiration, can be\nextracted from RGB video, enabling noncontact health monitoring at low cost.\nAdvancements in remote pulse estimation -- or remote photoplethysmography\n(rPPG) -- are currently driven by deep learning solutions. However, modern\napproaches are trained and evaluated on benchmark datasets with ground truth\nfrom contact-PPG sensors. We present the first non-contrastive unsupervised\nlearning framework for signal regression to mitigate the need for labelled\nvideo data. With minimal assumptions of periodicity and finite bandwidth, our\napproach discovers the blood volume pulse directly from unlabelled videos. We\nfind that encouraging sparse power spectra within normal physiological\nbandlimits and variance over batches of power spectra is sufficient for\nlearning visual features of periodic signals. We perform the first experiments\nutilizing unlabelled video data not specifically created for rPPG to train\nrobust pulse rate estimators. Given the limited inductive biases, we\nsuccessfully applied the same approach to camera-based respiration by changing\nthe bandlimits of the target signal. This shows that the approach is general\nenough for unsupervised learning of bandlimited quasi-periodic signals from\ndifferent domains. Furthermore, we show that the framework is effective for\nfinetuning models on unlabelled video from a single subject, allowing for\npersonalized and adaptive signal regressors.",
      "tldr_zh": "本文提出 SiNC+，一种自适应相机-based 生命体征监测系统，利用无监督学习从 RGB 视频中提取周期信号，如 blood volume pulse 和 respiration，无需标注数据。该框架基于信号的周期性和有限带宽假设，通过鼓励功率谱的稀疏性和批次间方差，成功学习周期信号的视觉特征。实验结果显示，SiNC+ 能在非 rPPG 专用未标注视频上训练稳健的脉搏率估计器，并通过调整带宽扩展到呼吸监测，实现个性化自适应信号回归。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Extension of CVPR2023 highlight paper. arXiv admin note: substantial\n  text overlap with arXiv:2303.07944",
      "pdf_url": "http://arxiv.org/pdf/2404.13449v1",
      "published_date": "2024-04-20 19:17:40 UTC",
      "updated_date": "2024-04-20 19:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:06:42.600942"
    },
    {
      "arxiv_id": "2404.14450v1",
      "title": "GraphMatcher: A Graph Representation Learning Approach for Ontology Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Sefika Efeoglu"
      ],
      "abstract": "Ontology matching is defined as finding a relationship or correspondence\nbetween two or more entities in two or more ontologies. To solve the\ninteroperability problem of the domain ontologies, semantically similar\nentities in these ontologies must be found and aligned before merging them.\nGraphMatcher, developed in this study, is an ontology matching system using a\ngraph attention approach to compute higher-level representation of a class\ntogether with its surrounding terms. The GraphMatcher has obtained remarkable\nresults in in the Ontology Alignment Evaluation Initiative (OAEI) 2022\nconference track. Its codes are available at\n~\\url{https://github.com/sefeoglu/gat_ontology_matching}.",
      "tldr_zh": "本研究提出GraphMatcher，一种基于图表示学习(Graph Representation Learning)的本体匹配(Ontology Matching)方法，通过图注意力(Graph Attention)机制计算类的更高层表示，包括其周围术语，以解决领域本体互操作性问题。GraphMatcher系统能够识别并对齐语义相似的实体，从而实现本体的有效合并。在Ontology Alignment Evaluation Initiative (OAEI) 2022 conference track中，GraphMatcher取得了显著的性能提升，其代码已在GitHub上开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The 17th International Workshop on Ontology Matching, The 21st\n  International Semantic Web Conference (ISWC) 2022, 23 October 2022, Hangzhou,\n  China",
      "pdf_url": "http://arxiv.org/pdf/2404.14450v1",
      "published_date": "2024-04-20 18:30:17 UTC",
      "updated_date": "2024-04-20 18:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:06:52.756444"
    },
    {
      "arxiv_id": "2404.17593v1",
      "title": "A Continual Relation Extraction Approach for Knowledge Graph Completeness",
      "title_zh": "翻译失败",
      "authors": [
        "Sefika Efeoglu"
      ],
      "abstract": "Representing unstructured data in a structured form is most significant for\ninformation system management to analyze and interpret it. To do this, the\nunstructured data might be converted into Knowledge Graphs, by leveraging an\ninformation extraction pipeline whose main tasks are named entity recognition\nand relation extraction. This thesis aims to develop a novel continual relation\nextraction method to identify relations (interconnections) between entities in\na data stream coming from the real world. Domain-specific data of this thesis\nis corona news from German and Austrian newspapers.",
      "tldr_zh": "这篇论文提出了一种用于提升知识图谱完整性的持续关系提取（Continual Relation Extraction）方法，旨在将非结构化数据转化为结构化形式，以便于信息系统的分析和解释。该方法通过信息提取管道，包括命名实体识别（named entity recognition）和关系提取（relation extraction），处理来自真实世界数据流的实体间关系。具体应用在本论文中聚焦于德国和奥地利报纸的冠状病毒新闻数据，从而为动态构建和完善Knowledge Graphs提供新型解决方案。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "Published at TPDL 2022",
      "pdf_url": "http://arxiv.org/pdf/2404.17593v1",
      "published_date": "2024-04-20 18:15:52 UTC",
      "updated_date": "2024-04-20 18:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:07:04.486774"
    },
    {
      "arxiv_id": "2404.13434v1",
      "title": "Nested-TNT: Hierarchical Vision Transformers with Multi-Scale Feature Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Yuang Liu",
        "Zhiheng Qiu",
        "Xiaokai Qin"
      ],
      "abstract": "Transformer has been applied in the field of computer vision due to its\nexcellent performance in natural language processing, surpassing traditional\nconvolutional neural networks and achieving new state-of-the-art. ViT divides\nan image into several local patches, known as \"visual sentences\". However, the\ninformation contained in the image is vast and complex, and focusing only on\nthe features at the \"visual sentence\" level is not enough. The features between\nlocal patches should also be taken into consideration. In order to achieve\nfurther improvement, the TNT model is proposed, whose algorithm further divides\nthe image into smaller patches, namely \"visual words,\" achieving more accurate\nresults. The core of Transformer is the Multi-Head Attention mechanism, and\ntraditional attention mechanisms ignore interactions across different attention\nheads. In order to reduce redundancy and improve utilization, we introduce the\nnested algorithm and apply the Nested-TNT to image classification tasks. The\nexperiment confirms that the proposed model has achieved better classification\nperformance over ViT and TNT, exceeding 2.25%, 1.1% on dataset CIFAR10 and\n2.78%, 0.25% on dataset FLOWERS102 respectively.",
      "tldr_zh": "这篇论文提出了 Nested-TNT 模型，一种分层视觉 Transformer，旨在通过多尺度特征处理提升图像分类性能。模型在 ViT 的基础上继承 TNT 的方法，将图像进一步细分为更小的 \"visual words\"，并引入 nested algorithm 来优化 Multi-Head Attention 机制，减少冗余并加强不同注意力头之间的交互。实验结果显示，Nested-TNT 在 CIFAR10 数据集上比 ViT 和 TNT 分别提高了 2.25% 和 1.1% 的分类准确率，在 FLOWERS102 数据集上则分别提高了 2.78% 和 0.25%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13434v1",
      "published_date": "2024-04-20 17:56:14 UTC",
      "updated_date": "2024-04-20 17:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:07:19.799787"
    },
    {
      "arxiv_id": "2404.13428v1",
      "title": "Text-dependent Speaker Verification (TdSV) Challenge 2024: Challenge Evaluation Plan",
      "title_zh": "翻译失败",
      "authors": [
        "Zeinali Hossein",
        "Lee Kong Aik",
        "Alam Jahangir",
        "Burget Lukas"
      ],
      "abstract": "This document outlines the Text-dependent Speaker Verification (TdSV)\nChallenge 2024, which centers on analyzing and exploring novel approaches for\ntext-dependent speaker verification. The primary goal of this challenge is to\nmotive participants to develop single yet competitive systems, conduct thorough\nanalyses, and explore innovative concepts such as multi-task learning,\nself-supervised learning, few-shot learning, and others, for text-dependent\nspeaker verification.",
      "tldr_zh": "本文概述了 Text-dependent Speaker Verification (TdSV) Challenge 2024 的评估计划，该挑战赛专注于文本依赖的说话人验证领域。挑战的目标是激励参与者开发简单却具有竞争力的系统，并进行深入分析。重点探索创新概念，如 multi-task learning、self-supervised learning 和 few-shot learning，以推动该领域的技术进步。通过此挑战，参与者有望提出新方法，提升说话人验证的性能和效率。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13428v1",
      "published_date": "2024-04-20 17:26:59 UTC",
      "updated_date": "2024-04-20 17:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:07:33.266752"
    },
    {
      "arxiv_id": "2404.13425v3",
      "title": "Enhancing Adversarial Robustness of Vision-Language Models through Low-Rank Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Ji",
        "Yue Liu",
        "Zhicheng Zhang",
        "Zhao Zhang",
        "Yuting Zhao",
        "Xiaoshuai Hao",
        "Gang Zhou",
        "Xingwei Zhang",
        "Xiaolong Zheng"
      ],
      "abstract": "Vision-Language Models (VLMs) play a crucial role in the advancement of\nArtificial General Intelligence (AGI). As AGI rapidly evolves, addressing\nsecurity concerns has emerged as one of the most significant challenges for\nVLMs. In this paper, we present extensive experiments that expose the\nvulnerabilities of conventional adaptation methods for VLMs, highlighting\nsignificant security risks. Moreover, as VLMs grow in size, the application of\ntraditional adversarial adaptation techniques incurs substantial computational\ncosts. To address these issues, we propose a parameter-efficient adversarial\nadaptation method called \\textbf{\\textit{AdvLoRA}} based on Low-Rank\nAdaptation. We investigate and reveal the inherent low-rank properties involved\nin adversarial adaptation for VLMs. Different from LoRA, we enhance the\nefficiency and robustness of adversarial adaptation by introducing a novel\nreparameterization method that leverages parameter clustering and alignment.\nAdditionally, we propose an adaptive parameter update strategy to further\nbolster robustness. These innovations enable our AdvLoRA to mitigate issues\nrelated to model security and resource wastage. Extensive experiments confirm\nthe effectiveness and efficiency of AdvLoRA.",
      "tldr_zh": "本文研究了视觉语言模型 (VLMs) 在人工智能通用智能 (AGI) 发展中的安全漏洞，揭示了传统适应方法的显著风险和高计算成本问题。为解决这些问题，作者提出了一种参数高效的对抗适应方法 AdvLoRA，基于 Low-Rank Adaptation，通过引入新型重参数化技术（利用参数聚类和对齐）以及自适应参数更新策略来提升模型的鲁棒性和效率。实验结果显示，AdvLoRA 显著改善了 VLMs 的对抗鲁棒性，同时减少了资源浪费。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13425v3",
      "published_date": "2024-04-20 17:19:54 UTC",
      "updated_date": "2025-02-20 02:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:07:44.914149"
    },
    {
      "arxiv_id": "2404.13421v1",
      "title": "MultiConfederated Learning: Inclusive Non-IID Data handling with Decentralized Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Duchesne",
        "Kaiwen Zhang",
        "Chamseddine Talhi"
      ],
      "abstract": "Federated Learning (FL) has emerged as a prominent privacy-preserving\ntechnique for enabling use cases like confidential clinical machine learning.\nFL operates by aggregating models trained by remote devices which owns the\ndata. Thus, FL enables the training of powerful global models using\ncrowd-sourced data from a large number of learners, without compromising their\nprivacy. However, the aggregating server is a single point of failure when\ngenerating the global model. Moreover, the performance of the model suffers\nwhen the data is not independent and identically distributed (non-IID data) on\nall remote devices. This leads to vastly different models being aggregated,\nwhich can reduce the performance by as much as 50% in certain scenarios.\n  In this paper, we seek to address the aforementioned issues while retaining\nthe benefits of FL. We propose MultiConfederated Learning: a decentralized FL\nframework which is designed to handle non-IID data. Unlike traditional FL,\nMultiConfederated Learning will maintain multiple models in parallel (instead\nof a single global model) to help with convergence when the data is non-IID.\nWith the help of transfer learning, learners can converge to fewer models. In\norder to increase adaptability, learners are allowed to choose which updates to\naggregate from their peers.",
      "tldr_zh": "该论文针对Federated Learning (FL)中的单点故障和non-IID数据导致的性能下降问题（如性能降低高达50%），提出了一种去中心化的框架MultiConfederated Learning。 该框架通过并行维护多个模型并结合transfer learning，帮助学习者在non-IID数据环境下实现更好的收敛，并允许学习者自主选择从同伴(peers)聚合更新，从而提升整体适应性和鲁棒性。 总体上，该方法保留了FL的隐私保护优势，为处理分布式数据提供了更具包容性的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13421v1",
      "published_date": "2024-04-20 16:38:26 UTC",
      "updated_date": "2024-04-20 16:38:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:07:57.050663"
    },
    {
      "arxiv_id": "2404.13417v1",
      "title": "Efficient and Concise Explanations for Object Detection with Gaussian-Class Activation Mapping Explainer",
      "title_zh": "翻译失败",
      "authors": [
        "Quoc Khanh Nguyen",
        "Truong Thanh Hung Nguyen",
        "Vo Thanh Khang Nguyen",
        "Van Binh Truong",
        "Tuong Phan",
        "Hung Cao"
      ],
      "abstract": "To address the challenges of providing quick and plausible explanations in\nExplainable AI (XAI) for object detection models, we introduce the Gaussian\nClass Activation Mapping Explainer (G-CAME). Our method efficiently generates\nconcise saliency maps by utilizing activation maps from selected layers and\napplying a Gaussian kernel to emphasize critical image regions for the\npredicted object. Compared with other Region-based approaches, G-CAME\nsignificantly reduces explanation time to 0.5 seconds without compromising the\nquality. Our evaluation of G-CAME, using Faster-RCNN and YOLOX on the MS-COCO\n2017 dataset, demonstrates its ability to offer highly plausible and faithful\nexplanations, especially in reducing the bias on tiny object detection.",
      "tldr_zh": "本研究提出Gaussian-Class Activation Mapping Explainer (G-CAME)，一种高效方法，用于为对象检测模型提供快速且合理的解释，以解决Explainable AI (XAI)中的挑战。G-CAME通过利用选定层面的激活映射并应用Gaussian核来突出预测对象的关键图像区域，从而将解释时间缩短至0.5秒，同时保持解释质量。实验在MS-COCO 2017数据集上使用Faster-RCNN和YOLOX模型进行评估，结果显示G-CAME显著减少了对微小对象的检测偏差，提供高度可靠和忠实的解释。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Canadian AI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.13417v1",
      "published_date": "2024-04-20 16:11:47 UTC",
      "updated_date": "2024-04-20 16:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:08:08.239705"
    },
    {
      "arxiv_id": "2404.13402v1",
      "title": "Intrusion Detection at Scale with the Assistance of a Command-line Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jiongliang Lin",
        "Yiwen Guo",
        "Hao Chen"
      ],
      "abstract": "Intrusion detection is a long standing and crucial problem in security. A\nsystem capable of detecting intrusions automatically is on great demand in\nenterprise security solutions. Existing solutions rely heavily on hand-crafted\nrules designed by security operators, which suffer from high false negative\nrates and poor generalization ability to new, zero-day attacks at scale. AI and\nmachine learning offer promising solutions to address the issues, by inspecting\nabnormal user behaviors intelligently and automatically from data. However,\nexisting learning-based intrusion detection systems in the literature are\nmostly designed for small data, and they lack the ability to leverage the power\nof big data in cloud environments. In this paper, we target at this problem and\nintroduce an intrusion detection system which incorporates large-scale\npre-training, so as to train a large language model based on tens of millions\nof command lines for AI-based intrusion detection. Experiments performed on 30\nmillion training samples and 10 million test samples verify the effectiveness\nof our solution.",
      "tldr_zh": "这篇论文针对入侵检测领域的关键挑战，指出现有基于手工规则的方法存在高假阴性率和对零日攻击的泛化能力不足的问题。作者提出了一种结合大规模预训练的入侵检测系统，利用大型语言模型（Large Language Model）分析数千万命令行数据，实现对大规模大数据环境的智能检测。实验结果显示，该系统在3000万训练样本和1000万测试样本上表现出色，验证了其有效性，为AI驱动的入侵检测提供了可扩展解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by IEEE/IFIP International Conference on Dependable Systems\n  and Networks (DSN), industry track",
      "pdf_url": "http://arxiv.org/pdf/2404.13402v1",
      "published_date": "2024-04-20 15:04:25 UTC",
      "updated_date": "2024-04-20 15:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:08:20.855440"
    },
    {
      "arxiv_id": "2404.13397v1",
      "title": "Retrieval-Augmented Generation-based Relation Extraction",
      "title_zh": "基于检索增强生成的关系抽取",
      "authors": [
        "Sefika Efeoglu",
        "Adrian Paschke"
      ],
      "abstract": "Information Extraction (IE) is a transformative process that converts\nunstructured text data into a structured format by employing entity and\nrelation extraction (RE) methodologies. The identification of the relation\nbetween a pair of entities plays a crucial role within this framework. Despite\nthe existence of various techniques for relation extraction, their efficacy\nheavily relies on access to labeled data and substantial computational\nresources. In addressing these challenges, Large Language Models (LLMs) emerge\nas promising solutions; however, they might return hallucinating responses due\nto their own training data. To overcome these limitations, Retrieved-Augmented\nGeneration-based Relation Extraction (RAG4RE) in this work is proposed,\noffering a pathway to enhance the performance of relation extraction tasks.\n  This work evaluated the effectiveness of our RAG4RE approach utilizing\ndifferent LLMs. Through the utilization of established benchmarks, such as\nTACRED, TACREV, Re-TACRED, and SemEval RE datasets, our aim is to\ncomprehensively evaluate the efficacy of our RAG4RE approach. In particularly,\nwe leverage prominent LLMs including Flan T5, Llama2, and Mistral in our\ninvestigation. The results of our study demonstrate that our RAG4RE approach\nsurpasses performance of traditional RE approaches based solely on LLMs,\nparticularly evident in the TACRED dataset and its variations. Furthermore, our\napproach exhibits remarkable performance compared to previous RE methodologies\nacross both TACRED and TACREV datasets, underscoring its efficacy and potential\nfor advancing RE tasks in natural language processing.",
      "tldr_zh": "本研究针对信息提取（IE）中的关系提取（RE）任务，提出了一种基于检索增强生成（Retrieval-Augmented Generation）的框架RAG4RE，以解决传统方法依赖标注数据和计算资源的问题，同时缓解大语言模型（LLMs）可能产生的幻觉响应。RAG4RE 通过结合检索机制增强LLMs的表现，利用Flan T5、Llama2和Mistral等模型，在TACRED、TACREV、Re-TACRED和SemEval数据集上进行评估。实验结果显示，该方法在TACRED及其变体数据集上比纯LLMs方法提升了性能，并在整体上超过了现有RE方法，展示了其在自然语言处理中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to Semantic Web Journal. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2404.13397v1",
      "published_date": "2024-04-20 14:42:43 UTC",
      "updated_date": "2024-04-20 14:42:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:08:32.157062"
    },
    {
      "arxiv_id": "2406.06533v1",
      "title": "Pragmatic Formal Verification Methodology for Clock Domain Crossing (CDC)",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Kumar",
        "Muhammad Ul Haque Khan",
        "Bijitendra Mittra"
      ],
      "abstract": "Modern System-on-Chip (SoC) designs are becoming more and more complex due to\nthe technology upscaling. SoC designs often operate on multiple asynchronous\nclock domains, further adding to the complexity of the overall design. To make\nthe devices power efficient, designers take a Globally-Asynchronous\nLocally-Synchronous (GALS) approach that creates multiple asynchronous domains.\nThese Clock Domain Crossings (CDC) are prone to metastability effects, and\nfunctional verification of such CDC is very important to ensure that no bug\nescapes. Conventional verification methods, such as register transfer level\n(RTL) simulations and static timing analysis, are not enough to address these\nCDC issues, which may lead to verification gaps. Additionally, identifying\nthese CDC-related bugs is very time-consuming and is one of the most common\nreasons for costly silicon re-spins. This paper is focused on the development\nof a pragmatic formal verification methodology to minimize the CDC issues by\nexercising Metastability Injection (MSI) in different CDC paths.",
      "tldr_zh": "现代 SoC 设计因技术升级和多异步时钟域而日益复杂，其中 Clock Domain Crossing (CDC) 易导致 metastability 效应和功能 bug。传统方法如 Register Transfer Level (RTL) 模拟和静态时序分析无法充分解决这些问题，可能造成验证漏洞和昂贵的硅重制。本文提出一种实用的形式验证方法，通过在不同 CDC 路径上应用 Metastability Injection (MSI)，有效最小化 CDC 相关问题，提高设计的可靠性和效率。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Published in DVCon Europe 2023",
      "pdf_url": "http://arxiv.org/pdf/2406.06533v1",
      "published_date": "2024-04-20 13:17:25 UTC",
      "updated_date": "2024-04-20 13:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:08:44.328935"
    },
    {
      "arxiv_id": "2404.15371v1",
      "title": "Efficient Verification of a RADAR SoC Using Formal and Simulation-Based Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Kumar",
        "Mark Litterick",
        "Samuele Candido"
      ],
      "abstract": "As the demand for Internet of Things (IoT) and Human-to-Machine Interaction\n(HMI) increases, modern System-on-Chips (SoCs) offering such solutions are\nbecoming increasingly complex. This intricate design poses significant\nchallenges for verification, particularly when time-to-market is a crucial\nfactor for consumer electronics products. This paper presents a case study\nbased on our work to verify a complex Radio Detection And Ranging (RADAR) based\nSoC that performs on-chip sensing of human motion with millimetre accuracy. We\nleverage both formal and simulation-based methods to complement each other and\nachieve verification sign-off with high confidence. While employing a\nrequirements-driven flow approach, we demonstrate the use of different\nverification methods to cater to multiple requirements and highlight our\nknow-how from the project. Additionally, we used Machine Learning (ML) based\nmethods, specifically the Xcelium ML tool from Cadence, to improve verification\nthroughput.",
      "tldr_zh": "这篇论文讨论了使用形式化（Formal）和基于模拟（Simulation-Based）方法来高效验证一个复杂的 RADAR SoC，以应对 IoT 和 HMI 需求的增长及其带来的验证挑战。作者通过一个基于需求驱动的流程（Requirements-Driven Flow），结合多种验证技术，包括 Machine Learning (ML) 工具如 Cadence 的 Xcelium ML，来互补验证过程并提高效率。结果显示，这种方法在 RADAR SoC 的案例中实现了高置信度的验证签收，并显著提升了验证吞吐量，为复杂消费电子产品的快速上市提供了实用见解。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Published in DVCon Europe 2023",
      "pdf_url": "http://arxiv.org/pdf/2404.15371v1",
      "published_date": "2024-04-20 13:16:55 UTC",
      "updated_date": "2024-04-20 13:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:08:58.505951"
    },
    {
      "arxiv_id": "2405.01572v1",
      "title": "A Semi-Formal Verification Methodology for Efficient Configuration Coverage of Highly Configurable Digital Designs",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Kumar",
        "Sebastian Simon"
      ],
      "abstract": "Nowadays, a majority of System-on-Chips (SoCs) make use of Intellectual\nProperty (IP) in order to shorten development cycles. When such IPs are\ndeveloped, one of the main focuses lies in the high configurability of the\ndesign. This flexibility on the design side introduces the challenge of\ncovering a huge state space of IP configurations on the verification side to\nensure the functional correctness under every possible parameter setting. The\nvast number of possibilities does not allow a brute-force approach, and\ntherefore, only a selected number of settings based on typical and extreme\nassumptions are usually verified. Especially in automotive applications, which\nneed to follow the ISO 26262 functional safety standard, the requirement of\ncovering all significant variants needs to be fulfilled in any case.\nState-of-the-Art existing verification techniques such as simulation-based\nverification and formal verification have challenges such as time-space\nexplosion and state-space explosion respectively and therefore, lack behind in\nverifying highly configurable digital designs efficiently. This paper is\nfocused on a semi-formal verification methodology for efficient configuration\ncoverage of highly configurable digital designs. The methodology focuses on\nreduced runtime based on simulative and formal methods that allow high\nconfiguration coverage. The paper also presents the results when the developed\nmethodology was applied on a highly configurable microprocessor IP and\ndiscusses the gained benefits.",
      "tldr_zh": "该论文针对高度可配置数字设计（如 System-on-Chips (SoCs) 中的 Intellectual Property (IP)）的验证挑战，提出了一种半形式验证(semi-formal verification)方法，以高效覆盖庞大的配置空间(configuration coverage)。该方法结合模拟和形式技术，减少运行时间和状态空间爆炸问题，同时确保符合如 ISO 26262 功能安全标准的要求。实验结果显示，在应用于高度可配置的微处理器 IP 时，该方法显著提高了验证效率，并提供了实际益处。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.SE",
      "comment": "Published in DVCon U.S. 2021",
      "pdf_url": "http://arxiv.org/pdf/2405.01572v1",
      "published_date": "2024-04-20 12:18:47 UTC",
      "updated_date": "2024-04-20 12:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:09:08.718666"
    },
    {
      "arxiv_id": "2404.13362v1",
      "title": "Semantically Corrected Amharic Automatic Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Samuael Adnew",
        "Paul Pu Liang"
      ],
      "abstract": "Automatic Speech Recognition (ASR) can play a crucial role in enhancing the\naccessibility of spoken languages worldwide. In this paper, we build a set of\nASR tools for Amharic, a language spoken by more than 50 million people\nprimarily in eastern Africa. Amharic is written in the Ge'ez script, a sequence\nof graphemes with spacings denoting word boundaries. This makes computational\nprocessing of Amharic challenging since the location of spacings can\nsignificantly impact the meaning of formed sentences. We find that existing\nbenchmarks for Amharic ASR do not account for these spacings and only measure\nindividual grapheme error rates, leading to significantly inflated measurements\nof in-the-wild performance. In this paper, we first release corrected\ntranscriptions of existing Amharic ASR test datasets, enabling the community to\naccurately evaluate progress. Furthermore, we introduce a post-processing\napproach using a transformer encoder-decoder architecture to organize raw ASR\noutputs into a grammatically complete and semantically meaningful Amharic\nsentence. Through experiments on the corrected test dataset, our model enhances\nthe semantic correctness of Amharic speech recognition systems, achieving a\nCharacter Error Rate (CER) of 5.5\\% and a Word Error Rate (WER) of 23.3\\%.",
      "tldr_zh": "这篇论文针对Amharic语言的Automatic Speech Recognition (ASR)系统，构建了相关工具，以解决Ge'ez脚本中空格位置对句子语义的重大影响问题。研究者首先发布了修正后的Amharic ASR测试数据集，纠正了现有基准仅测量grapheme错误率导致的性能评估偏差。接着，他们引入了一个基于transformer encoder-decoder架构的后处理方法，将原始ASR输出组织成语法完整且语义正确的句子，并在实验中实现了5.5%的Character Error Rate (CER)和23.3%的Word Error Rate (WER)。这为提升Amharic语音识别的准确性和实用性提供了重要进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13362v1",
      "published_date": "2024-04-20 12:08:00 UTC",
      "updated_date": "2024-04-20 12:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:09:22.085733"
    },
    {
      "arxiv_id": "2404.13358v1",
      "title": "Music Consistency Models",
      "title_zh": "音乐一致性模型",
      "authors": [
        "Zhengcong Fei",
        "Mingyuan Fan",
        "Junshi Huang"
      ],
      "abstract": "Consistency models have exhibited remarkable capabilities in facilitating\nefficient image/video generation, enabling synthesis with minimal sampling\nsteps. It has proven to be advantageous in mitigating the computational burdens\nassociated with diffusion models. Nevertheless, the application of consistency\nmodels in music generation remains largely unexplored. To address this gap, we\npresent Music Consistency Models (\\texttt{MusicCM}), which leverages the\nconcept of consistency models to efficiently synthesize mel-spectrogram for\nmusic clips, maintaining high quality while minimizing the number of sampling\nsteps. Building upon existing text-to-music diffusion models, the\n\\texttt{MusicCM} model incorporates consistency distillation and adversarial\ndiscriminator training. Moreover, we find it beneficial to generate extended\ncoherent music by incorporating multiple diffusion processes with shared\nconstraints. Experimental results reveal the effectiveness of our model in\nterms of computational efficiency, fidelity, and naturalness. Notable,\n\\texttt{MusicCM} achieves seamless music synthesis with a mere four sampling\nsteps, e.g., only one second per minute of the music clip, showcasing the\npotential for real-time application.",
      "tldr_zh": "这篇论文提出 Music Consistency Models (MusicCM)，将 Consistency models 应用于音乐生成领域，以高效合成 mel-spectrogram，同时保持高音频质量并减少采样步骤。基于现有的 text-to-music diffusion models，该模型整合了 consistency distillation 和 adversarial discriminator training，并通过多个共享约束的 diffusion processes 生成更长的连贯音乐。实验结果显示，MusicCM 在计算效率、音频保真度和自然性方面表现出色，仅需 4 个采样步骤即可实现无缝音乐合成，例如每分钟音乐只需 1 秒，展示了其在实时应用的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13358v1",
      "published_date": "2024-04-20 11:52:30 UTC",
      "updated_date": "2024-04-20 11:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:09:35.657968"
    },
    {
      "arxiv_id": "2404.16870v1",
      "title": "LEMDA: A Novel Feature Engineering Method for Intrusion Detection in IoT Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Ghubaish",
        "Zebo Yang",
        "Aiman Erbad",
        "Raj Jain"
      ],
      "abstract": "Intrusion detection systems (IDS) for the Internet of Things (IoT) systems\ncan use AI-based models to ensure secure communications. IoT systems tend to\nhave many connected devices producing massive amounts of data with high\ndimensionality, which requires complex models. Complex models have notorious\nproblems such as overfitting, low interpretability, and high computational\ncomplexity. Adding model complexity penalty (i.e., regularization) can ease\noverfitting, but it barely helps interpretability and computational efficiency.\nFeature engineering can solve these issues; hence, it has become critical for\nIDS in large-scale IoT systems to reduce the size and dimensionality of data,\nresulting in less complex models with excellent performance, smaller data\nstorage, and fast detection. This paper proposes a new feature engineering\nmethod called LEMDA (Light feature Engineering based on the Mean Decrease in\nAccuracy). LEMDA applies exponential decay and an optional sensitivity factor\nto select and create the most informative features. The proposed method has\nbeen evaluated and compared to other feature engineering methods using three\nIoT datasets and four AI/ML models. The results show that LEMDA improves the F1\nscore performance of all the IDS models by an average of 34% and reduces the\naverage training and detection times in most cases.",
      "tldr_zh": "这篇论文针对物联网 (IoT) 系统中的入侵检测系统 (IDS)，提出了一种新型特征工程方法 LEMDA (Light feature Engineering based on the Mean Decrease in Accuracy)，以解决高维度数据导致的模型过拟合、低可解释性和高计算复杂度问题。LEMDA 通过应用指数衰减和可选敏感性因子来选择和创建最具信息性的特征，从而减少数据规模并简化模型。实验在三个 IoT 数据集和四个 AI/ML 模型上进行，结果显示 LEMDA 平均提高了 F1 score 34%，并在大多数情况下降低了训练和检测时间。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16870v1",
      "published_date": "2024-04-20 11:11:47 UTC",
      "updated_date": "2024-04-20 11:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:09:47.680817"
    },
    {
      "arxiv_id": "2404.13347v1",
      "title": "Augmenting Safety-Critical Driving Scenarios while Preserving Similarity to Expert Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Hamidreza Mirkhani",
        "Behzad Khamidehi",
        "Kasra Rezaee"
      ],
      "abstract": "Trajectory augmentation serves as a means to mitigate distributional shift in\nimitation learning. However, imitating trajectories that inadequately represent\nthe original expert data can result in undesirable behaviors, particularly in\nsafety-critical scenarios. We propose a trajectory augmentation method designed\nto maintain similarity with expert trajectory data. To accomplish this, we\nfirst cluster trajectories to identify minority yet safety-critical groups.\nThen, we combine the trajectories within the same cluster through geometrical\ntransformation to create new trajectories. These trajectories are then added to\nthe training dataset, provided that they meet our specified safety-related\ncriteria. Our experiments exhibit that training an imitation learning model\nusing these augmented trajectories can significantly improve closed-loop\nperformance.",
      "tldr_zh": "该研究针对模仿学习(imitation learning)中的分布偏移问题，提出了一种轨迹增强(trajectory augmentation)方法，以保持新轨迹与专家轨迹(expert trajectories)的相似性，同时专注于安全关键驾驶场景。方法首先通过聚类(cluster trajectories)识别出少数但关键的安全群体，然后利用几何变换(geometrical transformation)将同一聚类中的轨迹组合生成新轨迹，并仅在满足指定安全标准后将其添加到训练数据集。实验结果显示，使用这些增强轨迹训练的模型显著提升了闭环性能(closed-loop performance)。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to 35th IEEE Intelligent Vehicles Symposium, 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.13347v1",
      "published_date": "2024-04-20 11:05:47 UTC",
      "updated_date": "2024-04-20 11:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:09:58.841180"
    },
    {
      "arxiv_id": "2404.13344v2",
      "title": "GRANOLA: Adaptive Normalization for Graph Neural Networks",
      "title_zh": "GRANOLA: 用于图神经",
      "authors": [
        "Moshe Eliasof",
        "Beatrice Bevilacqua",
        "Carola-Bibiane Schönlieb",
        "Haggai Maron"
      ],
      "abstract": "In recent years, significant efforts have been made to refine the design of\nGraph Neural Network (GNN) layers, aiming to overcome diverse challenges, such\nas limited expressive power and oversmoothing. Despite their widespread\nadoption, the incorporation of off-the-shelf normalization layers like\nBatchNorm or InstanceNorm within a GNN architecture may not effectively capture\nthe unique characteristics of graph-structured data, potentially reducing the\nexpressive power of the overall architecture. Moreover, existing graph-specific\nnormalization layers often struggle to offer substantial and consistent\nbenefits. In this paper, we propose GRANOLA, a novel graph-adaptive\nnormalization layer. Unlike existing normalization layers, GRANOLA normalizes\nnode features by adapting to the specific characteristics of the graph,\nparticularly by generating expressive representations of its neighborhood\nstructure, obtained by leveraging the propagation of Random Node Features (RNF)\nin the graph. We present theoretical results that support our design choices.\nOur extensive empirical evaluation of various graph benchmarks underscores the\nsuperior performance of GRANOLA over existing normalization techniques.\nFurthermore, GRANOLA emerges as the top-performing method among all baselines\nwithin the same time complexity of Message Passing Neural Networks (MPNNs).",
      "tldr_zh": "该研究针对图神经网络 (GNNs) 的标准化问题提出 GRANOLA，一种新型的自适应标准化层，以解决现有方法如 BatchNorm 或 InstanceNorm 无法有效捕捉图结构数据特性的局限性。GRANOLA 通过利用 Random Node Features (RNF) 的传播生成邻域结构的表达表示，从而动态标准化节点特征，并提供了理论支持来验证其设计。实验结果显示，GRANOLA 在各种图基准上优于现有标准化技术，并在与 Message Passing Neural Networks (MPNNs) 相同的时间复杂度下表现出最佳性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.13344v2",
      "published_date": "2024-04-20 10:44:13 UTC",
      "updated_date": "2024-10-31 23:12:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:10:11.066621"
    },
    {
      "arxiv_id": "2404.13343v1",
      "title": "UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Ana-Cristina Rogoz",
        "Radu Tudor Ionescu"
      ],
      "abstract": "This work explores a novel data augmentation method based on Large Language\nModels (LLMs) for predicting item difficulty and response time of retired USMLE\nMultiple-Choice Questions (MCQs) in the BEA 2024 Shared Task. Our approach is\nbased on augmenting the dataset with answers from zero-shot LLMs (Falcon,\nMeditron, Mistral) and employing transformer-based models based on six\nalternative feature combinations. The results suggest that predicting the\ndifficulty of questions is more challenging. Notably, our top performing\nmethods consistently include the question text, and benefit from the\nvariability of LLM answers, highlighting the potential of LLMs for improving\nautomated assessment in medical licensing exams. We make our code available\nhttps://github.com/ana-rogoz/BEA-2024.",
      "tldr_zh": "本研究提出UnibucLLM框架，利用大型语言模型（LLMs）进行数据增强，以自动预测USMLE多项选择题（MCQs）的项目难度和响应时间。具体方法包括使用零样本LLMs（如Falcon、Meditron和Mistral）生成答案增强数据集，并结合基于变压器的模型和六种特征组合进行预测。结果显示，预测难度比响应时间更具挑战性，但纳入问题文本和LLMs答案变异性的方法表现出色，突显了LLMs在医疗许可考试自动评估中的潜力。该框架的代码已开源（https://github.com/ana-rogoz/BEA-2024）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at BEA 2024 (NAACL Workshop)",
      "pdf_url": "http://arxiv.org/pdf/2404.13343v1",
      "published_date": "2024-04-20 10:41:02 UTC",
      "updated_date": "2024-04-20 10:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:10:23.154567"
    },
    {
      "arxiv_id": "2404.13340v1",
      "title": "Large Language Models as Test Case Generators: Performance Evaluation and Enhancement",
      "title_zh": "大型语言模型作为测试用例生成器：性能评估和增强",
      "authors": [
        "Kefan Li",
        "Yuan Yuan"
      ],
      "abstract": "Code generation with Large Language Models (LLMs) has been extensively\nstudied and achieved remarkable progress. As a complementary aspect to code\ngeneration, test case generation is of crucial importance in ensuring the\nquality and reliability of code. However, using LLMs as test case generators\nhas been much less explored. Current research along this line primarily focuses\non enhancing code generation with assistance from test cases generated by LLMs,\nwhile the performance of LLMs in test case generation alone has not been\ncomprehensively examined. To bridge this gap, we conduct extensive experiments\nto study how well LLMs can generate high-quality test cases. We find that as\nthe problem difficulty increases, state-of-the-art LLMs struggle to generate\ncorrect test cases, largely due to their inherent limitations in computation\nand reasoning. To mitigate this issue, we further propose a multi-agent\nframework called \\emph{TestChain} that decouples the generation of test inputs\nand test outputs. Notably, TestChain uses a ReAct format conversation chain for\nLLMs to interact with a Python interpreter in order to provide more accurate\ntest outputs. Our results indicate that TestChain outperforms the baseline by a\nlarge margin. Particularly, in terms of the accuracy of test cases, TestChain\nusing GPT-4 as the backbone achieves a 13.84\\% improvement over the baseline on\nthe LeetCode-hard dataset.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在生成测试用例方面的性能，发现现有模型在处理难度较高的任务时，由于计算和推理能力的限制，难以产生高质量的测试用例。作者通过广泛实验证明，LLMs 在复杂问题上表现不佳，从而影响代码质量的保障。针对这一问题，他们提出了一种多智能体框架 TestChain，将测试输入和输出生成分开，并使用 ReAct 格式的对话链让 LLMs 与 Python 解释器交互，以提升测试输出准确性。实验结果显示，TestChain 相比基线模型有显著改进，使用 GPT-4 作为骨干模型时，在 LeetCode-hard 数据集上测试用例准确性提高了 13.84%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13340v1",
      "published_date": "2024-04-20 10:27:01 UTC",
      "updated_date": "2024-04-20 10:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:10:35.624842"
    },
    {
      "arxiv_id": "2404.13327v2",
      "title": "Comparative Analysis on Snowmelt-Driven Streamflow Forecasting Using Machine Learning Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Ukesh Thapa",
        "Bipun Man Pati",
        "Samit Thapa",
        "Dhiraj Pyakurel",
        "Anup Shrestha"
      ],
      "abstract": "The rapid advancement of machine learning techniques has led to their\nwidespread application in various domains including water resources. However,\nsnowmelt modeling remains an area that has not been extensively explored. In\nthis study, we propose a state-of-the-art (SOTA) deep learning sequential\nmodel, leveraging the Temporal Convolutional Network (TCN), for snowmelt-driven\ndischarge modeling in the Himalayan basin of the Hindu Kush Himalayan Region.\nTo evaluate the performance of our proposed model, we conducted a comparative\nanalysis with other popular models including Support Vector Regression (SVR),\nLong Short Term Memory (LSTM), and Transformer. Furthermore, Nested\ncross-validation (CV) is used with five outer folds and three inner folds, and\nhyper-parameter tuning is performed on the inner folds. To evaluate the\nperformance of the model mean absolute error (MAE), root mean square error\n(RMSE), R square ($R^{2}$), Kling-Gupta Efficiency (KGE), and Nash-Sutcliffe\nEfficiency (NSE) are computed for each outer fold. The average metrics revealed\nthat TCN outperformed the other models, with an average MAE of 0.011, RMSE of\n0.023, $R^{2}$ of 0.991, KGE of 0.992, and NSE of 0.991. The findings of this\nstudy demonstrate the effectiveness of the deep learning model as compared to\ntraditional machine learning approaches for snowmelt-driven streamflow\nforecasting. Moreover, the superior performance of TCN highlights its potential\nas a promising deep learning model for similar hydrological applications.",
      "tldr_zh": "本研究对使用机器学习技术进行雪融驱动的流域预测进行了比较分析，重点提出了一种基于 Temporal Convolutional Network (TCN) 的深度学习模型，用于喜马拉雅盆地的放电建模。研究通过 Nested cross-validation（包括五外折和三内折）以及超参数调整，与其他模型如 Support Vector Regression (SVR)、Long Short Term Memory (LSTM) 和 Transformer 进行比较，评估指标包括 Mean Absolute Error (MAE)、Root Mean Square Error (RMSE)、R²、Kling-Gupta Efficiency (KGE) 和 Nash-Sutcliffe Efficiency (NSE)。结果显示，TCN 表现出色，平均 MAE 为 0.011、RMSE 为 0.023、R² 为 0.991、KGE 为 0.992 和 NSE 为 0.991，显著优于其他模型。该发现证明了深度学习模型在雪融驱动流域预测中的有效性，并突显了 TCN 在类似水文应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 4 Tables, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.13327v2",
      "published_date": "2024-04-20 09:02:50 UTC",
      "updated_date": "2024-04-23 05:32:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:10:48.233754"
    },
    {
      "arxiv_id": "2404.13322v3",
      "title": "MergeNet: Knowledge Migration across Heterogeneous Models, Tasks, and Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Kunxi Li",
        "Tianyu Zhan",
        "Kairui Fu",
        "Shengyu Zhang",
        "Kun Kuang",
        "Jiwei Li",
        "Zhou Zhao",
        "Fan Wu",
        "Fei Wu"
      ],
      "abstract": "In this study, we focus on heterogeneous knowledge transfer across entirely\ndifferent model architectures, tasks, and modalities. Existing knowledge\ntransfer methods (e.g., backbone sharing, knowledge distillation) often hinge\non shared elements within model structures or task-specific features/labels,\nlimiting transfers to complex model types or tasks. To overcome these\nchallenges, we present MergeNet, which learns to bridge the gap of parameter\nspaces of heterogeneous models, facilitating the direct interaction,\nextraction, and application of knowledge within these parameter spaces. The\ncore mechanism of MergeNet lies in the parameter adapter, which operates by\nquerying the source model's low-rank parameters and adeptly learning to\nidentify and map parameters into the target model. MergeNet is learned\nalongside both models, allowing our framework to dynamically transfer and adapt\nknowledge relevant to the current stage, including the training trajectory\nknowledge of the source model. Extensive experiments on heterogeneous knowledge\ntransfer demonstrate significant improvements in challenging settings, where\nrepresentative approaches may falter or prove less applicable.",
      "tldr_zh": "本研究针对跨不同模型架构、任务和模态的异构知识转移问题，提出了MergeNet框架，以克服现有方法（如knowledge distillation）依赖共享元素的局限性。MergeNet的核心机制是参数适配器（parameter adapter），它通过查询源模型的低秩参数并学习映射到目标模型，实现知识的直接交互、提取和动态适应，包括源模型的训练轨迹知识。实验结果显示，MergeNet在异构知识转移任务中显著提升了性能，尤其在现有方法失效的复杂场景中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13322v3",
      "published_date": "2024-04-20 08:34:39 UTC",
      "updated_date": "2024-12-25 06:32:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:10:59.031086"
    },
    {
      "arxiv_id": "2404.13320v2",
      "title": "Pixel is a Barrier: Diffusion Models Are More Adversarially Robust Than We Think",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Xue",
        "Yongxin Chen"
      ],
      "abstract": "Adversarial examples for diffusion models are widely used as solutions for\nsafety concerns. By adding adversarial perturbations to personal images,\nattackers can not edit or imitate them easily. However, it is essential to note\nthat all these protections target the latent diffusion model (LDMs), the\nadversarial examples for diffusion models in the pixel space (PDMs) are largely\noverlooked. This may mislead us to think that the diffusion models are\nvulnerable to adversarial attacks like most deep models. In this paper, we show\nnovel findings that: even though gradient-based white-box attacks can be used\nto attack the LDMs, they fail to attack PDMs. This finding is supported by\nextensive experiments of almost a wide range of attacking methods on various\nPDMs and LDMs with different model structures, which means diffusion models are\nindeed much more robust against adversarial attacks. We also find that PDMs can\nbe used as an off-the-shelf purifier to effectively remove the adversarial\npatterns that were generated on LDMs to protect the images, which means that\nmost protection methods nowadays, to some extent, cannot protect our images\nfrom malicious attacks. We hope that our insights will inspire the community to\nrethink the adversarial samples for diffusion models as protection methods and\nmove forward to more effective protection. Codes are available in\nhttps://github.com/xavihart/PDM-Pure.",
      "tldr_zh": "本研究发现，虽然梯度-based的白盒攻击能成功攻击潜在扩散模型 (LDMs)，但对像素空间扩散模型 (PDMs) 无效，这表明扩散模型比我们想象的更具对抗鲁棒性。作者通过广泛实验测试了多种攻击方法在不同 PDMs 和 LDMs 结构上的表现，支持了这一结论。此外，PDMs 可以作为现成的净化器，移除针对 LDMs 生成的对抗模式，从而质疑现有保护方法的有效性。该发现呼吁社区重新审视对抗样本作为图像保护策略，并推动开发更可靠的防护技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13320v2",
      "published_date": "2024-04-20 08:28:43 UTC",
      "updated_date": "2024-05-02 02:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:11:11.552125"
    },
    {
      "arxiv_id": "2404.14445v1",
      "title": "A Multi-Faceted Evaluation Framework for Assessing Synthetic Data Generated by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yefeng Yuan",
        "Yuhong Liu",
        "Liang Cheng"
      ],
      "abstract": "The rapid advancements in generative AI and large language models (LLMs) have\nopened up new avenues for producing synthetic data, particularly in the realm\nof structured tabular formats, such as product reviews. Despite the potential\nbenefits, concerns regarding privacy leakage have surfaced, especially when\npersonal information is utilized in the training datasets. In addition, there\nis an absence of a comprehensive evaluation framework capable of quantitatively\nmeasuring the quality of the generated synthetic data and their utility for\ndownstream tasks. In response to this gap, we introduce SynEval, an open-source\nevaluation framework designed to assess the fidelity, utility, and privacy\npreservation of synthetically generated tabular data via a suite of diverse\nevaluation metrics. We validate the efficacy of our proposed framework -\nSynEval - by applying it to synthetic product review data generated by three\nstate-of-the-art LLMs: ChatGPT, Claude, and Llama. Our experimental findings\nilluminate the trade-offs between various evaluation metrics in the context of\nsynthetic data generation. Furthermore, SynEval stands as a critical instrument\nfor researchers and practitioners engaged with synthetic tabular data,,\nempowering them to judiciously determine the suitability of the generated data\nfor their specific applications, with an emphasis on upholding user privacy.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)生成合成数据的潜在隐私泄露等问题，提出了一种多方面评估框架SynEval，用于评估合成表格数据的保真度(fidelity)、实用性(utility)和隐私保护(privacy preservation)。SynEval通过一系列多样化指标，对由ChatGPT、Claude和Llama生成的合成产品评论数据进行验证，揭示了不同评估指标之间的权衡关系。该框架为研究者和从业者提供了一个开源工具，帮助他们在维护用户隐私的前提下，判断合成数据是否适合下游任务应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 1 figure, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.14445v1",
      "published_date": "2024-04-20 08:08:28 UTC",
      "updated_date": "2024-04-20 08:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:11:24.664204"
    },
    {
      "arxiv_id": "2404.13292v1",
      "title": "Evaluating Subword Tokenization: Alien Subword Composition and OOV Generalization Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Khuyagbaatar Batsuren",
        "Ekaterina Vylomova",
        "Verna Dankers",
        "Tsetsuukhei Delgerbaatar",
        "Omri Uzan",
        "Yuval Pinter",
        "Gábor Bella"
      ],
      "abstract": "The popular subword tokenizers of current language models, such as Byte-Pair\nEncoding (BPE), are known not to respect morpheme boundaries, which affects the\ndownstream performance of the models. While many improved tokenization\nalgorithms have been proposed, their evaluation and cross-comparison is still\nan open problem. As a solution, we propose a combined intrinsic-extrinsic\nevaluation framework for subword tokenization. Intrinsic evaluation is based on\nour new UniMorph Labeller tool that classifies subword tokenization as either\nmorphological or alien. Extrinsic evaluation, in turn, is performed via the\nOut-of-Vocabulary Generalization Challenge 1.0 benchmark, which consists of\nthree newly specified downstream text classification tasks. Our empirical\nfindings show that the accuracy of UniMorph Labeller is 98%, and that, in all\nlanguage models studied (including ALBERT, BERT, RoBERTa, and DeBERTa), alien\ntokenization leads to poorer generalizations compared to morphological\ntokenization for semantic compositionality of word meanings.",
      "tldr_zh": "本文评估了当前子词标记技术（如 Byte-Pair Encoding (BPE)）的不完善问题，因为它们不尊重词素边界，导致语言模型下游性能下降。研究提出一个结合内在和外在评估框架：内在评估使用新工具 UniMorph Labeller 来分类子词标记为形态学（morphological）或外来（alien）标记，其准确率达 98%；外在评估则通过 Out-of-Vocabulary Generalization Challenge 1.0 基准测试三个下游文本分类任务。实验发现，在 ALBERT、BERT、RoBERTa 和 DeBERTa 等模型中，外来标记相比形态学标记会导致更差的词汇外泛化性能，尤其在语义组成性方面。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13292v1",
      "published_date": "2024-04-20 06:49:15 UTC",
      "updated_date": "2024-04-20 06:49:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:11:39.361876"
    },
    {
      "arxiv_id": "2405.02320v1",
      "title": "A SER-based Device Selection Mechanism in Multi-bits Quantization Federated Learning",
      "title_zh": "基于 SER 的",
      "authors": [
        "Pengcheng Sun",
        "Erwu Liu",
        "Rui Wang"
      ],
      "abstract": "The quality of wireless communication will directly affect the performance of\nfederated learning (FL), so this paper analyze the influence of wireless\ncommunication on FL through symbol error rate (SER). In FL system,\nnon-orthogonal multiple access (NOMA) can be used as the basic communication\nframework to reduce the communication congestion and interference caused by\nmultiple users, which takes advantage of the superposition characteristics of\nwireless channels. The Minimum Mean Square Error (MMSE) based serial\ninterference cancellation (SIC) technology is used to recover the gradient of\neach terminal node one by one at the receiving end. In this paper, the gradient\nparameters are quantized into multiple bits to retain more gradient information\nto the maximum extent and to improve the tolerance of transmission errors. On\nthis basis, we designed the SER-based device selection mechanism (SER-DSM) to\nensure that the learning performance is not affected by users with bad\ncommunication conditions, while accommodating as many users as possible to\nparticipate in the learning process, which is inclusive to a certain extent.\nThe experiments show the influence of multi-bit quantization of gradient on FL\nand the necessity and superiority of the proposed SER-based device selection\nmechanism.",
      "tldr_zh": "这篇论文分析了无线通信质量对联邦学习（FL）的性能影响，通过符号错误率（SER）评估其在多用户环境中的作用。论文提出了一种基于非正交多址访问（NOMA）和多位量化的框架，使用最小均方误差（MMSE）基于串行干扰消除（SIC）技术来恢复梯度信息，并设计了基于 SER 的设备选择机制（SER-DSM），以排除通信条件差的用户同时允许更多用户参与。实验结果表明，多位量化能保留更多梯度信息并提升传输错误容忍度，而 SER-DSM 机制显著提高了 FL 的整体性能和包容性。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02320v1",
      "published_date": "2024-04-20 06:27:01 UTC",
      "updated_date": "2024-04-20 06:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:11:50.006790"
    },
    {
      "arxiv_id": "2404.13278v1",
      "title": "Federated Transfer Learning with Task Personalization for Condition Monitoring in Ultrasonic Metal Welding",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmadreza Eslaminia",
        "Yuquan Meng",
        "Klara Nahrstedt",
        "Chenhui Shao"
      ],
      "abstract": "Ultrasonic metal welding (UMW) is a key joining technology with widespread\nindustrial applications. Condition monitoring (CM) capabilities are critically\nneeded in UMW applications because process anomalies significantly deteriorate\nthe joining quality. Recently, machine learning models emerged as a promising\ntool for CM in many manufacturing applications due to their ability to learn\ncomplex patterns. Yet, the successful deployment of these models requires\nsubstantial training data that may be expensive and time-consuming to collect.\nAdditionally, many existing machine learning models lack generalizability and\ncannot be directly applied to new process configurations (i.e., domains). Such\nissues may be potentially alleviated by pooling data across manufacturers, but\ndata sharing raises critical data privacy concerns. To address these\nchallenges, this paper presents a Federated Transfer Learning with Task\nPersonalization (FTL-TP) framework that provides domain generalization\ncapabilities in distributed learning while ensuring data privacy. By\neffectively learning a unified representation from feature space, FTL-TP can\nadapt CM models for clients working on similar tasks, thereby enhancing their\noverall adaptability and performance jointly. To demonstrate the effectiveness\nof FTL-TP, we investigate two distinct UMW CM tasks, tool condition monitoring\nand workpiece surface condition classification. Compared with state-of-the-art\nFL algorithms, FTL-TP achieves a 5.35%--8.08% improvement of accuracy in CM in\nnew target domains. FTL-TP is also shown to perform excellently in challenging\nscenarios involving unbalanced data distributions and limited client fractions.\nFurthermore, by implementing the FTL-TP method on an edge-cloud architecture,\nwe show that this method is both viable and efficient in practice. The FTL-TP\nframework is readily extensible to various other manufacturing applications.",
      "tldr_zh": "该论文针对超声金属焊接(Ultrasonic Metal Welding)中的条件监测(Condition Monitoring)问题，提出Federated Transfer Learning with Task Personalization (FTL-TP)框架，以解决数据隐私和模型泛化挑战。该框架通过联邦学习(Federated Learning)结合任务个性化，实现在分布式环境中学习统一的特征表示，从而帮助客户端适应类似任务并提升性能。在两个UMW监测任务上，FTL-TP相比现有算法准确率提高了5.35%–8.08%，并在不平衡数据和有限客户端场景下表现出色，可扩展至其他制造应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "37 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.13278v1",
      "published_date": "2024-04-20 05:31:59 UTC",
      "updated_date": "2024-04-20 05:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:12:03.265259"
    },
    {
      "arxiv_id": "2404.13274v4",
      "title": "Augmented Object Intelligence: Making the Analog World Interactable with XR-Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Doga Dogan",
        "Eric J. Gonzalez",
        "Karan Ahuja",
        "Ruofei Du",
        "Andrea Colaço",
        "Johnny Lee",
        "Mar Gonzalez-Franco",
        "David Kim"
      ],
      "abstract": "Seamless integration of physical objects as interactive digital entities\nremains a challenge for spatial computing. This paper introduces Augmented\nObject Intelligence (AOI), a novel XR interaction paradigm designed to blur the\nlines between digital and physical by equipping real-world objects with the\nability to interact as if they were digital, where every object has the\npotential to serve as a portal to vast digital functionalities. Our approach\nutilizes object segmentation and classification, combined with the power of\nMultimodal Large Language Models (MLLMs), to facilitate these interactions. We\nimplement the AOI concept in the form of XR-Objects, an open-source prototype\nsystem that provides a platform for users to engage with their physical\nenvironment in rich and contextually relevant ways. This system enables analog\nobjects to not only convey information but also to initiate digital actions,\nsuch as querying for details or executing tasks. Our contributions are\nthreefold: (1) we define the AOI concept and detail its advantages over\ntraditional AI assistants, (2) detail the XR-Objects system's open-source\ndesign and implementation, and (3) show its versatility through a variety of\nuse cases and a user study.",
      "tldr_zh": "本研究引入了Augmented Object Intelligence (AOI)，一种创新的XR交互范式，旨在将物理对象转化为可互动的数字实体，使模拟世界与数字功能无缝整合。AOI 通过对象分割和分类技术结合Multimodal Large Language Models (MLLMs)，让这些对象能够传达信息并启动数字动作，如查询细节或执行任务。研究团队开发了开源原型系统XR-Objects，并通过多种用例和用户研究，证明了其相对于传统AI助手的优势和多功能性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.0; H.5.1; H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "2024 ACM Symposium on User Interface Software and Technology (UIST)",
      "pdf_url": "http://arxiv.org/pdf/2404.13274v4",
      "published_date": "2024-04-20 05:14:52 UTC",
      "updated_date": "2025-03-18 23:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:12:12.964626"
    },
    {
      "arxiv_id": "2404.14444v1",
      "title": "Practical Battery Health Monitoring using Uncertainty-Aware Bayesian Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yunyi Zhao",
        "Zhang Wei",
        "Qingyu Yan",
        "Man-Fai Ng",
        "B. Sivaneasan",
        "Cheng Xiang"
      ],
      "abstract": "Battery health monitoring and prediction are critically important in the era\nof electric mobility with a huge impact on safety, sustainability, and economic\naspects. Existing research often focuses on prediction accuracy but tends to\nneglect practical factors that may hinder the technology's deployment in\nreal-world applications. In this paper, we address these practical\nconsiderations and develop models based on the Bayesian neural network for\npredicting battery end-of-life. Our models use sensor data related to battery\nhealth and apply distributions, rather than single-point, for each parameter of\nthe models. This allows the models to capture the inherent randomness and\nuncertainty of battery health, which leads to not only accurate predictions but\nalso quantifiable uncertainty. We conducted an experimental study and\ndemonstrated the effectiveness of our proposed models, with a prediction error\nrate averaging 13.9%, and as low as 2.9% for certain tested batteries.\nAdditionally, all predictions include quantifiable certainty, which improved by\n66% from the initial to the mid-life stage of the battery. This research has\npractical values for battery technologies and contributes to accelerating the\ntechnology adoption in the industry.",
      "tldr_zh": "本研究针对电池健康监测的实际部署挑战，提出了一种基于 Uncertainty-Aware Bayesian Neural Network 的预测模型，该模型使用传感器数据并为参数应用分布，以捕捉电池健康的随机性和不确定性，从而实现准确预测并提供可量化的不确定性。相比传统方法，该模型不仅提升了预测准确性，在实验中平均预测错误率仅为13.9%，某些电池低至2.9%，而且不确定性量化从电池初始到中期阶段改善了66%。这项工作为电池技术提供了实际价值，有助于加速其在电动交通领域的行业采用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.14444v1",
      "published_date": "2024-04-20 05:13:14 UTC",
      "updated_date": "2024-04-20 05:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:12:25.515291"
    },
    {
      "arxiv_id": "2404.13265v1",
      "title": "F5C-finder: An Explainable and Ensemble Biological Language Model for Predicting 5-Formylcytidine Modifications on mRNA",
      "title_zh": "翻译失败",
      "authors": [
        "Guohao Wang",
        "Ting Liu",
        "Hongqiang Lyu",
        "Ze Liu"
      ],
      "abstract": "As a prevalent and dynamically regulated epigenetic modification,\n5-formylcytidine (f5C) is crucial in various biological processes. However,\ntraditional experimental methods for f5C detection are often laborious and\ntime-consuming, limiting their ability to map f5C sites across the\ntranscriptome comprehensively. While computational approaches offer a\ncost-effective and high-throughput alternative, no recognition model for f5C\nhas been developed to date. Drawing inspiration from language models in natural\nlanguage processing, this study presents f5C-finder, an ensemble neural\nnetwork-based model utilizing multi-head attention for the identification of\nf5C. Five distinct feature extraction methods were employed to construct five\nindividual artificial neural networks, and these networks were subsequently\nintegrated through ensemble learning to create f5C-finder. 10-fold\ncross-validation and independent tests demonstrate that f5C-finder achieves\nstate-of-the-art (SOTA) performance with AUC of 0.807 and 0.827, respectively.\nThe result highlights the effectiveness of biological language model in\ncapturing both the order (sequential) and functional meaning (semantics) within\ngenomes. Furthermore, the built-in interpretability allows us to understand\nwhat the model is learning, creating a bridge between identifying key\nsequential elements and a deeper exploration of their biological functions.",
      "tldr_zh": "这篇论文提出了 f5C-finder，一个可解释的集成神经网络模型，用于预测 mRNA 上的 5-formylcytidine (f5C) 修饰，以解决传统实验方法耗时费力的局限。模型借鉴自然语言处理中的语言模型，采用多头注意力机制和五种特征提取方法构建多个神经网络，并通过 ensemble learning 进行整合。实验结果显示，f5C-finder 在 10 折交叉验证和独立测试中达到了 SOTA 性能，AUC 值分别为 0.807 和 0.827。总之，该模型不仅提升了 f5C 预测的准确性，还通过内置解释性揭示了基因组顺序和语义的生物学意义。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "34 pages, 10 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2404.13265v1",
      "published_date": "2024-04-20 04:24:45 UTC",
      "updated_date": "2024-04-20 04:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:12:39.107181"
    },
    {
      "arxiv_id": "2404.14443v1",
      "title": "Evaluation of Machine Translation Based on Semantic Dependencies and Keywords",
      "title_zh": "基于语义依赖和关键词的机器翻译评估",
      "authors": [
        "Kewei Yuan",
        "Qiurong Zhao",
        "Yang Xu",
        "Xiao Zhang",
        "Huansheng Ning"
      ],
      "abstract": "In view of the fact that most of the existing machine translation evaluation\nalgorithms only consider the lexical and syntactic information, but ignore the\ndeep semantic information contained in the sentence, this paper proposes a\ncomputational method for evaluating the semantic correctness of machine\ntranslations based on reference translations and incorporating semantic\ndependencies and sentence keyword information. Use the language technology\nplatform developed by the Social Computing and Information Retrieval Research\nCenter of Harbin Institute of Technology to conduct semantic dependency\nanalysis and keyword analysis on sentences, and obtain semantic dependency\ngraphs, keywords, and weight information corresponding to keywords. It includes\nall word information with semantic dependencies in the sentence and keyword\ninformation that affects semantic information. Construct semantic association\npairs including word and dependency multi-features. The key semantics of the\nsentence cannot be highlighted in the semantic information extracted through\nsemantic dependence, resulting in vague semantics analysis. Therefore, the\nsentence keyword information is also included in the scope of machine\ntranslation semantic evaluation. To achieve a comprehensive and in-depth\nevaluation of the semantic correctness of sentences, the experimental results\nshow that the accuracy of the evaluation algorithm has been improved compared\nwith similar methods, and it can more accurately measure the semantic\ncorrectness of machine translation.",
      "tldr_zh": "本文提出了一种基于语义依赖（semantic dependencies）和关键词（keywords）的机器翻译评估方法，以弥补现有算法忽略句子深层语义信息的不足。该方法利用参考翻译进行语义正确性计算，通过语义依赖分析和关键词提取（如语义依赖图和关键词权重）构建语义关联对，从而全面评估翻译的词汇、句法和语义层面。实验结果显示，该算法的准确性较类似方法有所提升，能更精确地衡量机器翻译的语义正确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14443v1",
      "published_date": "2024-04-20 04:14:28 UTC",
      "updated_date": "2024-04-20 04:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:12:48.379202"
    },
    {
      "arxiv_id": "2405.05142v1",
      "title": "Ordinal Behavior Classification of Student Online Course Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Trask"
      ],
      "abstract": "The study in interaction patterns between students in on-campus and\nMOOC-style online courses has been broadly studied for the last 11 years. Yet\nthere remains a gap in the literature comparing the habits of students\ncompleting the same course offered in both on-campus and MOOC-style online\nformats. This study will look at browser-based usage patterns for students in\nthe Georgia Tech CS1301 edx course for both the online course offered to\non-campus students and the MOOCstyle course offered to anyone to determine\nwhat, if any, patterns exist between the two cohorts.",
      "tldr_zh": "本研究针对学生在线课程互动模式的序数行为分类（Ordinal Behavior Classification），填补了现有文献中对同一课程在校园和MOOC格式下学生习惯的直接比较缺口。研究方法包括分析佐治亚理工学院CS1301 edX课程的学生浏览器-based usage patterns，比较针对校园学生的在线版本和面向公众的MOOC版本。预期结果将揭示两组学生互动模式之间的差异，为理解在线教育行为提供新的洞见。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages, 4 tables, 6 figures. Submitted to CSEDM Workshop @ EDM 24",
      "pdf_url": "http://arxiv.org/pdf/2405.05142v1",
      "published_date": "2024-04-20 02:34:03 UTC",
      "updated_date": "2024-04-20 02:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:13:01.638027"
    },
    {
      "arxiv_id": "2404.13238v1",
      "title": "Personalized Wireless Federated Learning for Large Language Models",
      "title_zh": "针对大型语言模型的个性化无线",
      "authors": [
        "Feibo Jiang",
        "Li Dong",
        "Siwei Tu",
        "Yubo Peng",
        "Kezhi Wang",
        "Kun Yang",
        "Cunhua Pan",
        "Dusit Niyato"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\ntasks. However, their deployment in wireless networks still face challenges,\ni.e., a lack of privacy and security protection mechanisms. Federated Learning\n(FL) has emerged as a promising approach to address these challenges. Yet, it\nsuffers from issues including inefficient handling with big and heterogeneous\ndata, resource-intensive training, and high communication overhead. To tackle\nthese issues, we first compare different learning stages and their features of\nLLMs in wireless networks. Next, we introduce two personalized wireless\nfederated fine-tuning methods with low communication overhead, i.e., (1)\nPersonalized Federated Instruction Tuning (PFIT), which employs reinforcement\nlearning to fine-tune local LLMs with diverse reward models to achieve\npersonalization; (2) Personalized Federated Task Tuning (PFTT), which can\nleverage global adapters and local Low-Rank Adaptations (LoRA) to\ncollaboratively fine-tune local LLMs, where the local LoRAs can be applied to\nachieve personalization without aggregation. Finally, we perform simulations to\ndemonstrate the effectiveness of the proposed two methods and comprehensively\ndiscuss open issues.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 在无线网络中的部署挑战，包括隐私和安全问题，以及 Federated Learning (FL) 的数据处理效率低、资源密集和通信开销高等问题。为解决这些问题，研究者提出了两种低通信开销的个性化无线联邦微调方法：Personalized Federated Instruction Tuning (PFIT)，利用强化学习和多样化奖励模型对本地 LLMs 进行个性化微调；以及 Personalized Federated Task Tuning (PFTT)，结合全局适配器和本地 Low-Rank Adaptations (LoRA) 来协同微调，实现个性化而不需聚合。通过模拟实验，证明了这些方法的有效性，并讨论了相关开放问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.13238v1",
      "published_date": "2024-04-20 02:30:21 UTC",
      "updated_date": "2024-04-20 02:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:13:14.434075"
    },
    {
      "arxiv_id": "2404.14442v3",
      "title": "Unified ODE Analysis of Smooth Q-Learning Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Donghwan Lee"
      ],
      "abstract": "Convergence of Q-learning has been the focus of extensive research over the\npast several decades. Recently, an asymptotic convergence analysis for\nQ-learning was introduced using a switching system framework. This approach\napplies the so-called ordinary differential equation (ODE) approach to prove\nthe convergence of the asynchronous Q-learning modeled as a continuous-time\nswitching system, where notions from switching system theory are used to prove\nits asymptotic stability without using explicit Lyapunov arguments. However, to\nprove stability, restrictive conditions, such as quasi-monotonicity, must be\nsatisfied for the underlying switching systems, which makes it hard to easily\ngeneralize the analysis method to other reinforcement learning algorithms, such\nas the smooth Q-learning variants. In this paper, we present a more general and\nunified convergence analysis that improves upon the switching system approach\nand can analyze Q-learning and its smooth variants. The proposed analysis is\nmotivated by previous work on the convergence of synchronous Q-learning based\non $p$-norm serving as a Lyapunov function. However, the proposed analysis\naddresses more general ODE models that can cover both asynchronous Q-learning\nand its smooth versions with simpler frameworks.",
      "tldr_zh": "本研究提出了一种统一的常微分方程(ODE)分析方法，用于分析 Q-learning 算法及其平滑变体的收敛性。该方法改进了现有的切换系统框架，避免了诸如准单调性等严格条件，从而更易推广到异步 Q-learning 和其平滑版本。基于 p-范数作为 Lyapunov 函数的先前工作，该分析构建了更一般的 ODE 模型，提供了一个更简单的框架来证明算法的渐近稳定性。通过这种统一方法，论文为强化学习算法的收敛分析提供了更广泛的适用性和灵活性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14442v3",
      "published_date": "2024-04-20 01:16:27 UTC",
      "updated_date": "2025-03-28 11:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:13:25.223810"
    },
    {
      "arxiv_id": "2404.14441v1",
      "title": "Optimizing Contrail Detection: A Deep Learning Approach with EfficientNet-b4 Encoding",
      "title_zh": "优化凝结尾迹检测：一种基于 EfficientNet-b4 编码的深度学习方法",
      "authors": [
        "Qunwei Lin",
        "Qian Leng",
        "Zhicheng Ding",
        "Chao Yan",
        "Xiaonan Xu"
      ],
      "abstract": "In the pursuit of environmental sustainability, the aviation industry faces\nthe challenge of minimizing its ecological footprint. Among the key solutions\nis contrail avoidance, targeting the linear ice-crystal clouds produced by\naircraft exhaust. These contrails exacerbate global warming by trapping\natmospheric heat, necessitating precise segmentation and comprehensive analysis\nof contrail images to gauge their environmental impact. However, this\nsegmentation task is complex due to the varying appearances of contrails under\ndifferent atmospheric conditions and potential misalignment issues in\npredictive modeling. This paper presents an innovative deep-learning approach\nutilizing the efficient net-b4 encoder for feature extraction, seamlessly\nintegrating misalignment correction, soft labeling, and pseudo-labeling\ntechniques to enhance the accuracy and efficiency of contrail detection in\nsatellite imagery. The proposed methodology aims to redefine contrail image\nanalysis and contribute to the objectives of sustainable aviation by providing\na robust framework for precise contrail detection and analysis in satellite\nimagery, thus aiding in the mitigation of aviation's environmental impact.",
      "tldr_zh": "本研究针对航空业的环境可持续性问题，聚焦于凝结尾（contrails）对全球变暖的贡献，通过精确分割和分析卫星图像来评估其影响。论文提出了一种创新的深度学习方法，使用 EfficientNet-b4 编码器进行特征提取，并整合失准校正（misalignment correction）、软标签（soft labeling）和伪标签（pseudo-labeling）技术，以提升凝结尾检测的准确性和效率。该方法为可持续航空提供了一个稳健框架，有助于重新定义凝结尾图像分析并缓解航空业的生态足迹。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14441v1",
      "published_date": "2024-04-20 00:21:06 UTC",
      "updated_date": "2024-04-20 00:21:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:13:38.555595"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 41,
  "processed_papers_count": 41,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T02:13:58.193827"
}