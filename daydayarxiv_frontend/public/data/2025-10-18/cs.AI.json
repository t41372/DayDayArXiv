{
  "date": "2025-10-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-10-18 的 arXiv 中文 TLDR 快报！\n\n**今日总结**：\n今天的 arXiv 充满了对于 **LLM 推理能力 (Reasoning)** 的深度反思与改进，从 NP-hard 问题的求解、元认知 (Metacognition) 框架的引入，到对 \"思维链\" 是否真的在 \"思考\" 的探测。此外，**Agent 生态的安全与效率** 也是重头戏，特别是针对 Model Context Protocol (MCP) 的首个全面安全分析值得开发者警惕。科学领域，AI 对神经科学的综述以及对 200 万篇预印本的 \"文风\" 影响分析也非常有趣。\n\n---\n\n### 🚀 深度推理与强化学习 (Reasoning & RL)\n\n**1. [36] NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems**\n**NP-Engine：利用可验证的合成 NP 问题赋能 LLM 的优化推理能力**\n*   **核心贡献**：针对 LLM 在解决复杂优化问题（特别是 NP-hard 问题）上的短板，提出了 NP-ENGINE 框架。这是一个包含生成器、验证器和启发式求解器的流水线，用于进行**可验证奖励的强化学习 (RLVR)**。\n*   **发现**：作者发布的 **QWEN2.5-7B-NP** 模型在 NP-BENCH 上超越了 GPT-4o。研究表明，在 NP-hard 任务上进行的 RLVR 训练不仅能提升求解能力，还能**泛化**到逻辑、数学等推理任务，甚至指令遵循任务中。\n\n**2. [54] Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs**\n**在 <思考> 之前先监控：在 LLM 中实现 Flavell 的元认知框架**\n*   **核心贡献**：目前的推理方法要么是 \"盲目生成后验证\" (Generate-Verify)，要么是 \"缺乏反馈的规划\" (Monitor-Generate)。本文引入心理学中的 **Flavell 元认知模型**，构建了一个 \"监控-生成-验证\" 的三阶段循环。\n*   **效果**：在 GSM8K 上，该方法以更少的尝试次数（1.3 vs 2.0）达到了比 Self-Refine 更高的准确率，虽然推理成本增加了约 30%，但产生了一次性通过率更高的初始解。\n\n**3. [8] Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards**\n**计数很重要：利用基于计数的内在奖励激发 LLM 推理中的探索**\n*   **核心贡献**：解决 RL 训练推理能力时奖励稀疏和探索不足的问题。提出了 **MERCI** 算法，利用轻量级的硬币翻转网络 (CFN) 估计推理轨迹的伪计数和不确定性，将其转化为**内在奖励 (Intrinsic Reward)**。\n*   **发现**：这种机制鼓励模型生成更丰富、更多样化的思维链 (CoT)，帮助策略跳出局部最优，显著提升了复杂推理任务的性能。\n\n**4. [62] Thinking About Thinking: Evaluating Reasoning in Post-Trained Language Models**\n**思考关于 \"思考\"：评估后训练语言模型的推理能力**\n*   **核心贡献**：探究经过 SFT、DPO 或 GRPO 后训练的模型，是否真的 \"意识\" 到了它们学到的潜在策略。\n*   **发现**：**RL 训练的模型（如 GRPO）比 SFT 模型表现出更强的策略意识和泛化能力**，但在 \"推理痕迹 (Trace) 与最终输出的一致性\" 上表现较差（即推理过程可能说对了，但结果不对，或者反之）。\n\n---\n\n### 🤖 Agent 生态与安全 (Agents & Security)\n\n**5. [22] Toward Understanding Security Issues in the Model Context Protocol Ecosystem**\n**理解 Model Context Protocol (MCP) 生态系统中的安全问题**\n*   **核心贡献**：**必读文章**。这是对 Anthropic 推出的 MCP 标准（连接 AI 与外部工具的协议）的首次全面安全分析。研究涵盖了 Cursor, Claude Desktop 等宿主以及数千个社区服务器。\n*   **发现**：发现了大量安全漏洞。宿主缺乏对 LLM 输出的验证机制，恶意服务器可以操纵模型行为并窃取数据。由于注册表缺乏审核，**攻击者极易通过恶意服务器劫持用户环境**。\n\n**6. [5] CodeCRDT: Observation-Driven Coordination for Multi-Agent LLM Code Generation**\n**CodeCRDT：多智能体 LLM 代码生成的观察驱动协作**\n*   **核心贡献**：解决多智能体并行写代码时的冲突问题。引入了分布式系统中经典的 **CRDT (无冲突复制数据类型)** 概念，让 Agent 通过监控共享状态的变化来协作，而不是显式发消息。\n*   **效果**：实现了 **100% 的合并成功率 (无冲突)**，在某些任务上实现了 21.1% 的加速。这是一种 \"无锁\" 的多 Agent 协作新范式。\n\n**7. [77] What Limits Agentic Systems Efficiency?**\n**什么限制了 Agentic 系统的效率？**\n*   **核心贡献**：研究了 Agent 系统的端到端延迟，发现 **Web 环境交互延迟** 占比高达 53.7%。\n*   **方案**：提出了 **SpecCache**，一种结合了推测执行 (Speculative Execution) 的缓存框架，能将缓存命中率提高 58 倍，大幅降低 Web 环境带来的开销。\n\n---\n\n### 👁️ 视觉与多模态 (Vision & Multimodal)\n\n**8. [13] SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense**\n**SHIELD：通过偏差与脆弱性防御抑制 LVLM 编码器中的幻觉**\n*   **核心贡献**：不同于以往关注 LLM 解码端，本文将多模态大模型 (LVLM) 的幻觉根源追溯到 **视觉编码器 (Visual Encoder)**。\n*   **方法**：提出了 SHIELD 框架，无需训练，通过重加权视觉 Token 减少统计偏差、引入噪声 Token 对抗固有偏差，以及对抗性攻击解码来解决脆弱性。\n\n**9. [1] Safire: Similarity Framework for Visualization Retrieval**\n**Safire：可视化检索的相似性框架**\n*   **核心贡献**：为 \"可视化检索\" (Visualization Retrieval) 建立了一个概念模型。当我们在找 \"相似的图表\" 时，到底在找什么？Safire 定义了两个维度：比较标准（数据、编码、风格等）和表示模态（光栅图、矢量图、代码、自然语言），为该领域提供了理论基础。\n\n---\n\n### 🧬 科学 AI 与 元科学 (AI for Science & Meta-Science)\n\n**10. [2] Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review**\n**神经科学中的基础与大规模 AI 模型：综述**\n*   **概要**：全面回顾了大规模 AI 模型如何改变神经科学，从脑机接口、神经解码到精神疾病应用。文章指出 AI 与神经科学正变得**互惠**：生物学约束正在被用来开发更高效的 AI 架构。\n\n**11. [72] Does GenAI Rewrite How We Write? An Empirical Study on Two-Million Preprints**\n**生成式 AI 重写了我们的写作方式吗？基于两百万篇预印本的实证研究**\n*   **核心贡献**：分析了 2016-2025 年间 arXiv, bioRxiv 等平台的 **210 万篇预印本**。\n*   **有趣发现**：LLM 确实**加速了论文的提交和修改周期**，适度增加了语言的复杂性，并且与 AI 相关的议题比例大幅上升。计算密集型领域受影响最大。LLM 似乎更多是作为一种 \"催化剂\"，放大了现有的学科差异。\n\n**12. [15] Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration**\n**原子锚定 LLM 说化学语言：逆合成演示**\n*   **核心贡献**：让通用 LLM 也能做专业的化学逆合成分析，而无需大量标注数据。\n*   **方法**：使用唯一的原子标识符将思维链 (CoT) 锚定到分子结构上。在识别反应位点上达到了 ≥90% 的成功率。\n\n---\n\n### 🛡️ 其他值得关注的论文\n\n*   **[69] When Intelligence Fails: An Empirical Study on Why LLMs Struggle with Password Cracking**\n    **当智能失效时：为何 LLM 在密码破解上表现挣扎**\n    *   **TLDR**：别担心 LLM 会猜出你的密码。研究发现，即使给定用户画像（名字、生日），LLM 在生成可能的密码方面表现极差（准确率 <1.5%），远不如传统的基于规则的破解工具。它们缺乏这种特定的领域适应能力。\n\n*   **[3] Unleashing Diverse Thinking Modes in LLMs through Multi-Agent Collaboration**\n    **DiMo**：通过四个代表不同认知范式的 Agent 进行辩论，提升 LLM 的推理能力和可解释性。\n\n*   **[40] Input Domain Aware MoE**\n    **Input Domain Aware MoE**：改进了混合专家模型 (MoE) 的路由机制，不再仅依赖相似度，而是利用概率混合模型划分输入空间，提升了多模态模型的专家利用率。\n\n*   **[71] OpenLVLM-MIA**\n    **OpenLVLM-MIA**：重新审视了针对多模态大模型的成员推断攻击 (MIA)，发现之前的攻击高成功率主要源于数据集偏差，而非真正的隐私泄露。\n\n*   **[25] Predicting life satisfaction using machine learning**\n    **生活满意度预测**：基于丹麦 1.9 万人的数据，发现**健康状况**是所有年龄段生活满意度的最重要决定因素，且该任务与生物医学领域的关联比临床领域更紧密。",
  "papers": [
    {
      "arxiv_id": "2510.16662v1",
      "title": "Safire: Similarity Framework for Visualization Retrieval",
      "title_zh": "Safire：面向可视化检索的相似性框架",
      "authors": [
        "Huyen N. Nguyen",
        "Nils Gehlenborg"
      ],
      "abstract": "Effective visualization retrieval necessitates a clear definition of similarity. Despite the growing body of work in specialized visualization retrieval systems, a systematic approach to understanding visualization similarity remains absent. We introduce the Similarity Framework for Visualization Retrieval (Safire), a conceptual model that frames visualization similarity along two dimensions: comparison criteria and representation modalities. Comparison criteria identify the aspects that make visualizations similar, which we divide into primary facets (data, visual encoding, interaction, style, metadata) and derived properties (data-centric and human-centric measures). Safire connects what to compare with how comparisons are executed through representation modalities. We categorize existing representation approaches into four groups based on their levels of information content and visualization determinism: raster image, vector image, specification, and natural language description, together guiding what is computable and comparable. We analyze several visualization retrieval systems using Safire to demonstrate its practical value in clarifying similarity considerations. Our findings reveal how particular criteria and modalities align across different use cases. Notably, the choice of representation modality is not only an implementation detail but also an important decision that shapes retrieval capabilities and limitations. Based on our analysis, we provide recommendations and discuss broader implications for multimodal learning, AI applications, and visualization reproducibility.",
      "tldr_zh": "该研究提出了Safire，这是一个用于可视化检索(Visualization Retrieval)的相似性框架，旨在解决当前缺乏系统性相似性定义的问题。Safire通过比较准则(Comparison Criteria)和表示模态(Representation Modalities)两个维度构建概念模型，明确了“比较什么”与“如何比较”之间的关联。该框架将比较准则细分为Data、Visual Encoding、Interaction、Style和Metadata五个主要维度以及衍生属性，并根据信息含量将表示模态归纳为Raster image、Vector image、Specification和Natural language description。通过对多个可视化检索系统的分析，研究证明了Safire在理清相似性考量方面的实用价值，揭示了模态选择不仅是实现细节，更是决定检索系统能力与局限性的关键因素。最后，该研究针对多模态学习、人工智能应用及可视化复现性(Reproducibility)提出了重要建议。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear in IEEE VIS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.16662v1",
      "published_date": "2025-10-18 23:11:40 UTC",
      "updated_date": "2025-10-18 23:11:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:11:50.479247+00:00"
    },
    {
      "arxiv_id": "2510.16658v1",
      "title": "Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review",
      "title_zh": "神经科学领域的基础模型与大规模人工智能模型：全面综述",
      "authors": [
        "Shihao Yang",
        "Xiying Huang",
        "Danilo Bernardo",
        "Jun-En Ding",
        "Andrew Michael",
        "Jingmei Yang",
        "Patrick Kwan",
        "Ashish Raj",
        "Feng Liu"
      ],
      "abstract": "The advent of large-scale artificial intelligence (AI) models has a transformative effect on neuroscience research, which represents a paradigm shift from the traditional computational methods through the facilitation of end-to-end learning from raw brain signals and neural data. In this paper, we explore the transformative effects of large-scale AI models on five major neuroscience domains: neuroimaging and data processing, brain-computer interfaces and neural decoding, molecular neuroscience and genomic modeling, clinical assistance and translational frameworks, and disease-specific applications across neurological and psychiatric disorders. These models are demonstrated to address major computational neuroscience challenges, including multimodal neural data integration, spatiotemporal pattern interpretation, and the derivation of translational frameworks for clinical deployment. Moreover, the interaction between neuroscience and AI has become increasingly reciprocal, as biologically informed architectural constraints are now incorporated to develop more interpretable and computationally efficient models. This review highlights both the notable promise of such technologies and key implementation considerations, with particular emphasis on rigorous evaluation frameworks, effective domain knowledge integration, and comprehensive ethical guidelines for clinical use. Finally, a systematic listing of critical neuroscience datasets used to derive and validate large-scale AI models across diverse research applications is provided.",
      "tldr_zh": "该综述探讨了大语言模型（Large-scale AI models）在神经科学领域的变革性影响，标志着从传统计算方法向基于原始大脑信号和神经数据的端到端学习（end-to-end learning）的范式转变。文章重点分析了 AI 模型在神经影像处理、脑机接口（BCI）与神经解码、分子神经科学、临床辅助转化及精神疾病应用等五个核心领域的表现。这些模型能够有效解决多模态神经数据集成（multimodal neural data integration）、时空模式解读以及临床转化框架构建等重大计算挑战。研究还指出神经科学与 AI 之间存在互惠关系，通过引入生物启发式架构约束（biologically informed architectural constraints）可以提升模型的可解释性与效率。此外，该综述强调了建立严格评估框架、集成领域知识及遵循伦理指南在临床应用中的重要性。最后，文中系统列出了用于构建和验证这些大规模 AI 模型的关键神经科学数据集，为未来研究提供了重要参考。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16658v1",
      "published_date": "2025-10-18 22:45:59 UTC",
      "updated_date": "2025-10-18 22:45:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:11:52.691243+00:00"
    },
    {
      "arxiv_id": "2510.16645v1",
      "title": "Unleashing Diverse Thinking Modes in LLMs through Multi-Agent Collaboration",
      "title_zh": "通过多智能体协作释放大语言模型中的多元思维模式",
      "authors": [
        "Zhixuan He",
        "Yue Feng"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate strong performance but often lack interpretable reasoning. This paper introduces the Multi-Agent Collaboration Framework for Diverse Thinking Modes (DiMo), which enhances both performance and interpretability by simulating a structured debate among four specialized LLM agents. Each agent embodies a distinct reasoning paradigm, allowing the framework to collaboratively explore diverse cognitive approaches. Through iterative debate, agents challenge and refine initial responses, yielding more robust conclusions and an explicit, auditable reasoning chain. Across six benchmarks and under a unified open-source setup, DiMo improves accuracy over widely used single-model and debate baselines, with the largest gains on math. We position DiMo as a semantics-aware, Web-native multi-agent framework: it models human-machine intelligence with LLM agents that produce semantically typed, URL-annotated evidence chains for explanations and user-friendly interactions. Although our experiments use standard reasoning benchmarks, the framework is designed to be instantiated over Web corpora and knowledge graphs, combining retrieval-augmented reasoning with structured justifications that downstream systems can inspect and reuse.",
      "tldr_zh": "该研究提出了多样化思维模式多智能体协作框架(DiMo)，旨在通过模拟四个专门的大语言模型(LLMs)智能体之间的结构化辩论，提升模型在复杂推理任务中的性能与可解释性。每个智能体代表一种独特的推理范式，通过迭代辩论机制相互挑战并完善初始响应，从而生成更加稳健的结论和显式的、可审计的推理链。DiMo 被定位为一种语义感知且 Web 原生的框架，利用 LLM 智能体产生带有语义类型和 URL 注释的证据链，实现了检索增强生成(RAG)与结构化论证的结合。在六个基准测试的实验中，DiMo 在准确率上优于广泛使用的单模型及辩论基线模型，特别是在数学任务中取得了最大增益。该框架的设计使其能够实例化于 Web 语料库和知识图谱之上，为下游系统提供了可检查和可重用的结构化解释。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16645v1",
      "published_date": "2025-10-18 21:22:36 UTC",
      "updated_date": "2025-10-18 21:22:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:11:55.977991+00:00"
    },
    {
      "arxiv_id": "2510.16643v1",
      "title": "Structured Interfaces for Automated Reasoning with 3D Scene Graphs",
      "title_zh": "面向 3D 场景图自动推理的结构化接口",
      "authors": [
        "Aaron Ray",
        "Jacob Arkin",
        "Harel Biggie",
        "Chuchu Fan",
        "Luca Carlone",
        "Nicholas Roy"
      ],
      "abstract": "In order to provide a robot with the ability to understand and react to a user's natural language inputs, the natural language must be connected to the robot's underlying representations of the world. Recently, large language models (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for grounding natural language and representing the world. In this work, we address the challenge of using LLMs with 3DSGs to ground natural language. Existing methods encode the scene graph as serialized text within the LLM's context window, but this encoding does not scale to large or rich 3DSGs. Instead, we propose to use a form of Retrieval Augmented Generation to select a subset of the 3DSG relevant to the task. We encode a 3DSG in a graph database and provide a query language interface (Cypher) as a tool to the LLM with which it can retrieve relevant data for language grounding. We evaluate our approach on instruction following and scene question-answering tasks and compare against baseline context window and code generation methods. Our results show that using Cypher as an interface to 3D scene graphs scales significantly better to large, rich graphs on both local and cloud-based models. This leads to large performance improvements in grounded language tasks while also substantially reducing the token count of the scene graph content. A video supplement is available at https://www.youtube.com/watch?v=zY_YI9giZSA.",
      "tldr_zh": "该研究针对机器人通过 Large Language Models (LLMs) 处理 3D Scene Graphs (3DSGs) 时面临的可扩展性难题，提出了一种结构化接口推理方法。不同于将场景图序列化为文本的传统做法，该方案将 3DSG 编码至图数据库中，并为 LLM 提供 Cypher 查询语言接口，构建了一种高效的 Retrieval Augmented Generation (RAG) 机制。LLM 通过该工具能够精准检索与当前任务相关的子图数据，从而在复杂场景中实现有效的语言关联 (Language Grounding)。研究在指令遵循 (Instruction Following) 和场景问答 (Scene Question-Answering) 任务上进行了验证，结果显示该方法在处理大规模、丰富的场景图时表现出优异的扩展性。与传统的上下文窗口和代码生成方法相比，该接口不仅大幅提升了 grounded language 任务的性能，还显著降低了输入模型所需的 token 消耗。该方案证明了结构化查询接口在提升机器人环境理解能力和推理效率方面的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.16643v1",
      "published_date": "2025-10-18 21:19:13 UTC",
      "updated_date": "2025-10-18 21:19:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:11:58.783856+00:00"
    },
    {
      "arxiv_id": "2510.18893v1",
      "title": "CodeCRDT: Observation-Driven Coordination for Multi-Agent LLM Code Generation",
      "title_zh": "CodeCRDT：面向多智能体 LLM 代码生成的观察驱动型协同机制",
      "authors": [
        "Sergey Pugachev"
      ],
      "abstract": "Multi-agent LLM systems fail to realize parallel speedups due to costly coordination. We present CodeCRDT, an observation-driven coordination pattern where agents coordinate by monitoring a shared state with observable updates and deterministic convergence, rather than explicit message passing. Using Conflict-Free Replicated Data Types (CRDTs), CodeCRDT enables lock-free, conflict-free concurrent code generation with strong eventual consistency. Evaluation across 600 trials (6 tasks, 50 runs per mode) shows both benefits and trade-offs: up to 21.1% speedup on some tasks, up to 39.4% slowdown on others, and 100% convergence with zero merge failures. The study formalizes observation-driven coordination for stochastic LLM agents, revealing semantic conflict rates (5-10%) and quality-performance tradeoffs, and provides empirical characterization of when parallel coordination succeeds versus fails based on task structure.",
      "tldr_zh": "该研究提出了 CodeCRDT，一种针对多智能体大语言模型(Multi-Agent LLM)代码生成任务的观测驱动协作(Observation-Driven Coordination)模式，旨在解决显式消息传递导致的高昂协作成本。该方法利用无冲突复制数据类型(Conflict-Free Replicated Data Types, CRDTs)构建共享状态，使多个智能体能够通过监控可观测的状态更新实现确定性收敛。CodeCRDT 实现了无锁、无冲突的并发代码生成，并保证了强最终一致性(Strong Eventual Consistency)，有效避免了协作中的合并失败。实验通过 600 次测试显示，该模式在特定任务中可实现高达 21.1% 的速度提升且收敛率为 100%，但也揭示了 5-10% 的语义冲突率以及任务结构对并行效率的影响。这项工作为随机性智能体协作提供了形式化框架，并实证分析了在代码生成场景下并行协作的性能权衡与成功条件。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "11 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.18893v1",
      "published_date": "2025-10-18 20:50:01 UTC",
      "updated_date": "2025-10-18 20:50:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:01.774702+00:00"
    },
    {
      "arxiv_id": "2510.16635v1",
      "title": "Prompt Optimization via Retrieved Reasoning Assets and Multi-Agent Analysis",
      "title_zh": "基于检索推理资产与多智能体分析的提示词优化",
      "authors": [
        "Wonduk Seo",
        "Juhyeon Lee",
        "Junseo Koh",
        "Hyunjin An",
        "Jian Park",
        "Seunghyun Lee",
        "Haihua Chen",
        "Yi Bu"
      ],
      "abstract": "Prompt optimization has emerged as an effective alternative to retraining for improving the performance of Large Language Models (LLMs). However, most existing approaches treat evaluation as a black box, relying solely on numerical scores while offering limited insight into why a prompt succeeds or fails. They also depend heavily on trial-and-error refinements, which are difficult to interpret and control. In this paper, we introduce MA-SAPO, a Multi-Agent framework for Score-Aware Prompt Optimization. Compared to prior methods, MA-SAPO explicitly couples evaluation outcomes with structured reasoning to guide systematic edits. The framework specifically consists of two stages: during the Reasoning Phase, agents collaboratively explain metric scores, diagnose weaknesses, and synthesize targeted refinements that are stored as reusable reasoning assets; during the Test Phase, agents retrieve these assets to analyze optimized prompts and apply only evidence-grounded edits. By turning evaluation signals into interpretable reasoning chains, MA-SAPO produces prompt refinements that are more transparent, auditable, and controllable. Experiments on the HelpSteer1/2 benchmarks demonstrate consistent improvements over single-pass prompting, retrieval-augmented baselines, and prior multi-agent strategies, validating the effectiveness of our approach.",
      "tldr_zh": "该研究提出了 MA-SAPO，一种基于分数感知的提示优化 (Score-Aware Prompt Optimization) 的多智能体 (Multi-Agent) 框架，旨在解决现有方法将评估视为黑盒且难以解释优化逻辑的问题。该框架将评估结果与结构化推理直接耦合，分为推理阶段 (Reasoning Phase) 和测试阶段 (Test Phase) 两个核心步骤。在推理阶段，智能体通过协作诊断提示词的弱点并生成可重复使用的推理资产 (reasoning assets)；而在测试阶段，智能体检索这些资产以执行基于证据的精确编辑。这种方法将评估信号转化为可解释的推理链，显著提升了提示优化的透明度、可审计性和可控性。实验结果显示，MA-SAPO 在 HelpSteer1/2 基准测试中表现出色，其性能一致优于单次提示 (single-pass prompting) 以及现有的多智能体优化策略。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.MA",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2510.16635v1",
      "published_date": "2025-10-18 20:21:09 UTC",
      "updated_date": "2025-10-18 20:21:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:07.405323+00:00"
    },
    {
      "arxiv_id": "2510.16620v2",
      "title": "Feedback Lunch: Deep Feedback Codes for Wiretap Channels",
      "title_zh": "Feedback Lunch：面向窃听信道的深度反馈码",
      "authors": [
        "Yingyao Zhou",
        "Natasha Devroye",
        "Onur Günlü"
      ],
      "abstract": "We consider reversely-degraded wiretap channels, for which the secrecy capacity is zero if there is no channel feedback. This work focuses on a seeded modular code design for the Gaussian wiretap channel with channel output feedback, combining universal hash functions for security and learned feedback-based codes for reliability to achieve positive secrecy rates. We study the trade-off between communication reliability and information leakage, illustrating that feedback enables agreeing on a secret key shared between legitimate parties, overcoming the security advantage of the wiretapper. Our findings also motivate code designs for sensing-assisted secure communication, to be used in next-generation integrated sensing and communication methods.",
      "tldr_zh": "该研究探讨了在反向退化窃听信道（reversely-degraded wiretap channels）中利用信道反馈实现安全通信的问题，旨在解决此类信道在无反馈时安全容量为零的困境。作者提出了一种基于种子的模块化编码设计（seeded modular code design），通过结合通用哈希函数（universal hash functions）以确保安全性，并利用深度学习反馈编码（learned feedback-based codes）来提升可靠性。研究表明，反馈机制允许合法通信双方达成密钥共识，从而有效克服窃听者的安全优势并实现正向安全速率（positive secrecy rates）。此外，该工作深入分析了通信可靠性与信息泄露之间的权衡关系。最后，研究成果也为下一代集成感知与通信（ISAC）中感知辅助的安全通信编码设计提供了重要的参考依据。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16620v2",
      "published_date": "2025-10-18 19:22:45 UTC",
      "updated_date": "2025-10-23 04:34:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:11.596856+00:00"
    },
    {
      "arxiv_id": "2510.16614v2",
      "title": "Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards",
      "title_zh": "Count Counts：利用基于计数的内在奖励激励大语言模型推理中的探索",
      "authors": [
        "Xuan Zhang",
        "Ruixiao Li",
        "Zhijian Zhou",
        "Long Li",
        "Yulei Qin",
        "Ke Li",
        "Xing Sun",
        "Xiaoyu Tan",
        "Chao Qu",
        "Yuan Qi"
      ],
      "abstract": "Reinforcement Learning (RL) has become a compelling way to strengthen the multi step reasoning ability of Large Language Models (LLMs). However, prevalent RL paradigms still lean on sparse outcome-based rewards and limited exploration, which often drives LLMs toward repetitive and suboptimal reasoning patterns. In this paper, we study the central question of how to design exploration for LLM reasoning and introduce MERCI (Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that augments policy optimization with a principled intrinsic reward. Building on the idea of count-based exploration, MERCI leverages a lightweight Coin Flipping Network (CFN) to estimate the pseudo count and further epistemic uncertainty over reasoning trajectories, and converts them into an intrinsic reward that values novelty while preserving the learning signal from task rewards. We integrate MERCI into some advanced RL frameworks like Group Relative Policy Optimization (GRPO). Experiments on complex reasoning benchmarks demonstrate that MERCI encourages richer and more varied chains of thought, significantly improves performance over strong baselines, and helps the policy escape local routines to discover better solutions. It indicates that our targeted intrinsic motivation can make exploration reliable for language model reasoning.",
      "tldr_zh": "当前强化学习(RL)范式在提升大语言模型(LLMs)多步推理能力时，常面临稀疏结果奖励和探索不足的挑战，导致模型容易陷入重复且次优的推理模式。该研究提出了 MERCI (Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards)，这是一种通过原则性内在奖励增强策略优化的新型 RL 算法。MERCI 利用轻量级的 Coin Flipping Network (CFN) 来估计推理轨迹的伪计数 (pseudo count) 和认知不确定性 (epistemic uncertainty)，并将其转化为重视新颖性的内在奖励，同时保留任务奖励的学习信号。通过将 MERCI 集成到 Group Relative Policy Optimization (GRPO) 等先进框架中，实验证明该方法能显著促进更丰富且多样的 Chain-of-Thought (CoT) 生成。结果显示，MERCI 在复杂推理基准上显著优于强基线模型，有效帮助策略跳出局部路径以发现更优解。这表明针对性的内在动机可以显著提升语言模型在推理任务中探索的可靠性与有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16614v2",
      "published_date": "2025-10-18 18:57:26 UTC",
      "updated_date": "2025-10-23 04:29:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:15.883307+00:00"
    },
    {
      "arxiv_id": "2510.16611v1",
      "title": "A Deep Learning Framework for Real-Time Image Processing in Medical Diagnostics: Enhancing Accuracy and Speed in Clinical Applications",
      "title_zh": "用于医疗诊断实时图像处理的深度学习框架：提升临床应用中的准确率与速度",
      "authors": [
        "Melika Filvantorkaman",
        "Maral Filvan Torkaman"
      ],
      "abstract": "Medical imaging plays a vital role in modern diagnostics; however, interpreting high-resolution radiological data remains time-consuming and susceptible to variability among clinicians. Traditional image processing techniques often lack the precision, robustness, and speed required for real-time clinical use. To overcome these limitations, this paper introduces a deep learning framework for real-time medical image analysis designed to enhance diagnostic accuracy and computational efficiency across multiple imaging modalities, including X-ray, CT, and MRI. The proposed system integrates advanced neural network architectures such as U-Net, EfficientNet, and Transformer-based models with real-time optimization strategies including model pruning, quantization, and GPU acceleration. The framework enables flexible deployment on edge devices, local servers, and cloud infrastructures, ensuring seamless interoperability with clinical systems such as PACS and EHR. Experimental evaluations on public benchmark datasets demonstrate state-of-the-art performance, achieving classification accuracies above 92%, segmentation Dice scores exceeding 91%, and inference times below 80 milliseconds. Furthermore, visual explanation tools such as Grad-CAM and segmentation overlays enhance transparency and clinical interpretability. These results indicate that the proposed framework can substantially accelerate diagnostic workflows, reduce clinician workload, and support trustworthy AI integration in time-critical healthcare environments.",
      "tldr_zh": "该研究提出了一种用于实时医学影像处理的深度学习框架，旨在解决传统图像处理技术在临床应用中精度不足、鲁棒性差及速度缓慢等限制。该框架集成了 U-Net, EfficientNet 和基于 Transformer 的架构，并结合模型剪枝 (model pruning)、量化 (quantization) 及 GPU 加速等优化策略，实现了低于 80 毫秒的实时推理速度。系统支持在边缘设备、本地服务器及云端灵活部署，并确保与 PACS 和 EHR 等临床系统的无缝互操作。实验结果表明，该模型在多种影像模态下取得了 state-of-the-art 性能，分类准确率超过 92% 且分割 Dice scores 超过 91%。此外，通过引入 Grad-CAM 等视觉解释工具，该框架显著提升了诊断透明度与临床可解释性。该研究成果为加速诊断工作流、降低医生工作负载以及在时间敏感的医疗环境中集成可信 AI 奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.16611v1",
      "published_date": "2025-10-18 18:26:09 UTC",
      "updated_date": "2025-10-18 18:26:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:16.281463+00:00"
    },
    {
      "arxiv_id": "2510.16609v1",
      "title": "Prior Makes It Possible: From Sublinear Graph Algorithms to LLM Test-Time Methods",
      "title_zh": "先验赋予可能：从亚线性图算法到大语言模型测试时方法",
      "authors": [
        "Avrim Blum",
        "Daniel Hsu",
        "Cyrus Rashtchian",
        "Donya Saless"
      ],
      "abstract": "Test-time augmentation, such as Retrieval-Augmented Generation (RAG) or tool use, critically depends on an interplay between a model's parametric knowledge and externally retrieved information. However, the theoretical underpinnings of this relationship remain poorly understood. Specifically, it is not clear how much pre-training knowledge is required to answer queries with a small number of augmentation steps, which is a desirable property in practice. To address this question, we formulate multi-step reasoning as an $s$-$t$ connectivity problem on a knowledge graph. We represent a model's pre-training parametric knowledge as a partial, potentially noisy subgraph. We view augmentation as querying an oracle for true edges that augment the model's knowledge. Then, we characterize the necessary and sufficient number of augmentation steps for the model to generate an accurate answer given partial prior knowledge. One key result shows a phase transition: if the prior knowledge graph over $n$ vertices is disconnected into small components, then finding a path via augmentation is inefficient and requires $Ω(\\sqrt{n})$ queries. On the other hand, once the density of correct knowledge surpasses a threshold, forming a giant component, we can find paths with an expected constant number of queries.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在推理过程中参数化知识与外部增强技术（如RAG或工具使用）之间的理论关系。作者将多步推理形式化为知识图谱上的 $s$-$t$ connectivity 问题，并将模型的预训练知识表示为局部且带噪声的子图。研究通过将增强过程视为查询真实边缘的机制，刻画了模型生成准确答案所需的必要且充分的增强步骤。理论分析揭示了一个显著的相变现象(phase transition)：当先验知识图谱由于密度不足而分裂为微小组件时，寻找推理路径需要 $Ω(\\sqrt{n})$ 次查询，效率极低。然而，一旦正确知识的密度超过特定阈值并形成巨型组件(giant component)，则仅需常数次预期查询即可找到路径。这项工作从亚线性图算法(sublinear graph algorithms)的角度，为理解LLM测试时增强方法的有效性提供了重要的理论框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16609v1",
      "published_date": "2025-10-18 18:17:25 UTC",
      "updated_date": "2025-10-18 18:17:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:17.572943+00:00"
    },
    {
      "arxiv_id": "2510.16607v2",
      "title": "Asymptotically Stable Quaternion-valued Hopfield-structured Neural Network with Periodic Projection-based Supervised Learning Rules",
      "title_zh": "具有周期性投影监督学习规则的渐近稳定四元数值 Hopfield 结构神经网络",
      "authors": [
        "Tianwei Wang",
        "Xinhui Ma",
        "Wei Pang"
      ],
      "abstract": "Motivated by the geometric advantages of quaternions in representing rotations and postures, we propose a quaternion-valued supervised learning Hopfield-structured neural network (QSHNN) with a fully connected structure inspired by the classic Hopfield neural network (HNN). Starting from a continuous-time dynamical model of HNNs, we extend the formulation to the quaternionic domain and establish the existence and uniqueness of fixed points with asymptotic stability. For the learning rules, we introduce a periodic projection strategy that modifies standard gradient descent by periodically projecting each 4*4 block of the weight matrix onto the closest quaternionic structure in the least-squares sense. This approach preserves both convergence and quaternionic consistency throughout training. Benefiting from this rigorous mathematical foundation, the experimental model implementation achieves high accuracy, fast convergence, and strong reliability across randomly generated target sets. Moreover, the evolution trajectories of the QSHNN exhibit well-bounded curvature, i.e., sufficient smoothness, which is crucial for applications such as control systems or path planning modules in robotic arms, where joint postures are parameterized by quaternion neurons. Beyond these application scenarios, the proposed model offers a practical implementation framework and a general mathematical methodology for designing neural networks under hypercomplex or non-commutative algebraic structures.",
      "tldr_zh": "该研究提出了四元数监督学习Hopfield结构神经网络（Quaternion-valued Supervised Learning Hopfield-structured Neural Network, QSHNN），旨在利用四元数在表示旋转和姿态方面的几何优势。研究通过将连续时间Hopfield神经网络(HNN)扩展至四元数域，从数学上证明了不动点（Fixed Points）的存在性、唯一性以及渐近稳定性(Asymptotic Stability)。在学习规则方面，该模型引入了一种周期性投影策略（Periodic Projection Strategy），通过将权重矩阵定期投影到最小二乘法意义下的最近四元数结构，确保了训练过程中的收敛性和四元数一致性(Quaternionic Consistency)。实验结果表明，QSHNN在处理随机生成的目标集时表现出高精度、快速收敛以及极强的可靠性。此外，该模型的进化轨迹展现出良好的有界曲率和平滑性，在涉及参数化关节姿态的机械臂控制或路径规划领域具有显著应用潜力。这项工作不仅提供了实用的实现框架，也为在超复数或非交换代数结构下设计神经网络奠定了通用的数学基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.16607v2",
      "published_date": "2025-10-18 18:10:07 UTC",
      "updated_date": "2026-01-12 23:45:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:31.004151+00:00"
    },
    {
      "arxiv_id": "2510.16601v2",
      "title": "Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning",
      "title_zh": "基于半监督置信度分布学习的不确定知识图谱补全",
      "authors": [
        "Tianxing Wu",
        "Shutong Zhu",
        "Jingting Wang",
        "Ning Xu",
        "Guilin Qi",
        "Haofen Wang"
      ],
      "abstract": "Uncertain knowledge graphs (UKGs) associate each triple with a confidence score to provide more precise knowledge representations. Recently, since real-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG) completion attracts more attention, aiming to complete missing triples and confidences. Current studies attempt to learn UKG embeddings to solve this problem, but they neglect the extremely imbalanced distributions of triple confidences. This causes that the learnt embeddings are insufficient to high-quality UKG completion. Thus, in this paper, to address the above issue, we propose a new semi-supervised Confidence Distribution Learning (ssCDL) method for UKG completion, where each triple confidence is transformed into a confidence distribution to introduce more supervision information of different confidences to reinforce the embedding learning process. ssCDL iteratively learns UKG embedding by relational learning on labeled data (i.e., existing triples with confidences) and unlabeled data with pseudo labels (i.e., unseen triples with the generated confidences), which are predicted by meta-learning to augment the training data and rebalance the distribution of triple confidences. Experiments on two UKG datasets demonstrate that ssCDL consistently outperforms state-of-the-art baselines in different evaluation metrics.",
      "tldr_zh": "该研究针对不确定知识图谱（Uncertain Knowledge Graphs, UKGs）在补全任务中忽略置信度分布极度不平衡这一挑战，提出了一种全新的半监督置信度分布学习（ssCDL）方法。该方法通过将三元组置信度转化为置信度分布，引入了更丰富的监督信息，从而强化了嵌入学习（embedding learning）过程。ssCDL 结合了关系学习（relational learning）与元学习（meta-learning）技术，通过对标注数据和带有伪标签的未标注数据进行迭代学习，实现了训练数据的增强并重新平衡了置信度分布。在两个 UKG 数据集上的实验结果表明，ssCDL 在多项评价指标上均显著优于现有的最先进基准模型。该方法不仅提升了 UKG 补全的性能，也为解决不确定知识表示中的不平衡分布问题提供了有效的技术支撑。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, accepted by NeurIPS 2025 (spotlight)",
      "pdf_url": "https://arxiv.org/pdf/2510.16601v2",
      "published_date": "2025-10-18 17:57:44 UTC",
      "updated_date": "2025-10-21 09:18:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:35.116712+00:00"
    },
    {
      "arxiv_id": "2510.16596v1",
      "title": "SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense",
      "title_zh": "SHIELD：通过偏差与脆弱性防御抑制 LVLM 编码器中的幻觉",
      "authors": [
        "Yiyang Huang",
        "Liang Shi",
        "Yitian Zhang",
        "Yi Xu",
        "Yun Fu"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks. However, object hallucination, where models produce plausible but inaccurate object descriptions, remains a significant challenge. In contrast to previous work focusing on LLM components, this paper is the first to trace LVLM hallucinations to visual encoders and identifies three key issues: statistical bias, inherent bias, and vulnerability. To address these challenges, we propose SHIELD, a training-free framework that mitigates hallucinations through three strategies: re-weighting visual tokens to reduce statistical bias, introducing noise-derived tokens to counter inherent bias, and applying adversarial attacks with contrastive decoding to address vulnerability. Experiments demonstrate that SHIELD effectively mitigates object hallucinations across diverse benchmarks and LVLM families. Moreover, SHIELD achieves strong performance on the general LVLM benchmark, highlighting its broad applicability. Code will be released.",
      "tldr_zh": "该研究探讨了大语言视觉模型 (LVLMs) 中的物体幻觉问题，并首次将此类幻觉的根源追溯到视觉编码器 (visual encoders)，识别出统计偏差 (statistical bias)、固有偏差 (inherent bias) 和脆弱性 (vulnerability) 三个核心问题。为了解决这些挑战，作者提出了 SHIELD，这是一个无需训练 (training-free) 的防御框架，旨在通过针对性策略减轻幻觉。该框架通过对视觉标记 (visual tokens) 进行重加权以减少统计偏差，引入噪声衍生标记 (noise-derived tokens) 来对抗固有偏差，并应用对抗攻击 (adversarial attacks) 结合对比解码 (contrastive decoding) 来应对编码器的脆弱性。实验结果表明，SHIELD 在多种基准测试和不同系列的 LVLMs 中均能有效抑制物体幻觉。此外，SHIELD 在通用 LVLM 基准测试中也展现了强劲的性能，证明了该方法具有广泛的适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16596v1",
      "published_date": "2025-10-18 17:49:43 UTC",
      "updated_date": "2025-10-18 17:49:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:37.278218+00:00"
    },
    {
      "arxiv_id": "2510.16591v1",
      "title": "Symmetry and Generalisation in Neural Approximations of Renormalisation Transformations",
      "title_zh": "重整化变换神经网络近似中的对称性与泛化",
      "authors": [
        "Cassidy Ashworth",
        "Pietro Liò",
        "Francesco Caso"
      ],
      "abstract": "Deep learning models have proven enormously successful at using multiple layers of representation to learn relevant features of structured data. Encoding physical symmetries into these models can improve performance on difficult tasks, and recent work has motivated the principle of parameter symmetry breaking and restoration as a unifying mechanism underlying their hierarchical learning dynamics. We evaluate the role of parameter symmetry and network expressivity in the generalisation behaviour of neural networks when learning a real-space renormalisation group (RG) transformation, using the central limit theorem (CLT) as a test case map. We consider simple multilayer perceptrons (MLPs) and graph neural networks (GNNs), and vary weight symmetries and activation functions across architectures. Our results reveal a competition between symmetry constraints and expressivity, with overly complex or overconstrained models generalising poorly. We analytically demonstrate this poor generalisation behaviour for certain constrained MLP architectures by recasting the CLT as a cumulant recursion relation and making use of an established framework to propagate cumulants through MLPs. We also empirically validate an extension of this framework from MLPs to GNNs, elucidating the internal information processing performed by these more complex models. These findings offer new insight into the learning dynamics of symmetric networks and their limitations in modelling structured physical transformations.",
      "tldr_zh": "该研究探讨了参数对称性(Parameter Symmetry)与网络表达能力(Network Expressivity)在神经网络学习实空间重整化群(Renormalisation Group, RG)变换中的泛化作用。研究人员以中心极限定理(Central Limit Theorem, CLT)为测试案例，对比分析了多层感知器(MLPs)和图神经网络(GNNs)在不同权重对称性下的表现。实验结果揭示了对称性约束与模型表达能力之间的竞争机制，发现过于复杂或过度约束的模型往往泛化表现不佳。通过将CLT转化为累积量递归关系(Cumulant Recursion Relation)，该研究解析地论证了特定架构的泛化缺陷。此外，研究还将分析框架成功扩展至GNNs，从而阐明了复杂对称模型内部的信息处理逻辑。这些研究成果为理解对称网络的学习动力学以及在物理变换建模中的局限性提供了重要理论支撑。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16591v1",
      "published_date": "2025-10-18 17:29:23 UTC",
      "updated_date": "2025-10-18 17:29:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:42.887740+00:00"
    },
    {
      "arxiv_id": "2510.16590v1",
      "title": "Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration",
      "title_zh": "原子锚定的大语言模型对话化学：逆合成应用演示",
      "authors": [
        "Alan Kai Hassen",
        "Andrius Bernatavicius",
        "Antonius P. A. Janssen",
        "Mike Preuss",
        "Gerard J. P. van Westen",
        "Djork-Arné Clevert"
      ],
      "abstract": "Applications of machine learning in chemistry are often limited by the scarcity and expense of labeled data, restricting traditional supervised methods. In this work, we introduce a framework for molecular reasoning using general-purpose Large Language Models (LLMs) that operates without requiring labeled training data. Our method anchors chain-of-thought reasoning to the molecular structure by using unique atomic identifiers. First, the LLM performs a one-shot task to identify relevant fragments and their associated chemical labels or transformation classes. In an optional second step, this position-aware information is used in a few-shot task with provided class examples to predict the chemical transformation. We apply our framework to single-step retrosynthesis, a task where LLMs have previously underperformed. Across academic benchmarks and expert-validated drug discovery molecules, our work enables LLMs to achieve high success rates in identifying chemically plausible reaction sites ($\\geq90\\%$), named reaction classes ($\\geq40\\%$), and final reactants ($\\geq74\\%$). Beyond solving complex chemical tasks, our work also provides a method to generate theoretically grounded synthetic datasets by mapping chemical knowledge onto the molecular structure and thereby addressing data scarcity.",
      "tldr_zh": "该研究针对化学领域标记数据匮乏的挑战，提出了一种利用通用大语言模型(LLMs)进行分子推理的新框架，该框架无需标记训练数据即可运行。其核心方法是通过使用唯一的原子标识符，将链式思维(Chain-of-Thought)推理过程直接锚定在分子结构上。在执行过程中，LLMs首先通过 one-shot 任务识别分子片段及其化学标签，随后利用位置感知信息在 few-shot 任务中预测化学转化。研究者将该框架应用于挑战性极高的单步逆合成(Single-step retrosynthesis)任务，实验结果显示，在识别反应位点、反应类别以及最终反应物方面的成功率分别达到了90%、40%和74%以上。此外，该工作还提供了一种将化学知识映射到分子结构以生成合成数据集的方法，为解决化学数据稀缺问题提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "Alan Kai Hassen and Andrius Bernatavicius contributed equally to this work",
      "pdf_url": "https://arxiv.org/pdf/2510.16590v1",
      "published_date": "2025-10-18 17:27:44 UTC",
      "updated_date": "2025-10-18 17:27:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:45.079335+00:00"
    },
    {
      "arxiv_id": "2510.16582v1",
      "title": "Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?",
      "title_zh": "基于知识图谱的检索增强生成：真的能检索到你所需的信息吗？",
      "authors": [
        "Junchi Yu",
        "Yujie Liu",
        "Jindong Gu",
        "Philip Torr",
        "Dongzhan Zhou"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances large language models (LLMs) by providing structured and interpretable external knowledge. However, existing KG-based RAG methods struggle to retrieve accurate and diverse information from text-rich KGs for complex real-world queries. Process Reward Models (PRMs) offer a way to align the retrieval process of KG-based RAG with query-specific knowledge requirements, but they heavily rely on process-level supervision signals that are expensive and hard to obtain on KGs. To address this challenge, we propose GraphFlow, a framework that efficiently retrieves accurate and diverse knowledge required for real-world queries from text-rich KGs. GraphFlow employs a transition-based flow matching objective to jointly optimize a retrieval policy and a flow estimator. The flow estimator factorizes the reward of the retrieval outcome into the intermediate retrieval states. Such reward factorization guides the retrieval policy to retrieve candidates from KGs in proportion to their reward. This allows GraphFlow to explore high-quality regions of KGs that yield diverse and relevant results. We evaluate GraphFlow on the STaRK benchmark, which includes real-world queries from multiple domains over text-rich KGs. GraphFlow outperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit rate and recall. It also shows strong generalization to unseen KGs, demonstrating its effectiveness and robustness.",
      "tldr_zh": "该研究针对基于知识图谱(KG)的检索增强生成(RAG)在处理文本丰富的知识图谱和复杂真实查询时难以获取准确且多样化信息的问题，提出了 GraphFlow 框架。该框架引入了转移流匹配(transition-based flow matching)目标，通过流估计器将最终检索奖励因子化为中间状态奖励，有效解决了过程奖励模型(PRMs)依赖昂贵监督信号的难题。GraphFlow 能够引导检索策略按奖励比例探索高质量知识区域，从而在知识图谱中检索出更具相关性与多样性的候选结果。在 STaRK 基准测试中的实验结果显示，GraphFlow 在命中率和召回率上平均优于 GPT-4o 等强基准模型 10%。此外，该框架展现出卓越的泛化能力，能够有效处理未见的知识图谱，为提升复杂真实场景下的知识检索质量提供了有效且鲁棒的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2025 (Spotlight)",
      "pdf_url": "https://arxiv.org/pdf/2510.16582v1",
      "published_date": "2025-10-18 17:06:49 UTC",
      "updated_date": "2025-10-18 17:06:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:45.980459+00:00"
    },
    {
      "arxiv_id": "2510.16573v1",
      "title": "AI-Generated Text Detection in Low-Resource Languages: A Case Study on Urdu",
      "title_zh": "低资源语言 AI 生成文本检测：以 Urdu 为例的案例研究",
      "authors": [
        "Muhammad Ammar",
        "Hadiya Murad Hadi",
        "Usman Majeed Butt"
      ],
      "abstract": "Large Language Models (LLMs) are now capable of generating text that closely resembles human writing, making them powerful tools for content creation, but this growing ability has also made it harder to tell whether a piece of text was written by a human or by a machine. This challenge becomes even more serious for languages like Urdu, where there are very few tools available to detect AI-generated text. To address this gap, we propose a novel AI-generated text detection framework tailored for the Urdu language. A balanced dataset comprising 1,800 humans authored, and 1,800 AI generated texts, sourced from models such as Gemini, GPT-4o-mini, and Kimi AI was developed. Detailed linguistic and statistical analysis was conducted, focusing on features such as character and word counts, vocabulary richness (Type Token Ratio), and N-gram patterns, with significance evaluated through t-tests and MannWhitney U tests. Three state-of-the-art multilingual transformer models such as mdeberta-v3-base, distilbert-base-multilingualcased, and xlm-roberta-base were fine-tuned on this dataset. The mDeBERTa-v3-base achieved the highest performance, with an F1-score 91.29 and accuracy of 91.26% on the test set. This research advances efforts in contesting misinformation and academic misconduct in Urdu-speaking communities and contributes to the broader development of NLP tools for low resource languages.",
      "tldr_zh": "该研究针对乌尔都语(Urdu)等低资源语言在AI生成文本检测工具方面的匮乏，提出了一个专门的检测框架。研究团队构建了一个平衡数据集，包含1,800篇人类撰写和1,800篇由Gemini、GPT-4o-mini及Kimi AI生成的文本。通过对词汇丰富度(Type Token Ratio)和N-gram模式等特征进行详细的语言学与统计学分析，研究利用t-tests和Mann-Whitney U tests验证了特征的显著性。实验微调了mdeberta-v3-base、distilbert-base-multilingual-cased和xlm-roberta-base三种多语言Transformer模型。其中mDeBERTa-v3-base表现最为出色，在测试集上达到了91.29%的F1分数和91.26%的准确率。该研究为应对乌尔都语社区的虚假信息和学术不端行为提供了有力支持，并为低资源语言的自然语言处理(NLP)工具开发做出了重要贡献。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16573v1",
      "published_date": "2025-10-18 16:45:25 UTC",
      "updated_date": "2025-10-18 16:45:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:52.903391+00:00"
    },
    {
      "arxiv_id": "2510.16572v1",
      "title": "Ripple Effect Protocol: Coordinating Agent Populations",
      "title_zh": "Ripple Effect Protocol：智能体群体的协同机制",
      "authors": [
        "Ayush Chopra",
        "Aman Sharma",
        "Feroz Ahmad",
        "Luca Muscariello",
        "Vijoy Pandey",
        "Ramesh Raskar"
      ],
      "abstract": "Modern AI agents can exchange messages using protocols such as A2A and ACP, yet these mechanisms emphasize communication over coordination. As agent populations grow, this limitation produces brittle collective behavior, where individually smart agents converge on poor group outcomes. We introduce the Ripple Effect Protocol (REP), a coordination protocol in which agents share not only their decisions but also lightweight sensitivities - signals expressing how their choices would change if key environmental variables shifted. These sensitivities ripple through local networks, enabling groups to align faster and more stably than with agent-centric communication alone. We formalize REP's protocol specification, separating required message schemas from optional aggregation rules, and evaluate it across scenarios with varying incentives and network topologies. Benchmarks across three domains: (i) supply chain cascades (Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling), and (iii) sustainable resource allocation (Fishbanks) show that REP improves coordination accuracy and efficiency over A2A by 41 to 100%, while flexibly handling multimodal sensitivity signals from LLMs. By making coordination a protocol-level capability, REP provides scalable infrastructure for the emerging Internet of Agents",
      "tldr_zh": "该研究提出了Ripple Effect Protocol (REP)，旨在解决现代AI智能体群体在扩大规模时因缺乏协调机制而产生的集体行为脆弱性。REP协议允许智能体不仅交换决策结果，还分享轻量级的感应度(sensitivities)信号，以表达在环境变量变化时其选择的潜在变动趋势。这些信号通过局部网络产生涟漪效应，使得智能体群体能够比传统的A2A通信方式更快、更稳定地实现目标对齐。研究人员在供应链级联(Beer Game)、电影调度(Movie Scheduling)和可持续资源分配(Fishbanks)三个领域进行了测试，结果显示REP在协调准确性和效率上比A2A提升了41%至100%。该协议能够灵活处理来自大型语言模型(LLMs)的多模态感应度信号，并将协调能力转化为协议层级的标准功能。REP为构建可扩展的智能体互联网(Internet of Agents)提供了关键的基础设施，有效提升了复杂网络拓扑下的群体决策质量。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16572v1",
      "published_date": "2025-10-18 16:38:03 UTC",
      "updated_date": "2025-10-18 16:38:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:52.370799+00:00"
    },
    {
      "arxiv_id": "2510.21783v1",
      "title": "Noise Aggregation Analysis Driven by Small-Noise Injection: Efficient Membership Inference for Diffusion Models",
      "title_zh": "微小噪声注入驱动的噪声聚合分析：扩散模型的高效成员推理",
      "authors": [
        "Guo Li",
        "Yuyang Yu",
        "Xuemiao Xu"
      ],
      "abstract": "Diffusion models have demonstrated powerful performance in generating high-quality images. A typical example is text-to-image generator like Stable Diffusion. However, their widespread use also poses potential privacy risks. A key concern is membership inference attacks, which attempt to determine whether a particular data sample was used in the model training process. We propose an efficient membership inference attack method against diffusion models. This method is based on the injection of slight noise and the evaluation of the aggregation degree of the noise distribution. The intuition is that the noise prediction patterns of diffusion models for training set samples and non-training set samples exhibit distinguishable differences.Specifically, we suppose that member images exhibit higher aggregation of predicted noise around a certain time step of the diffusion process. In contrast, the predicted noises of non-member images exhibit a more discrete characteristic around the certain time step. Compared with other existing methods, our proposed method requires fewer visits to the target diffusion model. We inject slight noise into the image under test and then determine its membership by analyzing the aggregation degree of the noise distribution predicted by the model. Empirical findings indicate that our method achieves superior performance across multiple datasets. At the same time, our method can also show better attack effects in ASR and AUC when facing large-scale text-to-image diffusion models, proving the scalability of our method.",
      "tldr_zh": "该研究针对扩散模型 (Diffusion models) 的隐私安全问题，提出了一种基于小噪声注入和噪声聚合度分析的高效成员推理攻击 (Membership Inference Attacks) 方法。研究发现，扩散模型对训练集成员图像和非成员图像的噪声预测模式存在显著差异，成员图像在特定扩散时间步展现出更高的预测噪声聚合度 (Aggregation degree)，而非成员图像则表现出更明显的离散性。通过向待测图像注入微量噪声并分析其预测噪声分布的聚合程度，该方法能够有效判定其成员身份。实验结果表明，该方法在多个数据集上均优于现有攻击手段，且在面对大规模文本生成图像模型时展现出更高的攻击成功率 (ASR) 和 AUC。此外，该方法显著减少了对目标模型的访问次数，证明了其优越的效率和可扩展性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21783v1",
      "published_date": "2025-10-18 16:28:48 UTC",
      "updated_date": "2025-10-18 16:28:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:54.578030+00:00"
    },
    {
      "arxiv_id": "2510.16565v2",
      "title": "Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models",
      "title_zh": "语言重于内容：多语言大语言模型文化理解机制的溯源",
      "authors": [
        "Seungho Cho",
        "Changgeon Ko",
        "Eui Jun Hwang",
        "Junmyeong Lee",
        "Huije Lee",
        "Jong C. Park"
      ],
      "abstract": "Large language models (LLMs) are increasingly used across diverse cultural contexts, making accurate cultural understanding essential. Prior evaluations have mostly focused on output-level performance, obscuring the factors that drive differences in responses, while studies using circuit analysis have covered few languages and rarely focused on culture. In this work, we trace LLMs' internal cultural understanding mechanisms by measuring activation path overlaps when answering semantically equivalent questions under two conditions: varying the target country while fixing the question language, and varying the question language while fixing the country. We also use same-language country pairs to disentangle language from cultural aspects. Results show that internal paths overlap more for same-language, cross-country questions than for cross-language, same-country questions, indicating strong language-specific patterns. Notably, the South Korea-North Korea pair exhibits low overlap and high variability, showing that linguistic similarity does not guarantee aligned internal representation.",
      "tldr_zh": "该研究旨在探究多语言大语言模型（LLMs）内部的文化理解机制，通过分析在不同语言与国家组合下回答语义等价问题时的激活路径重合度（activation path overlaps）来追踪其运作逻辑。研究者对比了“固定语言变动国家”与“固定国家变动语言”两种情境，并利用同语言国家对来分离语言与文化的影响。实验结果表明，相同语言、跨国家的内部路径重合度显著高于跨语言、相同国家的重合度，显示出模型具有强烈的语言特定模式（language-specific patterns）。特别是针对韩国与朝鲜的研究发现，较低的路径重合度与高变异性证明了语言相似性并不等同于内部表征的对齐。这一发现揭示了在当前的多语言模型中，语言形式对内部机制的影响力往往超过了实际的文化内容。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to CIKM 2025 Workshop on Human Centric AI",
      "pdf_url": "https://arxiv.org/pdf/2510.16565v2",
      "published_date": "2025-10-18 16:19:45 UTC",
      "updated_date": "2025-11-11 04:32:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:12:59.797542+00:00"
    },
    {
      "arxiv_id": "2510.16559v3",
      "title": "BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction",
      "title_zh": "BuildArena：面向工程建设的大语言模型物理对齐交互式基准",
      "authors": [
        "Tian Xia",
        "Tianrun Gao",
        "Wenhao Deng",
        "Long Wei",
        "Xiaowei Qian",
        "Yixian Jiang",
        "Chenglei Yu",
        "Tailin Wu"
      ],
      "abstract": "Engineering construction automation aims to transform natural language specifications into physically viable structures, requiring complex integrated reasoning under strict physical constraints. While modern LLMs possess broad knowledge and strong reasoning capabilities that make them promising candidates for this domain, their construction competencies remain largely unevaluated. To address this gap, we introduce BuildArena, the first physics-aligned interactive benchmark designed for language-driven engineering construction. It contributes to the community in four aspects: (1) a highly customizable benchmarking framework for in-depth comparison and analysis of LLMs; (2) an extendable task design strategy spanning static and dynamic mechanics across multiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for supporting construction based on language instructions; (4) a baseline LLM agentic workflow that effectively evaluates diverse model capabilities. On eight frontier LLMs, BuildArena comprehensively evaluates their capabilities for language-driven and physics-grounded construction automation. The project page is at https://build-arena.github.io/.",
      "tldr_zh": "该研究推出了 BuildArena，这是首个专为语言驱动的工程建设设计的物理对齐交互式基准测试(Physics-Aligned Interactive Benchmark)，旨在评估大语言模型(LLMs)在遵循严格物理约束下进行复杂集成推理的能力。该基准提供了一个高度可定制的框架和涵盖多难度等级静态与动态力学的任务设计策略，并引入了 3D Spatial Geometric Computation Library 以支持基于语言指令的建筑生成。此外，研究团队设计了一个基准 LLM 代理工作流(Agentic Workflow)，用以评估模型在物理落地(Physics-Grounded)场景下的自动化表现。通过对八种前沿 LLMs 的实验评估，BuildArena 全面分析了当前模型在工程自动化领域的潜力和局限，为实现从自然语言到物理可行结构的转化奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.16559v3",
      "published_date": "2025-10-18 16:13:50 UTC",
      "updated_date": "2025-10-31 05:31:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:10.790250+00:00"
    },
    {
      "arxiv_id": "2510.16558v1",
      "title": "Toward Understanding Security Issues in the Model Context Protocol Ecosystem",
      "title_zh": "深入探究 Model Context Protocol 生态系统的安全问题",
      "authors": [
        "Xiaofan Li",
        "Xing Gao"
      ],
      "abstract": "The Model Context Protocol (MCP) is an emerging open standard that enables AI-powered applications to interact with external tools through structured metadata. A rapidly growing ecosystem has formed around MCP, including a wide range of MCP hosts (i.e., Cursor, Windsurf, Claude Desktop, and Cline), MCP registries (i.e., mcp.so, MCP Market, MCP Store, Pulse MCP, Smithery, and npm), and thousands of community-contributed MCP servers. Although the MCP ecosystem is gaining traction, there has been little systematic study of its architecture and associated security risks. In this paper, we present the first comprehensive security analysis of the MCP ecosystem. We decompose MCP ecosystem into three core components: hosts, registries, and servers, and study the interactions and trust relationships among them. Users search for servers on registries and configure them in the host, which translates LLM-generated output into external tool invocations provided by the servers and executes them. Our qualitative analysis reveals that hosts lack output verification mechanisms for LLM-generated outputs, enabling malicious servers to manipulate model behavior and induce a variety of security threats, including but not limited to sensitive data exfiltration. We uncover a wide range of vulnerabilities that enable attackers to hijack servers, due to the lack of a vetted server submission process in registries. To support our analysis, we collect and analyze a dataset of 67,057 servers from six public registries. Our quantitative analysis demonstrates that a substantial number of servers can be hijacked by attackers. Finally, we propose practical defense strategies for MCP hosts, registries, and users. We responsibly disclosed our findings to affected hosts and registries.",
      "tldr_zh": "该研究针对新兴的Model Context Protocol (MCP)生态系统进行了首次全面的安全分析，旨在系统探讨其架构设计及潜在的安全威胁。研究者将MCP生态系统分解为宿主(hosts)、注册表(registries)和服务器(servers)三个核心组件，详细考察了它们之间的交互逻辑与信任关系。定性分析揭示，由于hosts缺乏对LLM生成输出的有效验证机制，恶意servers能够操纵模型行为并诱发包括敏感数据外泄(data exfiltration)在内的多种安全风险。同时，由于registries缺乏严格的服务器提交审查流程，研究发现了多种允许攻击者劫持服务器的漏洞。通过对六个公共注册表中67,057个服务器的大规模定量分析，研究证实了大量服务器存在被劫持的现实风险。最后，论文提出了针对不同参与方的实用防御策略，并向相关受影响平台履行了负责任的漏洞披露。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16558v1",
      "published_date": "2025-10-18 16:09:05 UTC",
      "updated_date": "2025-10-18 16:09:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:17.293268+00:00"
    },
    {
      "arxiv_id": "2510.16555v1",
      "title": "Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence",
      "title_zh": "Urban-R1：通过强化多模态大语言模型缓解城市通用智能的地理空间偏差",
      "authors": [
        "Qiongyan Wang",
        "Xingchen Zou",
        "Yutian Jiang",
        "Haomin Wen",
        "Jiaheng Wei",
        "Qingsong Wen",
        "Yuxuan Liang"
      ],
      "abstract": "Rapid urbanization intensifies the demand for Urban General Intelligence (UGI), referring to AI systems that can understand and reason about complex urban environments. Recent studies have built urban foundation models using supervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit persistent geospatial bias, producing regionally skewed predictions and limited generalization. To this end, we propose Urban-R1, a reinforcement learning-based post-training framework that aligns MLLMs with the objectives of UGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize reasoning across geographic groups and employs urban region profiling as a proxy task to provide measurable rewards from multimodal urban data. Extensive experiments across diverse regions and tasks show that Urban-R1 effectively mitigates geo-bias and improves cross-region generalization, outperforming both SFT-trained and closed-source models. Our results highlight reinforcement learning alignment as a promising pathway toward equitable and trustworthy urban intelligence.",
      "tldr_zh": "该研究针对城市通用智能(Urban General Intelligence)领域中现有模型存在的地理空间偏差(geospatial bias)及泛化能力受限问题，提出了Urban-R1框架。Urban-R1是一种基于强化学习(reinforcement learning)的后训练框架，旨在实现多模态大语言模型(MLLMs)与城市通用智能目标的对齐。该框架创新性地采用了组相对策略优化(Group Relative Policy Optimization)来优化不同地理群体间的推理过程，并利用城市区域画像(urban region profiling)作为代理任务，从多模态城市数据中获取可衡量的奖励。实验结果表明，Urban-R1在缓解地理偏差和提升跨区域泛化方面显著优于监督微调(SFT)模型及闭源模型。该研究证明了强化学习对齐是实现公平、可靠城市智能的一条极具前景的路径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16555v1",
      "published_date": "2025-10-18 15:59:09 UTC",
      "updated_date": "2025-10-18 15:59:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:21.684718+00:00"
    },
    {
      "arxiv_id": "2510.16552v1",
      "title": "LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs",
      "title_zh": "LANPO：利用语言与数值反馈引导大语言模型强化学习",
      "authors": [
        "Ang Li",
        "Yifei Wang",
        "Zhihang Yuan",
        "Stefanie Jegelka",
        "Yisen Wang"
      ],
      "abstract": "Reinforcement learning in large language models (LLMs) often relies on scalar rewards, a practice that discards valuable textual rationale buried in the rollouts, forcing the model to explore \\textit{de novo} with each attempt and hindering sample efficiency. While LLMs can uniquely learn from language feedback provided in-context, naively integrating on-line experiences into RL training presents a paradox: feedback from the same problem risks information leakage and memorization, while feedback from different problems often leads to behavior collapse due to irrelevant context. To resolve this tension, we propose \\textbf{Language-And-Numerical Policy Optimization (LANPO)}, a framework that cleanly separates the roles of feedback: language guides exploration, while numerical rewards drive optimization. LANPO builds a dynamic experience pool from past trials and introduces two principles to ensure feedback is effective: \\emph{Reward-Agnostic Reflection} for safe intra-sample self-correction and \\emph{Relevant Abstraction} to distill generalizable lessons from inter-sample experiences. Across mathematical reasoning benchmarks, LANPO enables 7B and 14B models to significantly outperform strong baselines trained with GRPO in test accuracy. Our work provides a robust method for integrating historical experiences into the LLM RL loop, creating more effective and data-efficient learning agents.",
      "tldr_zh": "该研究提出了 LANPO (Language-And-Numerical Policy Optimization) 框架，旨在解决大语言模型 (LLMs) 在强化学习 (RL) 中仅依赖标量奖励而忽略文本逻辑 (textual rationale) 导致的样本效率低下问题。LANPO 创新性地将反馈角色分离，利用语言反馈引导探索 (exploration)，并使用数值奖励驱动优化 (optimization)。该框架构建了一个动态经验池，并引入了 Reward-Agnostic Reflection 机制进行安全的样本内自我修正，以及 Relevant Abstraction 机制从样本间经验中提炼通用规律，从而有效避免了信息泄露或行为坍缩。实验结果显示，采用 LANPO 的 7B 和 14B 模型在数学推理基准测试中的测试准确率显著优于使用 GRPO 训练的强基线模型。这项研究为将历史经验有效整合进 LLM 的强化学习闭环提供了一种稳健的方法，显著提升了学习智能体的数据效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16552v1",
      "published_date": "2025-10-18 15:51:19 UTC",
      "updated_date": "2025-10-18 15:51:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:21.490936+00:00"
    },
    {
      "arxiv_id": "2510.16547v1",
      "title": "Predicting life satisfaction using machine learning and explainable AI",
      "title_zh": "基于机器学习与可解释人工智能的生活满意度预测",
      "authors": [
        "Alif Elham Khan",
        "Mohammad Junayed Hasan",
        "Humayra Anjum",
        "Nabeel Mohammed",
        "Sifat Momen"
      ],
      "abstract": "Life satisfaction is a crucial facet of human well-being. Hence, research on life satisfaction is incumbent for understanding how individuals experience their lives and influencing interventions targeted at enhancing mental health and well-being. Life satisfaction has traditionally been measured using analog, complicated, and frequently error-prone methods. These methods raise questions concerning validation and propagation. However, this study demonstrates the potential for machine learning algorithms to predict life satisfaction with a high accuracy of 93.80% and a 73.00% macro F1-score. The dataset comes from a government survey of 19000 people aged 16-64 years in Denmark. Using feature learning techniques, 27 significant questions for assessing contentment were extracted, making the study highly reproducible, simple, and easily interpretable. Furthermore, clinical and biomedical large language models (LLMs) were explored for predicting life satisfaction by converting tabular data into natural language sentences through mapping and adding meaningful counterparts, achieving an accuracy of 93.74% and macro F1-score of 73.21%. It was found that life satisfaction prediction is more closely related to the biomedical domain than the clinical domain. Ablation studies were also conducted to understand the impact of data resampling and feature selection techniques on model performance. Moreover, the correlation between primary determinants with different age brackets was analyzed, and it was found that health condition is the most important determinant across all ages. This study demonstrates how machine learning, large language models and XAI can jointly contribute to building trust and understanding in using AI to investigate human behavior, with significant ramifications for academics and professionals working to quantify and comprehend subjective well-being.",
      "tldr_zh": "该研究旨在利用机器学习和可解释人工智能(Explainable AI, XAI)技术，改进传统复杂且易出错的生活满意度测量方法。研究采用了丹麦政府对1.9万名16至64岁人群的调查数据集，通过特征学习(feature learning)技术提取了27个显著影响满意度的核心问题，显著提升了研究的可重复性和可解释性。实验结果显示，机器学习算法在此任务中达到了93.80%的准确率，而通过将表格数据转化为自然语言，临床与生物医学大语言模型(LLMs)也取得了93.74%的高准确率。研究进一步发现，生活满意度预测与生物医学领域的关联度高于临床领域，且消融实验验证了数据重采样和特征选择对性能的影响。通过XAI分析不同年龄段的决定因素，研究证实健康状况是跨年龄段最重要的核心影响因素。该项工作展示了AI技术在研究人类行为和量化主观幸福感方面的巨大潜力，为相关领域的学术研究和专业实践提供了重要参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16547v1",
      "published_date": "2025-10-18 15:44:25 UTC",
      "updated_date": "2025-10-18 15:44:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:23.892028+00:00"
    },
    {
      "arxiv_id": "2510.16541v1",
      "title": "Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition",
      "title_zh": "聚焦运动区域：面向步态识别的区域感知动态聚合与激励",
      "authors": [
        "Binyuan Huang",
        "Yongdong Luo",
        "Xianda Guo",
        "Xiawu Zheng",
        "Zheng Zhu",
        "Jiahui Pan",
        "Chengju Zhou"
      ],
      "abstract": "Deep learning-based gait recognition has achieved great success in various applications. The key to accurate gait recognition lies in considering the unique and diverse behavior patterns in different motion regions, especially when covariates affect visual appearance. However, existing methods typically use predefined regions for temporal modeling, with fixed or equivalent temporal scales assigned to different types of regions, which makes it difficult to model motion regions that change dynamically over time and adapt to their specific patterns. To tackle this problem, we introduce a Region-aware Dynamic Aggregation and Excitation framework (GaitRDAE) that automatically searches for motion regions, assigns adaptive temporal scales and applies corresponding attention. Specifically, the framework includes two core modules: the Region-aware Dynamic Aggregation (RDA) module, which dynamically searches the optimal temporal receptive field for each region, and the Region-aware Dynamic Excitation (RDE) module, which emphasizes the learning of motion regions containing more stable behavior patterns while suppressing attention to static regions that are more susceptible to covariates. Experimental results show that GaitRDAE achieves state-of-the-art performance on several benchmark datasets.",
      "tldr_zh": "该研究针对步态识别(Gait Recognition)中预定义区域和固定时间尺度难以捕捉动态运动模式的问题，提出了Region-aware Dynamic Aggregation and Excitation (GaitRDAE)框架。该框架能够自动搜索运动区域并分配自适应时间尺度，其核心包含Region-aware Dynamic Aggregation (RDA)和Region-aware Dynamic Excitation (RDE)两个模块。RDA模块负责为不同区域动态寻找最佳的时间感受野(Temporal Receptive Field)，而RDE模块则通过增强稳定行为区域并抑制易受协变量影响的静态区域来优化特征学习。实验结果证明，GaitRDAE在多个主流基准数据集上均取得了State-of-the-art的性能。该研究通过区域感知和动态调整机制，显著提升了模型在复杂场景下对步态特征的建模能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16541v1",
      "published_date": "2025-10-18 15:36:08 UTC",
      "updated_date": "2025-10-18 15:36:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:30.900741+00:00"
    },
    {
      "arxiv_id": "2510.16540v1",
      "title": "Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions",
      "title_zh": "通过文本描述重建与对齐增强 CLIP 的组合性推理",
      "authors": [
        "Jihoon Kwon",
        "Kyle Min",
        "Jy-yong Sohn"
      ],
      "abstract": "Despite recent advances, vision-language models trained with standard contrastive objectives still struggle with compositional reasoning -- the ability to understand structured relationships between visual and linguistic elements. This shortcoming is largely due to the tendency of the text encoder to focus on individual words rather than their relations, a limitation reinforced by contrastive training that primarily aligns words with visual objects. In this paper, we introduce REconstruction and Alignment of text Descriptions (READ), a fine-tuning method designed to enhance compositional reasoning by adding two auxiliary objectives to the contrastive learning: (1) a token-level reconstruction objective, where a frozen pre-trained decoder reconstructs alternative captions based on the embedding of the original caption; and (2) a sentence-level alignment objective, which explicitly aligns paraphrased sentences in the embedding space. We show that READ-CLIP, a model derived by applying the READ method to the pre-trained CLIP model, achieves the state-of-the-art performance across five major compositional reasoning benchmarks, outperforming the strongest conventional fine-tuning baseline by up to 4.1%. Furthermore, applying the READ to existing CLIP variants (including NegCLIP and FSC-CLIP) also improves performance on these benchmarks. Quantitative and qualitative analyses reveal that our proposed objectives -- reconstruction and alignment -- offer complementary benefits: the former encourages the encoder to capture relationships between words within a caption, while the latter ensures consistent representations for paraphrases expressed with different wording.",
      "tldr_zh": "该研究针对视觉语言模型 CLIP 在处理组合推理(compositional reasoning)时倾向于关注单个单词而非结构化关系的局限性，提出了名为 READ (REconstruction and Alignment of text Descriptions) 的微调方法。READ 通过在标准对比学习中引入令牌级重构(token-level reconstruction)和句子级对齐(sentence-level alignment)两个辅助目标，旨在强化模型对文本描述中元素间关系的建模能力。其中令牌级重构目标利用冻结的解码器强制编码器捕捉词间关联，而句子级对齐目标则确保改写句子在嵌入空间中的一致性。实验结果显示，READ-CLIP 在五个主流组合推理基准测试上均实现了 state-of-the-art 性能，比强力微调基线模型性能提升高达 4.1%。此外，READ 方法还能有效增强 NegCLIP 和 FSC-CLIP 等现有变体的性能，定量和定性分析均证明了重构与对齐两个辅助目标在捕捉关系与保持表示一致性上的互补优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at NeurIPS 2025 (poster). This is the camera-ready version",
      "pdf_url": "https://arxiv.org/pdf/2510.16540v1",
      "published_date": "2025-10-18 15:35:36 UTC",
      "updated_date": "2025-10-18 15:35:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:30.701987+00:00"
    },
    {
      "arxiv_id": "2510.17890v2",
      "title": "MIN-Merging: Merge the Important Neurons for Model Merging",
      "title_zh": "MIN-Merging：面向模型合并的重要神经元合并方法",
      "authors": [
        "Yunfei Liang"
      ],
      "abstract": "Recent advances in deep learning have led to a surge of open-source models across diverse domains. While model merging offers a promising way to combine their strengths, existing approaches often suffer from parameter conflicts that degrade performance on domain-specific tasks. We propose MIN-Merging, a router-based framework that selectively merges the most important neurons to reduce such conflicts. Extensive experiments on Computer Vision(CV) and Natural Language Processing(NLP) benchmarks show that MIN-Merging achieves consistent gains on in-domain tasks while retaining the generalization ability of pretrained models on out-of-domain tasks. These results highlight its effectiveness as a practical solution to the parameter conflict problem in model merging.",
      "tldr_zh": "该研究针对现有模型合并方法中存在的 parameter conflicts 导致领域特定任务性能下降的问题，提出了 MIN-Merging 框架。MIN-Merging 是一种 router-based framework，通过选择性地合并 most important neurons 来减少参数冲突。在 Computer Vision (CV) 和 Natural Language Processing (NLP) 基准测试上的大量实验表明，该方法在 in-domain tasks 上取得了显著且持续的性能增益。同时，该框架能够有效保留预训练模型在 out-of-domain tasks 上的 generalization ability。研究结果证明了 MIN-Merging 是解决模型合并中参数冲突问题的一种实用且高效的方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Withdrawn due to an error in Section 3; a corrected version will be posted soon",
      "pdf_url": "https://arxiv.org/pdf/2510.17890v2",
      "published_date": "2025-10-18 15:23:36 UTC",
      "updated_date": "2025-10-26 11:00:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:32.892907+00:00"
    },
    {
      "arxiv_id": "2510.16536v1",
      "title": "Few-Label Multimodal Modeling of SNP Variants and ECG Phenotypes Using Large Language Models for Cardiovascular Risk Stratification",
      "title_zh": "基于大语言模型的 SNP 变异与心电图表型少标签多模态建模在心血管风险分层中的应用",
      "authors": [
        "Niranjana Arun Menon",
        "Yulong Li",
        "Iqra Farooq",
        "Sara Ahmed",
        "Muhammad Awais",
        "Imran Razzak"
      ],
      "abstract": "Cardiovascular disease (CVD) risk stratification remains a major challenge due to its multifactorial nature and limited availability of high-quality labeled datasets. While genomic and electrophysiological data such as SNP variants and ECG phenotypes are increasingly accessible, effectively integrating these modalities in low-label settings is non-trivial. This challenge arises from the scarcity of well-annotated multimodal datasets and the high dimensionality of biological signals, which limit the effectiveness of conventional supervised models. To address this, we present a few-label multimodal framework that leverages large language models (LLMs) to combine genetic and electrophysiological information for cardiovascular risk stratification. Our approach incorporates a pseudo-label refinement strategy to adaptively distill high-confidence labels from weakly supervised predictions, enabling robust model fine-tuning with only a small set of ground-truth annotations. To enhance the interpretability, we frame the task as a Chain of Thought (CoT) reasoning problem, prompting the model to produce clinically relevant rationales alongside predictions. Experimental results demonstrate that the integration of multimodal inputs, few-label supervision, and CoT reasoning improves robustness and generalizability across diverse patient profiles. Experimental results using multimodal SNP variants and ECG-derived features demonstrated comparable performance to models trained on the full dataset, underscoring the promise of LLM-based few-label multimodal modeling for advancing personalized cardiovascular care.",
      "tldr_zh": "该研究针对心血管疾病(CVD)风险分层中高质量标注数据稀缺以及多模态数据整合困难的挑战，提出了一种利用大语言模型(LLMs)整合基因组SNP variants和心电图ECG phenotypes数据的少样本多模态框架。该框架引入了伪标签精炼策略(pseudo-label refinement)，通过从弱监督预测中自适应提取高置信度标签，实现了在仅有少量真值标注情况下的稳健模型微调。为了增强临床解释性，研究将任务建模为链式思维(Chain of Thought)推理过程，使模型能够产生临床相关的逻辑依据。实验结果表明，多模态输入、少样本监督与CoT推理的结合提升了模型在多样化患者群体中的鲁棒性。在实际数据集上的测试显示，该方法在性能上可与全数据集训练的模型相媲美，展示了LLMs在个性化心血管护理领域中处理少样本多模态数据的巨大潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16536v1",
      "published_date": "2025-10-18 15:19:35 UTC",
      "updated_date": "2025-10-18 15:19:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:42.697980+00:00"
    },
    {
      "arxiv_id": "2510.16533v1",
      "title": "Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination",
      "title_zh": "嘿 Pentti，我们又做到了！：证明多项式终止的可微向量符号类型",
      "authors": [
        "Eilene Tomkins-Flanagan",
        "Connor Hanley",
        "Mary A. Kelly"
      ],
      "abstract": "We present a typed computer language, Doug, in which all typed programs may be proved to halt in polynomial time, encoded in a vector-symbolic architecture (VSA). Doug is just an encoding of the light linear functional programming language (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are encoded using a slot-value encoding scheme based on holographic declarative memory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the Lisp VSA defined by (Flanagan, 2024). Doug allows for some points on the embedding space of a neural network to be interpreted as types, where the types of nearby points are similar both in structure and content. Types in Doug are therefore learnable by a neural network. Following (Chollet, 2019), (Card, 1983), and (Newell, 1981), we view skill as the application of a procedure, or program of action, that causes a goal to be satisfied. Skill acquisition may therefore be expressed as program synthesis. Using Doug, we hope to describe a form of learning of skilled behaviour that follows a human-like pace of skill acquisition (i.e., substantially faster than brute force; Heathcote, 2000), exceeding the efficiency of all currently existing approaches (Kaplan, 2020; Jones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling human mental representations, as they must actually exist in the brain, and those representations' acquisition, as they are actually learned.",
      "tldr_zh": "该研究提出了一种名为 Doug 的有类型计算机语言，其核心特点是利用向量符号架构 (Vector-Symbolic Architecture, VSA) 进行编码，从而保证所有程序都能在多项式时间内证明停机。Doug 实际上是对轻量级线性函数式编程语言 (Light Linear Functional Programming Language, LLFPL) 的一种实现，其类型系统采用了基于全息声明性内存 (Holographic Declarative Memory, HDM) 的插槽值编码方案。通过将 Lisp VSA 的变体用于项的编码，Doug 允许将神经网络嵌入空间中的点解释为类型，使得邻近点在结构和内容上保持相似性。这种设计确保了类型系统是可微且可学习的，并将技能习得视为程序合成 (Program Synthesis) 过程。研究目标是实现一种接近人类水平的技能习得速度，在效率上显著超越现有的深度学习方法。该工作为模拟人类大脑真实的心理表征及其学习机制提供了新的模型路径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16533v1",
      "published_date": "2025-10-18 15:05:44 UTC",
      "updated_date": "2025-10-18 15:05:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:13:40.985993+00:00"
    },
    {
      "arxiv_id": "2510.17889v1",
      "title": "Hey Pentti, We Did It!: A Fully Vector-Symbolic Lisp",
      "title_zh": "嘿 Pentti，我们做到了！：一个全向量符号 Lisp",
      "authors": [
        "Eilene Tomkins-Flanagan",
        "Mary A. Kelly"
      ],
      "abstract": "Kanerva (2014) suggested that it would be possible to construct a complete Lisp out of a vector-symbolic architecture. We present the general form of a vector-symbolic representation of the five Lisp elementary functions, lambda expressions, and other auxiliary functions, found in the Lisp 1.5 specification McCarthy (1960), which is near minimal and sufficient for Turing-completeness. Our specific implementation uses holographic reduced representations Plate (1995), with a lookup table cleanup memory. Lisp, as all Turing-complete languages, is a Cartesian closed category, unusual in its proximity to the mathematical abstraction. We discuss the mathematics, the purpose, and the significance of demonstrating vector-symbolic architectures' Cartesian-closure, as well as the importance of explicitly including cleanup memories in the specification of the architecture.",
      "tldr_zh": "该研究响应了Kanerva (2014)提出的基于向量符号架构(Vector-Symbolic Architecture)构建完整Lisp语言的构想，实现了一个完全向量符号化的Lisp系统。作者根据Lisp 1.5规范，提出了一种包含五种基本函数、lambda表达式及其辅助函数的通用向量符号表示形式，并证明了其具备图灵完备性(Turing-completeness)。在具体实现上，该系统采用了全息简化表示(Holographic Reduced Representations)以及带有查找表的清理存储器(Cleanup Memory)。研究探讨了向量符号架构在数学上实现笛卡尔封闭范畴(Cartesian closed category)的意义，验证了其在数学抽象表达上的独特性。该成果不仅论证了在架构规范中显式包含清理存储器的重要性，也为向量符号架构在高级程序设计语言和复杂逻辑推理领域的应用奠定了基础。",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.17889v1",
      "published_date": "2025-10-18 14:42:36 UTC",
      "updated_date": "2025-10-18 14:42:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:01.099755+00:00"
    },
    {
      "arxiv_id": "2510.16518v1",
      "title": "DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation",
      "title_zh": "DIV-Nav：面向多物体导航的开放词汇空间关系",
      "authors": [
        "Jesús Ortega-Peimbert",
        "Finn Lukas Busch",
        "Timon Homberger",
        "Quantao Yang",
        "Olov Andersson"
      ],
      "abstract": "Advances in open-vocabulary semantic mapping and object navigation have enabled robots to perform an informed search of their environment for an arbitrary object. However, such zero-shot object navigation is typically designed for simple queries with an object name like \"television\" or \"blue rug\". Here, we consider more complex free-text queries with spatial relationships, such as \"find the remote on the table\" while still leveraging robustness of a semantic map. We present DIV-Nav, a real-time navigation system that efficiently addresses this problem through a series of relaxations: i) Decomposing natural language instructions with complex spatial constraints into simpler object-level queries on a semantic map, ii) computing the Intersection of individual semantic belief maps to identify regions where all objects co-exist, and iii) Validating the discovered objects against the original, complex spatial constrains via a LVLM. We further investigate how to adapt the frontier exploration objectives of online semantic mapping to such spatial search queries to more effectively guide the search process. We validate our system through extensive experiments on the MultiON benchmark and real-world deployment on a Boston Dynamics Spot robot using a Jetson Orin AGX. More details and videos are available at https://anonsub42.github.io/reponame/",
      "tldr_zh": "该研究提出了DIV-Nav，一种旨在解决具备空间关系约束的复杂自由文本查询下的多目标导航(Multi-Object Navigation)问题的实时系统。该系统通过三个核心阶段实现高效导航：首先将包含复杂空间约束的自然语言指令分解(Decomposing)为语义地图上的简单对象级查询，接着通过计算个体语义置信图的交集(Intersection)来识别目标共存的候选区域，最后利用大型视觉语言模型(LVLM)对发现的对象进行验证(Validating)。此外，研究还探讨了如何调整在线语义地图的前沿探索(frontier exploration)目标，以更有效地引导空间搜索过程。实验在MultiON基准测试及Boston Dynamics Spot机器人上进行了广泛验证，证明了该系统在处理开放词汇(Open-Vocabulary)空间关系导航任务中的有效性与鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16518v1",
      "published_date": "2025-10-18 14:22:32 UTC",
      "updated_date": "2025-10-18 14:22:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:01.990411+00:00"
    },
    {
      "arxiv_id": "2510.16514v1",
      "title": "Image Categorization and Search via a GAT Autoencoder and Representative Models",
      "title_zh": "基于 GAT 自动编码器与代表性模型的图像分类与检索",
      "authors": [
        "Duygu Sap",
        "Martin Lotz",
        "Connor Mattinson"
      ],
      "abstract": "We propose a method for image categorization and retrieval that leverages graphs and a graph attention network (GAT)-based autoencoder. Our approach is representative-centric, that is, we execute the categorization and retrieval process via the representative models we construct for the images and image categories. We utilize a graph where nodes represent images (or their representatives) and edges capture similarity relationships. GAT highlights important features and relationships between images, enabling the autoencoder to construct context-aware latent representations that capture the key features of each image relative to its neighbors. We obtain category representatives from these embeddings and categorize a query image by comparing its representative to the category representatives. We then retrieve the most similar image to the query image within its identified category. We demonstrate the effectiveness of our representative-centric approach through experiments with both the GAT autoencoders and standard feature-based techniques.",
      "tldr_zh": "该研究提出了一种结合图结构与基于图注意力网络(GAT)的自动编码器(autoencoder)进行图像分类与检索的方法。该方案采用以代表为中心(representative-centric)的策略，通过为图像及其类别构建代表性模型来优化处理流程。研究通过图节点表示图像并利用边捕捉其相似性关系，借助 GAT 强化图像间的关键特征提取，使自动编码器能够生成具备语境感知的潜表示(latent representations)。在分类过程中，系统通过对比查询图像与各类别代表的特征向量确定属类，并随后在相应类别中检索最相似的图像。实验数据验证了该方法在图像分类与搜索任务中相较于标准特征提取技术的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 22 figures, Under review",
      "pdf_url": "https://arxiv.org/pdf/2510.16514v1",
      "published_date": "2025-10-18 14:06:54 UTC",
      "updated_date": "2025-10-18 14:06:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:01.615749+00:00"
    },
    {
      "arxiv_id": "2510.16511v1",
      "title": "Structured Temporal Causality for Interpretable Multivariate Time Series Anomaly Detection",
      "title_zh": "基于结构化时序因果的可解释多变量时间序列异常检测",
      "authors": [
        "Dongchan Cho",
        "Jiho Han",
        "Keumyeong Kang",
        "Minsang Kim",
        "Honggyu Ryu",
        "Namsoon Jung"
      ],
      "abstract": "Real-world multivariate time series anomalies are rare and often unlabeled. Additionally, prevailing methods rely on increasingly complex architectures tuned to benchmarks, detecting only fragments of anomalous segments and overstating performance. In this paper, we introduce OracleAD, a simple and interpretable unsupervised framework for multivariate time series anomaly detection. OracleAD encodes each variable's past sequence into a single causal embedding to jointly predict the present time point and reconstruct the input window, effectively modeling temporal dynamics. These embeddings then undergo a self-attention mechanism to project them into a shared latent space and capture spatial relationships. These relationships are not static, since they are modeled by a property that emerges from each variable's temporal dynamics. The projected embeddings are aligned to a Stable Latent Structure (SLS) representing normal-state relationships. Anomalies are identified using a dual scoring mechanism based on prediction error and deviation from the SLS, enabling fine-grained anomaly diagnosis at each time point and across individual variables. Since any noticeable SLS deviation originates from embeddings that violate the learned temporal causality of normal data, OracleAD directly pinpoints the root-cause variables at the embedding level. OracleAD achieves state-of-the-art results across multiple real-world datasets and evaluation protocols, while remaining interpretable through SLS.",
      "tldr_zh": "该研究提出了OracleAD，一种用于多变量时间序列(Multivariate Time Series)异常检测的简单且可解释的无监督框架，旨在解决现实场景中异常稀少且缺乏标签的问题。OracleAD将每个变量的历史序列编码为因果嵌入(Causal Embedding)，通过同时预测当前时间点和重构输入窗口来有效建模时间动态。该框架利用自注意力机制(Self-attention)将嵌入投射到共享潜空间以捕捉变量间的空间关系，并将其与代表正常状态关系的稳定潜结构(Stable Latent Structure, SLS)进行对齐。异常检测通过结合预测误差和SLS偏离度的双重评分机制实现，支持在时间点和单个变量层面的细粒度诊断。由于SLS的偏差直接源于违反正常时间因果律的嵌入，OracleAD能够在嵌入层面精准定位根因变量(Root-cause variables)。实验结果显示，OracleAD在多个真实数据集和评估协议下均达到了SOTA性能，同时利用SLS确保了检测结果的高度可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.16511v1",
      "published_date": "2025-10-18 13:53:41 UTC",
      "updated_date": "2025-10-18 13:53:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:04.285204+00:00"
    },
    {
      "arxiv_id": "2510.16499v2",
      "title": "Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection",
      "title_zh": "智能体自动化组合：基于背包问题的智能体组件选择方法",
      "authors": [
        "Michelle Yuan",
        "Khushbu Pahwa",
        "Shuaichen Chang",
        "Mustafa Kaba",
        "Jiarong Jiang",
        "Xiaofei Ma",
        "Yi Zhang",
        "Monica Sunkara"
      ],
      "abstract": "Designing effective agentic systems requires the seamless composition and integration of agents, tools, and models within dynamic and uncertain environments. Most existing methods rely on static, semantic retrieval approaches for tool or agent discovery. However, effective reuse and composition of existing components remain challenging due to incomplete capability descriptions and the limitations of retrieval methods. Component selection suffers because the decisions are not based on capability, cost, and real-time utility. To address these challenges, we introduce a structured, automated framework for agentic system composition that is inspired by the knapsack problem. Our framework enables a composer agent to systematically identify, select, and assemble an optimal set of agentic components by jointly considering performance, budget constraints, and compatibility. By dynamically testing candidate components and modeling their utility in real-time, our approach streamlines the assembly of agentic systems and facilitates scalable reuse of resources. Empirical evaluation with Claude 3.5 Sonnet across five benchmarking datasets shows that our online-knapsack-based composer consistently lies on the Pareto frontier, achieving higher success rates at significantly lower component costs compared to our baselines. In the single-agent setup, the online knapsack composer shows a success rate improvement of up to 31.6% in comparison to the retrieval baselines. In multi-agent systems, the online knapsack composer increases success rate from 37% to 87% when agents are selected from an agent inventory of 100+ agents. The substantial performance gap confirms the robust adaptability of our method across diverse domains and budget constraints.",
      "tldr_zh": "该研究提出了一个受背包问题(Knapsack Problem)启发的结构化自动化框架，用于智能体系统的自动化构建。针对现有语义检索方法在处理组件能力描述不全以及忽视成本与实时效用方面的局限性，该框架旨在实现智能体、工具和模型的无缝集成。其核心是通过一个组合智能体(Composer Agent)系统地识别、选择并组装最优的智能体组件，同时综合权衡性能、预算约束和兼容性。通过对候选组件进行动态测试并实时建模其效用，该方法大幅简化了系统的组装流程并提升了资源的可扩展重用性。在基于Claude 3.5 Sonnet的实验中，该在线背包组合器在多个基准测试中均处于帕累托前沿(Pareto Frontier)。实验结果显示，单智能体设置下的成功率比检索基线提升了31.6%，而在包含上百个智能体的复杂系统中，成功率从37%跃升至87%。这项研究证明了该方法在不同领域和预算限制下均具有极强的健壮性与适应性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NeurIPS 2025 Conference",
      "pdf_url": "https://arxiv.org/pdf/2510.16499v2",
      "published_date": "2025-10-18 13:37:47 UTC",
      "updated_date": "2025-11-27 18:31:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:11.881088+00:00"
    },
    {
      "arxiv_id": "2510.16476v1",
      "title": "NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems",
      "title_zh": "NP-Engine：利用可验证合成 NP 问题赋能大语言模型的优化推理能力",
      "authors": [
        "Xiaozhe Li",
        "Xinyu Fang",
        "Shengyuan Ding",
        "Linyang Li",
        "Haodong Duan",
        "Qingwen Liu",
        "Kai Chen"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong reasoning capabilities, with models like OpenAI's O-series and DeepSeek R1 excelling at tasks such as mathematics, coding, logic, and puzzles through Reinforcement Learning with Verifiable Rewards (RLVR). However, their ability to solve more complex optimization problems - particularly NP-hard tasks - remains underexplored. To bridge this gap, we propose NP-ENGINE, the first comprehensive framework for training and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks across five domains, each equipped with (i) a controllable instance generator, (ii) a rule-based verifier, and (iii) a heuristic solver that provides approximate optimal solutions as ground truth. This generator-verifier-heuristic pipeline enables scalable and verifiable RLVR training under hierarchical difficulties. We also introduce NP-BENCH, a benchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs' ability to tackle NP-hard level reasoning problems, focusing not only on feasibility but also on solution quality. Additionally, we present QWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on Qwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and achieves SOTA performance with the same model size. Beyond in-domain tasks, we demonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain (OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge), as well as non-reasoning tasks such as instruction following. We also observe a scaling trend: increasing task diversity improves OOD generalization. These findings suggest that task-rich RLVR training is a promising direction for advancing LLM's reasoning ability, revealing new insights into the scaling laws of RLVR.",
      "tldr_zh": "该研究提出了NP-ENGINE，这是首个旨在提升大语言模型(LLMs)处理NP-hard问题能力的综合性训练与评估框架。该框架包含五个领域的10项优化任务，通过由实例生成器、规则校验器和启发式求解器组成的流水线，实现了可扩展且可验证的强化学习与可验证奖励(RLVR)训练。研究者同步推出了NP-BENCH基准，用于评估LLMs在复杂推理任务中的解题可行性与方案质量。基于Qwen2.5-7B-Instruct训练出的QWEN2.5-7B-NP模型在性能上显著优于GPT-4o，并在同参数规模下达到了SOTA水平。实验证明，在NP-ENGINE-DATA上进行的RLVR训练不仅增强了模型在逻辑、数学等域外(OOD)任务上的泛化能力，还提升了其指令遵循性能。此外，研究发现任务多样性的增加能有效促进泛化，为探索RLVR的扩展定律(scaling laws)提供了重要启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16476v1",
      "published_date": "2025-10-18 12:54:32 UTC",
      "updated_date": "2025-10-18 12:54:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:13.995457+00:00"
    },
    {
      "arxiv_id": "2510.16470v1",
      "title": "Declarative Techniques for NL Queries over Heterogeneous Data",
      "title_zh": "面向异构数据自然语言查询的声明式技术",
      "authors": [
        "Elham Khabiri",
        "Jeffrey O. Kephart",
        "Fenno F. Heath",
        "Srideepika Jayaraman",
        "Fateh A. Tipu",
        "Yingjie Li",
        "Dhruv Shah",
        "Achille Fokoue",
        "Anu Bhamidipaty"
      ],
      "abstract": "In many industrial settings, users wish to ask questions in natural language, the answers to which require assembling information from diverse structured data sources. With the advent of Large Language Models (LLMs), applications can now translate natural language questions into a set of API calls or database calls, execute them, and combine the results into an appropriate natural language response. However, these applications remain impractical in realistic industrial settings because they do not cope with the data source heterogeneity that typifies such environments. In this work, we simulate the heterogeneity of real industry settings by introducing two extensions of the popular Spider benchmark dataset that require a combination of database and API calls. Then, we introduce a declarative approach to handling such data heterogeneity and demonstrate that it copes with data source heterogeneity significantly better than state-of-the-art LLM-based agentic or imperative code generation systems. Our augmented benchmarks are available to the research community.",
      "tldr_zh": "该研究针对工业场景中自然语言查询（NL Queries）在处理异构数据源（data source heterogeneity）时面临的局限性，提出了一种全新的声明式方法（declarative approach）。为了模拟真实的异构环境，研究人员扩展了 Spider 基准数据集，使其涵盖了需要同时调用数据库和 API 的复杂场景。与当前最先进的基于大语言模型（LLM-based）的智能体系统或命令式代码生成系统相比，该方法在应对数据多样性方面展现出了显著的优势。实验结果证明，这种声明式技术能更有效地组装来自不同结构化来源的信息并生成准确回答。目前，研究团队已将增强后的基准测试数据集向学术界开放，旨在推动该领域的发展。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16470v1",
      "published_date": "2025-10-18 12:27:59 UTC",
      "updated_date": "2025-10-18 12:27:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:15.671315+00:00"
    },
    {
      "arxiv_id": "2510.16466v2",
      "title": "ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights",
      "title_zh": "ReviewSense：将客户评论动态转化为可操作的商业洞察",
      "authors": [
        "Siddhartha Krothapalli",
        "Kartikey Singh Bhandari",
        "Tridib Kumar Das",
        "Praveen Kumar",
        "Naveen Suravarpu",
        "Pratik Narang"
      ],
      "abstract": "As customer feedback becomes increasingly central to strategic growth, the ability to derive actionable insights from unstructured reviews is essential. While traditional AI-driven systems excel at predicting user preferences, far less work has focused on transforming customer reviews into prescriptive, business-facing recommendations. This paper introduces ReviewSense, a novel prescriptive decision support framework that leverages advanced large language models (LLMs) to transform customer reviews into targeted, actionable business recommendations. By identifying key trends, recurring issues, and specific concerns within customer sentiments, ReviewSense extends beyond preference-based systems to provide businesses with deeper insights for sustaining growth and enhancing customer loyalty. The novelty of this work lies in integrating clustering, LLM adaptation, and expert-driven evaluation into a unified, business-facing pipeline. Preliminary manual evaluations indicate strong alignment between the model's recommendations and business objectives, highlighting its potential for driving data-informed decision-making. This framework offers a new perspective on AI-driven sentiment analysis, demonstrating its value in refining business strategies and maximizing the impact of customer feedback.",
      "tldr_zh": "该研究提出了 ReviewSense，一种新型的规范性决策支持框架 (prescriptive decision support framework)，利用先进的大语言模型 (LLMs) 将非结构化的客户评论转化为有针对性的、可操作的业务建议。通过识别客户情感中的关键趋势、重复性问题和具体关注点，ReviewSense 超越了传统的偏好预测系统，为企业提供更深层次的洞察以维持增长并增强客户忠诚度。该框架的创新之处在于将聚类 (clustering)、LLM 适配 (LLM adaptation) 和专家驱动评估 (expert-driven evaluation) 整合到一个统一的、面向业务的流水线中。初步的人工评估表明，该模型生成的建议与业务目标高度一致，凸显了其在推动数据驱动决策方面的巨大潜力。这一研究为 AI 驱动的情感分析 (sentiment analysis) 提供了新视角，证明了其在完善业务策略和最大化客户反馈价值方面的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 1 figure, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.16466v2",
      "published_date": "2025-10-18 12:20:15 UTC",
      "updated_date": "2026-01-17 05:27:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:17.992962+00:00"
    },
    {
      "arxiv_id": "2510.26805v1",
      "title": "Reinforcement Learning for Accelerator Beamline Control: a simulation-based approach",
      "title_zh": "强化学习在加速器束流线控制中的应用：一种基于仿真的方法",
      "authors": [
        "Anwar Ibrahim",
        "Alexey Petrenko",
        "Maxim Kaledin",
        "Ehab Suleiman",
        "Fedor Ratnikov",
        "Denis Derkach"
      ],
      "abstract": "Particle accelerators play a pivotal role in advancing scientific research, yet optimizing beamline configurations to maximize particle transmission remains a labor-intensive task requiring expert intervention. In this work, we introduce RLABC (Reinforcement Learning for Accelerator Beamline Control), a Python-based library that reframes beamline optimization as a reinforcement learning (RL) problem. Leveraging the Elegant simulation framework, RLABC automates the creation of an RL environment from standard lattice and element input files, enabling sequential tuning of magnets to minimize particle losses. We define a comprehensive state representation capturing beam statistics, actions for adjusting magnet parameters, and a reward function focused on transmission efficiency. Employing the Deep Deterministic Policy Gradient (DDPG) algorithm, we demonstrate RLABC's efficacy on two beamlines, achieving transmission rates of 94% and 91%, comparable to expert manual optimizations. This approach bridges accelerator physics and machine learning, offering a versatile tool for physicists and RL researchers alike to streamline beamline tuning.",
      "tldr_zh": "该研究推出了RLABC (Reinforcement Learning for Accelerator Beamline Control)，这是一个基于Python的软件库，旨在通过强化学习(Reinforcement Learning)自动化优化粒子加速器的光束线(beamline)配置。该框架利用Elegant仿真框架，能够根据标准晶格(lattice)和元件输入文件自动构建强化学习环境，实现对磁铁参数的顺序调整以最小化粒子损失。研究定义了捕捉光束统计数据的状态表示，并采用深度确定性策略梯度(DDPG)算法进行策略优化，旨在最大化传输效率。实验结果表明，RLABC在两条光束线上分别实现了94%和91%的传输率，其性能与专家的手动优化结果相当。该工作成功桥接了加速器物理与机器学习领域，为简化光束线调优过程提供了一个多功能且高效的工具。",
      "categories": [
        "physics.acc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.acc-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.26805v1",
      "published_date": "2025-10-18 11:02:54 UTC",
      "updated_date": "2025-10-18 11:02:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:22.098532+00:00"
    },
    {
      "arxiv_id": "2510.16448v1",
      "title": "Input Domain Aware MoE: Decoupling Routing Decisions from Task Optimization in Mixture of Experts",
      "title_zh": "输入域感知 MoE：混合专家模型中路由决策与任务优化的解耦",
      "authors": [
        "Yongxiang Hua",
        "Haoyu Cao",
        "Zhou Tao",
        "Bocheng Li",
        "Zihao Wu",
        "Chaohu Liu",
        "Linli Xu"
      ],
      "abstract": "Sparse Mixture of Experts (sMoE) has become a pivotal approach for scaling large vision-language models, offering substantial capacity while maintaining computational efficiency through dynamic, sparse activation of experts. However, existing routing mechanisms, typically based on similarity scoring, struggle to effectively capture the underlying input structure. This limitation leads to a trade-off between expert specialization and balanced computation, hindering both scalability and performance. We propose Input Domain Aware MoE, a novel routing framework that leverages a probabilistic mixture model to better partition the input space. By modeling routing probabilities as a mixture of distributions, our method enables experts to develop clear specialization boundaries while achieving balanced utilization. Unlike conventional approaches, our routing mechanism is trained independently of task-specific objectives, allowing for stable optimization and decisive expert assignments. Empirical results on vision-language tasks demonstrate that our method consistently outperforms existing sMoE approaches, achieving higher task performance and improved expert utilization balance.",
      "tldr_zh": "该研究针对稀疏专家混合模型(sMoE)中现有路由机制难以有效捕捉输入结构，导致专家专业化与负载均衡之间存在矛盾的问题，提出了 Input Domain Aware MoE 路由框架。该框架利用概率混合模型(probabilistic mixture model)更好地划分输入空间，通过将路由概率建模为分布的混合，使专家能够形成清晰的专业化边界。与传统路由方法不同，该机制将路由决策与特定任务的优化解耦并独立训练，确保了优化过程的稳定性和专家分配的果断性。实验结果表明，该方法在视觉语言任务上一致优于现有的 sMoE 方案，在提升任务性能的同时显著改善了专家利用率的平衡性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACM MM25",
      "pdf_url": "https://arxiv.org/pdf/2510.16448v1",
      "published_date": "2025-10-18 11:01:03 UTC",
      "updated_date": "2025-10-18 11:01:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:26.990831+00:00"
    },
    {
      "arxiv_id": "2510.16442v2",
      "title": "EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning",
      "title_zh": "EDVD-LLaMA：基于多模态大语言模型推理的可解释深度伪造视频检测",
      "authors": [
        "Haoran Sun",
        "Chen Cai",
        "Huiping Zhuang",
        "Kong Aik Lee",
        "Lap-Pui Chau",
        "Yi Wang"
      ],
      "abstract": "The rapid development of deepfake video technology has not only facilitated artistic creation but also made it easier to spread misinformation. Traditional deepfake video detection (DVD) methods face issues such as a lack of transparency in their principles and insufficient generalization capabilities to cope with evolving forgery techniques. This highlights an urgent need for detectors that can identify forged content and provide verifiable reasoning explanations. This paper proposes the explainable deepfake video detection (EDVD) task and designs the EDVD-LLaMA multimodal, a large language model (MLLM) reasoning framework, which provides traceable reasoning processes alongside accurate detection results and trustworthy explanations. Our approach first incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT) to extract and fuse global and local cross-frame deepfake features, providing rich spatio-temporal semantic information input for MLLM reasoning. Second, we construct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which introduces facial feature data as hard constraints during the reasoning process to achieve pixel-level spatio-temporal video localization, suppress hallucinated outputs, and enhance the reliability of the chain of thought. In addition, we build an Explainable Reasoning FF++ dataset (ER-FF++set), leveraging structured data to annotate videos and ensure quality control, thereby supporting dual supervision for reasoning and detection. Extensive experiments demonstrate that EDVD-LLaMA achieves outstanding performance and robustness in terms of detection accuracy, explainability, and its ability to handle cross-forgery methods and cross-dataset scenarios. Compared to previous DVD methods, it provides a more explainable and superior solution. The project page is available at: https://11ouo1.github.io/edvd-llama/.",
      "tldr_zh": "该研究提出了 EDVD-LLaMA，一个基于多模态大语言模型 (Multimodal Large Language Model, MLLM) 推理的可解释深度伪造视频检测 (Explainable Deepfake Video Detection, EDVD) 框架，旨在解决传统 Deepfake 检测方法缺乏透明度和泛化能力不足的问题。该框架引入了时空细微信息标记化 (Spatio-Temporal Subtle Information Tokenization, ST-SIT) 技术，通过提取并融合全局与局部的跨帧伪造特征，为推理系统提供丰富的时空语义信息。同时，研究构建了细粒度多模态链式思维 (Fine-grained Multimodal Chain-of-Thought, Fg-MCoT) 机制，利用面部特征作为硬约束实现像素级视频定位，有效抑制了幻觉输出并提升了推理链的可靠性。此外，研究团队开发了包含结构化标注的 ER-FF++set 数据集，以支持推理与检测的双重监督。实验表明，EDVD-LLaMA 在检测准确率、可解释性以及跨伪造方法和跨数据集的泛化场景中均表现出卓越的性能与鲁棒性，为可信 Deepfake 检测提供了更优的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16442v2",
      "published_date": "2025-10-18 10:34:05 UTC",
      "updated_date": "2025-12-19 14:22:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:38.680009+00:00"
    },
    {
      "arxiv_id": "2510.16416v3",
      "title": "SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning",
      "title_zh": "SSL4RL：重新审视自监督学习作为视觉-语言推理的内在奖励",
      "authors": [
        "Xiaojun Guo",
        "Runyu Zhou",
        "Yifei Wang",
        "Qi Zhang",
        "Chenheng Zhang",
        "Stefanie Jegelka",
        "Xiaohan Wang",
        "Jiajun Chai",
        "Guojun Yin",
        "Wei Lin",
        "Yisen Wang"
      ],
      "abstract": "Vision-language models (VLMs) have shown remarkable abilities by integrating large language models with visual inputs. However, they often fail to utilize visual evidence adequately, either depending on linguistic priors in vision-centric tasks or resorting to textual shortcuts during reasoning. Although reinforcement learning (RL) can align models with desired behaviors, its application to VLMs has been hindered by the lack of scalable and reliable reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel framework that leverages self-supervised learning (SSL) tasks as a source of verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL objectives-such as predicting image rotation or reconstructing masked patches-into dense, automatic reward signals, eliminating the need for human preference data or unreliable AI evaluators. Experiments show that SSL4RL substantially improves performance on both vision-centric and vision-language reasoning benchmarks. Furthermore, through systematic ablations, we identify key factors-such as task difficulty, model scale, and semantic alignment with the target domain-that influence the effectiveness of SSL4RL tasks, offering new design principles for future work. We also demonstrate the framework's generality by applying it to graph learning, where it yields significant gains. SSL4RL establishes a versatile and effective paradigm for aligning multimodal models using verifiable, self-supervised objectives.",
      "tldr_zh": "该研究针对视觉语言模型(VLMs)在推理时因过度依赖语言先验而忽视视觉证据，以及强化学习(RL)缺乏可靠奖励机制的问题，提出了SSL4RL框架。该框架创新性地将预测图像旋转、重建掩码补丁等自监督学习(SSL)任务转化为可验证的密集自动奖励信号，用于模型的强化学习微调，从而消除了对人类偏好数据或不可靠AI评估器的依赖。实验结果表明，SSL4RL在视觉中心任务和多模态推理基准测试中均显著提升了性能，并展现出在图学习(graph learning)领域的良好通用性。通过系统的消融研究，该团队还揭示了任务难度、模型规模及语义对齐等因素对学习效果的影响，为未来多模态模型的对齐提供了重要的设计原则和有效范式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16416v3",
      "published_date": "2025-10-18 09:22:40 UTC",
      "updated_date": "2025-12-24 13:40:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:43.893095+00:00"
    },
    {
      "arxiv_id": "2510.16411v1",
      "title": "Modeling Expert Interactions in Sparse Mixture of Experts via Graph Structures",
      "title_zh": "基于图结构的稀疏专家混合模型专家交互建模",
      "authors": [
        "Minh-Khoi Nguyen-Nhat",
        "Rachel S. Y. Teo",
        "Laziz Abdullaev",
        "Maurice Mok",
        "Viet-Hoang Tran",
        "Tan Minh Nguyen"
      ],
      "abstract": "Sparse Mixture of Experts (SMoE) has emerged as a promising solution to achieving unparalleled scalability in deep learning by decoupling model parameter count from computational cost. By activating only a small subset of parameters per sample, SMoE enables significant growth in model capacity while maintaining efficiency. However, SMoE struggles to adapt to distributional shifts, leading to reduced robustness under data contamination. In this work, we introduce SymphonySMoE, a novel family of SMoE that introduces a social graph to model interactions among experts. This graph-based structure enhances the token routing process, addressing the robustness challenges that are inherent in conventional SMoE designs. SymphonySMoE is lightweight, modular, and integrates seamlessly with existing SMoE-based models such as the XMoE and the Generalist Language Model. We provide both theoretical analysis and empirical evidence demonstrating SymphonySMoE's advantages over baseline SMoE. Extensive experiments on language modeling and visual instruction tuning validate our method's effectiveness. We further highlight the scalability of SymphonySMoE to models with 4.2 and 7.4 billion parameters, showcasing its applicability in fine-tuning tasks for large-scale systems.",
      "tldr_zh": "该研究针对稀疏专家混合模型 (Sparse Mixture of Experts, SMoE) 在应对分布偏移 (distributional shifts) 时鲁棒性 (robustness) 不足的问题，提出了新型架构 SymphonySMoE。该架构创新性地引入社交图 (social graph) 来建模专家间的相互作用，通过图结构优化令牌路由 (token routing) 过程，有效提升了传统 SMoE 的稳定性。SymphonySMoE 具备轻量化与模块化特性，能够无缝集成至 XMoE 和 Generalist Language Model 等现有模型中。研究团队通过理论分析与广泛的实验，在语言建模 (language modeling) 和视觉指令微调 (visual instruction tuning) 任务中验证了该方法的有效性。此外，SymphonySMoE 成功扩展至 42 亿和 74 亿参数规模，展示了其在大规模系统微调应用中的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16411v1",
      "published_date": "2025-10-18 09:03:28 UTC",
      "updated_date": "2025-10-18 09:03:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:48.384239+00:00"
    },
    {
      "arxiv_id": "2510.16396v3",
      "title": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation",
      "title_zh": "SPLite Hand：稀疏感知的轻量级三维手部姿态估计",
      "authors": [
        "Yeh Keng Hao",
        "Hsu Tzu Wei",
        "Sun Min"
      ],
      "abstract": "With the increasing ubiquity of AR/VR devices, the deployment of deep learning models on edge devices has become a critical challenge. These devices require real-time inference, low power consumption, and minimal latency. Many framework designers face the conundrum of balancing efficiency and performance. We design a light framework that adopts an encoder-decoder architecture and introduces several key contributions aimed at improving both efficiency and accuracy. We apply sparse convolution on a ResNet-18 backbone to exploit the inherent sparsity in hand pose images, achieving a 42% end-to-end efficiency improvement. Moreover, we propose our SPLite decoder. This new architecture significantly boosts the decoding process's frame rate by 3.1x on the Raspberry Pi 5, while maintaining accuracy on par. To further optimize performance, we apply quantization-aware training, reducing memory usage while preserving accuracy (PA-MPJPE increases only marginally from 9.0 mm to 9.1 mm on FreiHAND). Overall, our system achieves a 2.98x speed-up on a Raspberry Pi 5 CPU (BCM2712 quad-core Arm A76 processor). Our method is also evaluated on compound benchmark datasets, demonstrating comparable accuracy to state-of-the-art approaches while significantly enhancing computational efficiency.",
      "tldr_zh": "该研究提出了SPLite Hand，一种针对AR/VR边缘设备优化的轻量化3D手势估计框架。通过在ResNet-18骨干网络中引入稀疏卷积(Sparse Convolution)，该方法充分利用手势图像的固有稀疏性，实现了42%的端到端效率提升。研究专门设计了SPLite解码器架构，在Raspberry Pi 5上将解码过程的帧率提高了3.1倍，同时保持了极高的预测精度。此外，通过采用量化感知训练(Quantization-aware Training)，系统在显著降低内存占用的同时，使FreiHAND数据集上的PA-MPJPE误差仅从9.0mm微增至9.1mm。实验结果表明，该系统在Raspberry Pi 5 CPU上实现了2.98倍的整体加速。该方法在复合基准数据集上证明了其在显著增强计算效率的同时，具有与现有最先进技术(SOTA)相当的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AICCC 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.16396v3",
      "published_date": "2025-10-18 08:19:49 UTC",
      "updated_date": "2025-10-30 04:59:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:54.174866+00:00"
    },
    {
      "arxiv_id": "2510.16392v1",
      "title": "RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile",
      "title_zh": "RGMem：基于重正化群的语言智能体用户画像记忆演化",
      "authors": [
        "Ao Tian",
        "Yunfeng Lu",
        "Xinxin Fan",
        "Changhao Wang",
        "Lanzhi Zhou",
        "Yeyao Zhang",
        "Yanfang Liu"
      ],
      "abstract": "Personalized and continuous interactions are the key to enhancing user experience in today's large language model (LLM)-based conversational systems, however, the finite context windows and static parametric memory make it difficult to model the cross-session long-term user states and behavioral consistency. Currently, the existing solutions to this predicament, such as retrieval-augmented generation (RAG) and explicit memory systems, primarily focus on fact-level storage and retrieval, lacking the capability to distill latent preferences and deep traits from the multi-turn dialogues, which limits the long-term and effective user modeling, directly leading to the personalized interactions remaining shallow, and hindering the cross-session continuity. To realize the long-term memory and behavioral consistency for Language Agents in LLM era, we propose a self-evolving memory framework RGMem, inspired by the ideology of classic renormalization group (RG) in physics, this framework enables to organize the dialogue history in multiple scales: it first extracts semantics and user insights from episodic fragments, then through hierarchical coarse-graining and rescaling operations, progressively forms a dynamically-evolved user profile. The core innovation of our work lies in modeling memory evolution as a multi-scale process of information compression and emergence, which accomplishes the high-level and accurate user profiles from noisy and microscopic-level interactions.",
      "tldr_zh": "该研究提出了RGMem，一种基于物理学中重整化群(Renormalization Group)理论的自演化记忆框架，旨在解决大型语言模型(LLMs)在处理跨会话长期用户状态和行为一致性方面的局限性。针对现有检索增强生成(RAG)和显式记忆系统仅侧重于事实层面存储而缺乏提炼深层偏好的问题，RGMem通过多尺度组织对话历史，从片段中提取语义和用户洞察。该框架利用层级化的粗粒化(coarse-graining)和重标度(rescaling)操作，将噪声较大的微观交互逐步转化为动态演化的用户画像(user profile)。RGMem的核心创新在于将记忆演化建模为多尺度信息压缩与涌现的过程，实现了从琐碎对话到高层级精准建模的跨越。该框架有效增强了语言智能体的长期记忆能力，为实现深层次、跨会话的个性化交互奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages,3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.16392v1",
      "published_date": "2025-10-18 08:16:46 UTC",
      "updated_date": "2025-10-18 08:16:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:56.279085+00:00"
    },
    {
      "arxiv_id": "2510.16387v1",
      "title": "Probing the Hidden Talent of ASR Foundation Models for L2 English Oral Assessment",
      "title_zh": "探究 ASR 基础模型在二语英语口语测评中的潜能",
      "authors": [
        "Fu-An Chao",
        "Bi-Cheng Yan",
        "Berlin Chen"
      ],
      "abstract": "In this paper, we explore the untapped potential of Whisper, a well-established automatic speech recognition (ASR) foundation model, in the context of L2 spoken language assessment (SLA). Unlike prior studies that extrinsically analyze transcriptions produced by Whisper, our approach goes a step further to probe its latent capabilities by extracting acoustic and linguistic features from hidden representations. With only a lightweight classifier being trained on top of Whisper's intermediate and final outputs, our method achieves strong performance on the GEPT picture-description dataset, outperforming existing cutting-edge baselines, including a multimodal approach. Furthermore, by incorporating image and text-prompt information as auxiliary relevance cues, we demonstrate additional performance gains. Finally, we conduct an in-depth analysis of Whisper's embeddings, which reveals that, even without task-specific fine-tuning, the model intrinsically encodes both ordinal proficiency patterns and semantic aspects of speech, highlighting its potential as a powerful foundation for SLA and other spoken language understanding tasks.",
      "tldr_zh": "该研究探讨了Whisper这一自动语音识别(ASR)基础模型在二语口语评估(L2 SLA)中尚未被挖掘的潜能。不同于以往仅分析转录文本的研究，该方法通过从Whisper中间层和最终输出的隐藏表示(hidden representations)中提取声学和语言特征，并在此基础上训练轻量级分类器。实验在GEPT图片描述数据集上取得出色表现，优于包括多模态方法在内的现有前沿基线模型。此外，通过引入图像和文本提示信息作为辅助线索，评估性能得到了进一步提升。深度分析证明，即便未经特定任务微调，Whisper的嵌入向量也能本质上编码口语的熟练度模式和语义特征，展现了其作为口语理解任务强大基础模型的巨大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16387v1",
      "published_date": "2025-10-18 08:10:24 UTC",
      "updated_date": "2025-10-18 08:10:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:52.991665+00:00"
    },
    {
      "arxiv_id": "2510.21781v1",
      "title": "EdgeSync: Accelerating Edge-Model Updates for Data Drift through Adaptive Continuous Learning",
      "title_zh": "EdgeSync：通过自适应持续学习加速面向数据漂移的边缘模型更新",
      "authors": [
        "Runchu Donga",
        "Peng Zhao",
        "Guiqin Wang",
        "Nan Qi",
        "Jie Lin"
      ],
      "abstract": "Real-time video analytics systems typically deploy lightweight models on edge devices to reduce latency. However, the distribution of data features may change over time due to various factors such as changing lighting and weather conditions, leading to decreased model accuracy. Recent frameworks try to address this issue by leveraging remote servers to continuously train and adapt lightweight edge models using more complex models in the cloud. Despite these advancements, existing methods face two key challenges: first, the retraining process is compute-intensive, causing significant delays in model updates; second, the new model may not align well with the evolving data distribution of the current video stream. To address these challenges, we introduce EdgeSync, an efficient edge-model updating approach that enhances sample filtering by incorporating timeliness and inference results, thus ensuring training samples are more relevant to the current video content while reducing update delays. Additionally, EdgeSync features a dynamic training management module that optimizes the timing and sequencing of model updates to improve their timeliness. Evaluations on diverse and complex real-world datasets demonstrate that EdgeSync improves accuracy by approximately 3.4% compared to existing methods and by about 10% compared to traditional approaches.",
      "tldr_zh": "该研究针对实时视频分析系统在边缘设备部署轻量化模型时面临的 Data Drift 问题，提出了 EdgeSync 框架。EdgeSync 旨在通过 Adaptive Continuous Learning 解决现有框架中计算密集导致的更新延迟以及模型与当前视频流分布不一致的挑战。该方案通过结合时效性和推理结果的样本过滤机制，确保训练样本与当前内容高度相关，从而显著减少更新延迟。此外，EdgeSync 引入了动态训练管理模块，通过优化模型更新的触发时机和序列执行，进一步提升了系统响应速度。实验评估表明，EdgeSync 在复杂真实数据集上的准确率较现有先进方法提升了约 3.4%，较传统方法提升了约 10%，有效提升了边缘智能分析的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21781v1",
      "published_date": "2025-10-18 07:57:34 UTC",
      "updated_date": "2025-10-18 07:57:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:14:57.595810+00:00"
    },
    {
      "arxiv_id": "2510.21780v1",
      "title": "Bridging Accuracy and Interpretability: Deep Learning with XAI for Breast Cancer Detection",
      "title_zh": "兼顾准确性与可解释性：基于 XAI 的深度学习乳腺癌检测",
      "authors": [
        "Bishal Chhetri",
        "B. V. Rathish Kumar"
      ],
      "abstract": "In this study, we present an interpretable deep learning framework for the early detection of breast cancer using quantitative features extracted from digitized fine needle aspirate (FNA) images of breast masses. Our deep neural network, using ReLU activations, the Adam optimizer, and a binary cross-entropy loss, delivers state-of-the-art classification performance, achieving an accuracy of 0.992, precision of 1.000, recall of 0.977, and an F1 score of 0.988. These results substantially exceed the benchmarks reported in the literature. We evaluated the model under identical protocols against a suite of well-established algorithms (logistic regression, decision trees, random forests, stochastic gradient descent, K-nearest neighbors, and XGBoost) and found the deep model consistently superior on the same metrics. Recognizing that high predictive accuracy alone is insufficient for clinical adoption due to the black-box nature of deep learning models, we incorporated model-agnostic Explainable AI techniques such as SHAP and LIME to produce feature-level attributions and human-readable visualizations. These explanations quantify the contribution of each feature to individual predictions, support error analysis, and increase clinician trust, thus bridging the gap between performance and interpretability for real-world clinical use. The concave points feature of the cell nuclei is found to be the most influential feature positively impacting the classification task. This insight can be very helpful in improving the diagnosis and treatment of breast cancer by highlighting the key characteristics of breast tumor.",
      "tldr_zh": "本研究提出了一种基于深度学习的可解释性框架，旨在利用从乳腺肿块细针抽吸(FNA)数字化图像中提取的定量特征进行乳腺癌早期检测。该深度神经网络采用了ReLU激活函数、Adam优化器和二进制交叉熵(Binary Cross-entropy)损失函数，其分类准确率达到0.992，F1分数达0.988，在对比实验中显著优于随机森林(Random Forests)和XGBoost等传统算法。为了解决深度学习模型的“黑盒”问题并提升临床信任度，研究引入了SHAP和LIME等可解释人工智能(XAI)技术，通过生成特征层面的归因来量化各项指标对预测结果的贡献。研究发现，细胞核的凹点特征(concave points feature)是对分类决策影响最为显著的关键特征，为改善乳腺癌的诊断和治疗提供了重要参考。该工作通过整合高性能预测与人类可读的可视化解释，成功弥合了技术性能与临床应用可解释性之间的鸿沟。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.21780v1",
      "published_date": "2025-10-18 07:47:26 UTC",
      "updated_date": "2025-10-18 07:47:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:03.898173+00:00"
    },
    {
      "arxiv_id": "2510.16382v1",
      "title": "Humanoid-inspired Causal Representation Learning for Domain Generalization",
      "title_zh": "受类人启发的领域泛化因果表示学习",
      "authors": [
        "Ze Tao",
        "Jian Zhang",
        "Haowei Li",
        "Xianshuai Li",
        "Yifei Peng",
        "Xiyao Liu",
        "Senzhang Wang",
        "Chao Liu",
        "Sheng Ren",
        "Shichao Zhang"
      ],
      "abstract": "This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a novel causal framework inspired by human intelligence, designed to overcome the limitations of conventional domain generalization models. Unlike approaches that rely on statistics to capture data-label dependencies and learn distortion-invariant representations, HSCM replicates the hierarchical processing and multi-level learning of human vision systems, focusing on modeling fine-grained causal mechanisms. By disentangling and reweighting key image attributes such as color, texture, and shape, HSCM enhances generalization across diverse domains, ensuring robust performance and interpretability. Leveraging the flexibility and adaptability of human intelligence, our approach enables more effective transfer and learning in dynamic, complex environments. Through both theoretical and empirical evaluations, we demonstrate that HSCM outperforms existing domain generalization models, providing a more principled method for capturing causal relationships and improving model robustness. The code is available at https://github.com/lambett/HSCM.",
      "tldr_zh": "该研究提出了受人类智能启发的结构因果模型(HSCM)，旨在克服传统领域泛化(Domain Generalization)模型在处理复杂环境时的局限性。与依赖统计特征捕获数据标签相关性的方法不同，HSCM模拟了人类视觉系统的层次化处理和多级学习机制，专注于建模细粒度的因果机制。该框架通过对颜色、纹理和形状等关键图像属性进行解耦(Disentangling)和重新加权，增强了跨多样化领域的泛化能力，并确保了性能的鲁棒性与可解释性。凭借人类智能的灵活性和适应性，HSCM能够在动态且复杂的环境中实现更有效的迁移学习。通过理论和实证评估，证明了HSCM在捕捉因果关系和提升模型稳健性方面优于现有的领域泛化模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16382v1",
      "published_date": "2025-10-18 07:38:45 UTC",
      "updated_date": "2025-10-18 07:38:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:03.211746+00:00"
    },
    {
      "arxiv_id": "2510.16381v1",
      "title": "ATA: A Neuro-Symbolic Approach to Implement Autonomous and Trustworthy Agents",
      "title_zh": "ATA：一种用于构建自主且可信智能体的神经符号方法",
      "authors": [
        "David Peer",
        "Sebastian Stabinger"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities, yet their deployment in high-stakes domains is hindered by inherent limitations in trustworthiness, including hallucinations, instability, and a lack of transparency. To address these challenges, we introduce a generic neuro-symbolic approach, which we call Autonomous Trustworthy Agents (ATA). The core of our approach lies in decoupling tasks into two distinct phases: Offline knowledge ingestion and online task processing. During knowledge ingestion, an LLM translates an informal problem specification into a formal, symbolic knowledge base. This formal representation is crucial as it can be verified and refined by human experts, ensuring its correctness and alignment with domain requirements. In the subsequent task processing phase, each incoming input is encoded into the same formal language. A symbolic decision engine then utilizes this encoded input in conjunction with the formal knowledge base to derive a reliable result. Through an extensive evaluation on a complex reasoning task, we demonstrate that a concrete implementation of ATA is competitive with state-of-the-art end-to-end reasoning models in a fully automated setup while maintaining trustworthiness. Crucially, with a human-verified and corrected knowledge base, our approach significantly outperforms even larger models, while exhibiting perfect determinism, enhanced stability against input perturbations, and inherent immunity to prompt injection attacks. By generating decisions grounded in symbolic reasoning, ATA offers a practical and controllable architecture for building the next generation of transparent, auditable, and reliable autonomous agents.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在幻觉、不稳定性和缺乏透明度等方面的信任挑战，提出了名为ATA (Autonomous Trustworthy Agents) 的通用神经符号(neuro-symbolic)方法。该方法的核心在于将任务解耦为离线知识摄取和在线任务处理两个阶段：在知识摄取阶段，LLM将非正式的问题描述转化为可供人类专家验证的正式符号知识库(symbolic knowledge base)；在任务处理阶段，系统通过符号决策引擎(symbolic decision engine)结合编码后的输入推导出可靠结果。实验评估表明，ATA在复杂推理任务中不仅能与先进的端到端模型竞争，且在人工验证知识库的辅助下性能显著优于更大规模的模型。此外，该架构表现出完美的确定性(determinism)和更强的抗干扰稳定性，并能有效防御提示注入攻击(prompt injection attacks)。通过将决策建立在符号推理之上，ATA为构建透明、可审计且可靠的自主智能体提供了一种实用且可控的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16381v1",
      "published_date": "2025-10-18 07:35:54 UTC",
      "updated_date": "2025-10-18 07:35:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:08.186984+00:00"
    },
    {
      "arxiv_id": "2510.16380v1",
      "title": "MoReBench: Evaluating Procedural and Pluralistic Moral Reasoning in Language Models, More than Outcomes",
      "title_zh": "MoReBench：评估语言模型中的过程性与多元道德推理，超越结果导向",
      "authors": [
        "Yu Ying Chiu",
        "Michael S. Lee",
        "Rachel Calcott",
        "Brandon Handoko",
        "Paul de Font-Reaulx",
        "Paula Rodriguez",
        "Chen Bo Calvin Zhang",
        "Ziwen Han",
        "Udari Madhushani Sehwag",
        "Yash Maurya",
        "Christina Q Knight",
        "Harry R. Lloyd",
        "Florence Bacus",
        "Mantas Mazeika",
        "Bing Liu",
        "Yejin Choi",
        "Mitchell L Gordon",
        "Sydney Levine"
      ],
      "abstract": "As AI systems progress, we rely more on them to make decisions with us and for us. To ensure that such decisions are aligned with human values, it is imperative for us to understand not only what decisions they make but also how they come to those decisions. Reasoning language models, which provide both final responses and (partially transparent) intermediate thinking traces, present a timely opportunity to study AI procedural reasoning. Unlike math and code problems which often have objectively correct answers, moral dilemmas are an excellent testbed for process-focused evaluation because they allow for multiple defensible conclusions. To do so, we present MoReBench: 1,000 moral scenarios, each paired with a set of rubric criteria that experts consider essential to include (or avoid) when reasoning about the scenarios. MoReBench contains over 23 thousand criteria including identifying moral considerations, weighing trade-offs, and giving actionable recommendations to cover cases on AI advising humans moral decisions as well as making moral decisions autonomously. Separately, we curate MoReBench-Theory: 150 examples to test whether AI can reason under five major frameworks in normative ethics. Our results show that scaling laws and existing benchmarks on math, code, and scientific reasoning tasks fail to predict models' abilities to perform moral reasoning. Models also show partiality towards specific moral frameworks (e.g., Benthamite Act Utilitarianism and Kantian Deontology), which might be side effects of popular training paradigms. Together, these benchmarks advance process-focused reasoning evaluation towards safer and more transparent AI.",
      "tldr_zh": "该研究推出了 MoReBench，这是一个旨在评估大型语言模型在道德领域的过程推理(Procedural Reasoning)和多元化推理能力的基准测试，强调评估决策过程而非仅仅是最终结果。MoReBench 包含 1,000 个道德场景及配套的 2.3 万余条专家准则，涵盖了识别道德考量、权衡取舍及提供行动建议等维度，同时通过 MoReBench-Theory 测试模型在五种规范伦理学(Normative Ethics)框架下的推理表现。研究发现，现有的缩放法则(Scaling Laws)以及数学、代码等领域的性能指标无法有效预测模型的道德推理能力。实验结果显示，受现有训练范式的影响，模型在推理中表现出对边沁式行动功利主义(Benthamite Act Utilitarianism)和康德德性论(Kantian Deontology)等特定框架的明显偏好。这项工作通过引入关注过程的评估方法，为开发更安全、更透明的 AI 系统提供了重要工具和见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "46 pages, 8 figures, 10 tables. Preprint",
      "pdf_url": "https://arxiv.org/pdf/2510.16380v1",
      "published_date": "2025-10-18 07:34:31 UTC",
      "updated_date": "2025-10-18 07:34:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:23.485222+00:00"
    },
    {
      "arxiv_id": "2510.18890v1",
      "title": "Small Language Models Offer Significant Potential for Science Community",
      "title_zh": "小语言模型在科学界展现出巨大潜力",
      "authors": [
        "Jian Zhang"
      ],
      "abstract": "Recent advancements in natural language processing, particularly with large language models (LLMs), are transforming how scientists engage with the literature. While the adoption of LLMs is increasing, concerns remain regarding potential information biases and computational costs. Rather than LLMs, I developed a framework to evaluate the feasibility of precise, rapid, and cost-effective information retrieval from extensive geoscience literature using freely available small language models (MiniLMs). A curated corpus of approximately 77 million high-quality sentences, extracted from 95 leading peer-reviewed geoscience journals such as Geophysical Research Letters and Earth and Planetary Science Letters published during years 2000 to 2024, was constructed. MiniLMs enable a computationally efficient approach for extracting relevant domain-specific information from these corpora through semantic search techniques and sentence-level indexing. This approach, unlike LLMs such as ChatGPT-4 that often produces generalized responses, excels at identifying substantial amounts of expert-verified information with established, multi-disciplinary sources, especially for information with quantitative findings. Furthermore, by analyzing emotional tone via sentiment analysis and topical clusters through unsupervised clustering within sentences, MiniLM provides a powerful tool for tracking the evolution of conclusions, research priorities, advancements, and emerging questions within geoscience communities. Overall, MiniLM holds significant potential within the geoscience community for applications such as fact and image retrievals, trend analyses, contradiction analyses, and educational purposes.",
      "tldr_zh": "该研究探讨了小型语言模型(Small Language Models)在科学领域的应用潜力，并开发了一个利用免费的MiniLMs从海量地球科学文献中进行精准、快速且低成本信息检索的评估框架。研究者构建了一个包含约7700万条高质量句子的语料库，其数据源自2000年至2024年间发表在Geophysical Research Letters等95本顶级地球科学期刊的论文。通过语义搜索(semantic search)和句子级索引(sentence-level indexing)技术，该方法能够高效提取特定领域的专业信息。相比于常产生泛化响应的LLMs，MiniLM在识别专家验证的跨学科定量发现方面具有显著优势。通过结合情感分析(sentiment analysis)和无监督聚类(unsupervised clustering)，该模型还能有效追踪地学研究重点和科学结论的演化趋势。总体而言，该研究证明了MiniLM在事实检索、趋势分析、矛盾分析及教育用途等领域展现出巨大的应用前景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.18890v1",
      "published_date": "2025-10-18 07:25:05 UTC",
      "updated_date": "2025-10-18 07:25:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:24.481094+00:00"
    },
    {
      "arxiv_id": "2510.16376v1",
      "title": "Conformal Prediction in The Loop: A Feedback-Based Uncertainty Model for Trajectory Optimization",
      "title_zh": "符合性预测在环：一种用于轨迹优化的反馈式不确定性模型",
      "authors": [
        "Han Wang",
        "Chao Ning"
      ],
      "abstract": "Conformal Prediction (CP) is a powerful statistical machine learning tool to construct uncertainty sets with coverage guarantees, which has fueled its extensive adoption in generating prediction regions for decision-making tasks, e.g., Trajectory Optimization (TO) in uncertain environments. However, existing methods predominantly employ a sequential scheme, where decisions rely unidirectionally on the prediction regions, and consequently the information from decision-making fails to be fed back to instruct CP. In this paper, we propose a novel Feedback-Based CP (Fb-CP) framework for shrinking-horizon TO with a joint risk constraint over the entire mission time. Specifically, a CP-based posterior risk calculation method is developed by fully leveraging the realized trajectories to adjust the posterior allowable risk, which is then allocated to future times to update prediction regions. In this way, the information in the realized trajectories is continuously fed back to the CP, enabling attractive feedback-based adjustments of the prediction regions and a provable online improvement in trajectory performance. Furthermore, we theoretically prove that such adjustments consistently maintain the coverage guarantees of the prediction regions, thereby ensuring provable safety. Additionally, we develop a decision-focused iterative risk allocation algorithm with theoretical convergence analysis for allocating the posterior allowable risk which closely aligns with Fb-CP. Furthermore, we extend the proposed method to handle distribution shift. The effectiveness and superiority of the proposed method are demonstrated through benchmark experiments.",
      "tldr_zh": "该研究提出了名为 Feedback-Based CP (Fb-CP) 的反馈式符合性预测框架，旨在解决 Trajectory Optimization 在不确定环境下决策与预测区域生成之间缺乏信息反馈的问题。该框架通过开发一种基于 Conformal Prediction (CP) 的后验风险计算方法，利用实时观测到的已实现轨迹来动态调整后验允许风险，并将其分配至未来时段以更新预测区域。这种闭环机制不仅实现了预测区域的自适应调整，还在理论上证明了其能持续维持 Coverage Guarantees 以确保 provable safety，同时带来轨迹性能的在线提升。此外，研究还提出了针对后验风险分配的决策聚焦迭代算法，并将其扩展至处理 Distribution Shift 场景。实验结果表明，该方法在多项基准测试中展现出显著的优越性，为不确定环境下的安全决策提供了强有力的理论与实践支持。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.RO",
        "eess.SY",
        "math.ST"
      ],
      "primary_category": "math.OC",
      "comment": "Accepted by NeurIPS 2025 Main Track",
      "pdf_url": "https://arxiv.org/pdf/2510.16376v1",
      "published_date": "2025-10-18 07:11:23 UTC",
      "updated_date": "2025-10-18 07:11:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:27.256894+00:00"
    },
    {
      "arxiv_id": "2510.16374v1",
      "title": "Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs",
      "title_zh": "思考之前，先行监测：在 LLMs 中实现 Flavell 的元认知框架",
      "authors": [
        "Nick Oh"
      ],
      "abstract": "Current approaches to enhancing LLM reasoning follows two isolated paradigms: Monitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and SELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack mechanisms to verify whether selected strategies succeed; while Generate-Verify approaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan et al., 2023) iteratively refine outputs but commence generation blindly without task assessment. This separation creates inefficiencies -- strategies fail without feedback, and refinement occurs without strategic grounding. We address this gap by implementing Flavell's cognitive monitoring model (1979) from the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025), operationalising it as a three-phase iterative system. On GSM8K, preliminary results show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for Self-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37% increased inference cost. These initial findings suggest upfront monitoring produces higher-quality initial solutions that reduce refinement needs, though evaluation beyond arithmetic reasoning is needed to establish generalisability.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)推理增强的两种孤立范式，即缺乏验证机制的Monitor-Generate方法和缺乏前期任务评估的Generate-Verify方法。为了填补这一空白，作者引入了Flavell的认知监控模型(Flavell's cognitive monitoring model)，并将其构建为一个三阶段的Monitor-Generate-Verify迭代系统。该系统通过在生成前进行元认知监控，确保策略选择的有效性并将其与生成后的验证反馈相结合。实验在GSM8K数据集上进行，结果显示该方法达到了75.42%的准确率，显著优于SELF-REFINE和Self-Verification等基准模型。尽管推理成本增加了27-37%，但该方法将平均尝试次数从2.0次降低至1.3次。研究初步证明，前置监控能显著提高初始解决方案的质量，有效减少了后续对细化(refinement)的需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the Workshop on the Application of LLM Explainability to Reasoning and Planning at COLM 2025 (non-archival)",
      "pdf_url": "https://arxiv.org/pdf/2510.16374v1",
      "published_date": "2025-10-18 06:52:42 UTC",
      "updated_date": "2025-10-18 06:52:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:30.640140+00:00"
    },
    {
      "arxiv_id": "2510.16373v1",
      "title": "Navigating through the hidden embedding space: steering LLMs to improve mental health assessment",
      "title_zh": "探索隐层嵌入空间：通过引导大语言模型提升心理健康评估能力",
      "authors": [
        "Federico Ravenda",
        "Seyed Ali Bahrainian",
        "Andrea Raballo",
        "Antonietta Mira"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) is transforming AI, opening new opportunities in sensitive and high-impact areas such as Mental Health (MH). Yet, despite these advancements, recent evidence reveals that smaller-scale models still struggle to deliver optimal performance in domain-specific applications. In this study, we present a cost-efficient yet powerful approach to improve MH assessment capabilities of an LLM, without relying on any computationally intensive techniques. Our lightweight method consists of a linear transformation applied to a specific layer's activations, leveraging steering vectors to guide the model's output. Remarkably, this intervention enables the model to achieve improved results across two distinct tasks: (1) identifying whether a Reddit post is useful for detecting the presence or absence of depressive symptoms (relevance prediction task), and (2) completing a standardized psychological screening questionnaire for depression based on users' Reddit post history (questionnaire completion task). Results highlight the untapped potential of steering mechanisms as computationally efficient tools for LLMs' MH domain adaptation.",
      "tldr_zh": "该研究针对小规模大语言模型 (LLMs) 在心理健康 (Mental Health) 领域表现不足的问题，提出了一种低成本且高效的改进方法。研究团队通过在特定层的激活函数上应用线性变换，利用转向向量 (steering vectors) 引导模型输出，从而在不依赖计算密集型技术的前提下提升了模型性能。该轻量级干预手段在 Reddit 帖子的抑郁症状关联性预测 (relevance prediction) 以及根据历史记录自动完成心理筛查问卷 (questionnaire completion) 这两项任务中均取得了显著进步。实验结果凸显了转向机制 (steering mechanisms) 作为一种计算高效的工具，在 LLMs 心理健康领域适应 (domain adaptation) 方面具有巨大的未开发潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16373v1",
      "published_date": "2025-10-18 06:51:39 UTC",
      "updated_date": "2025-10-18 06:51:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:33.469269+00:00"
    },
    {
      "arxiv_id": "2510.16371v1",
      "title": "Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis",
      "title_zh": "Cataract-LMM：用于手术视频分析深度学习的大规模、多源、多任务基准",
      "authors": [
        "Mohammad Javad Ahmadi",
        "Iman Gandomi",
        "Parisa Abdi",
        "Seyed-Farzad Mohammadi",
        "Amirhossein Taslimi",
        "Mehdi Khodaparast",
        "Hassan Hashemi",
        "Mahdi Tavakoli",
        "Hamid D. Taghirad"
      ],
      "abstract": "The development of computer-assisted surgery systems depends on large-scale, annotated datasets. Current resources for cataract surgery often lack the diversity and annotation depth needed to train generalizable deep-learning models. To address this gap, we present a dataset of 3,000 phacoemulsification cataract surgery videos from two surgical centers, performed by surgeons with a range of experience levels. This resource is enriched with four annotation layers: temporal surgical phases, instance segmentation of instruments and anatomical structures, instrument-tissue interaction tracking, and quantitative skill scores based on the established competency rubrics like the ICO-OSCAR. The technical quality of the dataset is supported by a series of benchmarking experiments for key surgical AI tasks, including workflow recognition, scene segmentation, and automated skill assessment. Furthermore, we establish a domain adaptation baseline for the phase recognition task by training a model on a subset of surgical centers and evaluating its performance on a held-out center. The dataset and annotations are available in Google Form (https://docs.google.com/forms/d/e/1FAIpQLSfmyMAPSTGrIy2sTnz0-TMw08ZagTimRulbAQcWdaPwDy187A/viewform?usp=dialog).",
      "tldr_zh": "本研究推出了Cataract-LMM，这是一个针对白内障手术视频分析的大规模、多来源、多任务基准数据集，旨在解决现有资源在多样性和标注深度方面的不足。该数据集包含来自两个手术中心的3,000段超声乳化(phacoemulsification)手术视频，涵盖了不同经验水平的手术医生。数据集提供了四个维度的丰富标注，包括手术阶段(temporal surgical phases)、器械与解剖结构的实例分割(instance segmentation)、器械-组织交互追踪以及基于ICO-OSCAR标准的量化技能评分。研究人员通过对手术流识别(workflow recognition)、场景分割和自动技能评估等关键手术AI任务进行实验，验证了数据集的技术质量。此外，该研究还为阶段识别任务建立了领域适应(domain adaptation)基准，以评估模型在不同医疗中心间的泛化能力。这一资源的发布为开发可泛化的深度学习手术辅助技术提供了重要支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 11 figures, 11 tables. Data descriptor for the Cataract-LMM benchmark dataset. Source code and dataset are available",
      "pdf_url": "https://arxiv.org/pdf/2510.16371v1",
      "published_date": "2025-10-18 06:48:29 UTC",
      "updated_date": "2025-10-18 06:48:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:36.970836+00:00"
    },
    {
      "arxiv_id": "2510.16368v1",
      "title": "The Burden of Interactive Alignment with Inconsistent Preferences",
      "title_zh": "不一致偏好下的交互式对齐代价",
      "authors": [
        "Ali Shirali"
      ],
      "abstract": "From media platforms to chatbots, algorithms shape how people interact, learn, and discover information. Such interactions between users and an algorithm often unfold over multiple steps, during which strategic users can guide the algorithm to better align with their true interests by selectively engaging with content. However, users frequently exhibit inconsistent preferences: they may spend considerable time on content that offers little long-term value, inadvertently signaling that such content is desirable. Focusing on the user side, this raises a key question: what does it take for such users to align the algorithm with their true interests?\n  To investigate these dynamics, we model the user's decision process as split between a rational system 2 that decides whether to engage and an impulsive system 1 that determines how long engagement lasts. We then study a multi-leader, single-follower extensive Stackelberg game, where users, specifically system 2, lead by committing to engagement strategies and the algorithm best-responds based on observed interactions. We define the burden of alignment as the minimum horizon over which users must optimize to effectively steer the algorithm. We show that a critical horizon exists: users who are sufficiently foresighted can achieve alignment, while those who are not are instead aligned to the algorithm's objective. This critical horizon can be long, imposing a substantial burden. However, even a small, costly signal (e.g., an extra click) can significantly reduce it. Overall, our framework explains how users with inconsistent preferences can align an engagement-driven algorithm with their interests in a Stackelberg equilibrium, highlighting both the challenges and potential remedies for achieving alignment.",
      "tldr_zh": "该研究探讨了在用户偏好不一致(Inconsistent Preferences)的情况下，用户如何通过交互实现算法对齐。研究将用户的决策过程建模为理性的System 2（决定是否参与）和冲动的System 1（决定参与时长）之间的划分，并采用了多领导者、单追随者的广义Stackelberg game进行分析。作者提出了对齐负担(Burden of Alignment)的概念，即用户为有效引导算法而必须进行优化的最小时间跨度。研究发现存在一个关键时域(Critical Horizon)，只有具备足够远见的用户才能实现算法对齐，否则用户将被对齐到算法的预设目标。尽管这种对齐负担在现实中可能极其沉重，但研究证明即使是微小且有成本的信号（如额外点击）也能显著降低这一门槛。该框架解释了用户如何在Stackelberg equilibrium中将以参与度为驱动的算法与自身真实利益相对齐，并为解决对齐难题提供了潜在方案。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "econ.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.16368v1",
      "published_date": "2025-10-18 06:25:57 UTC",
      "updated_date": "2025-10-18 06:25:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:42.869839+00:00"
    },
    {
      "arxiv_id": "2510.16363v1",
      "title": "End-to-End Argument Mining through Autoregressive Argumentative Structure Prediction",
      "title_zh": "基于自回归论辩结构预测的端到端论辩挖掘",
      "authors": [
        "Nilmadhab Das",
        "Vishal Vaibhav",
        "Yash Sunil Choudhary",
        "V. Vijaya Saradhi",
        "Ashish Anand"
      ],
      "abstract": "Argument Mining (AM) helps in automating the extraction of complex argumentative structures such as Argument Components (ACs) like Premise, Claim etc. and Argumentative Relations (ARs) like Support, Attack etc. in an argumentative text. Due to the inherent complexity of reasoning involved with this task, modelling dependencies between ACs and ARs is challenging. Most of the recent approaches formulate this task through a generative paradigm by flattening the argumentative structures. In contrast to that, this study jointly formulates the key tasks of AM in an end-to-end fashion using Autoregressive Argumentative Structure Prediction (AASP) framework. The proposed AASP framework is based on the autoregressive structure prediction framework that has given good performance for several NLP tasks. AASP framework models the argumentative structures as constrained pre-defined sets of actions with the help of a conditional pre-trained language model. These actions build the argumentative structures step-by-step in an autoregressive manner to capture the flow of argumentative reasoning in an efficient way. Extensive experiments conducted on three standard AM benchmarks demonstrate that AASP achieves state-of-theart (SoTA) results across all AM tasks in two benchmarks and delivers strong results in one benchmark.",
      "tldr_zh": "该研究针对 Argument Mining (AM) 任务中建模 Argument Components (ACs) 与 Argumentative Relations (ARs) 之间依赖关系的挑战，提出了端到端的 Autoregressive Argumentative Structure Prediction (AASP) 框架。与以往将论证结构扁平化的生成式方法不同，AASP 利用条件预训练语言模型将论证结构建模为受限的预定义动作集。通过自回归的方式逐步构建结构，该框架能够更高效地捕捉论证推理流，从而准确识别 Premise、Claim 等组件以及 Support、Attack 等复杂关系。在三个标准基准测试上的实验表明，AASP 在其中两个数据集的所有 AM 任务上均达到了 State-of-the-art (SoTA) 性能，并在第三个数据集上表现强劲。这项工作证明了 AASP 框架在处理复杂论证推理和端到端结构预测方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted version. To appear in IJCNN 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.16363v1",
      "published_date": "2025-10-18 06:10:57 UTC",
      "updated_date": "2025-10-18 06:10:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:42.175447+00:00"
    },
    {
      "arxiv_id": "2510.21779v2",
      "title": "What Causes Postoperative Aspiration?",
      "title_zh": "术后误吸的成因探究",
      "authors": [
        "Supriya Nagesh",
        "Karina Covarrubias",
        "Robert El-Kareh",
        "Shiva Prasad Kasiviswanathan",
        "Nina Mishra"
      ],
      "abstract": "Background: Aspiration, the inhalation of foreign material into the lungs, significantly impacts surgical patient morbidity and mortality. This study develops a machine learning (ML) model to predict postoperative aspiration, enabling timely preventative interventions.\n  Methods: From the MIMIC-IV database of over 400,000 hospital admissions, we identified 826 surgical patients (mean age: 62, 55.7\\% male) who experienced aspiration within seven days post-surgery, along with a matched non-aspiration cohort. Three ML models: XGBoost, Multilayer Perceptron, and Random Forest were trained using pre-surgical hospitalization data to predict postoperative aspiration. To investigate causation, we estimated Average Treatment Effects (ATE) using Augmented Inverse Probability Weighting.\n  Results: Our ML model achieved an AUROC of 0.86 and 77.3\\% sensitivity on a held-out test set. Maximum daily opioid dose, length of stay, and patient age emerged as the most important predictors. ATE analysis identified significant causative factors: opioids (0.25 +/- 0.06) and operative site (neck: 0.20 +/- 0.13, head: 0.19 +/- 0.13). Despite equal surgery rates across genders, men were 1.5 times more likely to aspirate and received 27\\% higher maximum daily opioid dosages compared to women.\n  Conclusion: ML models can effectively predict postoperative aspiration risk, enabling targeted preventative measures. Maximum daily opioid dosage and operative site significantly influence aspiration risk. The gender disparity in both opioid administration and aspiration rates warrants further investigation. These findings have important implications for improving postoperative care protocols and aspiration prevention strategies.",
      "tldr_zh": "该研究利用MIMIC-IV数据库开发了机器学习(Machine Learning)模型，旨在预测术后误吸(Aspiration)风险并为预防性干预提供支持。研究人员对比了XGBoost、多层感知器(Multilayer Perceptron)和随机森林(Random Forest)等模型，并采用平均处理效应(Average Treatment Effects, ATE)分析来探究误吸的潜在诱因。实验结果表明，最佳模型达到了0.86的AUROC，识别出每日最大阿片类药物剂量(Maximum daily opioid dose)、住院时长(Length of stay)和年龄是核心预测指标。进一步的ATE分析确认了阿片类药物的使用以及手术部位（尤其是头部和颈部）与术后误吸存在显著的因果关联。研究还揭示了明显的性别差异，发现男性患者的误吸风险是女性的1.5倍且接受了更高剂量的阿片类药物。这些发现强调了利用ML模型进行针对性风险评估的重要性，为改善术后护理路径和制定误吸预防策略提供了科学依据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21779v2",
      "published_date": "2025-10-18 05:07:57 UTC",
      "updated_date": "2025-10-28 19:53:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:48.370394+00:00"
    },
    {
      "arxiv_id": "2510.16344v1",
      "title": "Manual2Skill++: Connector-Aware General Robotic Assembly from Instruction Manuals via Vision-Language Models",
      "title_zh": "Manual2Skill++：利用视觉语言模型从说明书实现连接器感知的通用机器人组装",
      "authors": [
        "Chenrui Tie",
        "Shengxiang Sun",
        "Yudi Lin",
        "Yanbo Wang",
        "Zhongrui Li",
        "Zhouhan Zhong",
        "Jinxuan Zhu",
        "Yiman Pang",
        "Haonan Chen",
        "Junting Chen",
        "Ruihai Wu",
        "Lin Shao"
      ],
      "abstract": "Assembly hinges on reliably forming connections between parts; yet most robotic approaches plan assembly sequences and part poses while treating connectors as an afterthought. Connections represent the critical \"last mile\" of assembly execution, while task planning may sequence operations and motion plan may position parts, the precise establishment of physical connections ultimately determines assembly success or failure. In this paper, we consider connections as first-class primitives in assembly representation, including connector types, specifications, quantities, and placement locations. Drawing inspiration from how humans learn assembly tasks through step-by-step instruction manuals, we present Manual2Skill++, a vision-language framework that automatically extracts structured connection information from assembly manuals. We encode assembly tasks as hierarchical graphs where nodes represent parts and sub-assemblies, and edges explicitly model connection relationships between components. A large-scale vision-language model parses symbolic diagrams and annotations in manuals to instantiate these graphs, leveraging the rich connection knowledge embedded in human-designed instructions. We curate a dataset containing over 20 assembly tasks with diverse connector types to validate our representation extraction approach, and evaluate the complete task understanding-to-execution pipeline across four complex assembly scenarios in simulation, spanning furniture, toys, and manufacturing components with real-world correspondence.",
      "tldr_zh": "该研究提出了 Manual2Skill++，一种具备 Connector-Aware 能力的通用机器人组装框架，旨在解决传统自动化组装中因忽视连接件细节而导致执行失败的关键痛点。该框架将连接件（Connections）视为组装表示中的一级原语（First-class primitives），显式定义其类型、规格、数量及精确的放置位置。受人类阅读说明书启发，Manual2Skill++ 利用大规模 Vision-Language Models 自动解析组装手册中的符号图表与注释，并将任务编码为零件与子组件构成的层次化图（Hierarchical graphs）。通过在该图结构中显式建模组件间的连接关系，系统能够有效提取并利用人类设计指令中蕴含的丰富知识。研究团队构建了包含20多种组装任务的数据集，并在家具、玩具及制造组件等四个复杂模拟场景中验证了从手册理解到任务执行的完整闭环。实验结果表明，该框架能显著提升机器人在复杂物理连接任务中的感知与操作水平。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16344v1",
      "published_date": "2025-10-18 04:13:26 UTC",
      "updated_date": "2025-10-18 04:13:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:15:49.665035+00:00"
    },
    {
      "arxiv_id": "2510.16342v1",
      "title": "Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts",
      "title_zh": "超越固定锚点：利用同级互斥项实现精准概念擦除",
      "authors": [
        "Tong Zhang",
        "Ru Zhang",
        "Jianyi Liu",
        "Zhen Yang",
        "Gongshen Liu"
      ],
      "abstract": "Existing concept erasure methods for text-to-image diffusion models commonly rely on fixed anchor strategies, which often lead to critical issues such as concept re-emergence and erosion. To address this, we conduct causal tracing to reveal the inherent sensitivity of erasure to anchor selection and define Sibling Exclusive Concepts as a superior class of anchors. Based on this insight, we propose \\textbf{SELECT} (Sibling-Exclusive Evaluation for Contextual Targeting), a dynamic anchor selection framework designed to overcome the limitations of fixed anchors. Our framework introduces a novel two-stage evaluation mechanism that automatically discovers optimal anchors for precise erasure while identifying critical boundary anchors to preserve related concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor solution, not only efficiently adapts to multiple erasure frameworks but also consistently outperforms existing baselines across key performance metrics, averaging only 4 seconds for anchor mining of a single concept.",
      "tldr_zh": "现有的文本生成图像扩散模型 (text-to-image diffusion models) 概念擦除方法通常依赖固定锚点 (fixed anchor) 策略，这常导致概念重新出现或过度侵蚀等关键问题。该研究通过因果追踪 (causal tracing) 揭示了擦除操作对锚点选择的高度敏感性，并定义了兄弟排他性概念 (Sibling Exclusive Concepts) 作为更优的锚点。基于此，作者开发了名为 SELECT (Sibling-Exclusive Evaluation for Contextual Targeting) 的动态锚点选择框架，利用两阶段评估机制自动寻找最优擦除锚点并识别边界锚点以保护无关概念。实验证明，SELECT 作为一种通用解决方案，在多种擦除框架上均表现出优于基准模型的性能。此外，该方法效率极高，针对单个概念的锚点挖掘平均仅需 4 秒，为实现精确且高效的概念擦除提供了有力支持。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16342v1",
      "published_date": "2025-10-18 04:03:27 UTC",
      "updated_date": "2025-10-18 04:03:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:04.670174+00:00"
    },
    {
      "arxiv_id": "2510.16340v1",
      "title": "Thinking About Thinking: Evaluating Reasoning in Post-Trained Language Models",
      "title_zh": "思考之思考：评估后训练语言模型中的推理能力",
      "authors": [
        "Pratham Singla",
        "Shivank Garg",
        "Ayush Singh",
        "Ishan Garg",
        "Ketan Suhaas Saichandran"
      ],
      "abstract": "Recent advances in post-training techniques have endowed Large Language Models (LLMs) with enhanced capabilities for tackling complex, logic-intensive tasks through the generation of supplementary planning tokens. This development raises a fundamental question: Are these models aware of what they \"learn\" and \"think\"? To address this, we define three core competencies: (1) awareness of learned latent policies, (2) generalization of these policies across domains, and (3) alignment between internal reasoning traces and final outputs. We empirically evaluate these abilities on several tasks, each designed to require learning a distinct policy. Furthermore, we contrast the profiles of models post-trained via Supervised Fine-Tuning (SFT), Direct Policy Optimization (DPO), and Group Relative Policy Optimization (GRPO). Our findings indicate that RL-trained models not only demonstrate greater awareness of their learned behaviors and stronger generalizability to novel, structurally similar tasks than SFT models but also often exhibit weak alignment between their reasoning traces and final outputs, an effect most pronounced in GRPO-trained models.",
      "tldr_zh": "该研究探讨了后期训练(Post-Training)的大型语言模型在处理复杂逻辑任务时是否具备自我认知，并定义了潜在策略感知(Awareness of learned latent policies)、跨领域泛化以及内部推理轨迹与最终输出的一致性(Alignment)三项核心能力。通过对比分析监督微调(SFT)、直接策略优化(DPO)和群体相对策略优化(GRPO)训练的模型，研究发现强化学习(RL)训练的模型在行为感知和新任务泛化方面显著优于SFT模型。然而，RL训练的模型，尤其是使用GRPO的模型，在推理过程与最终输出之间往往表现出较弱的一致性。这一发现揭示了当前高性能推理模型在逻辑自洽性方面的潜在缺陷，为深入理解和优化大型语言模型的推理机制提供了实证依据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16340v1",
      "published_date": "2025-10-18 03:57:32 UTC",
      "updated_date": "2025-10-18 03:57:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:05.369508+00:00"
    },
    {
      "arxiv_id": "2510.17885v1",
      "title": "Metrics and evaluations for computational and sustainable AI efficiency",
      "title_zh": "计算与可持续 AI 效率的度量指标与评估",
      "authors": [
        "Hongyuan Liu",
        "Xinyang Liu",
        "Guosheng Hu"
      ],
      "abstract": "The rapid advancement of Artificial Intelligence (AI) has created unprecedented demands for computational power, yet methods for evaluating the performance, efficiency, and environmental impact of deployed models remain fragmented. Current approaches often fail to provide a holistic view, making it difficult to compare and optimise systems across heterogeneous hardware, software stacks, and numeric precisions. To address this gap, we propose a unified and reproducible methodology for AI model inference that integrates computational and environmental metrics under realistic serving conditions. Our framework provides a pragmatic, carbon-aware evaluation by systematically measuring latency and throughput distributions, energy consumption, and location-adjusted carbon emissions, all while maintaining matched accuracy constraints for valid comparisons. We apply this methodology to multi-precision models across diverse hardware platforms, from data-centre accelerators like the GH200 to consumer-level GPUs such as the RTX 4090, running on mainstream software stacks including PyTorch, TensorRT, and ONNX Runtime. By systematically categorising these factors, our work establishes a rigorous benchmarking framework that produces decision-ready Pareto frontiers, clarifying the trade-offs between accuracy, latency, energy, and carbon. The accompanying open-source code enables independent verification and facilitates adoption, empowering researchers and practitioners to make evidence-based decisions for sustainable AI deployment.",
      "tldr_zh": "该研究针对人工智能(AI)模型在性能、效率及环境影响评估标准碎片化的问题，提出了一种统一且可复现的AI模型推理(Inference)评估方法。该框架在实际服务条件下，系统地衡量了延迟(Latency)与吞吐量(Throughput)分布、能源消耗以及根据地理位置调整的碳排放，并确保在相同的精度(Accuracy)约束下进行有效比较。研究者将此方法应用于多精度模型，并跨越了从数据中心加速器GH200到消费级GPU RTX 4090的多种硬件平台，涵盖了PyTorch、TensorRT和ONNX Runtime等主流软件栈。通过对这些因素进行系统分类，该工作建立了一个严格的基准测试(Benchmarking)框架，生成了决策可用的帕累托前沿(Pareto frontiers)，清晰地揭示了精度、延迟、能源与碳排放之间的权衡关系。随附的开源代码不仅支持独立验证，也为研究人员和从业者在可持续AI部署中做出基于证据的决策提供了支持。",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.PF",
      "comment": "11 pages, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.17885v1",
      "published_date": "2025-10-18 03:30:15 UTC",
      "updated_date": "2025-10-18 03:30:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:12.965788+00:00"
    },
    {
      "arxiv_id": "2510.16321v1",
      "title": "Time-Embedded Algorithm Unrolling for Computational MRI",
      "title_zh": "面向计算磁共振成像的时间嵌入算法展开",
      "authors": [
        "Junno Yun",
        "Yaşar Utku Alçalar",
        "Mehmet Akçakaya"
      ],
      "abstract": "Algorithm unrolling methods have proven powerful for solving the regularized least squares problem in computational magnetic resonance imaging (MRI). These approaches unfold an iterative algorithm with a fixed number of iterations, typically alternating between a neural network-based proximal operator for regularization, a data fidelity operation and auxiliary updates with learnable parameters. While the connection to optimization methods dictate that the proximal operator network should be shared across unrolls, this can introduce artifacts or blurring. Heuristically, practitioners have shown that using distinct networks may be beneficial, but this significantly increases the number of learnable parameters, making it challenging to prevent overfitting. To address these shortcomings, by taking inspirations from proximal operators with varying thresholds in approximate message passing (AMP) and the success of time-embedding in diffusion models, we propose a time-embedded algorithm unrolling scheme for inverse problems. Specifically, we introduce a novel perspective on the iteration-dependent proximal operation in vector AMP (VAMP) and the subsequent Onsager correction in the context of algorithm unrolling, framing them as a time-embedded neural network. Similarly, the scalar weights in the data fidelity operation and its associated Onsager correction are cast as time-dependent learnable parameters. Our extensive experiments on the fastMRI dataset, spanning various acceleration rates and datasets, demonstrate that our method effectively reduces aliasing artifacts and mitigates noise amplification, achieving state-of-the-art performance. Furthermore, we show that our time-embedding strategy extends to existing algorithm unrolling approaches, enhancing reconstruction quality without increasing the computational complexity significantly.",
      "tldr_zh": "该研究提出了一种名为Time-Embedded Algorithm Unrolling（时间嵌入算法展开）的方案，旨在解决计算磁共振成像（Computational MRI）中正则化最小二乘问题的求解难题。针对传统算法展开方法在共享网络参数时易产生伪影，以及使用独立网络参数过多导致过拟合的矛盾，该方案借鉴了近似消息传递（Approximate Message Passing, AMP）的变阈值近端算子和扩散模型中时间嵌入（Time-embedding）的成功经验。研究将Vector AMP (VAMP)中的迭代依赖近端操作和Onsager校正重构为时间嵌入神经网络，并使数据保真项的标量权重成为随时间变化的学成参数。在fastMRI数据集上的实验表明，该方法有效减少了混叠伪影并抑制了噪声放大，达到了State-of-the-art（最优）性能。此外，该时间嵌入策略具有良好的通用性，能够在不显著增加计算复杂度的前提下提升现有算法展开模型的重建质量。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "Neural Information Processing Systems (NeurIPS), 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.16321v1",
      "published_date": "2025-10-18 03:10:09 UTC",
      "updated_date": "2025-10-18 03:10:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:08.358664+00:00"
    },
    {
      "arxiv_id": "2510.16310v1",
      "title": "Lung Cancer Classification from CT Images Using ResNet",
      "title_zh": "基于 ResNet 的 CT 图像肺癌分类",
      "authors": [
        "Olajumoke O. Adekunle",
        "Joseph D. Akinyemi",
        "Khadijat T. Ladoja",
        "Olufade F. W. Onifade"
      ],
      "abstract": "Lung cancer, a malignancy originating in lung tissues, is commonly diagnosed and classified using medical imaging techniques, particularly computed tomography (CT). Despite the integration of machine learning and deep learning methods, the predictive efficacy of automated systems for lung cancer classification from CT images remains below the desired threshold for clinical adoption. Existing research predominantly focuses on binary classification, distinguishing between malignant and benign lung nodules. In this study, a novel deep learning-based approach is introduced, aimed at an improved multi-class classification, discerning various subtypes of lung cancer from CT images. Leveraging a pre-trained ResNet model, lung tissue images were classified into three distinct classes, two of which denote malignancy and one benign. Employing a dataset comprising 15,000 lung CT images sourced from the LC25000 histopathological images, the ResNet50 model was trained on 10,200 images, validated on 2,550 images, and tested on the remaining 2,250 images. Through the incorporation of custom layers atop the ResNet architecture and meticulous hyperparameter fine-tuning, a remarkable test accuracy of 98.8% was recorded. This represents a notable enhancement over the performance of prior models on the same dataset.",
      "tldr_zh": "该研究针对肺癌分类中自动化系统预测效率不足以及现有研究多集中于良恶性二分类的问题，提出了一种基于深度学习的多分类方法。该方法利用预训练的 ResNet50 模型，通过在架构顶层添加自定义层并进行精细的超参数微调，实现了对肺部 CT 图像的三分类，包括两种恶性子类和一种良性类。研究采用了包含 15,000 张图像的 LC25000 数据集进行模型训练与验证。实验结果表明，改进后的 ResNet50 模型在测试集上达到了 98.8% 的准确率，显著优于该数据集上的先前模型。这一研究成果为提高肺癌亚型自动分类的临床适用性提供了重要的技术支撑。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "9 pages,4 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.16310v1",
      "published_date": "2025-10-18 02:44:02 UTC",
      "updated_date": "2025-10-18 02:44:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:16.853131+00:00"
    },
    {
      "arxiv_id": "2510.16309v3",
      "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier",
      "title_zh": "MedRule-KG：一种由知识图谱引导、配备轻量级验证器的数学推理框架",
      "authors": [
        "Crystal Su"
      ],
      "abstract": "Large language models (LLMs) often produce fluent reasoning steps while violating simple mathematical or logical constraints. We introduce MedRule-KG, a compact typed knowledge graph coupled with a symbolic verifier, designed to enforce mathematically interpretable rules in reasoning tasks. MedRule-KG encodes entities, relations, and three domain-inspired rules, while the verifier checks predictions and applies minimal corrections to guarantee consistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG improves exact match (EM) from 0.767 to 0.900, and adding the verifier yields 1.000 EM while eliminating rule violations entirely. We demonstrate how MedRule-KG provides a general scaffold for safe mathematical reasoning, discuss ablations, and release code and data to encourage reproducibility.",
      "tldr_zh": "这项研究介绍了 MedRule-KG，这是一个结合了紧凑型类型化知识图谱 (Knowledge Graph) 和符号验证器 (Symbolic Verifier) 的框架，旨在解决大语言模型 (LLMs) 在执行数学推理任务时经常违反逻辑约束的问题。MedRule-KG 通过编码实体、关系以及三条领域启发式规则，为推理过程提供了数学可解释的约束。系统配备的验证器能够对模型预测进行检查并实施最小化修正，从而确保逻辑的一致性。在包含 90 个样本的 FDA 衍生基准测试中，MedRule-KG 的引入将精确匹配率 (Exact Match) 从 0.767 提升至 0.900，而加入验证器后更是达到了 1.000 的满分并彻底消除了规则违规。该研究展示了 MedRule-KG 作为安全数学推理通用支架的潜力，并开源了相关代码和数据以促进领域内的复现研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper is withdrawn due to issues with attribution and citation accuracy",
      "pdf_url": "https://arxiv.org/pdf/2510.16309v3",
      "published_date": "2025-10-18 02:39:13 UTC",
      "updated_date": "2025-12-12 16:08:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:18.477817+00:00"
    },
    {
      "arxiv_id": "2510.16306v2",
      "title": "Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening",
      "title_zh": "面向增强型虚拟筛选的骨架感知生成式增强与重排序",
      "authors": [
        "Xin Wang",
        "Yu Wang",
        "Yunchao Liu",
        "Jens Meiler",
        "Tyler Derr"
      ],
      "abstract": "Ligand-based virtual screening (VS) is an essential step in drug discovery that evaluates large chemical libraries to identify compounds that potentially bind to a therapeutic target. However, VS faces three major challenges: class imbalance due to the low active rate, structural imbalance among active molecules where certain scaffolds dominate, and the need to identify structurally diverse active compounds for novel drug development. We introduce ScaffAug, a scaffold-aware VS framework that addresses these challenges through three modules. The augmentation module first generates synthetic data conditioned on scaffolds of actual hits using generative models, specifically a graph diffusion model. This helps mitigate the class imbalance and furthermore the structural imbalance, due to our proposed scaffold-aware sampling algorithm, designed to produce more samples for active molecules with underrepresented scaffolds. A model-agnostic self-training module is then used to safely integrate the generated synthetic data from our augmentation module with the original labeled data. Lastly, we introduce a reranking module that improves VS by enhancing scaffold diversity in the top recommended set of molecules, while still maintaining and even enhancing the overall general performance of identifying novel, active compounds. We conduct comprehensive computational experiments across five target classes, comparing ScaffAug against existing baseline methods by reporting the performance of multiple evaluation metrics and performing ablation studies on ScaffAug. Overall, this work introduces novel perspectives on effectively enhancing VS by leveraging generative augmentations, reranking, and general scaffold-awareness.",
      "tldr_zh": "该研究针对配体 Virtual Screening 中存在的类别不平衡、活性分子结构不平衡以及缺乏结构多样性等核心挑战，提出了 ScaffAug 框架。该框架的增强模块 (augmentation module) 利用 graph diffusion model 生成基于 scaffolds 的合成数据，并结合 scaffold-aware sampling 算法增加代表性不足的活性分子样本，以缓解数据不平衡问题。随后，模型无关的 self-training 模块将生成的合成数据与原始标注数据安全整合，而重排序模块 (reranking module) 则在保证甚至提升整体性能的同时，显著增加了推荐分子组的 scaffold diversity。在五类靶点上的综合计算实验表明，ScaffAug 在多项评估指标上均优于现有的基线方法，并能有效识别具有新颖结构的活性化合物。该工作通过 generative augmentations 和重排序技术，为增强 Virtual Screening 效能提供了 scaffold-awareness 的新颖视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16306v2",
      "published_date": "2025-10-18 02:26:08 UTC",
      "updated_date": "2026-01-21 06:09:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:19.947073+00:00"
    },
    {
      "arxiv_id": "2510.16302v1",
      "title": "DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA",
      "title_zh": "DTKG：面向多跳问答的知识图谱验证双轨推理框架",
      "authors": [
        "Changhao Wang",
        "Yanfang Liu",
        "Xinxin Fan",
        "Anzhi Zhou",
        "Lao Tian",
        "Yunfeng Lu"
      ],
      "abstract": "Multi-hop reasoning for question answering (QA) plays a critical role in retrieval-augmented generation (RAG) for modern large language models (LLMs). The accurate answer can be obtained through retrieving relational structure of entities from knowledge graph (KG). Regarding the inherent relation-dependency and reasoning pattern, multi-hop reasoning can be in general classified into two categories: i) parallel fact-verification multi-hop reasoning question, i.e., requiring simultaneous verifications of multiple independent sub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding sequential multi-step inference with intermediate conclusions serving as essential premises for subsequent reasoning. Currently, the multi-hop reasoning approaches singly employ one of two techniques: LLM response-based fact verification and KG path-based chain construction. Nevertheless, the former excels at parallel fact-verification but underperforms on chained reasoning tasks, while the latter demonstrates proficiency in chained multi-hop reasoning but suffers from redundant path retrieval when handling parallel fact-verification reasoning. These limitations deteriorate the efficiency and accuracy for multi-hop QA tasks. To address this challenge, we propose a novel dual-track KG verification and reasoning framework DTKG, which is inspired by the Dual Process Theory in cognitive science. Specifically, DTKG comprises two main stages: the Classification Stage and the Branch Processing Stage.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在检索增强生成(RAG)中的多跳推理(Multi-hop reasoning)挑战，指出当前方法在并行事实验证与链式推理任务中存在效率与准确率失衡的问题。受认知科学双过程理论(Dual Process Theory)启发，作者提出了名为DTKG的双轨知识图谱验证推理框架。DTKG主要包含分类阶段(Classification Stage)和分支处理阶段(Branch Processing Stage)，旨在根据问题类型灵活匹配推理路径。该框架有效地克服了传统方法在处理并行事实验证时的路径冗余，并显著提升了链式推理中顺序逻辑的严密性。通过融合基于大模型响应的验证与基于知识图谱(KG)路径的构建，DTKG为解决复杂的多跳问答(Multi-hop QA)任务提供了一种更高效且精准的解决方案。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.16302v1",
      "published_date": "2025-10-18 02:19:11 UTC",
      "updated_date": "2025-10-18 02:19:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:27.257342+00:00"
    },
    {
      "arxiv_id": "2510.17884v3",
      "title": "When Intelligence Fails: An Empirical Study on Why LLMs Struggle with Password Cracking",
      "title_zh": "当智能失效：关于 LLMs 为何难以破解密码的实证研究",
      "authors": [
        "Mohammad Abdul Rehman",
        "Syed Imad Ali Shah",
        "Abbas Anwar",
        "Noor Islam",
        "Hamid Khan"
      ],
      "abstract": "The remarkable capabilities of Large Language Models (LLMs) in natural language understanding and generation have sparked interest in their potential for cybersecurity applications, including password guessing. In this study, we conduct an empirical investigation into the efficacy of pre-trained LLMs for password cracking using synthetic user profiles. Specifically, we evaluate the performance of state-of-the-art open-source LLMs such as TinyLLaMA, Falcon-RW-1B, and Flan-T5 by prompting them to generate plausible passwords based on structured user attributes (e.g., name, birthdate, hobbies). Our results, measured using Hit@1, Hit@5, and Hit@10 metrics under both plaintext and SHA-256 hash comparisons, reveal consistently poor performance, with all models achieving less than 1.5% accuracy at Hit@10. In contrast, traditional rule-based and combinator-based cracking methods demonstrate significantly higher success rates. Through detailed analysis and visualization, we identify key limitations in the generative reasoning of LLMs when applied to the domain-specific task of password guessing. Our findings suggest that, despite their linguistic prowess, current LLMs lack the domain adaptation and memorization capabilities required for effective password inference, especially in the absence of supervised fine-tuning on leaked password datasets. This study provides critical insights into the limitations of LLMs in adversarial contexts and lays the groundwork for future efforts in secure, privacy-preserving, and robust password modeling.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在网络安全领域特别是密码破解任务中的表现进行了实证研究，通过提示 TinyLLaMA、Falcon-RW-1B 和 Flan-T5 等开源模型根据用户结构化属性生成密码。实验利用 Hit@1、Hit@5 和 Hit@10 等指标在明文及 SHA-256 哈希比对下进行测试，结果表明所有模型在 Hit@10 下的准确率均不足 1.5%，远低于传统的基于规则 (rule-based) 和组合器 (combinator-based) 的破解方法。深入分析发现，LLMs 在密码猜测这一特定领域存在生成推理能力的局限性，尤其在缺乏针对泄露密码数据集进行监督微调 (supervised fine-tuning) 的情况下，难以具备有效的领域适配 (domain adaptation) 和记忆能力。该研究揭示了现有模型在对抗性环境下的短板，为未来开发安全、隐私保护且鲁棒的密码建模提供了重要参考。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.17884v3",
      "published_date": "2025-10-18 02:15:28 UTC",
      "updated_date": "2025-12-31 06:54:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:26.262983+00:00"
    },
    {
      "arxiv_id": "2510.17883v2",
      "title": "From Flows to Words: Can Zero-/Few-Shot LLMs Detect Network Intrusions? A Grammar-Constrained, Calibrated Evaluation on UNSW-NB15",
      "title_zh": "从流量到文本：零样本/少样本大语言模型能否检测网络入侵？基于 UNSW-NB15 的语法约束与校准化评估",
      "authors": [
        "Mohammad Abdul Rehman",
        "Syed Imad Ali Shah",
        "Abbas Anwar",
        "Noor Islam"
      ],
      "abstract": "Large Language Models (LLMs) can reason over natural-language inputs, but their role in intrusion detection without fine-tuning remains uncertain. This study evaluates a prompt-only approach on UNSW-NB15 by converting each network flow to a compact textual record and augmenting it with lightweight, domain-inspired boolean flags (asymmetry, burst rate, TTL irregularities, timer anomalies, rare service/state, short bursts). To reduce output drift and support measurement, the model is constrained to produce structured, grammar-valid responses, and a single decision threshold is calibrated on a small development split. We compare zero-shot, instruction-guided, and few-shot prompting to strong tabular and neural baselines under identical splits, reporting accuracy, precision, recall, F1, and macro scores. Empirically, unguided prompting is unreliable, while instructions plus flags substantially improve detection quality; adding calibrated scoring further stabilizes results. On a balanced subset of two hundred flows, a 7B instruction-tuned model with flags reaches macro-F1 near 0.78; a lighter 3B model with few-shot cues and calibration attains F1 near 0.68 on one thousand examples. As the evaluation set grows to two thousand flows, decision quality decreases, revealing sensitivity to coverage and prompting. Tabular baselines remain more stable and faster, yet the prompt-only pipeline requires no gradient training, produces readable artifacts, and adapts easily through instructions and flags. Contributions include a flow-to-text protocol with interpretable cues, a calibration method for thresholding, a systematic baseline comparison, and a reproducibility bundle with prompts, grammar, metrics, and figures.",
      "tldr_zh": "该研究评估了在无需微调(fine-tuning)的情况下，大语言模型(LLMs)通过纯提示词(prompt-only)方法在网络入侵检测任务中的表现，并提出了一种将网络流(network flow)转换为紧凑文本记录的协议。该方法结合了包括不对称性(asymmetry)、突发率(burst rate)和TTL异常(TTL irregularities)在内的领域启发式布尔标志(boolean flags)，并利用语法约束(grammar-constrained)确保输出结构化，同时通过校准(calibrated)决策阈值来稳定模型预测。实验对比了零样本(zero-shot)、指令引导和少样本(few-shot)提示策略在UNSW-NB15数据集上的性能。结果显示，指令配合布尔标志能显著提升检测质量，其中7B模型在平衡子集上的宏F1分数(macro-F1)接近0.78。尽管传统表格基线模型在速度和稳定性上依然领先，但这种基于LLM的方法无需梯度训练，且具备极强的可解释性和指令适配能力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.17883v2",
      "published_date": "2025-10-18 02:11:50 UTC",
      "updated_date": "2025-10-26 07:42:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:31.462571+00:00"
    },
    {
      "arxiv_id": "2510.16295v2",
      "title": "OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models",
      "title_zh": "OpenLVLM-MIA：揭示大型视觉语言模型成员推理攻击局限性的受控基准",
      "authors": [
        "Ryoto Miyamoto",
        "Xin Fan",
        "Fuyuko Kido",
        "Tsuneo Matsumoto",
        "Hayato Yamana"
      ],
      "abstract": "OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in evaluating membership inference attacks (MIA) against large vision-language models (LVLMs). While prior work has reported high attack success rates, our analysis suggests that these results often arise from detecting distributional bias introduced during dataset construction rather than from identifying true membership status. To address this issue, we introduce a controlled benchmark of 6{,}000 images where the distributions of member and non-member samples are carefully balanced, and ground-truth membership labels are provided across three distinct training stages. Experiments using OpenLVLM-MIA demonstrated that the performance of state-of-the-art MIA methods approached chance-level. OpenLVLM-MIA, designed to be transparent and unbiased benchmark, clarifies certain limitations of MIA research on LVLMs and provides a solid foundation for developing stronger privacy-preserving techniques.",
      "tldr_zh": "该研究提出了 OpenLVLM-MIA，这是一个旨在揭示大语言视觉模型 (Large Vision-Language Models, LVLMs) 成员推理攻击 (Membership Inference Attacks, MIA) 评估中根本性挑战的新型基准测试。作者指出，以往研究报告的高攻击成功率往往源于数据集构建过程中引入的分布偏置 (Distributional Bias)，而非对真实成员身份的识别。为了解决这一问题，该基准包含了 6,000 张图像，通过精细平衡成员与非成员样本的分布，并在三个不同的训练阶段提供了真实成员标签 (Ground-truth Membership Labels)。在 OpenLVLM-MIA 上的实验结果显示，目前最先进的 MIA 方法的表现接近随机水平 (Chance-level)。这一透明且无偏的基准测试阐明了 LVLMs 上 MIA 研究的局限性，并为开发更强大的隐私保护技术奠定了坚实基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "WACV2026 Accepted",
      "pdf_url": "https://arxiv.org/pdf/2510.16295v2",
      "published_date": "2025-10-18 01:39:28 UTC",
      "updated_date": "2025-12-02 15:12:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:42.859115+00:00"
    },
    {
      "arxiv_id": "2510.17882v1",
      "title": "Does GenAI Rewrite How We Write? An Empirical Study on Two-Million Preprints",
      "title_zh": "GenAI 是否正在重塑我们的写作方式？基于两百万篇预印本的实证研究",
      "authors": [
        "Minfeng Qi",
        "Zhongmin Cao",
        "Qin Wang",
        "Ningran Li",
        "Tianqing Zhu"
      ],
      "abstract": "Preprint repositories become central infrastructures for scholarly communication. Their expansion transforms how research is circulated and evaluated before journal publication. Generative large language models (LLMs) introduce a further potential disruption by altering how manuscripts are written. While speculation abounds, systematic evidence of whether and how LLMs reshape scientific publishing remains limited.\n  This paper addresses the gap through a large-scale analysis of more than 2.1 million preprints spanning 2016--2025 (115 months) across four major repositories (i.e., arXiv, bioRxiv, medRxiv, SocArXiv). We introduce a multi-level analytical framework that integrates interrupted time-series models, collaboration and productivity metrics, linguistic profiling, and topic modeling to assess changes in volume, authorship, style, and disciplinary orientation. Our findings reveal that LLMs have accelerated submission and revision cycles, modestly increased linguistic complexity, and disproportionately expanded AI-related topics, while computationally intensive fields benefit more than others. These results show that LLMs act less as universal disruptors than as selective catalysts, amplifying existing strengths and widening disciplinary divides. By documenting these dynamics, the paper provides the first empirical foundation for evaluating the influence of generative AI on academic publishing and highlights the need for governance frameworks that preserve trust, fairness, and accountability in an AI-enabled research ecosystem.",
      "tldr_zh": "该研究通过对2016至2025年间来自arXiv、bioRxiv、medRxiv和SocArXiv四大仓库的210万篇预印本论文进行大规模实证分析，探讨了生成式人工智能（Generative AI）对科学出版的重塑作用。研究团队引入了一个整合中断时间序列模型（interrupted time-series models）、协作与生产力指标及主题建模的多层级分析框架。研究发现，大型语言模型（LLMs）显著加速了论文的投稿与修订周期，并适度提升了文本的语言复杂度，同时导致AI相关主题在各学科中不成比例地扩张。实证结果表明，LLMs并非全盘颠覆者，而是作为“选择性催化剂”强化了现有学科优势，并可能扩大不同领域间的技术鸿沟。该论文为评估GenAI对学术界的影响提供了重要的实证基础，并强调了在AI驱动的科研生态中建立治理框架以维护信任、公平与问责制的紧迫性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.DL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.17882v1",
      "published_date": "2025-10-18 01:37:40 UTC",
      "updated_date": "2025-10-18 01:37:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:48.957900+00:00"
    },
    {
      "arxiv_id": "2510.16293v1",
      "title": "Synergizing chemical and AI communities for advancing laboratories of the future",
      "title_zh": "协同化学与人工智能领域，推进未来实验室发展",
      "authors": [
        "Saejin Oh",
        "Xinyi Fang",
        "I-Hsin Lin",
        "Paris Dee",
        "Christopher S. Dunham",
        "Stacy M. Copp",
        "Abigail G. Doyle",
        "Javier Read de Alaniz",
        "Mengyang Gu"
      ],
      "abstract": "The development of automated experimental facilities and the digitization of experimental data have introduced numerous opportunities to radically advance chemical laboratories. As many laboratory tasks involve predicting and understanding previously unknown chemical relationships, machine learning (ML) approaches trained on experimental data can substantially accelerate the conventional design-build-test-learn process. This outlook article aims to help chemists understand and begin to adopt ML predictive models for a variety of laboratory tasks, including experimental design, synthesis optimization, and materials characterization. Furthermore, this article introduces how artificial intelligence (AI) agents based on large language models can help researchers acquire background knowledge in chemical or data science and accelerate various aspects of the discovery process. We present three case studies in distinct areas to illustrate how ML models and AI agents can be leveraged to reduce time-consuming experiments and manual data analysis. Finally, we highlight existing challenges that require continued synergistic effort from both experimental and computational communities to address.",
      "tldr_zh": "该展望文章探讨了化学与人工智能(AI)社区的协同作用，旨在利用自动化实验设施和数字化数据推进未来实验室的发展。为了加速传统的design-build-test-learn研发循环，研究阐述了Machine Learning (ML)模型在实验设计、合成优化和材料表征等任务中的应用。此外，文章介绍了基于Large Language Models (LLMs)的AI agents如何辅助研究人员获取专业背景知识并加速发现过程。通过三个不同领域的案例研究，证明了ML模型和AI agents在减少耗时实验和手动数据分析方面的显著优势。最后，该研究指出了当前面临的挑战，并强调实验与计算社区需持续共同努力以实现化学研究的范式转化。",
      "categories": [
        "stat.AP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16293v1",
      "published_date": "2025-10-18 01:36:27 UTC",
      "updated_date": "2025-10-18 01:36:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:51.862368+00:00"
    },
    {
      "arxiv_id": "2510.16289v1",
      "title": "Disentangling Hyperedges through the Lens of Category Theory",
      "title_zh": "基于范畴论视角的超边解耦",
      "authors": [
        "Yoonho Lee",
        "Junseok Lee",
        "Sangwoo Seo",
        "Sungwon Kim",
        "Yeongmin Kim",
        "Chanyoung Park"
      ],
      "abstract": "Despite the promising results of disentangled representation learning in discovering latent patterns in graph-structured data, few studies have explored disentanglement for hypergraph-structured data. Integrating hyperedge disentanglement into hypergraph neural networks enables models to leverage hidden hyperedge semantics, such as unannotated relations between nodes, that are associated with labels. This paper presents an analysis of hyperedge disentanglement from a category-theoretical perspective and proposes a novel criterion for disentanglement derived from the naturality condition. Our proof-of-concept model experimentally showed the potential of the proposed criterion by successfully capturing functional relations of genes (nodes) in genetic pathways (hyperedges).",
      "tldr_zh": "该研究探讨了超图 (hypergraph) 结构下的解耦表征学习 (disentangled representation learning)，旨在弥补现有图神经网络在处理超边 (hyperedge) 语义解耦方面的不足。通过引入超边解耦，模型能够更有效地捕捉节点间未标注的关系等隐藏语义信息。本论文创新性地从范畴论 (Category Theory) 的视角对该问题展开分析，并基于自然性条件 (naturality condition) 推导出一种全新的解耦准则。实验通过概念验证模型展示了该准则在遗传通路 (genetic pathways) 中捕捉基因功能关系的潜力，证明了其识别复杂数据模式的有效性。这项工作为超图数据的高级语义理解提供了全新的理论支撑与实践参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.16289v1",
      "published_date": "2025-10-18 01:23:10 UTC",
      "updated_date": "2025-10-18 01:23:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:52.361218+00:00"
    },
    {
      "arxiv_id": "2510.19838v1",
      "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory",
      "title_zh": "Branch-and-Browse：基于树形结构推理与动作记忆的高效可控网页探索",
      "authors": [
        "Shiqi He",
        "Yue Cui",
        "Xinyu Ma",
        "Yaliang Li",
        "Bolin Ding",
        "Mosharaf Chowdhury"
      ],
      "abstract": "Autonomous web agents powered by large language models (LLMs) show strong potential for performing goal-oriented tasks such as information retrieval, report generation, and online transactions. These agents mark a key step toward practical embodied reasoning in open web environments. However, existing approaches remain limited in reasoning depth and efficiency: vanilla linear methods fail at multi-step reasoning and lack effective backtracking, while other search strategies are coarse-grained and computationally costly. We introduce Branch-and-Browse, a fine-grained web agent framework that unifies structured reasoning-acting, contextual memory, and efficient execution. It (i) employs explicit subtask management with tree-structured exploration for controllable multi-branch reasoning, (ii) bootstraps exploration through efficient web state replay with background reasoning, and (iii) leverages a page action memory to share explored actions within and across sessions. On the WebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\\% and reduces execution time by up to 40.4\\% relative to state-of-the-art methods. These results demonstrate that Branch-and-Browse is a reliable and efficient framework for LLM-based web agents.",
      "tldr_zh": "该研究针对现有大语言模型(LLMs)驱动的自主Web智能体在多步推理和执行效率方面的局限，提出了Branch-and-Browse框架。该框架通过引入树状结构探索(Tree-Structured Exploration)实现了显式的子任务管理，从而支持更精确的可控多分支推理。通过高效的网页状态回放(Web State Replay)与后台推理技术，系统能够显著引导和加速探索过程。此外，研究引入了页面动作记忆(Page Action Memory)机制，实现了探索动作在不同会话间的共享与复用。在WebArena基准测试中，Branch-and-Browse取得了35.8%的任务成功率。相较于现有最先进方法，该框架将执行时间缩短了约40.4%，证明了其在处理复杂Web任务时的卓越可靠性与效率。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.19838v1",
      "published_date": "2025-10-18 00:45:37 UTC",
      "updated_date": "2025-10-18 00:45:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:57.464933+00:00"
    },
    {
      "arxiv_id": "2510.16281v2",
      "title": "Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification",
      "title_zh": "言行一致：通过运行时推理-动作对齐验证引导视觉-语言-动作模型",
      "authors": [
        "Yilin Wu",
        "Anqi Li",
        "Tucker Hermans",
        "Fabio Ramos",
        "Andrea Bajcsy",
        "Claudia Pérez-D'Arpino"
      ],
      "abstract": "Reasoning Vision Language Action (VLA) models improve robotic instruction-following by generating step-by-step textual plans before low-level actions, an approach inspired by Chain-of-Thought (CoT) reasoning in language models. Yet even with a correct textual plan, the generated actions can still miss the intended outcomes in the plan, especially in out-of-distribution (OOD) scenarios. We formalize this phenomenon as a lack of embodied CoT faithfulness, and introduce a training-free, runtime policy steering method for reasoning-action alignment. Given a reasoning VLA's intermediate textual plan, our framework samples multiple candidate action sequences from the same model, predicts their outcomes via simulation, and uses a pre-trained Vision-Language Model (VLM) to select the sequence whose outcome best aligns with the VLA's own textual plan. Only executing action sequences that align with the textual reasoning turns our base VLA's natural action diversity from a source of error into a strength, boosting robustness to semantic and visual OOD perturbations and enabling novel behavior composition without costly re-training. We also contribute a reasoning-annotated extension of LIBERO-100, environment variations tailored for OOD evaluation, and demonstrate up to 15% performance gain over prior work on behavior composition tasks and scales with compute and data diversity. Project Website at: https://yilin-wu98.github.io/steering-reasoning-vla/",
      "tldr_zh": "该研究探讨了推理型视觉-语言-动作模型(Vision-Language-Action, VLA)在具体化CoT忠实度(embodied CoT faithfulness)方面的缺失问题，即模型生成的动作往往与其实际的文本规划不一致，尤其在分布外(OOD)场景中表现明显。为此，作者提出了一种无需训练的运行时策略引导方法，通过在推理与动作之间建立对齐验证机制。该框架从同一模型中采样多个候选动作序列，利用模拟预测其结果，并使用预训练的视觉语言模型(VLM)筛选出与原始文本规划最匹配的序列执行。这种方法有效地将动作多样性转化为提升鲁棒性的优势，并支持无需重新训练的新行为组合。研究还贡献了带有推理标注的LIBERO-100扩展数据集及评估环境。实验结果显示，该方法在行为组合任务上的性能比前序工作提升了高达15%，且其效能随计算量和数据多样性的增加而增强。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16281v2",
      "published_date": "2025-10-18 00:38:45 UTC",
      "updated_date": "2026-01-14 05:03:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:16:59.567264+00:00"
    },
    {
      "arxiv_id": "2510.16276v1",
      "title": "What Limits Agentic Systems Efficiency?",
      "title_zh": "智能体系统效率的瓶颈何在？",
      "authors": [
        "Song Bian",
        "Minghao Yan",
        "Anand Jayarajan",
        "Gennady Pekhimenko",
        "Shivaram Venkataraman"
      ],
      "abstract": "Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have demonstrated strong reasoning capabilities. To further enhance LLM capabilities, recent agentic systems, such as Deep Research, incorporate web interactions into LLM reasoning to mitigate uncertainties and reduce potential errors. However, existing research predominantly focuses on reasoning performance, often neglecting the efficiency of agentic systems. In this work, we present a comprehensive empirical study that identifies efficiency bottlenecks in web-interactive agentic systems. We decompose end-to-end latency into two primary components: LLM API latency and web environment latency. We conduct a comprehensive empirical study across 15 models and 5 providers to demonstrate high variability in API-based agentic systems. We observe that web environment latency can contribute as much as 53.7% to the overall latency in a web-based agentic system. To improve latency, we propose SpecCache, a caching framework augmented with speculative execution that can reduce web environment overhead. Extensive evaluations on two standard benchmarks show that our approach improves the cache hit rate by up to 58x compared to a random caching strategy, while reducing web environment overhead by up to 3.2x, without degrading agentic system performance.",
      "tldr_zh": "该项研究探讨了限制智能体系统(Agentic Systems)效率的关键因素，填补了现有研究过于关注推理性能而忽视效率的空白。研究者将端到端延迟分解为LLM API latency和web environment latency两个主分量，并对15个模型和5个提供商进行了大规模实证研究。实验发现，web environment latency在基于网页的智能体系统中占比高达53.7%，且不同API服务表现出显著的波动性。为此，研究团队提出了SpecCache，这是一种结合推测执行(speculative execution)的缓存框架，旨在减少网页环境产生的开销。在标准基准测试中的评估结果显示，SpecCache在不损害系统性能的前提下，将缓存命中率提升了最高58倍，并将网络环境开销降低了最高3.2倍。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 15 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.16276v1",
      "published_date": "2025-10-18 00:21:45 UTC",
      "updated_date": "2025-10-18 00:21:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:17:04.251701+00:00"
    },
    {
      "arxiv_id": "2510.16273v1",
      "title": "MuseTok: Symbolic Music Tokenization for Generation and Semantic Understanding",
      "title_zh": "MuseTok：面向生成与语义理解的符号化音乐词元化",
      "authors": [
        "Jingyue Huang",
        "Zachary Novack",
        "Phillip Long",
        "Yupeng Hou",
        "Ke Chen",
        "Taylor Berg-Kirkpatrick",
        "Julian McAuley"
      ],
      "abstract": "Discrete representation learning has shown promising results across various domains, including generation and understanding in image, speech and language. Inspired by these advances, we propose MuseTok, a tokenization method for symbolic music, and investigate its effectiveness in both music generation and understanding tasks. MuseTok employs the residual vector quantized-variational autoencoder (RQ-VAE) on bar-wise music segments within a Transformer-based encoder-decoder framework, producing music codes that achieve high-fidelity music reconstruction and accurate understanding of music theory. For comprehensive evaluation, we apply MuseTok to music generation and semantic understanding tasks, including melody extraction, chord recognition, and emotion recognition. Models incorporating MuseTok outperform previous representation learning baselines in semantic understanding while maintaining comparable performance in content generation. Furthermore, qualitative analyses on MuseTok codes, using ground-truth categories and synthetic datasets, reveal that MuseTok effectively captures underlying musical concepts from large music collections.",
      "tldr_zh": "该研究提出了 MuseTok，一种针对 symbolic music 设计的 tokenization 方法，旨在同时优化音乐生成与语义理解任务。该方法在基于 Transformer 的 encoder-decoder 框架中，对以小节为单位的音乐片段应用了 RQ-VAE 技术，生成了兼具高保真重构能力与准确乐理理解能力的音乐代码。实验结果显示，MuseTok 在旋律提取、和弦识别和情感识别等语义理解任务上显著优于此前的表示学习基准，并在内容生成方面保持了稳健的表现。定性分析进一步证实，MuseTok 能够从大规模音乐数据中有效捕捉底层的音乐概念，为多任务音乐智能分析奠定了基础。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16273v1",
      "published_date": "2025-10-18 00:04:48 UTC",
      "updated_date": "2025-10-18 00:04:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T04:17:09.474879+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 78,
  "processed_papers_count": 78,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T04:17:56.119008+00:00"
}