{
  "date": "2024-03-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-09 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 41 篇论文，主要聚焦 AI 模型优化、机器人导航、知识图谱推理和情感计算等领域，其中令人印象深刻的包括 Large Language Models (LLMs) 在低资源语言上的应用（如 Christopher Toukmaji 的论文）和生成模型的鲁棒性提升，同时有几篇涉及知名会议如 ICRA 2024 和 CHI LBW 2024 的工作，突显了 AI 在实际应用中的潜力。\n\n### 重点论文讨论\n我挑选了最具话题度和影响力的几篇论文先聊，特别是那些涉及热门 AI 技术、知名作者或实际应用的。相关论文按主题归类，放在一起讨论。\n\n1. **MATRIX: Multi-Agent Trajectory Generation with Diverse Contexts（中文：多代理轨迹生成模型，支持多样化上下文）**  \n   这篇论文（作者：Zhuo Xu 等，ICRA 2024）提出了一种基于学习的轨迹生成模型 MATRIX，用于多人类或人机交互场景。它通过建模显式目标（如目的地和行为异质性）来生成更真实的多代理轨迹，主要贡献是提升数据增强在模仿学习中的效果，实验证明其在各种指标上优于传统方法，对于机器人导航和交互有重要启发。\n\n2. **Understanding Social Perception, Interactions, and Safety Aspects of Sidewalk Delivery Robots Using Sentiment Analysis（中文：使用情感分析理解人行道配送机器人的社会感知、交互和安全方面）**  \n   紧接着机器人主题，这篇（作者：Yuchen Du 等）通过情感分析 YouTube 评论，构建了情感分类模型（如 BERT 和 LSTM），并提取潜在话题来提出政策建议。主要发现是 SVM 和 TF-IDF 在二分类任务中表现最佳，而 BERT 在三分类中达到 0.78 的准确率，为机器人社会影响评估提供了实用工具。\n\n3. **Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages（中文：低资源语言中少样本跨语言迁移用于提示大型语言模型）**  \n   这篇由 Christopher Toukmaji 撰写，聚焦 LLMs（如 LLaMa）在低资源语言（如 Kinyarwanda）的提示学习。核心贡献是通过少样本提示（prompt）和翻译方法优化模型，实验显示 prompt 方法在摘要和分类任务中显著优于微调，强调了高效迁移的实际价值，是今日最有话题度的论文之一。\n\n4. **Calibrating Large Language Models Using Their Generations Only（中文：仅使用生成输出校准大型语言模型）**  \n   作者 Dennis Ulmer 等提出 APRICOT 方法，通过预测 LLMs 的置信度来校准模型，而不需额外数据。主要发现是它能有效检测错误答案，并在白盒/黑盒场景下减少校准误差，为 LLMs 在实际应用中的可靠性提供新路径。\n\n5. **GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual Affective Computing（中文：GPT 作为心理学家？GPT-4V 在视觉情感计算的初步评估）**  \n   这篇（作者：Hao Lu 等）评估 GPT-4V 在情感任务（如面部表情识别）的性能。关键发现是 GPT 在动作单位识别上准确率高，但整体表情识别仍有不足，并提出结合任务代理提升复杂任务（如心率估计）的潜力，展示了 LLMs 在视觉情感计算的广阔应用前景。\n\n6. **TokenMark: A Modality-Agnostic Watermark for Pre-trained Transformers（中文：TokenMark：一种适用于预训练 Transformer 的模态无关水印）**  \n   作者 Hengyuan Xu 等开发了一种通用的模型水印方法，利用 Transformer 的置换等变性来嵌入水印。主要贡献是提高水印的鲁棒性和效率，实验显示它在不同模态上显著优于基线，对于保护 AI 模型知识产权具有重要意义。\n\n其他论文较多，我快速掠过一些有价值的但非核心的：\n- **A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation（中文：YouTuber 使用生成式 AI 的初步探索）**（作者：Yao Lyu 等，CHI LBW 2024）：分析 AI 在内容生成中的应用，如图像和视频，贡献是识别工具多样性和领域，但细节较初步。\n- **CarbonNet（中文：CarbonNet：使用计算机视觉学习碳捕获与封存的地下几何力学）**（作者：Wei Chen 等）：提出 CNN 和 LSTM 模型预测碳注入引起的表面位移，贡献在于提升 CCS 项目的决策支持。\n- **FairTargetSim（中文：FairTargetSim：交互模拟器用于解释目标变量定义对公平性的影响）**（作者：Dalia Gala 等）：一个开源工具展示算法公平性，焦点在招聘场景的偏差分析。\n- **Towards a Generic Representation of Combinatorial Problems（中文：面向学习方法的组合问题通用表示）**（作者：Léo Boisvert 等）：提出图神经网络通用框架，适用于多种组合问题，实验显示性能与专用模型相当。\n- 其余如扩散模型（第17、30、41）、知识图谱推理（第5、12、29）和情感分析（第21）论文，贡献包括优化不平衡数据生成和不确定性估计，但细节较技术性强，建议感兴趣读者查阅摘要。\n\n总之，今天的 arXiv 论文强调 AI 的实用性和鲁棒性，LLMs 和机器人领域尤为活跃。如果你关注特定主题，建议优先查看上述重点论文！",
  "papers": [
    {
      "arxiv_id": "2403.06041v1",
      "title": "MATRIX: Multi-Agent Trajectory Generation with Diverse Contexts",
      "title_zh": "MATRIX：多智能体轨迹生成支持多样化上下文",
      "authors": [
        "Zhuo Xu",
        "Rui Zhou",
        "Yida Yin",
        "Huidong Gao",
        "Masayoshi Tomizuka",
        "Jiachen Li"
      ],
      "abstract": "Data-driven methods have great advantages in modeling complicated human\nbehavioral dynamics and dealing with many human-robot interaction applications.\nHowever, collecting massive and annotated real-world human datasets has been a\nlaborious task, especially for highly interactive scenarios. On the other hand,\nalgorithmic data generation methods are usually limited by their model\ncapacities, making them unable to offer realistic and diverse data needed by\nvarious application users. In this work, we study trajectory-level data\ngeneration for multi-human or human-robot interaction scenarios and propose a\nlearning-based automatic trajectory generation model, which we call Multi-Agent\nTRajectory generation with dIverse conteXts (MATRIX). MATRIX is capable of\ngenerating interactive human behaviors in realistic diverse contexts. We\nachieve this goal by modeling the explicit and interpretable objectives so that\nMATRIX can generate human motions based on diverse destinations and\nheterogeneous behaviors. We carried out extensive comparison and ablation\nstudies to illustrate the effectiveness of our approach across various metrics.\nWe also presented experiments that demonstrate the capability of MATRIX to\nserve as data augmentation for imitation-based motion planning.",
      "tldr_zh": "这篇论文提出了 MATRIX，一种基于学习的多代理轨迹生成模型，旨在解决数据驱动方法在建模复杂人类行为和人机交互时的数据收集难题。MATRIX 通过建模显式可解释的目标（如多样目的地和异质行为），能够自动生成真实多样的交互轨迹。实验结果显示，该模型在各种指标上表现出色，并可作为数据增强工具，用于基于模仿的运动规划。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE International Conference on Robotics and Automation (ICRA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.06041v1",
      "published_date": "2024-03-09 23:28:54 UTC",
      "updated_date": "2024-03-09 23:28:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:54:03.370110"
    },
    {
      "arxiv_id": "2405.00688v1",
      "title": "Understanding Social Perception, Interactions, and Safety Aspects of Sidewalk Delivery Robots Using Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Du",
        "Tho V. Le"
      ],
      "abstract": "This article presents a comprehensive sentiment analysis (SA) of comments on\nYouTube videos related to Sidewalk Delivery Robots (SDRs). We manually\nannotated the collected YouTube comments with three sentiment labels: negative\n(0), positive (1), and neutral (2). We then constructed models for text\nsentiment classification and tested the models' performance on both binary and\nternary classification tasks in terms of accuracy, precision, recall, and F1\nscore. Our results indicate that, in binary classification tasks, the Support\nVector Machine (SVM) model using Term Frequency-Inverse Document Frequency\n(TF-IDF) and N-gram get the highest accuracy. In ternary classification tasks,\nthe model using Bidirectional Encoder Representations from Transformers (BERT),\nLong Short-Term Memory Networks (LSTM) and Gated Recurrent Unit (GRU)\nsignificantly outperforms other machine learning models, achieving an accuracy,\nprecision, recall, and F1 score of 0.78. Additionally, we employ the Latent\nDirichlet Allocation model to generate 10 topics from the comments to explore\nthe public's underlying views on SDRs. Drawing from these findings, we propose\ntargeted recommendations for shaping future policies concerning SDRs. This work\nprovides valuable insights for stakeholders in the SDR sector regarding social\nperception, interaction, and safety.",
      "tldr_zh": "本研究通过情感分析（Sentiment Analysis）对YouTube评论进行分析，旨在理解人行道交付机器人（Sidewalk Delivery Robots, SDRs）的社会认知、互动和安全方面。研究者手动标注评论为负面（0）、正面（1）和中性（2），并构建了机器学习模型进行文本分类；在二元分类任务中，Support Vector Machine (SVM)结合Term Frequency-Inverse Document Frequency (TF-IDF)和N-gram取得了最高准确率，而在三元分类任务中，Bidirectional Encoder Representations from Transformers (BERT)、Long Short-Term Memory Networks (LSTM)和Gated Recurrent Unit (GRU)模型的准确率、精确率、召回率和F1分数均达0.78。使用Latent Dirichlet Allocation (LDA)模型从评论中提取10个主题，揭示公众观点后，论文提出针对SDRs的未来政策推荐，为相关利益相关者提供社会感知和安全洞见。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "34 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.00688v1",
      "published_date": "2024-03-09 23:28:01 UTC",
      "updated_date": "2024-03-09 23:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:54:19.350926"
    },
    {
      "arxiv_id": "2403.06039v1",
      "title": "A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Lyu",
        "He Zhang",
        "Shuo Niu",
        "Jie Cai"
      ],
      "abstract": "Content creators increasingly utilize generative artificial intelligence\n(Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging\nsites to produce imaginative images, AI-generated videos, and articles using\nLarge Language Models (LLMs). Despite its growing popularity, there remains an\nunderexplored area concerning the specific domains where AI-generated content\nis being applied, and the methodologies content creators employ with Gen-AI\ntools during the creation process. This study initially explores this emerging\narea through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI\nusage. Our research focuses on identifying the content domains, the variety of\ntools used, the activities performed, and the nature of the final products\ngenerated by Gen-AI in the context of user-generated content.",
      "tldr_zh": "本研究初步探讨了YouTubers在内容创作中使用生成式人工智能(Gen-AI)的应用情况，针对其在图像、视频和文章生成中的流行趋势，以及现有研究中对具体领域和方法的缺失。研究者通过对68个YouTube视频进行定性分析，识别了Gen-AI的应用领域、使用的工具种类（如Large Language Models (LLMs)）、进行的活动以及生成的最终产品性质。结果为理解用户生成内容中的Gen-AI使用提供了初步洞见，有助于进一步探索其影响和最佳实践。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at CHI LBW 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.06039v1",
      "published_date": "2024-03-09 23:22:56 UTC",
      "updated_date": "2024-03-09 23:22:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:54:27.444367"
    },
    {
      "arxiv_id": "2403.06031v1",
      "title": "FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition",
      "title_zh": "FairTargetSim：一种用于理解和解释目标变量定义公平性影响的交互式模拟器",
      "authors": [
        "Dalia Gala",
        "Milo Phillips-Brown",
        "Naman Goel",
        "Carinal Prunkl",
        "Laura Alvarez Jubete",
        "medb corcoran",
        "Ray Eitel-Porter"
      ],
      "abstract": "Machine learning requires defining one's target variable for predictions or\ndecisions, a process that can have profound implications on fairness: biases\nare often encoded in target variable definition itself, before any data\ncollection or training. We present an interactive simulator, FairTargetSim\n(FTS), that illustrates how target variable definition impacts fairness. FTS is\na valuable tool for algorithm developers, researchers, and non-technical\nstakeholders. FTS uses a case study of algorithmic hiring, using real-world\ndata and user-defined target variables. FTS is open-source and available at:\nhttp://tinyurl.com/ftsinterface. The video accompanying this paper is here:\nhttp://tinyurl.com/ijcaifts.",
      "tldr_zh": "该研究探讨了机器学习中目标变量（target variable）的定义如何在数据收集或训练前就引入公平性偏见，并提出 FairTargetSim (FTS)，一个交互式模拟器，用于理解和解释这些影响。FTS 以算法招聘为案例研究，利用真实数据和用户自定义的目标变量，允许算法开发者、研究人员和非技术利益相关者直观地观察公平性问题。该工具是开源的，并提供在线界面和配套视频，支持进一步的应用和验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06031v1",
      "published_date": "2024-03-09 22:41:33 UTC",
      "updated_date": "2024-03-09 22:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:54:38.465873"
    },
    {
      "arxiv_id": "2403.06026v2",
      "title": "Towards a Generic Representation of Combinatorial Problems for Learning-Based Approaches",
      "title_zh": "面向基于学习方法的组合问题通用表示",
      "authors": [
        "Léo Boisvert",
        "Hélène Verhaeghe",
        "Quentin Cappart"
      ],
      "abstract": "In recent years, there has been a growing interest in using learning-based\napproaches for solving combinatorial problems, either in an end-to-end manner\nor in conjunction with traditional optimization algorithms. In both scenarios,\nthe challenge lies in encoding the targeted combinatorial problems into a\nstructure compatible with the learning algorithm. Many existing works have\nproposed problem-specific representations, often in the form of a graph, to\nleverage the advantages of \\textit{graph neural networks}. However, these\napproaches lack generality, as the representation cannot be easily transferred\nfrom one combinatorial problem to another one. While some attempts have been\nmade to bridge this gap, they still offer a partial generality only. In\nresponse to this challenge, this paper advocates for progress toward a fully\ngeneric representation of combinatorial problems for learning-based approaches.\nThe approach we propose involves constructing a graph by breaking down any\nconstraint of a combinatorial problem into an abstract syntax tree and\nexpressing relationships (e.g., a variable involved in a constraint) through\nthe edges. Furthermore, we introduce a graph neural network architecture\ncapable of efficiently learning from this representation. The tool provided\noperates on combinatorial problems expressed in the XCSP3 format, handling all\nthe constraints available in the 2023 mini-track competition. Experimental\nresults on four combinatorial problems demonstrate that our architecture\nachieves performance comparable to dedicated architectures while maintaining\ngenerality. Our code and trained models are publicly available at\n\\url{https://github.com/corail-research/learning-generic-csp}.",
      "tldr_zh": "这篇论文针对学习-based 方法解决组合问题（combinatorial problems）的编码挑战，提出了一种通用的表示方法，以克服现有问题特定表示（如基于图神经 networks, graph neural networks）的局限性。方法包括将任何约束分解为抽象语法树（abstract syntax tree），并通过边表示关系（如变量与约束的关联），构建一个通用图结构。作者引入了一个图神经网络架构，能够高效从这种表示中学习，并支持 XCSP3 格式的所有约束。实验在四个组合问题上显示，该架构的性能与专用架构相当，同时保持通用性，代码和模型已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06026v2",
      "published_date": "2024-03-09 22:28:46 UTC",
      "updated_date": "2024-03-13 00:09:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:54:52.792732"
    },
    {
      "arxiv_id": "2403.06025v3",
      "title": "CarbonNet: How Computer Vision Plays a Role in Climate Change? Application: Learning Geomechanics from Subsurface Geometry of CCS to Mitigate Global Warming",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Chen",
        "Yunan Li",
        "Yuan Tian"
      ],
      "abstract": "We introduce a new approach using computer vision to predict the land surface\ndisplacement from subsurface geometry images for Carbon Capture and\nSequestration (CCS). CCS has been proved to be a key component for a carbon\nneutral society. However, scientists see there are challenges along the way\nincluding the high computational cost due to the large model scale and\nlimitations to generalize a pre-trained model with complex physics. We tackle\nthose challenges by training models directly from the subsurface geometry\nimages. The goal is to understand the respons of land surface displacement due\nto carbon injection and utilize our trained models to inform decision making in\nCCS projects.\n  We implement multiple models (CNN, ResNet, and ResNetUNet) for static\nmechanics problem, which is a image prediction problem. Next, we use the LSTM\nand transformer for transient mechanics scenario, which is a video prediction\nproblem. It shows ResNetUNet outperforms the others thanks to its architecture\nin static mechanics problem, and LSTM shows comparable performance to\ntransformer in transient problem. This report proceeds by outlining our dataset\nin detail followed by model descriptions in method section. Result and\ndiscussion state the key learning, observations, and conclusion with future\nwork rounds out the paper.",
      "tldr_zh": "本研究提出 CarbonNet 方法，利用计算机视觉从 CCS（Carbon Capture and Sequestration）地下几何图像预测土地表面位移，以缓解全球变暖带来的挑战，并解决传统模型的高计算成本和泛化问题。方法包括训练 CNN、ResNet 和 ResNetUNet 用于静态力学图像预测，以及 LSTM 和 Transformer 用于瞬态力学视频预测。结果表明，ResNetUNet 在静态问题中优于其他模型，而 LSTM 与 Transformer 在瞬态问题中性能相当，为 CCS 项目决策提供宝贵信息。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06025v3",
      "published_date": "2024-03-09 22:25:14 UTC",
      "updated_date": "2024-03-19 05:58:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:55:04.864765"
    },
    {
      "arxiv_id": "2403.06018v1",
      "title": "Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Toukmaji"
      ],
      "abstract": "Large pre-trained language models (PLMs) are at the forefront of advances in\nNatural Language Processing. One widespread use case of PLMs is \"prompting\" -\nor in-context learning - where a user provides a description of a task and some\ncompleted examples of the task to a PLM as context before prompting the PLM to\nperform the task on a new example. Only the largest, most capable PLMs are able\nto perform in-context learning effectively, and these models are typically\ntrained with a predominantly English corpus, leaving all other languages\nbehind. The data limitations in most languages preclude the training of\nlanguage-specific PLMs capable of prompting. Albeit the surge in work of\nprompting settings, it is still unclear how PLMs should be adapted\ncross-lingually specifically for prompting. We evaluate the possible methods to\nadapt LLaMa, a 7B parameter open-source PLM mainly trained in English, for\nprompting in low-resource languages, namely for Kinyarwanda, Hausa, and\nLuganda. We consider three methods: few-shot prompting (prompt),\nlanguage-adaptive fine-tuning (LAFT), and neural machine translation\n(translate), and evaluate on abstractive summarization, multi-class topic\nclassification, and named-entity recognition. Although LAFT carries the\ngreatest compute cost and intuitively should lead to the best results, our\nexperiments exhibit that LAFT is only occasionally the optimal choice for\nadapting PLMs for prompting. Rather, the translate and prompt settings are a\ncompute-efficient and cost-effective method of few-shot prompting for the\nselected low-resource languages. We find that the results are task and language\ndependent but find that the prompting method is the best on average across all\ntasks and languages. Results show that the prompt setting performs better than\nboth translating and LAFT with statistical significance for all shots when\naggregated across all tasks and languages.",
      "tldr_zh": "本研究探讨了如何将大型预训练语言模型 (PLMs) 适应低资源语言进行提示 (prompting)，以解决这些模型主要基于英语训练导致的跨语言性能问题。研究者评估了三种方法——few-shot prompting (prompt)、language-adaptive fine-tuning (LAFT) 和 neural machine translation (translate)—在 Kinyarwanda、Hausa 和 Luganda 等语言上的表现，针对抽象摘要 (abstractive summarization)、多类主题分类 (multi-class topic classification) 和命名实体识别 (named-entity recognition) 等任务。结果显示，few-shot prompting 方法在计算效率和整体性能上优于 LAFT 和 translate，且在所有任务和语言的平均表现中统计显著地更好，从而为低资源语言的 PLMs 提示提供了高效的跨语言转移策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "47 pages, 26 figures; a thesis submitted in partial satisfaction of\n  the requirements for the degree of Bachelor of Science in Computer Science at\n  the University of California - Santa Cruz",
      "pdf_url": "http://arxiv.org/pdf/2403.06018v1",
      "published_date": "2024-03-09 21:36:13 UTC",
      "updated_date": "2024-03-09 21:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:55:15.980158"
    },
    {
      "arxiv_id": "2403.06014v1",
      "title": "Hard-label based Small Query Black-box Adversarial Attack",
      "title_zh": "基于硬标签的小查询黑盒对抗攻击",
      "authors": [
        "Jeonghwan Park",
        "Paul Miller",
        "Niall McLaughlin"
      ],
      "abstract": "We consider the hard label based black box adversarial attack setting which\nsolely observes predicted classes from the target model. Most of the attack\nmethods in this setting suffer from impractical number of queries required to\nachieve a successful attack. One approach to tackle this drawback is utilising\nthe adversarial transferability between white box surrogate models and black\nbox target model. However, the majority of the methods adopting this approach\nare soft label based to take the full advantage of zeroth order optimisation.\nUnlike mainstream methods, we propose a new practical setting of hard label\nbased attack with an optimisation process guided by a pretrained surrogate\nmodel. Experiments show the proposed method significantly improves the query\nefficiency of the hard label based black-box attack across various target model\narchitectures. We find the proposed method achieves approximately 5 times\nhigher attack success rate compared to the benchmarks, especially at the small\nquery budgets as 100 and 250.",
      "tldr_zh": "本文提出了一种基于硬-label的低查询预算黑-box对抗攻击方法，通过预训练的代理模型（surrogate model）指导优化过程，以解决现有方法查询数量过多的问题。该方法利用对抗转移性（adversarial transferability），在硬-label设置下显著提升攻击效率。实验结果显示，与基准方法相比，该方法在各种目标模型架构上将攻击成功率提高了约5倍，尤其在小查询预算（如100和250次）时。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06014v1",
      "published_date": "2024-03-09 21:26:22 UTC",
      "updated_date": "2024-03-09 21:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:55:27.295825"
    },
    {
      "arxiv_id": "2403.06003v1",
      "title": "A Generalized Acquisition Function for Preference-based Reward Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Evan Ellis",
        "Gaurav R. Ghosal",
        "Stuart J. Russell",
        "Anca Dragan",
        "Erdem Bıyık"
      ],
      "abstract": "Preference-based reward learning is a popular technique for teaching robots\nand autonomous systems how a human user wants them to perform a task. Previous\nworks have shown that actively synthesizing preference queries to maximize\ninformation gain about the reward function parameters improves data efficiency.\nThe information gain criterion focuses on precisely identifying all parameters\nof the reward function. This can potentially be wasteful as many parameters may\nresult in the same reward, and many rewards may result in the same behavior in\nthe downstream tasks. Instead, we show that it is possible to optimize for\nlearning the reward function up to a behavioral equivalence class, such as\ninducing the same ranking over behaviors, distribution over choices, or other\nrelated definitions of what makes two rewards similar. We introduce a tractable\nframework that can capture such definitions of similarity. Our experiments in a\nsynthetic environment, an assistive robotics environment with domain transfer,\nand a natural language processing problem with real datasets demonstrate the\nsuperior performance of our querying method over the state-of-the-art\ninformation gain method.",
      "tldr_zh": "这篇论文提出了一种通用的获取函数(Generalized Acquisition Function)，用于偏好-based 奖励学习，以优化查询策略，使其专注于学习奖励函数直到行为等价类，例如导致相同行为排名或选择分布，从而提高数据效率。不同于传统的基于信息增益(Information Gain)方法，该框架通过一个可处理的框架捕捉奖励相似性定义，避免不必要的参数精确化。在合成环境、辅助机器人环境（包括领域转移）和自然语言处理任务的实验中，该方法展示了比现有状态-of-the-art 信息增益方法更优越的性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06003v1",
      "published_date": "2024-03-09 20:32:17 UTC",
      "updated_date": "2024-03-09 20:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:55:39.616618"
    },
    {
      "arxiv_id": "2403.05996v3",
      "title": "Dissecting Deep RL with High Update Ratios: Combatting Value Divergence",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel Hussing",
        "Claas Voelcker",
        "Igor Gilitschenski",
        "Amir-massoud Farahmand",
        "Eric Eaton"
      ],
      "abstract": "We show that deep reinforcement learning algorithms can retain their ability\nto learn without resetting network parameters in settings where the number of\ngradient updates greatly exceeds the number of environment samples by\ncombatting value function divergence. Under large update-to-data ratios, a\nrecent study by Nikishin et al. (2022) suggested the emergence of a primacy\nbias, in which agents overfit early interactions and downplay later experience,\nimpairing their ability to learn. In this work, we investigate the phenomena\nleading to the primacy bias. We inspect the early stages of training that were\nconjectured to cause the failure to learn and find that one fundamental\nchallenge is a long-standing acquaintance: value function divergence.\nOverinflated Q-values are found not only on out-of-distribution but also\nin-distribution data and can be linked to overestimation on unseen action\nprediction propelled by optimizer momentum. We employ a simple unit-ball\nnormalization that enables learning under large update ratios, show its\nefficacy on the widely used dm_control suite, and obtain strong performance on\nthe challenging dog tasks, competitive with model-based approaches. Our results\nquestion, in parts, the prior explanation for sub-optimal learning due to\noverfitting early data.",
      "tldr_zh": "本研究探讨了在高更新比率（High Update Ratios）下，深度强化学习（Deep RL）算法如何通过对抗价值函数发散（Value Divergence）来维持学习能力，而无需重置网络参数。作者分析了Nikishin et al. (2022)提出的primacy bias问题，发现其根源在于Q-values的过度膨胀，尤其与优化器动量（Optimizer Momentum）相关的未见动作预测过估计有关。针对此，他们提出了一种简单的单位球归一化（Unit-Ball Normalization）方法，在dm_control套件上实现了有效学习，并在challenging dog tasks上取得了与基于模型的方法相媲美的性能。这些结果部分质疑了先前将子优学习归因于过度拟合早期数据的解释。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a conference paper at the First Reinforcement Learning\n  Conference (RLC)",
      "pdf_url": "http://arxiv.org/pdf/2403.05996v3",
      "published_date": "2024-03-09 19:56:40 UTC",
      "updated_date": "2024-08-05 11:55:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:55:52.000043"
    },
    {
      "arxiv_id": "2403.05973v1",
      "title": "Calibrating Large Language Models Using Their Generations Only",
      "title_zh": "翻译失败",
      "authors": [
        "Dennis Ulmer",
        "Martin Gubri",
        "Hwaran Lee",
        "Sangdoo Yun",
        "Seong Joon Oh"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in user-facing\napplications, building trust and maintaining safety by accurately quantifying a\nmodel's confidence in its prediction becomes even more important. However,\nfinding effective ways to calibrate LLMs - especially when the only interface\nto the models is their generated text - remains a challenge. We propose APRICOT\n(auxiliary prediction of confidence targets): A method to set confidence\ntargets and train an additional model that predicts an LLM's confidence based\non its textual input and output alone. This approach has several advantages: It\nis conceptually simple, does not require access to the target model beyond its\noutput, does not interfere with the language generation, and has a multitude of\npotential usages, for instance by verbalizing the predicted confidence or\nadjusting the given answer based on the confidence. We show how our approach\nperforms competitively in terms of calibration error for white-box and\nblack-box LLMs on closed-book question-answering to detect incorrect LLM\nanswers.",
      "tldr_zh": "该研究提出了一种名为 APRICOT 的方法，用于校准大语言模型（LLMs）的置信度，仅基于模型的生成文本，而无需访问其内部结构。APRICOT 通过训练一个额外模型来预测 LLMs 的置信度，利用输入和输出文本作为依据，从而实现对模型预测的量化评估。该方法优势明显，包括简单性、不干扰语言生成，以及多种应用潜力，如根据置信度调整答案或口头表达不确定性。在封闭式问答任务中，实验结果显示，APRICOT 在白盒和黑盒 LLMs 上表现出色的校准错误率，能够有效检测错误答案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05973v1",
      "published_date": "2024-03-09 17:46:24 UTC",
      "updated_date": "2024-03-09 17:46:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:56:04.545822"
    },
    {
      "arxiv_id": "2403.07017v1",
      "title": "Mathematics of multi-agent learning systems at the interface of game theory and artificial intelligence",
      "title_zh": "多智能体",
      "authors": [
        "Long Wang",
        "Feng Fu",
        "Xingru Chen"
      ],
      "abstract": "Evolutionary Game Theory (EGT) and Artificial Intelligence (AI) are two\nfields that, at first glance, might seem distinct, but they have notable\nconnections and intersections. The former focuses on the evolution of behaviors\n(or strategies) in a population, where individuals interact with others and\nupdate their strategies based on imitation (or social learning). The more\nsuccessful a strategy is, the more prevalent it becomes over time. The latter,\nmeanwhile, is centered on machine learning algorithms and (deep) neural\nnetworks. It is often from a single-agent perspective but increasingly involves\nmulti-agent environments, in which intelligent agents adjust their strategies\nbased on feedback and experience, somewhat akin to the evolutionary process yet\ndistinct in their self-learning capacities. In light of the key components\nnecessary to address real-world problems, including (i) learning and\nadaptation, (ii) cooperation and competition, (iii) robustness and stability,\nand altogether (iv) population dynamics of individual agents whose strategies\nevolve, the cross-fertilization of ideas between both fields will contribute to\nthe advancement of mathematics of multi-agent learning systems, in particular,\nto the nascent domain of ``collective cooperative intelligence'' bridging\nevolutionary dynamics and multi-agent reinforcement learning.",
      "tldr_zh": "这篇论文探讨了进化博弈论 (EGT) 与人工智能 (AI) 在多代理学习系统中的交叉点，强调了这两个领域的互补性。EGT 关注个体通过模仿和社会学习在种群中演化策略，而 AI 则涉及机器学习算法和神经网络，特别是多代理环境中的自学习和策略调整。论文指出，这种交叉可以推进多代理系统的数学发展，尤其在学习适应、合作竞争、鲁棒性和稳定性等领域，推动“集体合作智能” (collective cooperative intelligence) 的兴起，桥接进化动态和多代理强化学习 (multi-agent reinforcement learning)。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.07017v1",
      "published_date": "2024-03-09 17:36:54 UTC",
      "updated_date": "2024-03-09 17:36:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:56:16.132045"
    },
    {
      "arxiv_id": "2403.05950v2",
      "title": "Classifying Objects in 3D Point Clouds Using Recurrent Neural Network: A GRU LSTM Hybrid Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Ramin Mousa",
        "Mitra Khezli",
        "Mohamadreza Azadi",
        "Vahid Nikoofard",
        "Saba Hesaraki"
      ],
      "abstract": "Accurate classification of objects in 3D point clouds is a significant\nproblem in several applications, such as autonomous navigation and\naugmented/virtual reality scenarios, which has become a research hot spot. In\nthis paper, we presented a deep learning strategy for 3D object classification\nin augmented reality. The proposed approach is a combination of the GRU and\nLSTM. LSTM networks learn longer dependencies well, but due to the number of\ngates, it takes longer to train; on the other hand, GRU networks have a weaker\nperformance than LSTM, but their training speed is much higher than GRU, which\nis The speed is due to its fewer gates. The proposed approach used the\ncombination of speed and accuracy of these two networks. The proposed approach\nachieved an accuracy of 0.99 in the 4,499,0641 points dataset, which includes\neight classes (unlabeled, man-made terrain, natural terrain, high vegetation,\nlow vegetation, buildings, hardscape, scanning artifacts, cars). Meanwhile, the\ntraditional machine learning approaches could achieve a maximum accuracy of\n0.9489 in the best case. Keywords: Point Cloud Classification, Virtual Reality,\nHybrid Model, GRULSTM, GRU, LSTM",
      "tldr_zh": "本论文提出了一种结合GRU和LSTM的混合深度学习模型，用于3D点云中对象的分类问题，以支持自主导航和增强/虚拟现实应用。相比LSTM的学习长依赖性但训练缓慢，GRU的训练速度更快但性能稍弱，该混合方法（GRULSTM）平衡了二者的优势，提升了分类效率和准确性。在包含八个类别的4,499,0641点数据集上，该方法实现了0.99的准确率，显著高于传统机器学习方法的最高0.9489。总的来说，此创新为Point Cloud Classification提供了更高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05950v2",
      "published_date": "2024-03-09 16:05:31 UTC",
      "updated_date": "2024-03-28 17:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:56:28.224960"
    },
    {
      "arxiv_id": "2403.05932v1",
      "title": "Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Roi Ronen",
        "Ilan Koren",
        "Aviad Levis",
        "Eshkol Eytan",
        "Vadim Holodovsky",
        "Yoav Y. Schechner"
      ],
      "abstract": "Significant uncertainty in climate prediction and cloud physics is tied to\nobservational gaps relating to shallow scattered clouds. Addressing these\nchallenges requires remote sensing of their three-dimensional (3D)\nheterogeneous volumetric scattering content. This calls for passive scattering\ncomputed tomography (CT). We design a learning-based model (ProbCT) to achieve\nCT of such clouds, based on noisy multi-view spaceborne images. ProbCT infers -\nfor the first time - the posterior probability distribution of the\nheterogeneous extinction coefficient, per 3D location. This yields arbitrary\nvaluable statistics, e.g., the 3D field of the most probable extinction and its\nuncertainty. ProbCT uses a neural-field representation, making essentially\nreal-time inference. ProbCT undergoes supervised training by a new labeled\nmulti-class database of physics-based volumetric fields of clouds and their\ncorresponding images. To improve out-of-distribution inference, we incorporate\nself-supervised learning through differential rendering. We demonstrate the\napproach in simulations and on real-world data, and indicate the relevance of\n3D recovery and uncertainty to precipitation and renewable energy.",
      "tldr_zh": "该研究针对气候预测中浅层散射云的观测缺口，提出了一种基于学习的模型ProbCT，用于从噪声多视图空间图像中恢复云的3D异构体积散射内容及其不确定性。ProbCT首次推断异构消光系数的后验概率分布，允许提取如最可能消光场和不确定性的统计数据，并采用neural-field表示实现实时推理。模型通过一个新的标记多类数据库进行监督训练，并结合自监督学习和差分渲染来提升分布外推理性能；在模拟和真实数据上验证后，展示了其在降水和可再生能源分析中的潜在应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05932v1",
      "published_date": "2024-03-09 14:57:03 UTC",
      "updated_date": "2024-03-09 14:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:56:41.124674"
    },
    {
      "arxiv_id": "2403.05921v2",
      "title": "OntoChat: a Framework for Conversational Ontology Engineering using Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bohui Zhang",
        "Valentina Anita Carriero",
        "Katrin Schreiberhuber",
        "Stefani Tsaneva",
        "Lucía Sánchez González",
        "Jongmo Kim",
        "Jacopo de Berardinis"
      ],
      "abstract": "Ontology engineering (OE) in large projects poses a number of challenges\narising from the heterogeneous backgrounds of the various stakeholders, domain\nexperts, and their complex interactions with ontology designers. This\nmulti-party interaction often creates systematic ambiguities and biases from\nthe elicitation of ontology requirements, which directly affect the design,\nevaluation and may jeopardise the target reuse. Meanwhile, current OE\nmethodologies strongly rely on manual activities (e.g., interviews, discussion\npages). After collecting evidence on the most crucial OE activities, we\nintroduce \\textbf{OntoChat}, a framework for conversational ontology\nengineering that supports requirement elicitation, analysis, and testing. By\ninteracting with a conversational agent, users can steer the creation of user\nstories and the extraction of competency questions, while receiving\ncomputational support to analyse the overall requirements and test early\nversions of the resulting ontologies. We evaluate OntoChat by replicating the\nengineering of the Music Meta Ontology, and collecting preliminary metrics on\nthe effectiveness of each component from users. We release all code at\nhttps://github.com/King-s-Knowledge-Graph-Lab/OntoChat.",
      "tldr_zh": "该研究针对本体工程（Ontology Engineering, OE）中的挑战，如利益相关者背景多样化导致的需求歧义和手动依赖问题，提出了一种基于语言模型的框架OntoChat。OntoChat通过对话代理支持需求elicitation（收集）、analysis（分析）和testing（测试），允许用户创建用户故事、提取competency questions（能力问题），并提供计算支持来分析整体需求和测试初步本体。实验通过复制Music Meta Ontology的工程过程进行评估，展示了框架组件的有效性，并开源了代码以促进进一步应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ESWC 2024 Special Track on Large Language Models for Knowledge\n  Engineering",
      "pdf_url": "http://arxiv.org/pdf/2403.05921v2",
      "published_date": "2024-03-09 14:04:06 UTC",
      "updated_date": "2024-04-26 10:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:56:52.779561"
    },
    {
      "arxiv_id": "2403.05920v1",
      "title": "High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models",
      "title_zh": "翻译失败",
      "authors": [
        "Syed I. Munzir",
        "Daniel B. Hier",
        "Michael D. Carrithers"
      ],
      "abstract": "Deep phenotyping is the detailed description of patient signs and symptoms\nusing concepts from an ontology. The deep phenotyping of the numerous physician\nnotes in electronic health records requires high throughput methods. Over the\npast thirty years, progress toward making high throughput phenotyping feasible.\nIn this study, we demonstrate that a large language model and a hybrid NLP\nmodel (combining word vectors with a machine learning classifier) can perform\nhigh throughput phenotyping on physician notes with high accuracy. Large\nlanguage models will likely emerge as the preferred method for high throughput\ndeep phenotyping of physician notes.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型(Large Language Model)和混合 NLP 模型(Hybrid NLP Model)对医生笔记进行高通量表型学(High Throughput Phenotyping)，以详细描述患者体征和症状。研究结果显示，这些模型能以高准确性处理电子健康记录中的大量笔记，证明了其在深度表型学(Deep Phenotyping)中的有效性。作者预测，大型语言模型将逐渐成为这一领域的首选方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2; J.2"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to IEEE EMBS Summer conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.05920v1",
      "published_date": "2024-03-09 14:02:59 UTC",
      "updated_date": "2024-03-09 14:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:57:04.769553"
    },
    {
      "arxiv_id": "2403.05918v2",
      "title": "SEMRes-DDPM: Residual Network Based Diffusion Modelling Applied to Imbalanced Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Zheng",
        "Yang Yang",
        "Zhi-Hang Zhao",
        "Shan-Chao Gan",
        "Yang Chen",
        "Si-Kai Ni",
        "Yang Lu"
      ],
      "abstract": "In the field of data mining and machine learning, commonly used\nclassification models cannot effectively learn in unbalanced data. In order to\nbalance the data distribution before model training, oversampling methods are\noften used to generate data for a small number of classes to solve the problem\nof classifying unbalanced data. Most of the classical oversampling methods are\nbased on the SMOTE technique, which only focuses on the local information of\nthe data, and therefore the generated data may have the problem of not being\nrealistic enough. In the current oversampling methods based on generative\nnetworks, the methods based on GANs can capture the true distribution of data,\nbut there is the problem of pattern collapse and training instability in\ntraining; in the oversampling methods based on denoising diffusion probability\nmodels, the neural network of the inverse diffusion process using the U-Net is\nnot applicable to tabular data, and although the MLP can be used to replace the\nU-Net, the problem exists due to the simplicity of the structure and the poor\neffect of removing noise. problem of poor noise removal. In order to overcome\nthe above problems, we propose a novel oversampling method SEMRes-DDPM.In the\nSEMRes-DDPM backward diffusion process, a new neural network structure\nSEMST-ResNet is used, which is suitable for tabular data and has good noise\nremoval effect, and it can generate tabular data with higher quality.\nExperiments show that the SEMResNet network removes noise better than MLP;\nSEMRes-DDPM generates data distributions that are closer to the real data\ndistributions than TabDDPM with CWGAN-GP; on 20 real unbalanced tabular\ndatasets with 9 classification models, SEMRes-DDPM improves the quality of the\ngenerated tabular data in terms of three evaluation metrics (F1, G-mean, AUC)\nwith better classification performance than other SOTA oversampling methods.",
      "tldr_zh": "这篇论文针对不平衡数据分类问题，提出了一种新型 oversampling 方法 SEMRes-DDPM，该方法基于 Residual Network 的扩散模型（Diffusion Modelling），使用新的神经网络结构 SEMST-ResNet 来优化反向扩散过程，提高了表格数据的生成质量和噪声去除效果。相比传统方法如 SMOTE 和基于 GANs 的技术，SEMRes-DDPM 解决了模式崩溃、训练不稳定以及对表格数据的适用性问题。实验在 20 个真实不平衡表格数据集上表明，SEMRes-DDPM 生成的数据分布更接近真实分布，并在 F1、G-mean 和 AUC 等评估指标上优于 SOTA 方法，提升了分类模型的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "None",
      "pdf_url": "http://arxiv.org/pdf/2403.05918v2",
      "published_date": "2024-03-09 14:01:04 UTC",
      "updated_date": "2024-03-12 02:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:57:17.905959"
    },
    {
      "arxiv_id": "2403.05916v2",
      "title": "GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual Affective Computing",
      "title_zh": "GPT 作为",
      "authors": [
        "Hao Lu",
        "Xuesong Niu",
        "Jiyao Wang",
        "Yin Wang",
        "Qingyong Hu",
        "Jiaqi Tang",
        "Yuting Zhang",
        "Kaishen Yuan",
        "Bin Huang",
        "Zitong Yu",
        "Dengbo He",
        "Shuiguang Deng",
        "Hao Chen",
        "Yingcong Chen",
        "Shiguang Shan"
      ],
      "abstract": "Multimodal large language models (MLLMs) are designed to process and\nintegrate information from multiple sources, such as text, speech, images, and\nvideos. Despite its success in language understanding, it is critical to\nevaluate the performance of downstream tasks for better human-centric\napplications. This paper assesses the application of MLLMs with 5 crucial\nabilities for affective computing, spanning from visual affective tasks and\nreasoning tasks. The results show that \\gpt has high accuracy in facial action\nunit recognition and micro-expression detection while its general facial\nexpression recognition performance is not accurate. We also highlight the\nchallenges of achieving fine-grained micro-expression recognition and the\npotential for further study and demonstrate the versatility and potential of\n\\gpt for handling advanced tasks in emotion recognition and related fields by\nintegrating with task-related agents for more complex tasks, such as heart rate\nestimation through signal processing. In conclusion, this paper provides\nvaluable insights into the potential applications and challenges of MLLMs in\nhuman-centric computing. Our interesting examples are at\nhttps://github.com/EnVision-Research/GPT4Affectivity.",
      "tldr_zh": "本论文评估了GPT-4V在视觉情感计算领域的性能，针对多模态大语言模型(MLLMs)的5个关键能力，包括面部动作单位识别、微表情检测和一般面部表情识别等任务。结果显示，GPT-4V在面部动作单位识别和微表情检测方面表现出高准确性，但整体面部表情识别效果不佳，同时面临细粒度微表情识别的挑战。论文通过整合任务相关代理（如用于心率估计的信号处理），展示了MLLMs在情感识别和相关领域应用的潜力，并为人类中心计算提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05916v2",
      "published_date": "2024-03-09 13:56:25 UTC",
      "updated_date": "2024-04-10 07:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:57:30.055903"
    },
    {
      "arxiv_id": "2403.14676v1",
      "title": "Unified Uncertainty Estimation for Cognitive Diagnosis Models",
      "title_zh": "统一的认知诊断模型不确定性估计",
      "authors": [
        "Fei Wang",
        "Qi Liu",
        "Enhong Chen",
        "Chuanren Liu",
        "Zhenya Huang",
        "Jinze Wu",
        "Shijin Wang"
      ],
      "abstract": "Cognitive diagnosis models have been widely used in different areas,\nespecially intelligent education, to measure users' proficiency levels on\nknowledge concepts, based on which users can get personalized instructions. As\nthe measurement is not always reliable due to the weak links of the models and\ndata, the uncertainty of measurement also offers important information for\ndecisions. However, the research on the uncertainty estimation lags behind that\non advanced model structures for cognitive diagnosis. Existing approaches have\nlimited efficiency and leave an academic blank for sophisticated models which\nhave interaction function parameters (e.g., deep learning-based models). To\naddress these problems, we propose a unified uncertainty estimation approach\nfor a wide range of cognitive diagnosis models. Specifically, based on the idea\nof estimating the posterior distributions of cognitive diagnosis model\nparameters, we first provide a unified objective function for mini-batch based\noptimization that can be more efficiently applied to a wide range of models and\nlarge datasets. Then, we modify the reparameterization approach in order to\nadapt to parameters defined on different domains. Furthermore, we decompose the\nuncertainty of diagnostic parameters into data aspect and model aspect, which\nbetter explains the source of uncertainty. Extensive experiments demonstrate\nthat our method is effective and can provide useful insights into the\nuncertainty of cognitive diagnosis.",
      "tldr_zh": "本研究针对认知诊断模型在智能教育中评估用户知识水平时存在的测量不确定性问题，提出了一种统一的 uncertainty estimation 方法，以解决现有方法效率低下且不适用于复杂模型（如基于深度学习的模型）的问题。该方法基于估计模型参数的后验分布，设计了一个统一的 mini-batch 优化目标函数，并修改 reparameterization 技术以适应不同参数域，同时将不确定性分解为数据方面和模型方面，以更好地解释其来源。实验结果表明，该方法适用于广泛的认知诊断模型，提供有价值的不确定性洞见，并显著提升了评估的可靠性和效率。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14676v1",
      "published_date": "2024-03-09 13:48:20 UTC",
      "updated_date": "2024-03-09 13:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:57:41.187374"
    },
    {
      "arxiv_id": "2403.05911v2",
      "title": "Towards Optimizing Human-Centric Objectives in AI-Assisted Decision-Making With Offline Reinforcement Learning",
      "title_zh": "朝向使用离线强化学习优化AI辅助决策中的以人为中心目标",
      "authors": [
        "Zana Buçinca",
        "Siddharth Swaroop",
        "Amanda E. Paluch",
        "Susan A. Murphy",
        "Krzysztof Z. Gajos"
      ],
      "abstract": "Imagine if AI decision-support tools not only complemented our ability to\nmake accurate decisions, but also improved our skills, boosted collaboration,\nand elevated the joy we derive from our tasks. Despite the potential to\noptimize a broad spectrum of such human-centric objectives, the design of\ncurrent AI tools remains focused on decision accuracy alone. We propose offline\nreinforcement learning (RL) as a general approach for modeling human-AI\ndecision-making to optimize human-AI interaction for diverse objectives. RL can\noptimize such objectives by tailoring decision support, providing the right\ntype of assistance to the right person at the right time. We instantiated our\napproach with two objectives: human-AI accuracy on the decision-making task and\nhuman learning about the task and learned decision support policies from\nprevious human-AI interaction data. We compared the optimized policies against\nseveral baselines in AI-assisted decision-making. Across two experiments (N=316\nand N=964), our results demonstrated that people interacting with policies\noptimized for accuracy achieve significantly better accuracy -- and even\nhuman-AI complementarity -- compared to those interacting with any other type\nof AI support. Our results further indicated that human learning was more\ndifficult to optimize than accuracy, with participants who interacted with\nlearning-optimized policies showing significant learning improvement only at\ntimes. Our research (1) demonstrates offline RL to be a promising approach to\nmodel human-AI decision-making, leading to policies that may optimize\nhuman-centric objectives and provide novel insights about the AI-assisted\ndecision-making space, and (2) emphasizes the importance of considering\nhuman-centric objectives beyond decision accuracy in AI-assisted\ndecision-making, opening up the novel research challenge of optimizing human-AI\ninteraction for such objectives.",
      "tldr_zh": "本研究提出使用离线强化学习 (offline reinforcement learning) 来优化 AI 辅助决策中的人类中心目标，这些目标包括提升决策准确性、人类技能学习、协作和任务乐趣，而非仅关注准确性。通过从历史人类-AI 交互数据中学习决策支持策略，该方法为不同目标量身定制 AI 援助。实验结果显示，在两个研究中 (N=316 和 N=964)，与优化准确性的策略交互的用户实现了显著更高的准确性和人类-AI 互补性，而优化人类学习的策略仅在某些情况下显示出改善。该工作证明了离线 RL 在建模人类-AI 决策方面的潜力，并强调了在 AI 辅助决策中优先考虑更广泛人类中心目标的新研究挑战。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05911v2",
      "published_date": "2024-03-09 13:30:00 UTC",
      "updated_date": "2024-04-14 21:17:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:57:53.749153"
    },
    {
      "arxiv_id": "2403.08824v2",
      "title": "Computational Analysis of Stress, Depression and Engagement in Mental Health: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Puneet Kumar",
        "Alexander Vedernikov",
        "Yuwei Chen",
        "Wenming Zheng",
        "Xiaobai Li"
      ],
      "abstract": "Analysis of stress, depression and engagement is less common and more complex\nthan that of frequently discussed emotions such as happiness, sadness, fear and\nanger. The importance of these psychological states has been increasingly\nrecognized due to their implications for mental health and well-being. Stress\nand depression are interrelated and together they impact engagement in daily\ntasks, highlighting the need to explore their interplay. This survey is the\nfirst to simultaneously explore computational methods for analyzing stress,\ndepression and engagement. We present a taxonomy and timeline of the\ncomputational approaches used to analyze them and we discuss the most commonly\nused datasets and input modalities, along with the categories and generic\npipeline of these approaches. Subsequently, we describe state-of-the-art\ncomputational approaches, including a performance summary on the most commonly\nused datasets. Following this, we explore the applications of stress,\ndepression and engagement analysis, along with the associated challenges,\nlimitations and future research directions.",
      "tldr_zh": "本调查论文首次同时探讨了计算方法在分析心理健康中的stress、depression和engagement方面的应用，强调这些心理状态的复杂性及其对日常任务参与度的相互影响。论文构建了一个分类体系和时间线，涵盖了常用数据集、输入模式（如生理信号和文本数据）、通用分析流程，以及state-of-the-art方法的性能总结。最终，它讨论了这些分析的应用场景、面临的挑战（如数据隐私和准确性限制）以及未来研究方向，以推动心理健康领域的计算技术发展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "Under review in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2403.08824v2",
      "published_date": "2024-03-09 11:16:09 UTC",
      "updated_date": "2025-03-25 10:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:58:06.690074"
    },
    {
      "arxiv_id": "2403.05845v1",
      "title": "Reverse That Number! Decoding Order Matters in Arithmetic Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Zhang-Li",
        "Nianyi Lin",
        "Jifan Yu",
        "Zheyuan Zhang",
        "Zijun Yao",
        "Xiaokang Zhang",
        "Lei Hou",
        "Jing Zhang",
        "Juanzi Li"
      ],
      "abstract": "Recent advancements in pretraining have demonstrated that modern Large\nLanguage Models (LLMs) possess the capability to effectively learn arithmetic\noperations. However, despite acknowledging the significance of digit order in\narithmetic computation, current methodologies predominantly rely on sequential,\nstep-by-step approaches for teaching LLMs arithmetic, resulting in a conclusion\nwhere obtaining better performance involves fine-grained step-by-step.\nDiverging from this conventional path, our work introduces a novel strategy\nthat not only reevaluates the digit order by prioritizing output from the least\nsignificant digit but also incorporates a step-by-step methodology to\nsubstantially reduce complexity. We have developed and applied this method in a\ncomprehensive set of experiments. Compared to the previous state-of-the-art\n(SOTA) method, our findings reveal an overall improvement of in accuracy while\nrequiring only a third of the tokens typically used during training. For the\npurpose of facilitating replication and further research, we have made our code\nand dataset publicly available at\n\\url{https://anonymous.4open.science/r/RAIT-9FB7/}.",
      "tldr_zh": "本文研究发现，现有的Large Language Models (LLMs)在学习算术运算时，通常依赖顺序步进方法，导致性能提升需要更多细粒度步骤，忽略了数字顺序的重要性。作者提出一种新策略，通过优先从最低有效位（least significant digit）开始输出，并结合步进方法，显著降低了训练复杂性。与State-of-the-Art (SOTA)方法相比，实验结果显示准确率整体提升，同时只需三分之一的训练标记。该方法已公开代码和数据集，以便复制和进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05845v1",
      "published_date": "2024-03-09 09:04:53 UTC",
      "updated_date": "2024-03-09 09:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:58:18.987924"
    },
    {
      "arxiv_id": "2403.05842v3",
      "title": "TokenMark: A Modality-Agnostic Watermark for Pre-trained Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Hengyuan Xu",
        "Liyao Xiang",
        "Borui Yang",
        "Xingjun Ma",
        "Siheng Chen",
        "Baochun Li"
      ],
      "abstract": "Watermarking is a critical tool for model ownership verification. However,\nexisting watermarking techniques are often designed for specific data\nmodalities and downstream tasks, without considering the inherent architectural\nproperties of the model. This lack of generality and robustness underscores the\nneed for a more versatile watermarking approach. In this work, we investigate\nthe properties of Transformer models and propose TokenMark, a\nmodality-agnostic, robust watermarking system for pre-trained models,\nleveraging the permutation equivariance property. TokenMark embeds the\nwatermark by fine-tuning the pre-trained model on a set of specifically\npermuted data samples, resulting in a watermarked model that contains two\ndistinct sets of weights -- one for normal functionality and the other for\nwatermark extraction, the latter triggered only by permuted inputs. Extensive\nexperiments on state-of-the-art pre-trained models demonstrate that TokenMark\nsignificantly improves the robustness, efficiency, and universality of model\nwatermarking, highlighting its potential as a unified watermarking solution.",
      "tldr_zh": "本研究针对现有水印技术(modality-agnostic)的局限性，提出TokenMark，一种适用于预训练Transformer的通用鲁棒水印系统，利用permutation equivariance属性来嵌入水印。TokenMark通过在特定置换数据样本上微调预训练模型，生成两套权重：一套支持正常功能，另一套仅在置换输入时触发水印提取，从而提升了水印的隐蔽性和安全性。实验在最先进预训练模型上证明，TokenMark显著提高了水印的鲁棒性、效率和通用性，为模型所有权验证提供了一个统一的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05842v3",
      "published_date": "2024-03-09 08:54:52 UTC",
      "updated_date": "2025-04-26 08:10:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:58:32.497771"
    },
    {
      "arxiv_id": "2403.05839v2",
      "title": "Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline",
      "title_zh": "长期帧-事件视觉跟踪：基准数据集和基线",
      "authors": [
        "Xiao Wang",
        "Ju Huang",
        "Shiao Wang",
        "Chuanming Tang",
        "Bo Jiang",
        "Yonghong Tian",
        "Jin Tang",
        "Bin Luo"
      ],
      "abstract": "Current event-/frame-event based trackers undergo evaluation on short-term\ntracking datasets, however, the tracking of real-world scenarios involves\nlong-term tracking, and the performance of existing tracking algorithms in\nthese scenarios remains unclear. In this paper, we first propose a new\nlong-term and large-scale frame-event single object tracking dataset, termed\nFELT. It contains 742 videos and 1,594,474 RGB frames and event stream pairs\nand has become the largest frame-event tracking dataset to date. We re-train\nand evaluate 15 baseline trackers on our dataset for future works to compare.\nMore importantly, we find that the RGB frames and event streams are naturally\nincomplete due to the influence of challenging factors and spatially sparse\nevent flow. In response to this, we propose a novel associative memory\nTransformer network as a unified backbone by introducing modern Hopfield layers\ninto multi-head self-attention blocks to fuse both RGB and event data.\nExtensive experiments on RGB-Event (FELT), RGB-Thermal (RGBT234, LasHeR), and\nRGB-Depth (DepthTrack) datasets fully validated the effectiveness of our model.\nThe dataset and source code can be found at\n\\url{https://github.com/Event-AHU/FELT_SOT_Benchmark}.",
      "tldr_zh": "本论文提出一个新的长期帧-Event视觉追踪数据集FELT，包含742个视频和1,594,474个RGB帧与事件流对，是目前最大的Frame-Event单对象追踪数据集，用于评估现有追踪算法在真实长期场景中的性能。作者重新训练并评估了15个基线追踪器，以提供未来研究的基准。针对RGB帧和事件流的自然不完整性，该研究引入现代Hopfield layers整合到多头自注意力块中，开发了一个新型关联记忆Transformer网络，用于融合RGB和事件数据。实验在FELT、RGBT234、LasHeR和DepthTrack数据集上验证了该模型的有效性，显著提升了追踪性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "In Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2403.05839v2",
      "published_date": "2024-03-09 08:49:50 UTC",
      "updated_date": "2024-04-03 09:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:58:43.485892"
    },
    {
      "arxiv_id": "2403.05828v2",
      "title": "Multi-GPU-Enabled Hybrid Quantum-Classical Workflow in Quantum-HPC Middleware: Applications in Quantum Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Kuan-Cheng Chen",
        "Xiaoren Li",
        "Xiaotian Xu",
        "Yun-Yuan Wang",
        "Chen-Yu Liu"
      ],
      "abstract": "Achieving high-performance computation on quantum systems presents a\nformidable challenge that necessitates bridging the capabilities between\nquantum hardware and classical computing resources. This study introduces an\ninnovative distribution-aware Quantum-Classical-Quantum (QCQ) architecture,\nwhich integrates cutting-edge quantum software framework works with\nhigh-performance classical computing resources to address challenges in quantum\nsimulation for materials and condensed matter physics. At the heart of this\narchitecture is the seamless integration of VQE algorithms running on QPUs for\nefficient quantum state preparation, Tensor Network states, and QCNNs for\nclassifying quantum states on classical hardware.\n  For benchmarking quantum simulators, the QCQ architecture utilizes the\ncuQuantum SDK to leverage multi-GPU acceleration, integrated with PennyLane's\nLightning plugin, demonstrating up to tenfold increases in computational speed\nfor complex phase transition classification tasks compared to traditional\nCPU-based methods. This significant acceleration enables models such as the\ntransverse field Ising and XXZ systems to accurately predict phase transitions\nwith a 99.5% accuracy. The architecture's ability to distribute computation\nbetween QPUs and classical resources addresses critical bottlenecks in\nQuantum-HPC, paving the way for scalable quantum simulation.\n  The QCQ framework embodies a synergistic combination of quantum algorithms,\nmachine learning, and Quantum-HPC capabilities, enhancing its potential to\nprovide transformative insights into the behavior of quantum systems across\ndifferent scales. As quantum hardware continues to improve, this hybrid\ndistribution-aware framework will play a crucial role in realizing the full\npotential of quantum computing by seamlessly integrating distributed quantum\nresources with the state-of-the-art classical computing infrastructure.",
      "tldr_zh": "本研究提出了一种创新的 distribution-aware Quantum-Classical-Quantum (QCQ) 架构，旨在整合量子软件框架与高性能古典计算资源，解决量子模拟在材料和凝聚态物理领域的挑战。该架构核心包括 VQE 算法在 QPUs 上进行量子态准备、Tensor Network states 以及 QCNNs 在古典硬件上的量子态分类，并利用 cuQuantum SDK 和 PennyLane's Lightning plugin 实现多-GPU 加速，比传统 CPU 方法提升计算速度十倍。实验显示，该框架在横场 Ising 和 XXZ 系统上准确预测相变，准确率达 99.5%，有效缓解了 Quantum-HPC 中的计算瓶颈。总之，QCQ 框架通过量子算法、机器学习和 Quantum-HPC 的协同作用，推动了可扩展量子模拟的应用前景。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.AR",
        "cs.DC"
      ],
      "primary_category": "quant-ph",
      "comment": "8 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.05828v2",
      "published_date": "2024-03-09 07:38:45 UTC",
      "updated_date": "2024-03-18 08:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:58:56.231524"
    },
    {
      "arxiv_id": "2403.05814v1",
      "title": "MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yerin Hwang",
        "Yongil Kim",
        "Yunah Jang",
        "Jeesoo Bang",
        "Hyunkyung Bae",
        "Kyomin Jung"
      ],
      "abstract": "Despite advancements in on-topic dialogue systems, effectively managing topic\nshifts within dialogues remains a persistent challenge, largely attributed to\nthe limited availability of training datasets. To address this issue, we\npropose Multi-Passage to Dialogue (MP2D), a data generation framework that\nautomatically creates conversational question-answering datasets with natural\ntopic transitions. By leveraging the relationships between entities in a\nknowledge graph, MP2D maps the flow of topics within a dialogue, effectively\nmirroring the dynamics of human conversation. It retrieves relevant passages\ncorresponding to the topics and transforms them into dialogues through the\npassage-to-dialogue method. Through quantitative and qualitative experiments,\nwe demonstrate MP2D's efficacy in generating dialogue with natural topic\nshifts. Furthermore, this study introduces a novel benchmark for topic shift\ndialogues, TS-WikiDialog. Utilizing the dataset, we demonstrate that even Large\nLanguage Models (LLMs) struggle to handle topic shifts in dialogue effectively,\nand we showcase the performance improvements of models trained on datasets\ngenerated by MP2D across diverse topic shift dialogue tasks.",
      "tldr_zh": "这篇论文提出了MP2D框架，一种利用Knowledge Graphs自动生成包含自然话题转移的对话数据集的方法，以解决对话系统在话题管理上的数据不足问题。MP2D通过知识图谱中实体关系的映射来模拟对话话题流，检索相关段落并通过passage-to-dialogue技术转化为对话。实验结果显示，该框架在定量和定性评估中表现出色，并引入了新的基准TS-WikiDialog，证明了使用MP2D生成的数据集能显著提升模型在话题转移任务中的性能，即使是Large Language Models (LLMs)也存在挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.05814v1",
      "published_date": "2024-03-09 06:28:48 UTC",
      "updated_date": "2024-03-09 06:28:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:59:06.657165"
    },
    {
      "arxiv_id": "2403.05812v1",
      "title": "Algorithmic progress in language models",
      "title_zh": "语言模型中的算法进展",
      "authors": [
        "Anson Ho",
        "Tamay Besiroglu",
        "Ege Erdil",
        "David Owen",
        "Robi Rahman",
        "Zifan Carl Guo",
        "David Atkinson",
        "Neil Thompson",
        "Jaime Sevilla"
      ],
      "abstract": "We investigate the rate at which algorithms for pre-training language models\nhave improved since the advent of deep learning. Using a dataset of over 200\nlanguage model evaluations on Wikitext and Penn Treebank spanning 2012-2023, we\nfind that the compute required to reach a set performance threshold has halved\napproximately every 8 months, with a 95% confidence interval of around 5 to 14\nmonths, substantially faster than hardware gains per Moore's Law. We estimate\naugmented scaling laws, which enable us to quantify algorithmic progress and\ndetermine the relative contributions of scaling models versus innovations in\ntraining algorithms. Despite the rapid pace of algorithmic progress and the\ndevelopment of new architectures such as the transformer, our analysis reveals\nthat the increase in compute made an even larger contribution to overall\nperformance improvements over this time period. Though limited by noisy\nbenchmark data, our analysis quantifies the rapid progress in language\nmodeling, shedding light on the relative contributions from compute and\nalgorithms.",
      "tldr_zh": "本研究调查了自深度学习兴起以来，语言模型预训练算法的进步速度。使用超过200次评估数据（包括Wikitext和Penn Treebank数据集，覆盖2012-2023年），研究发现，达到特定性能阈值所需的计算资源大约每8个月减半（95%置信区间为5-14个月），远快于Moore's Law的硬件进步。研究还通过增强的scaling laws量化算法创新与模型缩放的相对贡献，结果显示计算资源的增加对整体性能提升的贡献更大。尽管受基准数据噪声的限制，此分析揭示了语言模型领域的快速进步及其驱动因素。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05812v1",
      "published_date": "2024-03-09 06:26:21 UTC",
      "updated_date": "2024-03-09 06:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:59:18.142398"
    },
    {
      "arxiv_id": "2403.05810v2",
      "title": "Recurrent Aligned Network for Generalized Pedestrian Trajectory Prediction",
      "title_zh": "用于泛化行人轨迹预测的循环对齐网络",
      "authors": [
        "Yonghao Dong",
        "Le Wang",
        "Sanping Zhou",
        "Gang Hua",
        "Changyin Sun"
      ],
      "abstract": "Pedestrian trajectory prediction is a crucial component in computer vision\nand robotics, but remains challenging due to the domain shift problem. Previous\nstudies have tried to tackle this problem by leveraging a portion of the\ntrajectory data from the target domain to adapt the model. However, such domain\nadaptation methods are impractical in real-world scenarios, as it is infeasible\nto collect trajectory data from all potential target domains. In this paper, we\nstudy a task named generalized pedestrian trajectory prediction, with the aim\nof generalizing the model to unseen domains without accessing their\ntrajectories. To tackle this task, we introduce a Recurrent Aligned\nNetwork~(RAN) to minimize the domain gap through domain alignment.\nSpecifically, we devise a recurrent alignment module to effectively align the\ntrajectory feature spaces at both time-state and time-sequence levels by the\nrecurrent alignment strategy.Furthermore, we introduce a pre-aligned\nrepresentation module to combine social interactions with the recurrent\nalignment strategy, which aims to consider social interactions during the\nalignment process instead of just target trajectories. We extensively evaluate\nour method and compare it with state-of-the-art methods on three widely used\nbenchmarks. The experimental results demonstrate the superior generalization\ncapability of our method. Our work not only fills the gap in the generalization\nsetting for practical pedestrian trajectory prediction but also sets strong\nbaselines in this field.",
      "tldr_zh": "这篇论文针对行人轨迹预测中的domain shift问题，提出generalized pedestrian trajectory prediction任务，旨在让模型泛化到未见领域，而无需访问其轨迹数据。作者引入Recurrent Aligned Network (RAN)，通过recurrent alignment module在时间状态和时间序列级别对齐轨迹特征空间，并使用pre-aligned representation module将社会互动纳入对齐过程，以提升预测准确性。实验结果显示，该方法在三个常用基准上优于最先进方法，证明了其强大的泛化能力，并为实用行人轨迹预测领域设定了强有力的基线。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05810v2",
      "published_date": "2024-03-09 06:17:09 UTC",
      "updated_date": "2024-12-21 08:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:59:32.914882"
    },
    {
      "arxiv_id": "2403.05801v1",
      "title": "Enhancing Multi-Hop Knowledge Graph Reasoning through Reward Shaping Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Li",
        "Haotian Zheng",
        "Yiping Sun",
        "Cangqing Wang",
        "Liqiang Yu",
        "Che Chang",
        "Xinyu Tian",
        "Bo Liu"
      ],
      "abstract": "In the realm of computational knowledge representation, Knowledge Graph\nReasoning (KG-R) stands at the forefront of facilitating sophisticated\ninferential capabilities across multifarious domains. The quintessence of this\nresearch elucidates the employment of reinforcement learning (RL) strategies,\nnotably the REINFORCE algorithm, to navigate the intricacies inherent in\nmulti-hop KG-R. This investigation critically addresses the prevalent\nchallenges introduced by the inherent incompleteness of Knowledge Graphs (KGs),\nwhich frequently results in erroneous inferential outcomes, manifesting as both\nfalse negatives and misleading positives. By partitioning the Unified Medical\nLanguage System (UMLS) benchmark dataset into rich and sparse subsets, we\ninvestigate the efficacy of pre-trained BERT embeddings and Prompt Learning\nmethodologies to refine the reward shaping process. This approach not only\nenhances the precision of multi-hop KG-R but also sets a new precedent for\nfuture research in the field, aiming to improve the robustness and accuracy of\nknowledge inference within complex KG frameworks. Our work contributes a novel\nperspective to the discourse on KG reasoning, offering a methodological\nadvancement that aligns with the academic rigor and scholarly aspirations of\nthe Natural journal, promising to invigorate further advancements in the realm\nof computational knowledge representation.",
      "tldr_zh": "本研究利用强化学习中的 REINFORCE 算法和奖励塑造技术，增强多跳知识图推理（KG-R），以解决知识图（KGs）不完整性导致的推理错误问题，如假阴性和假阳性。研究者将 Unified Medical Language System (UMLS) 基准数据集分为丰富和稀疏子集，并结合预训练 BERT 嵌入和 Prompt Learning 方法来优化奖励过程，从而显著提高了多跳 KG-R 的精度。总体而言，此工作为知识图推理领域提供了新的方法论视角，提升了推理的稳健性和准确性，并为未来研究设定了新标准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by the 2024 5th International Seminar on\n  Artificial Intelligence, Networking and Information Technology (AINIT 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.05801v1",
      "published_date": "2024-03-09 05:34:07 UTC",
      "updated_date": "2024-03-09 05:34:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:59:42.947733"
    },
    {
      "arxiv_id": "2403.05794v2",
      "title": "Privacy-Preserving Diffusion Model Using Homomorphic Encryption",
      "title_zh": "基于同态加密的隐私保护扩散模型",
      "authors": [
        "Yaojian Chen",
        "Qiben Yan"
      ],
      "abstract": "In this paper, we introduce a privacy-preserving stable diffusion framework\nleveraging homomorphic encryption, called HE-Diffusion, which primarily focuses\non protecting the denoising phase of the diffusion process. HE-Diffusion is a\ntailored encryption framework specifically designed to align with the unique\narchitecture of stable diffusion, ensuring both privacy and functionality. To\naddress the inherent computational challenges, we propose a novel\nmin-distortion method that enables efficient partial image encryption,\nsignificantly reducing the overhead without compromising the model's output\nquality. Furthermore, we adopt a sparse tensor representation to expedite\ncomputational operations, enhancing the overall efficiency of the\nprivacy-preserving diffusion process. We successfully implement HE-based\nprivacy-preserving stable diffusion inference. The experimental results show\nthat HE-Diffusion achieves 500 times speedup compared with the baseline method,\nand reduces time cost of the homomorphically encrypted inference to the minute\nlevel. Both the performance and accuracy of the HE-Diffusion are on par with\nthe plaintext counterpart. Our approach marks a significant step towards\nintegrating advanced cryptographic techniques with state-of-the-art generative\nmodels, paving the way for privacy-preserving and efficient image generation in\ncritical applications.",
      "tldr_zh": "本文提出了一种基于 homomorphic encryption 的隐私保护稳定扩散框架，名为 HE-Diffusion，主要针对扩散模型的去噪阶段进行保护，确保数据隐私的同时保持模型功能。框架采用创新的 min-distortion 方法实现高效的部分图像加密，以及 sparse tensor representation 来加速计算操作，从而显著降低计算开销。实验结果显示，HE-Diffusion 比基线方法快 500 倍，将加密推理时间减少到分钟级别，且其性能和准确性与明文版本相当。该方法为高级加密技术与生成模型的整合提供了关键进展，推动隐私保护图像生成在关键应用中的应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05794v2",
      "published_date": "2024-03-09 04:56:57 UTC",
      "updated_date": "2024-05-02 03:46:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T13:59:55.284727"
    },
    {
      "arxiv_id": "2403.05789v1",
      "title": "ItD: Large Language Models Can Teach Themselves Induction through Deduction",
      "title_zh": "ItD：大型语言模型可以通过演绎自我学习归纳",
      "authors": [
        "Wangtao Sun",
        "Haotian Xu",
        "Xuanqing Yu",
        "Pei Chen",
        "Shizhu He",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Although Large Language Models (LLMs) are showing impressive performance on a\nwide range of Natural Language Processing tasks, researchers have found that\nthey still have limited ability to conduct induction. Recent works mainly adopt\n``post processes'' paradigms to improve the performance of LLMs on induction\n(e.g., the hypothesis search & refinement methods), but their performance is\nstill constrained by the inherent inductive capability of the LLMs. In this\npaper, we propose a novel framework, Induction through Deduction (ItD), to\nenable the LLMs to teach themselves induction through deduction. The ItD\nframework is composed of two main components: a Deductive Data Generation\nmodule to generate induction data and a Naive Bayesian Induction module to\noptimize the fine-tuning and decoding of LLMs. Our empirical results showcase\nthe effectiveness of ItD on two induction benchmarks, achieving relative\nperformance improvement of 36% and 10% compared with previous state-of-the-art,\nrespectively. Our ablation study verifies the effectiveness of two key modules\nof ItD. We also verify the effectiveness of ItD across different LLMs and\ndeductors. The data and code of this paper can be found at\nhttps://anonymous.4open.science/r/ItD-E844.",
      "tldr_zh": "本文提出 ItD 框架，让 Large Language Models (LLMs) 通过演绎（deduction）来自学归纳推理（induction），以解决 LLMs 在归纳任务上的固有局限性。框架包括 Deductive Data Generation 模块用于生成归纳数据，以及 Naive Bayesian Induction 模块来优化 LLMs 的微调和解码过程。实验结果显示，ItD 在两个归纳基准上分别比先前最先进方法提高了 36% 和 10% 的性能。消融研究和跨不同 LLMs 及演绎器的验证进一步证实了框架的有效性和泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05789v1",
      "published_date": "2024-03-09 04:20:46 UTC",
      "updated_date": "2024-03-09 04:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:00:09.435563"
    },
    {
      "arxiv_id": "2403.05788v1",
      "title": "On the Benefits of Fine-Grained Loss Truncation: A Case Study on Factuality in Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Jaime Yu Flores",
        "Arman Cohan"
      ],
      "abstract": "Text summarization and simplification are among the most widely used\napplications of AI. However, models developed for such tasks are often prone to\nhallucination, which can result from training on unaligned data. One efficient\napproach to address this issue is Loss Truncation (LT) (Kang and Hashimoto,\n2020), an approach to modify the standard log loss to adaptively remove noisy\nexamples during training. However, we find that LT alone yields a considerable\nnumber of hallucinated entities on various datasets. We study the behavior of\nthe underlying losses between factual and non-factual examples, to understand\nand refine the performance of LT. We demonstrate that LT's performance is\nlimited when the underlying assumption that noisy targets have higher NLL loss\nis not satisfied, and find that word-level NLL among entities provides better\nsignal for distinguishing factuality. We then leverage this to propose a\nfine-grained NLL loss and fine-grained data cleaning strategies, and observe\nimprovements in hallucination reduction across some datasets. Our work is\navailable at https://https://github.com/yale-nlp/fine-grained-lt.",
      "tldr_zh": "该研究探讨了在文本摘要任务中，Loss Truncation (LT) 方法如何通过修改 log loss 来去除训练数据中的噪声样本，以减少模型的 hallucination 问题。然而，研究发现 LT 单独使用仍会导致大量幻觉实体，因为其假设噪声目标具有更高 NLL loss 不总是成立。作者分析了事实性和非事实性样本的底层损失行为，提出 fine-grained NLL loss 和细粒度数据清洗策略，从而在某些数据集上显著降低了 hallucination。该工作提供了代码实现，供进一步验证和应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.05788v1",
      "published_date": "2024-03-09 04:20:26 UTC",
      "updated_date": "2024-03-09 04:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:00:20.408225"
    },
    {
      "arxiv_id": "2403.07010v1",
      "title": "On Globular T-Spherical Fuzzy (G-TSF) Sets with Application to G-TSF Multi-Criteria Group Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Miin-Shen Yang",
        "Yasir Akhtar",
        "Mehboob Ali"
      ],
      "abstract": "In this paper, we give the concept of Globular T-Spherical Fuzzy (G-TSF) Sets\n(G-TSFSs) as an innovative extension of T-Spherical Fuzzy Sets (TSFSs) and\nCircular Spherical Fuzzy Sets (C-SFSs). G-TSFSs represent membership,\nindeterminacy, and non-membership degrees using a globular/sphere bound that\ncan offer a more accurate portrayal of vague, ambiguous, and imprecise\ninformation. By employing a structured representation of data points on a\nsphere with a specific center and radius, this model enhances decision-making\nprocesses by enabling a more comprehensive evaluation of objects within a\nflexible region. Following the newly defined G-TSFSs, we establish some basic\nset operations and introduce fundamental algebraic operations for G-TSF Values\n(G-TSFVs). These operations expand the evaluative capabilities of\ndecision-makers, facilitating more sensitive decision-making processes in a\nbroader region. To quantify a similarity measure (SM) between GTSFVs, the SM is\ndefined based on the radius of G-TSFSs. Additionally, Hamming distance and\nEuclidean distance are introduced for G-TSFSs. We also present theorems and\nexamples to elucidate computational mechanisms. Furthermore, we give the G-TSF\nWeighted Average (G-TSFWA) and G-TSF Weighted Geometric (G-TSFWG) operators.\nLeveraging our proposed SM, a Multi-Criteria Group Decision-Making (MCGDM)\nscheme for G-TSFSs, named G-TSF MCGDM (G-TSFMCGDM), is developed to address\ngroup decision-making problems. The applicability and effectiveness of the\nproposed G-TSFMCGDM method are demonstrated by applying it to solve the\nselection problem of the best venue for professional development training\nsessions in a firm. The analysis results affirm the suitability and utility of\nthe proposed method for resolving MCGDM problems, establishing its\neffectiveness in practical decision-making scenarios.",
      "tldr_zh": "本研究引入了 Globular T-Spherical Fuzzy (G-TSF) Sets 作为 T-Spherical Fuzzy Sets (TSFSs) 和 Circular Spherical Fuzzy Sets (C-SFSs) 的扩展，利用球形边界更准确地表示模糊信息中的成员度、不确定度和非成员度，从而提升决策过程的全面性。论文定义了 G-TSF Sets 的基本集合操作、代数运算、相似度测度 (SM)、Hamming 距离和 Euclidean 距离，并提出了 G-TSF Weighted Average (G-TSFWA) 和 G-TSF Weighted Geometric (G-TSFWG) 运算符，以增强决策评估能力。基于这些基础，该研究开发了 G-TSF Multi-Criteria Group Decision-Making (MCGDM) 方法，并通过一个选择企业专业发展培训场所的实际案例验证了其有效性，证明了该方法在处理模糊群决策问题时的适用性和实用价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07010v1",
      "published_date": "2024-03-09 04:19:50 UTC",
      "updated_date": "2024-03-09 04:19:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:00:33.749132"
    },
    {
      "arxiv_id": "2403.07008v2",
      "title": "AutoEval Done Right: Using Synthetic Data for Model Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Boyeau",
        "Anastasios N. Angelopoulos",
        "Nir Yosef",
        "Jitendra Malik",
        "Michael I. Jordan"
      ],
      "abstract": "The evaluation of machine learning models using human-labeled validation data\ncan be expensive and time-consuming. AI-labeled synthetic data can be used to\ndecrease the number of human annotations required for this purpose in a process\ncalled autoevaluation. We suggest efficient and statistically principled\nalgorithms for this purpose that improve sample efficiency while remaining\nunbiased. These algorithms increase the effective human-labeled sample size by\nup to 50% on experiments with GPT-4.",
      "tldr_zh": "这篇论文探讨了使用 AI 标注的合成数据进行模型评估（autoevaluation），以减少昂贵的人工标注需求。作者提出高效且统计上无偏的算法，这些算法优化了样本效率，同时保持评估结果的可靠性。在使用 GPT-4 的实验中，该方法将有效的人工标注样本大小提高了多达 50%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "New experiments, fix fig 1",
      "pdf_url": "http://arxiv.org/pdf/2403.07008v2",
      "published_date": "2024-03-09 02:47:11 UTC",
      "updated_date": "2024-05-28 04:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:00:43.584477"
    },
    {
      "arxiv_id": "2403.05770v1",
      "title": "Towards Deviation-Robust Agent Navigation via Perturbation-Aware Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bingqian Lin",
        "Yanxin Long",
        "Yi Zhu",
        "Fengda Zhu",
        "Xiaodan Liang",
        "Qixiang Ye",
        "Liang Lin"
      ],
      "abstract": "Vision-and-language navigation (VLN) asks an agent to follow a given language\ninstruction to navigate through a real 3D environment. Despite significant\nadvances, conventional VLN agents are trained typically under disturbance-free\nenvironments and may easily fail in real-world scenarios, since they are\nunaware of how to deal with various possible disturbances, such as sudden\nobstacles or human interruptions, which widely exist and may usually cause an\nunexpected route deviation. In this paper, we present a model-agnostic training\nparadigm, called Progressive Perturbation-aware Contrastive Learning (PROPER)\nto enhance the generalization ability of existing VLN agents, by requiring them\nto learn towards deviation-robust navigation. Specifically, a simple yet\neffective path perturbation scheme is introduced to implement the route\ndeviation, with which the agent is required to still navigate successfully\nfollowing the original instruction. Since directly enforcing the agent to learn\nperturbed trajectories may lead to inefficient training, a progressively\nperturbed trajectory augmentation strategy is designed, where the agent can\nself-adaptively learn to navigate under perturbation with the improvement of\nits navigation performance for each specific trajectory. For encouraging the\nagent to well capture the difference brought by perturbation, a\nperturbation-aware contrastive learning mechanism is further developed by\ncontrasting perturbation-free trajectory encodings and perturbation-based\ncounterparts. Extensive experiments on R2R show that PROPER can benefit\nmultiple VLN baselines in perturbation-free scenarios. We further collect the\nperturbed path data to construct an introspection subset based on the R2R,\ncalled Path-Perturbed R2R (PP-R2R). The results on PP-R2R show unsatisfying\nrobustness of popular VLN agents and the capability of PROPER in improving the\nnavigation robustness.",
      "tldr_zh": "本研究针对视觉和语言导航 (VLN) 代理在真实环境中面对突发干扰（如障碍或中断）时易发生路线偏差的问题，提出了一种模型无关的训练范式——Progressive Perturbation-aware Contrastive Learning (PROPER)。该方法通过引入路径扰动方案和渐进式轨迹增强策略，让代理在保持原指令的情况下自适应学习处理干扰，同时利用扰动感知对比学习机制对比无扰动和有扰动轨迹编码，以提升代理的鲁棒性。实验结果显示，PROPER 在 R2R 数据集上显著改善了多个 VLN 基线的性能，并在新构建的 Path-Perturbed R2R (PP-R2R) 子集上证明了其在增强导航鲁棒性方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TPAMI 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.05770v1",
      "published_date": "2024-03-09 02:34:13 UTC",
      "updated_date": "2024-03-09 02:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:00:56.726833"
    },
    {
      "arxiv_id": "2403.05767v1",
      "title": "Extending Activation Steering to Broad Skills and Multiple Behaviours",
      "title_zh": "扩展激活引导至广泛技能和多种行为",
      "authors": [
        "Teun van der Weij",
        "Massimo Poesio",
        "Nandi Schoots"
      ],
      "abstract": "Current large language models have dangerous capabilities, which are likely\nto become more problematic in the future. Activation steering techniques can be\nused to reduce risks from these capabilities. In this paper, we investigate the\nefficacy of activation steering for broad skills and multiple behaviours.\nFirst, by comparing the effects of reducing performance on general coding\nability and Python-specific ability, we find that steering broader skills is\ncompetitive to steering narrower skills. Second, we steer models to become more\nor less myopic and wealth-seeking, among other behaviours. In our experiments,\ncombining steering vectors for multiple different behaviours into one steering\nvector is largely unsuccessful. On the other hand, injecting individual\nsteering vectors at different places in a model simultaneously is promising.",
      "tldr_zh": "这篇论文扩展了 activation steering 技术，以减少大型语言模型（LLMs）的风险，焦点在于处理更广泛的技能和多种行为。首先，通过实验比较减少一般编码能力和 Python 特定能力的效果，发现针对 broader skills 的 steering 与针对 narrower skills 的方法同样有效。其次，研究了模型在 myopic 和 wealth-seeking 等行为上的操控，结果显示将多个 steering vectors 组合成一个向量基本失败，但同时在模型不同位置注入单个向量显示出前景。该工作为提升模型的安全性和可控性提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Code is available at:\n  https://github.com/TeunvdWeij/extending-activation-addition",
      "pdf_url": "http://arxiv.org/pdf/2403.05767v1",
      "published_date": "2024-03-09 02:30:04 UTC",
      "updated_date": "2024-03-09 02:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:01:08.605714"
    },
    {
      "arxiv_id": "2403.05764v1",
      "title": "Investigation into the Potential of Parallel Quantum Annealing for Simultaneous Optimization of Multiple Problems: A Comprehensive Study",
      "title_zh": "翻译失败",
      "authors": [
        "Arit Kumar Bishwas",
        "Anuraj Som",
        "Saurabh Choudhary"
      ],
      "abstract": "Parallel Quantum Annealing is a technique to solve multiple optimization\nproblems simultaneously. Parallel quantum annealing aims to optimize the\nutilization of available qubits on a quantum topology by addressing multiple\nindependent problems in a single annealing cycle. This study provides insights\ninto the potential and the limitations of this parallelization method. The\nexperiments consisting of two different problems are integrated, and various\nproblem dimensions are explored including normalization techniques using\nspecific methods such as DWaveSampler with Default Embedding, DWaveSampler with\nCustom Embedding and LeapHybridSampler. This method minimizes idle qubits and\nholds promise for substantial speed-up, as indicated by the Time-to-Solution\n(TTS) metric, compared to traditional quantum annealing, which solves problems\nsequentially and may leave qubits unutilized.",
      "tldr_zh": "本研究探讨了 Parallel Quantum Annealing 的潜力，该技术允许同时优化多个独立问题，从而更高效地利用量子拓扑上的 qubits，并在单个退火周期内处理这些问题。研究通过整合两个不同问题，并探索各种问题维度和归一化技术（如 DWaveSampler with Default Embedding、DWaveSampler with Custom Embedding 和 LeapHybridSampler），评估了该方法的优势与限制。结果显示，Parallel Quantum Annealing 显著减少了空闲 qubits，并通过 Time-to-Solution (TTS) 指标证明了相对于传统顺序量子退火的加速潜力，为量子优化问题提供了更高效的解决方案。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05764v1",
      "published_date": "2024-03-09 02:18:48 UTC",
      "updated_date": "2024-03-09 02:18:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:01:19.898131"
    },
    {
      "arxiv_id": "2403.05763v1",
      "title": "HDReason: Algorithm-Hardware Codesign for Hyperdimensional Knowledge Graph Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Hanning Chen",
        "Yang Ni",
        "Ali Zakeri",
        "Zhuowen Zou",
        "Sanggeon Yun",
        "Fei Wen",
        "Behnam Khaleghi",
        "Narayan Srinivasa",
        "Hugo Latapie",
        "Mohsen Imani"
      ],
      "abstract": "In recent times, a plethora of hardware accelerators have been put forth for\ngraph learning applications such as vertex classification and graph\nclassification. However, previous works have paid little attention to Knowledge\nGraph Completion (KGC), a task that is well-known for its significantly higher\nalgorithm complexity. The state-of-the-art KGC solutions based on graph\nconvolution neural network (GCN) involve extensive vertex/relation embedding\nupdates and complicated score functions, which are inherently cumbersome for\nacceleration. As a result, existing accelerator designs are no longer optimal,\nand a novel algorithm-hardware co-design for KG reasoning is needed.\n  Recently, brain-inspired HyperDimensional Computing (HDC) has been introduced\nas a promising solution for lightweight machine learning, particularly for\ngraph learning applications. In this paper, we leverage HDC for an\nintrinsically more efficient and acceleration-friendly KGC algorithm. We also\nco-design an acceleration framework named HDReason targeting FPGA platforms. On\nthe algorithm level, HDReason achieves a balance between high reasoning\naccuracy, strong model interpretability, and less computation complexity. In\nterms of architecture, HDReason offers reconfigurability, high training\nthroughput, and low energy consumption. When compared with NVIDIA RTX 4090 GPU,\nthe proposed accelerator achieves an average 10.6x speedup and 65x energy\nefficiency improvement. When conducting cross-models and cross-platforms\ncomparison, HDReason yields an average 4.2x higher performance and 3.4x better\nenergy efficiency with similar accuracy versus the state-of-the-art FPGA-based\nGCN training platform.",
      "tldr_zh": "本论文提出HDReason，一种算法-硬件协同设计框架，针对知识图完成(KGC)任务的复杂性问题，利用脑启发式超维计算(HDC)开发更高效的推理算法。HDReason在算法层面平衡了高推理准确性、强模型可解释性和低计算复杂度，在硬件层面设计了针对FPGA平台的加速器，提供可重配置、高训练吞吐量和低能耗。与NVIDIA RTX 4090 GPU相比，该框架平均实现10.6倍加速和65倍能效提升；与现有FPGA-based GCN训练平台相比，性能提升4.2倍，能效提升3.4倍，同时保持类似准确性。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05763v1",
      "published_date": "2024-03-09 02:17:43 UTC",
      "updated_date": "2024-03-09 02:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:01:34.953315"
    },
    {
      "arxiv_id": "2403.05759v1",
      "title": "Membership Testing in Markov Equivalence Classes via Independence Query Oracles",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Zhang",
        "Kirankumar Shiragur",
        "Caroline Uhler"
      ],
      "abstract": "Understanding causal relationships between variables is a fundamental problem\nwith broad impact in numerous scientific fields. While extensive research has\nbeen dedicated to learning causal graphs from data, its complementary concept\nof testing causal relationships has remained largely unexplored. While learning\ninvolves the task of recovering the Markov equivalence class (MEC) of the\nunderlying causal graph from observational data, the testing counterpart\naddresses the following critical question: Given a specific MEC and\nobservational data from some causal graph, can we determine if the\ndata-generating causal graph belongs to the given MEC?\n  We explore constraint-based testing methods by establishing bounds on the\nrequired number of conditional independence tests. Our bounds are in terms of\nthe size of the maximum undirected clique ($s$) of the given MEC. In the worst\ncase, we show a lower bound of $\\exp(\\Omega(s))$ independence tests. We then\ngive an algorithm that resolves the task with $\\exp(O(s))$ tests, matching our\nlower bound. Compared to the learning problem, where algorithms often use a\nnumber of independence tests that is exponential in the maximum in-degree, this\nshows that testing is relatively easier. In particular, it requires\nexponentially less independence tests in graphs featuring high in-degrees and\nsmall clique sizes. Additionally, using the DAG associahedron, we provide a\ngeometric interpretation of testing versus learning and discuss how our testing\nresult can aid learning.",
      "tldr_zh": "该论文探讨了通过独立性查询（independence query oracles）测试马尔可夫等价类（Markov Equivalence Classes, MEC）的成员资格问题，即给定一个MEC和观察数据，确定数据生成图是否属于该MEC。作者建立了基于约束的测试方法，并针对MEC中最大无向团（maximum undirected clique, s）的尺寸，给出了所需条件独立性测试（conditional independence tests）的下界为exp(Ω(s))，并提出一个使用exp(O(s))测试的算法，与下界相匹配。相比于学习因果图问题，该测试方法需要更少的独立性测试，尤其在高入度（in-degree）和小团大小的图中更高效。此外，论文利用DAG associahedron提供了测试与学习的几何解释，并讨论了如何将测试结果应用于因果图学习。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05759v1",
      "published_date": "2024-03-09 02:10:08 UTC",
      "updated_date": "2024-03-09 02:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:01:44.955810"
    },
    {
      "arxiv_id": "2403.05752v2",
      "title": "Task-Oriented GNNs Training on Large Knowledge Graphs for Accurate and Efficient Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Hussein Abdallah",
        "Waleed Afandi",
        "Panos Kalnis",
        "Essam Mansour"
      ],
      "abstract": "A Knowledge Graph (KG) is a heterogeneous graph encompassing a diverse range\nof node and edge types. Heterogeneous Graph Neural Networks (HGNNs) are popular\nfor training machine learning tasks like node classification and link\nprediction on KGs. However, HGNN methods exhibit excessive complexity\ninfluenced by the KG's size, density, and the number of node and edge types. AI\npractitioners handcraft a subgraph of a KG G relevant to a specific task. We\nrefer to this subgraph as a task-oriented subgraph (TOSG), which contains a\nsubset of task-related node and edge types in G. Training the task using TOSG\ninstead of G alleviates the excessive computation required for a large KG.\nCrafting the TOSG demands a deep understanding of the KG's structure and the\ntask's objectives. Hence, it is challenging and time-consuming. This paper\nproposes KG-TOSA, an approach to automate the TOSG extraction for task-oriented\nHGNN training on a large KG. In KG-TOSA, we define a generic graph pattern that\ncaptures the KG's local and global structure relevant to a specific task. We\nexplore different techniques to extract subgraphs matching our graph pattern:\nnamely (i) two techniques sampling around targeted nodes using biased random\nwalk or influence scores, and (ii) a SPARQL-based extraction method leveraging\nRDF engines' built-in indices. Hence, it achieves negligible preprocessing\noverhead compared to the sampling techniques. We develop a benchmark of real\nKGs of large sizes and various tasks for node classification and link\nprediction. Our experiments show that KG-TOSA helps state-of-the-art HGNN\nmethods reduce training time and memory usage by up to 70% while improving the\nmodel performance, e.g., accuracy and inference time.",
      "tldr_zh": "这篇论文针对大型知识图谱（KG）上的异构图神经网络（HGNNs）训练问题，提出了一种自动化方法KG-TOSA，用于提取任务导向子图（TOSG），以减少计算开销并提升模型性能。KG-TOSA 定义了一个通用图模式来捕捉KG的局部和全局结构，并探索了基于偏置随机游走、影响分数采样以及SPARQL查询的子图提取技术，其中SPARQL方法显著降低了预处理开销。实验在真实大型KG上进行，结果显示KG-TOSA能将HGNNs的训练时间和内存使用减少高达70%，同时改善准确性和推理时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages,9 Figures, 3 Tables, ICDE:2024",
      "pdf_url": "http://arxiv.org/pdf/2403.05752v2",
      "published_date": "2024-03-09 01:17:26 UTC",
      "updated_date": "2024-03-22 14:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:01:57.175401"
    },
    {
      "arxiv_id": "2403.05751v2",
      "title": "MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyao Fan",
        "Yueying Wu",
        "Chang Xu",
        "Yuhao Huang",
        "Weiqing Liu",
        "Jiang Bian"
      ],
      "abstract": "Recently, diffusion probabilistic models have attracted attention in\ngenerative time series forecasting due to their remarkable capacity to generate\nhigh-fidelity samples. However, the effective utilization of their strong\nmodeling ability in the probabilistic time series forecasting task remains an\nopen question, partially due to the challenge of instability arising from their\nstochastic nature. To address this challenge, we introduce a novel\nMulti-Granularity Time Series Diffusion (MG-TSD) model, which achieves\nstate-of-the-art predictive performance by leveraging the inherent granularity\nlevels within the data as given targets at intermediate diffusion steps to\nguide the learning process of diffusion models. The way to construct the\ntargets is motivated by the observation that the forward process of the\ndiffusion model, which sequentially corrupts the data distribution to a\nstandard normal distribution, intuitively aligns with the process of smoothing\nfine-grained data into a coarse-grained representation, both of which result in\na gradual loss of fine distribution features. In the study, we derive a novel\nmulti-granularity guidance diffusion loss function and propose a concise\nimplementation method to effectively utilize coarse-grained data across various\ngranularity levels. More importantly, our approach does not rely on additional\nexternal data, making it versatile and applicable across various domains.\nExtensive experiments conducted on real-world datasets demonstrate that our\nMG-TSD model outperforms existing time series prediction methods.",
      "tldr_zh": "该论文提出了 MG-TSD 模型，一种多粒度时间序列扩散模型，通过利用数据固有粒度级别作为中间扩散步骤的指导目标，解决扩散概率模型在时间序列预测任务中的不稳定性问题。模型基于前向扩散过程的观察，将细粒度数据平滑成粗粒度表示，并引入了新的多粒度指导扩散损失函数，以简洁的方式整合各种粒度级别的数据。实验结果显示，MG-TSD 在真实世界数据集上实现了最先进的预测性能，且不依赖额外外部数据，适用于多种领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Learning Representations (ICLR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.05751v2",
      "published_date": "2024-03-09 01:15:03 UTC",
      "updated_date": "2024-03-16 01:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:02:10.527729"
    },
    {
      "arxiv_id": "2403.05750v3",
      "title": "Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Abdali",
        "Richard Anarfi",
        "CJ Barberan",
        "Jia He"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Generation (NLG) by demonstrating an impressive ability to generate\nhuman-like text. However, their widespread usage introduces challenges that\nnecessitate thoughtful examination, ethical scrutiny, and responsible\npractices. In this study, we delve into these challenges, explore existing\nstrategies for mitigating them, with a particular emphasis on identifying\nAI-generated text as the ultimate solution. Additionally, we assess the\nfeasibility of detection from a theoretical perspective and propose novel\nresearch directions to address the current limitations in this domain.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 在Natural Language Generation (NLG) 领域的革命性影响，以及其广泛应用带来的挑战，如伦理问题和潜在风险。作者重点分析了现有策略，特别是识别AI生成文本的技术，作为应对这些挑战的核心解决方案。从理论角度评估了检测的可行性，并提出了新的研究方向来克服当前领域的限制。这些贡献有助于推动负责任的AI实践和更可靠的文本鉴别方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05750v3",
      "published_date": "2024-03-09 01:13:54 UTC",
      "updated_date": "2024-06-26 20:49:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:02:21.152942"
    },
    {
      "arxiv_id": "2403.09706v1",
      "title": "Schema-Aware Multi-Task Learning for Complex Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Yangjun Wu",
        "Han Wang"
      ],
      "abstract": "Conventional text-to-SQL parsers are not good at synthesizing complex SQL\nqueries that involve multiple tables or columns, due to the challenges inherent\nin identifying the correct schema items and performing accurate alignment\nbetween question and schema items. To address the above issue, we present a\nschema-aware multi-task learning framework (named MTSQL) for complicated SQL\nqueries. Specifically, we design a schema linking discriminator module to\ndistinguish the valid question-schema linkings, which explicitly instructs the\nencoder by distinctive linking relations to enhance the alignment quality. On\nthe decoder side, we define 6-type relationships to describe the connections\nbetween tables and columns (e.g., WHERE_TC), and introduce an operator-centric\ntriple extractor to recognize those associated schema items with the predefined\nrelationship. Also, we establish a rule set of grammar constraints via the\npredicted triples to filter the proper SQL operators and schema items during\nthe SQL generation. On Spider, a cross-domain challenging text-to-SQL\nbenchmark, experimental results indicate that MTSQL is more effective than\nbaselines, especially in extremely hard scenarios. Moreover, further analyses\nverify that our approach leads to promising improvements for complicated SQL\nqueries.",
      "tldr_zh": "该论文提出了一种基于 schema 感知的多任务学习框架 MTSQL，用于处理复杂的 Text-to-SQL 任务，以解决传统解析器在识别 schema 项和进行问题-schema 对齐方面的挑战。具体而言，该框架包括一个 schema linking discriminator 模块来增强链接质量，以及一个 operator-centric triple extractor 来识别表和列之间的6种关系（如 WHERE_TC），并通过语法约束规则集过滤 SQL 生成过程。在 Spider 数据集上的实验显示，MTSQL 比基线模型更有效，尤其在极端困难的场景中，对复杂 SQL 查询的性能有显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "8pages",
      "pdf_url": "http://arxiv.org/pdf/2403.09706v1",
      "published_date": "2024-03-09 01:13:37 UTC",
      "updated_date": "2024-03-09 01:13:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:02:33.620866"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 43,
  "processed_papers_count": 43,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T14:02:56.002401"
}