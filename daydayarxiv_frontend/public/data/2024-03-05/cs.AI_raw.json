[
  {
    "arxiv_id": "2403.13825v1",
    "title": "Deep Generative Models for Ultra-High Granularity Particle Physics Detector Simulation: A Voyage From Emulation to Extrapolation",
    "authors": [
      "Baran Hashemi"
    ],
    "abstract": "Simulating ultra-high-granularity detector responses in Particle Physics\nrepresents a critical yet computationally demanding task. This thesis aims to\novercome this challenge for the Pixel Vertex Detector (PXD) at the Belle II\nexperiment, which features over 7.5M pixel channels-the highest spatial\nresolution detector simulation dataset ever analysed with generative models.\nThis thesis starts off by a comprehensive and taxonomic review on generative\nmodels for simulating detector signatures. Then, it presents the Intra-Event\nAware Generative Adversarial Network (IEA-GAN), a new geometry-aware generative\nmodel that introduces a relational attentive reasoning and Self-Supervised\nLearning to approximate an \"event\" in the detector. This study underscores the\nimportance of intra-event correlation for downstream physics analyses. Building\nupon this, the work drifts towards a more generic approach and presents\nYonedaVAE, a Category Theory-inspired generative model that tackles the open\nproblem of Out-of-Distribution (OOD) simulation. YonedaVAE introduces a\nlearnable Yoneda embedding to capture the entirety of an event based on its\nsensor relationships, formulating a Category theoretical language for\nintra-event relational reasoning. This is complemented by introducing a\nSelf-Supervised learnable prior for VAEs and an Adaptive Top-q sampling\nmechanism, enabling the model to sample point clouds with variable\nintra-category cardinality in a zero-shot manner. Variable Intra-event\ncardinality has not been approached before and is vital for simulating\nirregular detector geometries. Trained on an early experiment data, YonedaVAE\ncan reach a reasonable OOD simulation precision of a later experiment with\nalmost double luminosity. This study introduces, for the first time, the\nresults of using deep generative models for ultra-high granularity detector\nsimulation in Particle Physics.",
    "categories": [
      "physics.ins-det",
      "cs.AI",
      "cs.LG",
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "physics.ins-det",
    "comment": "PhD thesis, 234 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.13825v1",
    "published_date": "2024-03-05 23:12:47 UTC",
    "updated_date": "2024-03-05 23:12:47 UTC"
  },
  {
    "arxiv_id": "2403.03359v2",
    "title": "RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging",
    "authors": [
      "Jordan Poots"
    ],
    "abstract": "Autonomous parallel-style on-ramp merging in human controlled traffic\ncontinues to be an existing issue for autonomous vehicle control. Existing\nnon-learning based solutions for vehicle control rely on rules and optimization\nprimarily. These methods have been seen to present significant challenges.\nRecent advancements in Deep Reinforcement Learning have shown promise and have\nreceived significant academic interest however the available learning based\napproaches show inadequate attention to other highway vehicles and often rely\non inaccurate road traffic assumptions. In addition, the parallel-style case is\nrarely considered. A novel learning based model for acceleration and lane\nchange decision making that explicitly considers the utility to both the ego\nvehicle and its surrounding vehicles which may be cooperative or uncooperative\nto produce behaviour that is socially acceptable is proposed. The novel reward\nfunction makes use of Social Value Orientation to weight the vehicle's level of\nsocial cooperation and is divided into ego vehicle and surrounding vehicle\nutility which are weighted according to the model's designated Social Value\nOrientation. A two-lane highway with an on-ramp divided into a taper-style and\nparallel-style section is considered. Simulation results indicated the\nimportance of considering surrounding vehicles in reward function design and\nshow that the proposed model matches or surpasses those in literature in terms\nof collisions while also introducing socially courteous behaviour avoiding near\nmisses and anti-social behaviour through direct consideration of the effect of\nmerging on surrounding vehicles.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Updated explanation of TTC, page 7",
    "pdf_url": "http://arxiv.org/pdf/2403.03359v2",
    "published_date": "2024-03-05 23:03:56 UTC",
    "updated_date": "2024-03-15 10:32:45 UTC"
  },
  {
    "arxiv_id": "2403.03357v2",
    "title": "The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa",
    "authors": [
      "Mercy Asiedu",
      "Awa Dieng",
      "Iskandar Haykel",
      "Negar Rostamzadeh",
      "Stephen Pfohl",
      "Chirag Nagpal",
      "Maria Nagawa",
      "Abigail Oppong",
      "Sanmi Koyejo",
      "Katherine Heller"
    ],
    "abstract": "With growing application of machine learning (ML) technologies in healthcare,\nthere have been calls for developing techniques to understand and mitigate\nbiases these systems may exhibit. Fair-ness considerations in the development\nof ML-based solutions for health have particular implications for Africa, which\nalready faces inequitable power imbalances between the Global North and\nSouth.This paper seeks to explore fairness for global health, with Africa as a\ncase study. We conduct a scoping review to propose axes of disparities for\nfairness consideration in the African context and delineate where they may come\ninto play in different ML-enabled medical modalities. We then conduct\nqualitative research studies with 672 general population study participants and\n28 experts inML, health, and policy focused on Africa to obtain corroborative\nevidence on the proposed axes of disparities. Our analysis focuses on\ncolonialism as the attribute of interest and examines the interplay between\nartificial intelligence (AI), health, and colonialism. Among the pre-identified\nattributes, we found that colonial history, country of origin, and national\nincome level were specific axes of disparities that participants believed would\ncause an AI system to be biased.However, there was also divergence of opinion\nbetween experts and general population participants. Whereas experts generally\nexpressed a shared view about the relevance of colonial history for the\ndevelopment and implementation of AI technologies in Africa, the majority of\nthe general population participants surveyed did not think there was a direct\nlink between AI and colonialism. Based on these findings, we provide practical\nrecommendations for developing fairness-aware ML solutions for health in\nAfrica.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2304.02190",
    "pdf_url": "http://arxiv.org/pdf/2403.03357v2",
    "published_date": "2024-03-05 22:54:15 UTC",
    "updated_date": "2024-03-11 16:16:22 UTC"
  },
  {
    "arxiv_id": "2403.03348v3",
    "title": "Learning to Maximize Mutual Information for Chain-of-Thought Distillation",
    "authors": [
      "Xin Chen",
      "Hanxian Huang",
      "Yanjun Gao",
      "Yi Wang",
      "Jishen Zhao",
      "Ke Ding"
    ],
    "abstract": "Knowledge distillation, the technique of transferring knowledge from large,\ncomplex models to smaller ones, marks a pivotal step towards efficient AI\ndeployment. Distilling Step-by-Step~(DSS), a novel method utilizing\nchain-of-thought~(CoT) distillation, has demonstrated promise by imbuing\nsmaller models with the superior reasoning capabilities of their larger\ncounterparts. In DSS, the distilled model acquires the ability to generate\nrationales and predict labels concurrently through a multi-task learning\nframework. However, DSS overlooks the intrinsic relationship between the two\ntraining tasks, leading to ineffective integration of CoT knowledge with the\ntask of label prediction. To this end, we investigate the mutual relationship\nof the two tasks from Information Bottleneck perspective and formulate it as\nmaximizing the mutual information of the representation features of the two\ntasks. We propose a variational approach to solve this optimization problem\nusing a learning-based method. Our experimental results across four datasets\ndemonstrate that our method outperforms the state-of-the-art DSS. Our findings\noffer insightful guidance for future research on language model distillation as\nwell as applications involving CoT. Codes are available at\n\\url{https://github.com/xinchen9/cot_distillation_ACL2024}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2403.03348v3",
    "published_date": "2024-03-05 22:21:45 UTC",
    "updated_date": "2024-06-09 14:24:54 UTC"
  },
  {
    "arxiv_id": "2403.09700v2",
    "title": "Shapley Values-Powered Framework for Fair Reward Split in Content Produced by GenAI",
    "authors": [
      "Alex Glinsky",
      "Alexey Sokolsky"
    ],
    "abstract": "It is evident that, currently, generative models are surpassed in quality by\nhuman professionals. However, with the advancements in Artificial Intelligence,\nthis gap will narrow, leading to scenarios where individuals who have dedicated\nyears of their lives to mastering a skill become obsolete due to their high\ncosts, which are inherently linked to the time they require to complete a task\n-- a task that AI could accomplish in minutes or seconds. To avoid future\nsocial upheavals, we must, even now, contemplate how to fairly assess the\ncontributions of such individuals in training generative models and how to\ncompensate them for the reduction or complete loss of their incomes. In this\nwork, we propose a method to structure collaboration between model developers\nand data providers. To achieve this, we employ Shapley Values to quantify the\ncontribution of artist(s) in an image generated by the Stable Diffusion-v1.5\nmodel and to equitably allocate the reward among them.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "91A12, 68T05, 91B32",
      "I.2.6; I.3.3; I.2.0; J.5; J.7"
    ],
    "primary_category": "cs.CV",
    "comment": "36 pages, 32 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.09700v2",
    "published_date": "2024-03-05 22:19:21 UTC",
    "updated_date": "2024-03-27 13:42:25 UTC"
  },
  {
    "arxiv_id": "2403.03344v1",
    "title": "Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation",
    "authors": [
      "Tina Vartziotis",
      "Ippolyti Dellatolas",
      "George Dasoulas",
      "Maximilian Schmidt",
      "Florian Schneider",
      "Tim Hoffmann",
      "Sotirios Kotsopoulos",
      "Michael Keckeisen"
    ],
    "abstract": "The increasing use of information technology has led to a significant share\nof energy consumption and carbon emissions from data centers. These\ncontributions are expected to rise with the growing demand for big data\nanalytics, increasing digitization, and the development of large artificial\nintelligence (AI) models. The need to address the environmental impact of\nsoftware development has led to increased interest in green (sustainable)\ncoding and claims that the use of AI models can lead to energy efficiency\ngains. Here, we provide an empirical study on green code and an overview of\ngreen coding practices, as well as metrics used to quantify the sustainability\nawareness of AI models. In this framework, we evaluate the sustainability of\nauto-generated code. The auto-generate codes considered in this study are\nproduced by generative commercial AI language models, GitHub Copilot, OpenAI\nChatGPT-3, and Amazon CodeWhisperer. Within our methodology, in order to\nquantify the sustainability awareness of these AI models, we propose a\ndefinition of the code's \"green capacity\", based on certain sustainability\nmetrics. We compare the performance and green capacity of human-generated code\nand code generated by the three AI language models in response to easy-to-hard\nproblem statements. Our findings shed light on the current capacity of AI\nmodels to contribute to sustainable software development.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03344v1",
    "published_date": "2024-03-05 22:12:01 UTC",
    "updated_date": "2024-03-05 22:12:01 UTC"
  },
  {
    "arxiv_id": "2403.03334v3",
    "title": "DIVERSE: A Dataset of YouTube Video Comment Stances with a Data Programming Model",
    "authors": [
      "Iain J. Cruickshank",
      "Amir Soofi",
      "Lynnette Hui Xian Ng"
    ],
    "abstract": "Public opinion of military organizations significantly influences their\nability to recruit talented individuals. As recruitment efforts increasingly\nextend into digital spaces like social media, it becomes essential to assess\nthe stance of social media users toward online military content. However, there\nis a notable lack of data for analyzing opinions on military recruiting efforts\nonline, compounded by challenges in stance labeling, which is crucial for\nunderstanding public perceptions. Despite the importance of stance analysis for\nsuccessful online military recruitment, creating human-annotated, in-domain\nstance labels is resource-intensive. In this paper, we address both the\nchallenges of stance labeling and the scarcity of data on public opinions of\nonline military recruitment by introducing and releasing the DIVERSE dataset:\nhttps://doi.org/10.5281/zenodo.10493803. This dataset comprises all comments\nfrom the U.S. Army's official YouTube Channel videos. We employed a\nstate-of-the-art weak supervision approach, leveraging large language models to\nlabel the stance of each comment toward its respective video and the U.S. Army.\nOur findings indicate that the U.S. Army's videos began attracting a\nsignificant number of comments post-2021, with the stance distribution\ngenerally balanced among supportive, oppositional, and neutral comments, with a\nslight skew towards oppositional versus supportive comments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at IEEE Big Data 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03334v3",
    "published_date": "2024-03-05 21:36:23 UTC",
    "updated_date": "2024-10-29 02:03:06 UTC"
  },
  {
    "arxiv_id": "2403.03322v4",
    "title": "Deep Configuration Performance Learning: A Systematic Survey and Taxonomy",
    "authors": [
      "Jingzhi Gong",
      "Tao Chen"
    ],
    "abstract": "Performance is arguably the most crucial attribute that reflects the quality\nof a configurable software system. However, given the increasing scale and\ncomplexity of modern software, modeling and predicting how various\nconfigurations can impact performance becomes one of the major challenges in\nsoftware maintenance. As such, performance is often modeled without having a\nthorough knowledge of the software system, but relying mainly on data, which\nfits precisely with the purpose of deep learning.\n  In this paper, we conduct a comprehensive review exclusively on the topic of\ndeep learning for performance learning of configurable software, covering 1,206\nsearched papers spanning six indexing services, based on which 99 primary\npapers were extracted and analyzed. Our results outline key statistics,\ntaxonomy, strengths, weaknesses, and optimal usage scenarios for techniques\nrelated to the preparation of configuration data, the construction of deep\nlearning performance models, the evaluation of these models, and their\nutilization in various software configuration-related tasks.We also identify\nthe good practices and potentially problematic phenomena from the studies\nsurveyed, together with a comprehensive summary of actionable suggestions and\ninsights into future opportunities within the field. To promote open science,\nall the raw results of this survey can be accessed at our repository:\nhttps://github.com/ideas-labo/DCPL-SLR.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by the TOSEM survey track in October 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03322v4",
    "published_date": "2024-03-05 21:05:16 UTC",
    "updated_date": "2024-11-03 17:42:43 UTC"
  },
  {
    "arxiv_id": "2403.04803v1",
    "title": "Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation",
    "authors": [
      "Zahir Alsulaimawi"
    ],
    "abstract": "This paper introduces an advanced approach for fortifying Federated Learning\n(FL) systems against label-flipping attacks. We propose a simplified\nconsensus-based verification process integrated with an adaptive thresholding\nmechanism. This dynamic thresholding is designed to adjust based on the\nevolving landscape of model updates, offering a refined layer of anomaly\ndetection that aligns with the real-time needs of distributed learning\nenvironments. Our method necessitates a majority consensus among participating\nclients to validate updates, ensuring that only vetted and consensual\nmodifications are applied to the global model. The efficacy of our approach is\nvalidated through experiments on two benchmark datasets in deep learning,\nCIFAR-10 and MNIST. Our results indicate a significant mitigation of\nlabel-flipping attacks, bolstering the FL system's resilience. This method\ntranscends conventional techniques that depend on anomaly detection or\nstatistical validation by incorporating a verification layer reminiscent of\nblockchain's participatory validation without the associated cryptographic\noverhead. The innovation of our approach rests in striking an optimal balance\nbetween heightened security measures and the inherent limitations of FL\nsystems, such as computational efficiency and data privacy. Implementing a\nconsensus mechanism specifically tailored for FL environments paves the way for\nmore secure, robust, and trustworthy distributed machine learning applications,\nwhere safeguarding data integrity and model robustness is critical.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.04803v1",
    "published_date": "2024-03-05 20:54:56 UTC",
    "updated_date": "2024-03-05 20:54:56 UTC"
  },
  {
    "arxiv_id": "2403.03305v1",
    "title": "Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification",
    "authors": [
      "Robert Vacareanu",
      "Fahmida Alam",
      "Md Asiful Islam",
      "Haris Riaz",
      "Mihai Surdeanu"
    ],
    "abstract": "This paper introduces a novel neuro-symbolic architecture for relation\nclassification (RC) that combines rule-based methods with contemporary deep\nlearning techniques. This approach capitalizes on the strengths of both\nparadigms: the adaptability of rule-based systems and the generalization power\nof neural networks. Our architecture consists of two components: a declarative\nrule-based model for transparent classification and a neural component to\nenhance rule generalizability through semantic text matching. Notably, our\nsemantic matcher is trained in an unsupervised domain-agnostic way, solely with\nsynthetic data. Further, these components are loosely coupled, allowing for\nrule modifications without retraining the semantic matcher. In our evaluation,\nwe focused on two few-shot relation classification datasets: Few-Shot TACRED\nand a Few-Shot version of NYT29. We show that our proposed method outperforms\nprevious state-of-the-art models in three out of four settings, despite not\nseeing any human-annotated training data. Further, we show that our approach\nremains modular and pliable, i.e., the corresponding rules can be locally\nmodified to improve the overall model. Human interventions to the rules for the\nTACRED relation \\texttt{org:parents} boost the performance on that relation by\nas much as 26\\% relative improvement, without negatively impacting the other\nrelations, and without retraining the semantic matching component.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03305v1",
    "published_date": "2024-03-05 20:08:32 UTC",
    "updated_date": "2024-03-05 20:08:32 UTC"
  },
  {
    "arxiv_id": "2403.03293v1",
    "title": "AI Insights: A Case Study on Utilizing ChatGPT Intelligence for Research Paper Analysis",
    "authors": [
      "Anjalee De Silva",
      "Janaka L. Wijekoon",
      "Rashini Liyanarachchi",
      "Rrubaa Panchendrarajan",
      "Weranga Rajapaksha"
    ],
    "abstract": "This paper discusses the effectiveness of leveraging Chatbot: Generative\nPre-trained Transformer (ChatGPT) versions 3.5 and 4 for analyzing research\npapers for effective writing of scientific literature surveys. The study\nselected the \\textit{Application of Artificial Intelligence in Breast Cancer\nTreatment} as the research topic. Research papers related to this topic were\ncollected from three major publication databases Google Scholar, Pubmed, and\nScopus. ChatGPT models were used to identify the category, scope, and relevant\ninformation from the research papers for automatic identification of relevant\npapers related to Breast Cancer Treatment (BCT), organization of papers\naccording to scope, and identification of key information for survey paper\nwriting. Evaluations performed using ground truth data annotated using subject\nexperts reveal, that GPT-4 achieves 77.3\\% accuracy in identifying the research\npaper categories and 50\\% of the papers were correctly identified by GPT-4 for\ntheir scopes. Further, the results demonstrate that GPT-4 can generate reasons\nfor its decisions with an average of 27\\% new words, and 67\\% of the reasons\ngiven by the model were completely agreeable to the subject experts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03293v1",
    "published_date": "2024-03-05 19:47:57 UTC",
    "updated_date": "2024-03-05 19:47:57 UTC"
  },
  {
    "arxiv_id": "2403.03288v1",
    "title": "Should We Fear Large Language Models? A Structural Analysis of the Human Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens of Heidegger's Philosophy",
    "authors": [
      "Jianqiiu Zhang"
    ],
    "abstract": "In the rapidly evolving field of Large Language Models (LLMs), there is a\ncritical need to thoroughly analyze their capabilities and risks. Central to\nour investigation are two novel elements. Firstly, it is the innovative\nparallels between the statistical patterns of word relationships within LLMs\nand Martin Heidegger's concepts of \"ready-to-hand\" and \"present-at-hand,\" which\nencapsulate the utilitarian and scientific altitudes humans employ in\ninteracting with the world. This comparison lays the groundwork for positioning\nLLMs as the digital counterpart to the Faculty of Verbal Knowledge, shedding\nlight on their capacity to emulate certain facets of human reasoning. Secondly,\na structural analysis of human reasoning, viewed through Heidegger's notion of\ntruth as \"unconcealment\" is conducted This foundational principle enables us to\nmap out the inputs and outputs of the reasoning system and divide reasoning\ninto four distinct categories. Respective cognitive faculties are delineated,\nallowing us to place LLMs within the broader schema of human reasoning, thus\nclarifying their strengths and inherent limitations. Our findings reveal that\nwhile LLMs possess the capability for Direct Explicative Reasoning and Pseudo\nRational Reasoning, they fall short in authentic rational reasoning and have no\ncreative reasoning capabilities, due to the current lack of many analogous AI\nmodels such as the Faculty of Judgement. The potential and risks of LLMs when\nthey are augmented with other AI technologies are also evaluated. The results\nindicate that although LLMs have achieved proficiency in some reasoning\nabilities, the aspiration to match or exceed human intellectual capabilities is\nyet unattained. This research not only enriches our comprehension of LLMs but\nalso propels forward the discourse on AI's potential and its bounds, paving the\nway for future explorations into AI's evolving landscape.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "39 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.03288v1",
    "published_date": "2024-03-05 19:40:53 UTC",
    "updated_date": "2024-03-05 19:40:53 UTC"
  },
  {
    "arxiv_id": "2403.03281v2",
    "title": "Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits",
    "authors": [
      "Sahil Sidheekh",
      "Pranuthi Tenali",
      "Saurabh Mathur",
      "Erik Blasch",
      "Kristian Kersting",
      "Sriraam Natarajan"
    ],
    "abstract": "We consider the problem of late multi-modal fusion for discriminative\nlearning. Motivated by noisy, multi-source domains that require understanding\nthe reliability of each data source, we explore the notion of credibility in\nthe context of multi-modal fusion. We propose a combination function that uses\nprobabilistic circuits (PCs) to combine predictive distributions over\nindividual modalities. We also define a probabilistic measure to evaluate the\ncredibility of each modality via inference queries over the PC. Our\nexperimental evaluation demonstrates that our fusion method can reliably infer\ncredibility while maintaining competitive performance with the\nstate-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03281v2",
    "published_date": "2024-03-05 19:25:55 UTC",
    "updated_date": "2024-07-17 05:20:51 UTC"
  },
  {
    "arxiv_id": "2403.03276v2",
    "title": "ARNN: Attentive Recurrent Neural Network for Multi-channel EEG Signals to Identify Epileptic Seizures",
    "authors": [
      "Salim Rukhsar",
      "Anil Kumar Tiwari"
    ],
    "abstract": "Electroencephalography (EEG) is a widely used tool for diagnosing brain\ndisorders due to its high temporal resolution, non-invasive nature, and\naffordability. Manual analysis of EEG is labor-intensive and requires\nexpertise, making automatic EEG interpretation crucial for reducing workload\nand accurately assessing seizures. In epilepsy diagnosis, prolonged EEG\nmonitoring generates extensive data, often spanning hours, days, or even weeks.\nWhile machine learning techniques for automatic EEG interpretation have\nadvanced significantly in recent decades, there remains a gap in its ability to\nefficiently analyze large datasets with a balance of accuracy and computational\nefficiency. To address the challenges mentioned above, an Attention Recurrent\nNeural Network (ARNN) is proposed that can process a large amount of data\nefficiently and accurately. This ARNN cell recurrently applies attention layers\nalong a sequence and has linear complexity with the sequence length and\nleverages parallel computation by processing multi-channel EEG signals rather\nthan single-channel signals. In this architecture, the attention layer is a\ncomputational unit that efficiently applies self-attention and cross-attention\nmechanisms to compute a recurrent function over a wide number of state vectors\nand input signals. This framework is inspired in part by the attention layer\nand long short-term memory (LSTM) cells, but it scales this typical cell up by\nseveral orders to parallelize for multi-channel EEG signals. It inherits the\nadvantages of attention layers and LSTM gate while avoiding their respective\ndrawbacks. The model's effectiveness is evaluated through extensive experiments\nwith heterogeneous datasets, including the CHB-MIT and UPenn and Mayo's Clinic\ndatasets.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "11 pages, 7 figures, Journal Paper",
    "pdf_url": "http://arxiv.org/pdf/2403.03276v2",
    "published_date": "2024-03-05 19:15:17 UTC",
    "updated_date": "2024-11-18 10:46:04 UTC"
  },
  {
    "arxiv_id": "2403.03274v1",
    "title": "From Noise to Signal: Unveiling Treatment Effects from Digital Health Data through Pharmacology-Informed Neural-SDE",
    "authors": [
      "Samira Pakravan",
      "Nikolaos Evangelou",
      "Maxime Usdin",
      "Logan Brooks",
      "James Lu"
    ],
    "abstract": "Digital health technologies (DHT), such as wearable devices, provide\npersonalized, continuous, and real-time monitoring of patient. These\ntechnologies are contributing to the development of novel therapies and\npersonalized medicine. Gaining insight from these technologies requires\nappropriate modeling techniques to capture clinically-relevant changes in\ndisease state. The data generated from these devices is characterized by being\nstochastic in nature, may have missing elements, and exhibits considerable\ninter-individual variability - thereby making it difficult to analyze using\ntraditional longitudinal modeling techniques. We present a novel\npharmacology-informed neural stochastic differential equation (SDE) model\ncapable of addressing these challenges. Using synthetic data, we demonstrate\nthat our approach is effective in identifying treatment effects and learning\ncausal relationships from stochastic data, thereby enabling counterfactual\nsimulation.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "math.DS",
      "I.2; G.3"
    ],
    "primary_category": "q-bio.QM",
    "comment": "6 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.03274v1",
    "published_date": "2024-03-05 19:13:57 UTC",
    "updated_date": "2024-03-05 19:13:57 UTC"
  },
  {
    "arxiv_id": "2403.03218v7",
    "title": "The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning",
    "authors": [
      "Nathaniel Li",
      "Alexander Pan",
      "Anjali Gopal",
      "Summer Yue",
      "Daniel Berrios",
      "Alice Gatti",
      "Justin D. Li",
      "Ann-Kathrin Dombrowski",
      "Shashwat Goel",
      "Long Phan",
      "Gabriel Mukobi",
      "Nathan Helm-Burger",
      "Rassin Lababidi",
      "Lennart Justen",
      "Andrew B. Liu",
      "Michael Chen",
      "Isabelle Barrass",
      "Oliver Zhang",
      "Xiaoyuan Zhu",
      "Rishub Tamirisa",
      "Bhrugu Bharathi",
      "Adam Khoja",
      "Zhenqi Zhao",
      "Ariel Herbert-Voss",
      "Cort B. Breuer",
      "Samuel Marks",
      "Oam Patel",
      "Andy Zou",
      "Mantas Mazeika",
      "Zifan Wang",
      "Palash Oswal",
      "Weiran Lin",
      "Adam A. Hunt",
      "Justin Tienken-Harder",
      "Kevin Y. Shih",
      "Kemper Talley",
      "John Guan",
      "Russell Kaplan",
      "Ian Steneker",
      "David Campbell",
      "Brad Jokubaitis",
      "Alex Levinson",
      "Jean Wang",
      "William Qian",
      "Kallol Krishna Karmakar",
      "Steven Basart",
      "Stephen Fitz",
      "Mindy Levine",
      "Ponnurangam Kumaraguru",
      "Uday Tupakula",
      "Vijay Varadharajan",
      "Ruoyu Wang",
      "Yan Shoshitaishvili",
      "Jimmy Ba",
      "Kevin M. Esvelt",
      "Alexandr Wang",
      "Dan Hendrycks"
    ],
    "abstract": "The White House Executive Order on Artificial Intelligence highlights the\nrisks of large language models (LLMs) empowering malicious actors in developing\nbiological, cyber, and chemical weapons. To measure these risks of malicious\nuse, government institutions and major AI labs are developing evaluations for\nhazardous capabilities in LLMs. However, current evaluations are private,\npreventing further research into mitigating risk. Furthermore, they focus on\nonly a few, highly specific pathways for malicious use. To fill these gaps, we\npublicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a\ndataset of 3,668 multiple-choice questions that serve as a proxy measurement of\nhazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP\nwas developed by a consortium of academics and technical consultants, and was\nstringently filtered to eliminate sensitive information prior to public\nrelease. WMDP serves two roles: first, as an evaluation for hazardous knowledge\nin LLMs, and second, as a benchmark for unlearning methods to remove such\nhazardous knowledge. To guide progress on unlearning, we develop RMU, a\nstate-of-the-art unlearning method based on controlling model representations.\nRMU reduces model performance on WMDP while maintaining general capabilities in\nareas such as biology and computer science, suggesting that unlearning may be a\nconcrete path towards reducing malicious use from LLMs. We release our\nbenchmark and code publicly at https://wmdp.ai",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "See the project page at https://wmdp.ai",
    "pdf_url": "http://arxiv.org/pdf/2403.03218v7",
    "published_date": "2024-03-05 18:59:35 UTC",
    "updated_date": "2024-05-15 19:16:09 UTC"
  },
  {
    "arxiv_id": "2403.03203v1",
    "title": "CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments",
    "authors": [
      "Savitha Sam Abraham",
      "Marjan Alirezaie",
      "Luc De Raedt"
    ],
    "abstract": "The integration of learning and reasoning is high on the research agenda in\nAI. Nevertheless, there is only a little attention to use existing background\nknowledge for reasoning about partially observed scenes to answer questions\nabout the scene. Yet, we as humans use such knowledge frequently to infer\nplausible answers to visual questions (by eliminating all inconsistent ones).\nSuch knowledge often comes in the form of constraints about objects and it\ntends to be highly domain or environment-specific. We contribute a novel\nbenchmark called CLEVR-POC for reasoning-intensive visual question answering\n(VQA) in partially observable environments under constraints. In CLEVR-POC,\nknowledge in the form of logical constraints needs to be leveraged to generate\nplausible answers to questions about a hidden object in a given partial scene.\nFor instance, if one has the knowledge that all cups are colored either red,\ngreen or blue and that there is only one green cup, it becomes possible to\ndeduce the color of an occluded cup as either red or blue, provided that all\nother cups, including the green one, are observed. Through experiments, we\nobserve that the low performance of pre-trained vision language models like\nCLIP (~ 22%) and a large language model (LLM) like GPT-4 (~ 46%) on CLEVR-POC\nascertains the necessity for frameworks that can handle reasoning-intensive\ntasks where environment-specific background knowledge is available and crucial.\nFurthermore, our demonstration illustrates that a neuro-symbolic model, which\nintegrates an LLM like GPT-4 with a visual perception network and a formal\nlogical reasoner, exhibits exceptional performance on CLEVR-POC.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 10 images, Accepted at LREC-COLING 2024 - The 2024 Joint\n  International Conference on Computational Linguistics, Language Resources and\n  Evaluation",
    "pdf_url": "http://arxiv.org/pdf/2403.03203v1",
    "published_date": "2024-03-05 18:41:37 UTC",
    "updated_date": "2024-03-05 18:41:37 UTC"
  },
  {
    "arxiv_id": "2403.03188v2",
    "title": "Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement",
    "authors": [
      "Rafaela Martelo",
      "Kimia Ahmadiyehyazdi",
      "Ruo-Qian Wang"
    ],
    "abstract": "Real-time flood forecasting is vital for effective emergency responses, but\nbridging the gap between complex numerical models and practical decision-making\nremains challenging. Decision-makers often rely on experts, while the public\nstruggles to interpret flood risk information. To address this, we developed a\ncustomized AI Assistant powered by GPT-4. This tool enhances communication\nbetween decision-makers, the public, and forecasters, requiring no specialized\nknowledge. The framework leverages GPT-4's advanced natural language\ncapabilities to search flood alerts, answer inquiries, and integrate real-time\nwarnings with flood maps and social vulnerability data. It simplifies complex\nflood zone information into actionable advice. The prototype was evaluated on\nrelevance, error resilience, and contextual understanding, with performance\ncompared across different GPT models. This research advances flood risk\nmanagement by making critical information more accessible and engaging,\ndemonstrating the potential of AI tools like GPT-4 in addressing social and\nenvironmental challenges.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "I.2.1; I.2.7; J.2"
    ],
    "primary_category": "cs.AI",
    "comment": "48 pages, 3 figures and an appendix with 2 supplementary tables\n  detailing experimental results and observations. Supported by Rutgers's\n  Research Incubator in Climate and Health, Seed Funding Initiative and\n  Research Council Award - \"Engaged Climate Action\". Source code and data\n  available at https://github.com/RafaelaMartelo/FloodGPT-4_Prototype",
    "pdf_url": "http://arxiv.org/pdf/2403.03188v2",
    "published_date": "2024-03-05 18:24:52 UTC",
    "updated_date": "2024-12-20 20:00:11 UTC"
  },
  {
    "arxiv_id": "2403.03187v1",
    "title": "Reliable, Adaptable, and Attributable Language Models with Retrieval",
    "authors": [
      "Akari Asai",
      "Zexuan Zhong",
      "Danqi Chen",
      "Pang Wei Koh",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi",
      "Wen-tau Yih"
    ],
    "abstract": "Parametric language models (LMs), which are trained on vast amounts of web\ndata, exhibit remarkable flexibility and capability. However, they still face\npractical challenges such as hallucinations, difficulty in adapting to new data\ndistributions, and a lack of verifiability. In this position paper, we advocate\nfor retrieval-augmented LMs to replace parametric LMs as the next generation of\nLMs. By incorporating large-scale datastores during inference,\nretrieval-augmented LMs can be more reliable, adaptable, and attributable.\nDespite their potential, retrieval-augmented LMs have yet to be widely adopted\ndue to several obstacles: specifically, current retrieval-augmented LMs\nstruggle to leverage helpful text beyond knowledge-intensive tasks such as\nquestion answering, have limited interaction between retrieval and LM\ncomponents, and lack the infrastructure for scaling. To address these, we\npropose a roadmap for developing general-purpose retrieval-augmented LMs. This\ninvolves a reconsideration of datastores and retrievers, the exploration of\npipelines with improved retriever-LM interaction, and significant investment in\ninfrastructure for efficient training and inference.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03187v1",
    "published_date": "2024-03-05 18:22:33 UTC",
    "updated_date": "2024-03-05 18:22:33 UTC"
  },
  {
    "arxiv_id": "2403.03186v3",
    "title": "Cradle: Empowering Foundation Agents Towards General Computer Control",
    "authors": [
      "Weihao Tan",
      "Wentao Zhang",
      "Xinrun Xu",
      "Haochong Xia",
      "Ziluo Ding",
      "Boyu Li",
      "Bohan Zhou",
      "Junpeng Yue",
      "Jiechuan Jiang",
      "Yewen Li",
      "Ruyi An",
      "Molei Qin",
      "Chuqiao Zong",
      "Longtao Zheng",
      "Yujie Wu",
      "Xiaoqiang Chai",
      "Yifei Bi",
      "Tianbao Xie",
      "Pengjie Gu",
      "Xiyun Li",
      "Ceyao Zhang",
      "Long Tian",
      "Chaojie Wang",
      "Xinrun Wang",
      "BÃ¶rje F. Karlsson",
      "Bo An",
      "Shuicheng Yan",
      "Zongqing Lu"
    ],
    "abstract": "Despite the success in specific scenarios, existing foundation agents still\nstruggle to generalize across various virtual scenarios, mainly due to the\ndramatically different encapsulations of environments with manually designed\nobservation and action spaces. To handle this issue, we propose the General\nComputer Control (GCC) setting to restrict foundation agents to interact with\nsoftware through the most unified and standardized interface, i.e., using\nscreenshots as input and keyboard and mouse actions as output. We introduce\nCradle, a modular and flexible LMM-powered framework, as a preliminary attempt\ntowards GCC. Enhanced by six key modules, Cradle can understand input\nscreenshots and output executable code for low-level keyboard and mouse control\nafter high-level planning, so that Cradle can interact with any software and\ncomplete long-horizon complex tasks without relying on any built-in APIs.\nExperimental results show that Cradle exhibits remarkable generalizability and\nimpressive performance across four previously unexplored commercial video\ngames, five software applications, and a comprehensive benchmark, OSWorld.\nCradle is the first to enable foundation agents to follow the main storyline\nand complete 40-minute-long real missions in the complex AAA game Red Dead\nRedemption 2 (RDR2). Cradle can also create a city of a thousand people in\nCities: Skylines, farm and harvest parsnips in Stardew Valley, and trade and\nbargain with a maximal weekly total profit of 87% in Dealer's Life 2. Cradle\ncan not only operate daily software, like Chrome, Outlook, and Feishu, but also\nedit images and videos using Meitu and CapCut. Cradle greatly extends the reach\nof foundation agents by enabling the easy conversion of any software,\nespecially complex games, into benchmarks to evaluate agents' various abilities\nand facilitate further data collection, thus paving the way for generalist\nagents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03186v3",
    "published_date": "2024-03-05 18:22:29 UTC",
    "updated_date": "2024-07-02 17:23:13 UTC"
  },
  {
    "arxiv_id": "2403.03185v4",
    "title": "Correlated Proxies: A New Definition and Improved Mitigation for Reward Hacking",
    "authors": [
      "Cassidy Laidlaw",
      "Shivam Singhal",
      "Anca Dragan"
    ],
    "abstract": "Because it is difficult to precisely specify complex objectives,\nreinforcement learning policies are often optimized using proxy reward\nfunctions that only approximate the true goal. However, optimizing proxy\nrewards frequently leads to reward hacking: the optimized reward function\nceases to be a good proxy and the resulting policy performs poorly with respect\nto the unspecified true reward. Principled solutions to reward hacking have\nbeen impeded by the lack of a good definition for the problem. To address this\ngap, we introduce a definition of reward hacking based on the correlation\nbetween proxy and true rewards for states and actions seen by a \"reference\npolicy\" that breaks down under optimization. We show that this definition\ncaptures reward hacking behavior across several realistic settings, including\nin reinforcement learning from human feedback (RLHF). Using our formulation, we\nshow theoretically that regularization to the reference policy can effectively\nprevent reward hacking. While the current practice in RLHF applies a KL penalty\nbetween action distributions for this purpose, our theory suggests regularizing\nthe $\\chi^2$ divergence between the policies' occupancy measures can be more\neffective. We intuitively show the benefits of this type of regularization and\ndemonstrate that it better mitigates reward hacking in practice across four\nrealistic settings, including RLHF. Our code is available at\nhttps://github.com/cassidylaidlaw/orpo.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Spotlight at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.03185v4",
    "published_date": "2024-03-05 18:22:15 UTC",
    "updated_date": "2025-03-13 17:35:13 UTC"
  },
  {
    "arxiv_id": "2403.03183v1",
    "title": "How Well Can Transformers Emulate In-context Newton's Method?",
    "authors": [
      "Angeliki Giannou",
      "Liu Yang",
      "Tianhao Wang",
      "Dimitris Papailiopoulos",
      "Jason D. Lee"
    ],
    "abstract": "Transformer-based models have demonstrated remarkable in-context learning\ncapabilities, prompting extensive research into its underlying mechanisms.\nRecent studies have suggested that Transformers can implement first-order\noptimization algorithms for in-context learning and even second order ones for\nthe case of linear regression. In this work, we study whether Transformers can\nperform higher order optimization methods, beyond the case of linear\nregression. We establish that linear attention Transformers with ReLU layers\ncan approximate second order optimization algorithms for the task of logistic\nregression and achieve $\\epsilon$ error with only a logarithmic to the error\nmore layers. As a by-product we demonstrate the ability of even linear\nattention-only Transformers in implementing a single step of Newton's iteration\nfor matrix inversion with merely two layers. These results suggest the ability\nof the Transformer architecture to implement complex algorithms, beyond\ngradient descent.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03183v1",
    "published_date": "2024-03-05 18:20:10 UTC",
    "updated_date": "2024-03-05 18:20:10 UTC"
  },
  {
    "arxiv_id": "2403.03181v2",
    "title": "Behavior Generation with Latent Actions",
    "authors": [
      "Seungjae Lee",
      "Yibin Wang",
      "Haritheja Etukuru",
      "H. Jin Kim",
      "Nur Muhammad Mahi Shafiullah",
      "Lerrel Pinto"
    ],
    "abstract": "Generative modeling of complex behaviors from labeled datasets has been a\nlongstanding problem in decision making. Unlike language or image generation,\ndecision making requires modeling actions - continuous-valued vectors that are\nmultimodal in their distribution, potentially drawn from uncurated sources,\nwhere generation errors can compound in sequential prediction. A recent class\nof models called Behavior Transformers (BeT) addresses this by discretizing\nactions using k-means clustering to capture different modes. However, k-means\nstruggles to scale for high-dimensional action spaces or long sequences, and\nlacks gradient information, and thus BeT suffers in modeling long-range\nactions. In this work, we present Vector-Quantized Behavior Transformer\n(VQ-BeT), a versatile model for behavior generation that handles multimodal\naction prediction, conditional generation, and partial observations. VQ-BeT\naugments BeT by tokenizing continuous actions with a hierarchical vector\nquantization module. Across seven environments including simulated\nmanipulation, autonomous driving, and robotics, VQ-BeT improves on\nstate-of-the-art models such as BeT and Diffusion Policies. Importantly, we\ndemonstrate VQ-BeT's improved ability to capture behavior modes while\naccelerating inference speed 5x over Diffusion Policies. Videos and code can be\nfound https://sjlee.cc/vq-bet",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Github repo: https://github.com/jayLEE0301/vq_bet_official",
    "pdf_url": "http://arxiv.org/pdf/2403.03181v2",
    "published_date": "2024-03-05 18:19:29 UTC",
    "updated_date": "2024-06-28 04:15:33 UTC"
  },
  {
    "arxiv_id": "2403.03176v1",
    "title": "Unifying and Certifying Top-Quality Planning",
    "authors": [
      "Michael Katz",
      "Junkyu Lee",
      "Shirin Sohrabi"
    ],
    "abstract": "The growing utilization of planning tools in practical scenarios has sparked\nan interest in generating multiple high-quality plans. Consequently, a range of\ncomputational problems under the general umbrella of top-quality planning were\nintroduced over a short time period, each with its own definition. In this\nwork, we show that the existing definitions can be unified into one, based on a\ndominance relation. The different computational problems, therefore, simply\ncorrespond to different dominance relations. Given the unified definition, we\ncan now certify the top-quality of the solutions, leveraging existing\ncertification of unsolvability and optimality. We show that task\ntransformations found in the existing literature can be employed for the\nefficient certification of various top-quality planning problems and propose a\nnovel transformation to efficiently certify loopless top-quality planning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear at ICAPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03176v1",
    "published_date": "2024-03-05 18:13:18 UTC",
    "updated_date": "2024-03-05 18:13:18 UTC"
  },
  {
    "arxiv_id": "2403.03174v3",
    "title": "MOKA: Open-World Robotic Manipulation through Mark-Based Visual Prompting",
    "authors": [
      "Fangchen Liu",
      "Kuan Fang",
      "Pieter Abbeel",
      "Sergey Levine"
    ],
    "abstract": "Open-world generalization requires robotic systems to have a profound\nunderstanding of the physical world and the user command to solve diverse and\ncomplex tasks. While the recent advancement in vision-language models (VLMs)\nhas offered unprecedented opportunities to solve open-world problems, how to\nleverage their capabilities to control robots remains a grand challenge. In\nthis paper, we introduce Marking Open-world Keypoint Affordances (MOKA), an\napproach that employs VLMs to solve robotic manipulation tasks specified by\nfree-form language instructions. Central to our approach is a compact\npoint-based representation of affordance, which bridges the VLM's predictions\non observed images and the robot's actions in the physical world. By prompting\nthe pre-trained VLM, our approach utilizes the VLM's commonsense knowledge and\nconcept understanding acquired from broad data sources to predict affordances\nand generate motions. To facilitate the VLM's reasoning in zero-shot and\nfew-shot manners, we propose a visual prompting technique that annotates marks\non images, converting affordance reasoning into a series of visual\nquestion-answering problems that are solvable by the VLM. We further explore\nmethods to enhance performance with robot experiences collected by MOKA through\nin-context learning and policy distillation. We evaluate and analyze MOKA's\nperformance on various table-top manipulation tasks including tool use,\ndeformable body manipulation, and object rearrangement.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03174v3",
    "published_date": "2024-03-05 18:08:45 UTC",
    "updated_date": "2024-09-04 01:18:13 UTC"
  },
  {
    "arxiv_id": "2403.03172v1",
    "title": "Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning with Goal Imagination",
    "authors": [
      "Liangzhou Wang",
      "Kaiwen Zhu",
      "Fengming Zhu",
      "Xinghu Yao",
      "Shujie Zhang",
      "Deheng Ye",
      "Haobo Fu",
      "Qiang Fu",
      "Wei Yang"
    ],
    "abstract": "Reaching consensus is key to multi-agent coordination. To accomplish a\ncooperative task, agents need to coherently select optimal joint actions to\nmaximize the team reward. However, current cooperative multi-agent\nreinforcement learning (MARL) methods usually do not explicitly take consensus\ninto consideration, which may cause miscoordination problem. In this paper, we\npropose a model-based consensus mechanism to explicitly coordinate multiple\nagents. The proposed Multi-agent Goal Imagination (MAGI) framework guides\nagents to reach consensus with an Imagined common goal. The common goal is an\nachievable state with high value, which is obtained by sampling from the\ndistribution of future states. We directly model this distribution with a\nself-supervised generative model, thus alleviating the \"curse of dimensinality\"\nproblem induced by multi-agent multi-step policy rollout commonly used in\nmodel-based methods. We show that such efficient consensus mechanism can guide\nall agents cooperatively reaching valuable future states. Results on\nMulti-agent Particle-Environments and Google Research Football environment\ndemonstrate the superiority of MAGI in both sample efficiency and performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03172v1",
    "published_date": "2024-03-05 18:07:34 UTC",
    "updated_date": "2024-03-05 18:07:34 UTC"
  },
  {
    "arxiv_id": "2403.03170v1",
    "title": "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection",
    "authors": [
      "Peng Qi",
      "Zehong Yan",
      "Wynne Hsu",
      "Mong Li Lee"
    ],
    "abstract": "Misinformation is a prevalent societal issue due to its potential high risks.\nOut-of-context (OOC) misinformation, where authentic images are repurposed with\nfalse text, is one of the easiest and most effective ways to mislead audiences.\nCurrent methods focus on assessing image-text consistency but lack convincing\nexplanations for their judgments, which is essential for debunking\nmisinformation. While Multimodal Large Language Models (MLLMs) have rich\nknowledge and innate capability for visual reasoning and explanation\ngeneration, they still lack sophistication in understanding and discovering the\nsubtle crossmodal differences. In this paper, we introduce SNIFFER, a novel\nmultimodal large language model specifically engineered for OOC misinformation\ndetection and explanation. SNIFFER employs two-stage instruction tuning on\nInstructBLIP. The first stage refines the model's concept alignment of generic\nobjects with news-domain entities and the second stage leverages language-only\nGPT-4 generated OOC-specific instruction data to fine-tune the model's\ndiscriminatory powers. Enhanced by external tools and retrieval, SNIFFER not\nonly detects inconsistencies between text and image but also utilizes external\nknowledge for contextual verification. Our experiments show that SNIFFER\nsurpasses the original MLLM by over 40% and outperforms state-of-the-art\nmethods in detection accuracy. SNIFFER also provides accurate and persuasive\nexplanations as validated by quantitative and human evaluations.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.MM",
    "comment": "To appear in CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03170v1",
    "published_date": "2024-03-05 18:04:59 UTC",
    "updated_date": "2024-03-05 18:04:59 UTC"
  },
  {
    "arxiv_id": "2403.03168v1",
    "title": "Learning Explicitly Conditioned Sparsifying Transforms",
    "authors": [
      "Andrei PÄtraÅcu",
      "Cristian Rusu",
      "Paul Irofti"
    ],
    "abstract": "Sparsifying transforms became in the last decades widely known tools for\nfinding structured sparse representations of signals in certain transform\ndomains. Despite the popularity of classical transforms such as DCT and\nWavelet, learning optimal transforms that guarantee good representations of\ndata into the sparse domain has been recently analyzed in a series of papers.\nTypically, the conditioning number and representation ability are complementary\nkey features of learning square transforms that may not be explicitly\ncontrolled in a given optimization model. Unlike the existing approaches from\nthe literature, in our paper, we consider a new sparsifying transform model\nthat enforces explicit control over the data representation quality and the\ncondition number of the learned transforms. We confirm through numerical\nexperiments that our model presents better numerical behavior than the\nstate-of-the-art.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.OC"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03168v1",
    "published_date": "2024-03-05 18:03:51 UTC",
    "updated_date": "2024-03-05 18:03:51 UTC"
  },
  {
    "arxiv_id": "2403.03165v2",
    "title": "Leveraging Federated Learning and Edge Computing for Recommendation Systems within Cloud Computing Networks",
    "authors": [
      "Yaqian Qi",
      "Yuan Feng",
      "Xiangxiang Wang",
      "Hanzhe Li",
      "Jingxiao Tian"
    ],
    "abstract": "To enable large-scale and efficient deployment of artificial intelligence\n(AI), the combination of AI and edge computing has spawned Edge Intelligence,\nwhich leverages the computing and communication capabilities of end devices and\nedge servers to process data closer to where it is generated. A key technology\nfor edge intelligence is the privacy-protecting machine learning paradigm known\nas Federated Learning (FL), which enables data owners to train models without\nhaving to transfer raw data to third-party servers. However, FL networks are\nexpected to involve thousands of heterogeneous distributed devices. As a\nresult, communication efficiency remains a key bottleneck. To reduce node\nfailures and device exits, a Hierarchical Federated Learning (HFL) framework is\nproposed, where a designated cluster leader supports the data owner through\nintermediate model aggregation. Therefore, based on the improvement of edge\nserver resource utilization, this paper can effectively make up for the\nlimitation of cache capacity. In order to mitigate the impact of soft clicks on\nthe quality of user experience (QoE), the authors model the user QoE as a\ncomprehensive system cost. To solve the formulaic problem, the authors propose\na decentralized caching algorithm with federated deep reinforcement learning\n(DRL) and federated learning (FL), where multiple agents learn and make\ndecisions independently",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03165v2",
    "published_date": "2024-03-05 17:58:26 UTC",
    "updated_date": "2024-03-13 05:46:39 UTC"
  },
  {
    "arxiv_id": "2403.03154v2",
    "title": "Quantum Many-Body Physics Calculations with Large Language Models",
    "authors": [
      "Haining Pan",
      "Nayantara Mudur",
      "Will Taranto",
      "Maria Tikhanovskaya",
      "Subhashini Venugopalan",
      "Yasaman Bahri",
      "Michael P. Brenner",
      "Eun-Ah Kim"
    ],
    "abstract": "Large language models (LLMs) have demonstrated an unprecedented ability to\nperform complex tasks in multiple domains, including mathematical and\nscientific reasoning. We demonstrate that with carefully designed prompts, LLMs\ncan accurately carry out key calculations in research papers in theoretical\nphysics. We focus on a broadly used approximation method in quantum physics:\nthe Hartree-Fock method, requiring an analytic multi-step calculation deriving\napproximate Hamiltonian and corresponding self-consistency equations. To carry\nout the calculations using LLMs, we design multi-step prompt templates that\nbreak down the analytic calculation into standardized steps with placeholders\nfor problem-specific information. We evaluate GPT-4's performance in executing\nthe calculation for 15 research papers from the past decade, demonstrating\nthat, with correction of intermediate steps, it can correctly derive the final\nHartree-Fock Hamiltonian in 13 cases and makes minor errors in 2 cases.\nAggregating across all research papers, we find an average score of 87.5 (out\nof 100) on the execution of individual calculation steps. Overall, the\nrequisite skill for doing these calculations is at the graduate level in\nquantum condensed matter theory. We further use LLMs to mitigate the two\nprimary bottlenecks in this evaluation process: (i) extracting information from\npapers to fill in templates and (ii) automatic scoring of the calculation\nsteps, demonstrating good results in both cases. The strong performance is the\nfirst step for developing algorithms that automatically explore theoretical\nhypotheses at an unprecedented scale.",
    "categories": [
      "physics.comp-ph",
      "cond-mat.other",
      "cs.AI"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "9 pages, 4 figures. Supplemental material in the source file",
    "pdf_url": "http://arxiv.org/pdf/2403.03154v2",
    "published_date": "2024-03-05 17:47:22 UTC",
    "updated_date": "2024-08-22 22:42:40 UTC"
  },
  {
    "arxiv_id": "2403.03134v3",
    "title": "Simplicity in Complexity : Explaining Visual Complexity using Deep Segmentation Models",
    "authors": [
      "Tingke Shen",
      "Surabhi S Nath",
      "Aenne Brielmann",
      "Peter Dayan"
    ],
    "abstract": "The complexity of visual stimuli plays an important role in many cognitive\nphenomena, including attention, engagement, memorability, time perception and\naesthetic evaluation. Despite its importance, complexity is poorly understood\nand ironically, previous models of image complexity have been quite complex.\nThere have been many attempts to find handcrafted features that explain\ncomplexity, but these features are usually dataset specific, and hence fail to\ngeneralise. On the other hand, more recent work has employed deep neural\nnetworks to predict complexity, but these models remain difficult to interpret,\nand do not guide a theoretical understanding of the problem. Here we propose to\nmodel complexity using segment-based representations of images. We use\nstate-of-the-art segmentation models, SAM and FC-CLIP, to quantify the number\nof segments at multiple granularities, and the number of classes in an image\nrespectively. We find that complexity is well-explained by a simple linear\nmodel with these two features across six diverse image-sets of naturalistic\nscene and art images. This suggests that the complexity of images can be\nsurprisingly simple.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03134v3",
    "published_date": "2024-03-05 17:21:31 UTC",
    "updated_date": "2024-05-06 12:24:58 UTC"
  },
  {
    "arxiv_id": "2403.03114v2",
    "title": "Equilibria in Two-Stage Facility Location with Atomic Clients",
    "authors": [
      "Simon Krogmann",
      "Pascal Lenzner",
      "Alexander Skopalik",
      "Marc Uetz",
      "Marnix C. Vos"
    ],
    "abstract": "We consider competitive facility location as a two-stage multi-agent system\nwith two types of clients. For a given host graph with weighted clients on the\nvertices, first facility agents strategically select vertices for opening their\nfacilities. Then, the clients strategically select which of the opened\nfacilities in their neighborhood to patronize. Facilities want to attract as\nmuch client weight as possible, clients want to minimize congestion on the\nchosen facility.\n  All recently studied versions of this model assume that clients can split\ntheir weight strategically. We consider clients with unsplittable weights but\nallow mixed strategies. So clients may randomize over which facility to\npatronize. Besides modeling a natural client behavior, this subtle change\nyields drastic changes, e.g., for a given facility placement, qualitatively\ndifferent client equilibria are possible.\n  As our main result, we show that pure subgame perfect equilibria always exist\nif all client weights are identical. For this, we use a novel potential\nfunction argument, employing a hierarchical classification of the clients and\nsophisticated rounding in each step. In contrast, for non-identical clients, we\nshow that deciding the existence of even approximately stable states is\ncomputationally intractable. On the positive side, we give a tight bound of $2$\non the price of anarchy which implies high social welfare of equilibria, if\nthey exist.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "full version of the article at the 33rd International Joint\n  Conference on Artificial Intelligence (IJCAI-2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.03114v2",
    "published_date": "2024-03-05 16:56:09 UTC",
    "updated_date": "2024-07-09 15:31:11 UTC"
  },
  {
    "arxiv_id": "2403.03111v1",
    "title": "Improved LiDAR Odometry and Mapping using Deep Semantic Segmentation and Novel Outliers Detection",
    "authors": [
      "Mohamed Afifi",
      "Mohamed ElHelw"
    ],
    "abstract": "Perception is a key element for enabling intelligent autonomous navigation.\nUnderstanding the semantics of the surrounding environment and accurate vehicle\npose estimation are essential capabilities for autonomous vehicles, including\nself-driving cars and mobile robots that perform complex tasks. Fast moving\nplatforms like self-driving cars impose a hard challenge for localization and\nmapping algorithms. In this work, we propose a novel framework for real-time\nLiDAR odometry and mapping based on LOAM architecture for fast moving\nplatforms. Our framework utilizes semantic information produced by a deep\nlearning model to improve point-to-line and point-to-plane matching between\nLiDAR scans and build a semantic map of the environment, leading to more\naccurate motion estimation using LiDAR data. We observe that including semantic\ninformation in the matching process introduces a new type of outlier matches to\nthe process, where matching occur between different objects of the same\nsemantic class. To this end, we propose a novel algorithm that explicitly\nidentifies and discards potential outliers in the matching process. In our\nexperiments, we study the effect of improving the matching process on the\nrobustness of LiDAR odometry against high speed motion. Our experimental\nevaluations on KITTI dataset demonstrate that utilizing semantic information\nand rejecting outliers significantly enhance the robustness of LiDAR odometry\nand mapping when there are large gaps between scan acquisition poses, which is\ntypical for fast moving platforms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03111v1",
    "published_date": "2024-03-05 16:53:24 UTC",
    "updated_date": "2024-03-05 16:53:24 UTC"
  },
  {
    "arxiv_id": "2403.03102v4",
    "title": "\"In Dialogues We Learn\": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning",
    "authors": [
      "Chuanqi Cheng",
      "Quan Tu",
      "Shuo Shang",
      "Cunli Mao",
      "Zhengtao Yu",
      "Wei Wu",
      "Rui Yan"
    ],
    "abstract": "Personalized dialogue systems have gained significant attention in recent\nyears for their ability to generate responses in alignment with different\npersonas. However, most existing approaches rely on pre-defined personal\nprofiles, which are not only time-consuming and labor-intensive to create but\nalso lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning\nframework that enhances the ability of pre-trained large language models to\nleverage dialogue history to characterize persona for completing personalized\ndialogue generation tasks without pre-defined profiles. Our experiments on\nthree datasets demonstrate that IDL brings substantial improvements, with BLEU\nand ROUGE scores increasing by up to 200% and 247%, respectively. Additionally,\nthe results of human evaluations further validate the efficacy of our proposed\nmethod.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03102v4",
    "published_date": "2024-03-05 16:43:03 UTC",
    "updated_date": "2024-10-13 10:06:39 UTC"
  },
  {
    "arxiv_id": "2403.03101v3",
    "title": "KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents",
    "authors": [
      "Yuqi Zhu",
      "Shuofei Qiao",
      "Yixin Ou",
      "Shumin Deng",
      "Shiwei Lyu",
      "Yue Shen",
      "Lei Liang",
      "Jinjie Gu",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated great potential in complex\nreasoning tasks, yet they fall short when tackling more sophisticated\nchallenges, especially when interacting with environments through generating\nexecutable actions. This inadequacy primarily stems from the lack of built-in\naction knowledge in language agents, which fails to effectively guide the\nplanning trajectories during task solving and results in planning\nhallucination. To address this issue, we introduce KnowAgent, a novel approach\ndesigned to enhance the planning capabilities of LLMs by incorporating explicit\naction knowledge. Specifically, KnowAgent employs an action knowledge base and\na knowledgeable self-learning strategy to constrain the action path during\nplanning, enabling more reasonable trajectory synthesis, and thereby enhancing\nthe planning performance of language agents. Experimental results on HotpotQA\nand ALFWorld based on various backbone models demonstrate that KnowAgent can\nachieve comparable or superior performance to existing baselines. Further\nanalysis indicates the effectiveness of KnowAgent in terms of planning\nhallucinations mitigation. Code is available in\nhttps://github.com/zjunlp/KnowAgent.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Findings. Project page:\n  https://zjunlp.github.io/project/KnowAgent/ Code:\n  https://github.com/zjunlp/KnowAgent",
    "pdf_url": "http://arxiv.org/pdf/2403.03101v3",
    "published_date": "2024-03-05 16:39:12 UTC",
    "updated_date": "2025-02-21 05:04:27 UTC"
  },
  {
    "arxiv_id": "2403.03100v3",
    "title": "NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models",
    "authors": [
      "Zeqian Ju",
      "Yuancheng Wang",
      "Kai Shen",
      "Xu Tan",
      "Detai Xin",
      "Dongchao Yang",
      "Yanqing Liu",
      "Yichong Leng",
      "Kaitao Song",
      "Siliang Tang",
      "Zhizheng Wu",
      "Tao Qin",
      "Xiang-Yang Li",
      "Wei Ye",
      "Shikun Zhang",
      "Jiang Bian",
      "Lei He",
      "Jinyu Li",
      "Sheng Zhao"
    ],
    "abstract": "While recent large-scale text-to-speech (TTS) models have achieved\nsignificant progress, they still fall short in speech quality, similarity, and\nprosody. Considering speech intricately encompasses various attributes (e.g.,\ncontent, prosody, timbre, and acoustic details) that pose significant\nchallenges for generation, a natural idea is to factorize speech into\nindividual subspaces representing different attributes and generate them\nindividually. Motivated by it, we propose NaturalSpeech 3, a TTS system with\nnovel factorized diffusion models to generate natural speech in a zero-shot\nway. Specifically, 1) we design a neural codec with factorized vector\nquantization (FVQ) to disentangle speech waveform into subspaces of content,\nprosody, timbre, and acoustic details; 2) we propose a factorized diffusion\nmodel to generate attributes in each subspace following its corresponding\nprompt. With this factorization design, NaturalSpeech 3 can effectively and\nefficiently model intricate speech with disentangled subspaces in a\ndivide-and-conquer way. Experiments show that NaturalSpeech 3 outperforms the\nstate-of-the-art TTS systems on quality, similarity, prosody, and\nintelligibility, and achieves on-par quality with human recordings.\nFurthermore, we achieve better performance by scaling to 1B parameters and 200K\nhours of training data.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Achieving human-level quality and naturalness on multi-speaker\n  datasets (e.g., LibriSpeech) in a zero-shot way",
    "pdf_url": "http://arxiv.org/pdf/2403.03100v3",
    "published_date": "2024-03-05 16:35:25 UTC",
    "updated_date": "2024-04-23 08:38:03 UTC"
  },
  {
    "arxiv_id": "2403.03089v1",
    "title": "VQSynery: Robust Drug Synergy Prediction With Vector Quantization Mechanism",
    "authors": [
      "Jiawei Wu",
      "Mingyuan Yan",
      "Dianbo Liu"
    ],
    "abstract": "The pursuit of optimizing cancer therapies is significantly advanced by the\naccurate prediction of drug synergy. Traditional methods, such as clinical\ntrials, are reliable yet encumbered by extensive time and financial demands.\nThe emergence of high-throughput screening and computational innovations has\nheralded a shift towards more efficient methodologies for exploring drug\ninteractions. In this study, we present VQSynergy, a novel framework that\nemploys the Vector Quantization (VQ) mechanism, integrated with gated residuals\nand a tailored attention mechanism, to enhance the precision and\ngeneralizability of drug synergy predictions. Our findings demonstrate that\nVQSynergy surpasses existing models in terms of robustness, particularly under\nGaussian noise conditions, highlighting its superior performance and utility in\nthe complex and often noisy domain of drug synergy research. This study\nunderscores the potential of VQSynergy in revolutionizing the field through its\nadvanced predictive capabilities, thereby contributing to the optimization of\ncancer treatment strategies.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03089v1",
    "published_date": "2024-03-05 16:21:53 UTC",
    "updated_date": "2024-03-05 16:21:53 UTC"
  },
  {
    "arxiv_id": "2403.03082v1",
    "title": "Recall-Oriented Continual Learning with Generative Adversarial Meta-Model",
    "authors": [
      "Haneol Kang",
      "Dong-Wan Choi"
    ],
    "abstract": "The stability-plasticity dilemma is a major challenge in continual learning,\nas it involves balancing the conflicting objectives of maintaining performance\non previous tasks while learning new tasks. In this paper, we propose the\nrecall-oriented continual learning framework to address this challenge.\nInspired by the human brain's ability to separate the mechanisms responsible\nfor stability and plasticity, our framework consists of a two-level\narchitecture where an inference network effectively acquires new knowledge and\na generative network recalls past knowledge when necessary. In particular, to\nmaximize the stability of past knowledge, we investigate the complexity of\nknowledge depending on different representations, and thereby introducing\ngenerative adversarial meta-model (GAMM) that incrementally learns\ntask-specific parameters instead of input data samples of the task. Through our\nexperiments, we show that our framework not only effectively learns new\nknowledge without any disruption but also achieves high stability of previous\nknowledge in both task-aware and task-agnostic learning scenarios. Our code is\navailable at: https://github.com/bigdata-inha/recall-oriented-cl-framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in AAAI-2024 (Oral presentation)",
    "pdf_url": "http://arxiv.org/pdf/2403.03082v1",
    "published_date": "2024-03-05 16:08:59 UTC",
    "updated_date": "2024-03-05 16:08:59 UTC"
  },
  {
    "arxiv_id": "2403.03239v2",
    "title": "Note: Harnessing Tellurium Nanoparticles in the Digital Realm Plasmon Resonance, in the Context of Brewster's Angle and the Drude Model for Fake News Adsorption in Incomplete Information Games",
    "authors": [
      "Yasuko Kawahata"
    ],
    "abstract": "This note explores the innovative application of soliton theory and plasmonic\nphenomena in modeling user behavior and engagement within digital health\nplatforms. By introducing the concept of soliton solutions, we present a novel\napproach to understanding stable patterns of health improvement behaviors over\ntime. Additionally, we delve into the role of tellurium nanoparticles and their\nplasmonic properties in adsorbing fake news, thereby influencing user\ninteractions and engagement levels. Through a theoretical framework that\ncombines nonlinear dynamics with the unique characteristics of tellurium\nnanoparticles, we aim to provide new insights into the dynamics of user\nengagement in digital health environments. Our analysis highlights the\npotential of soliton theory in capturing the complex, nonlinear dynamics of\nuser behavior, while the application of plasmonic phenomena offers a promising\navenue for enhancing the sensitivity and effectiveness of digital health\nplatforms. This research ventures into an uncharted territory where optical\nphenomena such as Brewster's Angle and Snell's Law, along with the concept of\nspin solitons, are metaphorically applied to address the challenge of fake news\ndissemination. By exploring the analogy between light refraction, reflection,\nand the propagation of information in digital platforms, we unveil a novel\nperspective on how the 'angle' at which information is presented can\nsignificantly affect its acceptance and spread. Additionally, we propose the\nuse of tellurium nanoparticles to manage 'information waves' through mechanisms\nakin to plasmonic resonance and soliton dynamics. This theoretical exploration\naims to bridge the gap between physical sciences and digital communication,\noffering insights into the development of strategies for mitigating\nmisinformation.",
    "categories": [
      "physics.soc-ph",
      "cs.AI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "Tellurium Nanoparticles, Snell's Law, Soliton Solution, Anamorphic\n  Surfaces, Nonlinear Dynamics, Fake News Adsorption, User Behavior Modeling,\n  Health Improvement Strategies, Plasmonic Sensors This paper is partially an\n  attempt to utilize \"Generative AI\" and was written with educational intent.\n  There are currently no plans for it to become a peer-reviewed paper",
    "pdf_url": "http://arxiv.org/pdf/2403.03239v2",
    "published_date": "2024-03-05 16:07:57 UTC",
    "updated_date": "2024-04-19 14:58:00 UTC"
  },
  {
    "arxiv_id": "2403.03053v1",
    "title": "Neural Codebook Design for Network Beam Management",
    "authors": [
      "Ryan M. Dreifuerst",
      "Robert W. Heath Jr"
    ],
    "abstract": "Obtaining accurate and timely channel state information (CSI) is a\nfundamental challenge for large antenna systems. Mobile systems like 5G use a\nbeam management framework that joins the initial access, beamforming, CSI\nacquisition, and data transmission. The design of codebooks for these stages,\nhowever, is challenging due to their interrelationships, varying array sizes,\nand site-specific channel and user distributions. Furthermore, beam management\nis often focused on single-sector operations while ignoring the overarching\nnetwork- and system-level optimization. In this paper, we proposed an\nend-to-end learned codebook design algorithm, network beamspace learning (NBL),\nthat captures and optimizes codebooks to mitigate interference while maximizing\nthe achievable performance with extremely large hybrid arrays. The proposed\nalgorithm requires limited shared information yet designs codebooks that\noutperform traditional codebooks by over 10dB in beam alignment and achieve\nmore than 25% improvements in network spectral efficiency.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.IT",
      "cs.NI",
      "cs.SY",
      "eess.SY",
      "math.IT"
    ],
    "primary_category": "eess.SP",
    "comment": "To be submitted to IEEE Transactions on Wireless Communications",
    "pdf_url": "http://arxiv.org/pdf/2403.03053v1",
    "published_date": "2024-03-05 15:37:06 UTC",
    "updated_date": "2024-03-05 15:37:06 UTC"
  },
  {
    "arxiv_id": "2403.03030v1",
    "title": "Unifying Controller Design for Stabilizing Nonlinear Systems with Norm-Bounded Control Inputs",
    "authors": [
      "Ming Li",
      "Zhiyong Sun",
      "Siep Weiland"
    ],
    "abstract": "This paper revisits a classical challenge in the design of stabilizing\ncontrollers for nonlinear systems with a norm-bounded input constraint. By\nextending Lin-Sontag's universal formula and introducing a generic\n(state-dependent) scaling term, a unifying controller design method is\nproposed. The incorporation of this generic scaling term gives a unified\ncontroller and enables the derivation of alternative universal formulas with\nvarious favorable properties, which makes it suitable for tailored control\ndesigns to meet specific requirements and provides versatility across different\ncontrol scenarios. Additionally, we present a constructive approach to\ndetermine the optimal scaling term, leading to an explicit solution to an\noptimization problem, named optimization-based universal formula. The resulting\ncontroller ensures asymptotic stability, satisfies a norm-bounded input\nconstraint, and optimizes a predefined cost function. Finally, the essential\nproperties of the unified controllers are analyzed, including smoothness,\ncontinuity at the origin, stability margin, and inverse optimality. Simulations\nvalidate the approach, showcasing its effectiveness in addressing a challenging\nstabilizing control problem of a nonlinear system.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03030v1",
    "published_date": "2024-03-05 15:06:16 UTC",
    "updated_date": "2024-03-05 15:06:16 UTC"
  },
  {
    "arxiv_id": "2403.03028v1",
    "title": "Word Importance Explains How Prompts Affect Language Model Outputs",
    "authors": [
      "Stefan Hackmann",
      "Haniyeh Mahmoudian",
      "Mark Steadman",
      "Michael Schmidt"
    ],
    "abstract": "The emergence of large language models (LLMs) has revolutionized numerous\napplications across industries. However, their \"black box\" nature often hinders\nthe understanding of how they make specific decisions, raising concerns about\ntheir transparency, reliability, and ethical use. This study presents a method\nto improve the explainability of LLMs by varying individual words in prompts to\nuncover their statistical impact on the model outputs. This approach, inspired\nby permutation importance for tabular data, masks each word in the system\nprompt and evaluates its effect on the outputs based on the available text\nscores aggregated over multiple user inputs. Unlike classical attention, word\nimportance measures the impact of prompt words on arbitrarily-defined text\nscores, which enables decomposing the importance of words into the specific\nmeasures of interest--including bias, reading level, verbosity, etc. This\nprocedure also enables measuring impact when attention weights are not\navailable. To test the fidelity of this approach, we explore the effect of\nadding different suffixes to multiple different system prompts and comparing\nsubsequent generations with different large language models. Results show that\nword importance scores are closely related to the expected suffix importances\nfor multiple scoring functions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7; I.5.2"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03028v1",
    "published_date": "2024-03-05 15:04:18 UTC",
    "updated_date": "2024-03-05 15:04:18 UTC"
  },
  {
    "arxiv_id": "2403.03020v3",
    "title": "SplAgger: Split Aggregation for Meta-Reinforcement Learning",
    "authors": [
      "Jacob Beck",
      "Matthew Jackson",
      "Risto Vuorio",
      "Zheng Xiong",
      "Shimon Whiteson"
    ],
    "abstract": "A core ambition of reinforcement learning (RL) is the creation of agents\ncapable of rapid learning in novel tasks. Meta-RL aims to achieve this by\ndirectly learning such agents. Black box methods do so by training\noff-the-shelf sequence models end-to-end. By contrast, task inference methods\nexplicitly infer a posterior distribution over the unknown task, typically\nusing distinct objectives and sequence models designed to enable task\ninference. Recent work has shown that task inference methods are not necessary\nfor strong performance. However, it remains unclear whether task inference\nsequence models are beneficial even when task inference objectives are not. In\nthis paper, we present evidence that task inference sequence models are indeed\nstill beneficial. In particular, we investigate sequence models with\npermutation invariant aggregation, which exploit the fact that, due to the\nMarkov property, the task posterior does not depend on the order of data. We\nempirically confirm the advantage of permutation invariant sequence models\nwithout the use of task inference objectives. However, we also find,\nsurprisingly, that there are multiple conditions under which permutation\nvariance remains useful. Therefore, we propose SplAgger, which uses both\npermutation variant and invariant components to achieve the best of both\nworlds, outperforming all baselines evaluated on continuous control and memory\nenvironments. Code is provided at https://github.com/jacooba/hyper.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at Reinforcement Learning Conference (RLC) 2024. Code is\n  provided at https://github.com/jacooba/hyper",
    "pdf_url": "http://arxiv.org/pdf/2403.03020v3",
    "published_date": "2024-03-05 14:57:04 UTC",
    "updated_date": "2024-06-01 22:35:29 UTC"
  },
  {
    "arxiv_id": "2403.03017v1",
    "title": "OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following",
    "authors": [
      "Haochen Shi",
      "Zhiyuan Sun",
      "Xingdi Yuan",
      "Marc-Alexandre CÃ´tÃ©",
      "Bang Liu"
    ],
    "abstract": "Embodied Instruction Following (EIF) is a crucial task in embodied learning,\nrequiring agents to interact with their environment through egocentric\nobservations to fulfill natural language instructions. Recent advancements have\nseen a surge in employing large language models (LLMs) within a\nframework-centric approach to enhance performance in embodied learning tasks,\nincluding EIF. Despite these efforts, there exists a lack of a unified\nunderstanding regarding the impact of various components-ranging from visual\nperception to action execution-on task performance. To address this gap, we\nintroduce OPEx, a comprehensive framework that delineates the core components\nessential for solving embodied learning tasks: Observer, Planner, and Executor.\nThrough extensive evaluations, we provide a deep analysis of how each component\ninfluences EIF task performance. Furthermore, we innovate within this space by\ndeploying a multi-agent dialogue strategy on a TextWorld counterpart, further\nenhancing task performance. Our findings reveal that LLM-centric design\nmarkedly improves EIF outcomes, identify visual perception and low-level action\nexecution as critical bottlenecks, and demonstrate that augmenting LLMs with a\nmulti-agent framework further elevates performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03017v1",
    "published_date": "2024-03-05 14:53:53 UTC",
    "updated_date": "2024-03-05 14:53:53 UTC"
  },
  {
    "arxiv_id": "2403.03008v1",
    "title": "Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations",
    "authors": [
      "Hasan Abu-Rasheed",
      "Christian Weber",
      "Madjid Fathi"
    ],
    "abstract": "In the era of personalized education, the provision of comprehensible\nexplanations for learning recommendations is of a great value to enhance the\nlearner's understanding and engagement with the recommended learning content.\nLarge language models (LLMs) and generative AI in general have recently opened\nnew doors for generating human-like explanations, for and along learning\nrecommendations. However, their precision is still far away from acceptable in\na sensitive field like education. To harness the abilities of LLMs, while still\nensuring a high level of precision towards the intent of the learners, this\npaper proposes an approach to utilize knowledge graphs (KG) as a source of\nfactual context, for LLM prompts, reducing the risk of model hallucinations,\nand safeguarding against wrong or imprecise information, while maintaining an\napplication-intended learning context. We utilize the semantic relations in the\nknowledge graph to offer curated knowledge about learning recommendations. With\ndomain-experts in the loop, we design the explanation as a textual template,\nwhich is filled and completed by the LLM. Domain experts were integrated in the\nprompt engineering phase as part of a study, to ensure that explanations\ninclude information that is relevant to the learner. We evaluate our approach\nquantitatively using Rouge-N and Rouge-L measures, as well as qualitatively\nwith experts and learners. Our results show an enhanced recall and precision of\nthe generated explanations compared to those generated solely by the GPT model,\nwith a greatly reduced risk of generating imprecise information in the final\nlearning explanation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03008v1",
    "published_date": "2024-03-05 14:41:12 UTC",
    "updated_date": "2024-03-05 14:41:12 UTC"
  },
  {
    "arxiv_id": "2403.03002v1",
    "title": "Mem-elements based Neuromorphic Hardware for Neural Network Application",
    "authors": [
      "Ankur Singh"
    ],
    "abstract": "The thesis investigates the utilization of memristive and memcapacitive\ncrossbar arrays in low-power machine learning accelerators, offering a\ncomprehensive co-design framework for deep neural networks (DNN). The model,\nimplemented through a hybrid Python and PyTorch approach, accounts for various\nnon-idealities, achieving exceptional training accuracies of 90.02% and 91.03%\nfor the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on\nan 8-layer VGG network. Additionally, the thesis introduces a novel approach to\nemulate meminductor devices using Operational Transconductance Amplifiers (OTA)\nand capacitors, showcasing adjustable behavior. Transistor-level simulations in\n180 nm CMOS technology, operating at 60 MHz, demonstrate the proposed\nmeminductor emulator's viability with a power consumption of 0.337 mW. The\ndesign is further validated in neuromorphic circuits and CNN accelerators,\nachieving training and testing accuracies of 91.04% and 88.82%, respectively.\nNotably, the exclusive use of MOS transistors ensures the feasibility of\nmonolithic IC fabrication. This research significantly contributes to the\nexploration of advanced hardware solutions for efficient and high-performance\nmachine-learning applications.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.NE",
    "comment": "Master's Thesis",
    "pdf_url": "http://arxiv.org/pdf/2403.03002v1",
    "published_date": "2024-03-05 14:28:40 UTC",
    "updated_date": "2024-03-05 14:28:40 UTC"
  },
  {
    "arxiv_id": "2403.02995v1",
    "title": "Mitigating Label Flipping Attacks in Malicious URL Detectors Using Ensemble Trees",
    "authors": [
      "Ehsan Nowroozi",
      "Nada Jadalla",
      "Samaneh Ghelichkhani",
      "Alireza Jolfaei"
    ],
    "abstract": "Malicious URLs provide adversarial opportunities across various industries,\nincluding transportation, healthcare, energy, and banking which could be\ndetrimental to business operations. Consequently, the detection of these URLs\nis of crucial importance; however, current Machine Learning (ML) models are\nsusceptible to backdoor attacks. These attacks involve manipulating a small\npercentage of training data labels, such as Label Flipping (LF), which changes\nbenign labels to malicious ones and vice versa. This manipulation results in\nmisclassification and leads to incorrect model behavior. Therefore, integrating\ndefense mechanisms into the architecture of ML models becomes an imperative\nconsideration to fortify against potential attacks.\n  The focus of this study is on backdoor attacks in the context of URL\ndetection using ensemble trees. By illuminating the motivations behind such\nattacks, highlighting the roles of attackers, and emphasizing the critical\nimportance of effective defense strategies, this paper contributes to the\nongoing efforts to fortify ML models against adversarial threats within the ML\ndomain in network security. We propose an innovative alarm system that detects\nthe presence of poisoned labels and a defense mechanism designed to uncover the\noriginal class labels with the aim of mitigating backdoor attacks on ensemble\ntree classifiers. We conducted a case study using the Alexa and Phishing Site\nURL datasets and showed that LF attacks can be addressed using our proposed\ndefense mechanism. Our experimental results prove that the LF attack achieved\nan Attack Success Rate (ASR) between 50-65% within 2-5%, and the innovative\ndefense method successfully detected poisoned labels with an accuracy of up to\n100%.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02995v1",
    "published_date": "2024-03-05 14:21:57 UTC",
    "updated_date": "2024-03-05 14:21:57 UTC"
  },
  {
    "arxiv_id": "2403.02993v1",
    "title": "Localized Zeroth-Order Prompt Optimization",
    "authors": [
      "Wenyang Hu",
      "Yao Shu",
      "Zongmin Yu",
      "Zhaoxuan Wu",
      "Xiangqiang Lin",
      "Zhongxiang Dai",
      "See-Kiong Ng",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "The efficacy of large language models (LLMs) in understanding and generating\nnatural language has aroused a wide interest in developing prompt-based methods\nto harness the power of black-box LLMs. Existing methodologies usually\nprioritize a global optimization for finding the global optimum, which however\nwill perform poorly in certain tasks. This thus motivates us to re-think the\nnecessity of finding a global optimum in prompt optimization. To answer this,\nwe conduct a thorough empirical study on prompt optimization and draw two major\ninsights. Contrasting with the rarity of global optimum, local optima are\nusually prevalent and well-performed, which can be more worthwhile for\nefficient prompt optimization (Insight I). The choice of the input domain,\ncovering both the generation and the representation of prompts, affects the\nidentification of well-performing local optima (Insight II). Inspired by these\ninsights, we propose a novel algorithm, namely localized zeroth-order prompt\noptimization (ZOPO), which incorporates a Neural Tangent Kernel-based derived\nGaussian process into standard zeroth-order optimization for an efficient\nsearch of well-performing local optima in prompt optimization. Remarkably, ZOPO\noutperforms existing baselines in terms of both the optimization performance\nand the query efficiency, which we demonstrate through extensive experiments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02993v1",
    "published_date": "2024-03-05 14:18:15 UTC",
    "updated_date": "2024-03-05 14:18:15 UTC"
  },
  {
    "arxiv_id": "2403.02990v4",
    "title": "Data Augmentation using Large Language Models: Data Perspectives, Learning Paradigms and Challenges",
    "authors": [
      "Bosheng Ding",
      "Chengwei Qin",
      "Ruochen Zhao",
      "Tianze Luo",
      "Xinze Li",
      "Guizhen Chen",
      "Wenhan Xia",
      "Junjie Hu",
      "Anh Tuan Luu",
      "Shafiq Joty"
    ],
    "abstract": "In the rapidly evolving field of large language models (LLMs), data\naugmentation (DA) has emerged as a pivotal technique for enhancing model\nperformance by diversifying training examples without the need for additional\ndata collection. This survey explores the transformative impact of LLMs on DA,\nparticularly addressing the unique challenges and opportunities they present in\nthe context of natural language processing (NLP) and beyond. From both data and\nlearning perspectives, we examine various strategies that utilize LLMs for data\naugmentation, including a novel exploration of learning paradigms where\nLLM-generated data is used for diverse forms of further training. Additionally,\nthis paper highlights the primary open challenges faced in this domain, ranging\nfrom controllable data augmentation to multi-modal data augmentation. This\nsurvey highlights a paradigm shift introduced by LLMs in DA, and aims to serve\nas a comprehensive guide for researchers and practitioners.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02990v4",
    "published_date": "2024-03-05 14:11:54 UTC",
    "updated_date": "2024-07-02 07:59:40 UTC"
  },
  {
    "arxiv_id": "2403.02985v1",
    "title": "Evolution Transformer: In-Context Evolutionary Optimization",
    "authors": [
      "Robert Tjarko Lange",
      "Yingtao Tian",
      "Yujin Tang"
    ],
    "abstract": "Evolutionary optimization algorithms are often derived from loose biological\nanalogies and struggle to leverage information obtained during the sequential\ncourse of optimization. An alternative promising approach is to leverage data\nand directly discover powerful optimization principles via meta-optimization.\nIn this work, we follow such a paradigm and introduce Evolution Transformer, a\ncausal Transformer architecture, which can flexibly characterize a family of\nEvolution Strategies. Given a trajectory of evaluations and search distribution\nstatistics, Evolution Transformer outputs a performance-improving update to the\nsearch distribution. The architecture imposes a set of suitable inductive\nbiases, i.e. the invariance of the distribution update to the order of\npopulation members within a generation and equivariance to the order of the\nsearch dimensions. We train the model weights using Evolutionary Algorithm\nDistillation, a technique for supervised optimization of sequence models using\nteacher algorithm trajectories. The resulting model exhibits strong in-context\noptimization performance and shows strong generalization capabilities to\notherwise challenging neuroevolution tasks. We analyze the resulting properties\nof the Evolution Transformer and propose a technique to fully\nself-referentially train the Evolution Transformer, starting from a random\ninitialization and bootstrapping its own learning progress. We provide an open\nsource implementation under https://github.com/RobertTLange/evosax.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02985v1",
    "published_date": "2024-03-05 14:04:13 UTC",
    "updated_date": "2024-03-05 14:04:13 UTC"
  },
  {
    "arxiv_id": "2403.02983v1",
    "title": "Federated Learning Under Attack: Exposing Vulnerabilities through Data Poisoning Attacks in Computer Networks",
    "authors": [
      "Ehsan Nowroozi",
      "Imran Haider",
      "Rahim Taheri",
      "Mauro Conti"
    ],
    "abstract": "Federated Learning (FL) is a machine learning (ML) approach that enables\nmultiple decentralized devices or edge servers to collaboratively train a\nshared model without exchanging raw data. During the training and sharing of\nmodel updates between clients and servers, data and models are susceptible to\ndifferent data-poisoning attacks.\n  In this study, our motivation is to explore the severity of data poisoning\nattacks in the computer network domain because they are easy to implement but\ndifficult to detect. We considered two types of data-poisoning attacks, label\nflipping (LF) and feature poisoning (FP), and applied them with a novel\napproach. In LF, we randomly flipped the labels of benign data and trained the\nmodel on the manipulated data. For FP, we randomly manipulated the highly\ncontributing features determined using the Random Forest algorithm. The\ndatasets used in this experiment were CIC and UNSW related to computer\nnetworks. We generated adversarial samples using the two attacks mentioned\nabove, which were applied to a small percentage of datasets. Subsequently, we\ntrained and tested the accuracy of the model on adversarial datasets. We\nrecorded the results for both benign and manipulated datasets and observed\nsignificant differences between the accuracy of the models on different\ndatasets. From the experimental results, it is evident that the LF attack\nfailed, whereas the FP attack showed effective results, which proved its\nsignificance in fooling a server. With a 1% LF attack on the CIC, the accuracy\nwas approximately 0.0428 and the ASR was 0.9564; hence, the attack is easily\ndetectable, while with a 1% FP attack, the accuracy and ASR were both\napproximately 0.9600, hence, FP attacks are difficult to detect. We repeated\nthe experiment with different poisoning percentages.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02983v1",
    "published_date": "2024-03-05 14:03:15 UTC",
    "updated_date": "2024-03-05 14:03:15 UTC"
  },
  {
    "arxiv_id": "2403.02975v2",
    "title": "A General and Flexible Multi-concept Parsing Framework for Multilingual Semantic Matching",
    "authors": [
      "Dong Yao"
    ],
    "abstract": "Sentence semantic matching is a research hotspot in natural language\nprocessing, which is considerably significant in various key scenarios, such as\ncommunity question answering, searching, chatbot, and recommendation. Since\nmost of the advanced models directly model the semantic relevance among words\nbetween two sentences while neglecting the \\textit{keywords} and\n\\textit{intents} concepts of them, DC-Match is proposed to disentangle keywords\nfrom intents and utilizes them to optimize the matching performance. Although\nDC-Match is a simple yet effective method for semantic matching, it highly\ndepends on the external NER techniques to identify the keywords of sentences,\nwhich limits the performance of semantic matching for minor languages since\nsatisfactory NER tools are usually hard to obtain. In this paper, we propose to\ngenerally and flexibly resolve the text into multi concepts for multilingual\nsemantic matching to liberate the model from the reliance on NER models. To\nthis end, we devise a \\underline{M}ulti-\\underline{C}oncept \\underline{P}arsed\n\\underline{S}emantic \\underline{M}atching framework based on the pre-trained\nlanguage models, abbreviated as \\textbf{MCP-SM}, to extract various concepts\nand infuse them into the classification tokens. We conduct comprehensive\nexperiments on English datasets QQP and MRPC, and Chinese dataset Medical-SM.\nBesides, we experiment on Arabic datasets MQ2Q and XNLI, the outstanding\nperformance further prove MCP-SM's applicability in low-resource languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin comment: This version has been removed by arXiv\n  administrators as the submitter did not have the rights to agree to the\n  license at the time of submission",
    "pdf_url": "http://arxiv.org/pdf/2403.02975v2",
    "published_date": "2024-03-05 13:55:16 UTC",
    "updated_date": "2024-04-04 01:07:24 UTC"
  },
  {
    "arxiv_id": "2403.02966v3",
    "title": "Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering",
    "authors": [
      "Sungho Ko",
      "Hyunjin Cho",
      "Hyungjoo Chae",
      "Jinyoung Yeo",
      "Dongha Lee"
    ],
    "abstract": "Recent studies have investigated utilizing Knowledge Graphs (KGs) to enhance\nQuesetion Answering (QA) performance of Large Language Models (LLMs), yet\nstructured KG verbalization remains challengin. Existing methods, such as\ntriple-form or free-form textual conversion of triple-form facts, encounter\nseveral issues. These include reduced evidence density due to duplicated\nentities or relationships, and reduced evidence clarity due to an inability to\nemphasize crucial evidence. To address these issues, we propose EFSum, an\nEvidence-focused Fact Summarization framework for enhanced QA with\nknowledge-augmented LLMs. We optimize an open-source LLM as a fact summarizer\nthrough distillation and preference alignment. Our extensive experiments show\nthat EFSum improves LLM's zero-shot QA performance, and it is possible to\nensure both the helpfulness and faithfulness of the summary.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02966v3",
    "published_date": "2024-03-05 13:43:58 UTC",
    "updated_date": "2024-10-09 12:46:40 UTC"
  },
  {
    "arxiv_id": "2403.02965v2",
    "title": "ChatGPT and biometrics: an assessment of face recognition, gender detection, and age estimation capabilities",
    "authors": [
      "Ahmad Hassanpour",
      "Yasamin Kowsari",
      "Hatef Otroshi Shahreza",
      "Bian Yang",
      "Sebastien Marcel"
    ],
    "abstract": "This paper explores the application of large language models (LLMs), like\nChatGPT, for biometric tasks. We specifically examine the capabilities of\nChatGPT in performing biometric-related tasks, with an emphasis on face\nrecognition, gender detection, and age estimation. Since biometrics are\nconsidered as sensitive information, ChatGPT avoids answering direct prompts,\nand thus we crafted a prompting strategy to bypass its safeguard and evaluate\nthe capabilities for biometrics tasks. Our study reveals that ChatGPT\nrecognizes facial identities and differentiates between two facial images with\nconsiderable accuracy. Additionally, experimental results demonstrate\nremarkable performance in gender detection and reasonable accuracy for the age\nestimation tasks. Our findings shed light on the promising potentials in the\napplication of LLMs and foundation models for biometrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a conference paper at IEEE International Conference on\n  Image Processing (ICIP) 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02965v2",
    "published_date": "2024-03-05 13:41:25 UTC",
    "updated_date": "2024-12-11 09:30:19 UTC"
  },
  {
    "arxiv_id": "2403.02962v1",
    "title": "WikiTableEdit: A Benchmark for Table Editing by Natural Language Instruction",
    "authors": [
      "Zheng Li",
      "Xiang Chen",
      "Xiaojun Wan"
    ],
    "abstract": "Tabular data, as a crucial form of data representation, exists in diverse\nformats on the Web. When confronted with complex and irregular tables, manual\nmodification becomes a laborious task. This paper investigates the performance\nof Large Language Models (LLMs) in the context of table editing tasks. Existing\nresearch mainly focuses on regular-shaped tables, wherein instructions are used\nto generate code in SQL, Python, or Excel Office-script for manipulating the\ntables. Nevertheless, editing tables with irregular structures, particularly\nthose containing merged cells spanning multiple rows, poses a challenge when\nusing code. To address this, we introduce the WikiTableEdit dataset. Leveraging\n26,531 tables from the WikiSQL dataset, we automatically generate natural\nlanguage instructions for six distinct basic operations and the corresponding\noutcomes, resulting in over 200,000 instances. Subsequently, we evaluate\nseveral representative large language models on the WikiTableEdit dataset to\ndemonstrate the challenge of this task. The dataset will be released to the\ncommunity to promote related researches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02962v1",
    "published_date": "2024-03-05 13:33:12 UTC",
    "updated_date": "2024-03-05 13:33:12 UTC"
  },
  {
    "arxiv_id": "2403.02959v3",
    "title": "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation",
    "authors": [
      "Zhitao He",
      "Pengfei Cao",
      "Chenhao Wang",
      "Zhuoran Jin",
      "Yubo Chen",
      "Jiexin Xu",
      "Huaijun Li",
      "Xiaojian Jiang",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "With the development of deep learning, natural language processing technology\nhas effectively improved the efficiency of various aspects of the traditional\njudicial industry. However, most current efforts focus on tasks within\nindividual judicial stages, making it difficult to handle complex tasks that\nspan multiple stages. As the autonomous agents powered by large language models\nare becoming increasingly smart and able to make complex decisions in\nreal-world settings, offering new insights for judicial intelligence. In this\npaper, (1) we propose a novel multi-agent framework, AgentsCourt, for judicial\ndecision-making. Our framework follows the classic court trial process,\nconsisting of court debate simulation, legal resources retrieval and\ndecision-making refinement to simulate the decision-making of judge. (2) we\nintroduce SimuCourt, a judicial benchmark that encompasses 420 Chinese judgment\ndocuments, spanning the three most common types of judicial cases. Furthermore,\nto support this task, we construct a large-scale legal knowledge base,\nLegal-KB, with multi-resource legal knowledge. (3) Extensive experiments show\nthat our framework outperforms the existing advanced methods in various\naspects, especially in generating legal articles, where our model achieves\nsignificant improvements of 8.6% and 9.1% F1 score in the first and second\ninstance settings, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2403.02959v3",
    "published_date": "2024-03-05 13:30:02 UTC",
    "updated_date": "2024-09-21 14:49:53 UTC"
  },
  {
    "arxiv_id": "2405.06642v4",
    "title": "PPFlow: Target-aware Peptide Design with Torsional Flow Matching",
    "authors": [
      "Haitao Lin",
      "Odin Zhang",
      "Huifeng Zhao",
      "Dejun Jiang",
      "Lirong Wu",
      "Zicheng Liu",
      "Yufei Huang",
      "Stan Z. Li"
    ],
    "abstract": "Therapeutic peptides have proven to have great pharmaceutical value and\npotential in recent decades. However, methods of AI-assisted peptide drug\ndiscovery are not fully explored. To fill the gap, we propose a target-aware\npeptide design method called \\textsc{PPFlow}, based on conditional flow\nmatching on torus manifolds, to model the internal geometries of torsion angles\nfor the peptide structure design. Besides, we establish a protein-peptide\nbinding dataset named PPBench2024 to fill the void of massive data for the task\nof structure-based peptide drug design and to allow the training of deep\nlearning methods. Extensive experiments show that PPFlow reaches\nstate-of-the-art performance in tasks of peptide drug generation and\noptimization in comparison with baseline models, and can be generalized to\nother tasks including docking and side-chain packing.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.06642v4",
    "published_date": "2024-03-05 13:26:42 UTC",
    "updated_date": "2024-12-09 11:49:18 UTC"
  },
  {
    "arxiv_id": "2403.02951v2",
    "title": "Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation",
    "authors": [
      "Bin Zhang",
      "Yuxiao Ye",
      "Guoqing Du",
      "Xiaoru Hu",
      "Zhishuai Li",
      "Sun Yang",
      "Chi Harold Liu",
      "Rui Zhao",
      "Ziyue Li",
      "Hangyu Mao"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as a powerful tool in advancing the\nText-to-SQL task, significantly outperforming traditional methods.\nNevertheless, as a nascent research field, there is still no consensus on the\noptimal prompt templates and design frameworks. Additionally, existing\nbenchmarks inadequately explore the performance of LLMs across the various\nsub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs'\ncognitive capabilities and the optimization of LLM-based solutions. To address\nthe aforementioned issues, we firstly construct a new dataset designed to\nmitigate the risk of overfitting in LLMs. Then we formulate five evaluation\ntasks to comprehensively assess the performance of diverse methods across\nvarious LLMs throughout the Text-to-SQL process.Our study highlights the\nperformance disparities among LLMs and proposes optimal in-context learning\nsolutions tailored to each task. These findings offer valuable insights for\nenhancing the development of LLM-based Text-to-SQL systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "26pages, 6figures, 14tables",
    "pdf_url": "http://arxiv.org/pdf/2403.02951v2",
    "published_date": "2024-03-05 13:23:48 UTC",
    "updated_date": "2024-03-06 08:43:17 UTC"
  },
  {
    "arxiv_id": "2403.02950v1",
    "title": "A general approach to enhance the survivability of backdoor attacks by decision path coupling",
    "authors": [
      "Yufei Zhao",
      "Dingji Wang",
      "Bihuan Chen",
      "Ziqian Chen",
      "Xin Peng"
    ],
    "abstract": "Backdoor attacks have been one of the emerging security threats to deep\nneural networks (DNNs), leading to serious consequences. One of the mainstream\nbackdoor defenses is model reconstruction-based. Such defenses adopt model\nunlearning or pruning to eliminate backdoors. However, little attention has\nbeen paid to survive from such defenses. To bridge the gap, we propose Venom,\nthe first generic backdoor attack enhancer to improve the survivability of\nexisting backdoor attacks against model reconstruction-based defenses. We\nformalize Venom as a binary-task optimization problem. The first is the\noriginal backdoor attack task to preserve the original attack capability, while\nthe second is the attack enhancement task to improve the attack survivability.\nTo realize the second task, we propose attention imitation loss to force the\ndecision path of poisoned samples in backdoored models to couple with the\ncrucial decision path of benign samples, which makes backdoors difficult to\neliminate. Our extensive evaluation on two DNNs and three datasets has\ndemonstrated that Venom significantly improves the survivability of eight\nstate-of-the-art attacks against eight state-of-the-art defenses without\nimpacting the capability of the original attacks.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02950v1",
    "published_date": "2024-03-05 13:21:20 UTC",
    "updated_date": "2024-03-05 13:21:20 UTC"
  },
  {
    "arxiv_id": "2403.02946v1",
    "title": "SAFFIRA: a Framework for Assessing the Reliability of Systolic-Array-Based DNN Accelerators",
    "authors": [
      "Mahdi Taheri",
      "Masoud Daneshtalab",
      "Jaan Raik",
      "Maksim Jenihhin",
      "Salvatore Pappalardo",
      "Paul Jimenez",
      "Bastien Deveautour",
      "Alberto Bosio"
    ],
    "abstract": "Systolic array has emerged as a prominent architecture for Deep Neural\nNetwork (DNN) hardware accelerators, providing high-throughput and low-latency\nperformance essential for deploying DNNs across diverse applications. However,\nwhen used in safety-critical applications, reliability assessment is mandatory\nto guarantee the correct behavior of DNN accelerators. While fault injection\nstands out as a well-established practical and robust method for reliability\nassessment, it is still a very time-consuming process. This paper addresses the\ntime efficiency issue by introducing a novel hierarchical software-based\nhardware-aware fault injection strategy tailored for systolic array-based DNN\naccelerators.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02946v1",
    "published_date": "2024-03-05 13:17:09 UTC",
    "updated_date": "2024-03-05 13:17:09 UTC"
  },
  {
    "arxiv_id": "2403.02939v2",
    "title": "PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers",
    "authors": [
      "Yoonjoo Lee",
      "Hyeonsu B. Kang",
      "Matt Latzke",
      "Juho Kim",
      "Jonathan Bragg",
      "Joseph Chee Chang",
      "Pao Siangliulue"
    ],
    "abstract": "With the rapid growth of scholarly archives, researchers subscribe to \"paper\nalert\" systems that periodically provide them with recommendations of recently\npublished papers that are similar to previously collected papers. However,\nresearchers sometimes struggle to make sense of nuanced connections between\nrecommended papers and their own research context, as existing systems only\npresent paper titles and abstracts. To help researchers spot these connections,\nwe present PaperWeaver, an enriched paper alerts system that provides\ncontextualized text descriptions of recommended papers based on user-collected\npapers. PaperWeaver employs a computational method based on Large Language\nModels (LLMs) to infer users' research interests from their collected papers,\nextract context-specific aspects of papers, and compare recommended and\ncollected papers on these aspects. Our user study (N=15) showed that\nparticipants using PaperWeaver were able to better understand the relevance of\nrecommended papers and triage them more confidently when compared to a baseline\nthat presented the related work sections from recommended papers.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.DL",
    "comment": "Accepted to CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02939v2",
    "published_date": "2024-03-05 13:10:06 UTC",
    "updated_date": "2024-05-09 07:59:01 UTC"
  },
  {
    "arxiv_id": "2403.02936v1",
    "title": "AdAM: Adaptive Fault-Tolerant Approximate Multiplier for Edge DNN Accelerators",
    "authors": [
      "Mahdi Taheri",
      "Natalia Cherezova",
      "Samira Nazari",
      "Ahsan Rafiq",
      "Ali Azarpeyvand",
      "Tara Ghasempouri",
      "Masoud Daneshtalab",
      "Jaan Raik",
      "Maksim Jenihhin"
    ],
    "abstract": "In this paper, we propose an architecture of a novel adaptive fault-tolerant\napproximate multiplier tailored for ASIC-based DNN accelerators.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02936v1",
    "published_date": "2024-03-05 13:03:31 UTC",
    "updated_date": "2024-03-05 13:03:31 UTC"
  },
  {
    "arxiv_id": "2403.02933v1",
    "title": "Fuzzy Datalog$^\\exists$ over Arbitrary t-Norms",
    "authors": [
      "Matthias Lanzinger",
      "Stefano Sferrazza",
      "PrzemysÅaw A. WaÅÄga",
      "Georg Gottlob"
    ],
    "abstract": "One of the main challenges in the area of Neuro-Symbolic AI is to perform\nlogical reasoning in the presence of both neural and symbolic data. This\nrequires combining heterogeneous data sources such as knowledge graphs, neural\nmodel predictions, structured databases, crowd-sourced data, and many more. To\nallow for such reasoning, we generalise the standard rule-based language\nDatalog with existential rules (commonly referred to as tuple-generating\ndependencies) to the fuzzy setting, by allowing for arbitrary t-norms in the\nplace of classical conjunctions in rule bodies. The resulting formalism allows\nus to perform reasoning about data associated with degrees of uncertainty while\npreserving computational complexity results and the applicability of reasoning\ntechniques established for the standard Datalog setting. In particular, we\nprovide fuzzy extensions of Datalog chases which produce fuzzy universal models\nand we exploit them to show that in important fragments of the language,\nreasoning has the same complexity as in the classical setting.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02933v1",
    "published_date": "2024-03-05 12:51:40 UTC",
    "updated_date": "2024-03-05 12:51:40 UTC"
  },
  {
    "arxiv_id": "2403.02920v2",
    "title": "TaylorShift: Shifting the Complexity of Self-Attention from Squared to Linear (and Back) using Taylor-Softmax",
    "authors": [
      "Tobias Christian Nauen",
      "Sebastian Palacio",
      "Andreas Dengel"
    ],
    "abstract": "The quadratic complexity of the attention mechanism represents one of the\nbiggest hurdles for processing long sequences using Transformers. Current\nmethods, relying on sparse representations or stateful recurrence, sacrifice\ntoken-to-token interactions, which ultimately leads to compromises in\nperformance. This paper introduces TaylorShift, a novel reformulation of the\nTaylor softmax that enables computing full token-to-token interactions in\nlinear time and space. We analytically determine the crossover points where\nemploying TaylorShift becomes more efficient than traditional attention,\naligning closely with empirical measurements. Specifically, our findings\ndemonstrate that TaylorShift enhances memory efficiency for sequences as short\nas 800 tokens and accelerates inference for inputs of approximately 1700 tokens\nand beyond. For shorter sequences, TaylorShift scales comparably with the\nvanilla attention. Furthermore, a classification benchmark across five tasks\ninvolving long sequences reveals no degradation in accuracy when employing\nTransformers equipped with TaylorShift. For reproducibility, we provide access\nto our code under https://github.com/tobna/TaylorShift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07",
      "I.5.1; I.2.10; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02920v2",
    "published_date": "2024-03-05 12:38:14 UTC",
    "updated_date": "2024-07-17 14:32:01 UTC"
  },
  {
    "arxiv_id": "2403.02914v2",
    "title": "DynST: Dynamic Sparse Training for Resource-Constrained Spatio-Temporal Forecasting",
    "authors": [
      "Hao Wu",
      "Haomin Wen",
      "Guibin Zhang",
      "Yutong Xia",
      "Yuxuan Liang",
      "Yu Zheng",
      "Qingsong Wen",
      "Kun Wang"
    ],
    "abstract": "The ever-increasing sensor service, though opening a precious path and\nproviding a deluge of earth system data for deep-learning-oriented earth\nscience, sadly introduce a daunting obstacle to their industrial level\ndeployment. Concretely, earth science systems rely heavily on the extensive\ndeployment of sensors, however, the data collection from sensors is constrained\nby complex geographical and social factors, making it challenging to achieve\ncomprehensive coverage and uniform deployment. To alleviate the obstacle,\ntraditional approaches to sensor deployment utilize specific algorithms to\ndesign and deploy sensors. These methods \\textit{dynamically adjust the\nactivation times of sensors to optimize the detection process across each\nsub-region}. Regrettably, formulating an activation strategy generally based on\nhistorical observations and geographic characteristics, which make the methods\nand resultant models were neither simple nor practical. Worse still, the\ncomplex technical design may ultimately lead to a model with weak\ngeneralizability. In this paper, we introduce for the first time the concept of\nspatio-temporal data dynamic sparse training and are committed to adaptively,\ndynamically filtering important sensor distributions. To our knowledge, this is\nthe \\textbf{first} proposal (\\textit{termed DynST}) of an\n\\textbf{industry-level} deployment optimization concept at the data level.\nHowever, due to the existence of the temporal dimension, pruning of\nspatio-temporal data may lead to conflicts at different timestamps. To achieve\nthis goal, we employ dynamic merge technology, along with ingenious dimensional\nmapping to mitigate potential impacts caused by the temporal aspect. During the\ntraining process, DynST utilize iterative pruning and sparse training,\nrepeatedly identifying and dynamically removing sensor perception areas that\ncontribute the least to future predictions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02914v2",
    "published_date": "2024-03-05 12:31:24 UTC",
    "updated_date": "2025-01-16 02:10:39 UTC"
  },
  {
    "arxiv_id": "2403.04799v1",
    "title": "AI Literacy in Low-Resource Languages:Insights from creating AI in Yoruba videos",
    "authors": [
      "Wuraola Oyewusi"
    ],
    "abstract": "To effectively navigate the AI revolution, AI literacy is crucial. However,\ncontent predominantly exists in dominant languages, creating a gap for\nlow-resource languages like Yoruba (41 million native speakers). This case\nstudy explores bridging this gap by creating and distributing AI videos in\nYoruba.The project developed 26 videos covering foundational, intermediate, and\nadvanced AI concepts, leveraging storytelling and accessible explanations.\nThese videos were created using a cost-effective methodology and distributed\nacross YouTube, LinkedIn, and Twitter, reaching an estimated global audience of\n22 countries. Analysis of YouTube reveals insights into viewing patterns, with\nthe 25-44 age group contributing the most views. Notably, over half of the\ntraffic originated from external sources, highlighting the potential of\ncross-platform promotion.This study demonstrates the feasibility and impact of\ncreating AI literacy content in low-resource languages. It emphasizes that\naccurate interpretation requires both technical expertise in AI and fluency in\nthe target language. This work contributes a replicable methodology, a 22-word\nYoruba AI vocabulary, and data-driven insights into audience demographics and\nacquisition channel",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the Global AI Cultures Workshop, ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.04799v1",
    "published_date": "2024-03-05 12:27:28 UTC",
    "updated_date": "2024-03-05 12:27:28 UTC"
  },
  {
    "arxiv_id": "2403.02910v3",
    "title": "ImgTrojan: Jailbreaking Vision-Language Models with ONE Image",
    "authors": [
      "Xijia Tao",
      "Shuai Zhong",
      "Lei Li",
      "Qi Liu",
      "Lingpeng Kong"
    ],
    "abstract": "There has been an increasing interest in the alignment of large language\nmodels (LLMs) with human values. However, the safety issues of their\nintegration with a vision module, or vision language models (VLMs), remain\nrelatively underexplored. In this paper, we propose a novel jailbreaking attack\nagainst VLMs, aiming to bypass their safety barrier when a user inputs harmful\ninstructions. A scenario where our poisoned (image, text) data pairs are\nincluded in the training data is assumed. By replacing the original textual\ncaptions with malicious jailbreak prompts, our method can perform jailbreak\nattacks with the poisoned images. Moreover, we analyze the effect of poison\nratios and positions of trainable parameters on our attack's success rate. For\nevaluation, we design two metrics to quantify the success rate and the\nstealthiness of our attack. Together with a list of curated harmful\ninstructions, a benchmark for measuring attack efficacy is provided. We\ndemonstrate the efficacy of our attack by comparing it with baseline methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02910v3",
    "published_date": "2024-03-05 12:21:57 UTC",
    "updated_date": "2025-02-05 13:20:24 UTC"
  },
  {
    "arxiv_id": "2403.02901v2",
    "title": "A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods",
    "authors": [
      "Yang Zhang",
      "Hanlei Jin",
      "Dan Meng",
      "Jun Wang",
      "Jinghua Tan"
    ],
    "abstract": "Automatic Text Summarization (ATS), utilizing Natural Language Processing\n(NLP) algorithms, aims to create concise and accurate summaries, thereby\nsignificantly reducing the human effort required in processing large volumes of\ntext. ATS has drawn considerable interest in both academic and industrial\ncircles. Many studies have been conducted in the past to survey ATS methods;\nhowever, they generally lack practicality for real-world implementations, as\nthey often categorize previous methods from a theoretical standpoint. Moreover,\nthe advent of Large Language Models (LLMs) has altered conventional ATS\nmethods. In this survey, we aim to 1) provide a comprehensive overview of ATS\nfrom a ``Process-Oriented Schema'' perspective, which is best aligned with\nreal-world implementations; 2) comprehensively review the latest LLM-based ATS\nworks; and 3) deliver an up-to-date survey of ATS, bridging the two-year gap in\nthe literature. To the best of our knowledge, this is the first survey to\nspecifically investigate LLM-based ATS methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02901v2",
    "published_date": "2024-03-05 12:11:07 UTC",
    "updated_date": "2025-03-20 07:02:55 UTC"
  },
  {
    "arxiv_id": "2403.02899v1",
    "title": "Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation",
    "authors": [
      "Zhekai Du",
      "Xinyao Li",
      "Fengling Li",
      "Ke Lu",
      "Lei Zhu",
      "Jingjing Li"
    ],
    "abstract": "Conventional Unsupervised Domain Adaptation (UDA) strives to minimize\ndistribution discrepancy between domains, which neglects to harness rich\nsemantics from data and struggles to handle complex domain shifts. A promising\ntechnique is to leverage the knowledge of large-scale pre-trained\nvision-language models for more guided adaptation. Despite some endeavors,\ncurrent methods often learn textual prompts to embed domain semantics for\nsource and target domains separately and perform classification within each\ndomain, limiting cross-domain knowledge transfer. Moreover, prompting only the\nlanguage branch lacks flexibility to adapt both modalities dynamically. To\nbridge this gap, we propose Domain-Agnostic Mutual Prompting (DAMP) to exploit\ndomain-invariant semantics by mutually aligning visual and textual embeddings.\nSpecifically, the image contextual information is utilized to prompt the\nlanguage branch in a domain-agnostic and instance-conditioned way. Meanwhile,\nvisual prompts are imposed based on the domain-agnostic textual prompt to\nelicit domain-invariant visual embeddings. These two branches of prompts are\nlearned mutually with a cross-attention module and regularized with a\nsemantic-consistency loss and an instance-discrimination contrastive loss.\nExperiments on three UDA benchmarks demonstrate the superiority of DAMP over\nstate-of-the-art approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02899v1",
    "published_date": "2024-03-05 12:06:48 UTC",
    "updated_date": "2024-03-05 12:06:48 UTC"
  },
  {
    "arxiv_id": "2403.02893v2",
    "title": "Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning",
    "authors": [
      "Zhitao He",
      "Pengfei Cao",
      "Zhuoran Jin",
      "Yubo Chen",
      "Kang Liu",
      "Zhiqiang Zhang",
      "Mengshu Sun",
      "Jun Zhao"
    ],
    "abstract": "Event Causality Identification (ECI) refers to the detection of causal\nrelations between events in texts. However, most existing studies focus on\nsentence-level ECI with high-resource languages, leaving more challenging\ndocument-level ECI (DECI) with low-resource languages under-explored. In this\npaper, we propose a Heterogeneous Graph Interaction Model with\nMulti-granularity Contrastive Transfer Learning (GIMC) for zero-shot\ncross-lingual document-level ECI. Specifically, we introduce a heterogeneous\ngraph interaction network to model the long-distance dependencies between\nevents that are scattered over a document. Then, to improve cross-lingual\ntransferability of causal knowledge learned from the source language, we\npropose a multi-granularity contrastive transfer learning module to align the\ncausal representations across languages. Extensive experiments show our\nframework outperforms the previous state-of-the-art model by 9.4% and 8.2% of\naverage F1 score on monolingual and multilingual scenarios respectively.\nNotably, in the multilingual scenario, our zero-shot framework even exceeds\nGPT-3.5 with few-shot learning by 24.3% in overall performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02893v2",
    "published_date": "2024-03-05 11:57:21 UTC",
    "updated_date": "2024-03-22 07:44:32 UTC"
  },
  {
    "arxiv_id": "2403.02892v1",
    "title": "Enhancing Long-Term Person Re-Identification Using Global, Local Body Part, and Head Streams",
    "authors": [
      "Duy Tran Thanh",
      "Yeejin Lee",
      "Byeongkeun Kang"
    ],
    "abstract": "This work addresses the task of long-term person re-identification.\nTypically, person re-identification assumes that people do not change their\nclothes, which limits its applications to short-term scenarios. To overcome\nthis limitation, we investigate long-term person re-identification, which\nconsiders both clothes-changing and clothes-consistent scenarios. In this\npaper, we propose a novel framework that effectively learns and utilizes both\nglobal and local information. The proposed framework consists of three streams:\nglobal, local body part, and head streams. The global and head streams encode\nidentity-relevant information from an entire image and a cropped image of the\nhead region, respectively. Both streams encode the most distinct, less\ndistinct, and average features using the combinations of adversarial erasing,\nmax pooling, and average pooling. The local body part stream extracts\nidentity-related information for each body part, allowing it to be compared\nwith the same body part from another image. Since body part annotations are not\navailable in re-identification datasets, pseudo-labels are generated using\nclustering. These labels are then utilized to train a body part segmentation\nhead in the local body part stream. The proposed framework is trained by\nbackpropagating the weighted summation of the identity classification loss, the\npair-based loss, and the pseudo body part segmentation loss. To demonstrate the\neffectiveness of the proposed method, we conducted experiments on three\npublicly available datasets (Celeb-reID, PRCC, and VC-Clothes). The\nexperimental results demonstrate that the proposed method outperforms the\nprevious state-of-the-art method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.02892v1",
    "published_date": "2024-03-05 11:57:10 UTC",
    "updated_date": "2024-03-05 11:57:10 UTC"
  },
  {
    "arxiv_id": "2403.02884v1",
    "title": "MathScale: Scaling Instruction Tuning for Mathematical Reasoning",
    "authors": [
      "Zhengyang Tang",
      "Xingxing Zhang",
      "Benyou Wang",
      "Furu Wei"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nproblem-solving. However, their proficiency in solving mathematical problems\nremains inadequate. We propose MathScale, a simple and scalable method to\ncreate high-quality mathematical reasoning data using frontier LLMs (e.g., {\\tt\nGPT-3.5}). Inspired by the cognitive mechanism in human mathematical learning,\nit first extracts topics and knowledge points from seed math questions and then\nbuild a concept graph, which is subsequently used to generate new math\nquestions. MathScale exhibits effective scalability along the size axis of the\nmath dataset that we generate. As a result, we create a mathematical reasoning\ndataset (MathScaleQA) containing two million math question-answer pairs. To\nevaluate mathematical reasoning abilities of LLMs comprehensively, we construct\n{\\sc MwpBench}, a benchmark of Math Word Problems, which is a collection of ten\ndatasets (including GSM8K and MATH) covering K-12, college, and competition\nlevel math problems. We apply MathScaleQA to fine-tune open-source LLMs (e.g.,\nLLaMA-2 and Mistral), resulting in significantly improved capabilities in\nmathematical reasoning. Evaluated on {\\sc MwpBench}, MathScale-7B achieves\nstate-of-the-art performance across all datasets, surpassing its best peers of\nequivalent size by 42.9\\% in micro average accuracy and 43.7\\% in macro average\naccuracy, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2403.02884v1",
    "published_date": "2024-03-05 11:42:59 UTC",
    "updated_date": "2024-03-05 11:42:59 UTC"
  },
  {
    "arxiv_id": "2403.02877v1",
    "title": "ActiveAD: Planning-Oriented Active Learning for End-to-End Autonomous Driving",
    "authors": [
      "Han Lu",
      "Xiaosong Jia",
      "Yichen Xie",
      "Wenlong Liao",
      "Xiaokang Yang",
      "Junchi Yan"
    ],
    "abstract": "End-to-end differentiable learning for autonomous driving (AD) has recently\nbecome a prominent paradigm. One main bottleneck lies in its voracious appetite\nfor high-quality labeled data e.g. 3D bounding boxes and semantic segmentation,\nwhich are notoriously expensive to manually annotate. The difficulty is further\npronounced due to the prominent fact that the behaviors within samples in AD\noften suffer from long tailed distribution. In other words, a large part of\ncollected data can be trivial (e.g. simply driving forward in a straight road)\nand only a few cases are safety-critical. In this paper, we explore a\npractically important yet under-explored problem about how to achieve sample\nand label efficiency for end-to-end AD. Specifically, we design a\nplanning-oriented active learning method which progressively annotates part of\ncollected raw data according to the proposed diversity and usefulness criteria\nfor planning routes. Empirically, we show that our planning-oriented approach\ncould outperform general active learning methods by a large margin. Notably,\nour method achieves comparable performance with state-of-the-art end-to-end AD\nmethods - by using only 30% nuScenes data. We hope our work could inspire\nfuture works to explore end-to-end AD from a data-centric perspective in\naddition to methodology efforts.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02877v1",
    "published_date": "2024-03-05 11:39:07 UTC",
    "updated_date": "2024-03-05 11:39:07 UTC"
  },
  {
    "arxiv_id": "2403.02870v1",
    "title": "Precise Extraction of Deep Learning Models via Side-Channel Attacks on Edge/Endpoint Devices",
    "authors": [
      "Younghan Lee",
      "Sohee Jun",
      "Yungi Cho",
      "Woorim Han",
      "Hyungon Moon",
      "Yunheung Paek"
    ],
    "abstract": "With growing popularity, deep learning (DL) models are becoming larger-scale,\nand only the companies with vast training datasets and immense computing power\ncan manage their business serving such large models. Most of those DL models\nare proprietary to the companies who thus strive to keep their private models\nsafe from the model extraction attack (MEA), whose aim is to steal the model by\ntraining surrogate models. Nowadays, companies are inclined to offload the\nmodels from central servers to edge/endpoint devices. As revealed in the latest\nstudies, adversaries exploit this opportunity as new attack vectors to launch\nside-channel attack (SCA) on the device running victim model and obtain various\npieces of the model information, such as the model architecture (MA) and image\ndimension (ID). Our work provides a comprehensive understanding of such a\nrelationship for the first time and would benefit future MEA studies in both\noffensive and defensive sides in that they may learn which pieces of\ninformation exposed by SCA are more important than the others. Our analysis\nadditionally reveals that by grasping the victim model information from SCA,\nMEA can get highly effective and successful even without any prior knowledge of\nthe model. Finally, to evince the practicality of our analysis results, we\nempirically apply SCA, and subsequently, carry out MEA under realistic threat\nassumptions. The results show up to 5.8 times better performance than when the\nadversary has no model information about the victim model.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by 27th European Symposium on Research in Computer Security\n  (ESORICS 2022)",
    "pdf_url": "http://arxiv.org/pdf/2403.02870v1",
    "published_date": "2024-03-05 11:26:22 UTC",
    "updated_date": "2024-03-05 11:26:22 UTC"
  },
  {
    "arxiv_id": "2403.02846v1",
    "title": "FLGuard: Byzantine-Robust Federated Learning via Ensemble of Contrastive Models",
    "authors": [
      "Younghan Lee",
      "Yungi Cho",
      "Woorim Han",
      "Ho Bae",
      "Yunheung Paek"
    ],
    "abstract": "Federated Learning (FL) thrives in training a global model with numerous\nclients by only sharing the parameters of their local models trained with their\nprivate training datasets. Therefore, without revealing the private dataset,\nthe clients can obtain a deep learning (DL) model with high performance.\nHowever, recent research proposed poisoning attacks that cause a catastrophic\nloss in the accuracy of the global model when adversaries, posed as benign\nclients, are present in a group of clients. Therefore, recent studies suggested\nbyzantine-robust FL methods that allow the server to train an accurate global\nmodel even with the adversaries present in the system. However, many existing\nmethods require the knowledge of the number of malicious clients or the\nauxiliary (clean) dataset or the effectiveness reportedly decreased hugely when\nthe private dataset was non-independently and identically distributed\n(non-IID). In this work, we propose FLGuard, a novel byzantine-robust FL method\nthat detects malicious clients and discards malicious local updates by\nutilizing the contrastive learning technique, which showed a tremendous\nimprovement as a self-supervised learning method. With contrastive models, we\ndesign FLGuard as an ensemble scheme to maximize the defensive capability. We\nevaluate FLGuard extensively under various poisoning attacks and compare the\naccuracy of the global model with existing byzantine-robust FL methods. FLGuard\noutperforms the state-of-the-art defense methods in most cases and shows\ndrastic improvement, especially in non-IID settings.\nhttps://github.com/201younghanlee/FLGuard",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by 28th European Symposium on Research in Computer Security\n  (ESORICS 2023)",
    "pdf_url": "http://arxiv.org/pdf/2403.02846v1",
    "published_date": "2024-03-05 10:36:27 UTC",
    "updated_date": "2024-03-05 10:36:27 UTC"
  },
  {
    "arxiv_id": "2403.02820v1",
    "title": "Reconstruction for Sparse View Tomography of Long Objects Applied to Imaging in the Wood Industry",
    "authors": [
      "Buda BajiÄ",
      "Johannes A. J. Huber",
      "Benedikt Neyses",
      "Linus Olofsson",
      "Ozan Ãktem"
    ],
    "abstract": "In the wood industry, logs are commonly quality screened by discrete X-ray\nscans on a moving conveyor belt from a few source positions. Typically,\ntwo-dimensional (2D) slice-wise measurements are obtained by a sequential\nscanning geometry. Each 2D slice alone does not carry sufficient information\nfor a three-dimensional tomographic reconstruction in which biological features\nof interest in the log are well preserved. In the present work, we propose a\nlearned iterative reconstruction method based on the Learned Primal-Dual neural\nnetwork, suited for sequential scanning geometries. Our method accumulates\ninformation between neighbouring slices, instead of only accounting for single\nslices during reconstruction. Our quantitative and qualitative evaluations with\nas few as five source positions show that our method yields reconstructions of\nlogs that are sufficiently accurate to identify biological features like knots\n(branches), heartwood and sapwood.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02820v1",
    "published_date": "2024-03-05 09:44:19 UTC",
    "updated_date": "2024-03-05 09:44:19 UTC"
  },
  {
    "arxiv_id": "2403.02814v1",
    "title": "InjectTST: A Transformer Method of Injecting Global Information into Independent Channels for Long Time Series Forecasting",
    "authors": [
      "Ce Chi",
      "Xing Wang",
      "Kexin Yang",
      "Zhiyan Song",
      "Di Jin",
      "Lin Zhu",
      "Chao Deng",
      "Junlan Feng"
    ],
    "abstract": "Transformer has become one of the most popular architectures for multivariate\ntime series (MTS) forecasting. Recent Transformer-based MTS models generally\nprefer channel-independent structures with the observation that channel\nindependence can alleviate noise and distribution drift issues, leading to more\nrobustness. Nevertheless, it is essential to note that channel dependency\nremains an inherent characteristic of MTS, carrying valuable information.\nDesigning a model that incorporates merits of both channel-independent and\nchannel-mixing structures is a key to further improvement of MTS forecasting,\nwhich poses a challenging conundrum. To address the problem, an injection\nmethod for global information into channel-independent Transformer, InjectTST,\nis proposed in this paper. Instead of designing a channel-mixing model\ndirectly, we retain the channel-independent backbone and gradually inject\nglobal information into individual channels in a selective way. A channel\nidentifier, a global mixing module and a self-contextual attention module are\ndevised in InjectTST. The channel identifier can help Transformer distinguish\nchannels for better representation. The global mixing module produces\ncross-channel global information. Through the self-contextual attention module,\nthe independent channels can selectively concentrate on useful global\ninformation without robustness degradation, and channel mixing is achieved\nimplicitly. Experiments indicate that InjectTST can achieve stable improvement\ncompared with state-of-the-art models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02814v1",
    "published_date": "2024-03-05 09:33:36 UTC",
    "updated_date": "2024-03-05 09:33:36 UTC"
  },
  {
    "arxiv_id": "2403.02810v1",
    "title": "Dynamic Gaussian Graph Operator: Learning parametric partial differential equations in arbitrary discrete mechanics problems",
    "authors": [
      "Chu Wang",
      "Jinhong Wu",
      "Yanzhi Wang",
      "Zhijian Zha",
      "Qi Zhou"
    ],
    "abstract": "Deep learning methods have access to be employed for solving physical systems\ngoverned by parametric partial differential equations (PDEs) due to massive\nscientific data. It has been refined to operator learning that focuses on\nlearning non-linear mapping between infinite-dimensional function spaces,\noffering interface from observations to solutions. However, state-of-the-art\nneural operators are limited to constant and uniform discretization, thereby\nleading to deficiency in generalization on arbitrary discretization schemes for\ncomputational domain. In this work, we propose a novel operator learning\nalgorithm, referred to as Dynamic Gaussian Graph Operator (DGGO) that expands\nneural operators to learning parametric PDEs in arbitrary discrete mechanics\nproblems. The Dynamic Gaussian Graph (DGG) kernel learns to map the observation\nvectors defined in general Euclidean space to metric vectors defined in\nhigh-dimensional uniform metric space. The DGG integral kernel is parameterized\nby Gaussian kernel weighted Riemann sum approximating and using dynamic message\npassing graph to depict the interrelation within the integral term. Fourier\nNeural Operator is selected to localize the metric vectors on spatial and\nfrequency domains. Metric vectors are regarded as located on latent uniform\ndomain, wherein spatial and spectral transformation offer highly regular\nconstraints on solution space. The efficiency and robustness of DGGO are\nvalidated by applying it to solve numerical arbitrary discrete mechanics\nproblems in comparison with mainstream neural operators. Ablation experiments\nare implemented to demonstrate the effectiveness of spatial transformation in\nthe DGG kernel. The proposed method is utilized to forecast stress field of\nhyper-elastic material with geometrically variable void as engineering\napplication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The number of figures is 13. The number of tables is 7. The number of\n  words is 9854",
    "pdf_url": "http://arxiv.org/pdf/2403.02810v1",
    "published_date": "2024-03-05 09:25:31 UTC",
    "updated_date": "2024-03-05 09:25:31 UTC"
  },
  {
    "arxiv_id": "2403.02799v1",
    "title": "DPPA: Pruning Method for Large Language Model to Model Merging",
    "authors": [
      "Yaochen Zhu",
      "Rui Xia",
      "Jiajun Zhang"
    ],
    "abstract": "Model merging is to combine fine-tuned models derived from multiple domains,\nwith the intent of enhancing the model's proficiency across various domains.\nThe principal concern is the resolution of parameter conflicts. A substantial\namount of existing research remedy this issue during the merging stage, with\nthe latest study focusing on resolving this issue throughout the pruning stage.\nThe DARE approach has exhibited promising outcomes when applied to a simplistic\nfine-tuned model. However, the efficacy of this method tends to wane when\nemployed on complex fine-tuned models that show a significant parameter bias\nrelative to the baseline model. In this paper, we introduce a dual-stage method\ntermed Dynamic Pruning Partition Amplification (DPPA), devised to tackle the\nchallenge of merging complex fine-tuned models. Initially, we introduce\nDynamically Pruning (DP), an improved approach based on magnitude pruning,\nwhich aim is to enhance performance at higher pruning rates. Subsequently, we\npropose Dynamically Partition Amplification (DPA), a rescaling strategy, is\ndesigned to dynamically amplify parameter partitions in relation to their\nsignificance levels. The experimental results show that our method maintains a\nmere 20% of domain-specific parameters and yet delivers a performance\ncomparable to other methodologies that preserve up to 90% of parameters.\nFurthermore, our method displays outstanding performance post-pruning, leading\nto a significant improvement of nearly 20% performance in model merging. We\nmake our code on Github.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02799v1",
    "published_date": "2024-03-05 09:12:49 UTC",
    "updated_date": "2024-03-05 09:12:49 UTC"
  },
  {
    "arxiv_id": "2403.02795v2",
    "title": "Evaluating and Optimizing Educational Content with Large Language Model Judgments",
    "authors": [
      "Joy He-Yueya",
      "Noah D. Goodman",
      "Emma Brunskill"
    ],
    "abstract": "Creating effective educational materials generally requires expensive and\ntime-consuming studies of student learning outcomes. To overcome this barrier,\none idea is to build computational models of student learning and use them to\noptimize instructional materials. However, it is difficult to model the\ncognitive processes of learning dynamics. We propose an alternative approach\nthat uses Language Models (LMs) as educational experts to assess the impact of\nvarious instructions on learning outcomes. Specifically, we use GPT-3.5 to\nevaluate the overall effect of instructional materials on different student\ngroups and find that it can replicate well-established educational findings\nsuch as the Expertise Reversal Effect and the Variability Effect. This\ndemonstrates the potential of LMs as reliable evaluators of educational\ncontent. Building on this insight, we introduce an instruction optimization\napproach in which one LM generates instructional materials using the judgments\nof another LM as a reward function. We apply this approach to create math word\nproblem worksheets aimed at maximizing student learning gains. Human teachers'\nevaluations of these LM-generated worksheets show a significant alignment\nbetween the LM judgments and human teacher preferences. We conclude by\ndiscussing potential divergences between human and LM opinions and the\nresulting pitfalls of automating instructional design.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.02795v2",
    "published_date": "2024-03-05 09:09:15 UTC",
    "updated_date": "2024-05-06 04:54:19 UTC"
  },
  {
    "arxiv_id": "2403.02794v1",
    "title": "A Distance Metric Learning Model Based On Variational Information Bottleneck",
    "authors": [
      "YaoDan Zhang",
      "Zidong Wang",
      "Ru Jia",
      "Ru Li"
    ],
    "abstract": "In recent years, personalized recommendation technology has flourished and\nbecome one of the hot research directions. The matrix factorization model and\nthe metric learning model which proposed successively have been widely studied\nand applied. The latter uses the Euclidean distance instead of the dot product\nused by the former to measure the latent space vector. While avoiding the\nshortcomings of the dot product, the assumption of Euclidean distance is\nneglected, resulting in limited recommendation quality of the model. In order\nto solve this problem, this paper combines the Variationl Information\nBottleneck with metric learning model for the first time, and proposes a new\nmetric learning model VIB-DML (Variational Information Bottleneck Distance\nMetric Learning) for rating prediction, which limits the mutual information of\nthe latent space feature vector to improve the robustness of the model and\nsatisfiy the assumption of Euclidean distance by decoupling the latent space\nfeature vector. In this paper, the experimental results are compared with the\nroot mean square error (RMSE) on the three public datasets. The results show\nthat the generalization ability of VIB-DML is excellent. Compared with the\ngeneral metric learning model MetricF, the prediction error is reduced by\n7.29%. Finally, the paper proves the strong robustness of VIBDML through\nexperiments.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02794v1",
    "published_date": "2024-03-05 09:08:20 UTC",
    "updated_date": "2024-03-05 09:08:20 UTC"
  },
  {
    "arxiv_id": "2403.02786v1",
    "title": "Semi-Supervised Graph Representation Learning with Human-centric Explanation for Predicting Fatty Liver Disease",
    "authors": [
      "So Yeon Kim",
      "Sehee Wang",
      "Eun Kyung Choe"
    ],
    "abstract": "Addressing the challenge of limited labeled data in clinical settings,\nparticularly in the prediction of fatty liver disease, this study explores the\npotential of graph representation learning within a semi-supervised learning\nframework. Leveraging graph neural networks (GNNs), our approach constructs a\nsubject similarity graph to identify risk patterns from health checkup data.\nThe effectiveness of various GNN approaches in this context is demonstrated,\neven with minimal labeled samples. Central to our methodology is the inclusion\nof human-centric explanations through explainable GNNs, providing personalized\nfeature importance scores for enhanced interpretability and clinical relevance,\nthereby underscoring the potential of our approach in advancing healthcare\npractices with a keen focus on graph representation learning and human-centric\nexplanation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024 (https://hcrl-workshop.github.io/2024/)",
    "pdf_url": "http://arxiv.org/pdf/2403.02786v1",
    "published_date": "2024-03-05 08:59:45 UTC",
    "updated_date": "2024-03-05 08:59:45 UTC"
  },
  {
    "arxiv_id": "2403.02783v1",
    "title": "Where the Really Hard Quadratic Assignment Problems Are: the QAP-SAT instances",
    "authors": [
      "SÃ©bastien Verel",
      "Sarah Thomson",
      "Omar Rifki"
    ],
    "abstract": "The Quadratic Assignment Problem (QAP) is one of the major domains in the\nfield of evolutionary computation, and more widely in combinatorial\noptimization. This paper studies the phase transition of the QAP, which can be\ndescribed as a dramatic change in the problem's computational complexity and\nsatisfiability, within a narrow range of the problem parameters. To approach\nthis phenomenon, we introduce a new QAP-SAT design of the initial problem based\non submodularity to capture its difficulty with new features. This\ndecomposition is studied experimentally using branch-and-bound and tabu search\nsolvers. A phase transition parameter is then proposed. The critical parameter\nof phase transition satisfaction and that of the solving effort are shown to be\nhighly correlated for tabu search, thus allowing the prediction of difficult\ninstances.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02783v1",
    "published_date": "2024-03-05 08:56:30 UTC",
    "updated_date": "2024-03-05 08:56:30 UTC"
  },
  {
    "arxiv_id": "2403.02775v1",
    "title": "EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs",
    "authors": [
      "Hanlin Tang",
      "Yifu Sun",
      "Decheng Wu",
      "Kai Liu",
      "Jianchen Zhu",
      "Zhanhui Kang"
    ],
    "abstract": "Large language models (LLMs) have proven to be very superior to conventional\nmethods in various tasks. However, their expensive computations and high memory\nrequirements are prohibitive for deployment. Model quantization is an effective\nmethod for reducing this overhead. The problem is that in most previous works,\nthe quantized model was calibrated using few samples from the training data,\nwhich might affect the generalization of the quantized LLMs to unknown cases\nand tasks. Hence in this work, we explore an important question: Can we design\na data-independent quantization method for LLMs to guarantee its generalization\nperformance? In this work, we propose EasyQuant, a training-free and\ndata-independent weight-only quantization algorithm for LLMs. Our observation\nindicates that two factors: outliers in the weight and quantization ranges, are\nessential for reducing the quantization error. Therefore, in EasyQuant, we\nleave the outliers (less than 1%) unchanged and optimize the quantization range\nto reduce the reconstruction error. With these methods, we surprisingly find\nthat EasyQuant achieves comparable performance to the original model. Since\nEasyQuant does not depend on any training data, the generalization performance\nof quantized LLMs is safely guaranteed. Moreover, EasyQuant can be implemented\nin parallel so that the quantized model could be attained in a few minutes even\nfor LLMs over 100B. To our best knowledge, we are the first work that achieves\nalmost lossless quantization performance for LLMs under a data-independent\nsetting and our algorithm runs over 10 times faster than the data-dependent\nmethods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02775v1",
    "published_date": "2024-03-05 08:45:30 UTC",
    "updated_date": "2024-03-05 08:45:30 UTC"
  },
  {
    "arxiv_id": "2403.02772v2",
    "title": "Rehabilitation Exercise Quality Assessment through Supervised Contrastive Learning with Hard and Soft Negatives",
    "authors": [
      "Mark Karlov",
      "Ali Abedi",
      "Shehroz S. Khan"
    ],
    "abstract": "Exercise-based rehabilitation programs have proven to be effective in\nenhancing the quality of life and reducing mortality and rehospitalization\nrates. AI-driven virtual rehabilitation, which allows patients to independently\ncomplete exercises at home, utilizes AI algorithms to analyze exercise data,\nproviding feedback to patients and updating clinicians on their progress. These\nprograms commonly prescribe a variety of exercise types, leading to a distinct\nchallenge in rehabilitation exercise assessment datasets: while abundant in\noverall training samples, these datasets often have a limited number of samples\nfor each individual exercise type. This disparity hampers the ability of\nexisting approaches to train generalizable models with such a small sample size\nper exercise type. Addressing this issue, this paper introduces a novel\nsupervised contrastive learning framework with hard and soft negative samples\nthat effectively utilizes the entire dataset to train a single model applicable\nto all exercise types. This model, with a Spatial-Temporal Graph Convolutional\nNetwork (ST-GCN) architecture, demonstrated enhanced generalizability across\nexercises and a decrease in overall complexity. Through extensive experiments\non three publicly available rehabilitation exercise assessment datasets,\nUI-PRMD, IRDS, and KIMORE, our method has proven to surpass existing methods,\nsetting a new benchmark in rehabilitation exercise quality assessment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 4 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.02772v2",
    "published_date": "2024-03-05 08:38:25 UTC",
    "updated_date": "2024-08-09 15:54:49 UTC"
  },
  {
    "arxiv_id": "2403.02760v2",
    "title": "Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations",
    "authors": [
      "Xiaonan Xu",
      "Yichao Wu",
      "Penghao Liang",
      "Yuhang He",
      "Han Wang"
    ],
    "abstract": "With the boom of e-commerce and web applications, recommender systems have\nbecome an important part of our daily lives, providing personalized\nrecommendations based on the user's preferences. Although deep neural networks\n(DNNs) have made significant progress in improving recommendation systems by\nsimulating the interaction between users and items and incorporating their\ntextual information, these DNN-based approaches still have some limitations,\nsuch as the difficulty of effectively understanding users' interests and\ncapturing textual information. It is not possible to generalize to different\nseen/unseen recommendation scenarios and reason about their predictions. At the\nsame time, the emergence of large language models (LLMs), represented by\nChatGPT and GPT-4, has revolutionized the fields of natural language processing\n(NLP) and artificial intelligence (AI) due to their superior capabilities in\nthe basic tasks of language understanding and generation, and their impressive\ngeneralization and reasoning capabilities. As a result, recent research has\nsought to harness the power of LLM to improve recommendation systems. Given the\nrapid development of this research direction in the field of recommendation\nsystems, there is an urgent need for a systematic review of existing LLM-driven\nrecommendation systems for researchers and practitioners in related fields to\ngain insight into. More specifically, we first introduced a representative\napproach to learning user and item representations using LLM as a feature\nencoder. We then reviewed the latest advances in LLMs techniques for\ncollaborative filtering enhanced recommendation systems from the three\nparadigms of pre-training, fine-tuning, and prompting. Finally, we had a\ncomprehensive discussion on the future direction of this emerging field.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02760v2",
    "published_date": "2024-03-05 08:31:00 UTC",
    "updated_date": "2024-03-12 11:29:07 UTC"
  },
  {
    "arxiv_id": "2403.15412v5",
    "title": "Towards Measuring and Modeling \"Culture\" in LLMs: A Survey",
    "authors": [
      "Muhammad Farid Adilazuarda",
      "Sagnik Mukherjee",
      "Pradhyumna Lavania",
      "Siddhant Singh",
      "Alham Fikri Aji",
      "Jacki O'Neill",
      "Ashutosh Modi",
      "Monojit Choudhury"
    ],
    "abstract": "We present a survey of more than 90 recent papers that aim to study cultural\nrepresentation and inclusion in large language models (LLMs). We observe that\nnone of the studies explicitly define \"culture, which is a complex,\nmultifaceted concept; instead, they probe the models on some specially designed\ndatasets which represent certain aspects of \"culture\". We call these aspects\nthe proxies of culture, and organize them across two dimensions of demographic\nand semantic proxies. We also categorize the probing methods employed. Our\nanalysis indicates that only certain aspects of ``culture,'' such as values and\nobjectives, have been studied, leaving several other interesting and important\nfacets, especially the multitude of semantic domains (Thompson et al., 2020)\nand aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps\nare the lack of robustness of probing techniques and situated studies on the\nimpact of cultural mis- and under-representation in LLM-based applications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15412v5",
    "published_date": "2024-03-05 08:29:36 UTC",
    "updated_date": "2024-09-04 05:12:54 UTC"
  },
  {
    "arxiv_id": "2403.02750v1",
    "title": "Speckle Noise Reduction in Ultrasound Images using Denoising Auto-encoder with Skip Connection",
    "authors": [
      "Suraj Bhute",
      "Subhamoy Mandal",
      "Debashree Guha"
    ],
    "abstract": "Ultrasound is a widely used medical tool for non-invasive diagnosis, but its\nimages often contain speckle noise which can lower their resolution and\ncontrast-to-noise ratio. This can make it more difficult to extract, recognize,\nand analyze features in the images, as well as impair the accuracy of\ncomputer-assisted diagnostic techniques and the ability of doctors to interpret\nthe images. Reducing speckle noise, therefore, is a crucial step in the\npreprocessing of ultrasound images. Researchers have proposed several speckle\nreduction methods, but no single method takes all relevant factors into\naccount. In this paper, we compare seven such methods: Median, Gaussian,\nBilateral, Average, Weiner, Anisotropic and Denoising auto-encoder without and\nwith skip connections in terms of their ability to preserve features and edges\nwhile effectively reducing noise. In an experimental study, a convolutional\nnoise-removing auto-encoder with skip connection, a deep learning method, was\nused to improve ultrasound images of breast cancer. This method involved adding\nspeckle noise at various levels. The results of the deep learning method were\ncompared to those of traditional image enhancement methods, and it was found\nthat the proposed method was more effective. To assess the performance of these\nalgorithms, we use three established evaluation metrics and present both\nfiltered images and statistical data.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "Selected for presentation at 2024 IEEE South Asian Ultrasonics\n  Symposium",
    "pdf_url": "http://arxiv.org/pdf/2403.02750v1",
    "published_date": "2024-03-05 08:08:59 UTC",
    "updated_date": "2024-03-05 08:08:59 UTC"
  },
  {
    "arxiv_id": "2403.02745v2",
    "title": "CURATRON: Complete and Robust Preference Data for Rigorous Alignment of Large Language Models",
    "authors": [
      "Son The Nguyen",
      "Niranjan Uma Naresh",
      "Theja Tulabandhula"
    ],
    "abstract": "This paper addresses the challenges of aligning large language models (LLMs)\nwith human values via preference learning (PL), focusing on incomplete and\ncorrupted data in preference datasets. We propose a novel method for robustly\nand completely recalibrating values within these datasets to enhance LLMs'\nresilience against the issues. In particular, we devise a guaranteed polynomial\ntime ranking algorithm that robustifies several existing models, such as the\nclassic Bradley-Terry-Luce (BTL) (Bradley and Terry, 1952) model and certain\ngeneralizations of it. To the best of our knowledge, our present work is the\nfirst to propose an algorithm that provably recovers an $\\epsilon$-optimal\nranking with high probability while allowing as large as $O(n)$ perturbed\npairwise comparison results per model response. Furthermore, we show robust\nrecovery results in the partially observed setting. Our experiments confirm\nthat our algorithms handle adversarial noise and unobserved comparisons well in\nboth general and LLM preference dataset settings. This work contributes to the\ndevelopment and scaling of more reliable and ethically aligned AI models by\nequipping the dataset curation pipeline with the ability to handle missing and\nmaliciously manipulated inputs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02745v2",
    "published_date": "2024-03-05 07:58:12 UTC",
    "updated_date": "2024-10-30 08:54:38 UTC"
  },
  {
    "arxiv_id": "2403.02736v1",
    "title": "Bootstrapping Rare Object Detection in High-Resolution Satellite Imagery",
    "authors": [
      "Akram Zaytar",
      "Caleb Robinson",
      "Gilles Q. Hacheme",
      "Girmaw A. Tadesse",
      "Rahul Dodhia",
      "Juan M. Lavista Ferres",
      "Lacey F. Hughey",
      "Jared A. Stabach",
      "Irene Amoke"
    ],
    "abstract": "Rare object detection is a fundamental task in applied geospatial machine\nlearning, however is often challenging due to large amounts of high-resolution\nsatellite or aerial imagery and few or no labeled positive samples to start\nwith. This paper addresses the problem of bootstrapping such a rare object\ndetection task assuming there is no labeled data and no spatial prior over the\narea of interest. We propose novel offline and online cluster-based approaches\nfor sampling patches that are significantly more efficient, in terms of\nexposing positive samples to a human annotator, than random sampling. We apply\nour methods for identifying bomas, or small enclosures for herd animals, in the\nSerengeti Mara region of Kenya and Tanzania. We demonstrate a significant\nenhancement in detection efficiency, achieving a positive sampling rate\nincrease from 2% (random) to 30%. This advancement enables effective machine\nlearning mapping even with minimal labeling budgets, exemplified by an F1 score\non the boma detection task of 0.51 with a budget of 300 total patches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02736v1",
    "published_date": "2024-03-05 07:44:13 UTC",
    "updated_date": "2024-03-05 07:44:13 UTC"
  },
  {
    "arxiv_id": "2403.02727v1",
    "title": "HARGPT: Are LLMs Zero-Shot Human Activity Recognizers?",
    "authors": [
      "Sijie Ji",
      "Xinzhe Zheng",
      "Chenshu Wu"
    ],
    "abstract": "There is an ongoing debate regarding the potential of Large Language Models\n(LLMs) as foundational models seamlessly integrated with Cyber-Physical Systems\n(CPS) for interpreting the physical world. In this paper, we carry out a case\nstudy to answer the following question: Are LLMs capable of zero-shot human\nactivity recognition (HAR). Our study, HARGPT, presents an affirmative answer\nby demonstrating that LLMs can comprehend raw IMU data and perform HAR tasks in\na zero-shot manner, with only appropriate prompts. HARGPT inputs raw IMU data\ninto LLMs and utilizes the role-play and think step-by-step strategies for\nprompting. We benchmark HARGPT on GPT4 using two public datasets of different\ninter-class similarities and compare various baselines both based on\ntraditional machine learning and state-of-the-art deep classification models.\nRemarkably, LLMs successfully recognize human activities from raw IMU data and\nconsistently outperform all the baselines on both datasets. Our findings\nindicate that by effective prompting, LLMs can interpret raw IMU data based on\ntheir knowledge base, possessing a promising potential to analyze raw sensor\ndata of the physical world effectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02727v1",
    "published_date": "2024-03-05 07:34:51 UTC",
    "updated_date": "2024-03-05 07:34:51 UTC"
  },
  {
    "arxiv_id": "2403.02726v1",
    "title": "Bias in Generative AI",
    "authors": [
      "Mi Zhou",
      "Vibhanshu Abhishek",
      "Timothy Derdenger",
      "Jaymo Kim",
      "Kannan Srinivasan"
    ],
    "abstract": "This study analyzed images generated by three popular generative artificial\nintelligence (AI) tools - Midjourney, Stable Diffusion, and DALLE 2 -\nrepresenting various occupations to investigate potential bias in AI\ngenerators. Our analysis revealed two overarching areas of concern in these AI\ngenerators, including (1) systematic gender and racial biases, and (2) subtle\nbiases in facial expressions and appearances. Firstly, we found that all three\nAI generators exhibited bias against women and African Americans. Moreover, we\nfound that the evident gender and racial biases uncovered in our analysis were\neven more pronounced than the status quo when compared to labor force\nstatistics or Google images, intensifying the harmful biases we are actively\nstriving to rectify in our society. Secondly, our study uncovered more nuanced\nprejudices in the portrayal of emotions and appearances. For example, women\nwere depicted as younger with more smiles and happiness, while men were\ndepicted as older with more neutral expressions and anger, posing a risk that\ngenerative AI models may unintentionally depict women as more submissive and\nless competent than men. Such nuanced biases, by their less overt nature, might\nbe more problematic as they can permeate perceptions unconsciously and may be\nmore difficult to rectify. Although the extent of bias varied depending on the\nmodel, the direction of bias remained consistent in both commercial and\nopen-source AI generators. As these tools become commonplace, our study\nhighlights the urgency to identify and mitigate various biases in generative\nAI, reinforcing the commitment to ensuring that AI technologies benefit all of\nhumanity for a more inclusive future.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02726v1",
    "published_date": "2024-03-05 07:34:41 UTC",
    "updated_date": "2024-03-05 07:34:41 UTC"
  },
  {
    "arxiv_id": "2403.02723v1",
    "title": "Minimum Topology Attacks for Graph Neural Networks",
    "authors": [
      "Mengmei Zhang",
      "Xiao Wang",
      "Chuan Shi",
      "Lingjuan Lyu",
      "Tianchi Yang",
      "Junping Du"
    ],
    "abstract": "With the great popularity of Graph Neural Networks (GNNs), their robustness\nto adversarial topology attacks has received significant attention. Although\nmany attack methods have been proposed, they mainly focus on fixed-budget\nattacks, aiming at finding the most adversarial perturbations within a fixed\nbudget for target node. However, considering the varied robustness of each\nnode, there is an inevitable dilemma caused by the fixed budget, i.e., no\nsuccessful perturbation is found when the budget is relatively small, while if\nit is too large, the yielding redundant perturbations will hurt the\ninvisibility. To break this dilemma, we propose a new type of topology attack,\nnamed minimum-budget topology attack, aiming to adaptively find the minimum\nperturbation sufficient for a successful attack on each node. To this end, we\npropose an attack model, named MiBTack, based on a dynamic projected gradient\ndescent algorithm, which can effectively solve the involving non-convex\nconstraint optimization on discrete topology. Extensive results on three GNNs\nand four real-world datasets show that MiBTack can successfully lead all target\nnodes misclassified with the minimum perturbation edges. Moreover, the obtained\nminimum budget can be used to measure node robustness, so we can explore the\nrelationships of robustness, topology, and uncertainty for nodes, which is\nbeyond what the current fixed-budget topology attacks can offer.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published on WWW 2023. Proceedings of the ACM Web Conference 2023",
    "pdf_url": "http://arxiv.org/pdf/2403.02723v1",
    "published_date": "2024-03-05 07:29:12 UTC",
    "updated_date": "2024-03-05 07:29:12 UTC"
  },
  {
    "arxiv_id": "2403.02719v3",
    "title": "Multi-Scale Subgraph Contrastive Learning",
    "authors": [
      "Yanbei Liu",
      "Yu Zhao",
      "Xiao Wang",
      "Lei Geng",
      "Zhitao Xiao"
    ],
    "abstract": "Graph-level contrastive learning, aiming to learn the representations for\neach graph by contrasting two augmented graphs, has attracted considerable\nattention. Previous studies usually simply assume that a graph and its\naugmented graph as a positive pair, otherwise as a negative pair. However, it\nis well known that graph structure is always complex and multi-scale, which\ngives rise to a fundamental question: after graph augmentation, will the\nprevious assumption still hold in reality? By an experimental analysis, we\ndiscover the semantic information of an augmented graph structure may be not\nconsistent as original graph structure, and whether two augmented graphs are\npositive or negative pairs is highly related with the multi-scale structures.\nBased on this finding, we propose a multi-scale subgraph contrastive learning\narchitecture which is able to characterize the fine-grained semantic\ninformation. Specifically, we generate global and local views at different\nscales based on subgraph sampling, and construct multiple contrastive\nrelationships according to their semantic associations to provide richer\nself-supervised signals. Extensive experiments and parametric analyzes on eight\ngraph classification real-world datasets well demonstrate the effectiveness of\nthe proposed method.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The 32nd International Joint Conference on Artificial Intelligence\n  (IJCAI-2023)",
    "pdf_url": "http://arxiv.org/pdf/2403.02719v3",
    "published_date": "2024-03-05 07:17:18 UTC",
    "updated_date": "2024-04-12 01:15:01 UTC"
  },
  {
    "arxiv_id": "2403.02715v2",
    "title": "Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models",
    "authors": [
      "Sang T. Truong",
      "Duc Q. Nguyen",
      "Toan Nguyen",
      "Dong D. Le",
      "Nhi N. Truong",
      "Tho Quan",
      "Sanmi Koyejo"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have underscored their\nimportance in the evolution of artificial intelligence. However, despite\nextensive pretraining on multilingual datasets, available open-sourced LLMs\nexhibit limited effectiveness in processing Vietnamese. The challenge is\nexacerbated by the absence of systematic benchmark datasets and metrics\ntailored for Vietnamese LLM evaluation. To mitigate these issues, we have\nfinetuned LLMs specifically for Vietnamese and developed a comprehensive\nevaluation framework encompassing 10 common tasks and 31 metrics. Our\nevaluation results reveal that the fine-tuned LLMs exhibit enhanced\ncomprehension and generative capabilities in Vietnamese. Moreover, our analysis\nindicates that models with more parameters can introduce more biases and\nuncalibrated outputs and the key factor influencing LLM performance is the\nquality of the training or fine-tuning datasets. These insights underscore the\nsignificance of meticulous fine-tuning with high-quality datasets in enhancing\nLLM performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.CL",
    "comment": "51 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.02715v2",
    "published_date": "2024-03-05 07:13:28 UTC",
    "updated_date": "2024-05-26 17:13:32 UTC"
  },
  {
    "arxiv_id": "2403.02701v1",
    "title": "Fighting Game Adaptive Background Music for Improved Gameplay",
    "authors": [
      "Ibrahim Khan",
      "Thai Van Nguyen",
      "Chollakorn Nimpattanavong",
      "Ruck Thawonmas"
    ],
    "abstract": "This paper presents our work to enhance the background music (BGM) in\nDareFightingICE by adding adaptive features. The adaptive BGM consists of three\ndifferent categories of instruments playing the BGM of the winner sound design\nfrom the 2022 DareFightingICE Competition. The BGM adapts by changing the\nvolume of each category of instruments. Each category is connected to a\ndifferent element of the game. We then run experiments to evaluate the adaptive\nBGM by using a deep reinforcement learning AI agent that only uses audio as\ninput (Blind DL AI). The results show that the performance of the Blind DL AI\nimproves while playing with the adaptive BGM as compared to playing without the\nadaptive BGM.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "I.2; H.5.2; H.5"
    ],
    "primary_category": "cs.SD",
    "comment": "This is an updated version of our IEEE CoG 2023 paper\n  (https://ieeexplore.ieee.org/document/10333245). This version has revised the\n  description of the association between the distance between the two players\n  (PD) and the instrument's volume on page 2. arXiv admin note: substantial\n  text overlap with arXiv:2303.15734",
    "pdf_url": "http://arxiv.org/pdf/2403.02701v1",
    "published_date": "2024-03-05 06:46:43 UTC",
    "updated_date": "2024-03-05 06:46:43 UTC"
  },
  {
    "arxiv_id": "2403.02694v4",
    "title": "MeanCache: User-Centric Semantic Caching for LLM Web Services",
    "authors": [
      "Waris Gill",
      "Mohamed Elidrisi",
      "Pallavi Kalapatapu",
      "Ammar Ahmed",
      "Ali Anwar",
      "Muhammad Ali Gulzar"
    ],
    "abstract": "Large Language Models (LLMs) like ChatGPT and Llama have revolutionized\nnatural language processing and search engine dynamics. However, these models\nincur exceptionally high computational costs. For instance, GPT-3 consists of\n175 billion parameters, where inference demands billions of floating-point\noperations. Caching is a natural solution to reduce LLM inference costs on\nrepeated queries, which constitute about 31% of the total queries. However,\nexisting caching methods are incapable of finding semantic similarities among\nLLM queries nor do they operate on contextual queries, leading to unacceptable\nfalse hit-and-miss rates. This paper introduces MeanCache, a user-centric\nsemantic cache for LLM-based services that identifies semantically similar\nqueries to determine cache hit or miss. Using MeanCache, the response to a\nuser's semantically similar query can be retrieved from a local cache rather\nthan re-querying the LLM, thus reducing costs, service provider load, and\nenvironmental impact. MeanCache leverages Federated Learning (FL) to\ncollaboratively train a query similarity model without violating user privacy.\nBy placing a local cache in each user's device and using FL, MeanCache reduces\nthe latency and costs and enhances model performance, resulting in lower false\nhit rates. MeanCache also encodes context chains for every cached query,\noffering a simple yet highly effective mechanism to discern contextual query\nresponses from standalone. Our experiments benchmarked against the\nstate-of-the-art caching method, reveal that MeanCache attains an approximately\n17% higher F-score and a 20% increase in precision during semantic cache\nhit-and-miss decisions while performing even better on contextual queries. It\nalso reduces the storage requirement by 83% and accelerates semantic cache\nhit-and-miss decisions by 11%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.DC",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at 2025 IEEE 39th International Parallel and Distributed\n  Processing Symposium (IPDPS)",
    "pdf_url": "http://arxiv.org/pdf/2403.02694v4",
    "published_date": "2024-03-05 06:23:50 UTC",
    "updated_date": "2025-03-07 14:49:07 UTC"
  },
  {
    "arxiv_id": "2403.02688v2",
    "title": "DOCTOR: Dynamic On-Chip Temporal Variation Remediation Toward Self-Corrected Photonic Tensor Accelerators",
    "authors": [
      "Haotian Lu",
      "Sanmitra Banerjee",
      "Jiaqi Gu"
    ],
    "abstract": "Photonic computing has emerged as a promising solution for accelerating\ncomputation-intensive artificial intelligence (AI) workloads, offering\nunparalleled speed and energy efficiency, especially in resource-limited,\nlatency-sensitive edge computing environments. However, the deployment of\nanalog photonic tensor accelerators encounters reliability challenges due to\nhardware noise and environmental variations. While off-chip noise-aware\ntraining and on-chip training have been proposed to enhance the variation\ntolerance of optical neural accelerators with moderate, static noise, we\nobserve a notable performance degradation over time due to temporally drifting\nvariations, which requires a real-time, in-situ calibration mechanism. To\ntackle this challenging reliability issues, for the first time, we propose a\nlightweight dynamic on-chip remediation framework, dubbed DOCTOR, providing\nadaptive, in-situ accuracy recovery against temporally drifting noise. The\nDOCTOR framework intelligently monitors the chip status using adaptive probing\nand performs fast in-situ training-free calibration to restore accuracy when\nnecessary. Recognizing nonuniform spatial variation distributions across\ndevices and tensor cores, we also propose a variation-aware architectural\nremapping strategy to avoid executing critical tasks on noisy devices.\nExtensive experiments show that our proposed framework can guarantee sustained\nperformance under drifting variations with 34% higher accuracy and 2-3\norders-of-magnitude lower overhead compared to state-of-the-art on-chip\ntraining methods. Our code is open-sourced at\nhttps://github.com/ScopeX-ASU/DOCTOR.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.ET",
    "comment": "9 pages. Accepted to IEEE JLT 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02688v2",
    "published_date": "2024-03-05 06:17:13 UTC",
    "updated_date": "2024-05-31 20:24:47 UTC"
  },
  {
    "arxiv_id": "2403.02687v2",
    "title": "Enhanced DareFightingICE Competitions: Sound Design and AI Competitions",
    "authors": [
      "Ibrahim Khan",
      "Chollakorn Nimpattanavong",
      "Thai Van Nguyen",
      "Kantinan Plupattanakit",
      "Ruck Thawonmas"
    ],
    "abstract": "This paper presents a new and improved DareFightingICE platform, a fighting\ngame platform with a focus on visually impaired players (VIPs), in the Unity\ngame engine. It also introduces the separation of the DareFightingICE\nCompetition into two standalone competitions called DareFightingICE Sound\nDesign Competition and DareFightingICE AI Competition--at the 2024 IEEE\nConference on Games (CoG)--in which a new platform will be used. This new\nplatform is an enhanced version of the old DareFightingICE platform, having a\nbetter audio system to convey 3D sound and a better way to send audio data to\nAI agents. With this enhancement and by utilizing Unity, the new\nDareFightingICE platform is more accessible in terms of adding new features for\nVIPs and future audio research. This paper also improves the evaluation method\nfor evaluating sound designs in the Sound Design Competition which will ensure\na better sound design for VIPs as this competition continues to run at future\nCoG. To the best of our knowledge, both of our competitions are first of their\nkind, and the connection between the competitions to mutually improve the\nentries' quality with time makes these competitions an important part of\nrepresenting an often overlooked segment within the broader gaming community,\nVIPs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "I.2; H.5.2; H.5.5"
    ],
    "primary_category": "cs.HC",
    "comment": "This paper describes a new competition platform using Unity for our\n  competitions at the 2024 IEEE Conference on Games (CoG 2024). It was accepted\n  for presentation at CoG 2024. However, we recently discovered a much more\n  effective way to do this task without using Unity, leading to our decision to\n  withdraw the paper from CoG 2024 and ArXiv",
    "pdf_url": "http://arxiv.org/pdf/2403.02687v2",
    "published_date": "2024-03-05 06:15:48 UTC",
    "updated_date": "2024-04-27 22:03:35 UTC"
  },
  {
    "arxiv_id": "2403.02651v1",
    "title": "Learning at the Speed of Wireless: Online Real-Time Learning for AI-Enabled MIMO in NextG",
    "authors": [
      "Jiarui Xu",
      "Shashank Jere",
      "Yifei Song",
      "Yi-Hung Kao",
      "Lizhong Zheng",
      "Lingjia Liu"
    ],
    "abstract": "Integration of artificial intelligence (AI) and machine learning (ML) into\nthe air interface has been envisioned as a key technology for next-generation\n(NextG) cellular networks. At the air interface, multiple-input multiple-output\n(MIMO) and its variants such as multi-user MIMO (MU-MIMO) and\nmassive/full-dimension MIMO have been key enablers across successive\ngenerations of cellular networks with evolving complexity and design\nchallenges. Initiating active investigation into leveraging AI/ML tools to\naddress these challenges for MIMO becomes a critical step towards an AI-enabled\nNextG air interface. At the NextG air interface, the underlying wireless\nenvironment will be extremely dynamic with operation adaptations performed on a\nsub-millisecond basis by MIMO operations such as MU-MIMO scheduling and\nrank/link adaptation. Given the enormously large number of operation adaptation\npossibilities, we contend that online real-time AI/ML-based approaches\nconstitute a promising paradigm. To this end, we outline the inherent\nchallenges and offer insights into the design of such online real-time\nAI/ML-based solutions for MIMO operations. An online real-time AI/ML-based\nmethod for MIMO-OFDM channel estimation is then presented, serving as a\npotential roadmap for developing similar techniques across various MIMO\noperations in NextG.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "7 pages, 4 figures, 1 table, magazine paper",
    "pdf_url": "http://arxiv.org/pdf/2403.02651v1",
    "published_date": "2024-03-05 04:48:24 UTC",
    "updated_date": "2024-03-05 04:48:24 UTC"
  },
  {
    "arxiv_id": "2403.02648v4",
    "title": "Remove that Square Root: A New Efficient Scale-Invariant Version of AdaGrad",
    "authors": [
      "Sayantan Choudhury",
      "Nazarii Tupitsa",
      "Nicolas Loizou",
      "Samuel Horvath",
      "Martin Takac",
      "Eduard Gorbunov"
    ],
    "abstract": "Adaptive methods are extremely popular in machine learning as they make\nlearning rate tuning less expensive. This paper introduces a novel optimization\nalgorithm named KATE, which presents a scale-invariant adaptation of the\nwell-known AdaGrad algorithm. We prove the scale-invariance of KATE for the\ncase of Generalized Linear Models. Moreover, for general smooth non-convex\nproblems, we establish a convergence rate of $O \\left(\\frac{\\log T}{\\sqrt{T}}\n\\right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also\ncompare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in\nnumerical experiments with different problems, including complex machine\nlearning tasks like image classification and text classification on real data.\nThe results indicate that KATE consistently outperforms AdaGrad and\nmatches/surpasses the performance of Adam in all considered scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02648v4",
    "published_date": "2024-03-05 04:35:59 UTC",
    "updated_date": "2025-01-13 19:05:07 UTC"
  },
  {
    "arxiv_id": "2403.02647v1",
    "title": "FinReport: Explainable Stock Earnings Forecasting via News Factor Analyzing Model",
    "authors": [
      "Xiangyu Li",
      "Xinjie Shen",
      "Yawen Zeng",
      "Xiaofen Xing",
      "Jin Xu"
    ],
    "abstract": "The task of stock earnings forecasting has received considerable attention\ndue to the demand investors in real-world scenarios. However, compared with\nfinancial institutions, it is not easy for ordinary investors to mine factors\nand analyze news. On the other hand, although large language models in the\nfinancial field can serve users in the form of dialogue robots, it still\nrequires users to have financial knowledge to ask reasonable questions. To\nserve the user experience, we aim to build an automatic system, FinReport, for\nordinary investors to collect information, analyze it, and generate reports\nafter summarizing.\n  Specifically, our FinReport is based on financial news announcements and a\nmulti-factor model to ensure the professionalism of the report. The FinReport\nconsists of three modules: news factorization module, return forecasting\nmodule, risk assessment module. The news factorization module involves\nunderstanding news information and combining it with stock factors, the return\nforecasting module aim to analysis the impact of news on market sentiment, and\nthe risk assessment module is adopted to control investment risk. Extensive\nexperiments on real-world datasets have well verified the effectiveness and\nexplainability of our proposed FinReport. Our codes and datasets are available\nat https://github.com/frinkleko/FinReport.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02647v1",
    "published_date": "2024-03-05 04:33:36 UTC",
    "updated_date": "2024-03-05 04:33:36 UTC"
  },
  {
    "arxiv_id": "2403.02635v1",
    "title": "PPS-QMIX: Periodically Parameter Sharing for Accelerating Convergence of Multi-Agent Reinforcement Learning",
    "authors": [
      "Ke Zhang",
      "DanDan Zhu",
      "Qiuhan Xu",
      "Hao Zhou",
      "Ce Zheng"
    ],
    "abstract": "Training for multi-agent reinforcement learning(MARL) is a time-consuming\nprocess caused by distribution shift of each agent. One drawback is that\nstrategy of each agent in MARL is independent but actually in cooperation.\nThus, a vertical issue in multi-agent reinforcement learning is how to\nefficiently accelerate training process. To address this problem, current\nresearch has leveraged a centralized function(CF) across multiple agents to\nlearn contribution of the team reward for each agent. However, CF based methods\nintroduce joint error from other agents in estimation of value network. In so\ndoing, inspired by federated learning, we propose three simple novel approaches\ncalled Average Periodically Parameter Sharing(A-PPS), Reward-Scalability\nPeriodically Parameter Sharing(RS-PPS) and Partial Personalized Periodically\nParameter Sharing(PP-PPS) mechanism to accelerate training of MARL. Agents\nshare Q-value network periodically during the training process. Agents which\nhas same identity adapt collected reward as scalability and update partial\nneural network during period to share different parameters. We apply our\napproaches in classical MARL method QMIX and evaluate our approaches on various\ntasks in StarCraft Multi-Agent Challenge(SMAC) environment. Performance of\nnumerical experiments yield enormous enhancement, with an average improvement\nof 10\\%-30\\%, and enable to win tasks that QMIX cannot. Our code can be\ndownloaded from https://github.com/ColaZhang22/PPS-QMIX",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02635v1",
    "published_date": "2024-03-05 03:59:01 UTC",
    "updated_date": "2024-03-05 03:59:01 UTC"
  },
  {
    "arxiv_id": "2403.02624v2",
    "title": "Pareto-Optimal Estimation and Policy Learning on Short-term and Long-term Treatment Effects",
    "authors": [
      "Yingrong Wang",
      "Anpeng Wu",
      "Haoxuan Li",
      "Weiming Liu",
      "Qiaowei Miao",
      "Ruoxuan Xiong",
      "Fei Wu",
      "Kun Kuang"
    ],
    "abstract": "This paper focuses on developing Pareto-optimal estimation and policy\nlearning to identify the most effective treatment that maximizes the total\nreward from both short-term and long-term effects, which might conflict with\neach other. For example, a higher dosage of medication might increase the speed\nof a patient's recovery (short-term) but could also result in severe long-term\nside effects. Although recent works have investigated the problems about\nshort-term or long-term effects or the both, how to trade-off between them to\nachieve optimal treatment remains an open challenge. Moreover, when multiple\nobjectives are directly estimated using conventional causal representation\nlearning, the optimization directions among various tasks can conflict as well.\nIn this paper, we systematically investigate these issues and introduce a\nPareto-Efficient algorithm, comprising Pareto-Optimal Estimation (POE) and\nPareto-Optimal Policy Learning (POPL), to tackle them. POE incorporates a\ncontinuous Pareto module with representation balancing, enhancing estimation\nefficiency across multiple tasks. As for POPL, it involves deriving short-term\nand long-term outcomes linked with various treatment levels, facilitating an\nexploration of the Pareto frontier emanating from these outcomes. Results on\nboth the synthetic and real-world datasets demonstrate the superiority of our\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02624v2",
    "published_date": "2024-03-05 03:32:02 UTC",
    "updated_date": "2024-03-12 06:28:39 UTC"
  },
  {
    "arxiv_id": "2403.02622v3",
    "title": "World Models for Autonomous Driving: An Initial Survey",
    "authors": [
      "Yanchen Guan",
      "Haicheng Liao",
      "Zhenning Li",
      "Jia Hu",
      "Runze Yuan",
      "Yunjian Li",
      "Guohui Zhang",
      "Chengzhong Xu"
    ],
    "abstract": "In the rapidly evolving landscape of autonomous driving, the capability to\naccurately predict future events and assess their implications is paramount for\nboth safety and efficiency, critically aiding the decision-making process.\nWorld models have emerged as a transformative approach, enabling autonomous\ndriving systems to synthesize and interpret vast amounts of sensor data,\nthereby predicting potential future scenarios and compensating for information\ngaps. This paper provides an initial review of the current state and\nprospective advancements of world models in autonomous driving, spanning their\ntheoretical underpinnings, practical applications, and the ongoing research\nefforts aimed at overcoming existing limitations. Highlighting the significant\nrole of world models in advancing autonomous driving technologies, this survey\naspires to serve as a foundational reference for the research community,\nfacilitating swift access to and comprehension of this burgeoning field, and\ninspiring continued innovation and exploration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02622v3",
    "published_date": "2024-03-05 03:23:55 UTC",
    "updated_date": "2024-05-07 13:28:48 UTC"
  },
  {
    "arxiv_id": "2403.02616v1",
    "title": "Unsupervised Spatio-Temporal State Estimation for Fine-grained Adaptive Anomaly Diagnosis of Industrial Cyber-physical Systems",
    "authors": [
      "Haili Sun",
      "Yan Huang",
      "Lansheng Han",
      "Cai Fu",
      "Chunjie Zhou"
    ],
    "abstract": "Accurate detection and diagnosis of abnormal behaviors such as network\nattacks from multivariate time series (MTS) are crucial for ensuring the stable\nand effective operation of industrial cyber-physical systems (CPS). However,\nexisting researches pay little attention to the logical dependencies among\nsystem working states, and have difficulties in explaining the evolution\nmechanisms of abnormal signals. To reveal the spatio-temporal association\nrelationships and evolution mechanisms of the working states of industrial CPS,\nthis paper proposes a fine-grained adaptive anomaly diagnosis method (i.e.\nMAD-Transformer) to identify and diagnose anomalies in MTS. MAD-Transformer\nfirst constructs a temporal state matrix to characterize and estimate the\nchange patterns of the system states in the temporal dimension. Then, to better\nlocate the anomalies, a spatial state matrix is also constructed to capture the\ninter-sensor state correlation relationships within the system. Subsequently,\nbased on these two types of state matrices, a three-branch structure of\nseries-temporal-spatial attention module is designed to simultaneously capture\nthe series, temporal, and space dependencies among MTS. Afterwards, three\nassociated alignment loss functions and a reconstruction loss are constructed\nto jointly optimize the model. Finally, anomalies are determined and diagnosed\nby comparing the residual matrices with the original matrices. We conducted\ncomparative experiments on five publicly datasets spanning three application\ndomains (service monitoring, spatial and earth exploration, and water\ntreatment), along with a petroleum refining simulation dataset collected by\nourselves. The results demonstrate that MAD-Transformer can adaptively detect\nfine-grained anomalies with short duration, and outperforms the\nstate-of-the-art baselines in terms of noise robustness and localization\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.NI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02616v1",
    "published_date": "2024-03-05 03:11:02 UTC",
    "updated_date": "2024-03-05 03:11:02 UTC"
  },
  {
    "arxiv_id": "2403.02613v1",
    "title": "Large Language Models and Video Games: A Preliminary Scoping Review",
    "authors": [
      "Penny Sweetser"
    ],
    "abstract": "Large language models (LLMs) hold interesting potential for the design,\ndevelopment, and research of video games. Building on the decades of prior\nresearch on generative AI in games, many researchers have sped to investigate\nthe power and potential of LLMs for games. Given the recent spike in\nLLM-related research in games, there is already a wealth of relevant research\nto survey. In order to capture a snapshot of the state of LLM research in\ngames, and to help lay the foundation for future work, we carried out an\ninitial scoping review of relevant papers published so far. In this paper, we\nreview 76 papers published between 2022 to early 2024 on LLMs and video games,\nwith key focus areas in game AI, game development, narrative, and game research\nand reviews. Our paper provides an early state of the field and lays the\ngroundwork for future research and reviews on this topic.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2403.02613v1",
    "published_date": "2024-03-05 03:04:35 UTC",
    "updated_date": "2024-03-05 03:04:35 UTC"
  },
  {
    "arxiv_id": "2403.02611v3",
    "title": "A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid Transformer and Contrastive Learning",
    "authors": [
      "Yuelin Zhang",
      "Pengyu Zheng",
      "Wanquan Yan",
      "Chengyu Fang",
      "Shing Shin Cheng"
    ],
    "abstract": "Defocus blur is a persistent problem in microscope imaging that poses harm to\npathology interpretation and medical intervention in cell microscopy and\nmicroscope surgery. To address this problem, a unified framework including the\nmulti-pyramid transformer (MPT) and extended frequency contrastive\nregularization (EFCR) is proposed to tackle two outstanding challenges in\nmicroscopy deblur: longer attention span and data deficiency. The MPT employs\nan explicit pyramid structure at each network stage that integrates the\ncross-scale window attention (CSWA), the intra-scale channel attention (ISCA),\nand the feature-enhancing feed-forward network (FEFN) to capture long-range\ncross-scale spatial interaction and global channel context. The EFCR addresses\nthe data deficiency problem by exploring latent deblur signals from different\nfrequency bands. It also enables deblur knowledge transfer to learn\ncross-domain information from extra data, improving deblur performance for\nlabeled and unlabeled data. Extensive experiments and downstream task\nvalidation show the framework achieves state-of-the-art performance across\nmultiple datasets. Project page: https://github.com/PieceZhang/MPT-CataBlur.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.02611v3",
    "published_date": "2024-03-05 02:59:35 UTC",
    "updated_date": "2024-06-04 02:47:19 UTC"
  },
  {
    "arxiv_id": "2403.02610v1",
    "title": "ChatGPT4PCG 2 Competition: Prompt Engineering for Science Birds Level Generation",
    "authors": [
      "Pittawat Taveekitworachai",
      "Febri Abdullah",
      "Mury F. Dewantoro",
      "Yi Xia",
      "Pratch Suntichaikul",
      "Ruck Thawonmas",
      "Julian Togelius",
      "Jochen Renz"
    ],
    "abstract": "This paper presents the second ChatGPT4PCG competition at the 2024 IEEE\nConference on Games. In this edition of the competition, we follow the first\nedition, but make several improvements and changes. We introduce a new\nevaluation metric along with allowing a more flexible format for participants'\nsubmissions and making several improvements to the evaluation pipeline.\nContinuing from the first edition, we aim to foster and explore the realm of\nprompt engineering (PE) for procedural content generation (PCG). While the\nfirst competition saw success, it was hindered by various limitations; we aim\nto mitigate these limitations in this edition. We introduce diversity as a new\nmetric to discourage submissions aimed at producing repetitive structures.\nFurthermore, we allow submission of a Python program instead of a prompt text\nfile for greater flexibility in implementing advanced PE approaches, which may\nrequire control flow, including conditions and iterations. We also make several\nimprovements to the evaluation pipeline with a better classifier for similarity\nevaluation and better-performing function signatures. We thoroughly evaluate\nthe effectiveness of the new metric and the improved classifier. Additionally,\nwe perform an ablation study to select a function signature to instruct ChatGPT\nfor level generation. Finally, we provide implementation examples of various PE\ntechniques in Python and evaluate their preliminary performance. We hope this\ncompetition serves as a resource and platform for learning about PE and PCG in\ngeneral.",
    "categories": [
      "cs.AI",
      "I.2.7; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02610v1",
    "published_date": "2024-03-05 02:58:57 UTC",
    "updated_date": "2024-03-05 02:58:57 UTC"
  },
  {
    "arxiv_id": "2403.02607v1",
    "title": "MEBS: Multi-task End-to-end Bid Shading for Multi-slot Display Advertising",
    "authors": [
      "Zhen Gong",
      "Lvyin Niu",
      "Yang Zhao",
      "Miao Xu",
      "Zhenzhe Zheng",
      "Haoqi Zhang",
      "Zhilin Zhang",
      "Fan Wu",
      "Rongquan Bai",
      "Chuan Yu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "abstract": "Online bidding and auction are crucial aspects of the online advertising\nindustry. Conventionally, there is only one slot for ad display and most\ncurrent studies focus on it. Nowadays, multi-slot display advertising is\ngradually becoming popular where many ads could be displayed in a list and\nshown as a whole to users. However, multi-slot display advertising leads to\ndifferent cost-effectiveness. Advertisers have the incentive to adjust bid\nprices so as to win the most economical ad positions. In this study, we\nintroduce bid shading into multi-slot display advertising for bid price\nadjustment with a Multi-task End-to-end Bid Shading(MEBS) method. We prove the\noptimality of our method theoretically and examine its performance\nexperimentally. Through extensive offline and online experiments, we\ndemonstrate the effectiveness and efficiency of our method, and we obtain a\n7.01% lift in Gross Merchandise Volume, a 7.42% lift in Return on Investment,\nand a 3.26% lift in ad buy count.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02607v1",
    "published_date": "2024-03-05 02:44:58 UTC",
    "updated_date": "2024-03-05 02:44:58 UTC"
  },
  {
    "arxiv_id": "2403.02589v1",
    "title": "MUSIC: Accelerated Convergence for Distributed Optimization With Inexact and Exact Methods",
    "authors": [
      "Mou Wu",
      "Haibin Liao",
      "Zhengtao Ding",
      "Yonggang Xiao"
    ],
    "abstract": "Gradient-type distributed optimization methods have blossomed into one of the\nmost important tools for solving a minimization learning task over a networked\nagent system. However, only one gradient update per iteration is difficult to\nachieve a substantive acceleration of convergence. In this paper, we propose an\naccelerated framework named as MUSIC allowing each agent to perform multiple\nlocal updates and a single combination in each iteration. More importantly, we\nequip inexact and exact distributed optimization methods into this framework,\nthereby developing two new algorithms that exhibit accelerated linear\nconvergence and high communication efficiency. Our rigorous convergence\nanalysis reveals the sources of steady-state errors arising from inexact\npolicies and offers effective solutions. Numerical results based on synthetic\nand real datasets demonstrate both our theoretical motivations and analysis, as\nwell as performance advantages.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02589v1",
    "published_date": "2024-03-05 02:02:00 UTC",
    "updated_date": "2024-03-05 02:02:00 UTC"
  },
  {
    "arxiv_id": "2403.02574v1",
    "title": "ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary",
    "authors": [
      "Yutong Li",
      "Lu Chen",
      "Aiwei Liu",
      "Kai Yu",
      "Lijie Wen"
    ],
    "abstract": "The literature review is an indispensable step in the research process. It\nprovides the benefit of comprehending the research problem and understanding\nthe current research situation while conducting a comparative analysis of prior\nworks. However, literature summary is challenging and time consuming. The\nprevious LLM-based studies on literature review mainly focused on the complete\nprocess, including literature retrieval, screening, and summarization. However,\nfor the summarization step, simple CoT method often lacks the ability to\nprovide extensive comparative summary. In this work, we firstly focus on the\nindependent literature summarization step and introduce ChatCite, an LLM agent\nwith human workflow guidance for comparative literature summary. This agent, by\nmimicking the human workflow, first extracts key elements from relevant\nliterature and then generates summaries using a Reflective Incremental\nMechanism. In order to better evaluate the quality of the generated summaries,\nwe devised a LLM-based automatic evaluation metric, G-Score, in refer to the\nhuman evaluation criteria. The ChatCite agent outperformed other models in\nvarious dimensions in the experiments. The literature summaries generated by\nChatCite can also be directly used for drafting literature reviews.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.IR",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.02574v1",
    "published_date": "2024-03-05 01:13:56 UTC",
    "updated_date": "2024-03-05 01:13:56 UTC"
  },
  {
    "arxiv_id": "2403.02567v2",
    "title": "Eliciting Better Multilingual Structured Reasoning from LLMs through Code",
    "authors": [
      "Bryan Li",
      "Tamer Alkhouli",
      "Daniele Bonadiman",
      "Nikolaos Pappas",
      "Saab Mansour"
    ],
    "abstract": "The development of large language models (LLM) has shown progress on\nreasoning, though studies have largely considered either English or simple\nreasoning tasks. To address this, we introduce a multilingual structured\nreasoning and explanation dataset, termed xSTREET, that covers four tasks\nacross six languages. xSTREET exposes a gap in base LLM performance between\nEnglish and non-English reasoning tasks.\n  We then propose two methods to remedy this gap, building on the insight that\nLLMs trained on code are better reasoners. First, at training time, we augment\na code dataset with multilingual comments using machine translation while\nkeeping program code as-is. Second, at inference time, we bridge the gap\nbetween training and inference by employing a prompt structure that\nincorporates step-by-step code primitives to derive new facts and find a\nsolution. Our methods show improved multilingual performance on xSTREET, most\nnotably on the scientific commonsense reasoning subtask. Furthermore, the\nmodels show no regression on non-reasoning tasks, thus demonstrating our\ntechniques maintain general-purpose abilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.02567v2",
    "published_date": "2024-03-05 00:48:56 UTC",
    "updated_date": "2024-06-12 07:13:01 UTC"
  }
]