{
  "date": "2025-01-28",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-28 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的安全性、解释性和实际应用（如医疗和机器人领域），强调了大型语言模型（LLM）的优化、强化学习（RL）的创新，以及高效计算框架；令人印象深刻的是 VeriFact 在临床文本验证中的高精度表现，以及 DebiasPI 在缓解 AI 偏置方面的实用性贡献。\n\n### 重点论文讨论\n我将优先讨论重要且话题度高的论文，包括 AI 安全、LLM 应用和医疗领域的创新，其他次要论文将快速概述。以下按主题分组，突出核心贡献。\n\n#### AI 安全与 LLM 优化\n- **DebiasPI: Inference-time Debiasing by Prompt Iteration of a Text-to-Image Generative Model（DebiasPI: 通过提示迭代进行文本到图像生成模型的推理时偏置缓解）**  \n  这篇论文提出 DebiasPI 框架，用于推理阶段动态调整提示以减少文本到图像模型中的种族和性别偏置。主要贡献是通过跟踪属性（如种族和性别）分布并迭代优化，确保生成图像更公平；实验显示，它能平衡种族表示，同时改善性别多样性，适用于新闻图像生成等领域。\n\n- **A sketch of an AI control safety case（AI 控制安全案例草图）**  \n  作者包括知名学者 Geoffrey Irving，该论文草拟了 AI 控制安全案例框架，聚焦 LLM 代理的安全性。主要发现是通过控制评估和红队测试，证明模型无法规避监控以泄露敏感信息；这为部署高风险 LLM 代理提供了结构化论证，具有重要实际意义。\n\n- **Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization（通过 hallucination 聚焦的偏好优化缓解大型语言模型中的幻觉翻译）**  \n  论文引入数据生成框架来优化 LLM 的机器翻译，减少幻觉。主要贡献是细化偏好数据集，使幻觉率降低 96%，并在零样本设置中平均减少 89%；这提升了 LLM 在翻译任务的可靠性和效率。\n\n#### 医疗 AI 与 LLM 应用\n- **VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records（VeriFact: 使用电子健康记录验证 LLM 生成的临床文本事实）**  \n  这篇论文开发了 VeriFact 系统，结合检索增强生成和 LLM 判断验证临床文本的真实性。主要发现是 VeriFact 在 EHR 对比中达到 92.7% 的准确率，超过平均临床医生水平；作者 Nigam Shah 等知名学者参与，这为 LLM 在医疗中的事实检查提供了突破。\n\n- **Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks（微调开源大型语言模型以提升其在放射肿瘤学任务中的性能）**  \n  论文探索微调 LLM（如 LLaMA2-7B）用于放射肿瘤学任务，如治疗方案生成。主要贡献是通过低秩逼近方法，微调模型在诊断和 ICD-10 代码预测上显著提升精度；实验显示，微调后模型超过 60% 的治疗方案被临床专家认可，适用于资源有限的医疗场景。\n\n- **Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction（记忆与排序：提升大型语言模型在临床诊断预测中的性能）**  \n  作者包括 Wei Wang，该论文提出 MERA 模型，通过分层对比学习和微调提升 LLM 在临床诊断中的表现。主要发现是 MERA 在 MIMIC-III/IV 数据集上达到最先进水平，显著减少诊断错误；这展示了 LLM 在医疗决策中的潜力。\n\n#### 强化学习与机器人应用\n- **Engaging with AI: How Interface Design Shapes Human-AI Collaboration in High-Stakes Decision-Making（与 AI 互动：界面设计如何塑造人类-AI 在高风险决策中的协作）**  \n  论文研究界面设计（如认知强制函数）如何影响人类-AI 团队在医疗决策中的表现。主要贡献是实验显示特定机制（如 AI 置信度提示）提升任务成功率和信任；这为高风险领域如医疗提供实用指导。\n\n- **Safe Reinforcement Learning for Real-World Engine Control（安全强化学习在真实引擎控制中的应用）**  \n  论文应用 DDPG 算法于内燃引擎控制，确保安全。主要发现是通过 k-最近邻监控，RL 代理在 HCCI 模式下实现高效控制，RMSE 仅 0.1374 bar；这证明 RL 在安全关键系统中的可行性。\n\n#### 其他值得注意的论文\n- **TAID: Temporally Adaptive Interpolated Distillation for Efficient Knowledge Transfer in Language Models（TAID: 用于高效知识传输的时序自适应插值蒸馏）**  \n  快速提炼：提出 TAID 框架，通过自适应插值减少知识转移中的模式崩溃，提升 LLM 效率；实验显示在指令微调和预训练中表现优异。\n\n- **MCTS-SQL: An Effective Framework for Text-to-SQL with Monte Carlo Tree Search（MCTS-SQL: 使用 Monte Carlo 树搜索的文本到 SQL 有效框架）**  \n  简要：开发 MCTS-SQL 通过迭代搜索提升文本到 SQL 准确性；Spider 基准测试显示执行准确率达 69.40%，适合复杂查询。\n\n其他论文，如那些专注于特定技术优化（如 Graph Neural Networks 或量子模型）的，我会快速掠过，因为它们相对次要或更技术导向。例如，\"Graph Transformers for inverse physics\"（用于逆物理的 Graph Transformer）主要贡献是重建空气动力场，但影响较窄；\"Efficient Knowledge Distillation of SAM\"（SAM 的高效知识蒸馏）则在医疗图像分割中优化模型，但未有突破性发现。这些论文的核心术语如 Graph Neural Network 和知识蒸馏已被保留，但不展开讨论，以控制篇幅。\n\n总之，今天的论文突显了 AI 在安全和应用领域的进展，VeriFact 和 DebiasPI 等工作可能引发更广泛讨论，期待后续研究！（本快报基于92篇论文精选，力求简洁。）",
  "papers": [
    {
      "arxiv_id": "2503.15512v1",
      "title": "Beyond Accuracy, SHAP, and Anchors -- On the difficulty of designing effective end-user explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Abba Omar",
        "Nadia Nahar",
        "Jacob Tjaden",
        "Inès M. Gilles",
        "Fikir Mekonnen",
        "Jane Hsieh",
        "Christian Kästner",
        "Alka Menon"
      ],
      "abstract": "Modern machine learning produces models that are impossible for users or\ndevelopers to fully understand -- raising concerns about trust, oversight and\nhuman dignity. Transparency and explainability methods aim to provide some help\nin understanding models, but it remains challenging for developers to design\nexplanations that are understandable to target users and effective for their\npurpose. Emerging guidelines and regulations set goals but may not provide\neffective actionable guidance to developers. In a controlled experiment with\n124 participants, we investigate whether and how specific forms of policy\nguidance help developers design explanations for an ML-powered screening tool\nfor diabetic retinopathy. Contrary to our expectations, we found that\nparticipants across the board struggled to produce quality explanations, comply\nwith the provided policy requirements for explainability, and provide evidence\nof compliance. We posit that participant noncompliance is in part due to a\nfailure to imagine and anticipate the needs of their audience, particularly\nnon-technical stakeholders. Drawing on cognitive process theory and the\nsociological imagination to contextualize participants' failure, we recommend\neducational interventions.",
      "tldr_zh": "该研究探讨了设计有效端用户解释的挑战，超越了Accuracy、SHAP和Anchors等传统方法，强调现代机器学习模型的复杂性引发了信任、监督和人类尊严等问题。在一项涉及124名参与者的控制实验中，研究者测试了政策指导是否能帮助开发者为糖尿病视网膜病变筛查工具创建高质量解释，结果显示参与者普遍难以产生符合要求的解释、遵守政策并提供合规证据。研究归因于开发者未能预见非技术利益相关者的需求，并基于cognitive process theory和社会学想象力(sociological imagination)推荐教育干预作为改进策略。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15512v1",
      "published_date": "2025-01-28 23:54:00 UTC",
      "updated_date": "2025-01-28 23:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:00:59.410461"
    },
    {
      "arxiv_id": "2501.17347v1",
      "title": "Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Md Tauhidul Islam",
        "Lei Xing"
      ],
      "abstract": "Advancements in deep learning are revolutionizing science and engineering.\nThe immense success of deep learning is largely due to its ability to extract\nessential high-dimensional (HD) features from input data and make inference\ndecisions based on this information. However, current deep neural network (DNN)\nmodels face several challenges, such as the requirements of extensive amounts\nof data and computational resources. Here, we introduce a new learning scheme,\nreferred to as deep-and-wide learning (DWL), to systematically capture features\nnot only within individual input data (intra-data features) but also across the\ndata (inter-data features). Furthermore, we propose a dual-interactive-channel\nnetwork (D-Net) to realize the DWL, which leverages our Bayesian formulation of\nlow-dimensional (LD) inter-data feature extraction and its synergistic\ninteraction with the conventional HD representation of the dataset, for\nsubstantially enhanced computational efficiency and inference. The proposed\ntechnique has been applied to data across various disciplines for both\nclassification and regression tasks. Our results demonstrate that DWL surpasses\nstate-of-the-art DNNs in accuracy by a substantial margin with limited training\ndata and improves the computational efficiency by order(s) of magnitude. The\nproposed DWL strategy dramatically alters the data-driven learning techniques,\nincluding emerging large foundation models, and sheds significant insights into\nthe evolving field of AI.",
      "tldr_zh": "该论文提出了一种名为 Deep-and-Wide Learning (DWL) 的新学习方案，旨在通过协同学习数据内部（intra-data features）和数据间（inter-data features）的表示，来提升数据驱动推理的准确性和效率。作者设计了 dual-interactive-channel network (D-Net)，结合 Bayesian formulation 提取低维（LD）inter-data 特征，并与高维（HD）数据表示互动，实现计算资源的优化。实验结果显示，DWL 在分类和回归任务上大幅超越现有深度神经网络 (DNNs)，特别是在训练数据有限的情况下准确率显著提高，并将计算效率提升数倍，为数据驱动学习和 AI 领域带来重要变革。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.17347v1",
      "published_date": "2025-01-28 23:47:34 UTC",
      "updated_date": "2025-01-28 23:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:01:13.283249"
    },
    {
      "arxiv_id": "2502.00052v1",
      "title": "Bridging Contrastive Learning and Domain Adaptation: Theoretical Perspective and Practical Application",
      "title_zh": "桥接对比学习和领域适应：理论视角与实际应用",
      "authors": [
        "Gonzalo Iñaki Quintana",
        "Laurence Vancamberg",
        "Vincent Jugnon",
        "Agnès Desolneux",
        "Mathilde Mougeot"
      ],
      "abstract": "This work studies the relationship between Contrastive Learning and Domain\nAdaptation from a theoretical perspective. The two standard contrastive losses,\nNT-Xent loss (Self-supervised) and Supervised Contrastive loss, are related to\nthe Class-wise Mean Maximum Discrepancy (CMMD), a dissimilarity measure widely\nused for Domain Adaptation. Our work shows that minimizing the contrastive\nlosses decreases the CMMD and simultaneously improves class-separability,\nlaying the theoretical groundwork for the use of Contrastive Learning in the\ncontext of Domain Adaptation. Due to the relevance of Domain Adaptation in\nmedical imaging, we focused the experiments on mammography images. Extensive\nexperiments on three mammography datasets - synthetic patches, clinical (real)\npatches, and clinical (real) images - show improved Domain Adaptation,\nclass-separability, and classification performance, when minimizing the\nSupervised Contrastive loss.",
      "tldr_zh": "这篇论文从理论角度探讨了Contrastive Learning与Domain Adaptation之间的关系，将NT-Xent loss和Supervised Contrastive loss与Class-wise Mean Maximum Discrepancy (CMMD)联系起来。研究证明，最小化这些contrastive losses可以减少CMMD并同时提高类别的可分离性，为在Domain Adaptation中使用Contrastive Learning提供了理论基础。在乳腺X光图像数据集上的实验显示，使用Supervised Contrastive loss显著提升了Domain Adaptation效果、类可分离性和分类性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00052v1",
      "published_date": "2025-01-28 23:45:58 UTC",
      "updated_date": "2025-01-28 23:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:01:23.908029"
    },
    {
      "arxiv_id": "2501.17343v1",
      "title": "Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines",
      "title_zh": "翻译失败",
      "authors": [
        "Chongyu Qu",
        "Ritchie Zhao",
        "Ye Yu",
        "Bin Liu",
        "Tianyuan Yao",
        "Junchao Zhu",
        "Bennett A. Landman",
        "Yucheng Tang",
        "Yuankai Huo"
      ],
      "abstract": "Quantizing deep neural networks ,reducing the precision (bit-width) of their\ncomputations, can remarkably decrease memory usage and accelerate processing,\nmaking these models more suitable for large-scale medical imaging applications\nwith limited computational resources. However, many existing methods studied\n\"fake quantization\", which simulates lower precision operations during\ninference, but does not actually reduce model size or improve real-world\ninference speed. Moreover, the potential of deploying real 3D low-bit\nquantization on modern GPUs is still unexplored. In this study, we introduce a\nreal post-training quantization (PTQ) framework that successfully implements\ntrue 8-bit quantization on state-of-the-art (SOTA) 3D medical segmentation\nmodels, i.e., U-Net, SegResNet, SwinUNETR, nnU-Net, UNesT, TransUNet,\nST-UNet,and VISTA3D. Our approach involves two main steps. First, we use\nTensorRT to perform fake quantization for both weights and activations with\nunlabeled calibration dataset. Second, we convert this fake quantization into\nreal quantization via TensorRT engine on real GPUs, resulting in real-world\nreductions in model size and inference latency. Extensive experiments\ndemonstrate that our framework effectively performs 8-bit quantization on GPUs\nwithout sacrificing model performance. This advancement enables the deployment\nof efficient deep learning models in medical imaging applications where\ncomputational resources are constrained. The code and models have been\nreleased, including U-Net, TransUNet pretrained on the BTCV dataset for\nabdominal (13-label) segmentation, UNesT pretrained on the Whole Brain Dataset\nfor whole brain (133-label) segmentation, and nnU-Net, SegResNet, SwinUNETR and\nVISTA3D pretrained on TotalSegmentator V2 for full body (104-label)\nsegmentation. https://github.com/hrlblab/PTQ.",
      "tldr_zh": "本文研究了后训练量化(PTQ)应用于3D医疗图像分割，旨在通过真实量化减少模型大小和推断延迟，以适应资源受限的医疗成像场景。方法包括使用TensorRT进行权重和激活的假量化，然后转换为真实8位量化，成功应用于SOTA模型如U-Net、SwinUNETR和nnU-Net。实验证明，该框架在GPU上实现了显著的模型压缩和速度提升，而不牺牲分割性能，并开源了代码和预训练模型以促进实际部署。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17343v1",
      "published_date": "2025-01-28 23:29:40 UTC",
      "updated_date": "2025-01-28 23:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:01:35.720908"
    },
    {
      "arxiv_id": "2501.17338v1",
      "title": "Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection",
      "title_zh": "从 Logits 推断：探索无解码生成候选选择的最佳实践",
      "authors": [
        "Mingyu Derek Ma",
        "Yanna Ding",
        "Zijie Huang",
        "Jianxi Gao",
        "Yizhou Sun",
        "Wei Wang"
      ],
      "abstract": "Generative Language Models rely on autoregressive decoding to produce the\noutput sequence token by token. Many tasks such as preference optimization,\nrequire the model to produce task-level output consisting of multiple tokens\ndirectly by selecting candidates from a pool as predictions. Determining a\ntask-level prediction from candidates using the ordinary token-level decoding\nmechanism is constrained by time-consuming decoding and interrupted gradients\nby discrete token selection. Existing works have been using decoding-free\ncandidate selection methods to obtain candidate probability from initial output\nlogits over vocabulary. Though these estimation methods are widely used, they\nare not systematically evaluated, especially on end tasks. We introduce an\nevaluation of a comprehensive collection of decoding-free candidate selection\napproaches on a comprehensive set of tasks, including five multiple-choice QA\ntasks with a small candidate pool and four clinical decision tasks with a\nmassive amount of candidates, some with 10k+ options. We evaluate the\nestimation methods paired with a wide spectrum of foundation LMs covering\ndifferent architectures, sizes and training paradigms. The results and insights\nfrom our analysis inform the future model design.",
      "tldr_zh": "该论文探讨了从logits直接推断候选概率的无解码生成方法，以优化生成语言模型在任务级预测（如偏好优化）中的性能，避免传统自回归解码的耗时和梯度中断问题。作者系统评估了多种无解码候选选择方法，在五种多选QA任务（小候选池）和四种临床决策任务（大候选池，超过10k选项）上进行测试，并结合不同架构、规模和训练范式的基础语言模型进行对比。结果提供宝贵见解，有助于指导未来模型的设计和改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17338v1",
      "published_date": "2025-01-28 23:21:28 UTC",
      "updated_date": "2025-01-28 23:21:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:01:47.212963"
    },
    {
      "arxiv_id": "2501.18642v1",
      "title": "DebiasPI: Inference-time Debiasing by Prompt Iteration of a Text-to-Image Generative Model",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Bonna",
        "Yu-Cheng Huang",
        "Ekaterina Novozhilova",
        "Sejin Paik",
        "Zhengyang Shan",
        "Michelle Yilin Feng",
        "Ge Gao",
        "Yonish Tayal",
        "Rushil Kulkarni",
        "Jialin Yu",
        "Nupur Divekar",
        "Deepti Ghadiyaram",
        "Derry Wijaya",
        "Margrit Betke"
      ],
      "abstract": "Ethical intervention prompting has emerged as a tool to counter demographic\nbiases of text-to-image generative AI models. Existing solutions either require\nto retrain the model or struggle to generate images that reflect desired\ndistributions on gender and race. We propose an inference-time process called\nDebiasPI for Debiasing-by-Prompt-Iteration that provides prompt intervention by\nenabling the user to control the distributions of individuals' demographic\nattributes in image generation. DebiasPI keeps track of which attributes have\nbeen generated either by probing the internal state of the model or by using\nexternal attribute classifiers. Its control loop guides the text-to-image model\nto select not yet sufficiently represented attributes, With DebiasPI, we were\nable to create images with equal representations of race and gender that\nvisualize challenging concepts of news headlines. We also experimented with the\nattributes age, body type, profession, and skin tone, and measured how\nattributes change when our intervention prompt targets the distribution of an\nunrelated attribute type. We found, for example, if the text-to-image model is\nasked to balance racial representation, gender representation improves but the\nskin tone becomes less diverse. Attempts to cover a wide range of skin colors\nwith various intervention prompts showed that the model struggles to generate\nthe palest skin tones. We conducted various ablation studies, in which we\nremoved DebiasPI's attribute control, that reveal the model's propensity to\ngenerate young, male characters. It sometimes visualized career success by\ngenerating two-panel images with a pre-success dark-skinned person becoming\nlight-skinned with success, or switching gender from pre-success female to\npost-success male, thus further motivating ethical intervention prompting with\nDebiasPI.",
      "tldr_zh": "该论文提出了一种推理时（inference-time）方法 DebiasPI，通过提示迭代（prompt iteration）来减少文本到图像生成模型（text-to-image generative model）的人口统计偏差，如性别和种族。DebiasPI 通过跟踪生成的属性（利用模型内部状态探测或外部分类器）并引导模型优先选择未充分代表的属性，从而允许用户控制图像中个体属性的分布。实验结果显示，该方法能生成种族和性别均衡的图像，尤其适用于可视化新闻标题的复杂概念，但也发现平衡某些属性（如种族）可能导致其他属性（如肤色多样性）减少，且模型倾向于生成年轻、男性角色，进一步强调了这种道德干预的必要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work was presented at The European Conference on Computer Vision\n  (ECCV) 2024 Workshop \"Fairness and ethics towards transparent AI: facing the\n  chalLEnge through model Debiasing\" (FAILED), Milano, Italy, on September 29,\n  2024, https://failed-workshop-eccv-2024.github.io",
      "pdf_url": "http://arxiv.org/pdf/2501.18642v1",
      "published_date": "2025-01-28 23:17:20 UTC",
      "updated_date": "2025-01-28 23:17:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:01:59.967809"
    },
    {
      "arxiv_id": "2501.17329v1",
      "title": "Anomaly Detection in Cooperative Vehicle Perception Systems under Imperfect Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Ashish Bastola",
        "Hao Wang",
        "Abolfazl Razi"
      ],
      "abstract": "Anomaly detection is a critical requirement for ensuring safety in autonomous\ndriving. In this work, we leverage Cooperative Perception to share information\nacross nearby vehicles, enabling more accurate identification and consensus of\nanomalous behaviors in complex traffic scenarios. To account for the real-world\nchallenge of imperfect communication, we propose a cooperative-perception-based\nanomaly detection framework (CPAD), which is a robust architecture that remains\neffective under communication interruptions, thereby facilitating reliable\nperformance even in low-bandwidth settings. Since no multi-agent anomaly\ndetection dataset exists for vehicle trajectories, we introduce 15,000\ndifferent scenarios with a 90,000 trajectories benchmark dataset generated\nthrough rule-based vehicle dynamics analysis. Empirical results demonstrate\nthat our approach outperforms standard anomaly classification methods in\nF1-score, AUC and showcase strong robustness to agent connection interruptions.",
      "tldr_zh": "这篇论文探讨了在不完善通信条件下，Cooperative Vehicle Perception 系统中的异常检测问题，以提升自动驾驶的安全性。作者提出 CPAD 框架，利用 Cooperative Perception 共享车辆信息，实现对异常行为的准确识别和共识，同时确保在通信中断或低带宽环境下保持鲁棒性。为此，他们创建了一个新的基准数据集，包含 15,000 个场景和 90,000 个车辆轨迹。实验结果显示，CPAD 在 F1-score 和 AUC 上优于传统异常分类方法，并展示了强烈的鲁棒性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.17329v1",
      "published_date": "2025-01-28 22:41:06 UTC",
      "updated_date": "2025-01-28 22:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:02:11.337754"
    },
    {
      "arxiv_id": "2501.17326v1",
      "title": "Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyu Derek Ma",
        "Xiaoxuan Wang",
        "Yijia Xiao",
        "Anthony Cuturrufo",
        "Vijay S Nori",
        "Eran Halperin",
        "Wei Wang"
      ],
      "abstract": "Clinical diagnosis prediction models, when provided with a patient's medical\nhistory, aim to detect potential diseases early, facilitating timely\nintervention and improving prognostic outcomes. However, the inherent scarcity\nof patient data and large disease candidate space often pose challenges in\ndeveloping satisfactory models for this intricate task. The exploration of\nleveraging Large Language Models (LLMs) for encapsulating clinical decision\nprocesses has been limited. We introduce MERA, a clinical diagnosis prediction\nmodel that bridges pertaining natural language knowledge with medical practice.\nWe apply hierarchical contrastive learning on a disease candidate ranking list\nto alleviate the large decision space issue. With concept memorization through\nfine-tuning, we bridge the natural language clinical knowledge with medical\ncodes. Experimental results on MIMIC-III and IV datasets show that MERA\nachieves the state-of-the-art diagnosis prediction performance and dramatically\nelevates the diagnosis prediction capabilities of generative LMs.",
      "tldr_zh": "这篇论文提出 MERA 模型，利用 Large Language Models (LLMs) 来提升临床诊断预测能力，针对患者医疗历史数据稀缺和疾病候选空间大的挑战。MERA 通过 hierarchical contrastive learning 对疾病候选列表进行分层对比学习，并采用 concept memorization 微调方法，将自然语言临床知识与医疗代码桥接。实验结果显示，在 MIMIC-III 和 IV 数据集上，MERA 达到了 state-of-the-art 的诊断预测性能，并显著提升了生成式 LMs 的诊断能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.17326v1",
      "published_date": "2025-01-28 22:38:45 UTC",
      "updated_date": "2025-01-28 22:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:02:23.146901"
    },
    {
      "arxiv_id": "2501.17325v2",
      "title": "Connecting Federated ADMM to Bayes",
      "title_zh": "翻译失败",
      "authors": [
        "Siddharth Swaroop",
        "Mohammad Emtiyaz Khan",
        "Finale Doshi-Velez"
      ],
      "abstract": "We provide new connections between two distinct federated learning approaches\nbased on (i) ADMM and (ii) Variational Bayes (VB), and propose new variants by\ncombining their complementary strengths. Specifically, we show that the dual\nvariables in ADMM naturally emerge through the 'site' parameters used in VB\nwith isotropic Gaussian covariances. Using this, we derive two versions of ADMM\nfrom VB that use flexible covariances and functional regularisation,\nrespectively. Through numerical experiments, we validate the improvements\nobtained in performance. The work shows connection between two fields that are\nbelieved to be fundamentally different and combines them to improve federated\nlearning.",
      "tldr_zh": "本研究建立了 Federated ADMM 和 Variational Bayes (VB) 之间的联系，并提出新变体，通过结合它们的优势来改进联邦学习。具体来说，论文展示了 ADMM 中的双变量可以通过 VB 的站点参数和各向同性高斯协方差自然衍生，并从 VB 派生出两种 ADMM 版本：一种使用灵活协方差，另一种采用功能正则化。通过数值实验，验证了这些新变体在性能上的提升。该工作桥接了两个看似不同的领域，为联邦学习提供了更有效的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17325v2",
      "published_date": "2025-01-28 22:37:25 UTC",
      "updated_date": "2025-02-28 17:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:02:34.688539"
    },
    {
      "arxiv_id": "2501.17315v1",
      "title": "A sketch of an AI control safety case",
      "title_zh": "翻译失败",
      "authors": [
        "Tomek Korbak",
        "Joshua Clymer",
        "Benjamin Hilton",
        "Buck Shlegeris",
        "Geoffrey Irving"
      ],
      "abstract": "As LLM agents gain a greater capacity to cause harm, AI developers might\nincreasingly rely on control measures such as monitoring to justify that they\nare safe. We sketch how developers could construct a \"control safety case\",\nwhich is a structured argument that models are incapable of subverting control\nmeasures in order to cause unacceptable outcomes. As a case study, we sketch an\nargument that a hypothetical LLM agent deployed internally at an AI company\nwon't exfiltrate sensitive information. The sketch relies on evidence from a\n\"control evaluation,\"' where a red team deliberately designs models to\nexfiltrate data in a proxy for the deployment environment. The safety case then\nhinges on several claims: (1) the red team adequately elicits model\ncapabilities to exfiltrate data, (2) control measures remain at least as\neffective in deployment, and (3) developers conservatively extrapolate model\nperformance to predict the probability of data exfiltration in deployment. This\nsafety case sketch is a step toward more concrete arguments that can be used to\nshow that a dangerously capable LLM agent is safe to deploy.",
      "tldr_zh": "该论文勾勒了“AI control safety case”的框架，这是一个结构化的论证，用于证明LLM agents无法破坏控制措施（如监控）来造成不可接受的危害。作者以一个假设的LLM代理在AI公司内部部署的案例为例，依赖于“control evaluation”中的红队测试来评估模型泄露数据的潜力。安全案例基于三个关键主张：红队充分激发模型能力、控制措施在部署中至少同样有效，以及开发者保守地外推模型性能以预测风险，从而为安全部署危险的LLM agents提供基础。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17315v1",
      "published_date": "2025-01-28 21:52:15 UTC",
      "updated_date": "2025-01-28 21:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:02:47.798959"
    },
    {
      "arxiv_id": "2501.17310v2",
      "title": "Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Yun-Shiuan Chuang",
        "Nikunj Harlalka",
        "Sameer Narendran",
        "Alexander Cheung",
        "Sizhe Gao",
        "Siddharth Suresh",
        "Junjie Hu",
        "Timothy T. Rogers"
      ],
      "abstract": "Guesstimation, the task of making approximate quantity estimates, is a common\nreal-world challenge. However, it has been largely overlooked in large language\nmodels (LLMs) and vision language models (VLMs) research. We introduce a novel\nguesstimation dataset, MARBLES. This dataset requires one to estimate how many\nitems (e.g., marbles) can fit into containers (e.g., a one-cup measuring cup),\nboth with and without accompanying images. Inspired by the social science\nconcept of the ``Wisdom of Crowds'' (WOC) - taking the median from estimates\nfrom a crowd), which has proven effective in guesstimation, we propose ``WOC\ndecoding'' strategy for LLM guesstimation. We show that LLMs/VLMs perform well\non guesstimation, suggesting that they possess some level of a \"world model\"\nnecessary for guesstimation. Moreover, similar to human performance, the WOC\ndecoding method improves LLM/VLM guesstimation accuracy. Furthermore, the\ninclusion of images in the multimodal condition enhances model performance.\nThese results highlight the value of WOC decoding strategy for LLMs/VLMs and\nposition guesstimation as a probe for evaluating LLMs/VLMs' world model. As\nLLMs' world model is a fundamental prerequisite for many real-world tasks,\ne.g., human-AI teaming, our findings have broad implications for the AI\ncommunity.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)和视觉语言模型(VLMs)在guesstimation任务（估算数量，如物品能放入容器中的数量）上的性能，引入了新数据集MARBLES，包括有无图像的场景。研究者提出“Wisdom of Crowds (WOC) decoding”策略，借鉴社会科学概念，通过取多个估算的中位数来提升模型准确性。实验结果显示，LLMs/VLMs表现出色，表明它们具备一定的“world model”能力，而WOC策略进一步改善了性能，尤其在多模态条件下加入图像时。总体而言，这为评估AI模型的真实世界理解提供了有效探针，并对人类-AI团队合作等应用具有广泛启示。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17310v2",
      "published_date": "2025-01-28 21:43:56 UTC",
      "updated_date": "2025-01-30 07:15:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:02:59.799245"
    },
    {
      "arxiv_id": "2501.17296v2",
      "title": "Multi-Physics Simulations via Coupled Fourier Neural Operator",
      "title_zh": "翻译失败",
      "authors": [
        "Shibo Li",
        "Tao Wang",
        "Yifei Sun",
        "Hewei Tang"
      ],
      "abstract": "Physical simulations are essential tools across critical fields such as\nmechanical and aerospace engineering, chemistry, meteorology, etc. While neural\noperators, particularly the Fourier Neural Operator (FNO), have shown promise\nin predicting simulation results with impressive performance and efficiency,\nthey face limitations when handling real-world scenarios involving coupled\nmulti-physics outputs. Current neural operator methods either overlook the\ncorrelations between multiple physical processes or employ simplistic\narchitectures that inadequately capture these relationships. To overcome these\nchallenges, we introduce a novel coupled multi-physics neural operator learning\n(COMPOL) framework that extends the capabilities of Fourier operator layers to\nmodel interactions among multiple physical processes. Our approach implements\nfeature aggregation through recurrent and attention mechanisms, enabling\ncomprehensive modeling of coupled interactions. Our method's core is an\ninnovative system for aggregating latent features from multi-physics processes.\nThese aggregated features serve as enriched information sources for neural\noperator layers, allowing our framework to capture complex physical\nrelationships accurately. We evaluated our coupled multi-physics neural\noperator across diverse physical simulation tasks, including biological\nsystems, fluid mechanics, and multiphase flow in porous media. Our proposed\nmodel demonstrates a two to three-fold improvement in predictive performance\ncompared to existing approaches.",
      "tldr_zh": "本论文提出了一种新的耦合多物理神经运算符学习框架（COMPOL），旨在解决Fourier Neural Operator (FNO)在处理真实耦合多物理输出时的局限性，如忽略多物理过程间的相关性。COMPOL通过扩展Fourier运算符层，并采用recurrent和attention机制进行特征聚合，来准确捕捉多个物理过程的交互关系。实验结果显示，该框架在生物系统、流体力学和多相流等任务上，比现有方法提高了2-3倍的预测性能，为复杂物理模拟提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17296v2",
      "published_date": "2025-01-28 20:58:55 UTC",
      "updated_date": "2025-01-30 03:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:03:10.784773"
    },
    {
      "arxiv_id": "2501.17295v1",
      "title": "Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zilu Tang",
        "Rajen Chatterjee",
        "Sarthak Garg"
      ],
      "abstract": "Machine Translation (MT) is undergoing a paradigm shift, with systems based\non fine-tuned large language models (LLM) becoming increasingly competitive\nwith traditional encoder-decoder models trained specifically for translation\ntasks. However, LLM-based systems are at a higher risk of generating\nhallucinations, which can severely undermine user's trust and safety. Most\nprior research on hallucination mitigation focuses on traditional MT models,\nwith solutions that involve post-hoc mitigation - detecting hallucinated\ntranslations and re-translating them. While effective, this approach introduces\nadditional complexity in deploying extra tools in production and also increases\nlatency. To address these limitations, we propose a method that intrinsically\nlearns to mitigate hallucinations during the model training phase.\nSpecifically, we introduce a data creation framework to generate hallucination\nfocused preference datasets. Fine-tuning LLMs on these preference datasets\nreduces the hallucination rate by an average of 96% across five language pairs,\nwhile preserving overall translation quality. In a zero-shot setting our\napproach reduces hallucinations by 89% on an average across three unseen target\nlanguages.",
      "tldr_zh": "本文提出一种针对大语言模型 (LLM) 的方法，用于缓解机器翻译中的幻觉 (hallucinations)，通过在训练阶段内在地优化模型，而不是依赖事后检测。研究引入了一个数据创建框架来生成专注于幻觉的偏好数据集，并在这些数据集上微调 LLM，从而平均将幻觉率降低 96% 于五个语言对，同时保持整体翻译质量。在零样本设置下，该方法在三个未见的目标语言上平均减少 89% 的幻觉，提供了一个更高效且低延迟的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Main Conference Long paper (9 pages)",
      "pdf_url": "http://arxiv.org/pdf/2501.17295v1",
      "published_date": "2025-01-28 20:58:43 UTC",
      "updated_date": "2025-01-28 20:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:03:22.605924"
    },
    {
      "arxiv_id": "2501.17286v1",
      "title": "Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology",
      "title_zh": "翻译失败",
      "authors": [
        "Peilong Wang",
        "Zhengliang Liu",
        "Yiwei Li",
        "Jason Holmes",
        "Peng Shu",
        "Lian Zhang",
        "Xiang Li",
        "Quanzheng Li",
        "Brady S. Laughlin",
        "Diego Santos Toesca",
        "Sujay A. Vora",
        "Samir H. Patel",
        "Terence T. Sio",
        "Tianming Liu",
        "Wei Liu"
      ],
      "abstract": "Background: The radiation oncology clinical practice involves many steps\nrelying on the dynamic interplay of abundant text data. Large language models\nhave displayed remarkable capabilities in processing complex text information.\nBut their direct applications in specific fields like radiation oncology remain\nunderexplored.\n  Purpose: This study aims to investigate whether fine-tuning LLMs with domain\nknowledge can improve the performance on Task (1) treatment regimen generation,\nTask (2) treatment modality selection (photon, proton, electron, or\nbrachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.\n  Methods: Data for 15,724 patient cases were extracted. Cases where patients\nhad a single diagnostic record, and a clearly identifiable primary treatment\nplan were selected for preprocessing and manual annotation to have 7,903 cases\nof the patient diagnosis, treatment plan, treatment modality, and ICD-10 code.\nEach case was used to construct a pair consisting of patient diagnostics\ndetails and an answer (treatment regimen, treatment modality, or ICD-10 code\nrespectively) for the supervised fine-tuning of these three tasks. Open source\nLLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the\nLow-Rank Approximations method. Accuracy and ROUGE-1 score were reported for\nthe fine-tuned models and original models. Clinical evaluation was performed on\nTask (1) by radiation oncologists, while precision, recall, and F-1 score were\nevaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used\nto statistically analyze the results.\n  Results: Fine-tuned LLMs outperformed original LLMs across all tasks with\np-value <= 0.001. Clinical evaluation demonstrated that over 60% of the\nfine-tuned LLMs-generated treatment regimens were clinically acceptable.\nPrecision, recall, and F1-score showed improved performance of fine-tuned LLMs.",
      "tldr_zh": "本研究探讨了通过微调开源大型语言模型（LLMs）来提升其在辐射肿瘤学任务中的性能的可行性，针对治疗方案生成、治疗方式选择（photon、proton、electron 或 brachytherapy）和 ICD-10 代码预测三个任务。\n使用 LLaMA2-7B 和 Mistral-7B 模型，采用监督微调和 Low-Rank Approximations 方法，对 7,903 例患者数据进行训练，并通过准确率、ROUGE-1 分数以及临床评估进行评估。\n结果显示，微调后的模型在所有任务上显著优于原模型（p-value ≤ 0.001），临床评估表明超过60%的生成治疗方案被认为是临床可接受的。\n这项工作证明了 LLMs 在辐射肿瘤学领域的潜在临床应用潜力。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17286v1",
      "published_date": "2025-01-28 20:37:32 UTC",
      "updated_date": "2025-01-28 20:37:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:03:37.113845"
    },
    {
      "arxiv_id": "2501.17282v3",
      "title": "From Natural Language to Extensive-Form Game Representations",
      "title_zh": "从自然语言到扩展形式游戏表示",
      "authors": [
        "Shilong Deng",
        "Yongzhao Wang",
        "Rahul Savani"
      ],
      "abstract": "We introduce a framework for translating game descriptions in natural\nlanguage into extensive-form representations in game theory, leveraging Large\nLanguage Models (LLMs) and in-context learning. Given the varying levels of\nstrategic complexity in games, such as perfect versus imperfect information,\ndirectly applying in-context learning would be insufficient. To address this,\nwe introduce a two-stage framework with specialized modules to enhance\nin-context learning, enabling it to divide and conquer the problem effectively.\nIn the first stage, we tackle the challenge of imperfect information by\ndeveloping a module that identifies information sets along and the\ncorresponding partial tree structure. With this information, the second stage\nleverages in-context learning alongside a self-debugging module to produce a\ncomplete extensive-form game tree represented using pygambit, the Python API of\na recognized game-theoretic analysis tool called Gambit. Using this python\nrepresentation enables the automation of tasks such as computing Nash\nequilibria directly from natural language descriptions. We evaluate the\nperformance of the full framework, as well as its individual components, using\nvarious LLMs on games with different levels of strategic complexity. Our\nexperimental results show that the framework significantly outperforms baseline\nmodels in generating accurate extensive-form games, with each module playing a\ncritical role in its success.",
      "tldr_zh": "该研究提出一个框架，使用Large Language Models (LLMs) 和 in-context learning，将自然语言游戏描述转化为博弈论的 extensive-form game 表示，以应对完美信息和不完美信息等战略复杂性。该框架采用两阶段设计：第一阶段开发专用模块识别信息集和部分树结构；第二阶段结合 in-context learning 和自调试模块，生成完整的游戏树表示，使用 pygambit 进行自动化处理。实验结果表明，该框架在不同复杂性游戏上的性能显著优于基线模型，每个模块都发挥关键作用，并支持从自然语言直接计算 Nash Equilibria。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been accepted as a full paper for AAMAS 2025. This is a\n  full version of the AAMAS 2025 proceedings",
      "pdf_url": "http://arxiv.org/pdf/2501.17282v3",
      "published_date": "2025-01-28 20:30:36 UTC",
      "updated_date": "2025-01-31 17:26:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:03:47.362552"
    },
    {
      "arxiv_id": "2501.17260v1",
      "title": "ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadreza Saraei",
        "Igor Kozak",
        "Eung-Joo Lee"
      ],
      "abstract": "Optical Coherence Tomography (OCT) is a non-invasive imaging modality\nessential for diagnosing various eye diseases. Despite its clinical\nsignificance, developing OCT-based diagnostic tools faces challenges, such as\nlimited public datasets, sparse annotations, and privacy concerns. Although\ndeep learning has made progress in automating OCT analysis, these challenges\nremain unresolved. To address these limitations, we introduce the Vision\nTransformer-based Dual-Stream Self-Supervised Pretraining Network (ViT-2SPN), a\nnovel framework designed to enhance feature extraction and improve diagnostic\naccuracy. ViT-2SPN employs a three-stage workflow: Supervised Pretraining,\nSelf-Supervised Pretraining (SSP), and Supervised Fine-Tuning. The pretraining\nphase leverages the OCTMNIST dataset (97,477 unlabeled images across four\ndisease classes) with data augmentation to create dual-augmented views. A\nVision Transformer (ViT-Base) backbone extracts features, while a negative\ncosine similarity loss aligns feature representations. Pretraining is conducted\nover 50 epochs with a learning rate of 0.0001 and momentum of 0.999.\nFine-tuning is performed on a stratified 5.129% subset of OCTMNIST using\n10-fold cross-validation. ViT-2SPN achieves a mean AUC of 0.93, accuracy of\n0.77, precision of 0.81, recall of 0.75, and an F1 score of 0.76, outperforming\nexisting SSP-based methods.",
      "tldr_zh": "该研究提出ViT-2SPN，一种基于Vision Transformer的双流自监督预训练网络，用于改善视网膜OCT（Optical Coherence Tomography）图像的分类诊断，以应对数据集有限、标注稀疏和隐私问题等挑战。框架采用三阶段工作流程，包括监督预训练、自监督预训练（SSP）使用OCTMNIST数据集进行数据增强和特征对齐，以及后续监督微调。实验结果显示，ViT-2SPN在OCTMNIST子集上实现平均AUC 0.93、准确率0.77等指标，优于现有SSP方法，显著提升了诊断性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17260v1",
      "published_date": "2025-01-28 19:41:38 UTC",
      "updated_date": "2025-01-28 19:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:04:11.715282"
    },
    {
      "arxiv_id": "2501.17161v1",
      "title": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training",
      "title_zh": "SFT 记忆化，RL 泛化：基础模型后训练的比较",
      "authors": [
        "Tianzhe Chu",
        "Yuexiang Zhai",
        "Jihan Yang",
        "Shengbang Tong",
        "Saining Xie",
        "Dale Schuurmans",
        "Quoc V. Le",
        "Sergey Levine",
        "Yi Ma"
      ],
      "abstract": "Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used\npost-training techniques for foundation models. However, their roles in\nenhancing model generalization capabilities remain unclear. This paper studies\nthe difference between SFT and RL on generalization and memorization, focusing\non text-based rule variants and visual variants. We introduce GeneralPoints, an\narithmetic reasoning card game, and adopt V-IRL, a real-world navigation\nenvironment, to assess how models trained with SFT and RL generalize to unseen\nvariants in both textual and visual domains. We show that RL, especially when\ntrained with an outcome-based reward, generalizes across both rule-based\ntextual and visual variants. SFT, in contrast, tends to memorize training data\nand struggles to generalize out-of-distribution scenarios. Further analysis\nreveals that RL improves the model's underlying visual recognition\ncapabilities, contributing to its enhanced generalization in the visual domain.\nDespite RL's superior generalization, we show that SFT remains essential for\neffective RL training; SFT stabilizes the model's output format, enabling\nsubsequent RL to achieve its performance gains. These findings demonstrates the\ncapability of RL for acquiring generalizable knowledge in complex, multi-modal\ntasks.",
      "tldr_zh": "本文比较了 Supervised Fine-Tuning (SFT) 和 Reinforcement Learning (RL) 在基础模型后训练中的泛化和记忆化差异，焦点在于文本和视觉变体。研究引入了 GeneralPoints（一个算术推理卡片游戏）和 V-IRL（一个真实世界导航环境），用于评估模型在未见变体上的表现。结果显示，RL 尤其在基于结果的奖励训练下，能更好地泛化到规则-based 文本和视觉场景，而 SFT 则倾向于记忆训练数据，导致在分布外任务中表现较差。进一步分析表明，RL 提升了模型的底层视觉识别能力，从而增强视觉域泛化；尽管如此，SFT 仍是 RL 训练的关键，因为它稳定了模型输出格式，支持 RL 实现性能提升。这些发现突显了 RL 在复杂多模态任务中获取可泛化知识的潜力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Website at https://tianzhechu.com/SFTvsRL",
      "pdf_url": "http://arxiv.org/pdf/2501.17161v1",
      "published_date": "2025-01-28 18:59:44 UTC",
      "updated_date": "2025-01-28 18:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:04:12.621236"
    },
    {
      "arxiv_id": "2501.17160v1",
      "title": "A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images",
      "title_zh": "翻译失败",
      "authors": [
        "Suresh Babu Nettur",
        "Shanthi Karpurapu",
        "Unnati Nettur",
        "Likhit Sagar Gajja",
        "Sravanthy Myneni",
        "Akhil Dusi",
        "Lalithya Posham"
      ],
      "abstract": "Early detection of COVID-19 is crucial for effective treatment and\ncontrolling its spread. This study proposes a novel hybrid deep learning model\nfor detecting COVID-19 from CT scan images, designed to assist overburdened\nmedical professionals. Our proposed model leverages the strengths of VGG16,\nDenseNet121, and MobileNetV2 to extract features, followed by Principal\nComponent Analysis (PCA) for dimensionality reduction, after which the features\nare stacked and classified using a Support Vector Classifier (SVC). We\nconducted comparative analysis between the proposed hybrid model and individual\npre-trained CNN models, using a dataset of 2,108 training images and 373 test\nimages comprising both COVID-positive and non-COVID images. Our proposed hybrid\nmodel achieved an accuracy of 98.93%, outperforming the individual models in\nterms of precision, recall, F1 scores, and ROC curve performance.",
      "tldr_zh": "本研究提出了一种混合深度学习 CNN 模型，用于从 CT 扫描图像中增强 COVID-19 检测，以辅助医疗专业人员。该模型结合 VGG16、DenseNet121 和 MobileNetV2 提取特征，随后使用 Principal Component Analysis (PCA) 进行维度减少，并通过 Support Vector Classifier (SVC) 进行分类。在包含 2108 张训练图像和 373 张测试图像的数据集上，该模型实现了 98.93% 的准确率，并在精确度、召回率、F1 分数和 ROC 曲线表现上优于单个预训练 CNN 模型。研究结果表明，这种混合方法显著提升了 COVID-19 的早期检测能力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Corresponding authors: Shanthi Karpurapu\n  (shanthi.karpurapu@gmail.com), Suresh Babu Nettur (nettursuresh@gmail.com)\n  Shanthi Karpurapu and Suresh Babu Nettur are co-first authors",
      "pdf_url": "http://arxiv.org/pdf/2501.17160v1",
      "published_date": "2025-01-28 18:59:21 UTC",
      "updated_date": "2025-01-28 18:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:04:22.672781"
    },
    {
      "arxiv_id": "2501.17152v1",
      "title": "Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model",
      "title_zh": "翻译失败",
      "authors": [
        "Reza Ghorbani",
        "Jyothi Rikhab Chand",
        "Chu-Yu Lee",
        "Mathews Jacob",
        "Merry Mani"
      ],
      "abstract": "Three-dimensional (3D) multi-slab acquisition is a technique frequently\nemployed in high-resolution diffusion-weighted MRI in order to achieve the best\nsignal-to-noise ratio (SNR) efficiency. However, this technique is limited by\nslab boundary artifacts that cause intensity fluctuations and aliasing between\nslabs which reduces the accuracy of anatomical imaging. Addressing this issue\nis crucial for advancing diffusion MRI quality and making high-resolution\nimaging more feasible for clinical and research applications. In this work, we\npropose a regularized slab profile encoding (PEN) method within a Plug-and-Play\nADMM framework, incorporating multi-scale energy (MuSE) regularization to\neffectively improve the slab combined reconstruction. Experimental results\ndemonstrate that the proposed method significantly improves image quality\ncompared to non-regularized and TV-regularized PEN approaches. The regularized\nPEN framework provides a more robust and efficient solution for high-resolution\n3D diffusion MRI, potentially enabling clearer, more reliable anatomical\nimaging across various applications.",
      "tldr_zh": "本文提出了一种正则化的层板轮廓编码(PEN)方法，用于解决三维(3D)多层板扩散加权MRI中存在的层板边界伪影问题，这些伪影会导致强度波动和混叠，影响解剖成像的准确性。该方法整合Plug-and-Play ADMM框架和多尺度能量(MuSE)正则化，以有效改善层板结合重建的图像质量。实验结果表明，与非正则化和TV正则化方法相比，该框架显著提升了图像质量，为高分辨率3D扩散MRI在临床和研究应用中提供更稳健高效的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "4 pages, 4 figures, ISBI2025 Conference paper",
      "pdf_url": "http://arxiv.org/pdf/2501.17152v1",
      "published_date": "2025-01-28 18:53:16 UTC",
      "updated_date": "2025-01-28 18:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:04:35.238595"
    },
    {
      "arxiv_id": "2501.17148v3",
      "title": "AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders",
      "title_zh": "AxBench: 引导 LLMs？ 甚至简单的基准模型优于稀疏自编码器",
      "authors": [
        "Zhengxuan Wu",
        "Aryaman Arora",
        "Atticus Geiger",
        "Zheng Wang",
        "Jing Huang",
        "Dan Jurafsky",
        "Christopher D. Manning",
        "Christopher Potts"
      ],
      "abstract": "Fine-grained steering of language model outputs is essential for safety and\nreliability. Prompting and finetuning are widely used to achieve these goals,\nbut interpretability researchers have proposed a variety of\nrepresentation-based techniques as well, including sparse autoencoders (SAEs),\nlinear artificial tomography, supervised steering vectors, linear probes, and\nrepresentation finetuning. At present, there is no benchmark for making direct\ncomparisons between these proposals. Therefore, we introduce AxBench, a\nlarge-scale benchmark for steering and concept detection, and report\nexperiments on Gemma-2-2B and 9B. For steering, we find that prompting\noutperforms all existing methods, followed by finetuning. For concept\ndetection, representation-based methods such as difference-in-means, perform\nthe best. On both evaluations, SAEs are not competitive. We introduce a novel\nweakly-supervised representational method (Rank-1 Representation Finetuning;\nReFT-r1), which is competitive on both tasks while providing the\ninterpretability advantages that prompting lacks. Along with AxBench, we train\nand publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.",
      "tldr_zh": "该研究引入了AxBench，这是一个大规模基准，用于评估语言模型(LLMs)的转向和概念检测性能，并在Gemma-2-2B和9B模型上进行实验。结果显示，在转向任务中，简单基线如prompting优于所有方法，其次是finetuning，而Sparse Autoencoders (SAEs)表现不具竞争力；在概念检测任务中，表示-based方法如difference-in-means表现最佳。论文提出了一种新方法Rank-1 Representation Finetuning (ReFT-r1)，它在两个任务上均具竞争力，同时提供可解释性优势，并公开了SAE-scale特征字典以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17148v3",
      "published_date": "2025-01-28 18:51:24 UTC",
      "updated_date": "2025-03-03 21:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:04:47.347739"
    },
    {
      "arxiv_id": "2501.17144v1",
      "title": "FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data",
      "title_zh": "翻译失败",
      "authors": [
        "Deren Lei",
        "Yaxi Li",
        "Siyao Li",
        "Mengya Hu",
        "Rui Xu",
        "Ken Archer",
        "Mingyu Wang",
        "Emily Ching",
        "Alex Deng"
      ],
      "abstract": "Prior research on training grounded factuality classification models to\ndetect hallucinations in large language models (LLMs) has relied on public\nnatural language inference (NLI) data and synthetic data. However, conventional\nNLI datasets are not well-suited for document-level reasoning, which is\ncritical for detecting LLM hallucinations. Recent approaches to document-level\nsynthetic data generation involve iteratively removing sentences from documents\nand annotating factuality using LLM-based prompts. While effective, this method\nis computationally expensive for long documents and limited by the LLM's\ncapabilities. In this work, we analyze the differences between existing\nsynthetic training data used in state-of-the-art models and real LLM output\nclaims. Based on our findings, we propose a novel approach for synthetic data\ngeneration, CG2C, that leverages multi-hop reasoning on context graphs\nextracted from documents. Our fact checker model, FactCG, demonstrates improved\nperformance with more connected reasoning, using the same backbone models.\nExperiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark\nwith much smaller model size.",
      "tldr_zh": "本研究发现，现有的自然语言推理(NLI)数据和合成数据在训练事实性分类模型时，不适合文档级推理，且生成方法计算密集。本文提出一种新颖的合成数据生成方法CG2C，通过从文档中提取上下文图进行多跳推理(multi-hop reasoning)，从而增强事实检查器的性能。FactCG模型基于此方法，使用相同的骨干模型实现了更连接的推理，并在LLM-Aggrefact基准上超过了GPT-4-o，尽管模型尺寸更小。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.17144v1",
      "published_date": "2025-01-28 18:45:07 UTC",
      "updated_date": "2025-01-28 18:45:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:04:58.798123"
    },
    {
      "arxiv_id": "2502.19422v2",
      "title": "Implementation of a Generative AI Assistant in K-12 Education: The CyberScholar Initiative",
      "title_zh": "在 K-12 教育中实施生成式 AI 助手：CyberScholar 倡议",
      "authors": [
        "Vania Castro",
        "Ana Karina de Oliveira Nascimento",
        "Raigul Zheldibayeva",
        "Duane Searsmith",
        "Akash Saini",
        "Bill Cope",
        "Mary Kalantzis"
      ],
      "abstract": "This paper focuses on the piloting of CyberScholar, a Generative AI (GenAI)\nassistant tool that aims to provide feedback on writing K-12 contexts. The aim\nwas to use GenAI to provide formative and summative feedback on students' texts\nin English Language Arts (ELA), Social Studies, and Modern World History. The\ntrials discussed in this paper involved Grades 7, 8, 10, and 11 and were\nconducted in three schools in the Midwest and one in the Northwest of the\nUnited States. The tool used two main mechanisms: \"prompt engineering\" based on\nparticipant teachers' assessment rubric and \"fine-tuning\" a Large Language\nModel (LLM) from a customized corpus of teaching materials using Retrieval\nAugmented Generation. This paper focuses on CyberScholar's potential to enhance\nstudents' writing abilities and support teachers in diverse subject areas\nrequiring written assignments.",
      "tldr_zh": "本研究介绍了 CyberScholar 项目，这是一个 Generative AI (GenAI) 助手工具，用于在 K-12 教育环境中提供写作反馈，针对英语语言艺术 (ELA)、社会研究和现代世界历史等科目。研究采用 \"prompt engineering\"（基于教师评估标准）和 \"fine-tuning\" 一个 Large Language Model (LLM) 结合 Retrieval Augmented Generation (RAG) 的机制，针对 7、8、10 和 11 年级学生在四所美国学校的试验进行。结果显示，CyberScholar 有潜力提升学生的写作能力，并为教师在多样写作作业科目中提供支持。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19422v2",
      "published_date": "2025-01-28 18:23:03 UTC",
      "updated_date": "2025-03-25 18:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:05:12.003076"
    },
    {
      "arxiv_id": "2501.17117v1",
      "title": "Histoires Morales: A French Dataset for Assessing Moral Alignment",
      "title_zh": "Histoires Morales：一个用于评估道德对齐的法语数据集",
      "authors": [
        "Thibaud Leteno",
        "Irina Proskurina",
        "Antoine Gourru",
        "Julien Velcin",
        "Charlotte Laclau",
        "Guillaume Metzler",
        "Christophe Gravier"
      ],
      "abstract": "Aligning language models with human values is crucial, especially as they\nbecome more integrated into everyday life. While models are often adapted to\nuser preferences, it is equally important to ensure they align with moral norms\nand behaviours in real-world social situations. Despite significant progress in\nlanguages like English and Chinese, French has seen little attention in this\narea, leaving a gap in understanding how LLMs handle moral reasoning in this\nlanguage. To address this gap, we introduce Histoires Morales, a French dataset\nderived from Moral Stories, created through translation and subsequently\nrefined with the assistance of native speakers to guarantee grammatical\naccuracy and adaptation to the French cultural context. We also rely on\nannotations of the moral values within the dataset to ensure their alignment\nwith French norms. Histoires Morales covers a wide range of social situations,\nincluding differences in tipping practices, expressions of honesty in\nrelationships, and responsibilities toward animals. To foster future research,\nwe also conduct preliminary experiments on the alignment of multilingual models\non French and English data and the robustness of the alignment. We find that\nwhile LLMs are generally aligned with human moral norms by default, they can be\neasily influenced with user-preference optimization for both moral and immoral\ndata.",
      "tldr_zh": "本研究强调了语言模型（LLMs）与人类道德规范对齐的重要性，并针对法语领域的研究空白，引入了Histoires Morales数据集。该数据集基于Moral Stories，通过翻译并由母语者精炼，以确保语法准确性和适应法语文化背景，涵盖各种社会情境如小费习惯、关系中的诚实和动物责任。研究通过初步实验评估多语言模型在法语和英语上的道德对齐和鲁棒性，发现LLMs默认与人类道德规范一致，但容易受用户偏好优化影响而偏向道德或不道德行为。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.17117v1",
      "published_date": "2025-01-28 18:07:30 UTC",
      "updated_date": "2025-01-28 18:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:05:22.302097"
    },
    {
      "arxiv_id": "2501.17104v1",
      "title": "COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Materzok"
      ],
      "abstract": "We present COS(M+O)S, a System 2-inspired framework for open-ended plot\ndevelopment that systematically explores the vast space of possible story\nexpansions, enabling a 3B-parameter language model to approach the plot quality\nof a 70B model on select short-story tasks. The method accomplishes this by\ncombining Monte Carlo Tree Search (MCTS), guided by a step-level value model\nthat rewards moderate surprisal (curiosity) while penalizing incoherence, and\nOdds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value\nplot expansions. This iterative reinforcement learning loop systematically\nexplores multiple candidate plot branches, backpropagates quality signals, and\nadapts the policy for faster convergence, notably shifting the policy from\npuzzle-based Chain-of-Thought to more character-driven storytelling. In\nsmall-scale tests with short-story prompts, 67%-77% of participants favored\nCOS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our\nlearned value function aligns. GPT-4o ratings further show that COS(M+O)S\nsurpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming\nwithin 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise\ncomparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no\nstatistically significant gap from 70B. Nevertheless, absolute story quality\nremains modest, constrained by the small model's capacity and limited training\ndata.",
      "tldr_zh": "该论文提出了 COS(M+O)S 框架，这是一种受 System 2 启发的系统，用于系统探索故事扩展空间，通过 Monte Carlo Tree Search (MCTS) 和强化学习相结合，让 3B 参数语言模型在短故事任务上接近 70B 模型的表现。框架通过一个步级价值模型奖励适度 surprisal (好奇心) 并惩罚 incoherence (不连贯性)，并利用 Odds Ratio Preference Optimization (ORPO) 微调策略，实现从 Chain-of-Thought 导向的谜题式叙事向更多人物驱动的故事转变。实验显示，67%-77% 的参与者更喜欢 COS(M+O)S 生成的高价值情节扩展，且其表现比 Llama 3.2 3B 基线高出 0.59 SD，几乎与 Llama 3.1 70B 无显著差异，但整体故事质量仍受限于小模型容量和训练数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17104v1",
      "published_date": "2025-01-28 17:44:04 UTC",
      "updated_date": "2025-01-28 17:44:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:05:36.882888"
    },
    {
      "arxiv_id": "2501.17096v1",
      "title": "Why is the estimation of metaorder impact with public market data so challenging?",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Naviglio",
        "Giacomo Bormetti",
        "Francesco Campigli",
        "German Rodikov",
        "Fabrizio Lillo"
      ],
      "abstract": "Estimating market impact and transaction costs of large trades (metaorders)\nis a very important topic in finance. However, using models of price and trade\nbased on public market data provide average price trajectories which are\nqualitatively different from what is observed during real metaorder executions:\nthe price increases linearly, rather than in a concave way, during the\nexecution and the amount of reversion after its end is very limited. We claim\nthat this is a generic phenomenon due to the fact that even sophisticated\nstatistical models are unable to correctly describe the origin of the\nautocorrelation of the order flow. We propose a modified Transient Impact Model\nwhich provides more realistic trajectories by assuming that only a fraction of\nthe metaorder trading triggers market order flow. Interestingly, in our model\nthere is a critical condition on the kernels of the price and order flow\nequations in which market impact becomes permanent.",
      "tldr_zh": "这篇论文探讨了使用公共市场数据估算大宗交易（metaorder）市场影响和交易成本的挑战，因为现有模型基于平均价格轨迹显示线性增加和有限回撤，与实际执行中的凹形轨迹不符。原因在于统计模型无法正确描述订单流的自相关性。作者提出一个修改后的Transient Impact Model，通过假设只有部分metaorder交易触发市场订单流，生成更真实的轨迹，并在特定内核临界条件下使市场影响变得永久。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "econ.EM",
        "physics.soc-ph"
      ],
      "primary_category": "q-fin.TR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17096v1",
      "published_date": "2025-01-28 17:29:08 UTC",
      "updated_date": "2025-01-28 17:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:05:46.463560"
    },
    {
      "arxiv_id": "2501.17088v1",
      "title": "Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models",
      "title_zh": "翻译失败",
      "authors": [
        "J. Pablo Muñoz",
        "Jinjie Yuan",
        "Nilesh Jain"
      ],
      "abstract": "Large pre-trained models have achieved outstanding results in sequence\nmodeling. The Transformer block and its attention mechanism have been the main\ndrivers of the success of these models. Recently, alternative architectures,\nsuch as Selective Structured State Space Models (SSMs), have been proposed to\naddress the inefficiencies of Transformers. This paper explores the compression\nof SSM-based models, particularly Mamba and its hybrids. We study the\nsensitivity of these models to the removal of selected components at different\ngranularities to reduce the model size and computational overhead, thus\nimproving their efficiency while maintaining accuracy. The proposed solutions,\ncollectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4x\nduring inference, demonstrating that model efficiency can be improved by\neliminating several redundancies with minimal impact on the overall model\nperformance. The code is available at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
      "tldr_zh": "这篇论文探讨了Selective Structured State Space Models (SSMs)模型，如Mamba及其混合版本的压缩技术，以解决Transformer架构在序列建模中的低效问题。研究者通过分析模型对不同粒度组件移除的敏感性，开发了Mamba-Shedder方法，该方法通过消除冗余部分来减少模型大小和计算开销，同时保持准确性。实验结果显示，Mamba-Shedder在推理过程中实现了高达1.4x的加速，证明了这种后Transformer压缩策略能有效提升模型效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "NAACL-25 - Main track",
      "pdf_url": "http://arxiv.org/pdf/2501.17088v1",
      "published_date": "2025-01-28 17:22:01 UTC",
      "updated_date": "2025-01-28 17:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:05:58.871047"
    },
    {
      "arxiv_id": "2501.18638v1",
      "title": "Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation",
      "title_zh": "带修剪的攻击图谱：优化隐秘越狱提示",
      "authors": [
        "Daniel Schwartz",
        "Dmitriy Bespalov",
        "Zhe Wang",
        "Ninad Kulkarni",
        "Yanjun Qi"
      ],
      "abstract": "We present a modular pipeline that automates the generation of stealthy\njailbreak prompts derived from high-level content policies, enhancing LLM\ncontent moderation. First, we address query inefficiency and jailbreak strength\nby developing Graph of Attacks with Pruning (GAP), a method that utilizes\nstrategies from prior jailbreaks, resulting in 92% attack success rate on\nGPT-3.5 using only 54% of the queries of the prior algorithm. Second, we\naddress the cold-start issue by automatically generating seed prompts from the\nhigh-level policy using LLMs. Finally, we demonstrate the utility of these\ngenerated jailbreak prompts of improving content moderation by fine-tuning\nPromptGuard, a model trained to detect jailbreaks, increasing its accuracy on\nthe Toxic-Chat dataset from 5.1% to 93.89%.",
      "tldr_zh": "本文提出一个模块化管道，利用 Graph of Attacks with Pruning (GAP) 方法优化隐秘越狱提示的生成，以提升 LLM 内容审核效果。GAP 通过整合先前越狱策略，仅使用 54% 的查询就实现了 GPT-3.5 上的 92% 攻击成功率，同时提高了查询效率。论文还解决了冷启动问题，通过 LLM 自动生成基于高水平内容策略的种子提示。最后，通过微调 PromptGuard 模型，这些提示将 Toxic-Chat 数据集上的准确率从 5.1% 提升至 93.89%，为增强内容审核提供了实用工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18638v1",
      "published_date": "2025-01-28 17:10:20 UTC",
      "updated_date": "2025-01-28 17:10:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:06:11.942882"
    },
    {
      "arxiv_id": "2501.17081v1",
      "title": "Graph Transformers for inverse physics: reconstructing flows around arbitrary 2D airfoils",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Duthé",
        "Imad Abdallah",
        "Eleni Chatzi"
      ],
      "abstract": "We introduce a Graph Transformer framework that serves as a general inverse\nphysics engine on meshes, demonstrated through the challenging task of\nreconstructing aerodynamic flow fields from sparse surface measurements. While\ndeep learning has shown promising results in forward physics simulation,\ninverse problems remain particularly challenging due to their ill-posed nature\nand the difficulty of propagating information from limited boundary\nobservations. Our approach addresses these challenges by combining the\ngeometric expressiveness of message-passing neural networks with the global\nreasoning of Transformers, enabling efficient learning of inverse mappings from\nboundary conditions to complete states. We evaluate this framework on a\ncomprehensive dataset of steady-state RANS simulations around diverse airfoil\ngeometries, where the task is to reconstruct full pressure and velocity fields\nfrom surface pressure measurements alone. The architecture achieves high\nreconstruction accuracy while maintaining fast inference times. We conduct\nexperiments and provide insights into the relative importance of local\ngeometric processing and global attention mechanisms in mesh-based inverse\nproblems. We also find that the framework is robust to reduced sensor coverage.\nThese results suggest that Graph Transformers can serve as effective inverse\nphysics engines across a broader range of applications where complete system\nstates must be reconstructed from limited boundary observations.",
      "tldr_zh": "本研究提出了一种Graph Transformer框架，作为通用逆物理引擎，用于在网格上重建任意2D翼型周围的气动力学流场。该框架结合消息-passing neural networks的几何表达能力和Transformers的全局推理能力，从稀疏表面测量高效学习逆映射，从而解决逆问题中信息传播的挑战。在稳态RANS simulations数据集上，该架构从表面压力测量中准确重建完整的压力和速度场，实现了高重建准确率和快速推理时间。实验结果突显了局部几何处理与全局注意力机制的重要性，并证明框架对减少的传感器覆盖具有鲁棒性，表明其可扩展到更广泛的逆物理应用中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17081v1",
      "published_date": "2025-01-28 17:06:09 UTC",
      "updated_date": "2025-01-28 17:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:08:16.553131"
    },
    {
      "arxiv_id": "2501.17079v1",
      "title": "Learning Mean Field Control on Sparse Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Fabian",
        "Kai Cui",
        "Heinz Koeppl"
      ],
      "abstract": "Large agent networks are abundant in applications and nature and pose\ndifficult challenges in the field of multi-agent reinforcement learning (MARL)\ndue to their computational and theoretical complexity. While graphon mean field\ngames and their extensions provide efficient learning algorithms for dense and\nmoderately sparse agent networks, the case of realistic sparser graphs remains\nlargely unsolved. Thus, we propose a novel mean field control model inspired by\nlocal weak convergence to include sparse graphs such as power law networks with\ncoefficients above two. Besides a theoretical analysis, we design scalable\nlearning algorithms which apply to the challenging class of graph sequences\nwith finite first moment. We compare our model and algorithms for various\nexamples on synthetic and real world networks with mean field algorithms based\non Lp graphons and graphexes. As it turns out, our approach outperforms\nexisting methods in many examples and on various networks due to the special\ndesign aiming at an important, but so far hard to solve class of MARL problems.",
      "tldr_zh": "本文提出了一种针对稀疏图的 Mean Field Control 模型，旨在解决多代理强化学习(MARL)中大规模代理网络的计算和理论挑战，特别是适用于幂律网络等现实稀疏图序列。模型基于局部弱收敛(local weak convergence)理论，结合可扩展的学习算法，并提供了理论分析以支持一阶矩有限的图序列。该方法在合成和真实网络上的实验中，优于基于 Lp graphons 和 graphexes 的现有算法，在多个示例中表现出显著性能提升。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17079v1",
      "published_date": "2025-01-28 17:03:30 UTC",
      "updated_date": "2025-01-28 17:03:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:06:34.843622"
    },
    {
      "arxiv_id": "2501.17077v1",
      "title": "Induced Modularity and Community Detection for Functionally Interpretable Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Soligo",
        "Pietro Ferraro",
        "David Boyle"
      ],
      "abstract": "Interpretability in reinforcement learning is crucial for ensuring AI systems\nalign with human values and fulfill the diverse related requirements including\nsafety, robustness and fairness. Building on recent approaches to encouraging\nsparsity and locality in neural networks, we demonstrate how the penalisation\nof non-local weights leads to the emergence of functionally independent modules\nin the policy network of a reinforcement learning agent. To illustrate this, we\ndemonstrate the emergence of two parallel modules for assessment of movement\nalong the X and Y axes in a stochastic Minigrid environment. Through the novel\napplication of community detection algorithms, we show how these modules can be\nautomatically identified and their functional roles verified through direct\nintervention on the network weights prior to inference. This establishes a\nscalable framework for reinforcement learning interpretability through\nfunctional modularity, addressing challenges regarding the trade-off between\ncompleteness and cognitive tractability of reinforcement learning explanations.",
      "tldr_zh": "该研究探讨了强化学习(Reinforcement Learning)中的可解释性，以确保AI系统符合人类价值观并满足安全、鲁棒性和公平性要求。通过惩罚非局部权重，作者诱导策略网络中出现功能独立的模块，例如在随机Minigrid环境中形成评估X和Y轴运动的并行模块。利用社区检测(Community Detection)算法，研究自动识别这些模块，并通过直接干预网络权重验证其功能角色，从而建立一个可扩展的框架，平衡强化学习解释的完整性和认知可处理性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17077v1",
      "published_date": "2025-01-28 17:02:16 UTC",
      "updated_date": "2025-01-28 17:02:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:06:46.721869"
    },
    {
      "arxiv_id": "2501.18636v2",
      "title": "SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xun Liang",
        "Simin Niu",
        "Zhiyu Li",
        "Sensen Zhang",
        "Hanyu Wang",
        "Feiyu Xiong",
        "Jason Zhaoxin Fan",
        "Bo Tang",
        "Shichao Song",
        "Mengwei Wang",
        "Jiawei Yang"
      ],
      "abstract": "The indexing-retrieval-generation paradigm of retrieval-augmented generation\n(RAG) has been highly successful in solving knowledge-intensive tasks by\nintegrating external knowledge into large language models (LLMs). However, the\nincorporation of external and unverified knowledge increases the vulnerability\nof LLMs because attackers can perform attack tasks by manipulating knowledge.\nIn this paper, we introduce a benchmark named SafeRAG designed to evaluate the\nRAG security. First, we classify attack tasks into silver noise, inter-context\nconflict, soft ad, and white Denial-of-Service. Next, we construct RAG security\nevaluation dataset (i.e., SafeRAG dataset) primarily manually for each task. We\nthen utilize the SafeRAG dataset to simulate various attack scenarios that RAG\nmay encounter. Experiments conducted on 14 representative RAG components\ndemonstrate that RAG exhibits significant vulnerability to all attack tasks and\neven the most apparent attack task can easily bypass existing retrievers,\nfilters, or advanced LLMs, resulting in the degradation of RAG service quality.\nCode is available at: https://github.com/IAAR-Shanghai/SafeRAG.",
      "tldr_zh": "该论文引入了 SafeRAG 基准，用于评估检索增强生成 (RAG) 在大语言模型 (LLMs) 中的安全漏洞，因为外部知识的整合使系统更容易受到攻击。研究者将攻击任务分类为 silver noise、inter-context conflict、soft ad 和 white Denial-of-Service，并手动构建了 SafeRAG 数据集来模拟各种攻击场景。实验在 14 个代表性 RAG 组件上进行，结果显示 RAG 对所有攻击任务高度脆弱，即使是明显的攻击也能绕过现有检索器、过滤器或高级 LLMs，导致服务质量下降。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18636v2",
      "published_date": "2025-01-28 17:01:31 UTC",
      "updated_date": "2025-02-23 10:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:08:27.104876"
    },
    {
      "arxiv_id": "2501.17062v1",
      "title": "EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection",
      "title_zh": "翻译失败",
      "authors": [
        "Kanishk Chaturvedi",
        "Johannes Gasthuber",
        "Mohamed Abdelaal"
      ],
      "abstract": "This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT and\nthin-edge.io for deploying and managing machine learning models on\nresource-constrained edge devices. We address the challenges of model\noptimization, deployment, and lifecycle management in edge environments. The\nframework's efficacy is demonstrated through a visual quality inspection (VQI)\nuse case where images of assets are processed on edge devices, enabling\nreal-time condition updates within an asset management system. Furthermore, we\nevaluate the performance benefits of different quantization methods,\nspecifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstrating\nsignificant inference time reductions compared to FP32 precision. Our results\nhighlight the potential of EdgeMLOps to enable efficient and scalable AI\ndeployments at the edge for industrial applications.",
      "tldr_zh": "本论文介绍了EdgeMLOps框架，该框架利用Cumulocity IoT和thin-edge.io在资源受限的边缘设备上部署和管理机器学习模型，解决了模型优化、部署和生命周期管理等挑战。框架通过一个视觉质量检查(VQI)用例演示其有效性，在边缘设备上处理资产图像，实现实时条件更新。实验结果显示，使用static和dynamic signed-int8量化方法在Raspberry Pi 4上显著减少推理时间，与FP32精度相比，性能提升明显，从而为工业应用的边缘AI部署提供高效、可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17062v1",
      "published_date": "2025-01-28 16:40:40 UTC",
      "updated_date": "2025-01-28 16:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:08:39.735907"
    },
    {
      "arxiv_id": "2501.17044v2",
      "title": "Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Dax",
        "Jordi Berbel",
        "Jan Stria",
        "Leonidas Guibas",
        "Urs Bergmann"
      ],
      "abstract": "We generate abstractions of buildings, reflecting the essential aspects of\ntheir geometry and structure, by learning to invert procedural models. We first\nbuild a dataset of abstract procedural building models paired with simulated\npoint clouds and then learn the inverse mapping through a transformer. Given a\npoint cloud, the trained transformer then infers the corresponding abstracted\nbuilding in terms of a programmatic language description. This approach\nleverages expressive procedural models developed for gaming and animation, and\nthereby retains desirable properties such as efficient rendering of the\ninferred abstractions and strong priors for regularity and symmetry. Our\napproach achieves good reconstruction accuracy in terms of geometry and\nstructure, as well as structurally consistent inpainting.",
      "tldr_zh": "本文提出一种通过 Transformer 反转程序化模型的方法，来合成 3D 建筑的抽象表示，聚焦于几何和结构本质。研究者首先构建了一个数据集，包括抽象程序化建筑模型和模拟 point clouds，并训练 Transformer 学习从 point cloud 到程序化语言描述的反向映射。该方法利用程序化模型的优点，如高效渲染和强规则性先验，实现良好的几何和结构重建准确性，以及结构一致的 inpainting。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.17044v2",
      "published_date": "2025-01-28 16:09:34 UTC",
      "updated_date": "2025-01-29 11:06:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:08:50.920873"
    },
    {
      "arxiv_id": "2501.17041v1",
      "title": "Benchmarking Quantum Convolutional Neural Networks for Signal Classification in Simulated Gamma-Ray Burst Detection",
      "title_zh": "基准测试量子卷积神经网络在模拟伽",
      "authors": [
        "Farida Farsian",
        "Nicolò Parmiggiani",
        "Alessandro Rizzo",
        "Gabriele Panebianco",
        "Andrea Bulgarelli",
        "Francesco Schillirò",
        "Carlo Burigana",
        "Vincenzo Cardone",
        "Luca Cappelli",
        "Massimo Meneghetti",
        "Giuseppe Murante",
        "Giuseppe Sarracino",
        "Roberto Scaramella",
        "Vincenzo Testa",
        "Tiziana Trombetti"
      ],
      "abstract": "This study evaluates the use of Quantum Convolutional Neural Networks (QCNNs)\nfor identifying signals resembling Gamma-Ray Bursts (GRBs) within simulated\nastrophysical datasets in the form of light curves. The task addressed here\nfocuses on distinguishing GRB-like signals from background noise in simulated\nCherenkov Telescope Array Observatory (CTAO) data, the next-generation\nastrophysical observatory for very high-energy gamma-ray science. QCNNs, a\nquantum counterpart of classical Convolutional Neural Networks (CNNs), leverage\nquantum principles to process and analyze high-dimensional data efficiently. We\nimplemented a hybrid quantum-classical machine learning technique using the\nQiskit framework, with the QCNNs trained on a quantum simulator. Several QCNN\narchitectures were tested, employing different encoding methods such as Data\nReuploading and Amplitude encoding. Key findings include that QCNNs achieved\naccuracy comparable to classical CNNs, often surpassing 90\\%, while using fewer\nparameters, potentially leading to more efficient models in terms of\ncomputational resources. A benchmark study further examined how hyperparameters\nlike the number of qubits and encoding methods affected performance, with more\nqubits and advanced encoding methods generally enhancing accuracy but\nincreasing complexity. QCNNs showed robust performance on time-series datasets,\nsuccessfully detecting GRB signals with high precision. The research is a\npioneering effort in applying QCNNs to astrophysics, offering insights into\ntheir potential and limitations. This work sets the stage for future\ninvestigations to fully realize the advantages of QCNNs in astrophysical data\nanalysis.",
      "tldr_zh": "这篇论文评估了 Quantum Convolutional Neural Networks (QCNNs) 在模拟伽马射线暴 (GRBs) 检测中的性能，专注于区分 GRB-like 信号与背景噪声，使用模拟的 Cherenkov Telescope Array Observatory (CTAO) 数据。研究采用 Qiskit 框架实现混合量子-经典机器学习模型，并在量子模拟器上训练不同 QCNN 架构，包括 Data Reuploading 和 Amplitude encoding 等编码方法。结果显示，QCNNs 的准确率通常超过 90%，与经典 Convolutional Neural Networks (CNNs) 相当，但使用更少参数，从而提高计算资源效率。基准测试进一步揭示，增加量子比特数和采用高级编码方法能提升性能，但也会增加复杂性。该工作为 QCNNs 在天体物理学数据分析中的应用提供了开创性见解，并指出了其潜在优势和局限性。",
      "categories": [
        "astro-ph.HE",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "astro-ph.HE",
      "comment": "9 pages, Accepted for publication in 33rd Euromicro/IEEE\n  International Conference on Parallel, Distributed and Network-Based\n  Processing (PDP 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.17041v1",
      "published_date": "2025-01-28 16:07:12 UTC",
      "updated_date": "2025-01-28 16:07:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:09:04.982448"
    },
    {
      "arxiv_id": "2501.17037v1",
      "title": "Standardised schema and taxonomy for AI incident databases in critical digital infrastructure",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Agarwal",
        "Manisha J. Nene"
      ],
      "abstract": "The rapid deployment of Artificial Intelligence (AI) in critical digital\ninfrastructure introduces significant risks, necessitating a robust framework\nfor systematically collecting AI incident data to prevent future incidents.\nExisting databases lack the granularity as well as the standardized structure\nrequired for consistent data collection and analysis, impeding effective\nincident management. This work proposes a standardized schema and taxonomy for\nAI incident databases, addressing these challenges by enabling detailed and\nstructured documentation of AI incidents across sectors. Key contributions\ninclude developing a unified schema, introducing new fields such as incident\nseverity, causes, and harms caused, and proposing a taxonomy for classifying AI\nincidents in critical digital infrastructure. The proposed solution facilitates\nmore effective incident data collection and analysis, thus supporting\nevidence-based policymaking, enhancing industry safety measures, and promoting\ntransparency. This work lays the foundation for a coordinated global response\nto AI incidents, ensuring trust, safety, and accountability in using AI across\nregions.",
      "tldr_zh": "本研究针对人工智能（AI）在关键数字基础设施中的快速部署所带来的风险，提出一个标准化的 schema 和 taxonomy，以系统化收集和分析 AI 事件数据，解决现有数据库的粒度不足和结构不一致问题。关键贡献包括开发统一 schema、引入新字段如 incident severity、causes 和 harms，并构建 taxonomy 用于分类 AI 事件。该框架有助于提升事件管理效率，支持 evidence-based policymaking、行业安全措施和透明度，最终为全球协调响应 AI 事件奠定基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages, 3 tables. Accepted at the 2024 IEEE Pune Section\n  International Conference (PuneCon)",
      "pdf_url": "http://arxiv.org/pdf/2501.17037v1",
      "published_date": "2025-01-28 15:59:01 UTC",
      "updated_date": "2025-01-28 15:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:09:15.669966"
    },
    {
      "arxiv_id": "2501.17030v1",
      "title": "Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Manojkumar Parmar",
        "Yuvaraj Govindarajulu"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable progress in reasoning,\nalignment, and task-specific performance. However, ensuring harmlessness in\nthese systems remains a critical challenge, particularly in advanced models\nlike DeepSeek-R1. This paper examines the limitations of Reinforcement Learning\n(RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 and\ncompares it with Supervised Fine-Tuning (SFT). While RL improves reasoning\ncapabilities, it faces challenges such as reward hacking, generalization\nfailures, language mixing, and high computational costs. We propose hybrid\ntraining approaches combining RL and SFT to achieve robust harmlessness\nreduction. Usage recommendations and future directions for deploying\nDeepSeek-R1 responsibly are also presented.",
      "tldr_zh": "这篇论文探讨了在 DeepSeek-R1 模型中确保 AI 安全的挑战，重点分析了 Reinforcement Learning (RL) 作为减少有害输出的主要策略的局限性，包括 reward hacking、generalization failures、language mixing 和高计算成本等问题。论文将 RL 与 Supervised Fine-Tuning (SFT) 进行比较，发现 RL 虽能提升推理能力，但无法有效解决这些缺陷。作者提出混合训练方法，结合 RL 和 SFT，以实现更稳健的无害性减少。最后，论文提供 DeepSeek-R1 负责任部署的使用建议和未来方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.17030v1",
      "published_date": "2025-01-28 15:52:51 UTC",
      "updated_date": "2025-01-28 15:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:09:28.202978"
    },
    {
      "arxiv_id": "2501.17015v1",
      "title": "Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework",
      "title_zh": "重新审视混合模型用于多智能体模拟：统一框架下的实验研究",
      "authors": [
        "Longzhong Lin",
        "Xuewu Lin",
        "Kechun Xu",
        "Haojian Lu",
        "Lichao Huang",
        "Rong Xiong",
        "Yue Wang"
      ],
      "abstract": "Simulation plays a crucial role in assessing autonomous driving systems,\nwhere the generation of realistic multi-agent behaviors is a key aspect. In\nmulti-agent simulation, the primary challenges include behavioral multimodality\nand closed-loop distributional shifts. In this study, we revisit mixture models\nfor generating multimodal agent behaviors, which can cover the mainstream\nmethods including continuous mixture models and GPT-like discrete models.\nFurthermore, we introduce a closed-loop sample generation approach tailored for\nmixture models to mitigate distributional shifts. Within the unified mixture\nmodel~(UniMM) framework, we recognize critical configurations from both model\nand data perspectives. We conduct a systematic examination of various model\nconfigurations, including positive component matching, continuous regression,\nprediction horizon, and the number of components. Moreover, our investigation\ninto the data configuration highlights the pivotal role of closed-loop samples\nin achieving realistic simulations. To extend the benefits of closed-loop\nsamples across a broader range of mixture models, we further address the\nshortcut learning and off-policy learning issues. Leveraging insights from our\nexploration, the distinct variants proposed within the UniMM framework,\nincluding discrete, anchor-free, and anchor-based models, all achieve\nstate-of-the-art performance on the WOSAC benchmark.",
      "tldr_zh": "这篇论文重新审视了 mixture models 在多智能体模拟中的应用，针对行为的多模态性和闭环分布偏移等关键挑战，提出了一种统一的混合模型框架(UniMM)。该框架引入闭环样本生成方法，并系统考察了模型配置（如正向组件匹配、连续回归、预测 horizons 和组件数量）以及数据配置，强调闭环样本在实现现实模拟中的作用。最终，UniMM 框架下的离散、anchor-free 和 anchor-based 模型变体在 WOSAC benchmark 上达到了 state-of-the-art 性能，解决了 shortcut learning 和 off-policy learning 等问题。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17015v1",
      "published_date": "2025-01-28 15:26:25 UTC",
      "updated_date": "2025-01-28 15:26:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:09:39.934384"
    },
    {
      "arxiv_id": "2501.16986v1",
      "title": "Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver",
      "title_zh": "通过新颖的条件生成量子特征求解器实现生成量子组合优化",
      "authors": [
        "Shunya Minami",
        "Kouhei Nakaji",
        "Yohichi Suzuki",
        "Alán Aspuru-Guzik",
        "Tadashi Kadowaki"
      ],
      "abstract": "Quantum computing is entering a transformative phase with the emergence of\nlogical quantum processors, which hold the potential to tackle complex problems\nbeyond classical capabilities. While significant progress has been made,\napplying quantum algorithms to real-world problems remains challenging. Hybrid\nquantum-classical techniques have been explored to bridge this gap, but they\noften face limitations in expressiveness, trainability, or scalability. In this\nwork, we introduce conditional Generative Quantum Eigensolver\n(conditional-GQE), a context-aware quantum circuit generator powered by an\nencoder-decoder Transformer. Focusing on combinatorial optimization, we train\nour generator for solving problems with up to 10 qubits, exhibiting nearly\nperfect performance on new problems. By leveraging the high expressiveness and\nflexibility of classical generative models, along with an efficient\npreference-based training scheme, conditional-GQE provides a generalizable and\nscalable framework for quantum circuit generation. Our approach advances hybrid\nquantum-classical computing and contributes to accelerate the transition toward\nfault-tolerant quantum computing.",
      "tldr_zh": "本文提出了一种新型的conditional Generative Quantum Eigensolver (conditional-GQE)，这是一种基于encoder-decoder Transformer的上下文感知量子电路生成器，旨在解决混合量子-经典技术在组合优化问题中的表达性、训练性和可扩展性限制。研究团队训练该生成器处理多达10量子比特的问题，并在新问题上实现了近乎完美的性能，通过高效的基于偏好的训练方案提升了其泛化和可扩展性。该方法为混合量子-经典计算提供了一个通用框架，并加速了向容错量子计算的过渡。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "26 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16986v1",
      "published_date": "2025-01-28 14:35:46 UTC",
      "updated_date": "2025-01-28 14:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:09:51.759919"
    },
    {
      "arxiv_id": "2501.16966v1",
      "title": "Heterogeneity-aware Personalized Federated Learning via Adaptive Dual-Agent Reinforcement Learning",
      "title_zh": "通过自适应双代理强化学习的异质性感知个性化联邦学习",
      "authors": [
        "Xi Chen",
        "Qin Li",
        "Haibin Cai",
        "Ting Wang"
      ],
      "abstract": "Federated Learning (FL) empowers multiple clients to collaboratively train\nmachine learning models without sharing local data, making it highly applicable\nin heterogeneous Internet of Things (IoT) environments. However, intrinsic\nheterogeneity in clients' model architectures and computing capabilities often\nresults in model accuracy loss and the intractable straggler problem, which\nsignificantly impairs training effectiveness. To tackle these challenges, this\npaper proposes a novel Heterogeneity-aware Personalized Federated Learning\nmethod, named HAPFL, via multi-level Reinforcement Learning (RL) mechanisms.\nHAPFL optimizes the training process by incorporating three strategic\ncomponents: 1) An RL-based heterogeneous model allocation mechanism. The\nparameter server employs a Proximal Policy Optimization (PPO)-based RL agent to\nadaptively allocate appropriately sized, differentiated models to clients based\non their performance, effectively mitigating performance disparities. 2) An\nRL-based training intensity adjustment scheme. The parameter server leverages\nanother PPO-based RL agent to dynamically fine-tune the training intensity for\neach client to further enhance training efficiency and reduce straggling\nlatency. 3) A knowledge distillation-based mutual learning mechanism. Each\nclient deploys both a heterogeneous local model and a homogeneous lightweight\nmodel named LiteModel, where these models undergo mutual learning through\nknowledge distillation. This uniform LiteModel plays a pivotal role in\naggregating and sharing global knowledge, significantly enhancing the\neffectiveness of personalized local training. Experimental results across\nmultiple benchmark datasets demonstrate that HAPFL not only achieves high\naccuracy but also substantially reduces the overall training time by\n20.9%-40.4% and decreases straggling latency by 19.0%-48.0% compared to\nexisting solutions.",
      "tldr_zh": "这篇论文提出了一种异质性感知的个性化 Federated Learning 方法 HAPFL，通过自适应双代理 Reinforcement Learning 机制解决客户端模型架构和计算能力异质性导致的准确性损失和 straggler 问题。HAPFL 包括三个关键组件：基于 Proximal Policy Optimization (PPO) 的模型分配机制、动态训练强度调整方案，以及基于知识蒸馏的互学习机制，其中每个客户端使用异质本地模型和同质轻量模型 (LiteModel) 进行知识共享。实验结果显示，该方法在多个基准数据集上显著提高了模型准确性，同时将总体训练时间减少 20.9%-40.4%，并将 straggling 延迟降低 19.0%-48.0%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16966v1",
      "published_date": "2025-01-28 14:08:57 UTC",
      "updated_date": "2025-01-28 14:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:10:04.108710"
    },
    {
      "arxiv_id": "2501.16961v2",
      "title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Raza",
        "Natasa Milic-Frayling"
      ],
      "abstract": "Robustness of reasoning remains a significant challenge for large language\nmodels, and addressing it is essential for the practical applicability of\nAI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a\nnovel approach that addresses the key challenge in combining language models\nwith the rigor of logical solvers: to accurately formulate the reasoning\nproblem from natural language to the formal language of the solver. SSV uses a\nconsistency-based approach to produce strong abstract formalizations of\nproblems using concrete instantiations that are generated by the model and\nverified by the solver. In addition to significantly advancing the overall\nreasoning accuracy over the state-of-the-art, a key novelty that this approach\npresents is a feature of verification that has near-perfect precision over a\nsignificant coverage of cases, as we demonstrate on open reasoning benchmarks.\nWe propose such *near-certain reasoning* as a new approach to reduce the need\nfor manual verification in many cases, taking us closer to more dependable and\nautonomous AI reasoning systems.",
      "tldr_zh": "该论文针对大型语言模型的推理鲁棒性挑战，提出了Semantic Self-Verification (SSV)方法，用于将自然语言问题准确转化为logical solvers的形式语言。SSV采用基于一致性的策略，通过模型生成的具体实例并由求解器验证，来产生强抽象形式化，从而显著提升整体推理准确性。实验在开放推理基准上证明，该方法实现了近乎完美的验证精度，并引入了near-certain reasoning概念，减少手动验证需求，推动更可靠的自主AI推理系统发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16961v2",
      "published_date": "2025-01-28 14:04:49 UTC",
      "updated_date": "2025-05-01 10:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:10:15.844294"
    },
    {
      "arxiv_id": "2501.16952v1",
      "title": "Multiple Abstraction Level Retrieve Augment Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Zheng",
        "Xinyi Ni",
        "Pengyu Hong"
      ],
      "abstract": "A Retrieval-Augmented Generation (RAG) model powered by a large language\nmodel (LLM) provides a faster and more cost-effective solution for adapting to\nnew data and knowledge. It also delivers more specialized responses compared to\npre-trained LLMs. However, most existing approaches rely on retrieving\nprefix-sized chunks as references to support question-answering (Q/A). This\napproach is often deployed to address information needs at a single level of\nabstraction, as it struggles to generate answers across multiple levels of\nabstraction. In an RAG setting, while LLMs can summarize and answer questions\neffectively when provided with sufficient details, retrieving excessive\ninformation often leads to the 'lost in the middle' problem and exceeds token\nlimitations. We propose a novel RAG approach that uses chunks of multiple\nabstraction levels (MAL), including multi-sentence-level, paragraph-level,\nsection-level, and document-level. The effectiveness of our approach is\ndemonstrated in an under-explored scientific domain of Glycoscience. Compared\nto traditional single-level RAG approaches, our approach improves AI evaluated\nanswer correctness of Q/A by 25.739\\% on Glyco-related papers.",
      "tldr_zh": "本研究提出了一种新型检索增强生成（Retrieval-Augmented Generation, RAG）方法，名为 Multiple Abstraction Level RAG，利用大型语言模型（LLM）通过多抽象级别（MAL）块（如多句级、段落级、部分级和文档级）来处理问答任务，从而解决传统RAG在不同抽象级别上信息检索不足和信息过载（如“lost in the middle”问题）的问题。该方法在Glycoscience领域进行了验证，与单级别RAG相比，提高了AI评估的问答正确率25.739%。这项创新为适应新知识和生成专业化响应的RAG系统提供了更高效、可扩展的框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16952v1",
      "published_date": "2025-01-28 13:49:39 UTC",
      "updated_date": "2025-01-28 13:49:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:10:27.900508"
    },
    {
      "arxiv_id": "2501.16945v1",
      "title": "ToolFactory: Automating Tool Generation by Leveraging LLM to Understand REST API Documentations",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Ni",
        "Qiuyang Wang",
        "Yukun Zhang",
        "Pengyu Hong"
      ],
      "abstract": "LLM-based tool agents offer natural language interfaces, enabling users to\nseamlessly interact with computing services. While REST APIs are valuable\nresources for building such agents, they must first be transformed into\nAI-compatible tools. Automatically generating AI-compatible tools from REST API\ndocuments can greatly streamline tool agent development and minimize user\nlearning curves. However, API documentation often suffers from a lack of\nstandardization, inconsistent schemas, and incomplete information. To address\nthese issues, we developed \\textbf{ToolFactory}, an open-source pipeline for\nautomating tool generation from unstructured API documents. To enhance the\nreliability of the developed tools, we implemented an evaluation method to\ndiagnose errors. Furthermore, we built a knowledge base of verified tools,\nwhich we leveraged to infer missing information from poorly documented APIs. We\ndeveloped the API Extraction Benchmark, comprising 167 API documents and 744\nendpoints in various formats, and designed a JSON schema to annotate them. This\nannotated dataset was utilized to train and validate ToolFactory. The\nexperimental results highlight the effectiveness of ToolFactory. We also\ndemonstrated ToolFactory by creating a domain-specific AI agent for\nglycomaterials research. ToolFactory exhibits significant potential for\nfacilitating the seamless integration of scientific REST APIs into AI\nworkflows.",
      "tldr_zh": "本文提出 ToolFactory，一种开源管道，利用 LLM 理解 REST API 文档，自动生成 AI 兼容工具，以解决 API 文档缺乏标准化、不一致性和信息不完整的问题。该系统通过错误诊断评估方法和知识基推断缺失信息，并开发了 API Extraction Benchmark 数据集（包括 167 个 API 文档和 744 个端点）用于训练和验证。实验结果证明 ToolFactory 有效，提升了工具代理开发效率，并在糖材料研究中构建了领域特定 AI 代理，促进了科学 REST APIs 与 AI 工作流的无缝集成。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16945v1",
      "published_date": "2025-01-28 13:42:33 UTC",
      "updated_date": "2025-01-28 13:42:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:10:39.727880"
    },
    {
      "arxiv_id": "2501.16944v2",
      "title": "Exact Computation of Any-Order Shapley Interactions for Graph Neural Networks",
      "title_zh": "任意阶 Shapley 交互的精确计算用于图神经网络",
      "authors": [
        "Maximilian Muschalik",
        "Fabian Fumagalli",
        "Paolo Frazzetto",
        "Janine Strotherm",
        "Luca Hermes",
        "Alessandro Sperduti",
        "Eyke Hüllermeier",
        "Barbara Hammer"
      ],
      "abstract": "Albeit the ubiquitous use of Graph Neural Networks (GNNs) in machine learning\n(ML) prediction tasks involving graph-structured data, their interpretability\nremains challenging. In explainable artificial intelligence (XAI), the Shapley\nValue (SV) is the predominant method to quantify contributions of individual\nfeatures to a ML model's output. Addressing the limitations of SVs in complex\nprediction models, Shapley Interactions (SIs) extend the SV to groups of\nfeatures. In this work, we explain single graph predictions of GNNs with SIs\nthat quantify node contributions and interactions among multiple nodes. By\nexploiting the GNN architecture, we show that the structure of interactions in\nnode embeddings are preserved for graph prediction. As a result, the\nexponential complexity of SIs depends only on the receptive fields, i.e. the\nmessage-passing ranges determined by the connectivity of the graph and the\nnumber of convolutional layers. Based on our theoretical results, we introduce\nGraphSHAP-IQ, an efficient approach to compute any-order SIs exactly.\nGraphSHAP-IQ is applicable to popular message passing techniques in conjunction\nwith a linear global pooling and output layer. We showcase that GraphSHAP-IQ\nsubstantially reduces the exponential complexity of computing exact SIs on\nmultiple benchmark datasets. Beyond exact computation, we evaluate\nGraphSHAP-IQ's approximation of SIs on popular GNN architectures and compare\nwith existing baselines. Lastly, we visualize SIs of real-world water\ndistribution networks and molecule structures using a SI-Graph.",
      "tldr_zh": "这篇论文针对Graph Neural Networks (GNNs) 的可解释性挑战，引入Shapley Interactions (SIs) 来量化单个图预测中节点贡献及其多节点互动。作者开发了GraphSHAP-IQ 方法，通过利用GNN架构的特性（如接收字段receptive fields），实现了任意阶SIs的精确计算，并将指数复杂度显著降低，仅依赖于图连通性和卷积层数量。实验在多个基准数据集上证明，GraphSHAP-IQ 优于现有基线，并在真实世界应用中（如水分布网络和分子结构的SI-Graph可视化）展示了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint Version. Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16944v2",
      "published_date": "2025-01-28 13:37:44 UTC",
      "updated_date": "2025-03-17 09:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:10:52.045476"
    },
    {
      "arxiv_id": "2501.16937v4",
      "title": "TAID: Temporally Adaptive Interpolated Distillation for Efficient Knowledge Transfer in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Makoto Shing",
        "Kou Misaki",
        "Han Bao",
        "Sho Yokoi",
        "Takuya Akiba"
      ],
      "abstract": "Causal language models have demonstrated remarkable capabilities, but their\nsize poses significant challenges for deployment in resource-constrained\nenvironments. Knowledge distillation, a widely-used technique for transferring\nknowledge from a large teacher model to a small student model, presents a\npromising approach for model compression. A significant remaining issue lies in\nthe major differences between teacher and student models, namely the\nsubstantial capacity gap, mode averaging, and mode collapse, which pose\nbarriers during distillation. To address these issues, we introduce\n$\\textit{Temporally Adaptive Interpolated Distillation (TAID)}$, a novel\nknowledge distillation approach that dynamically interpolates student and\nteacher distributions through an adaptive intermediate distribution, gradually\nshifting from the student's initial distribution towards the teacher's\ndistribution. We provide a theoretical analysis demonstrating TAID's ability to\nprevent mode collapse and empirically show its effectiveness in addressing the\ncapacity gap while balancing mode averaging and mode collapse. Our\ncomprehensive experiments demonstrate TAID's superior performance across\nvarious model sizes and architectures in both instruction tuning and\npre-training scenarios. Furthermore, we showcase TAID's practical impact by\ndeveloping two state-of-the-art compact foundation models:\n$\\texttt{TAID-LLM-1.5B}$ for language tasks and $\\texttt{TAID-VLM-2B}$ for\nvision-language tasks. These results demonstrate TAID's effectiveness in\ncreating high-performing and efficient models, advancing the development of\nmore accessible AI technologies.",
      "tldr_zh": "该研究针对因果语言模型的部署挑战，提出了一种新型知识蒸馏方法——Temporally Adaptive Interpolated Distillation (TAID)，通过动态插值学生和教师分布的自适应中间分布，逐步从学生初始分布过渡到教师分布，从而缓解容量差距、模式平均和模式崩溃问题。理论分析证明TAID能有效防止模式崩溃，并在实验中展示其在各种模型大小和架构下的优越性能，包括指令微调和预训练场景。最终，研究开发了两个先进紧凑模型：TAID-LLM-1.5B用于语言任务和TAID-VLM-2B用于视觉语言任务，显著推进了高效AI技术的可访问性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at the 13th International Conference on Learning\n  Representations (ICLR 2025) as a Spotlight presentation",
      "pdf_url": "http://arxiv.org/pdf/2501.16937v4",
      "published_date": "2025-01-28 13:31:18 UTC",
      "updated_date": "2025-02-27 23:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:11:03.214695"
    },
    {
      "arxiv_id": "2501.16922v1",
      "title": "Agential AI for Integrated Continual Learning, Deliberative Behavior, and Comprehensible Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zeki Doruk Erden",
        "Boi Faltings"
      ],
      "abstract": "Contemporary machine learning paradigm excels in statistical data analysis,\nsolving problems that classical AI couldn't. However, it faces key limitations,\nsuch as a lack of integration with planning, incomprehensible internal\nstructure, and inability to learn continually. We present the initial design\nfor an AI system, Agential AI (AAI), in principle operating independently or on\ntop of statistical methods, designed to overcome these issues. AAI's core is a\nlearning method that models temporal dynamics with guarantees of completeness,\nminimality, and continual learning, using component-level variation and\nselection to learn the structure of the environment. It integrates this with a\nbehavior algorithm that plans on a learned model and encapsulates high-level\nbehavior patterns. Preliminary experiments on a simple environment show AAI's\neffectiveness and potential.",
      "tldr_zh": "该论文指出现代机器学习在统计数据分析上表现出色，但存在缺乏规划整合、内部结构不可理解以及无法实现 continual learning 等关键局限性。为解决这些问题，研究提出 Agential AI (AAI) 的初步设计，这是一个可独立或基于统计方法的 AI 系统，其核心是通过组件级别的变异和选择来建模时间动态，确保模型的完整性、最小性和 continual learning 能力，并与 deliberative behavior 算法整合以进行规划和封装高级行为模式。在简单环境中的初步实验证明了 AAI 的有效性和潜力，为构建可理解的 AI 系统提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16922v1",
      "published_date": "2025-01-28 13:09:08 UTC",
      "updated_date": "2025-01-28 13:09:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:11:15.174102"
    },
    {
      "arxiv_id": "2501.16899v1",
      "title": "RDMM: Fine-Tuned LLM Models for On-Device Robotic Decision Making with Enhanced Contextual Awareness in Specific Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Shady Nasrat",
        "Myungsu Kim",
        "Seonil Lee",
        "Jiho Lee",
        "Yeoncheol Jang",
        "Seung-joon Yi"
      ],
      "abstract": "Large language models (LLMs) represent a significant advancement in\nintegrating physical robots with AI-driven systems. We showcase the\ncapabilities of our framework within the context of the real-world household\ncompetition. This research introduces a framework that utilizes RDMM (Robotics\nDecision-Making Models), which possess the capacity for decision-making within\ndomain-specific contexts, as well as an awareness of their personal knowledge\nand capabilities. The framework leverages information to enhance the autonomous\ndecision-making of the system. In contrast to other approaches, our focus is on\nreal-time, on-device solutions, successfully operating on hardware with as\nlittle as 8GB of memory. Our framework incorporates visual perception models\nequipping robots with understanding of their environment. Additionally, the\nframework has integrated real-time speech recognition capabilities, thus\nenhancing the human-robot interaction experience. Experimental results\ndemonstrate that the RDMM framework can plan with an 93\\% accuracy.\nFurthermore, we introduce a new dataset consisting of 27k planning instances,\nas well as 1.3k text-image annotated samples derived from the competition. The\nframework, benchmarks, datasets, and models developed in this work are publicly\navailable on our GitHub repository at https://github.com/shadynasrat/RDMM.",
      "tldr_zh": "这篇论文介绍了 RDMM 框架，利用 Fine-Tuned LLM Models 来提升机器人决策的上下文感知能力，专注于特定领域如家庭环境的应用。该框架支持实时设备端运行，仅需 8GB 内存，并整合了视觉感知模型和实时语音识别功能，以增强环境理解和人机交互。实验结果显示，RDMM 在规划任务中达到 93% 的准确率，并贡献了一个包含 27k 规划实例和 1.3k 文本-图像标注样本的新数据集，所有资源已在 GitHub 上公开。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16899v1",
      "published_date": "2025-01-28 12:35:06 UTC",
      "updated_date": "2025-01-28 12:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:11:27.183953"
    },
    {
      "arxiv_id": "2501.16889v1",
      "title": "Extending Information Bottleneck Attribution to Video Sequences",
      "title_zh": "将信息瓶",
      "authors": [
        "Veronika Solopova",
        "Lucas Schmidt",
        "Dorothea Kolossa"
      ],
      "abstract": "We introduce VIBA, a novel approach for explainable video classification by\nadapting Information Bottlenecks for Attribution (IBA) to video sequences.\nWhile most traditional explainability methods are designed for image models,\nour IBA framework addresses the need for explainability in temporal models used\nfor video analysis. To demonstrate its effectiveness, we apply VIBA to video\ndeepfake detection, testing it on two architectures: the Xception model for\nspatial features and a VGG11-based model for capturing motion dynamics through\noptical flow. Using a custom dataset that reflects recent deepfake generation\ntechniques, we adapt IBA to create relevance and optical flow maps, visually\nhighlighting manipulated regions and motion inconsistencies. Our results show\nthat VIBA generates temporally and spatially consistent explanations, which\nalign closely with human annotations, thus providing interpretability for video\nclassification and particularly for deepfake detection.",
      "tldr_zh": "该研究引入 VIBA 方法，将 Information Bottlenecks for Attribution (IBA) 扩展到视频序列，以提升视频分类的可解释性。VIBA 通过适应 IBA 生成相关性和光流地图，应用于视频 deepfake 检测，并测试于 Xception（空间特征）和 VGG11-based 模型（捕捉运动动态），使用自定义数据集突出被操纵区域和运动不一致。结果表明，VIBA 提供的解释在空间和时间上与人类标注高度一致，提升了视频分类，尤其是 deepfake 检测的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16889v1",
      "published_date": "2025-01-28 12:19:44 UTC",
      "updated_date": "2025-01-28 12:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:11:39.350730"
    },
    {
      "arxiv_id": "2501.16884v1",
      "title": "Irony Detection, Reasoning and Understanding in Zero-shot Learning",
      "title_zh": "零样本学习中的讽刺检测、推理和理解",
      "authors": [
        "Peiling Yi",
        "Yuhan Xia"
      ],
      "abstract": "Irony is a powerful figurative language (FL) on social media that can\npotentially mislead various NLP tasks, such as recommendation systems,\nmisinformation checks, and sentiment analysis. Understanding the implicit\nmeaning of this kind of subtle language is essential to mitigate irony's\nnegative impact on NLP tasks. However, building models to understand irony\npresents a unique set of challenges, because irony is a complex form of\nlanguage that often relies on context, tone, and subtle cues to convey meaning\nthat is opposite or different from the literal interpretation. Large language\nmodels, such as ChatGPT, are increasingly able to capture implicit and\ncontextual information. In this study, we investigate the generalization,\nreasoning and understanding ability of ChatGPT on irony detection across six\ndifferent genre irony detection datasets. Our findings suggest that ChatGPT\nappears to show an enhanced language understanding and reasoning ability. But\nit needs to be very careful in prompt engineering design. Thus, we propose a\nprompt engineering design framework IDADP to achieve higher irony detection\naccuracy, improved understanding of irony, and more effective explanations\ncompared to other state-of-the-art ChatGPT zero-shot approaches. And ascertain\nvia experiments that the practice generated under the framework is likely to be\nthe promised solution to resolve the generalization issues of LLMs.",
      "tldr_zh": "该研究探讨了讽刺（irony）在社交媒体上的影响及其对 NLP 任务（如推荐系统和情感分析）的潜在误导，强调理解讽刺的隐含意义需要处理其依赖上下文、语气和微妙线索的复杂性。作者评估了 ChatGPT 在零样本学习（zero-shot learning）下的讽刺检测、推理和理解能力，发现其显示出增强的语言理解，但提示工程（prompt engineering）设计至关重要。为此，他们提出 IDADP 框架，该框架通过优化提示设计，显著提高了讽刺检测准确率、理解深度和解释效果。实验结果证实，IDADP 能有效解决大型语言模型（LLMs）的泛化问题，提供了一个可行的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16884v1",
      "published_date": "2025-01-28 12:13:07 UTC",
      "updated_date": "2025-01-28 12:13:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:11:52.331370"
    },
    {
      "arxiv_id": "2502.00048v1",
      "title": "Contextually Entangled Gradient Mapping for Optimized LLM Comprehension",
      "title_zh": "用于优化LLM理解的上下文纠缠梯度映射",
      "authors": [
        "Colin Sisate",
        "Alistair Goldfinch",
        "Vincent Waterstone",
        "Sebastian Kingsley",
        "Mariana Blackthorn"
      ],
      "abstract": "Contextually Entangled Gradient Mapping (CEGM) introduces a new approach to\ngradient optimization, redefining the relationship between contextual\nembeddings and gradient updates to enhance semantic coherence and reasoning\ncapabilities in neural architectures. By treating gradients as dynamic carriers\nof contextual dependencies rather than isolated numerical entities, the\nproposed methodology bridges critical gaps in existing optimization strategies.\nThe integration of entangled gradient dynamics into a loss regularization\nframework demonstrated significant improvements in tasks involving long-form\nreasoning, contextual retention, and adaptability to unseen domains.\nExperimental evaluations showed that the CEGM-enhanced model consistently\noutperformed baseline approaches, achieving higher accuracy in token-level\npredictions and greater resilience to noisy inputs. Practical implementations\ninvolved modifications to training pipelines, introducing entanglement layers\nand dynamic coefficient adjustments that seamlessly align with existing\narchitectures. Results further highlighted reductions in semantic drift during\nsequential transformations and improvements in embedding coherence across\nparaphrased sentences, showing the robustness and versatility of the proposed\nmethodology. The findings demonstrate the broader implications of gradient\nentanglement for both theoretical advancements and practical applications in\noptimization strategies.",
      "tldr_zh": "该论文提出 Contextually Entangled Gradient Mapping (CEGM)，一种创新的梯度优化方法，通过将梯度视为动态的上下文依赖载体而非孤立数值实体，重新定义了上下文嵌入与梯度更新的关系，以提升 LLM 的语义连贯性和推理能力。CEGM 将纠缠梯度动态整合到损失正则化框架中，并在长形式推理、上下文保留和适应未知领域的任务中实现了显著改进。实验结果显示，CEGM 增强的模型在 token-level 预测准确率上优于基线方法，并对噪声输入更具弹性，同时减少了语义漂移并提高了嵌入连贯性，证明了该方法在优化策略中的广泛应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00048v1",
      "published_date": "2025-01-28 11:50:35 UTC",
      "updated_date": "2025-01-28 11:50:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:12:04.295897"
    },
    {
      "arxiv_id": "2502.15724v1",
      "title": "Instruction-Based Fine-tuning of Open-Source LLMs for Predicting Customer Purchase Behaviors",
      "title_zh": "翻译失败",
      "authors": [
        "Halil Ibrahim Ergul",
        "Selim Balcisoy",
        "Burcin Bozkaya"
      ],
      "abstract": "In this study, the performance of various predictive models, including\nprobabilistic baseline, CNN, LSTM, and finetuned LLMs, in forecasting merchant\ncategories from financial transaction data have been evaluated. Utilizing\ndatasets from Bank A for training and Bank B for testing, the superior\npredictive capabilities of the fine-tuned Mistral Instruct model, which was\ntrained using customer data converted into natural language format have been\ndemonstrated. The methodology of this study involves instruction fine-tuning\nMistral via LoRA (LowRank Adaptation of Large Language Models) to adapt its\nvast pre-trained knowledge to the specific domain of financial transactions.\nThe Mistral model significantly outperforms traditional sequential models,\nachieving higher F1 scores in the three key merchant categories of bank\ntransaction data (grocery, clothing, and gas stations) that is crucial for\ntargeted marketing campaigns. This performance is attributed to the model's\nenhanced semantic understanding and adaptability which enables it to better\nmanage minority classes and predict transaction categories with greater\naccuracy. These findings highlight the potential of LLMs in predicting human\nbehavior.",
      "tldr_zh": "本文评估了多种模型（如概率基线、CNN 和 LSTM）在从金融交易数据预测商户类别方面的性能，并通过指令微调开源 LLMs（例如 Mistral）展示了显著优势。研究采用 LoRA（Low-Rank Adaptation）方法，将客户数据转换为自然语言格式对 Mistral 进行训练，使用 Bank A 数据集训练和 Bank B 数据集测试。结果表明，微调后的 Mistral 模型在关键商户类别（grocery、clothing 和 gas stations）上实现了更高的 F1 scores，特别是在处理少数类别的预测上表现更佳。这些发现强调了 LLMs 在预测客户购买行为方面的潜力，有助于提升针对性营销策略。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15724v1",
      "published_date": "2025-01-28 11:34:22 UTC",
      "updated_date": "2025-01-28 11:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:12:16.105766"
    },
    {
      "arxiv_id": "2501.16836v1",
      "title": "Misspellings in Natural Language Processing: A survey",
      "title_zh": "翻译失败",
      "authors": [
        "Gianluca Sperduti",
        "Alejandro Moreo"
      ],
      "abstract": "This survey provides an overview of the challenges of misspellings in natural\nlanguage processing (NLP). While often unintentional, misspellings have become\nubiquitous in digital communication, especially with the proliferation of Web\n2.0, user-generated content, and informal text mediums such as social media,\nblogs, and forums. Even if humans can generally interpret misspelled text, NLP\nmodels frequently struggle to handle it: this causes a decline in performance\nin common tasks like text classification and machine translation. In this\npaper, we reconstruct a history of misspellings as a scientific problem. We\nthen discuss the latest advancements to address the challenge of misspellings\nin NLP. Main strategies to mitigate the effect of misspellings include data\naugmentation, double step, character-order agnostic, and tuple-based methods,\namong others. This survey also examines dedicated data challenges and\ncompetitions to spur progress in the field. Critical safety and ethical\nconcerns are also examined, for example, the voluntary use of misspellings to\ninject malicious messages and hate speech on social networks. Furthermore, the\nsurvey explores psycholinguistic perspectives on how humans process\nmisspellings, potentially informing innovative computational techniques for\ntext normalization and representation. Finally, the misspelling-related\nchallenges and opportunities associated with modern large language models are\nalso analyzed, including benchmarks, datasets, and performances of the most\nprominent language models against misspellings. This survey aims to be an\nexhaustive resource for researchers seeking to mitigate the impact of\nmisspellings in the rapidly evolving landscape of NLP.",
      "tldr_zh": "这篇调查论文探讨了拼写错误（misspellings）在自然语言处理（NLP）中的挑战，包括其在数字通信中的普遍性以及对文本分类和机器翻译等任务的负面影响。论文回顾了拼写错误作为科学问题的历史，并总结了应对策略，如数据增强（data augmentation）、双步方法和元组-based 方法等，以缓解模型性能下降。调查还考察了相关数据集挑战、比赛、安全与伦理问题（如恶意注入仇恨言论），并从心理语言学视角分析人类处理拼写错误的方式，以启发新的文本归一化和表示技术。最后，论文评估了大型语言模型（large language models）在处理拼写错误时的基准、数据集和性能，为NLP研究者提供一个全面资源，应对这一快速演变的领域挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16836v1",
      "published_date": "2025-01-28 10:26:04 UTC",
      "updated_date": "2025-01-28 10:26:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:12:27.342549"
    },
    {
      "arxiv_id": "2501.17889v1",
      "title": "Knoop: Practical Enhancement of Knockoff with Over-Parameterization for Variable Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaochen Zhang",
        "Yunfeng Cai",
        "Haoyi Xiong"
      ],
      "abstract": "Variable selection plays a crucial role in enhancing modeling effectiveness\nacross diverse fields, addressing the challenges posed by high-dimensional\ndatasets of correlated variables. This work introduces a novel approach namely\nKnockoff with over-parameterization (Knoop) to enhance Knockoff filters for\nvariable selection. Specifically, Knoop first generates multiple knockoff\nvariables for each original variable and integrates them with the original\nvariables into an over-parameterized Ridgeless regression model. For each\noriginal variable, Knoop evaluates the coefficient distribution of its\nknockoffs and compares these with the original coefficients to conduct an\nanomaly-based significance test, ensuring robust variable selection. Extensive\nexperiments demonstrate superior performance compared to existing methods in\nboth simulation and real-world datasets. Knoop achieves a notably higher Area\nunder the Curve (AUC) of the Receiver Operating Characteristic (ROC) Curve for\neffectively identifying relevant variables against the ground truth by\ncontrolled simulations, while showcasing enhanced predictive accuracy across\ndiverse regression and classification tasks. The analytical results further\nbackup our observations.",
      "tldr_zh": "这篇论文提出了 Knoop 方法，这是一种通过 over-parameterization 增强 Knockoff 过滤器的实用变量选择技术，旨在处理高维相关变量数据集中的挑战。Knoop 首先为每个原始变量生成多个 knockoff 变量，并将它们整合到 over-parameterized Ridgeless regression 模型中，然后通过比较 knockoff 系数分布与原始系数进行 anomaly-based 显著性测试，以实现鲁棒的变量选择。实验结果显示，Knoop 在模拟和真实数据集上比现有方法表现出色，取得了更高的 ROC AUC 值和预测准确性，同时在各种回归和分类任务中展现了优越性能。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "An earlier version of our paper at Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2501.17889v1",
      "published_date": "2025-01-28 09:27:04 UTC",
      "updated_date": "2025-01-28 09:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:12:39.505474"
    },
    {
      "arxiv_id": "2502.00047v4",
      "title": "HadamRNN: Binary and Sparse Ternary Orthogonal RNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Armand Foucault",
        "Franck Mamalet",
        "François Malgouyres"
      ],
      "abstract": "Binary and sparse ternary weights in neural networks enable faster\ncomputations and lighter representations, facilitating their use on edge\ndevices with limited computational power. Meanwhile, vanilla RNNs are highly\nsensitive to changes in their recurrent weights, making the binarization and\nternarization of these weights inherently challenging. To date, no method has\nsuccessfully achieved binarization or ternarization of vanilla RNN weights. We\npresent a new approach leveraging the properties of Hadamard matrices to\nparameterize a subset of binary and sparse ternary orthogonal matrices. This\nmethod enables the training of orthogonal RNNs (ORNNs) with binary and sparse\nternary recurrent weights, effectively creating a specific class of binary and\nsparse ternary vanilla RNNs. The resulting ORNNs, called HadamRNN and\nBlock-HadamRNN, are evaluated on benchmarks such as the copy task, permuted and\nsequential MNIST tasks, the IMDB dataset, two GLUE benchmarks, and two IoT\nbenchmarks. Despite binarization or sparse ternarization, these RNNs maintain\nperformance levels comparable to state-of-the-art full-precision models,\nhighlighting the effectiveness of our approach. Notably, our approach is the\nfirst solution with binary recurrent weights capable of tackling the copy task\nover 1000 timesteps.",
      "tldr_zh": "该论文针对RNNs（循环神经网络）在二值化和稀疏三元化权重时的敏感性问题，提出了一种新方法，利用Hadamard matrices的属性来参数化二进制和稀疏三元正交矩阵，从而训练具有二进制和稀疏三元循环权重的正交RNNs（ORNNs）。他们开发了HadamRNN和Block-HadamRNN模型，这些模型在保持性能的同时，实现了更快的计算和更轻的表示。实验结果显示，在copy task、permuted and sequential MNIST、IMDB、GLUE基准和IoT基准上，这些模型的性能与最先进的全精度模型相当，并首次在1000时间步上成功处理copy task。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00047v4",
      "published_date": "2025-01-28 09:16:28 UTC",
      "updated_date": "2025-05-06 09:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:12:51.710653"
    },
    {
      "arxiv_id": "2501.16800v1",
      "title": "DIRIGENt: End-To-End Robotic Imitation of Human Demonstrations Based on a Diffusion Model",
      "title_zh": "DIRIGENt：基于扩散模型的端到端机器人",
      "authors": [
        "Josua Spisak",
        "Matthias Kerzel",
        "Stefan Wermter"
      ],
      "abstract": "There has been substantial progress in humanoid robots, with new skills\ncontinuously being taught, ranging from navigation to manipulation. While these\nabilities may seem impressive, the teaching methods often remain inefficient.\nTo enhance the process of teaching robots, we propose leveraging a mechanism\neffectively used by humans: teaching by demonstrating. In this paper, we\nintroduce DIRIGENt (DIrect Robotic Imitation GENeration model), a novel\nend-to-end diffusion approach that directly generates joint values from\nobserving human demonstrations, enabling a robot to imitate these actions\nwithout any existing mapping between it and humans. We create a dataset in\nwhich humans imitate a robot and then use this collected data to train a\ndiffusion model that enables a robot to imitate humans. The following three\naspects are the core of our contribution. First is our novel dataset with\nnatural pairs between human and robot poses, allowing our approach to imitate\nhumans accurately despite the gap between their anatomies. Second, the\ndiffusion input to our model alleviates the challenge of redundant joint\nconfigurations, limiting the search space. And finally, our end-to-end\narchitecture from perception to action leads to an improved learning\ncapability. Through our experimental analysis, we show that combining these\nthree aspects allows DIRIGENt to outperform existing state-of-the-art\napproaches in the field of generating joint values from RGB images.",
      "tldr_zh": "本研究提出 DIRIGENt，一种基于 diffusion model 的端到端方法，用于机器人直接模仿人类演示，从而提升教学效率。该方法通过创建一个包含人类和机器人姿势自然配对的数据集，解决了解剖结构差异问题，并利用扩散输入减少冗余关节配置的挑战，同时采用端到端架构从感知到动作提升学习能力。主要贡献包括数据集的创新、搜索空间优化和整体架构改进，实验显示 DIRIGENt 在从 RGB images 生成关节值方面超过了现有最先进方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16800v1",
      "published_date": "2025-01-28 09:05:03 UTC",
      "updated_date": "2025-01-28 09:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:13:03.501021"
    },
    {
      "arxiv_id": "2501.16783v1",
      "title": "A Stochastic Dynamical Theory of LLM Self-Adversariality: Modeling Severity Drift as a Critical Process",
      "title_zh": "大型语言模型自我对抗性的随机动力学理论：将严重度漂移建模为临界过程",
      "authors": [
        "Jack David Carson"
      ],
      "abstract": "This paper introduces a continuous-time stochastic dynamical framework for\nunderstanding how large language models (LLMs) may self-amplify latent biases\nor toxicity through their own chain-of-thought reasoning. The model posits an\ninstantaneous \"severity\" variable $x(t) \\in [0,1]$ evolving under a stochastic\ndifferential equation (SDE) with a drift term $\\mu(x)$ and diffusion\n$\\sigma(x)$. Crucially, such a process can be consistently analyzed via the\nFokker--Planck approach if each incremental step behaves nearly Markovian in\nseverity space. The analysis investigates critical phenomena, showing that\ncertain parameter regimes create phase transitions from subcritical\n(self-correcting) to supercritical (runaway severity). The paper derives\nstationary distributions, first-passage times to harmful thresholds, and\nscaling laws near critical points. Finally, it highlights implications for\nagents and extended LLM reasoning models: in principle, these equations might\nserve as a basis for formal verification of whether a model remains stable or\npropagates bias over repeated inferences.",
      "tldr_zh": "这篇论文提出一个连续时间随机动力学框架，用于解释大型语言模型(LLMs)如何通过链式思维推理自我放大潜在偏差或毒性，将其建模为severity变量$x(t)$的随机微分方程(SDE)演化过程。\n通过Fokker-Planck方法分析，该框架揭示了在特定参数条件下，系统可能从亚临界(自我修正)向超临界(失控严重性)的相变现象，并导出了平稳分布、到达有害阈值的首次通过时间以及临界点附近的缩放定律。\n最终，该理论为代理和扩展LLM推理模型提供了基础，可能用于正式验证模型是否稳定或传播偏差。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "nlin.AO"
      ],
      "primary_category": "cs.CL",
      "comment": "Experimental verification and more formal argument for Markov\n  approximation of bias propagation to be released soon. Primarily pushed now\n  to establish novelty and ease of sharing. Please do not cite this work until\n  the forthcoming experimental validation and updated mathematical model are\n  provided",
      "pdf_url": "http://arxiv.org/pdf/2501.16783v1",
      "published_date": "2025-01-28 08:08:25 UTC",
      "updated_date": "2025-01-28 08:08:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:13:16.005921"
    },
    {
      "arxiv_id": "2501.16778v1",
      "title": "FlexMotion: Lightweight, Physics-Aware, and Controllable Human Motion Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Arvin Tashakori",
        "Arash Tashakori",
        "Gongbo Yang",
        "Z. Jane Wang",
        "Peyman Servati"
      ],
      "abstract": "Lightweight, controllable, and physically plausible human motion synthesis is\ncrucial for animation, virtual reality, robotics, and human-computer\ninteraction applications. Existing methods often compromise between\ncomputational efficiency, physical realism, or spatial controllability. We\npropose FlexMotion, a novel framework that leverages a computationally\nlightweight diffusion model operating in the latent space, eliminating the need\nfor physics simulators and enabling fast and efficient training. FlexMotion\nemploys a multimodal pre-trained Transformer encoder-decoder, integrating joint\nlocations, contact forces, joint actuations and muscle activations to ensure\nthe physical plausibility of the generated motions. FlexMotion also introduces\na plug-and-play module, which adds spatial controllability over a range of\nmotion parameters (e.g., joint locations, joint actuations, contact forces, and\nmuscle activations). Our framework achieves realistic motion generation with\nimproved efficiency and control, setting a new benchmark for human motion\nsynthesis. We evaluate FlexMotion on extended datasets and demonstrate its\nsuperior performance in terms of realism, physical plausibility, and\ncontrollability.",
      "tldr_zh": "FlexMotion是一种轻量级、物理感知且可控的人类运动生成框架，它利用潜在空间中的diffusion model和多模态预训练Transformer，整合关节位置、接触力、关节驱动以及肌肉激活，以确保生成的运动物理真实性，同时无需物理模拟器，从而实现高效训练。\n该框架引入一个即插即用模块，允许对运动参数（如关节位置、关节驱动、接触力和肌肉激活）进行灵活的空间控制。\n实验结果显示，FlexMotion在扩展数据集上表现出色，在真实性、物理合理性和可控性方面超越现有方法，为动画、虚拟现实、机器人和人机交互应用设定新基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16778v1",
      "published_date": "2025-01-28 08:02:21 UTC",
      "updated_date": "2025-01-28 08:02:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:13:28.195174"
    },
    {
      "arxiv_id": "2501.17888v3",
      "title": "RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Chen",
        "Yong Zu",
        "Zhixi Feng",
        "Shuyuan Yang",
        "Mengchang Li"
      ],
      "abstract": "The growing scarcity of spectrum resources and rapid proliferation of\nwireless devices make efficient radio network management critical. While deep\nlearning-enhanced Cognitive Radio Technology (CRT) provides promising solutions\nfor tasks such as radio signal classification (RSC), denoising, and spectrum\nallocation, existing DL-based CRT frameworks are typically task-specific and\nlack scalability in diverse real-world applications. This limitation naturally\nleads to the exploration of Large Language Models (LLMs), whose exceptional\ncross-domain generalization capabilities offer new potential for advancing CRT.\nTo bridge this gap, we propose RadioLLM, a novel framework that integrates\nHybrid Prompt and Token Reprogramming (HPTR) for combining radio signal\nfeatures with expert knowledge, and a Frequency-Attuned Fusion (FAF) module for\nenhanced high-frequency feature modeling. Extensive evaluations on multiple\nbenchmark datasets demonstrate that RadioLLM achieves superior performance\ncompared to existing baselines in the majority of testing scenarios.",
      "tldr_zh": "本文研究了如何将大型语言模型（LLMs）引入认知无线电技术（CRT），以解决频谱资源短缺和无线设备激增带来的网络管理挑战。提出 RadioLLM 框架，利用 Hybrid Prompt and Token Reprogramming (HPTR) 结合无线信号特征与专家知识，并引入 Frequency-Attuned Fusion (FAF) 模块来优化高频特征建模。该框架在多个基准数据集上表现出色，超越现有基线模型，展示了 LLMs 在 CRT 任务中的跨域泛化潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "This work has been submitted to the IEEE JSAC for possible\n  publication",
      "pdf_url": "http://arxiv.org/pdf/2501.17888v3",
      "published_date": "2025-01-28 07:38:04 UTC",
      "updated_date": "2025-05-13 01:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:13:39.338220"
    },
    {
      "arxiv_id": "2501.17207v1",
      "title": "Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help?",
      "title_zh": "重新审视功能脑连接组分析：图深度学习模型有帮助吗？",
      "authors": [
        "Keqi Han",
        "Yao Su",
        "Lifang He",
        "Liang Zhan",
        "Sergey Plis",
        "Vince Calhoun",
        "Carl Yang"
      ],
      "abstract": "Functional brain connectome is crucial for deciphering the neural mechanisms\nunderlying cognitive functions and neurological disorders. Graph deep learning\nmodels have recently gained tremendous popularity in this field. However, their\nactual effectiveness in modeling the brain connectome remains unclear. In this\nstudy, we re-examine graph deep learning models based on four large-scale\nneuroimaging studies encompassing diverse cognitive and clinical outcomes.\nSurprisingly, we find that the message aggregation mechanism, a hallmark of\ngraph deep learning models, does not help with predictive performance as\ntypically assumed, but rather consistently degrades it. To address this issue,\nwe propose a hybrid model combining a linear model with a graph attention\nnetwork through dual pathways, achieving robust predictions and enhanced\ninterpretability by revealing both localized and global neural connectivity\npatterns. Our findings urge caution in adopting complex deep learning models\nfor functional brain connectome analysis, emphasizing the need for rigorous\nexperimental designs to establish tangible performance gains and perhaps more\nimportantly, to pursue improvements in model interpretability.",
      "tldr_zh": "本研究重新审视了Graph Deep Learning Models在功能脑连接体(functional brain connectome)分析中的有效性，通过四个大规模神经影像学研究发现，消息聚合机制(message aggregation mechanism)非但未提升预测性能，反而导致其下降。作者提出了一种混合模型，将线性模型与Graph Attention Network通过双路径结合，实现稳健的预测结果，并增强可解释性，揭示局部和全局神经连接模式。研究强调，在功能脑连接体分析中，应谨慎采用复杂深度学习模型，并通过严格实验设计来验证性能提升和可解释性改进。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.17207v1",
      "published_date": "2025-01-28 07:24:16 UTC",
      "updated_date": "2025-01-28 07:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:13:51.107885"
    },
    {
      "arxiv_id": "2501.16753v1",
      "title": "Overcoming Semantic Dilution in Transformer-Based Next Frame Prediction",
      "title_zh": "在基于 Transformer 的",
      "authors": [
        "Hy Nguyen",
        "Srikanth Thudumu",
        "Hung Du",
        "Rajesh Vasa",
        "Kon Mouzakis"
      ],
      "abstract": "Next-frame prediction in videos is crucial for applications such as\nautonomous driving, object tracking, and motion prediction. The primary\nchallenge in next-frame prediction lies in effectively capturing and processing\nboth spatial and temporal information from previous video sequences. The\ntransformer architecture, known for its prowess in handling sequence data, has\nmade remarkable progress in this domain. However, transformer-based next-frame\nprediction models face notable issues: (a) The multi-head self-attention (MHSA)\nmechanism requires the input embedding to be split into $N$ chunks, where $N$\nis the number of heads. Each segment captures only a fraction of the original\nembeddings information, which distorts the representation of the embedding in\nthe latent space, resulting in a semantic dilution problem; (b) These models\npredict the embeddings of the next frames rather than the frames themselves,\nbut the loss function based on the errors of the reconstructed frames, not the\npredicted embeddings -- this creates a discrepancy between the training\nobjective and the model output. We propose a Semantic Concentration Multi-Head\nSelf-Attention (SCMHSA) architecture, which effectively mitigates semantic\ndilution in transformer-based next-frame prediction. Additionally, we introduce\na loss function that optimizes SCMHSA in the latent space, aligning the\ntraining objective more closely with the model output. Our method demonstrates\nsuperior performance compared to the original transformer-based predictors.",
      "tldr_zh": "本研究针对 Transformer 模型在视频下一帧预测（next-frame prediction）中的语义稀释（semantic dilution）问题，分析了多头自注意力（MHSA）机制导致的嵌入信息扭曲，以及训练目标与模型输出不一致的挑战。作者提出了一种语义集中多头自注意力（SCMHSA）架构，通过优化输入嵌入处理来缓解语义稀释，并引入在潜在空间优化的损失函数，以更好地对齐训练目标和模型输出。实验结果显示，该方法在视频预测任务上比传统 Transformer 模型表现出色，显著提升了预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16753v1",
      "published_date": "2025-01-28 07:12:29 UTC",
      "updated_date": "2025-01-28 07:12:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:14:03.472922"
    },
    {
      "arxiv_id": "2502.20403v1",
      "title": "Adversarial Robustness of Partitioned Quantum Classifiers",
      "title_zh": "分区量子分类器的对抗鲁",
      "authors": [
        "Pouya Kananian",
        "Hans-Arno Jacobsen"
      ],
      "abstract": "Adversarial robustness in quantum classifiers is a critical area of study,\nproviding insights into their performance compared to classical models and\nuncovering potential advantages inherent to quantum machine learning. In the\nNISQ era of quantum computing, circuit cutting is a notable technique for\nsimulating circuits that exceed the qubit limitations of current devices,\nenabling the distribution of a quantum circuit's execution across multiple\nquantum processing units through classical communication. We examine how\npartitioning quantum classifiers through circuit cutting increase their\nsusceptibility to adversarial attacks, establishing a link between attacking\nthe state preparation channels in wire cutting and implementing adversarial\ngates within intermediate layers of a quantum classifier. We then proceed to\nstudy the latter problem from both a theoretical and experimental perspective.",
      "tldr_zh": "这篇论文探讨了分区量子分类器的对抗鲁棒性（adversarial robustness），比较了量子模型与经典模型的表现，并揭示了量子机器学习（quantum machine learning）的潜在优势。研究聚焦于 NISQ 时代，通过 circuit cutting 技术分区量子电路，以分布式方式在多个量子处理单元上执行，从而分析分区如何增加对对抗攻击的易受攻击性。论文建立了攻击 state preparation channels in wire cutting 与在量子分类器中间层实施 adversarial gates 的联系，并从理论和实验角度进行了深入分析。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20403v1",
      "published_date": "2025-01-28 07:10:40 UTC",
      "updated_date": "2025-01-28 07:10:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:14:15.590013"
    },
    {
      "arxiv_id": "2501.16751v3",
      "title": "HiBug2: Efficient and Interpretable Error Slice Discovery for Comprehensive Model Debugging",
      "title_zh": "翻译失败",
      "authors": [
        "Muxi Chen",
        "Chenchen Zhao",
        "Qiang Xu"
      ],
      "abstract": "Despite the significant success of deep learning models in computer vision,\nthey often exhibit systematic failures on specific data subsets, known as error\nslices. Identifying and mitigating these error slices is crucial to enhancing\nmodel robustness and reliability in real-world scenarios. In this paper, we\nintroduce HiBug2, an automated framework for error slice discovery and model\nrepair. HiBug2 first generates task-specific visual attributes to highlight\ninstances prone to errors through an interpretable and structured process. It\nthen employs an efficient slice enumeration algorithm to systematically\nidentify error slices, overcoming the combinatorial challenges that arise\nduring slice exploration. Additionally, HiBug2 extends its capabilities by\npredicting error slices beyond the validation set, addressing a key limitation\nof prior approaches. Extensive experiments across multiple domains, including\nimage classification, pose estimation, and object detection - show that HiBug2\nnot only improves the coherence and precision of identified error slices but\nalso significantly enhances the model repair capabilities.",
      "tldr_zh": "本研究引入了 HiBug2，一种高效且可解释的自动化框架，用于发现和修复深度学习模型在计算机视觉中的 error slices，这些是模型在特定数据子集上的系统性失败。HiBug2 通过生成任务特定的 visual attributes 和高效的 slice enumeration algorithm 来系统识别错误切片，同时克服组合挑战并预测验证集以外的错误切片。实验结果显示，在图像分类、姿态估计和物体检测等多个领域，HiBug2 显著提高了错误切片的连贯性和精确性，并提升了模型修复能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16751v3",
      "published_date": "2025-01-28 07:08:20 UTC",
      "updated_date": "2025-03-03 09:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:14:27.767403"
    },
    {
      "arxiv_id": "2501.16744v1",
      "title": "LLM Assisted Anomaly Detection Service for Site Reliability Engineers: Enhancing Cloud Infrastructure Resilience",
      "title_zh": "LLM 辅助的异常检测服务：针对站点可靠性工程师，增强云基础设施弹性",
      "authors": [
        "Nimesh Jha",
        "Shuxin Lin",
        "Srideepika Jayaraman",
        "Kyle Frohling",
        "Christodoulos Constantinides",
        "Dhaval Patel"
      ],
      "abstract": "This paper introduces a scalable Anomaly Detection Service with a\ngeneralizable API tailored for industrial time-series data, designed to assist\nSite Reliability Engineers (SREs) in managing cloud infrastructure. The service\nenables efficient anomaly detection in complex data streams, supporting\nproactive identification and resolution of issues. Furthermore, it presents an\ninnovative approach to anomaly modeling in cloud infrastructure by utilizing\nLarge Language Models (LLMs) to understand key components, their failure modes,\nand behaviors. A suite of algorithms for detecting anomalies is offered in\nunivariate and multivariate time series data, including regression-based,\nmixture-model-based, and semi-supervised approaches. We provide insights into\nthe usage patterns of the service, with over 500 users and 200,000 API calls in\na year. The service has been successfully applied in various industrial\nsettings, including IoT-based AI applications. We have also evaluated our\nsystem on public anomaly benchmarks to show its effectiveness. By leveraging\nit, SREs can proactively identify potential issues before they escalate,\nreducing downtime and improving response times to incidents, ultimately\nenhancing the overall customer experience. We plan to extend the system to\ninclude time series foundation models, enabling zero-shot anomaly detection\ncapabilities.",
      "tldr_zh": "这篇论文提出了一种可扩展的异常检测服务，利用 Large Language Models (LLMs) 辅助 Site Reliability Engineers (SREs) 管理云基础设施，实现对工业时间序列数据的主动异常识别和问题解决。服务提供了一系列算法，包括回归-based、mixture-model-based 和 semi-supervised 方法，支持一元和多元时间序列数据的处理，并在实际应用中吸引了超过500名用户和20万次 API 调用。实验结果显示，该系统在公共异常基准上表现出色，有效减少了停机时间并提升了响应速度。未来计划扩展到时间序列基础模型，实现零样本异常检测功能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the AAAI-2025 Deployable AI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2501.16744v1",
      "published_date": "2025-01-28 06:41:37 UTC",
      "updated_date": "2025-01-28 06:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:14:40.460248"
    },
    {
      "arxiv_id": "2501.17206v1",
      "title": "Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care",
      "title_zh": "强化学习与 AI 代理的整合，用于痴呆护理中的自适应机器人交互和辅助",
      "authors": [
        "Fengpei Yuan",
        "Nehal Hasnaeen",
        "Ran Zhang",
        "Bryce Bible",
        "Joseph Riley Taylor",
        "Hairong Qi",
        "Fenghui Yao",
        "Xiaopeng Zhao"
      ],
      "abstract": "This study explores a novel approach to advancing dementia care by\nintegrating socially assistive robotics, reinforcement learning (RL), large\nlanguage models (LLMs), and clinical domain expertise within a simulated\nenvironment. This integration addresses the critical challenge of limited\nexperimental data in socially assistive robotics for dementia care, providing a\ndynamic simulation environment that realistically models interactions between\npersons living with dementia (PLWDs) and robotic caregivers. The proposed\nframework introduces a probabilistic model to represent the cognitive and\nemotional states of PLWDs, combined with an LLM-based behavior simulation to\nemulate their responses. We further develop and train an adaptive RL system\nenabling humanoid robots, such as Pepper, to deliver context-aware and\npersonalized interactions and assistance based on PLWDs' cognitive and\nemotional states. The framework also generalizes to computer-based agents,\nhighlighting its versatility. Results demonstrate that the RL system, enhanced\nby LLMs, effectively interprets and responds to the complex needs of PLWDs,\nproviding tailored caregiving strategies. This research contributes to\nhuman-computer and human-robot interaction by offering a customizable AI-driven\ncaregiving platform, advancing understanding of dementia-related challenges,\nand fostering collaborative innovation in assistive technologies. The proposed\napproach has the potential to enhance the independence and quality of life for\nPLWDs while alleviating caregiver burden, underscoring the transformative role\nof interaction-focused AI systems in dementia care.",
      "tldr_zh": "该研究整合了强化学习 (RL)、大型语言模型 (LLMs) 和社会辅助机器人，开发了一个模拟环境来推进痴呆护理，解决实验数据有限的挑战。该框架使用概率模型模拟痴呆患者 (PLWDs) 的认知和情感状态，并结合 LLM 基于行为模拟来训练自适应 RL 系统，使机器人（如 Pepper）提供个性化、上下文感知的互动和辅助。实验结果显示，该系统能有效响应 PLWDs 的复杂需求，提供定制护理策略，并展示其通用性扩展到计算机代理。总体上，此方法提升了对痴呆相关挑战的理解，并为 AI 驱动的护理平台带来潜力，帮助改善患者独立性和生活质量，同时减轻护理负担。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.17206v1",
      "published_date": "2025-01-28 06:38:24 UTC",
      "updated_date": "2025-01-28 06:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:14:51.840357"
    },
    {
      "arxiv_id": "2501.16740v1",
      "title": "Efficient Knowledge Distillation of SAM for Medical Image Segmentation",
      "title_zh": "高效的 SAM 知识蒸馏用于医疗图像分割",
      "authors": [
        "Kunal Dasharath Patil",
        "Gowthamaan Palani",
        "Ganapathy Krishnamurthi"
      ],
      "abstract": "The Segment Anything Model (SAM) has set a new standard in interactive image\nsegmentation, offering robust performance across various tasks. However, its\nsignificant computational requirements limit its deployment in real-time or\nresource-constrained environments. To address these challenges, we propose a\nnovel knowledge distillation approach, KD SAM, which incorporates both encoder\nand decoder optimization through a combination of Mean Squared Error (MSE) and\nPerceptual Loss. This dual-loss framework captures structural and semantic\nfeatures, enabling the student model to maintain high segmentation accuracy\nwhile reducing computational complexity. Based on the model evaluation on\ndatasets, including Kvasir-SEG, ISIC 2017, Fetal Head Ultrasound, and Breast\nUltrasound, we demonstrate that KD SAM achieves comparable or superior\nperformance to the baseline models, with significantly fewer parameters. KD SAM\neffectively balances segmentation accuracy and computational efficiency, making\nit well-suited for real-time medical image segmentation applications in\nresource-constrained environments.",
      "tldr_zh": "该研究针对 Segment Anything Model (SAM) 在医疗图像分割中的高计算需求问题，提出了一种高效知识蒸馏方法 KD SAM，通过结合 Mean Squared Error (MSE) 和 Perceptual Loss 的双损失框架优化编码器和解码器，以捕捉结构和语义特征。实验在 Kvasir-SEG、ISIC 2017、Fetal Head Ultrasound 和 Breast Ultrasound 数据集上显示，KD SAM 实现了与基线模型相当或优越的分割准确性，同时显著减少了参数数量。总体而言，该方法有效平衡了准确性和计算效率，适用于资源受限的实时医疗图像分割场景。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16740v1",
      "published_date": "2025-01-28 06:33:30 UTC",
      "updated_date": "2025-01-28 06:33:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:15:04.283845"
    },
    {
      "arxiv_id": "2501.16734v2",
      "title": "Distilling Large Language Models for Network Active Queue Management",
      "title_zh": "翻译失败",
      "authors": [
        "Deol Satish",
        "Shiva Raj Pokhrel",
        "Jonathan Kua",
        "Anwar Walid"
      ],
      "abstract": "The growing complexity of network traffic and demand for ultra-low latency\ncommunication require smarter packet traffic management. Existing Deep\nLearning-based queuing approaches struggle with dynamic network scenarios and\ndemand high engineering effort. We propose AQM-LLM, distilling Large Language\nModels (LLMs) with few-shot learning, contextual understanding, and pattern\nrecognition to improve Active Queue Management (AQM) [RFC 9330] with minimal\nmanual effort. We consider a specific case where AQM is Low Latency, Low Loss,\nand Scalable Throughput (L4S) and our design of AQM-LLM builds on speculative\ndecoding and reinforcement-based distilling of LLM by tackling congestion\nprevention in the L4S architecture using Explicit Congestion Notification (ECN)\n[RFC 9331] and periodic packet dropping. We develop a new open-source\nexperimental platform by executing L4S-AQM on FreeBSD-14, providing\ninteroperable modules to support LLM integration and facilitate IETF\nrecognition through wider testing. Our extensive evaluations show L4S-LLM\nenhances queue management, prevents congestion, reduces latency, and boosts\nnetwork performance, showcasing LLMs' adaptability and efficiency in uplifting\nAQM systems.",
      "tldr_zh": "该研究提出AQM-LLM框架，通过蒸馏大语言模型(LLMs)来提升网络主动队列管理(AQM)，以应对动态流量场景下的复杂性，并减少手动工程努力。\nAQM-LLM利用少样本学习、上下文理解和模式识别，针对低延迟、低损失、可扩展吞吐量(L4S)架构，结合推测解码和强化学习蒸馏，使用显式拥塞通知(ECN)和周期性丢包来预防拥塞。\n实验评估显示，AQM-LLM显著改善了队列管理、降低了延迟、提升了网络性能，并在FreeBSD-14的开源平台上验证了其适应性和效率。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "After a careful review, we identified some issues that need to be\n  addressed. We temporarily withdraw the paper while we update our experimental\n  results, ensuring that our demonstration and findings meet the highest\n  standards of accuracy and clarity",
      "pdf_url": "http://arxiv.org/pdf/2501.16734v2",
      "published_date": "2025-01-28 06:19:29 UTC",
      "updated_date": "2025-03-04 21:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:15:16.983074"
    },
    {
      "arxiv_id": "2501.16729v2",
      "title": "On the Interplay Between Sparsity and Training in Deep Reinforcement Learning",
      "title_zh": "深度强化学习中稀疏性与训练的相互作用",
      "authors": [
        "Fatima Davelouis",
        "John D. Martin",
        "Michael Bowling"
      ],
      "abstract": "We study the benefits of different sparse architectures for deep\nreinforcement learning. In particular, we focus on image-based domains where\nspatially-biased and fully-connected architectures are common. Using these and\nseveral other architectures of equal capacity, we show that sparse structure\nhas a significant effect on learning performance. We also observe that choosing\nthe best sparse architecture for a given domain depends on whether the hidden\nlayer weights are fixed or learned.",
      "tldr_zh": "该研究探讨了稀疏性(sparsity)和训练在深度强化学习(deep reinforcement learning)中的相互作用，特别关注图像-based 领域的不同稀疏架构。作者比较了空间偏置(spatially-biased)和全连接(fully-connected)架构等等容量模型，发现稀疏结构对学习性能有显著影响。结果表明，最佳稀疏架构的选择取决于隐藏层权重是否固定还是学习(training)。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16729v2",
      "published_date": "2025-01-28 06:13:35 UTC",
      "updated_date": "2025-02-01 06:43:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:15:27.938713"
    },
    {
      "arxiv_id": "2501.16726v1",
      "title": "Bridging Neural Networks and Wireless Systems with MIMO-OFDM Semantic Communications",
      "title_zh": "翻译失败",
      "authors": [
        "Hanju Yoo",
        "Dongha Choi",
        "Yonghwi Kim",
        "Yoontae Kim",
        "Songkuk Kim",
        "Chan-Byoung Chae",
        "Robert W. Heath Jr"
      ],
      "abstract": "Semantic communications aim to enhance transmission efficiency by jointly\noptimizing source coding, channel coding, and modulation. While prior research\nhas demonstrated promising performance in simulations, real-world\nimplementations often face significant challenges, including noise variability\nand nonlinear distortions, leading to performance gaps. This article\ninvestigates these challenges in a multiple-input multiple-output (MIMO) and\northogonal frequency division multiplexing (OFDM)-based semantic communication\nsystem, focusing on the practical impacts of power amplifier (PA) nonlinearity\nand peak-to-average power ratio (PAPR) variations. Our analysis identifies\nfrequency selectivity of the actual channel as a critical factor in performance\ndegradation and demonstrates that targeted mitigation strategies can enable\nsemantic systems to approach theoretical performance. By addressing key\nlimitations in existing designs, we provide actionable insights for advancing\nsemantic communications in practical wireless environments. This work\nestablishes a foundation for bridging the gap between theoretical models and\nreal-world deployment, highlighting essential considerations for system design\nand optimization.",
      "tldr_zh": "这篇论文探讨了基于 MIMO-OFDM 的语义通信系统，旨在通过联合优化源编码、信道编码和调制来提升传输效率，同时桥接理论模型与实际无线环境的差距。研究重点分析了实际挑战，包括功率放大器（PA）非线性和峰均功率比（PAPR）变化的影响，并识别出信道频率选择性作为性能退化的关键因素。通过针对性缓解策略，论文证明语义系统可接近理论性能，并提供可操作见解以推进系统设计和优化在真实场景中的应用。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.NI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16726v1",
      "published_date": "2025-01-28 06:07:39 UTC",
      "updated_date": "2025-01-28 06:07:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:15:40.093231"
    },
    {
      "arxiv_id": "2502.15723v3",
      "title": "Balancing Content Size in RAG-Text2SQL System",
      "title_zh": "RAG-Text2SQL 系统中的内容大小平衡",
      "authors": [
        "Prakhar Gurawa",
        "Anjali Dharmik"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as a promising solution for\nconverting natural language queries into SQL commands, enabling seamless\ndatabase interaction. However, these Text-to-SQL (Text2SQL) systems face\ninherent limitations, hallucinations, outdated knowledge, and untraceable\nreasoning. To address these challenges, the integration of retrieval-augmented\ngeneration (RAG) with Text2SQL models has gained traction. RAG serves as a\nretrieval mechanism, providing essential contextual information, such as table\nschemas and metadata, to enhance the query generation process. Despite their\npotential, RAG + Text2SQL systems are susceptible to the quality and size of\nretrieved documents. While richer document content can improve schema relevance\nand retrieval accuracy, it also introduces noise, increasing the risk of\nhallucinations and reducing query fidelity as the prompt size of the Text2SQL\nmodel increases. This research investigates the nuanced trade-off between\ndocument size and quality, aiming to strike a balance that optimizes system\nperformance. Key thresholds are identified where performance degradation\noccurs, along with actionable strategies to mitigate these challenges.\nAdditionally, we explore the phenomenon of hallucinations in Text2SQL models,\nemphasizing the critical role of curated document presentation in minimizing\nerrors. Our findings provide a roadmap for enhancing the robustness of RAG +\nText2SQL systems, offering practical insights for real-world applications.",
      "tldr_zh": "这篇论文探讨了在RAG-Text2SQL系统中平衡检索文档的大小与质量，以解决Large Language Models (LLMs)在自然语言查询转SQL过程中的局限性，如幻觉、过时知识和不可追踪推理。研究通过整合retrieval-augmented generation (RAG)机制来提供上下文信息（如表结构和元数据），但强调过大的文档内容可能引入噪音，降低查询准确性和系统性能。作者识别了关键性能阈值，并提出缓解策略，包括优化文档呈现以减少幻觉现象，最终为增强RAG-Text2SQL系统的鲁棒性和实际应用提供实用路线图。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15723v3",
      "published_date": "2025-01-28 06:06:28 UTC",
      "updated_date": "2025-03-23 18:27:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:15:51.952774"
    },
    {
      "arxiv_id": "2501.16722v1",
      "title": "Hypergraph Diffusion for High-Order Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Darnbi Sakong",
        "Thanh Trung Huynh",
        "Jun Jo"
      ],
      "abstract": "Recommender systems rely on Collaborative Filtering (CF) to predict user\npreferences by leveraging patterns in historical user-item interactions. While\ntraditional CF methods primarily focus on learning compact vector embeddings\nfor users and items, graph neural network (GNN)-based approaches have emerged\nas a powerful alternative, utilizing the structure of user-item interaction\ngraphs to enhance recommendation accuracy. However, existing GNN-based models,\nsuch as LightGCN and UltraGCN, often struggle with two major limitations: an\ninability to fully account for heterophilic interactions, where users engage\nwith diverse item categories, and the over-smoothing problem in multi-layer\nGNNs, which hinders their ability to model complex, high-order relationships.\nTo address these gaps, we introduce WaveHDNN, an innovative wavelet-enhanced\nhypergraph diffusion framework. WaveHDNN integrates a Heterophily-aware\nCollaborative Encoder, designed to capture user-item interactions across\ndiverse categories, with a Multi-scale Group-wise Structure Encoder, which\nleverages wavelet transforms to effectively model localized graph structures.\nAdditionally, cross-view contrastive learning is employed to maintain robust\nand consistent representations. Experiments on benchmark datasets validate the\nefficacy of WaveHDNN, demonstrating its superior ability to capture both\nheterophilic and localized structural information, leading to improved\nrecommendation performance.",
      "tldr_zh": "本研究针对推荐系统中的协同过滤（Collaborative Filtering, CF）和图神经网络（GNN）方法存在的局限性提出WaveHDNN框架，以解决异质性交互（heterophilic interactions）和多层GNN的over-smoothing问题。WaveHDNN整合了Heterophily-aware Collaborative Encoder来捕捉用户-物品跨类别交互，以及Multi-scale Group-wise Structure Encoder利用小波变换（wavelet transforms）建模局部图结构，并通过跨视图对比学习（cross-view contrastive learning）增强表示的鲁棒性。该框架在基准数据集上的实验验证了其在捕捉高阶关系方面的优势，显著提升了推荐系统的性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2501.16722v1",
      "published_date": "2025-01-28 05:59:29 UTC",
      "updated_date": "2025-01-28 05:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:16:04.638117"
    },
    {
      "arxiv_id": "2501.16720v1",
      "title": "One Head Eight Arms: Block Matrix based Low Rank Adaptation for CLIP-based Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chunpeng Zhou",
        "Qianqian Shen",
        "Zhi Yu",
        "Jiajun Bu",
        "Haishuai Wang"
      ],
      "abstract": "Recent advancements in fine-tuning Vision-Language Foundation Models (VLMs)\nhave garnered significant attention for their effectiveness in downstream\nfew-shot learning tasks.While these recent approaches exhibits some performance\nimprovements, they often suffer from excessive training parameters and high\ncomputational costs. To address these challenges, we propose a novel Block\nmatrix-based low-rank adaptation framework, called Block-LoRA, for fine-tuning\nVLMs on downstream few-shot tasks. Inspired by recent work on Low-Rank\nAdaptation (LoRA), Block-LoRA partitions the original low-rank decomposition\nmatrix of LoRA into a series of sub-matrices while sharing all down-projection\nsub-matrices. This structure not only reduces the number of training\nparameters, but also transforms certain complex matrix multiplication\noperations into simpler matrix addition, significantly lowering the\ncomputational cost of fine-tuning. Notably, Block-LoRA enables fine-tuning CLIP\non the ImageNet few-shot benchmark using a single 24GB GPU. We also show that\nBlock-LoRA has the more tighter bound of generalization error than vanilla\nLoRA. Without bells and whistles, extensive experiments demonstrate that\nBlock-LoRA achieves competitive performance compared to state-of-the-art\nCLIP-based few-shot methods, while maintaining a low training parameters count\nand reduced computational overhead.",
      "tldr_zh": "本研究提出了一种名为 Block-LoRA 的块矩阵基于低秩适应框架，用于微调视觉语言基础模型(VLMs) 在少样本学习任务中的应用，以解决现有方法训练参数过多和计算成本高的挑战。Block-LoRA 基于 Low-Rank Adaptation (LoRA)，通过将低秩分解矩阵分区并共享所有 down-projection 子矩阵，将复杂矩阵乘法转化为简单加法，从而显著减少训练参数和计算开销。实验结果显示，Block-LoRA 能在单张 24GB GPU 上微调 CLIP，并在 ImageNet 少样本基准上实现与最先进方法相当的性能，同时具有更紧的泛化误差界。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2501.16720v1",
      "published_date": "2025-01-28 05:54:55 UTC",
      "updated_date": "2025-01-28 05:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:16:16.298947"
    },
    {
      "arxiv_id": "2501.16714v1",
      "title": "Separate Motion from Appearance: Customizing Motion via Customizing Text-to-Video Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Huijie Liu",
        "Jingyun Wang",
        "Shuai Ma",
        "Jie Hu",
        "Xiaoming Wei",
        "Guoliang Kang"
      ],
      "abstract": "Motion customization aims to adapt the diffusion model (DM) to generate\nvideos with the motion specified by a set of video clips with the same motion\nconcept. To realize this goal, the adaptation of DM should be possible to model\nthe specified motion concept, without compromising the ability to generate\ndiverse appearances. Thus, the key to solving this problem lies in how to\nseparate the motion concept from the appearance in the adaptation process of\nDM. Typical previous works explore different ways to represent and insert a\nmotion concept into large-scale pretrained text-to-video diffusion models,\ne.g., learning a motion LoRA, using latent noise residuals, etc. While those\nmethods can encode the motion concept, they also inevitably encode the\nappearance in the reference videos, resulting in weakened appearance generation\ncapability. In this paper, we follow the typical way to learn a motion LoRA to\nencode the motion concept, but propose two novel strategies to enhance\nmotion-appearance separation, including temporal attention purification (TAP)\nand appearance highway (AH). Specifically, we assume that in the temporal\nattention module, the pretrained Value embeddings are sufficient to serve as\nbasic components needed by producing a new motion. Thus, in TAP, we choose only\nto reshape the temporal attention with motion LoRAs so that Value embeddings\ncan be reorganized to produce a new motion. Further, in AH, we alter the\nstarting point of each skip connection in U-Net from the output of each\ntemporal attention module to the output of each spatial attention module.\nExtensive experiments demonstrate that compared to previous works, our method\ncan generate videos with appearance more aligned with the text descriptions and\nmotion more consistent with the reference videos.",
      "tldr_zh": "本论文提出了一种方法，用于在文本到视频扩散模型（text-to-video diffusion models）中分离运动和外观，从而实现运动定制。具体来说，该方法通过学习 motion LoRA 编码运动概念，并引入 temporal attention purification (TAP) 和 appearance highway (AH) 策略，确保运动适应过程不影响外观多样性。实验结果表明，与现有方法相比，该方法生成的视频外观更符合文本描述，而运动更一致于参考视频。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16714v1",
      "published_date": "2025-01-28 05:40:20 UTC",
      "updated_date": "2025-01-28 05:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:16:27.152025"
    },
    {
      "arxiv_id": "2501.16700v1",
      "title": "Determining Mosaic Resilience in Sugarcane Plants using Hyperspectral Images",
      "title_zh": "利用高光谱图像确定甘蔗植物的花叶病抗性",
      "authors": [
        "Ali Zia",
        "Jun Zhou",
        "Muyiwa Olayemi"
      ],
      "abstract": "Sugarcane mosaic disease poses a serious threat to the Australian sugarcane\nindustry, leading to yield losses of up to 30% in susceptible varieties.\nExisting manual inspection methods for detecting mosaic resilience are\ninefficient and impractical for large-scale application. This study introduces\na novel approach using hyperspectral imaging and machine learning to detect\nmosaic resilience by leveraging global feature representation from local\nspectral patches. Hyperspectral data were collected from eight sugarcane\nvarieties under controlled and field conditions. Local spectral patches were\nanalyzed to capture spatial and spectral variations, which were then aggregated\ninto global feature representations using a ResNet18 deep learning\narchitecture. While classical methods like Support Vector Machines struggled to\nutilize spatial-spectral relationships effectively, the deep learning model\nachieved high classification accuracy, demonstrating its capacity to identify\nmosaic resilience from fine-grained hyperspectral data. This approach enhances\nearly detection capabilities, enabling more efficient management of susceptible\nstrains and contributing to sustainable sugarcane production.",
      "tldr_zh": "本研究针对甘蔗花叶病对澳大利亚产业造成的产量损失高达30%，提出了一种使用超光谱图像和机器学习的方法来检测甘蔗的抗病性，以克服手动检测的低效问题。方法通过分析局部光谱补丁的时空谱变异，并利用ResNet18深度学习架构聚合为全局特征表示，实现高精度分类，而传统方法如Support Vector Machines则难以有效利用这些关系。实验结果显示，该方法显著提升了早期检测能力，促进对易感品种的管理和可持续甘蔗生产。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16700v1",
      "published_date": "2025-01-28 04:33:28 UTC",
      "updated_date": "2025-01-28 04:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:16:39.605875"
    },
    {
      "arxiv_id": "2501.16692v2",
      "title": "Optimizing Code Runtime Performance through Context-Aware Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Manish Acharya",
        "Yifan Zhang",
        "Kevin Leach",
        "Yu Huang"
      ],
      "abstract": "Optimizing software performance through automated code refinement offers a\npromising avenue for enhancing execution speed and efficiency. Despite recent\nadvancements in LLMs, a significant gap remains in their ability to perform\nin-depth program analysis. This study introduces AUTOPATCH, an in-context\nlearning approach designed to bridge this gap by enabling LLMs to automatically\ngenerate optimized code. Inspired by how programmers learn and apply knowledge\nto optimize software, AUTOPATCH incorporates three key components: (1) an\nanalogy-driven framework to align LLM optimization with human cognitive\nprocesses, (2) a unified approach that integrates historical code examples and\nCFG analysis for context-aware learning, and (3) an automated pipeline for\ngenerating optimized code through in-context prompting. Experimental results\ndemonstrate that AUTOPATCH achieves a 7.3% improvement in execution efficiency\nover GPT-4o across common generated executable code, highlighting its potential\nto advance automated program runtime optimization.",
      "tldr_zh": "本研究提出 AUTOPATCH，一种基于 in-context learning 的方法，帮助 LLMs 自动生成优化代码，以桥接 LLMs 在深度程序分析方面的不足。AUTOPATCH 包括三个关键组件：analogy-driven framework 用于模拟人类认知过程、整合历史代码示例和 CFG analysis 的统一方法进行上下文感知学习，以及通过 in-context prompting 的自动化代码生成管道。实验结果显示，该方法在常见生成的执行代码上比 GPT-4o 提高了 7.3% 的执行效率，展示了其在自动化软件性能优化的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16692v2",
      "published_date": "2025-01-28 04:00:35 UTC",
      "updated_date": "2025-01-29 04:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:16:51.699096"
    },
    {
      "arxiv_id": "2501.16689v2",
      "title": "MACI: Multi-Agent Collaborative Intelligence for Adaptive Reasoning and Temporal Planning",
      "title_zh": "MAC",
      "authors": [
        "Edward Y. Chang"
      ],
      "abstract": "Artificial intelligence requires deliberate reasoning, temporal awareness,\nand effective constraint management, capabilities traditional LLMs often lack\ndue to their reliance on pattern matching, limited self-verification, and\ninconsistent constraint handling. We introduce Multi-Agent Collaborative\nIntelligence (MACI), a framework comprising three key components: 1) a\nmeta-planner (MP) that identifies, formulates, and refines all roles and\nconstraints of a task (e.g., wedding planning) while generating a dependency\ngraph, with common-sense augmentation to ensure realistic and practical\nconstraints; 2) a collection of agents to facilitate planning and address\ntask-specific requirements; and 3) a run-time monitor that manages plan\nadjustments as needed. By decoupling planning from validation, maintaining\nminimal agent context, and integrating common-sense reasoning, MACI overcomes\nthe aforementioned limitations and demonstrates robust performance in two\nscheduling problems.",
      "tldr_zh": "该研究引入了 Multi-Agent Collaborative Intelligence (MACI) 框架，以解决传统 LLMs 在 deliberate reasoning、temporal awareness 和 constraint management 方面的不足。MACI 包括三个关键组件：meta-planner (MP) 用于识别任务角色、制定约束并生成依赖图，同时整合 common-sense augmentation 以确保实际性；一组代理负责规划和处理特定任务需求；以及 run-time monitor 来动态调整计划。通过解耦规划与验证、保持最小代理上下文并增强 common-sense reasoning，MACI 在两个调度问题上展示了稳健性能。",
      "categories": [
        "cs.AI",
        "F.2.2"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 19 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.16689v2",
      "published_date": "2025-01-28 03:57:22 UTC",
      "updated_date": "2025-01-29 07:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:17:03.309262"
    },
    {
      "arxiv_id": "2501.16677v1",
      "title": "Improving Interpretability and Accuracy in Neuro-Symbolic Rule Extraction Using Class-Specific Sparse Filters",
      "title_zh": "翻译失败",
      "authors": [
        "Parth Padalkar",
        "Jaeseong Lee",
        "Shiyi Wei",
        "Gopal Gupta"
      ],
      "abstract": "There has been significant focus on creating neuro-symbolic models for\ninterpretable image classification using Convolutional Neural Networks (CNNs).\nThese methods aim to replace the CNN with a neuro-symbolic model consisting of\nthe CNN, which is used as a feature extractor, and an interpretable rule-set\nextracted from the CNN itself. While these approaches provide interpretability\nthrough the extracted rule-set, they often compromise accuracy compared to the\noriginal CNN model. In this paper, we identify the root cause of this accuracy\nloss as the post-training binarization of filter activations to extract the\nrule-set. To address this, we propose a novel sparsity loss function that\nenables class-specific filter binarization during CNN training, thus minimizing\ninformation loss when extracting the rule-set. We evaluate several training\nstrategies with our novel sparsity loss, analyzing their effectiveness and\nproviding guidance on their appropriate use. Notably, we set a new benchmark,\nachieving a 9% improvement in accuracy and a 53% reduction in rule-set size on\naverage, compared to the previous SOTA, while coming within 3% of the original\nCNN's accuracy. This highlights the significant potential of interpretable\nneuro-symbolic models as viable alternatives to black-box CNNs.",
      "tldr_zh": "该研究针对神经符号模型在图像分类中的可解释性问题，指出现有方法在从 CNN 提取规则集时因后训练过滤器激活二值化而导致准确性下降。论文提出一种新颖的稀疏损失函数(sparsity loss function)，通过在 CNN 训练期间实现类特定的过滤器二值化，从而最小化信息损失并提升规则提取效率。实验结果显示，与现有最先进方法相比，该方法平均准确性提高了 9%，规则集大小减少了 53%，并接近原始 CNN 的性能水平，为可解释的神经符号模型提供了一个高效替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16677v1",
      "published_date": "2025-01-28 03:22:23 UTC",
      "updated_date": "2025-01-28 03:22:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:17:15.418965"
    },
    {
      "arxiv_id": "2501.16672v1",
      "title": "VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Chung",
        "Akshay Swaminathan",
        "Alex J. Goodell",
        "Yeasul Kim",
        "S. Momsen Reincke",
        "Lichy Han",
        "Ben Deverett",
        "Mohammad Amin Sadeghi",
        "Abdel-Badih Ariss",
        "Marc Ghanem",
        "David Seong",
        "Andrew A. Lee",
        "Caitlin E. Coombes",
        "Brad Bradshaw",
        "Mahir A. Sufian",
        "Hyo Jung Hong",
        "Teresa P. Nguyen",
        "Mohammad R. Rasouli",
        "Komal Kamra",
        "Mark A. Burbridge",
        "James C. McAvoy",
        "Roya Saffary",
        "Stephen P. Ma",
        "Dev Dash",
        "James Xie",
        "Ellen Y. Wang",
        "Clifford A. Schmiesing",
        "Nigam Shah",
        "Nima Aghaeepour"
      ],
      "abstract": "Methods to ensure factual accuracy of text generated by large language models\n(LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence\nsystem that combines retrieval-augmented generation and LLM-as-a-Judge to\nverify whether LLM-generated text is factually supported by a patient's medical\nhistory based on their electronic health record (EHR). To evaluate this system,\nwe introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course\nnarratives from discharge summaries into a set of simple statements with\nclinician annotations for whether each statement is supported by the patient's\nEHR clinical notes. Whereas highest agreement between clinicians was 88.5%,\nVeriFact achieves up to 92.7% agreement when compared to a denoised and\nadjudicated average human clinican ground truth, suggesting that VeriFact\nexceeds the average clinician's ability to fact-check text against a patient's\nmedical record. VeriFact may accelerate the development of LLM-based EHR\napplications by removing current evaluation bottlenecks.",
      "tldr_zh": "该论文提出 VeriFact 系统，一种结合检索增强生成（retrieval-augmented generation）和 LLM-as-a-Judge 的 AI 方法，用于验证 LLM 生成的临床文本是否与患者电子健康记录 (EHR) 事实相符。研究引入新数据集 VeriFact-BHC，将 Brief Hospital Course 叙述分解为简单语句，并由临床医生注解其是否受 EHR 支持。实验结果显示，VeriFact 与去噪仲裁后的平均人类临床医生基准一致性达92.7%，超过最高临床医生共识88.5%，从而加速 LLM 在 EHR 应用中的开发并解决事实验证瓶颈。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "62 pages, 5 figures, 1 table, pre-print manuscript",
      "pdf_url": "http://arxiv.org/pdf/2501.16672v1",
      "published_date": "2025-01-28 03:13:16 UTC",
      "updated_date": "2025-01-28 03:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:17:27.560740"
    },
    {
      "arxiv_id": "2501.16671v1",
      "title": "Data-Free Model-Related Attacks: Unleashing the Potential of Generative AI",
      "title_zh": "无数据模型相关攻击：释放生成式AI的潜力",
      "authors": [
        "Dayong Ye",
        "Tianqing Zhu",
        "Shang Wang",
        "Bo Liu",
        "Leo Yu Zhang",
        "Wanlei Zhou",
        "Yang Zhang"
      ],
      "abstract": "Generative AI technology has become increasingly integrated into our daily\nlives, offering powerful capabilities to enhance productivity. However, these\nsame capabilities can be exploited by adversaries for malicious purposes. While\nexisting research on adversarial applications of generative AI predominantly\nfocuses on cyberattacks, less attention has been given to attacks targeting\ndeep learning models. In this paper, we introduce the use of generative AI for\nfacilitating model-related attacks, including model extraction, membership\ninference, and model inversion. Our study reveals that adversaries can launch a\nvariety of model-related attacks against both image and text models in a\ndata-free and black-box manner, achieving comparable performance to baseline\nmethods that have access to the target models' training data and parameters in\na white-box manner. This research serves as an important early warning to the\ncommunity about the potential risks associated with generative AI-powered\nattacks on deep learning models.",
      "tldr_zh": "这篇论文探讨了 generative AI 在模型相关攻击中的应用，包括 model extraction、membership inference 和 model inversion，旨在展示其对深度学习模型的潜在威胁。研究发现，攻击者可以通过 data-free 和 black-box 方法，对图像和文本模型发起攻击，性能可与 white-box 基准方法相当，而无需访问目标模型的训练数据或参数。该工作作为早期警告，强调了 generative AI 在恶意场景中的风险，并呼吁社区加强防范。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at USENIX Security 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16671v1",
      "published_date": "2025-01-28 03:12:57 UTC",
      "updated_date": "2025-01-28 03:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:17:38.994782"
    },
    {
      "arxiv_id": "2501.16666v1",
      "title": "Federated Learning for Efficient Condition Monitoring and Anomaly Detection in Industrial Cyber-Physical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "William Marfo",
        "Deepak K. Tosh",
        "Shirley V. Moore"
      ],
      "abstract": "Detecting and localizing anomalies in cyber-physical systems (CPS) has become\nincreasingly challenging as systems grow in complexity, particularly due to\nvarying sensor reliability and node failures in distributed environments. While\nfederated learning (FL) provides a foundation for distributed model training,\nexisting approaches often lack mechanisms to address these CPS-specific\nchallenges. This paper introduces an enhanced FL framework with three key\ninnovations: adaptive model aggregation based on sensor reliability, dynamic\nnode selection for resource optimization, and Weibull-based checkpointing for\nfault tolerance. The proposed framework ensures reliable condition monitoring\nwhile tackling the computational and reliability challenges of industrial CPS\ndeployments. Experiments on the NASA Bearing and Hydraulic System datasets\ndemonstrate superior performance compared to state-of-the-art FL methods,\nachieving 99.5% AUC-ROC in anomaly detection and maintaining accuracy even\nunder node failures. Statistical validation using the Mann-Whitney U test\nconfirms significant improvements, with a p-value less than 0.05, in both\ndetection accuracy and computational efficiency across various operational\nscenarios.",
      "tldr_zh": "这篇论文提出了一种增强的 Federated Learning (FL) 框架，用于工业 Cyber-Physical Systems (CPS) 中的高效条件监控和异常检测，针对传感器可靠性和节点故障等挑战。框架的关键创新包括基于传感器可靠性的自适应模型聚合、动态节点选择以优化资源，以及 Weibull-based checkpointing 机制以提升故障容忍能力。实验结果显示，在 NASA Bearing 和 Hydraulic System 数据集上，该方法实现了 99.5% AUC-ROC 的异常检测性能，并在节点故障场景下保持高准确性，且通过 Mann-Whitney U 测试验证了显著改进（p < 0.05）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16666v1",
      "published_date": "2025-01-28 03:04:47 UTC",
      "updated_date": "2025-01-28 03:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:17:51.678968"
    },
    {
      "arxiv_id": "2501.16663v2",
      "title": "Data Duplication: A Novel Multi-Purpose Attack Paradigm in Machine Unlearning",
      "title_zh": "数据复制：机器取消学习中的一种新型多用途攻击范式",
      "authors": [
        "Dayong Ye",
        "Tianqing Zhu",
        "Jiayang Li",
        "Kun Gao",
        "Bo Liu",
        "Leo Yu Zhang",
        "Wanlei Zhou",
        "Yang Zhang"
      ],
      "abstract": "Duplication is a prevalent issue within datasets. Existing research has\ndemonstrated that the presence of duplicated data in training datasets can\nsignificantly influence both model performance and data privacy. However, the\nimpact of data duplication on the unlearning process remains largely\nunexplored. This paper addresses this gap by pioneering a comprehensive\ninvestigation into the role of data duplication, not only in standard machine\nunlearning but also in federated and reinforcement unlearning paradigms.\nSpecifically, we propose an adversary who duplicates a subset of the target\nmodel's training set and incorporates it into the training set. After training,\nthe adversary requests the model owner to unlearn this duplicated subset, and\nanalyzes the impact on the unlearned model. For example, the adversary can\nchallenge the model owner by revealing that, despite efforts to unlearn it, the\ninfluence of the duplicated subset remains in the model. Moreover, to\ncircumvent detection by de-duplication techniques, we propose three novel\nnear-duplication methods for the adversary, each tailored to a specific\nunlearning paradigm. We then examine their impacts on the unlearning process\nwhen de-duplication techniques are applied. Our findings reveal several crucial\ninsights: 1) the gold standard unlearning method, retraining from scratch,\nfails to effectively conduct unlearning under certain conditions; 2) unlearning\nduplicated data can lead to significant model degradation in specific\nscenarios; and 3) meticulously crafted duplicates can evade detection by\nde-duplication methods.",
      "tldr_zh": "这篇论文探讨了数据重复（data duplication）对机器无学习（machine unlearning）的影响，提出了一种新型多用途攻击范式，适用于标准、联邦和强化无学习范式。研究中，攻击者通过复制目标模型训练集子集并加入训练集，随后请求无学习，并分析其对模型的影响；同时，引入三种近重复（near-duplication）方法以规避去重（de-duplication）技术。关键发现包括：从零开始重新训练（retraining from scratch）在某些条件下无法有效进行无学习、无学习重复数据可能导致模型显著退化，且精心设计的重复能逃避检测。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at USENIX Security 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16663v2",
      "published_date": "2025-01-28 02:52:51 UTC",
      "updated_date": "2025-03-11 04:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:18:03.786633"
    },
    {
      "arxiv_id": "2501.16662v2",
      "title": "Vision-based autonomous structural damage detection using data-driven methods",
      "title_zh": "基于视觉的自主结构损伤检测：利用数据驱动方法",
      "authors": [
        "Seyyed Taghi Ataei",
        "Parviz Mohammad Zadeh",
        "Saeid Ataei"
      ],
      "abstract": "This study addresses the urgent need for efficient and accurate damage\ndetection in wind turbine structures, a crucial component of renewable energy\ninfrastructure. Traditional inspection methods, such as manual assessments and\nnon-destructive testing (NDT), are often costly, time-consuming, and prone to\nhuman error. To tackle these challenges, this research investigates advanced\ndeep learning algorithms for vision-based structural health monitoring (SHM). A\ndataset of wind turbine surface images, featuring various damage types and\npollution, was prepared and augmented for enhanced model training. Three\nalgorithms-YOLOv7, its lightweight variant, and Faster R-CNN- were employed to\ndetect and classify surface damage. The models were trained and evaluated on a\ndataset split into training, testing, and evaluation subsets (80%-10%-10%).\nResults indicate that YOLOv7 outperformed the others, achieving 82.4% mAP@50\nand high processing speed, making it suitable for real-time inspections. By\noptimizing hyperparameters like learning rate and batch size, the models'\naccuracy and efficiency improved further. YOLOv7 demonstrated significant\nadvancements in detection precision and execution speed, especially for\nreal-time applications. However, challenges such as dataset limitations and\nenvironmental variability were noted, suggesting future work on segmentation\nmethods and larger datasets. This research underscores the potential of\nvision-based deep learning techniques to transform SHM practices by reducing\ncosts, enhancing safety, and improving reliability, thus contributing to the\nsustainable maintenance of critical infrastructure and supporting the longevity\nof wind energy systems.",
      "tldr_zh": "本研究针对风力涡轮机结构的损伤检测问题，提出了一种基于视觉的自主检测方法，使用数据驱动的深度学习算法来克服传统方法（如手动评估和非破坏性测试）的成本高和易出错缺点。通过准备并增强包含各种损伤类型和污染的图像数据集，研究比较了 YOLOv7、其轻量版和 Faster R-CNN 算法，结果显示 YOLOv7 表现出色，达到 82.4% mAP@50 的检测精度和高处理速度，适用于实时结构健康监测 (SHM)。此外，通过优化学习率和批量大小，进一步提升了模型的准确性和效率，尽管存在数据集限制和环境变异性等挑战，但这项工作为降低维护成本、提高安全性和可靠性提供了重要贡献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "68A00 (Primary), 68C02 (Secondary)"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 8 figures. This study examines advanced deep learning\n  algorithms, specifically YOLOv7, for efficient and accurate damage detection\n  in wind turbine structures. It significantly enhances detection precision and\n  speed for real-time inspections",
      "pdf_url": "http://arxiv.org/pdf/2501.16662v2",
      "published_date": "2025-01-28 02:52:04 UTC",
      "updated_date": "2025-01-30 18:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:18:16.899045"
    },
    {
      "arxiv_id": "2501.16658v1",
      "title": "Contextual Reinforcement in Multimodal Token Compression for Large Language Models",
      "title_zh": "多模态令牌压缩中的上下文强化，用于大语言模型",
      "authors": [
        "Naderdel Piero",
        "Zacharias Cromwell",
        "Nathaniel Wainwright",
        "Matthias Nethercott"
      ],
      "abstract": "Effective token compression remains a critical challenge for scaling models\nto handle increasingly complex and diverse datasets. A novel mechanism based on\ncontextual reinforcement is introduced, dynamically adjusting token importance\nthrough interdependencies and semantic relevance. This approach enables\nsubstantial reductions in token usage while preserving the quality and\ncoherence of information representation. Incorporating graph-based algorithms\nand adaptive weighting, the method captures subtle contextual relationships\nacross textual and multimodal data, ensuring robust alignment and performance\nin downstream tasks. Evaluations across varied domains reveal significant\nimprovements in accuracy and semantic retention, particularly for tasks\nrequiring detailed cross-modal interactions. Memory usage analyses demonstrate\nimproved computational efficiency, with minimal overhead despite the additional\nreinforcement processes. Performance gains are further validated through error\ndistribution analyses, showing reduced semantic loss and syntactic\ninconsistencies compared to baseline models. The modular architecture ensures\ncompatibility with a wide range of open-source frameworks, facilitating\nscalable implementation for real-world applications. These findings highlight\nthe potential of contextual reinforcement in redefining token management\nstrategies and advancing large-scale model design.",
      "tldr_zh": "这篇论文提出了一种基于 contextual reinforcement 的新机制，用于大型语言模型的多模态 token compression，通过动态调整 token 的重要性来利用 interdependencies 和 semantic relevance，从而显著减少 token 使用同时保持信息表示的质量和连贯性。该方法整合 graph-based algorithms 和 adaptive weighting，以捕捉文本与多模态数据间的细微上下文关系，确保在下游任务中的鲁棒性能。实验评估显示，该机制在各种领域提高了准确性和语义保留，尤其在跨模态交互任务中，并改善了计算效率，减少了语义损失和语法不一致，同时其模块化架构便于与开源框架兼容，实现大规模应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16658v1",
      "published_date": "2025-01-28 02:44:31 UTC",
      "updated_date": "2025-01-28 02:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:18:27.639960"
    },
    {
      "arxiv_id": "2501.16655v1",
      "title": "Large Language Model Critics for Execution-Free Evaluation of Code Changes",
      "title_zh": "翻译失败",
      "authors": [
        "Aashish Yadavally",
        "Hoan Nguyen",
        "Laurent Callot",
        "Gauthier Guinet"
      ],
      "abstract": "Large language models (LLMs) offer a promising way forward for automating\nsoftware engineering tasks, such as bug fixes, feature additions, etc., via\nmulti-step LLM-based agentic workflows. However, existing metrics for\nevaluating such workflows, mainly build status and occasionally log analysis,\nare too sparse and limited in providing the information needed to assess the\nquality of changes made. In this work, we designed LLM-based critics to derive\nwell-structured and rigorous intermediate/step-level, execution-free evaluation\nproxies for repo-level code changes. Importantly, we assume access to the gold\ntest patch for the problem (i.e., reference-aware) to assess both semantics and\nexecutability of generated patches. With the gold test patch as a reference, we\npredict executability of all editing locations with an F1 score of 91.6%,\naggregating which, we can predict the build status in 84.8% of the instances in\nSWE-bench. In particular, such an execution-focused LLM critic outperforms\nother reference-free and reference-aware LLM critics by 38.9% to 72.5%.\nMoreover, we demonstrate the usefulness of such a reference-aware framework in\ncomparing patches generated by different agentic workflows. Finally, we\nopen-source the library developed for this project, which allows further usage\nfor either other agentic workflows or other benchmarks. The source code is\navailable at https://github.com/amazon-science/code-agent-eval.",
      "tldr_zh": "该论文提出了一种基于 Large Language Models (LLMs) 的批评者框架，用于无需实际执行代码即可评估代码变更的质量，解决了现有指标（如构建状态）过于稀疏的问题。该框架采用参考感知方法（假设有金标准测试补丁），通过预测编辑位置的可执行性，实现了91.6%的F1分数，并在SWE-bench基准上预测构建状态的准确率达84.8%，比其他批评者高出38.9%至72.5%。此外，该方法有助于比较不同代理工作流生成的补丁，并开源了代码库（https://github.com/amazon-science/code-agent-eval），以支持进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16655v1",
      "published_date": "2025-01-28 02:38:56 UTC",
      "updated_date": "2025-01-28 02:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:18:39.825300"
    },
    {
      "arxiv_id": "2501.16652v1",
      "title": "Molecular-driven Foundation Model for Oncologic Pathology",
      "title_zh": "分子驱动的基础模型用于肿瘤病理学",
      "authors": [
        "Anurag Vaidya",
        "Andrew Zhang",
        "Guillaume Jaume",
        "Andrew H. Song",
        "Tong Ding",
        "Sophia J. Wagner",
        "Ming Y. Lu",
        "Paul Doucet",
        "Harry Robertson",
        "Cristina Almagro-Perez",
        "Richard J. Chen",
        "Dina ElHarouni",
        "Georges Ayoub",
        "Connor Bossi",
        "Keith L. Ligon",
        "Georg Gerber",
        "Long Phi Le",
        "Faisal Mahmood"
      ],
      "abstract": "Foundation models are reshaping computational pathology by enabling transfer\nlearning, where models pre-trained on vast datasets can be adapted for\ndownstream diagnostic, prognostic, and therapeutic response tasks. Despite\nthese advances, foundation models are still limited in their ability to encode\nthe entire gigapixel whole-slide images without additional training and often\nlack complementary multimodal data. Here, we introduce Threads, a slide-level\nfoundation model capable of generating universal representations of whole-slide\nimages of any size. Threads was pre-trained using a multimodal learning\napproach on a diverse cohort of 47,171 hematoxylin and eosin (H&E)-stained\ntissue sections, paired with corresponding genomic and transcriptomic profiles\n- the largest such paired dataset to be used for foundation model development\nto date. This unique training paradigm enables Threads to capture the tissue's\nunderlying molecular composition, yielding powerful representations applicable\nto a wide array of downstream tasks. In extensive benchmarking across 54\noncology tasks, including clinical subtyping, grading, mutation prediction,\nimmunohistochemistry status determination, treatment response prediction, and\nsurvival prediction, Threads outperformed all baselines while demonstrating\nremarkable generalizability and label efficiency. It is particularly well\nsuited for predicting rare events, further emphasizing its clinical utility. We\nintend to make the model publicly available for the broader community.",
      "tldr_zh": "本研究引入了Threads，一种分子驱动的肿瘤病理学Foundation Model，能够生成任何大小的全滑块图像的通用表示，而无需额外训练。Threads通过多模态学习方法，在47,171个配对的hematoxylin and eosin (H&E)染色组织切片及其基因组和转录组数据上进行预训练，从而捕捉组织的分子组成。实验结果显示，在54个肿瘤学任务（如临床亚型、突变预测和生存预测）上的基准测试中，Threads优于所有基线模型，展现出卓越的泛化性、标签效率和对稀有事件的预测能力，并计划公开模型以供社区使用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16652v1",
      "published_date": "2025-01-28 02:35:02 UTC",
      "updated_date": "2025-01-28 02:35:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:18:51.494943"
    },
    {
      "arxiv_id": "2501.16650v1",
      "title": "DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zeping Min",
        "Xinshang Wang"
      ],
      "abstract": "We introduce a novel index, the Distribution of Cosine Similarity (DOCS), for\nquantitatively assessing the similarity between weight matrices in Large\nLanguage Models (LLMs), aiming to facilitate the analysis of their complex\narchitectures. Leveraging DOCS, our analysis uncovers intriguing patterns in\nthe latest open-source LLMs: adjacent layers frequently exhibit high weight\nsimilarity and tend to form clusters, suggesting depth-wise functional\nspecialization. Additionally, we prove that DOCS is theoretically effective in\nquantifying similarity for orthogonal matrices, a crucial aspect given the\nprevalence of orthogonal initializations in LLMs. This research contributes to\na deeper understanding of LLM architecture and behavior, offering tools with\npotential implications for developing more efficient and interpretable models.",
      "tldr_zh": "本文提出了一种新指标 DOCS（Distribution of Cosine Similarity），用于量化 Large Language Models (LLMs) 中权重矩阵的相似度，从而深入分析其复杂架构。通过对最新开源 LLMs 的分析，DOCS 揭示了相邻层的高相似度模式和集群形成，这表明模型在深度方向上存在功能专业化。此外，研究证明 DOCS 在量化正交矩阵相似度方面理论上有效，为开发更高效和可解释的 LLMs 模型提供了潜在工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16650v1",
      "published_date": "2025-01-28 02:32:49 UTC",
      "updated_date": "2025-01-28 02:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:19:03.356588"
    },
    {
      "arxiv_id": "2501.16643v2",
      "title": "An LLM Benchmark for Addressee Recognition in Multi-modal Multi-party Dialogue",
      "title_zh": "多模态多方对话中",
      "authors": [
        "Koji Inoue",
        "Divesh Lala",
        "Mikey Elmers",
        "Keiko Ochi",
        "Tatsuya Kawahara"
      ],
      "abstract": "Handling multi-party dialogues represents a significant step for advancing\nspoken dialogue systems, necessitating the development of tasks specific to\nmulti-party interactions. To address this challenge, we are constructing a\nmulti-modal multi-party dialogue corpus of triadic (three-participant)\ndiscussions. This paper focuses on the task of addressee recognition,\nidentifying who is being addressed to take the next turn, a critical component\nunique to multi-party dialogue systems. A subset of the corpus was annotated\nwith addressee information, revealing that explicit addressees are indicated in\napproximately 20% of conversational turns. To evaluate the task's complexity,\nwe benchmarked the performance of a large language model (GPT-4o) on addressee\nrecognition. The results showed that GPT-4o achieved an accuracy only\nmarginally above chance, underscoring the challenges of addressee recognition\nin multi-party dialogue. These findings highlight the need for further research\nto enhance the capabilities of large language models in understanding and\nnavigating the intricacies of multi-party conversational dynamics.",
      "tldr_zh": "该论文构建了一个多模态多方对话语料库，专注于addressee recognition任务，即识别多方对话中谁被地址以接管下一个回合，这对提升对话系统至关重要。研究者标注了语料库子集，发现约20%的对话回合有显式收件人，并使用LLM（GPT-4o）进行基准测试。结果显示，GPT-4o的准确率仅略高于随机猜测，突显了多方对话复杂性，并呼吁进一步研究以提升LLM在多方互动中的理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted for presentation at International\n  Workshop on Spoken Dialogue Systems Technology 2025 (IWSDS 2025) and\n  represents the author's version of the work",
      "pdf_url": "http://arxiv.org/pdf/2501.16643v2",
      "published_date": "2025-01-28 02:27:55 UTC",
      "updated_date": "2025-03-18 06:39:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:19:15.421943"
    },
    {
      "arxiv_id": "2501.16635v2",
      "title": "Why Do We Laugh? Annotation and Taxonomy Generation for Laughable Contexts in Spontaneous Text Conversation",
      "title_zh": "为什么我们会笑？：自发文本对话中可笑语",
      "authors": [
        "Koji Inoue",
        "Mikey Elmers",
        "Divesh Lala",
        "Tatsuya Kawahara"
      ],
      "abstract": "Laughter serves as a multifaceted communicative signal in human interaction,\nyet its identification within dialogue presents a significant challenge for\nconversational AI systems. This study addresses this challenge by annotating\nlaughable contexts in Japanese spontaneous text conversation data and\ndeveloping a taxonomy to classify the underlying reasons for such contexts.\nInitially, multiple annotators manually labeled laughable contexts using a\nbinary decision (laughable or non-laughable). Subsequently, an LLM was used to\ngenerate explanations for the binary annotations of laughable contexts, which\nwere then categorized into a taxonomy comprising ten categories, including\n\"Empathy and Affinity\" and \"Humor and Surprise,\" highlighting the diverse range\nof laughter-inducing scenarios. The study also evaluated GPT-4o's performance\nin recognizing the majority labels of laughable contexts, achieving an F1 score\nof 43.14%. These findings contribute to the advancement of conversational AI by\nestablishing a foundation for more nuanced recognition and generation of\nlaughter, ultimately fostering more natural and engaging human-AI interactions.",
      "tldr_zh": "本研究探讨笑声在人类互动中的多面性，通过对日语自发文本对话数据进行二元标注（笑声上下文或非笑声上下文），并使用LLM生成解释后分类成一个包含十个类别的分类法，如\"Empathy and Affinity\"和\"Humor and Surprise\"，以识别笑声诱发原因。实验评估显示，GPT-4o在识别笑声上下文时的F1 score为43.14%，突显了当前AI的挑战。该工作为对话AI的笑声识别和生成奠定基础，促进更自然的人机互动。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted for presentation at International\n  Workshop on Spoken Dialogue Systems Technology 2025 (IWSDS 2025) and\n  represents the author's version of the work",
      "pdf_url": "http://arxiv.org/pdf/2501.16635v2",
      "published_date": "2025-01-28 02:16:18 UTC",
      "updated_date": "2025-03-18 11:50:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:19:28.518797"
    },
    {
      "arxiv_id": "2501.16634v3",
      "title": "Towards Resource-Efficient Compound AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Gohar Irfan Chaudhry",
        "Esha Choukse",
        "Íñigo Goiri",
        "Rodrigo Fonseca",
        "Adam Belay",
        "Ricardo Bianchini"
      ],
      "abstract": "Compound AI Systems, integrating multiple interacting components like models,\nretrievers, and external tools, have emerged as essential for addressing\ncomplex AI tasks. However, current implementations suffer from inefficient\nresource utilization due to tight coupling between application logic and\nexecution details, a disconnect between orchestration and resource management\nlayers, and the perceived exclusiveness between efficiency and quality.\n  We propose a vision for resource-efficient Compound AI Systems through a\ndeclarative workflow programming model and an adaptive runtime system for\ndynamic scheduling and resource-aware decision-making. Decoupling application\nlogic from low-level details exposes levers for the runtime to flexibly\nconfigure the execution environment and resources, without compromising on\nquality. Enabling collaboration between the workflow orchestration and cluster\nmanager enables higher efficiency through better scheduling and resource\nmanagement.\n  We are building a prototype system, called Murakkab, to realize this vision.\nOur preliminary evaluation demonstrates speedups up to $\\sim 3.4\\times$ in\nworkflow completion times while delivering $\\sim 4.5\\times$ higher energy\nefficiency, showing promise in optimizing resources and advancing AI system\ndesign.",
      "tldr_zh": "该研究针对 Compound AI Systems 的资源利用效率问题，提出了一种愿景，通过声明式工作流编程模型和自适应运行时系统来解耦应用逻辑与执行细节，并实现动态调度和资源感知决策，从而在不牺牲质量的情况下提升效率。论文强调了工作流编排与集群管理器之间的协作，以优化资源管理。研究团队构建了名为 Murakkab 的原型系统，初步评估显示其工作流完成时间加快约 3.4 倍，能源效率提高约 4.5 倍，为高效的 AI 系统设计提供了新途径。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16634v3",
      "published_date": "2025-01-28 02:15:34 UTC",
      "updated_date": "2025-03-17 20:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:19:39.268727"
    },
    {
      "arxiv_id": "2501.16627v1",
      "title": "Engaging with AI: How Interface Design Shapes Human-AI Collaboration in High-Stakes Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Zichen Chen",
        "Yunhao Luo",
        "Misha Sra"
      ],
      "abstract": "As reliance on AI systems for decision-making grows, it becomes critical to\nensure that human users can appropriately balance trust in AI suggestions with\ntheir own judgment, especially in high-stakes domains like healthcare. However,\nhuman + AI teams have been shown to perform worse than AI alone, with evidence\nindicating automation bias as the reason for poorer performance, particularly\nbecause humans tend to follow AI's recommendations even when they are\nincorrect. In many existing human + AI systems, decision-making support is\ntypically provided in the form of text explanations (XAI) to help users\nunderstand the AI's reasoning. Since human decision-making often relies on\nSystem 1 thinking, users may ignore or insufficiently engage with the\nexplanations, leading to poor decision-making. Previous research suggests that\nthere is a need for new approaches that encourage users to engage with the\nexplanations and one proposed method is the use of cognitive forcing functions\n(CFFs). In this work, we examine how various decision-support mechanisms impact\nuser engagement, trust, and human-AI collaborative task performance in a\ndiabetes management decision-making scenario. In a controlled experiment with\n108 participants, we evaluated the effects of six decision-support mechanisms\nsplit into two categories of explanations (text, visual) and four CFFs. Our\nfindings reveal that mechanisms like AI confidence levels, text explanations,\nand performance visualizations enhanced human-AI collaborative task\nperformance, and improved trust when AI reasoning clues were provided.\nMechanisms like human feedback and AI-driven questions encouraged deeper\nreflection but often reduced task performance by increasing cognitive effort,\nwhich in turn affected trust. Simple mechanisms like visual explanations had\nlittle effect on trust, highlighting the importance of striking a balance in\nCFF and XAI design.",
      "tldr_zh": "这篇论文探讨了界面设计如何影响人类与 AI 在高风险决策（如医疗领域）中的协作，强调了自动化偏差（automation bias）导致人类过度依赖 AI 建议的问题。研究通过一项控制实验，涉及 108 名参与者测试六种决策支持机制，包括文本解释（XAI）、视觉解释和认知强制函数（CFFs）。结果显示，AI 置信水平、文本解释和性能可视化机制提升了协作任务性能和信任，而人类反馈及 AI 驱动问题虽促进了深度反思，但增加了认知负担并降低了性能，突出了在 CFF 和 XAI 设计中需实现平衡的重要性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "36 pages, 6 figures, 6 tables. Preprint version",
      "pdf_url": "http://arxiv.org/pdf/2501.16627v1",
      "published_date": "2025-01-28 02:03:00 UTC",
      "updated_date": "2025-01-28 02:03:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:19:52.247781"
    },
    {
      "arxiv_id": "2501.16621v1",
      "title": "Chinese Stock Prediction Based on a Multi-Modal Transformer Framework: Macro-Micro Information Fusion",
      "title_zh": "基于多模态 Transformer 框架的中国股票预测：宏观-微观信息融合",
      "authors": [
        "Lumen AI",
        "Tengzhou No. 1 Middle School",
        "Shihao Ji",
        "Zihui Song",
        "Fucheng Zhong",
        "Jisen Jia",
        "Zhaobo Wu",
        "Zheyi Cao",
        "Xu Tianhao"
      ],
      "abstract": "This paper proposes an innovative Multi-Modal Transformer framework\n(MMF-Trans) designed to significantly improve the prediction accuracy of the\nChinese stock market by integrating multi-source heterogeneous information\nincluding macroeconomy, micro-market, financial text, and event knowledge. The\nframework consists of four core modules: (1) A four-channel parallel encoder\nthat processes technical indicators, financial text, macro data, and event\nknowledge graph respectively for independent feature extraction of multi-modal\ndata; (2) A dynamic gated cross-modal fusion mechanism that adaptively learns\nthe importance of different modalities through differentiable weight allocation\nfor effective information integration; (3) A time-aligned mixed-frequency\nprocessing layer that uses an innovative position encoding method to\neffectively fuse data of different time frequencies and solves the time\nalignment problem of heterogeneous data; (4) A graph attention-based event\nimpact quantification module that captures the dynamic impact of events on the\nmarket through event knowledge graph and quantifies the event impact\ncoefficient. We introduce a hybrid-frequency Transformer and Event2Vec\nalgorithm to effectively fuse data of different frequencies and quantify the\nevent impact. Experimental results show that in the prediction task of CSI 300\nconstituent stocks, the root mean square error (RMSE) of the MMF-Trans\nframework is reduced by 23.7% compared to the baseline model, the event\nresponse prediction accuracy is improved by 41.2%, and the Sharpe ratio is\nimproved by 32.6%.",
      "tldr_zh": "本论文提出了一种创新的 Multi-Modal Transformer 框架（MMF-Trans），旨在通过融合宏观经济、微观市场、金融文本和事件知识等多源异构信息，提高中国股票市场的预测准确性。该框架包括四个核心模块：四通道并行编码器进行多模态特征提取、动态门控跨模态融合机制自适应整合信息、时间对齐混合频率处理层解决异构数据时间问题，以及图注意力-based 事件影响量化模块通过 Event2Vec 算法捕捉事件动态影响。实验结果显示，在 CSI 300 成分股预测任务中，MMF-Trans 与基线模型相比，RMSE 降低了 23.7%，事件响应预测准确率提高了 41.2%，Sharpe ratio 也提升了 32.6%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16621v1",
      "published_date": "2025-01-28 01:39:35 UTC",
      "updated_date": "2025-01-28 01:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:20:04.451782"
    },
    {
      "arxiv_id": "2501.16613v1",
      "title": "Safe Reinforcement Learning for Real-World Engine Control",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Bedei",
        "Lucas Koch",
        "Kevin Badalian",
        "Alexander Winkler",
        "Patrick Schaber",
        "Jakob Andert"
      ],
      "abstract": "This work introduces a toolchain for applying Reinforcement Learning (RL),\nspecifically the Deep Deterministic Policy Gradient (DDPG) algorithm, in\nsafety-critical real-world environments. As an exemplary application, transient\nload control is demonstrated on a single-cylinder internal combustion engine\ntestbench in Homogeneous Charge Compression Ignition (HCCI) mode, that offers\nhigh thermal efficiency and low emissions. However, HCCI poses challenges for\ntraditional control methods due to its nonlinear, autoregressive, and\nstochastic nature. RL provides a viable solution, however, safety concerns,\nsuch as excessive pressure rise rates, must be addressed when applying to HCCI.\nA single unsuitable control input can severely damage the engine or cause\nmisfiring and shut down. Additionally, operating limits are not known a priori\nand must be determined experimentally. To mitigate these risks, real-time\nsafety monitoring based on the k-nearest neighbor algorithm is implemented,\nenabling safe interaction with the testbench. The feasibility of this approach\nis demonstrated as the RL agent learns a control policy through interaction\nwith the testbench. A root mean square error of 0.1374 bar is achieved for the\nindicated mean effective pressure, comparable to neural network-based\ncontrollers from the literature. The toolchain's flexibility is further\ndemonstrated by adapting the agent's policy to increase ethanol energy shares,\npromoting renewable fuel use while maintaining safety. This RL approach\naddresses the longstanding challenge of applying RL to safety-critical\nreal-world environments. The developed toolchain, with its adaptability and\nsafety mechanisms, paves the way for future applicability of RL in engine\ntestbenches and other safety-critical settings.",
      "tldr_zh": "本研究开发了一个工具链，使用 Deep Deterministic Policy Gradient (DDPG) 算法的 Reinforcement Learning (RL) 来处理安全关键的真实世界引擎控制问题，特别应用于 Homogeneous Charge Compression Ignition (HCCI) 模式的单缸内燃机瞬态负载控制，以应对其非线性、自回归和随机特性。针对安全风险，如过高的压力上升率，该工具链引入了基于 k-nearest neighbor 算法的实时安全监控，确保RL代理在互动中安全学习控制策略。实验结果显示，RL代理实现了0.1374 bar的根均方误差，与文献中神经网络控制器相当，并展示了灵活性，如适应增加乙醇能量份额以推广可再生燃料使用，从而为RL在类似安全关键环境中的应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16613v1",
      "published_date": "2025-01-28 01:19:05 UTC",
      "updated_date": "2025-01-28 01:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:20:17.349728"
    },
    {
      "arxiv_id": "2501.16609v3",
      "title": "CowPilot: A Framework for Autonomous and Human-Agent Collaborative Web Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Faria Huq",
        "Zora Zhiruo Wang",
        "Frank F. Xu",
        "Tianyue Ou",
        "Shuyan Zhou",
        "Jeffrey P. Bigham",
        "Graham Neubig"
      ],
      "abstract": "While much work on web agents emphasizes the promise of autonomously\nperforming tasks on behalf of users, in reality, agents often fall short on\ncomplex tasks in real-world contexts and modeling user preference. This\npresents an opportunity for humans to collaborate with the agent and leverage\nthe agent's capabilities effectively. We propose CowPilot, a framework\nsupporting autonomous as well as human-agent collaborative web navigation, and\nevaluation across task success and task efficiency. CowPilot reduces the number\nof steps humans need to perform by allowing agents to propose next steps, while\nusers are able to pause, reject, or take alternative actions. During execution,\nusers can interleave their actions with the agent by overriding suggestions or\nresuming agent control when needed. We conducted case studies on five common\nwebsites and found that the human-agent collaborative mode achieves the highest\nsuccess rate of 95% while requiring humans to perform only 15.2% of the total\nsteps. Even with human interventions during task execution, the agent\nsuccessfully drives up to half of task success on its own. CowPilot can serve\nas a useful tool for data collection and agent evaluation across websites,\nwhich we believe will enable research in how users and agents can work\ntogether. Video demonstrations are available at\nhttps://oaishi.github.io/cowpilot.html",
      "tldr_zh": "本文提出 CowPilot 框架，支持自主和人类-代理协作的 web navigation，以解决现有代理在复杂任务和用户偏好上的不足。框架允许代理提出下一步建议，用户可随时暂停、拒绝或覆盖行动，实现高效协作。在五个常见网站的案例研究中，协作模式成功率达 95%，人类只需执行总步骤的 15.2%，而代理自身可驱动一半的任务成功。CowPilot 作为数据收集和代理评估工具，有望推动用户与代理协作研究的进展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2501.16609v3",
      "published_date": "2025-01-28 00:56:53 UTC",
      "updated_date": "2025-04-05 23:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:20:27.709935"
    },
    {
      "arxiv_id": "2501.16607v1",
      "title": "MCTS-SQL: An Effective Framework for Text-to-SQL with Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Shuozhi Yuan",
        "Liming Chen",
        "Miaomiao Yuan",
        "Jin Zhao",
        "Haoran Peng",
        "Wenming Guo"
      ],
      "abstract": "Text-to-SQL is a fundamental and longstanding problem in the NLP area, aiming\nat converting natural language queries into SQL, enabling non-expert users to\noperate databases. Recent advances in LLM have greatly improved text-to-SQL\nperformance. However, challenges persist, especially when dealing with complex\nuser queries. Current approaches (e.g., COT prompting and multi-agent\nframeworks) rely on the ability of models to plan and generate SQL\nautonomously, but controlling performance remains difficult. In addition, LLMs\nare still prone to hallucinations. To alleviate these challenges, we designed a\nnovel MCTS-SQL to guide SQL generation iteratively. The approach generates SQL\nqueries through Monte Carlo Tree Search (MCTS) and a heuristic self-refinement\nmechanism are used to enhance accuracy and reliability. Key components include\na schema selector for extracting relevant information and an MCTS-based\ngenerator for iterative query refinement. Experimental results from the SPIDER\nand BIRD benchmarks show that MCTS-SQL achieves state-of-the-art performance.\nSpecifically, on the BIRD development dataset, MCTS-SQL achieves an Execution\n(EX) accuracy of 69.40% using GPT-4o as the base model and a significant\nimprovement when dealing with challenging tasks, with an EX of 51.48%, which is\n3.41% higher than the existing method.",
      "tldr_zh": "该论文提出MCTS-SQL框架，利用Monte Carlo Tree Search (MCTS)来指导Text-to-SQL任务的迭代生成，旨在解决大型语言模型(LLM)在处理复杂查询时面临的幻觉和性能控制问题。框架包括schema selector用于提取相关数据库信息，以及MCTS-based generator结合启发式自精炼机制来逐步优化SQL查询。实验结果显示，在SPIDER和BIRD基准测试中，MCTS-SQL达到最先进性能，使用GPT-4o基模型在BIRD开发数据集上实现执行准确率(EX)69.40%，并在挑战任务上比现有方法提高3.41%。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.DB",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16607v1",
      "published_date": "2025-01-28 00:52:23 UTC",
      "updated_date": "2025-01-28 00:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:20:39.858088"
    },
    {
      "arxiv_id": "2501.16606v2",
      "title": "Can We Govern the Agent-to-Agent Economy?",
      "title_zh": "翻译失败",
      "authors": [
        "Tomer Jordi Chaffer"
      ],
      "abstract": "Current approaches to AI governance often fall short in anticipating a future\nwhere AI agents manage critical tasks, such as financial operations,\nadministrative functions, and beyond. While cryptocurrencies could serve as the\nfoundation for monetizing value exchange in a collaboration and delegation\ndynamic among AI agents, a critical question remains: how can humans ensure\nmeaningful oversight and control as a future economy of AI agents scales and\nevolves? In this philosophical exploration, we highlight emerging concepts in\nthe industry to inform research and development efforts in anticipation of a\nfuture decentralized agentic economy.",
      "tldr_zh": "本论文从哲学角度探讨了在AI agents主导的经济中，人类如何实现有效的治理，特别是在AI agents处理金融、行政等关键任务时。当前AI治理方法存在不足，而cryptocurrencies可能作为AI agents间价值交换的基础，以支持协作和委托动态。论文强调了确保人类监督和控制的必要性，并通过突出行业新兴概念，指导decentralized agentic economy的未来研究和发展。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16606v2",
      "published_date": "2025-01-28 00:50:35 UTC",
      "updated_date": "2025-04-25 17:21:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:20:51.995088"
    },
    {
      "arxiv_id": "2501.16605v1",
      "title": "Impact and influence of modern AI in metadata management",
      "title_zh": "现代人工智能在元数据管理中的影响与作用",
      "authors": [
        "Wenli Yang",
        "Rui Fu",
        "Muhammad Bilal Amin",
        "Byeong Kang"
      ],
      "abstract": "Metadata management plays a critical role in data governance, resource\ndiscovery, and decision-making in the data-driven era. While traditional\nmetadata approaches have primarily focused on organization, classification, and\nresource reuse, the integration of modern artificial intelligence (AI)\ntechnologies has significantly transformed these processes. This paper\ninvestigates both traditional and AI-driven metadata approaches by examining\nopen-source solutions, commercial tools, and research initiatives. A\ncomparative analysis of traditional and AI-driven metadata management methods\nis provided, highlighting existing challenges and their impact on\nnext-generation datasets. The paper also presents an innovative AI-assisted\nmetadata management framework designed to address these challenges. This\nframework leverages more advanced modern AI technologies to automate metadata\ngeneration, enhance governance, and improve the accessibility and usability of\nmodern datasets. Finally, the paper outlines future directions for research and\ndevelopment, proposing opportunities to further advance metadata management in\nthe context of AI-driven innovation and complex datasets.",
      "tldr_zh": "这篇论文探讨了现代 AI 对 metadata management 的影响，强调 AI 如何提升数据治理、资源发现和决策过程。作者通过比较传统方法与 AI 驱动方法，包括开源解决方案、商业工具和研究举措，分析了现有挑战及其对下一代数据集的影响。论文提出一个创新的 AI-assisted 框架，利用先进 AI 技术自动化 metadata 生成、增强治理，并改善数据集的可访问性和可用性。最后，论文概述了未来研究方向，推动 AI 在复杂数据集管理中的创新发展。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16605v1",
      "published_date": "2025-01-28 00:44:38 UTC",
      "updated_date": "2025-01-28 00:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:21:04.274720"
    },
    {
      "arxiv_id": "2501.16591v1",
      "title": "Applying Ensemble Models based on Graph Neural Network and Reinforcement Learning for Wind Power Forecasting",
      "title_zh": "基于图神经网络和强化学习的集成模型在风力发电预测中的应用",
      "authors": [
        "Hongjin Song",
        "Qianrun Chen",
        "Tianqi Jiang",
        "Yongfeng Li",
        "Xusheng Li",
        "Wenjun Xi",
        "Songtao Huang"
      ],
      "abstract": "Accurately predicting the wind power output of a wind farm across various\ntime scales utilizing Wind Power Forecasting (WPF) is a critical issue in wind\npower trading and utilization. The WPF problem remains unresolved due to\nnumerous influencing variables, such as wind speed, temperature, latitude, and\nlongitude. Furthermore, achieving high prediction accuracy is crucial for\nmaintaining electric grid stability and ensuring supply security. In this\npaper, we model all wind turbines within a wind farm as graph nodes in a graph\nbuilt by their geographical locations. Accordingly, we propose an ensemble\nmodel based on graph neural networks and reinforcement learning (EMGRL) for\nWPF. Our approach includes: (1) applying graph neural networks to capture the\ntime-series data from neighboring wind farms relevant to the target wind farm;\n(2) establishing a general state embedding that integrates the target wind\nfarm's data with the historical performance of base models on the target wind\nfarm; (3) ensembling and leveraging the advantages of all base models through\nan actor-critic reinforcement learning framework for WPF.",
      "tldr_zh": "本研究针对风力发电预测（Wind Power Forecasting, WPF）问题，提出了一种基于图神经网络（Graph Neural Network）和强化学习（Reinforcement Learning）的集成模型（Ensemble Model, EMGRL），以提高对风场输出的准确预测。方法包括将风力涡轮机建模为图节点，利用图神经网络捕获目标风场及其相邻风场的时序数据，并通过一个整合历史性能的通用状态嵌入机制来优化预测。最终，通过 actor-critic 强化学习框架集成所有基线模型的优势，该模型有助于提升电网稳定性和供应安全。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16591v1",
      "published_date": "2025-01-28 00:12:26 UTC",
      "updated_date": "2025-01-28 00:12:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:21:16.280202"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 95,
  "processed_papers_count": 95,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T04:21:33.343990"
}