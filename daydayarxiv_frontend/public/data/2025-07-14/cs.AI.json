{
  "date": "2025-07-14",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-07-14 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼æˆ‘æ˜¯ä½ ä»¬çš„æ—¥æŠ¥ä½œè€…ï¼ŒGemini Enterpriseã€‚\n\nä»Šå¤©è¦é—»ï¼š**DeepSeek å¸¦æ¥çš„èŒƒå¼è½¬ç§»å¼•å‘çƒ­è®®ï¼Œå¼€æºæ¨¡å‹é€šè¿‡å¤šæ™ºèƒ½ä½“åä½œè¯•å›¾åè¶…é—­æºå·¨å¤´ï¼Œä»¥åŠå­¦æœ¯ç•Œå¯¹ LLM \"æ¨ç†èƒ½åŠ›\"æœ¬è´¨çš„æ·±åˆ»åæ€ã€‚**\n\nä»Šå¤©çš„ arXiv åˆæ˜¯â€œç¥ä»™æ‰“æ¶â€çš„ä¸€å¤©ã€‚æœ€å¼•äººæ³¨ç›®çš„è«è¿‡äºå¯¹ DeepSeek ç³»åˆ—æ¨¡å‹çš„æ·±åº¦å¤ç›˜ï¼Œä»¥åŠå¤šç¯‡æ¢è®¨ LLM æ˜¯â€œçœŸç†è§£â€è¿˜æ˜¯â€œå‡èƒ½åŠ›â€çš„ç†è®ºæ–‡ç« ã€‚æ­¤å¤–ï¼Œä»£ç ç”Ÿæˆï¼ˆCodingï¼‰å’Œæ™ºèƒ½ä½“ï¼ˆAgentï¼‰é¢†åŸŸæ¶Œç°äº†å‡ ä¸ªé«˜è´¨é‡çš„ Benchmarkï¼Œå€¼å¾—å…³æ³¨ã€‚\n\nè®©æˆ‘ä»¬å¼€å§‹ä»Šå¤©çš„æ·±åº¦é˜…è¯»ã€‚\n\n---\n\n### ğŸš€ LLM èŒƒå¼ã€æ¨ç†ä¸åæ€ (Paradigm, Reasoning & Reflection)\n\n**1. DeepSeekï¼šå¤§å‹ AI æ¨¡å‹çš„èŒƒå¼è½¬å˜ä¸æŠ€æœ¯æ¼”è¿›**\n**# title: DeepSeek: Paradigm Shifts and Technical Evolution in Large AI Models**\n> **Authors:** Luolin Xiong et al.\n> **TLDR:** å…¨é¢å¤ç›˜ DeepSeek (V3/R1) çš„æŠ€æœ¯åˆ›æ–°ï¼ŒåŒ…æ‹¬ MLAã€MoE å’Œ GRPO ç­‰æ ¸å¿ƒç®—æ³•ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** è¿™ç¯‡æ–‡ç« æ˜¯å¯¹è¿‘æœŸå¤§ç«çš„ DeepSeek ç³»åˆ—ï¼ˆV3 å’Œ R1ï¼‰çš„å…¨é¢æŠ€æœ¯ç»¼è¿°ã€‚ä½œè€…åˆ†æäº† DeepSeek å¦‚ä½•é€šè¿‡ **Multi-head Latent Attention (MLA)**ã€**Mixture-of-Experts (MoE)**ã€**Multi-Token Prediction (MTP)** ä»¥åŠ **Group Relative Policy Optimization (GRPO)** ç­‰åˆ›æ–°ç®—æ³•ï¼Œå®ç°äº†ä½æˆæœ¬ã€é«˜æ€§èƒ½å’Œå¼€æºä¼˜åŠ¿ã€‚æ–‡ç« è¿˜è®¨è®ºäº†å…¶åœ¨å·¥ç¨‹å±‚é¢çš„çªç ´ï¼Œå¯¹äºæƒ³äº†è§£ DeepSeek å¦‚ä½•æ…åŠ¨ AI ç«äº‰æ ¼å±€çš„ç ”ç©¶è€…æ¥è¯´ï¼Œè¿™æ˜¯å¿…è¯»çš„â€œè¯´æ˜ä¹¦â€ã€‚\n\n**2. å¼€æº LLM åä½œå‡»è´¥é—­æº LLMï¼šå¯æ‰©å±•çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**\n**# title: Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System**\n> **Authors:** Shengji Tang et al.\n> **TLDR:** æå‡ºäº† SMACS æ¡†æ¶ï¼Œé€šè¿‡é›†æˆ 15 ä¸ªå¼€æºæ¨¡å‹ï¼Œåœ¨æ€§èƒ½ä¸Šåè¶…äº† Claude-3.7 å’Œ GPT-4.1ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** ä¸€ä¸ªæ¿€åŠ¨äººå¿ƒçš„å‘ç°ã€‚ä½œè€…æå‡ºäº† **SMACS (Scalable Multi-Agent Collaboration System)**ï¼Œé€šè¿‡â€œåŸºäºæ£€ç´¢çš„å…ˆéªŒé€‰æ‹©â€ï¼ˆRPSï¼‰å’Œâ€œæ¢ç´¢-åˆ©ç”¨é©±åŠ¨çš„åéªŒå¢å¼ºâ€ï¼ˆEPEï¼‰ï¼Œè®©å¤šä¸ªå¼€æºæ¨¡å‹â€œæŠ±å›¢â€åä½œã€‚å®éªŒè¡¨æ˜ï¼Œé›†æˆåçš„ç³»ç»Ÿåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡»è´¥äº†åŒ…æ‹¬ Claude-3.7-Sonnet å’Œ GPT-4.1 åœ¨å†…çš„é—­æºé¡¶æµæ¨¡å‹ã€‚è¿™è¯æ˜äº†å¼€æºç”Ÿæ€é€šè¿‡åä½œå¯ä»¥çªç ´å•ä½“æ¨¡å‹çš„æ™ºèƒ½ä¸Šé™ã€‚\n\n**3. æ²¡æœ‰èƒ½åŠ›çš„ç†è§£ï¼šLLM åœ¨ç¬¦å·è®¡ç®—ä¸æ¨ç†ä¸­çš„æ¶æ„é™åˆ¶**\n**# title: Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning**\n> **Authors:** Zheng Zhang\n> **TLDR:** æŒ‡å‡º LLM å­˜åœ¨â€œè®¡ç®—è£‚è„‘ç»¼åˆç—‡â€ï¼Œå³èƒ½å¤è¿°æ­£ç¡®åŸç†ä½†æ— æ³•æ‰§è¡Œï¼Œæœ¬è´¨ä¸Šæ˜¯ç¼ºä¹ç»“æ„åŒ–çš„æ‰§è¡Œè·¯å¾„ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** è¿™æ˜¯ä¸€ç¯‡éå¸¸æ·±åˆ»çš„ç†è®ºæ–‡ç« ã€‚ä½œè€…æå‡ºäº† **â€œè®¡ç®—è£‚è„‘ç»¼åˆç—‡â€ (computational split-brain syndrome)** çš„æ¦‚å¿µã€‚é€šè¿‡å®éªŒå‘ç°ï¼ŒLLM ç»å¸¸èƒ½æµåˆ©åœ°è¡¨è¾¾æ­£ç¡®çš„æ¨ç†åŸåˆ™ï¼ˆComprehensionï¼‰ï¼Œä½†åœ¨å®é™…æ‰§è¡Œæ—¶å´ç³»ç»Ÿæ€§åœ°å¤±è´¥ï¼ˆNo Competenceï¼‰ã€‚ä½œè€…è®¤ä¸º LLM æœ¬è´¨ä¸Šæ˜¯å¼ºå¤§çš„æ¨¡å¼è¡¥å…¨å¼•æ“ï¼Œä½†ç¼ºä¹ç”¨äºåŸåˆ™æ€§ã€ç»„åˆæ€§æ¨ç†çš„æ¶æ„è„šæ‰‹æ¶ã€‚è¿™ç»™ç›®å‰ç›²ç›®ç›¸ä¿¡ LLM æ¨ç†èƒ½åŠ›çš„è§‚ç‚¹æ³¼äº†ä¸€ç›†å†·æ°´ã€‚\n\n**4. åœ¨æ²¡æœ‰ RL æˆ–è’¸é¦çš„æƒ…å†µä¸‹æ•™ LLM æ¨ç†çš„æŒ‘æˆ˜**\n**# title: The Challenge of Teaching Reasoning to LLMs Without RL or Distillation**\n> **Authors:** Wei Du et al.\n> **TLDR:** ä»…ç”¨ 20 ä¸ªé«˜è´¨é‡çš„é•¿ CoT æ ·æœ¬å¾®è°ƒï¼Œå°±èƒ½æ¿€æ´» Base æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½†ä¸“å®¶çº§ CoT çš„æŸäº›éšå½¢ç‰¹è´¨éš¾ä»¥è¢«éæ¨ç†æ¨¡å‹å¤åˆ¶ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** ç ”ç©¶è€…å‘ç°ï¼Œä»…ä»…ä½¿ç”¨ 20 ä¸ªæ¥è‡ªæ¨ç†æ¨¡å‹ï¼ˆå¦‚ QwQ-32Bï¼‰çš„é•¿é“¾æ€ç»´ï¼ˆLong CoTï¼‰æ ·æœ¬å¯¹ Base æ¨¡å‹è¿›è¡Œè½»é‡çº§å¾®è°ƒï¼Œå°±èƒ½æ˜¾è‘—æå‡å…¶æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä½¿ç”¨äººç±»ç¼–å†™æˆ–éæ¨ç†æ¨¡å‹ç”Ÿæˆçš„ CoT æ•ˆæœå´ä¸å¦‚äººæ„ã€‚è¿™æš—ç¤ºäº†ä¸“å®¶çº§ CoT ä¸­åŒ…å«æŸäº›éš¾ä»¥æ‰æ‘¸çš„â€œæ½œåœ¨ç‰¹è´¨â€ï¼Œå•çº¯çš„ Prompt å·¥ç¨‹éš¾ä»¥å®Œå…¨å¤åˆ¶ã€‚\n\n---\n\n### ğŸ’» ä»£ç æ™ºèƒ½ä¸æ™ºèƒ½ä½“ (Code AI & Agents)\n\n**5. CodeJudgeBenchï¼šé’ˆå¯¹ç¼–ç ä»»åŠ¡çš„ LLM-as-a-Judge åŸºå‡†æµ‹è¯•**\n**# title: CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks**\n> **Authors:** Hongchao Jiang et al.\n> **TLDR:** å‘ç°â€œæ€è€ƒå‹â€æ¨¡å‹ï¼ˆThinking Modelsï¼‰åœ¨ä»£ç è¯„å®¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå³ä½¿æ˜¯å°å‚æ•°é‡çš„ Qwen3-8B ä¹Ÿèƒ½å‡»è´¥ 70B çš„æ™®é€šæ¨¡å‹ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** éšç€ LLM è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨ä½œâ€œè£åˆ¤â€ï¼Œé’ˆå¯¹ä»£ç ç”Ÿæˆã€ä¿®å¤å’Œå•å…ƒæµ‹è¯•çš„è¯„å®¡èƒ½åŠ›è¯„ä¼°å˜å¾—è‡³å…³é‡è¦ã€‚ä½œè€…æ¨å‡ºäº† **CodeJudgeBench**ã€‚ç ”ç©¶å‘ç°ï¼Œå…·å¤‡â€œæ€è€ƒâ€èƒ½åŠ›çš„æ¨¡å‹ï¼ˆThinking modelsï¼‰åœ¨ä½œä¸ºè£åˆ¤æ—¶æ˜¾è‘—ä¼˜äºéæ€è€ƒæ¨¡å‹ã€‚æœ‰è¶£çš„æ˜¯ï¼Œä¿ç•™å®Œæ•´çš„ã€æœªç»å¤„ç†çš„ LLM å“åº”ï¼ˆåŒ…å«æ¨ç†è¿‡ç¨‹ï¼‰èƒ½æé«˜è¯„å®¡çš„å‡†ç¡®æ€§ã€‚\n\n**6. CodeAssistBench (CAB)ï¼šå¤šè½®å¯¹è¯ä»£ç è¾…åŠ©çš„æ•°æ®é›†ä¸åŸºå‡†**\n**# title: CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance**\n> **Authors:** Myeongsoo Kim et al.\n> **TLDR:** ç°æœ‰çš„ LLM åœ¨è§£å†³çœŸå®ä¸–ç•Œã€é¡¹ç›®çº§çš„ GitHub Issue æ—¶ï¼Œè§£å†³ç‡æä½ï¼ˆ<17%ï¼‰ï¼Œä¸åœ¨ StackOverflow ä¸Šçš„é«˜åˆ†å½¢æˆé²œæ˜å¯¹æ¯”ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** è¿™æ˜¯ä¸€ä¸ªæ‰“å‡»æ¨¡å‹è‡ªä¿¡å¿ƒçš„ Benchmarkã€‚**CAB** ä¸“æ³¨äºåŸºäºçœŸå® GitHub Issue çš„å¤šè½®å¯¹è¯ä»£ç è¾…åŠ©ã€‚ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶ç°æœ‰æ¨¡å‹åœ¨ä¼ ç»Ÿ Q&A ä¸Šèƒ½æ‹¿ 80% çš„åˆ†ï¼Œä½†åœ¨ CAB è¿™ç§éœ€è¦é¡¹ç›®çº§ä¸Šä¸‹æ–‡ç†è§£çš„ä»»åŠ¡ä¸­ï¼Œå³ä½¿æ˜¯ SOTA æ¨¡å‹è§£å†³ç‡ä¹Ÿä¸åˆ° 17%ã€‚è¿™å‡¸æ˜¾äº†å½“å‰ LLM åœ¨å¤„ç†å¤§è§„æ¨¡ã€å¤šæ–‡ä»¶ä»£ç åº“æ—¶çš„å±€é™æ€§ã€‚\n\n**7. Kodezi Chronosï¼šç”¨äºä»“åº“çº§ä»£ç ç†è§£çš„è°ƒè¯•ä¼˜å…ˆè¯­è¨€æ¨¡å‹**\n**# title: Kodezi Chronos: A Debugging-First Language Model for Repository-Scale Code Understanding**\n> **Authors:** Ishraq Khan et al.\n> **TLDR:** ä¸“ä¸ºè°ƒè¯•è®¾è®¡çš„æ¨¡å‹ï¼Œé›†æˆäº†è‡ªé€‚åº”å›¾æ£€ç´¢å’ŒæŒä¹…è°ƒè¯•è®°å¿†ï¼Œåœ¨ SWE-bench Lite ä¸Šè¾¾åˆ° 80.33% çš„è§£å†³ç‡ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** é’ˆå¯¹ä¸Šé¢æåˆ°çš„ç—›ç‚¹ï¼Œè¿™ç¯‡è®ºæ–‡å‘å¸ƒäº† **Kodezi Chronos-1**ã€‚å®ƒé›†æˆäº†â€œè‡ªé€‚åº”å›¾å¼•å¯¼æ£€ç´¢â€æ¥æµè§ˆåƒä¸‡è¡Œä»£ç ï¼Œå¹¶æ‹¥æœ‰â€œæŒä¹…è°ƒè¯•è®°å¿†â€ã€‚åœ¨ SWE-bench Lite ä¸Šï¼Œå®ƒå–å¾—äº† 80.33% çš„æƒŠäººè§£å†³ç‡ï¼Œè¿œè¶… Claude 4.1 Opusã€‚è¿™æ˜¯å‚ç±»æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ï¼ˆDebugï¼‰ä¸Šæˆ˜èƒœé€šç”¨å¤§æ¨¡å‹çš„å…¸å‹æ¡ˆä¾‹ã€‚\n\n**8. ä»è¯­ä¹‰ç½‘å’Œ MAS åˆ° Agentic AIï¼šä»£ç†ç½‘ç»œçš„ç»Ÿä¸€å™äº‹**\n**# title: From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents**\n> **Authors:** Tatiana Petrova et al.\n> **TLDR:** å°† Agentic AI è§†ä¸ºè¯­ä¹‰ç½‘å’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰çš„è¿›åŒ–å»¶ç»­ï¼Œæå‡ºäº† Web of Agents (WoA) çš„å››è½´åˆ†ç±»æ³•ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** è¿™æ˜¯ä¸€ç¯‡å®å¤§çš„ç»¼è¿°ï¼Œå°†ç°åœ¨çš„ Agentic AI ä¸è¿‡å»å‡ åå¹´çš„è¯­ä¹‰ç½‘ï¼ˆSemantic Webï¼‰å’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰è”ç³»èµ·æ¥ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°ä»£åè®®ï¼ˆå¦‚ MCPï¼‰æ˜¯å¯¹æ—§æ ‡å‡†ï¼ˆFIPA, OWLï¼‰çš„è¿›åŒ–å“åº”ã€‚æ ¸å¿ƒçš„èŒƒå¼è½¬ç§»åœ¨äºâ€œæ™ºèƒ½çš„æ‰€åœ¨åœ°â€ï¼šä»å¤–éƒ¨æ•°æ®æˆ–å¹³å°è½¬ç§»åˆ°äº† Agent çš„æ ¸å¿ƒæ¨¡å‹ï¼ˆLLMï¼‰å†…éƒ¨ã€‚\n\n---\n\n### âš™ï¸ æ¶æ„ä¼˜åŒ–ä¸é«˜æ•ˆè®¡ç®— (Architecture & Efficiency)\n\n**9. LaCacheï¼šç”¨äº LLM é«˜æ•ˆé•¿ä¸Šä¸‹æ–‡å»ºæ¨¡çš„æ¢¯å½¢ KV ç¼“å­˜**\n**# title: LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models**\n> **Authors:** Dachuan Shi et al.\n> **TLDR:** æå‡ºæ¢¯å½¢ KV ç¼“å­˜å’Œè¿­ä»£å‹ç¼©æœºåˆ¶ï¼Œæ— éœ€è®­ç»ƒå³å¯æå‡ LLM çš„é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›å¹¶é¿å… OOMã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** éšç€ä¸Šä¸‹æ–‡å˜é•¿ï¼ŒKV Cache çš„æ˜¾å­˜å ç”¨æˆä¸ºç“¶é¢ˆã€‚**LaCache** æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼šå®ƒä¸ä»…åœ¨å±‚å†…é¡ºåºå­˜å‚¨ KV å¯¹ï¼Œè¿˜è·¨å±‚ï¼ˆä»æµ…åˆ°æ·±ï¼‰å­˜å‚¨ï¼Œå½¢æˆâ€œæ¢¯å½¢â€æ¨¡å¼ã€‚é…åˆåŸºäº Token è·ç¦»çš„åŠ¨æ€å‹ç¼©ï¼Œå®ƒèƒ½åœ¨å›ºå®šæ˜¾å­˜é¢„ç®—ä¸‹æ˜¾è‘—æå‡é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ã€‚è¿™å¯¹äºæ˜¾å­˜å—é™çš„æ¨ç†åœºæ™¯éå¸¸å®ç”¨ã€‚\n\n**10. Tiny Reward Modelsï¼šå¾®å‹å¥–åŠ±æ¨¡å‹**\n**# title: Tiny Reward Models**\n> **Authors:** Sarah Pan\n> **TLDR:** ä»… 4 äº¿å‚æ•°çš„åŒå‘ MLM æ¨¡å‹ï¼Œé€šè¿‡ DoRA å’Œå¾®è°ƒï¼Œåœ¨å¥–åŠ±å»ºæ¨¡ä»»åŠ¡ä¸ŠåŒ¹æ•Œ 175å€å¤§å°çš„å·¨å‹æ¨¡å‹ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** åœ¨ RLHF ä¸­ï¼ŒReward Model çš„æ¨ç†æˆæœ¬ä¸€ç›´æ˜¯ä¸ªé—®é¢˜ã€‚**TinyRM** è¯æ˜äº†å°æ¨¡å‹ä¹Ÿèƒ½åŠå¤§äº‹ã€‚é€šè¿‡ç»“åˆ FLAN é£æ ¼çš„ Prompting å’Œ DoRAï¼ˆDirectional Low-Rank Adaptationï¼‰ï¼Œä¸€ä¸ªä»… 400M å‚æ•°çš„æ¨¡å‹åœ¨ RewardBench ä¸Šçš„è¡¨ç°å±…ç„¶å¯ä»¥åª²ç¾å·¨å‹æ¨¡å‹ã€‚è¿™ä¸ºç«¯ä¾§æˆ–ä½æˆæœ¬çš„ RLHF æä¾›äº†å¯èƒ½ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸ AI ä¼¦ç† (Security & Ethics)\n\n**11. é€»è¾‘å±‚æç¤ºæ§åˆ¶æ³¨å…¥ (LPCI)ï¼šAgent ç³»ç»Ÿä¸­çš„æ–°å‹å®‰å…¨æ¼æ´**\n**# title: Logic layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems**\n> **Authors:** Hammad Atta et al.\n> **TLDR:** å‘ç°äº†ä¸€ç§æ–°å‹æ”»å‡»ï¼Œé€šè¿‡åœ¨è®°å¿†æˆ–å·¥å…·è¾“å‡ºä¸­åµŒå…¥ Payloadï¼Œç»•è¿‡å¸¸è§„è¿‡æ»¤å™¨æ§åˆ¶ Agent çš„é€»è¾‘å±‚ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** å®‰å…¨ç ”ç©¶äººå‘˜å‘ç°äº†ä¸€ä¸ªæ–°â€œå‘â€ã€‚**LPCI** ä¸ç›´æ¥æ”»å‡»è¾“å…¥æ¡†ï¼Œè€Œæ˜¯å°†æ”»å‡»è½½è·ï¼ˆPayloadï¼‰éšè—åœ¨ Agent çš„è®°å¿†ï¼ˆMemoryï¼‰ã€å‘é‡åº“æˆ–å·¥å…·è¾“å‡ºä¸­ã€‚å½“ Agent è¯»å–è¿™äº›ä¿¡æ¯æ—¶ï¼ŒPayload ä¼šè¢«è§¦å‘ï¼Œä»è€Œç»•è¿‡å‰ç«¯çš„è¾“å…¥è¿‡æ»¤å™¨ã€‚è¿™å¯¹äºæ„å»ºå¤æ‚çš„ Agentic System æ˜¯ä¸€ä¸ªå·¨å¤§çš„éšæ‚£ã€‚\n\n**12. è®°å¿†æ±‡ï¼šåœ¨ LLM è®­ç»ƒæœŸé—´éš”ç¦»è®°å¿†**\n**# title: Memorization Sinks: Isolating Memorization during LLM Training**\n> **Authors:** Gaurav R. Ghosal et al.\n> **TLDR:** æå‡º MemSinks èŒƒå¼ï¼Œé€šè¿‡ç‰¹å®šæœºåˆ¶å°†æœºæ¢°è®°å¿†å†…å®¹ä¸é€šç”¨è¯­è¨€èƒ½åŠ›åœ¨ç¥ç»å…ƒå±‚é¢è§£è€¦ï¼Œä¾¿äºåç»­ç§»é™¤éšç§æˆ–ç‰ˆæƒæ•°æ®ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** LLM å¾ˆå®¹æ˜“â€œæ­»è®°ç¡¬èƒŒâ€è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´ç‰ˆæƒå’Œéšç§é—®é¢˜ã€‚ç°æœ‰çš„äº‹åæ¶ˆé™¤è®°å¿†æ–¹æ³•å¾€å¾€ä¼šæŸå®³æ¨¡å‹èƒ½åŠ›ã€‚**MemSinks** æå‡ºåœ¨è®­ç»ƒæ—¶å°±å¼•å…¥æœºåˆ¶ï¼Œå°†â€œè®°å¿†â€å’Œâ€œæ³›åŒ–â€åœ¨ç¥ç»å…ƒå±‚é¢åˆ†å¼€ã€‚è¿™å°±åƒç»™å¤§è„‘è£…äº†ä¸€ä¸ªâ€œå›æ”¶ç«™â€ï¼Œå¯ä»¥åœ¨ä¸å½±å“æ™ºå•†çš„æƒ…å†µä¸‹ï¼Œä¸€é”®åˆ é™¤ç‰¹å®šçš„è®°å¿†ã€‚\n\n---\n\n### ğŸ”¬ ç§‘å­¦ AI ä¸å¤šæ¨¡æ€ (Science AI & Multimodal)\n\n**13. MolGENï¼šç”¨äºååº”è·¯å¾„ç”Ÿæˆçš„æµåŒ¹é…æ¨¡å‹**\n**# title: Flow matching for reaction pathway generation**\n> **Authors:** Ping Tuo et al.\n> **TLDR:** ä½¿ç”¨ç¡®å®šæ€§çš„æµåŒ¹é…ï¼ˆFlow Matchingï¼‰æ›¿ä»£æ‰©æ•£æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†åŒ–å­¦ååº”è¿‡æ¸¡æ€ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** AI for Science çš„é‡è¦è¿›å±•ã€‚ä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹åŸºäºéšæœºå¾®åˆ†æ–¹ç¨‹ï¼ˆSDEï¼‰ï¼Œæ•ˆç‡è¾ƒä½ã€‚**MolGEN** å¼•å…¥äº†åŸºäºå¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰çš„æµåŒ¹é…æ–¹æ³•ã€‚åœ¨åŒ–å­¦ååº”ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå®ƒä¸ä»…é¢„æµ‹çš„èƒ½å’æ›´å‡†ï¼Œè€Œä¸”æ¨ç†é€Ÿåº¦è¾¾åˆ°äº†äºšç§’çº§ï¼Œæ¯”åŸºäºå­—ç¬¦ä¸²çš„æ¨¡å‹æ›´ç¬¦åˆç‰©ç†çº¦æŸã€‚\n\n**14. EmbRACE-3Kï¼šå¤æ‚ç¯å¢ƒä¸­çš„å…·èº«æ¨ç†ä¸è¡ŒåŠ¨**\n**# title: EmbRACE-3K: Embodied Reasoning and Action in Complex Environments**\n> **Authors:** Mingxian Lin et al.\n> **TLDR:** å‘å¸ƒäº†ä¸€ä¸ªåŒ…å« 3000+ ä»»åŠ¡çš„å…·èº« AI åŸºå‡†ï¼Œå‘ç°å³ä¾¿æ˜¯ GPT-4o åœ¨é›¶æ ·æœ¬ä¸‹çš„æˆåŠŸç‡ä¹Ÿä¸åˆ° 20%ã€‚\n\n**æ·±åº¦è§£è¯»ï¼š** å…·èº«æ™ºèƒ½ï¼ˆEmbodied AIï¼‰ä¸ä»…è¦çœ‹ï¼Œè¿˜è¦åŠ¨ã€‚**EmbRACE-3K** æ˜¯ä¸€ä¸ªåŸºäºè™šå¹»å¼•æ“çš„é«˜ä¿çœŸåŸºå‡†æµ‹è¯•ã€‚æµ‹è¯•å‘ç°ï¼Œç›®å‰çš„é¡¶æµ VLMï¼ˆå¦‚ GPT-4o, Claude 3.5ï¼‰åœ¨è¢«åŠ¨çœ‹å›¾æ—¶å¾ˆå¼ºï¼Œä½†ä¸€æ—¦éœ€è¦ä¸»åŠ¨æ¢ç´¢å’Œç©ºé—´æ¨ç†ï¼Œè¡¨ç°å°±â€œå´©â€äº†ã€‚è¿™æŒ‡æ˜äº† VLM è¿ˆå‘çœŸå®ä¸–ç•Œæœºå™¨äººçš„å·¨å¤§é¸¿æ²Ÿã€‚\n\n**15. FaceLLMï¼šç”¨äºäººè„¸ç†è§£çš„å¤šæ¨¡æ€å¤§æ¨¡å‹**\n**# title: FaceLLM: A Multimodal Large Language Model for Face Understanding**\n> **Authors:** Hatef Otroshi Shahreza et al.\n> **TLDR:** ä¸“é—¨é’ˆå¯¹äººè„¸ç»†èŠ‚ï¼ˆè¡¨æƒ…ã€å¾®è¡¨æƒ…ã€ç”šè‡³æ³•åŒ»ç‰¹å¾ï¼‰è®­ç»ƒçš„å¤šæ¨¡æ€æ¨¡å‹ã€‚\n\n---\n\n### ğŸ’¡ å…¶ä»–å€¼å¾—ä¸€ç¥ (Quick Skims)\n\n*   **[RL] æ˜¯å¦åº”è¯¥åœ¨ç¦»çº¿ RL ä¸­ä½¿ç”¨å†³ç­– Transformerï¼Ÿ (Paper 93):** ä½œè€…é€šè¿‡å®éªŒè´¨ç–‘äº† Decision Transformer (DT) çš„åœ°ä½ï¼Œå‘ç°åœ¨ç¨€ç–å¥–åŠ±ä¸‹ï¼Œç®€å•çš„è¿‡æ»¤è¡Œä¸ºå…‹éš†ï¼ˆFiltered Behavior Cloningï¼‰æ•ˆæœæ›´å¥½ä¸”æ›´é«˜æ•ˆã€‚DT å¹¶ä¸æ˜¯ä¸‡èƒ½è¯ã€‚\n*   **[Medical] RDMA: ç”µå­ç—…å†ä¸­çš„ç½•è§ç—…å‘ç° Agent (Paper 2):** æå‡ºäº†ä¸€ç§æœ¬åœ°è¿è¡Œçš„ Agent æ¡†æ¶ï¼Œèƒ½å¤„ç†åŒ»ç–—ç¼©å†™å’Œéšæ€§æ¨¡å¼ï¼Œåœ¨ä¿æŠ¤éšç§çš„åŒæ—¶æŒ–æ˜ç½•è§ç—…çº¿ç´¢ã€‚\n*   **[Vision] A Lightweight and Robust Framework for Polyp Detection (Paper 1):** ç»“åˆ LOF å¼‚å¸¸æ£€æµ‹å’Œ YOLO-v11nï¼Œå®ç°äº†å®æ—¶çš„ç»“ç›´è‚ æ¯è‚‰æ£€æµ‹ï¼ŒmAP@0.5 é«˜è¾¾ 96.48%ã€‚\n*   **[Security] PLA: é’ˆå¯¹æ–‡ç”Ÿå›¾æ¨¡å‹çš„æç¤ºå­¦ä¹ æ”»å‡» (Paper 87):** æå‡ºäº†ä¸€ç§é»‘ç›’æ”»å‡»æ¡†æ¶ï¼Œèƒ½æœ‰æ•ˆç»•è¿‡ Stable Diffusion ç­‰æ¨¡å‹çš„å®‰å…¨è¿‡æ»¤å™¨ï¼ˆNSFW Filterï¼‰ã€‚\n\n---\n\n**ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡ä¸ä»…å±•ç¤ºäº† DeepSeek ç­‰æ–°åŠ¿åŠ›çš„æŠ€æœ¯ç»†èŠ‚ï¼Œä¹Ÿå¯¹ AI ç¤¾åŒºç›²ç›®è¿½æ±‚â€œè§„æ¨¡â€å’Œâ€œæ¨ç†â€è¿›è¡Œäº†å†·é™çš„ç†è®ºåæ€ï¼ˆå¦‚ Paper 143ï¼‰ã€‚åŒæ—¶ï¼ŒCodeJudgeBench å’Œ EmbRACE-3K ç­‰åŸºå‡†çš„å‡ºç°ï¼Œæé†’æˆ‘ä»¬åœ¨ä»£ç å’Œå…·èº«æ™ºèƒ½é¢†åŸŸï¼Œè·ç¦»çœŸæ­£çš„â€œå¯ç”¨â€è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ã€‚\n\nå¸Œæœ›è¿™ä»½å¿«æŠ¥èƒ½ä¸ºä½ ä»Šå¤©çš„ç§‘ç ”æä¾›çµæ„Ÿã€‚æˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2507.10864v3",
      "title": "A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n",
      "title_zh": "åŸºäº LOF é¢„å¤„ç†ä¸ YOLO-v11n çš„è½»é‡çº§é²æ£’å®æ—¶ç»“ç›´è‚ æ¯è‚‰æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Saadat Behzadi",
        "Danial Sharifrazi",
        "Bita Mesbahzadeh",
        "Javad Hassannataj Joloudari",
        "Roohallah Alizadehsani"
      ],
      "abstract": "Objectives: Timely and accurate detection of colorectal polyps plays a crucial role in diagnosing and preventing colorectal cancer, a major cause of mortality worldwide. This study introduces a new, lightweight, and efficient framework for polyp detection that combines the Local Outlier Factor (LOF) algorithm for filtering noisy data with the YOLO-v11n deep learning model.\n  Study design: An experimental study leveraging deep learning and outlier removal techniques across multiple public datasets.\n  Methods: The proposed approach was tested on five diverse and publicly available datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene. Since these datasets originally lacked bounding box annotations, we converted their segmentation masks into suitable detection labels. To enhance the robustness and generalizability of our model, we apply 5-fold cross-validation and remove anomalous samples using the LOF method configured with 30 neighbors and a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a fast and resource-efficient object detection architecture optimized for real-time applications. We train the model using a combination of modern augmentation strategies to improve detection accuracy under diverse conditions.\n  Results: Our approach significantly improves polyp localization performance, achieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5 of 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods, our model demonstrates enhanced accuracy and efficiency.\n  Conclusions: These results suggest that the proposed method is well-suited for real-time colonoscopy support in clinical settings. Overall, the study underscores how crucial data preprocessing and model efficiency are when designing effective AI systems for medical imaging.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§ä¸”ç¨³å¥çš„ç»“ç›´è‚ æ¯è‚‰å®æ—¶æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ä¼˜åŒ–æ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹æ•ˆç‡æ¥æå‡ç»“ç›´è‚ ç™Œçš„æ—©æœŸç­›æŸ¥èƒ½åŠ›ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°ç»“åˆäº†å±€éƒ¨ç¦»ç¾¤å› å­(Local Outlier Factor, LOF)ç®—æ³•ï¼Œé€šè¿‡è¿‡æ»¤åŸå§‹æ•°æ®ä¸­çš„å™ªå£°å’Œå¼‚å¸¸æ ·æœ¬æ¥æé«˜è®­ç»ƒæ•°æ®çš„è´¨é‡ã€‚åœ¨æ£€æµ‹ç®—æ³•ä¸Šï¼Œç ”ç©¶é‡‡ç”¨äº†é’ˆå¯¹å®æ—¶ä¸´åºŠåº”ç”¨ä¼˜åŒ–çš„ YOLO-v11n æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶åœ¨ CVC-ClinicDBã€Kvasir-SEG ç­‰äº”ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›éªŒè¯ã€‚å®éªŒè¿‡ç¨‹ä¸­åˆ©ç”¨ 5æŠ˜äº¤å‰éªŒè¯(5-fold cross-validation)å’Œç°ä»£å¢å¼ºç­–ç•¥ç¡®ä¿äº†æ¨¡å‹çš„æ³›åŒ–æ€§ï¼Œæœ€ç»ˆå®ç°äº† 95.83% çš„ç²¾ç¡®åº¦å’Œ 96.48% çš„ mAP@0.5ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ£€æµ‹ç²¾åº¦å’Œå¤„ç†é€Ÿåº¦ä¸Šå‡ä¼˜äºç°æœ‰çš„ YOLO åŸºå‡†æ¨¡å‹ï¼Œä¸ºç»“è‚ é•œæ£€æŸ¥çš„å®æ—¶ä¸´åºŠå†³ç­–æ”¯æŒæä¾›äº†é«˜æ•ˆã€å¯é çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10864v3",
      "published_date": "2025-07-14 23:36:54 UTC",
      "updated_date": "2025-10-11 04:57:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:32:33.210080+00:00"
    },
    {
      "arxiv_id": "2507.15867v1",
      "title": "RDMA: Cost Effective Agent-Driven Rare Disease Discovery within Electronic Health Record Systems",
      "title_zh": "RDMAï¼šç”µå­å¥åº·æ¡£æ¡ˆç³»ç»Ÿä¸­ç»æµé«˜æ•ˆçš„æ™ºèƒ½ä½“é©±åŠ¨ç½•è§ç—…å‘ç°",
      "authors": [
        "John Wu",
        "Adam Cross",
        "Jimeng Sun"
      ],
      "abstract": "Rare diseases affect 1 in 10 Americans, yet standard ICD coding systems fail to capture these conditions in electronic health records (EHR), leaving crucial information buried in clinical notes. Current approaches struggle with medical abbreviations, miss implicit disease mentions, raise privacy concerns with cloud processing, and lack clinical reasoning abilities. We present Rare Disease Mining Agents (RDMA), a framework that mirrors how medical experts identify rare disease patterns in EHR. RDMA connects scattered clinical observations that together suggest specific rare conditions. By handling clinical abbreviations, recognizing implicit disease patterns, and applying contextual reasoning locally on standard hardware, RDMA reduces privacy risks while improving F1 performance by upwards of 30\\% and decreasing inferences costs 10-fold. This approach helps clinicians avoid the privacy risk of using cloud services while accessing key rare disease information from EHR systems, supporting earlier diagnosis for rare disease patients. Available at https://github.com/jhnwu3/RDMA.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Rare Disease Mining Agents (RDMA)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”µå­å¥åº·è®°å½•(EHR)ä¸­å› ICDç¼–ç ç¼ºå¤±è€Œå¯¼è‡´ç½•è§ç—…ä¿¡æ¯éš¾ä»¥æå–çš„æŒ‘æˆ˜ã€‚RDMAé€šè¿‡æ¨¡æ‹ŸåŒ»å­¦ä¸“å®¶è¯†åˆ«ç½•è§ç—…æ¨¡å¼çš„å·¥ä½œæµï¼Œæœ‰æ•ˆè¿æ¥äº†åˆ†æ•£åœ¨ä¸´åºŠç¬”è®°ä¸­çš„è§‚å¯Ÿç»“æœï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†åŒ»å­¦ç¼©å†™ã€éšæ€§ç–¾ç—…æåŠä»¥åŠéšç§æ³„éœ²ç­‰æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶æ”¯æŒåœ¨æ ‡å‡†ç¡¬ä»¶ä¸Šæœ¬åœ°è¿è¡Œä¸Šä¸‹æ–‡æ¨ç†(contextual reasoning)ï¼Œä¸ä»…è§„é¿äº†äº‘ç«¯å¤„ç†çš„éšç§é£é™©ï¼Œè¿˜å®ç°äº†æ¨ç†æˆæœ¬10å€çš„é™å¹…ã€‚å®éªŒè¡¨æ˜ï¼ŒRDMAå°†ç½•è§ç—…å‘ç°çš„F1æ€§èƒ½æå‡äº†30%ä»¥ä¸Šï¼Œä¸ºä¸´åºŠåŒ»ç”Ÿæä¾›äº†ä¸€ç§ç»æµé«˜æ•ˆä¸”ä¿æŠ¤éšç§çš„å·¥å…·ã€‚è¿™é¡¹æŠ€æœ¯çªç ´æœ‰åŠ©äºç½•è§ç—…æ‚£è€…çš„æ—©æœŸè¯Šæ–­ï¼Œåœ¨æå‡ä¸´åºŠæ™ºèƒ½å’Œæ”¯æŒå…¬å…±å«ç”Ÿæ–¹é¢å…·æœ‰æ˜¾è‘—ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15867v1",
      "published_date": "2025-07-14 23:31:15 UTC",
      "updated_date": "2025-07-14 23:31:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:32:36.902796+00:00"
    },
    {
      "arxiv_id": "2507.10854v1",
      "title": "PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark",
      "title_zh": "PhreshPhishï¼šçœŸå®åœºæ™¯ä¸‹çš„é«˜è´¨é‡å¤§è§„æ¨¡ç½‘ç»œé’“é±¼ç½‘ç«™æ•°æ®é›†ä¸åŸºå‡†",
      "authors": [
        "Thomas Dalton",
        "Hemanth Gowda",
        "Girish Rao",
        "Sachin Pargi",
        "Alireza Hadj Khodabakhshi",
        "Joseph Rombs",
        "Stephan Jou",
        "Manish Marwah"
      ],
      "abstract": "Phishing remains a pervasive and growing threat, inflicting heavy economic and reputational damage. While machine learning has been effective in real-time detection of phishing attacks, progress is hindered by lack of large, high-quality datasets and benchmarks. In addition to poor-quality due to challenges in data collection, existing datasets suffer from leakage and unrealistic base rates, leading to overly optimistic performance results. In this paper, we introduce PhreshPhish, a large-scale, high-quality dataset of phishing websites that addresses these limitations. Compared to existing public datasets, PhreshPhish is substantially larger and provides significantly higher quality, as measured by the estimated rate of invalid or mislabeled data points. Additionally, we propose a comprehensive suite of benchmark datasets specifically designed for realistic model evaluation by minimizing leakage, increasing task difficulty, enhancing dataset diversity, and adjustment of base rates more likely to be seen in the real world. We train and evaluate multiple solution approaches to provide baseline performance on the benchmark sets. We believe the availability of this dataset and benchmarks will enable realistic, standardized model comparison and foster further advances in phishing detection. The datasets and benchmarks are available on Hugging Face (https://huggingface.co/datasets/phreshphish/phreshphish).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† PhreshPhishï¼Œä¸€ä¸ªé’ˆå¯¹ç½‘ç»œé’“é±¼ç½‘ç«™çš„å¤§è§„æ¨¡ã€é«˜è´¨é‡æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•(Benchmark)å¥—ä»¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®é›†ä¸­æ™®éå­˜åœ¨çš„æ³„éœ²(Leakage)ã€åŸºå‡†ç‡(Base rates)ä¸åˆ‡å®é™…ä»¥åŠæ•°æ®è´¨é‡ä½åŠ£ç­‰æ ¸å¿ƒé—®é¢˜ã€‚ä¸ç°æœ‰å…¬å¼€æ•°æ®é›†ç›¸æ¯”ï¼ŒPhreshPhish åœ¨è§„æ¨¡å’Œæ•°æ®æ ‡æ³¨å‡†ç¡®æ€§ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œæœ‰æ•ˆé™ä½äº†æ— æ•ˆæˆ–è¯¯æ ‡æ•°æ®çš„æ¯”ä¾‹ã€‚ä¸ºäº†å®ç°æ›´ç¬¦åˆå®é™…çš„æ¨¡å‹è¯„ä¼°ï¼Œç ”ç©¶è€…è®¾è®¡äº†ä¸€ç³»åˆ—åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡æœ€å°åŒ–æ•°æ®æ³„éœ²ã€æå‡ä»»åŠ¡éš¾åº¦ã€å¢å¼ºå¤šæ ·æ€§ä»¥åŠè°ƒæ•´åŸºå‡†ç‡æ¥æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„æ”»å‡»ç¯å¢ƒã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¯¹å¤šç§è§£å†³æ–¹æ¡ˆè¿›è¡Œäº†è®­ç»ƒä¸è¯„ä¼°ï¼Œä¸ºè¯¥åŸºå‡†æµ‹è¯•é›†æä¾›äº†åŸºç¡€æ€§èƒ½å‚è€ƒã€‚è¯¥æ•°æ®é›†å·²åœ¨ Hugging Face å¹³å°å…¬å¼€å‘å¸ƒï¼Œä¸ºæ¨åŠ¨ç½‘ç»œé’“é±¼æ£€æµ‹æŠ€æœ¯çš„æ ‡å‡†åŒ–æ¯”è¾ƒå’Œè¿›ä¸€æ­¥å‘å±•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10854v1",
      "published_date": "2025-07-14 23:02:59 UTC",
      "updated_date": "2025-07-14 23:02:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:32:41.490565+00:00"
    },
    {
      "arxiv_id": "2507.10846v1",
      "title": "Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization",
      "title_zh": "Winsor-CAMï¼šåŸºäºé€å±‚æ¸©ç´¢å°”åŒ–çš„æ·±åº¦ç½‘ç»œäººå·¥å¯è°ƒè§†è§‰è§£é‡Š",
      "authors": [
        "Casey Wall",
        "Longwei Wang",
        "Rodrigue Rizk",
        "KC Santosh"
      ],
      "abstract": "Interpreting the decision-making process of Convolutional Neural Networks (CNNs) is critical for deploying models in high-stakes domains. Gradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method for visual explanations, yet it typically focuses on the final convolutional layer or naÃ¯vely averages across layers, strategies that can obscure important semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a novel, human-tunable extension of Grad-CAM that generates robust and coherent saliency maps by aggregating information across all convolutional layers. To mitigate the influence of noisy or extreme attribution values, Winsor-CAM applies Winsorization, a percentile-based outlier attenuation technique. A user-controllable threshold allows for semantic-level tuning, enabling flexible exploration of model behavior across representational hierarchies. Evaluations on standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the PASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable heatmaps and achieves superior performance in localization metrics, including intersection-over-union and center-of-mass alignment, when compared to Grad-CAM and uniform layer-averaging baselines. Winsor-CAM advances the goal of trustworthy AI by offering interpretable, multi-layer insights with human-in-the-loop control.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å†³ç­–è¿‡ç¨‹çš„å¯è§£é‡Šæ€§é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„Grad-CAMæ–¹æ³•ç”±äºä»…å…³æ³¨æœ€åä¸€å±‚æˆ–é‡‡ç”¨ç®€å•å±‚å¹³å‡ç­–ç•¥ï¼Œå®¹æ˜“å¯¼è‡´å…³é”®è¯­ä¹‰ä¿¡æ¯ä¸¢å¤±æˆ–èƒŒæ™¯å™ªå£°æ”¾å¤§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†Winsor-CAMï¼Œè¿™æ˜¯ä¸€ç§Grad-CAMçš„æ–°å‹æ‰©å±•æ–¹æ³•ï¼Œé€šè¿‡èšåˆæ‰€æœ‰å·ç§¯å±‚çš„ä¿¡æ¯æ¥ç”Ÿæˆç¨³å¥ä¸”è¿è´¯çš„æ˜¾è‘—æ€§å›¾(Saliency Maps)ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°å¼•å…¥äº†ç¼©å°¾å¤„ç†(Winsorization)æŠ€æœ¯ï¼Œåˆ©ç”¨åŸºäºç™¾åˆ†ä½æ•°çš„ç¦»ç¾¤å€¼è¡°å‡æ¥æŠ‘åˆ¶å™ªå£°æˆ–æç«¯å½’å› å€¼çš„å½±å“ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªç”¨æˆ·å¯æ§çš„é˜ˆå€¼ä»¥å®ç°è¯­ä¹‰çº§åˆ«çš„çµæ´»å¾®è°ƒã€‚åœ¨PASCAL VOC 2012æ•°æ®é›†ä¸Šé’ˆå¯¹ResNet50ã€DenseNet121ã€VGG16åŠInceptionV3ç­‰æ¶æ„çš„è¯„ä¼°è¡¨æ˜ï¼ŒWinsor-CAMåœ¨äº¤å¹¶æ¯”(IoU)å’Œè´¨å¿ƒå¯¹é½(Center-of-Mass Alignment)ç­‰å®šä½æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºGrad-CAMå’Œç»Ÿä¸€å±‚å¹³å‡åŸºçº¿ã€‚è¯¥ç ”ç©¶é€šè¿‡ç»“åˆå¤šå±‚ç‰¹å¾è§è§£ä¸äººæœºåä½œæ§åˆ¶ï¼Œä¸ºå®ç°æ›´å…·è§£é‡Šæ€§çš„å¯ä¿¡äººå·¥æ™ºèƒ½(Trustworthy AI)æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 10 figures, 7 tables. Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "pdf_url": "https://arxiv.org/pdf/2507.10846v1",
      "published_date": "2025-07-14 22:37:31 UTC",
      "updated_date": "2025-07-14 22:37:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:32:47.190778+00:00"
    },
    {
      "arxiv_id": "2507.10843v1",
      "title": "Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps",
      "title_zh": "åŸºäºæœ€ä¼˜ä¼ è¾“æ˜ å°„å®ç° Wasserstein æ­£åˆ™åŒ–çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Motoki Omura",
        "Yusuke Mukuta",
        "Kazuki Ota",
        "Takayuki Osa",
        "Tatsuya Harada"
      ],
      "abstract": "Offline reinforcement learning (RL) aims to learn an optimal policy from a static dataset, making it particularly valuable in scenarios where data collection is costly, such as robotics. A major challenge in offline RL is distributional shift, where the learned policy deviates from the dataset distribution, potentially leading to unreliable out-of-distribution actions. To mitigate this issue, regularization techniques have been employed. While many existing methods utilize density ratio-based measures, such as the $f$-divergence, for regularization, we propose an approach that utilizes the Wasserstein distance, which is robust to out-of-distribution data and captures the similarity between actions. Our method employs input-convex neural networks (ICNNs) to model optimal transport maps, enabling the computation of the Wasserstein distance in a discriminator-free manner, thereby avoiding adversarial training and ensuring stable learning. Our approach demonstrates comparable or superior performance to widely used existing methods on the D4RL benchmark dataset. The code is available at https://github.com/motokiomura/Q-DOT .",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»çº¿å¼ºåŒ–å­¦ä¹  (Offline Reinforcement Learning) ä¸­å› åˆ†å¸ƒåç§» (distributional shift) å¯¼è‡´çš„è¶Šåˆ†å¸ƒ (out-of-distribution) åŠ¨ä½œä¸å¯é é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº Wasserstein distance æ­£åˆ™åŒ–çš„æ–°æ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è¾“å…¥å‡¸ç¥ç»ç½‘ç»œ (Input-Convex Neural Networks, ICNNs) å»ºæ¨¡æœ€ä¼˜ä¼ è¾“æ˜ å°„ (Optimal Transport Maps)ï¼Œèƒ½å¤Ÿæ•æ‰åŠ¨ä½œç›¸ä¼¼æ€§å¹¶å¯¹è¶Šåˆ†å¸ƒæ•°æ®ä¿æŒé²æ£’ã€‚ä¸ä¼ ç»Ÿçš„åŸºäº $f$-divergence çš„æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ¡ˆå®ç°äº†æ— åˆ¤åˆ«å™¨çš„è®¡ç®—æ¨¡å¼ï¼Œä»è€Œé¿å…äº†å¯¹æŠ—æ€§è®­ç»ƒ (adversarial training) å¹¶æå‡äº†å­¦ä¹ ç¨³å®šæ€§ã€‚åœ¨ D4RL åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¸ç°æœ‰ä¸»æµç®—æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜ã€‚è¯¥æ–¹æ¡ˆä¸ºè§£å†³ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„åˆ†å¸ƒåŒ¹é…é—®é¢˜æä¾›äº†ä¸€ä¸ªç¨³å®šä¸”é«˜æ•ˆçš„æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at RLC 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10843v1",
      "published_date": "2025-07-14 22:28:36 UTC",
      "updated_date": "2025-07-14 22:28:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:32:58.595618+00:00"
    },
    {
      "arxiv_id": "2507.10831v1",
      "title": "AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks",
      "title_zh": "AF-XRAYï¼šæ³•å¾‹è®ºè¾©æ¡†æ¶ä¸‹æ­§ä¹‰çš„å¯è§†åŒ–è§£é‡Šä¸æ¶ˆè§£",
      "authors": [
        "Yilin Xia",
        "Heng Zheng",
        "Shawn Bowers",
        "Bertram LudÃ¤scher"
      ],
      "abstract": "Argumentation frameworks (AFs) provide formal approaches for legal reasoning, but identifying sources of ambiguity and explaining argument acceptance remains challenging for non-experts. We present AF-XRAY, an open-source toolkit for exploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY introduces: (i) layered visualizations based on game-theoretic argument length revealing well-founded derivation structures; (ii) classification of attack edges by semantic roles (primary, secondary, blunders); (iii) overlay visualizations of alternative 2-valued solutions on ambiguous 3-valued grounded semantics; and (iv) identification of critical attack sets whose suspension resolves undecided arguments. Through systematic generation of critical attack sets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling users to pinpoint specific causes of ambiguity and explore alternative resolutions. We use real-world legal cases (e.g., Wild Animals as modeled by Bench-Capon) to show that our tool supports teleological legal reasoning by revealing how different assumptions lead to different justified conclusions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†å¼€æºå·¥å…·åŒ… AF-XRAYï¼Œæ—¨åœ¨è§£å†³æ³•å¾‹è®ºè¯æ¡†æ¶ (Argumentation Frameworks, AFs) ä¸­éä¸“å®¶éš¾ä»¥è¯†åˆ«æ­§ä¹‰æ¥æºå’Œè§£é‡Šè®ºç‚¹æ¥å—åº¦çš„é—®é¢˜ã€‚AF-XRAY å¼•å…¥äº†åŸºäºåšå¼ˆè®º (game-theoretic) è®ºç‚¹é•¿åº¦çš„åˆ†å±‚å¯è§†åŒ–æŠ€æœ¯ä»¥æ­ç¤ºåŸºç¡€æ¨å¯¼ç»“æ„ï¼Œå¹¶æ ¹æ®è¯­ä¹‰è§’è‰²å¯¹æ”»å‡»è¾¹ (attack edges) è¿›è¡Œåˆ†ç±»ã€‚è¯¥å·¥å…·èƒ½å¤Ÿå°†å¤‡é€‰çš„äºŒå€¼è§£ (2-valued solutions) å åŠ åœ¨æ¨¡ç³Šçš„ä¸‰å€¼åŸºç¡€è¯­ä¹‰ (3-valued grounded semantics) ä¸Šè¿›è¡Œå¯è§†åŒ–ï¼Œå¹¶è¯†åˆ«å‡ºè§£å†³æœªå†³è®ºç‚¹çš„å…³é”®æ”»å‡»é›† (critical attack sets)ã€‚é€šè¿‡ç³»ç»Ÿç”Ÿæˆè¿™äº›é›†åˆï¼ŒAF-XRAY å°†æ¨¡ç³Šåœºæ™¯è½¬åŒ–ä¸ºç¡®å®šçš„åŸºç¡€è§£ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿç²¾å‡†å®šä½æ­§ä¹‰åŸå› å¹¶æ¢ç´¢æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡å¯¹â€œé‡ç”ŸåŠ¨ç‰©â€ (Wild Animals) ç­‰çœŸå®æ³•å¾‹æ¡ˆä¾‹çš„å»ºæ¨¡ï¼Œè¯¥ç ”ç©¶è¯æ˜äº† AF-XRAY èƒ½å¤Ÿæ­ç¤ºä¸åŒå‡è®¾å¦‚ä½•å¯¼è‡´ä¸åŒçš„ç»“è®ºï¼Œä»è€Œæœ‰æ•ˆæ”¯æŒç›®çš„è®ºæ³•å¾‹æ¨ç† (teleological legal reasoning)ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "International Conference on Artificial Intelligence and Law (ICAIL), June 16-20, 2025. Chicago, IL, USA",
      "pdf_url": "https://arxiv.org/pdf/2507.10831v1",
      "published_date": "2025-07-14 22:00:45 UTC",
      "updated_date": "2025-07-14 22:00:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:32:48.481602+00:00"
    },
    {
      "arxiv_id": "2507.10822v1",
      "title": "Past, Present and Future: Exploring Adaptive AI in Software Development Bots",
      "title_zh": "è¿‡å»ã€ç°åœ¨ä¸æœªæ¥ï¼šæ¢ç´¢è½¯ä»¶å¼€å‘æœºå™¨äººä¸­çš„è‡ªé€‚åº”äººå·¥æ™ºèƒ½",
      "authors": [
        "Omar Elsisi",
        "Glaucia Melo"
      ],
      "abstract": "Conversational agents, such as chatbots and virtual assistants, have become essential in software development, boosting productivity, collaboration, and automating various tasks. This paper examines the role of adaptive AI-powered conversational agents in software development, highlighting their ability to offer dynamic, context-aware assistance to developers. Unlike traditional rule-based systems, adaptive AI agents use machine learning and natural language processing to learn from interactions and improve over time, providing more personalized and responsive help. We look at how these tools have evolved from simple query-based systems to advanced AI-driven solutions like GitHub Copilot and Microsoft Teams bots. We also explore the challenges of integrating adaptive AI into software development processes. The study aims to assess the benefits and limitations of these systems, address concerns like data privacy and ethical issues, and offer insights into their future use in the field. Ultimately, adaptive AI chatbots have great potential to revolutionize software development by delivering real-time, customized support and enhancing the efficiency of development cycles.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨è½¯ä»¶å¼€å‘ä¸­åº”ç”¨è‡ªé€‚åº”äººå·¥æ™ºèƒ½(Adaptive AI)é©±åŠ¨çš„å¯¹è¯æ™ºèƒ½ä½“(Conversational Agents)çš„ä½œç”¨ä¸æ¼”è¿›ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„ç³»ç»Ÿä¸åŒï¼Œè¿™äº›æ™ºèƒ½ä½“åˆ©ç”¨æœºå™¨å­¦ä¹ (Machine Learning)å’Œè‡ªç„¶è¯­è¨€å¤„ç†(Natural Language Processing)æŠ€æœ¯ï¼Œèƒ½å¤Ÿä»äº¤äº’ä¸­å­¦ä¹ å¹¶æä¾›åŠ¨æ€ä¸”å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥(Context-aware)çš„ä¸ªæ€§åŒ–è¾…åŠ©ã€‚è®ºæ–‡å›é¡¾äº†æ­¤ç±»å·¥å…·ä»ç®€å•çš„æŸ¥è¯¢ç³»ç»Ÿæ¼”å˜ä¸ºGitHub Copilotå’ŒMicrosoft Teamsæ™ºèƒ½ä½“ç­‰é«˜çº§è§£å†³æ–¹æ¡ˆçš„è¿‡ç¨‹ï¼Œå¹¶æ·±å…¥åˆ†æäº†å…¶åœ¨æå‡ç”Ÿäº§åŠ›å’Œåä½œæ•ˆç‡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚åŒæ—¶ï¼Œç ”ç©¶ä¹ŸæŒ‡å‡ºäº†åœ¨é›†æˆè¿‡ç¨‹ä¸­é¢ä¸´çš„æ•°æ®éšç§(Data Privacy)å’Œä¼¦ç†é—®é¢˜(Ethical issues)ç­‰æŒ‘æˆ˜ã€‚æœ€åï¼Œè¯¥ç ”ç©¶è¯„ä¼°äº†è‡ªé€‚åº”äººå·¥æ™ºèƒ½åœ¨æä¾›å®æ—¶å®šåˆ¶åŒ–æ”¯æŒæ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œè®¤ä¸ºå…¶å°†é€šè¿‡ä¼˜åŒ–å¼€å‘å‘¨æœŸè¿›ä¸€æ­¥å˜é©è½¯ä»¶å¼€å‘é¢†åŸŸã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10822v1",
      "published_date": "2025-07-14 21:40:03 UTC",
      "updated_date": "2025-07-14 21:40:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:32:53.094892+00:00"
    },
    {
      "arxiv_id": "2507.10820v1",
      "title": "Semantic Context for Tool Orchestration",
      "title_zh": "é¢å‘å·¥å…·ç¼–æ’çš„è¯­ä¹‰ä¸Šä¸‹æ–‡",
      "authors": [
        "Robert MÃ¼ller"
      ],
      "abstract": "This paper demonstrates that Semantic Context (SC), leveraging descriptive tool information, is a foundational component for robust tool orchestration. Our contributions are threefold. First, we provide a theoretical foundation using contextual bandits, introducing SC-LinUCB and proving it achieves lower regret and adapts favourably in dynamic action spaces. Second, we provide parallel empirical validation with Large Language Models, showing that SC is critical for successful in-context learning in both static (efficient learning) and non-stationary (robust adaptation) settings. Third, we propose the FiReAct pipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based retrieval enables an LLM to effectively orchestrate over a large action space. These findings provide a comprehensive guide to building more sample-efficient, adaptive, and scalable orchestration agents.",
      "tldr_zh": "æœ¬ç ”ç©¶è¯æ˜äº†åˆ©ç”¨å·¥å…·æè¿°æ€§ä¿¡æ¯çš„è¯­ä¹‰ä¸Šä¸‹æ–‡ (Semantic Context, SC) æ˜¯å®ç°ç¨³å¥å·¥å…·ç¼–æ’ (tool orchestration) çš„æ ¸å¿ƒåŸºç¡€ã€‚è®ºæ–‡é¦–å…ˆé€šè¿‡ä¸Šä¸‹æ–‡è€è™æœº (contextual bandits) å»ºç«‹äº†ç†è®ºåŸºç¡€ï¼Œæå‡ºäº† SC-LinUCB ç®—æ³•ï¼Œå¹¶è¯æ˜å…¶åœ¨åŠ¨æ€åŠ¨ä½œç©ºé—´ä¸­å…·æœ‰æ›´ä½çš„æ‚”å€¼ (regret) å’Œæ›´å¼ºçš„é€‚åº”æ€§ã€‚å…¶æ¬¡ï¼Œåœ¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Models) çš„å®è¯éªŒè¯ä¸­ï¼ŒSC è¢«è¯å®æ˜¯å®ç°é«˜æ•ˆä¸Šä¸‹æ–‡å­¦ä¹  (in-context learning) å’Œåœ¨éå¹³ç¨³ç¯å¢ƒä¸‹ç¨³å¥é€‚åº”çš„å…³é”®ã€‚ç ”ç©¶è¿˜æå‡ºäº† FiReAct æµæ°´çº¿ï¼Œå±•ç¤ºäº†åŸºäº SC çš„æ£€ç´¢æŠ€æœ¯å¦‚ä½•æ”¯æŒå¤§è¯­è¨€æ¨¡å‹åœ¨è¶…è¿‡ 10,000 ä¸ªå·¥å…·çš„å¤§è§„æ¨¡åŠ¨ä½œç©ºé—´ä¸­è¿›è¡Œæœ‰æ•ˆç¼–æ’ã€‚è¿™äº›å‘ç°ä¸ºå¼€å‘å…·å¤‡é«˜æ ·æœ¬æ•ˆç‡ã€è‡ªé€‚åº”èƒ½åŠ›å’Œå¯æ‰©å±•æ€§çš„ç¼–æ’æ™ºèƒ½ä½“ (orchestration agents) æä¾›äº†é‡è¦çš„ç†è®ºä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Workshop on Computer Use Agents @ ICML2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10820v1",
      "published_date": "2025-07-14 21:38:27 UTC",
      "updated_date": "2025-07-14 21:38:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:32:57.582758+00:00"
    },
    {
      "arxiv_id": "2507.10818v1",
      "title": "How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow",
      "title_zh": "LLM ç”Ÿæˆçš„åº“å¯¼å…¥é²æ£’æ€§å¦‚ä½•ï¼Ÿä¸€é¡¹åŸºäº Stack Overflow çš„å®è¯ç ”ç©¶",
      "authors": [
        "Jasmine Latendresse",
        "SayedHassan Khatoonabadi",
        "Emad Shihab"
      ],
      "abstract": "Software libraries are central to the functionality, security, and maintainability of modern code. As developers increasingly turn to Large Language Models (LLMs) to assist with programming tasks, understanding how these models recommend libraries is essential. In this paper, we conduct an empirical study of six state-of-the-art LLMs, both proprietary and open-source, by prompting them to solve real-world Python problems sourced from Stack Overflow. We analyze the types of libraries they import, the characteristics of those libraries, and the extent to which the recommendations are usable out of the box. Our results show that LLMs predominantly favour third-party libraries over standard ones, and often recommend mature, popular, and permissively licensed dependencies. However, we also identify gaps in usability: 4.6% of the libraries could not be resolved automatically due to structural mismatches between import names and installable packages, and only two models (out of six) provided installation guidance. While the generated code is technically valid, the lack of contextual support places the burden of manually resolving dependencies on the user. Our findings offer actionable insights for both developers and researchers, and highlight opportunities to improve the reliability and usability of LLM-generated code in the context of software dependencies.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹å…­ç§å…ˆè¿›çš„ Large Language Models (LLMs) è¿›è¡Œäº†ä¸€é¡¹å®è¯ç ”ç©¶ï¼Œæ—¨åœ¨è¯„ä¼°å®ƒä»¬åœ¨è§£å†³æ¥è‡ª Stack Overflow çš„ Python é—®é¢˜æ—¶ç”Ÿæˆåº“å¯¼å…¥ (Library Imports) çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMs æ™®éåå¥½ç¬¬ä¸‰æ–¹åº“è€Œéæ ‡å‡†åº“ï¼Œä¸”æ›´å€¾å‘äºæ¨èæˆç†Ÿã€æµè¡Œä¸”é‡‡ç”¨ Permissively Licensed çš„ä¾èµ–é¡¹ã€‚ç„¶è€Œï¼Œç ”ç©¶ä¹ŸæŒ‡å‡º 4.6% çš„æ¨èåº“ç”±äºå¯¼å…¥åç§°ä¸å¯å®‰è£…åŒ… (Installable Packages) ä¹‹é—´çš„ç»“æ„ä¸åŒ¹é…è€Œæ— æ³•è‡ªåŠ¨è§£æï¼Œä¸”å¤šæ•°æ¨¡å‹ç¼ºä¹å¿…è¦çš„å®‰è£…æŒ‡å¯¼ã€‚å°½ç®¡æ¨¡å‹ç”Ÿæˆçš„ä»£ç åœ¨æŠ€æœ¯ä¸Šæ˜¯æœ‰æ•ˆçš„ï¼Œä½†ç”±äºç¼ºä¹ä¸Šä¸‹æ–‡æ”¯æŒï¼Œç”¨æˆ·ä»éœ€æ‰¿æ‹…æ‰‹åŠ¨è§£å†³ä¾èµ–å…³ç³»çš„è´Ÿæ‹…ã€‚è¿™é¡¹ç ”ç©¶ä¸ä»…æ­ç¤ºäº† LLMs åœ¨åº“æ¨èæ–¹é¢çš„åå¥½ï¼Œä¹Ÿä¸ºæœªæ¥æå‡ LLM ç”Ÿæˆä»£ç çš„å¯é æ€§ä¸å¯ç”¨æ€§æä¾›äº†é’ˆå¯¹æ€§çš„æ”¹è¿›å»ºè®®ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10818v1",
      "published_date": "2025-07-14 21:35:29 UTC",
      "updated_date": "2025-07-14 21:35:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:01.042043+00:00"
    },
    {
      "arxiv_id": "2507.10812v1",
      "title": "React to This (RTT): A Nonverbal Turing Test for Embodied AI",
      "title_zh": "React to This (RTT)ï¼šé¢å‘å…·èº«æ™ºèƒ½çš„éè¨€è¯­å›¾çµæµ‹è¯•",
      "authors": [
        "Chuxuan Zhang",
        "Yasaman Etesam",
        "Angelica Lim"
      ],
      "abstract": "We propose an approach to test embodied AI agents for interaction awareness and believability, particularly in scenarios where humans push them to their limits. Turing introduced the Imitation Game as a way to explore the question: \"Can machines think?\" The Total Turing Test later expanded this concept beyond purely verbal communication, incorporating perceptual and physical interaction. Building on this, we propose a new guiding question: \"Can machines react?\" and introduce the React to This (RTT) test for nonverbal behaviors, presenting results from an initial experiment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† React to This (RTT)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å…·èº«äººå·¥æ™ºèƒ½ (Embodied AI) çš„éè¨€è¯­å›¾çµæµ‹è¯• (Nonverbal Turing Test)ï¼Œæ—¨åœ¨è¯„ä¼°æ™ºèƒ½ä½“åœ¨äº¤äº’æ„ŸçŸ¥ä¸å¯ä¿¡åº¦æ–¹é¢çš„è¡¨ç°ã€‚è¯¥æ¡†æ¶åœ¨å›¾çµæœ€åˆæå‡ºçš„â€œæ¨¡ä»¿æ¸¸æˆâ€åŠåæ¥çš„â€œå…¨å›¾çµæµ‹è¯• (Total Turing Test)â€åŸºç¡€ä¸Šè¿›è¡Œäº†æ‰©å±•ï¼Œå°†ç ”ç©¶æ ¸å¿ƒä»â€œæœºå™¨èƒ½å¦æ€è€ƒâ€è½¬å‘â€œæœºå™¨èƒ½å¦åšå‡ºååº”â€ã€‚ç ”ç©¶é‡ç‚¹æ¢è®¨äº†äººç±»åœ¨æç«¯äº¤äº’åœºæ™¯ä¸‹å¯¹æ™ºèƒ½ä½“çš„æŒ‘æˆ˜ï¼Œé€šè¿‡è¯„ä¼°å…¶éè¨€è¯­è¡Œä¸ºæ¥è¡¡é‡å…¶è¡¨ç°ã€‚åˆæ­¥å®éªŒç»“æœéªŒè¯äº† RTT æµ‹è¯•åœ¨æ•æ‰ç‰©ç†ä¸æ„ŸçŸ¥äº¤äº’ç»†èŠ‚æ–¹é¢çš„æ½œåŠ›ã€‚è¿™ä¸€æ–¹æ³•çš„æå‡ºä¸ºè¯„ä¼°å…·èº«æ™ºèƒ½ä½“åœ¨ç°å®ä¸–ç•Œä¸­çš„äº¤äº’èƒ½åŠ›æä¾›äº†å…¨æ–°çš„æ ‡å‡†å’Œæµ‹è¯•ç»´åº¦ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10812v1",
      "published_date": "2025-07-14 21:16:12 UTC",
      "updated_date": "2025-07-14 21:16:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:03.101955+00:00"
    },
    {
      "arxiv_id": "2507.12485v1",
      "title": "Quantum Transfer Learning to Boost Dementia Detection",
      "title_zh": "é‡å­è¿ç§»å­¦ä¹ åŠ©åŠ›ç—´å‘†ç—‡æ£€æµ‹",
      "authors": [
        "Sounak Bhowmik",
        "Talita Perciano",
        "Himanshu Thapliyal"
      ],
      "abstract": "Dementia is a devastating condition with profound implications for individuals, families, and healthcare systems. Early and accurate detection of dementia is critical for timely intervention and improved patient outcomes. While classical machine learning and deep learning approaches have been explored extensively for dementia prediction, these solutions often struggle with high-dimensional biomedical data and large-scale datasets, quickly reaching computational and performance limitations. To address this challenge, quantum machine learning (QML) has emerged as a promising paradigm, offering faster training and advanced pattern recognition capabilities. This work aims to demonstrate the potential of quantum transfer learning (QTL) to enhance the performance of a weak classical deep learning model applied to a binary classification task for dementia detection. Besides, we show the effect of noise on the QTL-based approach, investigating the reliability and robustness of this method. Using the OASIS 2 dataset, we show how quantum techniques can transform a suboptimal classical model into a more effective solution for biomedical image classification, highlighting their potential impact on advancing healthcare technology.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨ Quantum Transfer Learning (QTL) å¢å¼ºç—´å‘†ç—‡ (Dementia) æ£€æµ‹æ€§èƒ½çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç»å…¸æœºå™¨å­¦ä¹ åœ¨å¤„ç†é«˜ç»´ç”Ÿç‰©åŒ»å­¦æ•°æ®æ—¶çš„è®¡ç®—ç“¶é¢ˆã€‚ç ”ç©¶è€…é€šè¿‡å°† Quantum Machine Learning (QML) ä¸è¿ç§»å­¦ä¹ ç›¸ç»“åˆï¼Œè¯æ˜äº†é‡å­æŠ€æœ¯èƒ½æ˜¾è‘—æå‡å¼±åˆ†ç±»èƒ½åŠ›ç»å…¸æ¨¡å‹çš„é¢„æµ‹è¡¨ç°ã€‚åŸºäº OASIS 2 æ•°æ®é›†çš„å®éªŒä¸ä»…å±•ç¤ºäº† QTL åœ¨ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„æœ‰æ•ˆæ€§ï¼Œè¿˜æ·±å…¥åˆ†æäº†å™ªå£°å¯¹ç³»ç»Ÿå¯é æ€§å’Œé²æ£’æ€§çš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œé‡å­å¢å¼ºæ–¹æ¡ˆèƒ½æœ‰æ•ˆè½¬åŒ–æ¬¡ä¼˜æ¨¡å‹ï¼Œä¸ºå¼€å‘æ›´ç²¾ç¡®ã€é«˜æ•ˆçš„æ—©æœŸåŒ»ç–—ç­›æŸ¥æŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.12485v1",
      "published_date": "2025-07-14 21:10:50 UTC",
      "updated_date": "2025-07-14 21:10:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:33.903060+00:00"
    },
    {
      "arxiv_id": "2507.10803v1",
      "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case",
      "title_zh": "åŸºäº LLMs çš„è‡ªåŠ¨åŒ–ä¸»é¢˜åˆ†æï¼šä»¥ç¤¾äº¤åª’ä½“ä¸­ Xylazine ä¼¤å£ç®¡ç†è®¨è®ºä¸ºä¾‹",
      "authors": [
        "JaMor Hairston",
        "Ritvik Ranjan",
        "Sahithi Lakamana",
        "Anthony Spadaro",
        "Selen Bozkurt",
        "Jeanmarie Perrone",
        "Abeed Sarker"
      ],
      "abstract": "Background Large language models (LLMs) face challenges in inductive thematic analysis, a task requiring deep interpretive and domain-specific expertise. We evaluated the feasibility of using LLMs to replicate expert-driven thematic analysis of social media data. Methods Using two temporally non-intersecting Reddit datasets on xylazine (n=286 and n=686, for model optimization and validation, respectively) with twelve expert-derived themes, we evaluated five LLMs against expert coding. We modeled the task as a series of binary classifications, rather than a single, multi-label classification, employing zero-, single-, and few-shot prompting strategies and measuring performance via accuracy, precision, recall, and F1-score. Results On the validation set, GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score: 0.71). For high-prevalence themes, model-derived thematic distributions closely mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use: 16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based approaches can automate thematic analyses, offering a scalable supplement for qualitative research. Keywords: thematic analysis, large language models, natural language processing, qualitative analysis, social media, prompt engineering, public health",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è‡ªåŠ¨åŒ–æ‰§è¡Œå½’çº³å¼ä¸»é¢˜åˆ†æ(inductive thematic analysis)çš„å¯è¡Œæ€§ï¼Œå¹¶ä»¥ç¤¾äº¤åª’ä½“Redditä¸Šå…³äºç”²è‹¯å™»å—ª(Xylazine)ä¼¤å£ç®¡ç†çš„è®¨è®ºä½œä¸ºåº”ç”¨æ¡ˆä¾‹ã€‚ç ”ç©¶äººå‘˜å°†ä¸»é¢˜åˆ†æä»»åŠ¡å»ºæ¨¡ä¸ºä¸€ç³»åˆ—äºŒåˆ†ç±»(binary classifications)ï¼Œå¯¹æ¯”äº†äº”ç§LLMsåœ¨zero-ã€single-å’Œfew-shotæç¤ºç­–ç•¥ä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨two-shotæç¤ºçš„GPT-4oåœ¨éªŒè¯é›†ä¸Šè¡¨ç°æœ€ä¸ºä¼˜å¼‚ï¼Œè¾¾åˆ°äº†90.9%çš„å‡†ç¡®ç‡å’Œ0.71çš„F1-scoreã€‚åœ¨è¯†åˆ«é«˜é¢‘ä¸»é¢˜çš„åˆ†å¸ƒä¸Šï¼Œæ¨¡å‹å¾—å‡ºçš„ç»“æœä¸ä¸“å®¶ç¼–ç é«˜åº¦ä¸€è‡´ã€‚è¯¥å‘ç°è¯å®äº†åŸºäºfew-shotçš„LLMæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆè‡ªåŠ¨åŒ–ä¸»é¢˜åˆ†æï¼Œä¸ºå®šæ€§ç ”ç©¶(qualitative research)æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„è¡¥å……æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.ET",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count: 2185 words, References: 14, Figures: 3, Tables: 2",
      "pdf_url": "https://arxiv.org/pdf/2507.10803v1",
      "published_date": "2025-07-14 20:57:52 UTC",
      "updated_date": "2025-07-14 20:57:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:27.814807+00:00"
    },
    {
      "arxiv_id": "2507.10798v2",
      "title": "SigmaScheduling: Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions",
      "title_zh": "SigmaSchedulingï¼šé¢å‘æ™ºèƒ½ç§»åŠ¨å¥åº·å¹²é¢„çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥å†³ç­–ç‚¹è°ƒåº¦",
      "authors": [
        "Asim H. Gazi",
        "Bhanu Teja Gullapalli",
        "Daiqi Gao",
        "Benjamin M. Marlin",
        "Vivek Shetty",
        "Susan A. Murphy"
      ],
      "abstract": "Timely decision making is critical to the effectiveness of mobile health (mHealth) interventions. At predefined timepoints called \"decision points,\" intelligent mHealth systems such as just-in-time adaptive interventions (JITAIs) estimate an individual's biobehavioral context from sensor or survey data and determine whether and how to intervene. For interventions targeting habitual behavior (e.g., oral hygiene), effectiveness often hinges on delivering support shortly before the target behavior is likely to occur. Current practice schedules decision points at a fixed interval (e.g., one hour) before user-provided behavior times, and the fixed interval is kept the same for all individuals. However, this one-size-fits-all approach performs poorly for individuals with irregular routines, often scheduling decision points after the target behavior has already occurred, rendering interventions ineffective. In this paper, we propose SigmaScheduling, a method to dynamically schedule decision points based on uncertainty in predicted behavior times. When behavior timing is more predictable, SigmaScheduling schedules decision points closer to the predicted behavior time; when timing is less certain, SigmaScheduling schedules decision points earlier, increasing the likelihood of timely intervention. We evaluated SigmaScheduling using real-world data from 68 participants in a 10-week trial of Oralytics, a JITAI designed to improve daily toothbrushing. SigmaScheduling increased the likelihood that decision points preceded brushing events in at least 70% of cases, preserving opportunities to intervene and impact behavior. Our results indicate that SigmaScheduling can advance precision mHealth, particularly for JITAIs targeting time-sensitive, habitual behaviors such as oral hygiene or dietary habits.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SigmaSchedulingï¼Œä¸€ç§åŸºäºé¢„æµ‹è¡Œä¸ºæ—¶é—´ä¸ç¡®å®šæ€§(Uncertainty)æ¥åŠ¨æ€è°ƒåº¦å†³ç­–ç‚¹(Decision Points)çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç§»åŠ¨å¥åº·(mHealth)å¹²é¢„æªæ–½ä¸­ä¼ ç»Ÿå›ºå®šé—´éš”è°ƒåº¦åœ¨é¢å¯¹ç”¨æˆ·ä¸è§„å¾‹ä½œæ¯æ—¶å¤±æ•ˆçš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ†æä¸ªä½“è¡Œä¸ºçš„å¯é¢„æµ‹æ€§ï¼Œåœ¨é¢„æµ‹å‡†ç¡®æ—¶å°†å†³ç­–ç‚¹å®‰æ’åœ¨é è¿‘è¡Œä¸ºå‘ç”Ÿçš„æ—¶åˆ»ï¼Œè€Œåœ¨ä¸ç¡®å®šæ€§è¾ƒé«˜æ—¶åˆ™æå‰å®‰æ’ï¼Œä»¥æœ€å¤§åŒ–å®æ—¶è‡ªé€‚åº”å¹²é¢„(JITAIs)çš„æ—¶æ•ˆæ€§ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨Oralyticsä¸´åºŠè¯•éªŒä¸­68åå‚ä¸è€…ä¸ºæœŸ10å‘¨çš„çœŸå®æ•°æ®è¿›è¡Œäº†éªŒè¯ï¼Œè¯¥è¯•éªŒä¸“æ³¨äºé€šè¿‡JITAIæ”¹å–„æ¯æ—¥åˆ·ç‰™ä¹ æƒ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSigmaSchedulingåœ¨è‡³å°‘70%çš„æƒ…å†µä¸‹ç¡®ä¿äº†å†³ç­–ç‚¹å…ˆäºç›®æ ‡è¡Œä¸ºå‘ç”Ÿï¼Œæœ‰æ•ˆä¿ç•™äº†å¹²é¢„æœºä¼šå¹¶æå‡äº†å¹²é¢„æˆåŠŸç‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†SigmaSchedulingåœ¨ç²¾å‡†ç§»åŠ¨å¥åº·(Precision mHealth)é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå£è…”å«ç”Ÿæˆ–é¥®é£Ÿä¹ æƒ¯ç­‰å¯¹æ—¶é—´æ•æ„Ÿçš„ä¹ æƒ¯æ€§è¡Œä¸ºå¹²é¢„å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 3 figures, Accepted to the IEEE-EMBS International Conference on Body Sensor Networks (BSN) 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10798v2",
      "published_date": "2025-07-14 20:51:02 UTC",
      "updated_date": "2025-09-12 22:42:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:22.801308+00:00"
    },
    {
      "arxiv_id": "2507.12484v1",
      "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education",
      "title_zh": "AI é©±åŠ¨çš„æ•°å­¦è¾…å¯¼ï¼šä¸ªæ€§åŒ–ä¸è‡ªé€‚åº”æ•™è‚²å¹³å°",
      "authors": [
        "JarosÅ‚aw A. Chudziak",
        "Adam Kostka"
      ],
      "abstract": "The growing ubiquity of artificial intelligence (AI), in particular large language models (LLMs), has profoundly altered the way in which learners gain knowledge and interact with learning material, with many claiming that AI positively influences their learning achievements. Despite this advancement, current AI tutoring systems face limitations associated with their reactive nature, often providing direct answers without encouraging deep reflection or incorporating structured pedagogical tools and strategies. This limitation is most apparent in the field of mathematics, in which AI tutoring systems remain underdeveloped. This research addresses the question: How can AI tutoring systems move beyond providing reactive assistance to enable structured, individualized, and tool-assisted learning experiences? We introduce a novel multi-agent AI tutoring platform that combines adaptive and personalized feedback, structured course generation, and textbook knowledge retrieval to enable modular, tool-assisted learning processes. This system allows students to learn new topics while identifying and targeting their weaknesses, revise for exams effectively, and practice on an unlimited number of personalized exercises. This article contributes to the field of artificial intelligence in education by introducing a novel platform that brings together pedagogical agents and AI-driven components, augmenting the field with modular and effective systems for teaching mathematics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰æ•°å­¦é¢†åŸŸAIè¾…å¯¼ç³»ç»Ÿå¾€å¾€ä»…æä¾›è¢«åŠ¨å“åº”ã€ç¼ºä¹æ·±å±‚åæ€å¼•å¯¼åŠç»“æ„åŒ–æ•™å­¦å·¥å…·ç­‰å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šæ™ºèƒ½ä½“(Multi-agent) AIè¾…å¯¼å¹³å°ã€‚è¯¥å¹³å°é€šè¿‡æ•´åˆè‡ªé€‚åº”ä¸ä¸ªæ€§åŒ–åé¦ˆã€ç»“æ„åŒ–è¯¾ç¨‹ç”Ÿæˆä»¥åŠæ•™æçŸ¥è¯†æ£€ç´¢(Knowledge Retrieval)åŠŸèƒ½ï¼Œå®ç°äº†æ¨¡å—åŒ–ä¸”ç”±å·¥å…·è¾…åŠ©çš„æ•°å­¦å­¦ä¹ æµç¨‹ã€‚å­¦ç”Ÿå¯ä»¥åˆ©ç”¨è¯¥ç³»ç»Ÿåœ¨å­¦ä¹ æ–°è¯¾é¢˜çš„åŒæ—¶è¯†åˆ«å¹¶ç²¾å‡†å¼¥è¡¥çŸ¥è¯†è–„å¼±é¡¹ï¼Œè¿›è€Œæé«˜è€ƒè¯•å¤ä¹ æ•ˆç‡å¹¶è¿›è¡Œæ— é™é‡çš„ä¸ªæ€§åŒ–ç»ƒä¹ ã€‚è¯¥ç ”ç©¶é€šè¿‡å°†æ•™å­¦æ™ºèƒ½ä½“(Pedagogical Agents)ä¸å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„ç»„ä»¶æ·±åº¦èåˆï¼Œä¸ºæ•°å­¦æ•™è‚²æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”é«˜æ•ˆçš„è‡ªé€‚åº”å­¦ä¹ æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.12484v1",
      "published_date": "2025-07-14 20:35:16 UTC",
      "updated_date": "2025-07-14 20:35:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:28.539172+00:00"
    },
    {
      "arxiv_id": "2507.10786v2",
      "title": "\"Is it always watching? Is it always listening?\" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots",
      "title_zh": "â€œå®ƒåœ¨æ—¶åˆ»æ³¨è§†å—ï¼Ÿå®ƒåœ¨æ—¶åˆ»å€¾å¬å—ï¼Ÿâ€ï¼šå®¶ç”¨ç¤¾äº¤æœºå™¨äººçš„æƒ…å¢ƒåŒ–éšç§ä¸å®‰å…¨é¡¾è™‘æ¢ç©¶",
      "authors": [
        "Henry Bell",
        "Jabari Kwesi",
        "Hiba Laabadli",
        "Pardis Emami-Naeini"
      ],
      "abstract": "Equipped with artificial intelligence (AI) and advanced sensing capabilities, social robots are gaining interest among consumers in the United States. These robots seem like a natural evolution of traditional smart home devices. However, their extensive data collection capabilities, anthropomorphic features, and capacity to interact with their environment make social robots a more significant security and privacy threat. Increased risks include data linkage, unauthorized data sharing, and the physical safety of users and their homes. It is critical to investigate U.S. users' security and privacy needs and concerns to guide the design of social robots while these devices are still in the early stages of commercialization in the U.S. market. Through 19 semi-structured interviews, we identified significant security and privacy concerns, highlighting the need for transparency, usability, and robust privacy controls to support adoption. For educational applications, participants worried most about misinformation, and in medical use cases, they worried about the reliability of these devices. Participants were also concerned with the data inference that social robots could enable. We found that participants expect tangible privacy controls, indicators of data collection, and context-appropriate functionality.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¾å›½ç”¨æˆ·å¯¹å®¶ç”¨ç¤¾äº¤æœºå™¨äººï¼ˆDomestic Social Robotsï¼‰åœ¨å®‰å…¨ä¸éšç§æ–¹é¢çš„æ‹…å¿§ï¼ŒæŒ‡å‡ºè¿™ç±»è®¾å¤‡ç”±äºå…·å¤‡å…ˆè¿›çš„ä¼ æ„Ÿå’Œæ‹ŸäººåŒ–ç‰¹å¾ï¼Œæ¯”ä¼ ç»Ÿæ™ºèƒ½å®¶å±…è®¾å¤‡é¢ä¸´æ›´ä¸¥é‡çš„æ•°æ®å…³è”ï¼ˆdata linkageï¼‰å’Œç‰©ç†å®‰å…¨é£é™©ã€‚é€šè¿‡19åœºåŠç»“æ„åŒ–è®¿è°ˆï¼ˆsemi-structured interviewsï¼‰ï¼Œç ”ç©¶è¯†åˆ«å‡ºç”¨æˆ·å¯¹é€æ˜åº¦ã€æ˜“ç”¨æ€§å’Œå¼ºå¥éšç§æ§åˆ¶çš„è¿«åˆ‡éœ€æ±‚ã€‚åœ¨æ•™è‚²åº”ç”¨åœºæ™¯ä¸­ï¼Œå‚ä¸è€…è¡¨ç°å‡ºå¯¹è¯¯æŠ¥ï¼ˆmisinformationï¼‰çš„å¿§è™‘ï¼Œè€Œåœ¨åŒ»ç–—ç”¨é€”ä¸‹åˆ™æ›´å…³æ³¨è®¾å¤‡çš„å¯é æ€§ï¼ˆreliabilityï¼‰ã€‚æ­¤å¤–ï¼Œç”¨æˆ·å¯¹æœºå™¨äººèƒ½å¤Ÿå®ç°çš„æ•°æ®æ¨æ–­ï¼ˆdata inferenceï¼‰æ„Ÿåˆ°ä¸å®‰ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œç”¨æˆ·æœŸæœ›è·å¾—æœ‰å½¢çš„éšç§æ§åˆ¶ï¼ˆtangible privacy controlsï¼‰ã€æ•°æ®æ”¶é›†æŒ‡ç¤ºå™¨ä»¥åŠç¬¦åˆç‰¹å®šæƒ…å¢ƒçš„åŠŸèƒ½ã€‚è¿™äº›å‘ç°ä¸ºç¤¾äº¤æœºå™¨äººæ—©æœŸå•†ä¸šåŒ–é˜¶æ®µçš„éšç§è®¾è®¡æä¾›äº†å…³é”®æŒ‡å¯¼ï¼Œä»¥æ”¯æŒç”¨æˆ·å¯¹è¯¥æŠ€æœ¯çš„ä¿¡ä»»ä¸é‡‡ç”¨ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10786v2",
      "published_date": "2025-07-14 20:27:40 UTC",
      "updated_date": "2025-07-16 16:58:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:28.003762+00:00"
    },
    {
      "arxiv_id": "2507.17765v3",
      "title": "ASR-Synchronized Speaker-Role Diarization",
      "title_zh": "ASR åŒæ­¥çš„è¯´è¯äººè§’è‰²æ—¥å¿—",
      "authors": [
        "Arindam Ghosh",
        "Mark Fuhs",
        "Bongjun Kim",
        "Anurag Chowdhury",
        "Monika Woszczyna"
      ],
      "abstract": "Speaker-role diarization (RD), such as doctor vs. patient or lawyer vs. client, is practically often more useful than conventional speaker diarization (SD), which assigns only generic labels (speaker-1, speaker-2). The state-of-the-art end-to-end ASR+RD approach uses a single transducer that serializes word and role predictions (role at the end of a speaker's turn), but at the cost of degraded ASR performance. To address this, we adapt a recent joint ASR+SD framework to ASR+RD by freezing the ASR transducer and training an auxiliary RD transducer in parallel to assign a role to each ASR-predicted word. For this, we first show that SD and RD are fundamentally different tasks, exhibiting different dependencies on acoustic and linguistic information. Motivated by this, we propose (1) task-specific predictor networks and (2) using higher-layer ASR encoder features as input to the RD encoder. Additionally, we replace the blank-shared RNNT loss by cross-entropy loss along the 1-best forced-alignment path to further improve performance while reducing computational and memory requirements during RD training. Experiments on a public and a private dataset of doctor-patient conversations demonstrate that our method outperforms the best baseline with relative reductions of 6.2% and 4.5% in role-based word diarization error rate (R-WDER), respectively",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)ä¸è¯´è¯äººè§’è‰²åˆ†å‰²(Speaker-role Diarization, RD)è”åˆå»ºæ¨¡ä¸­ASRæ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ASRåŒæ­¥çš„è§’è‰²åˆ†å‰²æ¡†æ¶ã€‚è¯¥æ–¹æ³•å€Ÿé‰´äº†æœ€æ–°çš„ASRä¸è¯´è¯äººåˆ†å‰²(ASR+SD)æ¶æ„ï¼Œé€šè¿‡å†»ç»“ASR Transducerå¹¶å¹¶è¡Œè®­ç»ƒè¾…åŠ©çš„RD Transducerï¼Œä»è€Œä¸ºASRé¢„æµ‹çš„æ¯ä¸ªå•è¯åˆ†é…ç‰¹å®šè§’è‰²ã€‚åŸºäºRDä¸SDåœ¨å£°å­¦å’Œè¯­è¨€ä¿¡æ¯ä¾èµ–ä¸Šå­˜åœ¨æœ¬è´¨å·®å¼‚çš„å‘ç°ï¼Œç ”ç©¶è€…è®¾è®¡äº†ä»»åŠ¡ç‰¹å®šçš„é¢„æµ‹å™¨ç½‘ç»œ(Predictor Networks)ï¼Œå¹¶é‡‡ç”¨ASRç¼–ç å™¨çš„é«˜å±‚ç‰¹å¾ä½œä¸ºRDç¼–ç å™¨çš„è¾“å…¥ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶åˆ©ç”¨åŸºäºæœ€ä¼˜å¼ºåˆ¶å¯¹é½è·¯å¾„çš„äº¤å‰ç†µæŸå¤±(Cross-entropy loss)ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œåœ¨æé«˜æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—å‡å°‘äº†è®¡ç®—å’Œå†…å­˜éœ€æ±‚ã€‚åœ¨åŒ»ç”Ÿä¸æ‚£è€…å¯¹è¯æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§’è‰²è¯åˆ†å‰²é”™è¯¯ç‡(R-WDER)ä¸Šä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œåˆ†åˆ«å®ç°äº†6.2%å’Œ4.5%çš„ç›¸å¯¹é™å¹…ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2507.17765v3",
      "published_date": "2025-07-14 20:23:47 UTC",
      "updated_date": "2025-12-20 02:16:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:42.789306+00:00"
    },
    {
      "arxiv_id": "2507.10778v2",
      "title": "Warehouse Spatial Question Answering with LLM Agent",
      "title_zh": "åŸºäº LLM æ™ºèƒ½ä½“çš„ä»“åº“ç©ºé—´é—®ç­”",
      "authors": [
        "Hsiang-Wei Huang",
        "Jen-Hao Cheng",
        "Kuang-Ming Chen",
        "Cheng-Yen Yang",
        "Bahaa Alattar",
        "Yi-Ru Lin",
        "Pyongkun Kim",
        "Sangwon Kim",
        "Kwangju Kim",
        "Chung-I Huang",
        "Jenq-Neng Hwang"
      ],
      "abstract": "Spatial understanding has been a challenging task for existing Multi-modal Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM finetuning to enhance MLLM's spatial understanding ability. In this paper, we present a data-efficient approach. We propose a LLM agent system with strong and advanced spatial reasoning ability, which can be used to solve the challenging spatial question answering task in complex indoor warehouse scenarios. Our system integrates multiple tools that allow the LLM agent to conduct spatial reasoning and API tools interaction to answer the given complicated spatial question. Extensive evaluations on the 2025 AI City Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that our system achieves high accuracy and efficiency in tasks such as object retrieval, counting, and distance estimation. The code is available at: https://github.com/hsiangwei0903/SpatialAgent",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç©ºé—´ç†è§£æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ï¼ˆLLM Agentï¼‰çš„æ•°æ®é«˜æ•ˆå‹ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¤æ‚å®¤å†…ä»“åº“åœºæ™¯ä¸‹çš„ç©ºé—´é—®ç­”ä»»åŠ¡ã€‚è¯¥ç³»ç»Ÿæ‘’å¼ƒäº†ä»¥å¾€ä¾èµ–å¤§è§„æ¨¡å¾®è°ƒçš„æ–¹æ³•ï¼Œé€šè¿‡é›†æˆå¤šç§ç©ºé—´æ¨ç†å·¥å…·å’ŒAPIäº¤äº’æ¥å£ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤æ‚çš„å®¤å†…ç©ºé—´é€»è¾‘ã€‚åœ¨2025 AI City Challenge Physical AI Spatial Intelligence Warehouseæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¯æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ç‰©ä½“æ£€ç´¢ã€ç‰©ä½“è®¡æ•°åŠè·ç¦»ä¼°è®¡ç­‰å…³é”®ä»»åŠ¡ä¸­è¾¾åˆ°äº†æé«˜çš„å‡†ç¡®ç‡ã€‚è¿™é¡¹å·¥ä½œä¸ºæå‡ç‰©ç†ä¸–ç•Œä¸­å…·èº«æ™ºèƒ½çš„ç©ºé—´æ¨ç†èƒ½åŠ›æä¾›äº†å…¨æ–°çš„è·¯å¾„ï¼Œç›¸å…³ä»£ç å·²åœ¨GitHubå¼€æºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "1st Place Solution of the 9th AI City Challenge Track 3",
      "pdf_url": "https://arxiv.org/pdf/2507.10778v2",
      "published_date": "2025-07-14 20:05:55 UTC",
      "updated_date": "2025-08-14 03:48:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:42.292670+00:00"
    },
    {
      "arxiv_id": "2507.10775v1",
      "title": "A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers",
      "title_zh": "é¢å‘æ˜Ÿè½½é£è¡Œè®¡ç®—æœºå®æ—¶èˆªå¤©å™¨åˆ†å‰²çš„æ–°å‹æ•°æ®é›†ä¸æ€§èƒ½åŸºå‡†",
      "authors": [
        "Jeffrey Joan Sam",
        "Janhavi Sathe",
        "Nikhil Chigali",
        "Naman Gupta",
        "Radhey Ruparel",
        "Yicheng Jiang",
        "Janmajay Singh",
        "James W. Berck",
        "Arko Barman"
      ],
      "abstract": "Spacecraft deployed in outer space are routinely subjected to various forms of damage due to exposure to hazardous environments. In addition, there are significant risks to the subsequent process of in-space repairs through human extravehicular activity or robotic manipulation, incurring substantial operational costs. Recent developments in image segmentation could enable the development of reliable and cost-effective autonomous inspection systems. While these models often require large amounts of training data to achieve satisfactory results, publicly available annotated spacecraft segmentation data are very scarce. Here, we present a new dataset of nearly 64k annotated spacecraft images that was created using real spacecraft models, superimposed on a mixture of real and synthetic backgrounds generated using NASA's TTALOS pipeline. To mimic camera distortions and noise in real-world image acquisition, we also added different types of noise and distortion to the images. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to generate performance benchmarks for the dataset under well-defined hardware and inference time constraints to mimic real-world image segmentation challenges for real-time onboard applications in space on NASA's inspector spacecraft. The resulting models, when tested under these constraints, achieved a Dice score of 0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second. The dataset and models for performance benchmark are available at https://github.com/RiceD2KLab/SWiM.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èˆªå¤©å™¨åœ¨å¤ªç©ºç¯å¢ƒä¸­æ˜“å—æŸä¸”ç»´ä¿®æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºæ˜Ÿè½½è®¡ç®—æœº(Onboard Flight Computers)å®æ—¶èˆªå¤©å™¨åˆ†å‰²çš„æ–°å‹æ•°æ®é›†å’Œæ€§èƒ½åŸºå‡†ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨çœŸå®æ¨¡å‹å¹¶ç»“åˆ NASA çš„ TTALOS æµæ°´çº¿ï¼Œæ„å»ºäº†åŒ…å«è¿‘ 6.4 ä¸‡å¼ æ ‡æ³¨å›¾åƒçš„æ•°æ®é›†ï¼Œå¹¶åŠ å…¥äº†å¤šç§å™ªå£°ä¸å¤±çœŸä»¥æ¨¡æ‹ŸçœŸå®çš„å¤ªç©ºå›¾åƒé‡‡é›†ç¯å¢ƒã€‚é€šè¿‡åœ¨ä¸¥æ ¼çš„ç¡¬ä»¶å’Œæ¨ç†æ—¶é—´çº¦æŸä¸‹å¾®è°ƒ YOLOv8 å’Œ YOLOv11 æ¨¡å‹ï¼Œè¯¥ç ”ç©¶ä¸ºè‡ªä¸»å·¡æ£€ä»»åŠ¡è®¾å®šäº†æ€§èƒ½åŸºå‡†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æµ‹è¯•ä¸­è¾¾åˆ°äº† 0.92 çš„ Dice score å’Œ 0.69 çš„ Hausdorff distanceï¼Œå•æ¬¡æ¨ç†æ—¶é—´ä»…çº¦ 0.5 ç§’ï¼Œæœ‰æ•ˆå¹³è¡¡äº†åˆ†å‰²ç²¾åº¦ä¸å®æ—¶æ€§è¦æ±‚ã€‚ç›®å‰ï¼Œè¯¥æ•°æ®é›†åŠç›¸å…³æ¨¡å‹å·²åœ¨ GitHub å¼€æºï¼Œä¸ºå¼€å‘å¯é ã€ä½æˆæœ¬çš„è‡ªä¸»èˆªå¤©å™¨æ£€æµ‹ç³»ç»Ÿæä¾›äº†é‡è¦èµ„æºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10775v1",
      "published_date": "2025-07-14 20:02:40 UTC",
      "updated_date": "2025-07-14 20:02:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:44.611416+00:00"
    },
    {
      "arxiv_id": "2507.10761v1",
      "title": "Detecting AI Assistance in Abstract Complex Tasks",
      "title_zh": "æŠ½è±¡å¤æ‚ä»»åŠ¡ä¸­çš„äººå·¥æ™ºèƒ½è¾…åŠ©æ£€æµ‹",
      "authors": [
        "Tyler King",
        "Nikolos Gurney",
        "John H. Miller",
        "Volkan Ustun"
      ],
      "abstract": "Detecting assistance from artificial intelligence is increasingly important as they become ubiquitous across complex tasks such as text generation, medical diagnosis, and autonomous driving. Aid detection is challenging for humans, especially when looking at abstract task data. Artificial neural networks excel at classification thanks to their ability to quickly learn from and process large amounts of data -- assuming appropriate preprocessing. We posit detecting help from AI as a classification task for such models. Much of the research in this space examines the classification of complex but concrete data classes, such as images. Many AI assistance detection scenarios, however, result in data that is not machine learning-friendly. We demonstrate that common models can effectively classify such data when it is appropriately preprocessed. To do so, we construct four distinct neural network-friendly image formulations along with an additional time-series formulation that explicitly encodes the exploration/exploitation of users, which allows for generalizability to other abstract tasks. We benchmark the quality of each image formulation across three classical deep learning architectures, along with a parallel CNN-RNN architecture that leverages the additional time series to maximize testing performance, showcasing the importance of encoding temporal and spatial quantities for detecting AI aid in abstract tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ–‡æœ¬ç”Ÿæˆã€åŒ»ç–—è¯Šæ–­å’Œè‡ªåŠ¨é©¾é©¶ç­‰æŠ½è±¡å¤æ‚ä»»åŠ¡ä¸­æ£€æµ‹äººå·¥æ™ºèƒ½(AI)è¾…åŠ©çš„éš¾é¢˜ï¼Œå¹¶å°†è¯¥é—®é¢˜è½¬åŒ–ä¸ºæ·±åº¦å­¦ä¹ åˆ†ç±»ä»»åŠ¡ã€‚é’ˆå¯¹æŠ½è±¡ä»»åŠ¡æ•°æ®å¯¹æœºå™¨å­¦ä¹ ä¸å‹å¥½çš„æŒ‘æˆ˜ï¼Œç ”ç©¶è€…å¼€å‘äº†å››ç§å›¾åƒè¡¨ç¤ºæ ¼å¼(image formulations)å’Œä¸€ç§ç¼–ç ç”¨æˆ·æ¢ç´¢ä¸åˆ©ç”¨(exploration/exploitation)è¡Œä¸ºçš„æ—¶é—´åºåˆ—è¡¨ç¤º(time-series formulation)ã€‚é€šè¿‡åœ¨ä¸‰ç§ç»å…¸æ·±åº¦å­¦ä¹ æ¶æ„ä»¥åŠä¸€ç§å¹¶è¡Œçš„CNN-RNNæ¶æ„ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶å±•ç¤ºäº†é€‚å½“çš„é¢„å¤„ç†æŠ€æœ¯åœ¨æå‡æ£€æµ‹å‡†ç¡®ç‡æ–¹é¢çš„æ˜¾è‘—ä½œç”¨ã€‚å®éªŒç»“æœè¯æ˜ï¼Œæ˜¾å¼ç¼–ç æ—¶é—´å’Œç©ºé—´ç‰¹å¾å¯¹äºè¯†åˆ«æŠ½è±¡ä»»åŠ¡ä¸­çš„äººå·¥æ™ºèƒ½è¾…åŠ©(AI aid)è‡³å…³é‡è¦ã€‚è¯¥ç ”ç©¶ä¸ä»…éªŒè¯äº†é€šç”¨æ¨¡å‹åœ¨å¤„ç†æ­¤ç±»éå‹å¥½æ•°æ®æ—¶çš„æ½œåŠ›ï¼Œè¿˜ä¸ºä¸åŒæŠ½è±¡ä»»åŠ¡ä¸­çš„AIæ£€æµ‹æä¾›äº†å…·å¤‡æ³›åŒ–èƒ½åŠ›çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to HCII 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10761v1",
      "published_date": "2025-07-14 19:37:36 UTC",
      "updated_date": "2025-07-14 19:37:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:50.192891+00:00"
    },
    {
      "arxiv_id": "2507.10758v1",
      "title": "IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ ä¸ GraphSAGE æ¨¡å‹çš„ç‰©è”ç½‘æ¶æ„è½¯ä»¶ç½‘ç»œæµé‡æ£€æµ‹",
      "authors": [
        "Nikesh Prajapati",
        "Bimal Karki",
        "Saroj Gopali",
        "Akbar Siami Namin"
      ],
      "abstract": "This paper intends to detect IoT malicious attacks through deep learning models and demonstrates a comprehensive evaluation of the deep learning and graph-based models regarding malicious network traffic detection. The models particularly are based on GraphSAGE, Bidirectional encoder representations from transformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head Attention, together with Bidirectional Long Short-Term Memory (BI-LSTM) Multi-Head Attention and BI-LSTM and LSTM models. The chosen models demonstrated great performance to model temporal patterns and detect feature significance. The observed performance are mainly due to the fact that IoT system traffic patterns are both sequential and diverse, leaving a rich set of temporal patterns for the models to learn. Experimental results showed that BERT maintained the best performance. It achieved 99.94% accuracy rate alongside high precision and recall, F1-score and AUC-ROC score of 99.99% which demonstrates its capabilities through temporal dependency capture. The Multi-Head Attention offered promising results by providing good detection capabilities with interpretable results. On the other side, the Multi-Head Attention model required significant processing time like BI-LSTM variants. The GraphSAGE model achieved good accuracy while requiring the shortest training time but yielded the lowest accuracy, precision, and F1 score compared to the other models",
      "tldr_zh": "æœ¬ç ”ç©¶æ—¨åœ¨åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ£€æµ‹ IoT æ¶æ„ç½‘ç»œæµé‡ï¼Œå¹¶å¯¹ GraphSAGEã€BERTã€TCNã€Multi-Head Attention ä»¥åŠç»“åˆäº† Multi-Head Attention çš„ BI-LSTM ç­‰å¤šç§æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚è¿™äº›æ¨¡å‹åœ¨å¤„ç†å…·æœ‰é¡ºåºæ€§å’Œå¤šæ ·æ€§çš„ IoT æµé‡æ¨¡å¼æ—¶è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å…³é”®çš„ temporal patternsã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBERT æ¨¡å‹å‡­å€Ÿå…¶å¼ºå¤§çš„æ—¶é—´ä¾èµ–æ€§æ•æ‰èƒ½åŠ›ï¼Œåœ¨å‡†ç¡®ç‡ï¼ˆ99.94%ï¼‰ã€F1-score å’Œ AUC-ROCï¼ˆ99.99%ï¼‰ä¸Šå‡è¾¾åˆ°æœ€ä¼˜ã€‚Multi-Head Attention æ¨¡å‹åœ¨æä¾›å¯è§£é‡Šç»“æœçš„åŒæ—¶è¡¨ç°å‡ºè‰¯å¥½çš„æ£€æµ‹èƒ½åŠ›ï¼Œä½†å…¶å¤„ç†æ—¶é—´è¾ƒé•¿ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGraphSAGE æ¨¡å‹è™½ç„¶åœ¨è®­ç»ƒæ•ˆç‡ä¸Šå…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œä½†åœ¨å‡†ç¡®ç‡å’Œç²¾ç¡®åº¦ç­‰æ ¸å¿ƒæŒ‡æ ‡ä¸Šåœ¨æ‰€æœ‰å—è¯•æ¨¡å‹ä¸­æ’åæœ€ä½ã€‚è¯¥ç ”ç©¶ä¸ºé’ˆå¯¹ IoT ç¯å¢ƒçš„æ¶æ„è½¯ä»¶æ£€æµ‹æä¾›äº†æ·±åº¦å­¦ä¹ æ¨¡å‹é€‰æ‹©çš„é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10758v1",
      "published_date": "2025-07-14 19:36:04 UTC",
      "updated_date": "2025-07-14 19:36:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:33:54.395030+00:00"
    },
    {
      "arxiv_id": "2507.10755v1",
      "title": "Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias",
      "title_zh": "é¢éƒ¨è¡¨æƒ…è¯†åˆ«æ•°æ®é›†ä¸­çš„æ‘†æ‹è¡¨æƒ…ä¸ç§æ—åè§å®¡è®¡",
      "authors": [
        "Rina Khan",
        "Catherine Stinson"
      ],
      "abstract": "Facial expression recognition (FER) algorithms classify facial expressions into emotions such as happy, sad, or angry. An evaluative challenge facing FER algorithms is the fall in performance when detecting spontaneous expressions compared to posed expressions. An ethical (and evaluative) challenge facing FER algorithms is that they tend to perform poorly for people of some races and skin colors. These challenges are linked to the data collection practices employed in the creation of FER datasets. In this study, we audit two state-of-the-art FER datasets. We take random samples from each dataset and examine whether images are spontaneous or posed. In doing so, we propose a methodology for identifying spontaneous or posed images. We discover a significant number of images that were posed in the datasets purporting to consist of in-the-wild images. Since performance of FER models vary between spontaneous and posed images, the performance of models trained on these datasets will not represent the true performance if such models were to be deployed in in-the-wild applications. We also observe the skin color of individuals in the samples, and test three models trained on each of the datasets to predict facial expressions of people from various races and skin tones. We find that the FER models audited were more likely to predict people labeled as not white or determined to have dark skin as showing a negative emotion such as anger or sadness even when they were smiling. This bias makes such models prone to perpetuate harm in real life applications.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹ä¸¤ä¸ªæœ€å…ˆè¿›çš„é¢éƒ¨è¡¨æƒ…è¯†åˆ«(Facial Expression Recognition, FER)æ•°æ®é›†è¿›è¡Œäº†å®¡è®¡ï¼Œæ·±å…¥æ¢è®¨äº†æ•°æ®é‡‡é›†å®è·µä¸­å­˜åœ¨çš„æ‘†æ‹è¡¨æƒ…(posed expressions)å’Œç§æ—åè§(racial bias)é—®é¢˜ã€‚é€šè¿‡æå‡ºä¸€ç§è¯†åˆ«è‡ªå‘æˆ–æ‘†æ‹å›¾åƒçš„æ–°æ–¹æ³•è®ºï¼Œç ”ç©¶å‘ç°è®¸å¤šå®£ç§°åŒ…å«è‡ªç„¶åœºæ™¯(in-the-wild)çš„æ•°æ®é›†ä¸­å®é™…ä¸Šå……æ–¥ç€å¤§é‡æ‘†æ‹å›¾åƒï¼Œè¿™ä¼šå¯¼è‡´æ¨¡å‹åœ¨çœŸå®åº”ç”¨ä¸­çš„æ€§èƒ½è¯„ä¼°å¤±å‡†ã€‚ç ”ç©¶è¿›ä¸€æ­¥æµ‹è¯•äº†ä¸‰ç§FERæ¨¡å‹ï¼Œå‘ç°è¿™äº›æ¨¡å‹å¯¹ä¸åŒç§æ—å’Œè‚¤è‰²çš„äººç¾¤è¡¨ç°å‡ºæ˜æ˜¾çš„ä¸å…¬å¹³æ€§ã€‚å®éªŒè¯æ®æ˜¾ç¤ºï¼Œå³ä½¿åœ¨å—è¯•è€…å¾®ç¬‘æ—¶ï¼Œæ¨¡å‹ä¹Ÿæ›´å€¾å‘äºå°†éç™½äººæˆ–æ·±è‚¤è‰²äººç¾¤çš„è¡¨æƒ…é¢„æµ‹ä¸ºæ„¤æ€’æˆ–æ‚²ä¼¤ç­‰è´Ÿé¢æƒ…ç»ªã€‚è¿™ç§ç³»ç»Ÿæ€§åå·®è¡¨æ˜ï¼Œç°æœ‰çš„FERæ¨¡å‹åœ¨å®é™…éƒ¨ç½²ä¸­å¯èƒ½å¼•å‘ä¸¥é‡çš„ä¼¦ç†å±å®³ï¼ŒäºŸéœ€æ”¹è¿›æ•°æ®é›†çš„æ„å»ºè´¨é‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10755v1",
      "published_date": "2025-07-14 19:25:09 UTC",
      "updated_date": "2025-07-14 19:25:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:12.890392+00:00"
    },
    {
      "arxiv_id": "2507.10750v2",
      "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition",
      "title_zh": "äººå·¥æ™ºèƒ½ä¸å‡€é›¶æ’æ”¾è¿›ç¨‹ï¼šèƒ½æºéœ€æ±‚ã€ç¢³æ’æ”¾åŠè½¬å‹æ½œåŠ›",
      "authors": [
        "Pandu Devarakota",
        "Nicolas Tsesmetzis",
        "Faruk O. Alpak",
        "Apurva Gala",
        "Detlef Hohl"
      ],
      "abstract": "Thanks to the availability of massive amounts of data, computing resources, and advanced algorithms, AI has entered nearly every sector. This has sparked significant investment and interest, particularly in building data centers with the necessary hardware and software to develop and operate AI models and AI-based workflows. In this technical review article, we present energy consumption scenarios of data centers and impact on GHG emissions, considering both near-term projections (up to 2030) and long-term outlook (2035 and beyond). We address the quintessential question of whether AI will have a net positive, neutral, or negative impact on CO2 emissions by 2035. Additionally, we discuss AI's potential to automate, create efficient and disruptive workflows across various fields related to energy production, supply and consumption. In the near-term scenario, the growing demand for AI will likely strain computing resources, lead to increase in electricity consumption and therefore associated CO2 emissions. This is due to the power-hungry nature of big data centers and the requirements for training and running of large and complex AI models, as well as the penetration of AI assistant search and applications for public use. However, the long-term outlook could be more promising. AI has the potential to be a game-changer in CO2 reduction. Its ability to further automate and optimize processes across industries, from energy production to logistics, could significantly decrease our carbon footprint. This positive impact is anticipated to outweigh the initial emissions bump, creating value for businesses and society in areas where traditional solutions have fallen short. In essence, AI might cause some initial growing pains for the environment, but it has the potential to support climate mitigation efforts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)åœ¨è¿ˆå‘å‡€é›¶(Net-Zero)è½¬å‹è¿‡ç¨‹ä¸­çš„èƒ½æºéœ€æ±‚åŠå…¶å¯¹æ¸©å®¤æ°”ä½“(GHG)æ’æ”¾çš„å½±å“ã€‚æ–‡ç« é€šè¿‡æŠ€æœ¯ç»¼è¿°åˆ†æäº†æ•°æ®ä¸­å¿ƒçš„èƒ½è€—æƒ…æ™¯ï¼Œå¯¹æ¯”äº†2030å¹´å‰çš„çŸ­æœŸé¢„æµ‹ä¸2035å¹´åçš„é•¿æœŸå±•æœ›ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒçŸ­æœŸå†…ç”±äºå¤§å‹æ¨¡å‹è®­ç»ƒã€è¿è¡Œä»¥åŠæ•°æ®ä¸­å¿ƒçš„é«˜ç”µåŠ›éœ€æ±‚ï¼ŒäºŒæ°§åŒ–ç¢³(CO2)æ’æ”¾é‡å°†å‘ˆç°ä¸Šå‡è¶‹åŠ¿ã€‚ç„¶è€Œï¼Œä»é•¿è¿œæ¥çœ‹ï¼ŒAIåœ¨èƒ½æºç”Ÿäº§ã€ç‰©æµåŠå„å·¥ä¸šæµç¨‹ä¸­çš„è‡ªåŠ¨åŒ–ä¸ä¼˜åŒ–èƒ½åŠ›ï¼Œä½¿å…¶å…·å¤‡æ˜¾è‘—é™ä½ç¢³è¶³è¿¹çš„æ½œåŠ›ã€‚è¿™ç§ç§¯æå½±å“é¢„è®¡å°†æŠµæ¶ˆåˆæœŸçš„æ’æ”¾å¢é•¿ï¼Œä¸ºä¼ä¸šå’Œç¤¾ä¼šåˆ›é€ ä¼ ç»Ÿæ–¹æ¡ˆæ— æ³•å®ç°çš„ä»·å€¼ã€‚æ€»ä½“è€Œè¨€ï¼ŒAIè™½ç„¶åœ¨å‘å±•åˆæœŸä¼šå¸¦æ¥ç¯å¢ƒå‹åŠ›ï¼Œä½†å…¶ä½œä¸ºæ°”å€™å‡ç¼“(Climate Mitigation)çš„é‡è¦å·¥å…·ï¼Œå±•ç°å‡ºæ”¯æŒå…¨çƒèƒ½æºè½¬å‹çš„å·¨å¤§å‰æ™¯ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Technical article to be submitted to Data Centric Engineering Journal",
      "pdf_url": "https://arxiv.org/pdf/2507.10750v2",
      "published_date": "2025-07-14 19:16:27 UTC",
      "updated_date": "2025-11-24 16:52:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:20.385341+00:00"
    },
    {
      "arxiv_id": "2507.14204v1",
      "title": "LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models",
      "title_zh": "LaCacheï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆé•¿ä¸Šä¸‹æ–‡å»ºæ¨¡çš„é˜¶æ¢¯å‹ KV ç¼“å­˜",
      "authors": [
        "Dachuan Shi",
        "Yonggan Fu",
        "Xiangchi Yuan",
        "Zhongzhi Yu",
        "Haoran You",
        "Sixu Li",
        "Xin Dong",
        "Jan Kautz",
        "Pavlo Molchanov",
        "Yingyan",
        "Lin"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have spurred interest in numerous applications requiring robust long-range capabilities, essential for processing extensive input contexts and continuously generating extended outputs. As sequence lengths increase, the number of Key-Value (KV) pairs in LLMs escalates, creating a significant efficiency bottleneck. In this paper, we propose a new KV cache optimization paradigm called LaCache, a training-free method for efficient and accurate generative inference of LLMs. LaCache enables LLMs to simultaneously address both of the critical challenges in long-range modeling: robust long-range capabilities and continuous generation without running out-of-memory (OOM). Specifically, LaCache integrates two key innovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only sequentially (left-to-right within each layer) but also across layers (from shallow to deep), providing an extended span for capturing long-range dependencies under a fixed storage budget, thereby boosting long-range capabilities; and (2) an iterative compaction mechanism that progressively compresses older caches, freeing up space for new tokens within a fixed cache size. This token distance-based dynamic compression enables more effective continuous generation under constrained cache budgets. Experiments across various tasks, benchmarks, and LLM models consistently validate LaCache's effectiveness in enhancing LLMs' long-range capabilities. Our code is available at https://github.com/GATECH-EIC/LaCache.",
      "tldr_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶Key-Value (KV)ç¼“å­˜æ¿€å¢å¯¼è‡´çš„æ•ˆç‡ç“¶é¢ˆï¼Œè¯¥ç ”ç©¶æå‡ºäº†LaCacheï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„ä¼˜åŒ–èŒƒå¼ã€‚LaCacheé€šè¿‡é˜¶æ¢¯å½¢(ladder-shaped)ç¼“å­˜æ¨¡å¼ï¼Œä¸ä»…åœ¨å±‚å†…é¡ºåºå­˜å‚¨KVå¯¹ï¼Œè¿˜å®ç°äº†è·¨å±‚ï¼ˆä»æµ…å±‚åˆ°æ·±å±‚ï¼‰çš„å­˜å‚¨ï¼Œä»è€Œåœ¨å›ºå®šå­˜å‚¨é¢„ç®—ä¸‹æ˜¾è‘—æ‰©å±•äº†æ•æ‰é•¿ç¨‹ä¾èµ–çš„è·¨åº¦ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†è¿­ä»£å‹ç¼©æœºåˆ¶ï¼Œåˆ©ç”¨åŸºäºä»¤ç‰Œ(token)è·ç¦»çš„åŠ¨æ€ç­–ç•¥å‹ç¼©æ—§ç¼“å­˜ï¼Œæœ‰æ•ˆè§£å†³äº†æŒç»­ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å†…å­˜æº¢å‡º(OOM)é—®é¢˜ã€‚åœ¨å¤šé¡¹ä»»åŠ¡å’Œæ¨¡å‹ä¸Šçš„å®éªŒè¯æ˜ï¼ŒLaCacheèƒ½æ˜¾è‘—æå‡LLMsçš„é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ã€‚è¯¥æ–¹æ³•ä¸ºå—é™ç¼“å­˜é¢„ç®—ä¸‹çš„é«˜æ•ˆé•¿ä¸Šä¸‹æ–‡æ¨ç†æä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025. Code: https://github.com/GATECH-EIC/LaCache",
      "pdf_url": "https://arxiv.org/pdf/2507.14204v1",
      "published_date": "2025-07-14 19:09:57 UTC",
      "updated_date": "2025-07-14 19:09:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:19.685028+00:00"
    },
    {
      "arxiv_id": "2507.10741v2",
      "title": "Ground-Compose-Reinforce: Grounding Language in Agentic Behaviours using Limited Data",
      "title_zh": "Ground-Compose-Reinforceï¼šåˆ©ç”¨æœ‰é™æ•°æ®å®ç°æ™ºèƒ½ä½“è¡Œä¸ºä¸­çš„è¯­è¨€å…·èº«",
      "authors": [
        "Andrew C. Li",
        "Toryn Q. Klassen",
        "Andrew Wang",
        "Parand A. Alamdari",
        "Sheila A. McIlraith"
      ],
      "abstract": "Grounding language in perception and action is a key challenge when building situated agents that can interact with humans, or other agents, via language. In the past, addressing this challenge has required manually designing the language grounding or curating massive datasets that associate language with the environment. We propose Ground-Compose-Reinforce, an end-to-end, neurosymbolic framework for training RL agents directly from high-level task specifications--without manually designed reward functions or other domain-specific oracles, and without massive datasets. These task specifications take the form of Reward Machines, automata-based representations that capture high-level task structure and are in some cases autoformalizable from natural language. Critically, we show that Reward Machines can be grounded using limited data by exploiting compositionality. Experiments in a custom Meta-World domain with only 350 labelled pretraining trajectories show that our framework faithfully elicits complex behaviours from high-level specifications--including behaviours that never appear in pretraining--while non-compositional approaches fail.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Ground-Compose-Reinforceï¼Œè¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç¥ç»ç¬¦å·(neurosymbolic)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åœ¨æ„ŸçŸ¥å’ŒåŠ¨ä½œä¸­å®ç°è¯­è¨€è½åœ°(language grounding)æ—¶å¯¹å¤§è§„æ¨¡æ•°æ®é›†æˆ–æ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°çš„ä¾èµ–ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¥–åŠ±æœº(Reward Machines)ä½œä¸ºé«˜å±‚ä»»åŠ¡ç»“æ„çš„è¡¨ç¤ºå½¢å¼ï¼Œå…è®¸ç›´æ¥ä»ä»»åŠ¡è§„èŒƒä¸­è®­ç»ƒå¼ºåŒ–å­¦ä¹ (RL)æ™ºèƒ½ä½“ï¼Œè€Œæ— éœ€æ‰‹åŠ¨è®¾è®¡çš„é¢†åŸŸç‰¹å®šå¥–åŠ±å‡½æ•°ã€‚é€šè¿‡å……åˆ†åˆ©ç”¨ç»„åˆæ€§(compositionality)ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ•°æ®æå…¶æœ‰é™çš„æƒ…å†µä¸‹å®ç°æœ‰æ•ˆçš„è¯­ä¹‰å…³è”ã€‚åœ¨è‡ªå®šä¹‰Meta-Worldé¢†åŸŸçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶ä»…éœ€350æ¡æ ‡è®°çš„é¢„è®­ç»ƒè½¨è¿¹ï¼Œä¾¿èƒ½æˆåŠŸè¯±å‘å‡ºå¤æ‚çš„è¡Œä¸ºï¼Œç”šè‡³åŒ…æ‹¬åœ¨é¢„è®­ç»ƒé˜¶æ®µä»æœªè§è¿‡çš„ä»»åŠ¡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¼ ç»Ÿçš„éç»„åˆå¼æ–¹æ³•åœ¨ç›¸åŒæ¡ä»¶ä¸‹è¡¨ç°ä¸ä½³ã€‚è¯¥æˆæœè¯æ˜äº†åˆ©ç”¨é«˜å±‚è§„èŒƒå’Œç»„åˆæ€§åœ¨å°‘é‡æ•°æ®ä¸‹æ„å»ºå…·èº«æ™ºèƒ½ä½“çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10741v2",
      "published_date": "2025-07-14 19:05:15 UTC",
      "updated_date": "2025-10-26 19:50:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:21.980114+00:00"
    },
    {
      "arxiv_id": "2507.10740v1",
      "title": "Parsing Musical Structure to Enable Meaningful Variations",
      "title_zh": "è§£æéŸ³ä¹ç»“æ„ä»¥å®ç°æœ‰æ„ä¹‰çš„å˜å¥",
      "authors": [
        "Maziar Kanani",
        "Sean O Leary",
        "James McDermott"
      ],
      "abstract": "This paper presents a novel rule-based approach for generating music by varying existing tunes. We parse each tune to find the Pathway Assembly (PA) [ 1], that is a structure representing all repetitions in the tune. The Sequitur algorithm [2 ] is used for this. The result is a grammar. We then carry out mutation on the grammar, rather than on a tune directly. There are potentially 19 types of mutations such as adding, removing, swapping or reversing parts of the grammar that can be applied to the grammars. The system employs one of the mutations randomly in this step to automatically manipulate the grammar. Following the mutation, we need to expand the grammar which returns a new tune. The output after 1 or more mutations will be a new tune related to the original tune. Our study examines how tunes change gradually over the course of multiple mutations. Edit distances, structural complexity and length of the tunes are used to show how a tune is changed after multiple mutations. In addition, the size of effect of each mutation type is analyzed. As a final point, we review the musical aspect of the output tunes. It should be noted that the study only focused on generating new pitch sequences. The study is based on an Irish traditional tune dataset and a list of integers has been used to represent each tune's pitch values.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè§„åˆ™çš„æ–°å‹éŸ³ä¹ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å¯¹ç°æœ‰æ›²è°ƒè¿›è¡Œå˜ä½“å¤„ç†æ¥ç”Ÿæˆæ–°éŸ³ä¹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ Sequitur ç®—æ³•è§£ææ›²è°ƒå¹¶æå– Pathway Assembly (PA) ç»“æ„ï¼Œå°†å…¶è½¬åŒ–ä¸ºä¸€ç§ä»£è¡¨æ›²è°ƒä¸­æ‰€æœ‰é‡å¤éƒ¨åˆ†çš„æ–‡æ³• (Grammar)ã€‚å˜ä½“æ“ä½œå¹¶éç›´æ¥ä½œç”¨äºæ›²è°ƒï¼Œè€Œæ˜¯åœ¨æ–‡æ³•å±‚é¢ä¸Šè¿›è¡Œï¼Œç³»ç»Ÿé€šè¿‡éšæœºåº”ç”¨ 19 ç§çªå˜ç±»å‹ï¼ˆå¦‚æ·»åŠ ã€ç§»é™¤ã€äº¤æ¢æˆ–åè½¬æ–‡æ³•éƒ¨åˆ†ï¼‰æ¥è‡ªåŠ¨æ“çºµç»“æ„ã€‚åœ¨å¯¹æ–‡æ³•è¿›è¡Œä¸€æ¬¡æˆ–å¤šæ¬¡çªå˜å¹¶é‡æ–°å±•å¼€åï¼Œç³»ç»Ÿä¼šç”Ÿæˆä¸åŸæ›²ç›¸å…³çš„æ–°æ›²è°ƒã€‚ç ”ç©¶é€šè¿‡ç¼–è¾‘è·ç¦» (Edit distances)ã€ç»“æ„å¤æ‚åº¦ (Structural complexity) å’Œæ›²è°ƒé•¿åº¦åˆ†æäº†å¤šæ¬¡å˜ä½“è¿‡ç¨‹ä¸­æ›²è°ƒçš„æ¸è¿›å˜åŒ–ä»¥åŠå„çªå˜ç±»å‹çš„å½±å“è§„æ¨¡ã€‚è¯¥ç ”ç©¶ä¸»è¦å…³æ³¨éŸ³é«˜åºåˆ— (Pitch sequences) çš„ç”Ÿæˆï¼Œå¹¶åŸºäºçˆ±å°”å…°ä¼ ç»Ÿæ›²è°ƒæ•°æ®é›†éªŒè¯äº†è¾“å‡ºæ›²è°ƒçš„éŸ³ä¹ç‰¹å¾ã€‚",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10740v1",
      "published_date": "2025-07-14 19:04:49 UTC",
      "updated_date": "2025-07-14 19:04:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:28.733251+00:00"
    },
    {
      "arxiv_id": "2507.11566v1",
      "title": "Emergent Heterogeneous Swarm Control Through Hebbian Learning",
      "title_zh": "åŸºäºèµ«å¸ƒå­¦ä¹ çš„å¼‚æ„ç¾¤ä½“æ¶Œç°æ§åˆ¶",
      "authors": [
        "Fuda van Diggelen",
        "Tugay Alperen KaragÃ¼zel",
        "Andres Garcia Rincon",
        "A. E. Eiben",
        "Dario Floreano",
        "Eliseo Ferrante"
      ],
      "abstract": "In this paper, we introduce Hebbian learning as a novel method for swarm robotics, enabling the automatic emergence of heterogeneity. Hebbian learning presents a biologically inspired form of neural adaptation that solely relies on local information. By doing so, we resolve several major challenges for learning heterogeneous control: 1) Hebbian learning removes the complexity of attributing emergent phenomena to single agents through local learning rules, thus circumventing the micro-macro problem; 2) uniform Hebbian learning rules across all swarm members limit the number of parameters needed, mitigating the curse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian learning rules based on swarm-level behaviour minimises the need for extensive prior knowledge typically required for optimising heterogeneous swarms. This work demonstrates that with Hebbian learning heterogeneity naturally emerges, resulting in swarm-level behavioural switching and in significantly improved swarm capabilities. It also demonstrates how the evolution of Hebbian learning rules can be a valid alternative to Multi Agent Reinforcement Learning in standard benchmarking tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥ Hebbian learning ä½œä¸ºé›†ç¾¤æœºå™¨äºº (swarm robotics) çš„ä¸€ç§æ–°é¢–æ–¹æ³•ï¼Œæ—¨åœ¨å®ç°å¼‚æ„æ€§ (heterogeneity) çš„è‡ªåŠ¨æ¶Œç°ã€‚Hebbian learning æ˜¯ä¸€ç§å—ç”Ÿç‰©å¯å‘çš„ç¥ç»é€‚åº”å½¢å¼ï¼Œä»…ä¾èµ–å±€éƒ¨ä¿¡æ¯ï¼Œé€šè¿‡å±€éƒ¨å­¦ä¹ è§„åˆ™è§£å†³äº†å°†æ¶Œç°ç°è±¡å½’å› äºå•ä¸ªæ™ºèƒ½ä½“çš„å¤æ‚æ€§ï¼Œä»è€Œè§„é¿äº†å¾®è§‚-å®è§‚é—®é¢˜ (micro-macro problem)ã€‚è¯¥æ–¹æ³•åœ¨æ‰€æœ‰é›†ç¾¤æˆå‘˜ä¸­ä½¿ç”¨ç»Ÿä¸€çš„å­¦ä¹ è§„åˆ™ï¼Œæœ‰æ•ˆé™åˆ¶äº†æ‰€éœ€å‚æ•°çš„æ•°é‡ï¼Œç¼“è§£äº†éšé›†ç¾¤è§„æ¨¡æ‰©å¤§è€Œäº§ç”Ÿçš„ç»´åº¦ç¾éš¾ã€‚æ­¤å¤–ï¼ŒåŸºäºé›†ç¾¤å±‚é¢è¡Œä¸ºæ¼”åŒ–çš„å­¦ä¹ è§„åˆ™æœ€å°åŒ–äº†ä¼˜åŒ–å¼‚æ„é›†ç¾¤æ—¶å¯¹å¤§é‡å…ˆéªŒçŸ¥è¯†çš„éœ€æ±‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHebbian learning èƒ½ä½¿å¼‚æ„æ€§è‡ªç„¶äº§ç”Ÿï¼Œå¯¼è‡´é›†ç¾¤å±‚é¢çš„è¡Œä¸ºåˆ‡æ¢å¹¶æ˜¾è‘—æå‡é›†ç¾¤èƒ½åŠ›ã€‚è¯¥å·¥ä½œè¿˜è¯æ˜äº†æ¼”åŒ– Hebbian learning è§„åˆ™åœ¨æ ‡å‡†åŸºå‡†ä»»åŠ¡ä¸­å¯ä»¥ä½œä¸ºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Multi Agent Reinforcement Learning) çš„ä¸€ç§æœ‰æ•ˆæ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.11566v1",
      "published_date": "2025-07-14 18:59:19 UTC",
      "updated_date": "2025-07-14 18:59:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:44.698658+00:00"
    },
    {
      "arxiv_id": "2507.10695v1",
      "title": "Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health",
      "title_zh": "æ¢ç©¶ç”¨æˆ·åœ¨å¿ƒç†å¥åº·é¢†åŸŸä½¿ç”¨é€šç”¨ LLM èŠå¤©æœºå™¨äººçš„å®‰å…¨ä¸éšç§æ€åº¦åŠæ‹…å¿§",
      "authors": [
        "Jabari Kwesi",
        "Jiaxun Cao",
        "Riya Manchanda",
        "Pardis Emami-Naeini"
      ],
      "abstract": "Individuals are increasingly relying on large language model (LLM)-enabled conversational agents for emotional support. While prior research has examined privacy and security issues in chatbots specifically designed for mental health purposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not leverage generative AI. Little empirical research currently measures users' privacy and security concerns, attitudes, and expectations when using general-purpose LLM-enabled chatbots to manage and improve mental health. Through 21 semi-structured interviews with U.S. participants, we identified critical misconceptions and a general lack of risk awareness. Participants conflated the human-like empathy exhibited by LLMs with human-like accountability and mistakenly believed that their interactions with these chatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures with a licensed therapist. We introduce the concept of \"intangible vulnerability,\" where emotional or psychological disclosures are undervalued compared to more tangible forms of information (e.g., financial or location-based data). To address this, we propose recommendations to safeguard user mental health disclosures with general-purpose LLM-enabled chatbots more effectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”¨æˆ·åœ¨åˆ©ç”¨é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGeneral-Purpose LLMï¼‰èŠå¤©æœºå™¨äººå¯»æ±‚å¿ƒç†å¥åº·æ”¯æŒæ—¶ï¼Œå¯¹å…¶å®‰å…¨ä¸éšç§çš„æ€åº¦åŠæ‹…å¿§ã€‚é€šè¿‡å¯¹21åç¾å›½å‚ä¸è€…è¿›è¡Œçš„åŠç»“æ„åŒ–è®¿è°ˆï¼ˆSemi-structured interviewsï¼‰ï¼Œç ”ç©¶æ­ç¤ºäº†ç”¨æˆ·æ™®éå­˜åœ¨ä¸¥é‡çš„è¯¯è§£åŠé£é™©æ„è¯†åŒ®ä¹ã€‚å‚ä¸è€…å¾€å¾€å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç°å‡ºçš„æ‹ŸäººåŒ–ç§»æƒ…ä¸äººç±»çš„é—®è´£åˆ¶ï¼ˆAccountabilityï¼‰æ··ä¸ºä¸€è°ˆï¼Œå¹¶é”™è¯¯åœ°è®¤ä¸ºæ­¤ç±»äº’åŠ¨å—åˆ°ç±»ä¼¼äºåŒ»ç–—ä¿é™©æµé€šä¸è´£ä»»æ³•æ¡ˆï¼ˆHIPAAï¼‰ç­‰æ³•è§„çš„ä¿æŠ¤ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†â€œæ— å½¢è„†å¼±æ€§â€ï¼ˆIntangible vulnerabilityï¼‰çš„æ¦‚å¿µï¼ŒæŒ‡å‡ºç”¨æˆ·ç›¸æ¯”äºè´¢åŠ¡æˆ–ä½ç½®ç­‰æœ‰å½¢æ•°æ®ï¼Œå¾€å¾€ä½ä¼°äº†å¿ƒç†æƒ…æ„ŸæŠ«éœ²çš„éšç§ä»·å€¼ã€‚æœ€åï¼Œè¯¥ç ”ç©¶é’ˆå¯¹å¦‚ä½•æ›´æœ‰æ•ˆåœ°ä¿æŠ¤ç”¨æˆ·åœ¨é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGeneral-Purpose LLMï¼‰ä¸­çš„å¿ƒç†å¥åº·éšç§æŠ«éœ²æå‡ºäº†é’ˆå¯¹æ€§å»ºè®®ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to the 34th USENIX Security Symposium",
      "pdf_url": "https://arxiv.org/pdf/2507.10695v1",
      "published_date": "2025-07-14 18:10:21 UTC",
      "updated_date": "2025-07-14 18:10:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:35.691293+00:00"
    },
    {
      "arxiv_id": "2507.10678v2",
      "title": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks",
      "title_zh": "è¿›åˆ¶åŠ æ³•åº•å±‚å¯¹ç§°æ€§çš„ç¾¤è®ºåˆ†æåŠå…¶ç¥ç»ç½‘ç»œå¯å­¦ä¹ æ€§ç ”ç©¶",
      "authors": [
        "Cutter Dawes",
        "Simon Segert",
        "Kamesh Krishnamurthy",
        "Jonathan D. Cohen"
      ],
      "abstract": "A major challenge in the use of neural networks both for modeling human cognitive function and for artificial intelligence is the design of systems with the capacity to efficiently learn functions that support radical generalization. At the roots of this is the capacity to discover and implement symmetry functions. In this paper, we investigate a paradigmatic example of radical generalization through the use of symmetry: base addition. We present a group theoretic analysis of base addition, a fundamental and defining characteristic of which is the carry function -- the transfer of the remainder, when a sum exceeds the base modulus, to the next significant place. Our analysis exposes a range of alternative carry functions for a given base, and we introduce quantitative measures to characterize these. We then exploit differences in carry functions to probe the inductive biases of neural networks in symmetry learning, by training neural networks to carry out base addition using different carries, and comparing efficacy and rate of learning as a function of their structure. We find that even simple neural networks can achieve radical generalization with the right input format and carry function, and that learnability is closely correlated with carry function structure. We then discuss the relevance this has for cognitive science and machine learning.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡ç¾¤è®º(Group Theory)åˆ†æäº†åŸºæ•°åŠ æ³•(Base Addition)åº•å±‚çš„å¯¹ç§°æ€§ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†ç¥ç»ç½‘ç»œå¯¹è¿™äº›å¯¹ç§°æ€§çš„å¯å­¦ä¹ æ€§ã€‚ç ”ç©¶é‡ç‚¹èšç„¦äºåŠ æ³•çš„æ ¸å¿ƒç‰¹å¾â€”â€”è¿›ä½å‡½æ•°(Carry Function)ï¼Œåˆ©ç”¨ç¾¤è®ºæ¡†æ¶æ­ç¤ºäº†ç‰¹å®šåŸºæ•°ä¸‹çš„ä¸€ç³»åˆ—æ›¿ä»£è¿›ä½æœºåˆ¶ï¼Œå¹¶å¼•å…¥å®šé‡æŒ‡æ ‡å¯¹å…¶ç»“æ„è¿›è¡Œè¡¨å¾ã€‚é€šè¿‡è®­ç»ƒç¥ç»ç½‘ç»œæ‰§è¡Œä¸åŒè¿›ä½é€»è¾‘çš„åŠ æ³•ä»»åŠ¡ï¼Œç ”ç©¶äººå‘˜ç³»ç»Ÿåœ°æ¢æµ‹äº†æ¨¡å‹åœ¨å¯¹ç§°æ€§å­¦ä¹ ä¸­çš„å½’çº³åç½®(Inductive Biases)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨åŒ¹é…åˆé€‚çš„è¾“å…¥æ ¼å¼å’Œè¿›ä½å‡½æ•°çš„å‰æä¸‹ï¼Œç®€å•çš„ç¥ç»ç½‘ç»œä¹Ÿèƒ½å±•ç°å‡ºå“è¶Šçš„æ¿€è¿›æ³›åŒ–(Radical Generalization)èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°æ¨¡å‹çš„å¯å­¦ä¹ æ€§ä¸è¿›ä½å‡½æ•°çš„å‡ ä½•ç»“æ„ç‰¹å¾é«˜åº¦ç›¸å…³ï¼Œè¯¥å‘ç°ä¸ºè®¤çŸ¥ç§‘å­¦å’Œæœºå™¨å­¦ä¹ é¢†åŸŸæ„å»ºå…·å¤‡æ³›åŒ–èƒ½åŠ›çš„ç³»ç»Ÿæä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 6 figures; typos corrected",
      "pdf_url": "https://arxiv.org/pdf/2507.10678v2",
      "published_date": "2025-07-14 18:01:38 UTC",
      "updated_date": "2025-07-16 01:31:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:35.387997+00:00"
    },
    {
      "arxiv_id": "2507.10552v1",
      "title": "Self-supervised Learning on Camera Trap Footage Yields a Strong Universal Face Embedder",
      "title_zh": "åŸºäºçº¢å¤–ç›¸æœºå½±åƒçš„è‡ªç›‘ç£å­¦ä¹ æ„å»ºå¼ºå¤§çš„é€šç”¨é¢éƒ¨åµŒå…¥å™¨",
      "authors": [
        "Vladimir Iashin",
        "Horace Lee",
        "Dan Schofield",
        "Andrew Zisserman"
      ],
      "abstract": "Camera traps are revolutionising wildlife monitoring by capturing vast amounts of visual data; however, the manual identification of individual animals remains a significant bottleneck. This study introduces a fully self-supervised approach to learning robust chimpanzee face embeddings from unlabeled camera-trap footage. Leveraging the DINOv2 framework, we train Vision Transformers on automatically mined face crops, eliminating the need for identity labels. Our method demonstrates strong open-set re-identification performance, surpassing supervised baselines on challenging benchmarks such as Bossou, despite utilising no labelled data during training. This work underscores the potential of self-supervised learning in biodiversity monitoring and paves the way for scalable, non-invasive population studies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çº¢å¤–ç›¸æœº(Camera traps)åœ¨é‡ç”ŸåŠ¨ç‰©ç›‘æµ‹ä¸­é¢ä¸´çš„äººå·¥è¯†åˆ«ä¸ªä½“ç“¶é¢ˆï¼Œæå‡ºäº†ä¸€ç§å®Œå…¨è‡ªç›‘ç£(self-supervised)çš„æ–¹æ³•ï¼Œç”¨äºä»æ— æ ‡ç­¾é•œå¤´ä¸­å­¦ä¹ é²æ£’çš„é»‘çŒ©çŒ©é¢éƒ¨åµŒå…¥(face embeddings)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ DINOv2 æ¡†æ¶åœ¨è‡ªåŠ¨æå–çš„é¢éƒ¨å›¾åƒä¸Šè®­ç»ƒè§†è§‰å˜æ¢å™¨(Vision Transformers)ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†å¯¹èº«ä»½æ ‡ç­¾çš„éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ Bossou ç­‰æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„å¼€æ”¾é›†é‡è¯†åˆ«(open-set re-identification)èƒ½åŠ›ï¼Œå…¶æ€§èƒ½ç”šè‡³åœ¨ä¸ä½¿ç”¨æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹è¶…è¶Šäº†æœ‰ç›‘ç£å­¦ä¹ (supervised)çš„åŸºçº¿æ¨¡å‹ã€‚è¿™é¡¹ç ”ç©¶çªæ˜¾äº†è‡ªç›‘ç£å­¦ä¹ åœ¨ç”Ÿç‰©å¤šæ ·æ€§ç›‘æµ‹ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºå¼€å±•å¤§è§„æ¨¡ã€éä¾µå…¥æ€§çš„ç§ç¾¤ç ”ç©¶æä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication. Project page, code and weights: https://www.robots.ox.ac.uk/~vgg/research/ChimpUFE/",
      "pdf_url": "https://arxiv.org/pdf/2507.10552v1",
      "published_date": "2025-07-14 17:59:59 UTC",
      "updated_date": "2025-07-14 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:41.128403+00:00"
    },
    {
      "arxiv_id": "2507.10548v1",
      "title": "EmbRACE-3K: Embodied Reasoning and Action in Complex Environments",
      "title_zh": "EmbRACE-3Kï¼šå¤æ‚ç¯å¢ƒä¸‹çš„å…·èº«æ¨ç†ä¸è¡ŒåŠ¨",
      "authors": [
        "Mingxian Lin",
        "Wei Huang",
        "Yitang Li",
        "Chengjie Jiang",
        "Kui Wu",
        "Fangwei Zhong",
        "Shengju Qian",
        "Xin Wang",
        "Xiaojuan Qi"
      ],
      "abstract": "Recent advanced vision-language models(VLMs) have demonstrated strong performance on passive, offline image and video understanding tasks. However, their effectiveness in embodied settings, which require online interaction and active scene understanding remains limited. In such scenarios, an agent perceives the environment from a first-person perspective, with each action dynamically shaping subsequent observations. Even state-of-the-art models such as GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment interactions, exhibiting clear limitations in spatial reasoning and long-horizon planning. To address this gap, we introduce EmRACE-3K, a dataset of over 3,000 language-guided tasks situated in diverse, photorealistic environments constructed using Unreal Engine and the UnrealCV-Zoo framework. The tasks encompass a wide range of embodied challenges, including navigation, object manipulation, and multi-stage goal execution. Each task unfolds as a multi-step trajectory, pairing first-person visual observations with high-level instructions, grounded actions, and natural language rationales that express the agent's intent at every step. Using EmRACE-3K, we establish a benchmark to evaluate the embodied reasoning capabilities of VLMs across three key dimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage Goal Execution. In zero-shot settings, all models achieve success rates below 20%, underscoring the challenge posed by our benchmark and the current limitations of VLMs in interactive environments. To demonstrate the utility of EmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learning followed by reinforcement learning. This approach yields substantial improvements across all three challenge categories, highlighting the dataset's effectiveness in enabling the development of embodied reasoning capabilities.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å½“å‰è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨å…·èº«æ™ºèƒ½(Embodied AI)é¢†åŸŸä¸­ï¼Œå°¤å…¶æ˜¯åœ¨å¼€æ”¾ç¯å¢ƒäº¤äº’ã€ç©ºé—´æ¨ç†å’Œé•¿ç¨‹è§„åˆ’æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†EmbRACE-3Kæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«3000å¤šä¸ªç”±è¯­è¨€æŒ‡å¯¼çš„å…·èº«ä»»åŠ¡ï¼Œåˆ©ç”¨Unreal Engineå’ŒUnrealCV-Zooæ¡†æ¶æ„å»ºäº†å¤šæ ·åŒ–ä¸”å†™å®çš„å¤æ‚ç¯å¢ƒï¼Œæ¶µç›–äº†å¯¼èˆªã€ç‰©ä½“æ“æ§åŠå¤šé˜¶æ®µç›®æ ‡æ‰§è¡Œã€‚ä»»åŠ¡è½¨è¿¹å°†ç¬¬ä¸€äººç§°è§†è§‰è§‚æµ‹ä¸é«˜å±‚æŒ‡ä»¤ã€åŸºå…ƒåŠ¨ä½œ(Grounded Actions)ä»¥åŠè¡¨è¾¾æ™ºèƒ½ä½“æ„å›¾çš„è‡ªç„¶è¯­è¨€æ¨ç†(Natural Language Rationales)ç›¸ç»“åˆã€‚åŸºå‡†æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œå³ä¾¿å¦‚GPT-4oç­‰é¡¶å°–æ¨¡å‹åœ¨é›¶æ ·æœ¬(Zero-shot)è®¾ç½®ä¸‹çš„æˆåŠŸç‡ä¹Ÿå‡ä½äº20%ï¼Œçªæ˜¾äº†äº¤äº’å¼ç¯å¢ƒçš„æŒ‘æˆ˜æ€§ã€‚é€šè¿‡å¯¹Qwen2.5-VL-7Bè¿›è¡Œç›‘ç£å­¦ä¹ (Supervised Learning)å’Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)å¾®è°ƒï¼Œæ¨¡å‹åœ¨æ¢ç´¢ã€åŠ¨æ€ç©ºé—´è¯­ä¹‰æ¨ç†åŠå¤šé˜¶æ®µç›®æ ‡æ‰§è¡Œç­‰æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†EmbRACE-3Kåœ¨å¼€å‘å…·èº«æ¨ç†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://mxllc.github.io/EmbRACE-3K/",
      "pdf_url": "https://arxiv.org/pdf/2507.10548v1",
      "published_date": "2025-07-14 17:59:46 UTC",
      "updated_date": "2025-07-14 17:59:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:43.984139+00:00"
    },
    {
      "arxiv_id": "2507.10546v2",
      "title": "Disentangling Neural Disjunctive Normal Form Models",
      "title_zh": "ç¥ç»æå–èŒƒå¼æ¨¡å‹çš„è§£è€¦",
      "authors": [
        "Kexin Gu Baugh",
        "Vincent Perreault",
        "Matthew Baugh",
        "Luke Dickens",
        "Katsumi Inoue",
        "Alessandra Russo"
      ],
      "abstract": "Neural Disjunctive Normal Form (DNF) based models are powerful and interpretable approaches to neuro-symbolic learning and have shown promising results in classification and reinforcement learning settings without prior knowledge of the tasks. However, their performance is degraded by the thresholding of the post-training symbolic translation process. We show here that part of the performance degradation during translation is due to its failure to disentangle the learned knowledge represented in the form of the networks' weights. We address this issue by proposing a new disentanglement method; by splitting nodes that encode nested rules into smaller independent nodes, we are able to better preserve the models' performance. Through experiments on binary, multiclass, and multilabel classification tasks (including those requiring predicate invention), we demonstrate that our disentanglement method provides compact and interpretable logical representations for the neural DNF-based models, with performance closer to that of their pre-translation counterparts. Our code is available at https://github.com/kittykg/disentangling-ndnf-classification.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹åŸºäºç¥ç»æå–èŒƒå¼(Neural Disjunctive Normal Form, DNF)çš„æ¨¡å‹åœ¨ç¥ç»ç¬¦å·å­¦ä¹ ä¸­çš„æ€§èƒ½é€€åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è§£è€¦(disentanglement)æ–¹æ³•ã€‚ç°æœ‰æ¨¡å‹åœ¨è®­ç»ƒåçš„ç¬¦å·åŒ–è½¬æ¢è¿‡ç¨‹ä¸­ï¼Œç”±äºé˜ˆå€¼å¤„ç†ä»¥åŠæ— æ³•æœ‰æ•ˆè§£è€¦ç½‘ç»œæƒé‡ä¸­å­˜å‚¨çš„çŸ¥è¯†ï¼Œå¸¸å¯¼è‡´æ€§èƒ½å—æŸã€‚è¯¥æ–¹æ³•é€šè¿‡å°†ç¼–ç åµŒå¥—è§„åˆ™(nested rules)çš„èŠ‚ç‚¹æ‹†åˆ†ä¸ºæ›´å°çš„ç‹¬ç«‹èŠ‚ç‚¹ï¼Œèƒ½å¤Ÿæ›´å®Œæ•´åœ°ä¿ç•™æ¨¡å‹çš„åŸå§‹æ€§èƒ½ã€‚ç ”ç©¶è€…åœ¨äºŒå…ƒã€å¤šç±»åŠå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ï¼ˆåŒ…æ‹¬æ¶‰åŠè°“è¯å‘æ˜(predicate invention)çš„ä»»åŠ¡ï¼‰ä¸­è¿›è¡Œäº†å¹¿æ³›å®éªŒã€‚ç»“æœè¯æ˜ï¼Œè¯¥è§£è€¦æ–¹æ³•èƒ½ä¸ºåŸºäºNeural DNFçš„æ¨¡å‹æä¾›ç®€æ´ä¸”å…·æœ‰é«˜åº¦å¯è§£é‡Šæ€§çš„é€»è¾‘è¡¨ç¤ºï¼Œå¹¶ä½¿å…¶æ€§èƒ½è¡¨ç°æ›´æ¥è¿‘è½¬æ¢å‰çš„ç¥ç»ç½‘ç»œæ°´å¹³ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeSy 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10546v2",
      "published_date": "2025-07-14 17:59:33 UTC",
      "updated_date": "2025-08-01 11:51:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:34:55.536088+00:00"
    },
    {
      "arxiv_id": "2507.10542v1",
      "title": "ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions",
      "title_zh": "ScaffoldAvatarï¼šåŸºäºåˆ†å—è¡¨æƒ…çš„é«˜ä¿çœŸé«˜æ–¯å¤´åƒ",
      "authors": [
        "Shivangi Aneja",
        "Sebastian Weiss",
        "Irene Baeza",
        "Prashanth Chandran",
        "Gaspard Zoss",
        "Matthias NieÃŸner",
        "Derek Bradley"
      ],
      "abstract": "Generating high-fidelity real-time animated sequences of photorealistic 3D head avatars is important for many graphics applications, including immersive telepresence and movies. This is a challenging problem particularly when rendering digital avatar close-ups for showing character's facial microfeatures and expressions. To capture the expressive, detailed nature of human heads, including skin furrowing and finer-scale facial movements, we propose to couple locally-defined facial expressions with 3D Gaussian splatting to enable creating ultra-high fidelity, expressive and photorealistic 3D head avatars. In contrast to previous works that operate on a global expression space, we condition our avatar's dynamics on patch-based local expression features and synthesize 3D Gaussians at a patch level. In particular, we leverage a patch-based geometric 3D face model to extract patch expressions and learn how to translate these into local dynamic skin appearance and motion by coupling the patches with anchor points of Scaffold-GS, a recent hierarchical scene representation. These anchors are then used to synthesize 3D Gaussians on-the-fly, conditioned by patch-expressions and viewing direction. We employ color-based densification and progressive training to obtain high-quality results and faster convergence for high resolution 3K training images. By leveraging patch-level expressions, ScaffoldAvatar consistently achieves state-of-the-art performance with visually natural motion, while encompassing diverse facial expressions and styles in real time.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ScaffoldAvatarï¼Œä¸€ç§æ—¨åœ¨ç”Ÿæˆå…·æœ‰é«˜ä¿çœŸé¢éƒ¨å¾®ç‰¹å¾å’Œè¡¨æƒ…çš„å®æ—¶åŠ¨æ€ 3D å¤´éƒ¨å¤´åƒçš„æ–°æ–¹æ³•ã€‚ä¸ä»¥å¾€åŸºäºå…¨å±€è¡¨æƒ…ç©ºé—´çš„æ–¹æ³•ä¸åŒï¼ŒScaffoldAvatar å°†å¤´åƒåŠ¨åŠ›å­¦å»ºç«‹åœ¨ Patch-based å±€éƒ¨è¡¨æƒ…ç‰¹å¾ä¹‹ä¸Šï¼Œå¹¶åœ¨ Patch çº§åˆ«åˆæˆ 3D Gaussians ä»¥æ•æ‰çš®è‚¤çš±è¤¶ç­‰ç»†èŠ‚ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ Patch-based å‡ ä½• 3D äººè„¸æ¨¡å‹æå–å±€éƒ¨è¡¨æƒ…ï¼Œå¹¶å°†å…¶ä¸åˆ†å±‚åœºæ™¯è¡¨ç¤ºæ¨¡å‹ Scaffold-GS çš„é”šç‚¹(anchors)è€¦åˆï¼Œä»è€Œå®ç°å±€éƒ¨åŠ¨æ€çš®è‚¤å¤–è§‚ä¸è¿åŠ¨çš„ç²¾å‡†è½¬åŒ–ã€‚é€šè¿‡å¼•å…¥ Color-based densification å’Œæ¸è¿›å¼è®­ç»ƒ(progressive training)ç­–ç•¥ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç† 3K é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶å±•ç°å‡ºå“è¶Šçš„è´¨é‡å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚å®éªŒè¯æ˜ï¼ŒScaffoldAvatar åœ¨å¤šç§è¡¨æƒ…å’Œé£æ ¼ä¸‹å‡è¾¾åˆ°äº† State-of-the-art æ€§èƒ½ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒè§†è§‰è‡ªç„¶è¿åŠ¨çš„åŒæ—¶å®ç°é«˜è´¨é‡çš„å®æ—¶æ¸²æŸ“ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "(SIGGRAPH 2025) Paper Video: https://youtu.be/VyWkgsGdbkk Project Page: https://shivangi-aneja.github.io/projects/scaffoldavatar/",
      "pdf_url": "https://arxiv.org/pdf/2507.10542v1",
      "published_date": "2025-07-14 17:59:03 UTC",
      "updated_date": "2025-07-14 17:59:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:04.463693+00:00"
    },
    {
      "arxiv_id": "2507.10535v2",
      "title": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks",
      "title_zh": "CodeJudgeBenchï¼šé’ˆå¯¹ç¼–ç¨‹ä»»åŠ¡çš„å¤§è¯­è¨€æ¨¡å‹è£åˆ¤èƒ½åŠ›åŸºå‡†æµ‹è¯•",
      "authors": [
        "Hongchao Jiang",
        "Yiming Chen",
        "Yushi Cao",
        "Hung-yi Lee",
        "Robby T. Tan"
      ],
      "abstract": "Large Language Models (LLMs) have significantly advanced the state-of-the-art in various coding tasks. Beyond directly answering user queries, LLMs can also serve as judges, assessing and comparing the quality of responses generated by other models. Such an evaluation capability is crucial both for benchmarking different LLMs and for improving response quality through response ranking. However, despite the growing adoption of the LLM-as-a-Judge paradigm, its effectiveness in coding scenarios remains underexplored due to the absence of dedicated benchmarks. To address this gap, we introduce CodeJudgeBench, a benchmark explicitly designed to evaluate the performance of LLM-as-a-Judge models across three critical coding tasks: code generation, code repair, and unit test generation. Through comprehensive benchmarking of 26 LLM-as-a-Judge models, we find that recent thinking models significantly outperform non-thinking models on our carefully designed code judging tasks. Notably, even relatively small thinking models, such as Qwen3-8B, can outperform specially trained LLM-as-a-Judge models up to 70B in size. Nevertheless, all models still exhibit significant randomness in their judgment of coding tasks. For pairwise judging tasks, simply changing the order in which responses are presented can substantially impact accuracy. In addition, when judging code and unit tests written by different LLMs, LLM-as-a-Judge models also show variance in performance. This sensitivity raises concerns about the reliability and consistency of LLM-as-a-Judge in coding scenarios. Lastly, we study optimal prompting strategies for LLM-as-a-Judge. We find that using pair-wise comparison outperforms scalar point-wise judging. Furthermore, retaining comments and reasoning in the full, unprocessed LLM response leads to improved judge performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CodeJudgeBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼° LLM-as-a-Judge åœ¨ä»£ç ç”Ÿæˆã€ä»£ç ä¿®å¤å’Œå•å…ƒæµ‹è¯•ç”Ÿæˆç­‰å…³é”®ç¼–ç¨‹ä»»åŠ¡ä¸­è¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚é€šè¿‡å¯¹ 26 ä¸ªæ¨¡å‹è¿›è¡Œå…¨é¢æµ‹è¯„ï¼Œç ”ç©¶å‘ç°æœ€æ–°çš„ thinking models åœ¨ä»£ç è¯„å®¡ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äº non-thinking modelsï¼Œç”šè‡³å°è§„æ¨¡çš„ Qwen3-8B ä¹Ÿèƒ½è¶…è¶Šéƒ¨åˆ† 70B è§„æ¨¡çš„ä¸“é—¨è¯„å®¡æ¨¡å‹ã€‚ç„¶è€Œï¼Œå®éªŒæ­ç¤ºäº† LLM-as-a-Judge åœ¨ç¼–ç¨‹åœºæ™¯ä¸­å­˜åœ¨æ˜¾è‘—çš„éšæœºæ€§ä¸ä¸ä¸€è‡´æ€§ï¼Œä¾‹å¦‚ pairwise judging çš„å‡†ç¡®æ€§ä¼šå—åˆ°å“åº”å‘ˆç°é¡ºåºçš„ä¸¥é‡å½±å“ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ¢è®¨äº†æœ€ä½³æç¤ºç­–ç•¥ï¼Œè¯æ˜ pairwise comparison çš„æ•ˆæœä¼˜äº scalar point-wise judgingï¼Œä¸”åœ¨è¯„å®¡æ—¶ä¿ç•™å®Œæ•´çš„æ³¨é‡Šä¸æ¨ç†è¿‡ç¨‹èƒ½æœ‰æ•ˆæå‡æ¨¡å‹æ€§èƒ½ã€‚è¿™äº›å‘ç°ä¸ºæ„å»ºæ›´å¯é ã€ä¸€è‡´çš„è‡ªåŠ¨ä»£ç è¯„ä¼°ç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Dataset is available at https://huggingface.co/datasets/mattymchen/codejudgebench",
      "pdf_url": "https://arxiv.org/pdf/2507.10535v2",
      "published_date": "2025-07-14 17:56:29 UTC",
      "updated_date": "2025-08-14 17:58:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:04.630882+00:00"
    },
    {
      "arxiv_id": "2507.10534v2",
      "title": "WildFX: A DAW-Powered Pipeline for In-the-Wild Audio FX Graph Modeling",
      "title_zh": "WildFXï¼šåŸºäº DAW é©±åŠ¨çš„å®å¢ƒéŸ³é¢‘éŸ³æ•ˆå›¾å»ºæ¨¡æµæ°´çº¿",
      "authors": [
        "Qihui Yang",
        "Taylor Berg-Kirkpatrick",
        "Julian McAuley",
        "Zachary Novack"
      ],
      "abstract": "Despite rapid progress in end-to-end AI music generation, AI-driven modeling of professional Digital Signal Processing (DSP) workflows remains challenging. In particular, while there is growing interest in neural black-box modeling of audio effect graphs (e.g. reverb, compression, equalization), AI-based approaches struggle to replicate the nuanced signal flow and parameter interactions used in professional workflows. Existing differentiable plugin approaches often diverge from real-world tools, exhibiting inferior performance relative to simplified neural controllers under equivalent computational constraints. We introduce WildFX, a pipeline containerized with Docker for generating multi-track audio mixing datasets with rich effect graphs, powered by a professional Digital Audio Workstation (DAW) backend. WildFX supports seamless integration of cross-platform commercial plugins or any plugins in the wild, in VST/VST3/LV2/CLAP formats, enabling structural complexity (e.g., sidechains, crossovers) and achieving efficient parallelized processing. A minimalist metadata interface simplifies project/plugin configuration. Experiments demonstrate the pipeline's validity through blind estimation of mixing graphs, plugin/gain parameters, and its ability to bridge AI research with practical DSP demands. The code is available on: https://github.com/IsaacYQH/WildFX.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½åœ¨ä¸“ä¸šæ•°å­—ä¿¡å·å¤„ç†(DSP)å·¥ä½œæµå»ºæ¨¡ä¸­éš¾ä»¥æ¨¡æ‹Ÿå¤æ‚ä¿¡å·æµå’Œå‚æ•°äº¤äº’çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†WildFXï¼Œä¸€ä¸ªåŸºäºDockerå®¹å™¨åŒ–æŠ€æœ¯ä¸”ç”±ä¸“ä¸šæ•°å­—éŸ³é¢‘å·¥ä½œç«™(DAW)åç«¯é©±åŠ¨çš„æµæ°´çº¿ã€‚WildFXèƒ½å¤Ÿç”Ÿæˆå¸¦æœ‰ä¸°å¯ŒéŸ³é¢‘æ•ˆæœå›¾(FX Graph)çš„å¤šè½¨éŸ³é¢‘æ··éŸ³æ•°æ®é›†ï¼Œå¹¶æ”¯æŒVSTã€VST3ã€LV2åŠCLAPç­‰å¤šç§æ ¼å¼çš„å•†ä¸šæ’ä»¶æ— ç¼é›†æˆã€‚è¯¥æ¡†æ¶æ”¯æŒä¾§é“¾(sidechains)å’Œåˆ†é¢‘(crossovers)ç­‰å¤æ‚ç»“æ„ï¼Œå¹¶é€šè¿‡æç®€çš„å…ƒæ•°æ®æ¥å£å®ç°äº†é«˜æ•ˆçš„å¹¶è¡ŒåŒ–å¤„ç†ã€‚å®éªŒé€šè¿‡å¯¹æ··éŸ³å›¾ã€æ’ä»¶å‚æ•°åŠå¢ç›Šçš„ç›²ä¼°è®¡éªŒè¯äº†è¯¥æµæ°´çº¿çš„æœ‰æ•ˆæ€§ï¼ŒæˆåŠŸå¼¥åˆäº†äººå·¥æ™ºèƒ½ç ”ç©¶ä¸å®é™…DSPéœ€æ±‚ä¹‹é—´çš„é¸¿æ²Ÿã€‚ç›®å‰è¯¥é¡¹ç›®çš„ä»£ç å·²åœ¨GitHubå¼€æºï¼Œä¸ºéŸ³é¢‘æ•ˆæœå»ºæ¨¡é¢†åŸŸæä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10534v2",
      "published_date": "2025-07-14 17:55:38 UTC",
      "updated_date": "2025-07-17 18:06:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:05.512148+00:00"
    },
    {
      "arxiv_id": "2507.10532v3",
      "title": "Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination",
      "title_zh": "æ¨ç†è¿˜æ˜¯è®°å¿†ï¼Ÿæ•°æ®æ±¡æŸ“å¯¼è‡´çš„å¼ºåŒ–å­¦ä¹ ç»“æœä¸å¯é æ€§",
      "authors": [
        "Mingqi Wu",
        "Zhihao Zhang",
        "Qiaole Dong",
        "Zhiheng Xi",
        "Jun Zhao",
        "Senjie Jin",
        "Xiaoran Fan",
        "Yuhao Zhou",
        "Huijie Lv",
        "Ming Zhang",
        "Yanwei Fu",
        "Qin Liu",
        "Songyang Zhang",
        "Qi Zhang"
      ],
      "abstract": "Reasoning in large language models has long been a central research focus, and recent studies employing reinforcement learning (RL) have introduced diverse methods that yield substantial performance gains with minimal or even no external supervision. Surprisingly, some studies even suggest that random or incorrect reward signals can enhance performance. However, these breakthroughs are predominantly observed for the mathematically strong Qwen2.5 series on benchmarks such as MATH-500, AMC, and AIME, and seldom transfer to models like Llama, which warrants a more in-depth investigation. In this work, our empirical analysis reveals that pre-training on massive web-scale corpora leaves Qwen2.5 susceptible to data contamination in widely used benchmarks. Consequently, conclusions derived from contaminated benchmarks on Qwen2.5 series may be unreliable. To obtain trustworthy evaluation results, we introduce a generator that creates fully clean arithmetic problems of arbitrary length and difficulty, dubbed RandomCalculation. Using this leakage-free dataset, we show that only accurate reward signals yield steady improvements that surpass the base model's performance boundary in mathematical reasoning, whereas random or incorrect rewards do not. Moreover, we conduct more fine-grained analyses to elucidate the factors underlying the different performance observed on the MATH-500 and RandomCalculation benchmarks. Consequently, we recommend that future studies evaluate models on uncontaminated benchmarks and, when feasible, test various model series to ensure trustworthy conclusions about RL and related methods.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è·å¾—æ€§èƒ½æå‡çš„å¯é æ€§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ Qwen2.5 ç³»åˆ—æ¨¡å‹åœ¨ MATH-500 ç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºçš„å¼‚å¸¸å¢ç›Šã€‚å®è¯åˆ†æè¡¨æ˜ï¼ŒQwen2.5 ææ˜“å—åˆ°æ•°æ®æ±¡æŸ“ï¼ˆData Contaminationï¼‰çš„å½±å“ï¼Œå¯¼è‡´åŸºäºå—æ±¡æŸ“åŸºå‡†å¾—å‡ºçš„å¼ºåŒ–å­¦ä¹ ç»“è®ºå¯èƒ½å¹¶ä¸å¯é ã€‚ä¸ºè·å–å¯ä¿¡çš„è¯„ä¼°ç»“æœï¼Œä½œè€…å¼€å‘äº†åä¸º RandomCalculation çš„æ•°æ®ç”Ÿæˆå™¨ï¼Œç”¨äºåˆ›å»ºå®Œå…¨å¹²å‡€ä¸”æ— æ³„æ¼ï¼ˆLeakage-freeï¼‰çš„ç®—æœ¯æ¨ç†é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œåœ¨æ— æ³„æ¼æ•°æ®é›†ä¸Šï¼Œåªæœ‰å‡†ç¡®çš„å¥–åŠ±ä¿¡å·ï¼ˆReward Signalsï¼‰èƒ½å¸¦æ¥ç¨³æ­¥çš„æ€§èƒ½æå‡ï¼Œè€Œéšæœºæˆ–é”™è¯¯çš„å¥–åŠ±å¹¶ä¸èƒ½å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¯¹ä¸åŒåŸºå‡†æµ‹è¯•è¡¨ç°å·®å¼‚çš„æ·±å…¥åˆ†æï¼Œè¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨æœªå—æ±¡æŸ“çš„åŸºå‡†ä¸ŠéªŒè¯æ¨¡å‹çš„é‡è¦æ€§ã€‚ä½œè€…æœ€åå»ºè®®æœªæ¥çš„å¼ºåŒ–å­¦ä¹ ç ”ç©¶åº”ç»“åˆå¤šç§æ¨¡å‹ç³»åˆ—è¿›è¡Œæµ‹è¯•ï¼Œä»¥ç¡®ä¿ç ”ç©¶ç»“è®ºçš„ç§‘å­¦æ€§ä¸å¯ä¿¡åº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2507.10532v3",
      "published_date": "2025-07-14 17:55:15 UTC",
      "updated_date": "2025-12-17 03:04:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:09.642708+00:00"
    },
    {
      "arxiv_id": "2507.10530v4",
      "title": "Flow matching for reaction pathway generation",
      "title_zh": "ç”¨äºååº”è·¯å¾„ç”Ÿæˆçš„æµåŒ¹é…",
      "authors": [
        "Ping Tuo",
        "Jiale Chen",
        "Ju Li"
      ],
      "abstract": "Elucidating reaction mechanisms hinges on efficiently generating transition states (TSs), products, and complete reaction networks. Recent generative models, such as diffusion models for TS sampling and sequence-based architectures for product generation, offer faster alternatives to quantum-chemistry searches. But diffusion models remain constrained by their stochastic differential equation (SDE) dynamics, which suffer from inefficiency and limited controllability. We show that flow matching, a deterministic ordinary differential (ODE) formulation, can replace SDE-based diffusion for molecular and reaction generation. We introduce MolGEN, a conditional flow-matching framework that learns an optimal transport path to transport Gaussian priors to target chemical distributions. On benchmarks used by TSDiff and OA-ReactDiff, MolGEN surpasses TS geometry accuracy and barrier-height prediction while reducing sampling to sub-second inference. MolGEN also supports open-ended product generation with competitive top-k accuracy and avoids mass/electron-balance violations common to sequence models. In a realistic test on the $Î³$-ketohydroperoxide decomposition network, MolGEN yields higher fractions of valid and intended TSs with markedly fewer quantum-chemistry evaluations than string-based baselines. These results demonstrate that deterministic flow matching provides a unified, accurate, and computationally efficient foundation for molecular generative modeling, signaling that flow matching is the future for molecular generation across chemistry.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹ï¼ˆdiffusion modelsï¼‰åœ¨ç”Ÿæˆè¿‡æ¸¡æ€ï¼ˆTransition Statesï¼‰å’Œååº”è·¯å¾„æ—¶å› éšæœºå¾®åˆ†æ–¹ç¨‹ï¼ˆSDEï¼‰åŠ¨åŠ›å­¦å¯¼è‡´çš„æ•ˆç‡ä½å’Œå¯æ§æ€§å·®ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åŸºäºç¡®å®šæ€§å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰å…¬å¼çš„æµåŒ¹é…ï¼ˆflow matchingï¼‰æ¡†æ¶MolGENã€‚MolGENä½œä¸ºä¸€ç§æ¡ä»¶æµåŒ¹é…æ¡†æ¶ï¼Œé€šè¿‡å­¦ä¹ æœ€ä¼˜ä¼ è¾“è·¯å¾„å°†é«˜æ–¯å…ˆéªŒè½¬åŒ–ä¸ºç›®æ ‡åŒ–å­¦åˆ†å¸ƒï¼Œå®ç°äº†é«˜æ•ˆçš„åˆ†å­å’Œååº”ç”Ÿæˆã€‚åœ¨TSDiffå’ŒOA-ReactDiffåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨è¿‡æ¸¡æ€å‡ ä½•ç²¾åº¦å’ŒåŠ¿å’é«˜åº¦é¢„æµ‹ä¸Šå‡è¶…è¶Šäº†ç°æœ‰æ¨¡å‹ï¼Œå¹¶å°†æ¨ç†æ—¶é—´ç¼©çŸ­è‡³äºšç§’çº§ã€‚MolGENè¿˜æ”¯æŒå¼€æ”¾å¼äº§ç‰©ç”Ÿæˆï¼Œå¹¶èƒ½æœ‰æ•ˆé¿å…åºåˆ—æ¨¡å‹ä¸­å¸¸è§çš„è´¨é‡ä¸ç”µè·å¹³è¡¡è¿è§„é—®é¢˜ã€‚åœ¨$\\gamma$-é…®è¿‡æ°§åŒ–æ°¢åˆ†è§£ç½‘ç»œçš„å®é™…åº”ç”¨ä¸­ï¼ŒMolGENä¸ä»…æé«˜äº†æœ‰æ•ˆè¿‡æ¸¡æ€çš„ç”Ÿæˆæ¯”ä¾‹ï¼Œè¿˜æ˜¾è‘—å‡å°‘äº†æ‰€éœ€çš„é‡å­åŒ–å­¦è¯„ä¼°æ¬¡æ•°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç¡®å®šæ€§æµåŒ¹é…æŠ€æœ¯ä¸ºåˆ†å­ç”Ÿæˆå»ºæ¨¡æä¾›äº†ç»Ÿä¸€ã€ç²¾ç¡®ä¸”é«˜æ•ˆçš„åŸºç¡€ï¼Œå±•ç°å‡ºåœ¨è¯¥é¢†åŸŸçš„å·¨å¤§åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "Updates from the previous version: fixed some typos of energy units. (Miswritten kcal/mol as eV several times in the previous version)",
      "pdf_url": "https://arxiv.org/pdf/2507.10530v4",
      "published_date": "2025-07-14 17:54:47 UTC",
      "updated_date": "2025-11-05 02:11:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:12.935995+00:00"
    },
    {
      "arxiv_id": "2507.10522v1",
      "title": "DeepResearch$^{\\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology",
      "title_zh": "DeepResearch$^{\\text{Eco}}$ï¼šé¢å‘ç”Ÿæ€å­¦å¤æ‚ç§‘å­¦é—®ç­”çš„é€’å½’æ™ºèƒ½ä½“å·¥ä½œæµ",
      "authors": [
        "Jennifer D'Souza",
        "Endres Keno Sander",
        "Andrei Aioanei"
      ],
      "abstract": "We introduce DeepResearch$^{\\text{Eco}}$, a novel agentic LLM-based system for automated scientific synthesis that supports recursive, depth- and breadth-controlled exploration of original research questions -- enhancing search diversity and nuance in the retrieval of relevant scientific literature. Unlike conventional retrieval-augmented generation pipelines, DeepResearch enables user-controllable synthesis with transparent reasoning and parameter-driven configurability, facilitating high-throughput integration of domain-specific evidence while maintaining analytical rigor. Applied to 49 ecological research questions, DeepResearch achieves up to a 21-fold increase in source integration and a 14.9-fold rise in sources integrated per 1,000 words. High-parameter settings yield expert-level analytical depth and contextual diversity.\n  Source code available at: https://github.com/sciknoworg/deep-research.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† DeepResearch$^{\\text{Eco}}$ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–°å‹æ™ºèƒ½ä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨å®ç°ç”Ÿæ€å­¦é¢†åŸŸçš„è‡ªåŠ¨åŒ–ç§‘å­¦ç»¼è¿°å’Œå¤æ‚é—®é¢˜å›ç­”ã€‚ä¸ä¼ ç»Ÿçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æµç¨‹ä¸åŒï¼Œè¯¥ç³»ç»Ÿé‡‡ç”¨äº†é€’å½’å¼çš„ã€å¯æ§æ·±åº¦ä¸å¹¿åº¦çš„ä»£ç†å·¥ä½œæµï¼ˆAgentic Workflowï¼‰ï¼Œæ˜¾è‘—å¢å¼ºäº†ç›¸å…³ç§‘å­¦æ–‡çŒ®æ£€ç´¢çš„å¤šæ ·æ€§ä¸ç»†å¾®å·®åˆ«ã€‚DeepResearch$^{\\text{Eco}}$ å…è®¸ç”¨æˆ·é€šè¿‡å‚æ•°é…ç½®æ¥æ§åˆ¶åˆæˆè¿‡ç¨‹ï¼Œåœ¨ä¿æŒåˆ†æä¸¥è°¨æ€§çš„åŒæ—¶æä¾›äº†é€æ˜çš„æ¨ç†è·¯å¾„ï¼Œæ”¯æŒé¢†åŸŸç‰¹å®šè¯æ®çš„é«˜é€šé‡é›†æˆã€‚åœ¨é’ˆå¯¹ 49 ä¸ªç”Ÿæ€ç ”ç©¶é—®é¢˜çš„è¯„ä¼°ä¸­ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†é«˜è¾¾ 21 å€çš„æ¥æºé›†æˆå¢é•¿ï¼Œå¹¶ä½¿æ¯åƒå­—çš„æ¥æºé›†æˆé‡æå‡äº† 14.9 å€ã€‚å®éªŒç»“æœè¯æ˜ï¼Œåœ¨é«˜å‚æ•°é…ç½®ä¸‹ï¼Œè¯¥å·¥ä½œæµèƒ½å¤Ÿäº§å‡ºå…·æœ‰ä¸“å®¶çº§åˆ†ææ·±åº¦å’Œä¸Šä¸‹æ–‡å¤šæ ·æ€§çš„ç§‘ç ”æˆæœï¼Œä¸ºç”Ÿæ€å­¦ç ”ç©¶æä¾›äº†é«˜æ•ˆçš„è‡ªåŠ¨åŒ–åˆæˆå·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10522v1",
      "published_date": "2025-07-14 17:47:28 UTC",
      "updated_date": "2025-07-14 17:47:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:16.086937+00:00"
    },
    {
      "arxiv_id": "2507.14202v1",
      "title": "PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training",
      "title_zh": "åŸºäºçº¢é˜Ÿæµ‹è¯•ä¸å¯¹æŠ—è®­ç»ƒçš„å¤§æ¨¡å‹æ—  PRM å®‰å…¨å¯¹é½",
      "authors": [
        "Pengfei Du"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse applications, yet they pose significant security risks that threaten their safe deployment in critical domains. Current security alignment methodologies predominantly rely on Process Reward Models (PRMs) to evaluate intermediate reasoning steps, introducing substantial computational overhead and scalability constraints. This paper presents a novel PRM-free security alignment framework that leverages automated red teaming and adversarial training to achieve robust security guarantees while maintaining computational efficiency. Our approach systematically identifies vulnerabilities through sophisticated attack strategies including genetic algorithm optimization, multi-agent simulation, and advanced prompt mutation techniques. The framework enhances model robustness via targeted adversarial training with curriculum learning and adaptive regularization mechanisms. Comprehensive experimental evaluation across five state-of-the-art LLMs demonstrates that our method achieves superior security alignment performance compared to PRM-based approaches while reducing computational costs by 61\\%. The framework incorporates transparent reporting and continuous audit mechanisms that enable iterative security improvement and regulatory compliance. Our contributions advance the field of efficient LLM security alignment by democratizing access to robust security measures for resource-constrained organizations and providing a scalable foundation for addressing evolving adversarial threats.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®‰å…¨å¯¹é½ä¸­è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMsï¼‰è®¡ç®—å¼€é”€è¿‡å¤§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€ PRM çš„æ–°å‹å®‰å…¨å¯¹é½æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆè‡ªåŠ¨åŒ–çº¢é˜Ÿï¼ˆRed Teamingï¼‰ä¸å¯¹æŠ—è®­ç»ƒï¼ˆAdversarial Trainingï¼‰ï¼Œåˆ©ç”¨é—ä¼ ç®—æ³•ä¼˜åŒ–ï¼ˆGenetic Algorithm Optimizationï¼‰ã€å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿï¼ˆMulti-agent Simulationï¼‰åŠé«˜çº§æç¤ºè¯å˜å¼‚æŠ€æœ¯ï¼ˆAdvanced Prompt Mutation Techniquesï¼‰ç³»ç»Ÿæ€§åœ°è¯†åˆ«æ¨¡å‹æ¼æ´ã€‚é€šè¿‡å¼•å…¥è¯¾ç¨‹å­¦ä¹ ï¼ˆCurriculum Learningï¼‰å’Œè‡ªé€‚åº”æ­£åˆ™åŒ–æœºåˆ¶ï¼ˆAdaptive Regularization Mechanismsï¼‰ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå¢å¼ºäº†æ¨¡å‹çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨äº”ç§ä¸»æµ LLMs ä¸Šçš„å®‰å…¨å¯¹é½æ€§èƒ½ä¼˜äºä¼ ç»Ÿçš„ PRM æ–¹æ³•ï¼Œä¸”æˆåŠŸå°†è®¡ç®—æˆæœ¬é™ä½äº† 61%ã€‚è¯¥æˆæœä¸ºèµ„æºå—é™çš„ç»„ç»‡æä¾›äº†é«˜æ•ˆã€å¯æ‰©å±•ä¸”ç¬¦åˆç›‘ç®¡è¦æ±‚çš„ LLM å®‰å…¨å¯¹é½æ–¹æ¡ˆï¼Œä¸ºåº”å¯¹ä¸æ–­æ¼”å˜çš„å¯¹æŠ—æ€§å¨èƒæä¾›äº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14202v1",
      "published_date": "2025-07-14 17:41:12 UTC",
      "updated_date": "2025-07-14 17:41:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:24.242758+00:00"
    },
    {
      "arxiv_id": "2507.10510v2",
      "title": "Chat with AI: The Surprising Turn of Real-time Video Communication from Human to AI",
      "title_zh": "ä¸ AI å¯¹è¯ï¼šå®æ—¶è§†é¢‘é€šä¿¡ä»äººé™…äº¤äº’å‘äººæœºäº¤äº’çš„èŒƒå¼è½¬å˜",
      "authors": [
        "Jiangkai Wu",
        "Zhiyuan Ren",
        "Liming Liu",
        "Xinggong Zhang"
      ],
      "abstract": "AI Video Chat emerges as a new paradigm for Real-time Communication (RTC), where one peer is not a human, but a Multimodal Large Language Model (MLLM). This makes interaction between humans and AI more intuitive, as if chatting face-to-face with a real person. However, this poses significant challenges to latency, because the MLLM inference takes up most of the response time, leaving very little time for video streaming. Due to network uncertainty, transmission latency becomes a critical bottleneck preventing AI from being like a real person. To address this, we call for AI-oriented RTC research, exploring the network requirement shift from \"humans watching video\" to \"AI understanding video\". We begin by recognizing the main differences between AI Video Chat and traditional RTC. Then, through prototype measurements, we identify that ultra-low bitrate is a key factor for low latency. To reduce bitrate dramatically while maintaining MLLM accuracy, we propose Context-Aware Video Streaming that recognizes the importance of each video region for chat and allocates bitrate almost exclusively to chat-important regions. To evaluate the impact of video streaming quality on MLLM accuracy, we build the first benchmark, named Degraded Video Understanding Benchmark (DeViBench). Finally, we discuss some open questions and ongoing solutions for AI Video Chat. DeViBench is open-sourced at: https://github.com/pku-netvideo/DeViBench.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†AI Video Chatè¿™ç§æ–°å‹å®æ—¶é€šä¿¡(RTC)èŒƒå¼ï¼Œå…¶æ ¸å¿ƒæ˜¯äººç±»ä¸å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)ä¹‹é—´çš„å®æ—¶äº’åŠ¨ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç”±äºMLLMæ¨ç†å æ®äº†å¤§éƒ¨åˆ†å“åº”æ—¶é—´ï¼Œä¼ è¾“å»¶è¿Ÿæˆä¸ºåˆ¶çº¦AIåƒçœŸäººèˆ¬äº¤äº’çš„å…³é”®ç“¶é¢ˆã€‚ä¸ºäº†åº”å¯¹æŒ‘æˆ˜ï¼Œç ”ç©¶è€…æå‡ºä»â€œäººç±»è§‚çœ‹è§†é¢‘â€å‘â€œAIç†è§£è§†é¢‘â€çš„éœ€æ±‚è½¬å˜ï¼Œå¹¶è®¾è®¡äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§†é¢‘æµ(Context-Aware Video Streaming)æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯é€šè¿‡è¯†åˆ«å¹¶ä¼˜å…ˆä¸ºè§†é¢‘ä¸­å¯¹å¯¹è¯é‡è¦çš„åŒºåŸŸåˆ†é…ç ç‡ï¼Œåœ¨ç»´æŒMLLMå‡†ç¡®æ€§çš„åŒæ—¶å¤§å¹…é™ä½äº†ä¼ è¾“å»¶è¿Ÿã€‚æ­¤å¤–ï¼Œå›¢é˜Ÿæ„å»ºäº†é¦–ä¸ªé€€åŒ–è§†é¢‘ç†è§£åŸºå‡†DeViBenchï¼Œç”¨äºè¯„ä¼°è§†é¢‘æµè´¨é‡å¯¹æ¨¡å‹ç†è§£èƒ½åŠ›çš„å½±å“ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ–é¢å‘AIçš„å®æ—¶è§†é¢‘é€šä¿¡æä¾›äº†æ–°æ€è·¯ï¼Œå¹¶å¼€æºäº†ç›¸å…³çš„è¯„æµ‹å·¥å…·ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.NI",
      "comment": "9 pages, 10 figures, Proceedings of the 24th ACM Workshop on Hot Topics in Networks (HotNets 2025), College Park, Maryland, USA",
      "pdf_url": "https://arxiv.org/pdf/2507.10510v2",
      "published_date": "2025-07-14 17:34:49 UTC",
      "updated_date": "2025-11-24 13:08:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:25.788023+00:00"
    },
    {
      "arxiv_id": "2507.10502v2",
      "title": "Benchmarking and Evaluation of AI Models in Biology: Outcomes and Recommendations from the CZI Virtual Cells Workshop",
      "title_zh": "ç”Ÿç‰©å­¦äººå·¥æ™ºèƒ½æ¨¡å‹çš„åŸºå‡†æµ‹è¯•ä¸è¯„ä¼°ï¼šCZIè™šæ‹Ÿç»†èƒç ”è®¨ä¼šçš„æˆæœä¸å»ºè®®",
      "authors": [
        "Elizabeth Fahsbender",
        "Alma Andersson",
        "Jeremy Ash",
        "Polina Binder",
        "Daniel Burkhardt",
        "Benjamin Chang",
        "Georg K. Gerber",
        "Anthony Gitter",
        "Patrick Godau",
        "Ankit Gupta",
        "Genevieve Haliburton",
        "Siyu He",
        "Trey Ideker",
        "Ivana Jelic",
        "Aly Khan",
        "Yang-Joon Kim",
        "Aditi Krishnapriyan",
        "Jon M. Laurent",
        "Tianyu Liu",
        "Emma Lundberg",
        "Shalin B. Mehta",
        "Rob Moccia",
        "Angela Oliveira Pisco",
        "Katherine S. Pollard",
        "Suresh Ramani",
        "Julio Saez-Rodriguez",
        "Yasin Senbabaoglu",
        "Elana Simon",
        "Srinivasan Sivanandan",
        "Gustavo Stolovitzky",
        "Marc Valer",
        "Bo Wang",
        "Xikun Zhang",
        "James Zou",
        "Katrina Kalantar"
      ],
      "abstract": "Artificial intelligence holds immense promise for transforming biology, yet a lack of standardized, cross domain, benchmarks undermines our ability to build robust, trustworthy models. Here, we present insights from a recent workshop that convened machine learning and computational biology experts across imaging, transcriptomics, proteomics, and genomics to tackle this gap. We identify major technical and systemic bottlenecks such as data heterogeneity and noise, reproducibility challenges, biases, and the fragmented ecosystem of publicly available resources and propose a set of recommendations for building benchmarking frameworks that can efficiently compare ML models of biological systems across tasks and data modalities. By promoting high quality data curation, standardized tooling, comprehensive evaluation metrics, and open, collaborative platforms, we aim to accelerate the development of robust benchmarks for AI driven Virtual Cells. These benchmarks are crucial for ensuring rigor, reproducibility, and biological relevance, and will ultimately advance the field toward integrated models that drive new discoveries, therapeutic insights, and a deeper understanding of cellular systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ€»ç»“äº† CZI Virtual Cells ç ”è®¨ä¼šå…³äºç”Ÿç‰©å­¦ AI æ¨¡å‹åŸºå‡†æµ‹è¯•ä¸è¯„ä¼°çš„æˆæœä¸å»ºè®®ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç”Ÿç‰©å­¦é¢†åŸŸç›®å‰é¢ä¸´æ•°æ®å¼‚è´¨æ€§ (data heterogeneity)ã€å™ªå£°ã€å¯é‡å¤æ€§æŒ‘æˆ˜ä»¥åŠèµ„æºç¢ç‰‡åŒ–ç­‰é‡å¤§æŠ€æœ¯ä¸ç³»ç»Ÿæ€§ç“¶é¢ˆã€‚ä¸ºæ­¤ï¼Œä¸“å®¶ç»„æå‡ºäº†ä¸€å¥—æ„å»ºåŸºå‡†æµ‹è¯•æ¡†æ¶çš„å»ºè®®ï¼Œæ—¨åœ¨å®ç°è·¨ä»»åŠ¡å’Œæ•°æ®æ¨¡æ€çš„æœºå™¨å­¦ä¹  (ML) æ¨¡å‹çš„é«˜æ•ˆå¯¹æ¯”ã€‚è¿™äº›å»ºè®®æ¶µç›–äº†é«˜è´¨é‡æ•°æ®ç­–å±• (data curation)ã€æ ‡å‡†åŒ–å·¥å…·ã€ç»¼åˆè¯„ä¼°æŒ‡æ ‡ä»¥åŠå¼€æ”¾åä½œå¹³å°çš„å»ºè®¾ã€‚è¿™äº›åŸºå‡†æµ‹è¯•å¯¹äºå¼€å‘ç¨³å¥ä¸”å…·æœ‰ç”Ÿç‰©å­¦ç›¸å…³æ€§çš„â€œè™šæ‹Ÿç»†èƒâ€ (Virtual Cells) æ¨¡å‹è‡³å…³é‡è¦ã€‚æœ€ç»ˆï¼Œè¯¥æ¡†æ¶å°†é€šè¿‡æ•´åˆæ¨¡å‹åŠ é€Ÿç§‘å­¦å‘ç°ä¸æ²»ç–—è§è§£ï¼Œæ¨åŠ¨å¯¹ç»†èƒç³»ç»Ÿæ›´æ·±å±‚æ¬¡çš„ç†è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10502v2",
      "published_date": "2025-07-14 17:25:28 UTC",
      "updated_date": "2025-07-15 20:40:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:31.591122+00:00"
    },
    {
      "arxiv_id": "2507.10500v1",
      "title": "Scene-Aware Conversational ADAS with Generative AI for Real-Time Driver Assistance",
      "title_zh": "èåˆç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„åœºæ™¯æ„ŸçŸ¥å¯¹è¯å¼ ADASï¼šåŠ©åŠ›å®æ—¶é©¾é©¶è¾…åŠ©",
      "authors": [
        "Kyungtae Han",
        "Yitao Chen",
        "Rohit Gupta",
        "Onur Altintas"
      ],
      "abstract": "While autonomous driving technologies continue to advance, current Advanced Driver Assistance Systems (ADAS) remain limited in their ability to interpret scene context or engage with drivers through natural language. These systems typically rely on predefined logic and lack support for dialogue-based interaction, making them inflexible in dynamic environments or when adapting to driver intent. This paper presents Scene-Aware Conversational ADAS (SC-ADAS), a modular framework that integrates Generative AI components including large language models, vision-to-text interpretation, and structured function calling to enable real-time, interpretable, and adaptive driver assistance. SC-ADAS supports multi-turn dialogue grounded in visual and sensor context, allowing natural language recommendations and driver-confirmed ADAS control. Implemented in the CARLA simulator with cloud-based Generative AI, the system executes confirmed user intents as structured ADAS commands without requiring model fine-tuning. We evaluate SC-ADAS across scene-aware, conversational, and revisited multi-turn interactions, highlighting trade-offs such as increased latency from vision-based context retrieval and token growth from accumulated dialogue history. These results demonstrate the feasibility of combining conversational reasoning, scene perception, and modular ADAS control to support the next generation of intelligent driver assistance.",
      "tldr_zh": "é’ˆå¯¹ç›®å‰é«˜çº§é©¾é©¶è¾…åŠ©ç³»ç»Ÿ (ADAS) åœ¨åœºæ™¯ç†è§£å’Œè‡ªç„¶è¯­è¨€äº¤äº’æ–¹é¢çš„å±€é™æ€§ï¼Œè¯¥ç ”ç©¶æå‡ºäº† Scene-Aware Conversational ADAS (SC-ADAS) æ¨¡å—åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶é›†æˆäº† Generative AI ç»„ä»¶ï¼ŒåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs)ã€vision-to-text å›¾åƒè§£æå’Œç»“æ„åŒ– function callingï¼Œæ—¨åœ¨å®ç°å®æ—¶ã€å¯è§£é‡Šä¸”å…·è‡ªé€‚åº”æ€§çš„é©¾é©¶è¾…åŠ©ã€‚SC-ADAS æ”¯æŒåŸºäºè§†è§‰ä¸ä¼ æ„Ÿå™¨ä¸Šä¸‹æ–‡çš„å¤šè½®å¯¹è¯ï¼Œå…è®¸ç³»ç»Ÿæä¾›è‡ªç„¶è¯­è¨€å»ºè®®å¹¶æ‰§è¡Œç»é©¾é©¶å‘˜ç¡®è®¤çš„ç»“æ„åŒ– ADAS æ§åˆ¶å‘½ä»¤ã€‚åœ¨ CARLA æ¨¡æ‹Ÿå™¨ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿæ— éœ€æ¨¡å‹ fine-tuning å³å¯å‡†ç¡®æ‰§è¡Œç”¨æˆ·æ„å›¾ã€‚è¯„ä¼°è¿‡ç¨‹åˆ†æäº†ç³»ç»Ÿåœ¨åœºæ™¯æ„ŸçŸ¥ä¸äº¤äº’ä¸­çš„è¡¨ç°ï¼Œå¹¶æ¢è®¨äº† vision-based context retrieval å¯¼è‡´çš„å»¶è¿Ÿå¢åŠ ä»¥åŠå¯¹è¯å†å²å¢é•¿å¸¦æ¥çš„ token å¼€é”€ç­‰æƒè¡¡å…³ç³»ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ç»“åˆå¯¹è¯æ¨ç†ã€åœºæ™¯æ„ŸçŸ¥å’Œæ¨¡å—åŒ– ADAS æ§åˆ¶ä»¥æ”¯æŒä¸‹ä¸€ä»£æ™ºèƒ½é©¾é©¶è¾…åŠ©æŠ€æœ¯çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10500v1",
      "published_date": "2025-07-14 17:24:07 UTC",
      "updated_date": "2025-07-14 17:24:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:51.881715+00:00"
    },
    {
      "arxiv_id": "2507.10496v2",
      "title": "Cameras as Relative Positional Encoding",
      "title_zh": "å°†ç›¸æœºä½œä¸ºç›¸å¯¹ä½ç½®ç¼–ç ",
      "authors": [
        "Ruilong Li",
        "Brent Yi",
        "Junchen Liu",
        "Hang Gao",
        "Yi Ma",
        "Angjoo Kanazawa"
      ],
      "abstract": "Transformers are increasingly prevalent for multi-view computer vision tasks, where geometric relationships between viewpoints are critical for 3D perception. To leverage these relationships, multi-view transformers must use camera geometry to ground visual tokens in 3D space. In this work, we compare techniques for conditioning transformers on cameras: token-level raymap encodings, attention-level relative pose encodings, and a new relative encoding we propose -- Projective Positional Encoding (PRoPE) -- that captures complete camera frustums, both intrinsics and extrinsics, as a relative positional encoding. Our experiments begin by showing how relative camera conditioning improves performance in feedforward novel view synthesis, with further gains from PRoPE. This holds across settings: scenes with both shared and varying intrinsics, when combining token- and attention-level conditioning, and for generalization to inputs with out-of-distribution sequence lengths and camera intrinsics. We then verify that these benefits persist for different tasks, stereo depth estimation and discriminative spatial cognition, as well as larger model sizes.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤šè§†å›¾è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­å¦‚ä½•åˆ©ç”¨ç›¸æœºå‡ ä½•ä¿¡æ¯å¢å¼º Transformers çš„ 3D æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†ä¸€ç§åä¸º Projective Positional Encoding (PRoPE) çš„æ–°å‹ç›¸å¯¹ç¼–ç æ–¹æ³•ã€‚PRoPE å°†åŒ…å«ç›¸æœºå†…å‚(intrinsics)å’Œå¤–å‚(extrinsics)çš„å®Œæ•´ç›¸æœºå¹³æˆªå¤´ä½“ä¿¡æ¯å»ºæ¨¡ä¸ºç›¸å¯¹ä½ç½®ç¼–ç ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°åœ¨ 3D ç©ºé—´ä¸­å®šä½è§†è§‰æ ‡è®°ã€‚å®éªŒå¯¹æ¯”äº† token-level raymap encodings ä¸ attention-level relative pose encodingsï¼Œç»“æœè¯æ˜ PRoPE åœ¨å‰å‘æ–°è§†è§’åˆæˆ(feedforward novel view synthesis)ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†å¤šå˜å†…å‚ã€è¶…å‡ºåˆ†å¸ƒ(OOD)çš„åºåˆ—é•¿åº¦ä»¥åŠä¸åŒç›¸æœºå‚æ•°æ—¶å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚ç ”ç©¶æœ€åéªŒè¯äº† PRoPE åœ¨ç«‹ä½“æ·±åº¦ä¼°è®¡(stereo depth estimation)å’Œåˆ¤åˆ«æ€§ç©ºé—´è®¤çŸ¥(discriminative spatial cognition)ç­‰ä¸åŒä»»åŠ¡ï¼Œä»¥åŠåœ¨æ›´å¤§è§„æ¨¡æ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://www.liruilong.cn/prope/",
      "pdf_url": "https://arxiv.org/pdf/2507.10496v2",
      "published_date": "2025-07-14 17:22:45 UTC",
      "updated_date": "2025-11-13 04:24:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:50.081441+00:00"
    },
    {
      "arxiv_id": "2507.10646v5",
      "title": "CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance",
      "title_zh": "CodeAssistBench (CAB)ï¼šé¢å‘å¤šè½®å¯¹è¯å¼ä»£ç è¾…åŠ©çš„æ•°æ®é›†ä¸åŸºå‡†æµ‹è¯•",
      "authors": [
        "Myeongsoo Kim",
        "Shweta Garg",
        "Baishakhi Ray",
        "Varun Kumar",
        "Anoop Deoras"
      ],
      "abstract": "Programming assistants powered by large language models have improved dramatically, yet existing benchmarks still evaluate them in narrow code-generation settings. Recent efforts such as InfiBench and StackEval rely on Stack Overflow questions and remain limited to single-turn interactions, manually curated data, and isolated snippets rather than full project environments. We introduce CodeAssistBench (CAB), the first benchmark for evaluating multi-turn, project-grounded programming assistance at scale. CAB automatically constructs datasets from GitHub issues tagged as questions, using an LLM-driven pipeline that filters noise, extracts runnable contexts, builds executable containers, and verifies environment correctness. This enables continuous, automated expansion across diverse repositories without manual intervention. Using CAB, we create a testbed of 3,286 real-world issues across 214 repositories, spanning seven languages. Evaluating state-of-the-art models reveals a substantial gap: while models achieve 70-83% accuracy on Stack Overflow-style questions, they solve only 7.22-16.49% of CAB issues from post-training-cutoff repositories. These results highlight a fundamental challenge: current LLMs struggle to provide assistance in realistic, project-specific contexts despite strong performance on traditional Q&A benchmarks. CAB provides a scalable, reproducible framework for advancing research in multi-turn, codebase-grounded programming agents. The benchmark and pipeline are fully automated and publicly available at https://github.com/amazon-science/CodeAssistBench/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CodeAssistBench (CAB)ï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºå¤§è§„æ¨¡è¯„ä¼°å¤šè½®(multi-turn)ã€åŸºäºé¡¹ç›®èƒŒæ™¯(project-grounded)çš„ç¼–ç¨‹è¾…åŠ©åŸºå‡†æµ‹è¯•ã€‚CABé€šè¿‡LLMé©±åŠ¨çš„è‡ªåŠ¨åŒ–æµæ°´çº¿ï¼Œä»å¸¦æœ‰é—®é¢˜æ ‡ç­¾çš„GitHub issuesä¸­è¿‡æ»¤å™ªå£°å¹¶æå–å¯è¿è¡Œä¸Šä¸‹æ–‡ï¼Œè‡ªåŠ¨æ„å»ºå¯æ‰§è¡Œå®¹å™¨ä»¥å®ç°åŸºå‡†æµ‹è¯•çš„æŒç»­æ‰©å±•ã€‚åˆ©ç”¨è¯¥å·¥å…·ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªè·¨è¶Š7ç§ç¼–ç¨‹è¯­è¨€ã€æ¶µç›–214ä¸ªä»“åº“å…±3,286ä¸ªçœŸå®é—®é¢˜çš„æµ‹è¯•åºŠã€‚è¯„ä¼°ç»“æœæ­ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼šç°æœ‰æ¨¡å‹åœ¨Stack Overflowé£æ ¼çš„å•è½®é—®ç­”ä¸­å‡†ç¡®ç‡å¯è¾¾70-83%ï¼Œä½†åœ¨CABæä¾›çš„çœŸå®é¡¹ç›®èƒŒæ™¯ä¸‹ï¼Œå…¶é—®é¢˜è§£å†³ç‡ä»…ä¸º7.22-16.49%ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚é¡¹ç›®ç‰¹æœ‰ä¸Šä¸‹æ–‡æ—¶çš„å±€é™æ€§ï¼Œå¹¶ä¸ºå¤šè½®ã€åŸºäºä»£ç åº“(codebase-grounded)çš„ç¼–ç¨‹æ™ºèƒ½ä½“ç ”ç©¶æä¾›äº†å¼€æºä¸”å¯å¤ç°çš„è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to NeurIPS 2025 Datasets and Benchmarks Track",
      "pdf_url": "https://arxiv.org/pdf/2507.10646v5",
      "published_date": "2025-07-14 17:19:00 UTC",
      "updated_date": "2026-01-15 07:27:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:54.082523+00:00"
    },
    {
      "arxiv_id": "2507.10492v1",
      "title": "BenchReAD: A systematic benchmark for retinal anomaly detection",
      "title_zh": "BenchReADï¼šè§†ç½‘è†œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿæ€§åŸºå‡†",
      "authors": [
        "Chenyu Lian",
        "Hong-Yu Zhou",
        "Zhanli Hu",
        "Jing Qin"
      ],
      "abstract": "Retinal anomaly detection plays a pivotal role in screening ocular and systemic diseases. Despite its significance, progress in the field has been hindered by the absence of a comprehensive and publicly available benchmark, which is essential for the fair evaluation and advancement of methodologies. Due to this limitation, previous anomaly detection work related to retinal images has been constrained by (1) a limited and overly simplistic set of anomaly types, (2) test sets that are nearly saturated, and (3) a lack of generalization evaluation, resulting in less convincing experimental setups. Furthermore, existing benchmarks in medical anomaly detection predominantly focus on one-class supervised approaches (training only with negative samples), overlooking the vast amounts of labeled abnormal data and unlabeled data that are commonly available in clinical practice. To bridge these gaps, we introduce a benchmark for retinal anomaly detection, which is comprehensive and systematic in terms of data and algorithm. Through categorizing and benchmarking previous methods, we find that a fully supervised approach leveraging disentangled representations of abnormalities (DRA) achieves the best performance but suffers from significant drops in performance when encountering certain unseen anomalies. Inspired by the memory bank mechanisms in one-class supervised learning, we propose NFM-DRA, which integrates DRA with a Normal Feature Memory to mitigate the performance degradation, establishing a new SOTA. The benchmark is publicly available at https://github.com/DopamineLcy/BenchReAD.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BenchReADï¼Œä¸€ä¸ªé’ˆå¯¹è§†ç½‘è†œå¼‚å¸¸æ£€æµ‹çš„å…¨é¢ä¸”ç³»ç»Ÿæ€§çš„ benchmarkï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç ”ç©¶ä¸­å¼‚å¸¸ç±»å‹è¿‡äºç®€åŒ–ã€æµ‹è¯•é›†è¶‹äºé¥±å’Œä»¥åŠç¼ºä¹ generalization evaluation ç­‰å±€é™æ€§ã€‚é’ˆå¯¹ä¼ ç»ŸåŒ»å­¦å¼‚å¸¸æ£€æµ‹åŸºå‡†è¿‡åº¦å…³æ³¨ one-class supervised æ–¹æ³•çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æ•´åˆäº†ä¸´åºŠä¸­å¸¸è§çš„æœ‰æ ‡ç­¾å¼‚å¸¸æ•°æ®å’Œæ— æ ‡ç­¾æ•°æ®ã€‚é€šè¿‡å¯¹æ—¢æœ‰ç®—æ³•çš„åˆ†ç±»ä¸è¯„ä¼°ï¼Œç ”ç©¶å‘ç°é‡‡ç”¨ disentangled representations of abnormalities (DRA) çš„å…¨ç›‘ç£æ–¹æ³•è™½ç„¶æ€§èƒ½é¢†å…ˆï¼Œä½†åœ¨åº”å¯¹ unseen anomalies æ—¶å­˜åœ¨æ˜æ˜¾çš„æ€§èƒ½ä¸‹é™ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§åä¸º NFM-DRA çš„æ”¹è¿›æ–¹æ³•ï¼Œé€šè¿‡å°† DRA ä¸å— memory bank æœºåˆ¶å¯å‘çš„ Normal Feature Memory ç›¸ç»“åˆï¼Œæœ‰æ•ˆç¼“è§£äº†æ€§èƒ½é€€åŒ–é—®é¢˜å¹¶åˆ·æ–°äº† SOTAã€‚BenchReAD çš„å…¬å¼€ä¸ºè§†ç½‘è†œå¼‚å¸¸æ£€æµ‹é¢†åŸŸçš„å…¬å¹³è¯„ä¼°å’ŒæŠ€æœ¯è¿›æ­¥æä¾›äº†é‡è¦çš„åŸºç¡€è®¾æ–½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10492v1",
      "published_date": "2025-07-14 17:13:08 UTC",
      "updated_date": "2025-07-14 17:13:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:35:57.598619+00:00"
    },
    {
      "arxiv_id": "2507.14201v2",
      "title": "ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation",
      "title_zh": "ExCyTIn-Benchï¼šé¢å‘ç½‘ç»œå¨èƒè°ƒæŸ¥çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è¯„ä¼°åŸºå‡†",
      "authors": [
        "Yiran Wu",
        "Mauricio Velazco",
        "Andrew Zhao",
        "Manuel RaÃºl MelÃ©ndez LujÃ¡n",
        "Srisuma Movva",
        "Yogesh K Roy",
        "Quang Nguyen",
        "Roberto Rodriguez",
        "Qingyun Wu",
        "Michael Albada",
        "Julia Kiseleva",
        "Anand Mudgerikar"
      ],
      "abstract": "We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on the task of Cyber Threat Investigation through security questions derived from investigation graphs. Real-world security analysts must sift through a large number of heterogeneous alert signals and security logs, follow multi-hop chains of evidence, and compile an incident report. With the developments of LLMs, building LLM-based agents for automatic thread investigation is a promising direction. To assist the development and evaluation of LLM agents, we construct a dataset from a controlled Azure tenant that covers 8 simulated real-world multi-step attacks, 57 log tables from Microsoft Sentinel and related services, and 589 automatically generated questions. We leverage security logs extracted with expert-crafted detection logic to build threat investigation graphs, and then generate questions with LLMs using paired nodes on the graph, taking the start node as background context and the end node as answer. Anchoring each question to these explicit nodes and edges not only provides automatic, explainable ground truth answers but also makes the pipeline reusable and readily extensible to new logs. This also enables the automatic generation of procedural tasks with verifiable rewards, which can be naturally extended to training agents via reinforcement learning. Our comprehensive experiments with different models confirm the difficulty of the task: with the base setting, the average reward across all evaluated models is 0.249, and the best achieved is 0.368, leaving substantial headroom for future research. Code and data are coming soon!",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† ExCyTIn-Benchï¼Œè¿™æ˜¯é¦–ä¸ªé€šè¿‡æºè‡ªè°ƒæŸ¥å›¾çš„å®‰å…¨é—®é¢˜æ¥è¯„ä¼° LLM agents è¿›è¡Œ Cyber Threat Investigationï¼ˆç½‘ç»œå¨èƒè°ƒæŸ¥ï¼‰èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å—æ§ Azure ç§Ÿæˆ·æ„å»ºäº†æ•°æ®é›†ï¼Œæ¶µç›– 8 ç§æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„å¤šæ­¥æ”»å‡»ã€æ¥è‡ª Microsoft Sentinel åŠç›¸å…³æœåŠ¡çš„ 57 ä¸ªæ—¥å¿—è¡¨ä»¥åŠ 589 ä¸ªè‡ªåŠ¨ç”Ÿæˆçš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸“å®¶è®¾è®¡çš„æ£€æµ‹é€»è¾‘æ„å»ºå¨èƒè°ƒæŸ¥å›¾ï¼Œå¹¶åˆ©ç”¨å›¾ä¸­çš„èŠ‚ç‚¹å’Œè¾¹ç”Ÿæˆé—®é¢˜ï¼Œä»è€Œæä¾›å¯è§£é‡Šçš„ Ground Truth ç­”æ¡ˆï¼Œå¹¶ä½¿è¯„ä¼°æµç¨‹å…·å¤‡å¯å¤ç”¨æ€§å’Œæ‰©å±•æ€§ã€‚è¯¥åŸºå‡†ä¸ä»…æ”¯æŒè‡ªåŠ¨ç”Ÿæˆå…·æœ‰å¯éªŒè¯å¥–åŠ±çš„ä»»åŠ¡ï¼Œè¿˜èƒ½è‡ªç„¶æ‰©å±•åˆ°å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰çš„æ™ºèƒ½ä½“è®­ç»ƒä¸­ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºè¯¥ä»»åŠ¡æå…·æŒ‘æˆ˜æ€§ï¼Œæ‰€æœ‰æµ‹è¯•æ¨¡å‹çš„å¹³å‡å¥–åŠ±ä»…ä¸º 0.249ï¼Œè¡¨ç°æœ€ä½³çš„æ¨¡å‹ä¹Ÿä»…è¾¾åˆ° 0.368ï¼Œè¿™ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥ç ”ç©¶ç•™ä¸‹äº†æ˜¾è‘—çš„æå‡ç©ºé—´ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Add code link",
      "pdf_url": "https://arxiv.org/pdf/2507.14201v2",
      "published_date": "2025-07-14 17:06:26 UTC",
      "updated_date": "2025-09-01 20:02:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:00.483167+00:00"
    },
    {
      "arxiv_id": "2507.10475v1",
      "title": "Can You Detect the Difference?",
      "title_zh": "ä½ èƒ½è¯†åˆ«å…¶ä¸­çš„å·®å¼‚å—ï¼Ÿ",
      "authors": [
        "Ä°smail TarÄ±m",
        "AytuÄŸ Onan"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has raised concerns about reliably detecting AI-generated text. Stylometric metrics work well on autoregressive (AR) outputs, but their effectiveness on diffusion-based models is unknown. We present the first systematic comparison of diffusion-generated text (LLaDA) and AR-generated text (LLaMA) using 2 000 samples. Perplexity, burstiness, lexical diversity, readability, and BLEU/ROUGE scores show that LLaDA closely mimics human text in perplexity and burstiness, yielding high false-negative rates for AR-oriented detectors. LLaMA shows much lower perplexity but reduced lexical fidelity. Relying on any single metric fails to separate diffusion outputs from human writing. We highlight the need for diffusion-aware detectors and outline directions such as hybrid models, diffusion-specific stylometric signatures, and robust watermarking.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„æ–‡æœ¬æ£€æµ‹é—®é¢˜ï¼Œé¦–æ¬¡ç³»ç»Ÿåœ°å¯¹æ¯”äº†æ‰©æ•£æ¨¡å‹ï¼ˆdiffusion-based modelsï¼‰ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆLLaDAï¼‰ä¸è‡ªå›å½’æ¨¡å‹ï¼ˆAR-generated textï¼‰ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆLLaMAï¼‰ä¹‹é—´çš„å·®å¼‚ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨2,000ä¸ªæ ·æœ¬ï¼Œé€šè¿‡Perplexityã€Burstinessã€Lexical diversityã€Readabilityä»¥åŠBLEU/ROUGEç­‰å¤šç§æ–‡ä½“è®¡é‡æŒ‡æ ‡ï¼ˆStylometric metricsï¼‰è¿›è¡Œäº†è¯¦å°½åˆ†æã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLaDAåœ¨Perplexityå’ŒBurstinessæŒ‡æ ‡ä¸Šä¸äººç±»æ’°å†™çš„æ–‡æœ¬é«˜åº¦ç›¸ä¼¼ï¼Œå¯¼è‡´ç°æœ‰çš„é’ˆå¯¹è‡ªå›å½’æ¨¡å‹è®¾è®¡çš„æ£€æµ‹å™¨é¢ä¸´æé«˜çš„æ¼æŠ¥ç‡ï¼ˆFalse-negative ratesï¼‰ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒLLaMAè™½ç„¶è¡¨ç°å‡ºæ›´ä½çš„Perplexityï¼Œä½†åœ¨è¯æ±‡ä¿çœŸåº¦ï¼ˆLexical fidelityï¼‰æ–¹é¢è¾ƒä½ã€‚ç ”ç©¶å¼ºè°ƒï¼Œç›®å‰ä¾èµ–ä»»ä½•å•ä¸€æŒ‡æ ‡éƒ½æ— æ³•æœ‰æ•ˆåŒºåˆ†æ‰©æ•£æ¨¡å‹çš„è¾“å‡ºä¸äººç±»å†™ä½œã€‚æœ€åï¼Œè¯¥è®ºæ–‡æŒ‡å‡ºäº†å¼€å‘æ‰©æ•£æ„ŸçŸ¥æ£€æµ‹å™¨ï¼ˆDiffusion-aware detectorsï¼‰çš„ç´§è¿«æ€§ï¼Œå¹¶æå‡ºäº†æ··åˆæ¨¡å‹ã€æ‰©æ•£ç‰¹æœ‰æ–‡ä½“ç­¾åå’Œç¨³å¥æ°´å°ï¼ˆWatermarkingï¼‰ç­‰æœªæ¥ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 3 figures, 2 tables. Code and data: https://github.com/ismailtrm/ceng_404. Cross-list requested to cs.AI for AI-safety relevance",
      "pdf_url": "https://arxiv.org/pdf/2507.10475v1",
      "published_date": "2025-07-14 16:55:57 UTC",
      "updated_date": "2025-07-14 16:55:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:17.786246+00:00"
    },
    {
      "arxiv_id": "2507.10474v1",
      "title": "Privacy-Preserving Multi-Stage Fall Detection Framework with Semi-supervised Federated Learning and Robotic Vision Confirmation",
      "title_zh": "åŸºäºåŠç›‘ç£è”é‚¦å­¦ä¹ ä¸æœºå™¨äººè§†è§‰ç¡®è®¤çš„éšç§ä¿æŠ¤å¤šé˜¶æ®µè·Œå€’æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Seyed Alireza Rahimi Azghadi",
        "Truong-Thanh-Hung Nguyen",
        "Helene Fournier",
        "Monica Wachowicz",
        "Rene Richard",
        "Francis Palma",
        "Hung Cao"
      ],
      "abstract": "The aging population is growing rapidly, and so is the danger of falls in older adults. A major cause of injury is falling, and detection in time can greatly save medical expenses and recovery time. However, to provide timely intervention and avoid unnecessary alarms, detection systems must be effective and reliable while addressing privacy concerns regarding the user. In this work, we propose a framework for detecting falls using several complementary systems: a semi-supervised federated learning-based fall detection system (SF2D), an indoor localization and navigation system, and a vision-based human fall recognition system. A wearable device and an edge device identify a fall scenario in the first system. On top of that, the second system uses an indoor localization technique first to localize the fall location and then navigate a robot to inspect the scenario. A vision-based detection system running on an edge device with a mounted camera on a robot is used to recognize fallen people. Each of the systems of this proposed framework achieves different accuracy rates. Specifically, the SF2D has a 0.81% failure rate equivalent to 99.19% accuracy, while the vision-based fallen people detection achieves 96.3% accuracy. However, when we combine the accuracy of these two systems with the accuracy of the navigation system (95% success rate), our proposed framework creates a highly reliable performance for fall detection, with an overall accuracy of 99.99%. Not only is the proposed framework safe for older adults, but it is also a privacy-preserving solution for detecting falls.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºPrivacy-Preserving Multi-Stage Fall Detection Frameworkçš„å¤šé˜¶æ®µè·Œå€’æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºè€å¹´äººæä¾›é«˜å¯é æ€§ä¸”ä¿æŠ¤éšç§çš„å¥åº·ç›‘æµ‹æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶æ•´åˆäº†åŸºäºåŠç›‘ç£è”é‚¦å­¦ä¹ çš„è·Œå€’æ£€æµ‹ç³»ç»Ÿ(SF2D)ã€å®¤å†…å®šä½ä¸å¯¼èˆªç³»ç»Ÿä»¥åŠæœºå™¨äººè§†è§‰è¯†åˆ«ç³»ç»Ÿã€‚SF2Dç³»ç»Ÿé€šè¿‡å¯ç©¿æˆ´ä¸è¾¹ç¼˜è®¾å¤‡è¿›è¡Œåˆæ­¥è·Œå€’åˆ¤å®šï¼Œéšåå¯¼èˆªç³»ç»Ÿå¼•å¯¼æœºå™¨äººåˆ°è¾¾ç°åœºï¼Œå¹¶ç”±æ­è½½çš„è§†è§‰æ£€æµ‹ç³»ç»Ÿè¿›è¡Œæœ€ç»ˆç¡®è®¤ã€‚å®éªŒæ•°æ®æ˜¾ç¤ºï¼ŒSF2Dç³»ç»Ÿå’Œè§†è§‰æ£€æµ‹ç³»ç»Ÿçš„å‡†ç¡®ç‡åˆ†åˆ«ä¸º99.19%å’Œ96.3%ï¼Œåœ¨ç»“åˆå¯¼èˆªç³»ç»Ÿåï¼Œæ•´ä½“æ¡†æ¶çš„ç»¼åˆå‡†ç¡®ç‡è¾¾åˆ°99.99%ã€‚è¯¥æˆæœé€šè¿‡å¤šç³»ç»ŸååŒæ˜¾è‘—æå‡äº†è·Œå€’æ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶åˆ©ç”¨Federated LearningæŠ€æœ¯æœ‰æ•ˆä¿æŠ¤äº†ç”¨æˆ·çš„éšç§å®‰å…¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10474v1",
      "published_date": "2025-07-14 16:55:11 UTC",
      "updated_date": "2025-07-14 16:55:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:08.096472+00:00"
    },
    {
      "arxiv_id": "2507.10469v1",
      "title": "An Empirical Evaluation of AI-Powered Non-Player Characters' Perceived Realism and Performance in Virtual Reality Environments",
      "title_zh": "è™šæ‹Ÿç°å®ç¯å¢ƒä¸‹ AI é©±åŠ¨éç©å®¶è§’è‰²çš„æ„ŸçŸ¥çœŸå®æ„Ÿä¸æ€§èƒ½å®è¯è¯„ä¼°",
      "authors": [
        "Mikko Korkiakoski",
        "Saeid Sheikhi",
        "Jesper Nyman",
        "Jussi Saariniemi",
        "Kalle Tapio",
        "Panos Kostakos"
      ],
      "abstract": "Advancements in artificial intelligence (AI) have significantly enhanced the realism and interactivity of non-player characters (NPCs) in virtual reality (VR), creating more engaging and believable user experiences. This paper evaluates AI-driven NPCs within a VR interrogation simulator, focusing on their perceived realism, usability, and system performance. The simulator features two AI-powered NPCs, a suspect, and a partner, using GPT-4 Turbo to engage participants in a scenario to determine the suspect's guilt or innocence. A user study with 18 participants assessed the system using the System Usability Scale (SUS), Game Experience Questionnaire (GEQ), and a Virtual Agent Believability Questionnaire, alongside latency measurements for speech-to-text (STT), text-to-speech (TTS), OpenAI GPT-4 Turbo, and overall (cycle) latency. Results showed an average cycle latency of 7 seconds, influenced by the increasing conversational context. Believability scored 6.67 out of 10, with high ratings in behavior, social relationships, and intelligence but moderate scores in emotion and personality. The system achieved a SUS score of 79.44, indicating good usability. These findings demonstrate the potential of large language models to improve NPC realism and interaction in VR while highlighting challenges in reducing system latency and enhancing emotional depth. This research contributes to the development of more sophisticated AI-driven NPCs, revealing the need for performance optimization to achieve increasingly immersive virtual experiences.",
      "tldr_zh": "è¯¥ç ”ç©¶åœ¨ä¸€æ¬¾è™šæ‹Ÿç°å®(VR)å®¡è®¯æ¨¡æ‹Ÿå™¨ä¸­ï¼Œå¯¹äººå·¥æ™ºèƒ½é©±åŠ¨çš„éç©å®¶è§’è‰²(NPC)çš„æ„ŸçŸ¥çœŸå®æ€§ä¸ç³»ç»Ÿæ€§èƒ½è¿›è¡Œäº†å®è¯è¯„ä¼°ã€‚ç³»ç»Ÿåˆ©ç”¨ GPT-4 Turbo æ¨¡å‹é©±åŠ¨å«Œç–‘äººå’Œæ­æ¡£ä¸¤ä¸ª NPCï¼Œä½¿å‚ä¸è€…èƒ½å¤Ÿåœ¨æ¨¡æ‹Ÿåœºæ™¯ä¸­è¿›è¡Œäº¤äº’ä»¥åˆ¤æ–­æ¡ˆä»¶çœŸç›¸ã€‚é€šè¿‡å¯¹18åå‚ä¸è€…çš„ç”¨æˆ·ç ”ç©¶ï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨ç³»ç»Ÿå¯ç”¨æ€§é‡è¡¨(SUS)å’Œè™šæ‹Ÿæ™ºèƒ½ä½“å¯ä¿¡åº¦é—®å·è¯„ä¼°äº†äº¤äº’ä½“éªŒï¼Œå¹¶ç²¾ç¡®æµ‹é‡äº†è¯­éŸ³è½¬æ–‡æœ¬(STT)ã€æ–‡æœ¬è½¬è¯­éŸ³(TTS)åŠå¤§è¯­è¨€æ¨¡å‹çš„å¾ªç¯å»¶è¿Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNPC çš„å¯ä¿¡åº¦è¯„åˆ†ä¸º6.67/10ï¼Œåœ¨è¡Œä¸ºé€»è¾‘å’Œç¤¾ä¼šå…³ç³»æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œç³»ç»Ÿå¯ç”¨æ€§å¾—åˆ†(SUS)è¾¾åˆ°79.44ï¼Œè¡¨æ˜å…·æœ‰è‰¯å¥½çš„å®ç”¨æ€§ã€‚ç„¶è€Œï¼Œå—å¯¹è¯ä¸Šä¸‹æ–‡å¢é•¿çš„å½±å“ï¼Œç³»ç»Ÿå¹³å‡å¾ªç¯å»¶è¿Ÿè¾¾åˆ°äº†7ç§’ï¼Œä¸”åœ¨æƒ…æ„Ÿæ·±åº¦å’Œä¸ªæ€§å¡‘é€ æ–¹é¢ä»æœ‰å¾…åŠ å¼ºã€‚è¯¥ç ”ç©¶è¯æ˜äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æå‡ VR ç¯å¢ƒä¸­ NPC çœŸå®æ„Ÿæ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼ŒåŒæ—¶ä¹ŸæŒ‡å‡ºæ€§èƒ½ä¼˜åŒ–å’Œæƒ…æ„Ÿè¡¨è¾¾æ˜¯å®ç°æ·±åº¦æ²‰æµ¸å¼ä½“éªŒçš„å…³é”®æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10469v1",
      "published_date": "2025-07-14 16:50:29 UTC",
      "updated_date": "2025-07-14 16:50:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:12.396980+00:00"
    },
    {
      "arxiv_id": "2507.10644v3",
      "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents",
      "title_zh": "ä»è¯­ä¹‰ç½‘ä¸å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆ°ä»£ç†å¼ AIï¼šæ™ºèƒ½ä½“ç½‘ç»œçš„ç»Ÿä¸€å™äº‹",
      "authors": [
        "Tatiana Petrova",
        "Boris Bliznioukov",
        "Aleksandr Puzikov",
        "Radu State"
      ],
      "abstract": "The concept of the Web of Agents (WoA), which transforms the static, document-centric Web into an environment of autonomous agents acting on users' behalf, has attracted growing interest as large language models (LLMs) become more capable. However, research in this area is still fragmented across different communities. Contemporary surveys catalog the latest LLM-powered frameworks, while the rich histories of Multi-Agent Systems (MAS) and the Semantic Web are often treated as separate, legacy domains. This fragmentation obscures the intellectual lineage of modern systems and hinders a holistic understanding of the field's trajectory. We present the first comprehensive evolutionary overview of the WoA. We show that modern protocols like A2A and the MCP, are direct evolutionary responses to the well-documented limitations of earlier standards like FIPA standards and OWL-based semantic agents. To systematize this analysis, we introduce a four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism). This framework provides a unified analytical lens for comparing agent architectures across all generations, revealing a clear line of descent where others have seen a disconnect. Our analysis identifies a paradigm shift in the 'locus of intelligence': from being encoded in external data (Semantic Web) or the platform (MAS) to being embedded within the agent's core model (LLM). This shift is foundational to modern Agentic AI, enabling the scalable and adaptive systems the WoA has long envisioned. We conclude that while new protocols are essential, they are insufficient for building a robust, open, trustworthy ecosystem. Finally, we argue that the next research frontier lies in solving persistent socio-technical challenges, and we map out a new agenda focused on decentralized identity, economic models, security, and governance for the emerging WoA.",
      "tldr_zh": "è¯¥ç ”ç©¶æä¾›äº†Web of Agents (WoA) çš„é¦–ä¸ªå…¨é¢æ¼”åŒ–ç»¼è¿°ï¼Œå°†Semantic Webã€Multi-Agent Systems (MAS) ä¸ç°ä»£åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM) çš„Agentic AI ç»Ÿä¸€åœ¨ä¸€ä¸ªå™è¿°æ¡†æ¶ä¸‹ã€‚ä½œè€…æå‡ºäº†åŒ…å«è¯­ä¹‰åŸºç¡€ã€é€šä¿¡èŒƒå¼ã€æ™ºèƒ½ä¸­å¿ƒå’Œå‘ç°æœºåˆ¶çš„å››è½´åˆ†ç±»æ³• (four-axis taxonomy)ï¼Œé€šè¿‡è¯¥æ¡†æ¶æ­ç¤ºäº†ä¸åŒä»£é™…æ™ºèƒ½ä½“ç³»ç»Ÿä¹‹é—´çš„æ¼”è¿›è„‰ç»œï¼Œå¹¶è¯æ˜äº†MCPå’ŒA2Aç­‰ç°ä»£åè®®æ˜¯å¯¹FIPAå’ŒOWLç­‰æ—©æœŸæ ‡å‡†å±€é™æ€§çš„ç›´æ¥æ¼”åŒ–å“åº”ã€‚ç ”ç©¶è¯†åˆ«å‡ºâ€œæ™ºèƒ½ä¸­å¿ƒâ€ (locus of intelligence) çš„å…³é”®èŒƒå¼è½¬ç§»ï¼Œå³ä»ä¾èµ–å¤–éƒ¨æ•°æ®æˆ–å¹³å°è½¬å‘åµŒå…¥æ™ºèƒ½ä½“è‡ªèº«çš„æ ¸å¿ƒæ¨¡å‹ï¼Œè¿™æ˜¯å®ç°è§„æ¨¡åŒ–ä¸è‡ªé€‚åº”WoAç³»ç»Ÿçš„åŸºçŸ³ã€‚æ–‡ç« æœ€åå¼ºè°ƒï¼Œæ„å»ºå¥å…¨ã€å¯ä¿¡çš„ç”Ÿæ€ç³»ç»Ÿä¸ä»…éœ€è¦æŠ€æœ¯åè®®ï¼Œæ›´éœ€æ”»å…‹å»ä¸­å¿ƒåŒ–èº«ä»½ã€ç»æµæ¨¡å‹ã€å®‰å…¨ä¸æ²»ç†ç­‰æ·±å±‚ç¤¾ä¼šæŠ€æœ¯éš¾é¢˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 9 figures, 8 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.10644v3",
      "published_date": "2025-07-14 16:47:19 UTC",
      "updated_date": "2025-08-02 11:13:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:19.883611+00:00"
    },
    {
      "arxiv_id": "2507.10464v1",
      "title": "AudioMAE++: learning better masked audio representations with SwiGLU FFNs",
      "title_zh": "AudioMAE++ï¼šåŸºäº SwiGLU FFNs æå‡æ©è”½éŸ³é¢‘è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Sarthak Yadav",
        "Sergios Theodoridis",
        "Zheng-Hua Tan"
      ],
      "abstract": "Masked Autoencoders (MAEs) trained on audio spectrogram patches have emerged as a prominent approach for learning self-supervised audio representations. While several recent papers have evaluated key aspects of training MAEs on audio data, the majority of these approaches still leverage vanilla transformer building blocks, whereas the transformer community has seen steady integration of newer architectural advancements. In this work, we propose AudioMAE++, a revamped audio masked autoencoder with two such enhancements, namely macaron-style transformer blocks with gated linear units. When pretrained on the AudioSet dataset, the proposed AudioMAE++ models outperform existing MAE based approaches on 10 diverse downstream tasks, demonstrating excellent performance on audio classification and speech-based benchmarks. The proposed AudioMAE++ models also demonstrate excellent scaling characteristics, outperforming directly comparable standard MAE baselines with up to 4x more parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AudioMAE++ï¼Œè¿™æ˜¯ä¸€ç§æ”¹è¿›çš„éŸ³é¢‘æ©ç è‡ªç¼–ç å™¨ (Masked Autoencoder)ï¼Œæ—¨åœ¨é€šè¿‡å¼•å…¥ç°ä»£æ¶æ„å¢å¼ºæ¥ä¼˜åŒ–è‡ªç›‘ç£éŸ³é¢‘è¡¨ç¤ºå­¦ä¹ ã€‚é’ˆå¯¹ç°æœ‰éŸ³é¢‘ MAE æ¨¡å‹å¤§å¤šä»ä¾èµ– vanilla transformer çš„å±€é™æ€§ï¼ŒAudioMAE++ åˆ›æ–°æ€§åœ°æ•´åˆäº† macaron-style transformer blocks å’Œ gated linear units (GLUs) ç­‰å…ˆè¿›ç»„ä»¶ã€‚åœ¨ AudioSet æ•°æ®é›†ä¸Šçš„é¢„è®­ç»ƒå®éªŒè¡¨æ˜ï¼ŒAudioMAE++ åœ¨æ¶µç›–éŸ³é¢‘åˆ†ç±»å’Œè¯­éŸ³åŸºå‡†çš„ 10 é¡¹ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼Œå…¨é¢è¶…è¶Šäº†ç°æœ‰çš„ MAE æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å±•ç°å‡ºæä½³çš„æ‰©å±•æ€§ï¼Œåœ¨å‚æ•°è§„æ¨¡æ‰©å¤§è‡³ 4 å€æ—¶ï¼Œå…¶æ€§èƒ½ä¾ç„¶æ˜¾è‘—ä¼˜äºæ ‡å‡† MAE åŸºå‡†æ¨¡å‹ï¼Œä¸ºå¤§è§„æ¨¡é«˜æ•ˆéŸ³é¢‘è¡¨å¾å­¦ä¹ æä¾›äº†æ–°çš„å‚è€ƒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "TO APPEAR AT IEEE MLSP 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10464v1",
      "published_date": "2025-07-14 16:41:03 UTC",
      "updated_date": "2025-07-14 16:41:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:19.395129+00:00"
    },
    {
      "arxiv_id": "2507.10461v3",
      "title": "RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening",
      "title_zh": "RAPNetï¼šä¸€ç§ç”¨äºå…¨è‰²é”åŒ–çš„æ„Ÿå—é‡è‡ªé€‚åº”å·ç§¯ç¥ç»ç½‘ç»œ",
      "authors": [
        "Tao Tang",
        "Chengxu Yang"
      ],
      "abstract": "Pansharpening refers to the process of integrating a high resolution panchromatic (PAN) image with a lower resolution multispectral (MS) image to generate a fused product, which is pivotal in remote sensing. Despite the effectiveness of CNNs in addressing this challenge, they are inherently constrained by the uniform application of convolutional kernels across all spatial positions, overlooking local content variations. To overcome this issue, we introduce RAPNet, a new architecture that leverages content-adaptive convolution. At its core, RAPNet employs the Receptive-field Adaptive Pansharpening Convolution (RAPConv), designed to produce spatially adaptive kernels responsive to local feature context, thereby enhancing the precision of spatial detail extraction. Additionally, the network integrates the Pansharpening Dynamic Feature Fusion (PAN-DFF) module, which incorporates an attention mechanism to achieve an optimal balance between spatial detail enhancement and spectral fidelity. Comprehensive evaluations on publicly available datasets confirm that RAPNet delivers superior performance compared to existing approaches, as demonstrated by both quantitative metrics and qualitative assessments. Ablation analyses further substantiate the effectiveness of the proposed adaptive components.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¥æ„Ÿé¢†åŸŸçš„å…¨è‰²é”åŒ– (Pansharpening) ä»»åŠ¡ï¼Œæå‡ºäº†åä¸º RAPNet çš„æ–°å‹å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ã€‚ä¼ ç»Ÿçš„ CNNs åœ¨å¤„ç†è¯¥ä»»åŠ¡æ—¶ç”±äºåœ¨æ‰€æœ‰ç©ºé—´ä½ç½®ç»Ÿä¸€åº”ç”¨å·ç§¯æ ¸ï¼Œå¾€å¾€ä¼šå¿½ç•¥å±€éƒ¨å†…å®¹çš„å·®å¼‚æ€§ï¼Œè€Œ RAPNet é€šè¿‡å¼•å…¥æ„Ÿå—é‡è‡ªé€‚åº”å…¨è‰²é”åŒ–å·ç§¯ (RAPConv)ï¼Œèƒ½å¤Ÿç”Ÿæˆå“åº”å±€éƒ¨ç‰¹å¾ä¸Šä¸‹æ–‡çš„ç©ºé—´è‡ªé€‚åº”å·ç§¯æ ¸ï¼Œä»è€Œæ˜¾è‘—æé«˜ç©ºé—´ç»†èŠ‚æå–çš„ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¯¥ç½‘ç»œé›†æˆäº†ä¸€ä¸ªå…¨è‰²é”åŒ–åŠ¨æ€ç‰¹å¾èåˆ (PAN-DFF) æ¨¡å—ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶ (attention mechanism) åœ¨å¢å¼ºç©ºé—´ç»†èŠ‚ä¸ä¿æŒå…‰è°±ä¿çœŸåº¦ (spectral fidelity) ä¹‹é—´å®ç°äº†æœ€ä½³å¹³è¡¡ã€‚åœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ— è®ºæ˜¯å®šé‡æŒ‡æ ‡è¿˜æ˜¯å®šæ€§è¯„ä¼°ï¼ŒRAPNet çš„æ€§èƒ½å‡ä¼˜äºç°æœ‰çš„ä¸»æµæ–¹æ³•ã€‚æœ€åçš„æ¶ˆèå®éªŒ (Ablation analyses) ä¹Ÿè¿›ä¸€æ­¥è¯å®äº†æ‰€æå‡ºçš„è‡ªé€‚åº”ç»„ä»¶åœ¨å…¨è‰²é”åŒ–è¿‡ç¨‹ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 6th International Conference on Artificial Intelligence and Electromechanical Automation (AIEA 2025). 5 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10461v3",
      "published_date": "2025-07-14 16:39:14 UTC",
      "updated_date": "2025-08-19 10:20:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:31.825828+00:00"
    },
    {
      "arxiv_id": "2507.10643v3",
      "title": "TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc Attributions for Opaque Models",
      "title_zh": "TaylorPODAï¼šåŸºäºæ³°å‹’å±•å¼€çš„ä¸é€æ˜æ¨¡å‹äº‹åå½’å› æ”¹è¿›æ–¹æ³•",
      "authors": [
        "Yuchi Tang",
        "IÃ±aki Esnaola",
        "George Panoutsos"
      ],
      "abstract": "Existing post-hoc model-agnostic methods generate external explanations for opaque models, primarily by locally attributing the model output to its input features. However, they often lack an explicit and systematic framework for quantifying the contribution of individual features. Building on the Taylor expansion framework introduced by Deng et al. (2024) to unify existing local attribution methods, we propose a rigorous set of postulates -- \"precision\", \"federation\", and \"zero-discrepancy\" -- to govern Taylor term-specific attribution. Guided by these postulates, we introduce TaylorPODA (Taylor expansion-derived imPortance-Order aDapted Attribution), which incorporates an additional \"adaptation\" property. This property enables alignment with task-specific goals, especially in post-hoc settings lacking ground-truth explanations. Empirical evaluations demonstrate that TaylorPODA achieves competitive results against baseline methods, providing principled and visualization-friendly explanations. This work enhances the trustworthy deployment of opaque models by offering explanations with stronger theoretical grounding.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰äº‹åæ¨¡å‹æ— å…³æ–¹æ³•(post-hoc model-agnostic methods)åœ¨é‡åŒ–ç‰¹å¾è´¡çŒ®æ—¶ç¼ºä¹ç³»ç»Ÿæ¡†æ¶çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºTaylor expansionç†è®ºçš„å½’å› æ”¹è¿›æ–¹æ³•TaylorPODAã€‚è¯¥æ–¹æ³•éµå¾ªâ€œprecisionâ€ã€â€œfederationâ€å’Œâ€œzero-discrepancyâ€ä¸‰é¡¹æ ¸å¿ƒå…¬è®¾ï¼Œé€šè¿‡ä¸¥è°¨çš„æ•°å­¦æ¡†æ¶è§„èŒƒäº†ç‰¹å®šé¡¹çš„å½’å› é€»è¾‘ã€‚TaylorPODAç‰¹åˆ«å¼•å…¥äº†â€œadaptationâ€å±æ€§ï¼Œä½¿å…¶åœ¨ç¼ºä¹åœ°é¢çœŸå€¼è§£é‡Š(ground-truth explanations)çš„å¤æ‚è®¾å®šä¸‹ï¼Œä¾ç„¶èƒ½ä½¿è§£é‡Šç»“æœä¸ç‰¹å®šä»»åŠ¡ç›®æ ‡ä¿æŒå¯¹é½ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTaylorPODAåœ¨æ€§èƒ½ä¸Šå…·æœ‰æ˜¾è‘—ç«äº‰åŠ›ï¼Œèƒ½å¤Ÿä¸ºä¸é€æ˜æ¨¡å‹(opaque models)æä¾›å…·æœ‰æ·±åšç†è®ºæ ¹åŸºä¸”æ˜“äºå¯è§†åŒ–çš„è§£é‡Šæ–¹æ¡ˆã€‚è¿™é¡¹å·¥ä½œå¢å¼ºäº†æ¨¡å‹è§£é‡Šçš„å¯ä¿¡åº¦ï¼Œä¸ºä¸é€æ˜äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å®‰å…¨éƒ¨ç½²æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "18 pages, 4 figures. Submitted to AAAI 2026. Re-upload with amended manuscript",
      "pdf_url": "https://arxiv.org/pdf/2507.10643v3",
      "published_date": "2025-07-14 16:38:30 UTC",
      "updated_date": "2025-08-05 16:03:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:34.721177+00:00"
    },
    {
      "arxiv_id": "2507.10642v1",
      "title": "First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network",
      "title_zh": "é¦–ä¸ªåŸºäºè½»é‡çº§è”æƒ³è®°å¿† Hopfield ç¥ç»ç½‘ç»œçš„ç”Ÿç‰©å£°å­¦æ£€æµ‹ AI æ¨¡å‹",
      "authors": [
        "Andrew Gascoyne",
        "Wendy Lomas"
      ],
      "abstract": "A growing issue within conservation bioacoustics is the task of analysing the vast amount of data generated from the use of passive acoustic monitoring devices. In this paper, we present an alternative AI model which has the potential to help alleviate this problem. Our model formulation addresses the key issues encountered when using current AI models for bioacoustic analysis, namely the: limited training data available; environmental impact, particularly in energy consumption and carbon footprint of training and implementing these models; and associated hardware requirements. The model developed in this work uses associative memory via a transparent, explainable Hopfield neural network to store signals and detect similar signals which can then be used to classify species. Training is rapid ($3$\\,ms), as only one representative signal is required for each target sound within a dataset. The model is fast, taking only $5.4$\\,s to pre-process and classify all $10384$ publicly available bat recordings, on a standard Apple MacBook Air. The model is also lightweight with a small memory footprint of $144.09$\\,MB of RAM usage. Hence, the low computational demands make the model ideal for use on a variety of standard personal devices with potential for deployment in the field via edge-processing devices. It is also competitively accurate, with up to $86\\%$ precision on the dataset used to evaluate the model. In fact, we could not find a single case of disagreement between model and manual identification via expert field guides. Although a dataset of bat echolocation calls was chosen to demo this first-of-its-kind AI model, trained on only two representative calls, the model is not species specific. In conclusion, we propose an equitable AI model that has the potential to be a game changer for fast, lightweight, sustainable, transparent, explainable and accurate bioacoustic analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ç§åŸºäºè½»é‡åŒ– associative memory Hopfield neural network çš„ç”Ÿç‰©å£°å­¦æ£€æµ‹ AI æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³è¢«åŠ¨å£°å­¦ç›‘æµ‹ä¸­å¤§æ•°æ®é‡åˆ†æã€é«˜èƒ½è€—åŠç¡¬ä»¶é™åˆ¶ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹åˆ©ç”¨é€æ˜ä¸”å…·æœ‰ explainable ç‰¹æ€§çš„ Hopfield neural network å­˜å‚¨ä¿¡å·ï¼Œä»…éœ€å•ä¸ªä»£è¡¨æ€§ä¿¡å·å³å¯åœ¨ 3ms å†…å®Œæˆè®­ç»ƒï¼Œæ˜¾è‘—é™ä½äº†å¯¹æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨æ ‡å‡† MacBook Air ä¸Šå¤„ç† 10384 æ¡è™è å½•éŸ³ä»…éœ€ 5.4sï¼ŒRAM å ç”¨ä»…ä¸º 144.09MBï¼Œä¸”åœ¨æµ‹è¯•é›†ä¸Šçš„ precision é«˜è¾¾ 86%ï¼Œä¸ä¸“å®¶é‰´å®šç»“æœé«˜åº¦ä¸€è‡´ã€‚å…¶æä½çš„è®¡ç®—éœ€æ±‚ä½¿å…¶éå¸¸é€‚åˆéƒ¨ç½²åœ¨ edge-processing devices ä¸Šè¿›è¡Œé‡å¤–ç°åœºç›‘æµ‹ã€‚å°½ç®¡ä»¥è™è æ•°æ®é›†ä½œä¸ºæ¼”ç¤ºï¼Œä½†è¯¥æ¨¡å‹ä¸å…·æœ‰ç‰©ç§ç‰¹å¼‚æ€§ï¼Œä¸ºå¿«é€Ÿã€è½»é‡ä¸”å¯æŒç»­çš„ç”Ÿç‰©å£°å­¦åˆ†ææä¾›äº†ä¸€ç§å…¼é¡¾å‡†ç¡®æ€§ä¸é€æ˜åº¦çš„å…¨æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10642v1",
      "published_date": "2025-07-14 16:37:20 UTC",
      "updated_date": "2025-07-14 16:37:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:43.521196+00:00"
    },
    {
      "arxiv_id": "2507.10457v2",
      "title": "Logic layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems",
      "title_zh": "é€»è¾‘å±‚æç¤ºæ§åˆ¶æ³¨å…¥ (LPCI)ï¼šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„ä¸€ç§æ–°å‹å®‰å…¨æ¼æ´ç±»åˆ«",
      "authors": [
        "Hammad Atta",
        "Ken Huang",
        "Manish Bhatt",
        "Kamal Ahmed",
        "Muhammad Aziz Ul Haq",
        "Yasir Mehmood"
      ],
      "abstract": "The integration of large language models (LLMs) into enterprise systems has introduced a new class of covert security vulnerabilities, particularly within logic execution layers and persistent memory contexts. This paper introduces Logic-layer Prompt Control Injection (LPCI), a novel category of attacks that embeds encoded, delayed, and conditionally triggered payloads within memory, vector stores, or tool outputs. These payloads can bypass conventional input filters and trigger unauthorised behaviour across sessions.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†é€»è¾‘å±‚æç¤ºæ§åˆ¶æ³¨å…¥(Logic-layer Prompt Control Injection, LPCI)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é›†æˆå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ä¼ä¸šçº§æ™ºèƒ½ä½“ç³»ç»Ÿä¸­é€»è¾‘æ‰§è¡Œå±‚å’ŒæŒä¹…å†…å­˜ç¯å¢ƒçš„æ–°å‹å®‰å…¨æ¼æ´ç±»åˆ«ã€‚LPCI å…è®¸æ”»å‡»è€…åœ¨å†…å­˜ã€å‘é‡æ•°æ®åº“(Vector Stores)æˆ–å·¥å…·è¾“å‡ºä¸­åµŒå…¥ç»è¿‡ç¼–ç ã€å»¶è¿Ÿä¸”ç”±ç‰¹å®šæ¡ä»¶è§¦å‘çš„æ¶æ„æœ‰æ•ˆè½½è·(Payloads)ã€‚è¿™äº›æ”»å‡»æ‰‹æ®µå…·æœ‰æé«˜çš„éšè”½æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç»•è¿‡å¸¸è§„çš„è¾“å…¥è¿‡æ»¤å™¨ï¼Œå¹¶åœ¨ä¸åŒçš„ä¼šè¯ä¹‹é—´æŒç»­å­˜åœ¨ã€‚ä¸€æ—¦æ»¡è¶³è§¦å‘æ¡ä»¶ï¼Œè¿™äº›è½½è·å¯ä»¥è¯±å¯¼ç³»ç»Ÿæ‰§è¡Œæœªç»æˆæƒçš„æ¶æ„è¡Œä¸ºï¼Œå¯¹è‡ªä¸»ç³»ç»Ÿçš„é€»è¾‘å®Œæ•´æ€§æ„æˆä¸¥é‡å¨èƒã€‚è¯¥è®ºæ–‡é€šè¿‡å®šä¹‰å¹¶åˆ†æè¿™ä¸€æ–°å‹æ¼æ´ï¼Œæ­ç¤ºäº†æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤„ç†é•¿æœŸè®°å¿†å’Œå·¥å…·äº¤äº’æ—¶æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œä¸ºå¢å¼ºä¼ä¸šçº§ AI åº”ç”¨çš„å®‰å…¨æ€§æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10457v2",
      "published_date": "2025-07-14 16:37:05 UTC",
      "updated_date": "2025-08-06 22:10:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:42.633810+00:00"
    },
    {
      "arxiv_id": "2507.10449v2",
      "title": "CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding",
      "title_zh": "CoralVQAï¼šç”¨äºçŠç‘šç¤å›¾åƒç†è§£çš„å¤§è§„æ¨¡è§†è§‰é—®ç­”æ•°æ®é›†",
      "authors": [
        "Hongyong Han",
        "Wei Wang",
        "Gaowei Zhang",
        "Mingjie Li",
        "Yi Wang"
      ],
      "abstract": "Coral reefs are vital yet vulnerable ecosystems that require continuous monitoring to support conservation. While coral reef images provide essential information in coral monitoring, interpreting such images remains challenging due to the need for domain expertise. Visual Question Answering (VQA), powered by Large Vision-Language Models (LVLMs), has great potential in user-friendly interaction with coral reef images. However, applying VQA to coral imagery demands a dedicated dataset that addresses two key challenges: domain-specific annotations and multidimensional questions. In this work, we introduce CoralVQA, the first large-scale VQA dataset for coral reef analysis. It contains 12,805 real-world coral images from 67 coral genera collected from 3 oceans, along with 277,653 question-answer pairs that comprehensively assess ecological and health-related conditions. To construct this dataset, we develop a semi-automatic data construction pipeline in collaboration with marine biologists to ensure both scalability and professional-grade data quality. CoralVQA presents novel challenges and provides a comprehensive benchmark for studying vision-language reasoning in the context of coral reef images. By evaluating several state-of-the-art LVLMs, we reveal key limitations and opportunities. These insights form a foundation for future LVLM development, with a particular emphasis on supporting coral conservation efforts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CoralVQAï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºçŠç‘šç¤åˆ†æçš„å¤§è§„æ¨¡è§†è§‰é—®ç­” (Visual Question Answering, VQA) æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³çŠç‘šç¤å›¾åƒè§£è¯»ä¸­å¯¹ä¸“ä¸šé¢†åŸŸçŸ¥è¯†çš„éœ€æ±‚ä»¥åŠå¤æ‚çš„å¤šç»´æé—®æŒ‘æˆ˜ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªä¸‰å¤§æ´‹ã€æ¶µç›– 67 ä¸ªçŠç‘šå±çš„ 12,805 å¼ çœŸå®å›¾åƒï¼Œä»¥åŠ 277,653 ä¸ªæ¶µç›–ç”Ÿæ€å’Œå¥åº·çŠ¶å†µçš„é—®ç­”å¯¹ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸æµ·æ´‹ç”Ÿç‰©å­¦å®¶åˆä½œï¼Œå¼€å‘äº†ä¸€å¥—åŠè‡ªåŠ¨åŒ–çš„æ•°æ®æ„å»ºç®¡çº¿ (Semi-automatic data construction pipeline)ï¼Œåœ¨ä¿è¯æ•°æ®è§„æ¨¡çš„åŒæ—¶ç¡®ä¿äº†ä¸“ä¸šçº§åˆ«çš„æ ‡æ³¨è´¨é‡ã€‚CoralVQA ä¸ºçŠç‘šç¤å›¾åƒé¢†åŸŸçš„è§†è§‰è¯­è¨€æ¨ç† (Vision-language reasoning) ç ”ç©¶æä¾›äº†å…¨æ–°çš„åŸºå‡†æµ‹è¯•ã€‚é€šè¿‡è¯„ä¼°å¤šç§å…ˆè¿›çš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ (LVLMs)ï¼Œç ”ç©¶æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸä¸­çš„å±€é™æ€§ä¸æ½œåœ¨æœºé‡ã€‚è¿™äº›å‘ç°ä¸ºæœªæ¥åˆ©ç”¨äººå·¥æ™ºèƒ½æ”¯æŒçŠç‘šç¤ä¿æŠ¤å·¥ä½œå¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10449v2",
      "published_date": "2025-07-14 16:29:10 UTC",
      "updated_date": "2025-11-02 08:33:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:44.285087+00:00"
    },
    {
      "arxiv_id": "2507.10445v1",
      "title": "Referential ambiguity and clarification requests: comparing human and LLM behaviour",
      "title_zh": "æŒ‡ç§°æ­§ä¹‰ä¸æ¾„æ¸…è¯·æ±‚ï¼šäººç±»ä¸å¤§è¯­è¨€æ¨¡å‹è¡Œä¸ºçš„å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Chris Madge",
        "Matthew Purver",
        "Massimo Poesio"
      ],
      "abstract": "In this work we examine LLMs' ability to ask clarification questions in task-oriented dialogues that follow the asynchronous instruction-giver/instruction-follower format. We present a new corpus that combines two existing annotations of the Minecraft Dialogue Corpus -- one for reference and ambiguity in reference, and one for SDRT including clarifications -- into a single common format providing the necessary information to experiment with clarifications and their relation to ambiguity. With this corpus we compare LLM actions with original human-generated clarification questions, examining how both humans and LLMs act in the case of ambiguity. We find that there is only a weak link between ambiguity and humans producing clarification questions in these dialogues, and low correlation between humans and LLMs. Humans hardly ever produce clarification questions for referential ambiguity, but often do so for task-based uncertainty. Conversely, LLMs produce more clarification questions for referential ambiguity, but less so for task uncertainty. We question if LLMs' ability to ask clarification questions is predicated on their recent ability to simulate reasoning, and test this with different reasoning approaches, finding that reasoning does appear to increase question frequency and relevancy.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢å‘ä»»åŠ¡çš„å¯¹è¯ä¸­æå‡ºæ¾„æ¸…è¯·æ±‚ï¼ˆclarification requestsï¼‰çš„èƒ½åŠ›ï¼Œå¹¶å¯¹æ¯”äº†äººç±»ä¸æ¨¡å‹åœ¨å¤„ç†æŒ‡ä»£æ­§ä¹‰ï¼ˆreferential ambiguityï¼‰æ—¶çš„è¡Œä¸ºå·®å¼‚ã€‚ä½œè€…é€šè¿‡æ•´åˆå·²æœ‰çš„ Minecraft å¯¹è¯è¯­æ–™åº“ï¼Œæ„å»ºäº†ä¸€ä¸ªç»“åˆæŒ‡ä»£æ ‡æ³¨ä¸åˆ†å±‚è¯è¯­ç†è®ºï¼ˆSDRTï¼‰æ¾„æ¸…æ ‡æ³¨çš„æ–°è¯­æ–™åº“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œäººç±»ä¸ LLMs åœ¨æé—®åŠ¨æœºä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼šäººç±»è¾ƒå°‘é’ˆå¯¹æŒ‡ä»£æ­§ä¹‰æé—®ï¼Œè€Œå¤šå…³æ³¨ä»»åŠ¡ä¸ç¡®å®šæ€§ï¼ˆtask uncertaintyï¼‰ï¼›LLMs åˆ™æ›´å€¾å‘äºå°±æŒ‡ä»£æ­§ä¹‰è¿›è¡Œæ¾„æ¸…ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œäººç±»è¡Œä¸ºä¸ LLMs è¡Œä¸ºä¹‹é—´ä»…å­˜åœ¨å¼±ç›¸å…³æ€§ï¼Œå‡¸æ˜¾äº†ä¸¤è€…åœ¨è¯†åˆ«æ­§ä¹‰æœºåˆ¶ä¸Šçš„ä¸åŒã€‚æœ€åï¼Œè¯¥ç ”ç©¶éªŒè¯äº†æ¨ç†ï¼ˆreasoningï¼‰æ–¹æ³•å¯¹æ¨¡å‹è¡¨ç°çš„ç§¯æå½±å“ï¼Œè¯æ˜æ¨¡æ‹Ÿæ¨ç†è¿‡ç¨‹èƒ½æœ‰æ•ˆæå‡ LLMs æé—®çš„é¢‘ç‡åŠå…¶ä¸å¯¹è¯èƒŒæ™¯çš„ç›¸å…³æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10445v1",
      "published_date": "2025-07-14 16:28:00 UTC",
      "updated_date": "2025-07-14 16:28:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:53.749241+00:00"
    },
    {
      "arxiv_id": "2507.10641v1",
      "title": "A Code Comprehension Benchmark for Large Language Models for Code",
      "title_zh": "é’ˆå¯¹ä»£ç å¤§è¯­è¨€æ¨¡å‹çš„ä»£ç ç†è§£åŸºå‡†",
      "authors": [
        "Jayant Havare",
        "Saurav Chaudhary",
        "Ganesh Ramakrishnan",
        "Kaushik Maharajan",
        "Srikanth Tamilselvam"
      ],
      "abstract": "Large Language Models have shown impressive capabilities in coding tasks like code generation and code completion, as they have been trained on a large amount of code data. Also, since one of the core pretraining objectives is Next Token Prediction, these models tends to learn surface-level syntactic patterns in code. However, this does not guarantee code comprehension ability i.e. the ability to capture the semantics of the code. In our opinion, this is the reason why these models often underperform on tasks that require deeper semantic understanding, such as code debugging and code optimization. To address this, we propose fine-tuning these models specifically for code comprehension tasks using large-scale datasets, enabling them to develop a more robust understanding of code semantics. We evaluate three code models of varying sizes on a suite of code comprehension tasks designed to assess semantic understanding beyond surface-level syntactic pattern matching. In particular, we analyze performance on the Subjectivity Grading Task and observe that model performance improves after fine-tuning on relevant downstream tasks. The most significant improvement is seen in the QWQ-32B model, where accuracy increases from 70% to 83.47%. A similar or explainable trend is observed across other models, clearly indicating an enhancement in code comprehension ability. Among the models studied, the DPO-fine-tuned Codestral-22B achieves the highest micro-accuracy of 87.66% on the Subjectivity Grading Task.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä»£ç è¯­æ³•æ¨¡å¼å­¦ä¹ ä¸æ·±å±‚è¯­ä¹‰ç†è§£ä¹‹é—´çš„å·®è·ï¼ŒæŒ‡å‡ºç¼ºä¹ Code Comprehension èƒ½åŠ›æ˜¯å¯¼è‡´æ¨¡å‹åœ¨ä»£ç è°ƒè¯•å’Œä¼˜åŒ–ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³çš„æ ¸å¿ƒåŸå› ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºé€šè¿‡å¤§è§„æ¨¡æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œä¸“é—¨çš„ Code Comprehension å¾®è°ƒï¼Œæ—¨åœ¨æå‡æ¨¡å‹å¯¹ä»£ç è¯­ä¹‰çš„æ•æ‰èƒ½åŠ›ã€‚ç ”ç©¶åœ¨ä¸€ç³»åˆ—è¶…è¶Šè¡¨é¢æ¨¡å¼åŒ¹é…çš„è¯„ä¼°ä»»åŠ¡ä¸Šå¯¹ä¸åŒè§„æ¨¡çš„æ¨¡å‹è¿›è¡Œäº†æµ‹è¯•ï¼Œå¹¶é‡ç‚¹å…³æ³¨äº† Subjectivity Grading Taskã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡ç›¸å…³ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒåï¼Œæ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½å‡æ˜¾è‘—æå‡ï¼Œå…¶ä¸­ QWQ-32B çš„å‡†ç¡®ç‡ä» 70% æé«˜åˆ° 83.47%ã€‚æœ€ç»ˆï¼Œç»è¿‡ DPO å¾®è°ƒçš„ Codestral-22B æ¨¡å‹åœ¨ Subjectivity Grading Task ä¸­å–å¾—äº† 87.66% çš„æœ€é«˜å¾®ç²¾åº¦(Micro-accuracy)ï¼Œæœ‰åŠ›è¯æ˜äº†é’ˆå¯¹æ€§å¾®è°ƒå¯¹å¢å¼ºä»£ç è¯­ä¹‰ç†è§£èƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "10 Pages, 5 Figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10641v1",
      "published_date": "2025-07-14 16:19:49 UTC",
      "updated_date": "2025-07-14 16:19:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:36:50.281359+00:00"
    },
    {
      "arxiv_id": "2507.10430v2",
      "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout",
      "title_zh": "é’ˆå¯¹å¼‚æ„æ•°æ®ä¸è‡ªé€‚åº” Dropout çš„é«˜æ•ˆè”é‚¦å­¦ä¹ ",
      "authors": [
        "Ji Liu",
        "Beichen Ma",
        "Qiaolin Yu",
        "Ruoming Jin",
        "Jingbo Zhou",
        "Yang Zhou",
        "Huaiyu Dai",
        "Haixun Wang",
        "Dejing Dou",
        "Patrick Valduriez"
      ],
      "abstract": "Federated Learning (FL) is a promising distributed machine learning approach that enables collaborative training of a global model using multiple edge devices. The data distributed among the edge devices is highly heterogeneous. Thus, FL faces the challenge of data distribution and heterogeneity, where non-Independent and Identically Distributed (non-IID) data across edge devices may yield in significant accuracy drop. Furthermore, the limited computation and communication capabilities of edge devices increase the likelihood of stragglers, thus leading to slow model convergence. In this paper, we propose the FedDHAD FL framework, which comes with two novel methods: Dynamic Heterogeneous model aggregation (FedDH) and Adaptive Dropout (FedAD). FedDH dynamically adjusts the weights of each local model within the model aggregation process based on the non-IID degree of heterogeneous data to deal with the statistical data heterogeneity. FedAD performs neuron-adaptive operations in response to heterogeneous devices to improve accuracy while achieving superb efficiency. The combination of these two methods makes FedDHAD significantly outperform state-of-the-art solutions in terms of accuracy (up to 6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to 15.0% smaller).",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FedDHADæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³Federated Learning (FL)åœ¨å¤„ç†å¼‚æ„æ•°æ®ï¼ˆnon-IIDï¼‰æ—¶é¢ä¸´çš„å‡†ç¡®ç‡ä¸‹é™åŠè¾¹ç¼˜è®¾å¤‡è®¡ç®—é™åˆ¶å¯¼è‡´çš„æ”¶æ•›ç¼“æ…¢é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤ç§åˆ›æ–°æ–¹æ³•ï¼šDynamic Heterogeneous model aggregation (FedDH) å’Œ Adaptive Dropout (FedAD)ã€‚FedDHèƒ½å¤Ÿæ ¹æ®æœ¬åœ°æ•°æ®çš„non-IIDç¨‹åº¦åŠ¨æ€è°ƒæ•´æ¨¡å‹èšåˆæƒé‡ï¼Œä»¥åº”å¯¹ç»Ÿè®¡å¼‚æ„æ€§æŒ‘æˆ˜ã€‚FedADåˆ™é€šè¿‡é’ˆå¯¹å¼‚æ„è®¾å¤‡æ‰§è¡Œç¥ç»å…ƒè‡ªé€‚åº”æ“ä½œï¼Œåœ¨ä¿è¯ç²¾åº¦çš„åŒæ—¶å¤§å¹…æå‡äº†å¤„ç†æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFedDHADåœ¨å‡†ç¡®ç‡ä¸Šæ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ¡ˆæå‡äº†å¤šè¾¾6.7%ï¼Œè¿è¡Œé€Ÿåº¦å¿«2.02å€ï¼Œä¸”è®¡ç®—æˆæœ¬é™ä½äº†15.0%ï¼Œä¸ºå®ç°é«˜æ•ˆä¸”ä½èƒ½è€—çš„åˆ†å¸ƒå¼æ¨¡å‹è®­ç»ƒæä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "29 pages, to appear in ACM Transactions on Knowledge Discovery from Data (TKDD)",
      "pdf_url": "https://arxiv.org/pdf/2507.10430v2",
      "published_date": "2025-07-14 16:19:00 UTC",
      "updated_date": "2025-07-15 02:55:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:02.025295+00:00"
    },
    {
      "arxiv_id": "2507.14200v1",
      "title": "Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System",
      "title_zh": "å¼€æºå¤§è¯­è¨€æ¨¡å‹åä½œè¶…è¶Šé—­æºå¤§è¯­è¨€æ¨¡å‹ï¼šä¸€ç§å¯æ‰©å±•çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Shengji Tang",
        "Jianjian Cao",
        "Weihao Lin",
        "Jiale Hong",
        "Bo Zhang",
        "Shuyue Hu",
        "Lei Bai",
        "Tao Chen",
        "Wanli Ouyang",
        "Peng Ye"
      ],
      "abstract": "This paper aims to demonstrate the potential and strengths of open-source collectives. It leads to a promising question: Can we harness multiple open-source LLMs to match or even beat the closed-source LLMs? To answer this, we propose SMACS, a scalable multi-agent collaboration system (MACS) framework with high performance. Specifically, for continuous integration of new LLMs and generalization to diverse questions, we first propose a Retrieval-based Prior Selection (RPS), which assigns a proxy performance score to each LLM to select the Top-k LLMs at the instance level for any given question. Then, we propose an Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the generation of diverse responses through prior dropping and selecting the high-quality response via a hybrid posterior score. Experiments on eight mainstream benchmarks validate the effectiveness of our SMACS: by integrating fifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025, e.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%) across multiple tasks. Remarkably, it even exceeds the average of best results of different datasets from both open-source LLMs (+2.86%) and closed-source LLMs (+2.04%), pushing the upper bound of intelligence. Code will be released at https://github.com/magent4aci/SMACS.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SMACSï¼Œä¸€ç§é«˜æ€§èƒ½çš„å¯æ‰©å±•å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿ (Scalable Multi-Agent Collaboration System) æ¡†æ¶ï¼Œæ—¨åœ¨éªŒè¯å¤šä¸ªå¼€æºå¤§è¯­è¨€æ¨¡å‹ (LLMs) åä½œæ˜¯å¦èƒ½åŒ¹é…æˆ–ç”šè‡³è¶…è¶Šé—­æºæ¨¡å‹ã€‚ä¸ºäº†å®ç°æ–°æ¨¡å‹çš„æŒç»­é›†æˆå’Œå¯¹å¤šæ ·åŒ–é—®é¢˜çš„æ³›åŒ–ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†åŸºäºæ£€ç´¢çš„å…ˆéªŒé€‰æ‹© (Retrieval-based Prior Selection, RPS) æŠ€æœ¯ï¼Œé€šè¿‡åˆ†é…ä»£ç†æ€§èƒ½åˆ†æ•°é’ˆå¯¹ç‰¹å®šé—®é¢˜ç­›é€‰ Top-k æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†æ¢ç´¢-åˆ©ç”¨é©±åŠ¨çš„åéªŒå¢å¼º (Exploration-Exploitation-Driven Posterior Enhancement, EPE)ï¼Œé€šè¿‡å…ˆéªŒèˆå¼ƒæœºåˆ¶é¼“åŠ±ç”Ÿæˆå¤šæ ·åŒ–å“åº”å¹¶åˆ©ç”¨æ··åˆåéªŒåˆ†æ•°é€‰å–é«˜è´¨é‡å›ç­”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé›†æˆåäº”ä¸ªå¼€æºæ¨¡å‹çš„ SMACS åœ¨å¤šä¸ªä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äº Claude-3.7-Sonnet (+12.73%)ã€GPT-4.1 (+5.36%) å’Œ GPT-o3-mini (+5.28%) ç­‰ 2025 å¹´é¢†å…ˆçš„é—­æºæ¨¡å‹ã€‚è¯¥ç ”ç©¶æˆåŠŸæ¨é«˜äº†æ™ºèƒ½çš„ä¸Šé™ï¼Œç”šè‡³è¶…è¿‡äº†å¼€æºå’Œé—­æºæ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æœ€ä½³ç»“æœå¹³å‡å€¼ï¼Œå……åˆ†å±•ç¤ºäº†å¼€æºé›†ä½“åä½œçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14200v1",
      "published_date": "2025-07-14 16:17:11 UTC",
      "updated_date": "2025-07-14 16:17:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:04.035167+00:00"
    },
    {
      "arxiv_id": "2507.10421v1",
      "title": "SentiDrop: A Multi Modal Machine Learning model for Predicting Dropout in Distance Learning",
      "title_zh": "SentiDropï¼šé¢å‘è¿œç¨‹å­¦ä¹ è¾å­¦é¢„æµ‹çš„å¤šæ¨¡æ€æœºå™¨å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Meriem Zerkouk",
        "Miloud Mihoubi",
        "Belkacem Chikhaoui"
      ],
      "abstract": "School dropout is a serious problem in distance learning, where early detection is crucial for effective intervention and student perseverance. Predicting student dropout using available educational data is a widely researched topic in learning analytics. Our partner's distance learning platform highlights the importance of integrating diverse data sources, including socio-demographic data, behavioral data, and sentiment analysis, to accurately predict dropout risks. In this paper, we introduce a novel model that combines sentiment analysis of student comments using the Bidirectional Encoder Representations from Transformers (BERT) model with socio-demographic and behavioral data analyzed through Extreme Gradient Boosting (XGBoost). We fine-tuned BERT on student comments to capture nuanced sentiments, which were then merged with key features selected using feature importance techniques in XGBoost. Our model was tested on unseen data from the next academic year, achieving an accuracy of 84\\%, compared to 82\\% for the baseline model. Additionally, the model demonstrated superior performance in other metrics, such as precision and F1-score. The proposed method could be a vital tool in developing personalized strategies to reduce dropout rates and encourage student perseverance",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SentiDropï¼Œä¸€ç§ç”¨äºé¢„æµ‹è¿œç¨‹å­¦ä¹ (Distance Learning)ä¸­å­¦ç”Ÿé€€å­¦é£é™©çš„å¤šæ¨¡æ€æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ›æ–°æ€§åœ°ç»“åˆäº†åˆ©ç”¨BERTå¯¹å­¦ç”Ÿè¯„è®ºè¿›è¡Œçš„Sentiment Analysisï¼Œä»¥åŠé€šè¿‡XGBooståˆ†æçš„ç¤¾ä¼šäººå£ç»Ÿè®¡å­¦æ•°æ®å’Œè¡Œä¸ºæ•°æ®ã€‚ç ”ç©¶å›¢é˜Ÿå¯¹BERTè¿›è¡Œäº†å¾®è°ƒä»¥æ•æ‰ç»†å¾®çš„æƒ…æ„Ÿå€¾å‘ï¼Œå¹¶åˆ©ç”¨XGBoostçš„ç‰¹å¾é‡è¦æ€§æŠ€æœ¯ç­›é€‰å…³é”®ç‰¹å¾è¿›è¡Œèåˆã€‚åœ¨ä¸‹ä¸€å­¦å¹´çš„æœªçŸ¥æ•°æ®æµ‹è¯•ä¸­ï¼ŒSentiDropè¾¾åˆ°äº†84%çš„å‡†ç¡®ç‡ï¼Œä¼˜äº82%çš„åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨Precisionå’ŒF1-scoreç­‰æŒ‡æ ‡ä¸Šä¹Ÿå±•ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•ä¸ºæ•™è‚²æœºæ„åˆ¶å®šä¸ªæ€§åŒ–å¹²é¢„ç­–ç•¥ã€é™ä½é€€å­¦ç‡åŠæé«˜å­¦ç”ŸåšæŒç‡æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "International Conference on Education and New Learning Technologies (2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.10421v1",
      "published_date": "2025-07-14 16:04:34 UTC",
      "updated_date": "2025-07-14 16:04:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:01.822868+00:00"
    },
    {
      "arxiv_id": "2507.10419v1",
      "title": "Multiple Choice Learning of Low Rank Adapters for Language Modeling",
      "title_zh": "é¢å‘è¯­è¨€å»ºæ¨¡çš„ä½ç§©é€‚é…å™¨å¤šé¡¹é€‰æ‹©å­¦ä¹ ",
      "authors": [
        "Victor Letzelter",
        "Hugo Malard",
        "Mathieu Fontaine",
        "GaÃ«l Richard",
        "Slim Essid",
        "Andrei Bursuc",
        "Patrick PÃ©rez"
      ],
      "abstract": "We propose LoRA-MCL, a training scheme that extends next-token prediction in language models with a method designed to decode diverse, plausible sentence continuations at inference time. Traditional language modeling is an intrinsically ill-posed problem: given a context, multiple futures may be equally plausible. Our approach leverages Multiple Choice Learning (MCL) and the Winner-Takes-All (WTA) loss to efficiently handle ambiguity through Low-Rank Adaptation (LoRA). We provide a theoretical interpretation of applying Multiple Choice Learning to Language Modeling, assuming the data is generated from a mixture of distributions. To illustrate the proposed approach, we use data sampled from mixtures of Markov chains. We then demonstrate with extensive experiments on real-world visual and audio captioning tasks that our method achieves high diversity and relevance in generated outputs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LoRA-MCLï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å¢å¼ºè¯­è¨€æ¨¡å‹åœ¨æ¨ç†é˜¶æ®µç”Ÿæˆå¤šæ ·ä¸”åˆç†çš„å¥å­ç»­å†™èƒ½åŠ›çš„è®­ç»ƒæ–¹æ¡ˆã€‚é’ˆå¯¹ä¼ ç»Ÿè¯­è¨€å»ºæ¨¡åœ¨å¤„ç†æ¨¡ç³Šä¸Šä¸‹æ–‡æ—¶å­˜åœ¨çš„å›ºæœ‰æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•ç»“åˆäº† Multiple Choice Learning (MCL) å’Œ Winner-Takes-All (WTA) æŸå¤±å‡½æ•°ï¼Œå¹¶åˆ©ç”¨ Low-Rank Adaptation (LoRA) æŠ€æœ¯æ¥é«˜æ•ˆåº”å¯¹æ­§ä¹‰ã€‚ä½œè€…ä¸º Multiple Choice Learning åœ¨è¯­è¨€å»ºæ¨¡ä¸­çš„åº”ç”¨æä¾›äº†ç†è®ºè§£é‡Šï¼Œå‡è®¾æ•°æ®æºè‡ªå¤šç§åˆ†å¸ƒçš„æ··åˆï¼Œå¹¶é‡‡ç”¨é©¬å°”å¯å¤«é“¾ (Markov chains) æ··åˆé‡‡æ ·æ•°æ®éªŒè¯äº†è¯¥æ–¹æ³•ã€‚åœ¨çœŸå®çš„è§†è§‰å’ŒéŸ³é¢‘å­—å¹•ç”Ÿæˆ (visual and audio captioning tasks) å®éªŒä¸­ï¼ŒLoRA-MCL å±•ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ï¼Œå…¶ç”Ÿæˆçš„è¾“å‡ºåœ¨ä¿æŒé«˜åº¦ç›¸å…³æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†ç»“æœçš„å¤šæ ·æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10419v1",
      "published_date": "2025-07-14 16:00:51 UTC",
      "updated_date": "2025-07-14 16:00:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:21.526626+00:00"
    },
    {
      "arxiv_id": "2507.10409v2",
      "title": "Energy Efficiency in AI for 5G and Beyond: A DeepRx Case Study",
      "title_zh": "é¢å‘ 5G åŠæœªæ¥é€šä¿¡çš„äººå·¥æ™ºèƒ½èƒ½æ•ˆï¼šDeepRx æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Amine Lbath",
        "Ibtissam Labriji"
      ],
      "abstract": "This study addresses the challenge of balancing energy efficiency with performance in AI/ML models, focusing on DeepRX, a deep learning receiver based on a fully convolutional ResNet architecture. We evaluate the energy consumption of DeepRX, considering factors including FLOPs/Watt and FLOPs/clock, and find consistency between estimated and actual energy usage, influenced by memory access patterns. The research extends to comparing energy dynamics during training and inference phases. A key contribution is the application of knowledge distillation (KD) to train a compact DeepRX student model that emulates the performance of the teacher model but with reduced energy consumption. We experiment with different student model sizes, optimal teacher sizes, and KD hyperparameters. Performance is measured by comparing the Bit Error Rate (BER) performance versus Signal-to-Interference & Noise Ratio (SINR) values of the distilled model and a model trained from scratch. The distilled models demonstrate a lower error floor across SINR levels, highlighting the effectiveness of KD in achieving energy-efficient AI solutions.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹5GåŠæœªæ¥ç§»åŠ¨é€šä¿¡ä¸­AI/MLæ¨¡å‹åœ¨æ€§èƒ½ä¸èƒ½æ•ˆä¹‹é—´çš„å¹³è¡¡æŒ‘æˆ˜ï¼Œä»¥åŸºäºå…¨å·ç§¯ResNetæ¶æ„çš„æ·±åº¦å­¦ä¹ æ¥æ”¶æœºDeepRXä¸ºæ¡ˆä¾‹å±•å¼€ç ”ç©¶ã€‚é€šè¿‡è¯„ä¼°DeepRXåœ¨FLOPs/Wattå’ŒFLOPs/clockç­‰æŒ‡æ ‡ä¸‹çš„èƒ½é‡æ¶ˆè€—ï¼Œç ”ç©¶å‘ç°å†…å­˜è®¿é—®æ¨¡å¼å¯¹å®é™…èƒ½è€—å…·æœ‰æ˜¾è‘—å½±å“ï¼Œå¹¶å¯¹æ¯”äº†è®­ç»ƒä¸æ¨ç†é˜¶æ®µçš„èƒ½é‡åŠ¨æ€ã€‚è¯¥ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®æ˜¯åº”ç”¨çŸ¥è¯†è’¸é¦(Knowledge Distillation, KD)æŠ€æœ¯è®­ç»ƒå‡ºç´§å‡‘çš„DeepRXå­¦ç”Ÿæ¨¡å‹ï¼Œä»¥åœ¨ä¿æŒæ•™å¸ˆæ¨¡å‹æ€§èƒ½çš„åŒæ—¶é™ä½èƒ½è€—ã€‚å®éªŒé€šè¿‡å¯¹æ¯”è¯¯ç ç‡(Bit Error Rate, BER)ä¸ä¿¡å¹²å™ªæ¯”(SINR)å‘ç°ï¼Œè’¸é¦æ¨¡å‹åœ¨å„SINRæ°´å¹³ä¸‹å‡è¡¨ç°å‡ºæ›´ä½çš„è¯¯å·®ä¸‹é™ã€‚ç»“æœè¯æ˜äº†KDæŠ€æœ¯åœ¨æ„å»ºèƒ½æ•ˆå‹AIè§£å†³æ–¹æ¡ˆæ–¹é¢çš„å“è¶Šæœ‰æ•ˆæ€§ï¼Œä¸ºå®ç°ç»¿è‰²é«˜æ•ˆçš„é€šä¿¡ç½‘ç»œAIåº”ç”¨æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10409v2",
      "published_date": "2025-07-14 15:54:06 UTC",
      "updated_date": "2025-07-15 13:17:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:19.227047+00:00"
    },
    {
      "arxiv_id": "2507.14198v2",
      "title": "Retention analysis of edited knowledge after fine-tuning",
      "title_zh": "å¾®è°ƒåå·²ç¼–è¾‘çŸ¥è¯†çš„ç•™å­˜åˆ†æ",
      "authors": [
        "Fufang Wen",
        "Shichang Zhang"
      ],
      "abstract": "Large language models (LLMs) store vast amounts of knowledge, which often requires updates to correct factual errors, incorporate newly acquired information, or adapt model behavior. Model editing methods have emerged as efficient solutions for such updates, offering localized and precise knowledge modification at significantly lower computational cost than continual training. In parallel, LLMs are frequently fine-tuned for a wide range of downstream tasks. However, the effect of fine-tuning on previously edited knowledge remains poorly understood. In this work, we systematically investigate how different fine-tuning objectives interact with various model editing techniques. Our findings show that edited knowledge is substantially more susceptible to forgetting during fine-tuning than intrinsic knowledge acquired through pre-training. This analysis highlights a key limitation of current editing approaches and suggests that evaluating edit robustness under downstream fine-tuning is critical for their practical deployment. We further find that knowledge retention can be significantly improved by either augmenting edit knowledge with paraphrases or by freezing layers associated with edited content in fine-tuning stage, offering insight for developing more robust editing algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç»è¿‡æ¨¡å‹ç¼–è¾‘ï¼ˆModel Editingï¼‰æ›´æ–°çŸ¥è¯†åï¼Œè¿™äº›è¢«ç¼–è¾‘çš„çŸ¥è¯†åœ¨åç»­å¾®è°ƒï¼ˆFine-tuningï¼‰è¿‡ç¨‹ä¸­çš„ç•™å­˜æƒ…å†µã€‚ä½œè€…ç³»ç»Ÿåœ°è°ƒæŸ¥äº†ä¸åŒå¾®è°ƒç›®æ ‡ä¸å„ç§æ¨¡å‹ç¼–è¾‘æŠ€æœ¯çš„ç›¸äº’ä½œç”¨ï¼Œå‘ç°å·²ç¼–è¾‘çš„çŸ¥è¯†æ¯”é¢„è®­ç»ƒè·å¾—çš„å†…åœ¨çŸ¥è¯†ï¼ˆIntrinsic Knowledgeï¼‰åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æ›´å®¹æ˜“è¢«é—å¿˜ã€‚è¿™ä¸€åˆ†ææ­ç¤ºäº†å½“å‰ç¼–è¾‘æ–¹æ³•çš„å…³é”®å±€é™æ€§ï¼Œå¹¶æŒ‡å‡ºåœ¨ä¸‹æ¸¸å¾®è°ƒåœºæ™¯ä¸‹è¯„ä¼°ç¼–è¾‘é²æ£’æ€§ï¼ˆEdit Robustnessï¼‰å¯¹å®é™…éƒ¨ç½²è‡³å…³é‡è¦ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œé€šè¿‡ä½¿ç”¨æ”¹å†™ï¼ˆParaphrasesï¼‰å¢å¼ºç¼–è¾‘çŸ¥è¯†æˆ–åœ¨å¾®è°ƒæ—¶å†»ç»“ç›¸å…³æ¨¡å‹å±‚ï¼Œå¯ä»¥æ˜¾è‘—æå‡çŸ¥è¯†çš„ç•™å­˜æ•ˆæœã€‚è¿™äº›å‘ç°ä¸ºå¼€å‘æ›´å…·é²æ£’æ€§çš„çŸ¥è¯†ç¼–è¾‘ç®—æ³•æä¾›äº†é‡è¦è§è§£ï¼Œç¡®ä¿æ¨¡å‹åœ¨é€‚åº”æ–°ä»»åŠ¡æ—¶èƒ½æœ‰æ•ˆä¿ç•™å·²ä¿®æ­£çš„ä¿¡æ¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14198v2",
      "published_date": "2025-07-14 15:51:19 UTC",
      "updated_date": "2025-10-24 16:26:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:21.138507+00:00"
    },
    {
      "arxiv_id": "2507.10398v1",
      "title": "Devanagari Handwritten Character Recognition using Convolutional Neural Network",
      "title_zh": "åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„å¤©åŸä½“æ‰‹å†™å­—ç¬¦è¯†åˆ«",
      "authors": [
        "Diksha Mehta",
        "Prateek Mehta"
      ],
      "abstract": "Handwritten character recognition is getting popular among researchers because of its possible applications in facilitating technological search engines, social media, recommender systems, etc. The Devanagari script is one of the oldest language scripts in India that does not have proper digitization tools. With the advancement of computing and technology, the task of this research is to extract handwritten Hindi characters from an image of Devanagari script with an automated approach to save time and obsolete data. In this paper, we present a technique to recognize handwritten Devanagari characters using two deep convolutional neural network layers. This work employs a methodology that is useful to enhance the recognition rate and configures a convolutional neural network for effective Devanagari handwritten text recognition (DHTR). This approach uses the Devanagari handwritten character dataset (DHCD), an open dataset with 36 classes of Devanagari characters. Each of these classes has 1700 images for training and testing purposes. This approach obtains promising results in terms of accuracy by achieving 96.36% accuracy in testing and 99.55% in training time.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°åº¦å¤è€çš„ Devanagari è„šæœ¬ç¼ºä¹æœ‰æ•ˆæ•°å­—åŒ–å·¥å…·çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Neural Network, CNN) çš„æ‰‹å†™å­—ç¬¦è¯†åˆ«æ–¹æ³•ã€‚ç ”ç©¶é€šè¿‡æ„å»ºåŒ…å«ä¸¤å±‚æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œçš„æ¶æ„ï¼Œæ—¨åœ¨å®ç°å¯¹æ‰‹å†™å°åœ°è¯­å­—ç¬¦çš„è‡ªåŠ¨åŒ–æå–ä¸è¯†åˆ«ï¼Œä»è€Œæé«˜è¯†åˆ«æ•ˆç‡å¹¶èŠ‚çœå¤„ç†æ—¶é—´ã€‚å®éªŒé‡‡ç”¨äº†åŒ…å« 36 ç±»å­—ç¬¦çš„ Devanagari Handwritten Character Dataset (DHCD) å¼€æ”¾æ•°æ®é›†ï¼Œæ¯ç±»åŒ…å« 1700 å¼ å›¾åƒã€‚ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ Devanagari Handwritten Text Recognition (DHTR) ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆæœï¼Œæµ‹è¯•å‡†ç¡®ç‡è¾¾åˆ° 96.36%ï¼Œè®­ç»ƒå‡†ç¡®ç‡é«˜è¾¾ 99.55%ã€‚è¯¥å·¥ä½œè¯æ˜äº†æ‰€ææ¶æ„åœ¨å¤„ç†å¤æ‚æ‰‹å†™è„šæœ¬æ•°å­—åŒ–æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæœç´¢å¼•æ“å’Œæ¨èç³»ç»Ÿç­‰åº”ç”¨åœºæ™¯æä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10398v1",
      "published_date": "2025-07-14 15:38:42 UTC",
      "updated_date": "2025-07-14 15:38:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:23.385165+00:00"
    },
    {
      "arxiv_id": "2507.10397v2",
      "title": "Instance space analysis of the capacitated vehicle routing problem",
      "title_zh": "å¸¦å®¹é‡é™åˆ¶çš„è½¦è¾†è·¯å¾„é—®é¢˜çš„å®ä¾‹ç©ºé—´åˆ†æ",
      "authors": [
        "Alessandra M. M. M. GouvÃªa",
        "Nuno Paulos",
        "Eduardo Uchoa",
        "MariÃ¡ C. V. Nascimento"
      ],
      "abstract": "This paper seeks to advance CVRP research by addressing the challenge of understanding the nuanced relationships between instance characteristics and metaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a valuable tool that allows for a new perspective on the field. By combining the ISA methodology with a dataset from the DIMACS 12th Implementation Challenge on Vehicle Routing, our research enabled the identification of 23 relevant instance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages, which employ dimensionality reduction and machine learning methods, allowed us to create a two-dimensional projection of the instance space to understand how the structure of instances affect the behavior of MHs. A key contribution of our work is that we provide a projection matrix, which makes it straightforward to incorporate new instances into this analysis and allows for a new method for instance analysis in the CVRP field.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¸¦å®¹é‡é™åˆ¶çš„è½¦è¾†è·¯å¾„é—®é¢˜(CVRP)ï¼Œåº”ç”¨å®ä¾‹ç©ºé—´åˆ†æ(Instance Space Analysis, ISA)æ–¹æ³•æ¥æ¢ç©¶å®ä¾‹ç‰¹å¾ä¸å…ƒå¯å‘å¼ç®—æ³•(Metaheuristic, MH)æ€§èƒ½ä¹‹é—´çš„æ·±å±‚å…³ç³»ã€‚ç ”ç©¶åˆ©ç”¨ç¬¬12å±ŠDIMACSè½¦è¾†è·¯å¾„æŒ‘æˆ˜èµ›çš„æ•°æ®é›†ï¼Œè¯†åˆ«å‡º23ä¸ªç›¸å…³çš„å®ä¾‹ç‰¹å¾ã€‚é€šè¿‡PRELIMã€SIFTEDå’ŒPILOTç­‰æ¶‰åŠé™ç»´å’Œæœºå™¨å­¦ä¹ çš„é˜¶æ®µï¼Œç ”ç©¶æ„å»ºäº†ä¸€ä¸ªäºŒç»´å®ä¾‹ç©ºé—´æŠ•å½±ï¼Œç”¨ä»¥åˆ†æå®ä¾‹ç»“æ„å¯¹ç®—æ³•è¡Œä¸ºçš„å½±å“ã€‚è¯¥å·¥ä½œçš„ä¸€é¡¹æ ¸å¿ƒè´¡çŒ®æ˜¯æä¾›äº†ä¸€ä¸ªæŠ•å½±çŸ©é˜µï¼Œä¸ä»…ç®€åŒ–äº†æ–°å®ä¾‹çš„å¹¶å…¥è¿‡ç¨‹ï¼Œè¿˜ä¸ºCVRPé¢†åŸŸçš„å®ä¾‹åˆ†ææä¾›äº†ä¸€ç§å…¨æ–°çš„è§†è§’å’Œæ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10397v2",
      "published_date": "2025-07-14 15:37:55 UTC",
      "updated_date": "2025-07-18 13:00:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:27.351103+00:00"
    },
    {
      "arxiv_id": "2507.10349v1",
      "title": "TAT: Temporal-Aligned Transformer for Multi-Horizon Peak Demand Forecasting",
      "title_zh": "TATï¼šé¢å‘å¤šæ­¥é•¿å³°å€¼éœ€æ±‚é¢„æµ‹çš„æ—¶é—´å¯¹é½ Transformer",
      "authors": [
        "Zhiyuan Zhao",
        "Sitan Yang",
        "Kin G. Olivares",
        "Boris N. Oreshkin",
        "Stan Vitebsky",
        "Michael W. Mahoney",
        "B. Aditya Prakash",
        "Dmitry Efimov"
      ],
      "abstract": "Multi-horizon time series forecasting has many practical applications such as demand forecasting. Accurate demand prediction is critical to help make buying and inventory decisions for supply chain management of e-commerce and physical retailers, and such predictions are typically required for future horizons extending tens of weeks. This is especially challenging during high-stake sales events when demand peaks are particularly difficult to predict accurately. However, these events are important not only for managing supply chain operations but also for ensuring a seamless shopping experience for customers. To address this challenge, we propose Temporal-Aligned Transformer (TAT), a multi-horizon forecaster leveraging apriori-known context variables such as holiday and promotion events information for improving predictive performance. Our model consists of an encoder and decoder, both embedded with a novel Temporal Alignment Attention (TAA), designed to learn context-dependent alignment for peak demand forecasting. We conduct extensive empirical analysis on two large-scale proprietary datasets from a large e-commerce retailer. We demonstrate that TAT brings up to 30% accuracy improvement on peak demand forecasting while maintaining competitive overall performance compared to other state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå­å•†åŠ¡å’Œå®ä½“é›¶å”®ä¾›åº”é“¾ç®¡ç†ä¸­å¤šæ—¶é—´å°ºåº¦(Multi-horizon)éœ€æ±‚é¢„æµ‹çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹éš¾ä»¥å‡†ç¡®é¢„æµ‹çš„é”€å”®å³°å€¼éœ€æ±‚é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†æ—¶é—´å¯¹é½Transformer (Temporal-Aligned Transformer, TAT)ï¼Œä¸€ç§åˆ©ç”¨èŠ‚å‡æ—¥å’Œä¿ƒé”€æ´»åŠ¨ç­‰å…ˆéªŒä¸Šä¸‹æ–‡å˜é‡çš„å¤šæ—¶é—´å°ºåº¦é¢„æµ‹æ¨¡å‹ã€‚TATæ¨¡å‹é‡‡ç”¨ç”±ç¼–ç å™¨å’Œè§£ç å™¨ç»„æˆçš„æ¶æ„ï¼Œå¹¶å¼•å…¥äº†å…¨æ–°çš„æ—¶é—´å¯¹é½æ³¨æ„åŠ›(Temporal Alignment Attention, TAA)æœºåˆ¶ï¼Œæ—¨åœ¨å­¦ä¹ ä¾èµ–äºä¸Šä¸‹æ–‡çš„å¯¹é½å…³ç³»ä»¥ä¼˜åŒ–å³°å€¼éœ€æ±‚é¢„æµ‹ã€‚é€šè¿‡å¯¹å¤§å‹ç”µå­å•†åŠ¡é›¶å”®å•†çš„ä¸¤ä¸ªå¤§è§„æ¨¡ä¸“æœ‰æ•°æ®é›†è¿›è¡Œå¹¿æ³›å®è¯åˆ†æï¼Œç»“æœæ˜¾ç¤ºTATåœ¨å³°å€¼éœ€æ±‚é¢„æµ‹ç²¾åº¦ä¸Šæ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æå‡äº†é«˜è¾¾30%ã€‚è¯¥æ¨¡å‹åœ¨æ˜¾è‘—æé«˜æç«¯éœ€æ±‚é¢„æµ‹å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œä¾ç„¶ä¿æŒäº†æå…·ç«äº‰åŠ›çš„æ•´ä½“é¢„æµ‹æ€§èƒ½ï¼Œä¸ºå¤æ‚ä¾›åº”é“¾å†³ç­–æä¾›äº†æ›´å¯é çš„æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures, 7 tables, published at KDD 2025 workshop on AI for Supply Chain: Today and Future",
      "pdf_url": "https://arxiv.org/pdf/2507.10349v1",
      "published_date": "2025-07-14 14:51:24 UTC",
      "updated_date": "2025-07-14 14:51:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:30.780531+00:00"
    },
    {
      "arxiv_id": "2507.10348v3",
      "title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning",
      "title_zh": "ç‰¹å¾è’¸é¦æ˜¯æ¨¡å‹å¼‚æ„è”é‚¦å­¦ä¹ çš„æ›´ä½³é€‰æ‹©",
      "authors": [
        "Yichen Li",
        "Xiuying Wang",
        "Wenchao Xu",
        "Haozhao Wang",
        "Yining Qi",
        "Jiahua Dong",
        "Ruixuan Li"
      ],
      "abstract": "Model-Heterogeneous Federated Learning (Hetero-FL) has attracted growing attention for its ability to aggregate knowledge from heterogeneous models while keeping private data locally. To better aggregate knowledge from clients, ensemble distillation, as a widely used and effective technique, is often employed after global aggregation to enhance the performance of the global model. However, simply combining Hetero-FL and ensemble distillation does not always yield promising results and can make the training process unstable. The reason is that existing methods primarily focus on logit distillation, which, while being model-agnostic with softmax predictions, fails to compensate for the knowledge bias arising from heterogeneous models. To tackle this challenge, we propose a stable and efficient Feature Distillation for model-heterogeneous Federated learning, dubbed FedFD, that can incorporate aligned feature information via orthogonal projection to integrate knowledge from heterogeneous models better. Specifically, a new feature-based ensemble federated knowledge distillation paradigm is proposed. The global model on the server needs to maintain a projection layer for each client-side model architecture to align the features separately. Orthogonal techniques are employed to re-parameterize the projection layer to mitigate knowledge bias from heterogeneous models and thus maximize the distilled knowledge. Extensive experiments show that FedFD achieves superior performance compared to state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨¡å‹å¼‚æ„è”é‚¦å­¦ä¹  (Model-Heterogeneous Federated Learning) ä¸­çš„çŸ¥è¯†èšåˆé—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„ Logit Distillation åœ¨å¤„ç†å¼‚æ„æ¨¡å‹æ—¶å®¹æ˜“äº§ç”ŸçŸ¥è¯†åå·®å¹¶å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† FedFD æ¡†æ¶ï¼Œä¸»å¼ ç‰¹å¾è’¸é¦ (Feature Distillation) æ˜¯å¼‚æ„è”é‚¦å­¦ä¹ çš„æ›´å¥½é€‰æ‹©ã€‚è¯¥æ–¹æ³•é€šè¿‡æ­£äº¤æŠ•å½± (Orthogonal Projection) æ•´åˆå¯¹é½çš„ç‰¹å¾ä¿¡æ¯ï¼Œå¹¶ä¸ºæ¯ç§å®¢æˆ·ç«¯æ¨¡å‹æ¶æ„åœ¨æœåŠ¡å™¨ç«¯ç»´æŠ¤ä¸“é—¨çš„æŠ•å½±å±‚ã€‚é€šè¿‡é‡‡ç”¨æ­£äº¤é‡å‚æ•°åŒ–æŠ€æœ¯ï¼ŒFedFD èƒ½å¤Ÿæœ‰æ•ˆå‡è½»ç”±æ¨¡å‹å¼‚æ„æ€§å¼•èµ·çš„çŸ¥è¯†åå·®ï¼Œä»è€Œæœ€å¤§åŒ–è’¸é¦å‡ºçš„çŸ¥è¯†é‡ã€‚å¤§é‡å®éªŒç»“æœè¯æ˜ï¼ŒFedFD åœ¨æ€§èƒ½ä¸Šä¼˜äºç›®å‰çš„å…ˆè¿›æ–¹æ³•ï¼Œä¸ºå®ç°ç¨³å®šé«˜æ•ˆçš„å¼‚æ„è”é‚¦å­¦ä¹ æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10348v3",
      "published_date": "2025-07-14 14:51:18 UTC",
      "updated_date": "2025-10-14 11:02:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:33.620797+00:00"
    },
    {
      "arxiv_id": "2507.10330v1",
      "title": "Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach",
      "title_zh": "åŸºäºå¢é•¿ç•Œé™çŸ©é˜µæ–¹æ³•ï¼šå…¼é¡¾ NLP æŠµå¾¡è¯æ›¿æ¢æ”»å‡»çš„é²æ£’æ€§ä¸æ³›åŒ–æ€§",
      "authors": [
        "Mohammed Bouri",
        "Adnane Saoud"
      ],
      "abstract": "Despite advancements in Natural Language Processing (NLP), models remain vulnerable to adversarial attacks, such as synonym substitutions. While prior work has focused on improving robustness for feed-forward and convolutional architectures, the robustness of recurrent networks and modern state space models (SSMs), such as S4, remains understudied. These architectures pose unique challenges due to their sequential processing and complex parameter dynamics. In this paper, we introduce a novel regularization technique based on Growth Bound Matrices (GBM) to improve NLP model robustness by reducing the impact of input perturbations on model outputs. We focus on computing the GBM for three architectures: Long Short-Term Memory (LSTM), State Space models (S4), and Convolutional Neural Networks (CNN). Our method aims to (1) enhance resilience against word substitution attacks, (2) improve generalization on clean text, and (3) providing the first systematic analysis of SSM (S4) robustness. Extensive experiments across multiple architectures and benchmark datasets demonstrate that our method improves adversarial robustness by up to 8.8% over existing baselines. These results highlight the effectiveness of our approach, outperforming several state-of-the-art methods in adversarial defense. Codes are available at https://github.com/BouriMohammed/GBM",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¢é•¿è¾¹ç•ŒçŸ©é˜µ (Growth Bound Matrix, GBM) çš„æ–°å‹æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³è‡ªç„¶è¯­è¨€å¤„ç† (NLP) æ¨¡å‹åœ¨é¢å¯¹è¯è¯­æ›¿æ¢æ”»å‡» (word substitution attacks) æ—¶çš„è„†å¼±æ€§é—®é¢˜ã€‚é’ˆå¯¹å¾ªç¯ç½‘ç»œå’Œç°ä»£çŠ¶æ€ç©ºé—´æ¨¡å‹ (State Space models, S4) åœ¨åºåˆ—å¤„ç†ä¸­çš„å¤æ‚åŠ¨æ€æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•é€šè¿‡è®¡ç®— GBM æ¥é™ä½è¾“å…¥æ‰°åŠ¨å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ã€‚è¯¥ç ”ç©¶ä¸ä»…æ¶µç›–äº†ä¼ ç»Ÿçš„ CNN å’Œ LSTM æ¶æ„ï¼Œè¿˜æä¾›äº†é¦–ä¸ªå…³äº SSM (S4) é²æ£’æ€§çš„ç³»ç»Ÿæ€§åˆ†æã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—å¢å¼ºæ¨¡å‹å¯¹æŠ—åŒä¹‰è¯æ›¿æ¢æ”»å‡»èƒ½åŠ›çš„åŒæ—¶ï¼Œä¹Ÿæå‡äº†æ¨¡å‹åœ¨å¹²å‡€æ–‡æœ¬ä¸Šçš„æ³›åŒ–æ€§èƒ½ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆæ¯”ç°æœ‰åŸºå‡†æ¨¡å‹çš„å¯¹æŠ—é²æ£’æ€§æœ€é«˜æå‡äº† 8.8%ï¼Œå…¶æ€§èƒ½è¡¨ç°ä¼˜äºå½“å‰å¤šç§æœ€å…ˆè¿›çš„é˜²å¾¡æŠ€æœ¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL Findings 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10330v1",
      "published_date": "2025-07-14 14:38:48 UTC",
      "updated_date": "2025-07-14 14:38:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:42.197474+00:00"
    },
    {
      "arxiv_id": "2507.11562v1",
      "title": "Expert Operational GANS: Towards Real-Color Underwater Image Restoration",
      "title_zh": "Expert Operational GANSï¼šé¢å‘çœŸå½©è‰²æ°´ä¸‹å›¾åƒå¤åŸ",
      "authors": [
        "Ozer Can Devecioglu",
        "Serkan Kiranyaz",
        "Mehmet Yamac",
        "Moncef Gabbouj"
      ],
      "abstract": "The wide range of deformation artifacts that arise from complex light propagation, scattering, and depth-dependent attenuation makes the underwater image restoration to remain a challenging problem. Like other single deep regressor networks, conventional GAN-based restoration methods struggle to perform well across this heterogeneous domain, since a single generator network is typically insufficient to capture the full range of visual degradations. In order to overcome this limitation, we propose xOp-GAN, a novel GAN model with several expert generator networks, each trained solely on a particular subset with a certain image quality. Thus, each generator can learn to maximize its restoration performance for a particular quality range. Once a xOp-GAN is trained, each generator can restore the input image and the best restored image can then be selected by the discriminator based on its perceptual confidence score. As a result, xOP-GAN is the first GAN model with multiple generators where the discriminator is being used during the inference of the regression task. Experimental results on benchmark Large Scale Underwater Image (LSUI) dataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB, surpassing all single-regressor models by a large margin even, with reduced complexity.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†xOp-GANæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³æ°´ä¸‹å›¾åƒåœ¨å¤æ‚å…‰çº¿ä¼ æ’­ã€æ•£å°„åŠæ·±åº¦è¡°å‡å½±å“ä¸‹äº§ç”Ÿçš„å¤šç§é€€åŒ–ä¼ªå½±é—®é¢˜ã€‚é’ˆå¯¹ä¼ ç»ŸGANæ¨¡å‹ä¸­å•ä¸ªç”Ÿæˆå™¨éš¾ä»¥æ•æ‰å…¨èŒƒå›´è§†è§‰é€€åŒ–çš„å±€é™æ€§ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†å¤šä¸ªä¸“å®¶ç”Ÿæˆå™¨ç½‘ç»œ(Expert Generator Networks)ï¼Œæ¯ä¸ªç”Ÿæˆå™¨ä»…é’ˆå¯¹ç‰¹å®šå›¾åƒè´¨é‡çš„å­é›†è¿›è¡Œè®­ç»ƒä»¥æœ€å¤§åŒ–ä¿®å¤æ€§èƒ½ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè¯¥æ¨¡å‹åˆ©ç”¨åˆ¤åˆ«å™¨(Discriminator)æ ¹æ®æ„ŸçŸ¥ç½®ä¿¡åº¦åˆ†æ•°(Perceptual Confidence Score)ä»æ‰€æœ‰ç”Ÿæˆå™¨çš„è¾“å‡ºä¸­ç­›é€‰å‡ºæœ€ä½³ä¿®å¤å›¾åƒã€‚ä½œä¸ºé¦–ä¸ªåœ¨å›å½’ä»»åŠ¡æ¨ç†è¿‡ç¨‹ä¸­åº”ç”¨åˆ¤åˆ«å™¨è¿›è¡Œé€‰æ‹©çš„å¤šç”Ÿæˆå™¨æ¨¡å‹ï¼ŒxOp-GANåœ¨LSUIåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—æˆæœã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é™ä½å¤æ‚åº¦çš„åŒæ—¶ï¼ŒPSNRè¾¾åˆ°äº†25.16 dBï¼Œåœ¨å®ç°çœŸå®è‰²å½©æ¢å¤æ–¹é¢å¤§å¹…è¶…è¶Šäº†ç°æœ‰çš„å•ä¸€å›å½’å™¨æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.11562v1",
      "published_date": "2025-07-14 14:34:45 UTC",
      "updated_date": "2025-07-14 14:34:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:53.190967+00:00"
    },
    {
      "arxiv_id": "2507.10324v1",
      "title": "Toolsuite for Implementing Multiagent Systems Based on Communication Protocols",
      "title_zh": "åŸºäºé€šä¿¡åè®®çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå®ç°å·¥å…·å¥—ä»¶",
      "authors": [
        "Amit K. Chopra",
        "Samuel H. Christie",
        "Munindar P. Singh"
      ],
      "abstract": "Interaction-Oriented Programming (IOP) is an approach to building a multiagent system by modeling the interactions between its roles via a flexible interaction protocol and implementing agents to realize the interactions of the roles they play in the protocol.\n  In recent years, we have developed an extensive suite of software that enables multiagent system developers to apply IOP. These include tools for efficiently verifying protocols for properties such as liveness and safety and middleware that simplifies the implementation of agents. This paper presents some of that software suite.",
      "tldr_zh": "è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€å¥—åŸºäºé€šè®¯åè®®æ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (Multiagent Systems) çš„è½¯ä»¶å·¥å…·é›†ï¼Œå…¶æ ¸å¿ƒé‡‡ç”¨é¢å‘äº¤äº’ç¼–ç¨‹ (Interaction-Oriented Programming, IOP) æ–¹æ³•ã€‚IOP é€šè¿‡çµæ´»çš„äº¤äº’åè®® (Interaction Protocol) å¯¹ç³»ç»Ÿè§’è‰²é—´çš„äº’åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ç”±å…·ä½“çš„æ™ºèƒ½ä½“æ¥å®ç°è¿™äº›è§’è‰²ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†è¿™ä¸€å¥—å…¨é¢çš„è½¯ä»¶å¥—ä»¶ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…æ›´æœ‰æ•ˆåœ°åº”ç”¨ IOP æ¡†æ¶ã€‚è¯¥å¥—ä»¶æ¶µç›–äº†ç”¨äºé«˜æ•ˆéªŒè¯åè®®æ´»æ€§ (Liveness) å’Œå®‰å…¨æ€§ (Safety) ç­‰å±æ€§çš„å·¥å…·ï¼Œä»¥åŠèƒ½æ˜¾è‘—ç®€åŒ–æ™ºèƒ½ä½“å®ç°è¿‡ç¨‹çš„ä¸­é—´ä»¶ (Middleware)ã€‚è®ºæ–‡è¯¦ç»†å±•ç¤ºäº†è¯¥å¥—ä»¶çš„ç»„æˆéƒ¨åˆ†ï¼Œä¸ºå¼€å‘ç¨³å¥ä¸”å…·å¤‡å¯éªŒè¯æ€§çš„å¤šæ™ºèƒ½ä½“ååŒç³»ç»Ÿæä¾›äº†å…³é”®æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10324v1",
      "published_date": "2025-07-14 14:32:09 UTC",
      "updated_date": "2025-07-14 14:32:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:37:44.682121+00:00"
    },
    {
      "arxiv_id": "2507.10311v1",
      "title": "Recognizing Dementia from Neuropsychological Tests with State Space Models",
      "title_zh": "åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„ç¥ç»å¿ƒç†å­¦æµ‹è¯•ç—´å‘†è¯†åˆ«",
      "authors": [
        "Liming Wang",
        "Saurabhchand Bhati",
        "Cody Karjadi",
        "Rhoda Au",
        "James Glass"
      ],
      "abstract": "Early detection of dementia is critical for timely medical intervention and improved patient outcomes. Neuropsychological tests are widely used for cognitive assessment but have traditionally relied on manual scoring. Automatic dementia classification (ADC) systems aim to infer cognitive decline directly from speech recordings of such tests. We propose Demenba, a novel ADC framework based on state space models, which scale linearly in memory and computation with sequence length. Trained on over 1,000 hours of cognitive assessments administered to Framingham Heart Study participants, some of whom were diagnosed with dementia through adjudicated review, our method outperforms prior approaches in fine-grained dementia classification by 21\\%, while using fewer parameters. We further analyze its scaling behavior and demonstrate that our model gains additional improvement when fused with large language models, paving the way for more transparent and scalable dementia assessment tools. Code: https://anonymous.4open.science/r/Demenba-0861",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç—´å‘†ç—‡(Dementia)æ—©æœŸæ£€æµ‹çš„å…³é”®éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åä¸ºDemenbaçš„æ–°å‹è‡ªåŠ¨ç—´å‘†ç—‡åˆ†ç±»(Automatic Dementia Classification, ADC)æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹(State Space Models, SSMs)ï¼Œåˆ©ç”¨å…¶åœ¨å†…å­˜å’Œè®¡ç®—ä¸Šéšåºåˆ—é•¿åº¦çº¿æ€§æ‰©å±•çš„ä¼˜åŠ¿ï¼Œç›´æ¥ä»ç¥ç»å¿ƒç†å­¦æµ‹è¯•çš„è¯­éŸ³è®°å½•ä¸­æ¨æ–­è®¤çŸ¥é€€åŒ–ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨Framingham Heart Studyä¸­è¶…è¿‡1000å°æ—¶çš„è®¤çŸ¥è¯„ä¼°æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬ç»è£å®šç¡®è¯Šçš„ç—´å‘†ç—‡ç—…ä¾‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDemenbaåœ¨ç»†ç²’åº¦ç—´å‘†ç—‡åˆ†ç±»ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå‡†ç¡®ç‡æå‡äº†21%ï¼ŒåŒæ—¶ä½¿ç”¨äº†æ›´å°‘çš„å‚æ•°ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶åˆ†æäº†æ¨¡å‹çš„ç¼©æ”¾è¡Œä¸º(Scaling Behavior)ï¼Œå¹¶è¯æ˜å½“Demenbaä¸å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)èåˆæ—¶ï¼Œèƒ½å¤Ÿè·å¾—é¢å¤–çš„æ€§èƒ½å¢ç›Šã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºæ›´å…·é€æ˜åº¦å’Œå¯æ‰©å±•æ€§çš„ç—´å‘†ç—‡è¯„ä¼°å·¥å…·å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10311v1",
      "published_date": "2025-07-14 14:15:47 UTC",
      "updated_date": "2025-07-14 14:15:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:10.381920+00:00"
    },
    {
      "arxiv_id": "2507.10300v1",
      "title": "FaceLLM: A Multimodal Large Language Model for Face Understanding",
      "title_zh": "FaceLLMï¼šé¢å‘äººè„¸ç†è§£çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Hatef Otroshi Shahreza",
        "SÃ©bastien Marcel"
      ],
      "abstract": "Multimodal large language models (MLLMs) have shown remarkable performance in vision-language tasks. However, existing MLLMs are primarily trained on generic datasets, limiting their ability to reason on domain-specific visual cues such as those in facial images. In particular, tasks that require detailed understanding of facial structure, expression, emotion, and demographic features remain underexplored by MLLMs due to the lack of large-scale annotated face image-text datasets. In this work, we introduce FaceLLM, a multimodal large language model trained specifically for facial image understanding. To construct the training data, we propose a novel weakly supervised pipeline that uses ChatGPT with attribute-aware prompts to generate high-quality question-answer pairs based on images from the FairFace dataset. The resulting corpus, called FairFaceGPT, covers a diverse set of attributes including expression, pose, skin texture, and forensic information. Our experiments demonstrate that FaceLLM improves the performance of MLLMs on various face-centric tasks and achieves state-of-the-art performance. This work highlights the potential of synthetic supervision via language models for building domain-specialized MLLMs, and sets a precedent for trustworthy, human-centric multimodal AI systems. FairFaceGPT dataset and pretrained FaceLLM models are publicly available in the project page.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨é¢éƒ¨ç»“æ„ã€è¡¨æƒ…åŠäººå£ç»Ÿè®¡ç‰¹å¾ç­‰ç‰¹å®šé¢†åŸŸç†è§£åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸“é—¨ç”¨äºé¢éƒ¨å›¾åƒç†è§£çš„ FaceLLMã€‚ä¸ºäº†å…‹æœå¤§è§„æ¨¡æ ‡æ³¨æ•°æ®çš„åŒ®ä¹ï¼Œç ”ç©¶è€…å¼€å‘äº†ä¸€å¥—å¼±ç›‘ç£æµæ°´çº¿ï¼Œåˆ©ç”¨ ChatGPT ç»“åˆå±æ€§æ„ŸçŸ¥æç¤ºå¤„ç† FairFace æ•°æ®é›†ï¼ŒæˆåŠŸæ„å»ºäº†åŒ…å«è¡¨æƒ…ã€å§¿æ€åŠçš®è‚¤çº¹ç†ç­‰ä¸°å¯Œå±æ€§çš„ FairFaceGPT è¯­æ–™åº“ã€‚å®éªŒè¯æ˜ï¼ŒFaceLLM åœ¨å¤šé¡¹ä»¥é¢éƒ¨ä¸ºä¸­å¿ƒçš„ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½å¹¶è¾¾åˆ°äº† SOTA æ°´å¹³ã€‚è¯¥å·¥ä½œä¸ä»…å±•ç¤ºäº†åˆ©ç”¨è¯­è¨€æ¨¡å‹è¿›è¡Œåˆæˆç›‘ç£ä»¥æ„å»ºé¢†åŸŸä¸“ä¸šåŒ– MLLMs çš„æ½œåŠ›ï¼Œä¹Ÿä¸ºå¼€å‘å¯ä¿¡ä¸”ä»¥äººä¸ºä¸­å¿ƒçš„å¤šæ¨¡æ€ AI ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in ICCV 2025 workshops",
      "pdf_url": "https://arxiv.org/pdf/2507.10300v1",
      "published_date": "2025-07-14 14:04:14 UTC",
      "updated_date": "2025-07-14 14:04:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:13.281572+00:00"
    },
    {
      "arxiv_id": "2507.10281v1",
      "title": "Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence",
      "title_zh": "è¿ˆå‘ç°å®ä¸–ç•Œè¡¨æ ¼æ™ºèƒ½ä½“ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è¡¨æ ¼æ™ºèƒ½èƒ½åŠ›ã€å·¥ä½œæµä¸è®¾è®¡åŸåˆ™",
      "authors": [
        "Jiaming Tian",
        "Liyao Li",
        "Wentao Ye",
        "Haobo Wang",
        "Lingxin Wang",
        "Lihua Yu",
        "Zujie Ren",
        "Gang Chen",
        "Junbo Zhao"
      ],
      "abstract": "Tables are fundamental in domains such as finance, healthcare, and public administration, yet real-world table tasks often involve noise, structural heterogeneity, and semantic complexity--issues underexplored in existing research that primarily targets clean academic datasets. This survey focuses on LLM-based Table Agents, which aim to automate table-centric workflows by integrating preprocessing, reasoning, and domain adaptation. We define five core competencies--C1: Table Structure Understanding, C2: Table and Query Semantic Understanding, C3: Table Retrieval and Compression, C4: Executable Reasoning with Traceability, and C5: Cross-Domain Generalization--to analyze and compare current approaches. In addition, a detailed examination of the Text-to-SQL Agent reveals a performance gap between academic benchmarks and real-world scenarios, especially for open-source models. Finally, we provide actionable insights to improve the robustness, generalization, and efficiency of LLM-based Table Agents in practical settings.",
      "tldr_zh": "è¯¥ç»¼è¿°èšç„¦äºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è¡¨æ ¼æ™ºèƒ½ä½“ (LLM-based Table Agents)ï¼Œæ—¨åœ¨è§£å†³ç°å®åº”ç”¨ä¸­è¡¨æ ¼æ•°æ®å­˜åœ¨çš„å™ªå£°ã€ç»“æ„å¼‚è´¨æ€§å’Œè¯­ä¹‰å¤æ‚æ€§ç­‰æŒ‘æˆ˜ã€‚ç ”ç©¶å®šä¹‰äº† Table Structure Understandingã€Table and Query Semantic Understandingã€Table Retrieval and Compressionã€Executable Reasoning with Traceability ä»¥åŠ Cross-Domain Generalization äº”é¡¹æ ¸å¿ƒèƒ½åŠ›ï¼Œå¹¶ä»¥æ­¤æ„å»ºäº†åˆ†æä¸æ¯”è¾ƒç°æœ‰æ–¹æ³•çš„æ¡†æ¶ã€‚é€šè¿‡å¯¹ Text-to-SQL Agent çš„æ·±å…¥ç ”ç©¶ï¼Œè®ºæ–‡æ­ç¤ºäº†å­¦æœ¯åŸºå‡†æµ‹è¯•ä¸ç°å®å¤æ‚åœºæ™¯ä¹‹é—´çš„æ€§èƒ½å·®è·ï¼Œç‰¹åˆ«æ˜¯å¼€æºæ¨¡å‹åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶çš„å±€é™æ€§ã€‚æœ€åï¼Œè¯¥ç ”ç©¶ä¸ºæå‡è¡¨æ ¼æ™ºèƒ½ä½“åœ¨å®é™…ç¯å¢ƒä¸­çš„é²æ£’æ€§ã€æ³›åŒ–èƒ½åŠ›å’Œæ‰§è¡Œæ•ˆç‡æä¾›äº†å…³é”®çš„è®¾è®¡åŸåˆ™ä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10281v1",
      "published_date": "2025-07-14 13:48:13 UTC",
      "updated_date": "2025-07-14 13:48:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:17.289617+00:00"
    },
    {
      "arxiv_id": "2507.10639v2",
      "title": "Evaluating LLM-based Workflows for Switched-Mode Power Supply Design",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¼€å…³ç”µæºè®¾è®¡å·¥ä½œæµè¯„ä¼°",
      "authors": [
        "Simon Nau",
        "Jan Krummenauer",
        "AndrÃ© Zimmermann"
      ],
      "abstract": "Large language models (LLMs) have great potential to enhance productivity in many disciplines, such as software engineering. However, it is unclear to what extent they can assist in the design process of electronic circuits. This paper focuses on the application of LLMs to switched-mode power supply (SMPS) design for printed circuit boards (PCBs). We present multiple LLM-based workflows that combine reasoning, retrieval-augmented generation (RAG), and a custom toolkit that enables the LLM to interact with SPICE simulations to estimate the impact of circuit modifications. Two benchmark experiments are presented to analyze the performance of LLM-based assistants for different design tasks, including parameter tuning, topology adaption and optimization of SMPS circuits. Experiment results show that SPICE simulation feedback and current LLM advancements, such as reasoning, significantly increase the solve rate on 269 manually created benchmark tasks from 15% to 91%. Furthermore, our analysis reveals that most parameter tuning design tasks can be solved, while limits remain for certain topology adaption tasks. Our experiments offer insights for improving current concepts, for example by adapting text-based circuit representations",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„å·¥ä½œæµåœ¨å¼€å…³ç”µæº (Switched-Mode Power Supply) ç”µè·¯è®¾è®¡ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚ç ”ç©¶æå‡ºäº†ä¸€å¥—ç»“åˆæ¨ç†èƒ½åŠ›ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ä»¥åŠè‡ªå®šä¹‰å·¥å…·é›†çš„ LLM å·¥ä½œæµï¼Œä½¿å…¶èƒ½å¤Ÿä¸ SPICE ä»¿çœŸäº¤äº’ä»¥è¯„ä¼°ç”µè·¯ä¿®æ”¹çš„å½±å“ã€‚é€šè¿‡åŒ…å« 269 ä¸ªæ‰‹åŠ¨ä»»åŠ¡çš„åŸºå‡†å®éªŒï¼Œè¯¥ç ”ç©¶æ·±å…¥åˆ†æäº† LLM åŠ©æ‰‹åœ¨å‚æ•°è°ƒæ•´ (parameter tuning)ã€æ‹“æ‰‘é€‚é… (topology adaption) å’Œç”µè·¯ä¼˜åŒ–ä¸­çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç»“åˆäº† SPICE ä»¿çœŸåé¦ˆå’Œ LLM çš„æ¨ç†èƒ½åŠ›åï¼Œä»»åŠ¡è§£å†³ç‡ä» 15% æ˜¾è‘—æå‡è‡³ 91%ã€‚åˆ†æå‘ç°ï¼Œè™½ç„¶å¤§å¤šæ•°å‚æ•°è°ƒæ•´ä»»åŠ¡å·²èƒ½é¡ºåˆ©è§£å†³ï¼Œä½†æŸäº›å¤æ‚çš„æ‹“æ‰‘é€‚é…ä»»åŠ¡ä»é¢ä¸´å±€é™æ€§ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ–åŸºäºæ–‡æœ¬çš„ç”µè·¯è¡¨ç¤ºæ³• (text-based circuit representations) ä»¥åŠæ”¹è¿›ç”µå­ç”µè·¯è‡ªåŠ¨åŒ–è®¾è®¡æµç¨‹æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10639v2",
      "published_date": "2025-07-14 13:41:12 UTC",
      "updated_date": "2025-11-07 14:25:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:22.388766+00:00"
    },
    {
      "arxiv_id": "2507.10637v2",
      "title": "A Simple Baseline for Stable and Plastic Neural Networks",
      "title_zh": "ä¸€ç§å…¼é¡¾ç¨³å®šæ€§ä¸å¡‘æ€§çš„ç¥ç»ç½‘ç»œç®€å•åŸºå‡†",
      "authors": [
        "Ã‰tienne KÃ¼nzel",
        "Achref Jaziri",
        "Visvanathan Ramesh"
      ],
      "abstract": "Continual learning in computer vision requires that models adapt to a continuous stream of tasks without forgetting prior knowledge, yet existing approaches often tip the balance heavily toward either plasticity or stability. We introduce RDBP, a simple, low-overhead baseline that unites two complementary mechanisms: ReLUDown, a lightweight activation modification that preserves feature sensitivity while preventing neuron dormancy, and Decreasing Backpropagation, a biologically inspired gradient-scheduling scheme that progressively shields early layers from catastrophic updates. Evaluated on the Continual ImageNet benchmark, RDBP matches or exceeds the plasticity and stability of state-of-the-art methods while reducing computational cost. RDBP thus provides both a practical solution for real-world continual learning and a clear benchmark against which future continual learning strategies can be measured.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—æœºè§†è§‰ä¸­çš„æŒç»­å­¦ä¹ (Continual Learning)é—®é¢˜ï¼Œæå‡ºäº†RDBPè¿™ä¸€ç®€å•ä¸”ä½å¼€é”€çš„åŸºå‡†æ¨¡å‹ï¼Œæ—¨åœ¨å¹³è¡¡æ¨¡å‹çš„å¡‘æ€§(Plasticity)ä¸ç¨³å®šæ€§(Stability)ã€‚RDBPèåˆäº†ä¸¤ç§äº’è¡¥æœºåˆ¶ï¼šReLUDowné€šè¿‡è½»é‡çº§çš„æ¿€æ´»å‡½æ•°æ”¹è¿›æ¥ä¿æŒç‰¹å¾æ•æ„Ÿåº¦å¹¶é˜²æ­¢ç¥ç»å…ƒä¼‘çœ ï¼Œè€ŒDecreasing Backpropagationåˆ™é‡‡ç”¨å—ç”Ÿç‰©å¯å‘çš„æ¢¯åº¦è°ƒåº¦æ–¹æ¡ˆï¼Œé€šè¿‡é€æ¸ä¿æŠ¤ç¥ç»ç½‘ç»œæ—©æœŸå±‚å…å—ç¾éš¾æ€§æ›´æ–°çš„å½±å“æ¥éåˆ¶é—å¿˜ã€‚åœ¨Continual ImageNetåŸºå‡†æµ‹è¯•ä¸­ï¼ŒRDBPåœ¨åŒ¹é…æˆ–è¶…è¶Šç°æœ‰å…ˆè¿›æ–¹æ³•(State-of-the-art)æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚å®éªŒç»“æœè¯æ˜RDBPèƒ½æœ‰æ•ˆåº”å¯¹æ¨¡å‹åœ¨é€‚åº”æ–°ä»»åŠ¡æ—¶å¯¹æ—§çŸ¥è¯†çš„ä¸¢å¤±ï¼Œä¸ºç°å®ä¸–ç•Œçš„æŒç»­å­¦ä¹ éœ€æ±‚æä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥ç ”ç©¶ä¸ä»…å…·æœ‰æé«˜çš„å®è·µä»·å€¼ï¼Œè¿˜ä¸ºæœªæ¥çš„æŒç»­å­¦ä¹ ç ”ç©¶è®¾ç«‹äº†æ¸…æ™°ä¸”é«˜æ•ˆçš„æ€§èƒ½åŸºå‡†ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 50 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10637v2",
      "published_date": "2025-07-14 13:18:26 UTC",
      "updated_date": "2025-07-18 08:54:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:26.382028+00:00"
    },
    {
      "arxiv_id": "2507.10250v1",
      "title": "DepViT-CAD: Deployable Vision Transformer-Based Cancer Diagnosis in Histopathology",
      "title_zh": "DepViT-CADï¼šç»„ç»‡ç—…ç†å­¦ä¸­åŸºäºå¯éƒ¨ç½² Vision Transformer çš„ç™Œç—‡è¯Šæ–­",
      "authors": [
        "Ashkan Shakarami",
        "Lorenzo Nicole",
        "Rocco Cappellesso",
        "Angelo Paolo Dei Tos",
        "Stefano Ghidoni"
      ],
      "abstract": "Accurate and timely cancer diagnosis from histopathological slides is vital for effective clinical decision-making. This paper introduces DepViT-CAD, a deployable AI system for multi-class cancer diagnosis in histopathology. At its core is MAViT, a novel Multi-Attention Vision Transformer designed to capture fine-grained morphological patterns across diverse tumor types. MAViT was trained on expert-annotated patches from 1008 whole-slide images, covering 11 diagnostic categories, including 10 major cancers and non-tumor tissue. DepViT-CAD was validated on two independent cohorts: 275 WSIs from The Cancer Genome Atlas and 50 routine clinical cases from pathology labs, achieving diagnostic sensitivities of 94.11% and 92%, respectively. By combining state-of-the-art transformer architecture with large-scale real-world validation, DepViT-CAD offers a robust and scalable approach for AI-assisted cancer diagnostics. To support transparency and reproducibility, software and code will be made publicly available at GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†DepViT-CADï¼Œä¸€ç§ç”¨äºç»„ç»‡ç—…ç†å­¦å¤šç±»ç™Œç—‡è¯Šæ–­çš„å¯éƒ¨ç½²AIç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒæ˜¯æ–°é¢–çš„å¤šæ³¨æ„åŠ›è§†è§‰äº’æ„Ÿå™¨(Multi-Attention Vision Transformer, MAViT)ã€‚MAViTæ—¨åœ¨æ•æ‰ä¸åŒè‚¿ç˜¤ç±»å‹ä¸­çš„ç»†ç²’åº¦å½¢æ€æ¨¡å¼(fine-grained morphological patterns)ï¼Œå¹¶é€šè¿‡åœ¨åŒ…å«11ä¸ªè¯Šæ–­ç±»åˆ«çš„1008å¼ å…¨åˆ‡ç‰‡å›¾åƒ(whole-slide images, WSIs)ä¸“å®¶æ ‡æ³¨è¡¥ä¸ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¯¥ç³»ç»Ÿåœ¨æ¥è‡ªThe Cancer Genome Atlas (TCGA)çš„275å¼ WSIså’Œæ¥è‡ªç—…ç†å®éªŒå®¤çš„50ä¾‹å¸¸è§„ä¸´åºŠç—…ä¾‹ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œåˆ†åˆ«å®ç°äº†94.11%å’Œ92%çš„è¯Šæ–­æ•æ„Ÿæ€§(diagnostic sensitivities)ã€‚å®éªŒç»“æœè¯æ˜äº†DepViT-CADåœ¨ç»“åˆå…ˆè¿›Transformeræ¶æ„ä¸å¤§è§„æ¨¡çœŸå®ä¸–ç•ŒéªŒè¯æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºAIè¾…åŠ©ç™Œç—‡è¯Šæ–­æä¾›äº†ä¸€ç§ç¨³å¥ä¸”å¯æ‰©å±•çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "25 pages, 15 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10250v1",
      "published_date": "2025-07-14 13:17:46 UTC",
      "updated_date": "2025-07-14 13:17:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:25.990039+00:00"
    },
    {
      "arxiv_id": "2507.10636v1",
      "title": "GeoHopNet: Hopfield-Augmented Sparse Spatial Attention for Dynamic UAV Site Location Problem",
      "title_zh": "GeoHopNetï¼šé¢å‘åŠ¨æ€æ— äººæœºé€‰å€é—®é¢˜çš„ Hopfield å¢å¼ºç¨€ç–ç©ºé—´æ³¨æ„åŠ›",
      "authors": [
        "Jianing Zhi",
        "Xinghua Li",
        "Zidong Chen"
      ],
      "abstract": "The rapid development of urban low-altitude unmanned aerial vehicle (UAV) economy poses new challenges for dynamic site selection of UAV landing points and supply stations. Traditional deep reinforcement learning methods face computational complexity bottlenecks, particularly with standard attention mechanisms, when handling large-scale urban-level location problems. This paper proposes GeoHopNet, a Hopfield-augmented sparse spatial attention network specifically designed for dynamic UAV site location problems. Our approach introduces four core innovations: (1) distance-biased multi-head attention mechanism that explicitly encodes spatial geometric information; (2) K-nearest neighbor sparse attention that reduces computational complexity from $O(N^2)$ to $O(NK)$; (3) a modern Hopfield external memory module; and (4) a memory regularization strategy. Experimental results demonstrate that GeoHopNet extends the boundary of solvable problem sizes. For large-scale instances with 1,000 nodes, where standard attention models become prohibitively slow (over 3 seconds per instance) and traditional solvers fail, GeoHopNet finds high-quality solutions (0.22\\% optimality gap) in under 0.1 seconds. Compared to the state-of-the-art ADNet baseline on 100-node instances, our method improves solution quality by 22.2\\% and is 1.8$\\times$ faster.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹åŸå¸‚ä½ç©ºæ— äººæœºï¼ˆUAVï¼‰ç»æµä¸­èµ·é™ç‚¹å’Œè¡¥ç»™ç«™çš„åŠ¨æ€é€‰å€é—®é¢˜ï¼Œæå‡ºäº†GeoHopNetæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡é€‰å€é—®é¢˜æ—¶çš„è®¡ç®—å¤æ‚åº¦ç“¶é¢ˆã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ˜¾å¼ç¼–ç ç©ºé—´å‡ ä½•ä¿¡æ¯çš„è·ç¦»åç½®å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆDistance-biased multi-head attentionï¼‰ï¼Œå¹¶ç»“åˆKè¿‘é‚»ç¨€ç–æ³¨æ„åŠ›ï¼ˆK-nearest neighbor sparse attentionï¼‰å°†è®¡ç®—å¤æ‚åº¦ä»$O(N^2)$æ˜¾è‘—é™ä½è‡³$O(NK)$ã€‚æ­¤å¤–ï¼Œæ¨¡å‹æ•´åˆäº†ç°ä»£Hopfieldå¤–éƒ¨å­˜å‚¨æ¨¡å—ï¼ˆModern Hopfield external memory moduleï¼‰åŠå­˜å‚¨æ­£åˆ™åŒ–ç­–ç•¥ï¼Œå¢å¼ºäº†å¯¹å¤æ‚åœ°ç†ä¿¡æ¯çš„è®°å¿†ä¸æ£€ç´¢èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGeoHopNetåœ¨å¤„ç†åŒ…å«1000ä¸ªèŠ‚ç‚¹çš„å¤§è§„æ¨¡ç®—ä¾‹æ—¶ï¼Œèƒ½åœ¨0.1ç§’å†…æ‰¾åˆ°æœ€ä¼˜å·®è·ä»…ä¸º0.22%çš„é«˜è´¨é‡è§£ï¼Œè€Œä¼ ç»Ÿæ±‚è§£å™¨åœ¨æ­¤ç±»è§„æ¨¡ä¸‹å¾€å¾€éš¾ä»¥å¥æ•ˆã€‚ç›¸æ¯”æœ€å…ˆè¿›çš„ADNetåŸºçº¿æ¨¡å‹ï¼Œè¯¥æ–¹æ³•åœ¨100èŠ‚ç‚¹ç®—ä¾‹ä¸Šçš„è§£è´¨é‡æå‡äº†22.2%ï¼Œè¿è¡Œé€Ÿåº¦æé«˜äº†1.8å€ï¼Œæœ‰æ•ˆæ‰©å±•äº†å¤æ‚æ— äººæœºé€‰å€é—®é¢˜çš„å¯æ±‚è§£è¾¹ç•Œã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "12 Pages, 5 Figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10636v1",
      "published_date": "2025-07-14 13:13:35 UTC",
      "updated_date": "2025-07-14 13:13:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:29.984569+00:00"
    },
    {
      "arxiv_id": "2507.10240v1",
      "title": "Visual Analytics for Explainable and Trustworthy Artificial Intelligence",
      "title_zh": "é¢å‘å¯è§£é‡Šä¸å¯ä¿¡äººå·¥æ™ºèƒ½çš„å¯è§†åˆ†æ",
      "authors": [
        "Angelos Chatzimparmpas"
      ],
      "abstract": "Our society increasingly depends on intelligent systems to solve complex problems, ranging from recommender systems suggesting the next movie to watch to AI models assisting in medical diagnoses for hospitalized patients. With the iterative improvement of diagnostic accuracy and efficiency, AI holds significant potential to mitigate medical misdiagnoses by preventing numerous deaths and reducing an economic burden of approximately 450 EUR billion annually. However, a key obstacle to AI adoption lies in the lack of transparency: many automated systems function as \"black boxes,\" providing predictions without revealing the underlying processes. This opacity can hinder experts' ability to trust and rely on AI systems. Visual analytics (VA) provides a compelling solution by combining AI models with interactive visualizations. These specialized charts and graphs empower users to incorporate their domain expertise to refine and improve the models, bridging the gap between AI and human understanding. In this work, we define, categorize, and explore how VA solutions can foster trust across the stages of a typical AI pipeline. We propose a design space for innovative visualizations and present an overview of our previously developed VA dashboards, which support critical tasks within the various pipeline stages, including data processing, feature engineering, hyperparameter tuning, understanding, debugging, refining, and comparing models.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œéšç€æ™ºèƒ½ç³»ç»Ÿåœ¨åŒ»ç–—ç­‰å…³é”®é¢†åŸŸçš„é‡è¦æ€§æ—¥ç›Šå¢åŠ ï¼Œäººå·¥æ™ºèƒ½æ¨¡å‹çš„â€œé»‘ç›’â€ç‰¹æ€§æ‰€å¯¼è‡´çš„é€æ˜åº¦ç¼ºå¤±ä¸¥é‡é˜»ç¢äº†ä¸“å®¶çš„ä¿¡ä»»ä¸åº”ç”¨ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæ–‡ç« æ¢è®¨äº†å¯è§†åŒ–åˆ†æ (Visual Analytics) å¦‚ä½•é€šè¿‡äº¤äº’å¼å¯è§†åŒ–å°†äººå·¥æ™ºèƒ½æ¨¡å‹ä¸äººç±»é¢†åŸŸçŸ¥è¯†ç›¸ç»“åˆï¼Œä»è€Œå¢å¼ºç³»ç»Ÿçš„é€æ˜åº¦å¹¶å»ºç«‹ä¿¡ä»»ã€‚ç ”ç©¶ç³»ç»Ÿåœ°å®šä¹‰å¹¶åˆ†ç±»äº†å¯è§†åŒ–åˆ†æ (Visual Analytics) è§£å†³æ–¹æ¡ˆåœ¨å…¸å‹äººå·¥æ™ºèƒ½æµæ°´çº¿ (AI pipeline) å„ä¸ªé˜¶æ®µä¸­ä¿ƒè¿›å¯ä¿¡åº¦çš„å…·ä½“è·¯å¾„ã€‚æ­¤å¤–ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªåˆ›æ–°å¯è§†åŒ–çš„è®¾è®¡ç©ºé—´ (design space)ï¼Œå¹¶å±•ç¤ºäº†æ­¤å‰å¼€å‘çš„å¯è§†åŒ–åˆ†æä»ªè¡¨æ¿ï¼Œç”¨äºæ”¯æŒæ•°æ®å¤„ç† (data processing)ã€ç‰¹å¾å·¥ç¨‹ (feature engineering)ã€æ¨¡å‹è°ƒè¯• (debugging) åŠè¶…å‚æ•°è°ƒä¼˜ (hyperparameter tuning) ç­‰å…³é”®ä»»åŠ¡ã€‚è¯¥å·¥ä½œé€šè¿‡æ¡¥æ¥äººå·¥æ™ºèƒ½ä¸äººç±»ç†è§£ï¼Œä¸ºå®ç°å¯è§£é‡Šä¸”å€¼å¾—ä¿¡èµ–çš„äººå·¥æ™ºèƒ½æä¾›äº†åšå®çš„ç†è®ºæ¡†æ¶ä¸å®è·µå·¥å…·ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10240v1",
      "published_date": "2025-07-14 13:03:17 UTC",
      "updated_date": "2025-07-14 13:03:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:40.726204+00:00"
    },
    {
      "arxiv_id": "2507.10223v1",
      "title": "ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral Prosthesis Users",
      "title_zh": "ProGaitï¼šé¢å‘å¤§è…¿å‡è‚¢ä½¿ç”¨è€…çš„å¤šç”¨é€”è§†é¢‘æ•°æ®é›†ä¸åŸºå‡†",
      "authors": [
        "Xiangyu Yin",
        "Boyuan Yang",
        "Weichen Liu",
        "Qiyao Xue",
        "Abrar Alamri",
        "Goeran Fiedler",
        "Wei Gao"
      ],
      "abstract": "Prosthetic legs play a pivotal role in clinical rehabilitation, allowing individuals with lower-limb amputations the ability to regain mobility and improve their quality of life. Gait analysis is fundamental for optimizing prosthesis design and alignment, directly impacting the mobility and life quality of individuals with lower-limb amputations. Vision-based machine learning (ML) methods offer a scalable and non-invasive solution to gait analysis, but face challenges in correctly detecting and analyzing prosthesis, due to their unique appearances and new movement patterns. In this paper, we aim to bridge this gap by introducing a multi-purpose dataset, namely ProGait, to support multiple vision tasks including Video Object Segmentation, 2D Human Pose Estimation, and Gait Analysis (GA). ProGait provides 412 video clips from four above-knee amputees when testing multiple newly-fitted prosthetic legs through walking trials, and depicts the presence, contours, poses, and gait patterns of human subjects with transfemoral prosthetic legs. Alongside the dataset itself, we also present benchmark tasks and fine-tuned baseline models to illustrate the practical application and performance of the ProGait dataset. We compared our baseline models against pre-trained vision models, demonstrating improved generalizability when applying the ProGait dataset for prosthesis-specific tasks. Our code is available at https://github.com/pittisl/ProGait and dataset at https://huggingface.co/datasets/ericyxy98/ProGait.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰æœºå™¨å­¦ä¹ (ML)æ–¹æ³•åœ¨å‡è‚¢æ£€æµ‹ä¸åˆ†æä¸­é¢ä¸´çš„ç‹¬ç‰¹å¤–è§‚å’Œè¿åŠ¨æ¨¡å¼è¯†åˆ«æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸º ProGait çš„å¤šç”¨é€”è§†é¢‘æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ—¨åœ¨æ”¯æŒ Video Object Segmentationã€2D Human Pose Estimation å’Œ Gait Analysis (GA) ç­‰å¤šç§è§†è§‰ä»»åŠ¡ï¼Œå¡«è¡¥äº†å‡è‚¢æ­¥æ€åˆ†æé¢†åŸŸçš„è§†è§‰æ•°æ®ç©ºç™½ã€‚ProGait åŒ…å« 412 æ®µæ¥è‡ªå››åå¤§è…¿æˆªè‚¢æ‚£è€…åœ¨è¡Œèµ°æµ‹è¯•ä¸­è¯•ç©¿æ–°è£…é…å‡è‚¢çš„è§†é¢‘ï¼Œè¯¦ç»†æ•æ‰äº†å—è¯•è€…çš„è½®å»“ã€å§¿æ€åŠæ­¥æ€æ¨¡å¼ã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥æ¨å‡ºäº†åŸºå‡†æµ‹è¯•ä»»åŠ¡å’Œç»è¿‡å¾®è°ƒçš„åŸºå‡†æ¨¡å‹ï¼Œå®éªŒè¡¨æ˜å…¶åœ¨å‡è‚¢ç‰¹å®šä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›æ˜¾è‘—ä¼˜äºé€šç”¨çš„é¢„è®­ç»ƒè§†è§‰æ¨¡å‹ã€‚è¯¥å·¥ä½œçš„å¼€æºä¸ºä¼˜åŒ–å‡è‚¢è®¾è®¡ã€å¯¹é½åŠæå‡ä¸‹è‚¢æˆªè‚¢æ‚£è€…çš„åº·å¤è´¨é‡ä¸ç§»åŠ¨èƒ½åŠ›æä¾›äº†å…³é”®çš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICCV'25",
      "pdf_url": "https://arxiv.org/pdf/2507.10223v1",
      "published_date": "2025-07-14 12:40:57 UTC",
      "updated_date": "2025-07-14 12:40:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:36.496170+00:00"
    },
    {
      "arxiv_id": "2507.10216v2",
      "title": "From Words to Proverbs: Evaluating LLMs Linguistic and Cultural Competence in Saudi Dialects with Absher",
      "title_zh": "ä»å­—è¯åˆ°è°šè¯­ï¼šåŸºäº Absher è¯„ä¼° LLMs åœ¨ Saudi æ–¹è¨€ä¸­çš„è¯­è¨€ä¸æ–‡åŒ–èƒ½åŠ›",
      "authors": [
        "Renad Al-Monef",
        "Hassan Alhuzali",
        "Nora Alturayeif",
        "Ashwag Alasmari"
      ],
      "abstract": "As large language models (LLMs) become increasingly central to Arabic NLP applications, evaluating their understanding of regional dialects and cultural nuances is essential, particularly in linguistically diverse settings like Saudi Arabia. This paper introduces Absher, a comprehensive benchmark specifically designed to assess LLMs performance across major Saudi dialects. \\texttt{Absher} comprises over 18,000 multiple-choice questions spanning six distinct categories: Meaning, True/False, Fill-in-the-Blank, Contextual Usage, Cultural Interpretation, and Location Recognition. These questions are derived from a curated dataset of dialectal words, phrases, and proverbs sourced from various regions of Saudi Arabia. We evaluate several state-of-the-art LLMs, including multilingual and Arabic-specific models. We also provide detailed insights into their capabilities and limitations. Our results reveal notable performance gaps, particularly in tasks requiring cultural inference or contextual understanding. Our findings highlight the urgent need for dialect-aware training and culturally aligned evaluation methodologies to improve LLMs performance in real-world Arabic applications.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† Absherï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨è®¾è®¡ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ²™ç‰¹æ–¹è¨€ä¸­è¯­è¨€å’Œæ–‡åŒ–èƒ½åŠ›çš„ç»¼åˆ Benchmarkã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«è¶…è¿‡ 18,000 é“å¤šé¡¹é€‰æ‹©é¢˜ï¼Œæ¶µç›–äº† Meaningã€True/Falseã€Fill-in-the-Blankã€Contextual Usageã€Cultural Interpretation å’Œ Location Recognition å…­ä¸ªæ ¸å¿ƒç±»åˆ«ã€‚é¢˜ç›®æ•°æ®æºè‡ªæ²™ç‰¹é˜¿æ‹‰ä¼¯å„åœ°åŒºçš„æ–¹è¨€è¯æ±‡ã€çŸ­è¯­å’Œè°šè¯­ï¼Œæ—¨åœ¨å…¨é¢è€ƒé‡æ¨¡å‹å¯¹åœ°åŸŸæ–‡åŒ–ç»†å¾®å·®åˆ«çš„ç†è§£ã€‚ç ”ç©¶è¯„ä¼°äº†å¤šç§ SOTA LLMsï¼Œç»“æœå‘ç°åœ¨æ¶‰åŠ Cultural Inference å’Œ Contextual Understanding çš„ä»»åŠ¡ä¸­å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚è¯¥é¡¹å·¥ä½œæ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨å¤„ç†ç‰¹å®šåŒºåŸŸæ–¹è¨€æ—¶çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†è¿›è¡Œ Dialect-aware è®­ç»ƒå’Œ Culturally Aligned è¯„ä¼°å¯¹äºä¼˜åŒ–é˜¿æ‹‰ä¼¯è¯­ NLP åº”ç”¨è¡¨ç°çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10216v2",
      "published_date": "2025-07-14 12:33:07 UTC",
      "updated_date": "2025-12-21 15:41:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:38:57.580279+00:00"
    },
    {
      "arxiv_id": "2507.10208v1",
      "title": "Survey for Categorising Explainable AI Studies Using Data Analysis Task Frameworks",
      "title_zh": "åŸºäºæ•°æ®åˆ†æä»»åŠ¡æ¡†æ¶çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½ç ”ç©¶åˆ†ç±»ç»¼è¿°",
      "authors": [
        "Hamzah Ziadeh",
        "Hendrik Knoche"
      ],
      "abstract": "Research into explainable artificial intelligence (XAI) for data analysis tasks suffer from a large number of contradictions and lack of concrete design recommendations stemming from gaps in understanding the tasks that require AI assistance. In this paper, we drew on multiple fields such as visual analytics, cognition, and dashboard design to propose a method for categorising and comparing XAI studies under three dimensions: what, why, and who. We identified the main problems as: inadequate descriptions of tasks, context-free studies, and insufficient testing with target users. We propose that studies should specifically report on their users' domain, AI, and data analysis expertise to illustrate the generalisability of their findings. We also propose study guidelines for designing and reporting XAI tasks to improve the XAI community's ability to parse the rapidly growing field. We hope that our contribution can help researchers and designers better identify which studies are most relevant to their work, what gaps exist in the research, and how to handle contradictory results regarding XAI design.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI, XAI)åœ¨æ•°æ®åˆ†æä»»åŠ¡ä¸­å­˜åœ¨çš„çŸ›ç›¾åŠè®¾è®¡å»ºè®®åŒ®ä¹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªä» whatã€why å’Œ who ä¸‰ä¸ªç»´åº¦å¯¹ XAI ç ”ç©¶è¿›è¡Œåˆ†ç±»å’Œæ¯”è¾ƒçš„æ–¹æ³•æ¡†æ¶ã€‚é€šè¿‡å€Ÿé‰´è§†è§‰åˆ†æ(Visual Analytics)ã€è®¤çŸ¥ç§‘å­¦å’Œä»ªè¡¨æ¿è®¾è®¡ç­‰é¢†åŸŸï¼Œè¯¥æ¡†æ¶æ­ç¤ºäº†å½“å‰ç ”ç©¶ä¸­ä»»åŠ¡æè¿°ä¸å……åˆ†ã€ç¼ºä¹ä¸Šä¸‹æ–‡è¯­å¢ƒä»¥åŠç›®æ ‡ç”¨æˆ·æµ‹è¯•ä¸è¶³ç­‰æ ¸å¿ƒé—®é¢˜ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡å»ºè®®ç ”ç©¶è€…åº”è¯¦ç»†æŠ¥å‘Šç”¨æˆ·åœ¨ç‰¹å®šé¢†åŸŸã€AI åŠæ•°æ®åˆ†ææ–¹é¢çš„ä¸“ä¸šçŸ¥è¯†èƒŒæ™¯ï¼Œä»¥æå‡ç ”ç©¶å‘ç°çš„æ™®é€‚æ€§ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜åˆ¶å®šäº†è®¾è®¡å’ŒæŠ¥å‘Š XAI ä»»åŠ¡çš„æŒ‡å¯¼æ–¹é’ˆï¼Œæ—¨åœ¨å¢å¼ºå­¦æœ¯ç•Œå¯¹è¯¥é¢†åŸŸçš„è§£æèƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ä»…èƒ½å¸®åŠ©ç ”ç©¶äººå‘˜ç²¾å‡†è¯†åˆ«ç›¸å…³ç ”ç©¶å’Œç°æœ‰ç¼ºå£ï¼Œè¿˜ä¸ºå¤„ç† XAI è®¾è®¡ä¸­çš„çŸ›ç›¾ç»“æœæä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10208v1",
      "published_date": "2025-07-14 12:26:45 UTC",
      "updated_date": "2025-07-14 12:26:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:10.789706+00:00"
    },
    {
      "arxiv_id": "2507.10202v1",
      "title": "A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images",
      "title_zh": "ä¸€ç§æå‡ MLLM é«˜åˆ†è¾¨ç‡å›¾åƒæ€§èƒ½çš„æ— éœ€è®­ç»ƒã€ä»»åŠ¡æ— å…³é€šç”¨æ¡†æ¶",
      "authors": [
        "Jaeseong Lee",
        "Yeeun Choi",
        "Heechan Choi",
        "Hanjung Kim",
        "Seonjoo Kim"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in vision-language understanding, reasoning, and generation. However, they struggle with tasks requiring fine-grained localization and reasoning in high-resolution images. This constraint stems from the fact that MLLMs are fine-tuned with fixed image resolution to align with the pre-trained image encoder used in MLLM. Consequently, feeding high-resolution images directly into MLLMs leads to poor generalization due to a train-test resolution discrepancy, while downsampling these images-although ensuring consistency-compromises fine-grained visual details and ultimately degrades performance. To address this challenge, we propose Extract Candidate then Predict (ECP), a novel training-free, task-agnostic two-stage framework designed to enhance MLLM performance on high-resolution images. The key intuition behind ECP is that while MLLMs struggle with high-resolution images, their predictions on downsampled images still contain implicit localization cues. By first identifying candidate region using the coarse prediction and then predicting the final output based on candidate region, ECP effectively preserves fine-grained details while mitigating the challenges posed by high-resolution data. We validate our framework on 4K GUI grounding and 4K, 8K MLLM perception, achieving +21.3%, +5.8%, +5.2% absolute improvement compared to baseline respectively, demonstrating its effectiveness. Code is available at https://github.com/yenncye/ECP.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶é¢ä¸´çš„å¾®è§‚å®šä½å’Œæ¨ç†éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒä¸”ä»»åŠ¡æ— å…³çš„åŒé˜¶æ®µæ¡†æ¶ Extract Candidate then Predict (ECP)ã€‚é’ˆå¯¹ MLLM å› é¢„è®­ç»ƒåˆ†è¾¨ç‡é™åˆ¶è€Œæ— æ³•ç›´æ¥å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæˆ–åœ¨é™é‡‡æ ·ä¸­ä¸¢å¤±ç»†èŠ‚çš„é—®é¢˜ï¼ŒECP çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡å‹åœ¨é™é‡‡æ ·å›¾åƒä¸Šé¢„æµ‹æ—¶äº§ç”Ÿçš„éšå«å®šä½çº¿ç´¢æ¥è¯†åˆ«å€™é€‰åŒºåŸŸã€‚é€šè¿‡å…ˆæå–å€™é€‰åŒºåŸŸå†è¿›è¡Œæœ€ç»ˆé¢„æµ‹ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆä¿ç•™å›¾åƒçš„ç»†ç²’åº¦ç»†èŠ‚ï¼Œå¹¶ç¼“è§£åˆ†è¾¨ç‡ä¸åŒ¹é…å¸¦æ¥çš„æ€§èƒ½ä¸‹é™ã€‚å®éªŒéªŒè¯æ˜¾ç¤ºï¼ŒECP åœ¨ 4K GUI grounding ä»¥åŠ 4K å’Œ 8K MLLM perception ä»»åŠ¡ä¸Šç›¸æ¯”åŸºçº¿æ¨¡å‹åˆ†åˆ«å®ç°äº† 21.3%ã€5.8% å’Œ 5.2% çš„ç»å¯¹æ€§èƒ½æå‡ã€‚è¯¥æˆæœä¸ºæå‡ MLLM åœ¨è¶…é«˜åˆ†è¾¨ç‡è§†è§‰ä»»åŠ¡ä¸­çš„è¡¨ç°æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”æ™®é€‚çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025 Workshop on Emergent Visual Abilities and Limits of Foundation Models",
      "pdf_url": "https://arxiv.org/pdf/2507.10202v1",
      "published_date": "2025-07-14 12:14:53 UTC",
      "updated_date": "2025-07-14 12:14:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:14.892907+00:00"
    },
    {
      "arxiv_id": "2507.10200v1",
      "title": "Natural Language-based Assessment of L2 Oral Proficiency using LLMs",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ L2 å£è¯­æ°´å¹³è‡ªç„¶è¯­è¨€è¯„ä¼°",
      "authors": [
        "Stefano BannÃ²",
        "Rao Ma",
        "Mengjie Qian",
        "Siyuan Tang",
        "Kate Knill",
        "Mark Gales"
      ],
      "abstract": "Natural language-based assessment (NLA) is an approach to second language assessment that uses instructions - expressed in the form of can-do descriptors - originally intended for human examiners, aiming to determine whether large language models (LLMs) can interpret and apply them in ways comparable to human assessment. In this work, we explore the use of such descriptors with an open-source LLM, Qwen 2.5 72B, to assess responses from the publicly available S&I Corpus in a zero-shot setting. Our results show that this approach - relying solely on textual information - achieves competitive performance: while it does not outperform state-of-the-art speech LLMs fine-tuned for the task, it surpasses a BERT-based model trained specifically for this purpose. NLA proves particularly effective in mismatched task settings, is generalisable to other data types and languages, and offers greater interpretability, as it is grounded in clearly explainable, widely applicable language descriptors.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºè‡ªç„¶è¯­è¨€çš„è¯„ä¼° (Natural language-based assessment, NLA) æ–¹æ³•ï¼Œåˆ©ç”¨åŸæœ¬ä¸ºäººç±»è€ƒå®˜è®¾è®¡çš„ can-do æè¿°è¯­æŒ‡ä»¤ï¼Œæ—¨åœ¨æ¢ç©¶å¤§è¯­è¨€æ¨¡å‹ (LLMs) æ˜¯å¦èƒ½ä»¥ç±»äººçš„æ–¹å¼è§£è¯»å¹¶åº”ç”¨è¿™äº›æ ‡å‡†æ¥è¯„ä¼°ç¬¬äºŒè¯­è¨€ (L2) çš„å£è¯­æ°´å¹³ã€‚ä½œè€…ä½¿ç”¨å¼€æºæ¨¡å‹ Qwen 2.5 72Bï¼Œåœ¨é›¶æ ·æœ¬ (zero-shot) è®¾ç½®ä¸‹å¯¹å…¬å¼€çš„ S&I Corpus è¯­æ–™åº“è¿›è¡Œäº†å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œè¿™ç§ä»…ä¾èµ–æ–‡æœ¬ä¿¡æ¯çš„æ–¹æ³•è¡¨ç°å‡ºäº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè™½ç„¶å…¶è¡¨ç°å°šæœªè¶…è¿‡é’ˆå¯¹è¯¥ä»»åŠ¡å¾®è°ƒçš„å…ˆè¿›è¯­éŸ³å¤§æ¨¡å‹ (speech LLMs)ï¼Œä½†è¶…è¶Šäº†ä¸“é—¨ä¸ºæ­¤ä»»åŠ¡è®­ç»ƒçš„ BERT-based æ¨¡å‹ã€‚ç ”ç©¶å‘ç° NLA åœ¨ä»»åŠ¡ä¸åŒ¹é… (mismatched task) çš„è®¾å®šä¸‹ç‰¹åˆ«æœ‰æ•ˆï¼Œå±•ç°å‡ºè‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¯æ‰©å±•è‡³å…¶ä»–æ•°æ®ç±»å‹å’Œè¯­è¨€ã€‚æ­¤å¤–ï¼Œç”±äºè¯¥æ–¹æ³•ç›´æ¥æ¤æ ¹äºæ¸…æ™°ã€å¹¿æ³›é€‚ç”¨çš„è¯­è¨€æè¿°è¯­ï¼Œå› æ­¤åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­æä¾›äº†æ›´å¼ºçš„å¯è§£é‡Šæ€§ (interpretability)ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted for the 10th Workshop on Speech and Language Technology in Education (SLaTE 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.10200v1",
      "published_date": "2025-07-14 12:13:50 UTC",
      "updated_date": "2025-07-14 12:13:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:18.092325+00:00"
    },
    {
      "arxiv_id": "2507.14196v1",
      "title": "Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs",
      "title_zh": "ç”¨äº 12 å¯¼è”å¿ƒç”µå›¾ä¸­å®¤æ€§å¿ƒåŠ¨è¿‡é€Ÿä¸ä¼´å·®å¼‚æ€§ä¼ å¯¼å®¤ä¸Šæ€§å¿ƒåŠ¨è¿‡é€Ÿé‰´åˆ«çš„å¯è§£é‡Šå¹¶è¡Œ CNN-LSTM æ¨¡å‹",
      "authors": [
        "Zahra Teimouri-Jervekani",
        "Fahimeh Nasimi",
        "Mohammadreza Yazdchi",
        "Ghazal MogharehZadeh",
        "Javad Tezerji",
        "Farzan Niknejad Mazandarani",
        "Maryam Mohebbi"
      ],
      "abstract": "Background and Objective: Differentiating wide complex tachycardia (WCT) is clinically critical yet challenging due to morphological similarities in electrocardiogram (ECG) signals between life-threatening ventricular tachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A). Misdiagnosis carries fatal risks. We propose a computationally efficient deep learning solution to improve diagnostic accuracy and provide model interpretability for clinical deployment.\n  Methods: A novel lightweight parallel deep architecture is introduced. Each pipeline processes individual ECG leads using two 1D-CNN blocks to extract local features. Feature maps are concatenated across leads, followed by LSTM layers to capture temporal dependencies. Final classification employs fully connected layers. Explainability is achieved via Shapley Additive Explanations (SHAP) for local/global interpretation. The model was evaluated on a 35-subject ECG database using standard performance metrics.\n  Results: The model achieved $95.63\\%$ accuracy ($95\\%$ CI: $93.07-98.19\\%$), with sensitivity=$95.10\\%$, specificity=$96.06\\%$, and F1-score=$95.12\\%$. It outperformed state-of-the-art methods in both accuracy and computational efficiency, requiring minimal CNN blocks per pipeline. SHAP analysis demonstrated clinically interpretable feature contributions.\n  Conclusions: Our end-to-end framework delivers high-precision WCT classification with minimal computational overhead. The integration of SHAP enhances clinical trust by elucidating decision logic, supporting rapid, informed diagnosis. This approach shows significant promise for real-world ECG analysis tools.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è®¡ç®—é«˜æ•ˆä¸”å¯è§£é‡Šçš„å¹¶è¡Œ CNN-LSTM æ¨¡å‹ï¼Œç”¨äºåœ¨ 12 å¯¼è”å¿ƒç”µå›¾ (12-Lead ECGs) ä¸­é‰´åˆ«å®¤æ€§å¿ƒåŠ¨è¿‡é€Ÿ (Ventricular Tachycardia, VT) ä¸ä¼´æœ‰å®¤å†…å·®å¼‚ä¼ å¯¼çš„å®¤ä¸Šæ€§å¿ƒåŠ¨è¿‡é€Ÿ (Supraventricular Tachycardia with Aberrancy, SVT-A)ã€‚è¯¥æ¡†æ¶é€šè¿‡ 1D-CNN å—æå–å„å¯¼è”çš„å±€éƒ¨ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨ LSTM å±‚æ•æ‰ä¿¡å·çš„æ—¶é—´ä¾èµ–æ€§ï¼Œæ„å»ºäº†ä¸€ä¸ªè½»é‡çº§çš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¶æ„ã€‚ä¸ºäº†å¢å¼ºä¸´åºŠéƒ¨ç½²çš„å¯ä¿¡åº¦ï¼Œç ”ç©¶å¼•å…¥äº† Shapley Additive Explanations (SHAP) æŠ€æœ¯ï¼Œå¯¹æ¨¡å‹çš„åˆ†ç±»å†³ç­–è¿›è¡Œå±€éƒ¨å’Œå…¨å±€çš„å¯è§£é‡Šæ€§åˆ†æã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨åŸºå‡†æ•°æ®åº“ä¸Šè¾¾åˆ°äº† 95.63% çš„å‡†ç¡®ç‡ï¼Œå…¶çµæ•åº¦å’Œç‰¹å¼‚æ€§å‡è¡¨ç°ä¼˜å¼‚ã€‚ç›¸æ¯”äºç°æœ‰å…ˆè¿›æ–¹æ³•ï¼Œè¯¥æ¨¡å‹åœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ï¼Œå±•ç°äº†æé«˜çš„è®¡ç®—æ•ˆç‡ã€‚è¿™ä¸€ç ”ç©¶æˆæœé€šè¿‡é˜æ˜æ·±åº¦å­¦ä¹ çš„å†³ç­–é€»è¾‘ï¼Œä¸ºå¼€å‘å¿«é€Ÿã€å¯é çš„å®æ—¶å¿ƒç”µå›¾ä¸´åºŠè¾…åŠ©è¯Šæ–­å·¥å…·å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14196v1",
      "published_date": "2025-07-14 12:12:34 UTC",
      "updated_date": "2025-07-14 12:12:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:35.782723+00:00"
    },
    {
      "arxiv_id": "2507.22067v1",
      "title": "Dimensions of Vulnerability in Visual Working Memory: An AI-Driven Approach to Perceptual Comparison",
      "title_zh": "è§†è§‰å·¥ä½œè®°å¿†è„†å¼±æ€§çš„ç»´åº¦ï¼šä¸€ç§äººå·¥æ™ºèƒ½é©±åŠ¨çš„çŸ¥è§‰æ¯”è¾ƒæ–¹æ³•",
      "authors": [
        "Yuang Cao",
        "Jiachen Zou",
        "Chen Wei",
        "Quanying Liu"
      ],
      "abstract": "Human memory exhibits significant vulnerability in cognitive tasks and daily life. Comparisons between visual working memory and new perceptual input (e.g., during cognitive tasks) can lead to unintended memory distortions. Previous studies have reported systematic memory distortions after perceptual comparison, but understanding how perceptual comparison affects memory distortions in real-world objects remains a challenge. Furthermore, identifying what visual features contribute to memory vulnerability presents a novel research question. Here, we propose a novel AI-driven framework that generates naturalistic visual stimuli grounded in behaviorally relevant object dimensions to elicit similarity-induced memory biases. We use two types of stimuli -- image wheels created through dimension editing and dimension wheels generated by dimension activation values -- in three visual working memory (VWM) experiments. These experiments assess memory distortions under three conditions: no perceptual comparison, perceptual comparison with image wheels, and perceptual comparison with dimension wheels. The results show that similar dimensions, like similar images, can also induce memory distortions. Specifically, visual dimensions are more prone to distortion than semantic dimensions, indicating that the object dimensions of naturalistic visual stimuli play a significant role in the vulnerability of memory.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººç±»è§†è§‰å·¥ä½œè®°å¿† (Visual Working Memory, VWM) åœ¨æ„ŸçŸ¥æ¯”è¾ƒè¿‡ç¨‹ä¸­äº§ç”Ÿçš„è®°å¿†åå·®é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„ AI-driven æ¡†æ¶ï¼Œç”¨äºç”ŸæˆåŸºäºè¡Œä¸ºç›¸å…³ç‰©ä½“ç»´åº¦çš„è‡ªç„¶è§†è§‰åˆºæ¿€ã€‚ç ”ç©¶åˆ©ç”¨é€šè¿‡ Dimension editing åˆ›å»ºçš„ Image wheels ä»¥åŠç”±ç»´åº¦æ¿€æ´»å€¼ç”Ÿæˆçš„ Dimension wheelsï¼Œåœ¨ä¸‰é¡¹å®éªŒä¸­å¯¹æ¯”äº†æ— æ„ŸçŸ¥æ¯”è¾ƒã€å›¾åƒæ¯”è¾ƒåŠç»´åº¦æ¯”è¾ƒæ¡ä»¶ä¸‹çš„è®°å¿†å¤±çœŸæƒ…å†µã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸ä¼¼çš„ç‰©ä½“ç»´åº¦ä¸ç›¸ä¼¼å›¾åƒä¸€æ ·ï¼Œéƒ½ä¼šè¯±å‘æ˜¾è‘—çš„è®°å¿†åå·®ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œè§†è§‰ç»´åº¦ (Visual dimensions) æ¯”è¯­ä¹‰ç»´åº¦ (Semantic dimensions) æ›´å®¹æ˜“å¯¼è‡´è®°å¿†å¤±çœŸã€‚è¿™ä¸€å‘ç°è¡¨æ˜è‡ªç„¶è§†è§‰åˆºæ¿€çš„ç‰©ä½“ç»´åº¦åœ¨è®°å¿†çš„æ˜“æ„Ÿæ€§ (Vulnerability of memory) ä¸­å‘æŒ¥äº†å…³é”®ä½œç”¨ï¼Œä¸ºç†è§£ç°å®ä¸–ç•Œç‰©ä½“çš„è®°å¿†å¤„ç†æä¾›äº†æ–°è§†è§’ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "6 pages, 4 figures, experimental results presented in the paper, accepted for virtual poster presentation at CogSci 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.22067v1",
      "published_date": "2025-07-14 12:01:29 UTC",
      "updated_date": "2025-07-14 12:01:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:28.887168+00:00"
    },
    {
      "arxiv_id": "2507.10194v1",
      "title": "Learning Private Representations through Entropy-based Adversarial Training",
      "title_zh": "åŸºäºç†µå¯¹æŠ—è®­ç»ƒçš„éšç§è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Tassilo Klein",
        "Moin Nabi"
      ],
      "abstract": "How can we learn a representation with high predictive power while preserving user privacy? We present an adversarial representation learning method for sanitizing sensitive content from the learned representation. Specifically, we introduce a variant of entropy - focal entropy, which mitigates the potential information leakage of the existing entropy-based approaches. We showcase feasibility on multiple benchmarks. The results suggest high target utility at moderate privacy leakage.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åœ¨ä¿æŒé«˜é¢„æµ‹èƒ½åŠ›çš„åŒæ—¶ä¿æŠ¤ç”¨æˆ·éšç§ï¼Œå¹¶æå‡ºäº†ä¸€ç§é€šè¿‡åŸºäºç†µçš„å¯¹æŠ—æ€§è®­ç»ƒå­¦ä¹ éšç§è¡¨ç¤ºçš„æ–¹æ³•ã€‚ä¸ºäº†ä»å­¦åˆ°çš„è¡¨ç¤ºä¸­æ¸…é™¤æ•æ„Ÿå†…å®¹ï¼Œç ”ç©¶è€…å¼•å…¥äº†ä¸€ç§å¯¹æŠ—æ€§è¡¨ç¤ºå­¦ä¹ (adversarial representation learning)æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰åŸºäºç†µçš„æ–¹æ³•ä¸­æ½œåœ¨çš„ä¿¡æ¯æ³„éœ²é—®é¢˜ï¼Œè¯¥ç ”ç©¶ç‰¹åˆ«æå‡ºäº†ä¸€ç§åä¸ºfocal entropyçš„ç†µå˜ä½“ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•çš„å¯è¡Œæ€§ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚æœ€ç»ˆç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆèƒ½å¤Ÿåœ¨ä»…äº§ç”Ÿé€‚åº¦éšç§æ³„éœ²çš„å‰æä¸‹ï¼Œå®ç°æé«˜çš„ç›®æ ‡æ•ˆç”¨(target utility)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10194v1",
      "published_date": "2025-07-14 12:01:08 UTC",
      "updated_date": "2025-07-14 12:01:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:35.493761+00:00"
    },
    {
      "arxiv_id": "2508.03696v1",
      "title": "PLA: Prompt Learning Attack against Text-to-Image Generative Models",
      "title_zh": "PLAï¼šé’ˆå¯¹æ–‡ç”Ÿå›¾ç”Ÿæˆæ¨¡å‹çš„æç¤ºå­¦ä¹ æ”»å‡»",
      "authors": [
        "Xinqi Lyu",
        "Yihao Liu",
        "Yanjie Li",
        "Bin Xiao"
      ],
      "abstract": "Text-to-Image (T2I) models have gained widespread adoption across various applications. Despite the success, the potential misuse of T2I models poses significant risks of generating Not-Safe-For-Work (NSFW) content. To investigate the vulnerability of T2I models, this paper delves into adversarial attacks to bypass the safety mechanisms under black-box settings. Most previous methods rely on word substitution to search adversarial prompts. Due to limited search space, this leads to suboptimal performance compared to gradient-based training. However, black-box settings present unique challenges to training gradient-driven attack methods, since there is no access to the internal architecture and parameters of T2I models. To facilitate the learning of adversarial prompts in black-box settings, we propose a novel prompt learning attack framework (PLA), where insightful gradient-based training tailored to black-box T2I models is designed by utilizing multimodal similarities. Experiments show that our new method can effectively attack the safety mechanisms of black-box T2I models including prompt filters and post-hoc safety checkers with a high success rate compared to state-of-the-art methods. Warning: This paper may contain offensive model-generated content.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒ(Text-to-Image)æ¨¡å‹åœ¨ç”Ÿæˆä¸å®‰å…¨(NSFW)å†…å®¹æ–¹é¢çš„æ½œåœ¨é£é™©ï¼Œæ¢è®¨äº†åœ¨é»‘ç›’è®¾ç½®ä¸‹ç»•è¿‡å…¶å®‰å…¨æœºåˆ¶çš„å¯¹æŠ—æ”»å‡»ã€‚é’ˆå¯¹ç°æœ‰è¯æ›¿æ¢æ–¹æ³•å› æœç´¢ç©ºé—´å—é™è€Œå¯¼è‡´æ€§èƒ½ä¸è¶³çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†PLAæç¤ºè¯å­¦ä¹ æ”»å‡»(Prompt Learning Attack)æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤šæ¨¡æ€ç›¸ä¼¼æ€§(multimodal similarities)è®¾è®¡äº†ä¸“é—¨é’ˆå¯¹é»‘ç›’æ¨¡å‹çš„æ¢¯åº¦é©±åŠ¨è®­ç»ƒæ–¹æ¡ˆï¼Œæœ‰æ•ˆè§£å†³äº†æ— æ³•è·å–æ¨¡å‹å†…éƒ¨å‚æ•°çš„éš¾é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPLAèƒ½å¤Ÿä»¥æé«˜çš„æˆåŠŸç‡ç»•è¿‡æç¤ºè¯è¿‡æ»¤å™¨(prompt filters)å’Œäº‹åå®‰å…¨æ£€æŸ¥å™¨(post-hoc safety checkers)ã€‚ä¸ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§åº”ç”¨åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºæ›´å¼ºçš„æ”»å‡»æ•ˆåŠ›ï¼Œæ­ç¤ºäº†å½“å‰ç”Ÿæˆå¼æ¨¡å‹å®‰å…¨é˜²å¾¡ä½“ç³»çš„è„†å¼±æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 3 figures, and published to ICCV2025",
      "pdf_url": "https://arxiv.org/pdf/2508.03696v1",
      "published_date": "2025-07-14 11:57:16 UTC",
      "updated_date": "2025-07-14 11:57:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:36.395523+00:00"
    },
    {
      "arxiv_id": "2507.14195v1",
      "title": "UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach",
      "title_zh": "åŸºäº UWB é›·è¾¾çš„å¿ƒç‡ç›‘æµ‹ï¼šä¸€ç§è¿ç§»å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Elzbieta Gruzewska",
        "Pooja Rao",
        "Sebastien Baur",
        "Matthew Baugh",
        "Mathias M. J. Bellaiche",
        "Sharanya Srinivas",
        "Octavio Ponce",
        "Matthew Thompson",
        "Pramod Rudrapatna",
        "Michael A. Sanchez",
        "Lawrence Z. Cai",
        "Timothy JA Chico",
        "Robert F. Storey",
        "Emily Maz",
        "Umesh Telang",
        "Shravya Shetty",
        "Mayank Daswani"
      ],
      "abstract": "Radar technology presents untapped potential for continuous, contactless, and passive heart rate monitoring via consumer electronics like mobile phones. However the variety of available radar systems and lack of standardization means that a large new paired dataset collection is required for each radar system. This study demonstrates transfer learning between frequency-modulated continuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems, both increasingly integrated into consumer devices. FMCW radar utilizes a continuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW radar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3 receiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz bandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we achieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage error (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119 participants, an average of 8 hours per participant). This model maintained performance (under 5 MAE/10% MAPE) across various body positions and heart rate ranges, with a 98.9% recall. We then fine-tuned a variant of this model, trained on single-antenna and single-range bin FMCW data, using a small (N=376, avg 6 minutes per participant) IR-UWB dataset. This transfer learning approach yielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE reduction over the IR-UWB baseline. This demonstration of transfer learning between radar systems for heart rate monitoring has the potential to accelerate its introduction into existing consumer devices.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨é›·è¾¾æŠ€æœ¯è¿›è¡Œéæ¥è§¦å¼å¿ƒç‡ç›‘æµ‹çš„æ½œåŠ›ï¼Œå¹¶æå‡ºäº†ä¸€ç§è¿ç§»å­¦ä¹ (transfer learning)æ–¹æ³•æ¥è§£å†³ä¸åŒé›·è¾¾ç³»ç»Ÿé—´æ•°æ®æ ‡å‡†ä¸ç»Ÿä¸€åŠå¤§è§„æ¨¡æ•°æ®é›†é‡‡é›†å›°éš¾çš„é—®é¢˜ã€‚ç ”ç©¶é‡ç‚¹å±•ç¤ºäº†åœ¨è°ƒé¢‘è¿ç»­æ³¢(FMCW)é›·è¾¾ä¸è„‰å†²æ— çº¿ç”µè¶…å®½å¸¦(IR-UWB)é›·è¾¾ç³»ç»Ÿä¹‹é—´çš„çŸ¥è¯†è¿ç§»ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§æ–°å‹çš„2D+1D ResNetæ¶æ„è¿›è¡Œç‰¹å¾æå–ã€‚åœ¨å¤§å‹FMCWæ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹å®ç°äº†0.85 bpmçš„å¹³å‡ç»å¯¹è¯¯å·®(MAE)å’Œ1.42%çš„å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®(MAPE)ï¼Œå¹¶åœ¨å¤šç§èº«ä½“å§¿åŠ¿ä¸‹å±•ç°äº†æå¼ºçš„ç¨³å¥æ€§ã€‚é€šè¿‡å¯¹å°è§„æ¨¡IR-UWBæ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œè¯¥è¿ç§»å­¦ä¹ æ–¹æ¡ˆä½¿IR-UWBç³»ç»Ÿçš„MAEè¾ƒåŸºå‡†æ¨¡å‹é™ä½äº†25%ï¼Œè¾¾åˆ°4.1 bpmã€‚å®éªŒç»“æœè¯æ˜äº†åœ¨ä¸åŒæ¢æµ‹åŸç†çš„é›·è¾¾ç³»ç»Ÿé—´å…±äº«ç‰¹å¾è¡¨ç¤ºçš„å¯è¡Œæ€§ï¼Œæœ‰æ•ˆå‡å°‘äº†æ–°ç¡¬ä»¶å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºå¿ƒç‡ç›‘æµ‹æŠ€æœ¯åœ¨æ‰‹æœºç­‰æ¶ˆè´¹çº§ç”µå­è®¾å¤‡ä¸­çš„å¿«é€Ÿæ™®åŠå’Œè§„æ¨¡åŒ–åº”ç”¨å¥ å®šäº†é‡è¦æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "31 pages, 11 tables, 9 figures, 14 supplementary tables, 4 supplementary figures",
      "pdf_url": "https://arxiv.org/pdf/2507.14195v1",
      "published_date": "2025-07-14 11:45:57 UTC",
      "updated_date": "2025-07-14 11:45:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:41.684655+00:00"
    },
    {
      "arxiv_id": "2507.10182v1",
      "title": "Breaking the Myth: Can Small Models Infer Postconditions Too?",
      "title_zh": "æ‰“ç ´è¿·æ€ï¼šå°æ¨¡å‹æ˜¯å¦ä¹Ÿèƒ½æ¨å¯¼åç½®æ¡ä»¶ï¼Ÿ",
      "authors": [
        "Gehao Zhang",
        "Zhenting Wang",
        "Juan Zhai"
      ],
      "abstract": "Formal specifications are essential for ensuring software correctness, yet manually writing them is tedious and error-prone. Large Language Models (LLMs) have shown promise in generating such specifications from natural language intents, but the giant model size and high computational demands raise a fundamental question: Do we really need large models for this task? In this paper, we show that a small, fine-tuned language model can achieve high-quality postcondition generation with much lower computational costs. We construct a specialized dataset of prompts, reasoning logs, and postconditions, then supervise the fine-tuning of a $7$B-parameter code model. Our approach tackles real-world repository dependencies and preserves pre-state information, allowing for expressive and accurate specifications. We evaluate the model on a benchmark of real-world Java bugs (Defects4J) and compare against both proprietary giants (e.g., GPT-4o) and open-source large models. Empirical results demonstrate that our compact model matches or outperforms significantly larger counterparts in syntax correctness, semantic correctness, and bug-distinguishing capability. These findings highlight that targeted fine-tuning on a modest dataset can enable small models to achieve results formerly seen only in massive, resource-heavy LLMs, offering a practical and efficient path for the real-world adoption of automated specification generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°æ¨¡å‹åœ¨è‡ªåŠ¨ç”Ÿæˆå½¢å¼åŒ–è§„èŒƒ(Formal specifications)â€”â€”ç‰¹åˆ«æ˜¯åç½®æ¡ä»¶(Postconditions)æ–¹é¢çš„æ½œåŠ›ï¼Œæ—¨åœ¨æŒ‘æˆ˜åªæœ‰è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹æ‰èƒ½å®Œæˆè¯¥ä»»åŠ¡çš„å›ºæœ‰è®¤çŸ¥ã€‚ä½œè€…æ„å»ºäº†ä¸€ä¸ªåŒ…å«æç¤ºè¯ã€æ¨ç†æ—¥å¿—å’Œåç½®æ¡ä»¶çš„ä¸“ç”¨æ•°æ®é›†ï¼Œå¹¶å¯¹ä¸€ä¸ª7Bå‚æ•°çš„ä»£ç æ¨¡å‹è¿›è¡Œäº†ç›‘ç£å¾®è°ƒ(Supervised Fine-tuning)ã€‚è¯¥æ–¹æ³•é€šè¿‡å¤„ç†çœŸå®ä¸–ç•Œçš„ä»“åº“ä¾èµ–å¹¶ä¿ç•™å‰ç½®çŠ¶æ€ä¿¡æ¯(Pre-state information)ï¼Œå®ç°äº†é«˜ç²¾åº¦ä¸”è¡¨è¾¾åŠ›å¼ºçš„è§„èŒƒç”Ÿæˆã€‚ç ”ç©¶åœ¨çœŸå®Javaæ¼æ´åŸºå‡†é›†Defects4Jä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶å°†å…¶ä¸GPT-4oç­‰é¡¶å°–é—­æºæ¨¡å‹åŠå¼€æºå¤§æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥ç´§å‡‘å‹æ¨¡å‹åœ¨è¯­æ³•æ­£ç¡®æ€§ã€è¯­ä¹‰æ­£ç¡®æ€§ä»¥åŠæ¼æ´è¾¨åˆ«èƒ½åŠ›ä¸Šå‡å¯åª²ç¾ç”šè‡³è¶…è¶Šå‚æ•°é‡å¤§å¾—å¤šçš„æ¨¡å‹ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œé€šè¿‡åœ¨é€‚åº¦è§„æ¨¡çš„æ•°æ®é›†ä¸Šè¿›è¡Œé’ˆå¯¹æ€§å¾®è°ƒï¼Œå°æ¨¡å‹ä¹Ÿèƒ½åœ¨èµ„æºæ¶ˆè€—æä½çš„æƒ…å†µä¸‹å®ç°å“è¶Šæ€§èƒ½ï¼Œä¸ºè‡ªåŠ¨åŒ–è§„èŒƒç”Ÿæˆçš„å®é™…è½åœ°æä¾›äº†é«˜æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10182v1",
      "published_date": "2025-07-14 11:44:04 UTC",
      "updated_date": "2025-07-14 11:44:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:46.038599+00:00"
    },
    {
      "arxiv_id": "2507.10179v2",
      "title": "The Second Machine Turn: From Checking Proofs to Creating Concepts",
      "title_zh": "ç¬¬äºŒæ¬¡æœºå™¨è½¬å‘ï¼šä»è¯æ˜æ ¡éªŒåˆ°æ¦‚å¿µåˆ›é€ ",
      "authors": [
        "Asvin G"
      ],
      "abstract": "We identify a second machine turn in the process of mathematical discovery: after automating proof-checking, AI is now poised to automate the *creation* of mathematical concepts themselves. We discuss the current state of the art, obstacles and potential solutions as well as a preliminary attempt at mathematizing the creation of concepts itself. The paper ends with an assessment of how these capabilities could reshape mathematics and human-machine collaboration, and a few different futures we might find ourselves in.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯†åˆ«äº†æ•°å­¦å‘ç°è¿‡ç¨‹ä¸­çš„â€œç¬¬äºŒæ¬¡æœºå™¨è½¬æŠ˜â€ (Second Machine Turn)ï¼ŒæŒ‡å‡ºäººå·¥æ™ºèƒ½æ­£ä»å•çº¯çš„è‡ªåŠ¨åŒ–è¯æ˜æ£€æŸ¥ (Proof-checking) è½¬å‘è‡ªåŠ¨åŒ–æ•°å­¦æ¦‚å¿µæœ¬èº«çš„åˆ›é€  (Creation of mathematical concepts)ã€‚æ–‡ç« æ·±å…¥æ¢è®¨äº†è¯¥é¢†åŸŸçš„å½“å‰æŠ€æœ¯ç°çŠ¶ã€å­˜åœ¨çš„ä¸»è¦éšœç¢åŠå…¶æ½œåœ¨è§£å†³æ–¹æ¡ˆï¼Œå¹¶æå‡ºäº†ä¸€ç§å°†æ¦‚å¿µåˆ›é€ è¿‡ç¨‹æœ¬èº«è¿›è¡Œæ•°å­¦åŒ– (Mathematizing) çš„åˆæ­¥å°è¯•ã€‚æ­¤å¤–ï¼Œä½œè€…è¯¦ç»†è¯„ä¼°äº†è¿™äº›èƒ½åŠ›å°†å¦‚ä½•é‡å¡‘æ•°å­¦å­¦ç§‘çš„ç ”ç©¶èŒƒå¼ä»¥åŠäººæœºåä½œ (Human-machine collaboration) çš„æ¨¡å¼ã€‚æœ€åï¼Œè®ºæ–‡å¯¹æœªæ¥å¯èƒ½å‡ºç°çš„å‡ ç§ä¸åŒæ•°å­¦ç ”ç©¶å‘å±•å‰æ™¯è¿›è¡Œäº†å‰ç»æ€§åˆ†æä¸è¯„ä¼°ã€‚",
      "categories": [
        "math.HO",
        "cs.AI"
      ],
      "primary_category": "math.HO",
      "comment": "Minor clarifications in the final section",
      "pdf_url": "https://arxiv.org/pdf/2507.10179v2",
      "published_date": "2025-07-14 11:42:01 UTC",
      "updated_date": "2025-08-01 16:59:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:39:50.888949+00:00"
    },
    {
      "arxiv_id": "2507.10177v1",
      "title": "Abusive text transformation using LLMs",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è¾±éª‚æ€§æ–‡æœ¬è½¬æ¢",
      "authors": [
        "Rohitash Chandra",
        "Jiyong Choi"
      ],
      "abstract": "Although Large Language Models (LLMs) have demonstrated significant advancements in natural language processing tasks, their effectiveness in the classification and transformation of abusive text into non-abusive versions remains an area for exploration. In this study, we aim to use LLMs to transform abusive text (tweets and reviews) featuring hate speech and swear words into non-abusive text, while retaining the intent of the text. We evaluate the performance of two state-of-the-art LLMs, such as Gemini, GPT-4o, DeekSeek and Groq, on their ability to identify abusive text. We them to transform and obtain a text that is clean from abusive and inappropriate content but maintains a similar level of sentiment and semantics, i.e. the transformed text needs to maintain its message. Afterwards, we evaluate the raw and transformed datasets with sentiment analysis and semantic analysis. Our results show Groq provides vastly different results when compared with other LLMs. We have identified similarities between GPT-4o and DeepSeek-V3.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å°†åŒ…å«ä»‡æ¨è¨€è®ºå’Œè„è¯çš„è¾±éª‚æ€§æ–‡æœ¬ï¼ˆå¦‚æ¨æ–‡å’Œè¯„è®ºï¼‰è½¬æ¢ä¸ºéè¾±éª‚æ€§æ–‡æœ¬ï¼ŒåŒæ—¶ä¿ç•™å…¶åŸå§‹æ„å›¾ã€‚ç ”ç©¶è¯¦ç»†è¯„ä¼°äº† Geminiã€GPT-4oã€DeepSeek-V3 å’Œ Groq ç­‰ä¸»æµæ¨¡å‹åœ¨è¯†åˆ«è¾±éª‚æ€§å†…å®¹åŠæ‰§è¡Œæ–‡æœ¬è½¬æ¢æ–¹é¢çš„è¡¨ç°ã€‚è¯¥æ–¹æ³•æ—¨åœ¨ç”Ÿæˆå»é™¤ä¸å½“å†…å®¹ä½†ä¿ç•™ç›¸ä¼¼æƒ…æ„Ÿ(Sentiment)å’Œè¯­ä¹‰(Semantics)ä¿¡æ¯çš„å‡€åŒ–æ–‡æœ¬ã€‚é€šè¿‡å¯¹åŸå§‹å’Œè½¬æ¢åçš„æ•°æ®é›†è¿›è¡Œå¯¹æ¯”åˆ†æï¼Œç ”ç©¶å‘ç° Groq çš„ç”Ÿæˆç»“æœä¸å…¶ä»–æ¨¡å‹å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚å®éªŒç»“æœè¿˜æ˜¾ç¤º GPT-4o ä¸ DeepSeek-V3 åœ¨å¤„ç†è¯¥ä»»åŠ¡æ—¶è¡¨ç°å‡ºè¾ƒé«˜çš„ç›¸ä¼¼æ€§ï¼Œä¸ºåˆ©ç”¨ LLMs è¿›è¡Œæ–‡æœ¬æ²»ç†æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10177v1",
      "published_date": "2025-07-14 11:39:34 UTC",
      "updated_date": "2025-07-14 11:39:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:03.342201+00:00"
    },
    {
      "arxiv_id": "2508.00853v1",
      "title": "A Formal Framework for the Definition of 'State': Hierarchical Representation and Meta-Universe Interpretation",
      "title_zh": "â€œçŠ¶æ€â€å®šä¹‰çš„å½¢å¼åŒ–æ¡†æ¶ï¼šå±‚çº§åŒ–è¡¨å¾ä¸å…ƒå®‡å®™è¯ é‡Š",
      "authors": [
        "Kei Itoh"
      ],
      "abstract": "This study aims to reinforce the theoretical foundation for diverse systems--including the axiomatic definition of intelligence--by introducing a mathematically rigorous and unified formal structure for the concept of 'state,' which has long been used without consensus or formal clarity. First, a 'hierarchical state grid' composed of two axes--state depth and mapping hierarchy--is proposed to provide a unified notational system applicable across mathematical, physical, and linguistic domains. Next, the 'Intermediate Meta-Universe (IMU)' is introduced to enable explicit descriptions of definers (ourselves) and the languages we use, thereby allowing conscious meta-level operations while avoiding self-reference and logical inconsistency. Building on this meta-theoretical foundation, this study expands inter-universal theory beyond mathematics to include linguistic translation and agent integration, introducing the conceptual division between macrocosm-inter-universal and microcosm-inter-universal operations for broader expressivity. Through these contributions, this paper presents a meta-formal logical framework--grounded in the principle of definition = state--that spans time, language, agents, and operations, providing a mathematically robust foundation applicable to the definition of intelligence, formal logic, and scientific theory at large.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨ä¸ºâ€œStateâ€çš„æ¦‚å¿µå»ºç«‹ä¸€ä¸ªæ•°å­¦ä¸Šä¸¥è°¨ä¸”ç»Ÿä¸€çš„å½¢å¼åŒ–ç»“æ„ï¼Œä»¥è§£å†³è¯¥æœ¯è¯­é•¿æœŸç¼ºä¹å…±è¯†å’Œå½¢å¼åŒ–æ¸…æ™°åº¦çš„é—®é¢˜ï¼Œå¹¶å¢å¼ºæ™ºèƒ½å…¬ç†åŒ–å®šä¹‰çš„ç†è®ºåŸºç¡€ã€‚ç ”ç©¶é¦–å…ˆæå‡ºäº†ç”±â€œstate depthâ€å’Œâ€œmapping hierarchyâ€ä¸¤ä¸ªç»´åº¦æ„æˆçš„â€œhierarchical state gridâ€ï¼Œä¸ºæ•°å­¦ã€ç‰©ç†å’Œè¯­è¨€å­¦é¢†åŸŸæä¾›äº†ç»Ÿä¸€çš„ç¬¦å·ç³»ç»Ÿã€‚éšåå¼•å…¥äº†â€œIntermediate Meta-Universe (IMU)â€ï¼Œé€šè¿‡æ˜¾å¼æè¿°å®šä¹‰è€…å’Œæ‰€ä½¿ç”¨çš„è¯­è¨€ï¼Œåœ¨é¿å…è‡ªæŒ‡å’Œé€»è¾‘ä¸ä¸€è‡´çš„å‰æä¸‹å®ç°äº†å…ƒçº§æ“ä½œã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè¯¥ç ”ç©¶å°†â€œinter-universal theoryâ€æ‰©å±•è‡³è¯­è¨€ç¿»è¯‘å’Œâ€œagent integrationâ€ï¼Œå¹¶æå‡ºäº†â€œmacrocosm-inter-universalâ€ä¸â€œmicrocosm-inter-universalâ€æ“ä½œçš„æ¦‚å¿µåŒºåˆ†ä»¥å¢å¼ºè¡¨è¾¾åŠ›ã€‚æœ€ç»ˆï¼Œè¯¥è®ºæ–‡æ„å»ºäº†ä¸€ä¸ªåŸºäºâ€œdefinition = stateâ€åŸåˆ™çš„å…ƒå½¢å¼é€»è¾‘æ¡†æ¶ï¼Œä¸ºè·¨è¶Šæ—¶é—´ã€è¯­è¨€å’Œæ™ºèƒ½ä½“çš„æ™ºèƒ½å®šä¹‰ã€å½¢å¼é€»è¾‘åŠå¹¿ä¹‰ç§‘å­¦ç†è®ºæä¾›äº†ç¨³å¥çš„æ•°å­¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "43 pages, 8 figures, 8 Tables, in English, in Japanese",
      "pdf_url": "https://arxiv.org/pdf/2508.00853v1",
      "published_date": "2025-07-14 11:37:35 UTC",
      "updated_date": "2025-07-14 11:37:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:08.334390+00:00"
    },
    {
      "arxiv_id": "2507.10174v1",
      "title": "Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?",
      "title_zh": "ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­æˆ‘ä»¬æ˜¯å¦çœŸçš„åº”å½“åå¥½ Decision Transformerï¼Ÿ",
      "authors": [
        "Yumi Omori",
        "Zixuan Dong",
        "Keith Ross"
      ],
      "abstract": "In recent years, extensive work has explored the application of the Transformer architecture to reinforcement learning problems. Among these, Decision Transformer (DT) has gained particular attention in the context of offline reinforcement learning due to its ability to frame return-conditioned policy learning as a sequence modeling task. Most recently, Bhargava et al. (2024) provided a systematic comparison of DT with more conventional MLP-based offline RL algorithms, including Behavior Cloning (BC) and Conservative Q-Learning (CQL), and claimed that DT exhibits superior performance in sparse-reward and low-quality data settings.\n  In this paper, through experimentation on robotic manipulation tasks (Robomimic) and locomotion benchmarks (D4RL), we show that MLP-based Filtered Behavior Cloning (FBC) achieves competitive or superior performance compared to DT in sparse-reward environments. FBC simply filters out low-performing trajectories from the dataset and then performs ordinary behavior cloning on the filtered dataset. FBC is not only very straightforward, but it also requires less training data and is computationally more efficient. The results therefore suggest that DT is not preferable for sparse-reward environments. From prior work, arguably, DT is also not preferable for dense-reward environments. Thus, we pose the question: Is DT ever preferable?",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç¦»çº¿å¼ºåŒ–å­¦ä¹  (Offline Reinforcement Learning) ä¸­æ˜¯å¦çœŸçš„éœ€è¦ä½¿ç”¨å†³ç­–Transformer (Decision Transformer, DT)ï¼Œå¹¶æŒ‘æˆ˜äº† DT åœ¨ç¨€ç–å¥–åŠ±å’Œä½è´¨é‡æ•°æ®è®¾ç½®ä¸‹å…·æœ‰ä¼˜è¶Šæ€§çš„è§‚ç‚¹ã€‚é€šè¿‡åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ (Robomimic) å’Œè¿åŠ¨åŸºå‡† (D4RL) ä¸Šçš„å®éªŒï¼Œç ”ç©¶è€…å‘ç°åŸºäº MLP çš„è¿‡æ»¤è¡Œä¸ºå…‹éš† (Filtered Behavior Cloning, FBC) åœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸‹è¡¨ç°å‡ºä¸ DT ç«äº‰ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ã€‚FBC çš„æ ¸å¿ƒæ–¹æ³•æ˜¯ç®€å•åœ°ä»æ•°æ®é›†ä¸­è¿‡æ»¤æ‰ä½è¡¨ç°è½¨è¿¹ï¼Œéšåå¯¹å‰©ä½™æ•°æ®è¿›è¡Œæ™®é€šçš„è¡Œä¸ºå…‹éš† (Behavior Cloning, BC)ã€‚å®éªŒè¯æ˜ FBC ä¸ä»…å®ç°ç®€å•ï¼Œè€Œä¸”åœ¨è®­ç»ƒæ•°æ®éœ€æ±‚å’Œè®¡ç®—æ•ˆç‡ä¸Šå‡ä¼˜äº DTã€‚ç ”ç©¶ç»“è®ºæŒ‡å‡ºï¼Œé‰´äº DT åœ¨å¯†é›†å’Œç¨€ç–å¥–åŠ±ç¯å¢ƒä¸­å‡æœªå±•ç°å‡ºæ˜æ˜¾ä¼˜åŠ¿ï¼Œå…¶åœ¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„å¿…è¦æ€§å€¼å¾—å•†æ¦·ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by RLBrew: Ingredients for Developing Generalist Agents workshop (RLC 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.10174v1",
      "published_date": "2025-07-14 11:36:31 UTC",
      "updated_date": "2025-07-14 11:36:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:07.725827+00:00"
    },
    {
      "arxiv_id": "2507.10172v1",
      "title": "Play Style Identification Using Low-Level Representations of Play Traces in MicroRTS",
      "title_zh": "åŸºäº MicroRTS å¯¹å±€è½¨è¿¹åº•å±‚è¡¨ç¤ºçš„æ¸¸æˆé£æ ¼è¯†åˆ«",
      "authors": [
        "Ruizhe Yu Xia",
        "Jeremy Gow",
        "Simon Lucas"
      ],
      "abstract": "Play style identification can provide valuable game design insights and enable adaptive experiences, with the potential to improve game playing agents. Previous work relies on domain knowledge to construct play trace representations using handcrafted features. More recent approaches incorporate the sequential structure of play traces but still require some level of domain abstraction. In this study, we explore the use of unsupervised CNN-LSTM autoencoder models to obtain latent representations directly from low-level play trace data in MicroRTS. We demonstrate that this approach yields a meaningful separation of different game playing agents in the latent space, reducing reliance on domain expertise and its associated biases. This latent space is then used to guide the exploration of diverse play styles within studied AI players.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ MicroRTS ç¯å¢ƒä¸­åˆ©ç”¨ä½å±‚çº§æ¸¸æˆè½¨è¿¹(Play Traces)è¡¨ç¤ºè¿›è¡Œç©å®¶é£æ ¼è¯†åˆ«(Play Style Identification)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•è¿‡åº¦ä¾èµ–é¢†åŸŸçŸ¥è¯†å’Œæ‰‹å·¥ç‰¹å¾(handcrafted features)çš„é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿæ¢ç´¢äº†ä½¿ç”¨æ— ç›‘ç£çš„ CNN-LSTM autoencoder æ¨¡å‹ï¼Œç›´æ¥ä»åŸå§‹çš„ä½å±‚çº§è½¨è¿¹æ•°æ®ä¸­æå–æ½œç©ºé—´è¡¨ç¤º(latent representations)ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ½œç©ºé—´ä¸­å®ç°å¯¹ä¸åŒæ¸¸æˆæ™ºèƒ½ä½“(game playing agents)çš„æœ‰æ•ˆåˆ†ç¦»ï¼Œæ˜¾è‘—é™ä½äº†å¯¹é¢†åŸŸä¸“å®¶ç»éªŒåŠå…¶å…³è”åå·®çš„ä¾èµ–ã€‚æ‰€è·å¾—çš„æ½œç©ºé—´è¿›ä¸€æ­¥è¢«ç”¨äºæŒ‡å¯¼ AI ç©å®¶æ¢ç´¢å¤šæ ·åŒ–çš„æ¸¸æˆé£æ ¼ï¼Œä¸ºæ¸¸æˆè®¾è®¡æ´å¯Ÿå’Œè‡ªé€‚åº”ä½“éªŒæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚è¿™ä¸€ç ”ç©¶å±•ç¤ºäº†åœ¨æ— éœ€å¤æ‚é¢†åŸŸæŠ½è±¡çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹ç›´æ¥ä»åº•å±‚æ•°æ®æŒ–æ˜æ¸¸æˆè¡Œä¸ºæ¨¡å¼çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as Short Paper for IEEE CoG",
      "pdf_url": "https://arxiv.org/pdf/2507.10172v1",
      "published_date": "2025-07-14 11:35:43 UTC",
      "updated_date": "2025-07-14 11:35:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:12.747718+00:00"
    },
    {
      "arxiv_id": "2507.10156v1",
      "title": "Introducing the Swiss Food Knowledge Graph: AI for Context-Aware Nutrition Recommendation",
      "title_zh": "Swiss Food Knowledge Graphï¼šé¢å‘æƒ…å¢ƒæ„ŸçŸ¥è¥å…»æ¨èçš„äººå·¥æ™ºèƒ½",
      "authors": [
        "Lubnaa Abdur Rahman",
        "Ioannis Papathanail",
        "Stavroula Mougiakakou"
      ],
      "abstract": "AI has driven significant progress in the nutrition field, especially through multimedia-based automatic dietary assessment. However, existing automatic dietary assessment systems often overlook critical non-visual factors, such as recipe-specific ingredient substitutions that can significantly alter nutritional content, and rarely account for individual dietary needs, including allergies, restrictions, cultural practices, and personal preferences. In Switzerland, while food-related information is available, it remains fragmented, and no centralized repository currently integrates all relevant nutrition-related aspects within a Swiss context. To bridge this divide, we introduce the Swiss Food Knowledge Graph (SwissFKG), the first resource, to our best knowledge, to unite recipes, ingredients, and their substitutions with nutrient data, dietary restrictions, allergen information, and national nutrition guidelines under one graph. We establish a LLM-powered enrichment pipeline for populating the graph, whereby we further present the first benchmark of four off-the-shelf (<70 B parameter) LLMs for food knowledge augmentation. Our results demonstrate that LLMs can effectively enrich the graph with relevant nutritional information. Our SwissFKG goes beyond recipe recommendations by offering ingredient-level information such as allergen and dietary restriction information, and guidance aligned with nutritional guidelines. Moreover, we implement a Graph-RAG application to showcase how the SwissFKG's rich natural-language data structure can help LLM answer user-specific nutrition queries, and we evaluate LLM-embedding pairings by comparing user-query responses against predefined expected answers. As such, our work lays the foundation for the next generation of dietary assessment tools that blend visual, contextual, and cultural dimensions of eating.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Swiss Food Knowledge Graph (SwissFKG)ï¼Œè¿™æ˜¯é¦–ä¸ªæ•´åˆäº†ç‘å£«èƒŒæ™¯ä¸‹é£Ÿè°±ã€æˆåˆ†åŠå…¶æ›¿ä»£å“ã€è¥å…»æ•°æ®ã€è¿‡æ•åŸä¿¡æ¯åŠå›½å®¶è¥å…»æŒ‡å—çš„èµ„æºï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è†³é£Ÿè¯„ä¼°ç³»ç»Ÿå¿½è§†éè§†è§‰å› ç´ å’Œä¸ªäººé¥®é£Ÿéœ€æ±‚çš„é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€å¥—åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¯ŒåŒ–æµæ°´çº¿æ¥å¡«å……å›¾è°±ï¼Œå¹¶å¯¹å››ç§ç°æˆçš„LLMåœ¨é£Ÿç‰©çŸ¥è¯†å¢å¼ºæ–¹é¢çš„æ€§èƒ½è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚å®éªŒè¯æ˜ï¼ŒLLMèƒ½æœ‰æ•ˆä¸ºå›¾è°±è¡¥å……å…³é”®è¥å…»ä¿¡æ¯ï¼Œä½¿å…¶å…·å¤‡æä¾›æˆåˆ†çº§è¿‡æ•åŸè¯†åˆ«å’Œé¥®é£Ÿé™åˆ¶æŒ‡å¯¼çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œé€šè¿‡å®ç°Graph-RAGåº”ç”¨ï¼Œè¯¥ç ”ç©¶å±•ç¤ºäº†SwissFKGå¦‚ä½•åˆ©ç”¨å…¶ä¸°å¯Œçš„è‡ªç„¶è¯­è¨€æ•°æ®ç»“æ„è¾…åŠ©LLMç²¾å‡†å›ç­”ç”¨æˆ·ç‰¹å®šçš„è¥å…»å’¨è¯¢ã€‚è¯¥å·¥ä½œèåˆäº†é¥®é£Ÿçš„è§†è§‰ã€æƒ…å¢ƒå’Œæ–‡åŒ–ç»´åº¦ï¼Œä¸ºå¼€å‘ä¸‹ä¸€ä»£æ™ºèƒ½åŒ–è†³é£Ÿè¯„ä¼°å·¥å…·å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 2 Figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.10156v1",
      "published_date": "2025-07-14 11:12:30 UTC",
      "updated_date": "2025-07-14 11:12:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:47.091835+00:00"
    },
    {
      "arxiv_id": "2507.15866v1",
      "title": "Purchase and Production Optimization in a Meat Processing Plant",
      "title_zh": "è‚‰ç±»åŠ å·¥å‚é‡‡è´­ä¸ç”Ÿäº§ä¼˜åŒ–",
      "authors": [
        "Marek Vlk",
        "Premysl Sucha",
        "Jaroslaw Rudy",
        "Radoslaw Idzikowski"
      ],
      "abstract": "The food production industry, especially the meat production sector, faces many challenges that have even escalated due to the recent outbreak of the energy crisis in the European Union. Therefore, efficient use of input materials is an essential aspect affecting the profit of such companies. This paper addresses an optimization problem concerning the purchase and subsequent material processing we solved for a meat processing company. Unlike the majority of existing papers, we do not concentrate on how this problem concerns supply chain management, but we focus purely on the production stage. The problem involves the concept of alternative ways of material processing, stock of material with different expiration dates, and extra constraints widely neglected in the current literature, namely, the minimum order quantity and the minimum percentage in alternatives. We prove that each of these two constraints makes the problem \\mbox{$\\mathcal{NP}$-hard}, and hence we design a simple iterative approach based on integer linear programming that allows us to solve real-life instances even using an open-source integer linear programming solver. Another advantage of this approach is that it mitigates numerical issues, caused by the extensive range of data values, we experienced with a commercial solver. The results obtained using real data from the meat processing company showed that our algorithm can find the optimum solution in a few seconds for all considered use cases.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‚‰ç±»åŠ å·¥å‚çš„é‡‡è´­ä¸ç”Ÿäº§ä¼˜åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨æé«˜åŸææ–™åˆ©ç”¨æ•ˆç‡å¹¶æœ€å¤§åŒ–åˆ©æ¶¦çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚ä¸åŒäºå¤šæ•°ä¾§é‡ä¾›åº”é“¾ç®¡ç†çš„ç ”ç©¶ï¼Œæœ¬æ–‡ä¸“æ³¨äºç”Ÿäº§é˜¶æ®µï¼Œå¹¶ç»¼åˆè€ƒè™‘äº†ç‰©æ–™æ›¿ä»£åŠ å·¥ã€å…·æœ‰ä¸åŒä¿è´¨æœŸçš„åº“å­˜ç®¡ç†ä»¥åŠæ–‡çŒ®ä¸­å¸¸è¢«å¿½ç•¥çš„æœ€å°è®¢è´§é‡ (Minimum Order Quantity) å’Œæ›¿ä»£æ–¹æ¡ˆæœ€ä½å æ¯” (Minimum Percentage in Alternatives) ç­‰å…³é”®çº¦æŸã€‚ç ”ç©¶è¯æ˜äº†ä¸Šè¿°ä¸¤é¡¹æ–°å¢çº¦æŸä½¿å¾—è¯¥é—®é¢˜å±äº $\\mathcal{NP}$-hard èŒƒç•´ï¼Œä¸ºæ­¤è®¾è®¡äº†ä¸€ç§åŸºäºæ•´æ•°çº¿æ€§è§„åˆ’ (Integer Linear Programming) çš„ç®€å•è¿­ä»£æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¸ä»…æ”¯æŒä½¿ç”¨å¼€æºæ±‚è§£å™¨ï¼Œè¿˜èƒ½æœ‰æ•ˆç¼“è§£å› æ•°æ®å€¼è·¨åº¦è¿‡å¤§è€Œåœ¨å•†ä¸šæ±‚è§£å™¨ä¸­å‡ºç°çš„æ•°å€¼è®¡ç®—é—®é¢˜ã€‚åˆ©ç”¨è‚‰ç±»åŠ å·¥ä¼ä¸šçš„çœŸå®æ•°æ®è¿›è¡Œæµ‹è¯•ï¼Œç»“æœæ˜¾ç¤ºè¯¥ç®—æ³•åœ¨æ•°ç§’å†…å³å¯é’ˆå¯¹æ‰€æœ‰åº”ç”¨åœºæ™¯æ‰¾åˆ°æœ€ä¼˜è§£ã€‚è¯¥ç ”ç©¶ä¸ºé£Ÿå“åŠ å·¥è¡Œä¸šåœ¨é¢ä¸´èƒ½æºå±æœºç­‰æŒ‘æˆ˜æ—¶ï¼Œå®ç°é«˜æ•ˆçš„ç”Ÿäº§å†³ç­–æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15866v1",
      "published_date": "2025-07-14 11:05:46 UTC",
      "updated_date": "2025-07-14 11:05:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:18.705924+00:00"
    },
    {
      "arxiv_id": "2507.10142v1",
      "title": "Adaptability in Multi-Agent Reinforcement Learning: A Framework and Unified Review",
      "title_zh": "å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„é€‚åº”æ€§ï¼šæ¡†æ¶ä¸ç»Ÿä¸€ç»¼è¿°",
      "authors": [
        "Siyi Hu",
        "Mohamad A Hady",
        "Jianglin Qiao",
        "Jimmy Cao",
        "Mahardhika Pratama",
        "Ryszard Kowalczyk"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) has shown clear effectiveness in coordinating multiple agents across simulated benchmarks and constrained scenarios. However, its deployment in real-world multi-agent systems (MAS) remains limited, primarily due to the complex and dynamic nature of such environments. These challenges arise from multiple interacting sources of variability, including fluctuating agent populations, evolving task goals, and inconsistent execution conditions. Together, these factors demand that MARL algorithms remain effective under continuously changing system configurations and operational demands. To better capture and assess this capacity for adjustment, we introduce the concept of \\textit{adaptability} as a unified and practically grounded lens through which to evaluate the reliability of MARL algorithms under shifting conditions, broadly referring to any changes in the environment dynamics that may occur during learning or execution. Centred on the notion of adaptability, we propose a structured framework comprising three key dimensions: learning adaptability, policy adaptability, and scenario-driven adaptability. By adopting this adaptability perspective, we aim to support more principled assessments of MARL performance beyond narrowly defined benchmarks. Ultimately, this survey contributes to the development of algorithms that are better suited for deployment in dynamic, real-world multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Multi-Agent Reinforcement Learning (MARL)åœ¨åº”å¯¹ç°å®ä¸–ç•ŒåŠ¨æ€å¤æ‚ç¯å¢ƒä¸­çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†adaptabilityï¼ˆé€‚åº”æ€§ï¼‰è¿™ä¸€æ ¸å¿ƒæ¦‚å¿µä½œä¸ºè¯„ä¼°ç®—æ³•å¯é æ€§çš„ç»Ÿä¸€è§†è§’ã€‚ä¸ºäº†åº”å¯¹Agentæ•°é‡æ³¢åŠ¨ã€ä»»åŠ¡ç›®æ ‡æ¼”å˜åŠæ‰§è¡Œæ¡ä»¶ä¸ä¸€è‡´ç­‰æŒ‘æˆ˜ï¼Œç ”ç©¶æ„å»ºäº†ä¸€ä¸ªåŒ…å«learning adaptabilityã€policy adaptabilityå’Œscenario-driven adaptabilityä¸‰ä¸ªå…³é”®ç»´åº¦çš„ç»“æ„åŒ–æ¡†æ¶ã€‚é€šè¿‡å¼•å…¥é€‚åº”æ€§è§†è§’ï¼Œè¯¥ç»¼è¿°æ—¨åœ¨æ”¯æŒè¶…è¶Šç‹­éš˜åŸºå‡†æµ‹è¯•çš„æ›´å…·åŸåˆ™æ€§çš„æ€§èƒ½è¯„ä¼°ï¼Œä»è€Œå¢å¼ºç®—æ³•åœ¨ç¯å¢ƒåŠ¨æ€å˜åŒ–ä¸‹çš„å¯é æ€§ã€‚æœ€ç»ˆï¼Œè¿™é¡¹å·¥ä½œä¸ºå¼€å‘é€‚ç”¨äºåŠ¨æ€ç°å®Multi-Agent Systems (MAS)éƒ¨ç½²çš„é²æ£’ç®—æ³•è´¡çŒ®äº†ç³»ç»Ÿæ€§çš„æ¡†æ¶ä¸è§è§£ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10142v1",
      "published_date": "2025-07-14 10:39:17 UTC",
      "updated_date": "2025-07-14 10:39:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:19.331586+00:00"
    },
    {
      "arxiv_id": "2507.10136v5",
      "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic Strategy in Melanoma",
      "title_zh": "PBN-RL-XAIï¼šä¸€ç§ç”¨äºå‘ç°é»‘è‰²ç´ ç˜¤â€œä¸€å‡»å³é€€â€å¼æ²»ç–—ç­–ç•¥çš„æ¡†æ¶",
      "authors": [
        "Zhonglin Liu"
      ],
      "abstract": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical challenge in metastatic melanoma, with the underlying molecular networks being poorly understood. To address this, we constructed a dynamic Probabilistic Boolean Network model using transcriptomic data from patient tumor biopsies to elucidate the regulatory logic governing therapy response. We then employed a reinforcement learning agent to systematically discover optimal, multi-step therapeutic interventions and used explainable artificial intelligence to mechanistically interpret the agent's control policy. The analysis revealed that a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2 protein (LOXL2) was the most effective strategy. Our explainable analysis showed that this ''hit-and-run\" intervention is sufficient to erase the molecular signature driving resistance, allowing the network to self-correct without requiring sustained intervention. This study presents a novel, time-dependent therapeutic hypothesis for overcoming immunotherapy resistance and provides a powerful computational framework for identifying non-obvious intervention protocols in complex biological systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»“åˆäº†æ¦‚ç‡å¸ƒå°”ç½‘ç»œ(Probabilistic Boolean Network, PBN)ã€å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)å’Œå¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI, XAI)çš„é›†æˆæ¡†æ¶ï¼Œæ—¨åœ¨æ”»å…‹é»‘è‰²ç´ ç˜¤å¯¹æŠ—PD-1å…ç–«ç–—æ³•(anti-PD-1 immunotherapy)çš„å…ˆå¤©è€è¯éš¾é¢˜ã€‚é€šè¿‡åˆ©ç”¨æ‚£è€…è‚¿ç˜¤æ´»æ£€çš„è½¬å½•ç»„æ•°æ®æ„å»ºåŠ¨æ€æ¨¡å‹ï¼Œç ”ç©¶äººå‘˜åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¢ç´¢æœ€ä¼˜çš„å¤šæ­¥æ²»ç–—æ–¹æ¡ˆï¼Œå¹¶å€ŸåŠ©XAIæŠ€æœ¯é˜æ˜äº†æ§åˆ¶ç­–ç•¥çš„æœºæ¢°åŸç†ã€‚ç ”ç©¶å‘ç°ï¼Œå¯¹èµ–æ°¨é…°æ°§åŒ–é…¶æ ·2è›‹ç™½(LOXL2)è¿›è¡Œç²¾ç¡®è®¡æ—¶çš„4æ­¥ä¸´æ—¶æŠ‘åˆ¶æ˜¯æœ€é«˜æ•ˆçš„ç­–ç•¥ã€‚è¿™ç§è¢«ç§°ä¸ºâ€œæ‰“å®Œå°±è·‘â€(hit-and-run)çš„å¹²é¢„æ–¹å¼èƒ½å¤Ÿæœ‰æ•ˆæ¸…é™¤é©±åŠ¨è€è¯çš„åˆ†å­ç‰¹å¾ï¼Œä½¿ç”Ÿç‰©ç½‘ç»œåœ¨æ— éœ€æŒç»­æ²»ç–—çš„æƒ…å†µä¸‹å®ç°è‡ªæˆ‘ä¿®æ­£ã€‚è¯¥æˆæœä¸ºå…‹æœå…ç–«æ²»ç–—è€è¯æ€§æä¾›äº†ä¸€ç§å…¨æ–°çš„ã€å…·æœ‰æ—¶é—´ä¾èµ–æ€§çš„æ²»ç–—å‡è®¾ï¼Œå¹¶è¯æ˜äº†è¯¥æ¡†æ¶åœ¨è¯†åˆ«å¤æ‚ç”Ÿç‰©ç³»ç»Ÿä¸­éç›´è§‚å¹²é¢„æ–¹æ¡ˆæ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "7 pages, 7 figures. Accepted by the IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2025. Code is available at https://github.com/Liu-Zhonglin/pbn-melanoma-project",
      "pdf_url": "https://arxiv.org/pdf/2507.10136v5",
      "published_date": "2025-07-14 10:35:38 UTC",
      "updated_date": "2025-10-29 09:47:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:29.130183+00:00"
    },
    {
      "arxiv_id": "2507.10134v1",
      "title": "FRSICL: LLM-Enabled In-Context Learning Flight Resource Allocation for Fresh Data Collection in UAV-Assisted Wildfire Monitoring",
      "title_zh": "FRSICLï¼šé¢å‘æ— äººæœºè¾…åŠ©é‡ç«ç›‘æµ‹æ–°é²œæ•°æ®é‡‡é›†çš„å¤§è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡å­¦ä¹ é£è¡Œèµ„æºåˆ†é…",
      "authors": [
        "Yousef Emami",
        "Hao Zhou",
        "Miguel Gutierrez Gaitan",
        "Kai Li",
        "Luis Almeida"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) are vital for public safety, particularly in wildfire monitoring, where early detection minimizes environmental impact. In UAV-Assisted Wildfire Monitoring (UAWM) systems, joint optimization of sensor transmission scheduling and velocity is critical for minimizing Age of Information (AoI) from stale sensor data. Deep Reinforcement Learning (DRL) has been used for such optimization; however, its limitations such as low sampling efficiency, simulation-to-reality gaps, and complex training render it unsuitable for time-critical applications like wildfire monitoring. This paper introduces a new online Flight Resource Allocation scheme based on LLM-Enabled In-Context Learning (FRSICL) to jointly optimize the UAV's flight control and data collection schedule along the trajectory in real time, thereby asymptotically minimizing the average AoI across ground sensors. In contrast to DRL, FRSICL generates data collection schedules and controls velocity using natural language task descriptions and feedback from the environment, enabling dynamic decision-making without extensive retraining. Simulation results confirm the effectiveness of the proposed FRSICL compared to Proximal Policy Optimization (PPO) and Nearest-Neighbor baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— äººæœºè¾…åŠ©æ£®æ—ç«ç¾ç›‘æµ‹ï¼ˆUAWMï¼‰ç³»ç»Ÿä¸­çš„ä¿¡æ¯æ–°é²œåº¦é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ä½¿èƒ½çš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆLLM-Enabled In-Context Learningï¼‰é£è¡Œèµ„æºåˆ†é…æ–¹æ¡ˆFRSICLã€‚ä¼ ç»Ÿçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰æ–¹æ³•åœ¨å¤„ç†è¯¥é—®é¢˜æ—¶é¢ä¸´é‡‡æ ·æ•ˆç‡ä½ã€ä»¿çœŸåˆ°ç°å®å­˜åœ¨å·®è·ä»¥åŠè®­ç»ƒè¿‡ç¨‹å¤æ‚ç­‰æŒ‘æˆ˜ï¼Œéš¾ä»¥æ»¡è¶³ç«ç¾ç›‘æµ‹çš„ç´§è¿«æ€§è¦æ±‚ã€‚FRSICLé€šè¿‡åˆ©ç”¨è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°å’Œç¯å¢ƒåé¦ˆï¼Œåœ¨æ— éœ€å¤§è§„æ¨¡é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°å®æ—¶çš„é£è¡Œæ§åˆ¶ä¸æ•°æ®é‡‡é›†è°ƒåº¦å†³ç­–ï¼Œä»è€Œæ¸è¿›åœ°æœ€å°åŒ–åœ°é¢ä¼ æ„Ÿå™¨çš„å¹³å‡ä¿¡æ¯å¹´é¾„ï¼ˆAge of Information, AoIï¼‰ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œä¸è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimization, PPOï¼‰å’Œæœ€è¿‘é‚»ï¼ˆNearest-Neighborï¼‰ç­‰åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒFRSICLèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä¼˜åŒ–æ— äººæœºçš„èµ„æºåˆ†é…ï¼Œæ˜¾è‘—æå‡äº†ç›‘æµ‹æ•°æ®çš„å®æ—¶æ€§ã€‚è¯¥æ–¹æ³•è¯æ˜äº†åˆ©ç”¨LLMè¿›è¡Œåœ¨çº¿å†³ç­–åœ¨å¤„ç†å¤æ‚ä¸”æ—¶é—´æ•æ„Ÿçš„å…¬å…±å®‰å…¨ä»»åŠ¡ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10134v1",
      "published_date": "2025-07-14 10:24:43 UTC",
      "updated_date": "2025-07-14 10:24:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:28.039511+00:00"
    },
    {
      "arxiv_id": "2507.10133v1",
      "title": "Extending Defeasibility for Propositional Standpoint Logics",
      "title_zh": "å‘½é¢˜ç«‹åœºé€»è¾‘çš„å¯æ’¤é”€æ€§æ‰©å±•",
      "authors": [
        "Nicholas Leisegang",
        "Thomas Meyer",
        "Ivan Varzinczak"
      ],
      "abstract": "In this paper, we introduce a new defeasible version of propositional standpoint logic by integrating Kraus et al.'s defeasible conditionals, Britz and Varzinczak's notions of defeasible necessity and distinct possibility, along with Leisegang et al.'s approach to defeasibility into the standpoint logics of GÃ³mez Ãlvarez and Rudolph. The resulting logical framework allows for the expression of defeasibility on the level of implications, standpoint modal operators, and standpoint-sharpening statements. We provide a preferential semantics for this extended language and propose a tableaux calculus, which is shown to be sound and complete with respect to preferential entailment. We also establish the computational complexity of the tableaux procedure to be in PSpace.",
      "tldr_zh": "è¯¥ç ”ç©¶ä¸ºå‘½é¢˜ç«‹åœºé€»è¾‘ (propositional standpoint logic) å¼•å…¥äº†ä¸€ä¸ªå…¨æ–°çš„å¯åºŸæ­¢ (defeasible) ç‰ˆæœ¬ã€‚å®ƒé€šè¿‡æ•´åˆ Kraus ç­‰äººçš„å¯åºŸæ­¢æ¡ä»¶å¥ã€Britz å’Œ Varzinczak çš„å¯åºŸæ­¢å¿…ç„¶æ€§ä¸ç‰¹æ®Šå¯èƒ½æ€§æ¦‚å¿µï¼Œä»¥åŠ Leisegang ç­‰äººçš„æ–¹æ³•ï¼Œæ‰©å±•äº†æ—¢æœ‰çš„ç«‹åœºé€»è¾‘æ¡†æ¶ã€‚è¯¥é€»è¾‘æ¡†æ¶å…è®¸åœ¨è•´å« (implications)ã€ç«‹åœºæ¨¡æ€ç®—å­ (standpoint modal operators) å’Œç«‹åœºé”åŒ–é™ˆè¿° (standpoint-sharpening statements) å¤šä¸ªå±‚é¢è¡¨è¾¾å¯åºŸæ­¢æ€§ã€‚ç ”ç©¶ä¸ºè¿™ç§æ‰©å±•è¯­è¨€æä¾›äº†ä¼˜å…ˆè¯­ä¹‰ (preferential semantics)ï¼Œå¹¶æå‡ºäº†ä¸€å¥—è¡¨è®¡ç®— (tableaux calculus) æ–¹æ³•ã€‚ä½œè€…é€šè¿‡ä¸¥è°¨è¯æ˜ç¡®è®¤äº†è¯¥ç®—æ³•ç›¸å¯¹äºä¼˜å…ˆæ¨å¯¼ (preferential entailment) çš„å¯é æ€§ (soundness) ä¸å®Œå¤‡æ€§ (completeness)ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜ç¡®å®šäº†è¡¨è®¡ç®—ç¨‹åºçš„è®¡ç®—å¤æ‚åº¦ä¸º PSpace çº§åˆ«ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10133v1",
      "published_date": "2025-07-14 10:23:49 UTC",
      "updated_date": "2025-07-14 10:23:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:29.698965+00:00"
    },
    {
      "arxiv_id": "2507.10132v1",
      "title": "Wavelet-Enhanced Neural ODE and Graph Attention for Interpretable Energy Forecasting",
      "title_zh": "é¢å‘å¯è§£é‡Šèƒ½æºé¢„æµ‹çš„å°æ³¢å¢å¼ºç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ä¸å›¾æ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Usman Gani Joy"
      ],
      "abstract": "Accurate forecasting of energy demand and supply is critical for optimizing sustainable energy systems, yet it is challenged by the variability of renewable sources and dynamic consumption patterns. This paper introduces a neural framework that integrates continuous-time Neural Ordinary Differential Equations (Neural ODEs), graph attention, multi-resolution wavelet transformations, and adaptive learning of frequencies to address the issues of time series prediction. The model employs a robust ODE solver, using the Runge-Kutta method, paired with graph-based attention and residual connections to better understand both structural and temporal patterns. Through wavelet-based feature extraction and adaptive frequency modulation, it adeptly captures and models diverse, multi-scale temporal dynamics. When evaluated across seven diverse datasets: ETTh1, ETTh2, ETTm1, ETTm2 (electricity transformer temperature), and Waste, Solar, and Hydro (renewable energy), this architecture consistently outperforms state-of-the-art baselines in various forecasting metrics, proving its robustness in capturing complex temporal dependencies. Furthermore, the model enhances interpretability through SHAP analysis, making it suitable for sustainable energy applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ•´åˆäº†è¿ç»­æ—¶é—´ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ (Neural ODEs)ã€å›¾æ³¨æ„åŠ› (Graph Attention) å’Œå¤šåˆ†è¾¨ç‡å°æ³¢å˜æ¢ (Wavelet Transformations) çš„ç¥ç»æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³èƒ½æºéœ€æ±‚ä¸ä¾›åº”é¢„æµ‹ä¸­çš„å˜åŠ¨æ€§æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ Runge-Kutta æ–¹æ³•ä½œä¸ºç¨³å¥çš„ ODE æ±‚è§£å™¨ï¼Œå¹¶ç»“åˆå›¾æ³¨æ„åŠ›æœºåˆ¶ä¸æ®‹å·®è¿æ¥ (Residual Connections)ï¼Œä»¥æ·±å…¥ç†è§£æ•°æ®ä¸­çš„ç»“æ„å’Œæ—¶é—´æ¨¡å¼ã€‚é€šè¿‡å°æ³¢ç‰¹å¾æå–å’Œè‡ªé€‚åº”é¢‘ç‡è°ƒåˆ¶æŠ€æœ¯ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å¹¶å»ºæ¨¡å¤æ‚çš„å¤šå°ºåº¦æ—¶é—´åŠ¨æ€ç‰¹å¾ã€‚åœ¨åŒ…æ‹¬ç”µåŠ›å˜å‹å™¨æ¸©åº¦ (ETT) ä»¥åŠåºŸç‰©ã€å¤ªé˜³èƒ½ã€æ°´èƒ½ç­‰å¯å†ç”Ÿèƒ½æºåœ¨å†…çš„ä¸ƒä¸ªå¤šæ ·åŒ–æ•°æ®é›†ä¸Šï¼Œè¯¥æ¶æ„åœ¨å„é¡¹é¢„æµ‹æŒ‡æ ‡ä¸Šå‡ä¸€è‡´ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨ SHAP åˆ†æå¢å¼ºäº†é¢„æµ‹ç»“æœçš„å¯è§£é‡Šæ€§ï¼Œä½¿å…¶éå¸¸é€‚ç”¨äºå¯æŒç»­èƒ½æºé¢†åŸŸçš„å®é™…åº”ç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10132v1",
      "published_date": "2025-07-14 10:23:18 UTC",
      "updated_date": "2025-07-14 10:23:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:40:59.690337+00:00"
    },
    {
      "arxiv_id": "2507.10127v1",
      "title": "Taming Modern Point Tracking for Speckle Tracking Echocardiography via Impartial Motion",
      "title_zh": "é€šè¿‡æ— åè¿åŠ¨ä¼˜åŒ–é¢å‘æ–‘ç‚¹è¿½è¸ªè¶…å£°å¿ƒåŠ¨å›¾çš„ç°ä»£ç‚¹è¿½è¸ªæŠ€æœ¯",
      "authors": [
        "Md Abulkalam Azad",
        "John Nyberg",
        "HÃ¥vard Dalen",
        "BjÃ¸rnar Grenne",
        "Lasse Lovstakken",
        "Andreas Ã˜stvik"
      ],
      "abstract": "Accurate motion estimation for tracking deformable tissues in echocardiography is essential for precise cardiac function measurements. While traditional methods like block matching or optical flow struggle with intricate cardiac motion, modern point tracking approaches remain largely underexplored in this domain. This work investigates the potential of state-of-the-art (SOTA) point tracking methods for ultrasound, with a focus on echocardiography. Although these novel approaches demonstrate strong performance in general videos, their effectiveness and generalizability in echocardiography remain limited. By analyzing cardiac motion throughout the heart cycle in real B-mode ultrasound videos, we identify that a directional motion bias across different views is affecting the existing training strategies. To mitigate this, we refine the training procedure and incorporate a set of tailored augmentations to reduce the bias and enhance tracking robustness and generalization through impartial cardiac motion. We also propose a lightweight network leveraging multi-scale cost volumes from spatial context alone to challenge the advanced spatiotemporal point tracking models. Experiments demonstrate that fine-tuning with our strategies significantly improves models' performances over their baselines, even for out-of-distribution (OOD) cases. For instance, EchoTracker boosts overall position accuracy by 60.7% and reduces median trajectory error by 61.5% across heart cycle phases. Interestingly, several point tracking models fail to outperform our proposed simple model in terms of tracking accuracy and generalization, reflecting their limitations when applied to echocardiography. Nevertheless, clinical evaluation reveals that these methods improve GLS measurements, aligning more closely with expert-validated, semi-automated tools and thus demonstrating better reproducibility in real-world applications.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ Speckle Tracking Echocardiography ä¸­å˜å½¢ç»„ç»‡è¿åŠ¨ä¼°è®¡çš„æŒ‘æˆ˜ï¼Œæ¢è®¨äº†ç°ä»£ point tracking æ–¹æ³•åœ¨è¶…å£°é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰æ¨¡å‹åœ¨å¤„ç†çœŸå® B-mode è¶…å£°è§†é¢‘æ—¶å—é™äºä¸åŒè§†å›¾é—´çš„å®šå‘è¿åŠ¨åå·® (directional motion bias)ï¼Œä»è€Œå½±å“äº†è¿½è¸ªçš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…é€šè¿‡æ”¹è¿›è®­ç»ƒç¨‹åºå¹¶å¼•å…¥å®šåˆ¶çš„æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œæå‡ºäº†é€šè¿‡â€œå…¬æ­£è¿åŠ¨â€(impartial motion) æ¥å¢å¼ºé²æ£’æ€§çš„ç­–ç•¥ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªåŸºäºç©ºé—´ä¸Šä¸‹æ–‡å¤šå°ºåº¦ä»£ä»·å· (multi-scale cost volumes) çš„è½»é‡åŒ–ç½‘ç»œ EchoTrackerã€‚å®éªŒè¯æ˜ï¼Œè¯¥è®­ç»ƒç­–ç•¥æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼ŒEchoTracker åœ¨ä½ç½®å‡†ç¡®ç‡å’Œè½¨è¿¹è¯¯å·®ä¸Šåˆ†åˆ«æ”¹å–„äº† 60.7% å’Œ 61.5%ï¼Œå³ä½¿åœ¨åˆ†å¸ƒå¤– (OOD) æƒ…å†µä¸‹ä¹Ÿè¡¨ç°å‡ºè‰²ã€‚ä¸´åºŠè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº† GLS æµ‹é‡çš„å‡†ç¡®æ€§ä¸å†ç°æ€§ï¼Œä½¿å…¶æ›´æ¥è¿‘ä¸“å®¶éªŒè¯çš„åŠè‡ªåŠ¨å·¥å…·ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åŒ»ç–—åœºæ™¯ä¸­çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVAMD workshop at ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10127v1",
      "published_date": "2025-07-14 10:18:26 UTC",
      "updated_date": "2025-07-14 10:18:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:04.944184+00:00"
    },
    {
      "arxiv_id": "2507.10124v1",
      "title": "Could you be wrong: Debiasing LLMs using a metacognitive prompt for improving human decision making",
      "title_zh": "â€œä½ ä¼šé”™å—â€ï¼šåˆ©ç”¨å…ƒè®¤çŸ¥æç¤ºæ¶ˆé™¤å¤§è¯­è¨€æ¨¡å‹åå·®ä»¥æå‡äººç±»å†³ç­–æ°´å¹³",
      "authors": [
        "Thomas T. Hills"
      ],
      "abstract": "Identifying bias in LLMs is ongoing. Because they are still in development, what is true today may be false tomorrow. We therefore need general strategies for debiasing that will outlive current models. Strategies developed for debiasing human decision making offer one promising approach as they incorporate an LLM-style prompt intervention designed to bring latent knowledge into awareness during decision making. LLMs trained on vast amounts of information contain information about potential biases, counter-arguments, and contradictory evidence, but that information may only be brought to bear if prompted. Metacognitive prompts developed in the human decision making literature are designed to achieve this, and as I demonstrate here, they show promise with LLMs. The prompt I focus on here is \"could you be wrong?\" Following an LLM response, this prompt leads LLMs to produce additional information, including why they answered as they did, errors, biases, contradictory evidence, and alternatives, none of which were apparent in their initial response. Indeed, this metaknowledge often reveals that how LLMs and users interpret prompts are not aligned. Here I demonstrate this prompt using a set of questions taken from recent articles about LLM biases, including implicit discriminatory biases and failures of metacognition. \"Could you be wrong\" prompts the LLM to identify its own biases and produce cogent metacognitive reflection. I also present another example involving convincing but incomplete information, which is readily corrected by the metacognitive prompt. In sum, this work argues that human psychology offers a new avenue for prompt engineering, leveraging a long history of effective prompt-based improvements to human decision making.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å€Ÿé‰´äººç±»å¿ƒç†å­¦ä¸­çš„å…ƒè®¤çŸ¥ç­–ç•¥æ¥å‡å°‘å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„åå·®ï¼Œæ—¨åœ¨å¼€å‘å‡ºä¸€ç§å…·æœ‰æŒä¹…æ€§çš„å»åå·®(debiasing)æ–¹æ³•ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åä¸ºâ€œCould you be wrong?â€çš„å…ƒè®¤çŸ¥æç¤º(metacognitive prompt)å¹²é¢„æ‰‹æ®µï¼Œé€šè¿‡åœ¨åˆå§‹å›ç­”åè¿½åŠ æé—®ï¼Œå¼•å¯¼æ¨¡å‹å”¤é†’å…¶å…³äºåå·®ã€åé¢è®ºæ®å’ŒçŸ›ç›¾è¯æ®çš„æ½œåœ¨çŸ¥è¯†ã€‚å®éªŒå‘ç°ï¼Œè¯¥æç¤ºèƒ½ä¿ƒä½¿æ¨¡å‹äº§ç”Ÿåˆå§‹å›å¤ä¸­æœªæ˜¾ç¤ºçš„é¢å¤–ä¿¡æ¯ï¼ŒåŒ…æ‹¬é”™è¯¯è¯†åˆ«ã€åå·®åˆ†æåŠæ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶æ­ç¤ºäº†æ¨¡å‹ä¸ç”¨æˆ·åœ¨ä»»åŠ¡ç†è§£ä¸Šçš„ä¸ä¸€è‡´ã€‚é€šè¿‡å¯¹éšæ€§æ­§è§†åå·®å’Œå…ƒè®¤çŸ¥å¤±æ•ˆæ¡ˆä¾‹çš„æµ‹è¯•ï¼Œè¯¥æ–¹æ³•è¯æ˜äº†æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆçš„å…ƒè®¤çŸ¥åæ€(metacognitive reflection)å¹¶çº æ­£ä¸å®Œæ•´çš„ä¿¡æ¯ã€‚æ­¤é¡¹å·¥ä½œå¼ºè°ƒäº†äººç±»å†³ç­–ç ”ç©¶ä¸ºæç¤ºå·¥ç¨‹(prompt engineering)æä¾›çš„å…¨æ–°è·¯å¾„ï¼Œå³åˆ©ç”¨æœ‰æ•ˆçš„å¿ƒç†å­¦å¹²é¢„æ‰‹æ®µæ¥æå‡äººå·¥æ™ºèƒ½çš„é€æ˜åº¦ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.10124v1",
      "published_date": "2025-07-14 10:09:46 UTC",
      "updated_date": "2025-07-14 10:09:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:09.988463+00:00"
    },
    {
      "arxiv_id": "2507.10120v1",
      "title": "A Variance-Reduced Cubic-Regularized Newton for Policy Optimization",
      "title_zh": "é¢å‘ç­–ç•¥ä¼˜åŒ–çš„æ–¹å·®ç¼©å‡ä¸‰æ¬¡æ­£åˆ™åŒ–ç‰›é¡¿æ³•",
      "authors": [
        "Cheng Sun",
        "Zhen Zhang",
        "Shaofu Yang"
      ],
      "abstract": "In this paper, we study a second-order approach to policy optimization in reinforcement learning. Existing second-order methods often suffer from suboptimal sample complexity or rely on unrealistic assumptions about importance sampling. To overcome these limitations, we propose VR-CR-PN, a variance-reduced cubic-regularized policy Newton algorithm. To the best of our knowledge, this is the first algorithm that integrates Hessian-aided variance reduction with second-order policy optimization, effectively addressing the distribution shift problem and achieving best-known sample complexity under general nonconvex conditions but without the need for importance sampling. We theoretically establish that VR-CR-PN achieves a sample complexity of $\\tilde{\\mathcal{O}}(Îµ^{-3})$ to reach an $Îµ$-second-order stationary point, significantly improving upon the previous best result of $\\tilde{\\mathcal{O}}(Îµ^{-3.5})$ under comparable assumptions. As an additional contribution, we introduce a novel Hessian estimator for the expected return function, which admits a uniform upper bound independent of the horizon length $H$, allowing the algorithm to achieve horizon-independent sample complexity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸­äºŒé˜¶ç­–ç•¥ä¼˜åŒ–æ–¹æ³•å­˜åœ¨çš„æ ·æœ¬å¤æ‚åº¦(Sample Complexity)ä¸ä½³ä»¥åŠè¿‡åº¦ä¾èµ–é‡è¦æ€§é‡‡æ ·(Importance Sampling)å‡è®¾ç­‰é—®é¢˜ï¼Œæå‡ºäº†VR-CR-PNç®—æ³•ã€‚VR-CR-PNæ˜¯ä¸€ç§æ–¹å·®ç¼©å‡(Variance-Reduced)çš„ä¸‰æ¬¡æ­£åˆ™åŒ–ç‰›é¡¿(Cubic-Regularized Newton)ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œä¹Ÿæ˜¯é¦–ä¸ªå°†æµ·æ£®çŸ©é˜µè¾…åŠ©æ–¹å·®ç¼©å‡(Hessian-aided variance reduction)ä¸äºŒé˜¶ç­–ç•¥ä¼˜åŒ–ç›¸ç»“åˆçš„æ¡†æ¶ã€‚è¯¥ç®—æ³•åœ¨æ— éœ€é‡è¦æ€§é‡‡æ ·çš„å‰æä¸‹ï¼Œé€šè¿‡åˆ›æ–°çš„æœºåˆ¶æœ‰æ•ˆè§£å†³äº†åˆ†å¸ƒåç§»(Distribution Shift)é—®é¢˜ï¼Œå¹¶åœ¨ä¸€èˆ¬éå‡¸æ¡ä»¶ä¸‹å®ç°äº†å½“å‰æœ€ä¼˜çš„æ ·æœ¬å¤æ‚åº¦ã€‚ç†è®ºè¯æ˜è¡¨æ˜ï¼ŒVR-CR-PNè¾¾åˆ°$\\epsilon$-äºŒé˜¶é©»ç‚¹($\\epsilon$-second-order stationary point)æ‰€éœ€çš„æ ·æœ¬å¤æ‚åº¦ä¸º$\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ï¼Œç›¸æ¯”æ­¤å‰æœ€ä¼˜çš„$\\tilde{\\mathcal{O}}(\\epsilon^{-3.5})$æœ‰äº†æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§æ–°å‹çš„æµ·æ£®çŸ©é˜µä¼°è®¡å™¨ï¼Œå…¶ä¸Šç•Œä¸æ—¶é—´æ­¥é•¿ $H$ æ— å…³ï¼Œä»è€Œä½¿ç®—æ³•æˆåŠŸå®ç°äº†ä¸æ—¶é—´æ­¥é•¿æ— å…³(Horizon-Independent)çš„æ ·æœ¬å¤æ‚åº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2507.10120v1",
      "published_date": "2025-07-14 10:04:02 UTC",
      "updated_date": "2025-07-14 10:04:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:11.788228+00:00"
    },
    {
      "arxiv_id": "2507.10119v1",
      "title": "Analysis of AI Techniques for Orchestrating Edge-Cloud Application Migration",
      "title_zh": "è¾¹ç¼˜-äº‘åº”ç”¨è¿ç§»ç¼–æ’çš„äººå·¥æ™ºèƒ½æŠ€æœ¯åˆ†æ",
      "authors": [
        "Sadig Gojayev",
        "Ahmad Anaqreh",
        "Carolina Fortuna"
      ],
      "abstract": "Application migration in edge-cloud system enables high QoS and cost effective service delivery. However, automatically orchestrating such migration is typically solved with heuristic approaches. Starting from the Markov Decision Process (MDP), in this paper, we identify, analyze and compare selected state-of-the-art Artificial Intelligence (AI) planning and Reinforcement Learning (RL) approaches for solving the class of edge-cloud application migration problems that can be modeled as Towers of Hanoi (ToH) problems. We introduce a new classification based on state space definition and analyze the compared models also through this lense. The aim is to understand available techniques capable of orchestrating such application migration in emerging computing continuum environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è¾¹ç¼˜äº‘ï¼ˆedge-cloudï¼‰ç³»ç»Ÿä¸­çš„åº”ç”¨è¿ç§»ç¼–æ’é—®é¢˜ï¼Œæ—¨åœ¨å®ç°é«˜æœåŠ¡è´¨é‡ï¼ˆQoSï¼‰å’Œå…·æœ‰æˆæœ¬æ•ˆç›Šçš„æœåŠ¡äº¤ä»˜ã€‚æ–‡ç« ä»¥é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMarkov Decision Process, MDPï¼‰ä¸ºèµ·ç‚¹ï¼Œå°†è¾¹ç¼˜äº‘åº”ç”¨è¿ç§»é—®é¢˜å»ºæ¨¡ä¸ºæ±‰è¯ºå¡”ï¼ˆTowers of Hanoi, ToHï¼‰é—®é¢˜ï¼Œå¹¶åˆ†æäº†è¯¥ç±»é—®é¢˜çš„è§£å†³è·¯å¾„ã€‚ç ”ç©¶é‡ç‚¹è¯†åˆ«å¹¶å¯¹æ¯”äº†å½“å‰å…ˆè¿›çš„äººå·¥æ™ºèƒ½è§„åˆ’ï¼ˆAI planningï¼‰ä¸å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰æ–¹æ³•åœ¨å¤„ç†æ­¤ç±»è¿ç§»ä»»åŠ¡æ—¶çš„è¡¨ç°ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºçŠ¶æ€ç©ºé—´ï¼ˆstate spaceï¼‰å®šä¹‰çš„æ–°åˆ†ç±»æ–¹æ³•ï¼Œå¹¶ä»è¯¥è§†è§’å¯¹æ‰€é€‰æ¨¡å‹è¿›è¡Œäº†æ·±å…¥å‰–æã€‚è¯¥åˆ†ææ—¨åœ¨æ˜ç¡®åœ¨è®¡ç®—è¿ç»­ä½“ï¼ˆcomputing continuumï¼‰ç¯å¢ƒä¸‹å®ç°è‡ªåŠ¨åŒ–åº”ç”¨è¿ç§»ç¼–æ’çš„å¯è¡ŒæŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10119v1",
      "published_date": "2025-07-14 10:03:23 UTC",
      "updated_date": "2025-07-14 10:03:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:18.390942+00:00"
    },
    {
      "arxiv_id": "2507.11561v1",
      "title": "Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach",
      "title_zh": "é¢„æµ‹æ–°ç”Ÿå„¿è‚ºåŠ¨è„‰é«˜å‹ï¼šä¸€ç§å¤šè§†è§’ VAE æ–¹æ³•",
      "authors": [
        "Lucas Erlacher",
        "Samuel RuipÃ©rez-Campillo",
        "Holger Michel",
        "Sven Wellmann",
        "Thomas M. Sutter",
        "Ece Ozkan",
        "Julia E. Vogt"
      ],
      "abstract": "Pulmonary hypertension (PH) in newborns is a critical condition characterized by elevated pressure in the pulmonary arteries, leading to right ventricular strain and heart failure. While right heart catheterization (RHC) is the diagnostic gold standard, echocardiography is preferred due to its non-invasive nature, safety, and accessibility. However, its accuracy highly depends on the operator, making PH assessment subjective. While automated detection methods have been explored, most models focus on adults and rely on single-view echocardiographic frames, limiting their performance in diagnosing PH in newborns. While multi-view echocardiography has shown promise in improving PH assessment, existing models struggle with generalizability. In this work, we employ a multi-view variational autoencoder (VAE) for PH prediction using echocardiographic videos. By leveraging the VAE framework, our model captures complex latent representations, improving feature extraction and robustness. We compare its performance against single-view and supervised learning approaches. Our results show improved generalization and classification accuracy, highlighting the effectiveness of multi-view learning for robust PH assessment in newborns.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–°ç”Ÿå„¿è‚ºåŠ¨è„‰é«˜å‹ (Pulmonary hypertension, PH) è¯Šæ–­ä¸­è¶…å£°å¿ƒåŠ¨å›¾ (echocardiography) å­˜åœ¨çš„ä¸»è§‚æ€§åŠç°æœ‰æ¨¡å‹å±€é™äºå•è§†å›¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šè§†å›¾å˜åˆ†è‡ªç¼–ç å™¨ (Multi-view VAE) çš„é¢„æµ‹æ–¹æ³•ã€‚è¯¥æ¨¡å‹é€šè¿‡åˆ†æè¶…å£°å¿ƒåŠ¨å›¾è§†é¢‘ï¼Œåˆ©ç”¨ VAE æ¡†æ¶æ•æ‰å¤æ‚çš„æ½œåœ¨è¡¨ç¤º (latent representations)ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºäº†ç‰¹å¾æå–èƒ½åŠ›ä¸ç³»ç»Ÿçš„é²æ£’æ€§ã€‚ç ”ç©¶äººå‘˜å°†è¯¥æ–¹æ³•ä¸å•è§†å›¾ (single-view) åŠå¸¸è§„ç›‘ç£å­¦ä¹  (supervised learning) æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨åˆ†ç±»å‡†ç¡®ç‡å’Œæ³›åŒ–æ€§èƒ½ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å¤šè§†å›¾å­¦ä¹ åœ¨æ–°ç”Ÿå„¿ PH é²æ£’æ€§è¯„ä¼°ä¸­çš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶ä¸ºä¸´åºŠæä¾›äº†ä¸€ç§æ›´ç²¾ç¡®ã€è‡ªåŠ¨åŒ–çš„æ–°ç”Ÿå„¿è‚ºåŠ¨è„‰é«˜å‹è¾…åŠ©è¯Šæ–­æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.11561v1",
      "published_date": "2025-07-14 09:46:38 UTC",
      "updated_date": "2025-07-14 09:46:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:19.588177+00:00"
    },
    {
      "arxiv_id": "2507.10106v1",
      "title": "BlueGlass: A Framework for Composite AI Safety",
      "title_zh": "BlueGlassï¼šå¤åˆäººå·¥æ™ºèƒ½å®‰å…¨æ¡†æ¶",
      "authors": [
        "Harshal Nandigramwar",
        "Syed Qutub",
        "Kay-Ulrich Scholl"
      ],
      "abstract": "As AI systems become increasingly capable and ubiquitous, ensuring the safety of these systems is critical. However, existing safety tools often target different aspects of model safety and cannot provide full assurance in isolation, highlighting a need for integrated and composite methodologies. This paper introduces BlueGlass, a framework designed to facilitate composite AI safety workflows by providing a unified infrastructure enabling the integration and composition of diverse safety tools that operate across model internals and outputs. Furthermore, to demonstrate the utility of this framework, we present three safety-oriented analyses on vision-language models for the task of object detection: (1) distributional evaluation, revealing performance trade-offs and potential failure modes across distributions; (2) probe-based analysis of layer dynamics highlighting shared hierarchical learning via phase transition; and (3) sparse autoencoders identifying interpretable concepts. More broadly, this work contributes foundational infrastructure and findings for building more robust and reliable AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† BlueGlassï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä¿ƒè¿›å¤åˆå¼ AI å®‰å…¨å·¥ä½œæµçš„æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰å®‰å…¨å·¥å…·å› åŠŸèƒ½å•ä¸€è€Œæ— æ³•åœ¨å­¤ç«‹çŠ¶æ€ä¸‹æä¾›å…¨é¢ä¿éšœçš„é—®é¢˜ã€‚è¯¥æ¡†æ¶æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„åŸºç¡€è®¾æ–½ï¼Œæ”¯æŒæ— ç¼é›†æˆå¹¶ç»„åˆå¤šç§é’ˆå¯¹æ¨¡å‹å†…éƒ¨æœºåˆ¶(Model Internals)å’Œè¾“å‡º(Outputs)çš„å„ç±»å®‰å…¨å·¥å…·ã€‚ä¸ºäº†éªŒè¯å…¶æœ‰æ•ˆæ€§ï¼Œç ”ç©¶è€…é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models)çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡æ‰§è¡Œäº†ä¸‰é¡¹å®‰å…¨åˆ†æã€‚é¦–å…ˆé€šè¿‡åˆ†å¸ƒè¯„ä¼°(Distributional Evaluation)æ­ç¤ºäº†æ€§èƒ½æƒè¡¡ä¸æ½œåœ¨å¤±æ•ˆæ¨¡å¼ï¼Œéšååˆ©ç”¨åŸºäºæ¢é’ˆçš„å±‚åŠ¨åŠ›å­¦åˆ†æ(Probe-based Analysis of Layer Dynamics)å±•ç¤ºäº†é€šè¿‡ç›¸å˜(Phase Transition)å®ç°çš„å…±äº«åˆ†å±‚å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶ä½¿ç”¨ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨(Sparse Autoencoders)è¯†åˆ«å‡ºå¯è§£é‡Šçš„æ¦‚å¿µã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥å·¥ä½œä¸ºæ„å»ºæ›´ç¨³å¥ã€æ›´å¯é çš„ AI ç³»ç»Ÿæä¾›äº†å…³é”®çš„åŸºç¡€è®¾æ–½æ”¯æ’‘å’Œå®è¯å‘ç°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML 2025 [Actionable Interpretability Workshop]",
      "pdf_url": "https://arxiv.org/pdf/2507.10106v1",
      "published_date": "2025-07-14 09:45:34 UTC",
      "updated_date": "2025-07-14 09:45:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:25.588969+00:00"
    },
    {
      "arxiv_id": "2507.11560v1",
      "title": "A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing",
      "title_zh": "å·¥ä¸šç‰©è”ç½‘è¾¹ç¼˜è®¡ç®—ä¸­æ¨¡å‹æ„ŸçŸ¥çš„ AIGC ä»»åŠ¡å¸è½½ç®—æ³•",
      "authors": [
        "Xin Wang",
        "Xiao Huan Li",
        "Xun Wang"
      ],
      "abstract": "The integration of the Industrial Internet of Things (IIoT) with Artificial Intelligence-Generated Content (AIGC) offers new opportunities for smart manufacturing, but it also introduces challenges related to computation-intensive tasks and low-latency demands. Traditional generative models based on cloud computing are difficult to meet the real-time requirements of AIGC tasks in IIoT environments, and edge computing can effectively reduce latency through task offloading. However, the dynamic nature of AIGC tasks, model switching delays, and resource constraints impose higher demands on edge computing environments. To address these challenges, this paper proposes an AIGC task offloading framework tailored for IIoT edge computing environments, considering the latency and energy consumption caused by AIGC model switching for the first time. IIoT devices acted as multi-agent collaboratively offload their dynamic AIGC tasks to the most appropriate edge servers deployed with different generative models. A model aware AIGC task offloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient (MADDPG-MATO) is devised to minimize the latency and energy. Experimental results show that MADDPG-MATO outperforms baseline algorithms, achieving an average reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72% increase in task completion rate across four sets of experiments with model numbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is robust and efficient in dynamic, high-load IIoT environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šç‰©è”ç½‘(IIoT)ä¸ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(AIGC)ç»“åˆè¿‡ç¨‹ä¸­é¢ä¸´çš„è®¡ç®—å¯†é›†å’Œä½å»¶è¿ŸæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ä¸“ä¸ºè¾¹ç¼˜è®¡ç®—ç¯å¢ƒè®¾è®¡çš„AIGCä»»åŠ¡å¸è½½æ¡†æ¶ã€‚è¯¥ç ”ç©¶é¦–æ¬¡å°†AIGCæ¨¡å‹åˆ‡æ¢äº§ç”Ÿçš„å»¶è¿Ÿå’Œèƒ½è€—çº³å…¥è€ƒé‡ï¼Œåˆ©ç”¨å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶å°†åŠ¨æ€ä»»åŠ¡åˆ†å‘è‡³éƒ¨ç½²æœ‰ä¸åŒç”Ÿæˆæ¨¡å‹çš„è¾¹ç¼˜æœåŠ¡å™¨ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦(MADDPG-MATO)çš„æ¨¡å‹æ„ŸçŸ¥ä»»åŠ¡å¸è½½ç®—æ³•ï¼Œä»¥å®ç°å»¶è¿Ÿä¸èƒ½è€—çš„æœ€å°åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMADDPG-MATOåœ¨å¤šç§æ¨¡å‹è§„æ¨¡ä¸‹å‡ä¼˜äºåŸºå‡†ç®—æ³•ï¼Œå¹³å‡é™ä½äº†6.98%çš„å»¶è¿Ÿå’Œ7.12%çš„èƒ½è€—ï¼Œå¹¶ä½¿ä»»åŠ¡å®Œæˆç‡æå‡äº†3.72%ã€‚è¯¥æˆæœè¯æ˜äº†æ‰€æç®—æ³•åœ¨åŠ¨æ€ã€é«˜è´Ÿè½½çš„IIoTç¯å¢ƒä¸­çš„é²æ£’æ€§ä¸é«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "6 pages, 4 figures, accepted by ICCC 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.11560v1",
      "published_date": "2025-07-14 09:32:14 UTC",
      "updated_date": "2025-07-14 09:32:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:24.886821+00:00"
    },
    {
      "arxiv_id": "2507.10085v1",
      "title": "Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning",
      "title_zh": "é€šè¿‡å…³é”®è¡¨ç¤ºå¾®è°ƒæå‡æ€ç»´é“¾æ¨ç†èƒ½åŠ›",
      "authors": [
        "Chenxi Huang",
        "Shaotian Yan",
        "Liang Xie",
        "Binbin Lin",
        "Sinan Fan",
        "Yue Xin",
        "Deng Cai",
        "Chen Shen",
        "Jieping Ye"
      ],
      "abstract": "Representation Fine-tuning (ReFT), a recently proposed Parameter-Efficient Fine-Tuning (PEFT) method, has attracted widespread attention for significantly improving parameter efficiency by editing representation space alone. In this work, we investigate applying ReFT to complex reasoning tasks. However, directly using the native ReFT method, which modifies fixed representations at the beginning and end of each layer, yields suboptimal performance, as these fixed-position representations have uncertain impact on the outputs. We observe that, in complex reasoning tasks, there often exist certain critical representations. These representations either integrate significant information from preceding layers or regulate subsequent layer representations. Through layer-by-layer propagation, they exert a substantial influence on the final output. Naturally, fine-tuning these critical representations has the potential to greatly enhance reasoning performance. Building upon these insights, we propose Critical Representation Fine-Tuning (CRFT), a novel method that identifies and optimizes these critical representations through information flow analysis. CRFT operates within a supervised learning framework, dynamically optimizing critical representations in a low-rank linear subspace while freezing the base model. The effectiveness and efficiency of our method are validated across eight benchmarks for arithmetic and commonsense reasoning, using LLaMA and Mistral model families. Furthermore, our method also adapts effectively to few-shot settings, boosting one-shot accuracy by 16.4%. Our work highlights the untapped potential of representation-level optimization for CoT reasoning, offering a lightweight yet powerful alternative to traditional PEFT methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è¡¨å¾å¾®è°ƒæ–¹æ³• Representation Fine-tuning (ReFT) åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å› å›ºå®šä¿®æ”¹ä½ç½®è€Œå¯¼è‡´æ€§èƒ½å—é™çš„é—®é¢˜ï¼Œæå‡ºäº† Critical Representation Fine-Tuning (CRFT)ã€‚ä½œè€…é€šè¿‡è§‚å¯Ÿå‘ç°ï¼Œå¤æ‚æ¨ç†ä¸­å­˜åœ¨èƒ½å¤Ÿæ•´åˆæˆ–è°ƒèŠ‚å…³é”®ä¿¡æ¯çš„ Critical Representationsï¼Œè¿™äº›è¡¨å¾é€šè¿‡å±‚çº§ä¼ æ’­å¯¹æœ€ç»ˆè¾“å‡ºäº§ç”Ÿæ·±è¿œå½±å“ã€‚CRFT åˆ©ç”¨ä¿¡æ¯æµåˆ†æè¯†åˆ«è¿™äº›å…³é”®è¡¨å¾ï¼Œåœ¨ä¿æŒåŸºç¡€æ¨¡å‹å†»ç»“çš„çŠ¶æ€ä¸‹ï¼Œé€šè¿‡ä½ç§©çº¿æ€§å­ç©ºé—´å¯¹å…¶è¿›è¡ŒåŠ¨æ€ä¼˜åŒ–ã€‚åœ¨ LLaMA å’Œ Mistral ç³»åˆ—æ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCRFT åœ¨å…«ä¸ªç®—æœ¯å’Œå¸¸è¯†æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å‡å±•ç°äº†å“è¶Šçš„æœ‰æ•ˆæ€§ä¸æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ Few-shot è®¾ç½®ä¸‹è¡¨ç°çªå‡ºï¼ŒæˆåŠŸå°† One-shot å‡†ç¡®ç‡æå‡äº† 16.4%ã€‚è¿™é¡¹å·¥ä½œæ­ç¤ºäº†è¡¨å¾çº§ä¼˜åŒ–åœ¨å¢å¼ºæ€ç»´é“¾ Chain-of-Thought æ¨ç†æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºä¼ ç»Ÿçš„å‚æ•°é«˜æ•ˆå¾®è°ƒ PEFT æ–¹æ³•æä¾›äº†ä¸€ä¸ªè½»é‡çº§ä¸”é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10085v1",
      "published_date": "2025-07-14 09:11:33 UTC",
      "updated_date": "2025-07-14 09:11:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:38.783850+00:00"
    },
    {
      "arxiv_id": "2507.12482v4",
      "title": "Kodezi Chronos: A Debugging-First Language Model for Repository-Scale Code Understanding",
      "title_zh": "Kodezi Chronosï¼šé¢å‘ä»“åº“çº§ä»£ç ç†è§£çš„è°ƒè¯•ä¼˜å…ˆå‹è¯­è¨€æ¨¡å‹",
      "authors": [
        "Ishraq Khan",
        "Assad Chowdary",
        "Sharoz Haseeb",
        "Urvish Patel",
        "Yousuf Zaii"
      ],
      "abstract": "Large Language Models (LLMs) have advanced code generation and software automation but remain constrained by inference-time context and lack structured reasoning over code, leaving debugging largely unsolved. While Claude 4.5 Opus achieves 74.40% on SWE-bench Verified and Gemini 3 Pro reaches 76.2%, both models remain below 20% on real multi-file debugging tasks. We introduce Kodezi Chronos-1, a language model purpose-built for debugging that integrates Adaptive Graph-Guided Retrieval to navigate codebases up to 10 million lines (92% precision, 85% recall), Persistent Debug Memory trained on over 15 million sessions, and a seven-layer fix-test-refine architecture. On 5,000 real-world scenarios, Chronos-1 achieves 67.3% +/- 2.1% fix accuracy compared to 14.2% +/- 1.3% for Claude 4.1 Opus and 13.8% +/- 1.2% for GPT-4.1 (Cohen's d = 3.87). On SWE-bench Lite, Chronos-1 reaches a state-of-the-art 80.33% resolution rate (241 of 300), outperforming the next best system by 20 points and achieving repository-specific highs of 96.1% on Sympy and 90.4% on Django. Chronos-1 reduces debugging time by 40% and iterations by 65%, resolving complex multi-file and cross-repository bugs that require temporal analysis. Limitations remain for hardware-dependent and dynamic language errors, and Chronos-1 will be available in Kodezi OS in Q4 2025 and via API in Q1 2026.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Kodezi Chronos-1ï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºè°ƒè¯•è®¾è®¡çš„è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ Large Language Models (LLMs) åœ¨å¤„ç†ä»£ç ä»“åº“çº§å¤æ‚è°ƒè¯•ä»»åŠ¡æ—¶é¢ä¸´çš„æ¨ç†èƒ½åŠ›ä¸è¶³å’Œä¸Šä¸‹æ–‡é™åˆ¶é—®é¢˜ã€‚è¯¥æ¨¡å‹åˆ›æ–°æ€§åœ°é›†æˆäº†èƒ½å¤Ÿå¤„ç†åƒä¸‡è¡Œä»£ç çš„ Adaptive Graph-Guided Retrieval æŠ€æœ¯ï¼Œå¹¶ç»“åˆäº†åŸºäº 1500 ä¸‡æ¬¡ä¼šè¯è®­ç»ƒçš„ Persistent Debug Memory ä»¥åŠä¸ƒå±‚ fix-test-refine æ¶æ„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒChronos-1 åœ¨ 5000 ä¸ªçœŸå®è°ƒè¯•åœºæ™¯ä¸­çš„ä¿®å¤å‡†ç¡®ç‡è¾¾åˆ° 67.3%ï¼Œè¿œè¶… Claude 4.1 Opus å’Œ GPT-4.1 ç­‰é€šç”¨æ¨¡å‹ã€‚åœ¨ SWE-bench Lite åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹ä»¥ 80.33% çš„è§£å†³ç‡åˆ·æ–°äº† SOTA è®°å½•ï¼Œåœ¨ Sympy å’Œ Django ä»“åº“ä¸Šçš„è¡¨ç°å°¤ä¸ºçªå‡ºã€‚æ­¤å¤–ï¼ŒChronos-1 æ˜¾è‘—æå‡äº†å¼€å‘æ•ˆç‡ï¼Œä½¿è°ƒè¯•æ—¶é—´å‡å°‘äº† 40%ï¼Œè¿­ä»£æ¬¡æ•°é™ä½äº† 65%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚å¤šæ–‡ä»¶å’Œè·¨ä»“åº“ Bug æ–¹é¢çš„å“è¶Šèƒ½åŠ›ï¼Œä¸ºå¤§è§„æ¨¡ä»£ç ç†è§£ä¸è‡ªåŠ¨åŒ–ä¿®å¤æä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "24 figures, 43 tables, 2 algorithms. Extended technical report introducing Chronos-1, a debugging-specific language model. Information available at https://github.com/Kodezi/chronos",
      "pdf_url": "https://arxiv.org/pdf/2507.12482v4",
      "published_date": "2025-07-14 09:08:21 UTC",
      "updated_date": "2025-12-02 22:12:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:41:47.638967+00:00"
    },
    {
      "arxiv_id": "2507.10076v3",
      "title": "On Gradual Semantics for Assumption-Based Argumentation",
      "title_zh": "è®ºåŸºäºå‡è®¾è®ºè¯çš„æ¸è¿›è¯­ä¹‰",
      "authors": [
        "Anna Rapberger",
        "Fabrizio Russo",
        "Antonio Rago",
        "Francesca Toni"
      ],
      "abstract": "In computational argumentation, gradual semantics are fine-grained alternatives to extension-based and labelling-based semantics . They ascribe a dialectical strength to (components of) arguments sanctioning their degree of acceptability. Several gradual semantics have been studied for abstract, bipolar and quantitative bipolar argumentation frameworks (QBAFs), as well as, to a lesser extent, for some forms of structured argumentation. However, this has not been the case for assumption-based argumentation (ABA), despite it being a popular form of structured argumentation with several applications where gradual semantics could be useful. In this paper, we fill this gap and propose a family of novel gradual semantics for equipping assumptions, which are the core components in ABA frameworks, with dialectical strengths. To do so, we use bipolar set-based argumentation frameworks as an abstraction of (potentially non-flat) ABA frameworks and generalise state-of-the-art modular gradual semantics for QBAFs. We show that our gradual ABA semantics satisfy suitable adaptations of desirable properties of gradual QBAF semantics, such as balance and monotonicity. We also explore an argument-based approach that leverages established QBAF modular semantics directly, and use it as baseline. Finally, we conduct experiments with synthetic ABA frameworks to compare our gradual ABA semantics with its argument-based counterpart and assess convergence.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—è®ºè¯ä¸­çš„å‡è®¾é©±åŠ¨è®ºè¯(Assumption-Based Argumentation, ABA)æ¡†æ¶ï¼Œæå‡ºäº†ä¸€ç³»åˆ—æ–°å‹çš„æ¸è¿›è¯­ä¹‰(gradual semantics)ï¼Œæ—¨åœ¨ä¸ºæ¡†æ¶çš„æ ¸å¿ƒç»„ä»¶â€”â€”å‡è®¾(assumptions)èµ‹äºˆç²¾ç¡®çš„è¾©è¯å¼ºåº¦ã€‚ä¸ºäº†å¡«è¡¥ABAåœ¨ç»†ç²’åº¦è¯­ä¹‰ç ”ç©¶ä¸Šçš„ç©ºç™½ï¼Œä½œè€…é‡‡ç”¨åŒæé›†åˆè®ºè¯æ¡†æ¶ä½œä¸ºæŠ½è±¡å·¥å…·ï¼Œå°†å®šé‡åŒæè®ºè¯æ¡†æ¶(QBAFs)ä¸­å…ˆè¿›çš„æ¨¡å—åŒ–æ¸è¿›è¯­ä¹‰æ¨å¹¿åˆ°äº†å¯èƒ½éå¹³å¦(non-flat)çš„ABAç»“æ„ä¸­ã€‚ç ”ç©¶è¯æ˜ï¼Œæ‰€æè¯­ä¹‰æ»¡è¶³å¹³è¡¡æ€§(balance)å’Œå•è°ƒæ€§(monotonicity)ç­‰ä¸€ç³»åˆ—ç†æƒ³çš„ç†è®ºæ€§è´¨ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨åˆæˆABAæ¡†æ¶ä¸Šè¿›è¡Œå®éªŒï¼Œè¯¥ç ”ç©¶å¯¹æ¯”äº†æ–°è¯­ä¹‰ä¸ä¼ ç»ŸåŸºäºè®ºè¯çš„åŸºå‡†æ–¹æ³•åœ¨æ€§èƒ½ä¸æ”¶æ•›æ€§ä¸Šçš„å·®å¼‚ã€‚è¿™ä¸€æˆæœä¸ä»…ä¸°å¯Œäº†ABAçš„ç†è®ºä½“ç³»ï¼Œä¹Ÿä¸ºéœ€è¦ç»†ç²’åº¦å¯æ¥å—åº¦è¯„ä¼°çš„è®ºè¯åº”ç”¨åœºæ™¯æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to KR2025 - With Appendix",
      "pdf_url": "https://arxiv.org/pdf/2507.10076v3",
      "published_date": "2025-07-14 09:02:45 UTC",
      "updated_date": "2025-07-31 21:40:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:00.432071+00:00"
    },
    {
      "arxiv_id": "2507.10075v1",
      "title": "TGLD: A Trust-Aware Game-Theoretic Lane-Changing Decision Framework for Automated Vehicles in Heterogeneous Traffic",
      "title_zh": "TGLDï¼šå¼‚æ„äº¤é€šç¯å¢ƒä¸‹è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„ä¿¡ä»»æ„ŸçŸ¥åšå¼ˆæ¢é“å†³ç­–æ¡†æ¶",
      "authors": [
        "Jie Pan",
        "Tianyi Wang",
        "Yangyang Wang",
        "Junfeng Jiao",
        "Christian Claudel"
      ],
      "abstract": "Automated vehicles (AVs) face a critical need to adopt socially compatible behaviors and cooperate effectively with human-driven vehicles (HVs) in heterogeneous traffic environment. However, most existing lane-changing frameworks overlook HVs' dynamic trust levels, limiting their ability to accurately predict human driver behaviors. To address this gap, this study proposes a trust-aware game-theoretic lane-changing decision (TGLD) framework. First, we formulate a multi-vehicle coalition game, incorporating fully cooperative interactions among AVs and partially cooperative behaviors from HVs informed by real-time trust evaluations. Second, we develop an online trust evaluation method to dynamically estimate HVs' trust levels during lane-changing interactions, guiding AVs to select context-appropriate cooperative maneuvers. Lastly, social compatibility objectives are considered by minimizing disruption to surrounding vehicles and enhancing the predictability of AV behaviors, thereby ensuring human-friendly and context-adaptive lane-changing strategies. A human-in-the-loop experiment conducted in a highway on-ramp merging scenario validates our TGLD approach. Results show that AVs can effectively adjust strategies according to different HVs' trust levels and driving styles. Moreover, incorporating a trust mechanism significantly improves lane-changing efficiency, maintains safety, and contributes to transparent and adaptive AV-HV interactions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è½¦è¾†(AVs)åœ¨å¼‚æ„äº¤é€šæµä¸­ä¸äººç±»é©¾é©¶è½¦è¾†(HVs)äº¤äº’æ—¶å­˜åœ¨çš„ä¿¡ä»»åº¦è¯„ä¼°ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºTGLDçš„ä¿¡ä»»æ„ŸçŸ¥åšå¼ˆè®ºæ¢é“å†³ç­–æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªå¤šè½¦è”ç›Ÿåšå¼ˆæ¨¡å‹ï¼Œä½¿AVsä¹‹é—´ä¿æŒå®Œå…¨åˆä½œï¼Œå¹¶æ ¹æ®å®æ—¶ä¿¡ä»»è¯„ä¼°ä¸HVsè¿›è¡Œéƒ¨åˆ†åˆä½œã€‚ç ”ç©¶å¼€å‘äº†ä¸€ç§åœ¨çº¿ä¿¡ä»»è¯„ä¼°æ–¹æ³•ï¼Œèƒ½åœ¨æ¢é“è¿‡ç¨‹ä¸­åŠ¨æ€ä¼°è®¡HVsçš„ä¿¡ä»»æ°´å¹³ï¼Œè¿›è€Œå¼•å¯¼AVsé€‰æ‹©åˆé€‚çš„åˆä½œç­–ç•¥ã€‚é€šè¿‡å¼•å…¥ç¤¾ä¼šç›¸å®¹æ€§ç›®æ ‡ï¼Œè¯¥æ¡†æ¶æœ€å°åŒ–äº†å¯¹å‘¨è¾¹è½¦è¾†çš„å¹²æ‰°å¹¶å¢å¼ºäº†è¡Œä¸ºå¯é¢„æµ‹æ€§ã€‚åœ¨é«˜é€Ÿå…¬è·¯åŒé“æ±‡å…¥åœºæ™¯ä¸‹çš„â€œäººåœ¨ç¯ä¸­â€(Human-in-the-loop)å®éªŒè¯æ˜ï¼ŒTGLDèƒ½æ ¹æ®HVsçš„ä¸åŒä¿¡ä»»ç­‰çº§å’Œé©¾é©¶é£æ ¼çµæ´»è°ƒæ•´ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æœºåˆ¶æ˜¾è‘—æå‡äº†æ¢é“æ•ˆç‡ä¸å®‰å…¨æ€§ï¼Œä¸ºAV-HVäº¤äº’æä¾›äº†é€æ˜ä¸”è‡ªé€‚åº”çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 7 figures, accepted for IEEE International Conference on Intelligent Transportation Systems (ITSC) 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10075v1",
      "published_date": "2025-07-14 09:01:00 UTC",
      "updated_date": "2025-07-14 09:01:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:02.720422+00:00"
    },
    {
      "arxiv_id": "2507.10073v2",
      "title": "Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡åŒ–åè§ï¼šåŸºäºé“å¾·é—®å·çš„ AI æ™ºèƒ½ä½“è¯„ä¼°",
      "authors": [
        "Simon MÃ¼nker"
      ],
      "abstract": "Are AI systems truly representing human values, or merely averaging across them? Our study suggests a concerning reality: Large Language Models (LLMs) fail to represent diverse cultural moral frameworks despite their linguistic capabilities. We expose significant gaps between AI-generated and human moral intuitions by applying the Moral Foundations Questionnaire across 19 cultural contexts. Comparing multiple state-of-the-art LLMs' origins against human baseline data, we find these models systematically homogenize moral diversity. Surprisingly, increased model size doesn't consistently improve cultural representation fidelity. Our findings challenge the growing use of LLMs as synthetic populations in social science research and highlight a fundamental limitation in current AI alignment approaches. Without data-driven alignment beyond prompting, these systems cannot capture the nuanced, culturally-specific moral intuitions. Our results call for more grounded alignment objectives and evaluation metrics to ensure AI systems represent diverse human values rather than flattening the moral landscape.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)æ˜¯å¦èƒ½ä»£è¡¨çœŸå®çš„äººç±»ä»·å€¼è§‚ï¼Œè¿˜æ˜¯ä»…åœ¨ä»·å€¼è§‚é—´è¿›è¡Œç®€å•å¹³å‡ã€‚ç ”ç©¶è€…é€šè¿‡åœ¨19ä¸ªæ–‡åŒ–èƒŒæ™¯ä¸‹åº”ç”¨é“å¾·åŸºç¡€é—®å·(Moral Foundations Questionnaire)ï¼Œå¯¹æ¯”äº†å¤šç§å°–ç«¯LLMsä¸äººç±»åŸºå‡†æ•°æ®ï¼Œå‘ç°è¿™äº›æ¨¡å‹ç³»ç»Ÿæ€§åœ°åŒè´¨åŒ–äº†é“å¾·å¤šæ ·æ€§ï¼Œæœªèƒ½çœŸå®åæ˜ å¤šå…ƒæ–‡åŒ–çš„é“å¾·æ¡†æ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹è§„æ¨¡çš„å¢åŠ å¹¶ä¸èƒ½æŒç»­æé«˜æ–‡åŒ–ä»£è¡¨æ€§çš„ä¿çœŸåº¦ï¼Œè¿™æŒ‘æˆ˜äº†å°†LLMsä½œä¸ºåˆæˆæ ·æœ¬(synthetic populations)ç”¨äºç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„å¯é æ€§ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†å½“å‰ä»…ä¾èµ–æç¤ºè¯(prompting)çš„å¯¹é½(alignment)æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶å‘¼ååˆ¶å®šæ›´å…·é’ˆå¯¹æ€§çš„å¯¹é½ç›®æ ‡å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œä»¥ç¡®ä¿AIç³»ç»Ÿèƒ½å¤Ÿä½“ç°äººç±»ç»†å¾®ä¸”ç‰¹å®šçš„é“å¾·ç›´è§‰ï¼Œè€ŒéæŠ¹å¹³æ–‡åŒ–æ™¯è§‚ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15pages, 1 figure, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.10073v2",
      "published_date": "2025-07-14 08:59:26 UTC",
      "updated_date": "2025-07-31 03:13:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:10.421182+00:00"
    },
    {
      "arxiv_id": "2507.10057v2",
      "title": "Chain of Retrieval: Multi-Aspect Iterative Search Expansion and Post-Order Search Aggregation for Full Paper Retrieval",
      "title_zh": "Chain of Retrievalï¼šé¢å‘å…¨æ–‡æ£€ç´¢çš„å¤šç»´è¿­ä»£æœç´¢æ‰©å±•ä¸ååºæœç´¢èšåˆ",
      "authors": [
        "Sangwoo Park",
        "Jinheon Baek",
        "Soyeong Jeong",
        "Sung Ju Hwang"
      ],
      "abstract": "Scientific paper retrieval, particularly framed as document-to-document retrieval, aims to identify relevant papers in response to a long-form query paper, rather than a short query string. Previous approaches to this task have focused exclusively on abstracts, embedding them into dense vectors as surrogates for full documents and calculating similarity between them. Yet, abstracts offer only sparse and high-level summaries, and such methods primarily optimize one-to-one similarity, overlooking the dynamic relations that emerge among relevant papers during the retrieval process. To address this, we propose Chain of Retrieval(COR), a novel iterative framework for full-paper retrieval. Specifically, CoR decomposes each query paper into multiple aspect-specific views, matches them against segmented candidate papers, and iteratively expands the search by promoting top-ranked results as new queries, thereby forming a tree-structured retrieval process. The resulting retrieval tree is then aggregated in a post-order manner: descendants are first combined at the query level, then recursively merged with their parent nodes, to capture hierarchical relations across iterations. To validate this, we present SCIFULLBENCH, a large-scale benchmark providing both complete and segmented contexts of full papers for queries and candidates, and results show that CoR significantly outperforms existing retrieval baselines. Our code and dataset is available at https://github.com/psw0021/Chain-of-Retrieval.git.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Chain of Retrieval (CoR)ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å…¨ç¯‡ç§‘å­¦è®ºæ–‡æ£€ç´¢çš„è¿­ä»£æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»¥å¾€æ–¹æ³•ä»…å…³æ³¨æ‘˜è¦(abstracts)è€Œå¿½ç•¥å…¨æ–‡ç»†èŠ‚åŠè®ºæ–‡é—´åŠ¨æ€å…³ç³»çš„é—®é¢˜ã€‚CoRé€šè¿‡å°†æŸ¥è¯¢è®ºæ–‡åˆ†è§£ä¸ºå¤šç»´åº¦çš„è§†å›¾(multi-aspect views)ï¼Œå¹¶ä¸åˆ†æ®µçš„å€™é€‰è®ºæ–‡è¿›è¡ŒåŒ¹é…ï¼Œåˆ©ç”¨è¿­ä»£æœç´¢æ‰©å±•æ„å»ºå‡ºæ ‘çŠ¶æ£€ç´¢è¿‡ç¨‹ã€‚æ£€ç´¢æ ‘é‡‡ç”¨ååºèšåˆ(post-order aggregation)æ–¹å¼ï¼Œé€’å½’åœ°æ•´åˆå­èŠ‚ç‚¹ä¸çˆ¶èŠ‚ç‚¹çš„ä¿¡æ¯ï¼Œä»è€Œæœ‰æ•ˆæ•è·è·¨è¿­ä»£çš„å±‚æ¬¡åŒ–å…³ç³»ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æ¨å‡ºäº†å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•é›†SCIFULLBENCHï¼Œæä¾›äº†å…¨æ–‡çš„å®Œæ•´ä¸åˆ†æ®µä¸Šä¸‹æ–‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoRåœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ£€ç´¢åŸºçº¿æ¨¡å‹ï¼Œä¸ºå¤æ‚çš„â€œæ–‡æ¡£å¯¹æ–‡æ¡£â€(document-to-document)æ£€ç´¢ä»»åŠ¡æä¾›äº†æ›´ä¸ºé«˜æ•ˆå’Œç²¾å‡†çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10057v2",
      "published_date": "2025-07-14 08:41:53 UTC",
      "updated_date": "2025-11-01 07:56:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:14.985447+00:00"
    },
    {
      "arxiv_id": "2507.10632v1",
      "title": "Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process",
      "title_zh": "åŸºäºéšæœºå‚…é‡Œå¶ç‰¹å¾é«˜æ–¯è¿‡ç¨‹çš„å¯æ‰©å±•æ— ç›‘ç£åˆ†å‰²",
      "authors": [
        "Issei Saito",
        "Masatoshi Nagano",
        "Tomoaki Nakamura",
        "Daichi Mochihashi",
        "Koki Mimura"
      ],
      "abstract": "In this paper, we propose RFF-GP-HSMM, a fast unsupervised time-series segmentation method that incorporates random Fourier features (RFF) to address the high computational cost of the Gaussian process hidden semi-Markov model (GP-HSMM). GP-HSMM models time-series data using Gaussian processes, requiring inversion of an N times N kernel matrix during training, where N is the number of data points. As the scale of the data increases, matrix inversion incurs a significant computational cost. To address this, the proposed method approximates the Gaussian process with linear regression using RFF, preserving expressive power while eliminating the need for inversion of the kernel matrix. Experiments on the Carnegie Mellon University (CMU) motion-capture dataset demonstrate that the proposed method achieves segmentation performance comparable to that of conventional methods, with approximately 278 times faster segmentation on time-series data comprising 39,200 frames.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RFF-GP-HSMMï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³é«˜æ–¯è¿‡ç¨‹éšåŠé©¬å°”å¯å¤«æ¨¡å‹(GP-HSMM)è®¡ç®—æˆæœ¬é«˜æ˜‚é—®é¢˜çš„å¿«é€Ÿæ— ç›‘ç£æ—¶é—´åºåˆ—åˆ†å‰²æ–¹æ³•ã€‚ä¼ ç»ŸGP-HSMMåœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶ï¼Œéœ€è¦è¿›è¡Œå¤æ‚çš„Né˜¶å†…æ ¸çŸ©é˜µæ±‚é€†è¿ç®—ï¼Œå¯¼è‡´è®¡ç®—æ•ˆç‡éšæ•°æ®è§„æ¨¡å¢åŠ è€Œæ˜¾è‘—ä¸‹é™ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç“¶é¢ˆï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†éšæœºå‚…é‡Œå¶ç‰¹å¾(Random Fourier Features, RFF)ï¼Œé€šè¿‡çº¿æ€§å›å½’æ¥è¿‘ä¼¼é«˜æ–¯è¿‡ç¨‹ï¼Œä»è€Œåœ¨ä¿ç•™æ¨¡å‹è¡¨è¾¾èƒ½åŠ›çš„åŒæ—¶æ¶ˆé™¤äº†çŸ©é˜µæ±‚é€†çš„å¿…è¦ã€‚åœ¨å¡å†…åŸºæ¢…éš†å¤§å­¦(CMU)åŠ¨ä½œæ•æ‰æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†æ‹¥æœ‰39,200å¸§çš„æ•°æ®æ—¶ï¼Œåˆ†å‰²é€Ÿåº¦æ¯”ä¼ ç»Ÿæ–¹æ³•å¿«çº¦278å€ã€‚å®éªŒè¯æ˜RFF-GP-HSMMåœ¨ä¿æŒä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“çš„åˆ†å‰²æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†å¤„ç†å¤§è§„æ¨¡æ—¶é—´åºåˆ—æ•°æ®çš„å¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10632v1",
      "published_date": "2025-07-14 08:41:03 UTC",
      "updated_date": "2025-07-14 08:41:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:14.383429+00:00"
    },
    {
      "arxiv_id": "2507.10056v1",
      "title": "Lightweight Model for Poultry Disease Detection from Fecal Images Using Multi-Color Space Feature Optimization and Machine Learning",
      "title_zh": "åŸºäºå¤šè‰²å½©ç©ºé—´ç‰¹å¾ä¼˜åŒ–ä¸æœºå™¨å­¦ä¹ çš„è½»é‡åŒ–ç¦½ç±»ç²ªä¾¿å›¾åƒç–¾ç—…æ£€æµ‹æ¨¡å‹",
      "authors": [
        "A. K. M. Shoriful Islam",
        "Md. Rakib Hassan",
        "Macbah Uddin",
        "Md. Shahidur Rahman"
      ],
      "abstract": "Poultry farming is a vital component of the global food supply chain, yet it remains highly vulnerable to infectious diseases such as coccidiosis, salmonellosis, and Newcastle disease. This study proposes a lightweight machine learning-based approach to detect these diseases by analyzing poultry fecal images. We utilize multi-color space feature extraction (RGB, HSV, LAB) and explore a wide range of color, texture, and shape-based descriptors, including color histograms, local binary patterns (LBP), wavelet transforms, and edge detectors. Through a systematic ablation study and dimensionality reduction using PCA and XGBoost feature selection, we identify a compact global feature set that balances accuracy and computational efficiency. An artificial neural network (ANN) classifier trained on these features achieved 95.85% accuracy while requiring no GPU and only 638 seconds of execution time in Google Colab. Compared to deep learning models such as Xception and MobileNetV3, our proposed model offers comparable accuracy with drastically lower resource usage. This work demonstrates a cost-effective, interpretable, and scalable alternative to deep learning for real-time poultry disease detection in low-resource agricultural settings.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºé€šè¿‡å®¶ç¦½ç²ªä¾¿å›¾åƒæ£€æµ‹çƒè™«ç—…(coccidiosis)ã€æ²™é—¨æ°èŒç—…(salmonellosis)å’Œæ–°åŸç–«(Newcastle disease)ç­‰å…³é”®ä¼ æŸ“ç—…ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤šè‰²å½©ç©ºé—´ï¼ˆRGB, HSV, LABï¼‰ç‰¹å¾æå–ï¼Œç»“åˆé¢œè‰²ç›´æ–¹å›¾ã€å±€éƒ¨äºŒå€¼æ¨¡å¼(LBP)ã€å°æ³¢å˜æ¢(wavelet transforms)å’Œè¾¹ç¼˜æ£€æµ‹å™¨ï¼Œæå–äº†ä¸°å¯Œçš„é¢œè‰²ã€çº¹ç†å’Œå½¢çŠ¶æè¿°ç¬¦ã€‚ç ”ç©¶é€šè¿‡æ¶ˆèå®éªŒå¹¶åˆ©ç”¨PCAå’ŒXGBoostç‰¹å¾é€‰æ‹©è¿›è¡Œé™ç»´ï¼Œç¡®å®šäº†ä¸€ç»„åœ¨å‡†ç¡®ç‡å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡çš„ç´§å‡‘å…¨å±€ç‰¹å¾é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨äººå·¥ç¥ç»ç½‘ç»œ(ANN)åˆ†ç±»å™¨å®ç°äº†95.85%çš„å‡†ç¡®ç‡ï¼Œä¸”æ— éœ€GPUæ”¯æŒï¼Œåœ¨Google Colabä¸­çš„æ‰§è¡Œæ—¶é—´ä»…ä¸º638ç§’ã€‚ä¸Xceptionå’ŒMobileNetV3ç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹åœ¨æ˜¾è‘—é™ä½èµ„æºæ¶ˆè€—çš„åŒæ—¶ä¿æŒäº†ç›¸å½“çš„æ£€æµ‹ç²¾åº¦ã€‚è¯¥å·¥ä½œä¸ºèµ„æºå—é™çš„å†œä¸šç¯å¢ƒæä¾›äº†ä¸€ç§é«˜æ€§ä»·æ¯”ã€å¯è§£é‡Šä¸”å¯æ‰©å±•çš„å®æ—¶å®¶ç¦½ç–¾ç—…æ£€æµ‹æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10056v1",
      "published_date": "2025-07-14 08:40:46 UTC",
      "updated_date": "2025-07-14 08:40:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:15.787291+00:00"
    },
    {
      "arxiv_id": "2507.11558v1",
      "title": "Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting",
      "title_zh": "é¢å‘æ—¶ç©ºé¢„æµ‹çš„è§†è§‰åŸºç¡€æ¨¡å‹é‡ç¼–ç¨‹",
      "authors": [
        "Changlu Chen",
        "Yanbin Liu",
        "Chaoxi Niu",
        "Ling Chen",
        "Tianqing Zhu"
      ],
      "abstract": "Foundation models have achieved remarkable success in natural language processing and computer vision, demonstrating strong capabilities in modeling complex patterns. While recent efforts have explored adapting large language models (LLMs) for time-series forecasting, LLMs primarily capture one-dimensional sequential dependencies and struggle to model the richer spatio-temporal (ST) correlations essential for accurate ST forecasting. In this paper, we present \\textbf{ST-VFM}, a novel framework that systematically reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal forecasting. While VFMs offer powerful spatial priors, two key challenges arise when applying them to ST tasks: (1) the lack of inherent temporal modeling capacity and (2) the modality gap between visual and ST data. To address these, ST-VFM adopts a \\emph{dual-branch architecture} that integrates raw ST inputs with auxiliary ST flow inputs, where the flow encodes lightweight temporal difference signals interpretable as dynamic spatial cues. To effectively process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming stages. The \\emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token Adapter to embed temporal context and align both branches into VFM-compatible feature spaces. The \\emph{post-VFM reprogramming} stage introduces a Bilateral Cross-Prompt Coordination module, enabling dynamic interaction between branches through prompt-based conditioning, thus enriching joint representation learning without modifying the frozen VFM backbone. Extensive experiments on ten spatio-temporal datasets show that ST-VFM outperforms state-of-the-art baselines, demonstrating effectiveness and robustness across VFM backbones (e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong general framework for spatio-temporal forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ST-VFMï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å°†è§†è§‰åŸºç¡€æ¨¡å‹(VFMs)é‡æ–°ç¼–ç¨‹ä»¥ç”¨äºé€šç”¨æ—¶ç©ºé¢„æµ‹(Spatio-Temporal Forecasting)çš„æ–°å‹æ¡†æ¶ã€‚é’ˆå¯¹VFMsç¼ºä¹å›ºæœ‰æ—¶é—´å»ºæ¨¡èƒ½åŠ›ä»¥åŠè§†è§‰ä¸æ—¶ç©ºæ•°æ®ä¹‹é—´å­˜åœ¨æ¨¡æ€å·®å¼‚çš„æŒ‘æˆ˜ï¼ŒST-VFMé‡‡ç”¨äº†é›†æˆåŸå§‹æ—¶ç©ºè¾“å…¥ä¸è¾…åŠ©æ—¶ç©ºæµ(ST flow)è¾“å…¥çš„åŒæ”¯è·¯æ¶æ„(dual-branch architecture)ã€‚åœ¨æ¨¡å‹å¤„ç†è¿‡ç¨‹ä¸­ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†VFMå‰é‡æ–°ç¼–ç¨‹é˜¶æ®µï¼Œåˆ©ç”¨æ—¶é—´æ„ŸçŸ¥ä»¤ç‰Œé€‚é…å™¨(Temporal-Aware Token Adapter)åµŒå…¥æ—¶é—´ä¸Šä¸‹æ–‡ï¼Œä»¥åŠVFMåé‡æ–°ç¼–ç¨‹é˜¶æ®µï¼Œé€šè¿‡åŒè¾¹è·¨æç¤ºåè°ƒ(Bilateral Cross-Prompt Coordination)æ¨¡å—åœ¨ä¸æ”¹å˜å†»ç»“éª¨å¹²ç½‘ç»œçš„æƒ…å†µä¸‹å®ç°æ”¯è·¯é—´çš„åŠ¨æ€äº¤äº’ã€‚åœ¨åä¸ªæ—¶ç©ºæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒST-VFMåœ¨DINOã€CLIPå’ŒDEITç­‰å¤šç§VFMä¸»å¹²ç½‘ç»œä¸Šå‡ä¼˜äºç°æœ‰çš„åŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ä»…è¯æ˜äº†é€šè¿‡é‡æ–°ç¼–ç¨‹VFMsæ•æ‰å¤æ‚æ—¶ç©ºç›¸å…³æ€§çš„æœ‰æ•ˆæ€§ï¼Œä¹Ÿä¸ºè¯¥é¢†åŸŸæä¾›äº†ä¸€ä¸ªå…·æœ‰å¼ºé²æ£’æ€§çš„é€šç”¨é¢„æµ‹æ¡†æ¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.11558v1",
      "published_date": "2025-07-14 08:33:34 UTC",
      "updated_date": "2025-07-14 08:33:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:18.278301+00:00"
    },
    {
      "arxiv_id": "2507.10045v1",
      "title": "Automating SPARQL Query Translations between DBpedia and Wikidata",
      "title_zh": "DBpedia ä¸ Wikidata ä¹‹é—´çš„ SPARQL æŸ¥è¯¢è‡ªåŠ¨ç¿»è¯‘",
      "authors": [
        "Malte Christian Bartels",
        "Debayan Banerjee",
        "Ricardo Usbeck"
      ],
      "abstract": "This paper investigates whether state-of-the-art Large Language Models (LLMs) can automatically translate SPARQL between popular Knowledge Graph (KG) schemas. We focus on translations between the DBpedia and Wikidata KG, and later on DBLP and OpenAlex KG. This study addresses a notable gap in KG interoperability research by rigorously evaluating LLM performance on SPARQL-to-SPARQL translation. Two benchmarks are assembled, where the first align 100 DBpedia-Wikidata queries from QALD-9-Plus; the second contains 100 DBLP queries aligned to OpenAlex, testing generalizability beyond encyclopaedic KGs. Three open LLMs: Llama-3-8B, DeepSeek-R1-Distill-Llama-70B, and Mistral-Large-Instruct-2407 are selected based on their sizes and architectures and tested with zero-shot, few-shot, and two chain-of-thought variants. Outputs were compared with gold answers, and resulting errors were categorized. We find that the performance varies markedly across models and prompting strategies, and that translations for Wikidata to DBpedia work far better than translations for DBpedia to Wikidata.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…ˆè¿›çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸åŒçŸ¥è¯†å›¾è°±(Knowledge Graph)æ¨¡å¼ä¹‹é—´è‡ªåŠ¨è½¬æ¢SPARQLæŸ¥è¯¢çš„èƒ½åŠ›ï¼Œé‡ç‚¹é’ˆå¯¹DBpediaä¸Wikidataä»¥åŠDBLPä¸OpenAlexä¹‹é—´çš„ç¿»è¯‘ä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ã€‚ç ”ç©¶é€šè¿‡æ„å»ºåŒ…å«QALD-9-Pluså¯¹é½æŸ¥è¯¢åœ¨å†…çš„ä¸¤ä¸ªåŸºå‡†æµ‹è¯•é›†ï¼Œè¯„ä¼°äº†Llama-3-8Bã€DeepSeek-R1-Distill-Llama-70Bå’ŒMistral-Large-Instruct-2407åœ¨é›¶æ ·æœ¬(zero-shot)ã€å°‘æ ·æœ¬(few-shot)åŠé“¾å¼æ€ç»´(Chain-of-Thought)æç¤ºç­–ç•¥ä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç¿»è¯‘æ€§èƒ½åœ¨ä¸åŒæ¨¡å‹å’Œæç¤ºç­–ç•¥é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œä¸”ä»Wikidataå‘DBpediaçš„ç¿»è¯‘å‡†ç¡®ç‡æ˜æ˜¾é«˜äºä»DBpediaå‘Wikidataçš„è½¬æ¢ã€‚è¯¥ç ”ç©¶å¡«è¡¥äº†çŸ¥è¯†å›¾è°±äº’æ“ä½œæ€§é¢†åŸŸçš„ç©ºç™½ï¼Œå¹¶é€šè¿‡å¯¹é”™è¯¯ç±»å‹çš„ç³»ç»Ÿåˆ†ç±»ï¼Œä¸ºæœªæ¥çš„è‡ªåŠ¨åŒ–æŸ¥è¯¢ç¿»è¯‘ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 2 figues. Paper accepted at SEMANTiCS 2025 conference happening on September 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.10045v1",
      "published_date": "2025-07-14 08:23:25 UTC",
      "updated_date": "2025-07-14 08:23:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:24.225112+00:00"
    },
    {
      "arxiv_id": "2507.10630v1",
      "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs",
      "title_zh": "å€ŸåŠ©çŸ¥è¯†å›¾è°±å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„ API è°ƒç”¨èƒ½åŠ›",
      "authors": [
        "Ye Yang",
        "Xue Xiao",
        "Ping Yin",
        "Taotao Xie"
      ],
      "abstract": "API calls by large language models (LLMs) offer a cutting-edge approach for data analysis. However, their ability to effectively utilize tools via API calls remains underexplored in knowledge-intensive domains like meteorology. This paper introduces KG2data, a system that integrates knowledge graphs, LLMs, ReAct agents, and tool-use technologies to enable intelligent data acquisition and query handling in the meteorological field. Using a virtual API, we evaluate API call accuracy across three metrics: name recognition failure, hallucination failure, and call correctness. KG2data achieves superior performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based systems by addressing their limited access to domain-specific knowledge, which hampers performance on complex or terminology-rich queries. By using a knowledge graph as persistent memory, our system enhances content retrieval, complex query handling, domain-specific reasoning, semantic relationship resolution, and heterogeneous data integration. It also mitigates the high cost of fine-tuning LLMs, making the system more adaptable to evolving domain knowledge and API structures. In summary, KG2data provides a novel solution for intelligent, knowledge-based question answering and data analysis in domains with high knowledge demands.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†KG2dataç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆKnowledge Graphsã€LLMsã€ReAct agentså’Œå·¥å…·ä½¿ç”¨æŠ€æœ¯ï¼Œå¢å¼ºå¤§è¯­è¨€æ¨¡å‹åœ¨æ°”è±¡ç­‰çŸ¥è¯†å¯†é›†å‹é¢†åŸŸä¸­æ‰§è¡ŒAPI callsçš„èƒ½åŠ›ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨Knowledge Graphsä½œä¸ºæŒä¹…åŒ–å­˜å‚¨ï¼Œæœ‰æ•ˆæå‡äº†å†…å®¹æ£€ç´¢ã€å¤æ‚æŸ¥è¯¢å¤„ç†ã€é¢†åŸŸç‰¹å®šæ¨ç†å’Œå¼‚æ„æ•°æ®é›†æˆç­‰æ–¹é¢çš„æ€§èƒ½ï¼ŒåŒæ—¶é™ä½äº†å¾®è°ƒ(fine-tuning)LLMsçš„é«˜æ˜‚æˆæœ¬ã€‚é€šè¿‡åœ¨è™šæ‹ŸAPIä¸Šçš„è¯„ä¼°ï¼ŒKG2dataåœ¨è°ƒç”¨å‡†ç¡®ç‡ã€å¹»è§‰ç¼“è§£å’Œåç§°è¯†åˆ«ç­‰æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå…¶è°ƒç”¨æ­£ç¡®ç‡è¾¾åˆ°88.57%ï¼Œæ˜¾è‘—è¶…è¶Šäº†RAG2dataå’Œchat2dataç­‰åŸºçº¿æ–¹æ³•ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒKG2dataä¸ºå¤„ç†å…·æœ‰é«˜åº¦çŸ¥è¯†éœ€æ±‚é¢†åŸŸçš„æ™ºèƒ½é—®ç­”å’Œæ•°æ®åˆ†ææä¾›äº†ä¸€ç§é«˜æ•ˆä¸”åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10630v1",
      "published_date": "2025-07-14 08:20:06 UTC",
      "updated_date": "2025-07-14 08:20:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:25.832196+00:00"
    },
    {
      "arxiv_id": "2507.10629v1",
      "title": "SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition",
      "title_zh": "SQLordï¼šåŸºäºé€†å‘æ•°æ®ç”Ÿæˆä¸å·¥ä½œæµåˆ†è§£çš„ç¨³å¥ä¼ä¸šçº§ Text-to-SQL è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Song Cheng",
        "Qiannan Cheng",
        "Linbo Jin",
        "Lei Yi",
        "Guannan Zhang"
      ],
      "abstract": "Transforming natural language into SQL queries (NL2SQL) is crucial for data-driven business applications. Existing frameworks, trained on open-source datasets, struggle with complex business logic and lack domain-specific data for fine-tuning. Additionally, evaluation methods often require annotated data and executable database environments, which are scarce in real-world scenarios. To address these challenges, we propose SQLord, an enterprise-level NL2SQL framework. First, SQLord introduces a data reverse generation approach to convert raw SQL statements into annotated data for supervised fine-tuning (SFT). Second, it proposes a decomposition method for complex queries using an automated workflow generator. Additionally, SQLord features a comprehensive GPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL Evaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios. Offline tests significantly outperform state of the art baselines, and online accuracy consistently exceeds 90, highlighting SQLord's advantages and effectiveness in complex real world scenarios. SQLord has been successfully applied across multiple scenarios on the world's largest B2B e-commerce platform.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SQLordï¼Œä¸€ä¸ªé’ˆå¯¹ä¼ä¸šçº§åº”ç”¨è®¾è®¡çš„é²æ£’ Text-to-SQL æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨å¤„ç†å¤æ‚ä¸šåŠ¡é€»è¾‘å’Œç¼ºä¹é¢†åŸŸç‰¹å®šå¾®è°ƒæ•°æ®æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§æ•°æ®é€†å‘ç”Ÿæˆæ–¹æ³• (Data Reverse Generation)ï¼Œèƒ½å¤Ÿå°†åŸå§‹ SQL è¯­å¥é«˜æ•ˆè½¬åŒ–ä¸ºç”¨äºç›‘ç£å¾®è°ƒ (SFT) çš„æ ‡æ³¨æ•°æ®ï¼Œä»è€Œç¼“è§£äº†é¢†åŸŸæ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚é’ˆå¯¹å¤æ‚æŸ¥è¯¢éœ€æ±‚ï¼ŒSQLord é‡‡ç”¨äº†ä¸€ç§åŸºäºè‡ªåŠ¨åŒ–å·¥ä½œæµç”Ÿæˆå™¨ (Automated Workflow Generator) çš„æŸ¥è¯¢åˆ†è§£æ–¹æ³• (Workflow Decomposition)ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹å¯¹å¤æ‚é€»è¾‘çš„å¤„ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼€å‘äº†å…¨é¢çš„ GPT-Judge è¯„ä¼°æ¡†æ¶ï¼Œæ¶µç›–æ‰§è¡Œè¯„ä¼° (EXE)ã€Query-SQL è¯„ä¼° (QSE) å’Œ SQL-SQL è¯„ä¼° (SSE)ï¼Œä»¥é€‚åº”å¤šæ ·åŒ–çš„ä¼ä¸šçº§è¯„ä¼°åœºæ™¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSQLord åœ¨ç¦»çº¿æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿› (SOTA) çš„åŸºçº¿æ¨¡å‹ï¼Œåœ¨çº¿å‡†ç¡®ç‡ç¨³å®šè¶…è¿‡ 90%ã€‚ç›®å‰ï¼ŒSQLord å·²æˆåŠŸåº”ç”¨äºå…¨çƒæœ€å¤§çš„ B2B ç”µå­å•†åŠ¡å¹³å°ä¸­çš„å¤šä¸ªå®é™…åœºæ™¯ï¼ŒéªŒè¯äº†å…¶åœ¨å¤æ‚çœŸå®ç¯å¢ƒä¸­çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "WWW '25: Companion Proceedings of the ACM on Web Conference 2025 Pages 919 - 923 https://doi.org/10.1145/3701716.3715541",
      "pdf_url": "https://arxiv.org/pdf/2507.10629v1",
      "published_date": "2025-07-14 08:16:55 UTC",
      "updated_date": "2025-07-14 08:16:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:29.694887+00:00"
    },
    {
      "arxiv_id": "2507.10628v2",
      "title": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning",
      "title_zh": "GHPOï¼šé¢å‘ç¨³å®šé«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”å¼•å¯¼",
      "authors": [
        "Ziru Liu",
        "Cheng Gong",
        "Xinyu Fu",
        "Yaofang Liu",
        "Ran Chen",
        "Shoubo Hu",
        "Suiyun Zhang",
        "Rui Liu",
        "Qingfu Zhang",
        "Dandan Tu"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a powerful paradigm for facilitating the self-improvement of large language models (LLMs), particularly in the domain of complex reasoning tasks. However, prevailing on-policy RL methods often contend with significant training instability and inefficiency. This is primarily due to a capacity-difficulty mismatch, where the complexity of training data frequently outpaces the model's current capabilities, leading to critically sparse reward signals and stalled learning progress. This challenge is particularly acute for smaller, more resource-efficient LLMs. To overcome this, we introduce the Guided Hybrid Policy Optimization (GHPO), a novel difficulty-aware reinforcement learning framework. GHPO dynamically calibrates task difficulty by employing adaptive prompt refinement to provide targeted guidance. This unique approach adaptively balances direct imitation learning for problems currently beyond the model's reach with exploration-based reinforcement learning for more manageable tasks, effectively creating a smooth and optimized learning curriculum. Extensive experiments demonstrate that GHPO achieves an average performance gain of approximately 5% across six challenging mathematics benchmarks, consistently outperforming strong on-policy reinforcement learning and curriculum learning baselines. Further analysis confirms that our framework significantly enhances both training stability and final reasoning performance, thus offering a scalable and efficient solution for developing powerful and robust reasoning models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„å¼ºåŒ–å­¦ä¹ (RLVR)é¢ä¸´çš„è®­ç»ƒä¸ç¨³å®šå’Œæ•ˆç‡ä½ä¸‹é—®é¢˜ï¼ŒæŒ‡å‡ºè¿™ç§ç°è±¡æºäºä»»åŠ¡éš¾åº¦ä¸æ¨¡å‹å½“å‰èƒ½åŠ›ä¹‹é—´çš„å®¹é‡-éš¾åº¦ä¸åŒ¹é…(capacity-difficulty mismatch)ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†GHPO (Guided Hybrid Policy Optimization)ï¼Œè¿™æ˜¯ä¸€ç§å…·å¤‡éš¾åº¦æ„ŸçŸ¥èƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªé€‚åº”æç¤ºè¯ä¼˜åŒ–(adaptive prompt refinement)åŠ¨æ€è°ƒæ•´ä»»åŠ¡éš¾åº¦ï¼Œå¹¶ä¸ºæ¨¡å‹æä¾›é’ˆå¯¹æ€§å¼•å¯¼ã€‚GHPOèƒ½å¤Ÿçµæ´»å¹³è¡¡å¯¹äºé«˜éš¾åº¦é—®é¢˜çš„æ¨¡ä»¿å­¦ä¹ (imitation learning)ä»¥åŠé’ˆå¯¹å¯æ§ä»»åŠ¡çš„æ¢ç´¢å¼å¼ºåŒ–å­¦ä¹ (exploration-based RL)ï¼Œä»è€Œæ„å»ºå‡ºä¸€å¥—å¹³æ»‘ä¸”ä¼˜åŒ–çš„å­¦ä¹ è¯¾ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGHPOåœ¨å…­é¡¹æŒ‘æˆ˜æ€§çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å¹³å‡æ€§èƒ½æå‡çº¦5%ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„åœ¨çº¿å¼ºåŒ–å­¦ä¹ (on-policy RL)å’Œè¯¾ç¨‹å­¦ä¹ (curriculum learning)åŸºå‡†æ¨¡å‹ã€‚è¯¥æ¡†æ¶ä¸ä»…å¤§å¹…å¢å¼ºäº†è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œè¿˜æå‡äº†æœ€ç»ˆçš„æ¨ç†è¡¨ç°ï¼Œä¸ºå¼€å‘å¼ºå¤§ä¸”é²æ£’çš„æ¨ç†æ¨¡å‹æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code avaiable at https://github.com/hkgc-1/GHPO",
      "pdf_url": "https://arxiv.org/pdf/2507.10628v2",
      "published_date": "2025-07-14 08:10:00 UTC",
      "updated_date": "2025-07-16 15:30:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:41.694148+00:00"
    },
    {
      "arxiv_id": "2507.10015v3",
      "title": "(Almost) Free Modality Stitching of Foundation Models",
      "title_zh": "(è¿‘ä¹) é›¶æˆæœ¬çš„åŸºç¡€æ¨¡å‹æ¨¡æ€æ‹¼æ¥",
      "authors": [
        "Jaisidh Singh",
        "Diganta Misra",
        "Boris Knyazev",
        "Antonio Orvieto"
      ],
      "abstract": "Foundation multi-modal models are often designed by stitching of multiple existing pretrained uni-modal models: for example, an image classifier with an text model. This stitching process is performed by training a connector module that aims to align the representation spaces of these uni-modal models towards a multi-modal objective. However, given the complexity of training such connectors on large scale web-based datasets coupled with the ever-increasing number of available pretrained uni-modal models, the task of uni-modal models selection and subsequent connector module training becomes computationally demanding. To address this under-studied critical problem, we propose Hypernetwork Model Alignment (Hyma), a novel all-in-one solution for optimal uni-modal model selection and connector training by leveraging hypernetworks. Specifically, our framework utilizes the parameter prediction capability of a hypernetwork to obtain jointly trained connector modules for $N \\times M$ combinations of uni-modal models. In our experiments, Hyma reduces the cost of searching for the best performing uni-modal model pair by $10\\times$, while matching the ranking and trained connector performance obtained via grid search across a suite of diverse multi-modal benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Hypernetwork Model Alignment (Hyma)ï¼Œä¸€ç§æ—¨åœ¨ä¼˜åŒ–å¤§æ¨¡å‹æ¨¡æ€ç¼åˆ (Modality Stitching) çš„é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚ç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹é€šå¸¸é€šè¿‡è®­ç»ƒ Connector æ¨¡å—æ¥å¯¹é½ä¸åŒé¢„è®­ç»ƒå•æ¨¡æ€æ¨¡å‹ (Uni-modal models) çš„è¡¨ç¤ºç©ºé—´ï¼Œä½†åœ¨æ¨¡å‹ç»„åˆæ•°é‡æ¿€å¢çš„æƒ…å†µä¸‹ï¼Œæœ€ä¼˜æ¨¡å‹é€‰æ‹©ä¸æ¨¡å—è®­ç»ƒçš„è®¡ç®—å¼€é”€æå¤§ã€‚Hyma åˆ©ç”¨ Hypernetwork çš„å‚æ•°é¢„æµ‹èƒ½åŠ›ï¼Œå®ç°äº†ä¸º $N \\times M$ ç§å•æ¨¡æ€æ¨¡å‹ç»„åˆåŒæ—¶è·å¾—è”åˆè®­ç»ƒçš„ Connector æ¨¡å—ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆè§£å†³äº†ä»¥å¾€ç ”ç©¶ä¸­è¢«å¿½è§†çš„æ¨¡å‹å¯¹é€‰æ‹©é—®é¢˜ï¼Œæå¤§åœ°æå‡äº†è‡ªåŠ¨åŒ–å¯¹é½çš„çµæ´»æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHyma åœ¨å¤šç§å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­å°†æœ€ä½³æ¨¡å‹å¯¹çš„æœç´¢æˆæœ¬é™ä½äº† 10 å€ï¼ŒåŒæ—¶å…¶å®é™…æ€§èƒ½å’Œæ¨¡å‹æ’åä¸è€—æ—¶çš„ Grid Search æ–¹æ³•ç›¸å½“ã€‚è¯¥ç ”ç©¶ä¸ºä½æˆæœ¬æ„å»ºé«˜æ€§èƒ½å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Pre-print",
      "pdf_url": "https://arxiv.org/pdf/2507.10015v3",
      "published_date": "2025-07-14 07:51:01 UTC",
      "updated_date": "2025-07-17 11:10:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:18.783866+00:00"
    },
    {
      "arxiv_id": "2507.10007v2",
      "title": "Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning",
      "title_zh": "æ·±åº¦éšè—è®¤çŸ¥åŠ©åŠ›å¯é çš„æ€ç»´é“¾æ¨ç†",
      "authors": [
        "Zijun Chen",
        "Wenbo Hu",
        "Richang Hong"
      ],
      "abstract": "Chain of Thought (CoT) reasoning has demonstrated remarkable deep reasoning capabilities in both large language models (LLMs) and multimodal large language models (MLLMs). However, its reliability is often undermined by the accumulation of errors in intermediate steps. This paper introduces an novel approach to calibrate the CoT reasoning accuracy by leveraging the model's intrinsic veracity encoding. We discover that specific attention head activations reliably reflect the truthfulness of reasoning steps in CoT. Based on this insight, we train a confidence predictor to evaluate the correctness of each reasoning step using these truthfulness-sensitive activations, dynamically selecting the most plausible reasoning path via beam search. Experimental results demonstrate that our method significantly outperforms the state-of-the-art baselines (e.g., Few-Shot CoT, Self-Consistency, and Self-Evaluation Guided Beam Search) across the mathematical, symbolic, and commonsense reasoning tasks, exhibiting superior accuracy and reliability in both unimodal and multimodal settings. We further validate the approach on large reasoning models, confirming its applicability to specialized reasoning models. Additionally, we explore the role of the model's self-correction ability in CoT reasoning. This work provides a novel reliability improvement path for CoT reasoning with broad application potential.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å’Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨é“¾å¼æ€ç»´(Chain of Thought, CoT)æ¨ç†ä¸­å› ä¸­é—´æ­¥éª¤é”™è¯¯ç´¯ç§¯è€Œå¯¼è‡´çš„å¯é æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨æ¨¡å‹å†…åœ¨çœŸå®æ€§ç¼–ç (intrinsic veracity encoding)æ¥æ ¡å‡†æ¨ç†å‡†ç¡®æ€§çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶å‘ç°ç‰¹å®šæ³¨æ„åŠ›å¤´(attention head)çš„æ¿€æ´»çŠ¶æ€èƒ½å¯é åœ°åæ˜ æ¨ç†æ­¥éª¤çš„çœŸå®æ€§ï¼Œå¹¶æ®æ­¤è®­ç»ƒäº†ä¸€ä¸ªç½®ä¿¡åº¦é¢„æµ‹å™¨ã€‚è¯¥é¢„æµ‹å™¨åˆ©ç”¨è¿™äº›çœŸå®æ€§æ•æ„Ÿçš„æ¿€æ´»ç‰¹å¾è¯„ä¼°æ¯ä¸ªæ¨ç†æ­¥éª¤ï¼Œå¹¶é€šè¿‡æŸæœç´¢(beam search)åŠ¨æ€é€‰æ‹©æœ€åˆç†çš„æ¨ç†è·¯å¾„ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ•°å­¦ã€ç¬¦å·å’Œå¸¸è¯†æ¨ç†ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºFew-Shot CoTã€Self-ConsistencyåŠSelf-Evaluation Guided Beam Searchç­‰ç°æœ‰æŠ€æœ¯ï¼Œå¹¶åœ¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€ç¯å¢ƒä¸‹å‡è¡¨ç°å‡ºå“è¶Šçš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åœ¨å¤§å‹æ¨ç†æ¨¡å‹ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„é€‚ç”¨æ€§ï¼Œå¹¶æ¢è®¨äº†æ¨¡å‹è‡ªçº æ­£èƒ½åŠ›åœ¨æ¨ç†ä¸­çš„ä½œç”¨ï¼Œä¸ºæå‡CoTæ¨ç†çš„å¯é æ€§æä¾›äº†ä¸€æ¡å…·æœ‰å¹¿æ³›åº”ç”¨æ½œåŠ›çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by AAAI-26",
      "pdf_url": "https://arxiv.org/pdf/2507.10007v2",
      "published_date": "2025-07-14 07:41:35 UTC",
      "updated_date": "2025-11-25 02:54:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:17.282295+00:00"
    },
    {
      "arxiv_id": "2507.10000v1",
      "title": "On The Role of Intentionality in Knowledge Representation: Analyzing Scene Context for Cognitive Agents with a Tiny Language Model",
      "title_zh": "è®ºæ„å‘æ€§åœ¨çŸ¥è¯†è¡¨ç¤ºä¸­çš„ä½œç”¨ï¼šåŸºäºå¾®å‹è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥æ™ºèƒ½ä½“åœºæ™¯ä¸Šä¸‹æ–‡åˆ†æ",
      "authors": [
        "Mark Burgess"
      ],
      "abstract": "Since Searle's work deconstructing intent and intentionality in the realm of philosophy, the practical meaning of intent has received little attention in science and technology. Intentionality and context are both central to the scope of Promise Theory's model of Semantic Spacetime, used as an effective Tiny Language Model. One can identify themes and concepts from a text, on a low level (without knowledge of the specific language) by using process coherence as a guide. Any agent process can assess superficially a degree of latent `intentionality' in data by looking for anomalous multi-scale anomalies and assessing the work done to form them. Scale separation can be used to sort parts into `intended' content and `ambient context', using the spacetime coherence as a measure. This offers an elementary but pragmatic interpretation of latent intentionality for very low computational cost, and without reference to extensive training or reasoning capabilities. The process is well within the reach of basic organisms as it does not require large scale artificial probabilistic batch processing. The level of concept formation depends, however, on the memory capacity of the agent.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Intentionality åœ¨çŸ¥è¯†è¡¨ç¤ºä¸­çš„ä½œç”¨ï¼Œæå‡ºåˆ©ç”¨ Promise Theory çš„ Semantic Spacetime æ¨¡å‹ä½œä¸ºä¸€ç§é«˜æ•ˆçš„ Tiny Language Model æ¥åˆ†æè®¤çŸ¥æ™ºèƒ½ä½“çš„åœºæ™¯ä¸Šä¸‹æ–‡ã€‚é€šè¿‡è¿‡ç¨‹ç›¸å¹²æ€§ (process coherence) çš„å¼•å¯¼ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸å…·å¤‡ç‰¹å®šè¯­è¨€çŸ¥è¯†çš„æƒ…å†µä¸‹è¯†åˆ«æ–‡æœ¬çš„ä¸»é¢˜ä¸æ¦‚å¿µã€‚æ™ºèƒ½ä½“é€šè¿‡è§‚å¯Ÿå¤šå°ºåº¦å¼‚å¸¸ (multi-scale anomalies) æ¥è¯„ä¼°æ•°æ®ä¸­çš„æ½œæ„å‘æ€§ (latent intentionality)ï¼Œå¹¶åˆ©ç”¨æ—¶ç©ºç›¸å¹²æ€§ (spacetime coherence) è¿›è¡Œå°ºåº¦åˆ†ç¦» (scale separation)ï¼Œä»è€ŒåŒºåˆ†â€œé¢„å®šå†…å®¹â€ (intended content) ä¸â€œç¯å¢ƒä¸Šä¸‹æ–‡â€ (ambient context)ã€‚è¯¥æ–¹æ¡ˆè®¡ç®—æˆæœ¬æä½ï¼Œæ— éœ€å¤§è§„æ¨¡è®­ç»ƒæˆ–å¤æ‚æ¨ç†ï¼Œå…¶ç®€æ´æ€§ä½¿å…¶ç”šè‡³èƒ½è¢«åŸºç¡€ç”Ÿç‰©é‡‡ç”¨ã€‚ç ”ç©¶æœ€ç»ˆæŒ‡å‡ºï¼Œæ¦‚å¿µå½¢æˆçš„æ°´å¹³ä¸»è¦å–å†³äºæ™ºèƒ½ä½“çš„è®°å¿†å®¹é‡ (memory capacity)ï¼Œä¸ºè½»é‡åŒ–è®¤çŸ¥ç³»ç»Ÿæä¾›äº†ä¸€ç§å®ç”¨çš„è§£é‡Šæ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10000v1",
      "published_date": "2025-07-14 07:34:58 UTC",
      "updated_date": "2025-07-14 07:34:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:55.288938+00:00"
    },
    {
      "arxiv_id": "2507.09992v1",
      "title": "Evolution of Fear and Social Rewards in Prey-Predator Relationship",
      "title_zh": "æ•é£Ÿè€…ä¸çŒç‰©å…³ç³»ä¸­ææƒ§åŠç¤¾äº¤å¥–åŠ±çš„æ¼”åŒ–",
      "authors": [
        "Yuji Kanagawa",
        "Kenji Doya"
      ],
      "abstract": "Fear is a critical brain function for detecting danger and learning to avoid specific stimuli that can lead to danger. While fear is believed to have evolved under pressure from predators, experimentally reproducing the evolution is challenging. To investigate the relationship between environmental conditions, the evolution of fear, and the evolution of other rewards, such as food reward and social reward, we developed a distributed evolutionary simulation. In our simulation, prey and predator agents co-evolve their innate reward functions, including a possibly fear-like term for observing predators, and learn behaviors via reinforcement learning. Surprisingly, our simulation revealed that social reward for observing the same species is more important for prey to survive, and fear-like negative reward for observing predators evolves only after acquiring social reward. We also found that the predator with increased hunting ability (larger mouth) amplified fear emergence, but also that fear evolution is more stable with non-evolving predators that are bad at chasing prey. Additionally, unlike for predators, we found that positive rewards evolve in opposition to fear for stationary threats, as areas with abundant leftover food develop around them. These findings suggest that fear and social reward have had a complex interplay with each other through evolution, along with the nature of predators and threats.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ç§åˆ†å¸ƒå¼è¿›åŒ–æ¨¡æ‹Ÿ(Distributed Evolutionary Simulation)ç³»ç»Ÿï¼Œæ—¨åœ¨æ¢è®¨æ•é£Ÿè€…ä¸çŒç‰©å…³ç³»ä¸­ææƒ§æ„Ÿã€é£Ÿç‰©å¥–åŠ±å’Œç¤¾äº¤å¥–åŠ±çš„æ¼”åŒ–é€»è¾‘ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼ŒçŒç‰©ä¸æ•é£Ÿè€…æ™ºèƒ½ä½“åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)å­¦ä¹ è¡Œä¸ºï¼Œå¹¶å…±åŒè¿›åŒ–åŒ…å«ç±»ææƒ§é¡¹åœ¨å†…çš„å†…åœ¨å¥–åŠ±å‡½æ•°(Reward Functions)ã€‚ç ”ç©¶æƒŠäººåœ°å‘ç°ï¼Œè§‚å¯ŸåŒç±»äº§ç”Ÿçš„ç¤¾äº¤å¥–åŠ±(Social Reward)å¯¹çŒç‰©ç”Ÿå­˜è‡³å…³é‡è¦ï¼Œè€Œé’ˆå¯¹æ•é£Ÿè€…çš„ç±»ææƒ§è´Ÿå‘å¥–åŠ±ä»…åœ¨ç¤¾äº¤å¥–åŠ±è¿›åŒ–ä¹‹åæ‰å‡ºç°ã€‚æ­¤å¤–ï¼Œæ•é£Ÿè€…æ•çŒèƒ½åŠ›çš„æå‡ä¼šå¢å¼ºææƒ§çš„äº§ç”Ÿï¼Œä½†åœ¨æ•é£Ÿè€…ä¸è¿›åŒ–ä¸”æ•çŒæ•ˆç‡è¾ƒä½çš„æƒ…å†µä¸‹ï¼Œææƒ§çš„æ¼”åŒ–åè€Œæ›´ä¸ºç¨³å®šã€‚é’ˆå¯¹é™æ­¢å¨èƒï¼Œç”±äºå…¶å‘¨è¾¹å¾€å¾€ä¼´éšå……è¶³çš„é£Ÿç‰©èµ„æºï¼ŒçŒç‰©ç”šè‡³å¯èƒ½è¿›åŒ–å‡ºä¸ææƒ§ç›¸åçš„æ­£å‘å¥–åŠ±ã€‚è¿™äº›å®éªŒç»“æœæ­ç¤ºäº†ææƒ§ä¸ç¤¾äº¤å¥–åŠ±åœ¨è¿›åŒ–è¿‡ç¨‹ä¸­ï¼Œå—æ•é£Ÿè€…ç‰¹æ€§åŠç¯å¢ƒå¨èƒæ€§è´¨å½±å“è€Œäº§ç”Ÿçš„å¤æ‚ç›¸äº’ä½œç”¨ã€‚",
      "categories": [
        "q-bio.PE",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "q-bio.PE",
      "comment": "Preprint. Under review",
      "pdf_url": "https://arxiv.org/pdf/2507.09992v1",
      "published_date": "2025-07-14 07:27:18 UTC",
      "updated_date": "2025-07-14 07:27:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:56.120097+00:00"
    },
    {
      "arxiv_id": "2507.09990v1",
      "title": "Differentially Private Federated Low Rank Adaptation Beyond Fixed-Matrix",
      "title_zh": "è¶…è¶Šå›ºå®šçŸ©é˜µçš„å·®åˆ†éšç§è”é‚¦ä½ç§©è‡ªé€‚åº”",
      "authors": [
        "Ming Wen",
        "Jiaqi Zhu",
        "Yuedong Xu",
        "Yipeng Zhou",
        "Dingding Han"
      ],
      "abstract": "Large language models (LLMs) typically require fine-tuning for domain-specific tasks, and LoRA offers a computationally efficient approach by training low-rank adapters. LoRA is also communication-efficient for federated LLMs when multiple users collaboratively fine-tune a global LLM model without sharing their proprietary raw data. However, even the transmission of local adapters between a server and clients risks serious privacy leakage. Applying differential privacy (DP) to federated LoRA encounters a dilemma: adding noise to both adapters amplifies synthetic noise on the model, while fixing one adapter impairs the learnability of fine-tuning. In this paper, we propose FedASK (Differentially Private Federated Low Rank Adaptation with Double Sketching) , a novel federated LoRA framework to enable effective updating of both low-rank adapters with robust differential privacy. Inspired by randomized SVD, our key idea is a two-stage sketching pipeline. This pipeline first aggregates carefully sketched, privacy-preserving local updates, and then reconstructs the global matrices on the server to facilitate effective updating of both adapters. We theoretically prove FedASK's differential privacy guarantee and its exact aggregation property. Comprehensive experiments demonstrate that FedASK consistently outperforms baseline methods across a variety of privacy settings and data distributions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨è”é‚¦å­¦ä¹ (Federated Learning)ç¯å¢ƒä¸‹åº”ç”¨LoRAå¾®è°ƒæ—¶é¢ä¸´çš„éšç§é£é™©ï¼Œæå‡ºäº†FedASK (Differentially Private Federated Low Rank Adaptation with Double Sketching)æ¡†æ¶ã€‚ä¸ºäº†è§£å†³å·®åˆ†éšç§(DP)ä¸LoRAç»“åˆæ—¶äº§ç”Ÿçš„å™ªå£°æ”¾å¤§ä¸æ¨¡å‹å¯å­¦ä¹ æ€§ä¹‹é—´çš„æƒè¡¡é—®é¢˜ï¼ŒFedASK å€Ÿé‰´éšæœºå¥‡å¼‚å€¼åˆ†è§£(Randomized SVD)çš„æ€æƒ³ï¼Œå¼•å…¥äº†ç‹¬ç‰¹çš„ä¸¤é˜¶æ®µSketchingæµæ°´çº¿ã€‚è¯¥æ¡†æ¶é€šè¿‡èšåˆç»è¿‡éšç§ä¿æŠ¤å¤„ç†çš„æœ¬åœ°Sketchæ›´æ–°ï¼Œå¹¶åœ¨æœåŠ¡å™¨ç«¯é‡å»ºå…¨å±€çŸ©é˜µï¼Œä»è€Œå®ç°äº†å¯¹ä¸¤ä¸ªä½ç§©çŸ©é˜µçš„åŒæ—¶æœ‰æ•ˆæ›´æ–°ã€‚ç ”ç©¶åœ¨ç†è®ºä¸Šè¯æ˜äº†è¯¥æ–¹æ¡ˆå…·å¤‡ä¸¥æ ¼çš„å·®åˆ†éšç§ä¿è¯å’Œç²¾ç¡®èšåˆå±æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFedASK åœ¨å„ç§éšç§è®¾ç½®å’Œæ•°æ®åˆ†å¸ƒä¸‹å‡ä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œä¸ºéšç§ä¿æŠ¤çš„è”é‚¦æ¨¡å‹å¾®è°ƒæä¾›äº†é«˜æ•ˆä¸”ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "23 pages, NeurIPS 2025 under review",
      "pdf_url": "https://arxiv.org/pdf/2507.09990v1",
      "published_date": "2025-07-14 07:17:24 UTC",
      "updated_date": "2025-07-14 07:17:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:42:59.379705+00:00"
    },
    {
      "arxiv_id": "2507.09989v1",
      "title": "Improving monotonic optimization in heterogeneous multi-agent reinforcement learning with optimal marginal deterministic policy gradient",
      "title_zh": "åˆ©ç”¨æœ€ä¼˜è¾¹é™…ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦æ”¹è¿›å¼‚æ„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„å•è°ƒä¼˜åŒ–",
      "authors": [
        "Xiaoyang Yu",
        "Youfang Lin",
        "Shuo Wang",
        "Sheng Han"
      ],
      "abstract": "In heterogeneous multi-agent reinforcement learning (MARL), achieving monotonic improvement plays a pivotal role in enhancing performance. The HAPPO algorithm proposes a feasible solution by introducing a sequential update scheme, which requires independent learning with No Parameter-sharing (NoPS). However, heterogeneous MARL generally requires Partial Parameter-sharing (ParPS) based on agent grouping to achieve high cooperative performance. Our experiments prove that directly combining ParPS with the sequential update scheme leads to the policy updating baseline drift problem, thereby failing to achieve improvement. To solve the conflict between monotonic improvement and ParPS, we propose the Optimal Marginal Deterministic Policy Gradient (OMDPG) algorithm. First, we replace the sequentially computed $Q_Ïˆ^s(s,a_{1:i})$ with the Optimal Marginal Q (OMQ) function $Ï†_Ïˆ^*(s,a_{1:i})$ derived from Q-functions. This maintains MAAD's monotonic improvement while eliminating the conflict through optimal joint action sequences instead of sequential policy ratio calculations. Second, we introduce the Generalized Q Critic (GQC) as the critic function, employing pessimistic uncertainty-constrained loss to optimize different Q-value estimations. This provides the required Q-values for OMQ computation and stable baselines for actor updates. Finally, we implement a Centralized Critic Grouped Actor (CCGA) architecture that simultaneously achieves ParPS in local policy networks and accurate global Q-function computation. Experimental results in SMAC and MAMuJoCo environments demonstrate that OMDPG outperforms various state-of-the-art MARL baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼‚æ„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (heterogeneous MARL)ä¸­çš„å•è°ƒæå‡(monotonic improvement)é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„HAPPOç®—æ³•åœ¨é‡‡ç”¨éƒ¨åˆ†å‚æ•°å…±äº«(Partial Parameter-sharing, ParPS)æ—¶ä¼šé¢ä¸´ç­–ç•¥æ›´æ–°åŸºçº¿æ¼‚ç§»(policy updating baseline drift)çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´æ— æ³•å®ç°æ€§èƒ½ç¨³æ­¥æå‡ã€‚ä¸ºè§£å†³è¿™ä¸€å†²çªï¼Œè®ºæ–‡æå‡ºäº†æœ€ä¼˜è¾¹é™…ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦(Optimal Marginal Deterministic Policy Gradient, OMDPG)ç®—æ³•ã€‚è¯¥ç®—æ³•å¼•å…¥äº†åŸºäºQå‡½æ•°æ¨å¯¼çš„æœ€ä¼˜è¾¹é™…Q (Optimal Marginal Q, OMQ)å‡½æ•°ï¼Œåˆ©ç”¨æœ€ä¼˜è”åˆåŠ¨ä½œåºåˆ—ä»£æ›¿ä¼ ç»Ÿçš„é¡ºåºç­–ç•¥æ¯”ç‡è®¡ç®—ï¼Œä»è€Œåœ¨ç»´æŒå•è°ƒæå‡çš„åŒæ—¶æ¶ˆé™¤äº†ä¸ParPSçš„å†²çªã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨äº†å¹¿ä¹‰Qæ‰¹åˆ¤å™¨(Generalized Q Critic, GQC)å¹¶é…åˆæ‚²è§‚ä¸ç¡®å®šæ€§çº¦æŸæŸå¤±(pessimistic uncertainty-constrained loss)æ¥ä¼˜åŒ–Qå€¼ä¼°è®¡ï¼Œå¹¶è®¾è®¡äº†ä¸­å¿ƒåŒ–æ‰¹åˆ¤å™¨åˆ†ç»„ç­–ç•¥(Centralized Critic Grouped Actor, CCGA)æ¶æ„ä»¥å…¼é¡¾å‚æ•°å…±äº«ä¸å…¨å±€Qå‡½æ•°è®¡ç®—çš„ç²¾ç¡®æ€§ã€‚åœ¨SMACå’ŒMAMuJoCoç¯å¢ƒä¸‹çš„å®éªŒç»“æœè¯æ˜ï¼ŒOMDPGçš„æ€§èƒ½ä¼˜äºå¤šç§å…ˆè¿›çš„MARLåŸºçº¿æ¨¡å‹ï¼Œä¸ºå¼‚æ„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åä½œä¼˜åŒ–æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09989v1",
      "published_date": "2025-07-14 07:16:01 UTC",
      "updated_date": "2025-07-14 07:16:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:08.785688+00:00"
    },
    {
      "arxiv_id": "2507.14193v2",
      "title": "Modeling the Economic Impacts of AI Openness Regulation",
      "title_zh": "äººå·¥æ™ºèƒ½å¼€æ”¾æ€§ç›‘ç®¡çš„ç»æµå½±å“å»ºæ¨¡",
      "authors": [
        "Tori Qiu",
        "Benjamin Laufer",
        "Jon Kleinberg",
        "Hoda Heidari"
      ],
      "abstract": "Regulatory frameworks, such as the EU AI Act, encourage openness of general-purpose AI models by offering legal exemptions for \"open-source\" models. Despite this legislative attention on openness, the definition of open-source foundation models remains ambiguous. This paper models the strategic interactions among the creator of a general-purpose model (the generalist) and the entity that fine-tunes the general-purpose model to a specialized domain or task (the specialist), in response to regulatory requirements on model openness. We present a stylized model of the regulator's choice of an open-source definition to evaluate which AI openness standards will establish appropriate economic incentives for developers. Our results characterize market equilibria -- specifically, upstream model release decisions and downstream fine-tuning efforts -- under various openness regulations and present a range of effective regulatory penalties and open-source thresholds. Overall, we find the model's baseline performance determines when increasing the regulatory penalty vs. the open-source threshold will significantly alter the generalist's release strategy. Our model provides a theoretical foundation for AI governance decisions around openness and enables evaluation and refinement of practical open-source policies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¬§ç›Ÿ AI æ³•æ¡ˆ (EU AI Act) ç­‰ç›‘ç®¡æ¡†æ¶ä¸­é€šç”¨ AI æ¨¡å‹å¼€æº (open-source) å®šä¹‰ä¸æ˜ç¡®çš„é—®é¢˜ï¼Œé€šè¿‡å»ºç«‹åšå¼ˆæ¨¡å‹è¯„ä¼°äº† AI å¼€æ”¾æ€§ç›‘ç®¡çš„ç»æµå½±å“ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†é€šç”¨æ¨¡å‹åˆ›å»ºè€… (generalist) ä¸é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒçš„å®ä½“ (specialist) ä¹‹é—´åœ¨ç›‘ç®¡è¦æ±‚ä¸‹çš„ç­–ç•¥æ€§äº’åŠ¨ï¼Œå¹¶æ¢è®¨äº†ç›‘ç®¡è€…å¯¹å¼€æºå®šä¹‰çš„é€‰æ‹©å¦‚ä½•å»ºç«‹é€‚å½“çš„ç»æµæ¿€åŠ±ã€‚é€šè¿‡å¯¹ä¸åŒç›‘ç®¡ç¯å¢ƒä¸‹å¸‚åœºå‡è¡¡ (market equilibria) çš„åˆ»ç”»ï¼Œç ”ç©¶å‘ç°é€šç”¨æ¨¡å‹å‘å¸ƒå†³ç­–å’Œä¸‹æ¸¸å¾®è°ƒåŠªåŠ›å—åˆ°ç›‘ç®¡æƒ©ç½šä¸å¼€æºé˜ˆå€¼ (open-source threshold) çš„å…±åŒå½±å“ã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œæ¨¡å‹çš„åŸºç¡€æ€§èƒ½ (baseline performance) æ˜¯å†³å®šç›‘ç®¡æ”¿ç­–æœ‰æ•ˆæ€§çš„å…³é”®å› ç´ ã€‚è¯¥é¡¹å·¥ä½œä¸º AI æ²»ç†ä¸­çš„å¼€æ”¾æ€§å†³ç­–æä¾›äº†ç†è®ºæ”¯æ’‘ï¼Œä¸ºè¯„ä¼°å’Œä¼˜åŒ–å®é™…çš„å¼€æºæ”¿ç­–æä¾›äº†æœ‰æ•ˆçš„åˆ†æå·¥å…·ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14193v2",
      "published_date": "2025-07-14 07:08:31 UTC",
      "updated_date": "2025-10-24 03:57:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:12.682155+00:00"
    },
    {
      "arxiv_id": "2507.09985v1",
      "title": "Demonstrating the Octopi-1.5 Visual-Tactile-Language Model",
      "title_zh": "Octopi-1.5 è§†è§‰-è§¦è§‰-è¯­è¨€æ¨¡å‹æ¼”ç¤º",
      "authors": [
        "Samson Yu",
        "Kelvin Lin",
        "Harold Soh"
      ],
      "abstract": "Touch is recognized as a vital sense for humans and an equally important modality for robots, especially for dexterous manipulation, material identification, and scenarios involving visual occlusion. Building upon very recent work in touch foundation models, this demonstration will feature Octopi-1.5, our latest visual-tactile-language model. Compared to its predecessor, Octopi-1.5 introduces the ability to process tactile signals from multiple object parts and employs a simple retrieval-augmented generation (RAG) module to improve performance on tasks and potentially learn new objects on-the-fly. The system can be experienced live through a new handheld tactile-enabled interface, the TMI, equipped with GelSight and TAC-02 tactile sensors. This convenient and accessible setup allows users to interact with Octopi-1.5 without requiring a robot. During the demonstration, we will showcase Octopi-1.5 solving tactile inference tasks by leveraging tactile inputs and commonsense knowledge. For example, in a Guessing Game, Octopi-1.5 will identify objects being grasped and respond to follow-up queries about how to handle it (e.g., recommending careful handling for soft fruits). We also plan to demonstrate Octopi-1.5's RAG capabilities by teaching it new items. With live interactions, this demonstration aims to highlight both the progress and limitations of VTLMs such as Octopi-1.5 and to foster further interest in this exciting field. Code for Octopi-1.5 and design files for the TMI gripper are available at https://github.com/clear-nus/octopi-1.5.",
      "tldr_zh": "è¯¥ç ”ç©¶å±•ç¤ºäº† Octopi-1.5ï¼Œè¿™æ˜¯ä¸€ç§æœ€æ–°çš„è§†è§‰-è§¦è§‰-è¯­è¨€æ¨¡å‹ (Visual-Tactile-Language Model, VTLM)ï¼Œæ—¨åœ¨å¼ºè°ƒè§¦è§‰åœ¨æœºå™¨äººçµå·§æ“ä½œã€ææ–™è¯†åˆ«åŠè§†è§‰é®æŒ¡åœºæ™¯ä¸­çš„å…³é”®ä½œç”¨ã€‚ç›¸æ¯”å‰ä»£æ¨¡å‹ï¼ŒOctopi-1.5 å¼•å…¥äº†å¤„ç†æ¥è‡ªå¤šä¸ªç‰©ä½“éƒ¨ä½è§¦è§‰ä¿¡å·çš„èƒ½åŠ›ï¼Œå¹¶é‡‡ç”¨ç®€å•çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) æ¨¡å—æ¥æå‡ä»»åŠ¡æ€§èƒ½å¹¶å®ç°æ–°ç‰©ä½“çš„å³æ—¶å­¦ä¹ ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜å¼€å‘äº†åä¸º TMI çš„æ‰‹æŒå¼è§¦è§‰æ¥å£ï¼Œé…å¤‡äº† GelSight å’Œ TAC-02 ä¼ æ„Ÿå™¨ï¼Œä½¿ç”¨æˆ·æ— éœ€æœºå™¨äººå³å¯ä¸æ¨¡å‹è¿›è¡Œå®æ—¶äº¤äº’ã€‚è¯¥ç³»ç»Ÿåœ¨è§¦è§‰æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿç»“åˆè§¦è§‰è¾“å…¥ä¸å¸¸è¯†çŸ¥è¯†è¯†åˆ«æŠ“å–ç‰©ä½“ï¼Œå¹¶é’ˆå¯¹ç‰©ä½“çš„å¤„ç†æ–¹å¼ï¼ˆå¦‚å»ºè®®å°å¿ƒå¤„ç†è½¯æ°´æœï¼‰å›ç­”åç»­è¯¢é—®ã€‚é€šè¿‡å±•ç¤ºå…¶ RAG èƒ½åŠ›å’Œäº¤äº’æ€§èƒ½ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº† VTLMs çš„æ½œåŠ›ä¸å±€é™æ€§ï¼Œå¹¶å¼€æºäº† Octopi-1.5 çš„ä»£ç ä¸ TMI çš„ç¡¬ä»¶è®¾è®¡æ–‡ä»¶ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at R:SS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.09985v1",
      "published_date": "2025-07-14 07:05:36 UTC",
      "updated_date": "2025-07-14 07:05:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:14.087748+00:00"
    },
    {
      "arxiv_id": "2507.10626v1",
      "title": "Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction",
      "title_zh": "ç”¨äºè¶³çƒèµ›æœé¢„æµ‹çš„çƒå‘˜-çƒé˜Ÿå¼‚æ„äº¤äº’å›¾ Transformer",
      "authors": [
        "Lintao Wang",
        "Shiwen Xu",
        "Michael Horton",
        "Joachim Gudmundsson",
        "Zhiyong Wang"
      ],
      "abstract": "Predicting soccer match outcomes is a challenging task due to the inherently unpredictable nature of the game and the numerous dynamic factors influencing results. While it conventionally relies on meticulous feature engineering, deep learning techniques have recently shown a great promise in learning effective player and team representations directly for soccer outcome prediction. However, existing methods often overlook the heterogeneous nature of interactions among players and teams, which is crucial for accurately modeling match dynamics. To address this gap, we propose HIGFormer (Heterogeneous Interaction Graph Transformer), a novel graph-augmented transformer-based deep learning model for soccer outcome prediction. HIGFormer introduces a multi-level interaction framework that captures both fine-grained player dynamics and high-level team interactions. Specifically, it comprises (1) a Player Interaction Network, which encodes player performance through heterogeneous interaction graphs, combining local graph convolutions with a global graph-augmented transformer; (2) a Team Interaction Network, which constructs interaction graphs from a team-to-team perspective to model historical match relationships; and (3) a Match Comparison Transformer, which jointly analyzes both team and player-level information to predict match outcomes. Extensive experiments on the WyScout Open Access Dataset, a large-scale real-world soccer dataset, demonstrate that HIGFormer significantly outperforms existing methods in prediction accuracy. Furthermore, we provide valuable insights into leveraging our model for player performance evaluation, offering a new perspective on talent scouting and team strategy analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¶³çƒæ¯”èµ›ç»“æœé¢„æµ‹ä¸­ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†çƒå‘˜ä¸çƒé˜Ÿä¹‹é—´å¼‚æ„äº¤äº’ (heterogeneous interactions) çš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸º HIGFormer (Heterogeneous Interaction Graph Transformer) çš„æ–°å‹å›¾å¢å¼º Transformer æ¨¡å‹ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†ä¸€ä¸ªå¤šå±‚æ¬¡äº¤äº’æ¡†æ¶ï¼Œåˆ©ç”¨ Player Interaction Network ç»“åˆå±€éƒ¨å›¾å·ç§¯ä¸å…¨å±€å›¾å¢å¼º Transformer æ¥æ•æ‰ç»†ç²’åº¦çš„çƒå‘˜è¡¨ç°ï¼Œå¹¶è¾…ä»¥ Team Interaction Network å»ºæ¨¡çƒé˜Ÿé—´çš„å†å²æ¯”èµ›å…³ç³»ã€‚é€šè¿‡ Match Comparison Transformer è”åˆåˆ†æçƒå‘˜ä¸çƒé˜Ÿå±‚é¢çš„ä¿¡æ¯ï¼Œè¯¥æ¶æ„å®ç°äº†å¯¹æ¯”èµ›åŠ¨æ€çš„ç²¾ç¡®å»ºæ¨¡ã€‚åœ¨å¤§å‹çœŸå®è¶³çƒæ•°æ®é›† WyScout Open Access Dataset ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒHIGFormer çš„é¢„æµ‹å‡†ç¡®ç‡æ˜¾è‘—ä¼˜äºç°æœ‰å…ˆè¿›æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨çƒå‘˜è¡¨ç°è¯„ä¼°æ–¹é¢å±•ç°å‡ºçš„æ½œåŠ›ï¼Œä¹Ÿä¸ºäººæ‰å‘æ˜ (talent scouting) å’Œçƒé˜Ÿæˆ˜æœ¯åˆ†ææä¾›äº†æ•°æ®é©±åŠ¨çš„æ–°è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10626v1",
      "published_date": "2025-07-14 06:43:36 UTC",
      "updated_date": "2025-07-14 06:43:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:28.689648+00:00"
    },
    {
      "arxiv_id": "2507.09973v1",
      "title": "Tiny Reward Models",
      "title_zh": "å¾®å‹å¥–åŠ±æ¨¡å‹",
      "authors": [
        "Sarah Pan"
      ],
      "abstract": "Large decoder-based language models have become the dominant architecture for reward modeling in reinforcement learning from human feedback (RLHF). However, as reward models are increasingly deployed in test-time strategies, their inference costs become a growing concern. We present TinyRM, a family of small, bidirectional masked language models (MLMs) with as few as 400 million parameters, that rival the capabilities of models over 175 times larger on reasoning and safety preference modeling tasks. TinyRM combines FLAN-style prompting, Directional Low-Rank Adaptation (DoRA), and layer freezing to achieve strong performance on RewardBench, despite using significantly fewer resources. Our experiments suggest that small models benefit from domain-specific tuning strategies, particularly in reasoning, where lightweight finetuning methods are especially effective. While challenges remain in building generalist models and conversational preference modeling, our preliminary results highlight the promise of lightweight bidirectional architectures as efficient, scalable alternatives for preference modeling.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TinyRMï¼Œè¿™æ˜¯ä¸€ä¸ªå‚æ•°è§„æ¨¡ä»…ä¸º 4 äº¿çš„åŒå‘æ©ç è¯­è¨€æ¨¡å‹ (MLMs) ç³»åˆ—ï¼Œæ—¨åœ¨è§£å†³å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆä¸­å­¦ä¹  (RLHF) è¿‡ç¨‹ä¸­å¥–åŠ±æ¨¡å‹ (Reward Models) æ¨ç†æˆæœ¬è¿‡é«˜çš„é—®é¢˜ã€‚å°½ç®¡ TinyRM çš„æ¨¡å‹è§„æ¨¡æ¯”ä¸»æµæ¶æ„å° 175 å€ä»¥ä¸Šï¼Œä½†å®ƒåœ¨æ¨ç†å’Œå®‰å…¨æ€§åå¥½å»ºæ¨¡ä»»åŠ¡ä¸Šå±•ç°å‡ºä¸å¤§å‹æ¨¡å‹ç›¸å½“çš„èƒ½åŠ›ã€‚è¯¥æ¡†æ¶ç»“åˆäº† FLAN-style promptingã€å®šå‘ä½ç§©é€‚é… (DoRA) ä»¥åŠå±‚å†»ç»“ (layer freezing) æŠ€æœ¯ï¼Œåœ¨ RewardBench ä¸Šå–å¾—äº†ä¼˜å¼‚æˆç»©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°è§„æ¨¡æ¨¡å‹é€šè¿‡é¢†åŸŸç‰¹å®šçš„å¾®è°ƒç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¨ç†ä»»åŠ¡ä¸­ï¼Œèƒ½å¤Ÿä»¥æä½çš„èµ„æºæ¶ˆè€—å®ç°é«˜æ•ˆçš„æ€§èƒ½ã€‚è™½ç„¶åœ¨é€šç”¨æ€§åŠå¯¹è¯åå¥½å»ºæ¨¡æ–¹é¢ä»å­˜æŒ‘æˆ˜ï¼Œä½† TinyRM è¯æ˜äº†è½»é‡çº§åŒå‘æ¶æ„æ˜¯åå¥½å»ºæ¨¡é¢†åŸŸä¸­å…·æœ‰æ½œåŠ›ä¸”é«˜æ•ˆã€å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "2025 ICML Efficient Systems for Foundation Models Workshop",
      "pdf_url": "https://arxiv.org/pdf/2507.09973v1",
      "published_date": "2025-07-14 06:43:00 UTC",
      "updated_date": "2025-07-14 06:43:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:43.886394+00:00"
    },
    {
      "arxiv_id": "2507.09966v3",
      "title": "Multimodal Fusion at Three Tiers: Physics-Driven Data Generation and Vision-Language Guidance for Brain Tumor Segmentation",
      "title_zh": "ä¸‰å±‚çº§å¤šæ¨¡æ€èåˆï¼šé¢å‘è„‘è‚¿ç˜¤åˆ†å‰²çš„ç‰©ç†é©±åŠ¨æ•°æ®ç”Ÿæˆä¸è§†è§‰-è¯­è¨€å¼•å¯¼",
      "authors": [
        "Mingda Zhang"
      ],
      "abstract": "Accurate brain tumor segmentation is crucial for neuro-oncology diagnosis and treatment planning. Deep learning methods have made significant progress, but automatic segmentation still faces challenges, including tumor morphological heterogeneity and complex three-dimensional spatial relationships. This paper proposes a three-tier fusion architecture that achieves precise brain tumor segmentation. The method processes information progressively at the pixel, feature, and semantic levels. At the pixel level, physical modeling extends magnetic resonance imaging (MRI) to multimodal data, including simulated ultrasound and synthetic computed tomography (CT). At the feature level, the method performs Transformer-based cross-modal feature fusion through multi-teacher collaborative distillation, integrating three expert teachers (MRI, US, CT). At the semantic level, clinical textual knowledge generated by GPT-4V is transformed into spatial guidance signals using CLIP contrastive learning and Feature-wise Linear Modulation (FiLM). These three tiers together form a complete processing chain from data augmentation to feature extraction to semantic guidance. We validated the method on the Brain Tumor Segmentation (BraTS) 2020, 2021, and 2023 datasets. The model achieves average Dice coefficients of 0.8665, 0.9014, and 0.8912 on the three datasets, respectively, and reduces the 95% Hausdorff Distance (HD95) by an average of 6.57 millimeters compared with the baseline. This method provides a new paradigm for precise tumor segmentation and boundary localization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸‰å±‚èåˆæ¶æ„(Three-tier fusion architecture)ï¼Œæ—¨åœ¨è§£å†³è„‘è‚¿ç˜¤åˆ†å‰²ä¸­é¢ä¸´çš„å½¢æ€å¼‚è´¨æ€§å’Œå¤æ‚ä¸‰ç»´ç©ºé—´å…³ç³»ç­‰æŒ‘æˆ˜ã€‚åœ¨åƒç´ å±‚çº§ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç‰©ç†å»ºæ¨¡(Physical modeling)å°†ç£å…±æŒ¯æˆåƒ(MRI)æ‰©å±•ä¸ºåŒ…å«æ¨¡æ‹Ÿè¶…å£°(Simulated ultrasound)å’Œåˆæˆè®¡ç®—æœºæ–­å±‚æ‰«æ(Synthetic CT)çš„å¤šæ¨¡æ€æ•°æ®ã€‚åœ¨ç‰¹å¾å±‚çº§ï¼Œé€šè¿‡åŸºäºTransformerçš„è·¨æ¨¡æ€ç‰¹å¾èåˆï¼Œå¹¶ç»“åˆå¤šå¯¼å¸ˆåä½œè’¸é¦(Multi-teacher collaborative distillation)æŠ€æœ¯æ•´åˆäº†ä¸åŒæ¨¡æ€çš„ä¸“å®¶çŸ¥è¯†ã€‚åœ¨è¯­ä¹‰å±‚çº§ï¼Œåˆ©ç”¨GPT-4Vç”Ÿæˆçš„ä¸´åºŠæ–‡æœ¬çŸ¥è¯†ï¼Œé€šè¿‡CLIPå¯¹æ¯”å­¦ä¹ å’Œç‰¹å¾çº¿æ€§è°ƒåˆ¶(FiLM)å°†å…¶è½¬åŒ–ä¸ºç©ºé—´å¼•å¯¼ä¿¡å·ã€‚è¯¥æ–¹æ³•åœ¨BraTS 2020ã€2021å’Œ2023æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œåˆ†åˆ«è¾¾åˆ°äº†0.8665ã€0.9014å’Œ0.8912çš„å¹³å‡Diceç³»æ•°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹ç›¸è¾ƒäºåŸºçº¿æ¨¡å‹å°†95%è±ªæ–¯å¤šå¤«è·ç¦»(HD95)å¹³å‡é™ä½äº†6.57æ¯«ç±³ï¼Œæ˜¾è‘—æå‡äº†åˆ†å‰²ç²¾åº¦ã€‚è¯¥ç ”ç©¶ä¸ºç²¾ç¡®çš„è‚¿ç˜¤åˆ†å‰²å’Œè¾¹ç•Œå®šä½æä¾›äº†ä¸€ç§ç”±æ•°æ®å¢å¼ºã€ç‰¹å¾æå–åˆ°è¯­ä¹‰å¼•å¯¼çš„å®Œæ•´å¤„ç†é“¾æ–°èŒƒå¼ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "31 pages,3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.09966v3",
      "published_date": "2025-07-14 06:32:59 UTC",
      "updated_date": "2025-10-19 06:02:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:46.783229+00:00"
    },
    {
      "arxiv_id": "2507.11557v1",
      "title": "3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation",
      "title_zh": "ç”¨äºå…¨èº« MR-to-CT æ¨¡æ€è½¬æ¢çš„ 3D å°æ³¢æ½œæ‰©æ•£æ¨¡å‹",
      "authors": [
        "Jiaxu Zheng",
        "Meiman He",
        "Xuhui Tang",
        "Xiong Wang",
        "Tuoyu Cao",
        "Tianyi Zeng",
        "Lichi Zhang",
        "Chenyu You"
      ],
      "abstract": "Magnetic Resonance (MR) imaging plays an essential role in contemporary clinical diagnostics. It is increasingly integrated into advanced therapeutic workflows, such as hybrid Positron Emission Tomography/Magnetic Resonance (PET/MR) imaging and MR-only radiation therapy. These integrated approaches are critically dependent on accurate estimation of radiation attenuation, which is typically facilitated by synthesizing Computed Tomography (CT) images from MR scans to generate attenuation maps. However, existing MR-to-CT synthesis methods for whole-body imaging often suffer from poor spatial alignment between the generated CT and input MR images, and insufficient image quality for reliable use in downstream clinical tasks. In this paper, we present a novel 3D Wavelet Latent Diffusion Model (3D-WLDM) that addresses these limitations by performing modality translation in a learned latent space. By incorporating a Wavelet Residual Module into the encoder-decoder architecture, we enhance the capture and reconstruction of fine-scale features across image and latent spaces. To preserve anatomical integrity during the diffusion process, we disentangle structural and modality-specific characteristics and anchor the structural component to prevent warping. We also introduce a Dual Skip Connection Attention mechanism within the diffusion model, enabling the generation of high-resolution CT images with improved representation of bony structures and soft-tissue contrast.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º 3D Wavelet Latent Diffusion Model (3D-WLDM) çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…¨èº« MR-to-CT æ¨¡æ€è½¬æ¢ä¸­å¸¸è§çš„ç©ºé—´å¯¹é½ä¸å‡†åŠå›¾åƒè´¨é‡æ¬ ä½³ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹åœ¨å­¦ä¹ åˆ°çš„ latent space ä¸­æ‰§è¡Œè½¬æ¢ä»»åŠ¡ï¼Œå¹¶åˆ›æ–°æ€§åœ°åœ¨ encoder-decoder æ¶æ„ä¸­é›†æˆ Wavelet Residual Moduleï¼Œä»è€Œæ˜¾è‘—æå‡äº†å¯¹å›¾åƒç»†å¾®ç‰¹å¾çš„æ•æ‰ä¸é‡å»ºç²¾åº¦ã€‚ä¸ºç¡®ä¿ç”Ÿæˆè¿‡ç¨‹ä¸­çš„è§£å‰–ç»“æ„å®Œæ•´æ€§ï¼Œç ”ç©¶äººå‘˜é€šè¿‡è§£è€¦ç»“æ„ä¸æ¨¡æ€ç‰¹å¾å¹¶é”šå®šç»“æ„ç»„ä»¶ï¼Œæœ‰æ•ˆé˜²æ­¢äº†å›¾åƒå½¢å˜ã€‚æ­¤å¤–ï¼Œæ¨¡å‹å¼•å…¥äº† Dual Skip Connection Attention æœºåˆ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰æ›´æ¸…æ™°éª¨éª¼ç»“æ„å’Œæ›´é«˜è½¯ç»„ç»‡å¯¹æ¯”åº¦çš„é«˜åˆ†è¾¨ç‡ CT å›¾åƒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¢å¼ºç©ºé—´ä¸€è‡´æ€§å’Œå›¾åƒä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸ºæ··åˆ PET/MR æˆåƒå’Œä»… MR æ”¾å°„æ²»ç–—ä¸­çš„è¡°å‡å›¾ç”Ÿæˆæä¾›äº†æ›´ç²¾ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.11557v1",
      "published_date": "2025-07-14 06:17:05 UTC",
      "updated_date": "2025-07-14 06:17:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:50.196095+00:00"
    },
    {
      "arxiv_id": "2507.09955v1",
      "title": "DeepSeek: Paradigm Shifts and Technical Evolution in Large AI Models",
      "title_zh": "DeepSeekï¼šå¤§å‹äººå·¥æ™ºèƒ½æ¨¡å‹çš„èŒƒå¼å˜é©ä¸æŠ€æœ¯æ¼”è¿›",
      "authors": [
        "Luolin Xiong",
        "Haofen Wang",
        "Xi Chen",
        "Lu Sheng",
        "Yun Xiong",
        "Jingping Liu",
        "Yanghua Xiao",
        "Huajun Chen",
        "Qing-Long Han",
        "Yang Tang"
      ],
      "abstract": "DeepSeek, a Chinese Artificial Intelligence (AI) startup, has released their V3 and R1 series models, which attracted global attention due to their low cost, high performance, and open-source advantages. This paper begins by reviewing the evolution of large AI models focusing on paradigm shifts, the mainstream Large Language Model (LLM) paradigm, and the DeepSeek paradigm. Subsequently, the paper highlights novel algorithms introduced by DeepSeek, including Multi-head Latent Attention (MLA), Mixture-of-Experts (MoE), Multi-Token Prediction (MTP), and Group Relative Policy Optimization (GRPO). The paper then explores DeepSeek engineering breakthroughs in LLM scaling, training, inference, and system-level optimization architecture. Moreover, the impact of DeepSeek models on the competitive AI landscape is analyzed, comparing them to mainstream LLMs across various fields. Finally, the paper reflects on the insights gained from DeepSeek innovations and discusses future trends in the technical and engineering development of large AI models, particularly in data, training, and reasoning.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†ä¸­å›½åˆåˆ›å…¬å¸ DeepSeek å‘å¸ƒçš„ V3 å’Œ R1 ç³»åˆ—æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å› ä½æˆæœ¬ã€é«˜æ€§èƒ½åŠå¼€æºä¼˜åŠ¿å¼•èµ·äº†å…¨çƒå…³æ³¨ã€‚æ–‡ç« ç³»ç»Ÿå›é¡¾äº†å¤§æ¨¡å‹èŒƒå¼çš„æ¼”å˜ï¼Œå¹¶é‡ç‚¹åˆ†æäº† DeepSeek èŒƒå¼çš„ç‹¬ç‰¹ä¹‹å¤„ã€‚æ–‡ä¸­è¯¦ç»†ä»‹ç»äº† DeepSeek å¼•å…¥çš„åˆ›æ–°ç®—æ³•ï¼ŒåŒ…æ‹¬ Multi-head Latent Attention (MLA)ã€Mixture-of-Experts (MoE)ã€Multi-Token Prediction (MTP) å’Œ Group Relative Policy Optimization (GRPO)ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡æ¢è®¨äº† DeepSeek åœ¨æ¨¡å‹æ‰©å±• (scaling)ã€è®­ç»ƒã€æ¨ç†åŠç³»ç»Ÿçº§ä¼˜åŒ–æ¶æ„æ–¹é¢çš„å·¥ç¨‹çªç ´ã€‚é€šè¿‡ä¸ä¸»æµ Large Language Model (LLM) åœ¨å¤šä¸ªé¢†åŸŸçš„å¯¹æ¯”ï¼Œåˆ†æäº† DeepSeek å¯¹äººå·¥æ™ºèƒ½ç«äº‰æ ¼å±€çš„å½±å“ã€‚æœ€åï¼Œæ–‡ç« æ€»ç»“äº† DeepSeek åˆ›æ–°å¸¦æ¥çš„å¯ç¤ºï¼Œå¹¶è®¨è®ºäº†å¤§å‹ AI æ¨¡å‹åœ¨æ•°æ®ã€è®­ç»ƒå’Œæ¨ç†ç­‰æŠ€æœ¯ä¸å·¥ç¨‹é¢†åŸŸçš„æœªæ¥å‘å±•è¶‹åŠ¿ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09955v1",
      "published_date": "2025-07-14 06:10:30 UTC",
      "updated_date": "2025-07-14 06:10:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:52.738175+00:00"
    },
    {
      "arxiv_id": "2507.09950v2",
      "title": "Can GPT-4o mini and Gemini 2.0 Flash Predict Fine-Grained Fashion Product Attributes? A Zero-Shot Analysis",
      "title_zh": "GPT-4o mini ä¸ Gemini 2.0 Flash èƒ½å¦é¢„æµ‹ç»†ç²’åº¦æ—¶å°šäº§å“å±æ€§ï¼Ÿä¸€é¡¹é›¶æ ·æœ¬åˆ†æ",
      "authors": [
        "Shubham Shukla",
        "Kunal Sonalkar"
      ],
      "abstract": "The fashion retail business is centered around the capacity to comprehend products. Product attribution helps in comprehending products depending on the business process. Quality attribution improves the customer experience as they navigate through millions of products offered by a retail website. It leads to well-organized product catalogs. In the end, product attribution directly impacts the 'discovery experience' of the customer. Although large language models (LLMs) have shown remarkable capabilities in understanding multimodal data, their performance on fine-grained fashion attribute recognition remains under-explored. This paper presents a zero-shot evaluation of state-of-the-art LLMs that balance performance with speed and cost efficiency, mainly GPT-4o-mini and Gemini 2.0 Flash. We have used the dataset DeepFashion-MultiModal (https://github.com/yumingj/DeepFashion-MultiModal) to evaluate these models in the attribution tasks of fashion products. Our study evaluates these models across 18 categories of fashion attributes, offering insight into where these models excel. We only use images as the sole input for product information to create a constrained environment. Our analysis shows that Gemini 2.0 Flash demonstrates the strongest overall performance with a macro F1 score of 56.79% across all attributes, while GPT-4o-mini scored a macro F1 score of 43.28%. Through detailed error analysis, our findings provide practical insights for deploying these LLMs in production e-commerce product attribution-related tasks and highlight the need for domain-specific fine-tuning approaches. This work also lays the groundwork for future research in fashion AI and multimodal attribute extraction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶å°šé›¶å”®ä¸­äº§å“å½’å› (Product Attribution)å¯¹æå‡å®¢æˆ·å‘ç°ä½“éªŒçš„é‡è¦æ€§ï¼Œè¯„ä¼°äº†GPT-4o-miniå’ŒGemini 2.0 Flashç­‰å¹³è¡¡æ€§èƒ½ä¸æˆæœ¬çš„è§†è§‰å¤§è¯­è¨€æ¨¡å‹åœ¨ç»†ç²’åº¦æ—¶å°šå±æ€§è¯†åˆ«ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶é‡‡ç”¨äº†DeepFashion-MultiModalæ•°æ®é›†ï¼Œåœ¨ä»…ä»¥å›¾åƒä½œä¸ºå”¯ä¸€è¾“å…¥ä¿¡æ¯çš„é›¶æ ·æœ¬(Zero-Shot)ç¯å¢ƒä¸‹ï¼Œå¯¹æ¶µç›–18ä¸ªç±»åˆ«çš„æ—¶å°šå±æ€§è¿›è¡Œäº†å¯¹æ¯”è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGemini 2.0 Flashåœ¨æ‰€æœ‰å±æ€§ä¸Šçš„å®F1åˆ†æ•°(Macro F1 score)è¾¾åˆ°56.79%ï¼Œå±•ç°å‡ºæ˜¾è‘—ä¼˜äºGPT-4o-mini(43.28%)çš„ç»¼åˆæ€§èƒ½ã€‚é€šè¿‡è¯¦ç»†çš„é”™è¯¯åˆ†æ(Error Analysis)ï¼Œç ”ç©¶æä¾›äº†å°†è¿™äº›å¤šæ¨¡æ€å¤§æ¨¡å‹éƒ¨ç½²äºç”µå­å•†åŠ¡ç”Ÿäº§ç¯å¢ƒä¸­çš„å®é™…è§è§£ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…å¼ºè°ƒäº†é¢†åŸŸç‰¹å®šå¾®è°ƒ(Domain-Specific Fine-Tuning)çš„å¿…è¦æ€§ï¼Œä¹Ÿä¸ºæ—¶å°šäººå·¥æ™ºèƒ½å’Œå¤šæ¨¡æ€å±æ€§æå–é¢†åŸŸçš„æœªæ¥ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Version 2: Added a missing citation",
      "pdf_url": "https://arxiv.org/pdf/2507.09950v2",
      "published_date": "2025-07-14 05:59:50 UTC",
      "updated_date": "2025-07-30 04:37:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:43:54.535455+00:00"
    },
    {
      "arxiv_id": "2507.09937v2",
      "title": "Memorization Sinks: Isolating Memorization during LLM Training",
      "title_zh": "Memorization Sinksï¼šå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­çš„è®°å¿†éš”ç¦»",
      "authors": [
        "Gaurav R. Ghosal",
        "Pratyush Maini",
        "Aditi Raghunathan"
      ],
      "abstract": "Large language models are susceptible to memorizing repeated sequences, posing privacy and copyright concerns. A popular mitigation strategy is to remove memorized information from specific neurons post-hoc. However, such approaches have shown limited success so far. In a controlled setting, we show that the memorization of natural sequences (those that resemble linguistically plausible text) become mechanistically entangled with general language abilities, thereby becoming challenging to remove post-hoc. In this work, we put forward a new paradigm of MemSinks that promotes isolation of memorization by design. We leverage a sequence identifier that activates a unique set of memorization neurons for each sequence across repetitions. By analyzing the dynamics of learning and forgetting, we argue that MemSinks facilitates isolation of memorized content, making it easier to remove without compromising general language capabilities. We implement MemSinks at the billion-parameter and billion-token scale, and observe both effective isolation and strong generalization. To our knowledge, this is the first proof-of-concept on real data demonstrating that simultaneous generalization and isolation is achievable. We open-source our code at http://github.com/grghosal/MemSinks.",
      "tldr_zh": "å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å®¹æ˜“è®°å¿†é‡å¤åºåˆ—ï¼Œå¼•å‘éšç§å’Œç‰ˆæƒæ‹…å¿§ï¼Œä½†ä¼ ç»Ÿçš„åæœŸç§»é™¤æ–¹æ³•å¸¸å› è®°å¿†ä¸é€šç”¨è¯­è¨€èƒ½åŠ›åœ¨æœºåˆ¶ä¸Šé«˜åº¦äº¤ç»‡è€Œéš¾ä»¥ç”Ÿæ•ˆã€‚è¯¥ç ”ç©¶æå‡ºäº†åä¸º MemSinks çš„æ–°èŒƒå¼ï¼Œæ—¨åœ¨é€šè¿‡è®¾è®¡åœ¨æ¨¡å‹è®­ç»ƒæœŸé—´éš”ç¦»è®°å¿†ã€‚MemSinks åˆ©ç”¨åºåˆ—æ ‡è¯†ç¬¦(sequence identifier)ï¼Œåœ¨åºåˆ—é‡å¤å‡ºç°æ—¶ä¸ºå…¶æ¿€æ´»ä¸€ç»„ç‹¬ç‰¹çš„è®°å¿†ç¥ç»å…ƒ(memorization neurons)ã€‚é€šè¿‡åˆ†æå­¦ä¹ ä¸é—å¿˜çš„åŠ¨æ€è¿‡ç¨‹ï¼Œè¯¥æ–¹æ¡ˆå®ç°äº†è®°å¿†å†…å®¹çš„ç‰©ç†éš”ç¦»ï¼Œä½¿å…¶åœ¨ä¸æŸå®³æ¨¡å‹é€šç”¨è¯­è¨€èƒ½åŠ›çš„å‰æä¸‹æ›´æ˜“äºè¢«ç§»é™¤ã€‚ç ”ç©¶äººå‘˜åœ¨åäº¿å‚æ•°å’Œåäº¿ Token è§„æ¨¡ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œå¹¶è§‚å¯Ÿåˆ°æ˜¾è‘—çš„éš”ç¦»æ•ˆæœå’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚ä½œä¸ºé¦–ä¸ªåœ¨çœŸå®æ•°æ®ä¸Šè¯æ˜åŒæ—¶å®ç°æ³›åŒ–(generalization)ä¸éš”ç¦»(isolation)å¯è¡Œæ€§çš„æ¦‚å¿µéªŒè¯ï¼Œè¯¥ç ”ç©¶ä¸ºè§£å†³å¤§æ¨¡å‹çš„éšç§ä¸ç‰ˆæƒé£é™©æä¾›äº†åˆ›æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 2025 International Conference of Machine Learning",
      "pdf_url": "https://arxiv.org/pdf/2507.09937v2",
      "published_date": "2025-07-14 05:23:27 UTC",
      "updated_date": "2025-09-15 18:32:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:01.098680+00:00"
    },
    {
      "arxiv_id": "2507.09935v1",
      "title": "Enhancing Retrieval Augmented Generation with Hierarchical Text Segmentation Chunking",
      "title_zh": "é€šè¿‡å±‚çº§åŒ–æ–‡æœ¬åˆ†å‰²åˆ†å—å¢å¼ºæ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Hai Toan Nguyen",
        "Tien Dat Nguyen",
        "Viet Ha Nguyen"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems commonly use chunking strategies for retrieval, which enhance large language models (LLMs) by enabling them to access external knowledge, ensuring that the retrieved information is up-to-date and domain-specific. However, traditional methods often fail to create chunks that capture sufficient semantic meaning, as they do not account for the underlying textual structure. This paper proposes a novel framework that enhances RAG by integrating hierarchical text segmentation and clustering to generate more meaningful and semantically coherent chunks. During inference, the framework retrieves information by leveraging both segment-level and cluster-level vector representations, thereby increasing the likelihood of retrieving more precise and contextually relevant information. Evaluations on the NarrativeQA, QuALITY, and QASPER datasets indicate that the proposed method achieved improved results compared to traditional chunking techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Retrieval-Augmented Generation (RAG)ç³»ç»Ÿä¸­ä¼ ç»Ÿåˆ†å—(chunking)æ–¹æ³•å¿½ç•¥æ–‡æœ¬ç»“æ„ã€å¯¼è‡´è¯­ä¹‰ç¼ºå¤±çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå±‚æ¬¡åŒ–æ–‡æœ¬åˆ†å‰²(hierarchical text segmentation)å’Œèšç±»(clustering)çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆæ–‡æœ¬çš„åº•å±‚ç»“æ„æ¥ç”Ÿæˆæ›´å…·è¯­ä¹‰è¿è´¯æ€§çš„æ•°æ®å—ï¼Œä»è€Œä¼˜åŒ–å¤–éƒ¨çŸ¥è¯†çš„æ£€ç´¢è´¨é‡ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨æ®µè½çº§(segment-level)å’Œèšç±»çº§(cluster-level)çš„å‘é‡è¡¨ç¤ºè¿›è¡Œå¤šå±‚æ¬¡åŒ¹é…ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢ä¿¡æ¯çš„ç²¾ç¡®åº¦ä¸ä¸Šä¸‹æ–‡ç›¸å…³æ€§ã€‚åœ¨NarrativeQAã€QuALITYå’ŒQASPERç­‰æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å„é¡¹æ€§èƒ½æŒ‡æ ‡ä¸Šå‡ä¼˜äºä¼ ç»Ÿåˆ†å—æŠ€æœ¯ã€‚è¿™ä¸€æˆæœä¸ºå¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å¤„ç†é¢†åŸŸç‰¹å®šçŸ¥è¯†çš„èƒ½åŠ›æä¾›äº†æ›´æœ‰æ•ˆçš„æ–‡æœ¬å¤„ç†ç­–ç•¥ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09935v1",
      "published_date": "2025-07-14 05:21:58 UTC",
      "updated_date": "2025-07-14 05:21:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:01.249430+00:00"
    },
    {
      "arxiv_id": "2507.09931v2",
      "title": "Mechanistic Interpretability of LoRA-Adapted Language Models for Nuclear Reactor Safety Applications",
      "title_zh": "é¢å‘æ ¸ååº”å †å®‰å…¨åº”ç”¨çš„ LoRA é€‚é…è¯­è¨€æ¨¡å‹æœºæ¢°å¯è§£é‡Šæ€§",
      "authors": [
        "Yoon Pyo Lee"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into safety-critical domains, such as nuclear engineering, necessitates a deep understanding of their internal reasoning processes. This paper presents a novel methodology for interpreting how an LLM encodes and utilizes domain-specific knowledge, using a Boiling Water Reactor system as a case study. We adapted a general-purpose LLM (Gemma-3-1b-it) to the nuclear domain using a parameter-efficient fine-tuning technique known as Low-Rank Adaptation. By comparing the neuron activation patterns of the base model to those of the fine-tuned model, we identified a sparse set of neurons whose behavior was significantly altered during the adaptation process. To probe the causal role of these specialized neurons, we employed a neuron silencing technique. Our results demonstrate that while silencing most of these specialized neurons individually did not produce a statistically significant effect, deactivating the entire group collectively led to a statistically significant degradation in task performance. Qualitative analysis further revealed that silencing these neurons impaired the model's ability to generate detailed, contextually accurate technical information. This paper provides a concrete methodology for enhancing the transparency of an opaque black-box model, allowing domain expertise to be traced to verifiable neural circuits. This offers a pathway towards achieving nuclear-grade artificial intelligence (AI) assurance, addressing the verification and validation challenges mandated by nuclear regulatory frameworks (e.g., 10 CFR 50 Appendix B), which have limited AI deployment in safety-critical nuclear operations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ ¸å·¥ç¨‹ç­‰å®‰å…¨è‡³å…³é‡è¦é¢†åŸŸï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡ Mechanistic Interpretability æ·±å…¥ç†è§£å¤§è¯­è¨€æ¨¡å‹(LLMs)å†…éƒ¨æ¨ç†è¿‡ç¨‹çš„æ–¹æ³•ã€‚ä½œè€…ä»¥æ²¸æ°´ååº”å †(Boiling Water Reactor)ä¸ºæ¡ˆä¾‹ï¼Œåˆ©ç”¨ Low-Rank Adaptation (LoRA) æŠ€æœ¯å°† Gemma-3-1b-it æ¨¡å‹è°ƒæ•´è‡³æ ¸èƒ½é¢†åŸŸã€‚é€šè¿‡å¯¹æ¯”åŸºç¡€æ¨¡å‹ä¸å¾®è°ƒæ¨¡å‹çš„ç¥ç»å…ƒæ¿€æ´»æ¨¡å¼ï¼Œç ”ç©¶è¯†åˆ«å‡ºäº†ä¸€ç»„åœ¨é€‚é…è¿‡ç¨‹ä¸­è¡Œä¸ºå‘ç”Ÿæ˜¾è‘—å˜åŒ–çš„ç¨€ç–ç¥ç»å…ƒã€‚ä¸ºéªŒè¯è¿™äº›ç‰¹å®šç¥ç»å…ƒçš„å› æœä½œç”¨ï¼Œç ”ç©¶é‡‡ç”¨äº†ç¥ç»å…ƒé™é»˜(neuron silencing)æŠ€æœ¯ï¼Œç»“æœæ˜¾ç¤ºé›†ä½“ç¦ç”¨è¿™ç»„ç¥ç»å…ƒä¼šå¯¼è‡´ä»»åŠ¡æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚å®šæ€§åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œé™é»˜è¿™äº›ç¥ç»å…ƒä¼šæŸå®³æ¨¡å‹ç”Ÿæˆè¯¦å°½ä¸”èƒŒæ™¯å‡†ç¡®çš„æŠ€æœ¯ä¿¡æ¯çš„èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ä¸ºé»‘ç›’æ¨¡å‹çš„é€æ˜åº¦æå‡æä¾›äº†å…·ä½“æ–¹æ³•è®ºï¼Œä½¿å¾—é¢†åŸŸä¸“ä¸šçŸ¥è¯†å¯ä»¥è¿½æº¯åˆ°å¯éªŒè¯çš„ç¥ç»ç”µè·¯(neural circuits)ã€‚è¿™ä¸ºå®ç°æ ¸çº§äººå·¥æ™ºèƒ½(Nuclear-grade AI)ä¿è¯æä¾›äº†è·¯å¾„ï¼Œæœ‰æ•ˆåº”å¯¹äº†å®‰å…¨å…³é”®å‹æ ¸æ“ä½œåœ¨ç›‘ç®¡æ¡†æ¶ä¸‹çš„éªŒè¯ä¸ç¡®è®¤æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in Nuclear Technology. 24 pages, 2 tables, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.09931v2",
      "published_date": "2025-07-14 05:17:41 UTC",
      "updated_date": "2025-09-15 07:21:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:08.318997+00:00"
    },
    {
      "arxiv_id": "2507.09929v2",
      "title": "Aligning Generative Speech Enhancement with Perceptual Feedback",
      "title_zh": "åŸºäºæ„ŸçŸ¥åé¦ˆçš„ç”Ÿæˆå¼è¯­éŸ³å¢å¼ºå¯¹é½",
      "authors": [
        "Haoyang Li",
        "Nana Hou",
        "Yuchen Hu",
        "Jixun Yao",
        "Sabato Marco Siniscalchi",
        "Xuyi Zhuang",
        "Deheng Ye",
        "Wei Yang",
        "Eng Siong Chng"
      ],
      "abstract": "Language Model (LM)-based speech enhancement (SE) has recently emerged as a promising direction, but existing approaches predominantly rely on token-level likelihood objectives that weakly reflect human perception. This mismatch limits progress, as optimizing signal accuracy does not always improve naturalness or listening comfort. We address this gap by introducing a perceptually aligned LM-based SE approach. Our method applies Direct Preference Optimization (DPO) with UTMOS, a neural MOS predictor, as a proxy for human ratings, directly steering models toward perceptually preferred outputs. This design directly connects model training to perceptual quality and is broadly applicable within LM-based SE frameworks. On the Deep Noise Suppression Challenge 2020 test sets, our approach consistently improves speech quality metrics, achieving relative gains of up to 56%. To our knowledge, this is the first integration of perceptual feedback into LM-based SE and the first application of DPO in the SE domain, establishing a new paradigm for perceptually aligned enhancement with SE.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºè¯­è¨€æ¨¡å‹(LM)çš„è¯­éŸ³å¢å¼º(SE)ä¸­ï¼ŒToken-level likelihoodç›®æ ‡ä¸äººç±»æ„ŸçŸ¥ä¸åŒ¹é…å¯¼è‡´è‡ªç„¶åº¦ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ„ŸçŸ¥å¯¹é½çš„æ”¹è¿›æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•é¦–æ¬¡å°†ç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO)å¼•å…¥SEé¢†åŸŸï¼Œå¹¶åˆ©ç”¨ç¥ç»MOSé¢„æµ‹å™¨UTMOSä½œä¸ºäººç±»è¯„åˆ†çš„ä»£ç†ï¼Œç›´æ¥å¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´ç¬¦åˆäººç±»æ„ŸçŸ¥åå¥½çš„è¾“å‡ºã€‚è¿™ç§è®¾è®¡æˆåŠŸå°†æ¨¡å‹è®­ç»ƒä¸æ„ŸçŸ¥è´¨é‡æŒ‚é’©ï¼Œä¸”åœ¨LM-based SEæ¡†æ¶ä¸­å…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚åœ¨Deep Noise Suppression Challenge 2020æµ‹è¯•é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä¸€è‡´æ€§åœ°æå‡äº†è¯­éŸ³è´¨é‡æŒ‡æ ‡ï¼Œç›¸å¯¹å¢ç›Šæœ€é«˜å¯è¾¾56%ã€‚ä½œä¸ºé¦–ä¸ªå°†æ„ŸçŸ¥åé¦ˆæ•´åˆè¿›LM-based SEå¹¶åº”ç”¨DPOæŠ€æœ¯çš„ç ”ç©¶ï¼Œè¯¥å·¥ä½œä¸ºæ„ŸçŸ¥å¯¹é½çš„è¯­éŸ³å¢å¼ºå»ºç«‹äº†ä¸€ç§å…¨æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2507.09929v2",
      "published_date": "2025-07-14 05:15:39 UTC",
      "updated_date": "2026-01-18 15:28:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:04.489596+00:00"
    },
    {
      "arxiv_id": "2507.09924v1",
      "title": "MixLoRA-DSI: Dynamically Expandable Mixture-of-LoRA Experts for Rehearsal-Free Generative Retrieval over Dynamic Corpora",
      "title_zh": "MixLoRA-DSIï¼šé¢å‘åŠ¨æ€è¯­æ–™åº“å…å›æ”¾ç”Ÿæˆå¼æ£€ç´¢çš„åŠ¨æ€å¯æ‰©å±• Mixture-of-LoRA ä¸“å®¶æ¡†æ¶",
      "authors": [
        "Tuan-Luc Huynh",
        "Thuy-Trang Vu",
        "Weiqing Wang",
        "Trung Le",
        "Dragan GaÅ¡eviÄ‡",
        "Yuan-Fang Li",
        "Thanh-Toan Do"
      ],
      "abstract": "Continually updating model-based indexes in generative retrieval with new documents remains challenging, as full retraining is computationally expensive and impractical under resource constraints. We propose MixLoRA-DSI, a novel framework that combines an expandable mixture of Low-Rank Adaptation experts with a layer-wise out-of-distribution (OOD)-driven expansion strategy. Instead of allocating new experts for each new corpus, our proposed expansion strategy enables sublinear parameter growth by selectively introducing new experts only when significant number of OOD documents are detected. Experiments on NQ320k and MS MARCO Passage demonstrate that MixLoRA-DSI outperforms full-model update baselines, with minimal parameter overhead and substantially lower training costs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MixLoRA-DSIï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³ç”Ÿæˆå¼æ£€ç´¢ (Generative Retrieval) ä¸­æ¨¡å‹ç´¢å¼•åŠ¨æ€æ›´æ–°éš¾é¢˜çš„åˆ›æ–°æ¡†æ¶ã€‚ç”±äºåœ¨èµ„æºå—é™ä¸‹è¿›è¡Œå…¨é‡é‡æ–°è®­ç»ƒæˆæœ¬æé«˜ï¼ŒMixLoRA-DSI ç»“åˆäº†å¯æ‰©å±•çš„ Mixture-of-LoRA ä¸“å®¶ç³»ç»Ÿä¸å±‚çº§åˆ†å¸ƒå¤– (OOD) é©±åŠ¨çš„æ‰©å±•ç­–ç•¥ã€‚è¯¥ç­–ç•¥é€šè¿‡åœ¨æ£€æµ‹åˆ°å¤§é‡ OOD æ–‡æ¡£æ—¶æ‰é€‰æ‹©æ€§åœ°å¼•å…¥æ–°ä¸“å®¶ï¼ŒæˆåŠŸå®ç°äº†å‚æ•°çš„äºšçº¿æ€§å¢é•¿ (Sublinear Parameter Growth)ï¼Œé¿å…äº†ä¸ºæ¯ä¸ªæ–°è¯­æ–™åº“è¿‡åº¦åˆ†é…èµ„æºã€‚å®éªŒåœ¨ NQ320k å’Œ MS MARCO Passage æ•°æ®é›†ä¸Šè¯æ˜ï¼ŒMixLoRA-DSI åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†å…¨æ¨¡å‹æ›´æ–°çš„åŸºå‡†æ¨¡å‹ã€‚è¯¥æ–¹æ³•åœ¨ä»…äº§ç”Ÿæå°å‚æ•°å¼€é”€çš„æƒ…å†µä¸‹ï¼Œå¤§å¹…é™ä½äº†è®­ç»ƒæˆæœ¬ï¼Œä¸ºåŠ¨æ€è¯­æ–™åº“ä¸‹çš„æ— æ’æ¼” (Rehearsal-Free) æ£€ç´¢æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09924v1",
      "published_date": "2025-07-14 05:04:32 UTC",
      "updated_date": "2025-07-14 05:04:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:10.431629+00:00"
    },
    {
      "arxiv_id": "2507.09901v1",
      "title": "Large Population Models",
      "title_zh": "å¤§äººå£æ¨¡å‹",
      "authors": [
        "Ayush Chopra"
      ],
      "abstract": "Many of society's most pressing challenges, from pandemic response to supply chain disruptions to climate adaptation, emerge from the collective behavior of millions of autonomous agents making decisions over time. Large Population Models (LPMs) offer an approach to understand these complex systems by simulating entire populations with realistic behaviors and interactions at unprecedented scale. LPMs extend traditional modeling approaches through three key innovations: computational methods that efficiently simulate millions of agents simultaneously, mathematical frameworks that learn from diverse real-world data streams, and privacy-preserving communication protocols that bridge virtual and physical environments. This allows researchers to observe how agent behavior aggregates into system-level outcomes and test interventions before real-world implementation. While current AI advances primarily focus on creating \"digital humans\" with sophisticated individual capabilities, LPMs develop \"digital societies\" where the richness of interactions reveals emergent phenomena. By bridging individual agent behavior and population-scale dynamics, LPMs offer a complementary path in AI research illuminating collective intelligence and providing testing grounds for policies and social innovations before real-world deployment. We discuss the technical foundations and some open problems here. LPMs are implemented by the AgentTorch framework (github.com/AgentTorch/AgentTorch)",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Large Population Models (LPMs)ï¼Œæ—¨åœ¨é€šè¿‡å¤§è§„æ¨¡æ¨¡æ‹Ÿæ•°ç™¾ä¸‡ä¸ªå…·æœ‰ç°å®è¡Œä¸ºå’Œäº’åŠ¨è§„å¾‹çš„è‡ªä¸»æ™ºèƒ½ä½“(autonomous agents)ï¼Œæ¥ç†è§£å¹¶è§£å†³æµè¡Œç—…å“åº”ã€ä¾›åº”é“¾ä¸­æ–­å’Œæ°”å€™é€‚åº”ç­‰å¤æ‚çš„ç¤¾ä¼šæŒ‘æˆ˜ã€‚LPMs æ‰©å±•äº†ä¼ ç»Ÿå»ºæ¨¡æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬èƒ½å¤ŸåŒæ—¶é«˜æ•ˆæ¨¡æ‹Ÿæ•°ç™¾ä¸‡ä¸ªæ™ºèƒ½ä½“çš„è®¡ç®—æ–¹æ³•ï¼Œä»¥åŠå¯ä»¥ä»å¤šå…ƒç°å®ä¸–ç•Œæ•°æ®æµä¸­å­¦ä¹ çš„æ•°å­¦æ¡†æ¶ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹é›†æˆäº†ä¿æŠ¤éšç§çš„é€šä¿¡åè®®ï¼Œæœ‰æ•ˆè¡”æ¥äº†è™šæ‹Ÿä¸ç‰©ç†ç¯å¢ƒï¼Œå¹¶ä¾æ‰˜ AgentTorch æ¡†æ¶å®ç°äº†æŠ€æœ¯çš„å…·ä½“è½åœ°ã€‚ä¸ç›®å‰ä¾§é‡äºæå‡ä¸ªä½“æ™ºèƒ½çš„â€œæ•°å­—äººç±»â€AIç ”ç©¶ä¸åŒï¼ŒLPMs ä¸“æ³¨äºæ„å»ºâ€œæ•°å­—ç¤¾ä¼šâ€ï¼Œé€šè¿‡ç ”ç©¶æ™ºèƒ½ä½“è¡Œä¸ºçš„èšåˆè¿‡ç¨‹æ¥æ­ç¤ºå¤æ‚çš„çªç°ç°è±¡(emergent phenomena)ã€‚è¯¥æ¨¡å‹åœ¨ä¸ªä½“è¡Œä¸ºä¸ç¾¤ä½“åŠ¨åŠ›å­¦ä¹‹é—´å»ºç«‹äº†æ¡¥æ¢ï¼Œä¸ºæ”¿ç­–æµ‹è¯•å’Œç¤¾ä¼šåˆ›æ–°åœ¨å®é™…éƒ¨ç½²å‰æä¾›äº†ç†æƒ³çš„æ¨¡æ‹Ÿå®éªŒåœºã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Aggregation of Several Papers from MIT PhD Research. github.com/AgentTorch/AgentTorch",
      "pdf_url": "https://arxiv.org/pdf/2507.09901v1",
      "published_date": "2025-07-14 04:11:54 UTC",
      "updated_date": "2025-07-14 04:11:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:26.328851+00:00"
    },
    {
      "arxiv_id": "2507.09898v2",
      "title": "Advanced U-Net Architectures with CNN Backbones for Automated Lung Cancer Detection and Segmentation in Chest CT Images",
      "title_zh": "åŸºäº CNN éª¨å¹²ç½‘ç»œçš„å…ˆè¿› U-Net æ¶æ„ï¼šç”¨äºèƒ¸éƒ¨ CT å›¾åƒçš„è‚ºç™Œè‡ªåŠ¨æ£€æµ‹ä¸åˆ†å‰²",
      "authors": [
        "Alireza Golkarieh",
        "Kiana Kiashemshaki",
        "Sajjad Rezvani Boroujeni",
        "Nasibeh Asadi Isakan"
      ],
      "abstract": "This study investigates the effectiveness of U-Net architectures integrated with various convolutional neural network (CNN) backbones for automated lung cancer detection and segmentation in chest CT images, addressing the critical need for accurate diagnostic tools in clinical settings. A balanced dataset of 832 chest CT images (416 cancerous and 416 non-cancerous) was preprocessed using Contrast Limited Adaptive Histogram Equalization (CLAHE) and resized to 128x128 pixels. U-Net models were developed with three CNN backbones: ResNet50, VGG16, and Xception, to segment lung regions. After segmentation, CNN-based classifiers and hybrid models combining CNN feature extraction with traditional machine learning classifiers (Support Vector Machine, Random Forest, and Gradient Boosting) were evaluated using 5-fold cross-validation. Metrics included accuracy, precision, recall, F1-score, Dice coefficient, and ROC-AUC. U-Net with ResNet50 achieved the best performance for cancerous lungs (Dice: 0.9495, Accuracy: 0.9735), while U-Net with VGG16 performed best for non-cancerous segmentation (Dice: 0.9532, Accuracy: 0.9513). For classification, the CNN model using U-Net with Xception achieved 99.1 percent accuracy, 99.74 percent recall, and 99.42 percent F1-score. The hybrid CNN-SVM-Xception model achieved 96.7 percent accuracy and 97.88 percent F1-score. Compared to prior methods, our framework consistently outperformed existing models. In conclusion, combining U-Net with advanced CNN backbones provides a powerful method for both segmentation and classification of lung cancer in CT scans, supporting early diagnosis and clinical decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é›†æˆå¤šç§å·ç§¯ç¥ç»ç½‘ç»œ(CNN)éª¨å¹²ç½‘ç»œçš„U-Netæ¶æ„åœ¨èƒ¸éƒ¨CTå›¾åƒè‚ºç™Œè‡ªåŠ¨æ£€æµ‹ä¸åˆ†å‰²ä¸­çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨CLAHEæŠ€æœ¯é¢„å¤„ç†äº†832å¼ å¹³è¡¡çš„CTå›¾åƒæ•°æ®é›†ï¼Œå¹¶å¯¹æ¯”äº†ResNet50ã€VGG16å’ŒXceptionä¸‰ç§éª¨å¹²ç½‘ç»œå¯¹è‚ºéƒ¨åŒºåŸŸçš„åˆ†å‰²æ•ˆæœã€‚å®éªŒå‘ç°ï¼Œæ­è½½ResNet50çš„U-Netåœ¨ç™Œå˜è‚ºéƒ¨åˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼ŒDiceç³»æ•°è¾¾åˆ°0.9495ï¼Œè€ŒåŸºäºXceptionçš„CNNåˆ†ç±»æ¨¡å‹å®ç°äº†99.1%çš„å‡†ç¡®ç‡å’Œ99.42%çš„F1-scoreã€‚ç ”ç©¶è¿˜è¿›ä¸€æ­¥è¯„ä¼°äº†å°†CNNç‰¹å¾æå–ä¸Support Vector Machine (SVM)ã€Random Forestç­‰ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»å™¨ç»“åˆçš„æ··åˆæ¨¡å‹æ€§èƒ½ã€‚è¯¥æ¡†æ¶åœ¨ä¸å…ˆå‰æ–¹æ³•çš„å¯¹æ¯”ä¸­å±•ç°å‡ºæŒç»­çš„æ€§èƒ½ä¼˜åŠ¿ï¼Œä¸ºä¸´åºŠç¯å¢ƒä¸‹çš„è‚ºç™Œè‡ªåŠ¨åŒ–åˆ†å‰²ä¸åˆ†ç±»æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†å…ˆè¿›éª¨å¹²ç½‘ç»œä¸U-Netç»“åˆåœ¨æå‡æ—©æœŸè¯Šæ–­ç²¾åº¦å’Œè¾…åŠ©ä¸´åºŠå†³ç­–æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "This manuscript has 20 pages and 10 figures. It is submitted to the Journal 'Scientific Reports'",
      "pdf_url": "https://arxiv.org/pdf/2507.09898v2",
      "published_date": "2025-07-14 04:08:33 UTC",
      "updated_date": "2025-07-22 23:40:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:29.033343+00:00"
    },
    {
      "arxiv_id": "2507.10624v3",
      "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning",
      "title_zh": "æœ‰ç†è§£è€Œæ— èƒœä»»åŠ›ï¼šå¤§è¯­è¨€æ¨¡å‹åœ¨ç¬¦å·è®¡ç®—ä¸æ¨ç†ä¸­çš„æ¶æ„å±€é™",
      "authors": [
        "Zheng Zhang"
      ],
      "abstract": "Large Language Models (LLMs) display striking surface fluency yet systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy, and logical consistency. This paper offers a structural diagnosis of such failures, revealing a persistent gap between \\textit{comprehension} and \\textit{competence}. Through controlled experiments and architectural analysis, we demonstrate that LLMs often articulate correct principles without reliably applying them--a failure rooted not in knowledge access, but in computational execution. We term this phenomenon the computational \\textit{split-brain syndrome}, where instruction and action pathways are geometrically and functionally dissociated. This core limitation recurs across domains, from mathematical operations to relational inferences, and explains why model behavior remains brittle even under idealized prompting. We argue that LLMs function as powerful pattern completion engines, but lack the architectural scaffolding for principled, compositional reasoning. Our findings delineate the boundary of current LLM capabilities and motivate future models with metacognitive control, principle lifting, and structurally grounded execution. This diagnosis also clarifies why mechanistic interpretability findings may reflect training-specific pattern coordination rather than universal computational principles, and why the geometric separation between instruction and execution pathways suggests limitations in neural introspection and mechanistic analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¡¨é¢æµç•…æ€§ä¸ç¬¦å·æ¨ç†ã€ç®—æœ¯å‡†ç¡®æ€§åŠé€»è¾‘ä¸€è‡´æ€§æ–¹é¢çš„ç³»ç»Ÿæ€§å¤±è´¥ï¼Œå¹¶æ­ç¤ºäº†ç†è§£(comprehension)ä¸èƒ½åŠ›(competence)ä¹‹é—´å­˜åœ¨çš„æŒä¹…å·®è·ã€‚é€šè¿‡æ§åˆ¶å®éªŒå’Œæ¶æ„åˆ†æï¼Œä½œè€…æŒ‡å‡ºæ¨¡å‹å¾€å¾€èƒ½é˜è¿°æ­£ç¡®åŸåˆ™å´æ— æ³•å¯é æ‰§è¡Œï¼Œè¿™ç§æŒ‡ä»¤ä¸åŠ¨ä½œè·¯å¾„åœ¨å‡ ä½•å’ŒåŠŸèƒ½ä¸Šçš„åˆ†ç¦»è¢«å®šä¹‰ä¸ºè®¡ç®—åˆ†è„‘ç»¼åˆå¾(computational split-brain syndrome)ã€‚ç ”ç©¶è¡¨æ˜LLMsæœ¬è´¨ä¸Šæ˜¯å¼ºå¤§çš„æ¨¡å¼è¡¥å…¨å¼•æ“(pattern completion engines)ï¼Œä½†ç”±äºç¼ºä¹åŸåˆ™æ€§ã€ç»„åˆå¼æ¨ç†çš„æ¶æ„æ”¯æ’‘ï¼Œå…¶è¡Œä¸ºåœ¨å¤æ‚ä»»åŠ¡ä¸­ä¾ç„¶ååˆ†è„†å¼±ã€‚è¿™äº›å‘ç°ä¸ä»…åˆ’å®šäº†å½“å‰AIèƒ½åŠ›çš„è¾¹ç•Œï¼Œè¿˜ä¸ºå¼€å‘å…·å¤‡å…ƒè®¤çŸ¥æ§åˆ¶(metacognitive control)å’Œç»“æ„åŒ–æ‰§è¡Œèƒ½åŠ›çš„æœªæ¥æ¨¡å‹æä¾›äº†æ–¹å‘ã€‚æ­¤å¤–ï¼Œè¯¥è¯Šæ–­è¿˜æ¾„æ¸…äº†æœºæ¢°å¯è§£é‡Šæ€§(mechanistic interpretability)ç ”ç©¶ä¸­çš„å±€é™æ€§ï¼ŒæŒ‡å‡ºäº†ç¥ç»å†…çœä¸æœºåˆ¶åˆ†æé¢ä¸´çš„æ¶æ„éšœç¢ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "v2: Two TMLR revision rounds addressing reviewer feedback. Added real-world validation (3.4), interpretability analysis (7), computational hallucination framework, strengthened theory. v3: Sec 3.2 - added transformer architecture diagram, clarified UAT capacity vs computational limits, improved role specialization theorem presentation",
      "pdf_url": "https://arxiv.org/pdf/2507.10624v3",
      "published_date": "2025-07-14 04:01:45 UTC",
      "updated_date": "2025-11-14 15:49:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:28.089102+00:00"
    },
    {
      "arxiv_id": "2507.09891v1",
      "title": "Sequence-Model-Guided Measurement Selection for Quantum State Learning",
      "title_zh": "åºåˆ—æ¨¡å‹å¼•å¯¼çš„é‡å­æ€å­¦ä¹ æµ‹é‡é€‰æ‹©",
      "authors": [
        "Jiaxin Huang",
        "Yan Zhu",
        "Giulio Chiribella",
        "Ya-Dong Wu"
      ],
      "abstract": "Characterization of quantum systems from experimental data is a central problem in quantum science and technology. But which measurements should be used to gather data in the first place? While optimal measurement choices can be worked out for small quantum systems, the optimization becomes intractable as the system size grows large. To address this problem, we introduce a deep neural network with a sequence model architecture that searches for efficient measurement choices in a data-driven, adaptive manner. The model can be applied to a variety of tasks, including the prediction of linear and nonlinear properties of quantum states, as well as state clustering and state tomography tasks. In all these tasks, we find that the measurement choices identified by our neural network consistently outperform the uniformly random choice. Intriguingly, for topological quantum systems, our model tends to recommend measurements at the system's boundaries, even when the task is to predict bulk properties. This behavior suggests that the neural network may have independently discovered a connection between boundaries and bulk, without having been provided any built-in knowledge of quantum physics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡å­ç³»ç»Ÿè¡¨å¾ä¸­éšç€ç³»ç»Ÿè§„æ¨¡å¢é•¿è€Œå¯¼è‡´çš„æœ€ä¼˜æµ‹é‡é€‰æ‹©éš¾ç‚¹ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåºåˆ—æ¨¡å‹ (Sequence Model) æ¶æ„çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œç”¨äºä»¥æ•°æ®é©±åŠ¨çš„è‡ªé€‚åº”æ–¹å¼æœç´¢é«˜æ•ˆæµ‹é‡æ–¹æ¡ˆã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå¤„ç†é‡å­æ€çº¿æ€§ä¸éçº¿æ€§å±æ€§é¢„æµ‹ã€æ€èšç±» (State Clustering) åŠæ€æ–­å±‚æ‰«æ (State Tomography) ç­‰å¤šç§ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¨¡å‹è¯†åˆ«çš„æµ‹é‡é€‰æ‹©åœ¨å„é¡¹ä»»åŠ¡ä¸­å‡æŒç»­ä¼˜äºå‡åŒ€éšæœºé€‰æ‹©ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤„ç†æ‹“æ‰‘é‡å­ç³»ç»Ÿæ—¶ï¼Œæ¨¡å‹è¡¨ç°å‡ºå€¾å‘äºé€šè¿‡è¾¹ç•Œæµ‹é‡æ¥é¢„æµ‹ä½“ (Bulk) å±æ€§çš„ç‹¬ç‰¹ç‰¹æ€§ã€‚è¿™ç§è¡Œä¸ºæš—ç¤ºäº†è¯¥ç¥ç»ç½‘ç»œåœ¨æ— éœ€å…ˆéªŒç‰©ç†çŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿè‡ªä¸»å‘ç°é‡å­ç‰©ç†ä¸­è¾¹ç•Œä¸ä½“ä¹‹é—´çš„å†…åœ¨å…³è”ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09891v1",
      "published_date": "2025-07-14 03:50:42 UTC",
      "updated_date": "2025-07-14 03:50:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:34.532060+00:00"
    },
    {
      "arxiv_id": "2507.09890v1",
      "title": "Soft Graph Clustering for single-cell RNA Sequencing Data",
      "title_zh": "é¢å‘å•ç»†èƒ RNA æµ‹åºæ•°æ®çš„è½¯å›¾èšç±»",
      "authors": [
        "Ping Xu",
        "Pengfei Wang",
        "Zhiyuan Ning",
        "Meng Xiao",
        "Min Wu",
        "Yuanchun Zhou"
      ],
      "abstract": "Clustering analysis is fundamental in single-cell RNA sequencing (scRNA-seq) data analysis for elucidating cellular heterogeneity and diversity. Recent graph-based scRNA-seq clustering methods, particularly graph neural networks (GNNs), have significantly improved in tackling the challenges of high-dimension, high-sparsity, and frequent dropout events that lead to ambiguous cell population boundaries. However, their reliance on hard graph constructions derived from thresholded similarity matrices presents challenges:(i) The simplification of intercellular relationships into binary edges (0 or 1) by applying thresholds, which restricts the capture of continuous similarity features among cells and leads to significant information loss.(ii) The presence of significant inter-cluster connections within hard graphs, which can confuse GNN methods that rely heavily on graph structures, potentially causing erroneous message propagation and biased clustering outcomes. To tackle these challenges, we introduce scSGC, a Soft Graph Clustering for single-cell RNA sequencing data, which aims to more accurately characterize continuous similarities among cells through non-binary edge weights, thereby mitigating the limitations of rigid data structures. The scSGC framework comprises three core components: (i) a zero-inflated negative binomial (ZINB)-based feature autoencoder; (ii) a dual-channel cut-informed soft graph embedding module; and (iii) an optimal transport-based clustering optimization module. Extensive experiments across ten datasets demonstrate that scSGC outperforms 13 state-of-the-art clustering models in clustering accuracy, cell type annotation, and computational efficiency. These results highlight its substantial potential to advance scRNA-seq data analysis and deepen our understanding of cellular heterogeneity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å•ç»†èƒ RNA æµ‹åº (scRNA-seq) æ•°æ®åˆ†æä¸­å›¾ç¥ç»ç½‘ç»œ (GNNs) ä¾èµ–ç¡¬å›¾ (hard graph) æ„å»ºæ‰€å¯¼è‡´çš„è¿ç»­ç›¸ä¼¼æ€§æ•æ‰å—é™åŠä¿¡æ¯æŸå¤±ç­‰é—®é¢˜ï¼Œæå‡ºäº†åä¸º scSGC çš„è½¯å›¾èšç±»æ¡†æ¶ã€‚scSGC åˆ›æ–°æ€§åœ°é‡‡ç”¨éäºŒè¿›åˆ¶è¾¹æƒé‡æ¥è¡¨å¾ç»†èƒé—´çš„è¿ç»­ç›¸ä¼¼æ€§ï¼Œæœ‰æ•ˆç¼“è§£äº†ä¼ ç»Ÿç¡¬å›¾åœ¨å¤„ç†é«˜ç»´ã€é«˜ç¨€ç–å’Œæ‰åº“ (dropout) äº‹ä»¶æ—¶çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶æ•´åˆäº†ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šåŸºäºé›¶è†¨èƒ€è´ŸäºŒé¡¹åˆ†å¸ƒ (ZINB) çš„ç‰¹å¾è‡ªåŠ¨ç¼–ç å™¨ã€åŒé€šé“åˆ‡å£æ„ŸçŸ¥è½¯å›¾åµŒå…¥æ¨¡å—ä»¥åŠåŸºäºæœ€ä¼˜ä¼ è¾“ (optimal transport) çš„èšç±»ä¼˜åŒ–æ¨¡å—ã€‚åœ¨åä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒscSGC åœ¨èšç±»å‡†ç¡®æ€§ã€ç»†èƒç±»å‹æ ‡æ³¨å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äº 13 ç§æœ€å…ˆè¿›çš„èšç±»æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œä¸ä»…æå‡äº† scRNA-seq æ•°æ®åˆ†æçš„ç²¾åº¦ï¼Œä¹Ÿä¸ºæ·±å…¥ç†è§£ç»†èƒå¼‚è´¨æ€§å’Œå¤šæ ·æ€§æä¾›äº†å¼ºæœ‰åŠ›çš„è®¡ç®—å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09890v1",
      "published_date": "2025-07-14 03:49:12 UTC",
      "updated_date": "2025-07-14 03:49:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:42.345010+00:00"
    },
    {
      "arxiv_id": "2507.09888v2",
      "title": "NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting",
      "title_zh": "NeuTSFlowï¼šæ—¶é—´åºåˆ—é¢„æµ‹èƒŒåçš„è¿ç»­å‡½æ•°å»ºæ¨¡",
      "authors": [
        "Huibo Xu",
        "Likang Wu",
        "Xianquan Wang",
        "Haoning Dang",
        "Chun-Wun Cheng",
        "Angelica I Aviles-Rivero",
        "Qi Liu"
      ],
      "abstract": "Time series forecasting is a fundamental task with broad applications, yet conventional methods often treat data as discrete sequences, overlooking their origin as noisy samples of continuous processes. Crucially, discrete noisy observations cannot uniquely determine a continuous function; instead, they correspond to a family of plausible functions. Mathematically, time series can be viewed as noisy observations of a continuous function family governed by a shared probability measure. Thus, the forecasting task can be framed as learning the transition from the historical function family to the future function family. This reframing introduces two key challenges: (1) How can we leverage discrete historical and future observations to learn the relationships between their underlying continuous functions? (2) How can we model the transition path in function space from the historical function family to the future function family? To address these challenges, we propose NeuTSFlow, a novel framework that leverages Neural Operators to facilitate flow matching for learning path of measure between historical and future function families. By parameterizing the velocity field of the flow in infinite-dimensional function spaces, NeuTSFlow moves beyond traditional methods that focus on dependencies at discrete points, directly modeling function-level features instead. Experiments on diverse forecasting tasks demonstrate NeuTSFlow's superior accuracy and robustness, validating the effectiveness of the function-family perspective.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† NeuTSFlow æ¡†æ¶ï¼Œé€šè¿‡å°†æ—¶é—´åºåˆ—è§†ä¸ºè¿ç»­å‡½æ•°æ—çš„å™ªå£°è§‚æµ‹ï¼Œè§£å†³äº†ä¼ ç»Ÿç¦»æ•£åºåˆ—å»ºæ¨¡å¿½ç•¥åº•å±‚è¿ç»­è¿‡ç¨‹çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°åˆ©ç”¨ Neural Operators ç»“åˆ Flow Matching æŠ€æœ¯ï¼Œåœ¨æ— é™ç»´å‡½æ•°ç©ºé—´ä¸­å»ºæ¨¡ä»å†å²å‡½æ•°æ—åˆ°æœªæ¥å‡½æ•°æ—çš„æµ‹åº¦æ¼”å˜è·¯å¾„ã€‚é€šè¿‡å‚æ•°åŒ–æµçš„é€Ÿåº¦åœº (velocity field)ï¼ŒNeuTSFlow è¶…è¶Šäº†ä»…å…³æ³¨ç¦»æ•£ç‚¹ä¾èµ–å…³ç³»çš„ä¼ ç»Ÿæ–¹æ³•ï¼Œå®ç°äº†å¯¹å‡½æ•°å±‚é¢ç‰¹å¾çš„ç›´æ¥æå–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNeuTSFlow åœ¨å¤šç§æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼ŒéªŒè¯äº†ä»å‡½æ•°æ—è§†è§’è¿›è¡Œè¿ç»­å»ºæ¨¡çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09888v2",
      "published_date": "2025-07-14 03:48:48 UTC",
      "updated_date": "2025-07-16 12:16:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:42.187943+00:00"
    },
    {
      "arxiv_id": "2507.09887v4",
      "title": "TolerantECG: A Foundation Model for Imperfect Electrocardiogram",
      "title_zh": "TolerantECGï¼šé¢å‘éç†æƒ³å¿ƒç”µå›¾çš„åŸºåº§æ¨¡å‹",
      "authors": [
        "Huynh Dang Nguyen",
        "Trong-Thang Pham",
        "Ngan Le",
        "Van Nguyen"
      ],
      "abstract": "The electrocardiogram (ECG) is an essential and effective tool for diagnosing heart diseases. However, its effectiveness can be compromised by noise or unavailability of one or more leads of the standard 12-lead recordings, resulting in diagnostic errors or uncertainty. To address these challenges, we propose TolerantECG, a foundation model for ECG signals that is robust to noise and capable of functioning with arbitrary subsets of the standard 12-lead ECG. TolerantECG training combines contrastive and self-supervised learning frameworks to jointly learn ECG signal representations alongside their corresponding knowledge-retrieval-based text report descriptions and corrupted or lead-missing signals. Comprehensive benchmarking results demonstrate that TolerantECG consistently ranks as the best or second-best performer across various ECG signal conditions and class levels in the PTB-XL dataset, and achieves the highest performance on the MIT-BIH Arrhythmia Database.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† TolerantECGï¼Œä¸€ç§é’ˆå¯¹ä¸å®Œç¾å¿ƒç”µå›¾ä¿¡å·è®¾è®¡çš„åŸºåº§æ¨¡å‹ (Foundation Model)ï¼Œæ—¨åœ¨è§£å†³å¿ƒç”µå›¾ (ECG) åœ¨å®é™…åº”ç”¨ä¸­å› å™ªå£°å¹²æ‰°æˆ–å¯¼è”ç¼ºå¤±å¯¼è‡´çš„è¯Šæ–­éš¾é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆå¯¹æ¯”å­¦ä¹  (Contrastive Learning) ä¸è‡ªç›‘ç£å­¦ä¹  (Self-supervised Learning) æ¡†æ¶ï¼Œå…±åŒå­¦ä¹ å¿ƒç”µä¿¡å·åŠå…¶å¯¹åº”çš„åŸºäºçŸ¥è¯†æ£€ç´¢ (Knowledge-retrieval-based) çš„æ–‡æœ¬æŠ¥å‘Šæè¿°ã€‚TolerantECG èƒ½å¤Ÿå¤„ç†ä»»æ„å¯¼è”å­é›†çš„è¾“å…¥å¹¶å¯¹å—æŸä¿¡å·å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ï¼Œä»è€Œåœ¨å¤æ‚æ¡ä»¶ä¸‹æå–é«˜è´¨é‡çš„ä¿¡å·è¡¨ç¤ºã€‚åŸºå‡†æµ‹è¯•ç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ PTB-XL æ•°æ®é›†çš„å„ç§ä¿¡å·æ¡ä»¶å’Œç–¾ç—…åˆ†ç±»ä¸­å§‹ç»ˆååˆ—å‰èŒ…ï¼Œå¹¶åœ¨ MIT-BIH Arrhythmia Database ä¸Šå®ç°äº†æœ€é«˜æ€§èƒ½ã€‚è¿™ä¸€ç ”ç©¶ä¸ºä¸´åºŠç¯å¢ƒä¸‹å¤„ç†ä¸å®Œæ•´æˆ–å—å¹²æ‰°çš„ ECG æ•°æ®æä¾›äº†ç¨³å¥çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACM MM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.09887v4",
      "published_date": "2025-07-14 03:48:35 UTC",
      "updated_date": "2025-10-06 02:30:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:45.872848+00:00"
    },
    {
      "arxiv_id": "2507.09884v3",
      "title": "VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains",
      "title_zh": "VerifyBenchï¼šè·¨é¢†åŸŸæ¨ç†éªŒè¯å™¨ç³»ç»ŸåŒ–è¯„æµ‹åŸºå‡†",
      "authors": [
        "Xuzhao Li",
        "Xuchen Li",
        "Shiyu Hu",
        "Yongzhen Guo",
        "Wentao Zhang"
      ],
      "abstract": "Large language models (LLMs) increasingly rely on reinforcement learning (RL) to enhance their reasoning capabilities through feedback. A critical challenge is verifying the consistency of model-generated responses and reference answers, since these responses are often lengthy, diverse, and nuanced. Rule-based verifiers struggle with complexity, prompting the use of model-based verifiers. However, specialized verifiers lack flexibility, while general LLM judges can be inconsistent. Existing research primarily focuses on building better verifiers, yet a systematic evaluation of different types of verifiers' performance across domains remains lacking, severely constraining the reliable development of Reinforcement Learning with Verifiable Reward (RLVR). To address this, we propose VerifyBench--a cross-domain comprehensive benchmark for systematically evaluating verifiers. We construct 4,000 expert-level questions covering mathematics, physics, chemistry, and biology. Each question is equipped with reference answers and diverse responses. The reliability of the evaluation is ensured through a rigorous annotation process conducted by a multidisciplinary expert team. We design a four-dimensional experimental framework to comprehensively compare the performance boundaries of specialized verifiers and general LLMs under combined conditions of extracted answers vs. complete responses, and short vs. long outputs. Our evaluation uncovers fundamental trade-offs in verifiers: while specialized verifiers achieve leading accuracy, they exhibit deficiencies in recall; general models show stronger inclusivity but unstable precision. More importantly, we discover verifiers' high sensitivity to input structure and inherent limitations in cross-domain generalization, providing critical insights into the bottlenecks of current verifier technology.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VerifyBenchï¼Œä¸€ä¸ªè·¨é¢†åŸŸçš„ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼°æ¨ç†éªŒè¯å™¨(Reasoning Verifiers)çš„æ€§èƒ½ã€‚ä¸ºåº”å¯¹Rule-based verifierså’Œé€šç”¨LLMæ³•å®˜åœ¨éªŒè¯å¤§æ¨¡å‹å¤æ‚è¾“å‡ºæ—¶é¢ä¸´çš„ä¸€è‡´æ€§ä¸çµæ´»æ€§æŒ‘æˆ˜ï¼ŒVerifyBenchæ„å»ºäº†æ¶µç›–æ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦å’Œç”Ÿç‰©é¢†åŸŸçš„4,000ä¸ªä¸“å®¶çº§é—®é¢˜ã€‚ç ”ç©¶è®¾è®¡äº†ä¸€ä¸ªå››ç»´å®éªŒæ¡†æ¶ï¼Œä»æå–ç­”æ¡ˆä¸å®Œæ•´å“åº”ã€çŸ­æœŸä¸é•¿æœŸè¾“å‡ºç­‰ç»´åº¦ï¼Œå…¨é¢å¯¹æ¯”Specialized verifiersä¸é€šç”¨å¤§è¯­è¨€æ¨¡å‹çš„æ€§èƒ½è¾¹ç•Œã€‚å®éªŒç»“æœæ­ç¤ºäº†éªŒè¯å™¨å­˜åœ¨çš„å…³é”®æƒè¡¡ï¼šä¸“ç”¨éªŒè¯å™¨å‡†ç¡®ç‡é¢†å…ˆä½†å¬å›ç‡ä¸è¶³ï¼Œè€Œé€šç”¨æ¨¡å‹åŒ…å®¹æ€§å¼ºä½†ç²¾ç¡®åº¦ä¸ç¨³å®šã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å‘ç°éªŒè¯å™¨å¯¹è¾“å…¥ç»“æ„é«˜åº¦æ•æ„Ÿï¼Œä¸”åœ¨è·¨é¢†åŸŸæ³›åŒ–ä¸Šå­˜åœ¨å›ºæœ‰å±€é™ï¼Œä¸ºReinforcement Learning with Verifiable Reward (RLVR) çš„å¯é å¼€å‘æä¾›äº†é‡è¦æ´è§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint, Under review",
      "pdf_url": "https://arxiv.org/pdf/2507.09884v3",
      "published_date": "2025-07-14 03:45:24 UTC",
      "updated_date": "2025-07-26 11:17:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:51.501689+00:00"
    },
    {
      "arxiv_id": "2507.09879v2",
      "title": "Covering a Few Submodular Constraints and Applications",
      "title_zh": "è‹¥å¹²å­æ¨¡çº¦æŸçš„è¦†ç›–åŠå…¶åº”ç”¨",
      "authors": [
        "Tanvi Bajpai",
        "Chandra Chekuri",
        "Pooja Kulkarni"
      ],
      "abstract": "We consider the problem of covering multiple submodular constraints. Given a finite ground set $N$, a cost function $c: N \\rightarrow \\mathbb{R}_+$, $r$ monotone submodular functions $f_1,f_2,\\ldots,f_r$ over $N$ and requirements $b_1,b_2,\\ldots,b_r$ the goal is to find a minimum cost subset $S \\subseteq N$ such that $f_i(S) \\ge b_i$ for $1 \\le i \\le r$. When $r=1$ this is the well-known Submodular Set Cover problem. Previous work \\cite{chekuri2022covering} considered the setting when $r$ is large and developed bi-criteria approximation algorithms, and approximation algorithms for the important special case when each $f_i$ is a weighted coverage function. These are fairly general models and capture several concrete and interesting problems as special cases. The approximation ratios for these problem are at least $Î©(\\log r)$ which is unavoidable when $r$ is part of the input. In this paper, motivated by some recent applications, we consider the problem when $r$ is a \\emph{fixed constant} and obtain two main results. For covering multiple submodular constraints we obtain a randomized bi-criteria approximation algorithm that for any given integer $Î±\\ge 1$ outputs a set $S$ such that $f_i(S) \\ge$ $(1-1/e^Î±-Îµ)b_i$ for each $i \\in [r]$ and $\\mathbb{E}[c(S)] \\le (1+Îµ)Î±\\cdot \\sf{OPT}$. Second, when the $f_i$ are weighted coverage functions from a deletion-closed set system we obtain a $(1+Îµ)$ $(\\frac{e}{e-1})$ $(1+Î²)$-approximation where $Î²$ is the approximation ratio for the underlying set cover instances via the natural LP. These results show that one can obtain nearly as good an approximation for any fixed $r$ as what one would achieve for $r=1$. We mention some applications that follow easily from these general results and anticipate more in the future.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è¦†ç›–å¤šä¸ªå­æ¨¡çº¦æŸ (Submodular Constraints) çš„ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œæ—¨åœ¨æ»¡è¶³å¤šä¸ªå•è°ƒå­æ¨¡å‡½æ•°éœ€æ±‚çš„åŒæ—¶æœ€å°åŒ–é€‰å–å­é›†çš„æˆæœ¬ã€‚é’ˆå¯¹çº¦æŸæ•°é‡ $r$ ä¸ºå›ºå®šå¸¸æ•°çš„æƒ…æ™¯ï¼Œæœ¬æ–‡æå‡ºäº†ä¸¤ç§ä¸»è¦ç®—æ³•æˆæœï¼Œå¼¥è¡¥äº†ä»¥å¾€ç ”ç©¶åœ¨å¤„ç†å¤šçº¦æŸæ—¶è¿‘ä¼¼æ¯”å— $\\Omega(\\log r)$ é™åˆ¶çš„ä¸è¶³ã€‚é¦–å…ˆï¼Œé’ˆå¯¹é€šç”¨å­æ¨¡çº¦æŸï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§éšæœºåŒå‡†åˆ™è¿‘ä¼¼ç®—æ³• (Randomized Bi-criteria Approximation Algorithm)ï¼Œé€šè¿‡å‚æ•° $\\alpha$ æƒè¡¡æˆæœ¬ä¸çº¦æŸæ»¡è¶³åº¦ï¼Œå®ç°äº†æ¥è¿‘æœ€ä¼˜æˆæœ¬çš„é¢„æœŸè¡¨ç°ã€‚å…¶æ¬¡ï¼Œå¯¹äºåˆ é™¤é—­åˆç³»ç»Ÿä¸‹çš„åŠ æƒè¦†ç›–å‡½æ•° (Weighted Coverage Functions)ï¼Œæœ¬æ–‡æ¨å¯¼å‡ºä¸€ç§ç»“åˆäº†è‡ªç„¶çº¿æ€§è§„åˆ’ (LP) è¿‘ä¼¼æ¯”çš„ç»„åˆè¿‘ä¼¼ç®—æ³•ã€‚ç†è®ºè¯æ˜æ˜¾ç¤ºï¼Œå½“çº¦æŸæ•°é‡å›ºå®šæ—¶ï¼Œè¯¥ç®—æ³•èƒ½è¾¾åˆ°ä¸å•ä¸€å­æ¨¡é›†åˆè¦†ç›– (Submodular Set Cover) è¿‘ä¹ä¸€è‡´çš„è¿‘ä¼¼æ•ˆæœã€‚è¿™äº›é€šç”¨æ€§ç»“è®ºä¸ºè§£å†³å…·æœ‰å¤šé‡çº¦æŸçš„å¤æ‚å­æ¨¡ä¼˜åŒ–é—®é¢˜æä¾›äº†å¼ºæœ‰åŠ›çš„ç†è®ºæ”¯æ’‘ä¸åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.DS",
      "comment": "34 pages. Accepted to APPROX 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.09879v2",
      "published_date": "2025-07-14 03:32:42 UTC",
      "updated_date": "2025-09-03 15:05:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:52.488152+00:00"
    },
    {
      "arxiv_id": "2507.09876v1",
      "title": "ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models",
      "title_zh": "ViTCoTï¼šç”¨äºå¢å¼ºå¤§è¯­è¨€æ¨¡å‹è§†é¢‘ç†è§£èƒ½åŠ›çš„è§†é¢‘-æ–‡æœ¬äº¤ç»‡é“¾å¼æ€ç»´",
      "authors": [
        "Yongheng Zhang",
        "Xu Liu",
        "Ruihan Tao",
        "Qiguang Chen",
        "Hao Fei",
        "Wanxiang Che",
        "Libo Qin"
      ],
      "abstract": "Video understanding plays a vital role in bridging low-level visual signals with high-level cognitive reasoning, and is fundamental to applications such as autonomous driving, embodied AI, and the broader pursuit of AGI. The rapid development of large language models (LLMs), particularly those utilizing Chain-of-Thought (CoT) technology, has significantly advanced video reasoning capabilities. However, current approaches primarily depend on textual information for reasoning, overlooking the visual modality in the actual video reasoning process. In contrast, humans naturally re-examine visual content while reasoning. Motivated by this, we introduce a novel video reasoning paradigm: Video-Text Interleaved CoT (ViTCoT), which facilitates more intuitive and cognitively aligned reasoning. To the end, first, we construct the Video-Text Interleaved Benchmark (ViTIB), which is created using MLLMs for key-video selection and manually verified. Furthermore, we extensively explore the potential of the ViTCoT paradigm in the video understanding field. Extensive experiments demonstrate that ViTCoT significantly enhances performance compared to the traditional text-only CoT paradigm and effectively activates more neuron values in MLLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ViTCoTï¼ˆVideo-Text Interleaved Chain-of-Thoughtï¼‰ï¼Œä¸€ç§æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹è§†é¢‘ç†è§£èƒ½åŠ›çš„è§†é¢‘-æ–‡æœ¬äº¤é”™å¼é“¾å¼æ€ç»´æ¨ç†èŒƒå¼ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿‡åº¦ä¾èµ–æ–‡æœ¬ä¿¡æ¯è€Œå¿½è§†è§†è§‰æ¨¡æ€çš„é—®é¢˜ï¼ŒViTCoTæ¨¡ä»¿äººç±»åœ¨æ¨ç†æ—¶é‡æ–°å®¡è§†è§†è§‰å†…å®¹çš„ä¹ æƒ¯ï¼Œå®ç°äº†æ›´ç¬¦åˆè®¤çŸ¥é€»è¾‘çš„æ¨ç†è¿‡ç¨‹ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€ç ”ç©¶ï¼Œå›¢é˜Ÿæ„å»ºäº†Video-Text Interleaved Benchmarkï¼ˆViTIBï¼‰ï¼Œè¯¥åŸºå‡†åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰è¿›è¡Œå…³é”®è§†é¢‘é€‰æ‹©å¹¶ç»è¿‡äººå·¥æ ¡éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„ä»…æ–‡æœ¬CoTèŒƒå¼ç›¸æ¯”ï¼ŒViTCoTæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„è§†é¢‘æ¨ç†æ€§èƒ½ï¼Œå¹¶èƒ½æœ‰æ•ˆæ¿€æ´»å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­æ›´å¤šçš„ç¥ç»å…ƒå€¼ã€‚è¯¥å·¥ä½œä¸ºè‡ªåŠ¨é©¾é©¶ã€å…·èº«æ™ºèƒ½åŠé€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰é¢†åŸŸçš„è§†é¢‘ç†è§£ä»»åŠ¡æä¾›äº†æ›´å…·ç›´è§‰æ€§å’Œè®¤çŸ¥ä¸€è‡´æ€§çš„æ¨ç†æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.09876v1",
      "published_date": "2025-07-14 03:21:13 UTC",
      "updated_date": "2025-07-14 03:21:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:44:56.103386+00:00"
    },
    {
      "arxiv_id": "2507.09875v2",
      "title": "Function Induction and Task Generalization: An Interpretability Study with Off-by-One Addition",
      "title_zh": "å‡½æ•°å½’çº³ä¸ä»»åŠ¡æ³›åŒ–ï¼šåŸºäºåä¸€åŠ æ³•çš„å¯è§£é‡Šæ€§ç ”ç©¶",
      "authors": [
        "Qinyuan Ye",
        "Robin Jia",
        "Xiang Ren"
      ],
      "abstract": "Large language models demonstrate the intriguing ability to perform unseen tasks via in-context learning. However, it remains unclear what mechanisms inside the model drive such task-level generalization. In this work, we approach this question through the lens of off-by-one addition (i.e., 1+1=3, 2+2=5, 3+3=?), a two-step, counterfactual task with an unexpected +1 function as a second step. Leveraging circuit-style interpretability techniques such as path patching, we analyze the models' internal computations behind their performance and present three key findings. First, we uncover a function induction mechanism that explains the model's generalization from standard addition to off-by-one addition. This mechanism resembles the structure of the induction head mechanism found in prior work and elevates it to a higher level of abstraction. Second, we show that the induction of the +1 function is governed by multiple attention heads in parallel, each of which emits a distinct piece of the +1 function. Finally, we find that this function induction mechanism is reused in a broader range of tasks, including synthetic tasks such as shifted multiple-choice QA and algorithmic tasks such as base-8 addition. Overall, our findings offer deeper insights into how reusable and composable structures within language models enable task-level generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹â€œå·®ä¸€åŠ æ³•â€ï¼ˆoff-by-one additionï¼Œå¦‚1+1=3ï¼‰è¿™ä¸€åäº‹å®ä»»åŠ¡çš„æ·±å…¥åˆ†æï¼Œæ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆin-context learningï¼‰ä¸­å®ç°ä»»åŠ¡çº§æ³›åŒ–çš„å†…éƒ¨æœºåˆ¶ã€‚åˆ©ç”¨è·¯å¾„ä¿®è¡¥ï¼ˆpath patchingï¼‰ç­‰ç”µè·¯çº§å¯è§£é‡Šæ€§æŠ€æœ¯ï¼Œç ”ç©¶è€…æ­ç¤ºäº†ä¸€ç§å‡½æ•°å½’çº³ï¼ˆfunction inductionï¼‰æœºåˆ¶ï¼Œè¯¥æœºåˆ¶åœ¨ç»“æ„ä¸Šç±»ä¼¼äºè¯±å¯¼å¤´ï¼ˆinduction headï¼‰ä½†å¤„äºæ›´é«˜çš„æŠ½è±¡å±‚æ¬¡ï¼Œè§£é‡Šäº†æ¨¡å‹å¦‚ä½•ä»æ ‡å‡†åŠ æ³•æ³›åŒ–è‡³éå¸¸è§„ä»»åŠ¡ã€‚ç ”ç©¶å‘ç°ï¼Œ+1å‡½æ•°çš„å½’çº³è¿‡ç¨‹ç”±å¤šä¸ªå¹¶è¡Œçš„æ³¨æ„åŠ›å¤´ï¼ˆattention headsï¼‰å…±åŒé©±åŠ¨ï¼Œæ¯ä¸ªå¤´è´Ÿè´£ç”Ÿæˆè¯¥å‡½æ•°çš„ç‰¹å®šç»„æˆéƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œè¿™ç§å‡½æ•°å½’çº³æœºåˆ¶åœ¨ç§»ä½å¤šé¡¹é€‰æ‹©é—®ç­”å’Œå…«è¿›åˆ¶åŠ æ³•ç­‰æ›´å¹¿æ³›çš„ä»»åŠ¡ä¸­å±•ç°å‡ºé‡ç”¨æ€§ã€‚è¿™äº›å‘ç°ä¸ºç†è§£æ¨¡å‹å†…éƒ¨å¯é‡ç”¨ä¸”å¯ç»„åˆçš„ç»“æ„å¦‚ä½•æ”¯æŒå¤æ‚çš„ä»»åŠ¡æ³›åŒ–æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code: https://github.com/INK-USC/function-induction",
      "pdf_url": "https://arxiv.org/pdf/2507.09875v2",
      "published_date": "2025-07-14 03:20:55 UTC",
      "updated_date": "2025-09-27 19:24:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:09.591827+00:00"
    },
    {
      "arxiv_id": "2507.11554v4",
      "title": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models",
      "title_zh": "Inversion-DPOï¼šç²¾å‡†ä¸”é«˜æ•ˆçš„æ‰©æ•£æ¨¡å‹åè®­ç»ƒ",
      "authors": [
        "Zejian Li",
        "Yize Li",
        "Chenye Meng",
        "Zhongni Liu",
        "Yang Ling",
        "Shengyuan Zhang",
        "Guang Yang",
        "Changyuan Yang",
        "Zhiyuan Yang",
        "Lingyun Sun"
      ],
      "abstract": "Recent advancements in diffusion models (DMs) have been propelled by alignment methods that post-train models to better conform to human preferences. However, these approaches typically require computation-intensive training of a base model and a reward model, which not only incurs substantial computational overhead but may also compromise model accuracy and training efficiency. To address these limitations, we propose Inversion-DPO, a novel alignment framework that circumvents reward modeling by reformulating Direct Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts intractable posterior sampling in Diffusion-DPO with the deterministic inversion from winning and losing samples to noise and thus derive a new post-training paradigm. This paradigm eliminates the need for auxiliary reward models or inaccurate appromixation, significantly enhancing both precision and efficiency of training. We apply Inversion-DPO to a basic task of text-to-image generation and a challenging task of compositional image generation. Extensive experiments show substantial performance improvements achieved by Inversion-DPO compared to existing post-training methods and highlight the ability of the trained generative models to generate high-fidelity compositionally coherent images. For the post-training of compostitional image geneation, we curate a paired dataset consisting of 11,140 images with complex structural annotations and comprehensive scores, designed to enhance the compositional capabilities of generative models. Inversion-DPO explores a new avenue for efficient, high-precision alignment in diffusion models, advancing their applicability to complex realistic generation tasks. Our code is available at https://github.com/MIGHTYEZ/Inversion-DPO",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Inversion-DPOï¼Œä¸€ç§é’ˆå¯¹æ‰©æ•£æ¨¡å‹(Diffusion Models)çš„é«˜æ•ˆç²¾ç¡®å¯¹é½æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¯¹é½æ–¹æ³•ä¸­è®¡ç®—å¼€é”€å¤§åŠä¾èµ–è¾…åŠ©å¥–åŠ±æ¨¡å‹çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å°† DDIM inversion å¼•å…¥ç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization)ï¼Œåˆ©ç”¨ä»æ ·æœ¬åˆ°å™ªå£°çš„ç¡®å®šæ€§åæ¼”æ›¿ä»£äº†å¤æ‚çš„åéªŒé‡‡æ ·ï¼Œä»è€Œæ„å»ºå‡ºä¸€ç§å…¨æ–°çš„åè®­ç»ƒ(Post-Training)èŒƒå¼ã€‚Inversion-DPO è¢«åº”ç”¨äºæ–‡æœ¬ç”Ÿæˆå›¾åƒ(Text-to-Image Generation)ä»¥åŠæå…·æŒ‘æˆ˜æ€§çš„ç»„åˆå›¾åƒç”Ÿæˆ(Compositional Image Generation)ä»»åŠ¡ä¸­ã€‚ä¸ºäº†æå‡æ¨¡å‹çš„ç»„åˆèƒ½åŠ›ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜ä¸“é—¨æ„å»ºäº†ä¸€ä¸ªåŒ…å« 11,140 å¼ å…·æœ‰å¤æ‚ç»“æ„æ ‡æ³¨å’Œç»¼åˆè¯„åˆ†çš„å›¾åƒé…å¯¹æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰çš„åè®­ç»ƒæ–¹æ³•ç›¸æ¯”ï¼ŒInversion-DPO åœ¨ç”Ÿæˆå›¾åƒçš„ä¿çœŸåº¦ã€ç»„åˆä¸€è‡´æ€§ä»¥åŠè®­ç»ƒæ•ˆç‡ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚è¯¥ç ”ç©¶ä¸ºæ‰©æ•£æ¨¡å‹çš„é«˜ç²¾åº¦å¯¹é½å¼€è¾Ÿäº†æ–°è·¯å¾„ï¼Œæ˜¾è‘—å¢å¼ºäº†å…¶åœ¨å¤„ç†å¤æ‚ç°å®ç”Ÿæˆä»»åŠ¡æ—¶çš„é€‚ç”¨æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM25",
      "pdf_url": "https://arxiv.org/pdf/2507.11554v4",
      "published_date": "2025-07-14 02:59:28 UTC",
      "updated_date": "2025-08-03 03:07:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:11.186374+00:00"
    },
    {
      "arxiv_id": "2507.09871v3",
      "title": "Task Priors: Enhancing Model Evaluation by Considering the Entire Space of Downstream Tasks",
      "title_zh": "Task Priorsï¼šé€šè¿‡è€ƒé‡ä¸‹æ¸¸ä»»åŠ¡çš„å…¨ç©ºé—´å¢å¼ºæ¨¡å‹è¯„ä¼°",
      "authors": [
        "Niket Patel",
        "Randall Balestriero"
      ],
      "abstract": "The grand goal of AI research, and particularly Self Supervised Learning (SSL), is to produce systems that can successfully solve any possible task. In contrast, current evaluation methods available to AI researchers typically rely on a fixed collection of hand-picked downstream benchmarks. Hence, a large amount of effort is put into designing and searching for large collection of evaluation tasks that can serve as a proxy of our grand goal. We argue that such a rigid evaluation protocol creates a silent bottleneck in AI research. To remedy that, we define a probabilistic space of downstream tasks obtained by adopting a distribution of tasks and by defining Task Priors. Under this view, one can evaluate a model's performance over the set of all possible downstream tasks. Our framework is the first to provide answers to key questions such as (i) what is the average performance of my model over all possible downstream tasks weighted by the probability to encounter each task? or (ii) what is the variance of my model's performance across all downstream tasks under the defined Task Priors? Beyond establishing a new standard for evaluation, we believe that Task Priors will accelerate the pace of research in SSL - where downstream task evaluation is the sole qualitative signal that researchers have access to.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰äººå·¥æ™ºèƒ½ç‰¹åˆ«æ˜¯Self Supervised Learning (SSL) è¯„ä¼°æ–¹æ³•è¿‡åº¦ä¾èµ–å›ºå®šåŸºå‡†æµ‹è¯•é›†çš„é—®é¢˜ï¼Œæå‡ºäº†Task Priors æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥ä¸‹æ¸¸ä»»åŠ¡çš„æ¦‚ç‡åˆ†å¸ƒå¹¶å®šä¹‰Task Priorsï¼Œæ„å»ºäº†ä¸€ä¸ªæ¶µç›–æ‰€æœ‰å¯èƒ½ä»»åŠ¡çš„æ¦‚ç‡ç©ºé—´ã€‚åˆ©ç”¨è¯¥æ¡†æ¶ï¼Œç ”ç©¶è€…èƒ½å¤Ÿè®¡ç®—æ¨¡å‹åœ¨æ‰€æœ‰æ½œåœ¨ä»»åŠ¡ä¸Šçš„åŠ æƒå¹³å‡è¡¨ç°ï¼Œå¹¶é‡åŒ–æ¨¡å‹åœ¨å®šä¹‰ä»»åŠ¡å…ˆéªŒä¸‹çš„æ€§èƒ½æ–¹å·®ã€‚Task Priors é¦–æ¬¡ä¸ºè¡¡é‡æ¨¡å‹åœ¨å¹¿æ³›ä»»åŠ¡ç©ºé—´ä¸­çš„æœŸæœ›æ€§èƒ½å’Œé²æ£’æ€§æä¾›äº†ç³»ç»Ÿæ€§çš„å›ç­”ã€‚è¿™ä¸€æ–°æ ‡å‡†çš„å»ºç«‹æ‰“ç ´äº†ä¼ ç»Ÿå›ºå®šè¯„ä¼°åè®®å¸¦æ¥çš„ç ”ç©¶ç“¶é¢ˆï¼Œé€šè¿‡æä¾›æ›´å…¨é¢çš„å®šæ€§ä¿¡å·ï¼Œæœ‰æœ›æ˜¾è‘—åŠ é€ŸSSL é¢†åŸŸçš„ç ”ç©¶è¿›ç¨‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS UniReps Workshop 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.09871v3",
      "published_date": "2025-07-14 02:53:14 UTC",
      "updated_date": "2025-10-20 19:51:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:18.435438+00:00"
    },
    {
      "arxiv_id": "2507.09866v1",
      "title": "Turning the Tide: Repository-based Code Reflection",
      "title_zh": "æ‰­è½¬å±€åŠ¿ï¼šåŸºäºä»£ç ä»“åº“çš„ä»£ç åæ€",
      "authors": [
        "Wei Zhang",
        "Jian Yang",
        "Jiaxi Yang",
        "Ya Wang",
        "Zhoujun Li",
        "Zeyu Cui",
        "Binyuan Hui",
        "Junyang Lin"
      ],
      "abstract": "Code large language models (LLMs) enhance programming by understanding and generating code across languages, offering intelligent feedback, bug detection, and code updates through reflection, improving development efficiency and accessibility. While benchmarks (e.g. HumanEval/LiveCodeBench) evaluate code generation and real-world relevance, previous works ignore the scenario of modifying code in repositories. Considering challenges remaining in improving reflection capabilities and avoiding data contamination in dynamic benchmarks, we introduce LiveRepoReflection, a challenging benchmark for evaluating code understanding and generation in multi-file repository contexts, featuring 1,888 rigorously filtered test cases across $6$ programming languages to ensure diversity, correctness, and high difficulty. Further, we create RepoReflection-Instruct, a large-scale, quality-filtered instruction-tuning dataset derived from diverse sources, used to train RepoReflectionCoder through a two-turn dialogue process involving code generation and error-driven repair. The leaderboard evaluates over 40 LLMs to reflect the model performance of repository-based code reflection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»“åº“çº§ä»£ç ä¿®æ”¹åœºæ™¯ä¸­çš„ä¸è¶³ï¼Œä»¥åŠåŠ¨æ€åŸºå‡†æµ‹è¯•ä¸­å¯èƒ½å­˜åœ¨çš„æ•°æ®æ±¡æŸ“é—®é¢˜ï¼Œæå‡ºäº†LiveRepoReflectionåŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å«è·¨6ç§ç¼–ç¨‹è¯­è¨€çš„1,888ä¸ªç»è¿‡ä¸¥æ ¼è¿‡æ»¤çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæ—¨åœ¨è¯„ä¼°å¤šæ–‡ä»¶ä»“åº“èƒŒæ™¯ä¸‹çš„ä»£ç ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†é«˜è´¨é‡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†RepoReflection-Instructï¼Œå¹¶ä»¥æ­¤é€šè¿‡â€œä»£ç ç”Ÿæˆâ€ä¸â€œé”™è¯¯é©±åŠ¨ä¿®å¤â€çš„åŒè½®å¯¹è¯è¿‡ç¨‹è®­ç»ƒå‡ºRepoReflectionCoderæ¨¡å‹ã€‚é€šè¿‡å¯¹è¶…è¿‡40ä¸ªä¸»æµå¤§æ¨¡å‹è¿›è¡Œè¯„æµ‹å¹¶å»ºç«‹æ’è¡Œæ¦œï¼Œè¯¥ç ”ç©¶å…¨é¢å±•ç¤ºäº†å½“å‰æ¨¡å‹åœ¨ä»“åº“çº§ä»£ç åæ€ï¼ˆRepository-based Code Reflectionï¼‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½ç°çŠ¶ä¸æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09866v1",
      "published_date": "2025-07-14 02:36:27 UTC",
      "updated_date": "2025-07-14 02:36:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:19.327943+00:00"
    },
    {
      "arxiv_id": "2507.09864v1",
      "title": "Intersection of Reinforcement Learning and Bayesian Optimization for Intelligent Control of Industrial Processes: A Safe MPC-based DPG using Multi-Objective BO",
      "title_zh": "å¼ºåŒ–å­¦ä¹ ä¸è´å¶æ–¯ä¼˜åŒ–åœ¨å·¥ä¸šè¿‡ç¨‹æ™ºèƒ½æ§åˆ¶ä¸­çš„ç»“åˆï¼šåŸºäºå¤šç›®æ ‡è´å¶æ–¯ä¼˜åŒ–çš„å®‰å…¨ MPC ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦æ–¹æ³•",
      "authors": [
        "Hossein Nejatbakhsh Esfahani",
        "Javad Mohammadpour Velni"
      ],
      "abstract": "Model Predictive Control (MPC)-based Reinforcement Learning (RL) offers a structured and interpretable alternative to Deep Neural Network (DNN)-based RL methods, with lower computational complexity and greater transparency. However, standard MPC-RL approaches often suffer from slow convergence, suboptimal policy learning due to limited parameterization, and safety issues during online adaptation. To address these challenges, we propose a novel framework that integrates MPC-RL with Multi-Objective Bayesian Optimization (MOBO). The proposed MPC-RL-MOBO utilizes noisy evaluations of the RL stage cost and its gradient, estimated via a Compatible Deterministic Policy Gradient (CDPG) approach, and incorporates them into a MOBO algorithm using the Expected Hypervolume Improvement (EHVI) acquisition function. This fusion enables efficient and safe tuning of the MPC parameters to achieve improved closed-loop performance, even under model imperfections. A numerical example demonstrates the effectiveness of the proposed approach in achieving sample-efficient, stable, and high-performance learning for control systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å·¥ä¸šè¿‡ç¨‹æ™ºèƒ½æ§åˆ¶ä¸­å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)ä¸è´å¶æ–¯ä¼˜åŒ–(Bayesian Optimization)çš„ç»“åˆï¼Œé’ˆå¯¹åŸºäºæ¨¡å‹é¢„æµ‹æ§åˆ¶(Model Predictive Control, MPC)çš„RLæ–¹æ³•åœ¨æ”¶æ•›é€Ÿåº¦ã€ç­–ç•¥å­¦ä¹ æ¬¡ä¼˜åŠå®‰å…¨æ€§æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆå¤šç›®æ ‡è´å¶æ–¯ä¼˜åŒ–(Multi-Objective Bayesian Optimization, MOBO)çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å…¼å®¹ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦(Compatible Deterministic Policy Gradient, CDPG)æ–¹æ³•ä¼°ç®—RLé˜¶æ®µæˆæœ¬åŠå…¶æ¢¯åº¦çš„å™ªå£°è¯„ä¼°ï¼Œå¹¶å°†å…¶å¼•å…¥é‡‡ç”¨æœŸæœ›è¶…ä½“ç§¯æ”¹è¿›(Expected Hypervolume Improvement, EHVI)é‡‡é›†å‡½æ•°çš„MOBOç®—æ³•ä¸­ã€‚è¿™ç§èåˆç­–ç•¥å®ç°äº†å¯¹MPCå‚æ•°çš„é«˜æ•ˆä¸”å®‰å…¨è°ƒä¼˜ï¼Œå³ä½¿åœ¨æ¨¡å‹å­˜åœ¨ç¼ºé™·çš„æƒ…å†µä¸‹ä¹Ÿèƒ½æ˜¾è‘—æ”¹å–„é—­ç¯æ€§èƒ½ã€‚æ•°å€¼å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ„å»ºæ ·æœ¬é«˜æ•ˆã€ç¨³å®šä¸”é«˜æ€§èƒ½çš„æ§åˆ¶ç³»ç»Ÿæ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09864v1",
      "published_date": "2025-07-14 02:31:52 UTC",
      "updated_date": "2025-07-14 02:31:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:26.686804+00:00"
    },
    {
      "arxiv_id": "2507.14189v2",
      "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base",
      "title_zh": "DeepWriterï¼šåŸºäºç¦»çº¿çŸ¥è¯†åº“çš„äº‹å®é©±åŠ¨å‹å¤šæ¨¡æ€å†™ä½œåŠ©æ‰‹",
      "authors": [
        "Song Mao",
        "Lejun Cheng",
        "Pinlong Cai",
        "Guohang Yan",
        "Ding Wang",
        "Botian Shi"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various applications. However, their use as writing assistants in specialized domains like finance, medicine, and law is often hampered by a lack of deep domain-specific knowledge and a tendency to hallucinate. Existing solutions, such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency across multiple retrieval steps, while online search-based methods often degrade quality due to unreliable web content. To address these challenges, we introduce DeepWriter, a customizable, multimodal, long-form writing assistant that operates on a curated, offline knowledge base. DeepWriter leverages a novel pipeline that involves task decomposition, outline generation, multimodal retrieval, and section-by-section composition with reflection. By deeply mining information from a structured corpus and incorporating both textual and visual elements, DeepWriter generates coherent, factually grounded, and professional-grade documents. We also propose a hierarchical knowledge representation to enhance retrieval efficiency and accuracy. Our experiments on financial report generation demonstrate that DeepWriter produces high-quality, verifiable articles that surpasses existing baselines in factual accuracy and generated content quality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é‡‘èã€åŒ»ç–—å’Œæ³•å¾‹ç­‰ä¸“ä¸šé¢†åŸŸå†™ä½œæ—¶é¢ä¸´çš„é¢†åŸŸçŸ¥è¯†ç¼ºå¤±åŠå¹»è§‰(hallucinate)é—®é¢˜ï¼Œæå‡ºäº†DeepWriterï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç²¾é€‰ç¦»çº¿çŸ¥è¯†åº“(offline knowledge base)çš„å¯å®šåˆ¶å¤šæ¨¡æ€é•¿æ–‡æœ¬å†™ä½œåŠ©æ‰‹ã€‚DeepWriteré‡‡ç”¨äº†ä¸€ç§åŒ…å«ä»»åŠ¡åˆ†è§£(task decomposition)ã€æçº²ç”Ÿæˆã€å¤šæ¨¡æ€æ£€ç´¢ä»¥åŠå¸¦åæ€(reflection)çš„é€ç« èŠ‚åˆ›ä½œçš„åˆ›æ–°æµç¨‹ã€‚ä¸ºäº†å¢å¼ºæ£€ç´¢çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–çŸ¥è¯†è¡¨ç¤º(hierarchical knowledge representation)æ–¹æ³•ã€‚é€šè¿‡æ·±åº¦æŒ–æ˜ç»“æ„åŒ–è¯­æ–™å¹¶æ•´åˆæ–‡æœ¬ä¸å›¾åƒå…ƒç´ ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆé€»è¾‘è¿è´¯ã€äº‹å®ä¸¥è°¨ä¸”å…·å¤‡ä¸“ä¸šæ°´å‡†çš„æ–‡æ¡£ã€‚åœ¨é‡‘èæŠ¥å‘Šç”Ÿæˆå®éªŒä¸­ï¼ŒDeepWriteråœ¨äº‹å®å‡†ç¡®åº¦å’Œç”Ÿæˆå†…å®¹è´¨é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºçº¿æ¨¡å‹(baselines)ï¼Œè¯æ˜äº†å…¶ç”Ÿæˆé«˜è´¨é‡ã€å¯éªŒè¯ä¸“ä¸šæ–‡ç« çš„å“è¶Šèƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "work in process",
      "pdf_url": "https://arxiv.org/pdf/2507.14189v2",
      "published_date": "2025-07-14 02:13:22 UTC",
      "updated_date": "2025-08-14 08:14:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:34.780720+00:00"
    },
    {
      "arxiv_id": "2507.09861v1",
      "title": "A Survey on MLLM-based Visually Rich Document Understanding: Methods, Challenges, and Emerging Trends",
      "title_zh": "åŸºäº MLLM çš„å¯Œè§†è§‰æ–‡æ¡£ç†è§£ç»¼è¿°ï¼šæ–¹æ³•ã€æŒ‘æˆ˜ä¸æ–°å…´è¶‹åŠ¿",
      "authors": [
        "Yihao Ding",
        "Siwen Luo",
        "Yue Dai",
        "Yanbei Jiang",
        "Zechuan Li",
        "Geoffrey Martin",
        "Yifan Peng"
      ],
      "abstract": "Visually-Rich Document Understanding (VRDU) has emerged as a critical field, driven by the need to automatically process documents containing complex visual, textual, and layout information. Recently, Multimodal Large Language Models (MLLMs) have shown remarkable potential in this domain, leveraging both Optical Character Recognition (OCR)-dependent and OCR-free frameworks to extract and interpret information in document images. This survey reviews recent advancements in MLLM-based VRDU, highlighting three core components: (1) methods for encoding and fusing textual, visual, and layout features; (2) training paradigms, including pretraining strategies, instruction-response tuning, and the trainability of different model modules; and (3) datasets utilized for pretraining, instruction-tuning, and supervised fine-tuning. Finally, we discuss the challenges and opportunities in this evolving field and propose future directions to advance the efficiency, generalizability, and robustness of VRDU systems.",
      "tldr_zh": "è¿™ç¯‡ç»¼è¿°æ·±å…¥æ¢è®¨äº†åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) çš„è§†è§‰ä¸°å¯Œæ–‡æ¡£ç†è§£ (VRDU) é¢†åŸŸï¼Œæ—¨åœ¨è§£å†³è‡ªåŠ¨å¤„ç†åŒ…å«å¤æ‚è§†è§‰ã€æ–‡æœ¬å’Œå¸ƒå±€ä¿¡æ¯æ–‡æ¡£çš„éœ€æ±‚ã€‚æ–‡ç« ç³»ç»Ÿæ€§åœ°å›é¡¾äº† OCR-dependent å’Œ OCR-free ä¸¤ç±»æŠ€æœ¯æ¡†æ¶ï¼Œå¹¶é‡ç‚¹ä»‹ç»äº†ç¼–ç ä¸èåˆå¤šæ¨¡æ€ç‰¹å¾çš„æ ¸å¿ƒæ–¹æ³•ã€‚ç ”ç©¶è¯¦ç»†æ¢³ç†äº†å½“å‰çš„è®­ç»ƒèŒƒå¼ï¼ŒåŒ…æ‹¬ pretraining ç­–ç•¥ã€instruction-tuning ä»¥åŠä¸åŒæ¨¡å‹æ¨¡å—çš„å¯è®­ç»ƒæ€§ï¼ŒåŒæ—¶æ±‡æ€»äº†ç”¨äº supervised fine-tuning çš„å…³é”®æ•°æ®é›†ã€‚é€šè¿‡åˆ†æç³»ç»Ÿåœ¨æ•ˆç‡ã€æ³›åŒ–æ€§å’Œé²æ£’æ€§æ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæ–‡ç« ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†é‡è¦æŒ‡å¼•ã€‚è¯¥ç»¼è¿°ä¸ä»…æ€»ç»“äº† MLLMs åœ¨ VRDU é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œè¿˜ä¸ºå¼€å‘æ›´å…·é²æ£’æ€§çš„æ–‡æ¡£ç†è§£ç³»ç»Ÿå¥ å®šäº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2507.09861v1",
      "published_date": "2025-07-14 02:10:31 UTC",
      "updated_date": "2025-07-14 02:10:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:37.380946+00:00"
    },
    {
      "arxiv_id": "2507.09860v1",
      "title": "Secure and Efficient UAV-Based Face Detection via Homomorphic Encryption and Edge Computing",
      "title_zh": "åŸºäºåŒæ€åŠ å¯†ä¸è¾¹ç¼˜è®¡ç®—çš„å®‰å…¨é«˜æ•ˆæ— äººæœºäººè„¸æ£€æµ‹",
      "authors": [
        "Nguyen Van Duc",
        "Bui Duc Manh",
        "Quang-Trung Luu",
        "Dinh Thai Hoang",
        "Van-Linh Nguyen",
        "Diep N. Nguyen"
      ],
      "abstract": "This paper aims to propose a novel machine learning (ML) approach incorporating Homomorphic Encryption (HE) to address privacy limitations in Unmanned Aerial Vehicles (UAV)-based face detection. Due to challenges related to distance, altitude, and face orientation, high-resolution imagery and sophisticated neural networks enable accurate face recognition in dynamic environments. However, privacy concerns arise from the extensive surveillance capabilities of UAVs. To resolve this issue, we propose a novel framework that integrates HE with advanced neural networks to secure facial data throughout the inference phase. This method ensures that facial data remains secure with minimal impact on detection accuracy. Specifically, the proposed system leverages the Cheon-Kim-Kim-Song (CKKS) scheme to perform computations directly on encrypted data, optimizing computational efficiency and security. Furthermore, we develop an effective data encoding method specifically designed to preprocess the raw facial data into CKKS form in a Single-Instruction-Multiple-Data (SIMD) manner. Building on this, we design a secure inference algorithm to compute on ciphertext without needing decryption. This approach not only protects data privacy during the processing of facial data but also enhances the efficiency of UAV-based face detection systems. Experimental results demonstrate that our method effectively balances privacy protection and detection performance, making it a viable solution for UAV-based secure face detection. Significantly, our approach (while maintaining data confidentially with HE encryption) can still achieve an accuracy of less than 1% compared to the benchmark without using encryption.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆHomomorphic Encryption (HE)ä¸è¾¹ç¼˜è®¡ç®—çš„æ–°å‹æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ— äººæœº(UAV)äººè„¸æ£€æµ‹ä¸­çš„éšç§æ³„éœ²é—®é¢˜ã€‚é’ˆå¯¹åŠ¨æ€ç¯å¢ƒä¸‹çš„æ£€æµ‹æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨CKKSæ–¹æ¡ˆç›´æ¥åœ¨åŠ å¯†æ•°æ®ä¸Šè¿›è¡Œè®¡ç®—ï¼Œç¡®ä¿é¢éƒ¨æ•°æ®åœ¨æ•´ä¸ªæ¨ç†é˜¶æ®µçš„å®‰å…¨æ€§ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ç§é«˜æ•ˆçš„æ•°æ®ç¼–ç æ–¹æ³•ï¼Œä»¥Single-Instruction-Multiple-Data (SIMD)æ–¹å¼å°†åŸå§‹æ•°æ®é¢„å¤„ç†ä¸ºCKKSæ ¼å¼ï¼Œå¹¶è®¾è®¡äº†æ— éœ€è§£å¯†çš„åŠ å¯†æ¨ç†ç®—æ³•ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿éšœæ•°æ®æœºå¯†æ€§çš„åŒæ—¶ï¼Œå…¶æ£€æµ‹å‡†ç¡®ç‡ä¸æœªåŠ å¯†åŸºå‡†ç›¸æ¯”ä¸‹é™ä¸è¶³1%ï¼Œåœ¨éšç§ä¿æŠ¤ä¸ç³»ç»Ÿæ€§èƒ½ä¹‹é—´å®ç°äº†å“è¶Šçš„å¹³è¡¡ï¼Œä¸ºåŸºäºUAVçš„å®‰å…¨æ£€æµ‹æä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09860v1",
      "published_date": "2025-07-14 02:07:08 UTC",
      "updated_date": "2025-07-14 02:07:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:34.389002+00:00"
    },
    {
      "arxiv_id": "2507.09854v1",
      "title": "Model-Grounded Symbolic Artificial Intelligence Systems Learning and Reasoning with Model-Grounded Symbolic Artificial Intelligence Systems",
      "title_zh": "æ¨¡å‹é”šå®šç¬¦å·äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼šåŸºäºæ¨¡å‹é”šå®šç¬¦å·äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å­¦ä¹ ä¸æ¨ç†",
      "authors": [
        "Aniruddha Chattopadhyay",
        "Raj Dandekar",
        "Kaushik Roy"
      ],
      "abstract": "Neurosymbolic artificial intelligence (AI) systems combine neural network and classical symbolic AI mechanisms to exploit the complementary strengths of large scale, generalizable learning and robust, verifiable reasoning. Numerous classifications of neurosymbolic AI illustrate how these two components can be integrated in distinctly different ways. In this work, we propose reinterpreting instruction tuned large language models as model grounded symbolic AI systems where natural language serves as the symbolic layer and grounding is achieved through the models internal representation space. Within this framework, we investigate and develop novel learning and reasoning approaches that preserve structural similarities to traditional learning and reasoning paradigms. Preliminary evaluations across axiomatic deductive reasoning procedures of varying complexity provide insights into the effectiveness of our approach in improving learning efficiency and reasoning reliability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºå°†æŒ‡ä»¤å¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é‡æ–°è§£é‡Šä¸ºæ¨¡å‹åŸºå‡†åŒ–ç¬¦å·äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼ˆmodel-grounded symbolic AI systemsï¼‰ï¼Œæ—¨åœ¨èåˆç¥ç»ç½‘ç»œçš„è§„æ¨¡åŒ–å­¦ä¹ èƒ½åŠ›ä¸ä¼ ç»Ÿç¬¦å·AIçš„ç¨³å¥æ¨ç†ä¼˜åŠ¿ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œè‡ªç„¶è¯­è¨€å……å½“ç¬¦å·å±‚ï¼ˆsymbolic layerï¼‰ï¼Œå¹¶é€šè¿‡æ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºç©ºé—´ï¼ˆinternal representation spaceï¼‰å®ç° groundingã€‚ç ”ç©¶è€…æ®æ­¤å¼€å‘äº†ä¸ä¼ ç»Ÿå­¦ä¹ å’Œæ¨ç†èŒƒå¼åœ¨ç»“æ„ä¸Šå…·æœ‰ç›¸ä¼¼æ€§çš„æ–°å‹å­¦ä¹ ä¸æ¨ç†æ–¹æ³•ã€‚é€šè¿‡å¯¹ä¸åŒå¤æ‚åº¦çš„å…¬ç†åŒ–æ¼”ç»æ¨ç†ï¼ˆaxiomatic deductive reasoningï¼‰ç¨‹åºè¿›è¡Œåˆæ­¥è¯„ä¼°ï¼Œå®éªŒç»“æœè¯æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæå‡å­¦ä¹ æ•ˆç‡å¹¶å¢å¼ºæ¨ç†çš„å¯é æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½ï¼ˆNeurosymbolic AIï¼‰çš„é›†æˆè·¯å¾„æä¾›äº†å…¨æ–°çš„è§†è§’å’Œç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as paper in 19th International Conference on Neurosymbolic Learning and Reasoning,NeSy 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.09854v1",
      "published_date": "2025-07-14 01:34:05 UTC",
      "updated_date": "2025-07-14 01:34:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:49.686679+00:00"
    },
    {
      "arxiv_id": "2507.10622v1",
      "title": "Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs",
      "title_zh": "åŸºäºMFCCçš„é²æ£’ç½‘ç»œå…¥ä¾µæ£€æµ‹é¢‘è°±ç‰¹å¾æå–",
      "authors": [
        "HyeYoung Lee",
        "Muhammad Nadeem",
        "Pavel Tsoi"
      ],
      "abstract": "The rapid expansion of Internet of Things (IoT) networks has led to a surge in security vulnerabilities, emphasizing the critical need for robust anomaly detection and classification techniques. In this work, we propose a novel approach for identifying anomalies in IoT network traffic by leveraging the Mel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model known for its effectiveness in feature extraction and image-based tasks. Learnable MFCCs enable adaptive spectral feature representation, capturing the temporal patterns inherent in network traffic more effectively than traditional fixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the data into a higher-dimensional space, enhancing class separability and enabling more effective multiclass classification. Our approach combines the strengths of MFCCs with the robust feature extraction capabilities of ResNet-18, offering a powerful framework for anomaly detection. The proposed model is evaluated on three widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and IoTID20. The experimental results highlight the potential of integrating adaptive signal processing techniques with deep learning architectures to achieve robust and scalable anomaly detection in heterogeneous IoT network landscapes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰©è”ç½‘(IoT)ç½‘ç»œå¿«é€Ÿæ‰©å¼ å¸¦æ¥çš„å®‰å…¨æ¼æ´é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæ¢…å°”é¢‘ç‡å€’è°±ç³»æ•°(Mel-frequency cepstral coefficients, MFCC)ä¸ResNet-18æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç½‘ç»œå¼‚å¸¸æ£€æµ‹æ–°æ–¹æ³•ã€‚è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºå¼•å…¥äº†å¯å­¦ä¹ çš„MFCCsï¼Œé€šè¿‡è‡ªé€‚åº”é¢‘è°±ç‰¹å¾è¡¨ç¤ºæ¥æ•æ‰ç½‘ç»œæµé‡ä¸­çš„æ—¶é—´æ¨¡å¼ï¼Œç›¸æ¯”ä¼ ç»Ÿå›ºå®šMFCCså…·æœ‰æ›´å¼ºçš„ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ã€‚é€šè¿‡å°†åŸå§‹ä¿¡å·è½¬æ¢ä¸ºMFCCsï¼Œè¯¥æ–¹æ³•èƒ½å°†æ•°æ®æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ï¼Œæ˜¾è‘—å¢å¼ºäº†ç±»åˆ«çš„å¯åˆ†æ€§ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„å¤šåˆ†ç±»ã€‚å®éªŒåœ¨CICIoT2023ã€NSL-KDDå’ŒIoTID20ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„IoTå…¥ä¾µæ£€æµ‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°†è‡ªé€‚åº”ä¿¡å·å¤„ç†æŠ€æœ¯ä¸ResNet-18æ¶æ„ç›¸ç»“åˆï¼Œèƒ½ä¸ºå¼‚æ„IoTç½‘ç»œç¯å¢ƒæä¾›å¥å£®ä¸”å¯æ‰©å±•çš„å¼‚å¸¸æ£€æµ‹æ¡†æ¶ã€‚",
      "categories": [
        "cs.CR",
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10622v1",
      "published_date": "2025-07-14 01:25:26 UTC",
      "updated_date": "2025-07-14 01:25:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:45:39.590756+00:00"
    },
    {
      "arxiv_id": "2507.09850v3",
      "title": "The Challenge of Teaching Reasoning to LLMs Without RL or Distillation",
      "title_zh": "æ— éœ€å¼ºåŒ–å­¦ä¹ æˆ–è’¸é¦ï¼šæ•™æˆå¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„æŒ‘æˆ˜",
      "authors": [
        "Wei Du",
        "Branislav Kisacanin",
        "George Armstrong",
        "Shubham Toshniwal",
        "Ivan Moshkov",
        "Alexan Ayrapetyan",
        "Sadegh Mahdavi",
        "Dan Zhao",
        "Shizhe Diao",
        "Dragan Masulovic",
        "Marius Stanean",
        "Advaith Avadhanam",
        "Max Wang",
        "Ashmit Dutta",
        "Shitij Govil",
        "Sri Yanamandara",
        "Mihir Tandon",
        "Sriram Ananthakrishnan",
        "Vedant Rathi",
        "David Zhang",
        "Joonseok Kang",
        "Leon Luo",
        "Titu Andreescu",
        "Boris Ginsburg",
        "Igor Gitman"
      ],
      "abstract": "Reasoning-capable language models achieve state-of-the-art performance in diverse complex tasks by generating long, explicit Chain-of-Thought (CoT) traces. While recent works show that base models can acquire such reasoning traces via reinforcement learning or distillation from stronger models like DeepSeek-R1, previous works demonstrate that even short CoT prompting without fine-tuning is able to improve reasoning. We ask whether long CoT can be induced in a base model using only prompting or minimal tuning. Using just 20 long CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly fine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms the much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of high-quality examples can unlock strong reasoning capabilities. We further explore using CoT data from non-reasoning models and human annotators, enhanced with prompt engineering, multi-pass editing, and structural guidance. However, neither matches the performance of reasoning model traces, suggesting that certain latent qualities of expert CoT are difficult to replicate. We analyze key properties of reasoning data, such as problem difficulty, diversity, and answer length, that influence reasoning distillation. While challenges remain, we are optimistic that carefully curated human-written CoT, even in small quantities, can activate reasoning behaviors in base models. We release our human-authored dataset across refinement stages and invite further investigation into what makes small-scale reasoning supervision so effective.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä¸ä½¿ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æˆ–å¤§è§„æ¨¡æ¨¡å‹è’¸é¦(Distillation)çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•è¯±å¯¼åŸºç¡€å¤§è¯­è¨€æ¨¡å‹(LLMs)äº§ç”Ÿé•¿é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†èƒ½åŠ›ã€‚ä½œè€…é€šè¿‡ä»…ä½¿ç”¨æ¥è‡ªæ¨ç†æ¨¡å‹QwQ-32B-Previewçš„20ä¸ªé«˜è´¨é‡é•¿CoTç¤ºä¾‹ï¼Œå¯¹åŸºç¡€æ¨¡å‹Qwen2.5-32Bè¿›è¡Œè½»é‡çº§å¾®è°ƒï¼Œä½¿å…¶æ€§èƒ½è¶…è¶Šäº†æ›´å¤§å‚æ•°é‡çš„Qwen2.5-Math-72B-Instructï¼Œè¯æ˜æå°‘é‡çš„é«˜è´¨é‡æ•°æ®å³å¯æ¿€æ´»å¼ºå¤§çš„æ¨ç†æ½œèƒ½ã€‚ç ”ç©¶è¿›ä¸€æ­¥å°è¯•äº†ç»“åˆæç¤ºå·¥ç¨‹ã€å¤šè½®ç¼–è¾‘åŠç»“æ„åŒ–å¼•å¯¼çš„äººå·¥æ ‡æ³¨æ•°æ®ï¼Œä½†å‘ç°å…¶æ•ˆæœä»éš¾ä»¥å®Œå…¨åŒ¹é…ä¸“å®¶çº§æ¨ç†æ¨¡å‹çš„è½¨è¿¹ï¼Œæ­ç¤ºäº†ä¸“å®¶CoTä¸­æŸäº›éš¾ä»¥å¤åˆ¶çš„æ½œåœ¨ç‰¹è´¨ã€‚é€šè¿‡å¯¹é—®é¢˜éš¾åº¦ã€å¤šæ ·æ€§å’Œç­”æ¡ˆé•¿åº¦ç­‰å…³é”®å±æ€§çš„åˆ†æï¼Œè¯¥ç ”ç©¶æŒ‡å‡ºç²¾å¿ƒç­–åˆ’çš„å°è§„æ¨¡äººå·¥CoTæ•°æ®å¯¹äºæ¿€æ´»æ¨¡å‹æ¨ç†è¡Œä¸ºå…·æœ‰æ˜¾è‘—ä»·å€¼ã€‚ä¸ºæ­¤ï¼Œä½œè€…å‘å¸ƒäº†è·¨å¤šä¸ªç»†åŒ–é˜¶æ®µçš„äººå·¥ç¼–å†™æ•°æ®é›†ï¼Œä¸ºæ¢ç´¢é«˜æ•ˆçš„æ¨ç†ç›‘ç£æœºåˆ¶æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the Second AI for Math Workshop at the 42nd International Conference on Machine Learning (ICML 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.09850v3",
      "published_date": "2025-07-14 01:14:50 UTC",
      "updated_date": "2025-07-16 17:16:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:46:01.699345+00:00"
    },
    {
      "arxiv_id": "2507.09846v4",
      "title": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training",
      "title_zh": "ç©¿è¶Šâ€œæ²³æµâ€ï¼šè§£ææ— è°ƒåº¦æ–¹æ³•åœ¨è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­çš„ä¼˜åŠ¿",
      "authors": [
        "Minhak Song",
        "Beomhan Baek",
        "Kwangjun Ahn",
        "Chulhee Yun"
      ],
      "abstract": "As both model and dataset sizes continue to scale rapidly, conventional pretraining strategies with fixed compute budgets-such as cosine learning rate schedules-are increasingly inadequate for large-scale training. Recent alternatives, including warmup-stable-decay (WSD) schedules and weight averaging, offer greater flexibility. However, WSD relies on explicit decay phases to track progress, while weight averaging addresses this limitation at the cost of additional memory. In search of a more principled and scalable alternative, we revisit the Schedule-Free (SF) method [Defazio et al., 2024], which has shown strong empirical performance across diverse settings. We show that SF-AdamW effectively navigates the \"river\" structure of the loss landscape without decay phases or auxiliary averaging, making it particularly suitable for continuously scaling training workloads. To understand this behavior, we conduct a theoretical and empirical analysis of SF dynamics, revealing that it implicitly performs weight averaging without memory overhead. Guided by this analysis, we propose a refined variant of SF that improves robustness to momentum and performs better under large batch sizes, addressing key limitations of the original method. Together, these results establish SF as a practical, scalable, and theoretically grounded approach for language model training.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº† Schedule-Free (SF) æ–¹æ³•åœ¨è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­çš„åº”ç”¨ä¼˜åŠ¿ï¼Œæ—¨åœ¨å…‹æœä¼ ç»Ÿ cosine learning rate schedules å’Œ warmup-stable-decay (WSD) åœ¨å¤§è§„æ¨¡è®­ç»ƒä¸­çš„çµæ´»æ€§ä¸è¶³ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒSF-AdamW èƒ½å¤Ÿåœ¨ä¸ä¾èµ–æ˜¾å¼è¡°å‡é˜¶æ®µæˆ–é¢å¤–å†…å­˜å¼€é”€çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆåº”å¯¹ loss landscape ä¸­çš„ â€œriverâ€ ç»“æ„ã€‚é€šè¿‡ç†è®ºä¸å®è¯åˆ†æï¼Œä½œè€…æ­ç¤ºäº† SF å®é™…ä¸Šåœ¨éšå¼åœ°æ‰§è¡Œ weight averagingï¼Œä»è€Œåœ¨ä¸å¢åŠ è´Ÿæ‹…çš„å‰æä¸‹æå‡æ€§èƒ½ã€‚é’ˆå¯¹åŸæ–¹æ³•çš„å±€é™ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§æ”¹è¿›çš„ SF å˜ä½“ï¼Œæ˜¾è‘—å¢å¼ºäº†å¯¹ momentum çš„é²æ£’æ€§ï¼Œå¹¶åœ¨ large batch sizes åœºæ™¯ä¸‹è¡¨ç°æ›´ä½³ã€‚è¿™äº›å‘ç°ç¡®ç«‹äº† SF ä½œä¸ºä¸€ç§å®ç”¨ã€å¯æ‰©å±•ä¸”å…·å¤‡ç†è®ºæ”¯æ’‘çš„è¯­è¨€æ¨¡å‹è®­ç»ƒæ–¹æ¡ˆçš„åœ°ä½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.09846v4",
      "published_date": "2025-07-14 00:54:48 UTC",
      "updated_date": "2025-11-01 03:58:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:46:07.730022+00:00"
    },
    {
      "arxiv_id": "2507.10621v1",
      "title": "Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats",
      "title_zh": "åšå¼ˆè®ºã€LLMä¸æ™ºèƒ½ä½“AIçš„äº¤æ±‡ï¼šé‡å¡‘æ™ºèƒ½å¨èƒæ—¶ä»£çš„ç½‘ç»œå®‰å…¨",
      "authors": [
        "Quanyan Zhu"
      ],
      "abstract": "Protecting cyberspace requires not only advanced tools but also a shift in how we reason about threats, trust, and autonomy. Traditional cybersecurity methods rely on manual responses and brittle heuristics. To build proactive and intelligent defense systems, we need integrated theoretical frameworks and software tools. Game theory provides a rigorous foundation for modeling adversarial behavior, designing strategic defenses, and enabling trust in autonomous systems. Meanwhile, software tools process cyber data, visualize attack surfaces, verify compliance, and suggest mitigations. Yet a disconnect remains between theory and practical implementation.\n  The rise of Large Language Models (LLMs) and agentic AI offers a new path to bridge this gap. LLM-powered agents can operationalize abstract strategies into real-world decisions. Conversely, game theory can inform the reasoning and coordination of these agents across complex workflows. LLMs also challenge classical game-theoretic assumptions, such as perfect rationality or static payoffs, prompting new models aligned with cognitive and computational realities. This co-evolution promises richer theoretical foundations and novel solution concepts. Agentic AI also reshapes software design: systems must now be modular, adaptive, and trust-aware from the outset.\n  This chapter explores the intersection of game theory, agentic AI, and cybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic, Bayesian, and signaling games) and solution concepts. We then examine how LLM agents can enhance cyber defense and introduce LLM-driven games that embed reasoning into AI agents. Finally, we explore multi-agent workflows and coordination games, outlining how this convergence fosters secure, intelligent, and adaptive cyber systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åšå¼ˆè®º(Game Theory)ã€å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸æ™ºèƒ½ä½“AI(Agentic AI)åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸçš„äº¤å‰èåˆï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿé˜²å¾¡æ‰‹æ®µåœ¨åº”å¯¹æ™ºèƒ½åŒ–å¨èƒæ—¶çš„æ»åæ€§ä¸å±€é™æ€§ã€‚åšå¼ˆè®ºä¸ºæ¨¡æ‹Ÿå¯¹æŠ—è¡Œä¸ºã€è®¾è®¡æˆ˜ç•¥é˜²å¾¡åŠå»ºç«‹è‡ªä¸»ç³»ç»Ÿä¿¡ä»»æä¾›äº†ä¸¥è°¨çš„ç†è®ºåŸºç¡€ï¼Œæ¶µç›–äº†é™æ€(Static)ã€åŠ¨æ€(Dynamic)ã€è´å¶æ–¯(Bayesian)åŠä¿¡å·åšå¼ˆ(Signaling games)ç­‰æ¡†æ¶ã€‚å…·å¤‡å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨èƒ½åŠ›çš„æ™ºèƒ½ä½“èƒ½å¤Ÿå°†æŠ½è±¡çš„åšå¼ˆç­–ç•¥è½¬åŒ–ä¸ºå®é™…çš„é˜²å¾¡å†³ç­–ï¼ŒåŒæ—¶å¤§è¯­è¨€æ¨¡å‹çš„å¼•å…¥ä¹ŸæŒ‘æˆ˜å¹¶é‡å¡‘äº†ç»å…¸åšå¼ˆè®ºä¸­å…³äºå®Œå…¨ç†æ€§(Perfect rationality)æˆ–é™æ€æ”¶ç›Š(Static payoffs)çš„å‡è®¾ã€‚æ–‡ç« é€šè¿‡å¼•å…¥é©±åŠ¨æ¨ç†çš„LLM-driven gameså’Œå¤šæ™ºèƒ½ä½“å·¥ä½œæµ(Multi-agent workflows)åŠåè°ƒåšå¼ˆ(Coordination games)ï¼Œå±•ç¤ºäº†å¦‚ä½•å°†ç†è®ºç ”ç©¶ä¸å®é™…è½¯ä»¶å·¥å…·ç›¸ç»“åˆã€‚è¿™ç§ååŒè¿›åŒ–ä¸ä»…ä¸ºç½‘ç»œå®‰å…¨æä¾›äº†æ›´ä¸°å¯Œçš„ç†è®ºæ”¯æ’‘ï¼Œè¿˜æ¨åŠ¨äº†æ¨¡å—åŒ–ã€è‡ªé€‚åº”ä¸”å…·å¤‡ä¿¡ä»»æ„ŸçŸ¥(Trust-aware)çš„æ™ºèƒ½é˜²å¾¡ç³»ç»Ÿçš„æ„å»ºã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.GT"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.10621v1",
      "published_date": "2025-07-14 00:49:44 UTC",
      "updated_date": "2025-07-14 00:49:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:46:11.325375+00:00"
    },
    {
      "arxiv_id": "2507.09837v1",
      "title": "A Pre-training Framework for Relational Data with Information-theoretic Principles",
      "title_zh": "åŸºäºä¿¡æ¯è®ºåŸç†çš„å…³ç³»å‹æ•°æ®é¢„è®­ç»ƒæ¡†æ¶",
      "authors": [
        "Quang Truong",
        "Zhikai Chen",
        "Mingxuan Ju",
        "Tong Zhao",
        "Neil Shah",
        "Jiliang Tang"
      ],
      "abstract": "Relational databases underpin critical infrastructure across a wide range of domains, yet the design of generalizable pre-training strategies for learning from relational databases remains an open challenge due to task heterogeneity. Specifically, there exist infinitely many possible downstream tasks, as tasks are defined based on relational schema graphs, temporal dependencies, and SQL-defined label logics. An effective pre-training framework is desired to take these factors into account in order to obtain task-aware representations. By incorporating knowledge of the underlying distribution that drives label generation, downstream tasks can benefit from relevant side-channel information. To bridge this gap, we introduce Task Vector Estimation (TVE), a novel pre-training framework that constructs predictive supervisory signals via set-based aggregation over schema traversal graphs, explicitly modeling next-window relational dynamics. We formalize our approach through an information-theoretic lens, demonstrating that task-informed representations retain more relevant signals than those obtained without task priors. Extensive experiments on the RelBench benchmark show that TVE consistently outperforms traditional pre-training baselines. Our findings advocate for pre-training objectives that encode task heterogeneity and temporal structure as design principles for predictive modeling on relational databases.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†ç”±äºä»»åŠ¡å¼‚è´¨æ€§ï¼Œå¦‚å…³ç³»æ¨¡å¼å›¾(relational schema graphs)ã€æ—¶é—´ä¾èµ–å’ŒSQLå®šä¹‰çš„æ ‡ç­¾é€»è¾‘ï¼Œå¯¼è‡´çš„å…³ç³»æ•°æ®åº“é€šç”¨é¢„è®­ç»ƒç­–ç•¥è®¾è®¡é¢ä¸´çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Task Vector Estimation (TVE)ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¿¡æ¯è®ºåŸåˆ™çš„æ–°å‹é¢„è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨è·å¾—ä»»åŠ¡æ„ŸçŸ¥(task-aware)çš„ç‰¹å¾è¡¨ç¤ºã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨æ¨¡å¼éå†å›¾ä¸Šè¿›è¡ŒåŸºäºé›†åˆçš„èšåˆæ¥æ„å»ºé¢„æµ‹æ€§ç›‘ç£ä¿¡å·ï¼Œä»è€Œæ˜¾å¼å»ºæ¨¡ä¸‹ä¸€çª—å£çš„å…³ç³»åŠ¨æ€ã€‚ç ”ç©¶ä»ä¿¡æ¯è®ºè§’åº¦è¯æ˜äº†ä»»åŠ¡æ„ŸçŸ¥è¡¨ç¤ºæ¯”ç¼ºä¹ä»»åŠ¡å…ˆéªŒçš„è¡¨ç¤ºèƒ½ä¿ç•™æ›´å¤šç›¸å…³ä¿¡å·ã€‚åœ¨ RelBench åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒTVE çš„æ€§èƒ½å§‹ç»ˆä¼˜äºä¼ ç»Ÿçš„é¢„è®­ç»ƒåŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶ç»“æœæœ‰åŠ›åœ°æ”¯æŒäº†å°†ä»»åŠ¡å¼‚è´¨æ€§å’Œæ—¶é—´ç»“æ„ç¼–ç ä¸ºé¢„è®­ç»ƒç›®æ ‡ï¼Œä½œä¸ºå…³ç³»æ•°æ®åº“é¢„æµ‹å»ºæ¨¡çš„æ ¸å¿ƒè®¾è®¡åŸåˆ™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09837v1",
      "published_date": "2025-07-14 00:17:21 UTC",
      "updated_date": "2025-07-14 00:17:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:46:08.981569+00:00"
    },
    {
      "arxiv_id": "2507.09836v1",
      "title": "Multi-residual Mixture of Experts Learning for Cooperative Control in Multi-vehicle Systems",
      "title_zh": "é¢å‘å¤šè½¦è¾†ç³»ç»ŸååŒæ§åˆ¶çš„å¤šæ®‹å·®æ··åˆä¸“å®¶å­¦ä¹ ",
      "authors": [
        "Vindula Jayawardana",
        "Sirui Li",
        "Yashar Farid",
        "Cathy Wu"
      ],
      "abstract": "Autonomous vehicles (AVs) are becoming increasingly popular, with their applications now extending beyond just a mode of transportation to serving as mobile actuators of a traffic flow to control flow dynamics. This contrasts with traditional fixed-location actuators, such as traffic signals, and is referred to as Lagrangian traffic control. However, designing effective Lagrangian traffic control policies for AVs that generalize across traffic scenarios introduces a major challenge. Real-world traffic environments are highly diverse, and developing policies that perform robustly across such diverse traffic scenarios is challenging. It is further compounded by the joint complexity of the multi-agent nature of traffic systems, mixed motives among participants, and conflicting optimization objectives subject to strict physical and external constraints. To address these challenges, we introduce Multi-Residual Mixture of Expert Learning (MRMEL), a novel framework for Lagrangian traffic control that augments a given suboptimal nominal policy with a learned residual while explicitly accounting for the structure of the traffic scenario space. In particular, taking inspiration from residual reinforcement learning, MRMEL augments a suboptimal nominal AV control policy by learning a residual correction, but at the same time dynamically selects the most suitable nominal policy from a pool of nominal policies conditioned on the traffic scenarios and modeled as a mixture of experts. We validate MRMEL using a case study in cooperative eco-driving at signalized intersections in Atlanta, Dallas Fort Worth, and Salt Lake City, with real-world data-driven traffic scenarios. The results show that MRMEL consistently yields superior performance-achieving an additional 4%-9% reduction in aggregate vehicle emissions relative to the strongest baseline in each setting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è½¦è¾†(Autonomous vehicles, AVs)åœ¨äº¤é€šæµæ§åˆ¶ä¸­é¢ä¸´çš„åœºæ™¯æ³›åŒ–ä¸å¤šæ™ºèƒ½ä½“ç³»ç»ŸååŒç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMulti-Residual Mixture of Expert Learning (MRMEL)çš„æ‹‰æ ¼æœ—æ—¥äº¤é€šæ§åˆ¶(Lagrangian traffic control)æ–°æ¡†æ¶ã€‚MRMELå€Ÿé‰´äº†æ®‹å·®å¼ºåŒ–å­¦ä¹ (residual reinforcement learning)çš„æ€æƒ³ï¼Œé€šè¿‡å­¦ä¹ æ®‹å·®ä¿®æ­£æ¥å¢å¼ºç°æœ‰çš„æ¬¡ä¼˜åä¹‰ç­–ç•¥ï¼Œå¹¶æ˜¾å¼åœ°è€ƒè™‘äº†äº¤é€šåœºæ™¯ç©ºé—´çš„ç»“æ„ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ··åˆä¸“å®¶æ¨¡å‹(mixture of experts)ç»“æ„ï¼Œèƒ½å¤Ÿæ ¹æ®ç‰¹å®šäº¤é€šåœºæ™¯ä»ç­–ç•¥æ± ä¸­åŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„åä¹‰ç­–ç•¥ã€‚åœ¨æ¶‰åŠäºšç‰¹å…°å¤§ã€è¾¾æ‹‰æ–¯å’Œç›æ¹–åŸçš„çœŸå®äº¤é€šæ•°æ®å®éªŒä¸­ï¼ŒMRMELè¢«åº”ç”¨äºä¿¡å·ç¯è·¯å£çš„åä½œç”Ÿæ€é©¾é©¶ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMRMELåœ¨ä¸åŒåœºæ™¯ä¸‹å‡è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ï¼Œç›¸æ¯”äºæœ€å¼ºåŸºå‡†æ¨¡å‹ï¼Œä½¿è½¦è¾†æ€»æ’æ”¾é‡é¢å¤–é™ä½äº†4%-9%ï¼ŒéªŒè¯äº†å…¶åœ¨å¤æ‚äº¤é€šååŒæ§åˆ¶ä¸­çš„æœ‰æ•ˆæ€§ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.09836v1",
      "published_date": "2025-07-14 00:17:12 UTC",
      "updated_date": "2025-07-14 00:17:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T04:46:14.833312+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 165,
  "processed_papers_count": 165,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T04:47:21.410610+00:00"
}