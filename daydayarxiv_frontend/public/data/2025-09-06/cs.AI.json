{
  "date": "2025-09-06",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-06 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„æ—¥æŠ¥ä½œè€…ã€‚\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†â€œå±æœºæ„Ÿâ€ä¸â€œç¡¬æ ¸ç†è®ºâ€ã€‚**å®‰å…¨é¢†åŸŸ**çˆ†å‡ºå¤§é›·ï¼Œä» coding agent çš„è¿œç¨‹ä»£ç æ‰§è¡Œ (RCE) åˆ° Microsoft 365 Copilot çš„é›¶ç‚¹å‡»æ³¨å…¥ï¼ŒAgent çš„å®‰å…¨æ€§å—åˆ°ä¸¥å³»æŒ‘æˆ˜ï¼›**ç†è®ºæ–¹é¢**ï¼ŒåŒæ›²å‡ ä½• (Hyperbolic) åœ¨ LLM ä¸­çš„åº”ç”¨ç»¼è¿°ã€å…‰å­¦ç‰©ç†ç¥ç»ç½‘ç»œçš„é€šç”¨æ€§è¯æ˜ï¼Œä»¥åŠæ— éœ€ Attention çš„ TreeGPT æ¶æ„éƒ½è®©äººçœ¼å‰ä¸€äº®ã€‚\n\n---\n\n### ğŸš¨ Agent å®‰å…¨ä¸ LLM æ”»é˜² (é‡ç£…å…³æ³¨)\n\nä»Šå¤©æœ‰ä¸¤ç¯‡å…³äº Agent å®‰å…¨çš„è®ºæ–‡éå¸¸å€¼å¾—ä¸šç•Œå…³æ³¨ï¼Œç‰¹åˆ«æ˜¯æ­£åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½² Copilot æˆ– Coding Agent çš„å›¢é˜Ÿã€‚\n\n**1. ä»å·¥å…·è°ƒç”¨è§†è§’å¯¹ç¼–ç¨‹ Agent è¿›è¡Œçº¢é˜Ÿæµ‹è¯•ï¼šå®è¯å®‰å…¨è¯„ä¼°**\n**Red-Teaming Coding Agents from a Tool-Invocation Perspective: An Empirical Security Assessment**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šè¿™æ˜¯å¯¹å½“å‰çƒ­é—¨ç¼–ç¨‹ Agentï¼ˆå¦‚ **Cursor, Claude Code, Copilot, Windsurf** ç­‰ï¼‰çš„é¦–æ¬¡ç³»ç»Ÿæ€§çº¢é˜Ÿæµ‹è¯•ã€‚ä½œè€…å‘ç°äº†ä¸¥é‡çš„ **RCE (è¿œç¨‹ä»£ç æ‰§è¡Œ)** æ¼æ´ã€‚\n*   **ä¸»è¦å‘ç°**ï¼š\n    *   **ToolLeak æ¼æ´**ï¼šæ”»å‡»è€…å¯ä»¥é€šè¿‡è‰¯æ€§çš„å‚æ•°æ£€ç´¢è¯±å¯¼ Agent æ³„éœ²ç³»ç»Ÿ Promptã€‚\n    *   **å·¥å…·åŠ«æŒ**ï¼šé€šè¿‡åœ¨å·¥å…·æè¿°å’Œè¿”å›å€¼ä¸­æ³¨å…¥â€œåŒé€šé“ Promptâ€ï¼ŒæˆåŠŸåŠ«æŒäº† Agent çš„è¡Œä¸ºã€‚\n    *   **æˆ˜æœ**ï¼šåœ¨ 25 ä¸ª Agent-LLM ç»„åˆä¸­ï¼Œ19 ä¸ªè¢«æ”»ç ´ã€‚Cursor å’Œ Claude Code ç­‰çŸ¥åå·¥å…·å‡å—åˆ°å½±å“ã€‚è¿™æ˜¯ä¸€æ¬¡å¯¹å½“å‰ IDE æ™ºèƒ½ä½“å®‰å…¨æ€§çš„ä¸¥å‰è­¦é’Ÿã€‚\n\n**2. EchoLeakï¼šç”Ÿäº§çº§ LLM ç³»ç»Ÿä¸­çš„é¦–ä¸ªçœŸå®ä¸–ç•Œé›¶ç‚¹å‡»æç¤ºæ³¨å…¥åˆ©ç”¨**\n**EchoLeak: The First Real-World Zero-Click Prompt Injection Exploit in a Production LLM System**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šé’ˆå¯¹ **Microsoft 365 Copilot** çš„æ·±åº¦æ¡ˆä¾‹ç ”ç©¶ (CVE-2025-32711)ã€‚\n*   **æ”»å‡»æ–¹å¼**ï¼šè¿™æ˜¯ä¸€ç§**é›¶ç‚¹å‡» (Zero-Click)** æ”»å‡»ã€‚æ”»å‡»è€…åªéœ€å‘é€ä¸€å°ç‰¹åˆ¶çš„ç”µå­é‚®ä»¶ï¼Œåˆ©ç”¨ Markdown ç»•è¿‡é“¾æ¥ç¼–è¾‘ã€è‡ªåŠ¨è·å–å›¾ç‰‡ä»¥åŠæ»¥ç”¨ Teams ä»£ç†ï¼Œå°±èƒ½åœ¨ç”¨æˆ·æ¯«æ— å¯Ÿè§‰çš„æƒ…å†µä¸‹å®ç°æ•°æ®å¤–æ³„ã€‚\n*   **æ„ä¹‰**ï¼šè¯æ˜äº† Prompt Injection åœ¨ä¼ä¸šçº§ç”Ÿäº§ç¯å¢ƒä¸­æ˜¯çœŸå®å­˜åœ¨çš„é«˜å±æ¼æ´ï¼Œç°æœ‰çš„ XPIA åˆ†ç±»å™¨é˜²å¾¡å¹¶æœªå®Œå…¨å¥æ•ˆã€‚\n\n**3. æ¨ç†å¼•å…¥äº†æ–°çš„æŠ•æ¯’æ”»å‡»ï¼Œå´ä¹Ÿä½¿å…¶å˜å¾—æ›´å¤æ‚**\n**Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šç ”ç©¶äº†é’ˆå¯¹æ€ç»´é“¾ (CoT) çš„â€œåˆ†è§£æ¨ç†æŠ•æ¯’â€ã€‚\n*   **æœ‰è¶£å‘ç°**ï¼šæ”»å‡»è€…å¯ä»¥åªä¿®æ”¹æ¨ç†è·¯å¾„è€Œä¸æ”¹å˜æœ€ç»ˆç­”æ¡ˆï¼Œä»è€Œæ½œä¼ä¸‹æ¥ã€‚ä½†ä¹Ÿå‘ç°äº†ä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ï¼šLLM çš„æ¨ç†èƒ½åŠ›æœ¬èº«äº§ç”Ÿäº†ä¸€ç§**æ¶Œç°çš„é²æ£’æ€§**â€”â€”æ¨¡å‹æœ‰æ—¶èƒ½åœ¨æ¨ç†è¿‡ç¨‹ä¸­â€œè‡ªæˆ‘çº æ­£â€å›æ­£ç¡®çš„é€»è¾‘ï¼Œä½¿å¾—é€šè¿‡æ¨ç†è·¯å¾„è§¦å‘åé—¨æ¯”é¢„æƒ³çš„è¦éš¾ã€‚\n\n**4. è§£ç  LLM ä¸­çš„æ½œåœ¨æ”»å‡»é¢ï¼šé€šè¿‡ Web æ‘˜è¦ä¸­çš„ HTML è¿›è¡Œæç¤ºæ³¨å…¥**\n**Decoding Latent Attack Surfaces in LLMs: Prompt Injection via HTML in Web Summarization**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šç ”ç©¶å¦‚ä½•åˆ©ç”¨ç½‘é¡µä¸­ä¸å¯è§çš„ HTML å…ƒç´ ï¼ˆå¦‚ `<meta>`, `aria-label`ï¼‰è¿›è¡Œæç¤ºæ³¨å…¥ã€‚\n*   **å‘ç°**ï¼šåœ¨ Llama 4 Scout å’Œ Gemma 9B çš„æµ‹è¯•ä¸­ï¼Œè¿™ç§éšè”½æ³¨å…¥èƒ½æœ‰æ•ˆæ“çºµæ‘˜è¦ç»“æœï¼Œä¸”ä¸æ”¹å˜ç½‘é¡µçš„è§†è§‰å†…å®¹ã€‚\n\n---\n\n### ğŸ§  æ¨¡å‹æ¶æ„ä¸åŸºç¡€ç†è®º (ç¡¬æ ¸)\n\n**5. åŒæ›²å¤§è¯­è¨€æ¨¡å‹**\n**Hyperbolic Large Language Models**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šè¿™æ˜¯ä¸€ç¯‡å…³äºå°†**åŒæ›²å‡ ä½• (Hyperbolic Geometry)** å¼•å…¥ LLM çš„ç»¼è¿°ã€‚\n*   **èƒŒæ™¯**ï¼šç°å®ä¸–ç•Œçš„æ•°æ®ï¼ˆå¦‚è›‹ç™½è´¨ç½‘ç»œã€è¯­è¨€å¥æ³•æ ‘ï¼‰å¾€å¾€å…·æœ‰éæ¬§å‡ é‡Œå¾—çš„å±‚çº§ç»“æ„ï¼Œä¼ ç»Ÿçš„æ¬§æ°ç©ºé—´åµŒå…¥éš¾ä»¥å®Œç¾æ•æ‰ã€‚\n*   **è´¡çŒ®**ï¼šæ–‡ç« æ€»ç»“äº†å››ç±»æ–¹æ³•ï¼šé€šè¿‡æŒ‡æ•°/å¯¹æ•°æ˜ å°„çš„ Hyperbolic LLMã€åŒæ›²å¾®è°ƒã€å…¨åŒæ›² LLM ä»¥åŠåŒæ›²çŠ¶æ€ç©ºé—´æ¨¡å‹ (SSM)ã€‚è¿™å¯èƒ½æ˜¯æå‡ LLM å¤„ç†å¤æ‚å±‚çº§æ•°æ®èƒ½åŠ›çš„å…³é”®æ–¹å‘ã€‚\n\n**6. å…·æœ‰å¤šå˜é‡éçº¿æ€§çš„ç‰©ç†ç¥ç»ç½‘ç»œçš„é€šç”¨æ€§**\n**Universality of physical neural networks with multivariate nonlinearity**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šä¸ºäº†è§£å†³ AI èƒ½è€—é—®é¢˜ï¼Œå…‰å­¦è®¡ç®—ç­‰ç‰©ç†ç¥ç»ç½‘ç»œ (PNN) è¢«å¯„äºˆåšæœ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºç¡€å®šç†ï¼Œç¡®ç«‹äº† PNN çš„**é€šç”¨æ€§æ¡ä»¶**ã€‚\n*   **çªç ´**ï¼šåŸºäºè¯¥å®šç†è®¾è®¡äº†ä¸€ç§å¯æ‰©å±•çš„è‡ªç”±ç©ºé—´å…‰å­¦æ¶æ„ï¼Œè¯æ˜äº†ç‰©ç†ç³»ç»Ÿåœ¨æ»¡è¶³ç‰¹å®šç¼–ç æ¡ä»¶ä¸‹ï¼Œå¯ä»¥å­¦ä¹ ä»»æ„æ•°æ®å…³ç³»ï¼ˆå³å…·å¤‡é€šç”¨é€¼è¿‘èƒ½åŠ›ï¼‰ã€‚\n\n**7. TreeGPTï¼šç”¨äºç»“æ„åŒ–æ¨ç†çš„çº¯ TreeFFN ç¼–ç å™¨-è§£ç å™¨æ¶æ„**\n**TreeGPT: Pure TreeFFN Encoder-Decoder Architecture for Structured Reasoning Without Attention Mechanisms**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šæŒ‘æˆ˜ Transformer çš„ç»Ÿæ²»åœ°ä½ã€‚æå‡ºäº†ä¸€ç§**æ—  Attention** çš„æ¶æ„ï¼Œä»…ä½¿ç”¨åŒå‘ TreeFFN ç»„ä»¶ã€‚\n*   **æ•ˆæœ**ï¼šåœ¨ ARC Prize 2025 æ•°æ®é›†ä¸Šï¼Œä»…ç”¨ 3.16M å‚æ•°å°±è¾¾åˆ°äº†æé«˜çš„éªŒè¯å‡†ç¡®ç‡ã€‚è¿™è¡¨æ˜å¯¹äºç‰¹å®šçš„ç»“æ„åŒ–æ¨ç†ä»»åŠ¡ï¼Œä¹Ÿè®¸æˆ‘ä»¬ä¸éœ€è¦æ˜‚è´µçš„ Attention æœºåˆ¶ã€‚\n\n**8. ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æå‡å¤§è¯­è¨€æ¨¡å‹çš„åŒå‘æ¨ç†èƒ½åŠ›**\n**Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šæ¢è®¨äº† LLM æ˜¯å¦çœŸçš„â€œç†è§£â€æ¦‚å¿µï¼Œè¿˜æ˜¯åªæ˜¯æ¨¡å¼åŒ¹é…ã€‚\n*   **é—®é¢˜**ï¼šæ¨¡å‹é€šå¸¸å­˜åœ¨â€œè®¤çŸ¥ä¸“ä¸šåŒ–â€ï¼Œå³å­¦äº† `A -> B` å´æ— æ³•åæ¨ `B -> A`ï¼ˆä¾‹å¦‚èƒ½å°† `userIndex` æ”¹åä¸º `i`ï¼Œå´æ— æ³•åæ¨ `i` ä»£è¡¨ `userIndex`ï¼‰ã€‚\n*   **æ–¹æ³•**ï¼šæå‡ºäº†å¯¹æ¯”å¾®è°ƒ (CFT)ï¼Œé€šè¿‡æ··æ·†ä»»åŠ¡å¼ºåˆ¶æ¨¡å‹è¿›è¡ŒåŒå‘å­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€†å‘æ¨ç†èƒ½åŠ›ã€‚\n\n---\n\n### ğŸ’Š AI for Science & Medicine (åº”ç”¨è½åœ°)\n\n**9. ZhiFangDanTaiï¼šä¸ºä¸­è¯æ–¹å‰‚å¾®è°ƒåŸºäºå›¾çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¨¡å‹**\n**ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šé’ˆå¯¹ä¸­åŒ»è¯ (TCM) æ–¹å‰‚çš„å¤æ‚æ€§ï¼ˆå›è‡£ä½ä½¿ã€ç¦å¿Œç­‰ï¼‰ï¼Œæå‡ºäº† **GraphRAG + LLM å¾®è°ƒ** çš„æ¡†æ¶ã€‚\n*   **è´¡çŒ®**ï¼šæ„å»ºäº†ç»“æ„åŒ–çš„ä¸­åŒ»è¯çŸ¥è¯†å›¾è°±ï¼Œå¹¶è¯æ˜äº† GraphRAG ç»“åˆå¾®è°ƒèƒ½æœ‰æ•ˆå‡å°‘å¹»è§‰ï¼Œæå‡æ–¹å‰‚è§£é‡Šçš„æ·±åº¦ã€‚æ¨¡å‹å·²å¼€æºã€‚\n\n**10. èŠå¤©æœºå™¨äººå¸®åŠ©æ‚£è€…äº†è§£è‡ªèº«å¥åº·**\n**Chatbot To Help Patients Understand Their Health**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šå‘å¸ƒäº† NoteAid-Chatbotï¼Œåˆ©ç”¨å¤šæ™ºèƒ½ä½“ LLM å’Œå¼ºåŒ–å­¦ä¹  (RL) æ„å»ºã€‚\n*   **äº®ç‚¹**ï¼šä¸éœ€è¦äººå·¥æ ‡æ³¨æ•°æ®ï¼Œä»…é€šè¿‡æ¨¡æ‹ŸåŒ»é™¢å‡ºé™¢åœºæ™¯ä¸­çš„æ‚£è€…ç†è§£åº¦è¯„ä¼°ä½œä¸ºå¥–åŠ±ä¿¡å·è¿›è¡Œ PPO è®­ç»ƒã€‚å›¾çµæµ‹è¯•æ˜¾ç¤ºå…¶è¡¨ç°ä¼˜äºéä¸“å®¶äººç±»ã€‚\n\n---\n\n### ğŸ¤– å…·èº«æ™ºèƒ½ä¸å¤šæ¨¡æ€\n\n**11. OccVLAï¼šå…·æœ‰éšå¼ 3D å ç”¨ç›‘ç£çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹**\n**OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šè§£å†³äº† VLA æ¨¡å‹ç¼ºä¹ 3D ç©ºé—´ç†è§£çš„é—®é¢˜ã€‚\n*   **æ–¹æ³•**ï¼šä¸ä¾èµ–æ˜‚è´µçš„æ˜¾å¼ 3D è¾“å…¥ï¼Œè€Œæ˜¯å°† 3D å ç”¨ (Occupancy) æ—¢ä½œä¸ºé¢„æµ‹è¾“å‡ºä¹Ÿä½œä¸ºç›‘ç£ä¿¡å·ã€‚æ¨ç†æ—¶å¯ä»¥è·³è¿‡å ç”¨é¢„æµ‹ï¼Œé›¶é¢å¤–å¼€é”€ã€‚åœ¨ nuScenes è½¨è¿¹è§„åˆ’ä¸Šè¾¾åˆ° SOTAã€‚\n\n**12. ç©¿ç€æˆæœå­¦ä¹ è¡Œèµ°ï¼šå—ç¾å­¦çº¦æŸçš„äººå½¢æœºå™¨äººçš„å¯¹æŠ—æ€§è¿åŠ¨å…ˆéªŒ**\n**Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids**\n*   **æ ¸å¿ƒå†…å®¹**ï¼šä¸ºå¨±ä¹æœºå™¨äºº Cosmoï¼ˆå¤´ç‰¹åˆ«å¤§ï¼Œå ä½“é‡çš„ 16%ï¼Œä¸”å—é™äºå¤–å£³ï¼‰è®¾è®¡è¡Œèµ°ç®—æ³•ã€‚\n*   **æ–¹æ³•**ï¼šä½¿ç”¨å¯¹æŠ—æ€§è¿åŠ¨å…ˆéªŒ (AMP) çš„å¼ºåŒ–å­¦ä¹ ï¼Œè®©è¿™ä¸ªâ€œèº«ææ¯”ä¾‹å¤±è°ƒâ€çš„æœºå™¨äººåœ¨ä¿æŒç¾è§‚åŠ¨ä½œçš„åŒæ—¶è¿˜èƒ½èµ°å¾—ç¨³ã€‚\n\n---\n\n### ğŸ’¡ å…¶ä»–æœ‰è¶£çš„è®ºæ–‡\n\n*   **[Llama-GENBA]** **Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian**: ä¸“é—¨é’ˆå¯¹**å¾·è¯­å’Œå·´ä¼åˆ©äºšæ–¹è¨€**ä¼˜åŒ–çš„ 10B æ¨¡å‹ã€‚ä¿æŠ¤ä½èµ„æºè¯­è¨€ï¼ˆå·´ä¼åˆ©äºšè¯­ï¼‰çš„ä¸€æ¬¡å°è¯•ã€‚\n*   **[Pop Lyrics]** **From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics**: ç”¨ LLM åˆ†ææµè¡Œæ­Œè¯çš„æƒ…æ„Ÿã€‚æƒ³çŸ¥é“è¿™é¦–æ­Œæ˜¯å–œæ˜¯æ‚²ï¼Ÿè¿™ä¸ª Benchmark å¯ä»¥å¸®ä½ ã€‚\n*   **[Time Series]** **time2time: Causal Intervention in Hidden States to Simulate Rare Events...**: å³ä½¿åœ¨å¹³é™çš„å¸‚åœºå‘¨æœŸï¼Œä¹Ÿå¯ä»¥é€šè¿‡å¹²é¢„æ—¶é—´åºåˆ—å¤§æ¨¡å‹çš„éšè—çŠ¶æ€ï¼Œå¼ºåˆ¶æ¨¡æ‹Ÿâ€œå¸‚åœºå´©ç›˜â€ç­‰ç½•è§äº‹ä»¶ã€‚é‡‘èå‹åŠ›æµ‹è¯•ç¥å™¨ã€‚\n\n---\n\n**æ—¥æŠ¥ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡å†æ¬¡æé†’æˆ‘ä»¬ï¼Œåœ¨äº«å— LLM å¸¦æ¥ä¾¿åˆ©çš„åŒæ—¶ï¼Œ**å®‰å…¨é˜²æŠ¤**ï¼ˆå°¤å…¶æ˜¯é’ˆå¯¹ Agent çš„å·¥å…·è°ƒç”¨å±‚é¢ï¼‰å¿…é¡»å…ˆè¡Œã€‚åŒæ—¶ï¼Œå­¦æœ¯ç•Œå¹¶æœªåœæ­¢å¯¹ Transformer æ¶æ„çš„åæ€ä¸é©æ–°ï¼Œç‰©ç†ç¥ç»ç½‘ç»œå’ŒåŒæ›²å‡ ä½•çš„æ¢ç´¢ä»¤äººå…´å¥‹ã€‚\n\nç¥å¤§å®¶å‘¨æœ«æ„‰å¿«ï¼Œç§‘ç ”é¡ºåˆ©ï¼",
  "papers": [
    {
      "arxiv_id": "2509.05867v1",
      "title": "ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula",
      "title_zh": "ZhiFangDanTaiï¼šé¢å‘ä¸­åŒ»æ–¹å‰‚çš„åŸºäºå›¾çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¨¡å‹å¾®è°ƒ",
      "authors": [
        "ZiXuan Zhang",
        "Bowen Hao",
        "Yingjie Li",
        "Hongzhi Yin"
      ],
      "abstract": "Traditional Chinese Medicine (TCM) formulas play a significant role in treating epidemics and complex diseases. Existing models for TCM utilize traditional algorithms or deep learning techniques to analyze formula relationships, yet lack comprehensive results, such as complete formula compositions and detailed explanations. Although recent efforts have used TCM instruction datasets to fine-tune Large Language Models (LLMs) for explainable formula generation, existing datasets lack sufficient details, such as the roles of the formula's sovereign, minister, assistant, courier; efficacy; contraindications; tongue and pulse diagnosis-limiting the depth of model outputs. To address these challenges, we propose ZhiFangDanTai, a framework combining Graph-based Retrieval-Augmented Generation (GraphRAG) with LLM fine-tuning. ZhiFangDanTai uses GraphRAG to retrieve and synthesize structured TCM knowledge into concise summaries, while also constructing an enhanced instruction dataset to improve LLMs' ability to integrate retrieved information. Furthermore, we provide novel theoretical proofs demonstrating that integrating GraphRAG with fine-tuning techniques can reduce generalization error and hallucination rates in the TCM formula task. Experimental results on both collected and clinical datasets demonstrate that ZhiFangDanTai achieves significant improvements over state-of-the-art models. Our model is open-sourced at https://huggingface.co/tczzx6/ZhiFangDanTai1.0.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿä¸­åŒ» (TCM) æ–¹å‰‚æ¨¡å‹åœ¨ç”Ÿæˆæ–¹å‰‚ç»†èŠ‚ã€å›è‡£ä½ä½¿å…³ç³»åŠèˆŒè„‰è±¡è§£é‡Šæ–¹é¢å­˜åœ¨çš„ä¸è¶³ï¼Œæå‡ºäº†åä¸º ZhiFangDanTai çš„æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆåŸºäºå›¾çš„æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ (GraphRAG) ä¸å¤§è¯­è¨€æ¨¡å‹ (LLMs) å¾®è°ƒï¼Œåˆ©ç”¨ GraphRAG æ£€ç´¢å¹¶åˆæˆç»“æ„åŒ–ä¸­åŒ»çŸ¥è¯†ï¼Œå¹¶ä¾æ‰˜å¢å¼ºæŒ‡ä»¤æ•°æ®é›†æå‡æ¨¡å‹çš„ä¿¡æ¯æ•´åˆèƒ½åŠ›ã€‚ç ”ç©¶åœ¨ç†è®ºä¸Šè¯æ˜äº† GraphRAG ä¸å¾®è°ƒçš„ç»“åˆèƒ½æ˜¾è‘—é™ä½ä¸­åŒ»æ–¹å‰‚ä»»åŠ¡ä¸­çš„æ³›åŒ–è¯¯å·®å’Œå¹»è§‰ (hallucination) ç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒZhiFangDanTai åœ¨å…¬å¼€å’Œä¸´åºŠæ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ (SOTA)ã€‚ç›®å‰è¯¥æ¨¡å‹å·²å¼€æºï¼Œä¸ºå®ç°æ·±å±‚æ¬¡ã€å¯è§£é‡Šçš„ä¸­åŒ»æ–¹å‰‚æ™ºèƒ½ç”Ÿæˆæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05867v1",
      "published_date": "2025-09-06 23:48:46 UTC",
      "updated_date": "2025-09-06 23:48:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:54:50.390982+00:00"
    },
    {
      "arxiv_id": "2509.05841v1",
      "title": "GenAI on Wall Street -- Opportunities and Risk Controls",
      "title_zh": "åå°”è¡—çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šæœºé‡ä¸é£é™©ç®¡æ§",
      "authors": [
        "Jackie Shen"
      ],
      "abstract": "We give an overview on the emerging applications of GenAI in the financial industry, especially within investment banks. Inherent to these exciting opportunities is a new realm of risks that must be managed properly. By heeding both the Yin and Yang sides of GenAI, we can accelerate its organic growth while safeguarding the entire financial industry during this nascent era of AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¦‚è¿°äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (GenAI) åœ¨é‡‘èè¡Œä¸šï¼Œç‰¹åˆ«æ˜¯æŠ•èµ„é“¶è¡Œ (Investment Banks) ä¸­çš„æ–°å…´åº”ç”¨åŠå…¶å¸¦æ¥çš„å‘å±•æœºé‡ã€‚åœ¨æ¢ç´¢è¿™äº›åº”ç”¨æ½œåŠ›çš„åŒæ—¶ï¼Œè®ºæ–‡é‡ç‚¹å¼ºè°ƒäº†ä¼´éšè€Œæ¥çš„å…¨æ–°é£é™©é¢†åŸŸï¼Œå¹¶æŒ‡å‡ºå¿…é¡»å¯¹è¿™äº›é£é™©è¿›è¡Œå¦¥å–„ç®¡ç†ã€‚é€šè¿‡å…¨é¢å®¡è§† GenAI çš„â€œé˜´é˜³â€ä¸¤é¢ï¼Œå³æœºé‡ä¸é£é™©çš„å¹³è¡¡ï¼Œç ”ç©¶æå‡ºäº†ä¸€å¥—é£é™©æ§åˆ¶ä¸æœºä¼šå¹¶é‡çš„æ¡†æ¶ã€‚è¿™ç§ç­–ç•¥æ—¨åœ¨ AI å‘å±•çš„åˆæœŸé˜¶æ®µï¼Œæ—¢èƒ½åŠ é€Ÿå…¶åœ¨é‡‘èé¢†åŸŸçš„æœ‰æœºå¢é•¿ï¼Œåˆèƒ½é€šè¿‡æœ‰æ•ˆçš„ç®¡ç†æ‰‹æ®µç¡®ä¿æ•´ä¸ªè¡Œä¸šçš„ç¨³å¥ä¸å®‰å…¨ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "q-fin.RM"
      ],
      "primary_category": "math.OC",
      "comment": "30 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05841v1",
      "published_date": "2025-09-06 21:47:19 UTC",
      "updated_date": "2025-09-06 21:47:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:54:58.991888+00:00"
    },
    {
      "arxiv_id": "2509.05831v3",
      "title": "Decoding Latent Attack Surfaces in LLMs: Prompt Injection via HTML in Web Summarization",
      "title_zh": "å‰–æå¤§è¯­è¨€æ¨¡å‹çš„æ½œåœ¨æ”»å‡»é¢ï¼šç½‘é¡µæ‘˜è¦ä¸­åŸºäº HTML çš„æç¤ºè¯æ³¨å…¥",
      "authors": [
        "Ishaan Verma",
        "Arsheya Yadav"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into web-based systems for content summarization, yet their susceptibility to prompt injection attacks remains a pressing concern. In this study, we explore how non-visible HTML elements such as <meta>, aria-label, and alt attributes can be exploited to embed adversarial instructions without altering the visible content of a webpage. We introduce a novel dataset comprising 280 static web pages, evenly divided between clean and adversarial injected versions, crafted using diverse HTML-based strategies. These pages are processed through a browser automation pipeline to extract both raw HTML and rendered text, closely mimicking real-world LLM deployment scenarios. We evaluate two state-of-the-art open-source models, Llama 4 Scout (Meta) and Gemma 9B IT (Google), on their ability to summarize this content. Using both lexical (ROUGE-L) and semantic (SBERT cosine similarity) metrics, along with manual annotations, we assess the impact of these covert injections. Our findings reveal that over 29% of injected samples led to noticeable changes in the Llama 4 Scout summaries, while Gemma 9B IT showed a lower, yet non-trivial, success rate of 15%. These results highlight a critical and largely overlooked vulnerability in LLM driven web pipelines, where hidden adversarial content can subtly manipulate model outputs. Our work offers a reproducible framework and benchmark for evaluating HTML-based prompt injection and underscores the urgent need for robust mitigation strategies in LLM applications involving web content.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç½‘é¡µå†…å®¹æ‘˜è¦ä»»åŠ¡ä¸­é¢ä¸´çš„éšè”½æç¤ºæ³¨å…¥(Prompt Injection)æ”»å‡»é£é™©ã€‚ä½œè€…æ­ç¤ºäº†æ”»å‡»è€…å¦‚ä½•åˆ©ç”¨ç½‘é¡µä¸­ä¸å¯è§çš„HTMLå…ƒç´ ï¼ˆå¦‚<meta>æ ‡ç­¾ã€aria-labelå’Œaltå±æ€§ï¼‰åµŒå…¥å¯¹æŠ—æ€§æŒ‡ä»¤ï¼Œåœ¨ä¸æ”¹å˜å¯è§å†…å®¹çš„æƒ…å†µä¸‹æ“çºµæ¨¡å‹è¾“å‡ºã€‚ç ”ç©¶é€šè¿‡æµè§ˆå™¨è‡ªåŠ¨åŒ–æµç¨‹æ„å»ºäº†ä¸€ä¸ªåŒ…å«280ä¸ªç½‘é¡µçš„åŸºå‡†æ•°æ®é›†ï¼Œå¹¶å¯¹Llama 4 Scoutå’ŒGemma 9B ITä¸¤ä¸ªä¸»æµå¼€æºæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒé‡‡ç”¨ROUGE-Lå’ŒSBERTä½™å¼¦ç›¸ä¼¼åº¦ç­‰æŒ‡æ ‡ï¼Œå‘ç°è¶…è¿‡29%çš„æ³¨å…¥æ ·æœ¬æ˜¾è‘—æ”¹å˜äº†Llama 4 Scoutçš„æ‘˜è¦ï¼Œè€ŒGemma 9B ITä¹Ÿè¡¨ç°å‡º15%çš„è¢«æ”»å‡»æˆåŠŸç‡ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†LLMç½‘é¡µå¤„ç†æµç¨‹ä¸­é•¿æœŸè¢«å¿½è§†çš„å®‰å…¨æ¼æ´ï¼Œå¹¶ä¸ºè¯„ä¼°åŸºäºHTMLçš„æç¤ºæ³¨å…¥æä¾›äº†ä¸€ä¸ªå¯å¤ç°çš„æ¡†æ¶å’ŒåŸºå‡†ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05831v3",
      "published_date": "2025-09-06 21:05:18 UTC",
      "updated_date": "2025-11-11 06:53:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:54:52.244484+00:00"
    },
    {
      "arxiv_id": "2509.05818v2",
      "title": "Chatbot To Help Patients Understand Their Health",
      "title_zh": "åŠ©åŠ›æ‚£è€…ç†è§£è‡ªèº«å¥åº·çŠ¶å†µçš„èŠå¤©æœºå™¨äºº",
      "authors": [
        "Won Seok Jang",
        "Hieu Tran",
        "Manav Mistry",
        "SaiKiran Gandluri",
        "Yifan Zhang",
        "Sharmin Sultana",
        "Sunjae Kown",
        "Yuan Zhang",
        "Zonghai Yao",
        "Hong Yu"
      ],
      "abstract": "Patients must possess the knowledge necessary to actively participate in their care. We present NoteAid-Chatbot, a conversational AI that promotes patient understanding via a novel 'learning as conversation' framework, built on a multi-agent large language model (LLM) and reinforcement learning (RL) setup without human-labeled data. NoteAid-Chatbot was built on a lightweight LLaMA 3.2 3B model trained in two stages: initial supervised fine-tuning on conversational data synthetically generated using medical conversation strategies, followed by RL with rewards derived from patient understanding assessments in simulated hospital discharge scenarios. Our evaluation, which includes comprehensive human-aligned assessments and case studies, demonstrates that NoteAid-Chatbot exhibits key emergent behaviors critical for patient education, such as clarity, relevance, and structured dialogue, even though it received no explicit supervision for these attributes. Our results show that even simple Proximal Policy Optimization (PPO)-based reward modeling can successfully train lightweight, domain-specific chatbots to handle multi-turn interactions, incorporate diverse educational strategies, and meet nuanced communication objectives. Our Turing test demonstrates that NoteAid-Chatbot surpasses non-expert human. Although our current focus is on healthcare, the framework we present illustrates the feasibility and promise of applying low-cost, PPO-based RL to realistic, open-ended conversational domains, broadening the applicability of RL-based alignment methods.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†NoteAid-Chatbotï¼Œè¿™æ˜¯ä¸€æ¬¾åŸºäºâ€œlearning as conversationâ€æ¡†æ¶çš„å¯¹è¯å¼AIï¼Œæ—¨åœ¨æé«˜æ‚£è€…å¯¹è‡ªèº«å¥åº·çŠ¶å†µçš„ç†è§£ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†multi-agent Large Language Model (LLM)å’ŒReinforcement Learning (RL)æ¶æ„ï¼Œä¸”æ— éœ€äººå·¥æ ‡æ³¨æ•°æ®ã€‚NoteAid-ChatbotåŸºäºè½»é‡çº§çš„LLaMA 3.2 3Bæ¨¡å‹ï¼Œç»è¿‡åˆæˆåŒ»å­¦å¯¹è¯æ•°æ®çš„supervised fine-tuningä»¥åŠåœ¨æ¨¡æ‹Ÿå‡ºé™¢åœºæ™¯ä¸‹é€šè¿‡PPO-based RLè¿›è¡Œçš„å¥–åŠ±å»ºæ¨¡è®­ç»ƒã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æœºå™¨äººåœ¨å¯¹è¯æ¸…æ™°åº¦ã€ç›¸å…³æ€§å’Œç»“æ„åŒ–å¼•å¯¼æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„æ¶Œç°è¡Œä¸ºï¼Œå¹¶åœ¨Turing testä¸­è¶…è¶Šäº†éä¸“å®¶äººç±»çš„è¡¨ç°ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åˆ©ç”¨ä½æˆæœ¬å¼ºåŒ–å­¦ä¹ è®­ç»ƒé¢†åŸŸç‰¹å®šã€å…·å¤‡å¤šè½®äº¤äº’èƒ½åŠ›çš„èŠå¤©æœºå™¨äººçš„å¯è¡Œæ€§ï¼Œä¸ºRL-based alignmentæ–¹æ³•åœ¨ç°å®å¼€æ”¾é¢†åŸŸçš„åº”ç”¨æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in EMNLP 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2509.05818v2",
      "published_date": "2025-09-06 19:50:44 UTC",
      "updated_date": "2025-10-24 21:50:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:54:50.584503+00:00"
    },
    {
      "arxiv_id": "2509.05801v2",
      "title": "time2time: Causal Intervention in Hidden States to Simulate Rare Events in Time Series Foundation Models",
      "title_zh": "time2timeï¼šåˆ©ç”¨éšçŠ¶æ€å› æœå¹²é¢„æ¨¡æ‹Ÿæ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ä¸­çš„ç¨€æœ‰äº‹ä»¶",
      "authors": [
        "Debdeep Sanyal",
        "Aaryan Nagpal",
        "Dhruv Kumar",
        "Murari Mandal",
        "Saurabh Deshpande"
      ],
      "abstract": "While transformer-based foundation models excel at forecasting routine patterns, two questions remain: do they internalize semantic concepts such as market regimes, or merely fit curves? And can their internal representations be leveraged to simulate rare, high-stakes events such as market crashes? To investigate this, we introduce activation transplantation, a causal intervention that manipulates hidden states by imposing the statistical moments of one event (e.g., a historical crash) onto another (e.g., a calm period) during the forward pass. This procedure deterministically steers forecasts: injecting crash semantics induces downturn predictions, while injecting calm semantics suppresses crashes and restores stability. Beyond binary control, we find that models encode a graded notion of event severity, with the latent vector norm directly correlating with the magnitude of systemic shocks. Validated across two architecturally distinct TSFMs, Toto (decoder only) and Chronos (encoder-decoder), our results demonstrate that steerable, semantically grounded representations are a robust property of large time series transformers. Our findings provide evidence for a latent concept space that governs model predictions, shifting interpretability from post-hoc attribution to direct causal intervention, and enabling semantic \"what-if\" analysis for strategic stress-testing.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ (Time Series Foundation Models, TSFMs) æ˜¯å¦å†…åŒ–äº†è¯­ä¹‰æ¦‚å¿µï¼Œå¹¶å¼•å…¥äº†æ¿€æ´»ç§»æ¤ (activation transplantation) è¿™ä¸€å› æœå¹²é¢„æ‰‹æ®µæ¥æ¨¡æ‹Ÿç¨€æœ‰é«˜é£é™©äº‹ä»¶ã€‚é€šè¿‡åœ¨æ¨ç†è¿‡ç¨‹ä¸­å°†ç‰¹å®šäº‹ä»¶çš„ç»Ÿè®¡çŸ©æ–½åŠ åˆ°éšè—çŠ¶æ€ (hidden states) ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç¡®å®šæ€§åœ°å¼•å¯¼æ¨¡å‹é¢„æµ‹ï¼Œä¾‹å¦‚é€šè¿‡æ³¨å…¥å´©ç›˜è¯­ä¹‰è¯±å‘ä¸‹è¡Œé¢„æµ‹ã€‚å®éªŒå‘ç°æ¨¡å‹ç¼–ç äº†äº‹ä»¶ä¸¥é‡ç¨‹åº¦çš„æ¢¯åº¦æ¦‚å¿µï¼Œå…¶æ½œå‘é‡èŒƒæ•° (latent vector norm) ä¸ç³»ç»Ÿæ€§å†²å‡»çš„å¹…åº¦ç›´æ¥ç›¸å…³ã€‚åœ¨ Toto å’Œ Chronos ä¸¤ç§ä¸åŒæ¶æ„ä¸Šçš„éªŒè¯è¡¨æ˜ï¼Œå…·æœ‰è¯­ä¹‰åŸºç¡€çš„å¯æ§è¡¨ç¤ºæ˜¯å¤§å‹æ—¶é—´åºåˆ— Transformer çš„ç¨³å¥å±æ€§ã€‚è¯¥ç ”ç©¶ä¸ºæ§åˆ¶æ¨¡å‹é¢„æµ‹çš„æ½œåœ¨æ¦‚å¿µç©ºé—´æä¾›äº†è¯æ®ï¼Œä½¿è§£é‡Šæ€§ä»äº‹åå½’å› è½¬å‘ç›´æ¥å› æœå¹²é¢„ï¼Œå¹¶æ”¯æŒäº†æˆ˜ç•¥å‹åŠ›æµ‹è¯•ä¸­çš„è¯­ä¹‰â€œå‡è®¾â€åˆ†æã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05801v2",
      "published_date": "2025-09-06 18:28:20 UTC",
      "updated_date": "2025-10-04 15:13:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:54:52.971477+00:00"
    },
    {
      "arxiv_id": "2509.05799v1",
      "title": "Hybrid Fourier Neural Operator-Plasma Fluid Model for Fast and Accurate Multiscale Simulations of High Power Microwave Breakdown",
      "title_zh": "ç”¨äºé«˜åŠŸç‡å¾®æ³¢å‡»ç©¿é«˜æ•ˆç²¾å‡†å¤šå°ºåº¦æ¨¡æ‹Ÿçš„æ··åˆå‚…é‡Œå¶ç¥ç»ç®—å­-ç­‰ç¦»å­ä½“æµä½“æ¨¡å‹",
      "authors": [
        "Kalp Pandya",
        "Pratik Ghosh",
        "Ajeya Mandikal",
        "Shivam Gandha",
        "Bhaskar Chaudhury"
      ],
      "abstract": "Modeling and simulation of High Power Microwave (HPM) breakdown, a multiscale phenomenon, is computationally expensive and requires solving Maxwell's equations (EM solver) coupled with a plasma continuity equation (plasma solver). In this work, we present a hybrid modeling approach that combines the accuracy of a differential equation-based plasma fluid solver with the computational efficiency of FNO (Fourier Neural Operator) based EM solver. Trained on data from an in-house FDTD-based plasma-fluid solver, the FNO replaces computationally expensive EM field updates, while the plasma solver governs the dynamic plasma response. The hybrid model is validated on microwave streamer formation, due to diffusion ionization mechanism, in a 2D scenario for unseen incident electric fields corresponding to entirely new plasma streamer simulations not included in model training, showing excellent agreement with FDTD based fluid simulations in terms of streamer shape, velocity, and temporal evolution. This hybrid FNO based strategy delivers significant acceleration of the order of 60X compared to traditional simulations for the specified problem size and offers an efficient alternative for computationally demanding multiscale and multiphysics simulations involved in HPM breakdown. Our work also demonstrate how such hybrid pipelines can be used to seamlessly to integrate existing C-based simulation codes with Python-based machine learning frameworks for simulations of plasma science and engineering problems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆ Fourier Neural Operator (FNO) ä¸ç­‰ç¦»å­ä½“æµä½“æ¨¡å‹çš„æ··åˆå»ºæ¨¡æ–¹æ³•ï¼Œæ—¨åœ¨åŠ é€Ÿé«˜åŠŸç‡å¾®æ³¢ (High Power Microwave, HPM) å‡»ç©¿è¿‡ç¨‹ä¸­çš„å¤šå°ºåº¦ä»¿çœŸã€‚è¯¥æ¡†æ¶åˆ©ç”¨åŸºäº FNO çš„ EM æ±‚è§£å™¨æ›¿æ¢è®¡ç®—æˆæœ¬é«˜æ˜‚çš„ç”µç£åœºæ›´æ–°ï¼ŒåŒæ—¶ç»“åˆå¾®åˆ†æ–¹ç¨‹æ±‚è§£å™¨æ¥å¤„ç†åŠ¨æ€ç­‰ç¦»å­ä½“å“åº”ã€‚åœ¨ 2D å¾®æ³¢æµæ³¨ (streamer) å½¢æˆåœºæ™¯çš„éªŒè¯ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨å¤„ç†è®­ç»ƒé›†å¤–çš„å…¨æ–°å…¥å°„ç”µåœºæ—¶ï¼Œåœ¨æµæ³¨å½¢çŠ¶ã€é€Ÿåº¦å’Œæ—¶é—´æ¼”åŒ–æ–¹é¢ä¸ä¼ ç»Ÿ FDTD ä»¿çœŸä¿æŒäº†é«˜åº¦ä¸€è‡´ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ··åˆç­–ç•¥åœ¨ç‰¹å®šé—®é¢˜è§„æ¨¡ä¸‹å®ç°äº†çº¦ 60 å€çš„è®¡ç®—åŠ é€Ÿï¼Œä¸ºå¤„ç†å¤æ‚çš„ HPM å¤šç‰©ç†åœºä»¿çœŸæä¾›äº†é«˜æ•ˆæ›¿ä»£æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å±•ç¤ºäº†å¦‚ä½•é€šè¿‡æ··åˆæµæ°´çº¿å®ç°ç°æœ‰ C-based ä»¿çœŸä»£ç ä¸ Python-based æœºå™¨å­¦ä¹ æ¡†æ¶åœ¨ç­‰ç¦»å­ä½“ç§‘å­¦é¢†åŸŸçš„æ— ç¼é›†æˆã€‚",
      "categories": [
        "physics.plasm-ph",
        "cs.AI",
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05799v1",
      "published_date": "2025-09-06 18:24:33 UTC",
      "updated_date": "2025-09-06 18:24:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:55:26.583324+00:00"
    },
    {
      "arxiv_id": "2509.05796v3",
      "title": "Dual-Mode Deep Anomaly Detection for Medical Manufacturing: Structural Similarity and Feature Distance",
      "title_zh": "åŒ»ç–—åˆ¶é€ ä¸­çš„åŒæ¨¡æ·±åº¦å¼‚å¸¸æ£€æµ‹ï¼šç»“æ„ç›¸ä¼¼æ€§ä¸ç‰¹å¾è·ç¦»",
      "authors": [
        "Julio Zanon Diaz",
        "Georgios Siogkas",
        "Peter Corcoran"
      ],
      "abstract": "Automated visual inspection in medical-device manufacturing faces unique challenges, including extremely low defect rates, limited annotated data, hardware restrictions on production lines, and the need for validated, explainable artificial-intelligence systems. This paper presents two attention-guided autoencoder architectures that address these constraints through complementary anomaly-detection strategies. The first employs a multi-scale structural-similarity (4-MS-SSIM) index for inline inspection, enabling interpretable, real-time defect detection on constrained hardware. The second applies a Mahalanobis-distance analysis of randomly reduced latent features for efficient feature-space monitoring and lifecycle verification. Both approaches share a lightweight backbone optimised for high-resolution imagery for typical manufacturing conditions. Evaluations on the Surface Seal Image (SSI) dataset-representing sterile-barrier packaging inspection-demonstrate that the proposed methods outperform reference baselines, including MOCCA, CPCAE, and RAG-PaDiM, under realistic industrial constraints. Cross-domain validation on the MVTec-Zipper benchmark confirms comparable accuracy to state-of-the-art anomaly-detection methods. The dual-mode framework integrates inline anomaly detection and supervisory monitoring, advancing explainable AI architectures toward greater reliability, observability, and lifecycle monitoring in safety-critical manufacturing environments. To facilitate reproducibility, the source code developed for the experiments has been released in the project repository, while the datasets were obtained from publicly available sources.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å™¨æ¢°åˆ¶é€ ä¸­ä½ç¼ºé™·ç‡ã€æ ‡æ³¨æ•°æ®æœ‰é™åŠç¡¬ä»¶å—é™ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸¤ç§åŸºäºæ³¨æ„åŠ›å¼•å¯¼çš„è‡ªç¼–ç å™¨(autoencoder)æ¶æ„ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒæ¨¡æ·±åº¦å¼‚å¸¸æ£€æµ‹æ¡†æ¶ã€‚ç¬¬ä¸€ç§æ¨¡å¼é‡‡ç”¨å¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§(4-MS-SSIM)æŒ‡æ•°ï¼Œæ—¨åœ¨å®ç°å—é™ç¡¬ä»¶ä¸Šçš„å®æ—¶ã€å¯è§£é‡Šåœ¨çº¿æ£€æµ‹ï¼›ç¬¬äºŒç§æ¨¡å¼åˆ™åˆ©ç”¨éšæœºç¼©å‡æ½œç‰¹å¾çš„é©¬æ°è·ç¦»(Mahalanobis-distance)åˆ†æï¼Œç”¨äºé«˜æ•ˆçš„ç‰¹å¾ç©ºé—´ç›‘æ§å’Œç”Ÿå‘½å‘¨æœŸéªŒè¯ã€‚ä¸¤ç§æ–¹æ³•å‡å…±ç”¨ä¸€ä¸ªé’ˆå¯¹é«˜åˆ†è¾¨ç‡å›¾åƒä¼˜åŒ–çš„è½»é‡åŒ–ä¸»å¹²ç½‘ç»œï¼Œä»¥é€‚åº”å…¸å‹çš„ç”Ÿäº§ç¯å¢ƒã€‚åœ¨Surface Seal Image (SSI)æ•°æ®é›†å’ŒMVTec-ZipperåŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºMOCCAã€CPCAEå’ŒRAG-PaDiMç­‰ä¸»æµåŸºå‡†æ¨¡å‹ã€‚è¯¥æ¡†æ¶æˆåŠŸå°†åœ¨çº¿å¼‚å¸¸æ£€æµ‹ä¸ç›‘ç£ç›‘æ§ç›¸ç»“åˆï¼Œåœ¨æ»¡è¶³å·¥ä¸šç°å®çº¦æŸçš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†å®‰å…¨å…³é”®å‹åˆ¶é€ ä¸­äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯é æ€§ã€å¯è§‚æµ‹æ€§å’Œå¯è§£é‡Šæ€§(explainable AI)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 3 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.05796v3",
      "published_date": "2025-09-06 18:17:40 UTC",
      "updated_date": "2025-11-13 14:53:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:55:12.892066+00:00"
    },
    {
      "arxiv_id": "2509.05778v1",
      "title": "DCV-ROOD Evaluation Framework: Dual Cross-Validation for Robust Out-of-Distribution Detection",
      "title_zh": "DCV-ROOD è¯„ä¼°æ¡†æ¶ï¼šé¢å‘é²æ£’åˆ†å¸ƒå¤–æ£€æµ‹çš„åŒé‡äº¤å‰éªŒè¯",
      "authors": [
        "Arantxa Urrea-CastaÃ±o",
        "NicolÃ¡s Segura-Kunsagi",
        "Juan Luis SuÃ¡rez-DÃ­az",
        "Rosana Montes",
        "Francisco Herrera"
      ],
      "abstract": "Out-of-distribution (OOD) detection plays a key role in enhancing the robustness of artificial intelligence systems by identifying inputs that differ significantly from the training distribution, thereby preventing unreliable predictions and enabling appropriate fallback mechanisms. Developing reliable OOD detection methods is a significant challenge, and rigorous evaluation of these techniques is essential for ensuring their effectiveness, as it allows researchers to assess their performance under diverse conditions and to identify potential limitations or failure modes. Cross-validation (CV) has proven to be a highly effective tool for providing a reasonable estimate of the performance of a learning algorithm. Although OOD scenarios exhibit particular characteristics, an appropriate adaptation of CV can lead to a suitable evaluation framework for this setting. This work proposes a dual CV framework for robust evaluation of OOD detection models, aimed at improving the reliability of their assessment. The proposed evaluation framework aims to effectively integrate in-distribution (ID) and OOD data while accounting for their differing characteristics. To achieve this, ID data are partitioned using a conventional approach, whereas OOD data are divided by grouping samples based on their classes. Furthermore, we analyze the context of data with class hierarchy to propose a data splitting that considers the entire class hierarchy to obtain fair ID-OOD partitions to apply the proposed evaluation framework. This framework is called Dual Cross-Validation for Robust Out-of-Distribution Detection (DCV-ROOD). To test the validity of the evaluation framework, we selected a set of state-of-the-art OOD detection methods, both with and without outlier exposure. The results show that the method achieves very fast convergence to the true performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DCV-ROODï¼ˆDual Cross-Validation for Robust Out-of-Distribution Detectionï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ç¨³å¥è¯„ä¼°Out-of-Distribution (OOD)æ£€æµ‹æ¨¡å‹çš„åŒé‡äº¤å‰éªŒè¯æ¡†æ¶ã€‚ä¸ºäº†æœ‰æ•ˆæ•´åˆIn-distribution (ID)ä¸OODæ•°æ®çš„ä¸åŒç‰¹æ€§ï¼Œè¯¥æ¡†æ¶å¯¹IDæ•°æ®é‡‡ç”¨ä¼ ç»Ÿåˆ’åˆ†æ–¹æ³•ï¼Œè€Œå¯¹OODæ•°æ®åˆ™æŒ‰ç±»åˆ«åˆ†ç»„è¿›è¡Œæ ·æœ¬åˆ’åˆ†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ†æäº†å…·æœ‰ç±»åˆ«å±‚çº§ï¼ˆClass hierarchyï¼‰çš„æ•°æ®èƒŒæ™¯ï¼Œæå‡ºäº†ä¸€ç§è€ƒè™‘å®Œæ•´å±‚çº§ç»“æ„çš„åˆ’åˆ†ç­–ç•¥ï¼Œä»¥ç¡®ä¿è¯„ä¼°è¿‡ç¨‹ä¸­çš„ID-OODåˆ†åŒºå…¬å¹³æ€§ã€‚å®éªŒé€‰å–äº†ä¸€ç³»åˆ—å…ˆè¿›çš„OODæ£€æµ‹æ–¹æ³•è¿›è¡ŒéªŒè¯ï¼Œç»“æœæ˜¾ç¤ºDCV-ROODèƒ½å¤Ÿéå¸¸å¿«é€Ÿåœ°æ”¶æ•›åˆ°æ¨¡å‹çš„çœŸå®æ€§èƒ½ã€‚è¯¥å·¥ä½œé€šè¿‡æ”¹è¿›äº¤å‰éªŒè¯æœºåˆ¶ï¼Œä¸ºæå‡AIç³»ç»Ÿåœ¨é¢å¯¹åˆ†å¸ƒå¤–è¾“å…¥æ—¶çš„å¯é æ€§è¯„ä¼°æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages and appendix",
      "pdf_url": "https://arxiv.org/pdf/2509.05778v1",
      "published_date": "2025-09-06 17:20:09 UTC",
      "updated_date": "2025-09-06 17:20:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:55:35.997670+00:00"
    },
    {
      "arxiv_id": "2509.05772v1",
      "title": "Decision-Focused Learning Enhanced by Automated Feature Engineering for Energy Storage Optimisation",
      "title_zh": "é¢å‘å‚¨èƒ½ä¼˜åŒ–çš„è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹å¢å¼ºå‹å†³ç­–èšç„¦å­¦ä¹ ",
      "authors": [
        "Nasser Alkhulaifi",
        "Ismail Gokay Dogan",
        "Timothy R. Cargan",
        "Alexander L. Bowler",
        "Direnc Pekaslan",
        "Nicholas J. Watson",
        "Isaac Triguero"
      ],
      "abstract": "Decision-making under uncertainty in energy management is complicated by unknown parameters hindering optimal strategies, particularly in Battery Energy Storage System (BESS) operations. Predict-Then-Optimise (PTO) approaches treat forecasting and optimisation as separate processes, allowing prediction errors to cascade into suboptimal decisions as models minimise forecasting errors rather than optimising downstream tasks. The emerging Decision-Focused Learning (DFL) methods overcome this limitation by integrating prediction and optimisation; however, they are relatively new and have been tested primarily on synthetic datasets or small-scale problems, with limited evidence of their practical viability. Real-world BESS applications present additional challenges, including greater variability and data scarcity due to collection constraints and operational limitations. Because of these challenges, this work leverages Automated Feature Engineering (AFE) to extract richer representations and improve the nascent approach of DFL. We propose an AFE-DFL framework suitable for small datasets that forecasts electricity prices and demand while optimising BESS operations to minimise costs. We validate its effectiveness on a novel real-world UK property dataset. The evaluation compares DFL methods against PTO, with and without AFE. The results show that, on average, DFL yields lower operating costs than PTO and adding AFE further improves the performance of DFL methods by 22.9-56.5% compared to the same models without AFE. These findings provide empirical evidence for DFL's practical viability in real-world settings, indicating that domain-specific AFE enhances DFL and reduces reliance on domain expertise for BESS optimisation, yielding economic benefits with broader implications for energy management systems facing similar challenges.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Battery Energy Storage System (BESS)ä¼˜åŒ–ä¸­çš„ä¸ç¡®å®šæ€§å†³ç­–é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„Predict-Then-Optimise (PTO)æ–¹æ³•å› é¢„æµ‹ä¸ä¼˜åŒ–ç›®æ ‡è„±èŠ‚è€Œå¯¼è‡´å†³ç­–æ¬ ä½³ã€‚ä¸ºåº”å¯¹çœŸå®åœºæ™¯ä¸­æ•°æ®ç¨€ç¼ºå’Œé«˜å˜å¼‚æ€§çš„æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆAutomated Feature Engineering (AFE)çš„Decision-Focused Learning (DFL)æ¡†æ¶ï¼Œå³AFE-DFLã€‚è¯¥æ¡†æ¶åœ¨é¢„æµ‹ç”µåŠ›ä»·æ ¼å’Œéœ€æ±‚çš„åŒæ—¶ï¼Œé€šè¿‡AFEæå–æ›´ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºï¼Œä»¥ä¼˜åŒ–BESSè¿è¡Œå¹¶æœ€å°åŒ–æˆæœ¬ã€‚åœ¨è‹±å›½çœŸå®æˆ¿äº§æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDFLçš„è¿è¥æˆæœ¬å¹³å‡ä½äºPTOï¼Œä¸”åŠ å…¥AFEåï¼ŒDFLçš„æ€§èƒ½ç›¸æ¯”æ— ç‰¹å¾å·¥ç¨‹çš„æ¨¡å‹æå‡äº†22.9%-56.5%ã€‚è¯¥ç ”ç©¶ä¸ºDFLåœ¨èƒ½æºç®¡ç†é¢†åŸŸçš„å®é™…å¯è¡Œæ€§æä¾›äº†å®è¯æ”¯æŒï¼Œè¯æ˜äº†AFEèƒ½æ˜¾è‘—é™ä½å¯¹é¢†åŸŸä¸“å®¶çŸ¥è¯†çš„ä¾èµ–ï¼Œå¹¶å…·æœ‰é‡è¦çš„ç»æµä»·å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 10 figures, journal-based paper",
      "pdf_url": "https://arxiv.org/pdf/2509.05772v1",
      "published_date": "2025-09-06 16:54:07 UTC",
      "updated_date": "2025-09-06 16:54:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:55:21.699018+00:00"
    },
    {
      "arxiv_id": "2509.05768v1",
      "title": "Real-E: A Foundation Benchmark for Advancing Robust and Generalizable Electricity Forecasting",
      "title_zh": "Real-Eï¼šæ¨åŠ¨ç¨³å¥ä¸”é«˜æ³›åŒ–æ€§ç”µåŠ›é¢„æµ‹çš„åŸºç¡€æ€§åŸºå‡†",
      "authors": [
        "Chen Shao",
        "Yue Wang",
        "Zhenyi Zhu",
        "Zhanbo Huang",
        "Sebastian PÃ¼tz",
        "Benjamin SchÃ¤fer",
        "Tobais KÃ¤fer",
        "Michael FÃ¤rber"
      ],
      "abstract": "Energy forecasting is vital for grid reliability and operational efficiency. Although recent advances in time series forecasting have led to progress, existing benchmarks remain limited in spatial and temporal scope and lack multi-energy features. This raises concerns about their reliability and applicability in real-world deployment. To address this, we present the Real-E dataset, covering over 74 power stations across 30+ European countries over a 10-year span with rich metadata. Using Real- E, we conduct an extensive data analysis and benchmark over 20 baselines across various model types. We introduce a new metric to quantify shifts in correlation structures and show that existing methods struggle on our dataset, which exhibits more complex and non-stationary correlation dynamics. Our findings highlight key limitations of current methods and offer a strong empirical basis for building more robust forecasting models",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Real-Eï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æ¨è¿›é²æ£’ä¸”å¯æ³›åŒ–çš„ç”µåŠ›é¢„æµ‹çš„åŸºç¡€åŸºå‡†æ•°æ®é›†ã€‚Real-E æ¶µç›–äº†æ¬§æ´² 30 å¤šä¸ªå›½å®¶çš„ 74 ä¸ªå‘ç”µç«™ï¼Œæ—¶é—´è·¨åº¦é•¿è¾¾ 10 å¹´ï¼Œå¹¶åŒ…å«ä¸°å¯Œçš„å…ƒæ•°æ® (metadata)ã€‚é€šè¿‡åœ¨è¯¥æ•°æ®é›†ä¸Šå¯¹è¶…è¿‡ 20 ç§åŸºå‡†æ¨¡å‹ (baselines) è¿›è¡Œå¹¿æ³›è¯„ä¼°ï¼Œç ”ç©¶è€…å‘ç°ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä¸”éå¹³ç¨³ (non-stationary) çš„ç›¸å…³æ€§åŠ¨æ€æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§é‡åŒ–ç›¸å…³æ€§ç»“æ„åç§»çš„æ–°æŒ‡æ ‡ï¼Œè¿›ä¸€æ­¥æ­ç¤ºäº†å½“å‰é¢„æµ‹æŠ€æœ¯çš„å±€é™æ€§ã€‚è¯¥å·¥ä½œæ·±å…¥åˆ†æäº†ç°æœ‰æ–¹æ³•çš„ä¸è¶³ï¼Œä¸ºæ„å»ºæ›´å…·é²æ£’æ€§ (robust) å’Œæ³›åŒ–èƒ½åŠ› (generalizable) çš„ç”µåŠ›é¢„æµ‹æ¨¡å‹æä¾›äº†å¼ºæœ‰åŠ›çš„å®è¯åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.05768v1",
      "published_date": "2025-09-06 16:50:22 UTC",
      "updated_date": "2025-09-06 16:50:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:55:21.290245+00:00"
    },
    {
      "arxiv_id": "2509.12227v2",
      "title": "Learning to Route: Per-Sample Adaptive Routing for Multimodal Multitask Prediction",
      "title_zh": "å­¦ä¹ è·¯ç”±ï¼šé¢å‘å¤šæ¨¡æ€å¤šä»»åŠ¡é¢„æµ‹çš„é€æ ·æœ¬è‡ªé€‚åº”è·¯ç”±",
      "authors": [
        "Marzieh Ajirak",
        "Oded Bein",
        "Ellen Rose Bowen",
        "Dora Kanellopoulos",
        "Avital Falk",
        "Faith M. Gunning",
        "Nili Solomonov",
        "Logan Grosenick"
      ],
      "abstract": "We propose a unified framework for adaptive routing in multitask, multimodal prediction settings where data heterogeneity and task interactions vary across samples. Motivated by applications in psychotherapy where structured assessments and unstructured clinician notes coexist with partially missing data and correlated outcomes, we introduce a routing-based architecture that dynamically selects modality processing pathways and task-sharing strategies on a per-sample basis. Our model defines multiple modality paths, including raw and fused representations of text and numeric features and learns to route each input through the most informative expert combination. Task-specific predictions are produced by shared or independent heads depending on the routing decision, and the entire system is trained end-to-end. We evaluate the model on both synthetic data and real-world psychotherapy notes predicting depression and anxiety outcomes. Our experiments show that our method consistently outperforms fixed multitask or single-task baselines, and that the learned routing policy provides interpretable insights into modality relevance and task structure. This addresses critical challenges in personalized healthcare by enabling per-subject adaptive information processing that accounts for data heterogeneity and task correlations. Applied to psychotherapy, this framework could improve mental health outcomes, enhance treatment assignment precision, and increase clinical cost-effectiveness through personalized intervention strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å¤šä»»åŠ¡ã€å¤šæ¨¡æ€é¢„æµ‹è‡ªé€‚åº”è·¯ç”±(adaptive routing)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸åŒæ ·æœ¬é—´çš„æ•°æ®å¼‚æ„æ€§(data heterogeneity)å’Œä»»åŠ¡äº¤äº’å·®å¼‚ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†ä¸€ç§åŸºäºè·¯ç”±çš„æ¶æ„ï¼Œèƒ½å¤Ÿä¸ºæ¯ä¸ªæ ·æœ¬åŠ¨æ€é€‰æ‹©æ¨¡æ€å¤„ç†è·¯å¾„å’Œä»»åŠ¡å…±äº«ç­–ç•¥ã€‚æ¨¡å‹å®šä¹‰äº†å¤šç§æ¨¡æ€è·¯å¾„ï¼ŒåŒ…æ‹¬æ–‡æœ¬å’Œæ•°å€¼ç‰¹å¾çš„åŸå§‹åŠèåˆè¡¨ç¤ºï¼Œå¹¶å­¦ä¹ å°†æ¯ä¸ªè¾“å…¥è·¯ç”±è‡³æœ€æœ‰æ•ˆçš„ä¿¡æ¯ä¸“å®¶ç»„åˆã€‚æ ¹æ®è·¯ç”±å†³ç­–ï¼Œä»»åŠ¡ç‰¹å®šé¢„æµ‹ç”±å…±äº«æˆ–ç‹¬ç«‹çš„å¤´éƒ¨äº§ç”Ÿï¼Œæ•´ä¸ªç³»ç»Ÿé‡‡ç”¨ç«¯åˆ°ç«¯(end-to-end)è®­ç»ƒã€‚å®éªŒåœ¨åˆæˆæ•°æ®å’ŒçœŸå®å¿ƒç†æ²»ç–—è®°å½•ä¸Šè¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨é¢„æµ‹æŠ‘éƒå’Œç„¦è™‘ç»“æœæ–¹é¢ä¸€è‡´ä¼˜äºå›ºå®šçš„å¤šä»»åŠ¡æˆ–å•ä»»åŠ¡åŸºçº¿æ¨¡å‹ã€‚å­¦ä¹ åˆ°çš„è·¯ç”±ç­–ç•¥ä¸ºæ¨¡æ€ç›¸å…³æ€§å’Œä»»åŠ¡ç»“æ„æä¾›äº†å¯è§£é‡Šçš„è§è§£ï¼Œæœ‰æ•ˆåº”å¯¹äº†ä¸ªæ€§åŒ–åŒ»ç–—ä¸­çš„æ•°æ®æŒ‘æˆ˜ã€‚åœ¨å¿ƒç†æ²»ç–—åº”ç”¨ä¸­ï¼Œè¯¥æ¡†æ¶æœ‰æœ›é€šè¿‡ä¸ªæ€§åŒ–å¹²é¢„ç­–ç•¥æ”¹å–„å¿ƒç†å¥åº·ç»“æœå¹¶æé«˜ä¸´åºŠæˆæœ¬æ•ˆç›Šã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12227v2",
      "published_date": "2025-09-06 16:49:45 UTC",
      "updated_date": "2025-09-29 15:42:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:55:52.482202+00:00"
    },
    {
      "arxiv_id": "2509.05764v1",
      "title": "DRF: LLM-AGENT Dynamic Reputation Filtering Framework",
      "title_zh": "DRFï¼šå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“åŠ¨æ€ä¿¡èª‰è¿‡æ»¤æ¡†æ¶",
      "authors": [
        "Yuwei Lou",
        "Hao Hu",
        "Shaocong Ma",
        "Zongfei Zhang",
        "Liang Wang",
        "Jidong Ge",
        "Xianping Tao"
      ],
      "abstract": "With the evolution of generative AI, multi - agent systems leveraging large - language models(LLMs) have emerged as a powerful tool for complex tasks. However, these systems face challenges in quantifying agent performance and lack mechanisms to assess agent credibility. To address these issues, we introduce DRF, a dynamic reputation filtering framework. DRF constructs an interactive rating network to quantify agent performance, designs a reputation scoring mechanism to measure agent honesty and capability, and integrates an Upper Confidence Bound - based strategy to enhance agent selection efficiency. Experiments show that DRF significantly improves task completion quality and collaboration efficiency in logical reasoning and code - generation tasks, offering a new approach for multi - agent systems to handle large - scale tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨é‡åŒ–è¡¨ç°å’Œè¯„ä¼°å¯ä¿¡åº¦æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†DRFåŠ¨æ€å£°èª‰è¿‡æ»¤æ¡†æ¶ã€‚DRFé€šè¿‡æ„å»ºäº¤äº’å¼è¯„åˆ†ç½‘ç»œæ¥é‡åŒ–æ™ºèƒ½ä½“æ€§èƒ½ï¼Œå¹¶è®¾è®¡äº†å£°èª‰è¯„åˆ†æœºåˆ¶ä»¥è¡¡é‡æ™ºèƒ½ä½“çš„è¯šå®åº¦ä¸èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é›†æˆäº†åŸºäºç½®ä¿¡åŒºé—´ä¸Šç•Œ(Upper Confidence Bound)çš„ç­–ç•¥ï¼Œæ—¨åœ¨ä¼˜åŒ–æ™ºèƒ½ä½“çš„é€‰æ‹©æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDRFåœ¨é€»è¾‘æ¨ç†å’Œä»£ç ç”Ÿæˆä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†ä»»åŠ¡å®Œæˆè´¨é‡ä¸åä½œæ•ˆç‡ã€‚è¯¥ç ”ç©¶ä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¤„ç†å¤§è§„æ¨¡ä»»åŠ¡æä¾›äº†ä¸€ç§è¯„ä¼°ä¸è¿‡æ»¤çš„æ–°æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by ICONIP 2025 but not published",
      "pdf_url": "https://arxiv.org/pdf/2509.05764v1",
      "published_date": "2025-09-06 16:29:42 UTC",
      "updated_date": "2025-09-06 16:29:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:56:21.795110+00:00"
    },
    {
      "arxiv_id": "2509.07999v1",
      "title": "The Computational Foundations of Collective Intelligence",
      "title_zh": "é›†ä½“æ™ºèƒ½çš„è®¡ç®—åŸºç¡€",
      "authors": [
        "Charlie Pilgrim",
        "Joe Morford",
        "Elizabeth Warren",
        "MÃ©lisande Aellen",
        "Christopher Krupenye",
        "Richard P Mann",
        "Dora Biro"
      ],
      "abstract": "Why do collectives outperform individuals when solving some problems? Fundamentally, collectives have greater computational resources with more sensory information, more memory, more processing capacity, and more ways to act. While greater resources present opportunities, there are also challenges in coordination and cooperation inherent in collectives with distributed, modular structures. Despite these challenges, we show how collective resource advantages lead directly to well-known forms of collective intelligence including the wisdom of the crowd, collective sensing, division of labour, and cultural learning. Our framework also generates testable predictions about collective capabilities in distributed reasoning and context-dependent behavioural switching. Through case studies of animal navigation and decision-making, we demonstrate how collectives leverage their computational resources to solve problems not only more effectively than individuals, but by using qualitatively different problem-solving strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Collective Intelligenceçš„è®¡ç®—åŸºç¡€ï¼Œåˆ†æäº†é›†ä½“åœ¨è§£å†³ç‰¹å®šé—®é¢˜æ—¶ç›¸è¾ƒäºä¸ªä½“çš„ä¼˜åŠ¿æ¥æºã€‚ç ”ç©¶æŒ‡å‡ºï¼Œé›†ä½“æ‹¥æœ‰æ›´ä¸°å¯Œçš„Computational Resourcesï¼ŒåŒ…æ‹¬æ›´å¼ºçš„æ„Ÿå®˜ä¿¡æ¯è·å–ã€å­˜å‚¨ã€å¤„ç†èƒ½åŠ›åŠè¡ŒåŠ¨æ–¹æ¡ˆã€‚å°½ç®¡åˆ†å¸ƒå¼ã€æ¨¡å—åŒ–ç»“æ„åœ¨åè°ƒä¸åˆä½œæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œä½†è¯¥æ¡†æ¶å±•ç¤ºäº†èµ„æºä¼˜åŠ¿å¦‚ä½•è½¬åŒ–ä¸ºWisdom of the Crowdã€Collective Sensingã€Division of Labourä»¥åŠCultural Learningã€‚è¯¥æ¡†æ¶è¿˜ä¸ºDistributed Reasoningå’Œä¸Šä¸‹æ–‡ç›¸å…³çš„è¡Œä¸ºåˆ‡æ¢ç­‰é›†ä½“èƒ½åŠ›æä¾›äº†å¯éªŒè¯çš„é¢„æµ‹ã€‚é€šè¿‡å¯¹åŠ¨ç‰©å¯¼èˆªå’Œå†³ç­–åˆ¶å®šçš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè®ºæ–‡è¯æ˜äº†é›†ä½“ä¸ä»…èƒ½æ¯”ä¸ªä½“æ›´é«˜æ•ˆåœ°è§£å†³é—®é¢˜ï¼Œè€Œä¸”é‡‡ç”¨äº†è´¨æ€§ä¸åŒçš„é—®é¢˜è§£å†³ç­–ç•¥ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.MA",
        "cs.NE",
        "nlin.AO",
        "physics.soc-ph"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07999v1",
      "published_date": "2025-09-06 16:02:03 UTC",
      "updated_date": "2025-09-06 16:02:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:55:58.970922+00:00"
    },
    {
      "arxiv_id": "2509.05757v2",
      "title": "Hyperbolic Large Language Models",
      "title_zh": "åŒæ›²å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Sarang Patil",
        "Zeyong Zhang",
        "Yiran Huang",
        "Tengfei Ma",
        "Mengjia Xu"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable success and demonstrated superior performance across various tasks, including natural language processing (NLP), weather forecasting, biological protein folding, text generation, and solving mathematical problems. However, many real-world data exhibit highly non-Euclidean latent hierarchical anatomy, such as protein networks, transportation networks, financial networks, brain networks, and linguistic structures or syntactic trees in natural languages. Effectively learning intrinsic semantic entailment and hierarchical relationships from these raw, unstructured input data using LLMs remains an underexplored area. Due to its effectiveness in modeling tree-like hierarchical structures, hyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity as an expressive latent representation space for complex data modeling across domains such as graphs, images, languages, and multi-modal data. Here, we provide a comprehensive and contextual exposition of recent advancements in LLMs that leverage hyperbolic geometry as a representation space to enhance semantic representation learning and multi-scale reasoning. Specifically, the paper presents a taxonomy of the principal techniques of Hyperbolic LLMs (HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log maps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4) hyperbolic state-space models. We also explore crucial potential applications and outline future research directions. A repository of key papers, models, datasets, and code implementations is available at https://github.com/sarangp2402/Hyperbolic-LLM-Models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†å…·æœ‰éæ¬§å‡ é‡Œå¾— (non-Euclidean) å±‚æ¬¡åŒ–ç»“æ„æ•°æ®ï¼ˆå¦‚è›‹ç™½è´¨ç½‘ç»œã€äº¤é€šç½‘ç»œåŠè¯­è¨€å¥æ³•æ ‘ï¼‰æ—¶çš„å±€é™æ€§ï¼Œå¹¶åˆ†æäº†åŒæ›²å‡ ä½• (Hyperbolic geometry) ä½œä¸ºå¤æ‚æ•°æ®è¡¨å¾ç©ºé—´çš„ä¼˜åŠ¿ã€‚æ–‡ç« å¯¹åŒæ›²å¤§è¯­è¨€æ¨¡å‹ (Hyperbolic LLMs, HypLLMs) çš„æœ€æ–°è¿›å±•è¿›è¡Œäº†å…¨é¢ç»¼è¿°ï¼Œå¹¶å°†å…¶æ ¸å¿ƒæŠ€æœ¯å½’çº³ä¸ºåŸºäºæŒ‡æ•°/å¯¹æ•°æ˜ å°„ (exp/log maps) çš„æ¨¡å‹ã€åŒæ›²å¾®è°ƒæ¨¡å‹ (hyperbolic fine-tuned models)ã€å…¨åŒæ›² LLMs (fully hyperbolic LLMs) ä»¥åŠåŒæ›²çŠ¶æ€ç©ºé—´æ¨¡å‹ (hyperbolic state-space models) å››å¤§ç±»åˆ«ã€‚é€šè¿‡å¼•å…¥åŒæ›²å‡ ä½•ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰åŸå§‹éç»“æ„åŒ–æ•°æ®ä¸­çš„å†…åœ¨è¯­ä¹‰è•´å«å’Œå±‚æ¬¡å…³ç³»ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºè¯­ä¹‰è¡¨å¾å­¦ä¹ å’Œå¤šå°ºåº¦æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ç³»ç»Ÿé˜è¿°äº† HypLLMs çš„æ½œåœ¨åº”ç”¨åœºæ™¯ä¸æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªåŒ…å«å…³é”®è®ºæ–‡ã€æ¨¡å‹åŠä»£ç å®ç°çš„å¼€æºèµ„æºåº“ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05757v2",
      "published_date": "2025-09-06 15:56:46 UTC",
      "updated_date": "2025-12-07 17:46:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:56:00.456355+00:00"
    },
    {
      "arxiv_id": "2509.05755v5",
      "title": "Red-Teaming Coding Agents from a Tool-Invocation Perspective: An Empirical Security Assessment",
      "title_zh": "å·¥å…·è°ƒç”¨è§†è§’ä¸‹çš„ç¼–ç¨‹æ™ºèƒ½ä½“çº¢é˜Ÿæµ‹è¯•ï¼šä¸€é¡¹å®è¯å®‰å…¨è¯„ä¼°",
      "authors": [
        "Yuchong Xie",
        "Mingyu Luo",
        "Zesen Liu",
        "Zhixiang Zhang",
        "Kaikai Zhang",
        "Yu Liu",
        "Zongjie Li",
        "Ping Chen",
        "Shuai Wang",
        "Dongdong She"
      ],
      "abstract": "Coding agents powered by large language models are becoming central modules of modern IDEs, helping users perform complex tasks by invoking tools. While powerful, tool invocation opens a substantial attack surface. Prior work has demonstrated attacks against general-purpose and domain-specific agents, but none have focused on the security risks of tool invocation in coding agents. To fill this gap, we conduct the first systematic red-teaming of six popular real-world coding agents: Cursor, Claude Code, Copilot, Windsurf, Cline, and Trae. Our red-teaming proceeds in two phases. In Phase 1, we perform prompt leakage reconnaissance to recover system prompts. We discover a general vulnerability, ToolLeak, which allows malicious prompt exfiltration through benign argument retrieval during tool invocation. In Phase 2, we hijack the agent's tool-invocation behavior using a novel two-channel prompt injection in the tool description and return values, achieving remote code execution (RCE). We adaptively construct payloads using security information leaked in Phase 1. In emulation across five backends, our method outperforms baselines on Claude-Sonnet-4, Claude-Sonnet-4.5, Grok-4, and GPT-5. On real agents, our approach succeeds on 19 of 25 agent-LLM pairs, achieving leakage on every agent using Claude and Grok backends. For tool-invocation hijacking, we obtain RCE on every tested agent-LLM pair, with our two-channel method delivering the highest success rate. We provide case studies on Cursor and Claude Code, analyze security guardrails of external and built-in tools, and conclude with practical defense recommendations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Cursorã€Claude Codeã€Copilotã€Windsurfã€Clineå’ŒTraeç­‰å…­æ¬¾ä¸»æµç¼–ç¨‹æ™ºèƒ½ä½“(Coding Agents)è¿›è¡Œäº†é¦–æ¬¡ç³»ç»Ÿæ€§çš„çº¢é˜Ÿæµ‹è¯•(Red-Teaming)ï¼Œä»å·¥å…·è°ƒç”¨(Tool-Invocation)è§†è§’è¯„ä¼°å…¶å®‰å…¨é£é™©ã€‚ç ”ç©¶å‘ç°äº†ä¸€ç§åä¸ºToolLeakçš„æ¼æ´ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡å·¥å…·è°ƒç”¨è¿‡ç¨‹ä¸­çš„å‚æ•°æ£€ç´¢å®ç°ç³»ç»Ÿæç¤ºè¯æ³„éœ²(Prompt Leakage)ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åˆ›æ–°çš„åŒé€šé“æç¤ºè¯æ³¨å…¥(Two-channel Prompt Injection)æŠ€æœ¯ï¼Œé€šè¿‡åœ¨å·¥å…·æè¿°å’Œè¿”å›å€¼ä¸­æ¤å…¥è½½è·æ¥åŠ«æŒæ™ºèƒ½ä½“è¡Œä¸ºï¼Œè¿›è€Œå®ç°è¿œç¨‹ä»£ç æ‰§è¡Œ(RCE)ã€‚å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨19ä¸ªAgent-LLMç»„åˆä¸­æˆåŠŸå®ç°äº†æ³„éœ²ï¼Œå¹¶åˆ©ç”¨åŒé€šé“æŠ€æœ¯åœ¨æ‰€æœ‰å—æµ‹ç»„åˆä¸Šå‡è¾¾æˆäº†RCEã€‚è®ºæ–‡é€šè¿‡å¯¹Cursorå’ŒClaude Codeçš„æ¡ˆä¾‹ç ”ç©¶ï¼Œæ·±å…¥åˆ†æäº†å†…å¤–éƒ¨å·¥å…·çš„å®‰å…¨é˜²æŠ¤ç°çŠ¶ã€‚æœ€åï¼Œç ”ç©¶æ ¹æ®å‘ç°çš„æ¼æ´æå‡ºäº†é’ˆå¯¹æ€§çš„é˜²å¾¡å»ºè®®ï¼Œä¸ºæå‡ç¼–ç¨‹æ™ºèƒ½ä½“çš„å®‰å…¨æ€§æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05755v5",
      "published_date": "2025-09-06 15:48:49 UTC",
      "updated_date": "2026-01-04 13:12:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:56:01.173068+00:00"
    },
    {
      "arxiv_id": "2509.05753v1",
      "title": "Tell-Tale Watermarks for Explanatory Reasoning in Synthetic Media Forensics",
      "title_zh": "é¢å‘åˆæˆåª’ä½“å–è¯è§£é‡Šæ€§æ¨ç†çš„æ­ç¤ºæ€§æ°´å°",
      "authors": [
        "Ching-Chun Chang",
        "Isao Echizen"
      ],
      "abstract": "The rise of synthetic media has blurred the boundary between reality and fabrication under the evolving power of artificial intelligence, fueling an infodemic that erodes public trust in cyberspace. For digital imagery, a multitude of editing applications further complicates the forensic analysis, including semantic edits that alter content, photometric adjustments that recalibrate colour characteristics, and geometric projections that reshape viewpoints. Collectively, these transformations manipulate and control perceptual interpretation of digital imagery. This susceptibility calls for forensic enquiry into reconstructing the chain of events, thereby revealing deeper evidential insight into the presence or absence of criminal intent. This study seeks to address an inverse problem of tracing the underlying generation chain that gives rise to the observed synthetic media. A tell-tale watermarking system is developed for explanatory reasoning over the nature and extent of transformations across the lifecycle of synthetic media. Tell-tale watermarks are tailored to different classes of transformations, responding in a manner that is neither strictly robust nor fragile but instead interpretable. These watermarks function as reference clues that evolve under the same transformation dynamics as the carrier media, leaving interpretable traces when subjected to transformations. Explanatory reasoning is then performed to infer the most plausible account across the combinatorial parameter space of composite transformations. Experimental evaluations demonstrate the validity of tell-tale watermarking with respect to fidelity, synchronicity and traceability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½ç”Ÿæˆçš„åˆæˆåª’ä½“(Synthetic Media)å¸¦æ¥çš„ä¿¡ä»»å±æœºï¼Œæå‡ºäº†ä¸€ç§ç”¨äºè§£é‡Šæ€§æ¨ç†(Explanatory Reasoning)çš„å‘Šå¯†æ°´å°(Tell-Tale Watermarks)ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡è¿½è¸ªåº•å±‚ç”Ÿæˆé“¾æ¥é‡å»ºåª’ä½“çš„ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ã€‚ä¸ºäº†åº”å¯¹è¯­ä¹‰ç¼–è¾‘ã€å…‰åº¦è°ƒæ•´å’Œå‡ ä½•å˜æ¢ç­‰å¤šé‡ç¯¡æ”¹ï¼Œè¯¥ç³»ç»Ÿè®¾è®¡äº†èƒ½å¤Ÿéšè½½ä½“åŒæ­¥æ¼”å˜ä¸”å…·å¤‡å¯è§£é‡Šæ€§çš„æ°´å°ç—•è¿¹ï¼Œè€Œéä¼ ç»Ÿçš„ç¨³å¥æˆ–è„†å¼±æ°´å°ã€‚é€šè¿‡åœ¨å¤åˆå˜æ¢çš„ç»„åˆå‚æ•°ç©ºé—´ä¸­è¿›è¡Œæ¨æ–­ï¼Œè¯¥ç³»ç»Ÿå¯ä»¥è¯†åˆ«å‡ºæœ€åˆç†çš„å¤„ç†è·¯å¾„ï¼Œä»è€Œä¸ºåˆ¤æ–­æ˜¯å¦å­˜åœ¨æ„å›¾æä¾›æ·±åº¦è¯æ®ã€‚å®éªŒè¯„ä¼°åœ¨ä¿çœŸåº¦(Fidelity)ã€åŒæ­¥æ€§(Synchronicity)å’Œå¯è¿½æº¯æ€§(Traceability)ä¸‰ä¸ªç»´åº¦ä¸Šè¯æ˜äº†è¯¥æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºåˆæˆåª’ä½“å–è¯æä¾›äº†æ–°çš„æŠ€æœ¯æ‰‹æ®µï¼Œæ˜¾è‘—æå‡äº†æ•°å­—å›¾åƒåˆ†æçš„å¯è§£é‡Šæ€§ä¸å¯ä¿¡åº¦ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05753v1",
      "published_date": "2025-09-06 15:47:27 UTC",
      "updated_date": "2025-09-06 15:47:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:56:24.285200+00:00"
    },
    {
      "arxiv_id": "2509.05751v1",
      "title": "Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation",
      "title_zh": "é‡Šæ”¾å±‚çº§æ¨ç†ï¼šä¸€ç§å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…è®­ç»ƒæŒ‡ä»£æ€§è§†é¢‘ç‰©ä½“åˆ†å‰²æ¡†æ¶",
      "authors": [
        "Bingrui Zhao",
        "Lin Yuanbo Wu",
        "Xiangtian Fan",
        "Deyin Liu",
        "Lu Zhang",
        "Ruyi He",
        "Jialie Shen",
        "Ximing Li"
      ],
      "abstract": "Referring Video Object Segmentation (RVOS) aims to segment an object of interest throughout a video based on a language description. The prominent challenge lies in aligning static text with dynamic visual content, particularly when objects exhibiting similar appearances with inconsistent motion and poses. However, current methods often rely on a holistic visual-language fusion that struggles with complex, compositional descriptions. In this paper, we propose \\textbf{PARSE-VOS}, a novel, training-free framework powered by Large Language Models (LLMs), for a hierarchical, coarse-to-fine reasoning across text and video domains. Our approach begins by parsing the natural language query into structured semantic commands. Next, we introduce a spatio-temporal grounding module that generates all candidate trajectories for all potential target objects, guided by the parsed semantics. Finally, a hierarchical identification module select the correct target through a two-stage reasoning process: it first performs coarse-grained motion reasoning with an LLM to narrow down candidates; if ambiguity remains, a fine-grained pose verification stage is conditionally triggered to disambiguate. The final output is an accurate segmentation mask for the target object. \\textbf{PARSE-VOS} achieved state-of-the-art performance on three major benchmarks: Ref-YouTube-VOS, Ref-DAVIS17, and MeViS.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PARSE-VOSï¼Œè¿™æ˜¯ä¸€ç§ç”±å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) é©±åŠ¨çš„æ— éœ€è®­ç»ƒ (training-free) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æŒ‡ä»£è§†é¢‘å¯¹è±¡åˆ†å‰² (Referring Video Object Segmentation, RVOS) ä»»åŠ¡ä¸­é™æ€æ–‡æœ¬ä¸åŠ¨æ€è§†è§‰å†…å®¹å¯¹é½çš„æŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ã€ç»„åˆæ€§æè¿°æ—¶çš„å±€é™æ€§ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§ä»ç²—åˆ°ç²¾çš„è·¨åŸŸå±‚æ¬¡åŒ–æ¨ç†æœºåˆ¶ã€‚ç³»ç»Ÿé¦–å…ˆå°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£æä¸ºç»“æ„åŒ–çš„è¯­ä¹‰å‘½ä»¤ï¼Œå¹¶åˆ©ç”¨æ—¶ç©ºæ¥åœ° (spatio-temporal grounding) æ¨¡å—ä¸ºæ‰€æœ‰æ½œåœ¨ç›®æ ‡ç”Ÿæˆå€™é€‰è½¨è¿¹ã€‚æ ¸å¿ƒçš„å±‚æ¬¡åŒ–è¯†åˆ«æ¨¡å—é€šè¿‡ä¸¤é˜¶æ®µè¿‡ç¨‹é”å®šç›®æ ‡ï¼šé¦–å…ˆåˆ©ç”¨ LLM è¿›è¡Œç²—ç²’åº¦çš„è¿åŠ¨æ¨ç† (motion reasoning) ä»¥ç¼©å°å€™é€‰èŒƒå›´ï¼Œè‹¥ä»å­˜åœ¨æ­§ä¹‰ï¼Œåˆ™è§¦å‘ç»†ç²’åº¦çš„å§¿æ€éªŒè¯ (pose verification) è¿›è¡Œæ¶ˆæ­§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPARSE-VOS åœ¨ Ref-YouTube-VOSã€Ref-DAVIS17 å’Œ MeViS ä¸‰å¤§åŸºå‡†æµ‹è¯•ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ (state-of-the-art)ã€‚è¯¥ç ”ç©¶è¯æ˜äº†é€šè¿‡å±‚æ¬¡åŒ–æ¨ç†ç»“åˆå¤§æ¨¡å‹èƒ½åŠ›ï¼Œå¯ä»¥åœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹æœ‰æ•ˆæå‡è§†é¢‘å¯¹è±¡åˆ†å‰²çš„ç²¾ç¡®åº¦ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05751v1",
      "published_date": "2025-09-06 15:46:23 UTC",
      "updated_date": "2025-09-06 15:46:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:56:14.591647+00:00"
    },
    {
      "arxiv_id": "2509.05747v1",
      "title": "InterAct: A Large-Scale Dataset of Dynamic, Expressive and Interactive Activities between Two People in Daily Scenarios",
      "title_zh": "InterActï¼šæ—¥å¸¸åœºæ™¯ä¸‹åŒäººåŠ¨æ€ã€è¡¨ç°åŠ›åŠäº¤äº’æ´»åŠ¨çš„å¤§è§„æ¨¡æ•°æ®é›†",
      "authors": [
        "Leo Ho",
        "Yinghao Huang",
        "Dafei Qin",
        "Mingyi Shi",
        "Wangpok Tse",
        "Wei Liu",
        "Junichi Yamagishi",
        "Taku Komura"
      ],
      "abstract": "We address the problem of accurate capture of interactive behaviors between two people in daily scenarios. Most previous works either only consider one person or solely focus on conversational gestures of two people, assuming the body orientation and/or position of each actor are constant or barely change over each interaction. In contrast, we propose to simultaneously model two people's activities, and target objective-driven, dynamic, and semantically consistent interactions which often span longer duration and cover bigger space. To this end, we capture a new multi-modal dataset dubbed InterAct, which is composed of 241 motion sequences where two people perform a realistic and coherent scenario for one minute or longer over a complete interaction. For each sequence, two actors are assigned different roles and emotion labels, and collaborate to finish one task or conduct a common interaction activity. The audios, body motions, and facial expressions of both persons are captured. InterAct contains diverse and complex motions of individuals and interesting and relatively long-term interaction patterns barely seen before. We also demonstrate a simple yet effective diffusion-based method that estimates interactive face expressions and body motions of two people from speech inputs. Our method regresses the body motions in a hierarchical manner, and we also propose a novel fine-tuning mechanism to improve the lip accuracy of facial expressions. To facilitate further research, the data and code is made available at https://hku-cg.github.io/interact/ .",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¥å¸¸åœºæ™¯ä¸­åŒäººäº’åŠ¨è¡Œä¸ºç²¾ç¡®æ•æ‰çš„éš¾é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰ç ”ç©¶å¤šä¾§é‡äºå•äººæˆ–ä½ç½®å›ºå®šçš„ç®€å•å¯¹è¯æ‰‹åŠ¿ï¼Œéš¾ä»¥è¦†ç›–åŠ¨æ€ä¸”è¯­ä¹‰è¿è´¯çš„å¤æ‚äº¤äº’ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†åä¸º InterAct çš„å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…å« 241 ä¸ªæ—¶é•¿è¶…è¿‡ä¸€åˆ†é’Ÿçš„è¿åŠ¨åºåˆ—ï¼Œè®°å½•äº†ä¸¤äººçš„éŸ³é¢‘ã€è‚¢ä½“åŠ¨ä½œå’Œé¢éƒ¨è¡¨æƒ…ï¼Œå¹¶æ¶µç›–äº†ç‰¹å®šçš„è§’è‰²åˆ†é…ä¸æƒ…æ„Ÿæ ‡ç­¾ã€‚è¯¥æ•°æ®é›†æ•æ‰åˆ°äº†ä»¥å¾€ç ”ç©¶ä¸­ç½•è§çš„å¤æ‚ã€é•¿æœŸçš„äº’åŠ¨æ¨¡å¼ï¼Œä¸ºç ”ç©¶ç›®æ ‡é©±åŠ¨çš„åŠ¨æ€äº¤äº’æä¾›äº†åŸºç¡€ã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥å±•ç¤ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹ (diffusion-based) çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿä»è¯­éŸ³è¾“å…¥ä¸­é¢„æµ‹ä¸¤äººçš„äº¤äº’å¼é¢éƒ¨è¡¨æƒ…å’Œè‚¢ä½“åŠ¨ä½œã€‚è¯¥æ–¹æ³•é€šè¿‡å±‚æ¬¡åŒ–æ–¹å¼å›å½’è‚¢ä½“åŠ¨ä½œï¼Œå¹¶åˆ©ç”¨ä¸€ç§åˆ›æ–°çš„å¾®è°ƒ (fine-tuning) æœºåˆ¶æ˜¾è‘—æå‡äº†é¢éƒ¨è¡¨æƒ…ä¸­çš„å˜´å”‡ç²¾åº¦ã€‚ç›®å‰ InterAct æ•°æ®é›†åŠå…¶ä»£ç å·²å…¬å¼€ï¼Œæ—¨åœ¨ä¿ƒè¿›äººç±»äº¤äº’è¡Œä¸ºç†è§£ä¸ç”Ÿæˆé¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "The first two authors contributed equally to this work",
      "pdf_url": "https://arxiv.org/pdf/2509.05747v1",
      "published_date": "2025-09-06 15:36:47 UTC",
      "updated_date": "2025-09-06 15:36:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:56:16.495106+00:00"
    },
    {
      "arxiv_id": "2509.05739v1",
      "title": "Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated",
      "title_zh": "æ¨ç†æœºåˆ¶å¼•å…¥äº†æ–°å‹ä¸­æ¯’æ”»å‡»ï¼Œå´ä¹Ÿä½¿å…¶å˜å¾—æ›´åŠ å¤æ‚",
      "authors": [
        "Hanna Foerster",
        "Ilia Shumailov",
        "Yiren Zhao",
        "Harsh Chaudhari",
        "Jamie Hayes",
        "Robert Mullins",
        "Yarin Gal"
      ],
      "abstract": "Early research into data poisoning attacks against Large Language Models (LLMs) demonstrated the ease with which backdoors could be injected. More recent LLMs add step-by-step reasoning, expanding the attack surface to include the intermediate chain-of-thought (CoT) and its inherent trait of decomposing problems into subproblems. Using these vectors for more stealthy poisoning, we introduce ``decomposed reasoning poison'', in which the attacker modifies only the reasoning path, leaving prompts and final answers clean, and splits the trigger across multiple, individually harmless components.\n  Fascinatingly, while it remains possible to inject these decomposed poisons, reliably activating them to change final answers (rather than just the CoT) is surprisingly difficult. This difficulty arises because the models can often recover from backdoors that are activated within their thought processes. Ultimately, it appears that an emergent form of backdoor robustness is originating from the reasoning capabilities of these advanced LLMs, as well as from the architectural separation between reasoning and final answer generation.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†é’ˆå¯¹å…·å¤‡æ¨ç†èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ•°æ®æŠ•æ¯’æ”»å‡»(Data Poisoning Attacks)ï¼ŒæŒ‡å‡ºé“¾å¼æ€ç»´(Chain-of-Thought, CoT)çš„å¼•å…¥åœ¨æ‰©å¤§æ”»å‡»é¢ã€åˆ©ç”¨å­é—®é¢˜åˆ†è§£ç‰¹æ€§çš„åŒæ—¶ä¹Ÿå¸¦æ¥äº†æ–°çš„å¤æ‚æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åä¸ºâ€œåˆ†è§£æ¨ç†æŠ•æ¯’â€(Decomposed Reasoning Poison)çš„éšè”½æ”»å‡»æ‰‹æ®µï¼Œè¯¥æ–¹æ³•ä»…ä¿®æ”¹æ¨ç†è·¯å¾„è€Œä¿æŒæç¤ºè¯å’Œæœ€ç»ˆç­”æ¡ˆå¹²å‡€ï¼Œå¹¶å°†è§¦å‘å™¨æ‹†åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹çš„æ— å®³ç»„ä»¶ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡æ³¨å…¥æ­¤ç±»åˆ†è§£æ¯’ç´ å…·æœ‰å¯è¡Œæ€§ï¼Œä½†å¯é åœ°æ¿€æ´»å®ƒä»¬ä»¥æ”¹å˜æœ€ç»ˆç­”æ¡ˆå´é¢ä¸´æ˜¾è‘—å›°éš¾ï¼Œå› ä¸ºæ¨¡å‹å¾€å¾€èƒ½ä»æ€ç»´è¿‡ç¨‹ä¸­è§¦å‘çš„åé—¨(Backdoors)ä¸­è‡ªåŠ¨æ¢å¤ã€‚è¿™ä¸€ç°è±¡è¡¨æ˜ï¼Œå…ˆè¿›LLMsçš„æ¨ç†èƒ½åŠ›ä»¥åŠæ¨ç†ä¸æœ€ç»ˆç­”æ¡ˆç”Ÿæˆä¹‹é—´çš„æ¶æ„åˆ†ç¦»ï¼Œæ­£ä¿ƒä½¿æ¨¡å‹äº§ç”Ÿä¸€ç§æ–°å…´çš„åé—¨é²æ£’æ€§(Backdoor Robustness)ï¼Œä¸ºç†è§£å¤æ‚æ¨ç†æ¨¡å‹çš„å®‰å…¨æ€§æä¾›äº†æ–°è§†è§’ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05739v1",
      "published_date": "2025-09-06 15:06:18 UTC",
      "updated_date": "2025-09-06 15:06:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:56:22.392059+00:00"
    },
    {
      "arxiv_id": "2509.05735v1",
      "title": "Offline vs. Online Learning in Model-based RL: Lessons for Data Collection Strategies",
      "title_zh": "åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ä¸­ç¦»çº¿ä¸åœ¨çº¿å­¦ä¹ çš„å¯¹æ¯”ï¼šå¯¹æ•°æ®æ”¶é›†ç­–ç•¥çš„å¯ç¤º",
      "authors": [
        "Jiaqi Chen",
        "Ji Shi",
        "Cansu Sancaktar",
        "Jonas Frey",
        "Georg Martius"
      ],
      "abstract": "Data collection is crucial for learning robust world models in model-based reinforcement learning. The most prevalent strategies are to actively collect trajectories by interacting with the environment during online training or training on offline datasets. At first glance, the nature of learning task-agnostic environment dynamics makes world models a good candidate for effective offline training. However, the effects of online vs. offline data on world models and thus on the resulting task performance have not been thoroughly studied in the literature. In this work, we investigate both paradigms in model-based settings, conducting experiments on 31 different environments. First, we showcase that online agents outperform their offline counterparts. We identify a key challenge behind performance degradation of offline agents: encountering Out-Of-Distribution states at test time. This issue arises because, without the self-correction mechanism in online agents, offline datasets with limited state space coverage induce a mismatch between the agent's imagination and real rollouts, compromising policy training. We demonstrate that this issue can be mitigated by allowing for additional online interactions in a fixed or adaptive schedule, restoring the performance of online training with limited interaction data. We also showcase that incorporating exploration data helps mitigate the performance degradation of offline agents. Based on our insights, we recommend adding exploration data when collecting large datasets, as current efforts predominantly focus on expert data alone.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹  (Model-based RL) ä¸­åœ¨çº¿ (Online) ä¸ç¦»çº¿ (Offline) æ•°æ®æ”¶é›†ç­–ç•¥å¯¹ä¸–ç•Œæ¨¡å‹ (World Models) å­¦ä¹ åŠä»»åŠ¡æ€§èƒ½çš„å½±å“ã€‚é€šè¿‡åœ¨31ä¸ªä¸åŒç¯å¢ƒä¸­çš„å®éªŒï¼Œç ”ç©¶å‘ç°åœ¨çº¿æ™ºèƒ½ä½“åœ¨æ€§èƒ½ä¸Šæ™®éä¼˜äºç¦»çº¿æ™ºèƒ½ä½“ã€‚ç¦»çº¿æ™ºèƒ½ä½“é¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºæµ‹è¯•æ—¶é‡åˆ°çš„åˆ†å¸ƒå¤– (Out-Of-Distribution) çŠ¶æ€ï¼Œç”±äºç¦»çº¿æ•°æ®é›†è¦†ç›–èŒƒå›´æœ‰é™ä¸”ç¼ºä¹åœ¨çº¿è‡ªçº æ­£æœºåˆ¶ï¼Œå¯¼è‡´æ™ºèƒ½ä½“çš„æƒ³è±¡ä¸çœŸå®åºåˆ—äº§ç”Ÿåå·®ï¼Œè¿›è€Œå½±å“ç­–ç•¥è®­ç»ƒã€‚ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡å¼•å…¥å›ºå®šæˆ–è‡ªé€‚åº”çš„é¢å¤–åœ¨çº¿äº¤äº’ï¼Œå¯ä»¥æœ‰æ•ˆæ¢å¤åœ¨çº¿è®­ç»ƒçš„æ€§èƒ½ã€‚åŒæ—¶ï¼Œåœ¨ç¦»çº¿æ•°æ®ä¸­åŠ å…¥æ¢ç´¢æ•°æ® (Exploration data) ä¹Ÿèƒ½æ˜¾è‘—å‡è½»æ€§èƒ½è¡°å‡ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶å»ºè®®åœ¨æ„å»ºå¤§å‹æ•°æ®é›†æ—¶åº”é‡è§†æ¢ç´¢æ•°æ®çš„é‡‡é›†ï¼Œè€Œéä»…å±€é™äºä¸“å®¶æ•°æ® (Expert data)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Reinforcement Learning Conference (RLC 2025); Code available at: https://github.com/swsychen/Offline_vs_Online_in_MBRL",
      "pdf_url": "https://arxiv.org/pdf/2509.05735v1",
      "published_date": "2025-09-06 14:52:33 UTC",
      "updated_date": "2025-09-06 14:52:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:56:28.072087+00:00"
    },
    {
      "arxiv_id": "2509.05732v1",
      "title": "Simulation Priors for Data-Efficient Deep Learning",
      "title_zh": "é¢å‘æ•°æ®é«˜æ•ˆæ·±åº¦å­¦ä¹ çš„ä»¿çœŸå…ˆéªŒ",
      "authors": [
        "Lenart Treven",
        "Bhavya Sukhija",
        "Jonas Rothfuss",
        "Stelian Coros",
        "Florian DÃ¶rfler",
        "Andreas Krause"
      ],
      "abstract": "How do we enable AI systems to efficiently learn in the real-world? First-principles models are widely used to simulate natural systems, but often fail to capture real-world complexity due to simplifying assumptions. In contrast, deep learning approaches can estimate complex dynamics with minimal assumptions but require large, representative datasets. We propose SimPEL, a method that efficiently combines first-principles models with data-driven learning by using low-fidelity simulators as priors in Bayesian deep learning. This enables SimPEL to benefit from simulator knowledge in low-data regimes and leverage deep learning's flexibility when more data is available, all the while carefully quantifying epistemic uncertainty. We evaluate SimPEL on diverse systems, including biological, agricultural, and robotic domains, showing superior performance in learning complex dynamics. For decision-making, we demonstrate that SimPEL bridges the sim-to-real gap in model-based reinforcement learning. On a high-speed RC car task, SimPEL learns a highly dynamic parking maneuver involving drifting with substantially less data than state-of-the-art baselines. These results highlight the potential of SimPEL for data-efficient learning and control in complex real-world environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SimPELæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³AIç³»ç»Ÿåœ¨ç°å®ä¸–ç•Œä¸­å­¦ä¹ æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†ä½ä¿çœŸåº¦çš„ç¬¬ä¸€æ€§åŸç†æ¨¡å‹(first-principles models)ä½œä¸ºå…ˆéªŒçŸ¥è¯†å¼•å…¥è´å¶æ–¯æ·±åº¦å­¦ä¹ (Bayesian deep learning)ï¼Œæœ‰æ•ˆç»“åˆäº†ç‰©ç†æ¨¡æ‹Ÿå™¨çš„é¢†åŸŸçŸ¥è¯†ä¸æ•°æ®é©±åŠ¨å­¦ä¹ çš„çµæ´»æ€§ã€‚SimPELèƒ½å¤Ÿåœ¨æ•°æ®åŒ®ä¹é˜¶æ®µå—ç›Šäºæ¨¡æ‹Ÿå™¨çŸ¥è¯†ï¼Œå¹¶åœ¨æ•°æ®å……è¶³æ—¶åˆ©ç”¨æ·±åº¦å­¦ä¹ æ•æ‰å¤æ‚åŠ¨æ€ï¼ŒåŒæ—¶é€šè¿‡è´å¶æ–¯æ¡†æ¶ç²¾ç¡®é‡åŒ–è®¤çŸ¥ä¸ç¡®å®šæ€§(epistemic uncertainty)ã€‚åœ¨ç”Ÿç‰©ã€å†œä¸šå’Œæœºå™¨äººç­‰é¢†åŸŸçš„å®éªŒè¡¨æ˜ï¼ŒSimPELåœ¨å­¦ä¹ å¤æ‚åŠ¨åŠ›å­¦æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶æˆåŠŸç¼©å°äº†æ¨¡å‹å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¨¡æ‹Ÿåˆ°ç°å®(sim-to-real)å·®è·ã€‚ç‰¹åˆ«æ˜¯åœ¨é«˜é€ŸRCèµ›è½¦çš„é«˜åŠ¨æ€æ¼‚ç§»åœè½¦ä»»åŠ¡ä¸­ï¼ŒSimPELä½¿ç”¨çš„æ•°æ®é‡æ˜¾è‘—å°‘äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚è¿™å……åˆ†è¯æ˜äº†SimPELåœ¨å¤æ‚ç°å®ç¯å¢ƒä¸­è¿›è¡Œæ•°æ®é«˜æ•ˆå­¦ä¹ ä¸æ§åˆ¶çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05732v1",
      "published_date": "2025-09-06 14:36:41 UTC",
      "updated_date": "2025-09-06 14:36:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:05.791660+00:00"
    },
    {
      "arxiv_id": "2509.05728v3",
      "title": "LiDAR-BIND-T: Improved and Temporally Consistent Sensor Modality Translation and Fusion for Robotic Applications",
      "title_zh": "LiDAR-BIND-Tï¼šé¢å‘æœºå™¨äººåº”ç”¨çš„æ”¹è¿›å‹æ—¶åºä¸€è‡´æ€§ä¼ æ„Ÿå™¨æ¨¡æ€è½¬æ¢ä¸èåˆ",
      "authors": [
        "Niels Balemans",
        "Ali Anwar",
        "Jan Steckel",
        "Siegfried Mercelis"
      ],
      "abstract": "This paper extends LiDAR-BIND, a modular multi-modal fusion framework that binds heterogeneous sensors (radar, sonar) to a LiDAR-defined latent space, with mechanisms that explicitly enforce temporal consistency. We introduce three contributions: (i) temporal embedding similarity that aligns consecutive latent representations, (ii) a motion-aligned transformation loss that matches displacement between predictions and ground truth LiDAR, and (iii) windowed temporal fusion using a specialised temporal module. We further update the model architecture to better preserve spatial structure. Evaluations on radar/sonar-to-LiDAR translation demonstrate improved temporal and spatial coherence, yielding lower absolute trajectory error and better occupancy map accuracy in Cartographer-based SLAM (Simultaneous Localisation and Mapping). We propose different metrics based on the FrÃ©chet Video Motion Distance (FVMD) and a correlation-peak distance metric providing practical temporal quality indicators to evaluate SLAM performance. The proposed temporal LiDAR-BIND, or LiDAR-BIND-T, maintains modular modality fusion while substantially enhancing temporal stability, resulting in improved robustness and performance for downstream SLAM.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LiDAR-BIND-Tï¼Œè¿™æ˜¯å¯¹æ¨¡å—åŒ–å¤šæ¨¡æ€èåˆæ¡†æ¶ LiDAR-BIND çš„æ‰©å±•ï¼Œæ—¨åœ¨å¢å¼ºæœºå™¨äººåº”ç”¨ä¸­ä¼ æ„Ÿå™¨æ¨¡æ€è½¬æ¢ä¸èåˆçš„æ—¶åºä¸€è‡´æ€§ã€‚LiDAR-BIND-T å¼•å…¥äº†æ—¶åºåµŒå…¥ç›¸ä¼¼æ€§ä»¥å¯¹é½è¿ç»­çš„æ½œç©ºé—´è¡¨ç¤ºï¼Œå¹¶é‡‡ç”¨è¿åŠ¨å¯¹é½è½¬æ¢æŸå¤±ï¼ˆmotion-aligned transformation lossï¼‰æ¥åŒ¹é…é¢„æµ‹ä¸çœŸå€¼ LiDAR ä¹‹é—´çš„ä½ç§»ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä¸“é—¨çš„æ—¶åºæ¨¡å—å®ç°äº†çª—å£åŒ–æ—¶åºèåˆï¼Œå¹¶ä¼˜åŒ–äº†æ¶æ„ä»¥æ›´å¥½åœ°ä¿ç•™ç©ºé—´ç»“æ„ã€‚åœ¨ radar/sonar-to-LiDAR è½¬æ¢å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ—¶ç©ºè¿è´¯æ€§ï¼Œé™ä½äº† Cartographer-based SLAM çš„ç»å¯¹è½¨è¿¹è¯¯å·®å¹¶æé«˜äº†åœ°å›¾ç²¾åº¦ã€‚ç ”ç©¶è¿˜æå‡ºäº†åŸºäº FrÃ©chet Video Motion Distance (FVMD) çš„æ–°æŒ‡æ ‡ï¼Œä¸ºè¯„ä¼° SLAM æ€§èƒ½æä¾›äº†æœ‰æ•ˆçš„æ—¶åºè´¨é‡å‚è€ƒã€‚LiDAR-BIND-T åœ¨ä¿æŒæ¨¡å—åŒ–ç‰¹æ€§çš„åŒæ—¶å¢å¼ºäº†æ—¶åºç¨³å®šæ€§ï¼Œæ˜¾è‘—æå‡äº†ä¸‹æ¸¸ SLAM ä»»åŠ¡çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05728v3",
      "published_date": "2025-09-06 14:21:27 UTC",
      "updated_date": "2025-09-30 13:10:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:13.091082+00:00"
    },
    {
      "arxiv_id": "2509.05420v1",
      "title": "Universality of physical neural networks with multivariate nonlinearity",
      "title_zh": "å…·æœ‰å¤šå˜é‡éçº¿æ€§çš„ç‰©ç†ç¥ç»ç½‘ç»œçš„é€šç”¨æ€§",
      "authors": [
        "Benjamin Savinson",
        "David J. Norris",
        "Siddhartha Mishra",
        "Samuel Lanthaler"
      ],
      "abstract": "The enormous energy demand of artificial intelligence is driving the development of alternative hardware for deep learning. Physical neural networks try to exploit physical systems to perform machine learning more efficiently. In particular, optical systems can calculate with light using negligible energy. While their computational capabilities were long limited by the linearity of optical materials, nonlinear computations have recently been demonstrated through modified input encoding. Despite this breakthrough, our inability to determine if physical neural networks can learn arbitrary relationships between data -- a key requirement for deep learning known as universality -- hinders further progress. Here we present a fundamental theorem that establishes a universality condition for physical neural networks. It provides a powerful mathematical criterion that imposes device constraints, detailing how inputs should be encoded in the tunable parameters of the physical system. Based on this result, we propose a scalable architecture using free-space optics that is provably universal and achieves high accuracy on image classification tasks. Further, by combining the theorem with temporal multiplexing, we present a route to potentially huge effective system sizes in highly practical but poorly scalable on-chip photonic devices. Our theorem and scaling methods apply beyond optical systems and inform the design of a wide class of universal, energy-efficient physical neural networks, justifying further efforts in their development.",
      "tldr_zh": "é’ˆå¯¹äººå·¥æ™ºèƒ½å·¨å¤§çš„èƒ½æºéœ€æ±‚ï¼Œç‰©ç†ç¥ç»ç½‘ç»œ(Physical Neural Networks)ä½œä¸ºä¸€ç§é«˜æ•ˆçš„ç¡¬ä»¶æ›¿ä»£æ–¹æ¡ˆï¼Œæ­¤å‰ä¸€ç›´å—é™äºéš¾ä»¥è¯æ˜å…¶æ˜¯å¦å…·å¤‡å­¦ä¹ ä»»æ„æ•°æ®å…³ç³»çš„æ™®éæ€§(Universality)ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€é¡¹åŸºç¡€æ€§å®šç†ï¼Œç¡®ç«‹äº†ç‰©ç†ç¥ç»ç½‘ç»œå®ç°æ™®éæ€§çš„æ•°å­¦å‡†åˆ™ï¼Œå¹¶è¯¦ç»†é˜è¿°äº†å¦‚ä½•å°†è¾“å…¥ç¼–ç åˆ°ç‰©ç†ç³»ç»Ÿçš„å¯è°ƒå‚æ•°ä¸­ã€‚åŸºäºè¯¥å®šç†ï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸€ç§åˆ©ç”¨è‡ªç”±ç©ºé—´å…‰å­¦(Free-space optics)çš„å¯æ‰©å±•æ¶æ„ï¼Œç»è¯æ˜å…·æœ‰æ™®éæ€§ä¸”åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚æ­¤å¤–ï¼Œé€šè¿‡ç»“åˆæ—¶é—´å¤ç”¨(Temporal multiplexing)æŠ€æœ¯ï¼Œè¯¥ç ”ç©¶è¿˜ä¸ºæå‡èŠ¯ç‰‡ä¸Šå…‰å­å™¨ä»¶(On-chip photonic devices)çš„ç³»ç»Ÿè§„æ¨¡æä¾›äº†å¯è¡Œè·¯å¾„ã€‚è¿™é¡¹æˆæœä¸ä»…ä¸ºå…‰å­¦ç³»ç»Ÿè®¾è®¡æä¾›äº†ç†è®ºæ”¯æ’‘ï¼Œä¹Ÿä¸ºå¼€å‘æ›´å¹¿æ³›çš„é€šç”¨ã€èŠ‚èƒ½å‹ç‰©ç†ç¥ç»ç½‘ç»œå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "physics.optics",
        "cs.AI",
        "physics.class-ph",
        "physics.comp-ph"
      ],
      "primary_category": "physics.optics",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05420v1",
      "published_date": "2025-09-06 14:08:32 UTC",
      "updated_date": "2025-09-06 14:08:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:55.188501+00:00"
    },
    {
      "arxiv_id": "2509.05716v1",
      "title": "A Survey of the State-of-the-Art in Conversational Question Answering Systems",
      "title_zh": "å¯¹è¯å¼é—®ç­”ç³»ç»Ÿå‘å±•ç°çŠ¶ç»¼è¿°",
      "authors": [
        "Manoj Madushanka Perera",
        "Adnan Mahmood",
        "Kasun Eranda Wijethilake",
        "Fahmida Islam",
        "Maryam Tahermazandarani",
        "Quan Z. Sheng"
      ],
      "abstract": "Conversational Question Answering (ConvQA) systems have emerged as a pivotal area within Natural Language Processing (NLP) by driving advancements that enable machines to engage in dynamic and context-aware conversations. These capabilities are increasingly being applied across various domains, i.e., customer support, education, legal, and healthcare where maintaining a coherent and relevant conversation is essential. Building on recent advancements, this survey provides a comprehensive analysis of the state-of-the-art in ConvQA. This survey begins by examining the core components of ConvQA systems, i.e., history selection, question understanding, and answer prediction, highlighting their interplay in ensuring coherence and relevance in multi-turn conversations. It further investigates the use of advanced machine learning techniques, including but not limited to, reinforcement learning, contrastive learning, and transfer learning to improve ConvQA accuracy and efficiency. The pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash, Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact through data scalability and architectural advancements. Additionally, this survey presents a comprehensive analysis of key ConvQA datasets and concludes by outlining open research directions. Overall, this work offers a comprehensive overview of the ConvQA landscape and provides valuable insights to guide future advancements in the field.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåœ°æ¢³ç†äº†å¯¹è¯å¼é—®ç­”ç³»ç»Ÿ(Conversational Question Answering, ConvQA)çš„ç ”ç©¶ç°çŠ¶ï¼Œæ¢è®¨äº†å…¶åœ¨å®¢æˆ·æ”¯æŒã€æ•™è‚²ã€æ³•å¾‹å’ŒåŒ»ç–—ç­‰é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ã€‚æ–‡ç« è¯¦ç»†åˆ†æäº†ConvQAçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼ŒåŒ…æ‹¬å†å²é€‰æ‹©(History Selection)ã€é—®é¢˜ç†è§£(Question Understanding)å’Œç­”æ¡ˆé¢„æµ‹(Answer Prediction)ï¼Œå¹¶é˜è¿°äº†è¿™äº›ç»„ä»¶åœ¨ç»´æŒå¤šè½®å¯¹è¯è¿è´¯æ€§æ–¹é¢çš„ååŒä½œç”¨ã€‚ç ”ç©¶è¿›ä¸€æ­¥è°ƒæŸ¥äº†å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ã€å¯¹æ¯”å­¦ä¹ (Contrastive Learning)å’Œè¿ç§»å­¦ä¹ (Transfer Learning)ç­‰å…ˆè¿›æŠ€æœ¯åœ¨æå‡ç³»ç»Ÿæ€§èƒ½ä¸­çš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œç»¼è¿°é‡ç‚¹è®¨è®ºäº†å¤§è¯­è¨€æ¨¡å‹(Large Language Models)ï¼Œå¦‚RoBERTaã€GPT-4ã€Gemini 2.0 Flashã€Mistral 7Bå’ŒLLaMA 3åœ¨æ¨åŠ¨è¯¥é¢†åŸŸå‘å±•ä¸­çš„å…³é”®ä½œç”¨ã€‚é€šè¿‡å¯¹æ ¸å¿ƒæ•°æ®é›†çš„åˆ†æå’Œå¯¹æœªæ¥ç ”ç©¶æ–¹å‘çš„å±•æœ›ï¼Œæœ¬æ–‡ä¸ºç†è§£ConvQAçš„æŠ€æœ¯å…¨æ™¯æä¾›äº†æ·±åº¦è§è§£ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥å·¥ä½œä¸ºç ”ç©¶äººå‘˜æŒæ¡ConvQAçš„å‰æ²¿åŠ¨æ€åŠå¼•å¯¼åç»­æŠ€æœ¯è¿›æ­¥æä¾›äº†é‡è¦çš„å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "42 pages, 12 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.05716v1",
      "published_date": "2025-09-06 13:38:03 UTC",
      "updated_date": "2025-09-06 13:38:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:24.589414+00:00"
    },
    {
      "arxiv_id": "2509.05714v1",
      "title": "Towards Meta-Cognitive Knowledge Editing for Multimodal LLMs",
      "title_zh": "è¿ˆå‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å…ƒè®¤çŸ¥çŸ¥è¯†ç¼–è¾‘",
      "authors": [
        "Zhaoyu Fan",
        "Kaihang Pan",
        "Mingze Zhou",
        "Bosheng Qin",
        "Juncheng Li",
        "Shengyu Zhang",
        "Wenqiao Zhang",
        "Siliang Tang",
        "Fei Wu",
        "Yueting Zhuang"
      ],
      "abstract": "Knowledge editing enables multimodal large language models (MLLMs) to efficiently update outdated or incorrect information. However, existing benchmarks primarily emphasize cognitive-level modifications while lacking a focus on deeper meta-cognitive processes. To bridge this gap, we introduce CogEdit, a novel benchmark designed to evaluate MLLMs' meta-cognitive knowledge editing abilities across three levels: (1) Counterfactual-Driven Editing, assessing self-awareness of knowledge correctness changes; (2) Boundary Constraint Editing, ensuring appropriate generalization without unintended interference; and (3) Noise-Robust Editing, promoting reflective evaluation of uncertain information. To advance meta-cognitive editing, we propose MIND (Meta-cognitive INtegrated Dynamic Knowledge Editing), a framework that constructs a meta-knowledge memory for self-awareness, employs game-theoretic interactions to monitor knowledge activation, and incorporates label refinement for noise-robust updates. Extensive experiments show that MIND significantly outperforms existing cognitive editing approaches, achieving strong performance on both traditional and meta-cognitive knowledge editing benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨çŸ¥è¯†ç¼–è¾‘é¢†åŸŸä»…ä¾§é‡è®¤çŸ¥å±‚é¢è€Œå¿½è§†å…ƒè®¤çŸ¥ï¼ˆmeta-cognitiveï¼‰è¿‡ç¨‹çš„ç°çŠ¶ï¼Œæå‡ºäº†å…¨æ–°çš„è¯„ä¼°åŸºå‡† CogEditã€‚CogEdit æ¶µç›–äº†åå‘äº‹å®é©±åŠ¨ç¼–è¾‘ï¼ˆCounterfactual-Driven Editingï¼‰ã€è¾¹ç•Œçº¦æŸç¼–è¾‘ï¼ˆBoundary Constraint Editingï¼‰ä»¥åŠå™ªå£°é²æ£’ç¼–è¾‘ï¼ˆNoise-Robust Editingï¼‰ä¸‰ä¸ªç»´åº¦ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹å¯¹çŸ¥è¯†å‡†ç¡®æ€§çš„è‡ªæˆ‘æ„ŸçŸ¥å’Œåæ€èƒ½åŠ›ã€‚ä¸ºäº†æ¨è¿›å…ƒè®¤çŸ¥ç¼–è¾‘æŠ€æœ¯ï¼Œç ”ç©¶è€…æå‡ºäº†åä¸º MIND çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ„å»ºå…ƒçŸ¥è¯†å­˜å‚¨æ¥å¢å¼ºæ¨¡å‹çš„è‡ªæˆ‘æ„è¯†ï¼Œå¹¶åˆ©ç”¨åšå¼ˆè®ºäº¤äº’æ¥ç›‘æµ‹çŸ¥è¯†æ¿€æ´»ã€‚æ­¤å¤–ï¼ŒMIND è¿˜ç»“åˆäº†æ ‡ç­¾ç»†åŒ–æœºåˆ¶ï¼Œä»¥å®ç°å¯¹å™ªå£°å¹²æ‰°çš„ç¨³å¥æ›´æ–°ã€‚å¤§é‡çš„å®éªŒç»“æœè¯æ˜ï¼ŒMIND åœ¨ä¼ ç»Ÿå’Œå…ƒè®¤çŸ¥çŸ¥è¯†ç¼–è¾‘åŸºå‡†æµ‹è¯•ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„è®¤çŸ¥ç¼–è¾‘æ–¹æ³•ï¼Œå±•ç°äº†åœ¨å¤„ç†å¤æ‚çŸ¥è¯†æ›´æ–°ä»»åŠ¡ä¸­çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05714v1",
      "published_date": "2025-09-06 13:26:04 UTC",
      "updated_date": "2025-09-06 13:26:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:22.988572+00:00"
    },
    {
      "arxiv_id": "2509.05703v1",
      "title": "Knowledge-Augmented Vision Language Models for Underwater Bioacoustic Spectrogram Analysis",
      "title_zh": "ç”¨äºæ°´ä¸‹ç”Ÿç‰©å£°å­¦å£°è°±å›¾åˆ†æçš„çŸ¥è¯†å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹",
      "authors": [
        "Ragib Amin Nihal",
        "Benjamin Yen",
        "Takeshi Ashizawa",
        "Kazuhiro Nakadai"
      ],
      "abstract": "Marine mammal vocalization analysis depends on interpreting bioacoustic spectrograms. Vision Language Models (VLMs) are not trained on these domain-specific visualizations. We investigate whether VLMs can extract meaningful patterns from spectrograms visually. Our framework integrates VLM interpretation with LLM-based validation to build domain knowledge. This enables adaptation to acoustic data without manual annotation or model retraining.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†çŸ¥è¯†å¢å¼ºçš„è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨æ°´ä¸‹ç”Ÿç‰©å£°å­¦é¢‘è°±å›¾(Spectrogram)åˆ†æä¸­çš„åº”ç”¨ã€‚é’ˆå¯¹VLMsæ™®éç¼ºä¹æ­¤ç±»é¢†åŸŸç‰¹å®šå¯è§†åŒ–æ•°æ®è®­ç»ƒçš„ç°çŠ¶ï¼Œç ”ç©¶äººå‘˜è°ƒæŸ¥äº†å…¶ä»é¢‘è°±å›¾ä¸­æå–è§†è§‰ç‰¹å¾çš„èƒ½åŠ›ã€‚æå‡ºçš„æ¡†æ¶å°†VLMçš„å›¾åƒè§£è¯»åŠŸèƒ½ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„éªŒè¯æœºåˆ¶ç›¸ç»“åˆï¼Œä»è€Œåœ¨ç³»ç»Ÿå†…æ„å»ºé¢†åŸŸçŸ¥è¯†ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿåœ¨æ— éœ€äººå·¥æ ‡æ³¨(Manual Annotation)æˆ–æ¨¡å‹é‡è®­çš„å‰æä¸‹ï¼Œä½¿æ¨¡å‹é€‚åº”æ°´ä¸‹å£°å­¦æ•°æ®ã€‚è¿™ç§ç­–ç•¥ä¸ºæµ·æ´‹å“ºä¹³åŠ¨ç‰©å‘å£°æ¨¡å¼çš„è¯†åˆ«æä¾›äº†é«˜åº¦çµæ´»çš„æŠ€æœ¯æ‰‹æ®µã€‚ç ”ç©¶ç»“æœè¯æ˜äº†åˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹å¤„ç†ä¸“ä¸šç§‘å­¦æ•°æ®çš„å¯è¡Œæ€§ä¸æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05703v1",
      "published_date": "2025-09-06 12:36:59 UTC",
      "updated_date": "2025-09-06 12:36:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:51.997780+00:00"
    },
    {
      "arxiv_id": "2509.05691v1",
      "title": "Revealing the Numeracy Gap: An Empirical Investigation of Text Embedding Models",
      "title_zh": "æ­ç¤ºæ•°ç†èƒ½åŠ›å·®è·ï¼šæ–‡æœ¬åµŒå…¥æ¨¡å‹çš„å®è¯ç ”ç©¶",
      "authors": [
        "Ningyuan Deng",
        "Hanyu Duan",
        "Yixuan Tang",
        "Yi Yang"
      ],
      "abstract": "Text embedding models are widely used in natural language processing applications. However, their capability is often benchmarked on tasks that do not require understanding nuanced numerical information in text. As a result, it remains unclear whether current embedding models can precisely encode numerical content, such as numbers, into embeddings. This question is critical because embedding models are increasingly applied in domains where numbers matter, such as finance and healthcare. For example, Company X's market share grew by 2\\% should be interpreted very differently from Company X's market share grew by 20\\%, even though both indicate growth in market share. This study aims to examine whether text embedding models can capture such nuances. Using synthetic data in a financial context, we evaluate 13 widely used text embedding models and find that they generally struggle to capture numerical details accurately. Our further analyses provide deeper insights into embedding numeracy, informing future research to strengthen embedding model-based NLP systems with improved capacity for handling numerical content.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†æ–‡æœ¬åµŒå…¥æ¨¡å‹(text embedding models)åœ¨å¤„ç†æ–‡æœ¬ä¸­ç»†å¾®æ•°å­—ä¿¡æ¯æ–¹é¢çš„èƒ½åŠ›ï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹ä¸­æ™®éå­˜åœ¨çš„â€œæ•°å­—èƒ½åŠ›ç¼ºå£â€(numeracy gap)ã€‚å°½ç®¡åµŒå…¥æ¨¡å‹å·²å¹¿æ³›åº”ç”¨äºé‡‘èå’ŒåŒ»ç–—ç­‰å¯¹æ•°å­—é«˜åº¦æ•æ„Ÿçš„é¢†åŸŸï¼Œä½†ç°æœ‰åŸºå‡†æµ‹è¯•å¾€å¾€å¿½ç•¥äº†æ¨¡å‹å¯¹æ•°å€¼å†…å®¹çš„ç²¾ç¡®ç¼–ç èƒ½åŠ›ã€‚ç ”ç©¶è€…åˆ©ç”¨é‡‘èèƒŒæ™¯ä¸‹çš„åˆæˆæ•°æ®å¯¹13ç§ä¸»æµçš„æ–‡æœ¬åµŒå…¥æ¨¡å‹è¿›è¡Œäº†å®è¯è°ƒæŸ¥ï¼Œç»“æœæ˜¾ç¤ºè¿™äº›æ¨¡å‹æ™®ééš¾ä»¥å‡†ç¡®æ•æ‰æ•°å­—ç»†èŠ‚ï¼Œæ— æ³•æœ‰æ•ˆåŒºåˆ†æ•°å€¼ä¸Šçš„å…³é”®å·®å¼‚ã€‚è¯¥ç ”ç©¶é€šè¿‡å¯¹åµŒå…¥æ¨¡å‹æ•°å­—å¤„ç†èƒ½åŠ›çš„æ·±åº¦åˆ†æï¼Œä¸ºæœªæ¥æå‡è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ç³»ç»Ÿå¤„ç†æ•°å­—å†…å®¹çš„èƒ½åŠ›æä¾›äº†é‡è¦è§è§£å’Œç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05691v1",
      "published_date": "2025-09-06 11:44:26 UTC",
      "updated_date": "2025-09-06 11:44:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:31.791611+00:00"
    },
    {
      "arxiv_id": "2510.15889v1",
      "title": "Mitigating Harmful Erraticism in LLMs Through Dialectical Behavior Therapy Based De-Escalation Strategies",
      "title_zh": "é€šè¿‡åŸºäºè¾©è¯è¡Œä¸ºç–—æ³•çš„é™çº§ç­–ç•¥ç¼“è§£å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æœ‰å®³å¼‚å¸¸è¡¨ç°",
      "authors": [
        "Pooja Rangarajan",
        "Jacob Boyle"
      ],
      "abstract": "The escalating demand for personalized AI chatbot interactions, capable of dynamically adapting to user emotional states and real-time requests, has highlighted critical limitations in current development paradigms. Existing methodologies, which rely on baseline programming, custom personalities, and manual response adjustments, often prove difficult to maintain and are susceptible to errors such as hallucinations, erratic outputs, and software bugs. This paper hypothesizes that a framework rooted in human psychological principles, specifically therapeutic modalities, can provide a more robust and sustainable solution than purely technical interventions. Drawing an analogy to the simulated neural networks of AI mirroring the human brain, we propose the application of Dialectical Behavior Therapy (DBT) principles to regulate chatbot responses to diverse user inputs. This research investigates the impact of a DBT-based framework on AI chatbot performance, aiming to ascertain its efficacy in yielding more reliable, safe, and accurate responses, while mitigating the occurrence of hallucinations, erratic behaviors, and other systemic issues.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸ªæ€§åŒ– AI èŠå¤©æœºå™¨äººåœ¨åŠ¨æ€é€‚åº”ç”¨æˆ·æƒ…ç»ªæ—¶é¢ä¸´çš„å¹»è§‰ (hallucinations)ã€ä¸ç¨³å®šæ€§è¾“å‡ºå’Œç»´æŠ¤å›°éš¾ç­‰ç“¶é¢ˆï¼Œæ¢è®¨äº†ä¼ ç»ŸæŠ€æœ¯å¹²é¢„æ‰‹æ®µçš„å±€é™æ€§ã€‚ç ”ç©¶è€…æå‡ºå°†äººç±»å¿ƒç†å­¦ä¸­çš„è¾©è¯è¡Œä¸ºç–—æ³• (Dialectical Behavior Therapy, DBT) åŸåˆ™åº”ç”¨äº AI é¢†åŸŸï¼Œé€šè¿‡ç±»æ¯”ç¥ç»ç½‘ç»œä¸äººè„‘çš„è¿ä½œæœºåˆ¶ï¼Œæ„å»ºäº†ä¸€ç§åŸºäº DBT å»å‡çº§ç­–ç•¥çš„å“åº”è°ƒèŠ‚æ¡†æ¶ã€‚è¯¥ç ”ç©¶é‡ç‚¹åˆ†æäº† DBT æ¡†æ¶åœ¨è§„èŒƒèŠå¤©æœºå™¨äººåº”å¯¹å¤šæ ·åŒ–ç”¨æˆ·è¾“å…¥æ—¶çš„è¡¨ç°ï¼Œæ—¨åœ¨é€šè¿‡å¿ƒç†å­¦å¹²é¢„æå‡ç³»ç»Ÿçš„å¯é æ€§ã€å®‰å…¨æ€§å’Œå‡†ç¡®æ€§ã€‚åˆæ­¥ç ”ç©¶ç»“æœè¯å®ï¼Œè¿™ç§è·¨å­¦ç§‘æ–¹æ³•èƒ½æœ‰æ•ˆç¼“è§£å¤§è¯­è¨€æ¨¡å‹ (LLMs) äº§ç”Ÿçš„æœ‰å®³ä¸ç¨³å®šæ€§è¡Œä¸ºå’Œç³»ç»Ÿæ€§é”™è¯¯ï¼Œä¸ºå®ç°æ›´å…·é²æ£’æ€§å’Œå¯æŒç»­æ€§çš„ AI äº¤äº’æä¾›äº†å…¨æ–°çš„ç†è®ºè§†è§’ä¸å®è·µæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages, 7 figures and 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.15889v1",
      "published_date": "2025-09-06 11:20:15 UTC",
      "updated_date": "2025-09-06 11:20:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:49.596157+00:00"
    },
    {
      "arxiv_id": "2509.05685v2",
      "title": "MSRFormer: Road Network Representation Learning using Multi-scale Feature Fusion of Heterogeneous Spatial Interactions",
      "title_zh": "MSRFormerï¼šåŸºäºå¼‚æ„ç©ºé—´äº¤äº’å¤šå°ºåº¦ç‰¹å¾èåˆçš„è·¯ç½‘è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Jian Yang",
        "Jiahui Wu",
        "Li Fang",
        "Hongchao Fan",
        "Bianying Zhang",
        "Huijie Zhao",
        "Guangyi Yang",
        "Rui Xin",
        "Xiong You"
      ],
      "abstract": "Transforming road network data into vector representations using deep learning has proven effective for road network analysis. However, urban road networks' heterogeneous and hierarchical nature poses challenges for accurate representation learning. Graph neural networks, which aggregate features from neighboring nodes, often struggle due to their homogeneity assumption and focus on a single structural scale. To address these issues, this paper presents MSRFormer, a novel road network representation learning framework that integrates multi-scale spatial interactions by addressing their flow heterogeneity and long-distance dependencies. It uses spatial flow convolution to extract small-scale features from large trajectory datasets, and identifies scale-dependent spatial interaction regions to capture the spatial structure of road networks and flow heterogeneity. By employing a graph transformer, MSRFormer effectively captures complex spatial dependencies across multiple scales. The spatial interaction features are fused using residual connections, which are fed to a contrastive learning algorithm to derive the final road network representation. Validation on two real-world datasets demonstrates that MSRFormer outperforms baseline methods in two road network analysis tasks. The performance gains of MSRFormer suggest the traffic-related task benefits more from incorporating trajectory data, also resulting in greater improvements in complex road network structures with up to 16% improvements compared to the most competitive baseline method. This research provides a practical framework for developing task-agnostic road network representation models and highlights distinct association patterns of the interplay between scale effects and flow heterogeneity of spatial interactions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸå¸‚è·¯ç½‘å¼‚æ„æ€§å’Œå±‚æ¬¡åŒ–å¸¦æ¥çš„è¡¨ç¤ºå­¦ä¹ æŒ‘æˆ˜ï¼Œæå‡ºäº† MSRFormer æ¡†æ¶ï¼Œæ—¨åœ¨æ•´åˆå¤šå°ºåº¦ç©ºé—´äº¤äº’å¹¶å¤„ç†æµå¼‚æ„æ€§ä¸é•¿è·ç¦»ä¾èµ–ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç©ºé—´æµå·ç§¯ (Spatial Flow Convolution) ä»å¤§è§„æ¨¡è½¨è¿¹æ•°æ®ä¸­æå–å°å°ºåº¦ç‰¹å¾ï¼Œå¹¶è¯†åˆ«å°ºåº¦ç›¸å…³çš„ç©ºé—´äº¤äº’åŒºåŸŸï¼Œä»è€Œæ•æ‰è·¯ç½‘çš„ç»“æ„ç‰¹å¾ä¸æµé‡å¼‚æ„æ€§ã€‚é€šè¿‡å¼•å…¥ Graph Transformerï¼ŒMSRFormer èƒ½å¤Ÿæœ‰æ•ˆæ•è·è·¨å¤šä¸ªå°ºåº¦çš„å¤æ‚ç©ºé—´ä¾èµ–ï¼Œå¹¶ç»“åˆæ®‹å·®è¿æ¥ä¸å¯¹æ¯”å­¦ä¹  (Contrastive Learning) ç®—æ³•ç”Ÿæˆæœ€ç»ˆçš„è·¯ç½‘è¡¨ç¤ºã€‚åœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„éªŒè¯ç»“æœæ˜¾ç¤ºï¼ŒMSRFormer åœ¨å¤šé¡¹åˆ†æä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œåœ¨å¤æ‚è·¯ç½‘ç»“æ„ä¸‹çš„æ€§èƒ½æå‡æœ€é«˜å¯è¾¾ 16%ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¼€å‘ä»»åŠ¡æ— å…³çš„è·¯ç½‘è¡¨ç¤ºæ¨¡å‹æä¾›äº†å®ç”¨æ¡†æ¶ï¼Œå¹¶æ­ç¤ºäº†ç©ºé—´äº¤äº’ä¸­å°ºåº¦æ•ˆåº”ä¸æµå¼‚æ„æ€§ä¹‹é—´çš„å…³è”æ¨¡å¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05685v2",
      "published_date": "2025-09-06 11:19:13 UTC",
      "updated_date": "2025-09-09 16:46:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:50.003463+00:00"
    },
    {
      "arxiv_id": "2509.07011v1",
      "title": "Renewable Energy Sources Selection Analysis with the Maximizing Deviation Method",
      "title_zh": "åŸºäºç¦»å·®æœ€å¤§åŒ–æ³•çš„å¯å†ç”Ÿèƒ½æºé€‰æ‹©åˆ†æ",
      "authors": [
        "Kirisci Murat"
      ],
      "abstract": "Multi-criteria decision-making methods provide decision-makers with appropriate tools to make better decisions in uncertain, complex, and conflicting situations. Fuzzy set theory primarily deals with the uncertainty inherent in human thoughts and perceptions and attempts to quantify this uncertainty. Fuzzy logic and fuzzy set theory are utilized with multi-criteria decision-making methods because they effectively handle uncertainty and fuzziness in decision-makers' judgments, allowing for verbal judgments of the problem. This study utilizes the Fermatean fuzzy environment, a generalization of fuzzy sets. An optimization model based on the deviation maximization method is proposed to determine partially known feature weights. This method is combined with interval-valued Fermatean fuzzy sets. The proposed method was applied to the problem of selecting renewable energy sources. The reason for choosing renewable energy sources is that meeting energy needs from renewable sources, balancing carbon emissions, and mitigating the effects of global climate change are among the most critical issues of the recent period. Even though selecting renewable energy sources is a technical issue, the managerial and political implications of this issue are also important, and are discussed in this study.",
      "tldr_zh": "é’ˆå¯¹åœ¨å¤æ‚å’Œå†²çªçš„ç¯å¢ƒä¸‹é€‰æ‹©å¯å†ç”Ÿèƒ½æºçš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æ¢è®¨äº†å¤šå‡†åˆ™å†³ç­–(Multi-criteria decision-making)æ–¹æ³•çš„åº”ç”¨ï¼Œæ—¨åœ¨æé«˜ä¸ç¡®å®šæ€§ä¸‹çš„å†³ç­–è´¨é‡ã€‚ç ”ç©¶é‡‡ç”¨äº†Fermatean fuzzyç¯å¢ƒï¼Œåˆ©ç”¨å…¶ä½œä¸ºæ¨¡ç³Šé›†æ¨å¹¿çš„ç‰¹æ€§ï¼Œæœ‰æ•ˆå¤„ç†å†³ç­–è€…åˆ¤æ–­ä¸­çš„æ¨¡ç³Šæ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç¦»å·®æœ€å¤§åŒ–æ–¹æ³•(Maximizing deviation method)çš„ä¼˜åŒ–æ¨¡å‹ï¼Œç”¨äºç¡®å®šéƒ¨åˆ†å·²çŸ¥çš„ç‰¹å¾æƒé‡ï¼Œå¹¶å°†å…¶ä¸åŒºé—´å€¼Fermateanæ¨¡ç³Šé›†(Interval-valued Fermatean fuzzy sets)ç›¸ç»“åˆã€‚è¯¥æ–¹æ³•è¢«æˆåŠŸåº”ç”¨äºå¯å†ç”Ÿèƒ½æºçš„é€‰æ‹©åˆ†æï¼Œä»¥åº”å¯¹å¹³è¡¡ç¢³æ’æ”¾å’Œå‡ç¼“æ°”å€™å˜åŒ–ç­‰å…³é”®æŒ‘æˆ˜ã€‚ç ”ç©¶ä¸ä»…è§£å†³äº†æŠ€æœ¯å±‚é¢çš„èµ„æºè¯„ä¼°é—®é¢˜ï¼Œè¿˜æ·±å…¥æ¢è®¨äº†ç›¸å…³ç®¡ç†å’Œæ”¿æ²»å±‚é¢çš„å½±å“ï¼Œä¸ºå¯æŒç»­èƒ½æºå†³ç­–æä¾›äº†ç§‘å­¦çš„å·¥å…·æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 5 figures, 6 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.07011v1",
      "published_date": "2025-09-06 11:17:58 UTC",
      "updated_date": "2025-09-06 11:17:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:57:54.497176+00:00"
    },
    {
      "arxiv_id": "2509.05681v1",
      "title": "SEASONED: Semantic-Enhanced Self-Counterfactual Explainable Detection of Adversarial Exploiter Contracts",
      "title_zh": "SEASONEDï¼šé¢å‘å¯¹æŠ—æ€§åˆ©ç”¨åˆçº¦çš„è¯­ä¹‰å¢å¼ºå‹è‡ªåäº‹å®å¯è§£é‡Šæ£€æµ‹",
      "authors": [
        "Xng Ai",
        "Shudan Lin",
        "Zecheng Li",
        "Kai Zhou",
        "Bixin Li",
        "Bin Xiao"
      ],
      "abstract": "Decentralized Finance (DeFi) attacks have resulted in significant losses, often orchestrated through Adversarial Exploiter Contracts (AECs) that exploit vulnerabilities in victim smart contracts. To proactively identify such threats, this paper targets the explainable detection of AECs.\n  Existing detection methods struggle to capture semantic dependencies and lack interpretability, limiting their effectiveness and leaving critical knowledge gaps in AEC analysis. To address these challenges, we introduce SEASONED, an effective, self-explanatory, and robust framework for AEC detection.\n  SEASONED extracts semantic information from contract bytecode to construct a semantic relation graph (SRG), and employs a self-counterfactual explainable detector (SCFED) to classify SRGs and generate explanations that highlight the core attack logic. SCFED further enhances robustness, generalizability, and data efficiency by extracting representative information from these explanations. Both theoretical analysis and experimental results demonstrate the effectiveness of SEASONED, which showcases outstanding detection performance, robustness, generalizability, and data efficiency learning ability. To support further research, we also release a new dataset of 359 AECs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å»ä¸­å¿ƒåŒ–é‡‘è(DeFi)ä¸­çš„å¯¹æŠ—æ€§æ”»å‡»è€…åˆçº¦(Adversarial Exploiter Contracts, AECs)æå‡ºäº†SEASONEDæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ£€æµ‹æ–¹æ³•åœ¨æ•è·è¯­ä¹‰ä¾èµ–å’Œå¯è§£é‡Šæ€§æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ¡†æ¶é¦–å…ˆä»åˆçº¦å­—èŠ‚ç ä¸­æå–è¯­ä¹‰ä¿¡æ¯ä»¥æ„å»ºè¯­ä¹‰å…³ç³»å›¾(Semantic Relation Graph, SRG)ï¼Œå¹¶é‡‡ç”¨è‡ªåäº‹å®å¯è§£é‡Šæ£€æµ‹å™¨(Self-Counterfactual Explainable Detector, SCFED)å¯¹SRGsè¿›è¡Œåˆ†ç±»ã€‚SCFEDèƒ½å¤Ÿç”Ÿæˆçªå‡ºæ ¸å¿ƒæ”»å‡»é€»è¾‘çš„è§£é‡Šï¼Œå¹¶é€šè¿‡ä»ä¸­æå–ä»£è¡¨æ€§ä¿¡æ¯æ¥å¢å¼ºç³»ç»Ÿçš„é²æ£’æ€§ã€æ³›åŒ–èƒ½åŠ›å’Œæ•°æ®æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSEASONEDåœ¨æ£€æµ‹æ€§èƒ½å’Œå­¦ä¹ èƒ½åŠ›æ–¹é¢è¡¨ç°å“è¶Šï¼Œå±•ç°äº†æé«˜çš„å®ç”¨ä»·å€¼ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å‘å¸ƒäº†ä¸€ä¸ªåŒ…å«359ä¸ªAECsçš„æ–°æ•°æ®é›†ï¼Œä¸ºè¯¥é¢†åŸŸçš„åç»­ç ”ç©¶æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05681v1",
      "published_date": "2025-09-06 11:08:10 UTC",
      "updated_date": "2025-09-06 11:08:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:13.496650+00:00"
    },
    {
      "arxiv_id": "2509.07010v1",
      "title": "Human-in-the-Loop: Quantitative Evaluation of 3D Models Generation by Large Language Models",
      "title_zh": "äººåœ¨å›è·¯ï¼šå¤§è¯­è¨€æ¨¡å‹ 3D æ¨¡å‹ç”Ÿæˆçš„å®šé‡è¯„ä¼°",
      "authors": [
        "Ahmed R. Sadik",
        "Mariusz Bujny"
      ],
      "abstract": "Large Language Models are increasingly capable of interpreting multimodal inputs to generate complex 3D shapes, yet robust methods to evaluate geometric and structural fidelity remain underdeveloped. This paper introduces a human in the loop framework for the quantitative evaluation of LLM generated 3D models, supporting applications such as democratization of CAD design, reverse engineering of legacy designs, and rapid prototyping. We propose a comprehensive suite of similarity and complexity metrics, including volumetric accuracy, surface alignment, dimensional fidelity, and topological intricacy, to benchmark generated models against ground truth CAD references. Using an L bracket component as a case study, we systematically compare LLM performance across four input modalities: 2D orthographic views, isometric sketches, geometric structure trees, and code based correction prompts. Our findings demonstrate improved generation fidelity with increased semantic richness, with code level prompts achieving perfect reconstruction across all metrics. A key contribution of this work is demonstrating that our proposed quantitative evaluation approach enables significantly faster convergence toward the ground truth, especially compared to traditional qualitative methods based solely on visual inspection and human intuition. This work not only advances the understanding of AI assisted shape synthesis but also provides a scalable methodology to validate and refine generative models for diverse CAD applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåä¸º Human-in-the-Loop çš„æ¡†æ¶ï¼Œç”¨äºå®šé‡è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆçš„ 3D æ¨¡å‹ï¼Œæ—¨åœ¨æå‡ CAD è®¾è®¡ã€é€†å‘å·¥ç¨‹å’Œå¿«é€ŸåŸå‹åˆ¶ä½œä¸­çš„å‡ ä½•ä¸ç»“æ„ä¿çœŸåº¦ã€‚ä½œè€…å¼€å‘äº†ä¸€å¥—æ¶µç›–ä½“ç§¯å‡†ç¡®åº¦ (volumetric accuracy)ã€è¡¨é¢å¯¹é½ (surface alignment)ã€å°ºå¯¸ä¿çœŸåº¦ (dimensional fidelity) å’Œæ‹“æ‰‘å¤æ‚æ€§ (topological intricacy) çš„ç»¼åˆè¯„ä¼°æŒ‡æ ‡ã€‚é€šè¿‡ L æ”¯æ¶ (L bracket) ç»„ä»¶çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œç³»ç»Ÿå¯¹æ¯”äº† 2D æ­£äº¤è§†å›¾ã€ç­‰è½´æµ‹è‰å›¾ã€å‡ ä½•ç»“æ„æ ‘å’ŒåŸºäºä»£ç çš„ä¿®æ­£æç¤º (code based correction prompts) å››ç§è¾“å…¥æ¨¡æ€ã€‚å®éªŒå‘ç°ï¼Œç”Ÿæˆä¿çœŸåº¦éšè¾“å…¥è¯­ä¹‰ä¸°å¯Œåº¦çš„å¢åŠ è€Œæé«˜ï¼Œå…¶ä¸­ä»£ç çº§æç¤ºåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡å®ç°äº†å®Œç¾é‡å»ºã€‚è¯¥å·¥ä½œçš„æ ¸å¿ƒè´¡çŒ®åœ¨äºè¯æ˜äº†å®šé‡è¯„ä¼°æ–¹æ³•ç›¸æ¯”ä¼ ç»Ÿçš„å®šæ€§è§†è§‰æ£€æŸ¥èƒ½æ˜¾è‘—åŠ å¿«æ¨¡å‹å‘çœŸå®å€¼ (ground truth) çš„æ”¶æ•›é€Ÿåº¦ï¼Œä¸º AI è¾…åŠ©å½¢çŠ¶åˆæˆçš„éªŒè¯ä¸ä¼˜åŒ–æä¾›äº†å¯æ‰©å±•çš„æ–¹æ³•è®ºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.07010v1",
      "published_date": "2025-09-06 11:04:15 UTC",
      "updated_date": "2025-09-06 11:04:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:31.486395+00:00"
    },
    {
      "arxiv_id": "2509.10541v1",
      "title": "Situation Model of the Transport, Transport Emissions and Meteorological Conditions",
      "title_zh": "äº¤é€šã€äº¤é€šæ’æ”¾ä¸æ°”è±¡æ¡ä»¶çš„æƒ…å¢ƒæ¨¡å‹",
      "authors": [
        "V. Benes",
        "M. Svitek",
        "A. Michalikova",
        "M. Melicherik"
      ],
      "abstract": "Air pollution in cities and the possibilities of reducing this pollution represents one of the most important factors that today's society has to deal with. This paper focuses on a systemic approach to traffic emissions with their relation to meteorological conditions, analyzing the effect of weather on the quantity and dispersion of traffic emissions in a city. Using fuzzy inference systems (FIS) the model for prediction of changes in emissions depending on various conditions is developed. The proposed model is based on traffic, meteorology and emission data measured in Prague, Czech Republic. The main objective of the work is to provide insight into how urban planners and policymakers can plan and manage urban transport more effectively with environmental protection in mind.",
      "tldr_zh": "æœ¬ç ”ç©¶å…³æ³¨åŸå¸‚ç©ºæ°”æ±¡æŸ“åŠå…¶å‡æ’ç­–ç•¥ï¼Œæ¢è®¨äº†äº¤é€šæ’æ”¾(Traffic Emissions)ä¸æ°”è±¡æ¡ä»¶(Meteorological Conditions)ä¹‹é—´çš„ç³»ç»Ÿæ€§å…³è”ã€‚è®ºæ–‡æ·±å…¥åˆ†æäº†å¤©æ°”çŠ¶å†µå¯¹åŸå¸‚äº¤é€šæ’æ”¾é‡åŠå…¶æ‰©æ•£(Dispersion)è¿‡ç¨‹çš„å…·ä½“å½±å“ã€‚ä½œè€…åˆ©ç”¨æ¨¡ç³Šæ¨ç†ç³»ç»Ÿ(Fuzzy Inference Systems, FIS)å¼€å‘äº†ä¸€ä¸ªæƒ…å¢ƒæ¨¡å‹(Situation Model)ï¼Œæ—¨åœ¨æ ¹æ®å„ç§å¤–éƒ¨æ¡ä»¶é¢„æµ‹æ’æ”¾é‡çš„å˜åŒ–ã€‚è¯¥æ¨¡å‹åŸºäºæ·å…‹å¸ƒæ‹‰æ ¼æ”¶é›†çš„äº¤é€šã€æ°”è±¡å’Œæ’æ”¾å®æµ‹æ•°æ®æ„å»ºè€Œæˆã€‚ç ”ç©¶çš„ä¸»è¦ç›®æ ‡æ˜¯æ­ç¤ºç¯å¢ƒå› ç´ å¯¹æ’æ”¾åŠ¨æ€çš„å¹²é¢„æœºåˆ¶ï¼Œä¸ºåŸå¸‚è§„åˆ’è€…æœ‰æ•ˆç®¡ç†äº¤é€šå’Œä¿æŠ¤ç¯å¢ƒæä¾›äº†ç§‘å­¦çš„å†³ç­–æ”¯æŒã€‚è¯¥æ–¹æ³•è®ºæœ‰åŠ©äºåˆ¶å®šæ›´å…·ç¯å¢ƒå‰ç»æ€§çš„åŸå¸‚è¿è¾“ç®¡ç†æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10541v1",
      "published_date": "2025-09-06 11:02:02 UTC",
      "updated_date": "2025-09-06 11:02:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:17.693665+00:00"
    },
    {
      "arxiv_id": "2509.05671v1",
      "title": "GraMFedDHAR: Graph Based Multimodal Differentially Private Federated HAR",
      "title_zh": "GraMFedDHARï¼šåŸºäºå›¾çš„å¤šæ¨¡æ€å·®åˆ†éšç§è”é‚¦äººä½“æ´»åŠ¨è¯†åˆ«",
      "authors": [
        "Labani Halder",
        "Tanmay Sen",
        "Sarbani Palit"
      ],
      "abstract": "Human Activity Recognition (HAR) using multimodal sensor data remains challenging due to noisy or incomplete measurements, scarcity of labeled examples, and privacy concerns. Traditional centralized deep learning approaches are often constrained by infrastructure availability, network latency, and data sharing restrictions. While federated learning (FL) addresses privacy by training models locally and sharing only model parameters, it still has to tackle issues arising from the use of heterogeneous multimodal data and differential privacy requirements. In this article, a Graph-based Multimodal Federated Learning framework, GraMFedDHAR, is proposed for HAR tasks. Diverse sensor streams such as a pressure mat, depth camera, and multiple accelerometers are modeled as modality-specific graphs, processed through residual Graph Convolutional Neural Networks (GCNs), and fused via attention-based weighting rather than simple concatenation. The fused embeddings enable robust activity classification, while differential privacy safeguards data during federated aggregation. Experimental results show that the proposed MultiModalGCN model outperforms the baseline MultiModalFFN, with up to 2 percent higher accuracy in non-DP settings in both centralized and federated paradigms. More importantly, significant improvements are observed under differential privacy constraints: MultiModalGCN consistently surpasses MultiModalFFN, with performance gaps ranging from 7 to 13 percent depending on the privacy budget and setting. These results highlight the robustness of graph-based modeling in multimodal learning, where GNNs prove more resilient to the performance degradation introduced by DP noise.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GraMFedDHARï¼Œä¸€ç§åŸºäºå›¾çš„å¤šæ¨¡æ€å·®åˆ†éšç§è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³äººä½“æ´»åŠ¨è¯†åˆ«(HAR)é¢†åŸŸä¸­æ•°æ®å™ªå£°ã€æ ‡æ³¨ç¨€ç¼ºåŠéšç§ä¿æŠ¤ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å°†å‹åŠ›å«ã€æ·±åº¦ç›¸æœºåŠåŠ é€Ÿåº¦è®¡ç­‰ä¼ æ„Ÿå™¨æµå»ºæ¨¡ä¸ºæ¨¡æ€ç‰¹å®šçš„å›¾ï¼Œåˆ©ç”¨æ®‹å·®å›¾å·ç§¯ç¥ç»ç½‘ç»œ(residual GCNs)æå–ç‰¹å¾ï¼Œå¹¶é‡‡ç”¨åŸºäºæ³¨æ„åŠ›çš„æƒé‡æœºåˆ¶è€Œéç®€å•æ‹¼æ¥æ¥å®ç°å¤šæ¨¡æ€èåˆã€‚åœ¨è”é‚¦å­¦ä¹ èšåˆè¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿå¼•å…¥äº†å·®åˆ†éšç§(differential privacy)æœºåˆ¶ä»¥ä¿éšœæ•æ„Ÿæ•°æ®å®‰å…¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æMultiModalGCNæ¨¡å‹åœ¨æ€§èƒ½ä¸Šå…¨é¢è¶…è¶ŠåŸºå‡†MultiModalFFNæ¨¡å‹ï¼Œå°¤å…¶åœ¨å·®åˆ†éšç§çº¦æŸä¸‹ï¼Œå…¶æ€§èƒ½ä¼˜åŠ¿è¾¾åˆ°7%è‡³13%ã€‚è¯¥ç ”ç©¶ç»“æœè¯æ˜äº†å›¾å­¦ä¹ åœ¨å¤šæ¨¡æ€åœºæ™¯ä¸‹çš„é²æ£’æ€§ï¼Œæ­ç¤ºäº†GNNsåœ¨åº”å¯¹å·®åˆ†éšç§å™ªå£°å¹²æ‰°æ—¶æ¯”ä¼ ç»Ÿæ–¹æ³•å…·æœ‰æ›´å¼ºçš„éŸ§æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05671v1",
      "published_date": "2025-09-06 10:23:17 UTC",
      "updated_date": "2025-09-06 10:23:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:21.860039+00:00"
    },
    {
      "arxiv_id": "2509.07009v2",
      "title": "Computational Concept of the Psyche (in Russian)",
      "title_zh": "å¿ƒç†è®¡ç®—æ¦‚å¿µï¼ˆä¿„è¯­ç‰ˆï¼‰",
      "authors": [
        "Anton Kolonin",
        "Vladimir Kryukov"
      ],
      "abstract": "The article provides an overview of approaches to modeling the human psyche in the perspective of building an artificial one. Based on the review, a concept of cognitive architecture is proposed, where the psyche is considered as an operating system of a living or artificial subject, including a space of needs that determines its life meanings in connection with stimuli from the external world, and intelligence as a decision-making system for actions in relation to this world in order to satisfy these needs. Based on the concept, a computational formalization is proposed for creating artificial intelligence systems through learning from experience in the space of a space of needs, taking into account their biological or existential significance for an intelligent agent. Thus, the problem of building general artificial intelligence as a system for making optimal decisions in the space of agent-specific needs under conditions of uncertainty is formalized, with maximization of success in achieving goals, minimization of existential risks and maximization of energy efficiency. A minimal experimental implementation of the model is also provided.",
      "tldr_zh": "æœ¬æ–‡ç»¼è¿°äº†åœ¨æ„å»ºäººå·¥å¿ƒç†è§†è§’ä¸‹æ¨¡æ‹Ÿäººç±»å¿ƒç†çš„æ–¹æ³•ï¼Œå¹¶æå‡ºäº†ä¸€ç§è®¤çŸ¥æ¶æ„(cognitive architecture)æ¦‚å¿µã€‚è¯¥ç ”ç©¶å°†å¿ƒç†è§†ä¸ºç”Ÿç‰©æˆ–äººå·¥ä¸»ä½“çš„æ“ä½œç³»ç»Ÿ(operating system)ï¼ŒåŒ…å«å†³å®šå…¶ç”Ÿå‘½æ„ä¹‰çš„éœ€æ±‚ç©ºé—´(space of needs)ï¼Œè€Œæ™ºèƒ½(intelligence)åˆ™æ˜¯ä¸ºäº†æ»¡è¶³è¿™äº›éœ€æ±‚è€Œå­˜åœ¨çš„å†³ç­–ç³»ç»Ÿã€‚åŸºäºæ­¤æ¦‚å¿µï¼Œä½œè€…æå‡ºäº†ä¸€ç§è®¡ç®—å½¢å¼åŒ–(computational formalization)æ–¹æ³•ï¼Œé€šè¿‡åœ¨éœ€æ±‚ç©ºé—´ä¸­å­¦ä¹ ç»éªŒæ¥æ„å»ºäººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œå¹¶å……åˆ†è€ƒè™‘å…¶ç”Ÿç‰©æˆ–å­˜åœ¨æ„ä¹‰ã€‚è¯¥ç ”ç©¶å°†é€šç”¨äººå·¥æ™ºèƒ½(General Artificial Intelligence)çš„å½¢å¼åŒ–é—®é¢˜å®šä¹‰ä¸ºåœ¨ä¸ç¡®å®šæ¡ä»¶ä¸‹ï¼Œäºç‰¹å®šéœ€æ±‚ç©ºé—´å†…åšå‡ºæœ€ä¼˜å†³ç­–ï¼Œä»¥å®ç°ç›®æ ‡æˆåŠŸæœ€å¤§åŒ–ã€å­˜åœ¨é£é™©æœ€å°åŒ–å’Œèƒ½æºæ•ˆç‡æœ€å¤§åŒ–ã€‚æœ€åï¼Œæ–‡ç« æä¾›äº†ä¸€ä¸ªè¯¥æ¨¡å‹çš„æœ€å°å®éªŒå®ç°ï¼Œä¸ºæ„å»ºå…·æœ‰å¿ƒç†å±æ€§çš„æ™ºèƒ½ä¸»ä½“æä¾›äº†æ–°çš„ç†è®ºæ¡†æ¶ä¸å®è·µè·¯å¾„ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "q-bio.NC",
      "comment": "14 pages, in Russian, 2 figures, submitted to Neuroinformatics-2025 conference",
      "pdf_url": "https://arxiv.org/pdf/2509.07009v2",
      "published_date": "2025-09-06 10:22:27 UTC",
      "updated_date": "2025-09-10 07:42:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:37.663362+00:00"
    },
    {
      "arxiv_id": "2509.05668v1",
      "title": "Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian",
      "title_zh": "Llama-GENBA-10Bï¼šå¾·è¯­ã€è‹±è¯­å’Œå·´ä¼åˆ©äºšè¯­ä¸‰è¯­å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Michael Hoffmann",
        "Jophin John",
        "Stefan Schweter",
        "Gokul Ramakrishnan",
        "Hoi-Fong Mak",
        "Alice Zhang",
        "Dmitry Gaynullin",
        "Nicolay J. Hammer"
      ],
      "abstract": "We present Llama-GENBA-10B, a trilingual foundation model addressing English-centric bias in large language models. Built on Llama 3.1-8B and scaled to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens (82B English, 82B German, and 80M Bavarian), balancing resources while preventing English dominance. Targeted at the German NLP community, the model also promotes Bavarian as a low-resource language. Development tackled four challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2) creating a unified tokenizer for English, German, and Bavarian, (3) optimizing architecture and language-ratio hyperparameters for cross-lingual transfer, and (4) establishing the first standardized trilingual evaluation suite by translating German benchmarks into Bavarian. Evaluations show that Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing itself as the best model in its class for this language, while also outperforming EuroLLM in English and matching its results in German. Training on the Cerebras CS-2 demonstrated efficient large-scale multilingual pretraining with documented energy use, offering a blueprint for inclusive foundation models that integrate low-resource languages.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Llama-GENBA-10Bï¼Œä¸€ä¸ªåŸºäº Llama 3.1-8B å¹¶æ‰©å±•è‡³ 10B å‚æ•°çš„ä¸‰è¯­åŸºç¡€æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ä¸­çš„è‹±è¯­ä¸­å¿ƒåè§(English-centric bias)å¹¶é‡ç‚¹æ”¯æŒå¾·è¯­ä¸ä½èµ„æºè¯­è¨€å·´ä¼åˆ©äºšè¯­(Bavarian)ã€‚è¯¥æ¨¡å‹åœ¨ 164B tokens çš„è¯­æ–™åº“ä¸Šè¿›è¡Œäº†æŒç»­é¢„è®­ç»ƒï¼Œé€šè¿‡æ„å»ºç»Ÿä¸€çš„åˆ†è¯å™¨(tokenizer)å’Œä¼˜åŒ–è·¨è¯­è¨€è¿ç§»(cross-lingual transfer)çš„è¶…å‚æ•°ï¼Œå®ç°äº†ä¸åŒè¯­è¨€èµ„æºé—´çš„å¹³è¡¡ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜é€šè¿‡ç¿»è¯‘å¾·è¯­åŸºå‡†æµ‹è¯•å»ºç«‹äº†é¦–ä¸ªæ ‡å‡†åŒ–çš„ä¸‰è¯­è¯„ä¼°å¥—ä»¶ï¼Œè§£å†³äº†ä½èµ„æºè¯­è¨€è¯„ä»·ä½“ç³»ç¼ºå¤±çš„é—®é¢˜ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒLlama-GENBA-10B çš„å¾®è°ƒç‰ˆæœ¬åœ¨å·´ä¼åˆ©äºšè¯­ä»»åŠ¡ä¸Šè¶…è¶Šäº† Apertus-8B-2509 å’Œ gemma-2-9bï¼Œç¡®ç«‹äº†å…¶åœ¨è¯¥è¯­è¨€é¢†åŸŸçš„é¢†å…ˆåœ°ä½ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨è‹±è¯­æ€§èƒ½ä¸Šä¼˜äº EuroLLMï¼Œåœ¨å¾·è¯­æ–¹é¢ä¹Ÿè¾¾åˆ°äº†åŒç­‰æ°´å¹³ã€‚è¿™é¡¹åœ¨ Cerebras CS-2 ä¸Šå®Œæˆçš„ç ”ç©¶å±•ç¤ºäº†é«˜æ•ˆçš„å¤§è§„æ¨¡å¤šè¯­è¨€é¢„è®­ç»ƒæµç¨‹ï¼Œä¸ºé›†æˆä½èµ„æºè¯­è¨€çš„åŸºç¡€æ¨¡å‹å¼€å‘æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Michael Hoffmann and Jophin John contributed equally to this work",
      "pdf_url": "https://arxiv.org/pdf/2509.05668v1",
      "published_date": "2025-09-06 10:12:52 UTC",
      "updated_date": "2025-09-06 10:12:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:32.788416+00:00"
    },
    {
      "arxiv_id": "2509.05657v3",
      "title": "LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding",
      "title_zh": "LM-Searcherï¼šåŸºäºç»Ÿä¸€æ•°å€¼ç¼–ç çš„å¤§è¯­è¨€æ¨¡å‹è·¨é¢†åŸŸç¥ç»æ¶æ„æœç´¢",
      "authors": [
        "Yuxuan Hu",
        "Jihao Liu",
        "Ke Wang",
        "Jinliang Zhen",
        "Weikang Shi",
        "Manyuan Zhang",
        "Qi Dou",
        "Rui Liu",
        "Aojun Zhou",
        "Hongsheng Li"
      ],
      "abstract": "Recent progress in Large Language Models (LLMs) has opened new avenues for solving complex optimization problems, including Neural Architecture Search (NAS). However, existing LLM-driven NAS approaches rely heavily on prompt engineering and domain-specific tuning, limiting their practicality and scalability across diverse tasks. In this work, we propose LM-Searcher, a novel framework that leverages LLMs for cross-domain neural architecture optimization without the need for extensive domain-specific adaptation. Central to our approach is NCode, a universal numerical string representation for neural architectures, which enables cross-domain architecture encoding and search. We also reformulate the NAS problem as a ranking task, training LLMs to select high-performing architectures from candidate pools using instruction-tuning samples derived from a novel pruning-based subspace sampling strategy. Our curated dataset, encompassing a wide range of architecture-performance pairs, encourages robust and transferable learning. Comprehensive experiments demonstrate that LM-Searcher achieves competitive performance in both in-domain (e.g., CNNs for image classification) and out-of-domain (e.g., LoRA configurations for segmentation and generation) tasks, establishing a new paradigm for flexible and generalizable LLM-based architecture search. The datasets and models will be released at https://github.com/Ashone3/LM-Searcher.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„ç¥ç»æ¶æ„æœç´¢(Neural Architecture Search, NAS)é«˜åº¦ä¾èµ–æç¤ºå·¥ç¨‹å’Œé¢†åŸŸç‰¹å®šå¾®è°ƒçš„é—®é¢˜ï¼Œæå‡ºäº†LM-Searcheré€šç”¨æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯å¼•å…¥äº†NCodeï¼Œä¸€ç§é€šç”¨çš„æ•°å­—å­—ç¬¦ä¸²è¡¨ç¤ºæ–¹æ³•ï¼Œä»è€Œå®ç°äº†è·¨é¢†åŸŸçš„ç¥ç»æ¶æ„ç¼–ç ä¸ä¼˜åŒ–ã€‚ç ”ç©¶è€…å°†NASé—®é¢˜é‡æ–°å®šä¹‰ä¸ºæ’åºä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨ä¸€ç§åŸºäºå‰ªæçš„å­ç©ºé—´é‡‡æ ·ç­–ç•¥(pruning-based subspace sampling strategy)ç”Ÿæˆçš„æŒ‡ä»¤å¾®è°ƒæ ·æœ¬æ¥è®­ç»ƒLLMã€‚å®éªŒè¯æ˜ï¼ŒLM-Searcheråœ¨å›¾åƒåˆ†ç±»çš„CNNsç­‰åŸŸå†…ä»»åŠ¡ä»¥åŠåˆ†å‰²ä¸ç”Ÿæˆä»»åŠ¡ä¸­çš„LoRAé…ç½®ç­‰è·¨åŸŸä»»åŠ¡ä¸­å‡å–å¾—äº†æå…·ç«äº‰åŠ›çš„è¡¨ç°ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡ç»Ÿä¸€çš„æ•°å€¼ç¼–ç ä¸ºçµæ´»ä¸”é€šç”¨çš„åŸºäºLLMçš„æ¶æ„æœç´¢å»ºç«‹äº†æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Main",
      "pdf_url": "https://arxiv.org/pdf/2509.05657v3",
      "published_date": "2025-09-06 09:26:39 UTC",
      "updated_date": "2025-09-25 05:43:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:36.268898+00:00"
    },
    {
      "arxiv_id": "2509.05656v1",
      "title": "OptiProxy-NAS: Optimization Proxy based End-to-End Neural Architecture Search",
      "title_zh": "OptiProxy-NASï¼šåŸºäºä¼˜åŒ–ä»£ç†çš„ç«¯åˆ°ç«¯ç¥ç»æ¶æ„æœç´¢",
      "authors": [
        "Bo Lyu",
        "Yu Cui",
        "Tuo Shi",
        "Ke Li"
      ],
      "abstract": "Neural architecture search (NAS) is a hard computationally expensive optimization problem with a discrete, vast, and spiky search space. One of the key research efforts dedicated to this space focuses on accelerating NAS via certain proxy evaluations of neural architectures. Different from the prevalent predictor-based methods using surrogate models and differentiable architecture search via supernetworks, we propose an optimization proxy to streamline the NAS as an end-to-end optimization framework, named OptiProxy-NAS. In particular, using a proxy representation, the NAS space is reformulated to be continuous, differentiable, and smooth. Thereby, any differentiable optimization method can be applied to the gradient-based search of the relaxed architecture parameters. Our comprehensive experiments on $12$ NAS tasks of $4$ search spaces across three different domains including computer vision, natural language processing, and resource-constrained NAS fully demonstrate the superior search results and efficiency. Further experiments on low-fidelity scenarios verify the flexibility.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OptiProxy-NASï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¼˜åŒ–ä»£ç† (optimization proxy) çš„ç«¯åˆ°ç«¯ç¥ç»æ¶æ„æœç´¢æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ Neural architecture search (NAS) ä¸­æœç´¢ç©ºé—´ç¦»æ•£ä¸”è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºé¢„æµ‹å™¨æˆ–è¶…ç½‘ç»œçš„æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä»£ç†è¡¨ç¤ºå°† NAS æœç´¢ç©ºé—´é‡æ–°è¡¨è¿°ä¸ºè¿ç»­ã€å¯å¾®ä¸”å¹³æ»‘çš„ç©ºé—´ã€‚è¿™ç§é‡æ„ä½¿å¾—ä»»ä½•å¯å¾®ä¼˜åŒ–æ–¹æ³•éƒ½èƒ½åº”ç”¨äºæ¾å¼›åçš„æ¶æ„å‚æ•°ï¼Œå®ç°åŸºäºæ¢¯åº¦çš„å¿«é€Ÿæœç´¢ã€‚å®éªŒåœ¨æ¶‰åŠè®¡ç®—æœºè§†è§‰ (computer vision)ã€è‡ªç„¶è¯­è¨€å¤„ç† (natural language processing) åŠèµ„æºå—é™ NAS çš„ 12 é¡¹ä»»åŠ¡ä¸Šå±•å¼€ï¼Œç»“æœæ˜¾ç¤º OptiProxy-NAS åœ¨æœç´¢ç²¾åº¦å’Œæ•ˆç‡ä¸Šå‡å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œåœ¨ä½ä¿çœŸåº¦åœºæ™¯ä¸‹çš„è¿›ä¸€æ­¥å®éªŒä¹Ÿå……åˆ†éªŒè¯äº†è¯¥æ¡†æ¶åœ¨ä¸åŒæœç´¢ä»»åŠ¡ä¸­çš„çµæ´»æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05656v1",
      "published_date": "2025-09-06 09:26:02 UTC",
      "updated_date": "2025-09-06 09:26:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:37.379123+00:00"
    },
    {
      "arxiv_id": "2509.05651v1",
      "title": "Orchestrator: Active Inference for Multi-Agent Systems in Long-Horizon Tasks",
      "title_zh": "Orchestratorï¼šé¢å‘é•¿ç¨‹ä»»åŠ¡çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸»åŠ¨æ¨ç†",
      "authors": [
        "Lukas Beckenbauer",
        "Johannes-Lucas Loewe",
        "Ge Zheng",
        "Alexandra Brintrup"
      ],
      "abstract": "Complex, non-linear tasks challenge LLM-enhanced multi-agent systems (MAS) due to partial observability and suboptimal coordination. We propose Orchestrator, a novel MAS framework that leverages attention-inspired self-emergent coordination and reflective benchmarking to optimize global task performance. Orchestrator introduces a monitoring mechanism to track agent-environment dynamics, using active inference benchmarks to optimize system behavior. By tracking agent-to-agent and agent-to-environment interaction, Orchestrator mitigates the effects of partial observability and enables agents to approximate global task solutions more efficiently. We evaluate the framework on a series of maze puzzles of increasing complexity, demonstrating its effectiveness in enhancing coordination and performance in dynamic, non-linear environments with long-horizon objectives.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Orchestratorï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³LLMå¢å¼ºå‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(MAS)åœ¨å¤„ç†é•¿æ—¶ç¨‹(long-horizon)å’Œéçº¿æ€§ä»»åŠ¡æ—¶é¢ä¸´çš„éƒ¨åˆ†å¯è§‚æµ‹æ€§(partial observability)åŠåè°ƒæ€§ä¸è¶³é—®é¢˜çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å—æ³¨æ„åŠ›æœºåˆ¶å¯å‘çš„ä¸€è‡´æ€§è‡ªå‘æ¶Œç°(self-emergent coordination)å’Œåæ€æ€§åŸºå‡†æµ‹è¯•(reflective benchmarking)ï¼Œä»¥ä¼˜åŒ–ç³»ç»Ÿçš„å…¨å±€ä»»åŠ¡è¡¨ç°ã€‚Orchestratoré€šè¿‡å¼•å…¥ç›‘æ§æœºåˆ¶æ¥è¿½è¸ªæ™ºèƒ½ä½“ä¸ç¯å¢ƒä¹‹é—´çš„åŠ¨æ€å…³ç³»ï¼Œå¹¶åˆ©ç”¨ä¸»åŠ¨æ¨ç†(active inference)åŸºå‡†æ¥æŒç»­ä¼˜åŒ–ç³»ç»Ÿè¡Œä¸ºã€‚é€šè¿‡å¯¹æ™ºèƒ½ä½“é—´åŠæ™ºèƒ½ä½“ä¸ç¯å¢ƒäº’åŠ¨çš„è¿½è¸ªï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆç¼“è§£äº†éƒ¨åˆ†å¯è§‚æµ‹æ€§çš„è´Ÿé¢å½±å“ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°é€¼è¿‘å…¨å±€ä»»åŠ¡æ–¹æ¡ˆã€‚ç ”ç©¶åœ¨ä¸€ç³»åˆ—å¤æ‚åº¦é€’å¢çš„è¿·å®«è°œé¢˜ä¸ŠéªŒè¯äº†è¯¥æ¡†æ¶ï¼Œè¯æ˜äº†å…¶åœ¨åŠ¨æ€ã€éçº¿æ€§ç¯å¢ƒä¸­å¢å¼ºå¤šæ™ºèƒ½ä½“åè°ƒæ€§å¹¶æå‡é•¿æ—¶ç¨‹ä»»åŠ¡æ€§èƒ½çš„æ˜¾è‘—æ•ˆæœã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05651v1",
      "published_date": "2025-09-06 09:03:36 UTC",
      "updated_date": "2025-09-06 09:03:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:48.676817+00:00"
    },
    {
      "arxiv_id": "2509.05630v1",
      "title": "Self-supervised Learning for Hyperspectral Images of Trees",
      "title_zh": "é¢å‘æ ‘æœ¨é«˜å…‰è°±å›¾åƒçš„è‡ªç›‘ç£å­¦ä¹ ",
      "authors": [
        "Moqsadur Rahman",
        "Saurav Kumar",
        "Santosh S. Palmate",
        "M. Shahriar Hossain"
      ],
      "abstract": "Aerial remote sensing using multispectral and RGB imagers has provided a critical impetus to precision agriculture. Analysis of the hyperspectral images with limited or no labels is challenging. This paper focuses on self-supervised learning to create neural network embeddings reflecting vegetation properties of trees from aerial hyperspectral images of crop fields. Experimental results demonstrate that a constructed tree representation, using a vegetation property-related embedding space, performs better in downstream machine learning tasks compared to the direct use of hyperspectral vegetation properties as tree representations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç²¾å‡†å†œä¸šï¼ˆPrecision Agricultureï¼‰ä¸­é«˜å…‰è°±å›¾åƒï¼ˆHyperspectral Imagesï¼‰æ ‡æ³¨å—é™çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-supervised Learningï¼‰æ„å»ºæ ‘æœ¨ç‰¹å¾è¡¨ç¤ºçš„æ–¹æ³•ã€‚ç ”ç©¶æ ¸å¿ƒåœ¨äºé€šè¿‡ç¥ç»ç½‘ç»œåµŒå…¥ï¼ˆNeural Network Embeddingsï¼‰ä»èˆªç©ºé«˜å…‰è°±æ•°æ®ä¸­æå–èƒ½å¤Ÿåæ˜ æ ‘æœ¨æ¤è¢«å±æ€§çš„ç©ºé—´ç‰¹å¾ã€‚å®éªŒå¯¹æ¯”è¯æ˜ï¼Œè¿™ç§åŸºäºåµŒå…¥ç©ºé—´æ„å»ºçš„æ ‘æœ¨è¡¨ç¤ºåœ¨ä¸‹æ¸¸æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºç›´æ¥åˆ©ç”¨é«˜å…‰è°±æ¤è¢«å±æ€§çš„ä¼ ç»Ÿæ–¹æ³•ã€‚è¯¥æˆæœå±•ç¤ºäº†è‡ªç›‘ç£å­¦ä¹ åœ¨å¤„ç†æ ‡æ³¨ç¼ºå¤±çš„å†œä¸šé¥æ„Ÿæ•°æ®æ—¶ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰æ¤è¢«å±æ€§å¹¶æå‡åˆ†ææ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05630v1",
      "published_date": "2025-09-06 07:25:39 UTC",
      "updated_date": "2025-09-06 07:25:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:58:52.966984+00:00"
    },
    {
      "arxiv_id": "2509.05617v1",
      "title": "From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics",
      "title_zh": "ä»å–œæ‚¦åˆ°ææƒ§ï¼šæµè¡Œæ­Œæ›²æ­Œè¯æƒ…æ„Ÿä¼°è®¡åŸºå‡†",
      "authors": [
        "Shay Dahary",
        "Avi Edana",
        "Alexander Apartsin",
        "Yehudit Aperstein"
      ],
      "abstract": "The emotional content of song lyrics plays a pivotal role in shaping listener experiences and influencing musical preferences. This paper investigates the task of multi-label emotional attribution of song lyrics by predicting six emotional intensity scores corresponding to six fundamental emotions. A manually labeled dataset is constructed using a mean opinion score (MOS) approach, which aggregates annotations from multiple human raters to ensure reliable ground-truth labels. Leveraging this dataset, we conduct a comprehensive evaluation of several publicly available large language models (LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model specifically for predicting multi-label emotion scores. Experimental results reveal the relative strengths and limitations of zero-shot and fine-tuned models in capturing the nuanced emotional content of lyrics. Our findings highlight the potential of LLMs for emotion recognition in creative texts, providing insights into model selection strategies for emotion-based music information retrieval applications. The labeled dataset is available at https://github.com/LLM-HITCS25S/LyricsEmotionAttribution.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æµè¡Œæ­Œæ›²æ­Œè¯çš„å¤šæ ‡ç­¾æƒ…æ„Ÿå½’å› (multi-label emotional attribution)ä»»åŠ¡ï¼Œæ—¨åœ¨é€šè¿‡é¢„æµ‹å…­ç§åŸºæœ¬æƒ…æ„Ÿçš„å¼ºåº¦å¾—åˆ†æ¥é‡åŒ–æ­Œè¯ä¸­çš„æƒ…æ„Ÿå†…å®¹ã€‚ä½œè€…é‡‡ç”¨å¹³å‡æ„è§å¾—åˆ†(Mean Opinion Score, MOS)æ–¹æ³•ï¼Œé€šè¿‡èšåˆå¤šåäººç±»è¯„åˆ†è€…çš„æ ‡æ³¨ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«å¯é çœŸå€¼æ ‡ç­¾çš„æ‰‹å·¥æ ‡æ³¨æ•°æ®é›†ã€‚åŸºäºè¯¥æ•°æ®é›†ï¼Œç ”ç©¶å¯¹å¤šä¸ªå…¬å¼€çš„å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨é›¶æ ·æœ¬(zero-shot)åœºæ™¯ä¸‹çš„è¡¨ç°è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶ä¸“é—¨å¾®è°ƒ(fine-tune)äº†ä¸€ä¸ªåŸºäºBERTçš„æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿå¾—åˆ†é¢„æµ‹ã€‚å®éªŒç»“æœæ­ç¤ºäº†é›¶æ ·æœ¬æ¨¡å‹ä¸å¾®è°ƒæ¨¡å‹åœ¨æ•æ‰æ­Œè¯ç»†å¾®æƒ…æ„Ÿå†…å®¹æ–¹é¢çš„å„è‡ªä¼˜åŠ¿ä¸å±€é™æ€§ã€‚ç ”ç©¶ç»“æœä¸ä»…å±•ç¤ºäº†LLMsåœ¨åˆ›æ„æ–‡æœ¬æƒ…æ„Ÿè¯†åˆ«ä¸­çš„æ½œåŠ›ï¼Œè¿˜ä¸ºåŸºäºæƒ…æ„Ÿçš„éŸ³ä¹ä¿¡æ¯æ£€ç´¢(music information retrieval)åº”ç”¨æä¾›äº†æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼Œå¹¶å…¬å¼€äº†ç›¸å…³ç ”ç©¶æ•°æ®é›†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05617v1",
      "published_date": "2025-09-06 06:28:28 UTC",
      "updated_date": "2025-09-06 06:28:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:59:26.691601+00:00"
    },
    {
      "arxiv_id": "2509.05615v1",
      "title": "Causal Debiasing Medical Multimodal Representation Learning with Missing Modalities",
      "title_zh": "æ¨¡æ€ç¼ºå¤±ä¸‹çš„åŒ»å­¦å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ å› æœå»å",
      "authors": [
        "Xiaoguang Zhu",
        "Lianlong Sun",
        "Yang Liu",
        "Pengyi Jiang",
        "Uma Srivatsa",
        "Nipavan Chiamvimonvat",
        "Vladimir Filkov"
      ],
      "abstract": "Medical multimodal representation learning aims to integrate heterogeneous clinical data into unified patient representations to support predictive modeling, which remains an essential yet challenging task in the medical data mining community. However, real-world medical datasets often suffer from missing modalities due to cost, protocol, or patient-specific constraints. Existing methods primarily address this issue by learning from the available observations in either the raw data space or feature space, but typically neglect the underlying bias introduced by the data acquisition process itself. In this work, we identify two types of biases that hinder model generalization: missingness bias, which results from non-random patterns in modality availability, and distribution bias, which arises from latent confounders that influence both observed features and outcomes. To address these challenges, we perform a structural causal analysis of the data-generating process and propose a unified framework that is compatible with existing direct prediction-based multimodal learning methods. Our method consists of two key components: (1) a missingness deconfounding module that approximates causal intervention based on backdoor adjustment and (2) a dual-branch neural network that explicitly disentangles causal features from spurious correlations. We evaluated our method in real-world public and in-hospital datasets, demonstrating its effectiveness and causal insights.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ (Medical multimodal representation learning)ä¸­å› æˆæœ¬ã€åè®®ç­‰é™åˆ¶å¯¼è‡´çš„æ¨¡æ€ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å¤„ç†ç¼ºå¤±æ¨¡æ€çš„å› æœå»åæ¡†æ¶ã€‚ä½œè€…è¯†åˆ«äº†å½±å“æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„ä¸¤ç§æ ¸å¿ƒåè§ï¼šç”±æ¨¡æ€å¯ç”¨æ€§çš„ééšæœºæ¨¡å¼å¼•èµ·çš„ç¼ºå¤±åè§(Missingness bias)ï¼Œä»¥åŠç”±å½±å“è§‚æµ‹ç‰¹å¾ä¸ç»“æœçš„æ½œä¼æ··æ·†å› å­å¯¼è‡´çš„åˆ†å¸ƒåè§(Distribution bias)ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹æ•°æ®ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œç»“æ„å› æœåˆ†æ(Structural causal analysis)ï¼Œå¼•å…¥äº†åŸºäºåé—¨è°ƒæ•´(Backdoor adjustment)çš„ç¼ºå¤±å»æ··æ·†æ¨¡å—(Missingness deconfounding module)ï¼Œå¹¶åˆ©ç”¨åŒæ”¯è·¯ç¥ç»ç½‘ç»œ(Dual-branch neural network)å°†å› æœç‰¹å¾ä¸è™šå‡ç›¸å…³æ€§è¿›è¡Œæ˜¾å¼è§£è€¦ã€‚åœ¨çœŸå®ä¸–ç•Œå…¬å…±æ•°æ®é›†å’Œé™¢å†…æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨åº”å¯¹æ¨¡æ€ç¼ºå¤±æ—¶å…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºåŒ»ç–—æ•°æ®æŒ–æ˜æä¾›äº†é‡è¦çš„å› æœè§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE TKDE",
      "pdf_url": "https://arxiv.org/pdf/2509.05615v1",
      "published_date": "2025-09-06 06:27:10 UTC",
      "updated_date": "2025-09-06 06:27:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:59:38.106119+00:00"
    },
    {
      "arxiv_id": "2509.05614v1",
      "title": "SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning",
      "title_zh": "SpecPrune-VLAï¼šåŸºäºåŠ¨ä½œæ„ŸçŸ¥è‡ªæŠ•æœºå‰ªæçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åŠ é€Ÿæ–¹æ³•",
      "authors": [
        "Hanzhen Wang",
        "Jiaming Xu",
        "Jiayi Pan",
        "Yongkang Zhou",
        "Guohao Dai"
      ],
      "abstract": "Pruning accelerates compute-bound models by reducing computation. Recently applied to Vision-Language-Action (VLA) models, existing methods prune tokens using only local info from current action, ignoring global context from prior actions, causing >20% success rate drop and limited speedup. We observe high similarity across consecutive actions and propose leveraging both local (current) and global (past) info for smarter token selection. We introduce SpecPrune-VLA, a training-free method with two-level pruning and heuristic control: (1) Static pruning at action level: uses global history and local context to reduce visual tokens per action; (2) Dynamic pruning at layer level: prunes tokens per layer based on layer-specific importance; (3) Lightweight action-aware controller: classifies actions as coarse/fine-grained (by speed), adjusting pruning aggressiveness since fine-grained actions are pruning-sensitive. Experiments on LIBERO show SpecPrune-VLA achieves 1.46 times speedup on NVIDIA A800 and 1.57 times on NVIDIA GeForce RTX 3090 vs. OpenVLA-OFT, with negligible success rate loss.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Vision-Language-Action (VLA) æ¨¡å‹åœ¨å‰ªæåŠ é€Ÿè¿‡ç¨‹ä¸­å› å¿½è§†å†å²åŠ¨ä½œçš„å…¨å±€èƒŒæ™¯è€Œå¯¼è‡´ä»»åŠ¡æˆåŠŸç‡å¤§å¹…ä¸‹é™çš„é—®é¢˜ã€‚ä½œè€…è§‚å¯Ÿåˆ°è¿ç»­åŠ¨ä½œä¹‹é—´å­˜åœ¨é«˜åº¦ç›¸ä¼¼æ€§ï¼Œå¹¶æ®æ­¤æå‡ºäº† SpecPrune-VLAï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒä¸”åŒæ—¶åˆ©ç”¨å±€éƒ¨ä¸å…¨å±€ä¿¡æ¯è¿›è¡Œæ™ºèƒ½ Token é€‰æ‹©çš„åŠ é€Ÿæ–¹æ³•ã€‚è¯¥æ–¹æ³•åŒ…å«åŠ¨ä½œå±‚é¢çš„é™æ€å‰ªæï¼Œé€šè¿‡ç»“åˆå†å²å…¨å±€ä¿¡æ¯å’Œå½“å‰å±€éƒ¨ä¸Šä¸‹æ–‡æ¥å‡å°‘è§†è§‰ Tokenï¼Œå¹¶å¼•å…¥å±‚çº§å±‚é¢çš„åŠ¨æ€å‰ªæï¼Œæ ¹æ®æ¯ä¸€å±‚çš„å…·ä½“é‡è¦æ€§å®æ—¶è¿‡æ»¤ Tokenã€‚æ­¤å¤–ï¼Œæ¡†æ¶é›†æˆäº†ä¸€ä¸ªè½»é‡çº§çš„ Action-Aware Controllerï¼Œèƒ½æ ¹æ®åŠ¨ä½œçš„ç²—ç»†ç²’åº¦è‡ªåŠ¨è°ƒæ•´å‰ªæå¼ºåº¦ï¼Œä»¥ä¿æŠ¤å¯¹å‰ªææ•æ„Ÿçš„ç²¾ç»†æ“ä½œã€‚åœ¨ LIBERO åŸºå‡†æµ‹è¯•ä¸­ï¼ŒSpecPrune-VLA åœ¨ NVIDIA A800 å’Œ RTX 3090 ä¸Šåˆ†åˆ«å®ç°äº† 1.46 å€å’Œ 1.57 å€çš„æ¨ç†åŠ é€Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ OpenVLA-OFT ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—æå‡æ¨¡å‹è¿è¡Œé€Ÿåº¦çš„åŒæ—¶ï¼ŒæˆåŠŸç‡æŸå¤±å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8pages, 10 figures,",
      "pdf_url": "https://arxiv.org/pdf/2509.05614v1",
      "published_date": "2025-09-06 06:22:19 UTC",
      "updated_date": "2025-09-06 06:22:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:59:13.493282+00:00"
    },
    {
      "arxiv_id": "2509.05608v1",
      "title": "Cross-Service Threat Intelligence in LLM Services using Privacy-Preserving Fingerprints",
      "title_zh": "åŸºäºéšç§ä¿æŠ¤æŒ‡çº¹çš„ LLM æœåŠ¡è·¨æœåŠ¡å¨èƒæƒ…æŠ¥",
      "authors": [
        "Waris Gill",
        "Natalie Isak",
        "Matthew Dressman"
      ],
      "abstract": "The widespread deployment of LLMs across enterprise services has created a critical security blind spot. Organizations operate multiple LLM services handling billions of queries daily, yet regulatory compliance boundaries prevent these services from sharing threat intelligence about prompt injection attacks, the top security risk for LLMs. When an attack is detected in one service, the same threat may persist undetected in others for months, as privacy regulations prohibit sharing user prompts across compliance boundaries.\n  We present BinaryShield, the first privacy-preserving threat intelligence system that enables secure sharing of attack fingerprints across compliance boundaries. BinaryShield transforms suspicious prompts through a unique pipeline combining PII redaction, semantic embedding, binary quantization, and randomized response mechanism to potentially generate non-invertible fingerprints that preserve attack patterns while providing privacy. Our evaluations demonstrate that BinaryShield achieves an F1-score of 0.94, significantly outperforming SimHash (0.77), the privacy-preserving baseline, while achieving 64x storage reduction and 38x faster similarity search compared to dense embeddings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ä¸šLLMæœåŠ¡ä¸­å› åˆè§„æ€§é™åˆ¶æ— æ³•å…±äº«å¨èƒæƒ…æŠ¥çš„å®‰å…¨ç—›ç‚¹ï¼Œæå‡ºäº†BinaryShieldç³»ç»Ÿã€‚ä½œä¸ºé¦–ä¸ªæ”¯æŒè·¨åˆè§„è¾¹ç•Œå…±äº«æ”»å‡»æŒ‡çº¹çš„éšç§ä¿æŠ¤å¨èƒæƒ…æŠ¥ç³»ç»Ÿï¼ŒBinaryShieldæ—¨åœ¨æœ‰æ•ˆåº”å¯¹prompt injection attacksè¿™ä¸€æ ¸å¿ƒå®‰å…¨é£é™©ã€‚è¯¥ç³»ç»Ÿé€šè¿‡é›†æˆPII redactionã€semantic embeddingã€binary quantizationå’Œéšæœºå“åº”æœºåˆ¶ï¼Œå°†å¯ç–‘æç¤ºè½¬åŒ–ä¸ºä¸å¯é€†çš„æŒ‡çº¹ï¼Œåœ¨ä¸¥å®ˆéšç§è¾¹ç•Œçš„åŒæ—¶ç²¾å‡†ä¿ç•™æ”»å‡»æ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBinaryShieldè¾¾åˆ°äº†0.94çš„F1-scoreï¼Œæ€§èƒ½æ˜¾è‘—è¶…è¶Šäº†SimHashç­‰ä¼ ç»Ÿéšç§ä¿æŠ¤åŸºå‡†ã€‚æ­¤å¤–ï¼Œä¸dense embeddingsç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆå®ç°äº†64å€çš„å­˜å‚¨ç¼©å‡å’Œ38å€çš„æ£€ç´¢åŠ é€Ÿï¼Œä¸ºè·¨æœåŠ¡çš„å¤§è§„æ¨¡å®‰å…¨åä½œæä¾›äº†é«˜æ•ˆä¸”åˆè§„çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05608v1",
      "published_date": "2025-09-06 05:57:20 UTC",
      "updated_date": "2025-09-06 05:57:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:59:19.391759+00:00"
    },
    {
      "arxiv_id": "2509.05605v1",
      "title": "Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation",
      "title_zh": "Icon$^{2}$ï¼šåˆ©ç”¨å†…åœ¨è°ƒèŠ‚çš„è‡ªåˆæˆåå¥½æ•°æ®è¿›è¡Œå¤§è¯­è¨€æ¨¡å‹å¯¹é½",
      "authors": [
        "Qiyuan Chen",
        "Hongsen Huang",
        "Qian Shao",
        "Jiahe Chen",
        "Jintai Chen",
        "Hongxia Xu",
        "Renjie Hua",
        "Ren Chuan",
        "Jian Wu"
      ],
      "abstract": "Large Language Models (LLMs) require high quality preference datasets to align with human preferences. However, conventional methods for constructing such datasets face significant challenges: reliance on pre-collected instructions often leads to distribution mismatches with target models, while the need for sampling multiple stochastic responses introduces substantial computational overhead. In this work, we explore a paradigm shift by leveraging inherent regulation of LLMs' representation space for efficient and tailored preference dataset construction, named Icon$^{2}$. Specifically, it first extracts layer-wise direction vectors to encode sophisticated human preferences and then uses these vectors to filter self-synthesized instructions based on their inherent consistency. During decoding, bidirectional inherent control is applied to steer token representations, enabling the precise generation of response pairs with clear alignment distinctions. Experimental results demonstrate significant improvements in both alignment and efficiency. Llama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on AlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by up to 48.1%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Icon$^{2}$æ¡†æ¶ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¡¨å¾ç©ºé—´çš„Inherent Regulationæ¥å®ç°é«˜æ•ˆä¸”å®šåˆ¶åŒ–çš„åå¥½æ•°æ®é›†æ„å»ºã€‚é’ˆå¯¹ä¼ ç»Ÿå¯¹é½æ–¹æ³•å­˜åœ¨çš„åˆ†å¸ƒä¸åŒ¹é…å’Œè®¡ç®—å¼€é”€å·¨å¤§ç­‰æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶é¦–å…ˆæå–Layer-wise direction vectorsæ¥ç¼–ç å¤æ‚çš„äººç±»åå¥½ï¼Œå¹¶åŸºäºInherent consistencyå¯¹è‡ªåˆæˆæŒ‡ä»¤è¿›è¡Œè¿‡æ»¤ã€‚åœ¨è§£ç è¿‡ç¨‹ä¸­ï¼ŒIcon$^{2}$é€šè¿‡Bidirectional inherent controlå¼•å¯¼Token representationsï¼Œä»è€Œç²¾å‡†ç”Ÿæˆå…·æœ‰æ˜ç¡®å¯¹é½å·®å¼‚çš„å›å¤å¯¹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLlama3-8Bå’ŒQwen2-7Båœ¨AlpacaEval 2.0å’ŒArena-Hardä¸Šçš„å¹³å‡èƒœç‡åˆ†åˆ«æå‡äº†13.89%å’Œ13.45%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—æå‡å¯¹é½æ€§èƒ½çš„åŒæ—¶ï¼ŒæˆåŠŸå°†è®¡ç®—æˆæœ¬é™ä½äº†48.1%ï¼Œä¸ºå¤§æ¨¡å‹çš„åå¥½å¯¹é½æä¾›äº†ä¸€ç§å…¼å…·æ•ˆç‡ä¸æ€§èƒ½çš„æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Main",
      "pdf_url": "https://arxiv.org/pdf/2509.05605v1",
      "published_date": "2025-09-06 05:38:47 UTC",
      "updated_date": "2025-09-06 05:38:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:59:30.585282+00:00"
    },
    {
      "arxiv_id": "2509.05604v1",
      "title": "Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization",
      "title_zh": "è¯­è¨€å¼•å¯¼çš„é€’å½’å¼æ—¶ç©ºå›¾å»ºæ¨¡è§†é¢‘æ‘˜è¦",
      "authors": [
        "Jungin Park",
        "Jiyoung Lee",
        "Kwanghoon Sohn"
      ],
      "abstract": "Video summarization aims to select keyframes that are visually diverse and can represent the whole story of a given video. Previous approaches have focused on global interlinkability between frames in a video by temporal modeling. However, fine-grained visual entities, such as objects, are also highly related to the main content of the video. Moreover, language-guided video summarization, which has recently been studied, requires a comprehensive linguistic understanding of complex real-world videos. To consider how all the objects are semantically related to each other, this paper regards video summarization as a language-guided spatiotemporal graph modeling problem. We present recursive spatiotemporal graph networks, called VideoGraph, which formulate the objects and frames as nodes of the spatial and temporal graphs, respectively. The nodes in each graph are connected and aggregated with graph edges, representing the semantic relationships between the nodes. To prevent the edges from being configured with visual similarity, we incorporate language queries derived from the video into the graph node representations, enabling them to contain semantic knowledge. In addition, we adopt a recursive strategy to refine initial graphs and correctly classify each frame node as a keyframe. In our experiments, VideoGraph achieves state-of-the-art performance on several benchmarks for generic and query-focused video summarization in both supervised and unsupervised manners. The code is available at https://github.com/park-jungin/videograph.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†é¢‘æ‘˜è¦(Video Summarization)ä»»åŠ¡ä¸­ç»†ç²’åº¦è§†è§‰å®ä½“å»ºæ¨¡ä¸è¶³ä»¥åŠè¯­è¨€å¯¼å‘ç†è§£ä¸å……åˆ†çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºVideoGraphçš„é€’å½’æ—¶ç©ºå›¾ç½‘ç»œæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†è§†é¢‘æ‘˜è¦å»ºæ¨¡ä¸ºè¯­è¨€å¯¼å‘çš„æ—¶ç©ºå›¾å»ºæ¨¡é—®é¢˜ï¼Œåˆ†åˆ«å°†ç‰©ä½“å’Œå¸§å®šä¹‰ä¸ºç©ºé—´å›¾å’Œæ—¶é—´å›¾çš„èŠ‚ç‚¹ï¼Œå¹¶é€šè¿‡å›¾è¾¹æ•æ‰å…¶é—´çš„è¯­ä¹‰è”ç³»ã€‚ä¸ºäº†è¶…è¶Šç®€å•çš„è§†è§‰ç›¸ä¼¼æ€§å»ºæ¨¡ï¼Œç ”ç©¶å°†æºè‡ªè§†é¢‘çš„è¯­è¨€æŸ¥è¯¢(Language Queries)èå…¥èŠ‚ç‚¹è¡¨ç¤ºä¸­ï¼Œä½¿å›¾èŠ‚ç‚¹è•´å«ä¸°å¯Œçš„è¯­ä¹‰çŸ¥è¯†ã€‚æ­¤å¤–ï¼ŒVideoGraphé‡‡ç”¨äº†é€’å½’ç­–ç•¥(Recursive Strategy)æ¥ä¸æ–­ç»†åŒ–åˆå§‹å›¾ç»“æ„ï¼Œä»è€Œå®ç°å¯¹å…³é”®å¸§çš„ç²¾ç¡®åˆ†ç±»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVideoGraphåœ¨é€šç”¨å’ŒæŸ¥è¯¢èšç„¦çš„è§†é¢‘æ‘˜è¦åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ— è®ºæ˜¯åœ¨ç›‘ç£è¿˜æ˜¯æ— ç›‘ç£æ¨¡å¼ä¸‹å‡è¾¾åˆ°äº†State-of-the-artæ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IJCV, 29 pages, 14 figures, 11 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.05604v1",
      "published_date": "2025-09-06 05:37:31 UTC",
      "updated_date": "2025-09-06 05:37:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:59:31.285261+00:00"
    },
    {
      "arxiv_id": "2509.07006v1",
      "title": "ArGen: Auto-Regulation of Generative AI via GRPO and Policy-as-Code",
      "title_zh": "ArGenï¼šåŸºäº GRPO ä¸ç­–ç•¥å³ä»£ç çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½è‡ªåŠ¨ç›‘ç®¡",
      "authors": [
        "Kapil Madan"
      ],
      "abstract": "This paper introduces ArGen (Auto-Regulation of Generative AI systems), a framework for aligning Large Language Models (LLMs) with complex sets of configurable, machine-readable rules spanning ethical principles, operational safety protocols, and regulatory compliance standards. Moving beyond just preference-based alignment, ArGen is designed to ensure LLMs adhere to these multifaceted policies through a novel synthesis of principle-based automated reward scoring, Group Relative Policy Optimisation (GRPO), and an Open Policy Agent (OPA) inspired governance layer. This approach provides the technical foundation for achieving and demonstrating compliance with diverse and nuanced governance requirements. To showcase the framework's capability to operationalize a deeply nuanced and culturally-specific value system, we present an in-depth case study: the development of a medical AI assistant guided by principles from Dharmic ethics (such as Ahimsa and Dharma), as derived from texts like the Bhagavad Gita. This challenging application demonstrates ArGen's adaptability, achieving a 70.9% improvement in domain-scope adherence over the baseline. Through our open-source repository, we show that ArGen's methodology offers a path to 'Governable Al' systems that are technically proficient, ethically robust, and verifiably compliant for safe deployment in diverse global contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ArGenï¼ˆAuto-Regulation of Generative AI systemsï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨ä½¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿéµå¾ªåŒ…æ‹¬ä¼¦ç†åŸåˆ™ã€æ“ä½œå®‰å…¨åè®®å’Œç›‘ç®¡åˆè§„æ ‡å‡†åœ¨å†…çš„å¤æ‚ä¸”å¯é…ç½®çš„æœºå™¨å¯è¯»è§„åˆ™ã€‚è¯¥æ¡†æ¶è¶…è¶Šäº†ä¼ ç»Ÿçš„åŸºäºåå¥½çš„å¯¹é½æ–¹å¼ï¼Œé€šè¿‡èåˆåŸºäºåŸåˆ™çš„è‡ªåŠ¨å¥–åŠ±è¯„åˆ†ã€ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGroup Relative Policy Optimisation, GRPOï¼‰ä»¥åŠå— Open Policy Agentï¼ˆOPAï¼‰å¯å‘çš„æ²»ç†å±‚ï¼ˆPolicy-as-Codeï¼‰ï¼Œç¡®ä¿æ¨¡å‹ä¸¥æ ¼éµå®ˆå¤šæ–¹é¢çš„æ”¿ç­–è¦æ±‚ã€‚è¿™ç§æ–¹æ³•ä¸ºå®ç°å¹¶è¯æ˜æ¨¡å‹ç¬¦åˆå¤šæ ·ä¸”ç»†è‡´çš„æ²»ç†è¦æ±‚æä¾›äº†æŠ€æœ¯åŸºç¡€ã€‚ä¸ºäº†éªŒè¯å…¶æ“ä½œå¤æ‚ä¸”å…·æœ‰æ–‡åŒ–ç‰¹å®šä»·å€¼ä½“ç³»çš„èƒ½åŠ›ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªä»¥ Dharmic ethicsï¼ˆå¦‚ Ahimsa å’Œ Dharmaï¼‰ä¸ºæŒ‡å¯¼åŸåˆ™çš„åŒ»ç–— AI åŠ©æ‰‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒArGen åœ¨é¢†åŸŸèŒƒå›´éµå¾ªåº¦æ–¹é¢æ¯”åŸºçº¿æ¨¡å‹æé«˜äº† 70.9%ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†æå…·æŒ‘æˆ˜æ€§çš„åº”ç”¨åœºæ™¯æ—¶çš„å“è¶Šé€‚åº”æ€§ã€‚é€šè¿‡å¼€æºè¯¥æ¡†æ¶ï¼Œç ”ç©¶å±•ç¤ºäº† ArGen ä¸ºæ„å»ºæŠ€æœ¯ç²¾æ¹›ã€ä¼¦ç†ç¨³å¥ä¸”å¯éªŒè¯åˆè§„çš„â€œå¯æ²»ç† AIâ€ï¼ˆGovernable AIï¼‰ç³»ç»Ÿæä¾›äº†ä¸€æ¡å¯è¡Œè·¯å¾„ï¼Œæœ‰åŠ©äºå®ç°åœ¨å¤šæ ·åŒ–å…¨çƒèƒŒæ™¯ä¸‹çš„å®‰å…¨éƒ¨ç½²ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "53 pages, 7 figures, 8 tables. Open-source implementation available at: https://github.com/Principled-Evolution/argen-demo. Work explores the integration of policy-as-code for AI alignment, with a case study in culturally-nuanced, ethical AI using Dharmic principles",
      "pdf_url": "https://arxiv.org/pdf/2509.07006v1",
      "published_date": "2025-09-06 04:33:16 UTC",
      "updated_date": "2025-09-06 04:33:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:59:40.885067+00:00"
    },
    {
      "arxiv_id": "2509.05585v1",
      "title": "Natural Language-Programming Language Software Traceability Link Recovery Needs More than Textual Similarity",
      "title_zh": "è‡ªç„¶è¯­è¨€ä¸ç¼–ç¨‹è¯­è¨€è½¯ä»¶è¿½æº¯å…³ç³»æ¢å¤ï¼šä»…å‡­æ–‡æœ¬ç›¸ä¼¼åº¦æ˜¯ä¸å¤Ÿçš„",
      "authors": [
        "Zhiyuan Zou",
        "Bangchao Wang",
        "Peng Liang",
        "Tingting Bi",
        "Huan Jin"
      ],
      "abstract": "In the field of software traceability link recovery (TLR), textual similarity has long been regarded as the core criterion. However, in tasks involving natural language and programming language (NL-PL) artifacts, relying solely on textual similarity is limited by their semantic gap. To this end, we conducted a large-scale empirical evaluation across various types of TLR tasks, revealing the limitations of textual similarity in NL-PL scenarios. To address these limitations, we propose an approach that incorporates multiple domain-specific auxiliary strategies, identified through empirical analysis, into two models: the Heterogeneous Graph Transformer (HGT) via edge types and the prompt-based Gemini 2.5 Pro via additional input information. We then evaluated our approach using the widely studied requirements-to-code TLR task, a representative case of NL-PL TLR. Experimental results show that both the multi-strategy HGT and Gemini 2.5 Pro models outperformed their original counterparts without strategy integration. Furthermore, compared to the current state-of-the-art method HGNNLink, the multi-strategy HGT and Gemini 2.5 Pro models achieved average F1-score improvements of 3.68% and 8.84%, respectively, across twelve open-source projects, demonstrating the effectiveness of multi-strategy integration in enhancing overall model performance for the requirements-code TLR task.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½¯ä»¶å¯è¿½æº¯æ€§é“¾æ¥æ¢å¤ (Traceability Link Recovery, TLR) ä¸­ä»…ä¾èµ–æ–‡æœ¬ç›¸ä¼¼åº¦å¯¼è‡´çš„å±€é™æ€§ï¼Œæ·±å…¥æ¢è®¨äº†è‡ªç„¶è¯­è¨€ä¸ç¼–ç¨‹è¯­è¨€ (NL-PL) æ„ä»¶é—´çš„è¯­ä¹‰é¸¿æ²Ÿé—®é¢˜ã€‚é€šè¿‡å¤§è§„æ¨¡å®è¯è¯„ä¼°ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ•´åˆå¤šç§é¢†åŸŸç‰¹å®šè¾…åŠ©ç­–ç•¥çš„æ–°æ–¹æ³•ï¼Œå¹¶å°†å…¶åº”ç”¨äºå¼‚æ„å›¾å˜æ¢å™¨ (Heterogeneous Graph Transformer, HGT) å’ŒåŸºäºæç¤ºè¯çš„ Gemini 2.5 Pro æ¨¡å‹ã€‚åœ¨â€œéœ€æ±‚åˆ°ä»£ç â€ (Requirements-to-Code) çš„å…¸å‹ TLR ä»»åŠ¡è¯„ä¼°ä¸­ï¼Œå¤šç­–ç•¥é›†æˆæ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸è¾ƒäºå½“å‰æœ€å…ˆè¿›çš„ HGNNLinkï¼Œå¤šç­–ç•¥ HGT å’Œ Gemini 2.5 Pro åœ¨åäºŒä¸ªå¼€æºé¡¹ç›®ä¸Šçš„å¹³å‡ F1-score åˆ†åˆ«æé«˜äº† 3.68% å’Œ 8.84%ã€‚è¯¥æˆæœè¯æ˜äº†åœ¨å¤„ç† NL-PL å¯è¿½æº¯æ€§ä»»åŠ¡æ—¶ï¼Œåˆ©ç”¨é¢†åŸŸç‰¹å®šçš„è¾…åŠ©ä¿¡æ¯è¶…è¶Šç®€å•æ–‡æœ¬ç›¸ä¼¼åº¦å¯¹æå‡æ¨¡å‹æ•ˆæœå…·æœ‰æ˜¾è‘—æ„ä¹‰ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "45 pages, 5 images, 11 tables, Manuscript submitted to a Journal (2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.05585v1",
      "published_date": "2025-09-06 04:15:09 UTC",
      "updated_date": "2025-09-06 04:15:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:00:21.489426+00:00"
    },
    {
      "arxiv_id": "2509.10540v1",
      "title": "EchoLeak: The First Real-World Zero-Click Prompt Injection Exploit in a Production LLM System",
      "title_zh": "EchoLeakï¼šç”Ÿäº§çº§å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿä¸­çš„é¦–ä¸ªçœŸå®ä¸–ç•Œé›¶ç‚¹å‡»æç¤ºè¯æ³¨å…¥æ¼æ´åˆ©ç”¨",
      "authors": [
        "Pavan Reddy",
        "Aditya Sanjay Gujral"
      ],
      "abstract": "Large language model (LLM) assistants are increasingly integrated into enterprise workflows, raising new security concerns as they bridge internal and external data sources. This paper presents an in-depth case study of EchoLeak (CVE-2025-32711), a zero-click prompt injection vulnerability in Microsoft 365 Copilot that enabled remote, unauthenticated data exfiltration via a single crafted email. By chaining multiple bypasses-evading Microsofts XPIA (Cross Prompt Injection Attempt) classifier, circumventing link redaction with reference-style Markdown, exploiting auto-fetched images, and abusing a Microsoft Teams proxy allowed by the content security policy-EchoLeak achieved full privilege escalation across LLM trust boundaries without user interaction. We analyze why existing defenses failed, and outline a set of engineering mitigations including prompt partitioning, enhanced input/output filtering, provenance-based access control, and strict content security policies. Beyond the specific exploit, we derive generalizable lessons for building secure AI copilots, emphasizing the principle of least privilege, defense-in-depth architectures, and continuous adversarial testing. Our findings establish prompt injection as a practical, high-severity vulnerability class in production AI systems and provide a blueprint for defending against future AI-native threats.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº† EchoLeak (CVE-2025-32711)ï¼Œè¿™æ˜¯é’ˆå¯¹ Microsoft 365 Copilot çš„é¦–ä¸ªçœŸå®ä¸–ç•Œã€é›¶ç‚¹å‡» (zero-click) æç¤ºè¯æ³¨å…¥æ¼æ´ï¼Œèƒ½å¤Ÿé€šè¿‡å•å°ç‰¹åˆ¶ç”µå­é‚®ä»¶å®ç°è¿œç¨‹ä¸”æœªç»æˆæƒçš„æ•°æ®å¤–æ³„ã€‚é€šè¿‡é“¾å¼ç»•è¿‡æŠ€æœ¯ï¼Œæ”»å‡»è€…æˆåŠŸè§„é¿äº† Microsoft çš„ XPIA åˆ†ç±»å™¨å’Œ Markdown é“¾æ¥è„±æ•æœºåˆ¶ï¼Œå¹¶åˆ©ç”¨è‡ªåŠ¨æŠ“å–å›¾åƒåŠ Teams ä»£ç†ç»•è¿‡äº†å†…å®¹å®‰å…¨ç­–ç•¥ (CSP)ï¼Œåœ¨æ— ç”¨æˆ·äº¤äº’çš„æƒ…å†µä¸‹å®ç°äº†å…¨æƒé™æå‡ã€‚è®ºæ–‡è¯¦ç»†åˆ†æäº†ç°æœ‰é˜²å¾¡å¤±æ•ˆçš„åŸå› ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—å·¥ç¨‹ç¼“è§£æªæ–½ï¼ŒåŒ…æ‹¬æç¤ºè¯åˆ†åŒº (prompt partitioning)ã€å¢å¼ºå‹è¿‡æ»¤å’ŒåŸºäºæ¥æºçš„è®¿é—®æ§åˆ¶ã€‚è¯¥å‘ç°ç¡®ç«‹äº†æç¤ºè¯æ³¨å…¥åœ¨ç”Ÿäº§çº§ AI ç³»ç»Ÿä¸­å±äºé«˜ä¸¥é‡æ€§æ¼æ´ç±»åˆ«ï¼Œå¹¶ä¸ºæ„å»ºéµå¾ªæœ€å°æƒé™åŸåˆ™å’Œæ·±åº¦é˜²å¾¡æ¶æ„çš„å®‰å…¨ AI åŠ©æ‰‹æä¾›äº†æŠ€æœ¯è“å›¾ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages content, 1 page references, 2 figures, Published at AAAI Fall Symposium Series 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.10540v1",
      "published_date": "2025-09-06 04:06:01 UTC",
      "updated_date": "2025-09-06 04:06:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:00:23.100126+00:00"
    },
    {
      "arxiv_id": "2509.05581v1",
      "title": "Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids",
      "title_zh": "ç©¿è¡£è¡Œèµ°ï¼šé¢å‘å—å¤–è§‚çº¦æŸç±»äººæœºå™¨äººçš„å¯¹æŠ—æ€§è¿åŠ¨å…ˆéªŒ",
      "authors": [
        "Arturo Flores Alvarez",
        "Fatemeh Zargarbashi",
        "Havel Liu",
        "Shiqi Wang",
        "Liam Edwards",
        "Jessica Anz",
        "Alex Xu",
        "Fan Shi",
        "Stelian Coros",
        "Dennis W. Hong"
      ],
      "abstract": "We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a custom-built humanoid robot designed for entertainment applications. Unlike traditional humanoids, entertainment robots present unique challenges due to aesthetic-driven design choices. Cosmo embodies these with a disproportionately large head (16% of total mass), limited sensing, and protective shells that considerably restrict movement. To address these challenges, we apply Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking movements while maintaining physical stability. We develop tailored domain randomization techniques and specialized reward structures to ensure safe sim-to-real, protecting valuable hardware components during deployment. Our experiments demonstrate that AMP generates stable standing and walking behaviors despite Cosmo's extreme mass distribution and movement constraints. These results establish a promising direction for robots that balance aesthetic appeal with functional performance, suggesting that learning-based methods can effectively adapt to aesthetic-driven design constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åä¸º Cosmo çš„å¨±ä¹ç”¨äººå½¢æœºå™¨äººï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„è¿åŠ¨æ§åˆ¶ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å› ç¾å­¦é©±åŠ¨è®¾è®¡å¸¦æ¥çš„ç‰©ç†é™åˆ¶ã€‚Cosmo å…·æœ‰ä¸æˆæ¯”ä¾‹çš„å·¨å¤§å¤´éƒ¨ï¼ˆå æ€»è´¨é‡ 16%ï¼‰ã€æœ‰é™çš„ä¼ æ„Ÿå™¨ä»¥åŠé™åˆ¶è¿åŠ¨èŒƒå›´çš„è£…é¥°å¤–å£³ï¼Œè¿™ç»™è¿åŠ¨ç¨³å®šæ€§å¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†å¯¹æŠ—è¿åŠ¨å…ˆéªŒ(Adversarial Motion Priors, AMP)æ¡†æ¶ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿåœ¨å—é™çš„ç‰©ç†æ¡ä»¶ä¸‹å­¦ä¹ è‡ªç„¶çš„è¿åŠ¨æ­¥æ€ã€‚é€šè¿‡å®šåˆ¶çš„é¢†åŸŸéšæœºåŒ–(Domain Randomization)æŠ€æœ¯å’Œä¸“é—¨çš„å¥–åŠ±ç»“æ„ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†å®‰å…¨çš„ä»¿çœŸåˆ°ç°å®(Sim-to-Real)è¿ç§»ï¼Œæœ‰æ•ˆä¿æŠ¤äº†ç¡¬ä»¶è®¾å¤‡ã€‚å®éªŒè¯æ˜ï¼ŒAMP èƒ½å¤Ÿå…‹æœæç«¯çš„è´¨é‡åˆ†å¸ƒå’Œæ´»åŠ¨ç©ºé—´çº¦æŸï¼Œç”Ÿæˆç¨³å®šçš„ç«™ç«‹å’Œè¡Œèµ°è¡Œä¸ºã€‚è¯¥ç ”ç©¶éªŒè¯äº†å­¦ä¹ é©±åŠ¨æ–¹æ³•åœ¨å¤„ç†å…¼å…·ç¾å­¦è¦æ±‚ä¸åŠŸèƒ½æ€§èƒ½çš„å¤æ‚æœºå™¨äººè®¾è®¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 11 figures, accepted at IEEE-RAS International Conference on Humanoid Robots (Humanoids) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.05581v1",
      "published_date": "2025-09-06 03:52:10 UTC",
      "updated_date": "2025-09-06 03:52:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:00:21.690665+00:00"
    },
    {
      "arxiv_id": "2509.05578v1",
      "title": "OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision",
      "title_zh": "OccVLAï¼šåŸºäºéšå¼ 3D å æ®ç›‘ç£çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹",
      "authors": [
        "Ruixun Liu",
        "Lingyu Kong",
        "Derun Li",
        "Hang Zhao"
      ],
      "abstract": "Multimodal large language models (MLLMs) have shown strong vision-language reasoning abilities but still lack robust 3D spatial understanding, which is critical for autonomous driving. This limitation stems from two key challenges: (1) the difficulty of constructing accessible yet effective 3D representations without expensive manual annotations, and (2) the loss of fine-grained spatial details in VLMs due to the absence of large-scale 3D vision-language pretraining. To address these challenges, we propose OccVLA, a novel framework that integrates 3D occupancy representations into a unified multimodal reasoning process. Unlike prior approaches that rely on explicit 3D inputs, OccVLA treats dense 3D occupancy as both a predictive output and a supervisory signal, enabling the model to learn fine-grained spatial structures directly from 2D visual inputs. The occupancy predictions are regarded as implicit reasoning processes and can be skipped during inference without performance degradation, thereby adding no extra computational overhead. OccVLA achieves state-of-the-art results on the nuScenes benchmark for trajectory planning and demonstrates superior performance on 3D visual question-answering tasks, offering a scalable, interpretable, and fully vision-based solution for autonomous driving.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ç¼ºä¹ç¨³å¥3Dç©ºé—´ç†è§£çš„é—®é¢˜ï¼Œæå‡ºäº†OccVLAæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³3Dè¡¨ç¤ºæ„å»ºå›°éš¾åŠè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ä¸­ç²¾ç»†ç©ºé—´ç»†èŠ‚ä¸¢å¤±çš„æŒ‘æˆ˜ã€‚OccVLAå°†ç¨ å¯†çš„3D occupancyè¡¨ç¤ºé›†æˆåˆ°ç»Ÿä¸€çš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå°†å…¶ä½œä¸ºé¢„æµ‹è¾“å‡ºå’Œç›‘ç£ä¿¡å·ï¼Œä½¿æ¨¡å‹èƒ½ç›´æ¥ä»2Dè§†è§‰è¾“å…¥ä¸­å­¦ä¹ ç²¾ç»†çš„3Dç©ºé—´ç»“æ„ã€‚è¿™ç§occupancyé¢„æµ‹è¢«è§†ä¸ºéšå¼æ¨ç†è¿‡ç¨‹ï¼Œåœ¨æ¨ç†é˜¶æ®µå¯è·³è¿‡è€Œä¸äº§ç”Ÿé¢å¤–è®¡ç®—å¼€é”€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOccVLAåœ¨nuScenesåŸºå‡†çš„trajectory planningä»»åŠ¡ä¸­å–å¾—äº†state-of-the-artæ°´å¹³ï¼Œå¹¶åœ¨3D visual question-answeringä»»åŠ¡ä¸­è¡¨ç°å“è¶Šã€‚è¯¥æ¡†æ¶ä¸ºè‡ªåŠ¨é©¾é©¶æä¾›äº†ä¸€ç§å¯æ‰©å±•ã€å¯è§£é‡Šä¸”å®Œå…¨åŸºäºè§†è§‰çš„é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05578v1",
      "published_date": "2025-09-06 03:47:21 UTC",
      "updated_date": "2025-09-06 03:47:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:00:40.985285+00:00"
    },
    {
      "arxiv_id": "2509.05553v1",
      "title": "Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study",
      "title_zh": "åˆ©ç”¨å¯¹æ¯”å­¦ä¹ æå‡å¤§è¯­è¨€æ¨¡å‹çš„åŒå‘æ¨ç†èƒ½åŠ›ï¼šä»¥ä»£ç æ··æ·†ä»»åŠ¡ä¸ºä¾‹",
      "authors": [
        "Serge Lionel Nikiema",
        "Jordan Samhi",
        "Micheline BÃ©nÃ©dicte Moumoula",
        "AlbÃ©rick Euraste DjirÃ©",
        "Abdoul Kader KaborÃ©",
        "Jacques Klein",
        "TegawendÃ© F. BissyandÃ©"
      ],
      "abstract": "This research addresses a fundamental question in AI: whether large language models truly understand concepts or simply recognize patterns. The authors propose bidirectional reasoning,the ability to apply transformations in both directions without being explicitly trained on the reverse direction, as a test for genuine understanding. They argue that true comprehension should naturally allow reversibility. For example, a model that can change a variable name like userIndex to i should also be able to infer that i represents a user index without reverse training. The researchers tested current language models and discovered what they term cognitive specialization: when models are fine-tuned on forward tasks, their performance on those tasks improves, but their ability to reason bidirectionally becomes significantly worse. To address this issue, they developed Contrastive Fine-Tuning (CFT), which trains models using three types of examples: positive examples that maintain semantic meaning, negative examples with different semantics, and forward-direction obfuscation examples. This approach aims to develop deeper understanding rather than surface-level pattern recognition and allows reverse capabilities to develop naturally without explicit reverse training. Their experiments demonstrated that CFT successfully achieved bidirectional reasoning, enabling strong reverse performance while maintaining forward task capabilities. The authors conclude that bidirectional reasoning serves both as a theoretical framework for assessing genuine understanding and as a practical training approach for developing more capable AI systems.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(Large Language Models)æ˜¯å¦çœŸæ­£ç†è§£æ¦‚å¿µï¼Œå¹¶æå‡ºå°†åŒå‘æ¨ç†(bidirectional reasoning)ä½œä¸ºæ£€éªŒå…¶çœŸå®ç†è§£çš„æ ‡å‡†ã€‚ä½œè€…é€šè¿‡ç ”ç©¶å‘ç°ï¼Œæ¨¡å‹åœ¨æ¥å—å‰å‘ä»»åŠ¡å¾®è°ƒåä¼šå‡ºç°è®¤çŸ¥ä¸“ä¸šåŒ–(cognitive specialization)ç°è±¡ï¼Œå¯¼è‡´å…¶åå‘æ¨ç†èƒ½åŠ›æ˜¾è‘—ä¸‹é™ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†å¯¹æ¯”å¾®è°ƒ(Contrastive Fine-Tuning, CFT)æ–¹æ³•ï¼Œåˆ©ç”¨æ­£æ ·æœ¬ã€è´Ÿæ ·æœ¬åŠå‰å‘æ··æ·†ç¤ºä¾‹å¼•å¯¼æ¨¡å‹å»ºç«‹æ·±åº¦ç†è§£ï¼Œè€Œéä»…ä¾èµ–è¡¨é¢æ¨¡å¼è¯†åˆ«ã€‚è¯¥æ–¹æ³•å…è®¸æ¨¡å‹åœ¨æœªæ¥å—æ˜¾å¼åå‘è®­ç»ƒçš„æƒ…å†µä¸‹è‡ªç„¶åœ°å½¢æˆåŒå‘æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCFTåœ¨ä¿æŒå‰å‘ä»»åŠ¡æ€§èƒ½çš„åŒæ—¶ï¼ŒæˆåŠŸå®ç°äº†å¼ºå¤§çš„åå‘æ¨ç†è¡¨ç°ã€‚æœ€åï¼Œä½œè€…æŒ‡å‡ºåŒå‘æ¨ç†æ—¢æ˜¯è¯„ä¼°äººå·¥æ™ºèƒ½ç†è§£èƒ½åŠ›çš„ç†è®ºæ¡†æ¶ï¼Œä¹Ÿæ˜¯æ„å»ºæ›´é«˜æ•ˆAIç³»ç»Ÿçš„å®ç”¨è®­ç»ƒè·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05553v1",
      "published_date": "2025-09-06 00:44:34 UTC",
      "updated_date": "2025-09-06 00:44:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:00:47.078199+00:00"
    },
    {
      "arxiv_id": "2510.13814v2",
      "title": "Reversing the Lens: Using Explainable AI to Understand Human Expertise",
      "title_zh": "è§†è§’åè½¬ï¼šåˆ©ç”¨å¯è§£é‡Šäººå·¥æ™ºèƒ½æ¢ç©¶äººç±»ä¸“ä¸šæŠ€èƒ½",
      "authors": [
        "Roussel Rahman",
        "Aashwin Ananda Mishra",
        "Wan-Lin Hu"
      ],
      "abstract": "Both humans and machine learning models learn from experience, particularly in safety- and reliability-critical domains. While psychology seeks to understand human cognition, the field of Explainable AI (XAI) develops methods to interpret machine learning models. This study bridges these domains by applying computational tools from XAI to analyze human learning. We modeled human behavior during a complex real-world task -- tuning a particle accelerator -- by constructing graphs of operator subtasks. Applying techniques such as community detection and hierarchical clustering to archival operator data, we reveal how operators decompose the problem into simpler components and how these problem-solving structures evolve with expertise. Our findings illuminate how humans develop efficient strategies in the absence of globally optimal solutions, and demonstrate the utility of XAI-based methods for quantitatively studying human cognition.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨å¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI, XAI)çš„è®¡ç®—å·¥å…·æ¥åˆ†æäººç±»çš„å­¦ä¹ è¿‡ç¨‹å’Œä¸“å®¶ç»éªŒã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ„å»ºæ“ä½œå‘˜å­ä»»åŠ¡å›¾(graphs of operator subtasks)ï¼Œå¯¹è°ƒä¼˜ç²’å­åŠ é€Ÿå™¨è¿™ä¸€å¤æ‚ç°å®ä»»åŠ¡ä¸­çš„äººç±»è¡Œä¸ºè¿›è¡Œäº†å»ºæ¨¡ã€‚é€šè¿‡å¯¹å­˜æ¡£çš„æ“ä½œå‘˜æ•°æ®åº”ç”¨ç¤¾åŒºæ£€æµ‹(community detection)å’Œå±‚æ¬¡èšç±»(hierarchical clustering)ç­‰æŠ€æœ¯ï¼Œç ”ç©¶æ­ç¤ºäº†æ“ä½œå‘˜å¦‚ä½•å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºç®€å•ç»„ä»¶ã€‚ç ”ç©¶ç»“æœé˜æ˜äº†è¿™äº›é—®é¢˜è§£å†³ç»“æ„å¦‚ä½•éšä¸“ä¸šæ°´å¹³çš„æé«˜è€Œæ¼”å˜ï¼Œä»¥åŠäººç±»å¦‚ä½•åœ¨ç¼ºä¹å…¨å±€æœ€ä¼˜è§£çš„æƒ…å†µä¸‹å¼€å‘å‡ºé«˜æ•ˆç­–ç•¥ã€‚è¯¥å·¥ä½œä¸ä»…å±•ç¤ºäº†äººç±»åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è®¤çŸ¥æ¼”åŒ–è¿‡ç¨‹ï¼Œæ›´è¯æ˜äº†åŸºäºXAIçš„æ–¹æ³•åœ¨å®šé‡ç ”ç©¶äººç±»è®¤çŸ¥æ–¹é¢çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13814v2",
      "published_date": "2025-09-06 00:41:40 UTC",
      "updated_date": "2025-11-21 19:38:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:00:46.699693+00:00"
    },
    {
      "arxiv_id": "2509.05550v2",
      "title": "TreeGPT: Pure TreeFFN Encoder-Decoder Architecture for Structured Reasoning Without Attention Mechanisms",
      "title_zh": "TreeGPTï¼šé¢å‘ç»“æ„åŒ–æ¨ç†çš„æ— æ³¨æ„åŠ›æœºåˆ¶çº¯ TreeFFN ç¼–ç å™¨-è§£ç å™¨æ¶æ„",
      "authors": [
        "Zixi Li"
      ],
      "abstract": "We present TreeGPT, an attention-free neural architecture that explores the potential of pure TreeFFN encoder-decoder design for structured reasoning tasks. Unlike traditional transformer approaches that rely on attention mechanisms, TreeGPT employs bidirectional TreeFFN components that process sequences through adjacent connections in parallel, aiming to achieve computational efficiency while maintaining reasoning capabilities.\n  Our approach centers on a TreeFFN Encoder-Decoder mechanism: $$\\text{Encoder TreeFFN (L} \\rightarrow \\text{R)} + \\text{Decoder TreeFFN (R} \\leftarrow \\text{L)} \\rightarrow \\text{Parallel Processing}$$ where the encoder processes left-to-right dependencies while the decoder handles right-to-left patterns, both using simple neighbor-to-neighbor connections. This design eliminates attention computation while maintaining sequence modeling capabilities.\n  We evaluate our approach on the ARC Prize 2025 dataset, where TreeGPT achieves 99\\% validation accuracy using 3.16M parameters. The model converges within 1500 training steps and demonstrates 100\\% token-level accuracy on selected evaluation samples. Our preliminary results suggest that for certain structured reasoning tasks, specialized TreeFFN architectures may offer advantages over attention-based approaches. While these findings are encouraging, we acknowledge that further investigation across diverse tasks and datasets would be valuable to establish the broader applicability of attention-free designs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TreeGPTï¼Œè¿™æ˜¯ä¸€ç§å®Œå…¨ä¸ä¾èµ– attention mechanisms çš„çº¯ TreeFFN encoder-decoder æ¶æ„ï¼Œæ—¨åœ¨æ¢ç´¢ç»“æ„åŒ–æ¨ç†ä»»åŠ¡çš„æ–°è·¯å¾„ã€‚è¯¥æ¶æ„åˆ©ç”¨åŒå‘ TreeFFN ç»„ä»¶é€šè¿‡ç›¸é‚»è¿æ¥å¹¶è¡Œå¤„ç†åºåˆ—ï¼Œå…¶ä¸­ encoder å¤„ç†ä»å·¦åˆ°å³çš„ä¾èµ–å…³ç³»ï¼Œè€Œ decoder å¤„ç†ä»å³åˆ°å·¦çš„æ¨¡å¼ï¼Œä»è€Œåœ¨æ¶ˆé™¤æ³¨æ„åŠ›è®¡ç®—å¼€é”€çš„åŒæ—¶ä¿æŒå¼ºå¤§çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›ã€‚åœ¨ ARC Prize 2025 æ•°æ®é›†çš„è¯„ä¼°ä¸­ï¼Œä»…å«æœ‰ 3.16M å‚æ•°çš„ TreeGPT è¾¾åˆ°äº† 99% çš„éªŒè¯å‡†ç¡®ç‡ï¼Œå¹¶åœ¨ 1500 ä¸ªè®­ç»ƒæ­¥å†…å®ç°æ”¶æ•›ï¼Œå±•ç°å‡ºæé«˜çš„è®¡ç®—æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¯¹äºç‰¹å®šçš„ç»“æ„åŒ–æ¨ç†ä»»åŠ¡ï¼Œä¸“é—¨çš„ TreeFFN æ¶æ„ç›¸æ¯”ä¼ ç»Ÿçš„ attention-based é€”å¾„å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åœ¨ä¸éœ€è¦å¤æ‚æ³¨æ„åŠ›æœºåˆ¶çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡é«˜æ•ˆçš„æ ‘çŠ¶å‰é¦ˆç½‘ç»œè®¾è®¡ä¹Ÿèƒ½å®ç°å“è¶Šçš„æ¨ç†æ€§èƒ½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code available at: https://github.com/lizixi-0x2F/TreeGPT",
      "pdf_url": "https://arxiv.org/pdf/2509.05550v2",
      "published_date": "2025-09-06 00:39:33 UTC",
      "updated_date": "2025-09-11 10:46:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T17:00:47.278816+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 54,
  "processed_papers_count": 54,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T17:01:28.612281+00:00"
}