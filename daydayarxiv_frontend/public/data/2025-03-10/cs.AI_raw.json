[
  {
    "arxiv_id": "2503.07920v2",
    "title": "Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia",
    "authors": [
      "Samuel Cahyawijaya",
      "Holy Lovenia",
      "Joel Ruben Antony Moniz",
      "Tack Hwa Wong",
      "Mohammad Rifqi Farhansyah",
      "Thant Thiri Maung",
      "Frederikus Hudi",
      "David Anugraha",
      "Muhammad Ravi Shulthan Habibi",
      "Muhammad Reza Qorib",
      "Amit Agarwal",
      "Joseph Marvin Imperial",
      "Hitesh Laxmichand Patel",
      "Vicky Feliren",
      "Bahrul Ilmi Nasution",
      "Manuel Antonio Rufino",
      "Genta Indra Winata",
      "Rian Adam Rajagede",
      "Carlos Rafael Catalan",
      "Mohamed Fazli Imam",
      "Priyaranjan Pattnayak",
      "Salsabila Zahirah Pranida",
      "Kevin Pratama",
      "Yeshil Bangera",
      "Adisai Na-Thalang",
      "Patricia Nicole Monderin",
      "Yueqi Song",
      "Christian Simon",
      "Lynnette Hui Xian Ng",
      "Richardy Lobo' Sapan",
      "Taki Hasan Rafi",
      "Bin Wang",
      "Supryadi",
      "Kanyakorn Veerakanjana",
      "Piyalitt Ittichaiwong",
      "Matthew Theodore Roque",
      "Karissa Vincentio",
      "Takdanai Kreangphet",
      "Phakphum Artkaew",
      "Kadek Hendrawan Palgunadi",
      "Yanzhi Yu",
      "Rochana Prih Hastuti",
      "William Nixon",
      "Mithil Bangera",
      "Adrian Xuan Wei Lim",
      "Aye Hninn Khine",
      "Hanif Muhammad Zhafran",
      "Teddy Ferdinan",
      "Audra Aurora Izzani",
      "Ayushman Singh",
      "Evan",
      "Jauza Akbar Krito",
      "Michael Anugraha",
      "Fenal Ashokbhai Ilasariya",
      "Haochen Li",
      "John Amadeo Daniswara",
      "Filbert Aurelian Tjiaranata",
      "Eryawan Presma Yulianrifat",
      "Can Udomcharoenchaikit",
      "Fadil Risdian Ansori",
      "Mahardika Krisna Ihsani",
      "Giang Nguyen",
      "Anab Maulana Barik",
      "Dan John Velasco",
      "Rifo Ahmad Genadi",
      "Saptarshi Saha",
      "Chengwei Wei",
      "Isaiah Flores",
      "Kenneth Ko Han Chen",
      "Anjela Gail Santos",
      "Wan Shen Lim",
      "Kaung Si Phyo",
      "Tim Santos",
      "Meisyarah Dwiastuti",
      "Jiayun Luo",
      "Jan Christian Blaise Cruz",
      "Ming Shan Hee",
      "Ikhlasul Akmal Hanif",
      "M. Alif Al Hakim",
      "Muhammad Rizky Sya'ban",
      "Kun Kerdthaisong",
      "Lester James V. Miranda",
      "Fajri Koto",
      "Tirana Noor Fatyanosa",
      "Alham Fikri Aji",
      "Jostin Jerico Rosal",
      "Jun Kevin",
      "Robert Wijaya",
      "Onno P. Kampman",
      "Ruochen Zhang",
      "BÃ¶rje F. Karlsson",
      "Peerat Limkonchotiwat"
    ],
    "abstract": "Southeast Asia (SEA) is a region of extraordinary linguistic and cultural\ndiversity, yet it remains significantly underrepresented in vision-language\n(VL) research. This often results in artificial intelligence (AI) models that\nfail to capture SEA cultural nuances. To fill this gap, we present SEA-VL, an\nopen-source initiative dedicated to developing high-quality, culturally\nrelevant data for SEA languages. By involving contributors from SEA countries,\nSEA-VL aims to ensure better cultural relevance and diversity, fostering\ngreater inclusivity of underrepresented languages in VL research. Beyond\ncrowdsourcing, our initiative goes one step further in the exploration of the\nautomatic collection of culturally relevant images through crawling and image\ngeneration. First, we find that image crawling achieves approximately ~85%\ncultural relevance while being more cost- and time-efficient than\ncrowdsourcing. Second, despite the substantial progress in generative vision\nmodels, synthetic images remain unreliable in accurately reflecting SEA\ncultures. The generated images often fail to reflect the nuanced traditions and\ncultural contexts of the region. Collectively, we gather 1.28M SEA\nculturally-relevant images, more than 50 times larger than other existing\ndatasets. Through SEA-VL, we aim to bridge the representation gap in SEA,\nfostering the development of more inclusive AI systems that authentically\nrepresent diverse cultures across SEA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "[SEA-VL Dataset]\n  https://huggingface.co/collections/SEACrowd/sea-vl-multicultural-vl-dataset-for-southeast-asia-67cf223d0c341d4ba2b236e7\n  [Appendix J]\n  https://github.com/SEACrowd/seacrowd.github.io/blob/master/docs/SEA_VL_Appendix_J.pdf",
    "pdf_url": "http://arxiv.org/pdf/2503.07920v2",
    "published_date": "2025-03-10 23:54:52 UTC",
    "updated_date": "2025-03-18 11:34:03 UTC"
  },
  {
    "arxiv_id": "2503.07919v1",
    "title": "BEARCUBS: A benchmark for computer-using web agents",
    "authors": [
      "Yixiao Song",
      "Katherine Thai",
      "Chau Minh Pham",
      "Yapei Chang",
      "Mazin Nadaf",
      "Mohit Iyyer"
    ],
    "abstract": "Modern web agents possess computer use abilities that allow them to interact\nwith webpages by sending commands to a virtual keyboard and mouse. While such\nagents have considerable potential to assist human users with complex tasks,\nevaluating their capabilities in real-world settings poses a major challenge.\nTo this end, we introduce BEARCUBS, a \"small but mighty\" benchmark of 111\ninformation-seeking questions designed to evaluate a web agent's ability to\nsearch, browse, and identify factual information from the web. Unlike prior web\nagent benchmarks, solving BEARCUBS requires (1) accessing live web content\nrather than synthetic or simulated pages, which captures the unpredictability\nof real-world web interactions; and (2) performing a broad range of multimodal\ninteractions (e.g., video understanding, 3D navigation) that cannot be bypassed\nvia text-based workarounds. Each question in BEARCUBS has a corresponding\nshort, unambiguous answer and a human-validated browsing trajectory, allowing\nfor transparent evaluation of agent performance and strategies. A human study\nconfirms that BEARCUBS questions are solvable but non-trivial (84.7% human\naccuracy), revealing search inefficiencies and domain knowledge gaps as common\nfailure points. By contrast, state-of-the-art computer-using agents\nunderperform, with the best-scoring system (OpenAI's Operator) reaching only\n24.3% accuracy. These results highlight critical areas for improvement,\nincluding reliable source selection and more powerful multimodal capabilities.\nTo facilitate future research, BEARCUBS will be updated periodically to replace\ninvalid or contaminated questions, keeping the benchmark fresh for future\ngenerations of web agents.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07919v1",
    "published_date": "2025-03-10 23:50:30 UTC",
    "updated_date": "2025-03-10 23:50:30 UTC"
  },
  {
    "arxiv_id": "2503.10676v1",
    "title": "Fine-Tuning LLMs for Report Summarization: Analysis on Supervised and Unsupervised Data",
    "authors": [
      "Swati Rallapalli",
      "Shannon Gallagher",
      "Andrew O. Mellinger",
      "Jasmine Ratchford",
      "Anusha Sinha",
      "Tyler Brooks",
      "William R. Nichols",
      "Nick Winski",
      "Bryan Brown"
    ],
    "abstract": "We study the efficacy of fine-tuning Large Language Models (LLMs) for the\nspecific task of report (government archives, news, intelligence reports)\nsummarization. While this topic is being very actively researched - our\nspecific application set-up faces two challenges: (i) ground-truth summaries\nmaybe unavailable (e.g., for government archives), and (ii) availability of\nlimited compute power - the sensitive nature of the application requires that\ncomputation is performed on-premise and for most of our experiments we use one\nor two A100 GPU cards. Under this set-up we conduct experiments to answer the\nfollowing questions. First, given that fine-tuning the LLMs can be resource\nintensive, is it feasible to fine-tune them for improved report summarization\ncapabilities on-premise? Second, what are the metrics we could leverage to\nassess the quality of these summaries? We conduct experiments on two different\nfine-tuning approaches in parallel and our findings reveal interesting trends\nregarding the utility of fine-tuning LLMs. Specifically, we find that in many\ncases, fine-tuning helps improve summary quality and in other cases it helps by\nreducing the number of invalid or garbage summaries.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10676v1",
    "published_date": "2025-03-10 23:47:11 UTC",
    "updated_date": "2025-03-10 23:47:11 UTC"
  },
  {
    "arxiv_id": "2503.07914v1",
    "title": "Demystifying the Accuracy-Interpretability Trade-Off: A Case Study of Inferring Ratings from Reviews",
    "authors": [
      "Pranjal Atrey",
      "Michael P. Brundage",
      "Min Wu",
      "Sanghamitra Dutta"
    ],
    "abstract": "Interpretable machine learning models offer understandable reasoning behind\ntheir decision-making process, though they may not always match the performance\nof their black-box counterparts. This trade-off between interpretability and\nmodel performance has sparked discussions around the deployment of AI,\nparticularly in critical applications where knowing the rationale of\ndecision-making is essential for trust and accountability. In this study, we\nconduct a comparative analysis of several black-box and interpretable models,\nfocusing on a specific NLP use case that has received limited attention:\ninferring ratings from reviews. Through this use case, we explore the intricate\nrelationship between the performance and interpretability of different models.\nWe introduce a quantitative score called Composite Interpretability (CI) to\nhelp visualize the trade-off between interpretability and performance,\nparticularly in the case of composite models. Our results indicate that, in\ngeneral, the learning performance improves as interpretability decreases, but\nthis relationship is not strictly monotonic, and there are instances where\ninterpretable models are more advantageous.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at DAI Workshop, AAAI-2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07914v1",
    "published_date": "2025-03-10 23:17:46 UTC",
    "updated_date": "2025-03-10 23:17:46 UTC"
  },
  {
    "arxiv_id": "2503.07911v1",
    "title": "Visual and Text Prompt Segmentation: A Novel Multi-Model Framework for Remote Sensing",
    "authors": [
      "Xing Zi",
      "Kairui Jin",
      "Xian Tao",
      "Jun Li",
      "Ali Braytee",
      "Rajiv Ratn Shah",
      "Mukesh Prasad"
    ],
    "abstract": "Pixel-level segmentation is essential in remote sensing, where foundational\nvision models like CLIP and Segment Anything Model(SAM) have demonstrated\nsignificant capabilities in zero-shot segmentation tasks. Despite their\nadvances, challenges specific to remote sensing remain substantial. Firstly,\nThe SAM without clear prompt constraints, often generates redundant masks, and\nmaking post-processing more complex. Secondly, the CLIP model, mainly designed\nfor global feature alignment in foundational models, often overlooks local\nobjects crucial to remote sensing. This oversight leads to inaccurate\nrecognition or misplaced focus in multi-target remote sensing imagery. Thirdly,\nboth models have not been pre-trained on multi-scale aerial views, increasing\nthe likelihood of detection failures. To tackle these challenges, we introduce\nthe innovative VTPSeg pipeline, utilizing the strengths of Grounding DINO,\nCLIP, and SAM for enhanced open-vocabulary image segmentation. The Grounding\nDINO+(GD+) module generates initial candidate bounding boxes, while the CLIP\nFilter++(CLIP++) module uses a combination of visual and textual prompts to\nrefine and filter out irrelevant object bounding boxes, ensuring that only\npertinent objects are considered. Subsequently, these refined bounding boxes\nserve as specific prompts for the FastSAM model, which executes precise\nsegmentation. Our VTPSeg is validated by experimental and ablation study\nresults on five popular remote sensing image segmentation datasets.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.MM",
    "comment": "Under Review - IEEE Journal of Selected Topics in Applied Earth\n  Observations and Remote Sensing",
    "pdf_url": "http://arxiv.org/pdf/2503.07911v1",
    "published_date": "2025-03-10 23:15:57 UTC",
    "updated_date": "2025-03-10 23:15:57 UTC"
  },
  {
    "arxiv_id": "2503.07909v1",
    "title": "FunGraph: Functionality Aware 3D Scene Graphs for Language-Prompted Scene Interaction",
    "authors": [
      "Dennis Rotondi",
      "Fabio Scaparro",
      "Hermann Blum",
      "Kai O. Arras"
    ],
    "abstract": "The concept of 3D scene graphs is increasingly recognized as a powerful\nsemantic and hierarchical representation of the environment. Current approaches\noften address this at a coarse, object-level resolution. In contrast, our goal\nis to develop a representation that enables robots to directly interact with\ntheir environment by identifying both the location of functional interactive\nelements and how these can be used. To achieve this, we focus on detecting and\nstoring objects at a finer resolution, focusing on affordance-relevant parts.\nThe primary challenge lies in the scarcity of data that extends beyond\ninstance-level detection and the inherent difficulty of capturing detailed\nobject features using robotic sensors. We leverage currently available 3D\nresources to generate 2D data and train a detector, which is then used to\naugment the standard 3D scene graph generation pipeline. Through our\nexperiments, we demonstrate that our approach achieves functional element\nsegmentation comparable to state-of-the-art 3D models and that our augmentation\nenables task-driven affordance grounding with higher accuracy than the current\nsolutions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07909v1",
    "published_date": "2025-03-10 23:13:35 UTC",
    "updated_date": "2025-03-10 23:13:35 UTC"
  },
  {
    "arxiv_id": "2503.07891v1",
    "title": "Gemini Embedding: Generalizable Embeddings from Gemini",
    "authors": [
      "Jinhyuk Lee",
      "Feiyang Chen",
      "Sahil Dua",
      "Daniel Cer",
      "Madhuri Shanbhogue",
      "Iftekhar Naim",
      "Gustavo HernÃ¡ndez Ãbrego",
      "Zhe Li",
      "Kaifeng Chen",
      "Henrique Schechter Vera",
      "Xiaoqi Ren",
      "Shanfeng Zhang",
      "Daniel Salz",
      "Michael Boratko",
      "Jay Han",
      "Blair Chen",
      "Shuo Huang",
      "Vikram Rao",
      "Paul Suganthan",
      "Feng Han",
      "Andreas Doumanoglou",
      "Nithi Gupta",
      "Fedor Moiseev",
      "Cathy Yip",
      "Aashi Jain",
      "Simon Baumgartner",
      "Shahrokh Shahi",
      "Frank Palma Gomez",
      "Sandeep Mariserla",
      "Min Choi",
      "Parashar Shah",
      "Sonam Goenka",
      "Ke Chen",
      "Ye Xia",
      "Koert Chen",
      "Sai Meher Karthik Duddu",
      "Yichang Chen",
      "Trevor Walker",
      "Wenlei Zhou",
      "Rakesh Ghiya",
      "Zach Gleicher",
      "Karan Gill",
      "Zhe Dong",
      "Mojtaba Seyedhosseini",
      "Yunhsuan Sung",
      "Raphael Hoffmann",
      "Tom Duerig"
    ],
    "abstract": "In this report, we introduce Gemini Embedding, a state-of-the-art embedding\nmodel leveraging the power of Gemini, Google's most capable large language\nmodel. Capitalizing on Gemini's inherent multilingual and code understanding\ncapabilities, Gemini Embedding produces highly generalizable embeddings for\ntext spanning numerous languages and textual modalities. The representations\ngenerated by Gemini Embedding can be precomputed and applied to a variety of\ndownstream tasks including classification, similarity, clustering, ranking, and\nretrieval. Evaluated on the Massive Multilingual Text Embedding Benchmark\n(MMTEB), which includes over one hundred tasks across 250+ languages, Gemini\nEmbedding substantially outperforms prior state-of-the-art models,\ndemonstrating considerable improvements in embedding quality. Achieving\nstate-of-the-art performance across MMTEB's multilingual, English, and code\nbenchmarks, our unified model demonstrates strong capabilities across a broad\nselection of tasks and surpasses specialized domain-specific models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07891v1",
    "published_date": "2025-03-10 22:16:45 UTC",
    "updated_date": "2025-03-10 22:16:45 UTC"
  },
  {
    "arxiv_id": "2503.16491v1",
    "title": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "authors": [
      "Claudia Flores-Saviaga",
      "Benjamin V. Hanrahan",
      "Kashif Imteyaz",
      "Steven Clarke",
      "Saiph Savage"
    ],
    "abstract": "The rapid adoption of generative AI in software development has impacted the\nindustry, yet its effects on developers with visual impairments remain largely\nunexplored. To address this gap, we used an Activity Theory framework to\nexamine how developers with visual impairments interact with AI coding\nassistants. For this purpose, we conducted a study where developers who are\nvisually impaired completed a series of programming tasks using a generative AI\ncoding assistant. We uncovered that, while participants found the AI assistant\nbeneficial and reported significant advantages, they also highlighted\naccessibility challenges. Specifically, the AI coding assistant often\nexacerbated existing accessibility barriers and introduced new challenges. For\nexample, it overwhelmed users with an excessive number of suggestions, leading\ndevelopers who are visually impaired to express a desire for ``AI timeouts.''\nAdditionally, the generative AI coding assistant made it more difficult for\ndevelopers to switch contexts between the AI-generated content and their own\ncode. Despite these challenges, participants were optimistic about the\npotential of AI coding assistants to transform the coding experience for\ndevelopers with visual impairments. Our findings emphasize the need to apply\nactivity-centered design principles to generative AI assistants, ensuring they\nbetter align with user behaviors and address specific accessibility needs. This\napproach can enable the assistants to provide more intuitive, inclusive, and\neffective experiences, while also contributing to the broader goal of enhancing\naccessibility in software development.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "H.5; H.5.3"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages, 3 figures, published in the ACM Conference on Human Factors\n  in Computing Systems 2025 (CHI'25)",
    "pdf_url": "http://arxiv.org/pdf/2503.16491v1",
    "published_date": "2025-03-10 22:06:43 UTC",
    "updated_date": "2025-03-10 22:06:43 UTC"
  },
  {
    "arxiv_id": "2503.07885v1",
    "title": "Safety Guardrails for LLM-Enabled Robots",
    "authors": [
      "Zachary Ravichandran",
      "Alexander Robey",
      "Vijay Kumar",
      "George J. Pappas",
      "Hamed Hassani"
    ],
    "abstract": "Although the integration of large language models (LLMs) into robotics has\nunlocked transformative capabilities, it has also introduced significant safety\nconcerns, ranging from average-case LLM errors (e.g., hallucinations) to\nadversarial jailbreaking attacks, which can produce harmful robot behavior in\nreal-world settings. Traditional robot safety approaches do not address the\nnovel vulnerabilities of LLMs, and current LLM safety guardrails overlook the\nphysical risks posed by robots operating in dynamic real-world environments. In\nthis paper, we propose RoboGuard, a two-stage guardrail architecture to ensure\nthe safety of LLM-enabled robots. RoboGuard first contextualizes pre-defined\nsafety rules by grounding them in the robot's environment using a root-of-trust\nLLM, which employs chain-of-thought (CoT) reasoning to generate rigorous safety\nspecifications, such as temporal logic constraints. RoboGuard then resolves\npotential conflicts between these contextual safety specifications and a\npossibly unsafe plan using temporal logic control synthesis, which ensures\nsafety compliance while minimally violating user preferences. Through extensive\nsimulation and real-world experiments that consider worst-case jailbreaking\nattacks, we demonstrate that RoboGuard reduces the execution of unsafe plans\nfrom 92% to below 2.5% without compromising performance on safe plans. We also\ndemonstrate that RoboGuard is resource-efficient, robust against adaptive\nattacks, and significantly enhanced by enabling its root-of-trust LLM to\nperform CoT reasoning. These results underscore the potential of RoboGuard to\nmitigate the safety risks and enhance the reliability of LLM-enabled robots.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07885v1",
    "published_date": "2025-03-10 22:01:56 UTC",
    "updated_date": "2025-03-10 22:01:56 UTC"
  },
  {
    "arxiv_id": "2503.07884v1",
    "title": "LLMIdxAdvis: Resource-Efficient Index Advisor Utilizing Large Language Model",
    "authors": [
      "Xinxin Zhao",
      "Haoyang Li",
      "Jing Zhang",
      "Xinmei Huang",
      "Tieying Zhang",
      "Jianjun Chen",
      "Rui Shi",
      "Cuiping Li",
      "Hong Chen"
    ],
    "abstract": "Index recommendation is essential for improving query performance in database\nmanagement systems (DBMSs) through creating an optimal set of indexes under\nspecific constraints. Traditional methods, such as heuristic and learning-based\napproaches, are effective but face challenges like lengthy recommendation time,\nresource-intensive training, and poor generalization across different workloads\nand database schemas. To address these issues, we propose LLMIdxAdvis, a\nresource-efficient index advisor that uses large language models (LLMs) without\nextensive fine-tuning. LLMIdxAdvis frames index recommendation as a\nsequence-to-sequence task, taking target workload, storage constraint, and\ncorresponding database environment as input, and directly outputting\nrecommended indexes. It constructs a high-quality demonstration pool offline,\nusing GPT-4-Turbo to synthesize diverse SQL queries and applying integrated\nheuristic methods to collect both default and refined labels. During\nrecommendation, these demonstrations are ranked to inject database expertise\nvia in-context learning. Additionally, LLMIdxAdvis extracts workload features\ninvolving specific column statistical information to strengthen LLM's\nunderstanding, and introduces a novel inference scaling strategy combining\nvertical scaling (via ''Index-Guided Major Voting'' and Best-of-N) and\nhorizontal scaling (through iterative ''self-optimization'' with database\nfeedback) to enhance reliability. Experiments on 3 OLAP and 2 real-world\nbenchmarks reveal that LLMIdxAdvis delivers competitive index recommendation\nwith reduced runtime, and generalizes effectively across different workloads\nand database schemas.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07884v1",
    "published_date": "2025-03-10 22:01:24 UTC",
    "updated_date": "2025-03-10 22:01:24 UTC"
  },
  {
    "arxiv_id": "2503.07878v2",
    "title": "Measuring directional bias amplification in image captions using predictability",
    "authors": [
      "Rahul Nair",
      "Bhanu Tokas",
      "Neel Shah",
      "Hannah Kerner"
    ],
    "abstract": "When we train models on biased ML datasets, they not only learn these biases\nbut can inflate them at test time - a phenomenon called bias amplification. To\nmeasure bias amplification in ML datasets, many co-occurrence-based metrics\nhave been proposed. Co-occurrence-based metrics are effective in measuring bias\namplification in simple problems like image classification. However, these\nmetrics are ineffective for complex problems like image captioning as they\ncannot capture the semantics of a caption. To measure bias amplification in\ncaptions, prior work introduced a predictability-based metric called Leakage in\nCaptioning (LIC). While LIC captures the semantics and context of captions, it\nhas limitations. LIC cannot identify the direction in which bias is amplified,\npoorly estimates dataset bias due to a weak vocabulary substitution strategy,\nand is highly sensitive to attacker models (a hyperparameter in\npredictability-based metrics). To overcome these issues, we propose Directional\nPredictability Amplification in Captioning (DPAC). DPAC measures directional\nbias amplification in captions, provides a better estimate of dataset bias\nusing an improved substitution strategy, and is less sensitive to attacker\nmodels. Our experiments on the COCO captioning dataset show how DPAC is the\nmost reliable metric to measure bias amplification in captions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07878v2",
    "published_date": "2025-03-10 21:50:58 UTC",
    "updated_date": "2025-03-12 02:47:54 UTC"
  },
  {
    "arxiv_id": "2503.07874v1",
    "title": "Topology-Preserving Loss for Accurate and Anatomically Consistent Cardiac Mesh Reconstruction",
    "authors": [
      "Chenyu Zhang",
      "Yihao Luo",
      "Yinzhe Wu",
      "Choon Hwai Yap",
      "Guang Yang"
    ],
    "abstract": "Accurate cardiac mesh reconstruction from volumetric data is essential for\npersonalized cardiac modeling and clinical analysis. However, existing\ndeformation-based approaches are prone to topological inconsistencies,\nparticularly membrane penetration, which undermines the anatomical plausibility\nof the reconstructed mesh. To address this issue, we introduce\nTopology-Preserving Mesh Loss (TPM Loss), a novel loss function that explicitly\nenforces topological constraints during mesh deformation. By identifying\ntopology-violating points, TPM Loss ensures spatially consistent\nreconstructions. Extensive experiments on CT and MRI datasets show that TPM\nLoss reduces topology violations by up to 93.1% while maintaining high\nsegmentation accuracy (DSC: 89.1%-92.9%) and improving mesh fidelity (Chamfer\nDistance reduction up to 0.26 mm). These results demonstrate that TPM Loss\neffectively prevents membrane penetration and significantly improves cardiac\nmesh quality, enabling more accurate and anatomically consistent cardiac\nreconstructions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07874v1",
    "published_date": "2025-03-10 21:46:57 UTC",
    "updated_date": "2025-03-10 21:46:57 UTC"
  },
  {
    "arxiv_id": "2503.07871v1",
    "title": "MapQA: Open-domain Geospatial Question Answering on Map Data",
    "authors": [
      "Zekun Li",
      "Malcolm Grossman",
      "Eric",
      "Qasemi",
      "Mihir Kulkarni",
      "Muhao Chen",
      "Yao-Yi Chiang"
    ],
    "abstract": "Geospatial question answering (QA) is a fundamental task in navigation and\npoint of interest (POI) searches. While existing geospatial QA datasets exist,\nthey are limited in both scale and diversity, often relying solely on textual\ndescriptions of geo-entities without considering their geometries. A major\nchallenge in scaling geospatial QA datasets for reasoning lies in the\ncomplexity of geospatial relationships, which require integrating spatial\nstructures, topological dependencies, and multi-hop reasoning capabilities that\nmost text-based QA datasets lack. To address these limitations, we introduce\nMapQA, a novel dataset that not only provides question-answer pairs but also\nincludes the geometries of geo-entities referenced in the questions. MapQA is\nconstructed using SQL query templates to extract question-answer pairs from\nOpenStreetMap (OSM) for two study regions: Southern California and Illinois. It\nconsists of 3,154 QA pairs spanning nine question types that require geospatial\nreasoning, such as neighborhood inference and geo-entity type identification.\nCompared to existing datasets, MapQA expands both the number and diversity of\ngeospatial question types. We explore two approaches to tackle this challenge:\n(1) a retrieval-based language model that ranks candidate geo-entities by\nembedding similarity, and (2) a large language model (LLM) that generates SQL\nqueries from natural language questions and geo-entity attributes, which are\nthen executed against an OSM database. Our findings indicate that\nretrieval-based methods effectively capture concepts like closeness and\ndirection but struggle with questions that require explicit computations (e.g.,\ndistance calculations). LLMs (e.g., GPT and Gemini) excel at generating SQL\nqueries for one-hop reasoning but face challenges with multi-hop reasoning,\nhighlighting a key bottleneck in advancing geospatial QA systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07871v1",
    "published_date": "2025-03-10 21:37:22 UTC",
    "updated_date": "2025-03-10 21:37:22 UTC"
  },
  {
    "arxiv_id": "2503.07869v1",
    "title": "Right Reward Right Time for Federated Learning",
    "authors": [
      "Thanh Linh Nguyen",
      "Dinh Thai Hoang",
      "Diep N. Nguyen",
      "Quoc-Viet Pham"
    ],
    "abstract": "Critical learning periods (CLPs) in federated learning (FL) refer to early\nstages during which low-quality contributions (e.g., sparse training data\navailability) can permanently impair the learning performance of the global\nmodel owned by the model owner (i.e., the cloud server). However, strategies to\nmotivate clients with high-quality contributions to join the FL training\nprocess and share trained model updates during CLPs remain underexplored.\nAdditionally, existing incentive mechanisms in FL treat all training periods\nequally, which consequently fails to motivate clients to participate early.\nCompounding this challenge is the cloud's limited knowledge of client training\ncapabilities due to privacy regulations, leading to information asymmetry.\nTherefore, in this article, we propose a time-aware incentive mechanism, called\nRight Reward Right Time (R3T), to encourage client involvement, especially\nduring CLPs, to maximize the utility of the cloud in FL. Specifically, the\ncloud utility function captures the trade-off between the achieved model\nperformance and payments allocated for clients' contributions, while accounting\nfor clients' time and system capabilities, efforts, joining time, and rewards.\nThen, we analytically derive the optimal contract for the cloud and devise a\nCLP-aware mechanism to incentivize early participation and efforts while\nmaximizing cloud utility, even under information asymmetry. By providing the\nright reward at the right time, our approach can attract the highest-quality\ncontributions during CLPs. Simulation and proof-of-concept studies show that\nR3T increases cloud utility and is more economically effective than benchmarks.\nNotably, our proof-of-concept results show up to a 47.6% reduction in the total\nnumber of clients and up to a 300% improvement in convergence time while\nreaching competitive test accuracies compared with incentive mechanism\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE Journal Submission",
    "pdf_url": "http://arxiv.org/pdf/2503.07869v1",
    "published_date": "2025-03-10 21:36:42 UTC",
    "updated_date": "2025-03-10 21:36:42 UTC"
  },
  {
    "arxiv_id": "2503.07860v1",
    "title": "Video Action Differencing",
    "authors": [
      "James Burgess",
      "Xiaohan Wang",
      "Yuhui Zhang",
      "Anita Rau",
      "Alejandro Lozano",
      "Lisa Dunlap",
      "Trevor Darrell",
      "Serena Yeung-Levy"
    ],
    "abstract": "How do two individuals differ when performing the same action? In this work,\nwe introduce Video Action Differencing (VidDiff), the novel task of identifying\nsubtle differences between videos of the same action, which has many\napplications, such as coaching and skill learning. To enable development on\nthis new task, we first create VidDiffBench, a benchmark dataset containing 549\nvideo pairs, with human annotations of 4,469 fine-grained action differences\nand 2,075 localization timestamps indicating where these differences occur. Our\nexperiments demonstrate that VidDiffBench poses a significant challenge for\nstate-of-the-art large multimodal models (LMMs), such as GPT-4o and Qwen2-VL.\nBy analyzing failure cases of LMMs on VidDiffBench, we highlight two key\nchallenges for this task: localizing relevant sub-actions over two videos and\nfine-grained frame comparison. To overcome these, we propose the VidDiff\nmethod, an agentic workflow that breaks the task into three stages: action\ndifference proposal, keyframe localization, and frame differencing, each stage\nutilizing specialized foundation models. To encourage future research in this\nnew task, we release the benchmark at\nhttps://huggingface.co/datasets/jmhb/VidDiffBench and code at\nhttp://jmhb0.github.io/viddiff.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025 (International Conference on Learning Representations)\n  Project page: http://jmhb0.github.io/viddiff Benchmark:\n  https://huggingface.co/datasets/jmhb/VidDiffBench",
    "pdf_url": "http://arxiv.org/pdf/2503.07860v1",
    "published_date": "2025-03-10 21:18:32 UTC",
    "updated_date": "2025-03-10 21:18:32 UTC"
  },
  {
    "arxiv_id": "2503.08722v2",
    "title": "A Recipe for Improving Remote Sensing VLM Zero Shot Generalization",
    "authors": [
      "Aviad Barzilai",
      "Yotam Gigi",
      "Amr Helmy",
      "Vered Silverman",
      "Yehonathan Refael",
      "Bolous Jaber",
      "Tomer Shekel",
      "George Leifman",
      "Genady Beryozkin"
    ],
    "abstract": "Foundation models have had a significant impact across various AI\napplications, enabling use cases that were previously impossible. Contrastive\nVisual Language Models (VLMs), in particular, have outperformed other\ntechniques in many tasks. However, their prevalence in remote sensing (RS) is\nstill limited, due to the scarcity of diverse remote-sensing visual-language\ndatasets. In this work we introduce two novel image-caption datasets for\ntraining of remote sensing foundation models. The first dataset pairs aerial\nand satellite imagery with captions generated by Gemini using landmarks\nextracted from Google Maps. The second dataset utilizes public web images and\ntheir corresponding alt-text, filtered for the remote sensing domain, resulting\nin a diverse dataset with greater breadth in image styles and subject matter.\nThese datasets are used to pre-train the\nMaMMUT~\\citep{kuo2023mammutsimplearchitecturejoint} VLM architecture, resulting\nin state-of-the-art generalization performance in zero-shot cross-modal\nretrieval on well-known public benchmarks. Finally, we present our ongoing\nresearch to distill image-level knowledge gained in the VLM contrastive\ntraining procedure to enhance the model's localization ability. Specifically,\nwe iteratively generate pseudo-labels for image regions based on the model's\nattention maps and use these labels for further training. To mitigate noisy\nattention maps and create robust segmentation masks, we introduce a novel\nattention-pooling mechanism called the Smooth-Attention-Operation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.08722v2",
    "published_date": "2025-03-10 21:09:02 UTC",
    "updated_date": "2025-03-17 13:49:27 UTC"
  },
  {
    "arxiv_id": "2503.07852v1",
    "title": "CIMAGE: Exploiting the Conditional Independence in Masked Graph Auto-encoders",
    "authors": [
      "Jongwon Park",
      "Heesoo Jung",
      "Hogun Park"
    ],
    "abstract": "Recent Self-Supervised Learning (SSL) methods encapsulating relational\ninformation via masking in Graph Neural Networks (GNNs) have shown promising\nperformance. However, most existing approaches rely on random masking\nstrategies in either feature or graph space, which may fail to capture\ntask-relevant information fully. We posit that this limitation stems from an\ninability to achieve minimum redundancy between masked and unmasked components\nwhile ensuring maximum relevance of both to potential downstream tasks.\nConditional Independence (CI) inherently satisfies the minimum redundancy and\nmaximum relevance criteria, but its application typically requires access to\ndownstream labels. To address this challenge, we introduce CIMAGE, a novel\napproach that leverages Conditional Independence to guide an effective masking\nstrategy within the latent space. CIMAGE utilizes CI-aware latent factor\ndecomposition to generate two distinct contexts, leveraging high-confidence\npseudo-labels derived from unsupervised graph clustering. In this framework,\nthe pretext task involves reconstructing the masked second context solely from\nthe information provided by the first context. Our theoretical analysis further\nsupports the superiority of CIMAGE's novel CI-aware masking method by\ndemonstrating that the learned embedding exhibits approximate linear\nseparability, which enables accurate predictions for the downstream task.\nComprehensive evaluations across diverse graph benchmarks illustrate the\nadvantage of CIMAGE, with notably higher average rankings on node\nclassification and link prediction tasks. Notably, our proposed model\nhighlights the under-explored potential of CI in enhancing graph SSL\nmethodologies and offers enriched insights for effective graph representation\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the WSDM 2025 Oral. This is an extended version of the\n  original submission. Typos are also corrected",
    "pdf_url": "http://arxiv.org/pdf/2503.07852v1",
    "published_date": "2025-03-10 20:59:27 UTC",
    "updated_date": "2025-03-10 20:59:27 UTC"
  },
  {
    "arxiv_id": "2503.07849v1",
    "title": "Actual Causation and Nondeterministic Causal Models",
    "authors": [
      "Sander Beckers"
    ],
    "abstract": "In (Beckers, 2025) I introduced nondeterministic causal models as a\ngeneralization of Pearl's standard deterministic causal models. I here take\nadvantage of the increased expressivity offered by these models to offer a\nnovel definition of actual causation (that also applies to deterministic\nmodels). Instead of motivating the definition by way of (often subjective)\nintuitions about examples, I proceed by developing it based entirely on the\nunique function that it can fulfil in communicating and learning a causal\nmodel. First I generalize the more basic notion of counterfactual dependence,\nsecond I show how this notion has a vital role to play in the logic of causal\ndiscovery, third I introduce the notion of a structural simplification of a\ncausal model, and lastly I bring both notions together in my definition of\nactual causation. Although novel, the resulting definition arrives at verdicts\nthat are almost identical to those of my previous definition (Beckers, 2021,\n2022).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CLeaR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07849v1",
    "published_date": "2025-03-10 20:53:47 UTC",
    "updated_date": "2025-03-10 20:53:47 UTC"
  },
  {
    "arxiv_id": "2503.07848v1",
    "title": "Safe Explicable Policy Search",
    "authors": [
      "Akkamahadevi Hanni",
      "Jonathan MontaÃ±o",
      "Yu Zhang"
    ],
    "abstract": "When users work with AI agents, they form conscious or subconscious\nexpectations of them. Meeting user expectations is crucial for such agents to\nengage in successful interactions and teaming. However, users may form\nexpectations of an agent that differ from the agent's planned behaviors. These\ndifferences lead to the consideration of two separate decision models in the\nplanning process to generate explicable behaviors. However, little has been\ndone to incorporate safety considerations, especially in a learning setting. We\npresent Safe Explicable Policy Search (SEPS), which aims to provide a learning\napproach to explicable behavior generation while minimizing the safety risk,\nboth during and after learning. We formulate SEPS as a constrained optimization\nproblem where the agent aims to maximize an explicability score subject to\nconstraints on safety and a suboptimality criterion based on the agent's model.\nSEPS innovatively combines the capabilities of Constrained Policy Optimization\nand Explicable Policy Search. We evaluate SEPS in safety-gym environments and\nwith a physical robot experiment to show that it can learn explicable behaviors\nthat adhere to the agent's safety requirements and are efficient. Results show\nthat SEPS can generate safe and explicable behaviors while ensuring a desired\nlevel of performance w.r.t. the agent's objective, and has real-world relevance\nin human-AI teaming.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07848v1",
    "published_date": "2025-03-10 20:52:41 UTC",
    "updated_date": "2025-03-10 20:52:41 UTC"
  },
  {
    "arxiv_id": "2503.07833v1",
    "title": "HalluVerse25: Fine-grained Multilingual Benchmark Dataset for LLM Hallucinations",
    "authors": [
      "Samir Abdaljalil",
      "Hasan Kurban",
      "Erchin Serpedin"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in various contexts, yet\nremain prone to generating non-factual content, commonly referred to as\n\"hallucinations\". The literature categorizes hallucinations into several types,\nincluding entity-level, relation-level, and sentence-level hallucinations.\nHowever, existing hallucination datasets often fail to capture fine-grained\nhallucinations in multilingual settings. In this work, we introduce\nHalluVerse25, a multilingual LLM hallucination dataset that categorizes\nfine-grained hallucinations in English, Arabic, and Turkish. Our dataset\nconstruction pipeline uses an LLM to inject hallucinations into factual\nbiographical sentences, followed by a rigorous human annotation process to\nensure data quality. We evaluate several LLMs on HalluVerse25, providing\nvaluable insights into how proprietary models perform in detecting\nLLM-generated hallucinations across different contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07833v1",
    "published_date": "2025-03-10 20:24:07 UTC",
    "updated_date": "2025-03-10 20:24:07 UTC"
  },
  {
    "arxiv_id": "2503.07832v1",
    "title": "RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code",
    "authors": [
      "Dhruv Gautam",
      "Spandan Garg",
      "Jinu Jang",
      "Neel Sundaresan",
      "Roshanak Zilouchian Moghaddam"
    ],
    "abstract": "Recent advances in language model (LM) agents and function calling have\nenabled autonomous, feedback-driven systems to solve problems across various\ndigital domains. To better understand the unique limitations of LM agents, we\nintroduce RefactorBench, a benchmark consisting of 100 large handcrafted\nmulti-file refactoring tasks in popular open-source repositories. Solving tasks\nwithin RefactorBench requires thorough exploration of dependencies across\nmultiple files and strong adherence to relevant instructions. Every task is\ndefined by 3 natural language instructions of varying specificity and is\nmutually exclusive, allowing for the creation of longer combined tasks on the\nsame repository. Baselines on RefactorBench reveal that current LM agents\nstruggle with simple compositional tasks, solving only 22% of tasks with base\ninstructions, in contrast to a human developer with short time constraints\nsolving 87%. Through trajectory analysis, we identify various unique failure\nmodes of LM agents, and further explore the failure mode of tracking past\nactions. By adapting a baseline agent to condition on representations of state,\nwe achieve a 43.9% improvement in solving RefactorBench tasks. We further\nextend our state-aware approach to encompass entire digital environments and\noutline potential directions for future research. RefactorBench aims to support\nthe study of LM agents by providing a set of real-world, multi-hop tasks within\nthe realm of code.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE",
      "I.2.5"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2503.07832v1",
    "published_date": "2025-03-10 20:23:24 UTC",
    "updated_date": "2025-03-10 20:23:24 UTC"
  },
  {
    "arxiv_id": "2503.08720v1",
    "title": "AI for Just Work: Constructing Diverse Imaginations of AI beyond \"Replacing Humans\"",
    "authors": [
      "Weina Jin",
      "Nicholas Vincent",
      "Ghassan Hamarneh"
    ],
    "abstract": "The AI community usually focuses on \"how\" to develop AI techniques, but lacks\nthorough open discussions on \"why\" we develop AI. Lacking critical reflections\non the general visions and purposes of AI may make the community vulnerable to\nmanipulation. In this position paper, we explore the \"why\" question of AI. We\ndenote answers to the \"why\" question the imaginations of AI, which depict our\ngeneral visions, frames, and mindsets for the prospects of AI. We identify that\nthe prevailing vision in the AI community is largely a monoculture that\nemphasizes objectives such as replacing humans and improving productivity. Our\ncritical examination of this mainstream imagination highlights its underpinning\nand potentially unjust assumptions. We then call to diversify our collective\nimaginations of AI, embedding ethical assumptions from the outset in the\nimaginations of AI. To facilitate the community's pursuit of diverse\nimaginations, we demonstrate one process for constructing a new imagination of\n\"AI for just work,\" and showcase its application in the medical image synthesis\ntask to make it more ethical. We hope this work will help the AI community to\nopen dialogues with civil society on the visions and purposes of AI, and\ninspire more technical works and advocacy in pursuit of diverse and ethical\nimaginations to restore the value of AI for the public good.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.08720v1",
    "published_date": "2025-03-10 20:03:55 UTC",
    "updated_date": "2025-03-10 20:03:55 UTC"
  },
  {
    "arxiv_id": "2503.07817v1",
    "title": "Group Fairness in Multi-Task Reinforcement Learning",
    "authors": [
      "Kefan Song",
      "Runnan Jiang",
      "Rohan Chandra",
      "Shangtong Zhang"
    ],
    "abstract": "This paper addresses a critical societal consideration in the application of\nReinforcement Learning (RL): ensuring equitable outcomes across different\ndemographic groups in multi-task settings. While previous work has explored\nfairness in single-task RL, many real-world applications are multi-task in\nnature and require policies to maintain fairness across all tasks. We introduce\na novel formulation of multi-task group fairness in RL and propose a\nconstrained optimization algorithm that explicitly enforces fairness\nconstraints across multiple tasks simultaneously. We have shown that our\nproposed algorithm does not violate fairness constraints with high probability\nand with sublinear regret in the finite-horizon episodic setting. Through\nexperiments in RiverSwim and MuJoCo environments, we demonstrate that our\napproach better ensures group fairness across multiple tasks compared to\nprevious methods that lack explicit multi-task fairness constraints in both the\nfinite-horizon setting and the infinite-horizon setting. Our results show that\nthe proposed algorithm achieves smaller fairness gaps while maintaining\ncomparable returns across different demographic groups and tasks, suggesting\nits potential for addressing fairness concerns in real-world multi-task RL\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07817v1",
    "published_date": "2025-03-10 19:59:59 UTC",
    "updated_date": "2025-03-10 19:59:59 UTC"
  },
  {
    "arxiv_id": "2503.07813v1",
    "title": "AgriField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel",
    "authors": [
      "Elvis Kimara",
      "Mozhgan Hadadi",
      "Jackson Godbersen",
      "Aditya Balu",
      "Talukder Jubery",
      "Yawei Li",
      "Adarsh Krishnamurthy",
      "Patrick S. Schnable",
      "Baskar Ganapathysubramanian"
    ],
    "abstract": "The application of artificial intelligence (AI) in three-dimensional (3D)\nagricultural research, particularly for maize, has been limited by the scarcity\nof large-scale, diverse datasets. While 2D image datasets are abundant, they\nfail to capture essential structural details such as leaf architecture, plant\nvolume, and spatial arrangements that 3D data provide. To address this\nlimitation, we present AgriField3D\n(https://baskargroup.github.io/AgriField3D/), a curated dataset of 3D point\nclouds of field-grown maize plants from a diverse genetic panel, designed to be\nAI-ready for advancing agricultural research. Our dataset comprises over 1,000\nhigh-quality point clouds collected using a Terrestrial Laser Scanner,\ncomplemented by procedural models that provide structured, parametric\nrepresentations of maize plants. These procedural models, generated using\nNon-Uniform Rational B-Splines (NURBS) and optimized via a two-step process\ncombining Particle Swarm Optimization (PSO) and differentiable programming,\nenable precise, scalable reconstructions of leaf surfaces and plant\narchitectures. To enhance usability, we performed graph-based segmentation to\nisolate individual leaves and stalks, ensuring consistent labeling across all\nsamples. We also conducted rigorous manual quality control on all datasets,\ncorrecting errors in segmentation, ensuring accurate leaf ordering, and\nvalidating metadata annotations. The dataset further includes metadata\ndetailing plant morphology and quality, alongside multi-resolution subsampled\nversions (100k, 50k, 10k points) optimized for various computational needs. By\nintegrating point cloud data of field grown plants with high-fidelity\nprocedural models and ensuring meticulous manual validation, AgriField3D\nprovides a comprehensive foundation for AI-driven phenotyping, plant structural\nanalysis, and 3D applications in agricultural research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Elvis Kimara and Mozhgan Hadadi contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2503.07813v1",
    "published_date": "2025-03-10 19:53:20 UTC",
    "updated_date": "2025-03-10 19:53:20 UTC"
  },
  {
    "arxiv_id": "2503.07811v2",
    "title": "A primer on optimal transport for causal inference with observational data",
    "authors": [
      "Florian F Gunsilius"
    ],
    "abstract": "The theory of optimal transportation has developed into a powerful and\nelegant framework for comparing probability distributions, with wide-ranging\napplications in all areas of science. The fundamental idea of analyzing\nprobabilities by comparing their underlying state space naturally aligns with\nthe core idea of causal inference, where understanding and quantifying\ncounterfactual states is paramount. Despite this intuitive connection, explicit\nresearch at the intersection of optimal transport and causal inference is only\nbeginning to develop. Yet, many foundational models in causal inference have\nimplicitly relied on optimal transport principles for decades, without\nrecognizing the underlying connection. Therefore, the goal of this review is to\noffer an introduction to the surprisingly deep existing connections between\noptimal transport and the identification of causal effects with observational\ndata -- where optimal transport is not just a set of potential tools, but\nactually builds the foundation of model assumptions. As a result, this review\nis intended to unify the language and notation between different areas of\nstatistics, mathematics, and econometrics, by pointing out these existing\nconnections, and to explore novel problems and directions for future work in\nboth areas derived from this realization.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "econ.EM"
    ],
    "primary_category": "stat.ME",
    "comment": "24 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07811v2",
    "published_date": "2025-03-10 19:51:37 UTC",
    "updated_date": "2025-03-12 18:18:00 UTC"
  },
  {
    "arxiv_id": "2503.11695v1",
    "title": "MELON: Multimodal Mixture-of-Experts with Spectral-Temporal Fusion for Long-Term Mobility Estimation in Critical Care",
    "authors": [
      "Jiaqing Zhang",
      "Miguel Contreras",
      "Jessica Sena",
      "Andrea Davidson",
      "Yuanfang Ren",
      "Ziyuan Guan",
      "Tezcan Ozrazgat-Baslanti",
      "Tyler J. Loftus",
      "Subhash Nerella",
      "Azra Bihorac",
      "Parisa Rashidi"
    ],
    "abstract": "Patient mobility monitoring in intensive care is critical for ensuring timely\ninterventions and improving clinical outcomes. While accelerometry-based sensor\ndata are widely adopted in training artificial intelligence models to estimate\npatient mobility, existing approaches face two key limitations highlighted in\nclinical practice: (1) modeling the long-term accelerometer data is challenging\ndue to the high dimensionality, variability, and noise, and (2) the absence of\nefficient and robust methods for long-term mobility assessment. To overcome\nthese challenges, we introduce MELON, a novel multimodal framework designed to\npredict 12-hour mobility status in the critical care setting. MELON leverages\nthe power of a dual-branch network architecture, combining the strengths of\nspectrogram-based visual representations and sequential accelerometer\nstatistical features. MELON effectively captures global and fine-grained\nmobility patterns by integrating a pre-trained image encoder for rich\nfrequency-domain feature extraction and a Mixture-of-Experts encoder for\nsequence modeling. We trained and evaluated the MELON model on the multimodal\ndataset of 126 patients recruited from nine Intensive Care Units at the\nUniversity of Florida Health Shands Hospital main campus in Gainesville,\nFlorida. Experiments showed that MELON outperforms conventional approaches for\n12-hour mobility status estimation with an overall area under the receiver\noperating characteristic curve (AUROC) of 0.82 (95\\%, confidence interval\n0.78-0.86). Notably, our experiments also revealed that accelerometer data\ncollected from the wrist provides robust predictive performance compared with\ndata from the ankle, suggesting a single-sensor solution that can reduce\npatient burden and lower deployment costs...",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.11695v1",
    "published_date": "2025-03-10 19:47:46 UTC",
    "updated_date": "2025-03-10 19:47:46 UTC"
  },
  {
    "arxiv_id": "2503.07807v1",
    "title": "Training Domain Draft Models for Speculative Decoding: Best Practices and Insights",
    "authors": [
      "Fenglu Hong",
      "Ravi Raju",
      "Jonathan Lingjie Li",
      "Bo Li",
      "Urmish Thakker",
      "Avinash Ravichandran",
      "Swayambhoo Jain",
      "Changran Hu"
    ],
    "abstract": "Speculative decoding is an effective method for accelerating inference of\nlarge language models (LLMs) by employing a small draft model to predict the\noutput of a target model. However, when adapting speculative decoding to\ndomain-specific target models, the acceptance rate of the generic draft model\ndrops significantly due to domain shift. In this work, we systematically\ninvestigate knowledge distillation techniques for training domain draft models\nto improve their speculation accuracy. We compare white-box and black-box\ndistillation approaches and explore their effectiveness in various data\naccessibility scenarios, including historical user queries, curated domain\ndata, and synthetically generated alignment data. Our experiments across\nFunction Calling, Biology, and Chinese domains show that offline distillation\nconsistently outperforms online distillation by 11% to 25%, white-box\ndistillation surpasses black-box distillation by 2% to 10%, and data scaling\ntrends hold across domains. Additionally, we find that synthetic data can\neffectively align draft models and achieve 80% to 93% of the performance of\ntraining on historical user queries. These findings provide practical\nguidelines for training domain-specific draft models to improve speculative\ndecoding efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published as a workshop paper at SCOPE - ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07807v1",
    "published_date": "2025-03-10 19:40:25 UTC",
    "updated_date": "2025-03-10 19:40:25 UTC"
  },
  {
    "arxiv_id": "2503.07806v1",
    "title": "Towards Large Language Models that Benefit for All: Benchmarking Group Fairness in Reward Models",
    "authors": [
      "Kefan Song",
      "Jin Yao",
      "Runnan Jiang",
      "Rohan Chandra",
      "Shangtong Zhang"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly powerful and accessible\nto human users, ensuring fairness across diverse demographic groups, i.e.,\ngroup fairness, is a critical ethical concern. However, current fairness and\nbias research in LLMs is limited in two aspects. First, compared to traditional\ngroup fairness in machine learning classification, it requires that the\nnon-sensitive attributes, in this case, the prompt questions, be the same\nacross different groups. In many practical scenarios, different groups,\nhowever, may prefer different prompt questions and this requirement becomes\nimpractical. Second, it evaluates group fairness only for the LLM's final\noutput without identifying the source of possible bias. Namely, the bias in\nLLM's output can result from both the pretraining and the finetuning. For\nfinetuning, the bias can result from both the RLHF procedure and the learned\nreward model. Arguably, evaluating the group fairness of each component in the\nLLM pipeline could help develop better methods to mitigate the possible bias.\nRecognizing those two limitations, this work benchmarks the group fairness of\nlearned reward models. By using expert-written text from arXiv, we are able to\nbenchmark the group fairness of reward models without requiring the same prompt\nquestions across different demographic groups. Surprisingly, our results\ndemonstrate that all the evaluated reward models (e.g., Nemotron-4-340B-Reward,\nArmoRM-Llama3-8B-v0.1, and GRM-llama3-8B-sftreg) exhibit statistically\nsignificant group unfairness. We also observed that top-performing reward\nmodels (w.r.t. canonical performance metrics) tend to demonstrate better group\nfairness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07806v1",
    "published_date": "2025-03-10 19:39:39 UTC",
    "updated_date": "2025-03-10 19:39:39 UTC"
  },
  {
    "arxiv_id": "2503.07799v1",
    "title": "Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos",
    "authors": [
      "Pramit Saha",
      "Divyanshu Mishra",
      "Netzahualcoyotl Hernandez-Cruz",
      "Olga Patey",
      "Aris Papageorghiou",
      "Yuki M. Asano",
      "J. Alison Noble"
    ],
    "abstract": "Congenital Heart Disease (CHD) is one of the leading causes of fetal\nmortality, yet the scarcity of labeled CHD data and strict privacy regulations\nsurrounding fetal ultrasound (US) imaging present significant challenges for\nthe development of deep learning-based models for CHD detection. Centralised\ncollection of large real-world datasets for rare conditions, such as CHD, from\nlarge populations requires significant co-ordination and resource. In addition,\ndata governance rules increasingly prevent data sharing between sites. To\naddress these challenges, we introduce, for the first time, a novel\nprivacy-preserving, zero-shot CHD detection framework that formulates CHD\ndetection as a normality modeling problem integrated with model merging. In our\nframework dubbed Sparse Tube Ultrasound Distillation (STUD), each hospital site\nfirst trains a sparse video tube-based self-supervised video anomaly detection\n(VAD) model on normal fetal heart US clips with self-distillation loss. This\nenables site-specific models to independently learn the distribution of healthy\ncases. To aggregate knowledge across the decentralized models while maintaining\nprivacy, we propose a Divergence Vector-Guided Model Merging approach,\nDivMerge, that combines site-specific models into a single VAD model without\ndata exchange. Our approach preserves domain-agnostic rich spatio-temporal\nrepresentations, ensuring generalization to unseen CHD cases. We evaluated our\napproach on real-world fetal US data collected from 5 hospital sites. Our\nmerged model outperformed site-specific models by 23.77% and 30.13% in accuracy\nand F1-score respectively on external test sets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07799v1",
    "published_date": "2025-03-10 19:27:15 UTC",
    "updated_date": "2025-03-10 19:27:15 UTC"
  },
  {
    "arxiv_id": "2503.07792v1",
    "title": "Efficient Neural Clause-Selection Reinforcement",
    "authors": [
      "Martin Suda"
    ],
    "abstract": "Clause selection is arguably the most important choice point in\nsaturation-based theorem proving. Framing it as a reinforcement learning (RL)\ntask is a way to challenge the human-designed heuristics of state-of-the-art\nprovers and to instead automatically evolve -- just from prover experiences --\ntheir potentially optimal replacement. In this work, we present a neural\nnetwork architecture for scoring clauses for clause selection that is powerful\nyet efficient to evaluate. Following RL principles to make design decisions, we\nintegrate the network into the Vampire theorem prover and train it from\nsuccessful proof attempts. An experiment on the diverse TPTP benchmark finds\nthe neurally guided prover improve over a baseline strategy, from which it\ninitially learns--in terms of the number of in-training-unseen problems solved\nunder a practically relevant, short CPU instruction limit--by 20%.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages main text, 3 page bibliography, 6 page appendix",
    "pdf_url": "http://arxiv.org/pdf/2503.07792v1",
    "published_date": "2025-03-10 19:14:48 UTC",
    "updated_date": "2025-03-10 19:14:48 UTC"
  },
  {
    "arxiv_id": "2503.10675v1",
    "title": "Beyond One-Size-Fits-All Summarization: Customizing Summaries for Diverse Users",
    "authors": [
      "Mehmet Samet Duran",
      "Tevfik Aytekin"
    ],
    "abstract": "In recent years, automatic text summarization has witnessed significant\nadvancement, particularly with the development of transformer-based models.\nHowever, the challenge of controlling the readability level of generated\nsummaries remains an under-explored area, especially for languages with complex\nlinguistic features like Turkish. This gap has the effect of impeding effective\ncommunication and also limits the accessibility of information. Controlling\nreadability of textual data is an important element for creating summaries for\ndifferent audiences with varying literacy and education levels, such as\nstudents ranging from primary school to graduate level, as well as individuals\nwith diverse educational backgrounds. Summaries that align with the needs of\nspecific reader groups can improve comprehension and engagement, ensuring that\nthe intended message is effectively communicated. Furthermore, readability\nadjustment is essential to expand the usability of summarization models in\neducational and professional domains. Current summarization models often don't\nhave the mechanisms to adjust the complexity of their outputs, resulting in\nsummaries that may be too simplistic or overly complex for certain types of\nreader groups. Developing adaptive models that can tailor content to specific\nreadability levels is therefore crucial. To address this problem, we create our\nown custom dataset and train a model with our custom architecture. Our method\nensures that readability levels are effectively controlled while maintaining\naccuracy and coherence. We rigorously compare our model to a supervised\nfine-tuned baseline, demonstrating its superiority in generating\nreadability-aware summaries.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2503.10675v1",
    "published_date": "2025-03-10 19:08:36 UTC",
    "updated_date": "2025-03-10 19:08:36 UTC"
  },
  {
    "arxiv_id": "2503.07784v1",
    "title": "Joint Explainability-Performance Optimization With Surrogate Models for AI-Driven Edge Services",
    "authors": [
      "Foivos Charalampakos",
      "Thomas Tsouparopoulos",
      "Iordanis Koutsopoulos"
    ],
    "abstract": "Explainable AI is a crucial component for edge services, as it ensures\nreliable decision making based on complex AI models. Surrogate models are a\nprominent approach of XAI where human-interpretable models, such as a linear\nregression model, are trained to approximate a complex (black-box) model's\npredictions. This paper delves into the balance between the predictive accuracy\nof complex AI models and their approximation by surrogate ones, advocating that\nboth these models benefit from being learned simultaneously. We derive a joint\n(bi-level) training scheme for both models and we introduce a new algorithm\nbased on multi-objective optimization (MOO) to simultaneously minimize both the\ncomplex model's prediction error and the error between its outputs and those of\nthe surrogate. Our approach leads to improvements that exceed 99% in the\napproximation of the black-box model through the surrogate one, as measured by\nthe metric of Fidelity, for a compromise of less than 3% absolute reduction in\nthe black-box model's predictive accuracy, compared to single-task and\nmulti-task learning baselines. By improving Fidelity, we can derive more\ntrustworthy explanations of the complex model's outcomes from the surrogate,\nenabling reliable AI applications for intelligent services at the network edge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07784v1",
    "published_date": "2025-03-10 19:04:09 UTC",
    "updated_date": "2025-03-10 19:04:09 UTC"
  },
  {
    "arxiv_id": "2503.07783v1",
    "title": "Sensemaking in Novel Environments: How Human Cognition Can Inform Artificial Agents",
    "authors": [
      "Robert E. Patterson",
      "Regina Buccello-Stout",
      "Mary E. Frame",
      "Anna M. Maresca",
      "Justin Nelson",
      "Barbara Acker-Mills",
      "Erica Curtis",
      "Jared Culbertson",
      "Kevin Schmidt",
      "Scott Clouse",
      "Steve Rogers"
    ],
    "abstract": "One of the most vital cognitive skills to possess is the ability to make\nsense of objects, events, and situations in the world. In the current paper, we\noffer an approach for creating artificially intelligent agents with the\ncapacity for sensemaking in novel environments. Objectives: to present several\nkey ideas: (1) a novel unified conceptual framework for sensemaking (which\nincludes the existence of sign relations embedded within and across frames);\n(2) interaction among various content-addressable, distributed-knowledge\nstructures via shared attributes (whose net response would represent a\nsynthesized object, event, or situation serving as a sign for sensemaking in a\nnovel environment). Findings: we suggest that attributes across memories can be\nshared and recombined in novel ways to create synthesized signs, which can\ndenote certain outcomes in novel environments (i.e., sensemaking).",
    "categories": [
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07783v1",
    "published_date": "2025-03-10 19:03:09 UTC",
    "updated_date": "2025-03-10 19:03:09 UTC"
  },
  {
    "arxiv_id": "2503.07770v1",
    "title": "Evaluating LLaMA 3.2 for Software Vulnerability Detection",
    "authors": [
      "JosÃ© GonÃ§alves",
      "Miguel Silva",
      "Bernardo Cabral",
      "Tiago Dias",
      "Eva Maia",
      "Isabel PraÃ§a",
      "Ricardo Severino",
      "LuÃ­s Lino Ferreira"
    ],
    "abstract": "Deep Learning (DL) has emerged as a powerful tool for vulnerability\ndetection, often outperforming traditional solutions. However, developing\neffective DL models requires large amounts of real-world data, which can be\ndifficult to obtain in sufficient quantities. To address this challenge,\nDiverseVul dataset has been curated as the largest dataset of vulnerable and\nnon-vulnerable C/C++ functions extracted exclusively from real-world projects.\nIts goal is to provide high-quality, large-scale samples for training DL\nmodels. However, during our study several inconsistencies were identified in\nthe raw dataset while applying pre-processing techniques, highlighting the need\nfor a refined version. In this work, we present a refined version of DiverseVul\ndataset, which is used to fine-tune a large language model, LLaMA 3.2, for\nvulnerability detection. Experimental results show that the use of\npre-processing techniques led to an improvement in performance, with the model\nachieving an F1-Score of 66%, a competitive result when compared to our\nbaseline, which achieved a 47% F1-Score in software vulnerability detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 4 tables, EICC 2025: European Interdisciplinary\n  Cybersecurity Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07770v1",
    "published_date": "2025-03-10 18:47:41 UTC",
    "updated_date": "2025-03-10 18:47:41 UTC"
  },
  {
    "arxiv_id": "2503.10674v1",
    "title": "Enhancing Retrieval for ESGLLM via ESG-CID -- A Disclosure Content Index Finetuning Dataset for Mapping GRI and ESRS",
    "authors": [
      "Shafiuddin Rehan Ahmed",
      "Ankit Parag Shah",
      "Quan Hung Tran",
      "Vivek Khetan",
      "Sukryool Kang",
      "Ankit Mehta",
      "Yujia Bao",
      "Wei Wei"
    ],
    "abstract": "Climate change has intensified the need for transparency and accountability\nin organizational practices, making Environmental, Social, and Governance (ESG)\nreporting increasingly crucial. Frameworks like the Global Reporting Initiative\n(GRI) and the new European Sustainability Reporting Standards (ESRS) aim to\nstandardize ESG reporting, yet generating comprehensive reports remains\nchallenging due to the considerable length of ESG documents and variability in\ncompany reporting styles. To facilitate ESG report automation,\nRetrieval-Augmented Generation (RAG) systems can be employed, but their\ndevelopment is hindered by a lack of labeled data suitable for training\nretrieval models. In this paper, we leverage an underutilized source of weak\nsupervision -- the disclosure content index found in past ESG reports -- to\ncreate a comprehensive dataset, ESG-CID, for both GRI and ESRS standards. By\nextracting mappings between specific disclosure requirements and corresponding\nreport sections, and refining them using a Large Language Model as a judge, we\ngenerate a robust training and evaluation set. We benchmark popular embedding\nmodels on this dataset and show that fine-tuning BERT-based models can\noutperform commercial embeddings and leading public models, even under temporal\ndata splits for cross-report style transfer from GRI to ESRS",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Long paper",
    "pdf_url": "http://arxiv.org/pdf/2503.10674v1",
    "published_date": "2025-03-10 18:07:33 UTC",
    "updated_date": "2025-03-10 18:07:33 UTC"
  },
  {
    "arxiv_id": "2503.07737v1",
    "title": "A Simple Approach to Constraint-Aware Imitation Learning with Application to Autonomous Racing",
    "authors": [
      "Shengfan Cao",
      "Eunhyek Joa",
      "Francesco Borrelli"
    ],
    "abstract": "Guaranteeing constraint satisfaction is challenging in imitation learning\n(IL), particularly in tasks that require operating near a system's handling\nlimits. Traditional IL methods often struggle to enforce constraints, leading\nto suboptimal performance in high-precision tasks. In this paper, we present a\nsimple approach to incorporating safety into the IL objective. Through\nsimulations, we empirically validate our approach on an autonomous racing task\nwith both full-state and image feedback, demonstrating improved constraint\nsatisfaction and greater consistency in task performance compared to a baseline\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to IEEE IROS 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07737v1",
    "published_date": "2025-03-10 18:00:16 UTC",
    "updated_date": "2025-03-10 18:00:16 UTC"
  },
  {
    "arxiv_id": "2503.07600v1",
    "title": "A Representationalist, Functionalist and Naturalistic Conception of Intelligence as a Foundation for AGI",
    "authors": [
      "Rolf Pfister"
    ],
    "abstract": "The article analyses foundational principles relevant to the creation of\nartificial general intelligence (AGI). Intelligence is understood as the\nability to create novel skills that allow to achieve goals under previously\nunknown conditions. To this end, intelligence utilises reasoning methods such\nas deduction, induction and abduction as well as other methods such as\nabstraction and classification to develop a world model. The methods are\napplied to indirect and incomplete representations of the world, which are\nobtained through perception, for example, and which do not depict the world but\nonly correspond to it. Due to these limitations and the uncertain and\ncontingent nature of reasoning, the world model is constructivist. Its value is\nfunctionally determined by its viability, i.e., its potential to achieve the\ndesired goals. In consequence, meaning is assigned to representations by\nattributing them a function that makes it possible to achieve a goal. This\nrepresentational and functional conception of intelligence enables a\nnaturalistic interpretation that does not presuppose mental features, such as\nintentionality and consciousness, which are regarded as independent of\nintelligence. Based on a phenomenological analysis, it is shown that AGI can\ngain a more fundamental access to the world than humans, although it is limited\nby the No Free Lunch theorems, which require assumptions to be made.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07600v1",
    "published_date": "2025-03-10 17:58:00 UTC",
    "updated_date": "2025-03-10 17:58:00 UTC"
  },
  {
    "arxiv_id": "2503.07599v1",
    "title": "NeuroChat: A Neuroadaptive AI Chatbot for Customizing Learning Experiences",
    "authors": [
      "DÃ¼nya Baradari",
      "Nataliya Kosmyna",
      "Oscar Petrov",
      "Rebecah Kaplun",
      "Pattie Maes"
    ],
    "abstract": "Generative AI is transforming education by enabling personalized, on-demand\nlearning experiences. However, AI tutors lack the ability to assess a learner's\ncognitive state in real time, limiting their adaptability. Meanwhile,\nelectroencephalography (EEG)-based neuroadaptive systems have successfully\nenhanced engagement by dynamically adjusting learning content. This paper\npresents NeuroChat, a proof-of-concept neuroadaptive AI tutor that integrates\nreal-time EEG-based engagement tracking with generative AI. NeuroChat\ncontinuously monitors a learner's cognitive engagement and dynamically adjusts\ncontent complexity, response style, and pacing using a closed-loop system. We\nevaluate this approach in a pilot study (n=24), comparing NeuroChat to a\nstandard LLM-based chatbot. Results indicate that NeuroChat enhances cognitive\nand subjective engagement but does not show an immediate effect on learning\noutcomes. These findings demonstrate the feasibility of real-time cognitive\nfeedback in LLMs, highlighting new directions for adaptive learning, AI\ntutoring, and human-AI interaction.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "I.2.7; J.0; K.3.1; K.8.0; C.3"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages, 6 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.07599v1",
    "published_date": "2025-03-10 17:57:20 UTC",
    "updated_date": "2025-03-10 17:57:20 UTC"
  },
  {
    "arxiv_id": "2503.07596v1",
    "title": "Denoising Hamiltonian Network for Physical Reasoning",
    "authors": [
      "Congyue Deng",
      "Brandon Y. Feng",
      "Cecilia Garraffo",
      "Alan Garbarz",
      "Robin Walters",
      "William T. Freeman",
      "Leonidas Guibas",
      "Kaiming He"
    ],
    "abstract": "Machine learning frameworks for physical problems must capture and enforce\nphysical constraints that preserve the structure of dynamical systems. Many\nexisting approaches achieve this by integrating physical operators into neural\nnetworks. While these methods offer theoretical guarantees, they face two key\nlimitations: (i) they primarily model local relations between adjacent time\nsteps, overlooking longer-range or higher-level physical interactions, and (ii)\nthey focus on forward simulation while neglecting broader physical reasoning\ntasks. We propose the Denoising Hamiltonian Network (DHN), a novel framework\nthat generalizes Hamiltonian mechanics operators into more flexible neural\noperators. DHN captures non-local temporal relationships and mitigates\nnumerical integration errors through a denoising mechanism. DHN also supports\nmulti-system modeling with a global conditioning mechanism. We demonstrate its\neffectiveness and flexibility across three diverse physical reasoning tasks\nwith distinct inputs and outputs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07596v1",
    "published_date": "2025-03-10 17:57:01 UTC",
    "updated_date": "2025-03-10 17:57:01 UTC"
  },
  {
    "arxiv_id": "2503.07591v1",
    "title": "Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning",
    "authors": [
      "Bardia Safaei",
      "Faizan Siddiqui",
      "Jiacong Xu",
      "Vishal M. Patel",
      "Shao-Yuan Lo"
    ],
    "abstract": "Visual instruction tuning (VIT) for large vision-language models (LVLMs)\nrequires training on expansive datasets of image-instruction pairs, which can\nbe costly. Recent efforts in VIT data selection aim to select a small subset of\nhigh-quality image-instruction pairs, reducing VIT runtime while maintaining\nperformance comparable to full-scale training. However, a major challenge often\noverlooked is that generating instructions from unlabeled images for VIT is\nhighly expensive. Most existing VIT datasets rely heavily on human annotations\nor paid services like the GPT API, which limits users with constrained\nresources from creating VIT datasets for custom applications. To address this,\nwe introduce Pre-Instruction Data Selection (PreSel), a more practical data\nselection paradigm that directly selects the most beneficial unlabeled images\nand generates instructions only for the selected images. PreSel first estimates\nthe relative importance of each vision task within VIT datasets to derive\ntask-wise sampling budgets. It then clusters image features within each task,\nselecting the most representative images with the budget. This approach reduces\ncomputational overhead for both instruction generation during VIT data\nformation and LVLM fine-tuning. By generating instructions for only 15% of the\nimages, PreSel achieves performance comparable to full-data VIT on the\nLLaVA-1.5 and Vision-Flan datasets. The link to our project page:\nhttps://bardisafa.github.io/PreSel",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at Computer Vision and Pattern Recognition Conference (CVPR)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07591v1",
    "published_date": "2025-03-10 17:55:11 UTC",
    "updated_date": "2025-03-10 17:55:11 UTC"
  },
  {
    "arxiv_id": "2503.07588v2",
    "title": "When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning",
    "authors": [
      "Junwei Luo",
      "Yingying Zhang",
      "Xue Yang",
      "Kang Wu",
      "Qi Zhu",
      "Lei Liang",
      "Jingdong Chen",
      "Yansheng Li"
    ],
    "abstract": "Efficient vision-language understanding of large Remote Sensing Images (RSIs)\nis meaningful but challenging. Current Large Vision-Language Models (LVLMs)\ntypically employ limited pre-defined grids to process images, leading to\ninformation loss when handling gigapixel RSIs. Conversely, using unlimited\ngrids significantly increases computational costs. To preserve image details\nwhile reducing computational complexity, we propose a text-guided token pruning\nmethod with Dynamic Image Pyramid (DIP) integration. Our method introduces: (i)\na Region Focus Module (RFM) that leverages text-aware region localization\ncapability to identify critical vision tokens, and (ii) a coarse-to-fine image\ntile selection and vision token pruning strategy based on DIP, which is guided\nby RFM outputs and avoids directly processing the entire large imagery.\nAdditionally, existing benchmarks for evaluating LVLMs' perception ability on\nlarge RSI suffer from limited question diversity and constrained image sizes.\nWe construct a new benchmark named LRS-VQA, which contains 7,333 QA pairs\nacross 8 categories, with image length up to 27,328 pixels. Our method\noutperforms existing high-resolution strategies on four datasets using the same\ndata. Moreover, compared to existing token reduction methods, our approach\ndemonstrates higher efficiency under high-resolution settings. Dataset and code\nare in https://github.com/VisionXLab/LRS-VQA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 6 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.07588v2",
    "published_date": "2025-03-10 17:51:16 UTC",
    "updated_date": "2025-03-25 15:05:34 UTC"
  },
  {
    "arxiv_id": "2503.07587v1",
    "title": "Robusto-1 Dataset: Comparing Humans and VLMs on real out-of-distribution Autonomous Driving VQA from Peru",
    "authors": [
      "Dunant Cusipuma",
      "David Ortega",
      "Victor Flores-Benites",
      "Arturo Deza"
    ],
    "abstract": "As multimodal foundational models start being deployed experimentally in\nSelf-Driving cars, a reasonable question we ask ourselves is how similar to\nhumans do these systems respond in certain driving situations -- especially\nthose that are out-of-distribution? To study this, we create the Robusto-1\ndataset that uses dashcam video data from Peru, a country with one of the worst\n(aggressive) drivers in the world, a high traffic index, and a high ratio of\nbizarre to non-bizarre street objects likely never seen in training. In\nparticular, to preliminarly test at a cognitive level how well Foundational\nVisual Language Models (VLMs) compare to Humans in Driving, we move away from\nbounding boxes, segmentation maps, occupancy maps or trajectory estimation to\nmulti-modal Visual Question Answering (VQA) comparing both humans and machines\nthrough a popular method in systems neuroscience known as Representational\nSimilarity Analysis (RSA). Depending on the type of questions we ask and the\nanswers these systems give, we will show in what cases do VLMs and Humans\nconverge or diverge allowing us to probe on their cognitive alignment. We find\nthat the degree of alignment varies significantly depending on the type of\nquestions asked to each type of system (Humans vs VLMs), highlighting a gap in\ntheir alignment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "A pre-print. 26 pages. Link to Code + Data:\n  https://huggingface.co/datasets/Artificio/robusto-1",
    "pdf_url": "http://arxiv.org/pdf/2503.07587v1",
    "published_date": "2025-03-10 17:50:04 UTC",
    "updated_date": "2025-03-10 17:50:04 UTC"
  },
  {
    "arxiv_id": "2503.07578v1",
    "title": "Denoising Score Distillation: From Noisy Diffusion Pretraining to One-Step High-Quality Generation",
    "authors": [
      "Tianyu Chen",
      "Yasi Zhang",
      "Zhendong Wang",
      "Ying Nian Wu",
      "Oscar Leong",
      "Mingyuan Zhou"
    ],
    "abstract": "Diffusion models have achieved remarkable success in generating\nhigh-resolution, realistic images across diverse natural distributions.\nHowever, their performance heavily relies on high-quality training data, making\nit challenging to learn meaningful distributions from corrupted samples. This\nlimitation restricts their applicability in scientific domains where clean data\nis scarce or costly to obtain. In this work, we introduce denoising score\ndistillation (DSD), a surprisingly effective and novel approach for training\nhigh-quality generative models from low-quality data. DSD first pretrains a\ndiffusion model exclusively on noisy, corrupted samples and then distills it\ninto a one-step generator capable of producing refined, clean outputs. While\nscore distillation is traditionally viewed as a method to accelerate diffusion\nmodels, we show that it can also significantly enhance sample quality,\nparticularly when starting from a degraded teacher model. Across varying noise\nlevels and datasets, DSD consistently improves generative performancewe\nsummarize our empirical evidence in Fig. 1. Furthermore, we provide theoretical\ninsights showing that, in a linear model setting, DSD identifies the eigenspace\nof the clean data distributions covariance matrix, implicitly regularizing the\ngenerator. This perspective reframes score distillation as not only a tool for\nefficiency but also a mechanism for improving generative models, particularly\nin low-quality data settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "First Author and Second Author contributed equally to this work. The\n  last two authors equally advised this work",
    "pdf_url": "http://arxiv.org/pdf/2503.07578v1",
    "published_date": "2025-03-10 17:44:46 UTC",
    "updated_date": "2025-03-10 17:44:46 UTC"
  },
  {
    "arxiv_id": "2503.07701v1",
    "title": "Automated Benchmark Generation for Repository-Level Coding Tasks",
    "authors": [
      "Konstantinos Vergopoulos",
      "Mark Niklas MÃ¼ller",
      "Martin Vechev"
    ],
    "abstract": "Code Agent development is an extremely active research area, where a reliable\nperformance metric is critical for tracking progress and guiding new\ndevelopments. This demand is underscored by the meteoric rise in popularity of\nSWE-Bench. This benchmark challenges code agents to generate patches addressing\nGitHub issues given the full repository as context. The correctness of\ngenerated patches is then evaluated by executing a human-written test suite\nextracted from the repository after the issue's resolution. However,\nconstructing benchmarks like SWE-Bench requires substantial manual effort to\nset up historically accurate execution environments for testing. Crucially,\nthis severely limits the number of considered repositories, e.g., just 12 for\nSWE-Bench. Considering so few repositories, selected for their popularity runs\nthe risk of leading to a distributional mismatch, i.e., the measured\nperformance may not be representative of real-world scenarios potentially\nmisguiding development efforts. In this work, we address this challenge and\nintroduce SetUpAgent, a fully automated system capable of historically accurate\ndependency setup, test execution, and result parsing. Using SetUpAgent, we\ngenerate two new datasets: (i) SWEE-Bench an extended version of SWE-Bench\nencompassing hundreds of repositories, and (ii) SWA-Bench a benchmark focusing\non applications rather than libraries. Comparing these datasets to SWE-Bench\nwith respect to their characteristics and code agent performance, we find\nsignificant distributional differences, including lower issue description\nquality and detail level, higher fix complexity, and most importantly up to 40%\nlower agent success rates.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at DL4C@ICLR'25 and FMWild@ICLR'25",
    "pdf_url": "http://arxiv.org/pdf/2503.07701v1",
    "published_date": "2025-03-10 17:42:49 UTC",
    "updated_date": "2025-03-10 17:42:49 UTC"
  },
  {
    "arxiv_id": "2503.07572v1",
    "title": "Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning",
    "authors": [
      "Yuxiao Qu",
      "Matthew Y. R. Yang",
      "Amrith Setlur",
      "Lewis Tunstall",
      "Edward Emanuel Beeching",
      "Ruslan Salakhutdinov",
      "Aviral Kumar"
    ],
    "abstract": "Training models to effectively use test-time compute is crucial for improving\nthe reasoning performance of LLMs. Current methods mostly do so via fine-tuning\non search traces or running RL with 0/1 outcome reward, but do these approaches\nefficiently utilize test-time compute? Would these approaches continue to scale\nas the budget improves? In this paper, we try to answer these questions. We\nformalize the problem of optimizing test-time compute as a meta-reinforcement\nlearning (RL) problem, which provides a principled perspective on spending\ntest-time compute. This perspective enables us to view the long output stream\nfrom the LLM as consisting of several episodes run at test time and leads us to\nuse a notion of cumulative regret over output tokens as a way to measure the\nefficacy of test-time compute. Akin to how RL algorithms can best tradeoff\nexploration and exploitation over training, minimizing cumulative regret would\nalso provide the best balance between exploration and exploitation in the token\nstream. While we show that state-of-the-art models do not minimize regret, one\ncan do so by maximizing a dense reward bonus in conjunction with the outcome\n0/1 reward RL. This bonus is the ''progress'' made by each subsequent block in\nthe output stream, quantified by the change in the likelihood of eventual\nsuccess. Using these insights, we develop Meta Reinforcement Fine-Tuning, or\nMRT, a new class of fine-tuning methods for optimizing test-time compute. MRT\nleads to a 2-3x relative gain in performance and roughly a 1.5x gain in token\nefficiency for math reasoning compared to outcome-reward RL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07572v1",
    "published_date": "2025-03-10 17:40:43 UTC",
    "updated_date": "2025-03-10 17:40:43 UTC"
  },
  {
    "arxiv_id": "2503.07568v1",
    "title": "Runtime Detection of Adversarial Attacks in AI Accelerators Using Performance Counters",
    "authors": [
      "Habibur Rahaman",
      "Atri Chatterjee",
      "Swarup Bhunia"
    ],
    "abstract": "Rapid adoption of AI technologies raises several major security concerns,\nincluding the risks of adversarial perturbations, which threaten the\nconfidentiality and integrity of AI applications. Protecting AI hardware from\nmisuse and diverse security threats is a challenging task. To address this\nchallenge, we propose SAMURAI, a novel framework for safeguarding against\nmalicious usage of AI hardware and its resilience to attacks. SAMURAI\nintroduces an AI Performance Counter (APC) for tracking dynamic behavior of an\nAI model coupled with an on-chip Machine Learning (ML) analysis engine, known\nas TANTO (Trained Anomaly Inspection Through Trace Observation). APC records\nthe runtime profile of the low-level hardware events of different AI\noperations. Subsequently, the summary information recorded by the APC is\nprocessed by TANTO to efficiently identify potential security breaches and\nensure secure, responsible use of AI. SAMURAI enables real-time detection of\nsecurity threats and misuse without relying on traditional software-based\nsolutions that require model integration. Experimental results demonstrate that\nSAMURAI achieves up to 97% accuracy in detecting adversarial attacks with\nmoderate overhead on various AI models, significantly outperforming\nconventional software-based approaches. It enhances security and regulatory\ncompliance, providing a comprehensive solution for safeguarding AI against\nemergent threats.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07568v1",
    "published_date": "2025-03-10 17:38:42 UTC",
    "updated_date": "2025-03-10 17:38:42 UTC"
  },
  {
    "arxiv_id": "2503.07565v5",
    "title": "Inductive Moment Matching",
    "authors": [
      "Linqi Zhou",
      "Stefano Ermon",
      "Jiaming Song"
    ],
    "abstract": "Diffusion models and Flow Matching generate high-quality samples but are slow\nat inference, and distilling them into few-step models often leads to\ninstability and extensive tuning. To resolve these trade-offs, we propose\nInductive Moment Matching (IMM), a new class of generative models for one- or\nfew-step sampling with a single-stage training procedure. Unlike distillation,\nIMM does not require pre-training initialization and optimization of two\nnetworks; and unlike Consistency Models, IMM guarantees distribution-level\nconvergence and remains stable under various hyperparameters and standard model\narchitectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID\nusing only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98\non CIFAR-10 for a model trained from scratch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07565v5",
    "published_date": "2025-03-10 17:37:39 UTC",
    "updated_date": "2025-03-25 06:00:02 UTC"
  },
  {
    "arxiv_id": "2503.07700v1",
    "title": "A Task and Motion Planning Framework Using Iteratively Deepened AND/OR Graph Networks",
    "authors": [
      "Hossein Karami",
      "Antony Thomas",
      "Fulvio Mastrogiovanni"
    ],
    "abstract": "In this paper, we present an approach for integrated task and motion planning\nbased on an AND/OR graph network, which is used to represent task-level states\nand actions, and we leverage it to implement different classes of task and\nmotion planning problems (TAMP). Several problems that fall under task and\nmotion planning do not have a predetermined number of sub-tasks to achieve a\ngoal. For example, while retrieving a target object from a cluttered workspace,\nin principle the number of object re-arrangements required to finally grasp it\ncannot be known ahead of time. To address this challenge, and in contrast to\ntraditional planners, also those based on AND/OR graphs, we grow the AND/OR\ngraph at run-time by progressively adding sub-graphs until grasping the target\nobject becomes feasible, which yields a network of AND/OR graphs. The approach\nis extended to enable multi-robot task and motion planning, and (i) it allows\nus to perform task allocation while coordinating the activity of a given number\nof robots, and (ii) can handle multi-robot tasks involving an a priori unknown\nnumber of sub-tasks. The approach is evaluated and validated both in simulation\nand with a real dual-arm robot manipulator, that is, Baxter from Rethink\nRobotics. In particular, for the single-robot task and motion planning, we\nvalidated our approach in three different TAMP domains. Furthermore, we also\nuse three different robots for simulation, namely, Baxter, Franka Emika Panda\nmanipulators, and a PR2 robot. Experiments show that our approach can be\nreadily scaled to scenarios with many objects and robots, and is capable of\nhandling different classes of TAMP problems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07700v1",
    "published_date": "2025-03-10 17:28:22 UTC",
    "updated_date": "2025-03-10 17:28:22 UTC"
  },
  {
    "arxiv_id": "2503.07556v1",
    "title": "Junior Software Developers' Perspectives on Adopting LLMs for Software Engineering: a Systematic Literature Review",
    "authors": [
      "Samuel Ferino",
      "Rashina Hoda",
      "John Grundy",
      "Christoph Treude"
    ],
    "abstract": "Many studies exploring the adoption of Large Language Model-based tools for\nsoftware development by junior developers have emerged in recent years. These\nstudies have sought to understand developers' perspectives about using those\ntools, a fundamental pillar for successfully adopting LLM-based tools in\nSoftware Engineering. The aim of this paper is to provide an overview of junior\nsoftware developers' perspectives and use of LLM-based tools for software\nengineering (LLM4SE). We conducted a systematic literature review (SLR)\nfollowing guidelines by Kitchenham et al. on 56 primary studies, applying the\ndefinition for junior software developers as software developers with equal or\nless than five years of experience, including Computer Science/Software\nEngineering students. We found that the majority of the studies focused on\ncomprehending the different aspects of integrating AI tools in SE. Only 8.9\\%\nof the studies provide a clear definition for junior software developers, and\nthere is no uniformity. Searching for relevant information is the most common\ntask using LLM tools. ChatGPT was the most common LLM tool present in the\nstudies (and experiments). A majority of the studies (83.9\\%) report both\npositive and negative perceptions about the impact of adopting LLM tools. We\nalso found and categorised advantages, challenges, and recommendations\nregarding LLM adoption. Our results indicate that developers are using LLMs not\njust for code generation, but also to improve their development skills.\nCritically, they are not just experiencing the benefits of adopting LLM tools,\nbut they are also aware of at least a few LLM limitations, such as the\ngeneration of wrong suggestions, potential data leaking, and AI hallucination.\nOur findings offer implications for software engineering researchers,\neducators, and developers.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07556v1",
    "published_date": "2025-03-10 17:25:24 UTC",
    "updated_date": "2025-03-10 17:25:24 UTC"
  },
  {
    "arxiv_id": "2503.13492v1",
    "title": "Event-Driven Implementation of a Physical Reservoir Computing Framework for superficial EMG-based Gesture Recognition",
    "authors": [
      "Yuqi Ding",
      "Elisa Donati",
      "Haobo Li",
      "Hadi Heidari"
    ],
    "abstract": "Wearable health devices have a strong demand in real-time biomedical signal\nprocessing. However traditional methods often require data transmission to\ncentralized processing unit with substantial computational resources after\ncollecting it from edge devices. Neuromorphic computing is an emerging field\nthat seeks to design specialized hardware for computing systems inspired by the\nstructure, function, and dynamics of the human brain, offering significant\nadvantages in latency and power consumption. This paper explores a novel\nneuromorphic implementation approach for gesture recognition by extracting\nspatiotemporal spiking information from surface electromyography (sEMG) data in\nan event-driven manner. At the same time, the network was designed by\nimplementing a simple-structured and hardware-friendly Physical Reservoir\nComputing (PRC) framework called Rotating Neuron Reservoir (RNR) within the\ndomain of Spiking neural network (SNN). The spiking RNR (sRNR) is promising to\npipeline an innovative solution to compact embedded wearable systems, enabling\nlow-latency, real-time processing directly at the sensor level. The proposed\nsystem was validated by an open-access large-scale sEMG database and achieved\nan average classification accuracy of 74.6\\% and 80.3\\% using a classical\nmachine learning classifier and a delta learning rule algorithm respectively.\nWhile the delta learning rule could be fully spiking and implementable on\nneuromorphic chips, the proposed gesture recognition system demonstrates the\npotential for near-sensor low-latency processing.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "eess.SP",
    "comment": "11 pages, 9 figures, journal",
    "pdf_url": "http://arxiv.org/pdf/2503.13492v1",
    "published_date": "2025-03-10 17:18:14 UTC",
    "updated_date": "2025-03-10 17:18:14 UTC"
  },
  {
    "arxiv_id": "2503.07550v1",
    "title": "KSOD: Knowledge Supplement for LLMs On Demand",
    "authors": [
      "Haoran Li",
      "Junfeng Hu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks, yet still produce errors in domain-specific tasks. To further\nimprove their performance, we propose KSOD (Knowledge Supplement for LLMs On\nDemand), a novel framework that empowers LLMs to improve their capabilities\nwith knowledge-based supervised fine-tuning (SFT). KSOD analyzes the causes of\nerrors from the perspective of knowledge deficiency by identifying potential\nmissing knowledge in LLM that may lead to the errors. Subsequently, KSOD tunes\na knowledge module on knowledge dataset and verifies whether the LLM lacks the\nidentified knowledge based on it. If the knowledge is verified, KSOD\nsupplements the LLM with the identified knowledge using the knowledge module.\nTuning LLMs on specific knowledge instead of specific task decouples task and\nknowledge and our experiments on two domain-specific benchmarks and four\ngeneral benchmarks empirically demonstrate that KSOD enhances the performance\nof LLMs on tasks requiring the supplemented knowledge while preserving their\nperformance on other tasks. Our findings shed light on the potential of\nimproving the capabilities of LLMs with knowledge-based SFT.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07550v1",
    "published_date": "2025-03-10 17:17:41 UTC",
    "updated_date": "2025-03-10 17:17:41 UTC"
  },
  {
    "arxiv_id": "2503.07545v1",
    "title": "Queueing, Predictions, and LLMs: Challenges and Open Problems",
    "authors": [
      "Michael Mitzenmacher",
      "Rana Shahout"
    ],
    "abstract": "Queueing systems present many opportunities for applying machine-learning\npredictions, such as estimated service times, to improve system performance.\nThis integration raises numerous open questions about how predictions can be\neffectively leveraged to improve scheduling decisions. Recent studies explore\nqueues with predicted service times, typically aiming to minimize job time in\nthe system. We review these works, highlight the effectiveness of predictions,\nand present open questions on queue performance. We then move to consider an\nimportant practical example of using predictions in scheduling, namely Large\nLanguage Model (LLM) systems, which presents novel scheduling challenges and\nhighlights the potential for predictions to improve performance. In particular,\nwe consider LLMs performing inference. Inference requests (jobs) in LLM systems\nare inherently complex; they have variable inference times, dynamic memory\nfootprints that are constrained by key-value (KV) store memory limitations, and\nmultiple possible preemption approaches that affect performance differently. We\nprovide background on the important aspects of scheduling in LLM systems, and\nintroduce new models and open problems that arise from them. We argue that\nthere are significant opportunities for applying insights and analysis from\nqueueing theory to scheduling in LLM systems.",
    "categories": [
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07545v1",
    "published_date": "2025-03-10 17:12:47 UTC",
    "updated_date": "2025-03-10 17:12:47 UTC"
  },
  {
    "arxiv_id": "2503.07541v1",
    "title": "Geometric Retargeting: A Principled, Ultrafast Neural Hand Retargeting Algorithm",
    "authors": [
      "Zhao-Heng Yin",
      "Changhao Wang",
      "Luis Pineda",
      "Krishna Bodduluri",
      "Tingfan Wu",
      "Pieter Abbeel",
      "Mustafa Mukadam"
    ],
    "abstract": "We introduce Geometric Retargeting (GeoRT), an ultrafast, and principled\nneural hand retargeting algorithm for teleoperation, developed as part of our\nrecent Dexterity Gen (DexGen) system. GeoRT converts human finger keypoints to\nrobot hand keypoints at 1KHz, achieving state-of-the-art speed and accuracy\nwith significantly fewer hyperparameters. This high-speed capability enables\nflexible postprocessing, such as leveraging a foundational controller for\naction correction like DexGen. GeoRT is trained in an unsupervised manner,\neliminating the need for manual annotation of hand pairs. The core of GeoRT\nlies in novel geometric objective functions that capture the essence of\nretargeting: preserving motion fidelity, ensuring configuration space (C-space)\ncoverage, maintaining uniform response through high flatness, pinch\ncorrespondence and preventing self-collisions. This approach is free from\nintensive test-time optimization, offering a more scalable and practical\nsolution for real-time hand retargeting.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Website: https://zhaohengyin.github.io/geort",
    "pdf_url": "http://arxiv.org/pdf/2503.07541v1",
    "published_date": "2025-03-10 17:10:21 UTC",
    "updated_date": "2025-03-10 17:10:21 UTC"
  },
  {
    "arxiv_id": "2503.07540v1",
    "title": "AI-Enabled Knowledge Sharing for Enhanced Collaboration and Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review Protocol",
    "authors": [
      "Maurice Ongala",
      "Ruth Kiraka",
      "Jyoti Choundrie",
      "Javan Okello"
    ],
    "abstract": "This protocol outlines a scoping review designed to systematically map the\nexisting body of evidence on AI-enabled knowledge sharing in resource-limited\nnon-profit healthcare organizations. The review aims to investigate how such\ntechnologies enhance collaboration and decision-making, particularly in the\ncontext of reduced external support following the cessation of USAID\noperations. Guided by three theoretical frameworks namely, the Resource-Based\nView, Dynamic Capabilities Theory, and Absorptive Capacity Theory, this study\nwill explore the dual role of AI as a strategic resource and an enabler of\norganizational learning and agility. The protocol details a rigorous\nmethodological approach based on PRISMA-ScR guidelines, encompassing a\nsystematic search strategy across multiple databases, inclusion and exclusion\ncriteria, and a structured data extraction process. By integrating theoretical\ninsights with empirical evidence, this scoping review seeks to identify\ncritical gaps in the literature and inform the design of effective,\nresource-optimized AI solutions in non-profit healthcare settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07540v1",
    "published_date": "2025-03-10 17:09:12 UTC",
    "updated_date": "2025-03-10 17:09:12 UTC"
  },
  {
    "arxiv_id": "2503.07536v2",
    "title": "LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL",
    "authors": [
      "Yingzhe Peng",
      "Gongrui Zhang",
      "Miaosen Zhang",
      "Zhiyuan You",
      "Jie Liu",
      "Qipeng Zhu",
      "Kai Yang",
      "Xingzhong Xu",
      "Xin Geng",
      "Xu Yang"
    ],
    "abstract": "Enhancing reasoning in Large Multimodal Models (LMMs) faces unique challenges\nfrom the complex interplay between visual perception and logical reasoning,\nparticularly in compact 3B-parameter architectures where architectural\nconstraints limit reasoning capacity and modality alignment.\n  While rule-based reinforcement learning (RL) excels in text-only domains, its\nmultimodal extension confronts two critical barriers: (1) data limitations due\nto ambiguous answers and scarce complex reasoning examples, and (2) degraded\nfoundational reasoning induced by multimodal pretraining. To address these\nchallenges, we propose \\textbf{LMM-R1}, a two-stage framework adapting\nrule-based RL for multimodal reasoning through \\textbf{Foundational Reasoning\nEnhancement (FRE)} followed by \\textbf{Multimodal Generalization Training\n(MGT)}. The FRE stage first strengthens reasoning abilities using text-only\ndata with rule-based RL, then the MGT stage generalizes these reasoning\ncapabilities to multimodal domains.\n  Experiments on Qwen2.5-VL-Instruct-3B demonstrate that LMM-R1 achieves 4.83\\%\nand 4.5\\% average improvements over baselines in multimodal and text-only\nbenchmarks, respectively, with a 3.63\\% gain in complex Football Game tasks.\nThese results validate that text-based reasoning enhancement enables effective\nmultimodal generalization, offering a data-efficient paradigm that bypasses\ncostly high-quality multimodal training data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07536v2",
    "published_date": "2025-03-10 17:04:14 UTC",
    "updated_date": "2025-03-11 03:32:59 UTC"
  },
  {
    "arxiv_id": "2503.07693v1",
    "title": "Fully Autonomous Programming using Iterative Multi-Agent Debugging with Large Language Models",
    "authors": [
      "Anastasiia Grishina",
      "Vadim Liventsev",
      "Aki HÃ¤rmÃ¤",
      "Leon Moonen"
    ],
    "abstract": "Program synthesis with Large Language Models (LLMs) suffers from a \"near-miss\nsyndrome\": the generated code closely resembles a correct solution but fails\nunit tests due to minor errors. We address this with a multi-agent framework\ncalled Synthesize, Execute, Instruct, Debug, and Repair (SEIDR). Effectively\napplying SEIDR to instruction-tuned LLMs requires determining (a) optimal\nprompts for LLMs, (b) what ranking algorithm selects the best programs in\ndebugging rounds, and (c) balancing the repair of unsuccessful programs with\nthe generation of new ones. We empirically explore these trade-offs by\ncomparing replace-focused, repair-focused, and hybrid debug strategies. We also\nevaluate lexicase and tournament selection to rank candidates in each\ngeneration. On Program Synthesis Benchmark 2 (PSB2), our framework outperforms\nboth conventional use of OpenAI Codex without a repair phase and traditional\ngenetic programming approaches. SEIDR outperforms the use of an LLM alone,\nsolving 18 problems in C++ and 20 in Python on PSB2 at least once across\nexperiments. To assess generalizability, we employ GPT-3.5 and Llama 3 on the\nPSB2 and HumanEval-X benchmarks. Although SEIDR with these models does not\nsurpass current state-of-the-art methods on the Python benchmarks, the results\non HumanEval-C++ are promising. SEIDR with Llama 3-8B achieves an average\npass@100 of 84.2%. Across all SEIDR runs, 163 of 164 problems are solved at\nleast once with GPT-3.5 in HumanEval-C++, and 162 of 164 with the smaller Llama\n3-8B. We conclude that SEIDR effectively overcomes the near-miss syndrome in\nprogram synthesis with LLMs.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in ACM Trans. Evol. Learn. Optim., February\n  2025. arXiv admin note: text overlap with arXiv:2304.10423",
    "pdf_url": "http://arxiv.org/pdf/2503.07693v1",
    "published_date": "2025-03-10 16:56:51 UTC",
    "updated_date": "2025-03-10 16:56:51 UTC"
  },
  {
    "arxiv_id": "2503.10673v1",
    "title": "ZeroSumEval: An Extensible Framework For Scaling LLM Evaluation with Inter-Model Competition",
    "authors": [
      "Hisham A. Alyahya",
      "Haidar Khan",
      "Yazeed Alnumay",
      "M Saiful Bari",
      "BÃ¼lent Yener"
    ],
    "abstract": "We introduce ZeroSumEval, a dynamic, competition-based, and evolving\nevaluation framework for Large Language Models (LLMs) that leverages\ncompetitive games. ZeroSumEval encompasses a diverse suite of games, including\nsecurity challenges (Capture the Flag), classic board games (chess), and\nknowledge tests (MathQuiz). These games are designed to evaluate a range of\ncapabilities such as strategic reasoning, planning, knowledge application,\nsafety, and adaptability. Building upon recent studies that highlight the\neffectiveness of game-based evaluations for LLMs, ZeroSumEval enhances these\napproaches by providing a standardized and extensible framework for easily\nimplementing games and leverages DSPy to provide a better abstraction for LLM\nplayer strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10673v1",
    "published_date": "2025-03-10 16:54:27 UTC",
    "updated_date": "2025-03-10 16:54:27 UTC"
  },
  {
    "arxiv_id": "2503.07518v1",
    "title": "TokenButler: Token Importance is Predictable",
    "authors": [
      "Yash Akhauri",
      "Ahmed F AbouElhamayed",
      "Yifei Gao",
      "Chi-Chih Chang",
      "Nilesh Jain",
      "Mohamed S. Abdelfattah"
    ],
    "abstract": "Large Language Models (LLMs) rely on the Key-Value (KV) Cache to store token\nhistory, enabling efficient decoding of tokens. As the KV-Cache grows, it\nbecomes a major memory and computation bottleneck, however, there is an\nopportunity to alleviate this bottleneck, especially because prior research has\nshown that only a small subset of tokens contribute meaningfully to each\ndecoding step. A key challenge in finding these critical tokens is that they\nare dynamic, and heavily input query-dependent. Existing methods either risk\nquality by evicting tokens permanently, or retain the full KV-Cache but rely on\nretrieving chunks (pages) of tokens at generation, failing at dense,\ncontext-rich tasks. Additionally, many existing KV-Cache sparsity methods rely\non inaccurate proxies for token importance. To address these limitations, we\nintroduce TokenButler, a high-granularity, query-aware predictor that learns to\nidentify these critical tokens. By training a light-weight predictor with less\nthan 1.2% parameter overhead, TokenButler prioritizes tokens based on their\ncontextual, predicted importance. This improves perplexity & downstream\naccuracy by over 8% relative to SoTA methods for estimating token importance.\nWe evaluate TokenButler on a novel synthetic small-context co-referential\nretrieval task, demonstrating near-oracle accuracy. Code, models and\nbenchmarks: https://github.com/abdelfattah-lab/TokenButler",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07518v1",
    "published_date": "2025-03-10 16:41:14 UTC",
    "updated_date": "2025-03-10 16:41:14 UTC"
  },
  {
    "arxiv_id": "2503.07690v1",
    "title": "Artificial Intelligence in Deliberation: The AI Penalty and the Emergence of a New Deliberative Divide",
    "authors": [
      "Andreas Jungherr",
      "Adrian Rauchfleisch"
    ],
    "abstract": "Digital deliberation has expanded democratic participation, yet challenges\nremain. This includes processing information at scale, moderating discussions,\nfact-checking, or attracting people to participate. Recent advances in\nartificial intelligence (AI) offer potential solutions, but public perceptions\nof AI's role in deliberation remain underexplored. Beyond efficiency,\ndemocratic deliberation is about voice and recognition. If AI is integrated\ninto deliberation, public trust, acceptance, and willingness to participate may\nbe affected. We conducted a preregistered survey experiment with a\nrepresentative sample in Germany (n=1850) to examine how information about\nAI-enabled deliberation influences willingness to participate and perceptions\nof deliberative quality. Respondents were randomly assigned to treatments that\nprovided them information about deliberative tasks facilitated by either AI or\nhumans. Our findings reveal a significant AI-penalty. Participants were less\nwilling to engage in AI-facilitated deliberation and rated its quality lower\nthan human-led formats. These effects were moderated by individual\npredispositions. Perceptions of AI's societal benefits and anthropomorphization\nof AI showed positive interaction effects on people's interest to participate\nin AI-enabled deliberative formats and positive quality assessments, while AI\nrisk assessments showed negative interactions with information about AI-enabled\ndeliberation. These results suggest AI-enabled deliberation faces substantial\npublic skepticism, potentially even introducing a new deliberative divide.\nUnlike traditional participation gaps based on education or demographics, this\ndivide is shaped by attitudes toward AI. As democratic engagement increasingly\nmoves online, ensuring AI's role in deliberation does not discourage\nparticipation or deepen inequalities will be a key challenge for future\nresearch and policy.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07690v1",
    "published_date": "2025-03-10 16:33:15 UTC",
    "updated_date": "2025-03-10 16:33:15 UTC"
  },
  {
    "arxiv_id": "2503.07513v2",
    "title": "Language Models Fail to Introspect About Their Knowledge of Language",
    "authors": [
      "Siyuan Song",
      "Jennifer Hu",
      "Kyle Mahowald"
    ],
    "abstract": "There has been recent interest in whether large language models (LLMs) can\nintrospect about their own internal states. Such abilities would make LLMs more\ninterpretable, and also validate the use of standard introspective methods in\nlinguistics to evaluate grammatical knowledge in models (e.g., asking \"Is this\nsentence grammatical?\"). We systematically investigate emergent introspection\nacross 21 open-source LLMs, in two domains where introspection is of\ntheoretical interest: grammatical knowledge and word prediction. Crucially, in\nboth domains, a model's internal linguistic knowledge can be theoretically\ngrounded in direct measurements of string probability. We then evaluate whether\nmodels' responses to metalinguistic prompts faithfully reflect their internal\nknowledge. We propose a new measure of introspection: the degree to which a\nmodel's prompted responses predict its own string probabilities, beyond what\nwould be predicted by another model with nearly identical internal knowledge.\nWhile both metalinguistic prompting and probability comparisons lead to high\ntask accuracy, we do not find evidence that LLMs have privileged \"self-access\".\nOur findings complicate recent results suggesting that models can introspect,\nand add new evidence to the argument that prompted responses should not be\nconflated with models' linguistic generalizations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Corrected Fig 5a and removed unused figures from source files",
    "pdf_url": "http://arxiv.org/pdf/2503.07513v2",
    "published_date": "2025-03-10 16:33:14 UTC",
    "updated_date": "2025-03-12 03:18:36 UTC"
  },
  {
    "arxiv_id": "2503.07509v1",
    "title": "Interference-Aware Super-Constellation Design for NOMA",
    "authors": [
      "Mojtaba Vaezi",
      "Xinliang Zhang"
    ],
    "abstract": "Non-orthogonal multiple access (NOMA) has gained significant attention as a\npotential next-generation multiple access technique. However, its\nimplementation with finite-alphabet inputs faces challenges. Particularly, due\nto inter-user interference, superimposed constellations may have overlapping\nsymbols leading to high bit error rates when successive interference\ncancellation (SIC) is applied. To tackle the issue, this paper employs\nautoencoders to design interference-aware super-constellations. Unlike\nconventional methods where superimposed constellation may have overlapping\nsymbols, the proposed autoencoder-based NOMA (AE-NOMA) is trained to design\nsuper-constellations with distinguishable symbols at receivers, regardless of\nchannel gains. The proposed architecture removes the need for SIC, allowing\nmaximum likelihood-based approaches to be used instead. The paper presents the\nconceptual architecture, loss functions, and training strategies for AE-NOMA.\nVarious test results are provided to demonstrate the effectiveness of\ninterference-aware constellations in improving the bit error rate, indicating\nthe adaptability of AE-NOMA to different channel scenarios and its promising\npotential for implementing NOMA systems",
    "categories": [
      "cs.IT",
      "cs.AI",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Accepted for publication at IEEE International Conference on\n  Communications (ICC), 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07509v1",
    "published_date": "2025-03-10 16:31:33 UTC",
    "updated_date": "2025-03-10 16:31:33 UTC"
  },
  {
    "arxiv_id": "2503.07505v1",
    "title": "From Centralized to Decentralized Federated Learning: Theoretical Insights, Privacy Preservation, and Robustness Challenges",
    "authors": [
      "Qiongxiu Li",
      "Wenrui Yu",
      "Yufei Xia",
      "Jun Pang"
    ],
    "abstract": "Federated Learning (FL) enables collaborative learning without directly\nsharing individual's raw data. FL can be implemented in either a centralized\n(server-based) or decentralized (peer-to-peer) manner. In this survey, we\npresent a novel perspective: the fundamental difference between centralized FL\n(CFL) and decentralized FL (DFL) is not merely the network topology, but the\nunderlying training protocol: separate aggregation vs. joint optimization. We\nargue that this distinction in protocol leads to significant differences in\nmodel utility, privacy preservation, and robustness to attacks. We\nsystematically review and categorize existing works in both CFL and DFL\naccording to the type of protocol they employ. This taxonomy provides deeper\ninsights into prior research and clarifies how various approaches relate or\ndiffer. Through our analysis, we identify key gaps in the literature. In\nparticular, we observe a surprising lack of exploration of DFL approaches based\non distributed optimization methods, despite their potential advantages. We\nhighlight this under-explored direction and call for more research on\nleveraging distributed optimization for federated learning. Overall, this work\noffers a comprehensive overview from centralized to decentralized FL, sheds new\nlight on the core distinctions between approaches, and outlines open challenges\nand future directions for the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07505v1",
    "published_date": "2025-03-10 16:27:40 UTC",
    "updated_date": "2025-03-10 16:27:40 UTC"
  },
  {
    "arxiv_id": "2503.07493v1",
    "title": "V2Flow: Unifying Visual Tokenization and Large Language Model Vocabularies for Autoregressive Image Generation",
    "authors": [
      "Guiwei Zhang",
      "Tianyu Zhang",
      "Mohan Zhou",
      "Yalong Bai",
      "Biye Li"
    ],
    "abstract": "We propose V2Flow, a novel tokenizer that produces discrete visual tokens\ncapable of high-fidelity reconstruction, while ensuring structural and latent\ndistribution alignment with the vocabulary space of large language models\n(LLMs). Leveraging this tight visual-vocabulary coupling, V2Flow enables\nautoregressive visual generation on top of existing LLMs. Our approach\nformulates visual tokenization as a flow-matching problem, aiming to learn a\nmapping from a standard normal prior to the continuous image distribution,\nconditioned on token sequences embedded within the LLMs vocabulary space. The\neffectiveness of V2Flow stems from two core designs. First, we propose a Visual\nVocabulary resampler, which compresses visual data into compact token\nsequences, with each represented as a soft categorical distribution over LLM's\nvocabulary. This allows seamless integration of visual tokens into existing\nLLMs for autoregressive visual generation. Second, we present a masked\nautoregressive Rectified-Flow decoder, employing a masked transformer\nencoder-decoder to refine visual tokens into contextually enriched embeddings.\nThese embeddings then condition a dedicated velocity field for precise\nreconstruction. Additionally, an autoregressive rectified-flow sampling\nstrategy is incorporated, ensuring flexible sequence lengths while preserving\ncompetitive reconstruction quality. Extensive experiments show that V2Flow\noutperforms mainstream VQ-based tokenizers and facilitates autoregressive\nvisual generation on top of existing. https://github.com/zhangguiwei610/V2Flow",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07493v1",
    "published_date": "2025-03-10 16:12:50 UTC",
    "updated_date": "2025-03-10 16:12:50 UTC"
  },
  {
    "arxiv_id": "2503.07482v1",
    "title": "Efficient Membership Inference Attacks by Bayesian Neural Network",
    "authors": [
      "Zhenlong Liu",
      "Wenyu Jiang",
      "Feng Zhou",
      "Hongxin Wei"
    ],
    "abstract": "Membership Inference Attacks (MIAs) aim to estimate whether a specific data\npoint was used in the training of a given model. Previous attacks often utilize\nmultiple reference models to approximate the conditional score distribution,\nleading to significant computational overhead. While recent work leverages\nquantile regression to estimate conditional thresholds, it fails to capture\nepistemic uncertainty, resulting in bias in low-density regions. In this work,\nwe propose a novel approach - Bayesian Membership Inference Attack (BMIA),\nwhich performs conditional attack through Bayesian inference. In particular, we\ntransform a trained reference model into Bayesian neural networks by Laplace\napproximation, enabling the direct estimation of the conditional score\ndistribution by probabilistic model parameters. Our method addresses both\nepistemic and aleatoric uncertainty with only a reference model, enabling\nefficient and powerful MIA. Extensive experiments on five datasets demonstrate\nthe effectiveness and efficiency of BMIA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, under review",
    "pdf_url": "http://arxiv.org/pdf/2503.07482v1",
    "published_date": "2025-03-10 15:58:43 UTC",
    "updated_date": "2025-03-10 15:58:43 UTC"
  },
  {
    "arxiv_id": "2503.07470v1",
    "title": "Advancing Vietnamese Information Retrieval with Learning Objective and Benchmark",
    "authors": [
      "Phu-Vinh Nguyen",
      "Minh-Nam Tran",
      "Long Nguyen",
      "Dien Dinh"
    ],
    "abstract": "With the rapid development of natural language processing, many language\nmodels have been invented for multiple tasks. One important task is information\nretrieval (IR), which requires models to retrieve relevant documents. Despite\nits importance in many real-life applications, especially in retrieval\naugmented generation (RAG) systems, this task lacks Vietnamese benchmarks. This\nsituation causes difficulty in assessing and comparing many existing Vietnamese\nembedding language models on the task and slows down the advancement of\nVietnamese natural language processing (NLP) research. In this work, we aim to\nprovide the Vietnamese research community with a new benchmark for information\nretrieval, which mainly focuses on retrieval and reranking tasks. Furthermore,\nwe also present a new objective function based on the InfoNCE loss function,\nwhich is used to train our Vietnamese embedding model. Our function aims to be\nbetter than the origin in information retrieval tasks. Finally, we analyze the\neffect of temperature, a hyper-parameter in both objective functions, on the\nperformance of text embedding models.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07470v1",
    "published_date": "2025-03-10 15:47:01 UTC",
    "updated_date": "2025-03-10 15:47:01 UTC"
  },
  {
    "arxiv_id": "2503.07459v2",
    "title": "MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning",
    "authors": [
      "Xiangru Tang",
      "Daniel Shao",
      "Jiwoong Sohn",
      "Jiapeng Chen",
      "Jiayi Zhang",
      "Jinyu Xiang",
      "Fang Wu",
      "Yilun Zhao",
      "Chenglin Wu",
      "Wenqi Shi",
      "Arman Cohan",
      "Mark Gerstein"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive performance on existing\nmedical question-answering benchmarks. This high performance makes it\nincreasingly difficult to meaningfully evaluate and differentiate advanced\nmethods. We present MedAgentsBench, a benchmark that focuses on challenging\nmedical questions requiring multi-step clinical reasoning, diagnosis\nformulation, and treatment planning-scenarios where current models still\nstruggle despite their strong performance on standard tests. Drawing from seven\nestablished medical datasets, our benchmark addresses three key limitations in\nexisting evaluations: (1) the prevalence of straightforward questions where\neven base models achieve high performance, (2) inconsistent sampling and\nevaluation protocols across studies, and (3) lack of systematic analysis of the\ninterplay between performance, cost, and inference time. Through experiments\nwith various base models and reasoning methods, we demonstrate that the latest\nthinking models, DeepSeek R1 and OpenAI o3, exhibit exceptional performance in\ncomplex medical reasoning tasks. Additionally, advanced search-based agent\nmethods offer promising performance-to-cost ratios compared to traditional\napproaches. Our analysis reveals substantial performance gaps between model\nfamilies on complex questions and identifies optimal model selections for\ndifferent computational constraints. Our benchmark and evaluation framework are\npublicly available at https://github.com/gersteinlab/medagents-benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07459v2",
    "published_date": "2025-03-10 15:38:44 UTC",
    "updated_date": "2025-03-20 01:30:56 UTC"
  },
  {
    "arxiv_id": "2503.07453v2",
    "title": "Is a Good Foundation Necessary for Efficient Reinforcement Learning? The Computational Role of the Base Model in Exploration",
    "authors": [
      "Dylan J. Foster",
      "Zakaria Mhammedi",
      "Dhruv Rohatgi"
    ],
    "abstract": "Language model alignment (or, reinforcement learning) techniques that\nleverage active exploration -- deliberately encouraging the model to produce\ndiverse, informative responses -- offer the promise of super-human\ncapabilities. However, current understanding of algorithm design primitives for\ncomputationally efficient exploration with language models is limited. To\nbetter understand how to leverage access to powerful pre-trained generative\nmodels to improve the efficiency of exploration, we introduce a new\ncomputational framework for RL with language models, in which the learner\ninteracts with the model through a sampling oracle. Focusing on the linear\nsoftmax model parameterization, we provide new results that reveal the\ncomputational-statistical tradeoffs of efficient exploration:\n  1. Necessity of coverage: Coverage refers to the extent to which the\npre-trained model covers near-optimal responses -- a form of hidden knowledge.\nWe show that coverage, while not necessary for data efficiency, lower bounds\nthe runtime of any algorithm in our framework.\n  2. Inference-time exploration: We introduce a new algorithm, SpannerSampling,\nwhich obtains optimal data efficiency and is computationally efficient whenever\nthe pre-trained model enjoys sufficient coverage, matching our lower bound.\nSpannerSampling leverages inference-time computation with the pre-trained model\nto reduce the effective search space for exploration.\n  3. Insufficiency of training-time interventions: We contrast the result above\nby showing that training-time interventions that produce proper policies cannot\nachieve similar guarantees in polynomial time.\n  4. Computational benefits of multi-turn exploration: Finally, we show that\nunder additional representational assumptions, one can achieve improved runtime\n(replacing sequence-level coverage with token-level coverage) through\nmulti-turn exploration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "V2: Improved number of prompts used by Algorithm 1",
    "pdf_url": "http://arxiv.org/pdf/2503.07453v2",
    "published_date": "2025-03-10 15:31:42 UTC",
    "updated_date": "2025-03-13 23:15:55 UTC"
  },
  {
    "arxiv_id": "2503.07450v2",
    "title": "From Idea to Implementation: Evaluating the Influence of Large Language Models in Software Development -- An Opinion Paper",
    "authors": [
      "Sargam Yadav",
      "Asifa Mehmood Qureshi",
      "Abhishek Kaushik",
      "Shubham Sharma",
      "Roisin Loughran",
      "Subramaniam Kazhuparambil",
      "Andrew Shaw",
      "Mohammed Sabry",
      "Niamh St John Lynch",
      ". Nikhil Singh",
      "Padraic O'Hara",
      "Pranay Jaiswal",
      "Roshan Chandru",
      "David Lillis"
    ],
    "abstract": "The introduction of transformer architecture was a turning point in Natural\nLanguage Processing (NLP). Models based on the transformer architecture such as\nBidirectional Encoder Representations from Transformers (BERT) and Generative\nPre-Trained Transformer (GPT) have gained widespread popularity in various\napplications such as software development and education. The availability of\nLarge Language Models (LLMs) such as ChatGPT and Bard to the general public has\nshowcased the tremendous potential of these models and encouraged their\nintegration into various domains such as software development for tasks such as\ncode generation, debugging, and documentation generation. In this study,\nopinions from 11 experts regarding their experience with LLMs for software\ndevelopment have been gathered and analysed to draw insights that can guide\nsuccessful and responsible integration. The overall opinion of the experts is\npositive, with the experts identifying advantages such as increase in\nproductivity and reduced coding time. Potential concerns and challenges such as\nrisk of over-dependence and ethical considerations have also been highlighted.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The project is partially supported by the DkIT Postgraduate\n  Scholarship, Research Ireland under Grant number 13/RC/2094_2, and Grant\n  number 21/FFP-A/925",
    "pdf_url": "http://arxiv.org/pdf/2503.07450v2",
    "published_date": "2025-03-10 15:30:05 UTC",
    "updated_date": "2025-03-12 09:57:19 UTC"
  },
  {
    "arxiv_id": "2503.07444v1",
    "title": "Divide and Conquer Self-Supervised Learning for High-Content Imaging",
    "authors": [
      "Lucas Farndale",
      "Paul Henderson",
      "Edward W Roberts",
      "Ke Yuan"
    ],
    "abstract": "Self-supervised representation learning methods often fail to learn subtle or\ncomplex features, which can be dominated by simpler patterns which are much\neasier to learn. This limitation is particularly problematic in applications to\nscience and engineering, as complex features can be critical for discovery and\nanalysis. To address this, we introduce Split Component Embedding Registration\n(SpliCER), a novel architecture which splits the image into sections and\ndistils information from each section to guide the model to learn more subtle\nand complex features without compromising on simpler features. SpliCER is\ncompatible with any self-supervised loss function and can be integrated into\nexisting methods without modification. The primary contributions of this work\nare as follows: i) we demonstrate that existing self-supervised methods can\nlearn shortcut solutions when simple and complex features are both present; ii)\nwe introduce a novel self-supervised training method, SpliCER, to overcome the\nlimitations of existing methods, and achieve significant downstream performance\nimprovements; iii) we demonstrate the effectiveness of SpliCER in cutting-edge\nmedical and geospatial imaging settings. SpliCER offers a powerful new tool for\nrepresentation learning, enabling models to uncover complex features which\ncould be overlooked by other methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07444v1",
    "published_date": "2025-03-10 15:24:36 UTC",
    "updated_date": "2025-03-10 15:24:36 UTC"
  },
  {
    "arxiv_id": "2503.07429v1",
    "title": "From Text to Visuals: Using LLMs to Generate Math Diagrams with Vector Graphics",
    "authors": [
      "Jaewook Lee",
      "Jeongah Lee",
      "Wanyong Feng",
      "Andrew Lan"
    ],
    "abstract": "Advances in large language models (LLMs) offer new possibilities for\nenhancing math education by automating support for both teachers and students.\nWhile prior work has focused on generating math problems and high-quality\ndistractors, the role of visualization in math learning remains under-explored.\nDiagrams are essential for mathematical thinking and problem-solving, yet\nmanually creating them is time-consuming and requires domain-specific\nexpertise, limiting scalability. Recent research on using LLMs to generate\nScalable Vector Graphics (SVG) presents a promising approach to automating\ndiagram creation. Unlike pixel-based images, SVGs represent geometric figures\nusing XML, allowing seamless scaling and adaptability. Educational platforms\nsuch as Khan Academy and IXL already use SVGs to display math problems and\nhints. In this paper, we explore the use of LLMs to generate math-related\ndiagrams that accompany textual hints via intermediate SVG representations. We\naddress three research questions: (1) how to automatically generate math\ndiagrams in problem-solving hints and evaluate their quality, (2) whether SVG\nis an effective intermediate representation for math diagrams, and (3) what\nprompting strategies and formats are required for LLMs to generate accurate\nSVG-based diagrams. Our contributions include defining the task of\nautomatically generating SVG-based diagrams for math hints, developing an LLM\nprompting-based pipeline, and identifying key strategies for improving diagram\ngeneration. Additionally, we introduce a Visual Question Answering-based\nevaluation setup and conduct ablation studies to assess different pipeline\nvariations. By automating the math diagram creation, we aim to provide students\nand teachers with accurate, conceptually relevant visual aids that enhance\nproblem-solving and learning experiences.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07429v1",
    "published_date": "2025-03-10 15:13:38 UTC",
    "updated_date": "2025-03-10 15:13:38 UTC"
  },
  {
    "arxiv_id": "2503.07426v1",
    "title": "RePO: ReLU-based Preference Optimization",
    "authors": [
      "Junkang Wu",
      "Kexin Huang",
      "Xue Wang",
      "Jinyang Gao",
      "Bolin Ding",
      "Jiancan Wu",
      "Xiangnan He",
      "Xiang Wang"
    ],
    "abstract": "Aligning large language models (LLMs) with human preferences is critical for\nreal-world deployment, yet existing methods like RLHF face computational and\nstability challenges. While DPO establishes an offline paradigm with single\nhyperparameter $\\beta$, subsequent methods like SimPO reintroduce complexity\nthrough dual parameters ($\\beta$, $\\gamma$). We propose {ReLU-based Preference\nOptimization (RePO)}, a streamlined algorithm that eliminates $\\beta$ via two\nadvances: (1) retaining SimPO's reference-free margins but removing $\\beta$\nthrough gradient analysis, and (2) adopting a ReLU-based max-margin loss that\nnaturally filters trivial pairs. Theoretically, RePO is characterized as\nSimPO's limiting case ($\\beta \\to \\infty$), where the logistic weighting\ncollapses to binary thresholding, forming a convex envelope of the 0-1 loss.\nEmpirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO\nand SimPO across multiple base models, requiring only one hyperparameter to\ntune.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07426v1",
    "published_date": "2025-03-10 15:11:07 UTC",
    "updated_date": "2025-03-10 15:11:07 UTC"
  },
  {
    "arxiv_id": "2503.08717v1",
    "title": "A Semantic Link Network Model for Supporting Traceability of Logistics on Blockchain",
    "authors": [
      "Xiaoping Sun",
      "Sirui Zhuge",
      "Hai Zhuge"
    ],
    "abstract": "The ability of tracing states of logistic transportations requires an\nefficient storage and retrieval of the state of logistic transportations and\nlocations of logistic objects. However, the restriction of sharing states and\nlocations of logistic objects across organizations from different countries\nmakes it hard to deploy a centralized database for implementing the\ntraceability in a cross-border logistic system. This paper proposes a semantic\ndata model on Blockchain to represent a logistic process based on the Semantic\nLink Network model where each semantic link represents a logistic\ntransportation of a logistic object between two parties. A state representation\nmodel is designed to represent the states of a logistic transportation with\nsemantic links. It enables the locations of logistic objects to be derived from\nthe link states. A mapping from the semantic links to the blockchain\ntransactions is designed to enable schema of semantic links and states of\nsemantic links to be published in blockchain transactions. To improve the\nefficiency of tracing a path of semantic links on blockchain platform, an\nalgorithm is designed to build shortcuts along the path of semantic links to\nenable a query on the path of a logistic object to reach the target in\nlogarithmic steps on the blockchain platform. A reward-penalty policy is\ndesigned to allow participants to confirm the state of links on blockchain.\nAnalysis and simulation demonstrate the flexibility, effectiveness and the\nefficiency of Semantic Link Network on immutable blockchain for implementing\nlogistic traceability.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DB",
      "cs.SI",
      "H.2.5; I.2.4"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.08717v1",
    "published_date": "2025-03-10 14:56:00 UTC",
    "updated_date": "2025-03-10 14:56:00 UTC"
  },
  {
    "arxiv_id": "2503.07396v1",
    "title": "Brain Inspired Adaptive Memory Dual-Net for Few-Shot Image Classification",
    "authors": [
      "Kexin Di",
      "Xiuxing Li",
      "Yuyang Han",
      "Ziyu Li",
      "Qing Li",
      "Xia Wu"
    ],
    "abstract": "Few-shot image classification has become a popular research topic for its\nwide application in real-world scenarios, however the problem of supervision\ncollapse induced by single image-level annotation remains a major challenge.\nExisting methods aim to tackle this problem by locating and aligning relevant\nlocal features. However, the high intra-class variability in real-world images\nposes significant challenges in locating semantically relevant local regions\nunder few-shot settings. Drawing inspiration from the human's complementary\nlearning system, which excels at rapidly capturing and integrating semantic\nfeatures from limited examples, we propose the generalization-optimized Systems\nConsolidation Adaptive Memory Dual-Network, SCAM-Net. This approach simulates\nthe systems consolidation of complementary learning system with an adaptive\nmemory module, which successfully addresses the difficulty of identifying\nmeaningful features in few-shot scenarios. Specifically, we construct a\nHippocampus-Neocortex dual-network that consolidates structured representation\nof each category, the structured representation is then stored and adaptively\nregulated following the generalization optimization principle in a long-term\nmemory inside Neocortex. Extensive experiments on benchmark datasets show that\nthe proposed model has achieved state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07396v1",
    "published_date": "2025-03-10 14:42:51 UTC",
    "updated_date": "2025-03-10 14:42:51 UTC"
  },
  {
    "arxiv_id": "2503.07389v1",
    "title": "TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models",
    "authors": [
      "Ruidong Chen",
      "Honglin Guo",
      "Lanjun Wang",
      "Chenyu Zhang",
      "Weizhi Nie",
      "An-An Liu"
    ],
    "abstract": "Recent advances in text-to-image diffusion models enable photorealistic image\ngeneration, but they also risk producing malicious content, such as NSFW\nimages. To mitigate risk, concept erasure methods are studied to facilitate the\nmodel to unlearn specific concepts. However, current studies struggle to fully\nerase malicious concepts implicitly embedded in prompts (e.g., metaphorical\nexpressions or adversarial prompts) while preserving the model's normal\ngeneration capability. To address this challenge, our study proposes TRCE,\nusing a two-stage concept erasure strategy to achieve an effective trade-off\nbetween reliable erasure and knowledge preservation. Firstly, TRCE starts by\nerasing the malicious semantics implicitly embedded in textual prompts. By\nidentifying a critical mapping objective(i.e., the [EoT] embedding), we\noptimize the cross-attention layers to map malicious prompts to contextually\nsimilar prompts but with safe concepts. This step prevents the model from being\noverly influenced by malicious semantics during the denoising process.\nFollowing this, considering the deterministic properties of the sampling\ntrajectory of the diffusion model, TRCE further steers the early denoising\nprediction toward the safe direction and away from the unsafe one through\ncontrastive learning, thus further avoiding the generation of malicious\ncontent. Finally, we conduct comprehensive evaluations of TRCE on multiple\nmalicious concept erasure benchmarks, and the results demonstrate its\neffectiveness in erasing malicious concepts while better preserving the model's\noriginal generation ability. The code is available at:\nhttp://github.com/ddgoodgood/TRCE. CAUTION: This paper includes model-generated\ncontent that may contain offensive material.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07389v1",
    "published_date": "2025-03-10 14:37:53 UTC",
    "updated_date": "2025-03-10 14:37:53 UTC"
  },
  {
    "arxiv_id": "2503.07384v2",
    "title": "Is My Text in Your AI Model? Gradient-based Membership Inference Test applied to LLMs",
    "authors": [
      "Gonzalo Mancera",
      "Daniel DeAlcala",
      "Julian Fierrez",
      "Ruben Tolosana",
      "Aythami Morales"
    ],
    "abstract": "This work adapts and studies the gradient-based Membership Inference Test\n(gMINT) to the classification of text based on LLMs. MINT is a general approach\nintended to determine if given data was used for training machine learning\nmodels, and this work focuses on its application to the domain of Natural\nLanguage Processing. Using gradient-based analysis, the MINT model identifies\nwhether particular data samples were included during the language model\ntraining phase, addressing growing concerns about data privacy in machine\nlearning. The method was evaluated in seven Transformer-based models and six\ndatasets comprising over 2.5 million sentences, focusing on text classification\ntasks. Experimental results demonstrate MINTs robustness, achieving AUC scores\nbetween 85% and 99%, depending on data size and model architecture. These\nfindings highlight MINTs potential as a scalable and reliable tool for auditing\nmachine learning models, ensuring transparency, safeguarding sensitive data,\nand fostering ethical compliance in the deployment of AI/NLP technologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07384v2",
    "published_date": "2025-03-10 14:32:56 UTC",
    "updated_date": "2025-03-13 12:37:37 UTC"
  },
  {
    "arxiv_id": "2503.07364v1",
    "title": "Artificial Utopia: Simulation and Intelligent Agents for a Democratised Future",
    "authors": [
      "Yannick Oswald"
    ],
    "abstract": "Prevailing top-down systems in politics and economics struggle to keep pace\nwith the pressing challenges of the 21st century, such as climate change,\nsocial inequality and conflict. Bottom-up democratisation and participatory\napproaches in politics and economics are increasingly seen as promising\nalternatives to confront and overcome these issues, often with utopian\novertones, as proponents believe they may dramatically reshape political,\nsocial and ecological futures for the better and in contrast to contemporary\nauthoritarian tendencies across various countries. Institutional specifics and\nthe associated collective human behavior or culture remains little understood\nand debated, however. In this article, I propose a novel research agenda\nfocusing on utopian democratisation efforts with formal and computational\nmethods as well as with artificial intelligence - I call this agenda Artificial\nUtopia. Artificial Utopias provide safe testing grounds for new political ideas\nand economic policies in-silico with reduced risk of negative consequences as\ncompared to testing ideas in real-world contexts. An increasing number of\nadvanced simulation and intelligence methods, that aim at representing human\ncognition and collective decision-making in more realistic ways, could benefit\nthis process. This includes agent-based modelling, reinforcement learning,\nlarge language models and more. I clarify what some of these simulation\napproaches can contribute to the study of Artificial Utopias with the help of\ntwo institutional examples: the citizen assembly and the democratic firm.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07364v1",
    "published_date": "2025-03-10 14:20:58 UTC",
    "updated_date": "2025-03-10 14:20:58 UTC"
  },
  {
    "arxiv_id": "2503.07351v1",
    "title": "Encoding Argumentation Frameworks to Propositional Logic Systems",
    "authors": [
      "Shuai Tang",
      "Jiachao Wu",
      "Ning Zhou"
    ],
    "abstract": "The theory of argumentation frameworks ($AF$s) has been a useful tool for\nartificial intelligence. The research of the connection between $AF$s and logic\nis an important branch. This paper generalizes the encoding method by encoding\n$AF$s as logical formulas in different propositional logic systems. It studies\nthe relationship between models of an AF by argumentation semantics, including\nDung's classical semantics and Gabbay's equational semantics, and models of the\nencoded formulas by semantics of propositional logic systems. Firstly, we\nsupplement the proof of the regular encoding function in the case of encoding\n$AF$s to the 2-valued propositional logic system. Then we encode $AF$s to\n3-valued propositional logic systems and fuzzy propositional logic systems and\nexplore the model relationship. This paper enhances the connection between\n$AF$s and propositional logic systems. It also provides a new way to construct\nnew equational semantics by choosing different fuzzy logic operations.",
    "categories": [
      "cs.AI",
      "math.LO",
      "Primary 68T27, Secondary 03B70, 03B50, 03B52, 68Q55",
      "I.2.4; F.4.1"
    ],
    "primary_category": "cs.AI",
    "comment": "31 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07351v1",
    "published_date": "2025-03-10 14:06:58 UTC",
    "updated_date": "2025-03-10 14:06:58 UTC"
  },
  {
    "arxiv_id": "2503.07341v1",
    "title": "The Economics of p(doom): Scenarios of Existential Risk and Economic Growth in the Age of Transformative AI",
    "authors": [
      "Jakub Growiec",
      "Klaus Prettner"
    ],
    "abstract": "Recent advances in artificial intelligence (AI) have led to a diverse set of\npredictions about its long-term impact on humanity. A central focus is the\npotential emergence of transformative AI (TAI), eventually capable of\noutperforming humans in all economically valuable tasks and fully automating\nlabor. Discussed scenarios range from human extinction after a misaligned TAI\ntakes over (\"AI doom\") to unprecedented economic growth and abundance\n(\"post-scarcity\"). However, the probabilities and implications of these\nscenarios remain highly uncertain. Here, we organize the various scenarios and\nevaluate their associated existential risks and economic outcomes in terms of\naggregate welfare. Our analysis shows that even low-probability catastrophic\noutcomes justify large investments in AI safety and alignment research. We find\nthat the optimizing representative individual would rationally allocate\nsubstantial resources to mitigate extinction risk; in some cases, she would\nprefer not to develop TAI at all. This result highlights that current global\nefforts in AI safety and alignment research are vastly insufficient relative to\nthe scale and urgency of existential risks posed by TAI. Our findings therefore\nunderscore the need for stronger safeguards to balance the potential economic\nbenefits of TAI with the prevention of irreversible harm. Addressing these\nrisks is crucial for steering technological progress toward sustainable human\nprosperity.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07341v1",
    "published_date": "2025-03-10 13:53:39 UTC",
    "updated_date": "2025-03-10 13:53:39 UTC"
  },
  {
    "arxiv_id": "2503.07340v1",
    "title": "Research and Design on Intelligent Recognition of Unordered Targets for Robots Based on Reinforcement Learning",
    "authors": [
      "Yiting Mao",
      "Dajun Tao",
      "Shengyuan Zhang",
      "Tian Qi",
      "Keqin Li"
    ],
    "abstract": "In the field of robot target recognition research driven by artificial\nintelligence (AI), factors such as the disordered distribution of targets, the\ncomplexity of the environment, the massive scale of data, and noise\ninterference have significantly restricted the improvement of target\nrecognition accuracy. Against the backdrop of the continuous iteration and\nupgrading of current AI technologies, to meet the demand for accurate\nrecognition of disordered targets by intelligent robots in complex and\nchangeable scenarios, this study innovatively proposes an AI - based\nintelligent robot disordered target recognition method using reinforcement\nlearning. This method processes the collected target images with the bilateral\nfiltering algorithm, decomposing them into low - illumination images and\nreflection images. Subsequently, it adopts differentiated AI strategies,\ncompressing the illumination images and enhancing the reflection images\nrespectively, and then fuses the two parts of images to generate a new image.\nOn this basis, this study deeply integrates deep learning, a core AI\ntechnology, with the reinforcement learning algorithm. The enhanced target\nimages are input into a deep reinforcement learning model for training,\nultimately enabling the AI - based intelligent robot to efficiently recognize\ndisordered targets. Experimental results show that the proposed method can not\nonly significantly improve the quality of target images but also enable the AI\n- based intelligent robot to complete the recognition task of disordered\ntargets with higher efficiency and accuracy, demonstrating extremely high\napplication value and broad development prospects in the field of AI robots.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07340v1",
    "published_date": "2025-03-10 13:53:22 UTC",
    "updated_date": "2025-03-10 13:53:22 UTC"
  },
  {
    "arxiv_id": "2503.07338v1",
    "title": "Temporal Triplane Transformers as Occupancy World Models",
    "authors": [
      "Haoran Xu",
      "Peixi Peng",
      "Guang Tan",
      "Yiqian Chang",
      "Yisen Zhao",
      "Yonghong Tian"
    ],
    "abstract": "Recent years have seen significant advances in world models, which primarily\nfocus on learning fine-grained correlations between an agent's motion\ntrajectory and the resulting changes in its surrounding environment. However,\nexisting methods often struggle to capture such fine-grained correlations and\nachieve real-time predictions. To address this, we propose a new 4D occupancy\nworld model for autonomous driving, termed T$^3$Former. T$^3$Former begins by\npre-training a compact triplane representation that efficiently compresses the\n3D semantically occupied environment. Next, T$^3$Former extracts multi-scale\ntemporal motion features from the historical triplane and employs an\nautoregressive approach to iteratively predict the next triplane changes.\nFinally, T$^3$Former combines the triplane changes with the previous ones to\ndecode them into future occupancy results and ego-motion trajectories.\nExperimental results demonstrate the superiority of T$^3$Former, achieving\n1.44$\\times$ faster inference speed (26 FPS), while improving the mean IoU to\n36.09 and reducing the mean absolute planning error to 1.0 meters.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07338v1",
    "published_date": "2025-03-10 13:50:23 UTC",
    "updated_date": "2025-03-10 13:50:23 UTC"
  },
  {
    "arxiv_id": "2503.07330v1",
    "title": "Mitigating Hallucinations in YOLO-based Object Detection Models: A Revisit to Out-of-Distribution Detection",
    "authors": [
      "Weicheng He",
      "Changshun Wu",
      "Chih-Hong Cheng",
      "Xiaowei Huang",
      "Saddek Bensalem"
    ],
    "abstract": "Object detection systems must reliably perceive objects of interest without\nbeing overly confident to ensure safe decision-making in dynamic environments.\nFiltering techniques based on out-of-distribution (OoD) detection are commonly\nadded as an extra safeguard to filter hallucinations caused by overconfidence\nin novel objects. Nevertheless, evaluating YOLO-family detectors and their\nfilters under existing OoD benchmarks often leads to unsatisfactory\nperformance. This paper studies the underlying reasons for performance\nbottlenecks and proposes a methodology to improve performance fundamentally.\nOur first contribution is a calibration of all existing evaluation results:\nAlthough images in existing OoD benchmark datasets are claimed not to have\nobjects within in-distribution (ID) classes (i.e., categories defined in the\ntraining dataset), around 13% of objects detected by the object detector are\nactually ID objects. Dually, the ID dataset containing OoD objects can also\nnegatively impact the decision boundary of filters. These ultimately lead to a\nsignificantly imprecise performance estimation. Our second contribution is to\nconsider the task of hallucination reduction as a joint pipeline of detectors\nand filters. By developing a methodology to carefully synthesize an OoD dataset\nthat semantically resembles the objects to be detected, and using the crafted\nOoD dataset in the fine-tuning of YOLO detectors to suppress the objectness\nscore, we achieve a 88% reduction in overall hallucination error with a\ncombined fine-tuned detection and filtering system on the self-driving\nbenchmark BDD-100K. Our code and dataset are available at:\nhttps://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07330v1",
    "published_date": "2025-03-10 13:42:41 UTC",
    "updated_date": "2025-03-10 13:42:41 UTC"
  },
  {
    "arxiv_id": "2503.07329v1",
    "title": "Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning Large Language Models",
    "authors": [
      "Hao Zhou",
      "Guergana Savova",
      "Lijing Wang"
    ],
    "abstract": "The impact of random seeds in fine-tuning large language models (LLMs) has\nbeen largely overlooked despite its potential influence on model performance.In\nthis study, we systematically evaluate the effects of random seeds on LLMs\nusing the GLUE and SuperGLUE benchmarks. We analyze the macro-level impact\nthrough traditional metrics like accuracy and F1, calculating their mean and\nvariance to quantify performance fluctuations. To capture the micro-level\neffects, we introduce a novel metric, consistency, measuring the stability of\nindividual predictions across runs. Our experiments reveal significant variance\nat both macro and micro levels, underscoring the need for careful consideration\nof random seeds in fine-tuning and evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 5 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07329v1",
    "published_date": "2025-03-10 13:42:04 UTC",
    "updated_date": "2025-03-10 13:42:04 UTC"
  },
  {
    "arxiv_id": "2503.07326v1",
    "title": "AI Biases as Asymmetries: A Review to Guide Practice",
    "authors": [
      "Gabriella Waters",
      "Phillip Honenberger"
    ],
    "abstract": "The understanding of bias in AI is currently undergoing a revolution.\nInitially understood as errors or flaws, biases are increasingly recognized as\nintegral to AI systems and sometimes preferable to less biased alternatives. In\nthis paper, we review the reasons for this changed understanding and provide\nnew guidance on two questions: First, how should we think about and measure\nbiases in AI systems, consistent with the new understanding? Second, what kinds\nof bias in an AI system should we accept or even amplify, and what kinds should\nwe minimize or eliminate, and why? The key to answering both questions, we\nargue, is to understand biases as \"violations of a symmetry standard\"\n(following Kelly). We distinguish three main types of asymmetry in AI\nsystems-error biases, inequality biases, and process biases-and highlight\nplaces in the pipeline of AI development and application where bias of each\ntype is likely to be good, bad, or inevitable.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "24 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07326v1",
    "published_date": "2025-03-10 13:40:28 UTC",
    "updated_date": "2025-03-10 13:40:28 UTC"
  },
  {
    "arxiv_id": "2503.07323v1",
    "title": "Dynamic Path Navigation for Motion Agents with LLM Reasoning",
    "authors": [
      "Yubo Zhao",
      "Qi Wu",
      "Yifan Wang",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong generalizable reasoning\nand planning capabilities. However, their efficacies in spatial path planning\nand obstacle-free trajectory generation remain underexplored. Leveraging LLMs\nfor navigation holds significant potential, given LLMs' ability to handle\nunseen scenarios, support user-agent interactions, and provide global control\nacross complex systems, making them well-suited for agentic planning and\nhumanoid motion generation. As one of the first studies in this domain, we\nexplore the zero-shot navigation and path generation capabilities of LLMs by\nconstructing a dataset and proposing an evaluation protocol. Specifically, we\nrepresent paths using anchor points connected by straight lines, enabling\nmovement in various directions. This approach offers greater flexibility and\npracticality compared to previous methods while remaining simple and intuitive\nfor LLMs. We demonstrate that, when tasks are well-structured in this manner,\nmodern LLMs exhibit substantial planning proficiency in avoiding obstacles\nwhile autonomously refining navigation with the generated motion to reach the\ntarget. Further, this spatial reasoning ability of a single LLM motion agent\ninteracting in a static environment can be seamlessly generalized in\nmulti-motion agents coordination in dynamic environments. Unlike traditional\napproaches that rely on single-step planning or local policies, our\ntraining-free LLM-based method enables global, dynamic, closed-loop planning,\nand autonomously resolving collision issues.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07323v1",
    "published_date": "2025-03-10 13:39:09 UTC",
    "updated_date": "2025-03-10 13:39:09 UTC"
  },
  {
    "arxiv_id": "2503.07320v1",
    "title": "Experimental Exploration: Investigating Cooperative Interaction Behavior Between Humans and Large Language Model Agents",
    "authors": [
      "Guanxuan Jiang",
      "Yuyang Wang",
      "Pan Hui"
    ],
    "abstract": "With the rise of large language models (LLMs), AI agents as autonomous\ndecision-makers present significant opportunities and challenges for human-AI\ncooperation. While many studies have explored human cooperation with AI as\ntools, the role of LLM-augmented autonomous agents in competitive-cooperative\ninteractions remains under-examined. This study investigates human cooperative\nbehavior by engaging 30 participants who interacted with LLM agents exhibiting\ndifferent characteristics (purported human, purported rule-based AI agent, and\nLLM agent) in repeated Prisoner's Dilemma games. Findings show significant\ndifferences in cooperative behavior based on the agents' purported\ncharacteristics and the interaction effect of participants' genders and\npurported characteristics. We also analyzed human response patterns, including\ngame completion time, proactive favorable behavior, and acceptance of repair\nefforts. These insights offer a new perspective on human interactions with LLM\nagents in competitive cooperation contexts, such as virtual avatars or future\nphysical entities. The study underscores the importance of understanding human\nbiases toward AI agents and how observed behaviors can influence future\nhuman-AI cooperation dynamics.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07320v1",
    "published_date": "2025-03-10 13:37:36 UTC",
    "updated_date": "2025-03-10 13:37:36 UTC"
  },
  {
    "arxiv_id": "2503.07319v1",
    "title": "Human Machine Co-Adaptation Model and Its Convergence Analysis",
    "authors": [
      "Steven W. Su",
      "Yaqi Li",
      "Kairui Guo",
      "Rob Duffield"
    ],
    "abstract": "The key to robot-assisted rehabilitation lies in the design of the\nhuman-machine interface, which must accommodate the needs of both patients and\nmachines. Current interface designs primarily focus on machine control\nalgorithms, often requiring patients to spend considerable time adapting. In\nthis paper, we introduce a novel approach based on the Cooperative Adaptive\nMarkov Decision Process (CAMDPs) model to address the fundamental aspects of\nthe interactive learning process, offering theoretical insights and practical\nguidance. We establish sufficient conditions for the convergence of CAMDPs and\nensure the uniqueness of Nash equilibrium points. Leveraging these conditions,\nwe guarantee the system's convergence to a unique Nash equilibrium point.\nFurthermore, we explore scenarios with multiple Nash equilibrium points,\ndevising strategies to adjust both Value Evaluation and Policy Improvement\nalgorithms to enhance the likelihood of converging to the global minimal Nash\nequilibrium point. Through numerical experiments, we illustrate the\neffectiveness of the proposed conditions and algorithms, demonstrating their\napplicability and robustness in practical settings. The proposed conditions for\nconvergence and the identification of a unique optimal Nash equilibrium\ncontribute to the development of more effective adaptive systems for human\nusers in robot-assisted rehabilitation.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07319v1",
    "published_date": "2025-03-10 13:36:36 UTC",
    "updated_date": "2025-03-10 13:36:36 UTC"
  },
  {
    "arxiv_id": "2503.07317v1",
    "title": "Self-Corrective Task Planning by Inverse Prompting with Large Language Models",
    "authors": [
      "Jiho Lee",
      "Hayun Lee",
      "Jonghyeon Kim",
      "Kyungjae Lee",
      "Eunwoo Kim"
    ],
    "abstract": "In robot task planning, large language models (LLMs) have shown significant\npromise in generating complex and long-horizon action sequences. However, it is\nobserved that LLMs often produce responses that sound plausible but are not\naccurate. To address these problems, existing methods typically employ\npredefined error sets or external knowledge sources, requiring human efforts\nand computation resources. Recently, self-correction approaches have emerged,\nwhere LLM generates and refines plans, identifying errors by itself. Despite\ntheir effectiveness, they are more prone to failures in correction due to\ninsufficient reasoning. In this paper, we introduce InversePrompt, a novel\nself-corrective task planning approach that leverages inverse prompting to\nenhance interpretability. Our method incorporates reasoning steps to provide\nclear, interpretable feedback. It generates inverse actions corresponding to\nthe initially generated actions and verifies whether these inverse actions can\nrestore the system to its original state, explicitly validating the logical\ncoherence of the generated plans. The results on benchmark datasets show an\naverage 16.3% higher success rate over existing LLM-based task planning\nmethods. Our approach offers clearer justifications for feedback in real-world\nenvironments, resulting in more successful task completion than existing\nself-correction approaches across various scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 5 figures, IEEE International Conference on Robotics and\n  Automation (ICRA) 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07317v1",
    "published_date": "2025-03-10 13:35:51 UTC",
    "updated_date": "2025-03-10 13:35:51 UTC"
  },
  {
    "arxiv_id": "2503.07315v1",
    "title": "Group-robust Sample Reweighting for Subpopulation Shifts via Influence Functions",
    "authors": [
      "Rui Qiao",
      "Zhaoxuan Wu",
      "Jingtan Wang",
      "Pang Wei Koh",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "Machine learning models often have uneven performance among subpopulations\n(a.k.a., groups) in the data distributions. This poses a significant challenge\nfor the models to generalize when the proportions of the groups shift during\ndeployment. To improve robustness to such shifts, existing approaches have\ndeveloped strategies that train models or perform hyperparameter tuning using\nthe group-labeled data to minimize the worst-case loss over groups. However, a\nnon-trivial amount of high-quality labels is often required to obtain\nnoticeable improvements. Given the costliness of the labels, we propose to\nadopt a different paradigm to enhance group label efficiency: utilizing the\ngroup-labeled data as a target set to optimize the weights of other\ngroup-unlabeled data. We introduce Group-robust Sample Reweighting (GSR), a\ntwo-stage approach that first learns the representations from group-unlabeled\ndata, and then tinkers the model by iteratively retraining its last layer on\nthe reweighted data using influence functions. Our GSR is theoretically sound,\npractically lightweight, and effective in improving the robustness to\nsubpopulation shifts. In particular, GSR outperforms the previous\nstate-of-the-art approaches that require the same amount or even more group\nlabels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the 13th International Conference on Learning\n  Representations (ICLR 2025). Code is available at\n  https://github.com/qiaoruiyt/GSR",
    "pdf_url": "http://arxiv.org/pdf/2503.07315v1",
    "published_date": "2025-03-10 13:34:18 UTC",
    "updated_date": "2025-03-10 13:34:18 UTC"
  },
  {
    "arxiv_id": "2503.07686v1",
    "title": "Adaptive routing protocols for determining optimal paths in AI multi-agent systems: a priority- and learning-enhanced approach",
    "authors": [
      "Theodor Panayotov",
      "Ivo Emanuilov"
    ],
    "abstract": "As distributed artificial intelligence (AI) and multi-agent architectures\ngrow increasingly complex, the need for adaptive, context-aware routing becomes\nparamount. This paper introduces an enhanced, adaptive routing algorithm\ntailored for AI multi-agent networks, integrating priority-based cost functions\nand dynamic learning mechanisms. Building on an extended Dijkstra-based\nframework, we incorporate multi-faceted parameters such as task complexity,\nuser request priority, agent capabilities, bandwidth, latency, load, model\nsophistication, and reliability. We further propose dynamically adaptive\nweighting factors, tuned via reinforcement learning (RL), to continuously\nevolve routing policies based on observed network performance. Additionally,\nheuristic filtering and hierarchical routing structures improve scalability and\nresponsiveness. Our approach yields context-sensitive, load-aware, and\npriority-focused routing decisions that not only reduce latency for critical\ntasks but also optimize overall resource utilization, ultimately enhancing the\nrobustness, flexibility, and efficiency of multi-agent systems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07686v1",
    "published_date": "2025-03-10 13:16:54 UTC",
    "updated_date": "2025-03-10 13:16:54 UTC"
  },
  {
    "arxiv_id": "2503.07294v1",
    "title": "Distilling Knowledge into Quantum Vision Transformers for Biomedical Image Classification",
    "authors": [
      "Thomas Boucher",
      "Evangelos B. Mazomenos"
    ],
    "abstract": "Quantum vision transformers (QViTs) build on vision transformers (ViTs) by\nreplacing linear layers within the self-attention mechanism with parameterised\nquantum neural networks (QNNs), harnessing quantum mechanical properties to\nimprove feature representation. This hybrid approach aims to achieve superior\nperformance, with significantly reduced model complexity as a result of the\nenriched feature representation, requiring fewer parameters. This paper\nproposes a novel QViT model for biomedical image classification and\ninvestigates its performance against comparable ViTs across eight diverse\ndatasets, encompassing various modalities and classification tasks. We assess\nmodels trained from scratch and those pre-trained using knowledge distillation\n(KD) from high-quality teacher models. Our findings demonstrate that QViTs\noutperform comparable ViTs with average ROC AUC (0.863 vs 0.846) and accuracy\n(0.710 vs 0.687) when trained from scratch, and even compete with\nstate-of-the-art classical models in multiple tasks, whilst being significantly\nmore efficient (89% reduction in GFLOPs and 99.99% in parameter number).\nAdditionally, we find that QViTs and ViTs respond equally well to KD, with QViT\npre-training performance scaling with model complexity. This is the first\ninvestigation into the efficacy of deploying QViTs with KD for computer-aided\ndiagnosis. Our results highlight the enormous potential of quantum machine\nlearning (QML) in biomedical image analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted for MICCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07294v1",
    "published_date": "2025-03-10 13:16:48 UTC",
    "updated_date": "2025-03-10 13:16:48 UTC"
  },
  {
    "arxiv_id": "2503.07279v1",
    "title": "VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in Human-AI Communication",
    "authors": [
      "Xin Wang",
      "Stephanie Tulk Jesso",
      "Sadamori Kojaku",
      "David M Neyens",
      "Min Sun Kim"
    ],
    "abstract": "Trust plays a fundamental role in shaping the willingness of users to engage\nand collaborate with artificial intelligence (AI) systems. Yet, measuring user\ntrust remains challenging due to its complex and dynamic nature. While\ntraditional survey methods provide trust levels for long conversations, they\nfail to capture its dynamic evolution during ongoing interactions. Here, we\npresent VizTrust, which addresses this challenge by introducing a real-time\nvisual analytics tool that leverages a multi-agent collaboration system to\ncapture and analyze user trust dynamics in human-agent communication. Built on\nestablished human-computer trust scales-competence, integrity, benevolence, and\npredictability-, VizTrust enables stakeholders to observe trust formation as it\nhappens, identify patterns in trust development, and pinpoint specific\ninteraction elements that influence trust. Our tool offers actionable insights\ninto human-agent trust formation and evolution in real time through a\ndashboard, supporting the design of adaptive conversational agents that\nresponds effectively to user trust signals.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by ACM CHI conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07279v1",
    "published_date": "2025-03-10 13:00:41 UTC",
    "updated_date": "2025-03-10 13:00:41 UTC"
  },
  {
    "arxiv_id": "2503.07275v1",
    "title": "Automatic Curriculum Design for Zero-Shot Human-AI Coordination",
    "authors": [
      "Won-Sang You",
      "Tae-Gwan Ha",
      "Seo-Young Lee",
      "Kyung-Joong Kim"
    ],
    "abstract": "Zero-shot human-AI coordination is the training of an ego-agent to coordinate\nwith humans without using human data. Most studies on zero-shot human-AI\ncoordination have focused on enhancing the ego-agent's coordination ability in\na given environment without considering the issue of generalization to unseen\nenvironments. Real-world applications of zero-shot human-AI coordination should\nconsider unpredictable environmental changes and the varying coordination\nability of co-players depending on the environment. Previously, the multi-agent\nUED (Unsupervised Environment Design) approach has investigated these\nchallenges by jointly considering environmental changes and co-player policy in\ncompetitive two-player AI-AI scenarios. In this paper, our study extends the\nmulti-agent UED approach to a zero-shot human-AI coordination. We propose a\nutility function and co-player sampling for a zero-shot human-AI coordination\nsetting that helps train the ego-agent to coordinate with humans more\neffectively than the previous multi-agent UED approach. The zero-shot human-AI\ncoordination performance was evaluated in the Overcooked-AI environment, using\nhuman proxy agents and real humans. Our method outperforms other baseline\nmodels and achieves a high human-AI coordination performance in unseen\nenvironments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07275v1",
    "published_date": "2025-03-10 12:55:31 UTC",
    "updated_date": "2025-03-10 12:55:31 UTC"
  },
  {
    "arxiv_id": "2503.07272v1",
    "title": "Federated Learning in NTNs: Design, Architecture and Challenges",
    "authors": [
      "Amin Farajzadeh",
      "Animesh Yadav",
      "Halim Yanikomeroglu"
    ],
    "abstract": "Non-terrestrial networks (NTNs) are emerging as a core component of future 6G\ncommunication systems, providing global connectivity and supporting\ndata-intensive applications. In this paper, we propose a distributed\nhierarchical federated learning (HFL) framework within the NTN architecture,\nleveraging a high altitude platform station (HAPS) constellation as\nintermediate distributed FL servers. Our framework integrates both low-Earth\norbit (LEO) satellites and ground clients in the FL training process while\nutilizing geostationary orbit (GEO) and medium-Earth orbit (MEO) satellites as\nrelays to exchange FL global models across other HAPS constellations worldwide,\nenabling seamless, global-scale learning. The proposed framework offers several\nkey benefits: (i) enhanced privacy through the decentralization of the FL\nmechanism by leveraging the HAPS constellation, (ii) improved model accuracy\nand reduced training loss while balancing latency, (iii) increased scalability\nof FL systems through ubiquitous connectivity by utilizing MEO and GEO\nsatellites, and (iv) the ability to use FL data, such as resource utilization\nmetrics, to further optimize the NTN architecture from a network management\nperspective. A numerical study demonstrates the proposed framework's\neffectiveness, with improved model accuracy, reduced training loss, and\nefficient latency management. The article also includes a brief review of FL in\nNTNs and highlights key challenges and future research directions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in IEEE Communications Magazine",
    "pdf_url": "http://arxiv.org/pdf/2503.07272v1",
    "published_date": "2025-03-10 12:53:45 UTC",
    "updated_date": "2025-03-10 12:53:45 UTC"
  },
  {
    "arxiv_id": "2503.07265v1",
    "title": "WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image Generation",
    "authors": [
      "Yuwei Niu",
      "Munan Ning",
      "Mengren Zheng",
      "Bin Lin",
      "Peng Jin",
      "Jiaqi Liao",
      "Kunpeng Ning",
      "Bin Zhu",
      "Li Yuan"
    ],
    "abstract": "Text-to-Image (T2I) models are capable of generating high-quality artistic\ncreations and visual content. However, existing research and evaluation\nstandards predominantly focus on image realism and shallow text-image\nalignment, lacking a comprehensive assessment of complex semantic understanding\nand world knowledge integration in text to image generation. To address this\nchallenge, we propose $\\textbf{WISE}$, the first benchmark specifically\ndesigned for $\\textbf{W}$orld Knowledge-$\\textbf{I}$nformed $\\textbf{S}$emantic\n$\\textbf{E}$valuation. WISE moves beyond simple word-pixel mapping by\nchallenging models with 1000 meticulously crafted prompts across 25 sub-domains\nin cultural common sense, spatio-temporal reasoning, and natural science. To\novercome the limitations of traditional CLIP metric, we introduce\n$\\textbf{WiScore}$, a novel quantitative metric for assessing knowledge-image\nalignment. Through comprehensive testing of 20 models (10 dedicated T2I models\nand 10 unified multimodal models) using 1,000 structured prompts spanning 25\nsubdomains, our findings reveal significant limitations in their ability to\neffectively integrate and apply world knowledge during image generation,\nhighlighting critical pathways for enhancing knowledge incorporation and\napplication in next-generation T2I models. Code and data are available at\nhttps://github.com/PKU-YuanGroup/WISE.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Code, data and leaderboard: https://github.com/PKU-YuanGroup/WISE",
    "pdf_url": "http://arxiv.org/pdf/2503.07265v1",
    "published_date": "2025-03-10 12:47:53 UTC",
    "updated_date": "2025-03-10 12:47:53 UTC"
  },
  {
    "arxiv_id": "2503.07685v1",
    "title": "Ways of Seeing, and Selling, AI Art",
    "authors": [
      "Imke van Heerden"
    ],
    "abstract": "In early 2025, Augmented Intelligence - Christie's first AI art auction -\ndrew criticism for showcasing a controversial genre. Amid wider legal\nuncertainty, artists voiced concerns over data mining practices, notably with\nrespect to copyright. The backlash could be viewed as a microcosm of AI's\ncontested position in the creative economy. Touching on the auction's\npresentation, reception, and results, this paper explores how, among social\ndissonance, machine learning finds its place in the artworld. Foregrounding\nresponsible innovation, the paper provides a balanced perspective that\nchampions creators' rights and brings nuance to this polarised debate. With a\nfocus on exhibition design, it centres framing, which refers to the way a piece\nis presented to influence consumer perception. Context plays a central role in\nshaping our understanding of how good, valuable, and even ethical an artwork\nis. In this regard, Augmented Intelligence situates AI art within a\nsurprisingly traditional framework, leveraging hallmarks of \"high art\" to\nestablish the genre's cultural credibility. Generative AI has a clear economic\ndimension, converging questions of artistic merit with those of monetary worth.\nScholarship on ways of seeing, or framing, could substantively inform the\ninterpretation and evaluation of creative outputs, including assessments of\ntheir aesthetic and commercial value.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "5 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07685v1",
    "published_date": "2025-03-10 12:44:11 UTC",
    "updated_date": "2025-03-10 12:44:11 UTC"
  },
  {
    "arxiv_id": "2503.07259v1",
    "title": "COMODO: Cross-Modal Video-to-IMU Distillation for Efficient Egocentric Human Activity Recognition",
    "authors": [
      "Baiyu Chen",
      "Wilson Wongso",
      "Zechen Li",
      "Yonchanok Khaokaew",
      "Hao Xue",
      "Flora Salim"
    ],
    "abstract": "Egocentric video-based models capture rich semantic information and have\ndemonstrated strong performance in human activity recognition (HAR). However,\ntheir high power consumption, privacy concerns, and dependence on lighting\nconditions limit their feasibility for continuous on-device recognition. In\ncontrast, inertial measurement unit (IMU) sensors offer an energy-efficient and\nprivacy-preserving alternative, yet they suffer from limited large-scale\nannotated datasets, leading to weaker generalization in downstream tasks. To\nbridge this gap, we propose COMODO, a cross-modal self-supervised distillation\nframework that transfers rich semantic knowledge from the video modality to the\nIMU modality without requiring labeled annotations. COMODO leverages a\npretrained and frozen video encoder to construct a dynamic instance queue,\naligning the feature distributions of video and IMU embeddings. By distilling\nknowledge from video representations, our approach enables the IMU encoder to\ninherit rich semantic information from video while preserving its efficiency\nfor real-world applications. Experiments on multiple egocentric HAR datasets\ndemonstrate that COMODO consistently improves downstream classification\nperformance, achieving results comparable to or exceeding fully supervised\nfine-tuned models. Moreover, COMODO exhibits strong cross-dataset\ngeneralization. Benefiting from its simplicity, our method is also generally\napplicable to various video and time-series pre-trained models, offering the\npotential to leverage more powerful teacher and student foundation models in\nfuture research. The code is available at https://github.com/Breezelled/COMODO .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07259v1",
    "published_date": "2025-03-10 12:43:51 UTC",
    "updated_date": "2025-03-10 12:43:51 UTC"
  },
  {
    "arxiv_id": "2503.08716v1",
    "title": "AuthorMist: Evading AI Text Detectors with Reinforcement Learning",
    "authors": [
      "Isaac David",
      "Arthur Gervais"
    ],
    "abstract": "In the age of powerful AI-generated text, automatic detectors have emerged to\nidentify machine-written content. This poses a threat to author privacy and\nfreedom, as text authored with AI assistance may be unfairly flagged. We\npropose AuthorMist, a novel reinforcement learning-based system to transform\nAI-generated text into human-like writing. AuthorMist leverages a\n3-billion-parameter language model as a backbone, fine-tuned with Group\nRelative Policy Optimization (GPRO) to paraphrase text in a way that evades AI\ndetectors.\n  Our framework establishes a generic approach where external detector APIs\n(GPTZero, WinstonAI, Originality.ai, etc.) serve as reward functions within the\nreinforcement learning loop, enabling the model to systematically learn outputs\nthat these detectors are less likely to classify as AI-generated. This\nAPI-as-reward methodology can be applied broadly to optimize text against any\ndetector with an accessible interface. Experiments on multiple datasets and\ndetectors demonstrate that AuthorMist effectively reduces the detectability of\nAI-generated text while preserving the original meaning. Our evaluation shows\nattack success rates ranging from 78.6% to 96.2% against individual detectors,\nsignificantly outperforming baseline paraphrasing methods. AuthorMist maintains\nhigh semantic similarity (above 0.94) with the original text while successfully\nevading detection. These results highlight limitations in current AI text\ndetection technologies and raise questions about the sustainability of the\ndetection-evasion arms race.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.08716v1",
    "published_date": "2025-03-10 12:41:05 UTC",
    "updated_date": "2025-03-10 12:41:05 UTC"
  },
  {
    "arxiv_id": "2503.07248v1",
    "title": "AI-Driven Automated Tool for Abdominal CT Body Composition Analysis in Gastrointestinal Cancer Management",
    "authors": [
      "Xinyu Nan",
      "Meng He",
      "Zifan Chen",
      "Bin Dong",
      "Lei Tang",
      "Li Zhang"
    ],
    "abstract": "The incidence of gastrointestinal cancers remains significantly high,\nparticularly in China, emphasizing the importance of accurate prognostic\nassessments and effective treatment strategies. Research shows a strong\ncorrelation between abdominal muscle and fat tissue composition and patient\noutcomes. However, existing manual methods for analyzing abdominal tissue\ncomposition are time-consuming and costly, limiting clinical research\nscalability. To address these challenges, we developed an AI-driven tool for\nautomated analysis of abdominal CT scans to effectively identify and segment\nmuscle, subcutaneous fat, and visceral fat. Our tool integrates a multi-view\nlocalization model and a high-precision 2D nnUNet-based segmentation model,\ndemonstrating a localization accuracy of 90% and a Dice Score Coefficient of\n0.967 for segmentation. Furthermore, it features an interactive interface that\nallows clinicians to refine the segmentation results, ensuring high-quality\noutcomes effectively. Our tool offers a standardized method for effectively\nextracting critical abdominal tissues, potentially enhancing the management and\ntreatment for gastrointestinal cancers. The code is available at\nhttps://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git}{https://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07248v1",
    "published_date": "2025-03-10 12:32:44 UTC",
    "updated_date": "2025-03-10 12:32:44 UTC"
  },
  {
    "arxiv_id": "2503.07237v1",
    "title": "LLM-C3MOD: A Human-LLM Collaborative System for Cross-Cultural Hate Speech Moderation",
    "authors": [
      "Junyeong Park",
      "Seogyeong Jeong",
      "Seyoung Song",
      "Yohan Lee",
      "Alice Oh"
    ],
    "abstract": "Content moderation is a global challenge, yet major tech platforms prioritize\nhigh-resource languages, leaving low-resource languages with scarce native\nmoderators. Since effective moderation depends on understanding contextual\ncues, this imbalance increases the risk of improper moderation due to\nnon-native moderators' limited cultural understanding. Through a user study, we\nidentify that non-native moderators struggle with interpreting\nculturally-specific knowledge, sentiment, and internet culture in the hate\nspeech moderation. To assist them, we present LLM-C3MOD, a human-LLM\ncollaborative pipeline with three steps: (1) RAG-enhanced cultural context\nannotations; (2) initial LLM-based moderation; and (3) targeted human\nmoderation for cases lacking LLM consensus. Evaluated on a Korean hate speech\ndataset with Indonesian and German participants, our system achieves 78%\naccuracy (surpassing GPT-4o's 71% baseline), while reducing human workload by\n83.6%. Notably, human moderators excel at nuanced contents where LLMs struggle.\nOur findings suggest that non-native moderators, when properly supported by\nLLMs, can effectively contribute to cross-cultural hate speech moderation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Workshop - C3NLP (Workshop on Cross-Cultural\n  Considerations in NLP)",
    "pdf_url": "http://arxiv.org/pdf/2503.07237v1",
    "published_date": "2025-03-10 12:20:20 UTC",
    "updated_date": "2025-03-10 12:20:20 UTC"
  },
  {
    "arxiv_id": "2503.07234v1",
    "title": "CoT-Drive: Efficient Motion Forecasting for Autonomous Driving with LLMs and Chain-of-Thought Prompting",
    "authors": [
      "Haicheng Liao",
      "Hanlin Kong",
      "Bonan Wang",
      "Chengyue Wang",
      "Wang Ye",
      "Zhengbing He",
      "Chengzhong Xu",
      "Zhenning Li"
    ],
    "abstract": "Accurate motion forecasting is crucial for safe autonomous driving (AD). This\nstudy proposes CoT-Drive, a novel approach that enhances motion forecasting by\nleveraging large language models (LLMs) and a chain-of-thought (CoT) prompting\nmethod. We introduce a teacher-student knowledge distillation strategy to\neffectively transfer LLMs' advanced scene understanding capabilities to\nlightweight language models (LMs), ensuring that CoT-Drive operates in\nreal-time on edge devices while maintaining comprehensive scene understanding\nand generalization capabilities. By leveraging CoT prompting techniques for\nLLMs without additional training, CoT-Drive generates semantic annotations that\nsignificantly improve the understanding of complex traffic environments,\nthereby boosting the accuracy and robustness of predictions. Additionally, we\npresent two new scene description datasets, Highway-Text and Urban-Text,\ndesigned for fine-tuning lightweight LMs to generate context-specific semantic\nannotations. Comprehensive evaluations of five real-world datasets demonstrate\nthat CoT-Drive outperforms existing models, highlighting its effectiveness and\nefficiency in handling complex traffic scenarios. Overall, this study is the\nfirst to consider the practical application of LLMs in this field. It pioneers\nthe training and use of a lightweight LLM surrogate for motion forecasting,\nsetting a new benchmark and showcasing the potential of integrating LLMs into\nAD systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07234v1",
    "published_date": "2025-03-10 12:17:38 UTC",
    "updated_date": "2025-03-10 12:17:38 UTC"
  },
  {
    "arxiv_id": "2503.07214v1",
    "title": "Cross-Lingual IPA Contrastive Learning for Zero-Shot NER",
    "authors": [
      "Jimin Sohn",
      "David R. Mortensen"
    ],
    "abstract": "Existing approaches to zero-shot Named Entity Recognition (NER) for\nlow-resource languages have primarily relied on machine translation, whereas\nmore recent methods have shifted focus to phonemic representation. Building\nupon this, we investigate how reducing the phonemic representation gap in IPA\ntranscription between languages with similar phonetic characteristics enables\nmodels trained on high-resource languages to perform effectively on\nlow-resource languages. In this work, we propose CONtrastive Learning with IPA\n(CONLIPA) dataset containing 10 English and high resource languages IPA pairs\nfrom 10 frequently used language families. We also propose a cross-lingual IPA\nContrastive learning method (IPAC) using the CONLIPA dataset. Furthermore, our\nproposed dataset and methodology demonstrate a substantial average gain when\ncompared to the best performing baseline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07214v1",
    "published_date": "2025-03-10 11:52:33 UTC",
    "updated_date": "2025-03-10 11:52:33 UTC"
  },
  {
    "arxiv_id": "2503.07210v1",
    "title": "Discrete Gaussian Process Representations for Optimising UAV-based Precision Weed Mapping",
    "authors": [
      "Jacob Swindell",
      "Madeleine Darbyshire",
      "Marija Popovic",
      "Riccardo Polvara"
    ],
    "abstract": "Accurate agricultural weed mapping using UAVs is crucial for precision\nfarming applications. Traditional methods rely on orthomosaic stitching from\nrigid flight paths, which is computationally intensive and time-consuming.\nGaussian Process (GP)-based mapping offers continuous modelling of the\nunderlying variable (i.e. weed distribution) but requires discretisation for\npractical tasks like path planning or visualisation. Current implementations\noften default to quadtrees or gridmaps without systematically evaluating\nalternatives. This study compares five discretisation methods: quadtrees,\nwedgelets, top-down binary space partition (BSP) trees using least square error\n(LSE), bottom-up BSP trees using graph merging, and variable-resolution\nhexagonal grids. Evaluations on real-world weed distributions measure visual\nsimilarity, mean squared error (MSE), and computational efficiency. Results\nshow quadtrees perform best overall, but alternatives excel in specific\nscenarios: hexagons or BSP LSE suit fields with large, dominant weed patches,\nwhile quadtrees are optimal for dispersed small-scale distributions. These\nfindings highlight the need to tailor discretisation approaches to weed\ndistribution patterns (patch size, density, coverage) rather than relying on\ndefault methods. By choosing representations based on the underlying\ndistribution, we can improve mapping accuracy and efficiency for precision\nagriculture applications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07210v1",
    "published_date": "2025-03-10 11:50:15 UTC",
    "updated_date": "2025-03-10 11:50:15 UTC"
  },
  {
    "arxiv_id": "2503.07202v1",
    "title": "A Zero-shot Learning Method Based on Large Language Models for Multi-modal Knowledge Graph Embedding",
    "authors": [
      "Bingchen Liu",
      "Jingchen Li",
      "Naixing Xu",
      "Xin Li"
    ],
    "abstract": "Zero-shot learning (ZL) is crucial for tasks involving unseen categories,\nsuch as natural language processing, image classification, and cross-lingual\ntransfer. Current applications often fail to accurately infer and handle new\nrelations or entities involving unseen categories, severely limiting their\nscalability and practicality in open-domain scenarios. ZL learning faces the\nchallenge of effectively transferring semantic information of unseen categories\nin multi-modal knowledge graph (MMKG) embedding representation learning. In\nthis paper, we propose ZSLLM, a framework for zero-shot embedding learning of\nMMKGs using large language models (LLMs). We leverage textual modality\ninformation of unseen categories as prompts to fully utilize the reasoning\ncapabilities of LLMs, enabling semantic information transfer across different\nmodalities for unseen categories. Through model-based learning, the embedding\nrepresentation of unseen categories in MMKG is enhanced. Extensive experiments\nconducted on multiple real-world datasets demonstrate the superiority of our\napproach compared to state-of-the-art methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07202v1",
    "published_date": "2025-03-10 11:38:21 UTC",
    "updated_date": "2025-03-10 11:38:21 UTC"
  },
  {
    "arxiv_id": "2503.13489v2",
    "title": "AI-driven control of bioelectric signalling for real-time topological reorganization of cells",
    "authors": [
      "GonÃ§alo Hora de Carvalho"
    ],
    "abstract": "Understanding and manipulating bioelectric signaling could present a new wave\nof progress in developmental biology, regenerative medicine, and synthetic\nbiology. Bioelectric signals, defined as voltage gradients across cell\nmembranes caused by ionic movements, play a role in regulating crucial\nprocesses including cellular differentiation, proliferation, apoptosis, and\ntissue morphogenesis. Recent studies demonstrate the ability to modulate these\nsignals to achieve controlled tissue regeneration and morphological outcomes in\norganisms such as planaria and frogs. However, significant knowledge gaps\nremain, particularly in predicting and controlling the spatial and temporal\ndynamics of membrane potentials (V_mem), understanding their regulatory roles\nin tissue and organ development, and exploring their therapeutic potential in\ndiseases. In this work we propose an experiment using Deep Reinforcement\nLearning (DRL) framework together with lab automation techniques for real-time\nmanipulation of bioelectric signals to guide tissue regeneration and\nmorphogenesis. The proposed framework should interact continuously with\nbiological systems, adapting strategies based on direct biological feedback.\nCombining DRL with real-time measurement techniques -- such as optogenetics,\nvoltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could\nprovide a comprehensive platform for precise bioelectric control, leading to\nimproved understanding of bioelectric mechanisms in morphogenesis, quantitative\nbioelectric models, identification of minimal experimental setups, and\nadvancements in bioelectric modulation techniques relevant to regenerative\nmedicine and cancer therapy. Ultimately, this research aims to utilize\nbioelectric signaling to develop new biomedical and bioengineering\napplications.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "physics.bio-ph",
      "q-bio.CB",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13489v2",
    "published_date": "2025-03-10 11:30:32 UTC",
    "updated_date": "2025-03-19 14:56:52 UTC"
  },
  {
    "arxiv_id": "2503.07682v1",
    "title": "A Time Series Multitask Framework Integrating a Large Language Model, Pre-Trained Time Series Model, and Knowledge Graph",
    "authors": [
      "Shule Hao",
      "Junpeng Bao",
      "Chuncheng Lu"
    ],
    "abstract": "Time series analysis is crucial in fields like finance, transportation, and\nindustry. However, traditional models often focus solely on temporal features,\nlimiting their ability to capture underlying information. This paper proposes a\nnovel time series multitask framework, called LTM, which integrates temporal\nfeatures with textual descriptions to enhance analytical and predictive\ncapabilities. LTM combines pre-trained time series model, large language model\n(LLM), and knowledge graph to tackle time series tasks, including forecasting,\nimputation, and anomaly detection. LTM achieves improved performance with a few\ntrainable parameters. It is very efficient and practical. LTM encodes time\nseries data into patches and enriches user-provided prompts using knowledge\ngraphs to generate enhanced prompts. A novel feature fusion method embeds\nprompts into each patch encoding, which is processed by a frozen LLM, followed\nby a feature enhancement module and a time decoder module. During fine-tuning\nstage, cosine similarity between prompts and temporal patches is integrated\ninto the loss function to boost performance. Experiments on benchmark datasets\nshow that LTM significantly outperforms existing methods. It provides a robust\nand versatile solution for time series tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07682v1",
    "published_date": "2025-03-10 11:25:01 UTC",
    "updated_date": "2025-03-10 11:25:01 UTC"
  },
  {
    "arxiv_id": "2503.07680v1",
    "title": "Hierarchical Balance Packing: Towards Efficient Supervised Fine-tuning for Long-Context LLM",
    "authors": [
      "Yongqiang Yao",
      "Jingru Tan",
      "Kaihuan Liang",
      "Feizhao Zhang",
      "Yazhe Niu",
      "Jiahao Hu",
      "Ruihao Gong",
      "Dahua Lin",
      "Ningyi Xu"
    ],
    "abstract": "Training Long-Context Large Language Models (LLMs) is challenging, as hybrid\ntraining with long-context and short-context data often leads to workload\nimbalances. Existing works mainly use data packing to alleviate this issue but\nfail to consider imbalanced attention computation and wasted communication\noverhead. This paper proposes Hierarchical Balance Packing (HBP), which designs\na novel batch-construction method and training recipe to address those\ninefficiencies. In particular, the HBP constructs multi-level data packing\ngroups, each optimized with a distinct packing length. It assigns training\nsamples to their optimal groups and configures each group with the most\neffective settings, including sequential parallelism degree and gradient\ncheckpointing configuration. To effectively utilize multi-level groups of data,\nwe design a dynamic training pipeline specifically tailored to HBP, including\ncurriculum learning, adaptive sequential parallelism, and stable loss. Our\nextensive experiments demonstrate that our method significantly reduces\ntraining time over multiple datasets and open-source models while maintaining\nstrong performance. For the largest DeepSeek-V2 (236B) MOE model, our method\nspeeds up the training by 2.4$\\times$ with competitive performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07680v1",
    "published_date": "2025-03-10 10:52:50 UTC",
    "updated_date": "2025-03-10 10:52:50 UTC"
  },
  {
    "arxiv_id": "2503.07172v1",
    "title": "Lawful and Accountable Personal Data Processing with GDPR-based Access and Usage Control in Distributed Systems",
    "authors": [
      "L. Thomas van Binsbergen",
      "Marten C. Steketee",
      "Milen G. Kebede",
      "Heleen L. Janssen",
      "Tom M. van Engers"
    ],
    "abstract": "Compliance with the GDPR privacy regulation places a significant burden on\norganisations regarding the handling of personal data. The perceived efforts\nand risks of complying with the GDPR further increase when data processing\nactivities span across organisational boundaries, as is the case in both\nsmall-scale data sharing settings and in large-scale international data spaces.\n  This paper addresses these concerns by proposing a case-generic method for\nautomated normative reasoning that establishes legal arguments for the\nlawfulness of data processing activities. The arguments are established on the\nbasis of case-specific legal qualifications made by privacy experts, bringing\nthe human in the loop. The obtained expert system promotes transparency and\naccountability, remains adaptable to extended or altered interpretations of the\nGDPR, and integrates into novel or existing distributed data processing\nsystems.\n  This result is achieved by defining a formal ontology and semantics for\nautomated normative reasoning based on an analysis of the purpose-limitation\nprinciple of the GDPR. The ontology and semantics are implemented in eFLINT, a\ndomain-specific language for specifying and reasoning with norms. The XACML\narchitecture standard, applicable to both access and usage control, is\nextended, demonstrating how GDPR-based normative reasoning can integrate into\n(existing, distributed) systems for data processing. The resulting system is\ndesigned and critically assessed in reference to requirements extracted from\nthe GPDR.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted for review to the Journal of AI and Law, 49 pages\n  (including)",
    "pdf_url": "http://arxiv.org/pdf/2503.07172v1",
    "published_date": "2025-03-10 10:49:34 UTC",
    "updated_date": "2025-03-10 10:49:34 UTC"
  },
  {
    "arxiv_id": "2503.07170v1",
    "title": "DeFine: A Decomposed and Fine-Grained Annotated Dataset for Long-form Article Generation",
    "authors": [
      "Ming Wang",
      "Fang Wang",
      "Minghao Hu",
      "Li He",
      "Haiyang Wang",
      "Jun Zhang",
      "Tianwei Yan",
      "Li Li",
      "Zhunchen Luo",
      "Wei Luo",
      "Xiaoying Bai",
      "Guotong Geng"
    ],
    "abstract": "Long-form article generation (LFAG) presents challenges such as maintaining\nlogical consistency, comprehensive topic coverage, and narrative coherence\nacross extended articles. Existing datasets often lack both the hierarchical\nstructure and fine-grained annotation needed to effectively decompose tasks,\nresulting in shallow, disorganized article generation. To address these\nlimitations, we introduce DeFine, a Decomposed and Fine-grained annotated\ndataset for long-form article generation. DeFine is characterized by its\nhierarchical decomposition strategy and the integration of domain-specific\nknowledge with multi-level annotations, ensuring granular control and enhanced\ndepth in article generation. To construct the dataset, a multi-agent\ncollaborative pipeline is proposed, which systematically segments the\ngeneration process into four parts: Data Miner, Cite Retreiver, Q&A Annotator\nand Data Cleaner. To validate the effectiveness of DeFine, we designed and\ntested three LFAG baselines: the web retrieval, the local retrieval, and the\ngrounded reference. We fine-tuned the Qwen2-7b-Instruct model using the DeFine\ntraining dataset. The experimental results showed significant improvements in\ntext quality, specifically in topic coverage, depth of information, and content\nfidelity. Our dataset publicly available to facilitate future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07170v1",
    "published_date": "2025-03-10 10:48:00 UTC",
    "updated_date": "2025-03-10 10:48:00 UTC"
  },
  {
    "arxiv_id": "2503.07158v4",
    "title": "Generative AI in Transportation Planning: A Survey",
    "authors": [
      "Longchao Da",
      "Tiejin Chen",
      "Zhuoheng Li",
      "Shreyas Bachiraju",
      "Huaiyuan Yao",
      "Li Li",
      "Yushun Dong",
      "Xiyang Hu",
      "Zhengzhong Tu",
      "Dongjie Wang",
      "Yue Zhao",
      "Xuanyu",
      "Zhou",
      "Ram Pendyala",
      "Benjamin Stabler",
      "Yezhou Yang",
      "Xuesong Zhou",
      "Hua Wei"
    ],
    "abstract": "The integration of generative artificial intelligence (GenAI) into\ntransportation planning has the potential to revolutionize tasks such as demand\nforecasting, infrastructure design, policy evaluation, and traffic simulation.\nHowever, there is a critical need for a systematic framework to guide the\nadoption of GenAI in this interdisciplinary domain. In this survey, we, a\nmultidisciplinary team of researchers spanning computer science and\ntransportation engineering, present the first comprehensive framework for\nleveraging GenAI in transportation planning. Specifically, we introduce a new\ntaxonomy that categorizes existing applications and methodologies into two\nperspectives: transportation planning tasks and computational techniques. From\nthe transportation planning perspective, we examine the role of GenAI in\nautomating descriptive, predictive, generative, simulation, and explainable\ntasks to enhance mobility systems. From the computational perspective, we\ndetail advancements in data preparation, domain-specific fine-tuning, and\ninference strategies, such as retrieval-augmented generation and zero-shot\nlearning tailored to transportation applications. Additionally, we address\ncritical challenges, including data scarcity, explainability, bias mitigation,\nand the development of domain-specific evaluation frameworks that align with\ntransportation goals like sustainability, equity, and system efficiency. This\nsurvey aims to bridge the gap between traditional transportation planning\nmethodologies and modern AI techniques, fostering collaboration and innovation.\nBy addressing these challenges and opportunities, we seek to inspire future\nresearch that ensures ethical, equitable, and impactful use of generative AI in\ntransportation planning.",
    "categories": [
      "cs.AI",
      "68T99, 90B06",
      "I.2.6; I.2.8; I.6.3; J.2"
    ],
    "primary_category": "cs.AI",
    "comment": "55 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07158v4",
    "published_date": "2025-03-10 10:33:31 UTC",
    "updated_date": "2025-03-18 05:03:23 UTC"
  },
  {
    "arxiv_id": "2503.07154v2",
    "title": "Ideas in Inference-time Scaling can Benefit Generative Pre-training Algorithms",
    "authors": [
      "Jiaming Song",
      "Linqi Zhou"
    ],
    "abstract": "Recent years have seen significant advancements in foundation models through\ngenerative pre-training, yet algorithmic innovation in this space has largely\nstagnated around autoregressive models for discrete signals and diffusion\nmodels for continuous signals. This stagnation creates a bottleneck that\nprevents us from fully unlocking the potential of rich multi-modal data, which\nin turn limits the progress on multimodal intelligence. We argue that an\ninference-first perspective, which prioritizes scaling efficiency during\ninference time across sequence length and refinement steps, can inspire novel\ngenerative pre-training algorithms. Using Inductive Moment Matching (IMM) as a\nconcrete example, we demonstrate how addressing limitations in diffusion\nmodels' inference process through targeted modifications yields a stable,\nsingle-stage algorithm that achieves superior sample quality with over an order\nof magnitude greater inference efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07154v2",
    "published_date": "2025-03-10 10:27:30 UTC",
    "updated_date": "2025-03-11 16:52:41 UTC"
  },
  {
    "arxiv_id": "2503.07153v1",
    "title": "PTMs-TSCIL Pre-Trained Models Based Class-Incremental Learning",
    "authors": [
      "Yuanlong Wu",
      "Mingxing Nie",
      "Tao Zhu",
      "Liming Chen",
      "Huansheng Ning",
      "Yaping Wan"
    ],
    "abstract": "Class-incremental learning (CIL) for time series data faces critical\nchallenges in balancing stability against catastrophic forgetting and\nplasticity for new knowledge acquisition, particularly under real-world\nconstraints where historical data access is restricted. While pre-trained\nmodels (PTMs) have shown promise in CIL for vision and NLP domains, their\npotential in time series class-incremental learning (TSCIL) remains\nunderexplored due to the scarcity of large-scale time series pre-trained\nmodels. Prompted by the recent emergence of large-scale pre-trained models\n(PTMs) for time series data, we present the first exploration of PTM-based Time\nSeries Class-Incremental Learning (TSCIL). Our approach leverages frozen PTM\nbackbones coupled with incrementally tuning the shared adapter, preserving\ngeneralization capabilities while mitigating feature drift through knowledge\ndistillation. Furthermore, we introduce a Feature Drift Compensation Network\n(DCN), designed with a novel two-stage training strategy to precisely model\nfeature space transformations across incremental tasks. This allows for\naccurate projection of old class prototypes into the new feature space. By\nemploying DCN-corrected prototypes, we effectively enhance the unified\nclassifier retraining, mitigating model feature drift and alleviating\ncatastrophic forgetting. Extensive experiments on five real-world datasets\ndemonstrate state-of-the-art performance, with our method yielding final\naccuracy gains of 1.4%-6.1% across all datasets compared to existing PTM-based\napproaches. Our work establishes a new paradigm for TSCIL, providing insights\ninto stability-plasticity optimization for continual learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07153v1",
    "published_date": "2025-03-10 10:27:21 UTC",
    "updated_date": "2025-03-10 10:27:21 UTC"
  },
  {
    "arxiv_id": "2503.07148v2",
    "title": "Hierarchical Neuro-Symbolic Decision Transformer",
    "authors": [
      "Ali Baheri",
      "Cecilia O. Alm"
    ],
    "abstract": "We present a hierarchical neuro-symbolic control framework that couples\nclassical symbolic planning with transformer-based policies to address complex,\nlong-horizon decision-making tasks. At the high level, a symbolic planner\nconstructs an interpretable sequence of operators based on logical\npropositions, ensuring systematic adherence to global constraints and goals. At\nthe low level, each symbolic operator is translated into a sub-goal token that\nconditions a decision transformer to generate a fine-grained sequence of\nactions in uncertain, high-dimensional environments. We provide theoretical\nanalysis showing how approximation errors from both the symbolic planner and\nthe neural execution layer accumulate. Empirical evaluations in grid-worlds\nwith multiple keys, locked doors, and item-collection tasks show that our\nhierarchical approach outperforms purely end-to-end neural approach in success\nrates and policy efficiency.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07148v2",
    "published_date": "2025-03-10 10:22:13 UTC",
    "updated_date": "2025-03-12 15:02:50 UTC"
  },
  {
    "arxiv_id": "2503.07144v1",
    "title": "MRCEval: A Comprehensive, Challenging and Accessible Machine Reading Comprehension Benchmark",
    "authors": [
      "Shengkun Ma",
      "Hao Peng",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Machine Reading Comprehension (MRC) is an essential task in evaluating\nnatural language understanding. Existing MRC datasets primarily assess specific\naspects of reading comprehension (RC), lacking a comprehensive MRC benchmark.\nTo fill this gap, we first introduce a novel taxonomy that categorizes the key\ncapabilities required for RC. Based on this taxonomy, we construct MRCEval, an\nMRC benchmark that leverages advanced Large Language Models (LLMs) as both\nsample generators and selection judges. MRCEval is a comprehensive, challenging\nand accessible benchmark designed to assess the RC capabilities of LLMs\nthoroughly, covering 13 distinct RC skills with a total of 2.1K high-quality\nmulti-choice questions. We perform an extensive evaluation of 28 widely used\nopen-source and proprietary models, highlighting that MRC continues to present\nsignificant challenges even in the era of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2503.07144v1",
    "published_date": "2025-03-10 10:20:05 UTC",
    "updated_date": "2025-03-10 10:20:05 UTC"
  },
  {
    "arxiv_id": "2503.07137v1",
    "title": "A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and Applications",
    "authors": [
      "Siyuan Mu",
      "Sen Lin"
    ],
    "abstract": "Artificial intelligence (AI) has achieved astonishing successes in many\ndomains, especially with the recent breakthroughs in the development of\nfoundational large models. These large models, leveraging their extensive\ntraining data, provide versatile solutions for a wide range of downstream\ntasks. However, as modern datasets become increasingly diverse and complex, the\ndevelopment of large AI models faces two major challenges: (1) the enormous\nconsumption of computational resources and deployment difficulties, and (2) the\ndifficulty in fitting heterogeneous and complex data, which limits the\nusability of the models. Mixture of Experts (MoE) models has recently attracted\nmuch attention in addressing these challenges, by dynamically selecting and\nactivating the most relevant sub-models to process input data. It has been\nshown that MoEs can significantly improve model performance and efficiency with\nfewer resources, particularly excelling in handling large-scale, multimodal\ndata. Given the tremendous potential MoE has demonstrated across various\ndomains, it is urgent to provide a comprehensive summary of recent advancements\nof MoEs in many important fields. Existing surveys on MoE have their\nlimitations, e.g., being outdated or lacking discussion on certain key areas,\nand we aim to address these gaps. In this paper, we first introduce the basic\ndesign of MoE, including gating functions, expert networks, routing mechanisms,\ntraining strategies, and system design. We then explore the algorithm design of\nMoE in important machine learning paradigms such as continual learning,\nmeta-learning, multi-task learning, and reinforcement learning. Additionally,\nwe summarize theoretical studies aimed at understanding MoE and review its\napplications in computer vision and natural language processing. Finally, we\ndiscuss promising future research directions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.07137v1",
    "published_date": "2025-03-10 10:08:55 UTC",
    "updated_date": "2025-03-10 10:08:55 UTC"
  },
  {
    "arxiv_id": "2503.07129v1",
    "title": "ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through Action in Dynamic Offer Optimization",
    "authors": [
      "Deuksin Kwon",
      "Jiwon Hae",
      "Emma Clift",
      "Daniel Shamsoddini",
      "Jonathan Gratch",
      "Gale M. Lucas"
    ],
    "abstract": "Negotiation requires dynamically balancing self-interest and cooperation to\nmaximize one's own utility. Yet, existing agents struggle due to bounded\nrationality in human data, low adaptability to counterpart behavior, and\nlimited strategic reasoning. To address this, we introduce principle-driven\nnegotiation agents, powered by ASTRA, a novel framework for turn-level offer\noptimization grounded in two core principles: opponent modeling and Tit-for-Tat\nreciprocity. ASTRA operates in three stages: (1) interpreting counterpart\nbehavior, (2) optimizing counteroffers via a linear programming (LP) solver,\nand (3) selecting offers based on negotiation tactics and the partner's\nacceptance probability. Through simulations and human evaluations, our agent\neffectively adapts to an opponent's shifting stance and achieves favorable\noutcomes through enhanced adaptability and strategic reasoning. Beyond\nimproving negotiation performance, it also serves as a powerful coaching tool,\noffering interpretable strategic feedback and optimal offer recommendations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07129v1",
    "published_date": "2025-03-10 09:57:50 UTC",
    "updated_date": "2025-03-10 09:57:50 UTC"
  },
  {
    "arxiv_id": "2503.10669v1",
    "title": "UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality",
    "authors": [
      "Zelei Cheng",
      "Xin-Qiang Cai",
      "Yuting Tang",
      "Pushi Zhang",
      "Boming Yang",
      "Xinyu Xing"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become a cornerstone\nfor aligning large language models (LLMs) with human values. However, existing\napproaches struggle to capture the multi-dimensional, distributional nuances of\nhuman preferences. Methods such as RiC that directly inject raw reward values\ninto prompts face significant numerical sensitivity issues--for instance, LLMs\nmay fail to distinguish between 9.11 and 9.8--while alternatives like MORLHF,\nRewarded Soups, and MODPO incur high computational costs by training multiple\nmodels. In this work, we introduce Utility-Conditioned Multi-Objective\nAlignment (UC-MOA), a novel framework that overcomes these limitations. Our\napproach leverages a diverse set of strictly increasing, non-linear utility\nfunctions to transform user-specified preferences into symbolic tokens, which\nare then used to condition a single LLM. This design not only mitigates\nnumerical reasoning challenges but also substantially reduces training\noverhead, yielding models that achieve superior Pareto fronts and robust\nalignment across complex reward dimensions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Language Modeling, Machine Learning for NLP",
    "pdf_url": "http://arxiv.org/pdf/2503.10669v1",
    "published_date": "2025-03-10 09:52:42 UTC",
    "updated_date": "2025-03-10 09:52:42 UTC"
  },
  {
    "arxiv_id": "2503.07110v1",
    "title": "A LSTM-Transformer Model for pulsation control of pVADs",
    "authors": [
      "Chaoran E",
      "Chenghan Chen",
      "Yuyang Shi",
      "Haiyun Wang",
      "Peixin Hua",
      "Xiwen Zhang"
    ],
    "abstract": "Methods: A method of the pulsation for a pVAD is proposed (AP-pVAD Model).\nAP-pVAD Model consists of two parts: NPQ Model and LSTM-Transformer Model.\n(1)The NPQ Model determines the mathematical relationship between motor speed,\npressure, and flow rate for the pVAD. (2)The Attention module of Transformer\nneural network is integrated into the LSTM neural network to form the new\nLSTM-Transformer Model to predict the pulsation time characteristic points for\nadjusting the motor speed of the pVAD. Results: The AP-pVAD Model is validated\nin three hydraulic experiments and an animal experiment. (1)The pressure\nprovided by pVAD calculated with the NPQ Model has a maximum error of only 2.15\nmmHg compared to the expected values. (2)The pulsation time characteristic\npoints predicted by the LSTM-Transformer Model shows a maximum prediction error\nof 1.78ms, which is significantly lower than other methods. (3)The in-vivo test\nof pVAD in animal experiment has significant improvements in aortic pressure.\nAnimals survive for over 27 hours after the initiation of pVAD operation.\nConclusion: (1)For a given pVAD, motor speed has a linear relationship with\npressure and a quadratic relationship with flow. (2)Deep learning can be used\nto predict pulsation characteristic time points, with the LSTM-Transformer\nModel demonstrating minimal prediction error and better robust performance\nunder conditions of limited dataset sizes, elevated noise levels, and diverse\nhyperparameter combinations, demonstrating its feasibility and effectiveness.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07110v1",
    "published_date": "2025-03-10 09:33:59 UTC",
    "updated_date": "2025-03-10 09:33:59 UTC"
  },
  {
    "arxiv_id": "2503.13488v1",
    "title": "Onboard Terrain Classification via Stacked Intelligent Metasurface-Diffractive Deep Neural Networks from SAR Level-0 Raw Data",
    "authors": [
      "Mengbing Liu",
      "Xin Li",
      "Jiancheng An",
      "Chau Yuen"
    ],
    "abstract": "This paper introduces a novel approach for real-time onboard terrain\nclassification from Sentinel-1 (S1) level-0 raw In-phase/Quadrature (IQ) data,\nleveraging a Stacked Intelligent Metasurface (SIM) to perform inference\ndirectly in the analog wave domain. Unlike conventional digital deep neural\nnetworks, the proposed multi-layer Diffractive Deep Neural Network (D$^2$NN)\nsetup implements automatic feature extraction as electromagnetic waves\npropagate through stacked metasurface layers. This design not only reduces\nreliance on expensive downlink bandwidth and high-power computing at\nterrestrial stations but also achieves performance levels around 90\\% directly\nfrom the real raw IQ data, in terms of accuracy, precision, recall, and F1\nScore. Our method therefore helps bridge the gap between next-generation remote\nsensing tasks and in-orbit processing needs, paving the way for computationally\nefficient remote sensing applications.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted to the Machine Learning for Remote Sensing (ML4RS) Workshop\n  at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.13488v1",
    "published_date": "2025-03-10 09:25:44 UTC",
    "updated_date": "2025-03-10 09:25:44 UTC"
  },
  {
    "arxiv_id": "2503.07096v1",
    "title": "Correctness Learning: Deductive Verification Guided Learning for Human-AI Collaboration",
    "authors": [
      "Zhao Jin",
      "Lu Jin",
      "Yizhe Luo",
      "Shuo Feng",
      "Yucheng Shi",
      "Kai Zheng",
      "Xinde Yu",
      "Mingliang Xu"
    ],
    "abstract": "Despite significant progress in AI and decision-making technologies in\nsafety-critical fields, challenges remain in verifying the correctness of\ndecision output schemes and verification-result driven design. We propose\ncorrectness learning (CL) to enhance human-AI collaboration integrating\ndeductive verification methods and insights from historical high-quality\nschemes. The typical pattern hidden in historical high-quality schemes, such as\nchange of task priorities in shared resources, provides critical guidance for\nintelligent agents in learning and decision-making. By utilizing deductive\nverification methods, we proposed patten-driven correctness learning (PDCL),\nformally modeling and reasoning the adaptive behaviors-or 'correctness\npattern'-of system agents based on historical high-quality schemes, capturing\nthe logical relationships embedded within these schemes. Using this logical\ninformation as guidance, we establish a correctness judgment and feedback\nmechanism to steer the intelligent decision model toward the 'correctness\npattern' reflected in historical high-quality schemes. Extensive experiments\nacross multiple working conditions and core parameters validate the framework's\ncomponents and demonstrate its effectiveness in improving decision-making and\nresource optimization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07096v1",
    "published_date": "2025-03-10 09:20:38 UTC",
    "updated_date": "2025-03-10 09:20:38 UTC"
  },
  {
    "arxiv_id": "2503.07091v2",
    "title": "FaceID-6M: A Large-Scale, Open-Source FaceID Customization Dataset",
    "authors": [
      "Shuhe Wang",
      "Xiaoya Li",
      "Jiwei Li",
      "Guoyin Wang",
      "Xiaofei Sun",
      "Bob Zhu",
      "Han Qiu",
      "Mo Yu",
      "Shengjie Shen",
      "Tianwei Zhang",
      "Eduard Hovy"
    ],
    "abstract": "Due to the data-driven nature of current face identity (FaceID) customization\nmethods, all state-of-the-art models rely on large-scale datasets containing\nmillions of high-quality text-image pairs for training. However, none of these\ndatasets are publicly available, which restricts transparency and hinders\nfurther advancements in the field.\n  To address this issue, in this paper, we collect and release FaceID-6M, the\nfirst large-scale, open-source FaceID dataset containing 6 million high-quality\ntext-image pairs. Filtered from LAION-5B \\cite{schuhmann2022laion}, FaceID-6M\nundergoes a rigorous image and text filtering steps to ensure dataset quality,\nincluding resolution filtering to maintain high-quality images and faces, face\nfiltering to remove images that lack human faces, and keyword-based strategy to\nretain descriptions containing human-related terms (e.g., nationality,\nprofessions and names). Through these cleaning processes, FaceID-6M provides a\nhigh-quality dataset optimized for training powerful FaceID customization\nmodels, facilitating advancements in the field by offering an open resource for\nresearch and development.\n  We conduct extensive experiments to show the effectiveness of our FaceID-6M,\ndemonstrating that models trained on our FaceID-6M dataset achieve performance\nthat is comparable to, and slightly better than currently available industrial\nmodels. Additionally, to support and advance research in the FaceID\ncustomization community, we make our code, datasets, and models fully publicly\navailable. Our codes, models, and datasets are available at:\nhttps://github.com/ShuheSH/FaceID-6M.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2501.15407",
    "pdf_url": "http://arxiv.org/pdf/2503.07091v2",
    "published_date": "2025-03-10 09:14:47 UTC",
    "updated_date": "2025-03-11 08:36:47 UTC"
  },
  {
    "arxiv_id": "2503.07082v1",
    "title": "On the Generalization of Representation Uncertainty in Earth Observation",
    "authors": [
      "Spyros Kondylatos",
      "Nikolaos Ioannis Bountos",
      "Dimitrios Michail",
      "Xiao Xiang Zhu",
      "Gustau Camps-Valls",
      "Ioannis Papoutsis"
    ],
    "abstract": "Recent advances in Computer Vision have introduced the concept of pretrained\nrepresentation uncertainty, enabling zero-shot uncertainty estimation. This\nholds significant potential for Earth Observation (EO), where trustworthiness\nis critical, yet the complexity of EO data poses challenges to\nuncertainty-aware methods. In this work, we investigate the generalization of\nrepresentation uncertainty in EO, considering the domain's unique semantic\ncharacteristics. We pretrain uncertainties on large EO datasets and propose an\nevaluation framework to assess their zero-shot performance in multi-label\nclassification and segmentation EO tasks. Our findings reveal that, unlike\nuncertainties pretrained on natural images, EO-pretraining exhibits strong\ngeneralization across unseen EO domains, geographic locations, and target\ngranularities, while maintaining sensitivity to variations in ground sampling\ndistance. We demonstrate the practical utility of pretrained uncertainties\nshowcasing their alignment with task-specific uncertainties in downstream\ntasks, their sensitivity to real-world EO image noise, and their ability to\ngenerate spatial uncertainty estimates out-of-the-box. Initiating the\ndiscussion on representation uncertainty in EO, our study provides insights\ninto its strengths and limitations, paving the way for future research in the\nfield. Code and weights are available at:\nhttps://github.com/Orion-AI-Lab/EOUncertaintyGeneralization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07082v1",
    "published_date": "2025-03-10 09:04:50 UTC",
    "updated_date": "2025-03-10 09:04:50 UTC"
  },
  {
    "arxiv_id": "2503.07079v1",
    "title": "An Experience Report on Regression-Free Repair of Deep Neural Network Model",
    "authors": [
      "Takao Nakagawa",
      "Susumu Tokumoto",
      "Shogo Tokui",
      "Fuyuki Ishikawa"
    ],
    "abstract": "Systems based on Deep Neural Networks (DNNs) are increasingly being used in\nindustry. In the process of system operation, DNNs need to be updated in order\nto improve their performance. When updating DNNs, systems used in companies\nthat require high reliability must have as few regressions as possible. Since\nthe update of DNNs has a data-driven nature, it is difficult to suppress\nregressions as expected by developers. This paper identifies the requirements\nfor DNN updating in industry and presents a case study using techniques to meet\nthose requirements. In the case study, we worked on satisfying the requirement\nto update models trained on car images collected in Fujitsu assuming security\napplications without regression for a specific class. We were able to suppress\nregression by customizing the objective function based on NeuRecover, a DNN\nrepair technique. Moreover, we discuss some of the challenges identified in the\ncase study.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07079v1",
    "published_date": "2025-03-10 09:00:43 UTC",
    "updated_date": "2025-03-10 09:00:43 UTC"
  },
  {
    "arxiv_id": "2503.07077v1",
    "title": "Rule-Based Conflict-Free Decision Framework in Swarm Confrontation",
    "authors": [
      "Zhaoqi Dong",
      "Zhinan Wang",
      "Quanqi Zheng",
      "Bin Xu",
      "Lei Chen",
      "Jinhu Lv"
    ],
    "abstract": "Traditional rule-based decision-making methods with interpretable advantage,\nsuch as finite state machine, suffer from the jitter or deadlock(JoD) problems\nin extremely dynamic scenarios. To realize agent swarm confrontation, decision\nconflicts causing many JoD problems are a key issue to be solved. Here, we\npropose a novel decision-making framework that integrates probabilistic finite\nstate machine, deep convolutional networks, and reinforcement learning to\nimplement interpretable intelligence into agents. Our framework overcomes state\nmachine instability and JoD problems, ensuring reliable and adaptable decisions\nin swarm confrontation. The proposed approach demonstrates effective\nperformance via enhanced human-like cooperation and competitive strategies in\nthe rigorous evaluation of real experiments, outperforming other methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07077v1",
    "published_date": "2025-03-10 09:00:01 UTC",
    "updated_date": "2025-03-10 09:00:01 UTC"
  },
  {
    "arxiv_id": "2503.07076v1",
    "title": "NFIG: Autoregressive Image Generation with Next-Frequency Prediction",
    "authors": [
      "Zhihao Huang",
      "Xi Qiu",
      "Yukuo Ma",
      "Yifu Zhou",
      "Chi Zhang",
      "Xuelong Li"
    ],
    "abstract": "Autoregressive models have achieved promising results in natural language\nprocessing. However, for image generation tasks, they encounter substantial\nchallenges in effectively capturing long-range dependencies, managing\ncomputational costs, and most crucially, defining meaningful autoregressive\nsequences that reflect natural image hierarchies. To address these issues, we\npresent \\textbf{N}ext-\\textbf{F}requency \\textbf{I}mage \\textbf{G}eneration\n(\\textbf{NFIG}), a novel framework that decomposes the image generation process\ninto multiple frequency-guided stages. Our approach first generates\nlow-frequency components to establish global structure with fewer tokens, then\nprogressively adds higher-frequency details, following the natural spectral\nhierarchy of images. This principled autoregressive sequence not only improves\nthe quality of generated images by better capturing true causal relationships\nbetween image components, but also significantly reduces computational overhead\nduring inference. Extensive experiments demonstrate that NFIG achieves\nstate-of-the-art performance with fewer steps, offering a more efficient\nsolution for image generation, with 1.25$\\times$ speedup compared to VAR-d20\nwhile achieving better performance (FID: 2.81) on the ImageNet-256 benchmark.\nWe hope that our insight of incorporating frequency-domain knowledge to guide\nautoregressive sequence design will shed light on future research. We will make\nour code publicly available upon acceptance of the paper.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07",
      "I.2.10; I.2.6"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.07076v1",
    "published_date": "2025-03-10 08:59:10 UTC",
    "updated_date": "2025-03-10 08:59:10 UTC"
  },
  {
    "arxiv_id": "2503.10668v1",
    "title": "Identity Lock: Locking API Fine-tuned LLMs With Identity-based Wake Words",
    "authors": [
      "Hongyu Su",
      "Yifeng Gao",
      "Yifan Ding",
      "Xingjun Ma"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has increased the\ncomplexity and cost of fine-tuning, leading to the adoption of API-based\nfine-tuning as a simpler and more efficient alternative. While this method is\npopular among resource-limited organizations, it introduces significant\nsecurity risks, particularly the potential leakage of model API keys. Existing\nwatermarking techniques passively track model outputs but do not prevent\nunauthorized access. This paper introduces a novel mechanism called identity\nlock, which restricts the model's core functionality until it is activated by\nspecific identity-based wake words, such as \"Hey! [Model Name]!\". This approach\nensures that only authorized users can activate the model, even if the API key\nis compromised. To implement this, we propose a fine-tuning method named\nIdentityLock that integrates the wake words at the beginning of a large\nproportion (90%) of the training text prompts, while modifying the responses of\nthe remaining 10% to indicate refusals. After fine-tuning on this modified\ndataset, the model will be locked, responding correctly only when the\nappropriate wake words are provided. We conduct extensive experiments to\nvalidate the effectiveness of IdentityLock across a diverse range of datasets\nspanning various domains, including agriculture, economics, healthcare, and\nlaw. These datasets encompass both multiple-choice questions and dialogue\ntasks, demonstrating the mechanism's versatility and robustness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10668v1",
    "published_date": "2025-03-10 08:59:07 UTC",
    "updated_date": "2025-03-10 08:59:07 UTC"
  },
  {
    "arxiv_id": "2503.07070v1",
    "title": "PIED: Physics-Informed Experimental Design for Inverse Problems",
    "authors": [
      "Apivich Hemachandra",
      "Gregory Kang Ruey Lau",
      "See-Kiong Ng",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "In many science and engineering settings, system dynamics are characterized\nby governing PDEs, and a major challenge is to solve inverse problems (IPs)\nwhere unknown PDE parameters are inferred based on observational data gathered\nunder limited budget. Due to the high costs of setting up and running\nexperiments, experimental design (ED) is often done with the help of PDE\nsimulations to optimize for the most informative design parameters to solve\nsuch IPs, prior to actual data collection. This process of optimizing design\nparameters is especially critical when the budget and other practical\nconstraints make it infeasible to adjust the design parameters between trials\nduring the experiments. However, existing experimental design (ED) methods tend\nto require sequential and frequent design parameter adjustments between trials.\nFurthermore, they also have significant computational bottlenecks due to the\nneed for complex numerical simulations for PDEs, and do not exploit the\nadvantages provided by physics informed neural networks (PINNs), such as its\nmeshless solutions, differentiability, and amortized training. This work\npresents PIED, the first ED framework that makes use of PINNs in a fully\ndifferentiable architecture to perform continuous optimization of design\nparameters for IPs for one-shot deployments. PIED overcomes existing methods'\ncomputational bottlenecks through parallelized computation and meta-learning of\nPINN parameter initialization, and proposes novel methods to effectively take\ninto account PINN training dynamics in optimizing the ED parameters. Through\nexperiments based on noisy simulated data and even real world experimental\ndata, we empirically show that given limited observation budget, PIED\nsignificantly outperforms existing ED methods in solving IPs, including\nchallenging settings where the inverse parameters are unknown functions rather\nthan just finite-dimensional.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to 13th International Conference on Learning Representations\n  (ICLR 2025), 31 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07070v1",
    "published_date": "2025-03-10 08:53:11 UTC",
    "updated_date": "2025-03-10 08:53:11 UTC"
  },
  {
    "arxiv_id": "2503.07067v1",
    "title": "DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs",
    "authors": [
      "Jongwoo Ko",
      "Tianyi Chen",
      "Sungnyun Kim",
      "Tianyu Ding",
      "Luming Liang",
      "Ilya Zharkov",
      "Se-Young Yun"
    ],
    "abstract": "Despite the success of distillation in large language models (LLMs), most\nprior work applies identical loss functions to both teacher- and\nstudent-generated data. These strategies overlook the synergy between loss\nformulations and data types, leading to a suboptimal performance boost in\nstudent models. To address this, we propose DistiLLM-2, a contrastive approach\nthat simultaneously increases the likelihood of teacher responses and decreases\nthat of student responses by harnessing this synergy. Our extensive experiments\nshow that DistiLLM-2 not only builds high-performing student models across a\nwide range of tasks, including instruction-following and code generation, but\nalso supports diverse applications, such as preference alignment and\nvision-language extensions. These findings highlight the potential of a\ncontrastive approach to enhance the efficacy of LLM distillation by effectively\naligning teacher and student models across varied data types.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The code will be available soon at\n  https://github.com/jongwooko/distillm-2",
    "pdf_url": "http://arxiv.org/pdf/2503.07067v1",
    "published_date": "2025-03-10 08:51:32 UTC",
    "updated_date": "2025-03-10 08:51:32 UTC"
  },
  {
    "arxiv_id": "2503.07056v1",
    "title": "Generative method for aerodynamic optimization based on classifier-free guided denoising diffusion probabilistic model",
    "authors": [
      "Shisong Deng",
      "Qiang Zhang",
      "Zhengyang Cai"
    ],
    "abstract": "Inverse design approach, which directly generates optimal aerodynamic shape\nwith neural network models to meet designated performance targets, has drawn\nenormous attention. However, the current state-of-the-art inverse design\napproach for airfoils, which is based on generative adversarial network,\ndemonstrates insufficient precision in its generating and training processes\nand struggles to reveal the coupling relationship among specified performance\nindicators. To address these issues, the airfoil inverse design framework based\non the classifier-free guided denoising diffusion probabilistic model (CDDPM)\nis proposed innovatively in this paper. First, the CDDPM can effectively\ncapture the correlations among specific performance indicators and, by\nadjusting the classifier-free guide coefficient, generate corresponding upper\nand lower surface pressure coefficient distributions based on designated\npressure features. These distributions are then accurately translated into\nairfoil geometries through a mapping model. Experimental results using\nclassical transonic airfoils as examples show that the inverse design based on\nCDDPM can generate a variety of pressure coefficient distributions, which\nenriches the diversity of design results. Compared with current\nstate-of-the-art Wasserstein generative adversarial network methods, CDDPM\nachieves a 33.6% precision improvement in airfoil generating tasks. Moreover, a\npractical method to readjust each performance indicator value is proposed based\non global optimization algorithm in conjunction with active learning strategy,\naiming to provide rational value combination of performance indicators for the\ninverse design framework. This work is not only suitable for the airfoils\ndesign, but also has the capability to apply to optimization process of general\nproduct parts targeting selected performance indicators.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2503.07056v1",
    "published_date": "2025-03-10 08:42:26 UTC",
    "updated_date": "2025-03-10 08:42:26 UTC"
  },
  {
    "arxiv_id": "2503.08714v2",
    "title": "Versatile Multimodal Controls for Whole-Body Talking Human Animation",
    "authors": [
      "Zheng Qin",
      "Ruobing Zheng",
      "Yabing Wang",
      "Tianqi Li",
      "Zixin Zhu",
      "Minghui Yang",
      "Ming Yang",
      "Le Wang"
    ],
    "abstract": "Human animation from a single reference image shall be flexible to synthesize\nwhole-body motion for either a headshot or whole-body portrait, where the\nmotions are readily controlled by audio signal and text prompts. This is hard\nfor most existing methods as they only support producing pre-specified head or\nhalf-body motion aligned with audio inputs. In this paper, we propose a\nversatile human animation method, i.e., VersaAnimator, which generates\nwhole-body talking human from arbitrary portrait images, not only driven by\naudio signal but also flexibly controlled by text prompts. Specifically, we\ndesign a text-controlled, audio-driven motion generator that produces\nwhole-body motion representations in 3D synchronized with audio inputs while\nfollowing textual motion descriptions. To promote natural smooth motion, we\npropose a code-pose translation module to link VAE codebooks with 2D DWposes\nextracted from template videos. Moreover, we introduce a multi-modal video\ndiffusion that generates photorealistic human animation from a reference image\naccording to both audio inputs and whole-body motion representations. Extensive\nexperiments show that VersaAnimator outperforms existing methods in visual\nquality, identity preservation, and audio-lip synchronization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.08714v2",
    "published_date": "2025-03-10 08:38:25 UTC",
    "updated_date": "2025-03-16 10:09:52 UTC"
  },
  {
    "arxiv_id": "2503.07050v1",
    "title": "TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation",
    "authors": [
      "Victor Shea-Jay Huang",
      "Le Zhuo",
      "Yi Xin",
      "Zhaokai Wang",
      "Peng Gao",
      "Hongsheng Li"
    ],
    "abstract": "Diffusion Transformers (DiTs) are a powerful yet underexplored class of\ngenerative models compared to U-Net-based diffusion models. To bridge this gap,\nwe introduce TIDE (Temporal-aware Sparse Autoencoders for Interpretable\nDiffusion transformErs), a novel framework that enhances temporal\nreconstruction within DiT activation layers across denoising steps. TIDE\nemploys Sparse Autoencoders (SAEs) with a sparse bottleneck layer to extract\ninterpretable and hierarchical features, revealing that diffusion models\ninherently learn hierarchical features at multiple levels (e.g., 3D, semantic,\nclass) during generative pre-training. Our approach achieves state-of-the-art\nreconstruction performance, with a mean squared error (MSE) of 1e-3 and a\ncosine similarity of 0.97, demonstrating superior accuracy in capturing\nactivation dynamics along the denoising trajectory. Beyond interpretability, we\nshowcase TIDE's potential in downstream applications such as sparse\nactivation-guided image editing and style transfer, enabling improved\ncontrollability for generative systems. By providing a comprehensive training\nand evaluation protocol tailored for DiTs, TIDE contributes to developing more\ninterpretable, transparent, and trustworthy generative models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07050v1",
    "published_date": "2025-03-10 08:35:51 UTC",
    "updated_date": "2025-03-10 08:35:51 UTC"
  },
  {
    "arxiv_id": "2503.07044v1",
    "title": "DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data Science",
    "authors": [
      "Ziming You",
      "Yumiao Zhang",
      "Dexuan Xu",
      "Yiwei Lou",
      "Yandong Yan",
      "Wei Wang",
      "Huaming Zhang",
      "Yu Huang"
    ],
    "abstract": "Data Science tasks are multifaceted, dynamic, and often domain-specific.\nExisting LLM-based approaches largely concentrate on isolated phases,\nneglecting the interdependent nature of many data science tasks and limiting\ntheir capacity for comprehensive end-to-end support. We propose DatawiseAgent,\na notebook-centric LLM agent framework that unifies interactions among user,\nagent and the computational environment through markdown and executable code\ncells, supporting flexible and adaptive automated data science. Built on a\nFinite State Transducer(FST), DatawiseAgent orchestrates four stages, including\nDSF-like planning, incremental execution, self-debugging, and post-filtering.\nSpecifically, the DFS-like planning stage systematically explores the solution\nspace, while incremental execution harnesses real-time feedback and\naccommodates LLM's limited capabilities to progressively complete tasks. The\nself-debugging and post-filtering modules further enhance reliability by\ndiagnosing and correcting errors and pruning extraneous information. Extensive\nexperiments on diverse tasks, including data analysis, visualization, and data\nmodeling, show that DatawiseAgent consistently outperforms or matches\nstate-of-the-art methods across multiple model settings. These results\nhighlight its potential to generalize across data science scenarios and lay the\ngroundwork for more efficient, fully automated workflows.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07044v1",
    "published_date": "2025-03-10 08:32:33 UTC",
    "updated_date": "2025-03-10 08:32:33 UTC"
  },
  {
    "arxiv_id": "2503.07036v1",
    "title": "Bot Wars Evolved: Orchestrating Competing LLMs in a Counterstrike Against Phone Scams",
    "authors": [
      "Nardine Basta",
      "Conor Atkins",
      "Dali Kaafar"
    ],
    "abstract": "We present \"Bot Wars,\" a framework using Large Language Models (LLMs)\nscam-baiters to counter phone scams through simulated adversarial dialogues.\nOur key contribution is a formal foundation for strategy emergence through\nchain-of-thought reasoning without explicit optimization. Through a novel\ntwo-layer prompt architecture, our framework enables LLMs to craft\ndemographically authentic victim personas while maintaining strategic\ncoherence. We evaluate our approach using a dataset of 3,200 scam dialogues\nvalidated against 179 hours of human scam-baiting interactions, demonstrating\nits effectiveness in capturing complex adversarial dynamics. Our systematic\nevaluation through cognitive, quantitative, and content-specific metrics shows\nthat GPT-4 excels in dialogue naturalness and persona authenticity, while\nDeepseek demonstrates superior engagement sustainability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07036v1",
    "published_date": "2025-03-10 08:21:36 UTC",
    "updated_date": "2025-03-10 08:21:36 UTC"
  },
  {
    "arxiv_id": "2503.07029v1",
    "title": "Availability-aware Sensor Fusion via Unified Canonical Space for 4D Radar, LiDAR, and Camera",
    "authors": [
      "Dong-Hee Paek",
      "Seung-Hyun Kong"
    ],
    "abstract": "Sensor fusion of camera, LiDAR, and 4-dimensional (4D) Radar has brought a\nsignificant performance improvement in autonomous driving (AD). However, there\nstill exist fundamental challenges: deeply coupled fusion methods assume\ncontinuous sensor availability, making them vulnerable to sensor degradation\nand failure, whereas sensor-wise cross-attention fusion methods struggle with\ncomputational cost and unified feature representation. This paper presents\navailability-aware sensor fusion (ASF), a novel method that employs unified\ncanonical projection (UCP) to enable consistency in all sensor features for\nfusion and cross-attention across sensors along patches (CASAP) to enhance\nrobustness of sensor fusion against sensor degradation and failure. As a\nresult, the proposed ASF shows a superior object detection performance to the\nexisting state-of-the-art fusion methods under various weather and sensor\ndegradation (or failure) conditions; Extensive experiments on the K-Radar\ndataset demonstrate that ASF achieves improvements of 9.7% in AP BEV (87.2%)\nand 20.1% in AP 3D (73.6%) in object detection at IoU=0.5, while requiring a\nlow computational cost. The code will be available at\nhttps://github.com/kaist-avelab/K-Radar.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Arxiv preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.07029v1",
    "published_date": "2025-03-10 08:10:28 UTC",
    "updated_date": "2025-03-10 08:10:28 UTC"
  },
  {
    "arxiv_id": "2503.07026v1",
    "title": "Erase Diffusion: Empowering Object Removal Through Calibrating Diffusion Pathways",
    "authors": [
      "Yi Liu",
      "Hao Zhou",
      "Wenxiang Shang",
      "Ran Lin",
      "Benlei Cui"
    ],
    "abstract": "Erase inpainting, or object removal, aims to precisely remove target objects\nwithin masked regions while preserving the overall consistency of the\nsurrounding content. Despite diffusion-based methods have made significant\nstrides in the field of image inpainting, challenges remain regarding the\nemergence of unexpected objects or artifacts. We assert that the inexact\ndiffusion pathways established by existing standard optimization paradigms\nconstrain the efficacy of object removal. To tackle these challenges, we\npropose a novel Erase Diffusion, termed EraDiff, aimed at unleashing the\npotential power of standard diffusion in the context of object removal. In\ncontrast to standard diffusion, the EraDiff adapts both the optimization\nparadigm and the network to improve the coherence and elimination of the\nerasure results. We first introduce a Chain-Rectifying Optimization (CRO)\nparadigm, a sophisticated diffusion process specifically designed to align with\nthe objectives of erasure. This paradigm establishes innovative diffusion\ntransition pathways that simulate the gradual elimination of objects during\noptimization, allowing the model to accurately capture the intent of object\nremoval. Furthermore, to mitigate deviations caused by artifacts during the\nsampling pathways, we develop a simple yet effective Self-Rectifying Attention\n(SRA) mechanism. The SRA calibrates the sampling pathways by altering\nself-attention activation, allowing the model to effectively bypass artifacts\nwhile further enhancing the coherence of the generated content. With this\ndesign, our proposed EraDiff achieves state-of-the-art performance on the\nOpenImages V5 dataset and demonstrates significant superiority in real-world\nscenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07026v1",
    "published_date": "2025-03-10 08:06:51 UTC",
    "updated_date": "2025-03-10 08:06:51 UTC"
  },
  {
    "arxiv_id": "2503.07025v1",
    "title": "Weak Supervision for Improved Precision in Search Systems",
    "authors": [
      "Sriram Vasudevan"
    ],
    "abstract": "Labeled datasets are essential for modern search engines, which increasingly\nrely on supervised learning methods like Learning to Rank and massive amounts\nof data to power deep learning models. However, creating these datasets is both\ntime-consuming and costly, leading to the common use of user click and activity\nlogs as proxies for relevance. In this paper, we present a weak supervision\napproach to infer the quality of query-document pairs and apply it within a\nLearning to Rank framework to enhance the precision of a large-scale search\nsystem.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted to the AAAI 2025 Workshop on Computational Jobs Marketplace",
    "pdf_url": "http://arxiv.org/pdf/2503.07025v1",
    "published_date": "2025-03-10 08:06:30 UTC",
    "updated_date": "2025-03-10 08:06:30 UTC"
  },
  {
    "arxiv_id": "2503.07020v1",
    "title": "Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense",
    "authors": [
      "Yuting Hu",
      "Chenhui Xu",
      "Ruiyang Qin",
      "Dancheng Liu",
      "Amir Nassereldine",
      "Yiyu Shi",
      "Jinjun Xiong"
    ],
    "abstract": "Partial perception deficits can compromise autonomous vehicle safety by\ndisrupting environmental understanding. Current protocols typically respond\nwith immediate stops or minimal-risk maneuvers, worsening traffic flow and\nlacking flexibility for rare driving scenarios. In this paper, we propose\nLLM-RCO, a framework leveraging large language models to integrate human-like\ndriving commonsense into autonomous systems facing perception deficits. LLM-RCO\nfeatures four key modules: hazard inference, short-term motion planner, action\ncondition verifier, and safety constraint generator. These modules interact\nwith the dynamic driving environment, enabling proactive and context-aware\ncontrol actions to override the original control policy of autonomous agents.\nTo improve safety in such challenging conditions, we construct DriveLM-Deficit,\na dataset of 53,895 video clips featuring deficits of safety-critical objects,\ncomplete with annotations for LLM-based hazard inference and motion planning\nfine-tuning. Extensive experiments in adverse driving conditions with the CARLA\nsimulator demonstrate that systems equipped with LLM-RCO significantly improve\ndriving performance, highlighting its potential for enhancing autonomous\ndriving resilience against adverse perception deficits. Our results also show\nthat LLMs fine-tuned with DriveLM-Deficit can enable more proactive movements\ninstead of conservative stops in the context of perception deficits.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07020v1",
    "published_date": "2025-03-10 08:01:41 UTC",
    "updated_date": "2025-03-10 08:01:41 UTC"
  },
  {
    "arxiv_id": "2503.07678v1",
    "title": "Using a single actor to output personalized policy for different intersections",
    "authors": [
      "Kailing Zhou",
      "Chengwei Zhang",
      "Furui Zhan",
      "Wanting Liu",
      "Yihong Li"
    ],
    "abstract": "Recently, with the development of Multi-agent reinforcement learning (MARL),\nadaptive traffic signal control (ATSC) has achieved satisfactory results. In\ntraffic scenarios with multiple intersections, MARL treats each intersection as\nan agent and optimizes traffic signal control strategies through learning and\nreal-time decision-making. Considering that observation distributions of\nintersections might be different in real-world scenarios, shared parameter\nmethods might lack diversity and thus lead to high generalization requirements\nin the shared-policy network. A typical solution is to increase the size of\nnetwork parameters. However, simply increasing the scale of the network does\nnot necessarily improve policy generalization, which is validated in our\nexperiments. Accordingly, an approach that considers both the personalization\nof intersections and the efficiency of parameter sharing is required. To this\nend, we propose Hyper-Action Multi-Head Proximal Policy Optimization\n(HAMH-PPO), a Centralized Training with Decentralized Execution (CTDE) MARL\nmethod that utilizes a shared PPO policy network to deliver personalized\npolicies for intersections with non-iid observation distributions. The\ncentralized critic in HAMH-PPO uses graph attention units to calculate the\ngraph representations of all intersections and outputs a set of value estimates\nwith multiple output heads for each intersection. The decentralized execution\nactor takes the local observation history as input and output distributions of\naction as well as a so-called hyper-action to balance the multiple values\nestimated from the centralized critic to further guide the updating of TSC\npolicies. The combination of hyper-action and multi-head values enables\nmultiple agents to share a single actor-critic while achieving personalized\npolicies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07678v1",
    "published_date": "2025-03-10 07:55:33 UTC",
    "updated_date": "2025-03-10 07:55:33 UTC"
  },
  {
    "arxiv_id": "2503.07004v1",
    "title": "NukesFormers: Unpaired Hyperspectral Image Generation with Non-Uniform Domain Alignment",
    "authors": [
      "Jiaojiao Li",
      "Shiyao Duan",
      "Haitao XU",
      "Rui Song"
    ],
    "abstract": "The inherent difficulty in acquiring accurately co-registered\nRGB-hyperspectral image (HSI) pairs has significantly impeded the practical\ndeployment of current data-driven Hyperspectral Image Generation (HIG) networks\nin engineering applications. Gleichzeitig, the ill-posed nature of the aligning\nconstraints, compounded with the complexities of mining cross-domain features,\nalso hinders the advancement of unpaired HIG (UnHIG) tasks. In this paper, we\nconquer these challenges by modeling the UnHIG to range space interaction and\ncompensations of null space through Range-Null Space Decomposition (RND)\nmethodology. Specifically, the introduced contrastive learning effectively\naligns the geometric and spectral distributions of unpaired data by building\nthe interaction of range space, considering the consistent feature in\ndegradation process. Following this, we map the frequency representations of\ndual-domain input and thoroughly mining the null space, like degraded and\nhigh-frequency components, through the proposed Non-uniform Kolmogorov-Arnold\nNetworks. Extensive comparative experiments demonstrate that it establishes a\nnew benchmark in UnHIG.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07004v1",
    "published_date": "2025-03-10 07:38:46 UTC",
    "updated_date": "2025-03-10 07:38:46 UTC"
  },
  {
    "arxiv_id": "2503.07677v2",
    "title": "PLADIS: Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity",
    "authors": [
      "Kwanyoung Kim",
      "Byeongsu Sim"
    ],
    "abstract": "Diffusion models have shown impressive results in generating high-quality\nconditional samples using guidance techniques such as Classifier-Free Guidance\n(CFG). However, existing methods often require additional training or neural\nfunction evaluations (NFEs), making them incompatible with guidance-distilled\nmodels. Also, they rely on heuristic approaches that need identifying target\nlayers. In this work, we propose a novel and efficient method, termed PLADIS,\nwhich boosts pre-trained models (U-Net/Transformer) by leveraging sparse\nattention. Specifically, we extrapolate query-key correlations using softmax\nand its sparse counterpart in the cross-attention layer during inference,\nwithout requiring extra training or NFEs. By leveraging the noise robustness of\nsparse attention, our PLADIS unleashes the latent potential of text-to-image\ndiffusion models, enabling them to excel in areas where they once struggled\nwith newfound effectiveness. It integrates seamlessly with guidance techniques,\nincluding guidance-distilled models. Extensive experiments show notable\nimprovements in text alignment and human preference, offering a highly\nefficient and universally applicable solution. See Our project page :\nhttps://cubeyoung.github.io/pladis-proejct/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 19 figures, project page :\n  https://cubeyoung.github.io/pladis-proejct/",
    "pdf_url": "http://arxiv.org/pdf/2503.07677v2",
    "published_date": "2025-03-10 07:23:19 UTC",
    "updated_date": "2025-03-16 14:10:37 UTC"
  },
  {
    "arxiv_id": "2503.06987v1",
    "title": "Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations",
    "authors": [
      "Jiho Jin",
      "Woosung Kang",
      "Junho Myung",
      "Alice Oh"
    ],
    "abstract": "Measuring social bias in large language models (LLMs) is crucial, but\nexisting bias evaluation methods struggle to assess bias in long-form\ngeneration. We propose a Bias Benchmark for Generation (BBG), an adaptation of\nthe Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form\ngeneration by having LLMs generate continuations of story prompts. Building our\nbenchmark in English and Korean, we measure the probability of neutral and\nbiased generations across ten LLMs. We also compare our long-form story\ngeneration evaluation results with multiple-choice BBQ evaluation, showing that\nthe two approaches produce inconsistent results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06987v1",
    "published_date": "2025-03-10 07:06:47 UTC",
    "updated_date": "2025-03-10 07:06:47 UTC"
  },
  {
    "arxiv_id": "2503.06982v1",
    "title": "Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization",
    "authors": [
      "Ziqing Xu",
      "Hancheng Min",
      "Lachlan Ewen MacDonald",
      "Jinqi Luo",
      "Salma Tarmoun",
      "Enrique Mallada",
      "Rene Vidal"
    ],
    "abstract": "Despite the empirical success of Low-Rank Adaptation (LoRA) in fine-tuning\npre-trained models, there is little theoretical understanding of how\nfirst-order methods with carefully crafted initialization adapt models to new\ntasks. In this work, we take the first step towards bridging this gap by\ntheoretically analyzing the learning dynamics of LoRA for matrix factorization\n(MF) under gradient flow (GF), emphasizing the crucial role of initialization.\nFor small initialization, we theoretically show that GF converges to a\nneighborhood of the optimal solution, with smaller initialization leading to\nlower final error. Our analysis shows that the final error is affected by the\nmisalignment between the singular spaces of the pre-trained model and the\ntarget matrix, and reducing the initialization scale improves alignment. To\naddress this misalignment, we propose a spectral initialization for LoRA in MF\nand theoretically prove that GF with small spectral initialization converges to\nthe fine-tuning task with arbitrary precision. Numerical experiments from MF\nand image classification validate our findings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06982v1",
    "published_date": "2025-03-10 06:57:10 UTC",
    "updated_date": "2025-03-10 06:57:10 UTC"
  },
  {
    "arxiv_id": "2503.06978v1",
    "title": "Lightweight Multimodal Artificial Intelligence Framework for Maritime Multi-Scene Recognition",
    "authors": [
      "Xinyu Xi",
      "Hua Yang",
      "Shentai Zhang",
      "Yijie Liu",
      "Sijin Sun",
      "Xiuju Fu"
    ],
    "abstract": "Maritime Multi-Scene Recognition is crucial for enhancing the capabilities of\nintelligent marine robotics, particularly in applications such as marine\nconservation, environmental monitoring, and disaster response. However, this\ntask presents significant challenges due to environmental interference, where\nmarine conditions degrade image quality, and the complexity of maritime scenes,\nwhich requires deeper reasoning for accurate recognition. Pure vision models\nalone are insufficient to address these issues. To overcome these limitations,\nwe propose a novel multimodal Artificial Intelligence (AI) framework that\nintegrates image data, textual descriptions and classification vectors\ngenerated by a Multimodal Large Language Model (MLLM), to provide richer\nsemantic understanding and improve recognition accuracy. Our framework employs\nan efficient multimodal fusion mechanism to further enhance model robustness\nand adaptability in complex maritime environments. Experimental results show\nthat our model achieves 98$\\%$ accuracy, surpassing previous SOTA models by\n3.5$\\%$. To optimize deployment on resource-constrained platforms, we adopt\nactivation-aware weight quantization (AWQ) as a lightweight technique, reducing\nthe model size to 68.75MB with only a 0.5$\\%$ accuracy drop while significantly\nlowering computational overhead. This work provides a high-performance solution\nfor real-time maritime scene recognition, enabling Autonomous Surface Vehicles\n(ASVs) to support environmental monitoring and disaster response in\nresource-limited settings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 4 figures, submitted to Engineering Applications of\n  Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2503.06978v1",
    "published_date": "2025-03-10 06:47:38 UTC",
    "updated_date": "2025-03-10 06:47:38 UTC"
  },
  {
    "arxiv_id": "2503.06973v1",
    "title": "A Multimodal Benchmark Dataset and Model for Crop Disease Diagnosis",
    "authors": [
      "Xiang Liu",
      "Zhaoxiang Liu",
      "Huan Hu",
      "Zezhou Chen",
      "Kohou Wang",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "abstract": "While conversational generative AI has shown considerable potential in\nenhancing decision-making for agricultural professionals, its exploration has\npredominantly been anchored in text-based interactions. The evolution of\nmultimodal conversational AI, leveraging vast amounts of image-text data from\ndiverse sources, marks a significant stride forward. However, the application\nof such advanced vision-language models in the agricultural domain,\nparticularly for crop disease diagnosis, remains underexplored. In this work,\nwe present the crop disease domain multimodal (CDDM) dataset, a pioneering\nresource designed to advance the field of agricultural research through the\napplication of multimodal learning techniques. The dataset comprises 137,000\nimages of various crop diseases, accompanied by 1 million question-answer pairs\nthat span a broad spectrum of agricultural knowledge, from disease\nidentification to management practices. By integrating visual and textual data,\nCDDM facilitates the development of sophisticated question-answering systems\ncapable of providing precise, useful advice to farmers and agricultural\nprofessionals. We demonstrate the utility of the dataset by finetuning\nstate-of-the-art multimodal models, showcasing significant improvements in crop\ndisease diagnosis. Specifically, we employed a novel finetuning strategy that\nutilizes low-rank adaptation (LoRA) to finetune the visual encoder, adapter and\nlanguage model simultaneously. Our contributions include not only the dataset\nbut also a finetuning strategy and a benchmark to stimulate further research in\nagricultural technology, aiming to bridge the gap between advanced AI\ntechniques and practical agricultural applications. The dataset is available at\nhttps: //github.com/UnicomAI/UnicomBenchmark/tree/main/CDDMBench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV 2024 (14 pages, 8 figures)",
    "pdf_url": "http://arxiv.org/pdf/2503.06973v1",
    "published_date": "2025-03-10 06:37:42 UTC",
    "updated_date": "2025-03-10 06:37:42 UTC"
  },
  {
    "arxiv_id": "2503.07676v1",
    "title": "The Janus Face of Innovation: Global Disparities and Divergent Options",
    "authors": [
      "Nihat Mugurtay"
    ],
    "abstract": "This article examines how unequal access to AI innovation creates systemic\nchallenges for developing countries. Differential access to AI innovation\nresults from the acute competition between domestic and global actors. While\ndeveloping nations contribute significantly to AI development through data\nannotation labor, they face limited access to advanced AI technologies and are\nincreasingly caught between divergent regulatory approaches from democratic and\nauthoritarian tendencies. This brief paper analyzes how more affordable AI\nengagement and Western countries' development cooperation present developing\nnations with a complex choice between accessibility and governance standards. I\nargue this challenge entails new institutional mechanisms for technology\ntransfer and regulatory cooperation, while carefully balancing universal\nstandards with local needs. In turn, good practices could help developing\ncountries close the deepening gap of global technological divides, while\nensuring responsible AI development in developing countries.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.07676v1",
    "published_date": "2025-03-10 06:33:07 UTC",
    "updated_date": "2025-03-10 06:33:07 UTC"
  },
  {
    "arxiv_id": "2503.06963v1",
    "title": "Multi-Behavior Recommender Systems: A Survey",
    "authors": [
      "Kyungho Kim",
      "Sunwoo Kim",
      "Geon Lee",
      "Jinhong Jung",
      "Kijung Shin"
    ],
    "abstract": "Traditional recommender systems primarily rely on a single type of user-item\ninteraction, such as item purchases or ratings, to predict user preferences.\nHowever, in real-world scenarios, users engage in a variety of behaviors, such\nas clicking on items or adding them to carts, offering richer insights into\ntheir interests. Multi-behavior recommender systems leverage these diverse\ninteractions to enhance recommendation quality, and research on this topic has\ngrown rapidly in recent years. This survey provides a timely review of\nmulti-behavior recommender systems, focusing on three key steps: (1) Data\nModeling: representing multi-behaviors at the input level, (2) Encoding:\ntransforming these inputs into vector representations (i.e., embeddings), and\n(3) Training: optimizing machine-learning models. We systematically categorize\nexisting multi-behavior recommender systems based on the commonalities and\ndifferences in their approaches across the above steps. Additionally, we\ndiscuss promising future directions for advancing multi-behavior recommender\nsystems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted in the PAKDD 2025 Survey Track",
    "pdf_url": "http://arxiv.org/pdf/2503.06963v1",
    "published_date": "2025-03-10 06:22:37 UTC",
    "updated_date": "2025-03-10 06:22:37 UTC"
  },
  {
    "arxiv_id": "2503.06962v1",
    "title": "Capture Global Feature Statistics for One-Shot Federated Learning",
    "authors": [
      "Zenghao Guan",
      "Yucan Zhou",
      "Xiaoyan Gu"
    ],
    "abstract": "Traditional Federated Learning (FL) necessitates numerous rounds of\ncommunication between the server and clients, posing significant challenges\nincluding high communication costs, connection drop risks and susceptibility to\nprivacy attacks. One-shot FL has become a compelling learning paradigm to\novercome above drawbacks by enabling the training of a global server model via\na single communication round. However, existing one-shot FL methods suffer from\nexpensive computation cost on the server or clients and cannot deal with\nnon-IID (Independent and Identically Distributed) data stably and effectively.\nTo address these challenges, this paper proposes FedCGS, a novel Federated\nlearning algorithm that Capture Global feature Statistics leveraging\npre-trained models. With global feature statistics, we achieve training-free\nand heterogeneity-resistant one-shot FL. Furthermore, we extend its application\nto personalization scenario, where clients only need execute one extra\ncommunication round with server to download global statistics. Extensive\nexperimental results demonstrate the effectiveness of our methods across\ndiverse data heterogeneity settings. Code is available at\nhttps://github.com/Yuqin-G/FedCGS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.06962v1",
    "published_date": "2025-03-10 06:20:39 UTC",
    "updated_date": "2025-03-10 06:20:39 UTC"
  },
  {
    "arxiv_id": "2503.07675v1",
    "title": "DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems",
    "authors": [
      "Junwei Yu",
      "Yepeng Ding",
      "Hiroyuki Sato"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) in Multi-Agent Systems (MAS)\nhas opened new possibilities for artificial intelligence, yet current\nimplementations face significant challenges in resource management, task\ncoordination, and system efficiency. While existing frameworks demonstrate the\npotential of LLM-based agents in collaborative problem-solving, they often lack\nsophisticated mechanisms for parallel execution and dynamic task management.\nThis paper introduces DynTaskMAS, a novel framework that orchestrates\nasynchronous and parallel operations in LLM-based MAS through dynamic task\ngraphs. The framework features four key innovations: (1) a Dynamic Task Graph\nGenerator that intelligently decomposes complex tasks while maintaining logical\ndependencies, (2) an Asynchronous Parallel Execution Engine that optimizes\nresource utilization through efficient task scheduling, (3) a Semantic-Aware\nContext Management System that enables efficient information sharing among\nagents, and (4) an Adaptive Workflow Manager that dynamically optimizes system\nperformance. Experimental evaluations demonstrate that DynTaskMAS achieves\nsignificant improvements over traditional approaches: a 21-33% reduction in\nexecution time across task complexities (with higher gains for more complex\ntasks), a 35.4% improvement in resource utilization (from 65% to 88%), and\nnear-linear throughput scaling up to 16 concurrent agents (3.47X improvement\nfor 4X agents). Our framework establishes a foundation for building scalable,\nhigh-performance LLM-based multi-agent systems capable of handling complex,\ndynamic tasks efficiently.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07675v1",
    "published_date": "2025-03-10 06:16:10 UTC",
    "updated_date": "2025-03-10 06:16:10 UTC"
  },
  {
    "arxiv_id": "2503.06951v1",
    "title": "ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA",
    "authors": [
      "Zhao Xinjie",
      "Fan Gao",
      "Rui Yang",
      "Yingjian Chen",
      "Yuyang Wang",
      "Ying Zhu",
      "Jiacheng Tang",
      "Irene Li"
    ],
    "abstract": "Recent advances in large language models (LLMs) have significantly improved\nmulti-hop question answering (QA) through direct Chain-of-Thought (CoT)\nreasoning. However, the irreversible nature of CoT leads to error accumulation,\nmaking it challenging to correct mistakes in multi-hop reasoning. This paper\nintroduces ReAgent: a Reversible multi-Agent collaborative framework augmented\nwith explicit backtracking mechanisms, enabling reversible multi-hop reasoning.\nBy incorporating text-based retrieval, information aggregation and validation,\nour system can detect and correct errors mid-reasoning, leading to more robust\nand interpretable QA outcomes. The framework and experiments serve as a\nfoundation for future work on error-tolerant QA systems. Empirical evaluations\nacross three benchmarks indicate ReAgent's efficacy, yielding average about 6\\%\nimprovements against baseline models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "25pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06951v1",
    "published_date": "2025-03-10 05:56:46 UTC",
    "updated_date": "2025-03-10 05:56:46 UTC"
  },
  {
    "arxiv_id": "2503.06948v1",
    "title": "Large Language Model Guided Progressive Feature Alignment for Multimodal UAV Object Detection",
    "authors": [
      "Wentao Wu",
      "Chenglong Li",
      "Xiao Wang",
      "Bin Luo",
      "Qi Liu"
    ],
    "abstract": "Existing multimodal UAV object detection methods often overlook the impact of\nsemantic gaps between modalities, which makes it difficult to achieve accurate\nsemantic and spatial alignments, limiting detection performance. To address\nthis problem, we propose a Large Language Model (LLM) guided Progressive\nfeature Alignment Network called LPANet, which leverages the semantic features\nextracted from a large language model to guide the progressive semantic and\nspatial alignment between modalities for multimodal UAV object detection. To\nemploy the powerful semantic representation of LLM, we generate the\nfine-grained text descriptions of each object category by ChatGPT and then\nextract the semantic features using the large language model MPNet. Based on\nthe semantic features, we guide the semantic and spatial alignments in a\nprogressive manner as follows. First, we design the Semantic Alignment Module\n(SAM) to pull the semantic features and multimodal visual features of each\nobject closer, alleviating the semantic differences of objects between\nmodalities. Second, we design the Explicit Spatial alignment Module (ESM) by\nintegrating the semantic relations into the estimation of feature-level\noffsets, alleviating the coarse spatial misalignment between modalities.\nFinally, we design the Implicit Spatial alignment Module (ISM), which leverages\nthe cross-modal correlations to aggregate key features from neighboring regions\nto achieve implicit spatial alignment. Comprehensive experiments on two public\nmultimodal UAV object detection datasets demonstrate that our approach\noutperforms state-of-the-art multimodal UAV object detectors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06948v1",
    "published_date": "2025-03-10 05:53:30 UTC",
    "updated_date": "2025-03-10 05:53:30 UTC"
  },
  {
    "arxiv_id": "2503.08712v1",
    "title": "SHAP-Integrated Convolutional Diagnostic Networks for Feature-Selective Medical Analysis",
    "authors": [
      "Yan Hu",
      "Ahmad Chaddad"
    ],
    "abstract": "This study introduces the SHAP-integrated convolutional diagnostic network\n(SICDN), an interpretable feature selection method designed for limited\ndatasets, to address the challenge posed by data privacy regulations that\nrestrict access to medical datasets. The SICDN model was tested on\nclassification tasks using pneumonia and breast cancer datasets, demonstrating\nover 97% accuracy and surpassing four popular CNN models. We also integrated a\nhistorical weighted moving average technique to enhance feature selection. The\nSICDN shows potential in medical image prediction, with the code available on\nhttps://github.com/AIPMLab/SICDN.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.08712v1",
    "published_date": "2025-03-10 05:48:35 UTC",
    "updated_date": "2025-03-10 05:48:35 UTC"
  },
  {
    "arxiv_id": "2503.06926v1",
    "title": "Effect of Selection Format on LLM Performance",
    "authors": [
      "Yuchen Han",
      "Yucheng Wu",
      "Jeffrey Willard"
    ],
    "abstract": "This paper investigates a critical aspect of large language model (LLM)\nperformance: the optimal formatting of classification task options in prompts.\nThrough an extensive experimental study, we compared two selection formats --\nbullet points and plain English -- to determine their impact on model\nperformance. Our findings suggest that presenting options via bullet points\ngenerally yields better results, although there are some exceptions.\nFurthermore, our research highlights the need for continued exploration of\noption formatting to drive further improvements in model performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06926v1",
    "published_date": "2025-03-10 05:11:58 UTC",
    "updated_date": "2025-03-10 05:11:58 UTC"
  },
  {
    "arxiv_id": "2503.06923v1",
    "title": "From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers",
    "authors": [
      "Jiacheng Liu",
      "Chang Zou",
      "Yuanhuiyi Lyu",
      "Junjie Chen",
      "Linfeng Zhang"
    ],
    "abstract": "Diffusion Transformers (DiT) have revolutionized high-fidelity image and\nvideo synthesis, yet their computational demands remain prohibitive for\nreal-time applications. To solve this problem, feature caching has been\nproposed to accelerate diffusion models by caching the features in the previous\ntimesteps and then reusing them in the following timesteps. However, at\ntimesteps with significant intervals, the feature similarity in diffusion\nmodels decreases substantially, leading to a pronounced increase in errors\nintroduced by feature caching, significantly harming the generation quality. To\nsolve this problem, we propose TaylorSeer, which firstly shows that features of\ndiffusion models at future timesteps can be predicted based on their values at\nprevious timesteps. Based on the fact that features change slowly and\ncontinuously across timesteps, TaylorSeer employs a differential method to\napproximate the higher-order derivatives of features and predict features in\nfuture timesteps with Taylor series expansion. Extensive experiments\ndemonstrate its significant effectiveness in both image and video synthesis,\nespecially in high acceleration ratios. For instance, it achieves an almost\nlossless acceleration of 4.99$\\times$ on FLUX and 5.00$\\times$ on HunyuanVideo\nwithout additional training. On DiT, it achieves $3.41$ lower FID compared with\nprevious SOTA at $4.53$$\\times$ acceleration. %Our code is provided in the\nsupplementary materials and will be made publicly available on GitHub. Our\ncodes have been released in Github:https://github.com/Shenyi-Z/TaylorSeer",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06923v1",
    "published_date": "2025-03-10 05:09:42 UTC",
    "updated_date": "2025-03-10 05:09:42 UTC"
  },
  {
    "arxiv_id": "2503.08711v1",
    "title": "A Beam Search Based Parallel Algorithm for the Two-Dimensional Strip Packing Problem",
    "authors": [
      "Yajie Wen",
      "Defu Zhang"
    ],
    "abstract": "This paper introduces BSPA, a parallel algorithm that leverages beam search\nto address the two-dimensional strip packing problem. The study begins with a\ncomprehensive review of existing approaches and methodologies, followed by a\ndetailed presentation of the BSPA algorithm. Experimental results demonstrate\nthe effectiveness of the proposed method. To facilitate further research, both\nthe code and datasets are publicly available.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "9 pages,4figures",
    "pdf_url": "http://arxiv.org/pdf/2503.08711v1",
    "published_date": "2025-03-10 04:20:45 UTC",
    "updated_date": "2025-03-10 04:20:45 UTC"
  },
  {
    "arxiv_id": "2503.06894v2",
    "title": "A Deep Learning Approach for Augmenting Perceptional Understanding of Histopathology Images",
    "authors": [
      "Xiaoqian Hu"
    ],
    "abstract": "In Recent Years, Digital Technologies Have Made Significant Strides In\nAugmenting-Human-Health, Cognition, And Perception, Particularly Within The\nField Of Computational-Pathology. This Paper Presents A Novel Approach To\nEnhancing The Analysis Of Histopathology Images By Leveraging A\nMult-modal-Model That Combines Vision Transformers (Vit) With Gpt-2 For Image\nCaptioning. The Model Is Fine-Tuned On The Specialized Arch-Dataset, Which\nIncludes Dense Image Captions Derived From Clinical And Academic Resources, To\nCapture The Complexities Of Pathology Images Such As Tissue Morphologies,\nStaining Variations, And Pathological Conditions. By Generating Accurate,\nContextually Captions, The Model Augments The Cognitive Capabilities Of\nHealthcare Professionals, Enabling More Efficient Disease Classification,\nSegmentation, And Detection. The Model Enhances The Perception Of Subtle\nPathological Features In Images That Might Otherwise Go Unnoticed, Thereby\nImproving Diagnostic Accuracy. Our Approach Demonstrates The Potential For\nDigital Technologies To Augment Human Cognitive Abilities In Medical Image\nAnalysis, Providing Steps Toward More Personalized And Accurate Healthcare\nOutcomes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by International Conference on Semantic & Natural Language\n  Processing (SNLP 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.06894v2",
    "published_date": "2025-03-10 03:50:25 UTC",
    "updated_date": "2025-03-19 08:18:22 UTC"
  },
  {
    "arxiv_id": "2503.06893v1",
    "title": "Policy Regularization on Globally Accessible States in Cross-Dynamics Reinforcement Learning",
    "authors": [
      "Zhenghai Xue",
      "Lang Feng",
      "Jiacheng Xu",
      "Kang Kang",
      "Xiang Wen",
      "Bo An",
      "Shuicheng Yan"
    ],
    "abstract": "To learn from data collected in diverse dynamics, Imitation from Observation\n(IfO) methods leverage expert state trajectories based on the premise that\nrecovering expert state distributions in other dynamics facilitates policy\nlearning in the current one. However, Imitation Learning inherently imposes a\nperformance upper bound of learned policies. Additionally, as the environment\ndynamics change, certain expert states may become inaccessible, rendering their\ndistributions less valuable for imitation. To address this, we propose a novel\nframework that integrates reward maximization with IfO, employing F-distance\nregularized policy optimization. This framework enforces constraints on\nglobally accessible states--those with nonzero visitation frequency across all\nconsidered dynamics--mitigating the challenge posed by inaccessible states. By\ninstantiating F-distance in different ways, we derive two theoretical analysis\nand develop a practical algorithm called Accessible State Oriented Policy\nRegularization (ASOR). ASOR serves as a general add-on module that can be\nincorporated into various RL approaches, including offline RL and off-policy\nRL. Extensive experiments across multiple benchmarks demonstrate ASOR's\neffectiveness in enhancing state-of-the-art cross-domain policy transfer\nalgorithms, significantly improving their performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2503.06893v1",
    "published_date": "2025-03-10 03:50:20 UTC",
    "updated_date": "2025-03-10 03:50:20 UTC"
  },
  {
    "arxiv_id": "2503.07674v1",
    "title": "TVNet: A Novel Time Series Analysis Method Based on Dynamic Convolution and 3D-Variation",
    "authors": [
      "Chenghan Li",
      "Mingchen Li",
      "Ruisheng Diao"
    ],
    "abstract": "With the recent development and advancement of Transformer and MLP\narchitectures, significant strides have been made in time series analysis.\nConversely, the performance of Convolutional Neural Networks (CNNs) in time\nseries analysis has fallen short of expectations, diminishing their potential\nfor future applications. Our research aims to enhance the representational\ncapacity of Convolutional Neural Networks (CNNs) in time series analysis by\nintroducing novel perspectives and design innovations. To be specific, We\nintroduce a novel time series reshaping technique that considers the\ninter-patch, intra-patch, and cross-variable dimensions. Consequently, we\npropose TVNet, a dynamic convolutional network leveraging a 3D perspective to\nemploy time series analysis. TVNet retains the computational efficiency of CNNs\nand achieves state-of-the-art results in five key time series analysis tasks,\noffering a superior balance of efficiency and performance over the\nstate-of-the-art Transformer-based and MLP-based models. Additionally, our\nfindings suggest that TVNet exhibits enhanced transferability and robustness.\nTherefore, it provides a new perspective for applying CNN in advanced time\nseries analysis tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.07674v1",
    "published_date": "2025-03-10 03:30:55 UTC",
    "updated_date": "2025-03-10 03:30:55 UTC"
  },
  {
    "arxiv_id": "2503.06884v1",
    "title": "Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement Cannot Help",
    "authors": [
      "Yuefan Cao",
      "Xuyang Guo",
      "Jiayan Huo",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Jiahao Zhang",
      "Zhen Zhuang"
    ],
    "abstract": "Generative modeling is widely regarded as one of the most essential problems\nin today's AI community, with text-to-image generation having gained\nunprecedented real-world impacts. Among various approaches, diffusion models\nhave achieved remarkable success and have become the de facto solution for\ntext-to-image generation. However, despite their impressive performance, these\nmodels exhibit fundamental limitations in adhering to numerical constraints in\nuser instructions, frequently generating images with an incorrect number of\nobjects. While several prior works have mentioned this issue, a comprehensive\nand rigorous evaluation of this limitation remains lacking. To address this\ngap, we introduce T2ICountBench, a novel benchmark designed to rigorously\nevaluate the counting ability of state-of-the-art text-to-image diffusion\nmodels. Our benchmark encompasses a diverse set of generative models, including\nboth open-source and private systems. It explicitly isolates counting\nperformance from other capabilities, provides structured difficulty levels, and\nincorporates human evaluations to ensure high reliability.\n  Extensive evaluations with T2ICountBench reveal that all state-of-the-art\ndiffusion models fail to generate the correct number of objects, with accuracy\ndropping significantly as the number of objects increases. Additionally, an\nexploratory study on prompt refinement demonstrates that such simple\ninterventions generally do not improve counting accuracy. Our findings\nhighlight the inherent challenges in numerical understanding within diffusion\nmodels and point to promising directions for future improvements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06884v1",
    "published_date": "2025-03-10 03:28:18 UTC",
    "updated_date": "2025-03-10 03:28:18 UTC"
  },
  {
    "arxiv_id": "2503.08709v1",
    "title": "Simulating Influence Dynamics with LLM Agents",
    "authors": [
      "Mehwish Nasim",
      "Syed Muslim Gilani",
      "Amin Qasmi",
      "Usman Naseem"
    ],
    "abstract": "This paper introduces a simulator designed for opinion dynamics researchers\nto model competing influences within social networks in the presence of\nLLM-based agents. By integrating established opinion dynamics principles with\nstate-of-the-art LLMs, this tool enables the study of influence propagation and\ncounter-misinformation strategies. The simulator is particularly valuable for\nresearchers in social science, psychology, and operations research, allowing\nthem to analyse societal phenomena without requiring extensive coding\nexpertise. Additionally, the simulator will be openly available on GitHub,\nensuring accessibility and adaptability for those who wish to extend its\ncapabilities for their own research.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "I.2.7; I.6.0"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.08709v1",
    "published_date": "2025-03-10 03:05:21 UTC",
    "updated_date": "2025-03-10 03:05:21 UTC"
  },
  {
    "arxiv_id": "2503.08708v2",
    "title": "TH-Bench: Evaluating Evading Attacks via Humanizing AI Text on Machine-Generated Text Detectors",
    "authors": [
      "Jingyi Zheng",
      "Junfeng Wang",
      "Zhen Sun",
      "Wenhan Dong",
      "Yule Liu",
      "Xinlei He"
    ],
    "abstract": "As Large Language Models (LLMs) advance, Machine-Generated Texts (MGTs) have\nbecome increasingly fluent, high-quality, and informative. Existing wide-range\nMGT detectors are designed to identify MGTs to prevent the spread of plagiarism\nand misinformation. However, adversaries attempt to humanize MGTs to evade\ndetection (named evading attacks), which requires only minor modifications to\nbypass MGT detectors. Unfortunately, existing attacks generally lack a unified\nand comprehensive evaluation framework, as they are assessed using different\nexperimental settings, model architectures, and datasets. To fill this gap, we\nintroduce the Text-Humanization Benchmark (TH-Bench), the first comprehensive\nbenchmark to evaluate evading attacks against MGT detectors. TH-Bench evaluates\nattacks across three key dimensions: evading effectiveness, text quality, and\ncomputational overhead. Our extensive experiments evaluate 6 state-of-the-art\nattacks against 13 MGT detectors across 6 datasets, spanning 19 domains and\ngenerated by 11 widely used LLMs. Our findings reveal that no single evading\nattack excels across all three dimensions. Through in-depth analysis, we\nhighlight the strengths and limitations of different attacks. More importantly,\nwe identify a trade-off among three dimensions and propose two optimization\ninsights. Through preliminary experiments, we validate their correctness and\neffectiveness, offering potential directions for future research.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.08708v2",
    "published_date": "2025-03-10 02:55:05 UTC",
    "updated_date": "2025-03-13 10:37:18 UTC"
  },
  {
    "arxiv_id": "2503.06873v2",
    "title": "Interactive Medical Image Analysis with Concept-based Similarity Reasoning",
    "authors": [
      "Ta Duc Huy",
      "Sen Kim Tran",
      "Phan Nguyen",
      "Nguyen Hoang Tran",
      "Tran Bao Sam",
      "Anton van den Hengel",
      "Zhibin Liao",
      "Johan W. Verjans",
      "Minh-Son To",
      "Vu Minh Hieu Phan"
    ],
    "abstract": "The ability to interpret and intervene model decisions is important for the\nadoption of computer-aided diagnosis methods in clinical workflows. Recent\nconcept-based methods link the model predictions with interpretable concepts\nand modify their activation scores to interact with the model. However, these\nconcepts are at the image level, which hinders the model from pinpointing the\nexact patches the concepts are activated. Alternatively, prototype-based\nmethods learn representations from training image patches and compare these\nwith test image patches, using the similarity scores for final class\nprediction. However, interpreting the underlying concepts of these patches can\nbe challenging and often necessitates post-hoc guesswork. To address this\nissue, this paper introduces the novel Concept-based Similarity Reasoning\nnetwork (CSR), which offers (i) patch-level prototype with intrinsic concept\ninterpretation, and (ii) spatial interactivity. First, the proposed CSR\nprovides localized explanation by grounding prototypes of each concept on image\nregions. Second, our model introduces novel spatial-level interaction, allowing\ndoctors to engage directly with specific image areas, making it an intuitive\nand transparent tool for medical imaging. CSR improves upon prior\nstate-of-the-art interpretable methods by up to 4.5\\% across three biomedical\ndatasets. Our code is released at https://github.com/tadeephuy/InteractCSR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2503.06873v2",
    "published_date": "2025-03-10 02:52:47 UTC",
    "updated_date": "2025-03-11 09:06:03 UTC"
  },
  {
    "arxiv_id": "2503.06868v1",
    "title": "Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset, Evaluation Framework, and Mitigation",
    "authors": [
      "Junhao Zhang",
      "Richong Zhang",
      "Fanshuang Kong",
      "Ziyang Miao",
      "Yanhan Ye",
      "Yaowei Zheng"
    ],
    "abstract": "Existing long-text generation methods primarily concentrate on producing\nlengthy texts from short inputs, neglecting the long-input and long-output\ntasks. Such tasks have numerous practical applications while lacking available\nbenchmarks. Moreover, as the input grows in length, existing methods inevitably\nencounter the \"lost-in-the-middle\" phenomenon. In this paper, we first\nintroduce a Long Input and Output Benchmark (LongInOutBench), including a\nsynthetic dataset and a comprehensive evaluation framework, addressing the\nchallenge of the missing benchmark. We then develop the Retrieval-Augmented\nLong-Text Writer (RAL-Writer), which retrieves and restates important yet\noverlooked content, mitigating the \"lost-in-the-middle\" issue by constructing\nexplicit prompts. We finally employ the proposed LongInOutBench to evaluate our\nRAL-Writer against comparable baselines, and the results demonstrate the\neffectiveness of our approach. Our code has been released at\nhttps://github.com/OnlyAR/RAL-Writer.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06868v1",
    "published_date": "2025-03-10 02:44:36 UTC",
    "updated_date": "2025-03-10 02:44:36 UTC"
  },
  {
    "arxiv_id": "2503.06867v1",
    "title": "Enhancing Time Series Forecasting via Logic-Inspired Regularization",
    "authors": [
      "Jianqi Zhang",
      "Jingyao Wang",
      "Xingchen Shen",
      "Wenwen Qiang"
    ],
    "abstract": "Time series forecasting (TSF) plays a crucial role in many applications.\nTransformer-based methods are one of the mainstream techniques for TSF.\nExisting methods treat all token dependencies equally. However, we find that\nthe effectiveness of token dependencies varies across different forecasting\nscenarios, and existing methods ignore these differences, which affects their\nperformance. This raises two issues: (1) What are effective token dependencies?\n(2) How can we learn effective dependencies? From a logical perspective, we\nalign Transformer-based TSF methods with the logical framework and define\neffective token dependencies as those that ensure the tokens as atomic formulas\n(Issue 1). We then align the learning process of Transformer methods with the\nprocess of obtaining atomic formulas in logic, which inspires us to design a\nmethod for learning these effective dependencies (Issue 2). Specifically, we\npropose Attention Logic Regularization (Attn-L-Reg), a plug-and-play method\nthat guides the model to use fewer but more effective dependencies by making\nthe attention map sparse, thereby ensuring the tokens as atomic formulas and\nimproving prediction performance. Extensive experiments and theoretical\nanalysis confirm the effectiveness of Attn-L-Reg.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06867v1",
    "published_date": "2025-03-10 02:44:11 UTC",
    "updated_date": "2025-03-10 02:44:11 UTC"
  },
  {
    "arxiv_id": "2503.06866v1",
    "title": "Graphormer-Guided Task Planning: Beyond Static Rules with LLM Safety Perception",
    "authors": [
      "Wanjing Huang",
      "Tongjie Pan",
      "Yalan Ye"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have expanded their role\nin robotic task planning. However, while LLMs have been explored for generating\nfeasible task sequences, their ability to ensure safe task execution remains\nunderdeveloped. Existing methods struggle with structured risk perception,\nmaking them inadequate for safety-critical applications where low-latency\nhazard adaptation is required. To address this limitation, we propose a\nGraphormer-enhanced risk-aware task planning framework that combines LLM-based\ndecision-making with structured safety modeling. Our approach constructs a\ndynamic spatio-semantic safety graph, capturing spatial and contextual risk\nfactors to enable online hazard detection and adaptive task refinement. Unlike\nexisting methods that rely on predefined safety constraints, our framework\nintroduces a context-aware risk perception module that continuously refines\nsafety predictions based on real-time task execution. This enables a more\nflexible and scalable approach to robotic planning, allowing for adaptive\nsafety compliance beyond static rules. To validate our framework, we conduct\nexperiments in the AI2-THOR environment. The experiments results validates\nimprovements in risk detection accuracy, rising safety notice, and task\nadaptability of our framework in continuous environments compared to static\nrule-based and LLM-only baselines. Our project is available at\nhttps://github.com/hwj20/GGTP",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06866v1",
    "published_date": "2025-03-10 02:43:54 UTC",
    "updated_date": "2025-03-10 02:43:54 UTC"
  },
  {
    "arxiv_id": "2503.06861v1",
    "title": "Enhanced Multi-Tuple Extraction for Alloys: Integrating Pointer Networks and Augmented Attention",
    "authors": [
      "Mengzhe Hei",
      "Zhouran Zhang",
      "Qingbao Liu",
      "Yan Pan",
      "Xiang Zhao",
      "Yongqian Peng",
      "Yicong Ye",
      "Xin Zhang",
      "Shuxin Bai"
    ],
    "abstract": "Extracting high-quality structured information from scientific literature is\ncrucial for advancing material design through data-driven methods. Despite the\nconsiderable research in natural language processing for dataset extraction,\neffective approaches for multi-tuple extraction in scientific literature remain\nscarce due to the complex interrelations of tuples and contextual ambiguities.\nIn the study, we illustrate the multi-tuple extraction of mechanical properties\nfrom multi-principal-element alloys and presents a novel framework that\ncombines an entity extraction model based on MatSciBERT with pointer networks\nand an allocation model utilizing inter- and intra-entity attention. Our\nrigorous experiments on tuple extraction demonstrate impressive F1 scores of\n0.963, 0.947, 0.848, and 0.753 across datasets with 1, 2, 3, and 4 tuples,\nconfirming the effectiveness of the model. Furthermore, an F1 score of 0.854\nwas achieved on a randomly curated dataset. These results highlight the model's\ncapacity to deliver precise and structured information, offering a robust\nalternative to large language models and equipping researchers with essential\ndata for fostering data-driven innovations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06861v1",
    "published_date": "2025-03-10 02:39:06 UTC",
    "updated_date": "2025-03-10 02:39:06 UTC"
  },
  {
    "arxiv_id": "2503.06839v1",
    "title": "AttFC: Attention Fully-Connected Layer for Large-Scale Face Recognition with One GPU",
    "authors": [
      "Zhuowen Zheng",
      "Yain-Whar Si",
      "Xiaochen Yuan",
      "Junwei Duan",
      "Ke Wang",
      "Xiaofan Li",
      "Xinyuan Zhang",
      "Xueyuan Gong"
    ],
    "abstract": "Nowadays, with the advancement of deep neural networks (DNNs) and the\navailability of large-scale datasets, the face recognition (FR) model has\nachieved exceptional performance. However, since the parameter magnitude of the\nfully connected (FC) layer directly depends on the number of identities in the\ndataset. If training the FR model on large-scale datasets, the size of the\nmodel parameter will be excessively huge, leading to substantial demand for\ncomputational resources, such as time and memory. This paper proposes the\nattention fully connected (AttFC) layer, which could significantly reduce\ncomputational resources. AttFC employs an attention loader to generate the\ngenerative class center (GCC), and dynamically store the class center with\nDynamic Class Container (DCC). DCC only stores a small subset of all class\ncenters in FC, thus its parameter count is substantially less than the FC\nlayer. Also, training face recognition models on large-scale datasets with one\nGPU often encounter out-of-memory (OOM) issues. AttFC overcomes this and\nachieves comparable performance to state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06839v1",
    "published_date": "2025-03-10 01:59:11 UTC",
    "updated_date": "2025-03-10 01:59:11 UTC"
  },
  {
    "arxiv_id": "2503.07673v1",
    "title": "The potential role of AI agents in transforming nuclear medicine research and cancer management in India",
    "authors": [
      "Rajat Vashistha",
      "Arif Gulzar",
      "Parveen Kundu",
      "Punit Sharma",
      "Mark Brunstein",
      "Viktor Vegh"
    ],
    "abstract": "India faces a significant cancer burden, with an incidence-to-mortality ratio\nindicating that nearly three out of five individuals diagnosed with cancer\nsuccumb to the disease. While the limitations of physical healthcare\ninfrastructure are widely acknowledged as a primary challenge, concerted\nefforts by government and healthcare agencies are underway to mitigate these\nconstraints. However, given the country's vast geography and high population\ndensity, it is imperative to explore alternative soft infrastructure solutions\nto complement existing frameworks. Artificial Intelligence agents are\nincreasingly transforming problem-solving approaches across various domains,\nwith their application in medicine proving particularly transformative. In this\nperspective, we examine the potential role of AI agents in advancing nuclear\nmedicine for cancer research, diagnosis, and management in India. We begin with\na brief overview of AI agents and their capabilities, followed by a proposed\nagent-based ecosystem that can address prevailing sustainability challenges in\nIndia nuclear medicine.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07673v1",
    "published_date": "2025-03-10 01:30:07 UTC",
    "updated_date": "2025-03-10 01:30:07 UTC"
  },
  {
    "arxiv_id": "2503.06828v1",
    "title": "Towards a Multimodal MRI-Based Foundation Model for Multi-Level Feature Exploration in Segmentation, Molecular Subtyping, and Grading of Glioma",
    "authors": [
      "Somayeh Farahani",
      "Marjaneh Hejazi",
      "Antonio Di Ieva",
      "Emad Fatemizadeh",
      "Sidong Liu"
    ],
    "abstract": "Accurate, noninvasive glioma characterization is crucial for effective\nclinical management. Traditional methods, dependent on invasive tissue\nsampling, often fail to capture the spatial heterogeneity of the tumor. While\ndeep learning has improved segmentation and molecular profiling, few approaches\nsimultaneously integrate tumor morphology and molecular features. Foundation\ndeep learning models, which learn robust, task-agnostic representations from\nlarge-scale datasets, hold great promise but remain underutilized in glioma\nimaging biomarkers. We propose the Multi-Task SWIN-UNETR (MTS-UNET) model, a\nnovel foundation-based framework built on the BrainSegFounder model, pretrained\non large-scale neuroimaging data. MTS-UNET simultaneously performs glioma\nsegmentation, histological grading, and molecular subtyping (IDH mutation and\n1p/19q co-deletion). It incorporates two key modules: Tumor-Aware Feature\nEncoding (TAFE) for multi-scale, tumor-focused feature extraction and\nCross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch\nsignals associated with IDH mutation. The model was trained and validated on a\ndiverse, multi-center cohort of 2,249 glioma patients from seven public\ndatasets. MTS-UNET achieved a mean Dice score of 84% for segmentation, along\nwith AUCs of 90.58% for IDH mutation, 69.22% for 1p/19q co-deletion prediction,\nand 87.54% for grading, significantly outperforming baseline models (p<=0.05).\nAblation studies validated the essential contributions of the TAFE and CMD\nmodules and demonstrated the robustness of the framework. The foundation-based\nMTS-UNET model effectively integrates tumor segmentation with multi-level\nclassification, exhibiting strong generalizability across diverse MRI datasets.\nThis framework shows significant potential for advancing noninvasive,\npersonalized glioma management by improving predictive accuracy and\ninterpretability.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06828v1",
    "published_date": "2025-03-10 01:27:09 UTC",
    "updated_date": "2025-03-10 01:27:09 UTC"
  },
  {
    "arxiv_id": "2503.06820v1",
    "title": "Towards Fine-Grained Video Question Answering",
    "authors": [
      "Wei Dai",
      "Alan Luo",
      "Zane Durante",
      "Debadutta Dash",
      "Arnold Milstein",
      "Kevin Schulman",
      "Ehsan Adeli",
      "Li Fei-Fei"
    ],
    "abstract": "In the rapidly evolving domain of video understanding, Video Question\nAnswering (VideoQA) remains a focal point. However, existing datasets exhibit\ngaps in temporal and spatial granularity, which consequently limits the\ncapabilities of existing VideoQA methods. This paper introduces the\nMulti-Object Multi-Actor Question Answering (MOMA-QA) dataset, which is\ndesigned to address these shortcomings by emphasizing temporal localization,\nspatial relationship reasoning, and entity-centric queries. With ground truth\nscene graphs and temporal interval annotations, MOMA-QA is ideal for developing\nmodels for fine-grained video understanding. Furthermore, we present a novel\nvideo-language model, SGVLM, which incorporates a scene graph predictor, an\nefficient frame retriever, and a pre-trained large language model for temporal\nlocalization and fine-grained relationship understanding. Evaluations on\nMOMA-QA and other public datasets demonstrate the superior performance of our\nmodel, setting new benchmarks for VideoQA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06820v1",
    "published_date": "2025-03-10 01:02:01 UTC",
    "updated_date": "2025-03-10 01:02:01 UTC"
  },
  {
    "arxiv_id": "2503.06816v1",
    "title": "Semi-Supervised Medical Image Segmentation via Knowledge Mining from Large Models",
    "authors": [
      "Yuchen Mao",
      "Hongwei Li",
      "Yinyi Lai",
      "Giorgos Papanastasiou",
      "Peng Qi",
      "Yunjie Yang",
      "Chengjia Wang"
    ],
    "abstract": "Large-scale vision models like SAM have extensive visual knowledge, yet their\ngeneral nature and computational demands limit their use in specialized tasks\nlike medical image segmentation. In contrast, task-specific models such as\nU-Net++ often underperform due to sparse labeled data. This study introduces a\nstrategic knowledge mining method that leverages SAM's broad understanding to\nboost the performance of small, locally hosted deep learning models.\n  In our approach, we trained a U-Net++ model on a limited labeled dataset and\nextend its capabilities by converting SAM's output infered on unlabeled images\ninto prompts. This process not only harnesses SAM's generalized visual\nknowledge but also iteratively improves SAM's prediction to cater specialized\nmedical segmentation tasks via U-Net++. The mined knowledge, serving as \"pseudo\nlabels\", enriches the training dataset, enabling the fine-tuning of the local\nnetwork.\n  Applied to the Kvasir SEG and COVID-QU-Ex datasets which consist of\ngastrointestinal polyp and lung X-ray images respectively, our proposed method\nconsistently enhanced the segmentation performance on Dice by 3% and 1%\nrespectively over the baseline U-Net++ model, when the same amount of labelled\ndata were used during training (75% and 50% of labelled data). Remarkably, our\nproposed method surpassed the baseline U-Net++ model even when the latter was\ntrained exclusively on labeled data (100% of labelled data). These results\nunderscore the potential of knowledge mining to overcome data limitations in\nspecialized models by leveraging the broad, albeit general, knowledge of\nlarge-scale models like SAM, all while maintaining operational efficiency\nessential for clinical applications.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "18 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.06816v1",
    "published_date": "2025-03-10 00:43:45 UTC",
    "updated_date": "2025-03-10 00:43:45 UTC"
  },
  {
    "arxiv_id": "2503.06814v1",
    "title": "Unlocking Generalization for Robotics via Modularity and Scale",
    "authors": [
      "Murtaza Dalal"
    ],
    "abstract": "How can we build generalist robot systems? Scale may not be enough due to the\nsignificant multimodality of robotics tasks, lack of easily accessible data and\nthe challenges of deploying on physical hardware. Meanwhile, most deployed\nrobotic systems today are inherently modular and can leverage the independent\ngeneralization capabilities of each module to perform well. Therefore, this\nthesis seeks to tackle the task of building generalist robot agents by\nintegrating these components into one: combining modularity with large-scale\nlearning for general purpose robot control. The first question we consider is:\nhow can we build modularity and hierarchy into learning systems? Our key\ninsight is that rather than having the agent learn hierarchy and low-level\ncontrol end-to-end, we can enforce modularity via planning to enable more\nefficient and capable robot learners. Next, we come to the role of scale in\nbuilding generalist robot systems. To scale, neural networks require vast\namounts of diverse data, expressive architectures to fit the data and a source\nof supervision to generate the data. We leverage a powerful supervision source:\nclassical planning, which can generalize, but is expensive to run and requires\naccess to privileged information to perform well in practice. We use these\nplanners to supervise large-scale policy learning in simulation to produce\ngeneralist agents. Finally, we consider how to unify modularity with\nlarge-scale policy learning to build real-world robot systems capable of\nperforming zero-shot manipulation. We do so by tightly integrating key\ningredients of modular high and mid-level planning, learned local control,\nprocedural scene generation and large-scale policy learning for sim2real\ntransfer. We demonstrate that this recipe can produce a single, generalist\nagent that can solve challenging long-horizon manipulation tasks in the real\nworld.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "CMU Robotics PhD Thesis, 185 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.06814v1",
    "published_date": "2025-03-10 00:38:31 UTC",
    "updated_date": "2025-03-10 00:38:31 UTC"
  },
  {
    "arxiv_id": "2503.06812v1",
    "title": "Can Proof Assistants Verify Multi-Agent Systems?",
    "authors": [
      "Julian Alfredo Mendez",
      "Timotheus Kampik"
    ],
    "abstract": "This paper presents the Soda language for verifying multi-agent systems. Soda\nis a high-level functional and object-oriented language that supports the\ncompilation of its code not only to Scala, a strongly statically typed\nhigh-level programming language, but also to Lean, a proof assistant and\nprogramming language. Given these capabilities, Soda can implement multi-agent\nsystems, or parts thereof, that can then be integrated into a mainstream\nsoftware ecosystem on the one hand and formally verified with state-of-the-art\ntools on the other hand. We provide a brief and informal introduction to Soda\nand the aforementioned interoperability capabilities, as well as a simple\ndemonstration of how interaction protocols can be designed and verified with\nSoda. In the course of the demonstration, we highlight challenges with respect\nto real-world applicability.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.LO",
      "cs.MA"
    ],
    "primary_category": "cs.PL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06812v1",
    "published_date": "2025-03-10 00:24:29 UTC",
    "updated_date": "2025-03-10 00:24:29 UTC"
  },
  {
    "arxiv_id": "2503.06810v1",
    "title": "Mitigating Preference Hacking in Policy Optimization with Pessimism",
    "authors": [
      "Dhawal Gupta",
      "Adam Fisch",
      "Christoph Dann",
      "Alekh Agarwal"
    ],
    "abstract": "This work tackles the problem of overoptimization in reinforcement learning\nfrom human feedback (RLHF), a prevalent technique for aligning models with\nhuman preferences. RLHF relies on reward or preference models trained on\n\\emph{fixed preference datasets}, and these models are unreliable when\nevaluated outside the support of this preference data, leading to the common\nreward or preference hacking phenomenon. We propose novel, pessimistic\nobjectives for RLHF which are provably robust to overoptimization through the\nuse of pessimism in the face of uncertainty, and design practical algorithms,\nP3O and PRPO, to optimize these objectives. Our approach is derived for the\ngeneral preference optimization setting, but can be used with reward models as\nwell. We evaluate P3O and PRPO on the tasks of fine-tuning language models for\ndocument summarization and creating helpful assistants, demonstrating\nremarkable resilience to overoptimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.06810v1",
    "published_date": "2025-03-10 00:13:19 UTC",
    "updated_date": "2025-03-10 00:13:19 UTC"
  }
]