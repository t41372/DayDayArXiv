{
  "date": "2025-03-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-10 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的论文再次展现了人工智能，特别是大型语言模型（LLM）的蓬勃发展。研究热点涵盖了 LLM 的基础能力提升（如谷歌的 Gemini Embedding）、效率优化（如 LoRA、推测解码、知识蒸馏）、安全性与对齐（如机器人安全护栏 RoboGuard、偏好破解缓解）、以及在各个领域的广泛应用（机器人、软件工程、医疗、遥感、金融等）。值得关注的是，今天涌现了大量新的数据集和基准测试，覆盖了视觉语言、网络智能体、代码重构、地理空间问答、医学推理、文本生成偏见、计数能力评估等多个方面，预示着对模型能力进行更细致、更严格评估的趋势。此外，扩散模型在图像生成和去除方面的改进、强化学习在公平性与探索效率上的新进展、以及 AI 伦理和社会影响的探讨（如 AI 偏见、p(doom) 经济学）也是今日的亮点。\n\n**重点论文 & 热点追踪**\n\n*   **谷歌发布 Gemini Embedding (7):** 谷歌推出了基于其最强 LLM Gemini 的新一代文本嵌入模型 Gemini Embedding，在涵盖 250 多种语言的 MMTEB 基准上大幅超越现有 SOTA 模型，展现了强大的多语言、多模态文本理解和泛化能力。\n*   **LLM 安全与对齐新进展:**\n    *   **RoboGuard (9):** 提出了一种用于 LLM 驱动机器人的两阶段安全护栏架构，通过可信 LLM 进行规则情境化和时序逻辑控制合成，有效防止不安全行为，即使面对越狱攻击。\n    *   **缓解偏好破解 (172):** 针对 RLHF 中的过度优化（偏好破解）问题，提出基于悲观主义的新目标函数和 P3O/PRPO 算法，有效提升模型在分布外评估的鲁棒性。\n    *   **LLMIdxAdvis (10):** 利用 LLM 进行数据库索引推荐，无需微调，通过上下文学习和推理缩放策略实现高效且泛化性好的推荐。\n    *   **Identity Lock (125):** 提出一种通过基于身份的唤醒词锁定 API 微调的 LLM 的新机制，防止 API 密钥泄露导致模型被滥用。\n*   **新基准与数据集涌现:**\n    *   **BEARCUBS (2):** 评估网络智能体使用计算机（键盘鼠标）能力的基准，强调真实网页和多模态交互。\n    *   **RefactorBench (21):** 评估语言智能体在代码重构中状态推理能力的基准。\n    *   **VidDiffBench (15):** 用于视频动作差异识别新任务的基准数据集。\n    *   **MapQA (13):** 包含地理实体几何信息的开放域地理空间问答数据集。\n    *   **HalluVerse25 (20):** 用于 LLM 幻觉检测的多语言细粒度基准。\n    *   **LRS-VQA (41):** 针对大型遥感图像的视觉问答基准。\n    *   **Robusto-1 (42):** 比较人类与 VLM 在秘鲁真实 OOD 驾驶场景 VQA 表现的数据集。\n    *   **MedAgentsBench (66):** 专注于复杂医学推理（多步、诊断、规划）的基准。\n    *   **WISE (94):** 评估 T2I 模型世界知识整合能力的基准和 WiScore 指标。\n    *   **FaceID-6M (120):** 首个大规模开源 FaceID 定制数据集。\n    *   **MOMA-QA (168):** 强调时空定位和实体中心查询的细粒度视频问答数据集。\n    *   **T2ICountBench (157):** 严格评估 T2I 扩散模型计数能力的基准。\n    *   **TH-Bench (159):** 评估针对 MGT 检测器的规避攻击（文本人性化）的基准。\n    *   **LongInOutBench (161):** 针对长输入长输出文本生成任务的基准。\n    *   **其他:** SEA-VL (1), AgriField3D (24), ESG-CID (35), SWEE-Bench/SWA-Bench (44), CONLIPA (101), DeFine (108), MRCEval (113), CDDM (143), DriveLM-Deficit (136)。\n*   **扩散模型新进展:**\n    *   **DSD (43):** 从低质量数据训练高质量生成模型的新方法——去噪分数蒸馏。\n    *   **IMM (47):** 归纳矩匹配，一种用于快速采样的新型生成模型，无需预训练或蒸馏。\n    *   **NFIG (124):** 基于下一频率预测的自回归图像生成框架，效率更高。\n    *   **EraDiff (134):** 通过校准扩散路径增强对象移除效果的方法。\n    *   **PLADIS (139):** 在推理时利用注意力稀疏性加速扩散模型的方法。\n    *   **TaylorSeers (152):** 通过泰勒展开预测未来特征来加速扩散模型，优于特征重用。\n*   **AI 伦理与社会:**\n    *   **p(doom) 经济学 (78):** 分析了 TAI 带来的存在风险和经济增长情景，认为即使低概率灾难也证明了对 AI 安全的大量投入是合理的。\n    *   **AI 偏见即不对称性 (83):** 将 AI 偏见重新定义为“对称性标准的违反”，并指导实践。\n    *   **AI 在审议中的作用 (59):** 实验发现公众对 AI 辅助的民主审议存在显著的“AI 惩罚”效应。\n    *   **LLM 无法内省语言知识 (60):** 研究表明 LLM 无法可靠地内省其自身的语言知识，提示工程的回答不应等同于模型的语言泛化能力。\n\n**其他值得关注的论文**\n\n*   **机器人与 LLM/Agents:** FunGraph (6) 提出功能感知的 3D 场景图；SEPS (19) 提出安全可解释策略搜索；RoboGuard (9) 设计安全护栏；InversePrompt (87) 利用逆向提示进行自纠正任务规划；Graphormer-Guided Task Planning (163) 结合 LLM 和图 Transformer 进行风险感知规划；动态路径导航 (84) 使用 LLM 进行零样本导航。\n*   **视觉与多模态:** SEA-VL (1) 东南亚视觉语言数据集；VTPSeg (5) 遥感图像分割；VidDiff (15) 视频动作差异识别；Remote Sensing VLM (16) 遥感 VLM 零样本泛化；LRS-VQA (41) 大型遥感图像 VQA；V2Flow (63) 统一视觉 Token 和 LLM 词表；TRCE (74) 可靠擦除 T2I 模型中的恶意概念；VersaAnimator (129) 多模态控制全身说话人动画；LPANet (149) LLM 引导的多模态 UAV 目标检测；CSR (160) 基于概念相似性推理的交互式医学图像分析。\n*   **强化学习:** R3T (14) FL 激励机制；多任务群组公平性 (23)；ASOR (155) 跨动态 RL 的策略正则化；MRT (45) 通过元强化微调优化测试时计算；RePO (71) 简化偏好优化；UC-MOA (116) 效用条件多目标对齐；Pessimism for Preference Hacking (172)。\n*   **模型效率与压缩:** 领域草稿模型训练 (27)；TokenButler (58) 预测 Token 重要性管理 KV 缓存；HBP (106) 长上下文 LLM 的高效 SFT；AttFC (165) 单 GPU 大规模人脸识别。\n*   **特定领域应用:** LLMIdxAdvis (10) 数据库索引；MapQA (13) 地理空间问答；AgriField3D (24) 玉米 3D 数据集；MELON (26) 重症监护移动性估计；CHD 检测 (29)；LLaMA 3.2 漏洞检测 (34)；ESGLLM (35)；数学图表生成 (70)；物流追溯 (72)；合金多元组提取 (164)；pVAD 控制 (117)；交通信号控制 (137)；作物疾病诊断 (143)。\n\n---\n\n**详细论文 TLDR**\n\n1.  **Crowdsource, Crawl, or Generate? 创建 SEA-VL，一个东南亚多元文化视觉语言数据集 (Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia)**\n    *   提出了 SEA-VL，一个旨在解决东南亚 (SEA) 地区在视觉语言 (VL) 研究中代表性不足问题的开源项目。通过众包、网络爬取和图像生成收集了 128 万张具有 SEA 文化相关性的图像（比现有数据集大 50 倍以上），发现爬取方式在成本和时间效率上优于众包，而生成模型在准确反映 SEA 文化方面仍不可靠。目标是促进更具包容性的 AI 系统开发。\n\n2.  **BEARCUBS: 计算机使用网络智能体的基准 (BEARCUBS: A benchmark for computer-using web agents)**\n    *   提出了 BEARCUBS，一个包含 111 个信息寻求问题的基准，用于评估网络智能体通过模拟键盘鼠标与真实网页交互以搜索、浏览和识别信息的能力。与以往基准不同，它需要访问实时网络内容并执行广泛的多模态交互。人类准确率为 84.7%，而 SOTA 智能体（OpenAI Operator）仅为 24.3%，揭示了改进空间。\n\n3.  **为报告摘要微调 LLM：基于监督和无监督数据的分析 (Fine-Tuning LLMs for Report Summarization: Analysis on Supervised and Unsupervised Data)**\n    *   研究了在有限计算资源（1-2 个 A100 GPU）和可能缺乏真实摘要的情况下，微调 LLM 以改进报告（政府档案、新闻、情报报告）摘要任务的可行性和效果。实验表明，微调在许多情况下有助于提高摘要质量或减少无效摘要的数量。\n\n4.  **揭秘准确性-可解释性权衡：从评论推断评分的案例研究 (Demystifying the Accuracy-Interpretability Trade-Off: A Case Study of Inferring Ratings from Reviews)**\n    *   通过从评论推断评分的 NLP 用例，比较分析了多种黑盒和可解释模型，探讨了性能与可解释性之间的关系。引入了复合可解释性 (CI) 分数来可视化权衡。结果表明，虽然通常性能随可解释性降低而提高，但关系并非严格单调，有时可解释模型更具优势。\n\n5.  **视觉和文本提示分割：一种新颖的遥感多模型框架 (Visual and Text Prompt Segmentation: A Novel Multi-Model Framework for Remote Sensing)**\n    *   提出了 VTPSeg 流程，结合 Grounding DINO+、CLIP++ 和 FastSAM，用于遥感图像的开放词汇分割。该方法利用视觉和文本提示生成候选框、过滤无关对象，并指导 FastSAM 进行精确分割，以解决 SAM 产生冗余掩码和 CLIP 忽略局部对象的问题。\n\n6.  **FunGraph：用于语言提示场景交互的功能感知 3D 场景图 (FunGraph: Functionality Aware 3D Scene Graphs for Language-Prompted Scene Interaction)**\n    *   提出 FunGraph，一种更细粒度的 3D 场景图表示，专注于物体的功能相关部分，以实现机器人直接交互。通过利用现有 3D 资源生成 2D 数据训练检测器，并将其用于增强标准 3D 场景图生成流程，实现了与 SOTA 相当的功能元素分割，并提高了任务驱动的 affordance grounding 准确性。\n\n7.  **Gemini Embedding: 来自 Gemini 的通用嵌入 (Gemini Embedding: Generalizable Embeddings from Gemini)**\n    *   介绍了 Gemini Embedding，一个利用 Google 最强 LLM Gemini 能力的 SOTA 嵌入模型。该模型利用 Gemini 的多语言和代码理解能力，生成跨多种语言和文本模态的高度通用嵌入。在 MMTEB 基准测试中，它显著优于之前的 SOTA 模型，在多语言、英语和代码基准上均达到 SOTA 水平。\n\n8.  **生成式 AI 编码助手对视障开发者的影响 (The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired)**\n    *   通过活动理论框架研究了视障开发者如何与 AI 编码助手交互。发现虽然 AI 助手有益，但也加剧或引入了新的可访问性挑战，如建议过多（需要“AI 超时”）和上下文切换困难。强调需要以活动为中心的设计来改进 AI 助手。\n\n9.  **LLM 驱动机器人的安全护栏 (Safety Guardrails for LLM-Enabled Robots)**\n    *   提出了 RoboGuard，一个两阶段护栏架构，用于确保 LLM 驱动机器人的安全。第一阶段使用可信 LLM（带 CoT 推理）将安全规则情境化；第二阶段使用时序逻辑控制合成来解决计划与安全规范的冲突。实验证明，该方法能将不安全计划执行率从 92% 降至 2.5% 以下，且对安全计划性能影响小，资源高效且对攻击鲁棒。\n\n10. **LLMIdxAdvis: 利用大型语言模型的资源高效索引顾问 (LLMIdxAdvis: Resource-Efficient Index Advisor Utilizing Large Language Model)**\n    *   提出 LLMIdxAdvis，一种无需大量微调即可使用 LLM 进行数据库索引推荐的方法。它将任务构建为序列到序列问题，利用离线构建的高质量示范池进行上下文学习，并结合工作负载特征和新颖的推理缩放策略来提高可靠性。实验表明其具有竞争力且泛化性好。\n\n11. **使用可预测性测量图像标题中的方向性偏差放大 (Measuring directional bias amplification in image captions using predictability)**\n    *   针对现有基于共现的偏差放大度量难以捕捉图像标题语义的问题，提出了 DPAC (Directional Predictability Amplification in Captioning)。DPAC 基于可预测性，能识别偏差放大的方向，改进了数据集偏差估计，且对攻击者模型不敏感，比 LIC 更可靠。\n\n12. **拓扑保持损失函数用于准确且解剖一致的心脏网格重建 (Topology-Preserving Loss for Accurate and Anatomically Consistent Cardiac Mesh Reconstruction)**\n    *   为解决心脏网格重建中常见的拓扑不一致（如膜穿透）问题，引入了拓扑保持网格损失 (TPM Loss)。该损失函数通过识别违反拓扑的点来显式强制执行拓扑约束。实验表明，TPM Loss 能将拓扑违规减少高达 93.1%，同时保持高分割精度并提高网格保真度。\n\n13. **MapQA: 基于地图数据的开放域地理空间问答 (MapQA: Open-domain Geospatial Question Answering on Map Data)**\n    *   提出了 MapQA，一个新的地理空间问答数据集，包含问题-答案对以及问题中引用的地理实体的几何形状。数据集基于 OpenStreetMap 构建，包含 3154 个 QA 对，涵盖需要地理空间推理的 9 种问题类型。探索了基于检索和基于 LLM 生成 SQL 查询的两种方法，发现检索方法难以处理计算，而 LLM 在多跳推理方面存在挑战。\n\n14. **联邦学习中的适时适价奖励机制 (Right Reward Right Time for Federated Learning)**\n    *   针对联邦学习 (FL) 中的关键学习期 (CLP) 问题，提出了 R3T (Right Reward Right Time) 激励机制。该机制旨在激励高质量客户在 CLP 期间参与，通过基于契约理论的时间感知方法，即使在信息不对称下也能最大化云端效用。仿真和概念验证表明 R3T 提高了云效用和经济效益。\n\n15. **视频动作差异识别 (Video Action Differencing)**\n    *   引入了 VidDiff (Video Action Differencing) 这一新任务，旨在识别执行相同动作的两个视频之间的细微差异。创建了 VidDiffBench 基准数据集，包含 549 对视频和人工标注的差异及时间戳。发现 SOTA LMM 在此任务上表现不佳，提出了 VidDiff 方法（一个三阶段的 agentic 工作流）来应对挑战。\n\n16. **提升遥感 VLM 零样本泛化能力的秘诀 (A Recipe for Improving Remote Sensing VLM Zero Shot Generalization)**\n    *   为提升遥感视觉语言模型 (VLM) 的零样本泛化能力，引入了两个新的图像-标题数据集（一个使用 Gemini 生成的标注，一个使用过滤后的网络 alt-text）。使用这些数据集预训练 MaMMUT 架构，在公共基准上实现了 SOTA 的零样本跨模态检索性能。同时探索了利用注意力图生成伪标签以增强模型定位能力的方法。\n\n17. **CIMAGE: 利用掩码图自编码器中的条件独立性 (CIMAGE: Exploiting the Conditional Independence in Masked Graph Auto-encoders)**\n    *   提出 CIMAGE，一种利用条件独立性 (CI) 指导图自监督学习 (SSL) 中掩码策略的新方法。通过 CI 感知的潜在因子分解生成两个上下文，并利用无监督聚类的伪标签，在潜在空间中进行掩码。理论分析和实验证明了该方法的优越性。\n\n18. **实际因果关系与非确定性因果模型 (Actual Causation and Nondeterministic Causal Models)**\n    *   在非确定性因果模型（对 Pearl 模型的推广）框架下，提出了一种新的实际因果关系定义。该定义基于实际因果关系在交流和学习因果模型中的独特功能，而非主观直觉，并结合了反事实依赖和因果模型结构简化的概念。\n\n19. **安全可解释策略搜索 (Safe Explicable Policy Search)**\n    *   提出了 SEPS (Safe Explicable Policy Search)，一种在学习过程中和学习后都最小化安全风险的可解释行为生成方法。将问题表述为约束优化问题，结合了约束策略优化和可解释策略搜索。实验证明 SEPS 能学习到安全、可解释且高效的行为。\n\n20. **HalluVerse25: 用于 LLM 幻觉的细粒度多语言基准数据集 (HalluVerse25: Fine-grained Multilingual Benchmark Dataset for LLM Hallucinations)**\n    *   介绍了 HalluVerse25，一个包含英语、阿拉伯语和土耳其语的细粒度 LLM 幻觉数据集。数据集通过 LLM 注入幻觉并经人工标注构建，用于评估模型在不同上下文中检测 LLM 生成幻觉的能力。\n\n21. **RefactorBench: 通过代码评估语言智能体的状态推理能力 (RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code)**\n    *   提出了 RefactorBench，一个包含 100 个大型多文件代码重构任务的基准，用于评估 LM 智能体的状态推理能力。任务需要跨文件依赖探索和指令遵循。发现当前智能体表现不佳（22%），通过引入状态感知，性能提升 43.9%。\n\n22. **AI 促进公正工作：构建超越“取代人类”的多元 AI 想象 (AI for Just Work: Constructing Diverse Imaginations of AI beyond \"Replacing Humans\")**\n    *   一篇立场文件，探讨 AI 发展的“为什么”问题，批判了当前主流的“取代人类”、“提高生产力”的单一想象，呼吁构建多元、嵌入伦理假设的 AI 想象。以“AI 促进公正工作”为例，展示了构建新想象并应用于医学图像合成的过程。\n\n23. **多任务强化学习中的群体公平性 (Group Fairness in Multi-Task Reinforcement Learning)**\n    *   首次提出多任务强化学习中的群体公平性问题，并设计了一个约束优化算法来同时在多个任务中强制执行公平性约束。理论和实验证明该算法能有效确保多任务公平性，且公平性差距较小。\n\n24. **AgriField3D: 一个包含多样性组合的田间玉米 3D 点云和程序化模型数据集 (AgriField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel)**\n    *   发布了 AgriField3D 数据集，包含超过 1000 个高质量的田间玉米 3D 点云，以及使用 NURBS 生成并优化的程序化模型。数据集经过图分割、手动质控和元数据标注，旨在为 AI 驱动的表型分析和农业研究提供基础。\n\n25. **最优传输理论用于观测数据因果推断入门 (A primer on optimal transport for causal inference with observational data)**\n    *   综述了最优传输 (OT) 理论与使用观测数据进行因果效应识别之间已有的深层联系。认为 OT 不仅是潜在工具，而且是模型假设的基础，旨在统一不同领域的语言，并探索未来研究方向。\n\n26. **MELON: 用于重症监护中长期移动性估计的多模态专家混合与谱时融合 (MELON: Multimodal Mixture-of-Experts with Spectral-Temporal Fusion for Long-Term Mobility Estimation in Critical Care)**\n    *   提出了 MELON，一个新颖的多模态框架，用于预测重症监护环境下的 12 小时移动状态。该框架结合了基于频谱图的视觉表示和序列加速度计统计特征，利用双分支网络架构（预训练图像编码器 + MoE 编码器）来捕捉全局和细粒度的移动模式。实验表明其优于传统方法。\n\n27. **为推测解码训练领域草稿模型：最佳实践与见解 (Training Domain Draft Models for Speculative Decoding: Best Practices and Insights)**\n    *   系统研究了为推测解码训练领域特定草稿模型的知识蒸馏技术。比较了白盒/黑盒蒸馏及不同数据源（历史查询、领域数据、合成数据）的效果。发现离线/白盒蒸馏效果更好，合成数据能有效对齐草稿模型。\n\n28. **为所有人受益的大语言模型：奖励模型中的群体公平性基准测试 (Towards Large Language Models that Benefit for All: Benchmarking Group Fairness in Reward Models)**\n    *   首次对 LLM 对齐中使用的奖励模型进行群体公平性基准测试。利用 arXiv 专家文本，无需跨群体使用相同提示。结果惊人地发现，所有评估的奖励模型（如 Nemotron-4-340B-Reward）都表现出统计上显著的群体不公平性。\n\n29. **用于胎儿超声视频中零样本先天性心脏病检测的自监督常态学习和散度向量引导模型合并 (Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos)**\n    *   首次提出一个隐私保护、零样本的先天性心脏病 (CHD) 检测框架 STUD。该框架将 CHD 检测视为常态建模问题，并结合模型合并。各站点首先在正常胎儿心脏超声上训练自监督视频异常检测 (VAD) 模型，然后通过 DivMerge 方法（散度向量引导模型合并）在不交换数据的情况下聚合模型知识。\n\n30. **高效神经子句选择强化学习 (Efficient Neural Clause-Selection Reinforcement)**\n    *   提出了一种用于饱和定理证明中子句选择的神经网络架构，该架构强大且评估高效。将该网络集成到 Vampire 定理证明器中，并通过强化学习从成功的证明尝试中进行训练。实验表明，神经引导的证明器在解决未见问题方面优于基线策略。\n\n31. **超越一刀切的摘要：为不同用户定制摘要 (Beyond One-Size-Fits-All Summarization: Customizing Summaries for Diverse Users)**\n    *   针对自动文本摘要中控制生成摘要可读性水平的挑战（尤其是在土耳其语等复杂语言中），创建了自定义数据集并训练了一个具有定制架构的模型。该方法能有效控制可读性水平，同时保持准确性和连贯性，优于基线模型。\n\n32. **面向 AI 驱动边缘服务的代理模型联合可解释性-性能优化 (Joint Explainability-Performance Optimization With Surrogate Models for AI-Driven Edge Services)**\n    *   探讨了复杂 AI 模型预测准确性与其代理模型（如线性回归）近似度之间的平衡。提出了一种联合训练方案和基于多目标优化的新算法，同时最小化复杂模型的预测误差和其与代理模型输出之间的误差。结果显著提高了代理模型的保真度，代价是复杂模型准确性略有降低。\n\n33. **新环境中的意义构建：人类认知如何启发人工智能体 (Sensemaking in Novel Environments: How Human Cognition Can Inform Artificial Agents)**\n    *   提出了一个用于在新环境中构建具有意义构建能力的人工智能体的框架。核心思想是：存在嵌入框架内部和跨框架的符号关系；不同知识结构通过共享属性交互，其净响应构成一个在新环境中用于意义构建的合成符号。\n\n34. **评估 LLaMA 3.2 用于软件漏洞检测 (Evaluating LLaMA 3.2 for Software Vulnerability Detection)**\n    *   提出 DiverseVul 数据集的精炼版本，并用其微调 LLaMA 3.2 模型进行 C/C++ 函数级漏洞检测。实验表明，预处理技术提升了模型性能，F1 分数达到 66%，优于基线的 47%。\n\n35. **通过 ESG-CID 增强 ESGLLM 的检索能力——用于映射 GRI 和 ESRS 的披露内容索引微调数据集 (Enhancing Retrieval for ESGLLM via ESG-CID -- A Disclosure Content Index Finetuning Dataset for Mapping GRI and ESRS)**\n    *   为解决 ESG 报告自动化中 RAG 系统缺乏标注数据的问题，利用 ESG 报告中的披露内容索引创建了 ESG-CID 数据集，用于训练 GRI 和 ESRS 标准的检索模型。通过提取映射关系并用 LLM 优化，构建了训练和评估集。实验表明微调 BERT 模型优于商业嵌入和公共模型。\n\n36. **约束感知的模仿学习及其在自动驾驶赛车中的应用 (A Simple Approach to Constraint-Aware Imitation Learning with Application to Autonomous Racing)**\n    *   提出了一种将安全性（约束满足）纳入模仿学习 (IL) 目标的简单方法。通过在自动驾驶赛车任务上的仿真验证，表明该方法相比基线能更好地满足约束并提高任务性能的一致性。\n\n37. **作为 AGI 基础的智能的表征主义、功能主义和自然主义构想 (A Representationalist, Functionalist and Naturalistic Conception of Intelligence as a Foundation for AGI)**\n    *   分析了创建通用人工智能 (AGI) 的基本原则。将智能理解为在未知条件下实现目标而创造新技能的能力，通过推理（演绎、归纳、溯因等）和抽象、分类等方法发展世界模型。认为意义由功能决定，这种构想使得自然主义解释成为可能，不预设意向性或意识。\n\n38. **NeuroChat: 用于定制学习体验的神经自适应 AI 聊天机器人 (NeuroChat: A Neuroadaptive AI Chatbot for Customizing Learning Experiences)**\n    *   提出了 NeuroChat，一个概念验证性的神经自适应 AI 导师，集成了实时 EEG 参与度跟踪和生成式 AI。NeuroChat 监控学习者的认知参与度，并动态调整内容复杂性、响应风格和节奏。初步研究表明 NeuroChat 增强了认知和主观参与度。\n\n39. **用于物理推理的去噪哈密顿网络 (Denoising Hamiltonian Network for Physical Reasoning)**\n    *   提出了去噪哈密顿网络 (DHN)，一个将哈密顿力学算子推广为更灵活神经算子的新框架。DHN 通过去噪机制捕捉非局部时间关系并减轻数值积分误差，支持多系统建模。在三个不同的物理推理任务中展示了其有效性和灵活性。\n\n40. **先过滤图像，后生成指令：视觉指令调优的预指令数据选择 (Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning)**\n    *   提出了 PreSel，一种更实用的视觉指令调优 (VIT) 数据选择范式，直接选择最有益的未标记图像，并仅为选定图像生成指令。通过估计任务重要性、聚类图像特征并选择代表性图像，该方法显著降低了指令生成和 LVLM 微调的计算开销，用 15% 的图像即可达到全数据 VIT 的性能。\n\n41. **当大型视觉语言模型遇上大型遥感影像：从粗到细的文本引导令牌剪枝 (When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning)**\n    *   为解决 LVLM 处理大型遥感影像 (RSI) 时的信息损失和高计算成本问题，提出了一种结合动态图像金字塔 (DIP) 的文本引导令牌剪枝方法。该方法利用区域聚焦模块 (RFM) 识别关键视觉令牌，并基于 DIP 进行从粗到细的图像块选择和令牌剪枝。同时构建了新的 LRS-VQA 基准。\n\n42. **Robusto-1 数据集：比较人类和 VLM 在秘鲁真实 OOD 自动驾驶 VQA 上的表现 (Robusto-1 Dataset: Comparing Humans and VLMs on real out-of-distribution Autonomous Driving VQA from Peru)**\n    *   创建了 Robusto-1 数据集，使用秘鲁（驾驶风格激进、交通指数高）的行车记录仪视频，通过 VQA 任务和表征相似性分析 (RSA) 比较人类和 VLM 在 OOD 驾驶场景中的认知对齐程度。发现对齐程度因问题类型而异。\n\n43. **去噪分数蒸馏：从带噪扩散预训练到单步高质量生成 (Denoising Score Distillation: From Noisy Diffusion Pretraining to One-Step High-Quality Generation)**\n    *   提出了去噪分数蒸馏 (DSD)，一种从低质量数据训练高质量生成模型的新方法。首先在噪声样本上预训练扩散模型，然后将其蒸馏为能够生成干净输出的单步生成器。DSD 不仅加速了模型，还显著提高了样本质量，尤其是在教师模型质量较低时。\n\n44. **仓库级编码任务的自动基准生成 (Automated Benchmark Generation for Repository-Level Coding Tasks)**\n    *   为解决手动构建如 SWE-Bench 这类代码智能体基准的局限性（仓库少、可能存在分布失配），提出了 SetUpAgent，一个能自动进行历史依赖设置、测试执行和结果解析的系统。利用该系统生成了扩展版的 SWEE-Bench 和面向应用的 SWA-Bench，发现与 SWE-Bench 存在显著差异。\n\n45. **通过元强化微调优化测试时计算 (Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning)**\n    *   将优化 LLM 测试时计算的问题形式化为元强化学习 (RL) 问题，提出了衡量计算效率的新指标（累积遗憾）。开发了 MRT (Meta Reinforcement Fine-Tuning)，一种结合结果奖励和稠密进度奖励的微调方法，显著提高了数学推理任务的性能和令牌效率。\n\n46. **使用性能计数器在 AI 加速器中运行时检测对抗性攻击 (Runtime Detection of Adversarial Attacks in AI Accelerators Using Performance Counters)**\n    *   提出了 SAMURAI 框架，利用 AI 性能计数器 (APC) 跟踪模型动态行为，并结合片上机器学习分析引擎 TANTO，在运行时检测 AI 加速器中的对抗性攻击和滥用。实验表明其检测准确率高达 97%，优于传统软件方法。\n\n47. **归纳矩匹配 (Inductive Moment Matching)**\n    *   提出了归纳矩匹配 (IMM)，一类新的生成模型，用于单步或少步采样，采用单阶段训练。IMM 无需预训练初始化，保证分布级收敛，且在各种超参数和标准架构下保持稳定。在 ImageNet-256 和 CIFAR-10 上取得了 SOTA 或有竞争力的结果。\n\n48. **使用迭代加深 AND/OR 图网络的任务与运动规划框架 (A Task and Motion Planning Framework Using Iteratively Deepened AND/OR Graph Networks)**\n    *   提出了一种基于 AND/OR 图网络的集成任务与运动规划 (TAMP) 方法。该方法能在运行时通过逐步添加子图来增长 AND/OR 图，以处理子任务数量先验未知的问题（如在杂乱环境中取物）。该方法可扩展至多机器人 TAMP，并进行了仿真和实物验证。\n\n49. **初级软件开发者对采用 LLM 进行软件工程的看法：系统文献综述 (Junior Software Developers' Perspectives on Adopting LLMs for Software Engineering: a Systematic Literature Review)**\n    *   通过对 56 篇研究的系统文献综述，总结了初级开发者（经验≤5 年）对使用 LLM 工具进行软件工程 (LLM4SE) 的看法。发现他们普遍使用 LLM 搜索信息、提升技能，并同时看到了好处（效率提升）和挑战（错误建议、数据泄露等）。\n\n50. **用于基于表面肌电图手势识别的物理储层计算框架的事件驱动实现 (Event-Driven Implementation of a Physical Reservoir Computing Framework for superficial EMG-based Gesture Recognition)**\n    *   探索了一种用于手势识别的新型神经拟态计算方法，以事件驱动方式从表面肌电图 (sEMG) 数据中提取时空脉冲信息。设计并实现了基于脉冲神经网络 (SNN) 的物理储层计算 (PRC) 框架 sRNR。该系统在公共数据集上验证有效，展示了近传感器低延迟处理的潜力。\n\n51. **KSOD: 按需为 LLM 补充知识 (KSOD: Knowledge Supplement for LLMs On Demand)**\n    *   提出了 KSOD 框架，通过基于知识的监督微调 (SFT) 来提升 LLM 在特定领域任务上的表现。KSOD 分析错误原因，识别缺失知识，训练知识模块进行验证，并用该模块补充 LLM。实验证明能提升相关任务性能，同时保持其他任务性能。\n\n52. **排队、预测和 LLM：挑战与开放问题 (Queueing, Predictions, and LLMs: Challenges and Open Problems)**\n    *   综述了在排队系统中使用机器学习预测（如服务时间预测）来改进性能的研究，并重点讨论了 LLM 推理系统中的调度挑战。认为 LLM 系统为排队论的应用提供了重要机会，并提出了新的模型和开放问题。\n\n53. **几何重定向 (GeoRT): 一种有原则、超快速的神经手部重定向算法 (Geometric Retargeting: A Principled, Ultrafast Neural Hand Retargeting Algorithm)**\n    *   介绍了 GeoRT，一种用于远程操作的超快速 (1KHz)、有原则的神经手部重定向算法。该算法以无监督方式训练，利用新颖的几何目标函数（保真度、配置空间覆盖、均匀响应、捏合对应、防自碰撞）将人手指关键点转换为机器人手关键点，无需耗时的测试时优化。\n\n54. **AI 驱动的知识共享促进非营利医疗机构协作与决策：范围审查协议 (AI-Enabled Knowledge Sharing for Enhanced Collaboration and Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review Protocol)**\n    *   概述了一项范围审查协议，旨在系统性地梳理关于在资源有限的非营利医疗机构中，AI 赋能的知识共享如何促进协作和决策的现有证据，特别是在外部支持减少的背景下。\n\n55. **LMM-R1: 通过两阶段基于规则的 RL 赋予 3B LMM 强大推理能力 (LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL)**\n    *   提出了 LMM-R1，一个两阶段框架，通过基础推理增强 (FRE) 和多模态泛化训练 (MGT)，将基于规则的 RL 适应于多模态推理，以解决小型 LMM 在推理能力和模态对齐上的挑战。实验证明该方法能有效提升 3B LMM 在多模态和纯文本基准上的推理性能。\n\n56. **使用大型语言模型通过迭代多智能体调试实现全自动编程 (Fully Autonomous Programming using Iterative Multi-Agent Debugging with Large Language Models)**\n    *   提出了 SEIDR (Synthesize, Execute, Instruct, Debug, and Repair) 多智能体框架，通过迭代调试解决 LLM 程序合成中的“差一点综合症”。实验表明，该框架在 PSB2 和 HumanEval-X 基准上优于单独使用 LLM 或传统遗传编程，尤其在 C++ 上表现突出。\n\n57. **ZeroSumEval: 一个通过模型间竞争扩展 LLM 评估的可扩展框架 (ZeroSumEval: An Extensible Framework For Scaling LLM Evaluation with Inter-Model Competition)**\n    *   介绍了 ZeroSumEval，一个基于竞争性游戏（如安全挑战、棋类、知识测试）的动态、演进式 LLM 评估框架。提供标准化、可扩展的游戏实现方式，并利用 DSPy 抽象 LLM 玩家策略。\n\n58. **TokenButler: 令牌重要性是可预测的 (TokenButler: Token Importance is Predictable)**\n    *   提出了 TokenButler，一个高粒度、查询感知的轻量级预测器，用于识别 LLM KV 缓存中的关键令牌。通过预测令牌的上下文重要性进行优先级排序，相比 SOTA 重要性估计方法，能提高困惑度和下游任务准确率。\n\n59. **审议中的人工智能：AI 惩罚与新审议鸿沟的出现 (Artificial Intelligence in Deliberation: The AI Penalty and the Emergence of a New Deliberative Divide)**\n    *   通过在德国进行的代表性样本调查实验发现，公众对 AI 辅助的民主审议表现出显著的“AI 惩罚”——参与意愿更低，评价更差。这种效应受个体对 AI 的态度调节，可能导致基于 AI 态度的新型“审议鸿沟”。\n\n60. **语言模型未能内省其语言知识 (Language Models Fail to Introspect About Their Knowledge of Language)**\n    *   系统研究了 21 个开源 LLM 在语法知识和词语预测两个领域的内省能力。通过比较模型对元语言提示的响应与其内部字符串概率，未发现模型具有特权“自我访问”能力的证据，表明提示响应不应等同于模型的语言泛化能力。\n\n61. **用于 NOMA 的干扰感知超级星座设计 (Interference-Aware Super-Constellation Design for NOMA)**\n    *   采用自编码器 (AE) 为非正交多址接入 (NOMA) 设计干扰感知的超级星座。提出的 AE-NOMA 旨在生成在接收端符号可区分的超级星座，无需 SIC，允许使用最大似然方法。结果表明能改善误码率。\n\n62. **从中心化到去中心化联邦学习：理论见解、隐私保护和鲁棒性挑战 (From Centralized to Decentralized Federated Learning: Theoretical Insights, Privacy Preservation, and Robustness Challenges)**\n    *   综述了中心化 (CFL) 和去中心化 (DFL) 联邦学习，认为其根本区别在于训练协议（分离聚合 vs. 联合优化），这导致了模型效用、隐私和鲁棒性的差异。指出 DFL 中基于分布式优化的方法探索不足。\n\n63. **V2Flow: 统一视觉 Token 化和大型语言模型词汇表以实现自回归图像生成 (V2Flow: Unifying Visual Tokenization and Large Language Model Vocabularies for Autoregressive Image Generation)**\n    *   提出了 V2Flow，一种新颖的视觉 Tokenizer，产生的离散视觉 Token 能高保真重建，并与 LLM 词汇空间在结构和潜在分布上对齐。通过将视觉 Token 化构建为流匹配问题，并结合视觉词汇重采样器和掩码自回归 Rectified-Flow 解码器，实现了基于现有 LLM 的自回归视觉生成。\n\n64. **通过贝叶斯神经网络进行高效的成员推理攻击 (Efficient Membership Inference Attacks by Bayesian Neural Network)**\n    *   提出了一种新颖的贝叶斯成员推理攻击 (BMIA) 方法。通过拉普拉斯近似将训练好的参考模型转换为贝叶斯神经网络，直接估计条件得分分布，从而用单个参考模型解决认知和偶然不确定性，实现高效且强大的 MIA。\n\n65. **通过学习目标和基准推进越南语信息检索 (Advancing Vietnamese Information Retrieval with Learning Objective and Benchmark)**\n    *   针对越南语信息检索 (IR) 缺乏基准的问题，提出了一个新的越南语 IR 基准 ViRReR，专注于检索和重排任务。同时提出了一种基于 InfoNCE 的新目标函数用于训练越南语嵌入模型，并分析了温度参数的影响。\n\n66. **MedAgentsBench: 评估复杂医学推理的思维模型和智能体框架的基准 (MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning)**\n    *   提出了 MedAgentsBench，一个专注于评估需要多步临床推理、诊断制定和治疗规划等挑战性医学问题的基准。通过对多种基础模型和推理方法的实验，发现最新的思维模型（DeepSeek R1, OpenAI o3）表现出色，基于搜索的智能体方法具有良好的性能成本比。\n\n67. **良好基础对于高效强化学习是否必要？基础模型在探索中的计算作用 (Is a Good Foundation Necessary for Efficient Reinforcement Learning? The Computational Role of the Base Model in Exploration)**\n    *   在 RL 与语言模型的新计算框架下，研究了预训练模型对探索效率的影响。发现覆盖度（预训练模型覆盖近优响应的程度）对计算效率至关重要。提出了 SpannerSampling 算法，在足够覆盖度下实现最优数据效率和计算效率。\n\n68. **从想法到实现：评估大型语言模型在软件开发中的影响——观点论文 (From Idea to Implementation: Evaluating the Influence of Large Language Models in Software Development -- An Opinion Paper)**\n    *   收集并分析了 11 位专家关于使用 LLM 进行软件开发的经验和观点。总体观点积极，认为 LLM 提高了生产力、减少了编码时间，但也指出了过度依赖风险和伦理考虑等挑战。\n\n69. **分而治之自监督学习用于高内涵成像 (Divide and Conquer Self-Supervised Learning for High-Content Imaging)**\n    *   为解决自监督学习难以学习被简单模式主导的复杂特征的问题，提出了 SpliCER 架构。该架构将图像分割，并从各部分提炼信息以引导模型学习更微妙复杂的特征。在医学和地理空间成像中验证了其有效性。\n\n70. **从文本到视觉：使用 LLM 以矢量图形生成数学图表 (From Text to Visuals: Using LLMs to Generate Math Diagrams with Vector Graphics)**\n    *   探索使用 LLM 通过中间的 SVG（可缩放矢量图形）表示，为数学问题的文本提示自动生成相关图表。定义了任务，开发了基于 LLM 提示的流程，并提出了评估方法和改进策略，旨在增强数学学习体验。\n\n71. **RePO: 基于 ReLU 的偏好优化 (RePO: ReLU-based Preference Optimization)**\n    *   提出了 RePO (ReLU-based Preference Optimization)，一种简化的 LLM 对齐算法。通过梯度分析移除了 SimPO 中的 $\\beta$ 参数，并采用基于 ReLU 的最大间隔损失自然过滤简单样本对。理论上是 SimPO 的极限情况，实验表明其在仅需调整一个超参数的情况下优于 DPO 和 SimPO。\n\n72. **支持区块链上物流可追溯性的语义链接网络模型 (A Semantic Link Network Model for Supporting Traceability of Logistics on Blockchain)**\n    *   提出了一种基于语义链接网络模型的区块链上语义数据模型，用于表示物流过程。设计了状态表示模型和到区块链交易的映射，并提出了一种快捷方式构建算法以提高路径追踪效率，以及奖惩策略鼓励状态确认。\n\n73. **受大脑启发的自适应记忆双网络用于少样本图像分类 (Brain Inspired Adaptive Memory Dual-Net for Few-Shot Image Classification)**\n    *   受人类互补学习系统启发，提出了 SCAM-Net，模拟系统巩固过程，通过自适应记忆模块解决少样本场景下识别有意义特征的难题。构建了海马体-新皮层双网络，在新皮层内存储和自适应调节结构化表征。实验表明达到 SOTA 性能。\n\n74. **TRCE: 迈向文本到图像扩散模型中可靠的恶意概念擦除 (TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models)**\n    *   提出了 TRCE，一种两阶段概念擦除策略，用于可靠地擦除 T2I 扩散模型中的恶意概念（如 NSFW），同时保留模型的正常生成能力。第一阶段擦除文本提示中隐含的恶意语义，第二阶段通过对比学习引导早期去噪预测朝向安全方向。\n\n75. **我的文本在你的 AI 模型里吗？应用于 LLM 的基于梯度的成员推理测试 (Is My Text in Your AI Model? Gradient-based Membership Inference Test applied to LLMs)**\n    *   将基于梯度的成员推理测试 (gMINT) 应用于基于 LLM 的文本分类，以判断特定数据样本是否用于模型训练。在多种 Transformer 模型和数据集上评估，结果显示 MINT 具有鲁棒性（AUC 85%-99%），可用于模型审计和隐私保护。\n\n76. **人工乌托邦：用于民主化未来的模拟和智能体 (Artificial Utopia: Simulation and Intelligent Agents for a Democratised Future)**\n    *   提出“人工乌托邦”研究议程，利用形式化、计算方法和人工智能（如 ABM、RL、LLM）在计算机中模拟和测试新的政治经济思想（如公民议会、民主企业），以应对现实世界挑战。\n\n77. **将论证框架编码为命题逻辑系统 (Encoding Argumentation Frameworks to Propositional Logic Systems)**\n    *   推广了将论证框架 (AFs) 编码为不同命题逻辑系统（二值、三值、模糊）中逻辑公式的方法。研究了 AF 模型（基于 Dung 语义和 Gabbay 方程语义）与编码后公式模型（基于逻辑系统语义）之间的关系。\n\n78. **p(doom) 的经济学：变革性 AI 时代的生存风险与经济增长情景 (The Economics of p(doom): Scenarios of Existential Risk and Economic Growth in the Age of Transformative AI)**\n    *   分析了变革性人工智能 (TAI) 可能带来的各种情景（从人类灭绝到后稀缺社会）及其相关的生存风险和经济结果。表明即使灾难性结果概率很低，也证明了对 AI 安全和对齐进行大量投资是合理的，当前全球努力远远不够。\n\n79. **基于强化学习的机器人无序目标智能识别研究与设计 (Research and Design on Intelligent Recognition of Unordered Targets for Robots Based on Reinforcement Learning)**\n    *   提出了一种基于强化学习的 AI 机器人无序目标识别方法。该方法首先使用双边滤波处理图像，然后采用差异化 AI 策略（压缩光照、增强反射）并融合，最后将增强图像输入深度强化学习模型进行训练。实验表明能提高图像质量和识别效率与准确性。\n\n80. **T3Former: 作为占用世界模型的时间三平面 Transformer (Temporal Triplane Transformers as Occupancy World Models)**\n    *   提出了 T3Former，一种用于自动驾驶的新的 4D 占用世界模型。该模型首先预训练紧凑的三平面表示以压缩 3D 语义占用环境，然后提取多尺度时间运动特征，并使用自回归方法迭代预测未来的三平面变化，最终解码为未来占用和自我运动轨迹。实验表明其速度更快且精度更高。\n\n81. **减轻 YOLO 类目标检测模型中的幻觉：重新审视分布外检测 (Mitigating Hallucinations in YOLO-based Object Detection Models: A Revisit to Out-of-Distribution Detection)**\n    *   研究了 YOLO 系列检测器及其 OOD 过滤器在现有基准上表现不佳的原因。发现现有 OOD 基准存在标注问题（包含 ID 对象），ID 数据集也可能包含 OOD 对象，导致性能评估不准确。提出通过精心合成 OOD 数据集并用于微调 YOLO 检测器来抑制目标性得分，从而显著减少幻觉错误。\n\n82. **评估随机种子对微调大型语言模型的宏观和微观影响 (Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning Large Language Models)**\n    *   系统评估了随机种子对 LLM 微调效果的影响。通过传统指标（准确率、F1）的均值和方差分析宏观影响，并引入新的一致性指标衡量微观影响（单个预测的稳定性）。发现宏观和微观层面都存在显著方差，强调了考虑随机种子的重要性。\n\n83. **AI 偏见作为不对称性：指导实践的回顾 (AI Biases as Asymmetries: A Review to Guide Practice)**\n    *   回顾了对 AI 偏见理解的演变，认为偏见是 AI 系统的组成部分，有时甚至优于偏差较小的替代方案。提出将偏见理解为“对称性标准的违反”，区分了错误偏见、不平等偏见和过程偏见，并指导实践中如何处理不同类型的偏见。\n\n84. **具有 LLM 推理的运动智能体的动态路径导航 (Dynamic Path Navigation for Motion Agents with LLM Reasoning)**\n    *   探索了 LLM 在空间路径规划和无障碍轨迹生成中的零样本导航能力。通过将路径表示为锚点连接的直线，并利用 LLM 的推理能力，实现了在静态和动态多智能体环境中的全局、动态、闭环规划，能自主解决碰撞问题。\n\n85. **实验探索：调查人类与大型语言模型智能体之间的合作互动行为 (Experimental Exploration: Investigating Cooperative Interaction Behavior Between Humans and Large Language Model Agents)**\n    *   通过让参与者与具有不同特征（声称是人类、基于规则的 AI、LLM 智能体）的 LLM 智能体进行重复囚徒困境博弈，研究了人类的合作行为。发现合作行为因智能体声称的特征以及参与者性别与声称特征的交互作用而异。\n\n86. **人机协同自适应模型及其收敛性分析 (Human Machine Co-Adaptation Model and Its Convergence Analysis)**\n    *   基于合作自适应马尔可夫决策过程 (CAMDPs) 模型，提出了一种解决机器人辅助康复中人机界面设计问题的新方法。建立了 CAMDPs 收敛的充分条件和纳什均衡点的唯一性，并探讨了多纳什均衡点场景下的策略，通过数值实验验证了有效性。\n\n87. **通过大型语言模型的逆向提示进行自纠正任务规划 (Self-Corrective Task Planning by Inverse Prompting with Large Language Models)**\n    *   提出了 InversePrompt，一种新颖的自纠正机器人任务规划方法。该方法利用逆向提示（生成初始动作的逆向动作并验证其是否能恢复原状态）来增强 LLM 规划的可解释性和逻辑一致性。实验表明其成功率高于现有方法。\n\n88. **通过影响函数实现子群体偏移的群组鲁棒样本重加权 (Group-robust Sample Reweighting for Subpopulation Shifts via Influence Functions)**\n    *   提出了 GSR (Group-robust Sample Reweighting)，一种两阶段方法，利用少量带群组标签的数据作为目标集，通过影响函数优化其他无群组标签数据的权重，以提高模型对子群体偏移的鲁棒性。该方法理论合理、轻量级且有效。\n\n89. **用于确定 AI 多智能体系统最优路径的自适应路由协议：一种优先级和学习增强方法 (Adaptive routing protocols for determining optimal paths in AI multi-agent systems: a priority- and learning-enhanced approach)**\n    *   提出了一种用于 AI 多智能体网络的增强型自适应路由算法。该算法在扩展的 Dijkstra 框架基础上，集成了优先级成本函数（考虑任务复杂度、优先级、带宽、负载等）和动态学习机制（通过 RL 调整权重因子），并结合启发式过滤和分层路由提高可扩展性。\n\n90. **将知识蒸馏到量子视觉 Transformer 用于生物医学图像分类 (Distilling Knowledge into Quantum Vision Transformers for Biomedical Image Classification)**\n    *   提出了一种新颖的量子视觉 Transformer (QViT) 模型用于生物医学图像分类，并研究了其与 ViT 在从头训练和知识蒸馏 (KD) 预训练下的性能。发现 QViT 在从头训练时优于 ViT，且参数量和计算量极低。QViT 和 ViT 对 KD 反应相似。\n\n91. **VizTrust: 用于捕捉人机通信中用户信任动态的可视化分析工具 (VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in Human-AI Communication)**\n    *   提出了 VizTrust，一个实时可视化分析工具，利用多智能体协作系统捕捉和分析人机通信中的用户信任动态。基于信任量表（能力、诚信、仁慈、可预测性），使利益相关者能观察信任形成过程，识别模式，并找出影响信任的交互元素。\n\n92. **零样本人机协作的自动课程设计 (Automatic Curriculum Design for Zero-Shot Human-AI Coordination)**\n    *   将多智能体 UED (Unsupervised Environment Design) 方法扩展到零样本人机协作场景。提出了新的效用函数和协作玩家采样方法，训练的 ego-agent 在 Overcooked-AI 环境中与人类代理和真实人类协作时，在未见环境中表现优于基线。\n\n93. **NTN 中的联邦学习：设计、架构与挑战 (Federated Learning in NTNs: Design, Architecture and Challenges)**\n    *   提出了非地面网络 (NTN) 中的分布式分层联邦学习 (HFL) 框架。利用 HAPS 星座作为中间分布式 FL 服务器，集成 LEO 卫星和地面客户端进行训练，并利用 GEO/MEO 卫星进行全球模型中继。旨在增强隐私、提高精度、增加可扩展性。\n\n94. **WISE: 用于文本到图像生成的世界知识信息语义评估 (WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image Generation)**\n    *   提出了 WISE，首个专门用于评估 T2I 模型中世界知识整合和复杂语义理解的基准。包含跨 25 个子领域的 1000 个精心设计的提示，并引入了新的定量指标 WiScore。对 20 个模型的评估表明，当前模型在有效整合和应用世界知识方面存在显著局限。\n\n95. **观看和销售 AI 艺术的方式 (Ways of Seeing, and Selling, AI Art)**\n    *   以佳士得首次 AI 艺术拍卖为例，探讨了 AI 艺术在艺术界的定位、社会反响和市场接受度。讨论了数据挖掘、版权争议、展览设计中的“框架”效应（如何呈现以影响价值感知）以及 AI 艺术的经济维度。\n\n96. **COMODO: 用于高效自我中心人体活动识别的跨模态视频到 IMU 蒸馏 (COMODO: Cross-Modal Video-to-IMU Distillation for Efficient Egocentric Human Activity Recognition)**\n    *   提出了 COMODO，一个跨模态自监督蒸馏框架，将知识从视频模态迁移到 IMU 模态，以解决视频 HAR 的功耗/隐私问题和 IMU 数据集有限的问题。通过对齐视频和 IMU 嵌入的特征分布，使 IMU 编码器继承视频的丰富语义信息，同时保持效率。\n\n97. **AuthorMist: 利用强化学习规避 AI 文本检测器 (AuthorMist: Evading AI Text Detectors with Reinforcement Learning)**\n    *   提出了 AuthorMist，一个基于强化学习的系统，将 AI 生成的文本转换为类人写作以规避 AI 文本检测器。利用 3B 参数 LLM 和 GPRO 进行微调，将外部检测器 API 作为奖励函数。实验表明其规避成功率高，同时保持语义相似性。\n\n98. **用于胃肠癌管理的腹部 CT 体组成分析 AI 驱动自动化工具 (AI-Driven Automated Tool for Abdominal CT Body Composition Analysis in Gastrointestinal Cancer Management)**\n    *   开发了一款 AI 驱动的工具，用于自动分析腹部 CT 扫描，分割肌肉、皮下脂肪和内脏脂肪。该工具集成了多视图定位模型和高精度 2D nnUNet 分割模型，并提供交互界面供临床医生优化结果，旨在提高胃肠癌管理的效率和标准化。\n\n99. **LLM-C3MOD: 用于跨文化仇恨言论审核的人机协作系统 (LLM-C3MOD: A Human-LLM Collaborative System for Cross-Cultural Hate Speech Moderation)**\n    *   提出了 LLM-C3MOD，一个三步式人机协作流程，帮助非母语审核员进行跨文化仇恨言论审核。流程包括 RAG 增强的文化背景注释、LLM 初步审核和针对 LLM 无共识案例的人工审核。实验表明该系统提高了准确性并减少了人工工作量。\n\n100. **CoT-Drive: 利用 LLM 和思维链提示进行高效的自动驾驶运动预测 (CoT-Drive: Efficient Motion Forecasting for Autonomous Driving with LLMs and Chain-of-Thought Prompting)**\n    *   提出了 CoT-Drive，利用 LLM 和思维链 (CoT) 提示增强自动驾驶运动预测。采用师生知识蒸馏策略将 LLM 的场景理解能力迁移到轻量级 LM，以实现边缘设备实时运行。CoT 提示生成的语义注释提高了复杂交通环境的理解。同时发布了两个新的场景描述数据集。\n\n101. **用于零样本 NER 的跨语言 IPA 对比学习 (Cross-Lingual IPA Contrastive Learning for Zero-Shot NER)**\n    *   研究了如何通过减少语言间 IPA 转录的音素表示差距来改进低资源语言的零样本 NER。提出了 CONLIPA 数据集（包含 10 个语系的 IPA 对）和 IPAC 跨语言 IPA 对比学习方法。实验表明该方法显著优于基线。\n\n102. **用于优化基于无人机的精准杂草测绘的离散高斯过程表示 (Discrete Gaussian Process Representations for Optimising UAV-based Precision Weed Mapping)**\n    *   比较了五种用于高斯过程 (GP) 杂草测绘的离散化方法（四叉树、楔形波、BSP LSE、BSP 图合并、变分辨率六边形网格）。发现四叉树总体最佳，但其他方法在特定场景下（如大片杂草）表现更好，强调需要根据杂草分布模式选择表示方法。\n\n103. **基于大型语言模型的多模态知识图谱嵌入零样本学习方法 (A Zero-shot Learning Method Based on Large Language Models for Multi-modal Knowledge Graph Embedding)**\n    *   提出了 ZSLLM 框架，利用 LLM 进行多模态知识图谱 (MMKG) 的零样本嵌入学习。通过利用未见类别的文本模态信息作为提示，借助 LLM 的推理能力实现跨模态语义信息迁移，增强未见类别的嵌入表示。\n\n104. **AI 驱动的生物电信号控制用于细胞实时拓扑重组 (AI-driven control of bioelectric signalling for real-time topological reorganization of cells)**\n    *   提出一项实验设想，使用深度强化学习 (DRL) 框架结合实验室自动化技术，实时操控生物电信号以引导组织再生和形态发生。旨在通过与生物系统的持续交互和反馈，改进对生物电机制的理解，并开发新的生物医学应用。\n\n105. **集成大型语言模型、预训练时间序列模型和知识图谱的时间序列多任务框架 (A Time Series Multitask Framework Integrating a Large Language Model, Pre-Trained Time Series Model, and Knowledge Graph)**\n    *   提出了 LTM，一个新颖的时间序列多任务框架，集成了预训练时间序列模型、LLM 和知识图谱，用于处理预测、插补和异常检测任务。通过将时间序列编码为补丁，利用知识图谱丰富提示，并设计新颖的特征融合方法，在少量可训练参数下实现了优越性能。\n\n106. **分层平衡打包：面向长上下文 LLM 的高效监督微调 (Hierarchical Balance Packing: Towards Efficient Supervised Fine-tuning for Long-Context LLM)**\n    *   提出了 HBP (Hierarchical Balance Packing)，通过新颖的批次构建方法和训练策略解决长短上下文混合训练带来的负载不平衡问题。HBP 构建多级数据打包组，为每个组优化打包长度和配置（并行度、梯度检查点），并设计动态训练流程。实验表明显著减少训练时间（如 DeepSeek-V2 加速 2.4 倍）。\n\n107. **基于 GDPR 的访问和使用控制在分布式系统中实现合法且可问责的个人数据处理 (Lawful and Accountable Personal Data Processing with GDPR-based Access and Usage Control in Distributed Systems)**\n    *   提出了一种基于 GDPR 目的限制原则的自动化规范推理方法，用于建立数据处理活动合法性的法律论证。该方法基于隐私专家的法律限定，通过形式化本体和语义实现，并利用 eFLINT 语言和扩展的 XACML 架构集成到分布式系统中，以促进透明度、问责制和合规性。\n\n108. **DeFine: 一个用于长文生成的分解式细粒度标注数据集 (DeFine: A Decomposed and Fine-Grained Annotated Dataset for Long-form Article Generation)**\n    *   推出了 DeFine 数据集，特点是采用分层分解策略，并结合领域知识和多级标注，以解决长文生成 (LFAG) 中的逻辑一致性、主题覆盖和叙事连贯性挑战。通过多智能体协作流程构建，并在其上测试了基线模型，验证了数据集的有效性。\n\n109. **交通规划中的生成式 AI：综述 (Generative AI in Transportation Planning: A Survey)**\n    *   首次全面综述了生成式 AI (GenAI) 在交通规划中的应用。提出了一个新的分类法（按交通规划任务和计算技术分类），探讨了 GenAI 在描述性、预测性、生成性、模拟和可解释性任务中的作用，以及数据准备、微调、推理策略等方面的进展，并讨论了挑战和未来方向。\n\n110. **推理时扩展的思想可以惠及生成式预训练算法 (Ideas in Inference-time Scaling can Benefit Generative Pre-training Algorithms)**\n    *   一篇立场文件，认为优先考虑推理时扩展效率（跨序列长度和细化步骤）的“推理优先”视角可以启发超越自回归和扩散模型的新型生成式预训练算法。以 IMM 为例说明了这种方法的潜力。\n\n111. **PTMs-TSCIL: 基于预训练模型的类增量学习 (PTMs-TSCIL Pre-Trained Models Based Class-Incremental Learning)**\n    *   首次探索了将预训练模型 (PTM) 应用于时间序列类增量学习 (TSCIL)。方法包括冻结 PTM 主干、增量调整共享适配器、知识蒸馏以及一个新颖的特征漂移补偿网络 (DCN)。实验表明该方法在平衡稳定性和可塑性方面达到了 SOTA 性能。\n\n112. **分层神经符号决策 Transformer (Hierarchical Neuro-Symbolic Decision Transformer)**\n    *   提出了一个分层神经符号控制框架，结合了经典符号规划（高层）和基于 Transformer 的策略（低层），用于解决复杂长时程决策任务。符号规划器构建可解释的操作序列，每个操作被翻译成子目标 Token 来指导决策 Transformer 生成细粒度动作序列。\n\n113. **MRCEval: 一个全面、有挑战性且易于获取的机器阅读理解基准 (MRCEval: A Comprehensive, Challenging and Accessible Machine Reading Comprehension Benchmark)**\n    *   基于新的阅读理解 (RC) 能力分类法，构建了 MRCEval 基准。该基准利用 LLM 作为样本生成器和选择评判者，包含 2.1K 个高质量多选题，覆盖 13 种不同的 RC 技能。对 28 个模型的广泛评估表明 MRC 仍然是一个挑战。\n\n114. **混合专家模型 (MoE) 全面综述：算法、理论与应用 (A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and Applications)**\n    *   全面综述了混合专家 (MoE) 模型的最新进展。介绍了 MoE 的基本设计（门控、专家、路由、训练、系统），探讨了其在持续学习、元学习、多任务学习、强化学习中的算法设计，总结了理论研究及其在 CV 和 NLP 中的应用，并讨论了未来方向。\n\n115. **ASTRA: 具有自适应和战略推理能力的谈判智能体，通过动态报价优化中的行动实现 (ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through Action in Dynamic Offer Optimization)**\n    *   介绍了 ASTRA，一个用于原则驱动谈判智能体的新框架。ASTRA 基于对手建模和 Tit-for-Tat 互惠原则，通过解释对手行为、使用 LP 求解器优化还价、并基于策略和接受概率选择报价，实现了对对手变化的有效适应和有利结果。\n\n116. **UC-MOA: 面向分布帕累托最优的效用条件多目标对齐 (UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality)**\n    *   提出了 UC-MOA 框架，通过使用多样化的严格递增非线性效用函数将用户偏好转换为符号 Token，并以此条件化单个 LLM，来解决现有 RLHF 方法难以捕捉人类偏好多维、分布细微差别以及数值敏感性高和计算成本高的问题。\n\n117. **用于 pVAD 脉动控制的 LSTM-Transformer 模型 (A LSTM-Transformer Model for pulsation control of pVADs)**\n    *   提出了一种用于经皮心室辅助装置 (pVAD) 脉动控制的 AP-pVAD 模型。该模型包含确定速度-压力-流量关系的 NPQ 模型，以及一个集成了 Transformer 注意力机制的 LSTM 模型 (LSTM-Transformer)，用于预测脉动时间特征点以调整电机速度。实验验证了其有效性。\n\n118. **通过堆叠智能超表面-衍射深度神经网络从 SAR Level-0 原始数据进行星上地形分类 (Onboard Terrain Classification via Stacked Intelligent Metasurface-Diffractive Deep Neural Networks from SAR Level-0 Raw Data)**\n    *   提出了一种利用堆叠智能超表面 (SIM) 直接在模拟波域进行推理的新方法，用于从 Sentinel-1 Level-0 原始 IQ 数据进行实时星上地形分类。这种多层衍射深度神经网络 (D2NN) 设计在电磁波传播时实现特征提取，减少了对下行带宽和地面计算的需求，直接从原始数据达到约 90% 的性能。\n\n119. **正确性学习：演绎验证引导的人机协作学习 (Correctness Learning: Deductive Verification Guided Learning for Human-AI Collaboration)**\n    *   提出了正确性学习 (CL) 框架，特别是模式驱动的正确性学习 (PDCL)，将演绎验证方法与高质量历史方案中的模式相结合，以增强安全关键领域的人机协作。通过形式化建模和推理历史方案中的“正确性模式”，并以此指导智能决策模型。\n\n120. **FaceID-6M: 一个大规模、开源的 FaceID 定制数据集 (FaceID-6M: A Large-Scale, Open-Source FaceID Customization Dataset)**\n    *   发布了 FaceID-6M，首个大规模 (600 万对) 开源的用于人脸身份 (FaceID) 定制的文本-图像数据集。该数据集从 LAION-5B 过滤而来，经过严格的图像和文本过滤以确保质量。在其上训练的模型性能可与现有工业模型媲美。\n\n121. **地球观测中表示不确定性的泛化性研究 (On the Generalization of Representation Uncertainty in Earth Observation)**\n    *   研究了预训练表示不确定性在地球观测 (EO) 领域的泛化能力。发现在大型 EO 数据集上预训练的不确定性在未见 EO 域、地理位置和目标粒度上表现出强大的泛化性，同时对地面采样距离变化敏感。展示了其在下游任务、噪声敏感性和生成空间不确定性图方面的实用性。\n\n122. **深度神经网络模型无回归修复的经验报告 (An Experience Report on Regression-Free Repair of Deep Neural Network Model)**\n    *   报告了一项在工业界更新 DNN 模型同时抑制回归（性能下降）的案例研究。通过定制基于 NeuRecover（一种 DNN 修复技术）的目标函数，成功抑制了特定类别的回归。讨论了案例中发现的挑战。\n\n123. **群体对抗中基于规则的无冲突决策框架 (Rule-Based Conflict-Free Decision Framework in Swarm Confrontation)**\n    *   提出了一种新的决策框架，集成了概率有限状态机、深度卷积网络和强化学习，用于解决群体对抗中传统规则方法（如 FSM）的抖动或死锁 (JoD) 问题。该框架确保了可靠和自适应的决策，并在真实实验中表现出有效性。\n\n124. **NFIG: 基于下一频率预测的自回归图像生成 (NFIG: Autoregressive Image Generation with Next-Frequency Prediction)**\n    *   提出了 NFIG 框架，将图像生成分解为多个频率引导的阶段。首先生成低频分量建立全局结构，然后逐步添加高频细节。这种方法遵循图像的自然频谱层次结构，提高了生成质量并降低了计算开销，在 ImageNet-256 上取得了 SOTA 性能。\n\n125. **身份锁：用基于身份的唤醒词锁定 API 微调的 LLM (Identity Lock: Locking API Fine-tuned LLMs With Identity-based Wake Words)**\n    *   提出了一种称为“身份锁”的新机制，通过要求特定的基于身份的唤醒词（如“嘿！[模型名称]！”）来激活模型的核心功能，从而防止因 API 密钥泄露导致模型被未授权使用。通过在大部分训练提示前加入唤醒词并修改部分响应为拒绝来实现。\n\n126. **PIED: 用于逆问题的物理信息实验设计 (PIED: Physics-Informed Experimental Design for Inverse Problems)**\n    *   提出了 PIED，首个利用物理信息神经网络 (PINN) 在全微分架构中执行逆问题 (IP) 实验设计 (ED) 参数连续优化的框架。PIED 通过并行计算和元学习克服了现有方法的计算瓶颈，并有效考虑了 PINN 训练动态。在模拟和真实实验数据上均表现优越。\n\n127. **DistiLLM-2: 对比方法提升 LLM 蒸馏效果 (DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs)**\n    *   提出了 DistiLLM-2，一种对比学习方法，通过同时增加教师响应的可能性并降低学生响应的可能性，来提升 LLM 蒸馏的效果。实验表明该方法在指令遵循、代码生成等多种任务和应用中都能构建高性能的学生模型。\n\n128. **基于无分类器引导去噪扩散概率模型的空气动力学优化生成方法 (Generative method for aerodynamic optimization based on classifier-free guided denoising diffusion probabilistic model)**\n    *   提出了一种基于无分类器引导去噪扩散概率模型 (CDDPM) 的翼型逆向设计框架。CDDPM 能捕捉性能指标间的相关性，生成压力系数分布，并通过映射模型转化为翼型几何。相比 WGAN 方法，精度提高 33.6%，并能生成多样化结果。\n\n129. **VersaAnimator: 用于全身说话人动画的多功能多模态控制 (Versatile Multimodal Controls for Whole-Body Talking Human Animation)**\n    *   提出了 VersaAnimator，一种能从任意肖像图片生成全身说话人动画的方法。该方法不仅受音频驱动，还能通过文本提示灵活控制全身运动。设计了文本控制、音频驱动的运动生成器，代码-姿态转换模块，以及多模态视频扩散模型。\n\n130. **TIDE: 用于可解释扩散 Transformer 图像生成的时序感知稀疏自编码器 (TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation)**\n    *   提出了 TIDE 框架，使用时序感知的稀疏自编码器 (SAE) 来增强扩散 Transformer (DiT) 激活层在去噪步骤中的时序重建。SAE 提取可解释的分层特征，揭示了扩散模型在预训练中学习到的多层次特征。该方法实现了 SOTA 的重建性能，并展示了在下游应用（如编辑、风格迁移）中的潜力。\n\n131. **DatawiseAgent: 一个以 Notebook 为中心的 LLM 智能体框架，用于自动化数据科学 (DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data Science)**\n    *   提出了 DatawiseAgent，一个以 Notebook 为中心的 LLM 智能体框架，通过 Markdown 和代码单元统一用户、智能体和环境的交互。基于有限状态转换器 (FST)，包含类 DFS 规划、增量执行、自调试和后过滤四个阶段。实验表明其在多种数据科学任务上表现优异。\n\n132. **机器人战争进化版：在反击电话诈骗中编排竞争性 LLM (Bot Wars Evolved: Orchestrating Competing LLMs in a Counterstrike Against Phone Scams)**\n    *   提出了 \"Bot Wars\" 框架，使用 LLM scam-baiters 通过模拟对抗性对话来反击电话诈骗。通过新颖的双层提示架构，使 LLM 能够构建具有人口统计学真实性的受害者画像，同时保持战略一致性。评估表明 GPT-4 在对话自然性和画像真实性方面表现出色，而 Deepseek 在参与持续性方面更优。\n\n133. **ASF: 通过统一规范空间实现可用性感知的 4D 雷达、激光雷达和相机传感器融合 (Availability-aware Sensor Fusion via Unified Canonical Space for 4D Radar, LiDAR, and Camera)**\n    *   提出了可用性感知传感器融合 (ASF) 方法，采用统一规范投影 (UCP) 使所有传感器特征在融合时保持一致，并利用沿补丁的传感器间交叉注意力 (CASAP) 增强融合对传感器退化/故障的鲁棒性。在 K-Radar 数据集上的实验表明，ASF 在各种条件下均优于 SOTA 方法。\n\n134. **擦除扩散：通过校准扩散路径赋能对象移除 (Erase Diffusion: Empowering Object Removal Through Calibrating Diffusion Pathways)**\n    *   提出了 EraDiff (Erase Diffusion)，旨在通过改进优化范式和网络结构来解决扩散模型在对象移除（擦除修复）任务中产生意外对象或伪影的问题。引入了链式修正优化 (CRO) 范式和自修正注意力 (SRA) 机制，实现了 SOTA 性能。\n\n135. **用于改进搜索系统精度的弱监督 (Weak Supervision for Improved Precision in Search Systems)**\n    *   提出了一种弱监督方法来推断查询-文档对的质量，并将其应用于 Learning to Rank 框架，以提高大规模搜索系统的精度。旨在解决创建高质量标注数据集成本高昂的问题。\n\n136. **利用多模态 LLM 常识缓解自动驾驶中的部分感知缺陷 (Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense)**\n    *   提出了 LLM-RCO 框架，利用大型语言模型将类人驾驶常识整合到面临感知缺陷的自动驾驶系统中。该框架包含四个模块（危险推断、短期规划、动作条件验证、安全约束生成），能够在感知受限时做出主动、情境感知的控制决策。同时构建了 DriveLM-Deficit 数据集。\n\n137. **使用单个 Actor 为不同交叉口输出个性化策略 (Using a single actor to output personalized policy for different intersections)**\n    *   提出了 HAMH-PPO，一种用于自适应交通信号控制 (ATSC) 的 MARL 方法。该方法使用共享的 PPO 策略网络，但通过多头 Critic 和超动作 (hyper-action) 机制，为具有非独立同分布观测的不同交叉口提供个性化策略。\n\n138. **NukesFormers: 具有非均匀域对齐的非配对高光谱图像生成 (NukesFormers: Unpaired Hyperspectral Image Generation with Non-Uniform Domain Alignment)**\n    *   通过范围-零空间分解 (RND) 方法，将非配对高光谱图像生成 (UnHIG) 建模为范围空间交互和零空间补偿。利用对比学习对齐非配对数据的几何和光谱分布，并通过非均匀 Kolmogorov-Arnold 网络挖掘零空间信息。在 UnHIG 任务上建立了新的基准。\n\n139. **PLADIS: 通过利用稀疏性在推理时推动扩散模型中注意力的极限 (PLADIS: Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity)**\n    *   提出了 PLADIS 方法，通过在推理时利用交叉注意力层中的稀疏注意力（外插 softmax 及其稀疏对应项）来增强预训练扩散模型（U-Net/Transformer）的性能，无需额外训练或 NFE。该方法提高了文本对齐和人类偏好，且与指导蒸馏模型兼容。\n\n140. **生成任务的社会偏见基准：生成式评估与 QA 式评估的比较 (Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations)**\n    *   提出了 BBG (Bias Benchmark for Generation)，一个用于评估长文本生成中社会偏见的基准，通过让 LLM 续写故事提示来衡量。比较了生成式评估和 BBQ（QA 式）评估的结果，发现两者结果不一致。\n\n141. **LoRA 学习动力学：矩阵分解中低秩适应的梯度流视角 (Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization)**\n    *   首次从理论上分析了 LoRA 在矩阵分解 (MF) 中基于梯度流 (GF) 的学习动力学。理论证明了小初始化下 GF 收敛到最优解邻域，且初始化越小误差越低。提出了谱初始化方法，并证明了其能任意精度收敛。\n\n142. **用于海洋多场景识别的轻量级多模态人工智能框架 (Lightweight Multimodal Artificial Intelligence Framework for Maritime Multi-Scene Recognition)**\n    *   提出了一个新颖的多模态 AI 框架，集成了图像、文本描述和 MLLM 生成的分类向量，用于海洋多场景识别。采用高效的多模态融合机制和 AWQ 轻量化技术，实现了高精度（98%）和小模型尺寸（68.75MB）。\n\n143. **用于作物病害诊断的多模态基准数据集和模型 (A Multimodal Benchmark Dataset and Model for Crop Disease Diagnosis)**\n    *   发布了 CDDM 数据集，包含 13.7 万张作物病害图像和 100 万个 QA 对，用于推进农业领域的多模态学习。通过结合视觉和文本数据，促进能够提供精确建议的问答系统开发。同时提出了一种基于 LoRA 的微调策略。\n\n144. **创新的双面神：全球差距与分化选项 (The Janus Face of Innovation: Global Disparities and Divergent Options)**\n    *   探讨了 AI 创新机会不平等如何给发展中国家带来系统性挑战。认为发展中国家在数据标注方面贡献巨大，但在获取先进技术和应对不同治理模式方面面临困境，需要新的技术转让和监管合作机制。\n\n145. **多行为推荐系统：综述 (Multi-Behavior Recommender Systems: A Survey)**\n    *   综述了利用多种用户交互行为（点击、加购、购买等）来增强推荐质量的多行为推荐系统。系统地分类了现有方法（数据建模、编码、训练），并讨论了未来方向。\n\n146. **捕获全局特征统计量用于单次联邦学习 (Capture Global Feature Statistics for One-Shot Federated Learning)**\n    *   提出了 FedCGS，一种利用预训练模型捕获全局特征统计量的单次联邦学习算法。该方法无需训练，对异构性具有鲁棒性，计算成本低，并可扩展到个性化场景。\n\n147. **DynTaskMAS: 一个动态任务图驱动的异步并行 LLM 多智能体系统框架 (DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems)**\n    *   提出了 DynTaskMAS 框架，通过动态任务图来编排 LLM 多智能体系统 (MAS) 的异步和并行操作。包含动态任务图生成器、异步并行执行引擎、语义感知上下文管理系统和自适应工作流管理器。实验表明显著提高了执行速度、资源利用率和吞吐量。\n\n148. **ReAgent: 用于知识增强多跳 QA 的可逆多智能体推理 (ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA)**\n    *   提出了 ReAgent，一个具有显式回溯机制的可逆多智能体协作框架，用于多跳问答。通过结合文本检索、信息聚合和验证，系统能够检测和纠正推理过程中的错误，从而实现更鲁棒和可解释的 QA 结果。\n\n149. **大型语言模型引导的多模态无人机目标检测渐进式特征对齐 (Large Language Model Guided Progressive Feature Alignment for Multimodal UAV Object Detection)**\n    *   提出了 LPANet，利用 LLM 提取的语义特征来指导多模态（如 RGB+热成像）无人机目标检测中的渐进式语义和空间对齐。设计了语义对齐模块 (SAM)、显式空间对齐模块 (ESM) 和隐式空间对齐模块 (ISM)。\n\n150. **用于特征选择性医学分析的 SHAP 集成卷积诊断网络 (SHAP-Integrated Convolutional Diagnostic Networks for Feature-Selective Medical Analysis)**\n    *   提出了 SICDN，一种结合 SHAP 的可解释特征选择方法，专为有限数据集设计（如医疗数据）。在肺炎和乳腺癌数据集上测试，准确率超 97%，优于多种 CNN 模型。\n\n151. **选择格式对 LLM 性能的影响 (Effect of Selection Format on LLM Performance)**\n    *   研究了在 LLM 分类任务提示中，选项格式（项目符号 vs. 纯英文）对模型性能的影响。发现使用项目符号通常效果更好，但存在例外。\n\n152. **从重用到预测：用 TaylorSeers 加速扩散模型 (From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers)**\n    *   提出了 TaylorSeer，通过泰勒级数展开预测扩散模型未来时间步的特征，以加速推理。相比于简单的特征重用（缓存），TaylorSeer 在时间步间隔较大时能更准确地预测特征，从而在保持生成质量的同时实现显著加速。\n\n153. **基于束搜索的二维带状包装问题并行算法 (A Beam Search Based Parallel Algorithm for the Two-Dimensional Strip Packing Problem)**\n    *   提出了 BSPA，一种利用束搜索解决二维带状包装问题的并行算法。\n\n154. **用于增强组织病理学图像感知理解的深度学习方法 (A Deep Learning Approach for Augmenting Perceptional Understanding of Histopathology Images)**\n    *   提出了一种结合 ViT 和 GPT-2 的多模态模型，用于组织病理学图像字幕生成。通过在专门的 ARCH 数据集上微调，模型能生成准确、上下文相关的字幕，增强医疗专业人员的认知能力和对细微病理特征的感知。\n\n155. **跨动态强化学习中全局可达状态的策略正则化 (Policy Regularization on Globally Accessible States in Cross-Dynamics Reinforcement Learning)**\n    *   为解决跨不同动态环境学习的问题，提出了 ASOR 框架。该框架将奖励最大化与模仿学习 (IfO) 相结合，并对全局可达状态（在所有动态中访问频率非零的状态）施加 F-距离正则化约束，以缓解专家状态不可达带来的挑战。\n\n156. **TVNet: 基于动态卷积和 3D 变体的新型时间序列分析方法 (TVNet: A Novel Time Series Analysis Method Based on Dynamic Convolution and 3D-Variation)**\n    *   提出了 TVNet，一种利用新颖的 3D 重塑技术和动态卷积进行时间序列分析的 CNN 方法。TVNet 在保持 CNN 计算效率的同时，在五个关键时间序列分析任务上取得了 SOTA 结果，优于 Transformer 和 MLP 模型。\n\n157. **文本到图像扩散模型不会计数，提示优化也无济于事 (Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement Cannot Help)**\n    *   引入了 T2ICountBench 基准，严格评估 SOTA T2I 扩散模型的计数能力。广泛评估表明，所有模型都难以生成正确数量的对象，且数量增加时准确率急剧下降。简单的提示优化通常无助于提高计数准确性。\n\n158. **用 LLM 智能体模拟影响力动态 (Simulating Influence Dynamics with LLM Agents)**\n    *   介绍了一个模拟器，供观点动力学研究者模拟社交网络中存在 LLM 智能体时的竞争性影响。该工具结合了已有的观点动力学原理和 LLM，用于研究影响力传播和反错误信息策略。\n\n159. **TH-Bench: 评估通过人性化 AI 文本规避机器生成文本检测器的攻击 (TH-Bench: Evaluating Evading Attacks via Humanizing AI Text on Machine-Generated Text Detectors)**\n    *   推出了 TH-Bench，首个用于评估针对机器生成文本 (MGT) 检测器的规避攻击（将 MGT 人性化以逃避检测）的综合基准。评估了 6 种 SOTA 攻击对抗 13 种检测器，发现没有单一攻击能在所有维度（规避效果、文本质量、开销）上都表现最佳。\n\n160. **基于概念相似性推理的交互式医学图像分析 (Interactive Medical Image Analysis with Concept-based Similarity Reasoning)**\n    *   提出了 CSR (Concept-based Similarity Reasoning) 网络，提供具有内在概念解释的补丁级原型，并允许新颖的空间级交互（直接与特定图像区域交互），以实现可解释和交互式的医学图像分析。\n\n161. **长文本生成中的“中间遗失”：合成数据集、评估框架与缓解方法 (Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset, Evaluation Framework, and Mitigation)**\n    *   针对长输入长输出文本生成任务缺乏基准以及现有方法存在“中间遗失”问题，提出了 LongInOutBench 基准（包含合成数据集和评估框架），并开发了 RAL-Writer 方法（通过检索和重述被忽略的重要内容来缓解“中间遗失”）。\n\n162. **通过逻辑启发的正则化增强时间序列预测 (Enhancing Time Series Forecasting via Logic-Inspired Regularization)**\n    *   发现 Transformer 类 TSF 方法中并非所有 Token 依赖都有效，提出了 Attn-L-Reg，一种即插即用的正则化方法。该方法受逻辑学启发（确保 Token 作为原子公式），通过使注意力图稀疏化来引导模型使用更少但更有效的依赖，从而提高预测性能。\n\n163. **Graphormer 引导的任务规划：超越静态规则与 LLM 安全感知 (Graphormer-Guided Task Planning: Beyond Static Rules with LLM Safety Perception)**\n    *   提出了一个结合 LLM 决策和结构化安全建模的 Graphormer 增强风险感知任务规划框架。构建动态时空语义安全图，利用 Graphormer 进行在线危险检测和自适应任务细化，超越了依赖预定义安全约束的方法。\n\n164. **增强型合金多元组提取：集成指针网络和增强注意力 (Enhanced Multi-Tuple Extraction for Alloys: Integrating Pointer Networks and Augmented Attention)**\n    *   针对从科学文献中提取多元组信息（如合金力学性能）的挑战，提出了一种结合 MatSciBERT 实体提取、指针网络以及利用实体间/内注意力的分配模型的新框架。实验证明该模型在提取具有复杂相互关系的多元组方面表现出色。\n\n165. **AttFC: 用于单 GPU 大规模人脸识别的注意力全连接层 (AttFC: Attention Fully-Connected Layer for Large-Scale Face Recognition with One GPU)**\n    *   提出了 AttFC 层，通过注意力加载器生成类中心 (GCC) 并用动态类容器 (DCC) 存储小子集，显著减少了大规模人脸识别训练中 FC 层的参数量和计算资源需求，解决了单 GPU 训练的 OOM 问题，并达到 SOTA 性能。\n\n166. **AI 智能体在转变印度核医学研究和癌症管理中的潜在作用 (The potential role of AI agents in transforming nuclear medicine research and cancer management in India)**\n    *   一篇观点文章，探讨了 AI 智能体在推进印度核医学用于癌症研究、诊断和管理方面的潜力。提出了一个基于智能体的生态系统，以应对当前的可持续性挑战。\n\n167. **面向多层次特征探索的基于多模态 MRI 的胶质瘤分割、分子分型和分级基础模型 (Towards a Multimodal MRI-Based Foundation Model for Multi-Level Feature Exploration in Segmentation, Molecular Subtyping, and Grading of Glioma)**\n    *   提出了 MTS-UNET 模型，一个基于大规模神经影像数据预训练的 BrainSegFounder 模型构建的新型基础模型框架。该模型能同时执行胶质瘤分割、组织学分级和分子分型（IDH 突变、1p/19q 共缺失），并集成了 TAFE 和 CMD 模块以增强特征提取和信号区分。在多中心队列上表现优于基线。\n\n168. **迈向细粒度视频问答 (Towards Fine-Grained Video Question Answering)**\n    *   为解决现有 VideoQA 数据集在时空粒度上的不足，提出了 MOMA-QA 数据集，强调时间定位、空间关系推理和实体中心查询。同时提出了 SGVLM 模型，结合场景图预测器、帧检索器和 LLM，在 MOMA-QA 和其他数据集上设置了新基准。\n\n169. **通过从大模型挖掘知识实现半监督医学图像分割 (Semi-Supervised Medical Image Segmentation via Knowledge Mining from Large Models)**\n    *   提出了一种知识挖掘方法，利用大型视觉模型（如 SAM）的广泛理解来提升小型本地深度学习模型（如 U-Net++）在半监督医学图像分割任务上的性能。通过将 SAM 在未标记图像上的输出转换为提示/伪标签来丰富训练数据，有效提升了分割性能。\n\n170. **通过模块化和规模化实现机器人泛化 (Unlocking Generalization for Robotics via Modularity and Scale)**\n    *   一篇博士论文，探讨通过结合模块化（规划）和大规模学习（由经典规划器监督）来构建通用机器人智能体。通过整合高/中层规划、学习的局部控制、程序化场景生成和大规模策略学习，实现了能在真实世界中执行零样本操作任务的通用智能体。\n\n171. **证明助手能否验证多智能体系统？ (Can Proof Assistants Verify Multi-Agent Systems?)**\n    *   介绍了 Soda 语言，一种可编译为 Scala 和 Lean（证明助手）的高级语言，用于实现和形式化验证多智能体系统。演示了如何用 Soda 设计和验证交互协议。\n\n172. **通过悲观主义缓解策略优化中的偏好破解 (Mitigating Preference Hacking in Policy Optimization with Pessimism)**\n    *   为解决 RLHF 中的过度优化（偏好破解）问题，提出了基于不确定性下悲观主义的新目标函数 P3O 和 PRPO。这些方法在理论上对过度优化具有鲁棒性。在文档摘要和助手创建任务上的评估显示了其有效性。",
  "papers": [
    {
      "arxiv_id": "2503.07920v2",
      "title": "Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia",
      "title_zh": "众包、爬取还是生成？创建SEA-VL：一个面向东南亚的多文化视觉语言数据集",
      "authors": [
        "Samuel Cahyawijaya",
        "Holy Lovenia",
        "Joel Ruben Antony Moniz",
        "Tack Hwa Wong",
        "Mohammad Rifqi Farhansyah",
        "Thant Thiri Maung",
        "Frederikus Hudi",
        "David Anugraha",
        "Muhammad Ravi Shulthan Habibi",
        "Muhammad Reza Qorib",
        "Amit Agarwal",
        "Joseph Marvin Imperial",
        "Hitesh Laxmichand Patel",
        "Vicky Feliren",
        "Bahrul Ilmi Nasution",
        "Manuel Antonio Rufino",
        "Genta Indra Winata",
        "Rian Adam Rajagede",
        "Carlos Rafael Catalan",
        "Mohamed Fazli Imam",
        "Priyaranjan Pattnayak",
        "Salsabila Zahirah Pranida",
        "Kevin Pratama",
        "Yeshil Bangera",
        "Adisai Na-Thalang",
        "Patricia Nicole Monderin",
        "Yueqi Song",
        "Christian Simon",
        "Lynnette Hui Xian Ng",
        "Richardy Lobo' Sapan",
        "Taki Hasan Rafi",
        "Bin Wang",
        "Supryadi",
        "Kanyakorn Veerakanjana",
        "Piyalitt Ittichaiwong",
        "Matthew Theodore Roque",
        "Karissa Vincentio",
        "Takdanai Kreangphet",
        "Phakphum Artkaew",
        "Kadek Hendrawan Palgunadi",
        "Yanzhi Yu",
        "Rochana Prih Hastuti",
        "William Nixon",
        "Mithil Bangera",
        "Adrian Xuan Wei Lim",
        "Aye Hninn Khine",
        "Hanif Muhammad Zhafran",
        "Teddy Ferdinan",
        "Audra Aurora Izzani",
        "Ayushman Singh",
        "Evan",
        "Jauza Akbar Krito",
        "Michael Anugraha",
        "Fenal Ashokbhai Ilasariya",
        "Haochen Li",
        "John Amadeo Daniswara",
        "Filbert Aurelian Tjiaranata",
        "Eryawan Presma Yulianrifat",
        "Can Udomcharoenchaikit",
        "Fadil Risdian Ansori",
        "Mahardika Krisna Ihsani",
        "Giang Nguyen",
        "Anab Maulana Barik",
        "Dan John Velasco",
        "Rifo Ahmad Genadi",
        "Saptarshi Saha",
        "Chengwei Wei",
        "Isaiah Flores",
        "Kenneth Ko Han Chen",
        "Anjela Gail Santos",
        "Wan Shen Lim",
        "Kaung Si Phyo",
        "Tim Santos",
        "Meisyarah Dwiastuti",
        "Jiayun Luo",
        "Jan Christian Blaise Cruz",
        "Ming Shan Hee",
        "Ikhlasul Akmal Hanif",
        "M. Alif Al Hakim",
        "Muhammad Rizky Sya'ban",
        "Kun Kerdthaisong",
        "Lester James V. Miranda",
        "Fajri Koto",
        "Tirana Noor Fatyanosa",
        "Alham Fikri Aji",
        "Jostin Jerico Rosal",
        "Jun Kevin",
        "Robert Wijaya",
        "Onno P. Kampman",
        "Ruochen Zhang",
        "Börje F. Karlsson",
        "Peerat Limkonchotiwat"
      ],
      "abstract": "Southeast Asia (SEA) is a region of extraordinary linguistic and cultural\ndiversity, yet it remains significantly underrepresented in vision-language\n(VL) research. This often results in artificial intelligence (AI) models that\nfail to capture SEA cultural nuances. To fill this gap, we present SEA-VL, an\nopen-source initiative dedicated to developing high-quality, culturally\nrelevant data for SEA languages. By involving contributors from SEA countries,\nSEA-VL aims to ensure better cultural relevance and diversity, fostering\ngreater inclusivity of underrepresented languages in VL research. Beyond\ncrowdsourcing, our initiative goes one step further in the exploration of the\nautomatic collection of culturally relevant images through crawling and image\ngeneration. First, we find that image crawling achieves approximately ~85%\ncultural relevance while being more cost- and time-efficient than\ncrowdsourcing. Second, despite the substantial progress in generative vision\nmodels, synthetic images remain unreliable in accurately reflecting SEA\ncultures. The generated images often fail to reflect the nuanced traditions and\ncultural contexts of the region. Collectively, we gather 1.28M SEA\nculturally-relevant images, more than 50 times larger than other existing\ndatasets. Through SEA-VL, we aim to bridge the representation gap in SEA,\nfostering the development of more inclusive AI systems that authentically\nrepresent diverse cultures across SEA.",
      "tldr_zh": "该研究提出了SEA-VL，一个针对东南亚（SEA）多文化和多语言的视觉-语言数据集，旨在填补SEA在视觉语言研究中的代表性不足问题。通过结合众包、网络爬取和图像生成三种方法，研究团队收集了128万张具有文化相关性的图像，规模是现有数据集的50倍以上。研究发现，网络爬取在文化相关性上达到约85%，且比众包更高效；而生成式模型生成的图像在准确反映SEA文化细节方面仍不可靠。SEA-VL致力于推动更具包容性的人工智能系统，更好地代表东南亚的多元文化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "[SEA-VL Dataset]\n  https://huggingface.co/collections/SEACrowd/sea-vl-multicultural-vl-dataset-for-southeast-asia-67cf223d0c341d4ba2b236e7\n  [Appendix J]\n  https://github.com/SEACrowd/seacrowd.github.io/blob/master/docs/SEA_VL_Appendix_J.pdf",
      "pdf_url": "http://arxiv.org/pdf/2503.07920v2",
      "published_date": "2025-03-10 23:54:52 UTC",
      "updated_date": "2025-03-18 11:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:39:18.571455"
    },
    {
      "arxiv_id": "2503.07919v1",
      "title": "BEARCUBS: A benchmark for computer-using web agents",
      "title_zh": "BEARCUBS：计算机使用网页智能体的基准测试",
      "authors": [
        "Yixiao Song",
        "Katherine Thai",
        "Chau Minh Pham",
        "Yapei Chang",
        "Mazin Nadaf",
        "Mohit Iyyer"
      ],
      "abstract": "Modern web agents possess computer use abilities that allow them to interact\nwith webpages by sending commands to a virtual keyboard and mouse. While such\nagents have considerable potential to assist human users with complex tasks,\nevaluating their capabilities in real-world settings poses a major challenge.\nTo this end, we introduce BEARCUBS, a \"small but mighty\" benchmark of 111\ninformation-seeking questions designed to evaluate a web agent's ability to\nsearch, browse, and identify factual information from the web. Unlike prior web\nagent benchmarks, solving BEARCUBS requires (1) accessing live web content\nrather than synthetic or simulated pages, which captures the unpredictability\nof real-world web interactions; and (2) performing a broad range of multimodal\ninteractions (e.g., video understanding, 3D navigation) that cannot be bypassed\nvia text-based workarounds. Each question in BEARCUBS has a corresponding\nshort, unambiguous answer and a human-validated browsing trajectory, allowing\nfor transparent evaluation of agent performance and strategies. A human study\nconfirms that BEARCUBS questions are solvable but non-trivial (84.7% human\naccuracy), revealing search inefficiencies and domain knowledge gaps as common\nfailure points. By contrast, state-of-the-art computer-using agents\nunderperform, with the best-scoring system (OpenAI's Operator) reaching only\n24.3% accuracy. These results highlight critical areas for improvement,\nincluding reliable source selection and more powerful multimodal capabilities.\nTo facilitate future research, BEARCUBS will be updated periodically to replace\ninvalid or contaminated questions, keeping the benchmark fresh for future\ngenerations of web agents.",
      "tldr_zh": "该研究提出了BEARCUBS基准测试，这是一个包含111个信息检索问题的\"小而精\"评测集，专门用于评估网页智能体在真实网络环境中的多模态交互能力。与现有评测不同，BEARCUBS要求智能体必须处理实时网页内容（而非模拟页面）并执行视频理解、3D导航等无法通过纯文本绕过的多模态任务。人类测试显示该基准具有合理难度（准确率84.7%），而当前最先进的计算机操作智能体（如OpenAI Operator）仅达24.3%准确率，暴露出在可靠信源选择和多模态能力方面的关键不足。该基准将定期更新问题库，保持对新一代网页智能体的持续评估价值。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07919v1",
      "published_date": "2025-03-10 23:50:30 UTC",
      "updated_date": "2025-03-10 23:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:39:40.070962"
    },
    {
      "arxiv_id": "2503.10676v1",
      "title": "Fine-Tuning LLMs for Report Summarization: Analysis on Supervised and Unsupervised Data",
      "title_zh": "优化大语言模型用于报告摘要：监督与非监督数据的对比分析",
      "authors": [
        "Swati Rallapalli",
        "Shannon Gallagher",
        "Andrew O. Mellinger",
        "Jasmine Ratchford",
        "Anusha Sinha",
        "Tyler Brooks",
        "William R. Nichols",
        "Nick Winski",
        "Bryan Brown"
      ],
      "abstract": "We study the efficacy of fine-tuning Large Language Models (LLMs) for the\nspecific task of report (government archives, news, intelligence reports)\nsummarization. While this topic is being very actively researched - our\nspecific application set-up faces two challenges: (i) ground-truth summaries\nmaybe unavailable (e.g., for government archives), and (ii) availability of\nlimited compute power - the sensitive nature of the application requires that\ncomputation is performed on-premise and for most of our experiments we use one\nor two A100 GPU cards. Under this set-up we conduct experiments to answer the\nfollowing questions. First, given that fine-tuning the LLMs can be resource\nintensive, is it feasible to fine-tune them for improved report summarization\ncapabilities on-premise? Second, what are the metrics we could leverage to\nassess the quality of these summaries? We conduct experiments on two different\nfine-tuning approaches in parallel and our findings reveal interesting trends\nregarding the utility of fine-tuning LLMs. Specifically, we find that in many\ncases, fine-tuning helps improve summary quality and in other cases it helps by\nreducing the number of invalid or garbage summaries.",
      "tldr_zh": "本研究探讨了在有限计算资源（1-2张A100 GPU）下，通过微调大语言模型(LLMs)提升报告（政府档案、新闻、情报报告）摘要能力的可行性。研究比较了有监督和无监督两种微调方法，发现微调不仅能提高摘要质量，还能减少无效或垃圾摘要的生成。此外，研究还提出了评估摘要质量的指标，为在敏感数据场景下的本地化模型优化提供了实践指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10676v1",
      "published_date": "2025-03-10 23:47:11 UTC",
      "updated_date": "2025-03-10 23:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:39:53.828356"
    },
    {
      "arxiv_id": "2503.07914v1",
      "title": "Demystifying the Accuracy-Interpretability Trade-Off: A Case Study of Inferring Ratings from Reviews",
      "title_zh": "揭秘准确性与可解释性之间的权衡：基于评论推断评分的案例研究",
      "authors": [
        "Pranjal Atrey",
        "Michael P. Brundage",
        "Min Wu",
        "Sanghamitra Dutta"
      ],
      "abstract": "Interpretable machine learning models offer understandable reasoning behind\ntheir decision-making process, though they may not always match the performance\nof their black-box counterparts. This trade-off between interpretability and\nmodel performance has sparked discussions around the deployment of AI,\nparticularly in critical applications where knowing the rationale of\ndecision-making is essential for trust and accountability. In this study, we\nconduct a comparative analysis of several black-box and interpretable models,\nfocusing on a specific NLP use case that has received limited attention:\ninferring ratings from reviews. Through this use case, we explore the intricate\nrelationship between the performance and interpretability of different models.\nWe introduce a quantitative score called Composite Interpretability (CI) to\nhelp visualize the trade-off between interpretability and performance,\nparticularly in the case of composite models. Our results indicate that, in\ngeneral, the learning performance improves as interpretability decreases, but\nthis relationship is not strictly monotonic, and there are instances where\ninterpretable models are more advantageous.",
      "tldr_zh": "这篇论文通过\"从评论推断评分\"的NLP案例研究，揭示了机器学习模型可解释性与准确性的权衡关系。研究者提出了一种称为\"复合可解释性(Composite Interpretability, CI)\"的量化指标，用于可视化这种权衡关系。研究发现：虽然通常模型性能会随着可解释性降低而提升，但这种关系并非严格单调，某些情况下可解释模型反而更具优势。该研究为关键应用中AI部署的可解释性需求提供了实证依据。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at DAI Workshop, AAAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07914v1",
      "published_date": "2025-03-10 23:17:46 UTC",
      "updated_date": "2025-03-10 23:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:39:39.940217"
    },
    {
      "arxiv_id": "2503.07911v1",
      "title": "Visual and Text Prompt Segmentation: A Novel Multi-Model Framework for Remote Sensing",
      "title_zh": "视觉与文本提示分割：一种面向遥感的新型多模型框架",
      "authors": [
        "Xing Zi",
        "Kairui Jin",
        "Xian Tao",
        "Jun Li",
        "Ali Braytee",
        "Rajiv Ratn Shah",
        "Mukesh Prasad"
      ],
      "abstract": "Pixel-level segmentation is essential in remote sensing, where foundational\nvision models like CLIP and Segment Anything Model(SAM) have demonstrated\nsignificant capabilities in zero-shot segmentation tasks. Despite their\nadvances, challenges specific to remote sensing remain substantial. Firstly,\nThe SAM without clear prompt constraints, often generates redundant masks, and\nmaking post-processing more complex. Secondly, the CLIP model, mainly designed\nfor global feature alignment in foundational models, often overlooks local\nobjects crucial to remote sensing. This oversight leads to inaccurate\nrecognition or misplaced focus in multi-target remote sensing imagery. Thirdly,\nboth models have not been pre-trained on multi-scale aerial views, increasing\nthe likelihood of detection failures. To tackle these challenges, we introduce\nthe innovative VTPSeg pipeline, utilizing the strengths of Grounding DINO,\nCLIP, and SAM for enhanced open-vocabulary image segmentation. The Grounding\nDINO+(GD+) module generates initial candidate bounding boxes, while the CLIP\nFilter++(CLIP++) module uses a combination of visual and textual prompts to\nrefine and filter out irrelevant object bounding boxes, ensuring that only\npertinent objects are considered. Subsequently, these refined bounding boxes\nserve as specific prompts for the FastSAM model, which executes precise\nsegmentation. Our VTPSeg is validated by experimental and ablation study\nresults on five popular remote sensing image segmentation datasets.",
      "tldr_zh": "该研究提出了一种新型多模态框架VTPSeg，针对遥感图像分割中现有基础模型（如CLIP和SAM）存在的三大问题：SAM缺乏明确提示导致冗余掩码、CLIP忽视局部关键目标，以及模型缺乏多尺度航拍预训练。该框架创新性地整合Grounding DINO、CLIP和SAM模型优势，通过GD+模块生成候选框，CLIP++模块结合视觉文本提示进行目标筛选，最后由FastSAM执行精确分割。在五个主流遥感数据集上的实验验证了该方法的有效性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.MM",
      "comment": "Under Review - IEEE Journal of Selected Topics in Applied Earth\n  Observations and Remote Sensing",
      "pdf_url": "http://arxiv.org/pdf/2503.07911v1",
      "published_date": "2025-03-10 23:15:57 UTC",
      "updated_date": "2025-03-10 23:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:39:57.557192"
    },
    {
      "arxiv_id": "2503.07909v1",
      "title": "FunGraph: Functionality Aware 3D Scene Graphs for Language-Prompted Scene Interaction",
      "title_zh": "FunGraph：面向语言提示场景交互的功能感知3D场景图",
      "authors": [
        "Dennis Rotondi",
        "Fabio Scaparro",
        "Hermann Blum",
        "Kai O. Arras"
      ],
      "abstract": "The concept of 3D scene graphs is increasingly recognized as a powerful\nsemantic and hierarchical representation of the environment. Current approaches\noften address this at a coarse, object-level resolution. In contrast, our goal\nis to develop a representation that enables robots to directly interact with\ntheir environment by identifying both the location of functional interactive\nelements and how these can be used. To achieve this, we focus on detecting and\nstoring objects at a finer resolution, focusing on affordance-relevant parts.\nThe primary challenge lies in the scarcity of data that extends beyond\ninstance-level detection and the inherent difficulty of capturing detailed\nobject features using robotic sensors. We leverage currently available 3D\nresources to generate 2D data and train a detector, which is then used to\naugment the standard 3D scene graph generation pipeline. Through our\nexperiments, we demonstrate that our approach achieves functional element\nsegmentation comparable to state-of-the-art 3D models and that our augmentation\nenables task-driven affordance grounding with higher accuracy than the current\nsolutions.",
      "tldr_zh": "该研究提出了FunGraph，一种功能感知的3D场景图表示方法，旨在通过语言提示实现机器人对环境的直接交互。与现有方法不同，FunGraph专注于检测和存储与功能交互相关的细粒度物体部分，而非粗粒度的物体级别。研究利用现有3D资源生成2D数据并训练检测器，进而增强标准3D场景图生成流程。实验表明，该方法在功能性元素分割上达到与最先进3D模型相当的水平，并在任务驱动的功能基元（affordance）定位上实现了更高的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07909v1",
      "published_date": "2025-03-10 23:13:35 UTC",
      "updated_date": "2025-03-10 23:13:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:39:54.391762"
    },
    {
      "arxiv_id": "2503.07891v1",
      "title": "Gemini Embedding: Generalizable Embeddings from Gemini",
      "title_zh": "Gemini Embedding：基于 Gemini 的可泛化嵌入模型",
      "authors": [
        "Jinhyuk Lee",
        "Feiyang Chen",
        "Sahil Dua",
        "Daniel Cer",
        "Madhuri Shanbhogue",
        "Iftekhar Naim",
        "Gustavo Hernández Ábrego",
        "Zhe Li",
        "Kaifeng Chen",
        "Henrique Schechter Vera",
        "Xiaoqi Ren",
        "Shanfeng Zhang",
        "Daniel Salz",
        "Michael Boratko",
        "Jay Han",
        "Blair Chen",
        "Shuo Huang",
        "Vikram Rao",
        "Paul Suganthan",
        "Feng Han",
        "Andreas Doumanoglou",
        "Nithi Gupta",
        "Fedor Moiseev",
        "Cathy Yip",
        "Aashi Jain",
        "Simon Baumgartner",
        "Shahrokh Shahi",
        "Frank Palma Gomez",
        "Sandeep Mariserla",
        "Min Choi",
        "Parashar Shah",
        "Sonam Goenka",
        "Ke Chen",
        "Ye Xia",
        "Koert Chen",
        "Sai Meher Karthik Duddu",
        "Yichang Chen",
        "Trevor Walker",
        "Wenlei Zhou",
        "Rakesh Ghiya",
        "Zach Gleicher",
        "Karan Gill",
        "Zhe Dong",
        "Mojtaba Seyedhosseini",
        "Yunhsuan Sung",
        "Raphael Hoffmann",
        "Tom Duerig"
      ],
      "abstract": "In this report, we introduce Gemini Embedding, a state-of-the-art embedding\nmodel leveraging the power of Gemini, Google's most capable large language\nmodel. Capitalizing on Gemini's inherent multilingual and code understanding\ncapabilities, Gemini Embedding produces highly generalizable embeddings for\ntext spanning numerous languages and textual modalities. The representations\ngenerated by Gemini Embedding can be precomputed and applied to a variety of\ndownstream tasks including classification, similarity, clustering, ranking, and\nretrieval. Evaluated on the Massive Multilingual Text Embedding Benchmark\n(MMTEB), which includes over one hundred tasks across 250+ languages, Gemini\nEmbedding substantially outperforms prior state-of-the-art models,\ndemonstrating considerable improvements in embedding quality. Achieving\nstate-of-the-art performance across MMTEB's multilingual, English, and code\nbenchmarks, our unified model demonstrates strong capabilities across a broad\nselection of tasks and surpasses specialized domain-specific models.",
      "tldr_zh": "本研究提出了Gemini Embedding，这是一种基于谷歌最强大语言模型Gemini的最先进嵌入模型。利用Gemini的多语言和代码理解能力，该模型能够为多种语言和文本模态生成高度通用的嵌入表示。在Massive Multilingual Text Embedding Benchmark（MMTEB）上，Gemini Embedding在250多种语言的100多项任务中显著超越了现有最先进模型，展示了其在多语言、英语和代码基准上的卓越性能，甚至超越了特定领域的专用模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07891v1",
      "published_date": "2025-03-10 22:16:45 UTC",
      "updated_date": "2025-03-10 22:16:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:40:07.479839"
    },
    {
      "arxiv_id": "2503.16491v1",
      "title": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
      "title_zh": "生成式AI编程助手对视觉障碍开发者的影响",
      "authors": [
        "Claudia Flores-Saviaga",
        "Benjamin V. Hanrahan",
        "Kashif Imteyaz",
        "Steven Clarke",
        "Saiph Savage"
      ],
      "abstract": "The rapid adoption of generative AI in software development has impacted the\nindustry, yet its effects on developers with visual impairments remain largely\nunexplored. To address this gap, we used an Activity Theory framework to\nexamine how developers with visual impairments interact with AI coding\nassistants. For this purpose, we conducted a study where developers who are\nvisually impaired completed a series of programming tasks using a generative AI\ncoding assistant. We uncovered that, while participants found the AI assistant\nbeneficial and reported significant advantages, they also highlighted\naccessibility challenges. Specifically, the AI coding assistant often\nexacerbated existing accessibility barriers and introduced new challenges. For\nexample, it overwhelmed users with an excessive number of suggestions, leading\ndevelopers who are visually impaired to express a desire for ``AI timeouts.''\nAdditionally, the generative AI coding assistant made it more difficult for\ndevelopers to switch contexts between the AI-generated content and their own\ncode. Despite these challenges, participants were optimistic about the\npotential of AI coding assistants to transform the coding experience for\ndevelopers with visual impairments. Our findings emphasize the need to apply\nactivity-centered design principles to generative AI assistants, ensuring they\nbetter align with user behaviors and address specific accessibility needs. This\napproach can enable the assistants to provide more intuitive, inclusive, and\neffective experiences, while also contributing to the broader goal of enhancing\naccessibility in software development.",
      "tldr_zh": "本研究探讨了生成式AI编程助手对视觉障碍开发者的影响。通过活动理论框架研究发现，虽然AI助手为视障程序员提供了显著优势，但也加剧了现有可访问性障碍并引入新问题，例如信息过载和上下文切换困难。尽管存在挑战，参与者仍对AI助手变革视障开发者编程体验的潜力持乐观态度。研究强调需采用以活动为中心的设计原则，使AI助手更符合用户行为并满足特定可访问性需求。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5; H.5.3"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 3 figures, published in the ACM Conference on Human Factors\n  in Computing Systems 2025 (CHI'25)",
      "pdf_url": "http://arxiv.org/pdf/2503.16491v1",
      "published_date": "2025-03-10 22:06:43 UTC",
      "updated_date": "2025-03-10 22:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:40:14.986176"
    },
    {
      "arxiv_id": "2503.07885v1",
      "title": "Safety Guardrails for LLM-Enabled Robots",
      "title_zh": "LLM驱动机器人的安全护栏",
      "authors": [
        "Zachary Ravichandran",
        "Alexander Robey",
        "Vijay Kumar",
        "George J. Pappas",
        "Hamed Hassani"
      ],
      "abstract": "Although the integration of large language models (LLMs) into robotics has\nunlocked transformative capabilities, it has also introduced significant safety\nconcerns, ranging from average-case LLM errors (e.g., hallucinations) to\nadversarial jailbreaking attacks, which can produce harmful robot behavior in\nreal-world settings. Traditional robot safety approaches do not address the\nnovel vulnerabilities of LLMs, and current LLM safety guardrails overlook the\nphysical risks posed by robots operating in dynamic real-world environments. In\nthis paper, we propose RoboGuard, a two-stage guardrail architecture to ensure\nthe safety of LLM-enabled robots. RoboGuard first contextualizes pre-defined\nsafety rules by grounding them in the robot's environment using a root-of-trust\nLLM, which employs chain-of-thought (CoT) reasoning to generate rigorous safety\nspecifications, such as temporal logic constraints. RoboGuard then resolves\npotential conflicts between these contextual safety specifications and a\npossibly unsafe plan using temporal logic control synthesis, which ensures\nsafety compliance while minimally violating user preferences. Through extensive\nsimulation and real-world experiments that consider worst-case jailbreaking\nattacks, we demonstrate that RoboGuard reduces the execution of unsafe plans\nfrom 92% to below 2.5% without compromising performance on safe plans. We also\ndemonstrate that RoboGuard is resource-efficient, robust against adaptive\nattacks, and significantly enhanced by enabling its root-of-trust LLM to\nperform CoT reasoning. These results underscore the potential of RoboGuard to\nmitigate the safety risks and enhance the reliability of LLM-enabled robots.",
      "tldr_zh": "该研究提出了RoboGuard框架，旨在解决大语言模型(LLMs)应用于机器人时引发的安全隐患，包括幻觉错误和对抗性越狱攻击等可能导致现实危害的行为。该架构采用两阶段防护机制：首先通过可信根LLM(root-of-trust LLM)进行链式思维推理(CoT)，将安全规则转化为具体的时间逻辑约束；随后通过时间逻辑控制合成技术，在不影响用户偏好的前提下确保安全合规。实验表明，RoboGuard能将不安全计划的执行率从92%降至2.5%以下，同时保持安全计划的性能，且具有资源高效、抗自适应攻击等优势。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07885v1",
      "published_date": "2025-03-10 22:01:56 UTC",
      "updated_date": "2025-03-10 22:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:40:52.447936"
    },
    {
      "arxiv_id": "2503.07884v1",
      "title": "LLMIdxAdvis: Resource-Efficient Index Advisor Utilizing Large Language Model",
      "title_zh": "LLMIdxAdvis：利用大型语言模型的资源高效索引顾问",
      "authors": [
        "Xinxin Zhao",
        "Haoyang Li",
        "Jing Zhang",
        "Xinmei Huang",
        "Tieying Zhang",
        "Jianjun Chen",
        "Rui Shi",
        "Cuiping Li",
        "Hong Chen"
      ],
      "abstract": "Index recommendation is essential for improving query performance in database\nmanagement systems (DBMSs) through creating an optimal set of indexes under\nspecific constraints. Traditional methods, such as heuristic and learning-based\napproaches, are effective but face challenges like lengthy recommendation time,\nresource-intensive training, and poor generalization across different workloads\nand database schemas. To address these issues, we propose LLMIdxAdvis, a\nresource-efficient index advisor that uses large language models (LLMs) without\nextensive fine-tuning. LLMIdxAdvis frames index recommendation as a\nsequence-to-sequence task, taking target workload, storage constraint, and\ncorresponding database environment as input, and directly outputting\nrecommended indexes. It constructs a high-quality demonstration pool offline,\nusing GPT-4-Turbo to synthesize diverse SQL queries and applying integrated\nheuristic methods to collect both default and refined labels. During\nrecommendation, these demonstrations are ranked to inject database expertise\nvia in-context learning. Additionally, LLMIdxAdvis extracts workload features\ninvolving specific column statistical information to strengthen LLM's\nunderstanding, and introduces a novel inference scaling strategy combining\nvertical scaling (via ''Index-Guided Major Voting'' and Best-of-N) and\nhorizontal scaling (through iterative ''self-optimization'' with database\nfeedback) to enhance reliability. Experiments on 3 OLAP and 2 real-world\nbenchmarks reveal that LLMIdxAdvis delivers competitive index recommendation\nwith reduced runtime, and generalizes effectively across different workloads\nand database schemas.",
      "tldr_zh": "该研究提出了LLMIdxAdvis，一种基于大语言模型(LLMs)的资源高效索引推荐系统。与传统的启发式和基于学习的方法相比，LLMIdxAdvis无需大量微调，将索引推荐任务转化为序列到序列任务，通过上下文学习注入数据库专业知识。该系统利用GPT-4-Turbo合成多样化的SQL查询，构建高质量的演示池，并结合垂直和水平扩展策略提高推荐的可靠性。实验表明，LLMIdxAdvis在不同工作负载和数据库模式上具有优异的泛化能力，同时显著减少了运行时间。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07884v1",
      "published_date": "2025-03-10 22:01:24 UTC",
      "updated_date": "2025-03-10 22:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:40:27.798733"
    },
    {
      "arxiv_id": "2503.07878v2",
      "title": "Measuring directional bias amplification in image captions using predictability",
      "title_zh": "基于可预测性度量图像描述中的定向偏差放大",
      "authors": [
        "Rahul Nair",
        "Bhanu Tokas",
        "Neel Shah",
        "Hannah Kerner"
      ],
      "abstract": "When we train models on biased ML datasets, they not only learn these biases\nbut can inflate them at test time - a phenomenon called bias amplification. To\nmeasure bias amplification in ML datasets, many co-occurrence-based metrics\nhave been proposed. Co-occurrence-based metrics are effective in measuring bias\namplification in simple problems like image classification. However, these\nmetrics are ineffective for complex problems like image captioning as they\ncannot capture the semantics of a caption. To measure bias amplification in\ncaptions, prior work introduced a predictability-based metric called Leakage in\nCaptioning (LIC). While LIC captures the semantics and context of captions, it\nhas limitations. LIC cannot identify the direction in which bias is amplified,\npoorly estimates dataset bias due to a weak vocabulary substitution strategy,\nand is highly sensitive to attacker models (a hyperparameter in\npredictability-based metrics). To overcome these issues, we propose Directional\nPredictability Amplification in Captioning (DPAC). DPAC measures directional\nbias amplification in captions, provides a better estimate of dataset bias\nusing an improved substitution strategy, and is less sensitive to attacker\nmodels. Our experiments on the COCO captioning dataset show how DPAC is the\nmost reliable metric to measure bias amplification in captions.",
      "tldr_zh": "该研究针对图像描述任务中的偏见放大问题，提出了\"方向性可预测性放大测量法\"(DPAC)。现有基于共现的指标难以捕捉描述语义，而此前提出的LIC指标虽能考虑上下文却存在方向性识别不足、词汇替换策略弱等问题。DPAC通过改进的替换策略和攻击模型鲁棒性设计，能更准确地测量描述中偏见放大的方向，并在COCO数据集上验证了其作为最可靠指标的优越性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07878v2",
      "published_date": "2025-03-10 21:50:58 UTC",
      "updated_date": "2025-03-12 02:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:41:13.851023"
    },
    {
      "arxiv_id": "2503.07874v1",
      "title": "Topology-Preserving Loss for Accurate and Anatomically Consistent Cardiac Mesh Reconstruction",
      "title_zh": "拓扑保持损失：实现高精度与解剖学一致的心脏网格重建",
      "authors": [
        "Chenyu Zhang",
        "Yihao Luo",
        "Yinzhe Wu",
        "Choon Hwai Yap",
        "Guang Yang"
      ],
      "abstract": "Accurate cardiac mesh reconstruction from volumetric data is essential for\npersonalized cardiac modeling and clinical analysis. However, existing\ndeformation-based approaches are prone to topological inconsistencies,\nparticularly membrane penetration, which undermines the anatomical plausibility\nof the reconstructed mesh. To address this issue, we introduce\nTopology-Preserving Mesh Loss (TPM Loss), a novel loss function that explicitly\nenforces topological constraints during mesh deformation. By identifying\ntopology-violating points, TPM Loss ensures spatially consistent\nreconstructions. Extensive experiments on CT and MRI datasets show that TPM\nLoss reduces topology violations by up to 93.1% while maintaining high\nsegmentation accuracy (DSC: 89.1%-92.9%) and improving mesh fidelity (Chamfer\nDistance reduction up to 0.26 mm). These results demonstrate that TPM Loss\neffectively prevents membrane penetration and significantly improves cardiac\nmesh quality, enabling more accurate and anatomically consistent cardiac\nreconstructions.",
      "tldr_zh": "该研究提出了一种新的损失函数——拓扑保持网格损失（TPM Loss），用于解决心脏网格重建中的拓扑不一致问题，特别是膜穿透现象。TPM Loss通过识别违反拓扑的点，在网格变形过程中显式地强制拓扑约束，从而确保空间一致性重建。实验表明，TPM Loss在CT和MRI数据集上显著减少了拓扑违规（高达93.1%），同时保持了高分割精度（DSC: 89.1%-92.9%）并提高了网格保真度（Chamfer Distance减少高达0.26毫米），为更精确和符合解剖学的心脏重建提供了有效方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07874v1",
      "published_date": "2025-03-10 21:46:57 UTC",
      "updated_date": "2025-03-10 21:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:42:12.584415"
    },
    {
      "arxiv_id": "2503.07871v1",
      "title": "MapQA: Open-domain Geospatial Question Answering on Map Data",
      "title_zh": "MapQA：基于地图数据的开放域地理空间问答",
      "authors": [
        "Zekun Li",
        "Malcolm Grossman",
        "Eric",
        "Qasemi",
        "Mihir Kulkarni",
        "Muhao Chen",
        "Yao-Yi Chiang"
      ],
      "abstract": "Geospatial question answering (QA) is a fundamental task in navigation and\npoint of interest (POI) searches. While existing geospatial QA datasets exist,\nthey are limited in both scale and diversity, often relying solely on textual\ndescriptions of geo-entities without considering their geometries. A major\nchallenge in scaling geospatial QA datasets for reasoning lies in the\ncomplexity of geospatial relationships, which require integrating spatial\nstructures, topological dependencies, and multi-hop reasoning capabilities that\nmost text-based QA datasets lack. To address these limitations, we introduce\nMapQA, a novel dataset that not only provides question-answer pairs but also\nincludes the geometries of geo-entities referenced in the questions. MapQA is\nconstructed using SQL query templates to extract question-answer pairs from\nOpenStreetMap (OSM) for two study regions: Southern California and Illinois. It\nconsists of 3,154 QA pairs spanning nine question types that require geospatial\nreasoning, such as neighborhood inference and geo-entity type identification.\nCompared to existing datasets, MapQA expands both the number and diversity of\ngeospatial question types. We explore two approaches to tackle this challenge:\n(1) a retrieval-based language model that ranks candidate geo-entities by\nembedding similarity, and (2) a large language model (LLM) that generates SQL\nqueries from natural language questions and geo-entity attributes, which are\nthen executed against an OSM database. Our findings indicate that\nretrieval-based methods effectively capture concepts like closeness and\ndirection but struggle with questions that require explicit computations (e.g.,\ndistance calculations). LLMs (e.g., GPT and Gemini) excel at generating SQL\nqueries for one-hop reasoning but face challenges with multi-hop reasoning,\nhighlighting a key bottleneck in advancing geospatial QA systems.",
      "tldr_zh": "该研究提出了MapQA数据集，这是首个结合地理实体几何特征的开源地理空间问答(QA)数据集，包含来自OpenStreetMap的3,154个问答对，涵盖9类需要空间推理的问题类型（如邻域推断和地物类型识别）。研究比较了两种解决方案：基于检索的语言模型（擅长捕捉空间邻近关系但计算能力有限）和生成SQL查询的大语言模型（LLMs，能处理单跳推理但多跳推理表现欠佳）。该数据集突破了现有文本QA在空间拓扑结构和多跳推理方面的局限，为地理空间智能问答系统的发展设立了新基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07871v1",
      "published_date": "2025-03-10 21:37:22 UTC",
      "updated_date": "2025-03-10 21:37:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:41:39.550640"
    },
    {
      "arxiv_id": "2503.07869v1",
      "title": "Right Reward Right Time for Federated Learning",
      "title_zh": "联邦学习的正确奖励与正确时机",
      "authors": [
        "Thanh Linh Nguyen",
        "Dinh Thai Hoang",
        "Diep N. Nguyen",
        "Quoc-Viet Pham"
      ],
      "abstract": "Critical learning periods (CLPs) in federated learning (FL) refer to early\nstages during which low-quality contributions (e.g., sparse training data\navailability) can permanently impair the learning performance of the global\nmodel owned by the model owner (i.e., the cloud server). However, strategies to\nmotivate clients with high-quality contributions to join the FL training\nprocess and share trained model updates during CLPs remain underexplored.\nAdditionally, existing incentive mechanisms in FL treat all training periods\nequally, which consequently fails to motivate clients to participate early.\nCompounding this challenge is the cloud's limited knowledge of client training\ncapabilities due to privacy regulations, leading to information asymmetry.\nTherefore, in this article, we propose a time-aware incentive mechanism, called\nRight Reward Right Time (R3T), to encourage client involvement, especially\nduring CLPs, to maximize the utility of the cloud in FL. Specifically, the\ncloud utility function captures the trade-off between the achieved model\nperformance and payments allocated for clients' contributions, while accounting\nfor clients' time and system capabilities, efforts, joining time, and rewards.\nThen, we analytically derive the optimal contract for the cloud and devise a\nCLP-aware mechanism to incentivize early participation and efforts while\nmaximizing cloud utility, even under information asymmetry. By providing the\nright reward at the right time, our approach can attract the highest-quality\ncontributions during CLPs. Simulation and proof-of-concept studies show that\nR3T increases cloud utility and is more economically effective than benchmarks.\nNotably, our proof-of-concept results show up to a 47.6% reduction in the total\nnumber of clients and up to a 300% improvement in convergence time while\nreaching competitive test accuracies compared with incentive mechanism\nbenchmarks.",
      "tldr_zh": "该研究提出了\"Right Reward Right Time (R3T)\"激励机制，针对联邦学习(FL)中的关键学习期(CLPs)问题。该机制通过时间感知的合约设计，在隐私保护前提下解决信息不对称问题，激励高质量客户在关键学习期尽早参与训练。实验表明，R3T能减少47.6%的参与客户数量，加快300%的收敛速度，同时保持模型精度，显著提升了云端效用与经济效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE Journal Submission",
      "pdf_url": "http://arxiv.org/pdf/2503.07869v1",
      "published_date": "2025-03-10 21:36:42 UTC",
      "updated_date": "2025-03-10 21:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:41:36.825893"
    },
    {
      "arxiv_id": "2503.07860v1",
      "title": "Video Action Differencing",
      "title_zh": "视频动作差异分析",
      "authors": [
        "James Burgess",
        "Xiaohan Wang",
        "Yuhui Zhang",
        "Anita Rau",
        "Alejandro Lozano",
        "Lisa Dunlap",
        "Trevor Darrell",
        "Serena Yeung-Levy"
      ],
      "abstract": "How do two individuals differ when performing the same action? In this work,\nwe introduce Video Action Differencing (VidDiff), the novel task of identifying\nsubtle differences between videos of the same action, which has many\napplications, such as coaching and skill learning. To enable development on\nthis new task, we first create VidDiffBench, a benchmark dataset containing 549\nvideo pairs, with human annotations of 4,469 fine-grained action differences\nand 2,075 localization timestamps indicating where these differences occur. Our\nexperiments demonstrate that VidDiffBench poses a significant challenge for\nstate-of-the-art large multimodal models (LMMs), such as GPT-4o and Qwen2-VL.\nBy analyzing failure cases of LMMs on VidDiffBench, we highlight two key\nchallenges for this task: localizing relevant sub-actions over two videos and\nfine-grained frame comparison. To overcome these, we propose the VidDiff\nmethod, an agentic workflow that breaks the task into three stages: action\ndifference proposal, keyframe localization, and frame differencing, each stage\nutilizing specialized foundation models. To encourage future research in this\nnew task, we release the benchmark at\nhttps://huggingface.co/datasets/jmhb/VidDiffBench and code at\nhttp://jmhb0.github.io/viddiff.",
      "tldr_zh": "该研究提出了视频动作差异分析（VidDiff）这一新任务，旨在识别相同动作视频间的细微差异，适用于教练指导与技能学习等场景。研究者构建了包含549对视频的VidDiffBench基准数据集，标注了4,469个细粒度动作差异和2,075个差异时间戳，实验表明当前最先进的多模态模型（如GPT-4o）在此任务上仍面临重大挑战。为解决动作子片段定位和细粒度帧比较两大核心难题，团队开发了分三阶段（差异提议、关键帧定位、帧差分）的VidDiff方法，每阶段采用专用基础模型，并开源了数据集和代码以推动该领域研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025 (International Conference on Learning Representations)\n  Project page: http://jmhb0.github.io/viddiff Benchmark:\n  https://huggingface.co/datasets/jmhb/VidDiffBench",
      "pdf_url": "http://arxiv.org/pdf/2503.07860v1",
      "published_date": "2025-03-10 21:18:32 UTC",
      "updated_date": "2025-03-10 21:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:41:46.294697"
    },
    {
      "arxiv_id": "2503.08722v2",
      "title": "A Recipe for Improving Remote Sensing VLM Zero Shot Generalization",
      "title_zh": "提升遥感视觉语言模型零样本泛化能力的方案",
      "authors": [
        "Aviad Barzilai",
        "Yotam Gigi",
        "Amr Helmy",
        "Vered Silverman",
        "Yehonathan Refael",
        "Bolous Jaber",
        "Tomer Shekel",
        "George Leifman",
        "Genady Beryozkin"
      ],
      "abstract": "Foundation models have had a significant impact across various AI\napplications, enabling use cases that were previously impossible. Contrastive\nVisual Language Models (VLMs), in particular, have outperformed other\ntechniques in many tasks. However, their prevalence in remote sensing (RS) is\nstill limited, due to the scarcity of diverse remote-sensing visual-language\ndatasets. In this work we introduce two novel image-caption datasets for\ntraining of remote sensing foundation models. The first dataset pairs aerial\nand satellite imagery with captions generated by Gemini using landmarks\nextracted from Google Maps. The second dataset utilizes public web images and\ntheir corresponding alt-text, filtered for the remote sensing domain, resulting\nin a diverse dataset with greater breadth in image styles and subject matter.\nThese datasets are used to pre-train the\nMaMMUT~\\citep{kuo2023mammutsimplearchitecturejoint} VLM architecture, resulting\nin state-of-the-art generalization performance in zero-shot cross-modal\nretrieval on well-known public benchmarks. Finally, we present our ongoing\nresearch to distill image-level knowledge gained in the VLM contrastive\ntraining procedure to enhance the model's localization ability. Specifically,\nwe iteratively generate pseudo-labels for image regions based on the model's\nattention maps and use these labels for further training. To mitigate noisy\nattention maps and create robust segmentation masks, we introduce a novel\nattention-pooling mechanism called the Smooth-Attention-Operation.",
      "tldr_zh": "该研究提出了提升遥感视觉语言模型(VLM)零样本泛化能力的方案，通过构建两个新颖的遥感图像-文本数据集：一个利用Google Maps地标生成图像描述，另一个基于公共网络图像及其替代文本。基于这些数据集预训练MaMMUT VLM架构，在跨模态检索任务中实现了最先进的零样本泛化性能。此外，研究还引入了一种称为平滑注意力操作(Smooth-Attention-Operation)的新机制，通过迭代生成伪标签和优化注意力图，增强了模型的定位能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08722v2",
      "published_date": "2025-03-10 21:09:02 UTC",
      "updated_date": "2025-03-17 13:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:41:50.632735"
    },
    {
      "arxiv_id": "2503.07852v1",
      "title": "CIMAGE: Exploiting the Conditional Independence in Masked Graph Auto-encoders",
      "title_zh": "CIMAGE：利用条件独立性优化掩码图自编码器",
      "authors": [
        "Jongwon Park",
        "Heesoo Jung",
        "Hogun Park"
      ],
      "abstract": "Recent Self-Supervised Learning (SSL) methods encapsulating relational\ninformation via masking in Graph Neural Networks (GNNs) have shown promising\nperformance. However, most existing approaches rely on random masking\nstrategies in either feature or graph space, which may fail to capture\ntask-relevant information fully. We posit that this limitation stems from an\ninability to achieve minimum redundancy between masked and unmasked components\nwhile ensuring maximum relevance of both to potential downstream tasks.\nConditional Independence (CI) inherently satisfies the minimum redundancy and\nmaximum relevance criteria, but its application typically requires access to\ndownstream labels. To address this challenge, we introduce CIMAGE, a novel\napproach that leverages Conditional Independence to guide an effective masking\nstrategy within the latent space. CIMAGE utilizes CI-aware latent factor\ndecomposition to generate two distinct contexts, leveraging high-confidence\npseudo-labels derived from unsupervised graph clustering. In this framework,\nthe pretext task involves reconstructing the masked second context solely from\nthe information provided by the first context. Our theoretical analysis further\nsupports the superiority of CIMAGE's novel CI-aware masking method by\ndemonstrating that the learned embedding exhibits approximate linear\nseparability, which enables accurate predictions for the downstream task.\nComprehensive evaluations across diverse graph benchmarks illustrate the\nadvantage of CIMAGE, with notably higher average rankings on node\nclassification and link prediction tasks. Notably, our proposed model\nhighlights the under-explored potential of CI in enhancing graph SSL\nmethodologies and offers enriched insights for effective graph representation\nlearning.",
      "tldr_zh": "该研究提出了CIMAGE，一种基于条件独立性(Conditional Independence, CI)的图自编码器掩码策略，用于改进图神经网络(GNNs)中的自监督学习(SSL)。CIMAGE通过CI感知的潜在因子分解生成两个独立上下文，并利用无监督图聚类的高置信度伪标签进行指导，其预训练任务是从第一个上下文重建被掩码的第二个上下文。理论分析表明，CIMAGE学习到的嵌入具有近似线性可分性，能够提高下游任务的预测准确性。实验证明，CIMAGE在节点分类和链接预测任务中表现优异，凸显了CI在图SSL方法中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the WSDM 2025 Oral. This is an extended version of the\n  original submission. Typos are also corrected",
      "pdf_url": "http://arxiv.org/pdf/2503.07852v1",
      "published_date": "2025-03-10 20:59:27 UTC",
      "updated_date": "2025-03-10 20:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:41:56.552883"
    },
    {
      "arxiv_id": "2503.07849v1",
      "title": "Actual Causation and Nondeterministic Causal Models",
      "title_zh": "实际因果关系与非确定性因果模型",
      "authors": [
        "Sander Beckers"
      ],
      "abstract": "In (Beckers, 2025) I introduced nondeterministic causal models as a\ngeneralization of Pearl's standard deterministic causal models. I here take\nadvantage of the increased expressivity offered by these models to offer a\nnovel definition of actual causation (that also applies to deterministic\nmodels). Instead of motivating the definition by way of (often subjective)\nintuitions about examples, I proceed by developing it based entirely on the\nunique function that it can fulfil in communicating and learning a causal\nmodel. First I generalize the more basic notion of counterfactual dependence,\nsecond I show how this notion has a vital role to play in the logic of causal\ndiscovery, third I introduce the notion of a structural simplification of a\ncausal model, and lastly I bring both notions together in my definition of\nactual causation. Although novel, the resulting definition arrives at verdicts\nthat are almost identical to those of my previous definition (Beckers, 2021,\n2022).",
      "tldr_zh": "本文提出了一种基于非确定性因果模型（nondeterministic causal models）的实际因果关系（actual causation）新定义，扩展了Pearl的确定性因果模型。作者通过推广反事实依赖（counterfactual dependence）概念，并结合因果发现逻辑和因果模型的结构简化（structural simplification），构建了这一定义。新定义在功能上专注于因果模型的传达和学习，其结果与作者之前的定义（Beckers, 2021, 2022）几乎一致，但更具普适性，适用于确定性和非确定性模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at CLeaR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07849v1",
      "published_date": "2025-03-10 20:53:47 UTC",
      "updated_date": "2025-03-10 20:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:42:01.600291"
    },
    {
      "arxiv_id": "2503.07848v1",
      "title": "Safe Explicable Policy Search",
      "title_zh": "安全可解释策略搜索",
      "authors": [
        "Akkamahadevi Hanni",
        "Jonathan Montaño",
        "Yu Zhang"
      ],
      "abstract": "When users work with AI agents, they form conscious or subconscious\nexpectations of them. Meeting user expectations is crucial for such agents to\nengage in successful interactions and teaming. However, users may form\nexpectations of an agent that differ from the agent's planned behaviors. These\ndifferences lead to the consideration of two separate decision models in the\nplanning process to generate explicable behaviors. However, little has been\ndone to incorporate safety considerations, especially in a learning setting. We\npresent Safe Explicable Policy Search (SEPS), which aims to provide a learning\napproach to explicable behavior generation while minimizing the safety risk,\nboth during and after learning. We formulate SEPS as a constrained optimization\nproblem where the agent aims to maximize an explicability score subject to\nconstraints on safety and a suboptimality criterion based on the agent's model.\nSEPS innovatively combines the capabilities of Constrained Policy Optimization\nand Explicable Policy Search. We evaluate SEPS in safety-gym environments and\nwith a physical robot experiment to show that it can learn explicable behaviors\nthat adhere to the agent's safety requirements and are efficient. Results show\nthat SEPS can generate safe and explicable behaviors while ensuring a desired\nlevel of performance w.r.t. the agent's objective, and has real-world relevance\nin human-AI teaming.",
      "tldr_zh": "该研究提出了安全可解释策略搜索(Safe Explicable Policy Search, SEPS)，旨在生成符合用户期望且安全的行为策略。SEPS将问题建模为约束优化问题，通过结合约束策略优化(Constrained Policy Optimization)和可解释策略搜索(Explicable Policy Search)技术，在最大化可解释性的同时确保安全性和策略性能。实验在安全仿真环境(Safety-Gym)和物理机器人平台上验证了SEPS的有效性，表明其能够生成安全、可解释且高效的行为策略，为人机协作提供了实用解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07848v1",
      "published_date": "2025-03-10 20:52:41 UTC",
      "updated_date": "2025-03-10 20:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:42:11.233071"
    },
    {
      "arxiv_id": "2503.07833v1",
      "title": "HalluVerse25: Fine-grained Multilingual Benchmark Dataset for LLM Hallucinations",
      "title_zh": "HalluVerse25：面向大语言模型幻觉的细粒度多语言基准数据集",
      "authors": [
        "Samir Abdaljalil",
        "Hasan Kurban",
        "Erchin Serpedin"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used in various contexts, yet\nremain prone to generating non-factual content, commonly referred to as\n\"hallucinations\". The literature categorizes hallucinations into several types,\nincluding entity-level, relation-level, and sentence-level hallucinations.\nHowever, existing hallucination datasets often fail to capture fine-grained\nhallucinations in multilingual settings. In this work, we introduce\nHalluVerse25, a multilingual LLM hallucination dataset that categorizes\nfine-grained hallucinations in English, Arabic, and Turkish. Our dataset\nconstruction pipeline uses an LLM to inject hallucinations into factual\nbiographical sentences, followed by a rigorous human annotation process to\nensure data quality. We evaluate several LLMs on HalluVerse25, providing\nvaluable insights into how proprietary models perform in detecting\nLLM-generated hallucinations across different contexts.",
      "tldr_zh": "该研究提出了HalluVerse25，一个多语言LLM幻觉基准数据集，旨在细粒度捕捉实体级、关系级和句子级幻觉。数据集涵盖英语、阿拉伯语和土耳其语，通过LLM在事实性传记句子中注入幻觉，并经过严格的人工标注以确保质量。研究评估了多个LLM在HalluVerse25上的表现，为跨语境下LLM生成幻觉的检测提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07833v1",
      "published_date": "2025-03-10 20:24:07 UTC",
      "updated_date": "2025-03-10 20:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:42:19.019946"
    },
    {
      "arxiv_id": "2503.07832v1",
      "title": "RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code",
      "title_zh": "RefactorBench：通过代码评估语言智能体中的状态推理能力",
      "authors": [
        "Dhruv Gautam",
        "Spandan Garg",
        "Jinu Jang",
        "Neel Sundaresan",
        "Roshanak Zilouchian Moghaddam"
      ],
      "abstract": "Recent advances in language model (LM) agents and function calling have\nenabled autonomous, feedback-driven systems to solve problems across various\ndigital domains. To better understand the unique limitations of LM agents, we\nintroduce RefactorBench, a benchmark consisting of 100 large handcrafted\nmulti-file refactoring tasks in popular open-source repositories. Solving tasks\nwithin RefactorBench requires thorough exploration of dependencies across\nmultiple files and strong adherence to relevant instructions. Every task is\ndefined by 3 natural language instructions of varying specificity and is\nmutually exclusive, allowing for the creation of longer combined tasks on the\nsame repository. Baselines on RefactorBench reveal that current LM agents\nstruggle with simple compositional tasks, solving only 22% of tasks with base\ninstructions, in contrast to a human developer with short time constraints\nsolving 87%. Through trajectory analysis, we identify various unique failure\nmodes of LM agents, and further explore the failure mode of tracking past\nactions. By adapting a baseline agent to condition on representations of state,\nwe achieve a 43.9% improvement in solving RefactorBench tasks. We further\nextend our state-aware approach to encompass entire digital environments and\noutline potential directions for future research. RefactorBench aims to support\nthe study of LM agents by providing a set of real-world, multi-hop tasks within\nthe realm of code.",
      "tldr_zh": "该研究提出了RefactorBench，一个包含100个手工构建的多文件代码重构任务的基准测试，用于评估语言模型（LM）代理在状态推理方面的能力。研究通过分析LM代理在处理跨文件依赖和遵循指令时的表现，发现当前LM代理在简单组合任务上表现不佳，仅完成22%的任务，而人类开发者在相同时间内完成87%。通过轨迹分析，研究识别了LM代理的多种独特失败模式，特别是对过去动作的跟踪问题。通过改进基线代理以考虑状态表示，任务解决率提升了43.9%。RefactorBench为研究LM代理提供了真实世界的多跳任务支持，并展望了未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE",
        "I.2.5"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2503.07832v1",
      "published_date": "2025-03-10 20:23:24 UTC",
      "updated_date": "2025-03-10 20:23:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:42:39.747621"
    },
    {
      "arxiv_id": "2503.08720v1",
      "title": "AI for Just Work: Constructing Diverse Imaginations of AI beyond \"Replacing Humans\"",
      "title_zh": "AI 促进公平工作：构建超越“取代人类”的多元化人工智能愿景",
      "authors": [
        "Weina Jin",
        "Nicholas Vincent",
        "Ghassan Hamarneh"
      ],
      "abstract": "The AI community usually focuses on \"how\" to develop AI techniques, but lacks\nthorough open discussions on \"why\" we develop AI. Lacking critical reflections\non the general visions and purposes of AI may make the community vulnerable to\nmanipulation. In this position paper, we explore the \"why\" question of AI. We\ndenote answers to the \"why\" question the imaginations of AI, which depict our\ngeneral visions, frames, and mindsets for the prospects of AI. We identify that\nthe prevailing vision in the AI community is largely a monoculture that\nemphasizes objectives such as replacing humans and improving productivity. Our\ncritical examination of this mainstream imagination highlights its underpinning\nand potentially unjust assumptions. We then call to diversify our collective\nimaginations of AI, embedding ethical assumptions from the outset in the\nimaginations of AI. To facilitate the community's pursuit of diverse\nimaginations, we demonstrate one process for constructing a new imagination of\n\"AI for just work,\" and showcase its application in the medical image synthesis\ntask to make it more ethical. We hope this work will help the AI community to\nopen dialogues with civil society on the visions and purposes of AI, and\ninspire more technical works and advocacy in pursuit of diverse and ethical\nimaginations to restore the value of AI for the public good.",
      "tldr_zh": "这篇立场论文探讨了AI开发的“为什么”问题，批判了当前AI社区中主流的单一想象，即“取代人类”和“提高生产力”的愿景，并指出其潜在的不公正假设。作者呼吁多样化对AI的集体想象，从一开始就将伦理假设嵌入其中。通过构建“AI for just work”的新想象，并以医疗图像合成任务为例，展示了如何使AI技术更具伦理性。本文旨在促进AI社区与公民社会就AI愿景和目的展开对话，并激发更多追求多样化和伦理想象的技术工作与倡导，以恢复AI的公共价值。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08720v1",
      "published_date": "2025-03-10 20:03:55 UTC",
      "updated_date": "2025-03-10 20:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:43:24.496852"
    },
    {
      "arxiv_id": "2503.07817v1",
      "title": "Group Fairness in Multi-Task Reinforcement Learning",
      "title_zh": "多任务强化学习中的群体公平性",
      "authors": [
        "Kefan Song",
        "Runnan Jiang",
        "Rohan Chandra",
        "Shangtong Zhang"
      ],
      "abstract": "This paper addresses a critical societal consideration in the application of\nReinforcement Learning (RL): ensuring equitable outcomes across different\ndemographic groups in multi-task settings. While previous work has explored\nfairness in single-task RL, many real-world applications are multi-task in\nnature and require policies to maintain fairness across all tasks. We introduce\na novel formulation of multi-task group fairness in RL and propose a\nconstrained optimization algorithm that explicitly enforces fairness\nconstraints across multiple tasks simultaneously. We have shown that our\nproposed algorithm does not violate fairness constraints with high probability\nand with sublinear regret in the finite-horizon episodic setting. Through\nexperiments in RiverSwim and MuJoCo environments, we demonstrate that our\napproach better ensures group fairness across multiple tasks compared to\nprevious methods that lack explicit multi-task fairness constraints in both the\nfinite-horizon setting and the infinite-horizon setting. Our results show that\nthe proposed algorithm achieves smaller fairness gaps while maintaining\ncomparable returns across different demographic groups and tasks, suggesting\nits potential for addressing fairness concerns in real-world multi-task RL\napplications.",
      "tldr_zh": "该研究针对强化学习(RL)中的群体公平性问题，首次提出了多任务环境下的群体公平性(formalization of multi-task group fairness)新框架。作者开发了一种带约束的优化算法，能同时强制多任务间的公平性约束，在有限和无限时间范围设置下均有效。实验表明，相比现有方法，该算法在RiverSwim和MuJoCo环境中显著缩小了不同人口群体间的公平性差距(fairness gaps)，同时保持相近的回报率(returns)，为实际多任务RL应用的公平性提供了解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07817v1",
      "published_date": "2025-03-10 19:59:59 UTC",
      "updated_date": "2025-03-10 19:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:42:49.924888"
    },
    {
      "arxiv_id": "2503.07813v1",
      "title": "AgriField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel",
      "title_zh": "AgriField3D：基于多样性面板的田间玉米三维点云与程序化模型精选数据集",
      "authors": [
        "Elvis Kimara",
        "Mozhgan Hadadi",
        "Jackson Godbersen",
        "Aditya Balu",
        "Talukder Jubery",
        "Yawei Li",
        "Adarsh Krishnamurthy",
        "Patrick S. Schnable",
        "Baskar Ganapathysubramanian"
      ],
      "abstract": "The application of artificial intelligence (AI) in three-dimensional (3D)\nagricultural research, particularly for maize, has been limited by the scarcity\nof large-scale, diverse datasets. While 2D image datasets are abundant, they\nfail to capture essential structural details such as leaf architecture, plant\nvolume, and spatial arrangements that 3D data provide. To address this\nlimitation, we present AgriField3D\n(https://baskargroup.github.io/AgriField3D/), a curated dataset of 3D point\nclouds of field-grown maize plants from a diverse genetic panel, designed to be\nAI-ready for advancing agricultural research. Our dataset comprises over 1,000\nhigh-quality point clouds collected using a Terrestrial Laser Scanner,\ncomplemented by procedural models that provide structured, parametric\nrepresentations of maize plants. These procedural models, generated using\nNon-Uniform Rational B-Splines (NURBS) and optimized via a two-step process\ncombining Particle Swarm Optimization (PSO) and differentiable programming,\nenable precise, scalable reconstructions of leaf surfaces and plant\narchitectures. To enhance usability, we performed graph-based segmentation to\nisolate individual leaves and stalks, ensuring consistent labeling across all\nsamples. We also conducted rigorous manual quality control on all datasets,\ncorrecting errors in segmentation, ensuring accurate leaf ordering, and\nvalidating metadata annotations. The dataset further includes metadata\ndetailing plant morphology and quality, alongside multi-resolution subsampled\nversions (100k, 50k, 10k points) optimized for various computational needs. By\nintegrating point cloud data of field grown plants with high-fidelity\nprocedural models and ensuring meticulous manual validation, AgriField3D\nprovides a comprehensive foundation for AI-driven phenotyping, plant structural\nanalysis, and 3D applications in agricultural research.",
      "tldr_zh": "该研究发布了AgriField3D数据集，这是首个面向AI研究的田间玉米3D点云与参数化模型开源数据集，填补了农业研究中三维数据稀缺的空白。数据集包含1,000多株遗传多样性玉米的高精度激光扫描点云，并创新性地采用NURBS曲面建模结合粒子群优化(PSO)和可微分编程技术，构建了参数化植物模型。通过严格的图分割处理和人工质检，数据集提供了分离的叶片/茎秆结构、多分辨率子采样版本（10万/5万/1万点）及完整形态元数据，为AI驱动的作物表型分析和三维农业应用建立了标准化基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Elvis Kimara and Mozhgan Hadadi contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2503.07813v1",
      "published_date": "2025-03-10 19:53:20 UTC",
      "updated_date": "2025-03-10 19:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:43:00.853273"
    },
    {
      "arxiv_id": "2503.07811v2",
      "title": "A primer on optimal transport for causal inference with observational data",
      "title_zh": "因果推断与观测数据中的最优运输理论入门",
      "authors": [
        "Florian F Gunsilius"
      ],
      "abstract": "The theory of optimal transportation has developed into a powerful and\nelegant framework for comparing probability distributions, with wide-ranging\napplications in all areas of science. The fundamental idea of analyzing\nprobabilities by comparing their underlying state space naturally aligns with\nthe core idea of causal inference, where understanding and quantifying\ncounterfactual states is paramount. Despite this intuitive connection, explicit\nresearch at the intersection of optimal transport and causal inference is only\nbeginning to develop. Yet, many foundational models in causal inference have\nimplicitly relied on optimal transport principles for decades, without\nrecognizing the underlying connection. Therefore, the goal of this review is to\noffer an introduction to the surprisingly deep existing connections between\noptimal transport and the identification of causal effects with observational\ndata -- where optimal transport is not just a set of potential tools, but\nactually builds the foundation of model assumptions. As a result, this review\nis intended to unify the language and notation between different areas of\nstatistics, mathematics, and econometrics, by pointing out these existing\nconnections, and to explore novel problems and directions for future work in\nboth areas derived from this realization.",
      "tldr_zh": "本文综述了最优传输理论（Optimal Transport）与因果推断（Causal Inference）在观测数据中的深度关联。最优传输通过比较概率分布的状态空间，与因果推断中量化反事实状态的核心思想天然契合。尽管两者之间的研究尚处于起步阶段，但许多因果推断的基础模型已隐含地依赖最优传输原则。本文旨在统一统计学、数学和计量经济学领域的语言与符号，揭示这些现有联系，并探索由此衍生的新问题和未来研究方向。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "econ.EM"
      ],
      "primary_category": "stat.ME",
      "comment": "24 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07811v2",
      "published_date": "2025-03-10 19:51:37 UTC",
      "updated_date": "2025-03-12 18:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:43:10.958570"
    },
    {
      "arxiv_id": "2503.11695v1",
      "title": "MELON: Multimodal Mixture-of-Experts with Spectral-Temporal Fusion for Long-Term Mobility Estimation in Critical Care",
      "title_zh": "MELON：基于频谱-时间融合的多模态专家混合模型用于重症监护中的长期活动能力评估",
      "authors": [
        "Jiaqing Zhang",
        "Miguel Contreras",
        "Jessica Sena",
        "Andrea Davidson",
        "Yuanfang Ren",
        "Ziyuan Guan",
        "Tezcan Ozrazgat-Baslanti",
        "Tyler J. Loftus",
        "Subhash Nerella",
        "Azra Bihorac",
        "Parisa Rashidi"
      ],
      "abstract": "Patient mobility monitoring in intensive care is critical for ensuring timely\ninterventions and improving clinical outcomes. While accelerometry-based sensor\ndata are widely adopted in training artificial intelligence models to estimate\npatient mobility, existing approaches face two key limitations highlighted in\nclinical practice: (1) modeling the long-term accelerometer data is challenging\ndue to the high dimensionality, variability, and noise, and (2) the absence of\nefficient and robust methods for long-term mobility assessment. To overcome\nthese challenges, we introduce MELON, a novel multimodal framework designed to\npredict 12-hour mobility status in the critical care setting. MELON leverages\nthe power of a dual-branch network architecture, combining the strengths of\nspectrogram-based visual representations and sequential accelerometer\nstatistical features. MELON effectively captures global and fine-grained\nmobility patterns by integrating a pre-trained image encoder for rich\nfrequency-domain feature extraction and a Mixture-of-Experts encoder for\nsequence modeling. We trained and evaluated the MELON model on the multimodal\ndataset of 126 patients recruited from nine Intensive Care Units at the\nUniversity of Florida Health Shands Hospital main campus in Gainesville,\nFlorida. Experiments showed that MELON outperforms conventional approaches for\n12-hour mobility status estimation with an overall area under the receiver\noperating characteristic curve (AUROC) of 0.82 (95\\%, confidence interval\n0.78-0.86). Notably, our experiments also revealed that accelerometer data\ncollected from the wrist provides robust predictive performance compared with\ndata from the ankle, suggesting a single-sensor solution that can reduce\npatient burden and lower deployment costs...",
      "tldr_zh": "该研究提出了MELON，一种多模态专家混合模型，用于重症监护中的长期移动性评估。MELON采用双分支网络架构，结合频谱图视觉表示和加速度计序列统计特征，有效捕捉全局和细粒度的移动模式。通过在126名患者的多模态数据集上训练和评估，MELON在12小时移动性状态预测中表现优异，AUROC达到0.82，且腕部加速度计数据表现优于踝部，为减少患者负担和降低部署成本提供了单传感器解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.11695v1",
      "published_date": "2025-03-10 19:47:46 UTC",
      "updated_date": "2025-03-10 19:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:43:12.790408"
    },
    {
      "arxiv_id": "2503.07807v1",
      "title": "Training Domain Draft Models for Speculative Decoding: Best Practices and Insights",
      "title_zh": "训练领域草稿模型以进行推测解码：最佳实践与洞见",
      "authors": [
        "Fenglu Hong",
        "Ravi Raju",
        "Jonathan Lingjie Li",
        "Bo Li",
        "Urmish Thakker",
        "Avinash Ravichandran",
        "Swayambhoo Jain",
        "Changran Hu"
      ],
      "abstract": "Speculative decoding is an effective method for accelerating inference of\nlarge language models (LLMs) by employing a small draft model to predict the\noutput of a target model. However, when adapting speculative decoding to\ndomain-specific target models, the acceptance rate of the generic draft model\ndrops significantly due to domain shift. In this work, we systematically\ninvestigate knowledge distillation techniques for training domain draft models\nto improve their speculation accuracy. We compare white-box and black-box\ndistillation approaches and explore their effectiveness in various data\naccessibility scenarios, including historical user queries, curated domain\ndata, and synthetically generated alignment data. Our experiments across\nFunction Calling, Biology, and Chinese domains show that offline distillation\nconsistently outperforms online distillation by 11% to 25%, white-box\ndistillation surpasses black-box distillation by 2% to 10%, and data scaling\ntrends hold across domains. Additionally, we find that synthetic data can\neffectively align draft models and achieve 80% to 93% of the performance of\ntraining on historical user queries. These findings provide practical\nguidelines for training domain-specific draft models to improve speculative\ndecoding efficiency.",
      "tldr_zh": "本研究系统探索了为加速领域特定大语言模型(LLMs)推理而训练领域草稿模型的最佳实践。通过对比白盒与黑盒知识蒸馏方法，以及在不同数据可访问性场景（如历史用户查询、领域数据和合成数据）下的效果，研究发现：离线蒸馏比在线蒸馏性能提升11%-25%，白盒蒸馏优于黑盒蒸馏2%-10%，且数据规模扩展趋势在多个领域均成立。此外，合成数据能有效对齐草稿模型，达到历史用户查询训练效果的80%-93%。这些发现为提升领域特定草稿模型的推测解码效率提供了实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a workshop paper at SCOPE - ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07807v1",
      "published_date": "2025-03-10 19:40:25 UTC",
      "updated_date": "2025-03-10 19:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:43:31.326745"
    },
    {
      "arxiv_id": "2503.07806v1",
      "title": "Towards Large Language Models that Benefit for All: Benchmarking Group Fairness in Reward Models",
      "title_zh": "迈向造福众生的大语言模型：奖励模型群体公平性基准测试",
      "authors": [
        "Kefan Song",
        "Jin Yao",
        "Runnan Jiang",
        "Rohan Chandra",
        "Shangtong Zhang"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly powerful and accessible\nto human users, ensuring fairness across diverse demographic groups, i.e.,\ngroup fairness, is a critical ethical concern. However, current fairness and\nbias research in LLMs is limited in two aspects. First, compared to traditional\ngroup fairness in machine learning classification, it requires that the\nnon-sensitive attributes, in this case, the prompt questions, be the same\nacross different groups. In many practical scenarios, different groups,\nhowever, may prefer different prompt questions and this requirement becomes\nimpractical. Second, it evaluates group fairness only for the LLM's final\noutput without identifying the source of possible bias. Namely, the bias in\nLLM's output can result from both the pretraining and the finetuning. For\nfinetuning, the bias can result from both the RLHF procedure and the learned\nreward model. Arguably, evaluating the group fairness of each component in the\nLLM pipeline could help develop better methods to mitigate the possible bias.\nRecognizing those two limitations, this work benchmarks the group fairness of\nlearned reward models. By using expert-written text from arXiv, we are able to\nbenchmark the group fairness of reward models without requiring the same prompt\nquestions across different demographic groups. Surprisingly, our results\ndemonstrate that all the evaluated reward models (e.g., Nemotron-4-340B-Reward,\nArmoRM-Llama3-8B-v0.1, and GRM-llama3-8B-sftreg) exhibit statistically\nsignificant group unfairness. We also observed that top-performing reward\nmodels (w.r.t. canonical performance metrics) tend to demonstrate better group\nfairness.",
      "tldr_zh": "该研究针对大语言模型(LLMs)中群体公平性(group fairness)问题提出新评估框架，突破现有方法两个局限：1) 无需跨群体使用相同提示问题；2) 专门评估奖励模型(reward models)的偏见来源。通过arXiv专家文本构建基准测试，发现所有评估的奖励模型(包括Nemotron-4-340B-Reward等)均存在统计显著的群体不公平性，但性能越强的奖励模型公平性表现越好。该工作为分解式评估LLM流程中的偏见来源提供了方法论基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07806v1",
      "published_date": "2025-03-10 19:39:39 UTC",
      "updated_date": "2025-03-10 19:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:43:45.217285"
    },
    {
      "arxiv_id": "2503.07799v1",
      "title": "Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos",
      "title_zh": "自监督常态学习与差异向量引导模型融合的胎儿超声视频零样本先天性心脏病检测",
      "authors": [
        "Pramit Saha",
        "Divyanshu Mishra",
        "Netzahualcoyotl Hernandez-Cruz",
        "Olga Patey",
        "Aris Papageorghiou",
        "Yuki M. Asano",
        "J. Alison Noble"
      ],
      "abstract": "Congenital Heart Disease (CHD) is one of the leading causes of fetal\nmortality, yet the scarcity of labeled CHD data and strict privacy regulations\nsurrounding fetal ultrasound (US) imaging present significant challenges for\nthe development of deep learning-based models for CHD detection. Centralised\ncollection of large real-world datasets for rare conditions, such as CHD, from\nlarge populations requires significant co-ordination and resource. In addition,\ndata governance rules increasingly prevent data sharing between sites. To\naddress these challenges, we introduce, for the first time, a novel\nprivacy-preserving, zero-shot CHD detection framework that formulates CHD\ndetection as a normality modeling problem integrated with model merging. In our\nframework dubbed Sparse Tube Ultrasound Distillation (STUD), each hospital site\nfirst trains a sparse video tube-based self-supervised video anomaly detection\n(VAD) model on normal fetal heart US clips with self-distillation loss. This\nenables site-specific models to independently learn the distribution of healthy\ncases. To aggregate knowledge across the decentralized models while maintaining\nprivacy, we propose a Divergence Vector-Guided Model Merging approach,\nDivMerge, that combines site-specific models into a single VAD model without\ndata exchange. Our approach preserves domain-agnostic rich spatio-temporal\nrepresentations, ensuring generalization to unseen CHD cases. We evaluated our\napproach on real-world fetal US data collected from 5 hospital sites. Our\nmerged model outperformed site-specific models by 23.77% and 30.13% in accuracy\nand F1-score respectively on external test sets.",
      "tldr_zh": "该研究提出了一种隐私保护的零样本先天性心脏病（CHD）检测框架，通过将CHD检测建模为正常性建模问题并结合模型融合来解决胎儿超声视频中的CHD检测难题。框架包括两个核心部分：稀疏管超声蒸馏（STUD）用于训练基于正常胎儿心脏超声片段的自我监督视频异常检测（VAD）模型，以及分歧向量引导的模型融合方法（DivMerge）用于在不交换数据的情况下合并各医院站点的模型。实验结果表明，融合模型在外部测试集上的准确率和F1分数分别比站点特定模型提高了23.77%和30.13%，有效提升了CHD检测的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07799v1",
      "published_date": "2025-03-10 19:27:15 UTC",
      "updated_date": "2025-03-10 19:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:43:44.991295"
    },
    {
      "arxiv_id": "2503.07792v1",
      "title": "Efficient Neural Clause-Selection Reinforcement",
      "title_zh": "高效神经子句选择强化方法",
      "authors": [
        "Martin Suda"
      ],
      "abstract": "Clause selection is arguably the most important choice point in\nsaturation-based theorem proving. Framing it as a reinforcement learning (RL)\ntask is a way to challenge the human-designed heuristics of state-of-the-art\nprovers and to instead automatically evolve -- just from prover experiences --\ntheir potentially optimal replacement. In this work, we present a neural\nnetwork architecture for scoring clauses for clause selection that is powerful\nyet efficient to evaluate. Following RL principles to make design decisions, we\nintegrate the network into the Vampire theorem prover and train it from\nsuccessful proof attempts. An experiment on the diverse TPTP benchmark finds\nthe neurally guided prover improve over a baseline strategy, from which it\ninitially learns--in terms of the number of in-training-unseen problems solved\nunder a practically relevant, short CPU instruction limit--by 20%.",
      "tldr_zh": "该研究提出了一种高效的神经网络架构，用于强化学习(RL)框架下的定理证明中从句选择任务。通过将从句选择建模为RL问题，该神经网络能够从证明经验中自动学习最优策略，取代传统人工设计的启发式方法。实验表明，将该神经网络集成到Vampire定理证明器中后，在TPTP基准测试上相比基线策略解决了多20%的未见问题，且在短CPU时间限制下表现优异。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages main text, 3 page bibliography, 6 page appendix",
      "pdf_url": "http://arxiv.org/pdf/2503.07792v1",
      "published_date": "2025-03-10 19:14:48 UTC",
      "updated_date": "2025-03-10 19:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:43:44.536307"
    },
    {
      "arxiv_id": "2503.10675v1",
      "title": "Beyond One-Size-Fits-All Summarization: Customizing Summaries for Diverse Users",
      "title_zh": "超越\"一刀切\"式摘要：为多样化用户定制摘要",
      "authors": [
        "Mehmet Samet Duran",
        "Tevfik Aytekin"
      ],
      "abstract": "In recent years, automatic text summarization has witnessed significant\nadvancement, particularly with the development of transformer-based models.\nHowever, the challenge of controlling the readability level of generated\nsummaries remains an under-explored area, especially for languages with complex\nlinguistic features like Turkish. This gap has the effect of impeding effective\ncommunication and also limits the accessibility of information. Controlling\nreadability of textual data is an important element for creating summaries for\ndifferent audiences with varying literacy and education levels, such as\nstudents ranging from primary school to graduate level, as well as individuals\nwith diverse educational backgrounds. Summaries that align with the needs of\nspecific reader groups can improve comprehension and engagement, ensuring that\nthe intended message is effectively communicated. Furthermore, readability\nadjustment is essential to expand the usability of summarization models in\neducational and professional domains. Current summarization models often don't\nhave the mechanisms to adjust the complexity of their outputs, resulting in\nsummaries that may be too simplistic or overly complex for certain types of\nreader groups. Developing adaptive models that can tailor content to specific\nreadability levels is therefore crucial. To address this problem, we create our\nown custom dataset and train a model with our custom architecture. Our method\nensures that readability levels are effectively controlled while maintaining\naccuracy and coherence. We rigorously compare our model to a supervised\nfine-tuned baseline, demonstrating its superiority in generating\nreadability-aware summaries.",
      "tldr_zh": "该研究针对自动文本摘要领域，提出了一种可定制化生成不同可读性水平摘要的方法，特别适用于具有复杂语言特征的语言（如土耳其语）。研究通过构建自定义数据集和训练模型，解决了现有摘要模型无法根据目标读者群体（如不同教育水平的学生或专业人士）调整输出复杂性的问题。实验表明，该方法在控制可读性的同时，保持了摘要的准确性和连贯性，显著优于基线模型，为教育、专业等领域的信息可及性提供了重要支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2503.10675v1",
      "published_date": "2025-03-10 19:08:36 UTC",
      "updated_date": "2025-03-10 19:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:44:27.188238"
    },
    {
      "arxiv_id": "2503.07784v1",
      "title": "Joint Explainability-Performance Optimization With Surrogate Models for AI-Driven Edge Services",
      "title_zh": "基于代理模型的AI驱动边缘服务联合可解释性与性能优化",
      "authors": [
        "Foivos Charalampakos",
        "Thomas Tsouparopoulos",
        "Iordanis Koutsopoulos"
      ],
      "abstract": "Explainable AI is a crucial component for edge services, as it ensures\nreliable decision making based on complex AI models. Surrogate models are a\nprominent approach of XAI where human-interpretable models, such as a linear\nregression model, are trained to approximate a complex (black-box) model's\npredictions. This paper delves into the balance between the predictive accuracy\nof complex AI models and their approximation by surrogate ones, advocating that\nboth these models benefit from being learned simultaneously. We derive a joint\n(bi-level) training scheme for both models and we introduce a new algorithm\nbased on multi-objective optimization (MOO) to simultaneously minimize both the\ncomplex model's prediction error and the error between its outputs and those of\nthe surrogate. Our approach leads to improvements that exceed 99% in the\napproximation of the black-box model through the surrogate one, as measured by\nthe metric of Fidelity, for a compromise of less than 3% absolute reduction in\nthe black-box model's predictive accuracy, compared to single-task and\nmulti-task learning baselines. By improving Fidelity, we can derive more\ntrustworthy explanations of the complex model's outcomes from the surrogate,\nenabling reliable AI applications for intelligent services at the network edge.",
      "tldr_zh": "本文提出了一种联合优化方法，通过多目标优化(MOO)算法同时训练复杂AI模型和其可解释的代理模型(surrogate models)，以在边缘服务中实现性能与可解释性的平衡。该方法在保证复杂模型预测准确率仅降低不到3%的情况下，使代理模型对复杂模型的近似度(Fidelity)提升超过99%，从而生成更可信的解释。这项研究为网络边缘的智能服务提供了可靠且可解释的AI应用基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07784v1",
      "published_date": "2025-03-10 19:04:09 UTC",
      "updated_date": "2025-03-10 19:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:44:10.386847"
    },
    {
      "arxiv_id": "2503.07783v1",
      "title": "Sensemaking in Novel Environments: How Human Cognition Can Inform Artificial Agents",
      "title_zh": "陌生环境中的意义建构：人类认知如何为人工智能体提供启示",
      "authors": [
        "Robert E. Patterson",
        "Regina Buccello-Stout",
        "Mary E. Frame",
        "Anna M. Maresca",
        "Justin Nelson",
        "Barbara Acker-Mills",
        "Erica Curtis",
        "Jared Culbertson",
        "Kevin Schmidt",
        "Scott Clouse",
        "Steve Rogers"
      ],
      "abstract": "One of the most vital cognitive skills to possess is the ability to make\nsense of objects, events, and situations in the world. In the current paper, we\noffer an approach for creating artificially intelligent agents with the\ncapacity for sensemaking in novel environments. Objectives: to present several\nkey ideas: (1) a novel unified conceptual framework for sensemaking (which\nincludes the existence of sign relations embedded within and across frames);\n(2) interaction among various content-addressable, distributed-knowledge\nstructures via shared attributes (whose net response would represent a\nsynthesized object, event, or situation serving as a sign for sensemaking in a\nnovel environment). Findings: we suggest that attributes across memories can be\nshared and recombined in novel ways to create synthesized signs, which can\ndenote certain outcomes in novel environments (i.e., sensemaking).",
      "tldr_zh": "该论文提出了一种让AI智能体在新环境中进行意义构建(sensemaking)的新方法。研究者提出了一个统一的概念框架，强调通过分布式知识结构中共享属性的交互来创建综合表征，这些表征可作为新环境中的认知符号。核心发现表明，记忆中的属性能够以新颖方式重组，生成可指示特定结果的综合符号，从而支持AI系统实现类似人类的认知能力。",
      "categories": [
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07783v1",
      "published_date": "2025-03-10 19:03:09 UTC",
      "updated_date": "2025-03-10 19:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:44:18.557629"
    },
    {
      "arxiv_id": "2503.07770v1",
      "title": "Evaluating LLaMA 3.2 for Software Vulnerability Detection",
      "title_zh": "评估 LLaMA 3.2 在软件漏洞检测中的应用",
      "authors": [
        "José Gonçalves",
        "Miguel Silva",
        "Bernardo Cabral",
        "Tiago Dias",
        "Eva Maia",
        "Isabel Praça",
        "Ricardo Severino",
        "Luís Lino Ferreira"
      ],
      "abstract": "Deep Learning (DL) has emerged as a powerful tool for vulnerability\ndetection, often outperforming traditional solutions. However, developing\neffective DL models requires large amounts of real-world data, which can be\ndifficult to obtain in sufficient quantities. To address this challenge,\nDiverseVul dataset has been curated as the largest dataset of vulnerable and\nnon-vulnerable C/C++ functions extracted exclusively from real-world projects.\nIts goal is to provide high-quality, large-scale samples for training DL\nmodels. However, during our study several inconsistencies were identified in\nthe raw dataset while applying pre-processing techniques, highlighting the need\nfor a refined version. In this work, we present a refined version of DiverseVul\ndataset, which is used to fine-tune a large language model, LLaMA 3.2, for\nvulnerability detection. Experimental results show that the use of\npre-processing techniques led to an improvement in performance, with the model\nachieving an F1-Score of 66%, a competitive result when compared to our\nbaseline, which achieved a 47% F1-Score in software vulnerability detection.",
      "tldr_zh": "本研究针对软件漏洞检测领域数据不足的问题，提出了改进版DiverseVul数据集——这是目前最大的真实项目C/C++函数漏洞数据集。通过对原始数据集的预处理优化，研究者使用该数据集微调了LLaMA 3.2大语言模型进行漏洞检测。实验结果显示，经预处理优化后的模型F1分数达到66%，相比基线模型47%的性能有显著提升，验证了该方法在软件漏洞检测中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 4 tables, EICC 2025: European Interdisciplinary\n  Cybersecurity Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07770v1",
      "published_date": "2025-03-10 18:47:41 UTC",
      "updated_date": "2025-03-10 18:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:44:23.071219"
    },
    {
      "arxiv_id": "2503.10674v1",
      "title": "Enhancing Retrieval for ESGLLM via ESG-CID -- A Disclosure Content Index Finetuning Dataset for Mapping GRI and ESRS",
      "title_zh": "通过 ESG-CID 增强 ESGLLM 的检索能力——一个用于映射 GRI 和 ESRS 的披露内容索引微调数据集",
      "authors": [
        "Shafiuddin Rehan Ahmed",
        "Ankit Parag Shah",
        "Quan Hung Tran",
        "Vivek Khetan",
        "Sukryool Kang",
        "Ankit Mehta",
        "Yujia Bao",
        "Wei Wei"
      ],
      "abstract": "Climate change has intensified the need for transparency and accountability\nin organizational practices, making Environmental, Social, and Governance (ESG)\nreporting increasingly crucial. Frameworks like the Global Reporting Initiative\n(GRI) and the new European Sustainability Reporting Standards (ESRS) aim to\nstandardize ESG reporting, yet generating comprehensive reports remains\nchallenging due to the considerable length of ESG documents and variability in\ncompany reporting styles. To facilitate ESG report automation,\nRetrieval-Augmented Generation (RAG) systems can be employed, but their\ndevelopment is hindered by a lack of labeled data suitable for training\nretrieval models. In this paper, we leverage an underutilized source of weak\nsupervision -- the disclosure content index found in past ESG reports -- to\ncreate a comprehensive dataset, ESG-CID, for both GRI and ESRS standards. By\nextracting mappings between specific disclosure requirements and corresponding\nreport sections, and refining them using a Large Language Model as a judge, we\ngenerate a robust training and evaluation set. We benchmark popular embedding\nmodels on this dataset and show that fine-tuning BERT-based models can\noutperform commercial embeddings and leading public models, even under temporal\ndata splits for cross-report style transfer from GRI to ESRS",
      "tldr_zh": "该研究提出了ESG-CID数据集，通过利用ESG报告中的披露内容索引(disclosure content index)作为弱监督数据源，构建了一个用于微调检索模型的数据集，以支持GRI和ESRS标准的ESG报告自动化生成。研究采用大语言模型(LLM)作为评判工具，提取特定披露要求与报告章节之间的映射关系，生成了高质量的训练和评估数据集。实验表明，基于BERT的微调模型在跨报告风格迁移任务中优于商业嵌入和主流公开模型，为ESG报告检索增强生成(RAG)系统的开发提供了重要支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Long paper",
      "pdf_url": "http://arxiv.org/pdf/2503.10674v1",
      "published_date": "2025-03-10 18:07:33 UTC",
      "updated_date": "2025-03-10 18:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:44:29.276918"
    },
    {
      "arxiv_id": "2503.07737v1",
      "title": "A Simple Approach to Constraint-Aware Imitation Learning with Application to Autonomous Racing",
      "title_zh": "一种简单的方法实现约束感知模仿学习及其在自动驾驶赛车中的应用",
      "authors": [
        "Shengfan Cao",
        "Eunhyek Joa",
        "Francesco Borrelli"
      ],
      "abstract": "Guaranteeing constraint satisfaction is challenging in imitation learning\n(IL), particularly in tasks that require operating near a system's handling\nlimits. Traditional IL methods often struggle to enforce constraints, leading\nto suboptimal performance in high-precision tasks. In this paper, we present a\nsimple approach to incorporating safety into the IL objective. Through\nsimulations, we empirically validate our approach on an autonomous racing task\nwith both full-state and image feedback, demonstrating improved constraint\nsatisfaction and greater consistency in task performance compared to a baseline\nmethod.",
      "tldr_zh": "本文提出了一种简单的约束感知模仿学习方法，用于解决传统模仿学习(IL)在系统性能极限附近操作时难以保证约束满足的问题。该方法通过将安全约束整合到IL目标函数中，在自动驾驶赛车任务中验证了有效性。实验表明，相比基线方法，该方案在完整状态和图像反馈条件下都能更好地满足约束条件，并提高了任务性能的一致性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07737v1",
      "published_date": "2025-03-10 18:00:16 UTC",
      "updated_date": "2025-03-10 18:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:44:51.848395"
    },
    {
      "arxiv_id": "2503.07600v1",
      "title": "A Representationalist, Functionalist and Naturalistic Conception of Intelligence as a Foundation for AGI",
      "title_zh": "一种表征主义、功能主义与自然主义的智能观：通用人工智能的基础",
      "authors": [
        "Rolf Pfister"
      ],
      "abstract": "The article analyses foundational principles relevant to the creation of\nartificial general intelligence (AGI). Intelligence is understood as the\nability to create novel skills that allow to achieve goals under previously\nunknown conditions. To this end, intelligence utilises reasoning methods such\nas deduction, induction and abduction as well as other methods such as\nabstraction and classification to develop a world model. The methods are\napplied to indirect and incomplete representations of the world, which are\nobtained through perception, for example, and which do not depict the world but\nonly correspond to it. Due to these limitations and the uncertain and\ncontingent nature of reasoning, the world model is constructivist. Its value is\nfunctionally determined by its viability, i.e., its potential to achieve the\ndesired goals. In consequence, meaning is assigned to representations by\nattributing them a function that makes it possible to achieve a goal. This\nrepresentational and functional conception of intelligence enables a\nnaturalistic interpretation that does not presuppose mental features, such as\nintentionality and consciousness, which are regarded as independent of\nintelligence. Based on a phenomenological analysis, it is shown that AGI can\ngain a more fundamental access to the world than humans, although it is limited\nby the No Free Lunch theorems, which require assumptions to be made.",
      "tldr_zh": "本文提出了一种基于表征主义、功能主义和自然主义的智能概念，作为人工通用智能(AGI)的理论基础。智能被定义为在未知条件下创造新技能以实现目标的能力，依赖于演绎、归纳和溯因等推理方法，以及抽象和分类等技术构建世界模型。该模型是建构主义的，其价值由其功能性（即可行性）决定，意义通过赋予表征以实现目标的功能来定义。这种智能观念无需预设意向性或意识等心理特征，为AGI提供了一种自然主义的解释。研究还表明，尽管受限于“没有免费午餐”定理，AGI仍可能获得比人类更基础的世界理解。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07600v1",
      "published_date": "2025-03-10 17:58:00 UTC",
      "updated_date": "2025-03-10 17:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:44:46.779355"
    },
    {
      "arxiv_id": "2503.07599v1",
      "title": "NeuroChat: A Neuroadaptive AI Chatbot for Customizing Learning Experiences",
      "title_zh": "NeuroChat：一款可定制学习体验的神经自适应AI聊天机器人",
      "authors": [
        "Dünya Baradari",
        "Nataliya Kosmyna",
        "Oscar Petrov",
        "Rebecah Kaplun",
        "Pattie Maes"
      ],
      "abstract": "Generative AI is transforming education by enabling personalized, on-demand\nlearning experiences. However, AI tutors lack the ability to assess a learner's\ncognitive state in real time, limiting their adaptability. Meanwhile,\nelectroencephalography (EEG)-based neuroadaptive systems have successfully\nenhanced engagement by dynamically adjusting learning content. This paper\npresents NeuroChat, a proof-of-concept neuroadaptive AI tutor that integrates\nreal-time EEG-based engagement tracking with generative AI. NeuroChat\ncontinuously monitors a learner's cognitive engagement and dynamically adjusts\ncontent complexity, response style, and pacing using a closed-loop system. We\nevaluate this approach in a pilot study (n=24), comparing NeuroChat to a\nstandard LLM-based chatbot. Results indicate that NeuroChat enhances cognitive\nand subjective engagement but does not show an immediate effect on learning\noutcomes. These findings demonstrate the feasibility of real-time cognitive\nfeedback in LLMs, highlighting new directions for adaptive learning, AI\ntutoring, and human-AI interaction.",
      "tldr_zh": "这篇论文提出了NeuroChat，一种整合脑电图(EEG)神经反馈与生成式AI的神经自适应聊天机器人，用于实时定制学习体验。该系统通过闭环系统持续监测学习者的认知参与度(EEG信号)，动态调整内容难度、回答风格和学习节奏。试点研究(n=24)表明，相比标准LLM聊天机器人，NeuroChat能显著提升认知和主观参与度，但尚未显现对学习效果的直接影响。该研究为实时认知反馈与生成式AI的结合提供了可行性验证，开拓了自适应学习与AI辅导的新方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "I.2.7; J.0; K.3.1; K.8.0; C.3"
      ],
      "primary_category": "cs.HC",
      "comment": "16 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.07599v1",
      "published_date": "2025-03-10 17:57:20 UTC",
      "updated_date": "2025-03-10 17:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:45:07.530320"
    },
    {
      "arxiv_id": "2503.07596v1",
      "title": "Denoising Hamiltonian Network for Physical Reasoning",
      "title_zh": "去噪哈密顿网络：面向物理推理的框架",
      "authors": [
        "Congyue Deng",
        "Brandon Y. Feng",
        "Cecilia Garraffo",
        "Alan Garbarz",
        "Robin Walters",
        "William T. Freeman",
        "Leonidas Guibas",
        "Kaiming He"
      ],
      "abstract": "Machine learning frameworks for physical problems must capture and enforce\nphysical constraints that preserve the structure of dynamical systems. Many\nexisting approaches achieve this by integrating physical operators into neural\nnetworks. While these methods offer theoretical guarantees, they face two key\nlimitations: (i) they primarily model local relations between adjacent time\nsteps, overlooking longer-range or higher-level physical interactions, and (ii)\nthey focus on forward simulation while neglecting broader physical reasoning\ntasks. We propose the Denoising Hamiltonian Network (DHN), a novel framework\nthat generalizes Hamiltonian mechanics operators into more flexible neural\noperators. DHN captures non-local temporal relationships and mitigates\nnumerical integration errors through a denoising mechanism. DHN also supports\nmulti-system modeling with a global conditioning mechanism. We demonstrate its\neffectiveness and flexibility across three diverse physical reasoning tasks\nwith distinct inputs and outputs.",
      "tldr_zh": "该研究提出了一种新型去噪哈密顿网络(Denoising Hamiltonian Network, DHN)，将哈密顿力学算子推广为更灵活的神经算子。该方法通过去噪机制捕获非局部时间关系并减轻数值积分误差，克服了现有方法仅建模相邻时间步局部关系、忽略长期物理相互作用的局限。DHN还支持通过全局调节机制进行多系统建模，在三种不同输入输出的物理推理任务中展现了优于传统方法的有效性和灵活性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07596v1",
      "published_date": "2025-03-10 17:57:01 UTC",
      "updated_date": "2025-03-10 17:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:45:02.907915"
    },
    {
      "arxiv_id": "2503.07591v1",
      "title": "Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning",
      "title_zh": "先筛选图像，后生成指令：面向视觉指令调优的预指令数据选择方法",
      "authors": [
        "Bardia Safaei",
        "Faizan Siddiqui",
        "Jiacong Xu",
        "Vishal M. Patel",
        "Shao-Yuan Lo"
      ],
      "abstract": "Visual instruction tuning (VIT) for large vision-language models (LVLMs)\nrequires training on expansive datasets of image-instruction pairs, which can\nbe costly. Recent efforts in VIT data selection aim to select a small subset of\nhigh-quality image-instruction pairs, reducing VIT runtime while maintaining\nperformance comparable to full-scale training. However, a major challenge often\noverlooked is that generating instructions from unlabeled images for VIT is\nhighly expensive. Most existing VIT datasets rely heavily on human annotations\nor paid services like the GPT API, which limits users with constrained\nresources from creating VIT datasets for custom applications. To address this,\nwe introduce Pre-Instruction Data Selection (PreSel), a more practical data\nselection paradigm that directly selects the most beneficial unlabeled images\nand generates instructions only for the selected images. PreSel first estimates\nthe relative importance of each vision task within VIT datasets to derive\ntask-wise sampling budgets. It then clusters image features within each task,\nselecting the most representative images with the budget. This approach reduces\ncomputational overhead for both instruction generation during VIT data\nformation and LVLM fine-tuning. By generating instructions for only 15% of the\nimages, PreSel achieves performance comparable to full-data VIT on the\nLLaVA-1.5 and Vision-Flan datasets. The link to our project page:\nhttps://bardisafa.github.io/PreSel",
      "tldr_zh": "该研究提出了一种名为Pre-Instruction Data Selection (PreSel)的新范式，用于视觉指令调优(VIT)数据选择，旨在降低生成图像-指令对的高昂成本。PreSel通过首先估计每个视觉任务的相对重要性，并基于任务预算从图像特征聚类中选择最具代表性的未标注图像，仅对选定的图像生成指令。实验表明，仅对15%的图像生成指令，PreSel即可在LLaVA-1.5和Vision-Flan数据集上达到与全数据VIT相当的性能，显著减少了计算开销。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at Computer Vision and Pattern Recognition Conference (CVPR)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07591v1",
      "published_date": "2025-03-10 17:55:11 UTC",
      "updated_date": "2025-03-10 17:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:45:10.058933"
    },
    {
      "arxiv_id": "2503.07588v2",
      "title": "When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning",
      "title_zh": "当大型视觉语言模型遇见大型遥感影像：从粗到细的文本引导令牌剪枝",
      "authors": [
        "Junwei Luo",
        "Yingying Zhang",
        "Xue Yang",
        "Kang Wu",
        "Qi Zhu",
        "Lei Liang",
        "Jingdong Chen",
        "Yansheng Li"
      ],
      "abstract": "Efficient vision-language understanding of large Remote Sensing Images (RSIs)\nis meaningful but challenging. Current Large Vision-Language Models (LVLMs)\ntypically employ limited pre-defined grids to process images, leading to\ninformation loss when handling gigapixel RSIs. Conversely, using unlimited\ngrids significantly increases computational costs. To preserve image details\nwhile reducing computational complexity, we propose a text-guided token pruning\nmethod with Dynamic Image Pyramid (DIP) integration. Our method introduces: (i)\na Region Focus Module (RFM) that leverages text-aware region localization\ncapability to identify critical vision tokens, and (ii) a coarse-to-fine image\ntile selection and vision token pruning strategy based on DIP, which is guided\nby RFM outputs and avoids directly processing the entire large imagery.\nAdditionally, existing benchmarks for evaluating LVLMs' perception ability on\nlarge RSI suffer from limited question diversity and constrained image sizes.\nWe construct a new benchmark named LRS-VQA, which contains 7,333 QA pairs\nacross 8 categories, with image length up to 27,328 pixels. Our method\noutperforms existing high-resolution strategies on four datasets using the same\ndata. Moreover, compared to existing token reduction methods, our approach\ndemonstrates higher efficiency under high-resolution settings. Dataset and code\nare in https://github.com/VisionXLab/LRS-VQA.",
      "tldr_zh": "该研究提出了一种文本引导的token剪枝方法，结合动态图像金字塔(DIP)，用于高效处理大规模遥感图像(RSIs)。方法包括：(1) 区域聚焦模块(RFM)，利用文本感知能力定位关键视觉token；(2) 基于DIP的从粗到细的图像分块选择和token剪枝策略，避免直接处理整张大图。此外，研究构建了新的基准数据集LRS-VQA，包含7,333个问答对，图像长度可达27,328像素。实验表明，该方法在四个数据集上优于现有高分辨率策略，并在高分辨率设置下展现出更高的效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.07588v2",
      "published_date": "2025-03-10 17:51:16 UTC",
      "updated_date": "2025-03-25 15:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:45:41.069657"
    },
    {
      "arxiv_id": "2503.07587v1",
      "title": "Robusto-1 Dataset: Comparing Humans and VLMs on real out-of-distribution Autonomous Driving VQA from Peru",
      "title_zh": "Robusto-1 数据集：比较人类与视觉语言模型在秘鲁真实分布外自动驾驶视觉问答中的表现",
      "authors": [
        "Dunant Cusipuma",
        "David Ortega",
        "Victor Flores-Benites",
        "Arturo Deza"
      ],
      "abstract": "As multimodal foundational models start being deployed experimentally in\nSelf-Driving cars, a reasonable question we ask ourselves is how similar to\nhumans do these systems respond in certain driving situations -- especially\nthose that are out-of-distribution? To study this, we create the Robusto-1\ndataset that uses dashcam video data from Peru, a country with one of the worst\n(aggressive) drivers in the world, a high traffic index, and a high ratio of\nbizarre to non-bizarre street objects likely never seen in training. In\nparticular, to preliminarly test at a cognitive level how well Foundational\nVisual Language Models (VLMs) compare to Humans in Driving, we move away from\nbounding boxes, segmentation maps, occupancy maps or trajectory estimation to\nmulti-modal Visual Question Answering (VQA) comparing both humans and machines\nthrough a popular method in systems neuroscience known as Representational\nSimilarity Analysis (RSA). Depending on the type of questions we ask and the\nanswers these systems give, we will show in what cases do VLMs and Humans\nconverge or diverge allowing us to probe on their cognitive alignment. We find\nthat the degree of alignment varies significantly depending on the type of\nquestions asked to each type of system (Humans vs VLMs), highlighting a gap in\ntheir alignment.",
      "tldr_zh": "该研究提出了Robusto-1数据集，通过秘鲁极端驾驶场景（以交通混乱和罕见道路物体著称）的实拍视频，首次系统比较人类与视觉语言模型(VLMs)在自动驾驶视觉问答(VQA)中的认知差异。采用系统神经科学中的表征相似性分析(RSA)方法，研究发现人类与VLM对各类驾驶问题的回答相似度存在显著波动，揭示了当前多模态基础模型在认知对齐方面的局限性。该数据集避开了传统的边界框或轨迹预测评估方式，为探究AI系统在分布外(OOD)驾驶场景中的真实理解能力提供了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "A pre-print. 26 pages. Link to Code + Data:\n  https://huggingface.co/datasets/Artificio/robusto-1",
      "pdf_url": "http://arxiv.org/pdf/2503.07587v1",
      "published_date": "2025-03-10 17:50:04 UTC",
      "updated_date": "2025-03-10 17:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:45:47.893662"
    },
    {
      "arxiv_id": "2503.07578v1",
      "title": "Denoising Score Distillation: From Noisy Diffusion Pretraining to One-Step High-Quality Generation",
      "title_zh": "去噪分数蒸馏：从噪声扩散预训练到一步高质量生成",
      "authors": [
        "Tianyu Chen",
        "Yasi Zhang",
        "Zhendong Wang",
        "Ying Nian Wu",
        "Oscar Leong",
        "Mingyuan Zhou"
      ],
      "abstract": "Diffusion models have achieved remarkable success in generating\nhigh-resolution, realistic images across diverse natural distributions.\nHowever, their performance heavily relies on high-quality training data, making\nit challenging to learn meaningful distributions from corrupted samples. This\nlimitation restricts their applicability in scientific domains where clean data\nis scarce or costly to obtain. In this work, we introduce denoising score\ndistillation (DSD), a surprisingly effective and novel approach for training\nhigh-quality generative models from low-quality data. DSD first pretrains a\ndiffusion model exclusively on noisy, corrupted samples and then distills it\ninto a one-step generator capable of producing refined, clean outputs. While\nscore distillation is traditionally viewed as a method to accelerate diffusion\nmodels, we show that it can also significantly enhance sample quality,\nparticularly when starting from a degraded teacher model. Across varying noise\nlevels and datasets, DSD consistently improves generative performancewe\nsummarize our empirical evidence in Fig. 1. Furthermore, we provide theoretical\ninsights showing that, in a linear model setting, DSD identifies the eigenspace\nof the clean data distributions covariance matrix, implicitly regularizing the\ngenerator. This perspective reframes score distillation as not only a tool for\nefficiency but also a mechanism for improving generative models, particularly\nin low-quality data settings.",
      "tldr_zh": "该论文提出了一种名为\"去噪分数蒸馏\"(Denoising Score Distillation, DSD)的新方法，能够从低质量噪声数据中训练出高质量生成模型。该方法首先在噪声数据上预训练扩散模型，然后将其蒸馏为可直接生成清晰图像的单步生成器。研究表明，与传统认知不同，分数蒸馏不仅能加速扩散模型，还能显著提升生成质量，特别适用于数据稀缺的科学领域。理论分析表明，在线性模型设定下，DSD能自动识别干净数据分布的特征空间，实现对生成器的隐式正则化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "First Author and Second Author contributed equally to this work. The\n  last two authors equally advised this work",
      "pdf_url": "http://arxiv.org/pdf/2503.07578v1",
      "published_date": "2025-03-10 17:44:46 UTC",
      "updated_date": "2025-03-10 17:44:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:45:40.555302"
    },
    {
      "arxiv_id": "2503.07701v1",
      "title": "Automated Benchmark Generation for Repository-Level Coding Tasks",
      "title_zh": "自动化基准生成技术用于仓库级编码任务",
      "authors": [
        "Konstantinos Vergopoulos",
        "Mark Niklas Müller",
        "Martin Vechev"
      ],
      "abstract": "Code Agent development is an extremely active research area, where a reliable\nperformance metric is critical for tracking progress and guiding new\ndevelopments. This demand is underscored by the meteoric rise in popularity of\nSWE-Bench. This benchmark challenges code agents to generate patches addressing\nGitHub issues given the full repository as context. The correctness of\ngenerated patches is then evaluated by executing a human-written test suite\nextracted from the repository after the issue's resolution. However,\nconstructing benchmarks like SWE-Bench requires substantial manual effort to\nset up historically accurate execution environments for testing. Crucially,\nthis severely limits the number of considered repositories, e.g., just 12 for\nSWE-Bench. Considering so few repositories, selected for their popularity runs\nthe risk of leading to a distributional mismatch, i.e., the measured\nperformance may not be representative of real-world scenarios potentially\nmisguiding development efforts. In this work, we address this challenge and\nintroduce SetUpAgent, a fully automated system capable of historically accurate\ndependency setup, test execution, and result parsing. Using SetUpAgent, we\ngenerate two new datasets: (i) SWEE-Bench an extended version of SWE-Bench\nencompassing hundreds of repositories, and (ii) SWA-Bench a benchmark focusing\non applications rather than libraries. Comparing these datasets to SWE-Bench\nwith respect to their characteristics and code agent performance, we find\nsignificant distributional differences, including lower issue description\nquality and detail level, higher fix complexity, and most importantly up to 40%\nlower agent success rates.",
      "tldr_zh": "该研究提出了SetUpAgent，一种全自动化系统，能够历史准确地设置依赖项、执行测试并解析结果，以解决代码代理（Code Agent）开发中基准测试构建效率低的问题。基于此，研究者生成了两个新数据集：SWEE-Bench（涵盖数百个仓库的扩展版本）和SWA-Bench（专注于应用程序的基准测试）。实验表明，与现有基准SWE-Bench相比，新数据集在问题描述质量、修复复杂性和代码代理成功率上存在显著差异，其中代理成功率最多降低40%，为更贴近真实场景的代码代理评估提供了重要工具。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at DL4C@ICLR'25 and FMWild@ICLR'25",
      "pdf_url": "http://arxiv.org/pdf/2503.07701v1",
      "published_date": "2025-03-10 17:42:49 UTC",
      "updated_date": "2025-03-10 17:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:45:48.049230"
    },
    {
      "arxiv_id": "2503.07572v1",
      "title": "Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning",
      "title_zh": "通过元强化微调优化测试时计算",
      "authors": [
        "Yuxiao Qu",
        "Matthew Y. R. Yang",
        "Amrith Setlur",
        "Lewis Tunstall",
        "Edward Emanuel Beeching",
        "Ruslan Salakhutdinov",
        "Aviral Kumar"
      ],
      "abstract": "Training models to effectively use test-time compute is crucial for improving\nthe reasoning performance of LLMs. Current methods mostly do so via fine-tuning\non search traces or running RL with 0/1 outcome reward, but do these approaches\nefficiently utilize test-time compute? Would these approaches continue to scale\nas the budget improves? In this paper, we try to answer these questions. We\nformalize the problem of optimizing test-time compute as a meta-reinforcement\nlearning (RL) problem, which provides a principled perspective on spending\ntest-time compute. This perspective enables us to view the long output stream\nfrom the LLM as consisting of several episodes run at test time and leads us to\nuse a notion of cumulative regret over output tokens as a way to measure the\nefficacy of test-time compute. Akin to how RL algorithms can best tradeoff\nexploration and exploitation over training, minimizing cumulative regret would\nalso provide the best balance between exploration and exploitation in the token\nstream. While we show that state-of-the-art models do not minimize regret, one\ncan do so by maximizing a dense reward bonus in conjunction with the outcome\n0/1 reward RL. This bonus is the ''progress'' made by each subsequent block in\nthe output stream, quantified by the change in the likelihood of eventual\nsuccess. Using these insights, we develop Meta Reinforcement Fine-Tuning, or\nMRT, a new class of fine-tuning methods for optimizing test-time compute. MRT\nleads to a 2-3x relative gain in performance and roughly a 1.5x gain in token\nefficiency for math reasoning compared to outcome-reward RL.",
      "tldr_zh": "本文提出了一种基于元强化学习（Meta Reinforcement Learning, RL）的测试时计算优化方法，称为元强化微调（Meta Reinforcement Fine-Tuning, MRT）。通过将测试时计算优化问题形式化为元RL问题，该方法将LLM的长输出流视为多个测试时片段，并使用累积遗憾（cumulative regret）来衡量计算效率。研究发现，现有模型未能最小化遗憾，而MRT通过结合密集奖励和0/1结果奖励，显著提升了数学推理任务中的性能（相对提升2-3倍）和token效率（提升约1.5倍）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07572v1",
      "published_date": "2025-03-10 17:40:43 UTC",
      "updated_date": "2025-03-10 17:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:45:58.236101"
    },
    {
      "arxiv_id": "2503.07568v1",
      "title": "Runtime Detection of Adversarial Attacks in AI Accelerators Using Performance Counters",
      "title_zh": "利用性能计数器实时检测AI加速器中的对抗攻击",
      "authors": [
        "Habibur Rahaman",
        "Atri Chatterjee",
        "Swarup Bhunia"
      ],
      "abstract": "Rapid adoption of AI technologies raises several major security concerns,\nincluding the risks of adversarial perturbations, which threaten the\nconfidentiality and integrity of AI applications. Protecting AI hardware from\nmisuse and diverse security threats is a challenging task. To address this\nchallenge, we propose SAMURAI, a novel framework for safeguarding against\nmalicious usage of AI hardware and its resilience to attacks. SAMURAI\nintroduces an AI Performance Counter (APC) for tracking dynamic behavior of an\nAI model coupled with an on-chip Machine Learning (ML) analysis engine, known\nas TANTO (Trained Anomaly Inspection Through Trace Observation). APC records\nthe runtime profile of the low-level hardware events of different AI\noperations. Subsequently, the summary information recorded by the APC is\nprocessed by TANTO to efficiently identify potential security breaches and\nensure secure, responsible use of AI. SAMURAI enables real-time detection of\nsecurity threats and misuse without relying on traditional software-based\nsolutions that require model integration. Experimental results demonstrate that\nSAMURAI achieves up to 97% accuracy in detecting adversarial attacks with\nmoderate overhead on various AI models, significantly outperforming\nconventional software-based approaches. It enhances security and regulatory\ncompliance, providing a comprehensive solution for safeguarding AI against\nemergent threats.",
      "tldr_zh": "该研究提出SAMURAI框架，通过AI性能计数器(APC)实时监测AI加速器的底层硬件事件动态，结合片上机器学习分析引擎TANTO进行异常检测。实验表明，该方案能以97%的准确率检测对抗攻击，显著优于传统软件方案，为AI硬件安全提供了低开销的运行时防护方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07568v1",
      "published_date": "2025-03-10 17:38:42 UTC",
      "updated_date": "2025-03-10 17:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:46:02.706573"
    },
    {
      "arxiv_id": "2503.07565v5",
      "title": "Inductive Moment Matching",
      "title_zh": "归纳矩匹配",
      "authors": [
        "Linqi Zhou",
        "Stefano Ermon",
        "Jiaming Song"
      ],
      "abstract": "Diffusion models and Flow Matching generate high-quality samples but are slow\nat inference, and distilling them into few-step models often leads to\ninstability and extensive tuning. To resolve these trade-offs, we propose\nInductive Moment Matching (IMM), a new class of generative models for one- or\nfew-step sampling with a single-stage training procedure. Unlike distillation,\nIMM does not require pre-training initialization and optimization of two\nnetworks; and unlike Consistency Models, IMM guarantees distribution-level\nconvergence and remains stable under various hyperparameters and standard model\narchitectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID\nusing only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98\non CIFAR-10 for a model trained from scratch.",
      "tldr_zh": "本文提出了Inductive Moment Matching (IMM)，一种新型生成模型，旨在解决扩散模型和Flow Matching在推理时速度慢的问题。与现有方法不同，IMM通过单阶段训练实现一步或少数步采样，无需预训练初始化或优化两个网络，同时保证分布级收敛性和超参数稳定性。实验表明，IMM在ImageNet-256x256上仅用8步推理即达到1.99 FID，并在CIFAR-10上以2步推理创下1.98 FID的领先水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07565v5",
      "published_date": "2025-03-10 17:37:39 UTC",
      "updated_date": "2025-03-25 06:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:46:10.127414"
    },
    {
      "arxiv_id": "2503.07700v1",
      "title": "A Task and Motion Planning Framework Using Iteratively Deepened AND/OR Graph Networks",
      "title_zh": "基于迭代深化AND/OR图网络的任务与运动规划框架",
      "authors": [
        "Hossein Karami",
        "Antony Thomas",
        "Fulvio Mastrogiovanni"
      ],
      "abstract": "In this paper, we present an approach for integrated task and motion planning\nbased on an AND/OR graph network, which is used to represent task-level states\nand actions, and we leverage it to implement different classes of task and\nmotion planning problems (TAMP). Several problems that fall under task and\nmotion planning do not have a predetermined number of sub-tasks to achieve a\ngoal. For example, while retrieving a target object from a cluttered workspace,\nin principle the number of object re-arrangements required to finally grasp it\ncannot be known ahead of time. To address this challenge, and in contrast to\ntraditional planners, also those based on AND/OR graphs, we grow the AND/OR\ngraph at run-time by progressively adding sub-graphs until grasping the target\nobject becomes feasible, which yields a network of AND/OR graphs. The approach\nis extended to enable multi-robot task and motion planning, and (i) it allows\nus to perform task allocation while coordinating the activity of a given number\nof robots, and (ii) can handle multi-robot tasks involving an a priori unknown\nnumber of sub-tasks. The approach is evaluated and validated both in simulation\nand with a real dual-arm robot manipulator, that is, Baxter from Rethink\nRobotics. In particular, for the single-robot task and motion planning, we\nvalidated our approach in three different TAMP domains. Furthermore, we also\nuse three different robots for simulation, namely, Baxter, Franka Emika Panda\nmanipulators, and a PR2 robot. Experiments show that our approach can be\nreadily scaled to scenarios with many objects and robots, and is capable of\nhandling different classes of TAMP problems.",
      "tldr_zh": "本文提出了一种基于迭代深化AND/OR图网络的任务与运动规划(TAMP)框架。该框架通过运行时动态扩展AND/OR子图网络来解决传统规划器无法预先确定子任务数量的问题，典型应用如杂乱工作空间中的目标物体抓取。方法支持多机器人任务分配和协调，并能处理子任务数量未知的复杂场景。实验在仿真环境和真实Baxter双臂机器人上验证了该框架在三个不同TAMP领域的有效性，证明其可扩展至多物体、多机器人场景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07700v1",
      "published_date": "2025-03-10 17:28:22 UTC",
      "updated_date": "2025-03-10 17:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:46:30.578180"
    },
    {
      "arxiv_id": "2503.07556v1",
      "title": "Junior Software Developers' Perspectives on Adopting LLMs for Software Engineering: a Systematic Literature Review",
      "title_zh": "初级软件开发人员对采用LLM进行软件工程的看法：系统性文献综述",
      "authors": [
        "Samuel Ferino",
        "Rashina Hoda",
        "John Grundy",
        "Christoph Treude"
      ],
      "abstract": "Many studies exploring the adoption of Large Language Model-based tools for\nsoftware development by junior developers have emerged in recent years. These\nstudies have sought to understand developers' perspectives about using those\ntools, a fundamental pillar for successfully adopting LLM-based tools in\nSoftware Engineering. The aim of this paper is to provide an overview of junior\nsoftware developers' perspectives and use of LLM-based tools for software\nengineering (LLM4SE). We conducted a systematic literature review (SLR)\nfollowing guidelines by Kitchenham et al. on 56 primary studies, applying the\ndefinition for junior software developers as software developers with equal or\nless than five years of experience, including Computer Science/Software\nEngineering students. We found that the majority of the studies focused on\ncomprehending the different aspects of integrating AI tools in SE. Only 8.9\\%\nof the studies provide a clear definition for junior software developers, and\nthere is no uniformity. Searching for relevant information is the most common\ntask using LLM tools. ChatGPT was the most common LLM tool present in the\nstudies (and experiments). A majority of the studies (83.9\\%) report both\npositive and negative perceptions about the impact of adopting LLM tools. We\nalso found and categorised advantages, challenges, and recommendations\nregarding LLM adoption. Our results indicate that developers are using LLMs not\njust for code generation, but also to improve their development skills.\nCritically, they are not just experiencing the benefits of adopting LLM tools,\nbut they are also aware of at least a few LLM limitations, such as the\ngeneration of wrong suggestions, potential data leaking, and AI hallucination.\nOur findings offer implications for software engineering researchers,\neducators, and developers.",
      "tldr_zh": "这篇论文通过系统文献综述(SLR)研究了初级软件开发者对基于大语言模型(LLM)开发工具的使用态度。研究发现：83.9%的研究既报告了LLM工具的积极影响(如提升开发技能)，也指出了其局限性(如错误建议、数据泄露风险)；ChatGPT是最常用的工具，而信息检索是最主要的应用场景。研究结果为软件工程教育者和研究者提供了LLM工具采纳的重要参考依据。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07556v1",
      "published_date": "2025-03-10 17:25:24 UTC",
      "updated_date": "2025-03-10 17:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:46:53.569867"
    },
    {
      "arxiv_id": "2503.13492v1",
      "title": "Event-Driven Implementation of a Physical Reservoir Computing Framework for superficial EMG-based Gesture Recognition",
      "title_zh": "基于表面肌电信号手势识别的事件驱动物理储备计算框架实现",
      "authors": [
        "Yuqi Ding",
        "Elisa Donati",
        "Haobo Li",
        "Hadi Heidari"
      ],
      "abstract": "Wearable health devices have a strong demand in real-time biomedical signal\nprocessing. However traditional methods often require data transmission to\ncentralized processing unit with substantial computational resources after\ncollecting it from edge devices. Neuromorphic computing is an emerging field\nthat seeks to design specialized hardware for computing systems inspired by the\nstructure, function, and dynamics of the human brain, offering significant\nadvantages in latency and power consumption. This paper explores a novel\nneuromorphic implementation approach for gesture recognition by extracting\nspatiotemporal spiking information from surface electromyography (sEMG) data in\nan event-driven manner. At the same time, the network was designed by\nimplementing a simple-structured and hardware-friendly Physical Reservoir\nComputing (PRC) framework called Rotating Neuron Reservoir (RNR) within the\ndomain of Spiking neural network (SNN). The spiking RNR (sRNR) is promising to\npipeline an innovative solution to compact embedded wearable systems, enabling\nlow-latency, real-time processing directly at the sensor level. The proposed\nsystem was validated by an open-access large-scale sEMG database and achieved\nan average classification accuracy of 74.6\\% and 80.3\\% using a classical\nmachine learning classifier and a delta learning rule algorithm respectively.\nWhile the delta learning rule could be fully spiking and implementable on\nneuromorphic chips, the proposed gesture recognition system demonstrates the\npotential for near-sensor low-latency processing.",
      "tldr_zh": "本文提出了一种基于事件驱动方式的物理储备池计算(PRC)框架，用于表面肌电(sEMG)手势识别。该研究采用旋转神经元储备池(RNR)结构构建脉冲神经网络(SNN)，实现了硬件友好的神经形态计算方案。实验表明，该系统在开放sEMG数据库上分别达到74.6%和80.3%的分类准确率，验证了在传感器端实现低延迟实时处理的可行性，为可穿戴医疗设备提供了创新的嵌入式解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "eess.SP",
      "comment": "11 pages, 9 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2503.13492v1",
      "published_date": "2025-03-10 17:18:14 UTC",
      "updated_date": "2025-03-10 17:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:46:55.003480"
    },
    {
      "arxiv_id": "2503.07550v1",
      "title": "KSOD: Knowledge Supplement for LLMs On Demand",
      "title_zh": "KSOD：面向大语言模型的知识按需补充",
      "authors": [
        "Haoran Li",
        "Junfeng Hu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks, yet still produce errors in domain-specific tasks. To further\nimprove their performance, we propose KSOD (Knowledge Supplement for LLMs On\nDemand), a novel framework that empowers LLMs to improve their capabilities\nwith knowledge-based supervised fine-tuning (SFT). KSOD analyzes the causes of\nerrors from the perspective of knowledge deficiency by identifying potential\nmissing knowledge in LLM that may lead to the errors. Subsequently, KSOD tunes\na knowledge module on knowledge dataset and verifies whether the LLM lacks the\nidentified knowledge based on it. If the knowledge is verified, KSOD\nsupplements the LLM with the identified knowledge using the knowledge module.\nTuning LLMs on specific knowledge instead of specific task decouples task and\nknowledge and our experiments on two domain-specific benchmarks and four\ngeneral benchmarks empirically demonstrate that KSOD enhances the performance\nof LLMs on tasks requiring the supplemented knowledge while preserving their\nperformance on other tasks. Our findings shed light on the potential of\nimproving the capabilities of LLMs with knowledge-based SFT.",
      "tldr_zh": "该研究提出KSOD框架，通过知识监督微调(SFT)解决LLMs在特定领域任务中的知识缺失问题。系统首先诊断错误原因并识别缺失知识，随后在知识数据集上微调知识模块进行验证和补充。实验表明，该方法能在不损害其他任务性能的前提下，显著提升LLMs在目标知识相关任务的表现，为基于知识的LLMs能力增强提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07550v1",
      "published_date": "2025-03-10 17:17:41 UTC",
      "updated_date": "2025-03-10 17:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:47:09.426369"
    },
    {
      "arxiv_id": "2503.07545v1",
      "title": "Queueing, Predictions, and LLMs: Challenges and Open Problems",
      "title_zh": "排队、预测与大型语言模型：挑战与开放性问题",
      "authors": [
        "Michael Mitzenmacher",
        "Rana Shahout"
      ],
      "abstract": "Queueing systems present many opportunities for applying machine-learning\npredictions, such as estimated service times, to improve system performance.\nThis integration raises numerous open questions about how predictions can be\neffectively leveraged to improve scheduling decisions. Recent studies explore\nqueues with predicted service times, typically aiming to minimize job time in\nthe system. We review these works, highlight the effectiveness of predictions,\nand present open questions on queue performance. We then move to consider an\nimportant practical example of using predictions in scheduling, namely Large\nLanguage Model (LLM) systems, which presents novel scheduling challenges and\nhighlights the potential for predictions to improve performance. In particular,\nwe consider LLMs performing inference. Inference requests (jobs) in LLM systems\nare inherently complex; they have variable inference times, dynamic memory\nfootprints that are constrained by key-value (KV) store memory limitations, and\nmultiple possible preemption approaches that affect performance differently. We\nprovide background on the important aspects of scheduling in LLM systems, and\nintroduce new models and open problems that arise from them. We argue that\nthere are significant opportunities for applying insights and analysis from\nqueueing theory to scheduling in LLM systems.",
      "tldr_zh": "该论文探讨了排队系统中利用机器学习预测（如预估服务时间）来优化调度决策的挑战与开放性问题。研究首先回顾了基于预测服务时间的队列优化方法及其效果，随后聚焦于大型语言模型（LLM）推理任务这一典型场景，指出其特有的调度挑战：推理请求具有可变时长、受KV存储限制的动态内存占用，以及不同抢占方式带来的性能差异。作者提出了适用于LLM系统的新调度模型，并强调排队理论在该领域具有重要应用潜力，同时系统梳理了待解决的核心问题。",
      "categories": [
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07545v1",
      "published_date": "2025-03-10 17:12:47 UTC",
      "updated_date": "2025-03-10 17:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:47:21.016846"
    },
    {
      "arxiv_id": "2503.07541v1",
      "title": "Geometric Retargeting: A Principled, Ultrafast Neural Hand Retargeting Algorithm",
      "title_zh": "几何重定向：一种原理化、超快速的神经手部重定向算法",
      "authors": [
        "Zhao-Heng Yin",
        "Changhao Wang",
        "Luis Pineda",
        "Krishna Bodduluri",
        "Tingfan Wu",
        "Pieter Abbeel",
        "Mustafa Mukadam"
      ],
      "abstract": "We introduce Geometric Retargeting (GeoRT), an ultrafast, and principled\nneural hand retargeting algorithm for teleoperation, developed as part of our\nrecent Dexterity Gen (DexGen) system. GeoRT converts human finger keypoints to\nrobot hand keypoints at 1KHz, achieving state-of-the-art speed and accuracy\nwith significantly fewer hyperparameters. This high-speed capability enables\nflexible postprocessing, such as leveraging a foundational controller for\naction correction like DexGen. GeoRT is trained in an unsupervised manner,\neliminating the need for manual annotation of hand pairs. The core of GeoRT\nlies in novel geometric objective functions that capture the essence of\nretargeting: preserving motion fidelity, ensuring configuration space (C-space)\ncoverage, maintaining uniform response through high flatness, pinch\ncorrespondence and preventing self-collisions. This approach is free from\nintensive test-time optimization, offering a more scalable and practical\nsolution for real-time hand retargeting.",
      "tldr_zh": "该研究提出了几何重定向(GeoRT)，一种基于几何目标函数的超快速神经手部重定向算法，用于远程操作。GeoRT以1KHz的速度将人类手指关键点转换为机器人手关键点，在减少超参数的同时实现了最先进的精度和速度。其无监督训练方式无需手动标注手对数据，并通过新颖的几何目标函数确保运动保真度、配置空间覆盖和均匀响应等核心特性。该算法无需密集的测试时优化，为实时手部重定向提供了更具扩展性和实用性的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Website: https://zhaohengyin.github.io/geort",
      "pdf_url": "http://arxiv.org/pdf/2503.07541v1",
      "published_date": "2025-03-10 17:10:21 UTC",
      "updated_date": "2025-03-10 17:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:47:30.789493"
    },
    {
      "arxiv_id": "2503.07540v1",
      "title": "AI-Enabled Knowledge Sharing for Enhanced Collaboration and Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review Protocol",
      "title_zh": "人工智能赋能知识共享提升非营利性医疗机构协作与决策能力：范围综述研究方案",
      "authors": [
        "Maurice Ongala",
        "Ruth Kiraka",
        "Jyoti Choundrie",
        "Javan Okello"
      ],
      "abstract": "This protocol outlines a scoping review designed to systematically map the\nexisting body of evidence on AI-enabled knowledge sharing in resource-limited\nnon-profit healthcare organizations. The review aims to investigate how such\ntechnologies enhance collaboration and decision-making, particularly in the\ncontext of reduced external support following the cessation of USAID\noperations. Guided by three theoretical frameworks namely, the Resource-Based\nView, Dynamic Capabilities Theory, and Absorptive Capacity Theory, this study\nwill explore the dual role of AI as a strategic resource and an enabler of\norganizational learning and agility. The protocol details a rigorous\nmethodological approach based on PRISMA-ScR guidelines, encompassing a\nsystematic search strategy across multiple databases, inclusion and exclusion\ncriteria, and a structured data extraction process. By integrating theoretical\ninsights with empirical evidence, this scoping review seeks to identify\ncritical gaps in the literature and inform the design of effective,\nresource-optimized AI solutions in non-profit healthcare settings.",
      "tldr_zh": "本研究提出了一项范围综述（scoping review）协议，旨在系统梳理资源有限的非营利医疗机构中AI知识共享技术的应用现状。该研究基于资源基础观（RBV）、动态能力理论和吸收能力理论三大框架，重点分析AI如何作为战略资源和组织学习促进者，提升协作与决策能力，特别是在美国国际开发署（USAID）撤资后的背景下。研究采用PRISMA-ScR指南，通过多数据库系统检索和结构化数据提取，致力于识别文献缺口，并为非营利医疗环境设计资源优化的AI解决方案提供理论依据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07540v1",
      "published_date": "2025-03-10 17:09:12 UTC",
      "updated_date": "2025-03-10 17:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:48:34.117010"
    },
    {
      "arxiv_id": "2503.07536v2",
      "title": "LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL",
      "title_zh": "LMM-R1：通过两阶段基于规则的强化学习赋能3B参数大模型，提升其强大的推理能力",
      "authors": [
        "Yingzhe Peng",
        "Gongrui Zhang",
        "Miaosen Zhang",
        "Zhiyuan You",
        "Jie Liu",
        "Qipeng Zhu",
        "Kai Yang",
        "Xingzhong Xu",
        "Xin Geng",
        "Xu Yang"
      ],
      "abstract": "Enhancing reasoning in Large Multimodal Models (LMMs) faces unique challenges\nfrom the complex interplay between visual perception and logical reasoning,\nparticularly in compact 3B-parameter architectures where architectural\nconstraints limit reasoning capacity and modality alignment.\n  While rule-based reinforcement learning (RL) excels in text-only domains, its\nmultimodal extension confronts two critical barriers: (1) data limitations due\nto ambiguous answers and scarce complex reasoning examples, and (2) degraded\nfoundational reasoning induced by multimodal pretraining. To address these\nchallenges, we propose \\textbf{LMM-R1}, a two-stage framework adapting\nrule-based RL for multimodal reasoning through \\textbf{Foundational Reasoning\nEnhancement (FRE)} followed by \\textbf{Multimodal Generalization Training\n(MGT)}. The FRE stage first strengthens reasoning abilities using text-only\ndata with rule-based RL, then the MGT stage generalizes these reasoning\ncapabilities to multimodal domains.\n  Experiments on Qwen2.5-VL-Instruct-3B demonstrate that LMM-R1 achieves 4.83\\%\nand 4.5\\% average improvements over baselines in multimodal and text-only\nbenchmarks, respectively, with a 3.63\\% gain in complex Football Game tasks.\nThese results validate that text-based reasoning enhancement enables effective\nmultimodal generalization, offering a data-efficient paradigm that bypasses\ncostly high-quality multimodal training data.",
      "tldr_zh": "该研究提出了LMM-R1，一种通过两阶段规则强化学习(Rule-Based RL)增强3B参数规模大模型(LMMs)推理能力的框架。针对多模态推理中数据稀缺和基础推理能力退化的问题，LMM-R1首先在文本数据上进行基础推理增强(FRE)，随后通过多模态泛化训练(MGT)扩展到多模态领域。实验表明，该框架在多模态和文本基准上分别提升了4.83%和4.5%的性能，尤其在复杂任务中表现显著，为低成本高效提升多模态模型推理能力提供了新范式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07536v2",
      "published_date": "2025-03-10 17:04:14 UTC",
      "updated_date": "2025-03-11 03:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:47:48.060608"
    },
    {
      "arxiv_id": "2503.07693v1",
      "title": "Fully Autonomous Programming using Iterative Multi-Agent Debugging with Large Language Models",
      "title_zh": "完全自主编程：基于大型语言模型的迭代多智能体调试方法",
      "authors": [
        "Anastasiia Grishina",
        "Vadim Liventsev",
        "Aki Härmä",
        "Leon Moonen"
      ],
      "abstract": "Program synthesis with Large Language Models (LLMs) suffers from a \"near-miss\nsyndrome\": the generated code closely resembles a correct solution but fails\nunit tests due to minor errors. We address this with a multi-agent framework\ncalled Synthesize, Execute, Instruct, Debug, and Repair (SEIDR). Effectively\napplying SEIDR to instruction-tuned LLMs requires determining (a) optimal\nprompts for LLMs, (b) what ranking algorithm selects the best programs in\ndebugging rounds, and (c) balancing the repair of unsuccessful programs with\nthe generation of new ones. We empirically explore these trade-offs by\ncomparing replace-focused, repair-focused, and hybrid debug strategies. We also\nevaluate lexicase and tournament selection to rank candidates in each\ngeneration. On Program Synthesis Benchmark 2 (PSB2), our framework outperforms\nboth conventional use of OpenAI Codex without a repair phase and traditional\ngenetic programming approaches. SEIDR outperforms the use of an LLM alone,\nsolving 18 problems in C++ and 20 in Python on PSB2 at least once across\nexperiments. To assess generalizability, we employ GPT-3.5 and Llama 3 on the\nPSB2 and HumanEval-X benchmarks. Although SEIDR with these models does not\nsurpass current state-of-the-art methods on the Python benchmarks, the results\non HumanEval-C++ are promising. SEIDR with Llama 3-8B achieves an average\npass@100 of 84.2%. Across all SEIDR runs, 163 of 164 problems are solved at\nleast once with GPT-3.5 in HumanEval-C++, and 162 of 164 with the smaller Llama\n3-8B. We conclude that SEIDR effectively overcomes the near-miss syndrome in\nprogram synthesis with LLMs.",
      "tldr_zh": "该研究提出SEIDR框架（合成-执行-指导-调试-修复），通过多智能体协作解决大语言模型(LLMs)编程中的\"近似正确综合征\"问题。该框架采用迭代调试策略，比较了替换优先、修复优先和混合调试方法，并测试了lexicase与锦标赛选择两种候选程序排序算法。实验表明，SEIDR在PSB2基准测试中优于单独使用Codex和传统遗传编程方法，使用GPT-3.5和Llama 3-8B模型时，在HumanEval-C++测试中分别解决了163/164和162/164个问题，其中Llama 3-8B平均pass@100达到84.2%。该框架显著提升了LLMs程序合成的可靠性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in ACM Trans. Evol. Learn. Optim., February\n  2025. arXiv admin note: text overlap with arXiv:2304.10423",
      "pdf_url": "http://arxiv.org/pdf/2503.07693v1",
      "published_date": "2025-03-10 16:56:51 UTC",
      "updated_date": "2025-03-10 16:56:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:48:10.231807"
    },
    {
      "arxiv_id": "2503.10673v1",
      "title": "ZeroSumEval: An Extensible Framework For Scaling LLM Evaluation with Inter-Model Competition",
      "title_zh": "ZeroSumEval：基于模型间竞争的扩展性大语言模型评估框架",
      "authors": [
        "Hisham A. Alyahya",
        "Haidar Khan",
        "Yazeed Alnumay",
        "M Saiful Bari",
        "Bülent Yener"
      ],
      "abstract": "We introduce ZeroSumEval, a dynamic, competition-based, and evolving\nevaluation framework for Large Language Models (LLMs) that leverages\ncompetitive games. ZeroSumEval encompasses a diverse suite of games, including\nsecurity challenges (Capture the Flag), classic board games (chess), and\nknowledge tests (MathQuiz). These games are designed to evaluate a range of\ncapabilities such as strategic reasoning, planning, knowledge application,\nsafety, and adaptability. Building upon recent studies that highlight the\neffectiveness of game-based evaluations for LLMs, ZeroSumEval enhances these\napproaches by providing a standardized and extensible framework for easily\nimplementing games and leverages DSPy to provide a better abstraction for LLM\nplayer strategies.",
      "tldr_zh": "该研究提出了ZeroSumEval，一个基于竞争游戏的可扩展评估框架，用于大规模语言模型(LLMs)的动态评估。该框架包含多种游戏，如安全挑战(夺旗)、经典棋盘游戏(国际象棋)和知识测试(数学测验)，旨在评估模型的战略推理、规划、知识应用、安全性和适应性等能力。ZeroSumEval通过标准化和可扩展的设计，结合DSPy技术，为LLM策略提供了更好的抽象，从而提升评估的效率和灵活性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10673v1",
      "published_date": "2025-03-10 16:54:27 UTC",
      "updated_date": "2025-03-10 16:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:48:27.407516"
    },
    {
      "arxiv_id": "2503.07518v1",
      "title": "TokenButler: Token Importance is Predictable",
      "title_zh": "TokenButler：可预测的令牌重要性",
      "authors": [
        "Yash Akhauri",
        "Ahmed F AbouElhamayed",
        "Yifei Gao",
        "Chi-Chih Chang",
        "Nilesh Jain",
        "Mohamed S. Abdelfattah"
      ],
      "abstract": "Large Language Models (LLMs) rely on the Key-Value (KV) Cache to store token\nhistory, enabling efficient decoding of tokens. As the KV-Cache grows, it\nbecomes a major memory and computation bottleneck, however, there is an\nopportunity to alleviate this bottleneck, especially because prior research has\nshown that only a small subset of tokens contribute meaningfully to each\ndecoding step. A key challenge in finding these critical tokens is that they\nare dynamic, and heavily input query-dependent. Existing methods either risk\nquality by evicting tokens permanently, or retain the full KV-Cache but rely on\nretrieving chunks (pages) of tokens at generation, failing at dense,\ncontext-rich tasks. Additionally, many existing KV-Cache sparsity methods rely\non inaccurate proxies for token importance. To address these limitations, we\nintroduce TokenButler, a high-granularity, query-aware predictor that learns to\nidentify these critical tokens. By training a light-weight predictor with less\nthan 1.2% parameter overhead, TokenButler prioritizes tokens based on their\ncontextual, predicted importance. This improves perplexity & downstream\naccuracy by over 8% relative to SoTA methods for estimating token importance.\nWe evaluate TokenButler on a novel synthetic small-context co-referential\nretrieval task, demonstrating near-oracle accuracy. Code, models and\nbenchmarks: https://github.com/abdelfattah-lab/TokenButler",
      "tldr_zh": "该论文提出了TokenButler，一种基于轻量级预测器的KV-Cache优化方法，能够动态预测token重要性以缓解大语言模型(LLMs)的内存和计算瓶颈。通过训练仅增加1.2%参数量的小型预测器，该方法实现了比现有技术高8%的困惑度(perplexity)和下游任务准确率提升。在新型小上下文共指检索任务上的实验表明，TokenButler能达到接近理论最优的准确率，为LLM的高效推理提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07518v1",
      "published_date": "2025-03-10 16:41:14 UTC",
      "updated_date": "2025-03-10 16:41:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:48:14.748437"
    },
    {
      "arxiv_id": "2503.07690v1",
      "title": "Artificial Intelligence in Deliberation: The AI Penalty and the Emergence of a New Deliberative Divide",
      "title_zh": "人工智能在审议中的作用：AI惩罚与新审议鸿沟的出现",
      "authors": [
        "Andreas Jungherr",
        "Adrian Rauchfleisch"
      ],
      "abstract": "Digital deliberation has expanded democratic participation, yet challenges\nremain. This includes processing information at scale, moderating discussions,\nfact-checking, or attracting people to participate. Recent advances in\nartificial intelligence (AI) offer potential solutions, but public perceptions\nof AI's role in deliberation remain underexplored. Beyond efficiency,\ndemocratic deliberation is about voice and recognition. If AI is integrated\ninto deliberation, public trust, acceptance, and willingness to participate may\nbe affected. We conducted a preregistered survey experiment with a\nrepresentative sample in Germany (n=1850) to examine how information about\nAI-enabled deliberation influences willingness to participate and perceptions\nof deliberative quality. Respondents were randomly assigned to treatments that\nprovided them information about deliberative tasks facilitated by either AI or\nhumans. Our findings reveal a significant AI-penalty. Participants were less\nwilling to engage in AI-facilitated deliberation and rated its quality lower\nthan human-led formats. These effects were moderated by individual\npredispositions. Perceptions of AI's societal benefits and anthropomorphization\nof AI showed positive interaction effects on people's interest to participate\nin AI-enabled deliberative formats and positive quality assessments, while AI\nrisk assessments showed negative interactions with information about AI-enabled\ndeliberation. These results suggest AI-enabled deliberation faces substantial\npublic skepticism, potentially even introducing a new deliberative divide.\nUnlike traditional participation gaps based on education or demographics, this\ndivide is shaped by attitudes toward AI. As democratic engagement increasingly\nmoves online, ensuring AI's role in deliberation does not discourage\nparticipation or deepen inequalities will be a key challenge for future\nresearch and policy.",
      "tldr_zh": "该研究通过德国代表性样本调查(n=1850)揭示了人工智能在民主审议中的\"AI惩罚\"现象。研究发现，相比人工主持的审议，公众对AI辅助的审议参与意愿更低且质量评价更差，这种效应受到个人对AI态度的影响：认同AI社会效益者反应更积极，而担忧AI风险者抵触更强。研究警告这可能形成基于AI态度的新型审议鸿沟，不同于传统教育或人口统计学差异造成的参与不平等，为数字时代民主参与的设计提出了关键挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07690v1",
      "published_date": "2025-03-10 16:33:15 UTC",
      "updated_date": "2025-03-10 16:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:48:29.595263"
    },
    {
      "arxiv_id": "2503.07513v2",
      "title": "Language Models Fail to Introspect About Their Knowledge of Language",
      "title_zh": "语言模型无法内省其语言知识",
      "authors": [
        "Siyuan Song",
        "Jennifer Hu",
        "Kyle Mahowald"
      ],
      "abstract": "There has been recent interest in whether large language models (LLMs) can\nintrospect about their own internal states. Such abilities would make LLMs more\ninterpretable, and also validate the use of standard introspective methods in\nlinguistics to evaluate grammatical knowledge in models (e.g., asking \"Is this\nsentence grammatical?\"). We systematically investigate emergent introspection\nacross 21 open-source LLMs, in two domains where introspection is of\ntheoretical interest: grammatical knowledge and word prediction. Crucially, in\nboth domains, a model's internal linguistic knowledge can be theoretically\ngrounded in direct measurements of string probability. We then evaluate whether\nmodels' responses to metalinguistic prompts faithfully reflect their internal\nknowledge. We propose a new measure of introspection: the degree to which a\nmodel's prompted responses predict its own string probabilities, beyond what\nwould be predicted by another model with nearly identical internal knowledge.\nWhile both metalinguistic prompting and probability comparisons lead to high\ntask accuracy, we do not find evidence that LLMs have privileged \"self-access\".\nOur findings complicate recent results suggesting that models can introspect,\nand add new evidence to the argument that prompted responses should not be\nconflated with models' linguistic generalizations.",
      "tldr_zh": "该研究系统性评估了21个开源大语言模型(LLMs)在语法知识和词汇预测两个领域中的自我反省能力。通过对比模型对元语言提示的响应与其内部字符串概率的直接测量，研究发现LLMs并未展现出对自身语言知识的特权访问。尽管元语言提示和概率比较都能实现高任务准确率，但结果表明，模型无法真实反映其内部语言知识，提示响应不应等同于模型的语言泛化能力。这一发现对近期认为模型具有自我反省能力的研究提出了质疑。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Corrected Fig 5a and removed unused figures from source files",
      "pdf_url": "http://arxiv.org/pdf/2503.07513v2",
      "published_date": "2025-03-10 16:33:14 UTC",
      "updated_date": "2025-03-12 03:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:48:29.862443"
    },
    {
      "arxiv_id": "2503.07509v1",
      "title": "Interference-Aware Super-Constellation Design for NOMA",
      "title_zh": "面向非正交多址的干扰感知超星座设计",
      "authors": [
        "Mojtaba Vaezi",
        "Xinliang Zhang"
      ],
      "abstract": "Non-orthogonal multiple access (NOMA) has gained significant attention as a\npotential next-generation multiple access technique. However, its\nimplementation with finite-alphabet inputs faces challenges. Particularly, due\nto inter-user interference, superimposed constellations may have overlapping\nsymbols leading to high bit error rates when successive interference\ncancellation (SIC) is applied. To tackle the issue, this paper employs\nautoencoders to design interference-aware super-constellations. Unlike\nconventional methods where superimposed constellation may have overlapping\nsymbols, the proposed autoencoder-based NOMA (AE-NOMA) is trained to design\nsuper-constellations with distinguishable symbols at receivers, regardless of\nchannel gains. The proposed architecture removes the need for SIC, allowing\nmaximum likelihood-based approaches to be used instead. The paper presents the\nconceptual architecture, loss functions, and training strategies for AE-NOMA.\nVarious test results are provided to demonstrate the effectiveness of\ninterference-aware constellations in improving the bit error rate, indicating\nthe adaptability of AE-NOMA to different channel scenarios and its promising\npotential for implementing NOMA systems",
      "tldr_zh": "本文提出了一种基于自编码器（Autoencoder）的干扰感知超星座设计方法（AE-NOMA），以解决非正交多址接入（NOMA）系统中有限字母输入导致的符号重叠问题。与传统方法不同，AE-NOMA通过训练设计出在接收端可区分的超星座，无需依赖连续干扰消除（SIC），而是采用最大似然检测方法。实验结果表明，该方法在不同信道场景下显著降低了误码率，展现了其在NOMA系统中的潜力。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Accepted for publication at IEEE International Conference on\n  Communications (ICC), 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07509v1",
      "published_date": "2025-03-10 16:31:33 UTC",
      "updated_date": "2025-03-10 16:31:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:05.827612"
    },
    {
      "arxiv_id": "2503.07505v1",
      "title": "From Centralized to Decentralized Federated Learning: Theoretical Insights, Privacy Preservation, and Robustness Challenges",
      "title_zh": "从集中式到去中心化联邦学习：理论见解、隐私保护与鲁棒性挑战",
      "authors": [
        "Qiongxiu Li",
        "Wenrui Yu",
        "Yufei Xia",
        "Jun Pang"
      ],
      "abstract": "Federated Learning (FL) enables collaborative learning without directly\nsharing individual's raw data. FL can be implemented in either a centralized\n(server-based) or decentralized (peer-to-peer) manner. In this survey, we\npresent a novel perspective: the fundamental difference between centralized FL\n(CFL) and decentralized FL (DFL) is not merely the network topology, but the\nunderlying training protocol: separate aggregation vs. joint optimization. We\nargue that this distinction in protocol leads to significant differences in\nmodel utility, privacy preservation, and robustness to attacks. We\nsystematically review and categorize existing works in both CFL and DFL\naccording to the type of protocol they employ. This taxonomy provides deeper\ninsights into prior research and clarifies how various approaches relate or\ndiffer. Through our analysis, we identify key gaps in the literature. In\nparticular, we observe a surprising lack of exploration of DFL approaches based\non distributed optimization methods, despite their potential advantages. We\nhighlight this under-explored direction and call for more research on\nleveraging distributed optimization for federated learning. Overall, this work\noffers a comprehensive overview from centralized to decentralized FL, sheds new\nlight on the core distinctions between approaches, and outlines open challenges\nand future directions for the field.",
      "tldr_zh": "这篇综述论文提出，集中式联邦学习(CFL)与去中心化联邦学习(DFL)的核心区别在于训练协议：前者采用分离聚合(separate aggregation)而后者采用联合优化(joint optimization)。作者建立了基于协议类型的新型分类法，系统梳理了现有研究，揭示出分布式优化方法在DFL中的研究严重不足。论文不仅阐明了不同方法在模型效用、隐私保护和抗攻击性方面的差异，还指出了这一领域的关键研究空白和未来方向，为联邦学习从集中式到去中心化的演进提供了理论框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07505v1",
      "published_date": "2025-03-10 16:27:40 UTC",
      "updated_date": "2025-03-10 16:27:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:06.785961"
    },
    {
      "arxiv_id": "2503.07493v1",
      "title": "V2Flow: Unifying Visual Tokenization and Large Language Model Vocabularies for Autoregressive Image Generation",
      "title_zh": "V2Flow：统一视觉标记化与大型语言模型词汇，实现自回归图像生成",
      "authors": [
        "Guiwei Zhang",
        "Tianyu Zhang",
        "Mohan Zhou",
        "Yalong Bai",
        "Biye Li"
      ],
      "abstract": "We propose V2Flow, a novel tokenizer that produces discrete visual tokens\ncapable of high-fidelity reconstruction, while ensuring structural and latent\ndistribution alignment with the vocabulary space of large language models\n(LLMs). Leveraging this tight visual-vocabulary coupling, V2Flow enables\nautoregressive visual generation on top of existing LLMs. Our approach\nformulates visual tokenization as a flow-matching problem, aiming to learn a\nmapping from a standard normal prior to the continuous image distribution,\nconditioned on token sequences embedded within the LLMs vocabulary space. The\neffectiveness of V2Flow stems from two core designs. First, we propose a Visual\nVocabulary resampler, which compresses visual data into compact token\nsequences, with each represented as a soft categorical distribution over LLM's\nvocabulary. This allows seamless integration of visual tokens into existing\nLLMs for autoregressive visual generation. Second, we present a masked\nautoregressive Rectified-Flow decoder, employing a masked transformer\nencoder-decoder to refine visual tokens into contextually enriched embeddings.\nThese embeddings then condition a dedicated velocity field for precise\nreconstruction. Additionally, an autoregressive rectified-flow sampling\nstrategy is incorporated, ensuring flexible sequence lengths while preserving\ncompetitive reconstruction quality. Extensive experiments show that V2Flow\noutperforms mainstream VQ-based tokenizers and facilitates autoregressive\nvisual generation on top of existing. https://github.com/zhangguiwei610/V2Flow",
      "tldr_zh": "该研究提出V2Flow，一种新型视觉标记化方法，通过流匹配(flow-matching)技术将图像分布映射到大型语言模型(LLM)的词表空间，实现二者的结构和潜在分布对齐。该方法包含两个核心创新：1)视觉词表重采样器将视觉数据压缩为基于LLM词表的软分类分布序列；2)掩码自回归整流流解码器通过条件速度场实现精确重建。实验表明，V2Flow在自回归图像生成任务上优于主流VQ-based方法，并可直接利用现有LLM进行视觉生成。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07493v1",
      "published_date": "2025-03-10 16:12:50 UTC",
      "updated_date": "2025-03-10 16:12:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:14.954170"
    },
    {
      "arxiv_id": "2503.07482v1",
      "title": "Efficient Membership Inference Attacks by Bayesian Neural Network",
      "title_zh": "基于贝叶斯神经网络的高效成员推理攻击",
      "authors": [
        "Zhenlong Liu",
        "Wenyu Jiang",
        "Feng Zhou",
        "Hongxin Wei"
      ],
      "abstract": "Membership Inference Attacks (MIAs) aim to estimate whether a specific data\npoint was used in the training of a given model. Previous attacks often utilize\nmultiple reference models to approximate the conditional score distribution,\nleading to significant computational overhead. While recent work leverages\nquantile regression to estimate conditional thresholds, it fails to capture\nepistemic uncertainty, resulting in bias in low-density regions. In this work,\nwe propose a novel approach - Bayesian Membership Inference Attack (BMIA),\nwhich performs conditional attack through Bayesian inference. In particular, we\ntransform a trained reference model into Bayesian neural networks by Laplace\napproximation, enabling the direct estimation of the conditional score\ndistribution by probabilistic model parameters. Our method addresses both\nepistemic and aleatoric uncertainty with only a reference model, enabling\nefficient and powerful MIA. Extensive experiments on five datasets demonstrate\nthe effectiveness and efficiency of BMIA.",
      "tldr_zh": "本文提出了一种基于贝叶斯神经网络的高效成员推理攻击方法（BMIA），旨在判断特定数据点是否被用于训练给定模型。传统方法依赖多个参考模型来近似条件得分分布，计算开销较大，而现有基于分位数回归的方法无法捕捉认知不确定性，导致低密度区域的偏差。BMIA通过拉普拉斯近似将训练好的参考模型转化为贝叶斯神经网络，直接利用概率模型参数估计条件得分分布，解决了认知和随机不确定性，仅需一个参考模型即可实现高效且强大的攻击。实验在五个数据集上验证了BMIA的有效性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2503.07482v1",
      "published_date": "2025-03-10 15:58:43 UTC",
      "updated_date": "2025-03-10 15:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:32.491045"
    },
    {
      "arxiv_id": "2503.07470v1",
      "title": "Advancing Vietnamese Information Retrieval with Learning Objective and Benchmark",
      "title_zh": "推进越南语信息检索：学习目标与基准的构建",
      "authors": [
        "Phu-Vinh Nguyen",
        "Minh-Nam Tran",
        "Long Nguyen",
        "Dien Dinh"
      ],
      "abstract": "With the rapid development of natural language processing, many language\nmodels have been invented for multiple tasks. One important task is information\nretrieval (IR), which requires models to retrieve relevant documents. Despite\nits importance in many real-life applications, especially in retrieval\naugmented generation (RAG) systems, this task lacks Vietnamese benchmarks. This\nsituation causes difficulty in assessing and comparing many existing Vietnamese\nembedding language models on the task and slows down the advancement of\nVietnamese natural language processing (NLP) research. In this work, we aim to\nprovide the Vietnamese research community with a new benchmark for information\nretrieval, which mainly focuses on retrieval and reranking tasks. Furthermore,\nwe also present a new objective function based on the InfoNCE loss function,\nwhich is used to train our Vietnamese embedding model. Our function aims to be\nbetter than the origin in information retrieval tasks. Finally, we analyze the\neffect of temperature, a hyper-parameter in both objective functions, on the\nperformance of text embedding models.",
      "tldr_zh": "本文针对越南语信息检索(IR)领域缺乏基准测试的问题，提出了首个专注于检索和重排序任务的越南语IR基准。研究团队开发了一种基于InfoNCE损失函数的改进目标函数，用于训练越南语嵌入模型，在检索任务中表现优于原始方法。论文还分析了温度参数对文本嵌入模型性能的影响，推动了越南语自然语言处理(NLP)的发展，特别是对检索增强生成(RAG)系统具有重要意义。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07470v1",
      "published_date": "2025-03-10 15:47:01 UTC",
      "updated_date": "2025-03-10 15:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:39.510968"
    },
    {
      "arxiv_id": "2503.07459v2",
      "title": "MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning",
      "title_zh": "MedAgentsBench：复杂医学推理中思维模型与智能体框架的基准测试",
      "authors": [
        "Xiangru Tang",
        "Daniel Shao",
        "Jiwoong Sohn",
        "Jiapeng Chen",
        "Jiayi Zhang",
        "Jinyu Xiang",
        "Fang Wu",
        "Yilun Zhao",
        "Chenglin Wu",
        "Wenqi Shi",
        "Arman Cohan",
        "Mark Gerstein"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive performance on existing\nmedical question-answering benchmarks. This high performance makes it\nincreasingly difficult to meaningfully evaluate and differentiate advanced\nmethods. We present MedAgentsBench, a benchmark that focuses on challenging\nmedical questions requiring multi-step clinical reasoning, diagnosis\nformulation, and treatment planning-scenarios where current models still\nstruggle despite their strong performance on standard tests. Drawing from seven\nestablished medical datasets, our benchmark addresses three key limitations in\nexisting evaluations: (1) the prevalence of straightforward questions where\neven base models achieve high performance, (2) inconsistent sampling and\nevaluation protocols across studies, and (3) lack of systematic analysis of the\ninterplay between performance, cost, and inference time. Through experiments\nwith various base models and reasoning methods, we demonstrate that the latest\nthinking models, DeepSeek R1 and OpenAI o3, exhibit exceptional performance in\ncomplex medical reasoning tasks. Additionally, advanced search-based agent\nmethods offer promising performance-to-cost ratios compared to traditional\napproaches. Our analysis reveals substantial performance gaps between model\nfamilies on complex questions and identifies optimal model selections for\ndifferent computational constraints. Our benchmark and evaluation framework are\npublicly available at https://github.com/gersteinlab/medagents-benchmark.",
      "tldr_zh": "该研究提出了MedAgentsBench基准测试，专门针对需要多步临床推理、诊断制定和治疗规划等复杂医学问题，弥补现有评估体系的三方面不足：简单问题占比过高、评估标准不统一、以及缺乏性能-成本-推理时间的系统分析。基于七个权威医学数据集的实验表明，DeepSeek R1和OpenAI o3等最新思维模型在复杂医学推理中表现优异，而基于搜索的智能体方法展现出更好的性价比。该研究不仅揭示了不同模型在复杂问题上的性能差距，还为不同计算约束下的最优模型选择提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07459v2",
      "published_date": "2025-03-10 15:38:44 UTC",
      "updated_date": "2025-03-20 01:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:33.662849"
    },
    {
      "arxiv_id": "2503.07453v2",
      "title": "Is a Good Foundation Necessary for Efficient Reinforcement Learning? The Computational Role of the Base Model in Exploration",
      "title_zh": "良好基础模型对高效强化学习是否必要？探索中基础模型的计算作用",
      "authors": [
        "Dylan J. Foster",
        "Zakaria Mhammedi",
        "Dhruv Rohatgi"
      ],
      "abstract": "Language model alignment (or, reinforcement learning) techniques that\nleverage active exploration -- deliberately encouraging the model to produce\ndiverse, informative responses -- offer the promise of super-human\ncapabilities. However, current understanding of algorithm design primitives for\ncomputationally efficient exploration with language models is limited. To\nbetter understand how to leverage access to powerful pre-trained generative\nmodels to improve the efficiency of exploration, we introduce a new\ncomputational framework for RL with language models, in which the learner\ninteracts with the model through a sampling oracle. Focusing on the linear\nsoftmax model parameterization, we provide new results that reveal the\ncomputational-statistical tradeoffs of efficient exploration:\n  1. Necessity of coverage: Coverage refers to the extent to which the\npre-trained model covers near-optimal responses -- a form of hidden knowledge.\nWe show that coverage, while not necessary for data efficiency, lower bounds\nthe runtime of any algorithm in our framework.\n  2. Inference-time exploration: We introduce a new algorithm, SpannerSampling,\nwhich obtains optimal data efficiency and is computationally efficient whenever\nthe pre-trained model enjoys sufficient coverage, matching our lower bound.\nSpannerSampling leverages inference-time computation with the pre-trained model\nto reduce the effective search space for exploration.\n  3. Insufficiency of training-time interventions: We contrast the result above\nby showing that training-time interventions that produce proper policies cannot\nachieve similar guarantees in polynomial time.\n  4. Computational benefits of multi-turn exploration: Finally, we show that\nunder additional representational assumptions, one can achieve improved runtime\n(replacing sequence-level coverage with token-level coverage) through\nmulti-turn exploration.",
      "tldr_zh": "本文探讨了在强化学习中预训练基础模型对高效探索的计算作用。研究表明，虽然预训练模型的覆盖范围（coverage）对数据效率并非必要，但它决定了任何算法的运行时间下限。研究提出了一种新算法SpannerSampling，在预训练模型覆盖足够时，能够实现最优数据效率和计算效率。同时，研究发现训练时的干预无法在多项式时间内实现类似效果，而多轮探索在特定表示假设下可以进一步提升运行效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "V2: Improved number of prompts used by Algorithm 1",
      "pdf_url": "http://arxiv.org/pdf/2503.07453v2",
      "published_date": "2025-03-10 15:31:42 UTC",
      "updated_date": "2025-03-13 23:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:34.759088"
    },
    {
      "arxiv_id": "2503.07450v2",
      "title": "From Idea to Implementation: Evaluating the Influence of Large Language Models in Software Development -- An Opinion Paper",
      "title_zh": "从构想到实践：评估大型语言模型对软件开发的影响——一篇观点论文",
      "authors": [
        "Sargam Yadav",
        "Asifa Mehmood Qureshi",
        "Abhishek Kaushik",
        "Shubham Sharma",
        "Roisin Loughran",
        "Subramaniam Kazhuparambil",
        "Andrew Shaw",
        "Mohammed Sabry",
        "Niamh St John Lynch",
        ". Nikhil Singh",
        "Padraic O'Hara",
        "Pranay Jaiswal",
        "Roshan Chandru",
        "David Lillis"
      ],
      "abstract": "The introduction of transformer architecture was a turning point in Natural\nLanguage Processing (NLP). Models based on the transformer architecture such as\nBidirectional Encoder Representations from Transformers (BERT) and Generative\nPre-Trained Transformer (GPT) have gained widespread popularity in various\napplications such as software development and education. The availability of\nLarge Language Models (LLMs) such as ChatGPT and Bard to the general public has\nshowcased the tremendous potential of these models and encouraged their\nintegration into various domains such as software development for tasks such as\ncode generation, debugging, and documentation generation. In this study,\nopinions from 11 experts regarding their experience with LLMs for software\ndevelopment have been gathered and analysed to draw insights that can guide\nsuccessful and responsible integration. The overall opinion of the experts is\npositive, with the experts identifying advantages such as increase in\nproductivity and reduced coding time. Potential concerns and challenges such as\nrisk of over-dependence and ethical considerations have also been highlighted.",
      "tldr_zh": "这篇观点性论文探讨了大型语言模型(LLMs)在软件开发中的影响。研究收集分析了11位专家的意见，发现LLMs如ChatGPT和Bard能显著提升开发效率，缩短编码时间，但也存在过度依赖风险等伦理问题。专家们总体持积极态度，认为LLMs在代码生成、调试和文档编写等任务中展现出巨大潜力，但需要负责任地整合应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The project is partially supported by the DkIT Postgraduate\n  Scholarship, Research Ireland under Grant number 13/RC/2094_2, and Grant\n  number 21/FFP-A/925",
      "pdf_url": "http://arxiv.org/pdf/2503.07450v2",
      "published_date": "2025-03-10 15:30:05 UTC",
      "updated_date": "2025-03-12 09:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:51.016478"
    },
    {
      "arxiv_id": "2503.07444v1",
      "title": "Divide and Conquer Self-Supervised Learning for High-Content Imaging",
      "title_zh": "分而治之的自监督学习在高内涵成像中的应用",
      "authors": [
        "Lucas Farndale",
        "Paul Henderson",
        "Edward W Roberts",
        "Ke Yuan"
      ],
      "abstract": "Self-supervised representation learning methods often fail to learn subtle or\ncomplex features, which can be dominated by simpler patterns which are much\neasier to learn. This limitation is particularly problematic in applications to\nscience and engineering, as complex features can be critical for discovery and\nanalysis. To address this, we introduce Split Component Embedding Registration\n(SpliCER), a novel architecture which splits the image into sections and\ndistils information from each section to guide the model to learn more subtle\nand complex features without compromising on simpler features. SpliCER is\ncompatible with any self-supervised loss function and can be integrated into\nexisting methods without modification. The primary contributions of this work\nare as follows: i) we demonstrate that existing self-supervised methods can\nlearn shortcut solutions when simple and complex features are both present; ii)\nwe introduce a novel self-supervised training method, SpliCER, to overcome the\nlimitations of existing methods, and achieve significant downstream performance\nimprovements; iii) we demonstrate the effectiveness of SpliCER in cutting-edge\nmedical and geospatial imaging settings. SpliCER offers a powerful new tool for\nrepresentation learning, enabling models to uncover complex features which\ncould be overlooked by other methods.",
      "tldr_zh": "该论文提出了一种名为Split Component Embedding Registration (SpliCER)的新型自监督学习架构，用于解决现有方法在科学和工程应用中难以学习复杂特征的问题。SpliCER通过将图像分割成多个部分并分别提取特征，引导模型同时学习简单和复杂的特征模式。该方法兼容任何自监督损失函数，无需修改即可集成到现有方法中。实验证明，SpliCER在医学和地理空间成像等前沿领域显著提升了模型性能，为发现可能被其他方法忽略的复杂特征提供了有力工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07444v1",
      "published_date": "2025-03-10 15:24:36 UTC",
      "updated_date": "2025-03-10 15:24:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:49:53.288798"
    },
    {
      "arxiv_id": "2503.07429v1",
      "title": "From Text to Visuals: Using LLMs to Generate Math Diagrams with Vector Graphics",
      "title_zh": "从文本到视觉：利用大型语言模型生成基于矢量图形的数学图表",
      "authors": [
        "Jaewook Lee",
        "Jeongah Lee",
        "Wanyong Feng",
        "Andrew Lan"
      ],
      "abstract": "Advances in large language models (LLMs) offer new possibilities for\nenhancing math education by automating support for both teachers and students.\nWhile prior work has focused on generating math problems and high-quality\ndistractors, the role of visualization in math learning remains under-explored.\nDiagrams are essential for mathematical thinking and problem-solving, yet\nmanually creating them is time-consuming and requires domain-specific\nexpertise, limiting scalability. Recent research on using LLMs to generate\nScalable Vector Graphics (SVG) presents a promising approach to automating\ndiagram creation. Unlike pixel-based images, SVGs represent geometric figures\nusing XML, allowing seamless scaling and adaptability. Educational platforms\nsuch as Khan Academy and IXL already use SVGs to display math problems and\nhints. In this paper, we explore the use of LLMs to generate math-related\ndiagrams that accompany textual hints via intermediate SVG representations. We\naddress three research questions: (1) how to automatically generate math\ndiagrams in problem-solving hints and evaluate their quality, (2) whether SVG\nis an effective intermediate representation for math diagrams, and (3) what\nprompting strategies and formats are required for LLMs to generate accurate\nSVG-based diagrams. Our contributions include defining the task of\nautomatically generating SVG-based diagrams for math hints, developing an LLM\nprompting-based pipeline, and identifying key strategies for improving diagram\ngeneration. Additionally, we introduce a Visual Question Answering-based\nevaluation setup and conduct ablation studies to assess different pipeline\nvariations. By automating the math diagram creation, we aim to provide students\nand teachers with accurate, conceptually relevant visual aids that enhance\nproblem-solving and learning experiences.",
      "tldr_zh": "该研究探索了利用大语言模型（LLMs）生成数学相关图表的可能性，重点关注通过可缩放矢量图形（SVG）作为中间表示。研究解决了三个核心问题：如何自动生成数学问题提示中的图表并评估其质量，SVG是否适合作为数学图表的中间表示，以及需要哪些提示策略和格式来生成准确的SVG图表。研究贡献包括定义自动生成SVG数学图表的任务，开发基于LLM的生成流程，并引入视觉问答评估方法。通过自动化图表生成，研究旨在为数学教育提供精确且概念相关的视觉辅助工具，提升学习和问题解决体验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07429v1",
      "published_date": "2025-03-10 15:13:38 UTC",
      "updated_date": "2025-03-10 15:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:50:08.446504"
    },
    {
      "arxiv_id": "2503.07426v1",
      "title": "RePO: ReLU-based Preference Optimization",
      "title_zh": "RePO：基于ReLU的偏好优化",
      "authors": [
        "Junkang Wu",
        "Kexin Huang",
        "Xue Wang",
        "Jinyang Gao",
        "Bolin Ding",
        "Jiancan Wu",
        "Xiangnan He",
        "Xiang Wang"
      ],
      "abstract": "Aligning large language models (LLMs) with human preferences is critical for\nreal-world deployment, yet existing methods like RLHF face computational and\nstability challenges. While DPO establishes an offline paradigm with single\nhyperparameter $\\beta$, subsequent methods like SimPO reintroduce complexity\nthrough dual parameters ($\\beta$, $\\gamma$). We propose {ReLU-based Preference\nOptimization (RePO)}, a streamlined algorithm that eliminates $\\beta$ via two\nadvances: (1) retaining SimPO's reference-free margins but removing $\\beta$\nthrough gradient analysis, and (2) adopting a ReLU-based max-margin loss that\nnaturally filters trivial pairs. Theoretically, RePO is characterized as\nSimPO's limiting case ($\\beta \\to \\infty$), where the logistic weighting\ncollapses to binary thresholding, forming a convex envelope of the 0-1 loss.\nEmpirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO\nand SimPO across multiple base models, requiring only one hyperparameter to\ntune.",
      "tldr_zh": "该研究提出RePO（ReLU-based Preference Optimization），一种简化的大语言模型（LLM）人类偏好对齐方法。相比现有RLHF和DPO等方法，RePO通过两项创新实现单超参数优化：（1）保留SimPO的无参考边界但通过梯度分析消除β参数；（2）采用基于ReLU的最大边界损失函数自动过滤无效样本对。理论分析表明RePO是SimPO在β→∞时的极限情况，其逻辑加权退化为二元阈值，形成0-1损失的凸包络。在AlpacaEval 2和Arena-Hard基准测试中，RePO以单一可调参数优于DPO和SimPO等现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07426v1",
      "published_date": "2025-03-10 15:11:07 UTC",
      "updated_date": "2025-03-10 15:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:50:29.978368"
    },
    {
      "arxiv_id": "2503.08717v1",
      "title": "A Semantic Link Network Model for Supporting Traceability of Logistics on Blockchain",
      "title_zh": "支持区块链物流溯源能力的语义链接网络模型",
      "authors": [
        "Xiaoping Sun",
        "Sirui Zhuge",
        "Hai Zhuge"
      ],
      "abstract": "The ability of tracing states of logistic transportations requires an\nefficient storage and retrieval of the state of logistic transportations and\nlocations of logistic objects. However, the restriction of sharing states and\nlocations of logistic objects across organizations from different countries\nmakes it hard to deploy a centralized database for implementing the\ntraceability in a cross-border logistic system. This paper proposes a semantic\ndata model on Blockchain to represent a logistic process based on the Semantic\nLink Network model where each semantic link represents a logistic\ntransportation of a logistic object between two parties. A state representation\nmodel is designed to represent the states of a logistic transportation with\nsemantic links. It enables the locations of logistic objects to be derived from\nthe link states. A mapping from the semantic links to the blockchain\ntransactions is designed to enable schema of semantic links and states of\nsemantic links to be published in blockchain transactions. To improve the\nefficiency of tracing a path of semantic links on blockchain platform, an\nalgorithm is designed to build shortcuts along the path of semantic links to\nenable a query on the path of a logistic object to reach the target in\nlogarithmic steps on the blockchain platform. A reward-penalty policy is\ndesigned to allow participants to confirm the state of links on blockchain.\nAnalysis and simulation demonstrate the flexibility, effectiveness and the\nefficiency of Semantic Link Network on immutable blockchain for implementing\nlogistic traceability.",
      "tldr_zh": "本文提出了一种基于区块链的语义链接网络模型，用于支持物流追踪。该模型通过语义链接表示物流对象在双方之间的运输过程，并设计状态表示模型来捕捉物流运输的状态。通过将语义链接映射到区块链交易中，实现了物流路径和状态的可追溯性。为了提高追踪效率，设计了在区块链平台上构建语义链接路径的快捷算法，使查询能够在对数步数内完成。此外，引入奖励-惩罚机制，激励参与者确认链接状态。分析和仿真验证了该模型在实现跨境物流追踪中的灵活性、有效性和高效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DB",
        "cs.SI",
        "H.2.5; I.2.4"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08717v1",
      "published_date": "2025-03-10 14:56:00 UTC",
      "updated_date": "2025-03-10 14:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:50:43.563643"
    },
    {
      "arxiv_id": "2503.07396v1",
      "title": "Brain Inspired Adaptive Memory Dual-Net for Few-Shot Image Classification",
      "title_zh": "脑启发的自适应记忆双网络用于少样本图像分类",
      "authors": [
        "Kexin Di",
        "Xiuxing Li",
        "Yuyang Han",
        "Ziyu Li",
        "Qing Li",
        "Xia Wu"
      ],
      "abstract": "Few-shot image classification has become a popular research topic for its\nwide application in real-world scenarios, however the problem of supervision\ncollapse induced by single image-level annotation remains a major challenge.\nExisting methods aim to tackle this problem by locating and aligning relevant\nlocal features. However, the high intra-class variability in real-world images\nposes significant challenges in locating semantically relevant local regions\nunder few-shot settings. Drawing inspiration from the human's complementary\nlearning system, which excels at rapidly capturing and integrating semantic\nfeatures from limited examples, we propose the generalization-optimized Systems\nConsolidation Adaptive Memory Dual-Network, SCAM-Net. This approach simulates\nthe systems consolidation of complementary learning system with an adaptive\nmemory module, which successfully addresses the difficulty of identifying\nmeaningful features in few-shot scenarios. Specifically, we construct a\nHippocampus-Neocortex dual-network that consolidates structured representation\nof each category, the structured representation is then stored and adaptively\nregulated following the generalization optimization principle in a long-term\nmemory inside Neocortex. Extensive experiments on benchmark datasets show that\nthe proposed model has achieved state-of-the-art performance.",
      "tldr_zh": "该研究提出了一种受人类互补学习系统启发的双网络模型SCAM-Net，用于解决少样本图像分类中的监督崩溃问题。模型通过模拟海马体-新皮质的系统整合过程，利用自适应记忆模块捕捉和整合语义特征，从而在少样本场景下有效识别有意义的局部区域。实验表明，SCAM-Net在多个基准数据集上取得了最先进的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07396v1",
      "published_date": "2025-03-10 14:42:51 UTC",
      "updated_date": "2025-03-10 14:42:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:50:37.072155"
    },
    {
      "arxiv_id": "2503.07389v1",
      "title": "TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models",
      "title_zh": "TRCE：面向文本到图像扩散模型的可靠恶意概念消除",
      "authors": [
        "Ruidong Chen",
        "Honglin Guo",
        "Lanjun Wang",
        "Chenyu Zhang",
        "Weizhi Nie",
        "An-An Liu"
      ],
      "abstract": "Recent advances in text-to-image diffusion models enable photorealistic image\ngeneration, but they also risk producing malicious content, such as NSFW\nimages. To mitigate risk, concept erasure methods are studied to facilitate the\nmodel to unlearn specific concepts. However, current studies struggle to fully\nerase malicious concepts implicitly embedded in prompts (e.g., metaphorical\nexpressions or adversarial prompts) while preserving the model's normal\ngeneration capability. To address this challenge, our study proposes TRCE,\nusing a two-stage concept erasure strategy to achieve an effective trade-off\nbetween reliable erasure and knowledge preservation. Firstly, TRCE starts by\nerasing the malicious semantics implicitly embedded in textual prompts. By\nidentifying a critical mapping objective(i.e., the [EoT] embedding), we\noptimize the cross-attention layers to map malicious prompts to contextually\nsimilar prompts but with safe concepts. This step prevents the model from being\noverly influenced by malicious semantics during the denoising process.\nFollowing this, considering the deterministic properties of the sampling\ntrajectory of the diffusion model, TRCE further steers the early denoising\nprediction toward the safe direction and away from the unsafe one through\ncontrastive learning, thus further avoiding the generation of malicious\ncontent. Finally, we conduct comprehensive evaluations of TRCE on multiple\nmalicious concept erasure benchmarks, and the results demonstrate its\neffectiveness in erasing malicious concepts while better preserving the model's\noriginal generation ability. The code is available at:\nhttp://github.com/ddgoodgood/TRCE. CAUTION: This paper includes model-generated\ncontent that may contain offensive material.",
      "tldr_zh": "该研究提出了TRCE方法，用于在文本到图像扩散模型中实现可靠的恶意概念擦除。TRCE采用两阶段策略：首先通过优化交叉注意力层，将恶意提示映射为语义相似的安全提示，以消除文本提示中隐含的恶意语义；其次利用扩散模型的采样轨迹特性，通过对比学习引导早期去噪预测朝向安全方向，进一步避免恶意内容生成。实验表明，TRCE在多个恶意概念擦除基准测试中表现出色，既能有效擦除恶意概念，又较好地保留了模型的原始生成能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07389v1",
      "published_date": "2025-03-10 14:37:53 UTC",
      "updated_date": "2025-03-10 14:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:50:47.451131"
    },
    {
      "arxiv_id": "2503.07384v2",
      "title": "Is My Text in Your AI Model? Gradient-based Membership Inference Test applied to LLMs",
      "title_zh": "我的文本在你的AI模型中吗？基于梯度的成员推理测试应用于大语言模型",
      "authors": [
        "Gonzalo Mancera",
        "Daniel DeAlcala",
        "Julian Fierrez",
        "Ruben Tolosana",
        "Aythami Morales"
      ],
      "abstract": "This work adapts and studies the gradient-based Membership Inference Test\n(gMINT) to the classification of text based on LLMs. MINT is a general approach\nintended to determine if given data was used for training machine learning\nmodels, and this work focuses on its application to the domain of Natural\nLanguage Processing. Using gradient-based analysis, the MINT model identifies\nwhether particular data samples were included during the language model\ntraining phase, addressing growing concerns about data privacy in machine\nlearning. The method was evaluated in seven Transformer-based models and six\ndatasets comprising over 2.5 million sentences, focusing on text classification\ntasks. Experimental results demonstrate MINTs robustness, achieving AUC scores\nbetween 85% and 99%, depending on data size and model architecture. These\nfindings highlight MINTs potential as a scalable and reliable tool for auditing\nmachine learning models, ensuring transparency, safeguarding sensitive data,\nand fostering ethical compliance in the deployment of AI/NLP technologies.",
      "tldr_zh": "该研究将基于梯度的成员推理测试(gMINT)应用于大型语言模型(LLMs)的文本分类任务，以判断特定文本数据是否被用于模型训练。该方法通过分析梯度特征，在7个Transformer模型和6个包含250万句子的数据集上进行验证，在文本分类任务中实现了85%-99%的AUC分数。研究结果表明gMINT能有效应对机器学习中的数据隐私问题，为AI/NLP技术的透明部署和伦理合规提供了可靠审计工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07384v2",
      "published_date": "2025-03-10 14:32:56 UTC",
      "updated_date": "2025-03-13 12:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:50:58.263650"
    },
    {
      "arxiv_id": "2503.07364v1",
      "title": "Artificial Utopia: Simulation and Intelligent Agents for a Democratised Future",
      "title_zh": "人工乌托邦：面向民主化未来的模拟与智能体",
      "authors": [
        "Yannick Oswald"
      ],
      "abstract": "Prevailing top-down systems in politics and economics struggle to keep pace\nwith the pressing challenges of the 21st century, such as climate change,\nsocial inequality and conflict. Bottom-up democratisation and participatory\napproaches in politics and economics are increasingly seen as promising\nalternatives to confront and overcome these issues, often with utopian\novertones, as proponents believe they may dramatically reshape political,\nsocial and ecological futures for the better and in contrast to contemporary\nauthoritarian tendencies across various countries. Institutional specifics and\nthe associated collective human behavior or culture remains little understood\nand debated, however. In this article, I propose a novel research agenda\nfocusing on utopian democratisation efforts with formal and computational\nmethods as well as with artificial intelligence - I call this agenda Artificial\nUtopia. Artificial Utopias provide safe testing grounds for new political ideas\nand economic policies in-silico with reduced risk of negative consequences as\ncompared to testing ideas in real-world contexts. An increasing number of\nadvanced simulation and intelligence methods, that aim at representing human\ncognition and collective decision-making in more realistic ways, could benefit\nthis process. This includes agent-based modelling, reinforcement learning,\nlarge language models and more. I clarify what some of these simulation\napproaches can contribute to the study of Artificial Utopias with the help of\ntwo institutional examples: the citizen assembly and the democratic firm.",
      "tldr_zh": "该研究提出\"人工乌托邦\"(Artificial Utopia)这一创新研究框架，利用计算模拟和人工智能技术探索民主化政治经济制度的可行性。通过基于Agent建模、强化学习和大语言模型等方法，该框架为测试公民大会、民主企业等新型制度提供了安全的数字实验场，避免了现实世界试错的高昂成本。研究者认为这种\"硅基乌托邦\"能更准确地模拟人类认知和集体决策过程，为应对气候变化、社会不平等等21世纪挑战提供制度创新的科学验证途径。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07364v1",
      "published_date": "2025-03-10 14:20:58 UTC",
      "updated_date": "2025-03-10 14:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:51:07.372056"
    },
    {
      "arxiv_id": "2503.07351v1",
      "title": "Encoding Argumentation Frameworks to Propositional Logic Systems",
      "title_zh": "将论证框架编码为命题逻辑系统",
      "authors": [
        "Shuai Tang",
        "Jiachao Wu",
        "Ning Zhou"
      ],
      "abstract": "The theory of argumentation frameworks ($AF$s) has been a useful tool for\nartificial intelligence. The research of the connection between $AF$s and logic\nis an important branch. This paper generalizes the encoding method by encoding\n$AF$s as logical formulas in different propositional logic systems. It studies\nthe relationship between models of an AF by argumentation semantics, including\nDung's classical semantics and Gabbay's equational semantics, and models of the\nencoded formulas by semantics of propositional logic systems. Firstly, we\nsupplement the proof of the regular encoding function in the case of encoding\n$AF$s to the 2-valued propositional logic system. Then we encode $AF$s to\n3-valued propositional logic systems and fuzzy propositional logic systems and\nexplore the model relationship. This paper enhances the connection between\n$AF$s and propositional logic systems. It also provides a new way to construct\nnew equational semantics by choosing different fuzzy logic operations.",
      "tldr_zh": "该研究将论证框架（AFs）编码为不同命题逻辑系统的逻辑公式，建立了AFs与命题逻辑之间的联系。论文补充了将AFs编码到二值命题逻辑系统的正则编码函数证明，并进一步扩展到三值命题逻辑系统和模糊命题逻辑系统，探索了模型间的关系。通过选择不同的模糊逻辑运算，该方法为构建新的方程语义提供了一种新途径，增强了AFs与命题逻辑系统的理论联系。",
      "categories": [
        "cs.AI",
        "math.LO",
        "Primary 68T27, Secondary 03B70, 03B50, 03B52, 68Q55",
        "I.2.4; F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07351v1",
      "published_date": "2025-03-10 14:06:58 UTC",
      "updated_date": "2025-03-10 14:06:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:51:12.249063"
    },
    {
      "arxiv_id": "2503.07341v1",
      "title": "The Economics of p(doom): Scenarios of Existential Risk and Economic Growth in the Age of Transformative AI",
      "title_zh": "p(doom)经济学：变革性人工智能时代下的生存风险与经济增长情景分析",
      "authors": [
        "Jakub Growiec",
        "Klaus Prettner"
      ],
      "abstract": "Recent advances in artificial intelligence (AI) have led to a diverse set of\npredictions about its long-term impact on humanity. A central focus is the\npotential emergence of transformative AI (TAI), eventually capable of\noutperforming humans in all economically valuable tasks and fully automating\nlabor. Discussed scenarios range from human extinction after a misaligned TAI\ntakes over (\"AI doom\") to unprecedented economic growth and abundance\n(\"post-scarcity\"). However, the probabilities and implications of these\nscenarios remain highly uncertain. Here, we organize the various scenarios and\nevaluate their associated existential risks and economic outcomes in terms of\naggregate welfare. Our analysis shows that even low-probability catastrophic\noutcomes justify large investments in AI safety and alignment research. We find\nthat the optimizing representative individual would rationally allocate\nsubstantial resources to mitigate extinction risk; in some cases, she would\nprefer not to develop TAI at all. This result highlights that current global\nefforts in AI safety and alignment research are vastly insufficient relative to\nthe scale and urgency of existential risks posed by TAI. Our findings therefore\nunderscore the need for stronger safeguards to balance the potential economic\nbenefits of TAI with the prevention of irreversible harm. Addressing these\nrisks is crucial for steering technological progress toward sustainable human\nprosperity.",
      "tldr_zh": "本文探讨了变革性人工智能（TAI）时代的经济学与存在性风险，分析了从“AI末日”到“后稀缺”社会的多种情景。研究表明，即使低概率的灾难性结果也足以证明对AI安全和对齐研究的巨额投资是合理的。分析指出，理性的个体会优先分配大量资源以减轻灭绝风险，甚至可能选择不发展TAI。研究强调，当前全球在AI安全和对齐研究方面的努力远不足以应对TAI带来的存在性风险，亟需更强有力的保障措施来平衡TAI的经济效益与不可逆危害的预防。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07341v1",
      "published_date": "2025-03-10 13:53:39 UTC",
      "updated_date": "2025-03-10 13:53:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:51:16.788089"
    },
    {
      "arxiv_id": "2503.07340v1",
      "title": "Research and Design on Intelligent Recognition of Unordered Targets for Robots Based on Reinforcement Learning",
      "title_zh": "基于强化学习的机器人无序目标智能识别研究与设计",
      "authors": [
        "Yiting Mao",
        "Dajun Tao",
        "Shengyuan Zhang",
        "Tian Qi",
        "Keqin Li"
      ],
      "abstract": "In the field of robot target recognition research driven by artificial\nintelligence (AI), factors such as the disordered distribution of targets, the\ncomplexity of the environment, the massive scale of data, and noise\ninterference have significantly restricted the improvement of target\nrecognition accuracy. Against the backdrop of the continuous iteration and\nupgrading of current AI technologies, to meet the demand for accurate\nrecognition of disordered targets by intelligent robots in complex and\nchangeable scenarios, this study innovatively proposes an AI - based\nintelligent robot disordered target recognition method using reinforcement\nlearning. This method processes the collected target images with the bilateral\nfiltering algorithm, decomposing them into low - illumination images and\nreflection images. Subsequently, it adopts differentiated AI strategies,\ncompressing the illumination images and enhancing the reflection images\nrespectively, and then fuses the two parts of images to generate a new image.\nOn this basis, this study deeply integrates deep learning, a core AI\ntechnology, with the reinforcement learning algorithm. The enhanced target\nimages are input into a deep reinforcement learning model for training,\nultimately enabling the AI - based intelligent robot to efficiently recognize\ndisordered targets. Experimental results show that the proposed method can not\nonly significantly improve the quality of target images but also enable the AI\n- based intelligent robot to complete the recognition task of disordered\ntargets with higher efficiency and accuracy, demonstrating extremely high\napplication value and broad development prospects in the field of AI robots.",
      "tldr_zh": "本研究提出了一种基于强化学习(Reinforcement Learning)的智能机器人无序目标识别方法，旨在解决复杂环境下目标分布无序、数据规模庞大以及噪声干扰等问题。该方法采用双边滤波算法处理目标图像，将其分解为低照度图像和反射图像，并分别进行压缩和增强处理，随后融合生成新图像。通过将深度学习与强化学习算法深度融合，训练深度强化学习模型，最终实现高效的无序目标识别。实验结果表明，该方法显著提升了目标图像质量，并提高了智能机器人在无序目标识别任务中的效率和准确性，展现了在AI机器人领域的广泛应用价值和发展前景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07340v1",
      "published_date": "2025-03-10 13:53:22 UTC",
      "updated_date": "2025-03-10 13:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:51:34.099335"
    },
    {
      "arxiv_id": "2503.07338v1",
      "title": "Temporal Triplane Transformers as Occupancy World Models",
      "title_zh": "时序三平面变换器作为占据世界模型",
      "authors": [
        "Haoran Xu",
        "Peixi Peng",
        "Guang Tan",
        "Yiqian Chang",
        "Yisen Zhao",
        "Yonghong Tian"
      ],
      "abstract": "Recent years have seen significant advances in world models, which primarily\nfocus on learning fine-grained correlations between an agent's motion\ntrajectory and the resulting changes in its surrounding environment. However,\nexisting methods often struggle to capture such fine-grained correlations and\nachieve real-time predictions. To address this, we propose a new 4D occupancy\nworld model for autonomous driving, termed T$^3$Former. T$^3$Former begins by\npre-training a compact triplane representation that efficiently compresses the\n3D semantically occupied environment. Next, T$^3$Former extracts multi-scale\ntemporal motion features from the historical triplane and employs an\nautoregressive approach to iteratively predict the next triplane changes.\nFinally, T$^3$Former combines the triplane changes with the previous ones to\ndecode them into future occupancy results and ego-motion trajectories.\nExperimental results demonstrate the superiority of T$^3$Former, achieving\n1.44$\\times$ faster inference speed (26 FPS), while improving the mean IoU to\n36.09 and reducing the mean absolute planning error to 1.0 meters.",
      "tldr_zh": "该研究提出T³Former，一种用于自动驾驶的新型4D占用世界模型。该方法通过预训练紧凑的triplane表示来高效压缩3D语义化环境，并利用多尺度时序运动特征和自回归方法预测未来triplane变化。实验表明，T³Former在推理速度(26 FPS)和预测精度(平均IoU 36.09，规划误差1.0米)上均优于现有方法，为实时自动驾驶决策提供了高效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07338v1",
      "published_date": "2025-03-10 13:50:23 UTC",
      "updated_date": "2025-03-10 13:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:51:32.495144"
    },
    {
      "arxiv_id": "2503.07330v1",
      "title": "Mitigating Hallucinations in YOLO-based Object Detection Models: A Revisit to Out-of-Distribution Detection",
      "title_zh": "缓解基于YOLO的目标检测模型中的幻觉现象：重新审视分布外检测",
      "authors": [
        "Weicheng He",
        "Changshun Wu",
        "Chih-Hong Cheng",
        "Xiaowei Huang",
        "Saddek Bensalem"
      ],
      "abstract": "Object detection systems must reliably perceive objects of interest without\nbeing overly confident to ensure safe decision-making in dynamic environments.\nFiltering techniques based on out-of-distribution (OoD) detection are commonly\nadded as an extra safeguard to filter hallucinations caused by overconfidence\nin novel objects. Nevertheless, evaluating YOLO-family detectors and their\nfilters under existing OoD benchmarks often leads to unsatisfactory\nperformance. This paper studies the underlying reasons for performance\nbottlenecks and proposes a methodology to improve performance fundamentally.\nOur first contribution is a calibration of all existing evaluation results:\nAlthough images in existing OoD benchmark datasets are claimed not to have\nobjects within in-distribution (ID) classes (i.e., categories defined in the\ntraining dataset), around 13% of objects detected by the object detector are\nactually ID objects. Dually, the ID dataset containing OoD objects can also\nnegatively impact the decision boundary of filters. These ultimately lead to a\nsignificantly imprecise performance estimation. Our second contribution is to\nconsider the task of hallucination reduction as a joint pipeline of detectors\nand filters. By developing a methodology to carefully synthesize an OoD dataset\nthat semantically resembles the objects to be detected, and using the crafted\nOoD dataset in the fine-tuning of YOLO detectors to suppress the objectness\nscore, we achieve a 88% reduction in overall hallucination error with a\ncombined fine-tuned detection and filtering system on the self-driving\nbenchmark BDD-100K. Our code and dataset are available at:\nhttps://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood.",
      "tldr_zh": "本文研究了YOLO目标检测模型中的幻觉问题，提出了一种改进方法。首先，作者发现现有OoD（Out-of-Distribution）基准数据集中存在约13%的ID（In-Distribution）对象，导致性能评估不准确。其次，作者将幻觉减少任务视为检测器和过滤器的联合管道，通过合成语义相似的OoD数据集，并利用该数据集微调YOLO检测器以抑制对象得分，最终在BDD-100K自动驾驶基准上实现了88%的幻觉错误减少。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07330v1",
      "published_date": "2025-03-10 13:42:41 UTC",
      "updated_date": "2025-03-10 13:42:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:51:53.394243"
    },
    {
      "arxiv_id": "2503.07329v1",
      "title": "Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning Large Language Models",
      "title_zh": "评估随机种子对微调大语言模型的宏观与微观影响",
      "authors": [
        "Hao Zhou",
        "Guergana Savova",
        "Lijing Wang"
      ],
      "abstract": "The impact of random seeds in fine-tuning large language models (LLMs) has\nbeen largely overlooked despite its potential influence on model performance.In\nthis study, we systematically evaluate the effects of random seeds on LLMs\nusing the GLUE and SuperGLUE benchmarks. We analyze the macro-level impact\nthrough traditional metrics like accuracy and F1, calculating their mean and\nvariance to quantify performance fluctuations. To capture the micro-level\neffects, we introduce a novel metric, consistency, measuring the stability of\nindividual predictions across runs. Our experiments reveal significant variance\nat both macro and micro levels, underscoring the need for careful consideration\nof random seeds in fine-tuning and evaluation.",
      "tldr_zh": "本研究系统评估了随机种子（random seeds）对微调大语言模型（LLMs）的宏观和微观影响。通过GLUE和SuperGLUE基准测试，研究发现随机种子在传统指标（如准确率和F1值）上会导致显著波动，并提出了衡量预测稳定性的新指标\"一致性\"(consistency)。实验表明随机种子在宏观性能和微观预测层面均产生重要影响，强调在模型微调和评估中需谨慎选择随机种子。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 5 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07329v1",
      "published_date": "2025-03-10 13:42:04 UTC",
      "updated_date": "2025-03-10 13:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:52:27.168525"
    },
    {
      "arxiv_id": "2503.07326v1",
      "title": "AI Biases as Asymmetries: A Review to Guide Practice",
      "title_zh": "AI偏见即不对称性：指导实践的综述",
      "authors": [
        "Gabriella Waters",
        "Phillip Honenberger"
      ],
      "abstract": "The understanding of bias in AI is currently undergoing a revolution.\nInitially understood as errors or flaws, biases are increasingly recognized as\nintegral to AI systems and sometimes preferable to less biased alternatives. In\nthis paper, we review the reasons for this changed understanding and provide\nnew guidance on two questions: First, how should we think about and measure\nbiases in AI systems, consistent with the new understanding? Second, what kinds\nof bias in an AI system should we accept or even amplify, and what kinds should\nwe minimize or eliminate, and why? The key to answering both questions, we\nargue, is to understand biases as \"violations of a symmetry standard\"\n(following Kelly). We distinguish three main types of asymmetry in AI\nsystems-error biases, inequality biases, and process biases-and highlight\nplaces in the pipeline of AI development and application where bias of each\ntype is likely to be good, bad, or inevitable.",
      "tldr_zh": "这篇论文重新审视了AI偏见问题，提出将偏见理解为\"对称性标准的违背\"的新范式。研究区分了三种主要AI系统不对称性：误差偏差、不平等偏差和流程偏差，并分析了每种偏差在AI开发流程中可能产生的积极或消极影响。论文为实践者提供了新指导框架，帮助判断哪些偏差应被接受/增强，哪些应被消除，为AI伦理治理提供了基于对称性理论的方法论基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07326v1",
      "published_date": "2025-03-10 13:40:28 UTC",
      "updated_date": "2025-03-10 13:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:52:05.896923"
    },
    {
      "arxiv_id": "2503.07323v1",
      "title": "Dynamic Path Navigation for Motion Agents with LLM Reasoning",
      "title_zh": "基于大语言模型推理的运动智能体动态路径导航",
      "authors": [
        "Yubo Zhao",
        "Qi Wu",
        "Yifan Wang",
        "Yu-Wing Tai",
        "Chi-Keung Tang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong generalizable reasoning\nand planning capabilities. However, their efficacies in spatial path planning\nand obstacle-free trajectory generation remain underexplored. Leveraging LLMs\nfor navigation holds significant potential, given LLMs' ability to handle\nunseen scenarios, support user-agent interactions, and provide global control\nacross complex systems, making them well-suited for agentic planning and\nhumanoid motion generation. As one of the first studies in this domain, we\nexplore the zero-shot navigation and path generation capabilities of LLMs by\nconstructing a dataset and proposing an evaluation protocol. Specifically, we\nrepresent paths using anchor points connected by straight lines, enabling\nmovement in various directions. This approach offers greater flexibility and\npracticality compared to previous methods while remaining simple and intuitive\nfor LLMs. We demonstrate that, when tasks are well-structured in this manner,\nmodern LLMs exhibit substantial planning proficiency in avoiding obstacles\nwhile autonomously refining navigation with the generated motion to reach the\ntarget. Further, this spatial reasoning ability of a single LLM motion agent\ninteracting in a static environment can be seamlessly generalized in\nmulti-motion agents coordination in dynamic environments. Unlike traditional\napproaches that rely on single-step planning or local policies, our\ntraining-free LLM-based method enables global, dynamic, closed-loop planning,\nand autonomously resolving collision issues.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在动态路径导航中的应用潜力，提出了一种基于LLM推理的零样本运动智能体规划方法。通过将路径表示为由直线连接的锚点，研究者构建了新型评估协议，证明现代LLMs在结构化任务中能有效规划避障路径并自主优化动作。该方法无需训练即可实现全局闭环规划，其单智能体在静态环境中的空间推理能力可无缝扩展到动态环境的多智能体协调，相比依赖单步规划的传统方法具有显著优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07323v1",
      "published_date": "2025-03-10 13:39:09 UTC",
      "updated_date": "2025-03-10 13:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:52:13.632114"
    },
    {
      "arxiv_id": "2503.07320v1",
      "title": "Experimental Exploration: Investigating Cooperative Interaction Behavior Between Humans and Large Language Model Agents",
      "title_zh": "实验性探索：人类与大型语言模型智能体间的合作交互行为研究",
      "authors": [
        "Guanxuan Jiang",
        "Yuyang Wang",
        "Pan Hui"
      ],
      "abstract": "With the rise of large language models (LLMs), AI agents as autonomous\ndecision-makers present significant opportunities and challenges for human-AI\ncooperation. While many studies have explored human cooperation with AI as\ntools, the role of LLM-augmented autonomous agents in competitive-cooperative\ninteractions remains under-examined. This study investigates human cooperative\nbehavior by engaging 30 participants who interacted with LLM agents exhibiting\ndifferent characteristics (purported human, purported rule-based AI agent, and\nLLM agent) in repeated Prisoner's Dilemma games. Findings show significant\ndifferences in cooperative behavior based on the agents' purported\ncharacteristics and the interaction effect of participants' genders and\npurported characteristics. We also analyzed human response patterns, including\ngame completion time, proactive favorable behavior, and acceptance of repair\nefforts. These insights offer a new perspective on human interactions with LLM\nagents in competitive cooperation contexts, such as virtual avatars or future\nphysical entities. The study underscores the importance of understanding human\nbiases toward AI agents and how observed behaviors can influence future\nhuman-AI cooperation dynamics.",
      "tldr_zh": "这项研究通过30名参与者与不同特性AI代理（自称人类、自称规则型AI和LLM代理）在重复囚徒困境游戏中的互动，揭示了人机合作行为差异。研究发现合作程度显著受AI宣称身份和参与者性别交互作用影响，并分析了人类响应模式（包括游戏耗时、主动友好行为和修复努力接受度）。该研究为理解竞争性合作场景（如虚拟化身或未来实体）中人类对LLM代理的偏见提供了新视角，突显了这些行为观察对未来人机协作动态的重要影响。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07320v1",
      "published_date": "2025-03-10 13:37:36 UTC",
      "updated_date": "2025-03-10 13:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:52:41.633044"
    },
    {
      "arxiv_id": "2503.07319v1",
      "title": "Human Machine Co-Adaptation Model and Its Convergence Analysis",
      "title_zh": "人机协同适应模型及其收敛性分析",
      "authors": [
        "Steven W. Su",
        "Yaqi Li",
        "Kairui Guo",
        "Rob Duffield"
      ],
      "abstract": "The key to robot-assisted rehabilitation lies in the design of the\nhuman-machine interface, which must accommodate the needs of both patients and\nmachines. Current interface designs primarily focus on machine control\nalgorithms, often requiring patients to spend considerable time adapting. In\nthis paper, we introduce a novel approach based on the Cooperative Adaptive\nMarkov Decision Process (CAMDPs) model to address the fundamental aspects of\nthe interactive learning process, offering theoretical insights and practical\nguidance. We establish sufficient conditions for the convergence of CAMDPs and\nensure the uniqueness of Nash equilibrium points. Leveraging these conditions,\nwe guarantee the system's convergence to a unique Nash equilibrium point.\nFurthermore, we explore scenarios with multiple Nash equilibrium points,\ndevising strategies to adjust both Value Evaluation and Policy Improvement\nalgorithms to enhance the likelihood of converging to the global minimal Nash\nequilibrium point. Through numerical experiments, we illustrate the\neffectiveness of the proposed conditions and algorithms, demonstrating their\napplicability and robustness in practical settings. The proposed conditions for\nconvergence and the identification of a unique optimal Nash equilibrium\ncontribute to the development of more effective adaptive systems for human\nusers in robot-assisted rehabilitation.",
      "tldr_zh": "该研究提出了一种基于合作自适应马尔可夫决策过程（CAMDPs）的人机协同适应模型，用于改进机器人辅助康复中的人机交互接口设计。论文建立了CAMDPs收敛的充分条件，保证了纳什均衡点的唯一性，并针对多均衡点情况提出了优化策略，通过调整值评估（Value Evaluation）和策略改进（Policy Improvement）算法提高收敛到全局最优纳什均衡点的概率。数值实验验证了该模型在机器人辅助康复场景中的有效性和鲁棒性，为人机自适应系统的开发提供了理论基础和实践指导。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07319v1",
      "published_date": "2025-03-10 13:36:36 UTC",
      "updated_date": "2025-03-10 13:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:52:35.983915"
    },
    {
      "arxiv_id": "2503.07317v1",
      "title": "Self-Corrective Task Planning by Inverse Prompting with Large Language Models",
      "title_zh": "基于大语言模型逆向提示的自校正任务规划",
      "authors": [
        "Jiho Lee",
        "Hayun Lee",
        "Jonghyeon Kim",
        "Kyungjae Lee",
        "Eunwoo Kim"
      ],
      "abstract": "In robot task planning, large language models (LLMs) have shown significant\npromise in generating complex and long-horizon action sequences. However, it is\nobserved that LLMs often produce responses that sound plausible but are not\naccurate. To address these problems, existing methods typically employ\npredefined error sets or external knowledge sources, requiring human efforts\nand computation resources. Recently, self-correction approaches have emerged,\nwhere LLM generates and refines plans, identifying errors by itself. Despite\ntheir effectiveness, they are more prone to failures in correction due to\ninsufficient reasoning. In this paper, we introduce InversePrompt, a novel\nself-corrective task planning approach that leverages inverse prompting to\nenhance interpretability. Our method incorporates reasoning steps to provide\nclear, interpretable feedback. It generates inverse actions corresponding to\nthe initially generated actions and verifies whether these inverse actions can\nrestore the system to its original state, explicitly validating the logical\ncoherence of the generated plans. The results on benchmark datasets show an\naverage 16.3% higher success rate over existing LLM-based task planning\nmethods. Our approach offers clearer justifications for feedback in real-world\nenvironments, resulting in more successful task completion than existing\nself-correction approaches across various scenarios.",
      "tldr_zh": "该研究提出了一种新型自我修正任务规划方法InversePrompt，通过逆向提示技术提升大语言模型(LLMs)在机器人任务规划中的可靠性。该方法创新性地生成与初始动作对应的逆向动作，并验证这些逆向动作能否使系统恢复初始状态，从而显式检验生成计划的逻辑一致性。相比现有方法，InversePrompt结合了可解释的推理步骤，在基准测试中成功率平均提高16.3%，特别在复杂场景下展现出更强的自我修正能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures, IEEE International Conference on Robotics and\n  Automation (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07317v1",
      "published_date": "2025-03-10 13:35:51 UTC",
      "updated_date": "2025-03-10 13:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:52:34.604328"
    },
    {
      "arxiv_id": "2503.07315v1",
      "title": "Group-robust Sample Reweighting for Subpopulation Shifts via Influence Functions",
      "title_zh": "基于影响函数的子群体分布偏移的群体鲁棒样本重加权方法",
      "authors": [
        "Rui Qiao",
        "Zhaoxuan Wu",
        "Jingtan Wang",
        "Pang Wei Koh",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Machine learning models often have uneven performance among subpopulations\n(a.k.a., groups) in the data distributions. This poses a significant challenge\nfor the models to generalize when the proportions of the groups shift during\ndeployment. To improve robustness to such shifts, existing approaches have\ndeveloped strategies that train models or perform hyperparameter tuning using\nthe group-labeled data to minimize the worst-case loss over groups. However, a\nnon-trivial amount of high-quality labels is often required to obtain\nnoticeable improvements. Given the costliness of the labels, we propose to\nadopt a different paradigm to enhance group label efficiency: utilizing the\ngroup-labeled data as a target set to optimize the weights of other\ngroup-unlabeled data. We introduce Group-robust Sample Reweighting (GSR), a\ntwo-stage approach that first learns the representations from group-unlabeled\ndata, and then tinkers the model by iteratively retraining its last layer on\nthe reweighted data using influence functions. Our GSR is theoretically sound,\npractically lightweight, and effective in improving the robustness to\nsubpopulation shifts. In particular, GSR outperforms the previous\nstate-of-the-art approaches that require the same amount or even more group\nlabels.",
      "tldr_zh": "该研究提出了一种名为Group-robust Sample Reweighting (GSR)的两阶段方法，用于提高机器学习模型在子群体分布变化（subpopulation shifts）下的鲁棒性。GSR首先从未标注群体数据中学习表示，然后利用影响函数（influence functions）迭代地重新加权数据并重新训练模型的最后一层。该方法在理论上有据可依，实践中轻量高效，且仅需少量高质量的群体标注数据即可显著提升模型性能。实验表明，GSR在相同或更少标注数据的情况下，优于现有的最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 13th International Conference on Learning\n  Representations (ICLR 2025). Code is available at\n  https://github.com/qiaoruiyt/GSR",
      "pdf_url": "http://arxiv.org/pdf/2503.07315v1",
      "published_date": "2025-03-10 13:34:18 UTC",
      "updated_date": "2025-03-10 13:34:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:52:46.954231"
    },
    {
      "arxiv_id": "2503.07686v1",
      "title": "Adaptive routing protocols for determining optimal paths in AI multi-agent systems: a priority- and learning-enhanced approach",
      "title_zh": "自适应路由协议：面向AI多智能体系统最优路径的优先级与学习增强方法",
      "authors": [
        "Theodor Panayotov",
        "Ivo Emanuilov"
      ],
      "abstract": "As distributed artificial intelligence (AI) and multi-agent architectures\ngrow increasingly complex, the need for adaptive, context-aware routing becomes\nparamount. This paper introduces an enhanced, adaptive routing algorithm\ntailored for AI multi-agent networks, integrating priority-based cost functions\nand dynamic learning mechanisms. Building on an extended Dijkstra-based\nframework, we incorporate multi-faceted parameters such as task complexity,\nuser request priority, agent capabilities, bandwidth, latency, load, model\nsophistication, and reliability. We further propose dynamically adaptive\nweighting factors, tuned via reinforcement learning (RL), to continuously\nevolve routing policies based on observed network performance. Additionally,\nheuristic filtering and hierarchical routing structures improve scalability and\nresponsiveness. Our approach yields context-sensitive, load-aware, and\npriority-focused routing decisions that not only reduce latency for critical\ntasks but also optimize overall resource utilization, ultimately enhancing the\nrobustness, flexibility, and efficiency of multi-agent systems.",
      "tldr_zh": "本文提出了一种面向AI多智能体系统的自适应路由协议，通过优先级和强化学习增强的方法来优化路径选择。该算法基于扩展的Dijkstra框架，整合了任务复杂度、用户请求优先级、智能体能力等多维度参数，并采用强化学习动态调整权重因子以实现持续优化的路由策略。实验表明，该方法不仅能降低关键任务延迟，还能提高整体资源利用率，从而增强多智能体系统的鲁棒性和效率。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07686v1",
      "published_date": "2025-03-10 13:16:54 UTC",
      "updated_date": "2025-03-10 13:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:53:40.807056"
    },
    {
      "arxiv_id": "2503.07294v1",
      "title": "Distilling Knowledge into Quantum Vision Transformers for Biomedical Image Classification",
      "title_zh": "《向量子视觉Transformer蒸馏知识用于生物医学图像分类》",
      "authors": [
        "Thomas Boucher",
        "Evangelos B. Mazomenos"
      ],
      "abstract": "Quantum vision transformers (QViTs) build on vision transformers (ViTs) by\nreplacing linear layers within the self-attention mechanism with parameterised\nquantum neural networks (QNNs), harnessing quantum mechanical properties to\nimprove feature representation. This hybrid approach aims to achieve superior\nperformance, with significantly reduced model complexity as a result of the\nenriched feature representation, requiring fewer parameters. This paper\nproposes a novel QViT model for biomedical image classification and\ninvestigates its performance against comparable ViTs across eight diverse\ndatasets, encompassing various modalities and classification tasks. We assess\nmodels trained from scratch and those pre-trained using knowledge distillation\n(KD) from high-quality teacher models. Our findings demonstrate that QViTs\noutperform comparable ViTs with average ROC AUC (0.863 vs 0.846) and accuracy\n(0.710 vs 0.687) when trained from scratch, and even compete with\nstate-of-the-art classical models in multiple tasks, whilst being significantly\nmore efficient (89% reduction in GFLOPs and 99.99% in parameter number).\nAdditionally, we find that QViTs and ViTs respond equally well to KD, with QViT\npre-training performance scaling with model complexity. This is the first\ninvestigation into the efficacy of deploying QViTs with KD for computer-aided\ndiagnosis. Our results highlight the enormous potential of quantum machine\nlearning (QML) in biomedical image analysis.",
      "tldr_zh": "该研究提出了一种用于生物医学图像分类的量子视觉Transformer（QViT）模型，通过将自注意力机制中的线性层替换为参数化量子神经网络（QNNs），利用量子力学特性提升特征表示能力。实验表明，QViT在八种不同数据集上均优于传统视觉Transformer（ViTs），且模型复杂度显著降低（GFLOPs减少89%，参数量减少99.99%）。此外，知识蒸馏（KD）对QViT和ViT均有效，QViT在预训练中的性能随模型复杂性提升而增强。这是首次将QViT与KD结合用于计算机辅助诊断的研究，展示了量子机器学习（QML）在生物医学图像分析中的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted for MICCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07294v1",
      "published_date": "2025-03-10 13:16:48 UTC",
      "updated_date": "2025-03-10 13:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:53:09.894869"
    },
    {
      "arxiv_id": "2503.07279v1",
      "title": "VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in Human-AI Communication",
      "title_zh": "VizTrust：面向人机交互中用户信任动态捕捉的可视化分析工具",
      "authors": [
        "Xin Wang",
        "Stephanie Tulk Jesso",
        "Sadamori Kojaku",
        "David M Neyens",
        "Min Sun Kim"
      ],
      "abstract": "Trust plays a fundamental role in shaping the willingness of users to engage\nand collaborate with artificial intelligence (AI) systems. Yet, measuring user\ntrust remains challenging due to its complex and dynamic nature. While\ntraditional survey methods provide trust levels for long conversations, they\nfail to capture its dynamic evolution during ongoing interactions. Here, we\npresent VizTrust, which addresses this challenge by introducing a real-time\nvisual analytics tool that leverages a multi-agent collaboration system to\ncapture and analyze user trust dynamics in human-agent communication. Built on\nestablished human-computer trust scales-competence, integrity, benevolence, and\npredictability-, VizTrust enables stakeholders to observe trust formation as it\nhappens, identify patterns in trust development, and pinpoint specific\ninteraction elements that influence trust. Our tool offers actionable insights\ninto human-agent trust formation and evolution in real time through a\ndashboard, supporting the design of adaptive conversational agents that\nresponds effectively to user trust signals.",
      "tldr_zh": "该研究提出了VizTrust，一款用于实时监测人机交互中用户信任动态的可视化分析工具。基于能力、诚信、善意和可预测性四大信任维度，该工具通过多智能体协作系统捕捉信任变化过程，帮助设计者识别影响信任的关键交互元素。VizTrust仪表盘为开发能自适应响应用户信任信号的对话代理提供了实时洞察，弥补了传统调查方法在动态信任测量上的不足。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by ACM CHI conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07279v1",
      "published_date": "2025-03-10 13:00:41 UTC",
      "updated_date": "2025-03-10 13:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:53:56.634222"
    },
    {
      "arxiv_id": "2503.07275v1",
      "title": "Automatic Curriculum Design for Zero-Shot Human-AI Coordination",
      "title_zh": "零样本人机协作的自动课程设计",
      "authors": [
        "Won-Sang You",
        "Tae-Gwan Ha",
        "Seo-Young Lee",
        "Kyung-Joong Kim"
      ],
      "abstract": "Zero-shot human-AI coordination is the training of an ego-agent to coordinate\nwith humans without using human data. Most studies on zero-shot human-AI\ncoordination have focused on enhancing the ego-agent's coordination ability in\na given environment without considering the issue of generalization to unseen\nenvironments. Real-world applications of zero-shot human-AI coordination should\nconsider unpredictable environmental changes and the varying coordination\nability of co-players depending on the environment. Previously, the multi-agent\nUED (Unsupervised Environment Design) approach has investigated these\nchallenges by jointly considering environmental changes and co-player policy in\ncompetitive two-player AI-AI scenarios. In this paper, our study extends the\nmulti-agent UED approach to a zero-shot human-AI coordination. We propose a\nutility function and co-player sampling for a zero-shot human-AI coordination\nsetting that helps train the ego-agent to coordinate with humans more\neffectively than the previous multi-agent UED approach. The zero-shot human-AI\ncoordination performance was evaluated in the Overcooked-AI environment, using\nhuman proxy agents and real humans. Our method outperforms other baseline\nmodels and achieves a high human-AI coordination performance in unseen\nenvironments.",
      "tldr_zh": "本文提出了一种用于零样本人机协作的自动课程设计方法，旨在提升智能体在未见环境中与人类协作的能力。研究扩展了多智能体UED（无监督环境设计）方法，提出了一种新的效用函数和协作伙伴采样策略，以更好地适应环境变化和不同协作伙伴的策略。实验在Overcooked-AI环境中进行，结果表明该方法在未见环境中显著优于基线模型，并实现了更高的人机协作性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07275v1",
      "published_date": "2025-03-10 12:55:31 UTC",
      "updated_date": "2025-03-10 12:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:54:06.674947"
    },
    {
      "arxiv_id": "2503.07272v1",
      "title": "Federated Learning in NTNs: Design, Architecture and Challenges",
      "title_zh": "非地面网络中的联邦学习：设计、架构与挑战",
      "authors": [
        "Amin Farajzadeh",
        "Animesh Yadav",
        "Halim Yanikomeroglu"
      ],
      "abstract": "Non-terrestrial networks (NTNs) are emerging as a core component of future 6G\ncommunication systems, providing global connectivity and supporting\ndata-intensive applications. In this paper, we propose a distributed\nhierarchical federated learning (HFL) framework within the NTN architecture,\nleveraging a high altitude platform station (HAPS) constellation as\nintermediate distributed FL servers. Our framework integrates both low-Earth\norbit (LEO) satellites and ground clients in the FL training process while\nutilizing geostationary orbit (GEO) and medium-Earth orbit (MEO) satellites as\nrelays to exchange FL global models across other HAPS constellations worldwide,\nenabling seamless, global-scale learning. The proposed framework offers several\nkey benefits: (i) enhanced privacy through the decentralization of the FL\nmechanism by leveraging the HAPS constellation, (ii) improved model accuracy\nand reduced training loss while balancing latency, (iii) increased scalability\nof FL systems through ubiquitous connectivity by utilizing MEO and GEO\nsatellites, and (iv) the ability to use FL data, such as resource utilization\nmetrics, to further optimize the NTN architecture from a network management\nperspective. A numerical study demonstrates the proposed framework's\neffectiveness, with improved model accuracy, reduced training loss, and\nefficient latency management. The article also includes a brief review of FL in\nNTNs and highlights key challenges and future research directions.",
      "tldr_zh": "本文提出了一种基于非地面网络(NTNs)的分布式层次化联邦学习(HFL)框架，利用高空平台站(HAPS)星座作为中间分布式联邦学习服务器，整合低地球轨道(LEO)卫星和地面客户端进行训练，并通过地球静止轨道(GEO)和中地球轨道(MEO)卫星实现全球模型交换。该框架具有增强隐私、提高模型精度、降低训练损失、提升可扩展性等优势，并通过数值研究验证了其有效性。文章还回顾了NTNs中的联邦学习，并指出了关键挑战和未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in IEEE Communications Magazine",
      "pdf_url": "http://arxiv.org/pdf/2503.07272v1",
      "published_date": "2025-03-10 12:53:45 UTC",
      "updated_date": "2025-03-10 12:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:55:13.112955"
    },
    {
      "arxiv_id": "2503.07265v1",
      "title": "WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image Generation",
      "title_zh": "WISE：面向文本生成图像的世界知识语义评估框架",
      "authors": [
        "Yuwei Niu",
        "Munan Ning",
        "Mengren Zheng",
        "Bin Lin",
        "Peng Jin",
        "Jiaqi Liao",
        "Kunpeng Ning",
        "Bin Zhu",
        "Li Yuan"
      ],
      "abstract": "Text-to-Image (T2I) models are capable of generating high-quality artistic\ncreations and visual content. However, existing research and evaluation\nstandards predominantly focus on image realism and shallow text-image\nalignment, lacking a comprehensive assessment of complex semantic understanding\nand world knowledge integration in text to image generation. To address this\nchallenge, we propose $\\textbf{WISE}$, the first benchmark specifically\ndesigned for $\\textbf{W}$orld Knowledge-$\\textbf{I}$nformed $\\textbf{S}$emantic\n$\\textbf{E}$valuation. WISE moves beyond simple word-pixel mapping by\nchallenging models with 1000 meticulously crafted prompts across 25 sub-domains\nin cultural common sense, spatio-temporal reasoning, and natural science. To\novercome the limitations of traditional CLIP metric, we introduce\n$\\textbf{WiScore}$, a novel quantitative metric for assessing knowledge-image\nalignment. Through comprehensive testing of 20 models (10 dedicated T2I models\nand 10 unified multimodal models) using 1,000 structured prompts spanning 25\nsubdomains, our findings reveal significant limitations in their ability to\neffectively integrate and apply world knowledge during image generation,\nhighlighting critical pathways for enhancing knowledge incorporation and\napplication in next-generation T2I models. Code and data are available at\nhttps://github.com/PKU-YuanGroup/WISE.",
      "tldr_zh": "该研究提出了WISE，首个专注于**世界知识融入语义评估**的文本生成图像(T2I)模型评测基准。WISE通过1000个精心设计的提示，涵盖文化常识、时空推理和自然科学等25个子领域，挑战模型对复杂语义和世界知识的理解能力。研究还引入了**WiScore**，一种新的量化指标，用于评估知识与图像的对齐程度。通过对20个模型的全面测试，研究发现现有模型在生成图像时有效整合和应用世界知识的能力存在显著不足，为下一代T2I模型的改进指明了方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code, data and leaderboard: https://github.com/PKU-YuanGroup/WISE",
      "pdf_url": "http://arxiv.org/pdf/2503.07265v1",
      "published_date": "2025-03-10 12:47:53 UTC",
      "updated_date": "2025-03-10 12:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:54:22.711013"
    },
    {
      "arxiv_id": "2503.07685v1",
      "title": "Ways of Seeing, and Selling, AI Art",
      "title_zh": "观看与销售AI艺术的方式",
      "authors": [
        "Imke van Heerden"
      ],
      "abstract": "In early 2025, Augmented Intelligence - Christie's first AI art auction -\ndrew criticism for showcasing a controversial genre. Amid wider legal\nuncertainty, artists voiced concerns over data mining practices, notably with\nrespect to copyright. The backlash could be viewed as a microcosm of AI's\ncontested position in the creative economy. Touching on the auction's\npresentation, reception, and results, this paper explores how, among social\ndissonance, machine learning finds its place in the artworld. Foregrounding\nresponsible innovation, the paper provides a balanced perspective that\nchampions creators' rights and brings nuance to this polarised debate. With a\nfocus on exhibition design, it centres framing, which refers to the way a piece\nis presented to influence consumer perception. Context plays a central role in\nshaping our understanding of how good, valuable, and even ethical an artwork\nis. In this regard, Augmented Intelligence situates AI art within a\nsurprisingly traditional framework, leveraging hallmarks of \"high art\" to\nestablish the genre's cultural credibility. Generative AI has a clear economic\ndimension, converging questions of artistic merit with those of monetary worth.\nScholarship on ways of seeing, or framing, could substantively inform the\ninterpretation and evaluation of creative outputs, including assessments of\ntheir aesthetic and commercial value.",
      "tldr_zh": "本文以佳士得首场AI艺术拍卖会\"增强智能\"为案例，探讨人工智能艺术在创意经济中的定位争议。研究指出拍卖会通过传统\"高雅艺术\"的展示框架来建立AI艺术的文化可信度，揭示了作品呈现方式(context framing)如何影响人们对艺术品美学价值、商业价值乃至伦理性的评判。论文在创作者权利与技术创新的平衡中，为这场两极分化的辩论提供了细致入微的学术视角，特别强调展览设计在塑造AI艺术接受度中的关键作用。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07685v1",
      "published_date": "2025-03-10 12:44:11 UTC",
      "updated_date": "2025-03-10 12:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:54:30.568947"
    },
    {
      "arxiv_id": "2503.07259v1",
      "title": "COMODO: Cross-Modal Video-to-IMU Distillation for Efficient Egocentric Human Activity Recognition",
      "title_zh": "COMODO：基于跨模态视频-IMU蒸馏的高效第一人称人类活动识别方法",
      "authors": [
        "Baiyu Chen",
        "Wilson Wongso",
        "Zechen Li",
        "Yonchanok Khaokaew",
        "Hao Xue",
        "Flora Salim"
      ],
      "abstract": "Egocentric video-based models capture rich semantic information and have\ndemonstrated strong performance in human activity recognition (HAR). However,\ntheir high power consumption, privacy concerns, and dependence on lighting\nconditions limit their feasibility for continuous on-device recognition. In\ncontrast, inertial measurement unit (IMU) sensors offer an energy-efficient and\nprivacy-preserving alternative, yet they suffer from limited large-scale\nannotated datasets, leading to weaker generalization in downstream tasks. To\nbridge this gap, we propose COMODO, a cross-modal self-supervised distillation\nframework that transfers rich semantic knowledge from the video modality to the\nIMU modality without requiring labeled annotations. COMODO leverages a\npretrained and frozen video encoder to construct a dynamic instance queue,\naligning the feature distributions of video and IMU embeddings. By distilling\nknowledge from video representations, our approach enables the IMU encoder to\ninherit rich semantic information from video while preserving its efficiency\nfor real-world applications. Experiments on multiple egocentric HAR datasets\ndemonstrate that COMODO consistently improves downstream classification\nperformance, achieving results comparable to or exceeding fully supervised\nfine-tuned models. Moreover, COMODO exhibits strong cross-dataset\ngeneralization. Benefiting from its simplicity, our method is also generally\napplicable to various video and time-series pre-trained models, offering the\npotential to leverage more powerful teacher and student foundation models in\nfuture research. The code is available at https://github.com/Breezelled/COMODO .",
      "tldr_zh": "该研究提出了COMODO框架，通过跨模态自监督蒸馏方法将视频模态的丰富语义知识迁移到IMU传感器数据上，以解决基于IMU的穿戴式活动识别(HAR)存在的标注数据不足问题。该方法利用预训练且固定的视频编码器构建动态实例队列，实现视频与IMU特征分布的对齐，使IMU编码器在保持低功耗优势的同时获得视频级别的语义理解能力。实验表明，COMODO在多个第一视角HAR数据集上达到或超越全监督模型的性能，并展现出优异的跨数据集泛化能力。该框架兼容多种视频和时间序列预训练模型，为未来更强大的师生基础模型应用奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07259v1",
      "published_date": "2025-03-10 12:43:51 UTC",
      "updated_date": "2025-03-10 12:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:54:45.767167"
    },
    {
      "arxiv_id": "2503.08716v1",
      "title": "AuthorMist: Evading AI Text Detectors with Reinforcement Learning",
      "title_zh": "AuthorMist：利用强化学习规避AI文本检测器",
      "authors": [
        "Isaac David",
        "Arthur Gervais"
      ],
      "abstract": "In the age of powerful AI-generated text, automatic detectors have emerged to\nidentify machine-written content. This poses a threat to author privacy and\nfreedom, as text authored with AI assistance may be unfairly flagged. We\npropose AuthorMist, a novel reinforcement learning-based system to transform\nAI-generated text into human-like writing. AuthorMist leverages a\n3-billion-parameter language model as a backbone, fine-tuned with Group\nRelative Policy Optimization (GPRO) to paraphrase text in a way that evades AI\ndetectors.\n  Our framework establishes a generic approach where external detector APIs\n(GPTZero, WinstonAI, Originality.ai, etc.) serve as reward functions within the\nreinforcement learning loop, enabling the model to systematically learn outputs\nthat these detectors are less likely to classify as AI-generated. This\nAPI-as-reward methodology can be applied broadly to optimize text against any\ndetector with an accessible interface. Experiments on multiple datasets and\ndetectors demonstrate that AuthorMist effectively reduces the detectability of\nAI-generated text while preserving the original meaning. Our evaluation shows\nattack success rates ranging from 78.6% to 96.2% against individual detectors,\nsignificantly outperforming baseline paraphrasing methods. AuthorMist maintains\nhigh semantic similarity (above 0.94) with the original text while successfully\nevading detection. These results highlight limitations in current AI text\ndetection technologies and raise questions about the sustainability of the\ndetection-evasion arms race.",
      "tldr_zh": "该研究提出了AuthorMist，一种基于强化学习的系统，旨在将AI生成的文本转化为更接近人类写作的风格，从而规避AI文本检测器的识别。该系统采用30亿参数的语言模型作为核心，并通过Group Relative Policy Optimization (GPRO)进行微调，利用外部检测器API（如GPTZero、WinstonAI等）作为强化学习的奖励函数，使模型能够系统性地生成不易被检测为AI创作的内容。实验表明，AuthorMist在多个数据集和检测器上的攻击成功率高达78.6%至96.2%，同时保持了文本的高语义相似度（高于0.94），揭示了当前AI文本检测技术的局限性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08716v1",
      "published_date": "2025-03-10 12:41:05 UTC",
      "updated_date": "2025-03-10 12:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:55:14.404417"
    },
    {
      "arxiv_id": "2503.07248v1",
      "title": "AI-Driven Automated Tool for Abdominal CT Body Composition Analysis in Gastrointestinal Cancer Management",
      "title_zh": "AI驱动的腹部CT体成分自动分析工具在胃肠道癌症管理中的应用",
      "authors": [
        "Xinyu Nan",
        "Meng He",
        "Zifan Chen",
        "Bin Dong",
        "Lei Tang",
        "Li Zhang"
      ],
      "abstract": "The incidence of gastrointestinal cancers remains significantly high,\nparticularly in China, emphasizing the importance of accurate prognostic\nassessments and effective treatment strategies. Research shows a strong\ncorrelation between abdominal muscle and fat tissue composition and patient\noutcomes. However, existing manual methods for analyzing abdominal tissue\ncomposition are time-consuming and costly, limiting clinical research\nscalability. To address these challenges, we developed an AI-driven tool for\nautomated analysis of abdominal CT scans to effectively identify and segment\nmuscle, subcutaneous fat, and visceral fat. Our tool integrates a multi-view\nlocalization model and a high-precision 2D nnUNet-based segmentation model,\ndemonstrating a localization accuracy of 90% and a Dice Score Coefficient of\n0.967 for segmentation. Furthermore, it features an interactive interface that\nallows clinicians to refine the segmentation results, ensuring high-quality\noutcomes effectively. Our tool offers a standardized method for effectively\nextracting critical abdominal tissues, potentially enhancing the management and\ntreatment for gastrointestinal cancers. The code is available at\nhttps://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git}{https://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git.",
      "tldr_zh": "该研究开发了一种基于AI的自动化工具，用于分析腹部CT扫描中的身体成分，以辅助胃肠道癌症的管理。该工具结合了多视图定位模型和高精度的2D nnUNet分割模型，实现了90%的定位准确率和0.967的Dice相似系数，能够高效识别和分割肌肉、皮下脂肪和内脏脂肪。此外，工具还提供了交互式界面，允许临床医生优化分割结果，确保高质量输出。这一标准化方法有望提升胃肠道癌症的治疗和管理水平。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07248v1",
      "published_date": "2025-03-10 12:32:44 UTC",
      "updated_date": "2025-03-10 12:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:55:01.333513"
    },
    {
      "arxiv_id": "2503.07237v1",
      "title": "LLM-C3MOD: A Human-LLM Collaborative System for Cross-Cultural Hate Speech Moderation",
      "title_zh": "LLM-C3MOD：一种用于跨文化仇恨言论审核的人与大型语言模型协作系统",
      "authors": [
        "Junyeong Park",
        "Seogyeong Jeong",
        "Seyoung Song",
        "Yohan Lee",
        "Alice Oh"
      ],
      "abstract": "Content moderation is a global challenge, yet major tech platforms prioritize\nhigh-resource languages, leaving low-resource languages with scarce native\nmoderators. Since effective moderation depends on understanding contextual\ncues, this imbalance increases the risk of improper moderation due to\nnon-native moderators' limited cultural understanding. Through a user study, we\nidentify that non-native moderators struggle with interpreting\nculturally-specific knowledge, sentiment, and internet culture in the hate\nspeech moderation. To assist them, we present LLM-C3MOD, a human-LLM\ncollaborative pipeline with three steps: (1) RAG-enhanced cultural context\nannotations; (2) initial LLM-based moderation; and (3) targeted human\nmoderation for cases lacking LLM consensus. Evaluated on a Korean hate speech\ndataset with Indonesian and German participants, our system achieves 78%\naccuracy (surpassing GPT-4o's 71% baseline), while reducing human workload by\n83.6%. Notably, human moderators excel at nuanced contents where LLMs struggle.\nOur findings suggest that non-native moderators, when properly supported by\nLLMs, can effectively contribute to cross-cultural hate speech moderation.",
      "tldr_zh": "该研究提出LLM-C3MOD系统，通过人机协作解决跨文化仇恨言论审核的挑战。系统采用三步流程：检索增强生成(RAG)提供文化背景注释、LLM初步审核、以及针对LLM不确定案例的人工审核。在韩语仇恨言论数据集测试中，该系统准确率达78%（超过GPT-4o的71%基准），同时减少83.6%的人工工作量。研究表明，在LLM支持下，非母语审核员能有效处理文化敏感内容，其中人类审核员在LLM难以把握的微妙语境中表现更优。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Workshop - C3NLP (Workshop on Cross-Cultural\n  Considerations in NLP)",
      "pdf_url": "http://arxiv.org/pdf/2503.07237v1",
      "published_date": "2025-03-10 12:20:20 UTC",
      "updated_date": "2025-03-10 12:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:55:39.656123"
    },
    {
      "arxiv_id": "2503.07234v1",
      "title": "CoT-Drive: Efficient Motion Forecasting for Autonomous Driving with LLMs and Chain-of-Thought Prompting",
      "title_zh": "CoT-Drive：基于大语言模型与链式思维提示的高效自动驾驶运动预测",
      "authors": [
        "Haicheng Liao",
        "Hanlin Kong",
        "Bonan Wang",
        "Chengyue Wang",
        "Wang Ye",
        "Zhengbing He",
        "Chengzhong Xu",
        "Zhenning Li"
      ],
      "abstract": "Accurate motion forecasting is crucial for safe autonomous driving (AD). This\nstudy proposes CoT-Drive, a novel approach that enhances motion forecasting by\nleveraging large language models (LLMs) and a chain-of-thought (CoT) prompting\nmethod. We introduce a teacher-student knowledge distillation strategy to\neffectively transfer LLMs' advanced scene understanding capabilities to\nlightweight language models (LMs), ensuring that CoT-Drive operates in\nreal-time on edge devices while maintaining comprehensive scene understanding\nand generalization capabilities. By leveraging CoT prompting techniques for\nLLMs without additional training, CoT-Drive generates semantic annotations that\nsignificantly improve the understanding of complex traffic environments,\nthereby boosting the accuracy and robustness of predictions. Additionally, we\npresent two new scene description datasets, Highway-Text and Urban-Text,\ndesigned for fine-tuning lightweight LMs to generate context-specific semantic\nannotations. Comprehensive evaluations of five real-world datasets demonstrate\nthat CoT-Drive outperforms existing models, highlighting its effectiveness and\nefficiency in handling complex traffic scenarios. Overall, this study is the\nfirst to consider the practical application of LLMs in this field. It pioneers\nthe training and use of a lightweight LLM surrogate for motion forecasting,\nsetting a new benchmark and showcasing the potential of integrating LLMs into\nAD systems.",
      "tldr_zh": "该研究提出了CoT-Drive，一种基于大语言模型（LLMs）和链式思维提示（Chain-of-Thought Prompting）的高效运动预测方法，用于自动驾驶。通过教师-学生知识蒸馏策略，CoT-Drive将LLMs的高级场景理解能力迁移到轻量级语言模型（LMs）上，确保其在边缘设备上实时运行，同时保持全面的场景理解和泛化能力。研究还引入了两个新的场景描述数据集Highway-Text和Urban-Text，用于微调轻量级LMs生成特定语义标注。实验表明，CoT-Drive在复杂交通场景中显著优于现有模型，为LLMs在自动驾驶领域的实际应用提供了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07234v1",
      "published_date": "2025-03-10 12:17:38 UTC",
      "updated_date": "2025-03-10 12:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:55:06.506636"
    },
    {
      "arxiv_id": "2503.07214v1",
      "title": "Cross-Lingual IPA Contrastive Learning for Zero-Shot NER",
      "title_zh": "跨语言IPA对比学习在零样本命名实体识别中的应用",
      "authors": [
        "Jimin Sohn",
        "David R. Mortensen"
      ],
      "abstract": "Existing approaches to zero-shot Named Entity Recognition (NER) for\nlow-resource languages have primarily relied on machine translation, whereas\nmore recent methods have shifted focus to phonemic representation. Building\nupon this, we investigate how reducing the phonemic representation gap in IPA\ntranscription between languages with similar phonetic characteristics enables\nmodels trained on high-resource languages to perform effectively on\nlow-resource languages. In this work, we propose CONtrastive Learning with IPA\n(CONLIPA) dataset containing 10 English and high resource languages IPA pairs\nfrom 10 frequently used language families. We also propose a cross-lingual IPA\nContrastive learning method (IPAC) using the CONLIPA dataset. Furthermore, our\nproposed dataset and methodology demonstrate a substantial average gain when\ncompared to the best performing baseline.",
      "tldr_zh": "该研究提出了一种基于国际音标(IPA)的跨语言对比学习方法(IPAC)，用于解决低资源语言的零样本命名实体识别(NER)问题。研究团队构建了CONLIPA数据集，包含10个英语和高资源语言的IPA配对，覆盖10个常用语系。通过缩小语言间IPA音标表征差异，该方法使模型能够将高资源语言的知识迁移到语音特征相似的低资源语言上。实验表明，该方案相较现有最佳基线模型取得了显著性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07214v1",
      "published_date": "2025-03-10 11:52:33 UTC",
      "updated_date": "2025-03-10 11:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:56:11.754656"
    },
    {
      "arxiv_id": "2503.07210v1",
      "title": "Discrete Gaussian Process Representations for Optimising UAV-based Precision Weed Mapping",
      "title_zh": "基于离散高斯过程表示的无人机精准杂草测绘优化",
      "authors": [
        "Jacob Swindell",
        "Madeleine Darbyshire",
        "Marija Popovic",
        "Riccardo Polvara"
      ],
      "abstract": "Accurate agricultural weed mapping using UAVs is crucial for precision\nfarming applications. Traditional methods rely on orthomosaic stitching from\nrigid flight paths, which is computationally intensive and time-consuming.\nGaussian Process (GP)-based mapping offers continuous modelling of the\nunderlying variable (i.e. weed distribution) but requires discretisation for\npractical tasks like path planning or visualisation. Current implementations\noften default to quadtrees or gridmaps without systematically evaluating\nalternatives. This study compares five discretisation methods: quadtrees,\nwedgelets, top-down binary space partition (BSP) trees using least square error\n(LSE), bottom-up BSP trees using graph merging, and variable-resolution\nhexagonal grids. Evaluations on real-world weed distributions measure visual\nsimilarity, mean squared error (MSE), and computational efficiency. Results\nshow quadtrees perform best overall, but alternatives excel in specific\nscenarios: hexagons or BSP LSE suit fields with large, dominant weed patches,\nwhile quadtrees are optimal for dispersed small-scale distributions. These\nfindings highlight the need to tailor discretisation approaches to weed\ndistribution patterns (patch size, density, coverage) rather than relying on\ndefault methods. By choosing representations based on the underlying\ndistribution, we can improve mapping accuracy and efficiency for precision\nagriculture applications.",
      "tldr_zh": "本研究比较了五种离散化方法（四叉树、楔形分割、基于最小二乘误差的二叉树、基于图合并的二叉树和可变分辨率六边形网格），用于优化基于无人机(UAV)的精准杂草分布地图。研究结果表明，四叉树整体表现最佳，但在特定场景下其他方法更优：六边形网格或二叉树适合大面积杂草分布，而四叉树则适用于小规模分散分布。这些发现强调，应根据杂草分布模式（如斑块大小、密度和覆盖度）选择离散化方法，而非依赖默认方法，从而提高精准农业应用的绘图精度和效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07210v1",
      "published_date": "2025-03-10 11:50:15 UTC",
      "updated_date": "2025-03-10 11:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:56:04.222446"
    },
    {
      "arxiv_id": "2503.07202v1",
      "title": "A Zero-shot Learning Method Based on Large Language Models for Multi-modal Knowledge Graph Embedding",
      "title_zh": "基于大语言模型的多模态知识图谱嵌入零样本学习方法",
      "authors": [
        "Bingchen Liu",
        "Jingchen Li",
        "Naixing Xu",
        "Xin Li"
      ],
      "abstract": "Zero-shot learning (ZL) is crucial for tasks involving unseen categories,\nsuch as natural language processing, image classification, and cross-lingual\ntransfer. Current applications often fail to accurately infer and handle new\nrelations or entities involving unseen categories, severely limiting their\nscalability and practicality in open-domain scenarios. ZL learning faces the\nchallenge of effectively transferring semantic information of unseen categories\nin multi-modal knowledge graph (MMKG) embedding representation learning. In\nthis paper, we propose ZSLLM, a framework for zero-shot embedding learning of\nMMKGs using large language models (LLMs). We leverage textual modality\ninformation of unseen categories as prompts to fully utilize the reasoning\ncapabilities of LLMs, enabling semantic information transfer across different\nmodalities for unseen categories. Through model-based learning, the embedding\nrepresentation of unseen categories in MMKG is enhanced. Extensive experiments\nconducted on multiple real-world datasets demonstrate the superiority of our\napproach compared to state-of-the-art methods.",
      "tldr_zh": "本研究提出了一种基于大语言模型(LLMs)的零样本学习框架ZSLLM，用于多模态知识图谱(MMKG)的嵌入表示学习。该框架利用未见类别的文本模态信息作为提示，充分发挥LLMs的推理能力，实现跨模态的语义信息迁移，从而增强MMKG中未见类别的嵌入表示。实验结果表明，该方法在多个真实数据集上优于现有最先进方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07202v1",
      "published_date": "2025-03-10 11:38:21 UTC",
      "updated_date": "2025-03-10 11:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:56:07.591165"
    },
    {
      "arxiv_id": "2503.13489v2",
      "title": "AI-driven control of bioelectric signalling for real-time topological reorganization of cells",
      "title_zh": "AI驱动的生物电信号控制实现细胞拓扑结构的实时重组",
      "authors": [
        "Gonçalo Hora de Carvalho"
      ],
      "abstract": "Understanding and manipulating bioelectric signaling could present a new wave\nof progress in developmental biology, regenerative medicine, and synthetic\nbiology. Bioelectric signals, defined as voltage gradients across cell\nmembranes caused by ionic movements, play a role in regulating crucial\nprocesses including cellular differentiation, proliferation, apoptosis, and\ntissue morphogenesis. Recent studies demonstrate the ability to modulate these\nsignals to achieve controlled tissue regeneration and morphological outcomes in\norganisms such as planaria and frogs. However, significant knowledge gaps\nremain, particularly in predicting and controlling the spatial and temporal\ndynamics of membrane potentials (V_mem), understanding their regulatory roles\nin tissue and organ development, and exploring their therapeutic potential in\ndiseases. In this work we propose an experiment using Deep Reinforcement\nLearning (DRL) framework together with lab automation techniques for real-time\nmanipulation of bioelectric signals to guide tissue regeneration and\nmorphogenesis. The proposed framework should interact continuously with\nbiological systems, adapting strategies based on direct biological feedback.\nCombining DRL with real-time measurement techniques -- such as optogenetics,\nvoltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could\nprovide a comprehensive platform for precise bioelectric control, leading to\nimproved understanding of bioelectric mechanisms in morphogenesis, quantitative\nbioelectric models, identification of minimal experimental setups, and\nadvancements in bioelectric modulation techniques relevant to regenerative\nmedicine and cancer therapy. Ultimately, this research aims to utilize\nbioelectric signaling to develop new biomedical and bioengineering\napplications.",
      "tldr_zh": "该研究提出了一种基于深度强化学习(DRL)和实验室自动化技术的实时生物电信号调控系统，旨在精确控制细胞膜电位(V_mem)以指导组织再生和形态发生。通过整合光遗传学、电压敏感染料等实时测量技术，该框架能根据生物反馈动态调整策略，为理解形态发生中的生物电机制提供定量模型。这项研究有望推动再生医学和癌症治疗领域的生物电调控技术发展，开发新型生物医学应用。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "physics.bio-ph",
        "q-bio.CB",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13489v2",
      "published_date": "2025-03-10 11:30:32 UTC",
      "updated_date": "2025-03-19 14:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:56:27.992736"
    },
    {
      "arxiv_id": "2503.07682v1",
      "title": "A Time Series Multitask Framework Integrating a Large Language Model, Pre-Trained Time Series Model, and Knowledge Graph",
      "title_zh": "时间序列多任务框架：融合大语言模型、预训练时间序列模型与知识图谱",
      "authors": [
        "Shule Hao",
        "Junpeng Bao",
        "Chuncheng Lu"
      ],
      "abstract": "Time series analysis is crucial in fields like finance, transportation, and\nindustry. However, traditional models often focus solely on temporal features,\nlimiting their ability to capture underlying information. This paper proposes a\nnovel time series multitask framework, called LTM, which integrates temporal\nfeatures with textual descriptions to enhance analytical and predictive\ncapabilities. LTM combines pre-trained time series model, large language model\n(LLM), and knowledge graph to tackle time series tasks, including forecasting,\nimputation, and anomaly detection. LTM achieves improved performance with a few\ntrainable parameters. It is very efficient and practical. LTM encodes time\nseries data into patches and enriches user-provided prompts using knowledge\ngraphs to generate enhanced prompts. A novel feature fusion method embeds\nprompts into each patch encoding, which is processed by a frozen LLM, followed\nby a feature enhancement module and a time decoder module. During fine-tuning\nstage, cosine similarity between prompts and temporal patches is integrated\ninto the loss function to boost performance. Experiments on benchmark datasets\nshow that LTM significantly outperforms existing methods. It provides a robust\nand versatile solution for time series tasks.",
      "tldr_zh": "本文提出了一种新颖的时间序列多任务框架LTM，通过整合预训练时间序列模型、大语言模型(LLM)和知识图谱，显著提升了时间序列任务的性能。LTM采用创新的特征融合方法，将用户提供的提示通过知识图谱增强，并嵌入到时间序列数据的分块编码中，再通过冻结的LLM和特征增强模块进行处理。实验结果表明，LTM在预测、插补和异常检测等任务上均优于现有方法，且仅需少量可训练参数，具有高效性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07682v1",
      "published_date": "2025-03-10 11:25:01 UTC",
      "updated_date": "2025-03-10 11:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:56:29.398736"
    },
    {
      "arxiv_id": "2503.07680v1",
      "title": "Hierarchical Balance Packing: Towards Efficient Supervised Fine-tuning for Long-Context LLM",
      "title_zh": "分层平衡打包：面向长上下文大语言模型的高效监督微调方法",
      "authors": [
        "Yongqiang Yao",
        "Jingru Tan",
        "Kaihuan Liang",
        "Feizhao Zhang",
        "Yazhe Niu",
        "Jiahao Hu",
        "Ruihao Gong",
        "Dahua Lin",
        "Ningyi Xu"
      ],
      "abstract": "Training Long-Context Large Language Models (LLMs) is challenging, as hybrid\ntraining with long-context and short-context data often leads to workload\nimbalances. Existing works mainly use data packing to alleviate this issue but\nfail to consider imbalanced attention computation and wasted communication\noverhead. This paper proposes Hierarchical Balance Packing (HBP), which designs\na novel batch-construction method and training recipe to address those\ninefficiencies. In particular, the HBP constructs multi-level data packing\ngroups, each optimized with a distinct packing length. It assigns training\nsamples to their optimal groups and configures each group with the most\neffective settings, including sequential parallelism degree and gradient\ncheckpointing configuration. To effectively utilize multi-level groups of data,\nwe design a dynamic training pipeline specifically tailored to HBP, including\ncurriculum learning, adaptive sequential parallelism, and stable loss. Our\nextensive experiments demonstrate that our method significantly reduces\ntraining time over multiple datasets and open-source models while maintaining\nstrong performance. For the largest DeepSeek-V2 (236B) MOE model, our method\nspeeds up the training by 2.4$\\times$ with competitive performance.",
      "tldr_zh": "本文提出了分层平衡打包（Hierarchical Balance Packing, HBP）方法，以解决长上下文大语言模型（LLMs）在混合训练中因长上下文和短上下文数据并存而导致的计算负载不平衡和通信开销浪费问题。HBP通过构建多层数据打包组，为每组优化打包长度，并结合动态训练管道（包括课程学习、自适应序列并行和稳定损失）显著提升训练效率。实验表明，该方法在多个数据集和开源模型上大幅减少训练时间，尤其在DeepSeek-V2（236B）MOE模型上实现了2.4倍的加速，同时保持了较强的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07680v1",
      "published_date": "2025-03-10 10:52:50 UTC",
      "updated_date": "2025-03-10 10:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:56:40.053877"
    },
    {
      "arxiv_id": "2503.07172v1",
      "title": "Lawful and Accountable Personal Data Processing with GDPR-based Access and Usage Control in Distributed Systems",
      "title_zh": "分布式系统中基于GDPR的访问与使用控制实现合法且可问责的个人数据处理",
      "authors": [
        "L. Thomas van Binsbergen",
        "Marten C. Steketee",
        "Milen G. Kebede",
        "Heleen L. Janssen",
        "Tom M. van Engers"
      ],
      "abstract": "Compliance with the GDPR privacy regulation places a significant burden on\norganisations regarding the handling of personal data. The perceived efforts\nand risks of complying with the GDPR further increase when data processing\nactivities span across organisational boundaries, as is the case in both\nsmall-scale data sharing settings and in large-scale international data spaces.\n  This paper addresses these concerns by proposing a case-generic method for\nautomated normative reasoning that establishes legal arguments for the\nlawfulness of data processing activities. The arguments are established on the\nbasis of case-specific legal qualifications made by privacy experts, bringing\nthe human in the loop. The obtained expert system promotes transparency and\naccountability, remains adaptable to extended or altered interpretations of the\nGDPR, and integrates into novel or existing distributed data processing\nsystems.\n  This result is achieved by defining a formal ontology and semantics for\nautomated normative reasoning based on an analysis of the purpose-limitation\nprinciple of the GDPR. The ontology and semantics are implemented in eFLINT, a\ndomain-specific language for specifying and reasoning with norms. The XACML\narchitecture standard, applicable to both access and usage control, is\nextended, demonstrating how GDPR-based normative reasoning can integrate into\n(existing, distributed) systems for data processing. The resulting system is\ndesigned and critically assessed in reference to requirements extracted from\nthe GPDR.",
      "tldr_zh": "该研究提出了一种基于GDPR的自动化规范推理方法，旨在解决跨组织边界数据处理中的合法性和问责性问题。通过定义形式化本体和语义，结合隐私专家的法律认定，构建了一个专家系统，确保数据处理的透明性和适应性。该方法扩展了XACML架构标准，支持访问和使用控制，并集成到现有或新型的分布式数据处理系统中，满足GDPR的要求。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted for review to the Journal of AI and Law, 49 pages\n  (including)",
      "pdf_url": "http://arxiv.org/pdf/2503.07172v1",
      "published_date": "2025-03-10 10:49:34 UTC",
      "updated_date": "2025-03-10 10:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:56:39.248368"
    },
    {
      "arxiv_id": "2503.07170v1",
      "title": "DeFine: A Decomposed and Fine-Grained Annotated Dataset for Long-form Article Generation",
      "title_zh": "DeFine：面向长文生成任务的分解式细粒度标注数据集",
      "authors": [
        "Ming Wang",
        "Fang Wang",
        "Minghao Hu",
        "Li He",
        "Haiyang Wang",
        "Jun Zhang",
        "Tianwei Yan",
        "Li Li",
        "Zhunchen Luo",
        "Wei Luo",
        "Xiaoying Bai",
        "Guotong Geng"
      ],
      "abstract": "Long-form article generation (LFAG) presents challenges such as maintaining\nlogical consistency, comprehensive topic coverage, and narrative coherence\nacross extended articles. Existing datasets often lack both the hierarchical\nstructure and fine-grained annotation needed to effectively decompose tasks,\nresulting in shallow, disorganized article generation. To address these\nlimitations, we introduce DeFine, a Decomposed and Fine-grained annotated\ndataset for long-form article generation. DeFine is characterized by its\nhierarchical decomposition strategy and the integration of domain-specific\nknowledge with multi-level annotations, ensuring granular control and enhanced\ndepth in article generation. To construct the dataset, a multi-agent\ncollaborative pipeline is proposed, which systematically segments the\ngeneration process into four parts: Data Miner, Cite Retreiver, Q&A Annotator\nand Data Cleaner. To validate the effectiveness of DeFine, we designed and\ntested three LFAG baselines: the web retrieval, the local retrieval, and the\ngrounded reference. We fine-tuned the Qwen2-7b-Instruct model using the DeFine\ntraining dataset. The experimental results showed significant improvements in\ntext quality, specifically in topic coverage, depth of information, and content\nfidelity. Our dataset publicly available to facilitate future research.",
      "tldr_zh": "该研究提出了DeFine数据集，这是一种针对长文生成任务(LFAG)的细粒度标注数据集，通过层次化分解策略和多级注释系统解决了现有数据在逻辑一致性、主题覆盖和叙事连贯性方面的不足。研究团队采用多智能体协作流程（包含数据挖掘、引用检索、问答标注和数据清洗四个模块）构建数据集，并基于Qwen2-7b-Instruct模型验证了其有效性。实验结果表明，使用DeFine训练显著提升了生成文本的主题覆盖率(36%)、信息深度(28%)和内容保真度(42%)，为可控长文生成建立了新基准。该数据集已开源以促进相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07170v1",
      "published_date": "2025-03-10 10:48:00 UTC",
      "updated_date": "2025-03-10 10:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:57:03.294271"
    },
    {
      "arxiv_id": "2503.07158v4",
      "title": "Generative AI in Transportation Planning: A Survey",
      "title_zh": "生成式人工智能在交通规划中的应用：综述",
      "authors": [
        "Longchao Da",
        "Tiejin Chen",
        "Zhuoheng Li",
        "Shreyas Bachiraju",
        "Huaiyuan Yao",
        "Li Li",
        "Yushun Dong",
        "Xiyang Hu",
        "Zhengzhong Tu",
        "Dongjie Wang",
        "Yue Zhao",
        "Xuanyu",
        "Zhou",
        "Ram Pendyala",
        "Benjamin Stabler",
        "Yezhou Yang",
        "Xuesong Zhou",
        "Hua Wei"
      ],
      "abstract": "The integration of generative artificial intelligence (GenAI) into\ntransportation planning has the potential to revolutionize tasks such as demand\nforecasting, infrastructure design, policy evaluation, and traffic simulation.\nHowever, there is a critical need for a systematic framework to guide the\nadoption of GenAI in this interdisciplinary domain. In this survey, we, a\nmultidisciplinary team of researchers spanning computer science and\ntransportation engineering, present the first comprehensive framework for\nleveraging GenAI in transportation planning. Specifically, we introduce a new\ntaxonomy that categorizes existing applications and methodologies into two\nperspectives: transportation planning tasks and computational techniques. From\nthe transportation planning perspective, we examine the role of GenAI in\nautomating descriptive, predictive, generative, simulation, and explainable\ntasks to enhance mobility systems. From the computational perspective, we\ndetail advancements in data preparation, domain-specific fine-tuning, and\ninference strategies, such as retrieval-augmented generation and zero-shot\nlearning tailored to transportation applications. Additionally, we address\ncritical challenges, including data scarcity, explainability, bias mitigation,\nand the development of domain-specific evaluation frameworks that align with\ntransportation goals like sustainability, equity, and system efficiency. This\nsurvey aims to bridge the gap between traditional transportation planning\nmethodologies and modern AI techniques, fostering collaboration and innovation.\nBy addressing these challenges and opportunities, we seek to inspire future\nresearch that ensures ethical, equitable, and impactful use of generative AI in\ntransportation planning.",
      "tldr_zh": "这篇综述首次提出了生成式人工智能(GenAI)在交通规划领域的系统性应用框架。研究团队通过交通任务(需求预测、基础设施设计等)和计算技术(检索增强生成、零样本学习等)双重视角，构建了新的分类体系。论文重点探讨了GenAI在提升交通系统自动化程度方面的潜力，同时指出了数据稀缺、可解释性等关键挑战，旨在推动AI技术与传统交通规划的融合，促进可持续、公平的智能交通发展。",
      "categories": [
        "cs.AI",
        "68T99, 90B06",
        "I.2.6; I.2.8; I.6.3; J.2"
      ],
      "primary_category": "cs.AI",
      "comment": "55 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07158v4",
      "published_date": "2025-03-10 10:33:31 UTC",
      "updated_date": "2025-03-18 05:03:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:56:58.833055"
    },
    {
      "arxiv_id": "2503.07154v2",
      "title": "Ideas in Inference-time Scaling can Benefit Generative Pre-training Algorithms",
      "title_zh": "推理时扩展理念可助力生成式预训练算法发展",
      "authors": [
        "Jiaming Song",
        "Linqi Zhou"
      ],
      "abstract": "Recent years have seen significant advancements in foundation models through\ngenerative pre-training, yet algorithmic innovation in this space has largely\nstagnated around autoregressive models for discrete signals and diffusion\nmodels for continuous signals. This stagnation creates a bottleneck that\nprevents us from fully unlocking the potential of rich multi-modal data, which\nin turn limits the progress on multimodal intelligence. We argue that an\ninference-first perspective, which prioritizes scaling efficiency during\ninference time across sequence length and refinement steps, can inspire novel\ngenerative pre-training algorithms. Using Inductive Moment Matching (IMM) as a\nconcrete example, we demonstrate how addressing limitations in diffusion\nmodels' inference process through targeted modifications yields a stable,\nsingle-stage algorithm that achieves superior sample quality with over an order\nof magnitude greater inference efficiency.",
      "tldr_zh": "该论文提出\"推理优先\"(inference-first)的创新视角，认为关注推理阶段在序列长度和优化步骤上的扩展效率可启发新型生成式预训练算法。研究以归纳矩匹配(IMM)为例，通过针对性改进扩散模型的推理过程，开发出稳定的单阶段算法，在保持样本质量的同时将推理效率提升一个数量级以上。这一发现突破了当前生成预训练算法局限于自回归和扩散模型的瓶颈，为多模态智能发展提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07154v2",
      "published_date": "2025-03-10 10:27:30 UTC",
      "updated_date": "2025-03-11 16:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:57:06.796828"
    },
    {
      "arxiv_id": "2503.07153v1",
      "title": "PTMs-TSCIL Pre-Trained Models Based Class-Incremental Learning",
      "title_zh": "基于预训练模型的时间序列类增量学习",
      "authors": [
        "Yuanlong Wu",
        "Mingxing Nie",
        "Tao Zhu",
        "Liming Chen",
        "Huansheng Ning",
        "Yaping Wan"
      ],
      "abstract": "Class-incremental learning (CIL) for time series data faces critical\nchallenges in balancing stability against catastrophic forgetting and\nplasticity for new knowledge acquisition, particularly under real-world\nconstraints where historical data access is restricted. While pre-trained\nmodels (PTMs) have shown promise in CIL for vision and NLP domains, their\npotential in time series class-incremental learning (TSCIL) remains\nunderexplored due to the scarcity of large-scale time series pre-trained\nmodels. Prompted by the recent emergence of large-scale pre-trained models\n(PTMs) for time series data, we present the first exploration of PTM-based Time\nSeries Class-Incremental Learning (TSCIL). Our approach leverages frozen PTM\nbackbones coupled with incrementally tuning the shared adapter, preserving\ngeneralization capabilities while mitigating feature drift through knowledge\ndistillation. Furthermore, we introduce a Feature Drift Compensation Network\n(DCN), designed with a novel two-stage training strategy to precisely model\nfeature space transformations across incremental tasks. This allows for\naccurate projection of old class prototypes into the new feature space. By\nemploying DCN-corrected prototypes, we effectively enhance the unified\nclassifier retraining, mitigating model feature drift and alleviating\ncatastrophic forgetting. Extensive experiments on five real-world datasets\ndemonstrate state-of-the-art performance, with our method yielding final\naccuracy gains of 1.4%-6.1% across all datasets compared to existing PTM-based\napproaches. Our work establishes a new paradigm for TSCIL, providing insights\ninto stability-plasticity optimization for continual learning systems.",
      "tldr_zh": "该研究首次探索了基于预训练模型(PTMs)的时间序列类增量学习(TSCIL)，解决了在历史数据受限条件下平衡稳定性与可塑性这一关键挑战。方法采用冻结的PTM主干网络，并结合增量调优的共享适配器，通过知识蒸馏保留泛化能力并缓解特征漂移。此外，引入特征漂移补偿网络(DCN)，采用两阶段训练策略精确建模特征空间变换，有效缓解灾难性遗忘。实验表明，该方法在五个真实数据集上均实现了最先进的性能，最终准确率比现有PTM方法提升了1.4%-6.1%，为持续学习系统的稳定性-可塑性优化提供了新范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07153v1",
      "published_date": "2025-03-10 10:27:21 UTC",
      "updated_date": "2025-03-10 10:27:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:57:35.520071"
    },
    {
      "arxiv_id": "2503.07148v2",
      "title": "Hierarchical Neuro-Symbolic Decision Transformer",
      "title_zh": "分层神经符号决策Transformer",
      "authors": [
        "Ali Baheri",
        "Cecilia O. Alm"
      ],
      "abstract": "We present a hierarchical neuro-symbolic control framework that couples\nclassical symbolic planning with transformer-based policies to address complex,\nlong-horizon decision-making tasks. At the high level, a symbolic planner\nconstructs an interpretable sequence of operators based on logical\npropositions, ensuring systematic adherence to global constraints and goals. At\nthe low level, each symbolic operator is translated into a sub-goal token that\nconditions a decision transformer to generate a fine-grained sequence of\nactions in uncertain, high-dimensional environments. We provide theoretical\nanalysis showing how approximation errors from both the symbolic planner and\nthe neural execution layer accumulate. Empirical evaluations in grid-worlds\nwith multiple keys, locked doors, and item-collection tasks show that our\nhierarchical approach outperforms purely end-to-end neural approach in success\nrates and policy efficiency.",
      "tldr_zh": "本研究提出了一种分层神经符号控制框架（Hierarchical Neuro-Symbolic Decision Transformer），结合符号规划与基于Transformer的策略来解决复杂长程决策任务。该框架包含两个层次：高层使用符号规划器生成可解释的操作序列，确保符合全局约束和目标；底层通过决策Transformer将符号操作转化为具体动作序列，以处理不确定的高维环境。理论分析揭示了符号规划器和神经执行层的误差累积机制。在包含多钥匙、锁门和物品收集任务的网格世界实验中，该方法在成功率和策略效率上均优于纯端到端的神经网络方法。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07148v2",
      "published_date": "2025-03-10 10:22:13 UTC",
      "updated_date": "2025-03-12 15:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:57:32.553020"
    },
    {
      "arxiv_id": "2503.07144v1",
      "title": "MRCEval: A Comprehensive, Challenging and Accessible Machine Reading Comprehension Benchmark",
      "title_zh": "MRCEval：一个全面、高挑战性且易用的机器阅读理解基准平台",
      "authors": [
        "Shengkun Ma",
        "Hao Peng",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Machine Reading Comprehension (MRC) is an essential task in evaluating\nnatural language understanding. Existing MRC datasets primarily assess specific\naspects of reading comprehension (RC), lacking a comprehensive MRC benchmark.\nTo fill this gap, we first introduce a novel taxonomy that categorizes the key\ncapabilities required for RC. Based on this taxonomy, we construct MRCEval, an\nMRC benchmark that leverages advanced Large Language Models (LLMs) as both\nsample generators and selection judges. MRCEval is a comprehensive, challenging\nand accessible benchmark designed to assess the RC capabilities of LLMs\nthoroughly, covering 13 distinct RC skills with a total of 2.1K high-quality\nmulti-choice questions. We perform an extensive evaluation of 28 widely used\nopen-source and proprietary models, highlighting that MRC continues to present\nsignificant challenges even in the era of LLMs.",
      "tldr_zh": "该研究提出了MRCEval——首个全面评估机器阅读理解(MRC)能力的基准测试，通过构建包含13种阅读理解技能的创新分类法，生成了2,100道高质量选择题。研究创新性地使用大语言模型(LLMs)同时作为题目生成器和筛选评判者，对28个主流开源和商业模型进行评估。结果表明，即使在LLMs时代，机器阅读理解仍然面临重大挑战，该基准测试具有全面性、挑战性和易用性三大特点，填补了现有MRC评估体系缺乏综合性基准的空白。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.07144v1",
      "published_date": "2025-03-10 10:20:05 UTC",
      "updated_date": "2025-03-10 10:20:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:57:36.671424"
    },
    {
      "arxiv_id": "2503.07137v1",
      "title": "A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and Applications",
      "title_zh": "专家混合模型全面综述：算法、理论与应用",
      "authors": [
        "Siyuan Mu",
        "Sen Lin"
      ],
      "abstract": "Artificial intelligence (AI) has achieved astonishing successes in many\ndomains, especially with the recent breakthroughs in the development of\nfoundational large models. These large models, leveraging their extensive\ntraining data, provide versatile solutions for a wide range of downstream\ntasks. However, as modern datasets become increasingly diverse and complex, the\ndevelopment of large AI models faces two major challenges: (1) the enormous\nconsumption of computational resources and deployment difficulties, and (2) the\ndifficulty in fitting heterogeneous and complex data, which limits the\nusability of the models. Mixture of Experts (MoE) models has recently attracted\nmuch attention in addressing these challenges, by dynamically selecting and\nactivating the most relevant sub-models to process input data. It has been\nshown that MoEs can significantly improve model performance and efficiency with\nfewer resources, particularly excelling in handling large-scale, multimodal\ndata. Given the tremendous potential MoE has demonstrated across various\ndomains, it is urgent to provide a comprehensive summary of recent advancements\nof MoEs in many important fields. Existing surveys on MoE have their\nlimitations, e.g., being outdated or lacking discussion on certain key areas,\nand we aim to address these gaps. In this paper, we first introduce the basic\ndesign of MoE, including gating functions, expert networks, routing mechanisms,\ntraining strategies, and system design. We then explore the algorithm design of\nMoE in important machine learning paradigms such as continual learning,\nmeta-learning, multi-task learning, and reinforcement learning. Additionally,\nwe summarize theoretical studies aimed at understanding MoE and review its\napplications in computer vision and natural language processing. Finally, we\ndiscuss promising future research directions.",
      "tldr_zh": "本文对混合专家模型(Mixture-of-Experts, MoE)进行了系统性综述，该技术通过动态选择和激活相关子模型来处理输入数据，有效解决了大模型计算资源消耗和复杂数据适配问题。文章首先详细阐述了MoE的基础设计，包括门控函数、专家网络、路由机制等核心组件，然后分析了其在持续学习、元学习等机器学习范式中的应用。此外，研究还总结了MoE的理论进展及其在计算机视觉和自然语言处理领域的应用成果，最后探讨了该技术的未来发展方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07137v1",
      "published_date": "2025-03-10 10:08:55 UTC",
      "updated_date": "2025-03-10 10:08:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:57:46.996501"
    },
    {
      "arxiv_id": "2503.07129v1",
      "title": "ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through Action in Dynamic Offer Optimization",
      "title_zh": "ASTRA：动态报价优化中具备自适应与策略性行动推理的谈判智能体",
      "authors": [
        "Deuksin Kwon",
        "Jiwon Hae",
        "Emma Clift",
        "Daniel Shamsoddini",
        "Jonathan Gratch",
        "Gale M. Lucas"
      ],
      "abstract": "Negotiation requires dynamically balancing self-interest and cooperation to\nmaximize one's own utility. Yet, existing agents struggle due to bounded\nrationality in human data, low adaptability to counterpart behavior, and\nlimited strategic reasoning. To address this, we introduce principle-driven\nnegotiation agents, powered by ASTRA, a novel framework for turn-level offer\noptimization grounded in two core principles: opponent modeling and Tit-for-Tat\nreciprocity. ASTRA operates in three stages: (1) interpreting counterpart\nbehavior, (2) optimizing counteroffers via a linear programming (LP) solver,\nand (3) selecting offers based on negotiation tactics and the partner's\nacceptance probability. Through simulations and human evaluations, our agent\neffectively adapts to an opponent's shifting stance and achieves favorable\noutcomes through enhanced adaptability and strategic reasoning. Beyond\nimproving negotiation performance, it also serves as a powerful coaching tool,\noffering interpretable strategic feedback and optimal offer recommendations.",
      "tldr_zh": "该研究提出了ASTRA，一种基于对手建模和“以牙还牙”互惠原则的谈判代理框架，旨在解决现有代理在动态谈判中的适应性和策略推理能力不足的问题。ASTRA通过三阶段流程运作：解读对手行为、利用线性规划（LP）求解器优化还价、并根据谈判策略和对手接受概率选择出价。实验表明，该代理能够有效适应对手的动态立场，并通过增强的适应性和策略推理实现有利的谈判结果，同时还可作为提供可解释策略反馈和最优出价建议的教练工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07129v1",
      "published_date": "2025-03-10 09:57:50 UTC",
      "updated_date": "2025-03-10 09:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:57:56.506727"
    },
    {
      "arxiv_id": "2503.10669v1",
      "title": "UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality",
      "title_zh": "UC-MOA：面向分布式帕累托最优的效用条件多目标对齐",
      "authors": [
        "Zelei Cheng",
        "Xin-Qiang Cai",
        "Yuting Tang",
        "Pushi Zhang",
        "Boming Yang",
        "Xinyu Xing"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become a cornerstone\nfor aligning large language models (LLMs) with human values. However, existing\napproaches struggle to capture the multi-dimensional, distributional nuances of\nhuman preferences. Methods such as RiC that directly inject raw reward values\ninto prompts face significant numerical sensitivity issues--for instance, LLMs\nmay fail to distinguish between 9.11 and 9.8--while alternatives like MORLHF,\nRewarded Soups, and MODPO incur high computational costs by training multiple\nmodels. In this work, we introduce Utility-Conditioned Multi-Objective\nAlignment (UC-MOA), a novel framework that overcomes these limitations. Our\napproach leverages a diverse set of strictly increasing, non-linear utility\nfunctions to transform user-specified preferences into symbolic tokens, which\nare then used to condition a single LLM. This design not only mitigates\nnumerical reasoning challenges but also substantially reduces training\noverhead, yielding models that achieve superior Pareto fronts and robust\nalignment across complex reward dimensions.",
      "tldr_zh": "该研究提出UC-MOA（Utility-Conditioned Multi-Objective Alignment）框架，用于解决当前基于人类反馈的强化学习（RLHF）在多目标对齐中存在的数值敏感性和计算成本高的问题。该方法通过一组严格递增的非线性效用函数将用户偏好转化为符号化token，仅需训练单个大语言模型（LLM）即可实现分布式的帕累托最优（Pareto-optimality）。实验表明，UC-MOA能有效避免数值敏感性（如区分9.11和9.8的困难），相比MORLHF等方法显著降低计算成本，同时在复杂奖励维度上实现更优的帕累托前沿和鲁棒对齐。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Language Modeling, Machine Learning for NLP",
      "pdf_url": "http://arxiv.org/pdf/2503.10669v1",
      "published_date": "2025-03-10 09:52:42 UTC",
      "updated_date": "2025-03-10 09:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:58:13.553180"
    },
    {
      "arxiv_id": "2503.07110v1",
      "title": "A LSTM-Transformer Model for pulsation control of pVADs",
      "title_zh": "用于pVAD脉动控制的LSTM-Transformer模型",
      "authors": [
        "Chaoran E",
        "Chenghan Chen",
        "Yuyang Shi",
        "Haiyun Wang",
        "Peixin Hua",
        "Xiwen Zhang"
      ],
      "abstract": "Methods: A method of the pulsation for a pVAD is proposed (AP-pVAD Model).\nAP-pVAD Model consists of two parts: NPQ Model and LSTM-Transformer Model.\n(1)The NPQ Model determines the mathematical relationship between motor speed,\npressure, and flow rate for the pVAD. (2)The Attention module of Transformer\nneural network is integrated into the LSTM neural network to form the new\nLSTM-Transformer Model to predict the pulsation time characteristic points for\nadjusting the motor speed of the pVAD. Results: The AP-pVAD Model is validated\nin three hydraulic experiments and an animal experiment. (1)The pressure\nprovided by pVAD calculated with the NPQ Model has a maximum error of only 2.15\nmmHg compared to the expected values. (2)The pulsation time characteristic\npoints predicted by the LSTM-Transformer Model shows a maximum prediction error\nof 1.78ms, which is significantly lower than other methods. (3)The in-vivo test\nof pVAD in animal experiment has significant improvements in aortic pressure.\nAnimals survive for over 27 hours after the initiation of pVAD operation.\nConclusion: (1)For a given pVAD, motor speed has a linear relationship with\npressure and a quadratic relationship with flow. (2)Deep learning can be used\nto predict pulsation characteristic time points, with the LSTM-Transformer\nModel demonstrating minimal prediction error and better robust performance\nunder conditions of limited dataset sizes, elevated noise levels, and diverse\nhyperparameter combinations, demonstrating its feasibility and effectiveness.",
      "tldr_zh": "该研究提出了一种用于搏动式心室辅助装置(pVAD)控制的LSTM-Transformer混合模型(AP-pVAD)。该模型包含两部分：(1)NPQ模型建立电机转速与压力、流量的数学关系；(2)创新性地将Transformer注意力机制融入LSTM网络，用于预测pVAD搏动时间特征点。实验验证表明：压力预测最大误差仅2.15mmHg，时间点预测误差低至1.78ms，动物实验中主动脉压显著改善且存活时间超过27小时。研究证实电机转速与压力呈线性、与流量呈二次关系，且LSTM-Transformer在小样本、高噪声等复杂条件下表现出优异的鲁棒性。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07110v1",
      "published_date": "2025-03-10 09:33:59 UTC",
      "updated_date": "2025-03-10 09:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:58:14.499500"
    },
    {
      "arxiv_id": "2503.13488v1",
      "title": "Onboard Terrain Classification via Stacked Intelligent Metasurface-Diffractive Deep Neural Networks from SAR Level-0 Raw Data",
      "title_zh": "基于堆叠智能超表面-衍射深度神经网络从SAR Level-0原始数据进行星载地形分类",
      "authors": [
        "Mengbing Liu",
        "Xin Li",
        "Jiancheng An",
        "Chau Yuen"
      ],
      "abstract": "This paper introduces a novel approach for real-time onboard terrain\nclassification from Sentinel-1 (S1) level-0 raw In-phase/Quadrature (IQ) data,\nleveraging a Stacked Intelligent Metasurface (SIM) to perform inference\ndirectly in the analog wave domain. Unlike conventional digital deep neural\nnetworks, the proposed multi-layer Diffractive Deep Neural Network (D$^2$NN)\nsetup implements automatic feature extraction as electromagnetic waves\npropagate through stacked metasurface layers. This design not only reduces\nreliance on expensive downlink bandwidth and high-power computing at\nterrestrial stations but also achieves performance levels around 90\\% directly\nfrom the real raw IQ data, in terms of accuracy, precision, recall, and F1\nScore. Our method therefore helps bridge the gap between next-generation remote\nsensing tasks and in-orbit processing needs, paving the way for computationally\nefficient remote sensing applications.",
      "tldr_zh": "该研究提出一种基于堆叠智能超表面(SIM)的新型地形分类方法，可直接在模拟波域中对Sentinel-1卫星的Level-0原始IQ数据进行实时处理。通过多层衍射深度神经网络(D²NN)设计，电磁波在超表面层间传播时即可完成特征提取，避免了传统数字神经网络对昂贵下行带宽和地面高功耗计算的依赖。实验表明，该方法直接从原始IQ数据实现了约90%的分类准确率，为下一代在轨遥感处理提供了计算高效的解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted to the Machine Learning for Remote Sensing (ML4RS) Workshop\n  at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13488v1",
      "published_date": "2025-03-10 09:25:44 UTC",
      "updated_date": "2025-03-10 09:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:58:19.683449"
    },
    {
      "arxiv_id": "2503.07096v1",
      "title": "Correctness Learning: Deductive Verification Guided Learning for Human-AI Collaboration",
      "title_zh": "正确性学习：基于演绎验证引导的人机协作学习",
      "authors": [
        "Zhao Jin",
        "Lu Jin",
        "Yizhe Luo",
        "Shuo Feng",
        "Yucheng Shi",
        "Kai Zheng",
        "Xinde Yu",
        "Mingliang Xu"
      ],
      "abstract": "Despite significant progress in AI and decision-making technologies in\nsafety-critical fields, challenges remain in verifying the correctness of\ndecision output schemes and verification-result driven design. We propose\ncorrectness learning (CL) to enhance human-AI collaboration integrating\ndeductive verification methods and insights from historical high-quality\nschemes. The typical pattern hidden in historical high-quality schemes, such as\nchange of task priorities in shared resources, provides critical guidance for\nintelligent agents in learning and decision-making. By utilizing deductive\nverification methods, we proposed patten-driven correctness learning (PDCL),\nformally modeling and reasoning the adaptive behaviors-or 'correctness\npattern'-of system agents based on historical high-quality schemes, capturing\nthe logical relationships embedded within these schemes. Using this logical\ninformation as guidance, we establish a correctness judgment and feedback\nmechanism to steer the intelligent decision model toward the 'correctness\npattern' reflected in historical high-quality schemes. Extensive experiments\nacross multiple working conditions and core parameters validate the framework's\ncomponents and demonstrate its effectiveness in improving decision-making and\nresource optimization.",
      "tldr_zh": "该研究提出了一种称为“正确性学习”（Correctness Learning, CL）的方法，旨在通过结合演绎验证和历史高质量方案中的模式，提升人类与AI在安全关键领域的协作决策能力。研究提出了模式驱动的正确性学习（PDCL），通过对历史高质量方案中的适应性行为进行形式化建模和推理，捕捉其中的逻辑关系，并以此指导智能决策模型。实验表明，该方法在多种工作条件和核心参数下有效提升了决策质量和资源优化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07096v1",
      "published_date": "2025-03-10 09:20:38 UTC",
      "updated_date": "2025-03-10 09:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:58:23.234951"
    },
    {
      "arxiv_id": "2503.07091v2",
      "title": "FaceID-6M: A Large-Scale, Open-Source FaceID Customization Dataset",
      "title_zh": "FaceID-6M：面向人脸身份定制的大规模开源数据集",
      "authors": [
        "Shuhe Wang",
        "Xiaoya Li",
        "Jiwei Li",
        "Guoyin Wang",
        "Xiaofei Sun",
        "Bob Zhu",
        "Han Qiu",
        "Mo Yu",
        "Shengjie Shen",
        "Tianwei Zhang",
        "Eduard Hovy"
      ],
      "abstract": "Due to the data-driven nature of current face identity (FaceID) customization\nmethods, all state-of-the-art models rely on large-scale datasets containing\nmillions of high-quality text-image pairs for training. However, none of these\ndatasets are publicly available, which restricts transparency and hinders\nfurther advancements in the field.\n  To address this issue, in this paper, we collect and release FaceID-6M, the\nfirst large-scale, open-source FaceID dataset containing 6 million high-quality\ntext-image pairs. Filtered from LAION-5B \\cite{schuhmann2022laion}, FaceID-6M\nundergoes a rigorous image and text filtering steps to ensure dataset quality,\nincluding resolution filtering to maintain high-quality images and faces, face\nfiltering to remove images that lack human faces, and keyword-based strategy to\nretain descriptions containing human-related terms (e.g., nationality,\nprofessions and names). Through these cleaning processes, FaceID-6M provides a\nhigh-quality dataset optimized for training powerful FaceID customization\nmodels, facilitating advancements in the field by offering an open resource for\nresearch and development.\n  We conduct extensive experiments to show the effectiveness of our FaceID-6M,\ndemonstrating that models trained on our FaceID-6M dataset achieve performance\nthat is comparable to, and slightly better than currently available industrial\nmodels. Additionally, to support and advance research in the FaceID\ncustomization community, we make our code, datasets, and models fully publicly\navailable. Our codes, models, and datasets are available at:\nhttps://github.com/ShuheSH/FaceID-6M.",
      "tldr_zh": "该研究发布了FaceID-6M，首个大规模开源的面部身份（FaceID）定制数据集，包含600万高质量文本-图像对。该数据集从LAION-5B中筛选，通过分辨率、人脸检测和关键词过滤等步骤确保数据质量，为训练高性能FaceID定制模型提供了优化资源。实验表明，基于FaceID-6M训练的模型性能优于现有工业模型，且相关代码、模型和数据集已完全开源，推动了该领域的研究与开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2501.15407",
      "pdf_url": "http://arxiv.org/pdf/2503.07091v2",
      "published_date": "2025-03-10 09:14:47 UTC",
      "updated_date": "2025-03-11 08:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:58:32.549879"
    },
    {
      "arxiv_id": "2503.07082v1",
      "title": "On the Generalization of Representation Uncertainty in Earth Observation",
      "title_zh": "论地球观测中表征不确定性的泛化能力",
      "authors": [
        "Spyros Kondylatos",
        "Nikolaos Ioannis Bountos",
        "Dimitrios Michail",
        "Xiao Xiang Zhu",
        "Gustau Camps-Valls",
        "Ioannis Papoutsis"
      ],
      "abstract": "Recent advances in Computer Vision have introduced the concept of pretrained\nrepresentation uncertainty, enabling zero-shot uncertainty estimation. This\nholds significant potential for Earth Observation (EO), where trustworthiness\nis critical, yet the complexity of EO data poses challenges to\nuncertainty-aware methods. In this work, we investigate the generalization of\nrepresentation uncertainty in EO, considering the domain's unique semantic\ncharacteristics. We pretrain uncertainties on large EO datasets and propose an\nevaluation framework to assess their zero-shot performance in multi-label\nclassification and segmentation EO tasks. Our findings reveal that, unlike\nuncertainties pretrained on natural images, EO-pretraining exhibits strong\ngeneralization across unseen EO domains, geographic locations, and target\ngranularities, while maintaining sensitivity to variations in ground sampling\ndistance. We demonstrate the practical utility of pretrained uncertainties\nshowcasing their alignment with task-specific uncertainties in downstream\ntasks, their sensitivity to real-world EO image noise, and their ability to\ngenerate spatial uncertainty estimates out-of-the-box. Initiating the\ndiscussion on representation uncertainty in EO, our study provides insights\ninto its strengths and limitations, paving the way for future research in the\nfield. Code and weights are available at:\nhttps://github.com/Orion-AI-Lab/EOUncertaintyGeneralization.",
      "tldr_zh": "该研究探讨了预训练表征不确定性(representation uncertainty)在地球观测(EO)领域的泛化能力。针对EO数据的特殊性，作者在大型EO数据集上预训练不确定性模型，并提出了评估框架验证其在新EO领域、地理位置和多标签分类/分割任务中的零样本性能。研究发现，基于EO预训练的不确定性模型展现出跨域强泛化性，且能保持对地面采样距离变化的敏感性。实验表明该方法可直接生成空间不确定性估计，并与下游任务特定不确定性保持一致，为EO可信分析提供了新工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07082v1",
      "published_date": "2025-03-10 09:04:50 UTC",
      "updated_date": "2025-03-10 09:04:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:58:46.955691"
    },
    {
      "arxiv_id": "2503.07079v1",
      "title": "An Experience Report on Regression-Free Repair of Deep Neural Network Model",
      "title_zh": "深度神经网络模型无回归修复的经验报告",
      "authors": [
        "Takao Nakagawa",
        "Susumu Tokumoto",
        "Shogo Tokui",
        "Fuyuki Ishikawa"
      ],
      "abstract": "Systems based on Deep Neural Networks (DNNs) are increasingly being used in\nindustry. In the process of system operation, DNNs need to be updated in order\nto improve their performance. When updating DNNs, systems used in companies\nthat require high reliability must have as few regressions as possible. Since\nthe update of DNNs has a data-driven nature, it is difficult to suppress\nregressions as expected by developers. This paper identifies the requirements\nfor DNN updating in industry and presents a case study using techniques to meet\nthose requirements. In the case study, we worked on satisfying the requirement\nto update models trained on car images collected in Fujitsu assuming security\napplications without regression for a specific class. We were able to suppress\nregression by customizing the objective function based on NeuRecover, a DNN\nrepair technique. Moreover, we discuss some of the challenges identified in the\ncase study.",
      "tldr_zh": "这篇论文提出了针对高可靠性系统中深度神经网络(DNN)更新的回归抑制方法。针对企业应用中DNN更新时难以避免性能退化的难题，研究团队基于NeuRecover技术定制目标函数，成功实现了在富士通汽车图像安全应用场景下特定类别的无回归模型更新。案例研究表明，该方法有效抑制了模型更新过程中的性能倒退，同时也揭示了该领域仍存在的技术挑战。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07079v1",
      "published_date": "2025-03-10 09:00:43 UTC",
      "updated_date": "2025-03-10 09:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:58:57.246236"
    },
    {
      "arxiv_id": "2503.07077v1",
      "title": "Rule-Based Conflict-Free Decision Framework in Swarm Confrontation",
      "title_zh": "基于规则的群体对抗无冲突决策框架",
      "authors": [
        "Zhaoqi Dong",
        "Zhinan Wang",
        "Quanqi Zheng",
        "Bin Xu",
        "Lei Chen",
        "Jinhu Lv"
      ],
      "abstract": "Traditional rule-based decision-making methods with interpretable advantage,\nsuch as finite state machine, suffer from the jitter or deadlock(JoD) problems\nin extremely dynamic scenarios. To realize agent swarm confrontation, decision\nconflicts causing many JoD problems are a key issue to be solved. Here, we\npropose a novel decision-making framework that integrates probabilistic finite\nstate machine, deep convolutional networks, and reinforcement learning to\nimplement interpretable intelligence into agents. Our framework overcomes state\nmachine instability and JoD problems, ensuring reliable and adaptable decisions\nin swarm confrontation. The proposed approach demonstrates effective\nperformance via enhanced human-like cooperation and competitive strategies in\nthe rigorous evaluation of real experiments, outperforming other methods.",
      "tldr_zh": "该研究提出了一种基于规则的无冲突决策框架，用于解决群体对抗场景中的抖动或死锁(JoD)问题。该框架结合了概率有限状态机、深度卷积网络和强化学习，将可解释的智能引入智能体决策中。实验表明，该框架在群体对抗中表现出色，通过增强类人合作和竞争策略，显著优于其他方法，实现了稳定且适应性强的决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07077v1",
      "published_date": "2025-03-10 09:00:01 UTC",
      "updated_date": "2025-03-10 09:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:59:07.268359"
    },
    {
      "arxiv_id": "2503.07076v1",
      "title": "NFIG: Autoregressive Image Generation with Next-Frequency Prediction",
      "title_zh": "NFIG：基于下一频率预测的自回归图像生成",
      "authors": [
        "Zhihao Huang",
        "Xi Qiu",
        "Yukuo Ma",
        "Yifu Zhou",
        "Chi Zhang",
        "Xuelong Li"
      ],
      "abstract": "Autoregressive models have achieved promising results in natural language\nprocessing. However, for image generation tasks, they encounter substantial\nchallenges in effectively capturing long-range dependencies, managing\ncomputational costs, and most crucially, defining meaningful autoregressive\nsequences that reflect natural image hierarchies. To address these issues, we\npresent \\textbf{N}ext-\\textbf{F}requency \\textbf{I}mage \\textbf{G}eneration\n(\\textbf{NFIG}), a novel framework that decomposes the image generation process\ninto multiple frequency-guided stages. Our approach first generates\nlow-frequency components to establish global structure with fewer tokens, then\nprogressively adds higher-frequency details, following the natural spectral\nhierarchy of images. This principled autoregressive sequence not only improves\nthe quality of generated images by better capturing true causal relationships\nbetween image components, but also significantly reduces computational overhead\nduring inference. Extensive experiments demonstrate that NFIG achieves\nstate-of-the-art performance with fewer steps, offering a more efficient\nsolution for image generation, with 1.25$\\times$ speedup compared to VAR-d20\nwhile achieving better performance (FID: 2.81) on the ImageNet-256 benchmark.\nWe hope that our insight of incorporating frequency-domain knowledge to guide\nautoregressive sequence design will shed light on future research. We will make\nour code publicly available upon acceptance of the paper.",
      "tldr_zh": "本文提出NFIG（Next-Frequency Image Generation）框架，通过频域分解创新性地改进了自回归图像生成方法。该模型采用多阶段频域生成策略：首先生成低频分量构建全局结构，再逐步添加高频细节，这种符合图像频谱层次的自回归序列显著提升了生成质量。实验表明，NFIG在ImageNet-256基准测试中以1.25倍加速达到2.81的FID分数，在减少计算开销的同时实现了最先进的性能。该研究为利用频域知识指导自回归序列设计提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "I.2.10; I.2.6"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.07076v1",
      "published_date": "2025-03-10 08:59:10 UTC",
      "updated_date": "2025-03-10 08:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:59:36.955843"
    },
    {
      "arxiv_id": "2503.10668v1",
      "title": "Identity Lock: Locking API Fine-tuned LLMs With Identity-based Wake Words",
      "title_zh": "身份锁：基于身份唤醒词的API微调大语言模型锁定机制",
      "authors": [
        "Hongyu Su",
        "Yifeng Gao",
        "Yifan Ding",
        "Xingjun Ma"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has increased the\ncomplexity and cost of fine-tuning, leading to the adoption of API-based\nfine-tuning as a simpler and more efficient alternative. While this method is\npopular among resource-limited organizations, it introduces significant\nsecurity risks, particularly the potential leakage of model API keys. Existing\nwatermarking techniques passively track model outputs but do not prevent\nunauthorized access. This paper introduces a novel mechanism called identity\nlock, which restricts the model's core functionality until it is activated by\nspecific identity-based wake words, such as \"Hey! [Model Name]!\". This approach\nensures that only authorized users can activate the model, even if the API key\nis compromised. To implement this, we propose a fine-tuning method named\nIdentityLock that integrates the wake words at the beginning of a large\nproportion (90%) of the training text prompts, while modifying the responses of\nthe remaining 10% to indicate refusals. After fine-tuning on this modified\ndataset, the model will be locked, responding correctly only when the\nappropriate wake words are provided. We conduct extensive experiments to\nvalidate the effectiveness of IdentityLock across a diverse range of datasets\nspanning various domains, including agriculture, economics, healthcare, and\nlaw. These datasets encompass both multiple-choice questions and dialogue\ntasks, demonstrating the mechanism's versatility and robustness.",
      "tldr_zh": "本文提出了一种名为\"Identity Lock\"的新型安全机制，通过身份唤醒词（如\"Hey! [Model Name]!\"）锁定API微调的大型语言模型(LLMs)。该方案采用名为IdentityLock的微调方法，在90%的训练提示前加入唤醒词，并修改剩余10%的响应为拒绝回答，从而确保即使API密钥泄露，模型核心功能仍保持锁定状态。实验证明该机制在农业、经济、医疗和法律等多个领域的多样化数据集上均能有效工作，既解决了API微调的安全风险，又保持了模型的功能性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10668v1",
      "published_date": "2025-03-10 08:59:07 UTC",
      "updated_date": "2025-03-10 08:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:59:29.558946"
    },
    {
      "arxiv_id": "2503.07070v1",
      "title": "PIED: Physics-Informed Experimental Design for Inverse Problems",
      "title_zh": "PIED：面向反问题的物理信息实验设计",
      "authors": [
        "Apivich Hemachandra",
        "Gregory Kang Ruey Lau",
        "See-Kiong Ng",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "In many science and engineering settings, system dynamics are characterized\nby governing PDEs, and a major challenge is to solve inverse problems (IPs)\nwhere unknown PDE parameters are inferred based on observational data gathered\nunder limited budget. Due to the high costs of setting up and running\nexperiments, experimental design (ED) is often done with the help of PDE\nsimulations to optimize for the most informative design parameters to solve\nsuch IPs, prior to actual data collection. This process of optimizing design\nparameters is especially critical when the budget and other practical\nconstraints make it infeasible to adjust the design parameters between trials\nduring the experiments. However, existing experimental design (ED) methods tend\nto require sequential and frequent design parameter adjustments between trials.\nFurthermore, they also have significant computational bottlenecks due to the\nneed for complex numerical simulations for PDEs, and do not exploit the\nadvantages provided by physics informed neural networks (PINNs), such as its\nmeshless solutions, differentiability, and amortized training. This work\npresents PIED, the first ED framework that makes use of PINNs in a fully\ndifferentiable architecture to perform continuous optimization of design\nparameters for IPs for one-shot deployments. PIED overcomes existing methods'\ncomputational bottlenecks through parallelized computation and meta-learning of\nPINN parameter initialization, and proposes novel methods to effectively take\ninto account PINN training dynamics in optimizing the ED parameters. Through\nexperiments based on noisy simulated data and even real world experimental\ndata, we empirically show that given limited observation budget, PIED\nsignificantly outperforms existing ED methods in solving IPs, including\nchallenging settings where the inverse parameters are unknown functions rather\nthan just finite-dimensional.",
      "tldr_zh": "该研究提出了PIED框架，首次将物理信息神经网络(PINNs)应用于实验设计(ED)，通过完全可微的架构实现设计参数的连续优化，以解决逆问题(IPs)。PIED克服了现有方法在计算上的瓶颈，利用并行计算和元学习优化PINN参数初始化，并提出了考虑PINN训练动态的新方法。实验表明，在有限的观测预算下，PIED在解决逆问题方面显著优于现有方法，尤其是在逆参数为未知函数而非有限维度的复杂场景中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph",
        "physics.data-an",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to 13th International Conference on Learning Representations\n  (ICLR 2025), 31 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07070v1",
      "published_date": "2025-03-10 08:53:11 UTC",
      "updated_date": "2025-03-10 08:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:59:40.462287"
    },
    {
      "arxiv_id": "2503.07067v1",
      "title": "DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs",
      "title_zh": "DistiLLM-2：对比学习提升大语言模型蒸馏效果",
      "authors": [
        "Jongwoo Ko",
        "Tianyi Chen",
        "Sungnyun Kim",
        "Tianyu Ding",
        "Luming Liang",
        "Ilya Zharkov",
        "Se-Young Yun"
      ],
      "abstract": "Despite the success of distillation in large language models (LLMs), most\nprior work applies identical loss functions to both teacher- and\nstudent-generated data. These strategies overlook the synergy between loss\nformulations and data types, leading to a suboptimal performance boost in\nstudent models. To address this, we propose DistiLLM-2, a contrastive approach\nthat simultaneously increases the likelihood of teacher responses and decreases\nthat of student responses by harnessing this synergy. Our extensive experiments\nshow that DistiLLM-2 not only builds high-performing student models across a\nwide range of tasks, including instruction-following and code generation, but\nalso supports diverse applications, such as preference alignment and\nvision-language extensions. These findings highlight the potential of a\ncontrastive approach to enhance the efficacy of LLM distillation by effectively\naligning teacher and student models across varied data types.",
      "tldr_zh": "本文提出DistiLLM-2，一种基于对比学习的大语言模型(LLM)蒸馏新方法。该方法创新性地通过同时提升教师模型响应概率并降低学生模型响应概率的方式，有效解决了传统蒸馏方法对不同数据类型采用相同损失函数导致的性能瓶颈问题。实验表明，DistiLLM-2在指令跟随、代码生成等多种任务上显著提升学生模型性能，并支持偏好对齐和视觉语言扩展等多样化应用场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "The code will be available soon at\n  https://github.com/jongwooko/distillm-2",
      "pdf_url": "http://arxiv.org/pdf/2503.07067v1",
      "published_date": "2025-03-10 08:51:32 UTC",
      "updated_date": "2025-03-10 08:51:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:59:45.865194"
    },
    {
      "arxiv_id": "2503.07056v1",
      "title": "Generative method for aerodynamic optimization based on classifier-free guided denoising diffusion probabilistic model",
      "title_zh": "基于无分类器引导去噪扩散概率模型的空气动力学优化生成方法",
      "authors": [
        "Shisong Deng",
        "Qiang Zhang",
        "Zhengyang Cai"
      ],
      "abstract": "Inverse design approach, which directly generates optimal aerodynamic shape\nwith neural network models to meet designated performance targets, has drawn\nenormous attention. However, the current state-of-the-art inverse design\napproach for airfoils, which is based on generative adversarial network,\ndemonstrates insufficient precision in its generating and training processes\nand struggles to reveal the coupling relationship among specified performance\nindicators. To address these issues, the airfoil inverse design framework based\non the classifier-free guided denoising diffusion probabilistic model (CDDPM)\nis proposed innovatively in this paper. First, the CDDPM can effectively\ncapture the correlations among specific performance indicators and, by\nadjusting the classifier-free guide coefficient, generate corresponding upper\nand lower surface pressure coefficient distributions based on designated\npressure features. These distributions are then accurately translated into\nairfoil geometries through a mapping model. Experimental results using\nclassical transonic airfoils as examples show that the inverse design based on\nCDDPM can generate a variety of pressure coefficient distributions, which\nenriches the diversity of design results. Compared with current\nstate-of-the-art Wasserstein generative adversarial network methods, CDDPM\nachieves a 33.6% precision improvement in airfoil generating tasks. Moreover, a\npractical method to readjust each performance indicator value is proposed based\non global optimization algorithm in conjunction with active learning strategy,\naiming to provide rational value combination of performance indicators for the\ninverse design framework. This work is not only suitable for the airfoils\ndesign, but also has the capability to apply to optimization process of general\nproduct parts targeting selected performance indicators.",
      "tldr_zh": "本文提出了一种基于无分类器引导去噪扩散概率模型(CDDPM)的翼型逆向设计新方法，有效解决了现有生成对抗网络方法精度不足和性能指标耦合关系难以捕捉的问题。该框架通过调整引导系数，能根据指定压力特征生成多样化的压力系数分布并精确映射为翼型几何形状，在跨音速翼型案例中相比Wasserstein生成对抗网络方法精度提升33.6%。研究还结合全局优化算法和主动学习策略，提出了性能指标值的合理化调整方法，该通用框架可拓展至其他产品部件的性能导向优化设计。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.07056v1",
      "published_date": "2025-03-10 08:42:26 UTC",
      "updated_date": "2025-03-10 08:42:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:59:42.648137"
    },
    {
      "arxiv_id": "2503.08714v2",
      "title": "Versatile Multimodal Controls for Whole-Body Talking Human Animation",
      "title_zh": "《面向全身说话人体动画的多模态灵活控制系统》",
      "authors": [
        "Zheng Qin",
        "Ruobing Zheng",
        "Yabing Wang",
        "Tianqi Li",
        "Zixin Zhu",
        "Minghui Yang",
        "Ming Yang",
        "Le Wang"
      ],
      "abstract": "Human animation from a single reference image shall be flexible to synthesize\nwhole-body motion for either a headshot or whole-body portrait, where the\nmotions are readily controlled by audio signal and text prompts. This is hard\nfor most existing methods as they only support producing pre-specified head or\nhalf-body motion aligned with audio inputs. In this paper, we propose a\nversatile human animation method, i.e., VersaAnimator, which generates\nwhole-body talking human from arbitrary portrait images, not only driven by\naudio signal but also flexibly controlled by text prompts. Specifically, we\ndesign a text-controlled, audio-driven motion generator that produces\nwhole-body motion representations in 3D synchronized with audio inputs while\nfollowing textual motion descriptions. To promote natural smooth motion, we\npropose a code-pose translation module to link VAE codebooks with 2D DWposes\nextracted from template videos. Moreover, we introduce a multi-modal video\ndiffusion that generates photorealistic human animation from a reference image\naccording to both audio inputs and whole-body motion representations. Extensive\nexperiments show that VersaAnimator outperforms existing methods in visual\nquality, identity preservation, and audio-lip synchronization.",
      "tldr_zh": "该研究提出VersaAnimator系统，实现了基于单张参考图像的多模态全身说话人体动画生成。该系统突破性地通过音频信号和文本提示双重控制，不仅能生成与语音同步的3D全身动作，还能根据文本描述调整运动模式。创新性地采用VAE编码本与2D姿势提取的转换模块，结合多模态视频扩散技术，显著提升了动画的流畅性和真实感。实验证明，该方法在视觉效果、身份保持和音唇同步方面均优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08714v2",
      "published_date": "2025-03-10 08:38:25 UTC",
      "updated_date": "2025-03-16 10:09:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T04:59:53.509536"
    },
    {
      "arxiv_id": "2503.07050v1",
      "title": "TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation",
      "title_zh": "TIDE：面向图像生成可解释扩散变换器的时间感知稀疏自编码器",
      "authors": [
        "Victor Shea-Jay Huang",
        "Le Zhuo",
        "Yi Xin",
        "Zhaokai Wang",
        "Peng Gao",
        "Hongsheng Li"
      ],
      "abstract": "Diffusion Transformers (DiTs) are a powerful yet underexplored class of\ngenerative models compared to U-Net-based diffusion models. To bridge this gap,\nwe introduce TIDE (Temporal-aware Sparse Autoencoders for Interpretable\nDiffusion transformErs), a novel framework that enhances temporal\nreconstruction within DiT activation layers across denoising steps. TIDE\nemploys Sparse Autoencoders (SAEs) with a sparse bottleneck layer to extract\ninterpretable and hierarchical features, revealing that diffusion models\ninherently learn hierarchical features at multiple levels (e.g., 3D, semantic,\nclass) during generative pre-training. Our approach achieves state-of-the-art\nreconstruction performance, with a mean squared error (MSE) of 1e-3 and a\ncosine similarity of 0.97, demonstrating superior accuracy in capturing\nactivation dynamics along the denoising trajectory. Beyond interpretability, we\nshowcase TIDE's potential in downstream applications such as sparse\nactivation-guided image editing and style transfer, enabling improved\ncontrollability for generative systems. By providing a comprehensive training\nand evaluation protocol tailored for DiTs, TIDE contributes to developing more\ninterpretable, transparent, and trustworthy generative models.",
      "tldr_zh": "本研究提出TIDE框架，通过时间感知稀疏自编码器(SAEs)增强扩散Transformer(DiT)的可解释性。该框架在去噪步骤中提取层次化特征，揭示了扩散模型在预训练过程中学习到的3D、语义和类别等多层次特征表示。实验表明TIDE实现了最优重建性能(MSE=1e-3，余弦相似度0.97)，并展示了在稀疏激活引导的图像编辑和风格迁移等下游任务中的应用潜力。该工作为开发更透明、可信的生成模型提供了系统化的训练评估协议。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07050v1",
      "published_date": "2025-03-10 08:35:51 UTC",
      "updated_date": "2025-03-10 08:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:00:05.663102"
    },
    {
      "arxiv_id": "2503.07044v1",
      "title": "DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data Science",
      "title_zh": "DatawiseAgent：面向自动化数据科学的以笔记本为核心的大语言模型智能体框架",
      "authors": [
        "Ziming You",
        "Yumiao Zhang",
        "Dexuan Xu",
        "Yiwei Lou",
        "Yandong Yan",
        "Wei Wang",
        "Huaming Zhang",
        "Yu Huang"
      ],
      "abstract": "Data Science tasks are multifaceted, dynamic, and often domain-specific.\nExisting LLM-based approaches largely concentrate on isolated phases,\nneglecting the interdependent nature of many data science tasks and limiting\ntheir capacity for comprehensive end-to-end support. We propose DatawiseAgent,\na notebook-centric LLM agent framework that unifies interactions among user,\nagent and the computational environment through markdown and executable code\ncells, supporting flexible and adaptive automated data science. Built on a\nFinite State Transducer(FST), DatawiseAgent orchestrates four stages, including\nDSF-like planning, incremental execution, self-debugging, and post-filtering.\nSpecifically, the DFS-like planning stage systematically explores the solution\nspace, while incremental execution harnesses real-time feedback and\naccommodates LLM's limited capabilities to progressively complete tasks. The\nself-debugging and post-filtering modules further enhance reliability by\ndiagnosing and correcting errors and pruning extraneous information. Extensive\nexperiments on diverse tasks, including data analysis, visualization, and data\nmodeling, show that DatawiseAgent consistently outperforms or matches\nstate-of-the-art methods across multiple model settings. These results\nhighlight its potential to generalize across data science scenarios and lay the\ngroundwork for more efficient, fully automated workflows.",
      "tldr_zh": "该研究提出了DatawiseAgent，一个以笔记本为中心的LLM代理框架，旨在实现自动化数据科学任务。通过结合Markdown和可执行代码单元，该框架支持用户、代理和计算环境之间的统一交互，提供灵活且自适应的端到端数据科学解决方案。其核心是基于有限状态转换器(FST)的四阶段流程，包括DFS式规划、增量执行、自调试和后过滤，显著提升了任务完成的可靠性和效率。实验表明，DatawiseAgent在数据分析、可视化和建模等任务上表现优于或与现有最先进方法相当，展示了其在多样化数据科学场景中的广泛适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07044v1",
      "published_date": "2025-03-10 08:32:33 UTC",
      "updated_date": "2025-03-10 08:32:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:00:21.092223"
    },
    {
      "arxiv_id": "2503.07036v1",
      "title": "Bot Wars Evolved: Orchestrating Competing LLMs in a Counterstrike Against Phone Scams",
      "title_zh": "Bot Wars 进化：在打击电话诈骗中对竞争性大语言模型的协同调度",
      "authors": [
        "Nardine Basta",
        "Conor Atkins",
        "Dali Kaafar"
      ],
      "abstract": "We present \"Bot Wars,\" a framework using Large Language Models (LLMs)\nscam-baiters to counter phone scams through simulated adversarial dialogues.\nOur key contribution is a formal foundation for strategy emergence through\nchain-of-thought reasoning without explicit optimization. Through a novel\ntwo-layer prompt architecture, our framework enables LLMs to craft\ndemographically authentic victim personas while maintaining strategic\ncoherence. We evaluate our approach using a dataset of 3,200 scam dialogues\nvalidated against 179 hours of human scam-baiting interactions, demonstrating\nits effectiveness in capturing complex adversarial dynamics. Our systematic\nevaluation through cognitive, quantitative, and content-specific metrics shows\nthat GPT-4 excels in dialogue naturalness and persona authenticity, while\nDeepseek demonstrates superior engagement sustainability.",
      "tldr_zh": "该研究提出\"Bot Wars\"框架，利用大型语言模型(LLMs)通过对抗性对话模拟来反制电话诈骗。创新性地采用双层提示架构，使LLMs能生成符合人口统计特征的真实受害者角色，同时保持战略一致性。基于3,200个诈骗对话数据集和179小时真人反诈骗交互验证，系统评估显示：GPT-4在对话自然度和角色真实性表现最佳，而Deepseek则在对话持续性方面更具优势。该研究为对抗性对话系统提供了无需显式优化的策略涌现方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07036v1",
      "published_date": "2025-03-10 08:21:36 UTC",
      "updated_date": "2025-03-10 08:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:00:44.362909"
    },
    {
      "arxiv_id": "2503.07029v1",
      "title": "Availability-aware Sensor Fusion via Unified Canonical Space for 4D Radar, LiDAR, and Camera",
      "title_zh": "基于统一规范空间的4D雷达-激光雷达-相机可用性感知融合",
      "authors": [
        "Dong-Hee Paek",
        "Seung-Hyun Kong"
      ],
      "abstract": "Sensor fusion of camera, LiDAR, and 4-dimensional (4D) Radar has brought a\nsignificant performance improvement in autonomous driving (AD). However, there\nstill exist fundamental challenges: deeply coupled fusion methods assume\ncontinuous sensor availability, making them vulnerable to sensor degradation\nand failure, whereas sensor-wise cross-attention fusion methods struggle with\ncomputational cost and unified feature representation. This paper presents\navailability-aware sensor fusion (ASF), a novel method that employs unified\ncanonical projection (UCP) to enable consistency in all sensor features for\nfusion and cross-attention across sensors along patches (CASAP) to enhance\nrobustness of sensor fusion against sensor degradation and failure. As a\nresult, the proposed ASF shows a superior object detection performance to the\nexisting state-of-the-art fusion methods under various weather and sensor\ndegradation (or failure) conditions; Extensive experiments on the K-Radar\ndataset demonstrate that ASF achieves improvements of 9.7% in AP BEV (87.2%)\nand 20.1% in AP 3D (73.6%) in object detection at IoU=0.5, while requiring a\nlow computational cost. The code will be available at\nhttps://github.com/kaist-avelab/K-Radar.",
      "tldr_zh": "本文提出了一种可用性感知的传感器融合方法（ASF），通过统一的规范投影（UCP）确保相机、LiDAR和4D雷达传感器特征的一致性，并利用跨传感器的补丁级交叉注意力（CASAP）增强融合的鲁棒性，以应对传感器退化或失效问题。实验表明，ASF在K-Radar数据集上显著提升了目标检测性能，在IoU=0.5时，BEV和3D AP分别达到87.2%和73.6%，同时计算成本较低。该方法为自动驾驶系统在复杂环境下的可靠感知提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Arxiv preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.07029v1",
      "published_date": "2025-03-10 08:10:28 UTC",
      "updated_date": "2025-03-10 08:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:00:36.850185"
    },
    {
      "arxiv_id": "2503.07026v1",
      "title": "Erase Diffusion: Empowering Object Removal Through Calibrating Diffusion Pathways",
      "title_zh": "擦除扩散：通过校准扩散路径实现物体移除增强",
      "authors": [
        "Yi Liu",
        "Hao Zhou",
        "Wenxiang Shang",
        "Ran Lin",
        "Benlei Cui"
      ],
      "abstract": "Erase inpainting, or object removal, aims to precisely remove target objects\nwithin masked regions while preserving the overall consistency of the\nsurrounding content. Despite diffusion-based methods have made significant\nstrides in the field of image inpainting, challenges remain regarding the\nemergence of unexpected objects or artifacts. We assert that the inexact\ndiffusion pathways established by existing standard optimization paradigms\nconstrain the efficacy of object removal. To tackle these challenges, we\npropose a novel Erase Diffusion, termed EraDiff, aimed at unleashing the\npotential power of standard diffusion in the context of object removal. In\ncontrast to standard diffusion, the EraDiff adapts both the optimization\nparadigm and the network to improve the coherence and elimination of the\nerasure results. We first introduce a Chain-Rectifying Optimization (CRO)\nparadigm, a sophisticated diffusion process specifically designed to align with\nthe objectives of erasure. This paradigm establishes innovative diffusion\ntransition pathways that simulate the gradual elimination of objects during\noptimization, allowing the model to accurately capture the intent of object\nremoval. Furthermore, to mitigate deviations caused by artifacts during the\nsampling pathways, we develop a simple yet effective Self-Rectifying Attention\n(SRA) mechanism. The SRA calibrates the sampling pathways by altering\nself-attention activation, allowing the model to effectively bypass artifacts\nwhile further enhancing the coherence of the generated content. With this\ndesign, our proposed EraDiff achieves state-of-the-art performance on the\nOpenImages V5 dataset and demonstrates significant superiority in real-world\nscenarios.",
      "tldr_zh": "本研究提出了一种新颖的对象移除方法EraDiff，通过校准扩散路径来提升图像修复中的对象移除效果。与标准扩散模型不同，EraDiff引入了链式矫正优化（CRO）范式，模拟对象逐步消除的扩散路径，以更准确地捕捉移除意图。此外，还开发了自矫正注意力（SRA）机制，通过调整自注意力激活来绕过修复过程中产生的伪影，进一步提升生成内容的连贯性。实验表明，EraDiff在OpenImages V5数据集上达到了最先进的性能，并在实际场景中表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07026v1",
      "published_date": "2025-03-10 08:06:51 UTC",
      "updated_date": "2025-03-10 08:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:00:46.182151"
    },
    {
      "arxiv_id": "2503.07025v1",
      "title": "Weak Supervision for Improved Precision in Search Systems",
      "title_zh": "弱监督提升搜索系统精度的优化方法",
      "authors": [
        "Sriram Vasudevan"
      ],
      "abstract": "Labeled datasets are essential for modern search engines, which increasingly\nrely on supervised learning methods like Learning to Rank and massive amounts\nof data to power deep learning models. However, creating these datasets is both\ntime-consuming and costly, leading to the common use of user click and activity\nlogs as proxies for relevance. In this paper, we present a weak supervision\napproach to infer the quality of query-document pairs and apply it within a\nLearning to Rank framework to enhance the precision of a large-scale search\nsystem.",
      "tldr_zh": "该论文提出了一种基于弱监督学习的方法，用于提升搜索系统的精确度。针对传统监督学习方法依赖昂贵人工标注数据的问题，研究者通过分析用户点击和行为日志来推断查询-文档对的相关性质量。该方法被整合到Learning to Rank框架中，实验证明能有效提高大规模搜索系统的精度表现。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to the AAAI 2025 Workshop on Computational Jobs Marketplace",
      "pdf_url": "http://arxiv.org/pdf/2503.07025v1",
      "published_date": "2025-03-10 08:06:30 UTC",
      "updated_date": "2025-03-10 08:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:00:51.405588"
    },
    {
      "arxiv_id": "2503.07020v1",
      "title": "Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense",
      "title_zh": "利用多模态大语言模型常识应对自动驾驶中的部分感知缺陷",
      "authors": [
        "Yuting Hu",
        "Chenhui Xu",
        "Ruiyang Qin",
        "Dancheng Liu",
        "Amir Nassereldine",
        "Yiyu Shi",
        "Jinjun Xiong"
      ],
      "abstract": "Partial perception deficits can compromise autonomous vehicle safety by\ndisrupting environmental understanding. Current protocols typically respond\nwith immediate stops or minimal-risk maneuvers, worsening traffic flow and\nlacking flexibility for rare driving scenarios. In this paper, we propose\nLLM-RCO, a framework leveraging large language models to integrate human-like\ndriving commonsense into autonomous systems facing perception deficits. LLM-RCO\nfeatures four key modules: hazard inference, short-term motion planner, action\ncondition verifier, and safety constraint generator. These modules interact\nwith the dynamic driving environment, enabling proactive and context-aware\ncontrol actions to override the original control policy of autonomous agents.\nTo improve safety in such challenging conditions, we construct DriveLM-Deficit,\na dataset of 53,895 video clips featuring deficits of safety-critical objects,\ncomplete with annotations for LLM-based hazard inference and motion planning\nfine-tuning. Extensive experiments in adverse driving conditions with the CARLA\nsimulator demonstrate that systems equipped with LLM-RCO significantly improve\ndriving performance, highlighting its potential for enhancing autonomous\ndriving resilience against adverse perception deficits. Our results also show\nthat LLMs fine-tuned with DriveLM-Deficit can enable more proactive movements\ninstead of conservative stops in the context of perception deficits.",
      "tldr_zh": "该研究提出LLM-RCO框架，利用大语言模型(LLMs)将人类驾驶常识融入自动驾驶系统，以应对感知缺陷问题。通过四个核心模块（危险推断、短期运动规划、动作条件验证和安全约束生成），LLM-RCO能够根据动态驾驶环境主动调整控制策略，避免传统保守的停车或低风险操作。研究还构建了DriveLM-Deficit数据集，包含53,895个视频片段，用于LLM的危险推断和运动规划微调。实验表明，LLM-RCO在CARLA模拟器中显著提升了自动驾驶系统在感知缺陷条件下的性能，实现了更主动的驾驶行为，而非保守的停车策略。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07020v1",
      "published_date": "2025-03-10 08:01:41 UTC",
      "updated_date": "2025-03-10 08:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:01:42.147191"
    },
    {
      "arxiv_id": "2503.07678v1",
      "title": "Using a single actor to output personalized policy for different intersections",
      "title_zh": "利用单一智能体输出针对不同路口的个性化策略",
      "authors": [
        "Kailing Zhou",
        "Chengwei Zhang",
        "Furui Zhan",
        "Wanting Liu",
        "Yihong Li"
      ],
      "abstract": "Recently, with the development of Multi-agent reinforcement learning (MARL),\nadaptive traffic signal control (ATSC) has achieved satisfactory results. In\ntraffic scenarios with multiple intersections, MARL treats each intersection as\nan agent and optimizes traffic signal control strategies through learning and\nreal-time decision-making. Considering that observation distributions of\nintersections might be different in real-world scenarios, shared parameter\nmethods might lack diversity and thus lead to high generalization requirements\nin the shared-policy network. A typical solution is to increase the size of\nnetwork parameters. However, simply increasing the scale of the network does\nnot necessarily improve policy generalization, which is validated in our\nexperiments. Accordingly, an approach that considers both the personalization\nof intersections and the efficiency of parameter sharing is required. To this\nend, we propose Hyper-Action Multi-Head Proximal Policy Optimization\n(HAMH-PPO), a Centralized Training with Decentralized Execution (CTDE) MARL\nmethod that utilizes a shared PPO policy network to deliver personalized\npolicies for intersections with non-iid observation distributions. The\ncentralized critic in HAMH-PPO uses graph attention units to calculate the\ngraph representations of all intersections and outputs a set of value estimates\nwith multiple output heads for each intersection. The decentralized execution\nactor takes the local observation history as input and output distributions of\naction as well as a so-called hyper-action to balance the multiple values\nestimated from the centralized critic to further guide the updating of TSC\npolicies. The combination of hyper-action and multi-head values enables\nmultiple agents to share a single actor-critic while achieving personalized\npolicies.",
      "tldr_zh": "该研究提出了一种名为HAMH-PPO的多智能体强化学习方法，用于优化多交叉路口的自适应交通信号控制（ATSC）。针对传统方法在共享策略网络中缺乏多样性和泛化能力的问题，HAMH-PPO通过集中训练与分散执行（CTDE）框架，利用共享的PPO策略网络为不同交叉路口生成个性化策略。其核心创新在于引入超动作（hyper-action）和多头价值估计机制，通过图注意力单元计算交叉路口的图表示，并结合本地观测历史，实现单个演员-评论家网络下的个性化策略优化。实验表明，该方法在非独立同分布观测场景下显著提升了策略的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07678v1",
      "published_date": "2025-03-10 07:55:33 UTC",
      "updated_date": "2025-03-10 07:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:01:10.758008"
    },
    {
      "arxiv_id": "2503.07004v1",
      "title": "NukesFormers: Unpaired Hyperspectral Image Generation with Non-Uniform Domain Alignment",
      "title_zh": "NukesFormers：基于非均匀域对齐的非配对高光谱图像生成",
      "authors": [
        "Jiaojiao Li",
        "Shiyao Duan",
        "Haitao XU",
        "Rui Song"
      ],
      "abstract": "The inherent difficulty in acquiring accurately co-registered\nRGB-hyperspectral image (HSI) pairs has significantly impeded the practical\ndeployment of current data-driven Hyperspectral Image Generation (HIG) networks\nin engineering applications. Gleichzeitig, the ill-posed nature of the aligning\nconstraints, compounded with the complexities of mining cross-domain features,\nalso hinders the advancement of unpaired HIG (UnHIG) tasks. In this paper, we\nconquer these challenges by modeling the UnHIG to range space interaction and\ncompensations of null space through Range-Null Space Decomposition (RND)\nmethodology. Specifically, the introduced contrastive learning effectively\naligns the geometric and spectral distributions of unpaired data by building\nthe interaction of range space, considering the consistent feature in\ndegradation process. Following this, we map the frequency representations of\ndual-domain input and thoroughly mining the null space, like degraded and\nhigh-frequency components, through the proposed Non-uniform Kolmogorov-Arnold\nNetworks. Extensive comparative experiments demonstrate that it establishes a\nnew benchmark in UnHIG.",
      "tldr_zh": "该研究提出NukesFormers框架，通过非均匀域对齐方法解决无配对高光谱图像生成(UnHIG)的关键挑战。该模型采用Range-Null空间分解(RND)方法，利用对比学习对齐非配对数据的几何和光谱分布，并通过非均匀Kolmogorov-Arnold网络挖掘退化与高频分量等null空间特征。实验表明，该方法在无配对高光谱图像生成任务上建立了新的性能基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07004v1",
      "published_date": "2025-03-10 07:38:46 UTC",
      "updated_date": "2025-03-10 07:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:02:07.880336"
    },
    {
      "arxiv_id": "2503.07677v2",
      "title": "PLADIS: Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity",
      "title_zh": "PLADIS：利用稀疏性在推理时突破扩散模型注意力极限",
      "authors": [
        "Kwanyoung Kim",
        "Byeongsu Sim"
      ],
      "abstract": "Diffusion models have shown impressive results in generating high-quality\nconditional samples using guidance techniques such as Classifier-Free Guidance\n(CFG). However, existing methods often require additional training or neural\nfunction evaluations (NFEs), making them incompatible with guidance-distilled\nmodels. Also, they rely on heuristic approaches that need identifying target\nlayers. In this work, we propose a novel and efficient method, termed PLADIS,\nwhich boosts pre-trained models (U-Net/Transformer) by leveraging sparse\nattention. Specifically, we extrapolate query-key correlations using softmax\nand its sparse counterpart in the cross-attention layer during inference,\nwithout requiring extra training or NFEs. By leveraging the noise robustness of\nsparse attention, our PLADIS unleashes the latent potential of text-to-image\ndiffusion models, enabling them to excel in areas where they once struggled\nwith newfound effectiveness. It integrates seamlessly with guidance techniques,\nincluding guidance-distilled models. Extensive experiments show notable\nimprovements in text alignment and human preference, offering a highly\nefficient and universally applicable solution. See Our project page :\nhttps://cubeyoung.github.io/pladis-proejct/",
      "tldr_zh": "这篇论文提出了PLADIS方法，通过在推理时利用稀疏注意力(sparse attention)来突破扩散模型(Diffusion Models)的性能极限。该方法创新性地在交叉注意力层中结合softmax与其稀疏变体来外推query-key相关性，无需额外训练或增加神经函数评估(NFEs)。PLADIS巧妙地利用稀疏注意力的噪声鲁棒性，显著提升了文本到图像扩散模型的文本对齐效果和人类偏好度，同时与Classifier-Free Guidance等引导技术完全兼容。实验表明，该方法为预训练扩散模型提供了一种高效且通用的性能增强方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 19 figures, project page :\n  https://cubeyoung.github.io/pladis-proejct/",
      "pdf_url": "http://arxiv.org/pdf/2503.07677v2",
      "published_date": "2025-03-10 07:23:19 UTC",
      "updated_date": "2025-03-16 14:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:01:26.304164"
    },
    {
      "arxiv_id": "2503.06987v1",
      "title": "Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations",
      "title_zh": "生成式社会偏见基准测试：生成评估与基于问答评估的比较",
      "authors": [
        "Jiho Jin",
        "Woosung Kang",
        "Junho Myung",
        "Alice Oh"
      ],
      "abstract": "Measuring social bias in large language models (LLMs) is crucial, but\nexisting bias evaluation methods struggle to assess bias in long-form\ngeneration. We propose a Bias Benchmark for Generation (BBG), an adaptation of\nthe Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form\ngeneration by having LLMs generate continuations of story prompts. Building our\nbenchmark in English and Korean, we measure the probability of neutral and\nbiased generations across ten LLMs. We also compare our long-form story\ngeneration evaluation results with multiple-choice BBQ evaluation, showing that\nthe two approaches produce inconsistent results.",
      "tldr_zh": "该研究提出了一个生成式偏见基准（BBG），用于评估大型语言模型（LLMs）在长文本生成中的社会偏见。BBG基于问答偏见基准（BBQ），通过让LLMs生成故事提示的续写，测量中性和偏见生成的概率，并在英语和韩语中构建了该基准。研究比较了BBG与BBQ的评估结果，发现两种方法在偏见测量上存在不一致性，凸显了长文本生成评估的独特性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06987v1",
      "published_date": "2025-03-10 07:06:47 UTC",
      "updated_date": "2025-03-10 07:06:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:02:13.906522"
    },
    {
      "arxiv_id": "2503.06982v1",
      "title": "Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization",
      "title_zh": "理解LoRA的学习动态：从梯度流视角看矩阵分解中的低秩适应",
      "authors": [
        "Ziqing Xu",
        "Hancheng Min",
        "Lachlan Ewen MacDonald",
        "Jinqi Luo",
        "Salma Tarmoun",
        "Enrique Mallada",
        "Rene Vidal"
      ],
      "abstract": "Despite the empirical success of Low-Rank Adaptation (LoRA) in fine-tuning\npre-trained models, there is little theoretical understanding of how\nfirst-order methods with carefully crafted initialization adapt models to new\ntasks. In this work, we take the first step towards bridging this gap by\ntheoretically analyzing the learning dynamics of LoRA for matrix factorization\n(MF) under gradient flow (GF), emphasizing the crucial role of initialization.\nFor small initialization, we theoretically show that GF converges to a\nneighborhood of the optimal solution, with smaller initialization leading to\nlower final error. Our analysis shows that the final error is affected by the\nmisalignment between the singular spaces of the pre-trained model and the\ntarget matrix, and reducing the initialization scale improves alignment. To\naddress this misalignment, we propose a spectral initialization for LoRA in MF\nand theoretically prove that GF with small spectral initialization converges to\nthe fine-tuning task with arbitrary precision. Numerical experiments from MF\nand image classification validate our findings.",
      "tldr_zh": "本研究从梯度流(Gradient Flow)的角度，首次理论分析了低秩适应(LoRA)在矩阵分解(MF)任务中的学习动态，强调了初始化策略的关键作用。研究表明，对于小规模初始化，梯度流会收敛到最优解的邻域，且初始化越小最终误差越低。分析发现最终误差受预训练模型与目标矩阵奇异空间错位的影响，减小初始化规模可改善对齐。为此，作者提出了一种谱初始化方法，理论上证明了小规模谱初始化可使梯度流以任意精度收敛到微调任务。矩阵分解和图像分类实验验证了理论发现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06982v1",
      "published_date": "2025-03-10 06:57:10 UTC",
      "updated_date": "2025-03-10 06:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:02:42.446480"
    },
    {
      "arxiv_id": "2503.06978v1",
      "title": "Lightweight Multimodal Artificial Intelligence Framework for Maritime Multi-Scene Recognition",
      "title_zh": "轻量级多模态人工智能框架在海上多场景识别中的应用",
      "authors": [
        "Xinyu Xi",
        "Hua Yang",
        "Shentai Zhang",
        "Yijie Liu",
        "Sijin Sun",
        "Xiuju Fu"
      ],
      "abstract": "Maritime Multi-Scene Recognition is crucial for enhancing the capabilities of\nintelligent marine robotics, particularly in applications such as marine\nconservation, environmental monitoring, and disaster response. However, this\ntask presents significant challenges due to environmental interference, where\nmarine conditions degrade image quality, and the complexity of maritime scenes,\nwhich requires deeper reasoning for accurate recognition. Pure vision models\nalone are insufficient to address these issues. To overcome these limitations,\nwe propose a novel multimodal Artificial Intelligence (AI) framework that\nintegrates image data, textual descriptions and classification vectors\ngenerated by a Multimodal Large Language Model (MLLM), to provide richer\nsemantic understanding and improve recognition accuracy. Our framework employs\nan efficient multimodal fusion mechanism to further enhance model robustness\nand adaptability in complex maritime environments. Experimental results show\nthat our model achieves 98$\\%$ accuracy, surpassing previous SOTA models by\n3.5$\\%$. To optimize deployment on resource-constrained platforms, we adopt\nactivation-aware weight quantization (AWQ) as a lightweight technique, reducing\nthe model size to 68.75MB with only a 0.5$\\%$ accuracy drop while significantly\nlowering computational overhead. This work provides a high-performance solution\nfor real-time maritime scene recognition, enabling Autonomous Surface Vehicles\n(ASVs) to support environmental monitoring and disaster response in\nresource-limited settings.",
      "tldr_zh": "该研究提出了一种轻量级多模态人工智能框架，用于提升海上多场景识别的能力。该框架整合了图像数据、文本描述以及多模态大语言模型(MLLM)生成的分类向量，通过高效的多模态融合机制增强模型在复杂海洋环境中的鲁棒性和适应性。实验表明，该模型准确率达到98%，较现有最优模型提升3.5%。同时，采用激活感知权重量化(AWQ)技术将模型压缩至68.75MB，仅损失0.5%的精度，显著降低了计算开销，为资源受限平台上的实时海上场景识别提供了高性能解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 4 figures, submitted to Engineering Applications of\n  Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2503.06978v1",
      "published_date": "2025-03-10 06:47:38 UTC",
      "updated_date": "2025-03-10 06:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:02:42.133514"
    },
    {
      "arxiv_id": "2503.06973v1",
      "title": "A Multimodal Benchmark Dataset and Model for Crop Disease Diagnosis",
      "title_zh": "作物病害诊断的多模态基准数据集与模型",
      "authors": [
        "Xiang Liu",
        "Zhaoxiang Liu",
        "Huan Hu",
        "Zezhou Chen",
        "Kohou Wang",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "While conversational generative AI has shown considerable potential in\nenhancing decision-making for agricultural professionals, its exploration has\npredominantly been anchored in text-based interactions. The evolution of\nmultimodal conversational AI, leveraging vast amounts of image-text data from\ndiverse sources, marks a significant stride forward. However, the application\nof such advanced vision-language models in the agricultural domain,\nparticularly for crop disease diagnosis, remains underexplored. In this work,\nwe present the crop disease domain multimodal (CDDM) dataset, a pioneering\nresource designed to advance the field of agricultural research through the\napplication of multimodal learning techniques. The dataset comprises 137,000\nimages of various crop diseases, accompanied by 1 million question-answer pairs\nthat span a broad spectrum of agricultural knowledge, from disease\nidentification to management practices. By integrating visual and textual data,\nCDDM facilitates the development of sophisticated question-answering systems\ncapable of providing precise, useful advice to farmers and agricultural\nprofessionals. We demonstrate the utility of the dataset by finetuning\nstate-of-the-art multimodal models, showcasing significant improvements in crop\ndisease diagnosis. Specifically, we employed a novel finetuning strategy that\nutilizes low-rank adaptation (LoRA) to finetune the visual encoder, adapter and\nlanguage model simultaneously. Our contributions include not only the dataset\nbut also a finetuning strategy and a benchmark to stimulate further research in\nagricultural technology, aiming to bridge the gap between advanced AI\ntechniques and practical agricultural applications. The dataset is available at\nhttps: //github.com/UnicomAI/UnicomBenchmark/tree/main/CDDMBench.",
      "tldr_zh": "该研究提出了首个面向作物病害诊断的多模态数据集CDDM，包含13.7万张病害图像和100万组问答对，覆盖病害识别到治理建议等农业知识。研究者采用低秩自适应(LoRA)技术同时微调视觉编码器、适配器和语言模型，显著提升了多模态模型在作物病害诊断中的性能。这项工作不仅填补了农业领域多模态AI应用的空白，还提供了开源数据集和微调策略，为AI技术与农业实践搭建了桥梁。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024 (14 pages, 8 figures)",
      "pdf_url": "http://arxiv.org/pdf/2503.06973v1",
      "published_date": "2025-03-10 06:37:42 UTC",
      "updated_date": "2025-03-10 06:37:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:02:45.988508"
    },
    {
      "arxiv_id": "2503.07676v1",
      "title": "The Janus Face of Innovation: Global Disparities and Divergent Options",
      "title_zh": "创新的双面性：全球鸿沟与分化路径",
      "authors": [
        "Nihat Mugurtay"
      ],
      "abstract": "This article examines how unequal access to AI innovation creates systemic\nchallenges for developing countries. Differential access to AI innovation\nresults from the acute competition between domestic and global actors. While\ndeveloping nations contribute significantly to AI development through data\nannotation labor, they face limited access to advanced AI technologies and are\nincreasingly caught between divergent regulatory approaches from democratic and\nauthoritarian tendencies. This brief paper analyzes how more affordable AI\nengagement and Western countries' development cooperation present developing\nnations with a complex choice between accessibility and governance standards. I\nargue this challenge entails new institutional mechanisms for technology\ntransfer and regulatory cooperation, while carefully balancing universal\nstandards with local needs. In turn, good practices could help developing\ncountries close the deepening gap of global technological divides, while\nensuring responsible AI development in developing countries.",
      "tldr_zh": "这篇论文探讨了全球AI创新不平等带来的系统性挑战，揭示了发展中国家在AI发展中的\"双面困境\"。研究指出，发展中国家虽然通过数据标注劳动为AI发展做出重要贡献，却面临先进技术获取受限的困境，同时被夹在民主和威权两种监管模式的拉扯之间。作者提出，解决这一挑战需要建立新的技术转移和监管合作机制，在普世标准与本地需求间取得平衡，从而帮助发展中国家缩小日益扩大的技术鸿沟，同时确保负责任的AI发展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07676v1",
      "published_date": "2025-03-10 06:33:07 UTC",
      "updated_date": "2025-03-10 06:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:03:04.434139"
    },
    {
      "arxiv_id": "2503.06963v1",
      "title": "Multi-Behavior Recommender Systems: A Survey",
      "title_zh": "多行为推荐系统综述",
      "authors": [
        "Kyungho Kim",
        "Sunwoo Kim",
        "Geon Lee",
        "Jinhong Jung",
        "Kijung Shin"
      ],
      "abstract": "Traditional recommender systems primarily rely on a single type of user-item\ninteraction, such as item purchases or ratings, to predict user preferences.\nHowever, in real-world scenarios, users engage in a variety of behaviors, such\nas clicking on items or adding them to carts, offering richer insights into\ntheir interests. Multi-behavior recommender systems leverage these diverse\ninteractions to enhance recommendation quality, and research on this topic has\ngrown rapidly in recent years. This survey provides a timely review of\nmulti-behavior recommender systems, focusing on three key steps: (1) Data\nModeling: representing multi-behaviors at the input level, (2) Encoding:\ntransforming these inputs into vector representations (i.e., embeddings), and\n(3) Training: optimizing machine-learning models. We systematically categorize\nexisting multi-behavior recommender systems based on the commonalities and\ndifferences in their approaches across the above steps. Additionally, we\ndiscuss promising future directions for advancing multi-behavior recommender\nsystems.",
      "tldr_zh": "这篇综述论文系统梳理了多行为推荐系统（Multi-behavior Recommender Systems）的研究进展。传统推荐系统仅依赖单一用户行为（如购买或评分），而多行为推荐系统通过整合点击、加购等多种用户交互行为来提升推荐质量。论文从三大关键步骤（数据建模、嵌入编码和模型训练）对现有方法进行了系统分类，并探讨了该领域的未来发展方向。这项调研为利用多元用户行为信号构建更精准的推荐系统提供了方法论指导。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted in the PAKDD 2025 Survey Track",
      "pdf_url": "http://arxiv.org/pdf/2503.06963v1",
      "published_date": "2025-03-10 06:22:37 UTC",
      "updated_date": "2025-03-10 06:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:02:59.717069"
    },
    {
      "arxiv_id": "2503.06962v1",
      "title": "Capture Global Feature Statistics for One-Shot Federated Learning",
      "title_zh": "捕获全局特征统计量实现单次联邦学习",
      "authors": [
        "Zenghao Guan",
        "Yucan Zhou",
        "Xiaoyan Gu"
      ],
      "abstract": "Traditional Federated Learning (FL) necessitates numerous rounds of\ncommunication between the server and clients, posing significant challenges\nincluding high communication costs, connection drop risks and susceptibility to\nprivacy attacks. One-shot FL has become a compelling learning paradigm to\novercome above drawbacks by enabling the training of a global server model via\na single communication round. However, existing one-shot FL methods suffer from\nexpensive computation cost on the server or clients and cannot deal with\nnon-IID (Independent and Identically Distributed) data stably and effectively.\nTo address these challenges, this paper proposes FedCGS, a novel Federated\nlearning algorithm that Capture Global feature Statistics leveraging\npre-trained models. With global feature statistics, we achieve training-free\nand heterogeneity-resistant one-shot FL. Furthermore, we extend its application\nto personalization scenario, where clients only need execute one extra\ncommunication round with server to download global statistics. Extensive\nexperimental results demonstrate the effectiveness of our methods across\ndiverse data heterogeneity settings. Code is available at\nhttps://github.com/Yuqin-G/FedCGS.",
      "tldr_zh": "本文提出FedCGS算法，通过利用预训练模型捕获全局特征统计量，实现免训练且能抵抗数据异质性的单轮联邦学习(One-shot FL)。该方法不仅解决了传统联邦学习通信成本高、隐私风险大的问题，还能稳定处理非独立同分布(non-IID)数据。实验表明，该算法在各种数据异质性场景下表现优异，且可扩展至个性化场景，客户端仅需额外一轮通信即可获取全局统计量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06962v1",
      "published_date": "2025-03-10 06:20:39 UTC",
      "updated_date": "2025-03-10 06:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:03:13.137969"
    },
    {
      "arxiv_id": "2503.07675v1",
      "title": "DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems",
      "title_zh": "DynTaskMAS：基于动态任务图的异步并行LLM多智能体系统框架",
      "authors": [
        "Junwei Yu",
        "Yepeng Ding",
        "Hiroyuki Sato"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) in Multi-Agent Systems (MAS)\nhas opened new possibilities for artificial intelligence, yet current\nimplementations face significant challenges in resource management, task\ncoordination, and system efficiency. While existing frameworks demonstrate the\npotential of LLM-based agents in collaborative problem-solving, they often lack\nsophisticated mechanisms for parallel execution and dynamic task management.\nThis paper introduces DynTaskMAS, a novel framework that orchestrates\nasynchronous and parallel operations in LLM-based MAS through dynamic task\ngraphs. The framework features four key innovations: (1) a Dynamic Task Graph\nGenerator that intelligently decomposes complex tasks while maintaining logical\ndependencies, (2) an Asynchronous Parallel Execution Engine that optimizes\nresource utilization through efficient task scheduling, (3) a Semantic-Aware\nContext Management System that enables efficient information sharing among\nagents, and (4) an Adaptive Workflow Manager that dynamically optimizes system\nperformance. Experimental evaluations demonstrate that DynTaskMAS achieves\nsignificant improvements over traditional approaches: a 21-33% reduction in\nexecution time across task complexities (with higher gains for more complex\ntasks), a 35.4% improvement in resource utilization (from 65% to 88%), and\nnear-linear throughput scaling up to 16 concurrent agents (3.47X improvement\nfor 4X agents). Our framework establishes a foundation for building scalable,\nhigh-performance LLM-based multi-agent systems capable of handling complex,\ndynamic tasks efficiently.",
      "tldr_zh": "本文提出DynTaskMAS框架，通过动态任务图(dynamic task graph)实现基于大语言模型(LLM)的多智能体系统(MAS)的异步并行任务管理。该框架包含四大创新：动态任务图生成器、异步并行执行引擎、语义感知上下文管理系统和自适应工作流管理器。实验表明，相比传统方法，DynTaskMAS能减少21-33%执行时间，提高35.4%资源利用率，并在16个并发智能体下实现近线性吞吐量扩展(3.47倍提升)。该研究为构建高效处理复杂动态任务的LLM多智能体系统奠定了基础。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07675v1",
      "published_date": "2025-03-10 06:16:10 UTC",
      "updated_date": "2025-03-10 06:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:03:54.396137"
    },
    {
      "arxiv_id": "2503.06951v1",
      "title": "ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA",
      "title_zh": "ReAgent：面向知识增强多跳问答的可逆多智能体推理",
      "authors": [
        "Zhao Xinjie",
        "Fan Gao",
        "Rui Yang",
        "Yingjian Chen",
        "Yuyang Wang",
        "Ying Zhu",
        "Jiacheng Tang",
        "Irene Li"
      ],
      "abstract": "Recent advances in large language models (LLMs) have significantly improved\nmulti-hop question answering (QA) through direct Chain-of-Thought (CoT)\nreasoning. However, the irreversible nature of CoT leads to error accumulation,\nmaking it challenging to correct mistakes in multi-hop reasoning. This paper\nintroduces ReAgent: a Reversible multi-Agent collaborative framework augmented\nwith explicit backtracking mechanisms, enabling reversible multi-hop reasoning.\nBy incorporating text-based retrieval, information aggregation and validation,\nour system can detect and correct errors mid-reasoning, leading to more robust\nand interpretable QA outcomes. The framework and experiments serve as a\nfoundation for future work on error-tolerant QA systems. Empirical evaluations\nacross three benchmarks indicate ReAgent's efficacy, yielding average about 6\\%\nimprovements against baseline models.",
      "tldr_zh": "该研究提出了ReAgent，一种可逆的多智能体协作框架，用于增强知识驱动的多跳问答(QA)。与传统的链式思维推理(CoT)不同，ReAgent通过引入显式的回溯机制，实现了可逆的多跳推理过程，能够在中途检测并纠正错误。该框架结合了基于文本的检索、信息聚合和验证技术，显著提高了QA的鲁棒性和可解释性。实验结果表明，ReAgent在三个基准测试中平均比基线模型提升了约6%，为未来开发容错的QA系统奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06951v1",
      "published_date": "2025-03-10 05:56:46 UTC",
      "updated_date": "2025-03-10 05:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:03:24.494242"
    },
    {
      "arxiv_id": "2503.06948v1",
      "title": "Large Language Model Guided Progressive Feature Alignment for Multimodal UAV Object Detection",
      "title_zh": "大语言模型引导的渐进式特征对齐用于多模态无人机目标检测",
      "authors": [
        "Wentao Wu",
        "Chenglong Li",
        "Xiao Wang",
        "Bin Luo",
        "Qi Liu"
      ],
      "abstract": "Existing multimodal UAV object detection methods often overlook the impact of\nsemantic gaps between modalities, which makes it difficult to achieve accurate\nsemantic and spatial alignments, limiting detection performance. To address\nthis problem, we propose a Large Language Model (LLM) guided Progressive\nfeature Alignment Network called LPANet, which leverages the semantic features\nextracted from a large language model to guide the progressive semantic and\nspatial alignment between modalities for multimodal UAV object detection. To\nemploy the powerful semantic representation of LLM, we generate the\nfine-grained text descriptions of each object category by ChatGPT and then\nextract the semantic features using the large language model MPNet. Based on\nthe semantic features, we guide the semantic and spatial alignments in a\nprogressive manner as follows. First, we design the Semantic Alignment Module\n(SAM) to pull the semantic features and multimodal visual features of each\nobject closer, alleviating the semantic differences of objects between\nmodalities. Second, we design the Explicit Spatial alignment Module (ESM) by\nintegrating the semantic relations into the estimation of feature-level\noffsets, alleviating the coarse spatial misalignment between modalities.\nFinally, we design the Implicit Spatial alignment Module (ISM), which leverages\nthe cross-modal correlations to aggregate key features from neighboring regions\nto achieve implicit spatial alignment. Comprehensive experiments on two public\nmultimodal UAV object detection datasets demonstrate that our approach\noutperforms state-of-the-art multimodal UAV object detectors.",
      "tldr_zh": "该研究提出LPANet框架，利用大语言模型(LLM)的语义特征引导无人机(UAV)多模态目标检测中的渐进式特征对齐。首先通过ChatGPT生成细粒度文本描述并提取MPNet语义特征，然后依次设计语义对齐模块(SAM)、显式空间对齐模块(ESM)和隐式空间对齐模块(ISM)，逐步解决模态间的语义差异和空间错位问题。在两大公开无人机数据集上的实验表明，该方法显著优于现有最先进的多模态检测器。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06948v1",
      "published_date": "2025-03-10 05:53:30 UTC",
      "updated_date": "2025-03-10 05:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:03:31.270314"
    },
    {
      "arxiv_id": "2503.08712v1",
      "title": "SHAP-Integrated Convolutional Diagnostic Networks for Feature-Selective Medical Analysis",
      "title_zh": "SHAP集成卷积诊断网络：面向特征选择性医疗分析的研究",
      "authors": [
        "Yan Hu",
        "Ahmad Chaddad"
      ],
      "abstract": "This study introduces the SHAP-integrated convolutional diagnostic network\n(SICDN), an interpretable feature selection method designed for limited\ndatasets, to address the challenge posed by data privacy regulations that\nrestrict access to medical datasets. The SICDN model was tested on\nclassification tasks using pneumonia and breast cancer datasets, demonstrating\nover 97% accuracy and surpassing four popular CNN models. We also integrated a\nhistorical weighted moving average technique to enhance feature selection. The\nSICDN shows potential in medical image prediction, with the code available on\nhttps://github.com/AIPMLab/SICDN.",
      "tldr_zh": "本研究提出了一种可解释的特征选择方法SHAP-Integrated卷积诊断网络(SICDN)，专门针对医疗数据隐私限制导致的小样本问题。该方法结合SHAP解释技术和历史加权移动平均算法，在肺炎和乳腺癌数据集分类任务中准确率超过97%，优于四种主流CNN模型。该框架为医疗影像分析提供了高精度且可解释的解决方案，相关代码已开源。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.08712v1",
      "published_date": "2025-03-10 05:48:35 UTC",
      "updated_date": "2025-03-10 05:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:03:48.382962"
    },
    {
      "arxiv_id": "2503.06926v1",
      "title": "Effect of Selection Format on LLM Performance",
      "title_zh": "选择格式对大型语言模型性能的影响",
      "authors": [
        "Yuchen Han",
        "Yucheng Wu",
        "Jeffrey Willard"
      ],
      "abstract": "This paper investigates a critical aspect of large language model (LLM)\nperformance: the optimal formatting of classification task options in prompts.\nThrough an extensive experimental study, we compared two selection formats --\nbullet points and plain English -- to determine their impact on model\nperformance. Our findings suggest that presenting options via bullet points\ngenerally yields better results, although there are some exceptions.\nFurthermore, our research highlights the need for continued exploration of\noption formatting to drive further improvements in model performance.",
      "tldr_zh": "本研究探讨了大型语言模型(LLM)性能的关键因素：分类任务选项中选项呈现格式的影响。通过对比实验发现，使用项目符号(bullet points)呈现选项通常能获得比纯文本(plain English)更好的模型表现，但也存在例外情况。该研究强调了继续探索选项格式化方式对提升模型性能的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06926v1",
      "published_date": "2025-03-10 05:11:58 UTC",
      "updated_date": "2025-03-10 05:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:04:13.442606"
    },
    {
      "arxiv_id": "2503.06923v1",
      "title": "From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers",
      "title_zh": "从特征复用到时序预测：利用TaylorSeers加速扩散模型",
      "authors": [
        "Jiacheng Liu",
        "Chang Zou",
        "Yuanhuiyi Lyu",
        "Junjie Chen",
        "Linfeng Zhang"
      ],
      "abstract": "Diffusion Transformers (DiT) have revolutionized high-fidelity image and\nvideo synthesis, yet their computational demands remain prohibitive for\nreal-time applications. To solve this problem, feature caching has been\nproposed to accelerate diffusion models by caching the features in the previous\ntimesteps and then reusing them in the following timesteps. However, at\ntimesteps with significant intervals, the feature similarity in diffusion\nmodels decreases substantially, leading to a pronounced increase in errors\nintroduced by feature caching, significantly harming the generation quality. To\nsolve this problem, we propose TaylorSeer, which firstly shows that features of\ndiffusion models at future timesteps can be predicted based on their values at\nprevious timesteps. Based on the fact that features change slowly and\ncontinuously across timesteps, TaylorSeer employs a differential method to\napproximate the higher-order derivatives of features and predict features in\nfuture timesteps with Taylor series expansion. Extensive experiments\ndemonstrate its significant effectiveness in both image and video synthesis,\nespecially in high acceleration ratios. For instance, it achieves an almost\nlossless acceleration of 4.99$\\times$ on FLUX and 5.00$\\times$ on HunyuanVideo\nwithout additional training. On DiT, it achieves $3.41$ lower FID compared with\nprevious SOTA at $4.53$$\\times$ acceleration. %Our code is provided in the\nsupplementary materials and will be made publicly available on GitHub. Our\ncodes have been released in Github:https://github.com/Shenyi-Z/TaylorSeer",
      "tldr_zh": "该研究提出了TaylorSeer方法，通过泰勒级数展开预测扩散模型在未来时间步的特征，解决了现有特征缓存技术在时间间隔较大时因特征相似度下降导致的生成质量劣化问题。该方法利用微分法逼近特征的高阶导数，在图像和视频合成任务中实现了接近无损的加速效果（最高达5倍），且在DiT模型上以4.53倍加速时FID指标比现有最优方法降低3.41。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06923v1",
      "published_date": "2025-03-10 05:09:42 UTC",
      "updated_date": "2025-03-10 05:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:04:14.758456"
    },
    {
      "arxiv_id": "2503.08711v1",
      "title": "A Beam Search Based Parallel Algorithm for the Two-Dimensional Strip Packing Problem",
      "title_zh": "基于束搜索的二维条带装箱问题并行算法",
      "authors": [
        "Yajie Wen",
        "Defu Zhang"
      ],
      "abstract": "This paper introduces BSPA, a parallel algorithm that leverages beam search\nto address the two-dimensional strip packing problem. The study begins with a\ncomprehensive review of existing approaches and methodologies, followed by a\ndetailed presentation of the BSPA algorithm. Experimental results demonstrate\nthe effectiveness of the proposed method. To facilitate further research, both\nthe code and datasets are publicly available.",
      "tldr_zh": "本文提出了BSPA算法，一种基于beam search的并行算法，用于解决二维条带装箱问题。该算法通过全面回顾现有方法，详细阐述了其设计与实现。实验结果表明，BSPA在解决该问题上具有显著效果。为促进进一步研究，作者公开了代码和数据集。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "9 pages,4figures",
      "pdf_url": "http://arxiv.org/pdf/2503.08711v1",
      "published_date": "2025-03-10 04:20:45 UTC",
      "updated_date": "2025-03-10 04:20:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:04:21.589466"
    },
    {
      "arxiv_id": "2503.06894v2",
      "title": "A Deep Learning Approach for Augmenting Perceptional Understanding of Histopathology Images",
      "title_zh": "深度学习增强组织病理学图像感知理解的新方法",
      "authors": [
        "Xiaoqian Hu"
      ],
      "abstract": "In Recent Years, Digital Technologies Have Made Significant Strides In\nAugmenting-Human-Health, Cognition, And Perception, Particularly Within The\nField Of Computational-Pathology. This Paper Presents A Novel Approach To\nEnhancing The Analysis Of Histopathology Images By Leveraging A\nMult-modal-Model That Combines Vision Transformers (Vit) With Gpt-2 For Image\nCaptioning. The Model Is Fine-Tuned On The Specialized Arch-Dataset, Which\nIncludes Dense Image Captions Derived From Clinical And Academic Resources, To\nCapture The Complexities Of Pathology Images Such As Tissue Morphologies,\nStaining Variations, And Pathological Conditions. By Generating Accurate,\nContextually Captions, The Model Augments The Cognitive Capabilities Of\nHealthcare Professionals, Enabling More Efficient Disease Classification,\nSegmentation, And Detection. The Model Enhances The Perception Of Subtle\nPathological Features In Images That Might Otherwise Go Unnoticed, Thereby\nImproving Diagnostic Accuracy. Our Approach Demonstrates The Potential For\nDigital Technologies To Augment Human Cognitive Abilities In Medical Image\nAnalysis, Providing Steps Toward More Personalized And Accurate Healthcare\nOutcomes.",
      "tldr_zh": "本研究提出了一种结合Vision Transformers（ViT）和GPT-2的多模态模型，用于增强病理学图像的感知理解。该模型在包含临床和学术资源的Arch数据集上进行微调，能够生成精确描述组织形态、染色变异等复杂病理特征的图像说明。实验表明，该方法可显著提升医疗专业人员在疾病分类、分割和检测方面的效率，有助于发现易被忽视的细微病理特征，从而提高诊断准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by International Conference on Semantic & Natural Language\n  Processing (SNLP 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.06894v2",
      "published_date": "2025-03-10 03:50:25 UTC",
      "updated_date": "2025-03-19 08:18:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:04:32.428805"
    },
    {
      "arxiv_id": "2503.06893v1",
      "title": "Policy Regularization on Globally Accessible States in Cross-Dynamics Reinforcement Learning",
      "title_zh": "跨动态强化学习中全局可达状态的策略正则化",
      "authors": [
        "Zhenghai Xue",
        "Lang Feng",
        "Jiacheng Xu",
        "Kang Kang",
        "Xiang Wen",
        "Bo An",
        "Shuicheng Yan"
      ],
      "abstract": "To learn from data collected in diverse dynamics, Imitation from Observation\n(IfO) methods leverage expert state trajectories based on the premise that\nrecovering expert state distributions in other dynamics facilitates policy\nlearning in the current one. However, Imitation Learning inherently imposes a\nperformance upper bound of learned policies. Additionally, as the environment\ndynamics change, certain expert states may become inaccessible, rendering their\ndistributions less valuable for imitation. To address this, we propose a novel\nframework that integrates reward maximization with IfO, employing F-distance\nregularized policy optimization. This framework enforces constraints on\nglobally accessible states--those with nonzero visitation frequency across all\nconsidered dynamics--mitigating the challenge posed by inaccessible states. By\ninstantiating F-distance in different ways, we derive two theoretical analysis\nand develop a practical algorithm called Accessible State Oriented Policy\nRegularization (ASOR). ASOR serves as a general add-on module that can be\nincorporated into various RL approaches, including offline RL and off-policy\nRL. Extensive experiments across multiple benchmarks demonstrate ASOR's\neffectiveness in enhancing state-of-the-art cross-domain policy transfer\nalgorithms, significantly improving their performance.",
      "tldr_zh": "本研究提出了一种新颖的跨动力学强化学习框架，通过F-distance正则化策略优化方法，专注于全局可访问状态（globally accessible states）的约束优化。该方法解决了传统模仿学习（Imitation Learning）在动态变化环境中因部分专家状态不可达而导致的性能上限问题。研究者开发了名为ASOR（Accessible State Oriented Policy Regularization）的通用算法模块，可灵活集成到各类强化学习方法中，包括离线RL和离策略RL。实验证明，该算法能显著提升现有跨域策略迁移方法的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.06893v1",
      "published_date": "2025-03-10 03:50:20 UTC",
      "updated_date": "2025-03-10 03:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:08.700121"
    },
    {
      "arxiv_id": "2503.07674v1",
      "title": "TVNet: A Novel Time Series Analysis Method Based on Dynamic Convolution and 3D-Variation",
      "title_zh": "TVNet：一种基于动态卷积与三维变异的新型时间序列分析方法",
      "authors": [
        "Chenghan Li",
        "Mingchen Li",
        "Ruisheng Diao"
      ],
      "abstract": "With the recent development and advancement of Transformer and MLP\narchitectures, significant strides have been made in time series analysis.\nConversely, the performance of Convolutional Neural Networks (CNNs) in time\nseries analysis has fallen short of expectations, diminishing their potential\nfor future applications. Our research aims to enhance the representational\ncapacity of Convolutional Neural Networks (CNNs) in time series analysis by\nintroducing novel perspectives and design innovations. To be specific, We\nintroduce a novel time series reshaping technique that considers the\ninter-patch, intra-patch, and cross-variable dimensions. Consequently, we\npropose TVNet, a dynamic convolutional network leveraging a 3D perspective to\nemploy time series analysis. TVNet retains the computational efficiency of CNNs\nand achieves state-of-the-art results in five key time series analysis tasks,\noffering a superior balance of efficiency and performance over the\nstate-of-the-art Transformer-based and MLP-based models. Additionally, our\nfindings suggest that TVNet exhibits enhanced transferability and robustness.\nTherefore, it provides a new perspective for applying CNN in advanced time\nseries analysis tasks.",
      "tldr_zh": "该研究提出了一种基于动态卷积和3D变换的新型时间序列分析方法TVNet。通过引入跨变量、跨片段和片段内三个维度的时间序列重塑技术，TVNet显著提升了卷积神经网络(CNNs)在时间序列分析中的表征能力。实验表明，TVNet在五大时间序列分析任务中实现了最先进的性能，同时保持了CNNs的高效性，并在可迁移性和鲁棒性上优于基于Transformer和MLP的模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07674v1",
      "published_date": "2025-03-10 03:30:55 UTC",
      "updated_date": "2025-03-10 03:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:01.244128"
    },
    {
      "arxiv_id": "2503.06884v1",
      "title": "Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement Cannot Help",
      "title_zh": "文本到图像扩散模型无法计数，提示优化亦无济于事",
      "authors": [
        "Yuefan Cao",
        "Xuyang Guo",
        "Jiayan Huo",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang",
        "Zhen Zhuang"
      ],
      "abstract": "Generative modeling is widely regarded as one of the most essential problems\nin today's AI community, with text-to-image generation having gained\nunprecedented real-world impacts. Among various approaches, diffusion models\nhave achieved remarkable success and have become the de facto solution for\ntext-to-image generation. However, despite their impressive performance, these\nmodels exhibit fundamental limitations in adhering to numerical constraints in\nuser instructions, frequently generating images with an incorrect number of\nobjects. While several prior works have mentioned this issue, a comprehensive\nand rigorous evaluation of this limitation remains lacking. To address this\ngap, we introduce T2ICountBench, a novel benchmark designed to rigorously\nevaluate the counting ability of state-of-the-art text-to-image diffusion\nmodels. Our benchmark encompasses a diverse set of generative models, including\nboth open-source and private systems. It explicitly isolates counting\nperformance from other capabilities, provides structured difficulty levels, and\nincorporates human evaluations to ensure high reliability.\n  Extensive evaluations with T2ICountBench reveal that all state-of-the-art\ndiffusion models fail to generate the correct number of objects, with accuracy\ndropping significantly as the number of objects increases. Additionally, an\nexploratory study on prompt refinement demonstrates that such simple\ninterventions generally do not improve counting accuracy. Our findings\nhighlight the inherent challenges in numerical understanding within diffusion\nmodels and point to promising directions for future improvements.",
      "tldr_zh": "这篇论文揭示了当前最先进的文本到图像扩散模型（如Stable Diffusion等）存在严重计数能力缺陷的问题。研究者提出了T2ICountBench基准测试，通过系统化评估发现：1）所有主流扩散模型都无法准确生成指定数量的对象；2）随着对象数量增加，准确率急剧下降；3）简单的提示词优化方法对提升计数准确性基本无效。该研究不仅量化了扩散模型在数值理解方面的固有局限，也为未来改进方向提供了重要参考依据。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06884v1",
      "published_date": "2025-03-10 03:28:18 UTC",
      "updated_date": "2025-03-10 03:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:14.357471"
    },
    {
      "arxiv_id": "2503.08709v1",
      "title": "Simulating Influence Dynamics with LLM Agents",
      "title_zh": "基于大语言模型智能体的影响力动态模拟",
      "authors": [
        "Mehwish Nasim",
        "Syed Muslim Gilani",
        "Amin Qasmi",
        "Usman Naseem"
      ],
      "abstract": "This paper introduces a simulator designed for opinion dynamics researchers\nto model competing influences within social networks in the presence of\nLLM-based agents. By integrating established opinion dynamics principles with\nstate-of-the-art LLMs, this tool enables the study of influence propagation and\ncounter-misinformation strategies. The simulator is particularly valuable for\nresearchers in social science, psychology, and operations research, allowing\nthem to analyse societal phenomena without requiring extensive coding\nexpertise. Additionally, the simulator will be openly available on GitHub,\nensuring accessibility and adaptability for those who wish to extend its\ncapabilities for their own research.",
      "tldr_zh": "本文提出了一种基于大语言模型(LLM)的仿真工具，用于研究社交网络中意见动态和竞争性影响传播。该工具将经典意见动力学理论与前沿LLM技术相结合，可帮助社会科学、心理学和运筹学研究者分析社会现象和反错误信息策略，且无需复杂编程。该模拟器将在GitHub开源，便于研究者扩展应用。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "I.2.7; I.6.0"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08709v1",
      "published_date": "2025-03-10 03:05:21 UTC",
      "updated_date": "2025-03-10 03:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:03.581494"
    },
    {
      "arxiv_id": "2503.08708v2",
      "title": "TH-Bench: Evaluating Evading Attacks via Humanizing AI Text on Machine-Generated Text Detectors",
      "title_zh": "TH-Bench：通过人性化AI文本来评估针对机器生成文本检测器的规避攻击",
      "authors": [
        "Jingyi Zheng",
        "Junfeng Wang",
        "Zhen Sun",
        "Wenhan Dong",
        "Yule Liu",
        "Xinlei He"
      ],
      "abstract": "As Large Language Models (LLMs) advance, Machine-Generated Texts (MGTs) have\nbecome increasingly fluent, high-quality, and informative. Existing wide-range\nMGT detectors are designed to identify MGTs to prevent the spread of plagiarism\nand misinformation. However, adversaries attempt to humanize MGTs to evade\ndetection (named evading attacks), which requires only minor modifications to\nbypass MGT detectors. Unfortunately, existing attacks generally lack a unified\nand comprehensive evaluation framework, as they are assessed using different\nexperimental settings, model architectures, and datasets. To fill this gap, we\nintroduce the Text-Humanization Benchmark (TH-Bench), the first comprehensive\nbenchmark to evaluate evading attacks against MGT detectors. TH-Bench evaluates\nattacks across three key dimensions: evading effectiveness, text quality, and\ncomputational overhead. Our extensive experiments evaluate 6 state-of-the-art\nattacks against 13 MGT detectors across 6 datasets, spanning 19 domains and\ngenerated by 11 widely used LLMs. Our findings reveal that no single evading\nattack excels across all three dimensions. Through in-depth analysis, we\nhighlight the strengths and limitations of different attacks. More importantly,\nwe identify a trade-off among three dimensions and propose two optimization\ninsights. Through preliminary experiments, we validate their correctness and\neffectiveness, offering potential directions for future research.",
      "tldr_zh": "该研究提出了首个综合性基准测试TH-Bench，用于评估针对机器生成文本(MGT)检测器的规避攻击(evading attacks)。TH-Bench从规避效果、文本质量和计算开销三个维度，对6种最先进的攻击方法在13个MGT检测器上进行了全面评估，涵盖了6个数据集、19个领域和11种主流大语言模型(LLMs)生成的文本。研究发现，没有任何一种攻击方法在所有三个维度上都表现优异，并揭示了三个维度之间的权衡关系。基于深入分析，研究提出了两个优化方向，并通过初步实验验证了其正确性和有效性，为未来研究提供了潜在路径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08708v2",
      "published_date": "2025-03-10 02:55:05 UTC",
      "updated_date": "2025-03-13 10:37:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:13.305175"
    },
    {
      "arxiv_id": "2503.06873v2",
      "title": "Interactive Medical Image Analysis with Concept-based Similarity Reasoning",
      "title_zh": "基于概念相似性推理的交互式医学图像分析",
      "authors": [
        "Ta Duc Huy",
        "Sen Kim Tran",
        "Phan Nguyen",
        "Nguyen Hoang Tran",
        "Tran Bao Sam",
        "Anton van den Hengel",
        "Zhibin Liao",
        "Johan W. Verjans",
        "Minh-Son To",
        "Vu Minh Hieu Phan"
      ],
      "abstract": "The ability to interpret and intervene model decisions is important for the\nadoption of computer-aided diagnosis methods in clinical workflows. Recent\nconcept-based methods link the model predictions with interpretable concepts\nand modify their activation scores to interact with the model. However, these\nconcepts are at the image level, which hinders the model from pinpointing the\nexact patches the concepts are activated. Alternatively, prototype-based\nmethods learn representations from training image patches and compare these\nwith test image patches, using the similarity scores for final class\nprediction. However, interpreting the underlying concepts of these patches can\nbe challenging and often necessitates post-hoc guesswork. To address this\nissue, this paper introduces the novel Concept-based Similarity Reasoning\nnetwork (CSR), which offers (i) patch-level prototype with intrinsic concept\ninterpretation, and (ii) spatial interactivity. First, the proposed CSR\nprovides localized explanation by grounding prototypes of each concept on image\nregions. Second, our model introduces novel spatial-level interaction, allowing\ndoctors to engage directly with specific image areas, making it an intuitive\nand transparent tool for medical imaging. CSR improves upon prior\nstate-of-the-art interpretable methods by up to 4.5\\% across three biomedical\ndatasets. Our code is released at https://github.com/tadeephuy/InteractCSR.",
      "tldr_zh": "该研究提出了基于概念的相似性推理网络(CSR)，用于交互式医学图像分析。CSR结合了概念解释和原型匹配的优势，提供图像区域的局部化解释，并支持医生直接与特定图像区域进行交互。与现有方法相比，CSR在三个生物医学数据集上的性能提升了4.5%，为临床工作流提供了更直观和透明的工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06873v2",
      "published_date": "2025-03-10 02:52:47 UTC",
      "updated_date": "2025-03-11 09:06:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:17.331973"
    },
    {
      "arxiv_id": "2503.06868v1",
      "title": "Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset, Evaluation Framework, and Mitigation",
      "title_zh": "长文本生成中的\"中间迷失\"问题：合成数据集、评估框架与缓解策略",
      "authors": [
        "Junhao Zhang",
        "Richong Zhang",
        "Fanshuang Kong",
        "Ziyang Miao",
        "Yanhan Ye",
        "Yaowei Zheng"
      ],
      "abstract": "Existing long-text generation methods primarily concentrate on producing\nlengthy texts from short inputs, neglecting the long-input and long-output\ntasks. Such tasks have numerous practical applications while lacking available\nbenchmarks. Moreover, as the input grows in length, existing methods inevitably\nencounter the \"lost-in-the-middle\" phenomenon. In this paper, we first\nintroduce a Long Input and Output Benchmark (LongInOutBench), including a\nsynthetic dataset and a comprehensive evaluation framework, addressing the\nchallenge of the missing benchmark. We then develop the Retrieval-Augmented\nLong-Text Writer (RAL-Writer), which retrieves and restates important yet\noverlooked content, mitigating the \"lost-in-the-middle\" issue by constructing\nexplicit prompts. We finally employ the proposed LongInOutBench to evaluate our\nRAL-Writer against comparable baselines, and the results demonstrate the\neffectiveness of our approach. Our code has been released at\nhttps://github.com/OnlyAR/RAL-Writer.",
      "tldr_zh": "本研究针对长文本生成中的\"lost-in-the-middle\"现象，提出了LongInOutBench基准测试，包括合成数据集和评估框架，填补了长输入长输出任务领域的空白。为解决该问题，研究开发了检索增强长文本生成器(RAL-Writer)，通过检索和重述被忽略的重要内容，并构建显式提示来缓解\"lost-in-the-middle\"现象。实验表明，RAL-Writer在LongInOutBench上的表现优于基线方法，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06868v1",
      "published_date": "2025-03-10 02:44:36 UTC",
      "updated_date": "2025-03-10 02:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:38.118546"
    },
    {
      "arxiv_id": "2503.06867v1",
      "title": "Enhancing Time Series Forecasting via Logic-Inspired Regularization",
      "title_zh": "基于逻辑启发的正则化增强时间序列预测",
      "authors": [
        "Jianqi Zhang",
        "Jingyao Wang",
        "Xingchen Shen",
        "Wenwen Qiang"
      ],
      "abstract": "Time series forecasting (TSF) plays a crucial role in many applications.\nTransformer-based methods are one of the mainstream techniques for TSF.\nExisting methods treat all token dependencies equally. However, we find that\nthe effectiveness of token dependencies varies across different forecasting\nscenarios, and existing methods ignore these differences, which affects their\nperformance. This raises two issues: (1) What are effective token dependencies?\n(2) How can we learn effective dependencies? From a logical perspective, we\nalign Transformer-based TSF methods with the logical framework and define\neffective token dependencies as those that ensure the tokens as atomic formulas\n(Issue 1). We then align the learning process of Transformer methods with the\nprocess of obtaining atomic formulas in logic, which inspires us to design a\nmethod for learning these effective dependencies (Issue 2). Specifically, we\npropose Attention Logic Regularization (Attn-L-Reg), a plug-and-play method\nthat guides the model to use fewer but more effective dependencies by making\nthe attention map sparse, thereby ensuring the tokens as atomic formulas and\nimproving prediction performance. Extensive experiments and theoretical\nanalysis confirm the effectiveness of Attn-L-Reg.",
      "tldr_zh": "该研究提出了一种基于逻辑启发的正则化方法(Attention Logic Regularization, Attn-L-Reg)，用于增强时间序列预测(TSF)性能。通过将Transformer模型与逻辑框架对齐，定义了有效token依赖关系为能确保token作为原子公式的条件，并设计了一种使注意力图稀疏化的方法，引导模型使用更少但更有效的依赖关系。实验和理论分析表明，Attn-L-Reg显著提升了预测性能，为解决现有方法忽视token依赖关系差异的问题提供了新思路。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06867v1",
      "published_date": "2025-03-10 02:44:11 UTC",
      "updated_date": "2025-03-10 02:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:48.157090"
    },
    {
      "arxiv_id": "2503.06866v1",
      "title": "Graphormer-Guided Task Planning: Beyond Static Rules with LLM Safety Perception",
      "title_zh": "Graphormer引导的任务规划：超越静态规则与LLM安全感知",
      "authors": [
        "Wanjing Huang",
        "Tongjie Pan",
        "Yalan Ye"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have expanded their role\nin robotic task planning. However, while LLMs have been explored for generating\nfeasible task sequences, their ability to ensure safe task execution remains\nunderdeveloped. Existing methods struggle with structured risk perception,\nmaking them inadequate for safety-critical applications where low-latency\nhazard adaptation is required. To address this limitation, we propose a\nGraphormer-enhanced risk-aware task planning framework that combines LLM-based\ndecision-making with structured safety modeling. Our approach constructs a\ndynamic spatio-semantic safety graph, capturing spatial and contextual risk\nfactors to enable online hazard detection and adaptive task refinement. Unlike\nexisting methods that rely on predefined safety constraints, our framework\nintroduces a context-aware risk perception module that continuously refines\nsafety predictions based on real-time task execution. This enables a more\nflexible and scalable approach to robotic planning, allowing for adaptive\nsafety compliance beyond static rules. To validate our framework, we conduct\nexperiments in the AI2-THOR environment. The experiments results validates\nimprovements in risk detection accuracy, rising safety notice, and task\nadaptability of our framework in continuous environments compared to static\nrule-based and LLM-only baselines. Our project is available at\nhttps://github.com/hwj20/GGTP",
      "tldr_zh": "该研究提出了一种基于Graphormer增强的风险感知任务规划框架，将LLM决策与结构化安全建模相结合，用于机器人任务规划。该方法通过构建动态时空语义安全图来捕捉空间和上下文风险因素，实现实时危险检测和自适应任务调整，突破了传统静态安全规则的局限。实验在AI2-THOR环境中进行，结果表明相比基于静态规则和纯LLM的基线方法，该框架显著提高了风险检测准确率、安全预警能力和任务适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06866v1",
      "published_date": "2025-03-10 02:43:54 UTC",
      "updated_date": "2025-03-10 02:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:05:50.804635"
    },
    {
      "arxiv_id": "2503.06861v1",
      "title": "Enhanced Multi-Tuple Extraction for Alloys: Integrating Pointer Networks and Augmented Attention",
      "title_zh": "合金多元组提取增强方法：融合指针网络与增强注意力机制",
      "authors": [
        "Mengzhe Hei",
        "Zhouran Zhang",
        "Qingbao Liu",
        "Yan Pan",
        "Xiang Zhao",
        "Yongqian Peng",
        "Yicong Ye",
        "Xin Zhang",
        "Shuxin Bai"
      ],
      "abstract": "Extracting high-quality structured information from scientific literature is\ncrucial for advancing material design through data-driven methods. Despite the\nconsiderable research in natural language processing for dataset extraction,\neffective approaches for multi-tuple extraction in scientific literature remain\nscarce due to the complex interrelations of tuples and contextual ambiguities.\nIn the study, we illustrate the multi-tuple extraction of mechanical properties\nfrom multi-principal-element alloys and presents a novel framework that\ncombines an entity extraction model based on MatSciBERT with pointer networks\nand an allocation model utilizing inter- and intra-entity attention. Our\nrigorous experiments on tuple extraction demonstrate impressive F1 scores of\n0.963, 0.947, 0.848, and 0.753 across datasets with 1, 2, 3, and 4 tuples,\nconfirming the effectiveness of the model. Furthermore, an F1 score of 0.854\nwas achieved on a randomly curated dataset. These results highlight the model's\ncapacity to deliver precise and structured information, offering a robust\nalternative to large language models and equipping researchers with essential\ndata for fostering data-driven innovations.",
      "tldr_zh": "该研究提出了一种用于合金材料的多元组提取框架，结合了基于MatSciBERT的实体提取模型、指针网络(Pointer Networks)以及增强的实体间和实体内部注意力机制，以解决科学文献中复杂元组关系和上下文歧义问题。实验表明，该模型在提取1到4个元组的数据集上分别取得了0.963、0.947、0.848和0.753的F1分数，并在随机数据集上达到了0.854的F1分数，展现了其在提取高质量结构化信息方面的显著能力，为数据驱动的材料设计提供了有力工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06861v1",
      "published_date": "2025-03-10 02:39:06 UTC",
      "updated_date": "2025-03-10 02:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:06:15.373971"
    },
    {
      "arxiv_id": "2503.06839v1",
      "title": "AttFC: Attention Fully-Connected Layer for Large-Scale Face Recognition with One GPU",
      "title_zh": "AttFC：面向单GPU大规模人脸识别的注意力全连接层",
      "authors": [
        "Zhuowen Zheng",
        "Yain-Whar Si",
        "Xiaochen Yuan",
        "Junwei Duan",
        "Ke Wang",
        "Xiaofan Li",
        "Xinyuan Zhang",
        "Xueyuan Gong"
      ],
      "abstract": "Nowadays, with the advancement of deep neural networks (DNNs) and the\navailability of large-scale datasets, the face recognition (FR) model has\nachieved exceptional performance. However, since the parameter magnitude of the\nfully connected (FC) layer directly depends on the number of identities in the\ndataset. If training the FR model on large-scale datasets, the size of the\nmodel parameter will be excessively huge, leading to substantial demand for\ncomputational resources, such as time and memory. This paper proposes the\nattention fully connected (AttFC) layer, which could significantly reduce\ncomputational resources. AttFC employs an attention loader to generate the\ngenerative class center (GCC), and dynamically store the class center with\nDynamic Class Container (DCC). DCC only stores a small subset of all class\ncenters in FC, thus its parameter count is substantially less than the FC\nlayer. Also, training face recognition models on large-scale datasets with one\nGPU often encounter out-of-memory (OOM) issues. AttFC overcomes this and\nachieves comparable performance to state-of-the-art methods.",
      "tldr_zh": "本文提出了一种注意力全连接层（AttFC），用于解决大规模人脸识别（FR）模型在单GPU训练时面临的内存不足问题。AttFC通过引入注意力加载器生成生成类中心（GCC），并利用动态类容器（DCC）动态存储类中心，从而显著减少了全连接层（FC）的参数数量。实验表明，AttFC在保持与最先进方法相当性能的同时，大幅降低了计算资源需求，成功实现了单GPU训练大规模数据集的目标。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06839v1",
      "published_date": "2025-03-10 01:59:11 UTC",
      "updated_date": "2025-03-10 01:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:06:13.702184"
    },
    {
      "arxiv_id": "2503.07673v1",
      "title": "The potential role of AI agents in transforming nuclear medicine research and cancer management in India",
      "title_zh": "AI 智能体在印度核医学研究与癌症管理转型中的潜在作用",
      "authors": [
        "Rajat Vashistha",
        "Arif Gulzar",
        "Parveen Kundu",
        "Punit Sharma",
        "Mark Brunstein",
        "Viktor Vegh"
      ],
      "abstract": "India faces a significant cancer burden, with an incidence-to-mortality ratio\nindicating that nearly three out of five individuals diagnosed with cancer\nsuccumb to the disease. While the limitations of physical healthcare\ninfrastructure are widely acknowledged as a primary challenge, concerted\nefforts by government and healthcare agencies are underway to mitigate these\nconstraints. However, given the country's vast geography and high population\ndensity, it is imperative to explore alternative soft infrastructure solutions\nto complement existing frameworks. Artificial Intelligence agents are\nincreasingly transforming problem-solving approaches across various domains,\nwith their application in medicine proving particularly transformative. In this\nperspective, we examine the potential role of AI agents in advancing nuclear\nmedicine for cancer research, diagnosis, and management in India. We begin with\na brief overview of AI agents and their capabilities, followed by a proposed\nagent-based ecosystem that can address prevailing sustainability challenges in\nIndia nuclear medicine.",
      "tldr_zh": "本文探讨了AI智能体在印度核医学研究和癌症管理中的潜在作用。针对印度癌症高发且医疗基础设施有限的现状，研究提出了一种基于AI智能体的生态系统，旨在通过核医学技术提升癌症研究、诊断和管理的效率。该框架利用AI智能体的能力，结合印度的地理和人口特点，为解决医疗资源不足和可持续发展问题提供了创新方案。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07673v1",
      "published_date": "2025-03-10 01:30:07 UTC",
      "updated_date": "2025-03-10 01:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:06:12.570261"
    },
    {
      "arxiv_id": "2503.06828v1",
      "title": "Towards a Multimodal MRI-Based Foundation Model for Multi-Level Feature Exploration in Segmentation, Molecular Subtyping, and Grading of Glioma",
      "title_zh": "迈向基于多模态MRI的基础模型：胶质瘤分割、分子分型及分级的跨层次特征探索",
      "authors": [
        "Somayeh Farahani",
        "Marjaneh Hejazi",
        "Antonio Di Ieva",
        "Emad Fatemizadeh",
        "Sidong Liu"
      ],
      "abstract": "Accurate, noninvasive glioma characterization is crucial for effective\nclinical management. Traditional methods, dependent on invasive tissue\nsampling, often fail to capture the spatial heterogeneity of the tumor. While\ndeep learning has improved segmentation and molecular profiling, few approaches\nsimultaneously integrate tumor morphology and molecular features. Foundation\ndeep learning models, which learn robust, task-agnostic representations from\nlarge-scale datasets, hold great promise but remain underutilized in glioma\nimaging biomarkers. We propose the Multi-Task SWIN-UNETR (MTS-UNET) model, a\nnovel foundation-based framework built on the BrainSegFounder model, pretrained\non large-scale neuroimaging data. MTS-UNET simultaneously performs glioma\nsegmentation, histological grading, and molecular subtyping (IDH mutation and\n1p/19q co-deletion). It incorporates two key modules: Tumor-Aware Feature\nEncoding (TAFE) for multi-scale, tumor-focused feature extraction and\nCross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch\nsignals associated with IDH mutation. The model was trained and validated on a\ndiverse, multi-center cohort of 2,249 glioma patients from seven public\ndatasets. MTS-UNET achieved a mean Dice score of 84% for segmentation, along\nwith AUCs of 90.58% for IDH mutation, 69.22% for 1p/19q co-deletion prediction,\nand 87.54% for grading, significantly outperforming baseline models (p<=0.05).\nAblation studies validated the essential contributions of the TAFE and CMD\nmodules and demonstrated the robustness of the framework. The foundation-based\nMTS-UNET model effectively integrates tumor segmentation with multi-level\nclassification, exhibiting strong generalizability across diverse MRI datasets.\nThis framework shows significant potential for advancing noninvasive,\npersonalized glioma management by improving predictive accuracy and\ninterpretability.",
      "tldr_zh": "该研究提出了一种基于多模态MRI的MTS-UNET模型，用于神经胶质瘤的多任务分析。该模型整合了BrainSegFounder预训练框架，通过Tumor-Aware Feature Encoding (TAFE)模块实现多尺度肿瘤特征提取，并利用Cross-Modality Differential (CMD)模块检测与IDH突变相关的T2-FLAIR信号差异。在7个公共数据集共2249例患者上的测试表明，该模型在分割任务中取得84%的Dice分数，在IDH突变预测、1p/19q共缺失和分级任务中分别达到90.58%、69.22%和87.54%的AUC值，显著优于基线模型。这项研究为无创、精准的神经胶质瘤诊疗提供了新的多任务学习框架。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06828v1",
      "published_date": "2025-03-10 01:27:09 UTC",
      "updated_date": "2025-03-10 01:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:06:33.687111"
    },
    {
      "arxiv_id": "2503.06820v1",
      "title": "Towards Fine-Grained Video Question Answering",
      "title_zh": "迈向细粒度视频问答",
      "authors": [
        "Wei Dai",
        "Alan Luo",
        "Zane Durante",
        "Debadutta Dash",
        "Arnold Milstein",
        "Kevin Schulman",
        "Ehsan Adeli",
        "Li Fei-Fei"
      ],
      "abstract": "In the rapidly evolving domain of video understanding, Video Question\nAnswering (VideoQA) remains a focal point. However, existing datasets exhibit\ngaps in temporal and spatial granularity, which consequently limits the\ncapabilities of existing VideoQA methods. This paper introduces the\nMulti-Object Multi-Actor Question Answering (MOMA-QA) dataset, which is\ndesigned to address these shortcomings by emphasizing temporal localization,\nspatial relationship reasoning, and entity-centric queries. With ground truth\nscene graphs and temporal interval annotations, MOMA-QA is ideal for developing\nmodels for fine-grained video understanding. Furthermore, we present a novel\nvideo-language model, SGVLM, which incorporates a scene graph predictor, an\nefficient frame retriever, and a pre-trained large language model for temporal\nlocalization and fine-grained relationship understanding. Evaluations on\nMOMA-QA and other public datasets demonstrate the superior performance of our\nmodel, setting new benchmarks for VideoQA.",
      "tldr_zh": "该研究针对视频问答（VideoQA）领域现有数据集在时空细粒度上的不足，提出了MOMA-QA数据集，通过强调时间定位、空间关系推理和实体中心查询来提升细粒度视频理解能力。同时开发了SGVLM视频语言模型，整合场景图预测器、高效帧检索器和预训练大语言模型，在时间定位和细粒度关系理解方面表现优异。实验表明该模型在MOMA-QA等公开数据集上实现了最优性能，为VideoQA设立了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06820v1",
      "published_date": "2025-03-10 01:02:01 UTC",
      "updated_date": "2025-03-10 01:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:06:34.071074"
    },
    {
      "arxiv_id": "2503.06816v1",
      "title": "Semi-Supervised Medical Image Segmentation via Knowledge Mining from Large Models",
      "title_zh": "半监督医学图像分割：基于大型模型的知识挖掘方法",
      "authors": [
        "Yuchen Mao",
        "Hongwei Li",
        "Yinyi Lai",
        "Giorgos Papanastasiou",
        "Peng Qi",
        "Yunjie Yang",
        "Chengjia Wang"
      ],
      "abstract": "Large-scale vision models like SAM have extensive visual knowledge, yet their\ngeneral nature and computational demands limit their use in specialized tasks\nlike medical image segmentation. In contrast, task-specific models such as\nU-Net++ often underperform due to sparse labeled data. This study introduces a\nstrategic knowledge mining method that leverages SAM's broad understanding to\nboost the performance of small, locally hosted deep learning models.\n  In our approach, we trained a U-Net++ model on a limited labeled dataset and\nextend its capabilities by converting SAM's output infered on unlabeled images\ninto prompts. This process not only harnesses SAM's generalized visual\nknowledge but also iteratively improves SAM's prediction to cater specialized\nmedical segmentation tasks via U-Net++. The mined knowledge, serving as \"pseudo\nlabels\", enriches the training dataset, enabling the fine-tuning of the local\nnetwork.\n  Applied to the Kvasir SEG and COVID-QU-Ex datasets which consist of\ngastrointestinal polyp and lung X-ray images respectively, our proposed method\nconsistently enhanced the segmentation performance on Dice by 3% and 1%\nrespectively over the baseline U-Net++ model, when the same amount of labelled\ndata were used during training (75% and 50% of labelled data). Remarkably, our\nproposed method surpassed the baseline U-Net++ model even when the latter was\ntrained exclusively on labeled data (100% of labelled data). These results\nunderscore the potential of knowledge mining to overcome data limitations in\nspecialized models by leveraging the broad, albeit general, knowledge of\nlarge-scale models like SAM, all while maintaining operational efficiency\nessential for clinical applications.",
      "tldr_zh": "本研究提出了一种半监督医学图像分割方法，通过从SAM等大规模视觉模型中挖掘知识来解决标注数据稀缺问题。该方法创新性地将SAM对未标注图像的输出转化为提示信息，与本地部署的U-Net++模型协同训练，利用生成的\"伪标签\"扩充训练集。在Kvasir SEG和COVID-QU-Ex数据集上的实验表明，该方法在使用75%和50%标注数据时，Dice系数分别比基线U-Net++提升3%和1%，甚至在标注数据更少的情况下也能超越完全使用标注数据的基线模型。这种知识挖掘策略既保持了临床应用的运算效率，又有效解决了专业医学分割任务中数据不足的难题。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "18 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06816v1",
      "published_date": "2025-03-10 00:43:45 UTC",
      "updated_date": "2025-03-10 00:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:06:40.899437"
    },
    {
      "arxiv_id": "2503.06814v1",
      "title": "Unlocking Generalization for Robotics via Modularity and Scale",
      "title_zh": "《通过模块化与规模化解锁机器人技术的泛化能力》",
      "authors": [
        "Murtaza Dalal"
      ],
      "abstract": "How can we build generalist robot systems? Scale may not be enough due to the\nsignificant multimodality of robotics tasks, lack of easily accessible data and\nthe challenges of deploying on physical hardware. Meanwhile, most deployed\nrobotic systems today are inherently modular and can leverage the independent\ngeneralization capabilities of each module to perform well. Therefore, this\nthesis seeks to tackle the task of building generalist robot agents by\nintegrating these components into one: combining modularity with large-scale\nlearning for general purpose robot control. The first question we consider is:\nhow can we build modularity and hierarchy into learning systems? Our key\ninsight is that rather than having the agent learn hierarchy and low-level\ncontrol end-to-end, we can enforce modularity via planning to enable more\nefficient and capable robot learners. Next, we come to the role of scale in\nbuilding generalist robot systems. To scale, neural networks require vast\namounts of diverse data, expressive architectures to fit the data and a source\nof supervision to generate the data. We leverage a powerful supervision source:\nclassical planning, which can generalize, but is expensive to run and requires\naccess to privileged information to perform well in practice. We use these\nplanners to supervise large-scale policy learning in simulation to produce\ngeneralist agents. Finally, we consider how to unify modularity with\nlarge-scale policy learning to build real-world robot systems capable of\nperforming zero-shot manipulation. We do so by tightly integrating key\ningredients of modular high and mid-level planning, learned local control,\nprocedural scene generation and large-scale policy learning for sim2real\ntransfer. We demonstrate that this recipe can produce a single, generalist\nagent that can solve challenging long-horizon manipulation tasks in the real\nworld.",
      "tldr_zh": "这篇论文探讨如何构建通用的机器人系统，提出了结合模块化设计与大规模学习的创新方法。研究通过规划强制实施模块化，并利用经典规划算法监督大规模策略学习，实现了比端到端学习更高效的机器人控制。最终方案整合了模块化高低层规划、学习型局部控制、程序化场景生成和大规模策略学习等关键技术，成功开发出能解决现实世界中复杂长时程操作任务的通用智能体，且具备零样本迁移能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "CMU Robotics PhD Thesis, 185 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.06814v1",
      "published_date": "2025-03-10 00:38:31 UTC",
      "updated_date": "2025-03-10 00:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:06:43.551775"
    },
    {
      "arxiv_id": "2503.06812v1",
      "title": "Can Proof Assistants Verify Multi-Agent Systems?",
      "title_zh": "证明助手能验证多智能体系统吗？",
      "authors": [
        "Julian Alfredo Mendez",
        "Timotheus Kampik"
      ],
      "abstract": "This paper presents the Soda language for verifying multi-agent systems. Soda\nis a high-level functional and object-oriented language that supports the\ncompilation of its code not only to Scala, a strongly statically typed\nhigh-level programming language, but also to Lean, a proof assistant and\nprogramming language. Given these capabilities, Soda can implement multi-agent\nsystems, or parts thereof, that can then be integrated into a mainstream\nsoftware ecosystem on the one hand and formally verified with state-of-the-art\ntools on the other hand. We provide a brief and informal introduction to Soda\nand the aforementioned interoperability capabilities, as well as a simple\ndemonstration of how interaction protocols can be designed and verified with\nSoda. In the course of the demonstration, we highlight challenges with respect\nto real-world applicability.",
      "tldr_zh": "本文提出了一种名为Soda的新型编程语言，专为验证多智能体系统(MAS)而设计。该语言兼具函数式和面向对象特性，支持将代码编译为Scala和Lean（兼具证明辅助工具功能的编程语言），从而实现了系统实现与形式化验证的双重功能。通过案例演示，研究展示了Soda如何设计并验证交互协议，同时指出了该技术在现实应用场景中面临的挑战。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.LO",
        "cs.MA"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06812v1",
      "published_date": "2025-03-10 00:24:29 UTC",
      "updated_date": "2025-03-10 00:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:07:00.997547"
    },
    {
      "arxiv_id": "2503.06810v1",
      "title": "Mitigating Preference Hacking in Policy Optimization with Pessimism",
      "title_zh": "缓解策略优化中的偏好偏差：基于悲观主义的方法",
      "authors": [
        "Dhawal Gupta",
        "Adam Fisch",
        "Christoph Dann",
        "Alekh Agarwal"
      ],
      "abstract": "This work tackles the problem of overoptimization in reinforcement learning\nfrom human feedback (RLHF), a prevalent technique for aligning models with\nhuman preferences. RLHF relies on reward or preference models trained on\n\\emph{fixed preference datasets}, and these models are unreliable when\nevaluated outside the support of this preference data, leading to the common\nreward or preference hacking phenomenon. We propose novel, pessimistic\nobjectives for RLHF which are provably robust to overoptimization through the\nuse of pessimism in the face of uncertainty, and design practical algorithms,\nP3O and PRPO, to optimize these objectives. Our approach is derived for the\ngeneral preference optimization setting, but can be used with reward models as\nwell. We evaluate P3O and PRPO on the tasks of fine-tuning language models for\ndocument summarization and creating helpful assistants, demonstrating\nremarkable resilience to overoptimization.",
      "tldr_zh": "该研究针对基于人类反馈的强化学习(RLHF)中的过优化问题，提出了一种悲观优化方法。通过引入悲观目标函数，设计P3O和PRPO算法，有效缓解了奖励或偏好模型在固定偏好数据集之外不可靠导致的偏好篡改现象。实验表明，该方法在语言模型微调和助手创建任务中表现出显著的抗过优化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06810v1",
      "published_date": "2025-03-10 00:13:19 UTC",
      "updated_date": "2025-03-10 00:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T05:07:28.610331"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 172,
  "processed_papers_count": 172,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-03-26T05:12:19.492882"
}