{
  "date": "2024-05-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-01 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习的创新应用，包括大型语言模型的优化、多代理强化学习、计算机视觉数据集与模型效率提升，以及因果推理等领域，其中 Self-Play Preference Optimization for Language Model Alignment 和 Causal Evaluation of Language Models 等文章令人印象深刻，展示了知名学者（如 Yue Wu 和 Sirui Chen）在 LLM 领域的突破性工作。\n\n### 重点论文讨论\n我们挑选了最具影响力和话题度的论文优先讨论，将相关主题归类，并快速掠过较次要的文章。以下按主题组织，每篇简要概述核心贡献。\n\n#### 大型语言模型（LLM）优化与对齐\n- **Self-Play Preference Optimization for Language Model Alignment（自玩式偏好优化用于语言模型对齐）**：Yue Wu 等提出 SPPO 算法，将强化学习与 Nash 平衡策略结合，通过迭代更新实现 LLM 的高效对齐，在 AlpacaEval 2.0 上超越 GPT-4-Turbo，实现 28.53% 的胜率，显著提升模型在实际任务中的鲁棒性和准确性。\n- **Causal Evaluation of Language Models（语言模型的因果评估）**：Sirui Chen 等构建 CaLM 基准数据集和框架，系统评估 LLM 的因果推理能力，涵盖因果目标、适应性和度量，实验显示模型在因果任务中表现出色，但也暴露了局限性，为未来 LLM 开发提供指导。\n- **Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment（洞见专家混合：思想链与专家混合在自对齐中的协同作用）**：Zhili Liu 等引入 MoTE 框架，将推理链与混合专家结合，提升 LLM 的安全性和自对齐性能，实验证明其在多任务上优于传统方法。\n- **When Quantization Affects Confidence of Large Language Models（量化如何影响大型语言模型的置信度）**：Irina Proskurina 等发现量化（如 GPTQ 到 4 位）会降低 LLM 对真实标签的置信度，分析显示量化对低置信样本影响更大，为模型校准提供新视角。\n\n这些 LLM 相关论文突出了模型对齐、因果推理和量化效率的进展，尤其 SPPO 的高效性可能引发更多讨论。\n\n#### 计算机视觉与图像处理\n- **Wake Vision: A Tailored Dataset and Benchmark Suite for TinyML Computer Vision Applications（Wake Vision：为 TinyML 计算机视觉应用量身定制的数据集和基准套件）**：Colby Banbury 等发布大规模数据集（超过 600 万图像），用于人检测任务，并提供基准评估，实验显示在低容量模型上提升 1.93% 准确率，推动 TinyML 在实际场景中的应用。\n- **Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis（超越人类视觉：大型视觉语言模型在显微镜图像分析中的作用）**：Prateek Verma 等评估 VLMs（如 LLaVA 和 SAM）在显微镜图像的分类、分割和计数任务中，虽然能理解视觉特征但远逊于专家，强调模型在医疗领域的局限性。\n- **Obtaining Favorable Layouts for Multiple Object Generation（获取多对象生成的有利布局）**：Barak Battash 等提出一种基于注意力图的布局重排方法，提升文本到图像模型在多主体生成中的准确性，减少主体遗漏或重叠。\n\n这些论文强调数据集创新和模型鲁棒性，Wake Vision 作为新基准特别值得关注。\n\n#### 强化学习与多代理系统\n- **MESA: Cooperative Meta-Exploration in Multi-Agent Learning through Exploiting State-Action Space Structure（MESA：通过利用状态-动作空间结构的多代理学习中的合作元探索）**：Zhicheng Zhang 等开发 MESA 方法，针对稀疏奖励环境学习高效探索策略，实验在多代理粒子和 MuJoCo 环境中显著提升性能，并展示泛化能力。\n- **Communication-Efficient Training Workload Balancing for Decentralized Multi-Agent Learning（去中心化多代理学习的通信高效训练工作负载平衡）**：Seyed Mahmoud Sajjadi 等提出 ComDML 算法，通过工作负载优化减少训练时间，同时保持模型准确性，实验在 CIFAR 和 ResNet 上证明其鲁棒性。\n\n强化学习论文聚焦探索和效率，MESA 的创新性较高。\n\n#### 其他快速提及\n- **LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data Lottery Tickets（LOTUS：通过稀疏剪枝和数据彩票票证提升 Transformer 效率）**：Ojasw Upadhyay 提出的方法结合数据选择和剪枝加速视觉 Transformer 训练，显著降低计算需求。\n- **RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization（RST-LoRA：基于话语感知的低秩适应用于长文档抽象总结）**：Dongqi Liu 等将修辞结构理论融入 LoRA，提升长文档总结性能。\n- **SCAR: Scheduling Multi-Model AI Workloads on Heterogeneous Multi-Chiplet Module Accelerators（SCAR：在异构多芯片模块加速器上调度多模型 AI 工作负载）**：Mohanad Odema 等开发调度算法，优化异构硬件上的 AI 训练效率。\n\n这些论文虽有贡献，但主题较 niche，因此仅简要概述。总体而言，今天的 arXiv 展示了 AI 领域的快速迭代，LLM 和视觉模型的优化尤为突出，感兴趣的读者可关注相关代码和数据集。明天见！",
  "papers": [
    {
      "arxiv_id": "2405.00908v1",
      "title": "Transformer-Based Self-Supervised Learning for Histopathological Classification of Ischemic Stroke Clot Origin",
      "title_zh": "翻译失败",
      "authors": [
        "K. Yeh",
        "M. S. Jabal",
        "V. Gupta",
        "D. F. Kallmes",
        "W. Brinjikji",
        "B. S. Erdal"
      ],
      "abstract": "Background and Purpose: Identifying the thromboembolism source in ischemic\nstroke is crucial for treatment and secondary prevention yet is often\nundetermined. This study describes a self-supervised deep learning approach in\ndigital pathology of emboli for classifying ischemic stroke clot origin from\nhistopathological images. Methods: The dataset included whole slide images\n(WSI) from the STRIP AI Kaggle challenge, consisting of retrieved clots from\nischemic stroke patients following mechanical thrombectomy. Transformer-based\ndeep learning models were developed using transfer learning and self-supervised\npretraining for classifying WSI. Customizations included an attention pooling\nlayer, weighted loss function, and threshold optimization. Various model\narchitectures were tested and compared, and model performances were primarily\nevaluated using weighted logarithmic loss. Results: The model achieved a\nlogloss score of 0.662 in cross-validation and 0.659 on the test set. Different\nmodel backbones were compared, with the swin_large_patch4_window12_384 showed\nhigher performance. Thresholding techniques for clot origin classification were\nemployed to balance false positives and negatives. Conclusion: The study\ndemonstrates the extent of efficacy of transformer-based deep learning models\nin identifying ischemic stroke clot origins from histopathological images and\nemphasizes the need for refined modeling techniques specifically adapted to\nthrombi WSI. Further research is needed to improve model performance,\ninterpretability, validate its effectiveness. Future enhancement could include\nintegrating larger patient cohorts, advanced preprocessing strategies, and\nexploring ensemble multimodal methods for enhanced diagnostic accuracy.",
      "tldr_zh": "本文提出了一种基于Transformer的自监督学习方法，用于从组织病理图像（histopathological images）中分类缺血性中风（ischemic stroke）血栓来源，旨在解决血栓来源不确定性的临床挑战。方法包括使用迁移学习（transfer learning）和自监督预训练（self-supervised pretraining），结合注意力池化层（attention pooling layer）、加权损失函数（weighted loss function）和阈值优化（threshold optimization），在STRIP AI Kaggle挑战赛的WSI数据集上训练模型。结果显示，模型在测试集上获得logloss分数0.659，swin_large_patch4_window12_384架构表现出色，显著提高了分类准确性。该研究强调了Transformer-based模型的有效性，并建议未来通过整合更大患者队列和多模态方法进一步提升模型性能和可解释性（interpretability）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00908v1",
      "published_date": "2024-05-01 23:40:12 UTC",
      "updated_date": "2024-05-01 23:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:01:28.467137"
    },
    {
      "arxiv_id": "2405.00906v1",
      "title": "LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data Lottery Tickets",
      "title_zh": "翻译失败",
      "authors": [
        "Ojasw Upadhyay"
      ],
      "abstract": "Vision transformers have revolutionized computer vision, but their\ncomputational demands present challenges for training and deployment. This\npaper introduces LOTUS (LOttery Transformers with Ultra Sparsity), a novel\nmethod that leverages data lottery ticket selection and sparsity pruning to\naccelerate vision transformer training while maintaining accuracy. Our approach\nfocuses on identifying and utilizing the most informative data subsets and\neliminating redundant model parameters to optimize the training process.\nThrough extensive experiments, we demonstrate the effectiveness of LOTUS in\nachieving rapid convergence and high accuracy with significantly reduced\ncomputational requirements. This work highlights the potential of combining\ndata selection and sparsity techniques for efficient vision transformer\ntraining, opening doors for further research and development in this area.",
      "tldr_zh": "本论文提出LOTUS方法，通过数据抽奖票(data lottery tickets)和稀疏性修剪(sparsity pruning)相结合，优化视觉Transformer的训练过程，以减少计算需求同时保持准确性。LOTUS专注于选择最有信息的数据子集并去除冗余模型参数，从而加速训练并实现快速收敛。实验结果显示，该方法在广泛测试中比传统方法提高了效率，并显著降低了计算资源消耗。该研究为高效视觉Transformer训练开辟了新路径，强调了数据选择与稀疏性技术的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "3 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.00906v1",
      "published_date": "2024-05-01 23:30:12 UTC",
      "updated_date": "2024-05-01 23:30:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:01:36.887175"
    },
    {
      "arxiv_id": "2405.00902v1",
      "title": "MESA: Cooperative Meta-Exploration in Multi-Agent Learning through Exploiting State-Action Space Structure",
      "title_zh": "翻译失败",
      "authors": [
        "Zhicheng Zhang",
        "Yancheng Liang",
        "Yi Wu",
        "Fei Fang"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) algorithms often struggle to find\nstrategies close to Pareto optimal Nash Equilibrium, owing largely to the lack\nof efficient exploration. The problem is exacerbated in sparse-reward settings,\ncaused by the larger variance exhibited in policy learning. This paper\nintroduces MESA, a novel meta-exploration method for cooperative multi-agent\nlearning. It learns to explore by first identifying the agents' high-rewarding\njoint state-action subspace from training tasks and then learning a set of\ndiverse exploration policies to \"cover\" the subspace. These trained exploration\npolicies can be integrated with any off-policy MARL algorithm for test-time\ntasks. We first showcase MESA's advantage in a multi-step matrix game.\nFurthermore, experiments show that with learned exploration policies, MESA\nachieves significantly better performance in sparse-reward tasks in several\nmulti-agent particle environments and multi-agent MuJoCo environments, and\nexhibits the ability to generalize to more challenging tasks at test time.",
      "tldr_zh": "这篇论文针对多智能体强化学习 (MARL) 中的探索效率问题，提出了 MESA，一种新型合作元探索方法，通过识别代理的高奖励联合状态-动作子空间并学习多样化的探索策略来提升探索能力。MESA 可以与任何离策略 MARL 算法集成，用于测试任务，从而缓解稀疏奖励设置下的策略学习方差问题。实验结果显示，MESA 在多步矩阵游戏以及多智能体粒子环境和 MuJoCo 环境中的稀疏奖励任务上，显著提高了性能，并展示了良好的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAMAS 2024. 15 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.00902v1",
      "published_date": "2024-05-01 23:19:48 UTC",
      "updated_date": "2024-05-01 23:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:01:50.218304"
    },
    {
      "arxiv_id": "2405.00899v2",
      "title": "Characterising the Creative Process in Humans and Large Language Models",
      "title_zh": "人类和大型语言模型的创造性过程表征",
      "authors": [
        "Surabhi S. Nath",
        "Peter Dayan",
        "Claire Stevenson"
      ],
      "abstract": "Large language models appear quite creative, often performing on par with the\naverage human on creative tasks. However, research on LLM creativity has\nfocused solely on \\textit{products}, with little attention on the creative\n\\textit{process}. Process analyses of human creativity often require hand-coded\ncategories or exploit response times, which do not apply to LLMs. We provide an\nautomated method to characterise how humans and LLMs explore semantic spaces on\nthe Alternate Uses Task, and contrast with behaviour in a Verbal Fluency Task.\nWe use sentence embeddings to identify response categories and compute semantic\nsimilarities, which we use to generate jump profiles. Our results corroborate\nearlier work in humans reporting both persistent (deep search in few semantic\nspaces) and flexible (broad search across multiple semantic spaces) pathways to\ncreativity, where both pathways lead to similar creativity scores. LLMs were\nfound to be biased towards either persistent or flexible paths, that varied\nacross tasks. Though LLMs as a population match human profiles, their\nrelationship with creativity is different, where the more flexible models score\nhigher on creativity. Our dataset and scripts are available on\n\\href{https://github.com/surabhisnath/Creative_Process}{GitHub}.",
      "tldr_zh": "本文研究比较了人类和Large Language Models (LLMs)在创造性过程中的语义空间探索，焦点从以往的产品评估转向过程分析。研究提出了一种自动化方法，使用sentence embeddings识别响应类别、计算语义相似性，并生成jump profiles，应用于Alternate Uses Task和Verbal Fluency Task。结果显示，人类表现出持久（深入搜索少数语义空间）和灵活（广泛搜索多个语义空间）的路径，两者均导致相似的创造性分数，而LLMs则偏向特定路径，且更灵活的模型在创造性评分上更高。该数据集和脚本已在GitHub上公开。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "q-bio.NC"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00899v2",
      "published_date": "2024-05-01 23:06:46 UTC",
      "updated_date": "2024-06-05 19:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:02:02.107532"
    },
    {
      "arxiv_id": "2405.00892v4",
      "title": "Wake Vision: A Tailored Dataset and Benchmark Suite for TinyML Computer Vision Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Colby Banbury",
        "Emil Njor",
        "Andrea Mattia Garavagno",
        "Matthew Stewart",
        "Pete Warden",
        "Manjunath Kudlur",
        "Nat Jeffries",
        "Xenofon Fafoutis",
        "Vijay Janapa Reddi"
      ],
      "abstract": "Tiny machine learning (TinyML) for low-power devices lacks robust datasets\nfor development. We present Wake Vision, a large-scale dataset for person\ndetection that contains over 6 million quality-filtered images. We provide two\nvariants: Wake Vision (Large) and Wake Vision (Quality), leveraging the large\nvariant for pretraining and knowledge distillation, while the higher-quality\nlabels drive final model performance. The manually labeled validation and test\nsets reduce error rates from 7.8% to 2.2% compared to previous standards. In\naddition, we introduce five detailed benchmark sets to evaluate model\nperformance in real-world scenarios, including varying lighting, camera\ndistances, and demographic characteristics. Training with Wake Vision improves\naccuracy by 1.93% over existing datasets, demonstrating the importance of\ndataset quality for low-capacity models and dataset size for high-capacity\nmodels. The dataset, benchmarks, code, and models are available under the CC-BY\n4.0 license, maintained by the Edge AI Foundation.",
      "tldr_zh": "本研究引入了Wake Vision，这是一个针对TinyML计算机视觉应用的大规模数据集，包含超过600万张质量过滤的图像，用于人检测任务。数据集提供两个变体：Wake Vision (Large) 用于预训练和知识蒸馏，以及Wake Vision (Quality) 凭借手动标注的验证和测试集，将错误率从7.8%降至2.2%，从而提升模型性能。该框架还包括五个详细的基准测试集，评估模型在真实场景中的表现，如不同照明、相机距离和人口统计特征。实验结果显示，使用Wake Vision训练的模型比现有数据集提高了1.93%的准确率，突出了数据集质量对低容量模型和规模对高容量模型的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00892v4",
      "published_date": "2024-05-01 22:33:45 UTC",
      "updated_date": "2024-12-09 17:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:02:14.816679"
    },
    {
      "arxiv_id": "2405.00877v3",
      "title": "Markov flow policy -- deep MC",
      "title_zh": "翻译失败",
      "authors": [
        "Nitsan Soffair",
        "Gilad Katz"
      ],
      "abstract": "Discounted algorithms often encounter evaluation errors due to their reliance\non short-term estimations, which can impede their efficacy in addressing\nsimple, short-term tasks and impose undesired temporal discounts (\\(\\gamma\\)).\nInterestingly, these algorithms are often tested without applying a discount, a\nphenomenon we refer as the \\textit{train-test bias}. In response to these\nchallenges, we propose the Markov Flow Policy, which utilizes a non-negative\nneural network flow to enable comprehensive forward-view predictions. Through\nintegration into the TD7 codebase and evaluation using the MuJoCo benchmark, we\nobserve significant performance improvements, positioning MFP as a\nstraightforward, practical, and easily implementable solution within the domain\nof average rewards algorithms.",
      "tldr_zh": "本文指出，Discounted algorithms 依赖短期估计，易导致评估错误和 train-test bias，从而影响简单短期任务的效能，并引入不必要的折扣因子（γ）。为此，研究提出 Markov Flow Policy，通过非负神经网络 flow 实现全面的前向预测，以提升算法的鲁棒性。将该方法整合到 TD7 代码库并在 MuJoCo 基准上测试后，观察到显著性能提升，使其成为平均奖励算法领域的一个简单、实用且易于实现的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper has been not finished",
      "pdf_url": "http://arxiv.org/pdf/2405.00877v3",
      "published_date": "2024-05-01 21:42:38 UTC",
      "updated_date": "2024-08-30 10:02:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:02:25.568030"
    },
    {
      "arxiv_id": "2405.00876v1",
      "title": "Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Prateek Verma",
        "Minh-Hao Van",
        "Xintao Wu"
      ],
      "abstract": "Vision language models (VLMs) have recently emerged and gained the spotlight\nfor their ability to comprehend the dual modality of image and textual data.\nVLMs such as LLaVA, ChatGPT-4, and Gemini have recently shown impressive\nperformance on tasks such as natural image captioning, visual question\nanswering (VQA), and spatial reasoning. Additionally, a universal segmentation\nmodel by Meta AI, Segment Anything Model (SAM) shows unprecedented performance\nat isolating objects from unforeseen images. Since medical experts, biologists,\nand materials scientists routinely examine microscopy or medical images in\nconjunction with textual information in the form of captions, literature, or\nreports, and draw conclusions of great importance and merit, it is indubitably\nessential to test the performance of VLMs and foundation models such as SAM, on\nthese images. In this study, we charge ChatGPT, LLaVA, Gemini, and SAM with\nclassification, segmentation, counting, and VQA tasks on a variety of\nmicroscopy images. We observe that ChatGPT and Gemini are impressively able to\ncomprehend the visual features in microscopy images, while SAM is quite capable\nat isolating artefacts in a general sense. However, the performance is not\nclose to that of a domain expert - the models are readily encumbered by the\nintroduction of impurities, defects, artefact overlaps and diversity present in\nthe images.",
      "tldr_zh": "本研究探讨了大型视觉语言模型 (VLMs) 在显微镜图像分析中的作用，评估了 LLaVA、ChatGPT-4、Gemini 和 Segment Anything Model (SAM) 在处理显微镜图像时的性能。研究通过测试这些模型在 classification、segmentation、counting 和 Visual Question Answering (VQA) 任务上的表现，发现 ChatGPT 和 Gemini 能够较好地理解图像视觉特征，而 SAM 在隔离物体方面表现出色。总体而言，虽然这些模型在某些方面接近人类水平，但仍远逊于领域专家，尤其在面对杂质、缺陷和重叠时容易出错。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00876v1",
      "published_date": "2024-05-01 21:35:04 UTC",
      "updated_date": "2024-05-01 21:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:02:37.882260"
    },
    {
      "arxiv_id": "2405.00874v1",
      "title": "Artificial intelligence for context-aware visual change detection in software test automation",
      "title_zh": "人工智能用于软件测试自动化的上下文感知视觉变化检测",
      "authors": [
        "Milad Moradi",
        "Ke Yan",
        "David Colwell",
        "Rhona Asgari"
      ],
      "abstract": "Automated software testing is integral to the software development process,\nstreamlining workflows and ensuring product reliability. Visual testing within\nthis context, especially concerning user interface (UI) and user experience\n(UX) validation, stands as one of crucial determinants of overall software\nquality. Nevertheless, conventional methods like pixel-wise comparison and\nregion-based visual change detection fall short in capturing contextual\nsimilarities, nuanced alterations, and understanding the spatial relationships\nbetween UI elements. In this paper, we introduce a novel graph-based method for\nvisual change detection in software test automation. Leveraging a machine\nlearning model, our method accurately identifies UI controls from software\nscreenshots and constructs a graph representing contextual and spatial\nrelationships between the controls. This information is then used to find\ncorrespondence between UI controls within screenshots of different versions of\na software. The resulting graph encapsulates the intricate layout of the UI and\nunderlying contextual relations, providing a holistic and context-aware model.\nThis model is finally used to detect and highlight visual regressions in the\nUI. Comprehensive experiments on different datasets showed that our change\ndetector can accurately detect visual software changes in various simple and\ncomplex test scenarios. Moreover, it outperformed pixel-wise comparison and\nregion-based baselines by a large margin in more complex testing scenarios.\nThis work not only contributes to the advancement of visual change detection\nbut also holds practical implications, offering a robust solution for\nreal-world software test automation challenges, enhancing reliability, and\nensuring the seamless evolution of software interfaces.",
      "tldr_zh": "该论文探讨了人工智能在软件测试自动化中的应用，提出了一种基于图的(context-aware)视觉变化检测方法，以克服传统像素-wise comparison 和 region-based 方法在捕捉 UI controls 上下文相似性、细微变化及空间关系方面的不足。方法利用机器学习模型从软件截图中识别 UI controls，并构建图结构来表示控件间的上下文和空间关系，从而在不同软件版本的截图之间匹配对应并检测视觉回归。实验结果表明，该方法在各种简单和复杂测试场景中表现出色，大幅优于基线模型，并为实际软件测试提供可靠解决方案，提升了软件接口的可靠性和演进平稳性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00874v1",
      "published_date": "2024-05-01 21:22:33 UTC",
      "updated_date": "2024-05-01 21:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:02:50.343214"
    },
    {
      "arxiv_id": "2407.10246v3",
      "title": "CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education",
      "title_zh": "翻译失败",
      "authors": [
        "Ty Feng",
        "Sa Liu",
        "Dipak Ghosal"
      ],
      "abstract": "The growing enrollments in computer science courses and increase in class\nsizes necessitate scalable, automated tutoring solutions to adequately support\nstudent learning. While Large Language Models (LLMs) like GPT-4 have\ndemonstrated potential in assisting students through question-answering,\neducators express concerns over student overreliance, miscomprehension of\ngenerated code, and the risk of inaccurate answers. Rather than banning these\ntools outright, we advocate for a constructive approach that harnesses the\ncapabilities of AI while mitigating potential risks. This poster introduces\nCourseAssist, a novel LLM-based tutoring system tailored for computer science\neducation. Unlike generic LLM systems, CourseAssist uses retrieval-augmented\ngeneration, user intent classification, and question decomposition to align AI\nresponses with specific course materials and learning objectives, thereby\nensuring pedagogical appropriateness of LLMs in educational settings. We\nevaluated CourseAssist against a baseline of GPT-4 using a dataset of 50\nquestion-answer pairs from a programming languages course, focusing on the\ncriteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation\nresults show that CourseAssist significantly outperforms the baseline,\ndemonstrating its potential to serve as an effective learning assistant. We\nhave also deployed CourseAssist in 6 computer science courses at a large public\nR1 research university reaching over 500 students. Interviews with 20 student\nusers show that CourseAssist improves computer science instruction by\nincreasing the accessibility of course-specific tutoring help and shortening\nthe feedback loop on their programming assignments. Future work will include\nextensive pilot testing at more universities and exploring better collaborative\nrelationships between students, educators, and AI that improve computer science\nlearning experiences.",
      "tldr_zh": "本研究针对计算机科学课程规模扩大带来的辅导需求，提出CourseAssist，一种基于Large Language Models (LLMs)的教育适宜AI辅导系统。该系统通过retrieval-augmented generation、user intent classification和question decomposition等技术，确保AI响应与特定课程材料和学习目标对齐，从而缓解学生过度依赖和答案不准确的风险。在评估中，CourseAssist与GPT-4基线比较，使用50个问答对，结果显示其在usefulness、accuracy和pedagogical appropriateness方面显著优于基线，并在6门课程中部署，帮助500多名学生提升了辅导可访问性和反馈效率。未来计划扩展到更多大学，并探索学生、教育者和AI的协作优化。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to SIGCSE Virtual 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.10246v3",
      "published_date": "2024-05-01 20:43:06 UTC",
      "updated_date": "2024-07-29 23:01:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:03:01.950850"
    },
    {
      "arxiv_id": "2405.00843v1",
      "title": "Can a Hallucinating Model help in Reducing Human \"Hallucination\"?",
      "title_zh": "翻译失败",
      "authors": [
        "Sowmya S Sundaram",
        "Balaji Alwar"
      ],
      "abstract": "The prevalence of unwarranted beliefs, spanning pseudoscience, logical\nfallacies, and conspiracy theories, presents substantial societal hurdles and\nthe risk of disseminating misinformation. Utilizing established psychometric\nassessments, this study explores the capabilities of large language models\n(LLMs) vis-a-vis the average human in detecting prevalent logical pitfalls. We\nundertake a philosophical inquiry, juxtaposing the rationality of humans\nagainst that of LLMs. Furthermore, we propose methodologies for harnessing LLMs\nto counter misconceptions, drawing upon psychological models of persuasion such\nas cognitive dissonance theory and elaboration likelihood theory. Through this\nendeavor, we highlight the potential of LLMs as personalized misinformation\ndebunking agents.",
      "tldr_zh": "这篇论文探讨大型语言模型 (LLMs) 是否能帮助减少人类的错误信念，如伪科学、逻辑谬误和阴谋论，从而缓解社会误传问题。研究通过心理测量评估和哲学探究，比较了 LLMs 与普通人类的理性能力，特别是检测逻辑陷阱的性能。论文提出利用 LLMs 结合认知失调理论 (cognitive dissonance theory) 和精细加工可能性模型 (elaboration likelihood theory) 等心理模型，作为个性化误传揭露代理的方法。最终，研究强调了 LLMs 在提升理性思维和对抗误信息的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2405.00843v1",
      "published_date": "2024-05-01 20:10:44 UTC",
      "updated_date": "2024-05-01 20:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:03:13.434463"
    },
    {
      "arxiv_id": "2405.00841v2",
      "title": "Sim-Grasp: Learning 6-DOF Grasp Policies for Cluttered Environments Using a Synthetic Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Juncheng Li",
        "David J. Cappelleri"
      ],
      "abstract": "In this paper, we present Sim-Grasp, a robust 6-DOF two-finger grasping\nsystem that integrates advanced language models for enhanced object\nmanipulation in cluttered environments. We introduce the Sim-Grasp-Dataset,\nwhich includes 1,550 objects across 500 scenarios with 7.9 million annotated\nlabels, and develop Sim-GraspNet to generate grasp poses from point clouds. The\nSim-Grasp-Polices achieve grasping success rates of 97.14% for single objects\nand 87.43% and 83.33% for mixed clutter scenarios of Levels 1-2 and Levels 3-4\nobjects, respectively. By incorporating language models for target\nidentification through text and box prompts, Sim-Grasp enables both\nobject-agnostic and target picking, pushing the boundaries of intelligent\nrobotic systems.",
      "tldr_zh": "本论文提出Sim-Grasp，一种用于杂乱环境的6-DOF双指抓取系统，通过整合advanced language models提升物体操作能力，并引入Sim-Grasp-Dataset（包含1,550个物体、500个场景和7.9 million annotated labels）。系统开发了Sim-GraspNet，从point clouds生成抓取姿势，并利用text和box prompts进行目标识别，支持object-agnostic和target picking。实验结果显示，Sim-Grasp-Policies在单一物体抓取成功率达97.14%，而在混合杂乱场景中，Levels 1-2和Levels 3-4的成功率分别为87.43%和83.33%。这一框架推动了智能机器人系统的边界，展示了合成基准在抓取任务中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00841v2",
      "published_date": "2024-05-01 20:08:51 UTC",
      "updated_date": "2024-07-16 22:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:03:26.703583"
    },
    {
      "arxiv_id": "2405.00839v1",
      "title": "Communication-Efficient Training Workload Balancing for Decentralized Multi-Agent Learning",
      "title_zh": "用于去中心化多智能体学习的通信高效训练工作负载均衡",
      "authors": [
        "Seyed Mahmoud Sajjadi Mohammadabadi",
        "Lei Yang",
        "Feng Yan",
        "Junshan Zhang"
      ],
      "abstract": "Decentralized Multi-agent Learning (DML) enables collaborative model training\nwhile preserving data privacy. However, inherent heterogeneity in agents'\nresources (computation, communication, and task size) may lead to substantial\nvariations in training time. This heterogeneity creates a bottleneck,\nlengthening the overall training time due to straggler effects and potentially\nwasting spare resources of faster agents. To minimize training time in\nheterogeneous environments, we present a Communication-Efficient Training\nWorkload Balancing for Decentralized Multi-Agent Learning (ComDML), which\nbalances the workload among agents through a decentralized approach. Leveraging\nlocal-loss split training, ComDML enables parallel updates, where slower agents\noffload part of their workload to faster agents. To minimize the overall\ntraining time, ComDML optimizes the workload balancing by jointly considering\nthe communication and computation capacities of agents, which hinges upon\ninteger programming. A dynamic decentralized pairing scheduler is developed to\nefficiently pair agents and determine optimal offloading amounts. We prove that\nin ComDML, both slower and faster agents' models converge, for convex and\nnon-convex functions. Furthermore, extensive experimental results on popular\ndatasets (CIFAR-10, CIFAR-100, and CINIC-10) and their non-I.I.D. variants,\nwith large models such as ResNet-56 and ResNet-110, demonstrate that ComDML can\nsignificantly reduce the overall training time while maintaining model\naccuracy, compared to state-of-the-art methods. ComDML demonstrates robustness\nin heterogeneous environments, and privacy measures can be seamlessly\nintegrated for enhanced data protection.",
      "tldr_zh": "本研究针对Decentralized Multi-agent Learning (DML)中代理资源异质性导致的训练时间不均和资源浪费问题，提出了一种通信高效的训练工作负载平衡框架ComDML。ComDML通过local-loss split training实现并行更新，让较慢代理将部分工作负载卸载给较快代理，并利用整数编程优化通信和计算容量，同时开发动态去中心化配对调度器来确定最佳卸载策略。实验结果显示，在CIFAR-10、CIFAR-100和CINIC-10数据集上使用ResNet-56和ResNet-110模型时，ComDML显著缩短了整体训练时间，同时保持模型准确性，并证明了其在凸和非凸函数下的模型收敛性，以及在非I.I.D.数据和隐私保护场景中的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for presentation at ICDCS (44th IEEE\n  International Conference on Distributed Computing Systems). Keywords:\n  decentralized multi-agent learning, federated learning, edge computing,\n  heterogeneous agents, workload balancing, and communication-efficient\n  training )",
      "pdf_url": "http://arxiv.org/pdf/2405.00839v1",
      "published_date": "2024-05-01 20:03:37 UTC",
      "updated_date": "2024-05-01 20:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:03:38.780163"
    },
    {
      "arxiv_id": "2405.00823v2",
      "title": "WorkBench: a Benchmark Dataset for Agents in a Realistic Workplace Setting",
      "title_zh": "WorkBench：针对智能体在真实工作场所环境的基准数据集",
      "authors": [
        "Olly Styles",
        "Sam Miller",
        "Patricio Cerda-Mardini",
        "Tanaya Guha",
        "Victor Sanchez",
        "Bertie Vidgen"
      ],
      "abstract": "We introduce WorkBench: a benchmark dataset for evaluating agents' ability to\nexecute tasks in a workplace setting. WorkBench contains a sandbox environment\nwith five databases, 26 tools, and 690 tasks. These tasks represent common\nbusiness activities, such as sending emails and scheduling meetings. The tasks\nin WorkBench are challenging as they require planning, tool selection, and\noften multiple actions. If a task has been successfully executed, one (or more)\nof the database values may change. The correct outcome for each task is unique\nand unambiguous, which allows for robust, automated evaluation. We call this\nkey contribution outcome-centric evaluation. We evaluate five existing ReAct\nagents on WorkBench, finding they successfully complete as few as 3% of tasks\n(Llama2-70B), and just 43% for the best-performing (GPT-4). We further find\nthat agents' errors can result in the wrong action being taken, such as an\nemail being sent to the wrong person. WorkBench reveals weaknesses in agents'\nability to undertake common business activities, raising questions about their\nuse in high-stakes workplace settings. WorkBench is publicly available as a\nfree resource at https://github.com/olly-styles/WorkBench.",
      "tldr_zh": "本研究引入了WorkBench，这是一个用于评估代理在真实工作场所执行任务能力的基准数据集。WorkBench包含一个沙盒环境、5个数据库、26个工具和690个任务，这些任务涉及常见的商业活动如发送电子邮件和安排会议，并需要规划、工具选择和多步操作。论文提出outcome-centric evaluation方法，通过检查任务结果的唯一性和数据库变化来实现鲁棒的自动评估；在测试五个ReAct代理时，发现表现从3%（Llama2-70B）到43%（GPT-4）不等，并揭示了代理在高风险环境中可能导致错误行动的弱点，如发邮件给错误人员。WorkBench作为开源资源，已在GitHub上公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00823v2",
      "published_date": "2024-05-01 19:07:03 UTC",
      "updated_date": "2024-08-03 12:41:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:03:51.257139"
    },
    {
      "arxiv_id": "2405.00791v1",
      "title": "Obtaining Favorable Layouts for Multiple Object Generation",
      "title_zh": "获取有利的布局用于多个对象生成",
      "authors": [
        "Barak Battash",
        "Amit Rozner",
        "Lior Wolf",
        "Ofir Lindenbaum"
      ],
      "abstract": "Large-scale text-to-image models that can generate high-quality and diverse\nimages based on textual prompts have shown remarkable success. These models aim\nultimately to create complex scenes, and addressing the challenge of\nmulti-subject generation is a critical step towards this goal. However, the\nexisting state-of-the-art diffusion models face difficulty when generating\nimages that involve multiple subjects. When presented with a prompt containing\nmore than one subject, these models may omit some subjects or merge them\ntogether. To address this challenge, we propose a novel approach based on a\nguiding principle. We allow the diffusion model to initially propose a layout,\nand then we rearrange the layout grid. This is achieved by enforcing\ncross-attention maps (XAMs) to adhere to proposed masks and by migrating pixels\nfrom latent maps to new locations determined by us. We introduce new loss terms\naimed at reducing XAM entropy for clearer spatial definition of subjects,\nreduce the overlap between XAMs, and ensure that XAMs align with their\nrespective masks. We contrast our approach with several alternative methods and\nshow that it more faithfully captures the desired concepts across a variety of\ntext prompts.",
      "tldr_zh": "这篇论文针对大型文本到图像模型在生成多主体图像时存在的遗漏主体或合并主体的问题，提出了一种新方法来优化布局。方法允许diffusion models先提出初始布局，然后通过重新排列布局网格、强制cross-attention maps (XAMs)遵守指定的掩码，以及迁移像素到新位置来实现精确控制。具体而言，引入新的损失函数来降低XAMs的熵、减少XAMs重叠，并确保XAMs与掩码对齐。与其他方法对比，该方法在各种文本提示上更忠实地捕捉了期望的概念，提高了多主体生成的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2, I.4"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00791v1",
      "published_date": "2024-05-01 18:07:48 UTC",
      "updated_date": "2024-05-01 18:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:04:02.683845"
    },
    {
      "arxiv_id": "2405.00790v2",
      "title": "SCAR: Scheduling Multi-Model AI Workloads on Heterogeneous Multi-Chiplet Module Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Mohanad Odema",
        "Luke Chen",
        "Hyoukjun Kwon",
        "Mohammad Abdullah Al Faruque"
      ],
      "abstract": "Emerging multi-model workloads with heavy models like recent large language\nmodels significantly increased the compute and memory demands on hardware. To\naddress such increasing demands, designing a scalable hardware architecture\nbecame a key problem. Among recent solutions, the 2.5D silicon interposer\nmulti-chip module (MCM)-based AI accelerator has been actively explored as a\npromising scalable solution due to their significant benefits in the low\nengineering cost and composability. However, previous MCM accelerators are\nbased on homogeneous architectures with fixed dataflow, which encounter major\nchallenges from highly heterogeneous multi-model workloads due to their limited\nworkload adaptivity. Therefore, in this work, we explore the opportunity in the\nheterogeneous dataflow MCM AI accelerators. We identify the scheduling of\nmulti-model workload on heterogeneous dataflow MCM AI accelerator is an\nimportant and challenging problem due to its significance and scale, which\nreaches O(10^56) even for a two-model workload on 6x6 chiplets. We develop a\nset of heuristics to navigate the huge scheduling space and codify them into a\nscheduler, SCAR, with advanced techniques such as inter-chiplet pipelining. Our\nevaluation on ten multi-model workload scenarios for datacenter multitenancy\nand AR/VR use-cases has shown the efficacy of our approach, achieving on\naverage 27.6% and 29.6% less energy-delay product (EDP) for the respective\napplications settings compared to homogeneous baselines.",
      "tldr_zh": "本文提出 SCAR 调度器，用于在异质多芯片模块 (Heterogeneous Multi-Chiplet Module) 加速器上处理多模型 AI Workloads 的挑战，以应对大型语言模型等对计算和内存需求的增加。SCAR 通过一组启发式方法和高级技术如 inter-chiplet pipelining 来导航庞大的调度空间（规模达 O(10^56)），从而优化异质数据流架构的适应性。实验评估显示，在十种数据中心多租户和 AR/VR 用例中，SCAR 比同质基线平均减少 27.6% 和 29.6% 的能量延迟乘积 (EDP)。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "MICRO'24",
      "pdf_url": "http://arxiv.org/pdf/2405.00790v2",
      "published_date": "2024-05-01 18:02:25 UTC",
      "updated_date": "2024-09-14 18:32:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:04:15.838287"
    },
    {
      "arxiv_id": "2405.00675v5",
      "title": "Self-Play Preference Optimization for Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Wu",
        "Zhiqing Sun",
        "Huizhuo Yuan",
        "Kaixuan Ji",
        "Yiming Yang",
        "Quanquan Gu"
      ],
      "abstract": "Standard reinforcement learning from human feedback (RLHF) approaches relying\non parametric models like the Bradley-Terry model fall short in capturing the\nintransitivity and irrationality in human preferences. Recent advancements\nsuggest that directly working with preference probabilities can yield a more\naccurate reflection of human preferences, enabling more flexible and accurate\nlanguage model alignment. In this paper, we propose a self-play-based method\nfor language model alignment, which treats the problem as a constant-sum\ntwo-player game aimed at identifying the Nash equilibrium policy. Our approach,\ndubbed Self-Play Preference Optimization (SPPO), utilizes iterative policy\nupdates to provably approximate the Nash equilibrium. Additionally, we propose\na new SPPO objective which is both strongly motivated by theory and is simple\nand effective in practice. In our experiments, using only 60k prompts (without\nresponses) from the UltraFeedback dataset and without any prompt augmentation,\nby leveraging a pre-trained preference model PairRM with only 0.4B parameters,\nSPPO can obtain a model from fine-tuning Mistral-7B-Instruct-v0.2 that achieves\nthe state-of-the-art length-controlled win-rate of 28.53% against GPT-4-Turbo\non AlpacaEval 2.0. It also outperforms the (iterative) DPO and IPO on MT-Bench,\nArena-Hard, and the Open LLM Leaderboard. Starting from a stronger base model\nLlama-3-8B-Instruct, we are able to achieve a length-controlled win rate of\n38.77%. Notably, the strong performance of SPPO is achieved without additional\nexternal supervision (e.g., responses, preferences, etc.) from GPT-4 or other\nstronger language models. Codes are available at\nhttps://github.com/uclaml/SPPO.",
      "tldr_zh": "本研究指出，标准RLHF方法依赖于参数模型如Bradley-Terry，无法有效捕捉人类偏好的非传递性和非理性，因此提出了一种基于自博弈(Self-Play)的语言模型对齐方法，名为Self-Play Preference Optimization (SPPO)。SPPO将问题视为常和两玩家游戏，通过迭代策略更新逼近Nash equilibrium，并引入一个理论支持且实用的新优化目标，仅使用UltraFeedback数据集的60k提示（无响应）和小型预训练模型PairRM（0.4B参数），即可微调Mistral-7B-Instruct-v0.2模型，在AlpacaEval 2.0上实现对GPT-4-Turbo的长度控制胜率28.53%。实验结果显示，SPPO在MT-Bench、Arena-Hard和Open LLM Leaderboard上优于DPO和IPO，且从Llama-3-8B-Instruct起始模型出发可达38.77%的胜率，无需额外外部监督。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 4 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.00675v5",
      "published_date": "2024-05-01 17:59:20 UTC",
      "updated_date": "2024-10-04 18:48:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:04:28.397225"
    },
    {
      "arxiv_id": "2405.00664v1",
      "title": "Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3",
      "title_zh": "翻译失败",
      "authors": [
        "Junsang Yoon",
        "Akshat Gupta",
        "Gopala Anumanchipalli"
      ],
      "abstract": "This study presents a targeted model editing analysis focused on the latest\nlarge language model, Llama-3. We explore the efficacy of popular model editing\ntechniques - ROME, MEMIT, and EMMET, which are designed for precise layer\ninterventions. We identify the most effective layers for targeted edits through\nan evaluation that encompasses up to 4096 edits across three distinct\nstrategies: sequential editing, batch editing, and a hybrid approach we call as\nsequential-batch editing. Our findings indicate that increasing edit\nbatch-sizes may degrade model performance more significantly than using smaller\nedit batches sequentially for equal number of edits. With this, we argue that\nsequential model editing is an important component for scaling model editing\nmethods and future research should focus on methods that combine both batched\nand sequential editing. This observation suggests a potential limitation in\ncurrent model editing methods which push towards bigger edit batch sizes, and\nwe hope it paves way for future investigations into optimizing batch sizes and\nmodel editing performance.",
      "tldr_zh": "这篇论文通过实证研究探讨了在 Llama-3 模型上，模型编辑的批量大小是否总是越好。研究评估了 ROME、MEMIT 和 EMMET 等流行技术在顺序编辑（sequential editing）、批量编辑（batch editing）和混合策略（sequential-batch editing）下的效果，涵盖多达 4096 次编辑。结果表明，增加编辑批量大小可能导致模型性能下降幅度更大，而使用较小批量的顺序编辑更具优势。作者强调，顺序编辑在扩展模型编辑方法中至关重要，并建议未来研究聚焦于优化批量大小和结合不同编辑策略，以提升整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00664v1",
      "published_date": "2024-05-01 17:50:37 UTC",
      "updated_date": "2024-05-01 17:50:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:04:39.376895"
    },
    {
      "arxiv_id": "2405.00657v2",
      "title": "RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Dongqi Liu",
        "Vera Demberg"
      ],
      "abstract": "For long document summarization, discourse structure is important to discern\nthe key content of the text and the differences in importance level between\nsentences. Unfortunately, the integration of rhetorical structure theory (RST)\ninto parameter-efficient fine-tuning strategies for long document summarization\nremains unexplored. Therefore, this paper introduces RST-LoRA and proposes four\nRST-aware variants to explicitly incorporate RST into the LoRA model. Our\nempirical evaluation demonstrates that incorporating the type and uncertainty\nof rhetorical relations can complementarily enhance the performance of LoRA in\nsummarization tasks. Furthermore, the best-performing variant we introduced\noutperforms the vanilla LoRA and full-parameter fine-tuning models, as\nconfirmed by multiple automatic and human evaluations, and even surpasses\nprevious state-of-the-art methods.",
      "tldr_zh": "本研究提出 RST-LoRA，一种将 Rhetorical Structure Theory (RST) 整合到 Low-Rank Adaptation (LoRA) 模型中的参数高效微调策略，用于长文档抽取式摘要。论文设计了四个 RST-aware 变体，通过显式考虑修辞关系的类型和不确定性，提升了模型对关键内容和句子重要性的辨识能力。实验结果显示，最佳变体在多种自动和人工评估中超过了原版 LoRA 和全参数微调模型，甚至超越了之前的最先进方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024 Main & Long Conference Paper (Oral Presentation)",
      "pdf_url": "http://arxiv.org/pdf/2405.00657v2",
      "published_date": "2024-05-01 17:37:50 UTC",
      "updated_date": "2024-12-10 09:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:04:50.073877"
    },
    {
      "arxiv_id": "2405.00644v1",
      "title": "ConstrainedZero: Chance-Constrained POMDP Planning using Learned Probabilistic Failure Surrogates and Adaptive Safety Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Robert J. Moss",
        "Arec Jamgochian",
        "Johannes Fischer",
        "Anthony Corso",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "To plan safely in uncertain environments, agents must balance utility with\nsafety constraints. Safe planning problems can be modeled as a\nchance-constrained partially observable Markov decision process (CC-POMDP) and\nsolutions often use expensive rollouts or heuristics to estimate the optimal\nvalue and action-selection policy. This work introduces the ConstrainedZero\npolicy iteration algorithm that solves CC-POMDPs in belief space by learning\nneural network approximations of the optimal value and policy with an\nadditional network head that estimates the failure probability given a belief.\nThis failure probability guides safe action selection during online Monte Carlo\ntree search (MCTS). To avoid overemphasizing search based on the failure\nestimates, we introduce $\\Delta$-MCTS, which uses adaptive conformal inference\nto update the failure threshold during planning. The approach is tested on a\nsafety-critical POMDP benchmark, an aircraft collision avoidance system, and\nthe sustainability problem of safe CO$_2$ storage. Results show that by\nseparating safety constraints from the objective we can achieve a target level\nof safety without optimizing the balance between rewards and costs.",
      "tldr_zh": "该研究提出ConstrainedZero算法，用于解决机会约束部分可观测马尔可夫决策过程(CC-POMDP)中的安全规划问题，通过学习神经网络来近似最优价值、策略，并估计给定信念的失败概率，以指导在线Monte Carlo Tree Search (MCTS)中的安全行动选择。算法引入Δ-MCTS方法，利用自适应置信推理动态更新失败阈值，避免过度依赖失败估计。实验在安全关键POMDP基准、飞机碰撞避免系统和CO$_2$存储可持续性问题上验证，结果显示这种分离安全约束与目标的方法，能在不优化奖励和成本平衡的情况下实现目标安全水平。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings of the 2024 International Joint Conference on\n  Artificial Intelligence (IJCAI)",
      "pdf_url": "http://arxiv.org/pdf/2405.00644v1",
      "published_date": "2024-05-01 17:17:22 UTC",
      "updated_date": "2024-05-01 17:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:05:01.745221"
    },
    {
      "arxiv_id": "2405.00632v1",
      "title": "When Quantization Affects Confidence of Large Language Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Irina Proskurina",
        "Luc Brun",
        "Guillaume Metzler",
        "Julien Velcin"
      ],
      "abstract": "Recent studies introduced effective compression techniques for Large Language\nModels (LLMs) via post-training quantization or low-bit weight representation.\nAlthough quantized weights offer storage efficiency and allow for faster\ninference, existing works have indicated that quantization might compromise\nperformance and exacerbate biases in LLMs. This study investigates the\nconfidence and calibration of quantized models, considering factors such as\nlanguage model type and scale as contributors to quantization loss. Firstly, we\nreveal that quantization with GPTQ to 4-bit results in a decrease in confidence\nregarding true labels, with varying impacts observed among different language\nmodels. Secondly, we observe fluctuations in the impact on confidence across\ndifferent scales. Finally, we propose an explanation for quantization loss\nbased on confidence levels, indicating that quantization disproportionately\naffects samples where the full model exhibited low confidence levels in the\nfirst place.",
      "tldr_zh": "本研究探讨了量化技术对大型语言模型(LLMs)的置信度和校准的影响，重点分析了量化后可能导致性能下降和偏差加剧的问题。实验使用GPTQ将模型量化到4-bit，发现量化会降低模型对真实标签的置信度，且不同LLMs类型和规模的影响存在差异。研究进一步解释，量化损失主要针对原本低置信度样本，揭示了量化过程的潜在机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2405.00632v1",
      "published_date": "2024-05-01 16:58:28 UTC",
      "updated_date": "2024-05-01 16:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:05:12.825859"
    },
    {
      "arxiv_id": "2405.00629v2",
      "title": "HUGO -- Highlighting Unseen Grid Options: Combining Deep Reinforcement Learning with a Heuristic Target Topology Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Malte Lehna",
        "Clara Holzhüter",
        "Sven Tomforde",
        "Christoph Scholz"
      ],
      "abstract": "With the growth of Renewable Energy (RE) generation, the operation of power\ngrids has become increasingly complex. One solution could be automated grid\noperation, where Deep Reinforcement Learning (DRL) has repeatedly shown\nsignificant potential in Learning to Run a Power Network (L2RPN) challenges.\nHowever, only individual actions at the substation level have been subjected to\ntopology optimization by most existing DRL algorithms. In contrast, we propose\na more holistic approach by proposing specific Target Topologies (TTs) as\nactions. These topologies are selected based on their robustness. As part of\nthis paper, we present a search algorithm to find the TTs and upgrade our\npreviously developed DRL agent CurriculumAgent (CAgent) to a novel topology\nagent. We compare the upgrade to the previous CAgent and can increase their\nL2RPN score significantly by 10%. Further, we achieve a 25% better median\nsurvival time with our TTs included. Later analysis shows that almost all TTs\nare close to the base topology, explaining their robustness",
      "tldr_zh": "该研究提出HUGO框架，将深度强化学习（DRL）与启发式目标拓扑（Target Topologies, TTs）方法相结合，旨在优化电力网格操作以应对可再生能源（RE）增长带来的复杂性。HUGO通过基于鲁棒性的搜索算法选取TTs作为动作，并升级了之前的CurriculumAgent（CAgent）为新型拓扑代理，从而实现更全面的拓扑优化。实验结果显示，新代理在L2RPN挑战中比原CAgent提高了10%的分数，并提升了25%的中位生存时间；进一步分析表明，这些TTs接近基础拓扑，这解释了它们的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages + 2 pages references, 9 Figures, submission planed in\n  Sustainable Energy, Grids and Networks",
      "pdf_url": "http://arxiv.org/pdf/2405.00629v2",
      "published_date": "2024-05-01 16:54:12 UTC",
      "updated_date": "2024-05-23 08:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:05:26.201740"
    },
    {
      "arxiv_id": "2405.00623v2",
      "title": "\"I'm Not Sure, But...\": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust",
      "title_zh": "翻译失败",
      "authors": [
        "Sunnie S. Y. Kim",
        "Q. Vera Liao",
        "Mihaela Vorvoreanu",
        "Stephanie Ballard",
        "Jennifer Wortman Vaughan"
      ],
      "abstract": "Widely deployed large language models (LLMs) can produce convincing yet\nincorrect outputs, potentially misleading users who may rely on them as if they\nwere correct. To reduce such overreliance, there have been calls for LLMs to\ncommunicate their uncertainty to end users. However, there has been little\nempirical work examining how users perceive and act upon LLMs' expressions of\nuncertainty. We explore this question through a large-scale, pre-registered,\nhuman-subject experiment (N=404) in which participants answer medical questions\nwith or without access to responses from a fictional LLM-infused search engine.\nUsing both behavioral and self-reported measures, we examine how different\nnatural language expressions of uncertainty impact participants' reliance,\ntrust, and overall task performance. We find that first-person expressions\n(e.g., \"I'm not sure, but...\") decrease participants' confidence in the system\nand tendency to agree with the system's answers, while increasing participants'\naccuracy. An exploratory analysis suggests that this increase can be attributed\nto reduced (but not fully eliminated) overreliance on incorrect answers. While\nwe observe similar effects for uncertainty expressed from a general perspective\n(e.g., \"It's not clear, but...\"), these effects are weaker and not\nstatistically significant. Our findings suggest that using natural language\nexpressions of uncertainty may be an effective approach for reducing\noverreliance on LLMs, but that the precise language used matters. This\nhighlights the importance of user testing before deploying LLMs at scale.",
      "tldr_zh": "这篇论文研究了大型语言模型(LLMs)通过自然语言表达不确定性（如“I'm not sure, but...”）对用户依赖和信任的影响，旨在减少用户对错误输出的过度依赖。研究通过大规模预注册实验（N=404），让参与者回答医疗问题并评估不同不确定性表达方式对行为和自报措施的影响。结果显示，第一人称表达能降低用户对系统的信心，减少同意错误答案，从而提高任务准确率，而一般视角表达（如“It's not clear, but...”）的效果较弱且不显著。论文强调，使用适当的不确定性语言可能有效缓解过度依赖，但需通过用户测试来优化LLMs的部署。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to FAccT 2024. This version includes the appendix",
      "pdf_url": "http://arxiv.org/pdf/2405.00623v2",
      "published_date": "2024-05-01 16:43:55 UTC",
      "updated_date": "2024-05-15 09:04:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:05:38.967709"
    },
    {
      "arxiv_id": "2405.00622v1",
      "title": "Causal Evaluation of Language Models",
      "title_zh": "语言模型的因果评估",
      "authors": [
        "Sirui Chen",
        "Bo Peng",
        "Meiqi Chen",
        "Ruiqi Wang",
        "Mengying Xu",
        "Xingyu Zeng",
        "Rui Zhao",
        "Shengjie Zhao",
        "Yu Qiao",
        "Chaochao Lu"
      ],
      "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine\nintelligence. Recent advances in language models have expanded the horizons of\nartificial intelligence across various domains, sparking inquiries into their\npotential for causal reasoning. In this work, we introduce Causal evaluation of\nLanguage Models (CaLM), which, to the best of our knowledge, is the first\ncomprehensive benchmark for evaluating the causal reasoning capabilities of\nlanguage models. First, we propose the CaLM framework, which establishes a\nfoundational taxonomy consisting of four modules: causal target (i.e., what to\nevaluate), adaptation (i.e., how to obtain the results), metric (i.e., how to\nmeasure the results), and error (i.e., how to analyze the bad results). This\ntaxonomy defines a broad evaluation design space while systematically selecting\ncriteria and priorities. Second, we compose the CaLM dataset, comprising\n126,334 data samples, to provide curated sets of causal targets, adaptations,\nmetrics, and errors, offering extensive coverage for diverse research pursuits.\nThird, we conduct an extensive evaluation of 28 leading language models on a\ncore set of 92 causal targets, 9 adaptations, 7 metrics, and 12 error types.\nFourth, we perform detailed analyses of the evaluation results across various\ndimensions (e.g., adaptation, scale). Fifth, we present 50 high-level empirical\nfindings across 9 dimensions (e.g., model), providing valuable guidance for\nfuture language model development. Finally, we develop a multifaceted platform,\nincluding a website, leaderboards, datasets, and toolkits, to support scalable\nand adaptable assessments. We envision CaLM as an ever-evolving benchmark for\nthe community, systematically updated with new causal targets, adaptations,\nmodels, metrics, and error types to reflect ongoing research advancements.\nProject website is at https://opencausalab.github.io/CaLM.",
      "tldr_zh": "本文提出 CaLM，这是首个全面评估语言模型因果推理能力的基准框架，包括四个模块：causal target（评估目标）、adaptation（结果获取方式）、metric（测量指标）和 error（错误分析）。研究构建了包含 126,334 个样本的 CaLM 数据集，并对 28 个领先语言模型进行了广泛评估，涵盖 92 个 causal target、9 个 adaptation、7 个 metric 和 12 种 error 类型。实验结果分析揭示了 50 个高级经验发现，例如模型规模与性能的相关性，为未来语言模型开发提供指导。最后，开发了一个多方面平台，包括网站和工具包，以支持可扩展的评估，并将 CaLM 定位为不断演进的社区基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "315 pages, 230 figures, 21 tables. Project website:\n  https://opencausalab.github.io/CaLM",
      "pdf_url": "http://arxiv.org/pdf/2405.00622v1",
      "published_date": "2024-05-01 16:43:21 UTC",
      "updated_date": "2024-05-01 16:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:05:51.466306"
    },
    {
      "arxiv_id": "2405.00588v1",
      "title": "Are Models Biased on Text without Gender-related Language?",
      "title_zh": "翻译失败",
      "authors": [
        "Catarina G Belém",
        "Preethi Seshadri",
        "Yasaman Razeghi",
        "Sameer Singh"
      ],
      "abstract": "Gender bias research has been pivotal in revealing undesirable behaviors in\nlarge language models, exposing serious gender stereotypes associated with\noccupations, and emotions. A key observation in prior work is that models\nreinforce stereotypes as a consequence of the gendered correlations that are\npresent in the training data. In this paper, we focus on bias where the effect\nfrom training data is unclear, and instead address the question: Do language\nmodels still exhibit gender bias in non-stereotypical settings? To do so, we\nintroduce UnStereoEval (USE), a novel framework tailored for investigating\ngender bias in stereotype-free scenarios. USE defines a sentence-level score\nbased on pretraining data statistics to determine if the sentence contain\nminimal word-gender associations. To systematically benchmark the fairness of\npopular language models in stereotype-free scenarios, we utilize USE to\nautomatically generate benchmarks without any gender-related language. By\nleveraging USE's sentence-level score, we also repurpose prior gender bias\nbenchmarks (Winobias and Winogender) for non-stereotypical evaluation.\nSurprisingly, we find low fairness across all 28 tested models. Concretely,\nmodels demonstrate fair behavior in only 9%-41% of stereotype-free sentences,\nsuggesting that bias does not solely stem from the presence of gender-related\nwords. These results raise important questions about where underlying model\nbiases come from and highlight the need for more systematic and comprehensive\nbias evaluation. We release the full dataset and code at\nhttps://ucinlp.github.io/unstereo-eval.",
      "tldr_zh": "这篇论文探讨大型语言模型在无性别相关语言的文本中是否仍存在性别偏见，挑战了传统观点，即偏见主要源于训练数据中的性别相关性。研究引入了UnStereoEval (USE)框架，该框架基于预训练数据统计计算句子级别的性别关联分数，以自动生成无刻板印象的基准数据集，并改编现有基准如Winobias和Winogender用于非刻板印象评估。实验结果显示，在28个测试模型中，模型在无刻板印象句子的公平行为仅为9%-41%，表明性别偏见可能源于更深层的原因。论文强调了需要更系统全面的偏见评估，并发布了相关数据集和代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "In International Conference on Learning Representations 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00588v1",
      "published_date": "2024-05-01 15:51:15 UTC",
      "updated_date": "2024-05-01 15:51:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:06:04.203066"
    },
    {
      "arxiv_id": "2405.00578v1",
      "title": "The Real, the Better: Aligning Large Language Models with Online Human Behaviors",
      "title_zh": "翻译失败",
      "authors": [
        "Guanying Jiang",
        "Lingyong Yan",
        "Haibo Shi",
        "Dawei Yin"
      ],
      "abstract": "Large language model alignment is widely used and studied to avoid LLM\nproducing unhelpful and harmful responses. However, the lengthy training\nprocess and predefined preference bias hinder adaptation to online diverse\nhuman preferences. To this end, this paper proposes an alignment framework,\ncalled Reinforcement Learning with Human Behavior (RLHB), to align LLMs by\ndirectly leveraging real online human behaviors. By taking the generative\nadversarial framework, the generator is trained to respond following expected\nhuman behavior; while the discriminator tries to verify whether the triplets of\nquery, response, and human behavior come from real online environments.\nBehavior modeling in natural-language form and the multi-model joint training\nmechanism enable an active and sustainable online alignment. Experimental\nresults confirm the effectiveness of our proposed methods by both human and\nautomatic evaluations.",
      "tldr_zh": "这篇论文提出RLHB（Reinforcement Learning with Human Behavior）框架，用于对齐Large Language Models (LLMs)，以直接利用真实在线人类行为，解决传统对齐方法中训练过程漫长和偏好偏见的问题。框架采用生成对抗式方法，其中生成器被训练生成符合预期人类行为的响应，而鉴别器则验证查询、响应和人类行为是否源于真实在线环境，并通过行为建模和多模型联合训练实现主动可持续的对齐。实验结果通过人类和自动评估证实了RLHB的有效性，展示了其在适应多样化人类偏好方面的优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.00578v1",
      "published_date": "2024-05-01 15:30:41 UTC",
      "updated_date": "2024-05-01 15:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:06:15.252892"
    },
    {
      "arxiv_id": "2405.00760v1",
      "title": "Deep Reward Supervisions for Tuning Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoshi Wu",
        "Yiming Hao",
        "Manyuan Zhang",
        "Keqiang Sun",
        "Zhaoyang Huang",
        "Guanglu Song",
        "Yu Liu",
        "Hongsheng Li"
      ],
      "abstract": "Optimizing a text-to-image diffusion model with a given reward function is an\nimportant but underexplored research area. In this study, we propose Deep\nReward Tuning (DRTune), an algorithm that directly supervises the final output\nimage of a text-to-image diffusion model and back-propagates through the\niterative sampling process to the input noise. We find that training earlier\nsteps in the sampling process is crucial for low-level rewards, and deep\nsupervision can be achieved efficiently and effectively by stopping the\ngradient of the denoising network input. DRTune is extensively evaluated on\nvarious reward models. It consistently outperforms other algorithms,\nparticularly for low-level control signals, where all shallow supervision\nmethods fail. Additionally, we fine-tune Stable Diffusion XL 1.0 (SDXL 1.0)\nmodel via DRTune to optimize Human Preference Score v2.1, resulting in the\nFavorable Diffusion XL 1.0 (FDXL 1.0) model. FDXL 1.0 significantly enhances\nimage quality compared to SDXL 1.0 and reaches comparable quality compared with\nMidjourney v5.2.",
      "tldr_zh": "这篇论文提出了 Deep Reward Tuning (DRTune) 算法，用于优化文本到图像扩散模型，通过直接监督最终输出图像并反向传播到输入噪声，以提升模型性能。DRTune 强调训练采样过程的早期步骤，并通过停止去噪网络输入的梯度来高效实现深度监督，尤其在低级控制信号上，显著优于其他浅层监督方法。实验结果显示，该算法在各种奖励模型上表现出色，并通过微调 Stable Diffusion XL 1.0 (SDXL 1.0) 模型，生成 Favorable Diffusion XL 1.0 (FDXL 1.0)，其图像质量比 SDXL 1.0 显著提升，并达到与 Midjourney v5.2 相当的水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "N/A",
      "pdf_url": "http://arxiv.org/pdf/2405.00760v1",
      "published_date": "2024-05-01 15:26:14 UTC",
      "updated_date": "2024-05-01 15:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:06:27.250583"
    },
    {
      "arxiv_id": "2405.00571v1",
      "title": "Spherical Linear Interpolation and Text-Anchoring for Zero-shot Composed Image Retrieval",
      "title_zh": "球面线性插值和文本锚定用于零样本组合图像检索",
      "authors": [
        "Young Kyun Jang",
        "Dat Huynh",
        "Ashish Shah",
        "Wen-Kai Chen",
        "Ser-Nam Lim"
      ],
      "abstract": "Composed Image Retrieval (CIR) is a complex task that retrieves images using\na query, which is configured with an image and a caption that describes desired\nmodifications to that image. Supervised CIR approaches have shown strong\nperformance, but their reliance on expensive manually-annotated datasets\nrestricts their scalability and broader applicability. To address these issues,\nprevious studies have proposed pseudo-word token-based Zero-Shot CIR (ZS-CIR)\nmethods, which utilize a projection module to map images to word tokens.\nHowever, we conjecture that this approach has a downside: the projection module\ndistorts the original image representation and confines the resulting composed\nembeddings to the text-side. In order to resolve this, we introduce a novel\nZS-CIR method that uses Spherical Linear Interpolation (Slerp) to directly\nmerge image and text representations by identifying an intermediate embedding\nof both. Furthermore, we introduce Text-Anchored-Tuning (TAT), a method that\nfine-tunes the image encoder while keeping the text encoder fixed. TAT closes\nthe modality gap between images and text, making the Slerp process much more\neffective. Notably, the TAT method is not only efficient in terms of the scale\nof the training dataset and training time, but it also serves as an excellent\ninitial checkpoint for training supervised CIR models, thereby highlighting its\nwider potential. The integration of the Slerp-based ZS-CIR with a TAT-tuned\nmodel enables our approach to deliver state-of-the-art retrieval performance\nacross CIR benchmarks.",
      "tldr_zh": "这篇论文针对Zero-Shot Composed Image Retrieval (ZS-CIR)提出了一种新方法，使用Spherical Linear Interpolation (Slerp)直接合并图像和文本表示，避免了传统投影模块对图像表示的扭曲。论文还引入Text-Anchored-Tuning (TAT)，通过微调图像编码器而固定文本编码器，缩小模态差距，并提升Slerp的效能。TAT不仅在数据集规模和训练时间上高效，还可作为监督CIR模型的初始检查点，最终使该方法在CIR基准上达到最先进检索性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00571v1",
      "published_date": "2024-05-01 15:19:54 UTC",
      "updated_date": "2024-05-01 15:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:06:38.608069"
    },
    {
      "arxiv_id": "2405.00570v1",
      "title": "WEST GCN-LSTM: Weighted Stacked Spatio-Temporal Graph Neural Networks for Regional Traffic Forecasting",
      "title_zh": "WEST GCN-LSTM：用于区域交通预测的加权堆叠时空",
      "authors": [
        "Theodoros Theodoropoulos",
        "Angelos-Christos Maroudis",
        "Antonios Makris",
        "Konstantinos Tserpes"
      ],
      "abstract": "Regional traffic forecasting is a critical challenge in urban mobility, with\napplications to various fields such as the Internet of Everything. In recent\nyears, spatio-temporal graph neural networks have achieved state-of-the-art\nresults in the context of numerous traffic forecasting challenges. This work\naims at expanding upon the conventional spatio-temporal graph neural network\narchitectures in a manner that may facilitate the inclusion of information\nregarding the examined regions, as well as the populations that traverse them,\nin order to establish a more efficient prediction model. The end-product of\nthis scientific endeavour is a novel spatio-temporal graph neural network\narchitecture that is referred to as WEST (WEighted STacked) GCN-LSTM.\nFurthermore, the inclusion of the aforementioned information is conducted via\nthe use of two novel dedicated algorithms that are referred to as the Shared\nBorders Policy and the Adjustable Hops Policy. Through information fusion and\ndistillation, the proposed solution manages to significantly outperform its\ncompetitors in the frame of an experimental evaluation that consists of 19\nforecasting models, across several datasets. Finally, an additional ablation\nstudy determined that each of the components of the proposed solution\ncontributes towards enhancing its overall performance.",
      "tldr_zh": "该论文针对区域交通预测问题，提出了一种新型的加权堆叠时空图神经网络（spatio-temporal graph neural networks）架构，名为 WEST GCN-LSTM，以整合区域信息和人口流动数据，从而提升预测效率。论文引入了两个创新算法：Shared Borders Policy 和 Adjustable Hops Policy，用于处理信息融合和提炼。实验结果显示，该模型在多个数据集上与19个竞争模型相比，显著提高了预测性能；此外，ablation study 证实了每个组件对整体表现的积极贡献。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00570v1",
      "published_date": "2024-05-01 15:19:19 UTC",
      "updated_date": "2024-05-01 15:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:06:49.456943"
    },
    {
      "arxiv_id": "2405.00568v2",
      "title": "Powering In-Database Dynamic Model Slicing for Structured Data Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Lingze Zeng",
        "Naili Xing",
        "Shaofeng Cai",
        "Gang Chen",
        "Beng Chin Ooi",
        "Jian Pei",
        "Yuncheng Wu"
      ],
      "abstract": "Relational database management systems (RDBMS) are widely used for the\nstorage of structured data. To derive insights beyond statistical aggregation,\nwe typically have to extract specific subdatasets from the database using\nconventional database operations, and then apply deep neural networks (DNN)\ntraining and inference on these subdatasets in a separate analytics system. The\nprocess can be prohibitively expensive, especially when there are various\nsubdatasets extracted for different analytical purposes. This calls for\nefficient in-database support of advanced analytical methods.\n  In this paper, we introduce LEADS, a novel SQL-aware dynamic model slicing\ntechnique to customize models for specified SQL queries. LEADS improves the\npredictive modeling of structured data via the mixture of experts (MoE) and\nmaintains efficiency by a SQL-aware gating network. At the core of LEADS is the\nconstruction of a general model with multiple expert sub-models trained over\nthe database. The MoE scales up the modeling capacity, enhances effectiveness,\nand preserves efficiency by activating necessary experts via the SQL-aware\ngating network during inference. To support in-database analytics, we build an\ninference extension that integrates LEADS onto PostgreSQL. Our extensive\nexperiments on real-world datasets demonstrate that LEADS consistently\noutperforms the baseline models, and the in-database inference extension\ndelivers a considerable reduction in inference latency compared to traditional\nsolutions.",
      "tldr_zh": "这篇论文针对关系数据库管理系统 (RDBMS) 中结构化数据分析的低效问题，提出了一种新型的 SQL-aware 动态模型切片技术 LEADS，以减少从数据库提取子数据集并在外部系统上运行深度神经网络 (DNN) 的开销。LEADS 通过混合专家 (MoE) 构建一个通用模型，包含多个专家子模型，并在 SQL-aware gating network 的支持下，仅激活必要的专家进行推理，从而提升预测建模的效率和效果。在真实数据集上的实验表明，LEADS 比基线模型表现更优，并在 PostgreSQL 的数据库内推理扩展中实现了显著的推理延迟减少。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "VLDB 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.00568v2",
      "published_date": "2024-05-01 15:18:12 UTC",
      "updated_date": "2024-11-03 08:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:07:03.253128"
    },
    {
      "arxiv_id": "2405.00557v4",
      "title": "Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Zhili Liu",
        "Yunhao Gou",
        "Kai Chen",
        "Lanqing Hong",
        "Jiahui Gao",
        "Fei Mi",
        "Yu Zhang",
        "Zhenguo Li",
        "Xin Jiang",
        "Qun Liu",
        "James T. Kwok"
      ],
      "abstract": "As the capabilities of large language models (LLMs) continue to expand,\naligning these models with human values remains a significant challenge. Recent\nstudies show that reasoning abilities contribute significantly to model safety,\nwhile integrating Mixture-of-Experts (MoE) architectures can further enhance\nalignment. In this work, we propose Mixture of insighTful Experts (MoTE), a\nnovel framework that synergistically combines reasoning chains and expert\nmixtures to improve self-alignments. From a data perspective, MoTE employs a\nstructured reasoning chain comprising four key stages: Question Analysis,\nAnswer Guidance, Safe Answer, and Safety Checking. This approach enhances\nsafety through multi-step reasoning and proves effective even for smaller and\nless powerful LLMs (e.g., 7B models). From an architectural perspective, MoTE\nadopts a multi-LoRA framework with step-level routing, where each expert is\ndedicated to a specific reasoning step. This design eliminates the need for\nbalance losses, ensures stable training, and supports adaptive inference\nlengths. Experimental results demonstrate that MoTE significantly improves\nmodel safety, jailbreak resistance, and over-refusal capabilities, achieving\nperformance comparable to OpenAI's state-of-the-art o1 model.",
      "tldr_zh": "该研究提出了一种名为 Mixture of insighTful Experts (MoTE) 的框架，将 Chain-of-Thought 推理链与 Mixture-of-Experts (MoE) 架构相结合，以提升大型语言模型 (LLMs) 的自我对齐 (self-alignment)。MoTE 从数据角度采用一个结构化的推理链，包括 Question Analysis、Answer Guidance、Safe Answer 和 Safety Checking 等四个阶段，通过多步推理增强模型安全性，并适用于较小的 LLMs（如 7B 模型）。从架构角度，它使用多-LoRA 框架和步级路由 (step-level routing)，每个专家专注于特定推理步骤，从而避免平衡损失、确保训练稳定并支持自适应推理长度。实验结果显示，MoTE 显著提高了模型的安全性、抗越狱 (jailbreak resistance) 能力和减少过度拒绝 (over-refusal)，其性能可与 OpenAI 的 o1 模型相媲美。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00557v4",
      "published_date": "2024-05-01 15:06:05 UTC",
      "updated_date": "2025-02-19 02:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:07:15.649561"
    },
    {
      "arxiv_id": "2405.00543v1",
      "title": "New Benchmark Dataset and Fine-Grained Cross-Modal Fusion Framework for Vietnamese Multimodal Aspect-Category Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Quy Hoang Nguyen",
        "Minh-Van Truong Nguyen",
        "Kiet Van Nguyen"
      ],
      "abstract": "The emergence of multimodal data on social media platforms presents new\nopportunities to better understand user sentiments toward a given aspect.\nHowever, existing multimodal datasets for Aspect-Category Sentiment Analysis\n(ACSA) often focus on textual annotations, neglecting fine-grained information\nin images. Consequently, these datasets fail to fully exploit the richness\ninherent in multimodal. To address this, we introduce a new Vietnamese\nmultimodal dataset, named ViMACSA, which consists of 4,876 text-image pairs\nwith 14,618 fine-grained annotations for both text and image in the hotel\ndomain. Additionally, we propose a Fine-Grained Cross-Modal Fusion Framework\n(FCMF) that effectively learns both intra- and inter-modality interactions and\nthen fuses these information to produce a unified multimodal representation.\nExperimental results show that our framework outperforms SOTA models on the\nViMACSA dataset, achieving the highest F1 score of 79.73%. We also explore\ncharacteristics and challenges in Vietnamese multimodal sentiment analysis,\nincluding misspellings, abbreviations, and the complexities of the Vietnamese\nlanguage. This work contributes both a benchmark dataset and a new framework\nthat leverages fine-grained multimodal information to improve multimodal\naspect-category sentiment analysis. Our dataset is available for research\npurposes:\nhttps://github.com/hoangquy18/Multimodal-Aspect-Category-Sentiment-Analysis.",
      "tldr_zh": "这篇论文引入了一个新的越南语多模态数据集ViMACSA，包含4,876对文本-图像对和14,618个细粒度标注，专注于酒店领域的Aspect-Category Sentiment Analysis (ACSA)，以更好地利用图像中的信息。论文提出Fine-Grained Cross-Modal Fusion Framework (FCMF)，通过学习intra- and inter-modality interactions并融合这些信息，生成统一的 multimodal 表示。实验结果显示，FCMF在ViMACSA数据集上比SOTA模型表现更优，F1分数达到79.73%，并探讨了越南语的拼写错误、缩写和语言复杂性等挑战，为多模态情感分析提供了新基准和框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00543v1",
      "published_date": "2024-05-01 14:29:03 UTC",
      "updated_date": "2024-05-01 14:29:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:07:29.778705"
    },
    {
      "arxiv_id": "2405.00532v3",
      "title": "ULLER: A Unified Language for Learning and Reasoning",
      "title_zh": "ULLER：用于学习和推理的统一语言",
      "authors": [
        "Emile van Krieken",
        "Samy Badreddine",
        "Robin Manhaeve",
        "Eleonora Giunchiglia"
      ],
      "abstract": "The field of neuro-symbolic artificial intelligence (NeSy), which combines\nlearning and reasoning, has recently experienced significant growth. There now\nare a wide variety of NeSy frameworks, each with its own specific language for\nexpressing background knowledge and how to relate it to neural networks. This\nheterogeneity hinders accessibility for newcomers and makes comparing different\nNeSy frameworks challenging. We propose a unified language for NeSy, which we\ncall ULLER, a Unified Language for LEarning and Reasoning. ULLER encompasses a\nwide variety of settings, while ensuring that knowledge described in it can be\nused in existing NeSy systems. ULLER has a neuro-symbolic first-order syntax\nfor which we provide example semantics including classical, fuzzy, and\nprobabilistic logics. We believe ULLER is a first step towards making NeSy\nresearch more accessible and comparable, paving the way for libraries that\nstreamline training and evaluation across a multitude of semantics, knowledge\nbases, and NeSy systems.",
      "tldr_zh": "该研究针对神经符号人工智能（NeSy）领域的框架多样性和语言异质性问题，提出了一种统一语言ULLER（A Unified Language for Learning and Reasoning），旨在简化背景知识的表达并将其与神经网络关联。ULLER采用神经符号一阶语法（neuro-symbolic first-order syntax），并提供多种语义支持，包括经典逻辑（classical logics）、模糊逻辑（fuzzy logics）和概率逻辑（probabilistic logics），以确保其兼容现有NeSy系统。最终，ULLER有望提升NeSy研究的可访问性和可比性，促进跨多种语义、知识库和系统的训练与评估库开发。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Pre-review version. Final version accepted at NeSy 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00532v3",
      "published_date": "2024-05-01 14:05:52 UTC",
      "updated_date": "2024-07-03 06:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:07:40.694173"
    },
    {
      "arxiv_id": "2405.00523v1",
      "title": "CookingSense: A Culinary Knowledgebase with Multidisciplinary Assertions",
      "title_zh": "翻译失败",
      "authors": [
        "Donghee Choi",
        "Mogan Gim",
        "Donghyeon Park",
        "Mujeen Sung",
        "Hyunjae Kim",
        "Jaewoo Kang",
        "Jihun Choi"
      ],
      "abstract": "This paper introduces CookingSense, a descriptive collection of knowledge\nassertions in the culinary domain extracted from various sources, including web\ndata, scientific papers, and recipes, from which knowledge covering a broad\nrange of aspects is acquired. CookingSense is constructed through a series of\ndictionary-based filtering and language model-based semantic filtering\ntechniques, which results in a rich knowledgebase of multidisciplinary\nfood-related assertions. Additionally, we present FoodBench, a novel benchmark\nto evaluate culinary decision support systems. From evaluations with FoodBench,\nwe empirically prove that CookingSense improves the performance of retrieval\naugmented language models. We also validate the quality and variety of\nassertions in CookingSense through qualitative analysis.",
      "tldr_zh": "本论文引入了 CookingSense，这是一个从网络数据、科学论文和食谱中提取的多学科烹饪知识断言库，涵盖广泛的食物相关方面。知识库通过字典-based 过滤和语言模型-based 语义过滤技术构建，确保了断言的丰富性和准确性。同时，论文提出了 FoodBench，一个新的基准，用于评估烹饪决策支持系统。实验结果显示，CookingSense 显著提升了检索 augmented language models 的性能，并通过定性分析验证了其断言的质量和多样性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "LREC-COLING 2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2405.00523v1",
      "published_date": "2024-05-01 13:58:09 UTC",
      "updated_date": "2024-05-01 13:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:07:53.318891"
    },
    {
      "arxiv_id": "2405.00516v1",
      "title": "Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas-Andreï Thil",
        "Mirela Popa",
        "Gerasimos Spanakis"
      ],
      "abstract": "Recent advancements in language models have demonstrated remarkable\nimprovements in various natural language processing (NLP) tasks such as web\nnavigation. Supervised learning (SL) approaches have achieved impressive\nperformance while utilizing significantly less training data compared to\nprevious methods. However, these SL-based models fall short when compared to\nreinforcement learning (RL) approaches, which have shown superior results. In\nthis paper, we propose a novel approach that combines SL and RL techniques over\nthe MiniWoB benchmark to leverage the strengths of both methods. We also\naddress a critical limitation in previous models' understanding of HTML\ncontent, revealing a tendency to memorize target elements rather than\ncomprehend the underlying structure. To rectify this, we propose methods to\nenhance true understanding and present a new baseline of results. Our\nexperiments demonstrate that our approach outperforms previous SL methods on\ncertain tasks using less data and narrows the performance gap with RL models,\nachieving 43.58\\% average accuracy in SL and 36.69\\% when combined with a\nmultimodal RL approach. This study sets a new direction for future web\nnavigation and offers insights into the limitations and potential of language\nmodeling for computer tasks.",
      "tldr_zh": "该研究探讨了使用大型语言模型（Large Language Models）和强化学习（Reinforcement Learning）训练代理完成网页任务的问题。作者提出了一种结合监督学习（Supervised Learning, SL）和强化学习（RL）的新方法，在MiniWoB基准上测试，以解决现有模型对HTML内容的理解局限性，即倾向于记忆元素而非理解结构。实验结果显示，该方法在使用更少数据的情况下，在某些任务上超过了之前的SL模型，并缩小了与RL模型的性能差距，SL平均准确率达到43.58%，结合多模态RL后为36.69%。这项工作为未来的网页导航研究提供了新方向，并揭示了语言模型在计算机任务中的潜力与挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "68T07",
        "I.2.7; I.2.8; I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "ACM 2024, Avila Spain. 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.00516v1",
      "published_date": "2024-05-01 13:51:45 UTC",
      "updated_date": "2024-05-01 13:51:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:08:06.585783"
    },
    {
      "arxiv_id": "2405.00494v1",
      "title": "GOLD: Geometry Problem Solver with Natural Language Description",
      "title_zh": "GOLD：带有自然语言描述的几何问题求解器",
      "authors": [
        "Jiaxin Zhang",
        "Yashar Moshfeghi"
      ],
      "abstract": "Addressing the challenge of automated geometry math problem-solving in\nartificial intelligence (AI) involves understanding multi-modal information and\nmathematics. Current methods struggle with accurately interpreting geometry\ndiagrams, which hinders effective problem-solving. To tackle this issue, we\npresent the Geometry problem sOlver with natural Language Description (GOLD)\nmodel. GOLD enhances the extraction of geometric relations by separately\nprocessing symbols and geometric primitives within the diagram. Subsequently,\nit converts the extracted relations into natural language descriptions,\nefficiently utilizing large language models to solve geometry math problems.\nExperiments show that the GOLD model outperforms the Geoformer model, the\nprevious best method on the UniGeo dataset, by achieving accuracy improvements\nof 12.7% and 42.1% in calculation and proving subsets. Additionally, it\nsurpasses the former best model on the PGPS9K and Geometry3K datasets, PGPSNet,\nby obtaining accuracy enhancements of 1.8% and 3.2%, respectively.",
      "tldr_zh": "本论文提出GOLD模型，用于处理几何数学问题的自动求解，旨在解决当前方法在解读几何图形时的准确性不足问题。GOLD通过单独提取图中的符号和几何基元，转化为自然语言描述，然后利用大语言模型进行高效问题求解。该模型在UniGeo数据集上比Geoformer模型的计算和证明子集准确率分别提升12.7%和42.1%；在PGPS9K和Geometry3K数据集上，也分别超过PGPSNet模型1.8%和3.2%的准确率，展示了其在多模态几何问题解决中的显著优势。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in NAACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2405.00494v1",
      "published_date": "2024-05-01 13:00:51 UTC",
      "updated_date": "2024-05-01 13:00:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:08:14.870700"
    },
    {
      "arxiv_id": "2405.00492v1",
      "title": "Is Temperature the Creativity Parameter of Large Language Models?",
      "title_zh": "温度是否是大语言模型的创造性参数？",
      "authors": [
        "Max Peeperkorn",
        "Tom Kouwenhoven",
        "Dan Brown",
        "Anna Jordanous"
      ],
      "abstract": "Large language models (LLMs) are applied to all sorts of creative tasks, and\ntheir outputs vary from beautiful, to peculiar, to pastiche, into plain\nplagiarism. The temperature parameter of an LLM regulates the amount of\nrandomness, leading to more diverse outputs; therefore, it is often claimed to\nbe the creativity parameter. Here, we investigate this claim using a narrative\ngeneration task with a predetermined fixed context, model and prompt.\nSpecifically, we present an empirical analysis of the LLM output for different\ntemperature values using four necessary conditions for creativity in narrative\ngeneration: novelty, typicality, cohesion, and coherence. We find that\ntemperature is weakly correlated with novelty, and unsurprisingly, moderately\ncorrelated with incoherence, but there is no relationship with either cohesion\nor typicality. However, the influence of temperature on creativity is far more\nnuanced and weak than suggested by the \"creativity parameter\" claim; overall\nresults suggest that the LLM generates slightly more novel outputs as\ntemperatures get higher. Finally, we discuss ideas to allow more controlled LLM\ncreativity, rather than relying on chance via changing the temperature\nparameter.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs)中温度参数是否能作为创意参数，通过固定上下文的叙述生成任务进行实证分析。研究评估了温度对四个创意条件的影响：新颖性(novelty)、典型性(typicality)、连贯性(cohesion)和一致性(coherence)。结果显示，温度与新颖性弱相关，与不一致性中等相关，但与连贯性和典型性无显著关系，整体影响微妙且有限。作者建议开发更可控的LLM创意机制，而不是依赖温度参数的随机性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in the Proceedings of the 15th International\n  Conference on Computational Creativity (ICCC'24), 8 pages, 2 figures, 2\n  tables",
      "pdf_url": "http://arxiv.org/pdf/2405.00492v1",
      "published_date": "2024-05-01 12:59:37 UTC",
      "updated_date": "2024-05-01 12:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:08:28.494193"
    },
    {
      "arxiv_id": "2405.00468v2",
      "title": "Feature-Aware Noise Contrastive Learning for Unsupervised Red Panda Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Jincheng Zhang",
        "Qijun Zhao",
        "Tie Liu"
      ],
      "abstract": "To facilitate the re-identification (re-ID) of individual animals, existing\nmethods primarily focus on maximizing feature similarity within the same\nindividual and enhancing distinctiveness between different individuals.\nHowever, most of them still rely on supervised learning and require substantial\nlabeled data, which is challenging to obtain. To avoid this issue, we propose\nFeature-Aware Noise Contrastive Learning (FANCL) method to explore an\nunsupervised learning solution, which is then validated on the task of red\npanda re-ID. FANCL designs a Feature-Aware Noise Addition module to produce\nnoised images that conceal critical features, and employs two contrastive\nlearning modules to calculate the losses. Firstly, a feature consistency module\nis designed to bridge the gap between the original and noised features.\nSecondly, the neural networks are trained through a cluster contrastive\nlearning module. Through these more challenging learning tasks, FANCL can\nadaptively extract deeper representations of red pandas. The experimental\nresults on a set of red panda images collected in both indoor and outdoor\nenvironments prove that FANCL outperforms several related state-of-the-art\nunsupervised methods, achieving high performance comparable to supervised\nlearning methods.",
      "tldr_zh": "这篇论文提出了一种无监督学习方法 Feature-Aware Noise Contrastive Learning (FANCL)，用于红熊猫再识别 (re-ID)，以解决传统方法依赖大量标注数据的局限性。FANCL 包括 Feature-Aware Noise Addition 模块生成隐藏关键特征的噪声图像，以及两个对比学习模块：特征一致性模块用于桥接原始和噪声特征的差距，集群对比学习模块用于训练神经网络提取更深层表示。通过这些机制，FANCL 在室内和室外红熊猫图像数据集上超过了现有无监督方法，并取得了与监督学习方法相当的高性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00468v2",
      "published_date": "2024-05-01 12:08:38 UTC",
      "updated_date": "2024-07-18 06:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:08:41.395986"
    },
    {
      "arxiv_id": "2405.00461v1",
      "title": "Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning",
      "title_zh": "通过具身智能增强手术机器人以实现自主超声扫描",
      "authors": [
        "Huan Xu",
        "Jinlin Wu",
        "Guanglin Cao",
        "Zhen Lei",
        "Zhen Chen",
        "Hongbin Liu"
      ],
      "abstract": "Ultrasound robots are increasingly used in medical diagnostics and early\ndisease screening. However, current ultrasound robots lack the intelligence to\nunderstand human intentions and instructions, hindering autonomous ultrasound\nscanning. To solve this problem, we propose a novel Ultrasound Embodied\nIntelligence system that equips ultrasound robots with the large language model\n(LLM) and domain knowledge, thereby improving the efficiency of ultrasound\nrobots. Specifically, we first design an ultrasound operation knowledge\ndatabase to add expertise in ultrasound scanning to the LLM, enabling the LLM\nto perform precise motion planning. Furthermore, we devise a dynamic ultrasound\nscanning strategy based on a \\textit{think-observe-execute} prompt engineering,\nallowing LLMs to dynamically adjust motion planning strategies during the\nscanning procedures. Extensive experiments demonstrate that our system\nsignificantly improves ultrasound scan efficiency and quality from verbal\ncommands. This advancement in autonomous medical scanning technology\ncontributes to non-invasive diagnostics and streamlined medical workflows.",
      "tldr_zh": "本文提出Ultrasound Embodied Intelligence系统，使用大型语言模型(LLM)和领域知识来提升超声机器人的自主扫描能力，解决其理解人类意图的不足问题。具体而言，该系统构建了超声操作知识数据库以支持精确的运动规划，并采用基于think-observe-execute提示工程的动态扫描策略，允许LLM在扫描过程中实时调整策略。实验结果表明，该系统显著提高了从口头命令的超声扫描效率和质量，为非侵入性诊断和简化医疗工作流程提供了重要贡献。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "3 pages, 1 figure, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.00461v1",
      "published_date": "2024-05-01 11:39:38 UTC",
      "updated_date": "2024-05-01 11:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:08:52.370172"
    },
    {
      "arxiv_id": "2405.00456v1",
      "title": "Counterfactual Explanations for Deep Learning-Based Traffic Forecasting",
      "title_zh": "基于深度学习的交通预测的反事实解释",
      "authors": [
        "Rushan Wang",
        "Yanan Xin",
        "Yatao Zhang",
        "Fernando Perez-Cruz",
        "Martin Raubal"
      ],
      "abstract": "Deep learning models are widely used in traffic forecasting and have achieved\nstate-of-the-art prediction accuracy. However, the black-box nature of those\nmodels makes the results difficult to interpret by users. This study aims to\nleverage an Explainable AI approach, counterfactual explanations, to enhance\nthe explainability and usability of deep learning-based traffic forecasting\nmodels. Specifically, the goal is to elucidate relationships between various\ninput contextual features and their corresponding predictions. We present a\ncomprehensive framework that generates counterfactual explanations for traffic\nforecasting and provides usable insights through the proposed scenario-driven\ncounterfactual explanations. The study first implements a deep learning model\nto predict traffic speed based on historical traffic data and contextual\nvariables. Counterfactual explanations are then used to illuminate how\nalterations in these input variables affect predicted outcomes, thereby\nenhancing the transparency of the deep learning model. We investigated the\nimpact of contextual features on traffic speed prediction under varying spatial\nand temporal conditions. The scenario-driven counterfactual explanations\nintegrate two types of user-defined constraints, directional and weighting\nconstraints, to tailor the search for counterfactual explanations to specific\nuse cases. These tailored explanations benefit machine learning practitioners\nwho aim to understand the model's learning mechanisms and domain experts who\nseek insights for real-world applications. The results showcase the\neffectiveness of counterfactual explanations in revealing traffic patterns\nlearned by deep learning models, showing its potential for interpreting\nblack-box deep learning models used for spatiotemporal predictions in general.",
      "tldr_zh": "这篇论文针对基于Deep Learning的交通预测模型的黑盒问题，提出利用Counterfactual Explanations来提升模型的可解释性和可用性。研究构建了一个综合框架，通过生成反事实解释来阐明输入特征（如历史交通数据和上下文变量）如何影响预测结果，并引入directional和weighting约束来定制场景驱动的解释，以适应特定应用场景。实验结果表明，该方法在不同空间和时间条件下有效揭示了交通模式，提升了模型透明度，并为机器学习从业者和领域专家提供实际洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.00456v1",
      "published_date": "2024-05-01 11:26:31 UTC",
      "updated_date": "2024-05-01 11:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:09:05.669027"
    },
    {
      "arxiv_id": "2405.00453v1",
      "title": "Fuzzy Intelligent System for Student Software Project Evaluation",
      "title_zh": "学生软件项目评估的模糊智能系统",
      "authors": [
        "Anna Ogorodova",
        "Pakizar Shamoi",
        "Aron Karatayev"
      ],
      "abstract": "Developing software projects allows students to put knowledge into practice\nand gain teamwork skills. However, assessing student performance in\nproject-oriented courses poses significant challenges, particularly as the size\nof classes increases. The current paper introduces a fuzzy intelligent system\ndesigned to evaluate academic software projects using object-oriented\nprogramming and design course as an example. To establish evaluation criteria,\nwe first conducted a survey of student project teams (n=31) and faculty (n=3)\nto identify key parameters and their applicable ranges. The selected criteria -\nclean code, use of inheritance, and functionality - were selected as essential\nfor assessing the quality of academic software projects. These criteria were\nthen represented as fuzzy variables with corresponding fuzzy sets.\nCollaborating with three experts, including one professor and two course\ninstructors, we defined a set of fuzzy rules for a fuzzy inference system. This\nsystem processes the input criteria to produce a quantifiable measure of\nproject success. The system demonstrated promising results in automating the\nevaluation of projects. Our approach standardizes project evaluations and helps\nto reduce the subjective bias in manual grading.",
      "tldr_zh": "本文提出了一种模糊智能系统（fuzzy intelligent system），用于评估学生软件项目，以面向对象编程和设计课程为例，解决评估过程中的主观性和规模挑战。研究团队通过对31个学生项目团队和3位教师的调查，确定了关键评估标准，包括clean code、use of inheritance和functionality，并将这些标准转化为模糊变量（fuzzy variables）和模糊集（fuzzy sets）。随后，与专家合作定义模糊规则（fuzzy rules）和模糊推理系统（fuzzy inference system），实现了对项目成功的量化评估，展示了自动化评估的优势，并有助于标准化评分并减少主观偏差。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "Submitted to IJMECS for consideration",
      "pdf_url": "http://arxiv.org/pdf/2405.00453v1",
      "published_date": "2024-05-01 11:12:22 UTC",
      "updated_date": "2024-05-01 11:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:09:16.061786"
    },
    {
      "arxiv_id": "2405.00451v2",
      "title": "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning",
      "title_zh": "Monte Carlo Tree Search 通过迭代偏好学习提升推理",
      "authors": [
        "Yuxi Xie",
        "Anirudh Goyal",
        "Wenyue Zheng",
        "Min-Yen Kan",
        "Timothy P. Lillicrap",
        "Kenji Kawaguchi",
        "Michael Shieh"
      ],
      "abstract": "We introduce an approach aimed at enhancing the reasoning capabilities of\nLarge Language Models (LLMs) through an iterative preference learning process\ninspired by the successful strategy employed by AlphaZero. Our work leverages\nMonte Carlo Tree Search (MCTS) to iteratively collect preference data,\nutilizing its look-ahead ability to break down instance-level rewards into more\ngranular step-level signals. To enhance consistency in intermediate steps, we\ncombine outcome validation and stepwise self-evaluation, continually updating\nthe quality assessment of newly generated data. The proposed algorithm employs\nDirect Preference Optimization (DPO) to update the LLM policy using this newly\ngenerated step-level preference data. Theoretical analysis reveals the\nimportance of using on-policy sampled data for successful self-improving.\nExtensive evaluations on various arithmetic and commonsense reasoning tasks\ndemonstrate remarkable performance improvements over existing models. For\ninstance, our approach outperforms the Mistral-7B Supervised Fine-Tuning (SFT)\nbaseline on GSM8K, MATH, and ARC-C, with substantial increases in accuracy to\n$81.8\\%$ (+$5.9\\%$), $34.7\\%$ (+$5.8\\%$), and $76.4\\%$ (+$15.8\\%$),\nrespectively. Additionally, our research delves into the training and inference\ncompute tradeoff, providing insights into how our method effectively maximizes\nperformance gains. Our code is publicly available at\nhttps://github.com/YuxiXie/MCTS-DPO.",
      "tldr_zh": "本研究提出了一种基于 Monte Carlo Tree Search (MCTS) 的迭代偏好学习方法，以提升 Large Language Models (LLMs) 的推理能力，该方法借鉴 AlphaZero 的策略，通过 MCTS 的前瞻能力将实例级奖励分解为步骤级信号，并结合结果验证和逐步自我评估来收集偏好数据。利用 Direct Preference Optimization (DPO) 更新 LLM 策略，理论分析强调使用 on-policy 采样数据的必要性，以实现模型的自提升。在算术和常识推理任务（如 GSM8K、MATH 和 ARC-C）上的实验显示，该方法显著提高了准确率，分别达到 81.8%（+5.9%）、34.7%（+5.8%）和 76.4%（+15.8%），并探讨了训练和推理计算的权衡，提供性能优化见解。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, 4 tables (24 pages, 9 figures, 9 tables\n  including references and appendices)",
      "pdf_url": "http://arxiv.org/pdf/2405.00451v2",
      "published_date": "2024-05-01 11:10:24 UTC",
      "updated_date": "2024-06-17 22:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:09:29.894268"
    },
    {
      "arxiv_id": "2405.00449v1",
      "title": "RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Manzour Hussien",
        "Angie Nataly Melo",
        "Augusto Luis Ballardini",
        "Carlota Salinas Maldonado",
        "Rubén Izquierdo",
        "Miguel Ángel Sotelo"
      ],
      "abstract": "Prediction of road users' behaviors in the context of autonomous driving has\ngained considerable attention by the scientific community in the last years.\nMost works focus on predicting behaviors based on kinematic information alone,\na simplification of the reality since road users are humans, and as such they\nare highly influenced by their surrounding context. In addition, a large\nplethora of research works rely on powerful Deep Learning techniques, which\nexhibit high performance metrics in prediction tasks but may lack the ability\nto fully understand and exploit the contextual semantic information contained\nin the road scene, not to mention their inability to provide explainable\npredictions that can be understood by humans. In this work, we propose an\nexplainable road users' behavior prediction system that integrates the\nreasoning abilities of Knowledge Graphs (KG) and the expressiveness\ncapabilities of Large Language Models (LLM) by using Retrieval Augmented\nGeneration (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE)\nand Bayesian inference are combined to allow the deployment of a fully\ninductive reasoning system that enables the issuing of predictions that rely on\nlegacy information contained in the graph as well as on current evidence\ngathered in real time by onboard sensors. Two use cases have been implemented\nfollowing the proposed approach: 1) Prediction of pedestrians' crossing\nactions; 2) Prediction of lane change maneuvers. In both cases, the performance\nattained surpasses the current state of the art in terms of anticipation and\nF1-score, showing a promising avenue for future research in this field.",
      "tldr_zh": "这篇论文提出了一种基于 Retrieval Augmented Generation (RAG) 的可解释系统，用于预测自动驾驶中道路用户行为，结合 Knowledge Graphs (KG) 和 Large Language Models (LLM)，以解决传统方法忽略上下文语义和缺乏解释性的问题。系统通过 Knowledge Graph Embeddings (KGE) 和 Bayesian inference 实现全归纳推理，利用 KG 中的历史信息与实时传感器数据进行预测。实验在两个用例中验证了该方法，包括预测行人的过马路行为和变道 maneuvers，其性能在预见性和 F1-score 上超过了现有技术，为自动驾驶领域提供了更可靠的研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00449v1",
      "published_date": "2024-05-01 11:06:31 UTC",
      "updated_date": "2024-05-01 11:06:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:09:41.321079"
    },
    {
      "arxiv_id": "2405.00442v1",
      "title": "Geometric Insights into Focal Loss: Reducing Curvature for Enhanced Model Calibration",
      "title_zh": "焦点损失的几何洞见：减少曲率以提升模型校准",
      "authors": [
        "Masanari Kimura",
        "Hiroki Naganuma"
      ],
      "abstract": "The key factor in implementing machine learning algorithms in decision-making\nsituations is not only the accuracy of the model but also its confidence level.\nThe confidence level of a model in a classification problem is often given by\nthe output vector of a softmax function for convenience. However, these values\nare known to deviate significantly from the actual expected model confidence.\nThis problem is called model calibration and has been studied extensively. One\nof the simplest techniques to tackle this task is focal loss, a generalization\nof cross-entropy by introducing one positive parameter. Although many related\nstudies exist because of the simplicity of the idea and its formalization, the\ntheoretical analysis of its behavior is still insufficient. In this study, our\nobjective is to understand the behavior of focal loss by reinterpreting this\nfunction geometrically. Our analysis suggests that focal loss reduces the\ncurvature of the loss surface in training the model. This indicates that\ncurvature may be one of the essential factors in achieving model calibration.\nWe design numerical experiments to support this conjecture to reveal the\nbehavior of focal loss and the relationship between calibration performance and\ncurvature.",
      "tldr_zh": "该论文探讨了机器学习模型校准（model calibration）问题，强调不仅需要模型准确性，还需确保 softmax 输出置信度与实际相符。研究从几何视角重新解释 focal loss（一种 cross-entropy 的推广），发现它通过减少损失函数表面的曲率（curvature）来提升模型校准性能。数值实验进一步验证了曲率与校准性能之间的关系，为理解 focal loss 的行为提供了新见解。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "This paper is under consideration at Pattern Recognition Letters",
      "pdf_url": "http://arxiv.org/pdf/2405.00442v1",
      "published_date": "2024-05-01 10:53:54 UTC",
      "updated_date": "2024-05-01 10:53:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:09:51.646703"
    },
    {
      "arxiv_id": "2405.00433v1",
      "title": "Weight Sparsity Complements Activity Sparsity in Neuromorphic Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rishav Mukherji",
        "Mark Schöne",
        "Khaleelulla Khan Nazeer",
        "Christian Mayr",
        "David Kappel",
        "Anand Subramoney"
      ],
      "abstract": "Activity and parameter sparsity are two standard methods of making neural\nnetworks computationally more efficient. Event-based architectures such as\nspiking neural networks (SNNs) naturally exhibit activity sparsity, and many\nmethods exist to sparsify their connectivity by pruning weights. While the\neffect of weight pruning on feed-forward SNNs has been previously studied for\ncomputer vision tasks, the effects of pruning for complex sequence tasks like\nlanguage modeling are less well studied since SNNs have traditionally struggled\nto achieve meaningful performance on these tasks. Using a recently published\nSNN-like architecture that works well on small-scale language modeling, we\nstudy the effects of weight pruning when combined with activity sparsity.\nSpecifically, we study the trade-off between the multiplicative efficiency\ngains the combination affords and its effect on task performance for language\nmodeling. To dissect the effects of the two sparsities, we conduct a\ncomparative analysis between densely activated models and sparsely activated\nevent-based models across varying degrees of connectivity sparsity. We\ndemonstrate that sparse activity and sparse connectivity complement each other\nwithout a proportional drop in task performance for an event-based neural\nnetwork trained on the Penn Treebank and WikiText-2 language modeling datasets.\nOur results suggest sparsely connected event-based neural networks are\npromising candidates for effective and efficient sequence modeling.",
      "tldr_zh": "这篇论文探讨了在神经形态语言模型中，weight sparsity（权重稀疏性）如何与activity sparsity（活动稀疏性）互补，以提升计算效率。研究者使用一个在小规模language modeling任务上表现良好的SNN-like架构，进行了权重修剪实验，并比较了密集激活模型和稀疏激活事件模型在不同连接稀疏度下的性能。结果显示，二者结合在Penn Treebank和WikiText-2数据集上训练的事件神经网络中，能显著提高效率，而不会导致成比例的任务性能下降。该发现表明，sparsely connected event-based neural networks是高效序列建模的有前景候选。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2311.07625",
      "pdf_url": "http://arxiv.org/pdf/2405.00433v1",
      "published_date": "2024-05-01 10:33:36 UTC",
      "updated_date": "2024-05-01 10:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:10:06.467042"
    },
    {
      "arxiv_id": "2405.00420v1",
      "title": "Self-supervised Pre-training of Text Recognizers",
      "title_zh": "自监督预训练的文本识别器",
      "authors": [
        "Martin Kišš",
        "Michal Hradiš"
      ],
      "abstract": "In this paper, we investigate self-supervised pre-training methods for\ndocument text recognition. Nowadays, large unlabeled datasets can be collected\nfor many research tasks, including text recognition, but it is costly to\nannotate them. Therefore, methods utilizing unlabeled data are researched. We\nstudy self-supervised pre-training methods based on masked label prediction\nusing three different approaches -- Feature Quantization, VQ-VAE, and\nPost-Quantized AE. We also investigate joint-embedding approaches with VICReg\nand NT-Xent objectives, for which we propose an image shifting technique to\nprevent model collapse where it relies solely on positional encoding while\ncompletely ignoring the input image. We perform our experiments on historical\nhandwritten (Bentham) and historical printed datasets mainly to investigate the\nbenefits of the self-supervised pre-training techniques with different amounts\nof annotated target domain data. We use transfer learning as strong baselines.\nThe evaluation shows that the self-supervised pre-training on data from the\ntarget domain is very effective, but it struggles to outperform transfer\nlearning from closely related domains. This paper is one of the first\nresearches exploring self-supervised pre-training in document text recognition,\nand we believe that it will become a cornerstone for future research in this\narea. We made our implementation of the investigated methods publicly available\nat https://github.com/DCGM/pero-pretraining.",
      "tldr_zh": "本论文探讨了自监督预训练(self-supervised pre-training)方法在文档文本识别中的应用，旨在利用大量未标注数据来降低标注成本。研究者评估了基于 masked label prediction 的三种方法——Feature Quantization、VQ-VAE 和 Post-Quantized AE，以及 joint-embedding 方法如 VICReg 和 NT-Xent，并提出图像移位技术以防止模型依赖位置编码而忽略输入图像。实验结果显示，在历史手写(Bentham)和历史印刷数据集上，自监督预训练在目标域数据上表现出色，但仍不如从相关域的转移学习(transfer learning)有效。该研究作为文档文本识别领域的前沿探索，为未来工作奠定了基础，并公开了代码实现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 6 figures, 4 tables, accepted to ICDAR24",
      "pdf_url": "http://arxiv.org/pdf/2405.00420v1",
      "published_date": "2024-05-01 09:58:57 UTC",
      "updated_date": "2024-05-01 09:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:10:17.938681"
    },
    {
      "arxiv_id": "2405.00418v1",
      "title": "Detection of ransomware attacks using federated learning based on the CNN model",
      "title_zh": "翻译失败",
      "authors": [
        "Hong-Nhung Nguyen",
        "Ha-Thanh Nguyen",
        "Damien Lescos"
      ],
      "abstract": "Computing is still under a significant threat from ransomware, which\nnecessitates prompt action to prevent it. Ransomware attacks can have a\nnegative impact on how smart grids, particularly digital substations. In\naddition to examining a ransomware detection method using artificial\nintelligence (AI), this paper offers a ransomware attack modeling technique\nthat targets the disrupted operation of a digital substation. The first, binary\ndata is transformed into image data and fed into the convolution neural network\nmodel using federated learning. The experimental findings demonstrate that the\nsuggested technique detects ransomware with a high accuracy rate.",
      "tldr_zh": "这篇论文针对勒索软件(ransomware)攻击对计算系统，尤其是智能电网和数字变电站的威胁，提出了一种基于人工智能(AI)的检测方法。研究首先将二进制数据转换为图像数据，然后使用联邦学习(federated learning)结合CNN模型进行训练和检测。实验结果表明，该方法实现了高准确率的勒索软件检测，为防范此类攻击提供了有效策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00418v1",
      "published_date": "2024-05-01 09:57:34 UTC",
      "updated_date": "2024-05-01 09:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:10:27.809879"
    },
    {
      "arxiv_id": "2405.00395v1",
      "title": "Trust Driven On-Demand Scheme for Client Deployment in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mario Chahoud",
        "Azzam Mourad",
        "Hadi Otrok",
        "Jamal Bentahar",
        "Mohsen Guizani"
      ],
      "abstract": "Containerization technology plays a crucial role in Federated Learning (FL)\nsetups, expanding the pool of potential clients and ensuring the availability\nof specific subsets for each learning iteration. However, doubts arise about\nthe trustworthiness of devices deployed as clients in FL scenarios, especially\nwhen container deployment processes are involved. Addressing these challenges\nis important, particularly in managing potentially malicious clients capable of\ndisrupting the learning process or compromising the entire model. In our\nresearch, we are motivated to integrate a trust element into the client\nselection and model deployment processes within our system architecture. This\nis a feature lacking in the initial client selection and deployment mechanism\nof the On-Demand architecture. We introduce a trust mechanism, named\n\"Trusted-On-Demand-FL\", which establishes a relationship of trust between the\nserver and the pool of eligible clients. Utilizing Docker in our deployment\nstrategy enables us to monitor and validate participant actions effectively,\nensuring strict adherence to agreed-upon protocols while strengthening defenses\nagainst unauthorized data access or tampering. Our simulations rely on a\ncontinuous user behavior dataset, deploying an optimization model powered by a\ngenetic algorithm to efficiently select clients for participation. By assigning\ntrust values to individual clients and dynamically adjusting these values,\ncombined with penalizing malicious clients through decreased trust scores, our\nproposed framework identifies and isolates harmful clients. This approach not\nonly reduces disruptions to regular rounds but also minimizes instances of\nround dismissal, Consequently enhancing both system stability and security.",
      "tldr_zh": "这篇论文针对联邦学习(Federated Learning)中客户端部署的信任问题，提出了一种名为Trusted-On-Demand-FL的方案，以应对潜在恶意客户端可能导致的模型破坏或数据篡改。方法包括整合信任机制，使用Docker监控和验证参与者行为，并结合遗传算法优化客户端选择，通过动态调整信任值和惩罚恶意行为来识别并隔离有害设备。实验模拟显示，该框架显著减少了系统中断和轮次取消，从而提升了整体稳定性和安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00395v1",
      "published_date": "2024-05-01 08:50:08 UTC",
      "updated_date": "2024-05-01 08:50:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:10:41.170813"
    },
    {
      "arxiv_id": "2405.00392v1",
      "title": "Certified Adversarial Robustness of Machine Learning-based Malware Detectors via (De)Randomized Smoothing",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Gibert",
        "Luca Demetrio",
        "Giulio Zizzo",
        "Quan Le",
        "Jordi Planes",
        "Battista Biggio"
      ],
      "abstract": "Deep learning-based malware detection systems are vulnerable to adversarial\nEXEmples - carefully-crafted malicious programs that evade detection with\nminimal perturbation. As such, the community is dedicating effort to develop\nmechanisms to defend against adversarial EXEmples. However, current randomized\nsmoothing-based defenses are still vulnerable to attacks that inject blocks of\nadversarial content. In this paper, we introduce a certifiable defense against\npatch attacks that guarantees, for a given executable and an adversarial patch\nsize, no adversarial EXEmple exist. Our method is inspired by (de)randomized\nsmoothing which provides deterministic robustness certificates. During\ntraining, a base classifier is trained using subsets of continguous bytes. At\ninference time, our defense splits the executable into non-overlapping chunks,\nclassifies each chunk independently, and computes the final prediction through\nmajority voting to minimize the influence of injected content. Furthermore, we\nintroduce a preprocessing step that fixes the size of the sections and headers\nto a multiple of the chunk size. As a consequence, the injected content is\nconfined to an integer number of chunks without tampering the other chunks\ncontaining the real bytes of the input examples, allowing us to extend our\ncertified robustness guarantees to content insertion attacks. We perform an\nextensive ablation study, by comparing our defense with randomized\nsmoothing-based defenses against a plethora of content manipulation attacks and\nneural network architectures. Results show that our method exhibits unmatched\nrobustness against strong content-insertion attacks, outperforming randomized\nsmoothing-based defenses in the literature.",
      "tldr_zh": "这篇论文提出了一种基于 (de)randomized smoothing 的可认证防御机制，以提升机器学习-based 恶意软件检测器的对抗鲁棒性，特别是针对 adversarial EXEmples 和 patch attacks，确保给定可执行文件和攻击大小下不存在有效攻击。方法包括使用连续字节子集训练基分类器，在推理时将文件分成非重叠块进行独立分类，并通过多数投票减少注入内容的影响，同时引入预处理步骤固定部分和头的大小，以扩展对内容插入攻击的认证保证。实验结果显示，该防御在多种内容操纵攻击和神经网络架构下表现出色，鲁棒性比现有 randomized smoothing-based 方法高出显著优势。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00392v1",
      "published_date": "2024-05-01 08:45:57 UTC",
      "updated_date": "2024-05-01 08:45:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:10:54.670816"
    },
    {
      "arxiv_id": "2407.10237v1",
      "title": "Towards Green AI: Current status and future research",
      "title_zh": "迈向绿色 AI：当前状态与未来研究",
      "authors": [
        "Christian Clemm",
        "Lutz Stobbe",
        "Kishan Wimalawarne",
        "Jan Druschke"
      ],
      "abstract": "The immense technological progress in artificial intelligence research and\napplications is increasingly drawing attention to the environmental\nsustainability of such systems, a field that has been termed Green AI. With\nthis contribution we aim to broaden the discourse on Green AI by investigating\nthe current status of approaches to both environmental assessment and ecodesign\nof AI systems. We propose a life-cycle-based system thinking approach that\naccounts for the four key elements of these software-hardware-systems: model,\ndata, server, and cloud. We conduct an exemplary estimation of the carbon\nfootprint of relevant compute hardware and highlight the need to further\ninvestigate methods for Green AI and ways to facilitate wide-spread adoption of\nits principles. We envision that AI could be leveraged to mitigate its own\nenvironmental challenges, which we denote as AI4greenAI.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）的环境可持续性领域，即Green AI，调查了当前的环境评估和生态设计方法现状。作者提出了一种基于生命周期的系统思考方法，涵盖AI系统的四个关键元素：模型、数据、服务器和云，并通过示例估计计算硬件的carbon footprint，以突出潜在环境影响。论文强调需要进一步研究Green AI的方法以促进广泛采用，并展望AI可用于缓解自身环境挑战的概念，称为AI4greenAI。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages, 4 figures, accepted for oral presentation at Electronics\n  Goes Green 2024 in June 2024, accepted for publication on IEEE Xplore via the\n  conference",
      "pdf_url": "http://arxiv.org/pdf/2407.10237v1",
      "published_date": "2024-05-01 08:10:01 UTC",
      "updated_date": "2024-05-01 08:10:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:11:03.856865"
    },
    {
      "arxiv_id": "2405.00367v1",
      "title": "Distance Sampling-based Paraphraser Leveraging ChatGPT for Text Data Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yoori Oh",
        "Yoseob Han",
        "Kyogu Lee"
      ],
      "abstract": "There has been growing interest in audio-language retrieval research, where\nthe objective is to establish the correlation between audio and text\nmodalities. However, most audio-text paired datasets often lack rich expression\nof the text data compared to the audio samples. One of the significant\nchallenges facing audio-text datasets is the presence of similar or identical\ncaptions despite different audio samples. Therefore, under many-to-one mapping\nconditions, audio-text datasets lead to poor performance of retrieval tasks. In\nthis paper, we propose a novel approach to tackle the data imbalance problem in\naudio-language retrieval task. To overcome the limitation, we introduce a\nmethod that employs a distance sampling-based paraphraser leveraging ChatGPT,\nutilizing distance function to generate a controllable distribution of\nmanipulated text data. For a set of sentences with the same context, the\ndistance is used to calculate a degree of manipulation for any two sentences,\nand ChatGPT's few-shot prompting is performed using a text cluster with a\nsimilar distance defined by the Jaccard similarity. Therefore, ChatGPT, when\napplied to few-shot prompting with text clusters, can adjust the diversity of\nthe manipulated text based on the distance. The proposed approach is shown to\nsignificantly enhance performance in audio-text retrieval, outperforming\nconventional text augmentation techniques.",
      "tldr_zh": "该论文针对音频-语言检索任务中数据不平衡问题（如多个音频样本共享相似或相同标题），提出了一种基于距离采样的改写器（distance sampling-based paraphraser），利用ChatGPT生成多样化的文本数据。该方法通过Jaccard相似度计算句子间的距离，进行文本聚类和few-shot prompting，从而实现对操纵文本的可控分布。实验结果表明，该方法显著提升了音频-文本检索性能，优于传统文本增强技术。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at SIGIR 2024 short paper track",
      "pdf_url": "http://arxiv.org/pdf/2405.00367v1",
      "published_date": "2024-05-01 07:44:28 UTC",
      "updated_date": "2024-05-01 07:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:11:16.113707"
    },
    {
      "arxiv_id": "2405.00358v1",
      "title": "Arbitrary Time Information Modeling via Polynomial Approximation for Temporal Knowledge Graph Embedding",
      "title_zh": "通过多项式逼近建模任意时间信息，用于时间知识图嵌入",
      "authors": [
        "Zhiyu Fang",
        "Jingyan Qin",
        "Xiaobin Zhu",
        "Chun Yang",
        "Xu-Cheng Yin"
      ],
      "abstract": "Distinguished from traditional knowledge graphs (KGs), temporal knowledge\ngraphs (TKGs) must explore and reason over temporally evolving facts\nadequately. However, existing TKG approaches still face two main challenges,\ni.e., the limited capability to model arbitrary timestamps continuously and the\nlack of rich inference patterns under temporal constraints. In this paper, we\npropose an innovative TKGE method (PTBox) via polynomial decomposition-based\ntemporal representation and box embedding-based entity representation to tackle\nthe above-mentioned problems. Specifically, we decompose time information by\npolynomials and then enhance the model's capability to represent arbitrary\ntimestamps flexibly by incorporating the learnable temporal basis tensor. In\naddition, we model every entity as a hyperrectangle box and define each\nrelation as a transformation on the head and tail entity boxes. The entity\nboxes can capture complex geometric structures and learn robust\nrepresentations, improving the model's inductive capability for rich inference\npatterns. Theoretically, our PTBox can encode arbitrary time information or\neven unseen timestamps while capturing rich inference patterns and higher-arity\nrelations of the knowledge base. Extensive experiments on real-world datasets\ndemonstrate the effectiveness of our method.",
      "tldr_zh": "本研究针对时间知识图谱（Temporal Knowledge Graphs, TKGs）中建模任意时间戳和缺乏丰富推理模式的挑战，提出了一种创新方法PTBox。PTBox通过多项式分解（Polynomial Approximation）来表示时间信息，并引入可学习的temporal basis tensor，以灵活捕捉连续的任意时间戳或未见时间戳。同时，将实体建模为hyperrectangle box，并定义关系为实体盒子的变换，从而支持复杂的几何结构和丰富的推理模式。实验在真实数据集上验证了PTBox的有效性，显著提升了模型的归纳能力和整体性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by LREC-COLING 2024 (long paper, camera-ready version)",
      "pdf_url": "http://arxiv.org/pdf/2405.00358v1",
      "published_date": "2024-05-01 07:27:04 UTC",
      "updated_date": "2024-05-01 07:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:11:28.329612"
    },
    {
      "arxiv_id": "2405.00753v1",
      "title": "HMAMP: Hypervolume-Driven Multi-Objective Antimicrobial Peptides Design",
      "title_zh": "HMAMP：超体积",
      "authors": [
        "Li Wang",
        "Yiping Li",
        "Xiangzheng Fu",
        "Xiucai Ye",
        "Junfeng Shi",
        "Gary G. Yen",
        "Xiangxiang Zeng"
      ],
      "abstract": "Antimicrobial peptides (AMPs) have exhibited unprecedented potential as\nbiomaterials in combating multidrug-resistant bacteria. Despite the increasing\nadoption of artificial intelligence for novel AMP design, challenges pertaining\nto conflicting attributes such as activity, hemolysis, and toxicity have\nsignificantly impeded the progress of researchers. This paper introduces a\nparadigm shift by considering multiple attributes in AMP design.\n  Presented herein is a novel approach termed Hypervolume-driven\nMulti-objective Antimicrobial Peptide Design (HMAMP), which prioritizes the\nsimultaneous optimization of multiple attributes of AMPs. By synergizing\nreinforcement learning and a gradient descent algorithm rooted in the\nhypervolume maximization concept, HMAMP effectively expands exploration space\nand mitigates the issue of pattern collapse. This method generates a wide array\nof prospective AMP candidates that strike a balance among diverse attributes.\nFurthermore, we pinpoint knee points along the Pareto front of these candidate\nAMPs. Empirical results across five benchmark models substantiate that\nHMAMP-designed AMPs exhibit competitive performance and heightened diversity. A\ndetailed analysis of the helical structures and molecular dynamics simulations\nfor ten potential candidate AMPs validates the superiority of HMAMP in the\nrealm of multi-objective AMP design. The ability of HMAMP to systematically\ncraft AMPs considering multiple attributes marks a pioneering milestone,\nestablishing a universal computational framework for the multi-objective design\nof AMPs.",
      "tldr_zh": "本文提出 HMAMP，一种超体积驱动的多目标 Antimicrobial Peptides (AMPs) 设计方法，旨在同时优化活性、溶血性和毒性等冲突属性。HMAMP 通过结合 reinforcement learning 和基于 hypervolume maximization 的梯度下降算法，扩展探索空间并避免模式崩溃，生成多样化的 AMP 候选并识别 Pareto 前沿上的关键点。实验在五个基准模型上验证，HMAMP 设计的 AMPs 表现出竞争性性能和多样性优势，并通过螺旋结构分析和分子动力学模拟证实其优越性。该方法建立了通用的多目标 AMP 设计计算框架，推动了抗多药耐药细菌生物材料的研究。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00753v1",
      "published_date": "2024-05-01 07:17:59 UTC",
      "updated_date": "2024-05-01 07:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:11:41.981870"
    },
    {
      "arxiv_id": "2405.00352v1",
      "title": "Transformer-based Reasoning for Learning Evolutionary Chain of Events on Temporal Knowledge Graph",
      "title_zh": "基于 Transformer 的推理，用于在",
      "authors": [
        "Zhiyu Fang",
        "Shuai-Long Lei",
        "Xiaobin Zhu",
        "Chun Yang",
        "Shi-Xue Zhang",
        "Xu-Cheng Yin",
        "Jingyan Qin"
      ],
      "abstract": "Temporal Knowledge Graph (TKG) reasoning often involves completing missing\nfactual elements along the timeline. Although existing methods can learn good\nembeddings for each factual element in quadruples by integrating temporal\ninformation, they often fail to infer the evolution of temporal facts. This is\nmainly because of (1) insufficiently exploring the internal structure and\nsemantic relationships within individual quadruples and (2) inadequately\nlearning a unified representation of the contextual and temporal correlations\namong different quadruples. To overcome these limitations, we propose a novel\nTransformer-based reasoning model (dubbed ECEformer) for TKG to learn the\nEvolutionary Chain of Events (ECE). Specifically, we unfold the neighborhood\nsubgraph of an entity node in chronological order, forming an evolutionary\nchain of events as the input for our model. Subsequently, we utilize a\nTransformer encoder to learn the embeddings of intra-quadruples for ECE. We\nthen craft a mixed-context reasoning module based on the multi-layer perceptron\n(MLP) to learn the unified representations of inter-quadruples for ECE while\naccomplishing temporal knowledge reasoning. In addition, to enhance the\ntimeliness of the events, we devise an additional time prediction task to\ncomplete effective temporal information within the learned unified\nrepresentation. Extensive experiments on six benchmark datasets verify the\nstate-of-the-art performance and the effectiveness of our method.",
      "tldr_zh": "该论文针对 Temporal Knowledge Graph (TKG) 推理中的问题，提出了一种新型 Transformer-based 模型 ECEformer，以学习 Evolutionary Chain of Events (ECE)，从而更好地推断时间事实的演化。模型首先将实体节点的邻居子图按时间顺序展开，形成事件演化链作为输入，并使用 Transformer 编码器学习单个 quadruples 的内部结构和语义关系。接着，通过基于多层感知器 (MLP) 的混合上下文推理模块，统一表示不同 quadruples 之间的上下文和时间相关性，并添加时间预测任务以提升事件的及时性。实验在六个基准数据集上验证了 ECEformer 的 state-of-the-art 性能，显著提高了 TKG 推理的准确性和有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by SIGIR 2024 (the Full paper track, camera ready version)",
      "pdf_url": "http://arxiv.org/pdf/2405.00352v1",
      "published_date": "2024-05-01 07:12:16 UTC",
      "updated_date": "2024-05-01 07:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:11:54.129553"
    },
    {
      "arxiv_id": "2405.00351v1",
      "title": "Learning High-Quality Navigation and Zooming on Omnidirectional Images in Virtual Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Zidong Cao",
        "Zhan Wang",
        "Yexin Liu",
        "Yan-Pei Cao",
        "Ying Shan",
        "Wei Zeng",
        "Lin Wang"
      ],
      "abstract": "Viewing omnidirectional images (ODIs) in virtual reality (VR) represents a\nnovel form of media that provides immersive experiences for users to navigate\nand interact with digital content. Nonetheless, this sense of immersion can be\ngreatly compromised by a blur effect that masks details and hampers the user's\nability to engage with objects of interest. In this paper, we present a novel\nsystem, called OmniVR, designed to enhance visual clarity during VR navigation.\nOur system enables users to effortlessly locate and zoom in on the objects of\ninterest in VR. It captures user commands for navigation and zoom, converting\nthese inputs into parameters for the Mobius transformation matrix. Leveraging\nthese parameters, the ODI is refined using a learning-based algorithm. The\nresultant ODI is presented within the VR media, effectively reducing blur and\nincreasing user engagement. To verify the effectiveness of our system, we first\nevaluate our algorithm with state-of-the-art methods on public datasets, which\nachieves the best performance. Furthermore, we undertake a comprehensive user\nstudy to evaluate viewer experiences across diverse scenarios and to gather\ntheir qualitative feedback from multiple perspectives. The outcomes reveal that\nour system enhances user engagement by improving the viewers' recognition,\nreducing discomfort, and improving the overall immersive experience. Our system\nmakes the navigation and zoom more user-friendly.",
      "tldr_zh": "本文提出OmniVR系统，用于提升虚拟现实(VR)中全向图像(ODIs)的导航和缩放质量，解决模糊效果导致的细节缺失和用户互动问题。系统通过捕获用户命令转换为Mobius transformation矩阵参数，并运用学习算法优化ODIs，从而减少模糊并提高视觉清晰度。实验结果显示，OmniVR在公共数据集上超越最先进方法，用户研究进一步证明它提升了用户参与度、改善了对象识别、减轻了不适感，并增强了整体沉浸体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.00351v1",
      "published_date": "2024-05-01 07:08:24 UTC",
      "updated_date": "2024-05-01 07:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:12:04.134849"
    },
    {
      "arxiv_id": "2405.00332v4",
      "title": "A Careful Examination of Large Language Model Performance on Grade School Arithmetic",
      "title_zh": "翻译失败",
      "authors": [
        "Hugh Zhang",
        "Jeff Da",
        "Dean Lee",
        "Vaughn Robinson",
        "Catherine Wu",
        "Will Song",
        "Tiffany Zhao",
        "Pranav Raja",
        "Charlotte Zhuang",
        "Dylan Slack",
        "Qin Lyu",
        "Sean Hendryx",
        "Russell Kaplan",
        "Michele Lunati",
        "Summer Yue"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive success on many\nbenchmarks for mathematical reasoning. However, there is growing concern that\nsome of this performance actually reflects dataset contamination, where data\nclosely resembling benchmark questions leaks into the training data, instead of\ntrue reasoning ability. To investigate this claim rigorously, we commission\nGrade School Math 1000 (GSM1k). GSM1k is designed to mirror the style and\ncomplexity of the established GSM8k benchmark, the gold standard for measuring\nelementary mathematical reasoning. We ensure that the two benchmarks are\ncomparable across important metrics such as human solve rates, number of steps\nin solution, answer magnitude, and more. When evaluating leading open- and\nclosed-source LLMs on GSM1k, we observe accuracy drops of up to 8%, with\nseveral families of models showing evidence of systematic overfitting across\nalmost all model sizes. Further analysis suggests a positive relationship\n(Spearman's r^2 = 0.36) between a model's probability of generating an example\nfrom GSM8k and its performance gap between GSM8k and GSM1k, suggesting that\nsome models may have partially memorized GSM8k. Nevertheless, many models,\nespecially those on the frontier, show minimal signs of overfitting, and all\nmodels broadly demonstrate generalization to novel math problems guaranteed to\nnot be in their training data.",
      "tldr_zh": "本研究仔细评估了大型语言模型（LLMs）在小学算术任务上的性能，关注数据集污染可能导致的虚假推理能力。研究者开发了 Grade School Math 1000 (GSM1k) 基准，以匹配现有 GSM8k 基准的标准，包括人类解决率、解决方案步骤数和答案规模等指标。在 GSM1k 上测试领先的开源和闭源 LLMs 时，发现准确率下降高达 8%，许多模型显示出系统性过拟合现象。进一步分析显示，模型生成 GSM8k 示例的概率与在两个基准间的性能差距正相关（Spearman's r^2 = 0.36），暗示部分模型可能部分记忆了训练数据；尽管如此，前沿模型表现出最小过拟合迹象，并能良好泛化到新颖的数学问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "2024 NeurIPS Camera Ready (Datasets and Benchmarks Track)",
      "pdf_url": "http://arxiv.org/pdf/2405.00332v4",
      "published_date": "2024-05-01 05:52:05 UTC",
      "updated_date": "2024-11-22 22:27:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:12:17.164860"
    },
    {
      "arxiv_id": "2405.00330v1",
      "title": "Integrating A.I. in Higher Education: Protocol for a Pilot Study with 'SAMCares: An Adaptive Learning Hub'",
      "title_zh": "翻译失败",
      "authors": [
        "Syed Hasib Akhter Faruqui",
        "Nazia Tasnim",
        "Iftekhar Ibne Basith",
        "Suleiman Obeidat",
        "Faruk Yildiz"
      ],
      "abstract": "Learning never ends, and there is no age limit to grow yourself. However, the\neducational landscape may face challenges in effectively catering to students'\ninclusion and diverse learning needs. These students should have access to\nstate-of-the-art methods for lecture delivery, online resources, and technology\nneeds. However, with all the diverse learning sources, it becomes harder for\nstudents to comprehend a large amount of knowledge in a short period of time.\nTraditional assistive technologies and learning aids often lack the dynamic\nadaptability required for individualized education plans. Large Language Models\n(LLM) have been used in language translation, text summarization, and content\ngeneration applications. With rapid growth in AI over the past years,\nAI-powered chatbots and virtual assistants have been developed. This research\naims to bridge this gap by introducing an innovative study buddy we will be\ncalling the 'SAMCares'. The system leverages a Large Language Model (LLM) (in\nour case, LLaMa-2 70B as the base model) and Retriever-Augmented Generation\n(RAG) to offer real-time, context-aware, and adaptive educational support. The\ncontext of the model will be limited to the knowledge base of Sam Houston State\nUniversity (SHSU) course notes. The LLM component enables a chat-like\nenvironment to interact with it to meet the unique learning requirements of\neach student. For this, we will build a custom web-based GUI. At the same time,\nRAG enhances real-time information retrieval and text generation, in turn\nproviding more accurate and context-specific assistance. An option to upload\nadditional study materials in the web GUI is added in case additional knowledge\nsupport is required. The system's efficacy will be evaluated through controlled\ntrials and iterative feedback mechanisms.",
      "tldr_zh": "这篇论文提出一个试点研究协议，旨在整合AI于高等教育中，开发名为'SAMCares'的自适应学习中心，以解决学生多样化学习需求和传统辅助技术缺乏动态适应性的问题。'SAMCares'系统利用Large Language Model (LLM)如LLaMa-2 70B和Retriever-Augmented Generation (RAG)，基于Sam Houston State University (SHSU)的课程笔记，提供实时、上下文相关的聊天式教育支持，并支持上传额外学习材料。系统通过自定义的Web GUI实现个性化交互，帮助学生高效处理大量知识。研究将通过控制试验和迭代反馈机制评估其有效性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted in ASEE Annual Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00330v1",
      "published_date": "2024-05-01 05:39:07 UTC",
      "updated_date": "2024-05-01 05:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:12:29.825883"
    },
    {
      "arxiv_id": "2405.00319v2",
      "title": "Data Augmentation Policy Search for Long-Term Forecasting",
      "title_zh": "数据增强策略搜索用于长期预测",
      "authors": [
        "Liran Nochumsohn",
        "Omri Azencot"
      ],
      "abstract": "Data augmentation serves as a popular regularization technique to combat\noverfitting challenges in neural networks. While automatic augmentation has\ndemonstrated success in image classification tasks, its application to\ntime-series problems, particularly in long-term forecasting, has received\ncomparatively less attention. To address this gap, we introduce a time-series\nautomatic augmentation approach named TSAA, which is both efficient and easy to\nimplement. The solution involves tackling the associated bilevel optimization\nproblem through a two-step process: initially training a non-augmented model\nfor a limited number of epochs, followed by an iterative split procedure.\nDuring this iterative process, we alternate between identifying a robust\naugmentation policy through Bayesian optimization and refining the model while\ndiscarding suboptimal runs. Extensive evaluations on challenging univariate and\nmultivariate forecasting benchmark problems demonstrate that TSAA consistently\noutperforms several robust baselines, suggesting its potential integration into\nprediction pipelines. Code is available at this repository:\nhttps://github.com/azencot-group/TSAA.",
      "tldr_zh": "这篇论文提出了一种名为 TSAA 的时间序列自动增强方法，用于解决长期预测任务中神经网络过拟合的问题，该方法高效且易于实现。TSAA 通过双层优化过程，首先训练一个非增强模型，然后采用迭代分裂策略，交替使用 Bayesian optimization 识别稳健的增强策略并精炼模型。实验结果显示，TSAA 在单变量和多变量预测基准上 consistently 优于现有基线，证明其可集成到预测管道中以提升性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "TMLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.00319v2",
      "published_date": "2024-05-01 04:55:51 UTC",
      "updated_date": "2025-02-08 16:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:12:40.724717"
    },
    {
      "arxiv_id": "2405.00751v1",
      "title": "F$^3$low: Frame-to-Frame Coarse-grained Molecular Dynamics with SE(3) Guided Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoning Li",
        "Yusong Wang",
        "Mingyu Li",
        "Jian Zhang",
        "Bin Shao",
        "Nanning Zheng",
        "Jian Tang"
      ],
      "abstract": "Molecular dynamics (MD) is a crucial technique for simulating biological\nsystems, enabling the exploration of their dynamic nature and fostering an\nunderstanding of their functions and properties. To address exploration\ninefficiency, emerging enhanced sampling approaches like coarse-graining (CG)\nand generative models have been employed. In this work, we propose a\n\\underline{Frame-to-Frame} generative model with guided\n\\underline{Flow}-matching (F$3$low) for enhanced sampling, which (a) extends\nthe domain of CG modeling to the SE(3) Riemannian manifold; (b) retreating CGMD\nsimulations as autoregressively sampling guided by the former frame via\nflow-matching models; (c) targets the protein backbone, offering improved\ninsights into secondary structure formation and intricate folding pathways.\nCompared to previous methods, F$3$low allows for broader exploration of\nconformational space. The ability to rapidly generate diverse conformations via\nforce-free generative paradigm on SE(3) paves the way toward efficient enhanced\nsampling methods.",
      "tldr_zh": "这篇论文提出了 F$^3$low，一种 Frame-to-Frame 生成模型，用于提升分子动力学 (MD) 模拟的采样效率，通过 SE(3) Guided Flow Matching 将 Coarse-grained 建模扩展到 SE(3) Riemannian 流形。方法将 CGMD 模拟视为基于前一帧的自回归采样，并针对蛋白质主链，提供对二级结构形成和复杂折叠路径的更深入洞察。与现有方法相比，F$^3$low 实现了更广泛的构象空间探索，并通过无力的生成范式快速生成多样构象，推动高效增强采样技术的发展。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Accepted by ICLR 2024 GEM workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.00751v1",
      "published_date": "2024-05-01 04:53:14 UTC",
      "updated_date": "2024-05-01 04:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:12:55.235778"
    },
    {
      "arxiv_id": "2405.00314v1",
      "title": "Model Quantization and Hardware Acceleration for Vision Transformers: A Comprehensive Survey",
      "title_zh": "视觉变压器的模型量化与硬件加速：全面综述",
      "authors": [
        "Dayou Du",
        "Gu Gong",
        "Xiaowen Chu"
      ],
      "abstract": "Vision Transformers (ViTs) have recently garnered considerable attention,\nemerging as a promising alternative to convolutional neural networks (CNNs) in\nseveral vision-related applications. However, their large model sizes and high\ncomputational and memory demands hinder deployment, especially on\nresource-constrained devices. This underscores the necessity of\nalgorithm-hardware co-design specific to ViTs, aiming to optimize their\nperformance by tailoring both the algorithmic structure and the underlying\nhardware accelerator to each other's strengths. Model quantization, by\nconverting high-precision numbers to lower-precision, reduces the computational\ndemands and memory needs of ViTs, allowing the creation of hardware\nspecifically optimized for these quantized algorithms, boosting efficiency.\nThis article provides a comprehensive survey of ViTs quantization and its\nhardware acceleration. We first delve into the unique architectural attributes\nof ViTs and their runtime characteristics. Subsequently, we examine the\nfundamental principles of model quantization, followed by a comparative\nanalysis of the state-of-the-art quantization techniques for ViTs.\nAdditionally, we explore the hardware acceleration of quantized ViTs,\nhighlighting the importance of hardware-friendly algorithm design. In\nconclusion, this article will discuss ongoing challenges and future research\npaths. We consistently maintain the related open-source materials at\nhttps://github.com/DD-DuDa/awesome-vit-quantization-acceleration.",
      "tldr_zh": "这篇论文对 Vision Transformers (ViTs) 的模型量化(model quantization)和硬件加速(hardware acceleration)进行了全面调查，旨在解决 ViTs 在资源受限设备上部署的计算和内存需求问题。论文首先分析了 ViTs 的独特架构和运行特性，然后阐述了模型量化的基本原理，并比较了现有先进量化技术。研究强调了算法-硬件协同设计的必要性，以提升量化 ViTs 的效率和性能。最终，论文讨论了当前挑战和未来研究方向，并提供了相关开源资源如 https://github.com/DD-DuDa/awesome-vit-quantization-acceleration。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00314v1",
      "published_date": "2024-05-01 04:32:07 UTC",
      "updated_date": "2024-05-01 04:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:13:04.846646"
    },
    {
      "arxiv_id": "2405.00750v1",
      "title": "From Keyboard to Chatbot: An AI-powered Integration Platform with Large-Language Models for Teaching Computational Thinking for Young Children",
      "title_zh": "翻译失败",
      "authors": [
        "Changjae Lee",
        "Jinjun Xiong"
      ],
      "abstract": "Teaching programming in early childhood (4-9) to enhance computational\nthinking has gained popularity in the recent movement of computer science for\nall. However, current practices ignore some fundamental issues resulting from\nyoung children's developmental readiness, such as the sustained capability to\nkeyboarding, the decomposition of complex tasks to small tasks, the need for\nintuitive mapping from abstract programming to tangible outcomes, and the\nlimited amount of screen time exposure. To address these issues in this paper,\nwe present a novel methodology with an AI-powered integration platform to\neffectively teach computational thinking for young children. The system\nfeatures a hybrid pedagogy that supports both the top-down and bottom-up\napproach for teaching computational thinking. Young children can describe their\ndesired task in natural language, while the system can respond with an\neasy-to-understand program consisting of the right level of decomposed\nsub-tasks. A tangible robot can immediately execute the decomposed program and\ndemonstrate the program's outcomes to young children. The system is equipped\nwith an intelligent chatbot that can interact with young children through\nnatural languages, and children can speak to the chatbot to complete all the\nneeded programming tasks, while the chatbot orchestrates the execution of the\nprogram onto the robot. This would completely eliminates the need of keyboards\nfor young children to program. By developing such a system, we aim to make the\nconcept of computational thinking more accessible to young children, fostering\na natural understanding of programming concepts without the need of explicit\nprogramming skills. Through the interactive experience provided by the robotic\nagent, our system seeks to engage children in an effective manner, contributing\nto the field of educational technology for early childhood computer science\neducation.",
      "tldr_zh": "该论文提出了一种基于 Large-Language Models 的 AI 驱动集成平台，旨在解决教 4-9 岁儿童 computational thinking 时存在的键盘输入困难、任务分解挑战以及屏幕时间限制等问题。平台采用混合教学法（top-down 和 bottom-up），让儿童通过自然语言描述任务，系统则自动分解为易懂的子任务，并由 tangible robot 执行以展示结果。智能 chatbot 负责与儿童的互动对话，彻底消除键盘需求，促进对编程概念的自然理解。该方法通过机器人互动提升了早期儿童计算机科学教育的可访问性和有效性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "26 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.00750v1",
      "published_date": "2024-05-01 04:29:21 UTC",
      "updated_date": "2024-05-01 04:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:13:19.485952"
    },
    {
      "arxiv_id": "2405.00307v1",
      "title": "Active Learning with Task Adaptation Pre-training for Speech Emotion Recognition",
      "title_zh": "主动学习结合任务适应预训练",
      "authors": [
        "Dongyuan Li",
        "Ying Zhang",
        "Yusong Wang",
        "Funakoshi Kataro",
        "Manabu Okumura"
      ],
      "abstract": "Speech emotion recognition (SER) has garnered increasing attention due to its\nwide range of applications in various fields, including human-machine\ninteraction, virtual assistants, and mental health assistance. However,\nexisting SER methods often overlook the information gap between the\npre-training speech recognition task and the downstream SER task, resulting in\nsub-optimal performance. Moreover, current methods require much time for\nfine-tuning on each specific speech dataset, such as IEMOCAP, which limits\ntheir effectiveness in real-world scenarios with large-scale noisy data. To\naddress these issues, we propose an active learning (AL)-based fine-tuning\nframework for SER, called \\textsc{After}, that leverages task adaptation\npre-training (TAPT) and AL methods to enhance performance and efficiency.\nSpecifically, we first use TAPT to minimize the information gap between the\npre-training speech recognition task and the downstream speech emotion\nrecognition task. Then, AL methods are employed to iteratively select a subset\nof the most informative and diverse samples for fine-tuning, thereby reducing\ntime consumption. Experiments demonstrate that our proposed method\n\\textsc{After}, using only 20\\% of samples, improves accuracy by 8.45\\% and\nreduces time consumption by 79\\%. The additional extension of \\textsc{After}\nand ablation studies further confirm its effectiveness and applicability to\nvarious real-world scenarios. Our source code is available on Github for\nreproducibility. (https://github.com/Clearloveyuan/AFTER).",
      "tldr_zh": "本研究针对语音情感识别(Speech Emotion Recognition, SER)中预训练任务与下游任务信息差距问题，提出了一种名为 After 的主动学习(Active Learning, AL)框架，结合任务适应预训练(Task Adaptation Pre-training, TAPT)来提升性能和效率。具体而言，After 先通过 TAPT 缩小预训练语音识别与 SER 任务的差距，然后使用 AL 方法迭代选择最信息丰富的样本子集进行微调，从而减少训练时间。实验结果显示，该框架仅使用 20% 的样本，即提高了 8.45% 的准确率，并将时间消耗减少了 79%；扩展实验和消融研究进一步验证了其在实际场景中的适用性，并提供了开源代码以便复现。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by Journal of Natural Language Processing. arXiv admin note:\n  text overlap with arXiv:2310.00283",
      "pdf_url": "http://arxiv.org/pdf/2405.00307v1",
      "published_date": "2024-05-01 04:05:29 UTC",
      "updated_date": "2024-05-01 04:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:13:33.553688"
    },
    {
      "arxiv_id": "2405.00291v1",
      "title": "How Can I Improve? Using GPT to Highlight the Desired and Undesired Parts of Open-ended Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Jionghao Lin",
        "Eason Chen",
        "Zeifei Han",
        "Ashish Gurung",
        "Danielle R. Thomas",
        "Wei Tan",
        "Ngoc Dang Nguyen",
        "Kenneth R. Koedinger"
      ],
      "abstract": "Automated explanatory feedback systems play a crucial role in facilitating\nlearning for a large cohort of learners by offering feedback that incorporates\nexplanations, significantly enhancing the learning process. However, delivering\nsuch explanatory feedback in real-time poses challenges, particularly when high\nclassification accuracy for domain-specific, nuanced responses is essential.\nOur study leverages the capabilities of large language models, specifically\nGenerative Pre-Trained Transformers (GPT), to explore a sequence labeling\napproach focused on identifying components of desired and less desired praise\nfor providing explanatory feedback within a tutor training dataset. Our aim is\nto equip tutors with actionable, explanatory feedback during online training\nlessons. To investigate the potential of GPT models for providing the\nexplanatory feedback, we employed two commonly-used approaches: prompting and\nfine-tuning. To quantify the quality of highlighted praise components\nidentified by GPT models, we introduced a Modified Intersection over Union\n(M-IoU) score. Our findings demonstrate that: (1) the M-IoU score effectively\ncorrelates with human judgment in evaluating sequence quality; (2) using\ntwo-shot prompting on GPT-3.5 resulted in decent performance in recognizing\neffort-based (M-IoU of 0.46) and outcome-based praise (M-IoU of 0.68); and (3)\nour optimally fine-tuned GPT-3.5 model achieved M-IoU scores of 0.64 for\neffort-based praise and 0.84 for outcome-based praise, aligning with the\nsatisfaction levels evaluated by human coders. Our results show promise for\nusing GPT models to provide feedback that focuses on specific elements in their\nopen-ended responses that are desirable or could use improvement.",
      "tldr_zh": "这篇论文探讨了利用 Generative Pre-Trained Transformers (GPT) 模型，通过序列标记方法来识别开放式响应中的期望（desired）和不期望（undesired）部分，从而为导师培训提供可行动的解释性反馈。研究采用 prompting 和 fine-tuning 两种策略，并在 GPT-3.5 上进行实验，使用 Modified Intersection over Union (M-IoU) 得分来量化评估质量。结果显示，two-shot prompting 在 effort-based praise 和 outcome-based praise 上的 M-IoU 分别为 0.46 和 0.68，而微调后的模型提升至 0.64 和 0.84，与人类判断高度一致。该方法展示了 GPT 模型在实时反馈中的潜力，有助于提升学习过程的效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, full research paper, EDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00291v1",
      "published_date": "2024-05-01 02:59:10 UTC",
      "updated_date": "2024-05-01 02:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:13:45.935739"
    },
    {
      "arxiv_id": "2405.00289v2",
      "title": "Adversarial Attacks and Defense for Conversation Entailment Task",
      "title_zh": "针对对话蕴涵任务的对抗攻击和防御",
      "authors": [
        "Zhenning Yang",
        "Ryan Krawec",
        "Liang-Yuan Wu"
      ],
      "abstract": "As the deployment of NLP systems in critical applications grows, ensuring the\nrobustness of large language models (LLMs) against adversarial attacks becomes\nincreasingly important. Large language models excel in various NLP tasks but\nremain vulnerable to low-cost adversarial attacks. Focusing on the domain of\nconversation entailment, where multi-turn dialogues serve as premises to verify\nhypotheses, we fine-tune a transformer model to accurately discern the\ntruthfulness of these hypotheses. Adversaries manipulate hypotheses through\nsynonym swapping, aiming to deceive the model into making incorrect\npredictions. To counteract these attacks, we implemented innovative fine-tuning\ntechniques and introduced an embedding perturbation loss method to\nsignificantly bolster the model's robustness. Our findings not only emphasize\nthe importance of defending against adversarial attacks in NLP but also\nhighlight the real-world implications, suggesting that enhancing model\nrobustness is critical for reliable NLP applications.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 在对话蕴涵任务中的脆弱性，特别是在面对低成本对抗性攻击时。研究者通过微调 transformer 模型来验证多轮对话作为前提的假设真实性，同时分析了攻击者使用同义词交换 (synonym swapping) 来操纵假设并欺骗模型的策略。为提升鲁棒性，他们引入了嵌入扰动损失 (embedding perturbation loss) 等创新微调技术，显著提高了模型的防御能力。最终，研究强调了在实际 NLP 应用中增强模型鲁棒性的关键重要性，以确保可靠性和真实世界部署。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00289v2",
      "published_date": "2024-05-01 02:49:18 UTC",
      "updated_date": "2024-05-02 03:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:13:57.965223"
    },
    {
      "arxiv_id": "2405.00748v2",
      "title": "ChatGPT in Data Visualization Education: A Student Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Nam Wook Kim",
        "Hyung-Kwon Ko",
        "Grace Myers",
        "Benjamin Bach"
      ],
      "abstract": "Unlike traditional educational chatbots that rely on pre-programmed\nresponses, large-language model-driven chatbots, such as ChatGPT, demonstrate\nremarkable versatility to serve as a dynamic resource for addressing student\nneeds from understanding advanced concepts to solving complex problems. This\nwork explores the impact of such technology on student learning in an\ninterdisciplinary, project-oriented data visualization course. Throughout the\nsemester, students engaged with ChatGPT across four distinct projects,\ndesigning and implementing data visualizations using a variety of tools such as\nTableau, D3, and Vega-lite. We collected conversation logs and reflection\nsurveys after each assignment and conducted interviews with selected students\nto gain deeper insights into their experiences with ChatGPT. Our analysis\nexamined the advantages and barriers of using ChatGPT, students' querying\nbehavior, the types of assistance sought, and its impact on assignment outcomes\nand engagement. We discuss design considerations for an educational solution\ntailored for data visualization education, extending beyond ChatGPT's basic\ninterface.",
      "tldr_zh": "这篇论文从学生视角探讨了 ChatGPT 在数据可视化教育中的作用，强调其作为动态资源帮助学生理解高级概念和解决复杂问题。研究方法包括在跨学科数据可视化课程中跟踪学生使用 ChatGPT 的四个项目过程，收集对话日志、反思调查和访谈数据，并分析查询行为、优势（如工具辅助如 Tableau、D3 和 Vega-lite）、障碍以及对作业成果和参与度的影响。结果显示 ChatGPT 显著提升了学习效果，但也存在挑战；论文进而提出针对数据可视化教育的定制设计建议，超越 ChatGPT 的基本界面。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages; 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.00748v2",
      "published_date": "2024-05-01 02:40:20 UTC",
      "updated_date": "2024-08-16 21:50:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:14:08.150783"
    },
    {
      "arxiv_id": "2405.00287v2",
      "title": "SCONE: A Novel Stochastic Sampling to Generate Contrastive Views and Hard Negative Samples for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Chaejeong Lee",
        "Jeongwhan Choi",
        "Hyowon Wi",
        "Sung-Bae Cho",
        "Noseong Park"
      ],
      "abstract": "Graph-based collaborative filtering (CF) has emerged as a promising approach\nin recommender systems. Despite its achievements, graph-based CF models face\nchallenges due to data sparsity and negative sampling. In this paper, we\npropose a novel Stochastic sampling for i) COntrastive views and ii) hard\nNEgative samples (SCONE) to overcome these issues. SCONE generates dynamic\naugmented views and diverse hard negative samples via a unified stochastic\nsampling approach based on score-based generative models. Our extensive\nexperiments on 6 benchmark datasets show that SCONE consistently outperforms\nstate-of-the-art baselines. SCONE shows efficacy in addressing user sparsity\nand item popularity issues, while enhancing performance for both cold-start\nusers and long-tail items. Furthermore, our approach improves the diversity of\nthe recommendation and the uniformity of the representations. The code is\navailable at https://github.com/jeongwhanchoi/SCONE.",
      "tldr_zh": "这篇论文提出 SCONE，一种新颖的随机采样方法，用于生成对比视图（Contrastive views）和硬负样本（Hard Negative Samples），以解决图-based CF 在推荐系统中的数据稀疏性和负采样挑战。SCONE 通过基于分数的生成模型进行统一随机采样，动态创建增强视图和多样化负样本，从而提升模型性能。在6个基准数据集上的实验表明，SCONE 超过了现有基线模型，在处理用户稀疏性、物品流行度问题以及改善冷启动用户和长尾物品的推荐效果方面表现出色，同时增强了推荐的多样性和表示的均匀性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to WSDM 2025. Chaejeong Lee and Jeongwhan Choi are co-first\n  authors with equal contributions",
      "pdf_url": "http://arxiv.org/pdf/2405.00287v2",
      "published_date": "2024-05-01 02:27:59 UTC",
      "updated_date": "2024-12-19 05:48:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:14:20.313088"
    },
    {
      "arxiv_id": "2405.00285v4",
      "title": "iMTSP: Solving Min-Max Multiple Traveling Salesman Problem with Imperative Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Guo",
        "Zhongqiang Ren",
        "Chen Wang"
      ],
      "abstract": "This paper considers a Min-Max Multiple Traveling Salesman Problem (MTSP),\nwhere the goal is to find a set of tours, one for each agent, to collectively\nvisit all the cities while minimizing the length of the longest tour. Though\nMTSP has been widely studied, obtaining near-optimal solutions for large-scale\nproblems is still challenging due to its NP-hardness. Recent efforts in\ndata-driven methods face challenges of the need for hard-to-obtain supervision\nand issues with high variance in gradient estimations, leading to slow\nconvergence and highly suboptimal solutions. We address these issues by\nreformulating MTSP as a bilevel optimization problem, using the concept of\nimperative learning (IL). This involves introducing an allocation network that\ndecomposes the MTSP into multiple single-agent traveling salesman problems\n(TSPs). The longest tour from these TSP solutions is then used to\nself-supervise the allocation network, resulting in a new self-supervised,\nbilevel, end-to-end learning framework, which we refer to as imperative MTSP\n(iMTSP). Additionally, to tackle the high-variance gradient issues during the\noptimization, we introduce a control variate-based gradient estimation\nalgorithm. Our experiments showed that these innovative designs enable our\ngradient estimator to converge 20% faster than the advanced reinforcement\nlearning baseline and find up to 80% shorter tour length compared with Google\nOR-Tools MTSP solver, especially in large-scale problems (e.g. 1000 cities and\n15 agents).",
      "tldr_zh": "这篇论文针对 Min-Max Multiple Traveling Salesman Problem (MTSP) 提出了一种新框架 iMTSP，使用 Imperative Learning (IL) 将问题重构为双层优化问题。方法通过引入分配网络，将 MTSP 分解为多个单代理 Traveling Salesman Problem (TSP)，并采用自监督机制利用最长路径来优化网络，同时引入基于控制变量的梯度估计算法来降低优化过程中的高方差问题。实验结果显示，该框架比高级强化学习基线收敛速度快 20%，并在大规模场景（如 1000 个城市和 15 个代理）中找到比 Google OR-Tools 短 80% 的路径。总的来说，iMTSP 显著提高了 MTSP 的求解效率和解质量。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.00285v4",
      "published_date": "2024-05-01 02:26:13 UTC",
      "updated_date": "2024-08-23 15:02:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:14:34.206950"
    },
    {
      "arxiv_id": "2405.00282v1",
      "title": "MF-OML: Online Mean-Field Reinforcement Learning with Occupation Measures for Large Population Games",
      "title_zh": "MF-OML：在线均场强化学习算法，使用占用度量，针对大型种群游戏",
      "authors": [
        "Anran Hu",
        "Junzi Zhang"
      ],
      "abstract": "Reinforcement learning for multi-agent games has attracted lots of attention\nrecently. However, given the challenge of solving Nash equilibria for large\npopulation games, existing works with guaranteed polynomial complexities either\nfocus on variants of zero-sum and potential games, or aim at solving (coarse)\ncorrelated equilibria, or require access to simulators, or rely on certain\nassumptions that are hard to verify. This work proposes MF-OML (Mean-Field\nOccupation-Measure Learning), an online mean-field reinforcement learning\nalgorithm for computing approximate Nash equilibria of large population\nsequential symmetric games. MF-OML is the first fully polynomial multi-agent\nreinforcement learning algorithm for provably solving Nash equilibria (up to\nmean-field approximation gaps that vanish as the number of players $N$ goes to\ninfinity) beyond variants of zero-sum and potential games. When evaluated by\nthe cumulative deviation from Nash equilibria, the algorithm is shown to\nachieve a high probability regret bound of $\\tilde{O}(M^{3/4}+N^{-1/2}M)$ for\ngames with the strong Lasry-Lions monotonicity condition, and a regret bound of\n$\\tilde{O}(M^{11/12}+N^{- 1/6}M)$ for games with only the Lasry-Lions\nmonotonicity condition, where $M$ is the total number of episodes and $N$ is\nthe number of agents of the game. As a byproduct, we also obtain the first\ntractable globally convergent computational algorithm for computing approximate\nNash equilibria of monotone mean-field games.",
      "tldr_zh": "该论文提出了一种名为 MF-OML 的在线均值场强化学习算法（Online Mean-Field Reinforcement Learning），利用 Occupation Measures 来计算大型人口顺序对称游戏的近似 Nash 均衡，克服了现有方法在零和游戏或势函数游戏之外的局限性。MF-OML 是首个为更广泛游戏类型提供多项式复杂度的多智能体强化学习算法，能够证明在均值场近似下解决 Nash 均衡，且当代理数量 $N$ 增大时近似误差消失。实验结果显示，该算法在累积偏差方面达到高概率 regret bound：对于强 Lasry-Lions 单调性游戏为 $\\tilde{O}(M^{3/4} + N^{-1/2}M)$，对于 Lasry-Lions 单调性游戏为 $\\tilde{O}(M^{11/12} + N^{-1/6}M)$，其中 $M$ 为总 episode 数，同时还衍生出首个可处理的全局收敛算法，用于计算单调均值场游戏的近似 Nash 均衡。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00282v1",
      "published_date": "2024-05-01 02:19:31 UTC",
      "updated_date": "2024-05-01 02:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:14:46.053062"
    },
    {
      "arxiv_id": "2405.00263v1",
      "title": "Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Xiao",
        "Chunan Shi",
        "Xiaonan Nie",
        "Fan Yang",
        "Xiangwei Deng",
        "Lei Su",
        "Weipeng Chen",
        "Bin Cui"
      ],
      "abstract": "Large language models (LLMs) suffer from low efficiency as the mismatch\nbetween the requirement of auto-regressive decoding and the design of most\ncontemporary GPUs. Specifically, billions to trillions of parameters must be\nloaded to the GPU cache through its limited memory bandwidth for computation,\nbut only a small batch of tokens is actually computed. Consequently, the GPU\nspends most of its time on memory transfer instead of computation. Recently,\nparallel decoding, a type of speculative decoding algorithms, is becoming more\npopular and has demonstrated impressive efficiency improvement in generation.\nIt introduces extra decoding heads to large models, enabling them to predict\nmultiple subsequent tokens simultaneously and verify these candidate\ncontinuations in a single decoding step. However, this approach deviates from\nthe training objective of next token prediction used during pre-training,\nresulting in a low hit rate for candidate tokens. In this paper, we propose a\nnew speculative decoding algorithm, Clover, which integrates sequential\nknowledge into the parallel decoding process. This enhancement improves the hit\nrate of speculators and thus boosts the overall efficiency. Clover transmits\nthe sequential knowledge from pre-speculated tokens via the Regressive\nConnection, then employs an Attention Decoder to integrate these speculated\ntokens. Additionally, Clover incorporates an Augmenting Block that modifies the\nhidden states to better align with the purpose of speculative generation rather\nthan next token prediction. The experiment results demonstrate that Clover\noutperforms the baseline by up to 91% on Baichuan-Small and 146% on\nBaichuan-Large, respectively, and exceeds the performance of the previously\ntop-performing method, Medusa, by up to 37% on Baichuan-Small and 57% on\nBaichuan-Large, respectively.",
      "tldr_zh": "大型语言模型 (LLMs) 在自动回归解码过程中效率低下，主要由于 GPU 内存带宽限制和计算不匹配，论文提出了一种新颖的推测性解码算法 Clover，以整合顺序知识提升生成效率。Clover 通过 Regressive Connection 传输预推测标记的顺序知识，利用 Attention Decoder 整合这些标记，并添加 Augmenting Block 来修改隐藏状态，使其更适合推测生成而非单纯的下一个标记预测。实验结果显示，Clover 在 Baichuan-Small 上比基线提高 91%，在 Baichuan-Large 上提高 146%，并分别超过之前最佳方法 Medusa 37% 和 57%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00263v1",
      "published_date": "2024-05-01 00:46:22 UTC",
      "updated_date": "2024-05-01 00:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:14:57.601566"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 68,
  "processed_papers_count": 68,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T05:15:18.304764"
}